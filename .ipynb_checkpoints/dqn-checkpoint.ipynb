{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.tensor as Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(env.observation_space.shape[0], 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, env.action_space.n)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.buffer = []\n",
    "        self.index = 0\n",
    "        self.transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "        \n",
    "    def fill_buffer(self):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        for trans in tqdm(range(0, self.size)):\n",
    "            action = env.action_space.sample()\n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            self.buffer.append(self.transition(obs, action, reward, new_obs, done))\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "                done = False\n",
    "            else:\n",
    "                obs = new_obs\n",
    "    \n",
    "    def store_filled(self, trans):\n",
    "        self.index = (self.index + 1) % self.size\n",
    "        self.buffer[self.index] = self.transition(trans[0], trans[1], trans[2], trans[3], trans[4])\n",
    "        \n",
    "    def store(self, trans):\n",
    "        if (self.index + 1) % self.size:\n",
    "            self.buffer.append(self.transition(trans[0], trans[1], trans[2], trans[3], trans[4]))\n",
    "            self.index += 1\n",
    "        else:\n",
    "            self.store_filled(trans)\n",
    "        \n",
    "    def sample(self, batch=32):\n",
    "        return random.sample(self.buffer, k=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "buffer = ReplayBuffer(10000)\n",
    "# buffer.fill_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "value = MLP()\n",
    "target = copy.deepcopy(value)\n",
    "optimizer = optim.Adam(value.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(obs):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return torch.argmax(get_current_value())\n",
    "    \n",
    "def get_target_value(obs):\n",
    "    return target.forward(torch.from_numpy(obs).float().unsqueeze(0)).detach()\n",
    "\n",
    "def get_current_value(obs):\n",
    "    return value.forward(torch.from_numpy(obs).float().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:12<00:00, 137.98it/s]\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 10000\n",
    "epsilon = 1\n",
    "gamma = 0.9\n",
    "rewards = []\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "for episode in tqdm(range(0, EPISODES)):\n",
    "    action = get_action(obs)\n",
    "    new_obs, reward, done, _ = env.step(action)\n",
    "    buffer.store((obs, action, reward, new_obs, done))\n",
    "    if done:\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        rewards.append(step)\n",
    "        step = 0\n",
    "    else:\n",
    "        step += 1\n",
    "        obs = new_obs\n",
    "        \n",
    "    if len(buffer.buffer) > 32:\n",
    "        optimizer.zero_grad()\n",
    "        minibatch = buffer.sample()\n",
    "        next_qs = [i.reward if i.done else i.reward + gamma * torch.max(get_target_value(i.next_state)) for i in minibatch]\n",
    "        current_qs = [get_current_value(i.state).squeeze(0)[0] for i in minibatch]\n",
    "        loss = loss_fn(current_qs, next_qs)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_qs[1].squeeze(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
