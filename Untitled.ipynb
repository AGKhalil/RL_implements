{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from policies import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dis = gym.make('MountainCar-v0')\n",
    "env_cont = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dis = [env_dis.observation_space.shape[0], 64, 32, env_dis.action_space.n]\n",
    "layers_cont = [env_cont.observation_space.shape[0], 64, 32, env_cont.action_space.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "  (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP(layers_cont)\n",
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0476]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env_dis.reset()\n",
    "net.forward(torch.from_numpy(obs).float().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.fc)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-a7bfda2ead8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/torchEnv/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     40\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     41\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torchEnv/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.7024, -0.5030],\n",
       "         [ 0.6408, -0.5348],\n",
       "         [ 0.2443,  0.4554],\n",
       "         [ 0.2933,  0.1217],\n",
       "         [ 0.7009,  0.3074],\n",
       "         [-0.2651, -0.6796],\n",
       "         [ 0.0119, -0.5161],\n",
       "         [ 0.4084, -0.2931],\n",
       "         [-0.5381, -0.1816],\n",
       "         [ 0.1700, -0.1500],\n",
       "         [ 0.0074, -0.2472],\n",
       "         [ 0.1574, -0.5488],\n",
       "         [-0.3381,  0.4484],\n",
       "         [ 0.1898, -0.1685],\n",
       "         [ 0.2756, -0.4325],\n",
       "         [ 0.0549, -0.3703],\n",
       "         [ 0.3157, -0.6183],\n",
       "         [-0.3918,  0.2805],\n",
       "         [ 0.6885,  0.6602],\n",
       "         [ 0.6684, -0.3978],\n",
       "         [-0.2718, -0.5511],\n",
       "         [-0.5039, -0.1366],\n",
       "         [ 0.0803,  0.6236],\n",
       "         [ 0.3304, -0.1790],\n",
       "         [-0.2548, -0.0737],\n",
       "         [ 0.2478, -0.3758],\n",
       "         [-0.5950, -0.2823],\n",
       "         [-0.1043, -0.3490],\n",
       "         [-0.4873, -0.1772],\n",
       "         [-0.4040,  0.1890],\n",
       "         [-0.2047, -0.4461],\n",
       "         [-0.2082, -0.6337],\n",
       "         [-0.6023,  0.0130],\n",
       "         [-0.6597,  0.5019],\n",
       "         [-0.4696,  0.1888],\n",
       "         [-0.2930,  0.1790],\n",
       "         [-0.3663, -0.4356],\n",
       "         [ 0.3555,  0.0017],\n",
       "         [ 0.6782, -0.6190],\n",
       "         [ 0.3684,  0.6994],\n",
       "         [ 0.4168, -0.0164],\n",
       "         [ 0.3859, -0.4181],\n",
       "         [-0.6372,  0.4235],\n",
       "         [ 0.2490,  0.4762],\n",
       "         [ 0.2934,  0.1317],\n",
       "         [ 0.2626,  0.0640],\n",
       "         [-0.6454, -0.1662],\n",
       "         [-0.3881, -0.5413],\n",
       "         [ 0.4746, -0.3542],\n",
       "         [ 0.5047,  0.6017],\n",
       "         [ 0.0904, -0.1836],\n",
       "         [ 0.1091,  0.4391],\n",
       "         [-0.0834, -0.3344],\n",
       "         [ 0.1244, -0.5653],\n",
       "         [-0.2870,  0.5034],\n",
       "         [-0.4236,  0.1188],\n",
       "         [ 0.0167,  0.3967],\n",
       "         [ 0.4910, -0.3319],\n",
       "         [-0.5223,  0.1025],\n",
       "         [-0.5247, -0.1390],\n",
       "         [-0.2861,  0.1747],\n",
       "         [-0.5667,  0.6432],\n",
       "         [ 0.1505, -0.1059],\n",
       "         [ 0.5085, -0.1606]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5737, -0.0762, -0.0173,  0.4891,  0.0629,  0.2859,  0.0261, -0.0997,\n",
       "          0.0646,  0.2832,  0.3095,  0.5558,  0.0078, -0.1673,  0.5922, -0.5266,\n",
       "          0.5903,  0.0946,  0.3278, -0.4644, -0.1957, -0.3990, -0.3331,  0.5179,\n",
       "         -0.1147, -0.2852, -0.1466, -0.5010,  0.4701,  0.2139,  0.3869, -0.1185,\n",
       "          0.4807, -0.6468,  0.6288, -0.5590,  0.4902,  0.2795,  0.5633,  0.5204,\n",
       "         -0.5938,  0.6593, -0.3638, -0.1556,  0.6475, -0.2798, -0.5180, -0.6742,\n",
       "         -0.3002,  0.4196, -0.0880, -0.3359, -0.4713,  0.6580,  0.4606, -0.5397,\n",
       "          0.3809,  0.2591,  0.6425, -0.2433,  0.4471, -0.4367, -0.4009, -0.3867],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1121, -0.0853,  0.0450,  ..., -0.0144,  0.1246, -0.0807],\n",
       "         [-0.0569, -0.0979,  0.0171,  ...,  0.0370, -0.0213,  0.0060],\n",
       "         [ 0.0803, -0.0721, -0.1019,  ..., -0.0500, -0.0343, -0.0824],\n",
       "         ...,\n",
       "         [-0.0186,  0.0228, -0.0371,  ...,  0.0847,  0.0745,  0.0922],\n",
       "         [-0.0251, -0.0433, -0.0086,  ...,  0.0353, -0.0249, -0.0193],\n",
       "         [ 0.0927, -0.0562, -0.0420,  ..., -0.0571,  0.1003,  0.1234]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0073, -0.0754, -0.0219,  0.1168,  0.0757,  0.0718,  0.0454, -0.0872,\n",
       "          0.0584, -0.0075, -0.0614, -0.1128,  0.0597,  0.0243, -0.0820,  0.0182,\n",
       "         -0.0542, -0.0221,  0.0745, -0.0448, -0.1012,  0.1003, -0.0620, -0.0187,\n",
       "          0.0496, -0.0146,  0.1046,  0.1036, -0.0556,  0.0206, -0.0856, -0.1013],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1273,  0.0508,  0.0132, -0.1029, -0.0847,  0.0787,  0.0290, -0.0056,\n",
       "           0.1113,  0.0368,  0.1374,  0.0875,  0.1194, -0.0450,  0.0288, -0.0829,\n",
       "          -0.0238,  0.0636,  0.0338,  0.0781,  0.0007, -0.0571, -0.1682,  0.0522,\n",
       "          -0.1511,  0.0228, -0.1603,  0.1339, -0.1185, -0.0411, -0.0696,  0.0314]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1083], requires_grad=True)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "            \n",
    "    def forward(self, x, softmax=False):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        if softmax:\n",
    "          return F.softmax(x)\n",
    "        else:\n",
    "          return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLP(\n",
       "  (fc1): Linear(in_features=1, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met = NLP()\n",
    "met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6854],\n",
       "         [-0.2397],\n",
       "         [-0.5557],\n",
       "         [-0.5008],\n",
       "         [-0.6596],\n",
       "         [-0.8064],\n",
       "         [-0.1296],\n",
       "         [ 0.9543],\n",
       "         [ 0.0958],\n",
       "         [-0.2036],\n",
       "         [-0.0941],\n",
       "         [ 0.1184],\n",
       "         [-0.6507],\n",
       "         [ 0.3455],\n",
       "         [ 0.1342],\n",
       "         [ 0.0562],\n",
       "         [ 0.6042],\n",
       "         [-0.8056],\n",
       "         [-0.2621],\n",
       "         [ 0.1702],\n",
       "         [ 0.6770],\n",
       "         [-0.6809],\n",
       "         [-0.0617],\n",
       "         [ 0.0544],\n",
       "         [ 0.4310],\n",
       "         [-0.9328],\n",
       "         [ 0.2418],\n",
       "         [ 0.1271],\n",
       "         [-0.6359],\n",
       "         [ 0.4335],\n",
       "         [-0.5251],\n",
       "         [-0.1287],\n",
       "         [-0.6560],\n",
       "         [-0.9672],\n",
       "         [ 0.1174],\n",
       "         [ 0.3408],\n",
       "         [-0.1155],\n",
       "         [ 0.5991],\n",
       "         [-0.7991],\n",
       "         [-0.0421],\n",
       "         [-0.8828],\n",
       "         [ 0.0873],\n",
       "         [ 0.4835],\n",
       "         [ 0.5592],\n",
       "         [ 0.5378],\n",
       "         [-0.0908],\n",
       "         [-0.7778],\n",
       "         [ 0.4203],\n",
       "         [-0.2409],\n",
       "         [-0.1736],\n",
       "         [-0.4588],\n",
       "         [ 0.8432],\n",
       "         [ 0.6659],\n",
       "         [ 0.5741],\n",
       "         [-0.6806],\n",
       "         [-0.6277],\n",
       "         [-0.0010],\n",
       "         [-0.6617],\n",
       "         [-0.8516],\n",
       "         [-0.7906],\n",
       "         [-0.0525],\n",
       "         [-0.1062],\n",
       "         [-0.4934],\n",
       "         [ 0.1645]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.8224, -0.5310,  0.3621,  0.9417,  0.8861, -0.9034, -0.2220, -0.4352,\n",
       "          0.1289, -0.0675,  0.2811, -0.0073, -0.3129,  0.3266, -0.6085, -0.7516,\n",
       "         -0.0354,  0.1433,  0.9076,  0.1006, -0.5692,  0.0731, -0.4137,  0.4385,\n",
       "          0.3824,  0.2325, -0.8275,  0.7904, -0.2314,  0.2962,  0.5675,  0.2886,\n",
       "          0.3015, -0.3509, -0.5405,  0.5099, -0.9322, -0.7912,  0.7130,  0.9766,\n",
       "          0.8095,  0.1414,  0.5081, -0.1066, -0.7537,  0.4232,  0.5479, -0.1973,\n",
       "          0.8532,  0.6353, -0.3825, -0.9297,  0.0718, -0.9154, -0.1350,  0.1626,\n",
       "         -0.4521, -0.5038,  0.4790, -0.3825,  0.8913, -0.0709, -0.3991,  0.4169],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0105, -0.0006,  0.0701,  ...,  0.1184,  0.1184,  0.0681],\n",
       "         [-0.0906, -0.0526,  0.1155,  ..., -0.0353,  0.0981,  0.0707],\n",
       "         [ 0.0682,  0.0438,  0.0553,  ..., -0.0527,  0.0149, -0.0006],\n",
       "         ...,\n",
       "         [-0.0432,  0.0790, -0.1020,  ..., -0.1154, -0.0895,  0.0933],\n",
       "         [-0.0995, -0.1047, -0.0808,  ...,  0.0275, -0.1198,  0.1009],\n",
       "         [ 0.1222,  0.1244,  0.0268,  ..., -0.1203, -0.1201, -0.0920]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0380,  0.1103, -0.0419,  0.0751,  0.0317, -0.0169, -0.0281,  0.1063,\n",
       "         -0.1026, -0.0245, -0.0519,  0.0790,  0.1013,  0.1239, -0.1115,  0.0434,\n",
       "          0.1103, -0.1114,  0.0149,  0.0240, -0.0155, -0.0404, -0.0670, -0.0807,\n",
       "          0.0798, -0.0148, -0.1233,  0.0887, -0.0778, -0.0117, -0.0032, -0.0516],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.8422e-02, -5.7541e-02,  6.8075e-02,  1.4250e-01, -1.6829e-01,\n",
       "          -7.9105e-02, -4.7124e-02,  5.1213e-02,  1.2149e-01, -1.0622e-01,\n",
       "           1.0736e-01,  2.4496e-02, -1.0401e-01,  6.0215e-02,  1.3237e-01,\n",
       "          -1.4107e-01, -1.5931e-01, -1.7367e-01, -1.2482e-01, -1.4980e-02,\n",
       "          -1.3110e-02,  1.1889e-01,  1.2797e-01,  3.3747e-02,  9.2636e-02,\n",
       "          -7.5506e-02, -1.6222e-01, -2.7681e-02, -1.1458e-01, -2.2091e-02,\n",
       "          -2.5814e-02, -1.6497e-01],\n",
       "         [-1.7289e-01, -1.3129e-04, -1.2938e-01,  1.4460e-02,  1.4941e-01,\n",
       "           1.0603e-01,  3.4040e-03,  4.6380e-02,  6.2450e-02, -1.5238e-01,\n",
       "           1.3883e-01, -5.2904e-02, -5.1656e-02,  4.4024e-02, -1.5572e-01,\n",
       "          -1.2591e-01, -6.6313e-02,  1.2362e-01, -1.2917e-02, -9.8691e-02,\n",
       "           1.4154e-01,  6.9582e-02,  1.5052e-01,  4.4402e-02, -7.8405e-02,\n",
       "          -1.7113e-01,  1.0682e-01,  7.4353e-02, -5.8080e-02,  1.7430e-01,\n",
       "          -1.2972e-01, -4.5727e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0402, 0.0095], requires_grad=True)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(met.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
