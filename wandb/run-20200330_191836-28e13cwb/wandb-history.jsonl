{"Episode reward": -74.29306958879737, "Episode length": 999, "Policy Loss": -0.02229991741478443, "Value Loss": 0.008325282484292984, "_runtime": 1186.3402814865112, "_timestamp": 1585595935.356955, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2732127904891968, "Value Loss": 0.07965404540300369, "_runtime": 1187.8250391483307, "_timestamp": 1585595936.8417127, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8645499348640442, "Value Loss": 0.6864460110664368, "_runtime": 1189.3786747455597, "_timestamp": 1585595938.3953483, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9715937376022339, "Value Loss": 1.0651637315750122, "_runtime": 1190.9193196296692, "_timestamp": 1585595939.9359932, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9918023943901062, "Value Loss": 1.985023856163025, "_runtime": 1192.4878749847412, "_timestamp": 1585595941.5045485, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.952134907245636, "Value Loss": 0.3934972584247589, "_runtime": 1194.054224729538, "_timestamp": 1585595943.0708983, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.02289879322052, "Value Loss": 0.8518438935279846, "_runtime": 1195.6065328121185, "_timestamp": 1585595944.6232064, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0113352537155151, "Value Loss": 6.151433944702148, "_runtime": 1197.1282320022583, "_timestamp": 1585595946.1449056, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1260216236114502, "Value Loss": 0.5627931952476501, "_runtime": 1198.6914081573486, "_timestamp": 1585595947.7080817, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3318228721618652, "Value Loss": 0.24007442593574524, "_runtime": 1200.2427577972412, "_timestamp": 1585595949.2594314, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0716402530670166, "Value Loss": 2.108018159866333, "_runtime": 1201.7670199871063, "_timestamp": 1585595950.7836936, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6559180617332458, "Value Loss": 0.01821139268577099, "_runtime": 1203.338811159134, "_timestamp": 1585595952.3554847, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3834899067878723, "Value Loss": 0.012544953264296055, "_runtime": 1204.8898148536682, "_timestamp": 1585595953.9064884, "_step": 12}
{"Episode reward": -99.8570593386906, "Episode length": 999, "Policy Loss": 0.23861612379550934, "Value Loss": 0.07818875461816788, "_runtime": 1206.440795660019, "_timestamp": 1585595955.4574692, "_step": 13}
{"Episode reward": -84.2864107945628, "Episode length": 999, "Policy Loss": -0.37539565563201904, "Value Loss": 0.1138589084148407, "_runtime": 1207.2152426242828, "_timestamp": 1585595956.2319162, "_step": 14}
{"Episode reward": 57.92444051319002, "Episode length": 481, "Policy Loss": -0.6150515675544739, "Value Loss": 21.085920333862305, "_runtime": 1207.4596750736237, "_timestamp": 1585595956.4763486, "_step": 15}
{"Episode reward": 90.75264808074215, "Episode length": 112, "Policy Loss": -0.18525704741477966, "Value Loss": 89.90504455566406, "_runtime": 1207.6842386722565, "_timestamp": 1585595956.7009122, "_step": 16}
{"Episode reward": 91.21519353793782, "Episode length": 109, "Policy Loss": 0.3465573787689209, "Value Loss": 91.74727630615234, "_runtime": 1207.9250254631042, "_timestamp": 1585595956.941699, "_step": 17}
{"Episode reward": 91.0943647851847, "Episode length": 144, "Policy Loss": 0.6108432412147522, "Value Loss": 68.88580322265625, "_runtime": 1208.2081491947174, "_timestamp": 1585595957.2248228, "_step": 18}
{"Episode reward": 87.01952222459938, "Episode length": 193, "Policy Loss": 0.6252334117889404, "Value Loss": 50.98074722290039, "_runtime": 1208.435126543045, "_timestamp": 1585595957.4518, "_step": 19}
{"Episode reward": 89.47852755714636, "Episode length": 155, "Policy Loss": 0.9794455170631409, "Value Loss": 63.09627151489258, "_runtime": 1208.7475137710571, "_timestamp": 1585595957.7641873, "_step": 20}
{"Episode reward": 84.49937910308435, "Episode length": 216, "Policy Loss": 0.9739015102386475, "Value Loss": 44.895416259765625, "_runtime": 1209.1531043052673, "_timestamp": 1585595958.1697779, "_step": 21}
{"Episode reward": 78.18551039790765, "Episode length": 278, "Policy Loss": 0.7202277183532715, "Value Loss": 36.045387268066406, "_runtime": 1209.457079410553, "_timestamp": 1585595958.473753, "_step": 22}
{"Episode reward": 84.43697632294646, "Episode length": 209, "Policy Loss": 0.4543972611427307, "Value Loss": 46.05858612060547, "_runtime": 1210.1449329853058, "_timestamp": 1585595959.1616066, "_step": 23}
{"Episode reward": 63.42216446581313, "Episode length": 478, "Policy Loss": 0.2816031277179718, "Value Loss": 20.278396606445312, "_runtime": 1210.4928939342499, "_timestamp": 1585595959.5095675, "_step": 24}
{"Episode reward": 82.42843833015826, "Episode length": 225, "Policy Loss": 0.5191430449485779, "Value Loss": 43.3835334777832, "_runtime": 1211.4179842472076, "_timestamp": 1585595960.4346578, "_step": 25}
{"Episode reward": 50.34733621679499, "Episode length": 638, "Policy Loss": 0.0376770906150341, "Value Loss": 15.464776039123535, "_runtime": 1212.212700843811, "_timestamp": 1585595961.2293744, "_step": 26}
{"Episode reward": 58.892422307371135, "Episode length": 537, "Policy Loss": 0.003149965312331915, "Value Loss": 18.26122283935547, "_runtime": 1213.3301267623901, "_timestamp": 1585595962.3468003, "_step": 27}
{"Episode reward": 47.91519649290402, "Episode length": 764, "Policy Loss": -0.08256515860557556, "Value Loss": 13.228754997253418, "_runtime": 1214.834882736206, "_timestamp": 1585595963.8515563, "_step": 28}
{"Episode reward": -70.36480672016317, "Episode length": 999, "Policy Loss": -0.2379010170698166, "Value Loss": 0.18553327023983002, "_runtime": 1216.3759574890137, "_timestamp": 1585595965.392631, "_step": 29}
{"Episode reward": -74.12123928241016, "Episode length": 999, "Policy Loss": -0.29298120737075806, "Value Loss": 0.033588580787181854, "_runtime": 1217.8896441459656, "_timestamp": 1585595966.9063177, "_step": 30}
{"Episode reward": -67.90289852620677, "Episode length": 999, "Policy Loss": -0.26063594222068787, "Value Loss": 0.1377338320016861, "_runtime": 1219.4413149356842, "_timestamp": 1585595968.4579885, "_step": 31}
{"Episode reward": -69.88777060200455, "Episode length": 999, "Policy Loss": -0.2673817276954651, "Value Loss": 0.2976360023021698, "_runtime": 1220.9796783924103, "_timestamp": 1585595969.996352, "_step": 32}
{"Episode reward": -70.09884708724026, "Episode length": 999, "Policy Loss": -0.30069205164909363, "Value Loss": 0.1700136512517929, "_runtime": 1222.5237784385681, "_timestamp": 1585595971.540452, "_step": 33}
{"Episode reward": -71.00664715655277, "Episode length": 999, "Policy Loss": -0.26158761978149414, "Value Loss": 0.20294131338596344, "_runtime": 1224.0713307857513, "_timestamp": 1585595973.0880044, "_step": 34}
{"Episode reward": -71.15968271807283, "Episode length": 999, "Policy Loss": -0.2638198733329773, "Value Loss": 0.05604350566864014, "_runtime": 1225.6270215511322, "_timestamp": 1585595974.643695, "_step": 35}
{"Episode reward": -66.95034305665112, "Episode length": 999, "Policy Loss": -0.24995948374271393, "Value Loss": 0.03957793861627579, "_runtime": 1227.186795949936, "_timestamp": 1585595976.2034695, "_step": 36}
{"Episode reward": -66.83604864778493, "Episode length": 999, "Policy Loss": -0.23801495134830475, "Value Loss": 0.04786006361246109, "_runtime": 1228.740611076355, "_timestamp": 1585595977.7572846, "_step": 37}
{"Episode reward": -63.29649119439327, "Episode length": 999, "Policy Loss": -0.21399252116680145, "Value Loss": 0.038923006504774094, "_runtime": 1230.2952620983124, "_timestamp": 1585595979.3119357, "_step": 38}
{"Episode reward": -62.31559907408591, "Episode length": 999, "Policy Loss": -0.21878303587436676, "Value Loss": 0.025358591228723526, "_runtime": 1231.8457176685333, "_timestamp": 1585595980.8623912, "_step": 39}
{"Episode reward": -59.47863027582852, "Episode length": 999, "Policy Loss": -0.19567255675792694, "Value Loss": 0.0237528458237648, "_runtime": 1233.400708436966, "_timestamp": 1585595982.417382, "_step": 40}
{"Episode reward": -62.61083913319808, "Episode length": 999, "Policy Loss": -0.1957932561635971, "Value Loss": 0.023166533559560776, "_runtime": 1234.9544370174408, "_timestamp": 1585595983.9711106, "_step": 41}
{"Episode reward": -56.118858236693036, "Episode length": 999, "Policy Loss": -0.18123501539230347, "Value Loss": 0.02083062008023262, "_runtime": 1236.5156745910645, "_timestamp": 1585595985.5323482, "_step": 42}
{"Episode reward": -58.25809369122078, "Episode length": 999, "Policy Loss": -0.18006055057048798, "Value Loss": 0.01807856187224388, "_runtime": 1238.0529136657715, "_timestamp": 1585595987.0695872, "_step": 43}
{"Episode reward": -57.470415244094916, "Episode length": 999, "Policy Loss": -0.1706039160490036, "Value Loss": 0.0174523014575243, "_runtime": 1239.6375555992126, "_timestamp": 1585595988.6542292, "_step": 44}
{"Episode reward": -55.36556093834841, "Episode length": 999, "Policy Loss": -0.1597178876399994, "Value Loss": 0.015842171385884285, "_runtime": 1241.1874914169312, "_timestamp": 1585595990.204165, "_step": 45}
{"Episode reward": -52.52266112814472, "Episode length": 999, "Policy Loss": -0.14976711571216583, "Value Loss": 0.01452326774597168, "_runtime": 1242.728408575058, "_timestamp": 1585595991.7450821, "_step": 46}
{"Episode reward": -50.835149792791206, "Episode length": 999, "Policy Loss": -0.1416424810886383, "Value Loss": 0.012960747815668583, "_runtime": 1244.2676763534546, "_timestamp": 1585595993.28435, "_step": 47}
{"Episode reward": -52.39858851535488, "Episode length": 999, "Policy Loss": -0.13814406096935272, "Value Loss": 0.012588134966790676, "_runtime": 1245.7945294380188, "_timestamp": 1585595994.811203, "_step": 48}
{"Episode reward": -52.17819303655315, "Episode length": 999, "Policy Loss": -0.1313907504081726, "Value Loss": 0.01187690906226635, "_runtime": 1247.3417670726776, "_timestamp": 1585595996.3584406, "_step": 49}
{"Episode reward": -49.65244086831064, "Episode length": 999, "Policy Loss": -0.12145064026117325, "Value Loss": 0.010642193257808685, "_runtime": 1248.8786935806274, "_timestamp": 1585595997.8953671, "_step": 50}
{"Episode reward": -49.53534492342256, "Episode length": 999, "Policy Loss": -0.12283589690923691, "Value Loss": 0.010035179555416107, "_runtime": 1250.412677526474, "_timestamp": 1585595999.429351, "_step": 51}
{"Episode reward": -48.85278965617038, "Episode length": 999, "Policy Loss": -0.11144443601369858, "Value Loss": 0.009559206664562225, "_runtime": 1251.9622991085052, "_timestamp": 1585596000.9789727, "_step": 52}
{"Episode reward": -49.019271521567525, "Episode length": 999, "Policy Loss": -0.1085149496793747, "Value Loss": 0.008927645161747932, "_runtime": 1253.500970363617, "_timestamp": 1585596002.517644, "_step": 53}
{"Episode reward": -46.18114163198709, "Episode length": 999, "Policy Loss": -0.09701491892337799, "Value Loss": 0.00788228027522564, "_runtime": 1255.0398762226105, "_timestamp": 1585596004.0565498, "_step": 54}
{"Episode reward": -46.48440130787146, "Episode length": 999, "Policy Loss": -0.09574909508228302, "Value Loss": 0.0075607444159686565, "_runtime": 1256.5673024654388, "_timestamp": 1585596005.583976, "_step": 55}
{"Episode reward": -45.92153167821313, "Episode length": 999, "Policy Loss": -0.09030088782310486, "Value Loss": 0.007095085456967354, "_runtime": 1258.0946021080017, "_timestamp": 1585596007.1112757, "_step": 56}
{"Episode reward": -44.3351270170218, "Episode length": 999, "Policy Loss": -0.08492875844240189, "Value Loss": 0.006468514911830425, "_runtime": 1259.643352508545, "_timestamp": 1585596008.660026, "_step": 57}
{"Episode reward": -45.447294000101174, "Episode length": 999, "Policy Loss": -0.0855078473687172, "Value Loss": 0.006439491640776396, "_runtime": 1261.2193574905396, "_timestamp": 1585596010.236031, "_step": 58}
{"Episode reward": -43.08656911162137, "Episode length": 999, "Policy Loss": -0.07599809020757675, "Value Loss": 0.005614470690488815, "_runtime": 1262.75404214859, "_timestamp": 1585596011.7707157, "_step": 59}
{"Episode reward": -44.32001093158328, "Episode length": 999, "Policy Loss": -0.07682561129331589, "Value Loss": 0.0053919474594295025, "_runtime": 1264.2935943603516, "_timestamp": 1585596013.310268, "_step": 60}
{"Episode reward": -44.75655031696496, "Episode length": 999, "Policy Loss": -0.07343152910470963, "Value Loss": 0.005331533495336771, "_runtime": 1265.8222708702087, "_timestamp": 1585596014.8389444, "_step": 61}
{"Episode reward": -44.40770984480756, "Episode length": 999, "Policy Loss": -0.06980618089437485, "Value Loss": 0.004925127606838942, "_runtime": 1267.3583488464355, "_timestamp": 1585596016.3750224, "_step": 62}
{"Episode reward": -42.58247833635225, "Episode length": 999, "Policy Loss": -0.06575340777635574, "Value Loss": 0.004478855524212122, "_runtime": 1268.9075047969818, "_timestamp": 1585596017.9241784, "_step": 63}
{"Episode reward": -41.225601869584374, "Episode length": 999, "Policy Loss": -0.057316575199365616, "Value Loss": 0.003993543330579996, "_runtime": 1270.4582271575928, "_timestamp": 1585596019.4749007, "_step": 64}
{"Episode reward": -43.59145829737773, "Episode length": 999, "Policy Loss": -0.05924677476286888, "Value Loss": 0.004025115631520748, "_runtime": 1271.995357990265, "_timestamp": 1585596021.0120316, "_step": 65}
{"Episode reward": -44.026784689138566, "Episode length": 999, "Policy Loss": -0.05815301463007927, "Value Loss": 0.003946904093027115, "_runtime": 1273.5325508117676, "_timestamp": 1585596022.5492244, "_step": 66}
{"Episode reward": -46.61742499745749, "Episode length": 999, "Policy Loss": -0.05990554764866829, "Value Loss": 0.004036309197545052, "_runtime": 1275.0715985298157, "_timestamp": 1585596024.088272, "_step": 67}
{"Episode reward": -41.31245616184809, "Episode length": 999, "Policy Loss": -0.050071634352207184, "Value Loss": 0.0032796827144920826, "_runtime": 1276.6104791164398, "_timestamp": 1585596025.6271527, "_step": 68}
{"Episode reward": -43.547025658273974, "Episode length": 999, "Policy Loss": -0.04908815398812294, "Value Loss": 0.0034079039469361305, "_runtime": 1278.1638247966766, "_timestamp": 1585596027.1804984, "_step": 69}
{"Episode reward": -40.19546097765744, "Episode length": 999, "Policy Loss": -0.04269860312342644, "Value Loss": 0.0029123707208782434, "_runtime": 1279.7017080783844, "_timestamp": 1585596028.7183816, "_step": 70}
{"Episode reward": -43.295699524810246, "Episode length": 999, "Policy Loss": -0.04650109261274338, "Value Loss": 0.003019795287400484, "_runtime": 1281.2423582077026, "_timestamp": 1585596030.2590318, "_step": 71}
{"Episode reward": -41.005636346034436, "Episode length": 999, "Policy Loss": -0.040460068732500076, "Value Loss": 0.002749999286606908, "_runtime": 1282.7810771465302, "_timestamp": 1585596031.7977507, "_step": 72}
{"Episode reward": -41.58536047210583, "Episode length": 999, "Policy Loss": -0.03704680874943733, "Value Loss": 0.0026413744781166315, "_runtime": 1284.366251707077, "_timestamp": 1585596033.3829253, "_step": 73}
{"Episode reward": -40.32468667061269, "Episode length": 999, "Policy Loss": -0.035888671875, "Value Loss": 0.0023745186626911163, "_runtime": 1285.9053823947906, "_timestamp": 1585596034.922056, "_step": 74}
{"Episode reward": -39.76477865515863, "Episode length": 999, "Policy Loss": -0.032077137380838394, "Value Loss": 0.0022897073067724705, "_runtime": 1287.4447858333588, "_timestamp": 1585596036.4614594, "_step": 75}
{"Episode reward": -41.245723884965976, "Episode length": 999, "Policy Loss": -0.033233705908060074, "Value Loss": 0.002261323155835271, "_runtime": 1288.9881052970886, "_timestamp": 1585596038.0047789, "_step": 76}
{"Episode reward": -39.8877243779524, "Episode length": 999, "Policy Loss": -0.029704097658395767, "Value Loss": 0.002183207543566823, "_runtime": 1290.512972831726, "_timestamp": 1585596039.5296464, "_step": 77}
{"Episode reward": -40.69172346321719, "Episode length": 999, "Policy Loss": -0.030271010473370552, "Value Loss": 0.002138047944754362, "_runtime": 1292.0619637966156, "_timestamp": 1585596041.0786374, "_step": 78}
{"Episode reward": -41.001731123310115, "Episode length": 999, "Policy Loss": -0.026967115700244904, "Value Loss": 0.0021140784956514835, "_runtime": 1293.6009078025818, "_timestamp": 1585596042.6175814, "_step": 79}
{"Episode reward": -41.087666994480294, "Episode length": 999, "Policy Loss": -0.029442401602864265, "Value Loss": 0.001978037878870964, "_runtime": 1295.1598970890045, "_timestamp": 1585596044.1765707, "_step": 80}
{"Episode reward": -40.317801606188006, "Episode length": 999, "Policy Loss": -0.02521463669836521, "Value Loss": 0.0019589716102927923, "_runtime": 1296.719598531723, "_timestamp": 1585596045.736272, "_step": 81}
{"Episode reward": -41.012342326134494, "Episode length": 999, "Policy Loss": -0.023985810577869415, "Value Loss": 0.0019161093514412642, "_runtime": 1298.2793152332306, "_timestamp": 1585596047.2959888, "_step": 82}
{"Episode reward": -40.01758748502662, "Episode length": 999, "Policy Loss": -0.020644884556531906, "Value Loss": 0.0018291397718712687, "_runtime": 1299.836138010025, "_timestamp": 1585596048.8528116, "_step": 83}
{"Episode reward": -39.7633845584826, "Episode length": 999, "Policy Loss": -0.01919255033135414, "Value Loss": 0.001682084403000772, "_runtime": 1301.3958141803741, "_timestamp": 1585596050.4124877, "_step": 84}
{"Episode reward": -42.625266811247386, "Episode length": 999, "Policy Loss": -0.023212693631649017, "Value Loss": 0.0018617603927850723, "_runtime": 1302.9546434879303, "_timestamp": 1585596051.971317, "_step": 85}
{"Episode reward": -40.26267889960069, "Episode length": 999, "Policy Loss": -0.020707182586193085, "Value Loss": 0.0017259449232369661, "_runtime": 1304.500158548355, "_timestamp": 1585596053.516832, "_step": 86}
{"Episode reward": -39.91948586217148, "Episode length": 999, "Policy Loss": -0.016219740733504295, "Value Loss": 0.0016425003996118903, "_runtime": 1306.0480856895447, "_timestamp": 1585596055.0647593, "_step": 87}
{"Episode reward": -41.46637303422825, "Episode length": 999, "Policy Loss": -0.01986788399517536, "Value Loss": 0.0017043984262272716, "_runtime": 1307.632316350937, "_timestamp": 1585596056.64899, "_step": 88}
{"Episode reward": -40.482409703869415, "Episode length": 999, "Policy Loss": -0.015533164143562317, "Value Loss": 0.0016259824624285102, "_runtime": 1309.1902890205383, "_timestamp": 1585596058.2069626, "_step": 89}
{"Episode reward": -40.52507803708697, "Episode length": 999, "Policy Loss": -0.01512558851391077, "Value Loss": 0.0015714878682047129, "_runtime": 1310.7481482028961, "_timestamp": 1585596059.7648218, "_step": 90}
{"Episode reward": -41.02596328420256, "Episode length": 999, "Policy Loss": -0.014833449386060238, "Value Loss": 0.0016057792818173766, "_runtime": 1312.2988266944885, "_timestamp": 1585596061.3155003, "_step": 91}
{"Episode reward": -42.68559161195177, "Episode length": 999, "Policy Loss": -0.014471970498561859, "Value Loss": 0.0016434420831501484, "_runtime": 1313.8443455696106, "_timestamp": 1585596062.8610191, "_step": 92}
{"Episode reward": -42.47615010430619, "Episode length": 999, "Policy Loss": -0.013034638948738575, "Value Loss": 0.0016521989600732923, "_runtime": 1315.4041726589203, "_timestamp": 1585596064.4208462, "_step": 93}
{"Episode reward": -41.11319193746121, "Episode length": 999, "Policy Loss": -0.01292626466602087, "Value Loss": 0.0015998983290046453, "_runtime": 1316.964278936386, "_timestamp": 1585596065.9809525, "_step": 94}
{"Episode reward": -39.83723571044341, "Episode length": 999, "Policy Loss": -0.009514833800494671, "Value Loss": 0.0015217650216072798, "_runtime": 1318.511487007141, "_timestamp": 1585596067.5281606, "_step": 95}
{"Episode reward": -39.03816857599114, "Episode length": 999, "Policy Loss": -0.009979096241295338, "Value Loss": 0.0014449342852458358, "_runtime": 1320.0706932544708, "_timestamp": 1585596069.0873668, "_step": 96}
{"Episode reward": -40.87640002891579, "Episode length": 999, "Policy Loss": -0.009814147837460041, "Value Loss": 0.0015262104570865631, "_runtime": 1321.6336588859558, "_timestamp": 1585596070.6503325, "_step": 97}
{"Episode reward": -41.27029741554779, "Episode length": 999, "Policy Loss": -0.009443609043955803, "Value Loss": 0.0015152881387621164, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816, 1.240153193473816]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-1.1725064516067505, -1.0808184146881104, -0.9891303777694702, -0.8974423408508301, -0.8057543039321899, -0.7140662670135498, -0.6223781704902649, -0.5306901335716248, -0.4390020966529846, -0.3473140597343445, -0.25562602281570435, -0.16393792629241943, -0.0722498893737793, 0.01943814754486084, 0.11112618446350098, 0.2028142213821411, 0.29450225830078125, 0.3861902952194214, 0.4778783321380615, 0.5695663690567017, 0.6612544059753418, 0.7529424428939819, 0.8446305990219116, 0.9363185167312622, 1.028006672859192, 1.1196945905685425, 1.2113827466964722, 1.3030706644058228, 1.3947588205337524, 1.486446738243103, 1.5781348943710327, 1.6698228120803833, 1.761510968208313, 1.8531991243362427, 1.9448870420455933, 2.0365753173828125, 2.128262996673584, 2.2199511528015137, 2.3116393089294434, 2.403327465057373, 2.4950151443481445, 2.586703300476074, 2.678391456604004, 2.7700796127319336, 2.8617677688598633, 2.9534554481506348, 3.0451436042785645, 3.136831760406494, 3.228519916534424, 3.3202080726623535, 3.411895751953125, 3.5035839080810547, 3.5952720642089844, 3.686960220336914, 3.7786478996276855, 3.8703360557556152, 3.962024211883545, 4.053712368011475, 4.145400047302246, 4.237088203430176, 4.3287763595581055, 4.420464515686035, 4.512152194976807, 4.603840351104736, 4.695528507232666]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.33027854561805725, -0.31962379813194275, -0.30896905064582825, -0.29831430315971375, -0.28765955567359924, -0.27700480818748474, -0.26635006070137024, -0.25569531321525574, -0.24504056572914124, -0.23438581824302673, -0.22373107075691223, -0.21307632327079773, -0.20242159068584442, -0.19176684319972992, -0.18111209571361542, -0.17045734822750092, -0.1598026007413864, -0.1491478532552719, -0.1384931057691574, -0.1278383582830429, -0.1171836107969284, -0.1065288633108139, -0.0958741158246994, -0.0852193683385849, -0.07456463575363159, -0.06390988826751709, -0.05325514078140259, -0.042600393295288086, -0.031945645809173584, -0.021290898323059082, -0.01063615083694458, 1.8596649169921875e-05, 0.010673344135284424, 0.021328091621398926, 0.03198283910751343, 0.04263758659362793, 0.05329233407974243, 0.06394708156585693, 0.07460182905197144, 0.08525657653808594, 0.09591132402420044, 0.10656607151031494, 0.11722081899642944, 0.12787556648254395, 0.13853031396865845, 0.14918506145477295, 0.15983980894088745, 0.17049452662467957, 0.18114927411079407, 0.19180402159690857, 0.20245876908302307, 0.21311351656913757, 0.22376826405525208, 0.23442301154136658, 0.24507775902748108, 0.2557325065135956, 0.2663872539997101, 0.2770420014858246, 0.2876967489719391, 0.2983514964580536, 0.3090062439441681, 0.3196609914302826, 0.3303157389163971, 0.3409704864025116, 0.3516252338886261]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 5.0, 1.0, 3.0, 4.0, 4.0, 10.0, 14.0, 12.0, 16.0, 37.0, 124.0, 142.0, 36.0, 21.0, 15.0, 14.0, 13.0, 6.0, 8.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3943921625614166, -0.3816691040992737, -0.36894604563713074, -0.3562229573726654, -0.34349989891052246, -0.3307768404483795, -0.3180537819862366, -0.30533069372177124, -0.2926076352596283, -0.27988457679748535, -0.2671615183353424, -0.25443845987319946, -0.24171538650989532, -0.2289923131465912, -0.21626925468444824, -0.2035461813211441, -0.19082312285900116, -0.17810006439685822, -0.16537699103355408, -0.15265393257141113, -0.1399308741092682, -0.12720778584480286, -0.11448472738265991, -0.10176166892051697, -0.08903861045837402, -0.07631555199623108, -0.06359246373176575, -0.0508694052696228, -0.03814634680747986, -0.025423288345336914, -0.012700200080871582, 2.2858381271362305e-05, 0.012745916843414307, 0.02546897530555725, 0.038192033767700195, 0.05091512203216553, 0.06363818049430847, 0.07636123895645142, 0.08908429741859436, 0.10180738568305969, 0.11453041434288025, 0.12725350260734558, 0.1399765908718109, 0.15269961953163147, 0.1654227077960968, 0.17814573645591736, 0.1908688247203827, 0.20359191298484802, 0.21631494164466858, 0.2290380299091339, 0.24176105856895447, 0.2544841468334198, 0.26720723509788513, 0.2799302637577057, 0.292653352022171, 0.30537644028663635, 0.3180994689464569, 0.33082255721092224, 0.3435455858707428, 0.35626867413520813, 0.36899176239967346, 0.381714791059494, 0.39443787932395935, 0.4071609079837799, 0.41988399624824524]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6455960273742676, -0.6265103816986084, -0.607424795627594, -0.5883391499519348, -0.5692535042762756, -0.5501679182052612, -0.531082272529602, -0.5119966268539429, -0.4929110109806061, -0.4738253951072693, -0.4547397494316101, -0.4356541335582733, -0.4165685176849365, -0.39748287200927734, -0.37839725613594055, -0.35931161046028137, -0.3402259945869446, -0.3211403787136078, -0.3020547330379486, -0.2829691171646118, -0.26388347148895264, -0.24479785561561584, -0.22571223974227905, -0.20662659406661987, -0.18754097819328308, -0.1684553623199463, -0.1493697166442871, -0.13028407096862793, -0.11119848489761353, -0.09211283922195435, -0.07302719354629517, -0.05394160747528076, -0.03485596179962158, -0.015770316123962402, 0.003315269947052002, 0.02240091562271118, 0.04148656129837036, 0.060572147369384766, 0.07965779304504395, 0.09874343872070312, 0.1178290843963623, 0.1369146704673767, 0.1560003161430359, 0.17508596181869507, 0.19417154788970947, 0.21325719356536865, 0.23234283924102783, 0.25142842531204224, 0.2705140709877014, 0.2895997166633606, 0.308685302734375, 0.3277709484100342, 0.34685659408569336, 0.36594223976135254, 0.3850278854370117, 0.40411341190338135, 0.4231990575790405, 0.4422847032546997, 0.4613703489303589, 0.48045599460601807, 0.49954164028167725, 0.5186271667480469, 0.537712812423706, 0.5567984580993652, 0.5758841037750244]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 5.0, 4.0, 2.0, 1.0, 2.0, 4.0, 6.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2235921025276184, -0.21614888310432434, -0.20870566368103027, -0.2012624442577362, -0.19381922483444214, -0.18637600541114807, -0.178932785987854, -0.17148956656455994, -0.16404634714126587, -0.1566031277179718, -0.14915990829467773, -0.14171668887138367, -0.1342734694480896, -0.12683025002479553, -0.11938703060150146, -0.1119438111782074, -0.10450059175491333, -0.09705737233161926, -0.0896141529083252, -0.08217093348503113, -0.07472771406173706, -0.067284494638443, -0.059841275215148926, -0.05239805579185486, -0.04495483636856079, -0.037511616945266724, -0.030068397521972656, -0.02262517809867859, -0.015181958675384521, -0.007738739252090454, -0.0002955198287963867, 0.007147699594497681, 0.014590919017791748, 0.022034138441085815, 0.029477357864379883, 0.03692057728767395, 0.04436379671096802, 0.051807016134262085, 0.05925023555755615, 0.06669345498085022, 0.07413667440414429, 0.08157989382743835, 0.08902311325073242, 0.09646633267402649, 0.10390955209732056, 0.11135277152061462, 0.11879599094390869, 0.12623921036720276, 0.13368242979049683, 0.1411256492137909, 0.14856886863708496, 0.15601208806037903, 0.1634553074836731, 0.17089852690696716, 0.17834174633026123, 0.1857849657535553, 0.19322818517684937, 0.20067140460014343, 0.2081146240234375, 0.21555784344673157, 0.22300106287002563, 0.2304442822933197, 0.23788750171661377, 0.24533072113990784, 0.2527739405632019]}, "_runtime": 1323.1942262649536, "_timestamp": 1585596072.2108998, "_step": 98}
{"Episode reward": -40.00147903678135, "Episode length": 999, "Policy Loss": -0.008070928044617176, "Value Loss": 0.001551206922158599, "_runtime": 1324.7478437423706, "_timestamp": 1585596073.7645173, "_step": 99}
{"Episode reward": -42.1385714875421, "Episode length": 999, "Policy Loss": -0.007541333790868521, "Value Loss": 0.0015145057113841176, "_runtime": 1326.3032848834991, "_timestamp": 1585596075.3199584, "_step": 100}
{"Episode reward": -41.51248928885653, "Episode length": 999, "Policy Loss": -0.009668047539889812, "Value Loss": 0.0014433932956308126, "_runtime": 1327.8599166870117, "_timestamp": 1585596076.8765903, "_step": 101}
{"Episode reward": -41.73129986678949, "Episode length": 999, "Policy Loss": -0.007971406914293766, "Value Loss": 0.0014738560421392322, "_runtime": 1329.4147489070892, "_timestamp": 1585596078.4314225, "_step": 102}
{"Episode reward": -39.99230310360499, "Episode length": 999, "Policy Loss": -0.0070962379686534405, "Value Loss": 0.001431989949196577, "_runtime": 1331.0076332092285, "_timestamp": 1585596080.0243068, "_step": 103}
{"Episode reward": -39.679728099636456, "Episode length": 999, "Policy Loss": -0.006765339523553848, "Value Loss": 0.0014414063189178705, "_runtime": 1332.564499616623, "_timestamp": 1585596081.5811732, "_step": 104}
{"Episode reward": -38.795308474186285, "Episode length": 999, "Policy Loss": -0.003008285304531455, "Value Loss": 0.0013773500686511397, "_runtime": 1334.1205966472626, "_timestamp": 1585596083.1372702, "_step": 105}
{"Episode reward": -40.06129269571063, "Episode length": 999, "Policy Loss": -0.004560039844363928, "Value Loss": 0.0014592076186090708, "_runtime": 1335.666659116745, "_timestamp": 1585596084.6833327, "_step": 106}
{"Episode reward": -42.99911674485208, "Episode length": 999, "Policy Loss": -0.006543015595525503, "Value Loss": 0.0015552144031971693, "_runtime": 1337.2197251319885, "_timestamp": 1585596086.2363987, "_step": 107}
{"Episode reward": -41.57497994553987, "Episode length": 999, "Policy Loss": -0.004256733693182468, "Value Loss": 0.00146588240750134, "_runtime": 1338.7752041816711, "_timestamp": 1585596087.7918777, "_step": 108}
{"Episode reward": -41.23753789597868, "Episode length": 999, "Policy Loss": -0.005064743105322123, "Value Loss": 0.0014595354441553354, "_runtime": 1340.3200974464417, "_timestamp": 1585596089.336771, "_step": 109}
{"Episode reward": -42.44933659240231, "Episode length": 999, "Policy Loss": -0.006191357970237732, "Value Loss": 0.0014289846876636147, "_runtime": 1341.8703582286835, "_timestamp": 1585596090.8870318, "_step": 110}
{"Episode reward": -42.03169297865725, "Episode length": 999, "Policy Loss": -0.005576574243605137, "Value Loss": 0.0014397760387510061, "_runtime": 1343.43359041214, "_timestamp": 1585596092.450264, "_step": 111}
{"Episode reward": -39.96872195957188, "Episode length": 999, "Policy Loss": -0.0014145197346806526, "Value Loss": 0.0014063406269997358, "_runtime": 1344.995417356491, "_timestamp": 1585596094.012091, "_step": 112}
{"Episode reward": -39.86377732255947, "Episode length": 999, "Policy Loss": -0.0024518542923033237, "Value Loss": 0.0013711415231227875, "_runtime": 1346.5559148788452, "_timestamp": 1585596095.5725884, "_step": 113}
{"Episode reward": -41.544111142682816, "Episode length": 999, "Policy Loss": -0.0015256748301908374, "Value Loss": 0.0015282346867024899, "_runtime": 1348.1222381591797, "_timestamp": 1585596097.1389117, "_step": 114}
{"Episode reward": -40.15006532911164, "Episode length": 999, "Policy Loss": -0.0008798245689831674, "Value Loss": 0.0014408108545467257, "_runtime": 1349.6857018470764, "_timestamp": 1585596098.7023754, "_step": 115}
{"Episode reward": -40.33908776792929, "Episode length": 999, "Policy Loss": -0.0008225950878113508, "Value Loss": 0.0014015824999660254, "_runtime": 1351.2511670589447, "_timestamp": 1585596100.2678406, "_step": 116}
{"Episode reward": -40.29292329675661, "Episode length": 999, "Policy Loss": -0.0002915179939009249, "Value Loss": 0.0014166345354169607, "_runtime": 1352.8129785060883, "_timestamp": 1585596101.829652, "_step": 117}
{"Episode reward": -40.846903860682744, "Episode length": 999, "Policy Loss": -0.0016161644598469138, "Value Loss": 0.0014523027930408716, "_runtime": 1354.4130885601044, "_timestamp": 1585596103.4297621, "_step": 118}
{"Episode reward": -39.10294728194246, "Episode length": 999, "Policy Loss": 0.001417167717590928, "Value Loss": 0.001397706801071763, "_runtime": 1355.9759521484375, "_timestamp": 1585596104.9926257, "_step": 119}
{"Episode reward": -39.880398567750625, "Episode length": 999, "Policy Loss": -0.0002926169545389712, "Value Loss": 0.0014158714329823852, "_runtime": 1357.5304987430573, "_timestamp": 1585596106.5471723, "_step": 120}
{"Episode reward": -39.396233444437144, "Episode length": 999, "Policy Loss": -0.0013395893620327115, "Value Loss": 0.001473254058510065, "_runtime": 1359.0943191051483, "_timestamp": 1585596108.1109927, "_step": 121}
{"Episode reward": -39.9241676295891, "Episode length": 999, "Policy Loss": -0.000374399998690933, "Value Loss": 0.0014920857502147555, "_runtime": 1360.6560616493225, "_timestamp": 1585596109.6727352, "_step": 122}
{"Episode reward": -40.107501562873594, "Episode length": 999, "Policy Loss": -0.0007489329436793923, "Value Loss": 0.0014218599535524845, "_runtime": 1362.2194950580597, "_timestamp": 1585596111.2361686, "_step": 123}
{"Episode reward": -41.57361687477946, "Episode length": 999, "Policy Loss": -0.00010950387513730675, "Value Loss": 0.001423319336026907, "_runtime": 1363.7842762470245, "_timestamp": 1585596112.8009498, "_step": 124}
{"Episode reward": -41.17579282380054, "Episode length": 999, "Policy Loss": 0.00133995630312711, "Value Loss": 0.0014446747954934835, "_runtime": 1365.3394775390625, "_timestamp": 1585596114.356151, "_step": 125}
{"Episode reward": -42.22895698599844, "Episode length": 999, "Policy Loss": -0.000184126416570507, "Value Loss": 0.0014581457944586873, "_runtime": 1366.8933019638062, "_timestamp": 1585596115.9099755, "_step": 126}
{"Episode reward": -41.45817598541636, "Episode length": 999, "Policy Loss": -0.0018004128942266107, "Value Loss": 0.0014541647396981716, "_runtime": 1368.4583666324615, "_timestamp": 1585596117.4750402, "_step": 127}
{"Episode reward": -39.19394832531429, "Episode length": 999, "Policy Loss": -0.0001947623968590051, "Value Loss": 0.001471552881412208, "_runtime": 1370.0103106498718, "_timestamp": 1585596119.0269842, "_step": 128}
{"Episode reward": -37.05167019038153, "Episode length": 999, "Policy Loss": 0.0042227162048220634, "Value Loss": 0.0013716062530875206, "_runtime": 1371.5652644634247, "_timestamp": 1585596120.581938, "_step": 129}
{"Episode reward": -39.47192023630032, "Episode length": 999, "Policy Loss": 0.0012902874732390046, "Value Loss": 0.0014284143690019846, "_runtime": 1373.1178495883942, "_timestamp": 1585596122.1345232, "_step": 130}
{"Episode reward": -39.01360589062689, "Episode length": 999, "Policy Loss": 0.0005192052340134978, "Value Loss": 0.0013879789039492607, "_runtime": 1374.6717283725739, "_timestamp": 1585596123.688402, "_step": 131}
{"Episode reward": -41.12177669912036, "Episode length": 999, "Policy Loss": -0.0027892999351024628, "Value Loss": 0.001456472440622747, "_runtime": 1376.273401260376, "_timestamp": 1585596125.2900748, "_step": 132}
{"Episode reward": -41.63099342178667, "Episode length": 999, "Policy Loss": -0.0018968571675941348, "Value Loss": 0.001461789826862514, "_runtime": 1377.8247306346893, "_timestamp": 1585596126.8414042, "_step": 133}
{"Episode reward": -40.779421982344715, "Episode length": 999, "Policy Loss": 0.0013430858962237835, "Value Loss": 0.0014448707224801183, "_runtime": 1379.3891007900238, "_timestamp": 1585596128.4057744, "_step": 134}
{"Episode reward": -40.32056149727516, "Episode length": 999, "Policy Loss": 0.0003689165459945798, "Value Loss": 0.001391081023029983, "_runtime": 1380.9526431560516, "_timestamp": 1585596129.9693167, "_step": 135}
{"Episode reward": -40.618344351110075, "Episode length": 999, "Policy Loss": 0.002807802986353636, "Value Loss": 0.0014857271453365684, "_runtime": 1382.5186350345612, "_timestamp": 1585596131.5353086, "_step": 136}
{"Episode reward": -40.19337431686501, "Episode length": 999, "Policy Loss": 0.0011009381851181388, "Value Loss": 0.0014269360108301044, "_runtime": 1384.0811800956726, "_timestamp": 1585596133.0978537, "_step": 137}
{"Episode reward": -40.124472271864676, "Episode length": 999, "Policy Loss": -0.0013836253201588988, "Value Loss": 0.0014655482955276966, "_runtime": 1385.6337714195251, "_timestamp": 1585596134.650445, "_step": 138}
{"Episode reward": -39.98208046606222, "Episode length": 999, "Policy Loss": 0.0011651496170088649, "Value Loss": 0.0014499175595119596, "_runtime": 1387.197231054306, "_timestamp": 1585596136.2139046, "_step": 139}
{"Episode reward": -40.27179651369834, "Episode length": 999, "Policy Loss": -0.0011286487570032477, "Value Loss": 0.0014149351045489311, "_runtime": 1388.7589514255524, "_timestamp": 1585596137.775625, "_step": 140}
{"Episode reward": -41.75097882253655, "Episode length": 999, "Policy Loss": -0.0009325602441094816, "Value Loss": 0.0015156087465584278, "_runtime": 1390.3198261260986, "_timestamp": 1585596139.3364997, "_step": 141}
{"Episode reward": -39.78975841907902, "Episode length": 999, "Policy Loss": 0.0016608445439487696, "Value Loss": 0.0014160090358927846, "_runtime": 1391.8813483715057, "_timestamp": 1585596140.898022, "_step": 142}
{"Episode reward": -40.78502308247508, "Episode length": 999, "Policy Loss": -0.00258453655987978, "Value Loss": 0.0014274510322138667, "_runtime": 1393.4434349536896, "_timestamp": 1585596142.4601085, "_step": 143}
{"Episode reward": -38.636250040617455, "Episode length": 999, "Policy Loss": 0.0031249718740582466, "Value Loss": 0.0014188791392371058, "_runtime": 1395.0034132003784, "_timestamp": 1585596144.0200868, "_step": 144}
{"Episode reward": -40.51694303585216, "Episode length": 999, "Policy Loss": -0.0008529513143002987, "Value Loss": 0.0014229138614609838, "_runtime": 1396.5670237541199, "_timestamp": 1585596145.5836973, "_step": 145}
{"Episode reward": -39.922783992987874, "Episode length": 999, "Policy Loss": -0.0009311254834756255, "Value Loss": 0.0013721389696002007, "_runtime": 1398.1295051574707, "_timestamp": 1585596147.1461787, "_step": 146}
{"Episode reward": -40.84648873106671, "Episode length": 999, "Policy Loss": -0.001198665937408805, "Value Loss": 0.0014600855065509677, "_runtime": 1399.7281818389893, "_timestamp": 1585596148.7448554, "_step": 147}
{"Episode reward": -41.11864248057979, "Episode length": 999, "Policy Loss": 9.294156188843772e-05, "Value Loss": 0.0014048516750335693, "_runtime": 1401.2918570041656, "_timestamp": 1585596150.3085306, "_step": 148}
{"Episode reward": -41.6060150323747, "Episode length": 999, "Policy Loss": -0.0025710707996040583, "Value Loss": 0.0014810132561251521, "_runtime": 1402.8565213680267, "_timestamp": 1585596151.873195, "_step": 149}
{"Episode reward": -41.19998483241705, "Episode length": 999, "Policy Loss": -0.000708563020452857, "Value Loss": 0.001434288453310728, "_runtime": 1404.4186391830444, "_timestamp": 1585596153.4353127, "_step": 150}
{"Episode reward": -40.64854478475909, "Episode length": 999, "Policy Loss": 0.0003648953279480338, "Value Loss": 0.0014152905205264688, "_runtime": 1405.9837605953217, "_timestamp": 1585596155.0004342, "_step": 151}
{"Episode reward": -40.25697790012651, "Episode length": 999, "Policy Loss": 0.0008677075966261327, "Value Loss": 0.0014583338052034378, "_runtime": 1407.5482749938965, "_timestamp": 1585596156.5649486, "_step": 152}
{"Episode reward": -39.77010018964996, "Episode length": 999, "Policy Loss": 0.0008799470961093903, "Value Loss": 0.0014977904502302408, "_runtime": 1409.0878548622131, "_timestamp": 1585596158.1045284, "_step": 153}
{"Episode reward": -40.43214480796203, "Episode length": 999, "Policy Loss": 0.0005069919279776514, "Value Loss": 0.0013871707487851381, "_runtime": 1410.6425306797028, "_timestamp": 1585596159.6592042, "_step": 154}
{"Episode reward": -40.660298640094695, "Episode length": 999, "Policy Loss": -0.00040285693830810487, "Value Loss": 0.0014621581649407744, "_runtime": 1412.2050521373749, "_timestamp": 1585596161.2217257, "_step": 155}
{"Episode reward": -39.8098748722886, "Episode length": 999, "Policy Loss": 0.0013396895956248045, "Value Loss": 0.0014453078620135784, "_runtime": 1413.755142211914, "_timestamp": 1585596162.7718158, "_step": 156}
{"Episode reward": -41.31588672008173, "Episode length": 999, "Policy Loss": -0.0014819821808487177, "Value Loss": 0.0013757519191130996, "_runtime": 1415.3175733089447, "_timestamp": 1585596164.3342469, "_step": 157}
{"Episode reward": -40.41697761005874, "Episode length": 999, "Policy Loss": -0.0008340979111380875, "Value Loss": 0.0014210387598723173, "_runtime": 1416.8807516098022, "_timestamp": 1585596165.8974252, "_step": 158}
{"Episode reward": -40.89231417320783, "Episode length": 999, "Policy Loss": -0.0005139519344083965, "Value Loss": 0.0014501995174214244, "_runtime": 1418.4425728321075, "_timestamp": 1585596167.4592464, "_step": 159}
{"Episode reward": -41.15429095054851, "Episode length": 999, "Policy Loss": -0.0005832100287079811, "Value Loss": 0.0014218558790162206, "_runtime": 1420.005288362503, "_timestamp": 1585596169.021962, "_step": 160}
{"Episode reward": -39.7113397419736, "Episode length": 999, "Policy Loss": 0.0003693360777106136, "Value Loss": 0.0014427099376916885, "_runtime": 1421.5691895484924, "_timestamp": 1585596170.585863, "_step": 161}
{"Episode reward": -38.44026997271204, "Episode length": 999, "Policy Loss": 0.0030221822671592236, "Value Loss": 0.00137546646874398, "_runtime": 1423.173670053482, "_timestamp": 1585596172.1903436, "_step": 162}
{"Episode reward": -41.20964354607381, "Episode length": 999, "Policy Loss": 0.0006542486953549087, "Value Loss": 0.001384988077916205, "_runtime": 1424.7356271743774, "_timestamp": 1585596173.7523007, "_step": 163}
{"Episode reward": -39.964957735154634, "Episode length": 999, "Policy Loss": 0.001103564165532589, "Value Loss": 0.0013839679304510355, "_runtime": 1426.2984735965729, "_timestamp": 1585596175.3151472, "_step": 164}
{"Episode reward": -40.409843373943154, "Episode length": 999, "Policy Loss": -0.0012490397784858942, "Value Loss": 0.0014520088443532586, "_runtime": 1427.8502204418182, "_timestamp": 1585596176.866894, "_step": 165}
{"Episode reward": -40.739292012058435, "Episode length": 999, "Policy Loss": 6.716370262438431e-05, "Value Loss": 0.0014441473176702857, "_runtime": 1429.403832435608, "_timestamp": 1585596178.420506, "_step": 166}
{"Episode reward": -39.52300311674195, "Episode length": 999, "Policy Loss": -0.00017133030632976443, "Value Loss": 0.0014410718576982617, "_runtime": 1430.9573833942413, "_timestamp": 1585596179.974057, "_step": 167}
{"Episode reward": -39.729672056728496, "Episode length": 999, "Policy Loss": -0.000690121145453304, "Value Loss": 0.0013601463288068771, "_runtime": 1432.5070247650146, "_timestamp": 1585596181.5236983, "_step": 168}
{"Episode reward": -40.7566384927084, "Episode length": 999, "Policy Loss": -0.0027084723114967346, "Value Loss": 0.0014378041960299015, "_runtime": 1434.0702135562897, "_timestamp": 1585596183.0868871, "_step": 169}
{"Episode reward": -40.12837486519449, "Episode length": 999, "Policy Loss": -0.0004292985540814698, "Value Loss": 0.0014947218587622046, "_runtime": 1435.634753704071, "_timestamp": 1585596184.6514273, "_step": 170}
{"Episode reward": -40.82821930829891, "Episode length": 999, "Policy Loss": -0.0007054192828945816, "Value Loss": 0.0014714612625539303, "_runtime": 1437.1964650154114, "_timestamp": 1585596186.2131386, "_step": 171}
{"Episode reward": -39.22123751934903, "Episode length": 999, "Policy Loss": 0.0009979981696233153, "Value Loss": 0.0013974534813314676, "_runtime": 1438.7588624954224, "_timestamp": 1585596187.775536, "_step": 172}
{"Episode reward": -38.92851602107115, "Episode length": 999, "Policy Loss": 0.0020589984487742186, "Value Loss": 0.0013806275092065334, "_runtime": 1440.3217816352844, "_timestamp": 1585596189.3384552, "_step": 173}
{"Episode reward": -40.75178634875853, "Episode length": 999, "Policy Loss": 0.0003706782008521259, "Value Loss": 0.0014534296933561563, "_runtime": 1441.874868631363, "_timestamp": 1585596190.8915422, "_step": 174}
{"Episode reward": -38.54847544461065, "Episode length": 999, "Policy Loss": 0.0026076415088027716, "Value Loss": 0.0013795532286167145, "_runtime": 1443.4295608997345, "_timestamp": 1585596192.4462345, "_step": 175}
{"Episode reward": -39.879694978515005, "Episode length": 999, "Policy Loss": -0.0015020573046058416, "Value Loss": 0.001377353211864829, "_runtime": 1444.9810845851898, "_timestamp": 1585596193.9977582, "_step": 176}
{"Episode reward": -38.39252421222321, "Episode length": 999, "Policy Loss": 0.0029595966916531324, "Value Loss": 0.001376015949063003, "_runtime": 1446.5717043876648, "_timestamp": 1585596195.588378, "_step": 177}
{"Episode reward": -40.51848473926178, "Episode length": 999, "Policy Loss": -0.0013903192011639476, "Value Loss": 0.0014667161740362644, "_runtime": 1448.126140832901, "_timestamp": 1585596197.1428144, "_step": 178}
{"Episode reward": -40.9996113794899, "Episode length": 999, "Policy Loss": -0.0013353730319067836, "Value Loss": 0.0014670545933768153, "_runtime": 1449.6798360347748, "_timestamp": 1585596198.6965096, "_step": 179}
{"Episode reward": -40.58936212877922, "Episode length": 999, "Policy Loss": -0.0018263478996232152, "Value Loss": 0.0014171591028571129, "_runtime": 1451.2415928840637, "_timestamp": 1585596200.2582664, "_step": 180}
{"Episode reward": -40.30442204001822, "Episode length": 999, "Policy Loss": 0.0014878230867907405, "Value Loss": 0.0014499304816126823, "_runtime": 1452.806039094925, "_timestamp": 1585596201.8227127, "_step": 181}
{"Episode reward": -41.06586171531241, "Episode length": 999, "Policy Loss": -0.0023714699782431126, "Value Loss": 0.0014723147032782435, "_runtime": 1454.3696455955505, "_timestamp": 1585596203.3863192, "_step": 182}
{"Episode reward": -40.348055786875264, "Episode length": 999, "Policy Loss": 0.0006253728060983121, "Value Loss": 0.0014390751020982862, "_runtime": 1455.9355883598328, "_timestamp": 1585596204.952262, "_step": 183}
{"Episode reward": -39.64894798360803, "Episode length": 999, "Policy Loss": 2.3293739559449023e-06, "Value Loss": 0.0013525745598599315, "_runtime": 1457.4972219467163, "_timestamp": 1585596206.5138955, "_step": 184}
{"Episode reward": -39.48016331940696, "Episode length": 999, "Policy Loss": 7.6869830081705e-05, "Value Loss": 0.0014054938219487667, "_runtime": 1459.0469970703125, "_timestamp": 1585596208.0636706, "_step": 185}
{"Episode reward": -38.391012080639435, "Episode length": 999, "Policy Loss": 0.004388461355119944, "Value Loss": 0.0014137264806777239, "_runtime": 1460.6074435710907, "_timestamp": 1585596209.6241171, "_step": 186}
{"Episode reward": -40.91525759314698, "Episode length": 999, "Policy Loss": -0.0007219212129712105, "Value Loss": 0.0014158610720187426, "_runtime": 1462.169192314148, "_timestamp": 1585596211.1858659, "_step": 187}
{"Episode reward": -41.944903149920314, "Episode length": 999, "Policy Loss": -0.004439040087163448, "Value Loss": 0.0014337076572701335, "_runtime": 1463.7356770038605, "_timestamp": 1585596212.7523506, "_step": 188}
{"Episode reward": -39.04351547002107, "Episode length": 999, "Policy Loss": 2.557993502705358e-05, "Value Loss": 0.0014082537963986397, "_runtime": 1465.2963070869446, "_timestamp": 1585596214.3129807, "_step": 189}
{"Episode reward": -39.846883639297644, "Episode length": 999, "Policy Loss": -0.0012444456806406379, "Value Loss": 0.001404609763994813, "_runtime": 1466.8586843013763, "_timestamp": 1585596215.8753579, "_step": 190}
{"Episode reward": -40.592814827291086, "Episode length": 999, "Policy Loss": 9.418701665708795e-05, "Value Loss": 0.001399568049237132, "_runtime": 1468.4572157859802, "_timestamp": 1585596217.4738894, "_step": 191}
{"Episode reward": -41.76201383628617, "Episode length": 999, "Policy Loss": -0.002374210860580206, "Value Loss": 0.0014781359350308776, "_runtime": 1470.0169143676758, "_timestamp": 1585596219.033588, "_step": 192}
{"Episode reward": -39.28876774110136, "Episode length": 999, "Policy Loss": 0.0017700714524835348, "Value Loss": 0.0013785279588773847, "_runtime": 1471.5682275295258, "_timestamp": 1585596220.584901, "_step": 193}
{"Episode reward": -38.072798829912074, "Episode length": 999, "Policy Loss": 0.0026179573033005, "Value Loss": 0.0013181164395064116, "_runtime": 1473.1302599906921, "_timestamp": 1585596222.1469336, "_step": 194}
{"Episode reward": -39.11644114872454, "Episode length": 999, "Policy Loss": 0.0004163351550232619, "Value Loss": 0.0014028220903128386, "_runtime": 1474.6924495697021, "_timestamp": 1585596223.7091231, "_step": 195}
{"Episode reward": -40.87273288756837, "Episode length": 999, "Policy Loss": -0.0005258660530671477, "Value Loss": 0.0014257748844102025, "_runtime": 1476.253811597824, "_timestamp": 1585596225.2704852, "_step": 196}
{"Episode reward": -41.671525644771506, "Episode length": 999, "Policy Loss": -0.0018863605801016092, "Value Loss": 0.00147802394349128, "_runtime": 1477.816424369812, "_timestamp": 1585596226.833098, "_step": 197}
{"Episode reward": -40.013662469409745, "Episode length": 999, "Policy Loss": 0.0002810277510434389, "Value Loss": 0.0014427963178604841, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787, 0.42976436018943787]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.42310231924057007, -0.40096011757850647, -0.37881791591644287, -0.3566757142543793, -0.3345335125923157, -0.3123913109302521, -0.2902491092681885, -0.2681069076061249, -0.24596470594406128, -0.22382250428199768, -0.20168030261993408, -0.17953810095787048, -0.15739589929580688, -0.1352536976337433, -0.11311149597167969, -0.09096929430961609, -0.06882709264755249, -0.04668489098548889, -0.024542689323425293, -0.0024004876613616943, 0.019741714000701904, 0.0418839156627655, 0.0640261173248291, 0.08616834878921509, 0.1083105206489563, 0.1304526925086975, 0.1525949239730835, 0.17473715543746948, 0.1968793272972107, 0.2190214991569519, 0.2411637306213379, 0.2633059620857239, 0.2854481339454651, 0.3075903058052063, 0.3297325372695923, 0.35187476873397827, 0.3740169405937195, 0.3961591124534607, 0.4183013439178467, 0.44044357538223267, 0.4625857472419739, 0.4847279191017151, 0.5068701505661011, 0.5290123820304871, 0.5511545538902283, 0.5732967257499695, 0.5954390168190002, 0.6175811886787415, 0.6397233605384827, 0.6618655323982239, 0.6840077042579651, 0.7061499953269958, 0.7282921671867371, 0.7504343390464783, 0.772576630115509, 0.7947188019752502, 0.8168609738349915, 0.8390031456947327, 0.8611453175544739, 0.8832876086235046, 0.9054297804832458, 0.9275719523429871, 0.9497142434120178, 0.971856415271759, 0.9939985871315002]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11763021349906921, -0.11382842808961868, -0.11002664268016815, -0.10622485727071762, -0.10242307186126709, -0.09862128645181656, -0.09481950104236603, -0.0910177081823349, -0.08721593022346497, -0.08341413736343384, -0.0796123594045639, -0.07581056654453278, -0.07200878113508224, -0.06820699572563171, -0.06440521031618118, -0.06060342490673065, -0.05680163949728012, -0.05299985408782959, -0.04919806867837906, -0.04539628326892853, -0.041594497859478, -0.037792712450027466, -0.033990927040576935, -0.030189141631126404, -0.026387348771095276, -0.022585563361644745, -0.018783777952194214, -0.014981992542743683, -0.011180207133293152, -0.007378421723842621, -0.00357663631439209, 0.00022514909505844116, 0.004026934504508972, 0.0078287273645401, 0.011630505323410034, 0.015432298183441162, 0.019234076142311096, 0.023035869002342224, 0.026837646961212158, 0.030639439821243286, 0.03444121778011322, 0.03824301064014435, 0.04204478859901428, 0.04584658145904541, 0.049648359417915344, 0.05345015227794647, 0.057251930236816406, 0.061053723096847534, 0.06485551595687866, 0.0686572939157486, 0.07245908677577972, 0.07626086473464966, 0.08006265759468079, 0.08386443555355072, 0.08766622841358185, 0.09146800637245178, 0.09526979923248291, 0.09907157719135284, 0.10287337005138397, 0.1066751480102539, 0.11047694087028503, 0.11427871882915497, 0.1180805116891861, 0.12188228964805603, 0.12568408250808716]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 4.0, 4.0, 6.0, 3.0, 6.0, 5.0, 11.0, 16.0, 30.0, 169.0, 143.0, 26.0, 23.0, 8.0, 7.0, 6.0, 8.0, 4.0, 3.0, 6.0, 2.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1407678723335266, -0.13621893525123596, -0.1316700130701065, -0.12712109088897705, -0.1225721538066864, -0.11802322417497635, -0.1134742945432663, -0.10892536491155624, -0.10437643527984619, -0.09982750564813614, -0.09527857601642609, -0.09072964638471603, -0.08618071675300598, -0.08163178712129593, -0.07708285748958588, -0.07253392785787582, -0.06798499822616577, -0.06343606859445572, -0.058887138962745667, -0.054338209331035614, -0.04978927969932556, -0.04524035006761551, -0.04069142043590546, -0.036142490804195404, -0.03159356117248535, -0.0270446315407753, -0.022495701909065247, -0.017946772277355194, -0.013397842645645142, -0.008848905563354492, -0.004299983382225037, 0.00024893879890441895, 0.004797875881195068, 0.009346812963485718, 0.013895735144615173, 0.01844465732574463, 0.02299359440803528, 0.027542531490325928, 0.03209145367145538, 0.03664037585258484, 0.04118931293487549, 0.04573825001716614, 0.05028717219829559, 0.05483609437942505, 0.0593850314617157, 0.06393396854400635, 0.0684828907251358, 0.07303181290626526, 0.07758074998855591, 0.08212968707084656, 0.08667860925197601, 0.09122753143310547, 0.09577646851539612, 0.10032540559768677, 0.10487432777881622, 0.10942324995994568, 0.11397218704223633, 0.11852112412452698, 0.12307006120681763, 0.1276189684867859, 0.13216790556907654, 0.1367168426513672, 0.14126574993133545, 0.1458146870136261, 0.15036362409591675]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16651614010334015, -0.16133366525173187, -0.1561512053012848, -0.1509687304496765, -0.14578625559806824, -0.14060378074645996, -0.13542130589485168, -0.1302388459444046, -0.12505637109279633, -0.11987389624118805, -0.11469142884016037, -0.10950896143913269, -0.10432648658752441, -0.09914401173591614, -0.09396154433488846, -0.08877907693386078, -0.0835966020822525, -0.07841412723064423, -0.07323165982961655, -0.06804919242858887, -0.06286671757698059, -0.057684242725372314, -0.052501775324344635, -0.047319307923316956, -0.04213683307170868, -0.0369543582201004, -0.031771883368492126, -0.026589423418045044, -0.021406948566436768, -0.01622447371482849, -0.011042013764381409, -0.005859538912773132, -0.000677064061164856, 0.00450541079044342, 0.009687885642051697, 0.01487034559249878, 0.020052820444107056, 0.025235295295715332, 0.030417755246162415, 0.03560023009777069, 0.04078270494937897, 0.045965179800987244, 0.05114765465259552, 0.0563301146030426, 0.06151258945465088, 0.06669506430625916, 0.07187752425670624, 0.07705999910831451, 0.08224247395992279, 0.08742494881153107, 0.09260742366313934, 0.09778989851474762, 0.1029723733663559, 0.10815481841564178, 0.11333729326725006, 0.11851976811885834, 0.12370224297046661, 0.1288847178220749, 0.13406719267368317, 0.13924966752529144, 0.14443211257457733, 0.1496145874261856, 0.15479706227779388, 0.15997953712940216, 0.16516201198101044]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 5.0, 5.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09243983030319214, -0.08950432389974594, -0.08656882494688034, -0.08363331854343414, -0.08069781959056854, -0.07776231318712234, -0.07482680678367615, -0.07189130783081055, -0.06895580887794495, -0.06602030247449875, -0.06308479607105255, -0.06014929711818695, -0.05721379071474075, -0.054278288036584854, -0.051342785358428955, -0.048407282680273056, -0.04547178000211716, -0.04253627732396126, -0.03960077464580536, -0.03666527196764946, -0.03372976928949356, -0.030794262886047363, -0.027858763933181763, -0.024923257529735565, -0.021987751126289368, -0.019052252173423767, -0.01611674576997757, -0.013181246817111969, -0.010245740413665771, -0.007310241460800171, -0.004374735057353973, -0.0014392361044883728, 0.0014962702989578247, 0.004431776702404022, 0.007367275655269623, 0.01030278205871582, 0.013238281011581421, 0.01617378741502762, 0.01910928636789322, 0.022044792771339417, 0.024980291724205017, 0.027915798127651215, 0.030851304531097412, 0.03378680348396301, 0.03672230243682861, 0.03965781629085541, 0.04259331524372101, 0.04552881419658661, 0.0484643280506134, 0.051399827003479004, 0.054335325956344604, 0.057270824909210205, 0.060206338763237, 0.0631418377161026, 0.0660773366689682, 0.0690128356218338, 0.0719483494758606, 0.0748838484287262, 0.0778193473815918, 0.08075486123561859, 0.08369036018848419, 0.08662585914134979, 0.0895613580942154, 0.09249687194824219, 0.09543237090110779]}, "_runtime": 1479.378180027008, "_timestamp": 1585596228.3948536, "_step": 198}
{"Episode reward": -39.59881050203086, "Episode length": 999, "Policy Loss": -0.0008381810621358454, "Value Loss": 0.0013872446725144982, "_runtime": 1480.9402735233307, "_timestamp": 1585596229.956947, "_step": 199}
{"Episode reward": -39.081838788597274, "Episode length": 999, "Policy Loss": 0.0005901755066588521, "Value Loss": 0.0014764349907636642, "_runtime": 1482.5033249855042, "_timestamp": 1585596231.5199986, "_step": 200}
{"Episode reward": -39.540031766694035, "Episode length": 999, "Policy Loss": 0.0012720684753730893, "Value Loss": 0.0013767858035862446, "_runtime": 1484.0566048622131, "_timestamp": 1585596233.0732784, "_step": 201}
{"Episode reward": -40.24505870361211, "Episode length": 999, "Policy Loss": 0.0009158480679616332, "Value Loss": 0.001426231348887086, "_runtime": 1485.612536430359, "_timestamp": 1585596234.62921, "_step": 202}
{"Episode reward": -40.84356262218282, "Episode length": 999, "Policy Loss": -0.0010429781395941973, "Value Loss": 0.0014050479512661695, "_runtime": 1487.166600227356, "_timestamp": 1585596236.1832738, "_step": 203}
{"Episode reward": -40.99228831840952, "Episode length": 999, "Policy Loss": -0.001738223829306662, "Value Loss": 0.0014356307219713926, "_runtime": 1488.720556974411, "_timestamp": 1585596237.7372305, "_step": 204}
{"Episode reward": -41.32915806046786, "Episode length": 999, "Policy Loss": -0.002891185460612178, "Value Loss": 0.0015029439236968756, "_runtime": 1490.2633430957794, "_timestamp": 1585596239.2800167, "_step": 205}
{"Episode reward": -40.62849834066629, "Episode length": 999, "Policy Loss": -0.002022509230300784, "Value Loss": 0.001447159331291914, "_runtime": 1491.8519172668457, "_timestamp": 1585596240.8685908, "_step": 206}
{"Episode reward": -38.425403384612714, "Episode length": 999, "Policy Loss": 0.002443027449771762, "Value Loss": 0.0013452996499836445, "_runtime": 1493.4121413230896, "_timestamp": 1585596242.428815, "_step": 207}
{"Episode reward": -42.81357437968104, "Episode length": 999, "Policy Loss": -0.0016393640544265509, "Value Loss": 0.0015243665548041463, "_runtime": 1494.9726212024689, "_timestamp": 1585596243.9892948, "_step": 208}
{"Episode reward": -38.95815902349272, "Episode length": 999, "Policy Loss": 0.002263725968077779, "Value Loss": 0.0013613406335934997, "_runtime": 1496.5316858291626, "_timestamp": 1585596245.5483594, "_step": 209}
{"Episode reward": -39.54906543317228, "Episode length": 999, "Policy Loss": -0.00037853315006941557, "Value Loss": 0.0013960727956146002, "_runtime": 1498.0927743911743, "_timestamp": 1585596247.109448, "_step": 210}
{"Episode reward": -37.12281668827227, "Episode length": 999, "Policy Loss": 0.002684950130060315, "Value Loss": 0.001353534054942429, "_runtime": 1499.6461291313171, "_timestamp": 1585596248.6628027, "_step": 211}
{"Episode reward": -40.155961620342495, "Episode length": 999, "Policy Loss": -0.002523146104067564, "Value Loss": 0.0014230096712708473, "_runtime": 1501.2208993434906, "_timestamp": 1585596250.237573, "_step": 212}
{"Episode reward": -39.930113570694104, "Episode length": 999, "Policy Loss": -0.0004465941747184843, "Value Loss": 0.0013946740655228496, "_runtime": 1502.775796175003, "_timestamp": 1585596251.7924697, "_step": 213}
{"Episode reward": -41.203188422883294, "Episode length": 999, "Policy Loss": 8.490272011840716e-05, "Value Loss": 0.001404391834512353, "_runtime": 1504.3350491523743, "_timestamp": 1585596253.3517227, "_step": 214}
{"Episode reward": -40.359134563223364, "Episode length": 999, "Policy Loss": -0.0009712955798022449, "Value Loss": 0.0014144501183182001, "_runtime": 1505.8859868049622, "_timestamp": 1585596254.9026604, "_step": 215}
{"Episode reward": -41.40523371894815, "Episode length": 999, "Policy Loss": -0.0017954489449039102, "Value Loss": 0.0014803021913394332, "_runtime": 1507.4495582580566, "_timestamp": 1585596256.4662318, "_step": 216}
{"Episode reward": -38.77729191866325, "Episode length": 999, "Policy Loss": 0.0023483000695705414, "Value Loss": 0.001411265111528337, "_runtime": 1509.0096385478973, "_timestamp": 1585596258.026312, "_step": 217}
{"Episode reward": -41.70095077784612, "Episode length": 999, "Policy Loss": -0.0024962930474430323, "Value Loss": 0.0014703072374686599, "_runtime": 1510.5771489143372, "_timestamp": 1585596259.5938225, "_step": 218}
{"Episode reward": -39.34759906496794, "Episode length": 999, "Policy Loss": 0.002532843966037035, "Value Loss": 0.0013981818920001388, "_runtime": 1512.137621641159, "_timestamp": 1585596261.1542952, "_step": 219}
{"Episode reward": -40.98553270726438, "Episode length": 999, "Policy Loss": -0.0003206850669812411, "Value Loss": 0.001446670270524919, "_runtime": 1513.698059797287, "_timestamp": 1585596262.7147334, "_step": 220}
{"Episode reward": -41.39179553516684, "Episode length": 999, "Policy Loss": -0.0026091388426721096, "Value Loss": 0.0014308526879176497, "_runtime": 1515.2963988780975, "_timestamp": 1585596264.3130724, "_step": 221}
{"Episode reward": -42.89068992647517, "Episode length": 999, "Policy Loss": -0.005113646388053894, "Value Loss": 0.0014591183280572295, "_runtime": 1516.8581247329712, "_timestamp": 1585596265.8747983, "_step": 222}
{"Episode reward": -39.12530898676783, "Episode length": 999, "Policy Loss": 0.0010167887667194009, "Value Loss": 0.0013873591087758541, "_runtime": 1518.4203684329987, "_timestamp": 1585596267.437042, "_step": 223}
{"Episode reward": -42.59303625093967, "Episode length": 999, "Policy Loss": -0.004747920669615269, "Value Loss": 0.001479203812777996, "_runtime": 1519.9703056812286, "_timestamp": 1585596268.9869792, "_step": 224}
{"Episode reward": -39.968348666719685, "Episode length": 999, "Policy Loss": 0.0003441322478465736, "Value Loss": 0.0013998501235619187, "_runtime": 1521.5317900180817, "_timestamp": 1585596270.5484636, "_step": 225}
{"Episode reward": -40.752609651999514, "Episode length": 999, "Policy Loss": -0.001555250957608223, "Value Loss": 0.0014496707590296865, "_runtime": 1523.0950577259064, "_timestamp": 1585596272.1117313, "_step": 226}
{"Episode reward": -40.27536513242008, "Episode length": 999, "Policy Loss": 0.0013308749767020345, "Value Loss": 0.0013428316451609135, "_runtime": 1524.6578590869904, "_timestamp": 1585596273.6745327, "_step": 227}
{"Episode reward": -40.35249829230799, "Episode length": 999, "Policy Loss": -0.0001598329545231536, "Value Loss": 0.0014070847537368536, "_runtime": 1526.2068769931793, "_timestamp": 1585596275.2235506, "_step": 228}
{"Episode reward": -41.08144550898346, "Episode length": 999, "Policy Loss": -0.0022437837906181812, "Value Loss": 0.001416448620148003, "_runtime": 1527.7704226970673, "_timestamp": 1585596276.7870963, "_step": 229}
{"Episode reward": -40.68381170419644, "Episode length": 999, "Policy Loss": -0.0009433978702872992, "Value Loss": 0.0014245386701077223, "_runtime": 1529.3353006839752, "_timestamp": 1585596278.3519742, "_step": 230}
{"Episode reward": -38.57205107248516, "Episode length": 999, "Policy Loss": 0.00236554560251534, "Value Loss": 0.0013893633149564266, "_runtime": 1530.9004456996918, "_timestamp": 1585596279.9171193, "_step": 231}
{"Episode reward": -40.33270078864885, "Episode length": 999, "Policy Loss": 0.00020522656268440187, "Value Loss": 0.0014120812993496656, "_runtime": 1532.4651319980621, "_timestamp": 1585596281.4818056, "_step": 232}
{"Episode reward": -39.862844534013405, "Episode length": 999, "Policy Loss": 6.7472055889084e-06, "Value Loss": 0.0013879312900826335, "_runtime": 1534.02561378479, "_timestamp": 1585596283.0422873, "_step": 233}
{"Episode reward": -37.97928143571354, "Episode length": 999, "Policy Loss": 0.001293647801503539, "Value Loss": 0.0013748195488005877, "_runtime": 1535.5890681743622, "_timestamp": 1585596284.6057417, "_step": 234}
{"Episode reward": -38.20968878023192, "Episode length": 999, "Policy Loss": 0.002796426648274064, "Value Loss": 0.0013886974193155766, "_runtime": 1537.1513929367065, "_timestamp": 1585596286.1680665, "_step": 235}
{"Episode reward": -40.58308418542666, "Episode length": 999, "Policy Loss": -0.0024749203585088253, "Value Loss": 0.0014244846533983946, "_runtime": 1538.738740682602, "_timestamp": 1585596287.7554142, "_step": 236}
{"Episode reward": -38.76784829362992, "Episode length": 999, "Policy Loss": 0.002673861337825656, "Value Loss": 0.0013920000055804849, "_runtime": 1540.2982392311096, "_timestamp": 1585596289.3149128, "_step": 237}
{"Episode reward": -39.243709970192064, "Episode length": 999, "Policy Loss": 0.0018600376788526773, "Value Loss": 0.0013666421873494983, "_runtime": 1541.8489291667938, "_timestamp": 1585596290.8656027, "_step": 238}
{"Episode reward": -41.02082941065046, "Episode length": 999, "Policy Loss": -0.0007888064137659967, "Value Loss": 0.0014298511669039726, "_runtime": 1543.4098658561707, "_timestamp": 1585596292.4265394, "_step": 239}
{"Episode reward": -41.00283855223542, "Episode length": 999, "Policy Loss": -0.0026831815484911203, "Value Loss": 0.0014289288083091378, "_runtime": 1544.9693274497986, "_timestamp": 1585596293.986001, "_step": 240}
{"Episode reward": -41.2040548731907, "Episode length": 999, "Policy Loss": -0.0024593896232545376, "Value Loss": 0.001413723104633391, "_runtime": 1546.5295071601868, "_timestamp": 1585596295.5461807, "_step": 241}
{"Episode reward": -39.05897394739644, "Episode length": 999, "Policy Loss": 0.0011943225981667638, "Value Loss": 0.001449213013984263, "_runtime": 1548.0907883644104, "_timestamp": 1585596297.107462, "_step": 242}
{"Episode reward": -41.801706896863394, "Episode length": 999, "Policy Loss": -0.00038144149584695697, "Value Loss": 0.001437842263840139, "_runtime": 1549.6406650543213, "_timestamp": 1585596298.6573386, "_step": 243}
{"Episode reward": -38.44768490061911, "Episode length": 999, "Policy Loss": 0.0018868076149374247, "Value Loss": 0.001347851357422769, "_runtime": 1551.1941277980804, "_timestamp": 1585596300.2108014, "_step": 244}
{"Episode reward": -38.89288390387947, "Episode length": 999, "Policy Loss": 0.0012003061128780246, "Value Loss": 0.0013258643448352814, "_runtime": 1552.7476739883423, "_timestamp": 1585596301.7643476, "_step": 245}
{"Episode reward": -39.96338077988784, "Episode length": 999, "Policy Loss": 0.0010446964297443628, "Value Loss": 0.0013787563657388091, "_runtime": 1554.2871644496918, "_timestamp": 1585596303.303838, "_step": 246}
{"Episode reward": -37.733081706174566, "Episode length": 999, "Policy Loss": 0.0013758306158706546, "Value Loss": 0.0013774073449894786, "_runtime": 1555.8387989997864, "_timestamp": 1585596304.8554726, "_step": 247}
{"Episode reward": -38.28564770451234, "Episode length": 999, "Policy Loss": 0.0024598215240985155, "Value Loss": 0.001352481311187148, "_runtime": 1557.4010438919067, "_timestamp": 1585596306.4177175, "_step": 248}
{"Episode reward": -37.8954988879188, "Episode length": 999, "Policy Loss": 0.002254554769024253, "Value Loss": 0.001333808177150786, "_runtime": 1558.9521298408508, "_timestamp": 1585596307.9688034, "_step": 249}
{"Episode reward": -39.66498252097177, "Episode length": 999, "Policy Loss": -0.0008129933848977089, "Value Loss": 0.0014388132840394974, "_runtime": 1560.507307767868, "_timestamp": 1585596309.5239813, "_step": 250}
{"Episode reward": -39.29956904360103, "Episode length": 999, "Policy Loss": -0.000612750940490514, "Value Loss": 0.0013816318241879344, "_runtime": 1562.1083884239197, "_timestamp": 1585596311.125062, "_step": 251}
{"Episode reward": -42.36849868913525, "Episode length": 999, "Policy Loss": -0.0025184117257595062, "Value Loss": 0.001441259286366403, "_runtime": 1563.6693441867828, "_timestamp": 1585596312.6860178, "_step": 252}
{"Episode reward": -40.376740354906204, "Episode length": 999, "Policy Loss": -0.0007514971075579524, "Value Loss": 0.0014328714460134506, "_runtime": 1565.2301564216614, "_timestamp": 1585596314.24683, "_step": 253}
{"Episode reward": -40.22872846114698, "Episode length": 999, "Policy Loss": -0.0017544300062581897, "Value Loss": 0.0014414904871955514, "_runtime": 1566.7925007343292, "_timestamp": 1585596315.8091743, "_step": 254}
{"Episode reward": -39.17341058555079, "Episode length": 999, "Policy Loss": -8.998261182568967e-05, "Value Loss": 0.0014054797356948256, "_runtime": 1568.3542680740356, "_timestamp": 1585596317.3709416, "_step": 255}
{"Episode reward": -38.44975340161448, "Episode length": 999, "Policy Loss": 0.003130320692434907, "Value Loss": 0.001416269689798355, "_runtime": 1569.8932509422302, "_timestamp": 1585596318.9099245, "_step": 256}
{"Episode reward": -38.717225007473196, "Episode length": 999, "Policy Loss": 0.0009746928699314594, "Value Loss": 0.0013898342149332166, "_runtime": 1571.44522356987, "_timestamp": 1585596320.4618971, "_step": 257}
{"Episode reward": -39.79002205583949, "Episode length": 999, "Policy Loss": 0.0006025796756148338, "Value Loss": 0.001393745420500636, "_runtime": 1573.006907939911, "_timestamp": 1585596322.0235815, "_step": 258}
{"Episode reward": -39.67952694321576, "Episode length": 999, "Policy Loss": -0.001903075841255486, "Value Loss": 0.0014450263697654009, "_runtime": 1574.5592334270477, "_timestamp": 1585596323.575907, "_step": 259}
{"Episode reward": -41.10497046538182, "Episode length": 999, "Policy Loss": -0.00016982074885163456, "Value Loss": 0.0015099094016477466, "_runtime": 1576.122478723526, "_timestamp": 1585596325.1391523, "_step": 260}
{"Episode reward": -38.597165684670784, "Episode length": 999, "Policy Loss": 0.0008766831015236676, "Value Loss": 0.0013693933142349124, "_runtime": 1577.6842324733734, "_timestamp": 1585596326.700906, "_step": 261}
{"Episode reward": -39.19809411533367, "Episode length": 999, "Policy Loss": 0.0009754934580996633, "Value Loss": 0.001406489871442318, "_runtime": 1579.2460224628448, "_timestamp": 1585596328.262696, "_step": 262}
{"Episode reward": -41.426554442130794, "Episode length": 999, "Policy Loss": -0.0024697822518646717, "Value Loss": 0.0014752476708963513, "_runtime": 1580.7952330112457, "_timestamp": 1585596329.8119066, "_step": 263}
{"Episode reward": -39.479881629334656, "Episode length": 999, "Policy Loss": 0.0009600745979696512, "Value Loss": 0.0014013159088790417, "_runtime": 1582.35418343544, "_timestamp": 1585596331.370857, "_step": 264}
{"Episode reward": -39.72745756043845, "Episode length": 999, "Policy Loss": 0.0007771224481984973, "Value Loss": 0.001414991682395339, "_runtime": 1583.9514470100403, "_timestamp": 1585596332.9681206, "_step": 265}
{"Episode reward": -39.91332629110735, "Episode length": 999, "Policy Loss": 0.0008929004543460906, "Value Loss": 0.0014060396933928132, "_runtime": 1585.5138926506042, "_timestamp": 1585596334.5305662, "_step": 266}
{"Episode reward": -39.851387928402325, "Episode length": 999, "Policy Loss": 0.0006947391084395349, "Value Loss": 0.0014448267174884677, "_runtime": 1587.0651812553406, "_timestamp": 1585596336.0818548, "_step": 267}
{"Episode reward": -40.75873718036035, "Episode length": 999, "Policy Loss": -0.0013675991212949157, "Value Loss": 0.0014144285814836621, "_runtime": 1588.6252958774567, "_timestamp": 1585596337.6419694, "_step": 268}
{"Episode reward": -38.8208491758248, "Episode length": 999, "Policy Loss": 0.0017444322584196925, "Value Loss": 0.0014219802105799317, "_runtime": 1590.1772344112396, "_timestamp": 1585596339.193908, "_step": 269}
{"Episode reward": -39.652267729031564, "Episode length": 999, "Policy Loss": -0.001825124491006136, "Value Loss": 0.001403431175276637, "_runtime": 1591.7384181022644, "_timestamp": 1585596340.7550917, "_step": 270}
{"Episode reward": -39.06151884170984, "Episode length": 999, "Policy Loss": 0.0011799343628808856, "Value Loss": 0.0014188834466040134, "_runtime": 1593.2877402305603, "_timestamp": 1585596342.3044138, "_step": 271}
{"Episode reward": -38.66199486926145, "Episode length": 999, "Policy Loss": 0.002043985528871417, "Value Loss": 0.0013466133968904614, "_runtime": 1594.8484461307526, "_timestamp": 1585596343.8651197, "_step": 272}
{"Episode reward": -40.138149991892725, "Episode length": 999, "Policy Loss": 0.0010317197302356362, "Value Loss": 0.0014134494122117758, "_runtime": 1596.4003736972809, "_timestamp": 1585596345.4170473, "_step": 273}
{"Episode reward": -40.475457098750525, "Episode length": 999, "Policy Loss": -0.0015046634944155812, "Value Loss": 0.001399622648023069, "_runtime": 1597.9489476680756, "_timestamp": 1585596346.9656212, "_step": 274}
{"Episode reward": -40.43478233840473, "Episode length": 999, "Policy Loss": -0.0028663568664342165, "Value Loss": 0.0014014040352776647, "_runtime": 1599.5193483829498, "_timestamp": 1585596348.536022, "_step": 275}
{"Episode reward": -38.62204944827297, "Episode length": 999, "Policy Loss": 0.001542753423564136, "Value Loss": 0.001327939797192812, "_runtime": 1601.0756628513336, "_timestamp": 1585596350.0923364, "_step": 276}
{"Episode reward": -37.75159909947662, "Episode length": 999, "Policy Loss": 0.0009205853566527367, "Value Loss": 0.0013674229849129915, "_runtime": 1602.6269998550415, "_timestamp": 1585596351.6436734, "_step": 277}
{"Episode reward": -40.415061259979545, "Episode length": 999, "Policy Loss": -0.0012357488740235567, "Value Loss": 0.0013872957788407803, "_runtime": 1604.1640729904175, "_timestamp": 1585596353.1807466, "_step": 278}
{"Episode reward": -40.78332753473473, "Episode length": 999, "Policy Loss": -0.0010691748466342688, "Value Loss": 0.0014594863168895245, "_runtime": 1605.709265947342, "_timestamp": 1585596354.7259395, "_step": 279}
{"Episode reward": -41.376194572186776, "Episode length": 999, "Policy Loss": -0.0028555255848914385, "Value Loss": 0.0015005416935309768, "_runtime": 1607.2928814888, "_timestamp": 1585596356.309555, "_step": 280}
{"Episode reward": -37.3841238521157, "Episode length": 999, "Policy Loss": 0.0025191556196659803, "Value Loss": 0.0013520743232220411, "_runtime": 1608.855880498886, "_timestamp": 1585596357.872554, "_step": 281}
{"Episode reward": -38.758775453583205, "Episode length": 999, "Policy Loss": 0.0014887468423694372, "Value Loss": 0.001413224614225328, "_runtime": 1610.4167773723602, "_timestamp": 1585596359.433451, "_step": 282}
{"Episode reward": -39.20933311476801, "Episode length": 999, "Policy Loss": 0.0013880558544769883, "Value Loss": 0.001440291409380734, "_runtime": 1611.9783771038055, "_timestamp": 1585596360.9950507, "_step": 283}
{"Episode reward": -38.20331269860737, "Episode length": 999, "Policy Loss": 0.0024357482325285673, "Value Loss": 0.0013809904921799898, "_runtime": 1613.5375502109528, "_timestamp": 1585596362.5542238, "_step": 284}
{"Episode reward": -39.494424044396894, "Episode length": 999, "Policy Loss": -0.0006451639928855002, "Value Loss": 0.00138550263363868, "_runtime": 1615.0991580486298, "_timestamp": 1585596364.1158316, "_step": 285}
{"Episode reward": -40.248281156815516, "Episode length": 999, "Policy Loss": -6.312282494036481e-06, "Value Loss": 0.0014251557877287269, "_runtime": 1616.6585202217102, "_timestamp": 1585596365.6751938, "_step": 286}
{"Episode reward": -38.663480133280906, "Episode length": 999, "Policy Loss": 4.554968109005131e-05, "Value Loss": 0.0013728702906519175, "_runtime": 1618.2061417102814, "_timestamp": 1585596367.2228153, "_step": 287}
{"Episode reward": -40.830762463991036, "Episode length": 999, "Policy Loss": -0.0028176032938063145, "Value Loss": 0.0014418878126889467, "_runtime": 1619.7688653469086, "_timestamp": 1585596368.785539, "_step": 288}
{"Episode reward": -40.427372466019186, "Episode length": 999, "Policy Loss": -0.001263502985239029, "Value Loss": 0.0013822255423292518, "_runtime": 1621.3334693908691, "_timestamp": 1585596370.350143, "_step": 289}
{"Episode reward": -37.51269070192501, "Episode length": 999, "Policy Loss": 0.0009480688604526222, "Value Loss": 0.0013020855840295553, "_runtime": 1622.8972642421722, "_timestamp": 1585596371.9139378, "_step": 290}
{"Episode reward": -38.972187799371305, "Episode length": 999, "Policy Loss": 0.0008381187217310071, "Value Loss": 0.0014195428229868412, "_runtime": 1624.4569489955902, "_timestamp": 1585596373.4736226, "_step": 291}
{"Episode reward": -40.17547647467397, "Episode length": 999, "Policy Loss": -0.0011644839541986585, "Value Loss": 0.001433802885003388, "_runtime": 1626.0149040222168, "_timestamp": 1585596375.0315776, "_step": 292}
{"Episode reward": -39.37197265255862, "Episode length": 999, "Policy Loss": -0.0009788157185539603, "Value Loss": 0.0014433636097237468, "_runtime": 1627.577448606491, "_timestamp": 1585596376.5941222, "_step": 293}
{"Episode reward": -39.06459338232413, "Episode length": 999, "Policy Loss": 0.0025159402284771204, "Value Loss": 0.0013709423365071416, "_runtime": 1629.1428699493408, "_timestamp": 1585596378.1595435, "_step": 294}
{"Episode reward": -41.634634788353424, "Episode length": 999, "Policy Loss": -0.0030745607800781727, "Value Loss": 0.0014531423803418875, "_runtime": 1630.7429821491241, "_timestamp": 1585596379.7596557, "_step": 295}
{"Episode reward": -42.69213895390872, "Episode length": 999, "Policy Loss": -0.004882389679551125, "Value Loss": 0.0014525448204949498, "_runtime": 1632.3028461933136, "_timestamp": 1585596381.3195198, "_step": 296}
{"Episode reward": -40.76965992135371, "Episode length": 999, "Policy Loss": -0.002086109947413206, "Value Loss": 0.0014871577732264996, "_runtime": 1633.8780813217163, "_timestamp": 1585596382.894755, "_step": 297}
{"Episode reward": -37.97891906940587, "Episode length": 999, "Policy Loss": 1.7968144675251096e-05, "Value Loss": 0.0013984780525788665, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125, -3.1116485595703125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0], "bins": [-9.310100555419922, -9.118406295776367, -8.926712989807129, -8.735018730163574, -8.54332447052002, -8.351631164550781, -8.159936904907227, -7.96824312210083, -7.776549339294434, -7.584855079650879, -7.393161296844482, -7.201467514038086, -7.009773254394531, -6.818079471588135, -6.626385688781738, -6.434691429138184, -6.242997646331787, -6.051303863525391, -5.859609603881836, -5.6679158210754395, -5.476222038269043, -5.284527778625488, -5.092833995819092, -4.901140213012695, -4.709445953369141, -4.517752170562744, -4.326058387756348, -4.134364604949951, -3.9426703453063965, -3.7509765625, -3.5592827796936035, -3.367588520050049, -3.1758947372436523, -2.984200954437256, -2.792506694793701, -2.6008129119873047, -2.409119129180908, -2.2174248695373535, -2.025731086730957, -1.8340373039245605, -1.642343521118164, -1.4506492614746094, -1.2589550018310547, -1.0672616958618164, -0.8755674362182617, -0.683873176574707, -0.49217987060546875, -0.30048561096191406, -0.10879135131835938, 0.0829019546508789, 0.2745962142944336, 0.4662895202636719, 0.6579837799072266, 0.8496780395507812, 1.0413713455200195, 1.2330656051635742, 1.424759864807129, 1.6164531707763672, 1.8081474304199219, 1.9998416900634766, 2.191534996032715, 2.3832292556762695, 2.574923515319824, 2.7666168212890625, 2.958311080932617]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.8773258328437805, -0.8507159352302551, -0.824105978012085, -0.7974960803985596, -0.7708861827850342, -0.7442762851715088, -0.7176663279533386, -0.6910564303398132, -0.6644464731216431, -0.6378365755081177, -0.6112266778945923, -0.5846167802810669, -0.5580068230628967, -0.5313969254493713, -0.5047869682312012, -0.47817710041999817, -0.4515671730041504, -0.4249572455883026, -0.3983473479747772, -0.37173742055892944, -0.34512752294540405, -0.3185175657272339, -0.2919076681137085, -0.2652977705001831, -0.23868781328201294, -0.21207791566848755, -0.18546801805496216, -0.15885812044143677, -0.1322481632232666, -0.10563826560974121, -0.07902836799621582, -0.052418410778045654, -0.025808513164520264, 0.000801384449005127, 0.027411341667175293, 0.054021239280700684, 0.08063113689422607, 0.10724109411239624, 0.13385099172592163, 0.16046088933944702, 0.1870707869529724, 0.2136806845664978, 0.24029070138931274, 0.26690059900283813, 0.2935104966163635, 0.3201203942298889, 0.3467302918434143, 0.3733401894569397, 0.39995020627975464, 0.42656010389328003, 0.4531700015068054, 0.4797798991203308, 0.5063897967338562, 0.5329996943473816, 0.559609591960907, 0.5862196087837219, 0.6128295063972473, 0.6394394040107727, 0.6660493016242981, 0.6926591992378235, 0.7192690968513489, 0.7458791136741638, 0.7724890112876892, 0.7990989089012146, 0.82570880651474]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 8.0, 3.0, 3.0, 11.0, 12.0, 9.0, 28.0, 46.0, 145.0, 125.0, 36.0, 21.0, 9.0, 6.0, 7.0, 6.0, 2.0, 7.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.042683720588684, -1.011059045791626, -0.9794343709945679, -0.9478096961975098, -0.9161850214004517, -0.8845603466033936, -0.8529356122016907, -0.8213109374046326, -0.7896862626075745, -0.7580615878105164, -0.7264369130134583, -0.6948121786117554, -0.6631875038146973, -0.6315628290176392, -0.599938154220581, -0.568313479423523, -0.5366888046264648, -0.5050641298294067, -0.47343945503234863, -0.4418147802352905, -0.4101901054382324, -0.37856537103652954, -0.34694069623947144, -0.31531602144241333, -0.2836913466453552, -0.2520666718482971, -0.220441997051239, -0.1888173222541809, -0.15719258785247803, -0.12556791305541992, -0.09394323825836182, -0.06231856346130371, -0.030693888664245605, 0.0009307861328125, 0.032555460929870605, 0.06418013572692871, 0.09580481052398682, 0.12742948532104492, 0.15905416011810303, 0.19067883491516113, 0.22230350971221924, 0.2539283037185669, 0.285552978515625, 0.3171776533126831, 0.3488023281097412, 0.3804270029067993, 0.4120516777038574, 0.4436763525009155, 0.47530102729797363, 0.5069257020950317, 0.5385503768920898, 0.570175051689148, 0.601799726486206, 0.6334244012832642, 0.6650490760803223, 0.6966737508773804, 0.728298544883728, 0.7599232196807861, 0.7915478944778442, 0.8231725692749023, 0.8547972440719604, 0.8864219188690186, 0.9180465936660767, 0.9496712684631348, 0.9812959432601929]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3142712116241455, -1.2723270654678345, -1.2303829193115234, -1.188438892364502, -1.146494746208191, -1.1045506000518799, -1.0626064538955688, -1.0206623077392578, -0.9787182211875916, -0.9367741346359253, -0.8948299884796143, -0.8528858423233032, -0.8109416961669922, -0.7689976096153259, -0.7270534634590149, -0.6851093769073486, -0.6431652307510376, -0.6012210845947266, -0.5592769980430603, -0.5173328518867493, -0.475388765335083, -0.433444619178772, -0.39150047302246094, -0.3495563864707947, -0.30761218070983887, -0.2656681537628174, -0.22372400760650635, -0.1817798614501953, -0.13983571529388428, -0.09789156913757324, -0.05594754219055176, -0.014003396034240723, 0.027940750122070312, 0.06988489627838135, 0.11182904243469238, 0.15377306938171387, 0.1957172155380249, 0.23766136169433594, 0.279605507850647, 0.321549654006958, 0.3634936809539795, 0.4054378271102905, 0.44738197326660156, 0.4893261194229126, 0.5312702655792236, 0.5732144117355347, 0.6151584386825562, 0.6571025848388672, 0.6990468502044678, 0.7409908771514893, 0.7829349040985107, 0.8248791694641113, 0.8668231964111328, 0.9087674617767334, 0.9507114887237549, 0.9926555156707764, 1.034599781036377, 1.0765438079833984, 1.118488073348999, 1.1604321002960205, 1.202376127243042, 1.2443203926086426, 1.286264419555664, 1.3282086849212646, 1.3701527118682861]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 23.0, 8.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.619290292263031, -0.6003274321556091, -0.5813645720481873, -0.5624017119407654, -0.5434388518333435, -0.5244759917259216, -0.5055131316184998, -0.4865502417087555, -0.4675873816013336, -0.44862452149391174, -0.42966166138648987, -0.4106987714767456, -0.39173591136932373, -0.37277305126190186, -0.35381019115448, -0.3348473310470581, -0.31588447093963623, -0.29692161083221436, -0.2779587507247925, -0.2589958906173706, -0.24003303050994873, -0.22107014060020447, -0.2021072804927826, -0.18314442038536072, -0.16418156027793884, -0.14521870017051697, -0.1262558400630951, -0.10729295015335083, -0.08833009004592896, -0.06936722993850708, -0.050404369831085205, -0.03144150972366333, -0.012478649616241455, 0.00648421049118042, 0.025447070598602295, 0.04440993070602417, 0.06337279081344604, 0.08233565092086792, 0.1012985110282898, 0.12026137113571167, 0.13922423124313354, 0.1581871509552002, 0.17715001106262207, 0.19611287117004395, 0.21507573127746582, 0.2340385913848877, 0.25300145149230957, 0.27196431159973145, 0.2909271717071533, 0.3098900318145752, 0.32885289192199707, 0.34781575202941895, 0.3667786121368408, 0.38574153184890747, 0.40470439195632935, 0.4236672520637512, 0.4426301121711731, 0.46159297227859497, 0.48055583238601685, 0.4995186924934387, 0.5184815526008606, 0.5374444127082825, 0.5564072728157043, 0.5753701329231262, 0.5943329930305481]}, "_runtime": 1635.4376146793365, "_timestamp": 1585596384.4542882, "_step": 298}
{"Episode reward": -37.1143070936643, "Episode length": 999, "Policy Loss": 0.0023375374730676413, "Value Loss": 0.0013744017342105508, "_runtime": 1636.98574757576, "_timestamp": 1585596386.0024211, "_step": 299}
{"Episode reward": -41.30146763072119, "Episode length": 999, "Policy Loss": -0.0036714430898427963, "Value Loss": 0.0014121599961072206, "_runtime": 1638.5339741706848, "_timestamp": 1585596387.5506477, "_step": 300}
{"Episode reward": -40.25755879849506, "Episode length": 999, "Policy Loss": -0.0007018205942586064, "Value Loss": 0.0014364608796313405, "_runtime": 1640.0806860923767, "_timestamp": 1585596389.0973597, "_step": 301}
{"Episode reward": -41.27149518567351, "Episode length": 999, "Policy Loss": -0.002557872561737895, "Value Loss": 0.0014609446516260505, "_runtime": 1641.6321289539337, "_timestamp": 1585596390.6488025, "_step": 302}
{"Episode reward": -42.67795893908511, "Episode length": 999, "Policy Loss": -0.004575181752443314, "Value Loss": 0.0015162520576268435, "_runtime": 1643.1794738769531, "_timestamp": 1585596392.1961474, "_step": 303}
{"Episode reward": -39.49994041300637, "Episode length": 999, "Policy Loss": -0.0027886012103408575, "Value Loss": 0.0013760121073573828, "_runtime": 1644.7302603721619, "_timestamp": 1585596393.746934, "_step": 304}
{"Episode reward": -41.7690269897356, "Episode length": 999, "Policy Loss": -0.0024279048666357994, "Value Loss": 0.0014366310788318515, "_runtime": 1646.2900638580322, "_timestamp": 1585596395.3067374, "_step": 305}
{"Episode reward": -39.95471496652219, "Episode length": 999, "Policy Loss": -0.0011049318127334118, "Value Loss": 0.0013789287768304348, "_runtime": 1647.8416311740875, "_timestamp": 1585596396.8583047, "_step": 306}
{"Episode reward": -40.28752003353918, "Episode length": 999, "Policy Loss": -0.0009161952184513211, "Value Loss": 0.0014174191746860743, "_runtime": 1649.3938119411469, "_timestamp": 1585596398.4104855, "_step": 307}
{"Episode reward": -39.1615562597563, "Episode length": 999, "Policy Loss": 0.001182640204206109, "Value Loss": 0.0014272829284891486, "_runtime": 1650.9368274211884, "_timestamp": 1585596399.953501, "_step": 308}
{"Episode reward": -38.32819901421659, "Episode length": 999, "Policy Loss": 0.0035092835314571857, "Value Loss": 0.0014004501281306148, "_runtime": 1652.4984376430511, "_timestamp": 1585596401.5151112, "_step": 309}
{"Episode reward": -39.81089767839666, "Episode length": 999, "Policy Loss": -0.0010091335279867053, "Value Loss": 0.0014171310467645526, "_runtime": 1654.097183227539, "_timestamp": 1585596403.1138568, "_step": 310}
{"Episode reward": -40.89408519087221, "Episode length": 999, "Policy Loss": 0.00023938427329994738, "Value Loss": 0.0014323522336781025, "_runtime": 1655.659718990326, "_timestamp": 1585596404.6763926, "_step": 311}
{"Episode reward": -40.098775009239176, "Episode length": 999, "Policy Loss": -0.00013250742631498724, "Value Loss": 0.0014209561049938202, "_runtime": 1657.2203936576843, "_timestamp": 1585596406.2370672, "_step": 312}
{"Episode reward": -40.42411880147313, "Episode length": 999, "Policy Loss": 0.0001156538346549496, "Value Loss": 0.0014419473009184003, "_runtime": 1658.7807767391205, "_timestamp": 1585596407.7974503, "_step": 313}
{"Episode reward": -39.16096279564648, "Episode length": 999, "Policy Loss": 0.0006746636354364455, "Value Loss": 0.001406430616043508, "_runtime": 1660.3339767456055, "_timestamp": 1585596409.3506503, "_step": 314}
{"Episode reward": -39.19649704849156, "Episode length": 999, "Policy Loss": 0.00017648853827267885, "Value Loss": 0.0014097564853727818, "_runtime": 1661.8950295448303, "_timestamp": 1585596410.911703, "_step": 315}
{"Episode reward": -40.024527546399916, "Episode length": 999, "Policy Loss": -0.0004372152325231582, "Value Loss": 0.0014277356676757336, "_runtime": 1663.4559156894684, "_timestamp": 1585596412.4725893, "_step": 316}
{"Episode reward": -39.85619881915671, "Episode length": 999, "Policy Loss": 1.6482686987728812e-05, "Value Loss": 0.0014290102990344167, "_runtime": 1665.0151879787445, "_timestamp": 1585596414.0318615, "_step": 317}
{"Episode reward": -40.08755444373433, "Episode length": 999, "Policy Loss": 0.0002627664362080395, "Value Loss": 0.0013644736027345061, "_runtime": 1666.5752167701721, "_timestamp": 1585596415.5918903, "_step": 318}
{"Episode reward": -38.370947100517405, "Episode length": 999, "Policy Loss": 0.002311572665348649, "Value Loss": 0.0013963873498141766, "_runtime": 1668.1274242401123, "_timestamp": 1585596417.1440978, "_step": 319}
{"Episode reward": -43.35654163838434, "Episode length": 999, "Policy Loss": -0.004047433380037546, "Value Loss": 0.0014677918516099453, "_runtime": 1669.6881093978882, "_timestamp": 1585596418.704783, "_step": 320}
{"Episode reward": -39.792916086149745, "Episode length": 999, "Policy Loss": 0.0009628855623304844, "Value Loss": 0.0013761684531345963, "_runtime": 1671.2498924732208, "_timestamp": 1585596420.266566, "_step": 321}
{"Episode reward": -40.6748685784716, "Episode length": 999, "Policy Loss": -0.00014295324217528105, "Value Loss": 0.0013579599326476455, "_runtime": 1672.8011074066162, "_timestamp": 1585596421.817781, "_step": 322}
{"Episode reward": -39.636894258820476, "Episode length": 999, "Policy Loss": 0.0003553190326783806, "Value Loss": 0.0014281056355684996, "_runtime": 1674.3640019893646, "_timestamp": 1585596423.3806756, "_step": 323}
{"Episode reward": -38.57934231601036, "Episode length": 999, "Policy Loss": 0.002560071647167206, "Value Loss": 0.0013922496000304818, "_runtime": 1675.961442232132, "_timestamp": 1585596424.9781158, "_step": 324}
{"Episode reward": -39.87860836892475, "Episode length": 999, "Policy Loss": -0.0009222754742950201, "Value Loss": 0.0014932830817997456, "_runtime": 1677.5129222869873, "_timestamp": 1585596426.5295959, "_step": 325}
{"Episode reward": -38.60028734691644, "Episode length": 999, "Policy Loss": -0.0004625766596291214, "Value Loss": 0.0014188841450959444, "_runtime": 1679.0744416713715, "_timestamp": 1585596428.0911152, "_step": 326}
{"Episode reward": -39.82797967906334, "Episode length": 999, "Policy Loss": -0.00025204895064234734, "Value Loss": 0.0013970364816486835, "_runtime": 1680.6160943508148, "_timestamp": 1585596429.632768, "_step": 327}
{"Episode reward": -40.126825330034364, "Episode length": 999, "Policy Loss": 0.00023130820773076266, "Value Loss": 0.0014456211356446147, "_runtime": 1682.1618764400482, "_timestamp": 1585596431.17855, "_step": 328}
{"Episode reward": -40.86733525822825, "Episode length": 999, "Policy Loss": 0.0011848426656797528, "Value Loss": 0.0014552116626873612, "_runtime": 1683.7151639461517, "_timestamp": 1585596432.7318375, "_step": 329}
{"Episode reward": -37.637847196361214, "Episode length": 999, "Policy Loss": 0.002640221267938614, "Value Loss": 0.0013730888022109866, "_runtime": 1685.2705912590027, "_timestamp": 1585596434.2872648, "_step": 330}
{"Episode reward": -39.97949365937725, "Episode length": 999, "Policy Loss": -3.598159673856571e-05, "Value Loss": 0.0014188061468303204, "_runtime": 1686.8269355297089, "_timestamp": 1585596435.843609, "_step": 331}
{"Episode reward": -40.117972438967634, "Episode length": 999, "Policy Loss": 0.0016259623225778341, "Value Loss": 0.001430738135240972, "_runtime": 1688.3707814216614, "_timestamp": 1585596437.387455, "_step": 332}
{"Episode reward": -41.51329127527907, "Episode length": 999, "Policy Loss": -0.0026536749210208654, "Value Loss": 0.001507926732301712, "_runtime": 1689.926275730133, "_timestamp": 1585596438.9429493, "_step": 333}
{"Episode reward": -42.082843872031404, "Episode length": 999, "Policy Loss": -0.00284295785240829, "Value Loss": 0.001450550858862698, "_runtime": 1691.4797277450562, "_timestamp": 1585596440.4964013, "_step": 334}
{"Episode reward": -40.01769444338856, "Episode length": 999, "Policy Loss": 0.000868499802891165, "Value Loss": 0.0013970064464956522, "_runtime": 1693.0228254795074, "_timestamp": 1585596442.039499, "_step": 335}
{"Episode reward": -40.21922481445283, "Episode length": 999, "Policy Loss": 0.0005621743039228022, "Value Loss": 0.0014143496518954635, "_runtime": 1694.5686972141266, "_timestamp": 1585596443.5853708, "_step": 336}
{"Episode reward": -40.14417246005465, "Episode length": 999, "Policy Loss": 0.00042807459249161184, "Value Loss": 0.0014482446713373065, "_runtime": 1696.112901687622, "_timestamp": 1585596445.1295753, "_step": 337}
{"Episode reward": -37.92798506615556, "Episode length": 999, "Policy Loss": 0.002422410063445568, "Value Loss": 0.0013762374874204397, "_runtime": 1697.6598773002625, "_timestamp": 1585596446.6765509, "_step": 338}
{"Episode reward": -41.45521447079403, "Episode length": 999, "Policy Loss": -0.0006944633205421269, "Value Loss": 0.0014120442792773247, "_runtime": 1699.242636680603, "_timestamp": 1585596448.2593102, "_step": 339}
{"Episode reward": -39.70016910644268, "Episode length": 999, "Policy Loss": -0.0016197806689888239, "Value Loss": 0.0013921933714300394, "_runtime": 1700.787130355835, "_timestamp": 1585596449.803804, "_step": 340}
{"Episode reward": -39.28632363347887, "Episode length": 999, "Policy Loss": 0.0002190080122090876, "Value Loss": 0.0014086852315813303, "_runtime": 1702.347445487976, "_timestamp": 1585596451.364119, "_step": 341}
{"Episode reward": -40.650523445829904, "Episode length": 999, "Policy Loss": 0.0012053382815793157, "Value Loss": 0.0014063832350075245, "_runtime": 1703.9043838977814, "_timestamp": 1585596452.9210575, "_step": 342}
{"Episode reward": -42.0087267085301, "Episode length": 999, "Policy Loss": -5.909939864068292e-05, "Value Loss": 0.001417288207449019, "_runtime": 1705.4654428958893, "_timestamp": 1585596454.4821165, "_step": 343}
{"Episode reward": -40.1376476139487, "Episode length": 999, "Policy Loss": -0.0003926772915292531, "Value Loss": 0.001474582590162754, "_runtime": 1707.0277075767517, "_timestamp": 1585596456.0443811, "_step": 344}
{"Episode reward": -39.38813426621, "Episode length": 999, "Policy Loss": 0.002884063869714737, "Value Loss": 0.0013831985415890813, "_runtime": 1708.5903701782227, "_timestamp": 1585596457.6070437, "_step": 345}
{"Episode reward": -39.90768563459975, "Episode length": 999, "Policy Loss": 0.0007921079522930086, "Value Loss": 0.0014535580994561315, "_runtime": 1710.154904127121, "_timestamp": 1585596459.1715777, "_step": 346}
{"Episode reward": -41.23633762948523, "Episode length": 999, "Policy Loss": -0.0007261581486091018, "Value Loss": 0.0014695818535983562, "_runtime": 1711.7151367664337, "_timestamp": 1585596460.7318103, "_step": 347}
{"Episode reward": -40.50253518821033, "Episode length": 999, "Policy Loss": -0.0006762079428881407, "Value Loss": 0.0014593394007533789, "_runtime": 1713.2760469913483, "_timestamp": 1585596462.2927206, "_step": 348}
{"Episode reward": -40.05251434308949, "Episode length": 999, "Policy Loss": 0.0001458719198126346, "Value Loss": 0.0014528295723721385, "_runtime": 1714.838395357132, "_timestamp": 1585596463.855069, "_step": 349}
{"Episode reward": -41.51439638706344, "Episode length": 999, "Policy Loss": -0.0016690791817381978, "Value Loss": 0.0014701546169817448, "_runtime": 1716.3983566761017, "_timestamp": 1585596465.4150302, "_step": 350}
{"Episode reward": -39.514045117360254, "Episode length": 999, "Policy Loss": 0.0011680262396112084, "Value Loss": 0.001422853209078312, "_runtime": 1717.9613480567932, "_timestamp": 1585596466.9780216, "_step": 351}
{"Episode reward": -40.491965836549355, "Episode length": 999, "Policy Loss": 0.001367559190839529, "Value Loss": 0.0014437163481488824, "_runtime": 1719.5234682559967, "_timestamp": 1585596468.5401418, "_step": 352}
{"Episode reward": -39.17095518011937, "Episode length": 999, "Policy Loss": 0.0019801510497927666, "Value Loss": 0.0014138740953058004, "_runtime": 1721.0717091560364, "_timestamp": 1585596470.0883827, "_step": 353}
{"Episode reward": -39.740396604961006, "Episode length": 999, "Policy Loss": -0.0007632622728124261, "Value Loss": 0.0014189413050189614, "_runtime": 1722.661549091339, "_timestamp": 1585596471.6782227, "_step": 354}
{"Episode reward": -40.7611436312464, "Episode length": 999, "Policy Loss": -0.0016249235486611724, "Value Loss": 0.0014669710071757436, "_runtime": 1724.2215962409973, "_timestamp": 1585596473.2382698, "_step": 355}
{"Episode reward": -40.13919015691935, "Episode length": 999, "Policy Loss": 0.001241395715624094, "Value Loss": 0.0014791423454880714, "_runtime": 1725.7831492424011, "_timestamp": 1585596474.7998228, "_step": 356}
{"Episode reward": -39.52694619465343, "Episode length": 999, "Policy Loss": -0.00040426113991998136, "Value Loss": 0.001437416416592896, "_runtime": 1727.345962047577, "_timestamp": 1585596476.3626356, "_step": 357}
{"Episode reward": -41.15562636119433, "Episode length": 999, "Policy Loss": -0.0017325617372989655, "Value Loss": 0.0014554514782503247, "_runtime": 1728.8991150856018, "_timestamp": 1585596477.9157887, "_step": 358}
{"Episode reward": -41.780403713436314, "Episode length": 999, "Policy Loss": -0.0030268453992903233, "Value Loss": 0.0014788095140829682, "_runtime": 1730.448103427887, "_timestamp": 1585596479.464777, "_step": 359}
{"Episode reward": -42.726033794030926, "Episode length": 999, "Policy Loss": -0.0018080293666571379, "Value Loss": 0.0014435445191338658, "_runtime": 1732.0112557411194, "_timestamp": 1585596481.0279293, "_step": 360}
{"Episode reward": -40.50711290597359, "Episode length": 999, "Policy Loss": -0.00036135807749815285, "Value Loss": 0.0013901515631005168, "_runtime": 1733.5717997550964, "_timestamp": 1585596482.5884733, "_step": 361}
{"Episode reward": -39.670132081932096, "Episode length": 999, "Policy Loss": -0.0002443038101773709, "Value Loss": 0.001422224915586412, "_runtime": 1735.1316108703613, "_timestamp": 1585596484.1482844, "_step": 362}
{"Episode reward": -41.573378458793954, "Episode length": 999, "Policy Loss": -0.0021501434966921806, "Value Loss": 0.0014863715041428804, "_runtime": 1736.6937901973724, "_timestamp": 1585596485.7104638, "_step": 363}
{"Episode reward": -41.258767356955765, "Episode length": 999, "Policy Loss": -0.0011812167940661311, "Value Loss": 0.0014055974315851927, "_runtime": 1738.2518305778503, "_timestamp": 1585596487.2685041, "_step": 364}
{"Episode reward": -39.66154410928931, "Episode length": 999, "Policy Loss": 0.0008884140406735241, "Value Loss": 0.001411160104908049, "_runtime": 1739.8032643795013, "_timestamp": 1585596488.819938, "_step": 365}
{"Episode reward": -40.82592005801232, "Episode length": 999, "Policy Loss": -0.001179325976409018, "Value Loss": 0.0014459401136264205, "_runtime": 1741.3552505970001, "_timestamp": 1585596490.3719242, "_step": 366}
{"Episode reward": -41.2384868957123, "Episode length": 999, "Policy Loss": -0.0021536380518227816, "Value Loss": 0.0014647010248154402, "_runtime": 1742.9067356586456, "_timestamp": 1585596491.9234092, "_step": 367}
{"Episode reward": -41.25115209602522, "Episode length": 999, "Policy Loss": -0.00413444684818387, "Value Loss": 0.0014130747877061367, "_runtime": 1744.4584686756134, "_timestamp": 1585596493.4751422, "_step": 368}
{"Episode reward": -40.55886966685207, "Episode length": 999, "Policy Loss": -0.0018143417546525598, "Value Loss": 0.0015072604874148965, "_runtime": 1746.0477366447449, "_timestamp": 1585596495.0644102, "_step": 369}
{"Episode reward": -41.333898540288374, "Episode length": 999, "Policy Loss": -0.0014827640261501074, "Value Loss": 0.0014332535210996866, "_runtime": 1747.600058555603, "_timestamp": 1585596496.6167321, "_step": 370}
{"Episode reward": -41.03790041844915, "Episode length": 999, "Policy Loss": 5.448771480587311e-05, "Value Loss": 0.0014480623649433255, "_runtime": 1749.1543552875519, "_timestamp": 1585596498.1710289, "_step": 371}
{"Episode reward": -42.104148561034854, "Episode length": 999, "Policy Loss": -0.002283241366967559, "Value Loss": 0.0015089631779119372, "_runtime": 1750.708323955536, "_timestamp": 1585596499.7249975, "_step": 372}
{"Episode reward": -39.15659843167959, "Episode length": 999, "Policy Loss": -0.0003874303656630218, "Value Loss": 0.0014075578656047583, "_runtime": 1752.269454240799, "_timestamp": 1585596501.2861278, "_step": 373}
{"Episode reward": -40.20789292230574, "Episode length": 999, "Policy Loss": -0.00020712887635454535, "Value Loss": 0.0014478799421340227, "_runtime": 1753.828115940094, "_timestamp": 1585596502.8447895, "_step": 374}
{"Episode reward": -40.5442579583436, "Episode length": 999, "Policy Loss": -0.0004821076581720263, "Value Loss": 0.0014635509578511119, "_runtime": 1755.387746334076, "_timestamp": 1585596504.40442, "_step": 375}
{"Episode reward": -40.58199270419872, "Episode length": 999, "Policy Loss": -3.428806667216122e-05, "Value Loss": 0.001461196574382484, "_runtime": 1756.949182510376, "_timestamp": 1585596505.965856, "_step": 376}
{"Episode reward": -40.12726798906863, "Episode length": 999, "Policy Loss": 0.0007064781966619194, "Value Loss": 0.0014251817483454943, "_runtime": 1758.509595632553, "_timestamp": 1585596507.5262692, "_step": 377}
{"Episode reward": -43.54156070533653, "Episode length": 999, "Policy Loss": -0.004620409570634365, "Value Loss": 0.0014929547905921936, "_runtime": 1760.062200307846, "_timestamp": 1585596509.0788739, "_step": 378}
{"Episode reward": -42.102155979881836, "Episode length": 999, "Policy Loss": -0.0013111631851643324, "Value Loss": 0.0014811002183705568, "_runtime": 1761.6107685565948, "_timestamp": 1585596510.6274421, "_step": 379}
{"Episode reward": -39.22564297373284, "Episode length": 999, "Policy Loss": 0.0016943055670708418, "Value Loss": 0.0014104268047958612, "_runtime": 1763.169754743576, "_timestamp": 1585596512.1864283, "_step": 380}
{"Episode reward": -39.63755427325402, "Episode length": 999, "Policy Loss": 0.000601253064814955, "Value Loss": 0.0013795072445645928, "_runtime": 1764.7298846244812, "_timestamp": 1585596513.7465582, "_step": 381}
{"Episode reward": -39.988934487920965, "Episode length": 999, "Policy Loss": -4.479500057641417e-05, "Value Loss": 0.0013913392322137952, "_runtime": 1766.2902154922485, "_timestamp": 1585596515.306889, "_step": 382}
{"Episode reward": -40.08271014333125, "Episode length": 999, "Policy Loss": 0.0005659105954691768, "Value Loss": 0.0014012117171660066, "_runtime": 1767.8403623104095, "_timestamp": 1585596516.8570359, "_step": 383}
{"Episode reward": -40.4881519888654, "Episode length": 999, "Policy Loss": 0.0033632253762334585, "Value Loss": 0.0014169012429192662, "_runtime": 1769.4274640083313, "_timestamp": 1585596518.4441376, "_step": 384}
{"Episode reward": -41.466005905611524, "Episode length": 999, "Policy Loss": -0.0028229181189090014, "Value Loss": 0.0014524535508826375, "_runtime": 1770.9935569763184, "_timestamp": 1585596520.0102305, "_step": 385}
{"Episode reward": -42.947842326640945, "Episode length": 999, "Policy Loss": -0.0020288056693971157, "Value Loss": 0.0015026441542431712, "_runtime": 1772.5651123523712, "_timestamp": 1585596521.581786, "_step": 386}
{"Episode reward": -40.75028906244648, "Episode length": 999, "Policy Loss": -0.0010089789284393191, "Value Loss": 0.0014470770256593823, "_runtime": 1774.1269690990448, "_timestamp": 1585596523.1436427, "_step": 387}
{"Episode reward": -39.7861662734215, "Episode length": 999, "Policy Loss": -0.00079901929711923, "Value Loss": 0.0014375030295923352, "_runtime": 1775.6888539791107, "_timestamp": 1585596524.7055275, "_step": 388}
{"Episode reward": -42.03694298058274, "Episode length": 999, "Policy Loss": -0.0020539485849440098, "Value Loss": 0.0014308171812444925, "_runtime": 1777.251844882965, "_timestamp": 1585596526.2685184, "_step": 389}
{"Episode reward": -41.22229548750552, "Episode length": 999, "Policy Loss": -0.0014050224563106894, "Value Loss": 0.0014834203757345676, "_runtime": 1778.8123905658722, "_timestamp": 1585596527.8290641, "_step": 390}
{"Episode reward": -39.27371012676103, "Episode length": 999, "Policy Loss": 0.0011250260286033154, "Value Loss": 0.001401968183927238, "_runtime": 1780.367193222046, "_timestamp": 1585596529.3838668, "_step": 391}
{"Episode reward": -39.2193731714174, "Episode length": 999, "Policy Loss": 0.004077395889908075, "Value Loss": 0.0014083082787692547, "_runtime": 1781.9277427196503, "_timestamp": 1585596530.9444163, "_step": 392}
{"Episode reward": -40.88479760440417, "Episode length": 999, "Policy Loss": -0.004018682055175304, "Value Loss": 0.001475062919780612, "_runtime": 1783.486855506897, "_timestamp": 1585596532.503529, "_step": 393}
{"Episode reward": -40.56933546038174, "Episode length": 999, "Policy Loss": -8.654715929878876e-05, "Value Loss": 0.001428646151907742, "_runtime": 1785.0498161315918, "_timestamp": 1585596534.0664897, "_step": 394}
{"Episode reward": -42.7812102535835, "Episode length": 999, "Policy Loss": -0.0038991132751107216, "Value Loss": 0.0014596610562875867, "_runtime": 1786.598974943161, "_timestamp": 1585596535.6156485, "_step": 395}
{"Episode reward": -41.57101602373032, "Episode length": 999, "Policy Loss": 9.985952783608809e-05, "Value Loss": 0.0013938480988144875, "_runtime": 1788.1610176563263, "_timestamp": 1585596537.1776912, "_step": 396}
{"Episode reward": -41.270787338551195, "Episode length": 999, "Policy Loss": -0.0012337430380284786, "Value Loss": 0.0014283371856436133, "_runtime": 1789.7229764461517, "_timestamp": 1585596538.73965, "_step": 397}
{"Episode reward": -41.62210105417825, "Episode length": 999, "Policy Loss": 3.128567186649889e-05, "Value Loss": 0.0014854308683425188, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635, -3.2756922245025635]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0], "bins": [-11.9714994430542, -11.735929489135742, -11.500360488891602, -11.264790534973145, -11.029220581054688, -10.79365062713623, -10.55808162689209, -10.322511672973633, -10.086941719055176, -9.851371765136719, -9.615802764892578, -9.380232810974121, -9.144662857055664, -8.909093856811523, -8.673523902893066, -8.43795394897461, -8.202384948730469, -7.966814994812012, -7.731245040893555, -7.495675563812256, -7.260105609893799, -7.0245361328125, -6.788966178894043, -6.553396701812744, -6.317827224731445, -6.082257270812988, -5.8466877937316895, -5.611117839813232, -5.375548362731934, -5.139978408813477, -4.904408931732178, -4.668838977813721, -4.433269500732422, -4.197700023651123, -3.962130546569824, -3.726560592651367, -3.49099063873291, -3.255420684814453, -3.0198516845703125, -2.7842817306518555, -2.5487117767333984, -2.313142776489258, -2.077572822570801, -1.8420028686523438, -1.6064329147338867, -1.370863914489746, -1.135293960571289, -0.899724006652832, -0.6641550064086914, -0.4285850524902344, -0.19301509857177734, 0.04255485534667969, 0.2781238555908203, 0.5136938095092773, 0.7492637634277344, 0.9848337173461914, 1.220402717590332, 1.455972671508789, 1.691542625427246, 1.9271116256713867, 2.1626815795898438, 2.398251533508301, 2.633821487426758, 2.8693904876708984, 3.1049604415893555]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.9285469055175781, -0.9004038572311401, -0.8722608089447021, -0.8441177606582642, -0.8159746527671814, -0.7878316044807434, -0.7596885561943054, -0.7315455079078674, -0.7034024000167847, -0.6752593517303467, -0.6471163034439087, -0.6189732551574707, -0.5908302068710327, -0.5626871585845947, -0.5345441102981567, -0.506401002407074, -0.478257954120636, -0.450114905834198, -0.42197185754776, -0.39382874965667725, -0.36568570137023926, -0.33754265308380127, -0.3093996047973633, -0.2812565565109253, -0.2531135082244873, -0.22497040033340454, -0.19682735204696655, -0.16868430376052856, -0.14054125547409058, -0.11239820718765259, -0.08425509929656982, -0.056112051010131836, -0.027969002723693848, 0.00017404556274414062, 0.02831709384918213, 0.05646020174026489, 0.0846031904220581, 0.1127462387084961, 0.14088940620422363, 0.16903245449066162, 0.1971755027770996, 0.2253185510635376, 0.2534615993499756, 0.2816046476364136, 0.30974769592285156, 0.33789074420928955, 0.36603379249572754, 0.3941768407821655, 0.4223198890686035, 0.45046305656433105, 0.47860610485076904, 0.506749153137207, 0.534892201423645, 0.563035249710083, 0.591178297996521, 0.619321346282959, 0.647464394569397, 0.675607442855835, 0.703750491142273, 0.7318936586380005, 0.7600367069244385, 0.7881797552108765, 0.8163228034973145, 0.8444658517837524, 0.8726089000701904]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 7.0, 9.0, 10.0, 14.0, 15.0, 19.0, 38.0, 144.0, 125.0, 38.0, 17.0, 12.0, 14.0, 8.0, 3.0, 4.0, 2.0, 2.0, 5.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.1357121467590332, -1.101290225982666, -1.0668681859970093, -1.032446265220642, -0.9980242252349854, -0.9636023044586182, -0.9291803240776062, -0.8947583436965942, -0.8603363633155823, -0.8259143829345703, -0.7914924025535583, -0.7570704221725464, -0.7226485013961792, -0.6882264614105225, -0.6538045406341553, -0.6193825602531433, -0.5849605798721313, -0.5505385994911194, -0.5161166191101074, -0.48169463872909546, -0.4472726583480835, -0.4128507375717163, -0.37842875719070435, -0.3440067768096924, -0.3095847964286804, -0.27516281604766846, -0.2407408356666565, -0.20631885528564453, -0.17189693450927734, -0.13747495412826538, -0.10305297374725342, -0.06863093376159668, -0.03420901298522949, 0.0002129077911376953, 0.034634947776794434, 0.06905686855316162, 0.10347890853881836, 0.13790082931518555, 0.17232286930084229, 0.20674479007720947, 0.2411668300628662, 0.2755887508392334, 0.3100106716156006, 0.3444327116012573, 0.3788546323776245, 0.41327667236328125, 0.44769859313964844, 0.4821206331253052, 0.5165425539016724, 0.5509644746780396, 0.5853865146636963, 0.6198084354400635, 0.6542304754257202, 0.6886523962020874, 0.7230744361877441, 0.7574963569641113, 0.7919182777404785, 0.8263403177261353, 0.8607622385025024, 0.8951842784881592, 0.9296061992645264, 0.9640281200408936, 0.9984502792358398, 1.032872200012207, 1.0672941207885742]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.5083104372024536, -1.4584511518478394, -1.408591866493225, -1.3587327003479004, -1.3088734149932861, -1.2590141296386719, -1.2091548442840576, -1.1592955589294434, -1.1094363927841187, -1.0595771074295044, -1.0097178220748901, -0.9598585963249207, -0.9099993109703064, -0.8601400852203369, -0.8102807998657227, -0.7604215741157532, -0.7105622887611389, -0.6607030034065247, -0.6108437776565552, -0.5609844923019409, -0.5111252665519714, -0.46126604080200195, -0.4114067554473877, -0.36154747009277344, -0.3116881847381592, -0.2618288993835449, -0.21196973323822021, -0.16211044788360596, -0.1122511625289917, -0.06239187717437744, -0.012532711029052734, 0.03732657432556152, 0.08718585968017578, 0.13704514503479004, 0.1869044303894043, 0.236763596534729, 0.28662288188934326, 0.3364821672439575, 0.3863414525985718, 0.4362006187438965, 0.48605990409851074, 0.5359193086624146, 0.5857783555984497, 0.635637640953064, 0.6854969263076782, 0.7353562116622925, 0.7852154970169067, 0.835074782371521, 0.8849340677261353, 0.9347933530807495, 0.9846526384353638, 1.034511685371399, 1.0843709707260132, 1.1342302560806274, 1.1840895414352417, 1.233948826789856, 1.2838081121444702, 1.3336673974990845, 1.3835266828536987, 1.433385968208313, 1.4832450151443481, 1.5331043004989624, 1.5829635858535767, 1.632822871208191, 1.6826821565628052]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 5.0, 4.0, 7.0, 1.0, 2.0, 3.0, 5.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7546746730804443, -0.7323880195617676, -0.7101013660430908, -0.6878147125244141, -0.6655280590057373, -0.6432414650917053, -0.6209548115730286, -0.5986681580543518, -0.576381504535675, -0.5540948510169983, -0.5318081974983215, -0.5095216035842896, -0.4872349202632904, -0.46494826674461365, -0.4426616430282593, -0.4203749895095825, -0.39808833599090576, -0.375801682472229, -0.35351502895355225, -0.3312284052371979, -0.3089417517185211, -0.28665509819984436, -0.26436847448349, -0.24208182096481323, -0.21979516744613647, -0.19750851392745972, -0.17522186040878296, -0.1529352068901062, -0.13064861297607422, -0.10836195945739746, -0.0860753059387207, -0.06378865242004395, -0.04150199890136719, -0.01921534538269043, 0.003071308135986328, 0.025357961654663086, 0.047644615173339844, 0.06993120908737183, 0.09221786260604858, 0.11450451612472534, 0.1367911696434021, 0.15907782316207886, 0.18136447668075562, 0.20365113019943237, 0.22593772411346436, 0.2482243776321411, 0.27051103115081787, 0.29279768466949463, 0.3150843381881714, 0.33737099170684814, 0.3596576452255249, 0.38194429874420166, 0.4042309522628784, 0.4265176057815552, 0.44880425930023193, 0.4710909128189087, 0.4933774471282959, 0.5156641006469727, 0.5379507541656494, 0.5602374076843262, 0.5825240612030029, 0.6048107147216797, 0.6270973682403564, 0.6493840217590332, 0.67167067527771]}, "_runtime": 1791.3206355571747, "_timestamp": 1585596540.3373091, "_step": 398}
{"Episode reward": -40.2588026579989, "Episode length": 999, "Policy Loss": 0.0010519009083509445, "Value Loss": 0.001400904031470418, "_runtime": 1792.8836364746094, "_timestamp": 1585596541.90031, "_step": 399}
{"Episode reward": -41.15039169408433, "Episode length": 999, "Policy Loss": -0.0005853950278833508, "Value Loss": 0.001423663692548871, "_runtime": 1794.4337241649628, "_timestamp": 1585596543.4503977, "_step": 400}
{"Episode reward": -39.74452322299371, "Episode length": 999, "Policy Loss": -0.00016453511489089578, "Value Loss": 0.0014242473989725113, "_runtime": 1795.985575914383, "_timestamp": 1585596545.0022495, "_step": 401}
{"Episode reward": -39.52359255714853, "Episode length": 999, "Policy Loss": 0.001942270202562213, "Value Loss": 0.0014479997335001826, "_runtime": 1797.5355205535889, "_timestamp": 1585596546.552194, "_step": 402}
{"Episode reward": -41.348509078080134, "Episode length": 999, "Policy Loss": -0.0016600637463852763, "Value Loss": 0.0014754246221855283, "_runtime": 1799.0847599506378, "_timestamp": 1585596548.1014335, "_step": 403}
{"Episode reward": -37.35278788286971, "Episode length": 999, "Policy Loss": 0.003145915921777487, "Value Loss": 0.001363675226457417, "_runtime": 1800.638394832611, "_timestamp": 1585596549.6550684, "_step": 404}
{"Episode reward": -41.875039801211955, "Episode length": 999, "Policy Loss": -0.001116740400902927, "Value Loss": 0.0014396358747035265, "_runtime": 1802.1933226585388, "_timestamp": 1585596551.2099962, "_step": 405}
{"Episode reward": -41.066360489916946, "Episode length": 999, "Policy Loss": -0.00038597191451117396, "Value Loss": 0.0014612284721806645, "_runtime": 1803.7525072097778, "_timestamp": 1585596552.7691808, "_step": 406}
{"Episode reward": -40.67953451786988, "Episode length": 999, "Policy Loss": 0.000698029703926295, "Value Loss": 0.001371260266751051, "_runtime": 1805.304059267044, "_timestamp": 1585596554.3207328, "_step": 407}
{"Episode reward": -39.76628580887085, "Episode length": 999, "Policy Loss": 0.00046943017514422536, "Value Loss": 0.0013801740715280175, "_runtime": 1806.8544030189514, "_timestamp": 1585596555.8710766, "_step": 408}
{"Episode reward": -40.92047630916663, "Episode length": 999, "Policy Loss": 7.475817255908623e-05, "Value Loss": 0.0014369209529832006, "_runtime": 1808.414796113968, "_timestamp": 1585596557.4314697, "_step": 409}
{"Episode reward": -39.93006016767126, "Episode length": 999, "Policy Loss": 0.001012228662148118, "Value Loss": 0.0014010040322318673, "_runtime": 1809.9769537448883, "_timestamp": 1585596558.9936273, "_step": 410}
{"Episode reward": -40.398018786517994, "Episode length": 999, "Policy Loss": -0.0017644246108829975, "Value Loss": 0.0014796904288232327, "_runtime": 1811.5374147891998, "_timestamp": 1585596560.5540884, "_step": 411}
{"Episode reward": -40.88074605507294, "Episode length": 999, "Policy Loss": -0.000553697522263974, "Value Loss": 0.0014430969022214413, "_runtime": 1813.0988104343414, "_timestamp": 1585596562.115484, "_step": 412}
{"Episode reward": -41.22609170397092, "Episode length": 999, "Policy Loss": 0.0008659577579237521, "Value Loss": 0.0014782065991312265, "_runtime": 1814.6957113742828, "_timestamp": 1585596563.712385, "_step": 413}
{"Episode reward": -38.966637565534846, "Episode length": 999, "Policy Loss": 5.718920874642208e-05, "Value Loss": 0.0013855594443157315, "_runtime": 1816.2564322948456, "_timestamp": 1585596565.2731059, "_step": 414}
{"Episode reward": -40.18560233427522, "Episode length": 999, "Policy Loss": 0.00029169704066589475, "Value Loss": 0.0014067614683881402, "_runtime": 1817.8066594600677, "_timestamp": 1585596566.823333, "_step": 415}
{"Episode reward": -41.87409562068598, "Episode length": 999, "Policy Loss": -0.0019071175483986735, "Value Loss": 0.0014529487816616893, "_runtime": 1819.3703699111938, "_timestamp": 1585596568.3870435, "_step": 416}
{"Episode reward": -39.61333043865725, "Episode length": 999, "Policy Loss": -6.606105307582766e-05, "Value Loss": 0.001388509408570826, "_runtime": 1820.931125164032, "_timestamp": 1585596569.9477987, "_step": 417}
{"Episode reward": -41.00409061277281, "Episode length": 999, "Policy Loss": -8.414503099629655e-05, "Value Loss": 0.0014613608364015818, "_runtime": 1822.4938566684723, "_timestamp": 1585596571.5105302, "_step": 418}
{"Episode reward": -38.840615187740745, "Episode length": 999, "Policy Loss": 0.0005178139545023441, "Value Loss": 0.001434404170140624, "_runtime": 1824.0583741664886, "_timestamp": 1585596573.0750477, "_step": 419}
{"Episode reward": -40.258598345249965, "Episode length": 999, "Policy Loss": 0.001143112313002348, "Value Loss": 0.0014321879716590047, "_runtime": 1825.6193079948425, "_timestamp": 1585596574.6359816, "_step": 420}
{"Episode reward": -40.59693572184393, "Episode length": 999, "Policy Loss": -0.00013166906137485057, "Value Loss": 0.0014389512361958623, "_runtime": 1827.1814975738525, "_timestamp": 1585596576.1981711, "_step": 421}
{"Episode reward": -38.37210410525596, "Episode length": 999, "Policy Loss": 0.0038227979093790054, "Value Loss": 0.001362537732347846, "_runtime": 1828.7435615062714, "_timestamp": 1585596577.760235, "_step": 422}
{"Episode reward": -42.18113769179893, "Episode length": 999, "Policy Loss": -0.001800349447876215, "Value Loss": 0.0014657621504738927, "_runtime": 1830.3052880764008, "_timestamp": 1585596579.3219616, "_step": 423}
{"Episode reward": -40.40172537622247, "Episode length": 999, "Policy Loss": 0.0008165283361449838, "Value Loss": 0.0014562953729182482, "_runtime": 1831.8572924137115, "_timestamp": 1585596580.873966, "_step": 424}
{"Episode reward": -39.884381008847214, "Episode length": 999, "Policy Loss": 0.0010313544189557433, "Value Loss": 0.001416941056959331, "_runtime": 1833.419569015503, "_timestamp": 1585596582.4362426, "_step": 425}
{"Episode reward": -41.32755093857451, "Episode length": 999, "Policy Loss": -0.0022158019710332155, "Value Loss": 0.0014727162197232246, "_runtime": 1834.9814207553864, "_timestamp": 1585596583.9980943, "_step": 426}
{"Episode reward": -41.18144016417203, "Episode length": 999, "Policy Loss": 0.0002658418961800635, "Value Loss": 0.001430767821148038, "_runtime": 1836.543963432312, "_timestamp": 1585596585.560637, "_step": 427}
{"Episode reward": -41.27434656372573, "Episode length": 999, "Policy Loss": -0.00170033925678581, "Value Loss": 0.0014543405268341303, "_runtime": 1838.143214225769, "_timestamp": 1585596587.1598878, "_step": 428}
{"Episode reward": -40.32480221266603, "Episode length": 999, "Policy Loss": -0.0002477985981386155, "Value Loss": 0.0013568319845944643, "_runtime": 1839.6925106048584, "_timestamp": 1585596588.7091842, "_step": 429}
{"Episode reward": -39.39396350686276, "Episode length": 999, "Policy Loss": 0.0009655517060309649, "Value Loss": 0.0013463763752952218, "_runtime": 1841.2552194595337, "_timestamp": 1585596590.271893, "_step": 430}
{"Episode reward": -40.34732616191552, "Episode length": 999, "Policy Loss": 0.002019200474023819, "Value Loss": 0.0014144153101369739, "_runtime": 1842.8178510665894, "_timestamp": 1585596591.8345246, "_step": 431}
{"Episode reward": -41.906391621135526, "Episode length": 999, "Policy Loss": -0.002800071146339178, "Value Loss": 0.0014325426891446114, "_runtime": 1844.3697321414948, "_timestamp": 1585596593.3864057, "_step": 432}
{"Episode reward": -39.378918921191506, "Episode length": 999, "Policy Loss": 0.0020154116209596395, "Value Loss": 0.0013676875969395041, "_runtime": 1845.9313473701477, "_timestamp": 1585596594.948021, "_step": 433}
{"Episode reward": -38.91526139055454, "Episode length": 999, "Policy Loss": 0.002311588265001774, "Value Loss": 0.0014120409032329917, "_runtime": 1847.4954071044922, "_timestamp": 1585596596.5120807, "_step": 434}
{"Episode reward": -40.87581766696005, "Episode length": 999, "Policy Loss": -0.0023532004561275244, "Value Loss": 0.001459165825508535, "_runtime": 1849.0543336868286, "_timestamp": 1585596598.0710073, "_step": 435}
{"Episode reward": -39.47136930600044, "Episode length": 999, "Policy Loss": 0.0009777974337339401, "Value Loss": 0.0013841264881193638, "_runtime": 1850.6197245121002, "_timestamp": 1585596599.636398, "_step": 436}
{"Episode reward": -38.36645541447676, "Episode length": 999, "Policy Loss": 0.0010359823936596513, "Value Loss": 0.001378990593366325, "_runtime": 1852.1837043762207, "_timestamp": 1585596601.200378, "_step": 437}
{"Episode reward": -40.971460199082095, "Episode length": 999, "Policy Loss": -0.0012936224229633808, "Value Loss": 0.001472397823818028, "_runtime": 1853.7341334819794, "_timestamp": 1585596602.750807, "_step": 438}
{"Episode reward": -42.00825426883569, "Episode length": 999, "Policy Loss": -0.0020526100415736437, "Value Loss": 0.0014304363867267966, "_runtime": 1855.2967054843903, "_timestamp": 1585596604.313379, "_step": 439}
{"Episode reward": -42.7629508943046, "Episode length": 999, "Policy Loss": -0.0018758910009637475, "Value Loss": 0.0014521853299811482, "_runtime": 1856.8585922718048, "_timestamp": 1585596605.8752658, "_step": 440}
{"Episode reward": -41.67872869482014, "Episode length": 999, "Policy Loss": -0.002233383245766163, "Value Loss": 0.0014563648728653789, "_runtime": 1858.4081854820251, "_timestamp": 1585596607.424859, "_step": 441}
{"Episode reward": -39.99973723481028, "Episode length": 999, "Policy Loss": 0.0008461825782433152, "Value Loss": 0.0014079796383157372, "_runtime": 1859.9712665081024, "_timestamp": 1585596608.98794, "_step": 442}
{"Episode reward": -41.93729999375741, "Episode length": 999, "Policy Loss": -0.003747439943253994, "Value Loss": 0.001479018828831613, "_runtime": 1861.572315454483, "_timestamp": 1585596610.588989, "_step": 443}
{"Episode reward": -41.30045903342843, "Episode length": 999, "Policy Loss": -0.0020310552790760994, "Value Loss": 0.001523101469501853, "_runtime": 1863.1225261688232, "_timestamp": 1585596612.1391997, "_step": 444}
{"Episode reward": -41.092222086793214, "Episode length": 999, "Policy Loss": -0.0019079371122643352, "Value Loss": 0.0014144334709271789, "_runtime": 1864.6769483089447, "_timestamp": 1585596613.6936219, "_step": 445}
{"Episode reward": -42.60868442666735, "Episode length": 999, "Policy Loss": -0.0030878076795488596, "Value Loss": 0.0015328057343140244, "_runtime": 1866.23078083992, "_timestamp": 1585596615.2474544, "_step": 446}
{"Episode reward": -41.5276062234975, "Episode length": 999, "Policy Loss": -0.0026740022003650665, "Value Loss": 0.0014144856249913573, "_runtime": 1867.7808299064636, "_timestamp": 1585596616.7975035, "_step": 447}
{"Episode reward": -40.44686474850796, "Episode length": 999, "Policy Loss": 0.001289792824536562, "Value Loss": 0.001410390599630773, "_runtime": 1869.3360559940338, "_timestamp": 1585596618.3527296, "_step": 448}
{"Episode reward": -40.64250398671724, "Episode length": 999, "Policy Loss": -0.0024195611476898193, "Value Loss": 0.001409315038472414, "_runtime": 1870.8878276348114, "_timestamp": 1585596619.9045012, "_step": 449}
{"Episode reward": -39.686500698278834, "Episode length": 999, "Policy Loss": 0.0009551090188324451, "Value Loss": 0.0014075151411816478, "_runtime": 1872.449497461319, "_timestamp": 1585596621.466171, "_step": 450}
{"Episode reward": -40.062987889466704, "Episode length": 999, "Policy Loss": 0.0010088789276778698, "Value Loss": 0.0014239851152524352, "_runtime": 1874.0111162662506, "_timestamp": 1585596623.0277898, "_step": 451}
{"Episode reward": -38.16430131064787, "Episode length": 999, "Policy Loss": 0.0027548957150429487, "Value Loss": 0.0013977925991639495, "_runtime": 1875.5759000778198, "_timestamp": 1585596624.5925736, "_step": 452}
{"Episode reward": -41.786870064451705, "Episode length": 999, "Policy Loss": -0.001859665266238153, "Value Loss": 0.001429834752343595, "_runtime": 1877.128189086914, "_timestamp": 1585596626.1448627, "_step": 453}
{"Episode reward": -39.49703477511626, "Episode length": 999, "Policy Loss": 0.002566934796050191, "Value Loss": 0.0014369324781000614, "_runtime": 1878.6893146038055, "_timestamp": 1585596627.7059882, "_step": 454}
{"Episode reward": -43.10655440487571, "Episode length": 999, "Policy Loss": -0.004264930263161659, "Value Loss": 0.0014398377388715744, "_runtime": 1880.2543847560883, "_timestamp": 1585596629.2710583, "_step": 455}
{"Episode reward": -40.99712427886402, "Episode length": 999, "Policy Loss": -0.0011145275784656405, "Value Loss": 0.0014483063714578748, "_runtime": 1881.8154480457306, "_timestamp": 1585596630.8321216, "_step": 456}
{"Episode reward": -40.23715358327957, "Episode length": 999, "Policy Loss": 0.0012396830134093761, "Value Loss": 0.0014337245374917984, "_runtime": 1883.4140174388885, "_timestamp": 1585596632.430691, "_step": 457}
{"Episode reward": -40.25904373307873, "Episode length": 999, "Policy Loss": 0.0005379148060455918, "Value Loss": 0.001406381488777697, "_runtime": 1884.9760746955872, "_timestamp": 1585596633.9927483, "_step": 458}
{"Episode reward": -40.95724093857446, "Episode length": 999, "Policy Loss": -0.0011517946841195226, "Value Loss": 0.0014856389025226235, "_runtime": 1886.5373446941376, "_timestamp": 1585596635.5540183, "_step": 459}
{"Episode reward": -39.332703272851546, "Episode length": 999, "Policy Loss": 0.0020168449264019728, "Value Loss": 0.0013671029591932893, "_runtime": 1888.1017181873322, "_timestamp": 1585596637.1183918, "_step": 460}
{"Episode reward": -40.36450162273725, "Episode length": 999, "Policy Loss": 0.0005625214544124901, "Value Loss": 0.001401401124894619, "_runtime": 1889.6650955677032, "_timestamp": 1585596638.6817691, "_step": 461}
{"Episode reward": -42.895375648552694, "Episode length": 999, "Policy Loss": -0.003542165504768491, "Value Loss": 0.0014791827416047454, "_runtime": 1891.2261154651642, "_timestamp": 1585596640.242789, "_step": 462}
{"Episode reward": -41.735437239066464, "Episode length": 999, "Policy Loss": -0.0002445910940878093, "Value Loss": 0.0014471457106992602, "_runtime": 1892.7875640392303, "_timestamp": 1585596641.8042376, "_step": 463}
{"Episode reward": -41.635711136676605, "Episode length": 999, "Policy Loss": -0.001026996411383152, "Value Loss": 0.0014527018647640944, "_runtime": 1894.349816083908, "_timestamp": 1585596643.3664896, "_step": 464}
{"Episode reward": -40.15313474879223, "Episode length": 999, "Policy Loss": 0.0002899104729294777, "Value Loss": 0.001448425929993391, "_runtime": 1895.9121787548065, "_timestamp": 1585596644.9288523, "_step": 465}
{"Episode reward": -38.880565530839206, "Episode length": 999, "Policy Loss": 0.0028163951355963945, "Value Loss": 0.0014289629179984331, "_runtime": 1897.473172903061, "_timestamp": 1585596646.4898465, "_step": 466}
{"Episode reward": -38.574602434804234, "Episode length": 999, "Policy Loss": 0.0026888702996075153, "Value Loss": 0.0014122824650257826, "_runtime": 1899.034467458725, "_timestamp": 1585596648.051141, "_step": 467}
{"Episode reward": -38.63525190407209, "Episode length": 999, "Policy Loss": 0.002285126829519868, "Value Loss": 0.0013695628149434924, "_runtime": 1900.5984585285187, "_timestamp": 1585596649.615132, "_step": 468}
{"Episode reward": -40.459599251226805, "Episode length": 999, "Policy Loss": 0.0004489428538363427, "Value Loss": 0.0014351606369018555, "_runtime": 1902.1606693267822, "_timestamp": 1585596651.177343, "_step": 469}
{"Episode reward": -39.57576401850043, "Episode length": 999, "Policy Loss": 0.001464470406062901, "Value Loss": 0.0014201921876519918, "_runtime": 1903.717036485672, "_timestamp": 1585596652.73371, "_step": 470}
{"Episode reward": -40.71830959544265, "Episode length": 999, "Policy Loss": 0.0020295060239732265, "Value Loss": 0.0014549799961969256, "_runtime": 1905.2667934894562, "_timestamp": 1585596654.283467, "_step": 471}
{"Episode reward": -40.48529931595568, "Episode length": 999, "Policy Loss": 0.00033582336618565023, "Value Loss": 0.001431541284546256, "_runtime": 1906.8649687767029, "_timestamp": 1585596655.8816423, "_step": 472}
{"Episode reward": -39.970589729492104, "Episode length": 999, "Policy Loss": 0.0022731651552021503, "Value Loss": 0.0014551369240507483, "_runtime": 1908.4182741641998, "_timestamp": 1585596657.4349477, "_step": 473}
{"Episode reward": -41.32073917693382, "Episode length": 999, "Policy Loss": -0.000662808888591826, "Value Loss": 0.0014304999494925141, "_runtime": 1909.9808566570282, "_timestamp": 1585596658.9975302, "_step": 474}
{"Episode reward": -43.34629228769264, "Episode length": 999, "Policy Loss": -0.004091046284884214, "Value Loss": 0.0014812217559665442, "_runtime": 1911.5455467700958, "_timestamp": 1585596660.5622203, "_step": 475}
{"Episode reward": -39.26524019176036, "Episode length": 999, "Policy Loss": 0.0006949697271920741, "Value Loss": 0.0014785274397581816, "_runtime": 1913.108591079712, "_timestamp": 1585596662.1252646, "_step": 476}
{"Episode reward": -40.796611147726175, "Episode length": 999, "Policy Loss": -0.002977403113618493, "Value Loss": 0.0014351647114381194, "_runtime": 1914.6614172458649, "_timestamp": 1585596663.6780908, "_step": 477}
{"Episode reward": -41.82020338043512, "Episode length": 999, "Policy Loss": -0.0005791780422441661, "Value Loss": 0.0014914489584043622, "_runtime": 1916.2147262096405, "_timestamp": 1585596665.2313998, "_step": 478}
{"Episode reward": -40.7655994365977, "Episode length": 999, "Policy Loss": 0.001239048084244132, "Value Loss": 0.0014024008996784687, "_runtime": 1917.778094291687, "_timestamp": 1585596666.7947679, "_step": 479}
{"Episode reward": -41.33926002116463, "Episode length": 999, "Policy Loss": -0.00048711473937146366, "Value Loss": 0.001490335213020444, "_runtime": 1919.3328485488892, "_timestamp": 1585596668.349522, "_step": 480}
{"Episode reward": -42.1415124759862, "Episode length": 999, "Policy Loss": -0.00111175247002393, "Value Loss": 0.001450886600650847, "_runtime": 1920.8845233917236, "_timestamp": 1585596669.901197, "_step": 481}
{"Episode reward": -39.07738746101658, "Episode length": 999, "Policy Loss": 0.0008736439631320536, "Value Loss": 0.001416853629052639, "_runtime": 1922.439712047577, "_timestamp": 1585596671.4563856, "_step": 482}
{"Episode reward": -40.624173125466385, "Episode length": 999, "Policy Loss": -0.0009566338267177343, "Value Loss": 0.0014860687078908086, "_runtime": 1923.9946308135986, "_timestamp": 1585596673.0113044, "_step": 483}
{"Episode reward": -38.998300651006645, "Episode length": 999, "Policy Loss": 0.001363834016956389, "Value Loss": 0.001375791267491877, "_runtime": 1925.5467236042023, "_timestamp": 1585596674.5633972, "_step": 484}
{"Episode reward": -41.79084787857976, "Episode length": 999, "Policy Loss": -0.001923922449350357, "Value Loss": 0.0014671697281301022, "_runtime": 1927.0984044075012, "_timestamp": 1585596676.115078, "_step": 485}
{"Episode reward": -40.727723234862445, "Episode length": 999, "Policy Loss": -0.00037897672154940665, "Value Loss": 0.00148439547047019, "_runtime": 1928.6509075164795, "_timestamp": 1585596677.667581, "_step": 486}
{"Episode reward": -42.02178301466363, "Episode length": 999, "Policy Loss": -0.0016792688984423876, "Value Loss": 0.001470640185289085, "_runtime": 1930.2412962913513, "_timestamp": 1585596679.2579699, "_step": 487}
{"Episode reward": -41.70615411817164, "Episode length": 999, "Policy Loss": -0.0013403513003140688, "Value Loss": 0.0014318105531856418, "_runtime": 1931.803780078888, "_timestamp": 1585596680.8204536, "_step": 488}
{"Episode reward": -39.86604213251362, "Episode length": 999, "Policy Loss": 0.000862020708154887, "Value Loss": 0.0014033118495717645, "_runtime": 1933.3592956066132, "_timestamp": 1585596682.3759692, "_step": 489}
{"Episode reward": -40.82430256168384, "Episode length": 999, "Policy Loss": 0.00041309031075797975, "Value Loss": 0.001475740340538323, "_runtime": 1934.910807609558, "_timestamp": 1585596683.9274812, "_step": 490}
{"Episode reward": -41.4970829095718, "Episode length": 999, "Policy Loss": 0.0008896570652723312, "Value Loss": 0.0014596343971788883, "_runtime": 1936.4676611423492, "_timestamp": 1585596685.4843347, "_step": 491}
{"Episode reward": -41.1648172605535, "Episode length": 999, "Policy Loss": -0.00030922723817639053, "Value Loss": 0.001483825035393238, "_runtime": 1938.0339095592499, "_timestamp": 1585596687.0505831, "_step": 492}
{"Episode reward": -41.4983350764431, "Episode length": 999, "Policy Loss": -0.00016964811948128045, "Value Loss": 0.0014122042339295149, "_runtime": 1939.5947787761688, "_timestamp": 1585596688.6114523, "_step": 493}
{"Episode reward": -41.301201854733655, "Episode length": 999, "Policy Loss": -0.001423044130206108, "Value Loss": 0.0014916947111487389, "_runtime": 1941.158991098404, "_timestamp": 1585596690.1756647, "_step": 494}
{"Episode reward": -40.68588450515013, "Episode length": 999, "Policy Loss": 0.00027919563581235707, "Value Loss": 0.001488174544647336, "_runtime": 1942.720885515213, "_timestamp": 1585596691.737559, "_step": 495}
{"Episode reward": -41.56647349713889, "Episode length": 999, "Policy Loss": -0.000543397618457675, "Value Loss": 0.0014517069794237614, "_runtime": 1944.2841143608093, "_timestamp": 1585596693.300788, "_step": 496}
{"Episode reward": -41.02724121953067, "Episode length": 999, "Policy Loss": -0.0004571056051645428, "Value Loss": 0.0014275062130764127, "_runtime": 1945.8485441207886, "_timestamp": 1585596694.8652177, "_step": 497}
{"Episode reward": -42.60583415241288, "Episode length": 999, "Policy Loss": -0.0034027150832116604, "Value Loss": 0.0014812577283009887, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613, -2.4390759468078613]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0], "bins": [-7.098688125610352, -6.951587200164795, -6.8044867515563965, -6.65738582611084, -6.510284900665283, -6.363183975219727, -6.216083526611328, -6.0689826011657715, -5.921881675720215, -5.774781227111816, -5.62768030166626, -5.480579376220703, -5.333478927612305, -5.186378002166748, -5.039277076721191, -4.892176151275635, -4.745075225830078, -4.59797477722168, -4.450873851776123, -4.303772926330566, -4.156672477722168, -4.009571552276611, -3.8624706268310547, -3.715369939804077, -3.5682692527770996, -3.421168327331543, -3.2740676403045654, -3.126966714859009, -2.9798660278320312, -2.8327651023864746, -2.685664176940918, -2.5385637283325195, -2.391462802886963, -2.2443618774414062, -2.097261428833008, -1.9501605033874512, -1.8030595779418945, -1.655958652496338, -1.5088582038879395, -1.3617572784423828, -1.2146563529968262, -1.0675559043884277, -0.9204549789428711, -0.7733540534973145, -0.6262531280517578, -0.4791526794433594, -0.33205175399780273, -0.1849508285522461, -0.037850379943847656, 0.10925054550170898, 0.2563514709472656, 0.40345239639282227, 0.5505528450012207, 0.6976537704467773, 0.844754695892334, 0.9918556213378906, 1.138956069946289, 1.2860565185546875, 1.4331579208374023, 1.5802583694458008, 1.7273597717285156, 1.874460220336914, 2.0215606689453125, 2.1686620712280273, 2.315762519836426]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.6914107799530029, -0.6704555153846741, -0.6495002508163452, -0.6285449862480164, -0.6075897216796875, -0.5866344571113586, -0.5656791925430298, -0.5447239279747009, -0.5237686634063721, -0.5028133988380432, -0.48185813426971436, -0.4609028697013855, -0.43994757533073425, -0.4189923107624054, -0.39803704619407654, -0.3770817816257477, -0.3561265170574188, -0.33517125248908997, -0.3142159879207611, -0.29326072335243225, -0.2723054587841034, -0.25135019421577454, -0.23039492964744568, -0.20943966507911682, -0.18848437070846558, -0.16752910614013672, -0.14657384157180786, -0.125618577003479, -0.10466331243515015, -0.08370804786682129, -0.06275278329849243, -0.041797518730163574, -0.020842254161834717, 0.00011301040649414062, 0.021068274974822998, 0.042023539543151855, 0.06297880411148071, 0.08393406867980957, 0.10488933324813843, 0.12584459781646729, 0.14679986238479614, 0.167755126953125, 0.18871039152145386, 0.20966565608978271, 0.23062092065811157, 0.25157618522644043, 0.2725314497947693, 0.29348671436309814, 0.3144420385360718, 0.33539724349975586, 0.3563525676727295, 0.3773077726364136, 0.3982630968093872, 0.4192183017730713, 0.4401736259460449, 0.461128830909729, 0.48208415508270264, 0.5030393600463867, 0.5239946842193604, 0.5449498891830444, 0.5659052133560181, 0.5868604183197021, 0.6078157424926758, 0.6287709474563599, 0.6497262716293335]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 8.0, 3.0, 5.0, 11.0, 9.0, 13.0, 21.0, 46.0, 142.0, 131.0, 37.0, 20.0, 10.0, 6.0, 6.0, 8.0, 2.0, 5.0, 3.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.794185996055603, -0.7701157927513123, -0.7460456490516663, -0.7219754457473755, -0.6979053020477295, -0.6738350987434387, -0.649764895439148, -0.625694751739502, -0.6016245484352112, -0.5775543451309204, -0.5534842014312744, -0.5294139981269836, -0.5053437948226929, -0.4812736511230469, -0.4572034478187561, -0.4331332743167877, -0.40906310081481934, -0.38499292731285095, -0.36092275381088257, -0.3368525505065918, -0.3127823770046234, -0.28871220350265503, -0.26464200019836426, -0.24057185649871826, -0.2165016531944275, -0.19243144989013672, -0.16836130619049072, -0.14429110288619995, -0.12022089958190918, -0.09615075588226318, -0.07208055257797241, -0.048010408878326416, -0.023940205574035645, 0.00012999773025512695, 0.024200141429901123, 0.048270344734191895, 0.07234048843383789, 0.09641069173812866, 0.12048089504241943, 0.14455103874206543, 0.1686212420463562, 0.19269144535064697, 0.21676158905029297, 0.24083173274993896, 0.2649019956588745, 0.2889721393585205, 0.3130422830581665, 0.33711254596710205, 0.36118268966674805, 0.38525283336639404, 0.4093230962753296, 0.4333932399749756, 0.4574633836746216, 0.48153364658355713, 0.5056037902832031, 0.5296739339828491, 0.5537441968917847, 0.5778143405914307, 0.6018844842910767, 0.6259546279907227, 0.6500248908996582, 0.6740950345993042, 0.6981651782989502, 0.7222354412078857, 0.7463055849075317]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0111478567123413, -0.9788382649421692, -0.9465286731719971, -0.9142190217971802, -0.8819094300270081, -0.8495998382568359, -0.8172902464866638, -0.7849806547164917, -0.7526710033416748, -0.7203614711761475, -0.6880518198013306, -0.6557422280311584, -0.6234326362609863, -0.5911229848861694, -0.5588134527206421, -0.5265038013458252, -0.4941942095756531, -0.46188461780548096, -0.42957502603530884, -0.39726537466049194, -0.3649557828903198, -0.3326461911201477, -0.3003365993499756, -0.26802700757980347, -0.23571741580963135, -0.20340776443481445, -0.17109817266464233, -0.13878858089447021, -0.1064789891242981, -0.07416939735412598, -0.04185974597930908, -0.009550213813781738, 0.022759437561035156, 0.05506908893585205, 0.0873786211013794, 0.11968827247619629, 0.15199780464172363, 0.18430745601654053, 0.21661710739135742, 0.24892663955688477, 0.28123629093170166, 0.313545823097229, 0.3458554744720459, 0.3781651258468628, 0.41047465801239014, 0.44278430938720703, 0.4750938415527344, 0.5074034929275513, 0.5397130250930786, 0.5720226764678955, 0.6043323278427124, 0.6366418600082397, 0.6689515113830566, 0.701261043548584, 0.7335706949234009, 0.7658803462982178, 0.7981898784637451, 0.830499529838562, 0.8628090620040894, 0.8951187133789062, 0.9274283647537231, 0.9597378969192505, 0.9920474290847778, 1.0243571996688843, 1.0566667318344116]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 8.0, 4.0, 9.0, 7.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.42237234115600586, -0.40947389602661133, -0.3965754508972168, -0.38367700576782227, -0.3707785904407501, -0.3578801453113556, -0.34498170018196106, -0.33208325505256653, -0.319184809923172, -0.30628639459609985, -0.2933879494667053, -0.2804895043373108, -0.26759105920791626, -0.25469261407852173, -0.2417941689491272, -0.22889573872089386, -0.21599729359149933, -0.2030988484621048, -0.19020041823387146, -0.17730197310447693, -0.1644035279750824, -0.15150508284568787, -0.13860663771629333, -0.1257082223892212, -0.11280977725982666, -0.09991133213043213, -0.0870128870010376, -0.07411444187164307, -0.061215996742248535, -0.04831758141517639, -0.03541913628578186, -0.02252069115638733, -0.009622246026992798, 0.0032761991024017334, 0.016174644231796265, 0.029073089361190796, 0.04197150468826294, 0.05486994981765747, 0.067768394947052, 0.08066684007644653, 0.09356528520584106, 0.1064637303352356, 0.11936217546463013, 0.13226062059402466, 0.1451590657234192, 0.15805745124816895, 0.17095589637756348, 0.183854341506958, 0.19675278663635254, 0.20965123176574707, 0.2225496768951416, 0.23544812202453613, 0.24834656715393066, 0.2612450122833252, 0.2741434574127197, 0.28704190254211426, 0.2999403476715088, 0.3128387928009033, 0.3257371783256531, 0.3386356234550476, 0.35153406858444214, 0.36443251371383667, 0.3773309588432312, 0.39022940397262573, 0.40312784910202026]}, "_runtime": 1947.412460565567, "_timestamp": 1585596696.4291341, "_step": 498}
{"Episode reward": -38.312245495115874, "Episode length": 999, "Policy Loss": 0.0038013923913240433, "Value Loss": 0.001380705158226192, "_runtime": 1947.412460565567, "_timestamp": 1585596696.4291341, "_step": 499}
