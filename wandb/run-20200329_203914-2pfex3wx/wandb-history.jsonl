{"Episode reward": -75.53356725149844, "Episode length": 999, "Policy Loss": -0.02738868072628975, "Value Loss": 0.02120429091155529, "_runtime": 5295.662933349609, "_timestamp": 1585514374.083663, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.958181381225586, "Value Loss": 86.44282531738281, "_runtime": 5297.19517993927, "_timestamp": 1585514375.6159096, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -95.36996459960938, "Value Loss": 1913.367919921875, "_runtime": 5298.7656173706055, "_timestamp": 1585514377.186347, "_step": 2}
{"Episode reward": -99.40254510938392, "Episode length": 999, "Policy Loss": -34.25584030151367, "Value Loss": 1067.0509033203125, "_runtime": 5300.311017751694, "_timestamp": 1585514378.7317474, "_step": 3}
{"Episode reward": -91.29571497872186, "Episode length": 999, "Policy Loss": 0.6079954504966736, "Value Loss": 67.1363525390625, "_runtime": 5301.835555076599, "_timestamp": 1585514380.2562847, "_step": 4}
{"Episode reward": -77.1711345329522, "Episode length": 999, "Policy Loss": -0.026781000196933746, "Value Loss": 25.57677459716797, "_runtime": 5303.404728651047, "_timestamp": 1585514381.8254583, "_step": 5}
{"Episode reward": -75.74315900234767, "Episode length": 999, "Policy Loss": -28.903432846069336, "Value Loss": 25932.892578125, "_runtime": 5304.958787202835, "_timestamp": 1585514383.3795168, "_step": 6}
{"Episode reward": -76.50679516050477, "Episode length": 999, "Policy Loss": 13.184428215026855, "Value Loss": 916.160400390625, "_runtime": 5306.4834768772125, "_timestamp": 1585514384.9042065, "_step": 7}
{"Episode reward": -76.84542575146654, "Episode length": 999, "Policy Loss": 105.31566619873047, "Value Loss": 17085.8125, "_runtime": 5308.046536207199, "_timestamp": 1585514386.4672658, "_step": 8}
{"Episode reward": -64.18716286322861, "Episode length": 999, "Policy Loss": -23.50227928161621, "Value Loss": 96038.453125, "_runtime": 5309.601179361343, "_timestamp": 1585514388.021909, "_step": 9}
{"Episode reward": -77.71114892560847, "Episode length": 999, "Policy Loss": 9.344313621520996, "Value Loss": 15382.55859375, "_runtime": 5311.128288984299, "_timestamp": 1585514389.5490186, "_step": 10}
{"Episode reward": -80.03826884393335, "Episode length": 999, "Policy Loss": 0.7657437920570374, "Value Loss": 678.1854858398438, "_runtime": 5312.69272518158, "_timestamp": 1585514391.1134548, "_step": 11}
{"Episode reward": -80.94692462641677, "Episode length": 999, "Policy Loss": -1.7728908061981201, "Value Loss": 79.83354949951172, "_runtime": 5314.258300065994, "_timestamp": 1585514392.6790297, "_step": 12}
{"Episode reward": -81.34628102180643, "Episode length": 999, "Policy Loss": -1.1822105646133423, "Value Loss": 37.51790237426758, "_runtime": 5315.797600746155, "_timestamp": 1585514394.2183304, "_step": 13}
{"Episode reward": -80.37098119383413, "Episode length": 999, "Policy Loss": -0.7134683728218079, "Value Loss": 4.109194755554199, "_runtime": 5317.368927240372, "_timestamp": 1585514395.7896569, "_step": 14}
{"Episode reward": -80.71408241916103, "Episode length": 999, "Policy Loss": -0.507003903388977, "Value Loss": 0.05485988408327103, "_runtime": 5318.938096046448, "_timestamp": 1585514397.3588257, "_step": 15}
{"Episode reward": -80.9458008234751, "Episode length": 999, "Policy Loss": -0.5459341406822205, "Value Loss": 0.06489697098731995, "_runtime": 5320.52781867981, "_timestamp": 1585514398.9485483, "_step": 16}
{"Episode reward": -80.75956944918934, "Episode length": 999, "Policy Loss": -0.6046739816665649, "Value Loss": 0.07504124194383621, "_runtime": 5322.097138404846, "_timestamp": 1585514400.517868, "_step": 17}
{"Episode reward": -80.7372451980636, "Episode length": 999, "Policy Loss": -0.6179297566413879, "Value Loss": 0.0849689245223999, "_runtime": 5323.666526317596, "_timestamp": 1585514402.087256, "_step": 18}
{"Episode reward": -78.56886677621094, "Episode length": 999, "Policy Loss": -0.6506236791610718, "Value Loss": 0.09321533888578415, "_runtime": 5325.221155643463, "_timestamp": 1585514403.6418853, "_step": 19}
{"Episode reward": -77.55207322419311, "Episode length": 999, "Policy Loss": -0.6429282426834106, "Value Loss": 0.10155599564313889, "_runtime": 5326.765216827393, "_timestamp": 1585514405.1859465, "_step": 20}
{"Episode reward": -76.71756715608113, "Episode length": 999, "Policy Loss": -0.664345383644104, "Value Loss": 0.10945265740156174, "_runtime": 5328.33468914032, "_timestamp": 1585514406.7554188, "_step": 21}
{"Episode reward": -77.30098172059479, "Episode length": 999, "Policy Loss": -0.6719855070114136, "Value Loss": 0.11772625893354416, "_runtime": 5329.880592107773, "_timestamp": 1585514408.3013217, "_step": 22}
{"Episode reward": -74.86951057844797, "Episode length": 999, "Policy Loss": -0.690295934677124, "Value Loss": 0.1234562024474144, "_runtime": 5331.437755346298, "_timestamp": 1585514409.858485, "_step": 23}
{"Episode reward": -73.7786326688829, "Episode length": 999, "Policy Loss": -0.6686052083969116, "Value Loss": 0.12944260239601135, "_runtime": 5333.000116586685, "_timestamp": 1585514411.4208462, "_step": 24}
{"Episode reward": -70.22965869637953, "Episode length": 999, "Policy Loss": -0.6387220025062561, "Value Loss": 0.13321609795093536, "_runtime": 5334.550808906555, "_timestamp": 1585514412.9715385, "_step": 25}
{"Episode reward": -68.26940452499815, "Episode length": 999, "Policy Loss": -0.6160032153129578, "Value Loss": 0.1374431699514389, "_runtime": 5336.114157438278, "_timestamp": 1585514414.534887, "_step": 26}
{"Episode reward": -70.00835285515268, "Episode length": 999, "Policy Loss": -0.6535640954971313, "Value Loss": 0.1438031792640686, "_runtime": 5337.6829879283905, "_timestamp": 1585514416.1037176, "_step": 27}
{"Episode reward": -67.71366678155158, "Episode length": 999, "Policy Loss": -0.6353766918182373, "Value Loss": 0.14683671295642853, "_runtime": 5339.245163440704, "_timestamp": 1585514417.665893, "_step": 28}
{"Episode reward": -67.88366339348015, "Episode length": 999, "Policy Loss": -0.6480333805084229, "Value Loss": 0.15109200775623322, "_runtime": 5340.80899310112, "_timestamp": 1585514419.2297227, "_step": 29}
{"Episode reward": -64.23328298475215, "Episode length": 999, "Policy Loss": -0.6313856244087219, "Value Loss": 0.15215535461902618, "_runtime": 5342.375397443771, "_timestamp": 1585514420.796127, "_step": 30}
{"Episode reward": -65.44145555705924, "Episode length": 999, "Policy Loss": -0.6404045224189758, "Value Loss": 0.15641145408153534, "_runtime": 5343.949069738388, "_timestamp": 1585514422.3697994, "_step": 31}
{"Episode reward": -64.7795369369735, "Episode length": 999, "Policy Loss": -0.6361574530601501, "Value Loss": 0.15891090035438538, "_runtime": 5345.504341840744, "_timestamp": 1585514423.9250715, "_step": 32}
{"Episode reward": -65.27876265032805, "Episode length": 999, "Policy Loss": -0.6629900336265564, "Value Loss": 0.16191405057907104, "_runtime": 5347.07440161705, "_timestamp": 1585514425.4951313, "_step": 33}
{"Episode reward": -63.27188589070829, "Episode length": 999, "Policy Loss": -0.6265875101089478, "Value Loss": 0.16265304386615753, "_runtime": 5348.63525223732, "_timestamp": 1585514427.0559819, "_step": 34}
{"Episode reward": -62.812190438074396, "Episode length": 999, "Policy Loss": -0.6329391002655029, "Value Loss": 0.1645500510931015, "_runtime": 5350.202154636383, "_timestamp": 1585514428.6228843, "_step": 35}
{"Episode reward": -62.34666649496, "Episode length": 999, "Policy Loss": -0.6074154376983643, "Value Loss": 0.1656026989221573, "_runtime": 5351.771502494812, "_timestamp": 1585514430.1922321, "_step": 36}
{"Episode reward": -60.96497903943128, "Episode length": 999, "Policy Loss": -0.6371119618415833, "Value Loss": 0.1659345179796219, "_runtime": 5353.324155092239, "_timestamp": 1585514431.7448847, "_step": 37}
{"Episode reward": -60.00623758487961, "Episode length": 999, "Policy Loss": -0.6037289500236511, "Value Loss": 0.16636908054351807, "_runtime": 5354.879525899887, "_timestamp": 1585514433.3002555, "_step": 38}
{"Episode reward": -60.073482817039555, "Episode length": 999, "Policy Loss": -0.6160064935684204, "Value Loss": 0.1674596071243286, "_runtime": 5356.447576999664, "_timestamp": 1585514434.8683066, "_step": 39}
{"Episode reward": -62.403404262877515, "Episode length": 999, "Policy Loss": -0.6062847375869751, "Value Loss": 0.17004746198654175, "_runtime": 5358.004832744598, "_timestamp": 1585514436.4255624, "_step": 40}
{"Episode reward": -59.951330631369544, "Episode length": 999, "Policy Loss": -0.6142681241035461, "Value Loss": 0.16857348382472992, "_runtime": 5359.570576667786, "_timestamp": 1585514437.9913063, "_step": 41}
{"Episode reward": -58.01547316313216, "Episode length": 999, "Policy Loss": -0.591152548789978, "Value Loss": 0.16743142902851105, "_runtime": 5361.138111591339, "_timestamp": 1585514439.5588412, "_step": 42}
{"Episode reward": -59.24675186715161, "Episode length": 999, "Policy Loss": -0.5845123529434204, "Value Loss": 0.16979674994945526, "_runtime": 5362.699843406677, "_timestamp": 1585514441.120573, "_step": 43}
{"Episode reward": -58.19975400794119, "Episode length": 999, "Policy Loss": -0.5921773910522461, "Value Loss": 0.16788631677627563, "_runtime": 5364.266361236572, "_timestamp": 1585514442.6870909, "_step": 44}
{"Episode reward": -59.17268788995193, "Episode length": 999, "Policy Loss": -0.6090068817138672, "Value Loss": 0.1686905026435852, "_runtime": 5365.812289953232, "_timestamp": 1585514444.2330196, "_step": 45}
{"Episode reward": -59.23326939061339, "Episode length": 999, "Policy Loss": -0.610144317150116, "Value Loss": 0.16844579577445984, "_runtime": 5367.387283086777, "_timestamp": 1585514445.8080127, "_step": 46}
{"Episode reward": -58.722428559854706, "Episode length": 999, "Policy Loss": -0.5896349549293518, "Value Loss": 0.16898541152477264, "_runtime": 5368.949523448944, "_timestamp": 1585514447.370253, "_step": 47}
{"Episode reward": -60.6463738403297, "Episode length": 999, "Policy Loss": -0.6134194731712341, "Value Loss": 0.16892746090888977, "_runtime": 5370.505164146423, "_timestamp": 1585514448.9258938, "_step": 48}
{"Episode reward": -58.20738188953127, "Episode length": 999, "Policy Loss": -0.5915916562080383, "Value Loss": 0.16644428670406342, "_runtime": 5372.0638880729675, "_timestamp": 1585514450.4846177, "_step": 49}
{"Episode reward": -56.492676755148565, "Episode length": 999, "Policy Loss": -0.589113712310791, "Value Loss": 0.1644972413778305, "_runtime": 5373.627906084061, "_timestamp": 1585514452.0486357, "_step": 50}
{"Episode reward": -56.85204682966151, "Episode length": 999, "Policy Loss": -0.5713493824005127, "Value Loss": 0.1641189008951187, "_runtime": 5375.181932687759, "_timestamp": 1585514453.6026623, "_step": 51}
{"Episode reward": -59.68186069343616, "Episode length": 999, "Policy Loss": -0.6169535517692566, "Value Loss": 0.17379692196846008, "_runtime": 5376.719826936722, "_timestamp": 1585514455.1405566, "_step": 52}
{"Episode reward": -57.44198660586909, "Episode length": 999, "Policy Loss": -0.5571634769439697, "Value Loss": 0.27145084738731384, "_runtime": 5378.274025440216, "_timestamp": 1585514456.694755, "_step": 53}
{"Episode reward": -55.46255822074894, "Episode length": 999, "Policy Loss": -0.5478963255882263, "Value Loss": 0.1605364829301834, "_runtime": 5379.855427742004, "_timestamp": 1585514458.2761574, "_step": 54}
{"Episode reward": -58.81155634523915, "Episode length": 999, "Policy Loss": -0.6046667098999023, "Value Loss": 0.16230686008930206, "_runtime": 5381.41185426712, "_timestamp": 1585514459.832584, "_step": 55}
{"Episode reward": -55.50516303102553, "Episode length": 999, "Policy Loss": -0.5546747446060181, "Value Loss": 0.15864640474319458, "_runtime": 5382.961290597916, "_timestamp": 1585514461.3820202, "_step": 56}
{"Episode reward": -58.323707676463314, "Episode length": 999, "Policy Loss": -0.5928423404693604, "Value Loss": 0.1598854809999466, "_runtime": 5384.513605356216, "_timestamp": 1585514462.934335, "_step": 57}
{"Episode reward": -56.77284598646311, "Episode length": 999, "Policy Loss": -0.5545763373374939, "Value Loss": 0.15755978226661682, "_runtime": 5386.06299161911, "_timestamp": 1585514464.4837213, "_step": 58}
{"Episode reward": -58.54619467816607, "Episode length": 999, "Policy Loss": -0.558966875076294, "Value Loss": 0.15784047544002533, "_runtime": 5387.611437320709, "_timestamp": 1585514466.032167, "_step": 59}
{"Episode reward": -57.355893092460214, "Episode length": 999, "Policy Loss": -0.5749272704124451, "Value Loss": 0.15584959089756012, "_runtime": 5389.2012774944305, "_timestamp": 1585514467.6220071, "_step": 60}
{"Episode reward": -56.24903624905633, "Episode length": 999, "Policy Loss": -0.5534210801124573, "Value Loss": 0.1537727266550064, "_runtime": 5390.736596107483, "_timestamp": 1585514469.1573257, "_step": 61}
{"Episode reward": -58.522283325941295, "Episode length": 999, "Policy Loss": -0.5655396580696106, "Value Loss": 0.1543576568365097, "_runtime": 5392.303645849228, "_timestamp": 1585514470.7243755, "_step": 62}
{"Episode reward": -54.35507386894295, "Episode length": 999, "Policy Loss": -0.548355221748352, "Value Loss": 0.15000423789024353, "_runtime": 5393.861523628235, "_timestamp": 1585514472.2822533, "_step": 63}
{"Episode reward": -57.26910156047739, "Episode length": 999, "Policy Loss": -0.5617803335189819, "Value Loss": 0.15092898905277252, "_runtime": 5395.426242113113, "_timestamp": 1585514473.8469718, "_step": 64}
{"Episode reward": -58.85963803004853, "Episode length": 999, "Policy Loss": -0.5728434324264526, "Value Loss": 0.1509436070919037, "_runtime": 5396.99001288414, "_timestamp": 1585514475.4107425, "_step": 65}
{"Episode reward": -55.162948158599285, "Episode length": 999, "Policy Loss": -0.5162827372550964, "Value Loss": 0.14680896699428558, "_runtime": 5398.560663700104, "_timestamp": 1585514476.9813933, "_step": 66}
{"Episode reward": -54.776638918260204, "Episode length": 999, "Policy Loss": -0.5296187996864319, "Value Loss": 0.1452496349811554, "_runtime": 5400.1223430633545, "_timestamp": 1585514478.5430727, "_step": 67}
{"Episode reward": -56.069472184750865, "Episode length": 999, "Policy Loss": -0.532856285572052, "Value Loss": 0.14497165381908417, "_runtime": 5401.6871173381805, "_timestamp": 1585514480.107847, "_step": 68}
{"Episode reward": -56.153375307613814, "Episode length": 999, "Policy Loss": -0.5225756764411926, "Value Loss": 0.14365234971046448, "_runtime": 5403.255134344101, "_timestamp": 1585514481.675864, "_step": 69}
{"Episode reward": -58.03344346934243, "Episode length": 999, "Policy Loss": -0.5399314761161804, "Value Loss": 0.14378279447555542, "_runtime": 5404.808817148209, "_timestamp": 1585514483.2295468, "_step": 70}
{"Episode reward": -56.20321392235, "Episode length": 999, "Policy Loss": -0.5214902758598328, "Value Loss": 0.14119096100330353, "_runtime": 5406.376361131668, "_timestamp": 1585514484.7970908, "_step": 71}
{"Episode reward": -54.68430247636376, "Episode length": 999, "Policy Loss": -0.5141463279724121, "Value Loss": 0.13869309425354004, "_runtime": 5407.9365084171295, "_timestamp": 1585514486.357238, "_step": 72}
{"Episode reward": -57.21127960258757, "Episode length": 999, "Policy Loss": -0.5402308106422424, "Value Loss": 0.13925588130950928, "_runtime": 5409.497164487839, "_timestamp": 1585514487.9178941, "_step": 73}
{"Episode reward": -56.68509975981444, "Episode length": 999, "Policy Loss": -0.5223963856697083, "Value Loss": 0.13752855360507965, "_runtime": 5411.062652826309, "_timestamp": 1585514489.4833825, "_step": 74}
{"Episode reward": -56.55636277776734, "Episode length": 999, "Policy Loss": -0.5196084976196289, "Value Loss": 0.13613511621952057, "_runtime": 5412.665422439575, "_timestamp": 1585514491.086152, "_step": 75}
{"Episode reward": -54.430722327671496, "Episode length": 999, "Policy Loss": -0.5034849643707275, "Value Loss": 0.1331813484430313, "_runtime": 5414.218514442444, "_timestamp": 1585514492.639244, "_step": 76}
{"Episode reward": -54.17464212767374, "Episode length": 999, "Policy Loss": -0.4912036657333374, "Value Loss": 0.13170616328716278, "_runtime": 5415.774131774902, "_timestamp": 1585514494.1948614, "_step": 77}
{"Episode reward": -56.56828000519889, "Episode length": 999, "Policy Loss": -0.506646454334259, "Value Loss": 0.1320747584104538, "_runtime": 5417.343908548355, "_timestamp": 1585514495.7646382, "_step": 78}
{"Episode reward": -55.239100111323985, "Episode length": 999, "Policy Loss": -0.49581626057624817, "Value Loss": 0.12975116074085236, "_runtime": 5418.906083345413, "_timestamp": 1585514497.326813, "_step": 79}
{"Episode reward": -56.633872717902605, "Episode length": 999, "Policy Loss": -0.5004642009735107, "Value Loss": 0.12943537533283234, "_runtime": 5420.472609996796, "_timestamp": 1585514498.8933396, "_step": 80}
{"Episode reward": -52.540081285427085, "Episode length": 999, "Policy Loss": -0.4717719852924347, "Value Loss": 0.12522800266742706, "_runtime": 5422.02890586853, "_timestamp": 1585514500.4496355, "_step": 81}
{"Episode reward": -55.06786601085362, "Episode length": 999, "Policy Loss": -0.49195247888565063, "Value Loss": 0.12571033835411072, "_runtime": 5423.5906591415405, "_timestamp": 1585514502.0113888, "_step": 82}
{"Episode reward": -55.48807043316303, "Episode length": 999, "Policy Loss": -0.4833838641643524, "Value Loss": 0.12471091747283936, "_runtime": 5425.156978368759, "_timestamp": 1585514503.577708, "_step": 83}
{"Episode reward": -56.266601754262865, "Episode length": 999, "Policy Loss": -0.49660027027130127, "Value Loss": 0.1239638552069664, "_runtime": 5426.72207570076, "_timestamp": 1585514505.1428053, "_step": 84}
{"Episode reward": -58.220396606359806, "Episode length": 999, "Policy Loss": -0.5252258777618408, "Value Loss": 0.1239912211894989, "_runtime": 5428.285515069962, "_timestamp": 1585514506.7062447, "_step": 85}
{"Episode reward": -57.37240278346654, "Episode length": 999, "Policy Loss": -0.5046546459197998, "Value Loss": 0.1220281645655632, "_runtime": 5429.8492748737335, "_timestamp": 1585514508.2700045, "_step": 86}
{"Episode reward": -56.301875593518794, "Episode length": 999, "Policy Loss": -0.48880672454833984, "Value Loss": 0.1200074553489685, "_runtime": 5431.4153661727905, "_timestamp": 1585514509.8360958, "_step": 87}
{"Episode reward": -58.245786508833646, "Episode length": 999, "Policy Loss": -0.5072615146636963, "Value Loss": 0.12001853436231613, "_runtime": 5432.969096660614, "_timestamp": 1585514511.3898263, "_step": 88}
{"Episode reward": -55.01321753396189, "Episode length": 999, "Policy Loss": -0.4713166058063507, "Value Loss": 0.11657465994358063, "_runtime": 5434.533188819885, "_timestamp": 1585514512.9539185, "_step": 89}
{"Episode reward": -56.48060900805939, "Episode length": 999, "Policy Loss": -0.47963958978652954, "Value Loss": 0.11623987555503845, "_runtime": 5436.136625051498, "_timestamp": 1585514514.5573547, "_step": 90}
{"Episode reward": -56.92897846357792, "Episode length": 999, "Policy Loss": -0.48686325550079346, "Value Loss": 0.11523138731718063, "_runtime": 5437.699637174606, "_timestamp": 1585514516.1203668, "_step": 91}
{"Episode reward": -55.70110013059763, "Episode length": 999, "Policy Loss": -0.4780818223953247, "Value Loss": 0.11317914724349976, "_runtime": 5439.252080440521, "_timestamp": 1585514517.67281, "_step": 92}
{"Episode reward": -57.805603477067514, "Episode length": 999, "Policy Loss": -0.48587673902511597, "Value Loss": 0.11326200515031815, "_runtime": 5440.819222688675, "_timestamp": 1585514519.2399523, "_step": 93}
{"Episode reward": -54.997551772231326, "Episode length": 999, "Policy Loss": -0.4552837014198303, "Value Loss": 0.11010169237852097, "_runtime": 5442.382956266403, "_timestamp": 1585514520.803686, "_step": 94}
{"Episode reward": -55.786558881525934, "Episode length": 999, "Policy Loss": -0.4560278058052063, "Value Loss": 0.10937807708978653, "_runtime": 5443.925920248032, "_timestamp": 1585514522.34665, "_step": 95}
{"Episode reward": -55.451731592340515, "Episode length": 999, "Policy Loss": -0.46998804807662964, "Value Loss": 0.10796662420034409, "_runtime": 5445.483047246933, "_timestamp": 1585514523.903777, "_step": 96}
{"Episode reward": -57.33292946438856, "Episode length": 999, "Policy Loss": -0.4642602503299713, "Value Loss": 0.10793104022741318, "_runtime": 5447.0358102321625, "_timestamp": 1585514525.4565399, "_step": 97}
{"Episode reward": -53.99419440048029, "Episode length": 999, "Policy Loss": -0.43531492352485657, "Value Loss": 0.10452312231063843, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934, 10.103575706481934]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-10.102413177490234, -9.460376739501953, -8.818341255187988, -8.176305770874023, -7.534269332885742, -6.892233371734619, -6.250197410583496, -5.608161449432373, -4.96612548828125, -4.324089527130127, -3.682053565979004, -3.040017604827881, -2.397981643676758, -1.7559452056884766, -1.1139097213745117, -0.4718742370605469, 0.17016220092773438, 0.8121986389160156, 1.4542341232299805, 2.0962696075439453, 2.7383060455322266, 3.380342483520508, 4.022377967834473, 4.6644134521484375, 5.306449890136719, 5.948486328125, 6.590522766113281, 7.23255729675293, 7.874593734741211, 8.516630172729492, 9.15866470336914, 9.800701141357422, 10.442737579345703, 11.084774017333984, 11.726810455322266, 12.368844985961914, 13.010881423950195, 13.652917861938477, 14.294952392578125, 14.936988830566406, 15.579025268554688, 16.22106170654297, 16.86309814453125, 17.5051326751709, 18.14716911315918, 18.78920555114746, 19.43124008178711, 20.07327651977539, 20.715312957763672, 21.357349395751953, 21.999385833740234, 22.641422271728516, 23.283458709716797, 23.925491333007812, 24.567527770996094, 25.209564208984375, 25.851600646972656, 26.493637084960938, 27.13567352294922, 27.7777099609375, 28.419742584228516, 29.061779022216797, 29.703815460205078, 30.34585189819336, 30.98788833618164]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0], "bins": [-8.626139640808105, -8.47257137298584, -8.319002151489258, -8.165433883666992, -8.01186466217041, -7.858295917510986, -7.7047271728515625, -7.551158905029297, -7.397589683532715, -7.244021415710449, -7.090452194213867, -6.936883926391602, -6.783315181732178, -6.629746437072754, -6.47617769241333, -6.322608947753906, -6.169040203094482, -6.015471458435059, -5.861902713775635, -5.708333969116211, -5.554765224456787, -5.401196479797363, -5.247628211975098, -5.094058990478516, -4.94049072265625, -4.786921501159668, -4.633353233337402, -4.4797844886779785, -4.326215744018555, -4.172646999359131, -4.019078254699707, -3.865509510040283, -3.7119407653808594, -3.5583720207214355, -3.4048032760620117, -3.251234531402588, -3.097665786743164, -2.9440970420837402, -2.7905282974243164, -2.6369595527648926, -2.4833908081054688, -2.329822540283203, -2.1762537956237793, -2.0226850509643555, -1.8691163063049316, -1.7155475616455078, -1.561978816986084, -1.4084100723266602, -1.2548413276672363, -1.1012725830078125, -0.9477038383483887, -0.7941350936889648, -0.640566349029541, -0.4869976043701172, -0.33342933654785156, -0.17986011505126953, -0.026291847229003906, 0.12727737426757812, 0.28084564208984375, 0.4344148635864258, 0.5879831314086914, 0.7415523529052734, 0.8951206207275391, 1.048689842224121, 1.2022581100463867]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 2.0, 2.0, 7.0, 4.0, 5.0, 7.0, 11.0, 23.0, 65.0, 235.0, 29.0, 23.0, 23.0, 15.0, 13.0, 6.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-9.47990608215332, -9.220327377319336, -8.960748672485352, -8.70116901397705, -8.441590309143066, -8.182011604309082, -7.9224324226379395, -7.662853240966797, -7.4032745361328125, -7.143695831298828, -6.8841166496276855, -6.624537467956543, -6.364958763122559, -6.105380058288574, -5.845800876617432, -5.586221694946289, -5.326642990112305, -5.06706428527832, -4.807485103607178, -4.547905921936035, -4.288327217102051, -4.028748512268066, -3.769169330596924, -3.5095901489257812, -3.250011444091797, -2.9904327392578125, -2.73085355758667, -2.4712743759155273, -2.211695671081543, -1.9521169662475586, -1.692537784576416, -1.4329586029052734, -1.173379898071289, -0.9138011932373047, -0.6542224884033203, -0.39464282989501953, -0.13506412506103516, 0.12451457977294922, 0.38409423828125, 0.6436729431152344, 0.9032516479492188, 1.1628303527832031, 1.4224090576171875, 1.6819887161254883, 1.9415674209594727, 2.201146125793457, 2.460725784301758, 2.720304489135742, 2.9798831939697266, 3.239461898803711, 3.4990406036376953, 3.758620262145996, 4.0181989669799805, 4.277777671813965, 4.537357330322266, 4.79693603515625, 5.056514739990234, 5.316093444824219, 5.575672149658203, 5.835251808166504, 6.094830513000488, 6.354409217834473, 6.613988876342773, 6.873567581176758, 7.133146286010742]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-17.19452667236328, -16.70394515991211, -16.21336555480957, -15.722784996032715, -15.23220443725586, -14.741622924804688, -14.251043319702148, -13.760461807250977, -13.269881248474121, -12.779300689697266, -12.28872013092041, -11.798139572143555, -11.3075590133667, -10.816978454589844, -10.326396942138672, -9.835817337036133, -9.345235824584961, -8.854655265808105, -8.36407470703125, -7.8734941482543945, -7.382913589477539, -6.892333030700684, -6.401752471923828, -5.911171913146973, -5.420591354370117, -4.930010795593262, -4.439430236816406, -3.9488487243652344, -3.458268165588379, -2.9676876068115234, -2.477107048034668, -1.9865264892578125, -1.495945930480957, -1.0053653717041016, -0.5147838592529297, -0.024204254150390625, 0.46637725830078125, 0.9569568634033203, 1.4475383758544922, 1.9381179809570312, 2.428699493408203, 2.919279098510742, 3.409860610961914, 3.900442123413086, 4.391021728515625, 4.881603240966797, 5.372182846069336, 5.862764358520508, 6.353343963623047, 6.843925476074219, 7.334505081176758, 7.82508659362793, 8.315666198730469, 8.80624771118164, 9.296829223632812, 9.787408828735352, 10.277990341186523, 10.768569946289062, 11.259151458740234, 11.749731063842773, 12.240312576293945, 12.730892181396484, 13.221473693847656, 13.712053298950195, 14.202634811401367]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 6.0, 10.0, 11.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-4.091400623321533, -3.9501290321350098, -3.8088574409484863, -3.667585611343384, -3.5263140201568604, -3.385042428970337, -3.2437705993652344, -3.102499008178711, -2.9612274169921875, -2.819955825805664, -2.6786842346191406, -2.537412405014038, -2.3961408138275146, -2.254869222640991, -2.1135973930358887, -1.9723258018493652, -1.8310542106628418, -1.6897826194763184, -1.548511028289795, -1.4072391986846924, -1.265967607498169, -1.1246960163116455, -0.983424186706543, -0.8421525955200195, -0.7008810043334961, -0.5596094131469727, -0.4183378219604492, -0.2770659923553467, -0.13579440116882324, 0.005477428436279297, 0.14674901962280273, 0.28802061080932617, 0.4292922019958496, 0.570563793182373, 0.7118353843688965, 0.8531069755554199, 0.9943785667419434, 1.135650634765625, 1.2769222259521484, 1.4181938171386719, 1.5594654083251953, 1.7007369995117188, 1.8420085906982422, 1.9832801818847656, 2.1245522499084473, 2.2658238410949707, 2.407095432281494, 2.5483670234680176, 2.689638614654541, 2.8309102058410645, 2.972181797027588, 3.1134533882141113, 3.2547249794006348, 3.3959970474243164, 3.53726863861084, 3.6785402297973633, 3.8198118209838867, 3.9610838890075684, 4.102355480194092, 4.243627071380615, 4.384898662567139, 4.526170253753662, 4.6674418449401855, 4.808713436126709, 4.949985027313232]}, "_runtime": 5448.590180635452, "_timestamp": 1585514527.0109103, "_step": 98}
{"Episode reward": -53.43998589058397, "Episode length": 999, "Policy Loss": -0.4227783977985382, "Value Loss": 0.10295680910348892, "_runtime": 5450.147047996521, "_timestamp": 1585514528.5677776, "_step": 99}
{"Episode reward": -57.52546652194691, "Episode length": 999, "Policy Loss": -0.44994235038757324, "Value Loss": 0.10438080877065659, "_runtime": 5451.71271109581, "_timestamp": 1585514530.1334407, "_step": 100}
{"Episode reward": -56.17287681517574, "Episode length": 999, "Policy Loss": -0.44689154624938965, "Value Loss": 0.10228534042835236, "_runtime": 5453.280166864395, "_timestamp": 1585514531.7008965, "_step": 101}
{"Episode reward": -56.23721535469888, "Episode length": 999, "Policy Loss": -0.43181148171424866, "Value Loss": 0.1011282429099083, "_runtime": 5454.83180141449, "_timestamp": 1585514533.252531, "_step": 102}
{"Episode reward": -55.73160930096216, "Episode length": 999, "Policy Loss": -0.42915043234825134, "Value Loss": 0.0995943546295166, "_runtime": 5456.3963186740875, "_timestamp": 1585514534.8170483, "_step": 103}
{"Episode reward": -54.790654449593596, "Episode length": 999, "Policy Loss": -0.4216863214969635, "Value Loss": 0.09780896455049515, "_runtime": 5457.948602676392, "_timestamp": 1585514536.3693323, "_step": 104}
{"Episode reward": -54.54652629269018, "Episode length": 999, "Policy Loss": -0.42377230525016785, "Value Loss": 0.09651245176792145, "_runtime": 5459.549734830856, "_timestamp": 1585514537.9704645, "_step": 105}
{"Episode reward": -53.854478608095235, "Episode length": 999, "Policy Loss": -0.4190390110015869, "Value Loss": 0.09490452706813812, "_runtime": 5461.109032154083, "_timestamp": 1585514539.5297618, "_step": 106}
{"Episode reward": -55.61312050454522, "Episode length": 999, "Policy Loss": -0.43189266324043274, "Value Loss": 0.0948169156908989, "_runtime": 5462.6717846393585, "_timestamp": 1585514541.0925143, "_step": 107}
{"Episode reward": -55.3789264099498, "Episode length": 999, "Policy Loss": -0.41461166739463806, "Value Loss": 0.09353099018335342, "_runtime": 5464.235146999359, "_timestamp": 1585514542.6558766, "_step": 108}
{"Episode reward": -57.07424722558231, "Episode length": 999, "Policy Loss": -0.442702054977417, "Value Loss": 0.09338344633579254, "_runtime": 5465.796235322952, "_timestamp": 1585514544.216965, "_step": 109}
{"Episode reward": -55.02318131659887, "Episode length": 999, "Policy Loss": -0.4155885875225067, "Value Loss": 0.09109777212142944, "_runtime": 5467.3593163490295, "_timestamp": 1585514545.780046, "_step": 110}
{"Episode reward": -55.4437315061722, "Episode length": 999, "Policy Loss": -0.41895925998687744, "Value Loss": 0.09019201993942261, "_runtime": 5468.920526742935, "_timestamp": 1585514547.3412564, "_step": 111}
{"Episode reward": -56.990028081504626, "Episode length": 999, "Policy Loss": -0.42715951800346375, "Value Loss": 0.0899527296423912, "_runtime": 5470.483275175095, "_timestamp": 1585514548.9040048, "_step": 112}
{"Episode reward": -56.33230870497503, "Episode length": 999, "Policy Loss": -0.41320616006851196, "Value Loss": 0.08845189958810806, "_runtime": 5472.035039186478, "_timestamp": 1585514550.4557688, "_step": 113}
{"Episode reward": -54.77517726684097, "Episode length": 999, "Policy Loss": -0.3973987400531769, "Value Loss": 0.08643922209739685, "_runtime": 5473.59934258461, "_timestamp": 1585514552.0200722, "_step": 114}
{"Episode reward": -58.24854763913395, "Episode length": 999, "Policy Loss": -0.4129907786846161, "Value Loss": 0.08736607432365417, "_runtime": 5475.161372661591, "_timestamp": 1585514553.5821023, "_step": 115}
{"Episode reward": -54.10611205411643, "Episode length": 999, "Policy Loss": -0.38123980164527893, "Value Loss": 0.08390095084905624, "_runtime": 5476.724304199219, "_timestamp": 1585514555.1450338, "_step": 116}
{"Episode reward": -55.471477082577415, "Episode length": 999, "Policy Loss": -0.4082990288734436, "Value Loss": 0.083626888692379, "_runtime": 5478.286429405212, "_timestamp": 1585514556.707159, "_step": 117}
{"Episode reward": -59.303811405621786, "Episode length": 999, "Policy Loss": -0.41474103927612305, "Value Loss": 0.08472481369972229, "_runtime": 5479.845941781998, "_timestamp": 1585514558.2666714, "_step": 118}
{"Episode reward": -56.204150189931696, "Episode length": 999, "Policy Loss": -0.3939659297466278, "Value Loss": 0.08189918100833893, "_runtime": 5481.444139003754, "_timestamp": 1585514559.8648686, "_step": 119}
{"Episode reward": -55.69353076968236, "Episode length": 999, "Policy Loss": -0.4014906883239746, "Value Loss": 0.0805908739566803, "_runtime": 5482.996249675751, "_timestamp": 1585514561.4169793, "_step": 120}
{"Episode reward": -55.1835974085122, "Episode length": 999, "Policy Loss": -0.39035356044769287, "Value Loss": 0.07923451066017151, "_runtime": 5484.568678855896, "_timestamp": 1585514562.9894085, "_step": 121}
{"Episode reward": -53.398764203807595, "Episode length": 999, "Policy Loss": -0.37913399934768677, "Value Loss": 0.07728282362222672, "_runtime": 5486.137145519257, "_timestamp": 1585514564.5578752, "_step": 122}
{"Episode reward": -54.66131689989518, "Episode length": 999, "Policy Loss": -0.3789866864681244, "Value Loss": 0.0769602358341217, "_runtime": 5487.710171461105, "_timestamp": 1585514566.130901, "_step": 123}
{"Episode reward": -57.31299052491708, "Episode length": 999, "Policy Loss": -0.3901429772377014, "Value Loss": 0.07739537954330444, "_runtime": 5489.281561613083, "_timestamp": 1585514567.7022913, "_step": 124}
{"Episode reward": -53.92752034867051, "Episode length": 999, "Policy Loss": -0.3748122453689575, "Value Loss": 0.0745524987578392, "_runtime": 5490.853820800781, "_timestamp": 1585514569.2745504, "_step": 125}
{"Episode reward": -55.96840174404233, "Episode length": 999, "Policy Loss": -0.3706710934638977, "Value Loss": 0.07467024028301239, "_runtime": 5492.420476198196, "_timestamp": 1585514570.8412058, "_step": 126}
{"Episode reward": -53.714998917885694, "Episode length": 999, "Policy Loss": -0.3711986243724823, "Value Loss": 0.07244262099266052, "_runtime": 5493.980379104614, "_timestamp": 1585514572.4011087, "_step": 127}
{"Episode reward": -54.1488229407259, "Episode length": 999, "Policy Loss": -0.36189180612564087, "Value Loss": 0.07171893119812012, "_runtime": 5495.549030303955, "_timestamp": 1585514573.96976, "_step": 128}
{"Episode reward": -54.41306781137058, "Episode length": 999, "Policy Loss": -0.35853564739227295, "Value Loss": 0.07096527516841888, "_runtime": 5497.120341539383, "_timestamp": 1585514575.5410712, "_step": 129}
{"Episode reward": -56.02962586052712, "Episode length": 999, "Policy Loss": -0.3767649531364441, "Value Loss": 0.07086029648780823, "_runtime": 5498.690308570862, "_timestamp": 1585514577.1110382, "_step": 130}
{"Episode reward": -53.74796245434822, "Episode length": 999, "Policy Loss": -0.36126798391342163, "Value Loss": 0.06873154640197754, "_runtime": 5500.252819299698, "_timestamp": 1585514578.673549, "_step": 131}
{"Episode reward": -53.50769498184885, "Episode length": 999, "Policy Loss": -0.35739341378211975, "Value Loss": 0.06764275580644608, "_runtime": 5501.820729494095, "_timestamp": 1585514580.2414591, "_step": 132}
{"Episode reward": -52.46707402177045, "Episode length": 999, "Policy Loss": -0.34101393818855286, "Value Loss": 0.06620751321315765, "_runtime": 5503.374316692352, "_timestamp": 1585514581.7950463, "_step": 133}
{"Episode reward": -53.57838973076157, "Episode length": 999, "Policy Loss": -0.3479304611682892, "Value Loss": 0.06588558852672577, "_runtime": 5504.9520699977875, "_timestamp": 1585514583.3727996, "_step": 134}
{"Episode reward": -53.11405856812182, "Episode length": 999, "Policy Loss": -0.33499908447265625, "Value Loss": 0.06468110531568527, "_runtime": 5506.501845121384, "_timestamp": 1585514584.9225748, "_step": 135}
{"Episode reward": -52.63227397269912, "Episode length": 999, "Policy Loss": -0.34201762080192566, "Value Loss": 0.0635870024561882, "_runtime": 5508.0771679878235, "_timestamp": 1585514586.4978976, "_step": 136}
{"Episode reward": -53.18376120463982, "Episode length": 999, "Policy Loss": -0.33158764243125916, "Value Loss": 0.06297925859689713, "_runtime": 5509.642976760864, "_timestamp": 1585514588.0637064, "_step": 137}
{"Episode reward": -53.83144415248329, "Episode length": 999, "Policy Loss": -0.31756478548049927, "Value Loss": 0.06240696832537651, "_runtime": 5511.202852487564, "_timestamp": 1585514589.6235821, "_step": 138}
{"Episode reward": -52.955869695638626, "Episode length": 999, "Policy Loss": -0.3286292850971222, "Value Loss": 0.061156027019023895, "_runtime": 5512.763645410538, "_timestamp": 1585514591.184375, "_step": 139}
{"Episode reward": -55.9139262295134, "Episode length": 999, "Policy Loss": -0.3504478633403778, "Value Loss": 0.061748720705509186, "_runtime": 5514.322352409363, "_timestamp": 1585514592.743082, "_step": 140}
{"Episode reward": -54.492355694596114, "Episode length": 999, "Policy Loss": -0.34086889028549194, "Value Loss": 0.06024570018053055, "_runtime": 5515.858893632889, "_timestamp": 1585514594.2796233, "_step": 141}
{"Episode reward": -54.435225969350924, "Episode length": 999, "Policy Loss": -0.3257216513156891, "Value Loss": 0.059376444667577744, "_runtime": 5517.418544769287, "_timestamp": 1585514595.8392744, "_step": 142}
{"Episode reward": -50.379123331924774, "Episode length": 999, "Policy Loss": -0.30158931016921997, "Value Loss": 0.05654788389801979, "_runtime": 5518.970461130142, "_timestamp": 1585514597.3911908, "_step": 143}
{"Episode reward": -53.2098847680144, "Episode length": 999, "Policy Loss": -0.32841941714286804, "Value Loss": 0.05717708542943001, "_runtime": 5520.530049085617, "_timestamp": 1585514598.9507787, "_step": 144}
{"Episode reward": -54.99146827362888, "Episode length": 999, "Policy Loss": -0.3207279145717621, "Value Loss": 0.057152219116687775, "_runtime": 5522.089056015015, "_timestamp": 1585514600.5097857, "_step": 145}
{"Episode reward": -53.1516039244159, "Episode length": 999, "Policy Loss": -0.3139501214027405, "Value Loss": 0.05551682040095329, "_runtime": 5523.649563074112, "_timestamp": 1585514602.0702927, "_step": 146}
{"Episode reward": -50.79823843987516, "Episode length": 999, "Policy Loss": -0.3083950877189636, "Value Loss": 0.05360513925552368, "_runtime": 5525.205963134766, "_timestamp": 1585514603.6266928, "_step": 147}
{"Episode reward": -53.686155223977394, "Episode length": 999, "Policy Loss": -0.3163466453552246, "Value Loss": 0.054253555834293365, "_runtime": 5526.76651930809, "_timestamp": 1585514605.187249, "_step": 148}
{"Episode reward": -53.480408501617916, "Episode length": 999, "Policy Loss": -0.3137700855731964, "Value Loss": 0.05336868762969971, "_runtime": 5528.366438150406, "_timestamp": 1585514606.7871678, "_step": 149}
{"Episode reward": -51.52844269874028, "Episode length": 999, "Policy Loss": -0.29655301570892334, "Value Loss": 0.051729630678892136, "_runtime": 5529.927968502045, "_timestamp": 1585514608.3486981, "_step": 150}
{"Episode reward": -53.219060397140815, "Episode length": 999, "Policy Loss": -0.30438295006752014, "Value Loss": 0.05168972909450531, "_runtime": 5531.478861808777, "_timestamp": 1585514609.8995914, "_step": 151}
{"Episode reward": -55.52475818554185, "Episode length": 999, "Policy Loss": -0.3227989077568054, "Value Loss": 0.05199799686670303, "_runtime": 5533.0199155807495, "_timestamp": 1585514611.4406452, "_step": 152}
{"Episode reward": -52.89824214280185, "Episode length": 999, "Policy Loss": -0.2989014983177185, "Value Loss": 0.05009124055504799, "_runtime": 5534.571917057037, "_timestamp": 1585514612.9926467, "_step": 153}
{"Episode reward": -52.386217799782976, "Episode length": 999, "Policy Loss": -0.2823580503463745, "Value Loss": 0.049105867743492126, "_runtime": 5536.126494884491, "_timestamp": 1585514614.5472245, "_step": 154}
{"Episode reward": -53.720462666460904, "Episode length": 999, "Policy Loss": -0.2945747673511505, "Value Loss": 0.049033306539058685, "_runtime": 5537.678615093231, "_timestamp": 1585514616.0993447, "_step": 155}
{"Episode reward": -52.30816652203816, "Episode length": 999, "Policy Loss": -0.28054118156433105, "Value Loss": 0.04766568914055824, "_runtime": 5539.241299152374, "_timestamp": 1585514617.6620288, "_step": 156}
{"Episode reward": -53.63226566325644, "Episode length": 999, "Policy Loss": -0.29097384214401245, "Value Loss": 0.04755459353327751, "_runtime": 5540.8033883571625, "_timestamp": 1585514619.224118, "_step": 157}
{"Episode reward": -55.02996683328596, "Episode length": 999, "Policy Loss": -0.29689183831214905, "Value Loss": 0.04746090993285179, "_runtime": 5542.3665890693665, "_timestamp": 1585514620.7873187, "_step": 158}
{"Episode reward": -51.607793170445795, "Episode length": 999, "Policy Loss": -0.27430298924446106, "Value Loss": 0.04532541707158089, "_runtime": 5543.915805101395, "_timestamp": 1585514622.3365347, "_step": 159}
{"Episode reward": -53.8940679924796, "Episode length": 999, "Policy Loss": -0.2859845459461212, "Value Loss": 0.04556902125477791, "_runtime": 5545.479535102844, "_timestamp": 1585514623.9002647, "_step": 160}
{"Episode reward": -53.65288818247193, "Episode length": 999, "Policy Loss": -0.2832596004009247, "Value Loss": 0.044829390943050385, "_runtime": 5547.041756153107, "_timestamp": 1585514625.4624858, "_step": 161}
{"Episode reward": -57.05677803730727, "Episode length": 999, "Policy Loss": -0.30266085267066956, "Value Loss": 0.04557414352893829, "_runtime": 5548.595735549927, "_timestamp": 1585514627.0164652, "_step": 162}
{"Episode reward": -53.752651942480206, "Episode length": 999, "Policy Loss": -0.2770666480064392, "Value Loss": 0.04357260465621948, "_runtime": 5550.157087087631, "_timestamp": 1585514628.5778167, "_step": 163}
{"Episode reward": -56.413649575317514, "Episode length": 999, "Policy Loss": -0.30026113986968994, "Value Loss": 0.04400503262877464, "_runtime": 5551.756088018417, "_timestamp": 1585514630.1768177, "_step": 164}
{"Episode reward": -55.49425933153364, "Episode length": 999, "Policy Loss": -0.291784405708313, "Value Loss": 0.04297243803739548, "_runtime": 5553.331115484238, "_timestamp": 1585514631.7518451, "_step": 165}
{"Episode reward": -52.722033892796894, "Episode length": 999, "Policy Loss": -0.2568415105342865, "Value Loss": 0.0412118062376976, "_runtime": 5554.909224271774, "_timestamp": 1585514633.329954, "_step": 166}
{"Episode reward": -55.42371285193227, "Episode length": 999, "Policy Loss": -0.28402087092399597, "Value Loss": 0.04168982431292534, "_runtime": 5556.489850282669, "_timestamp": 1585514634.91058, "_step": 167}
{"Episode reward": -56.71315617221951, "Episode length": 999, "Policy Loss": -0.28198128938674927, "Value Loss": 0.04160723090171814, "_runtime": 5558.058510303497, "_timestamp": 1585514636.47924, "_step": 168}
{"Episode reward": -52.96526605197379, "Episode length": 999, "Policy Loss": -0.25543174147605896, "Value Loss": 0.03948694095015526, "_runtime": 5559.636794567108, "_timestamp": 1585514638.0575242, "_step": 169}
{"Episode reward": -55.741989833279504, "Episode length": 999, "Policy Loss": -0.262265145778656, "Value Loss": 0.039946943521499634, "_runtime": 5561.218111276627, "_timestamp": 1585514639.638841, "_step": 170}
{"Episode reward": -52.68830371295209, "Episode length": 999, "Policy Loss": -0.2537820339202881, "Value Loss": 0.03818782791495323, "_runtime": 5562.796866178513, "_timestamp": 1585514641.2175958, "_step": 171}
{"Episode reward": -54.38511272045555, "Episode length": 999, "Policy Loss": -0.26369792222976685, "Value Loss": 0.038261719048023224, "_runtime": 5564.3626935482025, "_timestamp": 1585514642.7834232, "_step": 172}
{"Episode reward": -55.22823625393299, "Episode length": 999, "Policy Loss": -0.2683195471763611, "Value Loss": 0.037998467683792114, "_runtime": 5565.928663015366, "_timestamp": 1585514644.3493927, "_step": 173}
{"Episode reward": -57.79760551722832, "Episode length": 999, "Policy Loss": -0.26758795976638794, "Value Loss": 0.03839627653360367, "_runtime": 5567.496019363403, "_timestamp": 1585514645.916749, "_step": 174}
{"Episode reward": -57.74153280721505, "Episode length": 999, "Policy Loss": -0.2755400836467743, "Value Loss": 0.037769537419080734, "_runtime": 5569.072656393051, "_timestamp": 1585514647.493386, "_step": 175}
{"Episode reward": -53.642281097118925, "Episode length": 999, "Policy Loss": -0.2593223452568054, "Value Loss": 0.03571821749210358, "_runtime": 5570.642215013504, "_timestamp": 1585514649.0629447, "_step": 176}
{"Episode reward": -54.36386293736349, "Episode length": 999, "Policy Loss": -0.2508702278137207, "Value Loss": 0.035427480936050415, "_runtime": 5572.2142877578735, "_timestamp": 1585514650.6350174, "_step": 177}
{"Episode reward": -56.41366277698948, "Episode length": 999, "Policy Loss": -0.26676949858665466, "Value Loss": 0.03562873229384422, "_runtime": 5573.7809998989105, "_timestamp": 1585514652.2017295, "_step": 178}
{"Episode reward": -54.99338587998081, "Episode length": 999, "Policy Loss": -0.2461039274930954, "Value Loss": 0.03457954153418541, "_runtime": 5575.397838592529, "_timestamp": 1585514653.8185682, "_step": 179}
{"Episode reward": -56.19468413792492, "Episode length": 999, "Policy Loss": -0.2598632574081421, "Value Loss": 0.03447945415973663, "_runtime": 5576.9561648368835, "_timestamp": 1585514655.3768945, "_step": 180}
{"Episode reward": -55.08273813961568, "Episode length": 999, "Policy Loss": -0.2494712918996811, "Value Loss": 0.03349943086504936, "_runtime": 5578.522749662399, "_timestamp": 1585514656.9434793, "_step": 181}
{"Episode reward": -53.85407321253922, "Episode length": 999, "Policy Loss": -0.2443309724330902, "Value Loss": 0.03264438733458519, "_runtime": 5580.102874279022, "_timestamp": 1585514658.523604, "_step": 182}
{"Episode reward": -52.40989278834435, "Episode length": 999, "Policy Loss": -0.22832277417182922, "Value Loss": 0.03154115006327629, "_runtime": 5581.683547496796, "_timestamp": 1585514660.1042771, "_step": 183}
{"Episode reward": -54.549777879619384, "Episode length": 999, "Policy Loss": -0.23655371367931366, "Value Loss": 0.03184542432427406, "_runtime": 5583.25058889389, "_timestamp": 1585514661.6713185, "_step": 184}
{"Episode reward": -54.66899614474716, "Episode length": 999, "Policy Loss": -0.23838256299495697, "Value Loss": 0.03140431270003319, "_runtime": 5584.816920518875, "_timestamp": 1585514663.2376502, "_step": 185}
{"Episode reward": -59.47791394549934, "Episode length": 999, "Policy Loss": -0.25457239151000977, "Value Loss": 0.03249219059944153, "_runtime": 5586.395804166794, "_timestamp": 1585514664.8165338, "_step": 186}
{"Episode reward": -56.53900379266704, "Episode length": 999, "Policy Loss": -0.24192005395889282, "Value Loss": 0.031003419309854507, "_runtime": 5587.962177991867, "_timestamp": 1585514666.3829076, "_step": 187}
{"Episode reward": -53.282856053299966, "Episode length": 999, "Policy Loss": -0.22961179912090302, "Value Loss": 0.029414037242531776, "_runtime": 5589.530502080917, "_timestamp": 1585514667.9512317, "_step": 188}
{"Episode reward": -54.6976984655259, "Episode length": 999, "Policy Loss": -0.23042915761470795, "Value Loss": 0.02940870262682438, "_runtime": 5591.11385679245, "_timestamp": 1585514669.5345864, "_step": 189}
{"Episode reward": -55.07758621256719, "Episode length": 999, "Policy Loss": -0.2353859841823578, "Value Loss": 0.029137276113033295, "_runtime": 5592.6916353702545, "_timestamp": 1585514671.112365, "_step": 190}
{"Episode reward": -55.560301978948445, "Episode length": 999, "Policy Loss": -0.23243869841098785, "Value Loss": 0.028781285509467125, "_runtime": 5594.270683288574, "_timestamp": 1585514672.691413, "_step": 191}
{"Episode reward": -58.25617038602194, "Episode length": 999, "Policy Loss": -0.2504194378852844, "Value Loss": 0.029247835278511047, "_runtime": 5595.851083278656, "_timestamp": 1585514674.271813, "_step": 192}
{"Episode reward": -53.3423379556322, "Episode length": 999, "Policy Loss": -0.21976442635059357, "Value Loss": 0.027189284563064575, "_runtime": 5597.466670513153, "_timestamp": 1585514675.8874002, "_step": 193}
{"Episode reward": -55.78546182858236, "Episode length": 999, "Policy Loss": -0.22245463728904724, "Value Loss": 0.027491668239235878, "_runtime": 5599.036140918732, "_timestamp": 1585514677.4568706, "_step": 194}
{"Episode reward": -54.148310703313065, "Episode length": 999, "Policy Loss": -0.21654270589351654, "Value Loss": 0.026533832773566246, "_runtime": 5600.613734960556, "_timestamp": 1585514679.0344646, "_step": 195}
{"Episode reward": -56.19608592776226, "Episode length": 999, "Policy Loss": -0.2247643917798996, "Value Loss": 0.026768315583467484, "_runtime": 5602.180546283722, "_timestamp": 1585514680.601276, "_step": 196}
{"Episode reward": -55.618771397859426, "Episode length": 999, "Policy Loss": -0.22819389402866364, "Value Loss": 0.02621529996395111, "_runtime": 5603.74750494957, "_timestamp": 1585514682.1682346, "_step": 197}
{"Episode reward": -53.96613432303882, "Episode length": 999, "Policy Loss": -0.2122560292482376, "Value Loss": 0.025254709646105766, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714, -0.9962366819381714]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-4.2122955322265625, -4.118708610534668, -4.025121212005615, -3.9315342903137207, -3.837947130203247, -3.7443599700927734, -3.6507728099823, -3.557185649871826, -3.4635987281799316, -3.370011568069458, -3.2764244079589844, -3.1828372478485107, -3.089250087738037, -2.9956631660461426, -2.90207576751709, -2.8084888458251953, -2.7149016857147217, -2.621314525604248, -2.5277276039123535, -2.434140205383301, -2.3405532836914062, -2.2469661235809326, -2.153378963470459, -2.0597918033599854, -1.9662046432495117, -1.8726177215576172, -1.7790305614471436, -1.68544340133667, -1.5918562412261963, -1.4982690811157227, -1.4046821594238281, -1.3110949993133545, -1.2175078392028809, -1.1239206790924072, -1.0303335189819336, -0.9367465972900391, -0.8431594371795654, -0.7495722770690918, -0.6559851169586182, -0.5623979568481445, -0.46881103515625, -0.37522387504577637, -0.28163671493530273, -0.1880497932434082, -0.09446239471435547, -0.0008754730224609375, 0.0927119255065918, 0.18629884719848633, 0.27988624572753906, 0.3734731674194336, 0.4670600891113281, 0.5606474876403809, 0.6542344093322754, 0.7478218078613281, 0.8414087295532227, 0.9349956512451172, 1.02858304977417, 1.1221699714660645, 1.2157573699951172, 1.3093442916870117, 1.4029312133789062, 1.496518611907959, 1.5901055335998535, 1.6836929321289062, 1.7772798538208008]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-1.3754981756210327, -1.3489121198654175, -1.3223260641098022, -1.295740008354187, -1.2691539525985718, -1.2425678968429565, -1.2159818410873413, -1.1893956661224365, -1.1628096103668213, -1.136223554611206, -1.1096374988555908, -1.0830514430999756, -1.0564653873443604, -1.0298793315887451, -1.0032932758331299, -0.9767072200775146, -0.9501211643218994, -0.9235351085662842, -0.896949052810669, -0.8703629970550537, -0.8437769412994385, -0.8171908259391785, -0.7906047701835632, -0.764018714427948, -0.7374326586723328, -0.7108466029167175, -0.6842605471611023, -0.6576744914054871, -0.631088376045227, -0.6045023202896118, -0.5779162645339966, -0.5513302087783813, -0.5247441530227661, -0.4981580972671509, -0.47157204151153564, -0.4449859857559204, -0.4183999300003052, -0.39181381464004517, -0.3652278184890747, -0.3386417627334595, -0.31205570697784424, -0.28546953201293945, -0.2588834762573242, -0.23229742050170898, -0.20571136474609375, -0.17912530899047852, -0.15253925323486328, -0.12595319747924805, -0.09936714172363281, -0.07278108596801758, -0.046195030212402344, -0.01960897445678711, 0.006977081298828125, 0.03356313705444336, 0.060149192810058594, 0.08673524856567383, 0.11332142353057861, 0.13990747928619385, 0.16649353504180908, 0.19307959079742432, 0.21966564655303955, 0.24625170230865479, 0.27283775806427, 0.29942381381988525, 0.3260098695755005]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 4.0, 6.0, 13.0, 14.0, 25.0, 242.0, 94.0, 40.0, 22.0, 5.0, 9.0, 3.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.6281490325927734, -1.5852640867233276, -1.5423791408538818, -1.499494194984436, -1.4566092491149902, -1.4137243032455444, -1.3708393573760986, -1.3279544115066528, -1.285069465637207, -1.2421845197677612, -1.1992995738983154, -1.1564146280288696, -1.1135296821594238, -1.070644736289978, -1.0277597904205322, -0.9848748445510864, -0.9419898986816406, -0.8991049528121948, -0.856220006942749, -0.8133350610733032, -0.7704501152038574, -0.7275651693344116, -0.6846802234649658, -0.64179527759552, -0.5989103317260742, -0.5560253858566284, -0.5131404399871826, -0.4702554941177368, -0.427370548248291, -0.3844856023788452, -0.3416006565093994, -0.2987157106399536, -0.2558307647705078, -0.212945818901062, -0.1700608730316162, -0.1271759271621704, -0.08429098129272461, -0.04140603542327881, 0.0014789104461669922, 0.04436385631561279, 0.0872488021850586, 0.1301337480545044, 0.1730186939239502, 0.215903639793396, 0.2587885856628418, 0.3016735315322876, 0.3445584774017334, 0.38744354248046875, 0.430328369140625, 0.47321319580078125, 0.5160982608795166, 0.558983325958252, 0.6018681526184082, 0.6447529792785645, 0.6876380443572998, 0.7305231094360352, 0.7734079360961914, 0.8162927627563477, 0.859177827835083, 0.9020628929138184, 0.9449477195739746, 0.9878325462341309, 1.0307176113128662, 1.0736026763916016, 1.1164875030517578]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.84517240524292, -1.7910802364349365, -1.7369879484176636, -1.6828956604003906, -1.6288034915924072, -1.5747113227844238, -1.5206190347671509, -1.466526746749878, -1.4124345779418945, -1.3583424091339111, -1.3042501211166382, -1.2501578330993652, -1.1960656642913818, -1.1419734954833984, -1.0878812074661255, -1.0337889194488525, -0.9796967506408691, -0.925604522228241, -0.8715122938156128, -0.8174200057983398, -0.7633278369903564, -0.709235668182373, -0.6551433801651001, -0.6010510921478271, -0.5469589233398438, -0.49286675453186035, -0.4387744665145874, -0.38468217849731445, -0.33059000968933105, -0.27649784088134766, -0.2224055528640747, -0.16831326484680176, -0.11422109603881836, -0.06012892723083496, -0.006036639213562012, 0.04805564880371094, 0.10214781761169434, 0.15623998641967773, 0.21033239364624023, 0.26442456245422363, 0.31851673126220703, 0.37260890007019043, 0.42670106887817383, 0.48079347610473633, 0.5348856449127197, 0.5889778137207031, 0.6430702209472656, 0.697162389755249, 0.7512545585632324, 0.8053467273712158, 0.8594388961791992, 0.9135313034057617, 0.9676234722137451, 1.0217156410217285, 1.075808048248291, 1.1299002170562744, 1.1839923858642578, 1.2380845546722412, 1.2921767234802246, 1.346269130706787, 1.4003612995147705, 1.454453468322754, 1.5085458755493164, 1.5626380443572998, 1.6167302131652832]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 0.0, 5.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 5.0, 4.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.8954636454582214, -0.8690136671066284, -0.8425636887550354, -0.8161137104034424, -0.7896637916564941, -0.7632137537002563, -0.7367638349533081, -0.7103138566017151, -0.6838638782501221, -0.657413899898529, -0.630963921546936, -0.6045140027999878, -0.57806396484375, -0.5516140460968018, -0.5251640677452087, -0.4987140893936157, -0.4722641110420227, -0.4458141326904297, -0.41936415433883667, -0.39291417598724365, -0.36646419763565063, -0.3400142788887024, -0.3135643005371094, -0.28711432218551636, -0.26066434383392334, -0.23421436548233032, -0.2077643871307373, -0.1813144087791443, -0.15486449003219604, -0.12841451168060303, -0.10196453332901001, -0.07551455497741699, -0.049064576625823975, -0.022614598274230957, 0.0038353800773620605, 0.030285358428955078, 0.056735336780548096, 0.08318525552749634, 0.10963529348373413, 0.13608521223068237, 0.16253525018692017, 0.1889851689338684, 0.21543508768081665, 0.24188512563705444, 0.2683350443840027, 0.2947850823402405, 0.3212350010871887, 0.3476850390434265, 0.37413495779037476, 0.400584876537323, 0.4270349144935608, 0.45348483324050903, 0.4799348711967468, 0.5063847899436951, 0.5328348278999329, 0.5592847466468811, 0.5857346653938293, 0.6121847033500671, 0.6386346220970154, 0.6650846600532532, 0.6915345788002014, 0.7179846167564392, 0.7444345355033875, 0.7708845734596252, 0.7973344922065735]}, "_runtime": 5605.318150281906, "_timestamp": 1585514683.73888, "_step": 198}
{"Episode reward": -54.77429160152107, "Episode length": 999, "Policy Loss": -0.21275514364242554, "Value Loss": 0.0251064021140337, "_runtime": 5606.885182380676, "_timestamp": 1585514685.305912, "_step": 199}
{"Episode reward": -57.14124264204695, "Episode length": 999, "Policy Loss": -0.22468619048595428, "Value Loss": 0.02540029212832451, "_runtime": 5608.457486629486, "_timestamp": 1585514686.8782163, "_step": 200}
{"Episode reward": -56.14917341892203, "Episode length": 999, "Policy Loss": -0.22014747560024261, "Value Loss": 0.024701084941625595, "_runtime": 5610.028472185135, "_timestamp": 1585514688.4492018, "_step": 201}
{"Episode reward": -54.31202784755878, "Episode length": 999, "Policy Loss": -0.2016923427581787, "Value Loss": 0.023727620020508766, "_runtime": 5611.607400894165, "_timestamp": 1585514690.0281305, "_step": 202}
{"Episode reward": -58.43362667231741, "Episode length": 999, "Policy Loss": -0.22377927601337433, "Value Loss": 0.02456921897828579, "_runtime": 5613.189218759537, "_timestamp": 1585514691.6099484, "_step": 203}
{"Episode reward": -53.1692688272502, "Episode length": 999, "Policy Loss": -0.19176073372364044, "Value Loss": 0.02263432927429676, "_runtime": 5614.767693996429, "_timestamp": 1585514693.1884236, "_step": 204}
{"Episode reward": -55.447634407835075, "Episode length": 999, "Policy Loss": -0.2117718756198883, "Value Loss": 0.022993581369519234, "_runtime": 5616.3460421562195, "_timestamp": 1585514694.7667718, "_step": 205}
{"Episode reward": -57.71947756188072, "Episode length": 999, "Policy Loss": -0.2092605084180832, "Value Loss": 0.023244326934218407, "_runtime": 5617.913647890091, "_timestamp": 1585514696.3343775, "_step": 206}
{"Episode reward": -56.5811729380143, "Episode length": 999, "Policy Loss": -0.2064458131790161, "Value Loss": 0.022528568282723427, "_runtime": 5619.497312784195, "_timestamp": 1585514697.9180424, "_step": 207}
{"Episode reward": -57.677285751665, "Episode length": 999, "Policy Loss": -0.20732438564300537, "Value Loss": 0.022460849955677986, "_runtime": 5621.100711107254, "_timestamp": 1585514699.5214407, "_step": 208}
{"Episode reward": -54.866774034042976, "Episode length": 999, "Policy Loss": -0.19669221341609955, "Value Loss": 0.02134808339178562, "_runtime": 5622.6817491054535, "_timestamp": 1585514701.1024787, "_step": 209}
{"Episode reward": -54.40623810159903, "Episode length": 999, "Policy Loss": -0.18982598185539246, "Value Loss": 0.020831959322094917, "_runtime": 5624.258976459503, "_timestamp": 1585514702.679706, "_step": 210}
{"Episode reward": -52.92437231331229, "Episode length": 999, "Policy Loss": -0.18858928978443146, "Value Loss": 0.02009478583931923, "_runtime": 5625.8367738723755, "_timestamp": 1585514704.2575035, "_step": 211}
{"Episode reward": -55.24973812260459, "Episode length": 999, "Policy Loss": -0.1905013918876648, "Value Loss": 0.020371384918689728, "_runtime": 5627.416343212128, "_timestamp": 1585514705.8370728, "_step": 212}
{"Episode reward": -56.046378387334954, "Episode length": 999, "Policy Loss": -0.1919102519750595, "Value Loss": 0.020227273926138878, "_runtime": 5628.9954624176025, "_timestamp": 1585514707.416192, "_step": 213}
{"Episode reward": -55.49839358852296, "Episode length": 999, "Policy Loss": -0.18527351319789886, "Value Loss": 0.019770042970776558, "_runtime": 5630.575330495834, "_timestamp": 1585514708.9960601, "_step": 214}
{"Episode reward": -54.1731495523382, "Episode length": 999, "Policy Loss": -0.18251879513263702, "Value Loss": 0.019105609506368637, "_runtime": 5632.143903493881, "_timestamp": 1585514710.5646331, "_step": 215}
{"Episode reward": -54.213753395930446, "Episode length": 999, "Policy Loss": -0.1833319067955017, "Value Loss": 0.018824385479092598, "_runtime": 5633.7205312252045, "_timestamp": 1585514712.1412609, "_step": 216}
{"Episode reward": -54.50466070919151, "Episode length": 999, "Policy Loss": -0.18394964933395386, "Value Loss": 0.01859329454600811, "_runtime": 5635.297760725021, "_timestamp": 1585514713.7184904, "_step": 217}
{"Episode reward": -55.59527954965464, "Episode length": 999, "Policy Loss": -0.17619064450263977, "Value Loss": 0.018493419513106346, "_runtime": 5636.867111682892, "_timestamp": 1585514715.2878413, "_step": 218}
{"Episode reward": -52.95671427909093, "Episode length": 999, "Policy Loss": -0.17475874722003937, "Value Loss": 0.017569608986377716, "_runtime": 5638.434248685837, "_timestamp": 1585514716.8549783, "_step": 219}
{"Episode reward": -53.7201079851494, "Episode length": 999, "Policy Loss": -0.16380909085273743, "Value Loss": 0.017442939803004265, "_runtime": 5640.008557319641, "_timestamp": 1585514718.429287, "_step": 220}
{"Episode reward": -54.74013280532105, "Episode length": 999, "Policy Loss": -0.17348742485046387, "Value Loss": 0.01743576116859913, "_runtime": 5641.590280294418, "_timestamp": 1585514720.01101, "_step": 221}
{"Episode reward": -54.74573373923, "Episode length": 999, "Policy Loss": -0.17066168785095215, "Value Loss": 0.01709071919322014, "_runtime": 5643.160672664642, "_timestamp": 1585514721.5814023, "_step": 222}
{"Episode reward": -55.90939488917759, "Episode length": 999, "Policy Loss": -0.17522695660591125, "Value Loss": 0.017172565683722496, "_runtime": 5644.773562431335, "_timestamp": 1585514723.194292, "_step": 223}
{"Episode reward": -56.75587519791378, "Episode length": 999, "Policy Loss": -0.18371529877185822, "Value Loss": 0.017066635191440582, "_runtime": 5646.342696428299, "_timestamp": 1585514724.763426, "_step": 224}
{"Episode reward": -56.01286183962769, "Episode length": 999, "Policy Loss": -0.17259863018989563, "Value Loss": 0.016627175733447075, "_runtime": 5647.916168689728, "_timestamp": 1585514726.3368983, "_step": 225}
{"Episode reward": -56.77495519576157, "Episode length": 999, "Policy Loss": -0.17647267878055573, "Value Loss": 0.016523901373147964, "_runtime": 5649.495144128799, "_timestamp": 1585514727.9158738, "_step": 226}
{"Episode reward": -55.30181834296941, "Episode length": 999, "Policy Loss": -0.16751234233379364, "Value Loss": 0.015897158533334732, "_runtime": 5651.074056863785, "_timestamp": 1585514729.4947865, "_step": 227}
{"Episode reward": -54.08967414943432, "Episode length": 999, "Policy Loss": -0.1604904681444168, "Value Loss": 0.01538263913244009, "_runtime": 5652.656274318695, "_timestamp": 1585514731.077004, "_step": 228}
{"Episode reward": -56.26870767581331, "Episode length": 999, "Policy Loss": -0.16523903608322144, "Value Loss": 0.015640486031770706, "_runtime": 5654.222607135773, "_timestamp": 1585514732.6433368, "_step": 229}
{"Episode reward": -54.9057424451719, "Episode length": 999, "Policy Loss": -0.15807701647281647, "Value Loss": 0.014965971000492573, "_runtime": 5655.794989824295, "_timestamp": 1585514734.2157195, "_step": 230}
{"Episode reward": -56.435184137131785, "Episode length": 999, "Policy Loss": -0.16404445469379425, "Value Loss": 0.015114500187337399, "_runtime": 5657.373368501663, "_timestamp": 1585514735.7940981, "_step": 231}
{"Episode reward": -56.682729216632495, "Episode length": 999, "Policy Loss": -0.16850872337818146, "Value Loss": 0.014964176341891289, "_runtime": 5658.951128959656, "_timestamp": 1585514737.3718586, "_step": 232}
{"Episode reward": -54.3781986975412, "Episode length": 999, "Policy Loss": -0.1560276597738266, "Value Loss": 0.01414477825164795, "_runtime": 5660.529329538345, "_timestamp": 1585514738.9500592, "_step": 233}
{"Episode reward": -57.813961717501186, "Episode length": 999, "Policy Loss": -0.16244937479496002, "Value Loss": 0.01473091822117567, "_runtime": 5662.107403516769, "_timestamp": 1585514740.5281332, "_step": 234}
{"Episode reward": -54.3428916879543, "Episode length": 999, "Policy Loss": -0.15086981654167175, "Value Loss": 0.01369517482817173, "_runtime": 5663.685058832169, "_timestamp": 1585514742.1057885, "_step": 235}
{"Episode reward": -55.896484069887165, "Episode length": 999, "Policy Loss": -0.15532849729061127, "Value Loss": 0.013768632896244526, "_runtime": 5665.253462314606, "_timestamp": 1585514743.674192, "_step": 236}
{"Episode reward": -56.795502419547425, "Episode length": 999, "Policy Loss": -0.1529906839132309, "Value Loss": 0.013735153712332249, "_runtime": 5666.833565711975, "_timestamp": 1585514745.2542953, "_step": 237}
{"Episode reward": -56.28246927781023, "Episode length": 999, "Policy Loss": -0.1509191393852234, "Value Loss": 0.013418077491223812, "_runtime": 5668.44779753685, "_timestamp": 1585514746.8685272, "_step": 238}
{"Episode reward": -55.09256101537906, "Episode length": 999, "Policy Loss": -0.14907914400100708, "Value Loss": 0.012944980524480343, "_runtime": 5670.028343439102, "_timestamp": 1585514748.449073, "_step": 239}
{"Episode reward": -52.75498125821006, "Episode length": 999, "Policy Loss": -0.1393004059791565, "Value Loss": 0.012254441156983376, "_runtime": 5671.594983100891, "_timestamp": 1585514750.0157127, "_step": 240}
{"Episode reward": -52.64080794674918, "Episode length": 999, "Policy Loss": -0.13325755298137665, "Value Loss": 0.011976261623203754, "_runtime": 5673.173647880554, "_timestamp": 1585514751.5943775, "_step": 241}
{"Episode reward": -53.48627939114741, "Episode length": 999, "Policy Loss": -0.139664426445961, "Value Loss": 0.01195455715060234, "_runtime": 5674.752658128738, "_timestamp": 1585514753.1733878, "_step": 242}
{"Episode reward": -54.974068328673376, "Episode length": 999, "Policy Loss": -0.14393456280231476, "Value Loss": 0.01207407284528017, "_runtime": 5676.318586587906, "_timestamp": 1585514754.7393162, "_step": 243}
{"Episode reward": -54.244850802168074, "Episode length": 999, "Policy Loss": -0.13467440009117126, "Value Loss": 0.01175827905535698, "_runtime": 5677.902199268341, "_timestamp": 1585514756.322929, "_step": 244}
{"Episode reward": -54.865981921949576, "Episode length": 999, "Policy Loss": -0.13123168051242828, "Value Loss": 0.011623789556324482, "_runtime": 5679.471929311752, "_timestamp": 1585514757.892659, "_step": 245}
{"Episode reward": -56.38510616743809, "Episode length": 999, "Policy Loss": -0.14179593324661255, "Value Loss": 0.011751610785722733, "_runtime": 5681.052618741989, "_timestamp": 1585514759.4733484, "_step": 246}
{"Episode reward": -54.428131976088004, "Episode length": 999, "Policy Loss": -0.1365518718957901, "Value Loss": 0.01120034884661436, "_runtime": 5682.617477893829, "_timestamp": 1585514761.0382075, "_step": 247}
{"Episode reward": -55.22832994057603, "Episode length": 999, "Policy Loss": -0.13924860954284668, "Value Loss": 0.011128212325274944, "_runtime": 5684.196202993393, "_timestamp": 1585514762.6169326, "_step": 248}
{"Episode reward": -54.722934473238844, "Episode length": 999, "Policy Loss": -0.12995317578315735, "Value Loss": 0.0108311977237463, "_runtime": 5685.777581453323, "_timestamp": 1585514764.198311, "_step": 249}
{"Episode reward": -53.74818122743715, "Episode length": 999, "Policy Loss": -0.12985599040985107, "Value Loss": 0.010490014217793941, "_runtime": 5687.354588985443, "_timestamp": 1585514765.7753186, "_step": 250}
{"Episode reward": -53.28873491077248, "Episode length": 999, "Policy Loss": -0.12383455783128738, "Value Loss": 0.010193072259426117, "_runtime": 5688.935102939606, "_timestamp": 1585514767.3558326, "_step": 251}
{"Episode reward": -52.58770002135509, "Episode length": 999, "Policy Loss": -0.12385927885770798, "Value Loss": 0.009975550696253777, "_runtime": 5690.552733421326, "_timestamp": 1585514768.973463, "_step": 252}
{"Episode reward": -58.47651618043305, "Episode length": 999, "Policy Loss": -0.1363927721977234, "Value Loss": 0.010820620693266392, "_runtime": 5692.131542921066, "_timestamp": 1585514770.5522726, "_step": 253}
{"Episode reward": -54.792849283211595, "Episode length": 999, "Policy Loss": -0.1240149512887001, "Value Loss": 0.010007252916693687, "_runtime": 5693.711015224457, "_timestamp": 1585514772.1317449, "_step": 254}
{"Episode reward": -54.23165186306981, "Episode length": 999, "Policy Loss": -0.12190970033407211, "Value Loss": 0.0097712567076087, "_runtime": 5695.277865886688, "_timestamp": 1585514773.6985955, "_step": 255}
{"Episode reward": -57.82942354935602, "Episode length": 999, "Policy Loss": -0.1370306760072708, "Value Loss": 0.01019229181110859, "_runtime": 5696.852411985397, "_timestamp": 1585514775.2731416, "_step": 256}
{"Episode reward": -54.81099098957495, "Episode length": 999, "Policy Loss": -0.12166107445955276, "Value Loss": 0.009509218856692314, "_runtime": 5698.432429790497, "_timestamp": 1585514776.8531594, "_step": 257}
{"Episode reward": -54.85118077729207, "Episode length": 999, "Policy Loss": -0.12109453976154327, "Value Loss": 0.009391377680003643, "_runtime": 5700.002676725388, "_timestamp": 1585514778.4234064, "_step": 258}
{"Episode reward": -55.56622180207343, "Episode length": 999, "Policy Loss": -0.1218104436993599, "Value Loss": 0.009325141087174416, "_runtime": 5701.576591253281, "_timestamp": 1585514779.997321, "_step": 259}
{"Episode reward": -55.98296288620194, "Episode length": 999, "Policy Loss": -0.12368833273649216, "Value Loss": 0.00926309172064066, "_runtime": 5703.1506135463715, "_timestamp": 1585514781.5713432, "_step": 260}
{"Episode reward": -55.83239039832671, "Episode length": 999, "Policy Loss": -0.12445570528507233, "Value Loss": 0.009062650613486767, "_runtime": 5704.720562458038, "_timestamp": 1585514783.141292, "_step": 261}
{"Episode reward": -55.904637517866, "Episode length": 999, "Policy Loss": -0.11835657805204391, "Value Loss": 0.008944807574152946, "_runtime": 5706.299902677536, "_timestamp": 1585514784.7206323, "_step": 262}
{"Episode reward": -56.14106538034368, "Episode length": 999, "Policy Loss": -0.11898748576641083, "Value Loss": 0.008845292031764984, "_runtime": 5707.88058924675, "_timestamp": 1585514786.301319, "_step": 263}
{"Episode reward": -54.52711572913249, "Episode length": 999, "Policy Loss": -0.11720561981201172, "Value Loss": 0.008469458669424057, "_runtime": 5709.462909698486, "_timestamp": 1585514787.8836393, "_step": 264}
{"Episode reward": -52.90127363456589, "Episode length": 999, "Policy Loss": -0.1059427484869957, "Value Loss": 0.008061625063419342, "_runtime": 5711.040260076523, "_timestamp": 1585514789.4609897, "_step": 265}
{"Episode reward": -53.31247447966254, "Episode length": 999, "Policy Loss": -0.1094965860247612, "Value Loss": 0.00798299815505743, "_runtime": 5712.623966217041, "_timestamp": 1585514791.0446959, "_step": 266}
{"Episode reward": -54.12947250986284, "Episode length": 999, "Policy Loss": -0.11399132013320923, "Value Loss": 0.00800218153744936, "_runtime": 5714.238005638123, "_timestamp": 1585514792.6587353, "_step": 267}
{"Episode reward": -54.93655543337101, "Episode length": 999, "Policy Loss": -0.10862796008586884, "Value Loss": 0.00794263370335102, "_runtime": 5715.815111875534, "_timestamp": 1585514794.2358415, "_step": 268}
{"Episode reward": -51.372408607564815, "Episode length": 999, "Policy Loss": -0.09859046339988708, "Value Loss": 0.00727282278239727, "_runtime": 5717.396836519241, "_timestamp": 1585514795.8175662, "_step": 269}
{"Episode reward": -54.97690868346061, "Episode length": 999, "Policy Loss": -0.11064700037240982, "Value Loss": 0.007666738238185644, "_runtime": 5718.9731092453, "_timestamp": 1585514797.393839, "_step": 270}
{"Episode reward": -52.51545934870259, "Episode length": 999, "Policy Loss": -0.0947217121720314, "Value Loss": 0.007181263994425535, "_runtime": 5720.549482822418, "_timestamp": 1585514798.9702125, "_step": 271}
{"Episode reward": -54.25457913122741, "Episode length": 999, "Policy Loss": -0.1034613698720932, "Value Loss": 0.0073809376917779446, "_runtime": 5722.118493080139, "_timestamp": 1585514800.5392227, "_step": 272}
{"Episode reward": -51.3444232748532, "Episode length": 999, "Policy Loss": -0.09183795750141144, "Value Loss": 0.006807710975408554, "_runtime": 5723.696781635284, "_timestamp": 1585514802.1175113, "_step": 273}
{"Episode reward": -55.00241366694363, "Episode length": 999, "Policy Loss": -0.10553105920553207, "Value Loss": 0.007242090534418821, "_runtime": 5725.274370193481, "_timestamp": 1585514803.6950998, "_step": 274}
{"Episode reward": -54.45578409081032, "Episode length": 999, "Policy Loss": -0.10458056628704071, "Value Loss": 0.007031547836959362, "_runtime": 5726.856093883514, "_timestamp": 1585514805.2768235, "_step": 275}
{"Episode reward": -52.692659329186014, "Episode length": 999, "Policy Loss": -0.09528214484453201, "Value Loss": 0.006627474445849657, "_runtime": 5728.421023130417, "_timestamp": 1585514806.8417528, "_step": 276}
{"Episode reward": -52.62410201887933, "Episode length": 999, "Policy Loss": -0.0919964388012886, "Value Loss": 0.0065330020152032375, "_runtime": 5729.979293823242, "_timestamp": 1585514808.4000235, "_step": 277}
{"Episode reward": -55.219716249945414, "Episode length": 999, "Policy Loss": -0.1037791296839714, "Value Loss": 0.006820322014391422, "_runtime": 5731.550998210907, "_timestamp": 1585514809.9717278, "_step": 278}
{"Episode reward": -53.669442419886366, "Episode length": 999, "Policy Loss": -0.09601832181215286, "Value Loss": 0.006516466848552227, "_runtime": 5733.120738506317, "_timestamp": 1585514811.5414681, "_step": 279}
{"Episode reward": -52.27372406923988, "Episode length": 999, "Policy Loss": -0.08940442651510239, "Value Loss": 0.006236590910702944, "_runtime": 5734.699573278427, "_timestamp": 1585514813.120303, "_step": 280}
{"Episode reward": -54.69989466384273, "Episode length": 999, "Policy Loss": -0.09828851372003555, "Value Loss": 0.006438350770622492, "_runtime": 5736.280377149582, "_timestamp": 1585514814.7011068, "_step": 281}
{"Episode reward": -56.344511726753986, "Episode length": 999, "Policy Loss": -0.09699007123708725, "Value Loss": 0.006527791731059551, "_runtime": 5737.893423318863, "_timestamp": 1585514816.314153, "_step": 282}
{"Episode reward": -54.266186095531666, "Episode length": 999, "Policy Loss": -0.09186077862977982, "Value Loss": 0.006157878786325455, "_runtime": 5739.475883960724, "_timestamp": 1585514817.8966136, "_step": 283}
{"Episode reward": -53.536302460665645, "Episode length": 999, "Policy Loss": -0.09057319164276123, "Value Loss": 0.006013723090291023, "_runtime": 5741.055495023727, "_timestamp": 1585514819.4762247, "_step": 284}
{"Episode reward": -54.897232761515994, "Episode length": 999, "Policy Loss": -0.09351170808076859, "Value Loss": 0.00604376383125782, "_runtime": 5742.635152101517, "_timestamp": 1585514821.0558817, "_step": 285}
{"Episode reward": -54.17312579066981, "Episode length": 999, "Policy Loss": -0.0894739031791687, "Value Loss": 0.0059019518084824085, "_runtime": 5744.214153289795, "_timestamp": 1585514822.634883, "_step": 286}
{"Episode reward": -51.35075818330438, "Episode length": 999, "Policy Loss": -0.08125787228345871, "Value Loss": 0.005428646225482225, "_runtime": 5745.794686079025, "_timestamp": 1585514824.2154157, "_step": 287}
{"Episode reward": -54.26991821425152, "Episode length": 999, "Policy Loss": -0.08628891408443451, "Value Loss": 0.005719507113099098, "_runtime": 5747.37304854393, "_timestamp": 1585514825.7937782, "_step": 288}
{"Episode reward": -55.30763359401228, "Episode length": 999, "Policy Loss": -0.0919228196144104, "Value Loss": 0.005715587176382542, "_runtime": 5748.95570397377, "_timestamp": 1585514827.3764336, "_step": 289}
{"Episode reward": -56.02504023245149, "Episode length": 999, "Policy Loss": -0.08839823305606842, "Value Loss": 0.005768022034317255, "_runtime": 5750.5364644527435, "_timestamp": 1585514828.957194, "_step": 290}
{"Episode reward": -52.62880607574323, "Episode length": 999, "Policy Loss": -0.08304493129253387, "Value Loss": 0.005277689546346664, "_runtime": 5752.115848779678, "_timestamp": 1585514830.5365784, "_step": 291}
{"Episode reward": -54.891030588046604, "Episode length": 999, "Policy Loss": -0.08394092321395874, "Value Loss": 0.005428284872323275, "_runtime": 5753.696564435959, "_timestamp": 1585514832.117294, "_step": 292}
{"Episode reward": -54.51104712286768, "Episode length": 999, "Policy Loss": -0.08454126864671707, "Value Loss": 0.00530168367549777, "_runtime": 5755.278254985809, "_timestamp": 1585514833.6989846, "_step": 293}
{"Episode reward": -55.39043079001154, "Episode length": 999, "Policy Loss": -0.08247233182191849, "Value Loss": 0.005355428904294968, "_runtime": 5756.860185623169, "_timestamp": 1585514835.2809153, "_step": 294}
{"Episode reward": -54.36911809738575, "Episode length": 999, "Policy Loss": -0.07984478771686554, "Value Loss": 0.005080501548945904, "_runtime": 5758.428470373154, "_timestamp": 1585514836.8492, "_step": 295}
{"Episode reward": -52.989255423084245, "Episode length": 999, "Policy Loss": -0.07719269394874573, "Value Loss": 0.00496261939406395, "_runtime": 5759.999170541763, "_timestamp": 1585514838.4199002, "_step": 296}
{"Episode reward": -54.29917331503359, "Episode length": 999, "Policy Loss": -0.07702239602804184, "Value Loss": 0.004967831075191498, "_runtime": 5761.616323471069, "_timestamp": 1585514840.037053, "_step": 297}
{"Episode reward": -51.70466671187994, "Episode length": 999, "Policy Loss": -0.07331666350364685, "Value Loss": 0.004571910481899977, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052, 1.48578941822052]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.485627293586731, -1.3925135135650635, -1.299399733543396, -1.2062859535217285, -1.1131720542907715, -1.0200583934783936, -0.9269444942474365, -0.833830714225769, -0.7407169342041016, -0.6476031541824341, -0.5544893741607666, -0.4613755941390991, -0.3682616949081421, -0.2751479148864746, -0.18203413486480713, -0.08892035484313965, 0.004193425178527832, 0.09730720520019531, 0.1904209852218628, 0.2835347652435303, 0.37664854526519775, 0.4697624444961548, 0.5628761053085327, 0.6559900045394897, 0.7491039037704468, 0.8422175645828247, 0.9353314638137817, 1.0284451246261597, 1.1215590238571167, 1.2146726846694946, 1.3077865839004517, 1.4009002447128296, 1.4940141439437866, 1.5871280431747437, 1.6802417039871216, 1.7733556032180786, 1.8664692640304565, 1.9595831632614136, 2.052696704864502, 2.145810604095459, 2.238924503326416, 2.332038402557373, 2.42515230178833, 2.518266201019287, 2.611379623413086, 2.704493522644043, 2.797607421875, 2.890721321105957, 2.983835220336914, 3.076948642730713, 3.17006254196167, 3.263176441192627, 3.356290340423584, 3.449403762817383, 3.54251766204834, 3.635631561279297, 3.728745460510254, 3.821859359741211, 3.9149727821350098, 4.008086681365967, 4.101200580596924, 4.194314479827881, 4.28742790222168, 4.380541801452637, 4.473655700683594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-1.3836873769760132, -1.3596575260162354, -1.3356276750564575, -1.3115978240966797, -1.2875679731369019, -1.263538122177124, -1.2395082712173462, -1.2154784202575684, -1.191448450088501, -1.1674187183380127, -1.1433887481689453, -1.1193588972091675, -1.0953290462493896, -1.0712991952896118, -1.047269344329834, -1.0232394933700562, -0.9992096424102783, -0.9751797914505005, -0.9511499404907227, -0.9271200895309448, -0.903090238571167, -0.8790603280067444, -0.8550304770469666, -0.8310006260871887, -0.8069707751274109, -0.7829409241676331, -0.7589110732078552, -0.7348812222480774, -0.7108513116836548, -0.686821460723877, -0.6627916097640991, -0.6387617588043213, -0.6147319078445435, -0.5907020568847656, -0.5666722059249878, -0.54264235496521, -0.5186125040054321, -0.4945825934410095, -0.4705527424812317, -0.44652289152145386, -0.422493040561676, -0.3984631896018982, -0.3744332790374756, -0.35040342807769775, -0.3263735771179199, -0.3023437261581421, -0.27831387519836426, -0.2542840242385864, -0.2302541732788086, -0.20622432231903076, -0.18219447135925293, -0.1581646203994751, -0.13413476943969727, -0.11010491847991943, -0.0860750675201416, -0.06204521656036377, -0.03801524639129639, -0.013985395431518555, 0.010044455528259277, 0.03407430648803711, 0.05810415744781494, 0.08213400840759277, 0.1061638593673706, 0.13019371032714844, 0.15422356128692627]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 6.0, 6.0, 2.0, 12.0, 13.0, 56.0, 233.0, 56.0, 28.0, 22.0, 19.0, 8.0, 6.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.5559102296829224, -1.5135900974273682, -1.471269965171814, -1.4289498329162598, -1.386629581451416, -1.3443094491958618, -1.3019893169403076, -1.2596691846847534, -1.2173490524291992, -1.1750288009643555, -1.1327086687088013, -1.090388536453247, -1.0480684041976929, -1.0057482719421387, -0.9634280800819397, -0.9211078882217407, -0.8787877559661865, -0.8364676237106323, -0.7941474318504333, -0.7518272995948792, -0.7095071077346802, -0.667186975479126, -0.6248668432235718, -0.5825466513633728, -0.5402265787124634, -0.49790632724761963, -0.45558619499206543, -0.41326606273651123, -0.37094593048095703, -0.32862579822540283, -0.2863055467605591, -0.24398541450500488, -0.20166528224945068, -0.15934514999389648, -0.11702501773834229, -0.07470476627349854, -0.032384634017944336, 0.009935498237609863, 0.05225563049316406, 0.09457576274871826, 0.136896014213562, 0.1792161464691162, 0.2215362787246704, 0.2638564109802246, 0.3061765432357788, 0.348496675491333, 0.39081692695617676, 0.43313705921173096, 0.4754570722579956, 0.5177773237228394, 0.5600975751876831, 0.6024175882339478, 0.6447378396987915, 0.6870578527450562, 0.7293781042098999, 0.7716983556747437, 0.8140183687210083, 0.856338620185852, 0.8986586332321167, 0.9409788846969604, 0.9832991361618042, 1.0256191492080688, 1.0679394006729126, 1.1102594137191772, 1.152579665184021]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-2.6320719718933105, -2.5569379329681396, -2.4818038940429688, -2.406670093536377, -2.331536054611206, -2.256402015686035, -2.1812679767608643, -2.1061339378356934, -2.0309998989105225, -1.9558659791946411, -1.8807319402694702, -1.8055980205535889, -1.730463981628418, -1.655329942703247, -1.5801959037780762, -1.5050619840621948, -1.429927945137024, -1.354793906211853, -1.2796599864959717, -1.2045259475708008, -1.1293919086456299, -1.0542579889297485, -0.9791239500045776, -0.9039899110794067, -0.8288559913635254, -0.7537219524383545, -0.6785879135131836, -0.6034538745880127, -0.5283198356628418, -0.45318603515625, -0.3780519962310791, -0.3029179573059082, -0.2277839183807373, -0.1526498794555664, -0.07751584053039551, -0.0023818016052246094, 0.07275199890136719, 0.14788603782653809, 0.22302007675170898, 0.2981541156768799, 0.3732881546020508, 0.4484221935272217, 0.5235559940338135, 0.5986900329589844, 0.6738240718841553, 0.7489581108093262, 0.8240921497344971, 0.899226188659668, 0.9743599891662598, 1.0494940280914307, 1.1246280670166016, 1.1997621059417725, 1.2748961448669434, 1.3500301837921143, 1.4251642227172852, 1.500298023223877, 1.575432300567627, 1.6505661010742188, 1.7256999015808105, 1.8008341789245605, 1.8759679794311523, 1.9511022567749023, 2.026236057281494, 2.101370334625244, 2.176504135131836]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 5.0, 4.0, 11.0, 8.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.6842961311340332, -0.6606425642967224, -0.6369889974594116, -0.6133354902267456, -0.5896819233894348, -0.566028356552124, -0.542374849319458, -0.5187212824821472, -0.4950677156448364, -0.47141414880752563, -0.44776061177253723, -0.42410707473754883, -0.40045350790023804, -0.37679994106292725, -0.35314640402793884, -0.32949286699295044, -0.30583930015563965, -0.28218573331832886, -0.25853219628334045, -0.23487865924835205, -0.21122509241104126, -0.18757152557373047, -0.16391801834106445, -0.14026445150375366, -0.11661088466644287, -0.09295731782913208, -0.06930375099182129, -0.04565024375915527, -0.021996676921844482, 0.0016568899154663086, 0.025310397148132324, 0.048963963985443115, 0.0726175308227539, 0.0962710976600647, 0.11992466449737549, 0.1435781717300415, 0.1672317385673523, 0.19088530540466309, 0.2145388126373291, 0.2381923794746399, 0.2618459463119507, 0.2854995131492615, 0.30915307998657227, 0.3328065872192383, 0.3564600944519043, 0.38011372089385986, 0.4037672281265259, 0.42742085456848145, 0.45107436180114746, 0.4747278690338135, 0.49838149547576904, 0.5220350027084351, 0.5456886291503906, 0.5693421363830566, 0.5929956436157227, 0.6166492700576782, 0.6403027772903442, 0.6639562845230103, 0.6876099109649658, 0.7112634181976318, 0.7349169254302979, 0.7585705518722534, 0.7822240591049194, 0.805877685546875, 0.829531192779541]}, "_runtime": 5763.195630073547, "_timestamp": 1585514841.6163597, "_step": 298}
{"Episode reward": -52.40119034379004, "Episode length": 999, "Policy Loss": -0.0765714943408966, "Value Loss": 0.00466668326407671, "_runtime": 5764.778031349182, "_timestamp": 1585514843.198761, "_step": 299}
{"Episode reward": -55.055998310692914, "Episode length": 999, "Policy Loss": -0.07604176551103592, "Value Loss": 0.004888434428721666, "_runtime": 5766.3608140945435, "_timestamp": 1585514844.7815437, "_step": 300}
{"Episode reward": -53.43135091550235, "Episode length": 999, "Policy Loss": -0.07431032508611679, "Value Loss": 0.004596793092787266, "_runtime": 5767.938619852066, "_timestamp": 1585514846.3593495, "_step": 301}
{"Episode reward": -54.477137012971035, "Episode length": 999, "Policy Loss": -0.07722695916891098, "Value Loss": 0.0047069513238966465, "_runtime": 5769.504388332367, "_timestamp": 1585514847.925118, "_step": 302}
{"Episode reward": -53.660330618366025, "Episode length": 999, "Policy Loss": -0.07179722189903259, "Value Loss": 0.004533722531050444, "_runtime": 5771.082106590271, "_timestamp": 1585514849.5028362, "_step": 303}
{"Episode reward": -54.659406467992945, "Episode length": 999, "Policy Loss": -0.07356656342744827, "Value Loss": 0.004570716992020607, "_runtime": 5772.664298772812, "_timestamp": 1585514851.0850284, "_step": 304}
{"Episode reward": -55.325278963790666, "Episode length": 999, "Policy Loss": -0.07343052327632904, "Value Loss": 0.004514612723141909, "_runtime": 5774.24272274971, "_timestamp": 1585514852.6634524, "_step": 305}
{"Episode reward": -57.44481098419249, "Episode length": 999, "Policy Loss": -0.08151242882013321, "Value Loss": 0.004733051639050245, "_runtime": 5775.822117567062, "_timestamp": 1585514854.2428472, "_step": 306}
{"Episode reward": -53.81219368234945, "Episode length": 999, "Policy Loss": -0.07172894477844238, "Value Loss": 0.004289106000214815, "_runtime": 5777.401310443878, "_timestamp": 1585514855.82204, "_step": 307}
{"Episode reward": -54.88745190725322, "Episode length": 999, "Policy Loss": -0.0732191875576973, "Value Loss": 0.0043145776726305485, "_runtime": 5778.982626438141, "_timestamp": 1585514857.403356, "_step": 308}
{"Episode reward": -54.87073653166438, "Episode length": 999, "Policy Loss": -0.07189448177814484, "Value Loss": 0.004279938526451588, "_runtime": 5780.548759222031, "_timestamp": 1585514858.9694889, "_step": 309}
{"Episode reward": -55.204416087511106, "Episode length": 999, "Policy Loss": -0.07233422249555588, "Value Loss": 0.004260145127773285, "_runtime": 5782.116047143936, "_timestamp": 1585514860.5367768, "_step": 310}
{"Episode reward": -53.123127586999985, "Episode length": 999, "Policy Loss": -0.06562633812427521, "Value Loss": 0.003969166427850723, "_runtime": 5783.704859972, "_timestamp": 1585514862.1255896, "_step": 311}
{"Episode reward": -54.71533099196844, "Episode length": 999, "Policy Loss": -0.06689523160457611, "Value Loss": 0.004112577065825462, "_runtime": 5785.32288980484, "_timestamp": 1585514863.7436194, "_step": 312}
{"Episode reward": -56.40956673800421, "Episode length": 999, "Policy Loss": -0.07291840761899948, "Value Loss": 0.004244048148393631, "_runtime": 5786.901367425919, "_timestamp": 1585514865.322097, "_step": 313}
{"Episode reward": -53.455642198791914, "Episode length": 999, "Policy Loss": -0.06683918088674545, "Value Loss": 0.003895275294780731, "_runtime": 5788.483128070831, "_timestamp": 1585514866.9038577, "_step": 314}
{"Episode reward": -54.249207174991184, "Episode length": 999, "Policy Loss": -0.0646992027759552, "Value Loss": 0.003942226991057396, "_runtime": 5790.051241397858, "_timestamp": 1585514868.471971, "_step": 315}
{"Episode reward": -54.3958154608434, "Episode length": 999, "Policy Loss": -0.06297371536493301, "Value Loss": 0.0038159426767379045, "_runtime": 5791.623728275299, "_timestamp": 1585514870.044458, "_step": 316}
{"Episode reward": -52.46530216992133, "Episode length": 999, "Policy Loss": -0.05756597965955734, "Value Loss": 0.0035654117818921804, "_runtime": 5793.1937510967255, "_timestamp": 1585514871.6144807, "_step": 317}
{"Episode reward": -52.94294374695183, "Episode length": 999, "Policy Loss": -0.06119043380022049, "Value Loss": 0.00360698439180851, "_runtime": 5794.772597312927, "_timestamp": 1585514873.193327, "_step": 318}
{"Episode reward": -56.50455115215332, "Episode length": 999, "Policy Loss": -0.06547240912914276, "Value Loss": 0.0038638985715806484, "_runtime": 5796.333787918091, "_timestamp": 1585514874.7545176, "_step": 319}
{"Episode reward": -52.833059247755656, "Episode length": 999, "Policy Loss": -0.05641525983810425, "Value Loss": 0.0034973686560988426, "_runtime": 5797.914958953857, "_timestamp": 1585514876.3356886, "_step": 320}
{"Episode reward": -52.805549296320606, "Episode length": 999, "Policy Loss": -0.05884285643696785, "Value Loss": 0.0034779321867972612, "_runtime": 5799.4945113658905, "_timestamp": 1585514877.915241, "_step": 321}
{"Episode reward": -56.68577726199978, "Episode length": 999, "Policy Loss": -0.06371881067752838, "Value Loss": 0.003716877894476056, "_runtime": 5801.062082052231, "_timestamp": 1585514879.4828117, "_step": 322}
{"Episode reward": -51.94454657629848, "Episode length": 999, "Policy Loss": -0.05633208528161049, "Value Loss": 0.003327403450384736, "_runtime": 5802.6412444114685, "_timestamp": 1585514881.061974, "_step": 323}
{"Episode reward": -55.92173416263058, "Episode length": 999, "Policy Loss": -0.06350404024124146, "Value Loss": 0.003645884105935693, "_runtime": 5804.209320306778, "_timestamp": 1585514882.63005, "_step": 324}
{"Episode reward": -52.958005567983804, "Episode length": 999, "Policy Loss": -0.05538484454154968, "Value Loss": 0.0032657503616064787, "_runtime": 5805.787940502167, "_timestamp": 1585514884.2086701, "_step": 325}
{"Episode reward": -53.70087491669306, "Episode length": 999, "Policy Loss": -0.05462009832262993, "Value Loss": 0.003298078430816531, "_runtime": 5807.39647269249, "_timestamp": 1585514885.8172023, "_step": 326}
{"Episode reward": -54.22399581784431, "Episode length": 999, "Policy Loss": -0.05803374573588371, "Value Loss": 0.003380614798516035, "_runtime": 5808.975837230682, "_timestamp": 1585514887.3965669, "_step": 327}
{"Episode reward": -52.2042657531171, "Episode length": 999, "Policy Loss": -0.05175686255097389, "Value Loss": 0.0031372359953820705, "_runtime": 5810.551303386688, "_timestamp": 1585514888.972033, "_step": 328}
{"Episode reward": -52.48208594712245, "Episode length": 999, "Policy Loss": -0.052445948123931885, "Value Loss": 0.0030617329757660627, "_runtime": 5812.132616996765, "_timestamp": 1585514890.5533466, "_step": 329}
{"Episode reward": -51.59570475824192, "Episode length": 999, "Policy Loss": -0.0495276115834713, "Value Loss": 0.003033311339095235, "_runtime": 5813.712781190872, "_timestamp": 1585514892.1335108, "_step": 330}
{"Episode reward": -54.12292966257696, "Episode length": 999, "Policy Loss": -0.05328882485628128, "Value Loss": 0.0031645619310438633, "_runtime": 5815.292712688446, "_timestamp": 1585514893.7134423, "_step": 331}
{"Episode reward": -53.37004439343584, "Episode length": 999, "Policy Loss": -0.05356041342020035, "Value Loss": 0.003040010342374444, "_runtime": 5816.873175859451, "_timestamp": 1585514895.2939055, "_step": 332}
{"Episode reward": -51.44742586631249, "Episode length": 999, "Policy Loss": -0.04780431091785431, "Value Loss": 0.002933748532086611, "_runtime": 5818.454492330551, "_timestamp": 1585514896.875222, "_step": 333}
{"Episode reward": -52.89907558506758, "Episode length": 999, "Policy Loss": -0.0490160770714283, "Value Loss": 0.002983284881338477, "_runtime": 5820.018107414246, "_timestamp": 1585514898.438837, "_step": 334}
{"Episode reward": -52.20467597136967, "Episode length": 999, "Policy Loss": -0.048029690980911255, "Value Loss": 0.0029009475838392973, "_runtime": 5821.597051382065, "_timestamp": 1585514900.017781, "_step": 335}
{"Episode reward": -52.50180322690731, "Episode length": 999, "Policy Loss": -0.04551038146018982, "Value Loss": 0.002905532019212842, "_runtime": 5823.155828714371, "_timestamp": 1585514901.5765584, "_step": 336}
{"Episode reward": -55.00565999197326, "Episode length": 999, "Policy Loss": -0.0526496097445488, "Value Loss": 0.003036883193999529, "_runtime": 5824.741429567337, "_timestamp": 1585514903.1621592, "_step": 337}
{"Episode reward": -52.94275426854698, "Episode length": 999, "Policy Loss": -0.04600450024008751, "Value Loss": 0.0028610359877347946, "_runtime": 5826.319745063782, "_timestamp": 1585514904.7404747, "_step": 338}
{"Episode reward": -55.21472941708894, "Episode length": 999, "Policy Loss": -0.049954019486904144, "Value Loss": 0.003052678657695651, "_runtime": 5827.896458148956, "_timestamp": 1585514906.3171878, "_step": 339}
{"Episode reward": -52.462749296163715, "Episode length": 999, "Policy Loss": -0.04525615647435188, "Value Loss": 0.0027856193482875824, "_runtime": 5829.464950084686, "_timestamp": 1585514907.8856797, "_step": 340}
{"Episode reward": -52.50242501234111, "Episode length": 999, "Policy Loss": -0.04433651641011238, "Value Loss": 0.0027712478768080473, "_runtime": 5831.067509651184, "_timestamp": 1585514909.4882393, "_step": 341}
{"Episode reward": -53.31719679679569, "Episode length": 999, "Policy Loss": -0.04509603604674339, "Value Loss": 0.0027285029646009207, "_runtime": 5832.643725633621, "_timestamp": 1585514911.0644553, "_step": 342}
{"Episode reward": -53.14961927172643, "Episode length": 999, "Policy Loss": -0.042783476412296295, "Value Loss": 0.002713810419663787, "_runtime": 5834.208287715912, "_timestamp": 1585514912.6290174, "_step": 343}
{"Episode reward": -54.16011849872116, "Episode length": 999, "Policy Loss": -0.04398833215236664, "Value Loss": 0.0027837208472192287, "_runtime": 5835.78160238266, "_timestamp": 1585514914.202332, "_step": 344}
{"Episode reward": -53.73636637487744, "Episode length": 999, "Policy Loss": -0.043676164001226425, "Value Loss": 0.002755383960902691, "_runtime": 5837.362745523453, "_timestamp": 1585514915.7834752, "_step": 345}
{"Episode reward": -53.82584622553386, "Episode length": 999, "Policy Loss": -0.04491184279322624, "Value Loss": 0.002671591006219387, "_runtime": 5838.9447286129, "_timestamp": 1585514917.3654583, "_step": 346}
{"Episode reward": -52.43647413281135, "Episode length": 999, "Policy Loss": -0.038960136473178864, "Value Loss": 0.0025685899890959263, "_runtime": 5840.5231239795685, "_timestamp": 1585514918.9438536, "_step": 347}
{"Episode reward": -56.55517825230287, "Episode length": 999, "Policy Loss": -0.048522911965847015, "Value Loss": 0.0028423552867025137, "_runtime": 5842.099173307419, "_timestamp": 1585514920.519903, "_step": 348}
{"Episode reward": -52.01602805457799, "Episode length": 999, "Policy Loss": -0.03972276672720909, "Value Loss": 0.0025375792756676674, "_runtime": 5843.678956747055, "_timestamp": 1585514922.0996864, "_step": 349}
{"Episode reward": -53.88082632767421, "Episode length": 999, "Policy Loss": -0.04351723939180374, "Value Loss": 0.0026658037677407265, "_runtime": 5845.249862909317, "_timestamp": 1585514923.6705925, "_step": 350}
{"Episode reward": -55.00000008977549, "Episode length": 999, "Policy Loss": -0.04257580265402794, "Value Loss": 0.0026278456207364798, "_runtime": 5846.828973531723, "_timestamp": 1585514925.2497032, "_step": 351}
{"Episode reward": -54.704334105984344, "Episode length": 999, "Policy Loss": -0.042082756757736206, "Value Loss": 0.0025975790340453386, "_runtime": 5848.407927751541, "_timestamp": 1585514926.8286574, "_step": 352}
{"Episode reward": -52.91850082922411, "Episode length": 999, "Policy Loss": -0.03954312577843666, "Value Loss": 0.002512962557375431, "_runtime": 5849.990058898926, "_timestamp": 1585514928.4107885, "_step": 353}
{"Episode reward": -54.1330815116142, "Episode length": 999, "Policy Loss": -0.04117324948310852, "Value Loss": 0.002561607863754034, "_runtime": 5851.568987369537, "_timestamp": 1585514929.989717, "_step": 354}
{"Episode reward": -52.80197048437534, "Episode length": 999, "Policy Loss": -0.039545223116874695, "Value Loss": 0.0024313272442668676, "_runtime": 5853.1493356227875, "_timestamp": 1585514931.5700653, "_step": 355}
{"Episode reward": -52.99583616040833, "Episode length": 999, "Policy Loss": -0.036641962826251984, "Value Loss": 0.0024218112230300903, "_runtime": 5854.780348062515, "_timestamp": 1585514933.2010777, "_step": 356}
{"Episode reward": -53.019993368062714, "Episode length": 999, "Policy Loss": -0.035431988537311554, "Value Loss": 0.002465442754328251, "_runtime": 5856.349768877029, "_timestamp": 1585514934.7704985, "_step": 357}
{"Episode reward": -51.297781237489836, "Episode length": 999, "Policy Loss": -0.032033249735832214, "Value Loss": 0.002321049803867936, "_runtime": 5857.92778301239, "_timestamp": 1585514936.3485126, "_step": 358}
{"Episode reward": -54.07146906449044, "Episode length": 999, "Policy Loss": -0.037407681345939636, "Value Loss": 0.002452076645568013, "_runtime": 5859.507444620132, "_timestamp": 1585514937.9281743, "_step": 359}
{"Episode reward": -52.058040361962966, "Episode length": 999, "Policy Loss": -0.033682432025671005, "Value Loss": 0.002311874181032181, "_runtime": 5861.087792158127, "_timestamp": 1585514939.5085218, "_step": 360}
{"Episode reward": -53.968271307520524, "Episode length": 999, "Policy Loss": -0.03425389155745506, "Value Loss": 0.0024269099812954664, "_runtime": 5862.668577671051, "_timestamp": 1585514941.0893073, "_step": 361}
{"Episode reward": -53.03062875913913, "Episode length": 999, "Policy Loss": -0.034038905054330826, "Value Loss": 0.002322445623576641, "_runtime": 5864.246001958847, "_timestamp": 1585514942.6667316, "_step": 362}
{"Episode reward": -52.24129387088453, "Episode length": 999, "Policy Loss": -0.031136007979512215, "Value Loss": 0.0022807959467172623, "_runtime": 5865.823932886124, "_timestamp": 1585514944.2446625, "_step": 363}
{"Episode reward": -52.197615498012595, "Episode length": 999, "Policy Loss": -0.03267712518572807, "Value Loss": 0.002279106993228197, "_runtime": 5867.391934394836, "_timestamp": 1585514945.812664, "_step": 364}
{"Episode reward": -52.878064842797365, "Episode length": 999, "Policy Loss": -0.033747851848602295, "Value Loss": 0.002286560833454132, "_runtime": 5868.971236944199, "_timestamp": 1585514947.3919666, "_step": 365}
{"Episode reward": -52.79387524622398, "Episode length": 999, "Policy Loss": -0.03469372168183327, "Value Loss": 0.0022420589812099934, "_runtime": 5870.550487518311, "_timestamp": 1585514948.9712172, "_step": 366}
{"Episode reward": -52.136365266620956, "Episode length": 999, "Policy Loss": -0.031247582286596298, "Value Loss": 0.002190864644944668, "_runtime": 5872.131486654282, "_timestamp": 1585514950.5522163, "_step": 367}
{"Episode reward": -53.057487766810816, "Episode length": 999, "Policy Loss": -0.033373672515153885, "Value Loss": 0.002244700910523534, "_runtime": 5873.711729049683, "_timestamp": 1585514952.1324587, "_step": 368}
{"Episode reward": -53.9389178752146, "Episode length": 999, "Policy Loss": -0.03382185101509094, "Value Loss": 0.0022583322133868933, "_runtime": 5875.295395374298, "_timestamp": 1585514953.716125, "_step": 369}
{"Episode reward": -53.97702088899064, "Episode length": 999, "Policy Loss": -0.03540753945708275, "Value Loss": 0.002235500141978264, "_runtime": 5876.872662782669, "_timestamp": 1585514955.2933924, "_step": 370}
{"Episode reward": -52.53161549935036, "Episode length": 999, "Policy Loss": -0.03009294904768467, "Value Loss": 0.002166840247809887, "_runtime": 5878.474784374237, "_timestamp": 1585514956.895514, "_step": 371}
{"Episode reward": -55.03575455333798, "Episode length": 999, "Policy Loss": -0.03278045356273651, "Value Loss": 0.002279129344969988, "_runtime": 5880.056689023972, "_timestamp": 1585514958.4774187, "_step": 372}
{"Episode reward": -52.249646427689534, "Episode length": 999, "Policy Loss": -0.02900676429271698, "Value Loss": 0.0021627049427479506, "_runtime": 5881.63211274147, "_timestamp": 1585514960.0528424, "_step": 373}
{"Episode reward": -53.690152458573166, "Episode length": 999, "Policy Loss": -0.031308792531490326, "Value Loss": 0.0022044526413083076, "_runtime": 5883.208732843399, "_timestamp": 1585514961.6294625, "_step": 374}
{"Episode reward": -55.38340333813967, "Episode length": 999, "Policy Loss": -0.030960431322455406, "Value Loss": 0.0022842944599688053, "_runtime": 5884.786062955856, "_timestamp": 1585514963.2067926, "_step": 375}
{"Episode reward": -57.78795068644767, "Episode length": 999, "Policy Loss": -0.037213657051324844, "Value Loss": 0.002364323940128088, "_runtime": 5886.352294921875, "_timestamp": 1585514964.7730246, "_step": 376}
{"Episode reward": -52.898116595152246, "Episode length": 999, "Policy Loss": -0.028609832748770714, "Value Loss": 0.00207507680170238, "_runtime": 5887.933436393738, "_timestamp": 1585514966.354166, "_step": 377}
{"Episode reward": -53.76049875902912, "Episode length": 999, "Policy Loss": -0.028760410845279694, "Value Loss": 0.0020960988476872444, "_runtime": 5889.503061056137, "_timestamp": 1585514967.9237907, "_step": 378}
{"Episode reward": -52.8374411470673, "Episode length": 999, "Policy Loss": -0.02712414786219597, "Value Loss": 0.0020916860084980726, "_runtime": 5891.0831871032715, "_timestamp": 1585514969.5039167, "_step": 379}
{"Episode reward": -52.53901460415764, "Episode length": 999, "Policy Loss": -0.02595742605626583, "Value Loss": 0.0020879327785223722, "_runtime": 5892.660789728165, "_timestamp": 1585514971.0815194, "_step": 380}
{"Episode reward": -53.31690501801851, "Episode length": 999, "Policy Loss": -0.029595529660582542, "Value Loss": 0.002089073648676276, "_runtime": 5894.226421117783, "_timestamp": 1585514972.6471508, "_step": 381}
{"Episode reward": -50.36815216825549, "Episode length": 999, "Policy Loss": -0.02103179320693016, "Value Loss": 0.001956731313839555, "_runtime": 5895.804042816162, "_timestamp": 1585514974.2247725, "_step": 382}
{"Episode reward": -56.1085298662251, "Episode length": 999, "Policy Loss": -0.032601289451122284, "Value Loss": 0.002201235620304942, "_runtime": 5897.3847806453705, "_timestamp": 1585514975.8055103, "_step": 383}
{"Episode reward": -54.89508996166285, "Episode length": 999, "Policy Loss": -0.027621639892458916, "Value Loss": 0.0021135893184691668, "_runtime": 5898.958146572113, "_timestamp": 1585514977.3788762, "_step": 384}
{"Episode reward": -51.73720240707907, "Episode length": 999, "Policy Loss": -0.023529760539531708, "Value Loss": 0.0020262610632926226, "_runtime": 5900.560070037842, "_timestamp": 1585514978.9807997, "_step": 385}
{"Episode reward": -52.90440973816356, "Episode length": 999, "Policy Loss": -0.02710726670920849, "Value Loss": 0.002041660714894533, "_runtime": 5902.140540361404, "_timestamp": 1585514980.56127, "_step": 386}
{"Episode reward": -55.23820739183946, "Episode length": 999, "Policy Loss": -0.028853764757514, "Value Loss": 0.0020974993240088224, "_runtime": 5903.700262784958, "_timestamp": 1585514982.1209924, "_step": 387}
{"Episode reward": -54.72930898784597, "Episode length": 999, "Policy Loss": -0.02824452519416809, "Value Loss": 0.002080697799101472, "_runtime": 5905.268127679825, "_timestamp": 1585514983.6888573, "_step": 388}
{"Episode reward": -52.96652471243828, "Episode length": 999, "Policy Loss": -0.026108793914318085, "Value Loss": 0.0020527439191937447, "_runtime": 5906.838335037231, "_timestamp": 1585514985.2590647, "_step": 389}
{"Episode reward": -50.92924931894197, "Episode length": 999, "Policy Loss": -0.019956620410084724, "Value Loss": 0.0019125551916658878, "_runtime": 5908.418657064438, "_timestamp": 1585514986.8393867, "_step": 390}
{"Episode reward": -52.516930338901055, "Episode length": 999, "Policy Loss": -0.024693474173545837, "Value Loss": 0.0019770485814660788, "_runtime": 5909.986337184906, "_timestamp": 1585514988.4070668, "_step": 391}
{"Episode reward": -54.64905800560016, "Episode length": 999, "Policy Loss": -0.026649435982108116, "Value Loss": 0.0020428707357496023, "_runtime": 5911.553205251694, "_timestamp": 1585514989.973935, "_step": 392}
{"Episode reward": -54.71601122374617, "Episode length": 999, "Policy Loss": -0.024057017639279366, "Value Loss": 0.0019905383232980967, "_runtime": 5913.130902290344, "_timestamp": 1585514991.551632, "_step": 393}
{"Episode reward": -53.621944476266755, "Episode length": 999, "Policy Loss": -0.021410785615444183, "Value Loss": 0.001987460535019636, "_runtime": 5914.710943937302, "_timestamp": 1585514993.1316736, "_step": 394}
{"Episode reward": -55.62430793578652, "Episode length": 999, "Policy Loss": -0.02782275900244713, "Value Loss": 0.002045190427452326, "_runtime": 5916.289946317673, "_timestamp": 1585514994.710676, "_step": 395}
{"Episode reward": -54.827199197323786, "Episode length": 999, "Policy Loss": -0.023498062044382095, "Value Loss": 0.0020233974792063236, "_runtime": 5917.868399381638, "_timestamp": 1585514996.289129, "_step": 396}
{"Episode reward": -53.17971221234857, "Episode length": 999, "Policy Loss": -0.023312749341130257, "Value Loss": 0.0019559734500944614, "_runtime": 5919.435959100723, "_timestamp": 1585514997.8566887, "_step": 397}
{"Episode reward": -55.33091372872556, "Episode length": 999, "Policy Loss": -0.024068498983979225, "Value Loss": 0.0020229772198945284, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627, -1.4895012378692627]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0], "bins": [-4.623200416564941, -4.5276923179626465, -4.432183742523193, -4.336675643920898, -4.241167068481445, -4.14565896987915, -4.050150394439697, -3.9546422958374023, -3.8591339588165283, -3.7636256217956543, -3.6681172847747803, -3.5726089477539062, -3.4771008491516113, -3.381592273712158, -3.2860841751098633, -3.1905758380889893, -3.0950675010681152, -2.999559164047241, -2.904050827026367, -2.8085427284240723, -2.713034152984619, -2.617526054382324, -2.52201771736145, -2.426509380340576, -2.331001043319702, -2.235492706298828, -2.139984369277954, -2.04447603225708, -1.9489679336547852, -1.8534595966339111, -1.757951259613037, -1.662442922592163, -1.566934585571289, -1.471426248550415, -1.375917911529541, -1.280409574508667, -1.184901237487793, -1.089393138885498, -0.993884801864624, -0.89837646484375, -0.802868127822876, -0.707359790802002, -0.611851692199707, -0.5163431167602539, -0.420835018157959, -0.32532644271850586, -0.22981834411621094, -0.1343097686767578, -0.03880167007446289, 0.05670642852783203, 0.15221500396728516, 0.24772310256958008, 0.3432316780090332, 0.4387397766113281, 0.5342483520507812, 0.6297564506530762, 0.7252645492553711, 0.8207731246948242, 0.9162812232971191, 1.0117897987365723, 1.1072978973388672, 1.2028064727783203, 1.2983145713806152, 1.3938231468200684, 1.4893312454223633]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16854800283908844, -0.14199386537075043, -0.11543973535299301, -0.0888856053352356, -0.06233146786689758, -0.03577733039855957, -0.009223207831382751, 0.01733092963695526, 0.043885067105293274, 0.07043920457363129, 0.0969933420419693, 0.12354747951030731, 0.15010158717632294, 0.17665572464466095, 0.20320986211299896, 0.22976399958133698, 0.2563181519508362, 0.2828722596168518, 0.3094264268875122, 0.33598053455352783, 0.36253470182418823, 0.38908880949020386, 0.41564297676086426, 0.4421970844268799, 0.4687511920928955, 0.4953053593635559, 0.5218594670295715, 0.5484136343002319, 0.5749677419662476, 0.601521909236908, 0.6280760169029236, 0.654630184173584, 0.6811842918395996, 0.7077383995056152, 0.7342925667762756, 0.7608466744422913, 0.7874008417129517, 0.8139549493789673, 0.8405090570449829, 0.8670632839202881, 0.8936173915863037, 0.9201714992523193, 0.946725606918335, 0.9732797145843506, 0.9998339414596558, 1.0263880491256714, 1.052942156791687, 1.0794962644577026, 1.1060503721237183, 1.1326045989990234, 1.159158706665039, 1.1857128143310547, 1.2122669219970703, 1.2388211488723755, 1.2653752565383911, 1.2919293642044067, 1.3184834718704224, 1.345037579536438, 1.3715918064117432, 1.3981459140777588, 1.4247000217437744, 1.45125412940979, 1.4778083562850952, 1.5043624639511108, 1.5309165716171265]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 5.0, 6.0, 16.0, 26.0, 28.0, 61.0, 230.0, 58.0, 11.0, 12.0, 5.0, 7.0, 5.0, 2.0, 2.0, 2.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.2630316019058228, -1.2166749238967896, -1.170318365097046, -1.1239616870880127, -1.0776050090789795, -1.0312483310699463, -0.9848917722702026, -0.9385350942611694, -0.892178475856781, -0.8458218574523926, -0.7994651794433594, -0.753108561038971, -0.7067519426345825, -0.6603952646255493, -0.6140386462211609, -0.5676819682121277, -0.5213253498077393, -0.47496873140335083, -0.4286120533943176, -0.3822554349899292, -0.335898756980896, -0.28954213857650757, -0.24318552017211914, -0.19682884216308594, -0.15047228336334229, -0.10411560535430908, -0.05775892734527588, -0.011402249336242676, 0.03495430946350098, 0.08131098747253418, 0.12766766548156738, 0.17402422428131104, 0.22038090229034424, 0.26673758029937744, 0.3130941390991211, 0.3594508171081543, 0.4058074951171875, 0.45216405391693115, 0.49852073192596436, 0.5448774099349976, 0.5912340879440308, 0.6375906467437744, 0.6839473247528076, 0.7303040027618408, 0.7766605615615845, 0.8230172395706177, 0.8693739175796509, 0.9157305955886841, 0.9620870351791382, 1.0084437131881714, 1.0548003911972046, 1.1011570692062378, 1.147513747215271, 1.1938704252243042, 1.2402271032333374, 1.2865835428237915, 1.3329402208328247, 1.379296898841858, 1.4256535768508911, 1.4720102548599243, 1.5183669328689575, 1.5647233724594116, 1.6110800504684448, 1.657436728477478, 1.7037934064865112]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-2.275482177734375, -2.1957364082336426, -2.1159908771514893, -2.036245107650757, -1.9564993381500244, -1.8767536878585815, -1.7970080375671387, -1.7172622680664062, -1.6375166177749634, -1.5577709674835205, -1.478025197982788, -1.3982795476913452, -1.3185338973999023, -1.23878812789917, -1.159042477607727, -1.0792967081069946, -0.9995510578155518, -0.9198054075241089, -0.8400596380233765, -0.7603139877319336, -0.6805682182312012, -0.6008225679397583, -0.5210769176483154, -0.441331148147583, -0.36158549785614014, -0.28183984756469727, -0.20209407806396484, -0.12234830856323242, -0.0426027774810791, 0.03714299201965332, 0.11688876152038574, 0.19663429260253906, 0.2763800621032715, 0.3561258316040039, 0.4358713626861572, 0.5156171321868896, 0.5953629016876221, 0.6751084327697754, 0.7548542022705078, 0.8345999717712402, 0.9143457412719727, 0.994091272354126, 1.0738370418548584, 1.1535828113555908, 1.2333283424377441, 1.3130741119384766, 1.392819881439209, 1.4725654125213623, 1.5523111820220947, 1.6320569515228271, 1.7118024826049805, 1.791548252105713, 1.8712940216064453, 1.9510397911071777, 2.03078556060791, 2.1105308532714844, 2.190276622772217, 2.270022392272949, 2.3497681617736816, 2.429513931274414, 2.5092597007751465, 2.5890049934387207, 2.668750762939453, 2.7484965324401855, 2.828242301940918]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 6.0, 4.0, 3.0, 8.0, 10.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.817811131477356, -0.7947053909301758, -0.7715997099876404, -0.748494029045105, -0.7253882884979248, -0.7022825479507446, -0.6791768670082092, -0.6560711860656738, -0.6329654455184937, -0.6098597049713135, -0.5867540240287781, -0.5636483430862427, -0.5405426025390625, -0.5174368619918823, -0.4943311810493469, -0.47122547030448914, -0.44811975955963135, -0.42501404881477356, -0.40190833806991577, -0.378802627325058, -0.3556969165802002, -0.3325912058353424, -0.3094854950904846, -0.2863798141479492, -0.26327407360076904, -0.24016833305358887, -0.21706265211105347, -0.19395697116851807, -0.1708512306213379, -0.14774549007415771, -0.12463980913162231, -0.10153412818908691, -0.07842838764190674, -0.05532264709472656, -0.03221696615219116, -0.009111285209655762, 0.013994455337524414, 0.03710019588470459, 0.06020587682723999, 0.08331155776977539, 0.10641729831695557, 0.12952303886413574, 0.15262871980667114, 0.17573440074920654, 0.19884014129638672, 0.2219458818435669, 0.24505150318145752, 0.2681572437286377, 0.29126298427581787, 0.31436872482299805, 0.3374744653701782, 0.36058008670806885, 0.383685827255249, 0.4067915678024292, 0.4298971891403198, 0.4530029296875, 0.4761086702346802, 0.49921441078186035, 0.5223201513290405, 0.5454257726669312, 0.5685315132141113, 0.5916372537612915, 0.6147428750991821, 0.6378486156463623, 0.6609543561935425]}, "_runtime": 5921.004302024841, "_timestamp": 1585514999.4250317, "_step": 398}
{"Episode reward": -57.27186897636313, "Episode length": 999, "Policy Loss": -0.029450122267007828, "Value Loss": 0.0021013417281210423, "_runtime": 5922.5738978385925, "_timestamp": 1585515000.9946275, "_step": 399}
{"Episode reward": -54.26146738830493, "Episode length": 999, "Policy Loss": -0.022395430132746696, "Value Loss": 0.0019491836428642273, "_runtime": 5924.191742897034, "_timestamp": 1585515002.6124725, "_step": 400}
{"Episode reward": -56.74856968188318, "Episode length": 999, "Policy Loss": -0.02570308931171894, "Value Loss": 0.002044521039351821, "_runtime": 5925.772703170776, "_timestamp": 1585515004.1934328, "_step": 401}
{"Episode reward": -53.14111701032059, "Episode length": 999, "Policy Loss": -0.02067609876394272, "Value Loss": 0.001953983213752508, "_runtime": 5927.351187467575, "_timestamp": 1585515005.771917, "_step": 402}
{"Episode reward": -52.49393776683459, "Episode length": 999, "Policy Loss": -0.018438944593071938, "Value Loss": 0.0018651514546945691, "_runtime": 5928.93124127388, "_timestamp": 1585515007.351971, "_step": 403}
{"Episode reward": -55.162485712507326, "Episode length": 999, "Policy Loss": -0.025624200701713562, "Value Loss": 0.001966690644621849, "_runtime": 5930.512790679932, "_timestamp": 1585515008.9335203, "_step": 404}
{"Episode reward": -53.17527908619584, "Episode length": 999, "Policy Loss": -0.023214058950543404, "Value Loss": 0.001854629605077207, "_runtime": 5932.090388774872, "_timestamp": 1585515010.5111184, "_step": 405}
{"Episode reward": -53.97326224787882, "Episode length": 999, "Policy Loss": -0.019405804574489594, "Value Loss": 0.0018928576027974486, "_runtime": 5933.669753551483, "_timestamp": 1585515012.0904832, "_step": 406}
{"Episode reward": -54.59832757641068, "Episode length": 999, "Policy Loss": -0.023775052279233932, "Value Loss": 0.0019382991595193744, "_runtime": 5935.248962640762, "_timestamp": 1585515013.6696923, "_step": 407}
{"Episode reward": -56.61473061699912, "Episode length": 999, "Policy Loss": -0.024726426228880882, "Value Loss": 0.0019322363659739494, "_runtime": 5936.8246557712555, "_timestamp": 1585515015.2453854, "_step": 408}
{"Episode reward": -53.43060221248446, "Episode length": 999, "Policy Loss": -0.01721763424575329, "Value Loss": 0.0018950559897348285, "_runtime": 5938.392895698547, "_timestamp": 1585515016.8136253, "_step": 409}
{"Episode reward": -52.03665458279049, "Episode length": 999, "Policy Loss": -0.016511909663677216, "Value Loss": 0.0018092725658789277, "_runtime": 5939.966539621353, "_timestamp": 1585515018.3872693, "_step": 410}
{"Episode reward": -51.94917653047536, "Episode length": 999, "Policy Loss": -0.016265517100691795, "Value Loss": 0.001813668990507722, "_runtime": 5941.538735628128, "_timestamp": 1585515019.9594653, "_step": 411}
{"Episode reward": -55.59752127059104, "Episode length": 999, "Policy Loss": -0.02032867819070816, "Value Loss": 0.0018933068495243788, "_runtime": 5943.105328798294, "_timestamp": 1585515021.5260584, "_step": 412}
{"Episode reward": -52.84825125347514, "Episode length": 999, "Policy Loss": -0.01517890952527523, "Value Loss": 0.0018373236525803804, "_runtime": 5944.675616979599, "_timestamp": 1585515023.0963466, "_step": 413}
{"Episode reward": -57.086347874454255, "Episode length": 999, "Policy Loss": -0.02246720902621746, "Value Loss": 0.0019234102219343185, "_runtime": 5946.245626926422, "_timestamp": 1585515024.6663566, "_step": 414}
{"Episode reward": -55.80888220273663, "Episode length": 999, "Policy Loss": -0.020814253017306328, "Value Loss": 0.0018909034552052617, "_runtime": 5947.8585686683655, "_timestamp": 1585515026.2792983, "_step": 415}
{"Episode reward": -53.45147417652604, "Episode length": 999, "Policy Loss": -0.017476990818977356, "Value Loss": 0.0018504325998947024, "_runtime": 5949.437922954559, "_timestamp": 1585515027.8586526, "_step": 416}
{"Episode reward": -53.865668196055324, "Episode length": 999, "Policy Loss": -0.018768837675452232, "Value Loss": 0.0018373108468949795, "_runtime": 5951.028844356537, "_timestamp": 1585515029.449574, "_step": 417}
{"Episode reward": -54.75207197489283, "Episode length": 999, "Policy Loss": -0.017014749348163605, "Value Loss": 0.0018663086229935288, "_runtime": 5952.611714601517, "_timestamp": 1585515031.0324442, "_step": 418}
{"Episode reward": -53.15279929077703, "Episode length": 999, "Policy Loss": -0.017212769016623497, "Value Loss": 0.0017835911130532622, "_runtime": 5954.192684650421, "_timestamp": 1585515032.6134143, "_step": 419}
{"Episode reward": -51.98949121509603, "Episode length": 999, "Policy Loss": -0.01106028538197279, "Value Loss": 0.0017825302202254534, "_runtime": 5955.7510867118835, "_timestamp": 1585515034.1718163, "_step": 420}
{"Episode reward": -56.187809345645455, "Episode length": 999, "Policy Loss": -0.02133381925523281, "Value Loss": 0.0018831535708159208, "_runtime": 5957.328872919083, "_timestamp": 1585515035.7496026, "_step": 421}
{"Episode reward": -53.01279078011847, "Episode length": 999, "Policy Loss": -0.015451307408511639, "Value Loss": 0.0018267849227413535, "_runtime": 5958.906140804291, "_timestamp": 1585515037.3268704, "_step": 422}
{"Episode reward": -51.95878398081139, "Episode length": 999, "Policy Loss": -0.012995041906833649, "Value Loss": 0.0017826950643211603, "_runtime": 5960.485549449921, "_timestamp": 1585515038.906279, "_step": 423}
{"Episode reward": -53.136514445913605, "Episode length": 999, "Policy Loss": -0.015288538299500942, "Value Loss": 0.0017838815692812204, "_runtime": 5962.053498744965, "_timestamp": 1585515040.4742284, "_step": 424}
{"Episode reward": -54.49555553044296, "Episode length": 999, "Policy Loss": -0.01778240315616131, "Value Loss": 0.001821193378418684, "_runtime": 5963.6371858119965, "_timestamp": 1585515042.0579154, "_step": 425}
{"Episode reward": -55.00851759626135, "Episode length": 999, "Policy Loss": -0.0179440975189209, "Value Loss": 0.0018032919615507126, "_runtime": 5965.218343734741, "_timestamp": 1585515043.6390734, "_step": 426}
{"Episode reward": -53.26344309595278, "Episode length": 999, "Policy Loss": -0.013514393009245396, "Value Loss": 0.001746291876770556, "_runtime": 5966.78675365448, "_timestamp": 1585515045.2074833, "_step": 427}
{"Episode reward": -51.85636157262191, "Episode length": 999, "Policy Loss": -0.013374688103795052, "Value Loss": 0.0017952616326510906, "_runtime": 5968.367922067642, "_timestamp": 1585515046.7886517, "_step": 428}
{"Episode reward": -56.26540134005392, "Episode length": 999, "Policy Loss": -0.01675528660416603, "Value Loss": 0.0018292339518666267, "_runtime": 5969.932886600494, "_timestamp": 1585515048.3536162, "_step": 429}
{"Episode reward": -55.12107953952365, "Episode length": 999, "Policy Loss": -0.015481914393603802, "Value Loss": 0.0017594557721167803, "_runtime": 5971.538170576096, "_timestamp": 1585515049.9589002, "_step": 430}
{"Episode reward": -52.665748279551345, "Episode length": 999, "Policy Loss": -0.013505111448466778, "Value Loss": 0.0017803814262151718, "_runtime": 5973.116187095642, "_timestamp": 1585515051.5369167, "_step": 431}
{"Episode reward": -52.776660715810365, "Episode length": 999, "Policy Loss": -0.013757829554378986, "Value Loss": 0.0017461219104006886, "_runtime": 5974.695611000061, "_timestamp": 1585515053.1163406, "_step": 432}
{"Episode reward": -53.00348412067624, "Episode length": 999, "Policy Loss": -0.012083178386092186, "Value Loss": 0.001773008261807263, "_runtime": 5976.262984752655, "_timestamp": 1585515054.6837144, "_step": 433}
{"Episode reward": -52.718910066532835, "Episode length": 999, "Policy Loss": -0.010907318443059921, "Value Loss": 0.0018077694112434983, "_runtime": 5977.8319256305695, "_timestamp": 1585515056.2526553, "_step": 434}
{"Episode reward": -52.50838459643144, "Episode length": 999, "Policy Loss": -0.010937457904219627, "Value Loss": 0.0017527543241158128, "_runtime": 5979.4097599983215, "_timestamp": 1585515057.8304896, "_step": 435}
{"Episode reward": -53.15458577952137, "Episode length": 999, "Policy Loss": -0.011904120445251465, "Value Loss": 0.0017560838023200631, "_runtime": 5980.995168924332, "_timestamp": 1585515059.4158986, "_step": 436}
{"Episode reward": -54.938733999868724, "Episode length": 999, "Policy Loss": -0.015843572095036507, "Value Loss": 0.0018096964340656996, "_runtime": 5982.574550628662, "_timestamp": 1585515060.9952803, "_step": 437}
{"Episode reward": -53.90909822701499, "Episode length": 999, "Policy Loss": -0.014683765359222889, "Value Loss": 0.001767180161550641, "_runtime": 5984.1540694236755, "_timestamp": 1585515062.574799, "_step": 438}
{"Episode reward": -53.60473519848462, "Episode length": 999, "Policy Loss": -0.012413275428116322, "Value Loss": 0.0017858860082924366, "_runtime": 5985.722349643707, "_timestamp": 1585515064.1430793, "_step": 439}
{"Episode reward": -56.623019300635946, "Episode length": 999, "Policy Loss": -0.016772765666246414, "Value Loss": 0.001830191700719297, "_runtime": 5987.3003923892975, "_timestamp": 1585515065.721122, "_step": 440}
{"Episode reward": -50.9881784163159, "Episode length": 999, "Policy Loss": -0.008606861345469952, "Value Loss": 0.0016849972307682037, "_runtime": 5988.854221582413, "_timestamp": 1585515067.2749512, "_step": 441}
{"Episode reward": -51.76495817807495, "Episode length": 999, "Policy Loss": -0.008811079896986485, "Value Loss": 0.0017025069100782275, "_runtime": 5990.424303770065, "_timestamp": 1585515068.8450334, "_step": 442}
{"Episode reward": -54.306012980935996, "Episode length": 999, "Policy Loss": -0.013701662421226501, "Value Loss": 0.0017129285261034966, "_runtime": 5991.996867179871, "_timestamp": 1585515070.4175968, "_step": 443}
{"Episode reward": -52.68676381675721, "Episode length": 999, "Policy Loss": -0.009496212936937809, "Value Loss": 0.0017362295184284449, "_runtime": 5993.576979398727, "_timestamp": 1585515071.997709, "_step": 444}
{"Episode reward": -51.692305136306224, "Episode length": 999, "Policy Loss": -0.009026069194078445, "Value Loss": 0.001672512968070805, "_runtime": 5995.193073511124, "_timestamp": 1585515073.6138031, "_step": 445}
{"Episode reward": -52.09286567921119, "Episode length": 999, "Policy Loss": -0.008462951518595219, "Value Loss": 0.0016803562175482512, "_runtime": 5996.774314403534, "_timestamp": 1585515075.195044, "_step": 446}
{"Episode reward": -54.35324118946135, "Episode length": 999, "Policy Loss": -0.011473952792584896, "Value Loss": 0.0017139202682301402, "_runtime": 5998.35545539856, "_timestamp": 1585515076.776185, "_step": 447}
{"Episode reward": -54.665761764179564, "Episode length": 999, "Policy Loss": -0.01380198635160923, "Value Loss": 0.0017678409349173307, "_runtime": 5999.924529075623, "_timestamp": 1585515078.3452587, "_step": 448}
{"Episode reward": -54.32531995637082, "Episode length": 999, "Policy Loss": -0.011652624234557152, "Value Loss": 0.0016903964569792151, "_runtime": 6001.490509986877, "_timestamp": 1585515079.9112396, "_step": 449}
{"Episode reward": -55.283005528187616, "Episode length": 999, "Policy Loss": -0.014907708391547203, "Value Loss": 0.0017933513736352324, "_runtime": 6003.07329916954, "_timestamp": 1585515081.4940288, "_step": 450}
{"Episode reward": -52.961850528731766, "Episode length": 999, "Policy Loss": -0.006839842535555363, "Value Loss": 0.0017447000136598945, "_runtime": 6004.652456521988, "_timestamp": 1585515083.0731862, "_step": 451}
{"Episode reward": -53.80977587904186, "Episode length": 999, "Policy Loss": -0.01172141544520855, "Value Loss": 0.001766989124007523, "_runtime": 6006.231926679611, "_timestamp": 1585515084.6526563, "_step": 452}
{"Episode reward": -55.14874679119128, "Episode length": 999, "Policy Loss": -0.010845212265849113, "Value Loss": 0.0017551655182614923, "_runtime": 6007.8111255168915, "_timestamp": 1585515086.2318552, "_step": 453}
{"Episode reward": -53.855594588052334, "Episode length": 999, "Policy Loss": -0.010424678213894367, "Value Loss": 0.001702856388874352, "_runtime": 6009.387793064117, "_timestamp": 1585515087.8085227, "_step": 454}
{"Episode reward": -54.719200483925725, "Episode length": 999, "Policy Loss": -0.011022997088730335, "Value Loss": 0.0017246141796931624, "_runtime": 6010.946118593216, "_timestamp": 1585515089.3668482, "_step": 455}
{"Episode reward": -53.002686775272835, "Episode length": 999, "Policy Loss": -0.0074385604821145535, "Value Loss": 0.0017184031894430518, "_runtime": 6012.5257523059845, "_timestamp": 1585515090.946482, "_step": 456}
{"Episode reward": -52.87458271901747, "Episode length": 999, "Policy Loss": -0.008294224739074707, "Value Loss": 0.0017155918758362532, "_runtime": 6014.105475664139, "_timestamp": 1585515092.5262053, "_step": 457}
{"Episode reward": -54.012781469059796, "Episode length": 999, "Policy Loss": -0.009866874665021896, "Value Loss": 0.0017503550043329597, "_runtime": 6015.673977613449, "_timestamp": 1585515094.0947073, "_step": 458}
{"Episode reward": -53.69240738161665, "Episode length": 999, "Policy Loss": -0.009818566963076591, "Value Loss": 0.001746368478052318, "_runtime": 6017.284767866135, "_timestamp": 1585515095.7054975, "_step": 459}
{"Episode reward": -53.739848055709594, "Episode length": 999, "Policy Loss": -0.007774287834763527, "Value Loss": 0.0017123101279139519, "_runtime": 6018.847843408585, "_timestamp": 1585515097.268573, "_step": 460}
{"Episode reward": -51.38143889011795, "Episode length": 999, "Policy Loss": -0.004910028539597988, "Value Loss": 0.0016841068863868713, "_runtime": 6020.4087636470795, "_timestamp": 1585515098.8294933, "_step": 461}
{"Episode reward": -57.10729895666675, "Episode length": 999, "Policy Loss": -0.015008030459284782, "Value Loss": 0.0018132919212803245, "_runtime": 6021.960941076279, "_timestamp": 1585515100.3816707, "_step": 462}
{"Episode reward": -52.90464267291545, "Episode length": 999, "Policy Loss": -0.007026819046586752, "Value Loss": 0.0017315915320068598, "_runtime": 6023.532222747803, "_timestamp": 1585515101.9529524, "_step": 463}
{"Episode reward": -53.766595742631495, "Episode length": 999, "Policy Loss": -0.007716341409832239, "Value Loss": 0.0017076332587748766, "_runtime": 6025.1046051979065, "_timestamp": 1585515103.5253348, "_step": 464}
{"Episode reward": -56.89117622455044, "Episode length": 999, "Policy Loss": -0.014108994975686073, "Value Loss": 0.0017154786037281156, "_runtime": 6026.673772096634, "_timestamp": 1585515105.0945017, "_step": 465}
{"Episode reward": -51.931797239430466, "Episode length": 999, "Policy Loss": -0.005233218427747488, "Value Loss": 0.001671964069828391, "_runtime": 6028.236566066742, "_timestamp": 1585515106.6572957, "_step": 466}
{"Episode reward": -53.79200567273196, "Episode length": 999, "Policy Loss": -0.010073057375848293, "Value Loss": 0.0017203694442287087, "_runtime": 6029.802736997604, "_timestamp": 1585515108.2234666, "_step": 467}
{"Episode reward": -52.6611765761626, "Episode length": 999, "Policy Loss": -0.004884485621005297, "Value Loss": 0.0017134579829871655, "_runtime": 6031.35475230217, "_timestamp": 1585515109.775482, "_step": 468}
{"Episode reward": -51.76577973514318, "Episode length": 999, "Policy Loss": -0.0074606831185519695, "Value Loss": 0.0016832448309287429, "_runtime": 6032.893927097321, "_timestamp": 1585515111.3146567, "_step": 469}
{"Episode reward": -54.329924707193335, "Episode length": 999, "Policy Loss": -0.010266696102917194, "Value Loss": 0.0017047825967893004, "_runtime": 6034.4569301605225, "_timestamp": 1585515112.8776598, "_step": 470}
{"Episode reward": -54.449472879851726, "Episode length": 999, "Policy Loss": -0.009211678989231586, "Value Loss": 0.0017222461756318808, "_runtime": 6036.01942896843, "_timestamp": 1585515114.4401586, "_step": 471}
{"Episode reward": -55.124950611093084, "Episode length": 999, "Policy Loss": -0.007718061096966267, "Value Loss": 0.0017138003604486585, "_runtime": 6037.577513933182, "_timestamp": 1585515115.9982436, "_step": 472}
{"Episode reward": -54.54977010106786, "Episode length": 999, "Policy Loss": -0.008893460035324097, "Value Loss": 0.001768767717294395, "_runtime": 6039.128923892975, "_timestamp": 1585515117.5496535, "_step": 473}
{"Episode reward": -51.834220278425335, "Episode length": 999, "Policy Loss": -0.004037486854940653, "Value Loss": 0.0016493246657773852, "_runtime": 6040.728876113892, "_timestamp": 1585515119.1496058, "_step": 474}
{"Episode reward": -52.95295487993325, "Episode length": 999, "Policy Loss": -0.005588900297880173, "Value Loss": 0.0017163301818072796, "_runtime": 6042.291781425476, "_timestamp": 1585515120.712511, "_step": 475}
{"Episode reward": -51.96175253734906, "Episode length": 999, "Policy Loss": -0.002552120015025139, "Value Loss": 0.0017195611726492643, "_runtime": 6043.844045639038, "_timestamp": 1585515122.2647753, "_step": 476}
{"Episode reward": -54.10532814034436, "Episode length": 999, "Policy Loss": -0.0059002842754125595, "Value Loss": 0.0017458078218623996, "_runtime": 6045.3967461586, "_timestamp": 1585515123.8174758, "_step": 477}
{"Episode reward": -52.93184688318574, "Episode length": 999, "Policy Loss": -0.004102055914700031, "Value Loss": 0.0016837256262078881, "_runtime": 6046.9467577934265, "_timestamp": 1585515125.3674874, "_step": 478}
{"Episode reward": -54.895974548311536, "Episode length": 999, "Policy Loss": -0.008531731553375721, "Value Loss": 0.001672985847108066, "_runtime": 6048.509183168411, "_timestamp": 1585515126.9299128, "_step": 479}
{"Episode reward": -53.08147608787545, "Episode length": 999, "Policy Loss": -0.0033300670329481363, "Value Loss": 0.0017072808695957065, "_runtime": 6050.073901414871, "_timestamp": 1585515128.494631, "_step": 480}
{"Episode reward": -53.448354045246816, "Episode length": 999, "Policy Loss": -0.006417529657483101, "Value Loss": 0.0016984727699309587, "_runtime": 6051.62381362915, "_timestamp": 1585515130.0445433, "_step": 481}
{"Episode reward": -55.313164353093704, "Episode length": 999, "Policy Loss": -0.009478653781116009, "Value Loss": 0.0017411074368283153, "_runtime": 6053.187666893005, "_timestamp": 1585515131.6083965, "_step": 482}
{"Episode reward": -54.33423235772021, "Episode length": 999, "Policy Loss": -0.008895833045244217, "Value Loss": 0.0017423154786229134, "_runtime": 6054.7417850494385, "_timestamp": 1585515133.1625147, "_step": 483}
{"Episode reward": -52.6028721362891, "Episode length": 999, "Policy Loss": -0.005672874860465527, "Value Loss": 0.0017118084942921996, "_runtime": 6056.290892601013, "_timestamp": 1585515134.7116222, "_step": 484}
{"Episode reward": -52.58683133681076, "Episode length": 999, "Policy Loss": -0.0042170011438429356, "Value Loss": 0.00168835639487952, "_runtime": 6057.852423429489, "_timestamp": 1585515136.273153, "_step": 485}
{"Episode reward": -55.17828397716627, "Episode length": 999, "Policy Loss": -0.010305997915565968, "Value Loss": 0.0017270584357902408, "_runtime": 6059.404550552368, "_timestamp": 1585515137.8252802, "_step": 486}
{"Episode reward": -50.08279726608907, "Episode length": 999, "Policy Loss": -0.0015332000330090523, "Value Loss": 0.001648008357733488, "_runtime": 6060.958096504211, "_timestamp": 1585515139.3788261, "_step": 487}
{"Episode reward": -52.07384737306983, "Episode length": 999, "Policy Loss": -0.0052670324221253395, "Value Loss": 0.0016663630958646536, "_runtime": 6062.509699821472, "_timestamp": 1585515140.9304295, "_step": 488}
{"Episode reward": -52.54317688343602, "Episode length": 999, "Policy Loss": -0.004561782348901033, "Value Loss": 0.0017458226066082716, "_runtime": 6064.108270406723, "_timestamp": 1585515142.529, "_step": 489}
{"Episode reward": -52.98636647371345, "Episode length": 999, "Policy Loss": -0.0038170190528035164, "Value Loss": 0.001659182831645012, "_runtime": 6065.6484525203705, "_timestamp": 1585515144.0691822, "_step": 490}
{"Episode reward": -51.995580281573, "Episode length": 999, "Policy Loss": -0.004437353927642107, "Value Loss": 0.0016659931279718876, "_runtime": 6067.212219715118, "_timestamp": 1585515145.6329494, "_step": 491}
{"Episode reward": -53.70391745558754, "Episode length": 999, "Policy Loss": -0.006598375737667084, "Value Loss": 0.0017143584555014968, "_runtime": 6068.777160167694, "_timestamp": 1585515147.1978898, "_step": 492}
{"Episode reward": -53.72701571579509, "Episode length": 999, "Policy Loss": -0.003671977436169982, "Value Loss": 0.0016922656213864684, "_runtime": 6070.327040672302, "_timestamp": 1585515148.7477703, "_step": 493}
{"Episode reward": -52.07271148142665, "Episode length": 999, "Policy Loss": -0.005043555982410908, "Value Loss": 0.0016659304965287447, "_runtime": 6071.885600566864, "_timestamp": 1585515150.3063302, "_step": 494}
{"Episode reward": -52.93481349461099, "Episode length": 999, "Policy Loss": -0.0045402259565889835, "Value Loss": 0.00168346066493541, "_runtime": 6073.447445392609, "_timestamp": 1585515151.868175, "_step": 495}
{"Episode reward": -51.29994668353518, "Episode length": 999, "Policy Loss": -0.0019414863782003522, "Value Loss": 0.0016857843147590756, "_runtime": 6075.007193803787, "_timestamp": 1585515153.4279234, "_step": 496}
{"Episode reward": -54.284432388211876, "Episode length": 999, "Policy Loss": -0.00683086970821023, "Value Loss": 0.0017423125682398677, "_runtime": 6076.56224489212, "_timestamp": 1585515154.9829745, "_step": 497}
{"Episode reward": -53.830845608915304, "Episode length": 999, "Policy Loss": -0.005636635236442089, "Value Loss": 0.001693017198704183, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293, -2.1641077995300293]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0], "bins": [-7.117430686950684, -6.972410678863525, -6.827390670776367, -6.682371139526367, -6.537351131439209, -6.392331123352051, -6.247311115264893, -6.102291107177734, -5.957271575927734, -5.812251567840576, -5.667231559753418, -5.52221155166626, -5.377191543579102, -5.232172012329102, -5.087151527404785, -4.942131996154785, -4.797111988067627, -4.652091979980469, -4.507072448730469, -4.362051963806152, -4.217032432556152, -4.072012424468994, -3.926992416381836, -3.781972646713257, -3.6369526386260986, -3.4919326305389404, -3.3469128608703613, -3.201892852783203, -3.056872844696045, -2.9118528366088867, -2.7668333053588867, -2.6218132972717285, -2.4767932891845703, -2.331773281097412, -2.186753273010254, -2.041733741760254, -1.8967137336730957, -1.7516937255859375, -1.6066737174987793, -1.461653709411621, -1.316634178161621, -1.171614170074463, -1.0265941619873047, -0.8815741539001465, -0.7365541458129883, -0.5915341377258301, -0.4465146064758301, -0.3014945983886719, -0.15647459030151367, -0.011454582214355469, 0.13356542587280273, 0.27858495712280273, 0.42360496520996094, 0.5686249732971191, 0.7136449813842773, 0.8586649894714355, 1.0036849975585938, 1.1487045288085938, 1.2937250137329102, 1.4387445449829102, 1.5837640762329102, 1.7287845611572266, 1.8738040924072266, 2.018824577331543, 2.163844108581543]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.23876996338367462, -0.19713366031646729, -0.15549737215042114, -0.1138610765337944, -0.07222478091716766, -0.03058849275112152, 0.011047810316085815, 0.05268411338329315, 0.0943204015493393, 0.13595668971538544, 0.17759297788143158, 0.2192292958498001, 0.26086556911468506, 0.302501916885376, 0.3441382050514221, 0.38577449321746826, 0.4274107813835144, 0.46904706954956055, 0.5106833577156067, 0.5523196458816528, 0.593955934047699, 0.6355922818183899, 0.677228569984436, 0.7188648581504822, 0.7605011463165283, 0.8021374344825745, 0.8437737822532654, 0.8854100108146667, 0.9270463585853577, 0.968682587146759, 1.0103188753128052, 1.0519551038742065, 1.0935914516448975, 1.1352277994155884, 1.1768640279769897, 1.2185003757476807, 1.260136604309082, 1.301772952079773, 1.3434091806411743, 1.3850455284118652, 1.4266817569732666, 1.4683181047439575, 1.5099544525146484, 1.5515906810760498, 1.5932270288467407, 1.634863257408142, 1.676499605178833, 1.7181358337402344, 1.7597721815109253, 1.8014085292816162, 1.8430447578430176, 1.884680986404419, 1.9263174533843994, 1.9679536819458008, 2.009589910507202, 2.0512261390686035, 2.092862606048584, 2.1344988346099854, 2.1761350631713867, 2.217771530151367, 2.2594077587127686, 2.30104398727417, 2.3426802158355713, 2.3843166828155518, 2.425952911376953]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 10.0, 16.0, 27.0, 28.0, 70.0, 231.0, 49.0, 11.0, 9.0, 6.0, 9.0, 4.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.9981740713119507, -1.9247205257415771, -1.8512670993804932, -1.7778135538101196, -1.7043601274490356, -1.630906581878662, -1.5574531555175781, -1.4839996099472046, -1.410546064376831, -1.337092638015747, -1.263639211654663, -1.1901856660842896, -1.116732120513916, -1.043278694152832, -0.9698251485824585, -0.8963717222213745, -0.822918176651001, -0.7494646310806274, -0.6760112047195435, -0.6025576591491699, -0.5291042327880859, -0.4556506872177124, -0.3821972608566284, -0.3087437152862549, -0.23529016971588135, -0.16183674335479736, -0.08838319778442383, -0.014929771423339844, 0.05852377414703369, 0.13197720050811768, 0.20543062686920166, 0.27888429164886475, 0.35233771800994873, 0.4257911443710327, 0.4992448091506958, 0.5726982355117798, 0.6461516618728638, 0.7196050882339478, 0.7930587530136108, 0.8665121793746948, 0.9399656057357788, 1.013419270515442, 1.0868726968765259, 1.1603261232376099, 1.2337795495986938, 1.307233214378357, 1.380686640739441, 1.454140067100525, 1.527593731880188, 1.601047158241272, 1.674500584602356, 1.74795401096344, 1.821407675743103, 1.894861102104187, 1.968314528465271, 2.0417680740356445, 2.1152215003967285, 2.1886749267578125, 2.2621283531188965, 2.3355817794799805, 2.4090352058410645, 2.4824891090393066, 2.5559425354003906, 2.6293959617614746, 2.7028493881225586]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-3.4156785011291504, -3.29472017288208, -3.1737618446350098, -3.0528032779693604, -2.93184494972229, -2.8108866214752197, -2.6899280548095703, -2.5689697265625, -2.4480113983154297, -2.3270530700683594, -2.206094741821289, -2.0851361751556396, -1.9641778469085693, -1.843219518661499, -1.7222610712051392, -1.6013026237487793, -1.480344295501709, -1.3593859672546387, -1.2384276390075684, -1.117469072341919, -0.9965107440948486, -0.8755524158477783, -0.7545938491821289, -0.6336355209350586, -0.5126771926879883, -0.39171886444091797, -0.27076053619384766, -0.14980196952819824, -0.02884364128112793, 0.09211468696594238, 0.2130732536315918, 0.3340315818786621, 0.4549899101257324, 0.5759482383728027, 0.696906566619873, 0.8178648948669434, 0.9388232231140137, 1.0597820281982422, 1.1807403564453125, 1.3016986846923828, 1.4226570129394531, 1.5436153411865234, 1.6645736694335938, 1.785531997680664, 1.9064908027648926, 2.027449131011963, 2.148407459259033, 2.2693657875061035, 2.390324115753174, 2.511282444000244, 2.6322407722473145, 2.7531991004943848, 2.874157428741455, 2.9951162338256836, 3.116074562072754, 3.237032890319824, 3.3579912185668945, 3.478949546813965, 3.599907875061035, 3.7208662033081055, 3.841825008392334, 3.9627833366394043, 4.083741664886475, 4.204699993133545, 4.325658321380615]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 2.0, 5.0, 3.0, 2.0, 2.0, 8.0, 5.0, 7.0, 4.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1.2094708681106567, -1.1756932735443115, -1.1419156789779663, -1.108138084411621, -1.0743604898452759, -1.0405828952789307, -1.0068053007125854, -0.973027765750885, -0.9392501711845398, -0.9054725766181946, -0.8716949820518494, -0.8379174470901489, -0.8041398525238037, -0.7703622579574585, -0.7365846633911133, -0.7028070688247681, -0.6690294742584229, -0.6352518796920776, -0.6014742851257324, -0.5676966905593872, -0.533919095993042, -0.5001415610313416, -0.46636396646499634, -0.4325863718986511, -0.3988087773323059, -0.3650311827659607, -0.3312535881996155, -0.29747599363327026, -0.2636984586715698, -0.2299208641052246, -0.1961432695388794, -0.16236567497253418, -0.12858808040618896, -0.09481048583984375, -0.061032891273498535, -0.02725529670715332, 0.0065222978591918945, 0.04029989242553711, 0.07407748699188232, 0.10785508155822754, 0.14163267612457275, 0.17541015148162842, 0.20918774604797363, 0.24296534061431885, 0.27674293518066406, 0.3105205297470093, 0.3442981243133545, 0.3780757188796997, 0.4118533134460449, 0.44563090801239014, 0.47940850257873535, 0.5131860971450806, 0.5469636917114258, 0.580741286277771, 0.6145188808441162, 0.6482964754104614, 0.6820739507675171, 0.7158515453338623, 0.7496291399002075, 0.7834067344665527, 0.817184329032898, 0.8509620428085327, 0.8847395181655884, 0.9185172319412231, 0.9522947072982788]}, "_runtime": 6078.124665975571, "_timestamp": 1585515156.5453956, "_step": 498}
{"Episode reward": -54.89203871640885, "Episode length": 999, "Policy Loss": -0.007328952196985483, "Value Loss": 0.0017180328723043203, "_runtime": 6078.124665975571, "_timestamp": 1585515156.5453956, "_step": 499}
