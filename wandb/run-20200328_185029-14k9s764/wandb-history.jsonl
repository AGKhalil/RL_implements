{"Episode reward": -98.906853996173, "Episode length": 999, "Policy Loss": -0.13272510468959808, "Value Loss": 0.02986082434654236, "_runtime": 17.29128670692444, "_timestamp": 1585421446.2552705, "_step": 0}
{"Episode reward": -91.64357721265067, "Episode length": 999, "Policy Loss": -0.12951284646987915, "Value Loss": 0.02468968741595745, "_runtime": 18.918437004089355, "_timestamp": 1585421447.8824208, "_step": 1}
{"Episode reward": -106.12191225986724, "Episode length": 999, "Policy Loss": -0.15829332172870636, "Value Loss": 0.033204928040504456, "_runtime": 20.656468152999878, "_timestamp": 1585421449.620452, "_step": 2}
{"Episode reward": -100.57907961039199, "Episode length": 999, "Policy Loss": -0.1388971358537674, "Value Loss": 0.03374570608139038, "_runtime": 22.172860860824585, "_timestamp": 1585421451.1368446, "_step": 3}
{"Episode reward": -102.23533471690297, "Episode length": 999, "Policy Loss": -0.1431870460510254, "Value Loss": 0.030034249648451805, "_runtime": 23.8253333568573, "_timestamp": 1585421452.7893171, "_step": 4}
{"Episode reward": -105.41054774091936, "Episode length": 999, "Policy Loss": -0.14093254506587982, "Value Loss": 0.03452054411172867, "_runtime": 25.48486566543579, "_timestamp": 1585421454.4488494, "_step": 5}
{"Episode reward": -103.53042205461738, "Episode length": 999, "Policy Loss": -0.14080357551574707, "Value Loss": 0.031085478141903877, "_runtime": 26.97109365463257, "_timestamp": 1585421455.9350774, "_step": 6}
{"Episode reward": -99.03465702693202, "Episode length": 999, "Policy Loss": -0.14356526732444763, "Value Loss": 0.028038041666150093, "_runtime": 28.6353440284729, "_timestamp": 1585421457.5993278, "_step": 7}
{"Episode reward": -106.61804788665245, "Episode length": 999, "Policy Loss": -0.1456029713153839, "Value Loss": 0.03286374360322952, "_runtime": 30.18646812438965, "_timestamp": 1585421459.150452, "_step": 8}
{"Episode reward": -104.51558370467023, "Episode length": 999, "Policy Loss": -0.15241532027721405, "Value Loss": 0.03344147279858589, "_runtime": 31.668442726135254, "_timestamp": 1585421460.6324265, "_step": 9}
{"Episode reward": -103.56784371533735, "Episode length": 999, "Policy Loss": -0.14356639981269836, "Value Loss": 0.0347447544336319, "_runtime": 33.41712164878845, "_timestamp": 1585421462.3811054, "_step": 10}
{"Episode reward": -106.74030119303103, "Episode length": 999, "Policy Loss": -0.16015839576721191, "Value Loss": 0.03682762756943703, "_runtime": 35.31503939628601, "_timestamp": 1585421464.2790232, "_step": 11}
{"Episode reward": -101.65905338430811, "Episode length": 999, "Policy Loss": -0.14158378541469574, "Value Loss": 0.028843382373452187, "_runtime": 36.94110631942749, "_timestamp": 1585421465.90509, "_step": 12}
{"Episode reward": -92.85830410281473, "Episode length": 999, "Policy Loss": -0.1266401708126068, "Value Loss": 0.026068508625030518, "_runtime": 38.62389349937439, "_timestamp": 1585421467.5878773, "_step": 13}
{"Episode reward": -108.95135035344921, "Episode length": 999, "Policy Loss": -0.15311595797538757, "Value Loss": 0.034007780253887177, "_runtime": 40.12973618507385, "_timestamp": 1585421469.09372, "_step": 14}
{"Episode reward": -96.93774960009858, "Episode length": 999, "Policy Loss": -0.1267942488193512, "Value Loss": 0.027709130197763443, "_runtime": 41.66483736038208, "_timestamp": 1585421470.6288211, "_step": 15}
{"Episode reward": -98.45416518896464, "Episode length": 999, "Policy Loss": -0.13794474303722382, "Value Loss": 0.028205977752804756, "_runtime": 43.245344400405884, "_timestamp": 1585421472.2093282, "_step": 16}
{"Episode reward": -99.71173262832441, "Episode length": 999, "Policy Loss": -0.13836468756198883, "Value Loss": 0.033294156193733215, "_runtime": 44.89304280281067, "_timestamp": 1585421473.8570266, "_step": 17}
{"Episode reward": -102.23530323589262, "Episode length": 999, "Policy Loss": -0.14875131845474243, "Value Loss": 0.029512861743569374, "_runtime": 46.496665954589844, "_timestamp": 1585421475.4606497, "_step": 18}
{"Episode reward": -98.23600288760349, "Episode length": 999, "Policy Loss": -0.1318141222000122, "Value Loss": 0.03193041309714317, "_runtime": 48.21656322479248, "_timestamp": 1585421477.180547, "_step": 19}
{"Episode reward": -96.27783309427038, "Episode length": 999, "Policy Loss": -0.12985917925834656, "Value Loss": 0.026075473055243492, "_runtime": 49.84833884239197, "_timestamp": 1585421478.8123226, "_step": 20}
{"Episode reward": -102.14245644065747, "Episode length": 999, "Policy Loss": -0.1368008255958557, "Value Loss": 0.03856462612748146, "_runtime": 51.40657043457031, "_timestamp": 1585421480.3705542, "_step": 21}
{"Episode reward": -105.52920507032128, "Episode length": 999, "Policy Loss": -0.14834585785865784, "Value Loss": 0.029650680720806122, "_runtime": 53.03110480308533, "_timestamp": 1585421481.9950886, "_step": 22}
{"Episode reward": -101.75461341655178, "Episode length": 999, "Policy Loss": -0.14885438978672028, "Value Loss": 0.029329556971788406, "_runtime": 54.647144079208374, "_timestamp": 1585421483.6111279, "_step": 23}
{"Episode reward": -109.20615778756893, "Episode length": 999, "Policy Loss": -0.14835889637470245, "Value Loss": 0.03666402027010918, "_runtime": 56.33414626121521, "_timestamp": 1585421485.29813, "_step": 24}
{"Episode reward": -104.40094643266805, "Episode length": 999, "Policy Loss": -0.14469411969184875, "Value Loss": 0.034282129257917404, "_runtime": 57.899027824401855, "_timestamp": 1585421486.8630116, "_step": 25}
{"Episode reward": -111.38261672242096, "Episode length": 999, "Policy Loss": -0.1654323935508728, "Value Loss": 0.03668857738375664, "_runtime": 59.433149099349976, "_timestamp": 1585421488.3971329, "_step": 26}
{"Episode reward": -106.14482933879862, "Episode length": 999, "Policy Loss": -0.15030278265476227, "Value Loss": 0.03424599766731262, "_runtime": 61.016542196273804, "_timestamp": 1585421489.980526, "_step": 27}
{"Episode reward": -103.90962349108955, "Episode length": 999, "Policy Loss": -0.15189409255981445, "Value Loss": 0.0338367260992527, "_runtime": 62.67162013053894, "_timestamp": 1585421491.635604, "_step": 28}
{"Episode reward": -109.45308532012058, "Episode length": 999, "Policy Loss": -0.15733981132507324, "Value Loss": 0.039385125041007996, "_runtime": 64.29861283302307, "_timestamp": 1585421493.2625966, "_step": 29}
{"Episode reward": -102.41477276921586, "Episode length": 999, "Policy Loss": -0.14146806299686432, "Value Loss": 0.030937204137444496, "_runtime": 65.95882272720337, "_timestamp": 1585421494.9228065, "_step": 30}
{"Episode reward": -100.89058725326183, "Episode length": 999, "Policy Loss": -0.13122884929180145, "Value Loss": 0.03481443226337433, "_runtime": 67.02931547164917, "_timestamp": 1585421495.9932992, "_step": 31}
{"Episode reward": 22.85100593407769, "Episode length": 716, "Policy Loss": -0.02615574561059475, "Value Loss": 14.01865291595459, "_runtime": 68.58076786994934, "_timestamp": 1585421497.5447516, "_step": 32}
{"Episode reward": -105.83574075352627, "Episode length": 999, "Policy Loss": -0.14950816333293915, "Value Loss": 0.03473607450723648, "_runtime": 70.17159724235535, "_timestamp": 1585421499.135581, "_step": 33}
{"Episode reward": -103.49178839615463, "Episode length": 999, "Policy Loss": -0.14800713956356049, "Value Loss": 0.032699521631002426, "_runtime": 71.6797821521759, "_timestamp": 1585421500.643766, "_step": 34}
{"Episode reward": -105.97360996374996, "Episode length": 999, "Policy Loss": -0.1462096869945526, "Value Loss": 0.03239396587014198, "_runtime": 73.24248790740967, "_timestamp": 1585421502.2064717, "_step": 35}
{"Episode reward": -102.91556443204522, "Episode length": 999, "Policy Loss": -0.14652206003665924, "Value Loss": 0.03335629403591156, "_runtime": 74.97209620475769, "_timestamp": 1585421503.93608, "_step": 36}
{"Episode reward": -108.57922495597317, "Episode length": 999, "Policy Loss": -0.14545844495296478, "Value Loss": 0.034698907285928726, "_runtime": 76.58150625228882, "_timestamp": 1585421505.54549, "_step": 37}
{"Episode reward": -102.78359238729894, "Episode length": 999, "Policy Loss": -0.14519375562667847, "Value Loss": 0.03279383108019829, "_runtime": 78.1451256275177, "_timestamp": 1585421507.1091094, "_step": 38}
{"Episode reward": -100.96217000425045, "Episode length": 999, "Policy Loss": -0.1346285045146942, "Value Loss": 0.03025772050023079, "_runtime": 79.78828835487366, "_timestamp": 1585421508.7522721, "_step": 39}
{"Episode reward": -102.79591757091663, "Episode length": 999, "Policy Loss": -0.14581026136875153, "Value Loss": 0.03141777589917183, "_runtime": 81.31429743766785, "_timestamp": 1585421510.2782812, "_step": 40}
{"Episode reward": -105.13512345570486, "Episode length": 999, "Policy Loss": -0.1499910056591034, "Value Loss": 0.03200199082493782, "_runtime": 82.89102053642273, "_timestamp": 1585421511.8550043, "_step": 41}
{"Episode reward": -105.18181700519898, "Episode length": 999, "Policy Loss": -0.14879454672336578, "Value Loss": 0.03433051332831383, "_runtime": 84.52583837509155, "_timestamp": 1585421513.4898221, "_step": 42}
{"Episode reward": -106.20952517762073, "Episode length": 999, "Policy Loss": -0.161027729511261, "Value Loss": 0.03858737647533417, "_runtime": 86.1402575969696, "_timestamp": 1585421515.1042414, "_step": 43}
{"Episode reward": -111.66163404467095, "Episode length": 999, "Policy Loss": -0.1520884931087494, "Value Loss": 0.03717396408319473, "_runtime": 88.13219499588013, "_timestamp": 1585421517.0961788, "_step": 44}
{"Episode reward": -122.87812334865842, "Episode length": 999, "Policy Loss": -0.1838817000389099, "Value Loss": 0.04110763221979141, "_runtime": 89.77037262916565, "_timestamp": 1585421518.7343564, "_step": 45}
{"Episode reward": -111.80387397630076, "Episode length": 999, "Policy Loss": -0.15317663550376892, "Value Loss": 0.04057636857032776, "_runtime": 91.3586802482605, "_timestamp": 1585421520.322664, "_step": 46}
{"Episode reward": -8.641597910130173, "Episode length": 977, "Policy Loss": -0.05827716737985611, "Value Loss": 10.23697566986084, "_runtime": 92.90262484550476, "_timestamp": 1585421521.8666086, "_step": 47}
{"Episode reward": -107.81137076869265, "Episode length": 999, "Policy Loss": -0.14507871866226196, "Value Loss": 0.03815854340791702, "_runtime": 94.47859072685242, "_timestamp": 1585421523.4425745, "_step": 48}
{"Episode reward": -118.66451426856784, "Episode length": 999, "Policy Loss": -0.1786208599805832, "Value Loss": 0.03973749652504921, "_runtime": 96.16488218307495, "_timestamp": 1585421525.128866, "_step": 49}
{"Episode reward": -117.18084134863759, "Episode length": 999, "Policy Loss": -0.1588038057088852, "Value Loss": 0.04353763908147812, "_runtime": 97.86106491088867, "_timestamp": 1585421526.8250487, "_step": 50}
{"Episode reward": -118.87842873519686, "Episode length": 999, "Policy Loss": -0.16803871095180511, "Value Loss": 0.04139012470841408, "_runtime": 99.46226167678833, "_timestamp": 1585421528.4262455, "_step": 51}
{"Episode reward": -3.7336685301392265, "Episode length": 916, "Policy Loss": 0.04530045762658119, "Value Loss": 10.972305297851562, "_runtime": 100.97324299812317, "_timestamp": 1585421529.9372268, "_step": 52}
{"Episode reward": -8.598171616564116, "Episode length": 967, "Policy Loss": 0.045572176575660706, "Value Loss": 10.384706497192383, "_runtime": 102.55704069137573, "_timestamp": 1585421531.5210245, "_step": 53}
{"Episode reward": -114.63675101453312, "Episode length": 999, "Policy Loss": -0.15809045732021332, "Value Loss": 0.03937884420156479, "_runtime": 104.2085473537445, "_timestamp": 1585421533.1725311, "_step": 54}
{"Episode reward": -118.83892913589476, "Episode length": 999, "Policy Loss": -0.16912537813186646, "Value Loss": 0.039728276431560516, "_runtime": 105.93252754211426, "_timestamp": 1585421534.8965113, "_step": 55}
{"Episode reward": -118.3682683599236, "Episode length": 999, "Policy Loss": -0.1642082780599594, "Value Loss": 0.04020143672823906, "_runtime": 107.75129914283752, "_timestamp": 1585421536.715283, "_step": 56}
{"Episode reward": -126.98197651535146, "Episode length": 999, "Policy Loss": -0.1847582757472992, "Value Loss": 0.04807969182729721, "_runtime": 109.45819211006165, "_timestamp": 1585421538.422176, "_step": 57}
{"Episode reward": -118.28017507700612, "Episode length": 999, "Policy Loss": -0.16801467537879944, "Value Loss": 0.035368505865335464, "_runtime": 110.68690133094788, "_timestamp": 1585421539.650885, "_step": 58}
{"Episode reward": 10.19144494494904, "Episode length": 746, "Policy Loss": -0.027390748262405396, "Value Loss": 13.386869430541992, "_runtime": 112.27991724014282, "_timestamp": 1585421541.243901, "_step": 59}
{"Episode reward": -120.14616492897237, "Episode length": 999, "Policy Loss": -0.1650441437959671, "Value Loss": 0.04478001967072487, "_runtime": 113.78903388977051, "_timestamp": 1585421542.7530177, "_step": 60}
{"Episode reward": -124.78289210855641, "Episode length": 999, "Policy Loss": -0.1749284416437149, "Value Loss": 0.04505666717886925, "_runtime": 115.64536023139954, "_timestamp": 1585421544.609344, "_step": 61}
{"Episode reward": -116.32934394837416, "Episode length": 999, "Policy Loss": -0.16099144518375397, "Value Loss": 0.0387033186852932, "_runtime": 117.15697073936462, "_timestamp": 1585421546.1209545, "_step": 62}
{"Episode reward": -116.08573593192921, "Episode length": 999, "Policy Loss": -0.16580075025558472, "Value Loss": 0.03858579695224762, "_runtime": 118.70979046821594, "_timestamp": 1585421547.6737742, "_step": 63}
{"Episode reward": -107.30823878239751, "Episode length": 999, "Policy Loss": -0.14427486062049866, "Value Loss": 0.031596481800079346, "_runtime": 120.39544558525085, "_timestamp": 1585421549.3594294, "_step": 64}
{"Episode reward": -116.6764969518816, "Episode length": 999, "Policy Loss": -0.16429467499256134, "Value Loss": 0.03983602672815323, "_runtime": 122.105633020401, "_timestamp": 1585421551.0696168, "_step": 65}
{"Episode reward": -108.58040913751184, "Episode length": 999, "Policy Loss": -0.15678176283836365, "Value Loss": 0.03259894251823425, "_runtime": 123.76732850074768, "_timestamp": 1585421552.7313123, "_step": 66}
{"Episode reward": -118.27965096462482, "Episode length": 999, "Policy Loss": -0.15932166576385498, "Value Loss": 0.03830417990684509, "_runtime": 125.43191003799438, "_timestamp": 1585421554.3958938, "_step": 67}
{"Episode reward": -109.05415140159687, "Episode length": 999, "Policy Loss": -0.14851528406143188, "Value Loss": 0.03178280219435692, "_runtime": 127.1114399433136, "_timestamp": 1585421556.0754237, "_step": 68}
{"Episode reward": -108.54149753860781, "Episode length": 999, "Policy Loss": -0.14465510845184326, "Value Loss": 0.034708257764577866, "_runtime": 128.45277905464172, "_timestamp": 1585421557.4167628, "_step": 69}
{"Episode reward": 8.174790775665997, "Episode length": 805, "Policy Loss": 0.0766938179731369, "Value Loss": 12.47904109954834, "_runtime": 129.99536061286926, "_timestamp": 1585421558.9593444, "_step": 70}
{"Episode reward": -119.46696217818598, "Episode length": 999, "Policy Loss": -0.16895247995853424, "Value Loss": 0.040498215705156326, "_runtime": 131.60931134223938, "_timestamp": 1585421560.573295, "_step": 71}
{"Episode reward": -122.27257105764431, "Episode length": 999, "Policy Loss": -0.17886850237846375, "Value Loss": 0.04214770719408989, "_runtime": 133.19325733184814, "_timestamp": 1585421562.157241, "_step": 72}
{"Episode reward": -111.94970258874746, "Episode length": 999, "Policy Loss": -0.1555863916873932, "Value Loss": 0.03988629952073097, "_runtime": 134.89528584480286, "_timestamp": 1585421563.8592696, "_step": 73}
{"Episode reward": -114.08926012158352, "Episode length": 999, "Policy Loss": -0.14783251285552979, "Value Loss": 0.03892633318901062, "_runtime": 136.53756761550903, "_timestamp": 1585421565.5015514, "_step": 74}
{"Episode reward": -121.87568848919388, "Episode length": 999, "Policy Loss": -0.1790183037519455, "Value Loss": 0.04579125717282295, "_runtime": 137.6222858428955, "_timestamp": 1585421566.5862696, "_step": 75}
{"Episode reward": 22.46345495386157, "Episode length": 651, "Policy Loss": 0.04636617377400398, "Value Loss": 15.426851272583008, "_runtime": 139.16022872924805, "_timestamp": 1585421568.1242125, "_step": 76}
{"Episode reward": -120.43813504759073, "Episode length": 999, "Policy Loss": -0.1704970747232437, "Value Loss": 0.04474104568362236, "_runtime": 140.7306683063507, "_timestamp": 1585421569.694652, "_step": 77}
{"Episode reward": -116.91497080880772, "Episode length": 999, "Policy Loss": -0.15906992554664612, "Value Loss": 0.03878220170736313, "_runtime": 142.3762128353119, "_timestamp": 1585421571.3401966, "_step": 78}
{"Episode reward": -111.6881060602498, "Episode length": 999, "Policy Loss": -0.14580541849136353, "Value Loss": 0.033929791301488876, "_runtime": 144.01069045066833, "_timestamp": 1585421572.9746742, "_step": 79}
{"Episode reward": -130.50743344989394, "Episode length": 999, "Policy Loss": -0.18798129260540009, "Value Loss": 0.052268169820308685, "_runtime": 145.7296998500824, "_timestamp": 1585421574.6936836, "_step": 80}
{"Episode reward": -124.03600279869578, "Episode length": 999, "Policy Loss": -0.17347221076488495, "Value Loss": 0.043441612273454666, "_runtime": 147.36012864112854, "_timestamp": 1585421576.3241124, "_step": 81}
{"Episode reward": -124.99716431418634, "Episode length": 999, "Policy Loss": -0.17226789891719818, "Value Loss": 0.04272975027561188, "_runtime": 148.95409870147705, "_timestamp": 1585421577.9180825, "_step": 82}
{"Episode reward": -120.79437525042714, "Episode length": 999, "Policy Loss": -0.17719171941280365, "Value Loss": 0.044577013701200485, "_runtime": 150.594420671463, "_timestamp": 1585421579.5584044, "_step": 83}
{"Episode reward": -114.31224766599723, "Episode length": 999, "Policy Loss": -0.15711286664009094, "Value Loss": 0.038431767374277115, "_runtime": 152.18871140480042, "_timestamp": 1585421581.1526952, "_step": 84}
{"Episode reward": -112.84181512425722, "Episode length": 999, "Policy Loss": -0.15371419489383698, "Value Loss": 0.03541719168424606, "_runtime": 153.75515985488892, "_timestamp": 1585421582.7191436, "_step": 85}
{"Episode reward": -123.13115434803608, "Episode length": 999, "Policy Loss": -0.17152465879917145, "Value Loss": 0.044146955013275146, "_runtime": 155.4178273677826, "_timestamp": 1585421584.3818111, "_step": 86}
{"Episode reward": -124.47726155677148, "Episode length": 999, "Policy Loss": -0.1771208792924881, "Value Loss": 0.04734719917178154, "_runtime": 157.0103394985199, "_timestamp": 1585421585.9743233, "_step": 87}
{"Episode reward": -116.83762865862629, "Episode length": 999, "Policy Loss": -0.16313743591308594, "Value Loss": 0.04122743010520935, "_runtime": 158.64957737922668, "_timestamp": 1585421587.6135612, "_step": 88}
{"Episode reward": -120.09356173447021, "Episode length": 999, "Policy Loss": -0.169234961271286, "Value Loss": 0.040942560881376266, "_runtime": 159.8829140663147, "_timestamp": 1585421588.8468978, "_step": 89}
{"Episode reward": 8.182132586215957, "Episode length": 758, "Policy Loss": 0.05010802298784256, "Value Loss": 13.22457218170166, "_runtime": 161.61747574806213, "_timestamp": 1585421590.5814595, "_step": 90}
{"Episode reward": -118.2781955332365, "Episode length": 999, "Policy Loss": -0.16931211948394775, "Value Loss": 0.042672451585531235, "_runtime": 162.64997458457947, "_timestamp": 1585421591.6139584, "_step": 91}
{"Episode reward": 26.647802075929732, "Episode length": 608, "Policy Loss": 0.09242544323205948, "Value Loss": 16.483299255371094, "_runtime": 164.25888466835022, "_timestamp": 1585421593.2228684, "_step": 92}
{"Episode reward": -117.35327329210685, "Episode length": 999, "Policy Loss": -0.177472323179245, "Value Loss": 0.04183153435587883, "_runtime": 166.05761909484863, "_timestamp": 1585421595.0216029, "_step": 93}
{"Episode reward": -113.1774658949305, "Episode length": 999, "Policy Loss": -0.15681833028793335, "Value Loss": 0.036591626703739166, "_runtime": 167.69721245765686, "_timestamp": 1585421596.6611962, "_step": 94}
{"Episode reward": -127.42840030111338, "Episode length": 999, "Policy Loss": -0.18029046058654785, "Value Loss": 0.05197921022772789, "_runtime": 169.32029628753662, "_timestamp": 1585421598.28428, "_step": 95}
{"Episode reward": -23.74343580398491, "Episode length": 984, "Policy Loss": -0.014501803554594517, "Value Loss": 10.22201156616211, "_runtime": 170.90134716033936, "_timestamp": 1585421599.865331, "_step": 96}
{"Episode reward": -110.43540793624125, "Episode length": 999, "Policy Loss": -0.14154991507530212, "Value Loss": 0.03351955860853195, "_runtime": 172.50941276550293, "_timestamp": 1585421601.4733965, "_step": 97}
{"Episode reward": -119.82751268042591, "Episode length": 999, "Policy Loss": -0.1676812618970871, "Value Loss": 0.04206286743283272, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562, -140.00723266601562]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-122.31988525390625, -119.20545959472656, -116.0910415649414, -112.97661590576172, -109.86219787597656, -106.74777221679688, -103.63334655761719, -100.51892852783203, -97.40451049804688, -94.29008483886719, -91.1756591796875, -88.06124114990234, -84.94681549072266, -81.8323974609375, -78.71797180175781, -75.60354614257812, -72.48912811279297, -69.37471008300781, -66.26028442382812, -63.1458625793457, -60.03144073486328, -56.917015075683594, -53.80259704589844, -50.68817138671875, -47.57374572753906, -44.459327697753906, -41.34490203857422, -38.23048400878906, -35.116058349609375, -32.00164031982422, -28.88721466064453, -25.772796630859375, -22.658370971679688, -19.5439453125, -16.429527282714844, -13.315101623535156, -10.20068359375, -7.0862579345703125, -3.9718399047851562, -0.8574142456054688, 2.2570037841796875, 5.371429443359375, 8.485855102539062, 11.60028076171875, 14.714691162109375, 17.829116821289062, 20.94354248046875, 24.057968139648438, 27.172393798828125, 30.28680419921875, 33.40122985839844, 36.515655517578125, 39.63008117675781, 42.74449157714844, 45.858917236328125, 48.97334289550781, 52.0877685546875, 55.20219421386719, 58.31660461425781, 61.4310302734375, 64.54545593261719, 67.65988159179688, 70.7742919921875, 73.88871765136719, 77.00314331054688]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-68.27335357666016, -66.15116119384766, -64.02896881103516, -61.906776428222656, -59.784584045410156, -57.662391662597656, -55.54020309448242, -53.41801071166992, -51.29581832885742, -49.17362594604492, -47.05143356323242, -44.92924499511719, -42.80705261230469, -40.68486022949219, -38.56266784667969, -36.44047546386719, -34.31828308105469, -32.19609069824219, -30.073898315429688, -27.951705932617188, -25.829513549804688, -23.707324981689453, -21.585132598876953, -19.462940216064453, -17.340747833251953, -15.218555450439453, -13.096363067626953, -10.974170684814453, -8.851982116699219, -6.729789733886719, -4.607597351074219, -2.4854049682617188, -0.36321258544921875, 1.7589797973632812, 3.8811721801757812, 6.003364562988281, 8.125556945800781, 10.247749328613281, 12.369941711425781, 14.492134094238281, 16.61432647705078, 18.73651123046875, 20.85870361328125, 22.98089599609375, 25.10308837890625, 27.22528076171875, 29.34747314453125, 31.46966552734375, 33.59185791015625, 35.71405029296875, 37.83624267578125, 39.95843505859375, 42.08062744140625, 44.20281982421875, 46.32501220703125, 48.44720458984375, 50.56938934326172, 52.69158172607422, 54.81377410888672, 56.93596649169922, 59.05815887451172, 61.18035125732422, 63.30254364013672, 65.42473602294922, 67.54692840576172]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 6.0, 4.0, 5.0, 3.0, 4.0, 7.0, 4.0, 7.0, 15.0, 14.0, 30.0, 26.0, 27.0, 35.0, 36.0, 48.0, 40.0, 35.0, 17.0, 20.0, 10.0, 11.0, 11.0, 9.0, 11.0, 9.0, 9.0, 3.0, 12.0, 7.0, 3.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-58.435909271240234, -56.6195068359375, -54.8031005859375, -52.986698150634766, -51.170291900634766, -49.35388946533203, -47.53748321533203, -45.7210807800293, -43.90467834472656, -42.08827209472656, -40.27186584472656, -38.45546340942383, -36.639060974121094, -34.822654724121094, -33.00625228881836, -31.189847946166992, -29.373443603515625, -27.557039260864258, -25.74063491821289, -23.924232482910156, -22.107826232910156, -20.291423797607422, -18.475017547607422, -16.658615112304688, -14.842212677001953, -13.025806427001953, -11.209403991699219, -9.392997741699219, -7.576595306396484, -5.760189056396484, -3.94378662109375, -2.12738037109375, -0.3109779357910156, 1.5054244995117188, 3.3218307495117188, 5.138233184814453, 6.954639434814453, 8.771045684814453, 10.587444305419922, 12.403850555419922, 14.220256805419922, 16.03665542602539, 17.85306167602539, 19.66946792602539, 21.48587417602539, 23.30227279663086, 25.11867904663086, 26.93508529663086, 28.751483917236328, 30.567890167236328, 32.38429641723633, 34.20070266723633, 36.0171012878418, 37.8335075378418, 39.6499137878418, 41.4663200378418, 43.282718658447266, 45.099124908447266, 46.915531158447266, 48.731929779052734, 50.548336029052734, 52.364742279052734, 54.181148529052734, 55.9975471496582, 57.8139533996582]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-54.479434967041016, -53.224273681640625, -51.969112396240234, -50.713951110839844, -49.45878982543945, -48.20362854003906, -46.94846725463867, -45.69330596923828, -44.43814468383789, -43.1829833984375, -41.92782211303711, -40.67266082763672, -39.41749572753906, -38.16233825683594, -36.90717315673828, -35.652015686035156, -34.3968505859375, -33.141693115234375, -31.88652992248535, -30.63136863708496, -29.37620735168457, -28.12104606628418, -26.86588478088379, -25.6107234954834, -24.355560302734375, -23.100399017333984, -21.845237731933594, -20.590076446533203, -19.334915161132812, -18.079753875732422, -16.82459259033203, -15.56943130493164, -14.31427001953125, -13.05910873413086, -11.803947448730469, -10.548786163330078, -9.293624877929688, -8.038463592529297, -6.783302307128906, -5.528141021728516, -4.272979736328125, -3.0178184509277344, -1.7626571655273438, -0.5074958801269531, 0.7476654052734375, 2.002826690673828, 3.2579879760742188, 4.513149261474609, 5.768314361572266, 7.023475646972656, 8.278636932373047, 9.533794403076172, 10.788959503173828, 12.044116973876953, 13.29928207397461, 14.554439544677734, 15.80960464477539, 17.064762115478516, 18.319927215576172, 19.575084686279297, 20.830249786376953, 22.085407257080078, 23.340572357177734, 24.59572982788086, 25.850894927978516]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 33.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-13.59260082244873, -12.932226181030273, -12.271852493286133, -11.611477851867676, -10.951103210449219, -10.290728569030762, -9.630353927612305, -8.969980239868164, -8.309605598449707, -7.64923095703125, -6.988856792449951, -6.328482627868652, -5.668107986450195, -5.007733345031738, -4.347359657287598, -3.6869850158691406, -3.0266103744506836, -2.3662357330322266, -1.7058610916137695, -1.045487403869629, -0.3851127624511719, 0.27526187896728516, 0.9356355667114258, 1.5960102081298828, 2.25638484954834, 2.9167585372924805, 3.577134132385254, 4.2375078201293945, 4.897881507873535, 5.558257102966309, 6.218630790710449, 6.879006385803223, 7.539380073547363, 8.199753761291504, 8.860129356384277, 9.520503044128418, 10.180878639221191, 10.841252326965332, 11.501626014709473, 12.162001609802246, 12.822375297546387, 13.482748985290527, 14.1431245803833, 14.803498268127441, 15.463871955871582, 16.124248504638672, 16.784622192382812, 17.444995880126953, 18.105369567871094, 18.765743255615234, 19.426116943359375, 20.08649444580078, 20.746868133544922, 21.407241821289062, 22.067615509033203, 22.727989196777344, 23.388362884521484, 24.04874038696289, 24.70911407470703, 25.369487762451172, 26.029861450195312, 26.690235137939453, 27.35061264038086, 28.010986328125, 28.67136001586914]}, "_runtime": 173.24403834342957, "_timestamp": 1585421602.208022, "_step": 98}
{"Episode reward": 37.3041505202933, "Episode length": 503, "Policy Loss": 0.3101377785205841, "Value Loss": 19.90519142150879, "_runtime": 173.24403834342957, "_timestamp": 1585421602.208022, "_step": 99}
