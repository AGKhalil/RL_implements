{"Episode reward": -94.32314362335642, "Episode length": 999, "Policy Loss": 0.013646161183714867, "Value Loss": 0.04197946563363075, "_runtime": 11050.766578912735, "_timestamp": 1585608420.3994484, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.797395646572113, "Value Loss": 29.059328079223633, "_runtime": 11051.716317415237, "_timestamp": 1585608421.349187, "_step": 1}
{"Episode reward": 39.46611621346478, "Episode length": 639, "Policy Loss": 1.0623304843902588, "Value Loss": 18.949695587158203, "_runtime": 11053.290517091751, "_timestamp": 1585608422.9233866, "_step": 2}
{"Episode reward": -95.23481530484364, "Episode length": 999, "Policy Loss": -0.43106046319007874, "Value Loss": 0.10467261075973511, "_runtime": 11054.842902421951, "_timestamp": 1585608424.475772, "_step": 3}
{"Episode reward": -87.30356527052015, "Episode length": 999, "Policy Loss": -0.18015268445014954, "Value Loss": 0.09282682090997696, "_runtime": 11056.407320261002, "_timestamp": 1585608426.0401897, "_step": 4}
{"Episode reward": -97.73928209098959, "Episode length": 999, "Policy Loss": 2.106048822402954, "Value Loss": 0.23584586381912231, "_runtime": 11057.982434749603, "_timestamp": 1585608427.6153042, "_step": 5}
{"Episode reward": -99.51269978304946, "Episode length": 999, "Policy Loss": 3.0662600994110107, "Value Loss": 0.4411497712135315, "_runtime": 11059.538714885712, "_timestamp": 1585608429.1715844, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7653510570526123, "Value Loss": 0.2577718496322632, "_runtime": 11061.075793981552, "_timestamp": 1585608430.7086635, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9983800053596497, "Value Loss": 0.043986380100250244, "_runtime": 11062.656143903732, "_timestamp": 1585608432.2890134, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.876361608505249, "Value Loss": 0.012320712208747864, "_runtime": 11064.229496240616, "_timestamp": 1585608433.8623657, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7638230919837952, "Value Loss": 0.20496922731399536, "_runtime": 11065.760895967484, "_timestamp": 1585608435.3937654, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6404335498809814, "Value Loss": 1.5161659717559814, "_runtime": 11067.341407299042, "_timestamp": 1585608436.9742768, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5214328169822693, "Value Loss": 0.7605999708175659, "_runtime": 11068.923235177994, "_timestamp": 1585608438.5561047, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2948753535747528, "Value Loss": 0.12639030814170837, "_runtime": 11070.475076436996, "_timestamp": 1585608440.107946, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16489624977111816, "Value Loss": 0.03220846503973007, "_runtime": 11072.064212560654, "_timestamp": 1585608441.697082, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12008902430534363, "Value Loss": 0.052511900663375854, "_runtime": 11073.64627456665, "_timestamp": 1585608443.279144, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04323109611868858, "Value Loss": 1.1062030792236328, "_runtime": 11075.2110080719, "_timestamp": 1585608444.8438776, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9655210375785828, "Value Loss": 0.7547264099121094, "_runtime": 11076.799362897873, "_timestamp": 1585608446.4322324, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03722512349486351, "Value Loss": 0.04643745720386505, "_runtime": 11078.373884677887, "_timestamp": 1585608448.0067542, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.386476755142212, "Value Loss": 1.8747894763946533, "_runtime": 11078.601214170456, "_timestamp": 1585608448.2340837, "_step": 19}
{"Episode reward": 90.219968971315, "Episode length": 98, "Policy Loss": -19.55778694152832, "Value Loss": 107.92330169677734, "_runtime": 11078.82852602005, "_timestamp": 1585608448.4613955, "_step": 20}
{"Episode reward": 89.698864654325, "Episode length": 104, "Policy Loss": -12.431365013122559, "Value Loss": 96.39278411865234, "_runtime": 11080.437014341354, "_timestamp": 1585608450.0698838, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4350305199623108, "Value Loss": 0.011594071984291077, "_runtime": 11081.930364370346, "_timestamp": 1585608451.5632339, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5438908934593201, "Value Loss": 0.20690305531024933, "_runtime": 11083.41381573677, "_timestamp": 1585608453.0466852, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5939986705780029, "Value Loss": 0.76881343126297, "_runtime": 11085.00202178955, "_timestamp": 1585608454.6348913, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5642912983894348, "Value Loss": 0.18075817823410034, "_runtime": 11086.5528485775, "_timestamp": 1585608456.185718, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49720191955566406, "Value Loss": 0.019629552960395813, "_runtime": 11088.084831953049, "_timestamp": 1585608457.7177014, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40939849615097046, "Value Loss": 0.7342427372932434, "_runtime": 11089.68305683136, "_timestamp": 1585608459.3159263, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2706938087940216, "Value Loss": 0.8225690722465515, "_runtime": 11091.272855997086, "_timestamp": 1585608460.9057255, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15511657297611237, "Value Loss": 0.15335774421691895, "_runtime": 11092.847316265106, "_timestamp": 1585608462.4801857, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01792234182357788, "Value Loss": 0.37414228916168213, "_runtime": 11094.445465803146, "_timestamp": 1585608464.0783353, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10296519100666046, "Value Loss": 0.004961374215781689, "_runtime": 11096.037547588348, "_timestamp": 1585608465.670417, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21263115108013153, "Value Loss": 0.001672560814768076, "_runtime": 11097.59928059578, "_timestamp": 1585608467.23215, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30577078461647034, "Value Loss": 0.03135222941637039, "_runtime": 11099.206374645233, "_timestamp": 1585608468.8392441, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37308913469314575, "Value Loss": 0.03433933109045029, "_runtime": 11100.805127859116, "_timestamp": 1585608470.4379973, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4439481794834137, "Value Loss": 0.04767342656850815, "_runtime": 11102.38770365715, "_timestamp": 1585608472.0205731, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5125029683113098, "Value Loss": 0.18995414674282074, "_runtime": 11104.032646656036, "_timestamp": 1585608473.6655161, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5387165546417236, "Value Loss": 0.02513725683093071, "_runtime": 11105.633875608444, "_timestamp": 1585608475.266745, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5902962684631348, "Value Loss": 0.3430948853492737, "_runtime": 11107.20877456665, "_timestamp": 1585608476.841644, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6032310724258423, "Value Loss": 0.04235329478979111, "_runtime": 11108.793924331665, "_timestamp": 1585608478.4267938, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6389960050582886, "Value Loss": 0.0615052655339241, "_runtime": 11110.38982629776, "_timestamp": 1585608480.0226958, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6736984848976135, "Value Loss": 0.00885773915797472, "_runtime": 11111.972934246063, "_timestamp": 1585608481.6058037, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6875357627868652, "Value Loss": 0.20284117758274078, "_runtime": 11113.553679943085, "_timestamp": 1585608483.1865494, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7061557173728943, "Value Loss": 0.170074000954628, "_runtime": 11115.139807224274, "_timestamp": 1585608484.7726767, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7582736611366272, "Value Loss": 0.057328540831804276, "_runtime": 11116.72679066658, "_timestamp": 1585608486.3596601, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8127904534339905, "Value Loss": 0.03321008384227753, "_runtime": 11118.316007852554, "_timestamp": 1585608487.9488773, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8405777812004089, "Value Loss": 0.20764398574829102, "_runtime": 11119.900739431381, "_timestamp": 1585608489.533609, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8266971111297607, "Value Loss": 0.09860506653785706, "_runtime": 11121.47665810585, "_timestamp": 1585608491.1095276, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7935332655906677, "Value Loss": 0.11830878257751465, "_runtime": 11123.074010372162, "_timestamp": 1585608492.7068799, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7432069182395935, "Value Loss": 0.17458575963974, "_runtime": 11124.662865877151, "_timestamp": 1585608494.2957354, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6611981391906738, "Value Loss": 0.022123979404568672, "_runtime": 11126.250868320465, "_timestamp": 1585608495.8837378, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5965010523796082, "Value Loss": 0.08158934116363525, "_runtime": 11127.880633592606, "_timestamp": 1585608497.513503, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5456483364105225, "Value Loss": 0.03351455181837082, "_runtime": 11129.454922676086, "_timestamp": 1585608499.0877922, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5005940198898315, "Value Loss": 0.011288059875369072, "_runtime": 11131.010356664658, "_timestamp": 1585608500.6432261, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30882593989372253, "Value Loss": 0.04706869274377823, "_runtime": 11132.59575676918, "_timestamp": 1585608502.2286263, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07488635927438736, "Value Loss": 0.02704489976167679, "_runtime": 11134.182544469833, "_timestamp": 1585608503.815414, "_step": 55}
{"Episode reward": -49.867459796083594, "Episode length": 999, "Policy Loss": 0.0635795146226883, "Value Loss": 0.010327477939426899, "_runtime": 11135.760709285736, "_timestamp": 1585608505.3935788, "_step": 56}
{"Episode reward": -82.56599480540804, "Episode length": 999, "Policy Loss": 0.1433170586824417, "Value Loss": 0.005728241987526417, "_runtime": 11137.345683574677, "_timestamp": 1585608506.978553, "_step": 57}
{"Episode reward": -92.1419582111945, "Episode length": 999, "Policy Loss": 0.2043408751487732, "Value Loss": 0.018096376210451126, "_runtime": 11138.922530174255, "_timestamp": 1585608508.5553997, "_step": 58}
{"Episode reward": -93.84558262390298, "Episode length": 999, "Policy Loss": 0.2501868009567261, "Value Loss": 0.06481927633285522, "_runtime": 11140.503681898117, "_timestamp": 1585608510.1365514, "_step": 59}
{"Episode reward": -94.78949715888743, "Episode length": 999, "Policy Loss": 0.23981277644634247, "Value Loss": 0.04779135435819626, "_runtime": 11142.088067770004, "_timestamp": 1585608511.7209373, "_step": 60}
{"Episode reward": -96.30305083576037, "Episode length": 999, "Policy Loss": 0.2711077034473419, "Value Loss": 0.05966680496931076, "_runtime": 11143.67521739006, "_timestamp": 1585608513.3080869, "_step": 61}
{"Episode reward": -94.335997729007, "Episode length": 999, "Policy Loss": 0.15560881793498993, "Value Loss": 0.024680033326148987, "_runtime": 11145.242748737335, "_timestamp": 1585608514.8756182, "_step": 62}
{"Episode reward": -95.88582702577287, "Episode length": 999, "Policy Loss": 0.16571784019470215, "Value Loss": 0.012026685290038586, "_runtime": 11146.815979003906, "_timestamp": 1585608516.4488485, "_step": 63}
{"Episode reward": -96.75106610479655, "Episode length": 999, "Policy Loss": 0.09463033825159073, "Value Loss": 0.011822552420198917, "_runtime": 11148.40099811554, "_timestamp": 1585608518.0338676, "_step": 64}
{"Episode reward": -97.89308768710534, "Episode length": 999, "Policy Loss": 0.09998525679111481, "Value Loss": 0.008443083614110947, "_runtime": 11149.980331659317, "_timestamp": 1585608519.6132011, "_step": 65}
{"Episode reward": -99.04260975700615, "Episode length": 999, "Policy Loss": 0.10403969883918762, "Value Loss": 0.006339112296700478, "_runtime": 11151.602911233902, "_timestamp": 1585608521.2357807, "_step": 66}
{"Episode reward": -98.39529350190347, "Episode length": 999, "Policy Loss": 0.0863003060221672, "Value Loss": 0.03254513442516327, "_runtime": 11153.178948402405, "_timestamp": 1585608522.811818, "_step": 67}
{"Episode reward": -96.7363540560932, "Episode length": 999, "Policy Loss": -0.1705373078584671, "Value Loss": 0.18275491893291473, "_runtime": 11154.761199235916, "_timestamp": 1585608524.3940687, "_step": 68}
{"Episode reward": -98.44503636974636, "Episode length": 999, "Policy Loss": 0.06056421250104904, "Value Loss": 0.016612427309155464, "_runtime": 11156.362495183945, "_timestamp": 1585608525.9953647, "_step": 69}
{"Episode reward": -98.27860523862728, "Episode length": 999, "Policy Loss": 0.10950664430856705, "Value Loss": 0.0075395978055894375, "_runtime": 11157.954867124557, "_timestamp": 1585608527.5877366, "_step": 70}
{"Episode reward": -98.00357505410432, "Episode length": 999, "Policy Loss": 0.11794408410787582, "Value Loss": 0.013521541841328144, "_runtime": 11159.550085067749, "_timestamp": 1585608529.1829545, "_step": 71}
{"Episode reward": -98.32063002312367, "Episode length": 999, "Policy Loss": 0.11890174448490143, "Value Loss": 0.05150223150849342, "_runtime": 11161.1528942585, "_timestamp": 1585608530.7857637, "_step": 72}
{"Episode reward": -97.90084280734632, "Episode length": 999, "Policy Loss": 0.2542603313922882, "Value Loss": 0.22800612449645996, "_runtime": 11162.755959272385, "_timestamp": 1585608532.3888288, "_step": 73}
{"Episode reward": -98.81237211633828, "Episode length": 999, "Policy Loss": 0.07831080257892609, "Value Loss": 0.012476570904254913, "_runtime": 11164.35133934021, "_timestamp": 1585608533.9842088, "_step": 74}
{"Episode reward": -98.69690931147662, "Episode length": 999, "Policy Loss": 0.12334878742694855, "Value Loss": 0.04646994173526764, "_runtime": 11165.521371126175, "_timestamp": 1585608535.1542406, "_step": 75}
{"Episode reward": 29.22767174800883, "Episode length": 723, "Policy Loss": 0.8290455341339111, "Value Loss": 13.856162071228027, "_runtime": 11167.120863437653, "_timestamp": 1585608536.753733, "_step": 76}
{"Episode reward": -98.55054797866602, "Episode length": 999, "Policy Loss": 0.006872435100376606, "Value Loss": 0.0224137045443058, "_runtime": 11168.029654979706, "_timestamp": 1585608537.6625245, "_step": 77}
{"Episode reward": 45.055444888869125, "Episode length": 554, "Policy Loss": 0.8970682621002197, "Value Loss": 17.817232131958008, "_runtime": 11169.582643270493, "_timestamp": 1585608539.2155128, "_step": 78}
{"Episode reward": -98.84519148910415, "Episode length": 999, "Policy Loss": -0.057551462203264236, "Value Loss": 0.12220118194818497, "_runtime": 11171.185761213303, "_timestamp": 1585608540.8186307, "_step": 79}
{"Episode reward": -98.585910816147, "Episode length": 999, "Policy Loss": -0.20665106177330017, "Value Loss": 0.23676902055740356, "_runtime": 11172.065933942795, "_timestamp": 1585608541.6988034, "_step": 80}
{"Episode reward": 45.52013999627186, "Episode length": 560, "Policy Loss": 0.8014135360717773, "Value Loss": 17.650522232055664, "_runtime": 11173.657193422318, "_timestamp": 1585608543.290063, "_step": 81}
{"Episode reward": -98.79297611642563, "Episode length": 999, "Policy Loss": -0.3010314106941223, "Value Loss": 0.28772303462028503, "_runtime": 11175.292537212372, "_timestamp": 1585608544.9254067, "_step": 82}
{"Episode reward": -98.68450089961128, "Episode length": 999, "Policy Loss": -0.08146016299724579, "Value Loss": 0.020422866567969322, "_runtime": 11176.838494062424, "_timestamp": 1585608546.4713635, "_step": 83}
{"Episode reward": -98.97519129796832, "Episode length": 999, "Policy Loss": -0.11279353499412537, "Value Loss": 0.03317570313811302, "_runtime": 11178.06541132927, "_timestamp": 1585608547.6982808, "_step": 84}
{"Episode reward": 24.3761300520936, "Episode length": 764, "Policy Loss": 0.5574522018432617, "Value Loss": 12.952451705932617, "_runtime": 11179.652191638947, "_timestamp": 1585608549.2850611, "_step": 85}
{"Episode reward": -98.72480592455419, "Episode length": 999, "Policy Loss": -0.14117300510406494, "Value Loss": 0.01326561626046896, "_runtime": 11181.228446006775, "_timestamp": 1585608550.8613155, "_step": 86}
{"Episode reward": -98.36743165498942, "Episode length": 999, "Policy Loss": -0.1195807158946991, "Value Loss": 0.02678762935101986, "_runtime": 11182.789945840836, "_timestamp": 1585608552.4228153, "_step": 87}
{"Episode reward": -98.84740602272444, "Episode length": 999, "Policy Loss": -0.14686362445354462, "Value Loss": 0.003322529373690486, "_runtime": 11184.389995098114, "_timestamp": 1585608554.0228646, "_step": 88}
{"Episode reward": -98.64806542751934, "Episode length": 999, "Policy Loss": -0.14216291904449463, "Value Loss": 0.017577601596713066, "_runtime": 11185.965872526169, "_timestamp": 1585608555.598742, "_step": 89}
{"Episode reward": -99.18757516090383, "Episode length": 999, "Policy Loss": -0.1725534349679947, "Value Loss": 0.0046837590634822845, "_runtime": 11187.55592250824, "_timestamp": 1585608557.188792, "_step": 90}
{"Episode reward": -99.24621630692317, "Episode length": 999, "Policy Loss": -0.17852675914764404, "Value Loss": 0.01164618693292141, "_runtime": 11189.152329444885, "_timestamp": 1585608558.785199, "_step": 91}
{"Episode reward": -97.19262297304765, "Episode length": 999, "Policy Loss": -0.05850221589207649, "Value Loss": 0.04684573784470558, "_runtime": 11190.524809360504, "_timestamp": 1585608560.1576788, "_step": 92}
{"Episode reward": 14.514163462510695, "Episode length": 865, "Policy Loss": 0.5687443614006042, "Value Loss": 11.605761528015137, "_runtime": 11192.12169623375, "_timestamp": 1585608561.7545657, "_step": 93}
{"Episode reward": -98.79559680231627, "Episode length": 999, "Policy Loss": -0.22704488039016724, "Value Loss": 0.0021672332659363747, "_runtime": 11193.701352119446, "_timestamp": 1585608563.3342216, "_step": 94}
{"Episode reward": -97.37223666280846, "Episode length": 999, "Policy Loss": -0.2617706060409546, "Value Loss": 0.008699005469679832, "_runtime": 11195.276622056961, "_timestamp": 1585608564.9094915, "_step": 95}
{"Episode reward": -98.2899376853711, "Episode length": 999, "Policy Loss": -0.2617419958114624, "Value Loss": 0.007234061602503061, "_runtime": 11196.851665973663, "_timestamp": 1585608566.4845355, "_step": 96}
{"Episode reward": -99.14076930838392, "Episode length": 999, "Policy Loss": -0.2991241216659546, "Value Loss": 0.01961536519229412, "_runtime": 11198.368605852127, "_timestamp": 1585608568.0014753, "_step": 97}
{"Episode reward": 8.307565512826471, "Episode length": 927, "Policy Loss": 0.2941510081291199, "Value Loss": 10.764209747314453, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324, -4.432955741882324]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 12.0, 0.0, 1.0], "bins": [-150.717041015625, -148.1988983154297, -145.68075561523438, -143.16261291503906, -140.64447021484375, -138.12632751464844, -135.60818481445312, -133.0900421142578, -130.5718994140625, -128.0537567138672, -125.53561401367188, -123.01747131347656, -120.49932861328125, -117.98118591308594, -115.46304321289062, -112.94490051269531, -110.4267578125, -107.90861511230469, -105.39047241210938, -102.87232971191406, -100.35418701171875, -97.83604431152344, -95.31790161132812, -92.79975891113281, -90.28160858154297, -87.76346588134766, -85.24532318115234, -82.72718048095703, -80.20903778076172, -77.6908950805664, -75.1727523803711, -72.65460968017578, -70.13646697998047, -67.61832427978516, -65.10018157958984, -62.58203887939453, -60.06389617919922, -57.545753479003906, -55.027610778808594, -52.50946807861328, -49.99132537841797, -47.473182678222656, -44.955039978027344, -42.43689727783203, -39.91875457763672, -37.400611877441406, -34.882469177246094, -32.36432647705078, -29.846176147460938, -27.328033447265625, -24.809890747070312, -22.291748046875, -19.773605346679688, -17.255462646484375, -14.737319946289062, -12.21917724609375, -9.701034545898438, -7.182891845703125, -4.6647491455078125, -2.1466064453125, 0.3715362548828125, 2.889678955078125, 5.4078216552734375, 7.92596435546875, 10.444107055664062]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.975816249847412, -7.822792053222656, -7.669767379760742, -7.516743183135986, -7.363718509674072, -7.210694313049316, -7.057669639587402, -6.9046454429626465, -6.751621246337891, -6.598596572875977, -6.4455718994140625, -6.292547702789307, -6.139523506164551, -5.986498832702637, -5.833474636077881, -5.680450439453125, -5.527425765991211, -5.374401092529297, -5.221376895904541, -5.068352699279785, -4.915328025817871, -4.762303829193115, -4.609279632568359, -4.456254959106445, -4.303230285644531, -4.150206089019775, -3.9971816539764404, -3.8441572189331055, -3.6911330223083496, -3.5381083488464355, -3.3850841522216797, -3.2320594787597656, -3.0790352821350098, -2.926011085510254, -2.77298641204834, -2.619962215423584, -2.46693754196167, -2.313913345336914, -2.160888671875, -2.007864475250244, -1.85483980178833, -1.7018156051635742, -1.5487914085388184, -1.3957667350769043, -1.2427425384521484, -1.0897178649902344, -0.9366936683654785, -0.7836689949035645, -0.6306447982788086, -0.47762060165405273, -0.32459592819213867, -0.1715717315673828, -0.01854705810546875, 0.1344771385192871, 0.28750181198120117, 0.44052648544311523, 0.5935502052307129, 0.746574878692627, 0.899599552154541, 1.0526232719421387, 1.2056479454040527, 1.3586726188659668, 1.5116972923278809, 1.6647210121154785, 1.8177456855773926]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 10.0, 429.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 5.0, 7.0, 4.0, 8.0], "bins": [-28.82736587524414, -28.257362365722656, -27.687358856201172, -27.11735725402832, -26.547353744506836, -25.97735023498535, -25.4073486328125, -24.837345123291016, -24.26734161376953, -23.697338104248047, -23.127334594726562, -22.55733299255371, -21.987329483032227, -21.417325973510742, -20.84732437133789, -20.277320861816406, -19.707317352294922, -19.137313842773438, -18.567310333251953, -17.9973087310791, -17.427305221557617, -16.857301712036133, -16.28730010986328, -15.717296600341797, -15.147293090820312, -14.577289581298828, -14.00728702545166, -13.437284469604492, -12.867280960083008, -12.297277450561523, -11.727275848388672, -11.157272338867188, -10.587268829345703, -10.017265319824219, -9.447261810302734, -8.877260208129883, -8.307256698608398, -7.737253189086914, -7.1672515869140625, -6.597248077392578, -6.027244567871094, -5.457241058349609, -4.887237548828125, -4.317235946655273, -3.747232437133789, -3.1772289276123047, -2.607227325439453, -2.0372238159179688, -1.4672203063964844, -0.897216796875, -0.3272132873535156, 0.24278831481933594, 0.8127918243408203, 1.3827953338623047, 1.9527969360351562, 2.5228004455566406, 3.092803955078125, 3.6628074645996094, 4.232810974121094, 4.802814483642578, 5.372814178466797, 5.942817687988281, 6.512821197509766, 7.08282470703125, 7.652828216552734]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-10.514872550964355, -10.30135440826416, -10.087836265563965, -9.87431812286377, -9.66080093383789, -9.447282791137695, -9.2337646484375, -9.020246505737305, -8.80672836303711, -8.593210220336914, -8.379692077636719, -8.166173934936523, -7.9526567459106445, -7.739138603210449, -7.525620460510254, -7.312102317810059, -7.098584175109863, -6.885066509246826, -6.671548366546631, -6.4580302238464355, -6.244512557983398, -6.030994415283203, -5.817476272583008, -5.6039581298828125, -5.390440464019775, -5.17692232131958, -4.963404178619385, -4.749886512756348, -4.536368370056152, -4.322850227355957, -4.109332084655762, -3.8958144187927246, -3.6822962760925293, -3.468778133392334, -3.255260467529297, -3.0417423248291016, -2.8282241821289062, -2.614706039428711, -2.4011878967285156, -2.1876697540283203, -1.9741525650024414, -1.760634422302246, -1.5471162796020508, -1.3335981369018555, -1.1200799942016602, -0.9065618515014648, -0.6930437088012695, -0.4795265197753906, -0.2660083770751953, -0.052490234375, 0.1610279083251953, 0.3745460510253906, 0.5880641937255859, 0.8015823364257812, 1.0150995254516602, 1.2286176681518555, 1.4421358108520508, 1.655653953552246, 1.8691720962524414, 2.0826902389526367, 2.296208381652832, 2.509725570678711, 2.7232437133789062, 2.9367618560791016, 3.150279998779297]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 5.0, 4.0, 7.0, 4.0, 4.0, 2.0, 7.0, 5.0, 3.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.178133249282837, -1.1160082817077637, -1.0538833141326904, -0.9917582869529724, -0.9296333193778992, -0.8675083518028259, -0.8053833246231079, -0.7432583570480347, -0.6811333894729614, -0.6190084218978882, -0.5568834543228149, -0.4947584271430969, -0.4326334595680237, -0.37050849199295044, -0.3083834648132324, -0.24625849723815918, -0.18413352966308594, -0.1220085620880127, -0.05988359451293945, 0.002241373062133789, 0.06436634063720703, 0.12649142742156982, 0.18861639499664307, 0.2507413625717163, 0.31286633014678955, 0.3749912977218628, 0.43711626529693604, 0.4992412328720093, 0.5613663196563721, 0.6234912872314453, 0.6856162548065186, 0.7477412223815918, 0.809866189956665, 0.8719911575317383, 0.9341161251068115, 0.9962410926818848, 1.058366060256958, 1.1204910278320312, 1.1826159954071045, 1.2447409629821777, 1.306865930557251, 1.3689911365509033, 1.4311161041259766, 1.4932410717010498, 1.555366039276123, 1.6174910068511963, 1.6796159744262695, 1.7417409420013428, 1.803865909576416, 1.8659908771514893, 1.9281158447265625, 1.9902408123016357, 2.052365779876709, 2.1144907474517822, 2.1766157150268555, 2.2387406826019287, 2.300865888595581, 2.3629908561706543, 2.4251158237457275, 2.487240791320801, 2.549365758895874, 2.6114907264709473, 2.6736156940460205, 2.7357406616210938, 2.797865629196167]}, "_runtime": 11199.683009386063, "_timestamp": 1585608569.3158789, "_step": 98}
{"Episode reward": 18.20045057872045, "Episode length": 828, "Policy Loss": 0.35068273544311523, "Value Loss": 12.034869194030762, "_runtime": 11201.100027799606, "_timestamp": 1585608570.7328973, "_step": 99}
{"Episode reward": 12.065355146585162, "Episode length": 888, "Policy Loss": 0.22531276941299438, "Value Loss": 11.2410249710083, "_runtime": 11202.69219660759, "_timestamp": 1585608572.325066, "_step": 100}
{"Episode reward": -98.34231913776273, "Episode length": 999, "Policy Loss": -0.32460862398147583, "Value Loss": 0.04369170218706131, "_runtime": 11204.271817207336, "_timestamp": 1585608573.9046867, "_step": 101}
{"Episode reward": -97.78617736619844, "Episode length": 999, "Policy Loss": -0.2718624174594879, "Value Loss": 0.018213264644145966, "_runtime": 11205.755010604858, "_timestamp": 1585608575.38788, "_step": 102}
{"Episode reward": 7.7554093229176, "Episode length": 939, "Policy Loss": 0.18199817836284637, "Value Loss": 10.624785423278809, "_runtime": 11207.349894046783, "_timestamp": 1585608576.9827635, "_step": 103}
{"Episode reward": -98.9749908380128, "Episode length": 999, "Policy Loss": -0.28884392976760864, "Value Loss": 0.024667203426361084, "_runtime": 11208.941925525665, "_timestamp": 1585608578.574795, "_step": 104}
{"Episode reward": -98.9948611122346, "Episode length": 999, "Policy Loss": -0.2663043439388275, "Value Loss": 0.010081548243761063, "_runtime": 11210.294883489609, "_timestamp": 1585608579.927753, "_step": 105}
{"Episode reward": 16.03395812139729, "Episode length": 847, "Policy Loss": 0.40722283720970154, "Value Loss": 11.727542877197266, "_runtime": 11211.889930963516, "_timestamp": 1585608581.5228004, "_step": 106}
{"Episode reward": -99.01649168011255, "Episode length": 999, "Policy Loss": -0.2514890432357788, "Value Loss": 0.007026463747024536, "_runtime": 11212.772689342499, "_timestamp": 1585608582.4055588, "_step": 107}
{"Episode reward": 45.34491526455336, "Episode length": 552, "Policy Loss": 0.6187375783920288, "Value Loss": 17.966190338134766, "_runtime": 11213.415313959122, "_timestamp": 1585608583.0481834, "_step": 108}
{"Episode reward": 61.10719372848899, "Episode length": 394, "Policy Loss": 1.2249376773834229, "Value Loss": 25.14674186706543, "_runtime": 11214.992457151413, "_timestamp": 1585608584.6253266, "_step": 109}
{"Episode reward": -98.87036047770285, "Episode length": 999, "Policy Loss": -0.30652809143066406, "Value Loss": 0.03967849165201187, "_runtime": 11215.487746715546, "_timestamp": 1585608585.1206162, "_step": 110}
{"Episode reward": 70.44855394715806, "Episode length": 301, "Policy Loss": 1.5632206201553345, "Value Loss": 32.5223503112793, "_runtime": 11216.565727472305, "_timestamp": 1585608586.198597, "_step": 111}
{"Episode reward": 29.649541001582463, "Episode length": 711, "Policy Loss": 0.33830466866493225, "Value Loss": 13.735392570495605, "_runtime": 11218.141124248505, "_timestamp": 1585608587.7739937, "_step": 112}
{"Episode reward": -98.11329762806339, "Episode length": 999, "Policy Loss": -0.5239195823669434, "Value Loss": 0.49228110909461975, "_runtime": 11219.652955055237, "_timestamp": 1585608589.2858245, "_step": 113}
{"Episode reward": -98.80181429212294, "Episode length": 999, "Policy Loss": -0.366405725479126, "Value Loss": 0.08612186461687088, "_runtime": 11221.237865924835, "_timestamp": 1585608590.8707354, "_step": 114}
{"Episode reward": -99.19231205498225, "Episode length": 999, "Policy Loss": -0.3364242613315582, "Value Loss": 0.05401487275958061, "_runtime": 11222.827074766159, "_timestamp": 1585608592.4599442, "_step": 115}
{"Episode reward": -98.97095184200819, "Episode length": 999, "Policy Loss": -0.3877931535243988, "Value Loss": 0.09095370769500732, "_runtime": 11223.782320976257, "_timestamp": 1585608593.4151905, "_step": 116}
{"Episode reward": 40.649539902109034, "Episode length": 606, "Policy Loss": -0.10668262839317322, "Value Loss": 16.48158073425293, "_runtime": 11224.91779923439, "_timestamp": 1585608594.5506687, "_step": 117}
{"Episode reward": 27.719901542349874, "Episode length": 734, "Policy Loss": 0.28702932596206665, "Value Loss": 13.363439559936523, "_runtime": 11226.245161771774, "_timestamp": 1585608595.8780313, "_step": 118}
{"Episode reward": 16.10854818173368, "Episode length": 846, "Policy Loss": 0.20665343105793, "Value Loss": 11.51137638092041, "_runtime": 11227.771038532257, "_timestamp": 1585608597.403908, "_step": 119}
{"Episode reward": -98.30335868187701, "Episode length": 999, "Policy Loss": -0.3321835398674011, "Value Loss": 0.018421662971377373, "_runtime": 11229.314784765244, "_timestamp": 1585608598.9476542, "_step": 120}
{"Episode reward": -98.94285567868305, "Episode length": 999, "Policy Loss": -0.35607150197029114, "Value Loss": 0.05339793488383293, "_runtime": 11230.865016460419, "_timestamp": 1585608600.497886, "_step": 121}
{"Episode reward": -99.1627885293391, "Episode length": 999, "Policy Loss": -0.3324558436870575, "Value Loss": 0.013421609066426754, "_runtime": 11232.431175470352, "_timestamp": 1585608602.064045, "_step": 122}
{"Episode reward": -99.31972605332602, "Episode length": 999, "Policy Loss": -0.334026575088501, "Value Loss": 0.01451106183230877, "_runtime": 11234.000854969025, "_timestamp": 1585608603.6337245, "_step": 123}
{"Episode reward": -99.13320920429844, "Episode length": 999, "Policy Loss": -0.32060495018959045, "Value Loss": 0.006400746759027243, "_runtime": 11235.570854902267, "_timestamp": 1585608605.2037244, "_step": 124}
{"Episode reward": -99.0013332402881, "Episode length": 999, "Policy Loss": -0.3144600987434387, "Value Loss": 0.017138972878456116, "_runtime": 11236.8936150074, "_timestamp": 1585608606.5264845, "_step": 125}
{"Episode reward": 16.996414443567488, "Episode length": 846, "Policy Loss": 0.25261494517326355, "Value Loss": 11.686178207397461, "_runtime": 11238.463065862656, "_timestamp": 1585608608.0959353, "_step": 126}
{"Episode reward": -98.54310594164991, "Episode length": 999, "Policy Loss": -0.2735900282859802, "Value Loss": 0.017946427688002586, "_runtime": 11240.046125888824, "_timestamp": 1585608609.6789954, "_step": 127}
{"Episode reward": -98.615159238695, "Episode length": 999, "Policy Loss": -0.26194584369659424, "Value Loss": 0.0075530302710831165, "_runtime": 11241.268753051758, "_timestamp": 1585608610.9016225, "_step": 128}
{"Episode reward": 21.334778103194736, "Episode length": 790, "Policy Loss": 0.3251953125, "Value Loss": 12.569354057312012, "_runtime": 11242.82710647583, "_timestamp": 1585608612.459976, "_step": 129}
{"Episode reward": -98.91637904392871, "Episode length": 999, "Policy Loss": -0.25165921449661255, "Value Loss": 0.003732670797035098, "_runtime": 11244.450155735016, "_timestamp": 1585608614.0830252, "_step": 130}
{"Episode reward": -99.0967388383023, "Episode length": 999, "Policy Loss": -0.24812781810760498, "Value Loss": 0.0025993946474045515, "_runtime": 11245.995239496231, "_timestamp": 1585608615.628109, "_step": 131}
{"Episode reward": -99.3512393427013, "Episode length": 999, "Policy Loss": -0.24654541909694672, "Value Loss": 0.0023985696025192738, "_runtime": 11247.557473659515, "_timestamp": 1585608617.1903431, "_step": 132}
{"Episode reward": -98.93165166741721, "Episode length": 999, "Policy Loss": -0.2349509745836258, "Value Loss": 0.00226220372132957, "_runtime": 11249.129320383072, "_timestamp": 1585608618.7621899, "_step": 133}
{"Episode reward": -98.33964191027643, "Episode length": 999, "Policy Loss": -0.22346223890781403, "Value Loss": 0.002150842221453786, "_runtime": 11249.880434036255, "_timestamp": 1585608619.5133035, "_step": 134}
{"Episode reward": 54.497124862647446, "Episode length": 462, "Policy Loss": 0.8269502520561218, "Value Loss": 21.53227996826172, "_runtime": 11251.447297334671, "_timestamp": 1585608621.0801668, "_step": 135}
{"Episode reward": -99.20331933767203, "Episode length": 999, "Policy Loss": -0.22164778411388397, "Value Loss": 0.0021749145817011595, "_runtime": 11253.020066022873, "_timestamp": 1585608622.6529355, "_step": 136}
{"Episode reward": -98.74134653498719, "Episode length": 999, "Policy Loss": -0.2231985330581665, "Value Loss": 0.007426094729453325, "_runtime": 11254.537014722824, "_timestamp": 1585608624.1698842, "_step": 137}
{"Episode reward": -98.9475584783146, "Episode length": 999, "Policy Loss": -0.19932502508163452, "Value Loss": 0.013969490304589272, "_runtime": 11256.102204799652, "_timestamp": 1585608625.7350743, "_step": 138}
{"Episode reward": -99.05735206600676, "Episode length": 999, "Policy Loss": -0.20893725752830505, "Value Loss": 0.003625833662226796, "_runtime": 11257.664531230927, "_timestamp": 1585608627.2974007, "_step": 139}
{"Episode reward": -99.01702388620407, "Episode length": 999, "Policy Loss": -0.19654060900211334, "Value Loss": 0.002458736766129732, "_runtime": 11258.595875263214, "_timestamp": 1585608628.2287447, "_step": 140}
{"Episode reward": 41.94711144918387, "Episode length": 586, "Policy Loss": 0.614298939704895, "Value Loss": 16.876304626464844, "_runtime": 11260.165086269379, "_timestamp": 1585608629.7979558, "_step": 141}
{"Episode reward": -99.09900761786606, "Episode length": 999, "Policy Loss": -0.18614549934864044, "Value Loss": 0.0023822744842618704, "_runtime": 11261.314143419266, "_timestamp": 1585608630.947013, "_step": 142}
{"Episode reward": 28.504327701370997, "Episode length": 721, "Policy Loss": 0.7298608422279358, "Value Loss": 13.670286178588867, "_runtime": 11262.600478887558, "_timestamp": 1585608632.2333484, "_step": 143}
{"Episode reward": 17.737324582837587, "Episode length": 840, "Policy Loss": 0.3676135838031769, "Value Loss": 11.717328071594238, "_runtime": 11263.228293180466, "_timestamp": 1585608632.8611627, "_step": 144}
{"Episode reward": 62.907726225448634, "Episode length": 380, "Policy Loss": 1.077573299407959, "Value Loss": 25.840362548828125, "_runtime": 11264.323740005493, "_timestamp": 1585608633.9566095, "_step": 145}
{"Episode reward": 29.939141259092025, "Episode length": 708, "Policy Loss": 0.3151487112045288, "Value Loss": 13.895692825317383, "_runtime": 11265.878517389297, "_timestamp": 1585608635.5113869, "_step": 146}
{"Episode reward": -99.01559848862064, "Episode length": 999, "Policy Loss": -0.2064485400915146, "Value Loss": 0.03202897310256958, "_runtime": 11267.385322332382, "_timestamp": 1585608637.0181918, "_step": 147}
{"Episode reward": -98.92366431628601, "Episode length": 999, "Policy Loss": -0.271491140127182, "Value Loss": 0.08237868547439575, "_runtime": 11268.971091270447, "_timestamp": 1585608638.6039608, "_step": 148}
{"Episode reward": -98.4999404474272, "Episode length": 999, "Policy Loss": -0.23166149854660034, "Value Loss": 0.05924704298377037, "_runtime": 11269.64921784401, "_timestamp": 1585608639.2820873, "_step": 149}
{"Episode reward": 60.068386099025126, "Episode length": 410, "Policy Loss": 1.1566925048828125, "Value Loss": 23.624330520629883, "_runtime": 11270.865659475327, "_timestamp": 1585608640.498529, "_step": 150}
{"Episode reward": 22.9164945708101, "Episode length": 779, "Policy Loss": 0.4643773138523102, "Value Loss": 12.295604705810547, "_runtime": 11272.44057059288, "_timestamp": 1585608642.07344, "_step": 151}
{"Episode reward": -98.95190587694391, "Episode length": 999, "Policy Loss": -0.2041560411453247, "Value Loss": 0.012308837845921516, "_runtime": 11273.084498167038, "_timestamp": 1585608642.7173676, "_step": 152}
{"Episode reward": 58.34888693405408, "Episode length": 419, "Policy Loss": 0.9899525046348572, "Value Loss": 22.93362808227539, "_runtime": 11273.944921016693, "_timestamp": 1585608643.5777905, "_step": 153}
{"Episode reward": 44.67104762761213, "Episode length": 555, "Policy Loss": 0.8849570751190186, "Value Loss": 17.265993118286133, "_runtime": 11275.504684448242, "_timestamp": 1585608645.137554, "_step": 154}
{"Episode reward": -98.9811411498963, "Episode length": 999, "Policy Loss": -0.35544100403785706, "Value Loss": 0.43751370906829834, "_runtime": 11276.546795606613, "_timestamp": 1585608646.179665, "_step": 155}
{"Episode reward": 31.93644184990775, "Episode length": 686, "Policy Loss": 0.5038987994194031, "Value Loss": 14.094634056091309, "_runtime": 11278.065270662308, "_timestamp": 1585608647.6981401, "_step": 156}
{"Episode reward": -98.88124640341064, "Episode length": 999, "Policy Loss": -0.2452666163444519, "Value Loss": 0.1472645252943039, "_runtime": 11279.632301092148, "_timestamp": 1585608649.2651706, "_step": 157}
{"Episode reward": -99.03404863857297, "Episode length": 999, "Policy Loss": -0.2377004474401474, "Value Loss": 0.01335612591356039, "_runtime": 11281.163748979568, "_timestamp": 1585608650.7966185, "_step": 158}
{"Episode reward": -98.73115815498146, "Episode length": 999, "Policy Loss": -0.2619674503803253, "Value Loss": 0.047650329768657684, "_runtime": 11282.73330283165, "_timestamp": 1585608652.3661723, "_step": 159}
{"Episode reward": -98.57962643816295, "Episode length": 999, "Policy Loss": -0.23055191338062286, "Value Loss": 0.14797207713127136, "_runtime": 11284.084516525269, "_timestamp": 1585608653.717386, "_step": 160}
{"Episode reward": 16.53645714723352, "Episode length": 851, "Policy Loss": 0.27261149883270264, "Value Loss": 11.598442077636719, "_runtime": 11284.716506242752, "_timestamp": 1585608654.3493757, "_step": 161}
{"Episode reward": 61.832054622225776, "Episode length": 383, "Policy Loss": 1.1381652355194092, "Value Loss": 25.18338394165039, "_runtime": 11286.273652791977, "_timestamp": 1585608655.9065223, "_step": 162}
{"Episode reward": -98.74777241810975, "Episode length": 999, "Policy Loss": -0.36437758803367615, "Value Loss": 0.06384972482919693, "_runtime": 11287.844742536545, "_timestamp": 1585608657.477612, "_step": 163}
{"Episode reward": -98.62250090400862, "Episode length": 999, "Policy Loss": -0.354229599237442, "Value Loss": 0.12749341130256653, "_runtime": 11289.357007741928, "_timestamp": 1585608658.9898772, "_step": 164}
{"Episode reward": -99.12617399495512, "Episode length": 999, "Policy Loss": -0.38661208748817444, "Value Loss": 0.31945857405662537, "_runtime": 11290.912124156952, "_timestamp": 1585608660.5449936, "_step": 165}
{"Episode reward": -98.58533200781442, "Episode length": 999, "Policy Loss": -0.1612979769706726, "Value Loss": 0.8550910949707031, "_runtime": 11292.146174907684, "_timestamp": 1585608661.7790444, "_step": 166}
{"Episode reward": 25.4994180695639, "Episode length": 753, "Policy Loss": 0.4308852553367615, "Value Loss": 12.602615356445312, "_runtime": 11293.70487523079, "_timestamp": 1585608663.3377447, "_step": 167}
{"Episode reward": -98.98512073486974, "Episode length": 999, "Policy Loss": -0.12472721934318542, "Value Loss": 0.039238136261701584, "_runtime": 11295.280183553696, "_timestamp": 1585608664.913053, "_step": 168}
{"Episode reward": -99.42020789687275, "Episode length": 999, "Policy Loss": -0.02576499618589878, "Value Loss": 0.046395592391490936, "_runtime": 11296.783896923065, "_timestamp": 1585608666.4167664, "_step": 169}
{"Episode reward": 4.994502832238183, "Episode length": 967, "Policy Loss": 0.2863319218158722, "Value Loss": 10.700762748718262, "_runtime": 11297.580973863602, "_timestamp": 1585608667.2138433, "_step": 170}
{"Episode reward": 51.09408660145113, "Episode length": 494, "Policy Loss": 1.0911518335342407, "Value Loss": 19.973983764648438, "_runtime": 11299.145836353302, "_timestamp": 1585608668.7787058, "_step": 171}
{"Episode reward": -99.05296874458082, "Episode length": 999, "Policy Loss": -0.04827555641531944, "Value Loss": 0.16624750196933746, "_runtime": 11300.725390195847, "_timestamp": 1585608670.3582597, "_step": 172}
{"Episode reward": -98.66011673863636, "Episode length": 999, "Policy Loss": -0.21712903678417206, "Value Loss": 0.2158880978822708, "_runtime": 11302.250427007675, "_timestamp": 1585608671.8832965, "_step": 173}
{"Episode reward": -98.55254774196123, "Episode length": 999, "Policy Loss": -0.1498064249753952, "Value Loss": 0.0725153312087059, "_runtime": 11303.812997817993, "_timestamp": 1585608673.4458673, "_step": 174}
{"Episode reward": -98.6845428857475, "Episode length": 999, "Policy Loss": -0.2195267528295517, "Value Loss": 0.07153154164552689, "_runtime": 11305.133900165558, "_timestamp": 1585608674.7667696, "_step": 175}
{"Episode reward": 17.466114317967026, "Episode length": 838, "Policy Loss": 0.36024609208106995, "Value Loss": 11.81636905670166, "_runtime": 11306.687095165253, "_timestamp": 1585608676.3199646, "_step": 176}
{"Episode reward": -99.1499053407207, "Episode length": 999, "Policy Loss": -0.23410391807556152, "Value Loss": 0.01936517469584942, "_runtime": 11308.2631919384, "_timestamp": 1585608677.8960614, "_step": 177}
{"Episode reward": -98.76758426737881, "Episode length": 999, "Policy Loss": -0.24772338569164276, "Value Loss": 0.013421321287751198, "_runtime": 11309.83577466011, "_timestamp": 1585608679.4686441, "_step": 178}
{"Episode reward": -99.28118222667044, "Episode length": 999, "Policy Loss": -0.26928117871284485, "Value Loss": 0.008824186399579048, "_runtime": 11311.40511894226, "_timestamp": 1585608681.0379884, "_step": 179}
{"Episode reward": -98.0924643652944, "Episode length": 999, "Policy Loss": -0.27173474431037903, "Value Loss": 0.01014780905097723, "_runtime": 11312.9824924469, "_timestamp": 1585608682.615362, "_step": 180}
{"Episode reward": -98.95714162475389, "Episode length": 999, "Policy Loss": -0.3010709881782532, "Value Loss": 0.006117770913988352, "_runtime": 11314.600190401077, "_timestamp": 1585608684.23306, "_step": 181}
{"Episode reward": -98.3116361982097, "Episode length": 999, "Policy Loss": -0.26181772351264954, "Value Loss": 0.014927475713193417, "_runtime": 11316.16951084137, "_timestamp": 1585608685.8023803, "_step": 182}
{"Episode reward": -98.48906513417434, "Episode length": 999, "Policy Loss": -0.27016472816467285, "Value Loss": 0.017894290387630463, "_runtime": 11317.724893331528, "_timestamp": 1585608687.3577628, "_step": 183}
{"Episode reward": -98.38648437205104, "Episode length": 999, "Policy Loss": -0.29234713315963745, "Value Loss": 0.022718241438269615, "_runtime": 11319.296153068542, "_timestamp": 1585608688.9290226, "_step": 184}
{"Episode reward": -99.2924264938488, "Episode length": 999, "Policy Loss": -0.3250059485435486, "Value Loss": 0.008365770801901817, "_runtime": 11320.858420610428, "_timestamp": 1585608690.49129, "_step": 185}
{"Episode reward": -98.42060781661479, "Episode length": 999, "Policy Loss": -0.2840256989002228, "Value Loss": 0.032583676278591156, "_runtime": 11322.433285474777, "_timestamp": 1585608692.066155, "_step": 186}
{"Episode reward": -97.25179977922727, "Episode length": 999, "Policy Loss": -0.17098630964756012, "Value Loss": 0.1357407122850418, "_runtime": 11324.004854917526, "_timestamp": 1585608693.6377244, "_step": 187}
{"Episode reward": -98.85888732991093, "Episode length": 999, "Policy Loss": -0.28789931535720825, "Value Loss": 0.010617749765515327, "_runtime": 11324.779880523682, "_timestamp": 1585608694.41275, "_step": 188}
{"Episode reward": 52.74802004652441, "Episode length": 476, "Policy Loss": 0.7644418478012085, "Value Loss": 21.471099853515625, "_runtime": 11325.770030021667, "_timestamp": 1585608695.4028995, "_step": 189}
{"Episode reward": 39.423280199043376, "Episode length": 622, "Policy Loss": 0.5988873839378357, "Value Loss": 16.14949607849121, "_runtime": 11327.342008829117, "_timestamp": 1585608696.9748783, "_step": 190}
{"Episode reward": -97.95908071541591, "Episode length": 999, "Policy Loss": -0.3083038032054901, "Value Loss": 0.04366490989923477, "_runtime": 11328.85293674469, "_timestamp": 1585608698.4858062, "_step": 191}
{"Episode reward": -99.1159346762684, "Episode length": 999, "Policy Loss": -0.2878777086734772, "Value Loss": 0.03206861764192581, "_runtime": 11330.383357286453, "_timestamp": 1585608700.0162268, "_step": 192}
{"Episode reward": -98.12076928937971, "Episode length": 999, "Policy Loss": -0.3066372573375702, "Value Loss": 0.03185497224330902, "_runtime": 11331.611513853073, "_timestamp": 1585608701.2443833, "_step": 193}
{"Episode reward": 22.57872038220006, "Episode length": 777, "Policy Loss": 0.40309861302375793, "Value Loss": 12.420379638671875, "_runtime": 11333.159526586533, "_timestamp": 1585608702.792396, "_step": 194}
{"Episode reward": -98.99682721057992, "Episode length": 999, "Policy Loss": -0.28511086106300354, "Value Loss": 0.028229856863617897, "_runtime": 11334.728009223938, "_timestamp": 1585608704.3608787, "_step": 195}
{"Episode reward": -97.85076307382992, "Episode length": 999, "Policy Loss": -0.3082829415798187, "Value Loss": 0.05128980427980423, "_runtime": 11336.28884768486, "_timestamp": 1585608705.9217172, "_step": 196}
{"Episode reward": -99.21314468344836, "Episode length": 999, "Policy Loss": -0.24421833455562592, "Value Loss": 0.006770347710698843, "_runtime": 11337.846970796585, "_timestamp": 1585608707.4798403, "_step": 197}
{"Episode reward": -99.21477647056682, "Episode length": 999, "Policy Loss": -0.2473936527967453, "Value Loss": 0.011413438245654106, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875, 239891.71875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-347385.71875, -341076.53125, -334767.375, -328458.1875, -322149.0, -315839.84375, -309530.65625, -303221.46875, -296912.3125, -290603.125, -284293.9375, -277984.75, -271675.59375, -265366.40625, -259057.234375, -252748.0625, -246438.875, -240129.6875, -233820.515625, -227511.34375, -221202.15625, -214892.984375, -208583.8125, -202274.625, -195965.453125, -189656.28125, -183347.09375, -177037.921875, -170728.75, -164419.5625, -158110.390625, -151801.203125, -145492.03125, -139182.859375, -132873.671875, -126564.5, -120255.3125, -113946.140625, -107636.96875, -101327.78125, -95018.609375, -88709.4375, -82400.25, -76091.0625, -69781.90625, -63472.71875, -57163.53125, -50854.375, -44545.1875, -38236.0, -31926.84375, -25617.65625, -19308.46875, -12999.3125, -6690.125, -380.9375, 5928.21875, 12237.40625, 18546.59375, 24855.78125, 31164.9375, 37474.125, 43783.3125, 50092.46875, 56401.65625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-117559.6328125, -108922.5390625, -100285.4375, -91648.34375, -83011.25, -74374.1484375, -65737.0546875, -57099.95703125, -48462.859375, -39825.765625, -31188.6640625, -22551.5703125, -13914.4765625, -5277.375, 3359.71875, 11996.8203125, 20633.9140625, 29271.0078125, 37908.1015625, 46545.2109375, 55182.3046875, 63819.3984375, 72456.4921875, 81093.5859375, 89730.6796875, 98367.7890625, 107004.8828125, 115641.9765625, 124279.0703125, 132916.15625, 141553.28125, 150190.375, 158827.46875, 167464.5625, 176101.65625, 184738.75, 193375.84375, 202012.9375, 210650.0625, 219287.15625, 227924.25, 236561.34375, 245198.4375, 253835.53125, 262472.625, 271109.71875, 279746.8125, 288383.90625, 297021.0, 305658.125, 314295.21875, 322932.3125, 331569.40625, 340206.5, 348843.59375, 357480.6875, 366117.78125, 374754.875, 383391.96875, 392029.09375, 400666.1875, 409303.25, 417940.375, 426577.4375, 435214.5625]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 4.0, 8.0, 7.0, 26.0, 328.0, 78.0, 5.0, 6.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-172202.75, -161391.140625, -150579.53125, -139767.921875, -128956.3203125, -118144.7109375, -107333.109375, -96521.5, -85709.890625, -74898.28125, -64086.671875, -53275.0703125, -42463.4609375, -31651.859375, -20840.25, -10028.640625, 782.96875, 11594.578125, 22406.1875, 33217.796875, 44029.40625, 54841.0, 65652.609375, 76464.21875, 87275.828125, 98087.4375, 108899.03125, 119710.65625, 130522.25, 141333.875, 152145.46875, 162957.09375, 173768.6875, 184580.28125, 195391.90625, 206203.5, 217015.125, 227826.71875, 238638.34375, 249449.9375, 260261.5625, 271073.15625, 281884.75, 292696.375, 303507.96875, 314319.59375, 325131.1875, 335942.8125, 346754.40625, 357566.0, 368377.625, 379189.25, 390000.8125, 400812.4375, 411624.0625, 422435.6875, 433247.25, 444058.875, 454870.5, 465682.0625, 476493.6875, 487305.3125, 498116.9375, 508928.5, 519740.125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-1417897.875, -1379838.875, -1341779.875, -1303720.875, -1265662.0, -1227603.0, -1189544.0, -1151485.0, -1113426.0, -1075367.0, -1037308.0, -999249.0625, -961190.0625, -923131.0625, -885072.125, -847013.125, -808954.125, -770895.125, -732836.125, -694777.1875, -656718.1875, -618659.1875, -580600.25, -542541.25, -504482.25, -466423.25, -428364.25, -390305.3125, -352246.375, -314187.375, -276128.375, -238069.375, -200010.375, -161951.375, -123892.375, -85833.375, -47774.375, -9715.5, 28343.5, 66402.5, 104461.5, 142520.5, 180579.5, 218638.5, 256697.375, 294756.375, 332815.375, 370874.375, 408933.375, 446992.375, 485051.375, 523110.375, 561169.375, 599228.25, 637287.25, 675346.25, 713405.125, 751464.125, 789523.125, 827582.125, 865641.125, 903700.125, 941759.125, 979818.125, 1017877.125]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 4.0, 7.0, 1.0, 0.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-1672672.125, -1627798.125, -1582924.125, -1538050.125, -1493176.125, -1448302.125, -1403428.0, -1358554.0, -1313680.0, -1268806.0, -1223932.0, -1179058.0, -1134184.0, -1089310.0, -1044436.0, -999562.0, -954688.0, -909814.0, -864940.0, -820066.0, -775192.0, -730317.9375, -685443.9375, -640569.9375, -595695.875, -550821.875, -505947.875, -461073.875, -416199.875, -371325.875, -326451.875, -281577.875, -236703.875, -191829.875, -146955.875, -102081.875, -57207.875, -12333.875, 32540.125, 77414.125, 122288.125, 167162.25, 212036.25, 256910.25, 301784.25, 346658.25, 391532.25, 436406.125, 481280.375, 526154.375, 571028.375, 615902.375, 660776.375, 705650.375, 750524.375, 795398.375, 840272.375, 885146.375, 930020.375, 974894.375, 1019768.375, 1064642.375, 1109516.375, 1154390.375, 1199264.375]}, "_runtime": 11338.533745288849, "_timestamp": 1585608708.1666148, "_step": 198}
{"Episode reward": 61.354076859104325, "Episode length": 394, "Policy Loss": 0.726254940032959, "Value Loss": 24.643199920654297, "_runtime": 11340.102757692337, "_timestamp": 1585608709.7356272, "_step": 199}
{"Episode reward": -98.7811240833305, "Episode length": 999, "Policy Loss": -0.23573265969753265, "Value Loss": 0.008302489295601845, "_runtime": 11341.09057545662, "_timestamp": 1585608710.723445, "_step": 200}
{"Episode reward": 38.846831896228586, "Episode length": 619, "Policy Loss": 0.3307996392250061, "Value Loss": 15.717455863952637, "_runtime": 11341.780074357986, "_timestamp": 1585608711.4129438, "_step": 201}
{"Episode reward": 55.55799160504011, "Episode length": 449, "Policy Loss": 1.4045358896255493, "Value Loss": 20.421463012695312, "_runtime": 11343.370137929916, "_timestamp": 1585608713.0030074, "_step": 202}
{"Episode reward": -98.82449099365881, "Episode length": 999, "Policy Loss": -0.26216816902160645, "Value Loss": 0.16505815088748932, "_runtime": 11344.923132658005, "_timestamp": 1585608714.5560021, "_step": 203}
{"Episode reward": -98.67616846878114, "Episode length": 999, "Policy Loss": -0.28482314944267273, "Value Loss": 0.053451038897037506, "_runtime": 11346.44771194458, "_timestamp": 1585608716.0805814, "_step": 204}
{"Episode reward": -97.81259755686582, "Episode length": 999, "Policy Loss": -0.45145052671432495, "Value Loss": 0.31517648696899414, "_runtime": 11348.030405282974, "_timestamp": 1585608717.6632748, "_step": 205}
{"Episode reward": -98.66020662308054, "Episode length": 999, "Policy Loss": -0.27885469794273376, "Value Loss": 0.019158123061060905, "_runtime": 11348.794327020645, "_timestamp": 1585608718.4271965, "_step": 206}
{"Episode reward": 54.43772465413742, "Episode length": 464, "Policy Loss": 0.7815452218055725, "Value Loss": 20.461589813232422, "_runtime": 11350.356126308441, "_timestamp": 1585608719.9889958, "_step": 207}
{"Episode reward": -98.49137803534441, "Episode length": 999, "Policy Loss": -0.3757477104663849, "Value Loss": 0.23604974150657654, "_runtime": 11350.744398832321, "_timestamp": 1585608720.3772683, "_step": 208}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": 3.058624029159546, "Value Loss": 44.314395904541016, "_runtime": 11352.296224117279, "_timestamp": 1585608721.9290936, "_step": 209}
{"Episode reward": -99.01622171906648, "Episode length": 999, "Policy Loss": -0.3189869821071625, "Value Loss": 0.04552754759788513, "_runtime": 11353.868861436844, "_timestamp": 1585608723.501731, "_step": 210}
{"Episode reward": -99.38121519692693, "Episode length": 999, "Policy Loss": -0.3040211498737335, "Value Loss": 0.014358695596456528, "_runtime": 11355.247148513794, "_timestamp": 1585608724.880018, "_step": 211}
{"Episode reward": 10.343839625760793, "Episode length": 913, "Policy Loss": 0.08096439391374588, "Value Loss": 13.110657691955566, "_runtime": 11356.836713552475, "_timestamp": 1585608726.469583, "_step": 212}
{"Episode reward": -98.66836479165262, "Episode length": 999, "Policy Loss": -0.3494347929954529, "Value Loss": 0.026510965079069138, "_runtime": 11358.421983242035, "_timestamp": 1585608728.0548527, "_step": 213}
{"Episode reward": -98.59919449802487, "Episode length": 999, "Policy Loss": -0.37543824315071106, "Value Loss": 0.03483736142516136, "_runtime": 11359.120782136917, "_timestamp": 1585608728.7536516, "_step": 214}
{"Episode reward": 56.97159269241641, "Episode length": 434, "Policy Loss": 0.6375191807746887, "Value Loss": 23.583280563354492, "_runtime": 11360.718341827393, "_timestamp": 1585608730.3512113, "_step": 215}
{"Episode reward": -99.1418005643068, "Episode length": 999, "Policy Loss": -0.49143731594085693, "Value Loss": 0.12146250158548355, "_runtime": 11361.616120576859, "_timestamp": 1585608731.24899, "_step": 216}
{"Episode reward": 44.58650011269592, "Episode length": 561, "Policy Loss": 0.2608608603477478, "Value Loss": 18.14212417602539, "_runtime": 11363.182759284973, "_timestamp": 1585608732.8156288, "_step": 217}
{"Episode reward": -98.76516890455053, "Episode length": 999, "Policy Loss": -0.5250281691551208, "Value Loss": 0.10722795128822327, "_runtime": 11364.777716875076, "_timestamp": 1585608734.4105864, "_step": 218}
{"Episode reward": -98.84848779784997, "Episode length": 999, "Policy Loss": -0.5710374712944031, "Value Loss": 0.03635722026228905, "_runtime": 11366.310816764832, "_timestamp": 1585608735.9436862, "_step": 219}
{"Episode reward": -96.76959767183986, "Episode length": 999, "Policy Loss": -0.7244129776954651, "Value Loss": 0.13568834960460663, "_runtime": 11367.597088098526, "_timestamp": 1585608737.2299576, "_step": 220}
{"Episode reward": 19.784932105009503, "Episode length": 816, "Policy Loss": -0.060083117336034775, "Value Loss": 12.010995864868164, "_runtime": 11368.721885919571, "_timestamp": 1585608738.3547554, "_step": 221}
{"Episode reward": 30.876833862149525, "Episode length": 704, "Policy Loss": 0.08913052827119827, "Value Loss": 13.947640419006348, "_runtime": 11370.291754245758, "_timestamp": 1585608739.9246237, "_step": 222}
{"Episode reward": -98.6334139475484, "Episode length": 999, "Policy Loss": -0.6294882893562317, "Value Loss": 0.12200040370225906, "_runtime": 11371.841571331024, "_timestamp": 1585608741.4744408, "_step": 223}
{"Episode reward": -98.8838458794203, "Episode length": 999, "Policy Loss": -0.595818817615509, "Value Loss": 0.096785768866539, "_runtime": 11373.393298864365, "_timestamp": 1585608743.0261683, "_step": 224}
{"Episode reward": -98.40604718499617, "Episode length": 999, "Policy Loss": -0.6695159673690796, "Value Loss": 0.18454940617084503, "_runtime": 11374.957554101944, "_timestamp": 1585608744.5904236, "_step": 225}
{"Episode reward": -98.23958530424895, "Episode length": 999, "Policy Loss": -0.5058854818344116, "Value Loss": 0.11228517442941666, "_runtime": 11376.519196271896, "_timestamp": 1585608746.1520658, "_step": 226}
{"Episode reward": -98.11204112052748, "Episode length": 999, "Policy Loss": -0.4694187343120575, "Value Loss": 0.01573573611676693, "_runtime": 11378.105020046234, "_timestamp": 1585608747.7378895, "_step": 227}
{"Episode reward": -97.91795941666406, "Episode length": 999, "Policy Loss": -0.38779720664024353, "Value Loss": 0.013489150442183018, "_runtime": 11379.68419122696, "_timestamp": 1585608749.3170607, "_step": 228}
{"Episode reward": -98.85626690677793, "Episode length": 999, "Policy Loss": -0.3322206437587738, "Value Loss": 0.004884994588792324, "_runtime": 11381.259797334671, "_timestamp": 1585608750.8926668, "_step": 229}
{"Episode reward": -98.63005440103859, "Episode length": 999, "Policy Loss": -0.2737430930137634, "Value Loss": 0.005752943456172943, "_runtime": 11382.78511595726, "_timestamp": 1585608752.4179854, "_step": 230}
{"Episode reward": 4.519559712837122, "Episode length": 966, "Policy Loss": 0.2498086839914322, "Value Loss": 10.427925109863281, "_runtime": 11384.368167638779, "_timestamp": 1585608754.0010371, "_step": 231}
{"Episode reward": -99.27754333778987, "Episode length": 999, "Policy Loss": -0.22244559228420258, "Value Loss": 0.02930092252790928, "_runtime": 11385.349171876907, "_timestamp": 1585608754.9820414, "_step": 232}
{"Episode reward": 39.61924004196827, "Episode length": 615, "Policy Loss": 0.6415125727653503, "Value Loss": 16.360849380493164, "_runtime": 11386.968709945679, "_timestamp": 1585608756.6015794, "_step": 233}
{"Episode reward": -98.40474513475137, "Episode length": 999, "Policy Loss": -0.22857174277305603, "Value Loss": 0.018356353044509888, "_runtime": 11388.545789003372, "_timestamp": 1585608758.1786585, "_step": 234}
{"Episode reward": -98.82360354498547, "Episode length": 999, "Policy Loss": -0.22382567822933197, "Value Loss": 0.022240636870265007, "_runtime": 11390.082971572876, "_timestamp": 1585608759.715841, "_step": 235}
{"Episode reward": -97.3794692009524, "Episode length": 999, "Policy Loss": -0.24420608580112457, "Value Loss": 0.008774138055741787, "_runtime": 11391.659626722336, "_timestamp": 1585608761.2924962, "_step": 236}
{"Episode reward": -98.91959796835027, "Episode length": 999, "Policy Loss": -0.2743781507015228, "Value Loss": 0.0030996620189398527, "_runtime": 11393.243762254715, "_timestamp": 1585608762.8766317, "_step": 237}
{"Episode reward": -98.23839466342282, "Episode length": 999, "Policy Loss": -0.26400089263916016, "Value Loss": 0.007819895632565022, "_runtime": 11394.161150693893, "_timestamp": 1585608763.7940202, "_step": 238}
{"Episode reward": 44.566405802036456, "Episode length": 567, "Policy Loss": 0.5896351933479309, "Value Loss": 17.618328094482422, "_runtime": 11395.754582881927, "_timestamp": 1585608765.3874524, "_step": 239}
{"Episode reward": -99.24869728152018, "Episode length": 999, "Policy Loss": -0.3380586504936218, "Value Loss": 0.012304717674851418, "_runtime": 11396.472651004791, "_timestamp": 1585608766.1055205, "_step": 240}
{"Episode reward": 57.23196174429289, "Episode length": 430, "Policy Loss": 0.8713854551315308, "Value Loss": 23.21760368347168, "_runtime": 11398.029319763184, "_timestamp": 1585608767.6621892, "_step": 241}
{"Episode reward": -98.4123893807729, "Episode length": 999, "Policy Loss": -0.2933330833911896, "Value Loss": 0.03814489394426346, "_runtime": 11399.624118328094, "_timestamp": 1585608769.2569878, "_step": 242}
{"Episode reward": -99.25196882696628, "Episode length": 999, "Policy Loss": -0.36268725991249084, "Value Loss": 0.011899949982762337, "_runtime": 11401.156314611435, "_timestamp": 1585608770.789184, "_step": 243}
{"Episode reward": -99.3172048612395, "Episode length": 999, "Policy Loss": -0.33831411600112915, "Value Loss": 0.008273322135210037, "_runtime": 11402.736679077148, "_timestamp": 1585608772.3695486, "_step": 244}
{"Episode reward": -97.16818563007023, "Episode length": 999, "Policy Loss": -0.2799041271209717, "Value Loss": 0.014996156096458435, "_runtime": 11404.332594633102, "_timestamp": 1585608773.965464, "_step": 245}
{"Episode reward": -98.6249639961429, "Episode length": 999, "Policy Loss": -0.29285547137260437, "Value Loss": 0.007022302132099867, "_runtime": 11405.202464103699, "_timestamp": 1585608774.8353336, "_step": 246}
{"Episode reward": 47.20871248682957, "Episode length": 541, "Policy Loss": 0.7216776609420776, "Value Loss": 18.466171264648438, "_runtime": 11406.774646520615, "_timestamp": 1585608776.407516, "_step": 247}
{"Episode reward": -99.13985136939638, "Episode length": 999, "Policy Loss": -0.27216050028800964, "Value Loss": 0.003448556875810027, "_runtime": 11408.37394618988, "_timestamp": 1585608778.0068157, "_step": 248}
{"Episode reward": -99.50717340886084, "Episode length": 999, "Policy Loss": -0.26781901717185974, "Value Loss": 0.002859076950699091, "_runtime": 11409.950760126114, "_timestamp": 1585608779.5836296, "_step": 249}
{"Episode reward": -98.90500494397106, "Episode length": 999, "Policy Loss": -0.24913184344768524, "Value Loss": 0.0025670770555734634, "_runtime": 11410.60817027092, "_timestamp": 1585608780.2410398, "_step": 250}
{"Episode reward": 61.01169498542577, "Episode length": 394, "Policy Loss": 1.399359107017517, "Value Loss": 25.368972778320312, "_runtime": 11412.10123515129, "_timestamp": 1585608781.7341046, "_step": 251}
{"Episode reward": 7.432359493463338, "Episode length": 940, "Policy Loss": 0.31947922706604004, "Value Loss": 10.632218360900879, "_runtime": 11413.673785686493, "_timestamp": 1585608783.3066552, "_step": 252}
{"Episode reward": -98.64241849043079, "Episode length": 999, "Policy Loss": -0.23973901569843292, "Value Loss": 0.0025469500105828047, "_runtime": 11415.194633483887, "_timestamp": 1585608784.827503, "_step": 253}
{"Episode reward": -99.12772765595594, "Episode length": 999, "Policy Loss": -0.24863766133785248, "Value Loss": 0.0024372152984142303, "_runtime": 11416.773749351501, "_timestamp": 1585608786.4066188, "_step": 254}
{"Episode reward": -99.1008935782572, "Episode length": 999, "Policy Loss": -0.24383391439914703, "Value Loss": 0.00246039149351418, "_runtime": 11418.34378528595, "_timestamp": 1585608787.9766548, "_step": 255}
{"Episode reward": -97.71298871314099, "Episode length": 999, "Policy Loss": -0.23320603370666504, "Value Loss": 0.0025404414627701044, "_runtime": 11419.910858869553, "_timestamp": 1585608789.5437284, "_step": 256}
{"Episode reward": -99.0966942972854, "Episode length": 999, "Policy Loss": -0.24793723225593567, "Value Loss": 0.0025331336073577404, "_runtime": 11421.496703147888, "_timestamp": 1585608791.1295726, "_step": 257}
{"Episode reward": -98.79433656611455, "Episode length": 999, "Policy Loss": -0.24168147146701813, "Value Loss": 0.0025103657972067595, "_runtime": 11423.058055400848, "_timestamp": 1585608792.690925, "_step": 258}
{"Episode reward": -97.75778611599877, "Episode length": 999, "Policy Loss": -0.2366592139005661, "Value Loss": 0.0025043445639312267, "_runtime": 11424.626700162888, "_timestamp": 1585608794.2595696, "_step": 259}
{"Episode reward": -98.62371981289809, "Episode length": 999, "Policy Loss": -0.2403319925069809, "Value Loss": 0.0024903675075620413, "_runtime": 11426.204105377197, "_timestamp": 1585608795.8369749, "_step": 260}
{"Episode reward": -98.73825821132463, "Episode length": 999, "Policy Loss": -0.24085159599781036, "Value Loss": 0.0024604930076748133, "_runtime": 11427.478029489517, "_timestamp": 1585608797.110899, "_step": 261}
{"Episode reward": 20.016748941276916, "Episode length": 808, "Policy Loss": 0.581105649471283, "Value Loss": 12.366528511047363, "_runtime": 11429.045590877533, "_timestamp": 1585608798.6784604, "_step": 262}
{"Episode reward": -98.40943669882833, "Episode length": 999, "Policy Loss": -0.23354633152484894, "Value Loss": 0.0023447528947144747, "_runtime": 11430.627141952515, "_timestamp": 1585608800.2600114, "_step": 263}
{"Episode reward": -98.77111910633431, "Episode length": 999, "Policy Loss": -0.2313191145658493, "Value Loss": 0.002301957458257675, "_runtime": 11432.181825637817, "_timestamp": 1585608801.8146951, "_step": 264}
{"Episode reward": -98.77638269750473, "Episode length": 999, "Policy Loss": -0.23074626922607422, "Value Loss": 0.0022399062290787697, "_runtime": 11432.68800330162, "_timestamp": 1585608802.3208728, "_step": 265}
{"Episode reward": 70.37189812291273, "Episode length": 304, "Policy Loss": 1.5191234350204468, "Value Loss": 32.86740493774414, "_runtime": 11434.294879674911, "_timestamp": 1585608803.9277492, "_step": 266}
{"Episode reward": -98.65468688623126, "Episode length": 999, "Policy Loss": -0.23331157863140106, "Value Loss": 0.002256689826026559, "_runtime": 11435.86907339096, "_timestamp": 1585608805.5019429, "_step": 267}
{"Episode reward": -98.74733558494258, "Episode length": 999, "Policy Loss": -0.2339593768119812, "Value Loss": 0.00236465223133564, "_runtime": 11437.370914936066, "_timestamp": 1585608807.0037844, "_step": 268}
{"Episode reward": -98.18081063641888, "Episode length": 999, "Policy Loss": -0.2309805005788803, "Value Loss": 0.0024963365867733955, "_runtime": 11437.885512590408, "_timestamp": 1585608807.518382, "_step": 269}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 1.322909951210022, "Value Loss": 32.757301330566406, "_runtime": 11439.453004598618, "_timestamp": 1585608809.085874, "_step": 270}
{"Episode reward": -98.25108892769593, "Episode length": 999, "Policy Loss": -0.24566969275474548, "Value Loss": 0.00267716683447361, "_runtime": 11441.013105392456, "_timestamp": 1585608810.6459749, "_step": 271}
{"Episode reward": -98.74826676728183, "Episode length": 999, "Policy Loss": -0.24093161523342133, "Value Loss": 0.0028288369067013264, "_runtime": 11442.442091464996, "_timestamp": 1585608812.074961, "_step": 272}
{"Episode reward": 6.7368923855133005, "Episode length": 949, "Policy Loss": 0.2637897729873657, "Value Loss": 10.52813720703125, "_runtime": 11444.028068780899, "_timestamp": 1585608813.6609383, "_step": 273}
{"Episode reward": -98.23385713967157, "Episode length": 999, "Policy Loss": -0.23803195357322693, "Value Loss": 0.00392018212005496, "_runtime": 11445.594371557236, "_timestamp": 1585608815.227241, "_step": 274}
{"Episode reward": -99.19244259771595, "Episode length": 999, "Policy Loss": -0.2561868131160736, "Value Loss": 0.0028470002580434084, "_runtime": 11447.13533616066, "_timestamp": 1585608816.7682056, "_step": 275}
{"Episode reward": -98.77383445676546, "Episode length": 999, "Policy Loss": -0.24908220767974854, "Value Loss": 0.0026512944605201483, "_runtime": 11448.71575975418, "_timestamp": 1585608818.3486292, "_step": 276}
{"Episode reward": -97.17586823752822, "Episode length": 999, "Policy Loss": -0.22467991709709167, "Value Loss": 0.002911183051764965, "_runtime": 11450.26622080803, "_timestamp": 1585608819.8990903, "_step": 277}
{"Episode reward": -98.43210968280161, "Episode length": 999, "Policy Loss": -0.23491045832633972, "Value Loss": 0.0024312669411301613, "_runtime": 11451.214656829834, "_timestamp": 1585608820.8475263, "_step": 278}
{"Episode reward": 41.73521453384399, "Episode length": 597, "Policy Loss": 0.5817101001739502, "Value Loss": 16.736703872680664, "_runtime": 11452.793787956238, "_timestamp": 1585608822.4266574, "_step": 279}
{"Episode reward": -99.06292951862899, "Episode length": 999, "Policy Loss": -0.23059768974781036, "Value Loss": 0.002213930943980813, "_runtime": 11454.182879686356, "_timestamp": 1585608823.8157492, "_step": 280}
{"Episode reward": 11.246382635292349, "Episode length": 894, "Policy Loss": 0.29543808102607727, "Value Loss": 11.178518295288086, "_runtime": 11455.709694862366, "_timestamp": 1585608825.3425643, "_step": 281}
{"Episode reward": -98.75316292007497, "Episode length": 999, "Policy Loss": -0.21944479644298553, "Value Loss": 0.002253833692520857, "_runtime": 11456.790677070618, "_timestamp": 1585608826.4235466, "_step": 282}
{"Episode reward": 36.29296886637775, "Episode length": 655, "Policy Loss": 0.5330691933631897, "Value Loss": 15.25681209564209, "_runtime": 11458.356743097305, "_timestamp": 1585608827.9896126, "_step": 283}
{"Episode reward": -98.62733484960197, "Episode length": 999, "Policy Loss": -0.21931174397468567, "Value Loss": 0.002272689947858453, "_runtime": 11458.992028713226, "_timestamp": 1585608828.6248982, "_step": 284}
{"Episode reward": 61.664999497626006, "Episode length": 390, "Policy Loss": 1.0677207708358765, "Value Loss": 25.62200927734375, "_runtime": 11460.50140428543, "_timestamp": 1585608830.1342738, "_step": 285}
{"Episode reward": 2.697163893001459, "Episode length": 988, "Policy Loss": 0.30305755138397217, "Value Loss": 10.113922119140625, "_runtime": 11462.07739329338, "_timestamp": 1585608831.7102628, "_step": 286}
{"Episode reward": -99.41938487835004, "Episode length": 999, "Policy Loss": -0.24706615507602692, "Value Loss": 0.0025579349603503942, "_runtime": 11463.589499235153, "_timestamp": 1585608833.2223687, "_step": 287}
{"Episode reward": -98.61575870857118, "Episode length": 999, "Policy Loss": -0.24765053391456604, "Value Loss": 0.002712760353460908, "_runtime": 11464.337535619736, "_timestamp": 1585608833.970405, "_step": 288}
{"Episode reward": 53.92003715290592, "Episode length": 463, "Policy Loss": 1.3468592166900635, "Value Loss": 21.578977584838867, "_runtime": 11465.900644302368, "_timestamp": 1585608835.5335138, "_step": 289}
{"Episode reward": -99.00597336909897, "Episode length": 999, "Policy Loss": -0.2669747769832611, "Value Loss": 0.002974177710711956, "_runtime": 11467.463703393936, "_timestamp": 1585608837.0965729, "_step": 290}
{"Episode reward": -98.99104998868226, "Episode length": 999, "Policy Loss": -0.26871025562286377, "Value Loss": 0.0033265314996242523, "_runtime": 11468.985314130783, "_timestamp": 1585608838.6181836, "_step": 291}
{"Episode reward": -98.87856459637828, "Episode length": 999, "Policy Loss": -0.26300761103630066, "Value Loss": 0.004539991728961468, "_runtime": 11470.552019119263, "_timestamp": 1585608840.1848886, "_step": 292}
{"Episode reward": -97.77941022776497, "Episode length": 999, "Policy Loss": -0.23478052020072937, "Value Loss": 0.005524446722120047, "_runtime": 11472.120604991913, "_timestamp": 1585608841.7534745, "_step": 293}
{"Episode reward": -99.37235530301606, "Episode length": 999, "Policy Loss": -0.2686566412448883, "Value Loss": 0.0029930074233561754, "_runtime": 11473.690554380417, "_timestamp": 1585608843.3234239, "_step": 294}
{"Episode reward": -98.66981918210855, "Episode length": 999, "Policy Loss": -0.25138789415359497, "Value Loss": 0.0028732800856232643, "_runtime": 11475.27612233162, "_timestamp": 1585608844.9089918, "_step": 295}
{"Episode reward": -99.10200740087046, "Episode length": 999, "Policy Loss": -0.24885186553001404, "Value Loss": 0.0025721387937664986, "_runtime": 11476.847923517227, "_timestamp": 1585608846.480793, "_step": 296}
{"Episode reward": -98.88619053968807, "Episode length": 999, "Policy Loss": -0.2394939810037613, "Value Loss": 0.002424485282972455, "_runtime": 11478.040211439133, "_timestamp": 1585608847.673081, "_step": 297}
{"Episode reward": 25.39486598642901, "Episode length": 756, "Policy Loss": 0.4671378433704376, "Value Loss": 13.218876838684082, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177, -0.2350025475025177]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 9.0], "bins": [-4.347560882568359, -4.275130748748779, -4.202701091766357, -4.130270957946777, -4.057840824127197, -3.9854111671447754, -3.9129810333251953, -3.8405511379241943, -3.7681212425231934, -3.6956911087036133, -3.6232612133026123, -3.5508313179016113, -3.4784011840820312, -3.4059712886810303, -3.3335413932800293, -3.261111259460449, -3.1886813640594482, -3.1162514686584473, -3.043821334838867, -2.971391439437866, -2.8989615440368652, -2.826531410217285, -2.754101514816284, -2.681671619415283, -2.609241485595703, -2.536811590194702, -2.464381694793701, -2.391951560974121, -2.31952166557312, -2.247091770172119, -2.174661874771118, -2.102231740951538, -2.029801845550537, -1.9573719501495361, -1.884941816329956, -1.812511920928955, -1.740082025527954, -1.667651891708374, -1.595221996307373, -1.522792100906372, -1.450362205505371, -1.377932071685791, -1.30550217628479, -1.233072280883789, -1.160642147064209, -1.088212251663208, -1.015782356262207, -0.943352222442627, -0.870922327041626, -0.798492431640625, -0.7260622978210449, -0.653632402420044, -0.581202507019043, -0.5087723731994629, -0.4363424777984619, -0.36391258239746094, -0.29148244857788086, -0.21905279159545898, -0.1466226577758789, -0.07419252395629883, -0.0017628669738769531, 0.07066726684570312, 0.1430974006652832, 0.21552705764770508, 0.28795719146728516]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.42612719535827637, -0.41795089840888977, -0.4097745716571808, -0.4015982747077942, -0.3934219479560852, -0.3852456510066986, -0.3770693242549896, -0.368893027305603, -0.36071670055389404, -0.35254040360450745, -0.34436410665512085, -0.33618777990341187, -0.32801148295402527, -0.3198351562023163, -0.3116588592529297, -0.3034825325012207, -0.2953062355518341, -0.2871299386024475, -0.2789536118507385, -0.27077728509902954, -0.26260098814964294, -0.25442469120025635, -0.24624837934970856, -0.23807206749916077, -0.22989575564861298, -0.22171944379806519, -0.2135431319475174, -0.2053668200969696, -0.197190523147583, -0.18901421129703522, -0.18083789944648743, -0.17266157269477844, -0.16448527574539185, -0.15630897879600525, -0.14813265204429626, -0.13995635509490967, -0.13178002834320068, -0.12360373139381409, -0.1154274046421051, -0.1072511076927185, -0.09907478094100952, -0.09089848399162292, -0.08272218704223633, -0.07454586029052734, -0.06636956334114075, -0.05819323658943176, -0.050016939640045166, -0.04184061288833618, -0.033664315938949585, -0.02548801898956299, -0.017311692237854004, -0.009135395288467407, -0.0009590685367584229, 0.007217228412628174, 0.015393555164337158, 0.023569852113723755, 0.03174614906311035, 0.039922475814819336, 0.04809877276420593, 0.05627509951591492, 0.06445139646530151, 0.0726277232170105, 0.08080404996871948, 0.08898031711578369, 0.09715664386749268]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 0.0, 2.0, 3.0, 4.0, 1.0, 4.0, 4.0, 1.0, 8.0, 13.0, 16.0, 31.0, 301.0, 20.0, 7.0, 8.0, 5.0, 5.0, 9.0, 6.0, 4.0, 3.0, 1.0, 4.0, 2.0, 0.0, 0.0, 3.0, 8.0, 4.0], "bins": [-1.137974739074707, -1.113325595855713, -1.0886765718460083, -1.0640274286270142, -1.03937828540802, -1.0147292613983154, -0.9900801181793213, -0.9654309749603271, -0.9407818913459778, -0.9161328077316284, -0.8914836645126343, -0.8668345808982849, -0.8421854972839355, -0.8175363540649414, -0.792887270450592, -0.7682381868362427, -0.7435890436172485, -0.7189399003982544, -0.694290816783905, -0.6696417331695557, -0.6449925899505615, -0.6203435063362122, -0.5956944227218628, -0.5710452795028687, -0.5463961958885193, -0.5217471122741699, -0.4970979690551758, -0.4724488854408264, -0.44779980182647705, -0.4231506586074829, -0.39850157499313354, -0.3738524317741394, -0.34920334815979004, -0.3245542645454407, -0.29990512132644653, -0.27525603771209717, -0.250606894493103, -0.22595781087875366, -0.2013087272644043, -0.17665958404541016, -0.1520105004310608, -0.12736141681671143, -0.10271227359771729, -0.07806313037872314, -0.053414106369018555, -0.028764963150024414, -0.0041158199310302734, 0.020533204078674316, 0.04518234729766846, 0.0698314905166626, 0.09448051452636719, 0.11912965774536133, 0.14377880096435547, 0.16842782497406006, 0.1930769681930542, 0.21772611141204834, 0.24237513542175293, 0.26702427864074707, 0.2916734218597412, 0.31632256507873535, 0.34097158908843994, 0.3656207323074341, 0.3902698755264282, 0.4149188995361328, 0.43956804275512695]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6030522584915161, -0.5715733170509338, -0.5400944352149963, -0.5086154937744141, -0.4771365821361542, -0.4456576704978943, -0.414178729057312, -0.3826998174190521, -0.35122090578079224, -0.31974199414253235, -0.28826308250427246, -0.2567841410636902, -0.2253052294254303, -0.1938263177871704, -0.16234737634658813, -0.13086846470832825, -0.09938955307006836, -0.06791061162948608, -0.036431729793548584, -0.004952788352966309, 0.02652609348297119, 0.05800503492355347, 0.08948397636413574, 0.12096285820007324, 0.15244179964065552, 0.1839207410812378, 0.2153996229171753, 0.24687856435775757, 0.27835750579833984, 0.30983638763427734, 0.3413153290748596, 0.3727942109107971, 0.4042731523513794, 0.4357520341873169, 0.46723103523254395, 0.49870991706848145, 0.530188798904419, 0.561667799949646, 0.5931466817855835, 0.624625563621521, 0.6561044454574585, 0.6875834465026855, 0.719062328338623, 0.7505412101745605, 0.7820202112197876, 0.8134990930557251, 0.8449779748916626, 0.8764569759368896, 0.9079358577728271, 0.9394147396087646, 0.9708937406539917, 1.0023726224899292, 1.0338515043258667, 1.0653305053710938, 1.0968093872070312, 1.1282882690429688, 1.1597672700881958, 1.1912461519241333, 1.2227250337600708, 1.2542039155960083, 1.2856829166412354, 1.3171617984771729, 1.3486406803131104, 1.3801196813583374, 1.411598563194275]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 3.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 6.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4872138798236847, -0.4641209840774536, -0.44102805852890015, -0.41793516278266907, -0.394842267036438, -0.3717493414878845, -0.34865644574165344, -0.32556354999542236, -0.3024706244468689, -0.2793777287006378, -0.25628483295440674, -0.23319193720817566, -0.2100990116596222, -0.1870061159133911, -0.16391322016716003, -0.14082029461860657, -0.11772739887237549, -0.09463450312614441, -0.07154157757759094, -0.04844868183135986, -0.025355786085128784, -0.0022628605365753174, 0.020830005407333374, 0.04392293095588684, 0.06701585650444031, 0.090108722448349, 0.11320164799690247, 0.13629457354545593, 0.15938743948936462, 0.1824803650379181, 0.20557329058647156, 0.22866615653038025, 0.2517590820789337, 0.2748520076274872, 0.2979448735713959, 0.32103779911994934, 0.3441307246685028, 0.3672235906124115, 0.39031651616096497, 0.41340944170951843, 0.4365023076534271, 0.4595952332019806, 0.48268815875053406, 0.5057810544967651, 0.5288739204406738, 0.5519669055938721, 0.5750597715377808, 0.5981526374816895, 0.6212456226348877, 0.6443384885787964, 0.6674313545227051, 0.6905243396759033, 0.713617205619812, 0.7367100715637207, 0.759803056716919, 0.7828959226608276, 0.8059887886047363, 0.8290817737579346, 0.8521746397018433, 0.875267505645752, 0.8983604907989502, 0.9214533567428589, 0.9445462226867676, 0.9676392078399658, 0.9907320737838745]}, "_runtime": 11479.613991737366, "_timestamp": 1585608849.2468612, "_step": 298}
{"Episode reward": -98.95704418626951, "Episode length": 999, "Policy Loss": -0.2283681482076645, "Value Loss": 0.0023055262863636017, "_runtime": 11480.56412100792, "_timestamp": 1585608850.1969905, "_step": 299}
{"Episode reward": 45.03716278816116, "Episode length": 557, "Policy Loss": 0.7055007815361023, "Value Loss": 17.942358016967773, "_runtime": 11482.106389045715, "_timestamp": 1585608851.7392585, "_step": 300}
{"Episode reward": -99.24053053157787, "Episode length": 999, "Policy Loss": -0.2336476445198059, "Value Loss": 0.0024738614447414875, "_runtime": 11483.664453029633, "_timestamp": 1585608853.2973225, "_step": 301}
{"Episode reward": -98.79772151623324, "Episode length": 999, "Policy Loss": -0.2382403314113617, "Value Loss": 0.002392565133050084, "_runtime": 11485.18060350418, "_timestamp": 1585608854.813473, "_step": 302}
{"Episode reward": -99.011252490768, "Episode length": 999, "Policy Loss": -0.2402462363243103, "Value Loss": 0.002430984051898122, "_runtime": 11486.731385707855, "_timestamp": 1585608856.3642552, "_step": 303}
{"Episode reward": 2.3050278285979573, "Episode length": 993, "Policy Loss": 0.32599174976348877, "Value Loss": 10.062682151794434, "_runtime": 11488.291640043259, "_timestamp": 1585608857.9245095, "_step": 304}
{"Episode reward": -98.68224794722262, "Episode length": 999, "Policy Loss": -0.24563154578208923, "Value Loss": 0.0027121054008603096, "_runtime": 11489.225704908371, "_timestamp": 1585608858.8585744, "_step": 305}
{"Episode reward": 41.095322639005644, "Episode length": 596, "Policy Loss": 0.626703679561615, "Value Loss": 16.76309585571289, "_runtime": 11490.782041549683, "_timestamp": 1585608860.414911, "_step": 306}
{"Episode reward": -98.96007985452937, "Episode length": 999, "Policy Loss": -0.2601052522659302, "Value Loss": 0.0029085029382258654, "_runtime": 11491.547062635422, "_timestamp": 1585608861.179932, "_step": 307}
{"Episode reward": 52.93356582805352, "Episode length": 475, "Policy Loss": 1.2695908546447754, "Value Loss": 21.032024383544922, "_runtime": 11493.08471274376, "_timestamp": 1585608862.7175822, "_step": 308}
{"Episode reward": -98.60559190504459, "Episode length": 999, "Policy Loss": -0.23120738565921783, "Value Loss": 0.006007146090269089, "_runtime": 11494.636322975159, "_timestamp": 1585608864.2691925, "_step": 309}
{"Episode reward": -99.3162324238938, "Episode length": 999, "Policy Loss": -0.26117023825645447, "Value Loss": 0.003708160948008299, "_runtime": 11496.145049095154, "_timestamp": 1585608865.7779186, "_step": 310}
{"Episode reward": -98.10775102117384, "Episode length": 999, "Policy Loss": -0.23750300705432892, "Value Loss": 0.004115534946322441, "_runtime": 11497.715120315552, "_timestamp": 1585608867.3479898, "_step": 311}
{"Episode reward": -98.58997737435992, "Episode length": 999, "Policy Loss": -0.24927617609500885, "Value Loss": 0.0028749199118465185, "_runtime": 11498.708214521408, "_timestamp": 1585608868.341084, "_step": 312}
{"Episode reward": 38.43004044346735, "Episode length": 628, "Policy Loss": 0.546245276927948, "Value Loss": 15.908735275268555, "_runtime": 11499.429371118546, "_timestamp": 1585608869.0622406, "_step": 313}
{"Episode reward": 55.5613829053054, "Episode length": 453, "Policy Loss": 0.7970297932624817, "Value Loss": 22.056188583374023, "_runtime": 11500.998132944107, "_timestamp": 1585608870.6310024, "_step": 314}
{"Episode reward": -98.69278621331216, "Episode length": 999, "Policy Loss": -0.23820209503173828, "Value Loss": 0.0025297647807747126, "_runtime": 11502.549098491669, "_timestamp": 1585608872.181968, "_step": 315}
{"Episode reward": -98.93856651919539, "Episode length": 999, "Policy Loss": -0.24048636853694916, "Value Loss": 0.00243846676312387, "_runtime": 11504.106605529785, "_timestamp": 1585608873.739475, "_step": 316}
{"Episode reward": -98.73183451911476, "Episode length": 999, "Policy Loss": -0.23826785385608673, "Value Loss": 0.0024463310837745667, "_runtime": 11505.683286190033, "_timestamp": 1585608875.3161557, "_step": 317}
{"Episode reward": -96.14146147109456, "Episode length": 999, "Policy Loss": -0.21173465251922607, "Value Loss": 0.002357702236622572, "_runtime": 11507.273209095001, "_timestamp": 1585608876.9060786, "_step": 318}
{"Episode reward": -98.85074648036131, "Episode length": 999, "Policy Loss": -0.22911591827869415, "Value Loss": 0.002320688683539629, "_runtime": 11508.299674987793, "_timestamp": 1585608877.9325445, "_step": 319}
{"Episode reward": 37.126131518414525, "Episode length": 640, "Policy Loss": 0.5681143403053284, "Value Loss": 15.616473197937012, "_runtime": 11509.875905513763, "_timestamp": 1585608879.508775, "_step": 320}
{"Episode reward": -98.29933035855417, "Episode length": 999, "Policy Loss": -0.23302064836025238, "Value Loss": 0.0025968635454773903, "_runtime": 11511.469212293625, "_timestamp": 1585608881.1020818, "_step": 321}
{"Episode reward": -98.60916032343754, "Episode length": 999, "Policy Loss": -0.2390042245388031, "Value Loss": 0.002391412854194641, "_runtime": 11512.638441324234, "_timestamp": 1585608882.2713108, "_step": 322}
{"Episode reward": 26.10090907199563, "Episode length": 749, "Policy Loss": 0.6033775210380554, "Value Loss": 13.340497016906738, "_runtime": 11514.206180334091, "_timestamp": 1585608883.8390498, "_step": 323}
{"Episode reward": -98.91990845143782, "Episode length": 999, "Policy Loss": -0.2502341568470001, "Value Loss": 0.0026771125849336386, "_runtime": 11515.099650382996, "_timestamp": 1585608884.7325199, "_step": 324}
{"Episode reward": 46.208261021698135, "Episode length": 551, "Policy Loss": 0.7301713824272156, "Value Loss": 18.128324508666992, "_runtime": 11515.676102399826, "_timestamp": 1585608885.308972, "_step": 325}
{"Episode reward": 64.73996484525829, "Episode length": 354, "Policy Loss": 1.3309041261672974, "Value Loss": 28.209972381591797, "_runtime": 11517.254947185516, "_timestamp": 1585608886.8878167, "_step": 326}
{"Episode reward": -98.38888825478108, "Episode length": 999, "Policy Loss": -0.28396323323249817, "Value Loss": 0.005163409281522036, "_runtime": 11518.800137043, "_timestamp": 1585608888.4330065, "_step": 327}
{"Episode reward": -98.62345208891249, "Episode length": 999, "Policy Loss": -0.3100796341896057, "Value Loss": 0.006247362587600946, "_runtime": 11520.311880111694, "_timestamp": 1585608889.9447496, "_step": 328}
{"Episode reward": -97.33744529420514, "Episode length": 999, "Policy Loss": -0.2824171781539917, "Value Loss": 0.018327804282307625, "_runtime": 11521.89796090126, "_timestamp": 1585608891.5308304, "_step": 329}
{"Episode reward": -98.27910656276178, "Episode length": 999, "Policy Loss": -0.32398462295532227, "Value Loss": 0.009221910499036312, "_runtime": 11522.683215618134, "_timestamp": 1585608892.316085, "_step": 330}
{"Episode reward": 53.08031830898547, "Episode length": 480, "Policy Loss": 0.6961289048194885, "Value Loss": 20.79182243347168, "_runtime": 11524.25469827652, "_timestamp": 1585608893.8875678, "_step": 331}
{"Episode reward": -98.98353082679763, "Episode length": 999, "Policy Loss": -0.31605562567710876, "Value Loss": 0.0143947284668684, "_runtime": 11525.84319448471, "_timestamp": 1585608895.476064, "_step": 332}
{"Episode reward": -98.98538729786317, "Episode length": 999, "Policy Loss": -0.3216497302055359, "Value Loss": 0.006628981791436672, "_runtime": 11526.972405672073, "_timestamp": 1585608896.6052752, "_step": 333}
{"Episode reward": 27.781263005418168, "Episode length": 730, "Policy Loss": 0.5254147052764893, "Value Loss": 13.671096801757812, "_runtime": 11528.58844089508, "_timestamp": 1585608898.2213104, "_step": 334}
{"Episode reward": -99.29341560166733, "Episode length": 999, "Policy Loss": -0.3168375790119171, "Value Loss": 0.00643256725743413, "_runtime": 11529.781453609467, "_timestamp": 1585608899.414323, "_step": 335}
{"Episode reward": 25.994713915761395, "Episode length": 753, "Policy Loss": 0.7295930981636047, "Value Loss": 13.24986743927002, "_runtime": 11531.32941031456, "_timestamp": 1585608900.9622798, "_step": 336}
{"Episode reward": -99.04655661676745, "Episode length": 999, "Policy Loss": -0.301396906375885, "Value Loss": 0.009634810499846935, "_runtime": 11532.920397281647, "_timestamp": 1585608902.5532668, "_step": 337}
{"Episode reward": -98.46607695125556, "Episode length": 999, "Policy Loss": -0.28202202916145325, "Value Loss": 0.009107504971325397, "_runtime": 11534.485962867737, "_timestamp": 1585608904.1188323, "_step": 338}
{"Episode reward": -99.06518160433419, "Episode length": 999, "Policy Loss": -0.2988124489784241, "Value Loss": 0.0038463936652988195, "_runtime": 11536.079258680344, "_timestamp": 1585608905.7121282, "_step": 339}
{"Episode reward": -98.97740190632115, "Episode length": 999, "Policy Loss": -0.2857809364795685, "Value Loss": 0.0037561804056167603, "_runtime": 11537.658797502518, "_timestamp": 1585608907.291667, "_step": 340}
{"Episode reward": -98.7880630208439, "Episode length": 999, "Policy Loss": -0.26786816120147705, "Value Loss": 0.0032491900492459536, "_runtime": 11539.25605893135, "_timestamp": 1585608908.8889284, "_step": 341}
{"Episode reward": -98.68394825752935, "Episode length": 999, "Policy Loss": -0.2564946711063385, "Value Loss": 0.002841856563463807, "_runtime": 11540.84145784378, "_timestamp": 1585608910.4743273, "_step": 342}
{"Episode reward": -99.18142865535457, "Episode length": 999, "Policy Loss": -0.25002893805503845, "Value Loss": 0.0025405760388821363, "_runtime": 11541.772085428238, "_timestamp": 1585608911.404955, "_step": 343}
{"Episode reward": 43.23208732775582, "Episode length": 574, "Policy Loss": 0.593011200428009, "Value Loss": 17.41748809814453, "_runtime": 11542.669116020203, "_timestamp": 1585608912.3019855, "_step": 344}
{"Episode reward": 45.64318877300502, "Episode length": 554, "Policy Loss": 0.6248379349708557, "Value Loss": 18.032434463500977, "_runtime": 11544.205957174301, "_timestamp": 1585608913.8388267, "_step": 345}
{"Episode reward": 4.335702288546898, "Episode length": 973, "Policy Loss": 0.22970671951770782, "Value Loss": 10.25013542175293, "_runtime": 11545.094303131104, "_timestamp": 1585608914.7271726, "_step": 346}
{"Episode reward": 45.3183052492662, "Episode length": 562, "Policy Loss": 1.249216914176941, "Value Loss": 17.716196060180664, "_runtime": 11545.719859838486, "_timestamp": 1585608915.3527293, "_step": 347}
{"Episode reward": 60.966647148008995, "Episode length": 394, "Policy Loss": 1.006109595298767, "Value Loss": 25.18482780456543, "_runtime": 11547.284511327744, "_timestamp": 1585608916.9173808, "_step": 348}
{"Episode reward": -99.04243798468714, "Episode length": 999, "Policy Loss": -0.4336668848991394, "Value Loss": 0.01178155466914177, "_runtime": 11548.348902463913, "_timestamp": 1585608917.981772, "_step": 349}
{"Episode reward": 32.20312697367781, "Episode length": 684, "Policy Loss": 0.25741955637931824, "Value Loss": 14.47575855255127, "_runtime": 11549.538418531418, "_timestamp": 1585608919.171288, "_step": 350}
{"Episode reward": 23.022988868620445, "Episode length": 782, "Policy Loss": 0.07162081450223923, "Value Loss": 12.72237777709961, "_runtime": 11551.126826763153, "_timestamp": 1585608920.7596962, "_step": 351}
{"Episode reward": -99.04785434671369, "Episode length": 999, "Policy Loss": -0.5732340812683105, "Value Loss": 0.0436820425093174, "_runtime": 11552.203070640564, "_timestamp": 1585608921.8359401, "_step": 352}
{"Episode reward": 34.68340495692847, "Episode length": 666, "Policy Loss": 0.3196319043636322, "Value Loss": 14.843154907226562, "_runtime": 11553.74715590477, "_timestamp": 1585608923.3800254, "_step": 353}
{"Episode reward": -97.4976574236469, "Episode length": 999, "Policy Loss": -0.4333021640777588, "Value Loss": 0.2775532007217407, "_runtime": 11554.250280857086, "_timestamp": 1585608923.8831503, "_step": 354}
{"Episode reward": 71.43620563104638, "Episode length": 289, "Policy Loss": 1.240666151046753, "Value Loss": 33.675296783447266, "_runtime": 11555.802312850952, "_timestamp": 1585608925.4351823, "_step": 355}
{"Episode reward": -98.48625173623037, "Episode length": 999, "Policy Loss": -0.6038739681243896, "Value Loss": 0.24220845103263855, "_runtime": 11557.38480091095, "_timestamp": 1585608927.0176704, "_step": 356}
{"Episode reward": -99.19885556275558, "Episode length": 999, "Policy Loss": -0.5660337805747986, "Value Loss": 0.12074840068817139, "_runtime": 11558.890270709991, "_timestamp": 1585608928.5231402, "_step": 357}
{"Episode reward": 2.8397619266029466, "Episode length": 994, "Policy Loss": 0.019984934478998184, "Value Loss": 9.813050270080566, "_runtime": 11560.485981702805, "_timestamp": 1585608930.1188512, "_step": 358}
{"Episode reward": -98.72035446556916, "Episode length": 999, "Policy Loss": -0.5973392128944397, "Value Loss": 0.16805431246757507, "_runtime": 11562.051768541336, "_timestamp": 1585608931.684638, "_step": 359}
{"Episode reward": -98.81880234119919, "Episode length": 999, "Policy Loss": -0.4364427626132965, "Value Loss": 0.023830991238355637, "_runtime": 11563.61468219757, "_timestamp": 1585608933.2475517, "_step": 360}
{"Episode reward": -98.19282588356053, "Episode length": 999, "Policy Loss": -0.42146381735801697, "Value Loss": 0.03795177489519119, "_runtime": 11563.89955496788, "_timestamp": 1585608933.5324244, "_step": 361}
{"Episode reward": 86.72136114642166, "Episode length": 133, "Policy Loss": 3.397705078125, "Value Loss": 73.81137084960938, "_runtime": 11565.489173412323, "_timestamp": 1585608935.122043, "_step": 362}
{"Episode reward": -98.2747287202404, "Episode length": 999, "Policy Loss": -0.44578322768211365, "Value Loss": 0.03596969321370125, "_runtime": 11567.075620174408, "_timestamp": 1585608936.7084897, "_step": 363}
{"Episode reward": -98.69479614957294, "Episode length": 999, "Policy Loss": -0.516368567943573, "Value Loss": 0.16777892410755157, "_runtime": 11568.48514676094, "_timestamp": 1585608938.1180162, "_step": 364}
{"Episode reward": 7.921390024170904, "Episode length": 936, "Policy Loss": -0.12101899087429047, "Value Loss": 10.50014877319336, "_runtime": 11569.515507936478, "_timestamp": 1585608939.1483774, "_step": 365}
{"Episode reward": 37.49670118014921, "Episode length": 636, "Policy Loss": -0.16300909221172333, "Value Loss": 15.487058639526367, "_runtime": 11571.103609800339, "_timestamp": 1585608940.7364793, "_step": 366}
{"Episode reward": -98.25795037590959, "Episode length": 999, "Policy Loss": -0.6140053868293762, "Value Loss": 0.13587747514247894, "_runtime": 11572.328605651855, "_timestamp": 1585608941.9614751, "_step": 367}
{"Episode reward": 23.01009259248292, "Episode length": 783, "Policy Loss": 0.24140703678131104, "Value Loss": 12.226914405822754, "_runtime": 11573.872137784958, "_timestamp": 1585608943.5050073, "_step": 368}
{"Episode reward": -98.93523363099239, "Episode length": 999, "Policy Loss": -0.6408262848854065, "Value Loss": 0.03842175006866455, "_runtime": 11575.47548532486, "_timestamp": 1585608945.1083548, "_step": 369}
{"Episode reward": -98.71456817775545, "Episode length": 999, "Policy Loss": -0.6580089330673218, "Value Loss": 0.04201259836554527, "_runtime": 11577.063570261002, "_timestamp": 1585608946.6964397, "_step": 370}
{"Episode reward": -98.65536626903315, "Episode length": 999, "Policy Loss": -0.6144757270812988, "Value Loss": 0.06448575854301453, "_runtime": 11578.521090507507, "_timestamp": 1585608948.15396, "_step": 371}
{"Episode reward": 9.400823560302413, "Episode length": 920, "Policy Loss": 0.033037420362234116, "Value Loss": 10.379645347595215, "_runtime": 11580.11925816536, "_timestamp": 1585608949.7521276, "_step": 372}
{"Episode reward": -98.8198253980526, "Episode length": 999, "Policy Loss": -0.6711035370826721, "Value Loss": 0.056286830455064774, "_runtime": 11581.700938463211, "_timestamp": 1585608951.333808, "_step": 373}
{"Episode reward": -97.05614549762171, "Episode length": 999, "Policy Loss": -0.7083750367164612, "Value Loss": 0.12364398688077927, "_runtime": 11583.282537460327, "_timestamp": 1585608952.915407, "_step": 374}
{"Episode reward": -98.72286115639733, "Episode length": 999, "Policy Loss": -0.6564262509346008, "Value Loss": 0.054145049303770065, "_runtime": 11584.589907169342, "_timestamp": 1585608954.2227767, "_step": 375}
{"Episode reward": 18.740786602517503, "Episode length": 828, "Policy Loss": 0.19462743401527405, "Value Loss": 11.365708351135254, "_runtime": 11586.161951303482, "_timestamp": 1585608955.7948208, "_step": 376}
{"Episode reward": -98.56315954715689, "Episode length": 999, "Policy Loss": -0.6741322875022888, "Value Loss": 0.05809157341718674, "_runtime": 11587.480557441711, "_timestamp": 1585608957.113427, "_step": 377}
{"Episode reward": 19.16901953356343, "Episode length": 826, "Policy Loss": -0.02940523810684681, "Value Loss": 11.562065124511719, "_runtime": 11589.054621696472, "_timestamp": 1585608958.6874912, "_step": 378}
{"Episode reward": -98.42920248671172, "Episode length": 999, "Policy Loss": -0.6781438589096069, "Value Loss": 0.05035457760095596, "_runtime": 11590.642330884933, "_timestamp": 1585608960.2752004, "_step": 379}
{"Episode reward": -98.29763036738782, "Episode length": 999, "Policy Loss": -0.6864591836929321, "Value Loss": 0.09580346941947937, "_runtime": 11591.439213991165, "_timestamp": 1585608961.0720835, "_step": 380}
{"Episode reward": 51.40590975856586, "Episode length": 493, "Policy Loss": 0.3387446403503418, "Value Loss": 18.577314376831055, "_runtime": 11592.066306591034, "_timestamp": 1585608961.699176, "_step": 381}
{"Episode reward": 63.16507240620152, "Episode length": 373, "Policy Loss": 0.7872413992881775, "Value Loss": 25.621858596801758, "_runtime": 11593.644714593887, "_timestamp": 1585608963.277584, "_step": 382}
{"Episode reward": -98.58549399264044, "Episode length": 999, "Policy Loss": -0.567879319190979, "Value Loss": 0.022421423345804214, "_runtime": 11595.186779737473, "_timestamp": 1585608964.8196492, "_step": 383}
{"Episode reward": -99.22938621176736, "Episode length": 999, "Policy Loss": -0.5757974982261658, "Value Loss": 0.018647754564881325, "_runtime": 11596.71060538292, "_timestamp": 1585608966.3434749, "_step": 384}
{"Episode reward": -99.07376219217007, "Episode length": 999, "Policy Loss": -0.5843191742897034, "Value Loss": 0.03363867104053497, "_runtime": 11598.2978246212, "_timestamp": 1585608967.930694, "_step": 385}
{"Episode reward": -98.5194663611254, "Episode length": 999, "Policy Loss": -0.5432233810424805, "Value Loss": 0.0279080830514431, "_runtime": 11599.908770084381, "_timestamp": 1585608969.5416396, "_step": 386}
{"Episode reward": -98.80285094475995, "Episode length": 999, "Policy Loss": -0.5179600119590759, "Value Loss": 0.04133588820695877, "_runtime": 11601.31957435608, "_timestamp": 1585608970.9524438, "_step": 387}
{"Episode reward": 11.996976840272936, "Episode length": 893, "Policy Loss": -0.0006773266359232366, "Value Loss": 10.48231029510498, "_runtime": 11602.91823554039, "_timestamp": 1585608972.551105, "_step": 388}
{"Episode reward": -98.42464052388475, "Episode length": 999, "Policy Loss": -0.508834958076477, "Value Loss": 0.015255028381943703, "_runtime": 11604.511538743973, "_timestamp": 1585608974.1444082, "_step": 389}
{"Episode reward": -99.2115949909673, "Episode length": 999, "Policy Loss": -0.49665215611457825, "Value Loss": 0.02440096251666546, "_runtime": 11606.08159327507, "_timestamp": 1585608975.7144628, "_step": 390}
{"Episode reward": -99.17710613746686, "Episode length": 999, "Policy Loss": -0.47198620438575745, "Value Loss": 0.039743050932884216, "_runtime": 11607.658171653748, "_timestamp": 1585608977.2910411, "_step": 391}
{"Episode reward": -98.90995985567692, "Episode length": 999, "Policy Loss": -0.4853174388408661, "Value Loss": 0.023129044100642204, "_runtime": 11608.59807753563, "_timestamp": 1585608978.230947, "_step": 392}
{"Episode reward": 42.506940395477805, "Episode length": 585, "Policy Loss": 0.36556223034858704, "Value Loss": 16.306398391723633, "_runtime": 11610.157111406326, "_timestamp": 1585608979.789981, "_step": 393}
{"Episode reward": -98.99938867740325, "Episode length": 999, "Policy Loss": -0.4845794141292572, "Value Loss": 0.01675526425242424, "_runtime": 11611.737887144089, "_timestamp": 1585608981.3707566, "_step": 394}
{"Episode reward": -98.89414413505011, "Episode length": 999, "Policy Loss": -0.46808359026908875, "Value Loss": 0.01024071779102087, "_runtime": 11613.26498222351, "_timestamp": 1585608982.8978517, "_step": 395}
{"Episode reward": -98.89469431498885, "Episode length": 999, "Policy Loss": -0.4591163694858551, "Value Loss": 0.010553802363574505, "_runtime": 11614.830863237381, "_timestamp": 1585608984.4637327, "_step": 396}
{"Episode reward": -98.10658307316262, "Episode length": 999, "Policy Loss": -0.5272059440612793, "Value Loss": 0.05485402047634125, "_runtime": 11616.418379068375, "_timestamp": 1585608986.0512486, "_step": 397}
{"Episode reward": -98.82534934465191, "Episode length": 999, "Policy Loss": -0.4511507451534271, "Value Loss": 0.021425770595669746, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086, -12.573293685913086]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 5.0], "bins": [-143.08309936523438, -140.62863159179688, -138.17417907714844, -135.7197265625, -133.2652587890625, -130.810791015625, -128.35633850097656, -125.9018783569336, -123.44741821289062, -120.99295806884766, -118.53849792480469, -116.08403778076172, -113.62957763671875, -111.17511749267578, -108.72065734863281, -106.26619720458984, -103.81173706054688, -101.3572769165039, -98.90281677246094, -96.44835662841797, -93.993896484375, -91.53943634033203, -89.08497619628906, -86.6305160522461, -84.17605590820312, -81.72159576416016, -79.26713562011719, -76.81267547607422, -74.35821533203125, -71.90375518798828, -69.44929504394531, -66.99483489990234, -64.54037475585938, -62.085914611816406, -59.63145446777344, -57.17699432373047, -54.7225341796875, -52.26807403564453, -49.81361389160156, -47.359153747558594, -44.904693603515625, -42.450233459472656, -39.99577331542969, -37.54131317138672, -35.08685302734375, -32.63239288330078, -30.177932739257812, -27.723472595214844, -25.269012451171875, -22.814552307128906, -20.360092163085938, -17.90563201904297, -15.451171875, -12.9967041015625, -10.542251586914062, -8.087799072265625, -5.633331298828125, -3.178863525390625, -0.7244110107421875, 1.73004150390625, 4.18450927734375, 6.63897705078125, 9.093429565429688, 11.547882080078125, 14.002349853515625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-22.637113571166992, -22.20981788635254, -21.782520294189453, -21.355224609375, -20.927927017211914, -20.50063133239746, -20.073333740234375, -19.646038055419922, -19.21874237060547, -18.791444778442383, -18.36414909362793, -17.936851501464844, -17.50955581665039, -17.082260131835938, -16.65496253967285, -16.2276668548584, -15.800370216369629, -15.37307357788086, -14.945777893066406, -14.518481254577637, -14.091184616088867, -13.663887977600098, -13.236591339111328, -12.809294700622559, -12.381998062133789, -11.954702377319336, -11.527405738830566, -11.100109100341797, -10.672812461853027, -10.245515823364258, -9.818220138549805, -9.390923500061035, -8.963626861572266, -8.536330223083496, -8.109033584594727, -7.681737899780273, -7.254441261291504, -6.827144622802734, -6.399848937988281, -5.972551345825195, -5.545255661010742, -5.117958068847656, -4.690662384033203, -4.26336669921875, -3.836069107055664, -3.408773422241211, -2.981475830078125, -2.554180145263672, -2.126882553100586, -1.6995868682861328, -1.2722911834716797, -0.8449935913085938, -0.4176979064941406, 0.009599685668945312, 0.43689537048339844, 0.8641910552978516, 1.2914886474609375, 1.7187843322753906, 2.1460819244384766, 2.5733776092529297, 3.000673294067383, 3.4279708862304688, 3.855266571044922, 4.282564163208008, 4.709859848022461]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 9.0, 12.0, 10.0, 17.0, 357.0, 17.0, 10.0, 16.0, 10.0, 3.0, 5.0, 2.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0], "bins": [-41.88661575317383, -40.96940994262695, -40.05220031738281, -39.13499450683594, -38.21778869628906, -37.30058288574219, -36.38337707519531, -35.46616744995117, -34.5489616394043, -33.63175582885742, -32.71454620361328, -31.797340393066406, -30.88013458251953, -29.962928771972656, -29.04572105407715, -28.12851333618164, -27.211307525634766, -26.29410171508789, -25.376893997192383, -24.459686279296875, -23.54248046875, -22.625274658203125, -21.708066940307617, -20.79085922241211, -19.873653411865234, -18.95644760131836, -18.03923988342285, -17.122032165527344, -16.20482635498047, -15.287620544433594, -14.370412826538086, -13.453205108642578, -12.535999298095703, -11.618793487548828, -10.70158576965332, -9.784378051757812, -8.867172241210938, -7.9499664306640625, -7.032756805419922, -6.115550994873047, -5.198345184326172, -4.281139373779297, -3.363933563232422, -2.4467239379882812, -1.5295181274414062, -0.6123123168945312, 0.3048973083496094, 1.2221031188964844, 2.1393089294433594, 3.0565147399902344, 3.9737205505371094, 4.89093017578125, 5.808135986328125, 6.725341796875, 7.642551422119141, 8.559757232666016, 9.47696304321289, 10.394168853759766, 11.31137466430664, 12.228584289550781, 13.145790100097656, 14.062995910644531, 14.980205535888672, 15.897411346435547, 16.814617156982422]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-15.201128005981445, -14.47707462310791, -13.753020286560059, -13.028966903686523, -12.304912567138672, -11.580859184265137, -10.856805801391602, -10.13275146484375, -9.408697128295898, -8.684643745422363, -7.96058988571167, -7.236536026000977, -6.512482643127441, -5.78842830657959, -5.064374923706055, -4.340320587158203, -3.616267204284668, -2.892213821411133, -2.1681594848632812, -1.444106101989746, -0.7200517654418945, 0.004001617431640625, 0.7280559539794922, 1.4521102905273438, 2.1761627197265625, 2.900217056274414, 3.6242713928222656, 4.348323822021484, 5.072378158569336, 5.7964324951171875, 6.520486831665039, 7.244539260864258, 7.968593597412109, 8.692647933959961, 9.41670036315918, 10.140754699707031, 10.864809036254883, 11.588863372802734, 12.312915802001953, 13.036970138549805, 13.761024475097656, 14.485076904296875, 15.209131240844727, 15.933185577392578, 16.65723991394043, 17.38129234313965, 18.105348587036133, 18.82940101623535, 19.55345344543457, 20.277509689331055, 21.001562118530273, 21.725614547729492, 22.449670791625977, 23.173723220825195, 23.897775650024414, 24.6218318939209, 25.345884323120117, 26.069936752319336, 26.79399299621582, 27.51804542541504, 28.242101669311523, 28.966154098510742, 29.69020652770996, 30.414262771606445, 31.138315200805664]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-13.19363021850586, -12.636686325073242, -12.079743385314941, -11.522799491882324, -10.965855598449707, -10.408912658691406, -9.851968765258789, -9.295024871826172, -8.738080978393555, -8.181138038635254, -7.624194145202637, -7.067250728607178, -6.510307312011719, -5.953363418579102, -5.396420001983643, -4.839476585388184, -4.282532691955566, -3.725588798522949, -3.1686458587646484, -2.6117019653320312, -2.054758071899414, -1.4978151321411133, -0.9408712387084961, -0.3839273452758789, 0.17301559448242188, 0.7299594879150391, 1.2869033813476562, 1.8438472747802734, 2.400790214538574, 2.957733154296875, 3.514677047729492, 4.071620941162109, 4.628564834594727, 5.185508728027344, 5.742452621459961, 6.299396514892578, 6.8563385009765625, 7.41328239440918, 7.970226287841797, 8.527170181274414, 9.084114074707031, 9.641057968139648, 10.197999954223633, 10.75494384765625, 11.311887741088867, 11.868831634521484, 12.425775527954102, 12.982719421386719, 13.539661407470703, 14.09660530090332, 14.653549194335938, 15.210493087768555, 15.767436981201172, 16.32438087463379, 16.881324768066406, 17.43826675415039, 17.995210647583008, 18.552154541015625, 19.10909652709961, 19.66604232788086, 20.222984313964844, 20.779930114746094, 21.336872100830078, 21.893817901611328, 22.450759887695312]}, "_runtime": 11617.314144611359, "_timestamp": 1585608986.947014, "_step": 398}
{"Episode reward": 45.39752686129065, "Episode length": 558, "Policy Loss": 0.48931413888931274, "Value Loss": 16.585071563720703, "_runtime": 11617.946540355682, "_timestamp": 1585608987.5794098, "_step": 399}
{"Episode reward": 62.54920167821294, "Episode length": 391, "Policy Loss": 0.957176685333252, "Value Loss": 23.797487258911133, "_runtime": 11619.484796762466, "_timestamp": 1585608989.1176662, "_step": 400}
{"Episode reward": 2.275561811418214, "Episode length": 990, "Policy Loss": 0.05814768001437187, "Value Loss": 9.237725257873535, "_runtime": 11621.018092155457, "_timestamp": 1585608990.6509616, "_step": 401}
{"Episode reward": -98.03350123809012, "Episode length": 999, "Policy Loss": -0.5562970638275146, "Value Loss": 0.0714830681681633, "_runtime": 11622.532563447952, "_timestamp": 1585608992.165433, "_step": 402}
{"Episode reward": -99.03571296478978, "Episode length": 999, "Policy Loss": -0.5855833292007446, "Value Loss": 0.030069179832935333, "_runtime": 11624.152205467224, "_timestamp": 1585608993.785075, "_step": 403}
{"Episode reward": -98.40447206575074, "Episode length": 999, "Policy Loss": -0.6526581645011902, "Value Loss": 0.07846274971961975, "_runtime": 11625.599913358688, "_timestamp": 1585608995.2327828, "_step": 404}
{"Episode reward": 9.074145024399428, "Episode length": 921, "Policy Loss": 0.2269953340291977, "Value Loss": 9.851632118225098, "_runtime": 11626.366664886475, "_timestamp": 1585608995.9995344, "_step": 405}
{"Episode reward": 52.8293307531552, "Episode length": 478, "Policy Loss": 0.4803960621356964, "Value Loss": 18.687070846557617, "_runtime": 11627.19339632988, "_timestamp": 1585608996.8262658, "_step": 406}
{"Episode reward": 49.10997193956055, "Episode length": 512, "Policy Loss": 0.14474284648895264, "Value Loss": 17.61206817626953, "_runtime": 11628.74651002884, "_timestamp": 1585608998.3793795, "_step": 407}
{"Episode reward": -99.13727948141579, "Episode length": 999, "Policy Loss": -0.8298333883285522, "Value Loss": 0.06393837183713913, "_runtime": 11629.345585346222, "_timestamp": 1585608998.9784548, "_step": 408}
{"Episode reward": 62.36736259671645, "Episode length": 379, "Policy Loss": 0.5561604499816895, "Value Loss": 23.9703311920166, "_runtime": 11630.857631206512, "_timestamp": 1585609000.4905007, "_step": 409}
{"Episode reward": -99.01532401796004, "Episode length": 999, "Policy Loss": -0.9724313616752625, "Value Loss": 0.06154419854283333, "_runtime": 11632.423204183578, "_timestamp": 1585609002.0560737, "_step": 410}
{"Episode reward": -98.51001426717028, "Episode length": 999, "Policy Loss": -1.017057180404663, "Value Loss": 0.06149779632687569, "_runtime": 11633.930955171585, "_timestamp": 1585609003.5638247, "_step": 411}
{"Episode reward": -98.36233130278947, "Episode length": 999, "Policy Loss": -1.0222969055175781, "Value Loss": 0.11340589076280594, "_runtime": 11635.492411851883, "_timestamp": 1585609005.1252813, "_step": 412}
{"Episode reward": -99.01333264119596, "Episode length": 999, "Policy Loss": -1.080375075340271, "Value Loss": 0.08245232701301575, "_runtime": 11637.044600486755, "_timestamp": 1585609006.67747, "_step": 413}
{"Episode reward": 3.2229127651326905, "Episode length": 978, "Policy Loss": -0.614072859287262, "Value Loss": 9.901827812194824, "_runtime": 11637.676310539246, "_timestamp": 1585609007.30918, "_step": 414}
{"Episode reward": 61.969662815611414, "Episode length": 393, "Policy Loss": 0.20592252910137177, "Value Loss": 23.692081451416016, "_runtime": 11639.233287334442, "_timestamp": 1585609008.8661568, "_step": 415}
{"Episode reward": -99.12398006271043, "Episode length": 999, "Policy Loss": -0.9158490896224976, "Value Loss": 0.12624594569206238, "_runtime": 11640.796158075333, "_timestamp": 1585609010.4290276, "_step": 416}
{"Episode reward": -99.04209604183316, "Episode length": 999, "Policy Loss": -0.7958192229270935, "Value Loss": 0.21571779251098633, "_runtime": 11641.270762205124, "_timestamp": 1585609010.9036317, "_step": 417}
{"Episode reward": 69.73099321408684, "Episode length": 306, "Policy Loss": 0.9041242599487305, "Value Loss": 32.598243713378906, "_runtime": 11642.653844833374, "_timestamp": 1585609012.2867143, "_step": 418}
{"Episode reward": 12.826339952416873, "Episode length": 889, "Policy Loss": -0.14544393122196198, "Value Loss": 10.744544982910156, "_runtime": 11644.210197210312, "_timestamp": 1585609013.8430667, "_step": 419}
{"Episode reward": -98.69967449725212, "Episode length": 999, "Policy Loss": -0.7467188239097595, "Value Loss": 0.05772211030125618, "_runtime": 11645.70039176941, "_timestamp": 1585609015.3332613, "_step": 420}
{"Episode reward": -98.94748071308472, "Episode length": 999, "Policy Loss": -0.7196159362792969, "Value Loss": 0.06737471371889114, "_runtime": 11647.286661624908, "_timestamp": 1585609016.919531, "_step": 421}
{"Episode reward": -97.27918169087008, "Episode length": 999, "Policy Loss": -1.0521589517593384, "Value Loss": 0.870703935623169, "_runtime": 11648.707650184631, "_timestamp": 1585609018.3405197, "_step": 422}
{"Episode reward": 11.14966440092563, "Episode length": 911, "Policy Loss": -0.3095613718032837, "Value Loss": 10.670777320861816, "_runtime": 11650.252699375153, "_timestamp": 1585609019.8855689, "_step": 423}
{"Episode reward": -99.02391949933521, "Episode length": 999, "Policy Loss": -0.5555883049964905, "Value Loss": 0.10129548609256744, "_runtime": 11651.824801921844, "_timestamp": 1585609021.4576714, "_step": 424}
{"Episode reward": -98.56144521237812, "Episode length": 999, "Policy Loss": -0.39199018478393555, "Value Loss": 0.03628801554441452, "_runtime": 11652.59429192543, "_timestamp": 1585609022.2271614, "_step": 425}
{"Episode reward": 52.4134990448933, "Episode length": 483, "Policy Loss": 0.845676600933075, "Value Loss": 18.716073989868164, "_runtime": 11653.780867815018, "_timestamp": 1585609023.4137373, "_step": 426}
{"Episode reward": 24.63507881028268, "Episode length": 761, "Policy Loss": 0.5155056118965149, "Value Loss": 12.513409614562988, "_runtime": 11655.344212055206, "_timestamp": 1585609024.9770815, "_step": 427}
{"Episode reward": -98.77738854662972, "Episode length": 999, "Policy Loss": -0.3293537497520447, "Value Loss": 0.10719285905361176, "_runtime": 11656.103830337524, "_timestamp": 1585609025.7366998, "_step": 428}
{"Episode reward": 51.00656998650969, "Episode length": 495, "Policy Loss": 0.5868079662322998, "Value Loss": 18.096343994140625, "_runtime": 11657.643162488937, "_timestamp": 1585609027.276032, "_step": 429}
{"Episode reward": -98.56191856499453, "Episode length": 999, "Policy Loss": -0.5062889456748962, "Value Loss": 0.11095691472291946, "_runtime": 11659.206458806992, "_timestamp": 1585609028.8393283, "_step": 430}
{"Episode reward": -99.25906940331487, "Episode length": 999, "Policy Loss": -0.6263467669487, "Value Loss": 0.030525270849466324, "_runtime": 11660.538409948349, "_timestamp": 1585609030.1712794, "_step": 431}
{"Episode reward": 13.12069479244829, "Episode length": 884, "Policy Loss": -0.1072954535484314, "Value Loss": 10.961250305175781, "_runtime": 11662.095141172409, "_timestamp": 1585609031.7280107, "_step": 432}
{"Episode reward": -98.89732187948879, "Episode length": 999, "Policy Loss": -0.6832973957061768, "Value Loss": 0.11677546799182892, "_runtime": 11663.661547422409, "_timestamp": 1585609033.294417, "_step": 433}
{"Episode reward": -98.62484290148808, "Episode length": 999, "Policy Loss": -0.7168656587600708, "Value Loss": 0.2493501752614975, "_runtime": 11665.196054458618, "_timestamp": 1585609034.828924, "_step": 434}
{"Episode reward": -99.25361597693855, "Episode length": 999, "Policy Loss": -0.6186636686325073, "Value Loss": 0.03801732882857323, "_runtime": 11666.760615587234, "_timestamp": 1585609036.393485, "_step": 435}
{"Episode reward": -98.77842819133836, "Episode length": 999, "Policy Loss": -0.5738635659217834, "Value Loss": 0.0781095027923584, "_runtime": 11668.325518131256, "_timestamp": 1585609037.9583876, "_step": 436}
{"Episode reward": -99.24461135270522, "Episode length": 999, "Policy Loss": -0.4695010781288147, "Value Loss": 0.0225575752556324, "_runtime": 11669.921015262604, "_timestamp": 1585609039.5538847, "_step": 437}
{"Episode reward": -98.7421074203577, "Episode length": 999, "Policy Loss": -0.4354420006275177, "Value Loss": 0.02175193652510643, "_runtime": 11670.708122968674, "_timestamp": 1585609040.3409925, "_step": 438}
{"Episode reward": 51.09553745933055, "Episode length": 494, "Policy Loss": 0.6389514803886414, "Value Loss": 18.30303382873535, "_runtime": 11672.272201061249, "_timestamp": 1585609041.9050705, "_step": 439}
{"Episode reward": -98.79888080077957, "Episode length": 999, "Policy Loss": -0.3855290412902832, "Value Loss": 0.012429499998688698, "_runtime": 11673.834729671478, "_timestamp": 1585609043.4675992, "_step": 440}
{"Episode reward": -99.15250030364741, "Episode length": 999, "Policy Loss": -0.40545156598091125, "Value Loss": 0.009546100161969662, "_runtime": 11675.344576835632, "_timestamp": 1585609044.9774463, "_step": 441}
{"Episode reward": -99.15941438968021, "Episode length": 999, "Policy Loss": -0.42052969336509705, "Value Loss": 0.01180705614387989, "_runtime": 11676.911739110947, "_timestamp": 1585609046.5446086, "_step": 442}
{"Episode reward": -98.89469622169644, "Episode length": 999, "Policy Loss": -0.482765793800354, "Value Loss": 0.06076086312532425, "_runtime": 11678.159904956818, "_timestamp": 1585609047.7927744, "_step": 443}
{"Episode reward": 21.265647518547837, "Episode length": 800, "Policy Loss": 0.31848394870758057, "Value Loss": 10.960223197937012, "_runtime": 11679.711193323135, "_timestamp": 1585609049.3440628, "_step": 444}
{"Episode reward": -98.13440052984085, "Episode length": 999, "Policy Loss": -0.5237382054328918, "Value Loss": 0.05545545741915703, "_runtime": 11681.284511566162, "_timestamp": 1585609050.917381, "_step": 445}
{"Episode reward": -98.97981726080808, "Episode length": 999, "Policy Loss": -0.4743635654449463, "Value Loss": 0.017612062394618988, "_runtime": 11682.825102090836, "_timestamp": 1585609052.4579716, "_step": 446}
{"Episode reward": -98.03600536276679, "Episode length": 999, "Policy Loss": -0.5456914901733398, "Value Loss": 0.04413336515426636, "_runtime": 11683.448110818863, "_timestamp": 1585609053.0809803, "_step": 447}
{"Episode reward": 61.84151180446681, "Episode length": 384, "Policy Loss": 0.7443144917488098, "Value Loss": 23.677812576293945, "_runtime": 11685.012729167938, "_timestamp": 1585609054.6455986, "_step": 448}
{"Episode reward": -98.83902546314596, "Episode length": 999, "Policy Loss": -0.4776259660720825, "Value Loss": 0.0548669658601284, "_runtime": 11685.762428760529, "_timestamp": 1585609055.3952982, "_step": 449}
{"Episode reward": 54.339966607496656, "Episode length": 467, "Policy Loss": 0.49244430661201477, "Value Loss": 19.00107192993164, "_runtime": 11687.26502943039, "_timestamp": 1585609056.897899, "_step": 450}
{"Episode reward": -98.57010182157752, "Episode length": 999, "Policy Loss": -0.5281511545181274, "Value Loss": 0.02625156193971634, "_runtime": 11688.836599111557, "_timestamp": 1585609058.4694686, "_step": 451}
{"Episode reward": -98.90672301537681, "Episode length": 999, "Policy Loss": -0.5652951002120972, "Value Loss": 0.01842346414923668, "_runtime": 11690.344176530838, "_timestamp": 1585609059.977046, "_step": 452}
{"Episode reward": -98.45014095176963, "Episode length": 999, "Policy Loss": -0.5858754515647888, "Value Loss": 0.03531961888074875, "_runtime": 11691.891967535019, "_timestamp": 1585609061.524837, "_step": 453}
{"Episode reward": -98.88159916983979, "Episode length": 999, "Policy Loss": -0.5872843265533447, "Value Loss": 0.027301928028464317, "_runtime": 11693.500605344772, "_timestamp": 1585609063.1334748, "_step": 454}
{"Episode reward": -99.34788998801834, "Episode length": 999, "Policy Loss": -0.611411452293396, "Value Loss": 0.018955474719405174, "_runtime": 11694.885497570038, "_timestamp": 1585609064.518367, "_step": 455}
{"Episode reward": 12.406462103480948, "Episode length": 889, "Policy Loss": -0.03882333263754845, "Value Loss": 9.714899063110352, "_runtime": 11695.893615484238, "_timestamp": 1585609065.526485, "_step": 456}
{"Episode reward": 37.353416729720784, "Episode length": 645, "Policy Loss": 0.04517849534749985, "Value Loss": 13.270291328430176, "_runtime": 11697.461620092392, "_timestamp": 1585609067.0944896, "_step": 457}
{"Episode reward": -99.35413375292704, "Episode length": 999, "Policy Loss": -0.7738147974014282, "Value Loss": 0.03593539446592331, "_runtime": 11699.01653766632, "_timestamp": 1585609068.6494071, "_step": 458}
{"Episode reward": -99.21289410049803, "Episode length": 999, "Policy Loss": -0.8359925150871277, "Value Loss": 0.027975399047136307, "_runtime": 11699.648995399475, "_timestamp": 1585609069.281865, "_step": 459}
{"Episode reward": 59.54077629432402, "Episode length": 405, "Policy Loss": 0.7410531640052795, "Value Loss": 21.785696029663086, "_runtime": 11701.060719013214, "_timestamp": 1585609070.6935885, "_step": 460}
{"Episode reward": 10.572165449434749, "Episode length": 902, "Policy Loss": -0.37206029891967773, "Value Loss": 9.724411010742188, "_runtime": 11702.6188082695, "_timestamp": 1585609072.2516778, "_step": 461}
{"Episode reward": -98.87341954749911, "Episode length": 999, "Policy Loss": -0.9724321365356445, "Value Loss": 0.03950191289186478, "_runtime": 11703.837064027786, "_timestamp": 1585609073.4699335, "_step": 462}
{"Episode reward": 20.208806049584254, "Episode length": 814, "Policy Loss": -0.3993738293647766, "Value Loss": 9.995981216430664, "_runtime": 11705.398889303207, "_timestamp": 1585609075.0317588, "_step": 463}
{"Episode reward": -98.43931413355494, "Episode length": 999, "Policy Loss": -0.9966338872909546, "Value Loss": 0.08629675209522247, "_runtime": 11706.022558450699, "_timestamp": 1585609075.655428, "_step": 464}
{"Episode reward": 63.21219720332832, "Episode length": 374, "Policy Loss": 0.19711099565029144, "Value Loss": 22.31156349182129, "_runtime": 11706.991296291351, "_timestamp": 1585609076.6241658, "_step": 465}
{"Episode reward": 38.23610225307631, "Episode length": 621, "Policy Loss": -0.24644531309604645, "Value Loss": 12.30211353302002, "_runtime": 11708.581322908401, "_timestamp": 1585609078.2141924, "_step": 466}
{"Episode reward": -99.04502038166841, "Episode length": 999, "Policy Loss": -1.2017805576324463, "Value Loss": 0.07461976259946823, "_runtime": 11710.111577033997, "_timestamp": 1585609079.7444465, "_step": 467}
{"Episode reward": -98.59976765127155, "Episode length": 999, "Policy Loss": -1.2586524486541748, "Value Loss": 0.10871504247188568, "_runtime": 11711.594468832016, "_timestamp": 1585609081.2273383, "_step": 468}
{"Episode reward": 5.253162614205948, "Episode length": 955, "Policy Loss": -0.6332507729530334, "Value Loss": 9.470385551452637, "_runtime": 11713.17903995514, "_timestamp": 1585609082.8119094, "_step": 469}
{"Episode reward": -97.56294522771623, "Episode length": 999, "Policy Loss": -1.2476615905761719, "Value Loss": 0.19743835926055908, "_runtime": 11714.750136613846, "_timestamp": 1585609084.383006, "_step": 470}
{"Episode reward": -98.86816378677466, "Episode length": 999, "Policy Loss": -1.310829997062683, "Value Loss": 0.13999435305595398, "_runtime": 11716.332515239716, "_timestamp": 1585609085.9653847, "_step": 471}
{"Episode reward": -99.19935652805299, "Episode length": 999, "Policy Loss": -1.2046217918395996, "Value Loss": 0.12443613260984421, "_runtime": 11716.884628772736, "_timestamp": 1585609086.5174983, "_step": 472}
{"Episode reward": 71.48122152536922, "Episode length": 292, "Policy Loss": 0.5354747176170349, "Value Loss": 29.325719833374023, "_runtime": 11718.120603084564, "_timestamp": 1585609087.7534726, "_step": 473}
{"Episode reward": 23.038402455809617, "Episode length": 782, "Policy Loss": -0.5226146578788757, "Value Loss": 10.718201637268066, "_runtime": 11719.704756975174, "_timestamp": 1585609089.3376265, "_step": 474}
{"Episode reward": -98.46241723474573, "Episode length": 999, "Policy Loss": -1.0902708768844604, "Value Loss": 0.053352393209934235, "_runtime": 11721.141159296036, "_timestamp": 1585609090.7740288, "_step": 475}
{"Episode reward": 6.61525235512994, "Episode length": 943, "Policy Loss": -0.460511177778244, "Value Loss": 8.553348541259766, "_runtime": 11722.712986707687, "_timestamp": 1585609092.3458562, "_step": 476}
{"Episode reward": -98.83009194132805, "Episode length": 999, "Policy Loss": -0.9451152682304382, "Value Loss": 0.05717528238892555, "_runtime": 11724.29164814949, "_timestamp": 1585609093.9245176, "_step": 477}
{"Episode reward": -99.09179871778662, "Episode length": 999, "Policy Loss": -0.8789424300193787, "Value Loss": 0.04806540161371231, "_runtime": 11725.841383934021, "_timestamp": 1585609095.4742534, "_step": 478}
{"Episode reward": -99.16157400791779, "Episode length": 999, "Policy Loss": -0.7986993193626404, "Value Loss": 0.1523323655128479, "_runtime": 11726.480640649796, "_timestamp": 1585609096.1135101, "_step": 479}
{"Episode reward": 62.57355658992659, "Episode length": 380, "Policy Loss": 0.4595147371292114, "Value Loss": 25.956846237182617, "_runtime": 11727.155763864517, "_timestamp": 1585609096.7886333, "_step": 480}
{"Episode reward": 58.942140031055814, "Episode length": 412, "Policy Loss": 0.059303801506757736, "Value Loss": 19.83494758605957, "_runtime": 11728.73665857315, "_timestamp": 1585609098.369528, "_step": 481}
{"Episode reward": -98.95632431357201, "Episode length": 999, "Policy Loss": -1.539412498474121, "Value Loss": 0.1967763900756836, "_runtime": 11729.595782756805, "_timestamp": 1585609099.2286522, "_step": 482}
{"Episode reward": 44.57281044634243, "Episode length": 566, "Policy Loss": -0.4493635594844818, "Value Loss": 16.726633071899414, "_runtime": 11730.188806295395, "_timestamp": 1585609099.8216758, "_step": 483}
{"Episode reward": 62.70793386505768, "Episode length": 377, "Policy Loss": -0.6969664096832275, "Value Loss": 25.336162567138672, "_runtime": 11731.758712530136, "_timestamp": 1585609101.391582, "_step": 484}
{"Episode reward": -98.32109130547784, "Episode length": 999, "Policy Loss": -2.189175844192505, "Value Loss": 1.0483877658843994, "_runtime": 11732.637692928314, "_timestamp": 1585609102.2705624, "_step": 485}
{"Episode reward": 44.18816309097417, "Episode length": 565, "Policy Loss": -1.3299304246902466, "Value Loss": 17.273906707763672, "_runtime": 11734.155238866806, "_timestamp": 1585609103.7881083, "_step": 486}
{"Episode reward": -98.6212678878606, "Episode length": 999, "Policy Loss": -2.160330295562744, "Value Loss": 0.2504810392856598, "_runtime": 11735.416208028793, "_timestamp": 1585609105.0490775, "_step": 487}
{"Episode reward": 20.311654262165916, "Episode length": 804, "Policy Loss": -1.5999183654785156, "Value Loss": 12.570186614990234, "_runtime": 11736.954198122025, "_timestamp": 1585609106.5870676, "_step": 488}
{"Episode reward": -98.5178820242478, "Episode length": 999, "Policy Loss": -2.1089534759521484, "Value Loss": 0.43782198429107666, "_runtime": 11738.5189640522, "_timestamp": 1585609108.1518335, "_step": 489}
{"Episode reward": -99.0086719726321, "Episode length": 999, "Policy Loss": -2.0420234203338623, "Value Loss": 0.6365991830825806, "_runtime": 11740.086790323257, "_timestamp": 1585609109.7196598, "_step": 490}
{"Episode reward": -99.09072127032388, "Episode length": 999, "Policy Loss": -1.8420042991638184, "Value Loss": 0.5929749011993408, "_runtime": 11741.70705485344, "_timestamp": 1585609111.3399243, "_step": 491}
{"Episode reward": -98.99040604567067, "Episode length": 999, "Policy Loss": -1.2940529584884644, "Value Loss": 0.13910873234272003, "_runtime": 11743.284810066223, "_timestamp": 1585609112.9176795, "_step": 492}
{"Episode reward": -99.1473079192424, "Episode length": 999, "Policy Loss": -0.9551124572753906, "Value Loss": 0.04096565023064613, "_runtime": 11744.870424032211, "_timestamp": 1585609114.5032935, "_step": 493}
{"Episode reward": -98.44045874468065, "Episode length": 999, "Policy Loss": -0.5350722670555115, "Value Loss": 0.2084856629371643, "_runtime": 11746.450218200684, "_timestamp": 1585609116.0830877, "_step": 494}
{"Episode reward": -98.60887989368649, "Episode length": 999, "Policy Loss": -0.2715953290462494, "Value Loss": 0.04383520409464836, "_runtime": 11748.043045759201, "_timestamp": 1585609117.6759152, "_step": 495}
{"Episode reward": -98.76072764831561, "Episode length": 999, "Policy Loss": 0.013719789683818817, "Value Loss": 0.016974663361907005, "_runtime": 11749.393351078033, "_timestamp": 1585609119.0262206, "_step": 496}
{"Episode reward": 16.01120741598001, "Episode length": 848, "Policy Loss": 0.8714560866355896, "Value Loss": 11.869573593139648, "_runtime": 11750.985223770142, "_timestamp": 1585609120.6180933, "_step": 497}
{"Episode reward": -99.2109577612152, "Episode length": 999, "Policy Loss": 0.5477816462516785, "Value Loss": 0.012099970132112503, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371, -6.099776268005371]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0], "bins": [-246.23570251464844, -242.289794921875, -238.3438720703125, -234.39796447753906, -230.45205688476562, -226.50613403320312, -222.5602264404297, -218.61431884765625, -214.6684112548828, -210.7224884033203, -206.77658081054688, -202.83067321777344, -198.884765625, -194.9388427734375, -190.99293518066406, -187.04702758789062, -183.10110473632812, -179.1551971435547, -175.20928955078125, -171.26336669921875, -167.3174591064453, -163.37155151367188, -159.42562866210938, -155.47972106933594, -151.5338134765625, -147.587890625, -143.64199829101562, -139.69607543945312, -135.75015258789062, -131.80426025390625, -127.85833740234375, -123.91242980957031, -119.96651458740234, -116.02059936523438, -112.07469177246094, -108.1287841796875, -104.182861328125, -100.23695373535156, -96.29104614257812, -92.34512329101562, -88.39921569824219, -84.45330810546875, -80.50740051269531, -76.56147766113281, -72.61557006835938, -68.66966247558594, -64.72373962402344, -60.77783203125, -56.83192443847656, -52.88600158691406, -48.940093994140625, -44.99418640136719, -41.04827880859375, -37.10235595703125, -33.15644836425781, -29.210540771484375, -25.264617919921875, -21.318710327148438, -17.372802734375, -13.4268798828125, -9.480972290039062, -5.535064697265625, -1.5891571044921875, 2.3567657470703125, 6.30267333984375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.163443565368652, -10.95674991607666, -10.750056266784668, -10.543362617492676, -10.336668968200684, -10.129975318908691, -9.9232816696167, -9.716588020324707, -9.509894371032715, -9.303200721740723, -9.096506118774414, -8.889812469482422, -8.68311882019043, -8.476425170898438, -8.269731521606445, -8.063037872314453, -7.856344223022461, -7.649650573730469, -7.442956924438477, -7.236263275146484, -7.029569625854492, -6.8228759765625, -6.616182327270508, -6.409488677978516, -6.202795028686523, -5.996101379394531, -5.789407730102539, -5.582713603973389, -5.3760199546813965, -5.169326305389404, -4.962632656097412, -4.75593900680542, -4.549245357513428, -4.3425517082214355, -4.135858058929443, -3.929164409637451, -3.722470760345459, -3.515777111053467, -3.3090829849243164, -3.102389335632324, -2.895695686340332, -2.68900203704834, -2.4823083877563477, -2.2756147384643555, -2.0689210891723633, -1.862227439880371, -1.655533790588379, -1.4488401412963867, -1.2421464920043945, -1.0354528427124023, -0.8287591934204102, -0.622065544128418, -0.4153718948364258, -0.2086782455444336, -0.001983642578125, 0.2047100067138672, 0.4114036560058594, 0.6180973052978516, 0.8247909545898438, 1.031484603881836, 1.2381782531738281, 1.4448719024658203, 1.6515655517578125, 1.8582592010498047, 2.064952850341797]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 7.0, 406.0, 42.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 6.0, 3.0, 3.0, 8.0, 5.0], "bins": [-49.25535202026367, -48.28764724731445, -47.319942474365234, -46.35224151611328, -45.38453674316406, -44.416831970214844, -43.449127197265625, -42.481422424316406, -41.51372146606445, -40.546016693115234, -39.578311920166016, -38.6106071472168, -37.642906188964844, -36.675201416015625, -35.707496643066406, -34.73979187011719, -33.77208709716797, -32.80438232421875, -31.836679458618164, -30.868976593017578, -29.90127182006836, -28.933568954467773, -27.965864181518555, -26.998159408569336, -26.03045654296875, -25.06275177001953, -24.095048904418945, -23.127344131469727, -22.159639358520508, -21.191936492919922, -20.224231719970703, -19.256528854370117, -18.2888240814209, -17.32111930847168, -16.353416442871094, -15.385711669921875, -14.418006896972656, -13.450305938720703, -12.482601165771484, -11.514896392822266, -10.547191619873047, -9.579486846923828, -8.611785888671875, -7.644081115722656, -6.6763763427734375, -5.708671569824219, -4.740966796875, -3.773265838623047, -2.805561065673828, -1.8378562927246094, -0.8701515197753906, 0.09755325317382812, 1.0652542114257812, 2.032958984375, 3.0006637573242188, 3.9683685302734375, 4.936073303222656, 5.903774261474609, 6.871479034423828, 7.839183807373047, 8.806888580322266, 9.774593353271484, 10.742294311523438, 11.709999084472656, 12.677703857421875]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 7.0, 6.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-14.05305290222168, -13.78589153289795, -13.518730163574219, -13.251567840576172, -12.984406471252441, -12.717245101928711, -12.450082778930664, -12.182921409606934, -11.915760040283203, -11.648598670959473, -11.381437301635742, -11.114274978637695, -10.847113609313965, -10.579952239990234, -10.312789916992188, -10.045628547668457, -9.778467178344727, -9.511305809020996, -9.244144439697266, -8.976982116699219, -8.709820747375488, -8.442659378051758, -8.175497055053711, -7.9083356857299805, -7.64117431640625, -7.3740129470825195, -7.106851100921631, -6.839689254760742, -6.572527885437012, -6.305366516113281, -6.038204193115234, -5.771042823791504, -5.503881454467773, -5.236720085144043, -4.9695587158203125, -4.702396392822266, -4.435235023498535, -4.168073654174805, -3.900911331176758, -3.6337499618530273, -3.366588592529297, -3.0994272232055664, -2.832265853881836, -2.565103530883789, -2.2979421615600586, -2.030780792236328, -1.7636184692382812, -1.4964570999145508, -1.2292957305908203, -0.9621343612670898, -0.6949729919433594, -0.4278106689453125, -0.16064929962158203, 0.10651206970214844, 0.3736743927001953, 0.6408357620239258, 0.9079971313476562, 1.1751585006713867, 1.4423198699951172, 1.709482192993164, 1.976644515991211, 2.243804931640625, 2.510967254638672, 2.778127670288086, 3.045289993286133]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 13.0, 13.0, 7.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.3207027912139893, -3.1065287590026855, -2.8923544883728027, -2.678180456161499, -2.4640064239501953, -2.2498321533203125, -2.035658121109009, -1.821484088897705, -1.6073099374771118, -1.3931357860565186, -1.1789617538452148, -0.9647877216339111, -0.7506134510040283, -0.5364394187927246, -0.3222653865814209, -0.10809111595153809, 0.10608291625976562, 0.32025694847106934, 0.5344312191009521, 0.7486050128936768, 0.9627792835235596, 1.1769535541534424, 1.391127347946167, 1.6053016185760498, 1.8194758892059326, 2.0336496829986572, 2.24782395362854, 2.461998224258423, 2.6761720180511475, 2.8903462886810303, 3.104520559310913, 3.3186943531036377, 3.5328686237335205, 3.7470428943634033, 3.961216688156128, 4.17539119720459, 4.389565467834473, 4.603738784790039, 4.817913055419922, 5.032087326049805, 5.2462615966796875, 5.46043586730957, 5.674610137939453, 5.888784408569336, 6.102957725524902, 6.317131996154785, 6.531306266784668, 6.745480537414551, 6.959654808044434, 7.173829078674316, 7.388002395629883, 7.602176666259766, 7.816350936889648, 8.030525207519531, 8.244699478149414, 8.458873748779297, 8.673047065734863, 8.887221336364746, 9.101395606994629, 9.315569877624512, 9.529744148254395, 9.743918418884277, 9.958091735839844, 10.172266006469727, 10.38644027709961]}, "_runtime": 11751.899249792099, "_timestamp": 1585609121.5321193, "_step": 498}
{"Episode reward": 45.121808470261676, "Episode length": 564, "Policy Loss": 2.2597246170043945, "Value Loss": 17.80366325378418, "_runtime": 11751.899249792099, "_timestamp": 1585609121.5321193, "_step": 499}
