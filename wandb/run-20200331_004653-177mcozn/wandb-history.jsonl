{"Episode reward": -33.571289392053366, "Episode length": 999, "Policy Loss": -0.0208149291574955, "Value Loss": 0.03109452687203884, "_runtime": 18263.08255505562, "_timestamp": 1585615632.7154245, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3161691725254059, "Value Loss": 12.78934383392334, "_runtime": 18264.61165189743, "_timestamp": 1585615634.2445214, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7980785369873047, "Value Loss": 1.0637781620025635, "_runtime": 18266.201416254044, "_timestamp": 1585615635.8342857, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.830120086669922, "Value Loss": 625.651611328125, "_runtime": 18267.734174251556, "_timestamp": 1585615637.3670437, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.7855544090271, "Value Loss": 1310.173095703125, "_runtime": 18269.27593779564, "_timestamp": 1585615638.9088073, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.501840114593506, "Value Loss": 13.048343658447266, "_runtime": 18270.85473227501, "_timestamp": 1585615640.4876018, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0905156135559082, "Value Loss": 2.804165840148926, "_runtime": 18271.059111833572, "_timestamp": 1585615640.6919813, "_step": 6}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 5.4312262535095215, "Value Loss": 136.27520751953125, "_runtime": 18271.218282938004, "_timestamp": 1585615640.8511524, "_step": 7}
{"Episode reward": 92.89678209459713, "Episode length": 72, "Policy Loss": 46.418758392333984, "Value Loss": 204.13949584960938, "_runtime": 18272.63866353035, "_timestamp": 1585615642.271533, "_step": 8}
{"Episode reward": 10.060774195666468, "Episode length": 908, "Policy Loss": 3.5028915405273438, "Value Loss": 23.55232048034668, "_runtime": 18273.312678575516, "_timestamp": 1585615642.945548, "_step": 9}
{"Episode reward": 54.07910148027103, "Episode length": 461, "Policy Loss": 0.5463520288467407, "Value Loss": 23.77733612060547, "_runtime": 18273.81184387207, "_timestamp": 1585615643.4447134, "_step": 10}
{"Episode reward": 66.19889540290139, "Episode length": 340, "Policy Loss": 0.7409501075744629, "Value Loss": 32.36576461791992, "_runtime": 18275.083170175552, "_timestamp": 1585615644.7160397, "_step": 11}
{"Episode reward": 17.68852712966077, "Episode length": 825, "Policy Loss": -0.4615570902824402, "Value Loss": 16.114660263061523, "_runtime": 18276.58385491371, "_timestamp": 1585615646.2167244, "_step": 12}
{"Episode reward": -99.68140969614475, "Episode length": 999, "Policy Loss": -1.4594069719314575, "Value Loss": 3.945605754852295, "_runtime": 18278.065281152725, "_timestamp": 1585615647.6981506, "_step": 13}
{"Episode reward": -99.62739097152814, "Episode length": 999, "Policy Loss": -0.8344975709915161, "Value Loss": 8.464025497436523, "_runtime": 18279.62821483612, "_timestamp": 1585615649.2610843, "_step": 14}
{"Episode reward": -99.85774226719374, "Episode length": 999, "Policy Loss": -1.4291467666625977, "Value Loss": 5.363377094268799, "_runtime": 18280.79418849945, "_timestamp": 1585615650.427058, "_step": 15}
{"Episode reward": 24.833363985351752, "Episode length": 753, "Policy Loss": 1.2277445793151855, "Value Loss": 39.34649658203125, "_runtime": 18282.371455430984, "_timestamp": 1585615652.004325, "_step": 16}
{"Episode reward": -99.63029755210599, "Episode length": 999, "Policy Loss": -1.319142460823059, "Value Loss": 5.943365097045898, "_runtime": 18283.96386241913, "_timestamp": 1585615653.596732, "_step": 17}
{"Episode reward": -99.5084406595023, "Episode length": 999, "Policy Loss": -1.1787455081939697, "Value Loss": 3.7353837490081787, "_runtime": 18285.501717805862, "_timestamp": 1585615655.1345873, "_step": 18}
{"Episode reward": -99.72099573472374, "Episode length": 999, "Policy Loss": -1.1175076961517334, "Value Loss": 3.078997850418091, "_runtime": 18287.067395448685, "_timestamp": 1585615656.700265, "_step": 19}
{"Episode reward": -99.88721957041277, "Episode length": 999, "Policy Loss": -1.4727866649627686, "Value Loss": 2.269131660461426, "_runtime": 18288.648138046265, "_timestamp": 1585615658.2810075, "_step": 20}
{"Episode reward": -99.56614537297726, "Episode length": 999, "Policy Loss": -1.901589035987854, "Value Loss": 0.35502907633781433, "_runtime": 18290.052762031555, "_timestamp": 1585615659.6856315, "_step": 21}
{"Episode reward": 10.254348088592181, "Episode length": 899, "Policy Loss": -1.0219546556472778, "Value Loss": 11.554484367370605, "_runtime": 18291.608058214188, "_timestamp": 1585615661.2409277, "_step": 22}
{"Episode reward": -99.76054045260396, "Episode length": 999, "Policy Loss": -1.7830969095230103, "Value Loss": 0.08023684471845627, "_runtime": 18293.20039319992, "_timestamp": 1585615662.8332627, "_step": 23}
{"Episode reward": -99.88788919449296, "Episode length": 999, "Policy Loss": -1.6416656970977783, "Value Loss": 0.06580887734889984, "_runtime": 18294.660071134567, "_timestamp": 1585615664.2929406, "_step": 24}
{"Episode reward": 7.194261688530517, "Episode length": 929, "Policy Loss": -0.5698584318161011, "Value Loss": 10.788956642150879, "_runtime": 18295.19907426834, "_timestamp": 1585615664.8319438, "_step": 25}
{"Episode reward": 68.45789467822743, "Episode length": 317, "Policy Loss": 1.0712776184082031, "Value Loss": 31.45722198486328, "_runtime": 18296.761182546616, "_timestamp": 1585615666.394052, "_step": 26}
{"Episode reward": -99.80014158794516, "Episode length": 999, "Policy Loss": -1.4631543159484863, "Value Loss": 0.044649697840213776, "_runtime": 18297.85355591774, "_timestamp": 1585615667.4864254, "_step": 27}
{"Episode reward": 30.999999999999645, "Episode length": 690, "Policy Loss": -0.3640858829021454, "Value Loss": 14.448295593261719, "_runtime": 18299.359684705734, "_timestamp": 1585615668.9925542, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3183233737945557, "Value Loss": 0.03272740915417671, "_runtime": 18300.444189071655, "_timestamp": 1585615670.0770586, "_step": 29}
{"Episode reward": 31.965639108419012, "Episode length": 681, "Policy Loss": -0.16701754927635193, "Value Loss": 14.678567886352539, "_runtime": 18301.68937778473, "_timestamp": 1585615671.3222473, "_step": 30}
{"Episode reward": 20.280873691774005, "Episode length": 799, "Policy Loss": -0.036755479872226715, "Value Loss": 12.597021102905273, "_runtime": 18303.236756801605, "_timestamp": 1585615672.8696263, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0481973886489868, "Value Loss": 0.07422813773155212, "_runtime": 18304.787923812866, "_timestamp": 1585615674.4207933, "_step": 32}
{"Episode reward": -99.81035897640838, "Episode length": 999, "Policy Loss": -1.121779441833496, "Value Loss": 0.055756960064172745, "_runtime": 18306.37942314148, "_timestamp": 1585615676.0122926, "_step": 33}
{"Episode reward": -99.71535402692831, "Episode length": 999, "Policy Loss": -1.0337748527526855, "Value Loss": 0.08322318643331528, "_runtime": 18307.948487520218, "_timestamp": 1585615677.581357, "_step": 34}
{"Episode reward": -99.71252353006427, "Episode length": 999, "Policy Loss": -0.9042333960533142, "Value Loss": 0.1568385809659958, "_runtime": 18309.530241250992, "_timestamp": 1585615679.1631107, "_step": 35}
{"Episode reward": -99.49771198961272, "Episode length": 999, "Policy Loss": -0.8065475225448608, "Value Loss": 0.21357451379299164, "_runtime": 18311.109684228897, "_timestamp": 1585615680.7425537, "_step": 36}
{"Episode reward": -99.48414140019132, "Episode length": 999, "Policy Loss": -0.36945655941963196, "Value Loss": 0.4281024634838104, "_runtime": 18312.04959845543, "_timestamp": 1585615681.682468, "_step": 37}
{"Episode reward": 41.0811692801997, "Episode length": 591, "Policy Loss": 0.5771980881690979, "Value Loss": 17.949440002441406, "_runtime": 18313.629009246826, "_timestamp": 1585615683.2618787, "_step": 38}
{"Episode reward": -99.77097667176137, "Episode length": 999, "Policy Loss": -0.9923132658004761, "Value Loss": 0.2512393295764923, "_runtime": 18315.21452331543, "_timestamp": 1585615684.8473928, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.120877981185913, "Value Loss": 0.15608608722686768, "_runtime": 18316.27485013008, "_timestamp": 1585615685.9077196, "_step": 40}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": -0.016721807420253754, "Value Loss": 14.831348419189453, "_runtime": 18317.854484319687, "_timestamp": 1585615687.4873538, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.193665862083435, "Value Loss": 0.07809611409902573, "_runtime": 18319.435722112656, "_timestamp": 1585615689.0685916, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1920826435089111, "Value Loss": 0.02942506968975067, "_runtime": 18320.979560375214, "_timestamp": 1585615690.6124299, "_step": 43}
{"Episode reward": -99.71215899921815, "Episode length": 999, "Policy Loss": -1.2089612483978271, "Value Loss": 0.02887539006769657, "_runtime": 18322.555892705917, "_timestamp": 1585615692.1887622, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2203176021575928, "Value Loss": 0.032880108803510666, "_runtime": 18324.14070534706, "_timestamp": 1585615693.7735748, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2256858348846436, "Value Loss": 0.021204620599746704, "_runtime": 18325.70110964775, "_timestamp": 1585615695.3339791, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.221947431564331, "Value Loss": 0.024141594767570496, "_runtime": 18326.77104783058, "_timestamp": 1585615696.4039173, "_step": 47}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": 0.004632039461284876, "Value Loss": 14.837749481201172, "_runtime": 18328.233596801758, "_timestamp": 1585615697.8664663, "_step": 48}
{"Episode reward": 7.8000000000009635, "Episode length": 922, "Policy Loss": -0.27782806754112244, "Value Loss": 10.889301300048828, "_runtime": 18329.166674613953, "_timestamp": 1585615698.799544, "_step": 49}
{"Episode reward": 41.79999999999945, "Episode length": 582, "Policy Loss": 0.3016384541988373, "Value Loss": 17.070283889770508, "_runtime": 18329.54737520218, "_timestamp": 1585615699.1802447, "_step": 50}
{"Episode reward": 78.29999999999997, "Episode length": 217, "Policy Loss": 3.2740793228149414, "Value Loss": 45.61753463745117, "_runtime": 18331.14589905739, "_timestamp": 1585615700.7787685, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1456973552703857, "Value Loss": 0.10666323453187943, "_runtime": 18331.994801044464, "_timestamp": 1585615701.6276705, "_step": 52}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.3698901832103729, "Value Loss": 18.307876586914062, "_runtime": 18333.10119318962, "_timestamp": 1585615702.7340627, "_step": 53}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 0.13272500038146973, "Value Loss": 13.269901275634766, "_runtime": 18334.659427642822, "_timestamp": 1585615704.2922971, "_step": 54}
{"Episode reward": -99.89781480431417, "Episode length": 999, "Policy Loss": -1.1960617303848267, "Value Loss": 0.12915754318237305, "_runtime": 18336.18647837639, "_timestamp": 1585615705.8193479, "_step": 55}
{"Episode reward": -99.81608996987202, "Episode length": 999, "Policy Loss": -1.2183557748794556, "Value Loss": 0.12947171926498413, "_runtime": 18337.716474056244, "_timestamp": 1585615707.3493435, "_step": 56}
{"Episode reward": -99.80004935860494, "Episode length": 999, "Policy Loss": -1.1649372577667236, "Value Loss": 0.09410552680492401, "_runtime": 18339.306101083755, "_timestamp": 1585615708.9389706, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1489063501358032, "Value Loss": 0.0916919857263565, "_runtime": 18340.880172014236, "_timestamp": 1585615710.5130415, "_step": 58}
{"Episode reward": -99.80808969139913, "Episode length": 999, "Policy Loss": -1.1112656593322754, "Value Loss": 0.08678494393825531, "_runtime": 18341.84890985489, "_timestamp": 1585615711.4817793, "_step": 59}
{"Episode reward": 39.047706198691735, "Episode length": 610, "Policy Loss": 0.30598753690719604, "Value Loss": 16.398271560668945, "_runtime": 18343.40742945671, "_timestamp": 1585615713.040299, "_step": 60}
{"Episode reward": 1.2000000000013387, "Episode length": 988, "Policy Loss": -0.07486660033464432, "Value Loss": 10.076094627380371, "_runtime": 18344.77444767952, "_timestamp": 1585615714.4073172, "_step": 61}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": -0.07829980552196503, "Value Loss": 11.420559883117676, "_runtime": 18346.30702495575, "_timestamp": 1585615715.9398944, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0582159757614136, "Value Loss": 0.0156780406832695, "_runtime": 18347.581800937653, "_timestamp": 1585615717.2146704, "_step": 63}
{"Episode reward": 19.5000000000003, "Episode length": 805, "Policy Loss": 0.10777414590120316, "Value Loss": 12.39167308807373, "_runtime": 18348.81397461891, "_timestamp": 1585615718.446844, "_step": 64}
{"Episode reward": 21.800000000000168, "Episode length": 782, "Policy Loss": 0.0878356397151947, "Value Loss": 12.767288208007812, "_runtime": 18350.37905240059, "_timestamp": 1585615720.011922, "_step": 65}
{"Episode reward": -99.83291666507581, "Episode length": 999, "Policy Loss": -0.9962996244430542, "Value Loss": 0.012535258196294308, "_runtime": 18350.838726997375, "_timestamp": 1585615720.4715965, "_step": 66}
{"Episode reward": 73.60367650985708, "Episode length": 264, "Policy Loss": 3.3999276161193848, "Value Loss": 37.86864471435547, "_runtime": 18352.39993953705, "_timestamp": 1585615722.032809, "_step": 67}
{"Episode reward": -99.85400240421156, "Episode length": 999, "Policy Loss": -0.9793578386306763, "Value Loss": 0.012154607102274895, "_runtime": 18353.823785305023, "_timestamp": 1585615723.4566548, "_step": 68}
{"Episode reward": 12.200000000000713, "Episode length": 878, "Policy Loss": 0.00802422221750021, "Value Loss": 11.357669830322266, "_runtime": 18355.324353456497, "_timestamp": 1585615724.957223, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9826268553733826, "Value Loss": 0.018337121233344078, "_runtime": 18356.90572452545, "_timestamp": 1585615726.538594, "_step": 70}
{"Episode reward": -99.85530188083509, "Episode length": 999, "Policy Loss": -0.9576566219329834, "Value Loss": 0.021806437522172928, "_runtime": 18358.461062192917, "_timestamp": 1585615728.0939317, "_step": 71}
{"Episode reward": -99.80190272927145, "Episode length": 999, "Policy Loss": -0.9763538837432861, "Value Loss": 0.03221873193979263, "_runtime": 18360.01380133629, "_timestamp": 1585615729.6466708, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.94456946849823, "Value Loss": 0.021819381043314934, "_runtime": 18361.07906293869, "_timestamp": 1585615730.7119324, "_step": 73}
{"Episode reward": 33.4999999999995, "Episode length": 665, "Policy Loss": 0.7560998201370239, "Value Loss": 14.987040519714355, "_runtime": 18362.654470205307, "_timestamp": 1585615732.2873397, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9259605407714844, "Value Loss": 0.0675388053059578, "_runtime": 18364.218501091003, "_timestamp": 1585615733.8513706, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9091072678565979, "Value Loss": 0.053426675498485565, "_runtime": 18365.770080566406, "_timestamp": 1585615735.40295, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9164361357688904, "Value Loss": 0.018099728971719742, "_runtime": 18367.3437833786, "_timestamp": 1585615736.9766529, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8891800045967102, "Value Loss": 0.017173228785395622, "_runtime": 18368.59010195732, "_timestamp": 1585615738.2229714, "_step": 78}
{"Episode reward": 20.90000000000022, "Episode length": 791, "Policy Loss": 0.4155251085758209, "Value Loss": 12.588635444641113, "_runtime": 18369.436452150345, "_timestamp": 1585615739.0693216, "_step": 79}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 0.8309080600738525, "Value Loss": 19.02933692932129, "_runtime": 18371.01531767845, "_timestamp": 1585615740.6481872, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8451215624809265, "Value Loss": 0.017686067149043083, "_runtime": 18372.05312347412, "_timestamp": 1585615741.685993, "_step": 81}
{"Episode reward": 34.09999999999947, "Episode length": 659, "Policy Loss": 0.5499709248542786, "Value Loss": 15.132019996643066, "_runtime": 18373.554996967316, "_timestamp": 1585615743.1878664, "_step": 82}
{"Episode reward": 2.085120296479559, "Episode length": 980, "Policy Loss": 0.17310091853141785, "Value Loss": 10.171489715576172, "_runtime": 18375.137409210205, "_timestamp": 1585615744.7702787, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8187615275382996, "Value Loss": 0.009691662155091763, "_runtime": 18376.495401859283, "_timestamp": 1585615746.1282713, "_step": 84}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 0.1909017115831375, "Value Loss": 11.292893409729004, "_runtime": 18378.098042488098, "_timestamp": 1585615747.730912, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8221262097358704, "Value Loss": 0.011225398629903793, "_runtime": 18379.68205499649, "_timestamp": 1585615749.3149245, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.764215350151062, "Value Loss": 0.021205732598900795, "_runtime": 18381.072454690933, "_timestamp": 1585615750.7053242, "_step": 87}
{"Episode reward": 10.75805176636284, "Episode length": 893, "Policy Loss": 0.21563798189163208, "Value Loss": 11.151435852050781, "_runtime": 18381.9014377594, "_timestamp": 1585615751.5343072, "_step": 88}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 0.9992331862449646, "Value Loss": 19.39609146118164, "_runtime": 18383.46899008751, "_timestamp": 1585615753.1018596, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7665672898292542, "Value Loss": 0.0204189270734787, "_runtime": 18384.195038557053, "_timestamp": 1585615753.827908, "_step": 90}
{"Episode reward": 55.499999999999645, "Episode length": 445, "Policy Loss": 1.1790335178375244, "Value Loss": 22.326784133911133, "_runtime": 18385.445122480392, "_timestamp": 1585615755.077992, "_step": 91}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": 0.28988879919052124, "Value Loss": 12.266971588134766, "_runtime": 18386.443175315857, "_timestamp": 1585615756.0760448, "_step": 92}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.8643713593482971, "Value Loss": 15.914434432983398, "_runtime": 18387.964389562607, "_timestamp": 1585615757.597259, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7768269777297974, "Value Loss": 0.03135618567466736, "_runtime": 18389.522547006607, "_timestamp": 1585615759.1554165, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7612869739532471, "Value Loss": 0.07725291699171066, "_runtime": 18391.05969429016, "_timestamp": 1585615760.6925638, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8631200790405273, "Value Loss": 0.13243789970874786, "_runtime": 18392.50096154213, "_timestamp": 1585615762.133831, "_step": 96}
{"Episode reward": 7.700000000000969, "Episode length": 923, "Policy Loss": 0.17528000473976135, "Value Loss": 10.818193435668945, "_runtime": 18393.76951956749, "_timestamp": 1585615763.402389, "_step": 97}
{"Episode reward": 20.169375263899823, "Episode length": 801, "Policy Loss": 0.3958224356174469, "Value Loss": 12.415324211120605, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112, -0.017939493060112]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0], "bins": [-2.080228090286255, -2.040969133377075, -2.0017104148864746, -1.9624515771865845, -1.9231927394866943, -1.8839337825775146, -1.844675064086914, -1.8054161071777344, -1.7661572694778442, -1.726898431777954, -1.687639594078064, -1.6483807563781738, -1.6091219186782837, -1.5698630809783936, -1.5306041240692139, -1.4913454055786133, -1.4520864486694336, -1.412827730178833, -1.3735687732696533, -1.3343099355697632, -1.295051097869873, -1.255792260169983, -1.2165334224700928, -1.1772745847702026, -1.1380157470703125, -1.0987567901611328, -1.0594980716705322, -1.0202391147613525, -0.9809802770614624, -0.9417214393615723, -0.9024626016616821, -0.863203763961792, -0.8239449262619019, -0.7846860885620117, -0.7454272508621216, -0.7061684131622314, -0.6669095754623413, -0.6276507377624512, -0.5883917808532715, -0.5491329431533813, -0.5098741054534912, -0.4706152677536011, -0.43135643005371094, -0.3920975923538208, -0.35283875465393066, -0.3135799169540405, -0.2743210792541504, -0.23506224155426025, -0.19580340385437012, -0.15654444694519043, -0.11728560924530029, -0.07802677154541016, -0.03876805305480957, 0.0004909038543701172, 0.039749860763549805, 0.07900857925415039, 0.11826753616333008, 0.15752625465393066, 0.19678521156311035, 0.23604393005371094, 0.2753028869628906, 0.3145616054534912, 0.3538205623626709, 0.3930792808532715, 0.43233823776245117]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 1.0], "bins": [-0.10289864242076874, -0.10126269608736038, -0.09962674975395203, -0.09799079596996307, -0.09635484963655472, -0.09471890330314636, -0.093082956969738, -0.09144701063632965, -0.0898110568523407, -0.08817511051893234, -0.08653916418552399, -0.08490321785211563, -0.08326727151870728, -0.08163131773471832, -0.07999537885189056, -0.07835942506790161, -0.07672347873449326, -0.0750875324010849, -0.07345157861709595, -0.07181563973426819, -0.07017968595027924, -0.06854373961687088, -0.06690779328346252, -0.06527183949947357, -0.06363590061664581, -0.06199995055794716, -0.060364000499248505, -0.05872805416584015, -0.05709210783243179, -0.05545615777373314, -0.05382021144032478, -0.05218426138162613, -0.05054831504821777, -0.04891236871480942, -0.047276418656110764, -0.04564047232270241, -0.044004522264003754, -0.0423685759305954, -0.04073262959718704, -0.039096683263778687, -0.037460729479789734, -0.03582478314638138, -0.03418883681297302, -0.03255289047956467, -0.03091694414615631, -0.029280997812747955, -0.027645044028759003, -0.026009097695350647, -0.02437315136194229, -0.022737205028533936, -0.02110125869512558, -0.019465304911136627, -0.01782935857772827, -0.016193412244319916, -0.01455746591091156, -0.012921519577503204, -0.011285573244094849, -0.009649619460105896, -0.00801367312669754, -0.006377726793289185, -0.004741780459880829, -0.003105834126472473, -0.0014698803424835205, 0.0001660659909248352, 0.001802012324333191]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 5.0, 7.0, 10.0, 13.0, 83.0, 282.0, 13.0, 17.0, 7.0, 4.0, 4.0, 3.0, 2.0, 11.0, 6.0, 3.0, 4.0, 3.0, 9.0], "bins": [-0.37707141041755676, -0.36954838037490845, -0.3620253801345825, -0.3545023500919342, -0.3469793200492859, -0.3394562900066376, -0.33193325996398926, -0.32441025972366333, -0.316887229681015, -0.3093641996383667, -0.30184119939804077, -0.29431816935539246, -0.28679513931274414, -0.2792721092700958, -0.2717490792274475, -0.2642260789871216, -0.25670304894447327, -0.24918001890182495, -0.24165700376033783, -0.2341339886188507, -0.2266109585762024, -0.21908792853355408, -0.21156491339206696, -0.20404189825057983, -0.19651886820793152, -0.1889958381652832, -0.18147282302379608, -0.17394980788230896, -0.16642677783966064, -0.15890374779701233, -0.1513807326555252, -0.14385771751403809, -0.13633468747138977, -0.12881165742874146, -0.12128862738609314, -0.11376562714576721, -0.1062425971031189, -0.09871956706047058, -0.09119656682014465, -0.08367353677749634, -0.07615050673484802, -0.06862747669219971, -0.06110444664955139, -0.053581446409225464, -0.04605841636657715, -0.03853538632392883, -0.031012386083602905, -0.02348935604095459, -0.015966325998306274, -0.008443295955657959, -0.0009202659130096436, 0.006602734327316284, 0.0141257643699646, 0.021648794412612915, 0.029171794652938843, 0.03669482469558716, 0.044217854738235474, 0.05174088478088379, 0.059263914823532104, 0.06678691506385803, 0.07430994510650635, 0.08183297514915466, 0.08935597538948059, 0.0968790054321289, 0.10440203547477722]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.6614245772361755, -0.6432094573974609, -0.6249943375587463, -0.6067792773246765, -0.5885641574859619, -0.5703490376472473, -0.5521339178085327, -0.5339187979698181, -0.5157036781311035, -0.4974886178970337, -0.4792734980583191, -0.4610583782196045, -0.4428432583808899, -0.4246281683444977, -0.4064130485057831, -0.38819795846939087, -0.36998283863067627, -0.35176771879196167, -0.33355262875556946, -0.31533750891685486, -0.29712241888046265, -0.27890729904174805, -0.26069217920303345, -0.24247708916664124, -0.22426196932792664, -0.20604684948921204, -0.18783175945281982, -0.16961663961410522, -0.15140151977539062, -0.13318639993667603, -0.1149713397026062, -0.0967562198638916, -0.078541100025177, -0.0603259801864624, -0.0421108603477478, -0.02389580011367798, -0.005680680274963379, 0.01253443956375122, 0.03074955940246582, 0.04896467924118042, 0.06717973947525024, 0.08539485931396484, 0.10360997915267944, 0.12182509899139404, 0.14004021883010864, 0.15825533866882324, 0.17647039890289307, 0.19468551874160767, 0.21290063858032227, 0.23111575841903687, 0.24933087825775146, 0.2675459384918213, 0.2857610583305359, 0.3039761781692505, 0.3221912980079651, 0.3404063582420349, 0.3586215376853943, 0.3768365979194641, 0.3950517773628235, 0.4132668375968933, 0.43148189783096313, 0.4496970772743225, 0.46791213750839233, 0.4861273169517517, 0.5043423771858215]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 5.0, 11.0, 6.0, 7.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 4.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2246370315551758, -1.1921923160552979, -1.15974760055542, -1.127302885055542, -1.0948582887649536, -1.0624135732650757, -1.0299688577651978, -0.9975241422653198, -0.9650794267654419, -0.9326347708702087, -0.9001900553703308, -0.8677453994750977, -0.8353006839752197, -0.8028559684753418, -0.7704112529754639, -0.7379665374755859, -0.7055218815803528, -0.6730771660804749, -0.6406325101852417, -0.6081877946853638, -0.5757430791854858, -0.5432984232902527, -0.5108537077903748, -0.4784089922904968, -0.44596433639526367, -0.41351962089538574, -0.3810749053955078, -0.3486301898956299, -0.31618553400039673, -0.2837408185005188, -0.25129610300064087, -0.21885144710540771, -0.18640673160552979, -0.15396201610565186, -0.12151730060577393, -0.089072585105896, -0.05662798881530762, -0.024183273315429688, 0.008261442184448242, 0.04070615768432617, 0.0731508731842041, 0.10559558868408203, 0.1380401849746704, 0.17048490047454834, 0.20292961597442627, 0.2353743314743042, 0.26781904697418213, 0.30026376247406006, 0.33270835876464844, 0.36515307426452637, 0.3975977897644043, 0.4300425052642822, 0.46248722076416016, 0.4949319362640381, 0.527376651763916, 0.5598212480545044, 0.5922659635543823, 0.6247106790542603, 0.6571553945541382, 0.6896001100540161, 0.722044825553894, 0.7544894218444824, 0.7869341373443604, 0.8193788528442383, 0.8518235683441162]}, "_runtime": 18395.347043037415, "_timestamp": 1585615764.9799125, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7596806883811951, "Value Loss": 0.0729561522603035, "_runtime": 18396.904310941696, "_timestamp": 1585615766.5371804, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7182239890098572, "Value Loss": 0.02755812369287014, "_runtime": 18398.463514089584, "_timestamp": 1585615768.0963836, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7233256697654724, "Value Loss": 0.011954382993280888, "_runtime": 18400.041226625443, "_timestamp": 1585615769.674096, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7093259692192078, "Value Loss": 0.007012369576841593, "_runtime": 18400.63848900795, "_timestamp": 1585615770.2713585, "_step": 102}
{"Episode reward": 66.9999999999998, "Episode length": 330, "Policy Loss": 1.994734287261963, "Value Loss": 30.26580810546875, "_runtime": 18402.102736234665, "_timestamp": 1585615771.7356057, "_step": 103}
{"Episode reward": 6.700000000001026, "Episode length": 933, "Policy Loss": 0.3259132206439972, "Value Loss": 10.711396217346191, "_runtime": 18402.780861854553, "_timestamp": 1585615772.4137313, "_step": 104}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 1.4177534580230713, "Value Loss": 23.722003936767578, "_runtime": 18403.230535030365, "_timestamp": 1585615772.8634045, "_step": 105}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 2.56225323677063, "Value Loss": 34.74809646606445, "_runtime": 18404.218616247177, "_timestamp": 1585615773.8514857, "_step": 106}
{"Episode reward": 36.98722496032653, "Episode length": 631, "Policy Loss": 0.7644088864326477, "Value Loss": 15.773357391357422, "_runtime": 18405.729137659073, "_timestamp": 1585615775.3620071, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7452048063278198, "Value Loss": 0.019177386537194252, "_runtime": 18406.095880508423, "_timestamp": 1585615775.72875, "_step": 108}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 3.198657751083374, "Value Loss": 43.39743423461914, "_runtime": 18406.98351407051, "_timestamp": 1585615776.6163836, "_step": 109}
{"Episode reward": 42.29999999999946, "Episode length": 577, "Policy Loss": 0.7240267992019653, "Value Loss": 17.325599670410156, "_runtime": 18407.940649986267, "_timestamp": 1585615777.5735195, "_step": 110}
{"Episode reward": 38.99999999999941, "Episode length": 610, "Policy Loss": 0.5341277718544006, "Value Loss": 16.39348030090332, "_runtime": 18409.44834637642, "_timestamp": 1585615779.0812159, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7742169499397278, "Value Loss": 0.24564771354198456, "_runtime": 18410.977551698685, "_timestamp": 1585615780.6104212, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.808845579624176, "Value Loss": 0.38210636377334595, "_runtime": 18412.28682255745, "_timestamp": 1585615781.919692, "_step": 113}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": 0.08102837949991226, "Value Loss": 11.659369468688965, "_runtime": 18413.81121325493, "_timestamp": 1585615783.4440827, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8703897595405579, "Value Loss": 0.10699719935655594, "_runtime": 18415.378759622574, "_timestamp": 1585615785.011629, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8297054767608643, "Value Loss": 0.10268725454807281, "_runtime": 18416.916583299637, "_timestamp": 1585615786.5494528, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8360103368759155, "Value Loss": 0.0384165495634079, "_runtime": 18418.4609041214, "_timestamp": 1585615788.0937736, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8174256086349487, "Value Loss": 0.016364580020308495, "_runtime": 18419.339228630066, "_timestamp": 1585615788.972098, "_step": 118}
{"Episode reward": 44.299999999999486, "Episode length": 557, "Policy Loss": 0.7648748159408569, "Value Loss": 17.929122924804688, "_runtime": 18420.897887468338, "_timestamp": 1585615790.530757, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8066335916519165, "Value Loss": 0.014831369742751122, "_runtime": 18422.45714521408, "_timestamp": 1585615792.0900147, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7720537185668945, "Value Loss": 0.009936042129993439, "_runtime": 18423.564427137375, "_timestamp": 1585615793.1972966, "_step": 121}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.44437623023986816, "Value Loss": 13.909756660461426, "_runtime": 18425.050858974457, "_timestamp": 1585615794.6837285, "_step": 122}
{"Episode reward": 7.5000000000009805, "Episode length": 925, "Policy Loss": 0.2681364119052887, "Value Loss": 10.882448196411133, "_runtime": 18426.272859096527, "_timestamp": 1585615795.9057286, "_step": 123}
{"Episode reward": 21.313458041846943, "Episode length": 788, "Policy Loss": 0.3957592248916626, "Value Loss": 12.735921859741211, "_runtime": 18427.415673732758, "_timestamp": 1585615797.0485432, "_step": 124}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": 0.4292280375957489, "Value Loss": 13.536635398864746, "_runtime": 18428.975355386734, "_timestamp": 1585615798.6082249, "_step": 125}
{"Episode reward": -99.80575953125813, "Episode length": 999, "Policy Loss": -0.7811815142631531, "Value Loss": 0.008103379048407078, "_runtime": 18430.296921491623, "_timestamp": 1585615799.929791, "_step": 126}
{"Episode reward": 14.005670058727873, "Episode length": 861, "Policy Loss": 0.45297491550445557, "Value Loss": 11.592771530151367, "_runtime": 18431.213083982468, "_timestamp": 1585615800.8459535, "_step": 127}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 0.9402888417243958, "Value Loss": 16.93993377685547, "_runtime": 18432.774419546127, "_timestamp": 1585615802.407289, "_step": 128}
{"Episode reward": -99.85068216323712, "Episode length": 999, "Policy Loss": -0.8196524977684021, "Value Loss": 0.010852656327188015, "_runtime": 18433.768884897232, "_timestamp": 1585615803.4017544, "_step": 129}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.5053795576095581, "Value Loss": 15.568171501159668, "_runtime": 18435.29220867157, "_timestamp": 1585615804.9250782, "_step": 130}
{"Episode reward": -99.8327767431722, "Episode length": 999, "Policy Loss": -0.8575247526168823, "Value Loss": 0.022315122187137604, "_runtime": 18435.930831432343, "_timestamp": 1585615805.563701, "_step": 131}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.6761372089385986, "Value Loss": 25.009498596191406, "_runtime": 18436.538347244263, "_timestamp": 1585615806.1712167, "_step": 132}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 1.3452091217041016, "Value Loss": 25.032546997070312, "_runtime": 18437.23317527771, "_timestamp": 1585615806.8660448, "_step": 133}
{"Episode reward": 56.199999999999655, "Episode length": 438, "Policy Loss": 1.0601608753204346, "Value Loss": 22.716588973999023, "_runtime": 18438.60542345047, "_timestamp": 1585615808.238293, "_step": 134}
{"Episode reward": 8.40000000000093, "Episode length": 916, "Policy Loss": 0.07372976094484329, "Value Loss": 10.882402420043945, "_runtime": 18440.102758407593, "_timestamp": 1585615809.735628, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9700425863265991, "Value Loss": 0.09767507016658783, "_runtime": 18440.92358827591, "_timestamp": 1585615810.5564578, "_step": 136}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 0.7554872632026672, "Value Loss": 18.491907119750977, "_runtime": 18442.263879060745, "_timestamp": 1585615811.8967485, "_step": 137}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": 0.15021780133247375, "Value Loss": 11.660738945007324, "_runtime": 18443.81081724167, "_timestamp": 1585615813.4436867, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9588832259178162, "Value Loss": 0.233061283826828, "_runtime": 18444.324625730515, "_timestamp": 1585615813.9574952, "_step": 139}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 1.6170352697372437, "Value Loss": 30.760482788085938, "_runtime": 18445.303009986877, "_timestamp": 1585615814.9358795, "_step": 140}
{"Episode reward": 37.299999999999386, "Episode length": 627, "Policy Loss": 0.35561397671699524, "Value Loss": 15.755691528320312, "_runtime": 18446.83856153488, "_timestamp": 1585615816.471431, "_step": 141}
{"Episode reward": -99.86983833908896, "Episode length": 999, "Policy Loss": -1.0253996849060059, "Value Loss": 0.10157839953899384, "_runtime": 18448.371563196182, "_timestamp": 1585615818.0044327, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0050506591796875, "Value Loss": 0.14258980751037598, "_runtime": 18449.89601969719, "_timestamp": 1585615819.5288892, "_step": 143}
{"Episode reward": -99.80935798287251, "Episode length": 999, "Policy Loss": -0.9873175024986267, "Value Loss": 0.058259669691324234, "_runtime": 18451.107543468475, "_timestamp": 1585615820.740413, "_step": 144}
{"Episode reward": 21.988681769371198, "Episode length": 781, "Policy Loss": 0.23966780304908752, "Value Loss": 12.640741348266602, "_runtime": 18452.40732526779, "_timestamp": 1585615822.0401947, "_step": 145}
{"Episode reward": 15.900000000000503, "Episode length": 841, "Policy Loss": 0.09490234404802322, "Value Loss": 11.763501167297363, "_runtime": 18453.6122341156, "_timestamp": 1585615823.2451036, "_step": 146}
{"Episode reward": 22.9983929362149, "Episode length": 771, "Policy Loss": 0.20617438852787018, "Value Loss": 12.863409042358398, "_runtime": 18455.157707691193, "_timestamp": 1585615824.7905772, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9950780272483826, "Value Loss": 0.03540709614753723, "_runtime": 18456.695843696594, "_timestamp": 1585615826.3287132, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.957304060459137, "Value Loss": 0.02687542885541916, "_runtime": 18458.23655486107, "_timestamp": 1585615827.8694243, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9545999765396118, "Value Loss": 0.03048723004758358, "_runtime": 18459.79860806465, "_timestamp": 1585615829.4314775, "_step": 150}
{"Episode reward": -99.81476221717755, "Episode length": 999, "Policy Loss": -0.9072144627571106, "Value Loss": 0.018908845260739326, "_runtime": 18461.349089622498, "_timestamp": 1585615830.981959, "_step": 151}
{"Episode reward": -99.81647416502098, "Episode length": 999, "Policy Loss": -0.9069342017173767, "Value Loss": 0.027366455644369125, "_runtime": 18462.914394378662, "_timestamp": 1585615832.5472639, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8617880940437317, "Value Loss": 0.011091433465480804, "_runtime": 18464.468473672867, "_timestamp": 1585615834.1013432, "_step": 153}
{"Episode reward": -99.88754763752083, "Episode length": 999, "Policy Loss": -0.8253021836280823, "Value Loss": 0.00904698297381401, "_runtime": 18466.032022953033, "_timestamp": 1585615835.6648924, "_step": 154}
{"Episode reward": -99.8050449371324, "Episode length": 999, "Policy Loss": -0.7961046099662781, "Value Loss": 0.009886602871119976, "_runtime": 18466.410754680634, "_timestamp": 1585615836.0436242, "_step": 155}
{"Episode reward": 78.79999999999998, "Episode length": 212, "Policy Loss": 4.068118095397949, "Value Loss": 46.98783493041992, "_runtime": 18467.969497203827, "_timestamp": 1585615837.6023667, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7802127599716187, "Value Loss": 0.010251256637275219, "_runtime": 18469.534863233566, "_timestamp": 1585615839.1677327, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7720075249671936, "Value Loss": 0.011472370475530624, "_runtime": 18470.90244603157, "_timestamp": 1585615840.5353155, "_step": 158}
{"Episode reward": 7.8000000000009635, "Episode length": 922, "Policy Loss": 0.2562348246574402, "Value Loss": 10.779865264892578, "_runtime": 18472.508724927902, "_timestamp": 1585615842.1415944, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7918088436126709, "Value Loss": 0.014043367467820644, "_runtime": 18474.075552225113, "_timestamp": 1585615843.7084217, "_step": 160}
{"Episode reward": -99.80535669326642, "Episode length": 999, "Policy Loss": -0.7797430157661438, "Value Loss": 0.01422943640500307, "_runtime": 18475.606256961823, "_timestamp": 1585615845.2391264, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7746756672859192, "Value Loss": 0.021325858309864998, "_runtime": 18477.102785348892, "_timestamp": 1585615846.7356548, "_step": 162}
{"Episode reward": 4.900000000001128, "Episode length": 951, "Policy Loss": 0.13549350202083588, "Value Loss": 10.446968078613281, "_runtime": 18478.66192150116, "_timestamp": 1585615848.294791, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8239068388938904, "Value Loss": 0.0206011775881052, "_runtime": 18479.372888565063, "_timestamp": 1585615849.005758, "_step": 164}
{"Episode reward": 55.29999999999964, "Episode length": 447, "Policy Loss": 1.1777836084365845, "Value Loss": 22.128366470336914, "_runtime": 18480.936041116714, "_timestamp": 1585615850.5689106, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7925702333450317, "Value Loss": 0.010782050900161266, "_runtime": 18482.505751609802, "_timestamp": 1585615852.138621, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.807997465133667, "Value Loss": 0.013474378734827042, "_runtime": 18484.016375541687, "_timestamp": 1585615853.649245, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8341941237449646, "Value Loss": 0.07089235633611679, "_runtime": 18485.58098244667, "_timestamp": 1585615855.213852, "_step": 168}
{"Episode reward": -99.8130469813929, "Episode length": 999, "Policy Loss": -0.8166210055351257, "Value Loss": 0.04967620596289635, "_runtime": 18487.14438199997, "_timestamp": 1585615856.7772515, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7460461854934692, "Value Loss": 0.02778506465256214, "_runtime": 18487.964629411697, "_timestamp": 1585615857.597499, "_step": 170}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 0.8285388946533203, "Value Loss": 19.078746795654297, "_runtime": 18489.532210588455, "_timestamp": 1585615859.16508, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7642441391944885, "Value Loss": 0.02908473275601864, "_runtime": 18490.551127433777, "_timestamp": 1585615860.183997, "_step": 172}
{"Episode reward": 35.79999999999937, "Episode length": 642, "Policy Loss": 0.6408056616783142, "Value Loss": 15.363197326660156, "_runtime": 18492.03915286064, "_timestamp": 1585615861.6720223, "_step": 173}
{"Episode reward": 1.8000000000013046, "Episode length": 982, "Policy Loss": 0.14986880123615265, "Value Loss": 10.0448579788208, "_runtime": 18493.607789754868, "_timestamp": 1585615863.2406592, "_step": 174}
{"Episode reward": -99.85271837711194, "Episode length": 999, "Policy Loss": -0.7530304193496704, "Value Loss": 0.030953291803598404, "_runtime": 18495.17781186104, "_timestamp": 1585615864.8106813, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7444507479667664, "Value Loss": 0.07458502054214478, "_runtime": 18496.725861787796, "_timestamp": 1585615866.3587313, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7560887932777405, "Value Loss": 0.04909667745232582, "_runtime": 18498.288428544998, "_timestamp": 1585615867.921298, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.722068190574646, "Value Loss": 0.04914962872862816, "_runtime": 18499.85575556755, "_timestamp": 1585615869.488625, "_step": 178}
{"Episode reward": -99.72971925735335, "Episode length": 999, "Policy Loss": -0.69136643409729, "Value Loss": 0.03610599413514137, "_runtime": 18501.420869112015, "_timestamp": 1585615871.0537386, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6382136344909668, "Value Loss": 0.051846943795681, "_runtime": 18502.85414147377, "_timestamp": 1585615872.487011, "_step": 180}
{"Episode reward": 8.698660826683962, "Episode length": 914, "Policy Loss": 0.33545637130737305, "Value Loss": 10.852171897888184, "_runtime": 18503.65213036537, "_timestamp": 1585615873.2849998, "_step": 181}
{"Episode reward": 49.99999999999957, "Episode length": 500, "Policy Loss": 1.1365582942962646, "Value Loss": 19.777700424194336, "_runtime": 18504.301923274994, "_timestamp": 1585615873.9347928, "_step": 182}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.6850825548171997, "Value Loss": 24.589345932006836, "_runtime": 18505.85767865181, "_timestamp": 1585615875.4905481, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.589430034160614, "Value Loss": 0.00927953515201807, "_runtime": 18507.376000642776, "_timestamp": 1585615877.0088701, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.645612895488739, "Value Loss": 0.024072537198662758, "_runtime": 18508.886640548706, "_timestamp": 1585615878.51951, "_step": 185}
{"Episode reward": -99.81428308486798, "Episode length": 999, "Policy Loss": -0.6267179250717163, "Value Loss": 0.012783652171492577, "_runtime": 18510.091164827347, "_timestamp": 1585615879.7240343, "_step": 186}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.6127274036407471, "Value Loss": 12.917142868041992, "_runtime": 18511.657553195953, "_timestamp": 1585615881.2904227, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6036519408226013, "Value Loss": 0.032986562699079514, "_runtime": 18512.622400522232, "_timestamp": 1585615882.25527, "_step": 188}
{"Episode reward": 38.3999999999994, "Episode length": 616, "Policy Loss": 0.779178261756897, "Value Loss": 16.016252517700195, "_runtime": 18514.15846323967, "_timestamp": 1585615883.7913327, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6153343319892883, "Value Loss": 0.018463509157299995, "_runtime": 18515.719601631165, "_timestamp": 1585615885.352471, "_step": 190}
{"Episode reward": -99.80797896981099, "Episode length": 999, "Policy Loss": -0.6138836145401001, "Value Loss": 0.0483534075319767, "_runtime": 18517.246322155, "_timestamp": 1585615886.8791916, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6162809133529663, "Value Loss": 0.0476636067032814, "_runtime": 18518.83908843994, "_timestamp": 1585615888.471958, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5965625643730164, "Value Loss": 0.05042135342955589, "_runtime": 18520.215183734894, "_timestamp": 1585615889.8480532, "_step": 193}
{"Episode reward": 13.105177645385936, "Episode length": 870, "Policy Loss": 0.42193418741226196, "Value Loss": 11.329692840576172, "_runtime": 18520.774829626083, "_timestamp": 1585615890.407699, "_step": 194}
{"Episode reward": 66.5999999999998, "Episode length": 334, "Policy Loss": 2.219081401824951, "Value Loss": 29.46308708190918, "_runtime": 18521.439794540405, "_timestamp": 1585615891.072664, "_step": 195}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": 1.3762089014053345, "Value Loss": 24.00490951538086, "_runtime": 18522.23189496994, "_timestamp": 1585615891.8647645, "_step": 196}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": 1.4278184175491333, "Value Loss": 19.87972068786621, "_runtime": 18523.7115316391, "_timestamp": 1585615893.3444011, "_step": 197}
{"Episode reward": 1.7000000000013102, "Episode length": 983, "Policy Loss": 0.18165996670722961, "Value Loss": 10.046976089477539, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962, -0.0002981610596179962]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.4943416118621826, -0.477215051651001, -0.46008849143981934, -0.4429619312286377, -0.42583537101745605, -0.4087088108062744, -0.39158228039741516, -0.3744557201862335, -0.3573291599750519, -0.34020259976387024, -0.3230760395526886, -0.30594950914382935, -0.2888229489326477, -0.27169638872146606, -0.2545698285102844, -0.23744326829910278, -0.22031670808792114, -0.2031901478767395, -0.18606358766555786, -0.16893702745437622, -0.15181046724319458, -0.13468393683433533, -0.11755737662315369, -0.10043081641197205, -0.0833042562007904, -0.06617769598960876, -0.049051135778427124, -0.03192457556724548, -0.01479804515838623, 0.00232851505279541, 0.01945507526397705, 0.03658163547515869, 0.05370819568634033, 0.07083475589752197, 0.08796131610870361, 0.10508787631988525, 0.1222144365310669, 0.13934099674224854, 0.15646755695343018, 0.17359411716461182, 0.19072067737579346, 0.20784717798233032, 0.22497373819351196, 0.2421002984046936, 0.25922685861587524, 0.2763534188270569, 0.2934799790382385, 0.31060653924942017, 0.3277330994606018, 0.34485965967178345, 0.3619862198829651, 0.37911278009414673, 0.39623934030532837, 0.41336590051651, 0.43049246072769165, 0.4476190209388733, 0.46474552154541016, 0.4818720817565918, 0.49899864196777344, 0.5161252021789551, 0.5332517623901367, 0.5503783226013184, 0.5675048828125, 0.5846314430236816, 0.6017580032348633]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.00646982854232192, -0.005958552472293377, -0.005447276867926121, -0.004936000797897577, -0.004424724727869034, -0.003913449123501778, -0.003402173053473234, -0.0028908972162753344, -0.0023796213790774345, -0.001868345309048891, -0.001357069704681635, -0.0008457936346530914, -0.00033451756462454796, 0.0001767580397427082, 0.0006880341097712517, 0.0011993097141385078, 0.0017105857841670513, 0.0022218613885343075, 0.0027331379242241383, 0.0032444135285913944, 0.0037556891329586506, 0.004266965668648481, 0.0047782412730157375, 0.005289516877382994, 0.0058007934130728245, 0.006312069017440081, 0.006823344621807337, 0.007334620226174593, 0.007845897227525711, 0.008357172831892967, 0.008868448436260223, 0.00937972404062748, 0.009890999644994736, 0.010402275249361992, 0.010913550853729248, 0.011424826458096504, 0.01193610392510891, 0.012447379529476166, 0.012958655133843422, 0.013469930738210678, 0.013981206342577934, 0.01449248194694519, 0.015003759413957596, 0.015515035018324852, 0.016026310622692108, 0.016537586227059364, 0.01704886183142662, 0.017560137435793877, 0.018071414902806282, 0.018582690507173538, 0.019093966111540794, 0.01960524171590805, 0.020116517320275307, 0.020627792924642563, 0.02113906852900982, 0.021650345996022224, 0.02216162160038948, 0.022672897204756737, 0.023184172809123993, 0.02369544841349125, 0.024206724017858505, 0.02471800148487091, 0.025229277089238167, 0.025740550830960274, 0.02625182829797268]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 4.0, 6.0, 8.0, 5.0, 6.0, 23.0, 92.0, 86.0, 185.0, 55.0, 1.0, 1.0, 5.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15277907252311707, -0.14404799044132233, -0.1353169083595276, -0.12658584117889404, -0.1178547590970993, -0.10912367701530457, -0.10039259493350983, -0.09166151285171509, -0.08293043822050095, -0.07419935613870621, -0.06546828150749207, -0.05673719942569733, -0.04800611734390259, -0.039275042712688446, -0.030543960630893707, -0.021812885999679565, -0.013081803917884827, -0.004350721836090088, 0.004380360245704651, 0.013111427426338196, 0.021842509508132935, 0.030573591589927673, 0.03930467367172241, 0.04803575575351715, 0.05676683783531189, 0.06549790501594543, 0.07422898709774017, 0.08296006917953491, 0.09169115126132965, 0.10042223334312439, 0.10915330052375793, 0.11788439750671387, 0.1266154646873474, 0.13534653186798096, 0.1440776288509369, 0.15280869603157043, 0.16153979301452637, 0.1702708601951599, 0.17900192737579346, 0.1877330243587494, 0.19646409153938293, 0.20519518852233887, 0.2139262557029724, 0.22265732288360596, 0.2313884198665619, 0.24011948704719543, 0.24885058403015137, 0.2575816512107849, 0.26631274819374084, 0.2750438153743744, 0.28377488255500793, 0.29250597953796387, 0.3012370467185974, 0.30996814370155334, 0.3186992108821869, 0.32743027806282043, 0.33616137504577637, 0.3448924422264099, 0.35362353920936584, 0.3623546063899994, 0.37108567357063293, 0.3798167407512665, 0.3885478675365448, 0.39727893471717834, 0.4060100018978119]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.36548519134521484, -0.34746086597442627, -0.3294365406036377, -0.3114122152328491, -0.29338788986206055, -0.275363564491272, -0.2573392391204834, -0.23931491374969482, -0.22129058837890625, -0.20326626300811768, -0.1852419376373291, -0.16721761226654053, -0.14919328689575195, -0.13116896152496338, -0.1131446361541748, -0.09512031078338623, -0.07709598541259766, -0.05907166004180908, -0.04104733467102051, -0.023023009300231934, -0.004998683929443359, 0.013025641441345215, 0.03104996681213379, 0.04907429218292236, 0.06709861755371094, 0.08512294292449951, 0.10314726829528809, 0.12117159366607666, 0.13919591903686523, 0.1572202444076538, 0.17524456977844238, 0.19326889514923096, 0.21129322052001953, 0.2293175458908081, 0.24734187126159668, 0.26536619663238525, 0.28339052200317383, 0.3014148473739624, 0.319439172744751, 0.33746349811553955, 0.3554878234863281, 0.3735121488571167, 0.3915364742279053, 0.40956079959869385, 0.4275851249694824, 0.445609450340271, 0.46363377571105957, 0.48165810108184814, 0.4996824264526367, 0.5177067518234253, 0.5357310771942139, 0.5537554025650024, 0.571779727935791, 0.5898040533065796, 0.6078283786773682, 0.6258527040481567, 0.6438770294189453, 0.6619013547897339, 0.6799256801605225, 0.697950005531311, 0.7159743309020996, 0.7339986562728882, 0.7520229816436768, 0.7700473070144653, 0.7880716323852539]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 3.0, 4.0, 13.0, 4.0, 3.0, 5.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5253642797470093, -0.5126793384552002, -0.4999944269657135, -0.4873095154762268, -0.4746246039867401, -0.46193966269493103, -0.44925475120544434, -0.43656980991363525, -0.42388489842414856, -0.41119998693466187, -0.3985150456428528, -0.3858301341533661, -0.3731452226638794, -0.3604602813720703, -0.3477753698825836, -0.3350904583930969, -0.32240551710128784, -0.30972060561180115, -0.29703569412231445, -0.28435075283050537, -0.2716658413410187, -0.258980929851532, -0.2462959885597229, -0.2336110770702362, -0.2209261655807495, -0.20824122428894043, -0.19555631279945374, -0.18287140130996704, -0.17018646001815796, -0.15750154852867126, -0.14481663703918457, -0.1321316957473755, -0.1194467842578888, -0.1067618727684021, -0.09407693147659302, -0.08139201998710632, -0.06870710849761963, -0.05602216720581055, -0.04333725571632385, -0.030652344226837158, -0.017967402935028076, -0.005282461643218994, 0.0074024200439453125, 0.020087361335754395, 0.03277230262756348, 0.04545718431472778, 0.058142125606536865, 0.07082706689834595, 0.08351194858551025, 0.09619688987731934, 0.10888183116912842, 0.12156671285629272, 0.1342516541481018, 0.1469365954399109, 0.1596214771270752, 0.17230641841888428, 0.18499135971069336, 0.19767624139785767, 0.21036118268966675, 0.22304612398147583, 0.23573100566864014, 0.24841594696044922, 0.2611008882522583, 0.2737857699394226, 0.2864707112312317]}, "_runtime": 18524.232994556427, "_timestamp": 1585615893.865864, "_step": 198}
{"Episode reward": 67.19999999999982, "Episode length": 328, "Policy Loss": 2.0451910495758057, "Value Loss": 29.972248077392578, "_runtime": 18525.746930599213, "_timestamp": 1585615895.3798, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7597947120666504, "Value Loss": 0.07350803166627884, "_runtime": 18527.30528497696, "_timestamp": 1585615896.9381545, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9130355715751648, "Value Loss": 0.13193441927433014, "_runtime": 18528.81364297867, "_timestamp": 1585615898.4465125, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8226339221000671, "Value Loss": 0.028072714805603027, "_runtime": 18530.385617256165, "_timestamp": 1585615900.0184867, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9180474877357483, "Value Loss": 0.24357254803180695, "_runtime": 18531.952003240585, "_timestamp": 1585615901.5848727, "_step": 203}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": -0.04732759669423103, "Value Loss": 9.997964859008789, "_runtime": 18532.755651950836, "_timestamp": 1585615902.3885214, "_step": 204}
{"Episode reward": 49.98653525710063, "Episode length": 501, "Policy Loss": 0.9990319609642029, "Value Loss": 19.572893142700195, "_runtime": 18533.287930965424, "_timestamp": 1585615902.9208004, "_step": 205}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": 2.1098732948303223, "Value Loss": 30.27210807800293, "_runtime": 18534.84260082245, "_timestamp": 1585615904.4754703, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7816712856292725, "Value Loss": 0.03919535130262375, "_runtime": 18535.217916965485, "_timestamp": 1585615904.8507864, "_step": 207}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": 2.952216863632202, "Value Loss": 43.771324157714844, "_runtime": 18536.72097635269, "_timestamp": 1585615906.3538458, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.895763635635376, "Value Loss": 0.04206869378685951, "_runtime": 18538.28534603119, "_timestamp": 1585615907.9182155, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9777485132217407, "Value Loss": 0.12358587235212326, "_runtime": 18539.78204369545, "_timestamp": 1585615909.4149132, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0012531280517578, "Value Loss": 0.24426516890525818, "_runtime": 18540.90180492401, "_timestamp": 1585615910.5346744, "_step": 211}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 0.2056366354227066, "Value Loss": 13.835533142089844, "_runtime": 18542.509881019592, "_timestamp": 1585615912.1427505, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9987660050392151, "Value Loss": 0.09543436765670776, "_runtime": 18544.054264307022, "_timestamp": 1585615913.6871338, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9347313642501831, "Value Loss": 0.025177080184221268, "_runtime": 18544.842609643936, "_timestamp": 1585615914.4754791, "_step": 214}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 0.8262192010879517, "Value Loss": 19.278228759765625, "_runtime": 18545.754774570465, "_timestamp": 1585615915.387644, "_step": 215}
{"Episode reward": 42.799999999999464, "Episode length": 572, "Policy Loss": 0.5298990607261658, "Value Loss": 17.056377410888672, "_runtime": 18547.290707826614, "_timestamp": 1585615916.9235773, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1025193929672241, "Value Loss": 0.29817327857017517, "_runtime": 18548.831639528275, "_timestamp": 1585615918.464509, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9652757048606873, "Value Loss": 0.0469982735812664, "_runtime": 18550.357378721237, "_timestamp": 1585615919.9902482, "_step": 218}
{"Episode reward": -99.89651527404645, "Episode length": 999, "Policy Loss": -1.0277667045593262, "Value Loss": 0.2556189298629761, "_runtime": 18550.881321191788, "_timestamp": 1585615920.5141907, "_step": 219}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 1.971773624420166, "Value Loss": 31.514257431030273, "_runtime": 18552.42596554756, "_timestamp": 1585615922.058835, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9056997299194336, "Value Loss": 0.03306068107485771, "_runtime": 18553.99741959572, "_timestamp": 1585615923.630289, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9060463309288025, "Value Loss": 0.04502878710627556, "_runtime": 18555.508702516556, "_timestamp": 1585615925.141572, "_step": 222}
{"Episode reward": -99.80207483768324, "Episode length": 999, "Policy Loss": -0.8902849555015564, "Value Loss": 0.07758377492427826, "_runtime": 18557.075319767, "_timestamp": 1585615926.7081892, "_step": 223}
{"Episode reward": -99.88032465576985, "Episode length": 999, "Policy Loss": -0.8197544813156128, "Value Loss": 0.03638145700097084, "_runtime": 18558.653193473816, "_timestamp": 1585615928.286063, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7946431636810303, "Value Loss": 0.051432184875011444, "_runtime": 18560.113031864166, "_timestamp": 1585615929.7459013, "_step": 225}
{"Episode reward": 6.600000000001032, "Episode length": 934, "Policy Loss": 0.09885178506374359, "Value Loss": 10.593374252319336, "_runtime": 18561.69596338272, "_timestamp": 1585615931.3288329, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7826796770095825, "Value Loss": 0.015752378851175308, "_runtime": 18563.27823114395, "_timestamp": 1585615932.9111006, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7162895798683167, "Value Loss": 0.023601146414875984, "_runtime": 18564.84181380272, "_timestamp": 1585615934.4746833, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7014732360839844, "Value Loss": 0.03224152699112892, "_runtime": 18566.45279932022, "_timestamp": 1585615936.0856688, "_step": 229}
{"Episode reward": -99.83080846220115, "Episode length": 999, "Policy Loss": -0.6629055142402649, "Value Loss": 0.013644604943692684, "_runtime": 18568.023889541626, "_timestamp": 1585615937.656759, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6476386189460754, "Value Loss": 0.017906231805682182, "_runtime": 18569.59659099579, "_timestamp": 1585615939.2294605, "_step": 231}
{"Episode reward": -99.87469415664533, "Episode length": 999, "Policy Loss": -0.6098257899284363, "Value Loss": 0.01048118807375431, "_runtime": 18571.13331580162, "_timestamp": 1585615940.7661853, "_step": 232}
{"Episode reward": 2.4000000000012705, "Episode length": 976, "Policy Loss": 0.3040056526660919, "Value Loss": 10.143532752990723, "_runtime": 18572.536735534668, "_timestamp": 1585615942.169605, "_step": 233}
{"Episode reward": 11.600000000000747, "Episode length": 884, "Policy Loss": 0.4201289415359497, "Value Loss": 11.176139831542969, "_runtime": 18573.663309812546, "_timestamp": 1585615943.2961793, "_step": 234}
{"Episode reward": 28.71070765107848, "Episode length": 713, "Policy Loss": 0.7641414999961853, "Value Loss": 13.8424711227417, "_runtime": 18575.24022912979, "_timestamp": 1585615944.8730986, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.543999969959259, "Value Loss": 0.01493541244417429, "_runtime": 18576.545866966248, "_timestamp": 1585615946.1787364, "_step": 236}
{"Episode reward": 16.90116844177291, "Episode length": 831, "Policy Loss": 0.5157138705253601, "Value Loss": 11.862663269042969, "_runtime": 18578.099774837494, "_timestamp": 1585615947.7326443, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5408294796943665, "Value Loss": 0.010944238863885403, "_runtime": 18578.72478365898, "_timestamp": 1585615948.3576531, "_step": 238}
{"Episode reward": 62.419932238664224, "Episode length": 376, "Policy Loss": 1.765206217765808, "Value Loss": 26.216266632080078, "_runtime": 18580.273869276047, "_timestamp": 1585615949.9067388, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5635557770729065, "Value Loss": 0.013138039968907833, "_runtime": 18581.850467920303, "_timestamp": 1585615951.4833374, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5485469698905945, "Value Loss": 0.007957423105835915, "_runtime": 18583.36844062805, "_timestamp": 1585615953.00131, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5570436120033264, "Value Loss": 0.01684224233031273, "_runtime": 18584.949369430542, "_timestamp": 1585615954.582239, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6263328790664673, "Value Loss": 0.08930397778749466, "_runtime": 18586.51553797722, "_timestamp": 1585615956.1484075, "_step": 243}
{"Episode reward": -99.7159968674169, "Episode length": 999, "Policy Loss": -0.5616136789321899, "Value Loss": 0.013299311511218548, "_runtime": 18587.621334314346, "_timestamp": 1585615957.2542038, "_step": 244}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": 0.6584180593490601, "Value Loss": 14.009765625, "_runtime": 18588.89758992195, "_timestamp": 1585615958.5304594, "_step": 245}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.535064697265625, "Value Loss": 12.596822738647461, "_runtime": 18590.475390195847, "_timestamp": 1585615960.1082597, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5707152485847473, "Value Loss": 0.013956978917121887, "_runtime": 18592.01569390297, "_timestamp": 1585615961.6485634, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6046102643013, "Value Loss": 0.05062704160809517, "_runtime": 18593.57714319229, "_timestamp": 1585615963.2100127, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5995187163352966, "Value Loss": 0.018841631710529327, "_runtime": 18594.924632549286, "_timestamp": 1585615964.557502, "_step": 249}
{"Episode reward": 14.40700185298978, "Episode length": 856, "Policy Loss": 0.4382791817188263, "Value Loss": 11.46309757232666, "_runtime": 18596.109632253647, "_timestamp": 1585615965.7425017, "_step": 250}
{"Episode reward": 24.60000000000001, "Episode length": 754, "Policy Loss": 0.5123119354248047, "Value Loss": 13.053028106689453, "_runtime": 18597.68865442276, "_timestamp": 1585615967.321524, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6586352586746216, "Value Loss": 0.06424739211797714, "_runtime": 18599.260105848312, "_timestamp": 1585615968.8929753, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6421874165534973, "Value Loss": 0.06547754257917404, "_runtime": 18600.80685520172, "_timestamp": 1585615970.4397247, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6052596569061279, "Value Loss": 0.009787971153855324, "_runtime": 18602.37951683998, "_timestamp": 1585615972.0123863, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7026973962783813, "Value Loss": 0.13393859565258026, "_runtime": 18603.26117491722, "_timestamp": 1585615972.8940444, "_step": 255}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 0.9918915033340454, "Value Loss": 17.781112670898438, "_runtime": 18604.6392891407, "_timestamp": 1585615974.2721586, "_step": 256}
{"Episode reward": 12.299971622229336, "Episode length": 878, "Policy Loss": 0.38012710213661194, "Value Loss": 11.179555892944336, "_runtime": 18606.201643705368, "_timestamp": 1585615975.8345132, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5855206251144409, "Value Loss": 0.023613935336470604, "_runtime": 18607.22257399559, "_timestamp": 1585615976.8554435, "_step": 258}
{"Episode reward": 33.69999999999949, "Episode length": 663, "Policy Loss": 0.6537804007530212, "Value Loss": 14.865448951721191, "_runtime": 18608.775613069534, "_timestamp": 1585615978.4084826, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5951617360115051, "Value Loss": 0.033616628497838974, "_runtime": 18610.372330904007, "_timestamp": 1585615980.0052004, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6243532299995422, "Value Loss": 0.02816872112452984, "_runtime": 18611.91067481041, "_timestamp": 1585615981.5435443, "_step": 261}
{"Episode reward": -99.80546459108452, "Episode length": 999, "Policy Loss": -0.5775856375694275, "Value Loss": 0.005580664146691561, "_runtime": 18613.515991926193, "_timestamp": 1585615983.1488614, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6051508188247681, "Value Loss": 0.03388204053044319, "_runtime": 18614.007314920425, "_timestamp": 1585615983.6401844, "_step": 263}
{"Episode reward": 70.99999999999986, "Episode length": 290, "Policy Loss": 2.7367751598358154, "Value Loss": 33.75762176513672, "_runtime": 18615.57450389862, "_timestamp": 1585615985.2073734, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5775269269943237, "Value Loss": 0.03027043677866459, "_runtime": 18617.107449293137, "_timestamp": 1585615986.7403188, "_step": 265}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": 0.26933470368385315, "Value Loss": 9.988006591796875, "_runtime": 18618.607268810272, "_timestamp": 1585615988.2401383, "_step": 266}
{"Episode reward": -99.8186471734182, "Episode length": 999, "Policy Loss": -0.6663945913314819, "Value Loss": 0.08029889315366745, "_runtime": 18620.17355823517, "_timestamp": 1585615989.8064277, "_step": 267}
{"Episode reward": -99.81571998596051, "Episode length": 999, "Policy Loss": -0.6789851188659668, "Value Loss": 0.1061331108212471, "_runtime": 18621.742292642593, "_timestamp": 1585615991.3751621, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6056780815124512, "Value Loss": 0.026107389479875565, "_runtime": 18623.29526233673, "_timestamp": 1585615992.9281318, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6104521751403809, "Value Loss": 0.024558670818805695, "_runtime": 18624.226969242096, "_timestamp": 1585615993.8598387, "_step": 270}
{"Episode reward": 41.29999999999944, "Episode length": 587, "Policy Loss": 0.7963007092475891, "Value Loss": 16.726810455322266, "_runtime": 18625.79603409767, "_timestamp": 1585615995.4289036, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6874979138374329, "Value Loss": 0.0769413411617279, "_runtime": 18627.34632253647, "_timestamp": 1585615996.979192, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5789263248443604, "Value Loss": 0.007756268605589867, "_runtime": 18628.246041059494, "_timestamp": 1585615997.8789105, "_step": 273}
{"Episode reward": 41.499999999999446, "Episode length": 585, "Policy Loss": 1.0289280414581299, "Value Loss": 16.710926055908203, "_runtime": 18629.81087422371, "_timestamp": 1585615999.4437437, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5608946084976196, "Value Loss": 0.013603072613477707, "_runtime": 18631.36303114891, "_timestamp": 1585616000.9959006, "_step": 275}
{"Episode reward": -99.88137837052206, "Episode length": 999, "Policy Loss": -0.6000059843063354, "Value Loss": 0.09523195773363113, "_runtime": 18632.62450027466, "_timestamp": 1585616002.2573698, "_step": 276}
{"Episode reward": 17.29637365341229, "Episode length": 828, "Policy Loss": 0.5494099259376526, "Value Loss": 11.840385437011719, "_runtime": 18634.193313360214, "_timestamp": 1585616003.8261828, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5630447268486023, "Value Loss": 0.007220253348350525, "_runtime": 18634.98311662674, "_timestamp": 1585616004.615986, "_step": 278}
{"Episode reward": 51.09010424464899, "Episode length": 490, "Policy Loss": 1.2268171310424805, "Value Loss": 19.945293426513672, "_runtime": 18636.569131612778, "_timestamp": 1585616006.202001, "_step": 279}
{"Episode reward": -99.82762919068198, "Episode length": 999, "Policy Loss": -0.5769844651222229, "Value Loss": 0.03262099623680115, "_runtime": 18638.15114068985, "_timestamp": 1585616007.7840102, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5883480906486511, "Value Loss": 0.015009869821369648, "_runtime": 18639.363223791122, "_timestamp": 1585616008.9960933, "_step": 281}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.534807026386261, "Value Loss": 12.292192459106445, "_runtime": 18640.93930888176, "_timestamp": 1585616010.5721784, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5748459696769714, "Value Loss": 0.02218755893409252, "_runtime": 18642.50980949402, "_timestamp": 1585616012.142679, "_step": 283}
{"Episode reward": -99.86307368874411, "Episode length": 999, "Policy Loss": -0.5685007572174072, "Value Loss": 0.018580235540866852, "_runtime": 18644.0426197052, "_timestamp": 1585616013.6754892, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.638103723526001, "Value Loss": 0.09581442922353745, "_runtime": 18645.616605758667, "_timestamp": 1585616015.2494752, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6036334037780762, "Value Loss": 0.025203077122569084, "_runtime": 18646.779895544052, "_timestamp": 1585616016.412765, "_step": 286}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.5869654417037964, "Value Loss": 13.301025390625, "_runtime": 18647.603383541107, "_timestamp": 1585616017.236253, "_step": 287}
{"Episode reward": 48.59999999999955, "Episode length": 514, "Policy Loss": 1.1757490634918213, "Value Loss": 18.955768585205078, "_runtime": 18648.410182237625, "_timestamp": 1585616018.0430517, "_step": 288}
{"Episode reward": 50.309352957829404, "Episode length": 497, "Policy Loss": 1.0046378374099731, "Value Loss": 19.83451271057129, "_runtime": 18649.123029708862, "_timestamp": 1585616018.7558992, "_step": 289}
{"Episode reward": 55.39999999999964, "Episode length": 446, "Policy Loss": 1.4100695848464966, "Value Loss": 21.863252639770508, "_runtime": 18650.653760671616, "_timestamp": 1585616020.2866302, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6413726210594177, "Value Loss": 0.018271010369062424, "_runtime": 18652.183344125748, "_timestamp": 1585616021.8162136, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6635538339614868, "Value Loss": 0.011671464890241623, "_runtime": 18653.708145856857, "_timestamp": 1585616023.3410153, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6998017430305481, "Value Loss": 0.027439935132861137, "_runtime": 18655.268449783325, "_timestamp": 1585616024.9013193, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.688330352306366, "Value Loss": 0.014501466415822506, "_runtime": 18656.62600183487, "_timestamp": 1585616026.2588713, "_step": 294}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": 0.24341189861297607, "Value Loss": 11.28929328918457, "_runtime": 18658.18182873726, "_timestamp": 1585616027.8146982, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7079588174819946, "Value Loss": 0.01581428386271, "_runtime": 18659.79748082161, "_timestamp": 1585616029.4303503, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7204329967498779, "Value Loss": 0.15209366381168365, "_runtime": 18660.687086343765, "_timestamp": 1585616030.3199558, "_step": 297}
{"Episode reward": 44.149387335776765, "Episode length": 559, "Policy Loss": 0.7688755393028259, "Value Loss": 17.409887313842773, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425, 0.001368666416965425]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.1442907452583313, -0.13807274401187897, -0.13185474276542664, -0.1256367415189743, -0.11941874027252197, -0.11320073902606964, -0.10698273777961731, -0.10076473653316498, -0.09454673528671265, -0.08832873404026031, -0.08211073279380798, -0.07589273154735565, -0.06967473030090332, -0.06345672905445099, -0.05723872780799866, -0.051020726561546326, -0.044802725315093994, -0.03858472406864166, -0.03236672282218933, -0.026148721575737, -0.019930720329284668, -0.013712719082832336, -0.007494717836380005, -0.0012767165899276733, 0.004941284656524658, 0.01115928590297699, 0.01737728714942932, 0.023595288395881653, 0.029813289642333984, 0.036031290888786316, 0.04224929213523865, 0.04846729338169098, 0.05468529462814331, 0.06090329587459564, 0.06712129712104797, 0.0733392983675003, 0.07955729961395264, 0.08577530086040497, 0.0919933021068573, 0.09821130335330963, 0.10442930459976196, 0.11064732074737549, 0.11686530709266663, 0.12308329343795776, 0.1293013095855713, 0.13551932573318481, 0.14173731207847595, 0.1479552984237671, 0.15417331457138062, 0.16039133071899414, 0.16660931706428528, 0.17282730340957642, 0.17904531955718994, 0.18526333570480347, 0.1914813220500946, 0.19769930839538574, 0.20391732454299927, 0.2101353406906128, 0.21635332703590393, 0.22257131338119507, 0.2287893295288086, 0.23500734567642212, 0.24122533202171326, 0.2474433183670044, 0.2536613345146179]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006151725072413683, -0.005875654052942991, -0.0055995830334723, -0.005323512014001608, -0.005047440994530916, -0.0047713699750602245, -0.00449529942125082, -0.0042192284017801285, -0.003943157382309437, -0.0036670861300081015, -0.0033910151105374098, -0.003114944091066718, -0.00283887330442667, -0.0025628022849559784, -0.0022867312654852867, -0.002010660246014595, -0.0017345892265439034, -0.0014585182070732117, -0.00118244718760252, -0.0009063761681318283, -0.0006303051486611366, -0.00035423412919044495, -7.816310971975327e-05, 0.00019790790975093842, 0.0004739784635603428, 0.0007500494830310345, 0.0010261205025017262, 0.0013021915219724178, 0.0015782625414431095, 0.0018543335609138012, 0.002130404580384493, 0.0024064755998551846, 0.0026825466193258762, 0.002958617638796568, 0.0032346886582672596, 0.0035107596777379513, 0.003786830697208643, 0.004062901716679335, 0.004338972736150026, 0.004615043755620718, 0.00489111477509141, 0.005167185794562101, 0.005443256814032793, 0.005719327833503485, 0.005995398852974176, 0.006271469872444868, 0.00654754089191556, 0.0068236119113862514, 0.0070996819995343685, 0.00737575301900506, 0.007651824038475752, 0.007927894592285156, 0.008203966543078423, 0.00848003663122654, 0.008756108582019806, 0.009032178670167923, 0.00930825062096119, 0.009584322571754456, 0.009860392659902573, 0.010136464610695839, 0.010412534698843956, 0.010688606649637222, 0.01096467673778534, 0.011240748688578606, 0.011516818776726723]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 5.0, 14.0, 5.0, 3.0, 16.0, 5.0, 0.0, 8.0, 307.0, 24.0, 14.0, 40.0, 37.0, 0.0, 2.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.044058658182621, -0.04250193014740944, -0.040945202112197876, -0.039388470351696014, -0.03783174231648445, -0.03627501428127289, -0.034718286246061325, -0.03316155821084976, -0.0316048301756382, -0.030048100277781487, -0.028491372242569923, -0.02693464420735836, -0.025377914309501648, -0.023821186274290085, -0.02226445823907852, -0.02070772834122181, -0.019151000306010246, -0.017594272270798683, -0.01603754237294197, -0.014480814337730408, -0.012924086302518845, -0.011367358267307281, -0.009810630232095718, -0.008253898471593857, -0.006697170436382294, -0.005140442401170731, -0.0035837143659591675, -0.0020269863307476044, -0.00047025829553604126, 0.0010864734649658203, 0.0026432015001773834, 0.0041999295353889465, 0.00575665757060051, 0.007313385605812073, 0.008870113641023636, 0.010426841676235199, 0.01198357343673706, 0.013540301471948624, 0.015097029507160187, 0.01665375754237175, 0.018210485577583313, 0.019767217338085175, 0.02132394164800644, 0.0228806734085083, 0.024437397718429565, 0.025994129478931427, 0.02755086123943329, 0.029107585549354553, 0.030664317309856415, 0.03222104161977768, 0.03377777338027954, 0.035334497690200806, 0.03689122945070267, 0.03844796121120453, 0.04000468552112579, 0.041561417281627655, 0.04311814159154892, 0.04467487335205078, 0.04623160511255264, 0.04778832942247391, 0.04934506118297577, 0.050901785492897034, 0.052458517253398895, 0.05401524156332016, 0.05557197332382202]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 6.0, 9.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.26841259002685547, -0.2592790424823761, -0.2501455247402191, -0.24101197719573975, -0.23187844455242157, -0.2227449119091034, -0.21361136436462402, -0.20447783172130585, -0.19534429907798767, -0.1862107515335083, -0.17707721889019012, -0.16794368624687195, -0.15881013870239258, -0.1496766060590744, -0.14054307341575623, -0.13140952587127686, -0.12227599322795868, -0.1131424605846405, -0.10400891304016113, -0.09487538039684296, -0.08574184775352478, -0.07660830020904541, -0.06747476756572723, -0.05834123492240906, -0.04920768737792969, -0.04007415473461151, -0.030940622091293335, -0.02180708944797516, -0.012673556804656982, -0.0035400092601776123, 0.005593538284301758, 0.01472705602645874, 0.02386060357093811, 0.03299415111541748, 0.04212766885757446, 0.05126121640205383, 0.0603947639465332, 0.06952828168869019, 0.07866182923316956, 0.08779537677764893, 0.09692889451980591, 0.10606244206428528, 0.11519598960876465, 0.12432950735092163, 0.133463054895401, 0.14259660243988037, 0.15173012018203735, 0.16086366772651672, 0.1699972152709961, 0.17913073301315308, 0.18826428055763245, 0.19739779829978943, 0.2065313458442688, 0.21566489338874817, 0.22479841113090515, 0.23393195867538452, 0.2430654764175415, 0.25219905376434326, 0.26133257150650024, 0.2704660892486572, 0.279599666595459, 0.28873318433761597, 0.29786670207977295, 0.3070002794265747, 0.3161337971687317]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 5.0, 19.0, 8.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11746051162481308, -0.11339250952005386, -0.10932449996471405, -0.10525649785995483, -0.10118849575519562, -0.0971204861998558, -0.09305248409509659, -0.08898447453975677, -0.08491647243499756, -0.08084847033023834, -0.07678046077489853, -0.07271245867013931, -0.0686444491147995, -0.06457644701004028, -0.06050844490528107, -0.05644043907523155, -0.05237243324518204, -0.04830443114042282, -0.04423642158508301, -0.04016841948032379, -0.03610040992498398, -0.03203240782022476, -0.027964405715465546, -0.023896396160125732, -0.019828394055366516, -0.0157603919506073, -0.011692382395267487, -0.00762438029050827, -0.003556378185749054, 0.0005116313695907593, 0.004579633474349976, 0.008647643029689789, 0.012715645134449005, 0.01678364723920822, 0.020851649343967438, 0.024919666349887848, 0.028987668454647064, 0.03305567055940628, 0.0371236726641655, 0.04119167476892471, 0.04525969177484512, 0.04932769387960434, 0.053395695984363556, 0.05746369808912277, 0.06153170019388199, 0.0655997022986412, 0.06966771930456161, 0.07373572140932083, 0.07780372351408005, 0.08187172561883926, 0.08593972772359848, 0.09000774472951889, 0.0940757468342781, 0.09814374893903732, 0.10221175104379654, 0.10627975314855576, 0.11034775525331497, 0.11441577225923538, 0.1184837743639946, 0.12255177646875381, 0.12661978602409363, 0.13068777322769165, 0.13475579023361206, 0.13882377743721008, 0.1428917944431305]}, "_runtime": 18662.246739387512, "_timestamp": 1585616031.8796089, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7040664553642273, "Value Loss": 0.015202413313090801, "_runtime": 18662.844578266144, "_timestamp": 1585616032.4774477, "_step": 299}
{"Episode reward": 64.49999999999977, "Episode length": 355, "Policy Loss": 1.7426831722259521, "Value Loss": 27.217283248901367, "_runtime": 18663.60534596443, "_timestamp": 1585616033.2382154, "_step": 300}
{"Episode reward": 50.881881426274354, "Episode length": 492, "Policy Loss": 1.4118260145187378, "Value Loss": 19.82736587524414, "_runtime": 18665.171357393265, "_timestamp": 1585616034.8042269, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7407186031341553, "Value Loss": 0.0176760982722044, "_runtime": 18665.646575689316, "_timestamp": 1585616035.2794452, "_step": 302}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": 2.3439760208129883, "Value Loss": 31.480335235595703, "_runtime": 18667.161137104034, "_timestamp": 1585616036.7940066, "_step": 303}
{"Episode reward": -99.86114965081075, "Episode length": 999, "Policy Loss": -0.8581149578094482, "Value Loss": 0.15553532540798187, "_runtime": 18668.737320661545, "_timestamp": 1585616038.3701901, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8090305328369141, "Value Loss": 0.04075092822313309, "_runtime": 18669.243854522705, "_timestamp": 1585616038.876724, "_step": 305}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 1.8281244039535522, "Value Loss": 30.152023315429688, "_runtime": 18670.80824136734, "_timestamp": 1585616040.4411108, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8938465118408203, "Value Loss": 0.46937647461891174, "_runtime": 18672.39599084854, "_timestamp": 1585616042.0288603, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8004604578018188, "Value Loss": 0.1236158162355423, "_runtime": 18673.910842180252, "_timestamp": 1585616043.5437117, "_step": 308}
{"Episode reward": -99.83798663765053, "Episode length": 999, "Policy Loss": -0.9924150705337524, "Value Loss": 0.5360763669013977, "_runtime": 18675.488624095917, "_timestamp": 1585616045.1214936, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8216636776924133, "Value Loss": 0.20319150388240814, "_runtime": 18676.00308084488, "_timestamp": 1585616045.6359503, "_step": 310}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 1.9969598054885864, "Value Loss": 32.56217575073242, "_runtime": 18677.56910967827, "_timestamp": 1585616047.2019792, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8258370161056519, "Value Loss": 0.044409893453121185, "_runtime": 18679.158488035202, "_timestamp": 1585616048.7913575, "_step": 312}
{"Episode reward": -99.82832651138166, "Episode length": 999, "Policy Loss": -0.8157036900520325, "Value Loss": 0.01829608716070652, "_runtime": 18679.986360788345, "_timestamp": 1585616049.6192303, "_step": 313}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 0.6629912257194519, "Value Loss": 18.19446563720703, "_runtime": 18681.476018428802, "_timestamp": 1585616051.108888, "_step": 314}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": 0.09455361217260361, "Value Loss": 10.401264190673828, "_runtime": 18683.058149576187, "_timestamp": 1585616052.691019, "_step": 315}
{"Episode reward": -99.80139627456525, "Episode length": 999, "Policy Loss": -0.8114109635353088, "Value Loss": 0.04506698250770569, "_runtime": 18684.61867594719, "_timestamp": 1585616054.2515454, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7949146628379822, "Value Loss": 0.021596284583210945, "_runtime": 18686.18629550934, "_timestamp": 1585616055.819165, "_step": 317}
{"Episode reward": -99.87893038391927, "Episode length": 999, "Policy Loss": -0.8043568134307861, "Value Loss": 0.053098540753126144, "_runtime": 18687.757446050644, "_timestamp": 1585616057.3903155, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7686424851417542, "Value Loss": 0.012898512184619904, "_runtime": 18688.611240386963, "_timestamp": 1585616058.2441099, "_step": 319}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": 1.1405929327011108, "Value Loss": 18.204404830932617, "_runtime": 18689.28178882599, "_timestamp": 1585616058.9146583, "_step": 320}
{"Episode reward": 59.092509835958175, "Episode length": 410, "Policy Loss": 1.2721856832504272, "Value Loss": 23.957019805908203, "_runtime": 18690.74221944809, "_timestamp": 1585616060.375089, "_step": 321}
{"Episode reward": 7.100000000001003, "Episode length": 929, "Policy Loss": 0.2966599762439728, "Value Loss": 10.538289070129395, "_runtime": 18692.26651787758, "_timestamp": 1585616061.8993874, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7468655109405518, "Value Loss": 0.03611014783382416, "_runtime": 18693.780874490738, "_timestamp": 1585616063.413744, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7460445165634155, "Value Loss": 0.014244213700294495, "_runtime": 18694.94881081581, "_timestamp": 1585616064.5816803, "_step": 324}
{"Episode reward": 25.79999999999994, "Episode length": 742, "Policy Loss": 0.6689894199371338, "Value Loss": 13.224451065063477, "_runtime": 18695.58815050125, "_timestamp": 1585616065.22102, "_step": 325}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 1.4164782762527466, "Value Loss": 24.202953338623047, "_runtime": 18697.12766814232, "_timestamp": 1585616066.7605376, "_step": 326}
{"Episode reward": -99.84169955849508, "Episode length": 999, "Policy Loss": -0.8020964860916138, "Value Loss": 0.26831015944480896, "_runtime": 18698.18580889702, "_timestamp": 1585616067.8186784, "_step": 327}
{"Episode reward": 32.65347001552537, "Episode length": 674, "Policy Loss": 0.5103108882904053, "Value Loss": 14.73886489868164, "_runtime": 18698.666673898697, "_timestamp": 1585616068.2995434, "_step": 328}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": 3.233414649963379, "Value Loss": 32.1884880065918, "_runtime": 18700.207676887512, "_timestamp": 1585616069.8405464, "_step": 329}
{"Episode reward": -99.83323961645225, "Episode length": 999, "Policy Loss": -0.6786279082298279, "Value Loss": 0.025871872901916504, "_runtime": 18701.422057151794, "_timestamp": 1585616071.0549266, "_step": 330}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.3586205542087555, "Value Loss": 12.45419692993164, "_runtime": 18702.703230381012, "_timestamp": 1585616072.3360999, "_step": 331}
{"Episode reward": 14.400000000000588, "Episode length": 856, "Policy Loss": 0.24821579456329346, "Value Loss": 11.364630699157715, "_runtime": 18704.262989521027, "_timestamp": 1585616073.895859, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7167952656745911, "Value Loss": 0.020696861669421196, "_runtime": 18705.81604361534, "_timestamp": 1585616075.448913, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7267047762870789, "Value Loss": 0.04808446392416954, "_runtime": 18707.389720916748, "_timestamp": 1585616077.0225904, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7332955002784729, "Value Loss": 0.07438383996486664, "_runtime": 18708.966561317444, "_timestamp": 1585616078.5994308, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7121934294700623, "Value Loss": 0.03283776715397835, "_runtime": 18710.539086818695, "_timestamp": 1585616080.1719563, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7392261028289795, "Value Loss": 0.011339415796101093, "_runtime": 18712.09493994713, "_timestamp": 1585616081.7278094, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8283210396766663, "Value Loss": 0.10082903504371643, "_runtime": 18713.130274772644, "_timestamp": 1585616082.7631443, "_step": 338}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.5504170656204224, "Value Loss": 15.03610897064209, "_runtime": 18714.171122550964, "_timestamp": 1585616083.803992, "_step": 339}
{"Episode reward": 34.699999999999434, "Episode length": 653, "Policy Loss": 0.5239217281341553, "Value Loss": 15.027386665344238, "_runtime": 18714.81911635399, "_timestamp": 1585616084.4519858, "_step": 340}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 1.46808660030365, "Value Loss": 23.970552444458008, "_runtime": 18716.342249393463, "_timestamp": 1585616085.9751189, "_step": 341}
{"Episode reward": 1.8996982514871235, "Episode length": 982, "Policy Loss": 0.2659303843975067, "Value Loss": 9.904314994812012, "_runtime": 18717.474665880203, "_timestamp": 1585616087.1075354, "_step": 342}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.6846799850463867, "Value Loss": 13.451872825622559, "_runtime": 18718.996195077896, "_timestamp": 1585616088.6290646, "_step": 343}
{"Episode reward": -99.8765624999986, "Episode length": 999, "Policy Loss": -0.7787362933158875, "Value Loss": 0.012796049937605858, "_runtime": 18719.904189109802, "_timestamp": 1585616089.5370586, "_step": 344}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 0.6235825419425964, "Value Loss": 17.345134735107422, "_runtime": 18721.46646976471, "_timestamp": 1585616091.0993392, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8391693830490112, "Value Loss": 0.026715999469161034, "_runtime": 18722.475080251694, "_timestamp": 1585616092.1079497, "_step": 346}
{"Episode reward": 35.899999999999366, "Episode length": 641, "Policy Loss": 0.5049191117286682, "Value Loss": 15.241509437561035, "_runtime": 18723.999337911606, "_timestamp": 1585616093.6322074, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9851795434951782, "Value Loss": 0.3675636351108551, "_runtime": 18725.564024925232, "_timestamp": 1585616095.1968944, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8733626008033752, "Value Loss": 0.015468154102563858, "_runtime": 18726.81249642372, "_timestamp": 1585616096.445366, "_step": 349}
{"Episode reward": 18.60000000000035, "Episode length": 814, "Policy Loss": 0.12162216752767563, "Value Loss": 12.038081169128418, "_runtime": 18728.37405180931, "_timestamp": 1585616098.0069213, "_step": 350}
{"Episode reward": -99.80051519870618, "Episode length": 999, "Policy Loss": -0.921703040599823, "Value Loss": 0.2189500480890274, "_runtime": 18729.943664312363, "_timestamp": 1585616099.5765338, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8715810179710388, "Value Loss": 0.09445273131132126, "_runtime": 18730.98106598854, "_timestamp": 1585616100.6139355, "_step": 352}
{"Episode reward": 33.299999999999514, "Episode length": 667, "Policy Loss": 0.654686450958252, "Value Loss": 14.623673439025879, "_runtime": 18732.546194791794, "_timestamp": 1585616102.1790643, "_step": 353}
{"Episode reward": -99.8005257666097, "Episode length": 999, "Policy Loss": -0.8169837594032288, "Value Loss": 0.05415800213813782, "_runtime": 18733.33080482483, "_timestamp": 1585616102.9636743, "_step": 354}
{"Episode reward": 51.64841001033742, "Episode length": 484, "Policy Loss": 1.1447032690048218, "Value Loss": 20.16275978088379, "_runtime": 18734.87570977211, "_timestamp": 1585616104.5085793, "_step": 355}
{"Episode reward": -99.80149608254293, "Episode length": 999, "Policy Loss": -0.7234991788864136, "Value Loss": 0.01970113068819046, "_runtime": 18736.39013671875, "_timestamp": 1585616106.0230062, "_step": 356}
{"Episode reward": 2.5000000000012648, "Episode length": 975, "Policy Loss": 0.1765798181295395, "Value Loss": 9.987935066223145, "_runtime": 18736.964822769165, "_timestamp": 1585616106.5976923, "_step": 357}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.5372954607009888, "Value Loss": 26.52192497253418, "_runtime": 18738.564900159836, "_timestamp": 1585616108.1977696, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6953649520874023, "Value Loss": 0.010464899241924286, "_runtime": 18740.11750459671, "_timestamp": 1585616109.750374, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7043164968490601, "Value Loss": 0.02479233779013157, "_runtime": 18741.624933958054, "_timestamp": 1585616111.2578034, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6837444305419922, "Value Loss": 0.016551654785871506, "_runtime": 18742.428261756897, "_timestamp": 1585616112.0611312, "_step": 361}
{"Episode reward": 49.59999999999956, "Episode length": 504, "Policy Loss": 0.8978703022003174, "Value Loss": 19.428756713867188, "_runtime": 18743.99149942398, "_timestamp": 1585616113.624369, "_step": 362}
{"Episode reward": -99.81620770096639, "Episode length": 999, "Policy Loss": -0.7391222715377808, "Value Loss": 0.147731751203537, "_runtime": 18744.507292747498, "_timestamp": 1585616114.1401622, "_step": 363}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": 2.6288063526153564, "Value Loss": 31.235301971435547, "_runtime": 18746.03633904457, "_timestamp": 1585616115.6692085, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.675821840763092, "Value Loss": 0.03566230088472366, "_runtime": 18747.033932447433, "_timestamp": 1585616116.666802, "_step": 365}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.6734912991523743, "Value Loss": 15.331871032714844, "_runtime": 18748.53106737137, "_timestamp": 1585616118.1639369, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7089645266532898, "Value Loss": 0.014950178563594818, "_runtime": 18750.09540295601, "_timestamp": 1585616119.7282724, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.725503146648407, "Value Loss": 0.011714770458638668, "_runtime": 18751.2985765934, "_timestamp": 1585616120.931446, "_step": 368}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.351588636636734, "Value Loss": 12.387345314025879, "_runtime": 18752.854428052902, "_timestamp": 1585616122.4872975, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7773526906967163, "Value Loss": 0.1932021528482437, "_runtime": 18754.406909942627, "_timestamp": 1585616124.0397794, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8066398501396179, "Value Loss": 0.08000113815069199, "_runtime": 18755.948789834976, "_timestamp": 1585616125.5816593, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7873534560203552, "Value Loss": 0.0965152159333229, "_runtime": 18757.02484869957, "_timestamp": 1585616126.6577182, "_step": 372}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.46928149461746216, "Value Loss": 14.144779205322266, "_runtime": 18758.590530872345, "_timestamp": 1585616128.2234004, "_step": 373}
{"Episode reward": -99.82358031868795, "Episode length": 999, "Policy Loss": -0.7490413188934326, "Value Loss": 0.03421658277511597, "_runtime": 18759.609818935394, "_timestamp": 1585616129.2426884, "_step": 374}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": 0.5548673868179321, "Value Loss": 14.916986465454102, "_runtime": 18761.17707014084, "_timestamp": 1585616130.8099396, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.725686252117157, "Value Loss": 0.012423320673406124, "_runtime": 18762.746483564377, "_timestamp": 1585616132.379353, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7399918437004089, "Value Loss": 0.026290085166692734, "_runtime": 18764.27658224106, "_timestamp": 1585616133.9094517, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7148163318634033, "Value Loss": 0.008957505226135254, "_runtime": 18765.82825779915, "_timestamp": 1585616135.4611273, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7041400074958801, "Value Loss": 0.009977522306144238, "_runtime": 18767.39757490158, "_timestamp": 1585616137.0304444, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6817771196365356, "Value Loss": 0.0302615687251091, "_runtime": 18768.20827484131, "_timestamp": 1585616137.8411443, "_step": 380}
{"Episode reward": 48.79999999999955, "Episode length": 512, "Policy Loss": 0.9164168834686279, "Value Loss": 19.082958221435547, "_runtime": 18769.775010824203, "_timestamp": 1585616139.4078803, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6418680548667908, "Value Loss": 0.009716336615383625, "_runtime": 18770.422727823257, "_timestamp": 1585616140.0555973, "_step": 382}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 1.4182814359664917, "Value Loss": 24.29813575744629, "_runtime": 18771.95510482788, "_timestamp": 1585616141.5879743, "_step": 383}
{"Episode reward": -99.80041769295791, "Episode length": 999, "Policy Loss": -0.6226356625556946, "Value Loss": 0.04422266408801079, "_runtime": 18772.95454788208, "_timestamp": 1585616142.5874174, "_step": 384}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.6434414386749268, "Value Loss": 15.405674934387207, "_runtime": 18774.46399974823, "_timestamp": 1585616144.0968692, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7327327132225037, "Value Loss": 0.26408305764198303, "_runtime": 18776.033391952515, "_timestamp": 1585616145.6662614, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6247664093971252, "Value Loss": 0.047343116253614426, "_runtime": 18777.572080135345, "_timestamp": 1585616147.2049496, "_step": 387}
{"Episode reward": -99.8988801062093, "Episode length": 999, "Policy Loss": -0.5763536095619202, "Value Loss": 0.0375482551753521, "_runtime": 18779.141825437546, "_timestamp": 1585616148.774695, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.61334627866745, "Value Loss": 0.1501321792602539, "_runtime": 18780.640000343323, "_timestamp": 1585616150.2728698, "_step": 389}
{"Episode reward": 4.900000000001128, "Episode length": 951, "Policy Loss": 0.2948835790157318, "Value Loss": 10.239017486572266, "_runtime": 18782.21298599243, "_timestamp": 1585616151.8458555, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.538950502872467, "Value Loss": 0.0043711233884096146, "_runtime": 18783.074688911438, "_timestamp": 1585616152.7075584, "_step": 391}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 1.0620330572128296, "Value Loss": 18.116918563842773, "_runtime": 18784.684376239777, "_timestamp": 1585616154.3172457, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5161972045898438, "Value Loss": 0.024717405438423157, "_runtime": 18786.199342250824, "_timestamp": 1585616155.8322117, "_step": 393}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": 0.4811161458492279, "Value Loss": 10.187129974365234, "_runtime": 18787.125110387802, "_timestamp": 1585616156.7579799, "_step": 394}
{"Episode reward": 40.89999999999944, "Episode length": 591, "Policy Loss": 0.8980597257614136, "Value Loss": 16.49921989440918, "_runtime": 18787.63759827614, "_timestamp": 1585616157.2704678, "_step": 395}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 2.421659469604492, "Value Loss": 32.26697540283203, "_runtime": 18789.195856571198, "_timestamp": 1585616158.828726, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6057729721069336, "Value Loss": 0.0587480366230011, "_runtime": 18790.72376394272, "_timestamp": 1585616160.3566334, "_step": 397}
{"Episode reward": -99.85786358155171, "Episode length": 999, "Policy Loss": -0.6444036364555359, "Value Loss": 0.15924040973186493, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002, -0.2968590259552002]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-42.62541198730469, -41.95195388793945, -41.27849197387695, -40.60503387451172, -39.93157196044922, -39.258113861083984, -38.58465576171875, -37.91119384765625, -37.237735748291016, -36.56427764892578, -35.89081573486328, -35.21735763549805, -34.54389953613281, -33.87043762207031, -33.19697952270508, -32.523521423339844, -31.850059509277344, -31.176599502563477, -30.50313949584961, -29.829681396484375, -29.156221389770508, -28.48276138305664, -27.809303283691406, -27.13584327697754, -26.462383270263672, -25.788923263549805, -25.115463256835938, -24.442005157470703, -23.768545150756836, -23.09508514404297, -22.421627044677734, -21.748167037963867, -21.07470703125, -20.401247024536133, -19.727787017822266, -19.05432891845703, -18.380868911743164, -17.707408905029297, -17.033950805664062, -16.360490798950195, -15.687030792236328, -15.013570785522461, -14.340110778808594, -13.66665267944336, -12.993192672729492, -12.319732666015625, -11.64627456665039, -10.972814559936523, -10.299354553222656, -9.625896453857422, -8.952434539794922, -8.278976440429688, -7.6055145263671875, -6.932056427001953, -6.258598327636719, -5.585136413574219, -4.911678314208984, -4.23822021484375, -3.56475830078125, -2.8913002014160156, -2.2178421020507812, -1.5443801879882812, -0.8709220886230469, -0.19746017456054688, 0.4759979248046875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0], "bins": [-1.5668437480926514, -1.5420522689819336, -1.5172607898712158, -1.492469310760498, -1.4676779508590698, -1.442886471748352, -1.4180949926376343, -1.3933035135269165, -1.3685120344161987, -1.343720555305481, -1.3189290761947632, -1.294137716293335, -1.2693462371826172, -1.2445547580718994, -1.2197632789611816, -1.1949717998504639, -1.170180320739746, -1.1453888416290283, -1.1205973625183105, -1.0958060026168823, -1.0710145235061646, -1.0462230443954468, -1.021431565284729, -0.9966400861740112, -0.9718486666679382, -0.9470571875572205, -0.9222657084465027, -0.8974742889404297, -0.8726828098297119, -0.8478913307189941, -0.8230998516082764, -0.7983084321022034, -0.7735169529914856, -0.7487254738807678, -0.7239340543746948, -0.699142575263977, -0.6743510961532593, -0.6495596170425415, -0.6247681975364685, -0.5999767184257507, -0.575185239315033, -0.55039381980896, -0.5256023406982422, -0.5008108615875244, -0.47601938247680664, -0.45122790336608887, -0.4264364242553711, -0.40164506435394287, -0.3768535852432251, -0.3520621061325073, -0.32727062702178955, -0.3024791479110718, -0.277687668800354, -0.25289618968963623, -0.228104829788208, -0.20331335067749023, -0.17852187156677246, -0.1537303924560547, -0.12893891334533691, -0.10414743423461914, -0.07935595512390137, -0.054564595222473145, -0.02977311611175537, -0.004981637001037598, 0.019809842109680176]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 258.0, 30.0, 0.0, 4.0, 27.0, 64.0, 60.0, 31.0, 10.0], "bins": [-12.283926963806152, -12.06417465209961, -11.844422340393066, -11.624670028686523, -11.40491771697998, -11.185165405273438, -10.965412139892578, -10.745659828186035, -10.525907516479492, -10.30615520477295, -10.086402893066406, -9.866650581359863, -9.64689826965332, -9.427145957946777, -9.207393646240234, -8.987640380859375, -8.767889022827148, -8.548135757446289, -8.328383445739746, -8.108631134033203, -7.88887882232666, -7.669126510620117, -7.449374198913574, -7.229621887207031, -7.009869575500488, -6.790116786956787, -6.570364475250244, -6.350612163543701, -6.130859851837158, -5.911107540130615, -5.691354751586914, -5.471602439880371, -5.251850128173828, -5.032097816467285, -4.812345504760742, -4.592592716217041, -4.372840404510498, -4.153088569641113, -3.933335304260254, -3.713582992553711, -3.493830680847168, -3.274078369140625, -3.054326057434082, -2.834573745727539, -2.614821434020996, -2.395069122314453, -2.17531681060791, -1.9555644989013672, -1.7358121871948242, -1.5160589218139648, -1.2963066101074219, -1.076554298400879, -0.8568019866943359, -0.637049674987793, -0.41729736328125, -0.19754505157470703, 0.022207260131835938, 0.2419595718383789, 0.4617118835449219, 0.6814651489257812, 0.9012174606323242, 1.1209697723388672, 1.3407220840454102, 1.5604743957519531, 1.780226707458496]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 15.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-52.92599105834961, -51.614952087402344, -50.30391311645508, -48.99287414550781, -47.68183517456055, -46.37079620361328, -45.059757232666016, -43.74871826171875, -42.43767547607422, -41.12664031982422, -39.81559753417969, -38.50455856323242, -37.193519592285156, -35.88248062133789, -34.571441650390625, -33.26040267944336, -31.949363708496094, -30.638324737548828, -29.327285766601562, -28.016246795654297, -26.70520782470703, -25.394166946411133, -24.083127975463867, -22.7720890045166, -21.461050033569336, -20.150009155273438, -18.838970184326172, -17.527931213378906, -16.21689224243164, -14.905853271484375, -13.59481430053711, -12.283775329589844, -10.972736358642578, -9.661697387695312, -8.350658416748047, -7.039619445800781, -5.728580474853516, -4.41754150390625, -3.1065025329589844, -1.7954635620117188, -0.4844245910644531, 0.8266181945800781, 2.1376571655273438, 3.4486961364746094, 4.759735107421875, 6.070774078369141, 7.381813049316406, 8.692852020263672, 10.003890991210938, 11.314929962158203, 12.625972747802734, 13.937007904052734, 15.248050689697266, 16.559085845947266, 17.870128631591797, 19.181163787841797, 20.492206573486328, 21.803241729736328, 23.11428451538086, 24.42531967163086, 25.73636245727539, 27.04739761352539, 28.358440399169922, 29.669475555419922, 30.980518341064453]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 47.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-16.40323829650879, -15.706916809082031, -15.010595321655273, -14.314273834228516, -13.617952346801758, -12.921630859375, -12.225310325622559, -11.5289888381958, -10.832667350769043, -10.136345863342285, -9.440024375915527, -8.743703842163086, -8.047382354736328, -7.35106086730957, -6.6547393798828125, -5.958417892456055, -5.262096405029297, -4.565774917602539, -3.8694534301757812, -3.1731319427490234, -2.4768104553222656, -1.7804899215698242, -1.0841684341430664, -0.3878459930419922, 0.3084735870361328, 1.0047950744628906, 1.7011165618896484, 2.3974380493164062, 3.093759536743164, 3.790081024169922, 4.48640251159668, 5.1827239990234375, 5.879045486450195, 6.575366973876953, 7.271688461303711, 7.968009948730469, 8.664331436157227, 9.360652923583984, 10.056974411010742, 10.7532958984375, 11.449617385864258, 12.145936965942383, 12.84225845336914, 13.538579940795898, 14.234901428222656, 14.931222915649414, 15.627546310424805, 16.32386589050293, 17.020185470581055, 17.716508865356445, 18.41282844543457, 19.10915184020996, 19.805471420288086, 20.501794815063477, 21.1981143951416, 21.894437789916992, 22.590757369995117, 23.287080764770508, 23.983400344848633, 24.679723739624023, 25.37604331970215, 26.07236671447754, 26.768686294555664, 27.465009689331055, 28.16132926940918]}, "_runtime": 18792.203434228897, "_timestamp": 1585616161.8363037, "_step": 398}
{"Episode reward": 2.000000000001293, "Episode length": 980, "Policy Loss": 0.5469028353691101, "Value Loss": 10.099503517150879, "_runtime": 18793.696895360947, "_timestamp": 1585616163.3297648, "_step": 399}
{"Episode reward": 5.300000000001106, "Episode length": 947, "Policy Loss": 0.1787359118461609, "Value Loss": 10.354116439819336, "_runtime": 18794.915906906128, "_timestamp": 1585616164.5487764, "_step": 400}
{"Episode reward": 22.180039000511314, "Episode length": 779, "Policy Loss": 0.48104962706565857, "Value Loss": 12.44879150390625, "_runtime": 18796.469831228256, "_timestamp": 1585616166.1027007, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6382196545600891, "Value Loss": 0.011014950461685658, "_runtime": 18798.050446987152, "_timestamp": 1585616167.6833165, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6802543997764587, "Value Loss": 0.042199403047561646, "_runtime": 18799.599011182785, "_timestamp": 1585616169.2318807, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6737459301948547, "Value Loss": 0.032761018723249435, "_runtime": 18801.143981456757, "_timestamp": 1585616170.776851, "_step": 404}
{"Episode reward": 1.1000000000013443, "Episode length": 989, "Policy Loss": 0.11226605623960495, "Value Loss": 9.907745361328125, "_runtime": 18802.7263507843, "_timestamp": 1585616172.3592203, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7025290727615356, "Value Loss": 0.06823717802762985, "_runtime": 18804.301522254944, "_timestamp": 1585616173.9343917, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6692028045654297, "Value Loss": 0.007427414879202843, "_runtime": 18805.87570977211, "_timestamp": 1585616175.5085793, "_step": 407}
{"Episode reward": -99.86833670139173, "Episode length": 999, "Policy Loss": -0.6679043173789978, "Value Loss": 0.056536488234996796, "_runtime": 18807.448118925095, "_timestamp": 1585616177.0809884, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6372253894805908, "Value Loss": 0.00655605411157012, "_runtime": 18809.06007552147, "_timestamp": 1585616178.692945, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6093471050262451, "Value Loss": 0.018900055438280106, "_runtime": 18810.18626856804, "_timestamp": 1585616179.819138, "_step": 410}
{"Episode reward": 28.499999999999787, "Episode length": 715, "Policy Loss": 0.8822565078735352, "Value Loss": 13.588520050048828, "_runtime": 18811.76612019539, "_timestamp": 1585616181.3989897, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5776961445808411, "Value Loss": 0.020641205832362175, "_runtime": 18813.328063488007, "_timestamp": 1585616182.960933, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6121963858604431, "Value Loss": 0.11635679751634598, "_runtime": 18814.47584605217, "_timestamp": 1585616184.1087155, "_step": 413}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.556898832321167, "Value Loss": 13.405461311340332, "_runtime": 18815.01259303093, "_timestamp": 1585616184.6454625, "_step": 414}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 2.1705446243286133, "Value Loss": 30.76873016357422, "_runtime": 18816.581576108932, "_timestamp": 1585616186.2144456, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5329607725143433, "Value Loss": 0.01033810991793871, "_runtime": 18818.05599117279, "_timestamp": 1585616187.6888607, "_step": 416}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 0.3626779317855835, "Value Loss": 10.203814506530762, "_runtime": 18818.49870944023, "_timestamp": 1585616188.131579, "_step": 417}
{"Episode reward": 72.10864261984813, "Episode length": 279, "Policy Loss": 2.5264015197753906, "Value Loss": 34.587955474853516, "_runtime": 18819.71079516411, "_timestamp": 1585616189.3436646, "_step": 418}
{"Episode reward": 22.90940962359319, "Episode length": 772, "Policy Loss": 0.42954590916633606, "Value Loss": 12.766756057739258, "_runtime": 18821.27372121811, "_timestamp": 1585616190.9065907, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.631874680519104, "Value Loss": 0.01097264513373375, "_runtime": 18822.77932047844, "_timestamp": 1585616192.41219, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6914383769035339, "Value Loss": 0.029815558344125748, "_runtime": 18823.65780520439, "_timestamp": 1585616193.2906747, "_step": 421}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 0.7978569865226746, "Value Loss": 17.364437103271484, "_runtime": 18825.224672555923, "_timestamp": 1585616194.857542, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.775771975517273, "Value Loss": 0.2237984985113144, "_runtime": 18826.783431768417, "_timestamp": 1585616196.4163013, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7697900533676147, "Value Loss": 0.03116147220134735, "_runtime": 18827.955503940582, "_timestamp": 1585616197.5883734, "_step": 424}
{"Episode reward": 24.40000000000002, "Episode length": 756, "Policy Loss": 0.2963566780090332, "Value Loss": 13.015563011169434, "_runtime": 18829.52404332161, "_timestamp": 1585616199.1569128, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7781002521514893, "Value Loss": 0.04487508162856102, "_runtime": 18831.129647016525, "_timestamp": 1585616200.7625165, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.808603048324585, "Value Loss": 0.035200104117393494, "_runtime": 18832.679836034775, "_timestamp": 1585616202.3127055, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8271440863609314, "Value Loss": 0.07364435493946075, "_runtime": 18833.106214761734, "_timestamp": 1585616202.7390842, "_step": 428}
{"Episode reward": 76.49984405599528, "Episode length": 236, "Policy Loss": 3.6706838607788086, "Value Loss": 40.991294860839844, "_runtime": 18833.495366573334, "_timestamp": 1585616203.128236, "_step": 429}
{"Episode reward": 77.39999999999995, "Episode length": 226, "Policy Loss": 3.239990234375, "Value Loss": 42.55094528198242, "_runtime": 18834.873767137527, "_timestamp": 1585616204.5066366, "_step": 430}
{"Episode reward": 11.400000000000759, "Episode length": 886, "Policy Loss": 0.011212564073503017, "Value Loss": 10.97188663482666, "_runtime": 18836.28550672531, "_timestamp": 1585616205.9183762, "_step": 431}
{"Episode reward": 5.800000000001077, "Episode length": 942, "Policy Loss": -0.030169734731316566, "Value Loss": 10.345830917358398, "_runtime": 18837.783809185028, "_timestamp": 1585616207.4166787, "_step": 432}
{"Episode reward": -99.8205543577657, "Episode length": 999, "Policy Loss": -1.044362187385559, "Value Loss": 0.20125775039196014, "_runtime": 18839.341294050217, "_timestamp": 1585616208.9741635, "_step": 433}
{"Episode reward": -99.80770550370076, "Episode length": 999, "Policy Loss": -0.9962188601493835, "Value Loss": 0.013938523828983307, "_runtime": 18840.8805205822, "_timestamp": 1585616210.51339, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0125106573104858, "Value Loss": 0.056375306099653244, "_runtime": 18842.424206018448, "_timestamp": 1585616212.0570755, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0636345148086548, "Value Loss": 0.11211671680212021, "_runtime": 18843.151107549667, "_timestamp": 1585616212.783977, "_step": 436}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 0.9516428709030151, "Value Loss": 21.26600456237793, "_runtime": 18844.62427663803, "_timestamp": 1585616214.2571461, "_step": 437}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": -0.12116062641143799, "Value Loss": 10.288151741027832, "_runtime": 18846.18888735771, "_timestamp": 1585616215.8217568, "_step": 438}
{"Episode reward": -99.88507540225842, "Episode length": 999, "Policy Loss": -1.0906039476394653, "Value Loss": 0.15829159319400787, "_runtime": 18847.60293650627, "_timestamp": 1585616217.235806, "_step": 439}
{"Episode reward": 6.838429617882795, "Episode length": 932, "Policy Loss": 0.15826593339443207, "Value Loss": 10.28717041015625, "_runtime": 18848.550411462784, "_timestamp": 1585616218.183281, "_step": 440}
{"Episode reward": 40.29999999999943, "Episode length": 597, "Policy Loss": 0.4083890914916992, "Value Loss": 16.266475677490234, "_runtime": 18850.11478805542, "_timestamp": 1585616219.7476575, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9601098299026489, "Value Loss": 0.034999262541532516, "_runtime": 18851.686166763306, "_timestamp": 1585616221.3190362, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9798716902732849, "Value Loss": 0.01867595501244068, "_runtime": 18853.226360321045, "_timestamp": 1585616222.8592298, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9948155879974365, "Value Loss": 0.10144586861133575, "_runtime": 18854.779192209244, "_timestamp": 1585616224.4120617, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9631030559539795, "Value Loss": 0.01912858337163925, "_runtime": 18856.399223089218, "_timestamp": 1585616226.0320926, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9376344680786133, "Value Loss": 0.035292185842990875, "_runtime": 18857.969423532486, "_timestamp": 1585616227.602293, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9322142004966736, "Value Loss": 0.06178472936153412, "_runtime": 18859.461198329926, "_timestamp": 1585616229.0940678, "_step": 447}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": -0.16029907763004303, "Value Loss": 10.594128608703613, "_runtime": 18860.18671488762, "_timestamp": 1585616229.8195844, "_step": 448}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": 0.9118953943252563, "Value Loss": 22.387826919555664, "_runtime": 18861.759216070175, "_timestamp": 1585616231.3920856, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7648679614067078, "Value Loss": 0.021185357123613358, "_runtime": 18863.333525180817, "_timestamp": 1585616232.9663947, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7604868412017822, "Value Loss": 0.16827288269996643, "_runtime": 18864.13722705841, "_timestamp": 1585616233.7700965, "_step": 451}
{"Episode reward": 47.89999999999954, "Episode length": 521, "Policy Loss": 0.8319856524467468, "Value Loss": 18.869754791259766, "_runtime": 18865.706427812576, "_timestamp": 1585616235.3392973, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6124903559684753, "Value Loss": 0.019069809466600418, "_runtime": 18867.26872587204, "_timestamp": 1585616236.9015954, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5606365203857422, "Value Loss": 0.08669013530015945, "_runtime": 18868.795669317245, "_timestamp": 1585616238.4285388, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5213574171066284, "Value Loss": 0.027918173000216484, "_runtime": 18870.153928756714, "_timestamp": 1585616239.7867982, "_step": 455}
{"Episode reward": 12.89993615001508, "Episode length": 872, "Policy Loss": 0.511991560459137, "Value Loss": 11.21748161315918, "_runtime": 18870.984083890915, "_timestamp": 1585616240.6169534, "_step": 456}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 1.2880895137786865, "Value Loss": 18.956777572631836, "_runtime": 18872.547606229782, "_timestamp": 1585616242.1804757, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42391544580459595, "Value Loss": 0.013101162388920784, "_runtime": 18873.55882716179, "_timestamp": 1585616243.1916966, "_step": 458}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.9768438935279846, "Value Loss": 15.325469970703125, "_runtime": 18875.098628282547, "_timestamp": 1585616244.7314978, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3845632076263428, "Value Loss": 0.020026380196213722, "_runtime": 18876.596875667572, "_timestamp": 1585616246.2297451, "_step": 460}
{"Episode reward": 4.100000000001174, "Episode length": 959, "Policy Loss": 0.6007988452911377, "Value Loss": 10.308019638061523, "_runtime": 18878.13795018196, "_timestamp": 1585616247.7708197, "_step": 461}
{"Episode reward": -99.80275611877302, "Episode length": 999, "Policy Loss": -0.4147118926048279, "Value Loss": 0.05699405074119568, "_runtime": 18879.728359937668, "_timestamp": 1585616249.3612294, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37606334686279297, "Value Loss": 0.009837075136601925, "_runtime": 18881.306524515152, "_timestamp": 1585616250.939394, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3643590807914734, "Value Loss": 0.013980924151837826, "_runtime": 18882.335406780243, "_timestamp": 1585616251.9682763, "_step": 464}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 0.9008638858795166, "Value Loss": 14.926745414733887, "_runtime": 18883.90758228302, "_timestamp": 1585616253.5404518, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38374918699264526, "Value Loss": 0.006309335120022297, "_runtime": 18884.77494430542, "_timestamp": 1585616254.4078138, "_step": 466}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 1.1409943103790283, "Value Loss": 18.128854751586914, "_runtime": 18886.314349651337, "_timestamp": 1585616255.9472191, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4200919270515442, "Value Loss": 0.008107122965157032, "_runtime": 18887.088275432587, "_timestamp": 1585616256.721145, "_step": 468}
{"Episode reward": 52.3999999999996, "Episode length": 476, "Policy Loss": 1.7500557899475098, "Value Loss": 20.347183227539062, "_runtime": 18888.620351552963, "_timestamp": 1585616258.253221, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4723724126815796, "Value Loss": 0.007783912587910891, "_runtime": 18890.19748187065, "_timestamp": 1585616259.8303514, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48488619923591614, "Value Loss": 0.005361654795706272, "_runtime": 18891.425760507584, "_timestamp": 1585616261.05863, "_step": 471}
{"Episode reward": 19.200000000000315, "Episode length": 808, "Policy Loss": 0.36103901267051697, "Value Loss": 12.315678596496582, "_runtime": 18892.99805164337, "_timestamp": 1585616262.6309211, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.561258852481842, "Value Loss": 0.09632717072963715, "_runtime": 18894.567137002945, "_timestamp": 1585616264.2000065, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5866407155990601, "Value Loss": 0.12394791096448898, "_runtime": 18895.74903178215, "_timestamp": 1585616265.3819013, "_step": 474}
{"Episode reward": 24.40000000000002, "Episode length": 756, "Policy Loss": 0.5928882360458374, "Value Loss": 12.814233779907227, "_runtime": 18896.910400867462, "_timestamp": 1585616266.5432703, "_step": 475}
{"Episode reward": 26.399999999999906, "Episode length": 736, "Policy Loss": 0.6258454322814941, "Value Loss": 13.07172679901123, "_runtime": 18897.58574128151, "_timestamp": 1585616267.2186108, "_step": 476}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 1.7372984886169434, "Value Loss": 23.44390869140625, "_runtime": 18899.138689279556, "_timestamp": 1585616268.7715588, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5221604704856873, "Value Loss": 0.02959468588232994, "_runtime": 18900.697801351547, "_timestamp": 1585616270.3306708, "_step": 478}
{"Episode reward": -99.84338743686536, "Episode length": 999, "Policy Loss": -0.5195070505142212, "Value Loss": 0.09043797850608826, "_runtime": 18902.25583744049, "_timestamp": 1585616271.888707, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5968561768531799, "Value Loss": 0.020155612379312515, "_runtime": 18903.12732410431, "_timestamp": 1585616272.7601936, "_step": 480}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": 0.950547456741333, "Value Loss": 17.853670120239258, "_runtime": 18904.29107427597, "_timestamp": 1585616273.9239438, "_step": 481}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": 0.46353471279144287, "Value Loss": 13.093605995178223, "_runtime": 18905.011063814163, "_timestamp": 1585616274.6439333, "_step": 482}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 1.3679325580596924, "Value Loss": 21.486608505249023, "_runtime": 18906.534813642502, "_timestamp": 1585616276.1676831, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7294474244117737, "Value Loss": 0.04420499876141548, "_runtime": 18907.129961013794, "_timestamp": 1585616276.7628305, "_step": 484}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.6267186403274536, "Value Loss": 25.79434585571289, "_runtime": 18907.620309352875, "_timestamp": 1585616277.2531788, "_step": 485}
{"Episode reward": 68.39999999999984, "Episode length": 316, "Policy Loss": 2.027461290359497, "Value Loss": 30.58415412902832, "_runtime": 18909.169939041138, "_timestamp": 1585616278.8028085, "_step": 486}
{"Episode reward": -99.87820543683925, "Episode length": 999, "Policy Loss": -0.9235690832138062, "Value Loss": 0.19930697977542877, "_runtime": 18910.652334690094, "_timestamp": 1585616280.2852042, "_step": 487}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": -0.04338578134775162, "Value Loss": 9.693181991577148, "_runtime": 18912.160647153854, "_timestamp": 1585616281.7935166, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9514901041984558, "Value Loss": 0.03009207174181938, "_runtime": 18913.735915660858, "_timestamp": 1585616283.3687851, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9505316615104675, "Value Loss": 0.0935961976647377, "_runtime": 18915.206285715103, "_timestamp": 1585616284.8391552, "_step": 490}
{"Episode reward": 5.500000000001094, "Episode length": 945, "Policy Loss": -0.24404171109199524, "Value Loss": 10.293209075927734, "_runtime": 18915.980749368668, "_timestamp": 1585616285.6136189, "_step": 491}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 0.6070091128349304, "Value Loss": 19.725017547607422, "_runtime": 18916.75422024727, "_timestamp": 1585616286.3870897, "_step": 492}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": 0.4776933491230011, "Value Loss": 20.002790451049805, "_runtime": 18918.313786506653, "_timestamp": 1585616287.946656, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1427500247955322, "Value Loss": 0.023322151973843575, "_runtime": 18919.840566635132, "_timestamp": 1585616289.473436, "_step": 494}
{"Episode reward": -99.83955659419159, "Episode length": 999, "Policy Loss": -1.1593079566955566, "Value Loss": 0.02885228395462036, "_runtime": 18920.647331237793, "_timestamp": 1585616290.2802007, "_step": 495}
{"Episode reward": 48.19999999999954, "Episode length": 518, "Policy Loss": 0.4036945402622223, "Value Loss": 18.391157150268555, "_runtime": 18922.211608171463, "_timestamp": 1585616291.8444777, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2353206872940063, "Value Loss": 0.12197926640510559, "_runtime": 18923.131373405457, "_timestamp": 1585616292.764243, "_step": 497}
{"Episode reward": 42.29999999999946, "Episode length": 577, "Policy Loss": 0.21290263533592224, "Value Loss": 16.99156379699707, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197, 0.012465590611100197]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [12.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.014429443515837193, 0.00782597903162241, 0.030081402510404587, 0.05233682692050934, 0.07459224760532379, 0.09684766829013824, 0.1191030964255333, 0.14135850965976715, 0.1636139303445816, 0.18586935102939606, 0.2081247717142105, 0.23038019239902496, 0.2526356279850006, 0.27489104866981506, 0.2971464693546295, 0.31940189003944397, 0.3416573107242584, 0.3639127314090729, 0.38616815209388733, 0.4084235727787018, 0.43067899346351624, 0.4529344141483307, 0.47518983483314514, 0.497445285320282, 0.5197007060050964, 0.5419561266899109, 0.5642115473747253, 0.5864669680595398, 0.6087223887443542, 0.6309778094291687, 0.6532332301139832, 0.6754886507987976, 0.6977440714836121, 0.7199994921684265, 0.742254912853241, 0.7645103335380554, 0.7867657542228699, 0.8090211749076843, 0.8312765955924988, 0.8535320162773132, 0.8757874369621277, 0.8980428576469421, 0.9202982783317566, 0.942553699016571, 0.9648091197013855, 0.9870645999908447, 1.0093200206756592, 1.0315754413604736, 1.053830862045288, 1.0760862827301025, 1.098341703414917, 1.1205971240997314, 1.142852544784546, 1.1651079654693604, 1.1873633861541748, 1.2096188068389893, 1.2318742275238037, 1.2541296482086182, 1.2763850688934326, 1.298640489578247, 1.3208959102630615, 1.343151330947876, 1.3654067516326904, 1.3876621723175049, 1.4099175930023193]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0010486072860658169, 0.0020972145721316338, 0.0031458218581974506, 0.0041944291442632675, 0.005243036430329084, 0.006291643716394901, 0.007340251002460718, 0.008388858288526535, 0.00943746604025364, 0.010486072860658169, 0.011534679681062698, 0.012583287432789803, 0.013631895184516907, 0.014680502004921436, 0.015729108825325966, 0.01677771657705307, 0.017826324328780174, 0.01887493208050728, 0.019923537969589233, 0.020972145721316338, 0.022020753473043442, 0.023069359362125397, 0.0241179671138525, 0.025166574865579605, 0.02621518261730671, 0.027263790369033813, 0.02831239625811577, 0.029361004009842873, 0.030409611761569977, 0.03145821765065193, 0.032506827265024185, 0.03355543315410614, 0.034604039043188095, 0.03565264865756035, 0.0367012545466423, 0.03774986416101456, 0.03879847005009651, 0.03984707593917847, 0.04089568555355072, 0.041944291442632675, 0.04299289733171463, 0.044041506946086884, 0.04509011283516884, 0.04613871872425079, 0.04718732833862305, 0.048235934227705, 0.049284543842077255, 0.05033314973115921, 0.051381755620241165, 0.05243036523461342, 0.053478971123695374, 0.05452758073806763, 0.05557618662714958, 0.05662479251623154, 0.05767340213060379, 0.058722008019685745, 0.0597706139087677, 0.060819223523139954, 0.06186782941222191, 0.06291643530130386, 0.06396504491567612, 0.06501365453004837, 0.06606225669384003, 0.06711086630821228]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [17.0, 12.0, 10.0, 3.0, 8.0, 10.0, 21.0, 24.0, 23.0, 19.0, 0.0, 298.0, 13.0, 6.0, 5.0, 8.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06683554500341415, -0.06099071353673935, -0.055145882070064545, -0.04930105060338974, -0.043456219136714935, -0.03761138767004013, -0.03176655247807503, -0.025921721011400223, -0.020076889544725418, -0.014232058078050613, -0.008387226611375809, -0.0025423914194107056, 0.003302440047264099, 0.009147271513938904, 0.014992102980613708, 0.020836934447288513, 0.026681765913963318, 0.03252659738063812, 0.03837142884731293, 0.04421626031398773, 0.05006109178066254, 0.05590592324733734, 0.06175076216459274, 0.06759559363126755, 0.07344042509794235, 0.07928525656461716, 0.08513008803129196, 0.09097491949796677, 0.09681975096464157, 0.10266458243131638, 0.10850941389799118, 0.11435424536466599, 0.12019907683134079, 0.1260439157485962, 0.131888747215271, 0.1377335786819458, 0.1435784101486206, 0.1494232416152954, 0.15526807308197021, 0.16111290454864502, 0.16695773601531982, 0.17280256748199463, 0.17864739894866943, 0.18449223041534424, 0.19033706188201904, 0.19618189334869385, 0.20202672481536865, 0.20787155628204346, 0.21371638774871826, 0.21956121921539307, 0.22540605068206787, 0.23125088214874268, 0.23709571361541748, 0.24294054508209229, 0.2487853765487671, 0.2546302080154419, 0.2604750394821167, 0.2663198709487915, 0.2721647024154663, 0.2780095338821411, 0.2838543653488159, 0.2896991968154907, 0.2955440282821655, 0.30138885974884033, 0.30723369121551514]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 13.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.597885251045227, -0.5717184543609619, -0.5455517172813416, -0.5193849205970764, -0.49321815371513367, -0.4670513868331909, -0.44088461995124817, -0.4147178530693054, -0.3885510563850403, -0.3623843193054199, -0.3362175226211548, -0.31005075573921204, -0.2838839888572693, -0.25771722197532654, -0.2315504252910614, -0.20538365840911865, -0.1792168915271759, -0.15305012464523315, -0.1268833577632904, -0.10071656107902527, -0.07454979419708252, -0.04838305711746216, -0.02221626043319702, 0.003950536251068115, 0.030117273330688477, 0.05628407001495361, 0.08245080709457397, 0.10861760377883911, 0.13478440046310425, 0.1609511375427246, 0.18711793422698975, 0.2132846713066101, 0.23945146799087524, 0.2656182646751404, 0.29178500175476074, 0.3179517984390259, 0.34411853551864624, 0.3702853322029114, 0.3964521288871765, 0.4226188659667969, 0.448785662651062, 0.47495245933532715, 0.5011191368103027, 0.5272859334945679, 0.553452730178833, 0.5796195268630981, 0.6057863235473633, 0.6319530010223389, 0.658119797706604, 0.6842865943908691, 0.7104533910751343, 0.7366201877593994, 0.762786865234375, 0.7889536619186401, 0.8151204586029053, 0.8412872552871704, 0.8674540519714355, 0.8936207294464111, 0.9197875261306763, 0.9459543228149414, 0.9721211194992065, 0.9982879161834717, 1.0244545936584473, 1.0506213903427124, 1.0767881870269775]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 0.0, 2.0, 1.0, 2.0, 5.0, 15.0, 9.0, 7.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0], "bins": [-0.261260986328125, -0.2559104263782501, -0.25055989623069763, -0.24520933628082275, -0.23985879123210907, -0.23450824618339539, -0.2291576862335205, -0.22380714118480682, -0.21845659613609314, -0.21310605108737946, -0.20775550603866577, -0.2024049460887909, -0.1970544010400772, -0.19170385599136353, -0.18635329604148865, -0.18100275099277496, -0.17565220594406128, -0.1703016608953476, -0.1649511158466339, -0.15960055589675903, -0.15425001084804535, -0.14889946579933167, -0.1435489058494568, -0.1381983608007431, -0.13284781575202942, -0.12749727070331573, -0.12214672565460205, -0.11679616570472717, -0.11144562065601349, -0.1060950756072998, -0.10074451565742493, -0.09539397060871124, -0.09004342555999756, -0.08469288051128387, -0.07934233546257019, -0.07399177551269531, -0.06864123046398163, -0.06329068541526794, -0.057940125465393066, -0.05258958041667938, -0.0472390353679657, -0.041888490319252014, -0.03653794527053833, -0.031187385320663452, -0.025836840271949768, -0.020486295223236084, -0.015135735273361206, -0.009785205125808716, -0.004434645175933838, 0.00091591477394104, 0.00626644492149353, 0.011617004871368408, 0.0169675350189209, 0.022318094968795776, 0.027668654918670654, 0.033019185066223145, 0.03836974501609802, 0.0437203049659729, 0.04907083511352539, 0.05442139506340027, 0.059771955013275146, 0.06512248516082764, 0.07047304511070251, 0.075823575258255, 0.08117413520812988]}, "_runtime": 18924.654253959656, "_timestamp": 1585616294.2871234, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2205990552902222, "Value Loss": 0.03290852531790733, "_runtime": 18924.654253959656, "_timestamp": 1585616294.2871234, "_step": 499}
