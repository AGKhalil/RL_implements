{"Episode reward": -41.43980859580711, "Episode length": 999, "Policy Loss": -0.01912536844611168, "Value Loss": 0.02773965708911419, "_runtime": 1673.8261120319366, "_timestamp": 1585571589.6707454, "_step": 0}
{"Episode reward": -93.20171372613937, "Episode length": 999, "Policy Loss": 0.5350655913352966, "Value Loss": 112.65753936767578, "_runtime": 1675.324053287506, "_timestamp": 1585571591.1686866, "_step": 1}
{"Episode reward": -97.4721873015877, "Episode length": 999, "Policy Loss": -0.5098970532417297, "Value Loss": 34.69154357910156, "_runtime": 1676.94025015831, "_timestamp": 1585571592.7848835, "_step": 2}
{"Episode reward": -97.53093116317218, "Episode length": 999, "Policy Loss": -3.1035921573638916, "Value Loss": 1183.3514404296875, "_runtime": 1678.4866428375244, "_timestamp": 1585571594.3312762, "_step": 3}
{"Episode reward": -99.11708747425301, "Episode length": 999, "Policy Loss": -1.3636771440505981, "Value Loss": 13.787660598754883, "_runtime": 1680.0162825584412, "_timestamp": 1585571595.860916, "_step": 4}
{"Episode reward": -99.25381987410228, "Episode length": 999, "Policy Loss": -0.9697089195251465, "Value Loss": 39.427955627441406, "_runtime": 1680.7987892627716, "_timestamp": 1585571596.6434226, "_step": 5}
{"Episode reward": 51.96326776786987, "Episode length": 483, "Policy Loss": -0.07689734548330307, "Value Loss": 197.81446838378906, "_runtime": 1682.3437850475311, "_timestamp": 1585571598.1884184, "_step": 6}
{"Episode reward": -99.27879516692491, "Episode length": 999, "Policy Loss": -0.1150708794593811, "Value Loss": 0.03177564963698387, "_runtime": 1683.6549091339111, "_timestamp": 1585571599.4995425, "_step": 7}
{"Episode reward": 16.10683669380427, "Episode length": 843, "Policy Loss": 0.9745773077011108, "Value Loss": 20.737529754638672, "_runtime": 1685.16845703125, "_timestamp": 1585571601.0130904, "_step": 8}
{"Episode reward": -99.59992434938765, "Episode length": 999, "Policy Loss": -0.0181170292198658, "Value Loss": 1.1451777219772339, "_runtime": 1686.7357261180878, "_timestamp": 1585571602.5803595, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7559329271316528, "Value Loss": 7.927731037139893, "_runtime": 1688.275966644287, "_timestamp": 1585571604.1206, "_step": 10}
{"Episode reward": -99.58987102213294, "Episode length": 999, "Policy Loss": -1.5425313711166382, "Value Loss": 30.941539764404297, "_runtime": 1689.498339176178, "_timestamp": 1585571605.3429725, "_step": 11}
{"Episode reward": 23.181046756700468, "Episode length": 770, "Policy Loss": 0.3748829662799835, "Value Loss": 37.9786376953125, "_runtime": 1690.58331823349, "_timestamp": 1585571606.4279516, "_step": 12}
{"Episode reward": 31.282108701479956, "Episode length": 690, "Policy Loss": 0.8754851818084717, "Value Loss": 17.50065803527832, "_runtime": 1691.8358318805695, "_timestamp": 1585571607.6804652, "_step": 13}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 1.3421064615249634, "Value Loss": 22.426090240478516, "_runtime": 1693.0547919273376, "_timestamp": 1585571608.8994253, "_step": 14}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": 1.5676244497299194, "Value Loss": 20.017480850219727, "_runtime": 1694.4978384971619, "_timestamp": 1585571610.3424718, "_step": 15}
{"Episode reward": 6.529766956019316, "Episode length": 936, "Policy Loss": 0.8005944490432739, "Value Loss": 13.548684120178223, "_runtime": 1695.5360431671143, "_timestamp": 1585571611.3806765, "_step": 16}
{"Episode reward": 32.399999999999565, "Episode length": 676, "Policy Loss": 0.2231002151966095, "Value Loss": 51.360321044921875, "_runtime": 1697.0690066814423, "_timestamp": 1585571612.91364, "_step": 17}
{"Episode reward": -99.51158006728954, "Episode length": 999, "Policy Loss": 0.48516929149627686, "Value Loss": 3.7884373664855957, "_runtime": 1698.1432085037231, "_timestamp": 1585571613.9878418, "_step": 18}
{"Episode reward": 30.972558011090968, "Episode length": 692, "Policy Loss": 2.350477695465088, "Value Loss": 48.684444427490234, "_runtime": 1699.6774907112122, "_timestamp": 1585571615.522124, "_step": 19}
{"Episode reward": -99.73305456444947, "Episode length": 999, "Policy Loss": 1.4575233459472656, "Value Loss": 35.5235710144043, "_runtime": 1700.0712389945984, "_timestamp": 1585571615.9158723, "_step": 20}
{"Episode reward": 78.27478427132588, "Episode length": 219, "Policy Loss": 2.53082275390625, "Value Loss": 50.015316009521484, "_runtime": 1701.6461577415466, "_timestamp": 1585571617.490791, "_step": 21}
{"Episode reward": -99.80000971639389, "Episode length": 999, "Policy Loss": -1.5143276453018188, "Value Loss": 18.50994873046875, "_runtime": 1702.29318857193, "_timestamp": 1585571618.137822, "_step": 22}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": -1.5542776584625244, "Value Loss": 92.7559814453125, "_runtime": 1703.784137248993, "_timestamp": 1585571619.6287706, "_step": 23}
{"Episode reward": -99.6748434570837, "Episode length": 999, "Policy Loss": -1.3733532428741455, "Value Loss": 41.062747955322266, "_runtime": 1705.3560609817505, "_timestamp": 1585571621.2006943, "_step": 24}
{"Episode reward": -99.77479412408871, "Episode length": 999, "Policy Loss": -0.753778874874115, "Value Loss": 0.5872074961662292, "_runtime": 1706.8663992881775, "_timestamp": 1585571622.7110326, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3617408275604248, "Value Loss": 3.1097452640533447, "_runtime": 1708.4264678955078, "_timestamp": 1585571624.2711012, "_step": 26}
{"Episode reward": -99.84827519759861, "Episode length": 999, "Policy Loss": 1.2611397504806519, "Value Loss": 15.998420715332031, "_runtime": 1710.0054802894592, "_timestamp": 1585571625.8501136, "_step": 27}
{"Episode reward": -99.49857530079179, "Episode length": 999, "Policy Loss": 1.71182119846344, "Value Loss": 75.30487060546875, "_runtime": 1711.5668034553528, "_timestamp": 1585571627.4114368, "_step": 28}
{"Episode reward": -99.56309640619298, "Episode length": 999, "Policy Loss": 2.8132688999176025, "Value Loss": 96.56356048583984, "_runtime": 1713.1336522102356, "_timestamp": 1585571628.9782856, "_step": 29}
{"Episode reward": 0.7927755392868647, "Episode length": 993, "Policy Loss": 2.5107474327087402, "Value Loss": 76.59574890136719, "_runtime": 1714.0227434635162, "_timestamp": 1585571629.8673768, "_step": 30}
{"Episode reward": 45.36579278027589, "Episode length": 547, "Policy Loss": 1.7924383878707886, "Value Loss": 27.89484405517578, "_runtime": 1714.7138485908508, "_timestamp": 1585571630.558482, "_step": 31}
{"Episode reward": 56.79999999999966, "Episode length": 432, "Policy Loss": 1.1202088594436646, "Value Loss": 22.891674041748047, "_runtime": 1716.2809467315674, "_timestamp": 1585571632.12558, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.002018928527832, "Value Loss": 0.7951304912567139, "_runtime": 1717.8201444149017, "_timestamp": 1585571633.6647778, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3340709209442139, "Value Loss": 1.892969012260437, "_runtime": 1719.1315236091614, "_timestamp": 1585571634.976157, "_step": 34}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": -0.8596125841140747, "Value Loss": 22.67198371887207, "_runtime": 1720.682951927185, "_timestamp": 1585571636.5275853, "_step": 35}
{"Episode reward": -99.76476525822515, "Episode length": 999, "Policy Loss": -1.4631847143173218, "Value Loss": 2.1668453216552734, "_runtime": 1722.2622165679932, "_timestamp": 1585571638.10685, "_step": 36}
{"Episode reward": -99.86772253252425, "Episode length": 999, "Policy Loss": -1.3269513845443726, "Value Loss": 0.3256017565727234, "_runtime": 1723.3553717136383, "_timestamp": 1585571639.200005, "_step": 37}
{"Episode reward": 30.59685680791702, "Episode length": 696, "Policy Loss": -0.13075202703475952, "Value Loss": 14.546669960021973, "_runtime": 1724.965955734253, "_timestamp": 1585571640.810589, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8745526671409607, "Value Loss": 0.23080562055110931, "_runtime": 1726.5471935272217, "_timestamp": 1585571642.3918269, "_step": 39}
{"Episode reward": -99.71845331955562, "Episode length": 999, "Policy Loss": -0.7332130670547485, "Value Loss": 0.30565759539604187, "_runtime": 1728.0918138027191, "_timestamp": 1585571643.9364471, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6347930431365967, "Value Loss": 0.24655413627624512, "_runtime": 1729.6587443351746, "_timestamp": 1585571645.5033777, "_step": 41}
{"Episode reward": -99.8030057282173, "Episode length": 999, "Policy Loss": -0.4743943512439728, "Value Loss": 0.17014957964420319, "_runtime": 1731.2243885993958, "_timestamp": 1585571647.069022, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36444321274757385, "Value Loss": 0.16096775233745575, "_runtime": 1732.7946741580963, "_timestamp": 1585571648.6393075, "_step": 43}
{"Episode reward": -99.83403608584636, "Episode length": 999, "Policy Loss": -0.3000158965587616, "Value Loss": 0.3345368504524231, "_runtime": 1734.355849981308, "_timestamp": 1585571650.2004833, "_step": 44}
{"Episode reward": -99.85318027138571, "Episode length": 999, "Policy Loss": -0.2506379187107086, "Value Loss": 0.4653586447238922, "_runtime": 1734.9695324897766, "_timestamp": 1585571650.8141658, "_step": 45}
{"Episode reward": 63.04772385209774, "Episode length": 370, "Policy Loss": 1.8426849842071533, "Value Loss": 28.71820068359375, "_runtime": 1736.5333795547485, "_timestamp": 1585571652.378013, "_step": 46}
{"Episode reward": -99.85662599243084, "Episode length": 999, "Policy Loss": -0.15072336792945862, "Value Loss": 0.08765348792076111, "_runtime": 1737.6381380558014, "_timestamp": 1585571653.4827714, "_step": 47}
{"Episode reward": 30.12253247788145, "Episode length": 700, "Policy Loss": 1.0516729354858398, "Value Loss": 14.602614402770996, "_runtime": 1738.3463571071625, "_timestamp": 1585571654.1909904, "_step": 48}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 1.3504763841629028, "Value Loss": 22.68159294128418, "_runtime": 1739.9059102535248, "_timestamp": 1585571655.7505436, "_step": 49}
{"Episode reward": -99.8052554666982, "Episode length": 999, "Policy Loss": -0.27349358797073364, "Value Loss": 0.042031776160001755, "_runtime": 1741.441443681717, "_timestamp": 1585571657.286077, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33404162526130676, "Value Loss": 0.05253535509109497, "_runtime": 1742.9519765377045, "_timestamp": 1585571658.7966099, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41151705384254456, "Value Loss": 0.19746045768260956, "_runtime": 1744.0840647220612, "_timestamp": 1585571659.928698, "_step": 52}
{"Episode reward": 27.919083474576297, "Episode length": 721, "Policy Loss": 0.5824682116508484, "Value Loss": 13.55313777923584, "_runtime": 1745.2876417636871, "_timestamp": 1585571661.132275, "_step": 53}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.4779770076274872, "Value Loss": 14.728843688964844, "_runtime": 1746.8307890892029, "_timestamp": 1585571662.6754224, "_step": 54}
{"Episode reward": -99.81475049415464, "Episode length": 999, "Policy Loss": -0.5395323634147644, "Value Loss": 2.676542282104492, "_runtime": 1748.3951346874237, "_timestamp": 1585571664.239768, "_step": 55}
{"Episode reward": -99.77050396064156, "Episode length": 999, "Policy Loss": -0.4697193503379822, "Value Loss": 0.11810418218374252, "_runtime": 1748.8849773406982, "_timestamp": 1585571664.7296107, "_step": 56}
{"Episode reward": 70.29999999999986, "Episode length": 297, "Policy Loss": 1.9547511339187622, "Value Loss": 32.47788619995117, "_runtime": 1750.4336371421814, "_timestamp": 1585571666.2782705, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41881850361824036, "Value Loss": 0.0143407192081213, "_runtime": 1751.5727534294128, "_timestamp": 1585571667.4173868, "_step": 58}
{"Episode reward": 27.499999999999844, "Episode length": 725, "Policy Loss": 0.631401002407074, "Value Loss": 13.586414337158203, "_runtime": 1753.0556852817535, "_timestamp": 1585571668.9003186, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34444770216941833, "Value Loss": 0.2143121361732483, "_runtime": 1754.6149625778198, "_timestamp": 1585571670.459596, "_step": 60}
{"Episode reward": -99.82236347794392, "Episode length": 999, "Policy Loss": -0.356635183095932, "Value Loss": 0.3214324712753296, "_runtime": 1755.6565477848053, "_timestamp": 1585571671.5011811, "_step": 61}
{"Episode reward": 32.93110716305627, "Episode length": 671, "Policy Loss": 0.7700283527374268, "Value Loss": 14.849246978759766, "_runtime": 1757.2035908699036, "_timestamp": 1585571673.0482242, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45430320501327515, "Value Loss": 0.13165798783302307, "_runtime": 1758.763789176941, "_timestamp": 1585571674.6084225, "_step": 63}
{"Episode reward": -99.87852962650219, "Episode length": 999, "Policy Loss": -0.4796798825263977, "Value Loss": 0.11799963563680649, "_runtime": 1760.298308134079, "_timestamp": 1585571676.1429415, "_step": 64}
{"Episode reward": -99.80039291716972, "Episode length": 999, "Policy Loss": -0.5453583598136902, "Value Loss": 0.12165994942188263, "_runtime": 1761.8582785129547, "_timestamp": 1585571677.7029119, "_step": 65}
{"Episode reward": -99.69085398837784, "Episode length": 999, "Policy Loss": -0.5698130130767822, "Value Loss": 0.07306787371635437, "_runtime": 1763.4145066738129, "_timestamp": 1585571679.25914, "_step": 66}
{"Episode reward": -99.62758149141307, "Episode length": 999, "Policy Loss": -0.62663334608078, "Value Loss": 0.07439328730106354, "_runtime": 1764.9748125076294, "_timestamp": 1585571680.8194458, "_step": 67}
{"Episode reward": -99.8662538766847, "Episode length": 999, "Policy Loss": -0.6363727450370789, "Value Loss": 0.15609511733055115, "_runtime": 1765.7032117843628, "_timestamp": 1585571681.5478451, "_step": 68}
{"Episode reward": 54.881469895969715, "Episode length": 453, "Policy Loss": 0.9763100743293762, "Value Loss": 21.62846565246582, "_runtime": 1766.930713891983, "_timestamp": 1585571682.7753472, "_step": 69}
{"Episode reward": 22.17777091963231, "Episode length": 780, "Policy Loss": 0.38845711946487427, "Value Loss": 12.551288604736328, "_runtime": 1768.4965896606445, "_timestamp": 1585571684.341223, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8047266602516174, "Value Loss": 0.05216149985790253, "_runtime": 1770.008623600006, "_timestamp": 1585571685.853257, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8699471354484558, "Value Loss": 0.01575184054672718, "_runtime": 1771.0898087024689, "_timestamp": 1585571686.934442, "_step": 72}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": 0.17650431394577026, "Value Loss": 14.154204368591309, "_runtime": 1772.6051194667816, "_timestamp": 1585571688.4497528, "_step": 73}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": -0.21530047059059143, "Value Loss": 9.950300216674805, "_runtime": 1774.1564676761627, "_timestamp": 1585571690.001101, "_step": 74}
{"Episode reward": -99.65961564862961, "Episode length": 999, "Policy Loss": -1.0427387952804565, "Value Loss": 0.14169026911258698, "_runtime": 1775.6783146858215, "_timestamp": 1585571691.522948, "_step": 75}
{"Episode reward": -99.8713047478334, "Episode length": 999, "Policy Loss": -1.0295937061309814, "Value Loss": 0.026496445760130882, "_runtime": 1776.9207105636597, "_timestamp": 1585571692.765344, "_step": 76}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": -0.10976386815309525, "Value Loss": 11.962071418762207, "_runtime": 1778.4665298461914, "_timestamp": 1585571694.3111632, "_step": 77}
{"Episode reward": -99.85531095899502, "Episode length": 999, "Policy Loss": -1.0494132041931152, "Value Loss": 0.11266695708036423, "_runtime": 1780.0299272537231, "_timestamp": 1585571695.8745606, "_step": 78}
{"Episode reward": -99.85577037492627, "Episode length": 999, "Policy Loss": -1.0926042795181274, "Value Loss": 0.2517625093460083, "_runtime": 1781.574158668518, "_timestamp": 1585571697.418792, "_step": 79}
{"Episode reward": -99.80951924361149, "Episode length": 999, "Policy Loss": -1.070354700088501, "Value Loss": 0.15018309652805328, "_runtime": 1782.5318322181702, "_timestamp": 1585571698.3764656, "_step": 80}
{"Episode reward": 39.17190042398811, "Episode length": 609, "Policy Loss": 0.0746239423751831, "Value Loss": 15.857866287231445, "_runtime": 1784.0833637714386, "_timestamp": 1585571699.927997, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0261868238449097, "Value Loss": 0.08031690120697021, "_runtime": 1785.5029745101929, "_timestamp": 1585571701.3476079, "_step": 82}
{"Episode reward": 9.162430482731153, "Episode length": 910, "Policy Loss": -0.16501659154891968, "Value Loss": 10.623262405395508, "_runtime": 1786.812546491623, "_timestamp": 1585571702.6571798, "_step": 83}
{"Episode reward": 13.900000000000617, "Episode length": 861, "Policy Loss": -0.06702859699726105, "Value Loss": 11.580334663391113, "_runtime": 1788.3608543872833, "_timestamp": 1585571704.2054877, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.977196455001831, "Value Loss": 0.2838497757911682, "_runtime": 1789.7114706039429, "_timestamp": 1585571705.556104, "_step": 85}
{"Episode reward": 13.218136382103623, "Episode length": 868, "Policy Loss": -0.04635923355817795, "Value Loss": 11.063887596130371, "_runtime": 1791.2464852333069, "_timestamp": 1585571707.0911186, "_step": 86}
{"Episode reward": -99.83052117386693, "Episode length": 999, "Policy Loss": -0.8757144808769226, "Value Loss": 0.03143875673413277, "_runtime": 1792.8093619346619, "_timestamp": 1585571708.6539953, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.837062418460846, "Value Loss": 0.028396010398864746, "_runtime": 1794.3969368934631, "_timestamp": 1585571710.2415702, "_step": 88}
{"Episode reward": -99.76495834775129, "Episode length": 999, "Policy Loss": -0.8010551333427429, "Value Loss": 0.02669917233288288, "_runtime": 1795.9615423679352, "_timestamp": 1585571711.8061757, "_step": 89}
{"Episode reward": -99.87973495870689, "Episode length": 999, "Policy Loss": -0.7645387649536133, "Value Loss": 0.04193291813135147, "_runtime": 1797.393767118454, "_timestamp": 1585571713.2384005, "_step": 90}
{"Episode reward": 8.100000000000946, "Episode length": 919, "Policy Loss": 0.08680929988622665, "Value Loss": 10.725850105285645, "_runtime": 1798.9661033153534, "_timestamp": 1585571714.8107367, "_step": 91}
{"Episode reward": -99.80099585391442, "Episode length": 999, "Policy Loss": -0.7222598791122437, "Value Loss": 0.06474203616380692, "_runtime": 1800.5297629833221, "_timestamp": 1585571716.3743963, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7195378541946411, "Value Loss": 0.06800714135169983, "_runtime": 1801.7190325260162, "_timestamp": 1585571717.5636659, "_step": 93}
{"Episode reward": 23.711960538849297, "Episode length": 763, "Policy Loss": 0.2372928112745285, "Value Loss": 12.760936737060547, "_runtime": 1803.2778313159943, "_timestamp": 1585571719.1224647, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6965817213058472, "Value Loss": 0.03817807510495186, "_runtime": 1804.8353011608124, "_timestamp": 1585571720.6799345, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7019321322441101, "Value Loss": 0.03270005062222481, "_runtime": 1806.3757719993591, "_timestamp": 1585571722.2204053, "_step": 96}
{"Episode reward": -99.85844072438637, "Episode length": 999, "Policy Loss": -0.7014704942703247, "Value Loss": 0.03446473181247711, "_runtime": 1807.9384620189667, "_timestamp": 1585571723.7830954, "_step": 97}
{"Episode reward": -99.87070369273285, "Episode length": 999, "Policy Loss": -0.709236204624176, "Value Loss": 0.017180772498250008, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428, 0.2373434156179428]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0], "bins": [-0.2373434156179428, -0.041530951857566833, 0.15428151190280914, 0.3500939607620239, 0.5459064245223999, 0.7417188882827759, 0.9375313520431519, 1.1333438158035278, 1.3291562795639038, 1.5249687433242798, 1.7207812070846558, 1.9165936708450317, 2.1124062538146973, 2.3082187175750732, 2.504031181335449, 2.699843645095825, 2.895656108856201, 3.091468572616577, 3.287281036376953, 3.483093500137329, 3.678905963897705, 3.874718189239502, 4.070530891418457, 4.266343593597412, 4.462155818939209, 4.657968044281006, 4.853780746459961, 5.049593448638916, 5.245405673980713, 5.44121789932251, 5.637030601501465, 5.83284330368042, 6.028655529022217, 6.224467754364014, 6.420280456542969, 6.616093158721924, 6.811905384063721, 7.007717609405518, 7.203530311584473, 7.399343013763428, 7.595155239105225, 7.7909674644470215, 7.986779689788818, 8.182592391967773, 8.37840461730957, 8.574216842651367, 8.77003002166748, 8.965842247009277, 9.161654472351074, 9.357466697692871, 9.553278923034668, 9.749092102050781, 9.944904327392578, 10.140716552734375, 10.336529731750488, 10.532341957092285, 10.728154182434082, 10.923966407775879, 11.119778633117676, 11.315591812133789, 11.511404037475586, 11.707216262817383, 11.903029441833496, 12.098841667175293, 12.29465389251709]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-3.8285799064396997e-07, 0.007924620993435383, 0.015849623829126358, 0.023774627596139908, 0.03169963136315346, 0.03962463513016701, 0.04754963889718056, 0.05547464266419411, 0.06339965015649796, 0.0713246539235115, 0.07924965769052505, 0.0871746614575386, 0.09509966522455215, 0.1030246689915657, 0.11094967275857925, 0.1188746765255928, 0.12679967284202576, 0.1347246766090393, 0.14264968037605286, 0.1505746841430664, 0.15849968791007996, 0.1664246916770935, 0.17434969544410706, 0.1822746992111206, 0.19019970297813416, 0.1981247067451477, 0.20604971051216125, 0.2139747142791748, 0.22189971804618835, 0.2298247218132019, 0.23774972558021545, 0.245674729347229, 0.25359973311424255, 0.2615247368812561, 0.26944974064826965, 0.2773747444152832, 0.28529974818229675, 0.2932247519493103, 0.30114975571632385, 0.3090747594833374, 0.31699976325035095, 0.3249247670173645, 0.33284977078437805, 0.3407747745513916, 0.34869977831840515, 0.3566247820854187, 0.36454978585243225, 0.3724747896194458, 0.38039979338645935, 0.3883247971534729, 0.39624980092048645, 0.4041748046875, 0.41209980845451355, 0.4200248122215271, 0.42794981598854065, 0.4358748197555542, 0.44379982352256775, 0.4517248272895813, 0.45964983105659485, 0.4675748348236084, 0.47549983859062195, 0.4834248423576355, 0.49134984612464905, 0.4992748498916626, 0.5071998834609985]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [11.0, 13.0, 19.0, 10.0, 14.0, 13.0, 18.0, 20.0, 5.0, 4.0, 9.0, 14.0, 7.0, 3.0, 1.0, 0.0, 0.0, 287.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 5.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0], "bins": [-0.4551200866699219, -0.4297916889190674, -0.4044632911682129, -0.3791349232196808, -0.3538065254688263, -0.3284781277179718, -0.3031497597694397, -0.2778213620185852, -0.2524929642677307, -0.22716456651687622, -0.20183616876602173, -0.17650780081748962, -0.15117940306663513, -0.12585100531578064, -0.10052263736724854, -0.07519423961639404, -0.04986584186553955, -0.02453744411468506, 0.0007909536361694336, 0.026119321584701538, 0.05144774913787842, 0.07677608728408813, 0.10210448503494263, 0.12743288278579712, 0.1527612805366516, 0.1780896782875061, 0.2034180760383606, 0.2287464737892151, 0.2540748119354248, 0.2794032096862793, 0.3047316074371338, 0.3300600051879883, 0.3553884029388428, 0.38071680068969727, 0.40604519844055176, 0.43137359619140625, 0.45670199394226074, 0.48203033208847046, 0.507358729839325, 0.5326871275901794, 0.5580155849456787, 0.5833438634872437, 0.6086722612380981, 0.6340006589889526, 0.6593290567398071, 0.6846574544906616, 0.7099858522415161, 0.7353142499923706, 0.7606426477432251, 0.7859710454940796, 0.8112994432449341, 0.8366278409957886, 0.8619562387466431, 0.8872846364974976, 0.912613034248352, 0.9379414319992065, 0.9632697105407715, 0.988598108291626, 1.0139265060424805, 1.039254903793335, 1.0645833015441895, 1.089911699295044, 1.1152400970458984, 1.140568494796753, 1.1658968925476074]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.7082209587097168, -1.5994054079055786, -1.4905898571014404, -1.3817744255065918, -1.272958755493164, -1.1641433238983154, -1.0553277730941772, -0.9465122222900391, -0.8376966714859009, -0.7288811206817627, -0.6200655698776245, -0.5112500190734863, -0.4024345874786377, -0.2936190366744995, -0.18480348587036133, -0.07598793506622314, 0.03282761573791504, 0.14164316654205322, 0.2504587173461914, 0.35927414894104004, 0.4680898189544678, 0.5769052505493164, 0.6857209205627441, 0.7945363521575928, 0.9033517837524414, 1.0121674537658691, 1.1209828853607178, 1.2297985553741455, 1.3386139869689941, 1.4474296569824219, 1.5562450885772705, 1.6650607585906982, 1.7738761901855469, 1.8826916217803955, 1.9915072917938232, 2.100322723388672, 2.2091383934020996, 2.3179540634155273, 2.426769256591797, 2.5355849266052246, 2.6444005966186523, 2.753215789794922, 2.8620314598083496, 2.9708471298217773, 3.079662799835205, 3.1884779930114746, 3.2972936630249023, 3.40610933303833, 3.5149245262145996, 3.6237401962280273, 3.732555866241455, 3.841371536254883, 3.9501867294311523, 4.05900239944458, 4.167818069458008, 4.2766337394714355, 4.385448932647705, 4.494264602661133, 4.6030802726745605, 4.71189546585083, 4.820711135864258, 4.9295268058776855, 5.038342475891113, 5.147157669067383, 5.2559733390808105]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 0.0, 6.0, 11.0, 9.0, 1.0, 3.0, 4.0, 2.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0], "bins": [-0.4083858132362366, -0.3998905122280121, -0.3913952112197876, -0.3828999102115631, -0.3744046092033386, -0.3659093379974365, -0.35741403698921204, -0.34891873598098755, -0.34042343497276306, -0.3319281339645386, -0.3234328329563141, -0.3149375319480896, -0.3064422607421875, -0.2979469299316406, -0.2894516587257385, -0.28095635771751404, -0.27246105670928955, -0.26396575570106506, -0.2554704546928406, -0.24697516858577728, -0.2384798675775528, -0.2299845665693283, -0.22148928046226501, -0.21299397945404053, -0.20449867844581604, -0.19600337743759155, -0.18750807642936707, -0.17901279032230377, -0.17051748931407928, -0.1620221883058548, -0.1535269021987915, -0.14503160119056702, -0.13653630018234253, -0.12804099917411804, -0.11954569816589355, -0.11105039715766907, -0.10255509614944458, -0.09405982494354248, -0.085564523935318, -0.0770692229270935, -0.06857392191886902, -0.06007862091064453, -0.051583319902420044, -0.04308801889419556, -0.03459274768829346, -0.02609744668006897, -0.017602145671844482, -0.009106844663619995, -0.0006115436553955078, 0.00788375735282898, 0.016379058361053467, 0.024874359369277954, 0.03336966037750244, 0.04186493158340454, 0.05036023259162903, 0.058855533599853516, 0.067350834608078, 0.07584613561630249, 0.08434143662452698, 0.09283673763275146, 0.10133200883865356, 0.10982733964920044, 0.11832261085510254, 0.12681794166564941, 0.1353132128715515]}, "_runtime": 1809.076031446457, "_timestamp": 1585571724.9206648, "_step": 98}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.2768738269805908, "Value Loss": 13.386363983154297, "_runtime": 1810.6384789943695, "_timestamp": 1585571726.4831123, "_step": 99}
{"Episode reward": -99.8687105808393, "Episode length": 999, "Policy Loss": -0.6835277080535889, "Value Loss": 0.14410148561000824, "_runtime": 1812.1940567493439, "_timestamp": 1585571728.03869, "_step": 100}
{"Episode reward": -99.8015512291328, "Episode length": 999, "Policy Loss": -0.7048752903938293, "Value Loss": 0.011596146039664745, "_runtime": 1813.4437880516052, "_timestamp": 1585571729.2884214, "_step": 101}
{"Episode reward": 19.436646912992302, "Episode length": 807, "Policy Loss": 0.22194702923297882, "Value Loss": 11.774595260620117, "_runtime": 1814.9979786872864, "_timestamp": 1585571730.842612, "_step": 102}
{"Episode reward": -99.79003917649248, "Episode length": 999, "Policy Loss": -0.7054207921028137, "Value Loss": 0.013143407180905342, "_runtime": 1816.5699710845947, "_timestamp": 1585571732.4146044, "_step": 103}
{"Episode reward": -99.80346090793469, "Episode length": 999, "Policy Loss": -0.693038821220398, "Value Loss": 0.00934078823775053, "_runtime": 1817.2671852111816, "_timestamp": 1585571733.1118186, "_step": 104}
{"Episode reward": 58.96155303679376, "Episode length": 411, "Policy Loss": 1.1930549144744873, "Value Loss": 23.395904541015625, "_runtime": 1818.1410052776337, "_timestamp": 1585571733.9856386, "_step": 105}
{"Episode reward": 45.0892933960999, "Episode length": 550, "Policy Loss": 0.6380660533905029, "Value Loss": 17.803646087646484, "_runtime": 1819.7077615261078, "_timestamp": 1585571735.5523949, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7017542123794556, "Value Loss": 0.01999281905591488, "_runtime": 1820.0165536403656, "_timestamp": 1585571735.861187, "_step": 107}
{"Episode reward": 81.60000000000002, "Episode length": 184, "Policy Loss": 3.226332664489746, "Value Loss": 52.232234954833984, "_runtime": 1821.5425548553467, "_timestamp": 1585571737.3871882, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7066349983215332, "Value Loss": 0.06720462441444397, "_runtime": 1823.1028141975403, "_timestamp": 1585571738.9474475, "_step": 109}
{"Episode reward": -99.81578933335702, "Episode length": 999, "Policy Loss": -0.7110784649848938, "Value Loss": 0.017937423661351204, "_runtime": 1824.5887925624847, "_timestamp": 1585571740.433426, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7155354022979736, "Value Loss": 0.0491027757525444, "_runtime": 1826.1538639068604, "_timestamp": 1585571741.9984972, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7078253030776978, "Value Loss": 0.02446645498275757, "_runtime": 1826.9800522327423, "_timestamp": 1585571742.8246856, "_step": 112}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 0.6632803678512573, "Value Loss": 18.4805965423584, "_runtime": 1828.0677618980408, "_timestamp": 1585571743.9123952, "_step": 113}
{"Episode reward": 29.199999999999747, "Episode length": 708, "Policy Loss": 0.2701817750930786, "Value Loss": 13.672650337219238, "_runtime": 1829.6281297206879, "_timestamp": 1585571745.472763, "_step": 114}
{"Episode reward": -99.80310601899261, "Episode length": 999, "Policy Loss": -0.665482759475708, "Value Loss": 0.05283357948064804, "_runtime": 1831.1456174850464, "_timestamp": 1585571746.9902508, "_step": 115}
{"Episode reward": -99.66393928639452, "Episode length": 999, "Policy Loss": -0.6380913853645325, "Value Loss": 0.06270153075456619, "_runtime": 1832.3270585536957, "_timestamp": 1585571748.171692, "_step": 116}
{"Episode reward": 22.80000000000011, "Episode length": 772, "Policy Loss": 0.2865036725997925, "Value Loss": 12.228090286254883, "_runtime": 1833.8765184879303, "_timestamp": 1585571749.7211518, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5844441652297974, "Value Loss": 0.009007805958390236, "_runtime": 1835.382215499878, "_timestamp": 1585571751.2268488, "_step": 118}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": 0.159454345703125, "Value Loss": 9.76462173461914, "_runtime": 1836.9228534698486, "_timestamp": 1585571752.7674868, "_step": 119}
{"Episode reward": -99.8430183544741, "Episode length": 999, "Policy Loss": -0.532687783241272, "Value Loss": 0.020356999710202217, "_runtime": 1838.0262887477875, "_timestamp": 1585571753.870922, "_step": 120}
{"Episode reward": 29.788275909051023, "Episode length": 703, "Policy Loss": 0.4749746322631836, "Value Loss": 13.608383178710938, "_runtime": 1839.5865802764893, "_timestamp": 1585571755.4312136, "_step": 121}
{"Episode reward": -99.6773347573341, "Episode length": 999, "Policy Loss": -0.4746463894844055, "Value Loss": 0.017748994752764702, "_runtime": 1840.2984681129456, "_timestamp": 1585571756.1431015, "_step": 122}
{"Episode reward": 55.78876580139587, "Episode length": 443, "Policy Loss": 1.0982955694198608, "Value Loss": 21.435626983642578, "_runtime": 1841.8666038513184, "_timestamp": 1585571757.7112372, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4377068877220154, "Value Loss": 0.04864896461367607, "_runtime": 1843.4065551757812, "_timestamp": 1585571759.2511885, "_step": 124}
{"Episode reward": -99.80020898915687, "Episode length": 999, "Policy Loss": -0.4431248605251312, "Value Loss": 0.014839578419923782, "_runtime": 1844.5790293216705, "_timestamp": 1585571760.4236627, "_step": 125}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.5467733144760132, "Value Loss": 12.452251434326172, "_runtime": 1846.1435775756836, "_timestamp": 1585571761.988211, "_step": 126}
{"Episode reward": -99.68497579973052, "Episode length": 999, "Policy Loss": -0.4261060655117035, "Value Loss": 0.10050154477357864, "_runtime": 1847.4377615451813, "_timestamp": 1585571763.282395, "_step": 127}
{"Episode reward": 16.78191518476278, "Episode length": 833, "Policy Loss": 0.4402288794517517, "Value Loss": 11.601240158081055, "_runtime": 1848.9558408260345, "_timestamp": 1585571764.8004742, "_step": 128}
{"Episode reward": -99.82052946099871, "Episode length": 999, "Policy Loss": -0.40557393431663513, "Value Loss": 0.06002264469861984, "_runtime": 1850.515673160553, "_timestamp": 1585571766.3603065, "_step": 129}
{"Episode reward": -99.62561906436319, "Episode length": 999, "Policy Loss": -0.40427786111831665, "Value Loss": 0.03939008712768555, "_runtime": 1852.0630023479462, "_timestamp": 1585571767.9076357, "_step": 130}
{"Episode reward": -99.88978325882786, "Episode length": 999, "Policy Loss": -0.4038481116294861, "Value Loss": 0.09257373213768005, "_runtime": 1853.5438315868378, "_timestamp": 1585571769.388465, "_step": 131}
{"Episode reward": 5.200000000001111, "Episode length": 948, "Policy Loss": 0.28121209144592285, "Value Loss": 9.941924095153809, "_runtime": 1855.1010510921478, "_timestamp": 1585571770.9456844, "_step": 132}
{"Episode reward": -99.80908736921707, "Episode length": 999, "Policy Loss": -0.4149511158466339, "Value Loss": 0.01325176190584898, "_runtime": 1856.6736826896667, "_timestamp": 1585571772.518316, "_step": 133}
{"Episode reward": -99.89898938275734, "Episode length": 999, "Policy Loss": -0.4225068986415863, "Value Loss": 0.039591509848833084, "_runtime": 1858.2333600521088, "_timestamp": 1585571774.0779934, "_step": 134}
{"Episode reward": -99.73262899238476, "Episode length": 999, "Policy Loss": -0.41858920454978943, "Value Loss": 0.14730313420295715, "_runtime": 1859.790953874588, "_timestamp": 1585571775.6355872, "_step": 135}
{"Episode reward": -99.86893564583595, "Episode length": 999, "Policy Loss": -0.40852510929107666, "Value Loss": 0.11020944267511368, "_runtime": 1861.3558549880981, "_timestamp": 1585571777.2004883, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3635089695453644, "Value Loss": 0.35826465487480164, "_runtime": 1862.5331268310547, "_timestamp": 1585571778.3777602, "_step": 137}
{"Episode reward": 25.199999999999974, "Episode length": 748, "Policy Loss": 0.5074384808540344, "Value Loss": 13.029080390930176, "_runtime": 1864.1333317756653, "_timestamp": 1585571779.977965, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3902660012245178, "Value Loss": 0.015237481333315372, "_runtime": 1865.286188840866, "_timestamp": 1585571781.1308222, "_step": 139}
{"Episode reward": 26.4999999999999, "Episode length": 735, "Policy Loss": 0.550199568271637, "Value Loss": 12.941447257995605, "_runtime": 1866.8340973854065, "_timestamp": 1585571782.6787307, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.387588232755661, "Value Loss": 0.015885736793279648, "_runtime": 1868.4037947654724, "_timestamp": 1585571784.248428, "_step": 141}
{"Episode reward": -99.81186786519689, "Episode length": 999, "Policy Loss": -0.3525272607803345, "Value Loss": 0.12331245094537735, "_runtime": 1869.2761619091034, "_timestamp": 1585571785.1207952, "_step": 142}
{"Episode reward": 44.543162486236035, "Episode length": 556, "Policy Loss": 0.9479663372039795, "Value Loss": 17.228511810302734, "_runtime": 1870.832255601883, "_timestamp": 1585571786.676889, "_step": 143}
{"Episode reward": -99.77305902484665, "Episode length": 999, "Policy Loss": -0.38455116748809814, "Value Loss": 0.01668747514486313, "_runtime": 1872.3999383449554, "_timestamp": 1585571788.2445717, "_step": 144}
{"Episode reward": -99.89070516228536, "Episode length": 999, "Policy Loss": -0.3925251066684723, "Value Loss": 0.007051260210573673, "_runtime": 1873.921825170517, "_timestamp": 1585571789.7664585, "_step": 145}
{"Episode reward": -99.89817127967113, "Episode length": 999, "Policy Loss": -0.39075663685798645, "Value Loss": 0.04375934600830078, "_runtime": 1875.47847032547, "_timestamp": 1585571791.3231037, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37970829010009766, "Value Loss": 0.09745384752750397, "_runtime": 1876.5371565818787, "_timestamp": 1585571792.38179, "_step": 147}
{"Episode reward": 32.5533372021043, "Episode length": 675, "Policy Loss": 0.6105400919914246, "Value Loss": 14.274805068969727, "_runtime": 1876.9916577339172, "_timestamp": 1585571792.836291, "_step": 148}
{"Episode reward": 73.1999999999999, "Episode length": 268, "Policy Loss": 2.358173131942749, "Value Loss": 36.864112854003906, "_runtime": 1878.5305845737457, "_timestamp": 1585571794.375218, "_step": 149}
{"Episode reward": -99.74945813845703, "Episode length": 999, "Policy Loss": -0.4056303799152374, "Value Loss": 0.10752049088478088, "_runtime": 1879.979880809784, "_timestamp": 1585571795.8245142, "_step": 150}
{"Episode reward": 5.7002076442364285, "Episode length": 944, "Policy Loss": 0.27033740282058716, "Value Loss": 9.953832626342773, "_runtime": 1881.1221792697906, "_timestamp": 1585571796.9668126, "_step": 151}
{"Episode reward": 22.098381309118267, "Episode length": 780, "Policy Loss": 0.47160765528678894, "Value Loss": 12.611452102661133, "_runtime": 1882.2265949249268, "_timestamp": 1585571798.0712283, "_step": 152}
{"Episode reward": 29.37419045930703, "Episode length": 708, "Policy Loss": 0.5261960625648499, "Value Loss": 13.440651893615723, "_runtime": 1883.781198501587, "_timestamp": 1585571799.6258318, "_step": 153}
{"Episode reward": -99.6511064679348, "Episode length": 999, "Policy Loss": -0.4217207133769989, "Value Loss": 0.021934818476438522, "_runtime": 1885.3037667274475, "_timestamp": 1585571801.1484, "_step": 154}
{"Episode reward": -99.719727423972, "Episode length": 999, "Policy Loss": -0.4259572923183441, "Value Loss": 0.011966852471232414, "_runtime": 1886.8728110790253, "_timestamp": 1585571802.7174444, "_step": 155}
{"Episode reward": -99.78775140428776, "Episode length": 999, "Policy Loss": -0.42861008644104004, "Value Loss": 0.023364568129181862, "_runtime": 1887.7468163967133, "_timestamp": 1585571803.5914497, "_step": 156}
{"Episode reward": 45.14392381571183, "Episode length": 549, "Policy Loss": 0.7633338570594788, "Value Loss": 17.853845596313477, "_runtime": 1889.2825717926025, "_timestamp": 1585571805.1272051, "_step": 157}
{"Episode reward": -99.80158316725725, "Episode length": 999, "Policy Loss": -0.4271089434623718, "Value Loss": 0.005401015747338533, "_runtime": 1890.729774236679, "_timestamp": 1585571806.5744076, "_step": 158}
{"Episode reward": 7.763892435539546, "Episode length": 924, "Policy Loss": 0.28010615706443787, "Value Loss": 9.82898998260498, "_runtime": 1892.2591466903687, "_timestamp": 1585571808.10378, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4261474907398224, "Value Loss": 0.006654274184256792, "_runtime": 1893.8177070617676, "_timestamp": 1585571809.6623404, "_step": 160}
{"Episode reward": -99.73562976254476, "Episode length": 999, "Policy Loss": -0.41572022438049316, "Value Loss": 0.021802568808197975, "_runtime": 1895.373037815094, "_timestamp": 1585571811.2176712, "_step": 161}
{"Episode reward": -99.60501610995131, "Episode length": 999, "Policy Loss": -0.39220258593559265, "Value Loss": 0.18245063722133636, "_runtime": 1896.9124476909637, "_timestamp": 1585571812.757081, "_step": 162}
{"Episode reward": -99.7020564459716, "Episode length": 999, "Policy Loss": -0.4043140709400177, "Value Loss": 0.017918923869729042, "_runtime": 1898.4668326377869, "_timestamp": 1585571814.311466, "_step": 163}
{"Episode reward": -99.69583452069061, "Episode length": 999, "Policy Loss": -0.3813888728618622, "Value Loss": 0.12161976844072342, "_runtime": 1899.4983484745026, "_timestamp": 1585571815.3429818, "_step": 164}
{"Episode reward": 34.496043532038485, "Episode length": 657, "Policy Loss": 0.8265937566757202, "Value Loss": 21.00877571105957, "_runtime": 1900.1241614818573, "_timestamp": 1585571815.9687948, "_step": 165}
{"Episode reward": 61.872583918593314, "Episode length": 384, "Policy Loss": 1.5277491807937622, "Value Loss": 25.375154495239258, "_runtime": 1901.6701428890228, "_timestamp": 1585571817.5147762, "_step": 166}
{"Episode reward": -99.70739205316501, "Episode length": 999, "Policy Loss": -0.33546802401542664, "Value Loss": 0.024683455005288124, "_runtime": 1903.2136566638947, "_timestamp": 1585571819.05829, "_step": 167}
{"Episode reward": -99.3995129312375, "Episode length": 999, "Policy Loss": -0.3258810341358185, "Value Loss": 0.036207184195518494, "_runtime": 1904.7115442752838, "_timestamp": 1585571820.5561776, "_step": 168}
{"Episode reward": -99.84705372494506, "Episode length": 999, "Policy Loss": -0.31019455194473267, "Value Loss": 0.05144820362329483, "_runtime": 1906.2029230594635, "_timestamp": 1585571822.0475564, "_step": 169}
{"Episode reward": 4.144253561460644, "Episode length": 960, "Policy Loss": 0.5516244173049927, "Value Loss": 10.363656997680664, "_runtime": 1907.7624447345734, "_timestamp": 1585571823.607078, "_step": 170}
{"Episode reward": -99.68091136307784, "Episode length": 999, "Policy Loss": -0.3087996244430542, "Value Loss": 0.1036686822772026, "_runtime": 1908.3727390766144, "_timestamp": 1585571824.2173724, "_step": 171}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 1.3492839336395264, "Value Loss": 26.539466857910156, "_runtime": 1909.9518432617188, "_timestamp": 1585571825.7964766, "_step": 172}
{"Episode reward": -99.70494085298712, "Episode length": 999, "Policy Loss": -0.4033195674419403, "Value Loss": 0.049202483147382736, "_runtime": 1911.5184588432312, "_timestamp": 1585571827.3630922, "_step": 173}
{"Episode reward": -99.89871024042228, "Episode length": 999, "Policy Loss": -0.45529091358184814, "Value Loss": 0.031232604756951332, "_runtime": 1912.2202551364899, "_timestamp": 1585571828.0648885, "_step": 174}
{"Episode reward": 53.881159928347536, "Episode length": 462, "Policy Loss": 0.9022650718688965, "Value Loss": 21.504236221313477, "_runtime": 1913.7669913768768, "_timestamp": 1585571829.6116247, "_step": 175}
{"Episode reward": -99.66339966589446, "Episode length": 999, "Policy Loss": -0.5431466102600098, "Value Loss": 0.03313329070806503, "_runtime": 1914.5231792926788, "_timestamp": 1585571830.3678126, "_step": 176}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": 1.212730884552002, "Value Loss": 20.941801071166992, "_runtime": 1916.0341708660126, "_timestamp": 1585571831.8788042, "_step": 177}
{"Episode reward": -99.80001278428686, "Episode length": 999, "Policy Loss": -0.6985272169113159, "Value Loss": 0.011975709348917007, "_runtime": 1917.1710457801819, "_timestamp": 1585571833.0156791, "_step": 178}
{"Episode reward": 26.998254717420664, "Episode length": 732, "Policy Loss": 0.11362115293741226, "Value Loss": 13.385591506958008, "_runtime": 1918.6779012680054, "_timestamp": 1585571834.5225346, "_step": 179}
{"Episode reward": -99.84646339416364, "Episode length": 999, "Policy Loss": -0.8204848170280457, "Value Loss": 0.01705501228570938, "_runtime": 1919.5327434539795, "_timestamp": 1585571835.3773768, "_step": 180}
{"Episode reward": 46.196867030858506, "Episode length": 539, "Policy Loss": 0.38025161623954773, "Value Loss": 17.876815795898438, "_runtime": 1920.0134348869324, "_timestamp": 1585571835.8580682, "_step": 181}
{"Episode reward": 70.49999999999986, "Episode length": 295, "Policy Loss": 1.3315588235855103, "Value Loss": 33.08577346801758, "_runtime": 1921.5364422798157, "_timestamp": 1585571837.3810756, "_step": 182}
{"Episode reward": -99.8022902787649, "Episode length": 999, "Policy Loss": -0.9603164196014404, "Value Loss": 0.036324262619018555, "_runtime": 1922.2267842292786, "_timestamp": 1585571838.0714176, "_step": 183}
{"Episode reward": 55.33978224843705, "Episode length": 447, "Policy Loss": 0.5724645853042603, "Value Loss": 21.483728408813477, "_runtime": 1922.695674419403, "_timestamp": 1585571838.5403078, "_step": 184}
{"Episode reward": 69.29999999999984, "Episode length": 307, "Policy Loss": 1.172648549079895, "Value Loss": 31.54312515258789, "_runtime": 1923.9604721069336, "_timestamp": 1585571839.8051054, "_step": 185}
{"Episode reward": 17.592989355489095, "Episode length": 828, "Policy Loss": -0.31983682513237, "Value Loss": 12.249223709106445, "_runtime": 1925.4640202522278, "_timestamp": 1585571841.3086536, "_step": 186}
{"Episode reward": -99.60763444015618, "Episode length": 999, "Policy Loss": -1.1200745105743408, "Value Loss": 0.15969978272914886, "_runtime": 1926.938975572586, "_timestamp": 1585571842.783609, "_step": 187}
{"Episode reward": -99.79855782426755, "Episode length": 999, "Policy Loss": -1.1571307182312012, "Value Loss": 0.3104438781738281, "_runtime": 1927.558256149292, "_timestamp": 1585571843.4028895, "_step": 188}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": 0.8073967099189758, "Value Loss": 25.162662506103516, "_runtime": 1928.891135931015, "_timestamp": 1585571844.7357693, "_step": 189}
{"Episode reward": 12.982042278629464, "Episode length": 872, "Policy Loss": -0.32453110814094543, "Value Loss": 11.008572578430176, "_runtime": 1929.732147693634, "_timestamp": 1585571845.576781, "_step": 190}
{"Episode reward": 46.15368520226281, "Episode length": 539, "Policy Loss": 0.15020978450775146, "Value Loss": 18.069108963012695, "_runtime": 1930.2103657722473, "_timestamp": 1585571846.054999, "_step": 191}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 1.458807110786438, "Value Loss": 31.22743034362793, "_runtime": 1931.0326895713806, "_timestamp": 1585571846.877323, "_step": 192}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 0.15856055915355682, "Value Loss": 17.61606788635254, "_runtime": 1932.5504276752472, "_timestamp": 1585571848.395061, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.015454888343811, "Value Loss": 0.03461787477135658, "_runtime": 1933.1353690624237, "_timestamp": 1585571848.9800024, "_step": 194}
{"Episode reward": 61.383771406090545, "Episode length": 387, "Policy Loss": 0.7679393887519836, "Value Loss": 24.695877075195312, "_runtime": 1934.6569724082947, "_timestamp": 1585571850.5016057, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.956196665763855, "Value Loss": 0.15708652138710022, "_runtime": 1936.1949989795685, "_timestamp": 1585571852.0396323, "_step": 196}
{"Episode reward": -99.80331938909227, "Episode length": 999, "Policy Loss": -0.9439356923103333, "Value Loss": 0.06446567922830582, "_runtime": 1936.7641940116882, "_timestamp": 1585571852.6088274, "_step": 197}
{"Episode reward": 62.99999999999975, "Episode length": 370, "Policy Loss": 0.9599968194961548, "Value Loss": 25.582252502441406, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367, -0.009563464671373367]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.18553690612316132, -0.1819671243429184, -0.17839732766151428, -0.17482754588127136, -0.17125774919986725, -0.16768796741962433, -0.16411817073822021, -0.1605483889579773, -0.15697860717773438, -0.15340881049633026, -0.14983902871608734, -0.14626923203468323, -0.1426994502544403, -0.1391296684741974, -0.13555987179279327, -0.13199009001255035, -0.12842029333114624, -0.12485051155090332, -0.1212807223200798, -0.11771094053983688, -0.11414115130901337, -0.11057136207818985, -0.10700157284736633, -0.10343178361654282, -0.0998619943857193, -0.09629221260547638, -0.09272242337465286, -0.08915263414382935, -0.08558284491300583, -0.08201305568218231, -0.07844327390193939, -0.07487348467111588, -0.07130369544029236, -0.06773390620946884, -0.06416411697864532, -0.060594335198402405, -0.05702453851699829, -0.05345475673675537, -0.04988497495651245, -0.04631517827510834, -0.04274539649486542, -0.039175599813461304, -0.035605818033218384, -0.032036036252975464, -0.02846623957157135, -0.02489645779132843, -0.021326661109924316, -0.017756879329681396, -0.014187082648277283, -0.010617300868034363, -0.007047519087791443, -0.003477722406387329, 9.205937385559082e-05, 0.0036618560552597046, 0.0072316378355026245, 0.010801419615745544, 0.014371216297149658, 0.017940998077392578, 0.021510794758796692, 0.025080576539039612, 0.028650358319282532, 0.032220155000686646, 0.035789936780929565, 0.03935973346233368, 0.0429295152425766]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01757502369582653, -0.017228685319423676, -0.01688234694302082, -0.016536008566617966, -0.01618966832756996, -0.015843329951167107, -0.015496991574764252, -0.015150653198361397, -0.014804314821958542, -0.014457976445555687, -0.014111637137830257, -0.013765298761427402, -0.013418959453701973, -0.013072621077299118, -0.012726282700896263, -0.012379944324493408, -0.012033605948090553, -0.011687266640365124, -0.011340928263962269, -0.01099458895623684, -0.010648250579833984, -0.01030191220343113, -0.009955573827028275, -0.00960923545062542, -0.00926289614289999, -0.008916557766497135, -0.00857021939009428, -0.00822388008236885, -0.007877541705965996, -0.007531203329563141, -0.007184864953160286, -0.006838525645434856, -0.0064921872690320015, -0.006145848892629147, -0.005799509584903717, -0.005453171208500862, -0.005106832832098007, -0.004760494455695152, -0.004414155147969723, -0.004067816771566868, -0.003721478395164013, -0.0033751390874385834, -0.0030288007110357285, -0.0026824623346328735, -0.0023361239582300186, -0.001989784650504589, -0.0016434472054243088, -0.0012971069663763046, -0.0009507685899734497, -0.0006044302135705948, -0.00025809183716773987, 8.824653923511505e-05, 0.00043458491563796997, 0.0007809232920408249, 0.001127263531088829, 0.001473601907491684, 0.0018199402838945389, 0.002166278660297394, 0.0025126170367002487, 0.0028589554131031036, 0.0032052937895059586, 0.0035516340285539627, 0.0038979724049568176, 0.0042443107813596725, 0.0045906491577625275]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 19.0, 4.0, 291.0, 0.0, 4.0, 23.0, 30.0, 28.0, 18.0, 20.0, 8.0, 3.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-0.06746664643287659, -0.06539183109998703, -0.06331701576709747, -0.061242200434207916, -0.05916738510131836, -0.0570925697684288, -0.05501775071024895, -0.05294293537735939, -0.05086812004446983, -0.048793304711580276, -0.04671848937869072, -0.044643670320510864, -0.04256885498762131, -0.04049403965473175, -0.038419224321842194, -0.03634440898895264, -0.03426959365606308, -0.03219477832317352, -0.030119962990283966, -0.02804514765739441, -0.025970332324504852, -0.023895513266324997, -0.02182069793343544, -0.019745882600545883, -0.017671067267656326, -0.01559625193476677, -0.013521436601877213, -0.011446621268987656, -0.0093718022108078, -0.007296986877918243, -0.0052221715450286865, -0.0031473562121391296, -0.0010725408792495728, 0.0010022744536399841, 0.003077089786529541, 0.005151905119419098, 0.007226720452308655, 0.009301535785198212, 0.011376351118087769, 0.013451166450977325, 0.015525981783866882, 0.017600804567337036, 0.019675619900226593, 0.02175043523311615, 0.023825250566005707, 0.025900065898895264, 0.02797488123178482, 0.030049696564674377, 0.032124511897563934, 0.03419932723045349, 0.03627414256334305, 0.038348957896232605, 0.04042377322912216, 0.04249858856201172, 0.044573403894901276, 0.04664821922779083, 0.048723042011260986, 0.05079785734415054, 0.0528726726770401, 0.05494748800992966, 0.057022303342819214, 0.059097111225128174, 0.06117193400859833, 0.06324674189090729, 0.06532156467437744]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1244569644331932, -0.11979857832193375, -0.11514018476009369, -0.11048179864883423, -0.10582340508699417, -0.10116501897573471, -0.09650662541389465, -0.09184823930263519, -0.08718985319137573, -0.08253145962953568, -0.07787306606769562, -0.07321467995643616, -0.0685562938451767, -0.06389790773391724, -0.05923951417207718, -0.05458112061023712, -0.04992273449897766, -0.0452643483877182, -0.04060595482587814, -0.03594756871461868, -0.031289175152778625, -0.026630789041519165, -0.021972395479679108, -0.017314009368419647, -0.012655623257160187, -0.00799722969532013, -0.003338843584060669, 0.0013195499777793884, 0.005977936089038849, 0.01063632220029831, 0.015294723212718964, 0.019953109323978424, 0.024611495435237885, 0.029269881546497345, 0.033928267657756805, 0.03858666867017746, 0.04324505478143692, 0.04790344089269638, 0.05256182700395584, 0.057220228016376495, 0.061878614127635956, 0.06653700023889542, 0.07119538635015488, 0.07585377246141434, 0.08051217347383499, 0.08517055958509445, 0.08982894569635391, 0.09448733180761337, 0.09914571791887283, 0.10380411893129349, 0.10846250504255295, 0.11312089115381241, 0.11777927726507187, 0.12243767827749252, 0.1270960569381714, 0.13175445795059204, 0.1364128291606903, 0.14107123017311096, 0.14572960138320923, 0.15038800239562988, 0.15504640340805054, 0.1597047746181488, 0.16436317563056946, 0.16902154684066772, 0.17367994785308838]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 6.0, 1.0, 7.0, 5.0, 3.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.22115224599838257, -0.2098844349384308, -0.198616623878479, -0.18734881281852722, -0.17608100175857544, -0.16481319069862366, -0.15354536473751068, -0.1422775536775589, -0.13100974261760712, -0.11974193155765533, -0.10847412049770355, -0.09720630198717117, -0.0859384834766388, -0.07467067241668701, -0.06340286135673523, -0.05213505029678345, -0.040867239236831665, -0.029599428176879883, -0.0183316171169281, -0.007063806056976318, 0.004204005002975464, 0.01547183096408844, 0.026739642024040222, 0.03800743818283081, 0.04927527904510498, 0.06054309010505676, 0.07181090116500854, 0.08307871222496033, 0.09434652328491211, 0.10561433434486389, 0.11688214540481567, 0.12814995646476746, 0.13941776752471924, 0.15068557858467102, 0.1619533896446228, 0.17322120070457458, 0.18448901176452637, 0.19575682282447815, 0.20702463388442993, 0.2182924449443817, 0.2295602560043335, 0.24082809686660767, 0.25209590792655945, 0.26336371898651123, 0.274631530046463, 0.2858993411064148, 0.2971671223640442, 0.30843496322631836, 0.31970280408859253, 0.3309705853462219, 0.3422384262084961, 0.3535062074661255, 0.36477404832839966, 0.37604182958602905, 0.3873096704483032, 0.3985774517059326, 0.4098452925682068, 0.4211130738258362, 0.43238091468811035, 0.44364869594573975, 0.4549165368080139, 0.4661843180656433, 0.4774521589279175, 0.4887199401855469, 0.49998778104782104]}, "_runtime": 1938.289654493332, "_timestamp": 1585571854.1342878, "_step": 198}
{"Episode reward": -99.8004577533328, "Episode length": 999, "Policy Loss": -0.8763015270233154, "Value Loss": 0.11570414900779724, "_runtime": 1939.8347749710083, "_timestamp": 1585571855.6794083, "_step": 199}
{"Episode reward": -99.70848475815589, "Episode length": 999, "Policy Loss": -0.8386869430541992, "Value Loss": 0.025763966143131256, "_runtime": 1941.3380229473114, "_timestamp": 1585571857.1826563, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7840654850006104, "Value Loss": 0.07840358465909958, "_runtime": 1942.89750289917, "_timestamp": 1585571858.7421362, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7500062584877014, "Value Loss": 0.1832607537508011, "_runtime": 1944.478459596634, "_timestamp": 1585571860.323093, "_step": 202}
{"Episode reward": -99.82959658244951, "Episode length": 999, "Policy Loss": -0.7355439066886902, "Value Loss": 0.14199745655059814, "_runtime": 1946.0279009342194, "_timestamp": 1585571861.8725343, "_step": 203}
{"Episode reward": -99.63933225478839, "Episode length": 999, "Policy Loss": -0.707486629486084, "Value Loss": 0.019636059179902077, "_runtime": 1947.464269399643, "_timestamp": 1585571863.3089027, "_step": 204}
{"Episode reward": 8.40000000000093, "Episode length": 916, "Policy Loss": 0.10284511744976044, "Value Loss": 10.25700855255127, "_runtime": 1949.0342335700989, "_timestamp": 1585571864.878867, "_step": 205}
{"Episode reward": -99.66666985459022, "Episode length": 999, "Policy Loss": -0.6042697429656982, "Value Loss": 0.19440966844558716, "_runtime": 1950.6018116474152, "_timestamp": 1585571866.446445, "_step": 206}
{"Episode reward": -99.8001139227287, "Episode length": 999, "Policy Loss": -0.5882675051689148, "Value Loss": 0.052358854562044144, "_runtime": 1952.1669781208038, "_timestamp": 1585571868.0116115, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5769435167312622, "Value Loss": 0.15148653090000153, "_runtime": 1953.7353315353394, "_timestamp": 1585571869.5799649, "_step": 208}
{"Episode reward": -99.8005989611135, "Episode length": 999, "Policy Loss": -0.5232700705528259, "Value Loss": 0.07638303190469742, "_runtime": 1955.2989311218262, "_timestamp": 1585571871.1435645, "_step": 209}
{"Episode reward": -99.75581326084072, "Episode length": 999, "Policy Loss": -0.48618221282958984, "Value Loss": 0.05475322902202606, "_runtime": 1956.8492364883423, "_timestamp": 1585571872.6938698, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5063214898109436, "Value Loss": 0.013815845362842083, "_runtime": 1958.4092128276825, "_timestamp": 1585571874.2538462, "_step": 211}
{"Episode reward": 1.5872071555828882, "Episode length": 986, "Policy Loss": 0.3012551963329315, "Value Loss": 10.015427589416504, "_runtime": 1959.962733745575, "_timestamp": 1585571875.807367, "_step": 212}
{"Episode reward": -99.65124601118593, "Episode length": 999, "Policy Loss": -0.4560047686100006, "Value Loss": 0.04900256544351578, "_runtime": 1960.9173438549042, "_timestamp": 1585571876.7619772, "_step": 213}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 0.5904656052589417, "Value Loss": 15.579520225524902, "_runtime": 1961.5433857440948, "_timestamp": 1585571877.388019, "_step": 214}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.2923784255981445, "Value Loss": 24.449779510498047, "_runtime": 1963.0904994010925, "_timestamp": 1585571878.9351327, "_step": 215}
{"Episode reward": -99.75859838111651, "Episode length": 999, "Policy Loss": -0.4552997648715973, "Value Loss": 0.021740427240729332, "_runtime": 1964.2832744121552, "_timestamp": 1585571880.1279078, "_step": 216}
{"Episode reward": 21.897866731509737, "Episode length": 782, "Policy Loss": 0.35466596484184265, "Value Loss": 12.120957374572754, "_runtime": 1965.5611255168915, "_timestamp": 1585571881.4057589, "_step": 217}
{"Episode reward": 14.557165595517134, "Episode length": 855, "Policy Loss": 0.3461189568042755, "Value Loss": 11.027320861816406, "_runtime": 1967.0760986804962, "_timestamp": 1585571882.920732, "_step": 218}
{"Episode reward": 2.2889532214974793, "Episode length": 978, "Policy Loss": 0.4481111168861389, "Value Loss": 9.738641738891602, "_runtime": 1968.6105377674103, "_timestamp": 1585571884.455171, "_step": 219}
{"Episode reward": -99.80053420895571, "Episode length": 999, "Policy Loss": -0.4777642488479614, "Value Loss": 0.020455554127693176, "_runtime": 1970.141081571579, "_timestamp": 1585571885.985715, "_step": 220}
{"Episode reward": -99.70150020152657, "Episode length": 999, "Policy Loss": -0.34423357248306274, "Value Loss": 0.6299434304237366, "_runtime": 1971.2628166675568, "_timestamp": 1585571887.10745, "_step": 221}
{"Episode reward": 28.686412106896526, "Episode length": 715, "Policy Loss": 0.4951093792915344, "Value Loss": 13.293844223022461, "_runtime": 1972.1990413665771, "_timestamp": 1585571888.0436747, "_step": 222}
{"Episode reward": 40.49800223929285, "Episode length": 596, "Policy Loss": 0.6808738708496094, "Value Loss": 16.009483337402344, "_runtime": 1973.3037462234497, "_timestamp": 1585571889.1483796, "_step": 223}
{"Episode reward": 28.899999999999764, "Episode length": 711, "Policy Loss": 0.555552065372467, "Value Loss": 13.526954650878906, "_runtime": 1974.8334712982178, "_timestamp": 1585571890.6781046, "_step": 224}
{"Episode reward": -99.70652567292426, "Episode length": 999, "Policy Loss": -0.4832031726837158, "Value Loss": 0.011767890304327011, "_runtime": 1976.3608696460724, "_timestamp": 1585571892.205503, "_step": 225}
{"Episode reward": -99.81915397876735, "Episode length": 999, "Policy Loss": -0.4738808572292328, "Value Loss": 0.010067500174045563, "_runtime": 1977.889521598816, "_timestamp": 1585571893.734155, "_step": 226}
{"Episode reward": -99.64352604052844, "Episode length": 999, "Policy Loss": -0.46684694290161133, "Value Loss": 0.040665555745363235, "_runtime": 1978.4948861598969, "_timestamp": 1585571894.3395195, "_step": 227}
{"Episode reward": 62.89980674681694, "Episode length": 372, "Policy Loss": 1.3551863431930542, "Value Loss": 25.226383209228516, "_runtime": 1980.0846014022827, "_timestamp": 1585571895.9292347, "_step": 228}
{"Episode reward": -99.7256319558234, "Episode length": 999, "Policy Loss": -0.48014742136001587, "Value Loss": 0.016119714826345444, "_runtime": 1981.6466219425201, "_timestamp": 1585571897.4912553, "_step": 229}
{"Episode reward": -99.6865141396397, "Episode length": 999, "Policy Loss": -0.46738359332084656, "Value Loss": 0.034854594618082047, "_runtime": 1983.152839899063, "_timestamp": 1585571898.9974732, "_step": 230}
{"Episode reward": -99.81672768611323, "Episode length": 999, "Policy Loss": -0.46982061862945557, "Value Loss": 0.01307428814470768, "_runtime": 1984.7139909267426, "_timestamp": 1585571900.5586243, "_step": 231}
{"Episode reward": -99.70635449103874, "Episode length": 999, "Policy Loss": -0.4647230803966522, "Value Loss": 0.016126176342368126, "_runtime": 1986.2714936733246, "_timestamp": 1585571902.116127, "_step": 232}
{"Episode reward": -99.87283326471085, "Episode length": 999, "Policy Loss": -0.45643818378448486, "Value Loss": 0.030393239110708237, "_runtime": 1987.041041135788, "_timestamp": 1585571902.8856745, "_step": 233}
{"Episode reward": 51.74352671781048, "Episode length": 484, "Policy Loss": 0.9635968804359436, "Value Loss": 20.26259994506836, "_runtime": 1988.597655057907, "_timestamp": 1585571904.4422884, "_step": 234}
{"Episode reward": -99.86183407166833, "Episode length": 999, "Policy Loss": -0.44212427735328674, "Value Loss": 0.01734429970383644, "_runtime": 1990.098084449768, "_timestamp": 1585571905.9427178, "_step": 235}
{"Episode reward": 3.872884918657391, "Episode length": 962, "Policy Loss": 0.2468632310628891, "Value Loss": 9.934659957885742, "_runtime": 1991.6097016334534, "_timestamp": 1585571907.454335, "_step": 236}
{"Episode reward": -99.8245202829116, "Episode length": 999, "Policy Loss": -0.4396823048591614, "Value Loss": 0.020207053050398827, "_runtime": 1993.170737504959, "_timestamp": 1585571909.0153708, "_step": 237}
{"Episode reward": -99.80983823872963, "Episode length": 999, "Policy Loss": -0.4296780228614807, "Value Loss": 0.009987211786210537, "_runtime": 1994.7144367694855, "_timestamp": 1585571910.55907, "_step": 238}
{"Episode reward": -99.82175006307521, "Episode length": 999, "Policy Loss": -0.41350534558296204, "Value Loss": 0.027768993750214577, "_runtime": 1995.8525235652924, "_timestamp": 1585571911.697157, "_step": 239}
{"Episode reward": 26.993440562952188, "Episode length": 732, "Policy Loss": 0.5386744141578674, "Value Loss": 13.25222396850586, "_runtime": 1997.4208180904388, "_timestamp": 1585571913.2654514, "_step": 240}
{"Episode reward": -99.83615837693075, "Episode length": 999, "Policy Loss": -0.40108245611190796, "Value Loss": 0.07727089524269104, "_runtime": 1998.9789712429047, "_timestamp": 1585571914.8236046, "_step": 241}
{"Episode reward": -99.6586968401666, "Episode length": 999, "Policy Loss": -0.37190982699394226, "Value Loss": 0.1521490514278412, "_runtime": 2000.1433424949646, "_timestamp": 1585571915.9879758, "_step": 242}
{"Episode reward": 24.84628043724223, "Episode length": 752, "Policy Loss": 0.8012109994888306, "Value Loss": 12.679974555969238, "_runtime": 2001.6976552009583, "_timestamp": 1585571917.5422885, "_step": 243}
{"Episode reward": -99.77930286917696, "Episode length": 999, "Policy Loss": -0.361463338136673, "Value Loss": 0.06392485648393631, "_runtime": 2003.2531342506409, "_timestamp": 1585571919.0977676, "_step": 244}
{"Episode reward": 2.9907117667620327, "Episode length": 972, "Policy Loss": 0.4492444694042206, "Value Loss": 10.051265716552734, "_runtime": 2004.7898824214935, "_timestamp": 1585571920.6345158, "_step": 245}
{"Episode reward": -99.8174468354308, "Episode length": 999, "Policy Loss": -0.35214680433273315, "Value Loss": 0.04493720456957817, "_runtime": 2006.360387802124, "_timestamp": 1585571922.2050211, "_step": 246}
{"Episode reward": -99.78074767626683, "Episode length": 999, "Policy Loss": -0.33846837282180786, "Value Loss": 0.03848494216799736, "_runtime": 2006.7485091686249, "_timestamp": 1585571922.5931425, "_step": 247}
{"Episode reward": 78.54361258707938, "Episode length": 215, "Policy Loss": 2.7869887351989746, "Value Loss": 44.33872985839844, "_runtime": 2008.2925152778625, "_timestamp": 1585571924.1371486, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3314858078956604, "Value Loss": 0.020737631246447563, "_runtime": 2009.5966515541077, "_timestamp": 1585571925.441285, "_step": 249}
{"Episode reward": 16.10000000000049, "Episode length": 839, "Policy Loss": 0.4716608226299286, "Value Loss": 11.163625717163086, "_runtime": 2011.0866119861603, "_timestamp": 1585571926.9312453, "_step": 250}
{"Episode reward": -99.71852765166993, "Episode length": 999, "Policy Loss": -0.3338871896266937, "Value Loss": 0.037690408527851105, "_runtime": 2012.6481759548187, "_timestamp": 1585571928.4928093, "_step": 251}
{"Episode reward": -99.84120638503087, "Episode length": 999, "Policy Loss": -0.35201209783554077, "Value Loss": 0.013094492256641388, "_runtime": 2014.195806503296, "_timestamp": 1585571930.0404398, "_step": 252}
{"Episode reward": -99.75619480358297, "Episode length": 999, "Policy Loss": -0.3522208333015442, "Value Loss": 0.054015930742025375, "_runtime": 2014.860992193222, "_timestamp": 1585571930.7056255, "_step": 253}
{"Episode reward": 58.19999999999968, "Episode length": 418, "Policy Loss": 1.6840152740478516, "Value Loss": 23.480623245239258, "_runtime": 2016.426367521286, "_timestamp": 1585571932.2710009, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35521817207336426, "Value Loss": 0.06001108139753342, "_runtime": 2017.785485982895, "_timestamp": 1585571933.6301193, "_step": 255}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": 0.3676415979862213, "Value Loss": 10.914299964904785, "_runtime": 2019.2934517860413, "_timestamp": 1585571935.1380851, "_step": 256}
{"Episode reward": -99.65220325859126, "Episode length": 999, "Policy Loss": -0.3654510974884033, "Value Loss": 0.019146930426359177, "_runtime": 2020.8500499725342, "_timestamp": 1585571936.6946833, "_step": 257}
{"Episode reward": -99.62039852123569, "Episode length": 999, "Policy Loss": -0.36923566460609436, "Value Loss": 0.006783596705645323, "_runtime": 2022.4027688503265, "_timestamp": 1585571938.2474022, "_step": 258}
{"Episode reward": -99.79252980686584, "Episode length": 999, "Policy Loss": -0.3733973503112793, "Value Loss": 0.023883463814854622, "_runtime": 2023.9443681240082, "_timestamp": 1585571939.7890015, "_step": 259}
{"Episode reward": -99.86149377822736, "Episode length": 999, "Policy Loss": -0.3482998311519623, "Value Loss": 0.08370039612054825, "_runtime": 2025.4958477020264, "_timestamp": 1585571941.340481, "_step": 260}
{"Episode reward": -99.80425991732487, "Episode length": 999, "Policy Loss": -0.35393399000167847, "Value Loss": 0.018895508721470833, "_runtime": 2027.1076338291168, "_timestamp": 1585571942.9522672, "_step": 261}
{"Episode reward": -99.80006400430436, "Episode length": 999, "Policy Loss": -0.34189027547836304, "Value Loss": 0.007626599166542292, "_runtime": 2028.6503920555115, "_timestamp": 1585571944.4950254, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33637604117393494, "Value Loss": 0.010635609738528728, "_runtime": 2030.003725528717, "_timestamp": 1585571945.8483589, "_step": 263}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": 0.49503815174102783, "Value Loss": 11.340961456298828, "_runtime": 2031.5167858600616, "_timestamp": 1585571947.3614192, "_step": 264}
{"Episode reward": 3.485357139167661, "Episode length": 966, "Policy Loss": 0.426639199256897, "Value Loss": 9.78307819366455, "_runtime": 2033.0834155082703, "_timestamp": 1585571948.9280488, "_step": 265}
{"Episode reward": -99.67159681124473, "Episode length": 999, "Policy Loss": -0.31038662791252136, "Value Loss": 0.007599271833896637, "_runtime": 2034.6405465602875, "_timestamp": 1585571950.48518, "_step": 266}
{"Episode reward": -99.84233074681694, "Episode length": 999, "Policy Loss": -0.30252721905708313, "Value Loss": 0.015146488323807716, "_runtime": 2036.2036447525024, "_timestamp": 1585571952.048278, "_step": 267}
{"Episode reward": -99.80110401296848, "Episode length": 999, "Policy Loss": -0.30383434891700745, "Value Loss": 0.023222822695970535, "_runtime": 2037.7688727378845, "_timestamp": 1585571953.613506, "_step": 268}
{"Episode reward": -99.7066736993366, "Episode length": 999, "Policy Loss": -0.2922462224960327, "Value Loss": 0.05503713712096214, "_runtime": 2039.3299033641815, "_timestamp": 1585571955.1745367, "_step": 269}
{"Episode reward": -99.8562499999986, "Episode length": 999, "Policy Loss": -0.2964220345020294, "Value Loss": 0.0077217984944581985, "_runtime": 2040.8963968753815, "_timestamp": 1585571956.7410302, "_step": 270}
{"Episode reward": -99.84391019940237, "Episode length": 999, "Policy Loss": -0.28342801332473755, "Value Loss": 0.0398540124297142, "_runtime": 2042.4665381908417, "_timestamp": 1585571958.3111715, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29798224568367004, "Value Loss": 0.0071904887445271015, "_runtime": 2043.2412312030792, "_timestamp": 1585571959.0858645, "_step": 272}
{"Episode reward": 51.957544244732304, "Episode length": 481, "Policy Loss": 1.2884191274642944, "Value Loss": 19.75543212890625, "_runtime": 2044.8077936172485, "_timestamp": 1585571960.652427, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2940666973590851, "Value Loss": 0.013860968872904778, "_runtime": 2045.3242316246033, "_timestamp": 1585571961.168865, "_step": 274}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": 1.9051138162612915, "Value Loss": 30.460268020629883, "_runtime": 2046.8450300693512, "_timestamp": 1585571962.6896634, "_step": 275}
{"Episode reward": -99.8414869967834, "Episode length": 999, "Policy Loss": -0.3111627697944641, "Value Loss": 0.008851414546370506, "_runtime": 2048.41725230217, "_timestamp": 1585571964.2618856, "_step": 276}
{"Episode reward": -99.80900292992452, "Episode length": 999, "Policy Loss": -0.3256833553314209, "Value Loss": 0.08518020063638687, "_runtime": 2049.940621614456, "_timestamp": 1585571965.785255, "_step": 277}
{"Episode reward": -99.80870869494835, "Episode length": 999, "Policy Loss": -0.32539594173431396, "Value Loss": 0.03484594449400902, "_runtime": 2051.5020983219147, "_timestamp": 1585571967.3467317, "_step": 278}
{"Episode reward": -99.6061910067671, "Episode length": 999, "Policy Loss": -0.3287131190299988, "Value Loss": 0.005790782626718283, "_runtime": 2052.456979036331, "_timestamp": 1585571968.3016124, "_step": 279}
{"Episode reward": 39.81517774378823, "Episode length": 602, "Policy Loss": 1.0158413648605347, "Value Loss": 16.0717716217041, "_runtime": 2054.0013959407806, "_timestamp": 1585571969.8460293, "_step": 280}
{"Episode reward": -99.84884375268454, "Episode length": 999, "Policy Loss": -0.32419607043266296, "Value Loss": 0.012063332833349705, "_runtime": 2054.9861285686493, "_timestamp": 1585571970.830762, "_step": 281}
{"Episode reward": 36.904751740395405, "Episode length": 631, "Policy Loss": 0.8856348395347595, "Value Loss": 14.699726104736328, "_runtime": 2056.52205824852, "_timestamp": 1585571972.3666916, "_step": 282}
{"Episode reward": -99.70271208062628, "Episode length": 999, "Policy Loss": -0.30109429359436035, "Value Loss": 0.0103941410779953, "_runtime": 2058.0855779647827, "_timestamp": 1585571973.9302113, "_step": 283}
{"Episode reward": -99.81079866885999, "Episode length": 999, "Policy Loss": -0.2797106206417084, "Value Loss": 0.063567616045475, "_runtime": 2058.8340458869934, "_timestamp": 1585571974.6786792, "_step": 284}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 1.1938097476959229, "Value Loss": 20.450607299804688, "_runtime": 2059.49787569046, "_timestamp": 1585571975.342509, "_step": 285}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 1.4535976648330688, "Value Loss": 22.800203323364258, "_runtime": 2061.035924434662, "_timestamp": 1585571976.8805578, "_step": 286}
{"Episode reward": -99.85319807678322, "Episode length": 999, "Policy Loss": -0.25649529695510864, "Value Loss": 0.0736057460308075, "_runtime": 2062.5534920692444, "_timestamp": 1585571978.3981254, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2488102912902832, "Value Loss": 0.03498364984989166, "_runtime": 2063.1191687583923, "_timestamp": 1585571978.963802, "_step": 288}
{"Episode reward": 63.69999999999976, "Episode length": 363, "Policy Loss": 1.594038724899292, "Value Loss": 25.941375732421875, "_runtime": 2064.660074710846, "_timestamp": 1585571980.504708, "_step": 289}
{"Episode reward": -99.83403608584636, "Episode length": 999, "Policy Loss": -0.2705831825733185, "Value Loss": 0.0313664972782135, "_runtime": 2066.209747314453, "_timestamp": 1585571982.0543807, "_step": 290}
{"Episode reward": -99.81738824844221, "Episode length": 999, "Policy Loss": -0.27776390314102173, "Value Loss": 0.030740711838006973, "_runtime": 2067.7108783721924, "_timestamp": 1585571983.5555117, "_step": 291}
{"Episode reward": -99.82085429578879, "Episode length": 999, "Policy Loss": -0.2815811038017273, "Value Loss": 0.04950838163495064, "_runtime": 2068.7893736362457, "_timestamp": 1585571984.634007, "_step": 292}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": 0.7601634860038757, "Value Loss": 14.291407585144043, "_runtime": 2070.07617354393, "_timestamp": 1585571985.920807, "_step": 293}
{"Episode reward": 17.781914355885633, "Episode length": 824, "Policy Loss": 1.0842595100402832, "Value Loss": 11.361649513244629, "_runtime": 2071.6183652877808, "_timestamp": 1585571987.4629986, "_step": 294}
{"Episode reward": -99.87135114082926, "Episode length": 999, "Policy Loss": -0.2516520023345947, "Value Loss": 0.4053075611591339, "_runtime": 2073.1910586357117, "_timestamp": 1585571989.035692, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29094743728637695, "Value Loss": 0.03962450101971626, "_runtime": 2074.734899520874, "_timestamp": 1585571990.5795329, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29432961344718933, "Value Loss": 0.018773358315229416, "_runtime": 2076.2914719581604, "_timestamp": 1585571992.1361053, "_step": 297}
{"Episode reward": -99.84907009340684, "Episode length": 999, "Policy Loss": -0.3000560998916626, "Value Loss": 0.011952919885516167, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558, 0.21551033854484558]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0], "bins": [-0.21551033854484558, -0.03072012960910797, 0.15407007932662964, 0.33886030316352844, 0.5236505270004272, 0.7084406614303589, 0.8932309150695801, 1.0780210494995117, 1.262811303138733, 1.447601556777954, 1.6323916912078857, 1.8171818256378174, 2.001972198486328, 2.1867623329162598, 2.3715524673461914, 2.556342840194702, 2.741132974624634, 2.9259231090545654, 3.110713481903076, 3.295503616333008, 3.4802937507629395, 3.66508412361145, 3.8498740196228027, 4.034664630889893, 4.219454765319824, 4.404244899749756, 4.5890350341796875, 4.773825168609619, 4.958615303039551, 5.143405914306641, 5.328196048736572, 5.512986183166504, 5.6977763175964355, 5.882566452026367, 6.067356586456299, 6.2521467208862305, 6.43693733215332, 6.621727466583252, 6.806517601013184, 6.991307735443115, 7.176097869873047, 7.3608880043029785, 7.545678615570068, 7.73046875, 7.915258407592773, 8.100049018859863, 8.284839630126953, 8.469629287719727, 8.654419898986816, 8.83920955657959, 9.02400016784668, 9.208789825439453, 9.393580436706543, 9.578371047973633, 9.763160705566406, 9.947951316833496, 10.13274097442627, 10.31753158569336, 10.50232219696045, 10.687111854553223, 10.871902465820312, 11.056692123413086, 11.241482734680176, 11.42627239227295, 11.611063003540039]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-4.146195715293288e-05, 0.007684520445764065, 0.01541050337255001, 0.023136485368013382, 0.030862467363476753, 0.038588449358940125, 0.046314433217048645, 0.05404041334986687, 0.06176639720797539, 0.06949237734079361, 0.07721836119890213, 0.08494434505701065, 0.09267032891511917, 0.10039631277322769, 0.10812228918075562, 0.11584827303886414, 0.12357425689697266, 0.13130024075508118, 0.1390262246131897, 0.14675220847129822, 0.15447819232940674, 0.16220417618751526, 0.16993016004562378, 0.1776561439037323, 0.18538212776184082, 0.19310811161994934, 0.20083409547805786, 0.2085600644350052, 0.2162860482931137, 0.22401203215122223, 0.23173801600933075, 0.23946399986743927, 0.2471899837255478, 0.2549159526824951, 0.26264193654060364, 0.27036792039871216, 0.2780939042568207, 0.2858198881149292, 0.2935458719730377, 0.30127185583114624, 0.30899783968925476, 0.3167238235473633, 0.3244498074054718, 0.3321757912635803, 0.33990177512168884, 0.34762775897979736, 0.3553537428379059, 0.3630797266960144, 0.3708057105541229, 0.37853169441223145, 0.38625767827033997, 0.3939836621284485, 0.401709645986557, 0.4094356298446655, 0.41716158390045166, 0.4248875677585602, 0.4326135516166687, 0.4403395354747772, 0.44806551933288574, 0.45579150319099426, 0.4635174870491028, 0.4712434709072113, 0.4789694547653198, 0.48669543862342834, 0.49442142248153687]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [12.0, 25.0, 9.0, 16.0, 10.0, 14.0, 16.0, 18.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 0.0, 311.0, 2.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 5.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.4519449472427368, -0.4251859486103058, -0.39842694997787476, -0.37166792154312134, -0.3449089229106903, -0.3181499242782593, -0.29139092564582825, -0.2646319270133972, -0.237872913479805, -0.21111391484737396, -0.18435490131378174, -0.1575959026813507, -0.13083690404891968, -0.10407790541648865, -0.07731887698173523, -0.0505598783493042, -0.02380087971687317, 0.0029581189155578613, 0.02971711754798889, 0.05647611618041992, 0.08323514461517334, 0.10999411344528198, 0.1367531418800354, 0.16351217031478882, 0.19027113914489746, 0.21703016757965088, 0.24378913640975952, 0.27054816484451294, 0.29730719327926636, 0.324066162109375, 0.3508251905441284, 0.37758415937423706, 0.4043431878089905, 0.4311022162437439, 0.45786118507385254, 0.48462021350860596, 0.5113791823387146, 0.538138210773468, 0.5648971796035767, 0.5916562080383301, 0.6184152364730835, 0.6451742649078369, 0.6719331741333008, 0.6986922025680542, 0.7254512310028076, 0.752210259437561, 0.7789692878723145, 0.8057281970977783, 0.8324872255325317, 0.8592462539672852, 0.8860052824020386, 0.912764310836792, 0.9395232200622559, 0.9662822484970093, 0.9930412769317627, 1.0198003053665161, 1.0465593338012695, 1.0733182430267334, 1.1000772714614868, 1.1268362998962402, 1.1535953283309937, 1.180354356765747, 1.207113265991211, 1.2338722944259644, 1.2606313228607178]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 6.0, 2.0, 5.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-1.3828235864639282, -1.2888422012329102, -1.1948609352111816, -1.1008796691894531, -1.006898283958435, -0.9129169583320618, -0.8189356327056885, -0.7249543070793152, -0.6309729814529419, -0.5369916558265686, -0.4430103302001953, -0.34902894496917725, -0.25504767894744873, -0.16106641292572021, -0.06708502769470215, 0.026896357536315918, 0.12087762355804443, 0.21485888957977295, 0.308840274810791, 0.4028216600418091, 0.4968029260635376, 0.5907841920852661, 0.6847656965255737, 0.7787469625473022, 0.8727282285690308, 0.9667094945907593, 1.0606907606124878, 1.1546722650527954, 1.248653531074524, 1.3426347970962524, 1.43661630153656, 1.5305975675582886, 1.624578833580017, 1.7185600996017456, 1.8125413656234741, 1.9065228700637817, 2.0005040168762207, 2.094485282897949, 2.188467025756836, 2.2824482917785645, 2.376429557800293, 2.4704108238220215, 2.56439208984375, 2.6583733558654785, 2.7523550987243652, 2.8463363647460938, 2.9403176307678223, 3.034298896789551, 3.1282801628112793, 3.222261428833008, 3.3162426948547363, 3.410223960876465, 3.5042052268981934, 3.59818696975708, 3.6921682357788086, 3.786149501800537, 3.8801307678222656, 3.974112033843994, 4.068093299865723, 4.162074565887451, 4.256056308746338, 4.350037574768066, 4.444018840789795, 4.538000106811523, 4.631981372833252]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 10.0, 9.0, 4.0, 5.0, 5.0, 4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.656776785850525, -1.6225714683532715, -1.5883660316467285, -1.554160714149475, -1.5199552774429321, -1.4857499599456787, -1.4515445232391357, -1.4173392057418823, -1.383133888244629, -1.348928451538086, -1.314723014831543, -1.2805176973342896, -1.2463123798370361, -1.2121069431304932, -1.1779016256332397, -1.1436963081359863, -1.1094908714294434, -1.0752854347229004, -1.041080117225647, -1.0068747997283936, -0.9726693630218506, -0.9384640455245972, -0.904258668422699, -0.8700532913208008, -0.8358479142189026, -0.8016425371170044, -0.7674371600151062, -0.733231782913208, -0.6990264654159546, -0.6648210883140564, -0.6306157112121582, -0.5964102745056152, -0.5622049570083618, -0.5279996395111084, -0.49379420280456543, -0.459588885307312, -0.42538344860076904, -0.3911781311035156, -0.35697269439697266, -0.32276737689971924, -0.28856194019317627, -0.25435662269592285, -0.22015130519866943, -0.18594586849212646, -0.15174055099487305, -0.11753511428833008, -0.08332979679107666, -0.04912436008453369, -0.014919042587280273, 0.019286274909973145, 0.05349171161651611, 0.08769702911376953, 0.1219024658203125, 0.15610778331756592, 0.1903132200241089, 0.2245185375213623, 0.2587238550186157, 0.2929292917251587, 0.3271346092224121, 0.3613399267196655, 0.3955453634262085, 0.42975080013275146, 0.46395623683929443, 0.4981614351272583, 0.5323668718338013]}, "_runtime": 2077.1448366642, "_timestamp": 1585571992.98947, "_step": 298}
{"Episode reward": 45.79999999999951, "Episode length": 542, "Policy Loss": 1.0524643659591675, "Value Loss": 17.27314567565918, "_runtime": 2078.713345527649, "_timestamp": 1585571994.5579789, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29386940598487854, "Value Loss": 0.029756568372249603, "_runtime": 2080.279753446579, "_timestamp": 1585571996.1243868, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31395789980888367, "Value Loss": 0.05665963515639305, "_runtime": 2081.8022122383118, "_timestamp": 1585571997.6468456, "_step": 301}
{"Episode reward": -99.80273185372214, "Episode length": 999, "Policy Loss": -0.3200712502002716, "Value Loss": 0.03878321126103401, "_runtime": 2083.3676841259003, "_timestamp": 1585571999.2123175, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33132854104042053, "Value Loss": 0.027583250775933266, "_runtime": 2084.1422276496887, "_timestamp": 1585571999.986861, "_step": 303}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 1.1023995876312256, "Value Loss": 19.071475982666016, "_runtime": 2084.7842631340027, "_timestamp": 1585572000.6288965, "_step": 304}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.4607741832733154, "Value Loss": 23.211082458496094, "_runtime": 2086.329042673111, "_timestamp": 1585572002.173676, "_step": 305}
{"Episode reward": -99.80992705710092, "Episode length": 999, "Policy Loss": -0.37897372245788574, "Value Loss": 0.010745037347078323, "_runtime": 2087.834015607834, "_timestamp": 1585572003.678649, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39990487694740295, "Value Loss": 0.056451499462127686, "_runtime": 2089.145108938217, "_timestamp": 1585572004.9897423, "_step": 307}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 0.42960113286972046, "Value Loss": 10.772968292236328, "_runtime": 2090.700423717499, "_timestamp": 1585572006.545057, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4107140302658081, "Value Loss": 0.003401026362553239, "_runtime": 2091.2231850624084, "_timestamp": 1585572007.0678184, "_step": 309}
{"Episode reward": 68.73773803710921, "Episode length": 313, "Policy Loss": 1.8801624774932861, "Value Loss": 28.94085121154785, "_runtime": 2092.2929713726044, "_timestamp": 1585572008.1376047, "_step": 310}
{"Episode reward": 30.49778756163981, "Episode length": 696, "Policy Loss": 0.5723322033882141, "Value Loss": 12.984313011169434, "_runtime": 2093.445503473282, "_timestamp": 1585572009.2901368, "_step": 311}
{"Episode reward": 26.685257153957977, "Episode length": 735, "Policy Loss": 0.552355945110321, "Value Loss": 12.631909370422363, "_runtime": 2094.9476437568665, "_timestamp": 1585572010.792277, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40137210488319397, "Value Loss": 0.020567789673805237, "_runtime": 2096.519994735718, "_timestamp": 1585572012.364628, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3764614164829254, "Value Loss": 0.2954583168029785, "_runtime": 2096.7733528614044, "_timestamp": 1585572012.6179862, "_step": 314}
{"Episode reward": 86.80000000000004, "Episode length": 132, "Policy Loss": 5.246592998504639, "Value Loss": 71.75698852539062, "_runtime": 2098.3069326877594, "_timestamp": 1585572014.151566, "_step": 315}
{"Episode reward": -99.81117903143029, "Episode length": 999, "Policy Loss": -0.37243562936782837, "Value Loss": 0.028747860342264175, "_runtime": 2099.870451927185, "_timestamp": 1585572015.7150853, "_step": 316}
{"Episode reward": -99.87852962650219, "Episode length": 999, "Policy Loss": -0.38591161370277405, "Value Loss": 0.05550201237201691, "_runtime": 2101.352083683014, "_timestamp": 1585572017.196717, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.367952436208725, "Value Loss": 0.12028589099645615, "_runtime": 2102.912177324295, "_timestamp": 1585572018.7568107, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4066254198551178, "Value Loss": 0.09367997944355011, "_runtime": 2104.4714274406433, "_timestamp": 1585572020.3160608, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4206564724445343, "Value Loss": 0.16797113418579102, "_runtime": 2106.008543729782, "_timestamp": 1585572021.853177, "_step": 320}
{"Episode reward": -99.73762719780068, "Episode length": 999, "Policy Loss": -0.4295566976070404, "Value Loss": 0.09977056086063385, "_runtime": 2107.5813658237457, "_timestamp": 1585572023.4259992, "_step": 321}
{"Episode reward": -99.76697343662242, "Episode length": 999, "Policy Loss": -0.4440061151981354, "Value Loss": 0.05054020136594772, "_runtime": 2108.872195959091, "_timestamp": 1585572024.7168293, "_step": 322}
{"Episode reward": 18.100000000000378, "Episode length": 819, "Policy Loss": 0.4052061140537262, "Value Loss": 10.924644470214844, "_runtime": 2110.0959458351135, "_timestamp": 1585572025.9405792, "_step": 323}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 0.5423140525817871, "Value Loss": 11.62386417388916, "_runtime": 2111.66450881958, "_timestamp": 1585572027.5091422, "_step": 324}
{"Episode reward": -99.87174867540458, "Episode length": 999, "Policy Loss": -0.4661836624145508, "Value Loss": 0.02957911230623722, "_runtime": 2113.225287914276, "_timestamp": 1585572029.0699213, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4674602150917053, "Value Loss": 0.02081613428890705, "_runtime": 2114.7491924762726, "_timestamp": 1585572030.5938258, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46709543466567993, "Value Loss": 0.0420190654695034, "_runtime": 2115.3498618602753, "_timestamp": 1585572031.1944952, "_step": 327}
{"Episode reward": 63.39999999999976, "Episode length": 366, "Policy Loss": 1.5698484182357788, "Value Loss": 25.005346298217773, "_runtime": 2116.1950237751007, "_timestamp": 1585572032.039657, "_step": 328}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 0.9069197177886963, "Value Loss": 17.901010513305664, "_runtime": 2117.736818790436, "_timestamp": 1585572033.5814521, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47201213240623474, "Value Loss": 0.007315400522202253, "_runtime": 2118.307451248169, "_timestamp": 1585572034.1520846, "_step": 330}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 1.3628365993499756, "Value Loss": 23.727733612060547, "_runtime": 2119.726161003113, "_timestamp": 1585572035.5707943, "_step": 331}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": 0.2904397249221802, "Value Loss": 9.819518089294434, "_runtime": 2121.3247430324554, "_timestamp": 1585572037.1693764, "_step": 332}
{"Episode reward": -99.80319812446693, "Episode length": 999, "Policy Loss": -0.40661942958831787, "Value Loss": 0.2078131139278412, "_runtime": 2122.824761867523, "_timestamp": 1585572038.6693952, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4081685543060303, "Value Loss": 0.07426983118057251, "_runtime": 2124.383026123047, "_timestamp": 1585572040.2276595, "_step": 334}
{"Episode reward": -99.83072720914939, "Episode length": 999, "Policy Loss": -0.4006316363811493, "Value Loss": 0.043166954070329666, "_runtime": 2125.947189092636, "_timestamp": 1585572041.7918224, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38120561838150024, "Value Loss": 0.03847808018326759, "_runtime": 2127.0692336559296, "_timestamp": 1585572042.913867, "_step": 336}
{"Episode reward": 28.195925929769686, "Episode length": 719, "Policy Loss": 0.7355210781097412, "Value Loss": 12.942030906677246, "_runtime": 2128.3052401542664, "_timestamp": 1585572044.1498735, "_step": 337}
{"Episode reward": 21.56558679267782, "Episode length": 786, "Policy Loss": 0.617544949054718, "Value Loss": 12.085436820983887, "_runtime": 2129.3122568130493, "_timestamp": 1585572045.1568902, "_step": 338}
{"Episode reward": 36.29999999999937, "Episode length": 637, "Policy Loss": 0.9362483620643616, "Value Loss": 14.63842487335205, "_runtime": 2130.6125450134277, "_timestamp": 1585572046.4571784, "_step": 339}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.5748082399368286, "Value Loss": 11.266275405883789, "_runtime": 2132.1518433094025, "_timestamp": 1585572047.9964767, "_step": 340}
{"Episode reward": -99.81487028747658, "Episode length": 999, "Policy Loss": -0.43637192249298096, "Value Loss": 0.030259117484092712, "_runtime": 2133.681321144104, "_timestamp": 1585572049.5259545, "_step": 341}
{"Episode reward": -99.80717287659505, "Episode length": 999, "Policy Loss": -0.4569821059703827, "Value Loss": 0.1431993693113327, "_runtime": 2135.220137357712, "_timestamp": 1585572051.0647707, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48090994358062744, "Value Loss": 0.013652429915964603, "_runtime": 2136.788599252701, "_timestamp": 1585572052.6332326, "_step": 343}
{"Episode reward": -99.70871900617936, "Episode length": 999, "Policy Loss": -0.4770892858505249, "Value Loss": 0.06819383800029755, "_runtime": 2138.3284952640533, "_timestamp": 1585572054.1731286, "_step": 344}
{"Episode reward": -99.81809779554466, "Episode length": 999, "Policy Loss": -0.4916442930698395, "Value Loss": 0.04929068312048912, "_runtime": 2139.2124502658844, "_timestamp": 1585572055.0570836, "_step": 345}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 0.717373788356781, "Value Loss": 16.440189361572266, "_runtime": 2140.7808694839478, "_timestamp": 1585572056.6255028, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4935193657875061, "Value Loss": 0.06771676987409592, "_runtime": 2142.3469638824463, "_timestamp": 1585572058.1915972, "_step": 347}
{"Episode reward": -99.70154561586538, "Episode length": 999, "Policy Loss": -0.4723169505596161, "Value Loss": 0.1985013633966446, "_runtime": 2143.9054324626923, "_timestamp": 1585572059.7500658, "_step": 348}
{"Episode reward": -99.88066416717926, "Episode length": 999, "Policy Loss": -0.46028104424476624, "Value Loss": 0.024862676858901978, "_runtime": 2145.4067499637604, "_timestamp": 1585572061.2513833, "_step": 349}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": 0.30157795548439026, "Value Loss": 9.483530044555664, "_runtime": 2146.962632894516, "_timestamp": 1585572062.8072662, "_step": 350}
{"Episode reward": -99.84998068846622, "Episode length": 999, "Policy Loss": -0.4300558865070343, "Value Loss": 0.14466561377048492, "_runtime": 2147.962552547455, "_timestamp": 1585572063.807186, "_step": 351}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": 0.8155661821365356, "Value Loss": 14.29255199432373, "_runtime": 2149.5293624401093, "_timestamp": 1585572065.3739958, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.406495064496994, "Value Loss": 0.025351427495479584, "_runtime": 2151.0853867530823, "_timestamp": 1585572066.93002, "_step": 353}
{"Episode reward": -99.88657948113838, "Episode length": 999, "Policy Loss": -0.39755865931510925, "Value Loss": 0.07028790563344955, "_runtime": 2151.953758239746, "_timestamp": 1585572067.7983916, "_step": 354}
{"Episode reward": 43.29999999999947, "Episode length": 567, "Policy Loss": 1.1834759712219238, "Value Loss": 16.55120086669922, "_runtime": 2153.510503053665, "_timestamp": 1585572069.3551364, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37285274267196655, "Value Loss": 0.06696300953626633, "_runtime": 2155.077896118164, "_timestamp": 1585572070.9225295, "_step": 356}
{"Episode reward": -99.81718017496028, "Episode length": 999, "Policy Loss": -0.41521769762039185, "Value Loss": 0.0295607540756464, "_runtime": 2156.6009283065796, "_timestamp": 1585572072.4455616, "_step": 357}
{"Episode reward": -99.85245281606772, "Episode length": 999, "Policy Loss": -0.41376277804374695, "Value Loss": 0.043222974985837936, "_runtime": 2157.5671434402466, "_timestamp": 1585572073.4117768, "_step": 358}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.9927504062652588, "Value Loss": 14.960780143737793, "_runtime": 2159.13400888443, "_timestamp": 1585572074.9786422, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4528074562549591, "Value Loss": 0.02339334972202778, "_runtime": 2160.7015113830566, "_timestamp": 1585572076.5461447, "_step": 360}
{"Episode reward": -99.8365779850618, "Episode length": 999, "Policy Loss": -0.4813651144504547, "Value Loss": 0.020294154062867165, "_runtime": 2162.2447698116302, "_timestamp": 1585572078.0894032, "_step": 361}
{"Episode reward": -99.87367430962482, "Episode length": 999, "Policy Loss": -0.4925028085708618, "Value Loss": 0.005901271943002939, "_runtime": 2163.5722219944, "_timestamp": 1585572079.4168553, "_step": 362}
{"Episode reward": 14.879798310995668, "Episode length": 852, "Policy Loss": 0.4635334610939026, "Value Loss": 11.922662734985352, "_runtime": 2165.1480379104614, "_timestamp": 1585572080.9926713, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48321884870529175, "Value Loss": 0.010054771788418293, "_runtime": 2166.6708126068115, "_timestamp": 1585572082.515446, "_step": 364}
{"Episode reward": 6.247982474790078, "Episode length": 939, "Policy Loss": 0.27584150433540344, "Value Loss": 9.865959167480469, "_runtime": 2168.2277071475983, "_timestamp": 1585572084.0723405, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4118807315826416, "Value Loss": 0.040850043296813965, "_runtime": 2168.8688197135925, "_timestamp": 1585572084.713453, "_step": 366}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 1.427024483680725, "Value Loss": 22.33499526977539, "_runtime": 2170.430342912674, "_timestamp": 1585572086.2749763, "_step": 367}
{"Episode reward": -99.70239622667292, "Episode length": 999, "Policy Loss": -0.39073413610458374, "Value Loss": 0.09007113426923752, "_runtime": 2171.9355852603912, "_timestamp": 1585572087.7802186, "_step": 368}
{"Episode reward": 4.100000000001174, "Episode length": 959, "Policy Loss": 0.4195626378059387, "Value Loss": 9.604781150817871, "_runtime": 2172.304060459137, "_timestamp": 1585572088.1486938, "_step": 369}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 3.4917285442352295, "Value Loss": 41.87361526489258, "_runtime": 2173.8690531253815, "_timestamp": 1585572089.7136865, "_step": 370}
{"Episode reward": -99.80275814570346, "Episode length": 999, "Policy Loss": -0.4267673194408417, "Value Loss": 0.04517652839422226, "_runtime": 2175.429451942444, "_timestamp": 1585572091.2740853, "_step": 371}
{"Episode reward": -99.87287069707969, "Episode length": 999, "Policy Loss": -0.4689492881298065, "Value Loss": 0.24293965101242065, "_runtime": 2176.9292714595795, "_timestamp": 1585572092.7739048, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4625779390335083, "Value Loss": 0.043824609369039536, "_runtime": 2177.971120119095, "_timestamp": 1585572093.8157535, "_step": 373}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.682682991027832, "Value Loss": 13.764918327331543, "_runtime": 2179.5217015743256, "_timestamp": 1585572095.366335, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48487696051597595, "Value Loss": 0.04140951856970787, "_runtime": 2180.329199075699, "_timestamp": 1585572096.1738324, "_step": 375}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 1.0057376623153687, "Value Loss": 17.628131866455078, "_runtime": 2181.8734633922577, "_timestamp": 1585572097.7180967, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5461673140525818, "Value Loss": 0.865962028503418, "_runtime": 2182.630138397217, "_timestamp": 1585572098.4747717, "_step": 377}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.503420352935791, "Value Loss": 19.724414825439453, "_runtime": 2184.1667189598083, "_timestamp": 1585572100.0113523, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4846396744251251, "Value Loss": 0.08225777745246887, "_runtime": 2185.343113899231, "_timestamp": 1585572101.1877472, "_step": 379}
{"Episode reward": 24.799999999999997, "Episode length": 752, "Policy Loss": 0.5821400284767151, "Value Loss": 12.443589210510254, "_runtime": 2186.870452642441, "_timestamp": 1585572102.715086, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4169647693634033, "Value Loss": 0.20713716745376587, "_runtime": 2188.429334640503, "_timestamp": 1585572104.273968, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.482133686542511, "Value Loss": 0.0730036124587059, "_runtime": 2189.978362560272, "_timestamp": 1585572105.822996, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48699942231178284, "Value Loss": 0.061032745987176895, "_runtime": 2191.569856405258, "_timestamp": 1585572107.4144897, "_step": 383}
{"Episode reward": -99.77196636348823, "Episode length": 999, "Policy Loss": -0.511039137840271, "Value Loss": 0.03155791014432907, "_runtime": 2192.558396100998, "_timestamp": 1585572108.4030294, "_step": 384}
{"Episode reward": 37.999999999999396, "Episode length": 620, "Policy Loss": 0.8220634460449219, "Value Loss": 15.216924667358398, "_runtime": 2194.12446975708, "_timestamp": 1585572109.969103, "_step": 385}
{"Episode reward": -99.80827826410392, "Episode length": 999, "Policy Loss": -0.5479196310043335, "Value Loss": 0.02095099538564682, "_runtime": 2195.6890954971313, "_timestamp": 1585572111.5337288, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.570489227771759, "Value Loss": 0.13415254652500153, "_runtime": 2197.2267684936523, "_timestamp": 1585572113.0714018, "_step": 387}
{"Episode reward": -99.82751381546119, "Episode length": 999, "Policy Loss": -0.5834863185882568, "Value Loss": 0.027154037728905678, "_runtime": 2198.789464235306, "_timestamp": 1585572114.6340976, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5746286511421204, "Value Loss": 0.07168231159448624, "_runtime": 2200.355882167816, "_timestamp": 1585572116.2005155, "_step": 389}
{"Episode reward": -99.83886438757041, "Episode length": 999, "Policy Loss": -0.5793729424476624, "Value Loss": 0.029998183250427246, "_runtime": 2201.2309601306915, "_timestamp": 1585572117.0755935, "_step": 390}
{"Episode reward": 44.69611344188401, "Episode length": 554, "Policy Loss": 0.8443232774734497, "Value Loss": 17.17913055419922, "_runtime": 2202.80823636055, "_timestamp": 1585572118.6528697, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5359205603599548, "Value Loss": 0.0334668904542923, "_runtime": 2204.379285812378, "_timestamp": 1585572120.2239192, "_step": 392}
{"Episode reward": -99.88170906454185, "Episode length": 999, "Policy Loss": -0.510566234588623, "Value Loss": 0.021113364025950432, "_runtime": 2205.9114689826965, "_timestamp": 1585572121.7561023, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4826415777206421, "Value Loss": 0.030301282182335854, "_runtime": 2207.014912366867, "_timestamp": 1585572122.8595457, "_step": 394}
{"Episode reward": 30.299999999999685, "Episode length": 697, "Policy Loss": 0.9308536648750305, "Value Loss": 13.117794036865234, "_runtime": 2207.628341436386, "_timestamp": 1585572123.4729748, "_step": 395}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.7669569253921509, "Value Loss": 25.381736755371094, "_runtime": 2209.1728689670563, "_timestamp": 1585572125.0175023, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44258570671081543, "Value Loss": 0.06525049358606339, "_runtime": 2210.7294631004333, "_timestamp": 1585572126.5740964, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4428292512893677, "Value Loss": 0.1179555281996727, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023, 0.0008978561963886023]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0008978561963886023, -0.00013851845869794488, 0.0006208192789927125, 0.001380156958475709, 0.0021394947543740273, 0.0028988325502723455, 0.00365817011334002, 0.0044175079092383385, 0.0051768459379673, 0.005936183035373688, 0.00669552106410265, 0.007454859092831612, 0.008214196190237999, 0.008973534218966961, 0.009732872247695923, 0.01049220934510231, 0.011251547373831272, 0.012010885402560234, 0.012770222499966621, 0.013529560528695583, 0.014288898557424545, 0.015048235654830933, 0.01580757461488247, 0.016566911712288857, 0.017326248809695244, 0.01808558776974678, 0.018844924867153168, 0.019604261964559555, 0.02036360092461109, 0.02112293802201748, 0.021882275119423866, 0.022641614079475403, 0.02340095117688179, 0.024160288274288177, 0.024919627234339714, 0.0256789643317461, 0.02643830142915249, 0.027197640389204025, 0.027956977486610413, 0.0287163145840168, 0.029475653544068336, 0.030234990641474724, 0.03099432773888111, 0.03175366669893265, 0.032513007521629333, 0.03327234461903572, 0.03403168171644211, 0.034791018813848495, 0.03555035591125488, 0.03630969300866127, 0.037069033831357956, 0.03782837092876434, 0.03858770802617073, 0.03934704512357712, 0.040106382220983505, 0.04086571931838989, 0.04162506014108658, 0.042384397238492966, 0.04314373433589935, 0.04390307143330574, 0.04466240853071213, 0.045421745628118515, 0.0461810864508152, 0.04694042354822159, 0.047699760645627975]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-7.43842633710301e-07, 4.029426054330543e-05, 8.133236406138167e-05, 0.00012237047485541552, 0.00016340857837349176, 0.000204446681891568, 0.00024548478540964425, 0.0002865229034796357, 0.00032756099244579673, 0.00036859908141195774, 0.0004096371994819492, 0.0004506753175519407, 0.0004917134065181017, 0.0005327514954842627, 0.0005737896426580846, 0.0006148277316242456, 0.0006558658205904067, 0.0006969039095565677, 0.0007379419985227287, 0.0007789801456965506, 0.0008200182346627116, 0.0008610563236288726, 0.0009020944708026946, 0.0009431325597688556, 0.0009841705905273557, 0.0010252087377011776, 0.0010662467684596777, 0.0011072849156334996, 0.0011483230628073215, 0.0011893610935658216, 0.0012303992407396436, 0.0012714372714981437, 0.0013124754186719656, 0.0013535135658457875, 0.0013945515966042876, 0.0014355897437781096, 0.0014766277745366096, 0.0015176659217104316, 0.0015587040688842535, 0.0015997420996427536, 0.0016407802468165755, 0.0016818183939903975, 0.0017228564247488976, 0.0017638945719227195, 0.0018049327190965414, 0.0018459707498550415, 0.0018870088970288634, 0.0019280469277873635, 0.0019690850749611855, 0.0020101231057196856, 0.0020511613693088293, 0.0020921994000673294, 0.0021332374308258295, 0.0021742756944149733, 0.0022153137251734734, 0.0022563517559319735, 0.002297390019521117, 0.0023384280502796173, 0.0023794660810381174, 0.0024205041117966175, 0.0024615423753857613, 0.0025025804061442614, 0.0025436184369027615, 0.002584656700491905, 0.0026256947312504053]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 16.0, 8.0, 12.0, 19.0, 20.0, 13.0, 12.0, 11.0, 6.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 1.0, 21.0, 289.0, 4.0, 2.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.0028439201414585114, -0.002728820312768221, -0.002613720716908574, -0.0024986208882182837, -0.002383521292358637, -0.0022684214636683464, -0.002153321634978056, -0.002038222039118409, -0.0019231223268434405, -0.001808022614568472, -0.0016929229022935033, -0.0015778231900185347, -0.0014627233613282442, -0.0013476236490532756, -0.001232523936778307, -0.0011174242245033383, -0.0010023245122283697, -0.0008872246835380793, -0.0007721250876784325, -0.000657025258988142, -0.0005419256631284952, -0.00042682583443820477, -0.00031172623857855797, -0.00019662640988826752, -8.152658119797707e-05, 3.357301466166973e-05, 0.00014867284335196018, 0.000263772439211607, 0.00037887226790189743, 0.0004939718637615442, 0.0006090716924518347, 0.0007241712883114815, 0.0008392711170017719, 0.0009543709456920624, 0.0010694707743823528, 0.001184570137411356, 0.0012996699661016464, 0.0014147697947919369, 0.0015298696234822273, 0.0016449689865112305, 0.001760068815201521, 0.0018751686438918114, 0.001990268472582102, 0.0021053683012723923, 0.0022204676643013954, 0.002335567492991686, 0.0024506673216819763, 0.0025657671503722668, 0.0026808669790625572, 0.0027959663420915604, 0.002911066170781851, 0.0030261659994721413, 0.0031412658281624317, 0.003256365191191435, 0.0033714650198817253, 0.0034865648485720158, 0.003601664677262306, 0.0037167645059525967, 0.0038318638689816, 0.00394696369767189, 0.004062063526362181, 0.004177163355052471, 0.004292262718081474, 0.004407362546771765, 0.004522462375462055]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.029568005353212357, -0.028433460742235184, -0.02729891426861286, -0.02616436965763569, -0.025029825046658516, -0.023895278573036194, -0.02276073396205902, -0.021626189351081848, -0.020491644740104675, -0.019357098266482353, -0.01822255365550518, -0.01708800718188286, -0.015953462570905685, -0.014818917959928513, -0.01368437334895134, -0.012549826875329018, -0.011415282264351845, -0.010280737653374672, -0.00914619117975235, -0.008011646568775177, -0.006877101957798004, -0.005742555484175682, -0.004608010873198509, -0.0034734662622213364, -0.0023389197885990143, -0.0012043751776218414, -6.983056664466858e-05, 0.0010647140443325043, 0.002199258655309677, 0.0033338069915771484, 0.004468351602554321, 0.005602896213531494, 0.006737440824508667, 0.00787198543548584, 0.009006530046463013, 0.010141074657440186, 0.011275622993707657, 0.01241016760468483, 0.013544712215662003, 0.014679256826639175, 0.01581380143761635, 0.01694834604859352, 0.018082894384860992, 0.019217438995838165, 0.020351983606815338, 0.02148652821779251, 0.022621072828769684, 0.023755617439746857, 0.024890165776014328, 0.0260247103869915, 0.027159254997968674, 0.028293799608945847, 0.02942834421992302, 0.030562888830900192, 0.031697433441877365, 0.032831981778144836, 0.03396652266383171, 0.035101067274808884, 0.03623561933636665, 0.037370163947343826, 0.038504708558321, 0.03963925316929817, 0.040773797780275345, 0.04190834239125252, 0.04304288700222969]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 5.0, 4.0, 8.0, 4.0, 0.0, 1.0, 0.0, 4.0, 6.0, 6.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.07131846994161606, -0.06886126101016998, -0.06640405207872391, -0.06394683569669724, -0.06148962676525116, -0.059032417833805084, -0.05657520890235901, -0.05411799997091293, -0.05166078731417656, -0.049203574657440186, -0.04674636572599411, -0.044289156794548035, -0.04183194786310196, -0.039374735206365585, -0.03691752627491951, -0.034460313618183136, -0.03200310468673706, -0.029545895755290985, -0.02708868309855461, -0.024631474167108536, -0.022174261510372162, -0.019717052578926086, -0.01725984364748001, -0.014802630990743637, -0.012345422059297562, -0.009888213127851486, -0.007431000471115112, -0.004973791539669037, -0.0025165826082229614, -5.9373676776885986e-05, 0.0023978427052497864, 0.004855051636695862, 0.007312260568141937, 0.009769469499588013, 0.012226678431034088, 0.01468389481306076, 0.017141103744506836, 0.01959831267595291, 0.022055521607398987, 0.024512730538845062, 0.026969946920871735, 0.02942715585231781, 0.031884364783763885, 0.03434157371520996, 0.036798782646656036, 0.03925599157810211, 0.041713207960128784, 0.04417041689157486, 0.046627625823020935, 0.04908483475446701, 0.051542043685913086, 0.05399925261735916, 0.056456468999385834, 0.05891367048025131, 0.061370886862277985, 0.06382810324430466, 0.06628530472517014, 0.06874252110719681, 0.07119972258806229, 0.07365693897008896, 0.07611415535211563, 0.07857135683298111, 0.08102857321500778, 0.08348577469587326, 0.08594299107789993]}, "_runtime": 2212.2404522895813, "_timestamp": 1585572128.0850856, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46202990412712097, "Value Loss": 0.022169139236211777, "_runtime": 2213.054572582245, "_timestamp": 1585572128.899206, "_step": 399}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 1.1003854274749756, "Value Loss": 18.360227584838867, "_runtime": 2213.716068983078, "_timestamp": 1585572129.5607023, "_step": 400}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.5845144987106323, "Value Loss": 23.374832153320312, "_runtime": 2215.2998521327972, "_timestamp": 1585572131.1444855, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5173521637916565, "Value Loss": 0.03000284731388092, "_runtime": 2216.8178236484528, "_timestamp": 1585572132.662457, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5504751205444336, "Value Loss": 0.032218240201473236, "_runtime": 2217.652515888214, "_timestamp": 1585572133.4971492, "_step": 403}
{"Episode reward": 45.17460784912059, "Episode length": 549, "Policy Loss": 0.9572301506996155, "Value Loss": 17.040117263793945, "_runtime": 2218.8737354278564, "_timestamp": 1585572134.7183688, "_step": 404}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.38183674216270447, "Value Loss": 11.392179489135742, "_runtime": 2219.7096400260925, "_timestamp": 1585572135.5542734, "_step": 405}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 0.8668667674064636, "Value Loss": 17.968564987182617, "_runtime": 2221.024138212204, "_timestamp": 1585572136.8687716, "_step": 406}
{"Episode reward": 13.670252776146569, "Episode length": 864, "Policy Loss": 0.31233900785446167, "Value Loss": 10.369565963745117, "_runtime": 2222.3226013183594, "_timestamp": 1585572138.1672347, "_step": 407}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": 0.3727641999721527, "Value Loss": 11.232393264770508, "_runtime": 2223.84326004982, "_timestamp": 1585572139.6878934, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5580621957778931, "Value Loss": 0.047995809465646744, "_runtime": 2225.07163977623, "_timestamp": 1585572140.916273, "_step": 409}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.5163766145706177, "Value Loss": 11.609079360961914, "_runtime": 2225.680670976639, "_timestamp": 1585572141.5253043, "_step": 410}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.6031798124313354, "Value Loss": 23.988664627075195, "_runtime": 2227.2146286964417, "_timestamp": 1585572143.059262, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5267154574394226, "Value Loss": 0.1679985225200653, "_runtime": 2228.424595117569, "_timestamp": 1585572144.2692285, "_step": 412}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.5420050621032715, "Value Loss": 12.035688400268555, "_runtime": 2229.2952535152435, "_timestamp": 1585572145.1398869, "_step": 413}
{"Episode reward": 42.29999999999946, "Episode length": 577, "Policy Loss": 0.8299498558044434, "Value Loss": 15.406021118164062, "_runtime": 2230.8391790390015, "_timestamp": 1585572146.6838124, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5970109105110168, "Value Loss": 0.08326181024312973, "_runtime": 2232.0702600479126, "_timestamp": 1585572147.9148934, "_step": 415}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.34469807147979736, "Value Loss": 11.371047973632812, "_runtime": 2233.5741679668427, "_timestamp": 1585572149.4188013, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6482221484184265, "Value Loss": 0.042176611721515656, "_runtime": 2234.9173674583435, "_timestamp": 1585572150.7620008, "_step": 417}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": 0.22267161309719086, "Value Loss": 10.67979907989502, "_runtime": 2236.4678337574005, "_timestamp": 1585572152.312467, "_step": 418}
{"Episode reward": -99.81843167692283, "Episode length": 999, "Policy Loss": -0.6680776476860046, "Value Loss": 0.03276830166578293, "_runtime": 2237.7981085777283, "_timestamp": 1585572153.642742, "_step": 419}
{"Episode reward": 16.800000000000452, "Episode length": 832, "Policy Loss": 0.32726070284843445, "Value Loss": 11.527155876159668, "_runtime": 2239.1401357650757, "_timestamp": 1585572154.984769, "_step": 420}
{"Episode reward": 13.100000000000662, "Episode length": 869, "Policy Loss": 0.31711286306381226, "Value Loss": 10.55865478515625, "_runtime": 2240.6914417743683, "_timestamp": 1585572156.536075, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6499086022377014, "Value Loss": 0.05364548787474632, "_runtime": 2242.068373441696, "_timestamp": 1585572157.9130068, "_step": 422}
{"Episode reward": 11.300000000000765, "Episode length": 887, "Policy Loss": 0.19094298779964447, "Value Loss": 10.149898529052734, "_runtime": 2243.613571166992, "_timestamp": 1585572159.4582045, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6709765195846558, "Value Loss": 0.06730495393276215, "_runtime": 2245.1687710285187, "_timestamp": 1585572161.0134044, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.688479483127594, "Value Loss": 0.10186967253684998, "_runtime": 2246.729056596756, "_timestamp": 1585572162.57369, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6821429133415222, "Value Loss": 0.06730397045612335, "_runtime": 2247.6422448158264, "_timestamp": 1585572163.4868782, "_step": 426}
{"Episode reward": 41.59999999999945, "Episode length": 584, "Policy Loss": 0.6684070825576782, "Value Loss": 16.257247924804688, "_runtime": 2249.2018463611603, "_timestamp": 1585572165.0464797, "_step": 427}
{"Episode reward": -99.64790056198697, "Episode length": 999, "Policy Loss": -0.727476179599762, "Value Loss": 0.06585726886987686, "_runtime": 2249.8729679584503, "_timestamp": 1585572165.7176013, "_step": 428}
{"Episode reward": 59.242978328466116, "Episode length": 408, "Policy Loss": 1.2095692157745361, "Value Loss": 23.172693252563477, "_runtime": 2250.2462916374207, "_timestamp": 1585572166.090925, "_step": 429}
{"Episode reward": 77.79999999999995, "Episode length": 222, "Policy Loss": 2.8399767875671387, "Value Loss": 43.409725189208984, "_runtime": 2250.8833045959473, "_timestamp": 1585572166.727938, "_step": 430}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.7611150741577148, "Value Loss": 22.530059814453125, "_runtime": 2252.3925902843475, "_timestamp": 1585572168.2372236, "_step": 431}
{"Episode reward": -99.80559086948493, "Episode length": 999, "Policy Loss": -0.8242743015289307, "Value Loss": 0.5356618762016296, "_runtime": 2253.8793275356293, "_timestamp": 1585572169.7239609, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7554121613502502, "Value Loss": 0.033016473054885864, "_runtime": 2255.1010797023773, "_timestamp": 1585572170.945713, "_step": 433}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.27721166610717773, "Value Loss": 12.047392845153809, "_runtime": 2255.8691425323486, "_timestamp": 1585572171.7137759, "_step": 434}
{"Episode reward": 51.7745093345638, "Episode length": 483, "Policy Loss": 0.9889464974403381, "Value Loss": 20.1816349029541, "_runtime": 2256.7082934379578, "_timestamp": 1585572172.5529268, "_step": 435}
{"Episode reward": 46.09999999999951, "Episode length": 539, "Policy Loss": 0.9817355275154114, "Value Loss": 16.897294998168945, "_runtime": 2258.196435213089, "_timestamp": 1585572174.0410686, "_step": 436}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.05359558016061783, "Value Loss": 9.44509220123291, "_runtime": 2259.715168237686, "_timestamp": 1585572175.5598016, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8202961683273315, "Value Loss": 0.048186998814344406, "_runtime": 2261.264357328415, "_timestamp": 1585572177.1089907, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8966996669769287, "Value Loss": 0.08174193650484085, "_runtime": 2262.8235137462616, "_timestamp": 1585572178.668147, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9471673965454102, "Value Loss": 0.029602890834212303, "_runtime": 2264.388000011444, "_timestamp": 1585572180.2326334, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0005409717559814, "Value Loss": 0.12128786742687225, "_runtime": 2265.932750225067, "_timestamp": 1585572181.7773836, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0498379468917847, "Value Loss": 0.3834650218486786, "_runtime": 2267.493890762329, "_timestamp": 1585572183.338524, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9998488426208496, "Value Loss": 0.019372837617993355, "_runtime": 2269.055644273758, "_timestamp": 1585572184.9002776, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9826363325119019, "Value Loss": 0.017357798293232918, "_runtime": 2270.6121985912323, "_timestamp": 1585572186.456832, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9435586333274841, "Value Loss": 0.023605698719620705, "_runtime": 2272.1845903396606, "_timestamp": 1585572188.0292237, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9083946347236633, "Value Loss": 0.06820803880691528, "_runtime": 2273.463277578354, "_timestamp": 1585572189.307911, "_step": 446}
{"Episode reward": 18.300000000000367, "Episode length": 817, "Policy Loss": 0.0937037542462349, "Value Loss": 11.284605979919434, "_runtime": 2275.0192935466766, "_timestamp": 1585572190.863927, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.829406201839447, "Value Loss": 0.053836654871702194, "_runtime": 2276.5951492786407, "_timestamp": 1585572192.4397826, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8255313038825989, "Value Loss": 0.026148738339543343, "_runtime": 2277.875006914139, "_timestamp": 1585572193.7196403, "_step": 449}
{"Episode reward": 17.300000000000423, "Episode length": 827, "Policy Loss": 0.14399996399879456, "Value Loss": 11.110489845275879, "_runtime": 2278.650422811508, "_timestamp": 1585572194.4950562, "_step": 450}
{"Episode reward": 51.59989771246869, "Episode length": 485, "Policy Loss": 0.9312447309494019, "Value Loss": 20.012439727783203, "_runtime": 2280.070072412491, "_timestamp": 1585572195.9147058, "_step": 451}
{"Episode reward": 9.10000000000089, "Episode length": 909, "Policy Loss": 0.12130667269229889, "Value Loss": 10.183602333068848, "_runtime": 2281.6049933433533, "_timestamp": 1585572197.4496267, "_step": 452}
{"Episode reward": -99.8240090429769, "Episode length": 999, "Policy Loss": -0.7417256236076355, "Value Loss": 0.12471997737884521, "_runtime": 2283.1191630363464, "_timestamp": 1585572198.9637964, "_step": 453}
{"Episode reward": -99.8054531827555, "Episode length": 999, "Policy Loss": -0.7240944504737854, "Value Loss": 0.0824585035443306, "_runtime": 2284.709416627884, "_timestamp": 1585572200.55405, "_step": 454}
{"Episode reward": -99.82402100711921, "Episode length": 999, "Policy Loss": -0.7343960404396057, "Value Loss": 0.13859952986240387, "_runtime": 2286.268977165222, "_timestamp": 1585572202.1136105, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.763160228729248, "Value Loss": 0.03258407488465309, "_runtime": 2287.0472869873047, "_timestamp": 1585572202.8919203, "_step": 456}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": 1.1896412372589111, "Value Loss": 19.49742889404297, "_runtime": 2288.5943989753723, "_timestamp": 1585572204.4390323, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7846776843070984, "Value Loss": 0.020924976095557213, "_runtime": 2289.785100698471, "_timestamp": 1585572205.629734, "_step": 458}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.28539273142814636, "Value Loss": 12.016613006591797, "_runtime": 2290.5949063301086, "_timestamp": 1585572206.4395397, "_step": 459}
{"Episode reward": 47.34290456175757, "Episode length": 527, "Policy Loss": 0.7413175106048584, "Value Loss": 17.49007225036621, "_runtime": 2292.03307557106, "_timestamp": 1585572207.877709, "_step": 460}
{"Episode reward": 7.5000000000009805, "Episode length": 925, "Policy Loss": 0.27952468395233154, "Value Loss": 10.413272857666016, "_runtime": 2293.573990345001, "_timestamp": 1585572209.4186237, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.731285810470581, "Value Loss": 0.036413490772247314, "_runtime": 2294.160147190094, "_timestamp": 1585572210.0047805, "_step": 462}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": 1.3997102975845337, "Value Loss": 25.148927688598633, "_runtime": 2295.7087359428406, "_timestamp": 1585572211.5533693, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6879782676696777, "Value Loss": 0.11634895205497742, "_runtime": 2297.263841867447, "_timestamp": 1585572213.1084752, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6655780076980591, "Value Loss": 0.10118681192398071, "_runtime": 2298.7679085731506, "_timestamp": 1585572214.612542, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6825153231620789, "Value Loss": 0.045805126428604126, "_runtime": 2299.446344614029, "_timestamp": 1585572215.290978, "_step": 466}
{"Episode reward": 58.32067871093719, "Episode length": 417, "Policy Loss": 1.4568228721618652, "Value Loss": 23.143577575683594, "_runtime": 2300.7012672424316, "_timestamp": 1585572216.5459006, "_step": 467}
{"Episode reward": 20.00000000000027, "Episode length": 800, "Policy Loss": 0.3613087832927704, "Value Loss": 11.778459548950195, "_runtime": 2302.2526791095734, "_timestamp": 1585572218.0973125, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6453614234924316, "Value Loss": 0.0567670501768589, "_runtime": 2303.7676255702972, "_timestamp": 1585572219.612259, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6092476844787598, "Value Loss": 0.0998302772641182, "_runtime": 2304.4113817214966, "_timestamp": 1585572220.256015, "_step": 470}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.470029592514038, "Value Loss": 23.6153564453125, "_runtime": 2305.0679228305817, "_timestamp": 1585572220.9125562, "_step": 471}
{"Episode reward": 59.32955548167199, "Episode length": 408, "Policy Loss": 1.324407696723938, "Value Loss": 22.293315887451172, "_runtime": 2306.5544905662537, "_timestamp": 1585572222.399124, "_step": 472}
{"Episode reward": 3.800000000001191, "Episode length": 962, "Policy Loss": 0.16296668350696564, "Value Loss": 9.565464973449707, "_runtime": 2307.3945026397705, "_timestamp": 1585572223.239136, "_step": 473}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.8973777294158936, "Value Loss": 17.002058029174805, "_runtime": 2308.9407618045807, "_timestamp": 1585572224.7853951, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7185253500938416, "Value Loss": 0.053912680596113205, "_runtime": 2310.5004589557648, "_timestamp": 1585572226.3450923, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7406536340713501, "Value Loss": 0.05846058204770088, "_runtime": 2312.0255258083344, "_timestamp": 1585572227.8701591, "_step": 476}
{"Episode reward": -99.80444431453803, "Episode length": 999, "Policy Loss": -0.8036963939666748, "Value Loss": 0.12140929698944092, "_runtime": 2313.03919506073, "_timestamp": 1585572228.8838284, "_step": 477}
{"Episode reward": 34.59999999999944, "Episode length": 654, "Policy Loss": 0.4329022467136383, "Value Loss": 13.901193618774414, "_runtime": 2313.817374944687, "_timestamp": 1585572229.6620083, "_step": 478}
{"Episode reward": 51.39999999999959, "Episode length": 486, "Policy Loss": 0.798926055431366, "Value Loss": 18.074068069458008, "_runtime": 2314.9228761196136, "_timestamp": 1585572230.7675095, "_step": 479}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.4419223368167877, "Value Loss": 13.49350643157959, "_runtime": 2316.4695205688477, "_timestamp": 1585572232.314154, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7474258542060852, "Value Loss": 0.04593658447265625, "_runtime": 2317.4633009433746, "_timestamp": 1585572233.3079343, "_step": 481}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.5243236422538757, "Value Loss": 14.173578262329102, "_runtime": 2318.8988723754883, "_timestamp": 1585572234.7435057, "_step": 482}
{"Episode reward": 6.300000000001049, "Episode length": 937, "Policy Loss": 0.2290409654378891, "Value Loss": 9.770988464355469, "_runtime": 2320.437704563141, "_timestamp": 1585572236.282338, "_step": 483}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": 0.1140064001083374, "Value Loss": 8.936454772949219, "_runtime": 2321.974156141281, "_timestamp": 1585572237.8187895, "_step": 484}
{"Episode reward": -99.80387213229993, "Episode length": 999, "Policy Loss": -0.7228536009788513, "Value Loss": 0.027437342330813408, "_runtime": 2322.975663661957, "_timestamp": 1585572238.820297, "_step": 485}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.9365782737731934, "Value Loss": 14.389603614807129, "_runtime": 2323.5943608283997, "_timestamp": 1585572239.4389942, "_step": 486}
{"Episode reward": 62.19999999999974, "Episode length": 378, "Policy Loss": 1.458414077758789, "Value Loss": 25.409513473510742, "_runtime": 2324.308183670044, "_timestamp": 1585572240.152817, "_step": 487}
{"Episode reward": 54.59999999999963, "Episode length": 454, "Policy Loss": 1.0042312145233154, "Value Loss": 19.494298934936523, "_runtime": 2325.8415710926056, "_timestamp": 1585572241.6862044, "_step": 488}
{"Episode reward": -99.85468631386617, "Episode length": 999, "Policy Loss": -0.6708117127418518, "Value Loss": 0.1034323126077652, "_runtime": 2327.3349220752716, "_timestamp": 1585572243.1795554, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.669033408164978, "Value Loss": 0.11568575352430344, "_runtime": 2328.842028617859, "_timestamp": 1585572244.686662, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6834666132926941, "Value Loss": 0.15056847035884857, "_runtime": 2329.4407155513763, "_timestamp": 1585572245.285349, "_step": 491}
{"Episode reward": 63.39999999999976, "Episode length": 366, "Policy Loss": 1.5685917139053345, "Value Loss": 24.09990882873535, "_runtime": 2329.815135717392, "_timestamp": 1585572245.659769, "_step": 492}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": 3.006939649581909, "Value Loss": 40.22700119018555, "_runtime": 2331.3463439941406, "_timestamp": 1585572247.1909773, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7383953332901001, "Value Loss": 0.03959638625383377, "_runtime": 2332.876888513565, "_timestamp": 1585572248.7215219, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7603407502174377, "Value Loss": 0.061091214418411255, "_runtime": 2333.9776887893677, "_timestamp": 1585572249.8223221, "_step": 495}
{"Episode reward": 25.777567195892274, "Episode length": 743, "Policy Loss": 0.3220272958278656, "Value Loss": 13.303666114807129, "_runtime": 2335.5262920856476, "_timestamp": 1585572251.3709254, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7331076860427856, "Value Loss": 0.027234500274062157, "_runtime": 2337.072657585144, "_timestamp": 1585572252.917291, "_step": 497}
{"Episode reward": -99.80063345432141, "Episode length": 999, "Policy Loss": -0.7065896987915039, "Value Loss": 0.042585305869579315, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167, -0.006031841970980167]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-1.0481972694396973, -1.0317249298095703, -1.0152525901794434, -0.9987802505493164, -0.9823079705238342, -0.9658356308937073, -0.9493632912635803, -0.9328909516334534, -0.9164186120033264, -0.8999463319778442, -0.8834739923477173, -0.8670016527175903, -0.8505293130874634, -0.8340569734573364, -0.8175846338272095, -0.8011122941970825, -0.7846399545669556, -0.7681676149368286, -0.7516953349113464, -0.7352229952812195, -0.7187506556510925, -0.7022783756256104, -0.6858060359954834, -0.6693336963653564, -0.6528613567352295, -0.6363890171051025, -0.6199166774749756, -0.6034443378448486, -0.5869719982147217, -0.5704996585845947, -0.5540273189544678, -0.5375550389289856, -0.5210826992988586, -0.5046103596687317, -0.48813802003860474, -0.4716656804084778, -0.4551934003829956, -0.43872106075286865, -0.4222487211227417, -0.40577638149261475, -0.3893040418624878, -0.37283170223236084, -0.35635942220687866, -0.3398870825767517, -0.32341474294662476, -0.3069424033164978, -0.29047006368637085, -0.2739977240562439, -0.2575254440307617, -0.24105310440063477, -0.2245807647705078, -0.20810842514038086, -0.1916360855102539, -0.17516374588012695, -0.15869140625, -0.14221912622451782, -0.12574678659439087, -0.10927444696426392, -0.09280210733413696, -0.07632976770401001, -0.05985742807388306, -0.04338514804840088, -0.026912808418273926, -0.010440468788146973, 0.0060318708419799805]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.019893158227205276, -0.019582320004701614, -0.019271479919552803, -0.01896064169704914, -0.01864980161190033, -0.018338963389396667, -0.018028125166893005, -0.017717285081744194, -0.017406446859240532, -0.01709560677409172, -0.01678476855158806, -0.016473930329084396, -0.016163090243935585, -0.015852252021431923, -0.015541411936283112, -0.01523057371377945, -0.014919734559953213, -0.014608895406126976, -0.014298057183623314, -0.013987217098474503, -0.01367637887597084, -0.013365539722144604, -0.013054700568318367, -0.012743862345814705, -0.012433022260665894, -0.012122184038162231, -0.011811344884335995, -0.011500505730509758, -0.011189666576683521, -0.010878827422857285, -0.010567989200353622, -0.010257150046527386, -0.009946310892701149, -0.009635471738874912, -0.009324632585048676, -0.009013794362545013, -0.008702955208718777, -0.00839211605489254, -0.008081276901066303, -0.0077704377472400665, -0.007459599524736404, -0.007148760370910168, -0.006837921217083931, -0.006527082063257694, -0.0062162429094314575, -0.005905403755605221, -0.005594565533101559, -0.005283726379275322, -0.004972887225449085, -0.0046620480716228485, -0.004351208917796612, -0.004040369763970375, -0.003729531541466713, -0.0034186914563179016, -0.0031078532338142395, -0.0027970150113105774, -0.002486174926161766, -0.002175336703658104, -0.0018644966185092926, -0.0015536583960056305, -0.0012428201735019684, -0.000931980088353157, -0.0006211418658494949, -0.0003103017807006836, 5.364418029785156e-07]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 4.0, 7.0, 4.0, 3.0, 5.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 1.0, 0.0, 288.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 27.0, 57.0, 38.0], "bins": [-0.08857148140668869, -0.08689553290605545, -0.08521957695484161, -0.08354362845420837, -0.08186767995357513, -0.0801917240023613, -0.07851577550172806, -0.07683982700109482, -0.07516387104988098, -0.07348792254924774, -0.0718119740486145, -0.07013601809740067, -0.06846006959676743, -0.06678411364555359, -0.06510816514492035, -0.06343221664428711, -0.06175626441836357, -0.06008031219244003, -0.05840436369180679, -0.056728411465883255, -0.05505245923995972, -0.05337651073932648, -0.05170055851340294, -0.0500246062874794, -0.04834865778684616, -0.04667270556092262, -0.044996753334999084, -0.043320801109075546, -0.041644852608442307, -0.03996890038251877, -0.03829294815659523, -0.03661699965596199, -0.03494104743003845, -0.033265095204114914, -0.031589146703481674, -0.029913194477558136, -0.028237242251634598, -0.026561293751001358, -0.02488534152507782, -0.02320939302444458, -0.021533437073230743, -0.019857488572597504, -0.018181540071964264, -0.016505584120750427, -0.014829635620117188, -0.013153687119483948, -0.011477731168270111, -0.009801782667636871, -0.008125834167003632, -0.006449878215789795, -0.004773929715156555, -0.0030979737639427185, -0.0014220252633094788, 0.000253923237323761, 0.0019298791885375977, 0.0036058276891708374, 0.005281776189804077, 0.006957732141017914, 0.008633680641651154, 0.010309629142284393, 0.01198558509349823, 0.01366153359413147, 0.01533748209476471, 0.017013438045978546, 0.018689386546611786]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 9.0, 4.0, 3.0, 0.0, 1.0, 1.0], "bins": [-0.43434208631515503, -0.42644932866096497, -0.4185565710067749, -0.41066381335258484, -0.4027710556983948, -0.3948782682418823, -0.38698554039001465, -0.3790927529335022, -0.37119999527931213, -0.36330723762512207, -0.355414479970932, -0.34752172231674194, -0.3396289646625519, -0.3317362070083618, -0.32384344935417175, -0.3159506916999817, -0.30805790424346924, -0.30016517639160156, -0.2922723889350891, -0.28437963128089905, -0.276486873626709, -0.2685941159725189, -0.26070135831832886, -0.2528086006641388, -0.24491584300994873, -0.23702307045459747, -0.2291303128004074, -0.22123755514621735, -0.21334479749202728, -0.20545203983783722, -0.19755926728248596, -0.1896665096282959, -0.18177375197410583, -0.17388099431991577, -0.1659882366657257, -0.15809547901153564, -0.15020272135734558, -0.14230996370315552, -0.13441717624664307, -0.126524418592453, -0.11863166093826294, -0.11073890328407288, -0.10284614562988281, -0.09495338797569275, -0.08706063032150269, -0.07916787266731262, -0.07127511501312256, -0.0633823573589325, -0.05548959970474243, -0.04759681224822998, -0.03970405459403992, -0.031811296939849854, -0.02391853928565979, -0.016025781631469727, -0.008133023977279663, -0.0002402663230895996, 0.007652491331100464, 0.015545248985290527, 0.02343800663948059, 0.03133079409599304, 0.039223551750183105, 0.04711630940437317, 0.05500906705856323, 0.0629018247127533, 0.07079458236694336]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 2.0, 5.0, 9.0, 4.0, 0.0, 1.0, 11.0, 7.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.031207412481307983, -0.027602870017290115, -0.023998325690627098, -0.02039378136396408, -0.016789238899946213, -0.013184696435928345, -0.009580152109265327, -0.00597560778260231, -0.002371065318584442, 0.001233477145433426, 0.004838019609451294, 0.00844256579875946, 0.012047108262777328, 0.015651650726795197, 0.019256196916103363, 0.02286073938012123, 0.0264652818441391, 0.030069824308156967, 0.033674366772174835, 0.037278912961483, 0.04088345170021057, 0.04448799788951874, 0.048092544078826904, 0.051697082817554474, 0.05530162900686264, 0.05890617519617081, 0.06251071393489838, 0.06611526012420654, 0.06971980631351471, 0.07332434505224228, 0.07692889124155045, 0.08053342998027802, 0.08413797616958618, 0.08774252235889435, 0.09134706109762192, 0.09495159983634949, 0.09855614602565765, 0.10216069221496582, 0.10576523840427399, 0.10936978459358215, 0.11297431588172913, 0.11657886207103729, 0.12018340826034546, 0.12378795444965363, 0.1273925006389618, 0.13099704682826996, 0.13460157811641693, 0.1382061243057251, 0.14181067049503326, 0.14541521668434143, 0.1490197628736496, 0.15262429416179657, 0.15622884035110474, 0.1598333865404129, 0.16343793272972107, 0.16704247891902924, 0.1706470251083374, 0.17425155639648438, 0.17785610258579254, 0.1814606487751007, 0.18506519496440887, 0.18866974115371704, 0.192274272441864, 0.19587881863117218, 0.19948336482048035]}, "_runtime": 2338.590448617935, "_timestamp": 1585572254.435082, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6745865941047668, "Value Loss": 0.06082063540816307, "_runtime": 2338.590448617935, "_timestamp": 1585572254.435082, "_step": 499}
