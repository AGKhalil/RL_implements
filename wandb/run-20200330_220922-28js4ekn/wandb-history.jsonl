{"Episode reward": -57.63063072409113, "Episode length": 999, "Policy Loss": -0.08042404800653458, "Value Loss": 0.004816113505512476, "_runtime": 8812.316205978394, "_timestamp": 1585606181.9490755, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18450255692005157, "Value Loss": 31.696434020996094, "_runtime": 8813.831072330475, "_timestamp": 1585606183.4639418, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -18.773204803466797, "Value Loss": 5795.39599609375, "_runtime": 8815.413615226746, "_timestamp": 1585606185.0464847, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -75.3679428100586, "Value Loss": 3388.57177734375, "_runtime": 8816.967036485672, "_timestamp": 1585606186.599906, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0029537677764893, "Value Loss": 3665.27783203125, "_runtime": 8818.553723096848, "_timestamp": 1585606188.1865926, "_step": 4}
{"Episode reward": -37.027830796384485, "Episode length": 999, "Policy Loss": -1.1241334676742554, "Value Loss": 1825.4329833984375, "_runtime": 8819.169825315475, "_timestamp": 1585606188.8026948, "_step": 5}
{"Episode reward": 83.62064445263617, "Episode length": 366, "Policy Loss": -17.081605911254883, "Value Loss": 18412.978515625, "_runtime": 8819.857353448868, "_timestamp": 1585606189.490223, "_step": 6}
{"Episode reward": 80.93093802943017, "Episode length": 425, "Policy Loss": -1.3329826593399048, "Value Loss": 387.446533203125, "_runtime": 8821.406779527664, "_timestamp": 1585606191.039649, "_step": 7}
{"Episode reward": -58.18053714390875, "Episode length": 999, "Policy Loss": -1.5628654956817627, "Value Loss": 11.714971542358398, "_runtime": 8822.920201301575, "_timestamp": 1585606192.5530708, "_step": 8}
{"Episode reward": -70.76562496470292, "Episode length": 999, "Policy Loss": -2.157453775405884, "Value Loss": 60.53403091430664, "_runtime": 8824.44484090805, "_timestamp": 1585606194.0777104, "_step": 9}
{"Episode reward": -81.17327020844574, "Episode length": 999, "Policy Loss": -2.131483793258667, "Value Loss": 34.03032684326172, "_runtime": 8826.0179605484, "_timestamp": 1585606195.65083, "_step": 10}
{"Episode reward": -84.88227682734842, "Episode length": 999, "Policy Loss": -2.931913137435913, "Value Loss": 80.98543548583984, "_runtime": 8827.584451913834, "_timestamp": 1585606197.2173214, "_step": 11}
{"Episode reward": -86.8508512900872, "Episode length": 999, "Policy Loss": -6.154713153839111, "Value Loss": 96.11395263671875, "_runtime": 8829.149925231934, "_timestamp": 1585606198.7827947, "_step": 12}
{"Episode reward": -89.8543052676261, "Episode length": 999, "Policy Loss": -3.7761120796203613, "Value Loss": 47.82540512084961, "_runtime": 8830.729913711548, "_timestamp": 1585606200.3627832, "_step": 13}
{"Episode reward": -92.81684604949243, "Episode length": 999, "Policy Loss": -4.400461196899414, "Value Loss": 22.54479217529297, "_runtime": 8832.296244621277, "_timestamp": 1585606201.929114, "_step": 14}
{"Episode reward": -92.43110104379083, "Episode length": 999, "Policy Loss": -4.019890785217285, "Value Loss": 15.095466613769531, "_runtime": 8833.87607884407, "_timestamp": 1585606203.5089483, "_step": 15}
{"Episode reward": -92.04864548818804, "Episode length": 999, "Policy Loss": -4.932539939880371, "Value Loss": 27.72018814086914, "_runtime": 8835.44777393341, "_timestamp": 1585606205.0806434, "_step": 16}
{"Episode reward": -93.84105349758822, "Episode length": 999, "Policy Loss": -1.1866534948349, "Value Loss": 107.01067352294922, "_runtime": 8837.0172457695, "_timestamp": 1585606206.6501153, "_step": 17}
{"Episode reward": -94.68802450391635, "Episode length": 999, "Policy Loss": -0.16672800481319427, "Value Loss": 199.8881072998047, "_runtime": 8838.598771810532, "_timestamp": 1585606208.2316413, "_step": 18}
{"Episode reward": -96.44114769824735, "Episode length": 999, "Policy Loss": -2.341891050338745, "Value Loss": 133.09869384765625, "_runtime": 8840.180683851242, "_timestamp": 1585606209.8135533, "_step": 19}
{"Episode reward": -97.04555166166992, "Episode length": 999, "Policy Loss": -3.4066238403320312, "Value Loss": 38.90892791748047, "_runtime": 8841.798577308655, "_timestamp": 1585606211.4314468, "_step": 20}
{"Episode reward": -95.76143272552102, "Episode length": 999, "Policy Loss": -6.702212333679199, "Value Loss": 346.9014587402344, "_runtime": 8843.363345623016, "_timestamp": 1585606212.996215, "_step": 21}
{"Episode reward": -95.0213226711532, "Episode length": 999, "Policy Loss": -17.944622039794922, "Value Loss": 827.630615234375, "_runtime": 8844.943561553955, "_timestamp": 1585606214.576431, "_step": 22}
{"Episode reward": -95.88045406506022, "Episode length": 999, "Policy Loss": -1.312846064567566, "Value Loss": 51.93851089477539, "_runtime": 8846.525636196136, "_timestamp": 1585606216.1585057, "_step": 23}
{"Episode reward": -96.32585934521438, "Episode length": 999, "Policy Loss": 0.351428359746933, "Value Loss": 356.5942077636719, "_runtime": 8848.102313280106, "_timestamp": 1585606217.7351828, "_step": 24}
{"Episode reward": -95.75147681875775, "Episode length": 999, "Policy Loss": 19.129819869995117, "Value Loss": 1144.9654541015625, "_runtime": 8849.686493396759, "_timestamp": 1585606219.3193629, "_step": 25}
{"Episode reward": -96.49239744442549, "Episode length": 999, "Policy Loss": 6.4593071937561035, "Value Loss": 212.14573669433594, "_runtime": 8851.264981746674, "_timestamp": 1585606220.8978512, "_step": 26}
{"Episode reward": -96.63857879892346, "Episode length": 999, "Policy Loss": 2.760988712310791, "Value Loss": 180.7045135498047, "_runtime": 8852.841099977493, "_timestamp": 1585606222.4739695, "_step": 27}
{"Episode reward": -95.72691164582845, "Episode length": 999, "Policy Loss": -3.1974432468414307, "Value Loss": 1347.1849365234375, "_runtime": 8854.401083230972, "_timestamp": 1585606224.0339527, "_step": 28}
{"Episode reward": -97.02800274201525, "Episode length": 999, "Policy Loss": -1.6848368644714355, "Value Loss": 127.76615905761719, "_runtime": 8855.968918561935, "_timestamp": 1585606225.601788, "_step": 29}
{"Episode reward": -95.99434689309443, "Episode length": 999, "Policy Loss": -11.92860221862793, "Value Loss": 323.7512512207031, "_runtime": 8857.54522562027, "_timestamp": 1585606227.178095, "_step": 30}
{"Episode reward": -96.09219578746814, "Episode length": 999, "Policy Loss": -5.590481758117676, "Value Loss": 44.82792282104492, "_runtime": 8859.106417894363, "_timestamp": 1585606228.7392874, "_step": 31}
{"Episode reward": -97.0986367975323, "Episode length": 999, "Policy Loss": 2.1248505115509033, "Value Loss": 300.6893310546875, "_runtime": 8860.689834356308, "_timestamp": 1585606230.3227038, "_step": 32}
{"Episode reward": -97.41597147519182, "Episode length": 999, "Policy Loss": 3.4361231327056885, "Value Loss": 917.8823852539062, "_runtime": 8862.278935194016, "_timestamp": 1585606231.9118047, "_step": 33}
{"Episode reward": -97.41051662608432, "Episode length": 999, "Policy Loss": -2.4104466438293457, "Value Loss": 190.92132568359375, "_runtime": 8863.863906145096, "_timestamp": 1585606233.4967756, "_step": 34}
{"Episode reward": -96.53707961802137, "Episode length": 999, "Policy Loss": -4.133407115936279, "Value Loss": 27.272525787353516, "_runtime": 8865.48448228836, "_timestamp": 1585606235.1173518, "_step": 35}
{"Episode reward": -96.0327801692042, "Episode length": 999, "Policy Loss": -3.3441975116729736, "Value Loss": 93.72734832763672, "_runtime": 8867.073291778564, "_timestamp": 1585606236.7061613, "_step": 36}
{"Episode reward": -97.05964778891443, "Episode length": 999, "Policy Loss": -5.273757457733154, "Value Loss": 3.035080909729004, "_runtime": 8868.647900342941, "_timestamp": 1585606238.2807698, "_step": 37}
{"Episode reward": -97.20014523217903, "Episode length": 999, "Policy Loss": -6.739499568939209, "Value Loss": 34.23197937011719, "_runtime": 8870.22485256195, "_timestamp": 1585606239.857722, "_step": 38}
{"Episode reward": -96.66243734969383, "Episode length": 999, "Policy Loss": -8.844762802124023, "Value Loss": 94.17738342285156, "_runtime": 8871.812121868134, "_timestamp": 1585606241.4449914, "_step": 39}
{"Episode reward": -96.43241071988069, "Episode length": 999, "Policy Loss": -9.031296730041504, "Value Loss": 414.63653564453125, "_runtime": 8873.383519172668, "_timestamp": 1585606243.0163887, "_step": 40}
{"Episode reward": -96.45096190252733, "Episode length": 999, "Policy Loss": -8.664234161376953, "Value Loss": 142.7132110595703, "_runtime": 8874.964037179947, "_timestamp": 1585606244.5969067, "_step": 41}
{"Episode reward": -97.0294096747734, "Episode length": 999, "Policy Loss": -9.067357063293457, "Value Loss": 133.84547424316406, "_runtime": 8876.551150560379, "_timestamp": 1585606246.18402, "_step": 42}
{"Episode reward": -97.64189014475224, "Episode length": 999, "Policy Loss": -0.7601032853126526, "Value Loss": 41.46455001831055, "_runtime": 8878.133986234665, "_timestamp": 1585606247.7668557, "_step": 43}
{"Episode reward": -97.71403769557662, "Episode length": 999, "Policy Loss": -0.004127027001231909, "Value Loss": 9.686689376831055, "_runtime": 8879.717815160751, "_timestamp": 1585606249.3506846, "_step": 44}
{"Episode reward": -96.69462042230465, "Episode length": 999, "Policy Loss": 2.1366629600524902, "Value Loss": 16.40439224243164, "_runtime": 8881.286063194275, "_timestamp": 1585606250.9189327, "_step": 45}
{"Episode reward": -97.31605735137919, "Episode length": 999, "Policy Loss": 4.07916259765625, "Value Loss": 12.722086906433105, "_runtime": 8882.868887662888, "_timestamp": 1585606252.5017571, "_step": 46}
{"Episode reward": -98.71429838738254, "Episode length": 999, "Policy Loss": 4.729065418243408, "Value Loss": 4.218930244445801, "_runtime": 8884.446835041046, "_timestamp": 1585606254.0797045, "_step": 47}
{"Episode reward": -96.44880333393948, "Episode length": 999, "Policy Loss": 6.738850116729736, "Value Loss": 30.99433708190918, "_runtime": 8886.035564184189, "_timestamp": 1585606255.6684337, "_step": 48}
{"Episode reward": -97.80049353016614, "Episode length": 999, "Policy Loss": 11.83577823638916, "Value Loss": 58.17569351196289, "_runtime": 8887.620815515518, "_timestamp": 1585606257.253685, "_step": 49}
{"Episode reward": -96.9322952530489, "Episode length": 999, "Policy Loss": 7.403066635131836, "Value Loss": 9.844735145568848, "_runtime": 8889.229665279388, "_timestamp": 1585606258.8625348, "_step": 50}
{"Episode reward": -96.5169574503637, "Episode length": 999, "Policy Loss": 8.28022575378418, "Value Loss": 28.473196029663086, "_runtime": 8890.815431594849, "_timestamp": 1585606260.448301, "_step": 51}
{"Episode reward": -97.07810336146895, "Episode length": 999, "Policy Loss": 7.490079879760742, "Value Loss": 11.590658187866211, "_runtime": 8892.388381004333, "_timestamp": 1585606262.0212505, "_step": 52}
{"Episode reward": -97.24261202288875, "Episode length": 999, "Policy Loss": 9.194252014160156, "Value Loss": 9.969687461853027, "_runtime": 8893.970842838287, "_timestamp": 1585606263.6037123, "_step": 53}
{"Episode reward": -97.28668721850163, "Episode length": 999, "Policy Loss": 6.364858627319336, "Value Loss": 44.86170196533203, "_runtime": 8895.55611538887, "_timestamp": 1585606265.1889849, "_step": 54}
{"Episode reward": -96.83269466645133, "Episode length": 999, "Policy Loss": 8.487282752990723, "Value Loss": 15.776785850524902, "_runtime": 8897.128987789154, "_timestamp": 1585606266.7618573, "_step": 55}
{"Episode reward": -98.8707964287949, "Episode length": 999, "Policy Loss": 6.952549457550049, "Value Loss": 57.108543395996094, "_runtime": 8898.702461242676, "_timestamp": 1585606268.3353307, "_step": 56}
{"Episode reward": -97.50335662087562, "Episode length": 999, "Policy Loss": 8.572237968444824, "Value Loss": 14.414212226867676, "_runtime": 8900.288533687592, "_timestamp": 1585606269.9214032, "_step": 57}
{"Episode reward": -98.24441955811295, "Episode length": 999, "Policy Loss": 7.988026142120361, "Value Loss": 15.153684616088867, "_runtime": 8901.872978687286, "_timestamp": 1585606271.5058482, "_step": 58}
{"Episode reward": -97.85152640681086, "Episode length": 999, "Policy Loss": 8.676414489746094, "Value Loss": 6.621452808380127, "_runtime": 8903.444604635239, "_timestamp": 1585606273.077474, "_step": 59}
{"Episode reward": -97.93597904654305, "Episode length": 999, "Policy Loss": 8.301793098449707, "Value Loss": 5.904322147369385, "_runtime": 8905.030538320541, "_timestamp": 1585606274.6634078, "_step": 60}
{"Episode reward": -96.13614017629125, "Episode length": 999, "Policy Loss": 7.962713718414307, "Value Loss": 7.195972442626953, "_runtime": 8906.611573934555, "_timestamp": 1585606276.2444434, "_step": 61}
{"Episode reward": -98.40226191016538, "Episode length": 999, "Policy Loss": 8.169076919555664, "Value Loss": 7.618070602416992, "_runtime": 8908.183643579483, "_timestamp": 1585606277.816513, "_step": 62}
{"Episode reward": -97.84810140831064, "Episode length": 999, "Policy Loss": 7.904449939727783, "Value Loss": 4.578059673309326, "_runtime": 8909.758948087692, "_timestamp": 1585606279.3918176, "_step": 63}
{"Episode reward": -97.90797369273913, "Episode length": 999, "Policy Loss": 8.146575927734375, "Value Loss": 13.101527214050293, "_runtime": 8911.368822336197, "_timestamp": 1585606281.0016918, "_step": 64}
{"Episode reward": -96.38272231660727, "Episode length": 999, "Policy Loss": 7.252582550048828, "Value Loss": 10.376081466674805, "_runtime": 8912.938173532486, "_timestamp": 1585606282.571043, "_step": 65}
{"Episode reward": -97.45278084744706, "Episode length": 999, "Policy Loss": 7.327950954437256, "Value Loss": 11.46472454071045, "_runtime": 8914.515231370926, "_timestamp": 1585606284.1481009, "_step": 66}
{"Episode reward": -97.64826010909793, "Episode length": 999, "Policy Loss": 7.382788181304932, "Value Loss": 15.096132278442383, "_runtime": 8916.100913763046, "_timestamp": 1585606285.7337832, "_step": 67}
{"Episode reward": -97.7133088361209, "Episode length": 999, "Policy Loss": 7.712124824523926, "Value Loss": 16.41581916809082, "_runtime": 8917.681663036346, "_timestamp": 1585606287.3145325, "_step": 68}
{"Episode reward": -97.4891580853352, "Episode length": 999, "Policy Loss": 6.4601969718933105, "Value Loss": 5.86807918548584, "_runtime": 8919.264017820358, "_timestamp": 1585606288.8968873, "_step": 69}
{"Episode reward": -97.69049211110486, "Episode length": 999, "Policy Loss": 5.542321681976318, "Value Loss": 3.1305487155914307, "_runtime": 8920.846878290176, "_timestamp": 1585606290.4797478, "_step": 70}
{"Episode reward": -98.36436142712364, "Episode length": 999, "Policy Loss": 5.337673664093018, "Value Loss": 2.332176923751831, "_runtime": 8922.426642656326, "_timestamp": 1585606292.0595121, "_step": 71}
{"Episode reward": -97.762152400814, "Episode length": 999, "Policy Loss": 4.706771373748779, "Value Loss": 3.6238605976104736, "_runtime": 8924.001968383789, "_timestamp": 1585606293.6348379, "_step": 72}
{"Episode reward": -96.95975684657833, "Episode length": 999, "Policy Loss": 4.675803184509277, "Value Loss": 2.578214168548584, "_runtime": 8925.573830127716, "_timestamp": 1585606295.2066996, "_step": 73}
{"Episode reward": -97.59004666251887, "Episode length": 999, "Policy Loss": 4.270967960357666, "Value Loss": 4.234790325164795, "_runtime": 8927.154324054718, "_timestamp": 1585606296.7871935, "_step": 74}
{"Episode reward": -97.34991709163663, "Episode length": 999, "Policy Loss": 2.1872599124908447, "Value Loss": 14.905963897705078, "_runtime": 8928.731102466583, "_timestamp": 1585606298.363972, "_step": 75}
{"Episode reward": -98.51208723650912, "Episode length": 999, "Policy Loss": 4.173630237579346, "Value Loss": 2.033238649368286, "_runtime": 8930.306121349335, "_timestamp": 1585606299.9389908, "_step": 76}
{"Episode reward": -97.83107575896969, "Episode length": 999, "Policy Loss": 3.0744354724884033, "Value Loss": 5.396206378936768, "_runtime": 8931.875591516495, "_timestamp": 1585606301.508461, "_step": 77}
{"Episode reward": -97.91885162646322, "Episode length": 999, "Policy Loss": 3.424225330352783, "Value Loss": 1.48800528049469, "_runtime": 8933.451502799988, "_timestamp": 1585606303.0843723, "_step": 78}
{"Episode reward": -97.40783183091162, "Episode length": 999, "Policy Loss": 2.2621536254882812, "Value Loss": 2.509373903274536, "_runtime": 8935.07382440567, "_timestamp": 1585606304.706694, "_step": 79}
{"Episode reward": -98.88678124079301, "Episode length": 999, "Policy Loss": 2.882899522781372, "Value Loss": 0.6401280164718628, "_runtime": 8936.648261070251, "_timestamp": 1585606306.2811306, "_step": 80}
{"Episode reward": -96.01696179318867, "Episode length": 999, "Policy Loss": 2.5553085803985596, "Value Loss": 0.8076839447021484, "_runtime": 8938.232784032822, "_timestamp": 1585606307.8656535, "_step": 81}
{"Episode reward": -98.28244233495344, "Episode length": 999, "Policy Loss": 2.431363582611084, "Value Loss": 0.6590777039527893, "_runtime": 8939.818491458893, "_timestamp": 1585606309.451361, "_step": 82}
{"Episode reward": -98.07402220263774, "Episode length": 999, "Policy Loss": 2.318272352218628, "Value Loss": 1.2381635904312134, "_runtime": 8941.398380756378, "_timestamp": 1585606311.0312502, "_step": 83}
{"Episode reward": -97.6080522367814, "Episode length": 999, "Policy Loss": 2.4385733604431152, "Value Loss": 2.1965761184692383, "_runtime": 8942.979515314102, "_timestamp": 1585606312.6123848, "_step": 84}
{"Episode reward": -95.89092115146708, "Episode length": 999, "Policy Loss": 2.83443021774292, "Value Loss": 4.1624345779418945, "_runtime": 8944.577825546265, "_timestamp": 1585606314.210695, "_step": 85}
{"Episode reward": -97.73737308193974, "Episode length": 999, "Policy Loss": 1.6103649139404297, "Value Loss": 0.7879363894462585, "_runtime": 8946.165047168732, "_timestamp": 1585606315.7979167, "_step": 86}
{"Episode reward": -98.39762015807428, "Episode length": 999, "Policy Loss": 1.3613872528076172, "Value Loss": 0.38128411769866943, "_runtime": 8947.740458488464, "_timestamp": 1585606317.373328, "_step": 87}
{"Episode reward": -97.5953911127388, "Episode length": 999, "Policy Loss": 1.382574439048767, "Value Loss": 0.5788245797157288, "_runtime": 8949.321941375732, "_timestamp": 1585606318.9548109, "_step": 88}
{"Episode reward": -98.01805227884182, "Episode length": 999, "Policy Loss": 1.1058849096298218, "Value Loss": 0.23808962106704712, "_runtime": 8950.90398812294, "_timestamp": 1585606320.5368576, "_step": 89}
{"Episode reward": -97.49558962932647, "Episode length": 999, "Policy Loss": 0.9609474539756775, "Value Loss": 0.1890215128660202, "_runtime": 8952.489729642868, "_timestamp": 1585606322.1225991, "_step": 90}
{"Episode reward": -97.91269546571284, "Episode length": 999, "Policy Loss": 0.7609705328941345, "Value Loss": 0.1358647495508194, "_runtime": 8954.072564601898, "_timestamp": 1585606323.705434, "_step": 91}
{"Episode reward": -98.43150693267047, "Episode length": 999, "Policy Loss": 0.5111632347106934, "Value Loss": 0.19311703741550446, "_runtime": 8955.654287576675, "_timestamp": 1585606325.287157, "_step": 92}
{"Episode reward": -98.03686192511793, "Episode length": 999, "Policy Loss": 0.40645477175712585, "Value Loss": 0.22431500256061554, "_runtime": 8957.23578453064, "_timestamp": 1585606326.868654, "_step": 93}
{"Episode reward": -98.39125984339942, "Episode length": 999, "Policy Loss": 0.1995902806520462, "Value Loss": 0.49743083119392395, "_runtime": 8958.854255914688, "_timestamp": 1585606328.4871254, "_step": 94}
{"Episode reward": -98.34912391978246, "Episode length": 999, "Policy Loss": 0.2511482238769531, "Value Loss": 0.18566285073757172, "_runtime": 8960.440061092377, "_timestamp": 1585606330.0729306, "_step": 95}
{"Episode reward": -96.74512898881616, "Episode length": 999, "Policy Loss": -0.16755695641040802, "Value Loss": 0.5474134683609009, "_runtime": 8962.02565908432, "_timestamp": 1585606331.6585286, "_step": 96}
{"Episode reward": -97.82021664510512, "Episode length": 999, "Policy Loss": 0.13304226100444794, "Value Loss": 0.06320308893918991, "_runtime": 8963.599028110504, "_timestamp": 1585606333.2318976, "_step": 97}
{"Episode reward": -97.30621086774192, "Episode length": 999, "Policy Loss": 0.029015278443694115, "Value Loss": 0.09543562680482864, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547, -6.854930877685547]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-7.279604434967041, -7.1067962646484375, -6.933988094329834, -6.7611799240112305, -6.588371753692627, -6.415563583374023, -6.242755889892578, -6.069947242736816, -5.897139549255371, -5.724330902099609, -5.551523208618164, -5.3787150382995605, -5.205906867980957, -5.0330986976623535, -4.86029052734375, -4.6874823570251465, -4.514674186706543, -4.3418660163879395, -4.169057846069336, -3.9962496757507324, -3.823441505432129, -3.6506335735321045, -3.477825403213501, -3.3050172328948975, -3.132209300994873, -2.9594011306762695, -2.786592960357666, -2.6137847900390625, -2.440976619720459, -2.2681684494018555, -2.095360279083252, -1.9225521087646484, -1.749743938446045, -1.5769357681274414, -1.404127597808838, -1.2313194274902344, -1.0585112571716309, -0.8857030868530273, -0.7128949165344238, -0.5400867462158203, -0.3672785758972168, -0.19447088241577148, -0.02166271209716797, 0.15114545822143555, 0.32395362854003906, 0.4967617988586426, 0.6695699691772461, 0.8423781394958496, 1.015185832977295, 1.1879944801330566, 1.360802173614502, 1.5336108207702637, 1.706418514251709, 1.8792271614074707, 2.052034854888916, 2.2248435020446777, 2.397651195526123, 2.5704598426818848, 2.74326753616333, 2.916076183319092, 3.088883876800537, 3.261692523956299, 3.434500217437744, 3.607308864593506, 3.780116558074951]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-3.2404072284698486, -3.110093355178833, -2.9797794818878174, -2.8494656085968018, -2.719151735305786, -2.5888378620147705, -2.458523750305176, -2.32820987701416, -2.1978960037231445, -2.067582130432129, -1.9372683763504028, -1.8069545030593872, -1.676640510559082, -1.5463266372680664, -1.4160127639770508, -1.2856988906860352, -1.1553850173950195, -1.025071144104004, -0.8947572708129883, -0.7644433975219727, -0.634129524230957, -0.5038156509399414, -0.3735017776489258, -0.24318790435791016, -0.11287379264831543, 0.017440080642700195, 0.14775395393371582, 0.27806782722473145, 0.40838170051574707, 0.5386955738067627, 0.6690094470977783, 0.799323320388794, 0.9296371936798096, 1.0599510669708252, 1.1902649402618408, 1.3205788135528564, 1.450892686843872, 1.5812065601348877, 1.7115204334259033, 1.841834306716919, 1.9721481800079346, 2.10246205329895, 2.232775926589966, 2.3630897998809814, 2.493403673171997, 2.6237175464630127, 2.7540314197540283, 2.884345293045044, 3.0146596431732178, 3.1449735164642334, 3.275287389755249, 3.4056012630462646, 3.5359151363372803, 3.666229009628296, 3.7965428829193115, 3.926856756210327, 4.057170867919922, 4.1874847412109375, 4.317798614501953, 4.448112487792969, 4.578426361083984, 4.708740234375, 4.839054107666016, 4.969367980957031, 5.099681854248047]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 5.0, 3.0, 1.0, 6.0, 3.0, 5.0, 8.0, 8.0, 11.0, 9.0, 12.0, 11.0, 8.0, 11.0, 12.0, 14.0, 7.0, 15.0, 39.0, 61.0, 47.0, 44.0, 32.0, 22.0, 12.0, 11.0, 10.0, 8.0, 7.0, 9.0, 9.0, 5.0, 0.0, 7.0, 4.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-3.6730918884277344, -3.547316074371338, -3.4215404987335205, -3.295764923095703, -3.1699891090393066, -3.04421329498291, -2.9184377193450928, -2.7926621437072754, -2.666886329650879, -2.5411105155944824, -2.415334939956665, -2.2895593643188477, -2.163783550262451, -2.0380077362060547, -1.9122321605682373, -1.7864564657211304, -1.6606807708740234, -1.534904956817627, -1.4091293811798096, -1.2833538055419922, -1.1575779914855957, -1.0318021774291992, -0.9060266017913818, -0.7802510261535645, -0.654475212097168, -0.5286993980407715, -0.4029238224029541, -0.2771482467651367, -0.15137243270874023, -0.02559661865234375, 0.10017895698547363, 0.22595453262329102, 0.3517303466796875, 0.477506160736084, 0.6032819747924805, 0.7290573120117188, 0.8548331260681152, 0.9806089401245117, 1.10638427734375, 1.2321600914001465, 1.357935905456543, 1.4837117195129395, 1.609487533569336, 1.7352628707885742, 1.8610386848449707, 1.9868144989013672, 2.1125898361206055, 2.238365650177002, 2.3641414642333984, 2.489917278289795, 2.6156930923461914, 2.7414684295654297, 2.867244243621826, 2.9930200576782227, 3.118795394897461, 3.2445712089538574, 3.370347023010254, 3.4961228370666504, 3.621898651123047, 3.747673988342285, 3.8734498023986816, 3.999225616455078, 4.125000953674316, 4.250776767730713, 4.376552581787109]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-35.48436737060547, -34.305274963378906, -33.126182556152344, -31.94709014892578, -30.76799774169922, -29.588905334472656, -28.409814834594727, -27.230722427368164, -26.0516300201416, -24.87253761291504, -23.693445205688477, -22.514354705810547, -21.335262298583984, -20.156169891357422, -18.97707748413086, -17.797985076904297, -16.618892669677734, -15.439800262451172, -14.26070785522461, -13.081615447998047, -11.902523040771484, -10.723432540893555, -9.544340133666992, -8.36524772644043, -7.186155319213867, -6.007062911987305, -4.827970504760742, -3.6488780975341797, -2.46978759765625, -1.2906951904296875, -0.111602783203125, 1.0674896240234375, 2.24658203125, 3.4256744384765625, 4.604766845703125, 5.7838592529296875, 6.96295166015625, 8.142044067382812, 9.321136474609375, 10.500228881835938, 11.6793212890625, 12.858409881591797, 14.03750228881836, 15.216594696044922, 16.395687103271484, 17.574779510498047, 18.75387191772461, 19.932964324951172, 21.112056732177734, 22.291149139404297, 23.47024154663086, 24.649333953857422, 25.828426361083984, 27.007518768310547, 28.18661117553711, 29.365699768066406, 30.54479217529297, 31.72388458251953, 32.902976989746094, 34.082069396972656, 35.26116180419922, 36.44025421142578, 37.619346618652344, 38.798439025878906, 39.97753143310547]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 4.0, 0.0, 3.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-30.38166046142578, -29.35659408569336, -28.331527709960938, -27.306461334228516, -26.281394958496094, -25.256328582763672, -24.231264114379883, -23.20619773864746, -22.18113136291504, -21.156064987182617, -20.130998611450195, -19.105934143066406, -18.080867767333984, -17.055801391601562, -16.03073501586914, -15.005668640136719, -13.980602264404297, -12.955535888671875, -11.930469512939453, -10.905403137207031, -9.88033676147461, -8.85527229309082, -7.830205917358398, -6.805139541625977, -5.780073165893555, -4.755006790161133, -3.729940414428711, -2.704874038696289, -1.6798095703125, -0.6547431945800781, 0.37032318115234375, 1.3953895568847656, 2.4204559326171875, 3.4455223083496094, 4.470588684082031, 5.495655059814453, 6.520721435546875, 7.545787811279297, 8.570854187011719, 9.59592056274414, 10.620986938476562, 11.646049499511719, 12.67111587524414, 13.696182250976562, 14.721248626708984, 15.746315002441406, 16.771381378173828, 17.79644775390625, 18.821514129638672, 19.846580505371094, 20.871646881103516, 21.896713256835938, 22.92177963256836, 23.94684600830078, 24.971912384033203, 25.996978759765625, 27.02204132080078, 28.047107696533203, 29.072174072265625, 30.097240447998047, 31.12230682373047, 32.14737319946289, 33.17243957519531, 34.197509765625, 35.222572326660156]}, "_runtime": 8965.182178974152, "_timestamp": 1585606334.8150485, "_step": 98}
{"Episode reward": -96.16191121826229, "Episode length": 999, "Policy Loss": -0.180525004863739, "Value Loss": 0.2045859396457672, "_runtime": 8966.755646944046, "_timestamp": 1585606336.3885164, "_step": 99}
{"Episode reward": -97.25838742074784, "Episode length": 999, "Policy Loss": -0.14994172751903534, "Value Loss": 0.08864898234605789, "_runtime": 8968.337011814117, "_timestamp": 1585606337.9698813, "_step": 100}
{"Episode reward": -98.4189273001192, "Episode length": 999, "Policy Loss": -0.2122095376253128, "Value Loss": 0.0300972331315279, "_runtime": 8969.910578727722, "_timestamp": 1585606339.5434482, "_step": 101}
{"Episode reward": -98.2257065710572, "Episode length": 999, "Policy Loss": -0.2343284785747528, "Value Loss": 0.050223901867866516, "_runtime": 8971.48580956459, "_timestamp": 1585606341.118679, "_step": 102}
{"Episode reward": -97.26736466173925, "Episode length": 999, "Policy Loss": -0.20647789537906647, "Value Loss": 0.07628054916858673, "_runtime": 8973.068739891052, "_timestamp": 1585606342.7016094, "_step": 103}
{"Episode reward": -98.0054936959564, "Episode length": 999, "Policy Loss": -0.31853416562080383, "Value Loss": 0.06902284920215607, "_runtime": 8974.652518510818, "_timestamp": 1585606344.285388, "_step": 104}
{"Episode reward": -97.85346501036281, "Episode length": 999, "Policy Loss": -0.3462788462638855, "Value Loss": 0.07792253792285919, "_runtime": 8976.232903718948, "_timestamp": 1585606345.8657732, "_step": 105}
{"Episode reward": -98.23083261416838, "Episode length": 999, "Policy Loss": -0.4234188199043274, "Value Loss": 0.046542342752218246, "_runtime": 8977.814692020416, "_timestamp": 1585606347.4475615, "_step": 106}
{"Episode reward": -97.55374112229099, "Episode length": 999, "Policy Loss": -0.32882413268089294, "Value Loss": 0.14353974163532257, "_runtime": 8979.384580850601, "_timestamp": 1585606349.0174503, "_step": 107}
{"Episode reward": -98.45817429240984, "Episode length": 999, "Policy Loss": -0.4774484634399414, "Value Loss": 0.061962906271219254, "_runtime": 8980.956748485565, "_timestamp": 1585606350.589618, "_step": 108}
{"Episode reward": -97.96340812801179, "Episode length": 999, "Policy Loss": -0.5237542390823364, "Value Loss": 0.03496081009507179, "_runtime": 8982.56685423851, "_timestamp": 1585606352.1997237, "_step": 109}
{"Episode reward": -97.66815481182975, "Episode length": 999, "Policy Loss": -0.35419952869415283, "Value Loss": 0.16016781330108643, "_runtime": 8984.144723176956, "_timestamp": 1585606353.7775927, "_step": 110}
{"Episode reward": -96.25135235030776, "Episode length": 999, "Policy Loss": -0.31151053309440613, "Value Loss": 0.17776843905448914, "_runtime": 8985.726045370102, "_timestamp": 1585606355.3589149, "_step": 111}
{"Episode reward": -97.8256962794384, "Episode length": 999, "Policy Loss": -0.4182529151439667, "Value Loss": 0.09551408886909485, "_runtime": 8987.285706043243, "_timestamp": 1585606356.9185755, "_step": 112}
{"Episode reward": -97.76663379902794, "Episode length": 999, "Policy Loss": -0.38785189390182495, "Value Loss": 0.09462527185678482, "_runtime": 8988.864714622498, "_timestamp": 1585606358.497584, "_step": 113}
{"Episode reward": -96.3752379698738, "Episode length": 999, "Policy Loss": -0.35207444429397583, "Value Loss": 0.24418970942497253, "_runtime": 8990.443483114243, "_timestamp": 1585606360.0763526, "_step": 114}
{"Episode reward": -97.98434277994018, "Episode length": 999, "Policy Loss": -0.5155889987945557, "Value Loss": 0.0323684960603714, "_runtime": 8992.016099452972, "_timestamp": 1585606361.648969, "_step": 115}
{"Episode reward": -97.20091415849991, "Episode length": 999, "Policy Loss": -0.44569024443626404, "Value Loss": 0.06497139483690262, "_runtime": 8993.585656166077, "_timestamp": 1585606363.2185256, "_step": 116}
{"Episode reward": -98.23460537792278, "Episode length": 999, "Policy Loss": -0.5234222412109375, "Value Loss": 0.05105048790574074, "_runtime": 8995.153328418732, "_timestamp": 1585606364.786198, "_step": 117}
{"Episode reward": -97.8992746886936, "Episode length": 999, "Policy Loss": -0.46088656783103943, "Value Loss": 0.05337898060679436, "_runtime": 8996.732570171356, "_timestamp": 1585606366.3654397, "_step": 118}
{"Episode reward": -97.36444567897158, "Episode length": 999, "Policy Loss": -0.44646477699279785, "Value Loss": 0.0713271051645279, "_runtime": 8998.301061868668, "_timestamp": 1585606367.9339314, "_step": 119}
{"Episode reward": -99.07460143367325, "Episode length": 999, "Policy Loss": -0.4772924780845642, "Value Loss": 0.03468956798315048, "_runtime": 8999.86920595169, "_timestamp": 1585606369.5020754, "_step": 120}
{"Episode reward": -97.68548860379092, "Episode length": 999, "Policy Loss": -0.4423389434814453, "Value Loss": 0.05285024270415306, "_runtime": 9001.449959516525, "_timestamp": 1585606371.082829, "_step": 121}
{"Episode reward": -96.44132662925836, "Episode length": 999, "Policy Loss": -0.5190454721450806, "Value Loss": 0.09865942597389221, "_runtime": 9003.02839231491, "_timestamp": 1585606372.6612618, "_step": 122}
{"Episode reward": -98.51052606949791, "Episode length": 999, "Policy Loss": -0.40500104427337646, "Value Loss": 0.03610330820083618, "_runtime": 9004.60030245781, "_timestamp": 1585606374.233172, "_step": 123}
{"Episode reward": -97.01064839446329, "Episode length": 999, "Policy Loss": -0.41409778594970703, "Value Loss": 0.07175945490598679, "_runtime": 9006.217329263687, "_timestamp": 1585606375.8501987, "_step": 124}
{"Episode reward": -96.65140144444855, "Episode length": 999, "Policy Loss": -0.42830273509025574, "Value Loss": 0.07049845904111862, "_runtime": 9007.796747922897, "_timestamp": 1585606377.4296174, "_step": 125}
{"Episode reward": -98.24225206136529, "Episode length": 999, "Policy Loss": -0.41380181908607483, "Value Loss": 0.04601750522851944, "_runtime": 9009.365424633026, "_timestamp": 1585606378.998294, "_step": 126}
{"Episode reward": -98.15301419974473, "Episode length": 999, "Policy Loss": -0.3896157741546631, "Value Loss": 0.04890912398695946, "_runtime": 9010.945947170258, "_timestamp": 1585606380.5788167, "_step": 127}
{"Episode reward": -97.60954164463104, "Episode length": 999, "Policy Loss": -0.3253999650478363, "Value Loss": 0.05193966627120972, "_runtime": 9012.528304576874, "_timestamp": 1585606382.161174, "_step": 128}
{"Episode reward": -98.16274522587604, "Episode length": 999, "Policy Loss": -0.37627682089805603, "Value Loss": 0.021946486085653305, "_runtime": 9014.098615169525, "_timestamp": 1585606383.7314847, "_step": 129}
{"Episode reward": -98.5533642671451, "Episode length": 999, "Policy Loss": -0.3807410001754761, "Value Loss": 0.031504202634096146, "_runtime": 9015.66906785965, "_timestamp": 1585606385.3019373, "_step": 130}
{"Episode reward": -97.90153639445477, "Episode length": 999, "Policy Loss": -0.3328356146812439, "Value Loss": 0.04494408518075943, "_runtime": 9017.237070798874, "_timestamp": 1585606386.8699403, "_step": 131}
{"Episode reward": -96.91548063997035, "Episode length": 999, "Policy Loss": -0.22854627668857574, "Value Loss": 0.08991584926843643, "_runtime": 9018.816596269608, "_timestamp": 1585606388.4494658, "_step": 132}
{"Episode reward": -98.0929437540647, "Episode length": 999, "Policy Loss": -0.329136461019516, "Value Loss": 0.07257712632417679, "_runtime": 9020.387352228165, "_timestamp": 1585606390.0202217, "_step": 133}
{"Episode reward": -96.58255096526472, "Episode length": 999, "Policy Loss": -0.27679455280303955, "Value Loss": 0.05284785479307175, "_runtime": 9021.973035812378, "_timestamp": 1585606391.6059053, "_step": 134}
{"Episode reward": -98.64886335699792, "Episode length": 999, "Policy Loss": -0.3331650197505951, "Value Loss": 0.026563121005892754, "_runtime": 9023.544663906097, "_timestamp": 1585606393.1775334, "_step": 135}
{"Episode reward": -97.63705667908307, "Episode length": 999, "Policy Loss": -0.29717764258384705, "Value Loss": 0.0460045263171196, "_runtime": 9025.12439775467, "_timestamp": 1585606394.7572672, "_step": 136}
{"Episode reward": -97.39702137731088, "Episode length": 999, "Policy Loss": -0.3015058934688568, "Value Loss": 0.06964054703712463, "_runtime": 9026.706913232803, "_timestamp": 1585606396.3397827, "_step": 137}
{"Episode reward": -97.47202103249109, "Episode length": 999, "Policy Loss": -0.2646786868572235, "Value Loss": 0.05696246400475502, "_runtime": 9028.323815107346, "_timestamp": 1585606397.9566846, "_step": 138}
{"Episode reward": -97.06118881397501, "Episode length": 999, "Policy Loss": -0.2776750326156616, "Value Loss": 0.038214582949876785, "_runtime": 9029.90431857109, "_timestamp": 1585606399.537188, "_step": 139}
{"Episode reward": -97.88456674743787, "Episode length": 999, "Policy Loss": -0.33880048990249634, "Value Loss": 0.025930875912308693, "_runtime": 9031.469903945923, "_timestamp": 1585606401.1027734, "_step": 140}
{"Episode reward": -97.52319181941634, "Episode length": 999, "Policy Loss": -0.2670898139476776, "Value Loss": 0.043617527931928635, "_runtime": 9033.048032999039, "_timestamp": 1585606402.6809025, "_step": 141}
{"Episode reward": -97.88922519429617, "Episode length": 999, "Policy Loss": -0.271450400352478, "Value Loss": 0.03195245936512947, "_runtime": 9034.617500066757, "_timestamp": 1585606404.2503695, "_step": 142}
{"Episode reward": -97.47444910714225, "Episode length": 999, "Policy Loss": -0.2220253348350525, "Value Loss": 0.06310971826314926, "_runtime": 9036.18656373024, "_timestamp": 1585606405.8194332, "_step": 143}
{"Episode reward": -96.18372609694444, "Episode length": 999, "Policy Loss": -0.23180873692035675, "Value Loss": 0.09809398651123047, "_runtime": 9037.757640838623, "_timestamp": 1585606407.3905103, "_step": 144}
{"Episode reward": -97.30799726737631, "Episode length": 999, "Policy Loss": -0.2540455758571625, "Value Loss": 0.04832586646080017, "_runtime": 9039.326246023178, "_timestamp": 1585606408.9591155, "_step": 145}
{"Episode reward": -96.68228881081657, "Episode length": 999, "Policy Loss": -0.21514643728733063, "Value Loss": 0.053965818136930466, "_runtime": 9040.909687042236, "_timestamp": 1585606410.5425565, "_step": 146}
{"Episode reward": -97.59489721066129, "Episode length": 999, "Policy Loss": -0.2345496565103531, "Value Loss": 0.10799967497587204, "_runtime": 9042.479410886765, "_timestamp": 1585606412.1122804, "_step": 147}
{"Episode reward": -96.61500283241506, "Episode length": 999, "Policy Loss": -0.18606677651405334, "Value Loss": 0.04861810803413391, "_runtime": 9044.057793855667, "_timestamp": 1585606413.6906633, "_step": 148}
{"Episode reward": -98.35600710888615, "Episode length": 999, "Policy Loss": -0.23279930651187897, "Value Loss": 0.02604195475578308, "_runtime": 9045.628373384476, "_timestamp": 1585606415.2612429, "_step": 149}
{"Episode reward": -97.78829655611976, "Episode length": 999, "Policy Loss": -0.2601821720600128, "Value Loss": 0.020858291536569595, "_runtime": 9047.199353456497, "_timestamp": 1585606416.832223, "_step": 150}
{"Episode reward": -96.48353510060534, "Episode length": 999, "Policy Loss": -0.2107722908258438, "Value Loss": 0.03705347329378128, "_runtime": 9048.780038833618, "_timestamp": 1585606418.4129083, "_step": 151}
{"Episode reward": -97.42604045577228, "Episode length": 999, "Policy Loss": -0.1979440152645111, "Value Loss": 0.05756821110844612, "_runtime": 9050.359193086624, "_timestamp": 1585606419.9920626, "_step": 152}
{"Episode reward": -97.41475272148146, "Episode length": 999, "Policy Loss": -0.1958489865064621, "Value Loss": 0.05913116782903671, "_runtime": 9051.977134943008, "_timestamp": 1585606421.6100044, "_step": 153}
{"Episode reward": -97.44320885357675, "Episode length": 999, "Policy Loss": -0.2093847692012787, "Value Loss": 0.026567373424768448, "_runtime": 9053.546715021133, "_timestamp": 1585606423.1795845, "_step": 154}
{"Episode reward": -98.07152609140039, "Episode length": 999, "Policy Loss": -0.19870252907276154, "Value Loss": 0.033559106290340424, "_runtime": 9055.125612974167, "_timestamp": 1585606424.7584825, "_step": 155}
{"Episode reward": -97.17723186635249, "Episode length": 999, "Policy Loss": -0.0809880942106247, "Value Loss": 0.061441611498594284, "_runtime": 9056.706636667252, "_timestamp": 1585606426.3395061, "_step": 156}
{"Episode reward": -98.42938209272609, "Episode length": 999, "Policy Loss": -0.1846352517604828, "Value Loss": 0.02865026332437992, "_runtime": 9058.281450033188, "_timestamp": 1585606427.9143195, "_step": 157}
{"Episode reward": -97.04717592439803, "Episode length": 999, "Policy Loss": -0.16931208968162537, "Value Loss": 0.028170805424451828, "_runtime": 9059.861828565598, "_timestamp": 1585606429.494698, "_step": 158}
{"Episode reward": -98.41857684471374, "Episode length": 999, "Policy Loss": -0.17031320929527283, "Value Loss": 0.02868679165840149, "_runtime": 9061.44076538086, "_timestamp": 1585606431.0736349, "_step": 159}
{"Episode reward": -96.82534177480277, "Episode length": 999, "Policy Loss": -0.14391618967056274, "Value Loss": 0.06215573474764824, "_runtime": 9063.021033525467, "_timestamp": 1585606432.653903, "_step": 160}
{"Episode reward": -97.9412977356242, "Episode length": 999, "Policy Loss": -0.13889466226100922, "Value Loss": 0.03082136996090412, "_runtime": 9064.576229810715, "_timestamp": 1585606434.2090993, "_step": 161}
{"Episode reward": -97.00351931476133, "Episode length": 999, "Policy Loss": -0.15499305725097656, "Value Loss": 0.042277052998542786, "_runtime": 9066.164112091064, "_timestamp": 1585606435.7969816, "_step": 162}
{"Episode reward": -98.31791552517633, "Episode length": 999, "Policy Loss": -0.15886171162128448, "Value Loss": 0.030913155525922775, "_runtime": 9067.723817825317, "_timestamp": 1585606437.3566873, "_step": 163}
{"Episode reward": -97.40751071117323, "Episode length": 999, "Policy Loss": -0.15642240643501282, "Value Loss": 0.05288778617978096, "_runtime": 9069.303182840347, "_timestamp": 1585606438.9360523, "_step": 164}
{"Episode reward": -97.84406907497251, "Episode length": 999, "Policy Loss": -0.1434507668018341, "Value Loss": 0.029131866991519928, "_runtime": 9070.886286735535, "_timestamp": 1585606440.5191562, "_step": 165}
{"Episode reward": -98.13998962028823, "Episode length": 999, "Policy Loss": -0.14981812238693237, "Value Loss": 0.020946891978383064, "_runtime": 9072.468401908875, "_timestamp": 1585606442.1012714, "_step": 166}
{"Episode reward": -97.6157266305322, "Episode length": 999, "Policy Loss": -0.05816427990794182, "Value Loss": 0.049061067402362823, "_runtime": 9074.035978078842, "_timestamp": 1585606443.6688476, "_step": 167}
{"Episode reward": -98.10268439895847, "Episode length": 999, "Policy Loss": -0.10286302864551544, "Value Loss": 0.02547568269073963, "_runtime": 9075.642414331436, "_timestamp": 1585606445.2752838, "_step": 168}
{"Episode reward": -98.3244148461681, "Episode length": 999, "Policy Loss": -0.11452215909957886, "Value Loss": 0.012012389488518238, "_runtime": 9077.222816467285, "_timestamp": 1585606446.855686, "_step": 169}
{"Episode reward": -97.46756539854236, "Episode length": 999, "Policy Loss": -0.1090371236205101, "Value Loss": 0.023682549595832825, "_runtime": 9078.80365228653, "_timestamp": 1585606448.4365218, "_step": 170}
{"Episode reward": -97.7804800952648, "Episode length": 999, "Policy Loss": -0.05781923234462738, "Value Loss": 0.036940839141607285, "_runtime": 9080.372361898422, "_timestamp": 1585606450.0052314, "_step": 171}
{"Episode reward": -97.2147236238337, "Episode length": 999, "Policy Loss": -0.06501703709363937, "Value Loss": 0.0299054104834795, "_runtime": 9081.954809904099, "_timestamp": 1585606451.5876794, "_step": 172}
{"Episode reward": -98.77257450820906, "Episode length": 999, "Policy Loss": -0.10942021757364273, "Value Loss": 0.01473803911358118, "_runtime": 9083.524816989899, "_timestamp": 1585606453.1576865, "_step": 173}
{"Episode reward": -97.30636078539185, "Episode length": 999, "Policy Loss": -0.03301701322197914, "Value Loss": 0.029467374086380005, "_runtime": 9085.106135606766, "_timestamp": 1585606454.739005, "_step": 174}
{"Episode reward": -98.20368760386364, "Episode length": 999, "Policy Loss": -0.1004159078001976, "Value Loss": 0.00747325737029314, "_runtime": 9086.676806211472, "_timestamp": 1585606456.3096757, "_step": 175}
{"Episode reward": -97.89035787832208, "Episode length": 999, "Policy Loss": -0.01390373706817627, "Value Loss": 0.06275315582752228, "_runtime": 9088.247200250626, "_timestamp": 1585606457.8800697, "_step": 176}
{"Episode reward": -98.76527515921077, "Episode length": 999, "Policy Loss": -0.07708375155925751, "Value Loss": 0.011605801060795784, "_runtime": 9089.82122206688, "_timestamp": 1585606459.4540915, "_step": 177}
{"Episode reward": -98.30134662313776, "Episode length": 999, "Policy Loss": -0.10645664483308792, "Value Loss": 0.018560482189059258, "_runtime": 9091.400003671646, "_timestamp": 1585606461.0328732, "_step": 178}
{"Episode reward": -96.71900978153558, "Episode length": 999, "Policy Loss": -0.062197670340538025, "Value Loss": 0.049769897013902664, "_runtime": 9092.977401971817, "_timestamp": 1585606462.6102715, "_step": 179}
{"Episode reward": -97.2512886251557, "Episode length": 999, "Policy Loss": -0.028038250282406807, "Value Loss": 0.03134145587682724, "_runtime": 9094.559717178345, "_timestamp": 1585606464.1925867, "_step": 180}
{"Episode reward": -97.62444901532845, "Episode length": 999, "Policy Loss": -0.05868886783719063, "Value Loss": 0.044221870601177216, "_runtime": 9096.13939166069, "_timestamp": 1585606465.7722611, "_step": 181}
{"Episode reward": -97.71667844887118, "Episode length": 999, "Policy Loss": -0.06037653237581253, "Value Loss": 0.03242114931344986, "_runtime": 9097.719386816025, "_timestamp": 1585606467.3522563, "_step": 182}
{"Episode reward": -96.69370185398242, "Episode length": 999, "Policy Loss": -0.047742653638124466, "Value Loss": 0.02916579507291317, "_runtime": 9099.327261686325, "_timestamp": 1585606468.9601312, "_step": 183}
{"Episode reward": -98.26431944864134, "Episode length": 999, "Policy Loss": -0.10134872049093246, "Value Loss": 0.01707649789750576, "_runtime": 9100.906502723694, "_timestamp": 1585606470.5393722, "_step": 184}
{"Episode reward": -96.99665676101705, "Episode length": 999, "Policy Loss": -0.05136480554938316, "Value Loss": 0.03653641790151596, "_runtime": 9102.485019207, "_timestamp": 1585606472.1178887, "_step": 185}
{"Episode reward": -96.33433638791345, "Episode length": 999, "Policy Loss": -0.01511854026466608, "Value Loss": 0.07396253198385239, "_runtime": 9104.05657839775, "_timestamp": 1585606473.6894479, "_step": 186}
{"Episode reward": -98.49602996425189, "Episode length": 999, "Policy Loss": -0.06392333656549454, "Value Loss": 0.03839026764035225, "_runtime": 9105.635102510452, "_timestamp": 1585606475.267972, "_step": 187}
{"Episode reward": -97.62477426302505, "Episode length": 999, "Policy Loss": -0.05259787663817406, "Value Loss": 0.03352668508887291, "_runtime": 9107.207877159119, "_timestamp": 1585606476.8407466, "_step": 188}
{"Episode reward": -97.53798529983578, "Episode length": 999, "Policy Loss": -0.06662655621767044, "Value Loss": 0.01919654756784439, "_runtime": 9108.77784371376, "_timestamp": 1585606478.4107132, "_step": 189}
{"Episode reward": -98.21152328109653, "Episode length": 999, "Policy Loss": -0.06717859208583832, "Value Loss": 0.02390548586845398, "_runtime": 9110.356416225433, "_timestamp": 1585606479.9892857, "_step": 190}
{"Episode reward": -96.93922013800314, "Episode length": 999, "Policy Loss": -0.04894459992647171, "Value Loss": 0.04158451780676842, "_runtime": 9111.929835319519, "_timestamp": 1585606481.5627048, "_step": 191}
{"Episode reward": -98.40374323596357, "Episode length": 999, "Policy Loss": -0.10490663349628448, "Value Loss": 0.011920205317437649, "_runtime": 9113.495379924774, "_timestamp": 1585606483.1282494, "_step": 192}
{"Episode reward": -97.243614798381, "Episode length": 999, "Policy Loss": -0.04887653514742851, "Value Loss": 0.0515153743326664, "_runtime": 9115.067536592484, "_timestamp": 1585606484.700406, "_step": 193}
{"Episode reward": -98.92257092930164, "Episode length": 999, "Policy Loss": -0.1095547005534172, "Value Loss": 0.01521279290318489, "_runtime": 9116.640658378601, "_timestamp": 1585606486.2735279, "_step": 194}
{"Episode reward": -98.34403483501448, "Episode length": 999, "Policy Loss": -0.08269783854484558, "Value Loss": 0.033923931419849396, "_runtime": 9118.213052749634, "_timestamp": 1585606487.8459222, "_step": 195}
{"Episode reward": -97.88250359487176, "Episode length": 999, "Policy Loss": -0.0900728851556778, "Value Loss": 0.021925298497080803, "_runtime": 9119.783336639404, "_timestamp": 1585606489.4162061, "_step": 196}
{"Episode reward": -98.36650088954303, "Episode length": 999, "Policy Loss": -0.13331590592861176, "Value Loss": 0.02848813310265541, "_runtime": 9121.400388002396, "_timestamp": 1585606491.0332575, "_step": 197}
{"Episode reward": -96.44491290214425, "Episode length": 999, "Policy Loss": -0.09642825275659561, "Value Loss": 0.058840516954660416, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676, -2.3582425117492676]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.0004992485046387, -1.8537914752960205, -1.7070837020874023, -1.5603760480880737, -1.4136682748794556, -1.2669605016708374, -1.1202528476715088, -0.9735450744628906, -0.8268373012542725, -0.6801295280456543, -0.5334217548370361, -0.3867141008377075, -0.24000632762908936, -0.09329855442047119, 0.05340909957885742, 0.20011687278747559, 0.34682464599609375, 0.4935324192047119, 0.6402401924133301, 0.7869479656219482, 0.9336557388305664, 1.0803632736206055, 1.2270710468292236, 1.3737788200378418, 1.52048659324646, 1.6671943664550781, 1.8139021396636963, 1.9606099128723145, 2.1073174476623535, 2.254025459289551, 2.40073299407959, 2.547441005706787, 2.694148540496826, 2.8408560752868652, 2.9875640869140625, 3.1342716217041016, 3.280979633331299, 3.427687168121338, 3.574395179748535, 3.721102714538574, 3.8678107261657715, 4.0145182609558105, 4.16122579574585, 4.307933807373047, 4.454641342163086, 4.601349353790283, 4.748056888580322, 4.8947649002075195, 5.041472434997559, 5.188179969787598, 5.334887981414795, 5.481595516204834, 5.628303527832031, 5.77501106262207, 5.921719074249268, 6.068426609039307, 6.215134143829346, 6.361841678619385, 6.50855016708374, 6.655257701873779, 6.801965236663818, 6.948672771453857, 7.095381259918213, 7.242088794708252, 7.388796329498291]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.3899949789047241, -1.3394908905029297, -1.2889868021011353, -1.2384827136993408, -1.1879786252975464, -1.137474536895752, -1.0869704484939575, -1.036466360092163, -0.9859622716903687, -0.9354581832885742, -0.8849540948867798, -0.8344500064849854, -0.7839459180831909, -0.7334418296813965, -0.682937741279602, -0.6324336528778076, -0.5819295644760132, -0.5314254760742188, -0.4809213876724243, -0.4304172992706299, -0.37991321086883545, -0.329409122467041, -0.2789050340652466, -0.22840094566345215, -0.17789685726165771, -0.12739276885986328, -0.07688868045806885, -0.026384592056274414, 0.02411949634552002, 0.07462358474731445, 0.1251276731491089, 0.17563176155090332, 0.22613584995269775, 0.2766399383544922, 0.3271440267562866, 0.37764811515808105, 0.4281522035598755, 0.4786562919616699, 0.5291603803634644, 0.5796644687652588, 0.6301685571670532, 0.6806727647781372, 0.7311767339706421, 0.781680703163147, 0.832184910774231, 0.8826891183853149, 0.9331930875778198, 0.9836970567703247, 1.0342012643814087, 1.0847054719924927, 1.1352094411849976, 1.1857134103775024, 1.2362176179885864, 1.2867218255996704, 1.3372257947921753, 1.3877297639846802, 1.4382339715957642, 1.4887381792068481, 1.539242148399353, 1.589746117591858, 1.640250325202942, 1.6907545328140259, 1.7412585020065308, 1.7917624711990356, 1.8422666788101196]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 4.0, 2.0, 0.0, 2.0, 5.0, 6.0, 4.0, 11.0, 10.0, 9.0, 11.0, 8.0, 8.0, 5.0, 11.0, 15.0, 16.0, 16.0, 29.0, 27.0, 51.0, 25.0, 41.0, 38.0, 35.0, 12.0, 15.0, 14.0, 8.0, 6.0, 9.0, 5.0, 5.0, 6.0, 3.0, 6.0, 2.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.3864502906799316, -1.3390711545944214, -1.2916921377182007, -1.2443130016326904, -1.1969338655471802, -1.14955472946167, -1.1021757125854492, -1.054796576499939, -1.0074174404144287, -0.960038423538208, -0.9126592874526978, -0.8652802109718323, -0.8179011344909668, -0.7705219984054565, -0.7231429219245911, -0.6757637858390808, -0.6283847093582153, -0.5810056328773499, -0.5336264967918396, -0.4862474203109741, -0.43886828422546387, -0.3914892077445984, -0.3441101312637329, -0.29673099517822266, -0.24935197830200195, -0.2019728422164917, -0.15459370613098145, -0.10721457004547119, -0.05983555316925049, -0.012456417083740234, 0.03492271900177002, 0.08230173587799072, 0.12968087196350098, 0.17706000804901123, 0.22443902492523193, 0.2718181610107422, 0.31919729709625244, 0.36657631397247314, 0.4139554500579834, 0.46133458614349365, 0.5087137222290039, 0.5560927391052246, 0.6034718751907349, 0.6508510112762451, 0.6982300281524658, 0.7456090450286865, 0.7929883003234863, 0.840367317199707, 0.8877463340759277, 0.9351255893707275, 0.9825046062469482, 1.029883861541748, 1.0772628784179688, 1.1246418952941895, 1.1720211505889893, 1.21940016746521, 1.2667791843414307, 1.3141584396362305, 1.3615374565124512, 1.4089164733886719, 1.4562957286834717, 1.5036747455596924, 1.551053762435913, 1.598433017730713, 1.6458120346069336]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-13.62097454071045, -13.173288345336914, -12.725601196289062, -12.277915000915527, -11.830228805541992, -11.38254165649414, -10.934855461120605, -10.48716926574707, -10.039482116699219, -9.591795921325684, -9.144109725952148, -8.696422576904297, -8.248736381530762, -7.801049709320068, -7.353363037109375, -6.90567684173584, -6.4579901695251465, -6.010303497314453, -5.562617301940918, -5.114930152893066, -4.667243957519531, -4.219557762145996, -3.7718706130981445, -3.3241844177246094, -2.876498222351074, -2.4288110733032227, -1.9811248779296875, -1.5334386825561523, -1.0857515335083008, -0.6380653381347656, -0.19037914276123047, 0.2573080062866211, 0.7049942016601562, 1.1526803970336914, 1.600367546081543, 2.048053741455078, 2.4957399368286133, 2.943427085876465, 3.3911142349243164, 3.838799476623535, 4.286486625671387, 4.734173774719238, 5.181859016418457, 5.629546165466309, 6.07723331451416, 6.524918556213379, 6.9726057052612305, 7.420292854309082, 7.867978096008301, 8.315665245056152, 8.763352394104004, 9.211037635803223, 9.658724784851074, 10.106411933898926, 10.554097175598145, 11.001784324645996, 11.449471473693848, 11.897156715393066, 12.344843864440918, 12.79253101348877, 13.240216255187988, 13.68790340423584, 14.135590553283691, 14.58327579498291, 15.030962944030762]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 5.0, 13.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-9.623160362243652, -9.317115783691406, -9.01107120513916, -8.705025672912598, -8.398981094360352, -8.092936515808105, -7.786891937255859, -7.480847358703613, -7.174802303314209, -6.868757247924805, -6.562712669372559, -6.2566680908203125, -5.950623512268066, -5.644578456878662, -5.338533878326416, -5.032488822937012, -4.726444244384766, -4.4203996658325195, -4.114354610443115, -3.808310031890869, -3.502264976501465, -3.1962203979492188, -2.8901758193969727, -2.5841307640075684, -2.2780861854553223, -1.9720416069030762, -1.6659965515136719, -1.3599519729614258, -1.0539073944091797, -0.7478628158569336, -0.4418172836303711, -0.135772705078125, 0.1702718734741211, 0.4763164520263672, 0.7823610305786133, 1.0884065628051758, 1.3944511413574219, 1.700495719909668, 2.006540298461914, 2.31258487701416, 2.6186304092407227, 2.9246749877929688, 3.230719566345215, 3.536764144897461, 3.842808723449707, 4.148853302001953, 4.454898834228516, 4.760943412780762, 5.066987991333008, 5.373032569885254, 5.6790771484375, 5.9851226806640625, 6.291167259216309, 6.597210884094238, 6.903256416320801, 7.209301948547363, 7.515345573425293, 7.8213911056518555, 8.127434730529785, 8.433480262756348, 8.73952579498291, 9.04556941986084, 9.351614952087402, 9.657658576965332, 9.963704109191895]}, "_runtime": 9122.982429504395, "_timestamp": 1585606492.615299, "_step": 198}
{"Episode reward": -97.61458794451586, "Episode length": 999, "Policy Loss": -0.09414796531200409, "Value Loss": 0.03180847689509392, "_runtime": 9124.554887533188, "_timestamp": 1585606494.187757, "_step": 199}
{"Episode reward": -97.60363783100318, "Episode length": 999, "Policy Loss": -0.11972348392009735, "Value Loss": 0.02395680546760559, "_runtime": 9126.134036779404, "_timestamp": 1585606495.7669063, "_step": 200}
{"Episode reward": -97.09494588368959, "Episode length": 999, "Policy Loss": -0.07196938991546631, "Value Loss": 0.032939646393060684, "_runtime": 9127.705216646194, "_timestamp": 1585606497.3380861, "_step": 201}
{"Episode reward": -97.41150170762253, "Episode length": 999, "Policy Loss": -0.09882967919111252, "Value Loss": 0.02261805720627308, "_runtime": 9129.283018112183, "_timestamp": 1585606498.9158876, "_step": 202}
{"Episode reward": -95.87142758169618, "Episode length": 999, "Policy Loss": -0.10109130293130875, "Value Loss": 0.06928805261850357, "_runtime": 9130.856341600418, "_timestamp": 1585606500.489211, "_step": 203}
{"Episode reward": -98.23248945484367, "Episode length": 999, "Policy Loss": -0.12718266248703003, "Value Loss": 0.024686425924301147, "_runtime": 9132.438689947128, "_timestamp": 1585606502.0715594, "_step": 204}
{"Episode reward": -97.12051601075915, "Episode length": 999, "Policy Loss": -0.06150281801819801, "Value Loss": 0.03620311990380287, "_runtime": 9134.017762899399, "_timestamp": 1585606503.6506324, "_step": 205}
{"Episode reward": -98.36079144370132, "Episode length": 999, "Policy Loss": -0.136490598320961, "Value Loss": 0.008308826945722103, "_runtime": 9135.575809240341, "_timestamp": 1585606505.2086787, "_step": 206}
{"Episode reward": -97.52864212458921, "Episode length": 999, "Policy Loss": -0.06219284236431122, "Value Loss": 0.08938967436552048, "_runtime": 9137.156113386154, "_timestamp": 1585606506.7889829, "_step": 207}
{"Episode reward": -98.02566296550376, "Episode length": 999, "Policy Loss": -0.11600581556558609, "Value Loss": 0.019664034247398376, "_runtime": 9138.736586093903, "_timestamp": 1585606508.3694556, "_step": 208}
{"Episode reward": -98.50776929208872, "Episode length": 999, "Policy Loss": -0.1571599543094635, "Value Loss": 0.017334770411252975, "_runtime": 9140.31674027443, "_timestamp": 1585606509.9496098, "_step": 209}
{"Episode reward": -97.11704365961087, "Episode length": 999, "Policy Loss": -0.051488954573869705, "Value Loss": 0.050487369298934937, "_runtime": 9141.889733552933, "_timestamp": 1585606511.522603, "_step": 210}
{"Episode reward": -98.1179098333153, "Episode length": 999, "Policy Loss": -0.13464145362377167, "Value Loss": 0.022446878254413605, "_runtime": 9143.469712257385, "_timestamp": 1585606513.1025817, "_step": 211}
{"Episode reward": -96.33204283040567, "Episode length": 999, "Policy Loss": -0.09288125485181808, "Value Loss": 0.036626528948545456, "_runtime": 9145.086960792542, "_timestamp": 1585606514.7198303, "_step": 212}
{"Episode reward": -96.62351518795764, "Episode length": 999, "Policy Loss": -0.12100214511156082, "Value Loss": 0.02156505361199379, "_runtime": 9146.655838251114, "_timestamp": 1585606516.2887077, "_step": 213}
{"Episode reward": -96.06042861889581, "Episode length": 999, "Policy Loss": -0.08442867547273636, "Value Loss": 0.04358349367976189, "_runtime": 9148.232552528381, "_timestamp": 1585606517.865422, "_step": 214}
{"Episode reward": -98.6423980707847, "Episode length": 999, "Policy Loss": -0.1448838859796524, "Value Loss": 0.00909998919814825, "_runtime": 9149.812006473541, "_timestamp": 1585606519.444876, "_step": 215}
{"Episode reward": -97.61348779887412, "Episode length": 999, "Policy Loss": -0.11015606671571732, "Value Loss": 0.028511909767985344, "_runtime": 9151.39108467102, "_timestamp": 1585606521.0239542, "_step": 216}
{"Episode reward": -96.55914137718248, "Episode length": 999, "Policy Loss": -0.062441784888505936, "Value Loss": 0.07143756002187729, "_runtime": 9152.973793506622, "_timestamp": 1585606522.606663, "_step": 217}
{"Episode reward": -97.73056919618469, "Episode length": 999, "Policy Loss": -0.11332742869853973, "Value Loss": 0.01894824579358101, "_runtime": 9154.546458005905, "_timestamp": 1585606524.1793275, "_step": 218}
{"Episode reward": -97.99062931046019, "Episode length": 999, "Policy Loss": -0.1424141824245453, "Value Loss": 0.02176307514309883, "_runtime": 9156.116828918457, "_timestamp": 1585606525.7496984, "_step": 219}
{"Episode reward": -98.48519801260825, "Episode length": 999, "Policy Loss": -0.13567110896110535, "Value Loss": 0.027164215222001076, "_runtime": 9157.680850744247, "_timestamp": 1585606527.3137202, "_step": 220}
{"Episode reward": -96.22597601799833, "Episode length": 999, "Policy Loss": -0.04933492839336395, "Value Loss": 0.0417860671877861, "_runtime": 9159.252586364746, "_timestamp": 1585606528.8854558, "_step": 221}
{"Episode reward": -97.8469670672193, "Episode length": 999, "Policy Loss": -0.06156173348426819, "Value Loss": 0.10323844850063324, "_runtime": 9160.834886074066, "_timestamp": 1585606530.4677556, "_step": 222}
{"Episode reward": -98.34295859406821, "Episode length": 999, "Policy Loss": -0.0984058752655983, "Value Loss": 0.022030627354979515, "_runtime": 9162.417491912842, "_timestamp": 1585606532.0503614, "_step": 223}
{"Episode reward": -96.77513124211592, "Episode length": 999, "Policy Loss": -0.07338140159845352, "Value Loss": 0.052334610372781754, "_runtime": 9163.999546527863, "_timestamp": 1585606533.632416, "_step": 224}
{"Episode reward": -97.83345356695921, "Episode length": 999, "Policy Loss": -0.07418260723352432, "Value Loss": 0.03745012357831001, "_runtime": 9165.581273794174, "_timestamp": 1585606535.2141433, "_step": 225}
{"Episode reward": -97.35884462900312, "Episode length": 999, "Policy Loss": -0.04731248319149017, "Value Loss": 0.04412878304719925, "_runtime": 9167.1610724926, "_timestamp": 1585606536.793942, "_step": 226}
{"Episode reward": -96.49183104687177, "Episode length": 999, "Policy Loss": -0.03183754161000252, "Value Loss": 0.055163465440273285, "_runtime": 9168.7575674057, "_timestamp": 1585606538.390437, "_step": 227}
{"Episode reward": -98.52820099901535, "Episode length": 999, "Policy Loss": -0.13235902786254883, "Value Loss": 0.02014160342514515, "_runtime": 9170.338547706604, "_timestamp": 1585606539.9714172, "_step": 228}
{"Episode reward": -98.39102801491217, "Episode length": 999, "Policy Loss": -0.08838579058647156, "Value Loss": 0.01810544915497303, "_runtime": 9171.907193660736, "_timestamp": 1585606541.5400631, "_step": 229}
{"Episode reward": -97.31800009310338, "Episode length": 999, "Policy Loss": -0.053471889346838, "Value Loss": 0.03699396178126335, "_runtime": 9173.475900411606, "_timestamp": 1585606543.10877, "_step": 230}
{"Episode reward": -97.13904230048394, "Episode length": 999, "Policy Loss": -0.05937783047556877, "Value Loss": 0.03301228955388069, "_runtime": 9175.05816411972, "_timestamp": 1585606544.6910336, "_step": 231}
{"Episode reward": -97.21091405354248, "Episode length": 999, "Policy Loss": -0.05287455394864082, "Value Loss": 0.032488863915205, "_runtime": 9176.638513088226, "_timestamp": 1585606546.2713826, "_step": 232}
{"Episode reward": -98.33065648990589, "Episode length": 999, "Policy Loss": -0.06670301407575607, "Value Loss": 0.027830343693494797, "_runtime": 9178.208633422852, "_timestamp": 1585606547.841503, "_step": 233}
{"Episode reward": -97.32538000150501, "Episode length": 999, "Policy Loss": -0.0781078189611435, "Value Loss": 0.056158293038606644, "_runtime": 9179.768462896347, "_timestamp": 1585606549.4013324, "_step": 234}
{"Episode reward": -96.27893047914147, "Episode length": 999, "Policy Loss": -0.08362866193056107, "Value Loss": 0.02305121347308159, "_runtime": 9181.334643125534, "_timestamp": 1585606550.9675126, "_step": 235}
{"Episode reward": -97.72167261896111, "Episode length": 999, "Policy Loss": -0.07604220509529114, "Value Loss": 0.012640226632356644, "_runtime": 9182.915199756622, "_timestamp": 1585606552.5480692, "_step": 236}
{"Episode reward": -97.79367536171239, "Episode length": 999, "Policy Loss": -0.09765086323022842, "Value Loss": 0.01843610592186451, "_runtime": 9184.476539373398, "_timestamp": 1585606554.1094089, "_step": 237}
{"Episode reward": -96.93435137002412, "Episode length": 999, "Policy Loss": -0.030782025307416916, "Value Loss": 0.03047667257487774, "_runtime": 9186.044471502304, "_timestamp": 1585606555.677341, "_step": 238}
{"Episode reward": -97.34234852320282, "Episode length": 999, "Policy Loss": -0.08851667493581772, "Value Loss": 0.02097831852734089, "_runtime": 9187.614012479782, "_timestamp": 1585606557.246882, "_step": 239}
{"Episode reward": -97.6182898747572, "Episode length": 999, "Policy Loss": -0.05549702048301697, "Value Loss": 0.03668094426393509, "_runtime": 9189.196433544159, "_timestamp": 1585606558.829303, "_step": 240}
{"Episode reward": -97.99668901558296, "Episode length": 999, "Policy Loss": -0.07890066504478455, "Value Loss": 0.015308861620724201, "_runtime": 9190.778596162796, "_timestamp": 1585606560.4114656, "_step": 241}
{"Episode reward": -97.39368531733922, "Episode length": 999, "Policy Loss": -0.046469368040561676, "Value Loss": 0.032516300678253174, "_runtime": 9192.396927118301, "_timestamp": 1585606562.0297966, "_step": 242}
{"Episode reward": -96.47470472802449, "Episode length": 999, "Policy Loss": -0.015019498765468597, "Value Loss": 0.0367974229156971, "_runtime": 9193.978969573975, "_timestamp": 1585606563.611839, "_step": 243}
{"Episode reward": -97.79845160592643, "Episode length": 999, "Policy Loss": -0.030040213838219643, "Value Loss": 0.042726751416921616, "_runtime": 9195.548841953278, "_timestamp": 1585606565.1817114, "_step": 244}
{"Episode reward": -98.20324387266334, "Episode length": 999, "Policy Loss": -0.07217922806739807, "Value Loss": 0.02392726205289364, "_runtime": 9197.131036520004, "_timestamp": 1585606566.763906, "_step": 245}
{"Episode reward": -97.50009533594198, "Episode length": 999, "Policy Loss": -0.09278544783592224, "Value Loss": 0.031651370227336884, "_runtime": 9198.712266206741, "_timestamp": 1585606568.3451357, "_step": 246}
{"Episode reward": -97.88310459394012, "Episode length": 999, "Policy Loss": -0.05965635925531387, "Value Loss": 0.025632325559854507, "_runtime": 9200.281126976013, "_timestamp": 1585606569.9139965, "_step": 247}
{"Episode reward": -97.97034422495148, "Episode length": 999, "Policy Loss": -0.0821312740445137, "Value Loss": 0.020470624789595604, "_runtime": 9201.86035990715, "_timestamp": 1585606571.4932294, "_step": 248}
{"Episode reward": -98.41442322730717, "Episode length": 999, "Policy Loss": -0.08541802316904068, "Value Loss": 0.010239413939416409, "_runtime": 9203.439409255981, "_timestamp": 1585606573.0722787, "_step": 249}
{"Episode reward": -97.96131134976775, "Episode length": 999, "Policy Loss": -0.08407285809516907, "Value Loss": 0.014997430145740509, "_runtime": 9205.01964354515, "_timestamp": 1585606574.652513, "_step": 250}
{"Episode reward": -96.45639882805553, "Episode length": 999, "Policy Loss": -0.050820399075746536, "Value Loss": 0.0509919710457325, "_runtime": 9206.588883399963, "_timestamp": 1585606576.221753, "_step": 251}
{"Episode reward": -97.50067533468847, "Episode length": 999, "Policy Loss": -0.06979285180568695, "Value Loss": 0.029131604358553886, "_runtime": 9208.169905900955, "_timestamp": 1585606577.8027754, "_step": 252}
{"Episode reward": -97.96928573694024, "Episode length": 999, "Policy Loss": -0.09338835626840591, "Value Loss": 0.010682731866836548, "_runtime": 9209.750505685806, "_timestamp": 1585606579.3833752, "_step": 253}
{"Episode reward": -99.03545527798825, "Episode length": 999, "Policy Loss": -0.11759582906961441, "Value Loss": 0.017946800217032433, "_runtime": 9211.33153295517, "_timestamp": 1585606580.9644024, "_step": 254}
{"Episode reward": -97.34054921925174, "Episode length": 999, "Policy Loss": -0.04775773733854294, "Value Loss": 0.051718439906835556, "_runtime": 9212.909158945084, "_timestamp": 1585606582.5420284, "_step": 255}
{"Episode reward": -96.96784989888602, "Episode length": 999, "Policy Loss": -0.07544595748186111, "Value Loss": 0.02209024876356125, "_runtime": 9214.490408420563, "_timestamp": 1585606584.123278, "_step": 256}
{"Episode reward": -97.99575842108175, "Episode length": 999, "Policy Loss": -0.07504591345787048, "Value Loss": 0.023539340123534203, "_runtime": 9216.101604938507, "_timestamp": 1585606585.7344744, "_step": 257}
{"Episode reward": -97.74304225893341, "Episode length": 999, "Policy Loss": -0.053717657923698425, "Value Loss": 0.024112140759825706, "_runtime": 9217.671098947525, "_timestamp": 1585606587.3039684, "_step": 258}
{"Episode reward": -97.18278465525208, "Episode length": 999, "Policy Loss": -0.0660802349448204, "Value Loss": 0.01966368593275547, "_runtime": 9219.250566959381, "_timestamp": 1585606588.8834364, "_step": 259}
{"Episode reward": -97.02227673432836, "Episode length": 999, "Policy Loss": -0.06208061799407005, "Value Loss": 0.031363893300294876, "_runtime": 9220.819383859634, "_timestamp": 1585606590.4522533, "_step": 260}
{"Episode reward": -97.61480689900503, "Episode length": 999, "Policy Loss": -0.047840528190135956, "Value Loss": 0.024267757311463356, "_runtime": 9222.402277469635, "_timestamp": 1585606592.035147, "_step": 261}
{"Episode reward": -97.91932822220875, "Episode length": 999, "Policy Loss": -0.07092589139938354, "Value Loss": 0.022165633738040924, "_runtime": 9223.979779958725, "_timestamp": 1585606593.6126494, "_step": 262}
{"Episode reward": -95.82318286062069, "Episode length": 999, "Policy Loss": -0.034811414778232574, "Value Loss": 0.03753846883773804, "_runtime": 9225.550994873047, "_timestamp": 1585606595.1838644, "_step": 263}
{"Episode reward": -97.29837226481678, "Episode length": 999, "Policy Loss": -0.03904636949300766, "Value Loss": 0.031361378729343414, "_runtime": 9227.132461547852, "_timestamp": 1585606596.765331, "_step": 264}
{"Episode reward": -97.64382571468717, "Episode length": 999, "Policy Loss": -0.10149513930082321, "Value Loss": 0.01704135723412037, "_runtime": 9228.71560382843, "_timestamp": 1585606598.3484733, "_step": 265}
{"Episode reward": -97.27150678209051, "Episode length": 999, "Policy Loss": -0.07764396071434021, "Value Loss": 0.03416767716407776, "_runtime": 9230.287120342255, "_timestamp": 1585606599.9199898, "_step": 266}
{"Episode reward": -95.67927913440302, "Episode length": 999, "Policy Loss": -0.04567526653409004, "Value Loss": 0.0410715788602829, "_runtime": 9231.858260631561, "_timestamp": 1585606601.49113, "_step": 267}
{"Episode reward": -97.7326913102263, "Episode length": 999, "Policy Loss": -0.095653235912323, "Value Loss": 0.0337071418762207, "_runtime": 9233.438933372498, "_timestamp": 1585606603.0718029, "_step": 268}
{"Episode reward": -98.03668106049803, "Episode length": 999, "Policy Loss": -0.09944510459899902, "Value Loss": 0.016556043177843094, "_runtime": 9235.00792002678, "_timestamp": 1585606604.6407895, "_step": 269}
{"Episode reward": -96.50382533692343, "Episode length": 999, "Policy Loss": -0.06325051933526993, "Value Loss": 0.02564750425517559, "_runtime": 9236.567445516586, "_timestamp": 1585606606.200315, "_step": 270}
{"Episode reward": -98.47434240287691, "Episode length": 999, "Policy Loss": -0.09165841341018677, "Value Loss": 0.02415025793015957, "_runtime": 9238.175143003464, "_timestamp": 1585606607.8080125, "_step": 271}
{"Episode reward": -97.6132611341371, "Episode length": 999, "Policy Loss": -0.1014416515827179, "Value Loss": 0.02482406236231327, "_runtime": 9239.742121219635, "_timestamp": 1585606609.3749907, "_step": 272}
{"Episode reward": -97.68586553356162, "Episode length": 999, "Policy Loss": -0.03828670084476471, "Value Loss": 0.045848872512578964, "_runtime": 9241.310256958008, "_timestamp": 1585606610.9431264, "_step": 273}
{"Episode reward": -97.96697675979884, "Episode length": 999, "Policy Loss": -0.08180295675992966, "Value Loss": 0.023661572486162186, "_runtime": 9242.880987644196, "_timestamp": 1585606612.5138571, "_step": 274}
{"Episode reward": -97.75245900181079, "Episode length": 999, "Policy Loss": -0.0634257048368454, "Value Loss": 0.03634611889719963, "_runtime": 9244.450573205948, "_timestamp": 1585606614.0834427, "_step": 275}
{"Episode reward": -97.15437278056088, "Episode length": 999, "Policy Loss": -0.059809911996126175, "Value Loss": 0.029268747195601463, "_runtime": 9246.019637584686, "_timestamp": 1585606615.652507, "_step": 276}
{"Episode reward": -97.59783127275594, "Episode length": 999, "Policy Loss": -0.06165226176381111, "Value Loss": 0.02140067145228386, "_runtime": 9247.585625886917, "_timestamp": 1585606617.2184954, "_step": 277}
{"Episode reward": -97.31035171270732, "Episode length": 999, "Policy Loss": -0.0700271800160408, "Value Loss": 0.019828325137495995, "_runtime": 9249.156557559967, "_timestamp": 1585606618.789427, "_step": 278}
{"Episode reward": -97.16666604941251, "Episode length": 999, "Policy Loss": -0.06434018164873123, "Value Loss": 0.024403758347034454, "_runtime": 9250.717913389206, "_timestamp": 1585606620.3507829, "_step": 279}
{"Episode reward": -97.76792616365272, "Episode length": 999, "Policy Loss": -0.09356128424406052, "Value Loss": 0.017339810729026794, "_runtime": 9252.29156947136, "_timestamp": 1585606621.924439, "_step": 280}
{"Episode reward": -97.58419731696341, "Episode length": 999, "Policy Loss": -0.07238230854272842, "Value Loss": 0.029162127524614334, "_runtime": 9253.855050563812, "_timestamp": 1585606623.48792, "_step": 281}
{"Episode reward": -97.34159429984803, "Episode length": 999, "Policy Loss": -0.08565238863229752, "Value Loss": 0.020602725446224213, "_runtime": 9255.426561832428, "_timestamp": 1585606625.0594313, "_step": 282}
{"Episode reward": -97.93963449522582, "Episode length": 999, "Policy Loss": -0.04776882380247116, "Value Loss": 0.02807501330971718, "_runtime": 9256.997262477875, "_timestamp": 1585606626.630132, "_step": 283}
{"Episode reward": -98.87346354853346, "Episode length": 999, "Policy Loss": -0.08307900279760361, "Value Loss": 0.018355442211031914, "_runtime": 9258.554357767105, "_timestamp": 1585606628.1872272, "_step": 284}
{"Episode reward": -97.37343985696661, "Episode length": 999, "Policy Loss": -0.047626860439777374, "Value Loss": 0.029560565948486328, "_runtime": 9260.115386247635, "_timestamp": 1585606629.7482557, "_step": 285}
{"Episode reward": -97.91724329429792, "Episode length": 999, "Policy Loss": -0.06120222434401512, "Value Loss": 0.01760505512356758, "_runtime": 9261.720772743225, "_timestamp": 1585606631.3536422, "_step": 286}
{"Episode reward": -96.90361942736028, "Episode length": 999, "Policy Loss": -0.05048861354589462, "Value Loss": 0.04315928369760513, "_runtime": 9263.282063484192, "_timestamp": 1585606632.914933, "_step": 287}
{"Episode reward": -98.10041366512473, "Episode length": 999, "Policy Loss": -0.0634625181555748, "Value Loss": 0.019633205607533455, "_runtime": 9264.84226512909, "_timestamp": 1585606634.4751346, "_step": 288}
{"Episode reward": -98.4261235563718, "Episode length": 999, "Policy Loss": -0.09764649718999863, "Value Loss": 0.009057644754648209, "_runtime": 9266.403177976608, "_timestamp": 1585606636.0360475, "_step": 289}
{"Episode reward": -98.14668502759541, "Episode length": 999, "Policy Loss": -0.093597911298275, "Value Loss": 0.007613132707774639, "_runtime": 9267.97417974472, "_timestamp": 1585606637.6070492, "_step": 290}
{"Episode reward": -98.32925857122515, "Episode length": 999, "Policy Loss": -0.085899718105793, "Value Loss": 0.015339300967752934, "_runtime": 9269.544519901276, "_timestamp": 1585606639.1773894, "_step": 291}
{"Episode reward": -98.08923077708965, "Episode length": 999, "Policy Loss": -0.09080130606889725, "Value Loss": 0.016014553606510162, "_runtime": 9271.112624883652, "_timestamp": 1585606640.7454944, "_step": 292}
{"Episode reward": -97.4965625169387, "Episode length": 999, "Policy Loss": -0.04173991456627846, "Value Loss": 0.023991888388991356, "_runtime": 9272.682272911072, "_timestamp": 1585606642.3151424, "_step": 293}
{"Episode reward": -96.61627749006894, "Episode length": 999, "Policy Loss": -0.009470906108617783, "Value Loss": 0.04138058051466942, "_runtime": 9274.25153040886, "_timestamp": 1585606643.8844, "_step": 294}
{"Episode reward": -98.58080853299663, "Episode length": 999, "Policy Loss": -0.09248001873493195, "Value Loss": 0.011192185804247856, "_runtime": 9275.810675382614, "_timestamp": 1585606645.4435449, "_step": 295}
{"Episode reward": -98.42698234040832, "Episode length": 999, "Policy Loss": -0.09327436983585358, "Value Loss": 0.00675179110839963, "_runtime": 9277.378850460052, "_timestamp": 1585606647.01172, "_step": 296}
{"Episode reward": -98.07624121629577, "Episode length": 999, "Policy Loss": -0.057244040071964264, "Value Loss": 0.02478591911494732, "_runtime": 9278.950019836426, "_timestamp": 1585606648.5828893, "_step": 297}
{"Episode reward": -96.3657538402896, "Episode length": 999, "Policy Loss": -0.040616363286972046, "Value Loss": 0.0401163324713707, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584, -0.21329210698604584]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0], "bins": [-1.4693149328231812, -1.4422719478607178, -1.415229082107544, -1.3881860971450806, -1.3611432313919067, -1.3341002464294434, -1.3070573806762695, -1.2800143957138062, -1.2529715299606323, -1.225928544998169, -1.1988856792449951, -1.1718426942825317, -1.144799828529358, -1.1177568435668945, -1.0907139778137207, -1.0636709928512573, -1.0366281270980835, -1.0095851421356201, -0.9825422763824463, -0.9554992914199829, -0.9284563660621643, -0.9014134407043457, -0.8743705153465271, -0.8473275899887085, -0.8202846646308899, -0.7932417392730713, -0.7661988139152527, -0.7391558885574341, -0.7121129631996155, -0.6850700378417969, -0.6580271124839783, -0.6309841871261597, -0.6039412617683411, -0.5768983364105225, -0.5498554110527039, -0.5228124856948853, -0.49576956033706665, -0.46872663497924805, -0.44168365001678467, -0.41464078426361084, -0.38759779930114746, -0.36055493354797363, -0.33351194858551025, -0.3064690828323364, -0.27942609786987305, -0.2523832321166992, -0.22534024715423584, -0.198297381401062, -0.17125439643859863, -0.1442115306854248, -0.11716854572296143, -0.0901256799697876, -0.06308269500732422, -0.03603982925415039, -0.008996844291687012, 0.018046021461486816, 0.045089006423950195, 0.07213187217712402, 0.0991748571395874, 0.12621772289276123, 0.1532607078552246, 0.18030357360839844, 0.20734655857086182, 0.23438942432403564, 0.261432409286499]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12571915984153748, -0.12355808913707733, -0.12139701843261719, -0.11923594772815704, -0.1170748770236969, -0.11491379886865616, -0.11275272816419601, -0.11059165745973587, -0.10843058675527573, -0.10626951605081558, -0.10410844534635544, -0.1019473671913147, -0.09978629648685455, -0.09762522578239441, -0.09546415507793427, -0.09330308437347412, -0.09114201366901398, -0.08898094296455383, -0.08681987226009369, -0.08465880155563354, -0.0824977308511734, -0.08033666014671326, -0.07817558199167252, -0.07601451128721237, -0.07385344058275223, -0.07169236987829208, -0.06953129917383194, -0.0673702210187912, -0.06520915031433105, -0.06304807960987091, -0.06088700890541077, -0.05872593820095062, -0.05656486749649048, -0.054403796792030334, -0.05224272608757019, -0.050081655383110046, -0.0479205846786499, -0.04575950652360916, -0.04359843581914902, -0.04143736511468887, -0.03927629441022873, -0.037115223705768585, -0.03495415300130844, -0.0327930822968483, -0.030632004141807556, -0.028470933437347412, -0.026309862732887268, -0.024148792028427124, -0.02198772132396698, -0.019826650619506836, -0.017665579915046692, -0.015504509210586548, -0.013343438506126404, -0.011182360351085663, -0.009021289646625519, -0.006860218942165375, -0.004699148237705231, -0.0025380775332450867, -0.0003769993782043457, 0.0017840713262557983, 0.003945142030715942, 0.006106212735176086, 0.00826728343963623, 0.010428354144096375, 0.012589424848556519]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 5.0, 4.0, 2.0, 9.0, 14.0, 21.0, 24.0, 27.0, 25.0, 105.0, 65.0, 47.0, 32.0, 23.0, 10.0, 9.0, 7.0, 8.0, 4.0, 7.0, 2.0, 4.0, 3.0, 7.0, 1.0, 6.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0], "bins": [-0.1513449102640152, -0.14761407673358917, -0.14388325810432434, -0.14015242457389832, -0.1364215910434723, -0.13269077241420746, -0.12895993888378143, -0.1252291053533554, -0.12149828672409058, -0.11776745319366455, -0.11403662711381912, -0.1103058010339737, -0.10657496750354767, -0.10284414142370224, -0.09911331534385681, -0.09538248181343079, -0.09165165573358536, -0.08792082965373993, -0.0841899961233139, -0.08045917004346848, -0.07672834396362305, -0.07299751043319702, -0.06926668435335159, -0.06553585827350616, -0.06180502474308014, -0.05807419866323471, -0.05434337258338928, -0.050612546503543854, -0.04688171297311783, -0.0431508868932724, -0.03942006081342697, -0.035689227283000946, -0.03195840120315552, -0.02822757512331009, -0.02449674904346466, -0.020765915513038635, -0.01703508198261261, -0.013304263353347778, -0.009573429822921753, -0.0058425962924957275, -0.002111777663230896, 0.0016190558671951294, 0.005349889397621155, 0.009080708026885986, 0.012811541557312012, 0.016542375087738037, 0.02027319371700287, 0.024004027247428894, 0.02773486077785492, 0.03146567940711975, 0.035196512937545776, 0.03892733156681061, 0.04265816509723663, 0.04638899862766266, 0.05011981725692749, 0.053850650787353516, 0.05758148431777954, 0.06131230294704437, 0.0650431364774704, 0.06877397000789642, 0.07250478863716125, 0.07623562216758728, 0.0799664556980133, 0.08369727432727814, 0.08742810785770416]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.37177589535713196, -0.36105459928512573, -0.3503333032131195, -0.3396120071411133, -0.32889068126678467, -0.31816938519477844, -0.3074480891227722, -0.296726793050766, -0.28600549697875977, -0.27528420090675354, -0.2645629048347473, -0.2538415789604187, -0.24312029778957367, -0.23239900171756744, -0.22167769074440002, -0.2109563946723938, -0.20023509860038757, -0.18951380252838135, -0.17879250645637512, -0.1680711954832077, -0.15734989941120148, -0.14662860333919525, -0.13590729236602783, -0.1251859962940216, -0.11446470022201538, -0.10374340415000916, -0.09302210807800293, -0.0823008120059967, -0.07157948613166809, -0.060858190059661865, -0.05013689398765564, -0.039415597915649414, -0.02869430184364319, -0.017973005771636963, -0.007251709699630737, 0.0034695863723754883, 0.014190882444381714, 0.024912208318710327, 0.03563350439071655, 0.04635480046272278, 0.057076096534729004, 0.06779739260673523, 0.07851868867874146, 0.08923998475074768, 0.0999613106250763, 0.11068260669708252, 0.12140390276908875, 0.13212516903877258, 0.1428464949131012, 0.1535678207874298, 0.16428908705711365, 0.17501041293144226, 0.1857316792011261, 0.1964530050754547, 0.20717427134513855, 0.21789559721946716, 0.22861692309379578, 0.23933818936347961, 0.2500595152378082, 0.26078078150749207, 0.2715021073818207, 0.2822233736515045, 0.29294469952583313, 0.30366596579551697, 0.3143872916698456]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.1890086978673935, -0.18370561301708221, -0.17840252816677094, -0.17309944331645966, -0.16779635846614838, -0.1624932587146759, -0.15719017386436462, -0.15188708901405334, -0.14658400416374207, -0.1412809193134308, -0.1359778344631195, -0.13067474961280823, -0.12537166476249695, -0.12006857991218567, -0.11476548761129379, -0.10946240276098251, -0.10415931791067123, -0.09885623306035995, -0.09355314821004868, -0.0882500559091568, -0.08294697105884552, -0.07764388620853424, -0.07234080135822296, -0.06703771650791168, -0.0617346316576004, -0.056431546807289124, -0.051128461956977844, -0.04582536220550537, -0.04052227735519409, -0.03521919250488281, -0.029916107654571533, -0.024613022804260254, -0.019309937953948975, -0.014006853103637695, -0.008703768253326416, -0.0034006834030151367, 0.0019024014472961426, 0.007205486297607422, 0.012508586049079895, 0.017811670899391174, 0.023114755749702454, 0.028417840600013733, 0.03372092545032501, 0.03902401030063629, 0.04432709515094757, 0.04963018000125885, 0.05493326485157013, 0.06023634970188141, 0.06553943455219269, 0.07084251940250397, 0.07614560425281525, 0.08144868910312653, 0.0867517739534378, 0.09205485880374908, 0.09735797345638275, 0.10266105830669403, 0.10796414315700531, 0.11326722800731659, 0.11857031285762787, 0.12387339770793915, 0.12917648255825043, 0.1344795674085617, 0.13978265225887299, 0.14508573710918427, 0.15038882195949554]}, "_runtime": 9280.516495466232, "_timestamp": 1585606650.149365, "_step": 298}
{"Episode reward": -98.78180746232054, "Episode length": 999, "Policy Loss": -0.08427239954471588, "Value Loss": 0.014665156602859497, "_runtime": 9282.08894276619, "_timestamp": 1585606651.7218122, "_step": 299}
{"Episode reward": -98.36624409089947, "Episode length": 999, "Policy Loss": -0.08535054326057434, "Value Loss": 0.012804225087165833, "_runtime": 9283.64943933487, "_timestamp": 1585606653.2823088, "_step": 300}
{"Episode reward": -97.88992919234741, "Episode length": 999, "Policy Loss": -0.05698368698358536, "Value Loss": 0.019853048026561737, "_runtime": 9285.244617462158, "_timestamp": 1585606654.877487, "_step": 301}
{"Episode reward": -97.68964558973643, "Episode length": 999, "Policy Loss": -0.054350368678569794, "Value Loss": 0.01884479820728302, "_runtime": 9286.8162586689, "_timestamp": 1585606656.4491282, "_step": 302}
{"Episode reward": -95.6957145186521, "Episode length": 999, "Policy Loss": -0.03034067153930664, "Value Loss": 0.03431176021695137, "_runtime": 9288.37219786644, "_timestamp": 1585606658.0050673, "_step": 303}
{"Episode reward": -98.36962211184533, "Episode length": 999, "Policy Loss": -0.07802758365869522, "Value Loss": 0.014296185225248337, "_runtime": 9289.930547237396, "_timestamp": 1585606659.5634167, "_step": 304}
{"Episode reward": -97.70362927118562, "Episode length": 999, "Policy Loss": -0.06321628391742706, "Value Loss": 0.019000401720404625, "_runtime": 9291.492009162903, "_timestamp": 1585606661.1248786, "_step": 305}
{"Episode reward": -98.29585110978321, "Episode length": 999, "Policy Loss": -0.08558035641908646, "Value Loss": 0.009041968733072281, "_runtime": 9293.06358385086, "_timestamp": 1585606662.6964533, "_step": 306}
{"Episode reward": -98.03520600057175, "Episode length": 999, "Policy Loss": -0.06760980933904648, "Value Loss": 0.023072293028235435, "_runtime": 9294.63421368599, "_timestamp": 1585606664.2670832, "_step": 307}
{"Episode reward": -97.4367281716042, "Episode length": 999, "Policy Loss": -0.056911155581474304, "Value Loss": 0.017358899116516113, "_runtime": 9296.193522691727, "_timestamp": 1585606665.8263922, "_step": 308}
{"Episode reward": -98.28406611944749, "Episode length": 999, "Policy Loss": -0.08385084569454193, "Value Loss": 0.010921386070549488, "_runtime": 9297.764361143112, "_timestamp": 1585606667.3972306, "_step": 309}
{"Episode reward": -97.54290441750987, "Episode length": 999, "Policy Loss": -0.0788690373301506, "Value Loss": 0.017438894137740135, "_runtime": 9299.33099079132, "_timestamp": 1585606668.9638603, "_step": 310}
{"Episode reward": -97.71186781923751, "Episode length": 999, "Policy Loss": -0.09063727408647537, "Value Loss": 0.014541037380695343, "_runtime": 9300.9119515419, "_timestamp": 1585606670.544821, "_step": 311}
{"Episode reward": -97.45924304463831, "Episode length": 999, "Policy Loss": -0.08269669860601425, "Value Loss": 0.023663707077503204, "_runtime": 9302.484723806381, "_timestamp": 1585606672.1175933, "_step": 312}
{"Episode reward": -96.74751375037887, "Episode length": 999, "Policy Loss": -0.02745475433766842, "Value Loss": 0.02729886956512928, "_runtime": 9304.06690788269, "_timestamp": 1585606673.6997774, "_step": 313}
{"Episode reward": -97.51867865210717, "Episode length": 999, "Policy Loss": -0.058678995817899704, "Value Loss": 0.021097999066114426, "_runtime": 9305.639336824417, "_timestamp": 1585606675.2722063, "_step": 314}
{"Episode reward": -98.51534211487969, "Episode length": 999, "Policy Loss": -0.0949857160449028, "Value Loss": 0.009375986643135548, "_runtime": 9307.211954116821, "_timestamp": 1585606676.8448236, "_step": 315}
{"Episode reward": -97.34700093890145, "Episode length": 999, "Policy Loss": -0.026121731847524643, "Value Loss": 0.019758112728595734, "_runtime": 9308.83358168602, "_timestamp": 1585606678.4664512, "_step": 316}
{"Episode reward": -97.15207414369209, "Episode length": 999, "Policy Loss": -0.037512630224227905, "Value Loss": 0.022531719878315926, "_runtime": 9310.417184352875, "_timestamp": 1585606680.0500538, "_step": 317}
{"Episode reward": -97.18012027536753, "Episode length": 999, "Policy Loss": -0.07560960203409195, "Value Loss": 0.016043081879615784, "_runtime": 9311.997530460358, "_timestamp": 1585606681.6304, "_step": 318}
{"Episode reward": -97.78415889071341, "Episode length": 999, "Policy Loss": -0.06803897768259048, "Value Loss": 0.019096974283456802, "_runtime": 9313.576512098312, "_timestamp": 1585606683.2093816, "_step": 319}
{"Episode reward": -97.92597086921626, "Episode length": 999, "Policy Loss": -0.09179238229990005, "Value Loss": 0.00913863442838192, "_runtime": 9315.15664100647, "_timestamp": 1585606684.7895105, "_step": 320}
{"Episode reward": -96.68775916229838, "Episode length": 999, "Policy Loss": -0.058303531259298325, "Value Loss": 0.07551657408475876, "_runtime": 9316.719336032867, "_timestamp": 1585606686.3522055, "_step": 321}
{"Episode reward": -98.80270399176139, "Episode length": 999, "Policy Loss": -0.08993735909461975, "Value Loss": 0.0104522081092, "_runtime": 9318.292008399963, "_timestamp": 1585606687.924878, "_step": 322}
{"Episode reward": -98.90369937783053, "Episode length": 999, "Policy Loss": -0.08584530651569366, "Value Loss": 0.013758856803178787, "_runtime": 9319.864166498184, "_timestamp": 1585606689.497036, "_step": 323}
{"Episode reward": -97.54821825788648, "Episode length": 999, "Policy Loss": -0.06900085508823395, "Value Loss": 0.020914295688271523, "_runtime": 9321.437950611115, "_timestamp": 1585606691.07082, "_step": 324}
{"Episode reward": -97.81207432743392, "Episode length": 999, "Policy Loss": -0.04651618003845215, "Value Loss": 0.017290079966187477, "_runtime": 9323.01949095726, "_timestamp": 1585606692.6523604, "_step": 325}
{"Episode reward": -96.4636428911154, "Episode length": 999, "Policy Loss": -0.030951451510190964, "Value Loss": 0.027196010574698448, "_runtime": 9324.59255027771, "_timestamp": 1585606694.2254198, "_step": 326}
{"Episode reward": -98.07668457137179, "Episode length": 999, "Policy Loss": -0.07178638130426407, "Value Loss": 0.020541753619909286, "_runtime": 9326.173256158829, "_timestamp": 1585606695.8061256, "_step": 327}
{"Episode reward": -97.69265486471136, "Episode length": 999, "Policy Loss": -0.040038615465164185, "Value Loss": 0.022244680672883987, "_runtime": 9327.743288755417, "_timestamp": 1585606697.3761582, "_step": 328}
{"Episode reward": -96.93321949050582, "Episode length": 999, "Policy Loss": -0.011041419580578804, "Value Loss": 0.022670092061161995, "_runtime": 9329.328491926193, "_timestamp": 1585606698.9613614, "_step": 329}
{"Episode reward": -96.65347203570447, "Episode length": 999, "Policy Loss": -0.034846432507038116, "Value Loss": 0.03443584218621254, "_runtime": 9330.936817884445, "_timestamp": 1585606700.5696874, "_step": 330}
{"Episode reward": -97.88873527679411, "Episode length": 999, "Policy Loss": -0.0777834802865982, "Value Loss": 0.01858052797615528, "_runtime": 9332.517573356628, "_timestamp": 1585606702.1504428, "_step": 331}
{"Episode reward": -97.62967941136428, "Episode length": 999, "Policy Loss": -0.057554736733436584, "Value Loss": 0.01684722863137722, "_runtime": 9334.101369380951, "_timestamp": 1585606703.7342389, "_step": 332}
{"Episode reward": -95.50115208674899, "Episode length": 999, "Policy Loss": -0.046945855021476746, "Value Loss": 0.050944071263074875, "_runtime": 9335.672470331192, "_timestamp": 1585606705.3053398, "_step": 333}
{"Episode reward": -98.2927108482298, "Episode length": 999, "Policy Loss": -0.10142305493354797, "Value Loss": 0.014829852618277073, "_runtime": 9337.255015611649, "_timestamp": 1585606706.887885, "_step": 334}
{"Episode reward": -97.12400846007276, "Episode length": 999, "Policy Loss": -0.0320325642824173, "Value Loss": 0.022692488506436348, "_runtime": 9338.84002828598, "_timestamp": 1585606708.4728978, "_step": 335}
{"Episode reward": -97.72036953390759, "Episode length": 999, "Policy Loss": -0.06342081725597382, "Value Loss": 0.041194815188646317, "_runtime": 9340.421837806702, "_timestamp": 1585606710.0547073, "_step": 336}
{"Episode reward": -97.35473122783569, "Episode length": 999, "Policy Loss": -0.04105117917060852, "Value Loss": 0.04191095381975174, "_runtime": 9342.00156712532, "_timestamp": 1585606711.6344366, "_step": 337}
{"Episode reward": -96.70168145388256, "Episode length": 999, "Policy Loss": -0.032049510627985, "Value Loss": 0.033606335520744324, "_runtime": 9343.57310295105, "_timestamp": 1585606713.2059724, "_step": 338}
{"Episode reward": -97.01055669063135, "Episode length": 999, "Policy Loss": -0.059485260397195816, "Value Loss": 0.01816786266863346, "_runtime": 9345.144825458527, "_timestamp": 1585606714.777695, "_step": 339}
{"Episode reward": -97.08560081043221, "Episode length": 999, "Policy Loss": -0.06457731127738953, "Value Loss": 0.016908980906009674, "_runtime": 9346.725146532059, "_timestamp": 1585606716.358016, "_step": 340}
{"Episode reward": -98.0796298755129, "Episode length": 999, "Policy Loss": -0.11926808953285217, "Value Loss": 0.012559584341943264, "_runtime": 9348.306094408035, "_timestamp": 1585606717.938964, "_step": 341}
{"Episode reward": -98.17738164515501, "Episode length": 999, "Policy Loss": -0.09540955722332001, "Value Loss": 0.015026750043034554, "_runtime": 9349.87587094307, "_timestamp": 1585606719.5087404, "_step": 342}
{"Episode reward": -97.03589088659693, "Episode length": 999, "Policy Loss": -0.08096042275428772, "Value Loss": 0.01992509327828884, "_runtime": 9351.463628292084, "_timestamp": 1585606721.0964978, "_step": 343}
{"Episode reward": -98.24062478602796, "Episode length": 999, "Policy Loss": -0.12394192814826965, "Value Loss": 0.016918374225497246, "_runtime": 9353.044964551926, "_timestamp": 1585606722.677834, "_step": 344}
{"Episode reward": -97.06168167104535, "Episode length": 999, "Policy Loss": -0.08525779843330383, "Value Loss": 0.021595634520053864, "_runtime": 9354.662669181824, "_timestamp": 1585606724.2955387, "_step": 345}
{"Episode reward": -97.2488991148615, "Episode length": 999, "Policy Loss": -0.08717629313468933, "Value Loss": 0.014601406641304493, "_runtime": 9356.243166208267, "_timestamp": 1585606725.8760357, "_step": 346}
{"Episode reward": -96.8516112885751, "Episode length": 999, "Policy Loss": -0.028212398290634155, "Value Loss": 0.031986501067876816, "_runtime": 9357.821991205215, "_timestamp": 1585606727.4548607, "_step": 347}
{"Episode reward": -98.354114258608, "Episode length": 999, "Policy Loss": -0.11043994128704071, "Value Loss": 0.006715709809213877, "_runtime": 9359.403630495071, "_timestamp": 1585606729.0365, "_step": 348}
{"Episode reward": -98.08473707117952, "Episode length": 999, "Policy Loss": -0.08742129802703857, "Value Loss": 0.013068028725683689, "_runtime": 9360.970896482468, "_timestamp": 1585606730.603766, "_step": 349}
{"Episode reward": -97.55478350621073, "Episode length": 999, "Policy Loss": -0.09262721985578537, "Value Loss": 0.008738003671169281, "_runtime": 9362.544914722443, "_timestamp": 1585606732.1777842, "_step": 350}
{"Episode reward": -98.52206348998759, "Episode length": 999, "Policy Loss": -0.10627558827400208, "Value Loss": 0.011656662449240685, "_runtime": 9364.126253604889, "_timestamp": 1585606733.759123, "_step": 351}
{"Episode reward": -97.66290532730608, "Episode length": 999, "Policy Loss": -0.062006283551454544, "Value Loss": 0.02160695195198059, "_runtime": 9365.707354068756, "_timestamp": 1585606735.3402236, "_step": 352}
{"Episode reward": -98.33875889001806, "Episode length": 999, "Policy Loss": -0.07195764780044556, "Value Loss": 0.012542481534183025, "_runtime": 9367.293236732483, "_timestamp": 1585606736.9261062, "_step": 353}
{"Episode reward": -96.87397109749962, "Episode length": 999, "Policy Loss": -0.025825142860412598, "Value Loss": 0.026678521186113358, "_runtime": 9368.864696979523, "_timestamp": 1585606738.4975665, "_step": 354}
{"Episode reward": -98.02292240944585, "Episode length": 999, "Policy Loss": -0.05066319555044174, "Value Loss": 0.021442672237753868, "_runtime": 9370.437184333801, "_timestamp": 1585606740.0700538, "_step": 355}
{"Episode reward": -98.4764230852957, "Episode length": 999, "Policy Loss": -0.07531626522541046, "Value Loss": 0.004903702065348625, "_runtime": 9371.997649669647, "_timestamp": 1585606741.6305192, "_step": 356}
{"Episode reward": -97.32621975205134, "Episode length": 999, "Policy Loss": -0.05171005800366402, "Value Loss": 0.013500993140041828, "_runtime": 9373.570456981659, "_timestamp": 1585606743.2033265, "_step": 357}
{"Episode reward": -99.02457795752318, "Episode length": 999, "Policy Loss": -0.06094546243548393, "Value Loss": 0.005786772817373276, "_runtime": 9375.15955734253, "_timestamp": 1585606744.7924268, "_step": 358}
{"Episode reward": -97.49886543526489, "Episode length": 999, "Policy Loss": -0.04615183174610138, "Value Loss": 0.023528359830379486, "_runtime": 9376.729840517044, "_timestamp": 1585606746.36271, "_step": 359}
{"Episode reward": -97.1358067312168, "Episode length": 999, "Policy Loss": -0.02436753734946251, "Value Loss": 0.017233051359653473, "_runtime": 9378.35823893547, "_timestamp": 1585606747.9911084, "_step": 360}
{"Episode reward": -97.9120025292754, "Episode length": 999, "Policy Loss": -0.02927151508629322, "Value Loss": 0.011697307229042053, "_runtime": 9379.946146011353, "_timestamp": 1585606749.5790155, "_step": 361}
{"Episode reward": -98.23985774200034, "Episode length": 999, "Policy Loss": -0.03601221367716789, "Value Loss": 0.00469472398981452, "_runtime": 9381.537849903107, "_timestamp": 1585606751.1707194, "_step": 362}
{"Episode reward": -96.65226296129308, "Episode length": 999, "Policy Loss": -0.019116470590233803, "Value Loss": 0.013909609988331795, "_runtime": 9383.12925696373, "_timestamp": 1585606752.7621264, "_step": 363}
{"Episode reward": -98.28825951005791, "Episode length": 999, "Policy Loss": -0.034382566809654236, "Value Loss": 0.0069647859781980515, "_runtime": 9384.723980903625, "_timestamp": 1585606754.3568504, "_step": 364}
{"Episode reward": -98.00007759970872, "Episode length": 999, "Policy Loss": -0.012138023041188717, "Value Loss": 0.010614044964313507, "_runtime": 9386.31709265709, "_timestamp": 1585606755.9499621, "_step": 365}
{"Episode reward": -98.33605572375758, "Episode length": 999, "Policy Loss": -0.02293616347014904, "Value Loss": 0.015149405226111412, "_runtime": 9387.897696733475, "_timestamp": 1585606757.5305662, "_step": 366}
{"Episode reward": -96.41806991454055, "Episode length": 999, "Policy Loss": 0.00389295001514256, "Value Loss": 0.02840476669371128, "_runtime": 9389.489571332932, "_timestamp": 1585606759.1224408, "_step": 367}
{"Episode reward": -97.48757277154762, "Episode length": 999, "Policy Loss": -0.020068611949682236, "Value Loss": 0.01839657872915268, "_runtime": 9391.082231998444, "_timestamp": 1585606760.7151015, "_step": 368}
{"Episode reward": -97.84014460043073, "Episode length": 999, "Policy Loss": -0.019220197573304176, "Value Loss": 0.013811434619128704, "_runtime": 9392.67733502388, "_timestamp": 1585606762.3102045, "_step": 369}
{"Episode reward": -95.64054184561301, "Episode length": 999, "Policy Loss": -0.029878763481974602, "Value Loss": 0.03302809223532677, "_runtime": 9394.269381523132, "_timestamp": 1585606763.902251, "_step": 370}
{"Episode reward": -97.43989194847458, "Episode length": 999, "Policy Loss": -0.03403656184673309, "Value Loss": 0.022295329719781876, "_runtime": 9395.861791849136, "_timestamp": 1585606765.4946613, "_step": 371}
{"Episode reward": -97.89416628682673, "Episode length": 999, "Policy Loss": -0.05286765843629837, "Value Loss": 0.01005946472287178, "_runtime": 9397.447077512741, "_timestamp": 1585606767.079947, "_step": 372}
{"Episode reward": -97.8963792871717, "Episode length": 999, "Policy Loss": -0.03658111393451691, "Value Loss": 0.01978287659585476, "_runtime": 9399.029965639114, "_timestamp": 1585606768.6628351, "_step": 373}
{"Episode reward": -96.07804879409349, "Episode length": 999, "Policy Loss": -0.004962896462529898, "Value Loss": 0.027400396764278412, "_runtime": 9400.626988649368, "_timestamp": 1585606770.2598581, "_step": 374}
{"Episode reward": -97.20462995702682, "Episode length": 999, "Policy Loss": -0.03396989777684212, "Value Loss": 0.01764076203107834, "_runtime": 9402.249992847443, "_timestamp": 1585606771.8828623, "_step": 375}
{"Episode reward": -96.54904149259318, "Episode length": 999, "Policy Loss": -0.026696352288126945, "Value Loss": 0.01799142174422741, "_runtime": 9403.822895765305, "_timestamp": 1585606773.4557652, "_step": 376}
{"Episode reward": -97.52100521519718, "Episode length": 999, "Policy Loss": -0.07785946130752563, "Value Loss": 0.012152169831097126, "_runtime": 9405.409288167953, "_timestamp": 1585606775.0421576, "_step": 377}
{"Episode reward": -97.43379312655132, "Episode length": 999, "Policy Loss": -0.05924246087670326, "Value Loss": 0.014360670931637287, "_runtime": 9407.00269985199, "_timestamp": 1585606776.6355693, "_step": 378}
{"Episode reward": -97.5098700560511, "Episode length": 999, "Policy Loss": -0.06684546917676926, "Value Loss": 0.00679877819493413, "_runtime": 9408.59661769867, "_timestamp": 1585606778.2294872, "_step": 379}
{"Episode reward": -98.02853445415555, "Episode length": 999, "Policy Loss": -0.09305955469608307, "Value Loss": 0.0071987127885222435, "_runtime": 9410.191214084625, "_timestamp": 1585606779.8240836, "_step": 380}
{"Episode reward": -98.08701133740848, "Episode length": 999, "Policy Loss": -0.08460724353790283, "Value Loss": 0.00644973199814558, "_runtime": 9411.786298036575, "_timestamp": 1585606781.4191675, "_step": 381}
{"Episode reward": -98.53542411339109, "Episode length": 999, "Policy Loss": -0.09504919499158859, "Value Loss": 0.008272071368992329, "_runtime": 9413.381665945053, "_timestamp": 1585606783.0145354, "_step": 382}
{"Episode reward": -98.66844353829086, "Episode length": 999, "Policy Loss": -0.08996326476335526, "Value Loss": 0.004861800000071526, "_runtime": 9414.963053941727, "_timestamp": 1585606784.5959234, "_step": 383}
{"Episode reward": -97.78517559042545, "Episode length": 999, "Policy Loss": -0.054609622806310654, "Value Loss": 0.018763413652777672, "_runtime": 9416.546652555466, "_timestamp": 1585606786.179522, "_step": 384}
{"Episode reward": -98.63433059830867, "Episode length": 999, "Policy Loss": -0.09335745871067047, "Value Loss": 0.0068625775165855885, "_runtime": 9418.138474464417, "_timestamp": 1585606787.771344, "_step": 385}
{"Episode reward": -96.43088356390113, "Episode length": 999, "Policy Loss": -0.0333004854619503, "Value Loss": 0.02029096893966198, "_runtime": 9419.720767498016, "_timestamp": 1585606789.353637, "_step": 386}
{"Episode reward": -96.91508660037869, "Episode length": 999, "Policy Loss": -0.05397753417491913, "Value Loss": 0.017990006133913994, "_runtime": 9421.313861608505, "_timestamp": 1585606790.946731, "_step": 387}
{"Episode reward": -98.04846200046946, "Episode length": 999, "Policy Loss": -0.059892814606428146, "Value Loss": 0.016512835398316383, "_runtime": 9422.896312475204, "_timestamp": 1585606792.529182, "_step": 388}
{"Episode reward": -97.7738917946008, "Episode length": 999, "Policy Loss": -0.08432148396968842, "Value Loss": 0.006180452182888985, "_runtime": 9424.479459285736, "_timestamp": 1585606794.1123288, "_step": 389}
{"Episode reward": -97.85225734800517, "Episode length": 999, "Policy Loss": -0.06874842196702957, "Value Loss": 0.006285359617322683, "_runtime": 9426.112930059433, "_timestamp": 1585606795.7457995, "_step": 390}
{"Episode reward": -96.14209773728138, "Episode length": 999, "Policy Loss": -0.025539956986904144, "Value Loss": 0.02260650508105755, "_runtime": 9427.710521697998, "_timestamp": 1585606797.3433912, "_step": 391}
{"Episode reward": -97.65718261475882, "Episode length": 999, "Policy Loss": -0.015568936243653297, "Value Loss": 0.020679127424955368, "_runtime": 9429.29271364212, "_timestamp": 1585606798.9255831, "_step": 392}
{"Episode reward": -97.44035987427014, "Episode length": 999, "Policy Loss": -0.018963797017931938, "Value Loss": 0.01694491319358349, "_runtime": 9430.86644244194, "_timestamp": 1585606800.499312, "_step": 393}
{"Episode reward": -98.03902996871689, "Episode length": 999, "Policy Loss": -0.04356929659843445, "Value Loss": 0.006814257707446814, "_runtime": 9432.451447725296, "_timestamp": 1585606802.0843172, "_step": 394}
{"Episode reward": -97.25021964130376, "Episode length": 999, "Policy Loss": -0.02907842956483364, "Value Loss": 0.025912662968039513, "_runtime": 9434.037178754807, "_timestamp": 1585606803.6700482, "_step": 395}
{"Episode reward": -95.27908760676037, "Episode length": 999, "Policy Loss": -0.007719145622104406, "Value Loss": 0.01760355569422245, "_runtime": 9435.60798740387, "_timestamp": 1585606805.240857, "_step": 396}
{"Episode reward": -96.45851984493903, "Episode length": 999, "Policy Loss": 0.0014908883022144437, "Value Loss": 0.022872336208820343, "_runtime": 9437.186438798904, "_timestamp": 1585606806.8193083, "_step": 397}
{"Episode reward": -97.08493030774108, "Episode length": 999, "Policy Loss": -0.0010160170495510101, "Value Loss": 0.02517141029238701, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544, 0.10922329127788544]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11345823854207993, -0.09674743562936783, -0.08003662526607513, -0.06332582235336304, -0.04661501944065094, -0.029904216527938843, -0.013193406164646149, 0.0035173967480659485, 0.020228199660778046, 0.03693900257349014, 0.05364980548620224, 0.07036060839891434, 0.08707142621278763, 0.10378222912549973, 0.12049303203821182, 0.13720381259918213, 0.15391463041305542, 0.1706254482269287, 0.18733623623847961, 0.2040470540523529, 0.2207578420639038, 0.2374686598777771, 0.254179447889328, 0.2708902657032013, 0.2876010835170746, 0.3043118715286255, 0.3210226893424988, 0.3377334773540497, 0.354444295167923, 0.3711550831794739, 0.3878658711910248, 0.40457668900489807, 0.42128750681877136, 0.43799832463264465, 0.45470914244651794, 0.47141990065574646, 0.48813071846961975, 0.5048415660858154, 0.5215523838996887, 0.5382631421089172, 0.5549739599227905, 0.5716847777366638, 0.5883955955505371, 0.6051064133644104, 0.6218171715736389, 0.6385279893875122, 0.6552388072013855, 0.6719496250152588, 0.6886604428291321, 0.7053712010383606, 0.7220820188522339, 0.7387928366661072, 0.7555036544799805, 0.772214412689209, 0.7889252305030823, 0.8056360483169556, 0.8223468661308289, 0.8390576839447021, 0.8557684421539307, 0.872479259967804, 0.8891900181770325, 0.9059008955955505, 0.922611653804779, 0.9393225312232971, 0.9560332894325256]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0002876304788514972, 0.001399094588123262, 0.0025105588138103485, 0.0036220229230821133, 0.004733487032353878, 0.005844951141625643, 0.0069564152508974075, 0.008067878894507885, 0.009179343469440937, 0.010290808044373989, 0.011402271687984467, 0.012513735331594944, 0.013625199906527996, 0.014736664481461048, 0.015848128125071526, 0.01695959083735943, 0.01807105541229248, 0.019182519987225533, 0.020293984562158585, 0.021405447274446487, 0.02251691184937954, 0.02362837642431259, 0.024739839136600494, 0.025851303711533546, 0.0269627682864666, 0.02807423286139965, 0.029185697436332703, 0.030297160148620605, 0.03140862658619881, 0.03252008929848671, 0.03363155201077461, 0.034743018448352814, 0.03585448116064072, 0.03696594387292862, 0.03807741031050682, 0.039188873022794724, 0.040300339460372925, 0.04141180217266083, 0.04252326488494873, 0.04363473132252693, 0.044746194034814835, 0.04585765674710274, 0.04696912318468094, 0.04808058589696884, 0.049192048609256744, 0.050303515046834946, 0.05141497775912285, 0.05252644419670105, 0.05363790690898895, 0.054749369621276855, 0.05586083605885506, 0.05697229877114296, 0.05808376520872116, 0.059195227921009064, 0.06030669063329697, 0.06141815707087517, 0.06252962350845337, 0.06364108622074127, 0.06475254893302917, 0.06586401164531708, 0.06697547435760498, 0.06808693706989288, 0.06919840723276138, 0.07030986994504929, 0.07142133265733719]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 5.0, 4.0, 4.0, 3.0, 7.0, 6.0, 5.0, 5.0, 9.0, 7.0, 8.0, 11.0, 8.0, 8.0, 141.0, 187.0, 6.0, 7.0, 5.0, 9.0, 2.0, 8.0, 4.0, 2.0, 2.0, 2.0, 6.0, 0.0, 8.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.051726385951042175, -0.049483522772789, -0.04724065959453583, -0.044997792690992355, -0.04275492951273918, -0.04051206633448601, -0.038269199430942535, -0.03602633625268936, -0.03378347307443619, -0.031540609896183014, -0.02929774485528469, -0.027054879814386368, -0.024812016636133194, -0.02256915345788002, -0.020326286554336548, -0.018083423376083374, -0.0158405601978302, -0.013597697019577026, -0.011354833841323853, -0.00911196693778038, -0.006869103759527206, -0.004626240581274033, -0.0023833736777305603, -0.00014051049947738647, 0.0021023526787757874, 0.004345215857028961, 0.006588079035282135, 0.008830945938825607, 0.01107381284236908, 0.013316676020622253, 0.015559539198875427, 0.0178024023771286, 0.020045265555381775, 0.02228812873363495, 0.024530991911888123, 0.026773855090141296, 0.02901671826839447, 0.03125958889722824, 0.033502452075481415, 0.03574531525373459, 0.03798817843198776, 0.040231041610240936, 0.04247390478849411, 0.044716767966747284, 0.046959638595581055, 0.04920250177383423, 0.0514453649520874, 0.053688228130340576, 0.05593109130859375, 0.058173954486846924, 0.0604168176651001, 0.06265968084335327, 0.06490254402160645, 0.06714541465044022, 0.06938827782869339, 0.07163114100694656, 0.07387401163578033, 0.07611687481403351, 0.07835973799228668, 0.08060260117053986, 0.08284546434879303, 0.0850883275270462, 0.08733119070529938, 0.08957405388355255, 0.09181691706180573]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.15680545568466187, -0.15122036635875702, -0.14563527703285217, -0.14005018770694733, -0.13446509838104248, -0.12887999415397644, -0.1232949048280716, -0.11770981550216675, -0.1121247261762619, -0.10653963685035706, -0.10095454752445221, -0.09536945074796677, -0.08978436142206192, -0.08419927209615707, -0.07861417531967163, -0.07302908599376678, -0.06744399666786194, -0.06185890734195709, -0.056273818016052246, -0.0506887212395668, -0.04510363191366196, -0.03951854258775711, -0.03393344581127167, -0.02834835648536682, -0.022763267159461975, -0.01717817783355713, -0.011593088507652283, -0.0060079991817474365, -0.0004228949546813965, 0.00516219437122345, 0.010747283697128296, 0.016332373023033142, 0.02191746234893799, 0.027502551674842834, 0.03308764100074768, 0.03867273032665253, 0.04425781965255737, 0.04984292387962341, 0.05542801320552826, 0.061013102531433105, 0.06659819185733795, 0.0721832811832428, 0.07776837050914764, 0.08335345983505249, 0.08893856406211853, 0.09452363848686218, 0.10010874271392822, 0.10569381713867188, 0.11127892136573792, 0.11686402559280396, 0.12244910001754761, 0.12803420424461365, 0.1336192786693573, 0.13920438289642334, 0.144789457321167, 0.15037456154823303, 0.15595966577529907, 0.16154474020004272, 0.16712984442710876, 0.17271491885185242, 0.17830002307891846, 0.1838850975036621, 0.18947020173072815, 0.1950552761554718, 0.20064038038253784]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 4.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02518712729215622, -0.024507392197847366, -0.023827657103538513, -0.02314792014658451, -0.022468185052275658, -0.021788449957966805, -0.021108713001012802, -0.02042897790670395, -0.019749242812395096, -0.019069507718086243, -0.01838977262377739, -0.017710035666823387, -0.017030300572514534, -0.01635056547820568, -0.01567082852125168, -0.014991093426942825, -0.014311358332633972, -0.013631623238325119, -0.012951887212693691, -0.012272151187062263, -0.01159241609275341, -0.010912680998444557, -0.01023294497281313, -0.009553208947181702, -0.008873473852872849, -0.008193738758563995, -0.007514003664255142, -0.00683426670730114, -0.006154531612992287, -0.0054747965186834335, -0.004795059561729431, -0.004115324467420578, -0.003435589373111725, -0.0027558542788028717, -0.0020761191844940186, -0.0013963822275400162, -0.000716647133231163, -3.6912038922309875e-05, 0.0006428249180316925, 0.0013225600123405457, 0.002002295106649399, 0.002682030200958252, 0.003361765295267105, 0.0040415022522211075, 0.004721237346529961, 0.005400972440838814, 0.006080709397792816, 0.006760444492101669, 0.0074401795864105225, 0.008119914680719376, 0.008799649775028229, 0.009479384869337082, 0.010159119963645935, 0.010838858783245087, 0.01151859387755394, 0.012198328971862793, 0.012878064066171646, 0.0135577991604805, 0.014237534254789352, 0.014917269349098206, 0.015597008168697357, 0.01627674326300621, 0.016956478357315063, 0.017636213451623917, 0.01831594854593277]}, "_runtime": 9438.778059244156, "_timestamp": 1585606808.4109287, "_step": 398}
{"Episode reward": -98.47677792228423, "Episode length": 999, "Policy Loss": -0.06444638967514038, "Value Loss": 0.01395704597234726, "_runtime": 9440.371465206146, "_timestamp": 1585606810.0043347, "_step": 399}
{"Episode reward": -98.51206937131771, "Episode length": 999, "Policy Loss": -0.04333275929093361, "Value Loss": 0.005570594221353531, "_runtime": 9441.968270540237, "_timestamp": 1585606811.60114, "_step": 400}
{"Episode reward": -97.91750490134834, "Episode length": 999, "Policy Loss": -0.04323530197143555, "Value Loss": 0.01394688244909048, "_runtime": 9443.552906990051, "_timestamp": 1585606813.1857765, "_step": 401}
{"Episode reward": -98.58042319485865, "Episode length": 999, "Policy Loss": -0.0516730397939682, "Value Loss": 0.010434252209961414, "_runtime": 9445.148955821991, "_timestamp": 1585606814.7818253, "_step": 402}
{"Episode reward": -97.76295980584793, "Episode length": 999, "Policy Loss": -0.011988694779574871, "Value Loss": 0.018620455637574196, "_runtime": 9446.727825641632, "_timestamp": 1585606816.3606951, "_step": 403}
{"Episode reward": -98.2383862146879, "Episode length": 999, "Policy Loss": -0.05687042698264122, "Value Loss": 0.0043004900217056274, "_runtime": 9448.358926534653, "_timestamp": 1585606817.991796, "_step": 404}
{"Episode reward": -97.44654292454271, "Episode length": 999, "Policy Loss": -0.01136782020330429, "Value Loss": 0.023442327976226807, "_runtime": 9449.952564001083, "_timestamp": 1585606819.5854335, "_step": 405}
{"Episode reward": -97.51271276034095, "Episode length": 999, "Policy Loss": -0.004927294794470072, "Value Loss": 0.025578469038009644, "_runtime": 9451.547171831131, "_timestamp": 1585606821.1800413, "_step": 406}
{"Episode reward": -98.70175253883824, "Episode length": 999, "Policy Loss": -0.05782321095466614, "Value Loss": 0.01084162574261427, "_runtime": 9453.139545679092, "_timestamp": 1585606822.7724152, "_step": 407}
{"Episode reward": -98.17490535894063, "Episode length": 999, "Policy Loss": -0.058587655425071716, "Value Loss": 0.006834700237959623, "_runtime": 9454.739167690277, "_timestamp": 1585606824.3720372, "_step": 408}
{"Episode reward": -96.3319269161828, "Episode length": 999, "Policy Loss": -0.012888134457170963, "Value Loss": 0.023598795756697655, "_runtime": 9456.332563638687, "_timestamp": 1585606825.9654331, "_step": 409}
{"Episode reward": -97.51331670979556, "Episode length": 999, "Policy Loss": -0.06109623983502388, "Value Loss": 0.018818195909261703, "_runtime": 9457.926337957382, "_timestamp": 1585606827.5592074, "_step": 410}
{"Episode reward": -98.02662770531629, "Episode length": 999, "Policy Loss": -0.06076131761074066, "Value Loss": 0.008404354564845562, "_runtime": 9459.522928714752, "_timestamp": 1585606829.1557982, "_step": 411}
{"Episode reward": -96.64560475507139, "Episode length": 999, "Policy Loss": -0.03416970372200012, "Value Loss": 0.01311444491147995, "_runtime": 9461.106703519821, "_timestamp": 1585606830.739573, "_step": 412}
{"Episode reward": -98.34882345452569, "Episode length": 999, "Policy Loss": -0.06567981839179993, "Value Loss": 0.007445666939020157, "_runtime": 9462.688340425491, "_timestamp": 1585606832.32121, "_step": 413}
{"Episode reward": -96.26394072154137, "Episode length": 999, "Policy Loss": -0.05173025652766228, "Value Loss": 0.02485552616417408, "_runtime": 9464.272147655487, "_timestamp": 1585606833.9050171, "_step": 414}
{"Episode reward": -97.98346831915451, "Episode length": 999, "Policy Loss": -0.04603248089551926, "Value Loss": 0.01517607644200325, "_runtime": 9465.865959882736, "_timestamp": 1585606835.4988294, "_step": 415}
{"Episode reward": -98.52747104171564, "Episode length": 999, "Policy Loss": -0.07588698714971542, "Value Loss": 0.011233639903366566, "_runtime": 9467.461322784424, "_timestamp": 1585606837.0941923, "_step": 416}
{"Episode reward": -97.48091614890741, "Episode length": 999, "Policy Loss": -0.06177481636404991, "Value Loss": 0.01040640939027071, "_runtime": 9469.042430877686, "_timestamp": 1585606838.6753004, "_step": 417}
{"Episode reward": -98.00804955853644, "Episode length": 999, "Policy Loss": -0.05180560424923897, "Value Loss": 0.0073247007094323635, "_runtime": 9470.623249292374, "_timestamp": 1585606840.2561188, "_step": 418}
{"Episode reward": -96.16004855857545, "Episode length": 999, "Policy Loss": 0.00942820031195879, "Value Loss": 0.030097004026174545, "_runtime": 9472.244347333908, "_timestamp": 1585606841.8772168, "_step": 419}
{"Episode reward": -96.8412569756563, "Episode length": 999, "Policy Loss": -0.028788700699806213, "Value Loss": 0.01904863677918911, "_runtime": 9473.827860355377, "_timestamp": 1585606843.4607298, "_step": 420}
{"Episode reward": -96.64587800093624, "Episode length": 999, "Policy Loss": -0.003584468038752675, "Value Loss": 0.024523558095097542, "_runtime": 9475.422849178314, "_timestamp": 1585606845.0557187, "_step": 421}
{"Episode reward": -98.32144800852552, "Episode length": 999, "Policy Loss": -0.06270014494657516, "Value Loss": 0.008590590208768845, "_runtime": 9477.006004810333, "_timestamp": 1585606846.6388743, "_step": 422}
{"Episode reward": -98.55083136086876, "Episode length": 999, "Policy Loss": -0.05178980529308319, "Value Loss": 0.009646190330386162, "_runtime": 9478.590824127197, "_timestamp": 1585606848.2236936, "_step": 423}
{"Episode reward": -97.17650263198277, "Episode length": 999, "Policy Loss": -0.03622613474726677, "Value Loss": 0.014775075018405914, "_runtime": 9480.186119556427, "_timestamp": 1585606849.818989, "_step": 424}
{"Episode reward": -96.57108127262337, "Episode length": 999, "Policy Loss": -0.02612178958952427, "Value Loss": 0.014886670745909214, "_runtime": 9481.77088189125, "_timestamp": 1585606851.4037514, "_step": 425}
{"Episode reward": -98.71329337067851, "Episode length": 999, "Policy Loss": -0.05330153554677963, "Value Loss": 0.008159481920301914, "_runtime": 9483.366570472717, "_timestamp": 1585606852.99944, "_step": 426}
{"Episode reward": -98.79100022724846, "Episode length": 999, "Policy Loss": -0.0716269239783287, "Value Loss": 0.011321221478283405, "_runtime": 9484.938724279404, "_timestamp": 1585606854.5715938, "_step": 427}
{"Episode reward": -98.79401037978371, "Episode length": 999, "Policy Loss": -0.06134345382452011, "Value Loss": 0.004745933227241039, "_runtime": 9486.532242774963, "_timestamp": 1585606856.1651123, "_step": 428}
{"Episode reward": -97.21478469483952, "Episode length": 999, "Policy Loss": -0.03352869302034378, "Value Loss": 0.012777834199368954, "_runtime": 9488.115892887115, "_timestamp": 1585606857.7487624, "_step": 429}
{"Episode reward": -96.96458165507578, "Episode length": 999, "Policy Loss": -0.02135886810719967, "Value Loss": 0.01403264794498682, "_runtime": 9489.70749759674, "_timestamp": 1585606859.340367, "_step": 430}
{"Episode reward": -97.73811160894255, "Episode length": 999, "Policy Loss": -0.04922833666205406, "Value Loss": 0.006082481704652309, "_runtime": 9491.29232096672, "_timestamp": 1585606860.9251904, "_step": 431}
{"Episode reward": -98.07149258685742, "Episode length": 999, "Policy Loss": -0.05132565274834633, "Value Loss": 0.005472343415021896, "_runtime": 9492.877530574799, "_timestamp": 1585606862.5104, "_step": 432}
{"Episode reward": -96.91694357315497, "Episode length": 999, "Policy Loss": 0.012294309213757515, "Value Loss": 0.026202678680419922, "_runtime": 9494.461385965347, "_timestamp": 1585606864.0942554, "_step": 433}
{"Episode reward": -97.20239447157427, "Episode length": 999, "Policy Loss": 0.006669286638498306, "Value Loss": 0.024483617395162582, "_runtime": 9496.082253217697, "_timestamp": 1585606865.7151227, "_step": 434}
{"Episode reward": -97.75256275013331, "Episode length": 999, "Policy Loss": -0.03892955183982849, "Value Loss": 0.011411306448280811, "_runtime": 9497.677335739136, "_timestamp": 1585606867.3102052, "_step": 435}
{"Episode reward": -98.82775255339752, "Episode length": 999, "Policy Loss": -0.04582136124372482, "Value Loss": 0.004098552744835615, "_runtime": 9499.269377946854, "_timestamp": 1585606868.9022474, "_step": 436}
{"Episode reward": -97.74320605717863, "Episode length": 999, "Policy Loss": -0.0267848689109087, "Value Loss": 0.011002502404153347, "_runtime": 9500.863879203796, "_timestamp": 1585606870.4967487, "_step": 437}
{"Episode reward": -95.5937728512315, "Episode length": 999, "Policy Loss": 0.004323657136410475, "Value Loss": 0.01900496892631054, "_runtime": 9502.44817662239, "_timestamp": 1585606872.081046, "_step": 438}
{"Episode reward": -98.39936767455782, "Episode length": 999, "Policy Loss": -0.0388525053858757, "Value Loss": 0.0026351946871727705, "_runtime": 9504.028618097305, "_timestamp": 1585606873.6614876, "_step": 439}
{"Episode reward": -98.16025165882205, "Episode length": 999, "Policy Loss": -0.017869573086500168, "Value Loss": 0.010312511585652828, "_runtime": 9505.624297618866, "_timestamp": 1585606875.257167, "_step": 440}
{"Episode reward": -96.76926657025341, "Episode length": 999, "Policy Loss": 1.6613168554613367e-05, "Value Loss": 0.023831503465771675, "_runtime": 9507.197144985199, "_timestamp": 1585606876.8300145, "_step": 441}
{"Episode reward": -96.82091860232889, "Episode length": 999, "Policy Loss": -0.005262752529233694, "Value Loss": 0.019320599734783173, "_runtime": 9508.78010058403, "_timestamp": 1585606878.41297, "_step": 442}
{"Episode reward": -97.23314395085222, "Episode length": 999, "Policy Loss": -0.028514284640550613, "Value Loss": 0.015173000283539295, "_runtime": 9510.37546157837, "_timestamp": 1585606880.008331, "_step": 443}
{"Episode reward": -96.31652184774441, "Episode length": 999, "Policy Loss": -0.014985651709139347, "Value Loss": 0.016777820885181427, "_runtime": 9511.970797300339, "_timestamp": 1585606881.6036668, "_step": 444}
{"Episode reward": -95.90052210555777, "Episode length": 999, "Policy Loss": -0.024151204153895378, "Value Loss": 0.02137652039527893, "_runtime": 9513.554784059525, "_timestamp": 1585606883.1876535, "_step": 445}
{"Episode reward": -96.74297755220157, "Episode length": 999, "Policy Loss": -0.021853923797607422, "Value Loss": 0.01567450724542141, "_runtime": 9515.139198541641, "_timestamp": 1585606884.772068, "_step": 446}
{"Episode reward": -98.18749773583951, "Episode length": 999, "Policy Loss": -0.04758132994174957, "Value Loss": 0.005782953463494778, "_runtime": 9516.725566864014, "_timestamp": 1585606886.3584363, "_step": 447}
{"Episode reward": -96.85994767306855, "Episode length": 999, "Policy Loss": -0.027148233726620674, "Value Loss": 0.02247166819870472, "_runtime": 9518.3192653656, "_timestamp": 1585606887.9521348, "_step": 448}
{"Episode reward": -97.14675876915854, "Episode length": 999, "Policy Loss": -0.02871078811585903, "Value Loss": 0.012282534502446651, "_runtime": 9519.9471950531, "_timestamp": 1585606889.5800645, "_step": 449}
{"Episode reward": -96.7915579162477, "Episode length": 999, "Policy Loss": -0.041350722312927246, "Value Loss": 0.01710706576704979, "_runtime": 9521.54343008995, "_timestamp": 1585606891.1762996, "_step": 450}
{"Episode reward": -98.21162761685483, "Episode length": 999, "Policy Loss": -0.04367596283555031, "Value Loss": 0.009256885387003422, "_runtime": 9523.129715204239, "_timestamp": 1585606892.7625847, "_step": 451}
{"Episode reward": -97.45964264965963, "Episode length": 999, "Policy Loss": -0.03534484654664993, "Value Loss": 0.009602272883057594, "_runtime": 9524.708408355713, "_timestamp": 1585606894.3412778, "_step": 452}
{"Episode reward": -98.29546769080197, "Episode length": 999, "Policy Loss": -0.07347677648067474, "Value Loss": 0.01114905346184969, "_runtime": 9526.290048360825, "_timestamp": 1585606895.9229178, "_step": 453}
{"Episode reward": -97.97095449041157, "Episode length": 999, "Policy Loss": -0.04441734030842781, "Value Loss": 0.016364892944693565, "_runtime": 9527.87183380127, "_timestamp": 1585606897.5047033, "_step": 454}
{"Episode reward": -97.01465849941425, "Episode length": 999, "Policy Loss": -0.02274765633046627, "Value Loss": 0.014067841693758965, "_runtime": 9529.453695297241, "_timestamp": 1585606899.0865648, "_step": 455}
{"Episode reward": -97.34448679363321, "Episode length": 999, "Policy Loss": -0.042966701090335846, "Value Loss": 0.01599717140197754, "_runtime": 9531.0270986557, "_timestamp": 1585606900.6599681, "_step": 456}
{"Episode reward": -97.19063317436546, "Episode length": 999, "Policy Loss": -0.034771356731653214, "Value Loss": 0.017185257747769356, "_runtime": 9532.59914445877, "_timestamp": 1585606902.232014, "_step": 457}
{"Episode reward": -97.49707906071774, "Episode length": 999, "Policy Loss": -0.055041082203388214, "Value Loss": 0.00732464762404561, "_runtime": 9534.170277357101, "_timestamp": 1585606903.8031468, "_step": 458}
{"Episode reward": -98.76201031614559, "Episode length": 999, "Policy Loss": -0.06724095344543457, "Value Loss": 0.003102875081822276, "_runtime": 9535.751330137253, "_timestamp": 1585606905.3841996, "_step": 459}
{"Episode reward": -97.94118736609326, "Episode length": 999, "Policy Loss": -0.06112351641058922, "Value Loss": 0.00615609809756279, "_runtime": 9537.318868637085, "_timestamp": 1585606906.951738, "_step": 460}
{"Episode reward": -97.67231035275213, "Episode length": 999, "Policy Loss": -0.027979807928204536, "Value Loss": 0.012621973641216755, "_runtime": 9538.892567873001, "_timestamp": 1585606908.5254374, "_step": 461}
{"Episode reward": -98.7358292283867, "Episode length": 999, "Policy Loss": -0.06136786565184593, "Value Loss": 0.003310226835310459, "_runtime": 9540.46577501297, "_timestamp": 1585606910.0986445, "_step": 462}
{"Episode reward": -96.99578775765795, "Episode length": 999, "Policy Loss": -0.02056187391281128, "Value Loss": 0.014689099043607712, "_runtime": 9542.061861991882, "_timestamp": 1585606911.6947315, "_step": 463}
{"Episode reward": -97.87032376798433, "Episode length": 999, "Policy Loss": -0.037508975714445114, "Value Loss": 0.007966380566358566, "_runtime": 9543.629925251007, "_timestamp": 1585606913.2627947, "_step": 464}
{"Episode reward": -98.47325844197634, "Episode length": 999, "Policy Loss": -0.04776915907859802, "Value Loss": 0.003895517671480775, "_runtime": 9545.198913574219, "_timestamp": 1585606914.831783, "_step": 465}
{"Episode reward": -97.74205776852864, "Episode length": 999, "Policy Loss": -0.027595587074756622, "Value Loss": 0.006473270710557699, "_runtime": 9546.767980337143, "_timestamp": 1585606916.4008498, "_step": 466}
{"Episode reward": -97.10494458078024, "Episode length": 999, "Policy Loss": -0.022254984825849533, "Value Loss": 0.01498016994446516, "_runtime": 9548.336986541748, "_timestamp": 1585606917.969856, "_step": 467}
{"Episode reward": -97.30763569331292, "Episode length": 999, "Policy Loss": 0.0025786617770791054, "Value Loss": 0.014853469096124172, "_runtime": 9549.908441066742, "_timestamp": 1585606919.5413105, "_step": 468}
{"Episode reward": -97.36973389185297, "Episode length": 999, "Policy Loss": -0.0027106485795229673, "Value Loss": 0.011169904842972755, "_runtime": 9551.478662014008, "_timestamp": 1585606921.1115315, "_step": 469}
{"Episode reward": -98.1023341449166, "Episode length": 999, "Policy Loss": -0.029233869165182114, "Value Loss": 0.008635751903057098, "_runtime": 9553.046820163727, "_timestamp": 1585606922.6796896, "_step": 470}
{"Episode reward": -96.65361647119087, "Episode length": 999, "Policy Loss": 0.010426463559269905, "Value Loss": 0.01787175051867962, "_runtime": 9554.618540763855, "_timestamp": 1585606924.2514102, "_step": 471}
{"Episode reward": -98.16277823701412, "Episode length": 999, "Policy Loss": -0.006090785842388868, "Value Loss": 0.011990060098469257, "_runtime": 9556.188098192215, "_timestamp": 1585606925.8209677, "_step": 472}
{"Episode reward": -95.52639590919522, "Episode length": 999, "Policy Loss": 0.014355858787894249, "Value Loss": 0.017537616193294525, "_runtime": 9557.760088920593, "_timestamp": 1585606927.3929584, "_step": 473}
{"Episode reward": -97.46044147741672, "Episode length": 999, "Policy Loss": -0.01308735366910696, "Value Loss": 0.014447555877268314, "_runtime": 9559.32901763916, "_timestamp": 1585606928.9618871, "_step": 474}
{"Episode reward": -97.5524498343746, "Episode length": 999, "Policy Loss": -0.023718006908893585, "Value Loss": 0.018783824518322945, "_runtime": 9560.900904655457, "_timestamp": 1585606930.5337741, "_step": 475}
{"Episode reward": -96.24143889960565, "Episode length": 999, "Policy Loss": -0.017566366121172905, "Value Loss": 0.019904734566807747, "_runtime": 9562.473524093628, "_timestamp": 1585606932.1063936, "_step": 476}
{"Episode reward": -97.38386073161547, "Episode length": 999, "Policy Loss": -0.046256162226200104, "Value Loss": 0.010096405632793903, "_runtime": 9564.0448513031, "_timestamp": 1585606933.6777208, "_step": 477}
{"Episode reward": -98.4833839717339, "Episode length": 999, "Policy Loss": -0.05279526486992836, "Value Loss": 0.0055119735188782215, "_runtime": 9565.65799498558, "_timestamp": 1585606935.2908645, "_step": 478}
{"Episode reward": -96.76081732710281, "Episode length": 999, "Policy Loss": -0.01709734834730625, "Value Loss": 0.015641171485185623, "_runtime": 9567.22611117363, "_timestamp": 1585606936.8589807, "_step": 479}
{"Episode reward": -97.98987988263347, "Episode length": 999, "Policy Loss": -0.04508550837635994, "Value Loss": 0.007058325223624706, "_runtime": 9568.787450790405, "_timestamp": 1585606938.4203203, "_step": 480}
{"Episode reward": -97.60498794660512, "Episode length": 999, "Policy Loss": -0.048812396824359894, "Value Loss": 0.009209617972373962, "_runtime": 9570.34931921959, "_timestamp": 1585606939.9821887, "_step": 481}
{"Episode reward": -97.7324300558458, "Episode length": 999, "Policy Loss": -0.03326905146241188, "Value Loss": 0.008243391290307045, "_runtime": 9571.921312332153, "_timestamp": 1585606941.5541818, "_step": 482}
{"Episode reward": -96.79267914253596, "Episode length": 999, "Policy Loss": -0.028938954696059227, "Value Loss": 0.016987908631563187, "_runtime": 9573.490346431732, "_timestamp": 1585606943.123216, "_step": 483}
{"Episode reward": -96.8807268550975, "Episode length": 999, "Policy Loss": -0.03589114174246788, "Value Loss": 0.016498329117894173, "_runtime": 9575.060363054276, "_timestamp": 1585606944.6932325, "_step": 484}
{"Episode reward": -98.21295478638011, "Episode length": 999, "Policy Loss": -0.07321522384881973, "Value Loss": 0.004351659212261438, "_runtime": 9576.641025066376, "_timestamp": 1585606946.2738945, "_step": 485}
{"Episode reward": -96.43647723518899, "Episode length": 999, "Policy Loss": -0.01891954429447651, "Value Loss": 0.013541686348617077, "_runtime": 9578.210362195969, "_timestamp": 1585606947.8432317, "_step": 486}
{"Episode reward": -97.36485256449126, "Episode length": 999, "Policy Loss": -0.040627703070640564, "Value Loss": 0.0131671242415905, "_runtime": 9579.777307271957, "_timestamp": 1585606949.4101768, "_step": 487}
{"Episode reward": -96.69583354589767, "Episode length": 999, "Policy Loss": -0.017362650483846664, "Value Loss": 0.012470521964132786, "_runtime": 9581.360698223114, "_timestamp": 1585606950.9935677, "_step": 488}
{"Episode reward": -96.68873177305727, "Episode length": 999, "Policy Loss": -0.0337713398039341, "Value Loss": 0.009258946403861046, "_runtime": 9582.941811323166, "_timestamp": 1585606952.5746808, "_step": 489}
{"Episode reward": -98.13138901797065, "Episode length": 999, "Policy Loss": -0.05523909628391266, "Value Loss": 0.006653778254985809, "_runtime": 9584.52173280716, "_timestamp": 1585606954.1546023, "_step": 490}
{"Episode reward": -97.4945795227329, "Episode length": 999, "Policy Loss": -0.05260244011878967, "Value Loss": 0.019494464620947838, "_runtime": 9586.10431098938, "_timestamp": 1585606955.7371805, "_step": 491}
{"Episode reward": -98.50387530763346, "Episode length": 999, "Policy Loss": -0.055715885013341904, "Value Loss": 0.007884732447564602, "_runtime": 9587.674364566803, "_timestamp": 1585606957.307234, "_step": 492}
{"Episode reward": -98.24255238262997, "Episode length": 999, "Policy Loss": -0.035960376262664795, "Value Loss": 0.011911625042557716, "_runtime": 9589.29263997078, "_timestamp": 1585606958.9255095, "_step": 493}
{"Episode reward": -97.97424004545972, "Episode length": 999, "Policy Loss": -0.03228403255343437, "Value Loss": 0.010093631222844124, "_runtime": 9590.864822626114, "_timestamp": 1585606960.497692, "_step": 494}
{"Episode reward": -96.66376505907579, "Episode length": 999, "Policy Loss": 0.0025673413183540106, "Value Loss": 0.01701095700263977, "_runtime": 9592.447341918945, "_timestamp": 1585606962.0802114, "_step": 495}
{"Episode reward": -97.38678393093855, "Episode length": 999, "Policy Loss": -0.014140202663838863, "Value Loss": 0.011774732731282711, "_runtime": 9594.027967214584, "_timestamp": 1585606963.6608367, "_step": 496}
{"Episode reward": -97.4181699633364, "Episode length": 999, "Policy Loss": -0.009656928479671478, "Value Loss": 0.011162959039211273, "_runtime": 9595.598331451416, "_timestamp": 1585606965.231201, "_step": 497}
{"Episode reward": -98.427401386688, "Episode length": 999, "Policy Loss": -0.043951019644737244, "Value Loss": 0.005084725562483072, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117, -6.195249557495117]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0], "bins": [-8.38589859008789, -8.185410499572754, -7.984921932220459, -7.784433841705322, -7.5839457511901855, -7.383457183837891, -7.182969093322754, -6.982481002807617, -6.7819929122924805, -6.5815043449401855, -6.381016254425049, -6.180527687072754, -5.980039596557617, -5.7795515060424805, -5.579063415527344, -5.378575325012207, -5.178086757659912, -4.977598190307617, -4.7771100997924805, -4.576622009277344, -4.376133918762207, -4.175645351409912, -3.9751572608947754, -3.7746691703796387, -3.5741806030273438, -3.373692512512207, -3.1732044219970703, -2.9727163314819336, -2.7722277641296387, -2.571739673614502, -2.3712515830993652, -2.1707630157470703, -1.9702749252319336, -1.7697868347167969, -1.569298267364502, -1.3688101768493652, -1.1683220863342285, -0.9678335189819336, -0.7673454284667969, -0.5668573379516602, -0.36636924743652344, -0.16588115692138672, 0.034607887268066406, 0.23509597778320312, 0.43558406829833984, 0.6360721588134766, 0.8365602493286133, 1.03704833984375, 1.2375373840332031, 1.4380254745483398, 1.6385135650634766, 1.8390016555786133, 2.03948974609375, 2.2399778366088867, 2.4404659271240234, 2.6409549713134766, 2.8414430618286133, 3.04193115234375, 3.2424192428588867, 3.4429073333740234, 3.64339542388916, 3.8438844680786133, 4.04437255859375, 4.244860649108887, 4.445348739624023]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.4902257919311523, -3.359790563583374, -3.229355573654175, -3.0989203453063965, -2.9684853553771973, -2.838050127029419, -2.7076148986816406, -2.5771799087524414, -2.446744680404663, -2.3163094520568848, -2.1858744621276855, -2.0554392337799072, -1.9250041246414185, -1.7945690155029297, -1.6641337871551514, -1.5336986780166626, -1.4032635688781738, -1.2728283405303955, -1.1423933506011963, -1.011958122253418, -0.8815231323242188, -0.7510879039764404, -0.6206526756286621, -0.4902176856994629, -0.35978245735168457, -0.22934722900390625, -0.09891223907470703, 0.03152298927307129, 0.1619582176208496, 0.29239320755004883, 0.42282843589782715, 0.5532636642456055, 0.6836986541748047, 0.8141336441040039, 0.9445691108703613, 1.0750041007995605, 1.2054390907287598, 1.3358745574951172, 1.4663095474243164, 1.5967445373535156, 1.7271795272827148, 1.8576149940490723, 1.9880499839782715, 2.1184849739074707, 2.248920440673828, 2.3793554306030273, 2.5097904205322266, 2.640225887298584, 2.770660877227783, 2.9010958671569824, 3.03153133392334, 3.161966323852539, 3.2924013137817383, 3.4228367805480957, 3.553271770477295, 3.683706760406494, 3.8141422271728516, 3.944577217102051, 4.07501220703125, 4.205447196960449, 4.335882663726807, 4.466317653656006, 4.596753120422363, 4.7271881103515625, 4.857623100280762]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 5.0, 5.0, 2.0, 2.0, 5.0, 11.0, 7.0, 11.0, 9.0, 7.0, 11.0, 8.0, 7.0, 12.0, 10.0, 13.0, 15.0, 18.0, 48.0, 91.0, 48.0, 24.0, 15.0, 16.0, 16.0, 15.0, 3.0, 5.0, 9.0, 4.0, 4.0, 5.0, 8.0, 2.0, 3.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-3.3648784160614014, -3.2470967769622803, -3.129315137863159, -3.011533498764038, -2.893752098083496, -2.775970458984375, -2.658188819885254, -2.540407180786133, -2.4226255416870117, -2.3048439025878906, -2.1870622634887695, -2.0692806243896484, -1.951499104499817, -1.8337174654006958, -1.7159359455108643, -1.5981543064117432, -1.480372667312622, -1.362591028213501, -1.2448093891143799, -1.1270277500152588, -1.0092461109161377, -0.8914647102355957, -0.7736830711364746, -0.6559014320373535, -0.5381197929382324, -0.42033815383911133, -0.30255651473999023, -0.18477487564086914, -0.06699347496032715, 0.050788164138793945, 0.16856980323791504, 0.28635144233703613, 0.4041330814361572, 0.5219147205352783, 0.6396963596343994, 0.7574779987335205, 0.8752596378326416, 0.9930412769317627, 1.1108229160308838, 1.2286045551300049, 1.346386194229126, 1.4641673564910889, 1.58194899559021, 1.699730634689331, 1.8175122737884521, 1.9352939128875732, 2.0530755519866943, 2.1708571910858154, 2.2886388301849365, 2.4064204692840576, 2.5242021083831787, 2.6419837474823, 2.759765386581421, 2.877547025680542, 2.995328664779663, 3.113110303878784, 3.230891466140747, 3.348673105239868, 3.4664547443389893, 3.5842363834381104, 3.7020180225372314, 3.8197996616363525, 3.9375813007354736, 4.055362701416016, 4.173144340515137]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-33.08634567260742, -31.97420883178711, -30.862071990966797, -29.74993324279785, -28.63779640197754, -27.525659561157227, -26.41352081298828, -25.30138397216797, -24.189247131347656, -23.077110290527344, -21.96497344970703, -20.852834701538086, -19.740697860717773, -18.62856101989746, -17.516422271728516, -16.404285430908203, -15.29214859008789, -14.180011749267578, -13.067874908447266, -11.95573616027832, -10.843599319458008, -9.731462478637695, -8.61932373046875, -7.5071868896484375, -6.395050048828125, -5.2829132080078125, -4.1707763671875, -3.0586376190185547, -1.9465007781982422, -0.8343620300292969, 0.2777748107910156, 1.3899116516113281, 2.5020484924316406, 3.614185333251953, 4.726322174072266, 5.838459014892578, 6.950595855712891, 8.062736511230469, 9.174873352050781, 10.287010192871094, 11.399147033691406, 12.511283874511719, 13.623420715332031, 14.735557556152344, 15.847698211669922, 16.959835052490234, 18.071971893310547, 19.18410873413086, 20.296245574951172, 21.408382415771484, 22.520519256591797, 23.63265609741211, 24.744792938232422, 25.85693359375, 26.969070434570312, 28.081207275390625, 29.193344116210938, 30.30548095703125, 31.417621612548828, 32.52975845336914, 33.64189529418945, 34.754032135009766, 35.86616897583008, 36.97830581665039, 38.0904426574707]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 1.0, 5.0, 2.0, 3.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-26.81709861755371, -25.91582489013672, -25.014549255371094, -24.1132755279541, -23.21200180053711, -22.310726165771484, -21.409452438354492, -20.5081787109375, -19.606903076171875, -18.705629348754883, -17.80435562133789, -16.903079986572266, -16.001806259155273, -15.100532531738281, -14.199257850646973, -13.29798412322998, -12.396709442138672, -11.495434761047363, -10.594160079956055, -9.692886352539062, -8.79161262512207, -7.890336990356445, -6.989063262939453, -6.087789535522461, -5.186513900756836, -4.285240173339844, -3.3839664459228516, -2.4826927185058594, -1.5814170837402344, -0.6801433563232422, 0.22113037109375, 1.122406005859375, 2.023679733276367, 2.9249534606933594, 3.8262290954589844, 4.727502822875977, 5.628778457641602, 6.530050277709961, 7.431325912475586, 8.332601547241211, 9.23387336730957, 10.135149002075195, 11.03642463684082, 11.93769645690918, 12.838972091674805, 13.74024772644043, 14.641519546508789, 15.542795181274414, 16.44407081604004, 17.3453426361084, 18.246618270874023, 19.147890090942383, 20.049165725708008, 20.950441360473633, 21.851713180541992, 22.752988815307617, 23.654264450073242, 24.5555362701416, 25.456811904907227, 26.35808753967285, 27.25935935974121, 28.160634994506836, 29.06191062927246, 29.96318244934082, 30.864458084106445]}, "_runtime": 9597.181381464005, "_timestamp": 1585606966.814251, "_step": 498}
{"Episode reward": -97.86105513337958, "Episode length": 999, "Policy Loss": -0.024739712476730347, "Value Loss": 0.0063254339620471, "_runtime": 9597.181381464005, "_timestamp": 1585606966.814251, "_step": 499}
