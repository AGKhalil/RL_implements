{"Episode reward": -41.410278791057124, "Episode length": 999, "Policy Loss": -0.03918275609612465, "Value Loss": 0.014993559569120407, "_runtime": 6128.425531864166, "_timestamp": 1585515206.8462615, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.224530577659607, "Value Loss": 16.56856918334961, "_runtime": 6129.928203582764, "_timestamp": 1585515208.3489332, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -75.05459594726562, "Value Loss": 11923.3173828125, "_runtime": 6131.511239051819, "_timestamp": 1585515209.9319687, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0265666246414185, "Value Loss": 435.8462829589844, "_runtime": 6133.078077316284, "_timestamp": 1585515211.498807, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.450393199920654, "Value Loss": 3844.5234375, "_runtime": 6134.619946479797, "_timestamp": 1585515213.040676, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -25.560504913330078, "Value Loss": 1905.57861328125, "_runtime": 6136.2102382183075, "_timestamp": 1585515214.6309679, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -40.75469207763672, "Value Loss": 14341.5078125, "_runtime": 6137.7885682582855, "_timestamp": 1585515216.209298, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -22.320730209350586, "Value Loss": 10159.9775390625, "_runtime": 6139.3289313316345, "_timestamp": 1585515217.749661, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5214552879333496, "Value Loss": 207.40560913085938, "_runtime": 6140.92243885994, "_timestamp": 1585515219.3431685, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 16.095062255859375, "Value Loss": 2731.700927734375, "_runtime": 6142.495412111282, "_timestamp": 1585515220.9161417, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 17.42454719543457, "Value Loss": 14.08089542388916, "_runtime": 6144.050051689148, "_timestamp": 1585515222.4707813, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.156707763671875, "Value Loss": 5518.80078125, "_runtime": 6145.6342487335205, "_timestamp": 1585515224.0549784, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 24.27128028869629, "Value Loss": 202.30123901367188, "_runtime": 6147.223724365234, "_timestamp": 1585515225.644454, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 30.22291374206543, "Value Loss": 161.37173461914062, "_runtime": 6148.795286417007, "_timestamp": 1585515227.216016, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 35.10293197631836, "Value Loss": 54.667999267578125, "_runtime": 6150.387751817703, "_timestamp": 1585515228.8084815, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 39.09992599487305, "Value Loss": 464.22283935546875, "_runtime": 6152.0099992752075, "_timestamp": 1585515230.430729, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 42.23933029174805, "Value Loss": 1002.4506225585938, "_runtime": 6153.572940587997, "_timestamp": 1585515231.9936702, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 40.158939361572266, "Value Loss": 2808.921630859375, "_runtime": 6155.164201974869, "_timestamp": 1585515233.5849316, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 38.960960388183594, "Value Loss": 364.9084167480469, "_runtime": 6156.753215551376, "_timestamp": 1585515235.1739452, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 38.07548522949219, "Value Loss": 490.16424560546875, "_runtime": 6158.32764005661, "_timestamp": 1585515236.7483697, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 33.69304275512695, "Value Loss": 57.70012283325195, "_runtime": 6159.906725168228, "_timestamp": 1585515238.3274548, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 30.398408889770508, "Value Loss": 1256.1143798828125, "_runtime": 6161.48775601387, "_timestamp": 1585515239.9084857, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 30.37462043762207, "Value Loss": 3397.859619140625, "_runtime": 6163.056289672852, "_timestamp": 1585515241.4770193, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.39813232421875, "Value Loss": 75.86541748046875, "_runtime": 6164.621540307999, "_timestamp": 1585515243.04227, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.96001148223877, "Value Loss": 131.6181182861328, "_runtime": 6166.2161383628845, "_timestamp": 1585515244.636868, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.162930488586426, "Value Loss": 334.70751953125, "_runtime": 6167.785283327103, "_timestamp": 1585515246.206013, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8418430089950562, "Value Loss": 345.4630126953125, "_runtime": 6169.3630220890045, "_timestamp": 1585515247.7837517, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.374872207641602, "Value Loss": 199.2394561767578, "_runtime": 6170.946472644806, "_timestamp": 1585515249.3672023, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.77960205078125, "Value Loss": 276.4916076660156, "_runtime": 6172.519066810608, "_timestamp": 1585515250.9397964, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.890613555908203, "Value Loss": 849.020263671875, "_runtime": 6174.108251571655, "_timestamp": 1585515252.5289812, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.853696823120117, "Value Loss": 3692.03271484375, "_runtime": 6175.725855588913, "_timestamp": 1585515254.1465852, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.93242073059082, "Value Loss": 279.1432189941406, "_runtime": 6177.295433282852, "_timestamp": 1585515255.716163, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.166905403137207, "Value Loss": 234.16905212402344, "_runtime": 6178.879885673523, "_timestamp": 1585515257.3006153, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.908254861831665, "Value Loss": 632.2186889648438, "_runtime": 6180.457824230194, "_timestamp": 1585515258.8785539, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.739781379699707, "Value Loss": 1095.5804443359375, "_runtime": 6182.039717912674, "_timestamp": 1585515260.4604475, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5868695974349976, "Value Loss": 34983.8828125, "_runtime": 6183.614284276962, "_timestamp": 1585515262.035014, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8267031311988831, "Value Loss": 0.242274209856987, "_runtime": 6185.200630426407, "_timestamp": 1585515263.62136, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7044335603713989, "Value Loss": 40.41603469848633, "_runtime": 6186.784637212753, "_timestamp": 1585515265.2053668, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6518490314483643, "Value Loss": 343.3910827636719, "_runtime": 6188.371588468552, "_timestamp": 1585515266.792318, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.975327730178833, "Value Loss": 664.1107788085938, "_runtime": 6189.958300113678, "_timestamp": 1585515268.3790298, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.289677143096924, "Value Loss": 106.9183349609375, "_runtime": 6191.532381772995, "_timestamp": 1585515269.9531114, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.483715057373047, "Value Loss": 58.45346450805664, "_runtime": 6193.116677522659, "_timestamp": 1585515271.5374072, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.441287517547607, "Value Loss": 1599.280517578125, "_runtime": 6194.705211162567, "_timestamp": 1585515273.1259408, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.281504154205322, "Value Loss": 985.86865234375, "_runtime": 6196.286415338516, "_timestamp": 1585515274.707145, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.70422077178955, "Value Loss": 1236.1988525390625, "_runtime": 6197.8710198402405, "_timestamp": 1585515276.2917495, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.754093170166016, "Value Loss": 913.7119140625, "_runtime": 6199.495989322662, "_timestamp": 1585515277.916719, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.339155197143555, "Value Loss": 267.9622497558594, "_runtime": 6201.084973573685, "_timestamp": 1585515279.5057032, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -18.74662208557129, "Value Loss": 24.619670867919922, "_runtime": 6202.663134098053, "_timestamp": 1585515281.0838637, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -21.280208587646484, "Value Loss": 68.5564193725586, "_runtime": 6204.250710487366, "_timestamp": 1585515282.6714401, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -24.846721649169922, "Value Loss": 1763.3450927734375, "_runtime": 6205.833884716034, "_timestamp": 1585515284.2546144, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -27.13408088684082, "Value Loss": 820.7159423828125, "_runtime": 6207.396381855011, "_timestamp": 1585515285.8171115, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -27.805883407592773, "Value Loss": 7.237977981567383, "_runtime": 6208.977400779724, "_timestamp": 1585515287.3981304, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -29.07071304321289, "Value Loss": 10.935242652893066, "_runtime": 6210.564256906509, "_timestamp": 1585515288.9849865, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -29.94951820373535, "Value Loss": 213.61073303222656, "_runtime": 6212.1414115428925, "_timestamp": 1585515290.5621412, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -31.122222900390625, "Value Loss": 1441.3037109375, "_runtime": 6213.720789909363, "_timestamp": 1585515292.1415195, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -29.358219146728516, "Value Loss": 238.02383422851562, "_runtime": 6215.295698165894, "_timestamp": 1585515293.7164278, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -28.70452308654785, "Value Loss": 275.84222412109375, "_runtime": 6216.876060962677, "_timestamp": 1585515295.2967906, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -27.555070877075195, "Value Loss": 126.12305450439453, "_runtime": 6218.457670450211, "_timestamp": 1585515296.8784, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -27.160476684570312, "Value Loss": 321.4114990234375, "_runtime": 6220.0443115234375, "_timestamp": 1585515298.4650412, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -24.667469024658203, "Value Loss": 5.44476842880249, "_runtime": 6221.669181108475, "_timestamp": 1585515300.0899107, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -23.022449493408203, "Value Loss": 6.218854904174805, "_runtime": 6223.256660223007, "_timestamp": 1585515301.6773899, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -21.932649612426758, "Value Loss": 49.26508331298828, "_runtime": 6224.833955287933, "_timestamp": 1585515303.254685, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -20.839187622070312, "Value Loss": 24.17510223388672, "_runtime": 6226.421588420868, "_timestamp": 1585515304.842318, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -19.681438446044922, "Value Loss": 231.1197967529297, "_runtime": 6228.0098288059235, "_timestamp": 1585515306.4305584, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -18.7153263092041, "Value Loss": 167.5904998779297, "_runtime": 6229.583739042282, "_timestamp": 1585515308.0044687, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.36333465576172, "Value Loss": 394.2430114746094, "_runtime": 6231.1708426475525, "_timestamp": 1585515309.5915723, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.59256362915039, "Value Loss": 8.656107902526855, "_runtime": 6232.761653661728, "_timestamp": 1585515311.1823833, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.742286682128906, "Value Loss": 213.17735290527344, "_runtime": 6234.348747730255, "_timestamp": 1585515312.7694774, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.51793670654297, "Value Loss": 243.92713928222656, "_runtime": 6235.923675537109, "_timestamp": 1585515314.3444052, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.834901809692383, "Value Loss": 42.031715393066406, "_runtime": 6237.510391950607, "_timestamp": 1585515315.9311216, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.557903289794922, "Value Loss": 23.336803436279297, "_runtime": 6239.093933582306, "_timestamp": 1585515317.5146632, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.061573028564453, "Value Loss": 305.7055969238281, "_runtime": 6240.6830496788025, "_timestamp": 1585515319.1037793, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.456869125366211, "Value Loss": 151.17562866210938, "_runtime": 6242.269973039627, "_timestamp": 1585515320.6907027, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.08983039855957, "Value Loss": 303.30328369140625, "_runtime": 6243.845635652542, "_timestamp": 1585515322.2663653, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.054298400878906, "Value Loss": 41.00143051147461, "_runtime": 6245.460867404938, "_timestamp": 1585515323.881597, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.983399391174316, "Value Loss": 10.308137893676758, "_runtime": 6247.039368152618, "_timestamp": 1585515325.4600978, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.959761619567871, "Value Loss": 11.344502449035645, "_runtime": 6248.614135026932, "_timestamp": 1585515327.0348647, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.08454418182373, "Value Loss": 78.09930419921875, "_runtime": 6250.187721252441, "_timestamp": 1585515328.608451, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.83040714263916, "Value Loss": 91.47915649414062, "_runtime": 6251.778381586075, "_timestamp": 1585515330.1991112, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.567596435546875, "Value Loss": 105.22897338867188, "_runtime": 6253.365122318268, "_timestamp": 1585515331.785852, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.372989654541016, "Value Loss": 30.646339416503906, "_runtime": 6254.952092409134, "_timestamp": 1585515333.372822, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.29256248474121, "Value Loss": 16.25346565246582, "_runtime": 6256.540724039078, "_timestamp": 1585515334.9614537, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.892380714416504, "Value Loss": 5.288631439208984, "_runtime": 6258.128140926361, "_timestamp": 1585515336.5488706, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.416747093200684, "Value Loss": 8.348116874694824, "_runtime": 6259.714872121811, "_timestamp": 1585515338.1356018, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.812540054321289, "Value Loss": 5.096634864807129, "_runtime": 6261.303438901901, "_timestamp": 1585515339.7241685, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.427678108215332, "Value Loss": 4.117659568786621, "_runtime": 6262.889569044113, "_timestamp": 1585515341.3102987, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.957143783569336, "Value Loss": 2.8138606548309326, "_runtime": 6264.476843595505, "_timestamp": 1585515342.8975732, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.421393394470215, "Value Loss": 12.889349937438965, "_runtime": 6266.0528564453125, "_timestamp": 1585515344.473586, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.279492378234863, "Value Loss": 15.027595520019531, "_runtime": 6267.637829065323, "_timestamp": 1585515346.0585587, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.613588333129883, "Value Loss": 1.437703013420105, "_runtime": 6269.261850833893, "_timestamp": 1585515347.6825805, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.297931671142578, "Value Loss": 3.069024085998535, "_runtime": 6270.848191738129, "_timestamp": 1585515349.2689214, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.01990795135498, "Value Loss": 24.99578094482422, "_runtime": 6272.431815862656, "_timestamp": 1585515350.8525455, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.849939346313477, "Value Loss": 2.503694534301758, "_runtime": 6274.004228591919, "_timestamp": 1585515352.4249582, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.818326950073242, "Value Loss": 13.598587036132812, "_runtime": 6275.591742277145, "_timestamp": 1585515354.012472, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.533857345581055, "Value Loss": 3.542677164077759, "_runtime": 6277.166895866394, "_timestamp": 1585515355.5876255, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.557568550109863, "Value Loss": 2.8573362827301025, "_runtime": 6278.742468833923, "_timestamp": 1585515357.1631985, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.582655906677246, "Value Loss": 5.055215835571289, "_runtime": 6280.317694425583, "_timestamp": 1585515358.738424, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.500737190246582, "Value Loss": 1.4444135427474976, "_runtime": 6281.892342567444, "_timestamp": 1585515360.3130722, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.479545593261719, "Value Loss": 1.8070653676986694, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5, -34598.5]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-14996172.0, -14761316.0, -14526460.0, -14291605.0, -14056749.0, -13821893.0, -13587037.0, -13352181.0, -13117326.0, -12882470.0, -12647614.0, -12412758.0, -12177902.0, -11943046.0, -11708190.0, -11473335.0, -11238479.0, -11003623.0, -10768768.0, -10533912.0, -10299056.0, -10064200.0, -9829344.0, -9594488.0, -9359632.0, -9124776.0, -8889921.0, -8655065.0, -8420209.0, -8185353.5, -7950497.5, -7715642.0, -7480786.0, -7245930.0, -7011074.5, -6776218.5, -6541363.0, -6306507.0, -6071651.0, -5836795.0, -5601940.0, -5367084.0, -5132228.0, -4897372.0, -4662516.0, -4427660.0, -4192805.0, -3957949.0, -3723093.0, -3488237.0, -3253381.0, -3018526.0, -2783670.0, -2548814.0, -2313958.0, -2079102.0, -1844246.0, -1609391.0, -1374535.0, -1139679.0, -904823.0, -669967.0, -435112.0, -200256.0, 34600.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 916.580078125, 1833.16015625, 2749.740234375, 3666.3203125, 4582.900390625, 5499.48046875, 6416.060546875, 7332.640625, 8249.220703125, 9165.80078125, 10082.380859375, 10998.9609375, 11915.541015625, 12832.12109375, 13748.701171875, 14665.28125, 15581.861328125, 16498.44140625, 17415.021484375, 18331.6015625, 19248.181640625, 20164.76171875, 21081.341796875, 21997.921875, 22914.501953125, 23831.08203125, 24747.662109375, 25664.2421875, 26580.822265625, 27497.40234375, 28413.982421875, 29330.5625, 30247.142578125, 31163.72265625, 32080.302734375, 32996.8828125, 33913.4609375, 34830.04296875, 35746.625, 36663.203125, 37579.78125, 38496.36328125, 39412.9453125, 40329.5234375, 41246.1015625, 42162.68359375, 43079.265625, 43995.84375, 44912.421875, 45829.00390625, 46745.5859375, 47662.1640625, 48578.7421875, 49495.32421875, 50411.90625, 51328.484375, 52245.0625, 53161.64453125, 54078.2265625, 54994.8046875, 55911.3828125, 56827.96484375, 57744.546875, 58661.125]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [9.0, 37.0, 54.0, 66.0, 26.0, 0.0, 0.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 7.0, 7.0, 4.0, 2.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 9.0, 6.0, 7.0, 5.0, 5.0, 5.0, 5.0, 11.0, 5.0, 4.0, 10.0, 8.0, 6.0, 3.0, 2.0, 0.0, 4.0, 4.0, 1.0, 4.0, 5.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0], "bins": [-231634.5, -199858.53125, -168082.5625, -136306.59375, -104530.625, -72754.65625, -40978.6875, -9202.71875, 22573.25, 54349.21875, 86125.1875, 117901.15625, 149677.125, 181453.09375, 213229.0625, 245005.03125, 276781.0, 308557.0, 340332.9375, 372108.875, 403884.875, 435660.875, 467436.8125, 499212.75, 530988.75, 562764.75, 594540.6875, 626316.625, 658092.625, 689868.625, 721644.5625, 753420.5, 785196.5, 816972.5, 848748.5, 880524.375, 912300.375, 944076.375, 975852.25, 1007628.25, 1039404.25, 1071180.25, 1102956.25, 1134732.125, 1166508.125, 1198284.125, 1230060.0, 1261836.0, 1293612.0, 1325388.0, 1357164.0, 1388939.875, 1420715.875, 1452491.875, 1484267.75, 1516043.75, 1547819.75, 1579595.75, 1611371.75, 1643147.625, 1674923.625, 1706699.625, 1738475.5, 1770251.5, 1802027.5]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-436903.25, -400821.0625, -364738.875, -328656.65625, -292574.46875, -256492.28125, -220410.078125, -184327.875, -148245.6875, -112163.5, -76081.3125, -39999.09375, -3916.90625, 32165.28125, 68247.5, 104329.6875, 140411.875, 176494.0625, 212576.25, 248658.4375, 284740.625, 320822.875, 356905.0625, 392987.25, 429069.4375, 465151.625, 501233.8125, 537316.0, 573398.25, 609480.4375, 645562.625, 681644.75, 717727.0, 753809.25, 789891.375, 825973.625, 862055.75, 898138.0, 934220.125, 970302.375, 1006384.5, 1042466.75, 1078549.0, 1114631.125, 1150713.375, 1186795.5, 1222877.75, 1258959.875, 1295042.125, 1331124.375, 1367206.5, 1403288.75, 1439370.875, 1475453.125, 1511535.25, 1547617.5, 1583699.75, 1619781.875, 1655864.125, 1691946.25, 1728028.5, 1764110.75, 1800192.75, 1836275.0, 1872357.25]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 20.0, 7.0, 4.0, 9.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-14563245.0, -14283940.0, -14004635.0, -13725330.0, -13446025.0, -13166720.0, -12887415.0, -12608110.0, -12328805.0, -12049500.0, -11770195.0, -11490890.0, -11211585.0, -10932280.0, -10652975.0, -10373670.0, -10094365.0, -9815060.0, -9535755.0, -9256450.0, -8977145.0, -8697840.0, -8418535.0, -8139230.0, -7859925.0, -7580620.0, -7301315.0, -7022010.0, -6742705.0, -6463400.0, -6184095.0, -5904790.0, -5625485.0, -5346180.0, -5066875.0, -4787570.0, -4508265.0, -4228960.0, -3949655.0, -3670350.0, -3391045.0, -3111740.0, -2832435.0, -2553130.0, -2273825.0, -1994520.0, -1715215.0, -1435910.0, -1156605.0, -877300.0, -597995.0, -318690.0, -39385.0, 239920.0, 519225.0, 798530.0, 1077835.0, 1357140.0, 1636445.0, 1915750.0, 2195055.0, 2474359.0, 2753665.0, 3032971.0, 3312275.0]}, "_runtime": 6283.477672576904, "_timestamp": 1585515361.8984022, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.459882736206055, "Value Loss": 3.4193482398986816, "_runtime": 6285.06197810173, "_timestamp": 1585515363.4827077, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.552887916564941, "Value Loss": 1.2014293670654297, "_runtime": 6286.644112825394, "_timestamp": 1585515365.0648425, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.532366752624512, "Value Loss": 1.919887900352478, "_runtime": 6288.2166957855225, "_timestamp": 1585515366.6374254, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.51718807220459, "Value Loss": 3.9765701293945312, "_runtime": 6289.80114197731, "_timestamp": 1585515368.2218716, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.430951118469238, "Value Loss": 9.02640438079834, "_runtime": 6291.382879018784, "_timestamp": 1585515369.8036087, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.019972801208496, "Value Loss": 2.0888473987579346, "_runtime": 6293.002357959747, "_timestamp": 1585515371.4230876, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.754364013671875, "Value Loss": 5.502331733703613, "_runtime": 6294.584483623505, "_timestamp": 1585515373.0052133, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.422767639160156, "Value Loss": 2.0291316509246826, "_runtime": 6296.16738986969, "_timestamp": 1585515374.5881195, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.080151557922363, "Value Loss": 1.2190043926239014, "_runtime": 6297.729325771332, "_timestamp": 1585515376.1500554, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.712841033935547, "Value Loss": 1.8334153890609741, "_runtime": 6299.3143055438995, "_timestamp": 1585515377.7350352, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.24163818359375, "Value Loss": 0.8170422911643982, "_runtime": 6300.897291898727, "_timestamp": 1585515379.3180215, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.901202201843262, "Value Loss": 0.8586162328720093, "_runtime": 6302.478250026703, "_timestamp": 1585515380.8989797, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.612568855285645, "Value Loss": 1.614332675933838, "_runtime": 6304.064204931259, "_timestamp": 1585515382.4849346, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.324296951293945, "Value Loss": 4.148481369018555, "_runtime": 6305.647334098816, "_timestamp": 1585515384.0680637, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.083451271057129, "Value Loss": 2.002065896987915, "_runtime": 6307.230760574341, "_timestamp": 1585515385.6514902, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.9908552169799805, "Value Loss": 0.8632180094718933, "_runtime": 6308.803809642792, "_timestamp": 1585515387.2245393, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.815616607666016, "Value Loss": 0.9753607511520386, "_runtime": 6310.386046409607, "_timestamp": 1585515388.806776, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.779433727264404, "Value Loss": 2.564081907272339, "_runtime": 6311.9692142009735, "_timestamp": 1585515390.3899438, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.659957408905029, "Value Loss": 0.9303588271141052, "_runtime": 6313.572722196579, "_timestamp": 1585515391.9934518, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.60128927230835, "Value Loss": 0.7083064913749695, "_runtime": 6315.148019075394, "_timestamp": 1585515393.5687487, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.614908695220947, "Value Loss": 0.7920747995376587, "_runtime": 6316.745956897736, "_timestamp": 1585515395.1666865, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.546253204345703, "Value Loss": 0.8602186441421509, "_runtime": 6318.317493438721, "_timestamp": 1585515396.738223, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.514974594116211, "Value Loss": 0.5464065074920654, "_runtime": 6319.878583431244, "_timestamp": 1585515398.299313, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.467175006866455, "Value Loss": 0.6660342812538147, "_runtime": 6321.451369524002, "_timestamp": 1585515399.8720992, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.345407485961914, "Value Loss": 0.8625327348709106, "_runtime": 6323.013568639755, "_timestamp": 1585515401.4342983, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.334989547729492, "Value Loss": 0.8171162009239197, "_runtime": 6324.585244655609, "_timestamp": 1585515403.0059743, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.253513336181641, "Value Loss": 0.9108116030693054, "_runtime": 6326.156636953354, "_timestamp": 1585515404.5773666, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.172694206237793, "Value Loss": 0.5839607119560242, "_runtime": 6327.725868225098, "_timestamp": 1585515406.1465979, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.01659631729126, "Value Loss": 0.5247084498405457, "_runtime": 6329.287884712219, "_timestamp": 1585515407.7086143, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.9292802810668945, "Value Loss": 0.5126444101333618, "_runtime": 6330.862129688263, "_timestamp": 1585515409.2828593, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.824876308441162, "Value Loss": 0.6357738375663757, "_runtime": 6332.43705368042, "_timestamp": 1585515410.8577833, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.723115921020508, "Value Loss": 0.7394601702690125, "_runtime": 6333.995973348618, "_timestamp": 1585515412.416703, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.540379524230957, "Value Loss": 0.5084384679794312, "_runtime": 6335.568234920502, "_timestamp": 1585515413.9889646, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.412848472595215, "Value Loss": 1.2452728748321533, "_runtime": 6337.141316652298, "_timestamp": 1585515415.5620463, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.229269027709961, "Value Loss": 0.9976451992988586, "_runtime": 6338.7396466732025, "_timestamp": 1585515417.1603763, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.959269046783447, "Value Loss": 0.4327443838119507, "_runtime": 6340.308358430862, "_timestamp": 1585515418.729088, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.826359748840332, "Value Loss": 0.9039880037307739, "_runtime": 6341.869765996933, "_timestamp": 1585515420.2904956, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.6196370124816895, "Value Loss": 0.6782644391059875, "_runtime": 6343.424226999283, "_timestamp": 1585515421.8449566, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.5063371658325195, "Value Loss": 0.7033795118331909, "_runtime": 6344.98010468483, "_timestamp": 1585515423.4008343, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.344991683959961, "Value Loss": 0.2827740013599396, "_runtime": 6346.535814523697, "_timestamp": 1585515424.9565442, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.260349750518799, "Value Loss": 0.5545973777770996, "_runtime": 6348.077852010727, "_timestamp": 1585515426.4985816, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.155865669250488, "Value Loss": 0.5081533193588257, "_runtime": 6349.634101867676, "_timestamp": 1585515428.0548315, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.068932056427002, "Value Loss": 0.9698442220687866, "_runtime": 6351.202903985977, "_timestamp": 1585515429.6236336, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.950420379638672, "Value Loss": 0.32537567615509033, "_runtime": 6352.7680580616, "_timestamp": 1585515431.1887877, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.923138618469238, "Value Loss": 0.8445917367935181, "_runtime": 6354.330614566803, "_timestamp": 1585515432.7513442, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.959649085998535, "Value Loss": 0.6472697257995605, "_runtime": 6355.885928869247, "_timestamp": 1585515434.3066585, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.873425483703613, "Value Loss": 0.5802967548370361, "_runtime": 6357.45142531395, "_timestamp": 1585515435.872155, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.8362250328063965, "Value Loss": 0.21233271062374115, "_runtime": 6359.016723155975, "_timestamp": 1585515437.4374528, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.787256240844727, "Value Loss": 0.2748107314109802, "_runtime": 6360.592649698257, "_timestamp": 1585515439.0133793, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.682670593261719, "Value Loss": 0.22133620083332062, "_runtime": 6362.200995206833, "_timestamp": 1585515440.6217248, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.676273822784424, "Value Loss": 0.9354387521743774, "_runtime": 6363.766090869904, "_timestamp": 1585515442.1868205, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.570376396179199, "Value Loss": 0.5296971201896667, "_runtime": 6365.342055797577, "_timestamp": 1585515443.7627854, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.446341037750244, "Value Loss": 0.3228800892829895, "_runtime": 6366.920106172562, "_timestamp": 1585515445.3408358, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.333615303039551, "Value Loss": 0.39623650908470154, "_runtime": 6368.495838880539, "_timestamp": 1585515446.9165685, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.186295986175537, "Value Loss": 0.15904830396175385, "_runtime": 6370.070680141449, "_timestamp": 1585515448.4914098, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.080413818359375, "Value Loss": 0.227899968624115, "_runtime": 6371.6451280117035, "_timestamp": 1585515450.0658576, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.949977159500122, "Value Loss": 0.14959955215454102, "_runtime": 6373.212612628937, "_timestamp": 1585515451.6333423, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.8615128993988037, "Value Loss": 0.2975362539291382, "_runtime": 6374.768101930618, "_timestamp": 1585515453.1888316, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.750316619873047, "Value Loss": 0.15738925337791443, "_runtime": 6376.332779407501, "_timestamp": 1585515454.753509, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6722378730773926, "Value Loss": 0.2377478927373886, "_runtime": 6377.901664018631, "_timestamp": 1585515456.3223937, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.553598403930664, "Value Loss": 0.5537615418434143, "_runtime": 6379.459884405136, "_timestamp": 1585515457.880614, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5294315814971924, "Value Loss": 0.14548856019973755, "_runtime": 6381.013843536377, "_timestamp": 1585515459.4345732, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4596915245056152, "Value Loss": 0.16814108192920685, "_runtime": 6382.581995248795, "_timestamp": 1585515461.002725, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.405677080154419, "Value Loss": 0.15065181255340576, "_runtime": 6384.139384508133, "_timestamp": 1585515462.5601141, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3433616161346436, "Value Loss": 0.12390032410621643, "_runtime": 6385.7221076488495, "_timestamp": 1585515464.1428373, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3020873069763184, "Value Loss": 0.10857953876256943, "_runtime": 6387.278662204742, "_timestamp": 1585515465.6993918, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.268834114074707, "Value Loss": 0.3589913547039032, "_runtime": 6388.835258245468, "_timestamp": 1585515467.255988, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.206819534301758, "Value Loss": 0.25822797417640686, "_runtime": 6390.389982223511, "_timestamp": 1585515468.8107119, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1141653060913086, "Value Loss": 0.09959405660629272, "_runtime": 6391.957293510437, "_timestamp": 1585515470.3780231, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.062328338623047, "Value Loss": 0.08690693229436874, "_runtime": 6393.522737264633, "_timestamp": 1585515471.943467, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.994110584259033, "Value Loss": 0.0852605402469635, "_runtime": 6395.087959766388, "_timestamp": 1585515473.5086894, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.94596266746521, "Value Loss": 0.08646483719348907, "_runtime": 6396.642431735992, "_timestamp": 1585515475.0631614, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.889331340789795, "Value Loss": 0.12729649245738983, "_runtime": 6398.209112644196, "_timestamp": 1585515476.6298423, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.837313413619995, "Value Loss": 0.4535904824733734, "_runtime": 6399.762775659561, "_timestamp": 1585515478.1835053, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7466232776641846, "Value Loss": 0.07066278159618378, "_runtime": 6401.329312801361, "_timestamp": 1585515479.7500424, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6639645099639893, "Value Loss": 0.08998475223779678, "_runtime": 6402.897376775742, "_timestamp": 1585515481.3181064, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6008501052856445, "Value Loss": 0.06256627291440964, "_runtime": 6404.4618372917175, "_timestamp": 1585515482.882567, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5319509506225586, "Value Loss": 0.06694585084915161, "_runtime": 6406.031835317612, "_timestamp": 1585515484.452565, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.474947929382324, "Value Loss": 0.19023096561431885, "_runtime": 6407.576881170273, "_timestamp": 1585515485.9976108, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3992836475372314, "Value Loss": 0.08060155808925629, "_runtime": 6409.166655778885, "_timestamp": 1585515487.5873854, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3489840030670166, "Value Loss": 0.07791416347026825, "_runtime": 6410.7330548763275, "_timestamp": 1585515489.1537845, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2909648418426514, "Value Loss": 0.07118266820907593, "_runtime": 6412.291890382767, "_timestamp": 1585515490.71262, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.257941961288452, "Value Loss": 0.20695938169956207, "_runtime": 6413.85680937767, "_timestamp": 1585515492.277539, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2013473510742188, "Value Loss": 0.15004365146160126, "_runtime": 6415.419979810715, "_timestamp": 1585515493.8407094, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1252248287200928, "Value Loss": 0.09475800395011902, "_runtime": 6416.984899282455, "_timestamp": 1585515495.405629, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.063450813293457, "Value Loss": 0.06846480071544647, "_runtime": 6418.536374568939, "_timestamp": 1585515496.9571042, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0266246795654297, "Value Loss": 0.05727095156908035, "_runtime": 6420.102267026901, "_timestamp": 1585515498.5229967, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9981248378753662, "Value Loss": 0.29239797592163086, "_runtime": 6421.6675181388855, "_timestamp": 1585515500.0882478, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9588332176208496, "Value Loss": 0.27333083748817444, "_runtime": 6423.22358417511, "_timestamp": 1585515501.6443138, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8976303339004517, "Value Loss": 0.08956042677164078, "_runtime": 6424.790314912796, "_timestamp": 1585515503.2110445, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8657053709030151, "Value Loss": 0.059784337878227234, "_runtime": 6426.345331907272, "_timestamp": 1585515504.7660615, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8465782403945923, "Value Loss": 0.16872967779636383, "_runtime": 6427.9027643203735, "_timestamp": 1585515506.323494, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8142772912979126, "Value Loss": 0.10595837980508804, "_runtime": 6429.446398496628, "_timestamp": 1585515507.8671281, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7905941009521484, "Value Loss": 0.319815993309021, "_runtime": 6431.054267883301, "_timestamp": 1585515509.4749975, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7322182655334473, "Value Loss": 0.07960695028305054, "_runtime": 6432.605777025223, "_timestamp": 1585515511.0265067, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6756842136383057, "Value Loss": 0.0890260711312294, "_runtime": 6434.172944784164, "_timestamp": 1585515512.5936744, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6477853059768677, "Value Loss": 0.03893846645951271, "_runtime": 6435.739477157593, "_timestamp": 1585515514.1602068, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6036841869354248, "Value Loss": 0.09477148950099945, "_runtime": 6437.304394006729, "_timestamp": 1585515515.7251236, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5568608045578003, "Value Loss": 0.043503351509571075, "_runtime": 6438.870232343674, "_timestamp": 1585515517.290962, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5179601907730103, "Value Loss": 0.040938302874565125, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875, -591544.6875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-25152420.0, -24750170.0, -24347922.0, -23945672.0, -23543422.0, -23141172.0, -22738924.0, -22336674.0, -21934424.0, -21532176.0, -21129926.0, -20727676.0, -20325428.0, -19923178.0, -19520928.0, -19118678.0, -18716428.0, -18314180.0, -17911930.0, -17509680.0, -17107432.0, -16705182.0, -16302932.0, -15900683.0, -15498434.0, -15096184.0, -14693935.0, -14291685.0, -13889436.0, -13487186.0, -13084937.0, -12682687.0, -12280438.0, -11878189.0, -11475939.0, -11073690.0, -10671440.0, -10269191.0, -9866941.0, -9464692.0, -9062442.0, -8660193.0, -8257944.0, -7855694.0, -7453444.0, -7051196.0, -6648946.0, -6246696.0, -5844448.0, -5442198.0, -5039948.0, -4637698.0, -4235450.0, -3833200.0, -3430950.0, -3028700.0, -2626452.0, -2224202.0, -1821952.0, -1419704.0, -1017454.0, -615204.0, -212954.0, 189294.0, 591544.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5941835045814514, 15635.494140625, 31271.58203125, 46907.671875, 62543.7578125, 78179.84375, 93815.9375, 109452.0234375, 125088.109375, 140724.203125, 156360.28125, 171996.375, 187632.46875, 203268.546875, 218904.640625, 234540.71875, 250176.8125, 265812.90625, 281449.0, 297085.0625, 312721.15625, 328357.25, 343993.34375, 359629.4375, 375265.53125, 390901.59375, 406537.6875, 422173.78125, 437809.875, 453445.96875, 469082.03125, 484718.125, 500354.21875, 515990.3125, 531626.375, 547262.4375, 562898.5625, 578534.625, 594170.6875, 609806.8125, 625442.875, 641079.0, 656715.0625, 672351.125, 687987.25, 703623.3125, 719259.4375, 734895.5, 750531.625, 766167.6875, 781803.75, 797439.875, 813075.9375, 828712.0625, 844348.125, 859984.1875, 875620.3125, 891256.375, 906892.5, 922528.5625, 938164.625, 953800.75, 969436.8125, 985072.9375, 1000709.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 7.0, 21.0, 19.0, 27.0, 29.0, 25.0, 15.0, 22.0, 12.0, 5.0, 1.0, 3.0, 1.0, 7.0, 5.0, 0.0, 0.0, 128.0, 11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 7.0, 5.0, 2.0, 5.0, 7.0, 9.0, 10.0, 11.0, 9.0, 8.0, 13.0, 10.0, 4.0, 7.0, 4.0, 4.0, 4.0, 7.0, 6.0, 8.0, 6.0, 6.0, 1.0, 5.0, 1.0, 2.0, 1.0, 1.0], "bins": [-848332.0625, -802424.875, -756517.625, -710610.4375, -664703.25, -618796.0625, -572888.875, -526981.625, -481074.4375, -435167.25, -389260.03125, -343352.8125, -297445.625, -251538.4375, -205631.1875, -159724.0, -113816.8125, -67909.625, -22002.4375, 23904.8125, 69812.0, 115719.1875, 161626.4375, 207533.5625, 253440.8125, 299348.0625, 345255.1875, 391162.4375, 437069.6875, 482976.8125, 528884.0625, 574791.1875, 620698.4375, 666605.6875, 712512.8125, 758420.0625, 804327.1875, 850234.4375, 896141.6875, 942048.8125, 987956.0625, 1033863.3125, 1079770.5, 1125677.75, 1171585.0, 1217492.0, 1263399.25, 1309306.5, 1355213.75, 1401121.0, 1447028.25, 1492935.25, 1538842.5, 1584749.75, 1630657.0, 1676564.25, 1722471.5, 1768378.5, 1814285.75, 1860193.0, 1906100.25, 1952007.5, 1997914.5, 2043821.75, 2089729.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0], "bins": [-3734081.75, -3483723.25, -3233364.5, -2983006.0, -2732647.5, -2482288.75, -2231930.25, -1981571.625, -1731213.0, -1480854.5, -1230495.75, -980137.25, -729778.75, -479420.0, -229061.5, 21297.25, 271655.75, 522014.25, 772372.75, 1022731.75, 1273090.25, 1523448.75, 1773807.25, 2024165.75, 2274524.25, 2524883.25, 2775241.75, 3025600.25, 3275958.75, 3526317.25, 3776676.25, 4027034.75, 4277393.0, 4527752.0, 4778110.0, 5028469.0, 5278827.0, 5529186.0, 5779545.0, 6029903.0, 6280262.0, 6530620.0, 6780979.0, 7031338.0, 7281696.0, 7532055.0, 7782413.0, 8032772.0, 8283130.0, 8533489.0, 8783848.0, 9034206.0, 9284565.0, 9534923.0, 9785282.0, 10035641.0, 10285999.0, 10536358.0, 10786716.0, 11037075.0, 11287434.0, 11537792.0, 11788151.0, 12038509.0, 12288868.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 6.0, 7.0, 4.0, 3.0, 1.0, 3.0], "bins": [-2432750.75, -2383188.75, -2333627.0, -2284065.0, -2234503.0, -2184941.0, -2135379.25, -2085817.25, -2036255.25, -1986693.375, -1937131.375, -1887569.5, -1838007.5, -1788445.625, -1738883.75, -1689321.75, -1639759.75, -1590197.875, -1540636.0, -1491074.0, -1441512.0, -1391950.125, -1342388.25, -1292826.25, -1243264.375, -1193702.375, -1144140.5, -1094578.5, -1045016.625, -995454.625, -945892.75, -896330.75, -846768.875, -797207.0, -747645.0, -698083.125, -648521.125, -598959.25, -549397.25, -499835.375, -450273.375, -400711.5, -351149.5, -301587.5, -252025.75, -202463.75, -152901.75, -103339.75, -53778.0, -4216.0, 45346.0, 94907.75, 144469.75, 194031.75, 243593.75, 293155.5, 342717.5, 392279.5, 441841.5, 491403.25, 540965.25, 590527.25, 640089.25, 689651.0, 739213.0]}, "_runtime": 6440.438080787659, "_timestamp": 1585515518.8588104, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4798997640609741, "Value Loss": 0.18484704196453094, "_runtime": 6442.002594947815, "_timestamp": 1585515520.4233246, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4440884590148926, "Value Loss": 0.08220521360635757, "_runtime": 6443.559533596039, "_timestamp": 1585515521.9802632, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3939272165298462, "Value Loss": 0.022835303097963333, "_runtime": 6445.124987125397, "_timestamp": 1585515523.5457168, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3649319410324097, "Value Loss": 0.06675601005554199, "_runtime": 6446.668130636215, "_timestamp": 1585515525.0888603, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3461428880691528, "Value Loss": 0.2762662172317505, "_runtime": 6448.226967096329, "_timestamp": 1585515526.6476967, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2993590831756592, "Value Loss": 0.04966592416167259, "_runtime": 6449.797072172165, "_timestamp": 1585515528.2178018, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.273853063583374, "Value Loss": 0.03275159373879433, "_runtime": 6451.360719919205, "_timestamp": 1585515529.7814496, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2402374744415283, "Value Loss": 0.016179272904992104, "_runtime": 6452.928322553635, "_timestamp": 1585515531.3490522, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2291538715362549, "Value Loss": 0.2666128873825073, "_runtime": 6454.519643068314, "_timestamp": 1585515532.9403727, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1753767728805542, "Value Loss": 0.02113601565361023, "_runtime": 6456.083524465561, "_timestamp": 1585515534.504254, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.169161081314087, "Value Loss": 0.21792708337306976, "_runtime": 6457.639338254929, "_timestamp": 1585515536.060068, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1176462173461914, "Value Loss": 0.03228295221924782, "_runtime": 6459.2058980464935, "_timestamp": 1585515537.6266277, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0780119895935059, "Value Loss": 0.07432319968938828, "_runtime": 6460.770843029022, "_timestamp": 1585515539.1915727, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0456314086914062, "Value Loss": 0.012320654466748238, "_runtime": 6462.326769351959, "_timestamp": 1585515540.747499, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0382928848266602, "Value Loss": 0.2283955067396164, "_runtime": 6463.872454166412, "_timestamp": 1585515542.2931838, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9899635910987854, "Value Loss": 0.01637628674507141, "_runtime": 6465.435895204544, "_timestamp": 1585515543.8566248, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9868206977844238, "Value Loss": 0.20258451998233795, "_runtime": 6466.991402387619, "_timestamp": 1585515545.412132, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9423942565917969, "Value Loss": 0.02853585220873356, "_runtime": 6468.549070119858, "_timestamp": 1585515546.9697998, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.905543863773346, "Value Loss": 0.009563269093632698, "_runtime": 6470.113810300827, "_timestamp": 1585515548.53454, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8986659646034241, "Value Loss": 0.08297059684991837, "_runtime": 6471.670683145523, "_timestamp": 1585515550.0914128, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8564410209655762, "Value Loss": 0.021248532459139824, "_runtime": 6473.239861965179, "_timestamp": 1585515551.6605916, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8460939526557922, "Value Loss": 0.14093713462352753, "_runtime": 6474.80454993248, "_timestamp": 1585515553.2252796, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8101097941398621, "Value Loss": 0.2262388914823532, "_runtime": 6476.369504928589, "_timestamp": 1585515554.7902346, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7835801243782043, "Value Loss": 0.1875670701265335, "_runtime": 6477.9710812568665, "_timestamp": 1585515556.391811, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7574340105056763, "Value Loss": 0.024512147530913353, "_runtime": 6479.536258459091, "_timestamp": 1585515557.956988, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.741486132144928, "Value Loss": 0.02047228254377842, "_runtime": 6481.100898981094, "_timestamp": 1585515559.5216286, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7196781039237976, "Value Loss": 0.022392136976122856, "_runtime": 6482.666366100311, "_timestamp": 1585515561.0870957, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7018858790397644, "Value Loss": 0.08480656892061234, "_runtime": 6484.230556488037, "_timestamp": 1585515562.6512861, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6756368279457092, "Value Loss": 0.09856151044368744, "_runtime": 6485.795351266861, "_timestamp": 1585515564.216081, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6593998074531555, "Value Loss": 0.008500928990542889, "_runtime": 6487.362415313721, "_timestamp": 1585515565.783145, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6371291279792786, "Value Loss": 0.030456384643912315, "_runtime": 6488.926744699478, "_timestamp": 1585515567.3474743, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6159641742706299, "Value Loss": 0.006873199716210365, "_runtime": 6490.4953145980835, "_timestamp": 1585515568.9160442, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6112975478172302, "Value Loss": 0.14759203791618347, "_runtime": 6492.052681922913, "_timestamp": 1585515570.4734116, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.581400990486145, "Value Loss": 0.05014877766370773, "_runtime": 6493.616078853607, "_timestamp": 1585515572.0368085, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5512253046035767, "Value Loss": 0.012061853893101215, "_runtime": 6495.172076225281, "_timestamp": 1585515573.5928059, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5650153756141663, "Value Loss": 0.18358035385608673, "_runtime": 6496.719413757324, "_timestamp": 1585515575.1401434, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5319256782531738, "Value Loss": 0.016996784135699272, "_runtime": 6498.281702041626, "_timestamp": 1585515576.7024317, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5052664279937744, "Value Loss": 0.038576286286115646, "_runtime": 6499.857986688614, "_timestamp": 1585515578.2787163, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4949949085712433, "Value Loss": 0.007227864116430283, "_runtime": 6501.47314286232, "_timestamp": 1585515579.8938725, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4765610992908478, "Value Loss": 0.0042441911064088345, "_runtime": 6503.047526836395, "_timestamp": 1585515581.4682565, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4625363349914551, "Value Loss": 0.004630773328244686, "_runtime": 6504.614518404007, "_timestamp": 1585515583.035248, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46946361660957336, "Value Loss": 0.1743491142988205, "_runtime": 6506.181256055832, "_timestamp": 1585515584.6019857, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45832499861717224, "Value Loss": 0.13554009795188904, "_runtime": 6507.734360456467, "_timestamp": 1585515586.15509, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4305957853794098, "Value Loss": 0.034157779067754745, "_runtime": 6509.301586151123, "_timestamp": 1585515587.7223158, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43126726150512695, "Value Loss": 0.042435210198163986, "_runtime": 6510.867179632187, "_timestamp": 1585515589.2879093, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38947349786758423, "Value Loss": 0.007935707457363605, "_runtime": 6512.433257102966, "_timestamp": 1585515590.8539867, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37845686078071594, "Value Loss": 0.005092904902994633, "_runtime": 6513.999298334122, "_timestamp": 1585515592.420028, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3664114773273468, "Value Loss": 0.03445780649781227, "_runtime": 6515.565939664841, "_timestamp": 1585515593.9866693, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3439842462539673, "Value Loss": 0.04737020656466484, "_runtime": 6517.133560180664, "_timestamp": 1585515595.5542898, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.322862833738327, "Value Loss": 0.004276673775166273, "_runtime": 6518.69047164917, "_timestamp": 1585515597.1112013, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3186877965927124, "Value Loss": 0.02748551219701767, "_runtime": 6520.257590770721, "_timestamp": 1585515598.6783204, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30620551109313965, "Value Loss": 0.07907247543334961, "_runtime": 6521.822440862656, "_timestamp": 1585515600.2431705, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2997838258743286, "Value Loss": 0.17189304530620575, "_runtime": 6523.390766143799, "_timestamp": 1585515601.8114958, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2722667157649994, "Value Loss": 0.0150856738910079, "_runtime": 6524.998224020004, "_timestamp": 1585515603.4189537, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2593717575073242, "Value Loss": 0.014660757035017014, "_runtime": 6526.56242442131, "_timestamp": 1585515604.983154, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25540852546691895, "Value Loss": 0.17370814085006714, "_runtime": 6528.117706298828, "_timestamp": 1585515606.538436, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24809208512306213, "Value Loss": 0.12665124237537384, "_runtime": 6529.6692798137665, "_timestamp": 1585515608.0900095, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.257489413022995, "Value Loss": 0.1538030058145523, "_runtime": 6531.234253883362, "_timestamp": 1585515609.6549835, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2448282241821289, "Value Loss": 0.09844174236059189, "_runtime": 6532.790988922119, "_timestamp": 1585515611.2117186, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25697535276412964, "Value Loss": 0.022056525573134422, "_runtime": 6534.347463130951, "_timestamp": 1585515612.7681928, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24270622432231903, "Value Loss": 0.019562043249607086, "_runtime": 6535.900209903717, "_timestamp": 1585515614.3209395, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23935134708881378, "Value Loss": 0.033803533762693405, "_runtime": 6537.454582929611, "_timestamp": 1585515615.8753126, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24155530333518982, "Value Loss": 0.023286307230591774, "_runtime": 6539.026492834091, "_timestamp": 1585515617.4472225, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21821947395801544, "Value Loss": 0.018378807231783867, "_runtime": 6540.580701828003, "_timestamp": 1585515619.0014315, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21506154537200928, "Value Loss": 0.16377761960029602, "_runtime": 6542.156276464462, "_timestamp": 1585515620.577006, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19202572107315063, "Value Loss": 0.008467725478112698, "_runtime": 6543.718052148819, "_timestamp": 1585515622.1387818, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17474257946014404, "Value Loss": 0.017995484173297882, "_runtime": 6545.28086066246, "_timestamp": 1585515623.7015903, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16123314201831818, "Value Loss": 0.032372068613767624, "_runtime": 6546.891272783279, "_timestamp": 1585515625.3120024, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14481320977210999, "Value Loss": 0.008153189904987812, "_runtime": 6548.466377735138, "_timestamp": 1585515626.8871074, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14522013068199158, "Value Loss": 0.10705839842557907, "_runtime": 6550.0410668849945, "_timestamp": 1585515628.4617965, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13858813047409058, "Value Loss": 0.042227473109960556, "_runtime": 6551.6168513298035, "_timestamp": 1585515630.037581, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15204592049121857, "Value Loss": 0.15613190829753876, "_runtime": 6553.192606925964, "_timestamp": 1585515631.6133366, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10540241003036499, "Value Loss": 0.0025198343209922314, "_runtime": 6554.764810085297, "_timestamp": 1585515633.1855397, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10970620810985565, "Value Loss": 0.044666096568107605, "_runtime": 6556.340536355972, "_timestamp": 1585515634.761266, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12624642252922058, "Value Loss": 0.14430604875087738, "_runtime": 6557.917196035385, "_timestamp": 1585515636.3379257, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10167944431304932, "Value Loss": 0.048110708594322205, "_runtime": 6559.498168706894, "_timestamp": 1585515637.9188983, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09281978011131287, "Value Loss": 0.04475279897451401, "_runtime": 6561.080732584, "_timestamp": 1585515639.5014622, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08990230411291122, "Value Loss": 0.0016410001553595066, "_runtime": 6562.663065195084, "_timestamp": 1585515641.0837948, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0896962508559227, "Value Loss": 0.04029310494661331, "_runtime": 6564.246737003326, "_timestamp": 1585515642.6674666, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0970262736082077, "Value Loss": 0.06784933060407639, "_runtime": 6565.830201387405, "_timestamp": 1585515644.250931, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0716094896197319, "Value Loss": 0.002088534412905574, "_runtime": 6567.398593902588, "_timestamp": 1585515645.8193235, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0819840133190155, "Value Loss": 0.0964772179722786, "_runtime": 6568.981076002121, "_timestamp": 1585515647.4018056, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.062667116522789, "Value Loss": 0.04394463449716568, "_runtime": 6570.598360776901, "_timestamp": 1585515649.0190904, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04741416126489639, "Value Loss": 0.011391161009669304, "_runtime": 6572.170899152756, "_timestamp": 1585515650.5916288, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04677282273769379, "Value Loss": 0.1415381133556366, "_runtime": 6573.752353429794, "_timestamp": 1585515652.173083, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03456638753414154, "Value Loss": 0.09446035325527191, "_runtime": 6575.3274183273315, "_timestamp": 1585515653.748148, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01835998333990574, "Value Loss": 0.048249371349811554, "_runtime": 6576.904385089874, "_timestamp": 1585515655.3251147, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029593832790851593, "Value Loss": 0.038877472281455994, "_runtime": 6578.485395669937, "_timestamp": 1585515656.9061253, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016106726601719856, "Value Loss": 0.03118831478059292, "_runtime": 6580.061653375626, "_timestamp": 1585515658.482383, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009986397810280323, "Value Loss": 0.022375835105776787, "_runtime": 6581.648362636566, "_timestamp": 1585515660.0690923, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008100245147943497, "Value Loss": 0.0036115774419158697, "_runtime": 6583.231365442276, "_timestamp": 1585515661.652095, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01650712825357914, "Value Loss": 0.024814529344439507, "_runtime": 6584.816391468048, "_timestamp": 1585515663.237121, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006000894121825695, "Value Loss": 0.01011502742767334, "_runtime": 6586.39999294281, "_timestamp": 1585515664.8207226, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013953475281596184, "Value Loss": 0.05212762579321861, "_runtime": 6587.972554445267, "_timestamp": 1585515666.393284, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029771674890071154, "Value Loss": 0.0015265188412740827, "_runtime": 6589.558030605316, "_timestamp": 1585515667.9787602, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0044062696397304535, "Value Loss": 0.05132647231221199, "_runtime": 6591.14305639267, "_timestamp": 1585515669.563786, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01131466031074524, "Value Loss": 0.025840885937213898, "_runtime": 6592.714117527008, "_timestamp": 1585515671.1348472, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014437912963330746, "Value Loss": 0.007554229348897934, "_runtime": 6594.322954654694, "_timestamp": 1585515672.7436843, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019396966323256493, "Value Loss": 0.027592604979872704, "_runtime": 6595.919897079468, "_timestamp": 1585515674.3406267, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02174222655594349, "Value Loss": 0.09654258191585541, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875, 190134.1875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 4.0], "bins": [-190135.6875, -26258.78125, 137618.125, 301495.03125, 465371.9375, 629248.8125, 793125.75, 957002.6875, 1120879.5, 1284756.5, 1448633.25, 1612510.25, 1776387.25, 1940264.0, 2104141.0, 2268017.75, 2431894.75, 2595771.75, 2759648.5, 2923525.5, 3087402.25, 3251279.25, 3415156.25, 3579033.0, 3742910.0, 3906787.0, 4070663.75, 4234541.0, 4398418.0, 4562295.0, 4726171.5, 4890048.5, 5053925.5, 5217802.5, 5381679.5, 5545556.0, 5709433.0, 5873310.0, 6037187.0, 6201064.0, 6364940.5, 6528817.5, 6692694.5, 6856571.5, 7020448.5, 7184325.5, 7348202.0, 7512079.0, 7675956.0, 7839833.0, 8003710.0, 8167586.5, 8331463.5, 8495340.0, 8659217.0, 8823094.0, 8986971.0, 9150848.0, 9314725.0, 9478601.0, 9642478.0, 9806355.0, 9970232.0, 10134109.0, 10297986.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-322993.3125, -317946.53125, -312899.78125, -307853.0, -302806.21875, -297759.46875, -292712.6875, -287665.90625, -282619.15625, -277572.375, -272525.625, -267478.84375, -262432.0625, -257385.296875, -252338.53125, -247291.75, -242244.984375, -237198.21875, -232151.4375, -227104.671875, -222057.90625, -217011.125, -211964.359375, -206917.59375, -201870.8125, -196824.046875, -191777.28125, -186730.515625, -181683.734375, -176636.96875, -171590.203125, -166543.421875, -161496.65625, -156449.890625, -151403.109375, -146356.34375, -141309.578125, -136262.796875, -131216.03125, -126169.265625, -121122.5, -116075.71875, -111028.953125, -105982.1875, -100935.40625, -95888.640625, -90841.875, -85795.09375, -80748.328125, -75701.5625, -70654.78125, -65608.015625, -60561.25, -55514.46875, -50467.71875, -45420.9375, -40374.15625, -35327.40625, -30280.625, -25233.84375, -20187.09375, -15140.3125, -10093.53125, -5046.78125, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 2.0, 4.0, 7.0, 2.0, 8.0, 3.0, 6.0, 7.0, 9.0, 7.0, 7.0, 7.0, 4.0, 11.0, 10.0, 3.0, 9.0, 8.0, 10.0, 8.0, 3.0, 3.0, 3.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 5.0, 135.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 4.0, 11.0, 31.0, 21.0, 22.0, 42.0, 34.0, 16.0, 4.0], "bins": [-971034.5, -951107.375, -931180.3125, -911253.1875, -891326.0625, -871399.0, -851471.875, -831544.75, -811617.625, -791690.5625, -771763.4375, -751836.375, -731909.25, -711982.125, -692055.0, -672127.875, -652200.8125, -632273.75, -612346.625, -592419.5, -572492.375, -552565.25, -532638.1875, -512711.0625, -492783.96875, -472856.875, -452929.75, -433002.625, -413075.5625, -393148.4375, -373221.3125, -353294.25, -333367.125, -313440.0, -293512.9375, -273585.8125, -253658.6875, -233731.625, -213804.5, -193877.375, -173950.25, -154023.1875, -134096.0625, -114168.9375, -94241.875, -74314.75, -54387.625, -34460.5625, -14533.4375, 5393.6875, 25320.75, 45247.875, 65175.0, 85102.125, 105029.25, 124956.25, 144883.375, 164810.5, 184737.625, 204664.75, 224591.875, 244518.875, 264446.0, 284373.125, 304300.25]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 0.0, 1.0, 4.0], "bins": [-3994812.5, -3918496.75, -3842181.25, -3765865.5, -3689550.0, -3613234.25, -3536918.5, -3460603.0, -3384287.25, -3307971.5, -3231656.0, -3155340.25, -3079024.5, -3002709.0, -2926393.25, -2850077.5, -2773762.0, -2697446.5, -2621130.75, -2544815.0, -2468499.5, -2392183.75, -2315868.0, -2239552.5, -2163236.75, -2086921.125, -2010605.5, -1934289.75, -1857974.0, -1781658.5, -1705342.75, -1629027.25, -1552711.5, -1476395.75, -1400080.25, -1323764.5, -1247449.0, -1171133.25, -1094817.5, -1018502.0, -942186.25, -865870.5, -789555.0, -713239.25, -636923.5, -560608.0, -484292.25, -407976.75, -331661.0, -255345.25, -179029.75, -102714.0, -26398.5, 49917.25, 126233.0, 202548.5, 278864.5, 355180.0, 431495.5, 507811.0, 584127.0, 660442.5, 736758.0, 813074.0, 889389.5]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 2.0, 2.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 3.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 6.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0], "bins": [-3430282.0, -3321548.5, -3212815.0, -3104081.5, -2995348.0, -2886614.5, -2777881.0, -2669147.5, -2560414.0, -2451680.5, -2342947.0, -2234213.5, -2125480.25, -2016746.75, -1908013.25, -1799279.75, -1690546.25, -1581812.75, -1473079.25, -1364345.75, -1255612.25, -1146878.75, -1038145.25, -929411.75, -820678.5, -711945.0, -603211.5, -494478.0, -385744.5, -277011.0, -168277.5, -59544.0, 49189.5, 157923.0, 266656.5, 375390.0, 484123.5, 592857.0, 701590.5, 810324.0, 919057.5, 1027791.0, 1136524.5, 1245258.0, 1353991.5, 1462725.0, 1571458.5, 1680192.0, 1788925.0, 1897658.5, 2006392.0, 2115125.5, 2223859.0, 2332592.5, 2441326.0, 2550059.5, 2658793.0, 2767526.5, 2876260.0, 2984993.5, 3093727.0, 3202460.5, 3311194.0, 3419927.5, 3528661.0]}, "_runtime": 6597.5016412734985, "_timestamp": 1585515675.922371, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011040476150810719, "Value Loss": 0.06903490424156189, "_runtime": 6599.0755932331085, "_timestamp": 1585515677.4963229, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0308107640594244, "Value Loss": 0.005263650789856911, "_runtime": 6600.660383462906, "_timestamp": 1585515679.081113, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03274372220039368, "Value Loss": 0.012025926262140274, "_runtime": 6602.242565155029, "_timestamp": 1585515680.6632948, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03235453739762306, "Value Loss": 0.003080919152125716, "_runtime": 6603.831639289856, "_timestamp": 1585515682.252369, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02534351870417595, "Value Loss": 0.01512752566486597, "_runtime": 6605.4132380485535, "_timestamp": 1585515683.8339677, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03274182230234146, "Value Loss": 0.0038466625846922398, "_runtime": 6606.975822210312, "_timestamp": 1585515685.3965518, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031582243740558624, "Value Loss": 0.00042150955414399505, "_runtime": 6608.54457950592, "_timestamp": 1585515686.9653091, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031548626720905304, "Value Loss": 0.0006315391510725021, "_runtime": 6610.125373601913, "_timestamp": 1585515688.5461032, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.032319825142621994, "Value Loss": 0.015442073345184326, "_runtime": 6611.70223069191, "_timestamp": 1585515690.1229603, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016798367723822594, "Value Loss": 0.1218157485127449, "_runtime": 6613.2800414562225, "_timestamp": 1585515691.700771, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03803801164031029, "Value Loss": 0.02633277140557766, "_runtime": 6614.858538150787, "_timestamp": 1585515693.2792678, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04041741043329239, "Value Loss": 0.009708630852401257, "_runtime": 6616.432662725449, "_timestamp": 1585515694.8533924, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04566004127264023, "Value Loss": 0.00935283862054348, "_runtime": 6618.0349860191345, "_timestamp": 1585515696.4557157, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04987189918756485, "Value Loss": 0.0030932817608118057, "_runtime": 6619.611217021942, "_timestamp": 1585515698.0319467, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.050908904522657394, "Value Loss": 0.017725275829434395, "_runtime": 6621.187341928482, "_timestamp": 1585515699.6080716, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04789555072784424, "Value Loss": 0.06870818883180618, "_runtime": 6622.749626398087, "_timestamp": 1585515701.170356, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05828099697828293, "Value Loss": 0.008039651438593864, "_runtime": 6624.3161590099335, "_timestamp": 1585515702.7368886, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04389577731490135, "Value Loss": 0.08671417087316513, "_runtime": 6625.892090320587, "_timestamp": 1585515704.31282, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03903895616531372, "Value Loss": 0.10037724673748016, "_runtime": 6627.470073223114, "_timestamp": 1585515705.8908029, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054762158542871475, "Value Loss": 0.008165341801941395, "_runtime": 6629.034131765366, "_timestamp": 1585515707.4548614, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05524488165974617, "Value Loss": 0.015911048278212547, "_runtime": 6630.609271526337, "_timestamp": 1585515709.0300012, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06153237447142601, "Value Loss": 0.004052143543958664, "_runtime": 6632.1871519088745, "_timestamp": 1585515710.6078815, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06296345591545105, "Value Loss": 0.0042803240939974785, "_runtime": 6633.765853881836, "_timestamp": 1585515712.1865835, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05745397508144379, "Value Loss": 0.018246294930577278, "_runtime": 6635.340116262436, "_timestamp": 1585515713.760846, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05967525765299797, "Value Loss": 0.005141033325344324, "_runtime": 6636.9152092933655, "_timestamp": 1585515715.335939, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.055251479148864746, "Value Loss": 0.024958550930023193, "_runtime": 6638.492036581039, "_timestamp": 1585515716.9127662, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.059646621346473694, "Value Loss": 0.0007164460839703679, "_runtime": 6640.114062786102, "_timestamp": 1585515718.5347924, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.056800808757543564, "Value Loss": 0.0009573428542353213, "_runtime": 6641.672871351242, "_timestamp": 1585515720.093601, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048108890652656555, "Value Loss": 0.0072087314911186695, "_runtime": 6643.229118108749, "_timestamp": 1585515721.6498477, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0487067885696888, "Value Loss": 0.05834059789776802, "_runtime": 6644.784372329712, "_timestamp": 1585515723.205102, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054100461304187775, "Value Loss": 0.00808543711900711, "_runtime": 6646.341748476028, "_timestamp": 1585515724.762478, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0576467365026474, "Value Loss": 0.0012276697671040893, "_runtime": 6647.897154092789, "_timestamp": 1585515726.3178837, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06086128577589989, "Value Loss": 0.006443865597248077, "_runtime": 6649.451822280884, "_timestamp": 1585515727.872552, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05066240578889847, "Value Loss": 0.07905630767345428, "_runtime": 6651.020012617111, "_timestamp": 1585515729.4407423, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06800972670316696, "Value Loss": 0.0033039378467947245, "_runtime": 6652.589544773102, "_timestamp": 1585515731.0102744, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07201515883207321, "Value Loss": 0.002062120707705617, "_runtime": 6654.156125545502, "_timestamp": 1585515732.5768552, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0751582458615303, "Value Loss": 0.003943800460547209, "_runtime": 6655.721685171127, "_timestamp": 1585515734.1424148, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06105201318860054, "Value Loss": 0.041007570922374725, "_runtime": 6657.287029743195, "_timestamp": 1585515735.7077594, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0596967414021492, "Value Loss": 0.054006509482860565, "_runtime": 6658.848873615265, "_timestamp": 1585515737.2696033, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06830261647701263, "Value Loss": 0.004903937689960003, "_runtime": 6660.403821706772, "_timestamp": 1585515738.8245513, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06970389932394028, "Value Loss": 0.0011311834678053856, "_runtime": 6661.9673545360565, "_timestamp": 1585515740.3880842, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06551156938076019, "Value Loss": 0.0031858556903898716, "_runtime": 6663.557068109512, "_timestamp": 1585515741.9777977, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06222494691610336, "Value Loss": 0.010423061437904835, "_runtime": 6665.129514217377, "_timestamp": 1585515743.5502439, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06600930541753769, "Value Loss": 0.002941345563158393, "_runtime": 6666.6861934661865, "_timestamp": 1585515745.106923, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0675935223698616, "Value Loss": 0.003967635333538055, "_runtime": 6668.250006914139, "_timestamp": 1585515746.6707366, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0642118752002716, "Value Loss": 0.022625068202614784, "_runtime": 6669.810131311417, "_timestamp": 1585515748.230861, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.037243396043777466, "Value Loss": 0.09191951900720596, "_runtime": 6671.365650892258, "_timestamp": 1585515749.7863805, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05498736351728439, "Value Loss": 0.051498714834451675, "_runtime": 6672.908324241638, "_timestamp": 1585515751.3290539, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03937345743179321, "Value Loss": 0.059116948395967484, "_runtime": 6674.464455842972, "_timestamp": 1585515752.8851855, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05628840997815132, "Value Loss": 0.0017719091847538948, "_runtime": 6676.010862112045, "_timestamp": 1585515754.4315917, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05153197422623634, "Value Loss": 0.0005039608804509044, "_runtime": 6677.554813146591, "_timestamp": 1585515755.9755428, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04600563272833824, "Value Loss": 0.002094278112053871, "_runtime": 6679.122273683548, "_timestamp": 1585515757.5430033, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03790172562003136, "Value Loss": 0.034432534128427505, "_runtime": 6680.677932024002, "_timestamp": 1585515759.0986617, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027358146384358406, "Value Loss": 0.08015575259923935, "_runtime": 6682.235387325287, "_timestamp": 1585515760.656117, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.049788035452365875, "Value Loss": 0.009829509072005749, "_runtime": 6683.792601823807, "_timestamp": 1585515762.2133315, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04806059971451759, "Value Loss": 0.036424022167921066, "_runtime": 6685.351551532745, "_timestamp": 1585515763.7722812, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06595656275749207, "Value Loss": 0.003935478627681732, "_runtime": 6686.955780506134, "_timestamp": 1585515765.3765101, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07381860911846161, "Value Loss": 0.005674568470567465, "_runtime": 6688.523183107376, "_timestamp": 1585515766.9439127, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08363017439842224, "Value Loss": 0.005241949111223221, "_runtime": 6690.093077421188, "_timestamp": 1585515768.513807, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0783785805106163, "Value Loss": 0.07552312314510345, "_runtime": 6691.655759334564, "_timestamp": 1585515770.076489, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09052319079637527, "Value Loss": 0.004677502438426018, "_runtime": 6693.211024284363, "_timestamp": 1585515771.631754, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07946521043777466, "Value Loss": 0.029612228274345398, "_runtime": 6694.755671977997, "_timestamp": 1585515773.1764016, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06418562680482864, "Value Loss": 0.07684939354658127, "_runtime": 6696.319766044617, "_timestamp": 1585515774.7404957, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06346927583217621, "Value Loss": 0.00519157899543643, "_runtime": 6697.885410070419, "_timestamp": 1585515776.3061397, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05061764270067215, "Value Loss": 0.03756940737366676, "_runtime": 6699.448501110077, "_timestamp": 1585515777.8692307, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0487871989607811, "Value Loss": 0.0016049373662099242, "_runtime": 6701.017612457275, "_timestamp": 1585515779.438342, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0213400200009346, "Value Loss": 0.040637508034706116, "_runtime": 6702.574430465698, "_timestamp": 1585515780.99516, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04227132722735405, "Value Loss": 0.009819387458264828, "_runtime": 6704.118535280228, "_timestamp": 1585515782.539265, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04610307887196541, "Value Loss": 0.0058104293420910835, "_runtime": 6705.669434547424, "_timestamp": 1585515784.0901642, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05047353729605675, "Value Loss": 0.0005038707167841494, "_runtime": 6707.234303236008, "_timestamp": 1585515785.6550329, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04468284174799919, "Value Loss": 0.08031134307384491, "_runtime": 6708.786564350128, "_timestamp": 1585515787.207294, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04977742210030556, "Value Loss": 0.04589478671550751, "_runtime": 6710.403188228607, "_timestamp": 1585515788.8239179, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07315006107091904, "Value Loss": 0.0029412219300866127, "_runtime": 6711.960316419601, "_timestamp": 1585515790.381046, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07138515263795853, "Value Loss": 0.02731616422533989, "_runtime": 6713.505656719208, "_timestamp": 1585515791.9263864, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08812648057937622, "Value Loss": 0.004912432283163071, "_runtime": 6715.046568870544, "_timestamp": 1585515793.4672985, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0965689867734909, "Value Loss": 0.003340861527249217, "_runtime": 6716.598264217377, "_timestamp": 1585515795.0189939, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09856869280338287, "Value Loss": 0.036434195935726166, "_runtime": 6718.142426252365, "_timestamp": 1585515796.563156, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09693192690610886, "Value Loss": 0.0076381447724998, "_runtime": 6719.685563802719, "_timestamp": 1585515798.1062934, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09118325263261795, "Value Loss": 0.0029975948855280876, "_runtime": 6721.239970207214, "_timestamp": 1585515799.6606998, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08253192156553268, "Value Loss": 0.00424961419776082, "_runtime": 6722.793660640717, "_timestamp": 1585515801.2143903, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07536688446998596, "Value Loss": 0.0028591006994247437, "_runtime": 6724.3462266922, "_timestamp": 1585515802.7669563, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06261992454528809, "Value Loss": 0.0012102144537493587, "_runtime": 6725.891684770584, "_timestamp": 1585515804.3124144, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.052895061671733856, "Value Loss": 0.004544755443930626, "_runtime": 6727.4349546432495, "_timestamp": 1585515805.8556843, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04213084280490875, "Value Loss": 0.04859853535890579, "_runtime": 6728.990309238434, "_timestamp": 1585515807.4110389, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04282153397798538, "Value Loss": 0.01697278581559658, "_runtime": 6730.546227693558, "_timestamp": 1585515808.9669573, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02647443115711212, "Value Loss": 0.07799751311540604, "_runtime": 6732.10315823555, "_timestamp": 1585515810.5238879, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.043987926095724106, "Value Loss": 0.005868501961231232, "_runtime": 6733.694571733475, "_timestamp": 1585515812.1153014, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.046715736389160156, "Value Loss": 0.02005147375166416, "_runtime": 6735.249423027039, "_timestamp": 1585515813.6701527, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06811661273241043, "Value Loss": 0.008624641224741936, "_runtime": 6736.804058074951, "_timestamp": 1585515815.2247877, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07266051322221756, "Value Loss": 0.004035627003759146, "_runtime": 6738.357084989548, "_timestamp": 1585515816.7778146, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07203034311532974, "Value Loss": 0.020327700302004814, "_runtime": 6739.9093363285065, "_timestamp": 1585515818.330066, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08088913559913635, "Value Loss": 0.004985275212675333, "_runtime": 6741.466243267059, "_timestamp": 1585515819.886973, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07683323323726654, "Value Loss": 0.025165244936943054, "_runtime": 6743.008054256439, "_timestamp": 1585515821.428784, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08480587601661682, "Value Loss": 0.030841931700706482, "_runtime": 6744.562482595444, "_timestamp": 1585515822.9832122, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08966119587421417, "Value Loss": 0.00216015730984509, "_runtime": 6746.108991384506, "_timestamp": 1585515824.529721, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08086465299129486, "Value Loss": 0.0040159206837415695, "_runtime": 6747.661880970001, "_timestamp": 1585515826.0826106, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08066745847463608, "Value Loss": 0.00412406912073493, "_runtime": 6749.209819316864, "_timestamp": 1585515827.630549, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05918704718351364, "Value Loss": 0.06622105836868286, "_runtime": 6750.766256809235, "_timestamp": 1585515829.1869864, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0668492242693901, "Value Loss": 0.003761206055060029, "_runtime": 6752.3133981227875, "_timestamp": 1585515830.7341278, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06131255626678467, "Value Loss": 0.00506386486813426, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875, -19613.654296875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-1200042.0, -1180984.875, -1161927.75, -1142870.625, -1123813.5, -1104756.375, -1085699.25, -1066642.125, -1047585.0625, -1028527.9375, -1009470.8125, -990413.6875, -971356.5625, -952299.4375, -933242.375, -914185.25, -895128.125, -876071.0, -857013.875, -837956.75, -818899.625, -799842.5, -780785.375, -761728.25, -742671.125, -723614.0, -704556.875, -685499.75, -666442.6875, -647385.5625, -628328.4375, -609271.3125, -590214.1875, -571157.0625, -552099.9375, -533042.8125, -513985.6875, -494928.5625, -475871.5, -456814.375, -437757.25, -418700.125, -399643.0, -380585.875, -361528.75, -342471.625, -323414.5, -304357.375, -285300.25, -266243.1875, -247186.0625, -228128.9375, -209071.8125, -190014.6875, -170957.5625, -151900.4375, -132843.375, -113786.25, -94729.125, -75672.0, -56614.875, -37557.75, -18500.625, 556.5, 19613.625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 520.1820678710938, 1040.3641357421875, 1560.546142578125, 2080.728271484375, 2600.910400390625, 3121.09228515625, 3641.2744140625, 4161.45654296875, 4681.638671875, 5201.82080078125, 5722.0029296875, 6242.1845703125, 6762.36669921875, 7282.548828125, 7802.73095703125, 8322.9130859375, 8843.0947265625, 9363.27734375, 9883.458984375, 10403.6416015625, 10923.8232421875, 11444.005859375, 11964.1875, 12484.369140625, 13004.5517578125, 13524.7333984375, 14044.916015625, 14565.09765625, 15085.2802734375, 15605.4619140625, 16125.64453125, 16645.826171875, 17166.0078125, 17686.189453125, 18206.373046875, 18726.5546875, 19246.736328125, 19766.91796875, 20287.1015625, 20807.283203125, 21327.46484375, 21847.646484375, 22367.828125, 22888.01171875, 23408.193359375, 23928.375, 24448.556640625, 24968.73828125, 25488.921875, 26009.103515625, 26529.28515625, 27049.466796875, 27569.650390625, 28089.83203125, 28610.013671875, 29130.1953125, 29650.376953125, 30170.560546875, 30690.7421875, 31210.923828125, 31731.10546875, 32251.2890625, 32771.46875, 33291.65234375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [13.0, 25.0, 55.0, 24.0, 7.0, 40.0, 17.0, 4.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 128.0, 4.0, 8.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 6.0, 6.0, 5.0, 6.0, 5.0, 6.0, 10.0, 6.0, 9.0, 8.0, 8.0, 7.0, 10.0, 10.0, 8.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0], "bins": [-31955.328125, -29757.046875, -27558.765625, -25360.486328125, -23162.205078125, -20963.923828125, -18765.64453125, -16567.36328125, -14369.08203125, -12170.80078125, -9972.51953125, -7774.240234375, -5575.958984375, -3377.677734375, -1179.3984375, 1018.8828125, 3217.1640625, 5415.4453125, 7613.7265625, 9812.0078125, 12010.2890625, 14208.56640625, 16406.84765625, 18605.12890625, 20803.41015625, 23001.69140625, 25199.97265625, 27398.25390625, 29596.53125, 31794.8125, 33993.09375, 36191.375, 38389.65625, 40587.9375, 42786.21875, 44984.5, 47182.78125, 49381.0625, 51579.34375, 53777.625, 55975.90625, 58174.1796875, 60372.4609375, 62570.7421875, 64769.0234375, 66967.3046875, 69165.5859375, 71363.8671875, 73562.1484375, 75760.4296875, 77958.7109375, 80156.9921875, 82355.2734375, 84553.5546875, 86751.8359375, 88950.1171875, 91148.390625, 93346.671875, 95544.953125, 97743.234375, 99941.515625, 102139.796875, 104338.078125, 106536.359375, 108734.640625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 5.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0], "bins": [-91904.625, -84044.28125, -76183.9453125, -68323.6015625, -60463.26171875, -52602.921875, -44742.578125, -36882.23828125, -29021.8984375, -21161.5546875, -13301.21875, -5440.875, 2419.46875, 10279.8046875, 18140.1484375, 26000.484375, 33860.828125, 41721.171875, 49581.515625, 57441.84375, 65302.1875, 73162.53125, 81022.875, 88883.21875, 96743.5625, 104603.890625, 112464.234375, 120324.578125, 128184.921875, 136045.265625, 143905.59375, 151765.9375, 159626.28125, 167486.625, 175346.96875, 183207.3125, 191067.65625, 198928.0, 206788.3125, 214648.65625, 222509.0, 230369.34375, 238229.6875, 246090.03125, 253950.375, 261810.71875, 269671.0625, 277531.40625, 285391.75, 293252.0625, 301112.40625, 308972.75, 316833.09375, 324693.4375, 332553.78125, 340414.125, 348274.46875, 356134.8125, 363995.15625, 371855.46875, 379715.8125, 387576.15625, 395436.5, 403296.84375, 411157.1875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 13.0, 1.0, 0.0, 2.0, 1.0, 6.0, 5.0, 1.0, 2.0, 0.0, 0.0, 5.0, 4.0, 6.0], "bins": [-466002.71875, -456961.15625, -447919.5625, -438878.0, -429836.4375, -420794.875, -411753.3125, -402711.71875, -393670.15625, -384628.59375, -375587.0, -366545.4375, -357503.875, -348462.3125, -339420.75, -330379.15625, -321337.59375, -312296.03125, -303254.4375, -294212.875, -285171.3125, -276129.75, -267088.1875, -258046.59375, -249005.03125, -239963.46875, -230921.890625, -221880.3125, -212838.75, -203797.1875, -194755.59375, -185714.03125, -176672.46875, -167630.90625, -158589.34375, -149547.75, -140506.1875, -131464.625, -122423.03125, -113381.46875, -104339.90625, -95298.34375, -86256.78125, -77215.1875, -68173.625, -59132.0625, -50090.46875, -41048.90625, -32007.34375, -22965.78125, -13924.21875, -4882.625, 4158.9375, 13200.5, 22242.09375, 31283.65625, 40325.21875, 49366.78125, 58408.34375, 67449.90625, 76491.53125, 85533.09375, 94574.65625, 103616.21875, 112657.78125]}, "_runtime": 6753.870071172714, "_timestamp": 1585515832.2908008, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05899963900446892, "Value Loss": 0.0006069668452255428, "_runtime": 6755.472361803055, "_timestamp": 1585515833.8930914, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.051190778613090515, "Value Loss": 0.004588722717016935, "_runtime": 6757.037301063538, "_timestamp": 1585515835.4580307, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04177122563123703, "Value Loss": 0.05419154837727547, "_runtime": 6758.601742506027, "_timestamp": 1585515837.0224721, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06020526587963104, "Value Loss": 0.0007338945870287716, "_runtime": 6760.156800031662, "_timestamp": 1585515838.5775297, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.061738234013319016, "Value Loss": 0.06127343699336052, "_runtime": 6761.725256681442, "_timestamp": 1585515840.1459863, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06995806843042374, "Value Loss": 0.004415319301187992, "_runtime": 6763.290402173996, "_timestamp": 1585515841.7111318, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08013542741537094, "Value Loss": 0.017511965706944466, "_runtime": 6764.856934547424, "_timestamp": 1585515843.2776642, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08154075592756271, "Value Loss": 0.01751476153731346, "_runtime": 6766.422639608383, "_timestamp": 1585515844.8433692, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08625881373882294, "Value Loss": 0.01300093811005354, "_runtime": 6767.975241422653, "_timestamp": 1585515846.395971, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08831540495157242, "Value Loss": 0.0028144146781414747, "_runtime": 6769.540019750595, "_timestamp": 1585515847.9607494, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09297828376293182, "Value Loss": 0.004436365328729153, "_runtime": 6771.099597454071, "_timestamp": 1585515849.520327, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09241463243961334, "Value Loss": 0.021498622372746468, "_runtime": 6772.666870832443, "_timestamp": 1585515851.0876005, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08669407665729523, "Value Loss": 0.021306253969669342, "_runtime": 6774.231416940689, "_timestamp": 1585515852.6521466, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07775189727544785, "Value Loss": 0.04642549529671669, "_runtime": 6775.805608987808, "_timestamp": 1585515854.2263386, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.058102257549762726, "Value Loss": 0.06883507966995239, "_runtime": 6777.383766889572, "_timestamp": 1585515855.8044965, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06817438453435898, "Value Loss": 0.004399131517857313, "_runtime": 6778.992719173431, "_timestamp": 1585515857.4134488, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06147771328687668, "Value Loss": 0.0021925230976194143, "_runtime": 6780.568199157715, "_timestamp": 1585515858.9889288, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05445212498307228, "Value Loss": 0.0002191199455410242, "_runtime": 6782.122556686401, "_timestamp": 1585515860.5432863, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04135621339082718, "Value Loss": 0.013756223022937775, "_runtime": 6783.6978096961975, "_timestamp": 1585515862.1185393, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04226827621459961, "Value Loss": 0.003041771473363042, "_runtime": 6785.27626490593, "_timestamp": 1585515863.6969945, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028110450133681297, "Value Loss": 0.04868469387292862, "_runtime": 6786.852490186691, "_timestamp": 1585515865.2732198, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048273373395204544, "Value Loss": 0.001411416451446712, "_runtime": 6788.427206993103, "_timestamp": 1585515866.8479366, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054591160267591476, "Value Loss": 0.003494428237900138, "_runtime": 6790.0021069049835, "_timestamp": 1585515868.4228365, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06567849218845367, "Value Loss": 0.00015289887960534543, "_runtime": 6791.571603536606, "_timestamp": 1585515869.9923332, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.062052782624959946, "Value Loss": 0.06461165845394135, "_runtime": 6793.136416912079, "_timestamp": 1585515871.5571465, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08304157853126526, "Value Loss": 0.0043446714989840984, "_runtime": 6794.703923463821, "_timestamp": 1585515873.124653, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08352114260196686, "Value Loss": 0.032326631247997284, "_runtime": 6796.270958662033, "_timestamp": 1585515874.6916883, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08946546912193298, "Value Loss": 0.045942846685647964, "_runtime": 6797.836594581604, "_timestamp": 1585515876.2573242, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10572843253612518, "Value Loss": 0.003889513900503516, "_runtime": 6799.403465270996, "_timestamp": 1585515877.824195, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10718733817338943, "Value Loss": 0.010912981815636158, "_runtime": 6800.971866369247, "_timestamp": 1585515879.392596, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10132558643817902, "Value Loss": 0.0038424928206950426, "_runtime": 6802.5621547698975, "_timestamp": 1585515880.9828844, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09717848896980286, "Value Loss": 0.017187530174851418, "_runtime": 6804.107998132706, "_timestamp": 1585515882.5287278, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08635642379522324, "Value Loss": 0.0031887651421129704, "_runtime": 6805.6784834861755, "_timestamp": 1585515884.0992131, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08153723180294037, "Value Loss": 0.00033194173010997474, "_runtime": 6807.24462890625, "_timestamp": 1585515885.6653585, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07415767759084702, "Value Loss": 0.002393788192421198, "_runtime": 6808.810750484467, "_timestamp": 1585515887.2314801, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06066560000181198, "Value Loss": 0.0523882657289505, "_runtime": 6810.381253242493, "_timestamp": 1585515888.8019829, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06439874321222305, "Value Loss": 0.0005433860351331532, "_runtime": 6811.947358369827, "_timestamp": 1585515890.368088, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06125551834702492, "Value Loss": 0.0009282787796109915, "_runtime": 6813.502813100815, "_timestamp": 1585515891.9235427, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.060342010110616684, "Value Loss": 0.0008264351636171341, "_runtime": 6815.058930873871, "_timestamp": 1585515893.4796605, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054605454206466675, "Value Loss": 0.025717543438076973, "_runtime": 6816.625289201736, "_timestamp": 1585515895.0460188, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03485481068491936, "Value Loss": 0.06298767775297165, "_runtime": 6818.190110206604, "_timestamp": 1585515896.6108398, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0598582960665226, "Value Loss": 0.0019406462088227272, "_runtime": 6819.757328033447, "_timestamp": 1585515898.1780577, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05121234431862831, "Value Loss": 0.032348841428756714, "_runtime": 6821.322970151901, "_timestamp": 1585515899.7436998, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07354243099689484, "Value Loss": 0.0022202986292541027, "_runtime": 6822.889434576035, "_timestamp": 1585515901.3101642, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06900182366371155, "Value Loss": 0.06456319242715836, "_runtime": 6824.455120563507, "_timestamp": 1585515902.8758502, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08240573853254318, "Value Loss": 0.001978611573576927, "_runtime": 6826.045829534531, "_timestamp": 1585515904.4665592, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08074837177991867, "Value Loss": 0.014437462203204632, "_runtime": 6827.610059261322, "_timestamp": 1585515906.030789, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08088561147451401, "Value Loss": 0.0109329242259264, "_runtime": 6829.174725294113, "_timestamp": 1585515907.595455, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0735507607460022, "Value Loss": 0.010743153281509876, "_runtime": 6830.7389035224915, "_timestamp": 1585515909.1596332, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07501043379306793, "Value Loss": 0.0013695749221369624, "_runtime": 6832.298033952713, "_timestamp": 1585515910.7187636, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05596520006656647, "Value Loss": 0.022590111941099167, "_runtime": 6833.853107690811, "_timestamp": 1585515912.2738373, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06517782062292099, "Value Loss": 0.004397442564368248, "_runtime": 6835.420566320419, "_timestamp": 1585515913.841296, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.061941735446453094, "Value Loss": 0.0004386919317767024, "_runtime": 6836.966224431992, "_timestamp": 1585515915.386954, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05776789039373398, "Value Loss": 0.006259015295654535, "_runtime": 6838.521655082703, "_timestamp": 1585515916.9423847, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054480407387018204, "Value Loss": 0.014713199809193611, "_runtime": 6840.084897518158, "_timestamp": 1585515918.5056272, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05119111388921738, "Value Loss": 0.014487852342426777, "_runtime": 6841.6522336006165, "_timestamp": 1585515920.0729632, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05338567495346069, "Value Loss": 0.005312803201377392, "_runtime": 6843.2179889678955, "_timestamp": 1585515921.6387186, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05399956926703453, "Value Loss": 0.000250649347435683, "_runtime": 6844.783950805664, "_timestamp": 1585515923.2046804, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.055014170706272125, "Value Loss": 0.004340034443885088, "_runtime": 6846.348099708557, "_timestamp": 1585515924.7688293, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05615461245179176, "Value Loss": 0.02258128672838211, "_runtime": 6847.938474655151, "_timestamp": 1585515926.3592043, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06229764223098755, "Value Loss": 0.05412187799811363, "_runtime": 6849.501211643219, "_timestamp": 1585515927.9219413, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07441327720880508, "Value Loss": 0.002872494049370289, "_runtime": 6851.053835630417, "_timestamp": 1585515929.4745653, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08459499478340149, "Value Loss": 0.0022281815763562918, "_runtime": 6852.618328094482, "_timestamp": 1585515931.0390577, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09154345840215683, "Value Loss": 0.008724444545805454, "_runtime": 6854.181932687759, "_timestamp": 1585515932.6026623, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10043731331825256, "Value Loss": 0.0025763213634490967, "_runtime": 6855.744584321976, "_timestamp": 1585515934.165314, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1041332259774208, "Value Loss": 0.0038593329954892397, "_runtime": 6857.308050632477, "_timestamp": 1585515935.7287803, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10610154271125793, "Value Loss": 0.0024573442060500383, "_runtime": 6858.860907316208, "_timestamp": 1585515937.281637, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09194149821996689, "Value Loss": 0.042563263326883316, "_runtime": 6860.415776252747, "_timestamp": 1585515938.836506, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10460034012794495, "Value Loss": 0.0287147369235754, "_runtime": 6861.983009815216, "_timestamp": 1585515940.4037395, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10004398971796036, "Value Loss": 0.00244133360683918, "_runtime": 6863.5500428676605, "_timestamp": 1585515941.9707725, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0888243168592453, "Value Loss": 0.0023294277489185333, "_runtime": 6865.111832380295, "_timestamp": 1585515943.532562, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08136533945798874, "Value Loss": 0.0024394786451011896, "_runtime": 6866.678660392761, "_timestamp": 1585515945.09939, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07309457659721375, "Value Loss": 0.0006176387541927397, "_runtime": 6868.243901491165, "_timestamp": 1585515946.6646311, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05319681391119957, "Value Loss": 0.013164057396352291, "_runtime": 6869.796451330185, "_timestamp": 1585515948.217181, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.041713569313287735, "Value Loss": 0.03202326223254204, "_runtime": 6871.399753808975, "_timestamp": 1585515949.8204834, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.043454673141241074, "Value Loss": 0.004366125445812941, "_runtime": 6872.964802265167, "_timestamp": 1585515951.385532, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02908896654844284, "Value Loss": 0.019810425117611885, "_runtime": 6874.528916120529, "_timestamp": 1585515952.9496458, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.036047667264938354, "Value Loss": 0.0002708950487431139, "_runtime": 6876.098361253738, "_timestamp": 1585515954.519091, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03221038728952408, "Value Loss": 0.0004645688459277153, "_runtime": 6877.664409637451, "_timestamp": 1585515956.0851393, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019913360476493835, "Value Loss": 0.015938391909003258, "_runtime": 6879.228707790375, "_timestamp": 1585515957.6494374, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02867078222334385, "Value Loss": 0.0004326905473135412, "_runtime": 6880.793492794037, "_timestamp": 1585515959.2142224, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02773202396929264, "Value Loss": 0.002108933636918664, "_runtime": 6882.36089015007, "_timestamp": 1585515960.7816198, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02889581210911274, "Value Loss": 0.04938188195228577, "_runtime": 6883.927061319351, "_timestamp": 1585515962.347791, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0414806567132473, "Value Loss": 0.0001925959950312972, "_runtime": 6885.4943742752075, "_timestamp": 1585515963.915104, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048790931701660156, "Value Loss": 0.0014171460643410683, "_runtime": 6887.059812307358, "_timestamp": 1585515965.480542, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.056702062487602234, "Value Loss": 0.019016485661268234, "_runtime": 6888.624611377716, "_timestamp": 1585515967.045341, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06654607504606247, "Value Loss": 0.002564849564805627, "_runtime": 6890.18869137764, "_timestamp": 1585515968.609421, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07583001255989075, "Value Loss": 0.0015568927628919482, "_runtime": 6891.744338512421, "_timestamp": 1585515970.1650681, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07797512412071228, "Value Loss": 0.01439267210662365, "_runtime": 6893.3071410655975, "_timestamp": 1585515971.7278707, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07929768413305283, "Value Loss": 0.0022960358764976263, "_runtime": 6894.909457921982, "_timestamp": 1585515973.3301876, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07939037680625916, "Value Loss": 0.002214755630120635, "_runtime": 6896.464829206467, "_timestamp": 1585515974.8855588, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08068172633647919, "Value Loss": 0.00204918603412807, "_runtime": 6898.029077529907, "_timestamp": 1585515976.4498072, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08020023256540298, "Value Loss": 0.002089159330353141, "_runtime": 6899.585375785828, "_timestamp": 1585515978.0061054, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07175567746162415, "Value Loss": 0.0008189425570890307, "_runtime": 6901.142426729202, "_timestamp": 1585515979.5631564, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048236820846796036, "Value Loss": 0.030378488823771477, "_runtime": 6902.700008392334, "_timestamp": 1585515981.120738, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.052681829780340195, "Value Loss": 0.0008969728369265795, "_runtime": 6904.270230293274, "_timestamp": 1585515982.69096, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04302384704351425, "Value Loss": 0.003144304035231471, "_runtime": 6905.844786167145, "_timestamp": 1585515984.2655158, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03632509708404541, "Value Loss": 0.020956359803676605, "_runtime": 6907.4114644527435, "_timestamp": 1585515985.832194, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0244044978171587, "Value Loss": 0.054707545787096024, "_runtime": 6908.968336820602, "_timestamp": 1585515987.3890665, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030723240226507187, "Value Loss": 0.020354989916086197, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875, 76466.2421875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 4.0], "bins": [-76466.2421875, -13103.671875, 50258.8984375, 113621.4765625, 176984.03125, 240346.59375, 303709.1875, 367071.75, 430434.3125, 493796.875, 557159.4375, 620522.0, 683884.625, 747247.1875, 810609.75, 873972.3125, 937334.875, 1000697.5, 1064060.0, 1127422.625, 1190785.125, 1254147.75, 1317510.25, 1380872.875, 1444235.5, 1507598.0, 1570960.625, 1634323.125, 1697685.75, 1761048.25, 1824410.875, 1887773.375, 1951136.0, 2014498.625, 2077861.25, 2141223.75, 2204586.25, 2267948.75, 2331311.5, 2394674.0, 2458036.5, 2521399.25, 2584761.75, 2648124.25, 2711486.75, 2774849.5, 2838212.0, 2901574.5, 2964937.25, 3028299.75, 3091662.25, 3155024.75, 3218387.5, 3281750.0, 3345112.5, 3408475.0, 3471837.75, 3535200.25, 3598562.75, 3661925.5, 3725288.0, 3788650.5, 3852013.0, 3915375.75, 3978738.25]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-129731.921875, -127704.859375, -125677.796875, -123650.734375, -121623.671875, -119596.609375, -117569.546875, -115542.484375, -113515.421875, -111488.359375, -109461.296875, -107434.234375, -105407.171875, -103380.109375, -101353.0546875, -99325.9921875, -97298.9296875, -95271.8671875, -93244.8046875, -91217.7421875, -89190.6796875, -87163.6171875, -85136.5546875, -83109.4921875, -81082.4296875, -79055.3671875, -77028.3046875, -75001.25, -72974.1875, -70947.125, -68920.0625, -66893.0, -64865.93359375, -62838.875, -60811.8125, -58784.75, -56757.6875, -54730.625, -52703.5625, -50676.5, -48649.4375, -46622.375, -44595.3125, -42568.25, -40541.1875, -38514.125, -36487.0625, -34460.0, -32432.9375, -30405.875, -28378.8125, -26351.75, -24324.6875, -22297.625, -20270.5703125, -18243.5078125, -16216.4453125, -14189.3828125, -12162.3203125, -10135.2578125, -8108.1953125, -6081.1328125, -4054.0703125, -2027.0078125, 0.0546875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 2.0, 6.0, 6.0, 3.0, 8.0, 7.0, 4.0, 8.0, 8.0, 5.0, 6.0, 6.0, 11.0, 8.0, 10.0, 9.0, 10.0, 4.0, 8.0, 3.0, 2.0, 5.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 4.0, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 6.0, 17.0, 27.0, 24.0, 26.0, 39.0, 29.0, 15.0, 4.0], "bins": [-367226.53125, -359684.125, -352141.6875, -344599.28125, -337056.875, -329514.4375, -321972.03125, -314429.625, -306887.21875, -299344.78125, -291802.375, -284259.96875, -276717.5625, -269175.125, -261632.71875, -254090.296875, -246547.875, -239005.46875, -231463.046875, -223920.640625, -216378.21875, -208835.8125, -201293.390625, -193750.96875, -186208.5625, -178666.140625, -171123.734375, -163581.3125, -156038.890625, -148496.484375, -140954.0625, -133411.65625, -125869.234375, -118326.8125, -110784.40625, -103242.0, -95699.5625, -88157.15625, -80614.75, -73072.3125, -65529.90625, -57987.5, -50445.09375, -42902.65625, -35360.25, -27817.84375, -20275.40625, -12733.0, -5190.59375, 2351.84375, 9894.25, 17436.65625, 24979.0625, 32521.5, 40063.90625, 47606.3125, 55148.75, 62691.15625, 70233.5625, 77776.0, 85318.40625, 92860.8125, 100403.21875, 107945.65625, 115488.0625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 2.0, 2.0], "bins": [-1600724.5, -1569113.75, -1537503.0, -1505892.25, -1474281.5, -1442670.75, -1411060.0, -1379449.125, -1347838.375, -1316227.625, -1284616.875, -1253006.125, -1221395.375, -1189784.625, -1158173.875, -1126563.0, -1094952.25, -1063341.5, -1031730.8125, -1000120.0, -968509.25, -936898.5, -905287.75, -873677.0, -842066.25, -810455.4375, -778844.6875, -747233.9375, -715623.1875, -684012.4375, -652401.625, -620790.875, -589180.125, -557569.375, -525958.625, -494347.875, -462737.125, -431126.375, -399515.5, -367904.75, -336294.0, -304683.25, -273072.5, -241461.75, -209851.0, -178240.25, -146629.5, -115018.75, -83408.0, -51797.125, -20186.375, 11424.375, 43035.125, 74645.875, 106256.625, 137867.375, 169478.125, 201088.875, 232699.625, 264310.5, 295921.25, 327532.0, 359142.75, 390753.5, 422364.25]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 6.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0], "bins": [-828672.875, -796542.875, -764412.8125, -732282.8125, -700152.75, -668022.75, -635892.75, -603762.6875, -571632.6875, -539502.625, -507372.625, -475242.59375, -443112.5625, -410982.53125, -378852.53125, -346722.5, -314592.46875, -282462.4375, -250332.4375, -218202.375, -186072.375, -153942.3125, -121812.3125, -89682.3125, -57552.25, -25422.25, 6707.8125, 38837.8125, 70967.8125, 103097.875, 135227.875, 167357.9375, 199487.9375, 231618.0, 263748.0, 295878.0, 328008.0, 360138.125, 392268.125, 424398.125, 456528.125, 488658.125, 520788.25, 552918.25, 585048.25, 617178.25, 649308.25, 681438.375, 713568.375, 745698.375, 777828.375, 809958.375, 842088.5, 874218.5, 906348.5, 938478.5, 970608.5, 1002738.625, 1034868.625, 1066998.625, 1099128.625, 1131258.625, 1163388.75, 1195518.75, 1227648.75]}, "_runtime": 6910.534022331238, "_timestamp": 1585515988.954752, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03210971876978874, "Value Loss": 0.014110218733549118, "_runtime": 6910.534022331238, "_timestamp": 1585515988.954752, "_step": 499}
