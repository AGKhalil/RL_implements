{"Episode reward": -55.17433485723814, "Episode length": 999, "Policy Loss": -0.0876288041472435, "Value Loss": 0.016438864171504974, "_runtime": 6846.844817876816, "_timestamp": 1585576762.6894512, "_step": 0}
{"Episode reward": -89.69070427601785, "Episode length": 999, "Policy Loss": -64.08495330810547, "Value Loss": 926.7752685546875, "_runtime": 6848.3248636722565, "_timestamp": 1585576764.169497, "_step": 1}
{"Episode reward": -99.10919475974525, "Episode length": 999, "Policy Loss": 0.576758861541748, "Value Loss": 14.046112060546875, "_runtime": 6849.72941660881, "_timestamp": 1585576765.57405, "_step": 2}
{"Episode reward": 10.360570131603978, "Episode length": 898, "Policy Loss": 1.0070668458938599, "Value Loss": 293.7275085449219, "_runtime": 6851.054917812347, "_timestamp": 1585576766.8995512, "_step": 3}
{"Episode reward": 13.551933420141637, "Episode length": 865, "Policy Loss": 8.455281257629395, "Value Loss": 852.9068603515625, "_runtime": 6852.571355581284, "_timestamp": 1585576768.415989, "_step": 4}
{"Episode reward": -99.5441314844168, "Episode length": 999, "Policy Loss": 1.9066359996795654, "Value Loss": 434.1746520996094, "_runtime": 6854.138080835342, "_timestamp": 1585576769.9827142, "_step": 5}
{"Episode reward": -99.75133683951432, "Episode length": 999, "Policy Loss": -1.8904201984405518, "Value Loss": 335.7169494628906, "_runtime": 6855.6413831710815, "_timestamp": 1585576771.4860165, "_step": 6}
{"Episode reward": 2.4944285964373165, "Episode length": 976, "Policy Loss": -1.3899072408676147, "Value Loss": 137.52174377441406, "_runtime": 6857.170667886734, "_timestamp": 1585576773.0153012, "_step": 7}
{"Episode reward": -99.73738569505373, "Episode length": 999, "Policy Loss": -8.131563186645508, "Value Loss": 307.2535400390625, "_runtime": 6858.662420749664, "_timestamp": 1585576774.507054, "_step": 8}
{"Episode reward": 5.219105434418836, "Episode length": 948, "Policy Loss": -12.21658706665039, "Value Loss": 1874.677978515625, "_runtime": 6859.553396224976, "_timestamp": 1585576775.3980296, "_step": 9}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": -2.900726079940796, "Value Loss": 50.99083709716797, "_runtime": 6860.3977110385895, "_timestamp": 1585576776.2423444, "_step": 10}
{"Episode reward": 46.19981048495926, "Episode length": 539, "Policy Loss": 0.2239331305027008, "Value Loss": 43.64823913574219, "_runtime": 6861.9509654045105, "_timestamp": 1585576777.7955987, "_step": 11}
{"Episode reward": -99.80448041558125, "Episode length": 999, "Policy Loss": 1.2107986211776733, "Value Loss": 29.15622329711914, "_runtime": 6863.475388765335, "_timestamp": 1585576779.320022, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.345588445663452, "Value Loss": 3.796950101852417, "_runtime": 6864.985589027405, "_timestamp": 1585576780.8302224, "_step": 13}
{"Episode reward": -99.85184457041183, "Episode length": 999, "Policy Loss": 4.277941703796387, "Value Loss": 131.94638061523438, "_runtime": 6866.31037569046, "_timestamp": 1585576782.155009, "_step": 14}
{"Episode reward": 15.701066035789495, "Episode length": 844, "Policy Loss": 8.619366645812988, "Value Loss": 752.58203125, "_runtime": 6867.798399925232, "_timestamp": 1585576783.6430333, "_step": 15}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 6.04205322265625, "Value Loss": 128.50509643554688, "_runtime": 6868.656898498535, "_timestamp": 1585576784.5015318, "_step": 16}
{"Episode reward": 45.89895388705141, "Episode length": 542, "Policy Loss": 0.11758290231227875, "Value Loss": 106.63469696044922, "_runtime": 6870.251716375351, "_timestamp": 1585576786.0963497, "_step": 17}
{"Episode reward": -99.8022489014999, "Episode length": 999, "Policy Loss": 3.536320447921753, "Value Loss": 52.22111892700195, "_runtime": 6871.8129279613495, "_timestamp": 1585576787.6575613, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.669306755065918, "Value Loss": 109.98191833496094, "_runtime": 6873.320133686066, "_timestamp": 1585576789.164767, "_step": 19}
{"Episode reward": -99.7521992973882, "Episode length": 999, "Policy Loss": 0.008583763614296913, "Value Loss": 351.8187561035156, "_runtime": 6873.950948238373, "_timestamp": 1585576789.7955816, "_step": 20}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.6984740495681763, "Value Loss": 75.51939392089844, "_runtime": 6875.50048494339, "_timestamp": 1585576791.3451183, "_step": 21}
{"Episode reward": -99.78616524338582, "Episode length": 999, "Policy Loss": 1.2447937726974487, "Value Loss": 14.465326309204102, "_runtime": 6877.042934894562, "_timestamp": 1585576792.8875682, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02405247464776039, "Value Loss": 1.7264047861099243, "_runtime": 6878.5488493442535, "_timestamp": 1585576794.3934827, "_step": 23}
{"Episode reward": -99.72755370223756, "Episode length": 999, "Policy Loss": -0.25266674160957336, "Value Loss": 1.743269681930542, "_runtime": 6879.332405805588, "_timestamp": 1585576795.1770391, "_step": 24}
{"Episode reward": 52.29947384607327, "Episode length": 478, "Policy Loss": 4.471789360046387, "Value Loss": 23.184328079223633, "_runtime": 6880.221870660782, "_timestamp": 1585576796.066504, "_step": 25}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": -0.6885564923286438, "Value Loss": 21.6400089263916, "_runtime": 6881.649342536926, "_timestamp": 1585576797.4939759, "_step": 26}
{"Episode reward": 7.999733375013832, "Episode length": 921, "Policy Loss": -2.241222620010376, "Value Loss": 19.370094299316406, "_runtime": 6883.177582502365, "_timestamp": 1585576799.0222158, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.737375259399414, "Value Loss": 3.782871723175049, "_runtime": 6884.219881057739, "_timestamp": 1585576800.0645144, "_step": 28}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": -2.729835033416748, "Value Loss": 16.145156860351562, "_runtime": 6885.773465156555, "_timestamp": 1585576801.6180985, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.257010459899902, "Value Loss": 0.2396562546491623, "_runtime": 6887.317821264267, "_timestamp": 1585576803.1624546, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.431020736694336, "Value Loss": 0.800703763961792, "_runtime": 6888.844567298889, "_timestamp": 1585576804.6892006, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.578417778015137, "Value Loss": 1.323062777519226, "_runtime": 6889.522223949432, "_timestamp": 1585576805.3668573, "_step": 32}
{"Episode reward": 58.399999999999686, "Episode length": 416, "Policy Loss": -0.5647749304771423, "Value Loss": 51.936153411865234, "_runtime": 6890.036313533783, "_timestamp": 1585576805.8809469, "_step": 33}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": -0.26104381680488586, "Value Loss": 53.194000244140625, "_runtime": 6891.576287269592, "_timestamp": 1585576807.4209206, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.4563422203063965, "Value Loss": 9.400617599487305, "_runtime": 6893.106912851334, "_timestamp": 1585576808.9515462, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.763543128967285, "Value Loss": 8.198229789733887, "_runtime": 6894.6046352386475, "_timestamp": 1585576810.4492686, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.398036003112793, "Value Loss": 1.509865641593933, "_runtime": 6896.156714916229, "_timestamp": 1585576812.0013483, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.717168807983398, "Value Loss": 0.30358225107192993, "_runtime": 6897.712115287781, "_timestamp": 1585576813.5567486, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.961573123931885, "Value Loss": 0.5895298719406128, "_runtime": 6899.254194259644, "_timestamp": 1585576815.0988276, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.434906959533691, "Value Loss": 4.539878845214844, "_runtime": 6900.825750589371, "_timestamp": 1585576816.670384, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.259382724761963, "Value Loss": 1.559948444366455, "_runtime": 6901.3376359939575, "_timestamp": 1585576817.1822693, "_step": 41}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": -3.2020466327667236, "Value Loss": 42.06349563598633, "_runtime": 6902.881997346878, "_timestamp": 1585576818.7266307, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.289370536804199, "Value Loss": 2.6633212566375732, "_runtime": 6904.452456235886, "_timestamp": 1585576820.2970896, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.744121551513672, "Value Loss": 10.223254203796387, "_runtime": 6905.943143606186, "_timestamp": 1585576821.787777, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.999702453613281, "Value Loss": 0.653421938419342, "_runtime": 6907.499161243439, "_timestamp": 1585576823.3437946, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.838287353515625, "Value Loss": 0.6683462262153625, "_runtime": 6908.612503767014, "_timestamp": 1585576824.457137, "_step": 46}
{"Episode reward": 29.9999999999997, "Episode length": 700, "Policy Loss": -4.179468154907227, "Value Loss": 14.275195121765137, "_runtime": 6910.147778511047, "_timestamp": 1585576825.9924119, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.4790778160095215, "Value Loss": 0.3808530569076538, "_runtime": 6911.71703004837, "_timestamp": 1585576827.5616634, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.301303386688232, "Value Loss": 0.4533405900001526, "_runtime": 6913.253040790558, "_timestamp": 1585576829.0976741, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.108245849609375, "Value Loss": 0.3532553017139435, "_runtime": 6914.7889316082, "_timestamp": 1585576830.633565, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.819195747375488, "Value Loss": 2.405627727508545, "_runtime": 6915.397035598755, "_timestamp": 1585576831.241669, "_step": 51}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": -1.5569599866867065, "Value Loss": 31.011289596557617, "_runtime": 6916.1581773757935, "_timestamp": 1585576832.0028107, "_step": 52}
{"Episode reward": 54.899999999999636, "Episode length": 451, "Policy Loss": -2.0646865367889404, "Value Loss": 24.57379913330078, "_runtime": 6916.631224870682, "_timestamp": 1585576832.4758582, "_step": 53}
{"Episode reward": 72.19999999999987, "Episode length": 278, "Policy Loss": -0.11598934233188629, "Value Loss": 37.839088439941406, "_runtime": 6917.677476406097, "_timestamp": 1585576833.5221097, "_step": 54}
{"Episode reward": 29.69999999999972, "Episode length": 703, "Policy Loss": -3.031149387359619, "Value Loss": 14.395088195800781, "_runtime": 6918.837880849838, "_timestamp": 1585576834.6825142, "_step": 55}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": -3.5307693481445312, "Value Loss": 13.127134323120117, "_runtime": 6919.956112384796, "_timestamp": 1585576835.8007457, "_step": 56}
{"Episode reward": 23.800000000000054, "Episode length": 762, "Policy Loss": -3.517676830291748, "Value Loss": 13.277446746826172, "_runtime": 6921.475936889648, "_timestamp": 1585576837.3205702, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.832157611846924, "Value Loss": 0.656314492225647, "_runtime": 6923.0020616054535, "_timestamp": 1585576838.846695, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.930824279785156, "Value Loss": 1.792585015296936, "_runtime": 6923.546369552612, "_timestamp": 1585576839.391003, "_step": 59}
{"Episode reward": 65.9999999999998, "Episode length": 340, "Policy Loss": -2.0536046028137207, "Value Loss": 30.669694900512695, "_runtime": 6925.074051141739, "_timestamp": 1585576840.9186845, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.724760055541992, "Value Loss": 1.3064290285110474, "_runtime": 6925.605448961258, "_timestamp": 1585576841.4500823, "_step": 61}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": -1.3908004760742188, "Value Loss": 33.28116226196289, "_runtime": 6926.399089336395, "_timestamp": 1585576842.2437227, "_step": 62}
{"Episode reward": 46.59999999999952, "Episode length": 534, "Policy Loss": -2.633870840072632, "Value Loss": 20.309785842895508, "_runtime": 6927.947124481201, "_timestamp": 1585576843.7917578, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.2924017906188965, "Value Loss": 0.45925116539001465, "_runtime": 6929.443738460541, "_timestamp": 1585576845.2883718, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.158176898956299, "Value Loss": 0.3192817270755768, "_runtime": 6930.9417316913605, "_timestamp": 1585576846.786365, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.037282943725586, "Value Loss": 0.34334951639175415, "_runtime": 6932.290623426437, "_timestamp": 1585576848.1352568, "_step": 66}
{"Episode reward": 13.100000000000662, "Episode length": 869, "Policy Loss": -2.3762993812561035, "Value Loss": 11.43666934967041, "_runtime": 6933.841581583023, "_timestamp": 1585576849.686215, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6152968406677246, "Value Loss": 0.3042604923248291, "_runtime": 6935.180846452713, "_timestamp": 1585576851.0254798, "_step": 68}
{"Episode reward": 13.700000000000628, "Episode length": 863, "Policy Loss": -2.098466157913208, "Value Loss": 11.771049499511719, "_runtime": 6936.711986780167, "_timestamp": 1585576852.5566201, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3799877166748047, "Value Loss": 0.5876938700675964, "_runtime": 6938.2700278759, "_timestamp": 1585576854.1146612, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3134288787841797, "Value Loss": 0.6038274765014648, "_runtime": 6939.850525856018, "_timestamp": 1585576855.6951592, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2477917671203613, "Value Loss": 0.4384523928165436, "_runtime": 6940.825747251511, "_timestamp": 1585576856.6703806, "_step": 72}
{"Episode reward": 38.4999999999994, "Episode length": 615, "Policy Loss": -1.330784797668457, "Value Loss": 17.319622039794922, "_runtime": 6942.171446800232, "_timestamp": 1585576858.0160801, "_step": 73}
{"Episode reward": 12.60000000000069, "Episode length": 874, "Policy Loss": -1.6669903993606567, "Value Loss": 12.294987678527832, "_runtime": 6943.250181674957, "_timestamp": 1585576859.094815, "_step": 74}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": -1.2432142496109009, "Value Loss": 14.882118225097656, "_runtime": 6944.787831068039, "_timestamp": 1585576860.6324644, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1854054927825928, "Value Loss": 0.1101476401090622, "_runtime": 6946.141382217407, "_timestamp": 1585576861.9860156, "_step": 76}
{"Episode reward": 12.60000000000069, "Episode length": 874, "Policy Loss": -1.8340164422988892, "Value Loss": 11.394157409667969, "_runtime": 6946.635810852051, "_timestamp": 1585576862.4804442, "_step": 77}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 0.9772031903266907, "Value Loss": 31.478797912597656, "_runtime": 6948.1879460811615, "_timestamp": 1585576864.0325794, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.20744252204895, "Value Loss": 0.3399040102958679, "_runtime": 6949.42179608345, "_timestamp": 1585576865.2664294, "_step": 79}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": -1.9110395908355713, "Value Loss": 12.648850440979004, "_runtime": 6950.910583257675, "_timestamp": 1585576866.7552166, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1122539043426514, "Value Loss": 0.23006026446819305, "_runtime": 6952.468818187714, "_timestamp": 1585576868.3134515, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2925961017608643, "Value Loss": 1.3130109310150146, "_runtime": 6954.008558273315, "_timestamp": 1585576869.8531916, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1619656085968018, "Value Loss": 0.9557235836982727, "_runtime": 6955.558141946793, "_timestamp": 1585576871.4027753, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.031402826309204, "Value Loss": 0.41285356879234314, "_runtime": 6956.106427192688, "_timestamp": 1585576871.9510605, "_step": 84}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": 0.3375357389450073, "Value Loss": 30.349201202392578, "_runtime": 6957.661072015762, "_timestamp": 1585576873.5057054, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8465631008148193, "Value Loss": 0.28691428899765015, "_runtime": 6959.218530654907, "_timestamp": 1585576875.063164, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.683859348297119, "Value Loss": 0.10063261538743973, "_runtime": 6960.436075925827, "_timestamp": 1585576876.2807093, "_step": 87}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": -1.2378168106079102, "Value Loss": 12.192794799804688, "_runtime": 6962.007692337036, "_timestamp": 1585576877.8523257, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5227904319763184, "Value Loss": 0.23608674108982086, "_runtime": 6963.601162910461, "_timestamp": 1585576879.4457963, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4735355377197266, "Value Loss": 0.28442689776420593, "_runtime": 6965.106935501099, "_timestamp": 1585576880.9515688, "_step": 90}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": -1.2365275621414185, "Value Loss": 10.333845138549805, "_runtime": 6966.084536075592, "_timestamp": 1585576881.9291694, "_step": 91}
{"Episode reward": 38.89999999999941, "Episode length": 611, "Policy Loss": -0.5196647644042969, "Value Loss": 16.696971893310547, "_runtime": 6967.644996643066, "_timestamp": 1585576883.48963, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.320378065109253, "Value Loss": 0.374729186296463, "_runtime": 6969.201800107956, "_timestamp": 1585576885.0464334, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3720180988311768, "Value Loss": 0.21307826042175293, "_runtime": 6970.73420381546, "_timestamp": 1585576886.5788372, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3575782775878906, "Value Loss": 0.08054149150848389, "_runtime": 6972.289643287659, "_timestamp": 1585576888.1342766, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.328357219696045, "Value Loss": 0.062212567776441574, "_runtime": 6973.831781864166, "_timestamp": 1585576889.6764152, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3593738079071045, "Value Loss": 0.14903172850608826, "_runtime": 6975.3871281147, "_timestamp": 1585576891.2317615, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.285158395767212, "Value Loss": 0.059628069400787354, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036, 0.0012316086795181036]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.0012316086795181036, 0.011635584756731987, 0.02450277842581272, 0.037369973957538605, 0.05023716762661934, 0.06310436129570007, 0.07597155123949051, 0.08883874118328094, 0.10170593857765198, 0.11457313597202301, 0.12744033336639404, 0.14030751585960388, 0.15317471325397491, 0.16604191064834595, 0.1789090931415558, 0.19177629053592682, 0.20464348793029785, 0.21751068532466888, 0.23037788271903992, 0.24324506521224976, 0.256112277507782, 0.2689794600009918, 0.28184664249420166, 0.2947138547897339, 0.3075810372829437, 0.32044821977615356, 0.3333154320716858, 0.34618261456489563, 0.35904979705810547, 0.3719170093536377, 0.38478419184684753, 0.39765140414237976, 0.4105185866355896, 0.42338576912879944, 0.43625298142433167, 0.4491201639175415, 0.46198737621307373, 0.47485455870628357, 0.4877217411994934, 0.5005889534950256, 0.5134561657905579, 0.5263233184814453, 0.5391905307769775, 0.5520577430725098, 0.5649248957633972, 0.5777921080589294, 0.5906593203544617, 0.6035264730453491, 0.6163936853408813, 0.6292608976364136, 0.642128050327301, 0.6549952626228333, 0.6678624749183655, 0.6807296276092529, 0.6935968399047852, 0.7064640522003174, 0.7193312048912048, 0.7321984171867371, 0.7450656294822693, 0.7579328417778015, 0.770799994468689, 0.7836672067642212, 0.7965344190597534, 0.8094015717506409, 0.8222687840461731]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [0.0, 0.00018436124082654715, 0.0003687224816530943, 0.0005530837224796414, 0.0007374449633061886, 0.0009218062041327357, 0.0011061674449592829, 0.00129052868578583, 0.0014748899266123772, 0.0016592511674389243, 0.0018436124082654715, 0.0020279735326766968, 0.0022123348899185658, 0.0023966962471604347, 0.00258105737157166, 0.0027654184959828854, 0.0029497798532247543, 0.0031341412104666233, 0.0033185023348778486, 0.003502863459289074, 0.003687224816530943, 0.003871586173772812, 0.0040559470653533936, 0.0042403084225952625, 0.0044246697798371315, 0.0046090311370790005, 0.0047933924943208694, 0.004977753385901451, 0.00516211474314332, 0.005346476100385189, 0.005530836991965771, 0.00571519834920764, 0.005899559706449509, 0.006083921063691378, 0.006268282420933247, 0.006452643312513828, 0.006637004669755697, 0.006821366026997566, 0.007005726918578148, 0.007190088275820017, 0.007374449633061886, 0.007558810990303755, 0.007743172347545624, 0.007927533239126205, 0.008111894130706787, 0.008296255953609943, 0.008480616845190525, 0.008664978668093681, 0.008849339559674263, 0.009033700451254845, 0.009218062274158001, 0.009402423165738583, 0.009586784988641739, 0.00977114588022232, 0.009955506771802902, 0.010139868594706059, 0.01032422948628664, 0.010508590377867222, 0.010692952200770378, 0.01087731309235096, 0.011061673983931541, 0.011246035806834698, 0.01143039669841528, 0.011614758521318436, 0.011799119412899017]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [36.0, 0.0, 0.0, 72.0, 54.0, 224.0, 9.0, 13.0, 2.0, 0.0, 12.0, 10.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 4.0, 1.0, 3.0, 6.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0], "bins": [-0.011724178679287434, -0.009595725685358047, -0.007467273622751236, -0.005338821094483137, -0.0032103685662150383, -0.0010819165036082268, 0.0010465364903211594, 0.0031749894842505455, 0.005303441546857357, 0.0074318936094641685, 0.00956034567207098, 0.01168879959732294, 0.013817251659929752, 0.01594570279121399, 0.0180741585791111, 0.02020261064171791, 0.022331062704324722, 0.024459514766931534, 0.026587966829538345, 0.028716418892145157, 0.03084487095475197, 0.03297332674264908, 0.03510177880525589, 0.0372302308678627, 0.03935868293046951, 0.041487134993076324, 0.043615587055683136, 0.04574403911828995, 0.04787249490618706, 0.05000094696879387, 0.05212939903140068, 0.05425785109400749, 0.056386303156614304, 0.058514755219221115, 0.06064320728182793, 0.06277165561914444, 0.06490010768175125, 0.06702855974435806, 0.06915701180696487, 0.07128546386957169, 0.0734139159321785, 0.0755423754453659, 0.07767082750797272, 0.07979927957057953, 0.08192773163318634, 0.08405618369579315, 0.08618463575839996, 0.08831308782100677, 0.09044153988361359, 0.0925699919462204, 0.09469844400882721, 0.09682689607143402, 0.09895534813404083, 0.10108380019664764, 0.10321225225925446, 0.10534070432186127, 0.10746916383504868, 0.10959761589765549, 0.1117260679602623, 0.11385452002286911, 0.11598297208547592, 0.11811142414808273, 0.12023987621068954, 0.12236832827329636, 0.12449678033590317]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0], "bins": [-0.12676769495010376, -0.11984408646821976, -0.11292048543691635, -0.10599687695503235, -0.09907327592372894, -0.09214966744184494, -0.08522605895996094, -0.07830245792865753, -0.07137885689735413, -0.06445524841547012, -0.05753163993358612, -0.050608038902282715, -0.04368443042039871, -0.036760829389095306, -0.029837220907211304, -0.022913619875907898, -0.015990011394023895, -0.009066402912139893, -0.002142801880836487, 0.004780799150466919, 0.011704415082931519, 0.018628016114234924, 0.02555161714553833, 0.032475218176841736, 0.039398834109306335, 0.04632243514060974, 0.05324603617191315, 0.06016965210437775, 0.06709325313568115, 0.07401685416698456, 0.08094045519828796, 0.08786407113075256, 0.09478767216205597, 0.10171127319335938, 0.10863488912582397, 0.11555849015712738, 0.12248209118843079, 0.12940570712089539, 0.1363292932510376, 0.1432529091835022, 0.1501765251159668, 0.157100111246109, 0.1640237271785736, 0.1709473431110382, 0.17787092924118042, 0.18479454517364502, 0.19171813130378723, 0.19864174723625183, 0.20556536316871643, 0.21248894929885864, 0.21941256523132324, 0.22633618116378784, 0.23325976729393005, 0.24018338322639465, 0.24710699915885925, 0.25403058528900146, 0.26095420122146606, 0.26787781715393066, 0.2748014032840729, 0.2817250192165375, 0.2886486053466797, 0.2955722212791443, 0.3024958372116089, 0.3094194233417511, 0.3163430392742157]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 20.0, 16.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02930377423763275, -0.027973435819149017, -0.026643099263310432, -0.0253127608448267, -0.023982424288988113, -0.02265208587050438, -0.021321747452020645, -0.01999141089618206, -0.018661074340343475, -0.01733073592185974, -0.016000397503376007, -0.014670060947537422, -0.013339722529053688, -0.012009385973215103, -0.010679047554731369, -0.009348710998892784, -0.00801837258040905, -0.006688034161925316, -0.005357697606086731, -0.004027359187602997, -0.002697022631764412, -0.0013666842132806778, -3.6347657442092896e-05, 0.0012939907610416412, 0.0026243291795253754, 0.0039546675980091095, 0.005285002291202545, 0.006615340709686279, 0.007945679128170013, 0.009276017546653748, 0.010606352239847183, 0.011936690658330917, 0.013267029076814651, 0.014597367495298386, 0.01592770591378212, 0.017258040606975555, 0.01858837902545929, 0.019918717443943024, 0.021249055862426758, 0.022579390555620193, 0.023909728974103928, 0.025240067392587662, 0.026570405811071396, 0.02790074422955513, 0.029231078922748566, 0.0305614173412323, 0.031891755759716034, 0.03322209417819977, 0.0345524325966835, 0.035882771015167236, 0.03721310943365097, 0.03854344040155411, 0.03987377882003784, 0.041204117238521576, 0.04253445565700531, 0.043864794075489044, 0.04519513249397278, 0.04652547091245651, 0.04785580933094025, 0.04918614774942398, 0.05051647871732712, 0.05184681713581085, 0.053177155554294586, 0.05450749397277832, 0.055837832391262054]}, "_runtime": 6976.957818984985, "_timestamp": 1585576892.8024523, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.237774610519409, "Value Loss": 0.04469149187207222, "_runtime": 6978.520672082901, "_timestamp": 1585576894.3653054, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2412683963775635, "Value Loss": 0.11992379277944565, "_runtime": 6980.082454204559, "_timestamp": 1585576895.9270875, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.200521469116211, "Value Loss": 0.10039083659648895, "_runtime": 6981.642824649811, "_timestamp": 1585576897.487458, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1434004306793213, "Value Loss": 0.10554997622966766, "_runtime": 6983.195119142532, "_timestamp": 1585576899.0397525, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.071645736694336, "Value Loss": 0.06873111426830292, "_runtime": 6984.053226470947, "_timestamp": 1585576899.8978598, "_step": 103}
{"Episode reward": 46.79999999999952, "Episode length": 532, "Policy Loss": -0.11447462439537048, "Value Loss": 18.326583862304688, "_runtime": 6985.623769521713, "_timestamp": 1585576901.4684029, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0481367111206055, "Value Loss": 0.3719911277294159, "_runtime": 6987.230015516281, "_timestamp": 1585576903.0746489, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9292199611663818, "Value Loss": 0.061094388365745544, "_runtime": 6988.75017118454, "_timestamp": 1585576904.5948045, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8726398944854736, "Value Loss": 0.07909879088401794, "_runtime": 6990.301095962524, "_timestamp": 1585576906.1457293, "_step": 107}
{"Episode reward": -99.8430664062486, "Episode length": 999, "Policy Loss": -1.901190161705017, "Value Loss": 0.2778001129627228, "_runtime": 6991.855416297913, "_timestamp": 1585576907.7000496, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.728053331375122, "Value Loss": 0.035866666585206985, "_runtime": 6992.957105875015, "_timestamp": 1585576908.8017392, "_step": 109}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": -0.021974163129925728, "Value Loss": 13.962095260620117, "_runtime": 6994.520308971405, "_timestamp": 1585576910.3649423, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5916529893875122, "Value Loss": 0.06856028735637665, "_runtime": 6995.8389637470245, "_timestamp": 1585576911.683597, "_step": 111}
{"Episode reward": 15.300000000000537, "Episode length": 847, "Policy Loss": -0.2960723340511322, "Value Loss": 11.588027954101562, "_runtime": 6997.361820459366, "_timestamp": 1585576913.2064538, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.548407793045044, "Value Loss": 0.045966099947690964, "_runtime": 6998.562347412109, "_timestamp": 1585576914.4069808, "_step": 113}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": -0.06644761562347412, "Value Loss": 12.883830070495605, "_runtime": 7000.118726491928, "_timestamp": 1585576915.9633598, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4969829320907593, "Value Loss": 0.08534152060747147, "_runtime": 7000.878704547882, "_timestamp": 1585576916.723338, "_step": 115}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.7704728841781616, "Value Loss": 20.77656364440918, "_runtime": 7001.549542427063, "_timestamp": 1585576917.3941758, "_step": 116}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 1.139917254447937, "Value Loss": 23.107913970947266, "_runtime": 7003.1030423641205, "_timestamp": 1585576918.9476757, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.579158902168274, "Value Loss": 0.11565244942903519, "_runtime": 7004.619899511337, "_timestamp": 1585576920.4645329, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5563032627105713, "Value Loss": 0.02426953800022602, "_runtime": 7006.114684343338, "_timestamp": 1585576921.9593177, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.558854341506958, "Value Loss": 0.02499927394092083, "_runtime": 7007.654804468155, "_timestamp": 1585576923.4994378, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6096588373184204, "Value Loss": 0.14810889959335327, "_runtime": 7009.20233130455, "_timestamp": 1585576925.0469646, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5733208656311035, "Value Loss": 0.07453902810811996, "_runtime": 7010.792714834213, "_timestamp": 1585576926.6373482, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5385667085647583, "Value Loss": 0.04052197188138962, "_runtime": 7012.358190536499, "_timestamp": 1585576928.2028239, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5118076801300049, "Value Loss": 0.02316628023982048, "_runtime": 7013.923296451569, "_timestamp": 1585576929.7679298, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.493419885635376, "Value Loss": 0.049314986914396286, "_runtime": 7014.64287686348, "_timestamp": 1585576930.4875102, "_step": 125}
{"Episode reward": 55.499999999999645, "Episode length": 445, "Policy Loss": 0.8165656924247742, "Value Loss": 21.822988510131836, "_runtime": 7016.151887893677, "_timestamp": 1585576931.9965212, "_step": 126}
{"Episode reward": 2.992416000367456, "Episode length": 971, "Policy Loss": -0.35406091809272766, "Value Loss": 10.079127311706543, "_runtime": 7016.910503149033, "_timestamp": 1585576932.7551365, "_step": 127}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.763471245765686, "Value Loss": 20.511674880981445, "_runtime": 7018.420611381531, "_timestamp": 1585576934.2652447, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4149408340454102, "Value Loss": 0.03179424628615379, "_runtime": 7019.984363555908, "_timestamp": 1585576935.828997, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.414468765258789, "Value Loss": 0.035032693296670914, "_runtime": 7020.893198251724, "_timestamp": 1585576936.7378316, "_step": 130}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": 0.33863142132759094, "Value Loss": 16.336719512939453, "_runtime": 7022.438945055008, "_timestamp": 1585576938.2835784, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3700790405273438, "Value Loss": 0.021685900166630745, "_runtime": 7023.567826271057, "_timestamp": 1585576939.4124596, "_step": 132}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.06828110665082932, "Value Loss": 13.425517082214355, "_runtime": 7024.935746908188, "_timestamp": 1585576940.7803802, "_step": 133}
{"Episode reward": 9.400000000000873, "Episode length": 906, "Policy Loss": -0.2255530059337616, "Value Loss": 10.66614055633545, "_runtime": 7026.4961373806, "_timestamp": 1585576942.3407707, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3547537326812744, "Value Loss": 0.08063459396362305, "_runtime": 7028.031256437302, "_timestamp": 1585576943.8758898, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.363454818725586, "Value Loss": 0.051156457513570786, "_runtime": 7029.577744483948, "_timestamp": 1585576945.4223778, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3279348611831665, "Value Loss": 0.03080371394753456, "_runtime": 7031.1307718753815, "_timestamp": 1585576946.9754052, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.336581826210022, "Value Loss": 0.04307961091399193, "_runtime": 7032.690484523773, "_timestamp": 1585576948.5351179, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3157424926757812, "Value Loss": 0.0216379351913929, "_runtime": 7033.835188627243, "_timestamp": 1585576949.679822, "_step": 139}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": 0.28819212317466736, "Value Loss": 13.696603775024414, "_runtime": 7035.054898023605, "_timestamp": 1585576950.8995314, "_step": 140}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.014548679813742638, "Value Loss": 12.492239952087402, "_runtime": 7036.616360664368, "_timestamp": 1585576952.460994, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2832659482955933, "Value Loss": 0.019727153703570366, "_runtime": 7038.140208244324, "_timestamp": 1585576953.9848416, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2739596366882324, "Value Loss": 0.01753934472799301, "_runtime": 7039.6772611141205, "_timestamp": 1585576955.5218945, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2658823728561401, "Value Loss": 0.03196793049573898, "_runtime": 7041.133188247681, "_timestamp": 1585576956.9778216, "_step": 144}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": -0.14921361207962036, "Value Loss": 10.374842643737793, "_runtime": 7042.685814857483, "_timestamp": 1585576958.5304482, "_step": 145}
{"Episode reward": -99.80171241760114, "Episode length": 999, "Policy Loss": -1.2380852699279785, "Value Loss": 0.03227419778704643, "_runtime": 7044.249279499054, "_timestamp": 1585576960.0939128, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2052890062332153, "Value Loss": 0.030485035851597786, "_runtime": 7045.808879375458, "_timestamp": 1585576961.6535127, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2026597261428833, "Value Loss": 0.04441649466753006, "_runtime": 7047.361257314682, "_timestamp": 1585576963.2058907, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1522866487503052, "Value Loss": 0.019145367667078972, "_runtime": 7048.928785562515, "_timestamp": 1585576964.773419, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1237274408340454, "Value Loss": 0.013138965703547001, "_runtime": 7050.487614393234, "_timestamp": 1585576966.3322477, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0978822708129883, "Value Loss": 0.015414789319038391, "_runtime": 7051.383509874344, "_timestamp": 1585576967.2281432, "_step": 151}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.7589364647865295, "Value Loss": 17.123443603515625, "_runtime": 7052.574500083923, "_timestamp": 1585576968.4191334, "_step": 152}
{"Episode reward": 23.200000000000088, "Episode length": 768, "Policy Loss": 0.5989283919334412, "Value Loss": 12.657361030578613, "_runtime": 7053.544982433319, "_timestamp": 1585576969.3896158, "_step": 153}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.6447277069091797, "Value Loss": 15.568535804748535, "_runtime": 7054.690502643585, "_timestamp": 1585576970.535136, "_step": 154}
{"Episode reward": 25.09999999999998, "Episode length": 749, "Policy Loss": 0.2741527259349823, "Value Loss": 12.920856475830078, "_runtime": 7056.26062130928, "_timestamp": 1585576972.1052547, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0826561450958252, "Value Loss": 0.05935249105095863, "_runtime": 7057.164946317673, "_timestamp": 1585576973.0095797, "_step": 156}
{"Episode reward": 41.499999999999446, "Episode length": 585, "Policy Loss": 0.646824061870575, "Value Loss": 16.490947723388672, "_runtime": 7058.689782381058, "_timestamp": 1585576974.5344157, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0779393911361694, "Value Loss": 0.012702119536697865, "_runtime": 7059.0788905620575, "_timestamp": 1585576974.923524, "_step": 158}
{"Episode reward": 78.39999999999998, "Episode length": 216, "Policy Loss": 3.593426465988159, "Value Loss": 44.52357482910156, "_runtime": 7060.342215538025, "_timestamp": 1585576976.1868489, "_step": 159}
{"Episode reward": 17.00000000000044, "Episode length": 830, "Policy Loss": 0.115790456533432, "Value Loss": 11.423810005187988, "_runtime": 7061.883251190186, "_timestamp": 1585576977.7278845, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1501396894454956, "Value Loss": 0.02242482826113701, "_runtime": 7062.809816122055, "_timestamp": 1585576978.6544495, "_step": 161}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.4942348897457123, "Value Loss": 15.358506202697754, "_runtime": 7064.325611114502, "_timestamp": 1585576980.1702445, "_step": 162}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": -0.1650724858045578, "Value Loss": 9.700766563415527, "_runtime": 7064.716428518295, "_timestamp": 1585576980.5610619, "_step": 163}
{"Episode reward": 78.19999999999996, "Episode length": 218, "Policy Loss": 3.4874801635742188, "Value Loss": 43.32722091674805, "_runtime": 7065.646876335144, "_timestamp": 1585576981.4915097, "_step": 164}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 0.35885754227638245, "Value Loss": 15.447049140930176, "_runtime": 7067.190849781036, "_timestamp": 1585576983.0354831, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2906430959701538, "Value Loss": 0.045649316161870956, "_runtime": 7068.43283200264, "_timestamp": 1585576984.2774653, "_step": 166}
{"Episode reward": 15.300000000000537, "Episode length": 847, "Policy Loss": -0.08698271214962006, "Value Loss": 11.232014656066895, "_runtime": 7069.511288166046, "_timestamp": 1585576985.3559215, "_step": 167}
{"Episode reward": 28.899999999999764, "Episode length": 711, "Policy Loss": -0.051556915044784546, "Value Loss": 13.940360069274902, "_runtime": 7071.0576775074005, "_timestamp": 1585576986.9023108, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4099663496017456, "Value Loss": 0.053802985697984695, "_runtime": 7071.800622701645, "_timestamp": 1585576987.645256, "_step": 169}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": 0.5935558080673218, "Value Loss": 20.5670166015625, "_runtime": 7073.321474313736, "_timestamp": 1585576989.1661077, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3990048170089722, "Value Loss": 0.10955188423395157, "_runtime": 7074.4486565589905, "_timestamp": 1585576990.29329, "_step": 171}
{"Episode reward": 28.199999999999804, "Episode length": 718, "Policy Loss": -0.048995062708854675, "Value Loss": 13.687602043151855, "_runtime": 7075.954083442688, "_timestamp": 1585576991.7987168, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3064929246902466, "Value Loss": 0.10876687616109848, "_runtime": 7077.496660709381, "_timestamp": 1585576993.341294, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3269957304000854, "Value Loss": 0.046267133206129074, "_runtime": 7079.031710386276, "_timestamp": 1585576994.8763437, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3003168106079102, "Value Loss": 0.07543858140707016, "_runtime": 7079.537970066071, "_timestamp": 1585576995.3826034, "_step": 175}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 2.0833444595336914, "Value Loss": 31.050695419311523, "_runtime": 7081.1198554039, "_timestamp": 1585576996.9644887, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3061740398406982, "Value Loss": 0.1441812515258789, "_runtime": 7082.68737578392, "_timestamp": 1585576998.5320091, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2692726850509644, "Value Loss": 0.025892751291394234, "_runtime": 7084.0659263134, "_timestamp": 1585576999.9105597, "_step": 178}
{"Episode reward": 7.8000000000009635, "Episode length": 922, "Policy Loss": 0.1790159046649933, "Value Loss": 10.236289978027344, "_runtime": 7084.95988535881, "_timestamp": 1585577000.8045187, "_step": 179}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 0.5416103005409241, "Value Loss": 17.231857299804688, "_runtime": 7086.419106721878, "_timestamp": 1585577002.26374, "_step": 180}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": -0.16850054264068604, "Value Loss": 10.354692459106445, "_runtime": 7087.960638046265, "_timestamp": 1585577003.8052714, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2168312072753906, "Value Loss": 0.05942867323756218, "_runtime": 7089.483397483826, "_timestamp": 1585577005.3280308, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1898887157440186, "Value Loss": 0.020966125652194023, "_runtime": 7091.031554937363, "_timestamp": 1585577006.8761883, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2063120603561401, "Value Loss": 0.22826093435287476, "_runtime": 7092.03400850296, "_timestamp": 1585577007.8786418, "_step": 184}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.46622970700263977, "Value Loss": 14.925023078918457, "_runtime": 7092.958461761475, "_timestamp": 1585577008.803095, "_step": 185}
{"Episode reward": 41.29999999999944, "Episode length": 587, "Policy Loss": 0.6522369980812073, "Value Loss": 16.482704162597656, "_runtime": 7094.511944055557, "_timestamp": 1585577010.3565774, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1113572120666504, "Value Loss": 0.021168792620301247, "_runtime": 7095.629223108292, "_timestamp": 1585577011.4738564, "_step": 187}
{"Episode reward": 27.699999999999832, "Episode length": 723, "Policy Loss": 0.3058375120162964, "Value Loss": 13.274336814880371, "_runtime": 7097.1504447460175, "_timestamp": 1585577012.995078, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1029607057571411, "Value Loss": 0.024681217968463898, "_runtime": 7098.705420017242, "_timestamp": 1585577014.5500534, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1060205698013306, "Value Loss": 0.01801704801619053, "_runtime": 7100.2338445186615, "_timestamp": 1585577016.0784779, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1055443286895752, "Value Loss": 0.06743121892213821, "_runtime": 7101.792373180389, "_timestamp": 1585577017.6370065, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.144094705581665, "Value Loss": 0.16788749396800995, "_runtime": 7103.402836561203, "_timestamp": 1585577019.24747, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0943742990493774, "Value Loss": 0.05018778517842293, "_runtime": 7104.9612855911255, "_timestamp": 1585577020.805919, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0817203521728516, "Value Loss": 0.014868597500026226, "_runtime": 7106.517803668976, "_timestamp": 1585577022.362437, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.063881754875183, "Value Loss": 0.020435122773051262, "_runtime": 7108.081296443939, "_timestamp": 1585577023.9259298, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1079086065292358, "Value Loss": 0.2568126320838928, "_runtime": 7108.751300573349, "_timestamp": 1585577024.595934, "_step": 196}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.6347562074661255, "Value Loss": 23.342683792114258, "_runtime": 7110.304802894592, "_timestamp": 1585577026.1494362, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0225754976272583, "Value Loss": 0.02459103614091873, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805, 0.006245192140340805]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.006245192140340805, 0.05084759369492531, 0.10794037580490112, 0.16503316164016724, 0.22212594747543335, 0.27921873331069946, 0.3363115191459656, 0.3934043049812317, 0.4504970908164978, 0.5075898766517639, 0.56468266248703, 0.6217754483222961, 0.6788682341575623, 0.7359610199928284, 0.7930538058280945, 0.8501465916633606, 0.9072393774986267, 0.9643321633338928, 1.0214250087738037, 1.0785177946090698, 1.135610580444336, 1.192703366279602, 1.2497961521148682, 1.3068889379501343, 1.3639817237854004, 1.4210745096206665, 1.4781672954559326, 1.5352600812911987, 1.5923528671264648, 1.649445652961731, 1.706538438796997, 1.7636312246322632, 1.8207240104675293, 1.8778167963027954, 1.9349095821380615, 1.9920023679733276, 2.0490951538085938, 2.1061878204345703, 2.163280725479126, 2.2203736305236816, 2.277466297149658, 2.3345589637756348, 2.3916518688201904, 2.448744773864746, 2.5058374404907227, 2.562930107116699, 2.620023012161255, 2.6771159172058105, 2.734208583831787, 2.7913012504577637, 2.8483941555023193, 2.905487060546875, 2.9625797271728516, 3.019672393798828, 3.076765298843384, 3.1338582038879395, 3.190950870513916, 3.2480435371398926, 3.3051364421844482, 3.362229347229004, 3.4193220138549805, 3.476414680480957, 3.5335075855255127, 3.5906004905700684, 3.647693157196045]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [0.0, 0.000636134878732264, 0.001272269757464528, 0.0019084046361967921, 0.002544539514929056, 0.0031806742772459984, 0.0038168092723935843, 0.00445294426754117, 0.005089079029858112, 0.0057252137921750546, 0.006361348554491997, 0.006997483782470226, 0.0076336185447871685, 0.00826975330710411, 0.00890588853508234, 0.009542022831737995, 0.010178158059716225, 0.010814293287694454, 0.011450427584350109, 0.012086562812328339, 0.012722697108983994, 0.013358832336962223, 0.013994967564940453, 0.014631101861596107, 0.015267237089574337, 0.015903372317552567, 0.01653950661420822, 0.017175640910863876, 0.01781177707016468, 0.018447911366820335, 0.01908404566347599, 0.019720181822776794, 0.02035631611943245, 0.020992450416088104, 0.02162858657538891, 0.022264720872044563, 0.022900855168700218, 0.023536991328001022, 0.024173125624656677, 0.024809259921312332, 0.025445394217967987, 0.02608153037726879, 0.026717664673924446, 0.0273537989705801, 0.027989935129880905, 0.02862606942653656, 0.029262203723192215, 0.02989833988249302, 0.030534474179148674, 0.03117060847580433, 0.03180674463510513, 0.03244287893176079, 0.03307901322841644, 0.0337151475250721, 0.03435128182172775, 0.034987419843673706, 0.03562355414032936, 0.036259688436985016, 0.03689582273364067, 0.037531957030296326, 0.03816809132695198, 0.038804229348897934, 0.03944036364555359, 0.040076497942209244, 0.0407126322388649]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [32.0, 0.0, 0.0, 33.0, 275.0, 31.0, 20.0, 7.0, 5.0, 9.0, 7.0, 11.0, 8.0, 4.0, 3.0, 1.0, 1.0, 2.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 3.0, 8.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0], "bins": [-0.04399871453642845, -0.03476710617542267, -0.025535495951771736, -0.016303885728120804, -0.007072277367115021, 0.0021593309938907623, 0.011390943080186844, 0.02062254771590233, 0.02985415980219841, 0.03908577188849449, 0.048317376524209976, 0.05754898861050606, 0.06678059697151184, 0.07601220905780792, 0.08524380624294281, 0.09447541832923889, 0.10370703041553497, 0.11293864250183105, 0.12217025458812714, 0.13140185177326202, 0.1406334638595581, 0.1498650759458542, 0.15909668803215027, 0.16832830011844635, 0.17755991220474243, 0.18679150938987732, 0.1960231214761734, 0.20525473356246948, 0.21448633074760437, 0.22371795773506165, 0.23294955492019653, 0.2421811819076538, 0.2514127790927887, 0.2606443762779236, 0.26987600326538086, 0.27910760045051575, 0.288339227437973, 0.2975708246231079, 0.3068024218082428, 0.3160340487957001, 0.32526564598083496, 0.33449727296829224, 0.3437288701534271, 0.352960467338562, 0.3621920943260193, 0.3714236915111542, 0.38065531849861145, 0.38988691568374634, 0.3991185426712036, 0.4083501398563385, 0.4175817370414734, 0.42681336402893066, 0.43604496121406555, 0.4452765882015228, 0.4545081853866577, 0.463739812374115, 0.4729713797569275, 0.48220300674438477, 0.49143463373184204, 0.5006662011146545, 0.5098978281021118, 0.5191294550895691, 0.5283610820770264, 0.5375926494598389, 0.5468242764472961]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 5.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 0.0, 1.0], "bins": [-0.5881636738777161, -0.5601226687431335, -0.5320817232131958, -0.5040407180786133, -0.47599977254867554, -0.447958767414093, -0.4199177920818329, -0.39187681674957275, -0.3638358414173126, -0.3357948660850525, -0.30775389075279236, -0.2797129154205322, -0.2516719102859497, -0.22363093495368958, -0.19558995962142944, -0.1675489842891693, -0.13950800895690918, -0.11146703362464905, -0.08342605829238892, -0.055385053157806396, -0.027344107627868652, 0.0006968975067138672, 0.02873784303665161, 0.05677884817123413, 0.08481985330581665, 0.1128607988357544, 0.14090180397033691, 0.16894274950027466, 0.19698375463485718, 0.22502470016479492, 0.25306570529937744, 0.2811066508293152, 0.3091476559638977, 0.3371886610984802, 0.36522960662841797, 0.3932706117630005, 0.42131155729293823, 0.44935256242752075, 0.47739356756210327, 0.5054344534873962, 0.5334754586219788, 0.5615164637565613, 0.5895574688911438, 0.6175984740257263, 0.6456393599510193, 0.6736803650856018, 0.7017213702201843, 0.7297623753547668, 0.7578033804893494, 0.7858442664146423, 0.8138852715492249, 0.8419262766838074, 0.8699672818183899, 0.8980081677436829, 0.9260491728782654, 0.9540901780128479, 0.9821311831474304, 1.0101721286773682, 1.0382130146026611, 1.0662541389465332, 1.0942950248718262, 1.1223361492156982, 1.1503770351409912, 1.1784179210662842, 1.2064590454101562]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 6.0, 4.0, 0.0, 2.0, 0.0, 2.0, 6.0, 4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0], "bins": [-0.6229674220085144, -0.6089910268783569, -0.5950146317481995, -0.5810381770133972, -0.5670617818832397, -0.5530853867530823, -0.5391089916229248, -0.5251325964927673, -0.5111561417579651, -0.4971797466278076, -0.48320335149765015, -0.4692269563674927, -0.4552505314350128, -0.44127410650253296, -0.4272977113723755, -0.413321316242218, -0.39934492111206055, -0.3853684961795807, -0.3713921010494232, -0.35741567611694336, -0.3434392809867859, -0.32946285605430603, -0.31548646092414856, -0.3015100657939911, -0.28753364086151123, -0.27355724573135376, -0.2595808207988739, -0.24560442566871643, -0.23162803053855896, -0.2176516056060791, -0.20367521047592163, -0.18969878554344177, -0.1757223904132843, -0.16174599528312683, -0.14776957035064697, -0.1337931752204895, -0.11981678009033203, -0.10584032535552979, -0.09186393022537231, -0.07788753509521484, -0.06391113996505737, -0.0499347448348999, -0.035958290100097656, -0.021981894969940186, -0.008005499839782715, 0.005970895290374756, 0.019947290420532227, 0.03392374515533447, 0.04790014028549194, 0.061876535415649414, 0.07585293054580688, 0.08982932567596436, 0.1038057804107666, 0.11778217554092407, 0.13175857067108154, 0.145734965801239, 0.15971136093139648, 0.17368781566619873, 0.1876642107963562, 0.20164060592651367, 0.21561700105667114, 0.2295933961868286, 0.24356985092163086, 0.25754624605178833, 0.2715226411819458]}, "_runtime": 7111.504199028015, "_timestamp": 1585577027.3488324, "_step": 198}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.3084319531917572, "Value Loss": 12.469961166381836, "_runtime": 7113.0117926597595, "_timestamp": 1585577028.856426, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0435324907302856, "Value Loss": 0.06802813708782196, "_runtime": 7114.579685211182, "_timestamp": 1585577030.4243186, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.029188632965088, "Value Loss": 0.02571853995323181, "_runtime": 7116.127412080765, "_timestamp": 1585577031.9720454, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0272490978240967, "Value Loss": 0.07090375572443008, "_runtime": 7117.3192710876465, "_timestamp": 1585577033.1639044, "_step": 202}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": 0.23299357295036316, "Value Loss": 12.691801071166992, "_runtime": 7118.608348846436, "_timestamp": 1585577034.4529822, "_step": 203}
{"Episode reward": 17.100000000000435, "Episode length": 829, "Policy Loss": 0.2108137309551239, "Value Loss": 11.460036277770996, "_runtime": 7120.1752071380615, "_timestamp": 1585577036.0198405, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9864607453346252, "Value Loss": 0.009011074900627136, "_runtime": 7121.710055112839, "_timestamp": 1585577037.5546885, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.976690411567688, "Value Loss": 0.009618508629500866, "_runtime": 7123.254757165909, "_timestamp": 1585577039.0993905, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9639796018600464, "Value Loss": 0.009768267162144184, "_runtime": 7124.459612369537, "_timestamp": 1585577040.3042457, "_step": 207}
{"Episode reward": 24.100000000000037, "Episode length": 759, "Policy Loss": 0.33683666586875916, "Value Loss": 12.758867263793945, "_runtime": 7126.015072822571, "_timestamp": 1585577041.8597062, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.927970826625824, "Value Loss": 0.01766088232398033, "_runtime": 7126.94463467598, "_timestamp": 1585577042.789268, "_step": 209}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 1.2600221633911133, "Value Loss": 16.75375747680664, "_runtime": 7127.534317970276, "_timestamp": 1585577043.3789513, "_step": 210}
{"Episode reward": 63.59999999999976, "Episode length": 364, "Policy Loss": 2.1542904376983643, "Value Loss": 25.75109100341797, "_runtime": 7129.078491449356, "_timestamp": 1585577044.9231248, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9454570412635803, "Value Loss": 0.046447135508060455, "_runtime": 7130.285232782364, "_timestamp": 1585577046.1298661, "_step": 212}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 0.313480019569397, "Value Loss": 12.178140640258789, "_runtime": 7131.777184724808, "_timestamp": 1585577047.621818, "_step": 213}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": 0.05607097968459129, "Value Loss": 9.57762622833252, "_runtime": 7133.328625679016, "_timestamp": 1585577049.173259, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9505634307861328, "Value Loss": 0.009503224864602089, "_runtime": 7134.86355304718, "_timestamp": 1585577050.7081864, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9558554291725159, "Value Loss": 0.009670254774391651, "_runtime": 7136.410006046295, "_timestamp": 1585577052.2546394, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9623458385467529, "Value Loss": 0.011334789916872978, "_runtime": 7137.968628883362, "_timestamp": 1585577053.8132622, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9538270235061646, "Value Loss": 0.011598968878388405, "_runtime": 7139.325507879257, "_timestamp": 1585577055.1701412, "_step": 218}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": 0.12243548780679703, "Value Loss": 11.141767501831055, "_runtime": 7140.871332168579, "_timestamp": 1585577056.7159655, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9366067051887512, "Value Loss": 0.010108942165970802, "_runtime": 7142.334158658981, "_timestamp": 1585577058.178792, "_step": 220}
{"Episode reward": 6.300000000001049, "Episode length": 937, "Policy Loss": 0.1236824244260788, "Value Loss": 10.368559837341309, "_runtime": 7143.20037150383, "_timestamp": 1585577059.0450048, "_step": 221}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": 1.2056641578674316, "Value Loss": 17.591569900512695, "_runtime": 7144.3231744766235, "_timestamp": 1585577060.1678078, "_step": 222}
{"Episode reward": 28.299999999999798, "Episode length": 717, "Policy Loss": 0.5295336246490479, "Value Loss": 13.262042999267578, "_runtime": 7145.883580207825, "_timestamp": 1585577061.7282135, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8942193984985352, "Value Loss": 0.015251634642481804, "_runtime": 7147.419969320297, "_timestamp": 1585577063.2646027, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8814536333084106, "Value Loss": 0.014714334160089493, "_runtime": 7148.953038930893, "_timestamp": 1585577064.7976723, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8814237713813782, "Value Loss": 0.017408642917871475, "_runtime": 7150.542713880539, "_timestamp": 1585577066.3873472, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8745244741439819, "Value Loss": 0.016302725300192833, "_runtime": 7152.100779056549, "_timestamp": 1585577067.9454124, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8686894178390503, "Value Loss": 0.014879800379276276, "_runtime": 7153.661826848984, "_timestamp": 1585577069.5064602, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8563910722732544, "Value Loss": 0.02700074389576912, "_runtime": 7154.785087585449, "_timestamp": 1585577070.629721, "_step": 229}
{"Episode reward": 28.59999999999978, "Episode length": 714, "Policy Loss": 0.5787367224693298, "Value Loss": 13.147464752197266, "_runtime": 7156.347317934036, "_timestamp": 1585577072.1919513, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8358721137046814, "Value Loss": 0.013078567571938038, "_runtime": 7156.971314191818, "_timestamp": 1585577072.8159475, "_step": 231}
{"Episode reward": 61.899999999999736, "Episode length": 381, "Policy Loss": 1.9149882793426514, "Value Loss": 24.779830932617188, "_runtime": 7157.332554578781, "_timestamp": 1585577073.177188, "_step": 232}
{"Episode reward": 78.29999999999997, "Episode length": 217, "Policy Loss": 4.303436279296875, "Value Loss": 43.77911376953125, "_runtime": 7158.668907165527, "_timestamp": 1585577074.5135405, "_step": 233}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": 0.33821582794189453, "Value Loss": 11.190391540527344, "_runtime": 7160.161694288254, "_timestamp": 1585577076.0063276, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9645628333091736, "Value Loss": 0.13653147220611572, "_runtime": 7161.643866062164, "_timestamp": 1585577077.4884994, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9656482934951782, "Value Loss": 0.04881192743778229, "_runtime": 7162.299564123154, "_timestamp": 1585577078.1441975, "_step": 236}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 1.4170485734939575, "Value Loss": 23.90660858154297, "_runtime": 7163.849378824234, "_timestamp": 1585577079.6940122, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9632139205932617, "Value Loss": 0.008955775760114193, "_runtime": 7165.244823694229, "_timestamp": 1585577081.089457, "_step": 238}
{"Episode reward": 9.600000000000861, "Episode length": 904, "Policy Loss": 0.12413287907838821, "Value Loss": 10.631682395935059, "_runtime": 7166.748533248901, "_timestamp": 1585577082.5931666, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.95601487159729, "Value Loss": 0.03770110756158829, "_runtime": 7167.888180971146, "_timestamp": 1585577083.7328143, "_step": 240}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": 0.5452200770378113, "Value Loss": 13.367177963256836, "_runtime": 7169.431020736694, "_timestamp": 1585577085.275654, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8999578952789307, "Value Loss": 0.05862920358777046, "_runtime": 7170.291743040085, "_timestamp": 1585577086.1363764, "_step": 242}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 1.0045245885849, "Value Loss": 17.204774856567383, "_runtime": 7170.811433792114, "_timestamp": 1585577086.6560671, "_step": 243}
{"Episode reward": 67.89999999999982, "Episode length": 321, "Policy Loss": 2.488978385925293, "Value Loss": 29.41560173034668, "_runtime": 7172.348093032837, "_timestamp": 1585577088.1927264, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9681233763694763, "Value Loss": 0.01672385260462761, "_runtime": 7173.521310567856, "_timestamp": 1585577089.365944, "_step": 245}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": 0.2388657182455063, "Value Loss": 13.040372848510742, "_runtime": 7174.78790807724, "_timestamp": 1585577090.6325414, "_step": 246}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": 0.10124929249286652, "Value Loss": 11.176962852478027, "_runtime": 7176.341430187225, "_timestamp": 1585577092.1860635, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.053009033203125, "Value Loss": 0.011129463091492653, "_runtime": 7177.871864557266, "_timestamp": 1585577093.716498, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1409380435943604, "Value Loss": 0.19835251569747925, "_runtime": 7179.401500940323, "_timestamp": 1585577095.2461343, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.076466679573059, "Value Loss": 0.029626896604895592, "_runtime": 7180.954350233078, "_timestamp": 1585577096.7989836, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0621141195297241, "Value Loss": 0.03905541077256203, "_runtime": 7181.932477474213, "_timestamp": 1585577097.7771108, "_step": 251}
{"Episode reward": 37.79999999999939, "Episode length": 622, "Policy Loss": 0.6157267093658447, "Value Loss": 14.957881927490234, "_runtime": 7183.482782125473, "_timestamp": 1585577099.3274155, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0379706621170044, "Value Loss": 0.03369423374533653, "_runtime": 7184.88622713089, "_timestamp": 1585577100.7308605, "_step": 253}
{"Episode reward": 10.50000000000081, "Episode length": 895, "Policy Loss": 0.04983324185013771, "Value Loss": 10.749165534973145, "_runtime": 7185.698532819748, "_timestamp": 1585577101.5431662, "_step": 254}
{"Episode reward": 47.699999999999534, "Episode length": 523, "Policy Loss": 0.8999841809272766, "Value Loss": 18.421445846557617, "_runtime": 7186.580565214157, "_timestamp": 1585577102.4251986, "_step": 255}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 0.9501336216926575, "Value Loss": 16.866580963134766, "_runtime": 7188.130977869034, "_timestamp": 1585577103.9756112, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9964967966079712, "Value Loss": 0.09488097578287125, "_runtime": 7188.7473068237305, "_timestamp": 1585577104.5919402, "_step": 257}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.5521842241287231, "Value Loss": 24.393260955810547, "_runtime": 7189.964478254318, "_timestamp": 1585577105.8091116, "_step": 258}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": 0.24060417711734772, "Value Loss": 11.894583702087402, "_runtime": 7191.507282972336, "_timestamp": 1585577107.3519163, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9646976590156555, "Value Loss": 0.03140044957399368, "_runtime": 7192.603981733322, "_timestamp": 1585577108.448615, "_step": 260}
{"Episode reward": 26.4999999999999, "Episode length": 735, "Policy Loss": 0.44915875792503357, "Value Loss": 13.0684814453125, "_runtime": 7194.050435304642, "_timestamp": 1585577109.8950686, "_step": 261}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": 0.08117949962615967, "Value Loss": 10.061952590942383, "_runtime": 7195.599259376526, "_timestamp": 1585577111.4438927, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9854139685630798, "Value Loss": 0.014585861004889011, "_runtime": 7197.159681797028, "_timestamp": 1585577113.0043151, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9897615313529968, "Value Loss": 0.026796936988830566, "_runtime": 7198.712781906128, "_timestamp": 1585577114.5574152, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.008286714553833, "Value Loss": 0.009913266636431217, "_runtime": 7199.322754621506, "_timestamp": 1585577115.167388, "_step": 265}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 1.6662201881408691, "Value Loss": 25.34309196472168, "_runtime": 7200.87437081337, "_timestamp": 1585577116.7190042, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0348873138427734, "Value Loss": 0.01314153429120779, "_runtime": 7202.099349737167, "_timestamp": 1585577117.943983, "_step": 267}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.22896496951580048, "Value Loss": 12.306042671203613, "_runtime": 7203.231867313385, "_timestamp": 1585577119.0765007, "_step": 268}
{"Episode reward": 24.700000000000003, "Episode length": 753, "Policy Loss": 0.279093861579895, "Value Loss": 12.465514183044434, "_runtime": 7204.790070533752, "_timestamp": 1585577120.6347039, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1468585729599, "Value Loss": 0.23458068072795868, "_runtime": 7206.333746671677, "_timestamp": 1585577122.17838, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0546104907989502, "Value Loss": 0.0144225237891078, "_runtime": 7207.581626176834, "_timestamp": 1585577123.4262595, "_step": 271}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": 0.23181955516338348, "Value Loss": 11.868030548095703, "_runtime": 7209.1360013484955, "_timestamp": 1585577124.9806347, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.035314679145813, "Value Loss": 0.04501271992921829, "_runtime": 7210.693558454514, "_timestamp": 1585577126.5381918, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.018276333808899, "Value Loss": 0.03366703912615776, "_runtime": 7211.865412473679, "_timestamp": 1585577127.7100458, "_step": 274}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": 0.2937621772289276, "Value Loss": 12.791115760803223, "_runtime": 7213.434281110764, "_timestamp": 1585577129.2789145, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9580078721046448, "Value Loss": 0.10382996499538422, "_runtime": 7213.982221364975, "_timestamp": 1585577129.8268547, "_step": 276}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": 2.309149742126465, "Value Loss": 28.871246337890625, "_runtime": 7215.441189289093, "_timestamp": 1585577131.2858226, "_step": 277}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": -0.08465518802404404, "Value Loss": 10.301800727844238, "_runtime": 7217.009580373764, "_timestamp": 1585577132.8542137, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0265233516693115, "Value Loss": 0.019198041409254074, "_runtime": 7218.512532711029, "_timestamp": 1585577134.357166, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0148444175720215, "Value Loss": 0.03548046201467514, "_runtime": 7220.105095148087, "_timestamp": 1585577135.9497285, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.084833025932312, "Value Loss": 0.21520556509494781, "_runtime": 7220.3824763298035, "_timestamp": 1585577136.2271097, "_step": 281}
{"Episode reward": 86.70000000000003, "Episode length": 133, "Policy Loss": 6.4078779220581055, "Value Loss": 70.86701965332031, "_runtime": 7221.931564092636, "_timestamp": 1585577137.7761974, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0607924461364746, "Value Loss": 0.013142606243491173, "_runtime": 7223.0955719947815, "_timestamp": 1585577138.9402053, "_step": 283}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": 0.2524977922439575, "Value Loss": 13.386408805847168, "_runtime": 7224.582081317902, "_timestamp": 1585577140.4267147, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.111973524093628, "Value Loss": 0.014597518369555473, "_runtime": 7225.83167052269, "_timestamp": 1585577141.6763039, "_step": 285}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 0.29278188943862915, "Value Loss": 11.96877670288086, "_runtime": 7227.383961439133, "_timestamp": 1585577143.2285948, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1313228607177734, "Value Loss": 0.022597480565309525, "_runtime": 7228.918765306473, "_timestamp": 1585577144.7633986, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1835334300994873, "Value Loss": 0.12891893088817596, "_runtime": 7230.450701236725, "_timestamp": 1585577146.2953346, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1564364433288574, "Value Loss": 0.1179174929857254, "_runtime": 7230.837597370148, "_timestamp": 1585577146.6822307, "_step": 289}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": 3.5620434284210205, "Value Loss": 43.62337112426758, "_runtime": 7232.370621681213, "_timestamp": 1585577148.215255, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1492748260498047, "Value Loss": 0.020311210304498672, "_runtime": 7233.287834882736, "_timestamp": 1585577149.1324682, "_step": 291}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.7098409533500671, "Value Loss": 15.91491413116455, "_runtime": 7234.77872300148, "_timestamp": 1585577150.6233563, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2020994424819946, "Value Loss": 0.01888282038271427, "_runtime": 7236.332083463669, "_timestamp": 1585577152.1767168, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2169904708862305, "Value Loss": 0.03159673511981964, "_runtime": 7237.855485200882, "_timestamp": 1585577153.7001185, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2360213994979858, "Value Loss": 0.04488443210721016, "_runtime": 7238.861351251602, "_timestamp": 1585577154.7059846, "_step": 295}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": 0.24148054420948029, "Value Loss": 14.864802360534668, "_runtime": 7240.423350572586, "_timestamp": 1585577156.267984, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2287713289260864, "Value Loss": 0.017027880996465683, "_runtime": 7241.988912820816, "_timestamp": 1585577157.8335462, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2860345840454102, "Value Loss": 0.1400557905435562, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115, 0.00035570713225752115]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.038090240210294724, -0.03484853729605675, -0.03160683438181877, -0.028365131467580795, -0.02512342855334282, -0.021881725639104843, -0.018640022724866867, -0.015398319810628891, -0.012156616896390915, -0.008914913982152939, -0.005673211067914963, -0.0024315081536769867, 0.0008101947605609894, 0.0040518976747989655, 0.0072936005890369415, 0.010535303503274918, 0.013777006417512894, 0.01701870933175087, 0.020260412245988846, 0.023502115160226822, 0.026743818074464798, 0.029985520988702774, 0.03322722390294075, 0.036468926817178726, 0.0397106297314167, 0.04295233264565468, 0.046194035559892654, 0.04943573847413063, 0.05267744138836861, 0.05591914430260658, 0.05916084721684456, 0.062402550131082535, 0.06564424932003021, 0.06888595223426819, 0.07212765514850616, 0.07536935806274414, 0.07861106097698212, 0.08185276389122009, 0.08509446680545807, 0.08833616971969604, 0.09157787263393402, 0.094819575548172, 0.09806127846240997, 0.10130298137664795, 0.10454468429088593, 0.1077863872051239, 0.11102809011936188, 0.11426979303359985, 0.11751149594783783, 0.1207531988620758, 0.12399490177631378, 0.12723660469055176, 0.13047830760478973, 0.1337200105190277, 0.13696171343326569, 0.14020341634750366, 0.14344511926174164, 0.14668682217597961, 0.1499285250902176, 0.15317022800445557, 0.15641193091869354, 0.15965363383293152, 0.1628953367471695, 0.16613703966140747, 0.16937874257564545]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0002441887918394059, -0.00018710798758547753, -0.00013002718333154917, -7.29463790776208e-05, -1.586557482369244e-05, 4.121524398215115e-05, 9.829603368416429e-05, 0.00015537682338617742, 0.000212457642192021, 0.0002695384609978646, 0.0003266192798037082, 0.0003837000404018909, 0.00044078085920773447, 0.0004978616489097476, 0.0005549424095079303, 0.0006120232865214348, 0.0006691040471196175, 0.000726184924133122, 0.0007832656847313046, 0.0008403464453294873, 0.0008974273223429918, 0.0009545080829411745, 0.0010115888435393572, 0.0010686697205528617, 0.0011257504811510444, 0.001182831241749227, 0.0012399121187627316, 0.0012969928793609142, 0.001354073639959097, 0.0014111545169726014, 0.001468235277570784, 0.0015253161545842886, 0.0015823969151824713, 0.001639477675780654, 0.0016965585527941585, 0.001753639429807663, 0.0018107201904058456, 0.0018678009510040283, 0.001924881711602211, 0.0019819624722003937, 0.00203904346562922, 0.0020961242262274027, 0.0021532049868255854, 0.002210285747423768, 0.0022673665080219507, 0.0023244472686201334, 0.0023815282620489597, 0.0024386090226471424, 0.002495689783245325, 0.0025527705438435078, 0.0026098513044416904, 0.0026669322978705168, 0.0027240130584686995, 0.002781093819066882, 0.002838174579665065, 0.0028952553402632475, 0.00295233610086143, 0.0030094170942902565, 0.003066497854888439, 0.003123578615486622, 0.0031806593760848045, 0.003237740136682987, 0.0032948211301118135, 0.0033519018907099962, 0.003408982651308179]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 8.0, 9.0, 5.0, 19.0, 13.0, 28.0, 72.0, 248.0, 16.0, 2.0, 13.0, 5.0, 10.0, 7.0, 6.0, 6.0, 3.0, 3.0, 0.0, 0.0, 3.0, 5.0, 5.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0], "bins": [-0.01945001818239689, -0.018515240401029587, -0.017580464482307434, -0.016645686700940132, -0.01571090891957283, -0.014776131138205528, -0.013841354288160801, -0.012906577438116074, -0.011971799656748772, -0.01103702187538147, -0.010102245025336742, -0.009167468175292015, -0.008232690393924713, -0.007297912612557411, -0.006363135762512684, -0.0054283589124679565, -0.004493581131100655, -0.0035588033497333527, -0.0026240255683660507, -0.001689249649643898, -0.0007544718682765961, 0.00018030591309070587, 0.0011150818318128586, 0.0020498596131801605, 0.0029846373945474625, 0.003919415175914764, 0.004854192957282066, 0.005788968876004219, 0.006723746657371521, 0.007658524438738823, 0.008593300357460976, 0.009528078138828278, 0.01046285592019558, 0.011397633701562881, 0.012332411482930183, 0.013267187401652336, 0.014201967045664787, 0.01513674296438694, 0.016071518883109093, 0.017006298527121544, 0.017941074445843697, 0.01887585036456585, 0.0198106300085783, 0.020745405927300453, 0.021680181846022606, 0.022614961490035057, 0.02354973740875721, 0.02448451705276966, 0.025419292971491814, 0.026354068890213966, 0.027288848534226418, 0.02822362445294857, 0.02915840409696102, 0.030093180015683174, 0.031027955934405327, 0.03196273744106293, 0.03289750963449478, 0.03383228927850723, 0.034767068922519684, 0.03570184111595154, 0.03663662075996399, 0.03757140040397644, 0.038506172597408295, 0.039440952241420746, 0.0403757318854332]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], "bins": [-0.09823878854513168, -0.09527061879634857, -0.09230245649814606, -0.08933428674936295, -0.08636612445116043, -0.08339795470237732, -0.0804297924041748, -0.0774616226553917, -0.07449345290660858, -0.07152529060840607, -0.06855712831020355, -0.06558895856142044, -0.06262078881263733, -0.059652622789144516, -0.0566844567656517, -0.05371629074215889, -0.05074812471866608, -0.047779958695173264, -0.04481179267168045, -0.04184362664818764, -0.038875460624694824, -0.03590729087591171, -0.0329391285777092, -0.029970958828926086, -0.027002789080142975, -0.02403462678194046, -0.02106645703315735, -0.018098294734954834, -0.015130124986171722, -0.012161962687969208, -0.009193792939186096, -0.0062256306409835815, -0.00325746089220047, -0.0002892911434173584, 0.0026788711547851562, 0.005647040903568268, 0.008615203201770782, 0.011583372950553894, 0.014551535248756409, 0.01751970499753952, 0.020487867295742035, 0.023456037044525146, 0.026424206793308258, 0.029392369091510773, 0.03236053138971329, 0.035328708589076996, 0.03829687088727951, 0.041265033185482025, 0.044233210384845734, 0.04720137268304825, 0.05016953498125076, 0.05313769727945328, 0.056105874478816986, 0.0590740367770195, 0.062042199075222015, 0.06501036137342453, 0.06797853857278824, 0.07094670087099075, 0.07391486316919327, 0.07688304036855698, 0.07985120266675949, 0.082819364964962, 0.08578752726316452, 0.08875570446252823, 0.09172386676073074]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 6.0, 2.0, 4.0, 1.0, 6.0, 10.0, 6.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], "bins": [-0.10546331107616425, -0.1024918481707573, -0.09952037781476974, -0.09654891490936279, -0.09357744455337524, -0.09060598164796829, -0.08763451129198074, -0.08466304838657379, -0.08169157803058624, -0.07872011512517929, -0.07574864476919174, -0.07277718186378479, -0.06980571150779724, -0.06683424860239029, -0.06386278569698334, -0.06089131534099579, -0.05791984871029854, -0.05494838207960129, -0.05197691544890404, -0.04900544881820679, -0.04603398218750954, -0.043062515556812286, -0.040091052651405334, -0.037119582295417786, -0.034148119390010834, -0.031176649034023285, -0.028205186128616333, -0.025233715772628784, -0.022262252867221832, -0.019290782511234283, -0.01631931960582733, -0.013347849249839783, -0.01037638634443283, -0.007404923439025879, -0.00443345308303833, -0.0014619901776313782, 0.0015094801783561707, 0.0044809430837631226, 0.007452413439750671, 0.010423876345157623, 0.013395346701145172, 0.016366809606552124, 0.019338279962539673, 0.02230975031852722, 0.025281205773353577, 0.028252676129341125, 0.031224146485328674, 0.03419561684131622, 0.03716707229614258, 0.04013854265213013, 0.043110013008117676, 0.04608146846294403, 0.04905293881893158, 0.05202440917491913, 0.05499587953090668, 0.05796733498573303, 0.06093880534172058, 0.06391027569770813, 0.06688174605369568, 0.06985320150852203, 0.07282467186450958, 0.07579614222049713, 0.07876761257648468, 0.08173906803131104, 0.08471053838729858]}, "_runtime": 7243.55092549324, "_timestamp": 1585577159.3955588, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.220044732093811, "Value Loss": 0.057879649102687836, "_runtime": 7244.9793038368225, "_timestamp": 1585577160.8239372, "_step": 299}
{"Episode reward": 8.500000000000924, "Episode length": 915, "Policy Loss": -0.13538049161434174, "Value Loss": 10.327229499816895, "_runtime": 7246.523783445358, "_timestamp": 1585577162.3684168, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.130607008934021, "Value Loss": 0.030366286635398865, "_runtime": 7248.076295137405, "_timestamp": 1585577163.9209285, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.11319899559021, "Value Loss": 0.023743990808725357, "_runtime": 7249.62789607048, "_timestamp": 1585577165.4725294, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.070281744003296, "Value Loss": 0.03525364771485329, "_runtime": 7251.195914268494, "_timestamp": 1585577167.0405476, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0555109977722168, "Value Loss": 0.03302149102091789, "_runtime": 7252.746152162552, "_timestamp": 1585577168.5907855, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0332140922546387, "Value Loss": 0.02817504294216633, "_runtime": 7253.384347200394, "_timestamp": 1585577169.2289805, "_step": 305}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.7941932678222656, "Value Loss": 23.350961685180664, "_runtime": 7254.819759130478, "_timestamp": 1585577170.6643925, "_step": 306}
{"Episode reward": 7.900000000000958, "Episode length": 921, "Policy Loss": 0.06425769627094269, "Value Loss": 10.285022735595703, "_runtime": 7256.378317117691, "_timestamp": 1585577172.2229505, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0272455215454102, "Value Loss": 0.022229937836527824, "_runtime": 7257.892965078354, "_timestamp": 1585577173.7375984, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0265936851501465, "Value Loss": 0.02130977250635624, "_runtime": 7258.953906774521, "_timestamp": 1585577174.79854, "_step": 309}
{"Episode reward": 33.4999999999995, "Episode length": 665, "Policy Loss": 0.46552497148513794, "Value Loss": 14.172926902770996, "_runtime": 7260.515706062317, "_timestamp": 1585577176.3603394, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0414484739303589, "Value Loss": 0.0146652702242136, "_runtime": 7262.058024406433, "_timestamp": 1585577177.9026577, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.048153281211853, "Value Loss": 0.03072129748761654, "_runtime": 7262.824709177017, "_timestamp": 1585577178.6693425, "_step": 312}
{"Episode reward": 51.09999999999958, "Episode length": 489, "Policy Loss": 0.9751478433609009, "Value Loss": 19.61746597290039, "_runtime": 7264.375814914703, "_timestamp": 1585577180.2204483, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0646638870239258, "Value Loss": 0.16824594140052795, "_runtime": 7265.933419466019, "_timestamp": 1585577181.7780528, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9890891909599304, "Value Loss": 0.0351993665099144, "_runtime": 7266.843479633331, "_timestamp": 1585577182.688113, "_step": 315}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 0.7320461273193359, "Value Loss": 16.682300567626953, "_runtime": 7268.392408370972, "_timestamp": 1585577184.2370417, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9463701248168945, "Value Loss": 0.052162040024995804, "_runtime": 7269.857471704483, "_timestamp": 1585577185.702105, "_step": 317}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": 0.09003302454948425, "Value Loss": 9.90517520904541, "_runtime": 7270.90535402298, "_timestamp": 1585577186.7499874, "_step": 318}
{"Episode reward": 31.499999999999616, "Episode length": 685, "Policy Loss": 0.7278433442115784, "Value Loss": 13.886056900024414, "_runtime": 7271.625079631805, "_timestamp": 1585577187.469713, "_step": 319}
{"Episode reward": 55.29999999999964, "Episode length": 447, "Policy Loss": 1.5485219955444336, "Value Loss": 20.560243606567383, "_runtime": 7273.179772377014, "_timestamp": 1585577189.0244057, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.013572096824646, "Value Loss": 0.1855064332485199, "_runtime": 7274.70934343338, "_timestamp": 1585577190.5539768, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9804871678352356, "Value Loss": 0.027583008632063866, "_runtime": 7276.204104423523, "_timestamp": 1585577192.0487378, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0221580266952515, "Value Loss": 0.10735514014959335, "_runtime": 7277.756291627884, "_timestamp": 1585577193.600925, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9986118674278259, "Value Loss": 0.03499418869614601, "_runtime": 7278.3901216983795, "_timestamp": 1585577194.234755, "_step": 324}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.5033347606658936, "Value Loss": 24.81785774230957, "_runtime": 7279.929219245911, "_timestamp": 1585577195.7738526, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9625974893569946, "Value Loss": 0.009793359786272049, "_runtime": 7281.487977266312, "_timestamp": 1585577197.3326106, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9402665495872498, "Value Loss": 0.012407897971570492, "_runtime": 7282.412627458572, "_timestamp": 1585577198.2572608, "_step": 327}
{"Episode reward": 38.79999999999941, "Episode length": 612, "Policy Loss": 0.6508364677429199, "Value Loss": 14.713350296020508, "_runtime": 7283.97136926651, "_timestamp": 1585577199.8160026, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9146164655685425, "Value Loss": 0.015991631895303726, "_runtime": 7285.524537563324, "_timestamp": 1585577201.369171, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9081928730010986, "Value Loss": 0.025582022964954376, "_runtime": 7287.027024745941, "_timestamp": 1585577202.871658, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9034231901168823, "Value Loss": 0.012219619937241077, "_runtime": 7288.5820252895355, "_timestamp": 1585577204.4266586, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9672461152076721, "Value Loss": 0.26079538464546204, "_runtime": 7290.038751125336, "_timestamp": 1585577205.8833845, "_step": 332}
{"Episode reward": 9.000000000000895, "Episode length": 910, "Policy Loss": 0.21385619044303894, "Value Loss": 10.48237419128418, "_runtime": 7290.533226013184, "_timestamp": 1585577206.3778594, "_step": 333}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 3.4509878158569336, "Value Loss": 31.74102020263672, "_runtime": 7292.07470035553, "_timestamp": 1585577207.9193337, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8572338223457336, "Value Loss": 0.00891072116792202, "_runtime": 7293.442767620087, "_timestamp": 1585577209.287401, "_step": 335}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.3287891745567322, "Value Loss": 10.654948234558105, "_runtime": 7294.932531833649, "_timestamp": 1585577210.7771652, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8709374666213989, "Value Loss": 0.015271003358066082, "_runtime": 7295.8776869773865, "_timestamp": 1585577211.7223203, "_step": 337}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": 0.7578490376472473, "Value Loss": 15.982394218444824, "_runtime": 7297.421854734421, "_timestamp": 1585577213.266488, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9016245603561401, "Value Loss": 0.01507189217954874, "_runtime": 7298.220040559769, "_timestamp": 1585577214.064674, "_step": 339}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 1.0454888343811035, "Value Loss": 18.74941635131836, "_runtime": 7298.982489109039, "_timestamp": 1585577214.8271224, "_step": 340}
{"Episode reward": 51.09999999999958, "Episode length": 489, "Policy Loss": 0.9745811820030212, "Value Loss": 19.236459732055664, "_runtime": 7299.377026081085, "_timestamp": 1585577215.2216594, "_step": 341}
{"Episode reward": 77.79999999999995, "Episode length": 222, "Policy Loss": 4.407277584075928, "Value Loss": 41.3687629699707, "_runtime": 7300.873742818832, "_timestamp": 1585577216.7183762, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9658035635948181, "Value Loss": 0.11749687045812607, "_runtime": 7301.602212667465, "_timestamp": 1585577217.446846, "_step": 343}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.2293349504470825, "Value Loss": 19.653888702392578, "_runtime": 7302.752371311188, "_timestamp": 1585577218.5970047, "_step": 344}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.2041330635547638, "Value Loss": 11.697245597839355, "_runtime": 7304.306332826614, "_timestamp": 1585577220.1509662, "_step": 345}
{"Episode reward": -99.80705566406111, "Episode length": 999, "Policy Loss": -1.050039529800415, "Value Loss": 0.03705749288201332, "_runtime": 7305.812033891678, "_timestamp": 1585577221.6566672, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0924804210662842, "Value Loss": 0.013511636294424534, "_runtime": 7306.70626783371, "_timestamp": 1585577222.5509012, "_step": 347}
{"Episode reward": 41.99999999999945, "Episode length": 580, "Policy Loss": 0.5109458565711975, "Value Loss": 16.996356964111328, "_runtime": 7307.280643224716, "_timestamp": 1585577223.1252766, "_step": 348}
{"Episode reward": 63.999999999999766, "Episode length": 360, "Policy Loss": 1.700432538986206, "Value Loss": 25.44999122619629, "_runtime": 7308.811518669128, "_timestamp": 1585577224.656152, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.121816635131836, "Value Loss": 0.025890229269862175, "_runtime": 7310.313904285431, "_timestamp": 1585577226.1585376, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.146708369255066, "Value Loss": 0.1756117194890976, "_runtime": 7311.808375120163, "_timestamp": 1585577227.6530085, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1401340961456299, "Value Loss": 0.15511734783649445, "_runtime": 7313.36460018158, "_timestamp": 1585577229.2092335, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0893311500549316, "Value Loss": 0.04678010195493698, "_runtime": 7314.1126499176025, "_timestamp": 1585577229.9572833, "_step": 353}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 1.055220127105713, "Value Loss": 19.569732666015625, "_runtime": 7314.601007461548, "_timestamp": 1585577230.4456408, "_step": 354}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 2.300485372543335, "Value Loss": 31.459781646728516, "_runtime": 7316.186734199524, "_timestamp": 1585577232.0313675, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1497617959976196, "Value Loss": 0.045273348689079285, "_runtime": 7317.696566581726, "_timestamp": 1585577233.5412, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2067841291427612, "Value Loss": 0.030182503163814545, "_runtime": 7319.186812162399, "_timestamp": 1585577235.0314455, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.260110855102539, "Value Loss": 0.13358882069587708, "_runtime": 7319.754950761795, "_timestamp": 1585577235.599584, "_step": 358}
{"Episode reward": 65.79999999999978, "Episode length": 342, "Policy Loss": 1.2230697870254517, "Value Loss": 28.04649543762207, "_runtime": 7321.068724393845, "_timestamp": 1585577236.9133577, "_step": 359}
{"Episode reward": 14.2000000000006, "Episode length": 858, "Policy Loss": -0.16504274308681488, "Value Loss": 11.254289627075195, "_runtime": 7322.053992033005, "_timestamp": 1585577237.8986254, "_step": 360}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": 0.3325050175189972, "Value Loss": 14.344939231872559, "_runtime": 7323.47958445549, "_timestamp": 1585577239.3242178, "_step": 361}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": -0.08227574825286865, "Value Loss": 9.794844627380371, "_runtime": 7323.74827003479, "_timestamp": 1585577239.5929034, "_step": 362}
{"Episode reward": 86.60000000000004, "Episode length": 134, "Policy Loss": 7.710541248321533, "Value Loss": 70.4500961303711, "_runtime": 7325.268549203873, "_timestamp": 1585577241.1131825, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1714726686477661, "Value Loss": 0.12702272832393646, "_runtime": 7326.814556121826, "_timestamp": 1585577242.6591895, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2641600370407104, "Value Loss": 0.05736036226153374, "_runtime": 7328.296743154526, "_timestamp": 1585577244.1413765, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.325447678565979, "Value Loss": 0.02781037613749504, "_runtime": 7329.451382637024, "_timestamp": 1585577245.296016, "_step": 366}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": -0.08546057343482971, "Value Loss": 13.105074882507324, "_runtime": 7330.768260717392, "_timestamp": 1585577246.612894, "_step": 367}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": -0.1890588253736496, "Value Loss": 11.133185386657715, "_runtime": 7332.315724372864, "_timestamp": 1585577248.1603577, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4145359992980957, "Value Loss": 0.025687936693429947, "_runtime": 7333.092017173767, "_timestamp": 1585577248.9366505, "_step": 369}
{"Episode reward": 51.299999999999585, "Episode length": 487, "Policy Loss": 0.3666020929813385, "Value Loss": 19.966039657592773, "_runtime": 7333.5838277339935, "_timestamp": 1585577249.428461, "_step": 370}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 2.7054026126861572, "Value Loss": 31.643966674804688, "_runtime": 7335.048388719559, "_timestamp": 1585577250.893022, "_step": 371}
{"Episode reward": 4.200000000001168, "Episode length": 958, "Policy Loss": -0.33960244059562683, "Value Loss": 9.686123847961426, "_runtime": 7336.058703422546, "_timestamp": 1585577251.9033368, "_step": 372}
{"Episode reward": 34.699999999999434, "Episode length": 653, "Policy Loss": 0.1750834882259369, "Value Loss": 14.084444999694824, "_runtime": 7337.355947494507, "_timestamp": 1585577253.2005808, "_step": 373}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": -0.1691655069589615, "Value Loss": 10.934014320373535, "_runtime": 7338.040733337402, "_timestamp": 1585577253.8853667, "_step": 374}
{"Episode reward": 57.49999999999967, "Episode length": 425, "Policy Loss": 1.1838682889938354, "Value Loss": 21.943470001220703, "_runtime": 7339.631426811218, "_timestamp": 1585577255.4760602, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3104603290557861, "Value Loss": 0.07866556197404861, "_runtime": 7340.501361846924, "_timestamp": 1585577256.3459952, "_step": 376}
{"Episode reward": 44.199999999999484, "Episode length": 558, "Policy Loss": 0.42474988102912903, "Value Loss": 16.34284782409668, "_runtime": 7342.011237382889, "_timestamp": 1585577257.8558707, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2977031469345093, "Value Loss": 0.18429309129714966, "_runtime": 7343.5755751132965, "_timestamp": 1585577259.4202085, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3896663188934326, "Value Loss": 0.019810033962130547, "_runtime": 7345.067079544067, "_timestamp": 1585577260.911713, "_step": 379}
{"Episode reward": 2.000000000001293, "Episode length": 980, "Policy Loss": -0.41344690322875977, "Value Loss": 9.596368789672852, "_runtime": 7345.971320390701, "_timestamp": 1585577261.8159537, "_step": 380}
{"Episode reward": 43.09999999999947, "Episode length": 569, "Policy Loss": 0.008538003079593182, "Value Loss": 16.711681365966797, "_runtime": 7347.543421983719, "_timestamp": 1585577263.3880553, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.432692527770996, "Value Loss": 0.028695465996861458, "_runtime": 7349.103222608566, "_timestamp": 1585577264.947856, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3907794952392578, "Value Loss": 0.0434979647397995, "_runtime": 7350.631372690201, "_timestamp": 1585577266.476006, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3767063617706299, "Value Loss": 0.023512007668614388, "_runtime": 7352.1993060112, "_timestamp": 1585577268.0439394, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3437151908874512, "Value Loss": 0.0495448037981987, "_runtime": 7353.774607181549, "_timestamp": 1585577269.6192405, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3262646198272705, "Value Loss": 0.043513983488082886, "_runtime": 7355.331501722336, "_timestamp": 1585577271.176135, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3033729791641235, "Value Loss": 0.05347345024347305, "_runtime": 7356.905474901199, "_timestamp": 1585577272.7501082, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1926621198654175, "Value Loss": 0.32028692960739136, "_runtime": 7357.414331912994, "_timestamp": 1585577273.2589653, "_step": 388}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 2.055041551589966, "Value Loss": 31.004779815673828, "_runtime": 7358.970689058304, "_timestamp": 1585577274.8153224, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.348981261253357, "Value Loss": 0.1080770492553711, "_runtime": 7360.546217679977, "_timestamp": 1585577276.390851, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.399741768836975, "Value Loss": 0.12101807445287704, "_runtime": 7362.050034761429, "_timestamp": 1585577277.894668, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4199347496032715, "Value Loss": 0.1647668480873108, "_runtime": 7362.929104089737, "_timestamp": 1585577278.7737374, "_step": 392}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": 0.19484874606132507, "Value Loss": 17.784744262695312, "_runtime": 7364.524387836456, "_timestamp": 1585577280.3690212, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3701341152191162, "Value Loss": 0.21146896481513977, "_runtime": 7366.074279785156, "_timestamp": 1585577281.9189131, "_step": 394}
{"Episode reward": -99.79506387710431, "Episode length": 999, "Policy Loss": -1.240767478942871, "Value Loss": 0.03971796855330467, "_runtime": 7367.592829942703, "_timestamp": 1585577283.4374633, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1819711923599243, "Value Loss": 0.15848153829574585, "_runtime": 7368.611351251602, "_timestamp": 1585577284.4559846, "_step": 396}
{"Episode reward": 35.199999999999406, "Episode length": 648, "Policy Loss": 0.8539689779281616, "Value Loss": 14.762858390808105, "_runtime": 7370.15460395813, "_timestamp": 1585577285.9992373, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0343291759490967, "Value Loss": 0.19309355318546295, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164, 0.004736033733934164]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.004736033733934164, 0.03578919172286987, 0.07631441205739975, 0.11683963239192963, 0.1573648601770401, 0.19789008796215057, 0.23841530084609985, 0.2789405286312103, 0.3194657564163208, 0.3599909842014313, 0.40051621198654175, 0.4410414397716522, 0.4815666377544403, 0.5220919251441956, 0.5626171231269836, 0.6031423807144165, 0.6436675786972046, 0.6841927766799927, 0.7247180342674255, 0.7652432322502136, 0.8057684898376465, 0.8462936878204346, 0.8868189454078674, 0.9273441433906555, 0.9678693413734436, 1.008394479751587, 1.0489197969436646, 1.0894449949264526, 1.1299701929092407, 1.1704953908920288, 1.2110207080841064, 1.2515459060668945, 1.2920711040496826, 1.3325963020324707, 1.3731215000152588, 1.4136468172073364, 1.4541720151901245, 1.4946972131729126, 1.5352224111557007, 1.5757477283477783, 1.6162729263305664, 1.6567981243133545, 1.6973233222961426, 1.7378485202789307, 1.7783738374710083, 1.8188990354537964, 1.8594242334365845, 1.8999494314193726, 1.9404746294021606, 1.9809999465942383, 2.0215251445770264, 2.0620505809783936, 2.1025757789611816, 2.1431009769439697, 2.183626174926758, 2.224151372909546, 2.264676570892334, 2.305201768875122, 2.34572696685791, 2.3862521648406982, 2.4267776012420654, 2.4673027992248535, 2.5078279972076416, 2.5483531951904297, 2.5888783931732178]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [0.0, 0.0004897011676803231, 0.0009794023353606462, 0.0014691035030409694, 0.0019588046707212925, 0.002448505721986294, 0.0029382070060819387, 0.0034279082901775837, 0.003917609341442585, 0.004407310392707586, 0.004897011443972588, 0.005386712960898876, 0.0058764140121638775, 0.006366115063428879, 0.006855816580355167, 0.007345517631620169, 0.00783521868288517, 0.008324920199811459, 0.008814620785415173, 0.009304322302341461, 0.009794022887945175, 0.010283724404871464, 0.010773425921797752, 0.011263126507401466, 0.011752828024327755, 0.012242529541254044, 0.012732230126857758, 0.013221931643784046, 0.013711633160710335, 0.014201333746314049, 0.014691035263240337, 0.015180735848844051, 0.01567043736577034, 0.016160137951374054, 0.016649840399622917, 0.01713954098522663, 0.017629241570830345, 0.01811894401907921, 0.018608644604682922, 0.019098345190286636, 0.01958804577589035, 0.020077748224139214, 0.020567448809742928, 0.02105714939534664, 0.021546851843595505, 0.02203655242919922, 0.022526253014802933, 0.023015955463051796, 0.02350565604865551, 0.023995356634259224, 0.024485059082508087, 0.0249747596681118, 0.025464460253715515, 0.02595416270196438, 0.026443863287568092, 0.026933563873171806, 0.02742326632142067, 0.027912966907024384, 0.028402667492628098, 0.02889236807823181, 0.029382070526480675, 0.02987177111208439, 0.030361471697688103, 0.030851174145936966, 0.03134087473154068]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [26.0, 9.0, 31.0, 269.0, 33.0, 17.0, 12.0, 1.0, 7.0, 13.0, 7.0, 9.0, 5.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 10.0, 1.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.027907278388738632, -0.02063046023249626, -0.013353641144931316, -0.006076822057366371, 0.0011999960988759995, 0.00847681611776352, 0.01575363427400589, 0.02303045243024826, 0.03030727058649063, 0.0375840924680233, 0.04486091062426567, 0.05213772878050804, 0.05941454693675041, 0.06669136881828308, 0.07396818697452545, 0.08124500513076782, 0.08852182328701019, 0.09579864144325256, 0.10307545959949493, 0.1103522777557373, 0.11762909591197968, 0.12490591406822205, 0.13218273222446442, 0.1394595503807068, 0.14673636853694916, 0.15401318669319153, 0.1612900048494339, 0.16856682300567627, 0.17584364116191864, 0.183120459318161, 0.19039727747440338, 0.19767409563064575, 0.20495091378688812, 0.2122277319431305, 0.21950455009937286, 0.22678136825561523, 0.2340582013130188, 0.24133500456809998, 0.24861183762550354, 0.2558886408805847, 0.2631654739379883, 0.27044227719306946, 0.277719110250473, 0.2849959135055542, 0.29227274656295776, 0.29954954981803894, 0.3068263828754425, 0.3141031861305237, 0.32138001918792725, 0.3286568224430084, 0.335933655500412, 0.34321045875549316, 0.35048729181289673, 0.3577640950679779, 0.36504092812538147, 0.37231773138046265, 0.3795945644378662, 0.3868713676929474, 0.39414820075035095, 0.40142500400543213, 0.4087018370628357, 0.41597864031791687, 0.42325547337532043, 0.4305322766304016, 0.4378091096878052]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.5056930780410767, -0.48031264543533325, -0.45493221282958984, -0.42955178022384644, -0.404171347618103, -0.3787909150123596, -0.3534104824066162, -0.3280300498008728, -0.3026496171951294, -0.277269184589386, -0.2518887221813202, -0.22650828957557678, -0.20112785696983337, -0.17574742436408997, -0.15036699175834656, -0.12498655915260315, -0.09960612654685974, -0.07422569394111633, -0.048845261335372925, -0.023464828729629517, 0.0019156336784362793, 0.027296066284179688, 0.052676498889923096, 0.0780569314956665, 0.10343736410140991, 0.12881779670715332, 0.15419822931289673, 0.17957866191864014, 0.20495909452438354, 0.23033952713012695, 0.25571995973587036, 0.28110039234161377, 0.3064808249473572, 0.3318612575531006, 0.357241690158844, 0.3826221227645874, 0.4080025553703308, 0.4333829879760742, 0.4587634205818176, 0.48414385318756104, 0.5095243453979492, 0.5349047183990479, 0.560285210609436, 0.5856655836105347, 0.6110460758209229, 0.6364264488220215, 0.6618069410324097, 0.6871873140335083, 0.7125678062438965, 0.7379481792449951, 0.7633286714553833, 0.7887090444564819, 0.8140895366668701, 0.8394699096679688, 0.8648504018783569, 0.8902307748794556, 0.9156112670898438, 0.9409916400909424, 0.9663721323013306, 0.9917525053024292, 1.0171329975128174, 1.042513370513916, 1.0678938627243042, 1.0932742357254028, 1.118654727935791]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 5.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 6.0], "bins": [-0.39178475737571716, -0.3822370767593384, -0.3726893961429596, -0.3631417155265808, -0.353594034910202, -0.34404635429382324, -0.33449864387512207, -0.3249509632587433, -0.3154032826423645, -0.3058556020259857, -0.29630792140960693, -0.28676024079322815, -0.27721256017684937, -0.2676648795604706, -0.2581171989440918, -0.24856950342655182, -0.23902182281017303, -0.22947414219379425, -0.21992646157741547, -0.2103787660598755, -0.2008310854434967, -0.19128340482711792, -0.18173572421073914, -0.17218804359436035, -0.16264036297798157, -0.1530926674604416, -0.1435449868440628, -0.13399729132652283, -0.12444961071014404, -0.11490193009376526, -0.10535424947738647, -0.09580656886100769, -0.0862588882446289, -0.07671120762825012, -0.06716352701187134, -0.057615846395492554, -0.04806816577911377, -0.038520485162734985, -0.028972774744033813, -0.01942509412765503, -0.009877413511276245, -0.00032973289489746094, 0.009217947721481323, 0.018765628337860107, 0.02831330895423889, 0.037860989570617676, 0.04740867018699646, 0.056956350803375244, 0.06650403141975403, 0.0760517418384552, 0.08559942245483398, 0.09514710307121277, 0.10469478368759155, 0.11424246430397034, 0.12379017472267151, 0.1333378255367279, 0.14288553595542908, 0.15243318676948547, 0.16198089718818665, 0.17152854800224304, 0.1810762584209442, 0.1906239092350006, 0.20017161965370178, 0.20971927046775818, 0.21926698088645935]}, "_runtime": 7370.667063474655, "_timestamp": 1585577286.5116968, "_step": 398}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": 2.629063606262207, "Value Loss": 31.654096603393555, "_runtime": 7372.197703838348, "_timestamp": 1585577288.0423372, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0240439176559448, "Value Loss": 0.14445342123508453, "_runtime": 7373.756723642349, "_timestamp": 1585577289.601357, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0961658954620361, "Value Loss": 0.03365759178996086, "_runtime": 7374.886348485947, "_timestamp": 1585577290.7309818, "_step": 401}
{"Episode reward": 24.300000000000026, "Episode length": 757, "Policy Loss": 0.15272755920886993, "Value Loss": 12.260904312133789, "_runtime": 7375.98689365387, "_timestamp": 1585577291.831527, "_step": 402}
{"Episode reward": 30.099999999999696, "Episode length": 699, "Policy Loss": 0.22108657658100128, "Value Loss": 13.932638168334961, "_runtime": 7377.542469024658, "_timestamp": 1585577293.3871024, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1342769861221313, "Value Loss": 0.03582784906029701, "_runtime": 7378.07411813736, "_timestamp": 1585577293.9187515, "_step": 404}
{"Episode reward": 67.09999999999981, "Episode length": 329, "Policy Loss": 1.833544135093689, "Value Loss": 27.943777084350586, "_runtime": 7379.607757568359, "_timestamp": 1585577295.452391, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.045246958732605, "Value Loss": 0.016594594344496727, "_runtime": 7381.152116537094, "_timestamp": 1585577296.9967499, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9953528642654419, "Value Loss": 0.0442727692425251, "_runtime": 7382.583033800125, "_timestamp": 1585577298.4276671, "_step": 407}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": 0.06570777297019958, "Value Loss": 10.911308288574219, "_runtime": 7383.21836066246, "_timestamp": 1585577299.062994, "_step": 408}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 2.0070624351501465, "Value Loss": 24.365314483642578, "_runtime": 7384.60141992569, "_timestamp": 1585577300.4460533, "_step": 409}
{"Episode reward": 10.50000000000081, "Episode length": 895, "Policy Loss": 0.3319988250732422, "Value Loss": 11.006905555725098, "_runtime": 7385.758516550064, "_timestamp": 1585577301.60315, "_step": 410}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": 0.45246437191963196, "Value Loss": 12.647855758666992, "_runtime": 7387.2933168411255, "_timestamp": 1585577303.1379502, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.932324230670929, "Value Loss": 0.05013684555888176, "_runtime": 7388.586131095886, "_timestamp": 1585577304.4307644, "_step": 412}
{"Episode reward": 16.800000000000452, "Episode length": 832, "Policy Loss": 0.20880082249641418, "Value Loss": 11.296935081481934, "_runtime": 7389.564499616623, "_timestamp": 1585577305.409133, "_step": 413}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 0.34921854734420776, "Value Loss": 15.16485595703125, "_runtime": 7390.827112674713, "_timestamp": 1585577306.671746, "_step": 414}
{"Episode reward": 17.800000000000395, "Episode length": 822, "Policy Loss": 0.125840425491333, "Value Loss": 11.647652626037598, "_runtime": 7392.379976511002, "_timestamp": 1585577308.2246099, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0509085655212402, "Value Loss": 0.41393110156059265, "_runtime": 7393.900729894638, "_timestamp": 1585577309.7453632, "_step": 416}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": 0.04752255231142044, "Value Loss": 9.568194389343262, "_runtime": 7395.43012881279, "_timestamp": 1585577311.2747622, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8530758023262024, "Value Loss": 0.1621142029762268, "_runtime": 7395.94996714592, "_timestamp": 1585577311.7946005, "_step": 418}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": 2.7980170249938965, "Value Loss": 31.516441345214844, "_runtime": 7397.498020410538, "_timestamp": 1585577313.3426538, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8475608825683594, "Value Loss": 0.31109902262687683, "_runtime": 7398.347034692764, "_timestamp": 1585577314.191668, "_step": 420}
{"Episode reward": 46.79999999999952, "Episode length": 532, "Policy Loss": 0.843393087387085, "Value Loss": 17.047470092773438, "_runtime": 7399.840851306915, "_timestamp": 1585577315.6854846, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1128939390182495, "Value Loss": 0.028578920289874077, "_runtime": 7400.82927441597, "_timestamp": 1585577316.6739078, "_step": 422}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": 0.2236698716878891, "Value Loss": 14.893125534057617, "_runtime": 7402.334164857864, "_timestamp": 1585577318.1787982, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2168740034103394, "Value Loss": 0.0647299513220787, "_runtime": 7402.712210416794, "_timestamp": 1585577318.5568438, "_step": 424}
{"Episode reward": 78.69999999999997, "Episode length": 213, "Policy Loss": 3.013319969177246, "Value Loss": 44.0228385925293, "_runtime": 7403.919346809387, "_timestamp": 1585577319.7639802, "_step": 425}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": -0.5076748728752136, "Value Loss": 13.832509994506836, "_runtime": 7405.46191740036, "_timestamp": 1585577321.3065507, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9766034483909607, "Value Loss": 0.03856062889099121, "_runtime": 7406.890021562576, "_timestamp": 1585577322.734655, "_step": 427}
{"Episode reward": 3.900000000001185, "Episode length": 961, "Policy Loss": 0.27641406655311584, "Value Loss": 9.989059448242188, "_runtime": 7408.304794788361, "_timestamp": 1585577324.1494281, "_step": 428}
{"Episode reward": 8.300000000000935, "Episode length": 917, "Policy Loss": 0.49181562662124634, "Value Loss": 10.9233980178833, "_runtime": 7409.889357089996, "_timestamp": 1585577325.7339904, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5138805508613586, "Value Loss": 0.8894917964935303, "_runtime": 7411.414283275604, "_timestamp": 1585577327.2589166, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5443170666694641, "Value Loss": 0.492998868227005, "_runtime": 7412.95811009407, "_timestamp": 1585577328.8027434, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5538320541381836, "Value Loss": 0.16640110313892365, "_runtime": 7414.514211893082, "_timestamp": 1585577330.3588452, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.473128080368042, "Value Loss": 0.38604772090911865, "_runtime": 7416.069638490677, "_timestamp": 1585577331.9142718, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.522171676158905, "Value Loss": 0.15257342159748077, "_runtime": 7417.6254913806915, "_timestamp": 1585577333.4701247, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5935025215148926, "Value Loss": 0.1393938511610031, "_runtime": 7418.809128522873, "_timestamp": 1585577334.6537619, "_step": 435}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": 1.1701276302337646, "Value Loss": 12.828951835632324, "_runtime": 7420.057161331177, "_timestamp": 1585577335.9017947, "_step": 436}
{"Episode reward": 19.80000000000028, "Episode length": 802, "Policy Loss": 0.5571391582489014, "Value Loss": 12.31298542022705, "_runtime": 7421.61226940155, "_timestamp": 1585577337.4569027, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7489169239997864, "Value Loss": 0.37219130992889404, "_runtime": 7423.160751819611, "_timestamp": 1585577339.0053852, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7509473562240601, "Value Loss": 0.2764468491077423, "_runtime": 7423.839917421341, "_timestamp": 1585577339.6845508, "_step": 439}
{"Episode reward": 57.699999999999676, "Episode length": 423, "Policy Loss": 1.594919204711914, "Value Loss": 22.119714736938477, "_runtime": 7425.393112182617, "_timestamp": 1585577341.2377455, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7925886511802673, "Value Loss": 0.14337709546089172, "_runtime": 7426.530327320099, "_timestamp": 1585577342.3749607, "_step": 441}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.6074999570846558, "Value Loss": 13.259818077087402, "_runtime": 7427.649427652359, "_timestamp": 1585577343.494061, "_step": 442}
{"Episode reward": 25.699999999999946, "Episode length": 743, "Policy Loss": 0.5368680953979492, "Value Loss": 12.741955757141113, "_runtime": 7429.197237730026, "_timestamp": 1585577345.041871, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8105963468551636, "Value Loss": 0.061222855001688004, "_runtime": 7430.094018936157, "_timestamp": 1585577345.9386523, "_step": 444}
{"Episode reward": 42.991186523436966, "Episode length": 571, "Policy Loss": 0.9743810296058655, "Value Loss": 16.681568145751953, "_runtime": 7430.936586141586, "_timestamp": 1585577346.7812195, "_step": 445}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 1.0317151546478271, "Value Loss": 16.433502197265625, "_runtime": 7431.423336982727, "_timestamp": 1585577347.2679703, "_step": 446}
{"Episode reward": 71.19999999999987, "Episode length": 288, "Policy Loss": 2.6370151042938232, "Value Loss": 32.06453323364258, "_runtime": 7432.160737276077, "_timestamp": 1585577348.0053706, "_step": 447}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 1.4762324094772339, "Value Loss": 19.528362274169922, "_runtime": 7433.71860742569, "_timestamp": 1585577349.5632408, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9380741119384766, "Value Loss": 0.1821395754814148, "_runtime": 7434.56680226326, "_timestamp": 1585577350.4114356, "_step": 449}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.6728984117507935, "Value Loss": 17.056499481201172, "_runtime": 7435.464169740677, "_timestamp": 1585577351.308803, "_step": 450}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": 0.443362832069397, "Value Loss": 15.756654739379883, "_runtime": 7436.999160766602, "_timestamp": 1585577352.843794, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9641082286834717, "Value Loss": 0.03546769544482231, "_runtime": 7438.497896671295, "_timestamp": 1585577354.34253, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8932509422302246, "Value Loss": 0.023191748186945915, "_runtime": 7439.596767425537, "_timestamp": 1585577355.4414008, "_step": 453}
{"Episode reward": 28.499999999999787, "Episode length": 715, "Policy Loss": 0.4394713044166565, "Value Loss": 12.909881591796875, "_runtime": 7440.934821605682, "_timestamp": 1585577356.779455, "_step": 454}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": 0.3269009590148926, "Value Loss": 10.490640640258789, "_runtime": 7442.478913068771, "_timestamp": 1585577358.3235464, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7549750804901123, "Value Loss": 0.020359128713607788, "_runtime": 7443.643620252609, "_timestamp": 1585577359.4882536, "_step": 456}
{"Episode reward": 24.500000000000014, "Episode length": 755, "Policy Loss": 0.5958580374717712, "Value Loss": 11.964200019836426, "_runtime": 7445.178318023682, "_timestamp": 1585577361.0229514, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6947047710418701, "Value Loss": 0.06914173811674118, "_runtime": 7446.720874547958, "_timestamp": 1585577362.565508, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6838713884353638, "Value Loss": 0.05032223463058472, "_runtime": 7448.2536008358, "_timestamp": 1585577364.0982342, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5939462780952454, "Value Loss": 0.26792851090431213, "_runtime": 7449.80693936348, "_timestamp": 1585577365.6515727, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8124660849571228, "Value Loss": 0.8485679030418396, "_runtime": 7450.721586465836, "_timestamp": 1585577366.5662198, "_step": 461}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 1.0896531343460083, "Value Loss": 16.25786590576172, "_runtime": 7451.744506597519, "_timestamp": 1585577367.58914, "_step": 462}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.9046675562858582, "Value Loss": 14.265119552612305, "_runtime": 7452.888113737106, "_timestamp": 1585577368.732747, "_step": 463}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.8710166215896606, "Value Loss": 12.441490173339844, "_runtime": 7454.128478050232, "_timestamp": 1585577369.9731114, "_step": 464}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.4857248365879059, "Value Loss": 11.075064659118652, "_runtime": 7455.655011892319, "_timestamp": 1585577371.4996452, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7194584012031555, "Value Loss": 0.052489060908555984, "_runtime": 7457.211669445038, "_timestamp": 1585577373.0563028, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7778854370117188, "Value Loss": 0.0181796383112669, "_runtime": 7458.742673158646, "_timestamp": 1585577374.5873065, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7954091429710388, "Value Loss": 0.020264800637960434, "_runtime": 7460.304183959961, "_timestamp": 1585577376.1488173, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8321282267570496, "Value Loss": 0.0279270950704813, "_runtime": 7461.854096412659, "_timestamp": 1585577377.6987298, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8541726469993591, "Value Loss": 0.0099756745621562, "_runtime": 7463.117775917053, "_timestamp": 1585577378.9624093, "_step": 470}
{"Episode reward": 19.10000000000032, "Episode length": 809, "Policy Loss": 0.29062899947166443, "Value Loss": 11.561677932739258, "_runtime": 7464.684451580048, "_timestamp": 1585577380.529085, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8951451778411865, "Value Loss": 0.03437451645731926, "_runtime": 7465.668714284897, "_timestamp": 1585577381.5133476, "_step": 472}
{"Episode reward": 37.999999999999396, "Episode length": 620, "Policy Loss": 0.6315919160842896, "Value Loss": 14.583836555480957, "_runtime": 7466.165470123291, "_timestamp": 1585577382.0101035, "_step": 473}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 2.2563443183898926, "Value Loss": 30.15404510498047, "_runtime": 7467.616704702377, "_timestamp": 1585577383.461338, "_step": 474}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.05390928313136101, "Value Loss": 9.887706756591797, "_runtime": 7468.908826589584, "_timestamp": 1585577384.75346, "_step": 475}
{"Episode reward": 15.300000000000537, "Episode length": 847, "Policy Loss": 0.18616805970668793, "Value Loss": 11.255378723144531, "_runtime": 7470.392580270767, "_timestamp": 1585577386.2372136, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8987607359886169, "Value Loss": 0.01673407480120659, "_runtime": 7471.950229167938, "_timestamp": 1585577387.7948625, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8795972466468811, "Value Loss": 0.01003003865480423, "_runtime": 7472.9528868198395, "_timestamp": 1585577388.7975202, "_step": 478}
{"Episode reward": 35.199999999999406, "Episode length": 648, "Policy Loss": 0.7044955492019653, "Value Loss": 14.812882423400879, "_runtime": 7473.458579301834, "_timestamp": 1585577389.3032126, "_step": 479}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 2.3177366256713867, "Value Loss": 30.115211486816406, "_runtime": 7475.005832195282, "_timestamp": 1585577390.8504655, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8257350921630859, "Value Loss": 0.09161736816167831, "_runtime": 7476.536065578461, "_timestamp": 1585577392.380699, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8399056196212769, "Value Loss": 0.03247317299246788, "_runtime": 7478.029394626617, "_timestamp": 1585577393.874028, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7921956181526184, "Value Loss": 0.13058994710445404, "_runtime": 7478.699574708939, "_timestamp": 1585577394.544208, "_step": 483}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": 1.4719631671905518, "Value Loss": 21.67268943786621, "_runtime": 7479.609564065933, "_timestamp": 1585577395.4541974, "_step": 484}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 0.7641168832778931, "Value Loss": 16.006412506103516, "_runtime": 7481.186772823334, "_timestamp": 1585577397.0314062, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9041818976402283, "Value Loss": 0.06838513910770416, "_runtime": 7482.70983171463, "_timestamp": 1585577398.554465, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9324625730514526, "Value Loss": 0.03641930967569351, "_runtime": 7484.220155000687, "_timestamp": 1585577400.0647883, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9563956260681152, "Value Loss": 0.040528420358896255, "_runtime": 7485.571743965149, "_timestamp": 1585577401.4163773, "_step": 488}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": 0.037721410393714905, "Value Loss": 10.483196258544922, "_runtime": 7487.122072935104, "_timestamp": 1585577402.9667063, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.007486343383789, "Value Loss": 0.027119683101773262, "_runtime": 7488.683952331543, "_timestamp": 1585577404.5285857, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0403999090194702, "Value Loss": 0.040156248956918716, "_runtime": 7490.225478172302, "_timestamp": 1585577406.0701115, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0342864990234375, "Value Loss": 0.020937854424118996, "_runtime": 7491.526772975922, "_timestamp": 1585577407.3714063, "_step": 492}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.18215098977088928, "Value Loss": 11.065131187438965, "_runtime": 7493.090049505234, "_timestamp": 1585577408.9346828, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0241132974624634, "Value Loss": 0.027375955134630203, "_runtime": 7494.6549689769745, "_timestamp": 1585577410.4996023, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0115317106246948, "Value Loss": 0.018059713765978813, "_runtime": 7496.061574935913, "_timestamp": 1585577411.9062083, "_step": 495}
{"Episode reward": 9.700000000000855, "Episode length": 903, "Policy Loss": 0.07933755964040756, "Value Loss": 10.359562873840332, "_runtime": 7497.624709844589, "_timestamp": 1585577413.4693432, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0059914588928223, "Value Loss": 0.33739781379699707, "_runtime": 7498.513566732407, "_timestamp": 1585577414.3582, "_step": 497}
{"Episode reward": 44.199999999999484, "Episode length": 558, "Policy Loss": 0.7892007231712341, "Value Loss": 16.239301681518555, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489, 0.0002795825421344489]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-0.07233703136444092, -0.06971623003482819, -0.06709542870521545, -0.06447462737560272, -0.06185381859540939, -0.05923301726579666, -0.05661221593618393, -0.0539914146065712, -0.05137060955166817, -0.04874980449676514, -0.046129003167152405, -0.04350820183753967, -0.04088740050792694, -0.03826659545302391, -0.03564579412341118, -0.03302498906850815, -0.030404187738895416, -0.027783386409282684, -0.025162581354379654, -0.022541780024766922, -0.01992097496986389, -0.01730017364025116, -0.014679372310638428, -0.012058567255735397, -0.009437769651412964, -0.006816960871219635, -0.004196159541606903, -0.0015753582119941711, 0.0010454431176185608, 0.0036662444472312927, 0.006287053227424622, 0.008907854557037354, 0.011528655886650085, 0.014149457216262817, 0.01677025854587555, 0.019391067326068878, 0.02201186865568161, 0.024632669985294342, 0.027253471314907074, 0.029874272644519806, 0.032495081424713135, 0.03511588275432587, 0.0377366840839386, 0.04035748541355133, 0.04297828674316406, 0.045599088072776794, 0.04821989685297012, 0.050840698182582855, 0.05346149206161499, 0.056082308292388916, 0.05870310962200165, 0.06132391095161438, 0.06394471228122711, 0.06656551361083984, 0.06918631494045258, 0.07180711627006531, 0.07442791759967804, 0.07704871892929077, 0.0796695202589035, 0.08229033648967743, 0.08491113781929016, 0.0875319391489029, 0.09015274047851562, 0.09277354180812836, 0.09539434313774109]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [0.0, 4.186638034298085e-05, 8.37327606859617e-05, 0.00012559913739096373, 0.0001674655213719234, 0.00020933190535288304, 0.00025119827478192747, 0.0002930646587628871, 0.0003349310427438468, 0.00037679742672480643, 0.0004186638107057661, 0.00046053019468672574, 0.0005023965495638549, 0.0005442629335448146, 0.0005861293175257742, 0.0006279957015067339, 0.0006698620854876935, 0.0007117284694686532, 0.0007535948534496129, 0.0007954612374305725, 0.0008373276214115322, 0.0008791940053924918, 0.0009210603893734515, 0.0009629267733544111, 0.0010047930991277099, 0.0010466595413163304, 0.0010885258670896292, 0.0011303923092782497, 0.0011722586350515485, 0.001214125077240169, 0.0012559914030134678, 0.0012978578452020884, 0.001339724170975387, 0.0013815904967486858, 0.0014234569389373064, 0.0014653232647106051, 0.0015071897068992257, 0.0015490560326725245, 0.001590922474861145, 0.0016327888006344438, 0.0016746552428230643, 0.001716521568596363, 0.0017583880107849836, 0.0018002543365582824, 0.001842120778746903, 0.0018839871045202017, 0.0019258535467088223, 0.001967719988897443, 0.0020095861982554197, 0.0020514526404440403, 0.002093319082632661, 0.0021351852919906378, 0.0021770517341792583, 0.002218918176367879, 0.0022607846185564995, 0.0023026508279144764, 0.002344517270103097, 0.0023863837122917175, 0.002428250154480338, 0.002470116363838315, 0.0025119828060269356, 0.002553849248215556, 0.0025957156904041767, 0.0026375818997621536, 0.002679448341950774]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 4.0, 5.0, 5.0, 1.0, 6.0, 3.0, 12.0, 14.0, 25.0, 58.0, 115.0, 204.0, 1.0, 6.0, 7.0, 3.0, 1.0, 2.0, 0.0, 4.0, 2.0, 4.0, 6.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0], "bins": [-0.04017653316259384, -0.03888512775301933, -0.037593722343444824, -0.036302316933870316, -0.03501091152429581, -0.0337195098400116, -0.03242810443043709, -0.03113669902086258, -0.02984529361128807, -0.028553888201713562, -0.027262482792139053, -0.025971079245209694, -0.024679673835635185, -0.023388268426060677, -0.022096864879131317, -0.02080545946955681, -0.0195140540599823, -0.01822264865040779, -0.016931243240833282, -0.015639839693903923, -0.014348434284329414, -0.013057028874754906, -0.011765625327825546, -0.010474219918251038, -0.009182814508676529, -0.00789140909910202, -0.006600003689527512, -0.005308598279953003, -0.004017196595668793, -0.002725791186094284, -0.0014343857765197754, -0.00014298036694526672, 0.001148425042629242, 0.0024398304522037506, 0.0037312358617782593, 0.005022641271352768, 0.006314046680927277, 0.007605448365211487, 0.008896853774785995, 0.010188259184360504, 0.011479664593935013, 0.012771070003509521, 0.01406247541308403, 0.015353880822658539, 0.01664528250694275, 0.017936687916517258, 0.019228093326091766, 0.020519498735666275, 0.021810904145240784, 0.023102305829524994, 0.0243937149643898, 0.02568511664867401, 0.02697652578353882, 0.02826792746782303, 0.029559336602687836, 0.030850738286972046, 0.032142139971256256, 0.03343354910612106, 0.03472495079040527, 0.03601635992527008, 0.03730776160955429, 0.0385991707444191, 0.03989057242870331, 0.041181981563568115, 0.042473383247852325]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 2.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.10224466025829315, -0.09895492345094681, -0.09566517919301987, -0.09237544238567352, -0.08908570557832718, -0.08579596877098083, -0.0825062245130539, -0.07921648770570755, -0.0759267508983612, -0.07263700664043427, -0.06934726983308792, -0.06605753302574158, -0.06276778876781464, -0.05947805196046829, -0.05618831142783165, -0.052898574620485306, -0.04960883408784866, -0.04631909355521202, -0.04302935674786568, -0.039739616215229034, -0.03644987940788269, -0.03316013514995575, -0.029870398342609406, -0.02658066153526306, -0.02329091727733612, -0.020001180469989777, -0.016711443662643433, -0.013421706855297089, -0.010131962597370148, -0.006842225790023804, -0.0035524889826774597, -0.0002627447247505188, 0.003026992082595825, 0.006316728889942169, 0.00960647314786911, 0.012896209955215454, 0.016185946762561798, 0.01947569102048874, 0.022765427827835083, 0.026055172085762024, 0.02934490144252777, 0.03263464570045471, 0.03592438995838165, 0.0392141193151474, 0.04250386357307434, 0.04579360783100128, 0.04908333718776703, 0.05237308144569397, 0.05566282570362091, 0.05895255506038666, 0.0622422993183136, 0.06553202867507935, 0.06882177293300629, 0.07211151719093323, 0.07540124654769897, 0.07869099080562592, 0.08198073506355286, 0.0852704644203186, 0.08856020867824554, 0.09184995293617249, 0.09513968229293823, 0.09842942655086517, 0.10171917080879211, 0.10500890016555786, 0.1082986444234848]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 2.0, 1.0, 1.0, 0.0, 8.0, 25.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0], "bins": [-0.08807771652936935, -0.083452507853508, -0.07882730662822723, -0.07420209795236588, -0.06957688927650452, -0.06495168805122375, -0.060326479375362396, -0.055701274424791336, -0.051076069474220276, -0.046450864523649216, -0.041825659573078156, -0.0372004508972168, -0.03257524594664574, -0.027950040996074677, -0.023324832320213318, -0.018699631094932556, -0.014074422419071198, -0.009449213743209839, -0.004824012517929077, -0.0001988038420677185, 0.004426397383213043, 0.009051606059074402, 0.01367681473493576, 0.018302015960216522, 0.02292722463607788, 0.02755243331193924, 0.03217763453722, 0.03680284321308136, 0.04142805188894272, 0.04605325311422348, 0.05067845433950424, 0.0553036704659462, 0.05992887169122696, 0.06455407291650772, 0.06917928904294968, 0.07380449026823044, 0.0784296914935112, 0.08305490761995316, 0.08768010884523392, 0.09230531007051468, 0.09693051129579544, 0.1015557274222374, 0.10618092864751816, 0.11080612987279892, 0.11543134599924088, 0.12005654722452164, 0.1246817484498024, 0.12930697202682495, 0.1339321732521057, 0.13855737447738647, 0.14318257570266724, 0.147807776927948, 0.15243297815322876, 0.1570582091808319, 0.16168341040611267, 0.16630861163139343, 0.1709338128566742, 0.17555901408195496, 0.18018421530723572, 0.18480941653251648, 0.18943461775779724, 0.1940598487854004, 0.19868505001068115, 0.20331025123596191, 0.20793545246124268]}, "_runtime": 7500.074473142624, "_timestamp": 1585577415.9191065, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8654431700706482, "Value Loss": 0.07177188992500305, "_runtime": 7500.074473142624, "_timestamp": 1585577415.9191065, "_step": 499}
