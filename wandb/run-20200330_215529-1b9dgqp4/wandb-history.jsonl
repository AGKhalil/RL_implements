{"Episode reward": -33.61069245368061, "Episode length": 999, "Policy Loss": -0.03513503819704056, "Value Loss": 0.011335412040352821, "_runtime": 7978.905197381973, "_timestamp": 1585605348.5380669, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7784078121185303, "Value Loss": 187.21315002441406, "_runtime": 7980.3965792655945, "_timestamp": 1585605350.0294487, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.893324613571167, "Value Loss": 10968.3837890625, "_runtime": 7981.971627950668, "_timestamp": 1585605351.6044974, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.831997871398926, "Value Loss": 3243.643310546875, "_runtime": 7983.501653671265, "_timestamp": 1585605353.1345232, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -51.70665740966797, "Value Loss": 1723.444580078125, "_runtime": 7985.028204441071, "_timestamp": 1585605354.661074, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -58.61995315551758, "Value Loss": 2797.87890625, "_runtime": 7986.647987365723, "_timestamp": 1585605356.2808568, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -49.386348724365234, "Value Loss": 8997.5859375, "_runtime": 7988.200932025909, "_timestamp": 1585605357.8338015, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -30.86964225769043, "Value Loss": 2152.130615234375, "_runtime": 7989.719918251038, "_timestamp": 1585605359.3527877, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -27.5726318359375, "Value Loss": 49.30177688598633, "_runtime": 7991.290180444717, "_timestamp": 1585605360.92305, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -24.526262283325195, "Value Loss": 32.305912017822266, "_runtime": 7992.853448152542, "_timestamp": 1585605362.4863176, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -20.278486251831055, "Value Loss": 391.0764465332031, "_runtime": 7994.396001577377, "_timestamp": 1585605364.028871, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.793932914733887, "Value Loss": 464.2318420410156, "_runtime": 7995.975583314896, "_timestamp": 1585605365.6084528, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.749088764190674, "Value Loss": 21.196020126342773, "_runtime": 7997.543668746948, "_timestamp": 1585605367.1765382, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6696314811706543, "Value Loss": 5.089311122894287, "_runtime": 7999.104690313339, "_timestamp": 1585605368.7375598, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.294173240661621, "Value Loss": 87.43037414550781, "_runtime": 8000.689278125763, "_timestamp": 1585605370.3221476, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.321493148803711, "Value Loss": 27.243947982788086, "_runtime": 8002.262335777283, "_timestamp": 1585605371.8952053, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 16.6193904876709, "Value Loss": 449.9015197753906, "_runtime": 8003.824796676636, "_timestamp": 1585605373.4576662, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.186819076538086, "Value Loss": 104.27926635742188, "_runtime": 8005.404693841934, "_timestamp": 1585605375.0375633, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.1992130279541, "Value Loss": 183.1212615966797, "_runtime": 8006.977365493774, "_timestamp": 1585605376.610235, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.44133758544922, "Value Loss": 167.5875701904297, "_runtime": 8008.538017272949, "_timestamp": 1585605378.1708868, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.990093231201172, "Value Loss": 45.28170394897461, "_runtime": 8010.136149406433, "_timestamp": 1585605379.769019, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.485149383544922, "Value Loss": 38.85227966308594, "_runtime": 8011.7002766132355, "_timestamp": 1585605381.333146, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 17.65276336669922, "Value Loss": 35.04193878173828, "_runtime": 8013.265229701996, "_timestamp": 1585605382.8980992, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 16.532947540283203, "Value Loss": 56.03782653808594, "_runtime": 8014.840318918228, "_timestamp": 1585605384.4731884, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 14.703201293945312, "Value Loss": 8.001206398010254, "_runtime": 8016.413920879364, "_timestamp": 1585605386.0467904, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.078335762023926, "Value Loss": 70.43264770507812, "_runtime": 8017.981046199799, "_timestamp": 1585605387.6139157, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.491828918457031, "Value Loss": 36.892250061035156, "_runtime": 8019.545513153076, "_timestamp": 1585605389.1783826, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.110549926757812, "Value Loss": 36.227256774902344, "_runtime": 8021.100793123245, "_timestamp": 1585605390.7336626, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.95938777923584, "Value Loss": 19.327682495117188, "_runtime": 8022.654338121414, "_timestamp": 1585605392.2872076, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.837262153625488, "Value Loss": 10.207868576049805, "_runtime": 8024.231007814407, "_timestamp": 1585605393.8638773, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.585765838623047, "Value Loss": 79.99076843261719, "_runtime": 8025.784546375275, "_timestamp": 1585605395.4174159, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.71205997467041, "Value Loss": 46.57730484008789, "_runtime": 8027.339038848877, "_timestamp": 1585605396.9719083, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.05451488494873, "Value Loss": 6.435572624206543, "_runtime": 8028.91414141655, "_timestamp": 1585605398.547011, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.240930557250977, "Value Loss": 38.03065490722656, "_runtime": 8030.490041255951, "_timestamp": 1585605400.1229107, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.357383728027344, "Value Loss": 31.216964721679688, "_runtime": 8032.086571216583, "_timestamp": 1585605401.7194407, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.027685165405273, "Value Loss": 11.164689064025879, "_runtime": 8033.661859035492, "_timestamp": 1585605403.2947285, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.726919174194336, "Value Loss": 5.901839256286621, "_runtime": 8035.236644268036, "_timestamp": 1585605404.8695138, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.201797485351562, "Value Loss": 10.9872407913208, "_runtime": 8036.803118944168, "_timestamp": 1585605406.4359884, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.80005931854248, "Value Loss": 4.473133563995361, "_runtime": 8038.376425504684, "_timestamp": 1585605408.009295, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.301717758178711, "Value Loss": 2.982360601425171, "_runtime": 8039.950804233551, "_timestamp": 1585605409.5836737, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.58974552154541, "Value Loss": 4.965595245361328, "_runtime": 8041.507336854935, "_timestamp": 1585605411.1402063, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.331873893737793, "Value Loss": 21.359899520874023, "_runtime": 8043.075041055679, "_timestamp": 1585605412.7079105, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.904141426086426, "Value Loss": 23.104440689086914, "_runtime": 8044.6498827934265, "_timestamp": 1585605414.2827523, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.310275077819824, "Value Loss": 1.8514249324798584, "_runtime": 8046.21738576889, "_timestamp": 1585605415.8502553, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.954747676849365, "Value Loss": 22.574220657348633, "_runtime": 8047.793117284775, "_timestamp": 1585605417.4259868, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.40604305267334, "Value Loss": 38.776222229003906, "_runtime": 8049.369213819504, "_timestamp": 1585605419.0020833, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.865126609802246, "Value Loss": 6.397810935974121, "_runtime": 8050.9281895160675, "_timestamp": 1585605420.561059, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.30478048324585, "Value Loss": 0.8792098164558411, "_runtime": 8052.50222826004, "_timestamp": 1585605422.1350977, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.73884391784668, "Value Loss": 2.8506321907043457, "_runtime": 8054.077379226685, "_timestamp": 1585605423.7102487, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.367096424102783, "Value Loss": 0.33801257610321045, "_runtime": 8055.679242372513, "_timestamp": 1585605425.3121119, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.90185022354126, "Value Loss": 1.4725995063781738, "_runtime": 8057.253635168076, "_timestamp": 1585605426.8865047, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.507806301116943, "Value Loss": 0.2038363367319107, "_runtime": 8058.820478439331, "_timestamp": 1585605428.453348, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.126987934112549, "Value Loss": 0.3357507884502411, "_runtime": 8060.380011081696, "_timestamp": 1585605430.0128806, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.7737112045288086, "Value Loss": 0.19158169627189636, "_runtime": 8061.944987297058, "_timestamp": 1585605431.5778568, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.45208740234375, "Value Loss": 0.5543742179870605, "_runtime": 8063.519136190414, "_timestamp": 1585605433.1520057, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.1631882190704346, "Value Loss": 0.18061445653438568, "_runtime": 8065.088270902634, "_timestamp": 1585605434.7211404, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.866950273513794, "Value Loss": 0.08591611683368683, "_runtime": 8066.664927244186, "_timestamp": 1585605436.2977967, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6720829010009766, "Value Loss": 0.3202158510684967, "_runtime": 8068.239723920822, "_timestamp": 1585605437.8725934, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3975613117218018, "Value Loss": 0.20442207157611847, "_runtime": 8069.8081929683685, "_timestamp": 1585605439.4410625, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1564316749572754, "Value Loss": 0.2097540646791458, "_runtime": 8071.382791757584, "_timestamp": 1585605441.0156612, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9436908960342407, "Value Loss": 0.03748107701539993, "_runtime": 8072.95666718483, "_timestamp": 1585605442.5895367, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7940917015075684, "Value Loss": 0.1146470308303833, "_runtime": 8074.523866415024, "_timestamp": 1585605444.156736, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5926578044891357, "Value Loss": 0.17370040714740753, "_runtime": 8076.098437309265, "_timestamp": 1585605445.7313068, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.419332504272461, "Value Loss": 0.019365420565009117, "_runtime": 8077.672966241837, "_timestamp": 1585605447.3058357, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3324898481369019, "Value Loss": 0.8645424246788025, "_runtime": 8079.278679132462, "_timestamp": 1585605448.9115486, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2193896770477295, "Value Loss": 1.195204496383667, "_runtime": 8080.842401027679, "_timestamp": 1585605450.4752705, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0901460647583008, "Value Loss": 0.11514222621917725, "_runtime": 8082.416183233261, "_timestamp": 1585605452.0490527, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8839241862297058, "Value Loss": 0.014117846265435219, "_runtime": 8083.975134849548, "_timestamp": 1585605453.6080043, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8138856291770935, "Value Loss": 0.4923168122768402, "_runtime": 8085.538534641266, "_timestamp": 1585605455.1714041, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6974300742149353, "Value Loss": 0.2227368801832199, "_runtime": 8087.101913928986, "_timestamp": 1585605456.7347834, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6629241704940796, "Value Loss": 1.169177770614624, "_runtime": 8088.660630226135, "_timestamp": 1585605458.2934997, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5719637870788574, "Value Loss": 0.4058298170566559, "_runtime": 8090.223701238632, "_timestamp": 1585605459.8565707, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4063856899738312, "Value Loss": 0.02511213906109333, "_runtime": 8091.796239852905, "_timestamp": 1585605461.4291093, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.35256773233413696, "Value Loss": 0.009273265488445759, "_runtime": 8093.356148719788, "_timestamp": 1585605462.9890182, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30603426694869995, "Value Loss": 0.40696659684181213, "_runtime": 8094.926490783691, "_timestamp": 1585605464.5593603, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2291308045387268, "Value Loss": 0.09560827165842056, "_runtime": 8096.498692035675, "_timestamp": 1585605466.1315615, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1885196715593338, "Value Loss": 0.18206189572811127, "_runtime": 8098.060345172882, "_timestamp": 1585605467.6932147, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18068616092205048, "Value Loss": 0.8332495093345642, "_runtime": 8099.633206367493, "_timestamp": 1585605469.2660758, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09244346618652344, "Value Loss": 0.3324747681617737, "_runtime": 8101.205928325653, "_timestamp": 1585605470.8387978, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05976537615060806, "Value Loss": 0.3790489435195923, "_runtime": 8102.8132491111755, "_timestamp": 1585605472.4461186, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0071746851317584515, "Value Loss": 0.011330210603773594, "_runtime": 8104.388510942459, "_timestamp": 1585605474.0213804, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03752770647406578, "Value Loss": 0.835342288017273, "_runtime": 8105.96227312088, "_timestamp": 1585605475.5951426, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0605606809258461, "Value Loss": 0.026311419904232025, "_runtime": 8107.531015634537, "_timestamp": 1585605477.163885, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011937955394387245, "Value Loss": 0.5407246947288513, "_runtime": 8109.106057405472, "_timestamp": 1585605478.738927, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05232604220509529, "Value Loss": 0.5546509027481079, "_runtime": 8110.67999792099, "_timestamp": 1585605480.3128674, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12699569761753082, "Value Loss": 0.022520575672388077, "_runtime": 8112.252938985825, "_timestamp": 1585605481.8858085, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14338158071041107, "Value Loss": 0.05714830756187439, "_runtime": 8113.826514482498, "_timestamp": 1585605483.459384, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1721676141023636, "Value Loss": 0.020661672577261925, "_runtime": 8115.402325868607, "_timestamp": 1585605485.0351954, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19064287841320038, "Value Loss": 0.017147520557045937, "_runtime": 8116.96733880043, "_timestamp": 1585605486.6002083, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18296247720718384, "Value Loss": 0.15641848742961884, "_runtime": 8118.543991804123, "_timestamp": 1585605488.1768613, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15113529562950134, "Value Loss": 0.6259192228317261, "_runtime": 8120.116728067398, "_timestamp": 1585605489.7495975, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2276856005191803, "Value Loss": 0.010088372975587845, "_runtime": 8121.688184022903, "_timestamp": 1585605491.3210535, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21866895258426666, "Value Loss": 0.48139214515686035, "_runtime": 8123.249947071075, "_timestamp": 1585605492.8828166, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26131221652030945, "Value Loss": 0.0404171459376812, "_runtime": 8124.823420763016, "_timestamp": 1585605494.4562902, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2747825086116791, "Value Loss": 0.1115877777338028, "_runtime": 8126.432008743286, "_timestamp": 1585605496.0648782, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25086113810539246, "Value Loss": 0.8202484250068665, "_runtime": 8128.004829883575, "_timestamp": 1585605497.6376994, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3181735873222351, "Value Loss": 0.03721559792757034, "_runtime": 8129.577275276184, "_timestamp": 1585605499.2101448, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3168337047100067, "Value Loss": 0.35301873087882996, "_runtime": 8131.143749713898, "_timestamp": 1585605500.7766192, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3542131185531616, "Value Loss": 0.11266061663627625, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8132.716977596283, "_timestamp": 1585605502.349847, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3756895661354065, "Value Loss": 0.05921018496155739, "_runtime": 8134.277854681015, "_timestamp": 1585605503.9107242, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36310282349586487, "Value Loss": 0.39161863923072815, "_runtime": 8135.842326641083, "_timestamp": 1585605505.4751961, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4020223915576935, "Value Loss": 0.11808282881975174, "_runtime": 8137.413462877274, "_timestamp": 1585605507.0463324, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39458218216896057, "Value Loss": 0.4420009255409241, "_runtime": 8138.984534263611, "_timestamp": 1585605508.6174037, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44734102487564087, "Value Loss": 0.1468544453382492, "_runtime": 8140.549989461899, "_timestamp": 1585605510.182859, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4584910571575165, "Value Loss": 0.06606879830360413, "_runtime": 8142.121339559555, "_timestamp": 1585605511.754209, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4152926206588745, "Value Loss": 0.32733431458473206, "_runtime": 8143.6915447711945, "_timestamp": 1585605513.3244143, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45324984192848206, "Value Loss": 0.03425511717796326, "_runtime": 8145.260187149048, "_timestamp": 1585605514.8930566, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4526054561138153, "Value Loss": 0.06428312510251999, "_runtime": 8146.831123590469, "_timestamp": 1585605516.463993, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44409695267677307, "Value Loss": 0.08819128572940826, "_runtime": 8148.439408540726, "_timestamp": 1585605518.072278, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41045287251472473, "Value Loss": 0.1375340074300766, "_runtime": 8149.9939839839935, "_timestamp": 1585605519.6268535, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4421279728412628, "Value Loss": 0.005489441566169262, "_runtime": 8151.567810058594, "_timestamp": 1585605521.2006795, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4223991930484772, "Value Loss": 0.07649334520101547, "_runtime": 8153.140965938568, "_timestamp": 1585605522.7738354, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42482826113700867, "Value Loss": 0.033583369106054306, "_runtime": 8154.710127353668, "_timestamp": 1585605524.3429968, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4001557230949402, "Value Loss": 0.31892794370651245, "_runtime": 8156.280854463577, "_timestamp": 1585605525.913724, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39746445417404175, "Value Loss": 0.08647356182336807, "_runtime": 8157.842391967773, "_timestamp": 1585605527.4752614, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42241814732551575, "Value Loss": 0.04124831035733223, "_runtime": 8159.401732206345, "_timestamp": 1585605529.0346017, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.434745728969574, "Value Loss": 0.005042086821049452, "_runtime": 8160.973061084747, "_timestamp": 1585605530.6059306, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43113046884536743, "Value Loss": 0.013184133917093277, "_runtime": 8162.5443506240845, "_timestamp": 1585605532.17722, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4012221693992615, "Value Loss": 0.13546045124530792, "_runtime": 8164.101006031036, "_timestamp": 1585605533.7338755, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4204593300819397, "Value Loss": 0.006850750185549259, "_runtime": 8165.685098648071, "_timestamp": 1585605535.3179681, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43152064085006714, "Value Loss": 0.004166685976088047, "_runtime": 8167.2562510967255, "_timestamp": 1585605536.8891206, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4297386705875397, "Value Loss": 0.051379404962062836, "_runtime": 8168.8248608112335, "_timestamp": 1585605538.4577303, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43040964007377625, "Value Loss": 0.050981804728507996, "_runtime": 8170.38831949234, "_timestamp": 1585605540.021189, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4326172471046448, "Value Loss": 0.02057013288140297, "_runtime": 8171.995635032654, "_timestamp": 1585605541.6285045, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4294128119945526, "Value Loss": 0.05229579657316208, "_runtime": 8173.550019741058, "_timestamp": 1585605543.1828892, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4162760376930237, "Value Loss": 0.022910673171281815, "_runtime": 8175.120348215103, "_timestamp": 1585605544.7532177, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4418427646160126, "Value Loss": 0.008091593161225319, "_runtime": 8176.689775943756, "_timestamp": 1585605546.3226454, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41877442598342896, "Value Loss": 0.17830894887447357, "_runtime": 8178.252683162689, "_timestamp": 1585605547.8855526, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43298375606536865, "Value Loss": 0.16345083713531494, "_runtime": 8179.815705060959, "_timestamp": 1585605549.4485745, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4472936689853668, "Value Loss": 0.012984445318579674, "_runtime": 8181.377277135849, "_timestamp": 1585605551.0101466, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4479706585407257, "Value Loss": 0.04751352593302727, "_runtime": 8182.9332365989685, "_timestamp": 1585605552.566106, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45932257175445557, "Value Loss": 0.032645437866449356, "_runtime": 8184.495388507843, "_timestamp": 1585605554.128258, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45933282375335693, "Value Loss": 0.04674550145864487, "_runtime": 8186.052446603775, "_timestamp": 1585605555.685316, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4687616229057312, "Value Loss": 0.03130481019616127, "_runtime": 8187.617805719376, "_timestamp": 1585605557.2506752, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4660654664039612, "Value Loss": 0.02778376080095768, "_runtime": 8189.185748577118, "_timestamp": 1585605558.818618, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45318374037742615, "Value Loss": 0.1007111668586731, "_runtime": 8190.755106449127, "_timestamp": 1585605560.387976, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4427092671394348, "Value Loss": 0.14774833619594574, "_runtime": 8192.325032949448, "_timestamp": 1585605561.9579024, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4578399360179901, "Value Loss": 0.005163065157830715, "_runtime": 8193.89668726921, "_timestamp": 1585605563.5295568, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4493182599544525, "Value Loss": 0.051609400659799576, "_runtime": 8195.504655361176, "_timestamp": 1585605565.1375248, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45398542284965515, "Value Loss": 0.020373394712805748, "_runtime": 8197.069787740707, "_timestamp": 1585605566.7026572, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4475962221622467, "Value Loss": 0.015983153134584427, "_runtime": 8198.64204454422, "_timestamp": 1585605568.274914, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43325722217559814, "Value Loss": 0.038432151079177856, "_runtime": 8200.206135749817, "_timestamp": 1585605569.8390052, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4253045320510864, "Value Loss": 0.04460658133029938, "_runtime": 8201.766191720963, "_timestamp": 1585605571.3990612, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.427423894405365, "Value Loss": 0.006249218713492155, "_runtime": 8203.341567277908, "_timestamp": 1585605572.9744368, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40996718406677246, "Value Loss": 0.06267710775136948, "_runtime": 8204.900744915009, "_timestamp": 1585605574.5336144, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41884157061576843, "Value Loss": 0.0016938075423240662, "_runtime": 8206.450052261353, "_timestamp": 1585605576.0829217, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39366260170936584, "Value Loss": 0.04862351343035698, "_runtime": 8208.017448186874, "_timestamp": 1585605577.6503177, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40532514452934265, "Value Loss": 0.006235093809664249, "_runtime": 8209.600314855576, "_timestamp": 1585605579.2331843, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3851740062236786, "Value Loss": 0.02616131864488125, "_runtime": 8211.163718700409, "_timestamp": 1585605580.7965882, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39466041326522827, "Value Loss": 0.006471065804362297, "_runtime": 8212.739727973938, "_timestamp": 1585605582.3725975, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3895461857318878, "Value Loss": 0.006896642502397299, "_runtime": 8214.32043004036, "_timestamp": 1585605583.9532995, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3844696581363678, "Value Loss": 0.006341483909636736, "_runtime": 8215.88832950592, "_timestamp": 1585605585.521199, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3815646767616272, "Value Loss": 0.0021456293761730194, "_runtime": 8217.466385126114, "_timestamp": 1585605587.0992546, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36784541606903076, "Value Loss": 0.05226675420999527, "_runtime": 8219.071043014526, "_timestamp": 1585605588.7039125, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36946216225624084, "Value Loss": 0.011164392344653606, "_runtime": 8220.635823726654, "_timestamp": 1585605590.2686932, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3736484944820404, "Value Loss": 0.0016728013288229704, "_runtime": 8222.215185880661, "_timestamp": 1585605591.8480554, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3698374927043915, "Value Loss": 0.0036693799775093794, "_runtime": 8223.7914352417, "_timestamp": 1585605593.4243047, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3612889349460602, "Value Loss": 0.01574307680130005, "_runtime": 8225.368655920029, "_timestamp": 1585605595.0015254, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3565562963485718, "Value Loss": 0.012129588052630424, "_runtime": 8226.947386980057, "_timestamp": 1585605596.5802565, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3503645956516266, "Value Loss": 0.030837776139378548, "_runtime": 8228.523855924606, "_timestamp": 1585605598.1567254, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3422900438308716, "Value Loss": 0.053653351962566376, "_runtime": 8230.100942373276, "_timestamp": 1585605599.7338119, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3495843708515167, "Value Loss": 0.0065192487090826035, "_runtime": 8231.660058498383, "_timestamp": 1585605601.292928, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32862013578414917, "Value Loss": 0.05529375001788139, "_runtime": 8233.23949790001, "_timestamp": 1585605602.8723674, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34183675050735474, "Value Loss": 0.006034174468368292, "_runtime": 8234.812627315521, "_timestamp": 1585605604.4454968, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33826297521591187, "Value Loss": 0.0011450269958004355, "_runtime": 8236.38025689125, "_timestamp": 1585605606.0131264, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32890763878822327, "Value Loss": 0.010159401223063469, "_runtime": 8237.947838306427, "_timestamp": 1585605607.5807078, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3062797486782074, "Value Loss": 0.0586538091301918, "_runtime": 8239.514558792114, "_timestamp": 1585605609.1474283, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3101555407047272, "Value Loss": 0.010515925474464893, "_runtime": 8241.12024140358, "_timestamp": 1585605610.753111, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3037957549095154, "Value Loss": 0.024281179532408714, "_runtime": 8242.676440238953, "_timestamp": 1585605612.3093097, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3060840666294098, "Value Loss": 0.003927622456103563, "_runtime": 8244.243266105652, "_timestamp": 1585605613.8761356, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2830798923969269, "Value Loss": 0.07680656760931015, "_runtime": 8245.815321683884, "_timestamp": 1585605615.4481912, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2884190082550049, "Value Loss": 0.005386218894273043, "_runtime": 8247.38592839241, "_timestamp": 1585605617.0187979, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2729628384113312, "Value Loss": 0.06919332593679428, "_runtime": 8248.942747354507, "_timestamp": 1585605618.5756168, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26619088649749756, "Value Loss": 0.030569350346922874, "_runtime": 8250.50185084343, "_timestamp": 1585605620.1347203, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2613435685634613, "Value Loss": 0.0484490767121315, "_runtime": 8252.069880247116, "_timestamp": 1585605621.7027497, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.267374724149704, "Value Loss": 0.009592540562152863, "_runtime": 8253.63847899437, "_timestamp": 1585605623.2713485, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26830196380615234, "Value Loss": 0.003965372685343027, "_runtime": 8255.209686517715, "_timestamp": 1585605624.842556, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25828686356544495, "Value Loss": 0.013860801234841347, "_runtime": 8256.780468702316, "_timestamp": 1585605626.4133382, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25799062848091125, "Value Loss": 0.006212805863469839, "_runtime": 8258.34679055214, "_timestamp": 1585605627.97966, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23803843557834625, "Value Loss": 0.0470258891582489, "_runtime": 8259.918568134308, "_timestamp": 1585605629.5514376, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23861970007419586, "Value Loss": 0.03411249816417694, "_runtime": 8261.480246067047, "_timestamp": 1585605631.1131155, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2461039274930954, "Value Loss": 0.0066426899284124374, "_runtime": 8263.048090696335, "_timestamp": 1585605632.6809602, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24256469309329987, "Value Loss": 0.0009793451754376292, "_runtime": 8264.657843828201, "_timestamp": 1585605634.2907133, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22562657296657562, "Value Loss": 0.04107397422194481, "_runtime": 8266.216943025589, "_timestamp": 1585605635.8498125, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22207334637641907, "Value Loss": 0.036176107823848724, "_runtime": 8267.784374713898, "_timestamp": 1585605637.4172442, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23248939216136932, "Value Loss": 0.004200270865112543, "_runtime": 8269.357340097427, "_timestamp": 1585605638.9902096, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22759507596492767, "Value Loss": 0.0031447848305106163, "_runtime": 8270.924689769745, "_timestamp": 1585605640.5575593, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21652178466320038, "Value Loss": 0.05750325322151184, "_runtime": 8272.4936439991, "_timestamp": 1585605642.1265135, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22254744172096252, "Value Loss": 0.0014261070173233747, "_runtime": 8274.066772460938, "_timestamp": 1585605643.699642, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21925705671310425, "Value Loss": 0.01368732750415802, "_runtime": 8275.634107351303, "_timestamp": 1585605645.2669768, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.218308225274086, "Value Loss": 0.004891806747764349, "_runtime": 8277.192823648453, "_timestamp": 1585605646.8256931, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2120259553194046, "Value Loss": 0.004493311513215303, "_runtime": 8278.765282154083, "_timestamp": 1585605648.3981516, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22124207019805908, "Value Loss": 0.0021258925553411245, "_runtime": 8280.324863910675, "_timestamp": 1585605649.9577334, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22094711661338806, "Value Loss": 0.002058169338852167, "_runtime": 8281.884378433228, "_timestamp": 1585605651.517248, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2147572636604309, "Value Loss": 0.01623324118554592, "_runtime": 8283.448953866959, "_timestamp": 1585605653.0818233, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2165805995464325, "Value Loss": 0.005850601010024548, "_runtime": 8285.008517742157, "_timestamp": 1585605654.6413872, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2171822488307953, "Value Loss": 0.0016795095289126039, "_runtime": 8286.576741933823, "_timestamp": 1585605656.2096114, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21631750464439392, "Value Loss": 0.00046577583998441696, "_runtime": 8288.182518959045, "_timestamp": 1585605657.8153884, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20669591426849365, "Value Loss": 0.02482188493013382, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8289.751007080078, "_timestamp": 1585605659.3838766, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21365350484848022, "Value Loss": 0.0021859558764845133, "_runtime": 8291.320134401321, "_timestamp": 1585605660.953004, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2122737020254135, "Value Loss": 0.0023095461074262857, "_runtime": 8292.880467176437, "_timestamp": 1585605662.5133367, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19905373454093933, "Value Loss": 0.030880415812134743, "_runtime": 8294.453067064285, "_timestamp": 1585605664.0859365, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20529207587242126, "Value Loss": 0.002343317959457636, "_runtime": 8296.020341396332, "_timestamp": 1585605665.6532109, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20223906636238098, "Value Loss": 0.003169470001012087, "_runtime": 8297.592576265335, "_timestamp": 1585605667.2254457, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1899484544992447, "Value Loss": 0.042539387941360474, "_runtime": 8299.149953842163, "_timestamp": 1585605668.7828233, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18884941935539246, "Value Loss": 0.010341508314013481, "_runtime": 8300.72253537178, "_timestamp": 1585605670.3554049, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19428502023220062, "Value Loss": 0.0004703429585788399, "_runtime": 8302.295374631882, "_timestamp": 1585605671.928244, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18960651755332947, "Value Loss": 0.0010276982793584466, "_runtime": 8303.86440205574, "_timestamp": 1585605673.4972715, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18370544910430908, "Value Loss": 0.0028452894184738398, "_runtime": 8305.430725812912, "_timestamp": 1585605675.0635953, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17483019828796387, "Value Loss": 0.008930507116019726, "_runtime": 8306.993147611618, "_timestamp": 1585605676.626017, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17795023322105408, "Value Loss": 0.0005522497231140733, "_runtime": 8308.565185785294, "_timestamp": 1585605678.1980553, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1709025353193283, "Value Loss": 0.0011843173997476697, "_runtime": 8310.13303899765, "_timestamp": 1585605679.7659085, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1655668318271637, "Value Loss": 0.005323151126503944, "_runtime": 8311.743310689926, "_timestamp": 1585605681.3761802, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16861200332641602, "Value Loss": 0.0005730141419917345, "_runtime": 8313.317450284958, "_timestamp": 1585605682.9503198, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15289562940597534, "Value Loss": 0.015203013084828854, "_runtime": 8314.876635789871, "_timestamp": 1585605684.5095053, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15857648849487305, "Value Loss": 0.005030137486755848, "_runtime": 8316.447234153748, "_timestamp": 1585605686.0801036, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14681042730808258, "Value Loss": 0.03380269929766655, "_runtime": 8318.017827510834, "_timestamp": 1585605687.650697, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1555313616991043, "Value Loss": 0.00040932020056061447, "_runtime": 8319.577784776688, "_timestamp": 1585605689.2106543, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.149314284324646, "Value Loss": 0.0053795804269611835, "_runtime": 8321.139677524567, "_timestamp": 1585605690.772547, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14536304771900177, "Value Loss": 0.0019676825031638145, "_runtime": 8322.698944091797, "_timestamp": 1585605692.3318136, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14245107769966125, "Value Loss": 0.003179923864081502, "_runtime": 8324.26924610138, "_timestamp": 1585605693.9021156, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13843606412410736, "Value Loss": 0.0026269566733390093, "_runtime": 8325.842609405518, "_timestamp": 1585605695.475479, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12304412573575974, "Value Loss": 0.014374672435224056, "_runtime": 8327.414983034134, "_timestamp": 1585605697.0478525, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1280064880847931, "Value Loss": 0.005276728421449661, "_runtime": 8328.981716871262, "_timestamp": 1585605698.6145864, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1267797201871872, "Value Loss": 0.0017478977097198367, "_runtime": 8330.543182849884, "_timestamp": 1585605700.1760523, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11237666755914688, "Value Loss": 0.01259035523980856, "_runtime": 8332.100125312805, "_timestamp": 1585605701.7329948, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11580011993646622, "Value Loss": 0.01310393400490284, "_runtime": 8333.668596744537, "_timestamp": 1585605703.3014662, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1158672645688057, "Value Loss": 0.0060716294683516026, "_runtime": 8335.275832176208, "_timestamp": 1585605704.9087017, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11551467329263687, "Value Loss": 0.0010091461008414626, "_runtime": 8336.846401691437, "_timestamp": 1585605706.4792712, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1046532541513443, "Value Loss": 0.018264180049300194, "_runtime": 8338.411693811417, "_timestamp": 1585605708.0445633, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10573874413967133, "Value Loss": 0.02219991944730282, "_runtime": 8339.97350859642, "_timestamp": 1585605709.606378, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11179810017347336, "Value Loss": 0.0008478888776153326, "_runtime": 8341.532560825348, "_timestamp": 1585605711.1654303, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1125158742070198, "Value Loss": 0.0012745701242238283, "_runtime": 8343.091976165771, "_timestamp": 1585605712.7248456, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10905395448207855, "Value Loss": 0.004992909729480743, "_runtime": 8344.665490865707, "_timestamp": 1585605714.2983603, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10897649079561234, "Value Loss": 0.004041389562189579, "_runtime": 8346.221865177155, "_timestamp": 1585605715.8547347, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10533840954303741, "Value Loss": 0.016031116247177124, "_runtime": 8347.789057731628, "_timestamp": 1585605717.4219272, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11266423016786575, "Value Loss": 0.0006117346929386258, "_runtime": 8349.362560987473, "_timestamp": 1585605718.9954305, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10271691530942917, "Value Loss": 0.010715873911976814, "_runtime": 8350.935199737549, "_timestamp": 1585605720.5680692, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1117292270064354, "Value Loss": 0.0019510677084326744, "_runtime": 8352.491090774536, "_timestamp": 1585605722.1239603, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10543686896562576, "Value Loss": 0.015643417835235596, "_runtime": 8354.063520431519, "_timestamp": 1585605723.69639, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1126146987080574, "Value Loss": 0.00014013297914061695, "_runtime": 8355.6343832016, "_timestamp": 1585605725.2672527, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10421459376811981, "Value Loss": 0.014958981424570084, "_runtime": 8357.239533662796, "_timestamp": 1585605726.8724031, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10552878677845001, "Value Loss": 0.00615337211638689, "_runtime": 8358.800309419632, "_timestamp": 1585605728.433179, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10974281281232834, "Value Loss": 0.0015860472340136766, "_runtime": 8360.370473384857, "_timestamp": 1585605730.0033429, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10722603648900986, "Value Loss": 0.002972833113744855, "_runtime": 8361.941445589066, "_timestamp": 1585605731.574315, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10798255354166031, "Value Loss": 0.0013239922700449824, "_runtime": 8363.518500804901, "_timestamp": 1585605733.1513703, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10789546370506287, "Value Loss": 0.0005711099365726113, "_runtime": 8365.086907625198, "_timestamp": 1585605734.719777, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10473986715078354, "Value Loss": 0.0012613281141966581, "_runtime": 8366.642709732056, "_timestamp": 1585605736.2755792, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10148090124130249, "Value Loss": 0.002722798613831401, "_runtime": 8368.214500427246, "_timestamp": 1585605737.84737, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10118059068918228, "Value Loss": 0.0010093911550939083, "_runtime": 8369.787205457687, "_timestamp": 1585605739.420075, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09881790727376938, "Value Loss": 0.0010723278392106295, "_runtime": 8371.35292673111, "_timestamp": 1585605740.9857962, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08786143362522125, "Value Loss": 0.02042865939438343, "_runtime": 8372.926977872849, "_timestamp": 1585605742.5598474, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09067706018686295, "Value Loss": 0.0033010065089911222, "_runtime": 8374.495648145676, "_timestamp": 1585605744.1285176, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08296278864145279, "Value Loss": 0.008061605505645275, "_runtime": 8376.051864147186, "_timestamp": 1585605745.6847336, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0778757855296135, "Value Loss": 0.019207065925002098, "_runtime": 8377.623689174652, "_timestamp": 1585605747.2565587, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08263766020536423, "Value Loss": 0.0005136330146342516, "_runtime": 8379.194635152817, "_timestamp": 1585605748.8275046, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07228584587574005, "Value Loss": 0.0004568152653519064, "_runtime": 8380.78661108017, "_timestamp": 1585605750.4194806, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07011294364929199, "Value Loss": 0.013132975436747074, "_runtime": 8382.358346700668, "_timestamp": 1585605751.9912162, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07263730466365814, "Value Loss": 0.0008663292392157018, "_runtime": 8383.91535282135, "_timestamp": 1585605753.5482223, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07139714807271957, "Value Loss": 0.0006167353130877018, "_runtime": 8385.483121871948, "_timestamp": 1585605755.1159914, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06526636332273483, "Value Loss": 0.005765722133219242, "_runtime": 8387.05273938179, "_timestamp": 1585605756.6856089, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0679708942770958, "Value Loss": 0.0005046244477853179, "_runtime": 8388.62349319458, "_timestamp": 1585605758.2563627, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06377555429935455, "Value Loss": 0.0032604248262941837, "_runtime": 8390.190159082413, "_timestamp": 1585605759.8230286, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05720727890729904, "Value Loss": 0.004655900411307812, "_runtime": 8391.762395381927, "_timestamp": 1585605761.3952649, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.060860488563776016, "Value Loss": 0.003276105271652341, "_runtime": 8393.331232070923, "_timestamp": 1585605762.9641016, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0560174323618412, "Value Loss": 0.009926749393343925, "_runtime": 8394.902688741684, "_timestamp": 1585605764.5355582, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.060992710292339325, "Value Loss": 0.0004805837816093117, "_runtime": 8396.471863985062, "_timestamp": 1585605766.1047335, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05691278725862503, "Value Loss": 0.011121978051960468, "_runtime": 8398.042397260666, "_timestamp": 1585605767.6752667, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.061876777559518814, "Value Loss": 0.0015239074127748609, "_runtime": 8399.609331607819, "_timestamp": 1585605769.242201, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06008372828364372, "Value Loss": 0.002033503260463476, "_runtime": 8401.184092521667, "_timestamp": 1585605770.816962, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06187839061021805, "Value Loss": 0.001588495448231697, "_runtime": 8402.752333641052, "_timestamp": 1585605772.3852031, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06175455078482628, "Value Loss": 0.002119846409186721, "_runtime": 8404.356385469437, "_timestamp": 1585605773.989255, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06335746496915817, "Value Loss": 0.0007923056837171316, "_runtime": 8405.92674779892, "_timestamp": 1585605775.5596173, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06010832265019417, "Value Loss": 0.0034942030906677246, "_runtime": 8407.487862586975, "_timestamp": 1585605777.120732, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05577055737376213, "Value Loss": 0.017147477716207504, "_runtime": 8409.053586006165, "_timestamp": 1585605778.6864555, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06224621832370758, "Value Loss": 0.0012729102745652199, "_runtime": 8410.616927862167, "_timestamp": 1585605780.2497973, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.060211386531591415, "Value Loss": 0.002883440814912319, "_runtime": 8412.187726974487, "_timestamp": 1585605781.8205965, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05976766347885132, "Value Loss": 0.0017707968363538384, "_runtime": 8413.753660678864, "_timestamp": 1585605783.3865302, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05714958906173706, "Value Loss": 0.0030383497942239046, "_runtime": 8415.313886642456, "_timestamp": 1585605784.9467561, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0579630583524704, "Value Loss": 0.0010939134517684579, "_runtime": 8416.884857654572, "_timestamp": 1585605786.5177271, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05733080953359604, "Value Loss": 0.0002737556351348758, "_runtime": 8418.438840389252, "_timestamp": 1585605788.0717099, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05495234206318855, "Value Loss": 0.0008728171233087778, "_runtime": 8420.008201360703, "_timestamp": 1585605789.6410708, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0467500202357769, "Value Loss": 0.011852303519845009, "_runtime": 8421.578212022781, "_timestamp": 1585605791.2110815, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05219154804944992, "Value Loss": 0.00039892952190712094, "_runtime": 8423.146960020065, "_timestamp": 1585605792.7798295, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05098564922809601, "Value Loss": 3.9566250052303076e-05, "_runtime": 8424.728653907776, "_timestamp": 1585605794.3615234, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04798799380660057, "Value Loss": 0.0001169039387605153, "_runtime": 8426.293015480042, "_timestamp": 1585605795.925885, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04394521564245224, "Value Loss": 0.002122726058587432, "_runtime": 8427.885145425797, "_timestamp": 1585605797.518015, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0434734933078289, "Value Loss": 0.0023248980287462473, "_runtime": 8429.44443488121, "_timestamp": 1585605799.0773044, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.044349946081638336, "Value Loss": 0.00016932144353631884, "_runtime": 8431.004008054733, "_timestamp": 1585605800.6368775, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0423257052898407, "Value Loss": 0.0002433031622786075, "_runtime": 8432.558147907257, "_timestamp": 1585605802.1910174, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04093944653868675, "Value Loss": 0.0010984295513480902, "_runtime": 8434.116262435913, "_timestamp": 1585605803.749132, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.036002472043037415, "Value Loss": 0.00567911472171545, "_runtime": 8435.674582719803, "_timestamp": 1585605805.3074522, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03948104381561279, "Value Loss": 0.0018000768031924963, "_runtime": 8437.226779460907, "_timestamp": 1585605806.859649, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04182730242609978, "Value Loss": 0.00030915631214156747, "_runtime": 8438.773091077805, "_timestamp": 1585605808.4059606, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041333142668008804, "Value Loss": 5.195609628572129e-05, "_runtime": 8440.31825208664, "_timestamp": 1585605809.9511216, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04140317440032959, "Value Loss": 0.0005518421530723572, "_runtime": 8441.875387191772, "_timestamp": 1585605811.5082567, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03501075506210327, "Value Loss": 0.006932926829904318, "_runtime": 8443.43221783638, "_timestamp": 1585605813.0650873, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04075994715094566, "Value Loss": 5.539784979191609e-05, "_runtime": 8444.97730064392, "_timestamp": 1585605814.6101701, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.037409793585538864, "Value Loss": 0.005033253692090511, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8446.54503583908, "_timestamp": 1585605816.1779053, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03887306898832321, "Value Loss": 0.000601025007199496, "_runtime": 8448.115093231201, "_timestamp": 1585605817.7479627, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.034295760095119476, "Value Loss": 0.008091583847999573, "_runtime": 8449.722115039825, "_timestamp": 1585605819.3549845, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038354501128196716, "Value Loss": 0.00015645782696083188, "_runtime": 8451.282167196274, "_timestamp": 1585605820.9150367, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0393286868929863, "Value Loss": 2.3896312995930202e-05, "_runtime": 8452.86225605011, "_timestamp": 1585605822.4951255, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038303159177303314, "Value Loss": 0.00047795078717172146, "_runtime": 8454.430075883865, "_timestamp": 1585605824.0629454, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03699976205825806, "Value Loss": 0.0002550406788941473, "_runtime": 8455.997515678406, "_timestamp": 1585605825.6303852, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0370912104845047, "Value Loss": 0.000609816808719188, "_runtime": 8457.57091140747, "_timestamp": 1585605827.203781, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032082777470350266, "Value Loss": 0.0072709945961833, "_runtime": 8459.13946890831, "_timestamp": 1585605828.7723384, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03463486209511757, "Value Loss": 0.0004692927759606391, "_runtime": 8460.697017669678, "_timestamp": 1585605830.3298872, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03172807767987251, "Value Loss": 0.006872452795505524, "_runtime": 8462.267345666885, "_timestamp": 1585605831.9002151, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.036230068653821945, "Value Loss": 0.00029167061438784003, "_runtime": 8463.837565422058, "_timestamp": 1585605833.470435, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.034988775849342346, "Value Loss": 0.0016929167322814465, "_runtime": 8465.409050703049, "_timestamp": 1585605835.0419202, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03714524209499359, "Value Loss": 5.631089152302593e-05, "_runtime": 8466.970085382462, "_timestamp": 1585605836.6029549, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03639483451843262, "Value Loss": 0.0003334232314955443, "_runtime": 8468.54097533226, "_timestamp": 1585605838.1738448, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.031072285026311874, "Value Loss": 0.004982936196029186, "_runtime": 8470.10700082779, "_timestamp": 1585605839.7398703, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03602985665202141, "Value Loss": 0.00020089572353754193, "_runtime": 8471.67136502266, "_timestamp": 1585605841.3042345, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03342932090163231, "Value Loss": 0.0008386072004213929, "_runtime": 8473.256598234177, "_timestamp": 1585605842.8894677, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03415905684232712, "Value Loss": 0.000719965435564518, "_runtime": 8474.80462193489, "_timestamp": 1585605844.4374914, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03358949348330498, "Value Loss": 0.0005413231556303799, "_runtime": 8476.379163503647, "_timestamp": 1585605846.012033, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03294558450579643, "Value Loss": 0.00029882320086471736, "_runtime": 8477.950945854187, "_timestamp": 1585605847.5838153, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.031603842973709106, "Value Loss": 0.0005754360463470221, "_runtime": 8479.518976449966, "_timestamp": 1585605849.151846, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028923122212290764, "Value Loss": 0.0012458217097446322, "_runtime": 8481.080091953278, "_timestamp": 1585605850.7129614, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02384628914296627, "Value Loss": 0.01457147765904665, "_runtime": 8482.649599313736, "_timestamp": 1585605852.2824688, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027900759130716324, "Value Loss": 0.00020057271467521787, "_runtime": 8484.217081069946, "_timestamp": 1585605853.8499506, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0224686861038208, "Value Loss": 0.00024440616834908724, "_runtime": 8485.788440704346, "_timestamp": 1585605855.4213102, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024697106331586838, "Value Loss": 0.0006920414743945003, "_runtime": 8487.355827093124, "_timestamp": 1585605856.9886966, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022975828498601913, "Value Loss": 0.00031518450123257935, "_runtime": 8488.924148321152, "_timestamp": 1585605858.5570178, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022922823205590248, "Value Loss": 0.0008908093441277742, "_runtime": 8490.473324298859, "_timestamp": 1585605860.1061938, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02187950350344181, "Value Loss": 0.0008213936816900969, "_runtime": 8492.0438849926, "_timestamp": 1585605861.6767545, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0216849222779274, "Value Loss": 0.0006283639813773334, "_runtime": 8493.610973834991, "_timestamp": 1585605863.2438433, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019786134362220764, "Value Loss": 0.00046982933417893946, "_runtime": 8495.183950424194, "_timestamp": 1585605864.81682, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01919984444975853, "Value Loss": 9.714472980704159e-05, "_runtime": 8496.79335975647, "_timestamp": 1585605866.4262292, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01754073239862919, "Value Loss": 0.0016477766912430525, "_runtime": 8498.358988285065, "_timestamp": 1585605867.9918578, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018615104258060455, "Value Loss": 0.0007585202110931277, "_runtime": 8499.923116207123, "_timestamp": 1585605869.5559857, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01698988303542137, "Value Loss": 0.001549041480757296, "_runtime": 8501.481010437012, "_timestamp": 1585605871.11388, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01408679224550724, "Value Loss": 0.006730612367391586, "_runtime": 8503.03562450409, "_timestamp": 1585605872.668494, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018592754378914833, "Value Loss": 2.943362414953299e-05, "_runtime": 8504.592887163162, "_timestamp": 1585605874.2257566, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016002528369426727, "Value Loss": 0.0067005883902311325, "_runtime": 8506.152466058731, "_timestamp": 1585605875.7853355, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015509258955717087, "Value Loss": 0.007567244116216898, "_runtime": 8507.708416938782, "_timestamp": 1585605877.3412864, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02140694670379162, "Value Loss": 0.0002712872519623488, "_runtime": 8509.264695167542, "_timestamp": 1585605878.8975646, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018982745707035065, "Value Loss": 0.005579054355621338, "_runtime": 8510.821960449219, "_timestamp": 1585605880.45483, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018279530107975006, "Value Loss": 0.006960565224289894, "_runtime": 8512.369748592377, "_timestamp": 1585605882.002618, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018844101577997208, "Value Loss": 0.007926001213490963, "_runtime": 8513.91988992691, "_timestamp": 1585605883.5527594, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024273712188005447, "Value Loss": 0.00046701167593710124, "_runtime": 8515.476812124252, "_timestamp": 1585605885.1096816, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022505400702357292, "Value Loss": 0.0004100631922483444, "_runtime": 8517.0345287323, "_timestamp": 1585605886.6673982, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022676482796669006, "Value Loss": 0.0001223099825438112, "_runtime": 8518.593416690826, "_timestamp": 1585605888.2262862, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02320222556591034, "Value Loss": 0.0006921608000993729, "_runtime": 8520.186886310577, "_timestamp": 1585605889.8197558, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023181907832622528, "Value Loss": 0.0006385661545209587, "_runtime": 8521.741172790527, "_timestamp": 1585605891.3740423, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02179233357310295, "Value Loss": 0.0010367694776505232, "_runtime": 8523.299803256989, "_timestamp": 1585605892.9326727, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022042451426386833, "Value Loss": 6.749291787855327e-05, "_runtime": 8524.85844540596, "_timestamp": 1585605894.491315, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020699448883533478, "Value Loss": 0.00047094555338844657, "_runtime": 8526.411844015121, "_timestamp": 1585605896.0447135, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017669185996055603, "Value Loss": 4.648222602554597e-05, "_runtime": 8527.96157693863, "_timestamp": 1585605897.5944464, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019453633576631546, "Value Loss": 6.2438689383270685e-06, "_runtime": 8529.508262395859, "_timestamp": 1585605899.1411319, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02052559331059456, "Value Loss": 0.00013048636901658028, "_runtime": 8531.06687283516, "_timestamp": 1585605900.6997423, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02033284120261669, "Value Loss": 2.4150203898898326e-05, "_runtime": 8532.619262933731, "_timestamp": 1585605902.2521324, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019045455381274223, "Value Loss": 0.00025081608328036964, "_runtime": 8534.169591903687, "_timestamp": 1585605903.8024614, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016419872641563416, "Value Loss": 0.003417177591472864, "_runtime": 8535.72560930252, "_timestamp": 1585605905.3584788, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01708914525806904, "Value Loss": 0.0012483776081353426, "_runtime": 8537.292788743973, "_timestamp": 1585605906.9256582, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017897745594382286, "Value Loss": 0.00022228501620702446, "_runtime": 8538.847610473633, "_timestamp": 1585605908.48048, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018051031976938248, "Value Loss": 0.00011563284351723269, "_runtime": 8540.40300822258, "_timestamp": 1585605910.0358777, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01806742697954178, "Value Loss": 6.289889279287308e-05, "_runtime": 8541.964504241943, "_timestamp": 1585605911.5973737, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017310932278633118, "Value Loss": 0.00015067393542267382, "_runtime": 8543.560235261917, "_timestamp": 1585605913.1931047, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013812012039124966, "Value Loss": 0.004423604812473059, "_runtime": 8545.116022586823, "_timestamp": 1585605914.748892, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018027354031801224, "Value Loss": 0.00021440000273287296, "_runtime": 8546.675312042236, "_timestamp": 1585605916.3081815, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018273618072271347, "Value Loss": 9.491371019976214e-05, "_runtime": 8548.233398914337, "_timestamp": 1585605917.8662684, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01703285425901413, "Value Loss": 0.0014532486675307155, "_runtime": 8549.791812419891, "_timestamp": 1585605919.424682, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018830813467502594, "Value Loss": 0.00020841271907556802, "_runtime": 8551.352048873901, "_timestamp": 1585605920.9849184, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014388037845492363, "Value Loss": 0.0029035350307822227, "_runtime": 8552.901158571243, "_timestamp": 1585605922.534028, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01924910768866539, "Value Loss": 2.0404118913575076e-05, "_runtime": 8554.455625295639, "_timestamp": 1585605924.0884948, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01819642074406147, "Value Loss": 0.0003627624537330121, "_runtime": 8556.027286529541, "_timestamp": 1585605925.660156, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01457826979458332, "Value Loss": 0.0006011433433741331, "_runtime": 8557.599427461624, "_timestamp": 1585605927.232297, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01734909601509571, "Value Loss": 0.00041298719588667154, "_runtime": 8559.170138120651, "_timestamp": 1585605928.8030076, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016856729984283447, "Value Loss": 0.00041328082443214953, "_runtime": 8560.740330934525, "_timestamp": 1585605930.3732004, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014841621741652489, "Value Loss": 0.001952475169673562, "_runtime": 8562.305062294006, "_timestamp": 1585605931.9379318, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017257794737815857, "Value Loss": 0.0003169304982293397, "_runtime": 8563.860773086548, "_timestamp": 1585605933.4936426, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015665119513869286, "Value Loss": 0.0021331487223505974, "_runtime": 8565.472116708755, "_timestamp": 1585605935.1049862, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014585762284696102, "Value Loss": 0.0038727011997252703, "_runtime": 8567.041496276855, "_timestamp": 1585605936.6743658, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0176300760358572, "Value Loss": 0.0007770683150738478, "_runtime": 8568.599106311798, "_timestamp": 1585605938.2319758, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014169185422360897, "Value Loss": 0.0025080766063183546, "_runtime": 8570.169386386871, "_timestamp": 1585605939.8022559, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017743445932865143, "Value Loss": 0.0006102919578552246, "_runtime": 8571.729794979095, "_timestamp": 1585605941.3626645, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014831910841166973, "Value Loss": 0.0017451560124754906, "_runtime": 8573.29871416092, "_timestamp": 1585605942.9315836, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017093030735850334, "Value Loss": 0.00021541961177717894, "_runtime": 8574.86799287796, "_timestamp": 1585605944.5008624, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014716940931975842, "Value Loss": 0.0020059719681739807, "_runtime": 8576.436527013779, "_timestamp": 1585605946.0693965, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015727264806628227, "Value Loss": 0.0002341926156077534, "_runtime": 8578.00499510765, "_timestamp": 1585605947.6378646, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014389554969966412, "Value Loss": 0.0006814725347794592, "_runtime": 8579.575505018234, "_timestamp": 1585605949.2083745, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014312912710011005, "Value Loss": 0.00029554165666922927, "_runtime": 8581.146295547485, "_timestamp": 1585605950.779165, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013744141906499863, "Value Loss": 8.467839506920427e-05, "_runtime": 8582.713938236237, "_timestamp": 1585605952.3468077, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013218735344707966, "Value Loss": 0.0001435481826774776, "_runtime": 8584.286923885345, "_timestamp": 1585605953.9197934, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008445894345641136, "Value Loss": 0.0025826646015048027, "_runtime": 8585.857372045517, "_timestamp": 1585605955.4902415, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007689452730119228, "Value Loss": 0.005194944329559803, "_runtime": 8587.424615621567, "_timestamp": 1585605957.057485, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010576555505394936, "Value Loss": 0.00014810088032390922, "_runtime": 8589.030366182327, "_timestamp": 1585605958.6632357, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009423383511602879, "Value Loss": 0.0003001058357767761, "_runtime": 8590.602587938309, "_timestamp": 1585605960.2354574, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00831686519086361, "Value Loss": 0.00031128094997256994, "_runtime": 8592.169776201248, "_timestamp": 1585605961.8026457, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0073863486759364605, "Value Loss": 0.00035655085230246186, "_runtime": 8593.726680517197, "_timestamp": 1585605963.35955, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006591704674065113, "Value Loss": 0.0010809323284775019, "_runtime": 8595.294689893723, "_timestamp": 1585605964.9275594, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004420585464686155, "Value Loss": 0.0011884687701240182, "_runtime": 8596.863791942596, "_timestamp": 1585605966.4966614, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00493987463414669, "Value Loss": 0.000949862296693027, "_runtime": 8598.432693958282, "_timestamp": 1585605968.0655634, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005496967118233442, "Value Loss": 0.001843094709329307, "_runtime": 8599.99358510971, "_timestamp": 1585605969.6264546, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007740254048258066, "Value Loss": 0.0004839868634007871, "_runtime": 8601.560436964035, "_timestamp": 1585605971.1933064, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00535623962059617, "Value Loss": 0.003289008978754282, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8603.126723051071, "_timestamp": 1585605972.7595925, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009349759668111801, "Value Loss": 0.0013668055180460215, "_runtime": 8604.688508987427, "_timestamp": 1585605974.3213785, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012178062461316586, "Value Loss": 0.00020205114560667425, "_runtime": 8606.245749235153, "_timestamp": 1585605975.8786187, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01363137923181057, "Value Loss": 0.0008228159276768565, "_runtime": 8607.805984258652, "_timestamp": 1585605977.4388537, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016427570953965187, "Value Loss": 0.00025932383141480386, "_runtime": 8609.365514755249, "_timestamp": 1585605978.9983842, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019040822982788086, "Value Loss": 1.05791905298247e-05, "_runtime": 8610.934839487076, "_timestamp": 1585605980.567709, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018309613689780235, "Value Loss": 0.0024026415776461363, "_runtime": 8612.544295787811, "_timestamp": 1585605982.1771653, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021109243854880333, "Value Loss": 0.0003243263636250049, "_runtime": 8614.121271371841, "_timestamp": 1585605983.7541409, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022890174761414528, "Value Loss": 4.374093623482622e-05, "_runtime": 8615.688039302826, "_timestamp": 1585605985.3209088, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023814519867300987, "Value Loss": 0.00010822313925018534, "_runtime": 8617.259971380234, "_timestamp": 1585605986.8928409, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024178219959139824, "Value Loss": 0.0001012416832963936, "_runtime": 8618.819579839706, "_timestamp": 1585605988.4524493, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020592793822288513, "Value Loss": 0.004189133178442717, "_runtime": 8620.386631011963, "_timestamp": 1585605990.0195005, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02306399866938591, "Value Loss": 0.0007587140426039696, "_runtime": 8621.958299398422, "_timestamp": 1585605991.5911689, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01956682652235031, "Value Loss": 0.004177330061793327, "_runtime": 8623.528779268265, "_timestamp": 1585605993.1616488, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018349148333072662, "Value Loss": 0.005961610469967127, "_runtime": 8625.09501194954, "_timestamp": 1585605994.7278814, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01860385574400425, "Value Loss": 0.00244380091316998, "_runtime": 8626.664496898651, "_timestamp": 1585605996.2973664, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014973800629377365, "Value Loss": 0.002537310356274247, "_runtime": 8628.23412513733, "_timestamp": 1585605997.8669946, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01737571507692337, "Value Loss": 0.00019806678756140172, "_runtime": 8629.801577329636, "_timestamp": 1585605999.4344468, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015770437195897102, "Value Loss": 0.0002799234353005886, "_runtime": 8631.36250948906, "_timestamp": 1585606000.995379, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013268520124256611, "Value Loss": 0.0007818877347745001, "_runtime": 8632.920911550522, "_timestamp": 1585606002.553781, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01225100178271532, "Value Loss": 0.0012253145687282085, "_runtime": 8634.4796397686, "_timestamp": 1585606004.1125093, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01083378866314888, "Value Loss": 0.0006355299847200513, "_runtime": 8636.0768096447, "_timestamp": 1585606005.7096791, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009221592918038368, "Value Loss": 0.0005386921693570912, "_runtime": 8637.648828029633, "_timestamp": 1585606007.2816975, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007612462155520916, "Value Loss": 0.00020882775424979627, "_runtime": 8639.208135843277, "_timestamp": 1585606008.8410053, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005067020189017057, "Value Loss": 0.002852893667295575, "_runtime": 8640.770254850388, "_timestamp": 1585606010.4031243, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006085219327360392, "Value Loss": 9.368062455905601e-05, "_runtime": 8642.341081380844, "_timestamp": 1585606011.9739509, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002286876318976283, "Value Loss": 0.001093777478672564, "_runtime": 8643.909040212631, "_timestamp": 1585606013.5419097, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004214486572891474, "Value Loss": 0.00045214916463010013, "_runtime": 8645.480420827866, "_timestamp": 1585606015.1132903, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0044646491296589375, "Value Loss": 0.000781397451646626, "_runtime": 8647.04932641983, "_timestamp": 1585606016.682196, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0055209859274327755, "Value Loss": 0.00015963669284246862, "_runtime": 8648.615983486176, "_timestamp": 1585606018.248853, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005905131343752146, "Value Loss": 0.00017767662939149886, "_runtime": 8650.175441265106, "_timestamp": 1585606019.8083107, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0048356871120631695, "Value Loss": 0.004342040978372097, "_runtime": 8651.737766742706, "_timestamp": 1585606021.3706362, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008302353322505951, "Value Loss": 0.00013773495447821915, "_runtime": 8653.306407928467, "_timestamp": 1585606022.9392774, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0069008078426122665, "Value Loss": 0.0018615468870848417, "_runtime": 8654.876861095428, "_timestamp": 1585606024.5097306, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01120295561850071, "Value Loss": 0.00017565494636073709, "_runtime": 8656.435793161392, "_timestamp": 1585606026.0686626, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012601516209542751, "Value Loss": 0.00028471575933508575, "_runtime": 8658.043324708939, "_timestamp": 1585606027.6761942, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014417717233300209, "Value Loss": 7.821113104000688e-05, "_runtime": 8659.611018419266, "_timestamp": 1585606029.243888, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01608480140566826, "Value Loss": 9.301205136580393e-05, "_runtime": 8661.182816505432, "_timestamp": 1585606030.815686, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014203084632754326, "Value Loss": 0.0026835163589566946, "_runtime": 8662.740143299103, "_timestamp": 1585606032.3730128, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017905181273818016, "Value Loss": 2.5899549655150622e-05, "_runtime": 8664.31114768982, "_timestamp": 1585606033.9440172, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01691298373043537, "Value Loss": 0.00046583512448705733, "_runtime": 8665.881117582321, "_timestamp": 1585606035.513987, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01749728061258793, "Value Loss": 0.0005186610505916178, "_runtime": 8667.437855243683, "_timestamp": 1585606037.0707247, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017334746196866035, "Value Loss": 0.000497473229188472, "_runtime": 8669.006860494614, "_timestamp": 1585606038.63973, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01775122620165348, "Value Loss": 1.725203765090555e-05, "_runtime": 8670.576987743378, "_timestamp": 1585606040.2098572, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01607407070696354, "Value Loss": 0.0010066942777484655, "_runtime": 8672.146213054657, "_timestamp": 1585606041.7790825, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015392615459859371, "Value Loss": 0.0005142687587067485, "_runtime": 8673.719609737396, "_timestamp": 1585606043.3524792, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01428220048546791, "Value Loss": 0.0004079578793607652, "_runtime": 8675.288433790207, "_timestamp": 1585606044.9213033, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01078338548541069, "Value Loss": 0.0031374660320580006, "_runtime": 8676.845119476318, "_timestamp": 1585606046.477989, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01225018035620451, "Value Loss": 2.7966212655883282e-05, "_runtime": 8678.415577888489, "_timestamp": 1585606048.0484474, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00874130055308342, "Value Loss": 0.0015791073674336076, "_runtime": 8679.985325574875, "_timestamp": 1585606049.618195, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00955540407449007, "Value Loss": 2.562728332122788e-05, "_runtime": 8681.5893034935, "_timestamp": 1585606051.222173, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005988511256873608, "Value Loss": 0.0027870351914316416, "_runtime": 8683.151395320892, "_timestamp": 1585606052.7842648, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007321077398955822, "Value Loss": 0.00014737954188603908, "_runtime": 8684.710511446, "_timestamp": 1585606054.343381, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004128249362111092, "Value Loss": 0.0007201727712526917, "_runtime": 8686.278901338577, "_timestamp": 1585606055.9117708, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0065534766763448715, "Value Loss": 0.00028802829911001027, "_runtime": 8687.84100985527, "_timestamp": 1585606057.4738793, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026119076646864414, "Value Loss": 0.0022298756521195173, "_runtime": 8689.402958154678, "_timestamp": 1585606059.0358276, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004361695609986782, "Value Loss": 0.0004499086062423885, "_runtime": 8690.969691753387, "_timestamp": 1585606060.6025612, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004589427262544632, "Value Loss": 0.0003101139736827463, "_runtime": 8692.541068077087, "_timestamp": 1585606062.1739376, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006788871833123267, "Value Loss": 0.0007785696070641279, "_runtime": 8694.10345029831, "_timestamp": 1585606063.7363198, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003844823921099305, "Value Loss": 0.00047530751908198, "_runtime": 8695.668889045715, "_timestamp": 1585606065.3017585, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005688540986739099, "Value Loss": 0.001981306355446577, "_runtime": 8697.241238832474, "_timestamp": 1585606066.8741083, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029516653157770634, "Value Loss": 0.0005282905767671764, "_runtime": 8698.801286697388, "_timestamp": 1585606068.4341562, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0037799165584146976, "Value Loss": 0.00032107066363096237, "_runtime": 8700.371243715286, "_timestamp": 1585606070.0041132, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034290447365492582, "Value Loss": 0.00046568538527935743, "_runtime": 8701.941632509232, "_timestamp": 1585606071.574502, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00345223443582654, "Value Loss": 0.000846307200845331, "_runtime": 8703.512061595917, "_timestamp": 1585606073.144931, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017941443948075175, "Value Loss": 0.0006851086509414017, "_runtime": 8705.117441892624, "_timestamp": 1585606074.7503114, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004975230433046818, "Value Loss": 0.00042847925215028226, "_runtime": 8706.688248157501, "_timestamp": 1585606076.3211176, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005836046300828457, "Value Loss": 0.0002391440502833575, "_runtime": 8708.250155687332, "_timestamp": 1585606077.8830252, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006832583341747522, "Value Loss": 2.4865214072633535e-05, "_runtime": 8709.818374633789, "_timestamp": 1585606079.451244, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007255381438881159, "Value Loss": 0.00042751769069582224, "_runtime": 8711.389968633652, "_timestamp": 1585606081.022838, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007652198430150747, "Value Loss": 0.0008228489896282554, "_runtime": 8712.960456371307, "_timestamp": 1585606082.5933259, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008365319110453129, "Value Loss": 0.0009430138161405921, "_runtime": 8714.518822193146, "_timestamp": 1585606084.1516917, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008367534726858139, "Value Loss": 0.001469831564463675, "_runtime": 8716.105090856552, "_timestamp": 1585606085.7379603, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00904884748160839, "Value Loss": 0.0010895367013290524, "_runtime": 8717.692754983902, "_timestamp": 1585606087.3256245, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009195794351398945, "Value Loss": 0.002489299513399601, "_runtime": 8719.272384405136, "_timestamp": 1585606088.905254, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011188463307917118, "Value Loss": 0.00032257678685709834, "_runtime": 8720.852900505066, "_timestamp": 1585606090.48577, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011136826127767563, "Value Loss": 0.0006010407814756036, "_runtime": 8722.43312549591, "_timestamp": 1585606092.065995, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009070368483662605, "Value Loss": 0.0017121933633461595, "_runtime": 8723.99933385849, "_timestamp": 1585606093.6322033, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009506285190582275, "Value Loss": 6.0190817748662084e-05, "_runtime": 8725.565224409103, "_timestamp": 1585606095.198094, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00961740780621767, "Value Loss": 0.0005227815127000213, "_runtime": 8727.14548945427, "_timestamp": 1585606096.778359, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009833469986915588, "Value Loss": 0.0005380509537644684, "_runtime": 8728.758641242981, "_timestamp": 1585606098.3915107, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009243043139576912, "Value Loss": 0.00017720278992783278, "_runtime": 8730.335923194885, "_timestamp": 1585606099.9687927, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00880429707467556, "Value Loss": 0.0002193077525589615, "_runtime": 8731.914466381073, "_timestamp": 1585606101.5473359, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0086360527202487, "Value Loss": 0.00016796002455521375, "_runtime": 8733.501316070557, "_timestamp": 1585606103.1341856, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006297830492258072, "Value Loss": 0.0002710636763367802, "_runtime": 8735.07837176323, "_timestamp": 1585606104.7112412, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007115908432751894, "Value Loss": 4.498378257267177e-05, "_runtime": 8736.661617279053, "_timestamp": 1585606106.2944868, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00764186168089509, "Value Loss": 8.427980355918407e-05, "_runtime": 8738.23460817337, "_timestamp": 1585606107.8674777, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0071317353285849094, "Value Loss": 0.000696041330229491, "_runtime": 8739.809463739395, "_timestamp": 1585606109.4423332, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007359102368354797, "Value Loss": 0.000257985113421455, "_runtime": 8741.39735364914, "_timestamp": 1585606111.0302231, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008692676201462746, "Value Loss": 0.0006007961346767843, "_runtime": 8742.980096578598, "_timestamp": 1585606112.612966, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009634995833039284, "Value Loss": 8.76976628205739e-06, "_runtime": 8744.568406820297, "_timestamp": 1585606114.2012763, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010269597172737122, "Value Loss": 2.373654024268035e-05, "_runtime": 8746.143383264542, "_timestamp": 1585606115.7762527, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010044777765870094, "Value Loss": 0.001477122656069696, "_runtime": 8747.721133470535, "_timestamp": 1585606117.354003, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011167083866894245, "Value Loss": 0.0007250919006764889, "_runtime": 8749.299414157867, "_timestamp": 1585606118.9322836, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012386751361191273, "Value Loss": 0.00031502050114795566, "_runtime": 8750.886078834534, "_timestamp": 1585606120.5189483, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012164846062660217, "Value Loss": 0.0003185599634889513, "_runtime": 8752.507915496826, "_timestamp": 1585606122.140785, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012576022185385227, "Value Loss": 0.0002214560518041253, "_runtime": 8754.092587709427, "_timestamp": 1585606123.7254572, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013193206861615181, "Value Loss": 0.0008199936710298061, "_runtime": 8755.678614616394, "_timestamp": 1585606125.311484, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013499441556632519, "Value Loss": 3.6148489016341045e-05, "_runtime": 8757.25230550766, "_timestamp": 1585606126.885175, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010871685110032558, "Value Loss": 0.0018211957067251205, "_runtime": 8758.83937382698, "_timestamp": 1585606128.4722433, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011899429373443127, "Value Loss": 3.9146099879872054e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8760.424142837524, "_timestamp": 1585606130.0570123, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008367717266082764, "Value Loss": 0.0005998151027597487, "_runtime": 8760.424142837524, "_timestamp": 1585606130.0570123, "_step": 499}
