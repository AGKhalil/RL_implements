{"Episode reward": 74.21365493220674, "Episode length": 497, "Policy Loss": 0.10578157752752304, "Value Loss": 20.048503875732422, "_runtime": 1988.0700280666351, "_timestamp": 1585596737.0867016, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9396509528160095, "Value Loss": 0.16196748614311218, "_runtime": 1989.585837841034, "_timestamp": 1585596738.6025114, "_step": 1}
{"Episode reward": -59.29156515158666, "Episode length": 999, "Policy Loss": -0.08123563230037689, "Value Loss": 0.33214071393013, "_runtime": 1991.105058670044, "_timestamp": 1585596740.1217322, "_step": 2}
{"Episode reward": -63.18500742461884, "Episode length": 999, "Policy Loss": -0.19046913087368011, "Value Loss": 0.3917960226535797, "_runtime": 1992.653312444687, "_timestamp": 1585596741.669986, "_step": 3}
{"Episode reward": -68.38463237609399, "Episode length": 999, "Policy Loss": -0.1828262209892273, "Value Loss": 0.02845604345202446, "_runtime": 1994.1742765903473, "_timestamp": 1585596743.1909502, "_step": 4}
{"Episode reward": -61.703504414308156, "Episode length": 999, "Policy Loss": -0.12456873059272766, "Value Loss": 0.5403708815574646, "_runtime": 1995.7053785324097, "_timestamp": 1585596744.722052, "_step": 5}
{"Episode reward": -43.291432644882875, "Episode length": 999, "Policy Loss": -0.07979029417037964, "Value Loss": 0.03706207126379013, "_runtime": 1997.2638943195343, "_timestamp": 1585596746.280568, "_step": 6}
{"Episode reward": -38.32863922644877, "Episode length": 999, "Policy Loss": 0.17297783493995667, "Value Loss": 3.6346616744995117, "_runtime": 1998.7931532859802, "_timestamp": 1585596747.8098269, "_step": 7}
{"Episode reward": -39.379180748652495, "Episode length": 999, "Policy Loss": -0.03998912498354912, "Value Loss": 0.08768948912620544, "_runtime": 2000.3537702560425, "_timestamp": 1585596749.3704438, "_step": 8}
{"Episode reward": -40.2041156855072, "Episode length": 999, "Policy Loss": -0.015388401225209236, "Value Loss": 0.003701789304614067, "_runtime": 2001.909152507782, "_timestamp": 1585596750.925826, "_step": 9}
{"Episode reward": -36.557644938180665, "Episode length": 999, "Policy Loss": -0.0030852584168314934, "Value Loss": 0.0034272312186658382, "_runtime": 2003.4579980373383, "_timestamp": 1585596752.4746716, "_step": 10}
{"Episode reward": -33.98930455289511, "Episode length": 999, "Policy Loss": 0.009401942603290081, "Value Loss": 0.003119653556495905, "_runtime": 2005.0191910266876, "_timestamp": 1585596754.0358646, "_step": 11}
{"Episode reward": -42.06535015307272, "Episode length": 999, "Policy Loss": 0.012995542958378792, "Value Loss": 0.00419770460575819, "_runtime": 2006.5881097316742, "_timestamp": 1585596755.6047833, "_step": 12}
{"Episode reward": -46.87301287956525, "Episode length": 999, "Policy Loss": 0.014891526661813259, "Value Loss": 0.002938556019216776, "_runtime": 2008.1288418769836, "_timestamp": 1585596757.1455154, "_step": 13}
{"Episode reward": -55.36269881786269, "Episode length": 999, "Policy Loss": 0.01564556360244751, "Value Loss": 0.002850893884897232, "_runtime": 2009.694676399231, "_timestamp": 1585596758.71135, "_step": 14}
{"Episode reward": -61.36483550987727, "Episode length": 999, "Policy Loss": 0.012832799926400185, "Value Loss": 0.0033915548119693995, "_runtime": 2011.3011147975922, "_timestamp": 1585596760.3177884, "_step": 15}
{"Episode reward": -67.13008775693656, "Episode length": 999, "Policy Loss": 0.021601228043437004, "Value Loss": 0.004636507946997881, "_runtime": 2012.849035024643, "_timestamp": 1585596761.8657086, "_step": 16}
{"Episode reward": -71.97641479314886, "Episode length": 999, "Policy Loss": 0.007198512554168701, "Value Loss": 0.0032712812535464764, "_runtime": 2014.3904280662537, "_timestamp": 1585596763.4071016, "_step": 17}
{"Episode reward": -78.16132427980702, "Episode length": 999, "Policy Loss": 0.0018859361298382282, "Value Loss": 0.0027399654500186443, "_runtime": 2015.936585187912, "_timestamp": 1585596764.9532588, "_step": 18}
{"Episode reward": -79.14195714223527, "Episode length": 999, "Policy Loss": -0.003848810214549303, "Value Loss": 0.0025818280410021544, "_runtime": 2017.481482744217, "_timestamp": 1585596766.4981563, "_step": 19}
{"Episode reward": -81.75149375744029, "Episode length": 999, "Policy Loss": -0.009722982533276081, "Value Loss": 0.002686319639906287, "_runtime": 2019.0302906036377, "_timestamp": 1585596768.0469642, "_step": 20}
{"Episode reward": -84.46598573914848, "Episode length": 999, "Policy Loss": -0.014221304096281528, "Value Loss": 0.0027168630622327328, "_runtime": 2020.5772371292114, "_timestamp": 1585596769.5939107, "_step": 21}
{"Episode reward": -85.41609782756328, "Episode length": 999, "Policy Loss": -0.03421918675303459, "Value Loss": 0.004687369801104069, "_runtime": 2022.110139131546, "_timestamp": 1585596771.1268127, "_step": 22}
{"Episode reward": -84.92009597510861, "Episode length": 999, "Policy Loss": -0.02010130137205124, "Value Loss": 0.0029120107647031546, "_runtime": 2023.662032842636, "_timestamp": 1585596772.6787064, "_step": 23}
{"Episode reward": -87.00793950344257, "Episode length": 999, "Policy Loss": -0.014241216704249382, "Value Loss": 0.0017350477864965796, "_runtime": 2025.2072069644928, "_timestamp": 1585596774.2238805, "_step": 24}
{"Episode reward": -88.14903331970775, "Episode length": 999, "Policy Loss": -0.017257193103432655, "Value Loss": 0.0011694306740537286, "_runtime": 2026.754010438919, "_timestamp": 1585596775.770684, "_step": 25}
{"Episode reward": -87.67807550482742, "Episode length": 999, "Policy Loss": -0.005512581206858158, "Value Loss": 0.0008680843748152256, "_runtime": 2028.3001766204834, "_timestamp": 1585596777.3168502, "_step": 26}
{"Episode reward": -89.19657497427167, "Episode length": 999, "Policy Loss": -0.010279493406414986, "Value Loss": 0.001025628880597651, "_runtime": 2029.8585274219513, "_timestamp": 1585596778.875201, "_step": 27}
{"Episode reward": -88.37597453514108, "Episode length": 999, "Policy Loss": 0.0031525481026619673, "Value Loss": 0.0018646678654477, "_runtime": 2031.3970437049866, "_timestamp": 1585596780.4137173, "_step": 28}
{"Episode reward": -91.37819890402206, "Episode length": 999, "Policy Loss": -0.010102781467139721, "Value Loss": 0.002196675632148981, "_runtime": 2032.9457697868347, "_timestamp": 1585596781.9624434, "_step": 29}
{"Episode reward": -88.52595158558125, "Episode length": 999, "Policy Loss": 0.01445825770497322, "Value Loss": 0.004314802587032318, "_runtime": 2034.5279319286346, "_timestamp": 1585596783.5446055, "_step": 30}
{"Episode reward": -88.93389836959962, "Episode length": 999, "Policy Loss": -0.004891088232398033, "Value Loss": 0.0022487323731184006, "_runtime": 2036.064650297165, "_timestamp": 1585596785.0813239, "_step": 31}
{"Episode reward": -89.77261471436722, "Episode length": 999, "Policy Loss": 0.011558197438716888, "Value Loss": 0.0036745546385645866, "_runtime": 2037.618001461029, "_timestamp": 1585596786.634675, "_step": 32}
{"Episode reward": -89.63866984450007, "Episode length": 999, "Policy Loss": 0.004736751317977905, "Value Loss": 0.001785397413186729, "_runtime": 2039.1771187782288, "_timestamp": 1585596788.1937923, "_step": 33}
{"Episode reward": -91.17797902479553, "Episode length": 999, "Policy Loss": -0.007386465556919575, "Value Loss": 0.0010011910926550627, "_runtime": 2040.7253923416138, "_timestamp": 1585596789.742066, "_step": 34}
{"Episode reward": -90.75066431474443, "Episode length": 999, "Policy Loss": -0.008673083037137985, "Value Loss": 0.0010601957328617573, "_runtime": 2042.276657819748, "_timestamp": 1585596791.2933314, "_step": 35}
{"Episode reward": -90.41988316894341, "Episode length": 999, "Policy Loss": -0.01903732307255268, "Value Loss": 0.002443819772452116, "_runtime": 2043.80841755867, "_timestamp": 1585596792.8250911, "_step": 36}
{"Episode reward": -91.76224102172046, "Episode length": 999, "Policy Loss": -0.022875245660543442, "Value Loss": 0.003031083382666111, "_runtime": 2045.3584642410278, "_timestamp": 1585596794.3751378, "_step": 37}
{"Episode reward": -91.24171521719859, "Episode length": 999, "Policy Loss": -0.009167981334030628, "Value Loss": 0.0014028102159500122, "_runtime": 2046.910962820053, "_timestamp": 1585596795.9276364, "_step": 38}
{"Episode reward": -90.33121562158902, "Episode length": 999, "Policy Loss": -0.0015890949871391058, "Value Loss": 0.0007644019788131118, "_runtime": 2048.465416431427, "_timestamp": 1585596797.48209, "_step": 39}
{"Episode reward": -90.61157210911736, "Episode length": 999, "Policy Loss": 0.009373391047120094, "Value Loss": 0.0011011222377419472, "_runtime": 2050.0256056785583, "_timestamp": 1585596799.0422792, "_step": 40}
{"Episode reward": -91.04367592514609, "Episode length": 999, "Policy Loss": 0.017423441633582115, "Value Loss": 0.0017704969504848123, "_runtime": 2051.579825401306, "_timestamp": 1585596800.596499, "_step": 41}
{"Episode reward": -90.74051571832891, "Episode length": 999, "Policy Loss": 0.015165496617555618, "Value Loss": 0.0015391665510833263, "_runtime": 2053.1339888572693, "_timestamp": 1585596802.1506624, "_step": 42}
{"Episode reward": -90.41571681353932, "Episode length": 999, "Policy Loss": 0.005458441562950611, "Value Loss": 0.0008721803897060454, "_runtime": 2054.674232006073, "_timestamp": 1585596803.6909056, "_step": 43}
{"Episode reward": -91.16422254844188, "Episode length": 999, "Policy Loss": -0.0020802065264433622, "Value Loss": 0.0008029062300920486, "_runtime": 2056.2254843711853, "_timestamp": 1585596805.242158, "_step": 44}
{"Episode reward": -90.92517350340512, "Episode length": 999, "Policy Loss": -0.004869118332862854, "Value Loss": 0.0010710842907428741, "_runtime": 2057.815712928772, "_timestamp": 1585596806.8323865, "_step": 45}
{"Episode reward": -89.48672078419793, "Episode length": 999, "Policy Loss": 0.0012597813038155437, "Value Loss": 0.0010536155896261334, "_runtime": 2059.360233783722, "_timestamp": 1585596808.3769073, "_step": 46}
{"Episode reward": -90.95604607755868, "Episode length": 999, "Policy Loss": -0.001557777519337833, "Value Loss": 0.0008094371296465397, "_runtime": 2060.903975725174, "_timestamp": 1585596809.9206493, "_step": 47}
{"Episode reward": -92.60659449367297, "Episode length": 999, "Policy Loss": -0.005479934625327587, "Value Loss": 0.0005994272069074214, "_runtime": 2062.4592440128326, "_timestamp": 1585596811.4759176, "_step": 48}
{"Episode reward": -91.43543391447291, "Episode length": 999, "Policy Loss": 0.005687134340405464, "Value Loss": 0.0006584562943316996, "_runtime": 2063.9994411468506, "_timestamp": 1585596813.0161147, "_step": 49}
{"Episode reward": -91.23795243820831, "Episode length": 999, "Policy Loss": 0.0034728804603219032, "Value Loss": 0.0007309722132049501, "_runtime": 2065.551599264145, "_timestamp": 1585596814.5682728, "_step": 50}
{"Episode reward": -92.3777347560675, "Episode length": 999, "Policy Loss": 0.00172754458617419, "Value Loss": 0.0006510159000754356, "_runtime": 2067.1088609695435, "_timestamp": 1585596816.1255345, "_step": 51}
{"Episode reward": -89.9013909338739, "Episode length": 999, "Policy Loss": 0.0043210298754274845, "Value Loss": 0.0007790126255713403, "_runtime": 2068.6595816612244, "_timestamp": 1585596817.6762552, "_step": 52}
{"Episode reward": -93.30395249471816, "Episode length": 999, "Policy Loss": -0.005649852100759745, "Value Loss": 0.0005326996906660497, "_runtime": 2070.214524745941, "_timestamp": 1585596819.2311983, "_step": 53}
{"Episode reward": -91.94192016986284, "Episode length": 999, "Policy Loss": 0.0005365744000300765, "Value Loss": 0.0005977182881906629, "_runtime": 2071.7593216896057, "_timestamp": 1585596820.7759953, "_step": 54}
{"Episode reward": -91.97680507304266, "Episode length": 999, "Policy Loss": -0.005557654425501823, "Value Loss": 0.0006883625756017864, "_runtime": 2073.312812566757, "_timestamp": 1585596822.3294861, "_step": 55}
{"Episode reward": -92.67941045263527, "Episode length": 999, "Policy Loss": -0.005315593909472227, "Value Loss": 0.0007051234133541584, "_runtime": 2074.8663353919983, "_timestamp": 1585596823.883009, "_step": 56}
{"Episode reward": -93.58955840150935, "Episode length": 999, "Policy Loss": -0.008657287806272507, "Value Loss": 0.0005209831288084388, "_runtime": 2076.422503709793, "_timestamp": 1585596825.4391773, "_step": 57}
{"Episode reward": -92.61000390615101, "Episode length": 999, "Policy Loss": -0.00426527950912714, "Value Loss": 0.0005462385015562177, "_runtime": 2077.973452091217, "_timestamp": 1585596826.9901257, "_step": 58}
{"Episode reward": -91.28122644754698, "Episode length": 999, "Policy Loss": 0.0014960041735321283, "Value Loss": 0.0006566222873516381, "_runtime": 2079.529680252075, "_timestamp": 1585596828.5463538, "_step": 59}
{"Episode reward": -94.00473873439671, "Episode length": 999, "Policy Loss": -0.006385892163962126, "Value Loss": 0.0004676438693422824, "_runtime": 2081.1234328746796, "_timestamp": 1585596830.1401064, "_step": 60}
{"Episode reward": -92.41286648905631, "Episode length": 999, "Policy Loss": -0.0018602890195325017, "Value Loss": 0.0005495546502061188, "_runtime": 2082.6701216697693, "_timestamp": 1585596831.6867952, "_step": 61}
{"Episode reward": -91.65787135720045, "Episode length": 999, "Policy Loss": 0.004444574937224388, "Value Loss": 0.0006293877377174795, "_runtime": 2084.2242064476013, "_timestamp": 1585596833.24088, "_step": 62}
{"Episode reward": -91.58624918979892, "Episode length": 999, "Policy Loss": 0.0004750440130010247, "Value Loss": 0.0006526124780066311, "_runtime": 2085.781908750534, "_timestamp": 1585596834.7985823, "_step": 63}
{"Episode reward": -93.63991644336745, "Episode length": 999, "Policy Loss": -0.008496460504829884, "Value Loss": 0.0005350959836505353, "_runtime": 2087.3333485126495, "_timestamp": 1585596836.350022, "_step": 64}
{"Episode reward": -91.61956916575446, "Episode length": 999, "Policy Loss": -0.003812698181718588, "Value Loss": 0.0006703564431518316, "_runtime": 2088.875407934189, "_timestamp": 1585596837.8920815, "_step": 65}
{"Episode reward": -93.18061028711612, "Episode length": 999, "Policy Loss": -0.0032774240244179964, "Value Loss": 0.0005332492291927338, "_runtime": 2090.420928001404, "_timestamp": 1585596839.4376016, "_step": 66}
{"Episode reward": -91.32436207008016, "Episode length": 999, "Policy Loss": 0.001533510978333652, "Value Loss": 0.0007388482335954905, "_runtime": 2091.9488666057587, "_timestamp": 1585596840.9655402, "_step": 67}
{"Episode reward": -92.87923573629939, "Episode length": 999, "Policy Loss": -0.001732719480060041, "Value Loss": 0.000621388724539429, "_runtime": 2093.501700401306, "_timestamp": 1585596842.518374, "_step": 68}
{"Episode reward": -93.12779253056999, "Episode length": 999, "Policy Loss": -0.000227704003918916, "Value Loss": 0.0005960159469395876, "_runtime": 2095.0552825927734, "_timestamp": 1585596844.0719562, "_step": 69}
{"Episode reward": -90.0315627974226, "Episode length": 999, "Policy Loss": 0.006334731820970774, "Value Loss": 0.0006489140796475112, "_runtime": 2096.5973188877106, "_timestamp": 1585596845.6139925, "_step": 70}
{"Episode reward": -92.75961881172871, "Episode length": 999, "Policy Loss": -0.003997661639004946, "Value Loss": 0.0005557611002586782, "_runtime": 2098.13613820076, "_timestamp": 1585596847.1528118, "_step": 71}
{"Episode reward": -92.00100536420342, "Episode length": 999, "Policy Loss": -0.0005755950696766376, "Value Loss": 0.0006872070953249931, "_runtime": 2099.681079149246, "_timestamp": 1585596848.6977527, "_step": 72}
{"Episode reward": -91.91838617524668, "Episode length": 999, "Policy Loss": -0.007203875575214624, "Value Loss": 0.0007435019360855222, "_runtime": 2101.232286453247, "_timestamp": 1585596850.24896, "_step": 73}
{"Episode reward": -93.14516418291815, "Episode length": 999, "Policy Loss": -0.005757153499871492, "Value Loss": 0.0006121262558735907, "_runtime": 2102.7863445281982, "_timestamp": 1585596851.803018, "_step": 74}
{"Episode reward": -92.6158927005688, "Episode length": 999, "Policy Loss": 0.002346893772482872, "Value Loss": 0.0006192882428877056, "_runtime": 2104.3798654079437, "_timestamp": 1585596853.396539, "_step": 75}
{"Episode reward": -92.80009751594575, "Episode length": 999, "Policy Loss": 1.7161037249024957e-05, "Value Loss": 0.0006329864845611155, "_runtime": 2105.9216344356537, "_timestamp": 1585596854.938308, "_step": 76}
{"Episode reward": -93.33663954629321, "Episode length": 999, "Policy Loss": -0.004257109481841326, "Value Loss": 0.0005316889728419483, "_runtime": 2107.4764637947083, "_timestamp": 1585596856.4931374, "_step": 77}
{"Episode reward": -91.31656430523755, "Episode length": 999, "Policy Loss": 0.005120250396430492, "Value Loss": 0.0006105341599322855, "_runtime": 2109.0324981212616, "_timestamp": 1585596858.0491717, "_step": 78}
{"Episode reward": -90.71159929178089, "Episode length": 999, "Policy Loss": 0.0004465259553398937, "Value Loss": 0.0006568790995515883, "_runtime": 2110.583652496338, "_timestamp": 1585596859.600326, "_step": 79}
{"Episode reward": -92.63789959129981, "Episode length": 999, "Policy Loss": -0.007390264887362719, "Value Loss": 0.0006123341736383736, "_runtime": 2112.138696193695, "_timestamp": 1585596861.1553698, "_step": 80}
{"Episode reward": -91.5103503795922, "Episode length": 999, "Policy Loss": -0.0004971287562511861, "Value Loss": 0.0006629599956795573, "_runtime": 2113.693662881851, "_timestamp": 1585596862.7103364, "_step": 81}
{"Episode reward": -93.0029884276293, "Episode length": 999, "Policy Loss": -0.005969238467514515, "Value Loss": 0.0005124489543959498, "_runtime": 2115.2448420524597, "_timestamp": 1585596864.2615156, "_step": 82}
{"Episode reward": -92.16203994872522, "Episode length": 999, "Policy Loss": 0.004574135411530733, "Value Loss": 0.0006446266197599471, "_runtime": 2116.8009026050568, "_timestamp": 1585596865.8175762, "_step": 83}
{"Episode reward": -93.03183262795434, "Episode length": 999, "Policy Loss": -0.004705613013356924, "Value Loss": 0.0005281523335725069, "_runtime": 2118.35547208786, "_timestamp": 1585596867.3721457, "_step": 84}
{"Episode reward": -93.97928197111122, "Episode length": 999, "Policy Loss": -0.00584790576249361, "Value Loss": 0.0004224021977279335, "_runtime": 2119.8960094451904, "_timestamp": 1585596868.912683, "_step": 85}
{"Episode reward": -93.73604587641891, "Episode length": 999, "Policy Loss": -0.007598611991852522, "Value Loss": 0.00046827358892187476, "_runtime": 2121.4489364624023, "_timestamp": 1585596870.46561, "_step": 86}
{"Episode reward": -93.19138954809728, "Episode length": 999, "Policy Loss": -0.006120771169662476, "Value Loss": 0.0005338698974810541, "_runtime": 2122.992055416107, "_timestamp": 1585596872.008729, "_step": 87}
{"Episode reward": -92.94360574231135, "Episode length": 999, "Policy Loss": -0.009423649869859219, "Value Loss": 0.0006215553730726242, "_runtime": 2124.5437347888947, "_timestamp": 1585596873.5604084, "_step": 88}
{"Episode reward": -91.87409998517468, "Episode length": 999, "Policy Loss": -0.00027906379546038806, "Value Loss": 0.0006378451362252235, "_runtime": 2126.1318080425262, "_timestamp": 1585596875.1484816, "_step": 89}
{"Episode reward": -92.85684088941949, "Episode length": 999, "Policy Loss": 0.003432005876675248, "Value Loss": 0.0007591022294946015, "_runtime": 2127.684211730957, "_timestamp": 1585596876.7008853, "_step": 90}
{"Episode reward": -93.56442665248468, "Episode length": 999, "Policy Loss": -0.0023087929002940655, "Value Loss": 0.0005326207028701901, "_runtime": 2129.2363617420197, "_timestamp": 1585596878.2530353, "_step": 91}
{"Episode reward": -93.14694777074956, "Episode length": 999, "Policy Loss": -0.003337305737659335, "Value Loss": 0.0005000985693186522, "_runtime": 2130.7949118614197, "_timestamp": 1585596879.8115854, "_step": 92}
{"Episode reward": -92.65580291585185, "Episode length": 999, "Policy Loss": -0.002764531411230564, "Value Loss": 0.000612911768257618, "_runtime": 2132.3392469882965, "_timestamp": 1585596881.3559206, "_step": 93}
{"Episode reward": -92.50260954645425, "Episode length": 999, "Policy Loss": -0.007941906340420246, "Value Loss": 0.0008490568143315613, "_runtime": 2133.8806507587433, "_timestamp": 1585596882.8973243, "_step": 94}
{"Episode reward": -92.38885500924354, "Episode length": 999, "Policy Loss": -0.0038536156062036753, "Value Loss": 0.0005692429840564728, "_runtime": 2135.434564590454, "_timestamp": 1585596884.4512382, "_step": 95}
{"Episode reward": -94.03781160164898, "Episode length": 999, "Policy Loss": -0.005973628722131252, "Value Loss": 0.0004521832743193954, "_runtime": 2136.989882707596, "_timestamp": 1585596886.0065563, "_step": 96}
{"Episode reward": -94.07017918685597, "Episode length": 999, "Policy Loss": 3.1205265258904546e-05, "Value Loss": 0.000760622147936374, "_runtime": 2138.5305955410004, "_timestamp": 1585596887.547269, "_step": 97}
{"Episode reward": -93.68084023678507, "Episode length": 999, "Policy Loss": -0.0031924769282341003, "Value Loss": 0.0006094230338931084, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247, 0.12761755287647247]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5261529088020325, -0.5148259401321411, -0.5034989714622498, -0.4921720325946808, -0.48084506392478943, -0.46951809525489807, -0.4581911265850067, -0.44686418771743774, -0.4355372190475464, -0.42421025037765503, -0.41288328170776367, -0.4015563130378723, -0.39022934436798096, -0.378902405500412, -0.36757543683052063, -0.35624849796295166, -0.3449215292930603, -0.33359456062316895, -0.3222675919532776, -0.31094062328338623, -0.2996136546134949, -0.2882866859436035, -0.27695974707603455, -0.2656327784061432, -0.25430580973625183, -0.24297884106636047, -0.2316519021987915, -0.22032493352890015, -0.2089979648590088, -0.19767099618911743, -0.18634405732154846, -0.1750170886516571, -0.16369011998176575, -0.1523631513118744, -0.14103618264198303, -0.12970924377441406, -0.1183822751045227, -0.10705530643463135, -0.09572833776473999, -0.08440139889717102, -0.07307443022727966, -0.061747461557388306, -0.05042049288749695, -0.03909352421760559, -0.02776658535003662, -0.016439616680145264, -0.005112648010253906, 0.006214320659637451, 0.01754128932952881, 0.028868257999420166, 0.04019522666931152, 0.051522135734558105, 0.06284910440444946, 0.07417607307434082, 0.08550304174423218, 0.09683001041412354, 0.10815697908401489, 0.11948394775390625, 0.1308109164237976, 0.14213788509368896, 0.15346479415893555, 0.1647917628288269, 0.17611873149871826, 0.18744570016860962, 0.19877266883850098]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.13277243077754974, -0.12936604022979736, -0.12595966458320618, -0.1225532814860344, -0.11914689838886261, -0.11574051529169083, -0.11233413219451904, -0.10892774164676666, -0.10552136600017548, -0.1021149754524231, -0.09870859980583191, -0.09530220925807953, -0.09189582616090775, -0.08848944306373596, -0.08508305996656418, -0.0816766768693924, -0.07827029377222061, -0.07486391067504883, -0.07145752757787704, -0.06805114448070526, -0.06464476138353348, -0.061238378286361694, -0.05783199518918991, -0.05442561209201813, -0.05101922154426575, -0.047612838447093964, -0.04420645534992218, -0.0408000722527504, -0.03739368915557861, -0.03398730605840683, -0.030580922961235046, -0.027174539864063263, -0.02376815676689148, -0.020361773669719696, -0.016955390572547913, -0.01354900747537613, -0.010142624378204346, -0.006736233830451965, -0.003329858183860779, 7.653236389160156e-05, 0.003482908010482788, 0.0068892985582351685, 0.010295674204826355, 0.013702064752578735, 0.017108440399169922, 0.020514830946922302, 0.02392120659351349, 0.02732759714126587, 0.03073398768901825, 0.034140363335609436, 0.037546753883361816, 0.040953129529953, 0.04435952007770538, 0.04776589572429657, 0.05117228627204895, 0.05457866191864014, 0.05798505246639252, 0.061391428112983704, 0.06479781866073608, 0.06820419430732727, 0.07161058485507965, 0.07501696050167084, 0.07842335104942322, 0.0818297266960144, 0.08523611724376678]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 4.0, 3.0, 3.0, 4.0, 7.0, 8.0, 4.0, 6.0, 7.0, 4.0, 7.0, 9.0, 15.0, 11.0, 19.0, 18.0, 26.0, 22.0, 29.0, 43.0, 47.0, 34.0, 29.0, 15.0, 16.0, 9.0, 16.0, 9.0, 14.0, 8.0, 13.0, 8.0, 8.0, 5.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.08927897363901138, -0.08686251193284988, -0.08444605022668839, -0.08202958852052689, -0.07961312681436539, -0.07719666510820389, -0.07478020340204239, -0.07236374914646149, -0.06994728744029999, -0.06753082573413849, -0.06511436402797699, -0.06269790232181549, -0.06028144061565399, -0.05786497890949249, -0.055448517203330994, -0.053032055497169495, -0.050615593791007996, -0.0481991320848465, -0.045782670378685, -0.0433662086725235, -0.040949746966362, -0.0385332889854908, -0.0361168272793293, -0.0337003655731678, -0.0312839038670063, -0.028867442160844803, -0.026450984179973602, -0.024034522473812103, -0.021618060767650604, -0.019201599061489105, -0.016785137355327606, -0.014368675649166107, -0.011952213943004608, -0.009535752236843109, -0.00711929053068161, -0.004702828824520111, -0.002286367118358612, 0.00013009458780288696, 0.002546556293964386, 0.004963018000125885, 0.007379479706287384, 0.009795933961868286, 0.012212395668029785, 0.014628857374191284, 0.017045319080352783, 0.019461780786514282, 0.02187824249267578, 0.02429470419883728, 0.02671116590499878, 0.02912762761116028, 0.03154408931732178, 0.033960551023483276, 0.03637700527906418, 0.03879346698522568, 0.041209928691387177, 0.043626390397548676, 0.046042852103710175, 0.048459313809871674, 0.05087577551603317, 0.05329223722219467, 0.05570869892835617, 0.05812516063451767, 0.06054162234067917, 0.06295808404684067, 0.06537454575300217]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6638627052307129, -0.6435527801513672, -0.6232429146766663, -0.6029329895973206, -0.5826231241226196, -0.5623131990432739, -0.5420032739639282, -0.5216933488845825, -0.5013834834098816, -0.4810735881328583, -0.46076369285583496, -0.44045376777648926, -0.42014387249946594, -0.3998339772224426, -0.3795240521430969, -0.3592141568660736, -0.3389042615890503, -0.318594366312027, -0.29828447103500366, -0.27797454595565796, -0.25766465067863464, -0.23735475540161133, -0.21704483032226562, -0.1967349350452423, -0.176425039768219, -0.1561151146888733, -0.13580524921417236, -0.11549532413482666, -0.09518539905548096, -0.07487553358078003, -0.054565608501434326, -0.0342557430267334, -0.013945817947387695, 0.006364107131958008, 0.026673972606658936, 0.04698389768600464, 0.06729376316070557, 0.08760368824005127, 0.10791361331939697, 0.1282234787940979, 0.1485334038734436, 0.1688433289527893, 0.18915319442749023, 0.20946311950683594, 0.22977304458618164, 0.25008291006088257, 0.27039283514022827, 0.2907027006149292, 0.3110126256942749, 0.3313225507736206, 0.3516324758529663, 0.37194228172302246, 0.39225220680236816, 0.41256213188171387, 0.43287205696105957, 0.4531819820404053, 0.473491907119751, 0.49380171298980713, 0.5141116380691528, 0.5344215631484985, 0.5547314882278442, 0.5750414133071899, 0.5953512191772461, 0.6156611442565918, 0.6359710693359375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.286447674036026, -0.2782619297504425, -0.2700762152671814, -0.2618904709815979, -0.2537047266960144, -0.2455190122127533, -0.2373332679271698, -0.2291475385427475, -0.2209618091583252, -0.2127760648727417, -0.2045903354883194, -0.1964046061038971, -0.1882188618183136, -0.1800331324338913, -0.171847403049469, -0.1636616587638855, -0.1554759293794632, -0.1472901999950409, -0.1391044557094574, -0.1309187263250351, -0.12273299694061279, -0.1145472526550293, -0.106361523270607, -0.09817579388618469, -0.0899900496006012, -0.0818043202161789, -0.07361859083175659, -0.06543286144733429, -0.05724711716175079, -0.04906138777732849, -0.04087565839290619, -0.03268992900848389, -0.02450418472290039, -0.016318440437316895, -0.008132725954055786, 5.301833152770996e-05, 0.008238762617111206, 0.016424477100372314, 0.02461022138595581, 0.03279596567153931, 0.040981680154800415, 0.04916742444038391, 0.05735316872596741, 0.06553888320922852, 0.07372462749481201, 0.08191037178039551, 0.09009608626365662, 0.09828183054924011, 0.10646757483482361, 0.11465328931808472, 0.12283903360366821, 0.13102474808692932, 0.13921049237251282, 0.1473962366580963, 0.15558195114135742, 0.16376769542694092, 0.17195343971252441, 0.18013915419578552, 0.18832489848136902, 0.19651064276695251, 0.20469635725021362, 0.21288210153579712, 0.22106781601905823, 0.22925356030464172, 0.23743930459022522]}, "_runtime": 2140.07404255867, "_timestamp": 1585596889.0907161, "_step": 98}
{"Episode reward": -91.33268384251197, "Episode length": 999, "Policy Loss": 0.007533491589128971, "Value Loss": 0.0007386357756331563, "_runtime": 2141.6293227672577, "_timestamp": 1585596890.6459963, "_step": 99}
{"Episode reward": -92.26959028732774, "Episode length": 999, "Policy Loss": 0.0034228318836539984, "Value Loss": 0.0005683210329152644, "_runtime": 2143.178540945053, "_timestamp": 1585596892.1952145, "_step": 100}
{"Episode reward": -93.54486951450453, "Episode length": 999, "Policy Loss": -0.003665150608867407, "Value Loss": 0.0005695431027561426, "_runtime": 2144.730908870697, "_timestamp": 1585596893.7475824, "_step": 101}
{"Episode reward": -92.40590944601152, "Episode length": 999, "Policy Loss": -0.01071646437048912, "Value Loss": 0.0013805510243400931, "_runtime": 2146.283967733383, "_timestamp": 1585596895.3006413, "_step": 102}
{"Episode reward": -92.47169305608871, "Episode length": 999, "Policy Loss": -0.0057710399851202965, "Value Loss": 0.0006920014857314527, "_runtime": 2147.822742700577, "_timestamp": 1585596896.8394163, "_step": 103}
{"Episode reward": -91.37303419741644, "Episode length": 999, "Policy Loss": 0.004595519509166479, "Value Loss": 0.0007403384079225361, "_runtime": 2149.398951768875, "_timestamp": 1585596898.4156253, "_step": 104}
{"Episode reward": -94.69314981682656, "Episode length": 999, "Policy Loss": -0.003982501570135355, "Value Loss": 0.000768812489695847, "_runtime": 2150.9531559944153, "_timestamp": 1585596899.9698296, "_step": 105}
{"Episode reward": -94.70636818490193, "Episode length": 999, "Policy Loss": -0.005741320084780455, "Value Loss": 0.000736730289645493, "_runtime": 2152.493237018585, "_timestamp": 1585596901.5099106, "_step": 106}
{"Episode reward": -93.02246670367083, "Episode length": 999, "Policy Loss": 0.00017048808513209224, "Value Loss": 0.0008307304233312607, "_runtime": 2154.0458846092224, "_timestamp": 1585596903.0625582, "_step": 107}
{"Episode reward": -91.78286929505973, "Episode length": 999, "Policy Loss": 0.012849381193518639, "Value Loss": 0.0009696991182863712, "_runtime": 2155.5869493484497, "_timestamp": 1585596904.603623, "_step": 108}
{"Episode reward": -93.87174614178511, "Episode length": 999, "Policy Loss": -0.008235967718064785, "Value Loss": 0.0009905395563691854, "_runtime": 2157.1369621753693, "_timestamp": 1585596906.1536357, "_step": 109}
{"Episode reward": -94.1021515379342, "Episode length": 999, "Policy Loss": -0.013256901875138283, "Value Loss": 0.0015171077102422714, "_runtime": 2158.668650865555, "_timestamp": 1585596907.6853244, "_step": 110}
{"Episode reward": -95.08154389624238, "Episode length": 999, "Policy Loss": -0.011397751048207283, "Value Loss": 0.0007655705558136106, "_runtime": 2160.211481332779, "_timestamp": 1585596909.228155, "_step": 111}
{"Episode reward": -92.3782844480146, "Episode length": 999, "Policy Loss": 0.003214391181245446, "Value Loss": 0.0005281275371089578, "_runtime": 2161.751618385315, "_timestamp": 1585596910.768292, "_step": 112}
{"Episode reward": -94.07449743418513, "Episode length": 999, "Policy Loss": -0.0013089459389448166, "Value Loss": 0.0005601010052487254, "_runtime": 2163.2977769374847, "_timestamp": 1585596912.3144505, "_step": 113}
{"Episode reward": -93.29274340072621, "Episode length": 999, "Policy Loss": 0.010079184547066689, "Value Loss": 0.0011401725932955742, "_runtime": 2164.848881006241, "_timestamp": 1585596913.8655546, "_step": 114}
{"Episode reward": -92.3039147587624, "Episode length": 999, "Policy Loss": 0.007815835997462273, "Value Loss": 0.0006723029655404389, "_runtime": 2166.3874650001526, "_timestamp": 1585596915.4041386, "_step": 115}
{"Episode reward": -93.09437706008005, "Episode length": 999, "Policy Loss": -0.0012935440754517913, "Value Loss": 0.0006386312306858599, "_runtime": 2167.93811583519, "_timestamp": 1585596916.9547894, "_step": 116}
{"Episode reward": -94.40836635698854, "Episode length": 999, "Policy Loss": -0.004563773050904274, "Value Loss": 0.0008073759381659329, "_runtime": 2169.490706920624, "_timestamp": 1585596918.5073805, "_step": 117}
{"Episode reward": -94.73774329404276, "Episode length": 999, "Policy Loss": -0.00700913043692708, "Value Loss": 0.0009751496254466474, "_runtime": 2171.04052400589, "_timestamp": 1585596920.0571976, "_step": 118}
{"Episode reward": -95.00410867872789, "Episode length": 999, "Policy Loss": -0.004388302564620972, "Value Loss": 0.000520000234246254, "_runtime": 2172.6276540756226, "_timestamp": 1585596921.6443276, "_step": 119}
{"Episode reward": -92.92700716506047, "Episode length": 999, "Policy Loss": 0.0015319900121539831, "Value Loss": 0.0005924428114667535, "_runtime": 2174.183997631073, "_timestamp": 1585596923.2006712, "_step": 120}
{"Episode reward": -93.28370953322552, "Episode length": 999, "Policy Loss": 0.0010391144314780831, "Value Loss": 0.000504418567288667, "_runtime": 2175.7405636310577, "_timestamp": 1585596924.7572372, "_step": 121}
{"Episode reward": -93.09284200564551, "Episode length": 999, "Policy Loss": -0.0010088725248351693, "Value Loss": 0.0005779637722298503, "_runtime": 2177.2920632362366, "_timestamp": 1585596926.3087368, "_step": 122}
{"Episode reward": -91.53455682473277, "Episode length": 999, "Policy Loss": 0.011468910612165928, "Value Loss": 0.0008177633280865848, "_runtime": 2178.8365359306335, "_timestamp": 1585596927.8532095, "_step": 123}
{"Episode reward": -93.1084868848083, "Episode length": 999, "Policy Loss": 0.0012482660822570324, "Value Loss": 0.0005180475418455899, "_runtime": 2180.3750100135803, "_timestamp": 1585596929.3916836, "_step": 124}
{"Episode reward": -92.966400182835, "Episode length": 999, "Policy Loss": -0.003222600556910038, "Value Loss": 0.0005297246971167624, "_runtime": 2181.930234193802, "_timestamp": 1585596930.9469078, "_step": 125}
{"Episode reward": -92.50085369040143, "Episode length": 999, "Policy Loss": -0.0016691108467057347, "Value Loss": 0.0006324687274172902, "_runtime": 2183.473532676697, "_timestamp": 1585596932.4902062, "_step": 126}
{"Episode reward": -91.62780848166258, "Episode length": 999, "Policy Loss": -0.0014553042128682137, "Value Loss": 0.0006635327008552849, "_runtime": 2185.015214920044, "_timestamp": 1585596934.0318885, "_step": 127}
{"Episode reward": -92.16292770305381, "Episode length": 999, "Policy Loss": 0.004015665501356125, "Value Loss": 0.000578656850848347, "_runtime": 2186.5672006607056, "_timestamp": 1585596935.5838742, "_step": 128}
{"Episode reward": -92.77232757768111, "Episode length": 999, "Policy Loss": 0.009697407484054565, "Value Loss": 0.0007478619809262455, "_runtime": 2188.0979278087616, "_timestamp": 1585596937.1146014, "_step": 129}
{"Episode reward": -92.68410510338745, "Episode length": 999, "Policy Loss": 0.0011413315078243613, "Value Loss": 0.000554557191208005, "_runtime": 2189.6369450092316, "_timestamp": 1585596938.6536186, "_step": 130}
{"Episode reward": -92.47305828601736, "Episode length": 999, "Policy Loss": -0.003335972549393773, "Value Loss": 0.0006163603975437582, "_runtime": 2191.1925237178802, "_timestamp": 1585596940.2091973, "_step": 131}
{"Episode reward": -90.83342413886726, "Episode length": 999, "Policy Loss": 0.00011199704022146761, "Value Loss": 0.0008045481517910957, "_runtime": 2192.746499300003, "_timestamp": 1585596941.7631729, "_step": 132}
{"Episode reward": -91.10067344894493, "Episode length": 999, "Policy Loss": 0.002070242539048195, "Value Loss": 0.0006447426276281476, "_runtime": 2194.2866673469543, "_timestamp": 1585596943.303341, "_step": 133}
{"Episode reward": -91.01573405117028, "Episode length": 999, "Policy Loss": 0.0007299012504518032, "Value Loss": 0.0006721591926179826, "_runtime": 2195.880884170532, "_timestamp": 1585596944.8975577, "_step": 134}
{"Episode reward": -92.3459330846681, "Episode length": 999, "Policy Loss": 0.00024295579351019114, "Value Loss": 0.0006133061251603067, "_runtime": 2197.4347355365753, "_timestamp": 1585596946.451409, "_step": 135}
{"Episode reward": -91.92343987084303, "Episode length": 999, "Policy Loss": 0.008487413637340069, "Value Loss": 0.0007181647815741599, "_runtime": 2198.988615989685, "_timestamp": 1585596948.0052896, "_step": 136}
{"Episode reward": -92.03265249793832, "Episode length": 999, "Policy Loss": -0.005606167949736118, "Value Loss": 0.0005503502325154841, "_runtime": 2200.530638217926, "_timestamp": 1585596949.5473118, "_step": 137}
{"Episode reward": -92.43501227905948, "Episode length": 999, "Policy Loss": -0.008351326920092106, "Value Loss": 0.0006717154756188393, "_runtime": 2202.088009119034, "_timestamp": 1585596951.1046827, "_step": 138}
{"Episode reward": -91.70212920767108, "Episode length": 999, "Policy Loss": -0.010778448544442654, "Value Loss": 0.0007897890172898769, "_runtime": 2203.615123271942, "_timestamp": 1585596952.6317968, "_step": 139}
{"Episode reward": -93.39837582078111, "Episode length": 999, "Policy Loss": -0.00624833395704627, "Value Loss": 0.00047713646199554205, "_runtime": 2205.157592535019, "_timestamp": 1585596954.174266, "_step": 140}
{"Episode reward": -93.17063102207885, "Episode length": 999, "Policy Loss": -0.0010642524575814605, "Value Loss": 0.0007468495168723166, "_runtime": 2206.7126817703247, "_timestamp": 1585596955.7293553, "_step": 141}
{"Episode reward": -92.37092431588076, "Episode length": 999, "Policy Loss": -0.0004949430003762245, "Value Loss": 0.00075815204763785, "_runtime": 2208.2396788597107, "_timestamp": 1585596957.2563524, "_step": 142}
{"Episode reward": -91.37728923775475, "Episode length": 999, "Policy Loss": -0.0034641341771930456, "Value Loss": 0.0006434260867536068, "_runtime": 2209.7793452739716, "_timestamp": 1585596958.7960188, "_step": 143}
{"Episode reward": -94.35216379086184, "Episode length": 999, "Policy Loss": -0.010055245831608772, "Value Loss": 0.0004292717785574496, "_runtime": 2211.330347061157, "_timestamp": 1585596960.3470206, "_step": 144}
{"Episode reward": -91.51418481232066, "Episode length": 999, "Policy Loss": -0.009504539892077446, "Value Loss": 0.0008088464383035898, "_runtime": 2212.8819160461426, "_timestamp": 1585596961.8985896, "_step": 145}
{"Episode reward": -91.97266332995925, "Episode length": 999, "Policy Loss": -0.006971558090299368, "Value Loss": 0.0006607006653212011, "_runtime": 2214.432114839554, "_timestamp": 1585596963.4487884, "_step": 146}
{"Episode reward": -93.05770980124645, "Episode length": 999, "Policy Loss": -0.003618192858994007, "Value Loss": 0.0005265286890789866, "_runtime": 2215.9836888313293, "_timestamp": 1585596965.0003624, "_step": 147}
{"Episode reward": -93.30961421650784, "Episode length": 999, "Policy Loss": -0.0063490672037005424, "Value Loss": 0.0005868567968718708, "_runtime": 2217.5773463249207, "_timestamp": 1585596966.59402, "_step": 148}
{"Episode reward": -93.53914241797368, "Episode length": 999, "Policy Loss": 0.0012844507582485676, "Value Loss": 0.0009725993149913847, "_runtime": 2219.111820459366, "_timestamp": 1585596968.128494, "_step": 149}
{"Episode reward": -94.98165056782858, "Episode length": 999, "Policy Loss": -0.009804031811654568, "Value Loss": 0.00040342588908970356, "_runtime": 2220.662977695465, "_timestamp": 1585596969.6796513, "_step": 150}
{"Episode reward": -93.3615079677754, "Episode length": 999, "Policy Loss": -0.008980078622698784, "Value Loss": 0.0006054790574125946, "_runtime": 2222.2121074199677, "_timestamp": 1585596971.228781, "_step": 151}
{"Episode reward": -94.45763878499682, "Episode length": 999, "Policy Loss": -0.013392932713031769, "Value Loss": 0.0007825794746167958, "_runtime": 2223.780119419098, "_timestamp": 1585596972.796793, "_step": 152}
{"Episode reward": -92.48791124662854, "Episode length": 999, "Policy Loss": -0.002530061872676015, "Value Loss": 0.0006473621469922364, "_runtime": 2225.343193769455, "_timestamp": 1585596974.3598673, "_step": 153}
{"Episode reward": -90.36489034691331, "Episode length": 999, "Policy Loss": 0.0034838400315493345, "Value Loss": 0.0007224339642561972, "_runtime": 2226.8915112018585, "_timestamp": 1585596975.9081848, "_step": 154}
{"Episode reward": -92.20224675079047, "Episode length": 999, "Policy Loss": 0.0033235750161111355, "Value Loss": 0.0007319666328839958, "_runtime": 2228.446573972702, "_timestamp": 1585596977.4632475, "_step": 155}
{"Episode reward": -92.89714012191551, "Episode length": 999, "Policy Loss": 0.004630283918231726, "Value Loss": 0.0007059020572341979, "_runtime": 2230.0001521110535, "_timestamp": 1585596979.0168257, "_step": 156}
{"Episode reward": -94.17525177460386, "Episode length": 999, "Policy Loss": -0.004631279036402702, "Value Loss": 0.0004286422918085009, "_runtime": 2231.550046443939, "_timestamp": 1585596980.56672, "_step": 157}
{"Episode reward": -92.66724737015969, "Episode length": 999, "Policy Loss": -0.002243203576654196, "Value Loss": 0.0006075422861613333, "_runtime": 2233.1053054332733, "_timestamp": 1585596982.121979, "_step": 158}
{"Episode reward": -91.47692367253342, "Episode length": 999, "Policy Loss": -0.002338141668587923, "Value Loss": 0.0007877238094806671, "_runtime": 2234.656203508377, "_timestamp": 1585596983.672877, "_step": 159}
{"Episode reward": -91.39155321995682, "Episode length": 999, "Policy Loss": 0.0017120547126978636, "Value Loss": 0.0006303254049271345, "_runtime": 2236.197822332382, "_timestamp": 1585596985.214496, "_step": 160}
{"Episode reward": -92.56815217096042, "Episode length": 999, "Policy Loss": 9.423209849046543e-05, "Value Loss": 0.0006923486944288015, "_runtime": 2237.7530143260956, "_timestamp": 1585596986.769688, "_step": 161}
{"Episode reward": -93.94815321441601, "Episode length": 999, "Policy Loss": -0.0007325047045014799, "Value Loss": 0.0005534642841666937, "_runtime": 2239.297160387039, "_timestamp": 1585596988.313834, "_step": 162}
{"Episode reward": -93.07384457641217, "Episode length": 999, "Policy Loss": -6.461109296651557e-05, "Value Loss": 0.0005923654534853995, "_runtime": 2240.8848283290863, "_timestamp": 1585596989.901502, "_step": 163}
{"Episode reward": -91.86953243310276, "Episode length": 999, "Policy Loss": 0.005060436669737101, "Value Loss": 0.0006091424729675055, "_runtime": 2242.4350876808167, "_timestamp": 1585596991.4517612, "_step": 164}
{"Episode reward": -94.93775731835882, "Episode length": 999, "Policy Loss": -0.007748028263449669, "Value Loss": 0.0005169736687093973, "_runtime": 2243.9876177310944, "_timestamp": 1585596993.0042913, "_step": 165}
{"Episode reward": -93.33654907701042, "Episode length": 999, "Policy Loss": -0.012568916194140911, "Value Loss": 0.0010178365046158433, "_runtime": 2245.546782016754, "_timestamp": 1585596994.5634556, "_step": 166}
{"Episode reward": -92.6497845569182, "Episode length": 999, "Policy Loss": -0.0024305323604494333, "Value Loss": 0.0005268813110888004, "_runtime": 2247.1078062057495, "_timestamp": 1585596996.1244798, "_step": 167}
{"Episode reward": -93.12158674178623, "Episode length": 999, "Policy Loss": 0.0009811022318899632, "Value Loss": 0.0007231158087961376, "_runtime": 2248.6675460338593, "_timestamp": 1585596997.6842196, "_step": 168}
{"Episode reward": -92.48094353871676, "Episode length": 999, "Policy Loss": 0.013932784087955952, "Value Loss": 0.001220265869051218, "_runtime": 2250.2280864715576, "_timestamp": 1585596999.24476, "_step": 169}
{"Episode reward": -92.13451217829997, "Episode length": 999, "Policy Loss": 0.0006261434755288064, "Value Loss": 0.0005699832690879703, "_runtime": 2251.781769514084, "_timestamp": 1585597000.798443, "_step": 170}
{"Episode reward": -93.08872105893495, "Episode length": 999, "Policy Loss": -0.005535695236176252, "Value Loss": 0.0007505611283704638, "_runtime": 2253.3444504737854, "_timestamp": 1585597002.361124, "_step": 171}
{"Episode reward": -93.10340517683844, "Episode length": 999, "Policy Loss": -0.007274992298334837, "Value Loss": 0.0008790723513811827, "_runtime": 2254.903118133545, "_timestamp": 1585597003.9197917, "_step": 172}
{"Episode reward": -94.06399059783095, "Episode length": 999, "Policy Loss": -0.004272474907338619, "Value Loss": 0.000484482035972178, "_runtime": 2256.462470769882, "_timestamp": 1585597005.4791443, "_step": 173}
{"Episode reward": -94.00717630635089, "Episode length": 999, "Policy Loss": -0.002087170025333762, "Value Loss": 0.00045357507769949734, "_runtime": 2258.014993906021, "_timestamp": 1585597007.0316675, "_step": 174}
{"Episode reward": -93.09931546858687, "Episode length": 999, "Policy Loss": 0.004423572216182947, "Value Loss": 0.0006513981497846544, "_runtime": 2259.5757253170013, "_timestamp": 1585597008.592399, "_step": 175}
{"Episode reward": -96.3392759608999, "Episode length": 999, "Policy Loss": -0.010574939660727978, "Value Loss": 0.0002612282696645707, "_runtime": 2261.1277883052826, "_timestamp": 1585597010.1444619, "_step": 176}
{"Episode reward": -93.53231891976723, "Episode length": 999, "Policy Loss": -0.002241132315248251, "Value Loss": 0.00044851750135421753, "_runtime": 2262.678106546402, "_timestamp": 1585597011.69478, "_step": 177}
{"Episode reward": -92.6085309350849, "Episode length": 999, "Policy Loss": -0.0014334345469251275, "Value Loss": 0.0005602703895419836, "_runtime": 2264.2623183727264, "_timestamp": 1585597013.278992, "_step": 178}
{"Episode reward": -93.79576170974764, "Episode length": 999, "Policy Loss": -0.005480632185935974, "Value Loss": 0.00047632650239393115, "_runtime": 2265.807721853256, "_timestamp": 1585597014.8243954, "_step": 179}
{"Episode reward": -92.68029131942889, "Episode length": 999, "Policy Loss": -0.00039597833529114723, "Value Loss": 0.0005572463851422071, "_runtime": 2267.355167388916, "_timestamp": 1585597016.371841, "_step": 180}
{"Episode reward": -95.02339248429838, "Episode length": 999, "Policy Loss": -0.0042602503672242165, "Value Loss": 0.0003800437552854419, "_runtime": 2268.9069147109985, "_timestamp": 1585597017.9235883, "_step": 181}
{"Episode reward": -93.18765178748451, "Episode length": 999, "Policy Loss": 0.0037941664922982454, "Value Loss": 0.0005056083900853992, "_runtime": 2270.462587594986, "_timestamp": 1585597019.4792612, "_step": 182}
{"Episode reward": -91.57013269517414, "Episode length": 999, "Policy Loss": 0.002793162129819393, "Value Loss": 0.0006091536488384008, "_runtime": 2272.0194296836853, "_timestamp": 1585597021.0361032, "_step": 183}
{"Episode reward": -92.00644353335342, "Episode length": 999, "Policy Loss": 0.0013031940907239914, "Value Loss": 0.0005575611139647663, "_runtime": 2273.5702028274536, "_timestamp": 1585597022.5868764, "_step": 184}
{"Episode reward": -93.9559398361868, "Episode length": 999, "Policy Loss": -0.005504734348505735, "Value Loss": 0.0004766763304360211, "_runtime": 2275.113826751709, "_timestamp": 1585597024.1305003, "_step": 185}
{"Episode reward": -92.82288780098754, "Episode length": 999, "Policy Loss": -0.003402477828785777, "Value Loss": 0.0005298243486322463, "_runtime": 2276.6674284934998, "_timestamp": 1585597025.684102, "_step": 186}
{"Episode reward": -93.01558623142735, "Episode length": 999, "Policy Loss": 0.0018497927812859416, "Value Loss": 0.0004945297259837389, "_runtime": 2278.22136759758, "_timestamp": 1585597027.2380412, "_step": 187}
{"Episode reward": -92.63611780595454, "Episode length": 999, "Policy Loss": 0.0016799543518573046, "Value Loss": 0.0005682286573573947, "_runtime": 2279.763041496277, "_timestamp": 1585597028.779715, "_step": 188}
{"Episode reward": -91.52433672850904, "Episode length": 999, "Policy Loss": 0.0037837745621800423, "Value Loss": 0.0006084301858209074, "_runtime": 2281.319881916046, "_timestamp": 1585597030.3365555, "_step": 189}
{"Episode reward": -92.97852834523951, "Episode length": 999, "Policy Loss": -0.0014347482938319445, "Value Loss": 0.0005238409503363073, "_runtime": 2282.8727402687073, "_timestamp": 1585597031.8894138, "_step": 190}
{"Episode reward": -91.46681150365903, "Episode length": 999, "Policy Loss": 0.003684415016323328, "Value Loss": 0.0005820955848321319, "_runtime": 2284.4262175559998, "_timestamp": 1585597033.4428911, "_step": 191}
{"Episode reward": -94.30401297645756, "Episode length": 999, "Policy Loss": -0.007205813657492399, "Value Loss": 0.0004415730945765972, "_runtime": 2285.969499349594, "_timestamp": 1585597034.986173, "_step": 192}
{"Episode reward": -93.34989890649824, "Episode length": 999, "Policy Loss": -0.0018561638426035643, "Value Loss": 0.000452102511189878, "_runtime": 2287.54922914505, "_timestamp": 1585597036.5659027, "_step": 193}
{"Episode reward": -92.98924556979436, "Episode length": 999, "Policy Loss": -0.000731650332454592, "Value Loss": 0.0004983997787348926, "_runtime": 2289.1040959358215, "_timestamp": 1585597038.1207695, "_step": 194}
{"Episode reward": -93.24683741333503, "Episode length": 999, "Policy Loss": -0.004059169441461563, "Value Loss": 0.0005042145494371653, "_runtime": 2290.6413567066193, "_timestamp": 1585597039.6580303, "_step": 195}
{"Episode reward": -91.46223635457463, "Episode length": 999, "Policy Loss": 0.0022553238086402416, "Value Loss": 0.0005845171981491148, "_runtime": 2292.194093942642, "_timestamp": 1585597041.2107675, "_step": 196}
{"Episode reward": -93.78853733628033, "Episode length": 999, "Policy Loss": -0.00582347996532917, "Value Loss": 0.0004575324128381908, "_runtime": 2293.7360763549805, "_timestamp": 1585597042.75275, "_step": 197}
{"Episode reward": -92.50231590028496, "Episode length": 999, "Policy Loss": -0.002343029249459505, "Value Loss": 0.0005180410807952285, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839, -0.04841059446334839]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.17101062834262848, -0.16741549968719482, -0.16382037103176117, -0.16022522747516632, -0.15663009881973267, -0.153034970164299, -0.14943984150886536, -0.1458447128534317, -0.14224958419799805, -0.1386544406414032, -0.13505931198596954, -0.1314641833305359, -0.12786905467510223, -0.12427391856908798, -0.12067878991365433, -0.11708365380764008, -0.11348852515220642, -0.10989339649677277, -0.10629826039075851, -0.10270313173532486, -0.09910799562931061, -0.09551286697387695, -0.0919177383184433, -0.08832260221242905, -0.08472747355699539, -0.08113234490156174, -0.07753720879554749, -0.07394208014011383, -0.07034695148468018, -0.06675181537866592, -0.06315668672323227, -0.05956155061721802, -0.05596642196178436, -0.05237129330635071, -0.048776157200336456, -0.045181021094322205, -0.04158589243888855, -0.037990763783454895, -0.03439563512802124, -0.030800506472587585, -0.027205362915992737, -0.023610234260559082, -0.020015105605125427, -0.016419976949691772, -0.012824848294258118, -0.009229719638824463, -0.005634576082229614, -0.0020394474267959595, 0.0015556812286376953, 0.00515080988407135, 0.008745938539505005, 0.012341082096099854, 0.01593621075153351, 0.019531339406967163, 0.023126468062400818, 0.026721596717834473, 0.030316725373268127, 0.033911868929862976, 0.03750699758529663, 0.041102126240730286, 0.04469725489616394, 0.048292383551597595, 0.051887527108192444, 0.0554826557636261, 0.05907778441905975]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03232560306787491, -0.03100694715976715, -0.029688291251659393, -0.028369637206196785, -0.027050981298089027, -0.02573232538998127, -0.02441367134451866, -0.023095015436410904, -0.021776359528303146, -0.02045770362019539, -0.01913904771208763, -0.017820393666625023, -0.016501737758517265, -0.015183081850409508, -0.0138644278049469, -0.012545771896839142, -0.011227115988731384, -0.009908460080623627, -0.00858980417251587, -0.007271150127053261, -0.005952494218945503, -0.004633838310837746, -0.0033151842653751373, -0.0019965283572673798, -0.0006778724491596222, 0.0006407834589481354, 0.001959439367055893, 0.0032780952751636505, 0.00459674745798111, 0.005915403366088867, 0.007234059274196625, 0.008552715182304382, 0.00987137109041214, 0.011190026998519897, 0.012508682906627655, 0.013827338814735413, 0.01514599472284317, 0.01646464690566063, 0.017783302813768387, 0.019101958721876144, 0.020420614629983902, 0.02173927053809166, 0.023057926446199417, 0.024376582354307175, 0.025695234537124634, 0.02701389044523239, 0.02833254635334015, 0.029651202261447906, 0.030969858169555664, 0.03228851407766342, 0.03360716998577118, 0.03492582589387894, 0.036244481801986694, 0.03756313771009445, 0.03888179361820221, 0.04020044952630997, 0.04151909798383713, 0.042837753891944885, 0.04415640980005264, 0.0454750657081604, 0.04679372161626816, 0.048112377524375916, 0.04943103343248367, 0.05074968934059143, 0.05206834524869919]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 5.0, 6.0, 8.0, 10.0, 6.0, 7.0, 7.0, 10.0, 10.0, 22.0, 27.0, 26.0, 59.0, 57.0, 30.0, 29.0, 19.0, 11.0, 19.0, 21.0, 17.0, 17.0, 16.0, 8.0, 8.0, 5.0, 7.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03883448615670204, -0.037418946623802185, -0.03600340336561203, -0.03458786383271217, -0.03317232429981232, -0.03175678476691246, -0.030341243371367455, -0.02892570197582245, -0.027510162442922592, -0.026094622910022736, -0.02467908151447773, -0.023263540118932724, -0.021848000586032867, -0.02043246105313301, -0.019016919657588005, -0.017601378262043, -0.016185838729143143, -0.014770299196243286, -0.01335475780069828, -0.011939216405153275, -0.010523676872253418, -0.009108137339353561, -0.007692595943808556, -0.00627705454826355, -0.004861515015363693, -0.0034459754824638367, -0.00203043594956398, -0.0006148926913738251, 0.0008006468415260315, 0.002216186374425888, 0.003631729632616043, 0.0050472691655159, 0.006462808698415756, 0.007878348231315613, 0.00929388776421547, 0.010709431022405624, 0.012124970555305481, 0.013540510088205338, 0.014956053346395493, 0.01637159287929535, 0.017787132412195206, 0.019202671945095062, 0.02061821147799492, 0.022033754736185074, 0.02344929426908493, 0.024864833801984787, 0.026280377060174942, 0.0276959128677845, 0.029111456125974655, 0.03052699938416481, 0.03194253519177437, 0.03335807844996452, 0.03477361425757408, 0.036189157515764236, 0.03760470077395439, 0.03902023658156395, 0.040435779839754105, 0.04185132309794426, 0.04326685890555382, 0.04468240216374397, 0.04609794542193413, 0.047513481229543686, 0.04892902448773384, 0.0503445602953434, 0.051760103553533554]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.15369471907615662, -0.148499995470047, -0.14330528676509857, -0.13811056315898895, -0.13291585445404053, -0.1277211308479309, -0.12252641469240189, -0.11733169853687286, -0.11213697493076324, -0.10694226622581482, -0.1017475426197052, -0.09655282646417618, -0.09135811030864716, -0.08616339415311813, -0.08096867054700851, -0.07577395439147949, -0.07057923823595047, -0.06538452208042145, -0.060189805924892426, -0.054995082318782806, -0.049800366163253784, -0.04460565000772476, -0.03941093385219574, -0.03421621769666672, -0.029021501541137695, -0.023826777935028076, -0.01863206923007965, -0.013437345623970032, -0.008242622017860413, -0.0030479133129119873, 0.002146810293197632, 0.007341518998146057, 0.012536242604255676, 0.017730966210365295, 0.02292567491531372, 0.02812039852142334, 0.033315107226371765, 0.038509830832481384, 0.043704554438591, 0.04889926314353943, 0.05409398674964905, 0.05928869545459747, 0.06448341906070709, 0.06967814266681671, 0.07487285137176514, 0.08006757497787476, 0.08526228368282318, 0.0904570072889328, 0.09565171599388123, 0.10084643959999084, 0.10604116320610046, 0.11123588681221008, 0.11643058061599731, 0.12162530422210693, 0.12682002782821655, 0.13201475143432617, 0.1372094750404358, 0.14240416884422302, 0.14759889245033264, 0.15279361605644226, 0.15798833966255188, 0.1631830632686615, 0.16837775707244873, 0.17357248067855835, 0.17876720428466797]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 0.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0], "bins": [-0.09474781900644302, -0.09203706681728363, -0.08932630717754364, -0.08661555498838425, -0.08390479534864426, -0.08119404315948486, -0.07848328351974487, -0.07577253133058548, -0.07306177914142609, -0.0703510195016861, -0.0676402673125267, -0.06492951512336731, -0.06221875548362732, -0.05950799956917763, -0.056797247380018234, -0.05408649146556854, -0.05137573555111885, -0.04866497963666916, -0.04595422372221947, -0.043243471533060074, -0.04053271561861038, -0.03782195970416069, -0.035111203789711, -0.03240044787526131, -0.029689691960811615, -0.02697893977165222, -0.02426818013191223, -0.021557427942752838, -0.018846675753593445, -0.016135916113853455, -0.013425163924694061, -0.010714404284954071, -0.008003652095794678, -0.005292899906635284, -0.002582140266895294, 0.00012861192226409912, 0.0028393715620040894, 0.005550123751163483, 0.008260875940322876, 0.010971635580062866, 0.01368238776922226, 0.01639314740896225, 0.019103899598121643, 0.021814651787281036, 0.024525411427021027, 0.02723616361618042, 0.02994692325592041, 0.0326576754450798, 0.035368435084819794, 0.03807917982339859, 0.04078993946313858, 0.04350069910287857, 0.04621145874261856, 0.04892220348119736, 0.05163296312093735, 0.05434372276067734, 0.057054467499256134, 0.059765227138996124, 0.062475986778736115, 0.06518673151731491, 0.0678974911570549, 0.07060825079679489, 0.07331901043653488, 0.07602975517511368, 0.07874051481485367]}, "_runtime": 2295.2882976531982, "_timestamp": 1585597044.3049712, "_step": 198}
{"Episode reward": -93.7665921795964, "Episode length": 999, "Policy Loss": -0.0050735450349748135, "Value Loss": 0.0004395892610773444, "_runtime": 2296.8320457935333, "_timestamp": 1585597045.8487194, "_step": 199}
{"Episode reward": -93.35716599812176, "Episode length": 999, "Policy Loss": -0.00598658062517643, "Value Loss": 0.0004746154882013798, "_runtime": 2298.3845562934875, "_timestamp": 1585597047.4012299, "_step": 200}
{"Episode reward": -91.57305467333948, "Episode length": 999, "Policy Loss": 0.00016863913333509117, "Value Loss": 0.0005936307134106755, "_runtime": 2299.926281452179, "_timestamp": 1585597048.942955, "_step": 201}
{"Episode reward": -92.5456361080261, "Episode length": 999, "Policy Loss": -6.53727474855259e-05, "Value Loss": 0.0005122186848893762, "_runtime": 2301.4775400161743, "_timestamp": 1585597050.4942136, "_step": 202}
{"Episode reward": -91.94737237332478, "Episode length": 999, "Policy Loss": 0.002843437483534217, "Value Loss": 0.0005572514492087066, "_runtime": 2303.0231816768646, "_timestamp": 1585597052.0398552, "_step": 203}
{"Episode reward": -93.17941117996845, "Episode length": 999, "Policy Loss": -0.004433339927345514, "Value Loss": 0.00048038692330010235, "_runtime": 2304.567331314087, "_timestamp": 1585597053.5840049, "_step": 204}
{"Episode reward": -92.27805742084847, "Episode length": 999, "Policy Loss": -0.0015836122911423445, "Value Loss": 0.0005463391426019371, "_runtime": 2306.116156578064, "_timestamp": 1585597055.1328301, "_step": 205}
{"Episode reward": -92.83332609259483, "Episode length": 999, "Policy Loss": -0.0025549435522407293, "Value Loss": 0.0004957949859090149, "_runtime": 2307.6680092811584, "_timestamp": 1585597056.6846828, "_step": 206}
{"Episode reward": -93.87049671132428, "Episode length": 999, "Policy Loss": -0.0051262471824884415, "Value Loss": 0.0004343537148088217, "_runtime": 2309.2320172786713, "_timestamp": 1585597058.2486908, "_step": 207}
{"Episode reward": -93.72575242428599, "Episode length": 999, "Policy Loss": -0.005737313535064459, "Value Loss": 0.00045830218004994094, "_runtime": 2310.8285126686096, "_timestamp": 1585597059.8451862, "_step": 208}
{"Episode reward": -93.56558309057307, "Episode length": 999, "Policy Loss": -0.0028758470434695482, "Value Loss": 0.0004608199233189225, "_runtime": 2312.3884382247925, "_timestamp": 1585597061.4051118, "_step": 209}
{"Episode reward": -94.60233304970484, "Episode length": 999, "Policy Loss": -0.00877216923981905, "Value Loss": 0.00040886556962504983, "_runtime": 2313.9528172016144, "_timestamp": 1585597062.9694908, "_step": 210}
{"Episode reward": -93.89150807449285, "Episode length": 999, "Policy Loss": -0.006330545525997877, "Value Loss": 0.0004388153029140085, "_runtime": 2315.5118753910065, "_timestamp": 1585597064.528549, "_step": 211}
{"Episode reward": -93.26718575918109, "Episode length": 999, "Policy Loss": -0.005014469847083092, "Value Loss": 0.0004944106913171709, "_runtime": 2317.0657472610474, "_timestamp": 1585597066.0824208, "_step": 212}
{"Episode reward": -93.36242168422258, "Episode length": 999, "Policy Loss": -0.0030835906509310007, "Value Loss": 0.00045587512431666255, "_runtime": 2318.61678647995, "_timestamp": 1585597067.63346, "_step": 213}
{"Episode reward": -94.9869567504222, "Episode length": 999, "Policy Loss": -0.007140287663787603, "Value Loss": 0.0003600077179726213, "_runtime": 2320.1801438331604, "_timestamp": 1585597069.1968174, "_step": 214}
{"Episode reward": -93.67306874782051, "Episode length": 999, "Policy Loss": -0.003815054427832365, "Value Loss": 0.0004526156699284911, "_runtime": 2321.7397611141205, "_timestamp": 1585597070.7564347, "_step": 215}
{"Episode reward": -94.15282614473114, "Episode length": 999, "Policy Loss": -0.0031234424095600843, "Value Loss": 0.00039639847818762064, "_runtime": 2323.3078474998474, "_timestamp": 1585597072.324521, "_step": 216}
{"Episode reward": -92.6968959017894, "Episode length": 999, "Policy Loss": 0.002208096906542778, "Value Loss": 0.0004984446568414569, "_runtime": 2324.873274564743, "_timestamp": 1585597073.8899481, "_step": 217}
{"Episode reward": -93.74012356931127, "Episode length": 999, "Policy Loss": -0.0016897338209673762, "Value Loss": 0.0004458325856830925, "_runtime": 2326.429835796356, "_timestamp": 1585597075.4465094, "_step": 218}
{"Episode reward": -94.15691105006624, "Episode length": 999, "Policy Loss": -0.003991401754319668, "Value Loss": 0.00044052681187167764, "_runtime": 2327.986048936844, "_timestamp": 1585597077.0027225, "_step": 219}
{"Episode reward": -92.3598533750065, "Episode length": 999, "Policy Loss": 0.003006394486874342, "Value Loss": 0.0005018719821237028, "_runtime": 2329.540834903717, "_timestamp": 1585597078.5575085, "_step": 220}
{"Episode reward": -91.13966473053073, "Episode length": 999, "Policy Loss": 0.006017730571329594, "Value Loss": 0.0006371961208060384, "_runtime": 2331.110288619995, "_timestamp": 1585597080.1269622, "_step": 221}
{"Episode reward": -95.05019730132244, "Episode length": 999, "Policy Loss": -0.00240948423743248, "Value Loss": 0.0003602835931815207, "_runtime": 2332.712833881378, "_timestamp": 1585597081.7295074, "_step": 222}
{"Episode reward": -94.57110468091683, "Episode length": 999, "Policy Loss": -0.00427078315988183, "Value Loss": 0.00041378018795512617, "_runtime": 2334.2778911590576, "_timestamp": 1585597083.2945647, "_step": 223}
{"Episode reward": -92.708217258336, "Episode length": 999, "Policy Loss": 0.0024914960376918316, "Value Loss": 0.000515179883223027, "_runtime": 2335.8434710502625, "_timestamp": 1585597084.8601446, "_step": 224}
{"Episode reward": -93.94519880682564, "Episode length": 999, "Policy Loss": -0.001885548117570579, "Value Loss": 0.0004481377254705876, "_runtime": 2337.4115011692047, "_timestamp": 1585597086.4281747, "_step": 225}
{"Episode reward": -93.26910481361233, "Episode length": 999, "Policy Loss": -0.00199502962641418, "Value Loss": 0.0005121144931763411, "_runtime": 2338.9767105579376, "_timestamp": 1585597087.9933841, "_step": 226}
{"Episode reward": -92.61246452510024, "Episode length": 999, "Policy Loss": -0.0003643414529506117, "Value Loss": 0.0005306249368004501, "_runtime": 2340.535111427307, "_timestamp": 1585597089.551785, "_step": 227}
{"Episode reward": -93.5020992412831, "Episode length": 999, "Policy Loss": 0.0009612967260181904, "Value Loss": 0.00043404841562733054, "_runtime": 2342.1017546653748, "_timestamp": 1585597091.1184282, "_step": 228}
{"Episode reward": -91.07652029602464, "Episode length": 999, "Policy Loss": 0.009642996825277805, "Value Loss": 0.000604127359110862, "_runtime": 2343.667977333069, "_timestamp": 1585597092.684651, "_step": 229}
{"Episode reward": -93.84955970760564, "Episode length": 999, "Policy Loss": -0.001581700867973268, "Value Loss": 0.0004369942471385002, "_runtime": 2345.2311792373657, "_timestamp": 1585597094.2478528, "_step": 230}
{"Episode reward": -92.72419036323751, "Episode length": 999, "Policy Loss": 0.0011254786513745785, "Value Loss": 0.0005097074317745864, "_runtime": 2346.793562889099, "_timestamp": 1585597095.8102365, "_step": 231}
{"Episode reward": -93.06540556308263, "Episode length": 999, "Policy Loss": -0.0013967963168397546, "Value Loss": 0.0004813922569155693, "_runtime": 2348.347414255142, "_timestamp": 1585597097.3640878, "_step": 232}
{"Episode reward": -91.86318875644167, "Episode length": 999, "Policy Loss": 0.004169405438005924, "Value Loss": 0.0005658583249896765, "_runtime": 2349.9129457473755, "_timestamp": 1585597098.9296193, "_step": 233}
{"Episode reward": -94.66512427324575, "Episode length": 999, "Policy Loss": -0.0056767393834888935, "Value Loss": 0.00038399151526391506, "_runtime": 2351.478980064392, "_timestamp": 1585597100.4956536, "_step": 234}
{"Episode reward": -92.08203042096105, "Episode length": 999, "Policy Loss": -0.0016393493860960007, "Value Loss": 0.0005749798729084432, "_runtime": 2353.0427107810974, "_timestamp": 1585597102.0593843, "_step": 235}
{"Episode reward": -90.87301171010576, "Episode length": 999, "Policy Loss": 0.005783115513622761, "Value Loss": 0.0006201518699526787, "_runtime": 2354.5999031066895, "_timestamp": 1585597103.6165767, "_step": 236}
{"Episode reward": -93.02332526136841, "Episode length": 999, "Policy Loss": -0.002806516597047448, "Value Loss": 0.0005196677520871162, "_runtime": 2356.1915214061737, "_timestamp": 1585597105.208195, "_step": 237}
{"Episode reward": -92.52486817307756, "Episode length": 999, "Policy Loss": -0.004049133043736219, "Value Loss": 0.0005302525823935866, "_runtime": 2357.747312068939, "_timestamp": 1585597106.7639856, "_step": 238}
{"Episode reward": -92.59104756822848, "Episode length": 999, "Policy Loss": -0.0005982569418847561, "Value Loss": 0.0005190097144804895, "_runtime": 2359.314198255539, "_timestamp": 1585597108.3308718, "_step": 239}
{"Episode reward": -91.96654877745145, "Episode length": 999, "Policy Loss": 0.006493480876088142, "Value Loss": 0.0006379009573720396, "_runtime": 2360.8782954216003, "_timestamp": 1585597109.894969, "_step": 240}
{"Episode reward": -94.22280496685104, "Episode length": 999, "Policy Loss": -0.008436166681349277, "Value Loss": 0.0004185376164969057, "_runtime": 2362.4440207481384, "_timestamp": 1585597111.4606943, "_step": 241}
{"Episode reward": -93.2320470635756, "Episode length": 999, "Policy Loss": -0.005711876321583986, "Value Loss": 0.0005484745488502085, "_runtime": 2363.9999866485596, "_timestamp": 1585597113.0166602, "_step": 242}
{"Episode reward": -95.80624706786998, "Episode length": 999, "Policy Loss": -0.014204117469489574, "Value Loss": 0.00042340203071944416, "_runtime": 2365.5437803268433, "_timestamp": 1585597114.560454, "_step": 243}
{"Episode reward": -93.06212389615413, "Episode length": 999, "Policy Loss": -0.0062565794214606285, "Value Loss": 0.0005152065423317254, "_runtime": 2367.107479095459, "_timestamp": 1585597116.1241527, "_step": 244}
{"Episode reward": -93.60908970860969, "Episode length": 999, "Policy Loss": -0.0062345839105546474, "Value Loss": 0.0004964680992998183, "_runtime": 2368.6721003055573, "_timestamp": 1585597117.6887739, "_step": 245}
{"Episode reward": -93.03553027437641, "Episode length": 999, "Policy Loss": 0.008405313827097416, "Value Loss": 0.0009017973789013922, "_runtime": 2370.229680776596, "_timestamp": 1585597119.2463543, "_step": 246}
{"Episode reward": -93.90676255317987, "Episode length": 999, "Policy Loss": -0.006124257575720549, "Value Loss": 0.0004585508431773633, "_runtime": 2371.7967545986176, "_timestamp": 1585597120.8134282, "_step": 247}
{"Episode reward": -92.83845458709374, "Episode length": 999, "Policy Loss": -0.005259430501610041, "Value Loss": 0.0006889022188261151, "_runtime": 2373.364462375641, "_timestamp": 1585597122.381136, "_step": 248}
{"Episode reward": -93.67503610994748, "Episode length": 999, "Policy Loss": -0.00833512470126152, "Value Loss": 0.0007186310249380767, "_runtime": 2374.9295213222504, "_timestamp": 1585597123.946195, "_step": 249}
{"Episode reward": -92.79005230276559, "Episode length": 999, "Policy Loss": -0.0029089869931340218, "Value Loss": 0.0005142386071383953, "_runtime": 2376.4947180747986, "_timestamp": 1585597125.5113916, "_step": 250}
{"Episode reward": -91.92939669312541, "Episode length": 999, "Policy Loss": 0.005127772223204374, "Value Loss": 0.0006314250640571117, "_runtime": 2378.059579372406, "_timestamp": 1585597127.076253, "_step": 251}
{"Episode reward": -93.29722763964747, "Episode length": 999, "Policy Loss": -0.00042518210830166936, "Value Loss": 0.0005880913231521845, "_runtime": 2379.6615374088287, "_timestamp": 1585597128.678211, "_step": 252}
{"Episode reward": -93.76429421227738, "Episode length": 999, "Policy Loss": -0.0024403512943536043, "Value Loss": 0.0005415009218268096, "_runtime": 2381.2262799739838, "_timestamp": 1585597130.2429535, "_step": 253}
{"Episode reward": -91.97698746528593, "Episode length": 999, "Policy Loss": 0.0009033554815687239, "Value Loss": 0.0006127140950411558, "_runtime": 2382.7928931713104, "_timestamp": 1585597131.8095667, "_step": 254}
{"Episode reward": -93.07358384524889, "Episode length": 999, "Policy Loss": -0.004260522313416004, "Value Loss": 0.0006083034095354378, "_runtime": 2384.3579709529877, "_timestamp": 1585597133.3746445, "_step": 255}
{"Episode reward": -92.14331249513606, "Episode length": 999, "Policy Loss": -2.2040736439521424e-05, "Value Loss": 0.0006148780230432749, "_runtime": 2385.923235654831, "_timestamp": 1585597134.9399092, "_step": 256}
{"Episode reward": -92.04353552543411, "Episode length": 999, "Policy Loss": 0.000863470253534615, "Value Loss": 0.0005584594327956438, "_runtime": 2387.496017217636, "_timestamp": 1585597136.5126908, "_step": 257}
{"Episode reward": -95.4374102251106, "Episode length": 999, "Policy Loss": -0.00837068259716034, "Value Loss": 0.0003550110850483179, "_runtime": 2389.0636727809906, "_timestamp": 1585597138.0803463, "_step": 258}
{"Episode reward": -93.08043152778639, "Episode length": 999, "Policy Loss": -0.0007837378652766347, "Value Loss": 0.0005210086819715798, "_runtime": 2390.633936405182, "_timestamp": 1585597139.65061, "_step": 259}
{"Episode reward": -92.97375656391347, "Episode length": 999, "Policy Loss": -0.002489205449819565, "Value Loss": 0.0005159015418030322, "_runtime": 2392.2050344944, "_timestamp": 1585597141.221708, "_step": 260}
{"Episode reward": -92.61516443173784, "Episode length": 999, "Policy Loss": -0.0008171353838406503, "Value Loss": 0.0005228411173447967, "_runtime": 2393.761791229248, "_timestamp": 1585597142.7784648, "_step": 261}
{"Episode reward": -94.01038653645588, "Episode length": 999, "Policy Loss": -0.004417988006025553, "Value Loss": 0.000405771512305364, "_runtime": 2395.3165798187256, "_timestamp": 1585597144.3332534, "_step": 262}
{"Episode reward": -91.59234532895888, "Episode length": 999, "Policy Loss": 0.002503813011571765, "Value Loss": 0.0005496604135259986, "_runtime": 2396.884346961975, "_timestamp": 1585597145.9010205, "_step": 263}
{"Episode reward": -93.42438136843384, "Episode length": 999, "Policy Loss": -0.003909377381205559, "Value Loss": 0.000462574593257159, "_runtime": 2398.44189286232, "_timestamp": 1585597147.4585664, "_step": 264}
{"Episode reward": -91.78351300380284, "Episode length": 999, "Policy Loss": 0.004509380552917719, "Value Loss": 0.0005770152783952653, "_runtime": 2400.0005838871, "_timestamp": 1585597149.0172575, "_step": 265}
{"Episode reward": -92.62446382047254, "Episode length": 999, "Policy Loss": -0.00024767365539446473, "Value Loss": 0.0005229995585978031, "_runtime": 2401.55761384964, "_timestamp": 1585597150.5742874, "_step": 266}
{"Episode reward": -92.84304283022317, "Episode length": 999, "Policy Loss": 0.0019389173248782754, "Value Loss": 0.0005019200616516173, "_runtime": 2403.1611416339874, "_timestamp": 1585597152.1778152, "_step": 267}
{"Episode reward": -91.56282303554431, "Episode length": 999, "Policy Loss": 0.004318231716752052, "Value Loss": 0.0005763333756476641, "_runtime": 2404.7243959903717, "_timestamp": 1585597153.7410696, "_step": 268}
{"Episode reward": -89.6263077907992, "Episode length": 999, "Policy Loss": 0.006048136856406927, "Value Loss": 0.0006747152656316757, "_runtime": 2406.2937965393066, "_timestamp": 1585597155.31047, "_step": 269}
{"Episode reward": -92.3464667725649, "Episode length": 999, "Policy Loss": -0.0007791919051669538, "Value Loss": 0.0005489011527970433, "_runtime": 2407.859186410904, "_timestamp": 1585597156.87586, "_step": 270}
{"Episode reward": -92.50334840133445, "Episode length": 999, "Policy Loss": 0.00037296253140084445, "Value Loss": 0.000522696238476783, "_runtime": 2409.4230501651764, "_timestamp": 1585597158.4397237, "_step": 271}
{"Episode reward": -94.34798505638499, "Episode length": 999, "Policy Loss": -0.008448459208011627, "Value Loss": 0.00038919944199733436, "_runtime": 2410.989202976227, "_timestamp": 1585597160.0058765, "_step": 272}
{"Episode reward": -92.81738092265277, "Episode length": 999, "Policy Loss": -0.0033814883790910244, "Value Loss": 0.0005012378096580505, "_runtime": 2412.5570952892303, "_timestamp": 1585597161.5737689, "_step": 273}
{"Episode reward": -92.08933087864114, "Episode length": 999, "Policy Loss": -0.003371644299477339, "Value Loss": 0.0005782124935649335, "_runtime": 2414.1163573265076, "_timestamp": 1585597163.133031, "_step": 274}
{"Episode reward": -92.9263084796993, "Episode length": 999, "Policy Loss": -0.00512960460036993, "Value Loss": 0.0005008620792068541, "_runtime": 2415.6681785583496, "_timestamp": 1585597164.6848521, "_step": 275}
{"Episode reward": -92.6523030293788, "Episode length": 999, "Policy Loss": -0.004246738739311695, "Value Loss": 0.0004953697207383811, "_runtime": 2417.2197799682617, "_timestamp": 1585597166.2364535, "_step": 276}
{"Episode reward": -94.74264900656942, "Episode length": 999, "Policy Loss": -0.009813586249947548, "Value Loss": 0.00037041030009277165, "_runtime": 2418.771142721176, "_timestamp": 1585597167.7878163, "_step": 277}
{"Episode reward": -91.81483180275127, "Episode length": 999, "Policy Loss": 2.341853905818425e-05, "Value Loss": 0.0005789034767076373, "_runtime": 2420.320640563965, "_timestamp": 1585597169.3373141, "_step": 278}
{"Episode reward": -92.80094881928, "Episode length": 999, "Policy Loss": -0.0030589739326387644, "Value Loss": 0.0004951544106006622, "_runtime": 2421.881408214569, "_timestamp": 1585597170.8980818, "_step": 279}
{"Episode reward": -92.67956163493284, "Episode length": 999, "Policy Loss": -0.0057649859227240086, "Value Loss": 0.0005071776686236262, "_runtime": 2423.429944753647, "_timestamp": 1585597172.4466183, "_step": 280}
{"Episode reward": -92.30880390819802, "Episode length": 999, "Policy Loss": -0.002675127238035202, "Value Loss": 0.0005124885938130319, "_runtime": 2425.0342948436737, "_timestamp": 1585597174.0509684, "_step": 281}
{"Episode reward": -92.00198028550938, "Episode length": 999, "Policy Loss": -0.0024766623973846436, "Value Loss": 0.000574496341869235, "_runtime": 2426.5834114551544, "_timestamp": 1585597175.600085, "_step": 282}
{"Episode reward": -93.55035063428065, "Episode length": 999, "Policy Loss": -0.008283601142466068, "Value Loss": 0.00047327359789051116, "_runtime": 2428.132221698761, "_timestamp": 1585597177.1488953, "_step": 283}
{"Episode reward": -94.05166715961008, "Episode length": 999, "Policy Loss": -0.00697914557531476, "Value Loss": 0.00041904114186763763, "_runtime": 2429.6912133693695, "_timestamp": 1585597178.707887, "_step": 284}
{"Episode reward": -91.98447484867327, "Episode length": 999, "Policy Loss": 0.003118077991530299, "Value Loss": 0.0005522937281057239, "_runtime": 2431.2543795108795, "_timestamp": 1585597180.271053, "_step": 285}
{"Episode reward": -93.06681288364958, "Episode length": 999, "Policy Loss": -0.003831951878964901, "Value Loss": 0.0004823365597985685, "_runtime": 2432.804137945175, "_timestamp": 1585597181.8208115, "_step": 286}
{"Episode reward": -94.20500224662834, "Episode length": 999, "Policy Loss": -0.008426539599895477, "Value Loss": 0.0004234062216710299, "_runtime": 2434.35556435585, "_timestamp": 1585597183.372238, "_step": 287}
{"Episode reward": -93.64097072427613, "Episode length": 999, "Policy Loss": -0.006644232198596001, "Value Loss": 0.00044693838572129607, "_runtime": 2435.915111541748, "_timestamp": 1585597184.931785, "_step": 288}
{"Episode reward": -91.66492420365306, "Episode length": 999, "Policy Loss": 0.0047385916113853455, "Value Loss": 0.0005609919899143279, "_runtime": 2437.4536895751953, "_timestamp": 1585597186.4703631, "_step": 289}
{"Episode reward": -91.6270892912739, "Episode length": 999, "Policy Loss": 0.0027654729783535004, "Value Loss": 0.0005651553510688245, "_runtime": 2439.0061321258545, "_timestamp": 1585597188.0228057, "_step": 290}
{"Episode reward": -94.25656158559903, "Episode length": 999, "Policy Loss": -0.004343089647591114, "Value Loss": 0.00037711652112193406, "_runtime": 2440.543723344803, "_timestamp": 1585597189.560397, "_step": 291}
{"Episode reward": -91.68502806836675, "Episode length": 999, "Policy Loss": 0.00012270576553419232, "Value Loss": 0.0005722461501136422, "_runtime": 2442.0927979946136, "_timestamp": 1585597191.1094716, "_step": 292}
{"Episode reward": -92.19503494382676, "Episode length": 999, "Policy Loss": -1.6136389604071155e-05, "Value Loss": 0.0005743458750657737, "_runtime": 2443.6441462039948, "_timestamp": 1585597192.6608198, "_step": 293}
{"Episode reward": -93.26004091973235, "Episode length": 999, "Policy Loss": -0.003997894935309887, "Value Loss": 0.00048163472092710435, "_runtime": 2445.195636510849, "_timestamp": 1585597194.21231, "_step": 294}
{"Episode reward": -92.31844831055749, "Episode length": 999, "Policy Loss": -0.001910253195092082, "Value Loss": 0.0005822725943289697, "_runtime": 2446.7461411952972, "_timestamp": 1585597195.7628148, "_step": 295}
{"Episode reward": -92.40376369036414, "Episode length": 999, "Policy Loss": 0.006871030665934086, "Value Loss": 0.0007114901090972126, "_runtime": 2448.3320348262787, "_timestamp": 1585597197.3487084, "_step": 296}
{"Episode reward": -91.10291334777611, "Episode length": 999, "Policy Loss": 0.0026450329460203648, "Value Loss": 0.0006065861089155078, "_runtime": 2449.8738265037537, "_timestamp": 1585597198.8905, "_step": 297}
{"Episode reward": -91.2603950147561, "Episode length": 999, "Policy Loss": -0.003477086080238223, "Value Loss": 0.0007875259616412222, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184, -0.11833108961582184]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0], "bins": [-0.3733530044555664, -0.36599403619766235, -0.3586350679397583, -0.35127609968185425, -0.3439171314239502, -0.33655816316604614, -0.3291991949081421, -0.3218402564525604, -0.31448128819465637, -0.3071223199367523, -0.29976335167884827, -0.2924043834209442, -0.28504541516304016, -0.2776864469051361, -0.27032747864723206, -0.2629685401916504, -0.25560957193374634, -0.2482505887746811, -0.24089162051677704, -0.23353266716003418, -0.22617369890213013, -0.21881473064422607, -0.21145576238632202, -0.20409679412841797, -0.19673782587051392, -0.18937887251377106, -0.182019904255867, -0.17466093599796295, -0.1673019677400589, -0.15994299948215485, -0.152584046125412, -0.14522507786750793, -0.13786610960960388, -0.13050714135169983, -0.12314817309379578, -0.11578920483589172, -0.10843023657798767, -0.10107126832008362, -0.09371232986450195, -0.0863533616065979, -0.07899439334869385, -0.0716354250907898, -0.06427645683288574, -0.05691748857498169, -0.04955852031707764, -0.042199552059173584, -0.03484058380126953, -0.02748161554336548, -0.020122647285461426, -0.01276370882987976, -0.005404740571975708, 0.0019542276859283447, 0.009313195943832397, 0.01667216420173645, 0.024031132459640503, 0.031390100717544556, 0.03874906897544861, 0.04610803723335266, 0.053467005491256714, 0.06082594394683838, 0.06818491220474243, 0.07554388046264648, 0.08290284872055054, 0.09026181697845459, 0.09762078523635864]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07902055233716965, -0.0765325278043747, -0.07404449582099915, -0.0715564712882042, -0.06906844675540924, -0.06658041477203369, -0.06409239023923874, -0.06160436198115349, -0.05911633372306824, -0.056628305464982986, -0.054140277206897736, -0.05165225267410278, -0.04916422441601753, -0.04667619615793228, -0.04418817162513733, -0.04170014336705208, -0.03921211510896683, -0.03672408685088158, -0.034236058592796326, -0.03174803406000137, -0.029260005801916122, -0.02677197754383087, -0.02428395301103592, -0.02179592475295067, -0.019307896494865417, -0.016819868236780167, -0.014331839978694916, -0.011843815445899963, -0.009355790913105011, -0.006867758929729462, -0.004379734396934509, -0.00189170241355896, 0.0005963221192359924, 0.003084346652030945, 0.005572378635406494, 0.008060403168201447, 0.010548435151576996, 0.013036459684371948, 0.0155244842171669, 0.01801251620054245, 0.020500540733337402, 0.022988565266132355, 0.025476597249507904, 0.027964621782302856, 0.03045264631509781, 0.03294067829847336, 0.03542870283126831, 0.03791673481464386, 0.04040475934743881, 0.042892783880233765, 0.045380815863609314, 0.047868840396404266, 0.050356872379779816, 0.05284488946199417, 0.05533292144536972, 0.05782095342874527, 0.060308970510959625, 0.06279700249433517, 0.06528503447771072, 0.06777306646108627, 0.07026108354330063, 0.07274911552667618, 0.07523714751005173, 0.07772516459226608, 0.08021319657564163]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 4.0, 8.0, 8.0, 6.0, 6.0, 3.0, 8.0, 7.0, 8.0, 6.0, 15.0, 9.0, 14.0, 24.0, 55.0, 57.0, 53.0, 26.0, 32.0, 12.0, 7.0, 8.0, 16.0, 22.0, 15.0, 15.0, 11.0, 6.0, 6.0, 3.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07306748628616333, -0.07060326635837555, -0.06813904643058777, -0.06567481905221939, -0.06321059912443161, -0.06074637919664383, -0.05828215554356575, -0.05581793189048767, -0.05335371196269989, -0.05088949203491211, -0.04842526838183403, -0.04596104472875595, -0.04349682480096817, -0.04103260487318039, -0.03856838122010231, -0.03610415756702423, -0.03363993763923645, -0.03117571771144867, -0.02871149405837059, -0.02624727040529251, -0.02378305047750473, -0.02131883054971695, -0.01885460689663887, -0.01639038324356079, -0.01392616331577301, -0.01146194338798523, -0.008997723460197449, -0.006533496081829071, -0.00406927615404129, -0.0016050562262535095, 0.0008591711521148682, 0.003323391079902649, 0.00578761100769043, 0.00825183093547821, 0.010716050863265991, 0.013180278241634369, 0.01564449816942215, 0.01810871809720993, 0.020572945475578308, 0.02303716540336609, 0.02550138533115387, 0.02796560525894165, 0.03042982518672943, 0.03289405256509781, 0.03535827249288559, 0.03782249242067337, 0.04028671979904175, 0.04275093972682953, 0.04521515965461731, 0.04767937958240509, 0.05014359951019287, 0.05260781943798065, 0.05507203936576843, 0.05753627419471741, 0.06000049412250519, 0.06246471405029297, 0.06492893397808075, 0.06739315390586853, 0.06985737383365631, 0.07232159376144409, 0.07478582859039307, 0.07725004851818085, 0.07971426844596863, 0.08217848837375641, 0.08464270830154419]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.28645744919776917, -0.2763494551181793, -0.26624149084091187, -0.256133496761322, -0.24602550268173218, -0.23591752350330353, -0.22580954432487488, -0.21570155024528503, -0.20559357106685638, -0.19548559188842773, -0.1853775978088379, -0.17526961863040924, -0.1651616394519806, -0.15505364537239075, -0.1449456661939621, -0.13483767211437225, -0.1247296929359436, -0.11462171375751495, -0.10451371967792511, -0.09440574049949646, -0.08429774641990662, -0.07418976724147797, -0.06408178806304932, -0.05397379398345947, -0.04386581480503082, -0.03375783562660217, -0.02364984154701233, -0.013541847467422485, -0.0034338831901550293, 0.0066741108894348145, 0.016782104969024658, 0.026890069246292114, 0.03699806332588196, 0.0471060574054718, 0.05721402168273926, 0.0673220157623291, 0.07743000984191895, 0.0875379741191864, 0.09764596819877625, 0.10775396227836609, 0.11786195635795593, 0.1279699206352234, 0.13807791471481323, 0.14818590879440308, 0.15829387307167053, 0.16840186715126038, 0.17850986123085022, 0.18861782550811768, 0.19872581958770752, 0.20883381366729736, 0.21894177794456482, 0.22904977202415466, 0.2391577661037445, 0.24926576018333435, 0.2593737542629242, 0.26948168873786926, 0.2795896828174591, 0.28969767689704895, 0.2998056709766388, 0.30991366505622864, 0.3200216591358185, 0.33012959361076355, 0.3402375876903534, 0.35034558176994324, 0.3604535758495331]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.08016785979270935, -0.07789351791143417, -0.0756191685795784, -0.07334482669830322, -0.07107048481702805, -0.06879613548517227, -0.0665217936038971, -0.06424744427204132, -0.061973102390766144, -0.05969876050949097, -0.05742441490292549, -0.055150069296360016, -0.05287572741508484, -0.05060138180851936, -0.04832703620195389, -0.04605269432067871, -0.043778348714113235, -0.04150400310754776, -0.03922966122627258, -0.03695531561970711, -0.03468097001314163, -0.032406628131866455, -0.03013228252530098, -0.027857936918735504, -0.025583595037460327, -0.02330924943089485, -0.021034903824329376, -0.0187605582177639, -0.016486212611198425, -0.014211870729923248, -0.011937528848648071, -0.009663179516792297, -0.00738883763551712, -0.005114495754241943, -0.0028401464223861694, -0.0005658045411109924, 0.0017085373401641846, 0.0039828866720199585, 0.0062572285532951355, 0.008531570434570312, 0.010805919766426086, 0.013080261647701263, 0.01535460352897644, 0.017628952860832214, 0.01990329474210739, 0.02217763662338257, 0.024451985955238342, 0.02672632783651352, 0.029000669717788696, 0.03127501904964447, 0.03354936093091965, 0.03582371026277542, 0.0380980521440506, 0.040372394025325775, 0.04264674335718155, 0.044921085238456726, 0.0471954345703125, 0.04946976900100708, 0.051744118332862854, 0.05401846766471863, 0.05629280209541321, 0.05856715142726898, 0.060841500759124756, 0.06311583518981934, 0.06539018452167511]}, "_runtime": 2451.4248683452606, "_timestamp": 1585597200.441542, "_step": 298}
{"Episode reward": -92.35624117319125, "Episode length": 999, "Policy Loss": -0.004106772132217884, "Value Loss": 0.000662673672195524, "_runtime": 2452.972039937973, "_timestamp": 1585597201.9887135, "_step": 299}
{"Episode reward": -93.87501801900548, "Episode length": 999, "Policy Loss": -0.003695259802043438, "Value Loss": 0.00044362180051393807, "_runtime": 2454.5157339572906, "_timestamp": 1585597203.5324075, "_step": 300}
{"Episode reward": -93.69952361793075, "Episode length": 999, "Policy Loss": -0.0011042918777093291, "Value Loss": 0.0005731717101298273, "_runtime": 2456.0678651332855, "_timestamp": 1585597205.0845387, "_step": 301}
{"Episode reward": -92.26016275745046, "Episode length": 999, "Policy Loss": 0.005280200392007828, "Value Loss": 0.0006486693164333701, "_runtime": 2457.618936061859, "_timestamp": 1585597206.6356096, "_step": 302}
{"Episode reward": -91.49684806902268, "Episode length": 999, "Policy Loss": -0.00520646246150136, "Value Loss": 0.0007797107100486755, "_runtime": 2459.1659207344055, "_timestamp": 1585597208.1825943, "_step": 303}
{"Episode reward": -93.29223207282821, "Episode length": 999, "Policy Loss": -0.006512394640594721, "Value Loss": 0.0005409798468463123, "_runtime": 2460.6965301036835, "_timestamp": 1585597209.7132037, "_step": 304}
{"Episode reward": -92.79819781948848, "Episode length": 999, "Policy Loss": -0.005095311440527439, "Value Loss": 0.00048396430793218315, "_runtime": 2462.2544553279877, "_timestamp": 1585597211.271129, "_step": 305}
{"Episode reward": -93.80474487096394, "Episode length": 999, "Policy Loss": -0.006381866987794638, "Value Loss": 0.0004465941747184843, "_runtime": 2463.8065333366394, "_timestamp": 1585597212.823207, "_step": 306}
{"Episode reward": -91.71875186126215, "Episode length": 999, "Policy Loss": 0.008742989972233772, "Value Loss": 0.0007353788241744041, "_runtime": 2465.3568036556244, "_timestamp": 1585597214.3734772, "_step": 307}
{"Episode reward": -91.37262977126977, "Episode length": 999, "Policy Loss": -0.0011908229207620025, "Value Loss": 0.0006278618820942938, "_runtime": 2466.8963072299957, "_timestamp": 1585597215.9129808, "_step": 308}
{"Episode reward": -92.02050441533463, "Episode length": 999, "Policy Loss": -0.005057751666754484, "Value Loss": 0.0006790337502025068, "_runtime": 2468.4260246753693, "_timestamp": 1585597217.4426982, "_step": 309}
{"Episode reward": -91.84767125996487, "Episode length": 999, "Policy Loss": -0.0029602255672216415, "Value Loss": 0.0005601592129096389, "_runtime": 2469.977206468582, "_timestamp": 1585597218.99388, "_step": 310}
{"Episode reward": -89.29858633253725, "Episode length": 999, "Policy Loss": 0.006150555331259966, "Value Loss": 0.0008417508797720075, "_runtime": 2471.5648531913757, "_timestamp": 1585597220.5815268, "_step": 311}
{"Episode reward": -90.82047815687528, "Episode length": 999, "Policy Loss": 0.005078934598714113, "Value Loss": 0.0006945282220840454, "_runtime": 2473.1192166805267, "_timestamp": 1585597222.1358902, "_step": 312}
{"Episode reward": -92.42291887450031, "Episode length": 999, "Policy Loss": -0.005130074452608824, "Value Loss": 0.0006142887868918478, "_runtime": 2474.6709945201874, "_timestamp": 1585597223.687668, "_step": 313}
{"Episode reward": -92.89806158752278, "Episode length": 999, "Policy Loss": -0.0098798219114542, "Value Loss": 0.000568560732062906, "_runtime": 2476.2134001255035, "_timestamp": 1585597225.2300737, "_step": 314}
{"Episode reward": -92.26718430271832, "Episode length": 999, "Policy Loss": -0.006503637880086899, "Value Loss": 0.000567846407648176, "_runtime": 2477.763798713684, "_timestamp": 1585597226.7804723, "_step": 315}
{"Episode reward": -93.67700177106929, "Episode length": 999, "Policy Loss": -0.0064194998703897, "Value Loss": 0.00044743571197614074, "_runtime": 2479.320517539978, "_timestamp": 1585597228.337191, "_step": 316}
{"Episode reward": -92.52188148919112, "Episode length": 999, "Policy Loss": -0.0007090447470545769, "Value Loss": 0.0006557524902746081, "_runtime": 2480.872632741928, "_timestamp": 1585597229.8893063, "_step": 317}
{"Episode reward": -92.45059795776699, "Episode length": 999, "Policy Loss": -0.003298582509160042, "Value Loss": 0.000511891208589077, "_runtime": 2482.4256086349487, "_timestamp": 1585597231.4422822, "_step": 318}
{"Episode reward": -92.66006646185981, "Episode length": 999, "Policy Loss": -0.009919537231326103, "Value Loss": 0.0006458230782300234, "_runtime": 2483.9758524894714, "_timestamp": 1585597232.992526, "_step": 319}
{"Episode reward": -93.71893987438614, "Episode length": 999, "Policy Loss": -0.01019593607634306, "Value Loss": 0.0004626109730452299, "_runtime": 2485.527910232544, "_timestamp": 1585597234.5445838, "_step": 320}
{"Episode reward": -94.01894728458765, "Episode length": 999, "Policy Loss": -0.004061718937009573, "Value Loss": 0.0005041139083914459, "_runtime": 2487.083272457123, "_timestamp": 1585597236.099946, "_step": 321}
{"Episode reward": -94.66231500382436, "Episode length": 999, "Policy Loss": -0.009098278358578682, "Value Loss": 0.00038613402284681797, "_runtime": 2488.6325912475586, "_timestamp": 1585597237.6492648, "_step": 322}
{"Episode reward": -94.49288539527157, "Episode length": 999, "Policy Loss": -0.00992554984986782, "Value Loss": 0.00041542851249687374, "_runtime": 2490.174203157425, "_timestamp": 1585597239.1908767, "_step": 323}
{"Episode reward": -93.02030380102043, "Episode length": 999, "Policy Loss": -0.007328356616199017, "Value Loss": 0.0005502755520865321, "_runtime": 2491.719132423401, "_timestamp": 1585597240.735806, "_step": 324}
{"Episode reward": -94.17514884202917, "Episode length": 999, "Policy Loss": -0.006261564325541258, "Value Loss": 0.0004212661588098854, "_runtime": 2493.275554895401, "_timestamp": 1585597242.2922285, "_step": 325}
{"Episode reward": -92.02579019691856, "Episode length": 999, "Policy Loss": 0.0010445951484143734, "Value Loss": 0.0005869176238775253, "_runtime": 2494.8515162467957, "_timestamp": 1585597243.8681898, "_step": 326}
{"Episode reward": -93.06146510949112, "Episode length": 999, "Policy Loss": 0.002806901466101408, "Value Loss": 0.0005494069191627204, "_runtime": 2496.401104927063, "_timestamp": 1585597245.4177785, "_step": 327}
{"Episode reward": -93.46623829976235, "Episode length": 999, "Policy Loss": -0.0022888164967298508, "Value Loss": 0.0004615296784322709, "_runtime": 2497.953407049179, "_timestamp": 1585597246.9700806, "_step": 328}
{"Episode reward": -93.6870953287825, "Episode length": 999, "Policy Loss": -0.001675600535236299, "Value Loss": 0.000506324227899313, "_runtime": 2499.5030357837677, "_timestamp": 1585597248.5197093, "_step": 329}
{"Episode reward": -94.43750240023024, "Episode length": 999, "Policy Loss": -0.004604085814207792, "Value Loss": 0.00041937618516385555, "_runtime": 2501.0546610355377, "_timestamp": 1585597250.0713346, "_step": 330}
{"Episode reward": -94.8839279300939, "Episode length": 999, "Policy Loss": -0.004485101439058781, "Value Loss": 0.00037832415546290576, "_runtime": 2502.605672597885, "_timestamp": 1585597251.6223462, "_step": 331}
{"Episode reward": -93.20882011216749, "Episode length": 999, "Policy Loss": 0.006033136043697596, "Value Loss": 0.0005512794014066458, "_runtime": 2504.1568505764008, "_timestamp": 1585597253.1735241, "_step": 332}
{"Episode reward": -92.56709190794108, "Episode length": 999, "Policy Loss": 0.009622951038181782, "Value Loss": 0.0005554169765673578, "_runtime": 2505.7077181339264, "_timestamp": 1585597254.7243917, "_step": 333}
{"Episode reward": -91.99736927434107, "Episode length": 999, "Policy Loss": 0.0011587502667680383, "Value Loss": 0.0006217865739017725, "_runtime": 2507.2589433193207, "_timestamp": 1585597256.275617, "_step": 334}
{"Episode reward": -92.83523043392586, "Episode length": 999, "Policy Loss": -0.009879094548523426, "Value Loss": 0.0009714143816381693, "_runtime": 2508.8094975948334, "_timestamp": 1585597257.8261712, "_step": 335}
{"Episode reward": -91.84388670320497, "Episode length": 999, "Policy Loss": 0.011348976753652096, "Value Loss": 0.000997707131318748, "_runtime": 2510.352290391922, "_timestamp": 1585597259.368964, "_step": 336}
{"Episode reward": -91.69926578527155, "Episode length": 999, "Policy Loss": 0.018672438338398933, "Value Loss": 0.001638366375118494, "_runtime": 2511.904379606247, "_timestamp": 1585597260.9210532, "_step": 337}
{"Episode reward": -93.35440019713785, "Episode length": 999, "Policy Loss": -0.0016495708841830492, "Value Loss": 0.0005513727082870901, "_runtime": 2513.4483325481415, "_timestamp": 1585597262.465006, "_step": 338}
{"Episode reward": -93.38772356397675, "Episode length": 999, "Policy Loss": -0.006176388822495937, "Value Loss": 0.0010721158469095826, "_runtime": 2514.9978461265564, "_timestamp": 1585597264.0145197, "_step": 339}
{"Episode reward": -94.35756726736358, "Episode length": 999, "Policy Loss": -0.011078491806983948, "Value Loss": 0.0008511776686646044, "_runtime": 2516.5485298633575, "_timestamp": 1585597265.5652034, "_step": 340}
{"Episode reward": -92.98263945550136, "Episode length": 999, "Policy Loss": 0.004263239447027445, "Value Loss": 0.0005670179962180555, "_runtime": 2518.149742126465, "_timestamp": 1585597267.1664157, "_step": 341}
{"Episode reward": -93.22133067256384, "Episode length": 999, "Policy Loss": -0.0005420631496235728, "Value Loss": 0.000803886738140136, "_runtime": 2519.7039091587067, "_timestamp": 1585597268.7205827, "_step": 342}
{"Episode reward": -93.95008031814626, "Episode length": 999, "Policy Loss": -0.001331492094323039, "Value Loss": 0.0005719249602407217, "_runtime": 2521.24529838562, "_timestamp": 1585597270.261972, "_step": 343}
{"Episode reward": -92.91616617550497, "Episode length": 999, "Policy Loss": 0.0001897390466183424, "Value Loss": 0.00047885975800454617, "_runtime": 2522.7969949245453, "_timestamp": 1585597271.8136685, "_step": 344}
{"Episode reward": -93.73324147110398, "Episode length": 999, "Policy Loss": -0.011759546585381031, "Value Loss": 0.000811598205473274, "_runtime": 2524.3426213264465, "_timestamp": 1585597273.359295, "_step": 345}
{"Episode reward": -92.36445142716425, "Episode length": 999, "Policy Loss": -0.003320985473692417, "Value Loss": 0.0005561563302762806, "_runtime": 2525.8962647914886, "_timestamp": 1585597274.9129384, "_step": 346}
{"Episode reward": -95.21771950416792, "Episode length": 999, "Policy Loss": -0.0036649564281105995, "Value Loss": 0.0005473048659041524, "_runtime": 2527.4476566314697, "_timestamp": 1585597276.4643302, "_step": 347}
{"Episode reward": -94.21969305135377, "Episode length": 999, "Policy Loss": 0.002058639656752348, "Value Loss": 0.0007975070620886981, "_runtime": 2529.0001995563507, "_timestamp": 1585597278.0168731, "_step": 348}
{"Episode reward": -92.24767311923692, "Episode length": 999, "Policy Loss": -0.009427875280380249, "Value Loss": 0.0008067512535490096, "_runtime": 2530.552289247513, "_timestamp": 1585597279.5689628, "_step": 349}
{"Episode reward": -93.28866035469308, "Episode length": 999, "Policy Loss": -0.0004832195118069649, "Value Loss": 0.000549199350643903, "_runtime": 2532.0951330661774, "_timestamp": 1585597281.1118066, "_step": 350}
{"Episode reward": -93.20391174999585, "Episode length": 999, "Policy Loss": 0.002301356755197048, "Value Loss": 0.0006579965120181441, "_runtime": 2533.643591403961, "_timestamp": 1585597282.660265, "_step": 351}
{"Episode reward": -94.89746240635598, "Episode length": 999, "Policy Loss": -0.007347064558416605, "Value Loss": 0.0004076943441759795, "_runtime": 2535.172311067581, "_timestamp": 1585597284.1889846, "_step": 352}
{"Episode reward": -93.13126808860851, "Episode length": 999, "Policy Loss": -0.00456976005807519, "Value Loss": 0.0006233698804862797, "_runtime": 2536.7209181785583, "_timestamp": 1585597285.7375917, "_step": 353}
{"Episode reward": -93.74933363170904, "Episode length": 999, "Policy Loss": -0.0037969411350786686, "Value Loss": 0.0004073181189596653, "_runtime": 2538.2743651866913, "_timestamp": 1585597287.2910388, "_step": 354}
{"Episode reward": -95.91844424495447, "Episode length": 999, "Policy Loss": -0.010893464088439941, "Value Loss": 0.0003633126034401357, "_runtime": 2539.8601570129395, "_timestamp": 1585597288.8768306, "_step": 355}
{"Episode reward": -94.35132037615972, "Episode length": 999, "Policy Loss": -0.000783154449891299, "Value Loss": 0.0006125058280304074, "_runtime": 2541.4110112190247, "_timestamp": 1585597290.4276848, "_step": 356}
{"Episode reward": -95.25742964179729, "Episode length": 999, "Policy Loss": -0.007501532323658466, "Value Loss": 0.00036973931128159165, "_runtime": 2542.9609100818634, "_timestamp": 1585597291.9775836, "_step": 357}
{"Episode reward": -92.94279475149148, "Episode length": 999, "Policy Loss": 0.001752277254126966, "Value Loss": 0.0005599946598522365, "_runtime": 2544.512578725815, "_timestamp": 1585597293.5292523, "_step": 358}
{"Episode reward": -92.50923288764123, "Episode length": 999, "Policy Loss": -0.00732538104057312, "Value Loss": 0.0009470750228501856, "_runtime": 2546.0546250343323, "_timestamp": 1585597295.0712986, "_step": 359}
{"Episode reward": -92.78304139683135, "Episode length": 999, "Policy Loss": -0.0024684774689376354, "Value Loss": 0.0005707817035727203, "_runtime": 2547.594906806946, "_timestamp": 1585597296.6115804, "_step": 360}
{"Episode reward": -93.47413787813939, "Episode length": 999, "Policy Loss": 0.0024629773106426, "Value Loss": 0.0009270257432945073, "_runtime": 2549.133957386017, "_timestamp": 1585597298.150631, "_step": 361}
{"Episode reward": -92.47254666376863, "Episode length": 999, "Policy Loss": 0.004930827300995588, "Value Loss": 0.0008458458469249308, "_runtime": 2550.6835465431213, "_timestamp": 1585597299.70022, "_step": 362}
{"Episode reward": -93.42659276329613, "Episode length": 999, "Policy Loss": 0.0026695069391280413, "Value Loss": 0.0004753348184749484, "_runtime": 2552.235369205475, "_timestamp": 1585597301.2520428, "_step": 363}
{"Episode reward": -95.87824931377136, "Episode length": 999, "Policy Loss": -0.008668213151395321, "Value Loss": 0.0005316566093824804, "_runtime": 2553.783719062805, "_timestamp": 1585597302.8003926, "_step": 364}
{"Episode reward": -94.97798038038067, "Episode length": 999, "Policy Loss": -0.003562591038644314, "Value Loss": 0.000516556843649596, "_runtime": 2555.3362374305725, "_timestamp": 1585597304.352911, "_step": 365}
{"Episode reward": -93.34525171188344, "Episode length": 999, "Policy Loss": 0.0023940731771290302, "Value Loss": 0.0006144718499854207, "_runtime": 2556.8881051540375, "_timestamp": 1585597305.9047787, "_step": 366}
{"Episode reward": -93.31614867544025, "Episode length": 999, "Policy Loss": 0.0010797266149893403, "Value Loss": 0.0006114410352893174, "_runtime": 2558.436539411545, "_timestamp": 1585597307.453213, "_step": 367}
{"Episode reward": -92.43580871458707, "Episode length": 999, "Policy Loss": 0.0002713380381464958, "Value Loss": 0.0007418976747430861, "_runtime": 2559.98619890213, "_timestamp": 1585597309.0028725, "_step": 368}
{"Episode reward": -93.17698588733629, "Episode length": 999, "Policy Loss": 0.013222070410847664, "Value Loss": 0.0010396239813417196, "_runtime": 2561.5356171131134, "_timestamp": 1585597310.5522907, "_step": 369}
{"Episode reward": -91.36792201421001, "Episode length": 999, "Policy Loss": 0.006519096903502941, "Value Loss": 0.0006152266869321465, "_runtime": 2563.1220338344574, "_timestamp": 1585597312.1387074, "_step": 370}
{"Episode reward": -94.69516306637809, "Episode length": 999, "Policy Loss": -0.00807811040431261, "Value Loss": 0.0006701628444716334, "_runtime": 2564.6664180755615, "_timestamp": 1585597313.6830916, "_step": 371}
{"Episode reward": -91.83942848761676, "Episode length": 999, "Policy Loss": -0.013341259211301804, "Value Loss": 0.0017757137538865209, "_runtime": 2566.218214035034, "_timestamp": 1585597315.2348876, "_step": 372}
{"Episode reward": -93.2627694655086, "Episode length": 999, "Policy Loss": -0.001641205744817853, "Value Loss": 0.0005773616139777005, "_runtime": 2567.7561926841736, "_timestamp": 1585597316.7728662, "_step": 373}
{"Episode reward": -94.04432802038924, "Episode length": 999, "Policy Loss": 0.00753759266808629, "Value Loss": 0.0025602164678275585, "_runtime": 2569.306113243103, "_timestamp": 1585597318.3227868, "_step": 374}
{"Episode reward": -93.12313171981206, "Episode length": 999, "Policy Loss": 0.018191974610090256, "Value Loss": 0.002041357569396496, "_runtime": 2570.8481822013855, "_timestamp": 1585597319.8648558, "_step": 375}
{"Episode reward": -92.4107326114145, "Episode length": 999, "Policy Loss": -0.005448389798402786, "Value Loss": 0.0012490113731473684, "_runtime": 2572.3920543193817, "_timestamp": 1585597321.408728, "_step": 376}
{"Episode reward": -92.1480411098862, "Episode length": 999, "Policy Loss": -0.025028718635439873, "Value Loss": 0.005282006226480007, "_runtime": 2573.944718837738, "_timestamp": 1585597322.9613924, "_step": 377}
{"Episode reward": -92.749344457389, "Episode length": 999, "Policy Loss": -0.010914376005530357, "Value Loss": 0.001297754468396306, "_runtime": 2575.4967863559723, "_timestamp": 1585597324.51346, "_step": 378}
{"Episode reward": -91.93084953036453, "Episode length": 999, "Policy Loss": 0.017525192350149155, "Value Loss": 0.0026832527946680784, "_runtime": 2577.04922580719, "_timestamp": 1585597326.0658994, "_step": 379}
{"Episode reward": -94.86817959954767, "Episode length": 999, "Policy Loss": 0.007383039221167564, "Value Loss": 0.00490884855389595, "_runtime": 2578.592257499695, "_timestamp": 1585597327.608931, "_step": 380}
{"Episode reward": -92.37796404223555, "Episode length": 999, "Policy Loss": 0.0034968515392392874, "Value Loss": 0.0018821497214958072, "_runtime": 2580.1432678699493, "_timestamp": 1585597329.1599414, "_step": 381}
{"Episode reward": -92.29902368800023, "Episode length": 999, "Policy Loss": 0.005323735531419516, "Value Loss": 0.0023441114462912083, "_runtime": 2581.671647310257, "_timestamp": 1585597330.6883209, "_step": 382}
{"Episode reward": -92.86568197568191, "Episode length": 999, "Policy Loss": 0.0014062706613913178, "Value Loss": 0.0016585846897214651, "_runtime": 2583.2240722179413, "_timestamp": 1585597332.2407458, "_step": 383}
{"Episode reward": -91.61375301962421, "Episode length": 999, "Policy Loss": -0.05668838322162628, "Value Loss": 0.01072852686047554, "_runtime": 2584.7742488384247, "_timestamp": 1585597333.7909224, "_step": 384}
{"Episode reward": -93.07275745094111, "Episode length": 999, "Policy Loss": 0.0025900835171341896, "Value Loss": 0.0008141869329847395, "_runtime": 2586.363245010376, "_timestamp": 1585597335.3799186, "_step": 385}
{"Episode reward": -91.54678214212964, "Episode length": 999, "Policy Loss": 0.007548405788838863, "Value Loss": 0.004012015648186207, "_runtime": 2587.9167442321777, "_timestamp": 1585597336.9334178, "_step": 386}
{"Episode reward": -93.38199510432314, "Episode length": 999, "Policy Loss": -0.0008391041774302721, "Value Loss": 0.005295922048389912, "_runtime": 2589.4548859596252, "_timestamp": 1585597338.4715595, "_step": 387}
{"Episode reward": -91.58199212940143, "Episode length": 999, "Policy Loss": 0.07976965606212616, "Value Loss": 0.02290753461420536, "_runtime": 2591.0028324127197, "_timestamp": 1585597340.019506, "_step": 388}
{"Episode reward": -94.22010009930467, "Episode length": 999, "Policy Loss": -0.004473164211958647, "Value Loss": 0.000985512277111411, "_runtime": 2592.5550060272217, "_timestamp": 1585597341.5716796, "_step": 389}
{"Episode reward": -90.751425044879, "Episode length": 999, "Policy Loss": -0.011017109267413616, "Value Loss": 0.011651530861854553, "_runtime": 2594.1077432632446, "_timestamp": 1585597343.1244168, "_step": 390}
{"Episode reward": -92.31632009602762, "Episode length": 999, "Policy Loss": -0.00798015482723713, "Value Loss": 0.013871666043996811, "_runtime": 2595.6556375026703, "_timestamp": 1585597344.672311, "_step": 391}
{"Episode reward": -89.25636217652055, "Episode length": 999, "Policy Loss": -0.014650346711277962, "Value Loss": 0.016742369160056114, "_runtime": 2597.2105128765106, "_timestamp": 1585597346.2271864, "_step": 392}
{"Episode reward": -89.13275560792684, "Episode length": 999, "Policy Loss": -0.05478755757212639, "Value Loss": 0.01583155058324337, "_runtime": 2598.763118982315, "_timestamp": 1585597347.7797925, "_step": 393}
{"Episode reward": -93.20897872161964, "Episode length": 999, "Policy Loss": 0.013270024210214615, "Value Loss": 0.0018238257616758347, "_runtime": 2600.312884569168, "_timestamp": 1585597349.3295581, "_step": 394}
{"Episode reward": -93.80708920911928, "Episode length": 999, "Policy Loss": -0.01902143284678459, "Value Loss": 0.005164340138435364, "_runtime": 2601.861708164215, "_timestamp": 1585597350.8783817, "_step": 395}
{"Episode reward": -92.57238458189164, "Episode length": 999, "Policy Loss": 0.012862656265497208, "Value Loss": 0.020748551934957504, "_runtime": 2603.404142141342, "_timestamp": 1585597352.4208157, "_step": 396}
{"Episode reward": -91.23818811608068, "Episode length": 999, "Policy Loss": 0.06662435084581375, "Value Loss": 0.04437620937824249, "_runtime": 2604.945749282837, "_timestamp": 1585597353.9624228, "_step": 397}
{"Episode reward": -92.9618208613342, "Episode length": 999, "Policy Loss": 0.024773957207798958, "Value Loss": 0.020034264773130417, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696, -0.20704831182956696]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.23824246227741241, -0.22873519361019135, -0.21922792494297028, -0.209720641374588, -0.20021337270736694, -0.19070610404014587, -0.1811988353729248, -0.17169156670570374, -0.16218429803848267, -0.1526770293712616, -0.14316974580287933, -0.13366247713565826, -0.1241552084684372, -0.11464793235063553, -0.10514065623283386, -0.09563338756561279, -0.08612611889839172, -0.07661885023117065, -0.06711158156394958, -0.05760429799556732, -0.04809702932834625, -0.03858976066112518, -0.029082491993904114, -0.019575223326683044, -0.010067954659461975, -0.0005606710910797119, 0.008946597576141357, 0.01845388114452362, 0.02796114981174469, 0.03746841847896576, 0.04697568714618683, 0.0564829558134079, 0.06599022448062897, 0.07549749314785004, 0.0850047618150711, 0.09451203048229218, 0.10401929914951324, 0.11352656781673431, 0.12303386628627777, 0.13254113495349884, 0.1420484036207199, 0.15155567228794098, 0.16106294095516205, 0.17057020962238312, 0.1800774782896042, 0.18958474695682526, 0.19909201562404633, 0.2085992842912674, 0.21810655295848846, 0.22761385142803192, 0.237121120095253, 0.24662838876247406, 0.25613564252853394, 0.2656429409980774, 0.27515023946762085, 0.28465747833251953, 0.294164776802063, 0.30367201566696167, 0.3131793141365051, 0.3226865530014038, 0.33219385147094727, 0.34170109033584595, 0.3512083888053894, 0.3607156276702881, 0.37022292613983154]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.138331800699234, -0.1331244558095932, -0.1279171109199524, -0.12270977348089218, -0.11750242859125137, -0.11229508370161057, -0.10708774626255035, -0.10188040137290955, -0.09667305648326874, -0.09146571159362793, -0.08625836670398712, -0.08105102926492691, -0.0758436843752861, -0.0706363394856453, -0.06542900204658508, -0.060221657156944275, -0.05501431226730347, -0.04980696737766266, -0.04459962248802185, -0.03939228504896164, -0.03418494015932083, -0.028977595269680023, -0.023770257830619812, -0.018562912940979004, -0.013355568051338196, -0.008148223161697388, -0.0029408782720565796, 0.0022664666175842285, 0.007473796606063843, 0.012681141495704651, 0.01788848638534546, 0.023095831274986267, 0.028303176164627075, 0.03351052105426788, 0.03871786594390869, 0.0439252108335495, 0.04913255572319031, 0.05433988571166992, 0.05954723060131073, 0.06475457549095154, 0.06996192038059235, 0.07516926527023315, 0.08037661015987396, 0.08558395504951477, 0.09079128503799438, 0.09599862992763519, 0.101205974817276, 0.10641331970691681, 0.11162066459655762, 0.11682799458503723, 0.12203535437583923, 0.12724268436431885, 0.13245004415512085, 0.13765737414360046, 0.14286473393440247, 0.14807206392288208, 0.1532793939113617, 0.1584867537021637, 0.1636940836906433, 0.1689014434814453, 0.17410877346992493, 0.17931613326072693, 0.18452346324920654, 0.18973082304000854, 0.19493815302848816]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 5.0, 5.0, 3.0, 6.0, 9.0, 9.0, 7.0, 15.0, 19.0, 20.0, 19.0, 20.0, 29.0, 39.0, 26.0, 40.0, 38.0, 27.0, 23.0, 23.0, 23.0, 14.0, 15.0, 13.0, 7.0, 5.0, 7.0, 9.0, 4.0, 3.0, 0.0, 6.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08514346927404404, -0.08161371201276779, -0.07808394730091095, -0.0745541900396347, -0.07102443277835846, -0.06749467551708221, -0.06396491080522537, -0.06043515354394913, -0.056905392557382584, -0.05337563157081604, -0.049845874309539795, -0.04631611332297325, -0.04278635233640671, -0.03925659507513046, -0.03572683408856392, -0.032197076827287674, -0.02866731584072113, -0.025137554854154587, -0.021607793867588043, -0.018078036606311798, -0.014548279345035553, -0.011018514633178711, -0.007488757371902466, -0.003959000110626221, -0.00042923539876937866, 0.0031005218625068665, 0.006630279123783112, 0.010160036385059357, 0.013689801096916199, 0.017219558358192444, 0.02074931561946869, 0.02427908033132553, 0.027808837592601776, 0.03133859485387802, 0.03486835956573486, 0.03839811682701111, 0.04192788153886795, 0.045457638800144196, 0.04898739606142044, 0.052517153322696686, 0.05604691058397293, 0.059576667845249176, 0.06310644000768661, 0.06663619726896286, 0.0701659545302391, 0.07369571179151535, 0.0772254690527916, 0.08075522631406784, 0.08428499847650528, 0.08781475573778152, 0.09134451299905777, 0.09487427026033401, 0.09840402752161026, 0.1019337847828865, 0.10546354204416275, 0.10899331420660019, 0.11252307146787643, 0.11605282872915268, 0.11958258599042892, 0.12311234325170517, 0.126642107963562, 0.13017186522483826, 0.1337016224861145, 0.13723137974739075, 0.140761137008667]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9391685128211975, -0.9087019562721252, -0.8782353401184082, -0.8477687835693359, -0.8173022270202637, -0.7868356108665466, -0.7563690543174744, -0.7259024381637573, -0.6954358816146851, -0.6649693250656128, -0.6345027089118958, -0.6040361523628235, -0.5735695362091064, -0.5431029796600342, -0.5126364231109619, -0.48216983675956726, -0.4517032504081726, -0.42123669385910034, -0.3907700777053833, -0.36030352115631104, -0.329836905002594, -0.29937034845352173, -0.26890379190444946, -0.23843717575073242, -0.20797061920166016, -0.1775040626525879, -0.14703744649887085, -0.11657088994979858, -0.08610433340072632, -0.05563771724700928, -0.02517116069793701, 0.005295455455780029, 0.035762012004852295, 0.06622856855392456, 0.09669512510299683, 0.12716180086135864, 0.1576283574104309, 0.18809491395950317, 0.21856147050857544, 0.2490280270576477, 0.2794947028160095, 0.3099612593650818, 0.34042781591415405, 0.3708943724632263, 0.4013609290122986, 0.43182748556137085, 0.46229416131973267, 0.49276071786880493, 0.5232272744178772, 0.5536938309669495, 0.5841603875160217, 0.6146270632743835, 0.6450936198234558, 0.6755601763725281, 0.7060267329216003, 0.7364932894706726, 0.7669598460197449, 0.7974265217781067, 0.827893078327179, 0.8583596348762512, 0.8888261914253235, 0.9192927479743958, 0.9497594237327576, 0.9802259802818298, 1.0106925964355469]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.21806278824806213, -0.21062278747558594, -0.20318277180194855, -0.19574277102947235, -0.18830277025699615, -0.18086275458335876, -0.17342275381088257, -0.16598275303840637, -0.15854273736476898, -0.15110273659229279, -0.1436627209186554, -0.1362227201461792, -0.128782719373703, -0.12134271115064621, -0.11390270292758942, -0.10646270215511322, -0.09902269393205643, -0.09158268570899963, -0.08414268493652344, -0.07670266926288605, -0.06926266849040985, -0.061822667717933655, -0.054382652044296265, -0.04694265127182007, -0.03950265049934387, -0.03206263482570648, -0.024622634053230286, -0.01718263328075409, -0.0097426176071167, -0.002302616834640503, 0.005137383937835693, 0.012577399611473083, 0.02001740038394928, 0.027457401156425476, 0.034897416830062866, 0.04233741760253906, 0.04977741837501526, 0.057217419147491455, 0.06465744972229004, 0.07209745049476624, 0.07953745126724243, 0.08697745203971863, 0.09441745281219482, 0.10185745358467102, 0.1092974841594696, 0.1167374849319458, 0.124177485704422, 0.1316174864768982, 0.1390574872493744, 0.14649748802185059, 0.15393751859664917, 0.16137751936912537, 0.16881752014160156, 0.17625752091407776, 0.18369752168655396, 0.19113752245903015, 0.19857755303382874, 0.20601755380630493, 0.21345755457878113, 0.22089755535125732, 0.22833755612373352, 0.23577755689620972, 0.2432175874710083, 0.2506575882434845, 0.2580975890159607]}, "_runtime": 2606.4968786239624, "_timestamp": 1585597355.5135522, "_step": 398}
{"Episode reward": -94.121061906277, "Episode length": 999, "Policy Loss": -0.01584514044225216, "Value Loss": 0.0033449968323111534, "_runtime": 2608.0471851825714, "_timestamp": 1585597357.0638587, "_step": 399}
{"Episode reward": -94.46041752607988, "Episode length": 999, "Policy Loss": -0.026001671329140663, "Value Loss": 0.0005149947828613222, "_runtime": 2609.634385585785, "_timestamp": 1585597358.6510592, "_step": 400}
{"Episode reward": -92.32660995776726, "Episode length": 999, "Policy Loss": -0.03087644651532173, "Value Loss": 0.004751286469399929, "_runtime": 2611.1861250400543, "_timestamp": 1585597360.2027986, "_step": 401}
{"Episode reward": -94.51446256352467, "Episode length": 999, "Policy Loss": -0.0409248061478138, "Value Loss": 0.008814391680061817, "_runtime": 2612.726981163025, "_timestamp": 1585597361.7436547, "_step": 402}
{"Episode reward": -94.63766704965764, "Episode length": 999, "Policy Loss": -0.03270580992102623, "Value Loss": 0.010419542901217937, "_runtime": 2614.2882373332977, "_timestamp": 1585597363.304911, "_step": 403}
{"Episode reward": -94.37618066619726, "Episode length": 999, "Policy Loss": -0.028624434024095535, "Value Loss": 0.0067137167789042, "_runtime": 2614.2882373332977, "_timestamp": 1585597363.304911, "_step": 404}
