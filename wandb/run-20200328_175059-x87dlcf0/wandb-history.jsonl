{"Episode reward": -99.1895315512498, "Episode length": 999, "Policy Loss": -0.13356533646583557, "Value Loss": 0.028334761038422585, "_runtime": 6.162417888641357, "_timestamp": 1585417865.042644, "_step": 0}
{"Episode reward": -91.63955593746682, "Episode length": 999, "Policy Loss": -0.12935151159763336, "Value Loss": 0.02499447949230671, "_runtime": 7.314691781997681, "_timestamp": 1585417866.194918, "_step": 1}
{"Episode reward": -105.46827882009596, "Episode length": 999, "Policy Loss": -0.1552734673023224, "Value Loss": 0.03183898329734802, "_runtime": 8.529507637023926, "_timestamp": 1585417867.4097338, "_step": 2}
{"Episode reward": -101.20073533775961, "Episode length": 999, "Policy Loss": -0.14016006886959076, "Value Loss": 0.03404756635427475, "_runtime": 9.784003019332886, "_timestamp": 1585417868.6642292, "_step": 3}
{"Episode reward": -102.40379839595604, "Episode length": 999, "Policy Loss": -0.14338542520999908, "Value Loss": 0.03025117889046669, "_runtime": 10.985503911972046, "_timestamp": 1585417869.86573, "_step": 4}
{"Episode reward": -106.33207069114101, "Episode length": 999, "Policy Loss": -0.14215059578418732, "Value Loss": 0.035055290907621384, "_runtime": 12.186169862747192, "_timestamp": 1585417871.066396, "_step": 5}
{"Episode reward": -104.33598453247137, "Episode length": 999, "Policy Loss": -0.14215794205665588, "Value Loss": 0.03213786333799362, "_runtime": 13.368634700775146, "_timestamp": 1585417872.2488608, "_step": 6}
{"Episode reward": -100.04802390553905, "Episode length": 999, "Policy Loss": -0.14461538195610046, "Value Loss": 0.02853821963071823, "_runtime": 14.563843727111816, "_timestamp": 1585417873.4440699, "_step": 7}
{"Episode reward": -107.92806744833287, "Episode length": 999, "Policy Loss": -0.14694467186927795, "Value Loss": 0.03327764943242073, "_runtime": 15.7951500415802, "_timestamp": 1585417874.6753762, "_step": 8}
{"Episode reward": -105.72386148937667, "Episode length": 999, "Policy Loss": -0.1553145796060562, "Value Loss": 0.03442995995283127, "_runtime": 17.065500736236572, "_timestamp": 1585417875.9457269, "_step": 9}
{"Episode reward": -104.68564187642639, "Episode length": 999, "Policy Loss": -0.14611782133579254, "Value Loss": 0.034816596657037735, "_runtime": 18.239125967025757, "_timestamp": 1585417877.119352, "_step": 10}
{"Episode reward": -108.04543316748001, "Episode length": 999, "Policy Loss": -0.16205857694149017, "Value Loss": 0.03784077242016792, "_runtime": 19.54565668106079, "_timestamp": 1585417878.4258828, "_step": 11}
{"Episode reward": -102.16122251124438, "Episode length": 999, "Policy Loss": -0.1413859724998474, "Value Loss": 0.029020540416240692, "_runtime": 20.782346963882446, "_timestamp": 1585417879.662573, "_step": 12}
{"Episode reward": -93.69718240009266, "Episode length": 999, "Policy Loss": -0.12821181118488312, "Value Loss": 0.02644703909754753, "_runtime": 21.9924898147583, "_timestamp": 1585417880.872716, "_step": 13}
{"Episode reward": -109.79883946096278, "Episode length": 999, "Policy Loss": -0.15431083738803864, "Value Loss": 0.03461050987243652, "_runtime": 23.275274991989136, "_timestamp": 1585417882.1555011, "_step": 14}
{"Episode reward": -98.04826968840369, "Episode length": 999, "Policy Loss": -0.12807998061180115, "Value Loss": 0.028712181374430656, "_runtime": 24.523298025131226, "_timestamp": 1585417883.4035242, "_step": 15}
{"Episode reward": -99.83377700687788, "Episode length": 999, "Policy Loss": -0.1396947056055069, "Value Loss": 0.029053056612610817, "_runtime": 25.774279832839966, "_timestamp": 1585417884.654506, "_step": 16}
{"Episode reward": -101.09521367475861, "Episode length": 999, "Policy Loss": -0.1406426876783371, "Value Loss": 0.03421671316027641, "_runtime": 27.035940885543823, "_timestamp": 1585417885.916167, "_step": 17}
{"Episode reward": -103.65287393451769, "Episode length": 999, "Policy Loss": -0.15093491971492767, "Value Loss": 0.030256275087594986, "_runtime": 28.326969861984253, "_timestamp": 1585417887.207196, "_step": 18}
{"Episode reward": -100.57954857904275, "Episode length": 999, "Policy Loss": -0.13419067859649658, "Value Loss": 0.033300455659627914, "_runtime": 29.58979892730713, "_timestamp": 1585417888.470025, "_step": 19}
{"Episode reward": -98.25622506079286, "Episode length": 999, "Policy Loss": -0.13363589346408844, "Value Loss": 0.02751866541802883, "_runtime": 30.84090280532837, "_timestamp": 1585417889.721129, "_step": 20}
{"Episode reward": -104.25896635998308, "Episode length": 999, "Policy Loss": -0.1390707939863205, "Value Loss": 0.04013679921627045, "_runtime": 32.01134276390076, "_timestamp": 1585417890.891569, "_step": 21}
{"Episode reward": -108.16007001960618, "Episode length": 999, "Policy Loss": -0.15251567959785461, "Value Loss": 0.031017709523439407, "_runtime": 33.189467906951904, "_timestamp": 1585417892.069694, "_step": 22}
{"Episode reward": -104.71434030646495, "Episode length": 999, "Policy Loss": -0.1535656750202179, "Value Loss": 0.030797705054283142, "_runtime": 34.39841389656067, "_timestamp": 1585417893.27864, "_step": 23}
{"Episode reward": -112.2314013250297, "Episode length": 999, "Policy Loss": -0.1527920961380005, "Value Loss": 0.03861527517437935, "_runtime": 35.62502193450928, "_timestamp": 1585417894.505248, "_step": 24}
{"Episode reward": -107.02952797218708, "Episode length": 999, "Policy Loss": -0.1481688916683197, "Value Loss": 0.03696117550134659, "_runtime": 36.87041187286377, "_timestamp": 1585417895.750638, "_step": 25}
{"Episode reward": -114.73705347531194, "Episode length": 999, "Policy Loss": -0.1707085371017456, "Value Loss": 0.03816569596529007, "_runtime": 38.05362677574158, "_timestamp": 1585417896.933853, "_step": 26}
{"Episode reward": -109.70209947192905, "Episode length": 999, "Policy Loss": -0.15517526865005493, "Value Loss": 0.03734641149640083, "_runtime": 39.3031108379364, "_timestamp": 1585417898.183337, "_step": 27}
{"Episode reward": -106.63204632858418, "Episode length": 999, "Policy Loss": -0.15740449726581573, "Value Loss": 0.034321270883083344, "_runtime": 40.51079988479614, "_timestamp": 1585417899.391026, "_step": 28}
{"Episode reward": -112.33681329099632, "Episode length": 999, "Policy Loss": -0.16230036318302155, "Value Loss": 0.04109961912035942, "_runtime": 41.83007574081421, "_timestamp": 1585417900.7103019, "_step": 29}
{"Episode reward": -106.19608369617006, "Episode length": 999, "Policy Loss": -0.1468498408794403, "Value Loss": 0.033246833831071854, "_runtime": 43.0477569103241, "_timestamp": 1585417901.927983, "_step": 30}
{"Episode reward": -103.2304386529029, "Episode length": 999, "Policy Loss": -0.13372273743152618, "Value Loss": 0.03719739243388176, "_runtime": 44.248504638671875, "_timestamp": 1585417903.1287308, "_step": 31}
{"Episode reward": -105.61910172857108, "Episode length": 999, "Policy Loss": -0.13988567888736725, "Value Loss": 0.03542046248912811, "_runtime": 45.44199085235596, "_timestamp": 1585417904.322217, "_step": 32}
{"Episode reward": -112.349227198138, "Episode length": 999, "Policy Loss": -0.16366955637931824, "Value Loss": 0.03785298392176628, "_runtime": 46.63771080970764, "_timestamp": 1585417905.517937, "_step": 33}
{"Episode reward": -104.11267794223517, "Episode length": 999, "Policy Loss": -0.15066486597061157, "Value Loss": 0.03219800069928169, "_runtime": 47.87737488746643, "_timestamp": 1585417906.757601, "_step": 34}
{"Episode reward": -104.5908529954392, "Episode length": 999, "Policy Loss": -0.14061301946640015, "Value Loss": 0.032496705651283264, "_runtime": 49.08740568161011, "_timestamp": 1585417907.9676318, "_step": 35}
{"Episode reward": -109.7621235192227, "Episode length": 999, "Policy Loss": -0.15570828318595886, "Value Loss": 0.03508998453617096, "_runtime": 50.403496980667114, "_timestamp": 1585417909.283723, "_step": 36}
{"Episode reward": -110.22319575491578, "Episode length": 999, "Policy Loss": -0.16000616550445557, "Value Loss": 0.038787681609392166, "_runtime": 51.66399002075195, "_timestamp": 1585417910.5442162, "_step": 37}
{"Episode reward": -99.95271489754577, "Episode length": 999, "Policy Loss": -0.13986270129680634, "Value Loss": 0.029314788058400154, "_runtime": 52.925528049468994, "_timestamp": 1585417911.8057542, "_step": 38}
{"Episode reward": -99.0586967513616, "Episode length": 999, "Policy Loss": -0.1397089809179306, "Value Loss": 0.02870233543217182, "_runtime": 54.16118597984314, "_timestamp": 1585417913.041412, "_step": 39}
{"Episode reward": -97.7388692863183, "Episode length": 999, "Policy Loss": -0.13828378915786743, "Value Loss": 0.027708273380994797, "_runtime": 55.34844994544983, "_timestamp": 1585417914.228676, "_step": 40}
{"Episode reward": -106.61056931778757, "Episode length": 999, "Policy Loss": -0.13992589712142944, "Value Loss": 0.03476128727197647, "_runtime": 56.56894779205322, "_timestamp": 1585417915.449174, "_step": 41}
{"Episode reward": -100.09450895825, "Episode length": 999, "Policy Loss": -0.12416581809520721, "Value Loss": 0.03447409346699715, "_runtime": 57.99996995925903, "_timestamp": 1585417916.880196, "_step": 42}
{"Episode reward": -100.75609381431454, "Episode length": 999, "Policy Loss": -0.14101074635982513, "Value Loss": 0.031892988830804825, "_runtime": 59.282471895217896, "_timestamp": 1585417918.162698, "_step": 43}
{"Episode reward": -107.64758526102086, "Episode length": 999, "Policy Loss": -0.1512477695941925, "Value Loss": 0.03288308158516884, "_runtime": 60.5165798664093, "_timestamp": 1585417919.396806, "_step": 44}
{"Episode reward": -105.53046136187805, "Episode length": 999, "Policy Loss": -0.14130207896232605, "Value Loss": 0.03301399573683739, "_runtime": 61.718342781066895, "_timestamp": 1585417920.598569, "_step": 45}
{"Episode reward": -108.34586951700625, "Episode length": 999, "Policy Loss": -0.14365239441394806, "Value Loss": 0.039407260715961456, "_runtime": 62.93016862869263, "_timestamp": 1585417921.8103948, "_step": 46}
{"Episode reward": -100.31460033962597, "Episode length": 999, "Policy Loss": -0.13825760781764984, "Value Loss": 0.03009532392024994, "_runtime": 64.14513874053955, "_timestamp": 1585417923.0253649, "_step": 47}
{"Episode reward": -93.84861746154773, "Episode length": 999, "Policy Loss": -0.1261732578277588, "Value Loss": 0.02725692093372345, "_runtime": 64.87018895149231, "_timestamp": 1585417923.750415, "_step": 48}
{"Episode reward": 40.32945408245014, "Episode length": 580, "Policy Loss": 0.1517302691936493, "Value Loss": 17.179784774780273, "_runtime": 66.08722686767578, "_timestamp": 1585417924.967453, "_step": 49}
{"Episode reward": -106.18795498810692, "Episode length": 999, "Policy Loss": -0.17350883781909943, "Value Loss": 0.035009343177080154, "_runtime": 67.26775884628296, "_timestamp": 1585417926.147985, "_step": 50}
{"Episode reward": -104.17499631732416, "Episode length": 999, "Policy Loss": -0.14470630884170532, "Value Loss": 0.03463679552078247, "_runtime": 68.47849082946777, "_timestamp": 1585417927.358717, "_step": 51}
{"Episode reward": -98.13782259233376, "Episode length": 999, "Policy Loss": -0.13214130699634552, "Value Loss": 0.031811412423849106, "_runtime": 69.72260785102844, "_timestamp": 1585417928.602834, "_step": 52}
{"Episode reward": -100.59470839742968, "Episode length": 999, "Policy Loss": -0.13510563969612122, "Value Loss": 0.032258737832307816, "_runtime": 70.96016573905945, "_timestamp": 1585417929.8403919, "_step": 53}
{"Episode reward": -103.1556375099649, "Episode length": 999, "Policy Loss": -0.1440032422542572, "Value Loss": 0.031132705509662628, "_runtime": 72.17738890647888, "_timestamp": 1585417931.057615, "_step": 54}
{"Episode reward": -109.24392794645405, "Episode length": 999, "Policy Loss": -0.15208426117897034, "Value Loss": 0.03381531313061714, "_runtime": 73.37985301017761, "_timestamp": 1585417932.2600791, "_step": 55}
{"Episode reward": -108.37777503604875, "Episode length": 999, "Policy Loss": -0.14918868243694305, "Value Loss": 0.03332937881350517, "_runtime": 74.70520877838135, "_timestamp": 1585417933.585435, "_step": 56}
{"Episode reward": -117.01791804374626, "Episode length": 999, "Policy Loss": -0.16204962134361267, "Value Loss": 0.04045175760984421, "_runtime": 75.96189594268799, "_timestamp": 1585417934.842122, "_step": 57}
{"Episode reward": -109.28783044585374, "Episode length": 999, "Policy Loss": -0.15541023015975952, "Value Loss": 0.030867135152220726, "_runtime": 77.19908571243286, "_timestamp": 1585417936.0793118, "_step": 58}
{"Episode reward": -111.17636493631522, "Episode length": 999, "Policy Loss": -0.1567550152540207, "Value Loss": 0.034208472818136215, "_runtime": 78.39950895309448, "_timestamp": 1585417937.279735, "_step": 59}
{"Episode reward": -115.04008575728383, "Episode length": 999, "Policy Loss": -0.16391581296920776, "Value Loss": 0.04125818610191345, "_runtime": 79.61170196533203, "_timestamp": 1585417938.491928, "_step": 60}
{"Episode reward": -113.3882553376715, "Episode length": 999, "Policy Loss": -0.16151221096515656, "Value Loss": 0.03753473609685898, "_runtime": 80.8300428390503, "_timestamp": 1585417939.710269, "_step": 61}
{"Episode reward": -110.83267219096656, "Episode length": 999, "Policy Loss": -0.15332335233688354, "Value Loss": 0.034787651151418686, "_runtime": 82.05016684532166, "_timestamp": 1585417940.930393, "_step": 62}
{"Episode reward": -110.7067411098708, "Episode length": 999, "Policy Loss": -0.15188315510749817, "Value Loss": 0.03539169952273369, "_runtime": 83.31808185577393, "_timestamp": 1585417942.198308, "_step": 63}
{"Episode reward": -107.08567838367212, "Episode length": 999, "Policy Loss": -0.14811834692955017, "Value Loss": 0.03270580247044563, "_runtime": 84.54039287567139, "_timestamp": 1585417943.420619, "_step": 64}
{"Episode reward": -112.1570526065942, "Episode length": 999, "Policy Loss": -0.1611027866601944, "Value Loss": 0.03681691363453865, "_runtime": 85.80801391601562, "_timestamp": 1585417944.68824, "_step": 65}
{"Episode reward": -105.26105959263728, "Episode length": 999, "Policy Loss": -0.13979630172252655, "Value Loss": 0.030355015769600868, "_runtime": 87.0129747390747, "_timestamp": 1585417945.8932009, "_step": 66}
{"Episode reward": -117.18721877810826, "Episode length": 999, "Policy Loss": -0.16831153631210327, "Value Loss": 0.037306953221559525, "_runtime": 88.20438385009766, "_timestamp": 1585417947.08461, "_step": 67}
{"Episode reward": -108.79631916954133, "Episode length": 999, "Policy Loss": -0.1461493819952011, "Value Loss": 0.033876873552799225, "_runtime": 88.9533679485321, "_timestamp": 1585417947.833594, "_step": 68}
{"Episode reward": 38.656298589466346, "Episode length": 538, "Policy Loss": 0.11363860964775085, "Value Loss": 18.634775161743164, "_runtime": 90.0148389339447, "_timestamp": 1585417948.895065, "_step": 69}
{"Episode reward": -7.144511223835593, "Episode length": 915, "Policy Loss": -0.05645905062556267, "Value Loss": 10.989855766296387, "_runtime": 91.20658469200134, "_timestamp": 1585417950.0868108, "_step": 70}
{"Episode reward": -127.37901586237462, "Episode length": 999, "Policy Loss": -0.17079195380210876, "Value Loss": 0.045680686831474304, "_runtime": 92.38183188438416, "_timestamp": 1585417951.262058, "_step": 71}
{"Episode reward": -124.8180616910673, "Episode length": 999, "Policy Loss": -0.17912115156650543, "Value Loss": 0.04426799342036247, "_runtime": 93.60453677177429, "_timestamp": 1585417952.484763, "_step": 72}
{"Episode reward": -114.2684564077883, "Episode length": 999, "Policy Loss": -0.15369607508182526, "Value Loss": 0.03999954089522362, "_runtime": 94.74352693557739, "_timestamp": 1585417953.623753, "_step": 73}
{"Episode reward": -116.65395413134743, "Episode length": 999, "Policy Loss": -0.1570306420326233, "Value Loss": 0.04040506109595299, "_runtime": 95.94515490531921, "_timestamp": 1585417954.825381, "_step": 74}
{"Episode reward": -123.82047944780211, "Episode length": 999, "Policy Loss": -0.16675718128681183, "Value Loss": 0.04373430460691452, "_runtime": 96.67594385147095, "_timestamp": 1585417955.55617, "_step": 75}
{"Episode reward": 22.236691419022307, "Episode length": 642, "Policy Loss": -0.013988485559821129, "Value Loss": 15.627181053161621, "_runtime": 97.93913388252258, "_timestamp": 1585417956.81936, "_step": 76}
{"Episode reward": -125.98411949392124, "Episode length": 999, "Policy Loss": -0.191974937915802, "Value Loss": 0.0489262156188488, "_runtime": 99.20935797691345, "_timestamp": 1585417958.089584, "_step": 77}
{"Episode reward": -121.96632473251186, "Episode length": 999, "Policy Loss": -0.1708240509033203, "Value Loss": 0.04167803004384041, "_runtime": 100.43810677528381, "_timestamp": 1585417959.318333, "_step": 78}
{"Episode reward": -114.9549158459262, "Episode length": 999, "Policy Loss": -0.15373633801937103, "Value Loss": 0.0368080772459507, "_runtime": 101.73161292076111, "_timestamp": 1585417960.611839, "_step": 79}
{"Episode reward": -135.59317732610552, "Episode length": 999, "Policy Loss": -0.19921056926250458, "Value Loss": 0.05740297585725784, "_runtime": 102.92525482177734, "_timestamp": 1585417961.805481, "_step": 80}
{"Episode reward": -136.9681998403603, "Episode length": 999, "Policy Loss": -0.19433675706386566, "Value Loss": 0.051379863172769547, "_runtime": 104.15833806991577, "_timestamp": 1585417963.0385642, "_step": 81}
{"Episode reward": -135.28862980676584, "Episode length": 999, "Policy Loss": -0.18684884905815125, "Value Loss": 0.05005189776420593, "_runtime": 105.36701273918152, "_timestamp": 1585417964.2472389, "_step": 82}
{"Episode reward": -125.32825974354182, "Episode length": 999, "Policy Loss": -0.1699696183204651, "Value Loss": 0.04643790423870087, "_runtime": 106.58912682533264, "_timestamp": 1585417965.469353, "_step": 83}
{"Episode reward": -127.08793780029629, "Episode length": 999, "Policy Loss": -0.18781502544879913, "Value Loss": 0.048954129219055176, "_runtime": 107.7628698348999, "_timestamp": 1585417966.643096, "_step": 84}
{"Episode reward": -121.57451119539401, "Episode length": 999, "Policy Loss": -0.17384220659732819, "Value Loss": 0.03924918919801712, "_runtime": 109.05468988418579, "_timestamp": 1585417967.934916, "_step": 85}
{"Episode reward": -134.4794926193563, "Episode length": 999, "Policy Loss": -0.1822519600391388, "Value Loss": 0.05279357731342316, "_runtime": 110.23624396324158, "_timestamp": 1585417969.11647, "_step": 86}
{"Episode reward": -136.1356607503243, "Episode length": 999, "Policy Loss": -0.18870830535888672, "Value Loss": 0.05504518747329712, "_runtime": 111.45145797729492, "_timestamp": 1585417970.331684, "_step": 87}
{"Episode reward": -125.12750189233053, "Episode length": 999, "Policy Loss": -0.16422094404697418, "Value Loss": 0.04679131880402565, "_runtime": 112.71668982505798, "_timestamp": 1585417971.596916, "_step": 88}
{"Episode reward": -129.32020010250963, "Episode length": 999, "Policy Loss": -0.18799984455108643, "Value Loss": 0.048577308654785156, "_runtime": 113.9098207950592, "_timestamp": 1585417972.790047, "_step": 89}
{"Episode reward": -127.55783710390449, "Episode length": 999, "Policy Loss": -0.17402437329292297, "Value Loss": 0.0494520477950573, "_runtime": 115.20886778831482, "_timestamp": 1585417974.089094, "_step": 90}
{"Episode reward": -126.48694412518473, "Episode length": 999, "Policy Loss": -0.18080393970012665, "Value Loss": 0.0465942919254303, "_runtime": 116.41701292991638, "_timestamp": 1585417975.297239, "_step": 91}
{"Episode reward": -121.16914040948089, "Episode length": 999, "Policy Loss": -0.16354569792747498, "Value Loss": 0.04309390112757683, "_runtime": 117.63991975784302, "_timestamp": 1585417976.520146, "_step": 92}
{"Episode reward": -126.55593422539987, "Episode length": 999, "Policy Loss": -0.19261346757411957, "Value Loss": 0.04581344500184059, "_runtime": 118.84857273101807, "_timestamp": 1585417977.7287989, "_step": 93}
{"Episode reward": -115.50390115054594, "Episode length": 999, "Policy Loss": -0.1511574536561966, "Value Loss": 0.04167700931429863, "_runtime": 120.07901573181152, "_timestamp": 1585417978.9592419, "_step": 94}
{"Episode reward": -131.67832741617624, "Episode length": 999, "Policy Loss": -0.17665550112724304, "Value Loss": 0.05089624226093292, "_runtime": 121.28309607505798, "_timestamp": 1585417980.1633222, "_step": 95}
{"Episode reward": -123.66307112665255, "Episode length": 999, "Policy Loss": -0.17028243839740753, "Value Loss": 0.043023716658353806, "_runtime": 122.48274993896484, "_timestamp": 1585417981.362976, "_step": 96}
{"Episode reward": -121.01192098888387, "Episode length": 999, "Policy Loss": -0.17078375816345215, "Value Loss": 0.041675977408885956, "_runtime": 123.6154727935791, "_timestamp": 1585417982.495699, "_step": 97}
{"Episode reward": -22.051188247033053, "Episode length": 964, "Policy Loss": -0.03598269447684288, "Value Loss": 10.430546760559082, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268, -1.848436951637268]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.2488882541656494, -1.2154715061187744, -1.1820546388626099, -1.1486377716064453, -1.1152210235595703, -1.0818042755126953, -1.0483874082565308, -1.0149705410003662, -0.9815537929534912, -0.9481369853019714, -0.9147201776504517, -0.8813033699989319, -0.8478865623474121, -0.8144697546958923, -0.7810529470443726, -0.7476361393928528, -0.714219331741333, -0.6808025240898132, -0.6473857164382935, -0.6139689087867737, -0.5805521011352539, -0.5471352934837341, -0.5137184858322144, -0.4803016781806946, -0.4468848705291748, -0.41346806287765503, -0.38005125522613525, -0.3466344475746155, -0.3132176399230957, -0.2798008322715759, -0.24638402462005615, -0.2129671573638916, -0.1795504093170166, -0.1461336612701416, -0.11271679401397705, -0.0792999267578125, -0.0458831787109375, -0.0124664306640625, 0.02095043659210205, 0.0543673038482666, 0.0877840518951416, 0.1212007999420166, 0.15461766719818115, 0.1880345344543457, 0.2214512825012207, 0.2548680305480957, 0.28828489780426025, 0.3217017650604248, 0.3551185131072998, 0.3885352611541748, 0.42195212841033936, 0.4553689956665039, 0.4887857437133789, 0.5222024917602539, 0.5556193590164185, 0.589036226272583, 0.622452974319458, 0.655869722366333, 0.6892865896224976, 0.7227034568786621, 0.7561202049255371, 0.7895369529724121, 0.8229539394378662, 0.8563706874847412, 0.8897874355316162]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9039677977561951, -0.8736847043037415, -0.8434015512466431, -0.8131184577941895, -0.7828353643417358, -0.7525522112846375, -0.7222691178321838, -0.6919859647750854, -0.6617028713226318, -0.6314197778701782, -0.6011366248130798, -0.5708535313606262, -0.5405703783035278, -0.5102872848510742, -0.4800041913986206, -0.4497210681438446, -0.4194379448890686, -0.389154851436615, -0.3588716983795166, -0.328588604927063, -0.2983054518699646, -0.268022358417511, -0.23773926496505737, -0.20745611190795898, -0.17717301845550537, -0.14688992500305176, -0.11660677194595337, -0.08632367849349976, -0.05604058504104614, -0.025757431983947754, 0.004525661468505859, 0.03480881452560425, 0.06509190797805786, 0.09537500143051147, 0.1256580948829651, 0.15594130754470825, 0.18622440099716187, 0.21650749444961548, 0.2467905879020691, 0.2770736813545227, 0.30735689401626587, 0.3376399874687195, 0.3679230809211731, 0.3982061743736267, 0.4284892678260803, 0.45877236127853394, 0.4890555739402771, 0.5193386673927307, 0.5496217608451843, 0.5799048542976379, 0.6101879477500916, 0.6404711604118347, 0.6707542538642883, 0.7010373473167419, 0.7313204407691956, 0.7616035342216492, 0.7918866276741028, 0.822169840335846, 0.8524529337882996, 0.8827360272407532, 0.9130191206932068, 0.9433022141456604, 0.9735854268074036, 1.003868579864502, 1.034151554107666]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 5.0, 3.0, 0.0, 4.0, 3.0, 1.0, 3.0, 3.0, 5.0, 6.0, 4.0, 2.0, 7.0, 5.0, 4.0, 12.0, 8.0, 5.0, 16.0, 17.0, 20.0, 26.0, 30.0, 30.0, 43.0, 38.0, 41.0, 23.0, 17.0, 15.0, 13.0, 13.0, 1.0, 6.0, 9.0, 6.0, 6.0, 5.0, 9.0, 6.0, 2.0, 5.0, 9.0, 4.0, 0.0, 4.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0], "bins": [-0.610355794429779, -0.5910664796829224, -0.5717771649360657, -0.552487850189209, -0.5331985950469971, -0.5139092803001404, -0.4946199655532837, -0.475330650806427, -0.4560413360595703, -0.4367520213127136, -0.41746270656585693, -0.39817342162132263, -0.37888410687446594, -0.35959479212760925, -0.34030550718307495, -0.32101619243621826, -0.3017268776893616, -0.2824375629425049, -0.2631482481956482, -0.2438589632511139, -0.2245696485042572, -0.2052803337574005, -0.1859910488128662, -0.16670173406600952, -0.14741241931915283, -0.12812310457229614, -0.10883378982543945, -0.08954447507858276, -0.07025521993637085, -0.05096590518951416, -0.03167659044265747, -0.012387275695800781, 0.006902039051055908, 0.026191353797912598, 0.04548066854476929, 0.06476998329162598, 0.08405929803848267, 0.10334855318069458, 0.12263786792755127, 0.14192718267440796, 0.16121649742126465, 0.18050581216812134, 0.19979512691497803, 0.21908444166183472, 0.23837369680404663, 0.2576630115509033, 0.27695232629776, 0.2962416410446167, 0.3155309557914734, 0.3348202705383301, 0.35410958528518677, 0.37339890003204346, 0.39268821477890015, 0.41197746992111206, 0.4312668442726135, 0.45055609941482544, 0.46984535455703735, 0.4891347289085388, 0.5084239840507507, 0.5277133584022522, 0.5470026135444641, 0.5662919878959656, 0.5855812430381775, 0.604870617389679, 0.6241598725318909]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7830739617347717, -0.7610933780670166, -0.7391127347946167, -0.7171320915222168, -0.6951515078544617, -0.6731709241867065, -0.6511902809143066, -0.6292096376419067, -0.6072290539741516, -0.5852484703063965, -0.5632678270339966, -0.5412871837615967, -0.5193066000938416, -0.49732598662376404, -0.4753453731536865, -0.453364759683609, -0.4313841462135315, -0.409403532743454, -0.38742291927337646, -0.36544230580329895, -0.34346169233322144, -0.3214810788631439, -0.2995004653930664, -0.2775198817253113, -0.2555392384529114, -0.23355859518051147, -0.21157801151275635, -0.18959742784500122, -0.16761678457260132, -0.14563614130020142, -0.12365555763244629, -0.10167497396469116, -0.07969433069229126, -0.05771368741989136, -0.03573310375213623, -0.013752520084381104, 0.008228123188018799, 0.0302087664604187, 0.05218935012817383, 0.07416993379592896, 0.09615057706832886, 0.11813122034072876, 0.1401118040084839, 0.162092387676239, 0.18407303094863892, 0.20605367422103882, 0.22803419828414917, 0.2500148415565491, 0.271995484828949, 0.2939761281013489, 0.3159567713737488, 0.33793729543685913, 0.35991793870925903, 0.38189858198165894, 0.4038791060447693, 0.4258597493171692, 0.4478403925895691, 0.469821035861969, 0.4918016791343689, 0.5137822031974792, 0.5357628464698792, 0.557743489742279, 0.5797240138053894, 0.6017046570777893, 0.6236853003501892]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 15.0, 9.0, 7.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.3881673216819763, -0.37973660230636597, -0.3713058829307556, -0.3628751337528229, -0.3544444143772125, -0.3460136950016022, -0.33758294582366943, -0.3291522264480591, -0.32072150707244873, -0.3122907876968384, -0.303860068321228, -0.2954293191432953, -0.28699859976768494, -0.2785678803920746, -0.27013713121414185, -0.2617064118385315, -0.25327569246292114, -0.2448449730873108, -0.23641423881053925, -0.2279835045337677, -0.21955278515815735, -0.211122065782547, -0.20269133150577545, -0.1942605972290039, -0.18582987785339355, -0.1773991584777832, -0.16896842420101166, -0.1605376899242401, -0.15210697054862976, -0.1436762511730194, -0.13524550199508667, -0.12681478261947632, -0.11838406324386597, -0.10995334386825562, -0.10152262449264526, -0.09309187531471252, -0.08466115593910217, -0.07623043656349182, -0.06779968738555908, -0.05936896800994873, -0.05093824863433838, -0.04250752925872803, -0.034076809883117676, -0.025646060705184937, -0.017215341329574585, -0.008784621953964233, -0.00035387277603149414, 0.008076846599578857, 0.01650756597518921, 0.02493828535079956, 0.03336900472640991, 0.04179975390434265, 0.050230473279953, 0.058661192655563354, 0.0670919418334961, 0.07552266120910645, 0.0839533805847168, 0.09238409996032715, 0.1008148193359375, 0.10924556851387024, 0.11767631769180298, 0.12610703706741333, 0.13453775644302368, 0.14296847581863403, 0.15139919519424438]}, "_runtime": 124.86384201049805, "_timestamp": 1585417983.7440681, "_step": 98}
{"Episode reward": -115.20432135938655, "Episode length": 999, "Policy Loss": -0.15690506994724274, "Value Loss": 0.03758901357650757, "_runtime": 126.05711889266968, "_timestamp": 1585417984.937345, "_step": 99}
{"Episode reward": -119.43731780457371, "Episode length": 999, "Policy Loss": -0.165104940533638, "Value Loss": 0.04134393483400345, "_runtime": 127.28305673599243, "_timestamp": 1585417986.1632829, "_step": 100}
{"Episode reward": -114.55169347025388, "Episode length": 999, "Policy Loss": -0.15746667981147766, "Value Loss": 0.04206040874123573, "_runtime": 128.55080699920654, "_timestamp": 1585417987.4310331, "_step": 101}
{"Episode reward": -116.23089608178891, "Episode length": 999, "Policy Loss": -0.1676601767539978, "Value Loss": 0.04154765233397484, "_runtime": 129.93212795257568, "_timestamp": 1585417988.812354, "_step": 102}
{"Episode reward": -110.82698870132047, "Episode length": 999, "Policy Loss": -0.1497061848640442, "Value Loss": 0.035128530114889145, "_runtime": 131.33420586585999, "_timestamp": 1585417990.214432, "_step": 103}
{"Episode reward": -110.70243299631196, "Episode length": 999, "Policy Loss": -0.15049344301223755, "Value Loss": 0.03438825160264969, "_runtime": 132.6079318523407, "_timestamp": 1585417991.488158, "_step": 104}
{"Episode reward": -114.51462274759488, "Episode length": 999, "Policy Loss": -0.16120292246341705, "Value Loss": 0.042310237884521484, "_runtime": 133.82622480392456, "_timestamp": 1585417992.706451, "_step": 105}
{"Episode reward": -114.15359472858334, "Episode length": 999, "Policy Loss": -0.15631058812141418, "Value Loss": 0.03549567610025406, "_runtime": 135.08435893058777, "_timestamp": 1585417993.964585, "_step": 106}
{"Episode reward": -111.6073687603603, "Episode length": 999, "Policy Loss": -0.16515524685382843, "Value Loss": 0.03675740584731102, "_runtime": 136.32384085655212, "_timestamp": 1585417995.204067, "_step": 107}
{"Episode reward": -118.38945076333628, "Episode length": 999, "Policy Loss": -0.17693492770195007, "Value Loss": 0.04010773077607155, "_runtime": 137.56557273864746, "_timestamp": 1585417996.4457989, "_step": 108}
{"Episode reward": -114.89150753378225, "Episode length": 999, "Policy Loss": -0.15525531768798828, "Value Loss": 0.03737194836139679, "_runtime": 138.87782979011536, "_timestamp": 1585417997.758056, "_step": 109}
{"Episode reward": -111.3752059290999, "Episode length": 999, "Policy Loss": -0.1548883020877838, "Value Loss": 0.039888545870780945, "_runtime": 140.1037256717682, "_timestamp": 1585417998.9839518, "_step": 110}
{"Episode reward": -106.57326536485408, "Episode length": 999, "Policy Loss": -0.14690782129764557, "Value Loss": 0.03397538140416145, "_runtime": 141.32642197608948, "_timestamp": 1585418000.206648, "_step": 111}
{"Episode reward": -113.20134153535656, "Episode length": 999, "Policy Loss": -0.15402846038341522, "Value Loss": 0.03978903591632843, "_runtime": 142.6069197654724, "_timestamp": 1585418001.487146, "_step": 112}
{"Episode reward": -102.68636274821552, "Episode length": 999, "Policy Loss": -0.13456735014915466, "Value Loss": 0.03518298268318176, "_runtime": 143.67930698394775, "_timestamp": 1585418002.559533, "_step": 113}
{"Episode reward": 3.9969274642422477, "Episode length": 882, "Policy Loss": -0.034911543130874634, "Value Loss": 11.388131141662598, "_runtime": 144.86538791656494, "_timestamp": 1585418003.745614, "_step": 114}
{"Episode reward": -104.70222699068596, "Episode length": 999, "Policy Loss": -0.13455957174301147, "Value Loss": 0.03506122902035713, "_runtime": 146.14334177970886, "_timestamp": 1585418005.023568, "_step": 115}
{"Episode reward": -101.6100743119029, "Episode length": 999, "Policy Loss": -0.1349264234304428, "Value Loss": 0.03202824294567108, "_runtime": 147.35458874702454, "_timestamp": 1585418006.234815, "_step": 116}
{"Episode reward": -103.98477998819776, "Episode length": 999, "Policy Loss": -0.1460932195186615, "Value Loss": 0.030959678813815117, "_runtime": 148.5249388217926, "_timestamp": 1585418007.405165, "_step": 117}
{"Episode reward": -95.02937606750109, "Episode length": 999, "Policy Loss": -0.1266954094171524, "Value Loss": 0.026244577020406723, "_runtime": 149.7926468849182, "_timestamp": 1585418008.672873, "_step": 118}
{"Episode reward": -104.77167257327237, "Episode length": 999, "Policy Loss": -0.14320117235183716, "Value Loss": 0.03319463133811951, "_runtime": 151.02565383911133, "_timestamp": 1585418009.90588, "_step": 119}
{"Episode reward": -108.91490212151133, "Episode length": 999, "Policy Loss": -0.15534701943397522, "Value Loss": 0.03890468552708626, "_runtime": 152.18777179718018, "_timestamp": 1585418011.067998, "_step": 120}
{"Episode reward": -103.57958853839892, "Episode length": 999, "Policy Loss": -0.13726957142353058, "Value Loss": 0.03320252522826195, "_runtime": 153.37040376663208, "_timestamp": 1585418012.25063, "_step": 121}
{"Episode reward": -101.26656421068087, "Episode length": 999, "Policy Loss": -0.1352492719888687, "Value Loss": 0.03208405151963234, "_runtime": 154.57591485977173, "_timestamp": 1585418013.456141, "_step": 122}
{"Episode reward": -97.2776844734682, "Episode length": 999, "Policy Loss": -0.13570888340473175, "Value Loss": 0.03336504474282265, "_runtime": 155.80842685699463, "_timestamp": 1585418014.688653, "_step": 123}
{"Episode reward": -97.79453819758876, "Episode length": 999, "Policy Loss": -0.13276202976703644, "Value Loss": 0.028088431805372238, "_runtime": 157.05593395233154, "_timestamp": 1585418015.93616, "_step": 124}
{"Episode reward": -95.95762029111678, "Episode length": 999, "Policy Loss": -0.1304364651441574, "Value Loss": 0.025927139446139336, "_runtime": 158.2523148059845, "_timestamp": 1585418017.132541, "_step": 125}
{"Episode reward": -101.82339548548067, "Episode length": 999, "Policy Loss": -0.14235669374465942, "Value Loss": 0.030498730018734932, "_runtime": 159.52163100242615, "_timestamp": 1585418018.4018571, "_step": 126}
{"Episode reward": -101.56395071647302, "Episode length": 999, "Policy Loss": -0.1387634128332138, "Value Loss": 0.03188137337565422, "_runtime": 160.77208280563354, "_timestamp": 1585418019.652309, "_step": 127}
{"Episode reward": -97.0731768916372, "Episode length": 999, "Policy Loss": -0.13177205622196198, "Value Loss": 0.03137682005763054, "_runtime": 161.96497082710266, "_timestamp": 1585418020.845197, "_step": 128}
{"Episode reward": -105.04660849318381, "Episode length": 999, "Policy Loss": -0.14506462216377258, "Value Loss": 0.03261444345116615, "_runtime": 163.2102038860321, "_timestamp": 1585418022.09043, "_step": 129}
{"Episode reward": -104.9698555751603, "Episode length": 999, "Policy Loss": -0.15683212876319885, "Value Loss": 0.03368724510073662, "_runtime": 164.43132996559143, "_timestamp": 1585418023.311556, "_step": 130}
{"Episode reward": -103.51471209073868, "Episode length": 999, "Policy Loss": -0.1453472524881363, "Value Loss": 0.031156718730926514, "_runtime": 165.6617558002472, "_timestamp": 1585418024.541982, "_step": 131}
{"Episode reward": -96.0695007892203, "Episode length": 999, "Policy Loss": -0.12426310777664185, "Value Loss": 0.029722755774855614, "_runtime": 166.88128304481506, "_timestamp": 1585418025.7615092, "_step": 132}
{"Episode reward": -105.26446962058401, "Episode length": 999, "Policy Loss": -0.14681974053382874, "Value Loss": 0.033850669860839844, "_runtime": 168.08672785758972, "_timestamp": 1585418026.966954, "_step": 133}
{"Episode reward": -98.67573777006652, "Episode length": 999, "Policy Loss": -0.13832005858421326, "Value Loss": 0.02951647713780403, "_runtime": 169.39289379119873, "_timestamp": 1585418028.27312, "_step": 134}
{"Episode reward": -95.80677454883399, "Episode length": 999, "Policy Loss": -0.12360558658838272, "Value Loss": 0.028448686003684998, "_runtime": 170.63933682441711, "_timestamp": 1585418029.519563, "_step": 135}
{"Episode reward": -97.57107483837609, "Episode length": 999, "Policy Loss": -0.14284345507621765, "Value Loss": 0.028314514085650444, "_runtime": 171.88492274284363, "_timestamp": 1585418030.7651489, "_step": 136}
{"Episode reward": -106.7410336469248, "Episode length": 999, "Policy Loss": -0.15880581736564636, "Value Loss": 0.0330498144030571, "_runtime": 173.13871264457703, "_timestamp": 1585418032.0189388, "_step": 137}
{"Episode reward": -106.27560353125477, "Episode length": 999, "Policy Loss": -0.1487583965063095, "Value Loss": 0.03432894125580788, "_runtime": 174.40737199783325, "_timestamp": 1585418033.2875981, "_step": 138}
{"Episode reward": -105.67938787473368, "Episode length": 999, "Policy Loss": -0.14841482043266296, "Value Loss": 0.031123001128435135, "_runtime": 175.61469268798828, "_timestamp": 1585418034.4949188, "_step": 139}
{"Episode reward": -95.27450780268424, "Episode length": 999, "Policy Loss": -0.12594889104366302, "Value Loss": 0.026168914511799812, "_runtime": 176.8446400165558, "_timestamp": 1585418035.7248662, "_step": 140}
{"Episode reward": -103.1009245135033, "Episode length": 999, "Policy Loss": -0.14535251259803772, "Value Loss": 0.030295362696051598, "_runtime": 178.04033088684082, "_timestamp": 1585418036.920557, "_step": 141}
{"Episode reward": -99.52713594806315, "Episode length": 999, "Policy Loss": -0.13153132796287537, "Value Loss": 0.028296440839767456, "_runtime": 179.26930475234985, "_timestamp": 1585418038.149531, "_step": 142}
{"Episode reward": -107.151715331033, "Episode length": 999, "Policy Loss": -0.14744733273983002, "Value Loss": 0.03616197034716606, "_runtime": 180.64383268356323, "_timestamp": 1585418039.5240588, "_step": 143}
{"Episode reward": -105.16181155818828, "Episode length": 999, "Policy Loss": -0.15121281147003174, "Value Loss": 0.03247533738613129, "_runtime": 181.87042689323425, "_timestamp": 1585418040.750653, "_step": 144}
{"Episode reward": -100.56197525504646, "Episode length": 999, "Policy Loss": -0.14170661568641663, "Value Loss": 0.029097622260451317, "_runtime": 183.11609077453613, "_timestamp": 1585418041.996317, "_step": 145}
{"Episode reward": -94.71262025624026, "Episode length": 999, "Policy Loss": -0.13036324083805084, "Value Loss": 0.027882441878318787, "_runtime": 184.30155491828918, "_timestamp": 1585418043.181781, "_step": 146}
{"Episode reward": -98.8780033849225, "Episode length": 999, "Policy Loss": -0.13301920890808105, "Value Loss": 0.028751453384757042, "_runtime": 185.54203987121582, "_timestamp": 1585418044.422266, "_step": 147}
{"Episode reward": -104.90979604103782, "Episode length": 999, "Policy Loss": -0.1452406495809555, "Value Loss": 0.03361624479293823, "_runtime": 186.80386471748352, "_timestamp": 1585418045.6840909, "_step": 148}
{"Episode reward": -95.4454930347424, "Episode length": 999, "Policy Loss": -0.12677925825119019, "Value Loss": 0.025745363906025887, "_runtime": 188.08070588111877, "_timestamp": 1585418046.960932, "_step": 149}
{"Episode reward": -101.61014376110724, "Episode length": 999, "Policy Loss": -0.14120706915855408, "Value Loss": 0.031707655638456345, "_runtime": 189.4034938812256, "_timestamp": 1585418048.28372, "_step": 150}
{"Episode reward": -113.39564509640878, "Episode length": 999, "Policy Loss": -0.16010789573192596, "Value Loss": 0.04166916385293007, "_runtime": 190.73682975769043, "_timestamp": 1585418049.617056, "_step": 151}
{"Episode reward": -103.36343877404313, "Episode length": 999, "Policy Loss": -0.14256654679775238, "Value Loss": 0.03155873343348503, "_runtime": 191.9788637161255, "_timestamp": 1585418050.8590899, "_step": 152}
{"Episode reward": -102.50438256587869, "Episode length": 999, "Policy Loss": -0.141126349568367, "Value Loss": 0.030351363122463226, "_runtime": 193.17287707328796, "_timestamp": 1585418052.0531032, "_step": 153}
{"Episode reward": -107.57506689745712, "Episode length": 999, "Policy Loss": -0.14812561869621277, "Value Loss": 0.03250903636217117, "_runtime": 194.3687767982483, "_timestamp": 1585418053.249003, "_step": 154}
{"Episode reward": -101.53404061974159, "Episode length": 999, "Policy Loss": -0.13683687150478363, "Value Loss": 0.028949230909347534, "_runtime": 195.7056896686554, "_timestamp": 1585418054.5859158, "_step": 155}
{"Episode reward": -107.35944258343599, "Episode length": 999, "Policy Loss": -0.1433265209197998, "Value Loss": 0.03540993854403496, "_runtime": 197.01410675048828, "_timestamp": 1585418055.894333, "_step": 156}
{"Episode reward": -108.66817594926854, "Episode length": 999, "Policy Loss": -0.16206485033035278, "Value Loss": 0.03353080525994301, "_runtime": 198.22780895233154, "_timestamp": 1585418057.108035, "_step": 157}
{"Episode reward": -103.22239106974604, "Episode length": 999, "Policy Loss": -0.14216108620166779, "Value Loss": 0.029965149238705635, "_runtime": 199.56843781471252, "_timestamp": 1585418058.448664, "_step": 158}
{"Episode reward": -98.25422989554251, "Episode length": 999, "Policy Loss": -0.13137775659561157, "Value Loss": 0.02729691006243229, "_runtime": 200.87307476997375, "_timestamp": 1585418059.753301, "_step": 159}
{"Episode reward": -102.58889742653943, "Episode length": 999, "Policy Loss": -0.13741709291934967, "Value Loss": 0.03083966299891472, "_runtime": 202.06465983390808, "_timestamp": 1585418060.944886, "_step": 160}
{"Episode reward": -107.118093874853, "Episode length": 999, "Policy Loss": -0.15174677968025208, "Value Loss": 0.03376825898885727, "_runtime": 203.2326557636261, "_timestamp": 1585418062.112882, "_step": 161}
{"Episode reward": -97.2070503663511, "Episode length": 999, "Policy Loss": -0.1291302889585495, "Value Loss": 0.026539234444499016, "_runtime": 204.4367859363556, "_timestamp": 1585418063.317012, "_step": 162}
{"Episode reward": -92.36192540539888, "Episode length": 999, "Policy Loss": -0.12256259471178055, "Value Loss": 0.026533616706728935, "_runtime": 205.68958282470703, "_timestamp": 1585418064.569809, "_step": 163}
{"Episode reward": -103.77457665555139, "Episode length": 999, "Policy Loss": -0.13586166501045227, "Value Loss": 0.03543873503804207, "_runtime": 206.95151782035828, "_timestamp": 1585418065.831744, "_step": 164}
{"Episode reward": -102.54520097158556, "Episode length": 999, "Policy Loss": -0.14448323845863342, "Value Loss": 0.031598154455423355, "_runtime": 208.19876289367676, "_timestamp": 1585418067.078989, "_step": 165}
{"Episode reward": -100.34178714737844, "Episode length": 999, "Policy Loss": -0.12945394217967987, "Value Loss": 0.03040575236082077, "_runtime": 209.44888496398926, "_timestamp": 1585418068.329111, "_step": 166}
{"Episode reward": -105.62863912346211, "Episode length": 999, "Policy Loss": -0.14526468515396118, "Value Loss": 0.03360650688409805, "_runtime": 210.63622283935547, "_timestamp": 1585418069.516449, "_step": 167}
{"Episode reward": -106.53325740801824, "Episode length": 999, "Policy Loss": -0.1525091975927353, "Value Loss": 0.03185174614191055, "_runtime": 211.85731506347656, "_timestamp": 1585418070.7375412, "_step": 168}
{"Episode reward": -102.60816417853235, "Episode length": 999, "Policy Loss": -0.1358061283826828, "Value Loss": 0.03191675990819931, "_runtime": 213.09302878379822, "_timestamp": 1585418071.973255, "_step": 169}
{"Episode reward": -110.97368107299002, "Episode length": 999, "Policy Loss": -0.16109274327754974, "Value Loss": 0.03544476628303528, "_runtime": 214.29657173156738, "_timestamp": 1585418073.1767979, "_step": 170}
{"Episode reward": -104.88531787335988, "Episode length": 999, "Policy Loss": -0.14394314587116241, "Value Loss": 0.03466479852795601, "_runtime": 215.48992896080017, "_timestamp": 1585418074.370155, "_step": 171}
{"Episode reward": -105.97036902133432, "Episode length": 999, "Policy Loss": -0.14086537063121796, "Value Loss": 0.03439684957265854, "_runtime": 216.6883146762848, "_timestamp": 1585418075.5685408, "_step": 172}
{"Episode reward": -101.48712545882537, "Episode length": 999, "Policy Loss": -0.1303403377532959, "Value Loss": 0.031148510053753853, "_runtime": 217.92818689346313, "_timestamp": 1585418076.808413, "_step": 173}
{"Episode reward": -102.05045472085708, "Episode length": 999, "Policy Loss": -0.1421579271554947, "Value Loss": 0.03526626527309418, "_runtime": 219.14264798164368, "_timestamp": 1585418078.022874, "_step": 174}
{"Episode reward": -102.59122132351428, "Episode length": 999, "Policy Loss": -0.13786903023719788, "Value Loss": 0.03417312726378441, "_runtime": 220.34827375411987, "_timestamp": 1585418079.2285, "_step": 175}
{"Episode reward": -115.00485019266057, "Episode length": 999, "Policy Loss": -0.1653115153312683, "Value Loss": 0.038609933108091354, "_runtime": 221.54180574417114, "_timestamp": 1585418080.4220319, "_step": 176}
{"Episode reward": -108.21403220264874, "Episode length": 999, "Policy Loss": -0.1577916443347931, "Value Loss": 0.03647668659687042, "_runtime": 222.76662588119507, "_timestamp": 1585418081.646852, "_step": 177}
{"Episode reward": -104.77789167256549, "Episode length": 999, "Policy Loss": -0.14929413795471191, "Value Loss": 0.03416096791625023, "_runtime": 223.9857738018036, "_timestamp": 1585418082.866, "_step": 178}
{"Episode reward": -100.62924122266918, "Episode length": 999, "Policy Loss": -0.130476713180542, "Value Loss": 0.03143252432346344, "_runtime": 225.16258478164673, "_timestamp": 1585418084.042811, "_step": 179}
{"Episode reward": -95.14879801223226, "Episode length": 999, "Policy Loss": -0.13423243165016174, "Value Loss": 0.02778451330959797, "_runtime": 226.39152002334595, "_timestamp": 1585418085.2717462, "_step": 180}
{"Episode reward": -108.43862297976916, "Episode length": 999, "Policy Loss": -0.14819499850273132, "Value Loss": 0.03675335273146629, "_runtime": 227.57688879966736, "_timestamp": 1585418086.457115, "_step": 181}
{"Episode reward": -102.51560690237577, "Episode length": 999, "Policy Loss": -0.13654474914073944, "Value Loss": 0.032413844019174576, "_runtime": 228.80503869056702, "_timestamp": 1585418087.6852648, "_step": 182}
{"Episode reward": -106.63163787542736, "Episode length": 999, "Policy Loss": -0.15263476967811584, "Value Loss": 0.03269610181450844, "_runtime": 229.99708580970764, "_timestamp": 1585418088.877312, "_step": 183}
{"Episode reward": -106.03453984419598, "Episode length": 999, "Policy Loss": -0.14510422945022583, "Value Loss": 0.03537387773394585, "_runtime": 231.29032683372498, "_timestamp": 1585418090.170553, "_step": 184}
{"Episode reward": -103.69164158735188, "Episode length": 999, "Policy Loss": -0.14045143127441406, "Value Loss": 0.03339682146906853, "_runtime": 232.58673095703125, "_timestamp": 1585418091.466957, "_step": 185}
{"Episode reward": -110.4186678175693, "Episode length": 999, "Policy Loss": -0.1525793820619583, "Value Loss": 0.03624671325087547, "_runtime": 233.8040828704834, "_timestamp": 1585418092.684309, "_step": 186}
{"Episode reward": -104.15452300464902, "Episode length": 999, "Policy Loss": -0.13683509826660156, "Value Loss": 0.03191515430808067, "_runtime": 235.0072786808014, "_timestamp": 1585418093.8875048, "_step": 187}
{"Episode reward": -99.42525549002302, "Episode length": 999, "Policy Loss": -0.13411857187747955, "Value Loss": 0.03139301389455795, "_runtime": 236.25897789001465, "_timestamp": 1585418095.139204, "_step": 188}
{"Episode reward": -112.31106925504712, "Episode length": 999, "Policy Loss": -0.1610078066587448, "Value Loss": 0.03644152358174324, "_runtime": 237.6401708126068, "_timestamp": 1585418096.520397, "_step": 189}
{"Episode reward": -107.83328145504481, "Episode length": 999, "Policy Loss": -0.14885123074054718, "Value Loss": 0.037325065582990646, "_runtime": 238.93332767486572, "_timestamp": 1585418097.8135538, "_step": 190}
{"Episode reward": -100.96999605148453, "Episode length": 999, "Policy Loss": -0.1338699758052826, "Value Loss": 0.027200128883123398, "_runtime": 240.1713228225708, "_timestamp": 1585418099.051549, "_step": 191}
{"Episode reward": -107.85482602063223, "Episode length": 999, "Policy Loss": -0.1655169129371643, "Value Loss": 0.03540254384279251, "_runtime": 241.4143579006195, "_timestamp": 1585418100.294584, "_step": 192}
{"Episode reward": -98.05646755025549, "Episode length": 999, "Policy Loss": -0.12989674508571625, "Value Loss": 0.030597835779190063, "_runtime": 242.69734597206116, "_timestamp": 1585418101.577572, "_step": 193}
{"Episode reward": -102.79832235071552, "Episode length": 999, "Policy Loss": -0.14350387454032898, "Value Loss": 0.02998531050980091, "_runtime": 243.90830373764038, "_timestamp": 1585418102.7885299, "_step": 194}
{"Episode reward": -103.17683716514213, "Episode length": 999, "Policy Loss": -0.15571509301662445, "Value Loss": 0.03347927704453468, "_runtime": 245.14151287078857, "_timestamp": 1585418104.021739, "_step": 195}
{"Episode reward": -113.83140554604464, "Episode length": 999, "Policy Loss": -0.1600365936756134, "Value Loss": 0.03871748596429825, "_runtime": 246.33363580703735, "_timestamp": 1585418105.213862, "_step": 196}
{"Episode reward": -115.82781012920287, "Episode length": 999, "Policy Loss": -0.1708146035671234, "Value Loss": 0.03825262561440468, "_runtime": 247.5660457611084, "_timestamp": 1585418106.446272, "_step": 197}
{"Episode reward": -102.41035642622231, "Episode length": 999, "Policy Loss": -0.13806475698947906, "Value Loss": 0.03453882038593292, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084, -1.1631314754486084]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2130380868911743, -1.183447241783142, -1.1538565158843994, -1.1242656707763672, -1.094674825668335, -1.0650840997695923, -1.03549325466156, -1.0059024095535278, -0.9763116836547852, -0.9467208385467529, -0.9171300530433655, -0.887539267539978, -0.8579484224319458, -0.8283576369285583, -0.7987668514251709, -0.7691760063171387, -0.7395852208137512, -0.7099944353103638, -0.6804035902023315, -0.6508128046989441, -0.6212220191955566, -0.5916311740875244, -0.562040388584137, -0.5324496030807495, -0.5028587579727173, -0.47326797246932983, -0.4436771869659424, -0.41408640146255493, -0.3844955563545227, -0.35490477085113525, -0.3253139853477478, -0.2957231402397156, -0.2661323547363281, -0.23654156923294067, -0.20695078372955322, -0.177359938621521, -0.14776909351348877, -0.1181783676147461, -0.08858752250671387, -0.05899667739868164, -0.029405951499938965, 0.00018489360809326172, 0.02977573871612549, 0.059366464614868164, 0.08895730972290039, 0.11854815483093262, 0.1481388807296753, 0.17772972583770752, 0.20732057094573975, 0.23691129684448242, 0.26650214195251465, 0.2960928678512573, 0.32568371295928955, 0.3552745580673218, 0.38486528396606445, 0.4144561290740967, 0.4440469741821289, 0.4736377000808716, 0.5032285451889038, 0.532819390296936, 0.5624101161956787, 0.5920009613037109, 0.6215918064117432, 0.6511825323104858, 0.6807733774185181]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5549545288085938, -0.5364899039268494, -0.5180252194404602, -0.49956056475639343, -0.48109591007232666, -0.4626312553882599, -0.4441666007041931, -0.42570197582244873, -0.40723729133605957, -0.3887726664543152, -0.370307981967926, -0.35184335708618164, -0.33337870240211487, -0.3149140477180481, -0.2964493930339813, -0.27798473834991455, -0.2595200836658478, -0.241055428981781, -0.22259077429771423, -0.20412611961364746, -0.1856614649295807, -0.16719681024551392, -0.14873215556144714, -0.13026750087738037, -0.11180287599563599, -0.09333822131156921, -0.07487356662750244, -0.05640891194343567, -0.037944257259368896, -0.019479572772979736, -0.0010149478912353516, 0.01744973659515381, 0.03591436147689819, 0.05437898635864258, 0.07284367084503174, 0.09130829572677612, 0.10977298021316528, 0.12823760509490967, 0.14670228958129883, 0.1651669144630432, 0.18363159894943237, 0.20209622383117676, 0.22056090831756592, 0.2390255331993103, 0.25749021768569946, 0.27595484256744385, 0.294419527053833, 0.3128841519355774, 0.3313487768173218, 0.34981346130371094, 0.3682780861854553, 0.3867427706718445, 0.40520739555358887, 0.423672080039978, 0.4421367049217224, 0.4606013298034668, 0.47906601428985596, 0.4975306987762451, 0.5159953832626343, 0.5344599485397339, 0.552924633026123, 0.5713893175125122, 0.5898540019989014, 0.608318567276001, 0.6267832517623901]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 8.0, 2.0, 3.0, 1.0, 3.0, 5.0, 7.0, 6.0, 13.0, 11.0, 15.0, 28.0, 31.0, 28.0, 37.0, 42.0, 37.0, 54.0, 24.0, 21.0, 18.0, 11.0, 17.0, 9.0, 8.0, 7.0, 15.0, 7.0, 5.0, 2.0, 6.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-0.527401328086853, -0.5098534226417542, -0.4923055171966553, -0.4747576117515564, -0.4572097063064575, -0.43966180086135864, -0.4221138656139374, -0.4045659601688385, -0.3870180547237396, -0.36947014927864075, -0.35192224383354187, -0.3343743085861206, -0.31682640314102173, -0.29927849769592285, -0.281730592250824, -0.2641826868057251, -0.24663478136062622, -0.22908687591552734, -0.21153897047042847, -0.1939910650253296, -0.1764431595802307, -0.15889522433280945, -0.14134731888771057, -0.1237994134426117, -0.10625150799751282, -0.08870360255241394, -0.07115569710731506, -0.053607791662216187, -0.03605985641479492, -0.018511950969696045, -0.000964045524597168, 0.01658385992050171, 0.034131765365600586, 0.05167967081069946, 0.06922757625579834, 0.08677548170089722, 0.1043233871459961, 0.12187129259109497, 0.13941919803619385, 0.15696710348129272, 0.1745150089263916, 0.19206297397613525, 0.20961087942123413, 0.227158784866333, 0.24470669031143188, 0.26225459575653076, 0.27980250120162964, 0.2973504066467285, 0.3148983120918274, 0.33244621753692627, 0.34999412298202515, 0.367542028427124, 0.3850899338722229, 0.4026378393173218, 0.42018574476242065, 0.43773365020751953, 0.4552816152572632, 0.4728294610977173, 0.49037742614746094, 0.507925271987915, 0.5254732370376587, 0.5430210828781128, 0.5605690479278564, 0.5781168937683105, 0.5956648588180542]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5260058641433716, -0.5124866962432861, -0.49896755814552307, -0.48544842004776, -0.47192925214767456, -0.4584100842475891, -0.44489094614982605, -0.431371808052063, -0.41785264015197754, -0.4043334722518921, -0.39081433415412903, -0.37729519605636597, -0.3637760281562805, -0.35025686025619507, -0.336737722158432, -0.32321858406066895, -0.3096994161605835, -0.29618024826049805, -0.282661110162735, -0.2691419720649719, -0.2556228041648865, -0.24210363626480103, -0.22858449816703796, -0.2150653600692749, -0.20154619216918945, -0.188027024269104, -0.17450788617134094, -0.16098874807357788, -0.14746958017349243, -0.13395041227340698, -0.12043127417564392, -0.10691213607788086, -0.09339296817779541, -0.07987380027770996, -0.0663546621799469, -0.05283552408218384, -0.03931635618209839, -0.02579718828201294, -0.012278079986572266, 0.0012410879135131836, 0.014760255813598633, 0.028279423713684082, 0.04179859161376953, 0.055317699909210205, 0.06883686780929565, 0.0823560357093811, 0.09587514400482178, 0.10939431190490723, 0.12291347980499268, 0.13643264770507812, 0.14995181560516357, 0.16347092390060425, 0.1769900918006897, 0.19050925970077515, 0.20402836799621582, 0.21754753589630127, 0.23106670379638672, 0.24458587169647217, 0.2581050395965576, 0.2716241478919983, 0.28514331579208374, 0.2986624836921692, 0.31218159198760986, 0.3257007598876953, 0.33921992778778076]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 22.0, 10.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3086865544319153, -0.2967952787876129, -0.28490403294563293, -0.27301275730133057, -0.2611215114593506, -0.24923023581504822, -0.23733897507190704, -0.22544771432876587, -0.2135564535856247, -0.20166519284248352, -0.18977393209934235, -0.17788267135620117, -0.1659913957118988, -0.15410013496875763, -0.14220887422561646, -0.13031761348247528, -0.1184263527393341, -0.10653509199619293, -0.09464383125305176, -0.08275257050991058, -0.07086130976676941, -0.05897003412246704, -0.04707878828048706, -0.03518751263618469, -0.023296236991882324, -0.011404991149902344, 0.0004862844944000244, 0.012377530336380005, 0.024268805980682373, 0.036160051822662354, 0.04805132746696472, 0.0599425733089447, 0.07183384895324707, 0.08372512459754944, 0.09561637043952942, 0.10750764608383179, 0.11939889192581177, 0.13129016757011414, 0.14318141341209412, 0.15507268905639648, 0.16696393489837646, 0.17885521054267883, 0.1907464861869812, 0.20263773202896118, 0.21452897787094116, 0.22642028331756592, 0.2383115291595459, 0.2502027750015259, 0.26209408044815063, 0.2739853262901306, 0.2858765721321106, 0.2977678179740906, 0.30965912342071533, 0.3215503692626953, 0.3334416151046753, 0.3453328609466553, 0.35722416639328003, 0.36911541223526, 0.38100665807724, 0.39289796352386475, 0.4047892093658447, 0.4166804552078247, 0.4285717010498047, 0.44046300649642944, 0.4523542523384094]}, "_runtime": 248.87722182273865, "_timestamp": 1585418107.757448, "_step": 198}
{"Episode reward": -101.42522828370457, "Episode length": 999, "Policy Loss": -0.13731180131435394, "Value Loss": 0.03095926344394684, "_runtime": 250.1097400188446, "_timestamp": 1585418108.9899662, "_step": 199}
{"Episode reward": -110.24825491626869, "Episode length": 999, "Policy Loss": -0.15425436198711395, "Value Loss": 0.03114299662411213, "_runtime": 251.38803386688232, "_timestamp": 1585418110.26826, "_step": 200}
{"Episode reward": -102.21854738437452, "Episode length": 999, "Policy Loss": -0.14619502425193787, "Value Loss": 0.0322301983833313, "_runtime": 252.59507870674133, "_timestamp": 1585418111.4753048, "_step": 201}
{"Episode reward": -107.98432125147856, "Episode length": 999, "Policy Loss": -0.14913631975650787, "Value Loss": 0.03826889023184776, "_runtime": 253.80617785453796, "_timestamp": 1585418112.686404, "_step": 202}
{"Episode reward": -96.28742054785822, "Episode length": 999, "Policy Loss": -0.12644711136817932, "Value Loss": 0.026043053716421127, "_runtime": 254.98937964439392, "_timestamp": 1585418113.8696058, "_step": 203}
{"Episode reward": -110.86305023297561, "Episode length": 999, "Policy Loss": -0.1626131385564804, "Value Loss": 0.03547916188836098, "_runtime": 256.2762370109558, "_timestamp": 1585418115.1564631, "_step": 204}
{"Episode reward": -114.09411610670546, "Episode length": 999, "Policy Loss": -0.16234582662582397, "Value Loss": 0.03969188407063484, "_runtime": 257.57633996009827, "_timestamp": 1585418116.456566, "_step": 205}
{"Episode reward": -103.36646827863008, "Episode length": 999, "Policy Loss": -0.1407078355550766, "Value Loss": 0.031366899609565735, "_runtime": 258.920325756073, "_timestamp": 1585418117.800552, "_step": 206}
{"Episode reward": -113.07103147948577, "Episode length": 999, "Policy Loss": -0.15739408135414124, "Value Loss": 0.03977755457162857, "_runtime": 260.1542909145355, "_timestamp": 1585418119.034517, "_step": 207}
{"Episode reward": -102.89033499053528, "Episode length": 999, "Policy Loss": -0.13694381713867188, "Value Loss": 0.02921372279524803, "_runtime": 261.3417239189148, "_timestamp": 1585418120.22195, "_step": 208}
{"Episode reward": -94.72434685209817, "Episode length": 999, "Policy Loss": -0.12678179144859314, "Value Loss": 0.02962183952331543, "_runtime": 262.6686236858368, "_timestamp": 1585418121.5488498, "_step": 209}
{"Episode reward": -106.74973640642266, "Episode length": 999, "Policy Loss": -0.1500397026538849, "Value Loss": 0.032992638647556305, "_runtime": 263.87869596481323, "_timestamp": 1585418122.758922, "_step": 210}
{"Episode reward": -98.62904126486342, "Episode length": 999, "Policy Loss": -0.12416121363639832, "Value Loss": 0.027799615636467934, "_runtime": 265.17719173431396, "_timestamp": 1585418124.0574179, "_step": 211}
{"Episode reward": -99.18604881881376, "Episode length": 999, "Policy Loss": -0.1353953629732132, "Value Loss": 0.028536206111311913, "_runtime": 266.42906284332275, "_timestamp": 1585418125.309289, "_step": 212}
{"Episode reward": -109.11689771265826, "Episode length": 999, "Policy Loss": -0.15533319115638733, "Value Loss": 0.03478112816810608, "_runtime": 267.6295528411865, "_timestamp": 1585418126.509779, "_step": 213}
{"Episode reward": -107.38847330752219, "Episode length": 999, "Policy Loss": -0.14993686974048615, "Value Loss": 0.03422383591532707, "_runtime": 268.8987169265747, "_timestamp": 1585418127.778943, "_step": 214}
{"Episode reward": -110.02388394993419, "Episode length": 999, "Policy Loss": -0.15517690777778625, "Value Loss": 0.03617759421467781, "_runtime": 270.13838267326355, "_timestamp": 1585418129.0186088, "_step": 215}
{"Episode reward": -104.74151654628582, "Episode length": 999, "Policy Loss": -0.14602228999137878, "Value Loss": 0.036200713366270065, "_runtime": 271.3987247943878, "_timestamp": 1585418130.278951, "_step": 216}
{"Episode reward": -113.27799963857197, "Episode length": 999, "Policy Loss": -0.15679441392421722, "Value Loss": 0.036281585693359375, "_runtime": 272.59115290641785, "_timestamp": 1585418131.471379, "_step": 217}
{"Episode reward": -110.3625290050452, "Episode length": 999, "Policy Loss": -0.1518203318119049, "Value Loss": 0.03501073271036148, "_runtime": 273.75108671188354, "_timestamp": 1585418132.6313128, "_step": 218}
{"Episode reward": -112.08936312890448, "Episode length": 999, "Policy Loss": -0.16195209324359894, "Value Loss": 0.03764323517680168, "_runtime": 274.9810450077057, "_timestamp": 1585418133.8612711, "_step": 219}
{"Episode reward": -105.77491591876367, "Episode length": 999, "Policy Loss": -0.14632058143615723, "Value Loss": 0.0332094207406044, "_runtime": 276.21012783050537, "_timestamp": 1585418135.090354, "_step": 220}
{"Episode reward": -106.24241319524134, "Episode length": 999, "Policy Loss": -0.14887326955795288, "Value Loss": 0.03176052123308182, "_runtime": 277.4701030254364, "_timestamp": 1585418136.3503292, "_step": 221}
{"Episode reward": -104.33023225438036, "Episode length": 999, "Policy Loss": -0.1390846073627472, "Value Loss": 0.03208858519792557, "_runtime": 278.7194678783417, "_timestamp": 1585418137.599694, "_step": 222}
{"Episode reward": -107.99581038078297, "Episode length": 999, "Policy Loss": -0.15429478883743286, "Value Loss": 0.034179527312517166, "_runtime": 280.0053107738495, "_timestamp": 1585418138.885537, "_step": 223}
{"Episode reward": -112.63465650165288, "Episode length": 999, "Policy Loss": -0.15237991511821747, "Value Loss": 0.038909148424863815, "_runtime": 281.26104974746704, "_timestamp": 1585418140.141276, "_step": 224}
{"Episode reward": -104.13809170267855, "Episode length": 999, "Policy Loss": -0.14279919862747192, "Value Loss": 0.03165482357144356, "_runtime": 282.52919602394104, "_timestamp": 1585418141.4094222, "_step": 225}
{"Episode reward": -107.05600204026611, "Episode length": 999, "Policy Loss": -0.15433721244335175, "Value Loss": 0.03392694517970085, "_runtime": 283.75308179855347, "_timestamp": 1585418142.633308, "_step": 226}
{"Episode reward": -106.01761039765978, "Episode length": 999, "Policy Loss": -0.14548581838607788, "Value Loss": 0.031211337074637413, "_runtime": 284.96373987197876, "_timestamp": 1585418143.843966, "_step": 227}
{"Episode reward": -107.44459033020784, "Episode length": 999, "Policy Loss": -0.1536019742488861, "Value Loss": 0.03434869274497032, "_runtime": 286.17446279525757, "_timestamp": 1585418145.054689, "_step": 228}
{"Episode reward": -98.70815739812281, "Episode length": 999, "Policy Loss": -0.1323724240064621, "Value Loss": 0.029553180560469627, "_runtime": 287.41696786880493, "_timestamp": 1585418146.297194, "_step": 229}
{"Episode reward": -94.61870569339538, "Episode length": 999, "Policy Loss": -0.12269742041826248, "Value Loss": 0.026341944932937622, "_runtime": 288.71432185173035, "_timestamp": 1585418147.594548, "_step": 230}
{"Episode reward": -104.4235960155416, "Episode length": 999, "Policy Loss": -0.14885593950748444, "Value Loss": 0.03353516757488251, "_runtime": 289.9956977367401, "_timestamp": 1585418148.8759239, "_step": 231}
{"Episode reward": -105.2326757776458, "Episode length": 999, "Policy Loss": -0.15499497950077057, "Value Loss": 0.03687312826514244, "_runtime": 291.35784792900085, "_timestamp": 1585418150.238074, "_step": 232}
{"Episode reward": -93.48697799015463, "Episode length": 999, "Policy Loss": -0.13231341540813446, "Value Loss": 0.02829989604651928, "_runtime": 292.6049757003784, "_timestamp": 1585418151.4852018, "_step": 233}
{"Episode reward": -109.15530745958614, "Episode length": 999, "Policy Loss": -0.15467114746570587, "Value Loss": 0.03584963083267212, "_runtime": 293.8147418498993, "_timestamp": 1585418152.694968, "_step": 234}
{"Episode reward": -104.72076848231889, "Episode length": 999, "Policy Loss": -0.1445682793855667, "Value Loss": 0.026877304539084435, "_runtime": 295.0558867454529, "_timestamp": 1585418153.9361129, "_step": 235}
{"Episode reward": -106.53287367442171, "Episode length": 999, "Policy Loss": -0.14840678870677948, "Value Loss": 0.035520099103450775, "_runtime": 296.2684338092804, "_timestamp": 1585418155.14866, "_step": 236}
{"Episode reward": -107.20389061744837, "Episode length": 999, "Policy Loss": -0.14963656663894653, "Value Loss": 0.03372406214475632, "_runtime": 297.5436038970947, "_timestamp": 1585418156.42383, "_step": 237}
{"Episode reward": -104.75295519059524, "Episode length": 999, "Policy Loss": -0.1380634903907776, "Value Loss": 0.03231572359800339, "_runtime": 298.7932517528534, "_timestamp": 1585418157.673478, "_step": 238}
{"Episode reward": -99.19668830594821, "Episode length": 999, "Policy Loss": -0.13437478244304657, "Value Loss": 0.03225735202431679, "_runtime": 300.0162398815155, "_timestamp": 1585418158.896466, "_step": 239}
{"Episode reward": -108.25567156941958, "Episode length": 999, "Policy Loss": -0.14730332791805267, "Value Loss": 0.031185436993837357, "_runtime": 301.2954807281494, "_timestamp": 1585418160.1757069, "_step": 240}
{"Episode reward": -109.70221706412798, "Episode length": 999, "Policy Loss": -0.14945906400680542, "Value Loss": 0.03511974960565567, "_runtime": 302.60771584510803, "_timestamp": 1585418161.487942, "_step": 241}
{"Episode reward": -103.8518646139153, "Episode length": 999, "Policy Loss": -0.1407577246427536, "Value Loss": 0.03141985833644867, "_runtime": 303.8102238178253, "_timestamp": 1585418162.69045, "_step": 242}
{"Episode reward": -108.2878047083521, "Episode length": 999, "Policy Loss": -0.1490698605775833, "Value Loss": 0.034343183040618896, "_runtime": 305.0237560272217, "_timestamp": 1585418163.9039822, "_step": 243}
{"Episode reward": -106.71043348937938, "Episode length": 999, "Policy Loss": -0.14122648537158966, "Value Loss": 0.03604598343372345, "_runtime": 306.2306418418884, "_timestamp": 1585418165.110868, "_step": 244}
{"Episode reward": -113.12125752229909, "Episode length": 999, "Policy Loss": -0.16024918854236603, "Value Loss": 0.03876892477273941, "_runtime": 307.4460368156433, "_timestamp": 1585418166.326263, "_step": 245}
{"Episode reward": -112.65878300181106, "Episode length": 999, "Policy Loss": -0.15956375002861023, "Value Loss": 0.03690061345696449, "_runtime": 308.7443149089813, "_timestamp": 1585418167.624541, "_step": 246}
{"Episode reward": -110.14208847854724, "Episode length": 999, "Policy Loss": -0.1548791378736496, "Value Loss": 0.03670749068260193, "_runtime": 309.99014496803284, "_timestamp": 1585418168.870371, "_step": 247}
{"Episode reward": -101.08178887955575, "Episode length": 999, "Policy Loss": -0.13411273062229156, "Value Loss": 0.03350488096475601, "_runtime": 311.2972958087921, "_timestamp": 1585418170.177522, "_step": 248}
{"Episode reward": -94.53487554695921, "Episode length": 999, "Policy Loss": -0.1332588493824005, "Value Loss": 0.0285356342792511, "_runtime": 312.53691482543945, "_timestamp": 1585418171.417141, "_step": 249}
{"Episode reward": -107.05764433086698, "Episode length": 999, "Policy Loss": -0.16358798742294312, "Value Loss": 0.03487030416727066, "_runtime": 313.7361526489258, "_timestamp": 1585418172.6163788, "_step": 250}
{"Episode reward": -106.08673708932261, "Episode length": 999, "Policy Loss": -0.15026934444904327, "Value Loss": 0.0358697846531868, "_runtime": 314.96207189559937, "_timestamp": 1585418173.842298, "_step": 251}
{"Episode reward": -100.34656874366529, "Episode length": 999, "Policy Loss": -0.13691139221191406, "Value Loss": 0.02785251848399639, "_runtime": 316.2170696258545, "_timestamp": 1585418175.0972958, "_step": 252}
{"Episode reward": -99.40171381225827, "Episode length": 999, "Policy Loss": -0.1292748749256134, "Value Loss": 0.027637319639325142, "_runtime": 317.47377586364746, "_timestamp": 1585418176.354002, "_step": 253}
{"Episode reward": -93.25047324623678, "Episode length": 999, "Policy Loss": -0.12482419610023499, "Value Loss": 0.025485100224614143, "_runtime": 318.80555176734924, "_timestamp": 1585418177.685778, "_step": 254}
{"Episode reward": -97.70924172045538, "Episode length": 999, "Policy Loss": -0.12706607580184937, "Value Loss": 0.029608482494950294, "_runtime": 320.05055570602417, "_timestamp": 1585418178.9307818, "_step": 255}
{"Episode reward": -99.42392308155652, "Episode length": 999, "Policy Loss": -0.1449727714061737, "Value Loss": 0.028181590139865875, "_runtime": 321.32577991485596, "_timestamp": 1585418180.206006, "_step": 256}
{"Episode reward": -99.66872154501664, "Episode length": 999, "Policy Loss": -0.1332692801952362, "Value Loss": 0.031097110360860825, "_runtime": 322.63394689559937, "_timestamp": 1585418181.514173, "_step": 257}
{"Episode reward": -95.26246622753862, "Episode length": 999, "Policy Loss": -0.1270524561405182, "Value Loss": 0.02767185866832733, "_runtime": 323.87483167648315, "_timestamp": 1585418182.7550578, "_step": 258}
{"Episode reward": -100.14454238806209, "Episode length": 999, "Policy Loss": -0.1381915956735611, "Value Loss": 0.02882516011595726, "_runtime": 325.1614897251129, "_timestamp": 1585418184.0417159, "_step": 259}
{"Episode reward": -98.5473006630205, "Episode length": 999, "Policy Loss": -0.1309894323348999, "Value Loss": 0.029356518760323524, "_runtime": 326.4515187740326, "_timestamp": 1585418185.331745, "_step": 260}
{"Episode reward": -99.3947254265388, "Episode length": 999, "Policy Loss": -0.13976339995861053, "Value Loss": 0.02860439568758011, "_runtime": 327.6702756881714, "_timestamp": 1585418186.5505018, "_step": 261}
{"Episode reward": -107.04156651000791, "Episode length": 999, "Policy Loss": -0.15555348992347717, "Value Loss": 0.037087712436914444, "_runtime": 328.931893825531, "_timestamp": 1585418187.81212, "_step": 262}
{"Episode reward": -99.01306475308482, "Episode length": 999, "Policy Loss": -0.13814321160316467, "Value Loss": 0.02949507348239422, "_runtime": 330.1054358482361, "_timestamp": 1585418188.985662, "_step": 263}
{"Episode reward": -105.69159936385441, "Episode length": 999, "Policy Loss": -0.14233393967151642, "Value Loss": 0.0324108824133873, "_runtime": 331.29517698287964, "_timestamp": 1585418190.175403, "_step": 264}
{"Episode reward": -92.26638916389336, "Episode length": 999, "Policy Loss": -0.12309429049491882, "Value Loss": 0.025633912533521652, "_runtime": 332.5476689338684, "_timestamp": 1585418191.427895, "_step": 265}
{"Episode reward": -99.17062814289818, "Episode length": 999, "Policy Loss": -0.1384715586900711, "Value Loss": 0.030768757686018944, "_runtime": 333.78950786590576, "_timestamp": 1585418192.669734, "_step": 266}
{"Episode reward": -91.94367569631727, "Episode length": 999, "Policy Loss": -0.1249152198433876, "Value Loss": 0.02404782548546791, "_runtime": 335.0376968383789, "_timestamp": 1585418193.917923, "_step": 267}
{"Episode reward": -92.31497452907871, "Episode length": 999, "Policy Loss": -0.11873847991228104, "Value Loss": 0.024860475212335587, "_runtime": 336.26352190971375, "_timestamp": 1585418195.143748, "_step": 268}
{"Episode reward": -101.50545933946592, "Episode length": 999, "Policy Loss": -0.13694748282432556, "Value Loss": 0.029117975383996964, "_runtime": 337.50695872306824, "_timestamp": 1585418196.3871849, "_step": 269}
{"Episode reward": -106.10299670430058, "Episode length": 999, "Policy Loss": -0.1608314961194992, "Value Loss": 0.0332004651427269, "_runtime": 338.758996963501, "_timestamp": 1585418197.639223, "_step": 270}
{"Episode reward": -100.09010244864449, "Episode length": 999, "Policy Loss": -0.13782404363155365, "Value Loss": 0.030950333923101425, "_runtime": 340.060329914093, "_timestamp": 1585418198.940556, "_step": 271}
{"Episode reward": -99.16815849814246, "Episode length": 999, "Policy Loss": -0.13633199036121368, "Value Loss": 0.030430864542722702, "_runtime": 341.31793785095215, "_timestamp": 1585418200.198164, "_step": 272}
{"Episode reward": -108.484504435175, "Episode length": 999, "Policy Loss": -0.15664830803871155, "Value Loss": 0.03621648624539375, "_runtime": 342.54354882240295, "_timestamp": 1585418201.423775, "_step": 273}
{"Episode reward": -108.64863313697366, "Episode length": 999, "Policy Loss": -0.14931239187717438, "Value Loss": 0.037943363189697266, "_runtime": 343.79930901527405, "_timestamp": 1585418202.6795352, "_step": 274}
{"Episode reward": -97.82188124320628, "Episode length": 999, "Policy Loss": -0.12897208333015442, "Value Loss": 0.02814852073788643, "_runtime": 344.9842429161072, "_timestamp": 1585418203.864469, "_step": 275}
{"Episode reward": -95.0054883775445, "Episode length": 999, "Policy Loss": -0.12559528648853302, "Value Loss": 0.02606477588415146, "_runtime": 346.1685149669647, "_timestamp": 1585418205.048741, "_step": 276}
{"Episode reward": -100.05530649772948, "Episode length": 999, "Policy Loss": -0.1296462118625641, "Value Loss": 0.027755681425333023, "_runtime": 347.3771126270294, "_timestamp": 1585418206.2573388, "_step": 277}
{"Episode reward": -111.72187770146407, "Episode length": 999, "Policy Loss": -0.1642104685306549, "Value Loss": 0.040346723049879074, "_runtime": 348.3808798789978, "_timestamp": 1585418207.261106, "_step": 278}
{"Episode reward": 13.636040880833477, "Episode length": 844, "Policy Loss": 0.037902213633060455, "Value Loss": 11.88848876953125, "_runtime": 349.64356565475464, "_timestamp": 1585418208.5237918, "_step": 279}
{"Episode reward": -95.53073396722438, "Episode length": 999, "Policy Loss": -0.13032640516757965, "Value Loss": 0.026792602613568306, "_runtime": 350.8507468700409, "_timestamp": 1585418209.730973, "_step": 280}
{"Episode reward": -109.11210116389049, "Episode length": 999, "Policy Loss": -0.15789803862571716, "Value Loss": 0.03448532521724701, "_runtime": 352.0663800239563, "_timestamp": 1585418210.9466062, "_step": 281}
{"Episode reward": -99.16554065926975, "Episode length": 999, "Policy Loss": -0.1356067955493927, "Value Loss": 0.031151127070188522, "_runtime": 353.3116159439087, "_timestamp": 1585418212.191842, "_step": 282}
{"Episode reward": -98.20173430774456, "Episode length": 999, "Policy Loss": -0.1437932699918747, "Value Loss": 0.030607333406805992, "_runtime": 354.53519582748413, "_timestamp": 1585418213.415422, "_step": 283}
{"Episode reward": -93.78934662263084, "Episode length": 999, "Policy Loss": -0.1304830014705658, "Value Loss": 0.026745406910777092, "_runtime": 355.7287607192993, "_timestamp": 1585418214.6089869, "_step": 284}
{"Episode reward": -104.47514904124904, "Episode length": 999, "Policy Loss": -0.14374852180480957, "Value Loss": 0.030056888237595558, "_runtime": 356.925598859787, "_timestamp": 1585418215.805825, "_step": 285}
{"Episode reward": -94.22230519717507, "Episode length": 999, "Policy Loss": -0.13184130191802979, "Value Loss": 0.02357214130461216, "_runtime": 358.41653990745544, "_timestamp": 1585418217.296766, "_step": 286}
{"Episode reward": -105.57384122736259, "Episode length": 999, "Policy Loss": -0.14421886205673218, "Value Loss": 0.030767643824219704, "_runtime": 359.76400995254517, "_timestamp": 1585418218.644236, "_step": 287}
{"Episode reward": -99.36052349581371, "Episode length": 999, "Policy Loss": -0.1435641646385193, "Value Loss": 0.028019849210977554, "_runtime": 361.0607280731201, "_timestamp": 1585418219.9409542, "_step": 288}
{"Episode reward": -98.18356654682754, "Episode length": 999, "Policy Loss": -0.13782940804958344, "Value Loss": 0.031049223616719246, "_runtime": 362.2973208427429, "_timestamp": 1585418221.177547, "_step": 289}
{"Episode reward": -96.34718743610114, "Episode length": 999, "Policy Loss": -0.128295436501503, "Value Loss": 0.025516029447317123, "_runtime": 363.53522992134094, "_timestamp": 1585418222.415456, "_step": 290}
{"Episode reward": -100.20842735509795, "Episode length": 999, "Policy Loss": -0.13411323726177216, "Value Loss": 0.02774030528962612, "_runtime": 364.769779920578, "_timestamp": 1585418223.650006, "_step": 291}
{"Episode reward": -100.18338531057869, "Episode length": 999, "Policy Loss": -0.13941596448421478, "Value Loss": 0.03226105123758316, "_runtime": 365.9988899230957, "_timestamp": 1585418224.879116, "_step": 292}
{"Episode reward": -104.05013821037842, "Episode length": 999, "Policy Loss": -0.13925468921661377, "Value Loss": 0.032248470932245255, "_runtime": 367.2261698246002, "_timestamp": 1585418226.106396, "_step": 293}
{"Episode reward": -103.53115987210354, "Episode length": 999, "Policy Loss": -0.14363914728164673, "Value Loss": 0.029419681057333946, "_runtime": 368.5198588371277, "_timestamp": 1585418227.400085, "_step": 294}
{"Episode reward": -108.44210462713237, "Episode length": 999, "Policy Loss": -0.16656647622585297, "Value Loss": 0.039293356239795685, "_runtime": 369.7433068752289, "_timestamp": 1585418228.623533, "_step": 295}
{"Episode reward": -100.67507050958528, "Episode length": 999, "Policy Loss": -0.13141551613807678, "Value Loss": 0.031313683837652206, "_runtime": 371.01515793800354, "_timestamp": 1585418229.895384, "_step": 296}
{"Episode reward": -109.38485771508743, "Episode length": 999, "Policy Loss": -0.16033819317817688, "Value Loss": 0.03756191208958626, "_runtime": 372.2256886959076, "_timestamp": 1585418231.1059148, "_step": 297}
{"Episode reward": -95.19899922206727, "Episode length": 999, "Policy Loss": -0.1291511058807373, "Value Loss": 0.028171900659799576, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029, -6.371139049530029]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.987898349761963, -5.838155746459961, -5.688412666320801, -5.538670063018799, -5.388927459716797, -5.239184379577637, -5.089441776275635, -4.939699172973633, -4.789956092834473, -4.640213489532471, -4.490470886230469, -4.340727806091309, -4.190985202789307, -4.041242599487305, -3.8914997577667236, -3.7417571544647217, -3.5920143127441406, -3.4422714710235596, -3.2925288677215576, -3.1427860260009766, -2.9930434226989746, -2.8433005809783936, -2.6935577392578125, -2.5438151359558105, -2.3940722942352295, -2.2443294525146484, -2.0945868492126465, -1.9448442459106445, -1.7951011657714844, -1.6453585624694824, -1.4956159591674805, -1.3458728790283203, -1.1961302757263184, -1.0463876724243164, -0.8966445922851562, -0.7469019889831543, -0.5971593856811523, -0.4474163055419922, -0.29767370223999023, -0.14793109893798828, 0.0018115043640136719, 0.15155458450317383, 0.3012971878051758, 0.45103979110717773, 0.6007828712463379, 0.7505254745483398, 0.9002680778503418, 1.050011157989502, 1.199753761291504, 1.3494963645935059, 1.499239444732666, 1.648982048034668, 1.79872465133667, 1.94846773147583, 2.098209857940674, 2.247952938079834, 2.397696018218994, 2.547438144683838, 2.697181224822998, 2.846924304962158, 2.996666431427002, 3.146409511566162, 3.2961525917053223, 3.445894718170166, 3.595637798309326]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.0268807411193848, -2.9267635345458984, -2.826646327972412, -2.726529121398926, -2.6264119148254395, -2.526294708251953, -2.4261772632598877, -2.3260600566864014, -2.225942850112915, -2.1258256435394287, -2.0257084369659424, -1.9255911111831665, -1.8254739046096802, -1.7253566980361938, -1.625239372253418, -1.5251221656799316, -1.4250049591064453, -1.324887752532959, -1.2247705459594727, -1.1246532201766968, -1.0245361328125, -0.9244186878204346, -0.8243014812469482, -0.7241842746734619, -0.6240670680999756, -0.5239498615264893, -0.42383265495300293, -0.3237154483795166, -0.22359800338745117, -0.12348079681396484, -0.023363590240478516, 0.07675361633300781, 0.17687082290649414, 0.27698802947998047, 0.3771052360534668, 0.4772224426269531, 0.5773396492004395, 0.6774570941925049, 0.7775743007659912, 0.8776915073394775, 0.9778084754943848, 1.0779261589050293, 1.1780433654785156, 1.278160572052002, 1.3782777786254883, 1.4783949851989746, 1.578512191772461, 1.6786293983459473, 1.7787466049194336, 1.87886381149292, 1.9789810180664062, 2.0790982246398926, 2.179215431213379, 2.2793326377868652, 2.3794498443603516, 2.479567050933838, 2.5796847343444824, 2.6798019409179688, 2.779919147491455, 2.8800363540649414, 2.9801535606384277, 3.080270767211914, 3.1803879737854004, 3.2805051803588867, 3.380622386932373]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 8.0, 16.0, 10.0, 14.0, 29.0, 25.0, 19.0, 38.0, 38.0, 38.0, 57.0, 25.0, 18.0, 16.0, 15.0, 7.0, 12.0, 14.0, 10.0, 11.0, 5.0, 7.0, 6.0, 6.0, 8.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-2.4915242195129395, -2.409114360809326, -2.326704740524292, -2.2442948818206787, -2.1618852615356445, -2.0794754028320312, -1.997065544128418, -1.9146558046340942, -1.8322460651397705, -1.7498363256454468, -1.667426586151123, -1.5850167274475098, -1.502606987953186, -1.4201972484588623, -1.337787389755249, -1.2553776502609253, -1.1729679107666016, -1.0905581712722778, -1.008148431777954, -0.9257385730743408, -0.8433288335800171, -0.7609190940856934, -0.6785092353820801, -0.5960994958877563, -0.5136897563934326, -0.43127989768981934, -0.34887027740478516, -0.2664604187011719, -0.1840505599975586, -0.10164093971252441, -0.019231081008911133, 0.06317853927612305, 0.14558839797973633, 0.2279982566833496, 0.3104078769683838, 0.39281773567199707, 0.47522735595703125, 0.5576372146606445, 0.6400470733642578, 0.722456693649292, 0.8048665523529053, 0.8872764110565186, 0.9696860313415527, 1.052095890045166, 1.1345057487487793, 1.2169153690338135, 1.2993252277374268, 1.381734848022461, 1.4641447067260742, 1.5465545654296875, 1.6289644241333008, 1.7113738059997559, 1.7937836647033691, 1.8761935234069824, 1.9586033821105957, 2.041013240814209, 2.1234230995178223, 2.2058324813842773, 2.2882423400878906, 2.370652198791504, 2.453062057495117, 2.5354719161987305, 2.6178812980651855, 2.700291156768799, 2.782701015472412]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.6896474361419678, -2.6171040534973145, -2.5445609092712402, -2.472017765045166, -2.3994743824005127, -2.3269309997558594, -2.254387855529785, -2.181844711303711, -2.1093013286590576, -2.0367579460144043, -1.96421480178833, -1.8916715383529663, -1.8191282749176025, -1.7465850114822388, -1.674041748046875, -1.6014984846115112, -1.5289552211761475, -1.4564119577407837, -1.38386869430542, -1.3113254308700562, -1.2387821674346924, -1.1662389039993286, -1.0936956405639648, -1.021152377128601, -0.9486091136932373, -0.8760658502578735, -0.8035225868225098, -0.730979323387146, -0.6584360599517822, -0.585892915725708, -0.5133495330810547, -0.44080615043640137, -0.36826300621032715, -0.29571986198425293, -0.2231764793395996, -0.1506330966949463, -0.07808995246887207, -0.0055468082427978516, 0.06699657440185547, 0.1395399570465088, 0.212083101272583, 0.2846262454986572, 0.35716962814331055, 0.42971301078796387, 0.5022561550140381, 0.5747992992401123, 0.6473426818847656, 0.719886064529419, 0.7924292087554932, 0.8649723529815674, 0.9375157356262207, 1.010059118270874, 1.0826022624969482, 1.1551454067230225, 1.2276887893676758, 1.300232172012329, 1.3727753162384033, 1.4453184604644775, 1.5178616046905518, 1.5904052257537842, 1.6629483699798584, 1.7354915142059326, 1.808035135269165, 1.8805782794952393, 1.9531214237213135]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 8.0, 12.0, 10.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8815709352493286, -0.8486192226409912, -0.8156675696372986, -0.7827158570289612, -0.7497642040252686, -0.7168124914169312, -0.6838607788085938, -0.6509090662002563, -0.6179574131965637, -0.5850057601928711, -0.5520540475845337, -0.5191023349761963, -0.4861506521701813, -0.45319896936416626, -0.42024725675582886, -0.38729557394981384, -0.35434389114379883, -0.3213921785354614, -0.2884405255317688, -0.2554888129234314, -0.22253715991973877, -0.18958544731140137, -0.15663373470306396, -0.12368208169937134, -0.09073036909103394, -0.05777865648269653, -0.024827003479003906, 0.008124709129333496, 0.0410764217376709, 0.07402807474136353, 0.10697978734970093, 0.13993144035339355, 0.17288315296173096, 0.20583486557006836, 0.23878657817840576, 0.2717381715774536, 0.304689884185791, 0.3376415967941284, 0.3705933094024658, 0.4035450220108032, 0.4364966154098511, 0.4694483280181885, 0.5024000406265259, 0.5353517532348633, 0.5683034658432007, 0.6012551784515381, 0.6342067718505859, 0.6671584844589233, 0.7001101970672607, 0.7330619096755981, 0.7660136222839355, 0.7989652156829834, 0.8319169282913208, 0.8648686408996582, 0.8978203535079956, 0.930772066116333, 0.9637237787246704, 0.9966753721237183, 1.0296270847320557, 1.062578797340393, 1.0955305099487305, 1.1284822225570679, 1.1614338159561157, 1.1943856477737427, 1.2273372411727905]}, "_runtime": 373.4800457954407, "_timestamp": 1585418232.360272, "_step": 298}
{"Episode reward": -99.1140760516675, "Episode length": 999, "Policy Loss": -0.13626396656036377, "Value Loss": 0.027291089296340942, "_runtime": 374.76055693626404, "_timestamp": 1585418233.640783, "_step": 299}
{"Episode reward": -98.46397606363065, "Episode length": 999, "Policy Loss": -0.13235202431678772, "Value Loss": 0.03166651353240013, "_runtime": 376.02414989471436, "_timestamp": 1585418234.904376, "_step": 300}
{"Episode reward": -94.81346394388301, "Episode length": 999, "Policy Loss": -0.12224927544593811, "Value Loss": 0.02521507628262043, "_runtime": 377.27441573143005, "_timestamp": 1585418236.1546419, "_step": 301}
{"Episode reward": -110.05709031449777, "Episode length": 999, "Policy Loss": -0.16135315597057343, "Value Loss": 0.0340990275144577, "_runtime": 378.68449997901917, "_timestamp": 1585418237.564726, "_step": 302}
{"Episode reward": -101.3525004879045, "Episode length": 999, "Policy Loss": -0.14169873297214508, "Value Loss": 0.02972891554236412, "_runtime": 379.9568009376526, "_timestamp": 1585418238.837027, "_step": 303}
{"Episode reward": -101.62806477605476, "Episode length": 999, "Policy Loss": -0.13590332865715027, "Value Loss": 0.03149662911891937, "_runtime": 381.18614292144775, "_timestamp": 1585418240.066369, "_step": 304}
{"Episode reward": -110.46076381119113, "Episode length": 999, "Policy Loss": -0.149993434548378, "Value Loss": 0.036190763115882874, "_runtime": 382.4974389076233, "_timestamp": 1585418241.377665, "_step": 305}
{"Episode reward": -101.19338101702837, "Episode length": 999, "Policy Loss": -0.14258325099945068, "Value Loss": 0.030963845551013947, "_runtime": 383.75468587875366, "_timestamp": 1585418242.634912, "_step": 306}
{"Episode reward": -105.65063205316618, "Episode length": 999, "Policy Loss": -0.15273548662662506, "Value Loss": 0.036108601838350296, "_runtime": 384.9834327697754, "_timestamp": 1585418243.863659, "_step": 307}
{"Episode reward": -106.0763655531628, "Episode length": 999, "Policy Loss": -0.15147827565670013, "Value Loss": 0.03252226114273071, "_runtime": 386.3376829624176, "_timestamp": 1585418245.217909, "_step": 308}
{"Episode reward": -104.01381390740731, "Episode length": 999, "Policy Loss": -0.14393794536590576, "Value Loss": 0.035267625004053116, "_runtime": 387.55504989624023, "_timestamp": 1585418246.435276, "_step": 309}
{"Episode reward": -105.06620352939434, "Episode length": 999, "Policy Loss": -0.136763796210289, "Value Loss": 0.03403053805232048, "_runtime": 388.86917781829834, "_timestamp": 1585418247.749404, "_step": 310}
{"Episode reward": -101.5916522602262, "Episode length": 999, "Policy Loss": -0.13451199233531952, "Value Loss": 0.031762126833200455, "_runtime": 390.06701278686523, "_timestamp": 1585418248.947239, "_step": 311}
{"Episode reward": -107.53620394140682, "Episode length": 999, "Policy Loss": -0.15095080435276031, "Value Loss": 0.033569153398275375, "_runtime": 391.2596468925476, "_timestamp": 1585418250.139873, "_step": 312}
{"Episode reward": -104.68339093065106, "Episode length": 999, "Policy Loss": -0.14560863375663757, "Value Loss": 0.032164350152015686, "_runtime": 392.4633228778839, "_timestamp": 1585418251.343549, "_step": 313}
{"Episode reward": -96.9764174735306, "Episode length": 999, "Policy Loss": -0.13350842893123627, "Value Loss": 0.02749820053577423, "_runtime": 393.65679383277893, "_timestamp": 1585418252.53702, "_step": 314}
{"Episode reward": -99.99615590035678, "Episode length": 999, "Policy Loss": -0.13727547228336334, "Value Loss": 0.0272919200360775, "_runtime": 394.8903999328613, "_timestamp": 1585418253.770626, "_step": 315}
{"Episode reward": -97.49183519066176, "Episode length": 999, "Policy Loss": -0.13157884776592255, "Value Loss": 0.02894299477338791, "_runtime": 396.0978648662567, "_timestamp": 1585418254.978091, "_step": 316}
{"Episode reward": -90.14959887577479, "Episode length": 999, "Policy Loss": -0.12090098112821579, "Value Loss": 0.027499999850988388, "_runtime": 397.3108537197113, "_timestamp": 1585418256.1910799, "_step": 317}
{"Episode reward": -99.75893340851589, "Episode length": 999, "Policy Loss": -0.13487757742404938, "Value Loss": 0.029151983559131622, "_runtime": 398.5887396335602, "_timestamp": 1585418257.4689658, "_step": 318}
{"Episode reward": -106.17905335378055, "Episode length": 999, "Policy Loss": -0.14512918889522552, "Value Loss": 0.03416721522808075, "_runtime": 399.83251571655273, "_timestamp": 1585418258.7127419, "_step": 319}
{"Episode reward": -98.40059655860216, "Episode length": 999, "Policy Loss": -0.1257246434688568, "Value Loss": 0.029887286946177483, "_runtime": 401.06826186180115, "_timestamp": 1585418259.948488, "_step": 320}
{"Episode reward": -95.63674112973067, "Episode length": 999, "Policy Loss": -0.12763360142707825, "Value Loss": 0.027025766670703888, "_runtime": 402.31332182884216, "_timestamp": 1585418261.193548, "_step": 321}
{"Episode reward": -98.9906210364958, "Episode length": 999, "Policy Loss": -0.13043808937072754, "Value Loss": 0.03044729493558407, "_runtime": 403.53089475631714, "_timestamp": 1585418262.411121, "_step": 322}
{"Episode reward": -104.58157830322267, "Episode length": 999, "Policy Loss": -0.14099664986133575, "Value Loss": 0.03333627060055733, "_runtime": 404.75577902793884, "_timestamp": 1585418263.6360052, "_step": 323}
{"Episode reward": -101.65597249510876, "Episode length": 999, "Policy Loss": -0.13929060101509094, "Value Loss": 0.030143912881612778, "_runtime": 405.96117877960205, "_timestamp": 1585418264.841405, "_step": 324}
{"Episode reward": -106.03905875150711, "Episode length": 999, "Policy Loss": -0.14875981211662292, "Value Loss": 0.034876901656389236, "_runtime": 407.18661284446716, "_timestamp": 1585418266.066839, "_step": 325}
{"Episode reward": -103.04819970328623, "Episode length": 999, "Policy Loss": -0.1405034214258194, "Value Loss": 0.029038019478321075, "_runtime": 408.47084379196167, "_timestamp": 1585418267.35107, "_step": 326}
{"Episode reward": -104.72977827640793, "Episode length": 999, "Policy Loss": -0.1371918022632599, "Value Loss": 0.032887283712625504, "_runtime": 409.7331118583679, "_timestamp": 1585418268.613338, "_step": 327}
{"Episode reward": -104.77925955782602, "Episode length": 999, "Policy Loss": -0.14676719903945923, "Value Loss": 0.033791664987802505, "_runtime": 410.97123503685, "_timestamp": 1585418269.8514612, "_step": 328}
{"Episode reward": -95.72972163209606, "Episode length": 999, "Policy Loss": -0.12599319219589233, "Value Loss": 0.027134526520967484, "_runtime": 412.18281173706055, "_timestamp": 1585418271.0630379, "_step": 329}
{"Episode reward": -114.11528303168332, "Episode length": 999, "Policy Loss": -0.17388111352920532, "Value Loss": 0.03955237194895744, "_runtime": 413.37451696395874, "_timestamp": 1585418272.254743, "_step": 330}
{"Episode reward": -99.26592867712878, "Episode length": 999, "Policy Loss": -0.13627371191978455, "Value Loss": 0.032366205006837845, "_runtime": 414.6231937408447, "_timestamp": 1585418273.5034199, "_step": 331}
{"Episode reward": -100.73674662677435, "Episode length": 999, "Policy Loss": -0.1423756629228592, "Value Loss": 0.03079993464052677, "_runtime": 415.83846282958984, "_timestamp": 1585418274.718689, "_step": 332}
{"Episode reward": -96.58251781269772, "Episode length": 999, "Policy Loss": -0.13520774245262146, "Value Loss": 0.027681492269039154, "_runtime": 417.12292766571045, "_timestamp": 1585418276.0031538, "_step": 333}
{"Episode reward": -101.67407459926045, "Episode length": 999, "Policy Loss": -0.14137494564056396, "Value Loss": 0.031118813902139664, "_runtime": 418.3644847869873, "_timestamp": 1585418277.244711, "_step": 334}
{"Episode reward": -100.68145317653003, "Episode length": 999, "Policy Loss": -0.13882169127464294, "Value Loss": 0.02879481576383114, "_runtime": 419.7205927371979, "_timestamp": 1585418278.6008189, "_step": 335}
{"Episode reward": -102.23291872195949, "Episode length": 999, "Policy Loss": -0.14385539293289185, "Value Loss": 0.03207742050290108, "_runtime": 420.9510419368744, "_timestamp": 1585418279.831268, "_step": 336}
{"Episode reward": -112.7849492233568, "Episode length": 999, "Policy Loss": -0.15564227104187012, "Value Loss": 0.038743793964385986, "_runtime": 422.1858718395233, "_timestamp": 1585418281.066098, "_step": 337}
{"Episode reward": -105.64910915367463, "Episode length": 999, "Policy Loss": -0.14087337255477905, "Value Loss": 0.03388670086860657, "_runtime": 423.42898082733154, "_timestamp": 1585418282.309207, "_step": 338}
{"Episode reward": -109.26288203376501, "Episode length": 999, "Policy Loss": -0.14966008067131042, "Value Loss": 0.034814540296792984, "_runtime": 424.6453559398651, "_timestamp": 1585418283.525582, "_step": 339}
{"Episode reward": -101.1753097311465, "Episode length": 999, "Policy Loss": -0.13612331449985504, "Value Loss": 0.029544789344072342, "_runtime": 425.85787987709045, "_timestamp": 1585418284.738106, "_step": 340}
{"Episode reward": -98.05823120440742, "Episode length": 999, "Policy Loss": -0.13064521551132202, "Value Loss": 0.02942364290356636, "_runtime": 427.1316809654236, "_timestamp": 1585418286.011907, "_step": 341}
{"Episode reward": -106.8360398867802, "Episode length": 999, "Policy Loss": -0.15349510312080383, "Value Loss": 0.033501651138067245, "_runtime": 428.39474081993103, "_timestamp": 1585418287.274967, "_step": 342}
{"Episode reward": -96.36809005210264, "Episode length": 999, "Policy Loss": -0.12918749451637268, "Value Loss": 0.026175523176789284, "_runtime": 429.6755928993225, "_timestamp": 1585418288.555819, "_step": 343}
{"Episode reward": -100.0949813927602, "Episode length": 999, "Policy Loss": -0.13884249329566956, "Value Loss": 0.029646076261997223, "_runtime": 430.9847936630249, "_timestamp": 1585418289.8650198, "_step": 344}
{"Episode reward": -102.99508472347156, "Episode length": 999, "Policy Loss": -0.1395467221736908, "Value Loss": 0.03326719254255295, "_runtime": 432.21944069862366, "_timestamp": 1585418291.0996668, "_step": 345}
{"Episode reward": -99.36042251141232, "Episode length": 999, "Policy Loss": -0.13086779415607452, "Value Loss": 0.031078355386853218, "_runtime": 433.58680987358093, "_timestamp": 1585418292.467036, "_step": 346}
{"Episode reward": -108.29262165278432, "Episode length": 999, "Policy Loss": -0.15419462323188782, "Value Loss": 0.03548980504274368, "_runtime": 434.81866979599, "_timestamp": 1585418293.698896, "_step": 347}
{"Episode reward": -106.2434836050586, "Episode length": 999, "Policy Loss": -0.15038006007671356, "Value Loss": 0.033643677830696106, "_runtime": 436.1589238643646, "_timestamp": 1585418295.03915, "_step": 348}
{"Episode reward": -100.70416021017468, "Episode length": 999, "Policy Loss": -0.125740647315979, "Value Loss": 0.03192446380853653, "_runtime": 437.3813638687134, "_timestamp": 1585418296.26159, "_step": 349}
{"Episode reward": -105.97460728038305, "Episode length": 999, "Policy Loss": -0.14316660165786743, "Value Loss": 0.03669382631778717, "_runtime": 438.75407695770264, "_timestamp": 1585418297.634303, "_step": 350}
{"Episode reward": -107.56643315934105, "Episode length": 999, "Policy Loss": -0.14957615733146667, "Value Loss": 0.034842152148485184, "_runtime": 440.04469776153564, "_timestamp": 1585418298.924924, "_step": 351}
{"Episode reward": -106.99073191259217, "Episode length": 999, "Policy Loss": -0.1495738923549652, "Value Loss": 0.03343934938311577, "_runtime": 441.28230595588684, "_timestamp": 1585418300.162532, "_step": 352}
{"Episode reward": -105.79391057758333, "Episode length": 999, "Policy Loss": -0.15874618291854858, "Value Loss": 0.033440664410591125, "_runtime": 442.55001497268677, "_timestamp": 1585418301.430241, "_step": 353}
{"Episode reward": -109.83328627809678, "Episode length": 999, "Policy Loss": -0.15918225049972534, "Value Loss": 0.03931200131773949, "_runtime": 443.75132989883423, "_timestamp": 1585418302.631556, "_step": 354}
{"Episode reward": -104.59967265907669, "Episode length": 999, "Policy Loss": -0.14567407965660095, "Value Loss": 0.03256839141249657, "_runtime": 444.9926528930664, "_timestamp": 1585418303.872879, "_step": 355}
{"Episode reward": -106.90552597167235, "Episode length": 999, "Policy Loss": -0.14910580217838287, "Value Loss": 0.0338895209133625, "_runtime": 446.2585217952728, "_timestamp": 1585418305.138748, "_step": 356}
{"Episode reward": -101.49621201732037, "Episode length": 999, "Policy Loss": -0.13838401436805725, "Value Loss": 0.03003263846039772, "_runtime": 447.4911789894104, "_timestamp": 1585418306.3714051, "_step": 357}
{"Episode reward": -101.41444845724065, "Episode length": 999, "Policy Loss": -0.13836243748664856, "Value Loss": 0.030486131086945534, "_runtime": 448.800940990448, "_timestamp": 1585418307.6811671, "_step": 358}
{"Episode reward": -98.8127688222857, "Episode length": 999, "Policy Loss": -0.13542810082435608, "Value Loss": 0.029192475602030754, "_runtime": 450.030104637146, "_timestamp": 1585418308.9103308, "_step": 359}
{"Episode reward": -101.87070813683965, "Episode length": 999, "Policy Loss": -0.1366233229637146, "Value Loss": 0.02942197024822235, "_runtime": 451.2721998691559, "_timestamp": 1585418310.152426, "_step": 360}
{"Episode reward": -102.40390007094786, "Episode length": 999, "Policy Loss": -0.13790525496006012, "Value Loss": 0.032590918242931366, "_runtime": 452.52288579940796, "_timestamp": 1585418311.403112, "_step": 361}
{"Episode reward": -98.02060546597941, "Episode length": 999, "Policy Loss": -0.13369017839431763, "Value Loss": 0.028404217213392258, "_runtime": 453.7143249511719, "_timestamp": 1585418312.594551, "_step": 362}
{"Episode reward": -99.9766789533256, "Episode length": 999, "Policy Loss": -0.13257558643817902, "Value Loss": 0.031366825103759766, "_runtime": 454.91833901405334, "_timestamp": 1585418313.7985651, "_step": 363}
{"Episode reward": -103.01044390226728, "Episode length": 999, "Policy Loss": -0.14382974803447723, "Value Loss": 0.03279496729373932, "_runtime": 456.2063989639282, "_timestamp": 1585418315.086625, "_step": 364}
{"Episode reward": -103.73349707114393, "Episode length": 999, "Policy Loss": -0.1460462212562561, "Value Loss": 0.033998824656009674, "_runtime": 457.50421667099, "_timestamp": 1585418316.3844428, "_step": 365}
{"Episode reward": -99.3247245421342, "Episode length": 999, "Policy Loss": -0.1324124038219452, "Value Loss": 0.029741069301962852, "_runtime": 458.8231987953186, "_timestamp": 1585418317.703425, "_step": 366}
{"Episode reward": -103.36811234601433, "Episode length": 999, "Policy Loss": -0.14099709689617157, "Value Loss": 0.031354259699583054, "_runtime": 460.14299988746643, "_timestamp": 1585418319.023226, "_step": 367}
{"Episode reward": -104.61700876299986, "Episode length": 999, "Policy Loss": -0.13938499987125397, "Value Loss": 0.03341992199420929, "_runtime": 461.40538597106934, "_timestamp": 1585418320.285612, "_step": 368}
{"Episode reward": -97.58026312927703, "Episode length": 999, "Policy Loss": -0.125531867146492, "Value Loss": 0.028417445719242096, "_runtime": 462.6365759372711, "_timestamp": 1585418321.516802, "_step": 369}
{"Episode reward": -115.6352370899056, "Episode length": 999, "Policy Loss": -0.15864942967891693, "Value Loss": 0.03954625874757767, "_runtime": 463.84790873527527, "_timestamp": 1585418322.7281349, "_step": 370}
{"Episode reward": -103.2628708719287, "Episode length": 999, "Policy Loss": -0.14326228201389313, "Value Loss": 0.031812749803066254, "_runtime": 465.12981390953064, "_timestamp": 1585418324.01004, "_step": 371}
{"Episode reward": -109.5518486768376, "Episode length": 999, "Policy Loss": -0.14644280076026917, "Value Loss": 0.03293744847178459, "_runtime": 466.35745787620544, "_timestamp": 1585418325.237684, "_step": 372}
{"Episode reward": -104.4967600753952, "Episode length": 999, "Policy Loss": -0.1436576098203659, "Value Loss": 0.03183205425739288, "_runtime": 467.57400703430176, "_timestamp": 1585418326.4542332, "_step": 373}
{"Episode reward": -114.61295455249282, "Episode length": 999, "Policy Loss": -0.18135595321655273, "Value Loss": 0.03831515461206436, "_runtime": 468.9032897949219, "_timestamp": 1585418327.783516, "_step": 374}
{"Episode reward": -98.66218456438968, "Episode length": 999, "Policy Loss": -0.1336894929409027, "Value Loss": 0.029303189367055893, "_runtime": 470.147598028183, "_timestamp": 1585418329.0278242, "_step": 375}
{"Episode reward": -104.59661013132735, "Episode length": 999, "Policy Loss": -0.14433467388153076, "Value Loss": 0.03274092078208923, "_runtime": 471.39422583580017, "_timestamp": 1585418330.274452, "_step": 376}
{"Episode reward": -109.03273119002421, "Episode length": 999, "Policy Loss": -0.15864458680152893, "Value Loss": 0.036307401955127716, "_runtime": 472.6745648384094, "_timestamp": 1585418331.554791, "_step": 377}
{"Episode reward": -116.26478827767869, "Episode length": 999, "Policy Loss": -0.18109199404716492, "Value Loss": 0.04962834715843201, "_runtime": 473.9428117275238, "_timestamp": 1585418332.8230379, "_step": 378}
{"Episode reward": -108.20230102129997, "Episode length": 999, "Policy Loss": -0.15639710426330566, "Value Loss": 0.03870924934744835, "_runtime": 475.24326968193054, "_timestamp": 1585418334.1234958, "_step": 379}
{"Episode reward": -102.50350550283359, "Episode length": 999, "Policy Loss": -0.14370982348918915, "Value Loss": 0.028938010334968567, "_runtime": 476.52357602119446, "_timestamp": 1585418335.4038022, "_step": 380}
{"Episode reward": -99.44604334722317, "Episode length": 999, "Policy Loss": -0.13505308330059052, "Value Loss": 0.03143651410937309, "_runtime": 477.7959339618683, "_timestamp": 1585418336.67616, "_step": 381}
{"Episode reward": -112.15995437421383, "Episode length": 999, "Policy Loss": -0.14880068600177765, "Value Loss": 0.035628121346235275, "_runtime": 479.1703727245331, "_timestamp": 1585418338.0505989, "_step": 382}
{"Episode reward": -102.72455229441009, "Episode length": 999, "Policy Loss": -0.1354493349790573, "Value Loss": 0.03419910743832588, "_runtime": 480.4458019733429, "_timestamp": 1585418339.326028, "_step": 383}
{"Episode reward": -109.12081140183962, "Episode length": 999, "Policy Loss": -0.1507384479045868, "Value Loss": 0.03540090471506119, "_runtime": 481.7162160873413, "_timestamp": 1585418340.5964422, "_step": 384}
{"Episode reward": -107.83533929056856, "Episode length": 999, "Policy Loss": -0.14803001284599304, "Value Loss": 0.033322934061288834, "_runtime": 482.97886991500854, "_timestamp": 1585418341.859096, "_step": 385}
{"Episode reward": -110.13890459517856, "Episode length": 999, "Policy Loss": -0.1519140601158142, "Value Loss": 0.036195553839206696, "_runtime": 484.1798758506775, "_timestamp": 1585418343.060102, "_step": 386}
{"Episode reward": -101.01019603933369, "Episode length": 999, "Policy Loss": -0.13446521759033203, "Value Loss": 0.0289296954870224, "_runtime": 485.4562637805939, "_timestamp": 1585418344.33649, "_step": 387}
{"Episode reward": -108.10149423294712, "Episode length": 999, "Policy Loss": -0.1449883133172989, "Value Loss": 0.03625356778502464, "_runtime": 486.6817636489868, "_timestamp": 1585418345.5619898, "_step": 388}
{"Episode reward": -112.1397777141254, "Episode length": 999, "Policy Loss": -0.1506992131471634, "Value Loss": 0.04209701716899872, "_runtime": 487.96075987815857, "_timestamp": 1585418346.840986, "_step": 389}
{"Episode reward": -107.30537029393545, "Episode length": 999, "Policy Loss": -0.14990319311618805, "Value Loss": 0.03507865220308304, "_runtime": 489.2818009853363, "_timestamp": 1585418348.1620271, "_step": 390}
{"Episode reward": -107.725472072817, "Episode length": 999, "Policy Loss": -0.15474924445152283, "Value Loss": 0.03234338015317917, "_runtime": 490.58314394950867, "_timestamp": 1585418349.46337, "_step": 391}
{"Episode reward": -105.06386391469108, "Episode length": 999, "Policy Loss": -0.14991357922554016, "Value Loss": 0.036514006555080414, "_runtime": 491.8333339691162, "_timestamp": 1585418350.71356, "_step": 392}
{"Episode reward": -107.251209470669, "Episode length": 999, "Policy Loss": -0.14266230165958405, "Value Loss": 0.034327395260334015, "_runtime": 493.08777379989624, "_timestamp": 1585418351.968, "_step": 393}
{"Episode reward": -108.9615460268193, "Episode length": 999, "Policy Loss": -0.14944718778133392, "Value Loss": 0.031680043786764145, "_runtime": 494.3111717700958, "_timestamp": 1585418353.191398, "_step": 394}
{"Episode reward": -105.19903167200592, "Episode length": 999, "Policy Loss": -0.1440650224685669, "Value Loss": 0.033355604857206345, "_runtime": 495.56969594955444, "_timestamp": 1585418354.449922, "_step": 395}
{"Episode reward": -107.01138649108157, "Episode length": 999, "Policy Loss": -0.15054099261760712, "Value Loss": 0.03359689936041832, "_runtime": 496.870493888855, "_timestamp": 1585418355.75072, "_step": 396}
{"Episode reward": -106.80591635288505, "Episode length": 999, "Policy Loss": -0.14495103061199188, "Value Loss": 0.03200665861368179, "_runtime": 498.14893984794617, "_timestamp": 1585418357.029166, "_step": 397}
{"Episode reward": -106.97865114723685, "Episode length": 999, "Policy Loss": -0.14069999754428864, "Value Loss": 0.03490203246474266, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967, 4.095244884490967]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.416553258895874, -2.312180519104004, -2.2078075408935547, -2.1034348011016846, -1.9990618228912354, -1.8946890830993652, -1.7903162240982056, -1.685943365097046, -1.5815705060958862, -1.4771976470947266, -1.372824788093567, -1.2684519290924072, -1.164079189300537, -1.0597063302993774, -0.9553334712982178, -0.8509606122970581, -0.7465877532958984, -0.6422148942947388, -0.5378420352935791, -0.43346917629241943, -0.32909631729125977, -0.22472357749938965, -0.12035059928894043, -0.015977859497070312, 0.0883948802947998, 0.19276785850524902, 0.29714059829711914, 0.40151357650756836, 0.5058863162994385, 0.6102592945098877, 0.7146320343017578, 0.819005012512207, 0.9233777523040771, 1.0277504920959473, 1.1321234703063965, 1.2364962100982666, 1.3408691883087158, 1.445241928100586, 1.5496149063110352, 1.6539876461029053, 1.7583606243133545, 1.8627331256866455, 1.9671061038970947, 2.071479082107544, 2.175852060317993, 2.280224561691284, 2.3845975399017334, 2.4889705181121826, 2.5933430194854736, 2.697715997695923, 2.802088975906372, 2.9064619541168213, 3.0108344554901123, 3.1152074337005615, 3.2195804119110107, 3.32395339012146, 3.428325891494751, 3.5326988697052, 3.6370718479156494, 3.7414443492889404, 3.8458173274993896, 3.950190305709839, 4.054563522338867, 4.158935546875, 4.263308525085449]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.171205759048462, -2.1069424152374268, -2.0426790714263916, -1.9784157276153564, -1.9141523838043213, -1.8498890399932861, -1.7856255769729614, -1.7213622331619263, -1.6570988893508911, -1.592835545539856, -1.5285722017288208, -1.464308738708496, -1.400045394897461, -1.3357820510864258, -1.2715187072753906, -1.2072553634643555, -1.1429920196533203, -1.0787286758422852, -1.01446533203125, -0.9502019882202148, -0.8859386444091797, -0.821675181388855, -0.7574118375778198, -0.6931484937667847, -0.6288851499557495, -0.5646218061447144, -0.5003584623336792, -0.43609511852264404, -0.37183165550231934, -0.3075683116912842, -0.24330496788024902, -0.17904162406921387, -0.11477828025817871, -0.050514936447143555, 0.013748407363891602, 0.07801175117492676, 0.14227509498596191, 0.20653843879699707, 0.2708017826080322, 0.3350651264190674, 0.39932847023010254, 0.4635920524597168, 0.527855396270752, 0.5921187400817871, 0.6563820838928223, 0.7206454277038574, 0.7849087715148926, 0.8491721153259277, 0.9134354591369629, 0.977698802947998, 1.0419621467590332, 1.1062254905700684, 1.1704888343811035, 1.2347521781921387, 1.2990155220031738, 1.363278865814209, 1.4275424480438232, 1.4918057918548584, 1.5560691356658936, 1.6203324794769287, 1.6845958232879639, 1.748859167098999, 1.8131225109100342, 1.8773858547210693, 1.9416491985321045]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 5.0, 4.0, 2.0, 8.0, 4.0, 16.0, 6.0, 9.0, 10.0, 16.0, 12.0, 18.0, 21.0, 25.0, 65.0, 25.0, 50.0, 35.0, 27.0, 29.0, 27.0, 13.0, 12.0, 10.0, 7.0, 8.0, 3.0, 3.0, 1.0, 4.0, 5.0, 4.0, 4.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-2.032816171646118, -1.9726488590240479, -1.9124815464019775, -1.8523141145706177, -1.7921468019485474, -1.731979489326477, -1.6718121767044067, -1.6116447448730469, -1.5514774322509766, -1.4913101196289062, -1.431142807006836, -1.3709754943847656, -1.3108081817626953, -1.2506407499313354, -1.1904734373092651, -1.1303060054779053, -1.070138692855835, -1.0099713802337646, -0.9498040676116943, -0.889636754989624, -0.8294694423675537, -0.7693020105361938, -0.7091346979141235, -0.6489673852920532, -0.5888000726699829, -0.5286327600479126, -0.46846532821655273, -0.4082980155944824, -0.3481307029724121, -0.2879633903503418, -0.22779595851898193, -0.16762864589691162, -0.10746133327484131, -0.047294020652770996, 0.012873411178588867, 0.07304072380065918, 0.1332080364227295, 0.1933753490447998, 0.2535426616668701, 0.31370997428894043, 0.37387728691101074, 0.43404459953308105, 0.49421215057373047, 0.5543794631958008, 0.6145467758178711, 0.6747140884399414, 0.7348814010620117, 0.795048713684082, 0.8552160263061523, 0.9153833389282227, 0.975550651550293, 1.0357182025909424, 1.0958855152130127, 1.156052827835083, 1.2162201404571533, 1.2763874530792236, 1.336554765701294, 1.3967220783233643, 1.4568893909454346, 1.5170567035675049, 1.5772242546081543, 1.6373915672302246, 1.697558879852295, 1.7577261924743652, 1.8178935050964355]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2033864259719849, -1.1561063528060913, -1.1088261604309082, -1.0615460872650146, -1.0142658948898315, -0.966985821723938, -0.9197056889533997, -0.8724255561828613, -0.825145423412323, -0.7778652906417847, -0.7305851578712463, -0.683305025100708, -0.6360249519348145, -0.5887448191642761, -0.5414646863937378, -0.49418455362319946, -0.44690442085266113, -0.3996242880821228, -0.3523441553115845, -0.30506402254104614, -0.2577838897705078, -0.21050381660461426, -0.16322362422943115, -0.1159435510635376, -0.06866347789764404, -0.021383285522460938, 0.025896787643432617, 0.07317698001861572, 0.12045705318450928, 0.16773724555969238, 0.21501731872558594, 0.26229751110076904, 0.3095775842666626, 0.35685765743255615, 0.40413784980773926, 0.4514179229736328, 0.4986981153488159, 0.5459781885147095, 0.5932583808898926, 0.6405384540557861, 0.6878186464309692, 0.7350987195968628, 0.7823787927627563, 0.8296588659286499, 0.8769391775131226, 0.9242192506790161, 0.9714993238449097, 1.0187793970108032, 1.0660594701766968, 1.1133397817611694, 1.160619854927063, 1.2078999280929565, 1.25518000125885, 1.3024603128433228, 1.3497403860092163, 1.3970204591751099, 1.4443005323410034, 1.491580605506897, 1.5388609170913696, 1.5861409902572632, 1.6334210634231567, 1.6807011365890503, 1.727981448173523, 1.7752615213394165, 1.82254159450531]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 18.0, 14.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.5186436176300049, -1.478643536567688, -1.438643455505371, -1.3986433744430542, -1.3586432933807373, -1.3186432123184204, -1.2786431312561035, -1.238642930984497, -1.1986429691314697, -1.1586427688598633, -1.118642807006836, -1.0786426067352295, -1.0386425256729126, -0.9986424446105957, -0.9586423635482788, -0.9186422824859619, -0.878642201423645, -0.8386421203613281, -0.7986420392990112, -0.7586419582366943, -0.7186418771743774, -0.6786417365074158, -0.6386416554450989, -0.598641574382782, -0.5586414933204651, -0.5186413526535034, -0.4786412715911865, -0.43864119052886963, -0.39864110946655273, -0.35864102840423584, -0.31864094734191895, -0.27864086627960205, -0.23864078521728516, -0.19864070415496826, -0.15864062309265137, -0.11864054203033447, -0.07864046096801758, -0.038640379905700684, 0.001359701156616211, 0.041359782218933105, 0.08135986328125, 0.12136006355285645, 0.16136014461517334, 0.20136022567749023, 0.24136030673980713, 0.281360387802124, 0.3213604688644409, 0.3613605499267578, 0.4013606309890747, 0.4413607120513916, 0.48136091232299805, 0.5213608741760254, 0.5613610744476318, 0.6013610363006592, 0.6413612365722656, 0.681361198425293, 0.7213613986968994, 0.7613613605499268, 0.8013615608215332, 0.8413615226745605, 0.881361722946167, 0.9213616847991943, 0.9613618850708008, 1.0013618469238281, 1.0413620471954346]}, "_runtime": 499.5411329269409, "_timestamp": 1585418358.421359, "_step": 398}
{"Episode reward": -102.23835143138977, "Episode length": 999, "Policy Loss": -0.1438153088092804, "Value Loss": 0.030810564756393433, "_runtime": 500.7872598171234, "_timestamp": 1585418359.667486, "_step": 399}
{"Episode reward": -103.07338037909292, "Episode length": 999, "Policy Loss": -0.13284145295619965, "Value Loss": 0.03195442631840706, "_runtime": 502.03393483161926, "_timestamp": 1585418360.914161, "_step": 400}
{"Episode reward": -105.2286114838879, "Episode length": 999, "Policy Loss": -0.1442030668258667, "Value Loss": 0.03255147859454155, "_runtime": 503.2787981033325, "_timestamp": 1585418362.1590242, "_step": 401}
{"Episode reward": -105.74234300773259, "Episode length": 999, "Policy Loss": -0.1527053415775299, "Value Loss": 0.036264147609472275, "_runtime": 504.5390498638153, "_timestamp": 1585418363.419276, "_step": 402}
{"Episode reward": -102.2543530535578, "Episode length": 999, "Policy Loss": -0.13815678656101227, "Value Loss": 0.029587648808956146, "_runtime": 505.81418085098267, "_timestamp": 1585418364.694407, "_step": 403}
{"Episode reward": -104.25741866026169, "Episode length": 999, "Policy Loss": -0.1485418826341629, "Value Loss": 0.03151008114218712, "_runtime": 507.1668999195099, "_timestamp": 1585418366.047126, "_step": 404}
{"Episode reward": -98.77838498924865, "Episode length": 999, "Policy Loss": -0.13219468295574188, "Value Loss": 0.032321080565452576, "_runtime": 508.4819128513336, "_timestamp": 1585418367.362139, "_step": 405}
{"Episode reward": -101.00280817132756, "Episode length": 999, "Policy Loss": -0.13544581830501556, "Value Loss": 0.03193490579724312, "_runtime": 509.76343393325806, "_timestamp": 1585418368.64366, "_step": 406}
{"Episode reward": -102.5945902325324, "Episode length": 999, "Policy Loss": -0.14000245928764343, "Value Loss": 0.03005458414554596, "_runtime": 511.09958386421204, "_timestamp": 1585418369.97981, "_step": 407}
{"Episode reward": -101.39443867856028, "Episode length": 999, "Policy Loss": -0.13779114186763763, "Value Loss": 0.03006152994930744, "_runtime": 512.3698937892914, "_timestamp": 1585418371.25012, "_step": 408}
{"Episode reward": -99.84964161424418, "Episode length": 999, "Policy Loss": -0.1345021277666092, "Value Loss": 0.03033912554383278, "_runtime": 513.6672568321228, "_timestamp": 1585418372.547483, "_step": 409}
{"Episode reward": -106.09923544369842, "Episode length": 999, "Policy Loss": -0.14867952466011047, "Value Loss": 0.03262268379330635, "_runtime": 514.9680829048157, "_timestamp": 1585418373.848309, "_step": 410}
{"Episode reward": -102.63185820887898, "Episode length": 999, "Policy Loss": -0.13965173065662384, "Value Loss": 0.029860055074095726, "_runtime": 516.1509308815002, "_timestamp": 1585418375.031157, "_step": 411}
{"Episode reward": -98.16946276397616, "Episode length": 999, "Policy Loss": -0.12912648916244507, "Value Loss": 0.02990986593067646, "_runtime": 517.4512629508972, "_timestamp": 1585418376.331489, "_step": 412}
{"Episode reward": -100.5991722412421, "Episode length": 999, "Policy Loss": -0.14013035595417023, "Value Loss": 0.029181957244873047, "_runtime": 518.8452768325806, "_timestamp": 1585418377.725503, "_step": 413}
{"Episode reward": -98.75778382407998, "Episode length": 999, "Policy Loss": -0.13316841423511505, "Value Loss": 0.029072435572743416, "_runtime": 520.158273935318, "_timestamp": 1585418379.0385, "_step": 414}
{"Episode reward": -106.77825396067561, "Episode length": 999, "Policy Loss": -0.1512322872877121, "Value Loss": 0.0338965579867363, "_runtime": 521.3728349208832, "_timestamp": 1585418380.253061, "_step": 415}
{"Episode reward": -101.23544052254782, "Episode length": 999, "Policy Loss": -0.14736834168434143, "Value Loss": 0.03078026883304119, "_runtime": 522.6808588504791, "_timestamp": 1585418381.561085, "_step": 416}
{"Episode reward": -109.61183421782101, "Episode length": 999, "Policy Loss": -0.1515532284975052, "Value Loss": 0.03369889035820961, "_runtime": 523.9491829872131, "_timestamp": 1585418382.8294091, "_step": 417}
{"Episode reward": -102.13067207231092, "Episode length": 999, "Policy Loss": -0.1389492005109787, "Value Loss": 0.03282884135842323, "_runtime": 525.1771667003632, "_timestamp": 1585418384.0573928, "_step": 418}
{"Episode reward": -96.64820034852129, "Episode length": 999, "Policy Loss": -0.13030190765857697, "Value Loss": 0.02890871837735176, "_runtime": 526.3898596763611, "_timestamp": 1585418385.2700858, "_step": 419}
{"Episode reward": -103.80675964463643, "Episode length": 999, "Policy Loss": -0.1380334049463272, "Value Loss": 0.03071882762014866, "_runtime": 527.5774488449097, "_timestamp": 1585418386.457675, "_step": 420}
{"Episode reward": -103.25024111930722, "Episode length": 999, "Policy Loss": -0.13881975412368774, "Value Loss": 0.03392229601740837, "_runtime": 528.8760318756104, "_timestamp": 1585418387.756258, "_step": 421}
{"Episode reward": -104.25888142031955, "Episode length": 999, "Policy Loss": -0.15355922281742096, "Value Loss": 0.03122861497104168, "_runtime": 530.1730349063873, "_timestamp": 1585418389.053261, "_step": 422}
{"Episode reward": -96.28072078855155, "Episode length": 999, "Policy Loss": -0.13180358707904816, "Value Loss": 0.02956514060497284, "_runtime": 531.3824248313904, "_timestamp": 1585418390.262651, "_step": 423}
{"Episode reward": -107.14269334596213, "Episode length": 999, "Policy Loss": -0.1460745632648468, "Value Loss": 0.03770750015974045, "_runtime": 532.778431892395, "_timestamp": 1585418391.658658, "_step": 424}
{"Episode reward": -96.3196709419914, "Episode length": 999, "Policy Loss": -0.12211202085018158, "Value Loss": 0.028633832931518555, "_runtime": 534.017816066742, "_timestamp": 1585418392.8980422, "_step": 425}
{"Episode reward": -96.80185621996362, "Episode length": 999, "Policy Loss": -0.13597895205020905, "Value Loss": 0.028435997664928436, "_runtime": 535.2766530513763, "_timestamp": 1585418394.1568792, "_step": 426}
{"Episode reward": -101.08538473855027, "Episode length": 999, "Policy Loss": -0.14246714115142822, "Value Loss": 0.031177304685115814, "_runtime": 536.5045959949493, "_timestamp": 1585418395.3848221, "_step": 427}
{"Episode reward": -100.26776276026584, "Episode length": 999, "Policy Loss": -0.13150569796562195, "Value Loss": 0.031115926802158356, "_runtime": 537.7607617378235, "_timestamp": 1585418396.6409879, "_step": 428}
{"Episode reward": -89.26237428438128, "Episode length": 999, "Policy Loss": -0.11591359227895737, "Value Loss": 0.02518443576991558, "_runtime": 539.0678777694702, "_timestamp": 1585418397.948104, "_step": 429}
{"Episode reward": -103.15444973078215, "Episode length": 999, "Policy Loss": -0.14153791964054108, "Value Loss": 0.03070623055100441, "_runtime": 540.4242708683014, "_timestamp": 1585418399.304497, "_step": 430}
{"Episode reward": -102.49752951994479, "Episode length": 999, "Policy Loss": -0.1417524814605713, "Value Loss": 0.03544343635439873, "_runtime": 541.7386837005615, "_timestamp": 1585418400.6189098, "_step": 431}
{"Episode reward": -106.95398031725078, "Episode length": 999, "Policy Loss": -0.1434316337108612, "Value Loss": 0.03703483194112778, "_runtime": 543.0266678333282, "_timestamp": 1585418401.906894, "_step": 432}
{"Episode reward": -104.13910416159993, "Episode length": 999, "Policy Loss": -0.1473420262336731, "Value Loss": 0.03345608338713646, "_runtime": 544.2893998622894, "_timestamp": 1585418403.169626, "_step": 433}
{"Episode reward": -101.80566704851294, "Episode length": 999, "Policy Loss": -0.1370653212070465, "Value Loss": 0.03027637116611004, "_runtime": 545.4965796470642, "_timestamp": 1585418404.3768058, "_step": 434}
{"Episode reward": -85.27528968120428, "Episode length": 999, "Policy Loss": -0.10827544331550598, "Value Loss": 0.02072814106941223, "_runtime": 546.7245209217072, "_timestamp": 1585418405.604747, "_step": 435}
{"Episode reward": -105.49740277642515, "Episode length": 999, "Policy Loss": -0.14104998111724854, "Value Loss": 0.0327339731156826, "_runtime": 547.9639909267426, "_timestamp": 1585418406.844217, "_step": 436}
{"Episode reward": -101.95374933082299, "Episode length": 999, "Policy Loss": -0.1387195885181427, "Value Loss": 0.028958266600966454, "_runtime": 549.3290178775787, "_timestamp": 1585418408.209244, "_step": 437}
{"Episode reward": -103.45812798708342, "Episode length": 999, "Policy Loss": -0.1507708579301834, "Value Loss": 0.031778037548065186, "_runtime": 550.6430599689484, "_timestamp": 1585418409.523286, "_step": 438}
{"Episode reward": -102.35853089417736, "Episode length": 999, "Policy Loss": -0.146072119474411, "Value Loss": 0.031663473695516586, "_runtime": 551.9298827648163, "_timestamp": 1585418410.810109, "_step": 439}
{"Episode reward": -106.72554008425217, "Episode length": 999, "Policy Loss": -0.15318934619426727, "Value Loss": 0.03405909985303879, "_runtime": 553.2435078620911, "_timestamp": 1585418412.123734, "_step": 440}
{"Episode reward": -105.12139054880394, "Episode length": 999, "Policy Loss": -0.15617060661315918, "Value Loss": 0.03200912103056908, "_runtime": 554.5865998268127, "_timestamp": 1585418413.466826, "_step": 441}
{"Episode reward": -102.95194892521408, "Episode length": 999, "Policy Loss": -0.137192502617836, "Value Loss": 0.031052490696310997, "_runtime": 555.8778748512268, "_timestamp": 1585418414.758101, "_step": 442}
{"Episode reward": -105.62609079951439, "Episode length": 999, "Policy Loss": -0.15424156188964844, "Value Loss": 0.0319279320538044, "_runtime": 557.1659188270569, "_timestamp": 1585418416.046145, "_step": 443}
{"Episode reward": -98.67555002529124, "Episode length": 999, "Policy Loss": -0.13692159950733185, "Value Loss": 0.027288801968097687, "_runtime": 558.5141167640686, "_timestamp": 1585418417.394343, "_step": 444}
{"Episode reward": -109.20136770219335, "Episode length": 999, "Policy Loss": -0.15769430994987488, "Value Loss": 0.03565076366066933, "_runtime": 559.8726558685303, "_timestamp": 1585418418.752882, "_step": 445}
{"Episode reward": -95.69974820790712, "Episode length": 999, "Policy Loss": -0.12883268296718597, "Value Loss": 0.03100106120109558, "_runtime": 561.2616670131683, "_timestamp": 1585418420.1418931, "_step": 446}
{"Episode reward": -97.1641601372792, "Episode length": 999, "Policy Loss": -0.1347091943025589, "Value Loss": 0.030136439949274063, "_runtime": 562.5506458282471, "_timestamp": 1585418421.430872, "_step": 447}
{"Episode reward": -94.46385053288965, "Episode length": 999, "Policy Loss": -0.13316263258457184, "Value Loss": 0.026163648813962936, "_runtime": 563.8218307495117, "_timestamp": 1585418422.702057, "_step": 448}
{"Episode reward": -96.22916514632581, "Episode length": 999, "Policy Loss": -0.13541314005851746, "Value Loss": 0.026995902881026268, "_runtime": 565.0648047924042, "_timestamp": 1585418423.945031, "_step": 449}
{"Episode reward": -98.51188276697964, "Episode length": 999, "Policy Loss": -0.13038267195224762, "Value Loss": 0.029033919796347618, "_runtime": 566.2922396659851, "_timestamp": 1585418425.1724658, "_step": 450}
{"Episode reward": -103.02669560106385, "Episode length": 999, "Policy Loss": -0.1408250480890274, "Value Loss": 0.03226037696003914, "_runtime": 567.5170159339905, "_timestamp": 1585418426.397242, "_step": 451}
{"Episode reward": -93.68226018295297, "Episode length": 999, "Policy Loss": -0.12025465071201324, "Value Loss": 0.0250217504799366, "_runtime": 568.8353888988495, "_timestamp": 1585418427.715615, "_step": 452}
{"Episode reward": -91.28461447697826, "Episode length": 999, "Policy Loss": -0.12289860099554062, "Value Loss": 0.028547780588269234, "_runtime": 570.1289918422699, "_timestamp": 1585418429.009218, "_step": 453}
{"Episode reward": -95.78614535389411, "Episode length": 999, "Policy Loss": -0.1295023262500763, "Value Loss": 0.02886222116649151, "_runtime": 571.4118850231171, "_timestamp": 1585418430.2921112, "_step": 454}
{"Episode reward": -96.4013935303475, "Episode length": 999, "Policy Loss": -0.12754027545452118, "Value Loss": 0.029405852779746056, "_runtime": 572.8527989387512, "_timestamp": 1585418431.733025, "_step": 455}
{"Episode reward": -106.68992346665605, "Episode length": 999, "Policy Loss": -0.14934465289115906, "Value Loss": 0.03472787141799927, "_runtime": 574.1165869235992, "_timestamp": 1585418432.996813, "_step": 456}
{"Episode reward": -99.84268971379646, "Episode length": 999, "Policy Loss": -0.13203762471675873, "Value Loss": 0.028401866555213928, "_runtime": 575.3496928215027, "_timestamp": 1585418434.229919, "_step": 457}
{"Episode reward": -7.939087465810758, "Episode length": 995, "Policy Loss": -0.01575598120689392, "Value Loss": 10.101222038269043, "_runtime": 576.5604329109192, "_timestamp": 1585418435.440659, "_step": 458}
{"Episode reward": -106.12623035987637, "Episode length": 999, "Policy Loss": -0.15105080604553223, "Value Loss": 0.03256818652153015, "_runtime": 577.7593410015106, "_timestamp": 1585418436.6395671, "_step": 459}
{"Episode reward": -96.57216794185038, "Episode length": 999, "Policy Loss": -0.12640099227428436, "Value Loss": 0.03215024247765541, "_runtime": 579.0626859664917, "_timestamp": 1585418437.942912, "_step": 460}
{"Episode reward": -103.84140765115616, "Episode length": 999, "Policy Loss": -0.13746680319309235, "Value Loss": 0.03179074451327324, "_runtime": 580.355712890625, "_timestamp": 1585418439.235939, "_step": 461}
{"Episode reward": -103.04670218175958, "Episode length": 999, "Policy Loss": -0.1488097608089447, "Value Loss": 0.0332183875143528, "_runtime": 581.6639070510864, "_timestamp": 1585418440.5441332, "_step": 462}
{"Episode reward": -99.7436654346769, "Episode length": 999, "Policy Loss": -0.1331629604101181, "Value Loss": 0.0266600102186203, "_runtime": 582.9559679031372, "_timestamp": 1585418441.836194, "_step": 463}
{"Episode reward": -104.613466863514, "Episode length": 999, "Policy Loss": -0.14720316231250763, "Value Loss": 0.03258670121431351, "_runtime": 584.167397737503, "_timestamp": 1585418443.0476239, "_step": 464}
{"Episode reward": -100.58626476256212, "Episode length": 999, "Policy Loss": -0.1354602873325348, "Value Loss": 0.03138599917292595, "_runtime": 585.359158039093, "_timestamp": 1585418444.2393842, "_step": 465}
{"Episode reward": -106.32511550241782, "Episode length": 999, "Policy Loss": -0.14862793684005737, "Value Loss": 0.03589831292629242, "_runtime": 586.4323728084564, "_timestamp": 1585418445.312599, "_step": 466}
{"Episode reward": -2.364526662487137, "Episode length": 869, "Policy Loss": 0.11575119942426682, "Value Loss": 11.270528793334961, "_runtime": 587.6356899738312, "_timestamp": 1585418446.515916, "_step": 467}
{"Episode reward": -102.65311117857425, "Episode length": 999, "Policy Loss": -0.13408061861991882, "Value Loss": 0.03102518804371357, "_runtime": 589.0465998649597, "_timestamp": 1585418447.926826, "_step": 468}
{"Episode reward": -109.69050122182183, "Episode length": 999, "Policy Loss": -0.14362148940563202, "Value Loss": 0.036175064742565155, "_runtime": 590.3959927558899, "_timestamp": 1585418449.276219, "_step": 469}
{"Episode reward": -101.68093509360125, "Episode length": 999, "Policy Loss": -0.13829655945301056, "Value Loss": 0.03076104260981083, "_runtime": 591.7612719535828, "_timestamp": 1585418450.641498, "_step": 470}
{"Episode reward": -97.2918695401741, "Episode length": 999, "Policy Loss": -0.13105759024620056, "Value Loss": 0.02759537473320961, "_runtime": 593.1306278705597, "_timestamp": 1585418452.010854, "_step": 471}
{"Episode reward": -96.91457214024118, "Episode length": 999, "Policy Loss": -0.1389312893152237, "Value Loss": 0.027567679062485695, "_runtime": 594.3960418701172, "_timestamp": 1585418453.276268, "_step": 472}
{"Episode reward": -102.78287618805898, "Episode length": 999, "Policy Loss": -0.14353130757808685, "Value Loss": 0.03160926327109337, "_runtime": 595.5958168506622, "_timestamp": 1585418454.476043, "_step": 473}
{"Episode reward": -99.8006162174178, "Episode length": 999, "Policy Loss": -0.1382429003715515, "Value Loss": 0.03129183128476143, "_runtime": 596.7852079868317, "_timestamp": 1585418455.6654341, "_step": 474}
{"Episode reward": 7.107852833691041, "Episode length": 945, "Policy Loss": -0.02640336938202381, "Value Loss": 10.6276216506958, "_runtime": 598.060065984726, "_timestamp": 1585418456.9402921, "_step": 475}
{"Episode reward": -91.6658987568863, "Episode length": 999, "Policy Loss": -0.12373802065849304, "Value Loss": 0.0229091327637434, "_runtime": 599.4036767482758, "_timestamp": 1585418458.283903, "_step": 476}
{"Episode reward": -95.29634880152618, "Episode length": 999, "Policy Loss": -0.13598382472991943, "Value Loss": 0.02878124825656414, "_runtime": 600.6850039958954, "_timestamp": 1585418459.5652301, "_step": 477}
{"Episode reward": -93.93093487303993, "Episode length": 999, "Policy Loss": -0.13572725653648376, "Value Loss": 0.02801784873008728, "_runtime": 601.8511779308319, "_timestamp": 1585418460.731404, "_step": 478}
{"Episode reward": 14.725757302409193, "Episode length": 931, "Policy Loss": 0.019052641466259956, "Value Loss": 10.72802448272705, "_runtime": 603.0973198413849, "_timestamp": 1585418461.977546, "_step": 479}
{"Episode reward": -98.65253067953212, "Episode length": 999, "Policy Loss": -0.12940581142902374, "Value Loss": 0.02969565987586975, "_runtime": 604.3720197677612, "_timestamp": 1585418463.252246, "_step": 480}
{"Episode reward": -105.45417831046092, "Episode length": 999, "Policy Loss": -0.14302363991737366, "Value Loss": 0.031902700662612915, "_runtime": 605.6224517822266, "_timestamp": 1585418464.502678, "_step": 481}
{"Episode reward": -100.1454220841229, "Episode length": 999, "Policy Loss": -0.13424691557884216, "Value Loss": 0.03062666766345501, "_runtime": 606.8744399547577, "_timestamp": 1585418465.754666, "_step": 482}
{"Episode reward": -100.06539332901363, "Episode length": 999, "Policy Loss": -0.13739539682865143, "Value Loss": 0.028964387252926826, "_runtime": 608.1297190189362, "_timestamp": 1585418467.0099452, "_step": 483}
{"Episode reward": -97.99213261397226, "Episode length": 999, "Policy Loss": -0.1273953765630722, "Value Loss": 0.028572412207722664, "_runtime": 609.4230768680573, "_timestamp": 1585418468.303303, "_step": 484}
{"Episode reward": -107.92482206996449, "Episode length": 999, "Policy Loss": -0.14893971383571625, "Value Loss": 0.03358682990074158, "_runtime": 610.7344257831573, "_timestamp": 1585418469.614652, "_step": 485}
{"Episode reward": -107.23937592823204, "Episode length": 999, "Policy Loss": -0.1437380015850067, "Value Loss": 0.031557291746139526, "_runtime": 611.9783098697662, "_timestamp": 1585418470.858536, "_step": 486}
{"Episode reward": -118.05352323087762, "Episode length": 999, "Policy Loss": -0.16964228451251984, "Value Loss": 0.041908085346221924, "_runtime": 613.2394030094147, "_timestamp": 1585418472.1196291, "_step": 487}
{"Episode reward": -119.54162822404024, "Episode length": 999, "Policy Loss": -0.17282474040985107, "Value Loss": 0.03916897252202034, "_runtime": 614.5191447734833, "_timestamp": 1585418473.399371, "_step": 488}
{"Episode reward": -117.17738870557488, "Episode length": 999, "Policy Loss": -0.1581692397594452, "Value Loss": 0.041209544986486435, "_runtime": 615.7331819534302, "_timestamp": 1585418474.613408, "_step": 489}
{"Episode reward": -111.13266516169358, "Episode length": 999, "Policy Loss": -0.16327060759067535, "Value Loss": 0.035588521510362625, "_runtime": 616.9892318248749, "_timestamp": 1585418475.869458, "_step": 490}
{"Episode reward": -112.09416938819763, "Episode length": 999, "Policy Loss": -0.163487508893013, "Value Loss": 0.036318328231573105, "_runtime": 618.341304063797, "_timestamp": 1585418477.2215302, "_step": 491}
{"Episode reward": -110.0038450676673, "Episode length": 999, "Policy Loss": -0.15110450983047485, "Value Loss": 0.03904563561081886, "_runtime": 619.7560129165649, "_timestamp": 1585418478.636239, "_step": 492}
{"Episode reward": -115.80738550862603, "Episode length": 999, "Policy Loss": -0.15718144178390503, "Value Loss": 0.037666600197553635, "_runtime": 621.0466327667236, "_timestamp": 1585418479.926859, "_step": 493}
{"Episode reward": -105.5319402376953, "Episode length": 999, "Policy Loss": -0.14737051725387573, "Value Loss": 0.03437115252017975, "_runtime": 622.3832168579102, "_timestamp": 1585418481.263443, "_step": 494}
{"Episode reward": -116.03575920884798, "Episode length": 999, "Policy Loss": -0.15840694308280945, "Value Loss": 0.0388125404715538, "_runtime": 623.6837439537048, "_timestamp": 1585418482.56397, "_step": 495}
{"Episode reward": -109.14873997621211, "Episode length": 999, "Policy Loss": -0.14947615563869476, "Value Loss": 0.03751291334629059, "_runtime": 624.9811148643494, "_timestamp": 1585418483.861341, "_step": 496}
{"Episode reward": -123.3084736746464, "Episode length": 999, "Policy Loss": -0.169465109705925, "Value Loss": 0.044453635811805725, "_runtime": 626.2368688583374, "_timestamp": 1585418485.117095, "_step": 497}
{"Episode reward": -118.59151710599933, "Episode length": 999, "Policy Loss": -0.16210903227329254, "Value Loss": 0.042416200041770935, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116, 0.6976619362831116]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4223545491695404, -0.40450045466423035, -0.3866463303565979, -0.36879223585128784, -0.3509381413459778, -0.33308401703834534, -0.3152299225330353, -0.29737579822540283, -0.2795217037200928, -0.2616676092147827, -0.24381348490715027, -0.2259593904018402, -0.20810528099536896, -0.1902511715888977, -0.17239707708358765, -0.1545429527759552, -0.13668885827064514, -0.11883476376533508, -0.10098063945770264, -0.08312654495239258, -0.06527242064476013, -0.04741832613945007, -0.029564231634140015, -0.011710107326507568, 0.00614398717880249, 0.02399808168411255, 0.041852205991744995, 0.059706300497055054, 0.07756039500236511, 0.09541448950767517, 0.11326864361763, 0.13112273812294006, 0.14897683262825012, 0.16683092713356018, 0.18468502163887024, 0.20253917574882507, 0.22039327025413513, 0.2382473647594452, 0.25610145926475525, 0.2739555537700653, 0.29180970788002014, 0.3096638023853302, 0.32751789689064026, 0.3453719913959503, 0.3632260859012604, 0.38108018040657043, 0.39893433451652527, 0.4167884290218353, 0.4346425235271454, 0.45249661803245544, 0.4703507125377655, 0.48820486664772034, 0.506058931350708, 0.5239130258560181, 0.5417671203613281, 0.5596212148666382, 0.5774753093719482, 0.5953294038772583, 0.6131834983825684, 0.631037712097168, 0.648891806602478, 0.6667459011077881, 0.6845999956130981, 0.7024540901184082, 0.7203081846237183]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3556375801563263, -0.3449934720993042, -0.3343493640422821, -0.32370525598526, -0.3130611777305603, -0.3024170696735382, -0.2917729616165161, -0.281128853559494, -0.2704847455024719, -0.25984063744544983, -0.24919652938842773, -0.23855243623256683, -0.22790832817554474, -0.21726422011852264, -0.20662012696266174, -0.19597601890563965, -0.18533191084861755, -0.17468780279159546, -0.16404369473457336, -0.15339960157871246, -0.14275549352169037, -0.13211138546466827, -0.12146729230880737, -0.11082318425178528, -0.10017907619476318, -0.08953496813774109, -0.078890860080719, -0.0682467520236969, -0.05760267376899719, -0.0469585657119751, -0.036314457654953, -0.025670349597930908, -0.015026241540908813, -0.004382133483886719, 0.006261974573135376, 0.01690608263015747, 0.027550190687179565, 0.03819426894187927, 0.04883837699890137, 0.05948248505592346, 0.07012659311294556, 0.08077070116996765, 0.09141480922698975, 0.10205891728401184, 0.11270299553871155, 0.12334710359573364, 0.13399121165275574, 0.14463534951210022, 0.15527942776679993, 0.16592350602149963, 0.17656764388084412, 0.18721172213554382, 0.1978558599948883, 0.208499938249588, 0.2191440761089325, 0.2297881543636322, 0.2404322326183319, 0.2510763704776764, 0.2617204487323761, 0.2723645865917206, 0.2830086648464203, 0.29365280270576477, 0.3042968809604645, 0.31494101881980896, 0.32558509707450867]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 9.0, 2.0, 3.0, 11.0, 5.0, 13.0, 9.0, 9.0, 13.0, 12.0, 14.0, 13.0, 21.0, 43.0, 57.0, 30.0, 55.0, 19.0, 23.0, 22.0, 36.0, 11.0, 13.0, 8.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 5.0, 7.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.308793842792511, -0.29955175518989563, -0.2903096675872803, -0.2810675799846649, -0.27182549238204956, -0.2625834047794342, -0.25334131717681885, -0.2440992146730423, -0.23485712707042694, -0.22561503946781158, -0.21637295186519623, -0.20713084936141968, -0.19788876175880432, -0.18864667415618896, -0.1794045865535736, -0.17016249895095825, -0.1609204113483429, -0.15167832374572754, -0.14243623614311218, -0.13319414854049683, -0.12395206093788147, -0.11470995843410492, -0.10546787083148956, -0.0962257832288742, -0.08698369562625885, -0.0777416080236435, -0.06849952042102814, -0.05925743281841278, -0.05001533031463623, -0.040773242712020874, -0.03153115510940552, -0.02228906750679016, -0.013046979904174805, -0.0038048923015594482, 0.005437195301055908, 0.014679282903671265, 0.02392137050628662, 0.03316345810890198, 0.042405545711517334, 0.05164763331413269, 0.06088972091674805, 0.07013183832168579, 0.07937392592430115, 0.0886160135269165, 0.09785810112953186, 0.10710018873214722, 0.11634227633476257, 0.12558436393737793, 0.1348264515399933, 0.14406853914260864, 0.153310626745224, 0.16255271434783936, 0.1717948019504547, 0.18103688955307007, 0.19027897715568542, 0.19952106475830078, 0.20876318216323853, 0.2180052399635315, 0.22724735736846924, 0.2364894151687622, 0.24573153257369995, 0.2549735903739929, 0.26421570777893066, 0.27345776557922363, 0.2826998829841614]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.19650453329086304, -0.18907877802848816, -0.18165302276611328, -0.1742272675037384, -0.16680151224136353, -0.15937575697898865, -0.15195000171661377, -0.14452426135540009, -0.1370985060930252, -0.12967275083065033, -0.12224699556827545, -0.11482124030590057, -0.1073954850435257, -0.09996972978115082, -0.09254398196935654, -0.08511822670698166, -0.07769247144460678, -0.0702667236328125, -0.06284096837043762, -0.055415213108062744, -0.047989457845687866, -0.04056370258331299, -0.03313794732093811, -0.025712192058563232, -0.018286436796188354, -0.010860681533813477, -0.0034349262714385986, 0.0039908140897750854, 0.011416569352149963, 0.01884232461452484, 0.02626807987689972, 0.0336938351392746, 0.041119590401649475, 0.04854534566402435, 0.05597108602523804, 0.06339684128761292, 0.07082259654998779, 0.07824835181236267, 0.08567410707473755, 0.09309986233711243, 0.1005256175994873, 0.10795137286186218, 0.11537712812423706, 0.12280288338661194, 0.13022863864898682, 0.1376543939113617, 0.14508014917373657, 0.15250590443611145, 0.15993165969848633, 0.1673574149608612, 0.17478317022323608, 0.18220892548561096, 0.18963468074798584, 0.19706043601036072, 0.2044861614704132, 0.21191191673278809, 0.21933767199516296, 0.22676342725753784, 0.23418918251991272, 0.2416149377822876, 0.24904069304466248, 0.25646644830703735, 0.26389220356941223, 0.2713179588317871, 0.278743714094162]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 6.0, 7.0, 11.0, 8.0, 5.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.18166658282279968, -0.1768386960029602, -0.17201080918312073, -0.16718292236328125, -0.16235503554344177, -0.1575271487236023, -0.15269926190376282, -0.14787137508392334, -0.14304348826408386, -0.13821560144424438, -0.1333877146244049, -0.12855981290340424, -0.12373192608356476, -0.11890403926372528, -0.1140761524438858, -0.10924826562404633, -0.10442037880420685, -0.09959249198436737, -0.0947646051645279, -0.08993671834468842, -0.08510883152484894, -0.08028093725442886, -0.07545305043458939, -0.07062516361474991, -0.06579727679491043, -0.06096938997507095, -0.05614149570465088, -0.0513136088848114, -0.046485722064971924, -0.041657835245132446, -0.03682994842529297, -0.03200206160545349, -0.027174174785614014, -0.022346287965774536, -0.01751840114593506, -0.012690514326095581, -0.007862627506256104, -0.003034740686416626, 0.0017931461334228516, 0.006621032953262329, 0.011448919773101807, 0.016276821494102478, 0.021104708313941956, 0.025932595133781433, 0.03076048195362091, 0.03558836877346039, 0.040416255593299866, 0.04524414241313934, 0.05007202923297882, 0.0548999160528183, 0.059727802872657776, 0.06455568969249725, 0.06938359141349792, 0.0742114782333374, 0.07903936505317688, 0.08386725187301636, 0.08869513869285583, 0.09352302551269531, 0.09835091233253479, 0.10317879915237427, 0.10800668597221375, 0.11283457279205322, 0.1176624596118927, 0.12249034643173218, 0.12731823325157166]}, "_runtime": 627.5609579086304, "_timestamp": 1585418486.441184, "_step": 498}
{"Episode reward": -126.39269794140566, "Episode length": 999, "Policy Loss": -0.17636050283908844, "Value Loss": 0.04871760308742523, "_runtime": 628.8733339309692, "_timestamp": 1585418487.75356, "_step": 499}
