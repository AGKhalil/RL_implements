{"Episode reward": -45.290817572426995, "Episode length": 999, "Policy Loss": -0.05450757220387459, "Value Loss": 0.0217844620347023, "_runtime": 1314.8190166950226, "_timestamp": 1585510393.2397463, "_step": 0}
{"Episode reward": 24.6840707478991, "Episode length": 797, "Policy Loss": 0.3327782154083252, "Value Loss": 19.76620101928711, "_runtime": 1315.790693283081, "_timestamp": 1585510394.211423, "_step": 1}
{"Episode reward": 34.877200516159775, "Episode length": 665, "Policy Loss": 0.33669838309288025, "Value Loss": 15.464312553405762, "_runtime": 1316.8253061771393, "_timestamp": 1585510395.2460358, "_step": 2}
{"Episode reward": 34.54818383925493, "Episode length": 665, "Policy Loss": 0.17697441577911377, "Value Loss": 14.89604663848877, "_runtime": 1318.3232758045197, "_timestamp": 1585510396.7440054, "_step": 3}
{"Episode reward": -98.43502825652527, "Episode length": 999, "Policy Loss": -0.5178854465484619, "Value Loss": 0.17921759188175201, "_runtime": 1319.821192741394, "_timestamp": 1585510398.2419224, "_step": 4}
{"Episode reward": -98.2057663808675, "Episode length": 999, "Policy Loss": -0.48706141114234924, "Value Loss": 0.06680663675069809, "_runtime": 1320.8195688724518, "_timestamp": 1585510399.2402985, "_step": 5}
{"Episode reward": 36.54688353075816, "Episode length": 649, "Policy Loss": 0.17467840015888214, "Value Loss": 15.685166358947754, "_runtime": 1321.7702305316925, "_timestamp": 1585510400.1909602, "_step": 6}
{"Episode reward": 40.34071688317878, "Episode length": 616, "Policy Loss": 0.25700971484184265, "Value Loss": 16.38484001159668, "_runtime": 1322.775215625763, "_timestamp": 1585510401.1959453, "_step": 7}
{"Episode reward": 37.178360071314934, "Episode length": 662, "Policy Loss": 0.17856651544570923, "Value Loss": 15.176414489746094, "_runtime": 1324.2899458408356, "_timestamp": 1585510402.7106755, "_step": 8}
{"Episode reward": -92.84829020691313, "Episode length": 999, "Policy Loss": -0.3307552933692932, "Value Loss": 0.012306014075875282, "_runtime": 1325.7967302799225, "_timestamp": 1585510404.21746, "_step": 9}
{"Episode reward": -86.20382038854046, "Episode length": 999, "Policy Loss": -0.24488700926303864, "Value Loss": 0.011492370627820492, "_runtime": 1327.354157447815, "_timestamp": 1585510405.774887, "_step": 10}
{"Episode reward": -52.23587637023221, "Episode length": 999, "Policy Loss": -0.07748852670192719, "Value Loss": 0.005617753602564335, "_runtime": 1328.9031274318695, "_timestamp": 1585510407.323857, "_step": 11}
{"Episode reward": -47.42314486936312, "Episode length": 999, "Policy Loss": -0.03265753015875816, "Value Loss": 0.004436911549419165, "_runtime": 1330.4350295066833, "_timestamp": 1585510408.8557591, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17349296808242798, "Value Loss": 0.012366862036287785, "_runtime": 1331.973952293396, "_timestamp": 1585510410.394682, "_step": 13}
{"Episode reward": -71.69385828603666, "Episode length": 999, "Policy Loss": -0.13055920600891113, "Value Loss": 0.007870548404753208, "_runtime": 1333.531972169876, "_timestamp": 1585510411.9527018, "_step": 14}
{"Episode reward": -89.91477796448132, "Episode length": 999, "Policy Loss": -0.23447299003601074, "Value Loss": 0.009452957659959793, "_runtime": 1335.0851452350616, "_timestamp": 1585510413.5058749, "_step": 15}
{"Episode reward": -91.42966382539144, "Episode length": 999, "Policy Loss": -0.25884678959846497, "Value Loss": 0.009027293883264065, "_runtime": 1336.6397721767426, "_timestamp": 1585510415.0605018, "_step": 16}
{"Episode reward": -92.55729810865637, "Episode length": 999, "Policy Loss": -0.27579182386398315, "Value Loss": 0.013627911917865276, "_runtime": 1338.2111177444458, "_timestamp": 1585510416.6318474, "_step": 17}
{"Episode reward": -92.25495958776388, "Episode length": 999, "Policy Loss": -0.2933400273323059, "Value Loss": 0.015478352084755898, "_runtime": 1339.7558121681213, "_timestamp": 1585510418.1765418, "_step": 18}
{"Episode reward": -93.19082064299822, "Episode length": 999, "Policy Loss": -0.2934935390949249, "Value Loss": 0.009627637453377247, "_runtime": 1341.3060970306396, "_timestamp": 1585510419.7268267, "_step": 19}
{"Episode reward": -94.87380992587285, "Episode length": 999, "Policy Loss": -0.2886839509010315, "Value Loss": 0.010535992681980133, "_runtime": 1342.8659732341766, "_timestamp": 1585510421.2867029, "_step": 20}
{"Episode reward": -91.66118063240322, "Episode length": 999, "Policy Loss": -0.267392098903656, "Value Loss": 0.009822487831115723, "_runtime": 1344.423248052597, "_timestamp": 1585510422.8439777, "_step": 21}
{"Episode reward": -92.38406561275234, "Episode length": 999, "Policy Loss": -0.2455519139766693, "Value Loss": 0.011268544010818005, "_runtime": 1345.9841425418854, "_timestamp": 1585510424.4048722, "_step": 22}
{"Episode reward": -93.79234077134711, "Episode length": 999, "Policy Loss": -0.23253095149993896, "Value Loss": 0.017961330711841583, "_runtime": 1347.5456411838531, "_timestamp": 1585510425.9663708, "_step": 23}
{"Episode reward": -94.03251745003965, "Episode length": 999, "Policy Loss": -0.25049343705177307, "Value Loss": 0.014411184936761856, "_runtime": 1349.102439403534, "_timestamp": 1585510427.523169, "_step": 24}
{"Episode reward": -96.17727037314319, "Episode length": 999, "Policy Loss": -0.2905160188674927, "Value Loss": 0.009344383142888546, "_runtime": 1350.679559469223, "_timestamp": 1585510429.100289, "_step": 25}
{"Episode reward": -97.19776621971324, "Episode length": 999, "Policy Loss": -0.31004729866981506, "Value Loss": 0.009965579956769943, "_runtime": 1352.2362632751465, "_timestamp": 1585510430.656993, "_step": 26}
{"Episode reward": -96.58456664688764, "Episode length": 999, "Policy Loss": -0.2891536056995392, "Value Loss": 0.017323127016425133, "_runtime": 1353.795562028885, "_timestamp": 1585510432.2162917, "_step": 27}
{"Episode reward": -97.3087299686121, "Episode length": 999, "Policy Loss": -0.29945939779281616, "Value Loss": 0.012955856509506702, "_runtime": 1355.3478543758392, "_timestamp": 1585510433.768584, "_step": 28}
{"Episode reward": -95.3873056060072, "Episode length": 999, "Policy Loss": -0.27719026803970337, "Value Loss": 0.007399745285511017, "_runtime": 1356.904409646988, "_timestamp": 1585510435.3251393, "_step": 29}
{"Episode reward": -95.58884975234012, "Episode length": 999, "Policy Loss": -0.26253631711006165, "Value Loss": 0.009018356911838055, "_runtime": 1358.471811056137, "_timestamp": 1585510436.8925407, "_step": 30}
{"Episode reward": -95.81573847663488, "Episode length": 999, "Policy Loss": -0.2758466303348541, "Value Loss": 0.03446756303310394, "_runtime": 1360.0342240333557, "_timestamp": 1585510438.4549537, "_step": 31}
{"Episode reward": -97.79233471530092, "Episode length": 999, "Policy Loss": -0.2876661419868469, "Value Loss": 0.006162444595247507, "_runtime": 1361.589949131012, "_timestamp": 1585510440.0106788, "_step": 32}
{"Episode reward": -97.74350360001786, "Episode length": 999, "Policy Loss": -0.278878390789032, "Value Loss": 0.04177961125969887, "_runtime": 1363.1600711345673, "_timestamp": 1585510441.5808008, "_step": 33}
{"Episode reward": -95.40294745988322, "Episode length": 999, "Policy Loss": -0.26752200722694397, "Value Loss": 0.01048983633518219, "_runtime": 1364.7249100208282, "_timestamp": 1585510443.1456397, "_step": 34}
{"Episode reward": -97.0922363145421, "Episode length": 999, "Policy Loss": -0.23833946883678436, "Value Loss": 0.012009894475340843, "_runtime": 1366.2930035591125, "_timestamp": 1585510444.7137332, "_step": 35}
{"Episode reward": -97.13885967904942, "Episode length": 999, "Policy Loss": -0.32514920830726624, "Value Loss": 0.046324633061885834, "_runtime": 1367.8478066921234, "_timestamp": 1585510446.2685363, "_step": 36}
{"Episode reward": -97.57989429431643, "Episode length": 999, "Policy Loss": -0.2617730498313904, "Value Loss": 0.005684040021151304, "_runtime": 1369.400836467743, "_timestamp": 1585510447.821566, "_step": 37}
{"Episode reward": -96.51558978997767, "Episode length": 999, "Policy Loss": -0.18245582282543182, "Value Loss": 0.041371650993824005, "_runtime": 1370.9712643623352, "_timestamp": 1585510449.391994, "_step": 38}
{"Episode reward": -97.05130955026594, "Episode length": 999, "Policy Loss": -0.22981783747673035, "Value Loss": 0.0361422635614872, "_runtime": 1372.5284106731415, "_timestamp": 1585510450.9491403, "_step": 39}
{"Episode reward": -95.91259601269203, "Episode length": 999, "Policy Loss": -0.1952265352010727, "Value Loss": 0.006691701710224152, "_runtime": 1374.118910074234, "_timestamp": 1585510452.5396397, "_step": 40}
{"Episode reward": -95.54488742920282, "Episode length": 999, "Policy Loss": -0.22314782440662384, "Value Loss": 0.003773393342271447, "_runtime": 1375.6764526367188, "_timestamp": 1585510454.0971823, "_step": 41}
{"Episode reward": -94.95356057802277, "Episode length": 999, "Policy Loss": -0.20261171460151672, "Value Loss": 0.006436904892325401, "_runtime": 1377.2455170154572, "_timestamp": 1585510455.6662467, "_step": 42}
{"Episode reward": -95.97446028129092, "Episode length": 999, "Policy Loss": -0.23648113012313843, "Value Loss": 0.009760591201484203, "_runtime": 1378.8072428703308, "_timestamp": 1585510457.2279725, "_step": 43}
{"Episode reward": -94.59304416377324, "Episode length": 999, "Policy Loss": -0.18904900550842285, "Value Loss": 0.010391052812337875, "_runtime": 1380.3524405956268, "_timestamp": 1585510458.7731702, "_step": 44}
{"Episode reward": -95.38866438613316, "Episode length": 999, "Policy Loss": -0.21774686872959137, "Value Loss": 0.014239502139389515, "_runtime": 1381.9007818698883, "_timestamp": 1585510460.3215115, "_step": 45}
{"Episode reward": -97.67023138541715, "Episode length": 999, "Policy Loss": -0.17113596200942993, "Value Loss": 0.05825581029057503, "_runtime": 1383.4428565502167, "_timestamp": 1585510461.8635862, "_step": 46}
{"Episode reward": -97.88147967500885, "Episode length": 999, "Policy Loss": -0.221974715590477, "Value Loss": 0.02625175192952156, "_runtime": 1384.9884564876556, "_timestamp": 1585510463.4091861, "_step": 47}
{"Episode reward": -99.25899115687325, "Episode length": 999, "Policy Loss": -0.2606080174446106, "Value Loss": 0.003100162837654352, "_runtime": 1386.5360827445984, "_timestamp": 1585510464.9568124, "_step": 48}
{"Episode reward": -98.84212145486009, "Episode length": 999, "Policy Loss": -0.1941431164741516, "Value Loss": 0.010741841979324818, "_runtime": 1388.0810060501099, "_timestamp": 1585510466.5017357, "_step": 49}
{"Episode reward": -98.95892496105382, "Episode length": 999, "Policy Loss": -0.26887837052345276, "Value Loss": 0.04640764370560646, "_runtime": 1389.1048097610474, "_timestamp": 1585510467.5255394, "_step": 50}
{"Episode reward": 34.8727753480932, "Episode length": 658, "Policy Loss": 0.45483508706092834, "Value Loss": 15.45151138305664, "_runtime": 1390.6555359363556, "_timestamp": 1585510469.0762656, "_step": 51}
{"Episode reward": -99.21129828772726, "Episode length": 999, "Policy Loss": -0.26337599754333496, "Value Loss": 0.01037257444113493, "_runtime": 1392.2044060230255, "_timestamp": 1585510470.6251357, "_step": 52}
{"Episode reward": -99.42279223605011, "Episode length": 999, "Policy Loss": -0.1915174126625061, "Value Loss": 0.12498024106025696, "_runtime": 1393.065678358078, "_timestamp": 1585510471.486408, "_step": 53}
{"Episode reward": 43.966937162304234, "Episode length": 564, "Policy Loss": 0.7933145761489868, "Value Loss": 17.6197509765625, "_runtime": 1394.6034045219421, "_timestamp": 1585510473.0241342, "_step": 54}
{"Episode reward": -98.9431818854414, "Episode length": 999, "Policy Loss": -0.21625681221485138, "Value Loss": 0.05971229076385498, "_runtime": 1396.1891696453094, "_timestamp": 1585510474.6098993, "_step": 55}
{"Episode reward": -98.75077132424826, "Episode length": 999, "Policy Loss": -0.24500995874404907, "Value Loss": 0.07512358576059341, "_runtime": 1397.7075402736664, "_timestamp": 1585510476.12827, "_step": 56}
{"Episode reward": -99.61349796259172, "Episode length": 999, "Policy Loss": -0.2708912193775177, "Value Loss": 0.03091423586010933, "_runtime": 1399.2645535469055, "_timestamp": 1585510477.6852832, "_step": 57}
{"Episode reward": -99.0208655424189, "Episode length": 999, "Policy Loss": -0.29021593928337097, "Value Loss": 0.030014658346772194, "_runtime": 1400.8131139278412, "_timestamp": 1585510479.2338436, "_step": 58}
{"Episode reward": -99.207000463858, "Episode length": 999, "Policy Loss": -0.32134419679641724, "Value Loss": 0.004336663521826267, "_runtime": 1402.3678967952728, "_timestamp": 1585510480.7886264, "_step": 59}
{"Episode reward": -98.78383988742364, "Episode length": 999, "Policy Loss": -0.3116130232810974, "Value Loss": 0.004873450379818678, "_runtime": 1403.5901956558228, "_timestamp": 1585510482.0109253, "_step": 60}
{"Episode reward": 22.93720862109585, "Episode length": 782, "Policy Loss": 0.6888942718505859, "Value Loss": 12.755757331848145, "_runtime": 1404.5713086128235, "_timestamp": 1585510482.9920382, "_step": 61}
{"Episode reward": 38.059036211557796, "Episode length": 622, "Policy Loss": 0.4330877959728241, "Value Loss": 16.052976608276367, "_runtime": 1406.124492406845, "_timestamp": 1585510484.545222, "_step": 62}
{"Episode reward": -99.08519942111727, "Episode length": 999, "Policy Loss": -0.32455411553382874, "Value Loss": 0.003959223628044128, "_runtime": 1407.6733543872833, "_timestamp": 1585510486.094084, "_step": 63}
{"Episode reward": -99.3755583696752, "Episode length": 999, "Policy Loss": -0.32562172412872314, "Value Loss": 0.0036721257492899895, "_runtime": 1409.1817953586578, "_timestamp": 1585510487.602525, "_step": 64}
{"Episode reward": -99.58606700770768, "Episode length": 999, "Policy Loss": -0.33002081513404846, "Value Loss": 0.0037085795775055885, "_runtime": 1410.7291312217712, "_timestamp": 1585510489.1498609, "_step": 65}
{"Episode reward": -99.16566870766239, "Episode length": 999, "Policy Loss": -0.32012003660202026, "Value Loss": 0.003725151065737009, "_runtime": 1412.2790858745575, "_timestamp": 1585510490.6998155, "_step": 66}
{"Episode reward": -99.15192342029952, "Episode length": 999, "Policy Loss": -0.3187686502933502, "Value Loss": 0.0036473823711276054, "_runtime": 1413.8222723007202, "_timestamp": 1585510492.243002, "_step": 67}
{"Episode reward": -99.2539366803817, "Episode length": 999, "Policy Loss": -0.31841668486595154, "Value Loss": 0.003491439623758197, "_runtime": 1415.375610113144, "_timestamp": 1585510493.7963398, "_step": 68}
{"Episode reward": -97.74520583329034, "Episode length": 999, "Policy Loss": -0.28036126494407654, "Value Loss": 0.003711652709171176, "_runtime": 1416.9267437458038, "_timestamp": 1585510495.3474734, "_step": 69}
{"Episode reward": -98.98277757865495, "Episode length": 999, "Policy Loss": -0.3074491322040558, "Value Loss": 0.003494956996291876, "_runtime": 1418.4920253753662, "_timestamp": 1585510496.912755, "_step": 70}
{"Episode reward": -99.15628552827876, "Episode length": 999, "Policy Loss": -0.30977219343185425, "Value Loss": 0.003353833220899105, "_runtime": 1420.0818634033203, "_timestamp": 1585510498.502593, "_step": 71}
{"Episode reward": -97.41574608933671, "Episode length": 999, "Policy Loss": -0.23782125115394592, "Value Loss": 0.0035230189096182585, "_runtime": 1420.705052614212, "_timestamp": 1585510499.1257823, "_step": 72}
{"Episode reward": 62.292227460410416, "Episode length": 381, "Policy Loss": 1.9436454772949219, "Value Loss": 26.198482513427734, "_runtime": 1422.2550075054169, "_timestamp": 1585510500.6757371, "_step": 73}
{"Episode reward": -99.80248884132457, "Episode length": 999, "Policy Loss": -0.34206199645996094, "Value Loss": 0.0031628580763936043, "_runtime": 1423.816514968872, "_timestamp": 1585510502.2372446, "_step": 74}
{"Episode reward": -99.5163851205828, "Episode length": 999, "Policy Loss": -0.33830147981643677, "Value Loss": 0.004253148101270199, "_runtime": 1424.6644806861877, "_timestamp": 1585510503.0852103, "_step": 75}
{"Episode reward": 43.87629206394725, "Episode length": 562, "Policy Loss": 0.805760383605957, "Value Loss": 17.71817398071289, "_runtime": 1426.1353306770325, "_timestamp": 1585510504.5560603, "_step": 76}
{"Episode reward": 5.345300845354728, "Episode length": 950, "Policy Loss": 0.41816002130508423, "Value Loss": 10.449186325073242, "_runtime": 1427.6952965259552, "_timestamp": 1585510506.1160262, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30827733874320984, "Value Loss": 0.006033345125615597, "_runtime": 1429.205904006958, "_timestamp": 1585510507.6266336, "_step": 78}
{"Episode reward": -99.83130847820873, "Episode length": 999, "Policy Loss": -0.26396363973617554, "Value Loss": 0.1900658756494522, "_runtime": 1430.7548480033875, "_timestamp": 1585510509.1755776, "_step": 79}
{"Episode reward": -99.84322075343086, "Episode length": 999, "Policy Loss": -0.28383228182792664, "Value Loss": 0.059667881578207016, "_runtime": 1432.3079714775085, "_timestamp": 1585510510.728701, "_step": 80}
{"Episode reward": -99.80000050088717, "Episode length": 999, "Policy Loss": -0.3127211332321167, "Value Loss": 0.018161799758672714, "_runtime": 1433.8492867946625, "_timestamp": 1585510512.2700164, "_step": 81}
{"Episode reward": -99.71209475193034, "Episode length": 999, "Policy Loss": -0.30036646127700806, "Value Loss": 0.009549349546432495, "_runtime": 1435.334148645401, "_timestamp": 1585510513.7548783, "_step": 82}
{"Episode reward": 4.751435287478344, "Episode length": 953, "Policy Loss": 0.3717269003391266, "Value Loss": 10.453323364257812, "_runtime": 1436.9041032791138, "_timestamp": 1585510515.324833, "_step": 83}
{"Episode reward": -99.80945907868305, "Episode length": 999, "Policy Loss": -0.32186925411224365, "Value Loss": 0.01840423420071602, "_runtime": 1437.954089164734, "_timestamp": 1585510516.3748188, "_step": 84}
{"Episode reward": 33.06422327253921, "Episode length": 671, "Policy Loss": 0.8590695261955261, "Value Loss": 14.841832160949707, "_runtime": 1439.499421596527, "_timestamp": 1585510517.9201512, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30630749464035034, "Value Loss": 0.006704496219754219, "_runtime": 1441.0664751529694, "_timestamp": 1585510519.4872048, "_step": 86}
{"Episode reward": -99.70782689787309, "Episode length": 999, "Policy Loss": -0.30384954810142517, "Value Loss": 0.004492903593927622, "_runtime": 1442.1363897323608, "_timestamp": 1585510520.5571194, "_step": 87}
{"Episode reward": 30.08483880599931, "Episode length": 700, "Policy Loss": 0.7011212110519409, "Value Loss": 14.221086502075195, "_runtime": 1443.717708349228, "_timestamp": 1585510522.138438, "_step": 88}
{"Episode reward": -99.74008841076727, "Episode length": 999, "Policy Loss": -0.2960157096385956, "Value Loss": 0.0024035051465034485, "_runtime": 1445.2842276096344, "_timestamp": 1585510523.7049572, "_step": 89}
{"Episode reward": -99.80000676421774, "Episode length": 999, "Policy Loss": -0.2962777614593506, "Value Loss": 0.010010640136897564, "_runtime": 1446.8099241256714, "_timestamp": 1585510525.2306538, "_step": 90}
{"Episode reward": -99.6767971249516, "Episode length": 999, "Policy Loss": -0.3069729804992676, "Value Loss": 0.01918730139732361, "_runtime": 1448.3447880744934, "_timestamp": 1585510526.7655177, "_step": 91}
{"Episode reward": 1.1976874991333517, "Episode length": 989, "Policy Loss": 0.40377312898635864, "Value Loss": 10.06347942352295, "_runtime": 1449.888301372528, "_timestamp": 1585510528.309031, "_step": 92}
{"Episode reward": -99.70060312095892, "Episode length": 999, "Policy Loss": -0.28611230850219727, "Value Loss": 0.0032996274530887604, "_runtime": 1451.4348974227905, "_timestamp": 1585510529.855627, "_step": 93}
{"Episode reward": -99.8017228164696, "Episode length": 999, "Policy Loss": -0.2825044095516205, "Value Loss": 0.004542640410363674, "_runtime": 1452.9971261024475, "_timestamp": 1585510531.4178557, "_step": 94}
{"Episode reward": -99.6189612094299, "Episode length": 999, "Policy Loss": -0.27546125650405884, "Value Loss": 0.007941524498164654, "_runtime": 1454.5549602508545, "_timestamp": 1585510532.97569, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2848094403743744, "Value Loss": 0.018404986709356308, "_runtime": 1455.5563368797302, "_timestamp": 1585510533.9770665, "_step": 96}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.9097394347190857, "Value Loss": 15.62948226928711, "_runtime": 1456.0504450798035, "_timestamp": 1585510534.4711747, "_step": 97}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 2.1835010051727295, "Value Loss": 34.00706100463867, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863, -0.2689424455165863]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-13.054210662841797, -12.84544563293457, -12.636679649353027, -12.4279146194458, -12.219149589538574, -12.010384559631348, -11.801618576049805, -11.592853546142578, -11.384088516235352, -11.175323486328125, -10.966557502746582, -10.757792472839355, -10.549027442932129, -10.340261459350586, -10.13149642944336, -9.922731399536133, -9.713966369628906, -9.50520133972168, -9.296435356140137, -9.08767032623291, -8.878904342651367, -8.67013931274414, -8.461374282836914, -8.252609252929688, -8.043844223022461, -7.835078716278076, -7.626313209533691, -7.417548179626465, -7.20878267288208, -7.0000176429748535, -6.791252136230469, -6.582487106323242, -6.373721599578857, -6.164956092834473, -5.956191062927246, -5.747425556182861, -5.538660526275635, -5.32989501953125, -5.121129989624023, -4.912364959716797, -4.703598976135254, -4.494833946228027, -4.286068916320801, -4.077303886413574, -3.8685379028320312, -3.6597728729248047, -3.451007843017578, -3.2422428131103516, -3.0334768295288086, -2.824711799621582, -2.6159467697143555, -2.4071807861328125, -2.198415756225586, -1.9896507263183594, -1.7808856964111328, -1.5721197128295898, -1.3633546829223633, -1.1545896530151367, -0.9458246231079102, -0.7370586395263672, -0.5282936096191406, -0.31952857971191406, -0.1107635498046875, 0.09800243377685547, 0.30676746368408203]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6969028115272522, -0.6833605766296387, -0.6698182821273804, -0.6562760472297668, -0.6427337527275085, -0.629191517829895, -0.6156492233276367, -0.6021069884300232, -0.5885647535324097, -0.5750224590301514, -0.5614802241325378, -0.5479379892349243, -0.534395694732666, -0.5208534598350525, -0.5073111653327942, -0.49376893043518066, -0.48022666573524475, -0.46668440103530884, -0.4531421661376953, -0.4395999014377594, -0.4260576367378235, -0.4125153720378876, -0.39897310733795166, -0.38543084263801575, -0.37188857793807983, -0.3583463430404663, -0.3448040783405304, -0.3312618136405945, -0.31771954894065857, -0.30417728424072266, -0.29063504934310913, -0.2770927846431732, -0.2635505199432373, -0.2500082552433014, -0.23646599054336548, -0.22292375564575195, -0.20938149094581604, -0.19583922624588013, -0.1822969913482666, -0.1687546968460083, -0.15521246194839478, -0.14167016744613647, -0.12812793254852295, -0.11458569765090942, -0.10104340314865112, -0.0875011682510376, -0.0739588737487793, -0.06041663885116577, -0.04687434434890747, -0.033332109451293945, -0.01978987455368042, -0.006247580051422119, 0.007294654846191406, 0.020836949348449707, 0.03437918424606323, 0.04792141914367676, 0.06146371364593506, 0.07500594854354858, 0.08854824304580688, 0.10209047794342041, 0.11563271284103394, 0.12917500734329224, 0.14271724224090576, 0.15625953674316406, 0.1698017716407776]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 5.0, 2.0, 4.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 6.0, 1.0, 0.0, 4.0, 5.0, 2.0, 9.0, 13.0, 10.0, 7.0, 221.0, 14.0, 31.0, 32.0, 34.0, 18.0, 11.0, 11.0, 8.0, 3.0, 5.0, 6.0, 9.0, 3.0], "bins": [-2.428396701812744, -2.380112409591675, -2.3318283557891846, -2.2835440635681152, -2.235260009765625, -2.1869757175445557, -2.1386914253234863, -2.090407371520996, -2.0421230792999268, -1.993838906288147, -1.9455547332763672, -1.8972705602645874, -1.8489863872528076, -1.8007020950317383, -1.752418041229248, -1.7041337490081787, -1.655849575996399, -1.6075654029846191, -1.5592811107635498, -1.5109970569610596, -1.4627127647399902, -1.4144285917282104, -1.3661444187164307, -1.3178602457046509, -1.269576072692871, -1.2212917804718018, -1.173007607460022, -1.1247234344482422, -1.0764392614364624, -1.0281550884246826, -0.9798707962036133, -0.9315866231918335, -0.8833024501800537, -0.8350182771682739, -0.7867341041564941, -0.7384498119354248, -0.690165638923645, -0.6418814659118652, -0.5935972929000854, -0.5453131198883057, -0.49702882766723633, -0.44874465465545654, -0.40046048164367676, -0.3521761894226074, -0.3038921356201172, -0.25560784339904785, -0.20732378959655762, -0.15903949737548828, -0.11075544357299805, -0.06247115135192871, -0.014186859130859375, 0.03409719467163086, 0.0823814868927002, 0.13066554069519043, 0.17894983291625977, 0.2272341251373291, 0.27551817893981934, 0.32380247116088867, 0.3720865249633789, 0.42037081718444824, 0.4686551094055176, 0.5169391632080078, 0.5652234554290771, 0.6135075092315674, 0.6617918014526367]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.396900653839111, -6.260850429534912, -6.124800205230713, -5.988749980926514, -5.8526997566223145, -5.716649532318115, -5.580599308013916, -5.444548606872559, -5.308498382568359, -5.17244815826416, -5.036397933959961, -4.900347709655762, -4.7642974853515625, -4.628247261047363, -4.492197036743164, -4.356146812438965, -4.220096588134766, -4.084046363830566, -3.947996139526367, -3.811945915222168, -3.6758956909179688, -3.5398452281951904, -3.403795003890991, -3.267744779586792, -3.1316945552825928, -2.9956443309783936, -2.8595941066741943, -2.723543882369995, -2.587493419647217, -2.4514431953430176, -2.3153929710388184, -2.179342746734619, -2.04329252243042, -1.9072422981262207, -1.7711920738220215, -1.6351418495178223, -1.499091625213623, -1.3630414009094238, -1.2269911766052246, -1.0909409523010254, -0.9548907279968262, -0.8188400268554688, -0.6827898025512695, -0.5467395782470703, -0.4106893539428711, -0.2746391296386719, -0.13858890533447266, -0.0025386810302734375, 0.13351154327392578, 0.269561767578125, 0.4056119918823242, 0.5416622161865234, 0.6777124404907227, 0.8137626647949219, 0.9498128890991211, 1.0858631134033203, 1.2219138145446777, 1.357964038848877, 1.4940142631530762, 1.6300644874572754, 1.7661147117614746, 1.9021649360656738, 2.038215160369873, 2.1742653846740723, 2.3103156089782715]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 4.0, 6.0, 2.0, 5.0, 11.0, 9.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.42314785718917847, -0.39867037534713745, -0.37419289350509644, -0.3497154116630554, -0.3252379298210144, -0.3007604479789734, -0.2762829661369324, -0.25180548429489136, -0.22732800245285034, -0.20285052061080933, -0.1783730387687683, -0.1538955569267273, -0.12941807508468628, -0.10494059324264526, -0.08046311140060425, -0.05598562955856323, -0.03150814771652222, -0.007030665874481201, 0.017446815967559814, 0.04192429780960083, 0.06640177965164185, 0.09087926149368286, 0.11535674333572388, 0.1398342251777649, 0.1643117070198059, 0.18878918886184692, 0.21326667070388794, 0.23774415254592896, 0.26222163438796997, 0.286699116230011, 0.311176598072052, 0.335654079914093, 0.36013156175613403, 0.38460904359817505, 0.40908652544021606, 0.4335640072822571, 0.4580414891242981, 0.4825189709663391, 0.5069964528083801, 0.5314739346504211, 0.5559514164924622, 0.5804288983345032, 0.6049063801765442, 0.6293838620185852, 0.6538613438606262, 0.6783388257026672, 0.7028163075447083, 0.7272937893867493, 0.7517712712287903, 0.7762487530708313, 0.8007262349128723, 0.8252037167549133, 0.8496811985969543, 0.8741586804389954, 0.8986361622810364, 0.9231136441230774, 0.9475911259651184, 0.9720686078071594, 0.9965460896492004, 1.0210235118865967, 1.0455009937286377, 1.0699784755706787, 1.0944559574127197, 1.1189334392547607, 1.1434109210968018]}, "_runtime": 1457.421792268753, "_timestamp": 1585510535.842522, "_step": 98}
{"Episode reward": 11.336614099425105, "Episode length": 888, "Policy Loss": 0.5842587351799011, "Value Loss": 11.172555923461914, "_runtime": 1458.8451240062714, "_timestamp": 1585510537.2658536, "_step": 99}
{"Episode reward": 6.305570993363972, "Episode length": 938, "Policy Loss": 0.5523576736450195, "Value Loss": 10.562655448913574, "_runtime": 1460.31774020195, "_timestamp": 1585510538.7384698, "_step": 100}
{"Episode reward": -99.84021529108146, "Episode length": 999, "Policy Loss": -0.16299329698085785, "Value Loss": 0.11381886154413223, "_runtime": 1460.8166296482086, "_timestamp": 1585510539.2373593, "_step": 101}
{"Episode reward": 69.87873959308476, "Episode length": 302, "Policy Loss": 2.0426676273345947, "Value Loss": 32.53142166137695, "_runtime": 1462.3506977558136, "_timestamp": 1585510540.7714274, "_step": 102}
{"Episode reward": -99.73597485609213, "Episode length": 999, "Policy Loss": -0.20929847657680511, "Value Loss": 0.22524531185626984, "_runtime": 1463.891856431961, "_timestamp": 1585510542.312586, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1264995038509369, "Value Loss": 0.034497443586587906, "_runtime": 1465.387928724289, "_timestamp": 1585510543.8086584, "_step": 104}
{"Episode reward": -99.77358010355243, "Episode length": 999, "Policy Loss": -0.38175246119499207, "Value Loss": 0.5272889733314514, "_runtime": 1466.987841129303, "_timestamp": 1585510545.4085708, "_step": 105}
{"Episode reward": -99.83095430889958, "Episode length": 999, "Policy Loss": -0.2331884205341339, "Value Loss": 0.023297496140003204, "_runtime": 1468.375182390213, "_timestamp": 1585510546.795912, "_step": 106}
{"Episode reward": 10.600000000000804, "Episode length": 894, "Policy Loss": 0.4467121362686157, "Value Loss": 11.172472953796387, "_runtime": 1469.9175012111664, "_timestamp": 1585510548.3382308, "_step": 107}
{"Episode reward": -99.88379109436507, "Episode length": 999, "Policy Loss": -0.340047150850296, "Value Loss": 0.01586272194981575, "_runtime": 1471.4738352298737, "_timestamp": 1585510549.8945649, "_step": 108}
{"Episode reward": -99.78277918705577, "Episode length": 999, "Policy Loss": -0.36137065291404724, "Value Loss": 0.002673274604603648, "_runtime": 1473.0237534046173, "_timestamp": 1585510551.444483, "_step": 109}
{"Episode reward": -99.80914080524677, "Episode length": 999, "Policy Loss": -0.38967931270599365, "Value Loss": 0.002792480168864131, "_runtime": 1474.564185142517, "_timestamp": 1585510552.9849148, "_step": 110}
{"Episode reward": -99.78991382364043, "Episode length": 999, "Policy Loss": -0.41415488719940186, "Value Loss": 0.003087840508669615, "_runtime": 1475.0429253578186, "_timestamp": 1585510553.463655, "_step": 111}
{"Episode reward": 72.39999999999989, "Episode length": 276, "Policy Loss": 2.218677282333374, "Value Loss": 36.19597625732422, "_runtime": 1476.3765273094177, "_timestamp": 1585510554.797257, "_step": 112}
{"Episode reward": 13.669174596574791, "Episode length": 864, "Policy Loss": 0.37362268567085266, "Value Loss": 11.557600975036621, "_runtime": 1477.5336875915527, "_timestamp": 1585510555.9544172, "_step": 113}
{"Episode reward": 25.657145620044275, "Episode length": 744, "Policy Loss": 0.6263718008995056, "Value Loss": 13.398865699768066, "_runtime": 1477.898802280426, "_timestamp": 1585510556.319532, "_step": 114}
{"Episode reward": 76.99853215180332, "Episode length": 231, "Policy Loss": 2.6248130798339844, "Value Loss": 43.041046142578125, "_runtime": 1479.4292106628418, "_timestamp": 1585510557.8499403, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4820449948310852, "Value Loss": 0.02012632042169571, "_runtime": 1479.9420926570892, "_timestamp": 1585510558.3628223, "_step": 116}
{"Episode reward": 68.55050571775047, "Episode length": 315, "Policy Loss": 1.7639766931533813, "Value Loss": 31.38001251220703, "_runtime": 1481.4233691692352, "_timestamp": 1585510559.8440988, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45541393756866455, "Value Loss": 0.28856632113456726, "_runtime": 1482.98597073555, "_timestamp": 1585510561.4067004, "_step": 118}
{"Episode reward": -99.89142739921668, "Episode length": 999, "Policy Loss": -0.530782163143158, "Value Loss": 0.13606126606464386, "_runtime": 1484.1372845172882, "_timestamp": 1585510562.5580142, "_step": 119}
{"Episode reward": 22.857049672957615, "Episode length": 772, "Policy Loss": 0.3496558666229248, "Value Loss": 12.91283130645752, "_runtime": 1485.6804285049438, "_timestamp": 1585510564.1011581, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.54721999168396, "Value Loss": 0.03004744090139866, "_runtime": 1486.208083152771, "_timestamp": 1585510564.6288128, "_step": 121}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 2.149064540863037, "Value Loss": 31.412508010864258, "_runtime": 1487.7446081638336, "_timestamp": 1585510566.1653378, "_step": 122}
{"Episode reward": -99.89836489343875, "Episode length": 999, "Policy Loss": -0.6329729557037354, "Value Loss": 0.13244742155075073, "_runtime": 1488.5463495254517, "_timestamp": 1585510566.9670792, "_step": 123}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 0.6689104437828064, "Value Loss": 19.723154067993164, "_runtime": 1490.082603931427, "_timestamp": 1585510568.5033336, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5968666672706604, "Value Loss": 0.09681793302297592, "_runtime": 1491.6529166698456, "_timestamp": 1585510570.0736463, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5987755656242371, "Value Loss": 0.08054529875516891, "_runtime": 1492.843248128891, "_timestamp": 1585510571.2639778, "_step": 126}
{"Episode reward": 21.60000000000018, "Episode length": 784, "Policy Loss": 0.33201608061790466, "Value Loss": 12.663802146911621, "_runtime": 1493.8959608078003, "_timestamp": 1585510572.3166904, "_step": 127}
{"Episode reward": 32.412417005002055, "Episode length": 677, "Policy Loss": 0.531187891960144, "Value Loss": 14.708891868591309, "_runtime": 1495.4501037597656, "_timestamp": 1585510573.8708334, "_step": 128}
{"Episode reward": -99.68607413573052, "Episode length": 999, "Policy Loss": -0.5318563580513, "Value Loss": 0.00922264065593481, "_runtime": 1496.984384059906, "_timestamp": 1585510575.4051137, "_step": 129}
{"Episode reward": -99.74080972764501, "Episode length": 999, "Policy Loss": -0.5262824892997742, "Value Loss": 0.010849407874047756, "_runtime": 1498.0365431308746, "_timestamp": 1585510576.4572728, "_step": 130}
{"Episode reward": 31.062456958740597, "Episode length": 690, "Policy Loss": 0.5285878777503967, "Value Loss": 14.45125675201416, "_runtime": 1499.432827949524, "_timestamp": 1585510577.8535576, "_step": 131}
{"Episode reward": 10.930127107259665, "Episode length": 892, "Policy Loss": 0.30704933404922485, "Value Loss": 11.18438720703125, "_runtime": 1500.8005282878876, "_timestamp": 1585510579.221258, "_step": 132}
{"Episode reward": 12.396009271965141, "Episode length": 877, "Policy Loss": 0.30905163288116455, "Value Loss": 11.378216743469238, "_runtime": 1501.7942836284637, "_timestamp": 1585510580.2150133, "_step": 133}
{"Episode reward": 36.0403209801757, "Episode length": 640, "Policy Loss": 0.629547655582428, "Value Loss": 15.584991455078125, "_runtime": 1503.3503141403198, "_timestamp": 1585510581.7710438, "_step": 134}
{"Episode reward": -99.80535528072947, "Episode length": 999, "Policy Loss": -0.5227566957473755, "Value Loss": 0.005041008349508047, "_runtime": 1504.7967276573181, "_timestamp": 1585510583.2174573, "_step": 135}
{"Episode reward": 7.296719488409408, "Episode length": 928, "Policy Loss": 0.2619324028491974, "Value Loss": 10.730742454528809, "_runtime": 1505.725673675537, "_timestamp": 1585510584.1464033, "_step": 136}
{"Episode reward": 39.999999999999424, "Episode length": 600, "Policy Loss": 1.02811598777771, "Value Loss": 16.587230682373047, "_runtime": 1507.2873439788818, "_timestamp": 1585510585.7080736, "_step": 137}
{"Episode reward": -99.82591148018697, "Episode length": 999, "Policy Loss": -0.5481334924697876, "Value Loss": 0.009140104986727238, "_runtime": 1508.8391406536102, "_timestamp": 1585510587.2598703, "_step": 138}
{"Episode reward": -99.86587684303382, "Episode length": 999, "Policy Loss": -0.5567975044250488, "Value Loss": 0.007618010509759188, "_runtime": 1510.25066614151, "_timestamp": 1585510588.6713958, "_step": 139}
{"Episode reward": 7.400000000000986, "Episode length": 926, "Policy Loss": 0.18210652470588684, "Value Loss": 10.76423168182373, "_runtime": 1510.9194638729095, "_timestamp": 1585510589.3401935, "_step": 140}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 1.1212984323501587, "Value Loss": 24.064624786376953, "_runtime": 1512.2794902324677, "_timestamp": 1585510590.7002199, "_step": 141}
{"Episode reward": 12.988618025091213, "Episode length": 871, "Policy Loss": 0.22845464944839478, "Value Loss": 11.367470741271973, "_runtime": 1513.8547801971436, "_timestamp": 1585510592.2755098, "_step": 142}
{"Episode reward": -99.80662079008621, "Episode length": 999, "Policy Loss": -0.613959789276123, "Value Loss": 0.11994016170501709, "_runtime": 1515.1565012931824, "_timestamp": 1585510593.577231, "_step": 143}
{"Episode reward": 13.728751934227219, "Episode length": 863, "Policy Loss": 0.21987338364124298, "Value Loss": 11.4486722946167, "_runtime": 1516.0095448493958, "_timestamp": 1585510594.4302745, "_step": 144}
{"Episode reward": 45.92993194227989, "Episode length": 541, "Policy Loss": 0.7220793962478638, "Value Loss": 18.221899032592773, "_runtime": 1516.3790216445923, "_timestamp": 1585510594.7997513, "_step": 145}
{"Episode reward": 79.09999999999998, "Episode length": 209, "Policy Loss": 2.693729877471924, "Value Loss": 46.946807861328125, "_runtime": 1517.908682346344, "_timestamp": 1585510596.329412, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6505199074745178, "Value Loss": 0.12781251966953278, "_runtime": 1519.129507780075, "_timestamp": 1585510597.5502374, "_step": 147}
{"Episode reward": 19.5000000000003, "Episode length": 805, "Policy Loss": 0.22152209281921387, "Value Loss": 12.249994277954102, "_runtime": 1520.385332584381, "_timestamp": 1585510598.8060622, "_step": 148}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": 0.12231937795877457, "Value Loss": 12.018071174621582, "_runtime": 1521.5002155303955, "_timestamp": 1585510599.9209452, "_step": 149}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.13860060274600983, "Value Loss": 13.670198440551758, "_runtime": 1523.0459620952606, "_timestamp": 1585510601.4666917, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8423515558242798, "Value Loss": 0.217772975564003, "_runtime": 1524.5740587711334, "_timestamp": 1585510602.9947884, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7761803865432739, "Value Loss": 0.04816308617591858, "_runtime": 1526.1097402572632, "_timestamp": 1585510604.53047, "_step": 152}
{"Episode reward": -99.72157856868441, "Episode length": 999, "Policy Loss": -0.7842804193496704, "Value Loss": 0.0946977287530899, "_runtime": 1527.6771318912506, "_timestamp": 1585510606.0978615, "_step": 153}
{"Episode reward": -99.7213546796688, "Episode length": 999, "Policy Loss": -0.7265359163284302, "Value Loss": 0.03188939765095711, "_runtime": 1529.2221763134003, "_timestamp": 1585510607.642906, "_step": 154}
{"Episode reward": -99.82915103584388, "Episode length": 999, "Policy Loss": -0.6835229992866516, "Value Loss": 0.014698428101837635, "_runtime": 1530.2296867370605, "_timestamp": 1585510608.6504164, "_step": 155}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 0.6669636964797974, "Value Loss": 15.749629020690918, "_runtime": 1531.7952337265015, "_timestamp": 1585510610.2159634, "_step": 156}
{"Episode reward": -99.88440679171914, "Episode length": 999, "Policy Loss": -0.6170892715454102, "Value Loss": 0.007438139524310827, "_runtime": 1533.3579423427582, "_timestamp": 1585510611.778672, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5805447101593018, "Value Loss": 0.007027446758002043, "_runtime": 1534.8913087844849, "_timestamp": 1585510613.3120384, "_step": 158}
{"Episode reward": -99.71849039830127, "Episode length": 999, "Policy Loss": -0.5418457984924316, "Value Loss": 0.005426764488220215, "_runtime": 1536.4896779060364, "_timestamp": 1585510614.9104075, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5216168165206909, "Value Loss": 0.005191487725824118, "_runtime": 1538.0366742610931, "_timestamp": 1585510616.457404, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49072760343551636, "Value Loss": 0.00746546033769846, "_runtime": 1539.6063272953033, "_timestamp": 1585510618.027057, "_step": 161}
{"Episode reward": -99.80011495509977, "Episode length": 999, "Policy Loss": -0.46235769987106323, "Value Loss": 0.00663404818624258, "_runtime": 1541.170808315277, "_timestamp": 1585510619.591538, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4392603933811188, "Value Loss": 0.012939319014549255, "_runtime": 1542.234346151352, "_timestamp": 1585510620.6550758, "_step": 163}
{"Episode reward": 32.399999999999565, "Episode length": 676, "Policy Loss": 0.6472819447517395, "Value Loss": 14.737804412841797, "_runtime": 1543.7917325496674, "_timestamp": 1585510622.2124622, "_step": 164}
{"Episode reward": -99.78298407681147, "Episode length": 999, "Policy Loss": -0.40150028467178345, "Value Loss": 0.009695802815258503, "_runtime": 1544.6259937286377, "_timestamp": 1585510623.0467234, "_step": 165}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 1.0216447114944458, "Value Loss": 19.102977752685547, "_runtime": 1546.0800216197968, "_timestamp": 1585510624.5007513, "_step": 166}
{"Episode reward": 5.800000000001077, "Episode length": 942, "Policy Loss": 0.501544713973999, "Value Loss": 10.558157920837402, "_runtime": 1547.651428937912, "_timestamp": 1585510626.0721586, "_step": 167}
{"Episode reward": -99.71337902108068, "Episode length": 999, "Policy Loss": -0.3494693636894226, "Value Loss": 0.035179536789655685, "_runtime": 1549.122501373291, "_timestamp": 1585510627.543231, "_step": 168}
{"Episode reward": 3.4883028819237865, "Episode length": 966, "Policy Loss": 0.3987998366355896, "Value Loss": 10.280726432800293, "_runtime": 1550.664962053299, "_timestamp": 1585510629.0856917, "_step": 169}
{"Episode reward": -99.72249236451323, "Episode length": 999, "Policy Loss": -0.3305583596229553, "Value Loss": 0.0913158506155014, "_runtime": 1551.954912662506, "_timestamp": 1585510630.3756423, "_step": 170}
{"Episode reward": 17.53673226833385, "Episode length": 825, "Policy Loss": 0.48369958996772766, "Value Loss": 12.183985710144043, "_runtime": 1553.5047054290771, "_timestamp": 1585510631.925435, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3443071246147156, "Value Loss": 0.008874090388417244, "_runtime": 1554.5463559627533, "_timestamp": 1585510632.9670856, "_step": 172}
{"Episode reward": 33.86721976241046, "Episode length": 662, "Policy Loss": 0.6729291677474976, "Value Loss": 15.011310577392578, "_runtime": 1556.0917885303497, "_timestamp": 1585510634.5125182, "_step": 173}
{"Episode reward": -99.78377097109194, "Episode length": 999, "Policy Loss": -0.3819260001182556, "Value Loss": 0.025519797578454018, "_runtime": 1557.0723502635956, "_timestamp": 1585510635.49308, "_step": 174}
{"Episode reward": 37.98862668415471, "Episode length": 621, "Policy Loss": 0.7182518839836121, "Value Loss": 15.989272117614746, "_runtime": 1558.613177537918, "_timestamp": 1585510637.0339072, "_step": 175}
{"Episode reward": -99.67219261722501, "Episode length": 999, "Policy Loss": -0.4228259027004242, "Value Loss": 0.016119113191962242, "_runtime": 1560.2068247795105, "_timestamp": 1585510638.6275544, "_step": 176}
{"Episode reward": -99.80923330420488, "Episode length": 999, "Policy Loss": -0.43287551403045654, "Value Loss": 0.010484883561730385, "_runtime": 1561.726927280426, "_timestamp": 1585510640.147657, "_step": 177}
{"Episode reward": -99.80962120443444, "Episode length": 999, "Policy Loss": -0.4455684423446655, "Value Loss": 0.01115196943283081, "_runtime": 1563.2905731201172, "_timestamp": 1585510641.7113028, "_step": 178}
{"Episode reward": -99.84897180581326, "Episode length": 999, "Policy Loss": -0.4501585066318512, "Value Loss": 0.009899213910102844, "_runtime": 1564.7806086540222, "_timestamp": 1585510643.2013383, "_step": 179}
{"Episode reward": 5.098573270068684, "Episode length": 950, "Policy Loss": 0.33462509512901306, "Value Loss": 10.481743812561035, "_runtime": 1566.335886001587, "_timestamp": 1585510644.7566156, "_step": 180}
{"Episode reward": -99.82087799424632, "Episode length": 999, "Policy Loss": -0.4648326635360718, "Value Loss": 0.006191867869347334, "_runtime": 1567.280466079712, "_timestamp": 1585510645.7011957, "_step": 181}
{"Episode reward": 39.49214777909161, "Episode length": 606, "Policy Loss": 0.6847379803657532, "Value Loss": 16.41778564453125, "_runtime": 1567.8188166618347, "_timestamp": 1585510646.2395463, "_step": 182}
{"Episode reward": 67.49999999999982, "Episode length": 325, "Policy Loss": 1.693306565284729, "Value Loss": 30.61278533935547, "_runtime": 1568.3240191936493, "_timestamp": 1585510646.7447488, "_step": 183}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 2.654480218887329, "Value Loss": 32.147090911865234, "_runtime": 1569.8320586681366, "_timestamp": 1585510648.2527883, "_step": 184}
{"Episode reward": -99.87678696848313, "Episode length": 999, "Policy Loss": -0.4467749297618866, "Value Loss": 0.01695277728140354, "_runtime": 1571.3291096687317, "_timestamp": 1585510649.7498393, "_step": 185}
{"Episode reward": -99.80898096710304, "Episode length": 999, "Policy Loss": -0.43534326553344727, "Value Loss": 0.027984730899333954, "_runtime": 1572.8124549388885, "_timestamp": 1585510651.2331846, "_step": 186}
{"Episode reward": -99.82344417907157, "Episode length": 999, "Policy Loss": -0.4183475375175476, "Value Loss": 0.024086885154247284, "_runtime": 1573.8368427753448, "_timestamp": 1585510652.2575724, "_step": 187}
{"Episode reward": 35.07836932539881, "Episode length": 650, "Policy Loss": 0.7399228811264038, "Value Loss": 15.167835235595703, "_runtime": 1575.3879284858704, "_timestamp": 1585510653.8086581, "_step": 188}
{"Episode reward": -99.88438997007766, "Episode length": 999, "Policy Loss": -0.3826243281364441, "Value Loss": 0.02647598646581173, "_runtime": 1576.9325156211853, "_timestamp": 1585510655.3532453, "_step": 189}
{"Episode reward": -99.6524758608998, "Episode length": 999, "Policy Loss": -0.37051406502723694, "Value Loss": 0.027115754783153534, "_runtime": 1577.854028224945, "_timestamp": 1585510656.2747579, "_step": 190}
{"Episode reward": 40.89172875881139, "Episode length": 592, "Policy Loss": 0.9142041802406311, "Value Loss": 16.55240821838379, "_runtime": 1579.40118765831, "_timestamp": 1585510657.8219173, "_step": 191}
{"Episode reward": -99.84528935104468, "Episode length": 999, "Policy Loss": -0.3660176992416382, "Value Loss": 0.3121750056743622, "_runtime": 1580.9632935523987, "_timestamp": 1585510659.3840232, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3532507121562958, "Value Loss": 0.02947872504591942, "_runtime": 1582.4920551776886, "_timestamp": 1585510660.9127848, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39797744154930115, "Value Loss": 0.06815806776285172, "_runtime": 1584.0726335048676, "_timestamp": 1585510662.4933631, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4194610118865967, "Value Loss": 0.10439928621053696, "_runtime": 1585.1971464157104, "_timestamp": 1585510663.617876, "_step": 195}
{"Episode reward": 28.794926232751237, "Episode length": 713, "Policy Loss": 0.45928698778152466, "Value Loss": 13.915118217468262, "_runtime": 1586.7498798370361, "_timestamp": 1585510665.1706095, "_step": 196}
{"Episode reward": -99.79623459325964, "Episode length": 999, "Policy Loss": -0.4355395436286926, "Value Loss": 0.016601204872131348, "_runtime": 1587.5368778705597, "_timestamp": 1585510665.9576075, "_step": 197}
{"Episode reward": 51.38548288603738, "Episode length": 489, "Policy Loss": 0.9314620494842529, "Value Loss": 20.27788543701172, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797, -0.008654283359646797]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-0.42587602138519287, -0.4190794825553894, -0.41228291392326355, -0.4054863750934601, -0.3986898362636566, -0.39189326763153076, -0.3850967288017273, -0.37830018997192383, -0.371503621339798, -0.3647070825099945, -0.35791051387786865, -0.3511139750480652, -0.3443174362182617, -0.33752086758613586, -0.3307243287563324, -0.32392776012420654, -0.3171312212944031, -0.3103346824645996, -0.30353814363479614, -0.2967415750026703, -0.2899450361728668, -0.28314846754074097, -0.2763519287109375, -0.26955538988113403, -0.26275885105133057, -0.2559622824192047, -0.24916572868824005, -0.24236918985843658, -0.23557263612747192, -0.22877608239650726, -0.2219795286655426, -0.21518298983573914, -0.20838643610477448, -0.20158988237380981, -0.19479334354400635, -0.1879967898130417, -0.18120023608207703, -0.17440369725227356, -0.1676071286201477, -0.16081058979034424, -0.15401405096054077, -0.14721748232841492, -0.14042094349861145, -0.13362440466880798, -0.12682783603668213, -0.12003129720687866, -0.11323472857475281, -0.10643818974494934, -0.09964165091514587, -0.09284508228302002, -0.08604854345321655, -0.07925200462341309, -0.07245543599128723, -0.06565889716148376, -0.0588623583316803, -0.05206578969955444, -0.04526925086975098, -0.03847271203994751, -0.031676143407821655, -0.02487960457801819, -0.018083035945892334, -0.011286497116088867, -0.0044899582862854, 0.002306610345840454, 0.009103149175643921]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.022687524557113647, -0.022237170487642288, -0.021786818280816078, -0.02133646421134472, -0.02088611200451851, -0.02043575793504715, -0.01998540572822094, -0.01953505165874958, -0.01908469945192337, -0.01863434538245201, -0.0181839931756258, -0.017733639106154442, -0.017283286899328232, -0.016832932829856873, -0.016382580623030663, -0.015932226553559303, -0.015481874346733093, -0.015031520277261734, -0.01458116713911295, -0.014130814000964165, -0.01368046086281538, -0.013230107724666595, -0.01277975458651781, -0.012329401448369026, -0.011879048310220242, -0.011428695172071457, -0.010978342033922672, -0.010527988895773888, -0.010077635757625103, -0.009627282619476318, -0.009176929481327534, -0.008726576343178749, -0.008276223205029964, -0.00782587006688118, -0.007375516928732395, -0.0069251637905836105, -0.006474809721112251, -0.006024457514286041, -0.005574103444814682, -0.005123751237988472, -0.004673397168517113, -0.004223044961690903, -0.0037726908922195435, -0.0033223386853933334, -0.002871984615921974, -0.002421632409095764, -0.001971278339624405, -0.0015209261327981949, -0.0010705720633268356, -0.0006202198565006256, -0.00016986578702926636, 0.00028048641979694366, 0.0007308404892683029, 0.001181192696094513, 0.0016315467655658722, 0.002081898972392082, 0.0025322530418634415, 0.0029826052486896515, 0.0034329593181610107, 0.0038833115249872208, 0.00433366559445858, 0.00478401780128479, 0.005234371870756149, 0.005684724077582359, 0.006135078147053719]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 5.0, 1.0, 2.0, 2.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 1.0, 6.0, 8.0, 6.0, 13.0, 15.0, 5.0, 217.0, 3.0, 11.0, 48.0, 36.0, 28.0, 12.0, 6.0, 13.0, 9.0, 5.0, 6.0, 5.0, 4.0], "bins": [-0.08058861643075943, -0.07898890972137451, -0.07738921046257019, -0.07578950375318527, -0.07418979704380035, -0.07259009778499603, -0.07099039107561111, -0.0693906843662262, -0.06779098510742188, -0.06619127839803696, -0.06459157168865204, -0.06299187242984772, -0.0613921657204628, -0.05979246273636818, -0.05819275975227356, -0.05659305304288864, -0.05499335005879402, -0.0533936470746994, -0.051793940365314484, -0.050194237381219864, -0.048594534397125244, -0.046994827687740326, -0.045395124703645706, -0.043795421719551086, -0.04219571501016617, -0.04059601202607155, -0.03899630904197693, -0.03739660605788231, -0.03579689934849739, -0.03419719636440277, -0.03259749338030815, -0.030997786670923233, -0.029398083686828613, -0.027798380702733994, -0.026198673993349075, -0.024598971009254456, -0.022999268025159836, -0.021399561315774918, -0.019799858331680298, -0.018200155347585678, -0.01660045236349106, -0.01500074565410614, -0.013401038944721222, -0.0118013396859169, -0.010201632976531982, -0.008601926267147064, -0.007002227008342743, -0.005402520298957825, -0.0038028135895729065, -0.002203114330768585, -0.000603407621383667, 0.0009962916374206543, 0.0025959983468055725, 0.004195705056190491, 0.005795404314994812, 0.00739511102437973, 0.008994817733764648, 0.01059451699256897, 0.012194223701953888, 0.013793930411338806, 0.015393629670143127, 0.016993336379528046, 0.018593043088912964, 0.020192742347717285, 0.021792449057102203]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2054755836725235, -0.20095902681350708, -0.19644248485565186, -0.19192592799663544, -0.1874093860387802, -0.1828928291797638, -0.17837628722190857, -0.17385973036289215, -0.16934317350387573, -0.1648266315460205, -0.1603100746870041, -0.15579351782798767, -0.15127697587013245, -0.14676041901111603, -0.1422438621520996, -0.13772732019424438, -0.13321077823638916, -0.12869422137737274, -0.12417767196893692, -0.1196611151099205, -0.11514456570148468, -0.11062801629304886, -0.10611146688461304, -0.10159491747617722, -0.0970783680677414, -0.09256181120872498, -0.08804526180028915, -0.08352871239185333, -0.07901215553283691, -0.07449561357498169, -0.06997905671596527, -0.06546251475811005, -0.06094595789909363, -0.05642940104007721, -0.051912859082221985, -0.047396302223205566, -0.04287976026535034, -0.03836320340633392, -0.033846646547317505, -0.02933010458946228, -0.024813547730445862, -0.020297005772590637, -0.01578044891357422, -0.0112638920545578, -0.006747350096702576, -0.0022307932376861572, 0.0022857487201690674, 0.006802305579185486, 0.01131884753704071, 0.01583540439605713, 0.020351961255073547, 0.024868503212928772, 0.02938506007194519, 0.033901602029800415, 0.038418158888816833, 0.04293471574783325, 0.04745127260684967, 0.051967814564704895, 0.05648435652256012, 0.06100092828273773, 0.06551747024059296, 0.07003401219844818, 0.0745505541563034, 0.07906712591648102, 0.08358366787433624]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 7.0, 13.0, 5.0, 6.0, 1.0, 5.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.04764172062277794, -0.04561232030391693, -0.04358292371034622, -0.04155352711677551, -0.039524126797914505, -0.0374947264790535, -0.03546532988548279, -0.03343593329191208, -0.03140653297305107, -0.029377134516835213, -0.027347736060619354, -0.025318337604403496, -0.023288939148187637, -0.02125954069197178, -0.01923014223575592, -0.017200743779540062, -0.015171345323324203, -0.013141948729753494, -0.011112548410892487, -0.009083148092031479, -0.00705375149846077, -0.00502435490489006, -0.0029949545860290527, -0.000965554267168045, 0.0010638423264026642, 0.0030932389199733734, 0.005122639238834381, 0.007152039557695389, 0.009181436151266098, 0.011210832744836807, 0.013240233063697815, 0.015269633382558823, 0.017299029976129532, 0.01932842656970024, 0.02135782316327095, 0.023387227207422256, 0.025416623800992966, 0.027446020394563675, 0.02947542443871498, 0.03150482103228569, 0.0335342176258564, 0.03556361421942711, 0.03759301081299782, 0.039622414857149124, 0.04165181145071983, 0.04368120804429054, 0.04571061208844185, 0.04774000868201256, 0.04976940527558327, 0.051798801869153976, 0.053828198462724686, 0.05585760250687599, 0.0578869991004467, 0.05991639569401741, 0.061945799738168716, 0.06397520005702972, 0.06600458920001984, 0.06803399324417114, 0.07006338238716125, 0.07209278643131256, 0.07412219047546387, 0.07615157961845398, 0.07818098366260529, 0.0802103728055954, 0.0822397768497467]}, "_runtime": 1589.0733778476715, "_timestamp": 1585510667.4941075, "_step": 198}
{"Episode reward": -99.80133211947837, "Episode length": 999, "Policy Loss": -0.4774228036403656, "Value Loss": 0.009768671356141567, "_runtime": 1590.6409652233124, "_timestamp": 1585510669.0616949, "_step": 199}
{"Episode reward": -99.72243430511887, "Episode length": 999, "Policy Loss": -0.4846816062927246, "Value Loss": 0.006074374541640282, "_runtime": 1591.6731638908386, "_timestamp": 1585510670.0938935, "_step": 200}
{"Episode reward": 32.3291804984906, "Episode length": 678, "Policy Loss": 0.6239268183708191, "Value Loss": 14.67652416229248, "_runtime": 1593.2238659858704, "_timestamp": 1585510671.6445956, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.517232358455658, "Value Loss": 0.009639261290431023, "_runtime": 1593.699959039688, "_timestamp": 1585510672.1206887, "_step": 202}
{"Episode reward": 71.45045847296701, "Episode length": 286, "Policy Loss": 1.9322261810302734, "Value Loss": 34.77470397949219, "_runtime": 1595.2332162857056, "_timestamp": 1585510673.653946, "_step": 203}
{"Episode reward": -99.74126012557979, "Episode length": 999, "Policy Loss": -0.5134120583534241, "Value Loss": 0.0075983889400959015, "_runtime": 1596.3638136386871, "_timestamp": 1585510674.7845433, "_step": 204}
{"Episode reward": 27.764992092549633, "Episode length": 723, "Policy Loss": 0.4519011378288269, "Value Loss": 13.762763023376465, "_runtime": 1597.252405166626, "_timestamp": 1585510675.6731348, "_step": 205}
{"Episode reward": 40.99999999999944, "Episode length": 590, "Policy Loss": 0.8026400208473206, "Value Loss": 16.85743522644043, "_runtime": 1598.8075330257416, "_timestamp": 1585510677.2282627, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5108453035354614, "Value Loss": 0.008157907985150814, "_runtime": 1600.3324012756348, "_timestamp": 1585510678.753131, "_step": 207}
{"Episode reward": -99.84120834404463, "Episode length": 999, "Policy Loss": -0.5053333640098572, "Value Loss": 0.005600947421044111, "_runtime": 1601.848722934723, "_timestamp": 1585510680.2694526, "_step": 208}
{"Episode reward": -99.80000253552431, "Episode length": 999, "Policy Loss": -0.5017696022987366, "Value Loss": 0.013844616711139679, "_runtime": 1603.406615972519, "_timestamp": 1585510681.8273456, "_step": 209}
{"Episode reward": -99.73412585938209, "Episode length": 999, "Policy Loss": -0.4961865246295929, "Value Loss": 0.013880621641874313, "_runtime": 1604.9777672290802, "_timestamp": 1585510683.3984969, "_step": 210}
{"Episode reward": -99.83227986553545, "Episode length": 999, "Policy Loss": -0.49414563179016113, "Value Loss": 0.006379237398505211, "_runtime": 1606.5344822406769, "_timestamp": 1585510684.9552119, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4966251850128174, "Value Loss": 0.01767495460808277, "_runtime": 1608.144867181778, "_timestamp": 1585510686.5655968, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49605792760849, "Value Loss": 0.035696469247341156, "_runtime": 1609.7069399356842, "_timestamp": 1585510688.1276696, "_step": 213}
{"Episode reward": -99.8227119423435, "Episode length": 999, "Policy Loss": -0.49195313453674316, "Value Loss": 0.02819192223250866, "_runtime": 1611.2609114646912, "_timestamp": 1585510689.681641, "_step": 214}
{"Episode reward": -99.80529050538176, "Episode length": 999, "Policy Loss": -0.4871610403060913, "Value Loss": 0.024134943261742592, "_runtime": 1611.9031665325165, "_timestamp": 1585510690.3238962, "_step": 215}
{"Episode reward": 60.913687235768606, "Episode length": 391, "Policy Loss": 1.4052220582962036, "Value Loss": 25.33338165283203, "_runtime": 1613.4629271030426, "_timestamp": 1585510691.8836567, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48817771673202515, "Value Loss": 0.012822544202208519, "_runtime": 1615.0258293151855, "_timestamp": 1585510693.446559, "_step": 217}
{"Episode reward": -99.84193637519935, "Episode length": 999, "Policy Loss": -0.48228591680526733, "Value Loss": 0.006938670761883259, "_runtime": 1616.544605255127, "_timestamp": 1585510694.965335, "_step": 218}
{"Episode reward": -99.83031919235223, "Episode length": 999, "Policy Loss": -0.47468534111976624, "Value Loss": 0.015711965039372444, "_runtime": 1618.1132802963257, "_timestamp": 1585510696.53401, "_step": 219}
{"Episode reward": -99.63794567026059, "Episode length": 999, "Policy Loss": -0.4859464168548584, "Value Loss": 0.039534345269203186, "_runtime": 1619.3828511238098, "_timestamp": 1585510697.8035808, "_step": 220}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": 0.36274051666259766, "Value Loss": 12.178135871887207, "_runtime": 1620.9405703544617, "_timestamp": 1585510699.3613, "_step": 221}
{"Episode reward": -99.81176610588888, "Episode length": 999, "Policy Loss": -0.48634853959083557, "Value Loss": 0.03940851613879204, "_runtime": 1622.4922680854797, "_timestamp": 1585510700.9129977, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4754345715045929, "Value Loss": 0.02559569850564003, "_runtime": 1623.5225093364716, "_timestamp": 1585510701.943239, "_step": 223}
{"Episode reward": 34.09897284051351, "Episode length": 660, "Policy Loss": 1.1061216592788696, "Value Loss": 14.966201782226562, "_runtime": 1624.979318857193, "_timestamp": 1585510703.4000485, "_step": 224}
{"Episode reward": 6.749833594170482, "Episode length": 933, "Policy Loss": 0.2395784556865692, "Value Loss": 10.634025573730469, "_runtime": 1626.553922176361, "_timestamp": 1585510704.9746518, "_step": 225}
{"Episode reward": -99.7583853442208, "Episode length": 999, "Policy Loss": -0.48918429017066956, "Value Loss": 0.025141607969999313, "_runtime": 1628.0796291828156, "_timestamp": 1585510706.5003588, "_step": 226}
{"Episode reward": -99.79687029989297, "Episode length": 999, "Policy Loss": -0.5029938220977783, "Value Loss": 0.08660496026277542, "_runtime": 1629.6399891376495, "_timestamp": 1585510708.0607188, "_step": 227}
{"Episode reward": -99.56902483936726, "Episode length": 999, "Policy Loss": -0.48385998606681824, "Value Loss": 0.03624683991074562, "_runtime": 1631.2382159233093, "_timestamp": 1585510709.6589456, "_step": 228}
{"Episode reward": -99.69921962553497, "Episode length": 999, "Policy Loss": -0.47640907764434814, "Value Loss": 0.005826083477586508, "_runtime": 1632.4064490795135, "_timestamp": 1585510710.8271787, "_step": 229}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 0.42599183320999146, "Value Loss": 13.282535552978516, "_runtime": 1633.6165778636932, "_timestamp": 1585510712.0373075, "_step": 230}
{"Episode reward": 22.789845290407655, "Episode length": 773, "Policy Loss": 0.5339851975440979, "Value Loss": 12.803060531616211, "_runtime": 1635.1877765655518, "_timestamp": 1585510713.6085062, "_step": 231}
{"Episode reward": -99.79381571085985, "Episode length": 999, "Policy Loss": -0.4981042742729187, "Value Loss": 0.01939532905817032, "_runtime": 1636.4804751873016, "_timestamp": 1585510714.9012048, "_step": 232}
{"Episode reward": 16.600000000000463, "Episode length": 834, "Policy Loss": 0.38357749581336975, "Value Loss": 11.853376388549805, "_runtime": 1638.0174236297607, "_timestamp": 1585510716.4381533, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4898741543292999, "Value Loss": 0.014036468230187893, "_runtime": 1639.5872945785522, "_timestamp": 1585510718.0080242, "_step": 234}
{"Episode reward": -99.65292398445169, "Episode length": 999, "Policy Loss": -0.48489636182785034, "Value Loss": 0.011388730257749557, "_runtime": 1640.5462255477905, "_timestamp": 1585510718.9669552, "_step": 235}
{"Episode reward": 38.89576796954439, "Episode length": 612, "Policy Loss": 0.6578735709190369, "Value Loss": 16.126991271972656, "_runtime": 1642.0948832035065, "_timestamp": 1585510720.5156128, "_step": 236}
{"Episode reward": -99.81701109344, "Episode length": 999, "Policy Loss": -0.48023301362991333, "Value Loss": 0.029442088678479195, "_runtime": 1643.0745031833649, "_timestamp": 1585510721.4952328, "_step": 237}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 0.781494677066803, "Value Loss": 15.995095252990723, "_runtime": 1643.8942363262177, "_timestamp": 1585510722.314966, "_step": 238}
{"Episode reward": 47.330575714818664, "Episode length": 528, "Policy Loss": 0.821272075176239, "Value Loss": 18.607736587524414, "_runtime": 1644.369916677475, "_timestamp": 1585510722.7906463, "_step": 239}
{"Episode reward": 71.89399195639405, "Episode length": 283, "Policy Loss": 2.056729316711426, "Value Loss": 34.350242614746094, "_runtime": 1645.5861489772797, "_timestamp": 1585510724.0068786, "_step": 240}
{"Episode reward": 19.400000000000304, "Episode length": 806, "Policy Loss": 0.4174407422542572, "Value Loss": 12.116945266723633, "_runtime": 1647.0996973514557, "_timestamp": 1585510725.520427, "_step": 241}
{"Episode reward": -99.80285528311366, "Episode length": 999, "Policy Loss": -0.4926849901676178, "Value Loss": 0.5029463171958923, "_runtime": 1648.5901560783386, "_timestamp": 1585510727.0108857, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5294897556304932, "Value Loss": 0.6816535592079163, "_runtime": 1650.128569841385, "_timestamp": 1585510728.5492995, "_step": 243}
{"Episode reward": -99.74636905612284, "Episode length": 999, "Policy Loss": -0.46781256794929504, "Value Loss": 0.043124858289957047, "_runtime": 1651.6868007183075, "_timestamp": 1585510730.1075304, "_step": 244}
{"Episode reward": -99.71559962490434, "Episode length": 999, "Policy Loss": -0.5143526196479797, "Value Loss": 0.0714515820145607, "_runtime": 1653.2279267311096, "_timestamp": 1585510731.6486564, "_step": 245}
{"Episode reward": -99.8789141171598, "Episode length": 999, "Policy Loss": -0.5047639012336731, "Value Loss": 0.03975917026400566, "_runtime": 1653.7778165340424, "_timestamp": 1585510732.1985462, "_step": 246}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 1.9457638263702393, "Value Loss": 32.1394157409668, "_runtime": 1655.238261938095, "_timestamp": 1585510733.6589916, "_step": 247}
{"Episode reward": 6.10000000000106, "Episode length": 939, "Policy Loss": 0.2807086110115051, "Value Loss": 10.432318687438965, "_runtime": 1656.793176651001, "_timestamp": 1585510735.2139063, "_step": 248}
{"Episode reward": -99.7641344790333, "Episode length": 999, "Policy Loss": -0.5639177560806274, "Value Loss": 0.03454310819506645, "_runtime": 1657.520141363144, "_timestamp": 1585510735.940871, "_step": 249}
{"Episode reward": 51.99778574556072, "Episode length": 481, "Policy Loss": 1.0833096504211426, "Value Loss": 20.418724060058594, "_runtime": 1658.1915397644043, "_timestamp": 1585510736.6122694, "_step": 250}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.038571834564209, "Value Loss": 23.490726470947266, "_runtime": 1658.5845007896423, "_timestamp": 1585510737.0052304, "_step": 251}
{"Episode reward": 77.4996498486958, "Episode length": 226, "Policy Loss": 2.5432305335998535, "Value Loss": 43.28506088256836, "_runtime": 1659.1784796714783, "_timestamp": 1585510737.5992093, "_step": 252}
{"Episode reward": 60.87511052582385, "Episode length": 394, "Policy Loss": 1.6287462711334229, "Value Loss": 24.723003387451172, "_runtime": 1660.665431022644, "_timestamp": 1585510739.0861607, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4909965991973877, "Value Loss": 0.015713784843683243, "_runtime": 1662.022922039032, "_timestamp": 1585510740.4436517, "_step": 254}
{"Episode reward": 8.20000000000094, "Episode length": 918, "Policy Loss": 0.38710853457450867, "Value Loss": 10.721365928649902, "_runtime": 1662.5183029174805, "_timestamp": 1585510740.9390326, "_step": 255}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 1.4827113151550293, "Value Loss": 30.666805267333984, "_runtime": 1664.040284395218, "_timestamp": 1585510742.461014, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3824773132801056, "Value Loss": 0.1431412249803543, "_runtime": 1665.0769493579865, "_timestamp": 1585510743.497679, "_step": 257}
{"Episode reward": 32.68559078460049, "Episode length": 674, "Policy Loss": 0.7866383194923401, "Value Loss": 14.432647705078125, "_runtime": 1665.6402089595795, "_timestamp": 1585510744.0609386, "_step": 258}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 1.5660878419876099, "Value Loss": 25.870235443115234, "_runtime": 1667.1648585796356, "_timestamp": 1585510745.5855882, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3643733561038971, "Value Loss": 0.018656983971595764, "_runtime": 1668.6814954280853, "_timestamp": 1585510747.102225, "_step": 260}
{"Episode reward": -99.7417068630443, "Episode length": 999, "Policy Loss": -0.352756530046463, "Value Loss": 0.0059975567273795605, "_runtime": 1670.1781606674194, "_timestamp": 1585510748.5988903, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34687677025794983, "Value Loss": 0.014608359895646572, "_runtime": 1671.4678206443787, "_timestamp": 1585510749.8885503, "_step": 262}
{"Episode reward": 16.400000000000475, "Episode length": 836, "Policy Loss": 0.5464649200439453, "Value Loss": 11.803651809692383, "_runtime": 1672.5045042037964, "_timestamp": 1585510750.9252338, "_step": 263}
{"Episode reward": 33.799999999999486, "Episode length": 662, "Policy Loss": 0.8990695476531982, "Value Loss": 14.888943672180176, "_runtime": 1674.0396676063538, "_timestamp": 1585510752.4603972, "_step": 264}
{"Episode reward": -99.8299706795239, "Episode length": 999, "Policy Loss": -0.3539898991584778, "Value Loss": 0.015153451822698116, "_runtime": 1675.599309682846, "_timestamp": 1585510754.0200393, "_step": 265}
{"Episode reward": -99.8128909223699, "Episode length": 999, "Policy Loss": -0.3663168251514435, "Value Loss": 0.011516092345118523, "_runtime": 1676.3239574432373, "_timestamp": 1585510754.744687, "_step": 266}
{"Episode reward": 53.16228466610735, "Episode length": 469, "Policy Loss": 1.0666149854660034, "Value Loss": 20.829559326171875, "_runtime": 1677.8632073402405, "_timestamp": 1585510756.283937, "_step": 267}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.30765077471733093, "Value Loss": 10.014655113220215, "_runtime": 1679.417298078537, "_timestamp": 1585510757.8380277, "_step": 268}
{"Episode reward": -99.71487166751037, "Episode length": 999, "Policy Loss": -0.44989463686943054, "Value Loss": 0.016446614637970924, "_runtime": 1680.9289951324463, "_timestamp": 1585510759.3497248, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4688737988471985, "Value Loss": 0.00570514565333724, "_runtime": 1682.2145431041718, "_timestamp": 1585510760.6352727, "_step": 270}
{"Episode reward": 16.998792432691417, "Episode length": 833, "Policy Loss": 0.26899829506874084, "Value Loss": 11.48051929473877, "_runtime": 1683.6513049602509, "_timestamp": 1585510762.0720346, "_step": 271}
{"Episode reward": 7.7801723956140165, "Episode length": 923, "Policy Loss": 0.24130728840827942, "Value Loss": 10.664773941040039, "_runtime": 1684.7111072540283, "_timestamp": 1585510763.131837, "_step": 272}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": 0.3474658131599426, "Value Loss": 14.281902313232422, "_runtime": 1686.2591798305511, "_timestamp": 1585510764.6799095, "_step": 273}
{"Episode reward": -99.80031393915274, "Episode length": 999, "Policy Loss": -0.5411397218704224, "Value Loss": 0.03508128598332405, "_runtime": 1687.7982878684998, "_timestamp": 1585510766.2190175, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5311808586120605, "Value Loss": 0.008693975396454334, "_runtime": 1689.330139875412, "_timestamp": 1585510767.7508695, "_step": 275}
{"Episode reward": -99.84196800142387, "Episode length": 999, "Policy Loss": -0.5249484181404114, "Value Loss": 0.012047185562551022, "_runtime": 1690.8849806785583, "_timestamp": 1585510769.3057103, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5287733674049377, "Value Loss": 0.027463100850582123, "_runtime": 1692.4457521438599, "_timestamp": 1585510770.8664818, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5203843116760254, "Value Loss": 0.005358667112886906, "_runtime": 1693.355898141861, "_timestamp": 1585510771.7766278, "_step": 278}
{"Episode reward": 42.39999999999946, "Episode length": 576, "Policy Loss": 0.6326186060905457, "Value Loss": 16.635723114013672, "_runtime": 1694.9159035682678, "_timestamp": 1585510773.3366332, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5151070952415466, "Value Loss": 0.006852966733276844, "_runtime": 1695.4992356300354, "_timestamp": 1585510773.9199653, "_step": 280}
{"Episode reward": 64.79999999999978, "Episode length": 352, "Policy Loss": 1.3985955715179443, "Value Loss": 26.871227264404297, "_runtime": 1696.4468870162964, "_timestamp": 1585510774.8676167, "_step": 281}
{"Episode reward": 37.89640496736332, "Episode length": 622, "Policy Loss": 0.5307566523551941, "Value Loss": 15.470766067504883, "_runtime": 1697.5006992816925, "_timestamp": 1585510775.921429, "_step": 282}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.3884475827217102, "Value Loss": 13.96378231048584, "_runtime": 1698.9889779090881, "_timestamp": 1585510777.4097075, "_step": 283}
{"Episode reward": -99.80965151935676, "Episode length": 999, "Policy Loss": -0.566098690032959, "Value Loss": 0.07001683115959167, "_runtime": 1700.5155234336853, "_timestamp": 1585510778.936253, "_step": 284}
{"Episode reward": -99.80172579008946, "Episode length": 999, "Policy Loss": -0.5879822969436646, "Value Loss": 0.037712957710027695, "_runtime": 1702.0775685310364, "_timestamp": 1585510780.4982982, "_step": 285}
{"Episode reward": -99.73885020315508, "Episode length": 999, "Policy Loss": -0.5798353552818298, "Value Loss": 0.01398547925055027, "_runtime": 1702.9554696083069, "_timestamp": 1585510781.3761992, "_step": 286}
{"Episode reward": 44.09996557235666, "Episode length": 560, "Policy Loss": 0.4368983805179596, "Value Loss": 17.0560302734375, "_runtime": 1704.5138165950775, "_timestamp": 1585510782.9345462, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5888345241546631, "Value Loss": 0.014268433675169945, "_runtime": 1706.0665879249573, "_timestamp": 1585510784.4873176, "_step": 288}
{"Episode reward": -99.83585074096779, "Episode length": 999, "Policy Loss": -0.5937197804450989, "Value Loss": 0.011864503845572472, "_runtime": 1707.3641238212585, "_timestamp": 1585510785.7848535, "_step": 289}
{"Episode reward": 14.500000000000583, "Episode length": 855, "Policy Loss": 0.12882360816001892, "Value Loss": 11.659085273742676, "_runtime": 1708.402601480484, "_timestamp": 1585510786.823331, "_step": 290}
{"Episode reward": 33.116136258840086, "Episode length": 669, "Policy Loss": 0.5128457546234131, "Value Loss": 14.028056144714355, "_runtime": 1709.5385525226593, "_timestamp": 1585510787.9592822, "_step": 291}
{"Episode reward": 27.70367702506465, "Episode length": 725, "Policy Loss": 0.3705398142337799, "Value Loss": 13.274629592895508, "_runtime": 1710.2739317417145, "_timestamp": 1585510788.6946614, "_step": 292}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.0404614210128784, "Value Loss": 20.195688247680664, "_runtime": 1711.7968122959137, "_timestamp": 1585510790.217542, "_step": 293}
{"Episode reward": -99.81920476555685, "Episode length": 999, "Policy Loss": -0.5298892259597778, "Value Loss": 0.024749955162405968, "_runtime": 1712.5989832878113, "_timestamp": 1585510791.019713, "_step": 294}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 0.7512094378471375, "Value Loss": 18.735868453979492, "_runtime": 1712.970587015152, "_timestamp": 1585510791.3913167, "_step": 295}
{"Episode reward": 76.09999999999994, "Episode length": 239, "Policy Loss": 2.2732126712799072, "Value Loss": 39.73358917236328, "_runtime": 1713.6129505634308, "_timestamp": 1585510792.0336802, "_step": 296}
{"Episode reward": 59.1999999999997, "Episode length": 408, "Policy Loss": 0.9455081224441528, "Value Loss": 23.345869064331055, "_runtime": 1715.1192996501923, "_timestamp": 1585510793.5400293, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6968823075294495, "Value Loss": 0.01969411037862301, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788, 0.23216834664344788]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.37051284313201904, -0.2396201491355896, -0.10872745513916016, 0.022165238857269287, 0.15305793285369873, 0.2839506268501282, 0.4148433208465576, 0.5457360148429871, 0.6766287088394165, 0.8075214624404907, 0.9384140968322754, 1.06930673122406, 1.2001994848251343, 1.3310922384262085, 1.4619848728179932, 1.5928775072097778, 1.723770260810852, 1.8546630144119263, 1.9855557680130005, 2.116448402404785, 2.2473411560058594, 2.3782339096069336, 2.5091261863708496, 2.640018939971924, 2.770911693572998, 2.9018044471740723, 3.0326972007751465, 3.1635899543762207, 3.294482707977295, 3.425375461578369, 3.556267738342285, 3.6871604919433594, 3.8180532455444336, 3.948945999145508, 4.079838752746582, 4.210731506347656, 4.3416242599487305, 4.4725165367126465, 4.603409290313721, 4.734302043914795, 4.865194797515869, 4.996087551116943, 5.126980304718018, 5.257873058319092, 5.388765335083008, 5.519658088684082, 5.650550842285156, 5.7814435958862305, 5.912336349487305, 6.043229103088379, 6.174121856689453, 6.305014610290527, 6.435907363891602, 6.566799640655518, 6.697692394256592, 6.828585147857666, 6.95947790145874, 7.0903706550598145, 7.221263408660889, 7.352156162261963, 7.483048439025879, 7.613941192626953, 7.744833946228027, 7.875726699829102, 8.006619453430176]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.1630111187696457, -0.15149368345737457, -0.13997623324394226, -0.12845879793167114, -0.11694134771823883, -0.10542391240596771, -0.093906469643116, -0.08238902688026428, -0.07087158411741257, -0.05935414135456085, -0.04783669859170914, -0.03631925582885742, -0.024801820516586304, -0.013284370303153992, -0.0017669349908828735, 0.009750515222549438, 0.021267950534820557, 0.032785385847091675, 0.04430283606052399, 0.055820271372795105, 0.06733772158622742, 0.07885515689849854, 0.09037260711193085, 0.10189004242420197, 0.11340747773647308, 0.1249249130487442, 0.1364423781633377, 0.14795981347560883, 0.15947724878787994, 0.17099468410015106, 0.18251214921474457, 0.19402958452701569, 0.2055470198392868, 0.21706445515155792, 0.22858189046382904, 0.24009935557842255, 0.25161677598953247, 0.263134241104126, 0.2746516466140747, 0.2861691117286682, 0.2976865768432617, 0.30920398235321045, 0.32072144746780396, 0.3322388529777527, 0.3437563180923462, 0.3552737236022949, 0.3667911887168884, 0.37830865383148193, 0.38982605934143066, 0.40134352445602417, 0.4128609299659729, 0.4243783950805664, 0.4358958601951599, 0.44741326570510864, 0.45893073081970215, 0.47044819593429565, 0.4819656014442444, 0.4934830665588379, 0.5050004720687866, 0.5165179371833801, 0.5280354022979736, 0.5395528078079224, 0.5510702729225159, 0.5625876784324646, 0.5741051435470581]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [7.0, 1.0, 4.0, 5.0, 7.0, 3.0, 7.0, 7.0, 12.0, 26.0, 27.0, 28.0, 18.0, 30.0, 175.0, 16.0, 13.0, 8.0, 9.0, 11.0, 10.0, 7.0, 4.0, 6.0, 4.0, 3.0, 6.0, 9.0, 11.0, 5.0, 7.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.5585915446281433, -0.5191246867179871, -0.4796577990055084, -0.4401909112930298, -0.40072405338287354, -0.3612571656703949, -0.32179027795791626, -0.28232342004776, -0.24285653233528137, -0.20338964462280273, -0.16392278671264648, -0.12445589900016785, -0.08498901128768921, -0.04552215337753296, -0.006055295467376709, 0.033411622047424316, 0.07287847995758057, 0.11234533786773682, 0.15181225538253784, 0.1912791132926941, 0.23074597120285034, 0.27021288871765137, 0.3096797466278076, 0.34914660453796387, 0.3886135220527649, 0.42808037996292114, 0.4675472378730774, 0.5070140957832336, 0.5464809536933899, 0.5859479308128357, 0.6254147887229919, 0.6648816466331482, 0.7043485045433044, 0.7438153624534607, 0.7832822203636169, 0.8227490782737732, 0.862216055393219, 0.9016829133033752, 0.9411497712135315, 0.9806166291236877, 1.0200834274291992, 1.0595502853393555, 1.0990173816680908, 1.138484239578247, 1.1779510974884033, 1.2174179553985596, 1.2568848133087158, 1.296351671218872, 1.3358185291290283, 1.3752853870391846, 1.4147522449493408, 1.454219102859497, 1.4936859607696533, 1.5331528186798096, 1.5726196765899658, 1.612086534500122, 1.6515533924102783, 1.6910202503204346, 1.73048734664917, 1.7699542045593262, 1.8094210624694824, 1.8488879203796387, 1.888354778289795, 1.9278216361999512, 1.9672884941101074]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.8724446296691895, -1.76533842086792, -1.6582322120666504, -1.5511260032653809, -1.4440199136734009, -1.3369137048721313, -1.2298074960708618, -1.1227014064788818, -1.0155951976776123, -0.908488929271698, -0.8013827800750732, -0.6942765712738037, -0.5871703624725342, -0.48006415367126465, -0.37295806407928467, -0.26585185527801514, -0.1587456464767456, -0.051639437675476074, 0.05546677112579346, 0.16257286071777344, 0.26967906951904297, 0.3767852783203125, 0.48389148712158203, 0.5909976959228516, 0.6981039047241211, 0.8052101135253906, 0.9123163223266602, 1.0194222927093506, 1.1265285015106201, 1.2336347103118896, 1.3407409191131592, 1.4478471279144287, 1.5549533367156982, 1.6620595455169678, 1.7691657543182373, 1.8762719631195068, 1.9833781719207764, 2.090484380722046, 2.1975903511047363, 2.304696559906006, 2.4118027687072754, 2.518908977508545, 2.6260151863098145, 2.733121395111084, 2.8402276039123535, 2.947333812713623, 3.0544400215148926, 3.161546230316162, 3.2686524391174316, 3.375758647918701, 3.4828648567199707, 3.5899710655212402, 3.6970772743225098, 3.8041834831237793, 3.9112892150878906, 4.01839542388916, 4.12550163269043, 4.232607841491699, 4.339714050292969, 4.446820259094238, 4.553926467895508, 4.661032676696777, 4.768138885498047, 4.875245094299316, 4.982351303100586]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 10.0, 8.0, 5.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.8795703649520874, -1.8029944896697998, -1.7264186143875122, -1.6498427391052246, -1.5732669830322266, -1.4966909885406494, -1.4201152324676514, -1.3435393571853638, -1.2669634819030762, -1.1903876066207886, -1.113811731338501, -1.037235975265503, -0.9606600403785706, -0.884084165096283, -0.8075083494186401, -0.7309324741363525, -0.6543565988540649, -0.5777807235717773, -0.5012048482894897, -0.42462897300720215, -0.34805309772491455, -0.2714773416519165, -0.1949014663696289, -0.11832559108734131, -0.04174971580505371, 0.03482615947723389, 0.11140203475952148, 0.18797791004180908, 0.26455366611480713, 0.3411296606063843, 0.4177054166793823, 0.4942814111709595, 0.5708571672439575, 0.6474329233169556, 0.7240089178085327, 0.8005846738815308, 0.8771606683731079, 0.953736424446106, 1.030312418937683, 1.1068881750106812, 1.1834641695022583, 1.2600399255752563, 1.3366156816482544, 1.4131916761398315, 1.4897674322128296, 1.5663434267044067, 1.6429191827774048, 1.719495177268982, 1.79607093334198, 1.872646689414978, 1.9492226839065552, 2.0257983207702637, 2.10237455368042, 2.178950309753418, 2.255526065826416, 2.332101821899414, 2.408677577972412, 2.48525333404541, 2.5618295669555664, 2.6384053230285645, 2.7149810791015625, 2.7915568351745605, 2.868133068084717, 2.944708824157715, 3.021284580230713]}, "_runtime": 1716.1985223293304, "_timestamp": 1585510794.619252, "_step": 298}
{"Episode reward": 26.899999999999878, "Episode length": 731, "Policy Loss": 0.02907053381204605, "Value Loss": 12.598499298095703, "_runtime": 1717.6892297267914, "_timestamp": 1585510796.1099594, "_step": 299}
{"Episode reward": -99.71850327709551, "Episode length": 999, "Policy Loss": -0.7958974242210388, "Value Loss": 0.012655344791710377, "_runtime": 1719.2225511074066, "_timestamp": 1585510797.6432807, "_step": 300}
{"Episode reward": -99.80075646675984, "Episode length": 999, "Policy Loss": -0.8136304020881653, "Value Loss": 0.01227225549519062, "_runtime": 1720.7293367385864, "_timestamp": 1585510799.1500664, "_step": 301}
{"Episode reward": -99.8228072703802, "Episode length": 999, "Policy Loss": -0.8086786866188049, "Value Loss": 0.011923105455935001, "_runtime": 1722.12850522995, "_timestamp": 1585510800.5492349, "_step": 302}
{"Episode reward": 9.700000000000855, "Episode length": 903, "Policy Loss": -0.06990670412778854, "Value Loss": 10.39421558380127, "_runtime": 1722.6309697628021, "_timestamp": 1585510801.0516994, "_step": 303}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 1.3411017656326294, "Value Loss": 30.98741912841797, "_runtime": 1723.471485376358, "_timestamp": 1585510801.892215, "_step": 304}
{"Episode reward": 45.42370396908323, "Episode length": 547, "Policy Loss": 0.39712730050086975, "Value Loss": 16.360095977783203, "_runtime": 1724.111188173294, "_timestamp": 1585510802.5319178, "_step": 305}
{"Episode reward": 59.80939944051177, "Episode length": 402, "Policy Loss": 0.737198531627655, "Value Loss": 22.92544937133789, "_runtime": 1725.0594201087952, "_timestamp": 1585510803.4801497, "_step": 306}
{"Episode reward": 35.18886989206017, "Episode length": 649, "Policy Loss": 0.6378189325332642, "Value Loss": 14.337726593017578, "_runtime": 1726.555621623993, "_timestamp": 1585510804.9763513, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.835990309715271, "Value Loss": 0.012793570756912231, "_runtime": 1727.4399478435516, "_timestamp": 1585510805.8606775, "_step": 308}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 0.30508455634117126, "Value Loss": 16.28510284423828, "_runtime": 1728.934050321579, "_timestamp": 1585510807.35478, "_step": 309}
{"Episode reward": -99.871852111815, "Episode length": 999, "Policy Loss": -0.8549410700798035, "Value Loss": 0.013133164495229721, "_runtime": 1730.464920282364, "_timestamp": 1585510808.88565, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8609440326690674, "Value Loss": 0.013267678208649158, "_runtime": 1731.6607418060303, "_timestamp": 1585510810.0814714, "_step": 311}
{"Episode reward": 20.799898102507214, "Episode length": 793, "Policy Loss": -0.2900010049343109, "Value Loss": 13.715254783630371, "_runtime": 1733.1978826522827, "_timestamp": 1585510811.6186123, "_step": 312}
{"Episode reward": -99.71836538705836, "Episode length": 999, "Policy Loss": -0.8594739437103271, "Value Loss": 0.013271491043269634, "_runtime": 1734.746978521347, "_timestamp": 1585510813.1677082, "_step": 313}
{"Episode reward": -99.81427616560691, "Episode length": 999, "Policy Loss": -0.8619982004165649, "Value Loss": 0.013198048807680607, "_runtime": 1736.2717623710632, "_timestamp": 1585510814.692492, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8453250527381897, "Value Loss": 0.01309391763061285, "_runtime": 1736.9747467041016, "_timestamp": 1585510815.3954763, "_step": 315}
{"Episode reward": 55.89988317489589, "Episode length": 442, "Policy Loss": 0.7576006650924683, "Value Loss": 22.585912704467773, "_runtime": 1738.5135009288788, "_timestamp": 1585510816.9342306, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8436908721923828, "Value Loss": 0.01286038476973772, "_runtime": 1740.0648605823517, "_timestamp": 1585510818.4855902, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8458914756774902, "Value Loss": 0.012741409242153168, "_runtime": 1741.551650762558, "_timestamp": 1585510819.9723804, "_step": 318}
{"Episode reward": -99.72419554053201, "Episode length": 999, "Policy Loss": -0.8334634900093079, "Value Loss": 0.012573099695146084, "_runtime": 1743.0987839698792, "_timestamp": 1585510821.5195136, "_step": 319}
{"Episode reward": -99.74341796133528, "Episode length": 999, "Policy Loss": -0.827224850654602, "Value Loss": 0.012409402057528496, "_runtime": 1744.6548850536346, "_timestamp": 1585510823.0756147, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.822340726852417, "Value Loss": 0.01224689930677414, "_runtime": 1745.7940957546234, "_timestamp": 1585510824.2148254, "_step": 321}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.1491149514913559, "Value Loss": 13.624561309814453, "_runtime": 1747.338794708252, "_timestamp": 1585510825.7595243, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8166459202766418, "Value Loss": 0.01187471766024828, "_runtime": 1748.8982219696045, "_timestamp": 1585510827.3189516, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8108835816383362, "Value Loss": 0.01168739516288042, "_runtime": 1750.2597410678864, "_timestamp": 1585510828.6804707, "_step": 324}
{"Episode reward": 13.182730915654176, "Episode length": 870, "Policy Loss": 0.05015036091208458, "Value Loss": 11.48097038269043, "_runtime": 1751.8040001392365, "_timestamp": 1585510830.2247298, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7949106097221375, "Value Loss": 0.011307304725050926, "_runtime": 1753.3636376857758, "_timestamp": 1585510831.7843673, "_step": 326}
{"Episode reward": -99.78952287705476, "Episode length": 999, "Policy Loss": -0.784340500831604, "Value Loss": 0.011101498268544674, "_runtime": 1754.3032484054565, "_timestamp": 1585510832.723978, "_step": 327}
{"Episode reward": 39.57555837035121, "Episode length": 605, "Policy Loss": 0.5825049877166748, "Value Loss": 16.504751205444336, "_runtime": 1755.8456683158875, "_timestamp": 1585510834.266398, "_step": 328}
{"Episode reward": -99.80430010491843, "Episode length": 999, "Policy Loss": -0.7748326063156128, "Value Loss": 0.010737298987805843, "_runtime": 1757.3919777870178, "_timestamp": 1585510835.8127074, "_step": 329}
{"Episode reward": -99.8542493746602, "Episode length": 999, "Policy Loss": -0.7584095001220703, "Value Loss": 0.010563379153609276, "_runtime": 1758.9072115421295, "_timestamp": 1585510837.3279412, "_step": 330}
{"Episode reward": -99.78400880740816, "Episode length": 999, "Policy Loss": -0.7589659094810486, "Value Loss": 0.010367474518716335, "_runtime": 1759.6505117416382, "_timestamp": 1585510838.0712414, "_step": 331}
{"Episode reward": 53.690215292200065, "Episode length": 464, "Policy Loss": 0.7863056659698486, "Value Loss": 21.517210006713867, "_runtime": 1761.1967859268188, "_timestamp": 1585510839.6175156, "_step": 332}
{"Episode reward": -99.74887724704901, "Episode length": 999, "Policy Loss": -0.7518319487571716, "Value Loss": 0.010020842775702477, "_runtime": 1762.1573753356934, "_timestamp": 1585510840.578105, "_step": 333}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": 0.6009291410446167, "Value Loss": 16.002336502075195, "_runtime": 1762.9031021595001, "_timestamp": 1585510841.3238318, "_step": 334}
{"Episode reward": 50.29999999999957, "Episode length": 497, "Policy Loss": 0.7200485467910767, "Value Loss": 20.0886287689209, "_runtime": 1763.695912361145, "_timestamp": 1585510842.116642, "_step": 335}
{"Episode reward": 49.899999999999565, "Episode length": 501, "Policy Loss": 0.7445763349533081, "Value Loss": 19.92716407775879, "_runtime": 1764.3162469863892, "_timestamp": 1585510842.7369766, "_step": 336}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 1.2062994241714478, "Value Loss": 24.952125549316406, "_runtime": 1765.160596370697, "_timestamp": 1585510843.581326, "_step": 337}
{"Episode reward": 43.32329561328463, "Episode length": 569, "Policy Loss": 0.5530403256416321, "Value Loss": 17.52840805053711, "_runtime": 1766.654615163803, "_timestamp": 1585510845.0753448, "_step": 338}
{"Episode reward": -99.84009603196616, "Episode length": 999, "Policy Loss": -0.7222871780395508, "Value Loss": 0.016715817153453827, "_runtime": 1768.143611907959, "_timestamp": 1585510846.5643415, "_step": 339}
{"Episode reward": -99.70523058529805, "Episode length": 999, "Policy Loss": -0.7118505239486694, "Value Loss": 0.019057301804423332, "_runtime": 1769.2550673484802, "_timestamp": 1585510847.675797, "_step": 340}
{"Episode reward": 26.28437293162561, "Episode length": 739, "Policy Loss": 0.28295987844467163, "Value Loss": 13.442307472229004, "_runtime": 1770.5012512207031, "_timestamp": 1585510848.9219809, "_step": 341}
{"Episode reward": 18.939039875939812, "Episode length": 813, "Policy Loss": 0.19236336648464203, "Value Loss": 12.206644058227539, "_runtime": 1772.0290610790253, "_timestamp": 1585510850.4497907, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6357213854789734, "Value Loss": 0.0622682124376297, "_runtime": 1773.54523563385, "_timestamp": 1585510851.9659653, "_step": 343}
{"Episode reward": -99.81376426303619, "Episode length": 999, "Policy Loss": -0.6270748972892761, "Value Loss": 0.09846435487270355, "_runtime": 1775.1194474697113, "_timestamp": 1585510853.540177, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6390628218650818, "Value Loss": 0.11239489167928696, "_runtime": 1776.659852027893, "_timestamp": 1585510855.0805817, "_step": 345}
{"Episode reward": -99.66739174900438, "Episode length": 999, "Policy Loss": -0.6454234719276428, "Value Loss": 0.013513895682990551, "_runtime": 1778.2065756320953, "_timestamp": 1585510856.6273053, "_step": 346}
{"Episode reward": -99.72646666057268, "Episode length": 999, "Policy Loss": -0.6957186460494995, "Value Loss": 0.008692220784723759, "_runtime": 1779.750986814499, "_timestamp": 1585510858.1717165, "_step": 347}
{"Episode reward": -99.83444322952862, "Episode length": 999, "Policy Loss": -0.7508076429367065, "Value Loss": 0.010765601880848408, "_runtime": 1781.2977721691132, "_timestamp": 1585510859.7185018, "_step": 348}
{"Episode reward": -99.80335052646556, "Episode length": 999, "Policy Loss": -0.8092311024665833, "Value Loss": 0.012283805757761002, "_runtime": 1782.8359680175781, "_timestamp": 1585510861.2566977, "_step": 349}
{"Episode reward": -99.88708566808934, "Episode length": 999, "Policy Loss": -0.8621450066566467, "Value Loss": 0.02006719820201397, "_runtime": 1783.382554769516, "_timestamp": 1585510861.8032844, "_step": 350}
{"Episode reward": 66.2999999999998, "Episode length": 337, "Policy Loss": 1.2981919050216675, "Value Loss": 29.75309181213379, "_runtime": 1784.0871512889862, "_timestamp": 1585510862.507881, "_step": 351}
{"Episode reward": 55.32006871700251, "Episode length": 447, "Policy Loss": 0.6907291412353516, "Value Loss": 22.309856414794922, "_runtime": 1785.0971710681915, "_timestamp": 1585510863.5179007, "_step": 352}
{"Episode reward": 33.96133322119661, "Episode length": 661, "Policy Loss": 0.25169506669044495, "Value Loss": 15.0109224319458, "_runtime": 1786.5719542503357, "_timestamp": 1585510864.992684, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9762356877326965, "Value Loss": 0.05692652240395546, "_runtime": 1788.0583808422089, "_timestamp": 1585510866.4791105, "_step": 354}
{"Episode reward": -99.85195889621833, "Episode length": 999, "Policy Loss": -0.9741104245185852, "Value Loss": 0.05764253810048103, "_runtime": 1789.3337895870209, "_timestamp": 1585510867.7545192, "_step": 355}
{"Episode reward": 15.395638928469808, "Episode length": 847, "Policy Loss": -0.09948588907718658, "Value Loss": 11.58570384979248, "_runtime": 1790.3330047130585, "_timestamp": 1585510868.7537344, "_step": 356}
{"Episode reward": 34.29999999999946, "Episode length": 657, "Policy Loss": 0.0721096321940422, "Value Loss": 14.865949630737305, "_runtime": 1791.0219750404358, "_timestamp": 1585510869.4427047, "_step": 357}
{"Episode reward": 55.78740971749613, "Episode length": 443, "Policy Loss": 0.6517041325569153, "Value Loss": 22.442459106445312, "_runtime": 1792.5342798233032, "_timestamp": 1585510870.9550095, "_step": 358}
{"Episode reward": -99.74043509969349, "Episode length": 999, "Policy Loss": -0.9794987440109253, "Value Loss": 0.11643006652593613, "_runtime": 1794.0375227928162, "_timestamp": 1585510872.4582524, "_step": 359}
{"Episode reward": -99.84078627833956, "Episode length": 999, "Policy Loss": -0.8587902188301086, "Value Loss": 0.08074402809143066, "_runtime": 1795.5348613262177, "_timestamp": 1585510873.955591, "_step": 360}
{"Episode reward": -99.71626559691364, "Episode length": 999, "Policy Loss": -0.7221873998641968, "Value Loss": 0.014638031832873821, "_runtime": 1797.1147739887238, "_timestamp": 1585510875.5355036, "_step": 361}
{"Episode reward": -99.84564740890498, "Episode length": 999, "Policy Loss": -0.579947292804718, "Value Loss": 0.017963146790862083, "_runtime": 1798.6534478664398, "_timestamp": 1585510877.0741775, "_step": 362}
{"Episode reward": -99.72839080700511, "Episode length": 999, "Policy Loss": -0.5012423992156982, "Value Loss": 0.013215185143053532, "_runtime": 1800.200272321701, "_timestamp": 1585510878.621002, "_step": 363}
{"Episode reward": -99.82421537982161, "Episode length": 999, "Policy Loss": -0.40836408734321594, "Value Loss": 0.04634186252951622, "_runtime": 1801.1638443470001, "_timestamp": 1585510879.584574, "_step": 364}
{"Episode reward": 37.999999999999396, "Episode length": 620, "Policy Loss": 0.8322713375091553, "Value Loss": 16.562223434448242, "_runtime": 1802.2923655509949, "_timestamp": 1585510880.7130952, "_step": 365}
{"Episode reward": 27.25475582024069, "Episode length": 728, "Policy Loss": 0.5817548632621765, "Value Loss": 13.878532409667969, "_runtime": 1803.8388652801514, "_timestamp": 1585510882.259595, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49193230271339417, "Value Loss": 0.009690423496067524, "_runtime": 1805.3573908805847, "_timestamp": 1585510883.7781205, "_step": 367}
{"Episode reward": -99.73504321696096, "Episode length": 999, "Policy Loss": -0.5313791632652283, "Value Loss": 0.009018202312290668, "_runtime": 1806.6017761230469, "_timestamp": 1585510885.0225058, "_step": 368}
{"Episode reward": 18.300000000000367, "Episode length": 817, "Policy Loss": 0.3657068610191345, "Value Loss": 12.161386489868164, "_runtime": 1808.1154742240906, "_timestamp": 1585510886.5362039, "_step": 369}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.11849278211593628, "Value Loss": 10.199259757995605, "_runtime": 1809.6559927463531, "_timestamp": 1585510888.0767224, "_step": 370}
{"Episode reward": -99.8879421309554, "Episode length": 999, "Policy Loss": -0.6009406447410583, "Value Loss": 0.012503559701144695, "_runtime": 1811.175616979599, "_timestamp": 1585510889.5963466, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6150176525115967, "Value Loss": 0.01505718007683754, "_runtime": 1811.8152439594269, "_timestamp": 1585510890.2359736, "_step": 372}
{"Episode reward": 60.39565700245993, "Episode length": 397, "Policy Loss": 1.2274419069290161, "Value Loss": 25.048542022705078, "_runtime": 1813.3576419353485, "_timestamp": 1585510891.7783716, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6117703914642334, "Value Loss": 0.12952345609664917, "_runtime": 1814.922388792038, "_timestamp": 1585510893.3431184, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6625213027000427, "Value Loss": 0.20859532058238983, "_runtime": 1815.5561516284943, "_timestamp": 1585510893.9768813, "_step": 375}
{"Episode reward": 58.95858373641937, "Episode length": 411, "Policy Loss": 1.0880577564239502, "Value Loss": 23.9866886138916, "_runtime": 1817.1167800426483, "_timestamp": 1585510895.5375097, "_step": 376}
{"Episode reward": -99.6595059673288, "Episode length": 999, "Policy Loss": -0.6478127241134644, "Value Loss": 0.07068151980638504, "_runtime": 1818.411612033844, "_timestamp": 1585510896.8323417, "_step": 377}
{"Episode reward": 17.319330350961962, "Episode length": 827, "Policy Loss": 0.24159078299999237, "Value Loss": 11.939737319946289, "_runtime": 1819.9189369678497, "_timestamp": 1585510898.3396666, "_step": 378}
{"Episode reward": -99.80482797622541, "Episode length": 999, "Policy Loss": -0.6174900531768799, "Value Loss": 0.007028536405414343, "_runtime": 1821.5223076343536, "_timestamp": 1585510899.9430373, "_step": 379}
{"Episode reward": -99.80001409286493, "Episode length": 999, "Policy Loss": -0.621998131275177, "Value Loss": 0.006950078532099724, "_runtime": 1823.0681052207947, "_timestamp": 1585510901.4888349, "_step": 380}
{"Episode reward": -99.76534123141178, "Episode length": 999, "Policy Loss": -0.6180216670036316, "Value Loss": 0.0069070435129106045, "_runtime": 1824.6157279014587, "_timestamp": 1585510903.0364575, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6195563077926636, "Value Loss": 0.006917560938745737, "_runtime": 1825.8369166851044, "_timestamp": 1585510904.2576463, "_step": 382}
{"Episode reward": 22.182609206345077, "Episode length": 779, "Policy Loss": 0.2923043370246887, "Value Loss": 12.650238990783691, "_runtime": 1827.404149055481, "_timestamp": 1585510905.8248787, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6172075867652893, "Value Loss": 0.006780312862247229, "_runtime": 1828.3240723609924, "_timestamp": 1585510906.744802, "_step": 384}
{"Episode reward": 41.69336270950679, "Episode length": 584, "Policy Loss": 0.6317789554595947, "Value Loss": 16.696908950805664, "_runtime": 1829.853172302246, "_timestamp": 1585510908.273902, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6348204612731934, "Value Loss": 0.03057388961315155, "_runtime": 1831.3229203224182, "_timestamp": 1585510909.74365, "_step": 386}
{"Episode reward": 6.069993824419683, "Episode length": 942, "Policy Loss": 0.08525612205266953, "Value Loss": 10.709877967834473, "_runtime": 1832.8471450805664, "_timestamp": 1585510911.2678747, "_step": 387}
{"Episode reward": -99.8001210346804, "Episode length": 999, "Policy Loss": -0.6071648001670837, "Value Loss": 0.006676065269857645, "_runtime": 1833.598534822464, "_timestamp": 1585510912.0192645, "_step": 388}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.0149433612823486, "Value Loss": 21.40892219543457, "_runtime": 1835.1475987434387, "_timestamp": 1585510913.5683284, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6027729511260986, "Value Loss": 0.0065351021476089954, "_runtime": 1835.8062703609467, "_timestamp": 1585510914.227, "_step": 390}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.1573121547698975, "Value Loss": 24.537267684936523, "_runtime": 1837.0771083831787, "_timestamp": 1585510915.497838, "_step": 391}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": 0.3405887484550476, "Value Loss": 11.86397933959961, "_runtime": 1838.6264336109161, "_timestamp": 1585510917.0471632, "_step": 392}
{"Episode reward": -99.86739143282036, "Episode length": 999, "Policy Loss": -0.5969144701957703, "Value Loss": 0.0064389766193926334, "_runtime": 1839.3723878860474, "_timestamp": 1585510917.7931175, "_step": 393}
{"Episode reward": 51.299999999999585, "Episode length": 487, "Policy Loss": 0.8826815485954285, "Value Loss": 20.507539749145508, "_runtime": 1839.9846909046173, "_timestamp": 1585510918.4054205, "_step": 394}
{"Episode reward": 61.59117353984594, "Episode length": 385, "Policy Loss": 1.282395362854004, "Value Loss": 25.93890953063965, "_runtime": 1841.5159921646118, "_timestamp": 1585510919.9367218, "_step": 395}
{"Episode reward": -99.86175730386609, "Episode length": 999, "Policy Loss": -0.6009979248046875, "Value Loss": 0.006469215266406536, "_runtime": 1842.028698682785, "_timestamp": 1585510920.4494283, "_step": 396}
{"Episode reward": 66.98784551620464, "Episode length": 331, "Policy Loss": 2.5346035957336426, "Value Loss": 30.16916275024414, "_runtime": 1842.8905892372131, "_timestamp": 1585510921.3113189, "_step": 397}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.6413030624389648, "Value Loss": 17.27946662902832, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274, 0.18346697092056274]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.1838478446006775, -0.020448774099349976, 0.14295029640197754, 0.30634936690330505, 0.46974843740463257, 0.6331475377082825, 0.7965465784072876, 0.9599456191062927, 1.1233446598052979, 1.2867438793182373, 1.4501428604125977, 1.613541841506958, 1.7769410610198975, 1.9403400421142578, 2.103739023208618, 2.2671382427215576, 2.430537223815918, 2.5939362049102783, 2.7573354244232178, 2.920734405517578, 3.0841336250305176, 3.247532606124878, 3.4109315872192383, 3.5743308067321777, 3.737729787826538, 3.9011287689208984, 4.064527988433838, 4.227927207946777, 4.391325950622559, 4.554725170135498, 4.7181243896484375, 4.881523132324219, 5.044922351837158, 5.208321571350098, 5.371720314025879, 5.535119533538818, 5.698518753051758, 5.861917495727539, 6.0253167152404785, 6.188715934753418, 6.352115154266357, 6.515513896942139, 6.678913116455078, 6.842312335968018, 7.005711078643799, 7.169110298156738, 7.332509517669678, 7.495908260345459, 7.659307479858398, 7.822706699371338, 7.986105442047119, 8.149505615234375, 8.312904357910156, 8.476303100585938, 8.639702796936035, 8.803101539611816, 8.966500282287598, 9.129899978637695, 9.293298721313477, 9.456697463989258, 9.620097160339355, 9.783495903015137, 9.946894645690918, 10.110294342041016, 10.273693084716797]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.13353388011455536, -0.1239723488688469, -0.11441081762313843, -0.10484929382801056, -0.0952877551317215, -0.08572623133659363, -0.07616470009088516, -0.0666031688451767, -0.05704163759946823, -0.047480106353759766, -0.0379185751080513, -0.028357043862342834, -0.018795520067214966, -0.0092339888215065, 0.00032754242420196533, 0.009889081120491028, 0.019450604915618896, 0.029012128710746765, 0.03857366740703583, 0.048135191202163696, 0.05769672989845276, 0.06725825369358063, 0.07681979238986969, 0.08638131618499756, 0.09594283998012543, 0.10550437867641449, 0.11506590247154236, 0.12462742626667023, 0.1341889649629593, 0.14375050365924835, 0.15331204235553741, 0.1628735512495041, 0.17243508994579315, 0.18199662864208221, 0.1915581375360489, 0.20111967623233795, 0.21068121492862701, 0.22024275362491608, 0.22980426251888275, 0.23936580121517181, 0.24892733991146088, 0.25848883390426636, 0.2680503726005554, 0.2776119112968445, 0.28717344999313354, 0.2967349886894226, 0.30629652738571167, 0.31585806608200073, 0.325419545173645, 0.3349810838699341, 0.34454262256622314, 0.3541041612625122, 0.36366569995880127, 0.37322723865509033, 0.3827887177467346, 0.3923502564430237, 0.40191179513931274, 0.4114733338356018, 0.42103487253189087, 0.43059641122817993, 0.440157949924469, 0.4497194290161133, 0.45928096771240234, 0.4688425064086914, 0.47840404510498047]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 8.0, 8.0, 10.0, 8.0, 9.0, 10.0, 20.0, 33.0, 53.0, 23.0, 2.0, 215.0, 9.0, 7.0, 16.0, 8.0, 9.0, 4.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], "bins": [-0.529608964920044, -0.49168696999549866, -0.453764945268631, -0.4158429503440857, -0.377920925617218, -0.33999893069267273, -0.30207693576812744, -0.26415491104125977, -0.22623291611671448, -0.1883109211921692, -0.1503888964653015, -0.11246690154075623, -0.07454490661621094, -0.03662288188934326, 0.001299142837524414, 0.039221107959747314, 0.07714313268661499, 0.11506515741348267, 0.15298712253570557, 0.19090914726257324, 0.22883117198944092, 0.2667531371116638, 0.3046751618385315, 0.34259718656539917, 0.38051915168762207, 0.41844117641448975, 0.4563632011413574, 0.4942852258682251, 0.5322072505950928, 0.5701291561126709, 0.6080511808395386, 0.6459732055664062, 0.6838952302932739, 0.7218172550201416, 0.7597392797470093, 0.797661304473877, 0.8355832099914551, 0.8735052347183228, 0.9114272594451904, 0.9493492841720581, 0.9872713088989258, 1.0251933336257935, 1.0631152391433716, 1.1010372638702393, 1.138959288597107, 1.1768813133239746, 1.2148033380508423, 1.25272536277771, 1.290647268295288, 1.3285692930221558, 1.3664913177490234, 1.4044133424758911, 1.4423353672027588, 1.480257272720337, 1.5181794166564941, 1.5561013221740723, 1.5940234661102295, 1.6319453716278076, 1.6698672771453857, 1.707789421081543, 1.745711326599121, 1.7836334705352783, 1.8215553760528564, 1.8594775199890137, 1.8973994255065918]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.50857675075531, -1.4170291423797607, -1.325481653213501, -1.2339340448379517, -1.1423864364624023, -1.050838828086853, -0.9592912793159485, -0.867743730545044, -0.7761961221694946, -0.6846485137939453, -0.5931009650230408, -0.5015534162521362, -0.4100058078765869, -0.3184581995010376, -0.22691071033477783, -0.13536310195922852, -0.0438154935836792, 0.04773211479187012, 0.13927972316741943, 0.2308272123336792, 0.3223748207092285, 0.41392242908477783, 0.5054699182510376, 0.5970176458358765, 0.6885651350021362, 0.780112624168396, 0.8716603517532349, 0.9632078409194946, 1.0547553300857544, 1.1463030576705933, 1.237850546836853, 1.329398274421692, 1.4209457635879517, 1.5124932527542114, 1.6040409803390503, 1.69558846950531, 1.787136197090149, 1.8786836862564087, 1.9702311754226685, 2.061779022216797, 2.1533265113830566, 2.2448740005493164, 2.336421489715576, 2.427968978881836, 2.5195164680480957, 2.6110639572143555, 2.7026119232177734, 2.794159412384033, 2.885706901550293, 2.9772543907165527, 3.0688018798828125, 3.1603498458862305, 3.2518973350524902, 3.34344482421875, 3.4349923133850098, 3.5265398025512695, 3.6180872917175293, 3.7096352577209473, 3.801182746887207, 3.892730236053467, 3.9842777252197266, 4.075825214385986, 4.167373180389404, 4.258920669555664, 4.350468158721924]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 29.0, 10.0, 0.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.0892345905303955, -2.0455844402313232, -2.001934051513672, -1.9582839012145996, -1.9146337509155273, -1.8709834814071655, -1.8273333311080933, -1.7836830615997314, -1.7400329113006592, -1.6963826417922974, -1.652732491493225, -1.6090822219848633, -1.565432071685791, -1.5217818021774292, -1.4781315326690674, -1.4344813823699951, -1.3908312320709229, -1.347180962562561, -1.3035306930541992, -1.259880542755127, -1.2162303924560547, -1.1725801229476929, -1.128929853439331, -1.0852797031402588, -1.041629433631897, -0.9979792833328247, -0.9543290138244629, -0.9106788635253906, -0.8670285940170288, -0.8233784437179565, -0.7797281742095947, -0.7360780239105225, -0.6924277544021606, -0.6487774848937988, -0.6051273345947266, -0.5614770650863647, -0.5178269147872925, -0.47417664527893066, -0.4305264949798584, -0.3868762254714966, -0.3432260751724243, -0.2995758056640625, -0.25592565536499023, -0.21227538585662842, -0.16862523555755615, -0.12497496604919434, -0.08132481575012207, -0.037674665451049805, 0.0059757232666015625, 0.04962587356567383, 0.0932760238647461, 0.13692641258239746, 0.18057656288146973, 0.224226713180542, 0.26787686347961426, 0.3115272521972656, 0.3551774024963379, 0.39882755279541016, 0.4424777030944824, 0.4861280918121338, 0.529778242111206, 0.5734283924102783, 0.6170785427093506, 0.660728931427002, 0.7043790817260742]}, "_runtime": 1843.3923749923706, "_timestamp": 1585510921.8131046, "_step": 398}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": 1.9440428018569946, "Value Loss": 32.95560073852539, "_runtime": 1844.324935913086, "_timestamp": 1585510922.7456656, "_step": 399}
{"Episode reward": 36.70898066721794, "Episode length": 633, "Policy Loss": 0.5164952874183655, "Value Loss": 15.778122901916504, "_runtime": 1844.8462083339691, "_timestamp": 1585510923.266938, "_step": 400}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 1.7007896900177002, "Value Loss": 31.49878692626953, "_runtime": 1846.311027765274, "_timestamp": 1585510924.7317574, "_step": 401}
{"Episode reward": -99.70691567212204, "Episode length": 999, "Policy Loss": -0.625583827495575, "Value Loss": 0.007169848773628473, "_runtime": 1846.8946328163147, "_timestamp": 1585510925.3153625, "_step": 402}
{"Episode reward": 62.49128590067823, "Episode length": 376, "Policy Loss": 1.2509281635284424, "Value Loss": 26.554637908935547, "_runtime": 1847.4381210803986, "_timestamp": 1585510925.8588507, "_step": 403}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.2734041213989258, "Value Loss": 27.12749481201172, "_runtime": 1848.178926706314, "_timestamp": 1585510926.5996563, "_step": 404}
{"Episode reward": 51.53950105523649, "Episode length": 486, "Policy Loss": 0.9160826802253723, "Value Loss": 20.51097869873047, "_runtime": 1849.6573975086212, "_timestamp": 1585510928.0781271, "_step": 405}
{"Episode reward": -99.81576357520977, "Episode length": 999, "Policy Loss": -0.8733387589454651, "Value Loss": 0.681991457939148, "_runtime": 1850.7630615234375, "_timestamp": 1585510929.1837912, "_step": 406}
{"Episode reward": 24.60000000000001, "Episode length": 754, "Policy Loss": 0.028403542935848236, "Value Loss": 13.03837776184082, "_runtime": 1852.0557460784912, "_timestamp": 1585510930.4764757, "_step": 407}
{"Episode reward": 12.849937292841005, "Episode length": 872, "Policy Loss": -0.033740025013685226, "Value Loss": 11.355628967285156, "_runtime": 1853.5894136428833, "_timestamp": 1585510932.0101433, "_step": 408}
{"Episode reward": -99.81190788633981, "Episode length": 999, "Policy Loss": -0.903627872467041, "Value Loss": 0.015023434534668922, "_runtime": 1855.1035697460175, "_timestamp": 1585510933.5242994, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8787932991981506, "Value Loss": 0.015280919149518013, "_runtime": 1856.0281965732574, "_timestamp": 1585510934.4489262, "_step": 410}
{"Episode reward": 39.58976929476427, "Episode length": 605, "Policy Loss": 0.3536480963230133, "Value Loss": 16.498920440673828, "_runtime": 1857.560375213623, "_timestamp": 1585510935.9811049, "_step": 411}
{"Episode reward": -99.76024516001205, "Episode length": 999, "Policy Loss": -0.7671722769737244, "Value Loss": 0.010865180753171444, "_runtime": 1858.47363448143, "_timestamp": 1585510936.894364, "_step": 412}
{"Episode reward": 40.698874074872016, "Episode length": 594, "Policy Loss": 0.635239839553833, "Value Loss": 16.827701568603516, "_runtime": 1859.9863839149475, "_timestamp": 1585510938.4071136, "_step": 413}
{"Episode reward": -99.67765087019514, "Episode length": 999, "Policy Loss": -0.6289516091346741, "Value Loss": 0.017258349806070328, "_runtime": 1861.357780456543, "_timestamp": 1585510939.77851, "_step": 414}
{"Episode reward": 10.874844118115348, "Episode length": 892, "Policy Loss": 0.22142378985881805, "Value Loss": 11.263558387756348, "_runtime": 1862.74347782135, "_timestamp": 1585510941.1642075, "_step": 415}
{"Episode reward": 8.40000000000093, "Episode length": 916, "Policy Loss": 0.25222867727279663, "Value Loss": 10.927616119384766, "_runtime": 1863.3240399360657, "_timestamp": 1585510941.7447696, "_step": 416}
{"Episode reward": 64.39999999999978, "Episode length": 356, "Policy Loss": 1.3527027368545532, "Value Loss": 28.030580520629883, "_runtime": 1864.3120748996735, "_timestamp": 1585510942.7328045, "_step": 417}
{"Episode reward": 35.29933507442415, "Episode length": 648, "Policy Loss": 0.19722390174865723, "Value Loss": 15.338859558105469, "_runtime": 1865.847008228302, "_timestamp": 1585510944.2677379, "_step": 418}
{"Episode reward": -99.7861731437021, "Episode length": 999, "Policy Loss": -1.119266390800476, "Value Loss": 0.03796090930700302, "_runtime": 1867.3283264636993, "_timestamp": 1585510945.749056, "_step": 419}
{"Episode reward": 0.9176102089709133, "Episode length": 992, "Policy Loss": -0.538651168346405, "Value Loss": 9.968230247497559, "_runtime": 1868.8761808872223, "_timestamp": 1585510947.2969105, "_step": 420}
{"Episode reward": -99.76399250132825, "Episode length": 999, "Policy Loss": -1.4455963373184204, "Value Loss": 0.07085204124450684, "_runtime": 1870.4260864257812, "_timestamp": 1585510948.846816, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5774606466293335, "Value Loss": 0.05230983719229698, "_runtime": 1871.967396736145, "_timestamp": 1585510950.3881264, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7190595865249634, "Value Loss": 0.1279706060886383, "_runtime": 1873.5225775241852, "_timestamp": 1585510951.9433072, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6995186805725098, "Value Loss": 0.15488626062870026, "_runtime": 1875.058120250702, "_timestamp": 1585510953.47885, "_step": 424}
{"Episode reward": -99.63796797676338, "Episode length": 999, "Policy Loss": -1.5363132953643799, "Value Loss": 0.6229255795478821, "_runtime": 1875.5573177337646, "_timestamp": 1585510953.9780474, "_step": 425}
{"Episode reward": 70.29999999999986, "Episode length": 297, "Policy Loss": 0.9661042094230652, "Value Loss": 32.93236541748047, "_runtime": 1877.089498758316, "_timestamp": 1585510955.5102284, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3608964681625366, "Value Loss": 0.07682131975889206, "_runtime": 1878.2800858020782, "_timestamp": 1585510956.7008154, "_step": 427}
{"Episode reward": 23.200000000000088, "Episode length": 768, "Policy Loss": -0.3369502127170563, "Value Loss": 12.945916175842285, "_runtime": 1879.0956852436066, "_timestamp": 1585510957.5164149, "_step": 428}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": 0.12899047136306763, "Value Loss": 17.957746505737305, "_runtime": 1880.645262479782, "_timestamp": 1585510959.065992, "_step": 429}
{"Episode reward": -99.694705481919, "Episode length": 999, "Policy Loss": -1.0561635494232178, "Value Loss": 0.052161287516355515, "_runtime": 1882.1748206615448, "_timestamp": 1585510960.5955503, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.975274920463562, "Value Loss": 0.0506911426782608, "_runtime": 1883.6752998828888, "_timestamp": 1585510962.0960295, "_step": 431}
{"Episode reward": -99.8796096556806, "Episode length": 999, "Policy Loss": -0.8906605243682861, "Value Loss": 0.028823688626289368, "_runtime": 1885.222469329834, "_timestamp": 1585510963.643199, "_step": 432}
{"Episode reward": -99.81358820507164, "Episode length": 999, "Policy Loss": -0.7928880453109741, "Value Loss": 0.0164516381919384, "_runtime": 1886.472684621811, "_timestamp": 1585510964.8934143, "_step": 433}
{"Episode reward": 19.897238782327904, "Episode length": 803, "Policy Loss": 0.1694767028093338, "Value Loss": 12.33006477355957, "_runtime": 1888.0149114131927, "_timestamp": 1585510966.435641, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.723870038986206, "Value Loss": 0.01454575639218092, "_runtime": 1889.325107574463, "_timestamp": 1585510967.7458372, "_step": 435}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": 0.11066298186779022, "Value Loss": 11.751106262207031, "_runtime": 1890.9116370677948, "_timestamp": 1585510969.3323667, "_step": 436}
{"Episode reward": -99.80198441147664, "Episode length": 999, "Policy Loss": -0.7794574499130249, "Value Loss": 0.03801659867167473, "_runtime": 1892.3821802139282, "_timestamp": 1585510970.8029099, "_step": 437}
{"Episode reward": 5.980204416067494, "Episode length": 943, "Policy Loss": -0.07224131375551224, "Value Loss": 10.272867202758789, "_runtime": 1893.0007193088531, "_timestamp": 1585510971.421449, "_step": 438}
{"Episode reward": 61.92356028398473, "Episode length": 381, "Policy Loss": 0.7914301156997681, "Value Loss": 25.299543380737305, "_runtime": 1894.5583622455597, "_timestamp": 1585510972.979092, "_step": 439}
{"Episode reward": -99.802708700391, "Episode length": 999, "Policy Loss": -1.047758936882019, "Value Loss": 0.14187215268611908, "_runtime": 1896.1053590774536, "_timestamp": 1585510974.5260887, "_step": 440}
{"Episode reward": -99.83974061915511, "Episode length": 999, "Policy Loss": -1.1298770904541016, "Value Loss": 0.10101716965436935, "_runtime": 1896.9826855659485, "_timestamp": 1585510975.4034152, "_step": 441}
{"Episode reward": 42.058709335326604, "Episode length": 580, "Policy Loss": 0.22588221728801727, "Value Loss": 16.899295806884766, "_runtime": 1898.1009078025818, "_timestamp": 1585510976.5216374, "_step": 442}
{"Episode reward": 28.59999999999978, "Episode length": 714, "Policy Loss": -0.40155720710754395, "Value Loss": 13.265347480773926, "_runtime": 1899.6585659980774, "_timestamp": 1585510978.0792956, "_step": 443}
{"Episode reward": -99.77897392082821, "Episode length": 999, "Policy Loss": -1.0464961528778076, "Value Loss": 0.03241056203842163, "_runtime": 1901.176914691925, "_timestamp": 1585510979.5976443, "_step": 444}
{"Episode reward": -99.66707615163038, "Episode length": 999, "Policy Loss": -0.9491350650787354, "Value Loss": 0.03852154314517975, "_runtime": 1902.7154536247253, "_timestamp": 1585510981.1361833, "_step": 445}
{"Episode reward": -99.77675406569476, "Episode length": 999, "Policy Loss": -0.8657459020614624, "Value Loss": 0.01580527238547802, "_runtime": 1903.3158977031708, "_timestamp": 1585510981.7366273, "_step": 446}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.1425498723983765, "Value Loss": 26.6331844329834, "_runtime": 1904.8500225543976, "_timestamp": 1585510983.2707522, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8083618879318237, "Value Loss": 0.027381526306271553, "_runtime": 1906.3943150043488, "_timestamp": 1585510984.8150446, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8442497253417969, "Value Loss": 0.021846476942300797, "_runtime": 1907.5155487060547, "_timestamp": 1585510985.9362783, "_step": 449}
{"Episode reward": 25.496406124532186, "Episode length": 746, "Policy Loss": 0.08427082747220993, "Value Loss": 13.09636116027832, "_runtime": 1908.8701510429382, "_timestamp": 1585510987.2908807, "_step": 450}
{"Episode reward": 12.877697094437409, "Episode length": 872, "Policy Loss": -0.12609052658081055, "Value Loss": 11.075668334960938, "_runtime": 1910.438655614853, "_timestamp": 1585510988.8593853, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.041792631149292, "Value Loss": 0.03627520427107811, "_runtime": 1911.074299812317, "_timestamp": 1585510989.4950294, "_step": 452}
{"Episode reward": 59.11732813082605, "Episode length": 409, "Policy Loss": 0.487731009721756, "Value Loss": 23.14198112487793, "_runtime": 1912.2959575653076, "_timestamp": 1585510990.7166872, "_step": 453}
{"Episode reward": 21.38787353278623, "Episode length": 787, "Policy Loss": -0.3475089371204376, "Value Loss": 11.877318382263184, "_runtime": 1913.8590655326843, "_timestamp": 1585510992.2797952, "_step": 454}
{"Episode reward": -99.81639745766158, "Episode length": 999, "Policy Loss": -1.5344908237457275, "Value Loss": 0.04701567441225052, "_runtime": 1915.3630945682526, "_timestamp": 1585510993.7838242, "_step": 455}
{"Episode reward": -99.83952160477499, "Episode length": 999, "Policy Loss": -1.7303571701049805, "Value Loss": 0.08302267640829086, "_runtime": 1916.936074256897, "_timestamp": 1585510995.356804, "_step": 456}
{"Episode reward": -99.84468756029243, "Episode length": 999, "Policy Loss": -1.8586598634719849, "Value Loss": 0.0911756157875061, "_runtime": 1918.5064158439636, "_timestamp": 1585510996.9271455, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9818931818008423, "Value Loss": 0.7880887389183044, "_runtime": 1919.9603021144867, "_timestamp": 1585510998.3810318, "_step": 458}
{"Episode reward": 6.10000000000106, "Episode length": 939, "Policy Loss": -1.3157585859298706, "Value Loss": 10.696146011352539, "_runtime": 1921.1308960914612, "_timestamp": 1585510999.5516257, "_step": 459}
{"Episode reward": 25.792466342076608, "Episode length": 743, "Policy Loss": -0.4369989037513733, "Value Loss": 13.100068092346191, "_runtime": 1922.6807837486267, "_timestamp": 1585511001.1015134, "_step": 460}
{"Episode reward": -99.68093107482281, "Episode length": 999, "Policy Loss": -1.2316111326217651, "Value Loss": 0.07873901724815369, "_runtime": 1924.238198518753, "_timestamp": 1585511002.6589282, "_step": 461}
{"Episode reward": -99.8032899148981, "Episode length": 999, "Policy Loss": -0.9788923263549805, "Value Loss": 0.17691650986671448, "_runtime": 1925.775695323944, "_timestamp": 1585511004.196425, "_step": 462}
{"Episode reward": -99.64108761260147, "Episode length": 999, "Policy Loss": -0.7602877020835876, "Value Loss": 0.055871039628982544, "_runtime": 1927.346109867096, "_timestamp": 1585511005.7668395, "_step": 463}
{"Episode reward": -99.81426463723042, "Episode length": 999, "Policy Loss": -0.6095955967903137, "Value Loss": 0.07784265279769897, "_runtime": 1928.0420141220093, "_timestamp": 1585511006.4627438, "_step": 464}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.3813403844833374, "Value Loss": 22.753583908081055, "_runtime": 1929.6024804115295, "_timestamp": 1585511008.02321, "_step": 465}
{"Episode reward": -99.81430846983427, "Episode length": 999, "Policy Loss": -0.42500051856040955, "Value Loss": 0.01699889823794365, "_runtime": 1930.8050878047943, "_timestamp": 1585511009.2258174, "_step": 466}
{"Episode reward": 23.466567483358162, "Episode length": 768, "Policy Loss": 0.727410078048706, "Value Loss": 12.945061683654785, "_runtime": 1932.3150382041931, "_timestamp": 1585511010.7357678, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40718305110931396, "Value Loss": 0.00403409730643034, "_runtime": 1933.8735554218292, "_timestamp": 1585511012.294285, "_step": 468}
{"Episode reward": -99.84508420862117, "Episode length": 999, "Policy Loss": -0.4337295889854431, "Value Loss": 0.007831309922039509, "_runtime": 1934.5024082660675, "_timestamp": 1585511012.923138, "_step": 469}
{"Episode reward": 60.74281690185862, "Episode length": 393, "Policy Loss": 1.7159438133239746, "Value Loss": 24.998672485351562, "_runtime": 1935.3309371471405, "_timestamp": 1585511013.7516668, "_step": 470}
{"Episode reward": 46.79999999999952, "Episode length": 532, "Policy Loss": 0.932152271270752, "Value Loss": 18.422815322875977, "_runtime": 1936.2084488868713, "_timestamp": 1585511014.6291785, "_step": 471}
{"Episode reward": 44.68270325511643, "Episode length": 554, "Policy Loss": 0.6445111036300659, "Value Loss": 17.64958381652832, "_runtime": 1937.7110900878906, "_timestamp": 1585511016.1318197, "_step": 472}
{"Episode reward": -99.80077569819846, "Episode length": 999, "Policy Loss": -0.6544943451881409, "Value Loss": 0.1861506700515747, "_runtime": 1939.2153627872467, "_timestamp": 1585511017.6360924, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6834123730659485, "Value Loss": 0.16189877688884735, "_runtime": 1940.766125679016, "_timestamp": 1585511019.1868553, "_step": 474}
{"Episode reward": -99.80331598678464, "Episode length": 999, "Policy Loss": -0.7184343934059143, "Value Loss": 0.09802684932947159, "_runtime": 1941.218631029129, "_timestamp": 1585511019.6393607, "_step": 475}
{"Episode reward": 73.39999999999989, "Episode length": 266, "Policy Loss": 1.8921116590499878, "Value Loss": 36.01148986816406, "_runtime": 1942.7531080245972, "_timestamp": 1585511021.1738377, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.902335524559021, "Value Loss": 0.2446766197681427, "_runtime": 1944.2976541519165, "_timestamp": 1585511022.7183838, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9364445805549622, "Value Loss": 0.19541996717453003, "_runtime": 1945.79083776474, "_timestamp": 1585511024.2115674, "_step": 478}
{"Episode reward": -99.77475414220105, "Episode length": 999, "Policy Loss": -0.9906312227249146, "Value Loss": 0.12267768383026123, "_runtime": 1947.3495573997498, "_timestamp": 1585511025.770287, "_step": 479}
{"Episode reward": -99.80871950536827, "Episode length": 999, "Policy Loss": -1.0515011548995972, "Value Loss": 0.2994466722011566, "_runtime": 1948.912201166153, "_timestamp": 1585511027.3329308, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.037092685699463, "Value Loss": 0.030578847974538803, "_runtime": 1949.4204053878784, "_timestamp": 1585511027.841135, "_step": 481}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 1.2330844402313232, "Value Loss": 31.885189056396484, "_runtime": 1950.972987651825, "_timestamp": 1585511029.3937173, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0608333349227905, "Value Loss": 0.026379575952887535, "_runtime": 1952.5351328849792, "_timestamp": 1585511030.9558625, "_step": 483}
{"Episode reward": -99.75729617969925, "Episode length": 999, "Policy Loss": -1.104364037513733, "Value Loss": 0.029436493292450905, "_runtime": 1953.4284620285034, "_timestamp": 1585511031.8491917, "_step": 484}
{"Episode reward": 40.44759579738545, "Episode length": 596, "Policy Loss": 0.09814123809337616, "Value Loss": 16.445707321166992, "_runtime": 1954.9700005054474, "_timestamp": 1585511033.3907301, "_step": 485}
{"Episode reward": -99.82319365376466, "Episode length": 999, "Policy Loss": -1.1385024785995483, "Value Loss": 0.03582445904612541, "_runtime": 1956.524629354477, "_timestamp": 1585511034.945359, "_step": 486}
{"Episode reward": -99.7208043428124, "Episode length": 999, "Policy Loss": -1.172837257385254, "Value Loss": 0.031244080513715744, "_runtime": 1957.5055990219116, "_timestamp": 1585511035.9263287, "_step": 487}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": -0.11198925971984863, "Value Loss": 14.923861503601074, "_runtime": 1959.056411266327, "_timestamp": 1585511037.477141, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2097362279891968, "Value Loss": 0.08228001743555069, "_runtime": 1959.9365873336792, "_timestamp": 1585511038.357317, "_step": 489}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": -0.023835085332393646, "Value Loss": 17.100425720214844, "_runtime": 1961.4581027030945, "_timestamp": 1585511039.8788323, "_step": 490}
{"Episode reward": -99.79628700688342, "Episode length": 999, "Policy Loss": -1.2661843299865723, "Value Loss": 0.03845248371362686, "_runtime": 1962.1048529148102, "_timestamp": 1585511040.5255826, "_step": 491}
{"Episode reward": 60.48023485541315, "Episode length": 396, "Policy Loss": 0.27923423051834106, "Value Loss": 23.329252243041992, "_runtime": 1963.6540987491608, "_timestamp": 1585511042.0748284, "_step": 492}
{"Episode reward": -99.71175345815578, "Episode length": 999, "Policy Loss": -1.378843069076538, "Value Loss": 0.04365121200680733, "_runtime": 1964.3482120037079, "_timestamp": 1585511042.7689416, "_step": 493}
{"Episode reward": 56.69999999999966, "Episode length": 433, "Policy Loss": 0.1427953839302063, "Value Loss": 21.55915069580078, "_runtime": 1965.8469457626343, "_timestamp": 1585511044.2676754, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5401242971420288, "Value Loss": 0.052289631217718124, "_runtime": 1967.4104886054993, "_timestamp": 1585511045.8312182, "_step": 495}
{"Episode reward": -99.8148467604057, "Episode length": 999, "Policy Loss": -1.5942639112472534, "Value Loss": 0.05283437296748161, "_runtime": 1968.9143557548523, "_timestamp": 1585511047.3350854, "_step": 496}
{"Episode reward": -99.73472889298434, "Episode length": 999, "Policy Loss": -1.6233011484146118, "Value Loss": 0.06548379361629486, "_runtime": 1970.1317048072815, "_timestamp": 1585511048.5524344, "_step": 497}
{"Episode reward": 21.95938116163032, "Episode length": 781, "Policy Loss": -0.7467284202575684, "Value Loss": 12.02763843536377, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145, -0.010026006028056145]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-0.40437835454940796, -0.3978622853755951, -0.3913462460041046, -0.38483017683029175, -0.37831413745880127, -0.3717980682849884, -0.36528199911117554, -0.35876595973968506, -0.3522498905658722, -0.3457338511943817, -0.33921778202056885, -0.33270174264907837, -0.3261856734752655, -0.31966960430145264, -0.31315356492996216, -0.3066374957561493, -0.3001214265823364, -0.29360538721084595, -0.2870893180370331, -0.2805732786655426, -0.27405720949172974, -0.26754117012023926, -0.2610251009464264, -0.2545090317726135, -0.24799299240112305, -0.24147692322731018, -0.2349608689546585, -0.22844481468200684, -0.22192876040935516, -0.2154127061367035, -0.20889663696289062, -0.20238058269023895, -0.19586452841758728, -0.1893484741449356, -0.18283241987228394, -0.17631635069847107, -0.1698002964258194, -0.16328424215316772, -0.15676818788051605, -0.15025213360786438, -0.1437360644340515, -0.13722002506256104, -0.13070395588874817, -0.1241878867149353, -0.11767184734344482, -0.11115577816963196, -0.10463973879814148, -0.09812366962432861, -0.09160763025283813, -0.08509156107902527, -0.0785754919052124, -0.07205945253372192, -0.06554338335990906, -0.05902734398841858, -0.05251127481460571, -0.04599520564079285, -0.03947916626930237, -0.0329630970954895, -0.026447057723999023, -0.019930988550186157, -0.013414919376373291, -0.0068988800048828125, -0.0003828108310699463, 0.006133228540420532, 0.012649297714233398]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.026087705045938492, -0.025564830750226974, -0.025041958317160606, -0.02451908402144909, -0.02399620972573757, -0.023473337292671204, -0.022950462996959686, -0.02242758870124817, -0.0219047162681818, -0.021381841972470284, -0.020858969539403915, -0.020336095243692398, -0.01981322094798088, -0.019290346652269363, -0.018767474219202995, -0.018244599923491478, -0.01772172749042511, -0.017198853194713593, -0.016675978899002075, -0.016153104603290558, -0.01563023217022419, -0.015107357874512672, -0.01458448451012373, -0.014061611145734787, -0.01353873685002327, -0.013015863485634327, -0.012492990121245384, -0.011970116756856441, -0.011447242461144924, -0.010924369096755981, -0.010401494801044464, -0.009878622367978096, -0.009355748072266579, -0.008832873776555061, -0.008310001343488693, -0.007787127047777176, -0.007264252752065659, -0.0067413803189992905, -0.006218506023287773, -0.005695631727576256, -0.005172759294509888, -0.00464988499879837, -0.004127010703086853, -0.003604138270020485, -0.0030812639743089676, -0.0025583896785974503, -0.002035517245531082, -0.0015126429498195648, -0.0009897686541080475, -0.0004668962210416794, 5.597807466983795e-05, 0.0005788505077362061, 0.0011017248034477234, 0.0016245990991592407, 0.002147471532225609, 0.002670345827937126, 0.0031932201236486435, 0.0037160925567150116, 0.004238966852426529, 0.004761841148138046, 0.005284715443849564, 0.005807589739561081, 0.0063304603099823, 0.006853334605693817, 0.0073762089014053345]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 5.0, 3.0, 4.0, 3.0, 1.0, 7.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 9.0, 8.0, 10.0, 15.0, 228.0, 14.0, 18.0, 30.0, 22.0, 26.0, 17.0, 10.0, 7.0, 4.0, 1.0, 5.0, 8.0, 4.0, 2.0, 5.0], "bins": [-0.07885436713695526, -0.07722742110490799, -0.07560048252344131, -0.07397353649139404, -0.07234659790992737, -0.0707196518778801, -0.06909270584583282, -0.06746576726436615, -0.06583882123231888, -0.0642118752002716, -0.06258493661880493, -0.06095799058675766, -0.05933104828000069, -0.05770410597324371, -0.05607715994119644, -0.05445021763443947, -0.052823275327682495, -0.05119633302092552, -0.04956939071416855, -0.04794244468212128, -0.046315502375364304, -0.04468856006860733, -0.04306161403656006, -0.041434671729803085, -0.03980772942304611, -0.03818078711628914, -0.036553844809532166, -0.034926898777484894, -0.03329995647072792, -0.03167301416397095, -0.030046068131923676, -0.028419125825166702, -0.02679218351840973, -0.025165241211652756, -0.023538298904895782, -0.02191135287284851, -0.020284410566091537, -0.018657468259334564, -0.017030522227287292, -0.015403583645820618, -0.013776637613773346, -0.012149691581726074, -0.0105227530002594, -0.008895806968212128, -0.007268860936164856, -0.005641922354698181, -0.004014976322650909, -0.0023880377411842346, -0.0007610917091369629, 0.0008658543229103088, 0.0024927929043769836, 0.004119738936424255, 0.00574667751789093, 0.007373623549938202, 0.009000569581985474, 0.010627508163452148, 0.01225445419549942, 0.013881400227546692, 0.015508338809013367, 0.01713528484106064, 0.01876223087310791, 0.020389169454574585, 0.022016115486621857, 0.02364305406808853, 0.025270000100135803]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0], "bins": [-0.23012158274650574, -0.22527940571308136, -0.22043722867965698, -0.2155950516462326, -0.21075287461280823, -0.20591069757938385, -0.20106852054595947, -0.1962263286113739, -0.19138416647911072, -0.18654197454452515, -0.18169981241226196, -0.1768576204776764, -0.17201544344425201, -0.16717326641082764, -0.16233108937740326, -0.15748891234397888, -0.1526467353105545, -0.14780455827713013, -0.14296238124370575, -0.13812020421028137, -0.133278027176857, -0.12843585014343262, -0.12359366565942764, -0.11875148862600327, -0.11390931159257889, -0.10906713455915451, -0.10422495007514954, -0.09938277304172516, -0.09454059600830078, -0.0896984189748764, -0.08485624194145203, -0.08001406490802765, -0.07517188787460327, -0.0703297108411789, -0.06548753380775452, -0.06064535677433014, -0.05580317974090576, -0.050961002707481384, -0.04611882567405701, -0.04127664864063263, -0.03643447160720825, -0.03159227967262268, -0.026750102639198303, -0.021907925605773926, -0.01706574857234955, -0.012223571538925171, -0.0073813945055007935, -0.002539217472076416, 0.0023029595613479614, 0.007145136594772339, 0.011987313628196716, 0.016829490661621094, 0.021671682596206665, 0.02651384472846985, 0.03135603666305542, 0.036198198795318604, 0.041040390729904175, 0.04588255286216736, 0.05072474479675293, 0.05556690692901611, 0.060409098863601685, 0.06525126099586487, 0.07009345293045044, 0.07493561506271362, 0.0797778069972992]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 7.0, 16.0, 1.0, 0.0, 4.0, 0.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.060093075037002563, -0.05824423208832741, -0.05639539286494255, -0.054546549916267395, -0.05269771069288254, -0.05084886774420738, -0.049000028520822525, -0.04715118557214737, -0.04530234634876251, -0.04345350340008736, -0.0416046604514122, -0.039755821228027344, -0.03790698200464249, -0.03605813905596733, -0.034209296107292175, -0.03236045688390732, -0.03051161579787731, -0.028662774711847305, -0.02681393176317215, -0.024965092539787292, -0.023116249591112137, -0.02126741036772728, -0.019418567419052124, -0.017569728195667267, -0.01572088524699211, -0.013872046023607254, -0.012023203074932098, -0.010174363851547241, -0.008325520902872086, -0.006476681679487228, -0.004627838730812073, -0.0027789995074272156, -0.0009301565587520599, 0.0009186863899230957, 0.002767525613307953, 0.00461636483669281, 0.006465211510658264, 0.008314050734043121, 0.010162889957427979, 0.012011729180812836, 0.01386057585477829, 0.015709415078163147, 0.017558254301548004, 0.01940709352493286, 0.021255940198898315, 0.023104779422283173, 0.02495361864566803, 0.026802457869052887, 0.02865130454301834, 0.030500143766403198, 0.032348982989788055, 0.03419782966375351, 0.03604666888713837, 0.037895508110523224, 0.03974434733390808, 0.041593194007873535, 0.04344203323125839, 0.04529087245464325, 0.04713971167802811, 0.04898855835199356, 0.05083739757537842, 0.052686236798763275, 0.05453507602214813, 0.056383922696113586, 0.058232761919498444]}, "_runtime": 1971.6873891353607, "_timestamp": 1585511050.1081188, "_step": 498}
{"Episode reward": -99.8075924062156, "Episode length": 999, "Policy Loss": -1.587561845779419, "Value Loss": 0.049101073294878006, "_runtime": 1971.6873891353607, "_timestamp": 1585511050.1081188, "_step": 499}
