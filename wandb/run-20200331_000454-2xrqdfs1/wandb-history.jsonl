{"Episode reward": 70.35913772125632, "Episode length": 675, "Policy Loss": 0.10032913833856583, "Value Loss": 14.76972484588623, "_runtime": 15739.250236749649, "_timestamp": 1585613108.8831062, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.139000415802002, "Value Loss": 2.1602070331573486, "_runtime": 15740.757910490036, "_timestamp": 1585613110.39078, "_step": 1}
{"Episode reward": -93.57738555611537, "Episode length": 999, "Policy Loss": -1.1115199327468872, "Value Loss": 33.6176872253418, "_runtime": 15742.320459127426, "_timestamp": 1585613111.9533286, "_step": 2}
{"Episode reward": -96.68342718168286, "Episode length": 999, "Policy Loss": 0.08524961769580841, "Value Loss": 74.27098083496094, "_runtime": 15742.54108762741, "_timestamp": 1585613112.173957, "_step": 3}
{"Episode reward": 90.6525374710805, "Episode length": 101, "Policy Loss": 23.146339416503906, "Value Loss": 124.76995849609375, "_runtime": 15743.29658460617, "_timestamp": 1585613112.929454, "_step": 4}
{"Episode reward": 52.48413927761027, "Episode length": 486, "Policy Loss": 0.4192511737346649, "Value Loss": 24.214054107666016, "_runtime": 15744.375854492188, "_timestamp": 1585613114.008724, "_step": 5}
{"Episode reward": 32.1168103919826, "Episode length": 685, "Policy Loss": 0.6295279860496521, "Value Loss": 25.645505905151367, "_runtime": 15745.81638121605, "_timestamp": 1585613115.4492507, "_step": 6}
{"Episode reward": 4.285874058365209, "Episode length": 966, "Policy Loss": 1.3159514665603638, "Value Loss": 34.168670654296875, "_runtime": 15747.28939628601, "_timestamp": 1585613116.9222658, "_step": 7}
{"Episode reward": 3.280162754692469, "Episode length": 971, "Policy Loss": 0.5412558317184448, "Value Loss": 10.522773742675781, "_runtime": 15747.925312757492, "_timestamp": 1585613117.5581822, "_step": 8}
{"Episode reward": 60.66714783630422, "Episode length": 398, "Policy Loss": 1.29457688331604, "Value Loss": 34.762901306152344, "_runtime": 15749.287356615067, "_timestamp": 1585613118.920226, "_step": 9}
{"Episode reward": 12.931163080182813, "Episode length": 876, "Policy Loss": 0.7954338192939758, "Value Loss": 16.569639205932617, "_runtime": 15750.849763154984, "_timestamp": 1585613120.4826326, "_step": 10}
{"Episode reward": -99.35011455002689, "Episode length": 999, "Policy Loss": 0.026598036289215088, "Value Loss": 0.7912470698356628, "_runtime": 15752.358693122864, "_timestamp": 1585613121.9915626, "_step": 11}
{"Episode reward": -99.80144786199676, "Episode length": 999, "Policy Loss": -0.2673582434654236, "Value Loss": 0.9595845937728882, "_runtime": 15753.543102264404, "_timestamp": 1585613123.1759717, "_step": 12}
{"Episode reward": 24.813519481982794, "Episode length": 753, "Policy Loss": 0.20139935612678528, "Value Loss": 16.816030502319336, "_runtime": 15754.626229286194, "_timestamp": 1585613124.2590988, "_step": 13}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": 0.2211940437555313, "Value Loss": 15.046822547912598, "_runtime": 15756.175141096115, "_timestamp": 1585613125.8080106, "_step": 14}
{"Episode reward": -99.67875614783122, "Episode length": 999, "Policy Loss": -0.5988726615905762, "Value Loss": 0.17865167558193207, "_runtime": 15757.732141256332, "_timestamp": 1585613127.3650107, "_step": 15}
{"Episode reward": -99.73339404787264, "Episode length": 999, "Policy Loss": -0.5840556621551514, "Value Loss": 0.16021886467933655, "_runtime": 15758.899899244308, "_timestamp": 1585613128.5327687, "_step": 16}
{"Episode reward": 25.299977410188845, "Episode length": 748, "Policy Loss": 0.340375155210495, "Value Loss": 13.550320625305176, "_runtime": 15760.17259311676, "_timestamp": 1585613129.8054626, "_step": 17}
{"Episode reward": 18.900628060731435, "Episode length": 812, "Policy Loss": 0.3598535358905792, "Value Loss": 12.848963737487793, "_runtime": 15761.790355682373, "_timestamp": 1585613131.4232252, "_step": 18}
{"Episode reward": -99.69903534934717, "Episode length": 999, "Policy Loss": -0.8303179144859314, "Value Loss": 0.019458932802081108, "_runtime": 15763.073571681976, "_timestamp": 1585613132.7064412, "_step": 19}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": -0.34305742383003235, "Value Loss": 12.909893989562988, "_runtime": 15764.608220815659, "_timestamp": 1585613134.2410903, "_step": 20}
{"Episode reward": -99.69037457227103, "Episode length": 999, "Policy Loss": -1.0519981384277344, "Value Loss": 0.25082772970199585, "_runtime": 15765.956628084183, "_timestamp": 1585613135.5894976, "_step": 21}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": -0.19796517491340637, "Value Loss": 11.766679763793945, "_runtime": 15767.230260372162, "_timestamp": 1585613136.8631299, "_step": 22}
{"Episode reward": 18.15578853935041, "Episode length": 819, "Policy Loss": 0.01107718888670206, "Value Loss": 12.546692848205566, "_runtime": 15768.79916548729, "_timestamp": 1585613138.432035, "_step": 23}
{"Episode reward": -99.71530492207829, "Episode length": 999, "Policy Loss": -0.864274263381958, "Value Loss": 0.13392603397369385, "_runtime": 15770.373924732208, "_timestamp": 1585613140.0067942, "_step": 24}
{"Episode reward": -99.59815841957324, "Episode length": 999, "Policy Loss": -0.9805802702903748, "Value Loss": 0.03275778517127037, "_runtime": 15771.930879592896, "_timestamp": 1585613141.563749, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.098103642463684, "Value Loss": 0.05792626738548279, "_runtime": 15773.504863739014, "_timestamp": 1585613143.1377332, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1749262809753418, "Value Loss": 0.1409485936164856, "_runtime": 15775.081487417221, "_timestamp": 1585613144.714357, "_step": 27}
{"Episode reward": -99.85870230831067, "Episode length": 999, "Policy Loss": -1.161636233329773, "Value Loss": 0.15411514043807983, "_runtime": 15775.939718961716, "_timestamp": 1585613145.5725884, "_step": 28}
{"Episode reward": 47.17145542418537, "Episode length": 529, "Policy Loss": 0.19081392884254456, "Value Loss": 18.74701690673828, "_runtime": 15777.429352998734, "_timestamp": 1585613147.0622225, "_step": 29}
{"Episode reward": 5.791784222983907, "Episode length": 944, "Policy Loss": -0.24231524765491486, "Value Loss": 10.947319984436035, "_runtime": 15778.222286939621, "_timestamp": 1585613147.8551564, "_step": 30}
{"Episode reward": 51.8925620320249, "Episode length": 483, "Policy Loss": 0.15115228295326233, "Value Loss": 20.414865493774414, "_runtime": 15779.76934838295, "_timestamp": 1585613149.4022179, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2749675512313843, "Value Loss": 0.14620289206504822, "_runtime": 15781.346486091614, "_timestamp": 1585613150.9793556, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2344353199005127, "Value Loss": 0.041692063212394714, "_runtime": 15782.082249403, "_timestamp": 1585613151.715119, "_step": 33}
{"Episode reward": 53.32947649918458, "Episode length": 467, "Policy Loss": 0.22771836817264557, "Value Loss": 21.163204193115234, "_runtime": 15783.65746307373, "_timestamp": 1585613153.2903326, "_step": 34}
{"Episode reward": -99.64760154867406, "Episode length": 999, "Policy Loss": -1.2460546493530273, "Value Loss": 0.043658096343278885, "_runtime": 15784.289847612381, "_timestamp": 1585613153.922717, "_step": 35}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 0.470788836479187, "Value Loss": 25.988420486450195, "_runtime": 15785.818815946579, "_timestamp": 1585613155.4516854, "_step": 36}
{"Episode reward": -99.73311166781792, "Episode length": 999, "Policy Loss": -1.277012825012207, "Value Loss": 0.12328609079122543, "_runtime": 15786.89836859703, "_timestamp": 1585613156.531238, "_step": 37}
{"Episode reward": 32.646327319717514, "Episode length": 675, "Policy Loss": -0.14693020284175873, "Value Loss": 14.56928825378418, "_runtime": 15788.450749397278, "_timestamp": 1585613158.0836189, "_step": 38}
{"Episode reward": -99.85984888411919, "Episode length": 999, "Policy Loss": -1.0919113159179688, "Value Loss": 0.0906141921877861, "_runtime": 15790.019972801208, "_timestamp": 1585613159.6528423, "_step": 39}
{"Episode reward": -99.81472706207866, "Episode length": 999, "Policy Loss": -0.9526604413986206, "Value Loss": 0.1457403004169464, "_runtime": 15790.790645122528, "_timestamp": 1585613160.4235146, "_step": 40}
{"Episode reward": 50.499999999999574, "Episode length": 495, "Policy Loss": 0.8026522397994995, "Value Loss": 20.212627410888672, "_runtime": 15791.507874965668, "_timestamp": 1585613161.1407444, "_step": 41}
{"Episode reward": 55.488959306478144, "Episode length": 446, "Policy Loss": 0.6661343574523926, "Value Loss": 21.773279190063477, "_runtime": 15792.95166349411, "_timestamp": 1585613162.584533, "_step": 42}
{"Episode reward": 8.687273841887688, "Episode length": 914, "Policy Loss": -0.5173676609992981, "Value Loss": 11.283206939697266, "_runtime": 15794.477682352066, "_timestamp": 1585613164.1105518, "_step": 43}
{"Episode reward": -99.63516951661883, "Episode length": 999, "Policy Loss": -1.040042757987976, "Value Loss": 0.05981043353676796, "_runtime": 15795.322213411331, "_timestamp": 1585613164.955083, "_step": 44}
{"Episode reward": 44.65333460716014, "Episode length": 554, "Policy Loss": 0.377751886844635, "Value Loss": 18.376779556274414, "_runtime": 15795.951355457306, "_timestamp": 1585613165.584225, "_step": 45}
{"Episode reward": 61.65383774561315, "Episode length": 384, "Policy Loss": 0.6651442646980286, "Value Loss": 25.41390037536621, "_runtime": 15796.937858819962, "_timestamp": 1585613166.5707283, "_step": 46}
{"Episode reward": 37.04338319301544, "Episode length": 630, "Policy Loss": 0.32489708065986633, "Value Loss": 15.838631629943848, "_runtime": 15797.643368005753, "_timestamp": 1585613167.2762375, "_step": 47}
{"Episode reward": 54.70852306801789, "Episode length": 454, "Policy Loss": 0.2619374990463257, "Value Loss": 21.9843692779541, "_runtime": 15799.16626048088, "_timestamp": 1585613168.79913, "_step": 48}
{"Episode reward": -99.71212715706649, "Episode length": 999, "Policy Loss": -0.7293930053710938, "Value Loss": 0.05799909308552742, "_runtime": 15800.701563119888, "_timestamp": 1585613170.3344326, "_step": 49}
{"Episode reward": -99.75778734031925, "Episode length": 999, "Policy Loss": -0.2839331328868866, "Value Loss": 0.8788403272628784, "_runtime": 15802.212512731552, "_timestamp": 1585613171.8453822, "_step": 50}
{"Episode reward": -99.8386838596533, "Episode length": 999, "Policy Loss": -0.25286033749580383, "Value Loss": 2.6501924991607666, "_runtime": 15803.773280143738, "_timestamp": 1585613173.4061496, "_step": 51}
{"Episode reward": -99.84579185284534, "Episode length": 999, "Policy Loss": -0.7628945708274841, "Value Loss": 1.117521047592163, "_runtime": 15805.178225040436, "_timestamp": 1585613174.8110945, "_step": 52}
{"Episode reward": 11.345801158902063, "Episode length": 888, "Policy Loss": -0.1939694732427597, "Value Loss": 11.051873207092285, "_runtime": 15806.740943431854, "_timestamp": 1585613176.373813, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1035263538360596, "Value Loss": 0.9005205631256104, "_runtime": 15807.382555484772, "_timestamp": 1585613177.015425, "_step": 54}
{"Episode reward": 61.36248893570128, "Episode length": 388, "Policy Loss": 0.589605450630188, "Value Loss": 26.72174835205078, "_runtime": 15808.268344402313, "_timestamp": 1585613177.901214, "_step": 55}
{"Episode reward": 43.39999999999947, "Episode length": 566, "Policy Loss": 0.13275612890720367, "Value Loss": 17.832836151123047, "_runtime": 15809.835655212402, "_timestamp": 1585613179.4685247, "_step": 56}
{"Episode reward": -99.75375290848176, "Episode length": 999, "Policy Loss": -0.5105900168418884, "Value Loss": 0.7561553716659546, "_runtime": 15811.04179763794, "_timestamp": 1585613180.6746671, "_step": 57}
{"Episode reward": 20.25277213295948, "Episode length": 798, "Policy Loss": 0.7479325532913208, "Value Loss": 14.331015586853027, "_runtime": 15812.608513832092, "_timestamp": 1585613182.2413833, "_step": 58}
{"Episode reward": -99.87694482731027, "Episode length": 999, "Policy Loss": -0.2912601828575134, "Value Loss": 0.9136155247688293, "_runtime": 15814.17388868332, "_timestamp": 1585613183.8067582, "_step": 59}
{"Episode reward": -99.7256122384672, "Episode length": 999, "Policy Loss": -0.17299848794937134, "Value Loss": 2.1182456016540527, "_runtime": 15814.878011226654, "_timestamp": 1585613184.5108807, "_step": 60}
{"Episode reward": 55.998711198567996, "Episode length": 441, "Policy Loss": 0.9712055325508118, "Value Loss": 22.326496124267578, "_runtime": 15816.391072511673, "_timestamp": 1585613186.023942, "_step": 61}
{"Episode reward": 2.7257640643989163, "Episode length": 973, "Policy Loss": 0.15764635801315308, "Value Loss": 10.442458152770996, "_runtime": 15817.886256217957, "_timestamp": 1585613187.5191257, "_step": 62}
{"Episode reward": 4.893251444540184, "Episode length": 953, "Policy Loss": -0.098333939909935, "Value Loss": 10.664887428283691, "_runtime": 15818.510846376419, "_timestamp": 1585613188.1437159, "_step": 63}
{"Episode reward": 60.39041491223005, "Episode length": 398, "Policy Loss": 0.8559427857398987, "Value Loss": 25.340736389160156, "_runtime": 15819.140204191208, "_timestamp": 1585613188.7730737, "_step": 64}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 0.8002487421035767, "Value Loss": 25.825523376464844, "_runtime": 15820.695207595825, "_timestamp": 1585613190.328077, "_step": 65}
{"Episode reward": -99.67875321898471, "Episode length": 999, "Policy Loss": -0.7993887662887573, "Value Loss": 0.7280062437057495, "_runtime": 15821.679581165314, "_timestamp": 1585613191.3124506, "_step": 66}
{"Episode reward": 35.62686049155829, "Episode length": 645, "Policy Loss": 0.16703630983829498, "Value Loss": 15.94878101348877, "_runtime": 15823.165371656418, "_timestamp": 1585613192.7982411, "_step": 67}
{"Episode reward": -99.69156240629825, "Episode length": 999, "Policy Loss": -0.7622827887535095, "Value Loss": 0.2414669543504715, "_runtime": 15823.926954984665, "_timestamp": 1585613193.5598245, "_step": 68}
{"Episode reward": 52.991547856269946, "Episode length": 471, "Policy Loss": 0.8497966527938843, "Value Loss": 20.924945831298828, "_runtime": 15825.468042373657, "_timestamp": 1585613195.1009119, "_step": 69}
{"Episode reward": -99.81191311515728, "Episode length": 999, "Policy Loss": -0.6985053420066833, "Value Loss": 0.039246104657649994, "_runtime": 15827.024609088898, "_timestamp": 1585613196.6574786, "_step": 70}
{"Episode reward": -99.8164818712729, "Episode length": 999, "Policy Loss": -0.7463653087615967, "Value Loss": 0.12886933982372284, "_runtime": 15827.480427503586, "_timestamp": 1585613197.113297, "_step": 71}
{"Episode reward": 70.89999999999986, "Episode length": 291, "Policy Loss": 1.6132216453552246, "Value Loss": 34.63693618774414, "_runtime": 15829.047040462494, "_timestamp": 1585613198.67991, "_step": 72}
{"Episode reward": -99.62117213923344, "Episode length": 999, "Policy Loss": -0.7653270959854126, "Value Loss": 0.16768784821033478, "_runtime": 15830.484640836716, "_timestamp": 1585613200.1175103, "_step": 73}
{"Episode reward": 8.503613822302768, "Episode length": 917, "Policy Loss": -0.013814781792461872, "Value Loss": 10.979215621948242, "_runtime": 15831.999148368835, "_timestamp": 1585613201.6320179, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.844388484954834, "Value Loss": 0.08795981854200363, "_runtime": 15833.590990543365, "_timestamp": 1585613203.22386, "_step": 75}
{"Episode reward": -99.80041306353965, "Episode length": 999, "Policy Loss": -0.9137833118438721, "Value Loss": 0.038330432027578354, "_runtime": 15834.924816131592, "_timestamp": 1585613204.5576856, "_step": 76}
{"Episode reward": 16.010003053746672, "Episode length": 841, "Policy Loss": -0.1959841400384903, "Value Loss": 11.797232627868652, "_runtime": 15836.256885766983, "_timestamp": 1585613205.8897552, "_step": 77}
{"Episode reward": 17.63977359719614, "Episode length": 826, "Policy Loss": -0.23984743654727936, "Value Loss": 12.012404441833496, "_runtime": 15837.47247171402, "_timestamp": 1585613207.1053412, "_step": 78}
{"Episode reward": 24.097386382310688, "Episode length": 760, "Policy Loss": -0.16118113696575165, "Value Loss": 13.045212745666504, "_runtime": 15838.427359104156, "_timestamp": 1585613208.0602286, "_step": 79}
{"Episode reward": 40.42495132151468, "Episode length": 597, "Policy Loss": 0.045814674347639084, "Value Loss": 16.544824600219727, "_runtime": 15839.990087747574, "_timestamp": 1585613209.6229572, "_step": 80}
{"Episode reward": -99.83819759040931, "Episode length": 999, "Policy Loss": -1.1106247901916504, "Value Loss": 0.1437479555606842, "_runtime": 15841.560409545898, "_timestamp": 1585613211.193279, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1116758584976196, "Value Loss": 0.17947199940681458, "_runtime": 15843.004702568054, "_timestamp": 1585613212.637572, "_step": 82}
{"Episode reward": 7.2352142786384235, "Episode length": 929, "Policy Loss": -0.25769177079200745, "Value Loss": 10.694811820983887, "_runtime": 15843.78218793869, "_timestamp": 1585613213.4150574, "_step": 83}
{"Episode reward": 52.67235476588791, "Episode length": 474, "Policy Loss": 0.5885438323020935, "Value Loss": 20.794937133789062, "_runtime": 15845.333198547363, "_timestamp": 1585613214.966068, "_step": 84}
{"Episode reward": 1.5084732508067162, "Episode length": 987, "Policy Loss": -0.1298903524875641, "Value Loss": 9.98943042755127, "_runtime": 15845.963800907135, "_timestamp": 1585613215.5966704, "_step": 85}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 1.0507034063339233, "Value Loss": 26.069313049316406, "_runtime": 15846.450432062149, "_timestamp": 1585613216.0833015, "_step": 86}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 1.4679579734802246, "Value Loss": 31.79146385192871, "_runtime": 15847.57418179512, "_timestamp": 1585613217.2070513, "_step": 87}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.21744750440120697, "Value Loss": 13.923696517944336, "_runtime": 15848.362815856934, "_timestamp": 1585613217.9956853, "_step": 88}
{"Episode reward": 49.08044999015939, "Episode length": 510, "Policy Loss": 0.5567792654037476, "Value Loss": 19.273895263671875, "_runtime": 15849.140892267227, "_timestamp": 1585613218.7737617, "_step": 89}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 0.7046303749084473, "Value Loss": 19.535676956176758, "_runtime": 15850.216520786285, "_timestamp": 1585613219.8493903, "_step": 90}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.026026170700788498, "Value Loss": 14.237513542175293, "_runtime": 15851.222580909729, "_timestamp": 1585613220.8554504, "_step": 91}
{"Episode reward": 35.09999999999941, "Episode length": 649, "Policy Loss": 0.042278971523046494, "Value Loss": 15.1939115524292, "_runtime": 15852.145731210709, "_timestamp": 1585613221.7786007, "_step": 92}
{"Episode reward": 40.3702471577091, "Episode length": 599, "Policy Loss": 0.09946062415838242, "Value Loss": 16.607929229736328, "_runtime": 15853.13215637207, "_timestamp": 1585613222.7650259, "_step": 93}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.14013713598251343, "Value Loss": 15.750743865966797, "_runtime": 15854.675699710846, "_timestamp": 1585613224.3085692, "_step": 94}
{"Episode reward": -99.88716542729968, "Episode length": 999, "Policy Loss": -0.8813737034797668, "Value Loss": 0.08488783985376358, "_runtime": 15855.639950037003, "_timestamp": 1585613225.2728195, "_step": 95}
{"Episode reward": 37.52423117821975, "Episode length": 625, "Policy Loss": 0.2432982623577118, "Value Loss": 15.827753067016602, "_runtime": 15856.821632623672, "_timestamp": 1585613226.454502, "_step": 96}
{"Episode reward": 23.800000000000054, "Episode length": 762, "Policy Loss": 0.054222121834754944, "Value Loss": 12.950348854064941, "_runtime": 15858.197834014893, "_timestamp": 1585613227.8307035, "_step": 97}
{"Episode reward": 12.5424707953825, "Episode length": 877, "Policy Loss": -0.006674787029623985, "Value Loss": 11.240836143493652, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885, 0.01528258342295885]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.006808476056903601, 0.0030706855468451977, 0.012949846684932709, 0.02282900922000408, 0.032708171755075455, 0.04258733242750168, 0.0524664968252182, 0.062345653772354126, 0.07222481817007065, 0.08210398256778717, 0.0919831395149231, 0.10186230391263962, 0.11174146831035614, 0.12162062525749207, 0.131499782204628, 0.1413789540529251, 0.15125811100006104, 0.16113726794719696, 0.17101643979549408, 0.18089559674263, 0.19077475368976593, 0.20065392553806305, 0.21053308248519897, 0.2204122394323349, 0.23029141128063202, 0.24017056822776794, 0.2500497102737427, 0.2599288821220398, 0.2698080241680145, 0.27968719601631165, 0.28956636786460876, 0.2994455099105835, 0.3093246817588806, 0.31920385360717773, 0.32908299565315247, 0.3389621675014496, 0.3488413393497467, 0.35872048139572144, 0.36859965324401855, 0.3784788250923157, 0.3883579671382904, 0.3982371389865875, 0.40811631083488464, 0.4179954528808594, 0.4278746247291565, 0.4377537965774536, 0.44763293862342834, 0.45751211047172546, 0.4673912823200226, 0.4772704243659973, 0.48714959621429443, 0.49702873826026917, 0.5069079399108887, 0.5167871117591858, 0.5266662836074829, 0.53654545545578, 0.5464245676994324, 0.5563037395477295, 0.5661829113960266, 0.5760620832443237, 0.5859412550926208, 0.595820426940918, 0.6056995391845703, 0.6155787110328674, 0.6254578828811646]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02530050091445446, -0.02428557723760605, -0.023270653560757637, -0.022255729883909225, -0.021240806207060814, -0.020225882530212402, -0.01921095885336399, -0.01819603517651558, -0.017181111499667168, -0.016166187822818756, -0.015151264145970345, -0.014136340469121933, -0.013121416792273521, -0.01210649311542511, -0.011091569438576698, -0.010076645761728287, -0.009061722084879875, -0.008046798408031464, -0.007031874731183052, -0.0060169510543346405, -0.005002027377486229, -0.003987103700637817, -0.002972180023789406, -0.0019572563469409943, -0.0009423326700925827, 7.259100675582886e-05, 0.0010875146836042404, 0.002102438360452652, 0.0031173620373010635, 0.004132285714149475, 0.005147209390997887, 0.006162131205201149, 0.00717705674469471, 0.00819198228418827, 0.009206904098391533, 0.010221825912594795, 0.011236751452088356, 0.012251676991581917, 0.01326659880578518, 0.014281520619988441, 0.015296446159482002, 0.016311371698975563, 0.017326293513178825, 0.018341215327382088, 0.01935614086687565, 0.02037106640636921, 0.02138598822057247, 0.022400910034775734, 0.023415835574269295, 0.024430761113762856, 0.025445682927966118, 0.02646060474216938, 0.02747553028166294, 0.028490455821156502, 0.029505377635359764, 0.030520299449563026, 0.03153522312641144, 0.032550148665905, 0.03356507420539856, 0.03457999229431152, 0.035594917833805084, 0.036609843373298645, 0.03762476146221161, 0.03863968700170517, 0.03965461254119873]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 4.0, 9.0, 7.0, 16.0, 9.0, 18.0, 14.0, 7.0, 7.0, 5.0, 16.0, 17.0, 15.0, 49.0, 36.0, 20.0, 26.0, 26.0, 9.0, 7.0, 12.0, 9.0, 13.0, 7.0, 4.0, 14.0, 16.0, 9.0, 6.0, 8.0, 15.0, 13.0, 2.0, 4.0, 3.0, 4.0, 8.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.04181881994009018, -0.04007718712091446, -0.03833555057644844, -0.03659391775727272, -0.0348522812128067, -0.03311064839363098, -0.03136901557445526, -0.029627379029989243, -0.027885746210813522, -0.026144111528992653, -0.024402476847171783, -0.022660842165350914, -0.020919207483530045, -0.019177572801709175, -0.017435939982533455, -0.015694305300712585, -0.013952670618891716, -0.012211035937070847, -0.010469403117895126, -0.008727766573429108, -0.0069861337542533875, -0.005244497209787369, -0.0035028643906116486, -0.0017612315714359283, -1.9595026969909668e-05, 0.0017220377922058105, 0.0034636743366718292, 0.0052053071558475494, 0.00694693997502327, 0.008688576519489288, 0.010430209338665009, 0.012171845883131027, 0.013913478702306747, 0.015655111521482468, 0.017396748065948486, 0.019138380885124207, 0.020880013704299927, 0.022621653974056244, 0.024363286793231964, 0.026104919612407684, 0.027846552431583405, 0.029588185250759125, 0.03132982552051544, 0.03307145833969116, 0.03481309115886688, 0.0365547239780426, 0.03829635679721832, 0.04003799706697464, 0.04177962988615036, 0.04352126270532608, 0.0452628955245018, 0.04700452834367752, 0.04874616861343384, 0.05048780143260956, 0.05222943425178528, 0.053971067070961, 0.05571269989013672, 0.057454340159893036, 0.059195972979068756, 0.060937605798244476, 0.0626792386174202, 0.06442087143659592, 0.06616251170635223, 0.06790414452552795, 0.06964577734470367]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1169050857424736, -0.11115235090255737, -0.10539961606264114, -0.09964688122272491, -0.09389413893222809, -0.08814141154289246, -0.08238866925239563, -0.0766359344124794, -0.07088319957256317, -0.06513046473264694, -0.05937772989273071, -0.053624995052814484, -0.04787225276231766, -0.04211951792240143, -0.0363667830824852, -0.03061404824256897, -0.02486131340265274, -0.01910857856273651, -0.013355843722820282, -0.007603108882904053, -0.0018503740429878235, 0.0039023682475090027, 0.009655095636844635, 0.015407837927341461, 0.021160580217838287, 0.02691330760717392, 0.032666049897670746, 0.03841877728700638, 0.044171519577503204, 0.04992424696683884, 0.05567698925733566, 0.061429716646671295, 0.06718245893716812, 0.07293520122766495, 0.07868792861700058, 0.0844406709074974, 0.09019339829683304, 0.09594614058732986, 0.1016988679766655, 0.10745161026716232, 0.11320433765649796, 0.11895707994699478, 0.12470982223749161, 0.13046255707740784, 0.13621526956558228, 0.1419680118560791, 0.14772075414657593, 0.15347349643707275, 0.15922623872756958, 0.16497895121574402, 0.17073169350624084, 0.17648443579673767, 0.1822371780872345, 0.18798989057540894, 0.19374263286590576, 0.1994953751564026, 0.20524811744689941, 0.21100085973739624, 0.21675357222557068, 0.2225063145160675, 0.22825905680656433, 0.23401179909706116, 0.2397645115852356, 0.24551725387573242, 0.25126999616622925]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 1.0], "bins": [-0.21041478216648102, -0.20448380708694458, -0.19855284690856934, -0.1926218867301941, -0.18669091165065765, -0.18075993657112122, -0.17482897639274597, -0.16889801621437073, -0.1629670411348343, -0.15703606605529785, -0.1511051058769226, -0.14517414569854736, -0.13924317061901093, -0.1333121955394745, -0.12738123536109924, -0.1214502677321434, -0.11551930010318756, -0.10958833247423172, -0.10365736484527588, -0.09772639721632004, -0.0917954295873642, -0.08586446195840836, -0.07993349432945251, -0.07400251924991608, -0.06807155907154083, -0.06214059889316559, -0.05620962381362915, -0.05027864873409271, -0.04434768855571747, -0.038416728377342224, -0.032485753297805786, -0.026554778218269348, -0.020623818039894104, -0.01469285786151886, -0.008761882781982422, -0.002830907702445984, 0.0031000524759292603, 0.009031012654304504, 0.014961987733840942, 0.02089296281337738, 0.026823922991752625, 0.03275488317012787, 0.03868585824966431, 0.044616833329200745, 0.05054779350757599, 0.05647875368595123, 0.062409743666648865, 0.06834070384502411, 0.07427166402339935, 0.0802026242017746, 0.08613358438014984, 0.09206457436084747, 0.09799553453922272, 0.10392649471759796, 0.1098574846982956, 0.11578844487667084, 0.12171940505504608, 0.12765036523342133, 0.13358132541179657, 0.1395123153924942, 0.14544327557086945, 0.1513742357492447, 0.15730522572994232, 0.16323618590831757, 0.1691671460866928]}, "_runtime": 15859.783421039581, "_timestamp": 1585613229.4162905, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7739512920379639, "Value Loss": 0.018407896161079407, "_runtime": 15860.1458735466, "_timestamp": 1585613229.778743, "_step": 99}
{"Episode reward": 79.0193193866871, "Episode length": 210, "Policy Loss": 3.1019792556762695, "Value Loss": 46.81137466430664, "_runtime": 15861.722504854202, "_timestamp": 1585613231.3553743, "_step": 100}
{"Episode reward": -99.58873423777848, "Episode length": 999, "Policy Loss": -0.8350085020065308, "Value Loss": 0.025605017319321632, "_runtime": 15862.659881353378, "_timestamp": 1585613232.2927508, "_step": 101}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 0.2716412842273712, "Value Loss": 17.057289123535156, "_runtime": 15863.629351377487, "_timestamp": 1585613233.2622209, "_step": 102}
{"Episode reward": 36.36081342396729, "Episode length": 637, "Policy Loss": 0.2956348657608032, "Value Loss": 15.339083671569824, "_runtime": 15865.223880052567, "_timestamp": 1585613234.8567495, "_step": 103}
{"Episode reward": -99.69132782632812, "Episode length": 999, "Policy Loss": -1.055060863494873, "Value Loss": 0.029174262657761574, "_runtime": 15866.758330821991, "_timestamp": 1585613236.3912003, "_step": 104}
{"Episode reward": -99.86053550401563, "Episode length": 999, "Policy Loss": -1.1208797693252563, "Value Loss": 0.039034318178892136, "_runtime": 15867.19764471054, "_timestamp": 1585613236.8305142, "_step": 105}
{"Episode reward": 73.6999999999999, "Episode length": 263, "Policy Loss": 1.3419713973999023, "Value Loss": 36.79296112060547, "_runtime": 15868.268703222275, "_timestamp": 1585613237.9015727, "_step": 106}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": -0.21895731985569, "Value Loss": 14.350748062133789, "_runtime": 15869.851820468903, "_timestamp": 1585613239.48469, "_step": 107}
{"Episode reward": -99.68115621630429, "Episode length": 999, "Policy Loss": -1.4172039031982422, "Value Loss": 0.2087436467409134, "_runtime": 15871.36934542656, "_timestamp": 1585613241.002215, "_step": 108}
{"Episode reward": -99.69261344515114, "Episode length": 999, "Policy Loss": -1.5281174182891846, "Value Loss": 0.5049325227737427, "_runtime": 15872.68073272705, "_timestamp": 1585613242.3136022, "_step": 109}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": -0.6520337462425232, "Value Loss": 11.65126895904541, "_runtime": 15874.27097773552, "_timestamp": 1585613243.9038472, "_step": 110}
{"Episode reward": -99.82248342207028, "Episode length": 999, "Policy Loss": -1.4995369911193848, "Value Loss": 0.11347048729658127, "_runtime": 15875.844703435898, "_timestamp": 1585613245.477573, "_step": 111}
{"Episode reward": -99.75413782945695, "Episode length": 999, "Policy Loss": -1.5068858861923218, "Value Loss": 0.12513959407806396, "_runtime": 15877.217481136322, "_timestamp": 1585613246.8503506, "_step": 112}
{"Episode reward": 13.387391542713814, "Episode length": 869, "Policy Loss": -0.7331171631813049, "Value Loss": 11.23483657836914, "_runtime": 15878.811068058014, "_timestamp": 1585613248.4439375, "_step": 113}
{"Episode reward": -99.87607195526222, "Episode length": 999, "Policy Loss": -1.4182358980178833, "Value Loss": 0.08467118442058563, "_runtime": 15879.445511341095, "_timestamp": 1585613249.0783808, "_step": 114}
{"Episode reward": 61.93800263842542, "Episode length": 381, "Policy Loss": 0.49929261207580566, "Value Loss": 25.351839065551758, "_runtime": 15881.018732070923, "_timestamp": 1585613250.6516016, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3005424737930298, "Value Loss": 0.03843756020069122, "_runtime": 15881.396802425385, "_timestamp": 1585613251.029672, "_step": 116}
{"Episode reward": 79.15712963631374, "Episode length": 209, "Policy Loss": 2.7415363788604736, "Value Loss": 46.05979919433594, "_runtime": 15881.753029584885, "_timestamp": 1585613251.385899, "_step": 117}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 2.3329997062683105, "Value Loss": 43.047000885009766, "_runtime": 15883.33959722519, "_timestamp": 1585613252.9724667, "_step": 118}
{"Episode reward": -99.78849152012123, "Episode length": 999, "Policy Loss": -1.2608580589294434, "Value Loss": 0.11802472919225693, "_runtime": 15884.89925456047, "_timestamp": 1585613254.532124, "_step": 119}
{"Episode reward": -99.62717714188481, "Episode length": 999, "Policy Loss": -1.2792689800262451, "Value Loss": 0.34391874074935913, "_runtime": 15885.78957748413, "_timestamp": 1585613255.422447, "_step": 120}
{"Episode reward": 41.399999999999444, "Episode length": 586, "Policy Loss": 0.21299642324447632, "Value Loss": 16.523454666137695, "_runtime": 15886.917659521103, "_timestamp": 1585613256.550529, "_step": 121}
{"Episode reward": 29.930640300735533, "Episode length": 701, "Policy Loss": -0.33944591879844666, "Value Loss": 13.67659854888916, "_runtime": 15888.487689256668, "_timestamp": 1585613258.1205587, "_step": 122}
{"Episode reward": -99.51712169651735, "Episode length": 999, "Policy Loss": -1.2788351774215698, "Value Loss": 0.044363245368003845, "_runtime": 15889.974816322327, "_timestamp": 1585613259.6076858, "_step": 123}
{"Episode reward": 2.8864566079353295, "Episode length": 973, "Policy Loss": -0.621005117893219, "Value Loss": 10.3667631149292, "_runtime": 15891.53895163536, "_timestamp": 1585613261.171821, "_step": 124}
{"Episode reward": -99.56080872707396, "Episode length": 999, "Policy Loss": -1.334328532218933, "Value Loss": 0.15882138907909393, "_runtime": 15892.90684747696, "_timestamp": 1585613262.539717, "_step": 125}
{"Episode reward": 13.443079414126174, "Episode length": 866, "Policy Loss": -0.4613886773586273, "Value Loss": 11.215182304382324, "_runtime": 15893.736646652222, "_timestamp": 1585613263.3695161, "_step": 126}
{"Episode reward": 48.09999999999954, "Episode length": 519, "Policy Loss": 0.43157899379730225, "Value Loss": 18.62147331237793, "_runtime": 15895.338357925415, "_timestamp": 1585613264.9712274, "_step": 127}
{"Episode reward": -99.78657472135826, "Episode length": 999, "Policy Loss": -1.0629230737686157, "Value Loss": 0.0956948772072792, "_runtime": 15896.074043273926, "_timestamp": 1585613265.7069128, "_step": 128}
{"Episode reward": 54.2009620305147, "Episode length": 458, "Policy Loss": 0.6661428809165955, "Value Loss": 21.084529876708984, "_runtime": 15897.592619895935, "_timestamp": 1585613267.2254894, "_step": 129}
{"Episode reward": 0.7813264608396793, "Episode length": 993, "Policy Loss": -0.11467619240283966, "Value Loss": 9.761847496032715, "_runtime": 15899.174196481705, "_timestamp": 1585613268.807066, "_step": 130}
{"Episode reward": -99.82724930078118, "Episode length": 999, "Policy Loss": -0.7050006985664368, "Value Loss": 0.030597683042287827, "_runtime": 15900.691679954529, "_timestamp": 1585613270.3245494, "_step": 131}
{"Episode reward": -99.56815298276351, "Episode length": 999, "Policy Loss": -0.6116984486579895, "Value Loss": 0.2208336442708969, "_runtime": 15902.26750946045, "_timestamp": 1585613271.900379, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5701295733451843, "Value Loss": 0.0356023944914341, "_runtime": 15903.85431098938, "_timestamp": 1585613273.4871805, "_step": 133}
{"Episode reward": -99.78354611731926, "Episode length": 999, "Policy Loss": -0.460809588432312, "Value Loss": 0.08726014941930771, "_runtime": 15905.409384965897, "_timestamp": 1585613275.0422544, "_step": 134}
{"Episode reward": -99.88480539321759, "Episode length": 999, "Policy Loss": -0.4508586525917053, "Value Loss": 0.03900277614593506, "_runtime": 15906.98650097847, "_timestamp": 1585613276.6193705, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42671024799346924, "Value Loss": 0.12717308104038239, "_runtime": 15908.607315778732, "_timestamp": 1585613278.2401853, "_step": 136}
{"Episode reward": -99.81642960347095, "Episode length": 999, "Policy Loss": -0.41686683893203735, "Value Loss": 0.07156194746494293, "_runtime": 15910.184017896652, "_timestamp": 1585613279.8168874, "_step": 137}
{"Episode reward": -99.80074141307128, "Episode length": 999, "Policy Loss": -0.36244335770606995, "Value Loss": 0.021820664405822754, "_runtime": 15911.758919000626, "_timestamp": 1585613281.3917885, "_step": 138}
{"Episode reward": -99.8661098816418, "Episode length": 999, "Policy Loss": -0.3563215136528015, "Value Loss": 0.04740286245942116, "_runtime": 15913.261300563812, "_timestamp": 1585613282.89417, "_step": 139}
{"Episode reward": 5.715873350110982, "Episode length": 943, "Policy Loss": 0.357916921377182, "Value Loss": 10.38166332244873, "_runtime": 15914.82878446579, "_timestamp": 1585613284.461654, "_step": 140}
{"Episode reward": -99.87214213013509, "Episode length": 999, "Policy Loss": -0.29558485746383667, "Value Loss": 0.005107657518237829, "_runtime": 15915.249931573868, "_timestamp": 1585613284.882801, "_step": 141}
{"Episode reward": 76.29852771162982, "Episode length": 238, "Policy Loss": 2.8200016021728516, "Value Loss": 39.44597625732422, "_runtime": 15916.834625005722, "_timestamp": 1585613286.4674945, "_step": 142}
{"Episode reward": -99.6156597455484, "Episode length": 999, "Policy Loss": -0.40184229612350464, "Value Loss": 0.017858650535345078, "_runtime": 15918.23617696762, "_timestamp": 1585613287.8690464, "_step": 143}
{"Episode reward": 11.098256018642175, "Episode length": 891, "Policy Loss": 0.24169103801250458, "Value Loss": 10.6039457321167, "_runtime": 15919.11438202858, "_timestamp": 1585613288.7472515, "_step": 144}
{"Episode reward": 41.43290386339594, "Episode length": 586, "Policy Loss": 0.534284234046936, "Value Loss": 16.33393669128418, "_runtime": 15920.700016736984, "_timestamp": 1585613290.3328862, "_step": 145}
{"Episode reward": -99.80545175755258, "Episode length": 999, "Policy Loss": -0.708340048789978, "Value Loss": 0.02486860752105713, "_runtime": 15921.598417758942, "_timestamp": 1585613291.2312872, "_step": 146}
{"Episode reward": 43.351079435552876, "Episode length": 567, "Policy Loss": 0.48169493675231934, "Value Loss": 16.4764404296875, "_runtime": 15922.710653543472, "_timestamp": 1585613292.343523, "_step": 147}
{"Episode reward": 27.3982859846203, "Episode length": 727, "Policy Loss": 0.09230326861143112, "Value Loss": 13.831610679626465, "_runtime": 15923.692456960678, "_timestamp": 1585613293.3253264, "_step": 148}
{"Episode reward": 38.46232869625032, "Episode length": 616, "Policy Loss": 0.26102134585380554, "Value Loss": 15.356987953186035, "_runtime": 15925.232741832733, "_timestamp": 1585613294.8656113, "_step": 149}
{"Episode reward": -99.86321434015268, "Episode length": 999, "Policy Loss": -0.7465689778327942, "Value Loss": 0.11477645486593246, "_runtime": 15926.773285627365, "_timestamp": 1585613296.406155, "_step": 150}
{"Episode reward": -99.83224429199332, "Episode length": 999, "Policy Loss": -0.7311865091323853, "Value Loss": 0.0780755877494812, "_runtime": 15928.311299562454, "_timestamp": 1585613297.944169, "_step": 151}
{"Episode reward": -99.73967496249685, "Episode length": 999, "Policy Loss": -0.7198373079299927, "Value Loss": 0.026351958513259888, "_runtime": 15929.483792304993, "_timestamp": 1585613299.1166618, "_step": 152}
{"Episode reward": 25.91007219068699, "Episode length": 743, "Policy Loss": 0.32588791847229004, "Value Loss": 13.27135181427002, "_runtime": 15931.041936159134, "_timestamp": 1585613300.6748056, "_step": 153}
{"Episode reward": -99.86720116771617, "Episode length": 999, "Policy Loss": -0.6241916418075562, "Value Loss": 0.038938190788030624, "_runtime": 15932.66293144226, "_timestamp": 1585613302.295801, "_step": 154}
{"Episode reward": -99.89771824478963, "Episode length": 999, "Policy Loss": -0.5684974193572998, "Value Loss": 0.04738175496459007, "_runtime": 15934.220894813538, "_timestamp": 1585613303.8537643, "_step": 155}
{"Episode reward": -99.71354930298263, "Episode length": 999, "Policy Loss": -0.5014205574989319, "Value Loss": 0.026110926643013954, "_runtime": 15935.785381317139, "_timestamp": 1585613305.4182508, "_step": 156}
{"Episode reward": -99.49777736808036, "Episode length": 999, "Policy Loss": -0.419558048248291, "Value Loss": 0.02914303168654442, "_runtime": 15936.578350543976, "_timestamp": 1585613306.21122, "_step": 157}
{"Episode reward": 50.777945829834366, "Episode length": 493, "Policy Loss": 1.136743426322937, "Value Loss": 20.088376998901367, "_runtime": 15937.482611179352, "_timestamp": 1585613307.1154807, "_step": 158}
{"Episode reward": 43.56108993887849, "Episode length": 565, "Policy Loss": 0.9259358644485474, "Value Loss": 17.492307662963867, "_runtime": 15939.045254945755, "_timestamp": 1585613308.6781244, "_step": 159}
{"Episode reward": -99.85655711972946, "Episode length": 999, "Policy Loss": -0.2187846153974533, "Value Loss": 0.004608573392033577, "_runtime": 15940.574937582016, "_timestamp": 1585613310.207807, "_step": 160}
{"Episode reward": -99.58127414896015, "Episode length": 999, "Policy Loss": -0.18704624474048615, "Value Loss": 0.04023585096001625, "_runtime": 15942.11098742485, "_timestamp": 1585613311.743857, "_step": 161}
{"Episode reward": -99.80456869751075, "Episode length": 999, "Policy Loss": -0.12349718064069748, "Value Loss": 0.056043945252895355, "_runtime": 15943.632791757584, "_timestamp": 1585613313.2656612, "_step": 162}
{"Episode reward": 3.482468932868258, "Episode length": 966, "Policy Loss": 0.6322672963142395, "Value Loss": 10.159673690795898, "_runtime": 15945.205533504486, "_timestamp": 1585613314.838403, "_step": 163}
{"Episode reward": -99.7247681664289, "Episode length": 999, "Policy Loss": -0.030362531542778015, "Value Loss": 0.02101258747279644, "_runtime": 15946.78402376175, "_timestamp": 1585613316.4168932, "_step": 164}
{"Episode reward": -99.85784036973351, "Episode length": 999, "Policy Loss": -0.007589823100715876, "Value Loss": 0.0068159340880811214, "_runtime": 15948.36281824112, "_timestamp": 1585613317.9956877, "_step": 165}
{"Episode reward": -99.69143097074563, "Episode length": 999, "Policy Loss": 0.004817537032067776, "Value Loss": 0.024581611156463623, "_runtime": 15949.940026760101, "_timestamp": 1585613319.5728962, "_step": 166}
{"Episode reward": -99.87871904680365, "Episode length": 999, "Policy Loss": 0.019466126337647438, "Value Loss": 0.012052780948579311, "_runtime": 15951.521735668182, "_timestamp": 1585613321.1546052, "_step": 167}
{"Episode reward": -99.67833618726443, "Episode length": 999, "Policy Loss": 0.023599833250045776, "Value Loss": 0.0188725795596838, "_runtime": 15953.09380531311, "_timestamp": 1585613322.7266748, "_step": 168}
{"Episode reward": -99.76433631472615, "Episode length": 999, "Policy Loss": 0.04446035251021385, "Value Loss": 0.013718504458665848, "_runtime": 15954.677151441574, "_timestamp": 1585613324.310021, "_step": 169}
{"Episode reward": -99.80170962328417, "Episode length": 999, "Policy Loss": 0.045129917562007904, "Value Loss": 0.029211947694420815, "_runtime": 15956.302865743637, "_timestamp": 1585613325.9357352, "_step": 170}
{"Episode reward": -99.73477180991183, "Episode length": 999, "Policy Loss": -0.004364010877907276, "Value Loss": 0.11089619994163513, "_runtime": 15957.881952524185, "_timestamp": 1585613327.514822, "_step": 171}
{"Episode reward": -99.84096773473871, "Episode length": 999, "Policy Loss": 0.04518285393714905, "Value Loss": 0.0860389992594719, "_runtime": 15958.80741763115, "_timestamp": 1585613328.440287, "_step": 172}
{"Episode reward": 43.1658494262718, "Episode length": 570, "Policy Loss": 1.2242878675460815, "Value Loss": 17.105775833129883, "_runtime": 15960.404173374176, "_timestamp": 1585613330.0370429, "_step": 173}
{"Episode reward": -99.74191956408184, "Episode length": 999, "Policy Loss": 0.016932034865021706, "Value Loss": 0.024099741131067276, "_runtime": 15962.000279188156, "_timestamp": 1585613331.6331487, "_step": 174}
{"Episode reward": -99.52573684193055, "Episode length": 999, "Policy Loss": 0.014486229047179222, "Value Loss": 0.004214417655020952, "_runtime": 15963.54937171936, "_timestamp": 1585613333.1822412, "_step": 175}
{"Episode reward": -99.82392239207262, "Episode length": 999, "Policy Loss": -0.011918244883418083, "Value Loss": 0.012435153126716614, "_runtime": 15965.144141197205, "_timestamp": 1585613334.7770107, "_step": 176}
{"Episode reward": -99.8684628979289, "Episode length": 999, "Policy Loss": -0.036318372935056686, "Value Loss": 0.004398515447974205, "_runtime": 15966.55943107605, "_timestamp": 1585613336.1923006, "_step": 177}
{"Episode reward": 11.234150633123534, "Episode length": 890, "Policy Loss": 0.7607099413871765, "Value Loss": 11.046707153320312, "_runtime": 15968.141435623169, "_timestamp": 1585613337.774305, "_step": 178}
{"Episode reward": -99.82665934720868, "Episode length": 999, "Policy Loss": -0.08921770006418228, "Value Loss": 0.004437191411852837, "_runtime": 15969.74283671379, "_timestamp": 1585613339.3757062, "_step": 179}
{"Episode reward": -99.79467980051274, "Episode length": 999, "Policy Loss": -0.10976622998714447, "Value Loss": 0.0031856668647378683, "_runtime": 15971.321743488312, "_timestamp": 1585613340.954613, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1395893543958664, "Value Loss": 0.006386263761669397, "_runtime": 15971.86870265007, "_timestamp": 1585613341.5015721, "_step": 181}
{"Episode reward": 68.34785175016133, "Episode length": 317, "Policy Loss": 1.9502357244491577, "Value Loss": 31.168277740478516, "_runtime": 15973.457723617554, "_timestamp": 1585613343.090593, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2156171351671219, "Value Loss": 0.0035128360614180565, "_runtime": 15975.053598165512, "_timestamp": 1585613344.6864676, "_step": 183}
{"Episode reward": -99.76059861352994, "Episode length": 999, "Policy Loss": -0.25870341062545776, "Value Loss": 0.00226106820628047, "_runtime": 15976.574776172638, "_timestamp": 1585613346.2076457, "_step": 184}
{"Episode reward": -99.75835139818815, "Episode length": 999, "Policy Loss": -0.31050410866737366, "Value Loss": 0.022728534415364265, "_runtime": 15977.9324259758, "_timestamp": 1585613347.5652955, "_step": 185}
{"Episode reward": 15.430040360428933, "Episode length": 848, "Policy Loss": 0.47786903381347656, "Value Loss": 11.594971656799316, "_runtime": 15979.554228782654, "_timestamp": 1585613349.1870983, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38609856367111206, "Value Loss": 0.01627640426158905, "_runtime": 15980.542526006699, "_timestamp": 1585613350.1753955, "_step": 187}
{"Episode reward": 37.91929745590254, "Episode length": 621, "Policy Loss": 0.684441089630127, "Value Loss": 15.562187194824219, "_runtime": 15982.12593126297, "_timestamp": 1585613351.7588007, "_step": 188}
{"Episode reward": -99.67871590510337, "Episode length": 999, "Policy Loss": -0.47422850131988525, "Value Loss": 0.03376293182373047, "_runtime": 15983.718234062195, "_timestamp": 1585613353.3511035, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5400051474571228, "Value Loss": 0.055937036871910095, "_runtime": 15985.263105154037, "_timestamp": 1585613354.8959746, "_step": 190}
{"Episode reward": -99.87427275180677, "Episode length": 999, "Policy Loss": -0.5626628994941711, "Value Loss": 0.0161900594830513, "_runtime": 15986.613003015518, "_timestamp": 1585613356.2458725, "_step": 191}
{"Episode reward": 15.487574725575342, "Episode length": 847, "Policy Loss": 0.3424752950668335, "Value Loss": 11.434948921203613, "_runtime": 15987.390531301498, "_timestamp": 1585613357.0234008, "_step": 192}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.805300772190094, "Value Loss": 19.70921516418457, "_runtime": 15988.507421731949, "_timestamp": 1585613358.1402912, "_step": 193}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 0.2955816984176636, "Value Loss": 13.56636905670166, "_runtime": 15989.90919303894, "_timestamp": 1585613359.5420625, "_step": 194}
{"Episode reward": 11.824235319998849, "Episode length": 884, "Policy Loss": -0.05951493978500366, "Value Loss": 11.059418678283691, "_runtime": 15990.937642812729, "_timestamp": 1585613360.5705123, "_step": 195}
{"Episode reward": 33.7926064070309, "Episode length": 663, "Policy Loss": 0.09327010065317154, "Value Loss": 14.42220687866211, "_runtime": 15992.485348701477, "_timestamp": 1585613362.1182182, "_step": 196}
{"Episode reward": -99.76164088663505, "Episode length": 999, "Policy Loss": -0.9866647124290466, "Value Loss": 0.04759164899587631, "_runtime": 15994.065670490265, "_timestamp": 1585613363.69854, "_step": 197}
{"Episode reward": -99.60054038436945, "Episode length": 999, "Policy Loss": -1.0190256834030151, "Value Loss": 0.027818135917186737, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837, -0.08046765625476837]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0], "bins": [-4.183523178100586, -4.114389419555664, -4.045255184173584, -3.976121425628662, -3.906987428665161, -3.83785343170166, -3.7687196731567383, -3.6995856761932373, -3.6304516792297363, -3.5613179206848145, -3.4921839237213135, -3.4230499267578125, -3.3539161682128906, -3.2847821712493896, -3.2156481742858887, -3.146514415740967, -3.077380418777466, -3.008246421813965, -2.939112663269043, -2.869978666305542, -2.800844669342041, -2.731710910797119, -2.662576913833618, -2.593442916870117, -2.5243091583251953, -2.4551751613616943, -2.3860411643981934, -2.3169074058532715, -2.2477734088897705, -2.1786394119262695, -2.1095054149627686, -2.0403716564178467, -1.9712376594543457, -1.9021036624908447, -1.8329699039459229, -1.7638359069824219, -1.694701910018921, -1.625568151473999, -1.556434154510498, -1.487300157546997, -1.418166160583496, -1.3490324020385742, -1.2798984050750732, -1.2107644081115723, -1.1416306495666504, -1.0724966526031494, -1.0033626556396484, -0.9342288970947266, -0.8650949001312256, -0.7959609031677246, -0.7268271446228027, -0.6576931476593018, -0.5885591506958008, -0.5194253921508789, -0.45029139518737793, -0.38115739822387695, -0.3120236396789551, -0.2428896427154541, -0.17375564575195312, -0.10462188720703125, -0.03548765182495117, 0.0336461067199707, 0.10277986526489258, 0.17191410064697266, 0.24104785919189453]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1274910867214203, -0.12508265674114227, -0.12267422676086426, -0.12026578933000565, -0.11785735934972763, -0.11544892936944962, -0.1130404993891716, -0.11063206940889359, -0.10822363197803497, -0.10581520199775696, -0.10340677201747894, -0.10099834203720093, -0.09858991205692291, -0.0961814820766449, -0.09377305209636688, -0.09136461466550827, -0.08895618468523026, -0.08654775470495224, -0.08413931727409363, -0.08173088729381561, -0.0793224573135376, -0.07691402733325958, -0.07450559735298157, -0.07209716737270355, -0.06968873739242554, -0.06728030741214752, -0.06487186998128891, -0.062463440001010895, -0.06005501002073288, -0.057646580040454865, -0.05523814260959625, -0.05282971262931824, -0.05042128264904022, -0.04801285266876221, -0.04560442268848419, -0.04319598525762558, -0.040787555277347565, -0.03837912529706955, -0.035970695316791534, -0.03356226533651352, -0.031153827905654907, -0.028745397925376892, -0.026336967945098877, -0.023928537964820862, -0.021520107984542847, -0.01911167800426483, -0.01670324057340622, -0.014294810593128204, -0.01188638061285019, -0.009477950632572174, -0.007069520652294159, -0.004661083221435547, -0.0022526532411575317, 0.0001557767391204834, 0.0025642067193984985, 0.004972636699676514, 0.007381066679954529, 0.009789496660232544, 0.012197926640510559, 0.014606371521949768, 0.017014801502227783, 0.0194232314825058, 0.021831661462783813, 0.02424009144306183, 0.026648521423339844]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 5.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 4.0, 8.0, 6.0, 7.0, 7.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 12.0, 11.0, 7.0, 4.0, 1.0, 1.0, 5.0, 7.0, 5.0, 1.0, 4.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 7.0, 91.0, 108.0, 4.0, 5.0, 4.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 5.0, 15.0, 9.0, 8.0, 24.0, 30.0, 10.0, 8.0, 3.0], "bins": [-0.2964940071105957, -0.2899279296398163, -0.28336185216903687, -0.27679574489593506, -0.27022966742515564, -0.2636635899543762, -0.2570975124835968, -0.2505314350128174, -0.24396535754203796, -0.23739926517009735, -0.23083318769931793, -0.22426709532737732, -0.2177010178565979, -0.21113494038581848, -0.20456886291503906, -0.19800278544425964, -0.19143669307231903, -0.18487060070037842, -0.178304523229599, -0.17173844575881958, -0.16517236828804016, -0.15860627591609955, -0.15204019844532013, -0.1454741209745407, -0.1389080286026001, -0.13234195113182068, -0.12577587366104126, -0.11920979619026184, -0.11264370381832123, -0.10607762634754181, -0.09951154887676239, -0.09294545650482178, -0.08637937903404236, -0.07981330156326294, -0.07324720919132233, -0.06668113172054291, -0.06011505424976349, -0.053548961877822876, -0.04698288440704346, -0.04041680693626404, -0.03385072946548462, -0.0272846519947052, -0.020718544721603394, -0.014152467250823975, -0.007586389780044556, -0.0010203123092651367, 0.005545765161514282, 0.012111842632293701, 0.018677949905395508, 0.025244027376174927, 0.031810104846954346, 0.038376182317733765, 0.044942259788513184, 0.0515083372592926, 0.05807441473007202, 0.06464052200317383, 0.07120659947395325, 0.07777267694473267, 0.08433875441551208, 0.0909048318862915, 0.09747090935707092, 0.10403701663017273, 0.11060309410095215, 0.11716917157173157, 0.12373524904251099]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1.4101340770721436, -1.3746387958526611, -1.3391435146331787, -1.3036482334136963, -1.2681529521942139, -1.2326576709747314, -1.197162389755249, -1.1616671085357666, -1.1261718273162842, -1.0906765460968018, -1.0551812648773193, -1.0196861028671265, -0.984190821647644, -0.9486955404281616, -0.9132002592086792, -0.8777049779891968, -0.8422096967697144, -0.8067144155502319, -0.7712191343307495, -0.7357238531112671, -0.7002285718917847, -0.664733350276947, -0.6292380690574646, -0.5937427878379822, -0.5582475066184998, -0.5227522253990173, -0.4872569441795349, -0.4517616629600525, -0.41626644134521484, -0.3807711601257324, -0.34527587890625, -0.3097805976867676, -0.27428531646728516, -0.23879003524780273, -0.2032947540283203, -0.1677994728088379, -0.13230419158935547, -0.09680891036987305, -0.061313629150390625, -0.025818347930908203, 0.009676933288574219, 0.04517209529876709, 0.08066737651824951, 0.11616265773773193, 0.15165793895721436, 0.18715322017669678, 0.2226485013961792, 0.2581437826156616, 0.29363906383514404, 0.32913434505462646, 0.3646296262741089, 0.4001249074935913, 0.43562018871307373, 0.47111546993255615, 0.5066107511520386, 0.542106032371521, 0.5776011943817139, 0.6130964756011963, 0.6485917568206787, 0.6840870380401611, 0.7195823192596436, 0.755077600479126, 0.7905728816986084, 0.8260681629180908, 0.8615634441375732]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 3.0, 5.0, 3.0, 1.0, 1.0, 2.0, 3.0, 5.0, 2.0, 2.0, 6.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0], "bins": [-0.26635515689849854, -0.2571004331111908, -0.24784569442272186, -0.23859097063541412, -0.2293362319469452, -0.22008150815963745, -0.2108267843723297, -0.20157204568386078, -0.19231730699539185, -0.1830625832080841, -0.17380785942077637, -0.16455312073230743, -0.1552983969449997, -0.14604365825653076, -0.13678893446922302, -0.1275341957807541, -0.11827947199344635, -0.10902474820613861, -0.09977000951766968, -0.09051528573036194, -0.081260547041893, -0.07200582325458527, -0.06275108456611633, -0.053496360778808594, -0.044241636991500854, -0.03498689830303192, -0.025732174515724182, -0.01647743582725525, -0.00722271203994751, 0.0020320117473602295, 0.011286765336990356, 0.020541489124298096, 0.029796212911605835, 0.039050936698913574, 0.048305660486221313, 0.05756041407585144, 0.06681513786315918, 0.07606986165046692, 0.08532458543777466, 0.09457933902740479, 0.10383406281471252, 0.11308878660202026, 0.122343510389328, 0.13159823417663574, 0.14085298776626587, 0.1501077115535736, 0.15936243534088135, 0.1686171591281891, 0.17787188291549683, 0.18712663650512695, 0.1963813602924347, 0.20563608407974243, 0.21489080786705017, 0.2241455614566803, 0.23340028524398804, 0.24265503883361816, 0.2519097328186035, 0.26116448640823364, 0.270419180393219, 0.2796739339828491, 0.28892868757247925, 0.2981833815574646, 0.3074381351470947, 0.3166928291320801, 0.3259475827217102]}, "_runtime": 15994.947623252869, "_timestamp": 1585613364.5804927, "_step": 198}
{"Episode reward": 44.288225518166506, "Episode length": 558, "Policy Loss": 0.10351564735174179, "Value Loss": 17.78337860107422, "_runtime": 15996.525314807892, "_timestamp": 1585613366.1581843, "_step": 199}
{"Episode reward": -99.8541460275636, "Episode length": 999, "Policy Loss": -0.9757494330406189, "Value Loss": 0.041149720549583435, "_runtime": 15998.124303102493, "_timestamp": 1585613367.7571726, "_step": 200}
{"Episode reward": -99.70207905443246, "Episode length": 999, "Policy Loss": -0.9353605508804321, "Value Loss": 0.03783241659402847, "_runtime": 15999.653798341751, "_timestamp": 1585613369.2866678, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.880532443523407, "Value Loss": 0.034221623092889786, "_runtime": 16001.235656261444, "_timestamp": 1585613370.8685257, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.821378231048584, "Value Loss": 0.03454658016562462, "_runtime": 16002.873559236526, "_timestamp": 1585613372.5064287, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6326329708099365, "Value Loss": 0.30065640807151794, "_runtime": 16004.45686340332, "_timestamp": 1585613374.089733, "_step": 204}
{"Episode reward": -99.78669399323267, "Episode length": 999, "Policy Loss": -0.5998865365982056, "Value Loss": 0.03935094550251961, "_runtime": 16006.049723625183, "_timestamp": 1585613375.682593, "_step": 205}
{"Episode reward": -99.82051840061182, "Episode length": 999, "Policy Loss": -0.4107738137245178, "Value Loss": 0.1470753401517868, "_runtime": 16007.530220985413, "_timestamp": 1585613377.1630905, "_step": 206}
{"Episode reward": 7.873791179038619, "Episode length": 923, "Policy Loss": 0.3793010413646698, "Value Loss": 10.623947143554688, "_runtime": 16009.118638753891, "_timestamp": 1585613378.7515082, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23646824061870575, "Value Loss": 0.012181918136775494, "_runtime": 16010.699830770493, "_timestamp": 1585613380.3327003, "_step": 208}
{"Episode reward": -99.83406279722554, "Episode length": 999, "Policy Loss": -0.10370294004678726, "Value Loss": 0.02608325704932213, "_runtime": 16011.32711482048, "_timestamp": 1585613380.9599843, "_step": 209}
{"Episode reward": 62.69172524772559, "Episode length": 374, "Policy Loss": 1.7635866403579712, "Value Loss": 25.579301834106445, "_runtime": 16012.716018676758, "_timestamp": 1585613382.3488882, "_step": 210}
{"Episode reward": 12.390308619943227, "Episode length": 877, "Policy Loss": 0.7786968350410461, "Value Loss": 10.882346153259277, "_runtime": 16013.369597434998, "_timestamp": 1585613383.002467, "_step": 211}
{"Episode reward": 60.9035416817057, "Episode length": 391, "Policy Loss": 1.7550556659698486, "Value Loss": 24.15995216369629, "_runtime": 16014.862482070923, "_timestamp": 1585613384.4953516, "_step": 212}
{"Episode reward": 2.3619353513013124, "Episode length": 980, "Policy Loss": 0.6705616116523743, "Value Loss": 9.336226463317871, "_runtime": 16016.453361749649, "_timestamp": 1585613386.0862312, "_step": 213}
{"Episode reward": -99.6016063693897, "Episode length": 999, "Policy Loss": -0.09312991797924042, "Value Loss": 0.23540695011615753, "_runtime": 16017.189524888992, "_timestamp": 1585613386.8223944, "_step": 214}
{"Episode reward": 52.976250797044095, "Episode length": 471, "Policy Loss": 1.652208685874939, "Value Loss": 19.57056427001953, "_runtime": 16018.755838394165, "_timestamp": 1585613388.3887079, "_step": 215}
{"Episode reward": -99.89853446194762, "Episode length": 999, "Policy Loss": -0.2809542119503021, "Value Loss": 0.011526893824338913, "_runtime": 16020.344357728958, "_timestamp": 1585613389.9772272, "_step": 216}
{"Episode reward": -99.60832422554822, "Episode length": 999, "Policy Loss": -0.39320898056030273, "Value Loss": 0.006529605481773615, "_runtime": 16021.874272108078, "_timestamp": 1585613391.5071416, "_step": 217}
{"Episode reward": -99.80018752748006, "Episode length": 999, "Policy Loss": -0.49730294942855835, "Value Loss": 0.012494081631302834, "_runtime": 16022.987660884857, "_timestamp": 1585613392.6205304, "_step": 218}
{"Episode reward": 30.477888103481064, "Episode length": 697, "Policy Loss": 0.28841716051101685, "Value Loss": 14.098855972290039, "_runtime": 16024.584765434265, "_timestamp": 1585613394.217635, "_step": 219}
{"Episode reward": -99.67117539583566, "Episode length": 999, "Policy Loss": -0.6540191769599915, "Value Loss": 0.01808490976691246, "_runtime": 16026.16610789299, "_timestamp": 1585613395.7989774, "_step": 220}
{"Episode reward": -99.82083061078889, "Episode length": 999, "Policy Loss": -0.6927911639213562, "Value Loss": 0.013558232225477695, "_runtime": 16027.753412485123, "_timestamp": 1585613397.386282, "_step": 221}
{"Episode reward": -99.87116657513985, "Episode length": 999, "Policy Loss": -0.7410376667976379, "Value Loss": 0.0211420189589262, "_runtime": 16028.492117404938, "_timestamp": 1585613398.124987, "_step": 222}
{"Episode reward": 55.29999999999964, "Episode length": 447, "Policy Loss": 0.6717319488525391, "Value Loss": 20.581371307373047, "_runtime": 16030.082478046417, "_timestamp": 1585613399.7153475, "_step": 223}
{"Episode reward": -99.8039118678295, "Episode length": 999, "Policy Loss": -0.7808730602264404, "Value Loss": 0.02328339032828808, "_runtime": 16031.668988227844, "_timestamp": 1585613401.3018577, "_step": 224}
{"Episode reward": -99.61486861500751, "Episode length": 999, "Policy Loss": -0.764241099357605, "Value Loss": 0.03638938441872597, "_runtime": 16033.208076238632, "_timestamp": 1585613402.8409457, "_step": 225}
{"Episode reward": -99.86314641991491, "Episode length": 999, "Policy Loss": -0.7796897888183594, "Value Loss": 0.018173979595303535, "_runtime": 16034.795298099518, "_timestamp": 1585613404.4281676, "_step": 226}
{"Episode reward": -99.40197161133264, "Episode length": 999, "Policy Loss": -0.7452509999275208, "Value Loss": 0.028343677520751953, "_runtime": 16036.394122362137, "_timestamp": 1585613406.0269918, "_step": 227}
{"Episode reward": -99.65709659666615, "Episode length": 999, "Policy Loss": -0.7288468480110168, "Value Loss": 0.013361095450818539, "_runtime": 16037.157162427902, "_timestamp": 1585613406.790032, "_step": 228}
{"Episode reward": 53.39991128444633, "Episode length": 467, "Policy Loss": 0.7827616930007935, "Value Loss": 19.718299865722656, "_runtime": 16038.747811079025, "_timestamp": 1585613408.3806806, "_step": 229}
{"Episode reward": -99.81392249287897, "Episode length": 999, "Policy Loss": -0.6665782928466797, "Value Loss": 0.03879152610898018, "_runtime": 16040.340323925018, "_timestamp": 1585613409.9731934, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.643312931060791, "Value Loss": 0.039013609290122986, "_runtime": 16041.174938440323, "_timestamp": 1585613410.807808, "_step": 231}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 0.5451934933662415, "Value Loss": 16.33854866027832, "_runtime": 16042.762417793274, "_timestamp": 1585613412.3952873, "_step": 232}
{"Episode reward": -99.66801201191127, "Episode length": 999, "Policy Loss": -0.6710283160209656, "Value Loss": 0.01207820512354374, "_runtime": 16043.423429727554, "_timestamp": 1585613413.0562992, "_step": 233}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 0.8947808742523193, "Value Loss": 22.327428817749023, "_runtime": 16044.673754930496, "_timestamp": 1585613414.3066244, "_step": 234}
{"Episode reward": 19.11881864618077, "Episode length": 810, "Policy Loss": 0.13225683569908142, "Value Loss": 11.456774711608887, "_runtime": 16046.261399507523, "_timestamp": 1585613415.894269, "_step": 235}
{"Episode reward": -99.8474673510515, "Episode length": 999, "Policy Loss": -0.8475520014762878, "Value Loss": 0.02964167483150959, "_runtime": 16047.773373126984, "_timestamp": 1585613417.4062426, "_step": 236}
{"Episode reward": -99.51307491650667, "Episode length": 999, "Policy Loss": -0.9020731449127197, "Value Loss": 0.04046698659658432, "_runtime": 16049.348063707352, "_timestamp": 1585613418.9809332, "_step": 237}
{"Episode reward": -99.70904966341193, "Episode length": 999, "Policy Loss": -0.944466233253479, "Value Loss": 0.02793588489294052, "_runtime": 16050.97991156578, "_timestamp": 1585613420.612781, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9562289118766785, "Value Loss": 0.06803727895021439, "_runtime": 16052.153794288635, "_timestamp": 1585613421.7866638, "_step": 239}
{"Episode reward": 26.348087591864086, "Episode length": 738, "Policy Loss": 0.2012225091457367, "Value Loss": 13.393609046936035, "_runtime": 16053.742539167404, "_timestamp": 1585613423.3754086, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9175131916999817, "Value Loss": 0.07118940353393555, "_runtime": 16055.344421863556, "_timestamp": 1585613424.9772913, "_step": 241}
{"Episode reward": -99.80342579791183, "Episode length": 999, "Policy Loss": -0.8919097781181335, "Value Loss": 0.1819276213645935, "_runtime": 16056.901557445526, "_timestamp": 1585613426.534427, "_step": 242}
{"Episode reward": -99.88904739862633, "Episode length": 999, "Policy Loss": -0.7451722621917725, "Value Loss": 0.17688843607902527, "_runtime": 16058.2050614357, "_timestamp": 1585613427.837931, "_step": 243}
{"Episode reward": 18.32130545284636, "Episode length": 818, "Policy Loss": 0.17888663709163666, "Value Loss": 10.690990447998047, "_runtime": 16059.657828330994, "_timestamp": 1585613429.2906978, "_step": 244}
{"Episode reward": 8.335336178169584, "Episode length": 917, "Policy Loss": 0.22505460679531097, "Value Loss": 10.090218544006348, "_runtime": 16061.241702795029, "_timestamp": 1585613430.8745723, "_step": 245}
{"Episode reward": -99.60703304672941, "Episode length": 999, "Policy Loss": -0.4171943664550781, "Value Loss": 0.04718610271811485, "_runtime": 16062.814869880676, "_timestamp": 1585613432.4477394, "_step": 246}
{"Episode reward": -99.83639733055466, "Episode length": 999, "Policy Loss": -0.33348870277404785, "Value Loss": 0.029837070032954216, "_runtime": 16064.38556098938, "_timestamp": 1585613434.0184305, "_step": 247}
{"Episode reward": -99.71879667641922, "Episode length": 999, "Policy Loss": -0.25737103819847107, "Value Loss": 0.07544270902872086, "_runtime": 16065.617459774017, "_timestamp": 1585613435.2503293, "_step": 248}
{"Episode reward": 22.9003719679081, "Episode length": 771, "Policy Loss": 0.6369742751121521, "Value Loss": 11.183087348937988, "_runtime": 16067.013781309128, "_timestamp": 1585613436.6466508, "_step": 249}
{"Episode reward": 12.562765720464043, "Episode length": 876, "Policy Loss": 0.5867335200309753, "Value Loss": 10.017075538635254, "_runtime": 16068.607437133789, "_timestamp": 1585613438.2403066, "_step": 250}
{"Episode reward": -99.77600514264638, "Episode length": 999, "Policy Loss": -0.2392238974571228, "Value Loss": 0.18182089924812317, "_runtime": 16070.172423124313, "_timestamp": 1585613439.8052926, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.249371737241745, "Value Loss": 0.007125156000256538, "_runtime": 16071.567291736603, "_timestamp": 1585613441.2001612, "_step": 252}
{"Episode reward": 12.317458494171277, "Episode length": 877, "Policy Loss": 0.4829482138156891, "Value Loss": 9.848666191101074, "_runtime": 16072.734008789062, "_timestamp": 1585613442.3668783, "_step": 253}
{"Episode reward": 27.2343205370706, "Episode length": 730, "Policy Loss": 0.5264365673065186, "Value Loss": 11.800408363342285, "_runtime": 16074.36021566391, "_timestamp": 1585613443.9930851, "_step": 254}
{"Episode reward": -99.72595121685742, "Episode length": 999, "Policy Loss": -0.4021085202693939, "Value Loss": 0.07720860838890076, "_runtime": 16075.942494869232, "_timestamp": 1585613445.5753644, "_step": 255}
{"Episode reward": -99.74469247246022, "Episode length": 999, "Policy Loss": -0.43109115958213806, "Value Loss": 0.029397759586572647, "_runtime": 16077.000754356384, "_timestamp": 1585613446.6336238, "_step": 256}
{"Episode reward": 33.514672671025124, "Episode length": 667, "Policy Loss": 0.5565332174301147, "Value Loss": 13.354594230651855, "_runtime": 16078.569007873535, "_timestamp": 1585613448.2018774, "_step": 257}
{"Episode reward": -99.71053869966278, "Episode length": 999, "Policy Loss": -0.4352375566959381, "Value Loss": 0.025137847289443016, "_runtime": 16080.139171361923, "_timestamp": 1585613449.7720408, "_step": 258}
{"Episode reward": -99.81723967774165, "Episode length": 999, "Policy Loss": -0.4228062033653259, "Value Loss": 0.01854591816663742, "_runtime": 16081.68278002739, "_timestamp": 1585613451.3156495, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3912772834300995, "Value Loss": 0.03757532313466072, "_runtime": 16083.244253873825, "_timestamp": 1585613452.8771234, "_step": 260}
{"Episode reward": -99.7593115680837, "Episode length": 999, "Policy Loss": -0.3589397966861725, "Value Loss": 0.15801747143268585, "_runtime": 16084.823919296265, "_timestamp": 1585613454.4567888, "_step": 261}
{"Episode reward": -99.74060939345371, "Episode length": 999, "Policy Loss": -0.3607838749885559, "Value Loss": 0.09476933628320694, "_runtime": 16086.398858070374, "_timestamp": 1585613456.0317276, "_step": 262}
{"Episode reward": -99.7725768477642, "Episode length": 999, "Policy Loss": -0.37079042196273804, "Value Loss": 0.11535271257162094, "_runtime": 16086.791434049606, "_timestamp": 1585613456.4243035, "_step": 263}
{"Episode reward": 77.96622690474611, "Episode length": 221, "Policy Loss": 2.8796777725219727, "Value Loss": 38.814388275146484, "_runtime": 16088.363839387894, "_timestamp": 1585613457.9967089, "_step": 264}
{"Episode reward": -99.89170774370292, "Episode length": 999, "Policy Loss": -0.482220858335495, "Value Loss": 0.024896349757909775, "_runtime": 16089.815673828125, "_timestamp": 1585613459.4485433, "_step": 265}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": 0.21535161137580872, "Value Loss": 10.504057884216309, "_runtime": 16091.324580907822, "_timestamp": 1585613460.9574504, "_step": 266}
{"Episode reward": -99.80850000427895, "Episode length": 999, "Policy Loss": -0.5489887595176697, "Value Loss": 0.04701514169573784, "_runtime": 16092.906600236893, "_timestamp": 1585613462.5394697, "_step": 267}
{"Episode reward": -99.88763903528313, "Episode length": 999, "Policy Loss": -0.4517812430858612, "Value Loss": 0.43795841932296753, "_runtime": 16093.800711631775, "_timestamp": 1585613463.433581, "_step": 268}
{"Episode reward": 44.39395869933018, "Episode length": 557, "Policy Loss": 1.1519362926483154, "Value Loss": 18.337657928466797, "_runtime": 16095.363507509232, "_timestamp": 1585613464.996377, "_step": 269}
{"Episode reward": -99.59426578581194, "Episode length": 999, "Policy Loss": -0.14269010722637177, "Value Loss": 0.030989279970526695, "_runtime": 16095.93130350113, "_timestamp": 1585613465.564173, "_step": 270}
{"Episode reward": 66.84749633667505, "Episode length": 332, "Policy Loss": 2.0964407920837402, "Value Loss": 29.926490783691406, "_runtime": 16096.28180193901, "_timestamp": 1585613465.9146714, "_step": 271}
{"Episode reward": 78.87790271302217, "Episode length": 212, "Policy Loss": 3.340383291244507, "Value Loss": 46.656009674072266, "_runtime": 16097.852358341217, "_timestamp": 1585613467.4852278, "_step": 272}
{"Episode reward": -99.8000340324114, "Episode length": 999, "Policy Loss": 0.3355988562107086, "Value Loss": 0.042662933468818665, "_runtime": 16098.339863538742, "_timestamp": 1585613467.972733, "_step": 273}
{"Episode reward": 69.35731841016079, "Episode length": 308, "Policy Loss": 2.7741897106170654, "Value Loss": 32.22715759277344, "_runtime": 16099.869414567947, "_timestamp": 1585613469.502284, "_step": 274}
{"Episode reward": -99.76778486484989, "Episode length": 999, "Policy Loss": 0.3435106575489044, "Value Loss": 0.42663678526878357, "_runtime": 16101.464829444885, "_timestamp": 1585613471.097699, "_step": 275}
{"Episode reward": -99.66829622119992, "Episode length": 999, "Policy Loss": 0.35935187339782715, "Value Loss": 0.11763891577720642, "_runtime": 16102.974702596664, "_timestamp": 1585613472.607572, "_step": 276}
{"Episode reward": -99.71847048185161, "Episode length": 999, "Policy Loss": 0.34727272391319275, "Value Loss": 0.020823273807764053, "_runtime": 16104.498010635376, "_timestamp": 1585613474.13088, "_step": 277}
{"Episode reward": 2.5000000000012648, "Episode length": 975, "Policy Loss": 0.9729158282279968, "Value Loss": 10.277787208557129, "_runtime": 16106.09834074974, "_timestamp": 1585613475.7312102, "_step": 278}
{"Episode reward": -99.85081955166393, "Episode length": 999, "Policy Loss": 0.23181916773319244, "Value Loss": 0.09917854517698288, "_runtime": 16107.667128801346, "_timestamp": 1585613477.2999983, "_step": 279}
{"Episode reward": -99.83802037471766, "Episode length": 999, "Policy Loss": 0.20207399129867554, "Value Loss": 0.03503131493926048, "_runtime": 16109.112941980362, "_timestamp": 1585613478.7458115, "_step": 280}
{"Episode reward": 8.646676821798067, "Episode length": 917, "Policy Loss": 0.7844519019126892, "Value Loss": 10.85622787475586, "_runtime": 16110.71115231514, "_timestamp": 1585613480.3440218, "_step": 281}
{"Episode reward": 0.9931291026775284, "Episode length": 992, "Policy Loss": 0.7812163233757019, "Value Loss": 9.991060256958008, "_runtime": 16112.286854028702, "_timestamp": 1585613481.9197235, "_step": 282}
{"Episode reward": -99.83360835949284, "Episode length": 999, "Policy Loss": -0.06730182468891144, "Value Loss": 0.19306625425815582, "_runtime": 16113.860388040543, "_timestamp": 1585613483.4932575, "_step": 283}
{"Episode reward": -99.78731063129241, "Episode length": 999, "Policy Loss": -0.023770039901137352, "Value Loss": 0.011608809232711792, "_runtime": 16115.458111047745, "_timestamp": 1585613485.0909805, "_step": 284}
{"Episode reward": -99.85304905513628, "Episode length": 999, "Policy Loss": -0.05935823544859886, "Value Loss": 0.003862406127154827, "_runtime": 16117.043610811234, "_timestamp": 1585613486.6764803, "_step": 285}
{"Episode reward": -99.84754718625778, "Episode length": 999, "Policy Loss": -0.09750732034444809, "Value Loss": 0.005334925372153521, "_runtime": 16118.235776662827, "_timestamp": 1585613487.8686461, "_step": 286}
{"Episode reward": 25.371637847903145, "Episode length": 749, "Policy Loss": 0.7721768617630005, "Value Loss": 13.362083435058594, "_runtime": 16118.97725892067, "_timestamp": 1585613488.6101284, "_step": 287}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 1.384909987449646, "Value Loss": 22.403182983398438, "_runtime": 16120.572028398514, "_timestamp": 1585613490.2048979, "_step": 288}
{"Episode reward": -99.79227142426977, "Episode length": 999, "Policy Loss": -0.2717497646808624, "Value Loss": 0.006210165563970804, "_runtime": 16122.186901569366, "_timestamp": 1585613491.819771, "_step": 289}
{"Episode reward": -99.80001873376175, "Episode length": 999, "Policy Loss": -0.36334192752838135, "Value Loss": 0.003586733480915427, "_runtime": 16123.588234901428, "_timestamp": 1585613493.2211044, "_step": 290}
{"Episode reward": 9.269798804471222, "Episode length": 911, "Policy Loss": 0.3213745653629303, "Value Loss": 10.88833999633789, "_runtime": 16125.188224554062, "_timestamp": 1585613494.821094, "_step": 291}
{"Episode reward": -99.70415675465344, "Episode length": 999, "Policy Loss": -0.5157238245010376, "Value Loss": 0.010264270938932896, "_runtime": 16126.764909982681, "_timestamp": 1585613496.3977795, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.598569929599762, "Value Loss": 0.037043455988168716, "_runtime": 16128.3194065094, "_timestamp": 1585613497.952276, "_step": 293}
{"Episode reward": -99.5936964167501, "Episode length": 999, "Policy Loss": -0.6265963315963745, "Value Loss": 0.01675228402018547, "_runtime": 16129.582725286484, "_timestamp": 1585613499.2155948, "_step": 294}
{"Episode reward": 21.354177515744425, "Episode length": 788, "Policy Loss": 0.2204447090625763, "Value Loss": 12.540823936462402, "_runtime": 16130.434048891068, "_timestamp": 1585613500.0669184, "_step": 295}
{"Episode reward": 47.267778745362996, "Episode length": 530, "Policy Loss": 0.5716167688369751, "Value Loss": 18.511913299560547, "_runtime": 16132.015971899033, "_timestamp": 1585613501.6488414, "_step": 296}
{"Episode reward": -99.80000610351422, "Episode length": 999, "Policy Loss": -0.7698790431022644, "Value Loss": 0.01914382539689541, "_runtime": 16133.263385295868, "_timestamp": 1585613502.8962548, "_step": 297}
{"Episode reward": 21.77779805667251, "Episode length": 784, "Policy Loss": 0.3831380009651184, "Value Loss": 12.472723960876465, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625, -0.03543828800320625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-3.0143795013427734, -2.961794376373291, -2.9092090129852295, -2.856623888015747, -2.8040385246276855, -2.751453399658203, -2.6988680362701416, -2.646282911300659, -2.5936975479125977, -2.5411124229431152, -2.4885270595550537, -2.4359419345855713, -2.3833565711975098, -2.3307714462280273, -2.278186082839966, -2.2256009578704834, -2.173015594482422, -2.1204304695129395, -2.067845106124878, -2.0152599811553955, -1.9626747369766235, -1.9100894927978516, -1.8575042486190796, -1.8049190044403076, -1.7523337602615356, -1.6997485160827637, -1.6471632719039917, -1.5945780277252197, -1.5419927835464478, -1.4894075393676758, -1.4368222951889038, -1.3842370510101318, -1.3316518068313599, -1.279066562652588, -1.226481318473816, -1.173896074295044, -1.121310830116272, -1.0687255859375, -1.016140341758728, -0.963555097579956, -0.9109699726104736, -0.8583846092224121, -0.8057994842529297, -0.7532141208648682, -0.7006289958953857, -0.6480436325073242, -0.5954585075378418, -0.5428731441497803, -0.49028801918029785, -0.43770265579223633, -0.3851175308227539, -0.3325321674346924, -0.27994704246520996, -0.22736167907714844, -0.17477655410766602, -0.12219119071960449, -0.06960606575012207, -0.017020702362060547, 0.035564422607421875, 0.0881497859954834, 0.14073491096496582, 0.19332027435302734, 0.24590539932250977, 0.2984907627105713, 0.3510758876800537]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0708499625325203, -0.06928510963916779, -0.06772026419639587, -0.06615541130304337, -0.06459056586027145, -0.06302571296691895, -0.061460863798856735, -0.059896014630794525, -0.05833116173744202, -0.056766312569379807, -0.055201463401317596, -0.053636614233255386, -0.052071765065193176, -0.05050691217184067, -0.048942066729068756, -0.04737721383571625, -0.04581236466765404, -0.04424751549959183, -0.04268266260623932, -0.04111781716346741, -0.0395529642701149, -0.03798811510205269, -0.03642326593399048, -0.03485841676592827, -0.03329356759786606, -0.03172871470451355, -0.03016386553645134, -0.02859901636838913, -0.02703416720032692, -0.02546931803226471, -0.0239044651389122, -0.02233961597084999, -0.02077476680278778, -0.01920991763472557, -0.01764506846666336, -0.016080215573310852, -0.014515366405248642, -0.012950517237186432, -0.011385668069124222, -0.009820818901062012, -0.008255966007709503, -0.0066911205649375916, -0.005126267671585083, -0.0035614147782325745, -0.001996569335460663, -0.0004317164421081543, 0.0011331290006637573, 0.002697981894016266, 0.0042628273367881775, 0.005827680230140686, 0.007392533123493195, 0.008957378566265106, 0.010522231459617615, 0.012087076902389526, 0.013651929795742035, 0.015216782689094543, 0.016781628131866455, 0.018346481025218964, 0.019911326467990875, 0.021476179361343384, 0.023041032254695892, 0.024605877697467804, 0.026170730590820312, 0.027735576033592224, 0.029300428926944733]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 1.0, 5.0, 5.0, 3.0, 3.0, 5.0, 0.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 5.0, 6.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 6.0, 4.0, 6.0, 2.0, 3.0, 9.0, 7.0, 2.0, 4.0, 13.0, 41.0, 117.0, 59.0, 17.0, 14.0, 6.0, 3.0, 1.0, 3.0, 12.0, 7.0, 21.0, 22.0, 16.0, 4.0, 6.0], "bins": [-0.29226410388946533, -0.2863726317882538, -0.28048115968704224, -0.2745896875858307, -0.26869821548461914, -0.2628067433834076, -0.25691527128219604, -0.2510237991809845, -0.24513232707977295, -0.2392408549785614, -0.23334938287734985, -0.2274579107761383, -0.22156642377376556, -0.21567495167255402, -0.20978347957134247, -0.20389200747013092, -0.19800053536891937, -0.19210906326770782, -0.18621759116649628, -0.18032611906528473, -0.17443464696407318, -0.16854315996170044, -0.16265170276165009, -0.15676023066043854, -0.1508687436580658, -0.14497727155685425, -0.1390857994556427, -0.13319432735443115, -0.1273028552532196, -0.12141138315200806, -0.11551991105079651, -0.10962843894958496, -0.10373696684837341, -0.09784549474716187, -0.09195402264595032, -0.08606255054473877, -0.08017107844352722, -0.07427960634231567, -0.06838813424110413, -0.06249666213989258, -0.05660519003868103, -0.05071370303630829, -0.04482223093509674, -0.03893077373504639, -0.03303930163383484, -0.02714782953262329, -0.021256357431411743, -0.015364885330200195, -0.00947338342666626, -0.003581911325454712, 0.002309560775756836, 0.008201032876968384, 0.014092504978179932, 0.01998397707939148, 0.025875449180603027, 0.031766921281814575, 0.03765839338302612, 0.04354986548423767, 0.04944133758544922, 0.05533280968666077, 0.061224281787872314, 0.06711575388908386, 0.07300722599029541, 0.07889869809150696, 0.0847901701927185]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.7027549147605896, -0.6868332028388977, -0.6709114909172058, -0.6549898386001587, -0.6390681266784668, -0.6231464147567749, -0.607224702835083, -0.5913029909133911, -0.5753812789916992, -0.5594595670700073, -0.5435378551483154, -0.5276162028312683, -0.5116944909095764, -0.4957727789878845, -0.4798510670661926, -0.46392935514450073, -0.4480076730251312, -0.43208596110343933, -0.4161642789840698, -0.40024256706237793, -0.38432085514068604, -0.36839917302131653, -0.35247746109962463, -0.33655574917793274, -0.32063406705856323, -0.30471235513687134, -0.28879064321517944, -0.27286893129348755, -0.25694724917411804, -0.24102553725242615, -0.22510382533073425, -0.20918214321136475, -0.19326043128967285, -0.17733871936798096, -0.16141700744628906, -0.14549529552459717, -0.12957364320755005, -0.11365193128585815, -0.09773021936416626, -0.08180850744247437, -0.06588679552078247, -0.049965083599090576, -0.03404343128204346, -0.018121719360351562, -0.002200007438659668, 0.013721704483032227, 0.02964341640472412, 0.045565128326416016, 0.061486780643463135, 0.07740849256515503, 0.09333020448684692, 0.10925191640853882, 0.1251736283302307, 0.1410953402519226, 0.1570170521736145, 0.17293870449066162, 0.18886041641235352, 0.2047821283340454, 0.2207038402557373, 0.2366255521774292, 0.2525472640991211, 0.2684689164161682, 0.2843906283378601, 0.300312340259552, 0.3162340521812439]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 3.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0], "bins": [-0.5199938416481018, -0.5013774037361145, -0.4827609360218048, -0.4641444683074951, -0.4455280303955078, -0.4269115626811981, -0.4082950949668884, -0.3896786570549011, -0.37106218934059143, -0.35244572162628174, -0.33382928371429443, -0.31521281599998474, -0.29659634828567505, -0.27797991037368774, -0.25936344265937805, -0.24074700474739075, -0.22213053703308105, -0.20351406931877136, -0.18489763140678406, -0.16628116369247437, -0.14766472578048706, -0.12904825806617737, -0.11043179035186768, -0.09181535243988037, -0.07319888472557068, -0.054582417011260986, -0.03596597909927368, -0.017349541187286377, 0.0012669563293457031, 0.019883394241333008, 0.03849983215332031, 0.05711632966995239, 0.0757327675819397, 0.094349205493927, 0.11296570301055908, 0.1315821409225464, 0.1501985788345337, 0.16881507635116577, 0.18743151426315308, 0.20604795217514038, 0.22466439008712769, 0.24328088760375977, 0.26189732551574707, 0.2805137634277344, 0.29913026094436646, 0.31774669885635376, 0.33636313676834106, 0.35497963428497314, 0.37359607219696045, 0.39221251010894775, 0.41082900762557983, 0.42944544553756714, 0.44806188344955444, 0.4666783809661865, 0.48529475927352905, 0.5039113163948059, 0.5225277543067932, 0.5411441922187805, 0.5597606301307678, 0.5783770680427551, 0.5969935059547424, 0.6156100630760193, 0.6342265009880066, 0.6528429388999939, 0.6714593768119812]}, "_runtime": 16134.814363718033, "_timestamp": 1585613504.4472332, "_step": 298}
{"Episode reward": -99.81961077758902, "Episode length": 999, "Policy Loss": -0.8758832812309265, "Value Loss": 0.06227743253111839, "_runtime": 16136.400037288666, "_timestamp": 1585613506.0329068, "_step": 299}
{"Episode reward": -99.8334261645782, "Episode length": 999, "Policy Loss": -0.9293573498725891, "Value Loss": 0.0777098536491394, "_runtime": 16137.971648693085, "_timestamp": 1585613507.6045182, "_step": 300}
{"Episode reward": -99.81344459364051, "Episode length": 999, "Policy Loss": -0.9269942045211792, "Value Loss": 0.08336750417947769, "_runtime": 16139.55081486702, "_timestamp": 1585613509.1836843, "_step": 301}
{"Episode reward": -99.80042412020126, "Episode length": 999, "Policy Loss": -0.8950230479240417, "Value Loss": 0.03284062445163727, "_runtime": 16140.504811525345, "_timestamp": 1585613510.137681, "_step": 302}
{"Episode reward": 40.99999999999944, "Episode length": 590, "Policy Loss": 0.22591038048267365, "Value Loss": 16.612972259521484, "_runtime": 16142.100778579712, "_timestamp": 1585613511.733648, "_step": 303}
{"Episode reward": -99.72114480391473, "Episode length": 999, "Policy Loss": -0.8978052139282227, "Value Loss": 0.1020793616771698, "_runtime": 16142.739913225174, "_timestamp": 1585613512.3727827, "_step": 304}
{"Episode reward": 61.57389553450021, "Episode length": 385, "Policy Loss": 0.8830921649932861, "Value Loss": 25.085922241210938, "_runtime": 16143.502560138702, "_timestamp": 1585613513.1354296, "_step": 305}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 0.6553404331207275, "Value Loss": 20.045560836791992, "_runtime": 16145.095364570618, "_timestamp": 1585613514.728234, "_step": 306}
{"Episode reward": -99.73701304504509, "Episode length": 999, "Policy Loss": -0.8360109329223633, "Value Loss": 0.06824519485235214, "_runtime": 16146.662729740143, "_timestamp": 1585613516.2955992, "_step": 307}
{"Episode reward": -99.76130802128324, "Episode length": 999, "Policy Loss": -0.7821723222732544, "Value Loss": 0.025728458538651466, "_runtime": 16148.192180395126, "_timestamp": 1585613517.8250499, "_step": 308}
{"Episode reward": -99.76518301535258, "Episode length": 999, "Policy Loss": -0.7575938105583191, "Value Loss": 0.06685496866703033, "_runtime": 16149.562883615494, "_timestamp": 1585613519.195753, "_step": 309}
{"Episode reward": 13.9795727338648, "Episode length": 861, "Policy Loss": 0.07117119431495667, "Value Loss": 11.290403366088867, "_runtime": 16151.144129276276, "_timestamp": 1585613520.7769988, "_step": 310}
{"Episode reward": -99.64129406579166, "Episode length": 999, "Policy Loss": -0.702181875705719, "Value Loss": 0.14063242077827454, "_runtime": 16151.935718536377, "_timestamp": 1585613521.568588, "_step": 311}
{"Episode reward": 51.75048406233505, "Episode length": 484, "Policy Loss": 0.7366067171096802, "Value Loss": 19.663480758666992, "_runtime": 16153.105303764343, "_timestamp": 1585613522.7381732, "_step": 312}
{"Episode reward": 26.794665863434673, "Episode length": 734, "Policy Loss": 0.28168025612831116, "Value Loss": 12.926265716552734, "_runtime": 16154.405179023743, "_timestamp": 1585613524.0380485, "_step": 313}
{"Episode reward": 18.170330318808936, "Episode length": 819, "Policy Loss": 0.1704767495393753, "Value Loss": 11.843213081359863, "_runtime": 16155.945924520493, "_timestamp": 1585613525.578794, "_step": 314}
{"Episode reward": -99.82165623018379, "Episode length": 999, "Policy Loss": -0.6507325172424316, "Value Loss": 0.01186449360102415, "_runtime": 16157.513813257217, "_timestamp": 1585613527.1466827, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6602658629417419, "Value Loss": 0.1469266712665558, "_runtime": 16159.068663358688, "_timestamp": 1585613528.7015328, "_step": 316}
{"Episode reward": -99.74068981157477, "Episode length": 999, "Policy Loss": -0.6604547500610352, "Value Loss": 0.014277572743594646, "_runtime": 16160.636452674866, "_timestamp": 1585613530.2693222, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6550102233886719, "Value Loss": 0.025305600836873055, "_runtime": 16162.21546792984, "_timestamp": 1585613531.8483374, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6010493040084839, "Value Loss": 0.07948680222034454, "_runtime": 16163.3708152771, "_timestamp": 1585613533.0036848, "_step": 319}
{"Episode reward": 26.70783578120161, "Episode length": 733, "Policy Loss": 0.3394269049167633, "Value Loss": 13.320024490356445, "_runtime": 16164.387855529785, "_timestamp": 1585613534.020725, "_step": 320}
{"Episode reward": 35.786001513897745, "Episode length": 643, "Policy Loss": 0.5119484066963196, "Value Loss": 15.183350563049316, "_runtime": 16165.962198972702, "_timestamp": 1585613535.5950685, "_step": 321}
{"Episode reward": -99.75141179386853, "Episode length": 999, "Policy Loss": -0.5094220042228699, "Value Loss": 0.03291016072034836, "_runtime": 16167.510727882385, "_timestamp": 1585613537.1435974, "_step": 322}
{"Episode reward": -99.80177319433865, "Episode length": 999, "Policy Loss": -0.475572407245636, "Value Loss": 0.009399582631886005, "_runtime": 16169.034041166306, "_timestamp": 1585613538.6669106, "_step": 323}
{"Episode reward": -99.79640918236552, "Episode length": 999, "Policy Loss": -0.4285088777542114, "Value Loss": 0.005659807473421097, "_runtime": 16170.654288053513, "_timestamp": 1585613540.2871575, "_step": 324}
{"Episode reward": -99.71651235408942, "Episode length": 999, "Policy Loss": -0.38503164052963257, "Value Loss": 0.0044469027779996395, "_runtime": 16172.219098806381, "_timestamp": 1585613541.8519683, "_step": 325}
{"Episode reward": -99.78046381829633, "Episode length": 999, "Policy Loss": -0.35088270902633667, "Value Loss": 0.02503838948905468, "_runtime": 16173.788977861404, "_timestamp": 1585613543.4218473, "_step": 326}
{"Episode reward": -99.80127291390532, "Episode length": 999, "Policy Loss": -0.29700183868408203, "Value Loss": 0.007783052045851946, "_runtime": 16175.004880905151, "_timestamp": 1585613544.6377504, "_step": 327}
{"Episode reward": 23.2319631781197, "Episode length": 768, "Policy Loss": 0.7596037983894348, "Value Loss": 12.31945514678955, "_runtime": 16176.57731294632, "_timestamp": 1585613546.2101824, "_step": 328}
{"Episode reward": -99.77427981495718, "Episode length": 999, "Policy Loss": -0.22337453067302704, "Value Loss": 0.009726451709866524, "_runtime": 16177.778167963028, "_timestamp": 1585613547.4110374, "_step": 329}
{"Episode reward": 24.278415947780033, "Episode length": 758, "Policy Loss": 0.6765127182006836, "Value Loss": 12.315282821655273, "_runtime": 16179.34124660492, "_timestamp": 1585613548.974116, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20176950097084045, "Value Loss": 0.013264879584312439, "_runtime": 16179.724995136261, "_timestamp": 1585613549.3578646, "_step": 331}
{"Episode reward": 79.09999999999998, "Episode length": 209, "Policy Loss": 3.0679163932800293, "Value Loss": 44.5296516418457, "_runtime": 16181.27609705925, "_timestamp": 1585613550.9089665, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2679993212223053, "Value Loss": 0.006565713323652744, "_runtime": 16182.854291439056, "_timestamp": 1585613552.487161, "_step": 333}
{"Episode reward": -99.85716463783616, "Episode length": 999, "Policy Loss": -0.3344569206237793, "Value Loss": 0.005733303260058165, "_runtime": 16184.350563287735, "_timestamp": 1585613553.9834328, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3807236850261688, "Value Loss": 0.0052256654016673565, "_runtime": 16185.3314743042, "_timestamp": 1585613554.9643438, "_step": 335}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 1.0521268844604492, "Value Loss": 16.383316040039062, "_runtime": 16186.911361217499, "_timestamp": 1585613556.5442307, "_step": 336}
{"Episode reward": -99.74750761459443, "Episode length": 999, "Policy Loss": -0.4628666341304779, "Value Loss": 0.04079084098339081, "_runtime": 16188.465505123138, "_timestamp": 1585613558.0983746, "_step": 337}
{"Episode reward": -99.73033124825312, "Episode length": 999, "Policy Loss": -0.47819995880126953, "Value Loss": 0.03863033279776573, "_runtime": 16190.003455877304, "_timestamp": 1585613559.6363254, "_step": 338}
{"Episode reward": -99.76796003151546, "Episode length": 999, "Policy Loss": -0.48114529252052307, "Value Loss": 0.016559815034270287, "_runtime": 16191.569657564163, "_timestamp": 1585613561.202527, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4918173849582672, "Value Loss": 0.015024668537080288, "_runtime": 16192.72794675827, "_timestamp": 1585613562.3608162, "_step": 340}
{"Episode reward": 28.443893051403364, "Episode length": 716, "Policy Loss": 0.4848349690437317, "Value Loss": 13.701327323913574, "_runtime": 16194.29737830162, "_timestamp": 1585613563.9302478, "_step": 341}
{"Episode reward": -99.74277692558104, "Episode length": 999, "Policy Loss": -0.4260994493961334, "Value Loss": 0.039706915616989136, "_runtime": 16195.551797866821, "_timestamp": 1585613565.1846673, "_step": 342}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": 0.41844412684440613, "Value Loss": 12.61235523223877, "_runtime": 16195.917499780655, "_timestamp": 1585613565.5503693, "_step": 343}
{"Episode reward": 78.19999999999996, "Episode length": 218, "Policy Loss": 3.58756422996521, "Value Loss": 45.41673278808594, "_runtime": 16196.819475412369, "_timestamp": 1585613566.452345, "_step": 344}
{"Episode reward": 42.98373327255196, "Episode length": 571, "Policy Loss": 0.7841455340385437, "Value Loss": 17.220762252807617, "_runtime": 16197.458938598633, "_timestamp": 1585613567.091808, "_step": 345}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.3701789379119873, "Value Loss": 24.764925003051758, "_runtime": 16198.961426258087, "_timestamp": 1585613568.5942957, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3805621564388275, "Value Loss": 0.0356094092130661, "_runtime": 16200.490922927856, "_timestamp": 1585613570.1237924, "_step": 347}
{"Episode reward": -99.75622535990412, "Episode length": 999, "Policy Loss": -0.39580410718917847, "Value Loss": 0.025752738118171692, "_runtime": 16202.00143456459, "_timestamp": 1585613571.634304, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4181731939315796, "Value Loss": 0.09256156533956528, "_runtime": 16203.570357561111, "_timestamp": 1585613573.203227, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37238436937332153, "Value Loss": 0.03180260211229324, "_runtime": 16205.140966653824, "_timestamp": 1585613574.7738361, "_step": 350}
{"Episode reward": -99.7137898929636, "Episode length": 999, "Policy Loss": -0.38387060165405273, "Value Loss": 0.10186226665973663, "_runtime": 16206.704035282135, "_timestamp": 1585613576.3369048, "_step": 351}
{"Episode reward": -99.8157187760095, "Episode length": 999, "Policy Loss": -0.32097816467285156, "Value Loss": 0.08287683129310608, "_runtime": 16208.259505033493, "_timestamp": 1585613577.8923745, "_step": 352}
{"Episode reward": -99.78102072495828, "Episode length": 999, "Policy Loss": -0.2960945665836334, "Value Loss": 0.014366556890308857, "_runtime": 16209.121581792831, "_timestamp": 1585613578.7544513, "_step": 353}
{"Episode reward": 46.83821084704202, "Episode length": 533, "Policy Loss": 0.9548801779747009, "Value Loss": 17.79759407043457, "_runtime": 16210.478892087936, "_timestamp": 1585613580.1117616, "_step": 354}
{"Episode reward": 13.091262728977682, "Episode length": 871, "Policy Loss": 0.42552685737609863, "Value Loss": 10.706154823303223, "_runtime": 16211.539576292038, "_timestamp": 1585613581.1724458, "_step": 355}
{"Episode reward": 32.84026452815114, "Episode length": 673, "Policy Loss": 0.7894949913024902, "Value Loss": 14.441431999206543, "_runtime": 16213.056190729141, "_timestamp": 1585613582.6890602, "_step": 356}
{"Episode reward": -99.56936903884497, "Episode length": 999, "Policy Loss": -0.24176067113876343, "Value Loss": 0.01345456950366497, "_runtime": 16214.256221055984, "_timestamp": 1585613583.8890905, "_step": 357}
{"Episode reward": 23.645905385888256, "Episode length": 766, "Policy Loss": 0.8400318026542664, "Value Loss": 12.504170417785645, "_runtime": 16215.79246377945, "_timestamp": 1585613585.4253333, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23113670945167542, "Value Loss": 0.06003842502832413, "_runtime": 16216.688055753708, "_timestamp": 1585613586.3209252, "_step": 359}
{"Episode reward": 46.99837586879683, "Episode length": 531, "Policy Loss": 1.1345816850662231, "Value Loss": 16.877878189086914, "_runtime": 16218.234351158142, "_timestamp": 1585613587.8672206, "_step": 360}
{"Episode reward": -99.7436553215827, "Episode length": 999, "Policy Loss": -0.3306090235710144, "Value Loss": 0.13283078372478485, "_runtime": 16219.08775472641, "_timestamp": 1585613588.7206242, "_step": 361}
{"Episode reward": 47.10660063219209, "Episode length": 531, "Policy Loss": 0.7632469534873962, "Value Loss": 18.293224334716797, "_runtime": 16220.340346813202, "_timestamp": 1585613589.9732163, "_step": 362}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": 0.35281944274902344, "Value Loss": 11.31547737121582, "_runtime": 16221.915504455566, "_timestamp": 1585613591.548374, "_step": 363}
{"Episode reward": -99.82556159058446, "Episode length": 999, "Policy Loss": -0.4382200539112091, "Value Loss": 0.09832628816366196, "_runtime": 16222.601502656937, "_timestamp": 1585613592.2343721, "_step": 364}
{"Episode reward": 55.86868175817619, "Episode length": 443, "Policy Loss": 1.059205174446106, "Value Loss": 21.05970001220703, "_runtime": 16224.070600509644, "_timestamp": 1585613593.70347, "_step": 365}
{"Episode reward": 5.097841697559872, "Episode length": 950, "Policy Loss": 0.10591278225183487, "Value Loss": 9.912026405334473, "_runtime": 16225.64590215683, "_timestamp": 1585613595.2787716, "_step": 366}
{"Episode reward": -99.87904429817432, "Episode length": 999, "Policy Loss": -0.7295811772346497, "Value Loss": 0.01263350062072277, "_runtime": 16227.16043972969, "_timestamp": 1585613596.7933092, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.83440762758255, "Value Loss": 0.018748635426163673, "_runtime": 16228.708712816238, "_timestamp": 1585613598.3415823, "_step": 368}
{"Episode reward": -99.82237213784688, "Episode length": 999, "Policy Loss": -0.9163571000099182, "Value Loss": 0.03134070336818695, "_runtime": 16230.27953338623, "_timestamp": 1585613599.9124029, "_step": 369}
{"Episode reward": -99.65623037624034, "Episode length": 999, "Policy Loss": -0.9911084771156311, "Value Loss": 0.20900021493434906, "_runtime": 16231.268984794617, "_timestamp": 1585613600.9018543, "_step": 370}
{"Episode reward": 37.66062100778739, "Episode length": 624, "Policy Loss": 0.005011112429201603, "Value Loss": 14.42155933380127, "_runtime": 16232.842604398727, "_timestamp": 1585613602.4754739, "_step": 371}
{"Episode reward": -99.7402354900944, "Episode length": 999, "Policy Loss": -1.0199428796768188, "Value Loss": 0.14180888235569, "_runtime": 16233.489127635956, "_timestamp": 1585613603.121997, "_step": 372}
{"Episode reward": 61.489610467664626, "Episode length": 387, "Policy Loss": 0.7540044784545898, "Value Loss": 23.856220245361328, "_runtime": 16234.613920211792, "_timestamp": 1585613604.2467897, "_step": 373}
{"Episode reward": 26.922372751287057, "Episode length": 732, "Policy Loss": -0.150900736451149, "Value Loss": 13.835124969482422, "_runtime": 16235.988436698914, "_timestamp": 1585613605.6213062, "_step": 374}
{"Episode reward": 12.931087531429455, "Episode length": 872, "Policy Loss": -0.19793583452701569, "Value Loss": 10.792350769042969, "_runtime": 16237.00400853157, "_timestamp": 1585613606.636878, "_step": 375}
{"Episode reward": 33.01386293023778, "Episode length": 670, "Policy Loss": 0.14993788301944733, "Value Loss": 14.485357284545898, "_runtime": 16237.945120573044, "_timestamp": 1585613607.57799, "_step": 376}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 0.5071701407432556, "Value Loss": 16.67176628112793, "_runtime": 16239.498653173447, "_timestamp": 1585613609.1315227, "_step": 377}
{"Episode reward": -99.86035044193129, "Episode length": 999, "Policy Loss": -0.8375919461250305, "Value Loss": 0.062034521251916885, "_runtime": 16241.030430078506, "_timestamp": 1585613610.6632996, "_step": 378}
{"Episode reward": -99.84572489000718, "Episode length": 999, "Policy Loss": -0.8463727235794067, "Value Loss": 0.05866902694106102, "_runtime": 16242.603081941605, "_timestamp": 1585613612.2359514, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8688207268714905, "Value Loss": 0.0834101065993309, "_runtime": 16243.7049202919, "_timestamp": 1585613613.3377898, "_step": 380}
{"Episode reward": 30.558181239920344, "Episode length": 696, "Policy Loss": 0.13047826290130615, "Value Loss": 12.568958282470703, "_runtime": 16244.579468011856, "_timestamp": 1585613614.2123375, "_step": 381}
{"Episode reward": 45.13616801379198, "Episode length": 550, "Policy Loss": 0.4028274118900299, "Value Loss": 16.705734252929688, "_runtime": 16245.62546801567, "_timestamp": 1585613615.2583375, "_step": 382}
{"Episode reward": 33.691714709996674, "Episode length": 664, "Policy Loss": 0.1622152030467987, "Value Loss": 13.95091724395752, "_runtime": 16247.165176391602, "_timestamp": 1585613616.7980459, "_step": 383}
{"Episode reward": -99.80772924162308, "Episode length": 999, "Policy Loss": -0.8730122447013855, "Value Loss": 0.13690486550331116, "_runtime": 16248.690435409546, "_timestamp": 1585613618.323305, "_step": 384}
{"Episode reward": -99.71979400412971, "Episode length": 999, "Policy Loss": -0.9031637907028198, "Value Loss": 0.18524952232837677, "_runtime": 16249.852275133133, "_timestamp": 1585613619.4851446, "_step": 385}
{"Episode reward": 25.130044296290706, "Episode length": 749, "Policy Loss": -0.10370654612779617, "Value Loss": 13.207950592041016, "_runtime": 16251.119292497635, "_timestamp": 1585613620.752162, "_step": 386}
{"Episode reward": 19.30000000000031, "Episode length": 807, "Policy Loss": -0.16050967574119568, "Value Loss": 10.968338966369629, "_runtime": 16251.74848151207, "_timestamp": 1585613621.381351, "_step": 387}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 0.7914316654205322, "Value Loss": 22.76259422302246, "_runtime": 16253.293721914291, "_timestamp": 1585613622.9265914, "_step": 388}
{"Episode reward": -99.81416338831046, "Episode length": 999, "Policy Loss": -0.9700770378112793, "Value Loss": 0.04171522706747055, "_runtime": 16253.849445104599, "_timestamp": 1585613623.4823146, "_step": 389}
{"Episode reward": 66.48039597903824, "Episode length": 336, "Policy Loss": 1.140622854232788, "Value Loss": 29.358142852783203, "_runtime": 16255.357377529144, "_timestamp": 1585613624.990247, "_step": 390}
{"Episode reward": -99.72765488270531, "Episode length": 999, "Policy Loss": -0.9664546251296997, "Value Loss": 0.15943381190299988, "_runtime": 16256.919313907623, "_timestamp": 1585613626.5521834, "_step": 391}
{"Episode reward": -99.67874538285984, "Episode length": 999, "Policy Loss": -0.9744672179222107, "Value Loss": 0.05922933667898178, "_runtime": 16257.83084154129, "_timestamp": 1585613627.463711, "_step": 392}
{"Episode reward": 39.55104100704135, "Episode length": 605, "Policy Loss": 0.1905917227268219, "Value Loss": 16.265056610107422, "_runtime": 16259.290439367294, "_timestamp": 1585613628.9233088, "_step": 393}
{"Episode reward": 6.4057616945366505, "Episode length": 936, "Policy Loss": -0.12715379893779755, "Value Loss": 10.485030174255371, "_runtime": 16259.790774822235, "_timestamp": 1585613629.4236443, "_step": 394}
{"Episode reward": 70.98966556452201, "Episode length": 291, "Policy Loss": 1.50137460231781, "Value Loss": 33.34736251831055, "_runtime": 16261.203991413116, "_timestamp": 1585613630.836861, "_step": 395}
{"Episode reward": 7.600000000000975, "Episode length": 924, "Policy Loss": 0.15115824341773987, "Value Loss": 10.338753700256348, "_runtime": 16262.774191141129, "_timestamp": 1585613632.4070606, "_step": 396}
{"Episode reward": -99.67297419330433, "Episode length": 999, "Policy Loss": -0.7082009315490723, "Value Loss": 0.011700480245053768, "_runtime": 16263.244307756424, "_timestamp": 1585613632.8771772, "_step": 397}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 1.5334317684173584, "Value Loss": 30.460988998413086, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343, 0.275412380695343]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [0.708584189414978, 0.8900690674781799, 1.0715539455413818, 1.253038763999939, 1.434523582458496, 1.6160085201263428, 1.7974933385849, 1.9789782762527466, 2.1604630947113037, 2.3419480323791504, 2.523432731628418, 2.7049176692962646, 2.8864026069641113, 3.067887306213379, 3.2493724822998047, 3.4308571815490723, 3.61234188079834, 3.7938270568847656, 3.975311756134033, 4.156796455383301, 4.338281631469727, 4.519766330718994, 4.701251029968262, 4.8827362060546875, 5.064220905303955, 5.245706081390381, 5.427190780639648, 5.608675479888916, 5.790160655975342, 5.971645355224609, 6.153130054473877, 6.334615230560303, 6.51609992980957, 6.697584629058838, 6.879069805145264, 7.060554504394531, 7.242039203643799, 7.423524379730225, 7.605009078979492, 7.78649377822876, 7.9679789543151855, 8.149463653564453, 8.330947875976562, 8.512433052062988, 8.693918228149414, 8.875402450561523, 9.05688762664795, 9.238372802734375, 9.419857025146484, 9.60134220123291, 9.782827377319336, 9.964311599731445, 10.145796775817871, 10.327281951904297, 10.508766174316406, 10.690251350402832, 10.871736526489258, 11.053220748901367, 11.234705924987793, 11.416191101074219, 11.597675323486328, 11.779160499572754, 11.96064567565918, 12.142129898071289, 12.323615074157715]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [0.04348425194621086, 0.05012761056423187, 0.056770969182252884, 0.0634143278002739, 0.0700576901435852, 0.07670104503631592, 0.08334440737962723, 0.08998776972293854, 0.09663112461566925, 0.10327447950839996, 0.10991784930229187, 0.11656120419502258, 0.1232045590877533, 0.129847913980484, 0.13649128377437592, 0.14313463866710663, 0.14977799355983734, 0.15642136335372925, 0.16306471824645996, 0.16970807313919067, 0.17635144293308258, 0.1829947978258133, 0.189638152718544, 0.19628150761127472, 0.20292487740516663, 0.20956823229789734, 0.21621158719062805, 0.22285495698451996, 0.22949831187725067, 0.23614166676998138, 0.2427850216627121, 0.249428391456604, 0.2560717463493347, 0.26271510124206543, 0.26935845613479614, 0.27600181102752686, 0.28264516592025757, 0.2892885208129883, 0.295931875705719, 0.3025752305984497, 0.3092186152935028, 0.3158619701862335, 0.32250532507896423, 0.32914867997169495, 0.33579203486442566, 0.34243538975715637, 0.3490787446498871, 0.3557221293449402, 0.3623654842376709, 0.3690088391304016, 0.3756521940231323, 0.38229554891586304, 0.38893890380859375, 0.39558225870132446, 0.40222564339637756, 0.4088689982891083, 0.415512353181839, 0.4221557080745697, 0.4287990629673004, 0.43544241786003113, 0.44208577275276184, 0.44872915744781494, 0.45537251234054565, 0.46201586723327637, 0.4686592221260071]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 4.0, 6.0, 12.0, 27.0, 32.0, 11.0, 9.0, 1.0, 10.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 49.0, 49.0, 27.0, 43.0, 30.0, 20.0, 7.0, 2.0, 1.0, 1.0, 5.0, 3.0, 5.0, 4.0, 1.0, 3.0, 2.0, 4.0, 6.0, 10.0, 8.0, 2.0, 7.0, 7.0, 7.0, 2.0, 0.0, 8.0, 8.0, 8.0, 4.0, 3.0, 3.0, 6.0, 7.0, 4.0, 8.0, 7.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0], "bins": [-0.3757481575012207, -0.3547506332397461, -0.3337531089782715, -0.3127555847167969, -0.2917580306529999, -0.27076050639152527, -0.24976298213005066, -0.22876544296741486, -0.20776791870594025, -0.18677039444446564, -0.16577285528182983, -0.14477533102035522, -0.12377780675888062, -0.102780282497406, -0.08178272843360901, -0.0607852041721344, -0.03978767991065979, -0.01879015564918518, 0.0022073686122894287, 0.023204922676086426, 0.044202446937561035, 0.06519997119903564, 0.08619749546051025, 0.10719501972198486, 0.12819254398345947, 0.14919006824493408, 0.1701875925064087, 0.19118517637252808, 0.21218270063400269, 0.2331802248954773, 0.2541777491569519, 0.2751752734184265, 0.2961727976799011, 0.31717032194137573, 0.33816784620285034, 0.35916537046432495, 0.38016289472579956, 0.40116041898727417, 0.42215800285339355, 0.44315552711486816, 0.4641530513763428, 0.4851505756378174, 0.506148099899292, 0.5271456241607666, 0.5481431484222412, 0.5691406726837158, 0.5901381969451904, 0.611135721206665, 0.6321332454681396, 0.6531307697296143, 0.6741282939910889, 0.6951258182525635, 0.7161233425140381, 0.7371208667755127, 0.7581185102462769, 0.7791160345077515, 0.8001135587692261, 0.8211110830307007, 0.8421086072921753, 0.8631061315536499, 0.8841036558151245, 0.9051011800765991, 0.9260987043380737, 0.9470962285995483, 0.968093752861023]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0], "bins": [-3.481382131576538, -3.3587570190429688, -3.2361321449279785, -3.113507032394409, -2.99088191986084, -2.8682570457458496, -2.7456319332122803, -2.623006820678711, -2.5003819465637207, -2.3777568340301514, -2.255131721496582, -2.132506847381592, -2.0098817348480225, -1.8872566223144531, -1.7646316289901733, -1.642006516456604, -1.5193815231323242, -1.3967564105987549, -1.2741315364837646, -1.1515064239501953, -1.028881311416626, -0.9062564373016357, -0.7836313247680664, -0.6610062122344971, -0.5383813381195068, -0.4157562255859375, -0.29313111305236816, -0.17050600051879883, -0.047881126403808594, 0.07474398612976074, 0.19736909866333008, 0.3199939727783203, 0.44261908531188965, 0.5652439594268799, 0.6878693103790283, 0.8104941844940186, 0.9331190586090088, 1.0557444095611572, 1.1783692836761475, 1.3009941577911377, 1.4236195087432861, 1.5462443828582764, 1.6688692569732666, 1.791494607925415, 1.9141194820404053, 2.0367443561553955, 2.159369707107544, 2.281994581222534, 2.4046194553375244, 2.527244806289673, 2.649869680404663, 2.7724950313568115, 2.8951199054718018, 3.017744779586792, 3.1403701305389404, 3.2629950046539307, 3.385619878768921, 3.5082452297210693, 3.6308701038360596, 3.75349497795105, 3.8761203289031982, 3.9987452030181885, 4.121370315551758, 4.243995666503906, 4.366620063781738]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0], "bins": [-1.4416756629943848, -1.4052833318710327, -1.3688910007476807, -1.3324987888336182, -1.2961064577102661, -1.259714126586914, -1.223321795463562, -1.18692946434021, -1.150537133216858, -1.1141448020935059, -1.0777525901794434, -1.0413602590560913, -1.0049679279327393, -0.9685755968093872, -0.9321832656860352, -0.8957909941673279, -0.8593986630439758, -0.8230063319206238, -0.7866140604019165, -0.7502217292785645, -0.7138293981552124, -0.6774371266365051, -0.6410447955131531, -0.604652464389801, -0.5682601928710938, -0.5318678617477417, -0.49547553062438965, -0.4590831995010376, -0.42269086837768555, -0.38629865646362305, -0.349906325340271, -0.31351399421691895, -0.2771216630935669, -0.24072933197021484, -0.2043370008468628, -0.16794466972351074, -0.13155245780944824, -0.09516012668609619, -0.05876779556274414, -0.02237546443939209, 0.014016866683959961, 0.05040919780731201, 0.08680140972137451, 0.12319374084472656, 0.1595860719680786, 0.19597840309143066, 0.23237073421478271, 0.26876306533813477, 0.30515527725219727, 0.3415476083755493, 0.37793993949890137, 0.4143322706222534, 0.45072460174560547, 0.4871169328689575, 0.5235092639923096, 0.5599014759063721, 0.5962939262390137, 0.6326861381530762, 0.6690783500671387, 0.7054708003997803, 0.7418630123138428, 0.7782554626464844, 0.8146476745605469, 0.8510401248931885, 0.887432336807251]}, "_runtime": 16263.834278583527, "_timestamp": 1585613633.467148, "_step": 398}
{"Episode reward": 63.364364550914374, "Episode length": 367, "Policy Loss": 1.094984531402588, "Value Loss": 25.19024085998535, "_runtime": 16264.330518007278, "_timestamp": 1585613633.9633875, "_step": 399}
{"Episode reward": 70.09993279108296, "Episode length": 300, "Policy Loss": 1.2876871824264526, "Value Loss": 31.263689041137695, "_runtime": 16265.845323562622, "_timestamp": 1585613635.478193, "_step": 400}
{"Episode reward": -99.82263416631473, "Episode length": 999, "Policy Loss": -0.7640345096588135, "Value Loss": 0.018249599263072014, "_runtime": 16266.519988775253, "_timestamp": 1585613636.1528583, "_step": 401}
{"Episode reward": 56.199999999999655, "Episode length": 438, "Policy Loss": 0.7468395233154297, "Value Loss": 20.440120697021484, "_runtime": 16268.014807224274, "_timestamp": 1585613637.6476767, "_step": 402}
{"Episode reward": -99.80419944757456, "Episode length": 999, "Policy Loss": -0.8176401853561401, "Value Loss": 0.018258482217788696, "_runtime": 16268.866685390472, "_timestamp": 1585613638.4995549, "_step": 403}
{"Episode reward": 47.2528371251882, "Episode length": 528, "Policy Loss": 0.3424491584300995, "Value Loss": 16.794414520263672, "_runtime": 16270.209835529327, "_timestamp": 1585613639.842705, "_step": 404}
{"Episode reward": 12.100000000000719, "Episode length": 879, "Policy Loss": -0.03700188547372818, "Value Loss": 9.755648612976074, "_runtime": 16271.630049705505, "_timestamp": 1585613641.2629192, "_step": 405}
{"Episode reward": 11.47933064529282, "Episode length": 886, "Policy Loss": -0.2133139669895172, "Value Loss": 10.621438026428223, "_runtime": 16273.148465871811, "_timestamp": 1585613642.7813354, "_step": 406}
{"Episode reward": -99.61136550505041, "Episode length": 999, "Policy Loss": -1.0029038190841675, "Value Loss": 0.024177461862564087, "_runtime": 16273.65261554718, "_timestamp": 1585613643.285485, "_step": 407}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 1.0749449729919434, "Value Loss": 29.35579490661621, "_runtime": 16275.204913854599, "_timestamp": 1585613644.8377833, "_step": 408}
{"Episode reward": -99.68170548800705, "Episode length": 999, "Policy Loss": -1.1135207414627075, "Value Loss": 0.027512390166521072, "_runtime": 16276.773055791855, "_timestamp": 1585613646.4059253, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1452163457870483, "Value Loss": 0.03639836236834526, "_runtime": 16277.557054281235, "_timestamp": 1585613647.1899238, "_step": 410}
{"Episode reward": 48.19999999999954, "Episode length": 518, "Policy Loss": 0.008540473878383636, "Value Loss": 17.1710205078125, "_runtime": 16279.121098279953, "_timestamp": 1585613648.7539678, "_step": 411}
{"Episode reward": -99.72778856651718, "Episode length": 999, "Policy Loss": -1.1194608211517334, "Value Loss": 0.05334170162677765, "_runtime": 16280.695980072021, "_timestamp": 1585613650.3288496, "_step": 412}
{"Episode reward": -99.81235318267578, "Episode length": 999, "Policy Loss": -0.9861639142036438, "Value Loss": 0.1332898736000061, "_runtime": 16282.211577892303, "_timestamp": 1585613651.8444474, "_step": 413}
{"Episode reward": -99.76819576853748, "Episode length": 999, "Policy Loss": -0.9841662049293518, "Value Loss": 0.04771830141544342, "_runtime": 16283.787953853607, "_timestamp": 1585613653.4208233, "_step": 414}
{"Episode reward": -99.68985148575018, "Episode length": 999, "Policy Loss": -0.8742040991783142, "Value Loss": 0.2745484709739685, "_runtime": 16285.364860534668, "_timestamp": 1585613654.99773, "_step": 415}
{"Episode reward": -99.8236621633158, "Episode length": 999, "Policy Loss": -0.8867312073707581, "Value Loss": 0.05728636682033539, "_runtime": 16286.928671360016, "_timestamp": 1585613656.5615408, "_step": 416}
{"Episode reward": -99.70640155230511, "Episode length": 999, "Policy Loss": -0.7634351253509521, "Value Loss": 0.17718680202960968, "_runtime": 16288.495361328125, "_timestamp": 1585613658.1282308, "_step": 417}
{"Episode reward": -99.80628361441056, "Episode length": 999, "Policy Loss": -0.7600734233856201, "Value Loss": 0.030898474156856537, "_runtime": 16289.871608495712, "_timestamp": 1585613659.504478, "_step": 418}
{"Episode reward": 12.601580618322586, "Episode length": 874, "Policy Loss": 0.03793967887759209, "Value Loss": 10.490802764892578, "_runtime": 16291.435610294342, "_timestamp": 1585613661.0684798, "_step": 419}
{"Episode reward": -99.73458549850481, "Episode length": 999, "Policy Loss": -0.6688206791877747, "Value Loss": 0.01480227429419756, "_runtime": 16292.600187778473, "_timestamp": 1585613662.2330573, "_step": 420}
{"Episode reward": 27.31596569472444, "Episode length": 727, "Policy Loss": 0.3512001633644104, "Value Loss": 12.871564865112305, "_runtime": 16294.175603866577, "_timestamp": 1585613663.8084733, "_step": 421}
{"Episode reward": -99.50212976331684, "Episode length": 999, "Policy Loss": -0.6015607714653015, "Value Loss": 0.014863913878798485, "_runtime": 16295.77790403366, "_timestamp": 1585613665.4107735, "_step": 422}
{"Episode reward": -99.8129023659029, "Episode length": 999, "Policy Loss": -0.5964281558990479, "Value Loss": 0.03495680168271065, "_runtime": 16297.329563617706, "_timestamp": 1585613666.962433, "_step": 423}
{"Episode reward": -99.67515441460861, "Episode length": 999, "Policy Loss": -0.5181342959403992, "Value Loss": 0.008426710031926632, "_runtime": 16298.903908729553, "_timestamp": 1585613668.5367782, "_step": 424}
{"Episode reward": -99.80071253217616, "Episode length": 999, "Policy Loss": -0.4661555290222168, "Value Loss": 0.04025006666779518, "_runtime": 16300.469556808472, "_timestamp": 1585613670.1024263, "_step": 425}
{"Episode reward": -99.7756213507834, "Episode length": 999, "Policy Loss": -0.4104340076446533, "Value Loss": 0.017524955794215202, "_runtime": 16301.445786237717, "_timestamp": 1585613671.0786557, "_step": 426}
{"Episode reward": 38.72706773281038, "Episode length": 613, "Policy Loss": 0.7791727781295776, "Value Loss": 14.758164405822754, "_runtime": 16302.311526536942, "_timestamp": 1585613671.944396, "_step": 427}
{"Episode reward": 46.733337713591276, "Episode length": 535, "Policy Loss": 0.7791932821273804, "Value Loss": 15.545374870300293, "_runtime": 16303.882324934006, "_timestamp": 1585613673.5151944, "_step": 428}
{"Episode reward": -99.7192014186862, "Episode length": 999, "Policy Loss": -0.37006253004074097, "Value Loss": 0.01167850662022829, "_runtime": 16304.755756616592, "_timestamp": 1585613674.388626, "_step": 429}
{"Episode reward": 44.299999999999486, "Episode length": 557, "Policy Loss": 0.6924088001251221, "Value Loss": 17.84187889099121, "_runtime": 16306.268071174622, "_timestamp": 1585613675.9009407, "_step": 430}
{"Episode reward": -99.5369549370357, "Episode length": 999, "Policy Loss": -0.4563913941383362, "Value Loss": 0.007104582618921995, "_runtime": 16307.845204114914, "_timestamp": 1585613677.4780736, "_step": 431}
{"Episode reward": -99.88996263146261, "Episode length": 999, "Policy Loss": -0.484430193901062, "Value Loss": 0.04424281418323517, "_runtime": 16309.375442743301, "_timestamp": 1585613679.0083122, "_step": 432}
{"Episode reward": -99.82305570579925, "Episode length": 999, "Policy Loss": -0.49213907122612, "Value Loss": 0.059564609080553055, "_runtime": 16310.947360992432, "_timestamp": 1585613680.5802305, "_step": 433}
{"Episode reward": -99.82490778732905, "Episode length": 999, "Policy Loss": -0.4933883249759674, "Value Loss": 0.0865963026881218, "_runtime": 16312.220690727234, "_timestamp": 1585613681.8535602, "_step": 434}
{"Episode reward": 19.82840592241874, "Episode length": 803, "Policy Loss": 0.52915358543396, "Value Loss": 10.908064842224121, "_runtime": 16313.040857076645, "_timestamp": 1585613682.6737266, "_step": 435}
{"Episode reward": 48.928116842731384, "Episode length": 511, "Policy Loss": 0.7829449772834778, "Value Loss": 16.246440887451172, "_runtime": 16313.534725189209, "_timestamp": 1585613683.1675947, "_step": 436}
{"Episode reward": 71.19025343917296, "Episode length": 289, "Policy Loss": 1.6717153787612915, "Value Loss": 27.539587020874023, "_runtime": 16315.058319807053, "_timestamp": 1585613684.6911893, "_step": 437}
{"Episode reward": 1.2954038648879447, "Episode length": 988, "Policy Loss": 0.3945849537849426, "Value Loss": 8.768098831176758, "_runtime": 16316.587446928024, "_timestamp": 1585613686.2203164, "_step": 438}
{"Episode reward": -99.71128667369345, "Episode length": 999, "Policy Loss": -0.43270981311798096, "Value Loss": 0.04764482378959656, "_runtime": 16317.2959856987, "_timestamp": 1585613686.9288552, "_step": 439}
{"Episode reward": 53.481373905762645, "Episode length": 466, "Policy Loss": 0.8444783687591553, "Value Loss": 17.622648239135742, "_runtime": 16318.844453334808, "_timestamp": 1585613688.4773228, "_step": 440}
{"Episode reward": 3.67290398469315, "Episode length": 964, "Policy Loss": 0.17821505665779114, "Value Loss": 8.116686820983887, "_runtime": 16319.913670778275, "_timestamp": 1585613689.5465403, "_step": 441}
{"Episode reward": 31.399999999999622, "Episode length": 686, "Policy Loss": 0.26800915598869324, "Value Loss": 11.617942810058594, "_runtime": 16320.792565107346, "_timestamp": 1585613690.4254346, "_step": 442}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.31762444972991943, "Value Loss": 14.823064804077148, "_runtime": 16322.339090824127, "_timestamp": 1585613691.9719603, "_step": 443}
{"Episode reward": -99.8167353101992, "Episode length": 999, "Policy Loss": -0.8674978613853455, "Value Loss": 0.08819114416837692, "_runtime": 16323.879604578018, "_timestamp": 1585613693.512474, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0139505863189697, "Value Loss": 0.08470232784748077, "_runtime": 16325.137496709824, "_timestamp": 1585613694.7703662, "_step": 445}
{"Episode reward": 17.483007403533392, "Episode length": 826, "Policy Loss": -0.29458245635032654, "Value Loss": 11.021904945373535, "_runtime": 16325.75617980957, "_timestamp": 1585613695.3890493, "_step": 446}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 0.43482717871665955, "Value Loss": 22.161767959594727, "_runtime": 16327.320451021194, "_timestamp": 1585613696.9533205, "_step": 447}
{"Episode reward": -99.80297760460385, "Episode length": 999, "Policy Loss": -1.2513185739517212, "Value Loss": 0.15251557528972626, "_runtime": 16328.873395442963, "_timestamp": 1585613698.506265, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2135698795318604, "Value Loss": 0.14492152631282806, "_runtime": 16330.059332847595, "_timestamp": 1585613699.6922023, "_step": 449}
{"Episode reward": 21.564803542010665, "Episode length": 787, "Policy Loss": -0.3706296384334564, "Value Loss": 11.088165283203125, "_runtime": 16331.640082359314, "_timestamp": 1585613701.2729518, "_step": 450}
{"Episode reward": -99.72084519166825, "Episode length": 999, "Policy Loss": -0.9788862466812134, "Value Loss": 0.21417686343193054, "_runtime": 16333.193881511688, "_timestamp": 1585613702.826751, "_step": 451}
{"Episode reward": -99.65183369929301, "Episode length": 999, "Policy Loss": -0.7113528847694397, "Value Loss": 0.01806187629699707, "_runtime": 16334.72774028778, "_timestamp": 1585613704.3606098, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5679796934127808, "Value Loss": 0.6188094019889832, "_runtime": 16336.305589914322, "_timestamp": 1585613705.9384594, "_step": 453}
{"Episode reward": -99.74005900807539, "Episode length": 999, "Policy Loss": -0.39999574422836304, "Value Loss": 0.20617429912090302, "_runtime": 16337.878777265549, "_timestamp": 1585613707.5116467, "_step": 454}
{"Episode reward": -99.86506937148376, "Episode length": 999, "Policy Loss": -0.26121214032173157, "Value Loss": 0.02055196464061737, "_runtime": 16338.879135370255, "_timestamp": 1585613708.5120049, "_step": 455}
{"Episode reward": 37.1786453118076, "Episode length": 629, "Policy Loss": 0.9435418248176575, "Value Loss": 14.958096504211426, "_runtime": 16340.460074186325, "_timestamp": 1585613710.0929437, "_step": 456}
{"Episode reward": -99.6352044926011, "Episode length": 999, "Policy Loss": -0.06635743379592896, "Value Loss": 0.00022656341025140136, "_runtime": 16341.800981998444, "_timestamp": 1585613711.4338515, "_step": 457}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": 0.7222738265991211, "Value Loss": 10.286077499389648, "_runtime": 16343.379232645035, "_timestamp": 1585613713.0121021, "_step": 458}
{"Episode reward": -99.86181007660785, "Episode length": 999, "Policy Loss": 0.004326376132667065, "Value Loss": 0.018229588866233826, "_runtime": 16344.91316652298, "_timestamp": 1585613714.546036, "_step": 459}
{"Episode reward": 2.802936770186122, "Episode length": 974, "Policy Loss": 0.6490923166275024, "Value Loss": 9.273309707641602, "_runtime": 16346.466052055359, "_timestamp": 1585613716.0989215, "_step": 460}
{"Episode reward": -99.78793286478474, "Episode length": 999, "Policy Loss": 0.006299127358943224, "Value Loss": 0.060551293194293976, "_runtime": 16348.037072181702, "_timestamp": 1585613717.6699417, "_step": 461}
{"Episode reward": -99.84547849334636, "Episode length": 999, "Policy Loss": -0.05591735243797302, "Value Loss": 0.032521042972803116, "_runtime": 16348.89357495308, "_timestamp": 1585613718.5264444, "_step": 462}
{"Episode reward": 46.717233135550735, "Episode length": 534, "Policy Loss": 1.1568260192871094, "Value Loss": 17.20052146911621, "_runtime": 16350.470533370972, "_timestamp": 1585613720.1034029, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1196817085146904, "Value Loss": 0.0041324724443256855, "_runtime": 16351.566982984543, "_timestamp": 1585613721.1998525, "_step": 464}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": 0.7191019654273987, "Value Loss": 12.368908882141113, "_runtime": 16352.515547990799, "_timestamp": 1585613722.1484175, "_step": 465}
{"Episode reward": 38.89304610481427, "Episode length": 612, "Policy Loss": 0.6919923424720764, "Value Loss": 12.8634672164917, "_runtime": 16354.089796066284, "_timestamp": 1585613723.7226655, "_step": 466}
{"Episode reward": -99.6912674760665, "Episode length": 999, "Policy Loss": -0.37973782420158386, "Value Loss": 0.03982215374708176, "_runtime": 16355.344020605087, "_timestamp": 1585613724.97689, "_step": 467}
{"Episode reward": 19.574669323861897, "Episode length": 805, "Policy Loss": 0.34133535623550415, "Value Loss": 11.29284954071045, "_runtime": 16356.874956846237, "_timestamp": 1585613726.5078263, "_step": 468}
{"Episode reward": -99.72272713763967, "Episode length": 999, "Policy Loss": -0.47142651677131653, "Value Loss": 0.09219573438167572, "_runtime": 16358.44347500801, "_timestamp": 1585613728.0763445, "_step": 469}
{"Episode reward": -99.73086652003555, "Episode length": 999, "Policy Loss": -0.5284047722816467, "Value Loss": 0.04539501294493675, "_runtime": 16359.59652876854, "_timestamp": 1585613729.2293983, "_step": 470}
{"Episode reward": 25.597850328497543, "Episode length": 745, "Policy Loss": 0.31431105732917786, "Value Loss": 12.29088306427002, "_runtime": 16361.162893533707, "_timestamp": 1585613730.795763, "_step": 471}
{"Episode reward": -99.8848222562098, "Episode length": 999, "Policy Loss": -0.5442916750907898, "Value Loss": 0.06323131173849106, "_runtime": 16362.745207548141, "_timestamp": 1585613732.378077, "_step": 472}
{"Episode reward": -99.73689891137043, "Episode length": 999, "Policy Loss": -0.5176609754562378, "Value Loss": 0.16820114850997925, "_runtime": 16363.894527673721, "_timestamp": 1585613733.5273972, "_step": 473}
{"Episode reward": 26.928891704371054, "Episode length": 731, "Policy Loss": 0.31932663917541504, "Value Loss": 11.262022018432617, "_runtime": 16364.957849502563, "_timestamp": 1585613734.590719, "_step": 474}
{"Episode reward": 32.20996209448161, "Episode length": 678, "Policy Loss": 0.5021860003471375, "Value Loss": 11.445249557495117, "_runtime": 16366.103517055511, "_timestamp": 1585613735.7363865, "_step": 475}
{"Episode reward": 30.241344445943525, "Episode length": 698, "Policy Loss": 0.060349997133016586, "Value Loss": 10.53238296508789, "_runtime": 16367.478501319885, "_timestamp": 1585613737.1113708, "_step": 476}
{"Episode reward": 11.699886686914425, "Episode length": 885, "Policy Loss": -0.18447165191173553, "Value Loss": 9.238636016845703, "_runtime": 16368.234050989151, "_timestamp": 1585613737.8669205, "_step": 477}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 0.8322439789772034, "Value Loss": 19.78179931640625, "_runtime": 16369.773446321487, "_timestamp": 1585613739.4063158, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8342467546463013, "Value Loss": 0.043594840914011, "_runtime": 16371.328401088715, "_timestamp": 1585613740.9612706, "_step": 479}
{"Episode reward": -99.78686303172587, "Episode length": 999, "Policy Loss": -0.7144797444343567, "Value Loss": 0.3978792428970337, "_runtime": 16372.844434976578, "_timestamp": 1585613742.4773045, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7465553879737854, "Value Loss": 0.04339024797081947, "_runtime": 16374.210313796997, "_timestamp": 1585613743.8431833, "_step": 481}
{"Episode reward": 13.464173009410217, "Episode length": 866, "Policy Loss": 0.05604265257716179, "Value Loss": 8.899938583374023, "_runtime": 16375.51195883751, "_timestamp": 1585613745.1448283, "_step": 482}
{"Episode reward": 17.689669488370825, "Episode length": 824, "Policy Loss": -0.05747896060347557, "Value Loss": 9.333271026611328, "_runtime": 16377.076514720917, "_timestamp": 1585613746.7093842, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8258170485496521, "Value Loss": 0.0844796821475029, "_runtime": 16378.639972925186, "_timestamp": 1585613748.2728424, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8470252156257629, "Value Loss": 0.10987292975187302, "_runtime": 16379.331057786942, "_timestamp": 1585613748.9639273, "_step": 485}
{"Episode reward": 57.235278619639246, "Episode length": 429, "Policy Loss": 0.8777071237564087, "Value Loss": 21.699796676635742, "_runtime": 16380.196185827255, "_timestamp": 1585613749.8290553, "_step": 486}
{"Episode reward": 46.199546983255516, "Episode length": 539, "Policy Loss": 0.39982715249061584, "Value Loss": 15.104351997375488, "_runtime": 16381.773016929626, "_timestamp": 1585613751.4058864, "_step": 487}
{"Episode reward": -99.72528102174262, "Episode length": 999, "Policy Loss": -0.711796224117279, "Value Loss": 0.03606725484132767, "_runtime": 16383.294664621353, "_timestamp": 1585613752.927534, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6181018948554993, "Value Loss": 0.0319983996450901, "_runtime": 16384.820852041245, "_timestamp": 1585613754.4537215, "_step": 489}
{"Episode reward": -99.80052046924689, "Episode length": 999, "Policy Loss": -0.546606183052063, "Value Loss": 0.05083175376057625, "_runtime": 16386.39526772499, "_timestamp": 1585613756.0281372, "_step": 490}
{"Episode reward": -99.79155497886102, "Episode length": 999, "Policy Loss": -0.4212327301502228, "Value Loss": 0.014049934223294258, "_runtime": 16387.96669125557, "_timestamp": 1585613757.5995607, "_step": 491}
{"Episode reward": -99.80941033512214, "Episode length": 999, "Policy Loss": -0.29154735803604126, "Value Loss": 0.055431801825761795, "_runtime": 16389.57692193985, "_timestamp": 1585613759.2097914, "_step": 492}
{"Episode reward": -99.85015343762795, "Episode length": 999, "Policy Loss": -0.18826444447040558, "Value Loss": 0.04974190518260002, "_runtime": 16391.03166794777, "_timestamp": 1585613760.6645374, "_step": 493}
{"Episode reward": 8.525479924679729, "Episode length": 916, "Policy Loss": 0.554865300655365, "Value Loss": 8.120631217956543, "_runtime": 16392.257091760635, "_timestamp": 1585613761.8899612, "_step": 494}
{"Episode reward": 22.571849295939444, "Episode length": 776, "Policy Loss": 0.8302907347679138, "Value Loss": 11.55866527557373, "_runtime": 16393.265924930573, "_timestamp": 1585613762.8987944, "_step": 495}
{"Episode reward": 36.6574367996299, "Episode length": 634, "Policy Loss": 1.1487114429473877, "Value Loss": 14.899163246154785, "_runtime": 16394.839233875275, "_timestamp": 1585613764.4721034, "_step": 496}
{"Episode reward": -99.74625270562107, "Episode length": 999, "Policy Loss": 0.06931552290916443, "Value Loss": 0.003066370729357004, "_runtime": 16396.38106560707, "_timestamp": 1585613766.013935, "_step": 497}
{"Episode reward": -99.84525649696448, "Episode length": 999, "Policy Loss": 0.07670508325099945, "Value Loss": 0.013175838626921177, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053, -0.012745258398354053]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-0.607836902141571, -0.598140299320221, -0.5884436964988708, -0.5787470936775208, -0.5690504908561707, -0.5593539476394653, -0.5496573448181152, -0.5399607419967651, -0.530264139175415, -0.5205675363540649, -0.5108709335327148, -0.5011743307113647, -0.49147772789001465, -0.48178115487098694, -0.47208455204963684, -0.46238797903060913, -0.45269137620925903, -0.44299477338790894, -0.43329817056655884, -0.42360156774520874, -0.41390496492385864, -0.40420836210250854, -0.39451178908348083, -0.38481518626213074, -0.37511858344078064, -0.36542201042175293, -0.35572540760040283, -0.34602880477905273, -0.33633220195770264, -0.32663559913635254, -0.31693902611732483, -0.30724242329597473, -0.29754582047462463, -0.28784921765327454, -0.27815261483192444, -0.26845604181289673, -0.25875943899154663, -0.24906283617019653, -0.23936623334884644, -0.22966966032981873, -0.21997305750846863, -0.21027645468711853, -0.20057985186576843, -0.19088324904441833, -0.18118667602539062, -0.17149007320404053, -0.16179347038269043, -0.15209686756134033, -0.14240026473999023, -0.13270369172096252, -0.12300708889961243, -0.11331048607826233, -0.10361391305923462, -0.09391731023788452, -0.08422070741653442, -0.07452410459518433, -0.06482750177383423, -0.05513089895248413, -0.04543429613113403, -0.035737693309783936, -0.026041150093078613, -0.016344547271728516, -0.006647944450378418, 0.0030486583709716797, 0.012745261192321777]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0], "bins": [-0.02788696438074112, -0.02743608132004738, -0.026985198259353638, -0.026534315198659897, -0.026083430275321007, -0.025632547214627266, -0.025181664153933525, -0.024730781093239784, -0.024279898032546043, -0.023829014971852303, -0.023378130048513412, -0.02292724698781967, -0.02247636392712593, -0.02202548086643219, -0.02157459780573845, -0.021123714745044708, -0.020672831684350967, -0.020221948623657227, -0.019771065562963486, -0.019320182502269745, -0.018869297578930855, -0.018418414518237114, -0.017967531457543373, -0.017516648396849632, -0.017065763473510742, -0.016614880412817, -0.01616399735212326, -0.01571311429142952, -0.015262231230735779, -0.014811348170042038, -0.014360465109348297, -0.013909581117331982, -0.01345869805663824, -0.0130078149959445, -0.012556931003928185, -0.012106047943234444, -0.011655164882540703, -0.011204281821846962, -0.010753398761153221, -0.01030251570045948, -0.00985163077712059, -0.00940074771642685, -0.008949864655733109, -0.008498981595039368, -0.008048098534345627, -0.007597215473651886, -0.007146332412958145, -0.006695447489619255, -0.006244564428925514, -0.005793681368231773, -0.0053427983075380325, -0.004891915246844292, -0.004441032186150551, -0.00399014912545681, -0.00353926420211792, -0.003088381141424179, -0.0026374980807304382, -0.0021866150200366974, -0.0017357319593429565, -0.0012848488986492157, -0.0008339658379554749, -0.0003830809146165848, 6.780214607715607e-05, 0.0005186852067708969, 0.0009695682674646378]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 5.0, 5.0, 6.0, 1.0, 5.0, 8.0, 3.0, 6.0, 3.0, 3.0, 5.0, 4.0, 5.0, 10.0, 1.0, 6.0, 7.0, 9.0, 2.0, 4.0, 7.0, 12.0, 3.0, 4.0, 6.0, 11.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 3.0, 3.0, 2.0, 195.0, 9.0, 3.0, 4.0, 3.0, 15.0, 5.0, 3.0, 5.0, 8.0, 8.0, 7.0, 17.0, 20.0, 12.0, 5.0, 3.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.044714562594890594, -0.04368138685822487, -0.04264821112155914, -0.04161503538489342, -0.04058185964822769, -0.039548683911561966, -0.03851550817489624, -0.037482332438230515, -0.03644915670156479, -0.03541598096489906, -0.03438280522823334, -0.03334962949156761, -0.032316453754901886, -0.03128327429294586, -0.030250100418925285, -0.02921692468225956, -0.028183748945593834, -0.027150573208928108, -0.026117397472262383, -0.025084221735596657, -0.02405104599893093, -0.023017870262265205, -0.02198469452559948, -0.020951518788933754, -0.01991834118962288, -0.018885165452957153, -0.017851989716291428, -0.016818813979625702, -0.015785638242959976, -0.01475246250629425, -0.013719286769628525, -0.012686111032962799, -0.011652935296297073, -0.010619759559631348, -0.009586583822965622, -0.008553408086299896, -0.0075202323496341705, -0.006487056612968445, -0.005453880876302719, -0.004420705139636993, -0.0033875294029712677, -0.002354353666305542, -0.0013211779296398163, -0.0002880021929740906, 0.0007451735436916351, 0.0017783492803573608, 0.0028115250170230865, 0.0038447007536888123, 0.004877880215644836, 0.005911055952310562, 0.006944231688976288, 0.007977407425642014, 0.00901058316230774, 0.010043758898973465, 0.01107693463563919, 0.012110110372304916, 0.013143286108970642, 0.014176461845636368, 0.015209637582302094, 0.01624281331896782, 0.017275989055633545, 0.018309161067008972, 0.019342340528964996, 0.020375512540340424, 0.021408692002296448]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.28310954570770264, -0.2750265300273895, -0.26694348454475403, -0.2588604688644409, -0.2507774233818054, -0.2426944077014923, -0.234611377120018, -0.2265283465385437, -0.2184453159570694, -0.2103622853755951, -0.2022792547941208, -0.19419622421264648, -0.18611320853233337, -0.17803016304969788, -0.16994714736938477, -0.16186411678791046, -0.15378108620643616, -0.14569805562496185, -0.13761502504348755, -0.12953199446201324, -0.12144896388053894, -0.11336594820022583, -0.10528291761875153, -0.09719988703727722, -0.08911685645580292, -0.08103382587432861, -0.07295079529285431, -0.06486776471138, -0.056784749031066895, -0.04870171844959259, -0.040618687868118286, -0.03253564238548279, -0.024452626705169678, -0.016369611024856567, -0.00828656554222107, -0.00020354986190795898, 0.007879495620727539, 0.01596251130104065, 0.024045556783676147, 0.03212857246398926, 0.040211617946624756, 0.048294633626937866, 0.05637764930725098, 0.06446069478988647, 0.07254371047019958, 0.08062675595283508, 0.0887097716331482, 0.09679281711578369, 0.1048758327960968, 0.11295884847640991, 0.12104189395904541, 0.12912490963935852, 0.13720795512199402, 0.14529097080230713, 0.15337401628494263, 0.16145703196525574, 0.16954004764556885, 0.17762309312820435, 0.18570610880851746, 0.19378915429115295, 0.20187216997146606, 0.20995521545410156, 0.21803826093673706, 0.22612124681472778, 0.23420429229736328]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 4.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 5.0, 6.0, 5.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.022423988208174706, -0.020995134487748146, -0.019566282629966736, -0.018137428909540176, -0.016708575189113617, -0.015279721468687057, -0.013850868679583073, -0.012422015890479088, -0.010993162170052528, -0.009564308449625969, -0.008135455660521984, -0.006706602871417999, -0.00527774915099144, -0.0038488954305648804, -0.00242004357278347, -0.0009911898523569107, 0.00043766386806964874, 0.0018665175884962082, 0.0032953713089227676, 0.004724223166704178, 0.006153076887130737, 0.007581930607557297, 0.009010782465338707, 0.010439636185765266, 0.011868489906191826, 0.013297343626618385, 0.014726197347044945, 0.016155051067471504, 0.017583901062607765, 0.019012754783034325, 0.020441608503460884, 0.021870462223887444, 0.023299315944314003, 0.024728169664740562, 0.026157023385167122, 0.02758587710559368, 0.02901473082602024, 0.030443580821156502, 0.03187243640422821, 0.03330128639936447, 0.03473014384508133, 0.03615899384021759, 0.03758785128593445, 0.03901670128107071, 0.04044555127620697, 0.04187440872192383, 0.04330325871706009, 0.04473211616277695, 0.04616096615791321, 0.04758981615304947, 0.04901867359876633, 0.05044752359390259, 0.051876381039619446, 0.05330523103475571, 0.054734088480472565, 0.056162938475608826, 0.05759178847074509, 0.059020645916461945, 0.060449495911598206, 0.061878353357315063, 0.06330720335245132, 0.06473606079816818, 0.06616491079330444, 0.0675937682390213, 0.06902261823415756]}, "_runtime": 16397.917570352554, "_timestamp": 1585613767.5504398, "_step": 498}
{"Episode reward": -99.83847913837387, "Episode length": 999, "Policy Loss": 0.08324010670185089, "Value Loss": 0.011677485890686512, "_runtime": 16397.917570352554, "_timestamp": 1585613767.5504398, "_step": 499}
