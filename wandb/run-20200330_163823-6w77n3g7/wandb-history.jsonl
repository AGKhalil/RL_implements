{"Episode reward": -53.547116642941916, "Episode length": 999, "Policy Loss": -0.02480512484908104, "Value Loss": 0.008363243192434311, "_runtime": 16406.70166349411, "_timestamp": 1585586322.5462968, "_step": 0}
{"Episode reward": -95.9988561015204, "Episode length": 999, "Policy Loss": 0.7285329699516296, "Value Loss": 111.45466613769531, "_runtime": 16408.237634897232, "_timestamp": 1585586324.0822682, "_step": 1}
{"Episode reward": -98.85588205881224, "Episode length": 999, "Policy Loss": 5.259799957275391, "Value Loss": 115.42974853515625, "_runtime": 16409.852008104324, "_timestamp": 1585586325.6966414, "_step": 2}
{"Episode reward": -99.44097953634926, "Episode length": 999, "Policy Loss": 32.0440673828125, "Value Loss": 91674.640625, "_runtime": 16411.43360900879, "_timestamp": 1585586327.2782423, "_step": 3}
{"Episode reward": -98.71530290923852, "Episode length": 999, "Policy Loss": -0.5278670787811279, "Value Loss": 1115.5645751953125, "_runtime": 16411.875987768173, "_timestamp": 1585586327.720621, "_step": 4}
{"Episode reward": 74.81970487845773, "Episode length": 257, "Policy Loss": -85.42156219482422, "Value Loss": 650.690185546875, "_runtime": 16412.589437007904, "_timestamp": 1585586328.4340703, "_step": 5}
{"Episode reward": 56.72274788202101, "Episode length": 440, "Policy Loss": 282.3680725097656, "Value Loss": 2867.031982421875, "_runtime": 16413.733452558517, "_timestamp": 1585586329.578086, "_step": 6}
{"Episode reward": 29.047818875467158, "Episode length": 720, "Policy Loss": 35.33820343017578, "Value Loss": 1238.2115478515625, "_runtime": 16415.237555742264, "_timestamp": 1585586331.082189, "_step": 7}
{"Episode reward": -98.32810288374179, "Episode length": 999, "Policy Loss": -2.892833709716797, "Value Loss": 10.61944580078125, "_runtime": 16416.55090737343, "_timestamp": 1585586332.3955407, "_step": 8}
{"Episode reward": 15.379106310741662, "Episode length": 861, "Policy Loss": -24.46079444885254, "Value Loss": 2874.236083984375, "_runtime": 16417.388370990753, "_timestamp": 1585586333.2330043, "_step": 9}
{"Episode reward": 47.54943179813589, "Episode length": 530, "Policy Loss": -10.169967651367188, "Value Loss": 5301.8779296875, "_runtime": 16418.953545808792, "_timestamp": 1585586334.7981791, "_step": 10}
{"Episode reward": -98.74579736538786, "Episode length": 999, "Policy Loss": -4.343429088592529, "Value Loss": 195.93145751953125, "_runtime": 16420.505519866943, "_timestamp": 1585586336.3501532, "_step": 11}
{"Episode reward": -98.49895948623103, "Episode length": 999, "Policy Loss": -1.0394792556762695, "Value Loss": 18.620925903320312, "_runtime": 16421.287392616272, "_timestamp": 1585586337.132026, "_step": 12}
{"Episode reward": 50.5804451017479, "Episode length": 500, "Policy Loss": 0.16916492581367493, "Value Loss": 50.4488639831543, "_runtime": 16422.11387014389, "_timestamp": 1585586337.9585035, "_step": 13}
{"Episode reward": 49.322286700479815, "Episode length": 512, "Policy Loss": 1.0685393810272217, "Value Loss": 24.173856735229492, "_runtime": 16423.693162202835, "_timestamp": 1585586339.5377955, "_step": 14}
{"Episode reward": -98.3307573630345, "Episode length": 999, "Policy Loss": -0.0571136511862278, "Value Loss": 0.0325290821492672, "_runtime": 16425.25083255768, "_timestamp": 1585586341.095466, "_step": 15}
{"Episode reward": 2.7010470107904183, "Episode length": 988, "Policy Loss": 0.28253307938575745, "Value Loss": 13.119791030883789, "_runtime": 16426.789484500885, "_timestamp": 1585586342.6341178, "_step": 16}
{"Episode reward": -98.5663887299173, "Episode length": 999, "Policy Loss": -0.10929811745882034, "Value Loss": 3.331641435623169, "_runtime": 16427.477874994278, "_timestamp": 1585586343.3225083, "_step": 17}
{"Episode reward": 59.27987732746912, "Episode length": 414, "Policy Loss": 0.849179744720459, "Value Loss": 37.83679962158203, "_runtime": 16429.068168401718, "_timestamp": 1585586344.9128017, "_step": 18}
{"Episode reward": -97.14966269156342, "Episode length": 999, "Policy Loss": -0.40945136547088623, "Value Loss": 21.81480598449707, "_runtime": 16430.245536088943, "_timestamp": 1585586346.0901694, "_step": 19}
{"Episode reward": 26.856628544027345, "Episode length": 743, "Policy Loss": 0.06821597367525101, "Value Loss": 41.34346008300781, "_runtime": 16431.77082324028, "_timestamp": 1585586347.6154566, "_step": 20}
{"Episode reward": -98.65935597858673, "Episode length": 999, "Policy Loss": -0.277629017829895, "Value Loss": 0.6650596261024475, "_runtime": 16433.371327638626, "_timestamp": 1585586349.215961, "_step": 21}
{"Episode reward": -98.50062004730329, "Episode length": 999, "Policy Loss": -1.0423372983932495, "Value Loss": 66.8104476928711, "_runtime": 16434.09452533722, "_timestamp": 1585586349.9391587, "_step": 22}
{"Episode reward": 55.81727507522866, "Episode length": 451, "Policy Loss": 0.04408832639455795, "Value Loss": 14.4046630859375, "_runtime": 16435.656284093857, "_timestamp": 1585586351.5009174, "_step": 23}
{"Episode reward": -97.94734258688423, "Episode length": 999, "Policy Loss": -0.4592299163341522, "Value Loss": 4.9828948974609375, "_runtime": 16436.507818460464, "_timestamp": 1585586352.3524518, "_step": 24}
{"Episode reward": 48.822775715959516, "Episode length": 523, "Policy Loss": -0.3152366280555725, "Value Loss": 9.751957893371582, "_runtime": 16438.032588481903, "_timestamp": 1585586353.8772218, "_step": 25}
{"Episode reward": -98.59249403031929, "Episode length": 999, "Policy Loss": -0.42774686217308044, "Value Loss": 0.3398449122905731, "_runtime": 16438.94182229042, "_timestamp": 1585586354.7864556, "_step": 26}
{"Episode reward": 44.57374147405294, "Episode length": 567, "Policy Loss": 0.27172422409057617, "Value Loss": 17.617338180541992, "_runtime": 16439.834322452545, "_timestamp": 1585586355.6789558, "_step": 27}
{"Episode reward": 43.78088874286217, "Episode length": 574, "Policy Loss": 0.22632016241550446, "Value Loss": 17.396656036376953, "_runtime": 16440.37183690071, "_timestamp": 1585586356.2164702, "_step": 28}
{"Episode reward": 68.96983599680499, "Episode length": 318, "Policy Loss": 0.8651702404022217, "Value Loss": 31.635164260864258, "_runtime": 16441.897739887238, "_timestamp": 1585586357.7423732, "_step": 29}
{"Episode reward": -97.6989958992853, "Episode length": 999, "Policy Loss": -0.42642533779144287, "Value Loss": 0.011027318425476551, "_runtime": 16443.434998512268, "_timestamp": 1585586359.2796319, "_step": 30}
{"Episode reward": -97.62207176202338, "Episode length": 999, "Policy Loss": -0.43763914704322815, "Value Loss": 0.011513568460941315, "_runtime": 16443.907294750214, "_timestamp": 1585586359.751928, "_step": 31}
{"Episode reward": 70.56734408152619, "Episode length": 301, "Policy Loss": 0.9212248921394348, "Value Loss": 35.06022262573242, "_runtime": 16445.459774255753, "_timestamp": 1585586361.3044076, "_step": 32}
{"Episode reward": -98.07890588106794, "Episode length": 999, "Policy Loss": -0.4545378088951111, "Value Loss": 0.015774795785546303, "_runtime": 16446.93752837181, "_timestamp": 1585586362.7821617, "_step": 33}
{"Episode reward": 8.050946616383271, "Episode length": 937, "Policy Loss": 0.09146729111671448, "Value Loss": 11.155712127685547, "_runtime": 16448.43978357315, "_timestamp": 1585586364.284417, "_step": 34}
{"Episode reward": -97.2253632651608, "Episode length": 999, "Policy Loss": -0.4634700417518616, "Value Loss": 0.01647331565618515, "_runtime": 16450.060277700424, "_timestamp": 1585586365.904911, "_step": 35}
{"Episode reward": -97.63347924093635, "Episode length": 999, "Policy Loss": -0.4231262505054474, "Value Loss": 0.6844437718391418, "_runtime": 16451.49594593048, "_timestamp": 1585586367.3405793, "_step": 36}
{"Episode reward": 11.816094384209435, "Episode length": 914, "Policy Loss": -0.058062490075826645, "Value Loss": 11.069377899169922, "_runtime": 16453.043147325516, "_timestamp": 1585586368.8877807, "_step": 37}
{"Episode reward": -98.02707378331206, "Episode length": 999, "Policy Loss": -0.48347458243370056, "Value Loss": 0.016799893230199814, "_runtime": 16454.62523674965, "_timestamp": 1585586370.46987, "_step": 38}
{"Episode reward": -97.74587845175078, "Episode length": 999, "Policy Loss": -0.47888514399528503, "Value Loss": 0.02145230583846569, "_runtime": 16456.19687771797, "_timestamp": 1585586372.041511, "_step": 39}
{"Episode reward": -98.00599912087789, "Episode length": 999, "Policy Loss": -0.49055489897727966, "Value Loss": 0.014606991782784462, "_runtime": 16456.850967407227, "_timestamp": 1585586372.6956007, "_step": 40}
{"Episode reward": 60.92559994456096, "Episode length": 399, "Policy Loss": 0.41237470507621765, "Value Loss": 25.02369499206543, "_runtime": 16458.42440009117, "_timestamp": 1585586374.2690334, "_step": 41}
{"Episode reward": -96.88403344804043, "Episode length": 999, "Policy Loss": -0.48097747564315796, "Value Loss": 0.014277749694883823, "_runtime": 16460.008479595184, "_timestamp": 1585586375.853113, "_step": 42}
{"Episode reward": -97.93944976238679, "Episode length": 999, "Policy Loss": -0.48580244183540344, "Value Loss": 0.014468617737293243, "_runtime": 16461.527296304703, "_timestamp": 1585586377.3719296, "_step": 43}
{"Episode reward": -97.00361444712077, "Episode length": 999, "Policy Loss": -0.4783676266670227, "Value Loss": 0.014109427109360695, "_runtime": 16462.78085565567, "_timestamp": 1585586378.625489, "_step": 44}
{"Episode reward": 22.664454950416257, "Episode length": 791, "Policy Loss": 0.41708722710609436, "Value Loss": 12.626394271850586, "_runtime": 16464.36513876915, "_timestamp": 1585586380.209772, "_step": 45}
{"Episode reward": -97.56496878649399, "Episode length": 999, "Policy Loss": -0.4728702902793884, "Value Loss": 0.01378182228654623, "_runtime": 16465.92884373665, "_timestamp": 1585586381.773477, "_step": 46}
{"Episode reward": -97.8086728139283, "Episode length": 999, "Policy Loss": -0.46905314922332764, "Value Loss": 0.013573918491601944, "_runtime": 16467.48200726509, "_timestamp": 1585586383.3266406, "_step": 47}
{"Episode reward": -97.69846482590934, "Episode length": 999, "Policy Loss": -0.4598769247531891, "Value Loss": 0.013238304294645786, "_runtime": 16468.216319561005, "_timestamp": 1585586384.060953, "_step": 48}
{"Episode reward": 56.22228009060813, "Episode length": 448, "Policy Loss": 0.35056403279304504, "Value Loss": 22.283126831054688, "_runtime": 16469.774775266647, "_timestamp": 1585586385.6194086, "_step": 49}
{"Episode reward": -98.18923365107138, "Episode length": 999, "Policy Loss": -0.45230573415756226, "Value Loss": 0.012687177397310734, "_runtime": 16470.638074159622, "_timestamp": 1585586386.4827075, "_step": 50}
{"Episode reward": 47.97074941059107, "Episode length": 533, "Policy Loss": -0.09175215661525726, "Value Loss": 44.287559509277344, "_runtime": 16471.5060441494, "_timestamp": 1585586387.3506775, "_step": 51}
{"Episode reward": 44.29124214429736, "Episode length": 563, "Policy Loss": -0.031315628439188004, "Value Loss": 14.955121040344238, "_runtime": 16472.931222200394, "_timestamp": 1585586388.7758555, "_step": 52}
{"Episode reward": 13.749902573496357, "Episode length": 884, "Policy Loss": -0.04451967403292656, "Value Loss": 11.299079895019531, "_runtime": 16473.7685713768, "_timestamp": 1585586389.6132047, "_step": 53}
{"Episode reward": 47.37331927212764, "Episode length": 539, "Policy Loss": 0.43948107957839966, "Value Loss": 18.523731231689453, "_runtime": 16474.59096813202, "_timestamp": 1585586390.4356015, "_step": 54}
{"Episode reward": 48.8324500299649, "Episode length": 528, "Policy Loss": 0.2206679731607437, "Value Loss": 18.909278869628906, "_runtime": 16476.151993513107, "_timestamp": 1585586391.9966269, "_step": 55}
{"Episode reward": -96.34183453631852, "Episode length": 999, "Policy Loss": -0.43555375933647156, "Value Loss": 0.011877826415002346, "_runtime": 16477.14852142334, "_timestamp": 1585586392.9931548, "_step": 56}
{"Episode reward": 37.09160186868368, "Episode length": 647, "Policy Loss": 0.12334924191236496, "Value Loss": 15.433563232421875, "_runtime": 16478.66570520401, "_timestamp": 1585586394.5103385, "_step": 57}
{"Episode reward": -97.45793963554175, "Episode length": 999, "Policy Loss": -0.4395630955696106, "Value Loss": 0.012013056315481663, "_runtime": 16480.22403359413, "_timestamp": 1585586396.068667, "_step": 58}
{"Episode reward": -98.22844712903132, "Episode length": 999, "Policy Loss": -0.44344791769981384, "Value Loss": 0.01206307951360941, "_runtime": 16481.747393131256, "_timestamp": 1585586397.5920265, "_step": 59}
{"Episode reward": -97.218218837268, "Episode length": 999, "Policy Loss": -0.43999892473220825, "Value Loss": 0.011757483705878258, "_runtime": 16482.135999441147, "_timestamp": 1585586397.9806328, "_step": 60}
{"Episode reward": 79.13774317116906, "Episode length": 215, "Policy Loss": 1.3541406393051147, "Value Loss": 46.421546936035156, "_runtime": 16483.70463681221, "_timestamp": 1585586399.5492702, "_step": 61}
{"Episode reward": -97.47380514209516, "Episode length": 999, "Policy Loss": -0.43764159083366394, "Value Loss": 0.011663364246487617, "_runtime": 16485.278438091278, "_timestamp": 1585586401.1230714, "_step": 62}
{"Episode reward": -96.25388228526295, "Episode length": 999, "Policy Loss": -0.42817676067352295, "Value Loss": 0.011494729667901993, "_runtime": 16486.763784646988, "_timestamp": 1585586402.608418, "_step": 63}
{"Episode reward": -97.38328366983268, "Episode length": 999, "Policy Loss": -0.4303010404109955, "Value Loss": 0.01156346034258604, "_runtime": 16488.355546712875, "_timestamp": 1585586404.20018, "_step": 64}
{"Episode reward": -97.17400318091282, "Episode length": 999, "Policy Loss": -0.4278954565525055, "Value Loss": 0.011378413066267967, "_runtime": 16488.8875105381, "_timestamp": 1585586404.7321439, "_step": 65}
{"Episode reward": 70.00673484491357, "Episode length": 310, "Policy Loss": 0.7345800995826721, "Value Loss": 32.1999626159668, "_runtime": 16490.43337225914, "_timestamp": 1585586406.2780056, "_step": 66}
{"Episode reward": -98.24308285780339, "Episode length": 999, "Policy Loss": -0.42779672145843506, "Value Loss": 0.011232343502342701, "_runtime": 16491.658204317093, "_timestamp": 1585586407.5028377, "_step": 67}
{"Episode reward": 24.462716951425747, "Episode length": 770, "Policy Loss": 0.03322666138410568, "Value Loss": 12.970441818237305, "_runtime": 16492.918577432632, "_timestamp": 1585586408.7632108, "_step": 68}
{"Episode reward": 19.663459710311656, "Episode length": 834, "Policy Loss": 0.010182260535657406, "Value Loss": 11.975764274597168, "_runtime": 16494.50001001358, "_timestamp": 1585586410.3446434, "_step": 69}
{"Episode reward": -97.44415450366054, "Episode length": 999, "Policy Loss": -0.41843220591545105, "Value Loss": 0.010891448706388474, "_runtime": 16495.91901230812, "_timestamp": 1585586411.7636456, "_step": 70}
{"Episode reward": 11.324990626242851, "Episode length": 909, "Policy Loss": -0.0325254425406456, "Value Loss": 9.432391166687012, "_runtime": 16497.49815750122, "_timestamp": 1585586413.3427908, "_step": 71}
{"Episode reward": -98.5322772166475, "Episode length": 999, "Policy Loss": -0.4157857596874237, "Value Loss": 0.010819612070918083, "_runtime": 16498.317335128784, "_timestamp": 1585586414.1619685, "_step": 72}
{"Episode reward": 49.996928888742424, "Episode length": 508, "Policy Loss": 0.2726931869983673, "Value Loss": 19.6546688079834, "_runtime": 16499.895572185516, "_timestamp": 1585586415.7402055, "_step": 73}
{"Episode reward": -97.8769087369616, "Episode length": 999, "Policy Loss": -0.4126683175563812, "Value Loss": 0.010513316839933395, "_runtime": 16501.421724319458, "_timestamp": 1585586417.2663577, "_step": 74}
{"Episode reward": 6.123078938195391, "Episode length": 977, "Policy Loss": 0.047928616404533386, "Value Loss": 10.224455833435059, "_runtime": 16502.94722890854, "_timestamp": 1585586418.7918622, "_step": 75}
{"Episode reward": -97.27735669869438, "Episode length": 999, "Policy Loss": -0.40768828988075256, "Value Loss": 0.010216593742370605, "_runtime": 16503.334599256516, "_timestamp": 1585586419.1792326, "_step": 76}
{"Episode reward": 79.9531838703764, "Episode length": 208, "Policy Loss": 1.1634138822555542, "Value Loss": 37.45836639404297, "_runtime": 16504.903546333313, "_timestamp": 1585586420.7481797, "_step": 77}
{"Episode reward": -97.3018617090353, "Episode length": 999, "Policy Loss": -0.40906137228012085, "Value Loss": 0.010424608364701271, "_runtime": 16506.48924970627, "_timestamp": 1585586422.333883, "_step": 78}
{"Episode reward": -97.1927093276339, "Episode length": 999, "Policy Loss": -0.30546295642852783, "Value Loss": 3.7121074199676514, "_runtime": 16508.003972768784, "_timestamp": 1585586423.848606, "_step": 79}
{"Episode reward": -97.85997675459039, "Episode length": 999, "Policy Loss": -0.4155065715312958, "Value Loss": 0.010753882117569447, "_runtime": 16509.342596769333, "_timestamp": 1585586425.18723, "_step": 80}
{"Episode reward": 18.0299705933013, "Episode length": 836, "Policy Loss": 0.9331905841827393, "Value Loss": 773.5372314453125, "_runtime": 16510.925042390823, "_timestamp": 1585586426.7696757, "_step": 81}
{"Episode reward": -97.43926825508278, "Episode length": 999, "Policy Loss": -0.38067442178726196, "Value Loss": 0.009042610414326191, "_runtime": 16512.17897796631, "_timestamp": 1585586428.0236113, "_step": 82}
{"Episode reward": 22.83468854150263, "Episode length": 795, "Policy Loss": 0.10920778661966324, "Value Loss": 12.563859939575195, "_runtime": 16513.77213191986, "_timestamp": 1585586429.6167653, "_step": 83}
{"Episode reward": -96.7148121281103, "Episode length": 999, "Policy Loss": -0.31838828325271606, "Value Loss": 0.006534932181239128, "_runtime": 16515.368680477142, "_timestamp": 1585586431.2133138, "_step": 84}
{"Episode reward": -97.74867996559891, "Episode length": 999, "Policy Loss": -0.2984066903591156, "Value Loss": 0.005635159555822611, "_runtime": 16516.926690340042, "_timestamp": 1585586432.7713237, "_step": 85}
{"Episode reward": -98.01437441572409, "Episode length": 999, "Policy Loss": -0.27569103240966797, "Value Loss": 0.004785113502293825, "_runtime": 16518.520952939987, "_timestamp": 1585586434.3655863, "_step": 86}
{"Episode reward": -97.41904127553694, "Episode length": 999, "Policy Loss": -0.24963931739330292, "Value Loss": 0.004010230302810669, "_runtime": 16519.768941640854, "_timestamp": 1585586435.613575, "_step": 87}
{"Episode reward": 26.625717795563602, "Episode length": 758, "Policy Loss": 0.35604918003082275, "Value Loss": 13.180461883544922, "_runtime": 16520.729444503784, "_timestamp": 1585586436.5740778, "_step": 88}
{"Episode reward": 41.69159558185345, "Episode length": 599, "Policy Loss": 0.39971107244491577, "Value Loss": 16.67930030822754, "_runtime": 16521.514837026596, "_timestamp": 1585586437.3594704, "_step": 89}
{"Episode reward": 53.06759801059736, "Episode length": 476, "Policy Loss": 0.5406237244606018, "Value Loss": 20.989755630493164, "_runtime": 16523.092355251312, "_timestamp": 1585586438.9369886, "_step": 90}
{"Episode reward": -96.67139913538678, "Episode length": 999, "Policy Loss": -0.18094651401042938, "Value Loss": 0.0022280924022197723, "_runtime": 16524.644206762314, "_timestamp": 1585586440.48884, "_step": 91}
{"Episode reward": -96.65104613233449, "Episode length": 999, "Policy Loss": -0.16726182401180267, "Value Loss": 0.002006848808377981, "_runtime": 16526.183154582977, "_timestamp": 1585586442.027788, "_step": 92}
{"Episode reward": -97.25998603423055, "Episode length": 999, "Policy Loss": -0.1611606776714325, "Value Loss": 0.0017887656576931477, "_runtime": 16527.379932165146, "_timestamp": 1585586443.2245655, "_step": 93}
{"Episode reward": 26.5689648965557, "Episode length": 755, "Policy Loss": 0.40101468563079834, "Value Loss": 13.236030578613281, "_runtime": 16528.962958097458, "_timestamp": 1585586444.8075914, "_step": 94}
{"Episode reward": -97.4277060781717, "Episode length": 999, "Policy Loss": -0.14313681423664093, "Value Loss": 0.001463007414713502, "_runtime": 16530.552771806717, "_timestamp": 1585586446.3974051, "_step": 95}
{"Episode reward": -96.60139559398391, "Episode length": 999, "Policy Loss": -0.13473503291606903, "Value Loss": 0.0013659426476806402, "_runtime": 16531.30390024185, "_timestamp": 1585586447.1485336, "_step": 96}
{"Episode reward": 55.25715114254771, "Episode length": 462, "Policy Loss": 0.7941470742225647, "Value Loss": 21.631208419799805, "_runtime": 16532.893458366394, "_timestamp": 1585586448.7380917, "_step": 97}
{"Episode reward": -97.82663530226112, "Episode length": 999, "Policy Loss": -0.1282452642917633, "Value Loss": 0.0011752797290682793, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375, 5.970550537109375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-5.967916965484619, -4.646928310394287, -3.325939893722534, -2.0049514770507812, -0.6839628219604492, 0.6370258331298828, 1.9580140113830566, 3.2790026664733887, 4.599991321563721, 5.920979976654053, 7.241968631744385, 8.562957763671875, 9.88394546508789, 11.204935073852539, 12.525922775268555, 13.846912384033203, 15.167900085449219, 16.488887786865234, 17.809877395629883, 19.1308650970459, 20.451854705810547, 21.772842407226562, 23.09383201599121, 24.414819717407227, 25.735807418823242, 27.056795120239258, 28.37778663635254, 29.698774337768555, 31.01976203918457, 32.34074783325195, 33.661739349365234, 34.98272705078125, 36.303714752197266, 37.62470245361328, 38.9456901550293, 40.26668167114258, 41.587669372558594, 42.90865707397461, 44.229644775390625, 45.550636291503906, 46.87162399291992, 48.19261169433594, 49.51359939575195, 50.83458709716797, 52.15557861328125, 53.476566314697266, 54.79755401611328, 56.1185417175293, 57.43952941894531, 58.760520935058594, 60.081504821777344, 61.402496337890625, 62.723487854003906, 64.04447174072266, 65.36546325683594, 66.68645477294922, 68.00743865966797, 69.32843017578125, 70.6494140625, 71.97040557861328, 73.29139709472656, 74.61238098144531, 75.9333724975586, 77.25435638427734, 78.57534790039062]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3376981019973755, -1.2465786933898926, -1.1554591655731201, -1.0643397569656372, -0.9732202887535095, -0.8821008205413818, -0.7909814119338989, -0.6998619437217712, -0.6087424755096436, -0.5176230072975159, -0.4265035390853882, -0.3353841304779053, -0.24426472187042236, -0.1531451940536499, -0.06202578544616699, 0.02909374237060547, 0.12021315097808838, 0.2113325595855713, 0.30245208740234375, 0.39357149600982666, 0.4846910238265991, 0.575810432434082, 0.6669298410415649, 0.7580493688583374, 0.8491686582565308, 0.9402881860733032, 1.0314077138900757, 1.1225272417068481, 1.2136465311050415, 1.304766058921814, 1.3958855867385864, 1.4870048761367798, 1.5781244039535522, 1.6692439317703247, 1.760363221168518, 1.8514827489852905, 1.942602276802063, 2.033721446990967, 2.1248412132263184, 2.2159605026245117, 2.3070802688598633, 2.3981995582580566, 2.48931884765625, 2.5804386138916016, 2.671557903289795, 2.7626771926879883, 2.85379695892334, 2.944916248321533, 3.0360355377197266, 3.127155303955078, 3.2182745933532715, 3.309394359588623, 3.4005136489868164, 3.4916329383850098, 3.5827527046203613, 3.6738719940185547, 3.764991283416748, 3.8561110496520996, 3.947230339050293, 4.038349628448486, 4.129469394683838, 4.220588684082031, 4.311707973480225, 4.402827739715576, 4.4939470291137695]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 2.0, 6.0, 7.0, 1.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 17.0, 14.0, 17.0, 10.0, 12.0, 10.0, 12.0, 192.0, 16.0, 5.0, 18.0, 17.0, 16.0, 8.0, 6.0, 5.0, 3.0, 6.0, 2.0, 5.0, 3.0, 6.0, 2.0, 4.0, 3.0, 4.0, 3.0, 5.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.6413261890411377, -3.4636640548706055, -3.2860019207000732, -3.108339786529541, -2.9306774139404297, -2.7530155181884766, -2.5753531455993652, -2.397691011428833, -2.220028877258301, -2.0423667430877686, -1.8647046089172363, -1.6870423555374146, -1.5093801021575928, -1.3317179679870605, -1.1540558338165283, -0.9763936996459961, -0.7987315654754639, -0.6210694313049316, -0.4434072971343994, -0.2657451629638672, -0.08808302879333496, 0.08957934379577637, 0.2672414779663086, 0.4449036121368408, 0.6225659847259521, 0.8002278804779053, 0.9778902530670166, 1.1555521488189697, 1.333214521408081, 1.5108764171600342, 1.6885387897491455, 1.8662006855010986, 2.04386305809021, 2.2215254306793213, 2.3991873264312744, 2.5768496990203857, 2.754511594772339, 2.93217396736145, 3.1098358631134033, 3.2874982357025146, 3.4651601314544678, 3.642822504043579, 3.8204848766326904, 3.9981467723846436, 4.175808906555176, 4.353470802307129, 4.531133651733398, 4.708795547485352, 4.886458396911621, 5.064120292663574, 5.241782188415527, 5.4194440841674805, 5.59710693359375, 5.774768829345703, 5.952430725097656, 6.130092620849609, 6.307755470275879, 6.485417366027832, 6.663079261779785, 6.840742111206055, 7.018404006958008, 7.196065902709961, 7.373727798461914, 7.551390647888184, 7.729052543640137]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0], "bins": [-17.867048263549805, -17.355085372924805, -16.843122482299805, -16.331159591674805, -15.819196701049805, -15.307233810424805, -14.795269966125488, -14.283307075500488, -13.771344184875488, -13.259381294250488, -12.747418403625488, -12.235454559326172, -11.723491668701172, -11.211528778076172, -10.699565887451172, -10.187602996826172, -9.675640106201172, -9.163677215576172, -8.651714324951172, -8.139751434326172, -7.627788543701172, -7.1158246994018555, -6.6038618087768555, -6.0918989181518555, -5.5799360275268555, -5.0679731369018555, -4.5560102462768555, -4.0440473556518555, -3.532083511352539, -3.020120620727539, -2.508157730102539, -1.996194839477539, -1.484231948852539, -0.9722690582275391, -0.46030616760253906, 0.05165672302246094, 0.5636196136474609, 1.075582504272461, 1.587545394897461, 2.099508285522461, 2.611471176147461, 3.1234359741210938, 3.6353988647460938, 4.147361755371094, 4.659324645996094, 5.171287536621094, 5.683250427246094, 6.195213317871094, 6.707176208496094, 7.219139099121094, 7.731101989746094, 8.243064880371094, 8.755027770996094, 9.266990661621094, 9.778953552246094, 10.290916442871094, 10.802881240844727, 11.314844131469727, 11.826807022094727, 12.338769912719727, 12.850732803344727, 13.362695693969727, 13.874658584594727, 14.386621475219727, 14.898584365844727]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 9.0, 22.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-4.4178595542907715, -4.266724586486816, -4.1155900955200195, -3.9644551277160645, -3.8133201599121094, -3.6621854305267334, -3.5110507011413574, -3.3599157333374023, -3.2087807655334473, -3.0576460361480713, -2.9065113067626953, -2.7553763389587402, -2.6042416095733643, -2.4531068801879883, -2.301971912384033, -2.150836944580078, -1.9997022151947021, -1.8485674858093262, -1.697432518005371, -1.5462977886199951, -1.39516282081604, -1.244028091430664, -1.092893123626709, -0.941758394241333, -0.790623664855957, -0.639488697052002, -0.488353967666626, -0.33721923828125, -0.18608427047729492, -0.034949302673339844, 0.11618566513061523, 0.2673201560974121, 0.4184551239013672, 0.5695900917053223, 0.7207245826721191, 0.8718595504760742, 1.0229945182800293, 1.1741294860839844, 1.3252639770507812, 1.4763989448547363, 1.6275339126586914, 1.7786684036254883, 1.9298033714294434, 2.0809383392333984, 2.2320733070373535, 2.3832077980041504, 2.5343427658081055, 2.6854777336120605, 2.8366122245788574, 2.9877471923828125, 3.1388821601867676, 3.2900171279907227, 3.4411516189575195, 3.5922865867614746, 3.7434210777282715, 3.8945565223693848, 4.045691013336182, 4.1968255043029785, 4.347960948944092, 4.499095439910889, 4.650230884552002, 4.801365375518799, 4.952499866485596, 5.103635311126709, 5.254769802093506]}, "_runtime": 16534.470272779465, "_timestamp": 1585586450.3149061, "_step": 98}
{"Episode reward": 4.187920001720357, "Episode length": 987, "Policy Loss": 0.302717387676239, "Value Loss": 10.12614917755127, "_runtime": 16535.462182998657, "_timestamp": 1585586451.3068163, "_step": 99}
{"Episode reward": 38.0465191606009, "Episode length": 637, "Policy Loss": 0.4475981593132019, "Value Loss": 15.689445495605469, "_runtime": 16536.41493654251, "_timestamp": 1585586452.25957, "_step": 100}
{"Episode reward": 42.30274754339515, "Episode length": 594, "Policy Loss": 0.6423288583755493, "Value Loss": 16.82509422302246, "_runtime": 16538.00063753128, "_timestamp": 1585586453.8452709, "_step": 101}
{"Episode reward": -97.81921211131504, "Episode length": 999, "Policy Loss": -0.12754133343696594, "Value Loss": 0.0011550759663805366, "_runtime": 16539.556143522263, "_timestamp": 1585586455.4007769, "_step": 102}
{"Episode reward": -98.17792296890467, "Episode length": 999, "Policy Loss": -0.1310703158378601, "Value Loss": 0.0011922194389626384, "_runtime": 16540.23706626892, "_timestamp": 1585586456.0816996, "_step": 103}
{"Episode reward": 58.99895636169683, "Episode length": 425, "Policy Loss": 0.9231950044631958, "Value Loss": 23.514419555664062, "_runtime": 16541.39338350296, "_timestamp": 1585586457.2380168, "_step": 104}
{"Episode reward": 30.239251962980703, "Episode length": 725, "Policy Loss": 0.39794912934303284, "Value Loss": 13.784564018249512, "_runtime": 16542.696380615234, "_timestamp": 1585586458.541014, "_step": 105}
{"Episode reward": 19.38239960622124, "Episode length": 830, "Policy Loss": 0.3258149027824402, "Value Loss": 12.040599822998047, "_runtime": 16544.266355514526, "_timestamp": 1585586460.1109889, "_step": 106}
{"Episode reward": -97.74473070187015, "Episode length": 999, "Policy Loss": -0.14891336858272552, "Value Loss": 0.0015385765582323074, "_runtime": 16545.832145929337, "_timestamp": 1585586461.6767793, "_step": 107}
{"Episode reward": -97.93371268893911, "Episode length": 999, "Policy Loss": -0.1552731692790985, "Value Loss": 0.0016398580046370625, "_runtime": 16546.970058918, "_timestamp": 1585586462.8146923, "_step": 108}
{"Episode reward": 30.088813422724414, "Episode length": 721, "Policy Loss": 0.4027479290962219, "Value Loss": 13.859803199768066, "_runtime": 16548.532539606094, "_timestamp": 1585586464.377173, "_step": 109}
{"Episode reward": -97.13584603169761, "Episode length": 999, "Policy Loss": -0.1646738201379776, "Value Loss": 0.0018631970742717385, "_runtime": 16549.133091688156, "_timestamp": 1585586464.977725, "_step": 110}
{"Episode reward": 64.38779491585458, "Episode length": 364, "Policy Loss": 0.8179695010185242, "Value Loss": 27.45000457763672, "_runtime": 16549.76559829712, "_timestamp": 1585586465.6102316, "_step": 111}
{"Episode reward": 61.054931384864744, "Episode length": 398, "Policy Loss": 0.7067220211029053, "Value Loss": 25.10429573059082, "_runtime": 16551.34930229187, "_timestamp": 1585586467.1939356, "_step": 112}
{"Episode reward": -97.14685865351137, "Episode length": 999, "Policy Loss": -0.1885720193386078, "Value Loss": 0.002431114437058568, "_runtime": 16552.694075345993, "_timestamp": 1585586468.5387087, "_step": 113}
{"Episode reward": 14.112901073190969, "Episode length": 878, "Policy Loss": 0.3690623939037323, "Value Loss": 11.38772201538086, "_runtime": 16554.22414445877, "_timestamp": 1585586470.0687778, "_step": 114}
{"Episode reward": -97.95379236258384, "Episode length": 999, "Policy Loss": -0.2130926102399826, "Value Loss": 0.002917811507359147, "_runtime": 16555.649868249893, "_timestamp": 1585586471.4945016, "_step": 115}
{"Episode reward": 12.493377426111422, "Episode length": 900, "Policy Loss": 0.18917588889598846, "Value Loss": 11.101663589477539, "_runtime": 16557.219520807266, "_timestamp": 1585586473.0641541, "_step": 116}
{"Episode reward": -96.90028823279727, "Episode length": 999, "Policy Loss": -0.22560186684131622, "Value Loss": 0.0033400075044482946, "_runtime": 16558.785862207413, "_timestamp": 1585586474.6304955, "_step": 117}
{"Episode reward": -96.87787016736203, "Episode length": 999, "Policy Loss": -0.23071832954883575, "Value Loss": 0.003515977179631591, "_runtime": 16560.362556934357, "_timestamp": 1585586476.2071903, "_step": 118}
{"Episode reward": -97.50030020485764, "Episode length": 999, "Policy Loss": -0.23829299211502075, "Value Loss": 0.0036735120229423046, "_runtime": 16561.934099435806, "_timestamp": 1585586477.7787328, "_step": 119}
{"Episode reward": -97.84776409823542, "Episode length": 999, "Policy Loss": -0.24224787950515747, "Value Loss": 0.003784723347052932, "_runtime": 16563.008203983307, "_timestamp": 1585586478.8528373, "_step": 120}
{"Episode reward": 34.548357296465184, "Episode length": 671, "Policy Loss": 0.30109354853630066, "Value Loss": 14.888273239135742, "_runtime": 16564.596501350403, "_timestamp": 1585586480.4411347, "_step": 121}
{"Episode reward": -98.39849999987051, "Episode length": 999, "Policy Loss": -0.25116103887557983, "Value Loss": 0.003951255232095718, "_runtime": 16566.176182746887, "_timestamp": 1585586482.020816, "_step": 122}
{"Episode reward": -97.86135718297233, "Episode length": 999, "Policy Loss": -0.25378116965293884, "Value Loss": 0.003988320007920265, "_runtime": 16567.775054693222, "_timestamp": 1585586483.619688, "_step": 123}
{"Episode reward": -97.24304727441985, "Episode length": 999, "Policy Loss": -0.24728597700595856, "Value Loss": 0.003985043615102768, "_runtime": 16568.82057118416, "_timestamp": 1585586484.6652045, "_step": 124}
{"Episode reward": 36.69575019508825, "Episode length": 649, "Policy Loss": 0.38228243589401245, "Value Loss": 15.392669677734375, "_runtime": 16570.408205986023, "_timestamp": 1585586486.2528393, "_step": 125}
{"Episode reward": -97.537991254142, "Episode length": 999, "Policy Loss": -0.24997250735759735, "Value Loss": 0.003998341038823128, "_runtime": 16571.990277290344, "_timestamp": 1585586487.8349106, "_step": 126}
{"Episode reward": -97.65927505318908, "Episode length": 999, "Policy Loss": -0.2502119243144989, "Value Loss": 0.003969632554799318, "_runtime": 16573.547511339188, "_timestamp": 1585586489.3921447, "_step": 127}
{"Episode reward": -97.21465318611169, "Episode length": 999, "Policy Loss": -0.24516147375106812, "Value Loss": 0.003959544003009796, "_runtime": 16575.131652116776, "_timestamp": 1585586490.9762855, "_step": 128}
{"Episode reward": -97.23908961790067, "Episode length": 999, "Policy Loss": -0.24507956206798553, "Value Loss": 0.0038508421275764704, "_runtime": 16576.257560014725, "_timestamp": 1585586492.1021934, "_step": 129}
{"Episode reward": 32.59433509472487, "Episode length": 699, "Policy Loss": 0.28326693177223206, "Value Loss": 14.292129516601562, "_runtime": 16577.83143377304, "_timestamp": 1585586493.676067, "_step": 130}
{"Episode reward": -97.04383396166266, "Episode length": 999, "Policy Loss": -0.23672303557395935, "Value Loss": 0.0036819661036133766, "_runtime": 16579.42786026001, "_timestamp": 1585586495.2724936, "_step": 131}
{"Episode reward": -97.60710242506038, "Episode length": 999, "Policy Loss": -0.23653529584407806, "Value Loss": 0.0036183942575007677, "_runtime": 16580.990144729614, "_timestamp": 1585586496.834778, "_step": 132}
{"Episode reward": -97.96812429005338, "Episode length": 999, "Policy Loss": -0.23468457162380219, "Value Loss": 0.0036146596539765596, "_runtime": 16582.5741250515, "_timestamp": 1585586498.4187584, "_step": 133}
{"Episode reward": -97.35021486050358, "Episode length": 999, "Policy Loss": -0.22986054420471191, "Value Loss": 0.0033880695700645447, "_runtime": 16583.817454338074, "_timestamp": 1585586499.6620877, "_step": 134}
{"Episode reward": 23.525026694594132, "Episode length": 787, "Policy Loss": 0.22567300498485565, "Value Loss": 12.695052146911621, "_runtime": 16585.412051677704, "_timestamp": 1585586501.256685, "_step": 135}
{"Episode reward": -97.22721816732086, "Episode length": 999, "Policy Loss": -0.22090299427509308, "Value Loss": 0.0031507189851254225, "_runtime": 16586.997469186783, "_timestamp": 1585586502.8421025, "_step": 136}
{"Episode reward": -98.03363913251466, "Episode length": 999, "Policy Loss": -0.219325989484787, "Value Loss": 0.0030779510270804167, "_runtime": 16588.55818247795, "_timestamp": 1585586504.4028158, "_step": 137}
{"Episode reward": -97.0991659229514, "Episode length": 999, "Policy Loss": -0.21094216406345367, "Value Loss": 0.0029768841341137886, "_runtime": 16589.414030313492, "_timestamp": 1585586505.2586637, "_step": 138}
{"Episode reward": 48.24543232012975, "Episode length": 528, "Policy Loss": 0.47128745913505554, "Value Loss": 18.92195701599121, "_runtime": 16590.99822330475, "_timestamp": 1585586506.8428566, "_step": 139}
{"Episode reward": -97.44917000604256, "Episode length": 999, "Policy Loss": -0.20462574064731598, "Value Loss": 0.002745043719187379, "_runtime": 16592.038922548294, "_timestamp": 1585586507.883556, "_step": 140}
{"Episode reward": 38.94471994103633, "Episode length": 624, "Policy Loss": 0.5716708898544312, "Value Loss": 16.011632919311523, "_runtime": 16593.589899778366, "_timestamp": 1585586509.434533, "_step": 141}
{"Episode reward": -97.77361104793823, "Episode length": 999, "Policy Loss": -0.20092664659023285, "Value Loss": 0.0026874267496168613, "_runtime": 16595.16336631775, "_timestamp": 1585586511.0079997, "_step": 142}
{"Episode reward": -97.35376050825187, "Episode length": 999, "Policy Loss": -0.2005668580532074, "Value Loss": 0.0026384966913610697, "_runtime": 16596.54007959366, "_timestamp": 1585586512.384713, "_step": 143}
{"Episode reward": 13.252385901077716, "Episode length": 889, "Policy Loss": 0.19673824310302734, "Value Loss": 11.239703178405762, "_runtime": 16597.37847685814, "_timestamp": 1585586513.2231102, "_step": 144}
{"Episode reward": 48.803318735535605, "Episode length": 528, "Policy Loss": 0.4703556001186371, "Value Loss": 18.922595977783203, "_runtime": 16598.94142961502, "_timestamp": 1585586514.786063, "_step": 145}
{"Episode reward": -98.32533294306228, "Episode length": 999, "Policy Loss": -0.2055133879184723, "Value Loss": 0.002643539337441325, "_runtime": 16600.509281396866, "_timestamp": 1585586516.3539147, "_step": 146}
{"Episode reward": -96.89888245910524, "Episode length": 999, "Policy Loss": -0.1968606412410736, "Value Loss": 0.0026955874636769295, "_runtime": 16601.350937604904, "_timestamp": 1585586517.195571, "_step": 147}
{"Episode reward": 47.22008003221905, "Episode length": 541, "Policy Loss": 0.4603404700756073, "Value Loss": 18.4677734375, "_runtime": 16602.921521902084, "_timestamp": 1585586518.7661552, "_step": 148}
{"Episode reward": -97.83304823938323, "Episode length": 999, "Policy Loss": -0.20497551560401917, "Value Loss": 0.0027375619392842054, "_runtime": 16604.146821022034, "_timestamp": 1585586519.9914544, "_step": 149}
{"Episode reward": 23.88873969553991, "Episode length": 781, "Policy Loss": 0.2871466279029846, "Value Loss": 12.793254852294922, "_runtime": 16605.675161600113, "_timestamp": 1585586521.519795, "_step": 150}
{"Episode reward": -98.13363803227894, "Episode length": 999, "Policy Loss": -0.21237534284591675, "Value Loss": 0.0028675063513219357, "_runtime": 16607.25130724907, "_timestamp": 1585586523.0959406, "_step": 151}
{"Episode reward": -97.06653400495325, "Episode length": 999, "Policy Loss": -0.20836983621120453, "Value Loss": 0.0028962306678295135, "_runtime": 16608.801015138626, "_timestamp": 1585586524.6456485, "_step": 152}
{"Episode reward": -97.66356022922817, "Episode length": 999, "Policy Loss": -0.21077297627925873, "Value Loss": 0.0028910734690725803, "_runtime": 16610.366403102875, "_timestamp": 1585586526.2110364, "_step": 153}
{"Episode reward": -97.63561177949008, "Episode length": 999, "Policy Loss": -0.2115020900964737, "Value Loss": 0.002877048449590802, "_runtime": 16611.939878940582, "_timestamp": 1585586527.7845123, "_step": 154}
{"Episode reward": -97.9468866699682, "Episode length": 999, "Policy Loss": -0.21032686531543732, "Value Loss": 0.0028372604865580797, "_runtime": 16613.50274515152, "_timestamp": 1585586529.3473785, "_step": 155}
{"Episode reward": -97.87082360930465, "Episode length": 999, "Policy Loss": -0.2072630524635315, "Value Loss": 0.0027721587102860212, "_runtime": 16614.32926940918, "_timestamp": 1585586530.1739028, "_step": 156}
{"Episode reward": 48.992585891474604, "Episode length": 522, "Policy Loss": 0.47414159774780273, "Value Loss": 19.139827728271484, "_runtime": 16615.264798879623, "_timestamp": 1585586531.1094322, "_step": 157}
{"Episode reward": 45.93463202419208, "Episode length": 559, "Policy Loss": 0.48119157552719116, "Value Loss": 17.873125076293945, "_runtime": 16616.836631059647, "_timestamp": 1585586532.6812644, "_step": 158}
{"Episode reward": -97.8986332654507, "Episode length": 999, "Policy Loss": -0.20470517873764038, "Value Loss": 0.002747829770669341, "_runtime": 16618.366785764694, "_timestamp": 1585586534.211419, "_step": 159}
{"Episode reward": -97.76456988347051, "Episode length": 999, "Policy Loss": -0.20560288429260254, "Value Loss": 0.0027721975930035114, "_runtime": 16619.89789366722, "_timestamp": 1585586535.742527, "_step": 160}
{"Episode reward": -97.17413926751892, "Episode length": 999, "Policy Loss": -0.2045186311006546, "Value Loss": 0.0028005309868603945, "_runtime": 16621.466691732407, "_timestamp": 1585586537.311325, "_step": 161}
{"Episode reward": -96.987810607729, "Episode length": 999, "Policy Loss": -0.20180027186870575, "Value Loss": 0.002802593633532524, "_runtime": 16622.101896762848, "_timestamp": 1585586537.94653, "_step": 162}
{"Episode reward": 62.61314559537637, "Episode length": 386, "Policy Loss": 0.724886953830719, "Value Loss": 25.882314682006836, "_runtime": 16623.65814089775, "_timestamp": 1585586539.5027742, "_step": 163}
{"Episode reward": -97.38313004841501, "Episode length": 999, "Policy Loss": -0.20410603284835815, "Value Loss": 0.002764347940683365, "_runtime": 16625.22611808777, "_timestamp": 1585586541.0707514, "_step": 164}
{"Episode reward": -96.95979815702195, "Episode length": 999, "Policy Loss": -0.20517022907733917, "Value Loss": 0.002835797844454646, "_runtime": 16626.740620851517, "_timestamp": 1585586542.5852542, "_step": 165}
{"Episode reward": -97.67047330460929, "Episode length": 999, "Policy Loss": -0.2056025266647339, "Value Loss": 0.0027878584805876017, "_runtime": 16628.312492370605, "_timestamp": 1585586544.1571257, "_step": 166}
{"Episode reward": -97.13609364003686, "Episode length": 999, "Policy Loss": -0.204513818025589, "Value Loss": 0.0027512589003890753, "_runtime": 16629.88338136673, "_timestamp": 1585586545.7280147, "_step": 167}
{"Episode reward": -97.60244771965748, "Episode length": 999, "Policy Loss": -0.20211167633533478, "Value Loss": 0.0027104844339191914, "_runtime": 16631.101048469543, "_timestamp": 1585586546.9456818, "_step": 168}
{"Episode reward": 24.20273255015985, "Episode length": 776, "Policy Loss": 0.2577478587627411, "Value Loss": 12.875932693481445, "_runtime": 16632.677307844162, "_timestamp": 1585586548.5219412, "_step": 169}
{"Episode reward": -97.24646210939783, "Episode length": 999, "Policy Loss": -0.1969848871231079, "Value Loss": 0.0026514597702771425, "_runtime": 16634.010097503662, "_timestamp": 1585586549.8547308, "_step": 170}
{"Episode reward": 17.849609369497927, "Episode length": 841, "Policy Loss": 0.2600759267807007, "Value Loss": 11.881095886230469, "_runtime": 16635.543552160263, "_timestamp": 1585586551.3881855, "_step": 171}
{"Episode reward": -97.93035731043167, "Episode length": 999, "Policy Loss": -0.19462384283542633, "Value Loss": 0.0025775081012398005, "_runtime": 16637.122764587402, "_timestamp": 1585586552.967398, "_step": 172}
{"Episode reward": -97.12667478518746, "Episode length": 999, "Policy Loss": -0.19570806622505188, "Value Loss": 0.002562254900112748, "_runtime": 16638.721048116684, "_timestamp": 1585586554.5656815, "_step": 173}
{"Episode reward": -97.45269874585045, "Episode length": 999, "Policy Loss": -0.19433274865150452, "Value Loss": 0.002483617514371872, "_runtime": 16640.27681827545, "_timestamp": 1585586556.1214516, "_step": 174}
{"Episode reward": -98.46272037361635, "Episode length": 999, "Policy Loss": -0.19526104629039764, "Value Loss": 0.002430347725749016, "_runtime": 16641.73033475876, "_timestamp": 1585586557.574968, "_step": 175}
{"Episode reward": 9.910814763209785, "Episode length": 917, "Policy Loss": 0.19550111889839172, "Value Loss": 10.896906852722168, "_runtime": 16643.02033519745, "_timestamp": 1585586558.8649685, "_step": 176}
{"Episode reward": 19.95472645906979, "Episode length": 816, "Policy Loss": 0.25607767701148987, "Value Loss": 12.245453834533691, "_runtime": 16644.291597366333, "_timestamp": 1585586560.1362307, "_step": 177}
{"Episode reward": 21.872597557505173, "Episode length": 808, "Policy Loss": 0.259494423866272, "Value Loss": 12.366689682006836, "_runtime": 16645.15415287018, "_timestamp": 1585586560.9987862, "_step": 178}
{"Episode reward": 46.65322665400811, "Episode length": 543, "Policy Loss": 0.47292202711105347, "Value Loss": 18.400728225708008, "_runtime": 16646.325927734375, "_timestamp": 1585586562.170561, "_step": 179}
{"Episode reward": 27.26765716182649, "Episode length": 748, "Policy Loss": 0.27728691697120667, "Value Loss": 13.358259201049805, "_runtime": 16647.88879609108, "_timestamp": 1585586563.7334294, "_step": 180}
{"Episode reward": -97.40876500546241, "Episode length": 999, "Policy Loss": -0.1959245651960373, "Value Loss": 0.0025803118478506804, "_runtime": 16649.418189287186, "_timestamp": 1585586565.2628226, "_step": 181}
{"Episode reward": -97.12715171528377, "Episode length": 999, "Policy Loss": -0.2017010897397995, "Value Loss": 0.002652721479535103, "_runtime": 16650.958672761917, "_timestamp": 1585586566.803306, "_step": 182}
{"Episode reward": -97.84915264732925, "Episode length": 999, "Policy Loss": -0.20647448301315308, "Value Loss": 0.002763814991340041, "_runtime": 16652.530222415924, "_timestamp": 1585586568.3748558, "_step": 183}
{"Episode reward": -96.71311584814639, "Episode length": 999, "Policy Loss": -0.20506666600704193, "Value Loss": 0.0027843855787068605, "_runtime": 16654.0992872715, "_timestamp": 1585586569.9439206, "_step": 184}
{"Episode reward": -97.65283661772393, "Episode length": 999, "Policy Loss": -0.21062855422496796, "Value Loss": 0.00286600342951715, "_runtime": 16655.664349079132, "_timestamp": 1585586571.5089824, "_step": 185}
{"Episode reward": -97.71752776953092, "Episode length": 999, "Policy Loss": -0.20598316192626953, "Value Loss": 0.0027598533779382706, "_runtime": 16657.230931043625, "_timestamp": 1585586573.0755644, "_step": 186}
{"Episode reward": -97.57731851923427, "Episode length": 999, "Policy Loss": -0.20351819694042206, "Value Loss": 0.002717640483751893, "_runtime": 16658.7976167202, "_timestamp": 1585586574.64225, "_step": 187}
{"Episode reward": -97.0800416991938, "Episode length": 999, "Policy Loss": -0.1983775794506073, "Value Loss": 0.00270369416102767, "_runtime": 16659.635662794113, "_timestamp": 1585586575.4802961, "_step": 188}
{"Episode reward": 49.97112184701176, "Episode length": 517, "Policy Loss": 0.4923788011074066, "Value Loss": 19.325353622436523, "_runtime": 16661.2107629776, "_timestamp": 1585586577.0553963, "_step": 189}
{"Episode reward": -97.79985153288462, "Episode length": 999, "Policy Loss": -0.19667331874370575, "Value Loss": 0.002539154374971986, "_runtime": 16661.75417304039, "_timestamp": 1585586577.5988064, "_step": 190}
{"Episode reward": 69.35912996384836, "Episode length": 317, "Policy Loss": 0.9134369492530823, "Value Loss": 31.516590118408203, "_runtime": 16663.16157245636, "_timestamp": 1585586579.0062058, "_step": 191}
{"Episode reward": 11.807421617785863, "Episode length": 901, "Policy Loss": 0.21529899537563324, "Value Loss": 11.090027809143066, "_runtime": 16664.73750948906, "_timestamp": 1585586580.5821428, "_step": 192}
{"Episode reward": -97.2671596866383, "Episode length": 999, "Policy Loss": -0.20594647526741028, "Value Loss": 0.0028663044795393944, "_runtime": 16666.233725070953, "_timestamp": 1585586582.0783584, "_step": 193}
{"Episode reward": -97.635962969058, "Episode length": 999, "Policy Loss": -0.21245472133159637, "Value Loss": 0.0029088391456753016, "_runtime": 16667.800538301468, "_timestamp": 1585586583.6451716, "_step": 194}
{"Episode reward": -96.88905748996507, "Episode length": 999, "Policy Loss": -0.21073296666145325, "Value Loss": 0.0029838511254638433, "_runtime": 16668.495178699493, "_timestamp": 1585586584.339812, "_step": 195}
{"Episode reward": 59.1722204613271, "Episode length": 423, "Policy Loss": 0.6723620295524597, "Value Loss": 23.617494583129883, "_runtime": 16670.058581590652, "_timestamp": 1585586585.903215, "_step": 196}
{"Episode reward": -96.92030012654382, "Episode length": 999, "Policy Loss": -0.21579991281032562, "Value Loss": 0.003134931903332472, "_runtime": 16671.218964338303, "_timestamp": 1585586587.0635977, "_step": 197}
{"Episode reward": 29.423009752128635, "Episode length": 728, "Policy Loss": 0.41289201378822327, "Value Loss": 13.723662376403809, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492, 0.20637215673923492]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1633076667785645, -1.085949182510376, -1.0085906982421875, -0.9312320947647095, -0.853873610496521, -0.7765151262283325, -0.6991565823554993, -0.621798038482666, -0.5444395542144775, -0.46708106994628906, -0.3897225260734558, -0.31236398220062256, -0.23500549793243408, -0.1576470136642456, -0.08028841018676758, -0.0029299259185791016, 0.07442855834960938, 0.15178704261779785, 0.22914552688598633, 0.30650413036346436, 0.38386261463165283, 0.4612210988998413, 0.5385797023773193, 0.6159381866455078, 0.6932966709136963, 0.7706551551818848, 0.8480136394500732, 0.9253721237182617, 1.0027308464050293, 1.0800893306732178, 1.1574478149414062, 1.2348062992095947, 1.3121647834777832, 1.3895232677459717, 1.4668817520141602, 1.5442402362823486, 1.621598720550537, 1.6989574432373047, 1.7763159275054932, 1.8536744117736816, 1.9310328960418701, 2.0083913803100586, 2.085749864578247, 2.1631083488464355, 2.240467071533203, 2.3178255558013916, 2.39518404006958, 2.4725425243377686, 2.549901008605957, 2.6272594928741455, 2.704617977142334, 2.7819764614105225, 2.859334945678711, 2.9366936683654785, 3.014051914215088, 3.0914106369018555, 3.168769359588623, 3.2461276054382324, 3.323486328125, 3.4008445739746094, 3.478203296661377, 3.5555615425109863, 3.632920265197754, 3.7102785110473633, 3.787637233734131]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.04625719413161278, -0.043571725487709045, -0.040886253118515015, -0.03820078447461128, -0.03551531583070755, -0.03282984346151352, -0.030144374817609787, -0.027458906173706055, -0.024773435667157173, -0.02208796516060829, -0.01940249651670456, -0.016717026010155678, -0.014031555503606796, -0.011346086859703064, -0.008660618215799332, -0.005975145846605301, -0.0032896772027015686, -0.0006042085587978363, 0.0020812638103961945, 0.004766732454299927, 0.007452201098203659, 0.01013767346739769, 0.012823142111301422, 0.015508610755205154, 0.018194083124399185, 0.02087954804301262, 0.02356502041220665, 0.02625049278140068, 0.028935957700014114, 0.031621430069208145, 0.034306902438402176, 0.03699236735701561, 0.03967783972620964, 0.04236331209540367, 0.045048777014017105, 0.047734249383211136, 0.05041972175240517, 0.0531051866710186, 0.05579065904021263, 0.05847613140940666, 0.061161596328020096, 0.06384706497192383, 0.06653253734111786, 0.06921800971031189, 0.07190348207950592, 0.07458895444869995, 0.07727441191673279, 0.07995988428592682, 0.08264535665512085, 0.08533082902431488, 0.08801628649234772, 0.09070175886154175, 0.09338723123073578, 0.09607270359992981, 0.09875817596912384, 0.10144364833831787, 0.10412910580635071, 0.10681457817554474, 0.10950005054473877, 0.1121855229139328, 0.11487099528312683, 0.11755646765232086, 0.1202419251203537, 0.12292739748954773, 0.12561286985874176]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 9.0, 4.0, 7.0, 6.0, 6.0, 6.0, 10.0, 6.0, 11.0, 13.0, 6.0, 9.0, 10.0, 18.0, 11.0, 20.0, 13.0, 201.0, 27.0, 10.0, 16.0, 19.0, 13.0, 14.0, 6.0, 5.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0], "bins": [-0.11563774943351746, -0.10939976572990417, -0.1031617820262909, -0.09692379832267761, -0.09068581461906433, -0.08444783091545105, -0.07820984721183777, -0.07197186350822449, -0.0657338798046112, -0.059495892375707626, -0.053257908672094345, -0.047019921243190765, -0.040781937539577484, -0.0345439538359642, -0.02830597013235092, -0.02206798642873764, -0.01583000272512436, -0.009592019021511078, -0.0033540353178977966, 0.0028839483857154846, 0.009121932089328766, 0.015359923243522644, 0.021597906947135925, 0.027835890650749207, 0.03407387435436249, 0.04031185805797577, 0.04654984176158905, 0.05278782546520233, 0.05902580916881561, 0.0652637928724289, 0.07150177657604218, 0.07773976027965546, 0.08397774398326874, 0.09021572768688202, 0.0964537113904953, 0.10269169509410858, 0.10892967879772186, 0.11516766250133514, 0.12140564620494843, 0.1276436299085617, 0.133881613612175, 0.14011961221694946, 0.14635759592056274, 0.15259557962417603, 0.1588335633277893, 0.1650715470314026, 0.17130953073501587, 0.17754751443862915, 0.18378549814224243, 0.1900234818458557, 0.196261465549469, 0.20249944925308228, 0.20873743295669556, 0.21497541666030884, 0.22121340036392212, 0.2274513840675354, 0.23368936777114868, 0.23992735147476196, 0.24616533517837524, 0.2524033188819885, 0.2586413025856018, 0.2648792862892151, 0.27111726999282837, 0.27735525369644165, 0.28359323740005493]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.28690171241760254, -0.27639979124069214, -0.2658978998661041, -0.2553959786891937, -0.24489405751228333, -0.23439215123653412, -0.2238902449607849, -0.2133883237838745, -0.2028864175081253, -0.1923845112323761, -0.1818825900554657, -0.1713806837797165, -0.16087877750396729, -0.15037685632705688, -0.13987495005130768, -0.12937302887439728, -0.11887112259864807, -0.10836921632289886, -0.09786729514598846, -0.08736538887023926, -0.07686346769332886, -0.06636156141757965, -0.055859655141830444, -0.045357733964920044, -0.03485584259033203, -0.02435392141342163, -0.01385200023651123, -0.00335007905960083, 0.007151812314987183, 0.017653733491897583, 0.028155654668807983, 0.038657546043395996, 0.049159467220306396, 0.0596613883972168, 0.07016327977180481, 0.08066520094871521, 0.09116712212562561, 0.10166901350021362, 0.11217093467712402, 0.12267285585403442, 0.13317477703094482, 0.14367666840553284, 0.15417858958244324, 0.16468051075935364, 0.17518240213394165, 0.18568432331085205, 0.19618624448776245, 0.20668813586235046, 0.21719002723693848, 0.22769194841384888, 0.23819386959075928, 0.24869579076766968, 0.2591977119445801, 0.2696996331214905, 0.2802015542984009, 0.2907034158706665, 0.3012053370475769, 0.3117072582244873, 0.3222091794013977, 0.3327111005783081, 0.3432130217552185, 0.35371488332748413, 0.36421680450439453, 0.37471872568130493, 0.38522064685821533]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 6.0, 6.0, 6.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.3426066040992737, -0.3320448696613312, -0.32148313522338867, -0.3109213709831238, -0.3003596365451813, -0.28979790210723877, -0.27923616766929626, -0.26867443323135376, -0.25811266899108887, -0.24755093455314636, -0.23698920011520386, -0.22642745077610016, -0.21586571633815765, -0.20530396699905396, -0.19474223256111145, -0.18418048322200775, -0.17361874878406525, -0.16305701434612274, -0.15249526500701904, -0.14193353056907654, -0.13137178122997284, -0.12081004679203033, -0.11024829745292664, -0.09968656301498413, -0.08912482857704163, -0.07856309413909912, -0.06800132989883423, -0.057439595460891724, -0.04687786102294922, -0.036316126585006714, -0.02575436234474182, -0.015192627906799316, -0.0046308934688568115, 0.005930840969085693, 0.016492575407028198, 0.02705433964729309, 0.037616074085235596, 0.0481778085231781, 0.058739542961120605, 0.0693013072013855, 0.079863041639328, 0.09042477607727051, 0.10098651051521301, 0.11154824495315552, 0.12211000919342041, 0.13267174363136292, 0.14323347806930542, 0.15379521250724792, 0.16435694694519043, 0.17491871118545532, 0.18548041582107544, 0.19604218006134033, 0.20660394430160522, 0.21716564893722534, 0.22772741317749023, 0.23828917741775513, 0.24885088205337524, 0.25941264629364014, 0.26997435092926025, 0.28053611516952515, 0.29109787940979004, 0.30165958404541016, 0.31222134828567505, 0.32278305292129517, 0.33334481716156006]}, "_runtime": 16672.736220121384, "_timestamp": 1585586588.5808535, "_step": 198}
{"Episode reward": -97.45535345949402, "Episode length": 999, "Policy Loss": -0.22972504794597626, "Value Loss": 0.003406163305044174, "_runtime": 16674.312209129333, "_timestamp": 1585586590.1568425, "_step": 199}
{"Episode reward": -97.27136609246634, "Episode length": 999, "Policy Loss": -0.2328687310218811, "Value Loss": 0.003498096950352192, "_runtime": 16675.03961801529, "_timestamp": 1585586590.8842514, "_step": 200}
{"Episode reward": 56.46561670344862, "Episode length": 454, "Policy Loss": 0.8660879731178284, "Value Loss": 22.003313064575195, "_runtime": 16676.608533620834, "_timestamp": 1585586592.453167, "_step": 201}
{"Episode reward": -97.67131871149189, "Episode length": 999, "Policy Loss": -0.2389499396085739, "Value Loss": 0.003717508167028427, "_runtime": 16677.748613357544, "_timestamp": 1585586593.5932467, "_step": 202}
{"Episode reward": 28.9680604140042, "Episode length": 727, "Policy Loss": 0.3114285469055176, "Value Loss": 13.741795539855957, "_runtime": 16678.885652303696, "_timestamp": 1585586594.7302856, "_step": 203}
{"Episode reward": 27.853764535411287, "Episode length": 742, "Policy Loss": 0.2447601705789566, "Value Loss": 13.463863372802734, "_runtime": 16680.443741083145, "_timestamp": 1585586596.2883744, "_step": 204}
{"Episode reward": -96.4084383888681, "Episode length": 999, "Policy Loss": -0.24949412047863007, "Value Loss": 0.004246892407536507, "_runtime": 16681.991184711456, "_timestamp": 1585586597.835818, "_step": 205}
{"Episode reward": -97.57875135918984, "Episode length": 999, "Policy Loss": -0.25932276248931885, "Value Loss": 0.0043212780728936195, "_runtime": 16683.534690618515, "_timestamp": 1585586599.379324, "_step": 206}
{"Episode reward": -97.19038419036413, "Episode length": 999, "Policy Loss": -0.2583201825618744, "Value Loss": 0.004382983315736055, "_runtime": 16685.145149469376, "_timestamp": 1585586600.9897828, "_step": 207}
{"Episode reward": -97.05547676218224, "Episode length": 999, "Policy Loss": -0.25872185826301575, "Value Loss": 0.004403921775519848, "_runtime": 16686.588185310364, "_timestamp": 1585586602.4328187, "_step": 208}
{"Episode reward": 9.378980190132438, "Episode length": 923, "Policy Loss": 0.1330183446407318, "Value Loss": 10.824131965637207, "_runtime": 16688.157529592514, "_timestamp": 1585586604.002163, "_step": 209}
{"Episode reward": -97.31849249825864, "Episode length": 999, "Policy Loss": -0.262984961271286, "Value Loss": 0.0044314186088740826, "_runtime": 16688.96448159218, "_timestamp": 1585586604.809115, "_step": 210}
{"Episode reward": 50.07712748070478, "Episode length": 508, "Policy Loss": 0.4620409905910492, "Value Loss": 19.66318130493164, "_runtime": 16689.383271217346, "_timestamp": 1585586605.2279046, "_step": 211}
{"Episode reward": 76.70049254330976, "Episode length": 240, "Policy Loss": 1.2337974309921265, "Value Loss": 41.61518859863281, "_runtime": 16690.94407582283, "_timestamp": 1585586606.7887092, "_step": 212}
{"Episode reward": -97.41913649711027, "Episode length": 999, "Policy Loss": -0.2692506015300751, "Value Loss": 0.004771814681589603, "_runtime": 16692.470415353775, "_timestamp": 1585586608.3150487, "_step": 213}
{"Episode reward": -97.64002948238316, "Episode length": 999, "Policy Loss": -0.28059154748916626, "Value Loss": 0.00504960585385561, "_runtime": 16693.955980062485, "_timestamp": 1585586609.8006134, "_step": 214}
{"Episode reward": -97.24358363462386, "Episode length": 999, "Policy Loss": -0.28664281964302063, "Value Loss": 0.005202070344239473, "_runtime": 16695.1490585804, "_timestamp": 1585586610.993692, "_step": 215}
{"Episode reward": 26.99669080216499, "Episode length": 748, "Policy Loss": 0.2753733992576599, "Value Loss": 13.354602813720703, "_runtime": 16696.69079065323, "_timestamp": 1585586612.535424, "_step": 216}
{"Episode reward": -96.44730846840838, "Episode length": 999, "Policy Loss": -0.28914958238601685, "Value Loss": 0.005453518591821194, "_runtime": 16698.24503803253, "_timestamp": 1585586614.0896714, "_step": 217}
{"Episode reward": -97.63957099392975, "Episode length": 999, "Policy Loss": -0.2984255850315094, "Value Loss": 0.005581761244684458, "_runtime": 16699.78892827034, "_timestamp": 1585586615.6335616, "_step": 218}
{"Episode reward": 3.4205384265985828, "Episode length": 989, "Policy Loss": 0.09007564932107925, "Value Loss": 10.10152530670166, "_runtime": 16701.36326265335, "_timestamp": 1585586617.207896, "_step": 219}
{"Episode reward": -97.22054050733335, "Episode length": 999, "Policy Loss": -0.2994944155216217, "Value Loss": 0.005523602478206158, "_runtime": 16702.27620601654, "_timestamp": 1585586618.1208394, "_step": 220}
{"Episode reward": 43.6399115856681, "Episode length": 575, "Policy Loss": 0.3382367193698883, "Value Loss": 17.37082290649414, "_runtime": 16703.80870604515, "_timestamp": 1585586619.6533394, "_step": 221}
{"Episode reward": 5.050341937031888, "Episode length": 974, "Policy Loss": 0.10071289539337158, "Value Loss": 10.256994247436523, "_runtime": 16705.38773727417, "_timestamp": 1585586621.2323706, "_step": 222}
{"Episode reward": -96.37302492606435, "Episode length": 999, "Policy Loss": -0.29104316234588623, "Value Loss": 0.005560637917369604, "_runtime": 16706.91673183441, "_timestamp": 1585586622.7613652, "_step": 223}
{"Episode reward": -97.43362147838239, "Episode length": 999, "Policy Loss": -0.3019310235977173, "Value Loss": 0.005630822386592627, "_runtime": 16708.031153440475, "_timestamp": 1585586623.8757868, "_step": 224}
{"Episode reward": 32.05742423922193, "Episode length": 701, "Policy Loss": 0.2928800880908966, "Value Loss": 14.249300956726074, "_runtime": 16709.631764888763, "_timestamp": 1585586625.4763982, "_step": 225}
{"Episode reward": -98.00434812376788, "Episode length": 999, "Policy Loss": -0.29828980565071106, "Value Loss": 0.005578141193836927, "_runtime": 16711.19345641136, "_timestamp": 1585586627.0380898, "_step": 226}
{"Episode reward": -97.40455630432761, "Episode length": 999, "Policy Loss": -0.29397448897361755, "Value Loss": 0.005506142042577267, "_runtime": 16712.754157304764, "_timestamp": 1585586628.5987906, "_step": 227}
{"Episode reward": -96.74480487253835, "Episode length": 999, "Policy Loss": -0.2866315543651581, "Value Loss": 0.005342402495443821, "_runtime": 16713.98475074768, "_timestamp": 1585586629.829384, "_step": 228}
{"Episode reward": 23.330308740404362, "Episode length": 782, "Policy Loss": 0.3234432637691498, "Value Loss": 12.774271965026855, "_runtime": 16714.407927036285, "_timestamp": 1585586630.2525604, "_step": 229}
{"Episode reward": 76.93695630158265, "Episode length": 239, "Policy Loss": 1.1995221376419067, "Value Loss": 41.78558349609375, "_runtime": 16715.970930337906, "_timestamp": 1585586631.8155637, "_step": 230}
{"Episode reward": -97.35909869709496, "Episode length": 999, "Policy Loss": -0.2882828414440155, "Value Loss": 0.005287602543830872, "_runtime": 16717.523757457733, "_timestamp": 1585586633.3683908, "_step": 231}
{"Episode reward": -98.04641817997668, "Episode length": 999, "Policy Loss": -0.295445054769516, "Value Loss": 0.005480930209159851, "_runtime": 16718.92193055153, "_timestamp": 1585586634.766564, "_step": 232}
{"Episode reward": 8.746711236817589, "Episode length": 931, "Policy Loss": 0.11392030864953995, "Value Loss": 10.730521202087402, "_runtime": 16720.512016057968, "_timestamp": 1585586636.3566494, "_step": 233}
{"Episode reward": -97.18703892192859, "Episode length": 999, "Policy Loss": -0.2939609885215759, "Value Loss": 0.005626419093459845, "_runtime": 16722.082945346832, "_timestamp": 1585586637.9275787, "_step": 234}
{"Episode reward": -97.88678746066041, "Episode length": 999, "Policy Loss": -0.2966584265232086, "Value Loss": 0.005626769736409187, "_runtime": 16723.628900766373, "_timestamp": 1585586639.473534, "_step": 235}
{"Episode reward": -97.39086880736248, "Episode length": 999, "Policy Loss": -0.2916732728481293, "Value Loss": 0.005510025192052126, "_runtime": 16724.782921552658, "_timestamp": 1585586640.627555, "_step": 236}
{"Episode reward": 29.737375935391952, "Episode length": 720, "Policy Loss": 0.29356929659843445, "Value Loss": 13.873618125915527, "_runtime": 16726.354343891144, "_timestamp": 1585586642.1989772, "_step": 237}
{"Episode reward": -97.73350101853143, "Episode length": 999, "Policy Loss": -0.287122905254364, "Value Loss": 0.005395443644374609, "_runtime": 16727.926165819168, "_timestamp": 1585586643.7707992, "_step": 238}
{"Episode reward": -97.30652923825068, "Episode length": 999, "Policy Loss": -0.2861298620700836, "Value Loss": 0.005235975608229637, "_runtime": 16729.4884390831, "_timestamp": 1585586645.3330724, "_step": 239}
{"Episode reward": -96.98645105143467, "Episode length": 999, "Policy Loss": -0.2810254991054535, "Value Loss": 0.005023602861911058, "_runtime": 16730.18574142456, "_timestamp": 1585586646.0303748, "_step": 240}
{"Episode reward": 58.58650643849561, "Episode length": 426, "Policy Loss": 1.2038445472717285, "Value Loss": 23.445871353149414, "_runtime": 16731.753042459488, "_timestamp": 1585586647.5976758, "_step": 241}
{"Episode reward": -98.03179822070801, "Episode length": 999, "Policy Loss": -0.2752036452293396, "Value Loss": 0.0048853373154997826, "_runtime": 16732.164769649506, "_timestamp": 1585586648.009403, "_step": 242}
{"Episode reward": 77.52973908140896, "Episode length": 229, "Policy Loss": 1.5048128366470337, "Value Loss": 43.6120491027832, "_runtime": 16732.952258586884, "_timestamp": 1585586648.796892, "_step": 243}
{"Episode reward": 51.917173631465666, "Episode length": 490, "Policy Loss": 0.5700794458389282, "Value Loss": 20.384000778198242, "_runtime": 16734.5122089386, "_timestamp": 1585586650.3568423, "_step": 244}
{"Episode reward": -97.17440152545129, "Episode length": 999, "Policy Loss": -0.2893419861793518, "Value Loss": 0.005326834041625261, "_runtime": 16735.502198934555, "_timestamp": 1585586651.3468323, "_step": 245}
{"Episode reward": 35.78527985078435, "Episode length": 663, "Policy Loss": 0.49628347158432007, "Value Loss": 15.065690040588379, "_runtime": 16736.074513673782, "_timestamp": 1585586651.919147, "_step": 246}
{"Episode reward": 64.50161997267963, "Episode length": 362, "Policy Loss": 0.7802654504776001, "Value Loss": 27.587162017822266, "_runtime": 16737.629037618637, "_timestamp": 1585586653.473671, "_step": 247}
{"Episode reward": -98.41681801617942, "Episode length": 999, "Policy Loss": -0.325896292924881, "Value Loss": 0.006496714893728495, "_runtime": 16739.149377822876, "_timestamp": 1585586654.9940112, "_step": 248}
{"Episode reward": -96.80149649872337, "Episode length": 999, "Policy Loss": -0.3270193636417389, "Value Loss": 0.006767114158719778, "_runtime": 16740.656473636627, "_timestamp": 1585586656.501107, "_step": 249}
{"Episode reward": -97.74030062108523, "Episode length": 999, "Policy Loss": -0.34120500087738037, "Value Loss": 0.0071143582463264465, "_runtime": 16742.2164041996, "_timestamp": 1585586658.0610375, "_step": 250}
{"Episode reward": -96.35996853455795, "Episode length": 999, "Policy Loss": -0.33715251088142395, "Value Loss": 0.007241287734359503, "_runtime": 16743.77793598175, "_timestamp": 1585586659.6225693, "_step": 251}
{"Episode reward": -97.78861971459234, "Episode length": 999, "Policy Loss": -0.3379271626472473, "Value Loss": 0.007336373440921307, "_runtime": 16745.329426765442, "_timestamp": 1585586661.17406, "_step": 252}
{"Episode reward": -97.18183129420385, "Episode length": 999, "Policy Loss": -0.33597126603126526, "Value Loss": 0.0072317710146307945, "_runtime": 16746.913752794266, "_timestamp": 1585586662.7583861, "_step": 253}
{"Episode reward": -96.22886611063096, "Episode length": 999, "Policy Loss": -0.32998165488243103, "Value Loss": 0.007040718570351601, "_runtime": 16748.4805393219, "_timestamp": 1585586664.3251727, "_step": 254}
{"Episode reward": -97.55915864123982, "Episode length": 999, "Policy Loss": -0.3307654559612274, "Value Loss": 0.006873690523207188, "_runtime": 16749.492217302322, "_timestamp": 1585586665.3368506, "_step": 255}
{"Episode reward": 36.426315289278264, "Episode length": 649, "Policy Loss": 0.650122344493866, "Value Loss": 15.38967514038086, "_runtime": 16750.91008734703, "_timestamp": 1585586666.7547207, "_step": 256}
{"Episode reward": 11.700107694015713, "Episode length": 901, "Policy Loss": 0.09547639638185501, "Value Loss": 11.087254524230957, "_runtime": 16752.479126930237, "_timestamp": 1585586668.3237603, "_step": 257}
{"Episode reward": -97.4389077161807, "Episode length": 999, "Policy Loss": -0.31745627522468567, "Value Loss": 0.006280153524130583, "_runtime": 16753.484889745712, "_timestamp": 1585586669.329523, "_step": 258}
{"Episode reward": 36.829162295311875, "Episode length": 645, "Policy Loss": 0.2436615228652954, "Value Loss": 15.485413551330566, "_runtime": 16755.0397605896, "_timestamp": 1585586670.884394, "_step": 259}
{"Episode reward": -97.47878302163599, "Episode length": 999, "Policy Loss": -0.30773451924324036, "Value Loss": 0.00604510260745883, "_runtime": 16756.646295785904, "_timestamp": 1585586672.4909291, "_step": 260}
{"Episode reward": -97.26642991817543, "Episode length": 999, "Policy Loss": -0.30711033940315247, "Value Loss": 0.005856584757566452, "_runtime": 16757.49466085434, "_timestamp": 1585586673.3392942, "_step": 261}
{"Episode reward": 46.09494856923936, "Episode length": 549, "Policy Loss": 0.6952112913131714, "Value Loss": 18.192882537841797, "_runtime": 16759.066133499146, "_timestamp": 1585586674.9107668, "_step": 262}
{"Episode reward": -97.26322957924386, "Episode length": 999, "Policy Loss": -0.2933007776737213, "Value Loss": 0.005554910749197006, "_runtime": 16760.6377325058, "_timestamp": 1585586676.4823658, "_step": 263}
{"Episode reward": -97.40699518450722, "Episode length": 999, "Policy Loss": -0.29113033413887024, "Value Loss": 0.0054802848026156425, "_runtime": 16762.164892673492, "_timestamp": 1585586678.009526, "_step": 264}
{"Episode reward": -96.33474832416356, "Episode length": 999, "Policy Loss": -0.2803741991519928, "Value Loss": 0.0051762196235358715, "_runtime": 16763.750139951706, "_timestamp": 1585586679.5947733, "_step": 265}
{"Episode reward": -96.76783685254398, "Episode length": 999, "Policy Loss": -0.27352476119995117, "Value Loss": 0.004935551434755325, "_runtime": 16765.324099063873, "_timestamp": 1585586681.1687324, "_step": 266}
{"Episode reward": -97.85946757833507, "Episode length": 999, "Policy Loss": -0.2739189863204956, "Value Loss": 0.0047036949545145035, "_runtime": 16765.989392995834, "_timestamp": 1585586681.8340263, "_step": 267}
{"Episode reward": 60.46901359395265, "Episode length": 408, "Policy Loss": 0.6075054407119751, "Value Loss": 24.48134422302246, "_runtime": 16767.565091848373, "_timestamp": 1585586683.4097252, "_step": 268}
{"Episode reward": -97.44836628766039, "Episode length": 999, "Policy Loss": -0.25747454166412354, "Value Loss": 0.004324575886130333, "_runtime": 16768.771240472794, "_timestamp": 1585586684.6158738, "_step": 269}
{"Episode reward": 25.38577898226407, "Episode length": 764, "Policy Loss": 0.21495597064495087, "Value Loss": 13.076133728027344, "_runtime": 16770.283905029297, "_timestamp": 1585586686.1285384, "_step": 270}
{"Episode reward": -97.3336397563779, "Episode length": 999, "Policy Loss": -0.2490389496088028, "Value Loss": 0.004060779232531786, "_runtime": 16770.86692261696, "_timestamp": 1585586686.711556, "_step": 271}
{"Episode reward": 66.306389880891, "Episode length": 347, "Policy Loss": 0.8084174990653992, "Value Loss": 28.785791397094727, "_runtime": 16771.83456993103, "_timestamp": 1585586687.6792033, "_step": 272}
{"Episode reward": 39.19540717866431, "Episode length": 623, "Policy Loss": 0.3433414101600647, "Value Loss": 16.034805297851562, "_runtime": 16773.09119939804, "_timestamp": 1585586688.9358327, "_step": 273}
{"Episode reward": 21.217107129817137, "Episode length": 808, "Policy Loss": 0.2773093581199646, "Value Loss": 12.364187240600586, "_runtime": 16774.5986392498, "_timestamp": 1585586690.4432726, "_step": 274}
{"Episode reward": -97.85823927817395, "Episode length": 999, "Policy Loss": -0.2615274488925934, "Value Loss": 0.00439421134069562, "_runtime": 16776.135540246964, "_timestamp": 1585586691.9801736, "_step": 275}
{"Episode reward": -96.87721049067082, "Episode length": 999, "Policy Loss": -0.2637234330177307, "Value Loss": 0.004544080700725317, "_runtime": 16777.677468776703, "_timestamp": 1585586693.522102, "_step": 276}
{"Episode reward": -96.97659957723418, "Episode length": 999, "Policy Loss": -0.27023470401763916, "Value Loss": 0.004558563698083162, "_runtime": 16779.234728336334, "_timestamp": 1585586695.0793617, "_step": 277}
{"Episode reward": -98.22367133339738, "Episode length": 999, "Policy Loss": -0.2712278962135315, "Value Loss": 0.0046023232862353325, "_runtime": 16780.840023994446, "_timestamp": 1585586696.6846573, "_step": 278}
{"Episode reward": -97.70324070128623, "Episode length": 999, "Policy Loss": -0.2676853537559509, "Value Loss": 0.004527767654508352, "_runtime": 16782.17348265648, "_timestamp": 1585586698.018116, "_step": 279}
{"Episode reward": 17.55673232765561, "Episode length": 850, "Policy Loss": 0.1635769158601761, "Value Loss": 11.753291130065918, "_runtime": 16783.58208155632, "_timestamp": 1585586699.426715, "_step": 280}
{"Episode reward": 11.797195573171635, "Episode length": 907, "Policy Loss": 0.144212543964386, "Value Loss": 11.015015602111816, "_runtime": 16784.20598602295, "_timestamp": 1585586700.0506194, "_step": 281}
{"Episode reward": 63.72695130070458, "Episode length": 375, "Policy Loss": 0.726963222026825, "Value Loss": 26.635534286499023, "_runtime": 16785.101533651352, "_timestamp": 1585586700.946167, "_step": 282}
{"Episode reward": 43.790476429088876, "Episode length": 576, "Policy Loss": 0.3518930673599243, "Value Loss": 17.34207534790039, "_runtime": 16786.662164211273, "_timestamp": 1585586702.5067976, "_step": 283}
{"Episode reward": -97.25427221916587, "Episode length": 999, "Policy Loss": -0.26966553926467896, "Value Loss": 0.0047368877567350864, "_runtime": 16788.17344045639, "_timestamp": 1585586704.0180738, "_step": 284}
{"Episode reward": -98.09434402431049, "Episode length": 999, "Policy Loss": -0.2805757224559784, "Value Loss": 0.004985990934073925, "_runtime": 16789.36165690422, "_timestamp": 1585586705.2062902, "_step": 285}
{"Episode reward": 24.18005334277825, "Episode length": 772, "Policy Loss": 0.22838973999023438, "Value Loss": 12.939802169799805, "_runtime": 16790.915486097336, "_timestamp": 1585586706.7601194, "_step": 286}
{"Episode reward": -97.74530454201697, "Episode length": 999, "Policy Loss": -0.28685569763183594, "Value Loss": 0.0051795681938529015, "_runtime": 16791.635001420975, "_timestamp": 1585586707.4796348, "_step": 287}
{"Episode reward": 55.79718286060851, "Episode length": 450, "Policy Loss": 0.5297519564628601, "Value Loss": 22.194896697998047, "_runtime": 16793.186226844788, "_timestamp": 1585586709.0308602, "_step": 288}
{"Episode reward": -97.09996010050928, "Episode length": 999, "Policy Loss": -0.2900824248790741, "Value Loss": 0.005441515706479549, "_runtime": 16794.201565265656, "_timestamp": 1585586710.0461986, "_step": 289}
{"Episode reward": 37.23949886684858, "Episode length": 643, "Policy Loss": 0.27388134598731995, "Value Loss": 15.534143447875977, "_runtime": 16795.724285840988, "_timestamp": 1585586711.5689192, "_step": 290}
{"Episode reward": -97.28302485231177, "Episode length": 999, "Policy Loss": -0.30389949679374695, "Value Loss": 0.005766422487795353, "_runtime": 16797.29663324356, "_timestamp": 1585586713.1412666, "_step": 291}
{"Episode reward": -97.88200798395728, "Episode length": 999, "Policy Loss": -0.3064277470111847, "Value Loss": 0.00589762581512332, "_runtime": 16798.366972208023, "_timestamp": 1585586714.2116055, "_step": 292}
{"Episode reward": 32.59335640777249, "Episode length": 692, "Policy Loss": 0.43210306763648987, "Value Loss": 14.4342679977417, "_runtime": 16799.926069259644, "_timestamp": 1585586715.7707026, "_step": 293}
{"Episode reward": -97.88410062465086, "Episode length": 999, "Policy Loss": -0.3061210513114929, "Value Loss": 0.00598082086071372, "_runtime": 16801.491389513016, "_timestamp": 1585586717.3360229, "_step": 294}
{"Episode reward": -97.02806729239015, "Episode length": 999, "Policy Loss": -0.30274873971939087, "Value Loss": 0.005915833171457052, "_runtime": 16803.02987599373, "_timestamp": 1585586718.8745093, "_step": 295}
{"Episode reward": -97.75304658799213, "Episode length": 999, "Policy Loss": -0.3076322674751282, "Value Loss": 0.005885517690330744, "_runtime": 16804.48739051819, "_timestamp": 1585586720.3320239, "_step": 296}
{"Episode reward": 13.094740694638674, "Episode length": 901, "Policy Loss": 0.1448272168636322, "Value Loss": 11.087395668029785, "_runtime": 16806.055461406708, "_timestamp": 1585586721.9000947, "_step": 297}
{"Episode reward": -97.67344958573683, "Episode length": 999, "Policy Loss": -0.2955682575702667, "Value Loss": 0.005658912938088179, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846, -0.21243028342723846]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-4.482593536376953, -4.409239292144775, -4.3358845710754395, -4.262530326843262, -4.189175605773926, -4.115821361541748, -4.04246711730957, -3.9691123962402344, -3.8957581520080566, -3.8224036693573, -3.749049186706543, -3.6756949424743652, -3.6023402214050293, -3.5289859771728516, -3.4556314945220947, -3.382277011871338, -3.30892276763916, -3.235568046569824, -3.1622138023376465, -3.0888593196868896, -3.015504837036133, -2.942150592803955, -2.8687961101531982, -2.7954416275024414, -2.7220871448516846, -2.6487326622009277, -2.57537841796875, -2.502023935317993, -2.4286694526672363, -2.3553149700164795, -2.2819607257843018, -2.208606243133545, -2.135251760482788, -2.0618972778320312, -1.9885427951812744, -1.9151885509490967, -1.8418340682983398, -1.768479585647583, -1.6951251029968262, -1.6217708587646484, -1.5484163761138916, -1.4750618934631348, -1.401707410812378, -1.328352928161621, -1.2549986839294434, -1.1816442012786865, -1.1082897186279297, -1.0349352359771729, -0.961580753326416, -0.8882265090942383, -0.8148720264434814, -0.7415175437927246, -0.6681630611419678, -0.59480881690979, -0.5214543342590332, -0.44810009002685547, -0.37474536895751953, -0.3013911247253418, -0.22803640365600586, -0.15468215942382812, -0.08132791519165039, -0.007973194122314453, 0.06538105010986328, 0.13873577117919922, 0.21209001541137695]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.354903906583786, -0.34861457347869873, -0.34232524037361145, -0.33603590726852417, -0.3297465741634369, -0.3234572410583496, -0.31716787815093994, -0.31087854504585266, -0.3045892119407654, -0.2982998788356781, -0.2920105457305908, -0.28572121262550354, -0.27943187952041626, -0.2731425166130066, -0.2668532133102417, -0.26056385040283203, -0.25427451729774475, -0.24798518419265747, -0.2416958510875702, -0.2354065179824829, -0.22911718487739563, -0.22282783687114716, -0.21653850376605988, -0.2102491706609726, -0.20395983755588531, -0.19767050445079803, -0.19138115644454956, -0.18509182333946228, -0.178802490234375, -0.17251315712928772, -0.16622380912303925, -0.15993447601795197, -0.15364514291286469, -0.1473558098077774, -0.14106647670269012, -0.13477712869644165, -0.12848779559135437, -0.12219846248626709, -0.11590912938117981, -0.10961978137493134, -0.10333046317100525, -0.09704113006591797, -0.0907517671585083, -0.08446243405342102, -0.07817310094833374, -0.07188376784324646, -0.06559443473815918, -0.0593051016330719, -0.05301576852798462, -0.04672643542289734, -0.04043710231781006, -0.03414773941040039, -0.02785840630531311, -0.02156907320022583, -0.01527974009513855, -0.00899040699005127, -0.0027010738849639893, 0.003588259220123291, 0.009877592325210571, 0.01616692543029785, 0.02245628833770752, 0.0287456214427948, 0.03503495454788208, 0.04132428765296936, 0.04761362075805664]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 5.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 4.0, 4.0, 4.0, 1.0, 3.0, 3.0, 6.0, 4.0, 17.0, 30.0, 26.0, 221.0, 35.0, 18.0, 18.0, 14.0, 19.0, 9.0, 12.0, 5.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0], "bins": [-0.5491591095924377, -0.5362213850021362, -0.5232837200164795, -0.510345995426178, -0.49740827083587646, -0.48447057604789734, -0.4715328812599182, -0.4585951566696167, -0.4456574618816376, -0.43271976709365845, -0.41978204250335693, -0.4068443477153778, -0.3939066529273987, -0.38096892833709717, -0.36803123354911804, -0.3550935387611389, -0.3421558141708374, -0.3292180895805359, -0.31628039479255676, -0.30334270000457764, -0.2904049754142761, -0.277467280626297, -0.26452958583831787, -0.25159186124801636, -0.23865416646003723, -0.2257164716720581, -0.2127787470817566, -0.19984105229377747, -0.18690335750579834, -0.17396563291549683, -0.1610279381275177, -0.1480902135372162, -0.13515251874923706, -0.12221482396125793, -0.10927709937095642, -0.0963394045829773, -0.08340167999267578, -0.07046398520469666, -0.05752629041671753, -0.044588565826416016, -0.0316508412361145, -0.018713176250457764, -0.00577545166015625, 0.007162272930145264, 0.020099937915802002, 0.033037662506103516, 0.04597538709640503, 0.05891305208206177, 0.07185077667236328, 0.0847885012626648, 0.09772616624832153, 0.11066389083862305, 0.12360161542892456, 0.1365392804145813, 0.1494770050048828, 0.16241472959518433, 0.17535239458084106, 0.18829011917114258, 0.2012278437614441, 0.2141655683517456, 0.22710323333740234, 0.24004095792770386, 0.25297868251800537, 0.2659163475036621, 0.2788540720939636]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.716978907585144, -0.6884425282478333, -0.6599062085151672, -0.6313698291778564, -0.6028334498405457, -0.5742970705032349, -0.5457607507705688, -0.5172243714332581, -0.48868799209594727, -0.46015164256095886, -0.43161529302597046, -0.40307891368865967, -0.37454256415367126, -0.3460061848163605, -0.31746983528137207, -0.2889334559440613, -0.2603971064090729, -0.23186075687408447, -0.20332437753677368, -0.1747879981994629, -0.14625167846679688, -0.11771529912948608, -0.08917891979217529, -0.0606425404548645, -0.032106220722198486, -0.0035698413848876953, 0.024966537952423096, 0.05350285768508911, 0.0820392370223999, 0.1105756163597107, 0.13911199569702148, 0.1676483154296875, 0.1961846947669983, 0.22472107410430908, 0.2532573938369751, 0.2817937731742859, 0.3103301525115967, 0.3388664722442627, 0.36740291118621826, 0.3959392309188843, 0.4244755506515503, 0.45301198959350586, 0.4815483093261719, 0.5100846290588379, 0.5386210680007935, 0.5671573877334595, 0.595693826675415, 0.624230146408081, 0.6527664661407471, 0.6813029050827026, 0.7098392248153687, 0.7383755445480347, 0.7669119834899902, 0.7954483032226562, 0.8239846229553223, 0.8525210618972778, 0.8810573816299438, 0.9095937013626099, 0.9381301403045654, 0.9666664600372314, 0.995202898979187, 1.023739218711853, 1.052275538444519, 1.0808119773864746, 1.1093482971191406]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 5.0, 1.0, 4.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.4154544770717621, -0.40299609303474426, -0.39053767919540405, -0.37807929515838623, -0.365620881319046, -0.3531624972820282, -0.340704083442688, -0.32824569940567017, -0.31578731536865234, -0.30332890152931213, -0.2908704876899719, -0.2784121036529541, -0.2659537196159363, -0.25349533557891846, -0.24103692173957825, -0.22857852280139923, -0.21612012386322021, -0.2036617249250412, -0.19120332598686218, -0.17874492704868317, -0.16628652811050415, -0.15382814407348633, -0.14136973023414612, -0.1289113461971283, -0.11645296216011047, -0.10399454832077026, -0.09153616428375244, -0.07907775044441223, -0.06661936640739441, -0.0541609525680542, -0.04170256853103638, -0.029244154691696167, -0.016785770654678345, -0.0043273866176605225, 0.008131027221679688, 0.02058941125869751, 0.03304782509803772, 0.04550620913505554, 0.05796462297439575, 0.07042300701141357, 0.08288142085075378, 0.0953398048877716, 0.10779818892478943, 0.12025657296180725, 0.13271501660346985, 0.14517340064048767, 0.1576317846775055, 0.17009016871452332, 0.18254855275154114, 0.19500699639320374, 0.20746538043022156, 0.21992376446723938, 0.2323821485042572, 0.2448405921459198, 0.2572989761829376, 0.26975736021995544, 0.28221574425697327, 0.2946741282939911, 0.3071325719356537, 0.3195909559726715, 0.33204934000968933, 0.34450772404670715, 0.35696616768836975, 0.3694245517253876, 0.3818829357624054]}, "_runtime": 16807.62605881691, "_timestamp": 1585586723.4706922, "_step": 298}
{"Episode reward": -96.98326864491469, "Episode length": 999, "Policy Loss": -0.28858545422554016, "Value Loss": 0.005418683402240276, "_runtime": 16808.215228557587, "_timestamp": 1585586724.059862, "_step": 299}
{"Episode reward": 64.64261272096053, "Episode length": 364, "Policy Loss": 0.8528248071670532, "Value Loss": 27.437532424926758, "_runtime": 16808.711819410324, "_timestamp": 1585586724.5564528, "_step": 300}
{"Episode reward": 70.70301409799217, "Episode length": 299, "Policy Loss": 0.9547603130340576, "Value Loss": 33.401123046875, "_runtime": 16810.27411031723, "_timestamp": 1585586726.1187437, "_step": 301}
{"Episode reward": -97.45279659487215, "Episode length": 999, "Policy Loss": -0.29401203989982605, "Value Loss": 0.005477223079651594, "_runtime": 16811.78664970398, "_timestamp": 1585586727.631283, "_step": 302}
{"Episode reward": -98.01778614664514, "Episode length": 999, "Policy Loss": -0.3032003343105316, "Value Loss": 0.005710171535611153, "_runtime": 16813.290709733963, "_timestamp": 1585586729.135343, "_step": 303}
{"Episode reward": -97.85594161447241, "Episode length": 999, "Policy Loss": -0.3034569025039673, "Value Loss": 0.005821857135742903, "_runtime": 16814.800669193268, "_timestamp": 1585586730.6453025, "_step": 304}
{"Episode reward": 7.119893557531412, "Episode length": 955, "Policy Loss": 0.34711697697639465, "Value Loss": 10.460853576660156, "_runtime": 16816.3621199131, "_timestamp": 1585586732.2067533, "_step": 305}
{"Episode reward": -97.36695836607036, "Episode length": 999, "Policy Loss": -0.3030451238155365, "Value Loss": 0.0057908049784600735, "_runtime": 16817.90643453598, "_timestamp": 1585586733.7510679, "_step": 306}
{"Episode reward": -97.77665028450798, "Episode length": 999, "Policy Loss": -0.29947540163993835, "Value Loss": 0.005749656818807125, "_runtime": 16819.326355695724, "_timestamp": 1585586735.170989, "_step": 307}
{"Episode reward": 11.837864541037405, "Episode length": 903, "Policy Loss": 0.12070837616920471, "Value Loss": 11.063040733337402, "_runtime": 16820.898401498795, "_timestamp": 1585586736.7430348, "_step": 308}
{"Episode reward": -98.1268393319982, "Episode length": 999, "Policy Loss": -0.29745417833328247, "Value Loss": 0.005558013450354338, "_runtime": 16821.860513687134, "_timestamp": 1585586737.705147, "_step": 309}
{"Episode reward": 39.86946820315166, "Episode length": 616, "Policy Loss": 0.32614681124687195, "Value Loss": 16.215009689331055, "_runtime": 16823.433403253555, "_timestamp": 1585586739.2780366, "_step": 310}
{"Episode reward": -96.86752237991259, "Episode length": 999, "Policy Loss": -0.28845593333244324, "Value Loss": 0.005301680415868759, "_runtime": 16824.775626897812, "_timestamp": 1585586740.6202602, "_step": 311}
{"Episode reward": 16.702674699740996, "Episode length": 852, "Policy Loss": 0.13374382257461548, "Value Loss": 11.725127220153809, "_runtime": 16825.793879032135, "_timestamp": 1585586741.6385124, "_step": 312}
{"Episode reward": 35.73898367664816, "Episode length": 659, "Policy Loss": 0.7427487373352051, "Value Loss": 15.157524108886719, "_runtime": 16827.405812978745, "_timestamp": 1585586743.2504463, "_step": 313}
{"Episode reward": -97.76289755387606, "Episode length": 999, "Policy Loss": -0.290813148021698, "Value Loss": 0.005240666680037975, "_runtime": 16828.61729335785, "_timestamp": 1585586744.4619267, "_step": 314}
{"Episode reward": 24.482348441974665, "Episode length": 771, "Policy Loss": 0.49644041061401367, "Value Loss": 12.956459045410156, "_runtime": 16830.14957022667, "_timestamp": 1585586745.9942036, "_step": 315}
{"Episode reward": -97.25340080105022, "Episode length": 999, "Policy Loss": -0.28463679552078247, "Value Loss": 0.005217438563704491, "_runtime": 16831.717136383057, "_timestamp": 1585586747.5617697, "_step": 316}
{"Episode reward": -97.70762761904356, "Episode length": 999, "Policy Loss": -0.2848100960254669, "Value Loss": 0.005227371584624052, "_runtime": 16832.409122228622, "_timestamp": 1585586748.2537556, "_step": 317}
{"Episode reward": 57.49691149942091, "Episode length": 432, "Policy Loss": 0.5978701114654541, "Value Loss": 23.119966506958008, "_runtime": 16833.97431087494, "_timestamp": 1585586749.8189442, "_step": 318}
{"Episode reward": -97.77329650942886, "Episode length": 999, "Policy Loss": -0.2836119532585144, "Value Loss": 0.005183578003197908, "_runtime": 16835.55812549591, "_timestamp": 1585586751.4027588, "_step": 319}
{"Episode reward": -97.4827743746253, "Episode length": 999, "Policy Loss": -0.28429722785949707, "Value Loss": 0.005116680171340704, "_runtime": 16837.073513269424, "_timestamp": 1585586752.9181466, "_step": 320}
{"Episode reward": -97.57983913991607, "Episode length": 999, "Policy Loss": -0.2772505581378937, "Value Loss": 0.005038508679717779, "_runtime": 16838.642590522766, "_timestamp": 1585586754.4872239, "_step": 321}
{"Episode reward": -97.70131271295975, "Episode length": 999, "Policy Loss": -0.2766142785549164, "Value Loss": 0.004876064136624336, "_runtime": 16840.215819597244, "_timestamp": 1585586756.060453, "_step": 322}
{"Episode reward": -97.11436470431482, "Episode length": 999, "Policy Loss": -0.26778486371040344, "Value Loss": 0.004682688973844051, "_runtime": 16841.770686149597, "_timestamp": 1585586757.6153195, "_step": 323}
{"Episode reward": -97.77740655149282, "Episode length": 999, "Policy Loss": -0.26649969816207886, "Value Loss": 0.0044152094051241875, "_runtime": 16843.350729703903, "_timestamp": 1585586759.195363, "_step": 324}
{"Episode reward": -97.4970382797103, "Episode length": 999, "Policy Loss": -0.2575071454048157, "Value Loss": 0.004131012130528688, "_runtime": 16844.93651342392, "_timestamp": 1585586760.7811468, "_step": 325}
{"Episode reward": -97.70395969634346, "Episode length": 999, "Policy Loss": -0.24518154561519623, "Value Loss": 0.0038729719817638397, "_runtime": 16845.47803425789, "_timestamp": 1585586761.3226676, "_step": 326}
{"Episode reward": 68.80082881001702, "Episode length": 320, "Policy Loss": 0.9611290693283081, "Value Loss": 31.216018676757812, "_runtime": 16846.339616775513, "_timestamp": 1585586762.18425, "_step": 327}
{"Episode reward": 47.4172886916565, "Episode length": 544, "Policy Loss": 0.546272337436676, "Value Loss": 18.363910675048828, "_runtime": 16847.38739991188, "_timestamp": 1585586763.2320333, "_step": 328}
{"Episode reward": 35.58801809174048, "Episode length": 660, "Policy Loss": 0.3295504152774811, "Value Loss": 15.160134315490723, "_runtime": 16848.773551225662, "_timestamp": 1585586764.6181846, "_step": 329}
{"Episode reward": 10.099185549941822, "Episode length": 920, "Policy Loss": 0.18271899223327637, "Value Loss": 10.859938621520996, "_runtime": 16849.15381360054, "_timestamp": 1585586764.998447, "_step": 330}
{"Episode reward": 77.66042164293587, "Episode length": 231, "Policy Loss": 1.3426122665405273, "Value Loss": 43.239402770996094, "_runtime": 16850.602130889893, "_timestamp": 1585586766.4467642, "_step": 331}
{"Episode reward": 8.817535226727998, "Episode length": 938, "Policy Loss": 0.128736212849617, "Value Loss": 10.6510648727417, "_runtime": 16852.16742992401, "_timestamp": 1585586768.0120633, "_step": 332}
{"Episode reward": 3.905509829808537, "Episode length": 988, "Policy Loss": 0.08049429208040237, "Value Loss": 10.11193561553955, "_runtime": 16852.90264415741, "_timestamp": 1585586768.7472775, "_step": 333}
{"Episode reward": 52.17153333749218, "Episode length": 491, "Policy Loss": 0.4368029236793518, "Value Loss": 20.34153938293457, "_runtime": 16854.44766664505, "_timestamp": 1585586770.2923, "_step": 334}
{"Episode reward": -96.89915998035579, "Episode length": 999, "Policy Loss": -0.3091385066509247, "Value Loss": 0.006135847885161638, "_runtime": 16854.950627088547, "_timestamp": 1585586770.7952604, "_step": 335}
{"Episode reward": 71.61335511774388, "Episode length": 298, "Policy Loss": 1.070990800857544, "Value Loss": 33.50780487060547, "_runtime": 16856.464395046234, "_timestamp": 1585586772.3090284, "_step": 336}
{"Episode reward": -97.18415472019747, "Episode length": 999, "Policy Loss": -0.34413209557533264, "Value Loss": 0.007546065840870142, "_runtime": 16858.041682481766, "_timestamp": 1585586773.8863158, "_step": 337}
{"Episode reward": -97.20924944127256, "Episode length": 999, "Policy Loss": -0.3613603711128235, "Value Loss": 0.008228795602917671, "_runtime": 16859.542254447937, "_timestamp": 1585586775.3868878, "_step": 338}
{"Episode reward": -97.47444852347073, "Episode length": 999, "Policy Loss": -0.3742459714412689, "Value Loss": 0.008801291696727276, "_runtime": 16860.380545139313, "_timestamp": 1585586776.2251785, "_step": 339}
{"Episode reward": 48.80655819451516, "Episode length": 526, "Policy Loss": 0.6266082525253296, "Value Loss": 18.983673095703125, "_runtime": 16861.30498290062, "_timestamp": 1585586777.1496162, "_step": 340}
{"Episode reward": 43.9314870259679, "Episode length": 581, "Policy Loss": 0.5024022459983826, "Value Loss": 17.18697166442871, "_runtime": 16862.85833954811, "_timestamp": 1585586778.702973, "_step": 341}
{"Episode reward": -97.42765293854646, "Episode length": 999, "Policy Loss": -0.401843786239624, "Value Loss": 0.010170298628509045, "_runtime": 16864.396634817123, "_timestamp": 1585586780.2412682, "_step": 342}
{"Episode reward": -97.46758895314296, "Episode length": 999, "Policy Loss": -0.40799248218536377, "Value Loss": 0.010533462278544903, "_runtime": 16865.08171391487, "_timestamp": 1585586780.9263473, "_step": 343}
{"Episode reward": 56.94162007466453, "Episode length": 441, "Policy Loss": 0.5096114277839661, "Value Loss": 22.63896942138672, "_runtime": 16866.647169828415, "_timestamp": 1585586782.4918032, "_step": 344}
{"Episode reward": -97.87208034152742, "Episode length": 999, "Policy Loss": -0.4232563376426697, "Value Loss": 0.011076703667640686, "_runtime": 16868.199962615967, "_timestamp": 1585586784.044596, "_step": 345}
{"Episode reward": -97.73982380462041, "Episode length": 999, "Policy Loss": -0.42353156208992004, "Value Loss": 0.011209369637072086, "_runtime": 16869.719685077667, "_timestamp": 1585586785.5643184, "_step": 346}
{"Episode reward": -97.32842560538664, "Episode length": 999, "Policy Loss": -0.4223470389842987, "Value Loss": 0.011103043332695961, "_runtime": 16871.290199756622, "_timestamp": 1585586787.134833, "_step": 347}
{"Episode reward": -97.35518308588821, "Episode length": 999, "Policy Loss": -0.4205886721611023, "Value Loss": 0.010894731618463993, "_runtime": 16872.393038272858, "_timestamp": 1585586788.2376716, "_step": 348}
{"Episode reward": 30.94103903324192, "Episode length": 703, "Policy Loss": 0.15022675693035126, "Value Loss": 14.205753326416016, "_runtime": 16873.909760951996, "_timestamp": 1585586789.7543943, "_step": 349}
{"Episode reward": 5.012546726140812, "Episode length": 977, "Policy Loss": -0.04061559960246086, "Value Loss": 10.224645614624023, "_runtime": 16875.52448964119, "_timestamp": 1585586791.369123, "_step": 350}
{"Episode reward": -97.71158246391566, "Episode length": 999, "Policy Loss": -0.4014419615268707, "Value Loss": 0.010168067179620266, "_runtime": 16877.06841635704, "_timestamp": 1585586792.9130497, "_step": 351}
{"Episode reward": -96.65475068488223, "Episode length": 999, "Policy Loss": -0.39270731806755066, "Value Loss": 0.009679269976913929, "_runtime": 16878.631474018097, "_timestamp": 1585586794.4761074, "_step": 352}
{"Episode reward": -97.50123828111954, "Episode length": 999, "Policy Loss": -0.3889458179473877, "Value Loss": 0.00930373277515173, "_runtime": 16879.6365711689, "_timestamp": 1585586795.4812045, "_step": 353}
{"Episode reward": 38.45911236278107, "Episode length": 632, "Policy Loss": 0.19206717610359192, "Value Loss": 15.801445960998535, "_runtime": 16881.193545103073, "_timestamp": 1585586797.0381784, "_step": 354}
{"Episode reward": -96.30311155494097, "Episode length": 999, "Policy Loss": -0.357237845659256, "Value Loss": 0.008322987705469131, "_runtime": 16882.265627384186, "_timestamp": 1585586798.1102607, "_step": 355}
{"Episode reward": 34.09192456269689, "Episode length": 678, "Policy Loss": 0.20459307730197906, "Value Loss": 14.730497360229492, "_runtime": 16883.35125851631, "_timestamp": 1585586799.1958919, "_step": 356}
{"Episode reward": 31.37079658421034, "Episode length": 700, "Policy Loss": 0.19958113133907318, "Value Loss": 14.268073081970215, "_runtime": 16884.079590320587, "_timestamp": 1585586799.9242237, "_step": 357}
{"Episode reward": 55.78153926053273, "Episode length": 451, "Policy Loss": 0.4374845623970032, "Value Loss": 22.141630172729492, "_runtime": 16885.615957975388, "_timestamp": 1585586801.4605913, "_step": 358}
{"Episode reward": -97.14030362238746, "Episode length": 999, "Policy Loss": -0.3405205011367798, "Value Loss": 0.00738522270694375, "_runtime": 16887.160293340683, "_timestamp": 1585586803.0049267, "_step": 359}
{"Episode reward": -97.56758075206864, "Episode length": 999, "Policy Loss": -0.3397083878517151, "Value Loss": 0.007329990155994892, "_runtime": 16888.677306890488, "_timestamp": 1585586804.5219402, "_step": 360}
{"Episode reward": -97.37342975266995, "Episode length": 999, "Policy Loss": -0.3340499997138977, "Value Loss": 0.007179589942097664, "_runtime": 16890.245445728302, "_timestamp": 1585586806.090079, "_step": 361}
{"Episode reward": -96.6825675944886, "Episode length": 999, "Policy Loss": -0.32200321555137634, "Value Loss": 0.006748279556632042, "_runtime": 16890.74196791649, "_timestamp": 1585586806.5866013, "_step": 362}
{"Episode reward": 71.99701547595181, "Episode length": 289, "Policy Loss": 0.8948075175285339, "Value Loss": 34.5521354675293, "_runtime": 16892.296713590622, "_timestamp": 1585586808.141347, "_step": 363}
{"Episode reward": -97.10299472833131, "Episode length": 999, "Policy Loss": -0.32110118865966797, "Value Loss": 0.006406298838555813, "_runtime": 16893.243228912354, "_timestamp": 1585586809.0878623, "_step": 364}
{"Episode reward": 42.634596491868365, "Episode length": 588, "Policy Loss": 0.3251606523990631, "Value Loss": 16.98564910888672, "_runtime": 16893.611018896103, "_timestamp": 1585586809.4556522, "_step": 365}
{"Episode reward": 77.85056331444419, "Episode length": 231, "Policy Loss": 1.3527445793151855, "Value Loss": 43.22616195678711, "_runtime": 16895.166038751602, "_timestamp": 1585586811.010672, "_step": 366}
{"Episode reward": -97.51515016313343, "Episode length": 999, "Policy Loss": -0.3316008448600769, "Value Loss": 0.006876596249639988, "_runtime": 16896.702308177948, "_timestamp": 1585586812.5469415, "_step": 367}
{"Episode reward": -96.74908874584315, "Episode length": 999, "Policy Loss": -0.3327927589416504, "Value Loss": 0.007173122372478247, "_runtime": 16897.961337327957, "_timestamp": 1585586813.8059707, "_step": 368}
{"Episode reward": 18.029005183816153, "Episode length": 846, "Policy Loss": 0.15438833832740784, "Value Loss": 11.830480575561523, "_runtime": 16899.558583021164, "_timestamp": 1585586815.4032164, "_step": 369}
{"Episode reward": -97.53070607762496, "Episode length": 999, "Policy Loss": -0.3488253355026245, "Value Loss": 0.007665219716727734, "_runtime": 16900.624222278595, "_timestamp": 1585586816.4688556, "_step": 370}
{"Episode reward": 33.34110904962854, "Episode length": 680, "Policy Loss": 0.25623175501823425, "Value Loss": 14.687426567077637, "_runtime": 16902.153092861176, "_timestamp": 1585586817.9977262, "_step": 371}
{"Episode reward": -97.3938189212619, "Episode length": 999, "Policy Loss": -0.35503676533699036, "Value Loss": 0.00791291892528534, "_runtime": 16903.731132507324, "_timestamp": 1585586819.5757658, "_step": 372}
{"Episode reward": -97.53280498527072, "Episode length": 999, "Policy Loss": -0.35862764716148376, "Value Loss": 0.007950316183269024, "_runtime": 16904.49428009987, "_timestamp": 1585586820.3389134, "_step": 373}
{"Episode reward": 52.952702455834334, "Episode length": 481, "Policy Loss": 0.4071672856807709, "Value Loss": 20.76054573059082, "_runtime": 16905.799166679382, "_timestamp": 1585586821.6438, "_step": 374}
{"Episode reward": 17.895291293463103, "Episode length": 839, "Policy Loss": 0.40116071701049805, "Value Loss": 11.905362129211426, "_runtime": 16906.853306531906, "_timestamp": 1585586822.6979399, "_step": 375}
{"Episode reward": 35.135616206372575, "Episode length": 667, "Policy Loss": 0.37975940108299255, "Value Loss": 14.973224639892578, "_runtime": 16908.378190517426, "_timestamp": 1585586824.2228239, "_step": 376}
{"Episode reward": -97.19700522514925, "Episode length": 999, "Policy Loss": -0.36187252402305603, "Value Loss": 0.008230038918554783, "_runtime": 16909.923161029816, "_timestamp": 1585586825.7677944, "_step": 377}
{"Episode reward": -97.36208282435074, "Episode length": 999, "Policy Loss": -0.35929569602012634, "Value Loss": 0.008288114331662655, "_runtime": 16911.463811397552, "_timestamp": 1585586827.3084447, "_step": 378}
{"Episode reward": -97.5303318870617, "Episode length": 999, "Policy Loss": -0.36303389072418213, "Value Loss": 0.0082024447619915, "_runtime": 16913.00555920601, "_timestamp": 1585586828.8501925, "_step": 379}
{"Episode reward": 4.302778818089536, "Episode length": 986, "Policy Loss": 0.2744157910346985, "Value Loss": 10.131539344787598, "_runtime": 16914.576983451843, "_timestamp": 1585586830.4216168, "_step": 380}
{"Episode reward": -97.5390298403936, "Episode length": 999, "Policy Loss": -0.35176631808280945, "Value Loss": 0.007854581810534, "_runtime": 16916.151469945908, "_timestamp": 1585586831.9961033, "_step": 381}
{"Episode reward": -97.46266988719486, "Episode length": 999, "Policy Loss": -0.34775635600090027, "Value Loss": 0.007597979623824358, "_runtime": 16917.72569012642, "_timestamp": 1585586833.5703235, "_step": 382}
{"Episode reward": -97.93343767850492, "Episode length": 999, "Policy Loss": -0.34490513801574707, "Value Loss": 0.0072545078583061695, "_runtime": 16919.289298295975, "_timestamp": 1585586835.1339316, "_step": 383}
{"Episode reward": -97.32392362355895, "Episode length": 999, "Policy Loss": -0.3262271583080292, "Value Loss": 0.006822454743087292, "_runtime": 16920.86762404442, "_timestamp": 1585586836.7122574, "_step": 384}
{"Episode reward": -97.80618464982251, "Episode length": 999, "Policy Loss": -0.31978657841682434, "Value Loss": 0.0063399579375982285, "_runtime": 16922.489036798477, "_timestamp": 1585586838.3336701, "_step": 385}
{"Episode reward": -97.00287813528291, "Episode length": 999, "Policy Loss": -0.3037731647491455, "Value Loss": 0.005772513337433338, "_runtime": 16924.065041065216, "_timestamp": 1585586839.9096744, "_step": 386}
{"Episode reward": -97.76424126068336, "Episode length": 999, "Policy Loss": -0.2913062870502472, "Value Loss": 0.0053125955164432526, "_runtime": 16925.63772559166, "_timestamp": 1585586841.482359, "_step": 387}
{"Episode reward": -97.97576734640872, "Episode length": 999, "Policy Loss": -0.275909423828125, "Value Loss": 0.004789205268025398, "_runtime": 16926.313846111298, "_timestamp": 1585586842.1584795, "_step": 388}
{"Episode reward": 58.943787618777236, "Episode length": 416, "Policy Loss": 0.6406193971633911, "Value Loss": 24.011016845703125, "_runtime": 16927.887926101685, "_timestamp": 1585586843.7325594, "_step": 389}
{"Episode reward": -97.42561126293776, "Episode length": 999, "Policy Loss": -0.24997831881046295, "Value Loss": 0.0039931186474859715, "_runtime": 16929.47066283226, "_timestamp": 1585586845.3152962, "_step": 390}
{"Episode reward": -98.09839624974451, "Episode length": 999, "Policy Loss": -0.2449716329574585, "Value Loss": 0.0037041078321635723, "_runtime": 16930.97651195526, "_timestamp": 1585586846.8211453, "_step": 391}
{"Episode reward": -97.37376053399039, "Episode length": 999, "Policy Loss": -0.22664521634578705, "Value Loss": 0.0033638610038906336, "_runtime": 16932.550482988358, "_timestamp": 1585586848.3951163, "_step": 392}
{"Episode reward": -96.81805639758986, "Episode length": 999, "Policy Loss": -0.21161405742168427, "Value Loss": 0.0030572237446904182, "_runtime": 16934.11005973816, "_timestamp": 1585586849.954693, "_step": 393}
{"Episode reward": -97.3626394568492, "Episode length": 999, "Policy Loss": -0.20308342576026917, "Value Loss": 0.002739239949733019, "_runtime": 16935.67361664772, "_timestamp": 1585586851.51825, "_step": 394}
{"Episode reward": -97.68103446247704, "Episode length": 999, "Policy Loss": -0.19150608777999878, "Value Loss": 0.0024380784016102552, "_runtime": 16937.261324882507, "_timestamp": 1585586853.1059582, "_step": 395}
{"Episode reward": -97.39638828456846, "Episode length": 999, "Policy Loss": -0.17792761325836182, "Value Loss": 0.0021482149604707956, "_runtime": 16938.84071612358, "_timestamp": 1585586854.6853495, "_step": 396}
{"Episode reward": -97.32708816836818, "Episode length": 999, "Policy Loss": -0.16421785950660706, "Value Loss": 0.0018602825002744794, "_runtime": 16940.415830373764, "_timestamp": 1585586856.2604637, "_step": 397}
{"Episode reward": -96.92466846637757, "Episode length": 999, "Policy Loss": -0.15002065896987915, "Value Loss": 0.0016710582422092557, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094, 0.14054812490940094]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.14047686755657196, -0.10904476046562195, -0.07761266082525253, -0.04618056118488312, -0.014748454093933105, 0.016683652997016907, 0.048115745186805725, 0.07954785227775574, 0.11097995936870575, 0.14241205155849457, 0.17384417355060577, 0.2052762657403946, 0.2367083579301834, 0.2681404948234558, 0.29957258701324463, 0.33100467920303345, 0.36243677139282227, 0.3938688635826111, 0.4253009557723999, 0.4567331075668335, 0.4881651997566223, 0.5195972919464111, 0.5510293841362, 0.5824614763259888, 0.6138935685157776, 0.6453257203102112, 0.6767578125, 0.7081899046897888, 0.7396219968795776, 0.7710540890693665, 0.8024862408638, 0.8339183330535889, 0.8653504252433777, 0.8967825770378113, 0.9282146096229553, 0.9596467614173889, 0.991078794002533, 1.0225110054016113, 1.053943157196045, 1.085375189781189, 1.1168073415756226, 1.1482393741607666, 1.1796715259552002, 1.2111036777496338, 1.2425357103347778, 1.2739678621292114, 1.3053998947143555, 1.336832046508789, 1.368264079093933, 1.3996962308883667, 1.4311283826828003, 1.4625604152679443, 1.493992567062378, 1.525424599647522, 1.5568567514419556, 1.5882889032363892, 1.6197209358215332, 1.6511530876159668, 1.6825851202011108, 1.7140172719955444, 1.745449423789978, 1.776881456375122, 1.8083136081695557, 1.8397456407546997, 1.8711777925491333]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-0.031493108719587326, -0.029632391408085823, -0.02777167409658432, -0.025910958647727966, -0.024050239473581314, -0.02218952402472496, -0.020328806713223457, -0.018468089401721954, -0.01660737209022045, -0.014746654778718948, -0.012885937467217445, -0.011025220155715942, -0.009164504706859589, -0.007303787395358086, -0.005443070083856583, -0.0035823527723550797, -0.0017216354608535767, 0.0001390799880027771, 0.0019997991621494293, 0.003860514611005783, 0.005721233785152435, 0.007581949234008789, 0.009442668408155441, 0.011303383857011795, 0.013164099305868149, 0.015024818480014801, 0.016885533928871155, 0.018746253103017807, 0.02060696855187416, 0.022467687726020813, 0.024328403174877167, 0.02618912234902382, 0.028049837797880173, 0.029910553246736526, 0.03177126869559288, 0.03363199159502983, 0.035492707043886185, 0.03735342249274254, 0.03921413794159889, 0.04107486084103584, 0.0429355762898922, 0.04479629173874855, 0.046657007187604904, 0.04851772263646126, 0.05037844553589821, 0.05223916098475456, 0.054099876433610916, 0.05596059188246727, 0.057821307331323624, 0.059682030230760574, 0.06154274567961693, 0.06340345740318298, 0.06526418030261993, 0.06712490320205688, 0.06898561120033264, 0.07084633409976959, 0.07270704209804535, 0.0745677649974823, 0.07642848789691925, 0.07828919589519501, 0.08014991879463196, 0.08201062679290771, 0.08387134969234467, 0.08573207259178162, 0.08759278059005737]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 6.0, 3.0, 2.0, 9.0, 7.0, 5.0, 8.0, 9.0, 3.0, 11.0, 15.0, 9.0, 16.0, 12.0, 8.0, 11.0, 7.0, 13.0, 182.0, 21.0, 5.0, 6.0, 14.0, 15.0, 16.0, 9.0, 6.0, 3.0, 5.0, 2.0, 7.0, 1.0, 4.0, 2.0, 2.0, 5.0, 3.0, 2.0, 5.0, 7.0, 2.0, 0.0, 3.0, 7.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-0.07012922316789627, -0.06660114228725433, -0.0630730614066124, -0.05954498425126076, -0.05601690709590912, -0.05248882621526718, -0.048960745334625244, -0.04543266445398331, -0.04190458729863167, -0.03837650641798973, -0.03484842926263809, -0.031320348381996155, -0.027792267501354218, -0.02426419034600258, -0.02073610946536064, -0.017208032310009003, -0.013679951429367065, -0.010151870548725128, -0.006623789668083191, -0.0030957162380218506, 0.00043236464262008667, 0.003960445523262024, 0.007488526403903961, 0.011016607284545898, 0.014544688165187836, 0.018072761595249176, 0.021600842475891113, 0.02512892335653305, 0.028657004237174988, 0.032185085117816925, 0.035713158547878265, 0.0392412394285202, 0.04276932030916214, 0.04629740118980408, 0.049825482070446014, 0.053353555500507355, 0.05688164383172989, 0.06040971726179123, 0.06393779069185257, 0.0674658790230751, 0.07099395245313644, 0.07452204078435898, 0.07805011421442032, 0.08157818764448166, 0.0851062759757042, 0.08863434940576553, 0.09216243773698807, 0.09569051116704941, 0.09921859949827194, 0.10274667292833328, 0.10627474635839462, 0.10980283468961716, 0.1133309081196785, 0.11685899645090103, 0.12038706988096237, 0.12391514331102371, 0.12744322419166565, 0.13097131252288818, 0.13449940085411072, 0.13802745938301086, 0.1415555477142334, 0.14508363604545593, 0.14861169457435608, 0.1521397829055786, 0.15566787123680115]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.37498897314071655, -0.36392953991889954, -0.35287007689476013, -0.3418106436729431, -0.3307511806488037, -0.3196917474269867, -0.3086323142051697, -0.2975728511810303, -0.28651341795921326, -0.27545398473739624, -0.26439452171325684, -0.2533350884914398, -0.2422756403684616, -0.2312161922454834, -0.22015675902366638, -0.20909731090068817, -0.19803786277770996, -0.18697841465473175, -0.17591896653175354, -0.16485953330993652, -0.1538000851869583, -0.1427406370639801, -0.13168120384216309, -0.12062174081802368, -0.10956230759620667, -0.09850287437438965, -0.08744341135025024, -0.07638397812843323, -0.06532454490661621, -0.05426508188247681, -0.04320564866065979, -0.032146185636520386, -0.02108675241470337, -0.010027319192886353, 0.0010321438312530518, 0.012091577053070068, 0.023151040077209473, 0.03421047329902649, 0.045269906520843506, 0.05632936954498291, 0.06738880276679993, 0.07844823598861694, 0.08950769901275635, 0.10056713223457336, 0.11162656545639038, 0.12268602848052979, 0.1337454915046692, 0.14480489492416382, 0.15586435794830322, 0.16692382097244263, 0.17798322439193726, 0.18904268741607666, 0.20010215044021606, 0.2111615538597107, 0.2222210168838501, 0.2332804799079895, 0.24433988332748413, 0.25539934635162354, 0.26645880937576294, 0.27751827239990234, 0.288577675819397, 0.2996371388435364, 0.3106966018676758, 0.3217560052871704, 0.3328154683113098]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 5.0, 8.0, 1.0, 2.0, 8.0, 6.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.1604977697134018, -0.15519674122333527, -0.14989572763442993, -0.1445946991443634, -0.13929367065429688, -0.13399265706539154, -0.128691628575325, -0.12339060753583908, -0.11808958649635315, -0.11278855800628662, -0.10748753696680069, -0.10218651592731476, -0.09688548743724823, -0.0915844663977623, -0.08628344535827637, -0.08098241686820984, -0.07568139582872391, -0.07038037478923798, -0.06507934629917145, -0.059778325259685516, -0.054477304220199585, -0.04917627573013306, -0.043875254690647125, -0.038574233651161194, -0.033273205161094666, -0.02797219157218933, -0.022671163082122803, -0.017370134592056274, -0.01206912100315094, -0.006768092513084412, -0.0014670640230178833, 0.003833949565887451, 0.00913497805595398, 0.014436006546020508, 0.019737020134925842, 0.02503804862499237, 0.0303390771150589, 0.03564009070396423, 0.04094111919403076, 0.04624214768409729, 0.051543161273002625, 0.05684418976306915, 0.06214521825313568, 0.06744623184204102, 0.07274726033210754, 0.07804828882217407, 0.0833493024110794, 0.08865033090114594, 0.09395135939121246, 0.09925238788127899, 0.10455338656902313, 0.10985441505908966, 0.11515544354915619, 0.12045647203922272, 0.12575750052928925, 0.13105852901935577, 0.13635952770709991, 0.14166055619716644, 0.14696158468723297, 0.1522626131772995, 0.15756364166736603, 0.16286467015743256, 0.1681656688451767, 0.17346669733524323, 0.17876772582530975]}, "_runtime": 16941.99867129326, "_timestamp": 1585586857.8433046, "_step": 398}
{"Episode reward": -97.33830692331559, "Episode length": 999, "Policy Loss": -0.1394312083721161, "Value Loss": 0.0013668081955984235, "_runtime": 16943.58300304413, "_timestamp": 1585586859.4276364, "_step": 399}
{"Episode reward": -97.74214732807117, "Episode length": 999, "Policy Loss": -0.12595234811306, "Value Loss": 0.0011649414664134383, "_runtime": 16945.146429538727, "_timestamp": 1585586860.9910629, "_step": 400}
{"Episode reward": -97.22935355515682, "Episode length": 999, "Policy Loss": -0.11229151487350464, "Value Loss": 0.0009914799593389034, "_runtime": 16946.770978927612, "_timestamp": 1585586862.6156123, "_step": 401}
{"Episode reward": -97.65617724537377, "Episode length": 999, "Policy Loss": -0.1030116155743599, "Value Loss": 0.0008054073550738394, "_runtime": 16947.53744316101, "_timestamp": 1585586863.3820765, "_step": 402}
{"Episode reward": 54.23984356520251, "Episode length": 471, "Policy Loss": 0.9362757205963135, "Value Loss": 21.221817016601562, "_runtime": 16949.13301873207, "_timestamp": 1585586864.977652, "_step": 403}
{"Episode reward": -97.06001954967465, "Episode length": 999, "Policy Loss": -0.08261328935623169, "Value Loss": 0.0006737492512911558, "_runtime": 16950.729553937912, "_timestamp": 1585586866.5741873, "_step": 404}
{"Episode reward": -97.62099829800695, "Episode length": 999, "Policy Loss": -0.0807696133852005, "Value Loss": 0.0005700167384929955, "_runtime": 16952.26899766922, "_timestamp": 1585586868.113631, "_step": 405}
{"Episode reward": -97.90368548749665, "Episode length": 999, "Policy Loss": -0.07693170756101608, "Value Loss": 0.0005174550460651517, "_runtime": 16953.85896730423, "_timestamp": 1585586869.7036006, "_step": 406}
{"Episode reward": -97.57756536889927, "Episode length": 999, "Policy Loss": -0.0699034258723259, "Value Loss": 0.0004732407396659255, "_runtime": 16954.399327993393, "_timestamp": 1585586870.2439613, "_step": 407}
{"Episode reward": 69.5365438920004, "Episode length": 312, "Policy Loss": 1.120901346206665, "Value Loss": 32.03994369506836, "_runtime": 16955.984825372696, "_timestamp": 1585586871.8294587, "_step": 408}
{"Episode reward": -97.05721738394027, "Episode length": 999, "Policy Loss": -0.06834429502487183, "Value Loss": 0.0005407709977589548, "_runtime": 16957.588525533676, "_timestamp": 1585586873.4331589, "_step": 409}
{"Episode reward": -97.77787650446861, "Episode length": 999, "Policy Loss": -0.07608558237552643, "Value Loss": 0.0005505849840119481, "_runtime": 16958.075458288193, "_timestamp": 1585586873.9200916, "_step": 410}
{"Episode reward": 70.45362732068673, "Episode length": 307, "Policy Loss": 1.1085411310195923, "Value Loss": 32.55977249145508, "_runtime": 16959.64597415924, "_timestamp": 1585586875.4906075, "_step": 411}
{"Episode reward": -97.04263681906446, "Episode length": 999, "Policy Loss": -0.08999036997556686, "Value Loss": 0.0007083892705850303, "_runtime": 16960.355628728867, "_timestamp": 1585586876.200262, "_step": 412}
{"Episode reward": 57.12269393535892, "Episode length": 437, "Policy Loss": 0.7620224356651306, "Value Loss": 22.87149429321289, "_runtime": 16961.182733297348, "_timestamp": 1585586877.0273666, "_step": 413}
{"Episode reward": 47.534518007420154, "Episode length": 539, "Policy Loss": 0.5628030896186829, "Value Loss": 18.542078018188477, "_runtime": 16961.79861474037, "_timestamp": 1585586877.643248, "_step": 414}
{"Episode reward": 62.8624820845891, "Episode length": 378, "Policy Loss": 0.8245325684547424, "Value Loss": 26.43679428100586, "_runtime": 16962.783121347427, "_timestamp": 1585586878.6277547, "_step": 415}
{"Episode reward": 36.94330113009604, "Episode length": 646, "Policy Loss": 0.42126110196113586, "Value Loss": 15.46834659576416, "_runtime": 16964.33218741417, "_timestamp": 1585586880.1768208, "_step": 416}
{"Episode reward": -97.2082112649357, "Episode length": 999, "Policy Loss": -0.19268780946731567, "Value Loss": 0.002496095607057214, "_runtime": 16965.264568567276, "_timestamp": 1585586881.109202, "_step": 417}
{"Episode reward": 40.72165245015838, "Episode length": 608, "Policy Loss": 0.3677145838737488, "Value Loss": 16.4320125579834, "_runtime": 16966.806836128235, "_timestamp": 1585586882.6514695, "_step": 418}
{"Episode reward": -96.87729933969365, "Episode length": 999, "Policy Loss": -0.23616649210453033, "Value Loss": 0.003745662048459053, "_runtime": 16967.96883869171, "_timestamp": 1585586883.813472, "_step": 419}
{"Episode reward": 28.40546415466538, "Episode length": 735, "Policy Loss": 0.2241281270980835, "Value Loss": 13.591607093811035, "_runtime": 16969.509783029556, "_timestamp": 1585586885.3544164, "_step": 420}
{"Episode reward": -98.00111867602138, "Episode length": 999, "Policy Loss": -0.2864466607570648, "Value Loss": 0.005060003604739904, "_runtime": 16971.12830233574, "_timestamp": 1585586886.9729357, "_step": 421}
{"Episode reward": -96.57730162722548, "Episode length": 999, "Policy Loss": -0.2918352484703064, "Value Loss": 0.0055257235653698444, "_runtime": 16972.6833217144, "_timestamp": 1585586888.527955, "_step": 422}
{"Episode reward": -97.98291940288887, "Episode length": 999, "Policy Loss": -0.3105629086494446, "Value Loss": 0.00610218895599246, "_runtime": 16973.94087100029, "_timestamp": 1585586889.7855043, "_step": 423}
{"Episode reward": 22.52121130000856, "Episode length": 796, "Policy Loss": 0.12759742140769958, "Value Loss": 12.548822402954102, "_runtime": 16975.5305352211, "_timestamp": 1585586891.3751686, "_step": 424}
{"Episode reward": -97.73586026991447, "Episode length": 999, "Policy Loss": -0.3272075355052948, "Value Loss": 0.006756221875548363, "_runtime": 16977.116142511368, "_timestamp": 1585586892.9607759, "_step": 425}
{"Episode reward": -97.03221678242771, "Episode length": 999, "Policy Loss": -0.33045944571495056, "Value Loss": 0.006909203715622425, "_runtime": 16978.593299865723, "_timestamp": 1585586894.4379332, "_step": 426}
{"Episode reward": 8.103276394872537, "Episode length": 941, "Policy Loss": 0.08039938658475876, "Value Loss": 10.615947723388672, "_runtime": 16980.18360567093, "_timestamp": 1585586896.028239, "_step": 427}
{"Episode reward": -97.28747617183025, "Episode length": 999, "Policy Loss": -0.33619225025177, "Value Loss": 0.007109282072633505, "_runtime": 16981.761632204056, "_timestamp": 1585586897.6062655, "_step": 428}
{"Episode reward": -96.81870721991297, "Episode length": 999, "Policy Loss": -0.3312528431415558, "Value Loss": 0.007068844977766275, "_runtime": 16982.514477968216, "_timestamp": 1585586898.3591113, "_step": 429}
{"Episode reward": 54.032412228382405, "Episode length": 468, "Policy Loss": 0.516700267791748, "Value Loss": 21.338294982910156, "_runtime": 16984.106085062027, "_timestamp": 1585586899.9507184, "_step": 430}
{"Episode reward": -98.19521441648257, "Episode length": 999, "Policy Loss": -0.34078875184059143, "Value Loss": 0.007125884294509888, "_runtime": 16985.6986246109, "_timestamp": 1585586901.543258, "_step": 431}
{"Episode reward": -98.00390606600223, "Episode length": 999, "Policy Loss": -0.3352038562297821, "Value Loss": 0.007049850653856993, "_runtime": 16986.97190785408, "_timestamp": 1585586902.8165412, "_step": 432}
{"Episode reward": 19.134392505887803, "Episode length": 829, "Policy Loss": 0.13816358149051666, "Value Loss": 12.049307823181152, "_runtime": 16988.24573493004, "_timestamp": 1585586904.0903683, "_step": 433}
{"Episode reward": 21.758956661293126, "Episode length": 804, "Policy Loss": 0.12117281556129456, "Value Loss": 12.423840522766113, "_runtime": 16989.312341451645, "_timestamp": 1585586905.1569748, "_step": 434}
{"Episode reward": 34.432681987713735, "Episode length": 670, "Policy Loss": 0.20541085302829742, "Value Loss": 14.907271385192871, "_runtime": 16990.88102030754, "_timestamp": 1585586906.7256536, "_step": 435}
{"Episode reward": -97.29566095116616, "Episode length": 999, "Policy Loss": -0.3269522488117218, "Value Loss": 0.006781945005059242, "_runtime": 16992.45667743683, "_timestamp": 1585586908.3013108, "_step": 436}
{"Episode reward": -97.4060273470738, "Episode length": 999, "Policy Loss": -0.3246454894542694, "Value Loss": 0.0067822872661054134, "_runtime": 16993.864270925522, "_timestamp": 1585586909.7089043, "_step": 437}
{"Episode reward": 10.999495538968233, "Episode length": 910, "Policy Loss": 0.06917490810155869, "Value Loss": 10.977553367614746, "_runtime": 16995.491574048996, "_timestamp": 1585586911.3362074, "_step": 438}
{"Episode reward": -97.35736812268621, "Episode length": 999, "Policy Loss": -0.3196831941604614, "Value Loss": 0.006528276018798351, "_runtime": 16997.0836622715, "_timestamp": 1585586912.9282956, "_step": 439}
{"Episode reward": -97.16147984400773, "Episode length": 999, "Policy Loss": -0.3160763084888458, "Value Loss": 0.006315622944384813, "_runtime": 16998.645066022873, "_timestamp": 1585586914.4896994, "_step": 440}
{"Episode reward": -97.75574224973442, "Episode length": 999, "Policy Loss": -0.31155794858932495, "Value Loss": 0.006031262222677469, "_runtime": 16999.958834409714, "_timestamp": 1585586915.8034678, "_step": 441}
{"Episode reward": 18.332154058156988, "Episode length": 830, "Policy Loss": 0.12297920882701874, "Value Loss": 12.03555965423584, "_runtime": 17001.539613485336, "_timestamp": 1585586917.3842468, "_step": 442}
{"Episode reward": -97.56721353105931, "Episode length": 999, "Policy Loss": -0.2936345934867859, "Value Loss": 0.005459772422909737, "_runtime": 17002.450289011, "_timestamp": 1585586918.2949224, "_step": 443}
{"Episode reward": 44.66010466756031, "Episode length": 563, "Policy Loss": 0.41233518719673157, "Value Loss": 17.741308212280273, "_runtime": 17003.674544095993, "_timestamp": 1585586919.5191774, "_step": 444}
{"Episode reward": 24.588749345028333, "Episode length": 775, "Policy Loss": 0.17397508025169373, "Value Loss": 12.889659881591797, "_runtime": 17004.959634780884, "_timestamp": 1585586920.8042681, "_step": 445}
{"Episode reward": 21.394849122514486, "Episode length": 813, "Policy Loss": 0.16584844887256622, "Value Loss": 12.287467002868652, "_runtime": 17006.506409406662, "_timestamp": 1585586922.3510427, "_step": 446}
{"Episode reward": -98.82312229396707, "Episode length": 999, "Policy Loss": -0.28660207986831665, "Value Loss": 0.00505946995690465, "_runtime": 17008.073821544647, "_timestamp": 1585586923.918455, "_step": 447}
{"Episode reward": -97.21390853498994, "Episode length": 999, "Policy Loss": -0.27679386734962463, "Value Loss": 0.004929916001856327, "_runtime": 17009.641279459, "_timestamp": 1585586925.4859128, "_step": 448}
{"Episode reward": 3.18036489036605, "Episode length": 997, "Policy Loss": 0.07928349822759628, "Value Loss": 10.020795822143555, "_runtime": 17011.22891330719, "_timestamp": 1585586927.0735466, "_step": 449}
{"Episode reward": -97.28112441599535, "Episode length": 999, "Policy Loss": -0.2696337103843689, "Value Loss": 0.004694103728979826, "_runtime": 17012.809960126877, "_timestamp": 1585586928.6545935, "_step": 450}
{"Episode reward": -98.06421394414838, "Episode length": 999, "Policy Loss": -0.27114781737327576, "Value Loss": 0.0045734187588095665, "_runtime": 17013.931963443756, "_timestamp": 1585586929.7765968, "_step": 451}
{"Episode reward": 31.308871517588457, "Episode length": 708, "Policy Loss": 0.23631171882152557, "Value Loss": 14.109807968139648, "_runtime": 17014.92298436165, "_timestamp": 1585586930.7676177, "_step": 452}
{"Episode reward": 40.93871793820169, "Episode length": 617, "Policy Loss": 0.37250635027885437, "Value Loss": 16.190250396728516, "_runtime": 17016.51329112053, "_timestamp": 1585586932.3579245, "_step": 453}
{"Episode reward": -97.11280816041419, "Episode length": 999, "Policy Loss": -0.257811039686203, "Value Loss": 0.00427266163751483, "_runtime": 17018.12580895424, "_timestamp": 1585586933.9704423, "_step": 454}
{"Episode reward": -96.74900084817803, "Episode length": 999, "Policy Loss": -0.2534305155277252, "Value Loss": 0.0041868118569254875, "_runtime": 17019.034178733826, "_timestamp": 1585586934.878812, "_step": 455}
{"Episode reward": 44.013618839221266, "Episode length": 575, "Policy Loss": 0.6501557230949402, "Value Loss": 17.372819900512695, "_runtime": 17020.376116514206, "_timestamp": 1585586936.2207499, "_step": 456}
{"Episode reward": 16.95022633960957, "Episode length": 850, "Policy Loss": 0.16616636514663696, "Value Loss": 11.753538131713867, "_runtime": 17021.953949928284, "_timestamp": 1585586937.7985833, "_step": 457}
{"Episode reward": -97.21219241012992, "Episode length": 999, "Policy Loss": -0.25477972626686096, "Value Loss": 0.004211772233247757, "_runtime": 17023.21882724762, "_timestamp": 1585586939.0634606, "_step": 458}
{"Episode reward": 20.416143700367385, "Episode length": 816, "Policy Loss": 0.3348563313484192, "Value Loss": 12.243033409118652, "_runtime": 17024.78751349449, "_timestamp": 1585586940.6321468, "_step": 459}
{"Episode reward": -97.02075272728861, "Episode length": 999, "Policy Loss": -0.2571573555469513, "Value Loss": 0.004287267569452524, "_runtime": 17026.180894374847, "_timestamp": 1585586942.0255277, "_step": 460}
{"Episode reward": 13.612540582319397, "Episode length": 880, "Policy Loss": 0.136525958776474, "Value Loss": 11.352923393249512, "_runtime": 17027.743098258972, "_timestamp": 1585586943.5877316, "_step": 461}
{"Episode reward": -98.10058108338369, "Episode length": 999, "Policy Loss": -0.2606399953365326, "Value Loss": 0.004324186127632856, "_runtime": 17029.33634018898, "_timestamp": 1585586945.1809735, "_step": 462}
{"Episode reward": -98.27517099209749, "Episode length": 999, "Policy Loss": -0.2620876431465149, "Value Loss": 0.004313059616833925, "_runtime": 17030.913479328156, "_timestamp": 1585586946.7581127, "_step": 463}
{"Episode reward": -96.82902157184449, "Episode length": 999, "Policy Loss": -0.25253844261169434, "Value Loss": 0.00412537669762969, "_runtime": 17032.489673376083, "_timestamp": 1585586948.3343067, "_step": 464}
{"Episode reward": -97.38226113241917, "Episode length": 999, "Policy Loss": -0.2477714717388153, "Value Loss": 0.004011103417724371, "_runtime": 17033.436415433884, "_timestamp": 1585586949.2810488, "_step": 465}
{"Episode reward": 42.49619908566107, "Episode length": 587, "Policy Loss": 0.456915944814682, "Value Loss": 17.018314361572266, "_runtime": 17033.969408512115, "_timestamp": 1585586949.8140419, "_step": 466}
{"Episode reward": 69.75728744524284, "Episode length": 312, "Policy Loss": 0.9001091122627258, "Value Loss": 32.0152473449707, "_runtime": 17035.549372673035, "_timestamp": 1585586951.394006, "_step": 467}
{"Episode reward": -96.92782613808447, "Episode length": 999, "Policy Loss": -0.24874189496040344, "Value Loss": 0.003941395785659552, "_runtime": 17037.099321126938, "_timestamp": 1585586952.9439545, "_step": 468}
{"Episode reward": -97.89181166316735, "Episode length": 999, "Policy Loss": -0.2532564401626587, "Value Loss": 0.004149186424911022, "_runtime": 17038.62065768242, "_timestamp": 1585586954.465291, "_step": 469}
{"Episode reward": -97.38803216544845, "Episode length": 999, "Policy Loss": -0.25295311212539673, "Value Loss": 0.004156551323831081, "_runtime": 17040.21838450432, "_timestamp": 1585586956.0630178, "_step": 470}
{"Episode reward": -97.34488970264569, "Episode length": 999, "Policy Loss": -0.2521510720252991, "Value Loss": 0.004149929154664278, "_runtime": 17041.104958295822, "_timestamp": 1585586956.9495916, "_step": 471}
{"Episode reward": 47.284175107821156, "Episode length": 547, "Policy Loss": 0.4039626121520996, "Value Loss": 18.262012481689453, "_runtime": 17041.612424850464, "_timestamp": 1585586957.4570582, "_step": 472}
{"Episode reward": 70.48086309497991, "Episode length": 302, "Policy Loss": 0.9091293811798096, "Value Loss": 33.07372283935547, "_runtime": 17043.18775320053, "_timestamp": 1585586959.0323865, "_step": 473}
{"Episode reward": -97.55275878940297, "Episode length": 999, "Policy Loss": -0.26517167687416077, "Value Loss": 0.004479302559047937, "_runtime": 17044.774083852768, "_timestamp": 1585586960.6187172, "_step": 474}
{"Episode reward": -97.40447700836297, "Episode length": 999, "Policy Loss": -0.27012327313423157, "Value Loss": 0.004712662193924189, "_runtime": 17046.281156539917, "_timestamp": 1585586962.1257899, "_step": 475}
{"Episode reward": -97.17151253813213, "Episode length": 999, "Policy Loss": -0.2764979302883148, "Value Loss": 0.004911114927381277, "_runtime": 17047.308313846588, "_timestamp": 1585586963.1529472, "_step": 476}
{"Episode reward": 37.50305479314294, "Episode length": 638, "Policy Loss": 0.3756311237812042, "Value Loss": 15.656637191772461, "_runtime": 17048.88448023796, "_timestamp": 1585586964.7291136, "_step": 477}
{"Episode reward": -98.59148922026904, "Episode length": 999, "Policy Loss": -0.28778234124183655, "Value Loss": 0.005149617325514555, "_runtime": 17049.984258651733, "_timestamp": 1585586965.828892, "_step": 478}
{"Episode reward": 31.881696038316107, "Episode length": 697, "Policy Loss": 0.23187321424484253, "Value Loss": 14.331533432006836, "_runtime": 17051.539848566055, "_timestamp": 1585586967.384482, "_step": 479}
{"Episode reward": -96.51575062480855, "Episode length": 999, "Policy Loss": -0.28374770283699036, "Value Loss": 0.005272896494716406, "_runtime": 17053.12055873871, "_timestamp": 1585586968.965192, "_step": 480}
{"Episode reward": 3.7451057130795817, "Episode length": 988, "Policy Loss": 0.17671824991703033, "Value Loss": 10.111818313598633, "_runtime": 17054.21870779991, "_timestamp": 1585586970.0633411, "_step": 481}
{"Episode reward": 31.980943220500592, "Episode length": 701, "Policy Loss": 0.3023838698863983, "Value Loss": 14.249462127685547, "_runtime": 17055.79141831398, "_timestamp": 1585586971.6360517, "_step": 482}
{"Episode reward": -97.51405655594128, "Episode length": 999, "Policy Loss": -0.29954105615615845, "Value Loss": 0.0055564832873642445, "_runtime": 17057.37703347206, "_timestamp": 1585586973.2216668, "_step": 483}
{"Episode reward": -97.89165792844756, "Episode length": 999, "Policy Loss": -0.3000287711620331, "Value Loss": 0.005643042735755444, "_runtime": 17058.863775491714, "_timestamp": 1585586974.7084088, "_step": 484}
{"Episode reward": 6.479645220640009, "Episode length": 964, "Policy Loss": 0.17568352818489075, "Value Loss": 10.363279342651367, "_runtime": 17060.43395423889, "_timestamp": 1585586976.2785876, "_step": 485}
{"Episode reward": -96.95128062578355, "Episode length": 999, "Policy Loss": -0.2889607548713684, "Value Loss": 0.005512884818017483, "_runtime": 17061.30731368065, "_timestamp": 1585586977.151947, "_step": 486}
{"Episode reward": 47.34319136569338, "Episode length": 543, "Policy Loss": 0.7862116694450378, "Value Loss": 18.394020080566406, "_runtime": 17062.131242275238, "_timestamp": 1585586977.9758756, "_step": 487}
{"Episode reward": 49.38200608340542, "Episode length": 523, "Policy Loss": 0.4264622628688812, "Value Loss": 19.09712791442871, "_runtime": 17063.399735450745, "_timestamp": 1585586979.2443688, "_step": 488}
{"Episode reward": 21.83161769385427, "Episode length": 805, "Policy Loss": 0.1455349624156952, "Value Loss": 12.409013748168945, "_runtime": 17064.934269189835, "_timestamp": 1585586980.7789025, "_step": 489}
{"Episode reward": -97.40149645637754, "Episode length": 999, "Policy Loss": -0.3064824342727661, "Value Loss": 0.005976748187094927, "_runtime": 17066.364133119583, "_timestamp": 1585586982.2087665, "_step": 490}
{"Episode reward": 8.80741052118556, "Episode length": 936, "Policy Loss": 0.15859940648078918, "Value Loss": 10.672918319702148, "_runtime": 17067.96033024788, "_timestamp": 1585586983.8049636, "_step": 491}
{"Episode reward": -97.75919163081912, "Episode length": 999, "Policy Loss": -0.3170833885669708, "Value Loss": 0.006312678102403879, "_runtime": 17069.01441001892, "_timestamp": 1585586984.8590434, "_step": 492}
{"Episode reward": 34.51013791398809, "Episode length": 672, "Policy Loss": 0.21566832065582275, "Value Loss": 14.863300323486328, "_runtime": 17070.573845148087, "_timestamp": 1585586986.4184785, "_step": 493}
{"Episode reward": -97.27687486013431, "Episode length": 999, "Policy Loss": -0.31519559025764465, "Value Loss": 0.00645273644477129, "_runtime": 17071.381728172302, "_timestamp": 1585586987.2263615, "_step": 494}
{"Episode reward": 50.73717461959494, "Episode length": 504, "Policy Loss": 0.473377525806427, "Value Loss": 19.815380096435547, "_runtime": 17072.826280593872, "_timestamp": 1585586988.670914, "_step": 495}
{"Episode reward": 9.003793373922036, "Episode length": 929, "Policy Loss": 0.1693306863307953, "Value Loss": 10.7531156539917, "_runtime": 17074.395768642426, "_timestamp": 1585586990.240402, "_step": 496}
{"Episode reward": -97.85547353347876, "Episode length": 999, "Policy Loss": -0.3340827226638794, "Value Loss": 0.006881130393594503, "_runtime": 17075.52200627327, "_timestamp": 1585586991.3666396, "_step": 497}
{"Episode reward": 27.817438729141543, "Episode length": 738, "Policy Loss": 0.15367239713668823, "Value Loss": 13.534214973449707, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445, 8.949419021606445]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-8.945880889892578, -6.97552490234375, -5.00516939163208, -3.03481388092041, -1.064457893371582, 0.9058980941772461, 2.876253128051758, 4.846609115600586, 6.816965103149414, 8.787321090698242, 10.75767707824707, 12.728033065795898, 14.698387145996094, 16.668743133544922, 18.63909912109375, 20.609455108642578, 22.579811096191406, 24.550167083740234, 26.520523071289062, 28.49087905883789, 30.46123504638672, 32.43159103393555, 34.401947021484375, 36.3723030090332, 38.342655181884766, 40.313011169433594, 42.28336715698242, 44.25372314453125, 46.22407913208008, 48.194435119628906, 50.164791107177734, 52.13514709472656, 54.10550308227539, 56.07585525512695, 58.04621505737305, 60.01656723022461, 61.9869270324707, 63.957279205322266, 65.92764282226562, 67.89799499511719, 69.86834716796875, 71.83869934082031, 73.80906677246094, 75.7794189453125, 77.74977111816406, 79.72012329101562, 81.69049072265625, 83.66084289550781, 85.63119506835938, 87.60154724121094, 89.5718994140625, 91.54226684570312, 93.51261901855469, 95.48297119140625, 97.45332336425781, 99.42369079589844, 101.39404296875, 103.36439514160156, 105.33474731445312, 107.30511474609375, 109.27546691894531, 111.24581909179688, 113.21617126464844, 115.18653869628906, 117.15689086914062]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.005401134490967, -1.8721721172332764, -1.738943099975586, -1.605713963508606, -1.4724849462509155, -1.339255928993225, -1.2060267925262451, -1.0727977752685547, -0.9395687580108643, -0.8063397407531738, -0.6731107234954834, -0.5398815870285034, -0.406652569770813, -0.27342355251312256, -0.14019441604614258, -0.0069653987884521484, 0.12626361846923828, 0.2594926357269287, 0.39272165298461914, 0.5259506702423096, 0.6591796875, 0.7924089431762695, 0.92563796043396, 1.0588669776916504, 1.1920959949493408, 1.3253250122070312, 1.4585540294647217, 1.591783046722412, 1.7250123023986816, 1.858241319656372, 1.9914703369140625, 2.124699115753174, 2.2579283714294434, 2.391157627105713, 2.524386405944824, 2.6576156616210938, 2.790844440460205, 2.9240736961364746, 3.057302474975586, 3.1905317306518555, 3.323760509490967, 3.4569897651672363, 3.590219020843506, 3.723447799682617, 3.8566770553588867, 3.989905834197998, 4.123135089874268, 4.256363868713379, 4.389593124389648, 4.522822380065918, 4.656051158905029, 4.789280414581299, 4.92250919342041, 5.05573844909668, 5.188967227935791, 5.3221964836120605, 5.45542573928833, 5.588654518127441, 5.721883773803711, 5.855112552642822, 5.988341808319092, 6.121571063995361, 6.2547993659973145, 6.388028621673584, 6.5212578773498535]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 4.0, 6.0, 5.0, 5.0, 8.0, 7.0, 7.0, 4.0, 7.0, 12.0, 18.0, 11.0, 16.0, 11.0, 12.0, 10.0, 12.0, 192.0, 16.0, 6.0, 13.0, 20.0, 13.0, 12.0, 6.0, 4.0, 3.0, 5.0, 5.0, 6.0, 1.0, 6.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.290658473968506, -5.0331621170043945, -4.775665760040283, -4.518169403076172, -4.2606730461120605, -4.003176689147949, -3.745680570602417, -3.4881842136383057, -3.2306878566741943, -2.973191499710083, -2.7156951427459717, -2.4581987857818604, -2.200702667236328, -1.9432063102722168, -1.6857099533081055, -1.4282135963439941, -1.1707172393798828, -0.9132208824157715, -0.6557245254516602, -0.39822816848754883, -0.1407318115234375, 0.11676454544067383, 0.37426090240478516, 0.6317572593688965, 0.8892531394958496, 1.146749496459961, 1.4042458534240723, 1.6617422103881836, 1.919238567352295, 2.1767349243164062, 2.4342312812805176, 2.691727638244629, 2.9492239952087402, 3.2067198753356934, 3.464216709136963, 3.721712589263916, 3.9792094230651855, 4.236705303192139, 4.494202136993408, 4.751698017120361, 5.009194850921631, 5.266690731048584, 5.5241875648498535, 5.781683444976807, 6.039180278778076, 6.296676158905029, 6.554172992706299, 6.811668872833252, 7.069164752960205, 7.326661586761475, 7.584157466888428, 7.841654300689697, 8.099149703979492, 8.356647491455078, 8.614143371582031, 8.871639251708984, 9.129135131835938, 9.386632919311523, 9.644128799438477, 9.90162467956543, 10.159120559692383, 10.416618347167969, 10.674114227294922, 10.931610107421875, 11.189105987548828]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0], "bins": [-26.240169525146484, -25.483814239501953, -24.727458953857422, -23.97110366821289, -23.21474838256836, -22.458393096923828, -21.702037811279297, -20.945682525634766, -20.189327239990234, -19.432971954345703, -18.676616668701172, -17.92026138305664, -17.16390609741211, -16.407550811767578, -15.65119457244873, -14.8948392868042, -14.138484001159668, -13.382128715515137, -12.625773429870605, -11.869418144226074, -11.113062858581543, -10.356707572937012, -9.600351333618164, -8.843996047973633, -8.087640762329102, -7.33128547668457, -6.574930191040039, -5.818574905395508, -5.062219619750977, -4.305864334106445, -3.549509048461914, -2.793153762817383, -2.0367984771728516, -1.2804431915283203, -0.5240879058837891, 0.2322673797607422, 0.9886226654052734, 1.7449779510498047, 2.501333236694336, 3.257688522338867, 4.014043807983398, 4.77039909362793, 5.526754379272461, 6.283111572265625, 7.039466857910156, 7.7958221435546875, 8.552177429199219, 9.30853271484375, 10.064888000488281, 10.821243286132812, 11.577598571777344, 12.333953857421875, 13.090309143066406, 13.846664428710938, 14.603019714355469, 15.359375, 16.11573028564453, 16.872085571289062, 17.628440856933594, 18.384796142578125, 19.141151428222656, 19.897506713867188, 20.65386199951172, 21.41021728515625, 22.16657257080078]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 7.0, 5.0, 9.0, 6.0, 0.0, 3.0, 0.0, 1.0, 1.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-6.157309055328369, -5.946826934814453, -5.736344814300537, -5.525862693786621, -5.315380096435547, -5.104897975921631, -4.894415855407715, -4.683933734893799, -4.473451614379883, -4.262969017028809, -4.052487373352051, -3.8420050144195557, -3.6315226554870605, -3.4210405349731445, -3.2105584144592285, -3.0000760555267334, -2.7895939350128174, -2.5791118144989014, -2.3686294555664062, -2.1581473350524902, -1.9476652145385742, -1.7371830940246582, -1.5267009735107422, -1.316218376159668, -1.105736255645752, -0.8952541351318359, -0.6847720146179199, -0.4742898941040039, -0.2638077735900879, -0.05332517623901367, 0.15715694427490234, 0.36763906478881836, 0.5781211853027344, 0.7886033058166504, 0.9990854263305664, 1.2095675468444824, 1.4200501441955566, 1.6305322647094727, 1.8410143852233887, 2.051496982574463, 2.2619786262512207, 2.472461223602295, 2.6829428672790527, 2.893425464630127, 3.1039071083068848, 3.314389705657959, 3.524872303009033, 3.735353946685791, 3.9458365440368652, 4.156318187713623, 4.366800785064697, 4.577282428741455, 4.787765026092529, 4.9982476234436035, 5.208729267120361, 5.4192118644714355, 5.629693508148193, 5.840176105499268, 6.050658702850342, 6.2611403465271, 6.471622943878174, 6.682104587554932, 6.892587184906006, 7.103068828582764, 7.313551425933838]}, "_runtime": 17076.397328853607, "_timestamp": 1585586992.2419622, "_step": 498}
{"Episode reward": 47.17210292743521, "Episode length": 543, "Policy Loss": 0.343974769115448, "Value Loss": 18.39182472229004, "_runtime": 17076.397328853607, "_timestamp": 1585586992.2419622, "_step": 499}
