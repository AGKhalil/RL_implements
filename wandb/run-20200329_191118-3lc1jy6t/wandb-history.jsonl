{"Episode reward": -37.865742582910926, "Episode length": 999, "Policy Loss": -0.03473100811243057, "Value Loss": 0.005120111163705587, "_runtime": 19.067237377166748, "_timestamp": 1585509097.487967, "_step": 0}
{"Episode reward": 38.54948644654482, "Episode length": 631, "Policy Loss": -0.4230073392391205, "Value Loss": 875.1356811523438, "_runtime": 20.51035976409912, "_timestamp": 1585509098.9310894, "_step": 1}
{"Episode reward": -98.90123520732789, "Episode length": 999, "Policy Loss": -7.576755523681641, "Value Loss": 4922.07666015625, "_runtime": 21.99182391166687, "_timestamp": 1585509100.4125535, "_step": 2}
{"Episode reward": -99.61779172887772, "Episode length": 999, "Policy Loss": 7.869823932647705, "Value Loss": 7518.0068359375, "_runtime": 23.47437334060669, "_timestamp": 1585509101.895103, "_step": 3}
{"Episode reward": -99.70502667669068, "Episode length": 999, "Policy Loss": -2.5640711784362793, "Value Loss": 487.34521484375, "_runtime": 24.966195821762085, "_timestamp": 1585509103.3869255, "_step": 4}
{"Episode reward": -99.39859668295692, "Episode length": 999, "Policy Loss": 5.642764091491699, "Value Loss": 1672.8182373046875, "_runtime": 26.482994318008423, "_timestamp": 1585509104.903724, "_step": 5}
{"Episode reward": -99.74579124870222, "Episode length": 999, "Policy Loss": 41.51640701293945, "Value Loss": 17257.259765625, "_runtime": 27.489721298217773, "_timestamp": 1585509105.910451, "_step": 6}
{"Episode reward": 34.38052952056697, "Episode length": 657, "Policy Loss": 11.7317533493042, "Value Loss": 1474.68896484375, "_runtime": 28.991761207580566, "_timestamp": 1585509107.4124908, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.882449746131897, "Value Loss": 57.5913200378418, "_runtime": 30.517314434051514, "_timestamp": 1585509108.938044, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6790289878845215, "Value Loss": 212.37783813476562, "_runtime": 32.011327028274536, "_timestamp": 1585509110.4320567, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6500098705291748, "Value Loss": 90.89334869384766, "_runtime": 33.53598666191101, "_timestamp": 1585509111.9567163, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7732289433479309, "Value Loss": 65.753173828125, "_runtime": 34.57521653175354, "_timestamp": 1585509112.9959462, "_step": 11}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.44258278608322144, "Value Loss": 33.25579071044922, "_runtime": 36.101012229919434, "_timestamp": 1585509114.5217419, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7739885449409485, "Value Loss": 0.009471445344388485, "_runtime": 36.889403343200684, "_timestamp": 1585509115.310133, "_step": 13}
{"Episode reward": 49.69999999999956, "Episode length": 503, "Policy Loss": 0.8932163119316101, "Value Loss": 19.96300506591797, "_runtime": 38.37940239906311, "_timestamp": 1585509116.800132, "_step": 14}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.3815774619579315, "Value Loss": 10.288420677185059, "_runtime": 39.42094445228577, "_timestamp": 1585509117.841674, "_step": 15}
{"Episode reward": 31.09999999999964, "Episode length": 689, "Policy Loss": 0.6584882140159607, "Value Loss": 14.52885913848877, "_runtime": 40.90452551841736, "_timestamp": 1585509119.3252552, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7685816884040833, "Value Loss": 0.007012833375483751, "_runtime": 42.43340349197388, "_timestamp": 1585509120.8541331, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.766015887260437, "Value Loss": 0.013962558470666409, "_runtime": 43.09440612792969, "_timestamp": 1585509121.5151358, "_step": 18}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.3823177814483643, "Value Loss": 23.22774887084961, "_runtime": 44.61554408073425, "_timestamp": 1585509123.0362737, "_step": 19}
{"Episode reward": -99.83258135318617, "Episode length": 999, "Policy Loss": -0.7561936974525452, "Value Loss": 0.0065396311692893505, "_runtime": 46.14919090270996, "_timestamp": 1585509124.5699205, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7536118626594543, "Value Loss": 0.006414269562810659, "_runtime": 47.639973878860474, "_timestamp": 1585509126.0607035, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7421269416809082, "Value Loss": 0.028481457382440567, "_runtime": 49.177964210510254, "_timestamp": 1585509127.5986938, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7371416687965393, "Value Loss": 0.006449928041547537, "_runtime": 50.70358490943909, "_timestamp": 1585509129.1243145, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7288824915885925, "Value Loss": 0.011784911155700684, "_runtime": 51.38881182670593, "_timestamp": 1585509129.8095415, "_step": 24}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 1.8731049299240112, "Value Loss": 23.233932495117188, "_runtime": 52.91876578330994, "_timestamp": 1585509131.3394954, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7124317288398743, "Value Loss": 0.005495299119502306, "_runtime": 53.89836835861206, "_timestamp": 1585509132.319098, "_step": 26}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": 0.7683776021003723, "Value Loss": 15.835500717163086, "_runtime": 55.37786054611206, "_timestamp": 1585509133.7985902, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7040513753890991, "Value Loss": 0.009945097379386425, "_runtime": 56.90843415260315, "_timestamp": 1585509135.3291638, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6978097558021545, "Value Loss": 0.00556521350517869, "_runtime": 58.000999450683594, "_timestamp": 1585509136.421729, "_step": 29}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.6747197508811951, "Value Loss": 13.899468421936035, "_runtime": 59.30062460899353, "_timestamp": 1585509137.7213542, "_step": 30}
{"Episode reward": 14.2000000000006, "Episode length": 858, "Policy Loss": 0.4325038194656372, "Value Loss": 11.945685386657715, "_runtime": 60.867555141448975, "_timestamp": 1585509139.2882848, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.674052894115448, "Value Loss": 0.006033462937921286, "_runtime": 62.36861824989319, "_timestamp": 1585509140.789348, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6723716855049133, "Value Loss": 0.004737485200166702, "_runtime": 63.87719392776489, "_timestamp": 1585509142.2979236, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6561626195907593, "Value Loss": 0.1508108675479889, "_runtime": 65.31614112854004, "_timestamp": 1585509143.7368708, "_step": 34}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": 0.3092489540576935, "Value Loss": 10.934297561645508, "_runtime": 65.86246752738953, "_timestamp": 1585509144.2831972, "_step": 35}
{"Episode reward": 65.5999999999998, "Episode length": 344, "Policy Loss": 2.320127487182617, "Value Loss": 29.10079574584961, "_runtime": 67.37739133834839, "_timestamp": 1585509145.798121, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6500073671340942, "Value Loss": 0.8000895977020264, "_runtime": 68.90568447113037, "_timestamp": 1585509147.326414, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.650018572807312, "Value Loss": 0.004361285362392664, "_runtime": 70.37548613548279, "_timestamp": 1585509148.7962158, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6477800011634827, "Value Loss": 0.004307820927351713, "_runtime": 71.90506792068481, "_timestamp": 1585509150.3257976, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.641401469707489, "Value Loss": 0.0042255031876266, "_runtime": 73.43901944160461, "_timestamp": 1585509151.859749, "_step": 40}
{"Episode reward": -99.8026437997804, "Episode length": 999, "Policy Loss": -0.6406497955322266, "Value Loss": 0.21155305206775665, "_runtime": 74.96084761619568, "_timestamp": 1585509153.3815773, "_step": 41}
{"Episode reward": -99.84351618289809, "Episode length": 999, "Policy Loss": -0.6195122003555298, "Value Loss": 0.10352777689695358, "_runtime": 76.49010992050171, "_timestamp": 1585509154.9108396, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6156649589538574, "Value Loss": 0.028498783707618713, "_runtime": 76.87369728088379, "_timestamp": 1585509155.294427, "_step": 43}
{"Episode reward": 78.19999999999996, "Episode length": 218, "Policy Loss": 3.710678815841675, "Value Loss": 47.08617401123047, "_runtime": 78.1688323020935, "_timestamp": 1585509156.589562, "_step": 44}
{"Episode reward": 14.400000000000588, "Episode length": 856, "Policy Loss": 0.8803777694702148, "Value Loss": 12.039395332336426, "_runtime": 79.69265270233154, "_timestamp": 1585509158.1133823, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6096566319465637, "Value Loss": 0.0037842534948140383, "_runtime": 81.15482831001282, "_timestamp": 1585509159.575558, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6056448221206665, "Value Loss": 0.014016978442668915, "_runtime": 82.65384197235107, "_timestamp": 1585509161.0745716, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6079052686691284, "Value Loss": 0.006798087153583765, "_runtime": 83.64167618751526, "_timestamp": 1585509162.0624058, "_step": 48}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": 1.2100800275802612, "Value Loss": 16.165122985839844, "_runtime": 84.46642470359802, "_timestamp": 1585509162.8871543, "_step": 49}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 1.355317234992981, "Value Loss": 18.603939056396484, "_runtime": 85.97762989997864, "_timestamp": 1585509164.3983595, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6173530220985413, "Value Loss": 0.004361180122941732, "_runtime": 87.46997547149658, "_timestamp": 1585509165.890705, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6207029819488525, "Value Loss": 0.003915047738701105, "_runtime": 88.47978472709656, "_timestamp": 1585509166.9005144, "_step": 52}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.7765759229660034, "Value Loss": 14.751190185546875, "_runtime": 89.99043679237366, "_timestamp": 1585509168.4111664, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6261471509933472, "Value Loss": 0.004013316240161657, "_runtime": 91.50691390037537, "_timestamp": 1585509169.9276435, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6279601454734802, "Value Loss": 0.003978675696998835, "_runtime": 92.96973729133606, "_timestamp": 1585509171.390467, "_step": 55}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.341959148645401, "Value Loss": 10.226572036743164, "_runtime": 93.9524884223938, "_timestamp": 1585509172.373218, "_step": 56}
{"Episode reward": 36.499999999999375, "Episode length": 635, "Policy Loss": 0.9006366729736328, "Value Loss": 15.732766151428223, "_runtime": 95.47957158088684, "_timestamp": 1585509173.9003012, "_step": 57}
{"Episode reward": -99.89824991226057, "Episode length": 999, "Policy Loss": -0.631022036075592, "Value Loss": 0.004004513844847679, "_runtime": 96.07631063461304, "_timestamp": 1585509174.4970403, "_step": 58}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 2.288037061691284, "Value Loss": 26.779682159423828, "_runtime": 96.58758521080017, "_timestamp": 1585509175.0083148, "_step": 59}
{"Episode reward": 66.19999999999979, "Episode length": 338, "Policy Loss": 2.170802593231201, "Value Loss": 29.552867889404297, "_runtime": 98.08677744865417, "_timestamp": 1585509176.507507, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6616630554199219, "Value Loss": 0.004375972785055637, "_runtime": 99.52461314201355, "_timestamp": 1585509177.9453428, "_step": 61}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.29818296432495117, "Value Loss": 10.229461669921875, "_runtime": 100.87939167022705, "_timestamp": 1585509179.3001213, "_step": 62}
{"Episode reward": 7.593919730187437, "Episode length": 925, "Policy Loss": 0.4447859525680542, "Value Loss": 10.80160140991211, "_runtime": 101.96603107452393, "_timestamp": 1585509180.3867607, "_step": 63}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": 0.6246536374092102, "Value Loss": 13.952284812927246, "_runtime": 103.48562240600586, "_timestamp": 1585509181.906352, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7178101539611816, "Value Loss": 0.0051784091629087925, "_runtime": 105.00467658042908, "_timestamp": 1585509183.4254062, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.731660008430481, "Value Loss": 0.005343205761164427, "_runtime": 106.54472279548645, "_timestamp": 1585509184.9654524, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.734734058380127, "Value Loss": 0.005596369970589876, "_runtime": 107.7836012840271, "_timestamp": 1585509186.204331, "_step": 67}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 0.42611411213874817, "Value Loss": 12.318146705627441, "_runtime": 109.31583976745605, "_timestamp": 1585509187.7365694, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7440628409385681, "Value Loss": 0.005568465683609247, "_runtime": 109.92032670974731, "_timestamp": 1585509188.3410563, "_step": 69}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 2.551403045654297, "Value Loss": 49.285545349121094, "_runtime": 110.89056491851807, "_timestamp": 1585509189.3112946, "_step": 70}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.7171575427055359, "Value Loss": 15.449037551879883, "_runtime": 112.41203236579895, "_timestamp": 1585509190.832762, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7603198885917664, "Value Loss": 0.005795543547719717, "_runtime": 113.44738245010376, "_timestamp": 1585509191.868112, "_step": 72}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.6413442492485046, "Value Loss": 14.19702434539795, "_runtime": 114.93340849876404, "_timestamp": 1585509193.3541381, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7739806771278381, "Value Loss": 0.005963585339486599, "_runtime": 116.12905406951904, "_timestamp": 1585509194.5497837, "_step": 74}
{"Episode reward": 22.000000000000156, "Episode length": 780, "Policy Loss": 0.5425477027893066, "Value Loss": 13.035123825073242, "_runtime": 117.62292909622192, "_timestamp": 1585509196.0436587, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7781751751899719, "Value Loss": 0.006076986901462078, "_runtime": 118.02057337760925, "_timestamp": 1585509196.441303, "_step": 76}
{"Episode reward": 76.09999999999994, "Episode length": 239, "Policy Loss": 3.472324848175049, "Value Loss": 41.78179168701172, "_runtime": 119.508868932724, "_timestamp": 1585509197.9295986, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7982938885688782, "Value Loss": 0.00633408734574914, "_runtime": 121.03043341636658, "_timestamp": 1585509199.451163, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8098893761634827, "Value Loss": 0.006503627169877291, "_runtime": 122.48919200897217, "_timestamp": 1585509200.9099216, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.811923623085022, "Value Loss": 0.006599812302738428, "_runtime": 123.55749654769897, "_timestamp": 1585509201.9782262, "_step": 80}
{"Episode reward": 30.19999999999969, "Episode length": 698, "Policy Loss": 0.5484604835510254, "Value Loss": 14.30996322631836, "_runtime": 125.06921815872192, "_timestamp": 1585509203.4899478, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.82071852684021, "Value Loss": 0.006698593031615019, "_runtime": 125.92747092247009, "_timestamp": 1585509204.3482006, "_step": 82}
{"Episode reward": 44.381410765647374, "Episode length": 557, "Policy Loss": 1.0409541130065918, "Value Loss": 17.930627822875977, "_runtime": 126.62395453453064, "_timestamp": 1585509205.0446842, "_step": 83}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 1.298627257347107, "Value Loss": 22.192411422729492, "_runtime": 127.09252452850342, "_timestamp": 1585509205.5132542, "_step": 84}
{"Episode reward": 71.59999999999988, "Episode length": 284, "Policy Loss": 2.5120596885681152, "Value Loss": 35.15948486328125, "_runtime": 128.56372022628784, "_timestamp": 1585509206.9844499, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8556408286094666, "Value Loss": 0.007317225448787212, "_runtime": 130.07262682914734, "_timestamp": 1585509208.4933565, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8695327043533325, "Value Loss": 0.0075852274894714355, "_runtime": 130.79404211044312, "_timestamp": 1585509209.2147717, "_step": 87}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 1.0605427026748657, "Value Loss": 20.463462829589844, "_runtime": 132.30271768569946, "_timestamp": 1585509210.7234473, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8957277536392212, "Value Loss": 0.008017390966415405, "_runtime": 133.44374012947083, "_timestamp": 1585509211.8644698, "_step": 89}
{"Episode reward": 25.29999999999997, "Episode length": 747, "Policy Loss": 0.3634319305419922, "Value Loss": 13.370826721191406, "_runtime": 134.7554726600647, "_timestamp": 1585509213.1762023, "_step": 90}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 0.17272739112377167, "Value Loss": 11.312702178955078, "_runtime": 135.85746383666992, "_timestamp": 1585509214.2781935, "_step": 91}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": 0.4228822886943817, "Value Loss": 13.949212074279785, "_runtime": 136.45123386383057, "_timestamp": 1585509214.8719635, "_step": 92}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 1.582995891571045, "Value Loss": 26.48431968688965, "_runtime": 137.95645689964294, "_timestamp": 1585509216.3771865, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9533039927482605, "Value Loss": 0.00909972470253706, "_runtime": 139.46559739112854, "_timestamp": 1585509217.886327, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9605251550674438, "Value Loss": 0.009328543208539486, "_runtime": 140.93608045578003, "_timestamp": 1585509219.35681, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9674375653266907, "Value Loss": 0.009450049139559269, "_runtime": 141.70856094360352, "_timestamp": 1585509220.1292906, "_step": 96}
{"Episode reward": 51.09999999999958, "Episode length": 489, "Policy Loss": 0.9713224172592163, "Value Loss": 20.419578552246094, "_runtime": 143.24100494384766, "_timestamp": 1585509221.6617346, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9730954766273499, "Value Loss": 0.009589958004653454, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408, 0.0018090592930093408]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0018090734956786036, 0.004095572978258133, 0.010000219568610191, 0.01590486615896225, 0.021809512749314308, 0.027714159339666367, 0.033618807792663574, 0.03952345624566078, 0.04542810097336769, 0.0513327457010746, 0.05723739415407181, 0.06314203888177872, 0.06904668360948563, 0.07495132833719254, 0.08085598051548004, 0.08676062524318695, 0.09266526997089386, 0.09856991469860077, 0.10447455942630768, 0.11037921160459518, 0.1162838563323021, 0.122188501060009, 0.1280931532382965, 0.13399779796600342, 0.13990244269371033, 0.14580708742141724, 0.15171173214912415, 0.15761637687683105, 0.16352103650569916, 0.16942568123340607, 0.17533032596111298, 0.18123497068881989, 0.1871396154165268, 0.1930442601442337, 0.1989489048719406, 0.20485354959964752, 0.21075819432735443, 0.21666285395622253, 0.22256749868392944, 0.22847214341163635, 0.23437678813934326, 0.24028143286705017, 0.24618607759475708, 0.2520907521247864, 0.2579953968524933, 0.2639000415802002, 0.2698046863079071, 0.275709331035614, 0.2816139757633209, 0.28751862049102783, 0.29342326521873474, 0.29932790994644165, 0.30523255467414856, 0.31113719940185547, 0.3170418441295624, 0.3229464888572693, 0.3288511633872986, 0.3347558081150055, 0.3406604528427124, 0.3465650975704193, 0.3524697422981262, 0.35837438702583313, 0.36427903175354004, 0.37018367648124695, 0.37608832120895386]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-1.844272823348092e-08, 0.00011011469905497506, 0.0002202478499384597, 0.0003303809789940715, 0.0004405141226015985, 0.0005506472662091255, 0.0006607804098166525, 0.0007709135534241796, 0.0008810466970317066, 0.0009911798406392336, 0.0011013130424544215, 0.0012114462442696095, 0.0013215793296694756, 0.0014317124150693417, 0.0015418456168845296, 0.0016519788186997175, 0.0017621119040995836, 0.0018722449894994497, 0.001982378074899316, 0.0020925113931298256, 0.0022026444785296917, 0.002312777563929558, 0.0024229108821600676, 0.0025330439675599337, 0.0026431770529597998, 0.002753310138359666, 0.002863443223759532, 0.0029735765419900417, 0.003083709627389908, 0.003193842712789774, 0.0033039760310202837, 0.00341410911642015, 0.003524242201820016, 0.003634375287219882, 0.003744508372619748, 0.003854641690850258, 0.003964774310588837, 0.00407490786164999, 0.004185040947049856, 0.004295174032449722, 0.004405307117849588, 0.0045154402032494545, 0.004625573288649321, 0.004735706374049187, 0.00484583992511034, 0.004955973010510206, 0.005066106095910072, 0.005176239181309938, 0.0052863722667098045, 0.005396505352109671, 0.005506638437509537, 0.005616771522909403, 0.005726904608309269, 0.005837038159370422, 0.0059471712447702885, 0.006057304330170155, 0.006167437415570021, 0.006277570500969887, 0.006387703586369753, 0.006497836671769619, 0.006607970222830772, 0.0067181033082306385, 0.006828236393630505, 0.006938369479030371, 0.007048502564430237]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [35.0, 6.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 224.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 7.0, 9.0, 12.0, 10.0, 14.0, 7.0, 6.0, 7.0, 3.0, 9.0, 5.0, 11.0, 9.0, 8.0, 9.0, 2.0, 5.0, 5.0, 1.0, 4.0, 6.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 0.0, 2.0, 4.0], "bins": [-0.006999347358942032, -0.006342258304357529, -0.0056851692497730255, -0.005028080195188522, -0.004370991140604019, -0.0037139023188501596, -0.0030568134970963, -0.002399724442511797, -0.0017426353879272938, -0.0010855463333427906, -0.00042845727875828743, 0.00022863177582621574, 0.0008857203647494316, 0.0015428094193339348, 0.002199898473918438, 0.002856987528502941, 0.0035140765830874443, 0.0041711656376719475, 0.004828254692256451, 0.005485343746840954, 0.006142432801425457, 0.00679952185600996, 0.007456610910594463, 0.008113699965178967, 0.008770788088440895, 0.009427877143025398, 0.010084966197609901, 0.010742055252194405, 0.011399144306778908, 0.012056233361363411, 0.012713322415947914, 0.013370411470532417, 0.01402750052511692, 0.014684589579701424, 0.015341678634285927, 0.01599876768887043, 0.016655856743454933, 0.017312945798039436, 0.01797003485262394, 0.018627123907208443, 0.019284212961792946, 0.01994130201637745, 0.020598391070961952, 0.021255480125546455, 0.02191256918013096, 0.02256965823471546, 0.023226747289299965, 0.023883836343884468, 0.024540923535823822, 0.025198012590408325, 0.02585510164499283, 0.02651219069957733, 0.027169279754161835, 0.027826368808746338, 0.02848345786333084, 0.029140546917915344, 0.029797635972499847, 0.03045472502708435, 0.031111814081668854, 0.03176890313625336, 0.03242599219083786, 0.03308308124542236, 0.033740170300006866, 0.03439725935459137, 0.03505434840917587]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.029916126281023026, -0.02673538774251938, -0.02355465106666088, -0.020373912528157234, -0.017193175852298737, -0.01401243731379509, -0.010831698775291443, -0.007650962099432945, -0.004470223560929298, -0.0012894850224256516, 0.001891251653432846, 0.005071990191936493, 0.00825272873044014, 0.011433467268943787, 0.014614202082157135, 0.017794940620660782, 0.02097567915916443, 0.024156417697668076, 0.027337156236171722, 0.03051789104938507, 0.03369862958788872, 0.03687937185168266, 0.04006010666489601, 0.04324084147810936, 0.046421583741903305, 0.04960231855511665, 0.0527830608189106, 0.05596379563212395, 0.059144530445337296, 0.06232527270913124, 0.06550601124763489, 0.06868675351142883, 0.07186748087406158, 0.07504822313785553, 0.07822896540164948, 0.08140969276428223, 0.08459043502807617, 0.08777117729187012, 0.09095190465450287, 0.09413264691829681, 0.09731338918209076, 0.1004941314458847, 0.10367487370967865, 0.1068556010723114, 0.11003634333610535, 0.11321708559989929, 0.11639781296253204, 0.11957855522632599, 0.12275929749011993, 0.12594002485275269, 0.12912076711654663, 0.13230150938034058, 0.13548225164413452, 0.13866297900676727, 0.14184372127056122, 0.14502446353435516, 0.14820519089698792, 0.15138593316078186, 0.1545666754245758, 0.15774740278720856, 0.1609281450510025, 0.16410888731479645, 0.1672896295785904, 0.17047035694122314, 0.1736510992050171]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 14.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0], "bins": [-0.0794350728392601, -0.07786677032709122, -0.07629847526550293, -0.07473017275333405, -0.07316187024116516, -0.07159356772899628, -0.07002527266740799, -0.0684569701552391, -0.06688866764307022, -0.06532036513090134, -0.06375207006931305, -0.062183767557144165, -0.06061546504497528, -0.059047166258096695, -0.05747886747121811, -0.055910564959049225, -0.05434226244688034, -0.052773963660001755, -0.05120566487312317, -0.049637362360954285, -0.0480690635740757, -0.046500761061906815, -0.04493246227502823, -0.043364159762859344, -0.04179586097598076, -0.040227558463811874, -0.03865925967693329, -0.037090957164764404, -0.03552265837788582, -0.033954355865716934, -0.03238605707883835, -0.030817754566669464, -0.02924945577979088, -0.027681156992912292, -0.026112854480743408, -0.024544555693864822, -0.022976253181695938, -0.021407954394817352, -0.019839651882648468, -0.018271353095769882, -0.016703054308891296, -0.015134751796722412, -0.013566449284553528, -0.011998146772384644, -0.010429851710796356, -0.008861549198627472, -0.007293246686458588, -0.005724944174289703, -0.004156649112701416, -0.0025883466005325317, -0.0010200440883636475, 0.0005482509732246399, 0.002116553485393524, 0.0036848559975624084, 0.005253158509731293, 0.00682145357131958, 0.008389756083488464, 0.009958058595657349, 0.011526361107826233, 0.01309465616941452, 0.014662958681583405, 0.01623126119375229, 0.017799563705921173, 0.01936785876750946, 0.020936161279678345]}, "_runtime": 144.77402663230896, "_timestamp": 1585509223.1947563, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9750556945800781, "Value Loss": 0.009606913663446903, "_runtime": 146.21110105514526, "_timestamp": 1585509224.6318307, "_step": 99}
{"Episode reward": 3.4000000000012136, "Episode length": 966, "Policy Loss": 0.05449337139725685, "Value Loss": 10.341291427612305, "_runtime": 147.51326990127563, "_timestamp": 1585509225.9339995, "_step": 100}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.15419209003448486, "Value Loss": 11.82077407836914, "_runtime": 149.05559849739075, "_timestamp": 1585509227.4763281, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9624040126800537, "Value Loss": 0.009434256702661514, "_runtime": 150.58601307868958, "_timestamp": 1585509229.0067427, "_step": 102}
{"Episode reward": -99.80006952285626, "Episode length": 999, "Policy Loss": -0.9565744400024414, "Value Loss": 0.009302829392254353, "_runtime": 152.11027264595032, "_timestamp": 1585509230.5310023, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9451079964637756, "Value Loss": 0.009114705957472324, "_runtime": 153.3636782169342, "_timestamp": 1585509231.7844079, "_step": 104}
{"Episode reward": 20.90000000000022, "Episode length": 791, "Policy Loss": 0.2878555953502655, "Value Loss": 12.627283096313477, "_runtime": 154.9053738117218, "_timestamp": 1585509233.3261034, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9219858050346375, "Value Loss": 0.008648055605590343, "_runtime": 156.45311212539673, "_timestamp": 1585509234.8738418, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9053277969360352, "Value Loss": 0.008383631706237793, "_runtime": 157.97673654556274, "_timestamp": 1585509236.3974662, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8916731476783752, "Value Loss": 0.008068946190178394, "_runtime": 159.52446842193604, "_timestamp": 1585509237.945198, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8688794374465942, "Value Loss": 0.007713600993156433, "_runtime": 160.77945828437805, "_timestamp": 1585509239.200188, "_step": 109}
{"Episode reward": 18.60000000000035, "Episode length": 814, "Policy Loss": 0.36698874831199646, "Value Loss": 12.271329879760742, "_runtime": 162.31382203102112, "_timestamp": 1585509240.7345517, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.828011155128479, "Value Loss": 0.007015342824161053, "_runtime": 163.4513235092163, "_timestamp": 1585509241.8720531, "_step": 111}
{"Episode reward": 26.299999999999912, "Episode length": 737, "Policy Loss": 0.500767171382904, "Value Loss": 13.553033828735352, "_runtime": 164.98262906074524, "_timestamp": 1585509243.4033587, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7888915538787842, "Value Loss": 0.006413994822651148, "_runtime": 166.5316183567047, "_timestamp": 1585509244.952348, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7703813314437866, "Value Loss": 0.006122643128037453, "_runtime": 168.05280685424805, "_timestamp": 1585509246.4735365, "_step": 114}
{"Episode reward": -99.84461822509626, "Episode length": 999, "Policy Loss": -0.752595841884613, "Value Loss": 0.00580106396228075, "_runtime": 169.58806133270264, "_timestamp": 1585509248.008791, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7299671173095703, "Value Loss": 0.005472276825457811, "_runtime": 170.1329972743988, "_timestamp": 1585509248.553727, "_step": 116}
{"Episode reward": 66.6999999999998, "Episode length": 333, "Policy Loss": 2.103919506072998, "Value Loss": 29.99213981628418, "_runtime": 171.66153693199158, "_timestamp": 1585509250.0822666, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6918929815292358, "Value Loss": 0.0049844663590192795, "_runtime": 173.01477098464966, "_timestamp": 1585509251.4355006, "_step": 118}
{"Episode reward": 11.692144680023944, "Episode length": 884, "Policy Loss": 0.39951667189598083, "Value Loss": 11.301337242126465, "_runtime": 173.84124779701233, "_timestamp": 1585509252.2619774, "_step": 119}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 1.097452163696289, "Value Loss": 18.030527114868164, "_runtime": 175.37992072105408, "_timestamp": 1585509253.8006504, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6708380579948425, "Value Loss": 0.004647094290703535, "_runtime": 176.94118404388428, "_timestamp": 1585509255.3619137, "_step": 121}
{"Episode reward": -99.89776651859144, "Episode length": 999, "Policy Loss": -0.6636092066764832, "Value Loss": 0.004567885305732489, "_runtime": 178.42824625968933, "_timestamp": 1585509256.848976, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6584345102310181, "Value Loss": 0.0044523850083351135, "_runtime": 179.8140664100647, "_timestamp": 1585509258.234796, "_step": 123}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.4799501895904541, "Value Loss": 11.150362968444824, "_runtime": 181.27417254447937, "_timestamp": 1585509259.6949022, "_step": 124}
{"Episode reward": 4.900000000001128, "Episode length": 951, "Policy Loss": 0.35428059101104736, "Value Loss": 10.505797386169434, "_runtime": 182.73306107521057, "_timestamp": 1585509261.1537907, "_step": 125}
{"Episode reward": 4.600000000001145, "Episode length": 954, "Policy Loss": 0.3561491370201111, "Value Loss": 10.472822189331055, "_runtime": 184.26539158821106, "_timestamp": 1585509262.6861212, "_step": 126}
{"Episode reward": -99.80500116348126, "Episode length": 999, "Policy Loss": -0.6307249069213867, "Value Loss": 0.004104312509298325, "_runtime": 185.8113489151001, "_timestamp": 1585509264.2320786, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.623033344745636, "Value Loss": 0.004037389066070318, "_runtime": 186.6752302646637, "_timestamp": 1585509265.09596, "_step": 128}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 1.2244611978530884, "Value Loss": 18.097150802612305, "_runtime": 188.21574568748474, "_timestamp": 1585509266.6364753, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6152175068855286, "Value Loss": 0.003917224705219269, "_runtime": 189.70597434043884, "_timestamp": 1585509268.126704, "_step": 130}
{"Episode reward": 3.3000000000012193, "Episode length": 967, "Policy Loss": 0.36248329281806946, "Value Loss": 10.332274436950684, "_runtime": 190.418936252594, "_timestamp": 1585509268.839666, "_step": 131}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 1.5379770994186401, "Value Loss": 21.716032028198242, "_runtime": 191.29105472564697, "_timestamp": 1585509269.7117844, "_step": 132}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 1.082244634628296, "Value Loss": 17.80691909790039, "_runtime": 191.80828619003296, "_timestamp": 1585509270.2290158, "_step": 133}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 2.9171698093414307, "Value Loss": 31.21420669555664, "_runtime": 193.29190301895142, "_timestamp": 1585509271.7126327, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6464264392852783, "Value Loss": 0.004362641833722591, "_runtime": 194.77551913261414, "_timestamp": 1585509273.1962488, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6627702116966248, "Value Loss": 0.00459503335878253, "_runtime": 196.25462746620178, "_timestamp": 1585509274.675357, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6789388656616211, "Value Loss": 0.004762119613587856, "_runtime": 197.787495136261, "_timestamp": 1585509276.2082248, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6816855669021606, "Value Loss": 0.004866103641688824, "_runtime": 199.36315035820007, "_timestamp": 1585509277.78388, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6877816915512085, "Value Loss": 0.004910645075142384, "_runtime": 200.88536858558655, "_timestamp": 1585509279.3060982, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6845607161521912, "Value Loss": 0.004900425206869841, "_runtime": 202.42060589790344, "_timestamp": 1585509280.8413355, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6843581795692444, "Value Loss": 0.0048408228904008865, "_runtime": 203.9667477607727, "_timestamp": 1585509282.3874774, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6741777062416077, "Value Loss": 0.004737735725939274, "_runtime": 205.51227259635925, "_timestamp": 1585509283.9330022, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6643620729446411, "Value Loss": 0.00459717120975256, "_runtime": 207.06317591667175, "_timestamp": 1585509285.4839056, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6517338156700134, "Value Loss": 0.0044250949285924435, "_runtime": 208.17792510986328, "_timestamp": 1585509286.5986547, "_step": 144}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.6567431688308716, "Value Loss": 13.875039100646973, "_runtime": 209.02749347686768, "_timestamp": 1585509287.448223, "_step": 145}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 1.3745924234390259, "Value Loss": 18.464693069458008, "_runtime": 210.56876754760742, "_timestamp": 1585509288.9894972, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6262800097465515, "Value Loss": 0.004072490613907576, "_runtime": 212.08151936531067, "_timestamp": 1585509290.502249, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6189183592796326, "Value Loss": 0.004002832341939211, "_runtime": 213.57984256744385, "_timestamp": 1585509292.0005722, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6126396656036377, "Value Loss": 0.0038988899905234575, "_runtime": 215.11763906478882, "_timestamp": 1585509293.5383687, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6028560400009155, "Value Loss": 0.003765823319554329, "_runtime": 216.29349446296692, "_timestamp": 1585509294.714224, "_step": 150}
{"Episode reward": 23.600000000000065, "Episode length": 764, "Policy Loss": 0.6387102603912354, "Value Loss": 13.076908111572266, "_runtime": 217.81804895401, "_timestamp": 1585509296.2387786, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5810842514038086, "Value Loss": 0.0035138814710080624, "_runtime": 218.45354676246643, "_timestamp": 1585509296.8742764, "_step": 152}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 1.8331255912780762, "Value Loss": 25.099727630615234, "_runtime": 219.96288132667542, "_timestamp": 1585509298.383611, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.572862982749939, "Value Loss": 0.0034039535094052553, "_runtime": 221.5341637134552, "_timestamp": 1585509299.9548934, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.572025716304779, "Value Loss": 0.0033781302627176046, "_runtime": 222.25470185279846, "_timestamp": 1585509300.6754315, "_step": 155}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 1.3899016380310059, "Value Loss": 20.683385848999023, "_runtime": 223.31545519828796, "_timestamp": 1585509301.7361848, "_step": 156}
{"Episode reward": 30.89999999999965, "Episode length": 691, "Policy Loss": 0.7804970145225525, "Value Loss": 14.458341598510742, "_runtime": 224.83528542518616, "_timestamp": 1585509303.256015, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5725799202919006, "Value Loss": 0.003447100054472685, "_runtime": 226.3165934085846, "_timestamp": 1585509304.737323, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5816119909286499, "Value Loss": 0.003491475712507963, "_runtime": 227.15249276161194, "_timestamp": 1585509305.5732224, "_step": 159}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 1.1700719594955444, "Value Loss": 18.098033905029297, "_runtime": 228.6707146167755, "_timestamp": 1585509307.0914443, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.587860643863678, "Value Loss": 0.0035745196510106325, "_runtime": 230.13890528678894, "_timestamp": 1585509308.559635, "_step": 161}
{"Episode reward": 3.6000000000012022, "Episode length": 964, "Policy Loss": 0.4223346710205078, "Value Loss": 10.36459732055664, "_runtime": 230.61192512512207, "_timestamp": 1585509309.0326548, "_step": 162}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 2.5033974647521973, "Value Loss": 33.18602752685547, "_runtime": 232.12144088745117, "_timestamp": 1585509310.5421705, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6118841767311096, "Value Loss": 0.003900261130183935, "_runtime": 233.65256261825562, "_timestamp": 1585509312.0732923, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6220335960388184, "Value Loss": 0.004072733223438263, "_runtime": 235.12814688682556, "_timestamp": 1585509313.5488765, "_step": 165}
{"Episode reward": -99.80163660049298, "Episode length": 999, "Policy Loss": -0.6316749453544617, "Value Loss": 0.004184437915682793, "_runtime": 236.65987014770508, "_timestamp": 1585509315.0805998, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6368833184242249, "Value Loss": 0.004247352480888367, "_runtime": 238.19866228103638, "_timestamp": 1585509316.619392, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6389495730400085, "Value Loss": 0.004256153013557196, "_runtime": 239.08793568611145, "_timestamp": 1585509317.5086653, "_step": 168}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 1.1272159814834595, "Value Loss": 17.403169631958008, "_runtime": 239.83104705810547, "_timestamp": 1585509318.2517767, "_step": 169}
{"Episode reward": 52.799999999999606, "Episode length": 472, "Policy Loss": 1.3439691066741943, "Value Loss": 21.16301155090332, "_runtime": 241.35801219940186, "_timestamp": 1585509319.7787418, "_step": 170}
{"Episode reward": -99.84358062744, "Episode length": 999, "Policy Loss": -0.6470016837120056, "Value Loss": 0.004398297984153032, "_runtime": 242.85115766525269, "_timestamp": 1585509321.2718873, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6536789536476135, "Value Loss": 0.004484645556658506, "_runtime": 244.34172463417053, "_timestamp": 1585509322.7624543, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6586921215057373, "Value Loss": 0.0045107705518603325, "_runtime": 245.9105794429779, "_timestamp": 1585509324.331309, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6535500884056091, "Value Loss": 0.004485824145376682, "_runtime": 247.43721413612366, "_timestamp": 1585509325.8579438, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6476194858551025, "Value Loss": 0.004415174480527639, "_runtime": 248.14443802833557, "_timestamp": 1585509326.5651677, "_step": 175}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 1.525217056274414, "Value Loss": 22.246782302856445, "_runtime": 249.6772654056549, "_timestamp": 1585509328.097995, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6401028633117676, "Value Loss": 0.004317342769354582, "_runtime": 250.67710614204407, "_timestamp": 1585509329.0978358, "_step": 177}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.8470903635025024, "Value Loss": 15.251460075378418, "_runtime": 252.15981888771057, "_timestamp": 1585509330.5805485, "_step": 178}
{"Episode reward": -99.80943281650404, "Episode length": 999, "Policy Loss": -0.6396743655204773, "Value Loss": 0.004308071918785572, "_runtime": 253.15081405639648, "_timestamp": 1585509331.5715437, "_step": 179}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.8206852674484253, "Value Loss": 15.511886596679688, "_runtime": 254.3725290298462, "_timestamp": 1585509332.7932587, "_step": 180}
{"Episode reward": 18.100000000000378, "Episode length": 819, "Policy Loss": 0.48531126976013184, "Value Loss": 12.198243141174316, "_runtime": 255.89127469062805, "_timestamp": 1585509334.3120043, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.649608314037323, "Value Loss": 0.0044193877838552, "_runtime": 257.36500692367554, "_timestamp": 1585509335.7857366, "_step": 182}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": 0.2870436906814575, "Value Loss": 10.132932662963867, "_runtime": 258.861093044281, "_timestamp": 1585509337.2818227, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6491131782531738, "Value Loss": 0.004494354594498873, "_runtime": 260.40197372436523, "_timestamp": 1585509338.8227034, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.649776041507721, "Value Loss": 0.00448927516117692, "_runtime": 261.9406580924988, "_timestamp": 1585509340.3613877, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.644774854183197, "Value Loss": 0.0044354782439768314, "_runtime": 263.02059984207153, "_timestamp": 1585509341.4413295, "_step": 186}
{"Episode reward": 30.89999999999965, "Episode length": 691, "Policy Loss": 0.692636251449585, "Value Loss": 14.45702838897705, "_runtime": 264.5547149181366, "_timestamp": 1585509342.9754446, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6403391361236572, "Value Loss": 0.0043093860149383545, "_runtime": 265.5810270309448, "_timestamp": 1585509344.0017567, "_step": 188}
{"Episode reward": 33.69999999999949, "Episode length": 663, "Policy Loss": 1.153381586074829, "Value Loss": 15.06753921508789, "_runtime": 266.54649925231934, "_timestamp": 1585509344.967229, "_step": 189}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 0.818720281124115, "Value Loss": 15.756555557250977, "_runtime": 268.0768492221832, "_timestamp": 1585509346.4975789, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6369790434837341, "Value Loss": 0.004294094629585743, "_runtime": 269.61627173423767, "_timestamp": 1585509348.0370014, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6356247663497925, "Value Loss": 0.004303380846977234, "_runtime": 270.80977272987366, "_timestamp": 1585509349.2305024, "_step": 192}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.5250509977340698, "Value Loss": 12.58225154876709, "_runtime": 272.32144236564636, "_timestamp": 1585509350.742172, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6360031366348267, "Value Loss": 0.004272781778126955, "_runtime": 273.27817463874817, "_timestamp": 1585509351.6989043, "_step": 194}
{"Episode reward": 38.4999999999994, "Episode length": 615, "Policy Loss": 1.0870387554168701, "Value Loss": 16.24321746826172, "_runtime": 274.79650497436523, "_timestamp": 1585509353.2172346, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6364693641662598, "Value Loss": 0.004268512595444918, "_runtime": 276.3361361026764, "_timestamp": 1585509354.7568657, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.63094162940979, "Value Loss": 0.004252701997756958, "_runtime": 277.8404469490051, "_timestamp": 1585509356.2611766, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6297840476036072, "Value Loss": 0.004190921317785978, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023, 0.000651114503853023]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.000651114503853023, 0.0013895625015720725, 0.0034302393905818462, 0.0054709166288375854, 0.007511593401432037, 0.00955227017402649, 0.011592947877943516, 0.013633624650537968, 0.015674302354454994, 0.017714979127049446, 0.019755655899643898, 0.02179633267223835, 0.02383701130747795, 0.025877688080072403, 0.027918364852666855, 0.029959041625261307, 0.03199971839785576, 0.03404039517045021, 0.03608107194304466, 0.038121748715639114, 0.040162425488233566, 0.04220310226082802, 0.04424377903342247, 0.04628445580601692, 0.04832513630390167, 0.050365813076496124, 0.052406489849090576, 0.05444716662168503, 0.05648784339427948, 0.05852852016687393, 0.060569196939468384, 0.06260987371206284, 0.06465055048465729, 0.06669122725725174, 0.06873190402984619, 0.07077258080244064, 0.0728132575750351, 0.07485393434762955, 0.076894611120224, 0.07893528789281845, 0.0809759646654129, 0.08301664143800735, 0.0850573182106018, 0.08709799498319626, 0.08913867175579071, 0.09117934852838516, 0.09322002530097961, 0.09526070207357407, 0.09730138629674911, 0.09934206306934357, 0.10138273984193802, 0.10342341661453247, 0.10546409338712692, 0.10750477015972137, 0.10954544693231583, 0.11158612370491028, 0.11362680047750473, 0.11566747725009918, 0.11770815402269363, 0.11974883079528809, 0.12178950756788254, 0.12383018434047699, 0.12587085366249084, 0.1279115229845047, 0.12995220720767975]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [0.0, 3.8123598642414436e-05, 7.624719728482887e-05, 0.0001143707922892645, 0.00015249439456965774, 0.00019061799685005099, 0.000228741584578529, 0.00026686518685892224, 0.0003049887891393155, 0.00034311239141970873, 0.00038123599370010197, 0.0004193595959804952, 0.000457483169157058, 0.0004956068005412817, 0.0005337303737178445, 0.0005718540051020682, 0.000609977578278631, 0.0006481011514551938, 0.0006862247828394175, 0.0007243483560159802, 0.0007624719874002039, 0.0008005955605767667, 0.0008387191919609904, 0.0008768427651375532, 0.000914966338314116, 0.0009530899696983397, 0.0009912136010825634, 0.0010293371742591262, 0.001067460747435689, 0.0011055843206122518, 0.0011437080102041364, 0.0011818315833806992, 0.001219955156557262, 0.0012580787297338247, 0.0012962023029103875, 0.0013343259925022721, 0.001372449565678835, 0.0014105731388553977, 0.0014486967120319605, 0.001486820401623845, 0.0015249439748004079, 0.0015630675479769707, 0.0016011911211535335, 0.0016393146943300962, 0.0016774383839219809, 0.0017155619570985436, 0.0017536855302751064, 0.0017918091034516692, 0.001829932676628232, 0.0018680563662201166, 0.0019061799393966794, 0.0019443035125732422, 0.001982427202165127, 0.0020205506589263678, 0.0020586743485182524, 0.002096798038110137, 0.002134921494871378, 0.0021730451844632626, 0.0022111686412245035, 0.002249292330816388, 0.0022874160204082727, 0.0023255394771695137, 0.0023636631667613983, 0.0024017866235226393, 0.002439910313114524]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [35.0, 5.0, 41.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 224.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 7.0, 8.0, 16.0, 13.0, 8.0, 9.0, 7.0, 5.0, 9.0, 8.0, 10.0, 15.0, 5.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0], "bins": [-0.0024212896823883057, -0.0021985063795000315, -0.001975723309442401, -0.0017529400065541267, -0.0015301569364964962, -0.001307373633608222, -0.0010845904471352696, -0.0008618072606623173, -0.0006390240741893649, -0.00041624088771641254, -0.00019345758482813835, 2.9325485229492188e-05, 0.0002521087881177664, 0.0004748918581753969, 0.0006976751610636711, 0.0009204582311213017, 0.0011432415340095758, 0.00136602483689785, 0.0015888079069554806, 0.0018115909770131111, 0.002034374512732029, 0.0022571575827896595, 0.00247994065284729, 0.0027027237229049206, 0.0029255072586238384, 0.003148290328681469, 0.0033710733987390995, 0.0035938569344580173, 0.003816640004515648, 0.004039423074573278, 0.004262206144630909, 0.004484989680349827, 0.004707772750407457, 0.004930555820465088, 0.005153339356184006, 0.005376122426241636, 0.005598905496299267, 0.005821689032018185, 0.006044471636414528, 0.006267255172133446, 0.006490038707852364, 0.006712821312248707, 0.006935604847967625, 0.0071583883836865425, 0.007381170988082886, 0.007603954523801804, 0.007826737128198147, 0.008049520663917065, 0.008272304199635983, 0.008495086804032326, 0.008717870339751244, 0.008940653875470161, 0.009163436479866505, 0.009386220015585423, 0.00960900355130434, 0.009831786155700684, 0.010054569691419601, 0.01027735322713852, 0.010500135831534863, 0.01072291936725378, 0.010945701971650124, 0.011168485507369041, 0.01139126904308796, 0.011614051647484303, 0.01183683518320322]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0], "bins": [-0.0179302878677845, -0.016813036054372787, -0.015695782378315926, -0.014578530564904213, -0.013461277820169926, -0.012344025075435638, -0.011226773262023926, -0.010109520517289639, -0.008992267772555351, -0.007875015027821064, -0.006757762283086777, -0.005640510469675064, -0.004523257724940777, -0.0034060049802064896, -0.002288753166794777, -0.001171499490737915, -5.424767732620239e-05, 0.0010630041360855103, 0.002180257812142372, 0.0032975096255540848, 0.004414763301610947, 0.005532015115022659, 0.006649266928434372, 0.007766520604491234, 0.008883772417902946, 0.010001024231314659, 0.011118277907371521, 0.012235529720783234, 0.013352781534194946, 0.014470033347606659, 0.01558728888630867, 0.016704540699720383, 0.017821792513132095, 0.018939044326543808, 0.02005629613995552, 0.021173551678657532, 0.022290803492069244, 0.023408055305480957, 0.02452530711889267, 0.025642558932304382, 0.026759814471006393, 0.027877066284418106, 0.02899431809782982, 0.03011156991124153, 0.031228821724653244, 0.03234607353806496, 0.03346332907676697, 0.03458058089017868, 0.03569783270359039, 0.036815084517002106, 0.03793233633041382, 0.03904959186911583, 0.04016684368252754, 0.041284095495939255, 0.04240134730935097, 0.04351859912276268, 0.04463585093617439, 0.045753102749586105, 0.04687035456299782, 0.04798761382699013, 0.04910486564040184, 0.05022211745381355, 0.051339369267225266, 0.05245662108063698, 0.05357387289404869]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 1.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 18.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0], "bins": [-0.006578973028808832, -0.0061825355514883995, -0.005786098074167967, -0.005389660596847534, -0.0049932231195271015, -0.004596785642206669, -0.004200347699224949, -0.00380391045473516, -0.003407472977414727, -0.0030110355000942945, -0.0026145977899432182, -0.0022181603126227856, -0.001821722835302353, -0.0014252853579819202, -0.0010288478806614876, -0.0006324104033410549, -0.00023597292602062225, 0.0001604645512998104, 0.0005569020286202431, 0.0009533395059406757, 0.0013497774489223957, 0.001746214460581541, 0.002142652403563261, 0.0025390894152224064, 0.0029355273582041264, 0.0033319643698632717, 0.0037284023128449917, 0.004124839324504137, 0.004521277267485857, 0.004917714279145002, 0.005314152222126722, 0.005710589233785868, 0.006107027176767588, 0.006503465119749308, 0.006899902131408453, 0.007296340074390173, 0.007692777086049318, 0.008089214563369751, 0.008485652506351471, 0.008882090449333191, 0.009278528392314911, 0.009674964472651482, 0.010071402415633202, 0.010467840358614922, 0.010864278301596642, 0.011260714381933212, 0.011657152324914932, 0.012053590267896652, 0.012450028210878372, 0.012846466153860092, 0.013242902234196663, 0.013639340177178383, 0.014035778120160103, 0.014432216063141823, 0.014828652143478394, 0.015225090086460114, 0.015621528029441833, 0.016017965972423553, 0.016414402052760124, 0.016810839995741844, 0.017207277938723564, 0.017603715881705284, 0.018000151962041855, 0.018396589905023575, 0.018793027848005295]}, "_runtime": 279.3730413913727, "_timestamp": 1585509357.793771, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6225584149360657, "Value Loss": 0.004088878631591797, "_runtime": 280.0520746707916, "_timestamp": 1585509358.4728043, "_step": 199}
{"Episode reward": 57.49999999999967, "Episode length": 425, "Policy Loss": 1.553596019744873, "Value Loss": 23.50377082824707, "_runtime": 281.5770802497864, "_timestamp": 1585509359.99781, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6100772619247437, "Value Loss": 0.0039531514048576355, "_runtime": 282.827241897583, "_timestamp": 1585509361.2479715, "_step": 201}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 0.5445528030395508, "Value Loss": 12.31894302368164, "_runtime": 283.204656124115, "_timestamp": 1585509361.6253858, "_step": 202}
{"Episode reward": 76.09999999999994, "Episode length": 239, "Policy Loss": 3.246386766433716, "Value Loss": 41.792572021484375, "_runtime": 284.3223006725311, "_timestamp": 1585509362.7430303, "_step": 203}
{"Episode reward": 26.299999999999912, "Episode length": 737, "Policy Loss": 0.6486034393310547, "Value Loss": 13.555160522460938, "_runtime": 285.8407332897186, "_timestamp": 1585509364.261463, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6490718126296997, "Value Loss": 0.004450701177120209, "_runtime": 287.3124620914459, "_timestamp": 1585509365.7331917, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6646803021430969, "Value Loss": 0.0046662259846925735, "_runtime": 288.8189480304718, "_timestamp": 1585509367.2396777, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6705330610275269, "Value Loss": 0.00481223501265049, "_runtime": 290.31674003601074, "_timestamp": 1585509368.7374697, "_step": 207}
{"Episode reward": 2.000000000001293, "Episode length": 980, "Policy Loss": 0.2845333218574524, "Value Loss": 10.194697380065918, "_runtime": 291.08790159225464, "_timestamp": 1585509369.5086312, "_step": 208}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 1.1865531206130981, "Value Loss": 20.30147933959961, "_runtime": 292.6492884159088, "_timestamp": 1585509371.070018, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6974371075630188, "Value Loss": 0.005182937253266573, "_runtime": 294.19156217575073, "_timestamp": 1585509372.6122918, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7066493630409241, "Value Loss": 0.005302188452333212, "_runtime": 295.3838622570038, "_timestamp": 1585509373.804592, "_step": 211}
{"Episode reward": 20.300000000000253, "Episode length": 797, "Policy Loss": 0.5978381037712097, "Value Loss": 12.534015655517578, "_runtime": 296.32540011405945, "_timestamp": 1585509374.7461298, "_step": 212}
{"Episode reward": 39.49999999999942, "Episode length": 605, "Policy Loss": 1.096055507659912, "Value Loss": 16.5100154876709, "_runtime": 297.68074893951416, "_timestamp": 1585509376.1014786, "_step": 213}
{"Episode reward": 11.600000000000747, "Episode length": 884, "Policy Loss": 0.31364575028419495, "Value Loss": 11.305434226989746, "_runtime": 298.86907839775085, "_timestamp": 1585509377.289808, "_step": 214}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 0.504742443561554, "Value Loss": 12.757760047912598, "_runtime": 300.3669168949127, "_timestamp": 1585509378.7876465, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7494657635688782, "Value Loss": 0.00597725622355938, "_runtime": 301.89116525650024, "_timestamp": 1585509380.311895, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7574062347412109, "Value Loss": 0.006097892299294472, "_runtime": 302.2683298587799, "_timestamp": 1585509380.6890595, "_step": 217}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 3.468536853790283, "Value Loss": 44.579036712646484, "_runtime": 303.78819942474365, "_timestamp": 1585509382.208929, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7832536101341248, "Value Loss": 0.006497249472886324, "_runtime": 305.3247277736664, "_timestamp": 1585509383.7454574, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7959088087081909, "Value Loss": 0.006756005343049765, "_runtime": 306.3293216228485, "_timestamp": 1585509384.7500513, "_step": 220}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 0.5432380437850952, "Value Loss": 14.688335418701172, "_runtime": 307.2834949493408, "_timestamp": 1585509385.7042246, "_step": 221}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": 0.7133181691169739, "Value Loss": 16.16101837158203, "_runtime": 308.81249952316284, "_timestamp": 1585509387.2332292, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8321029543876648, "Value Loss": 0.007387463469058275, "_runtime": 310.32531476020813, "_timestamp": 1585509388.7460444, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8398794531822205, "Value Loss": 0.007545039523392916, "_runtime": 311.4550156593323, "_timestamp": 1585509389.8757453, "_step": 224}
{"Episode reward": 25.09999999999998, "Episode length": 749, "Policy Loss": 0.40561890602111816, "Value Loss": 13.335458755493164, "_runtime": 312.24306654930115, "_timestamp": 1585509390.6637962, "_step": 225}
{"Episode reward": 49.69999999999956, "Episode length": 503, "Policy Loss": 1.2566816806793213, "Value Loss": 19.853527069091797, "_runtime": 312.85884976387024, "_timestamp": 1585509391.2795794, "_step": 226}
{"Episode reward": 60.99999999999972, "Episode length": 390, "Policy Loss": 1.5934079885482788, "Value Loss": 25.603330612182617, "_runtime": 314.3607528209686, "_timestamp": 1585509392.7814825, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8776264786720276, "Value Loss": 0.008251294493675232, "_runtime": 315.2900047302246, "_timestamp": 1585509393.7107344, "_step": 228}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": 0.7711455821990967, "Value Loss": 16.840843200683594, "_runtime": 316.1849801540375, "_timestamp": 1585509394.6057098, "_step": 229}
{"Episode reward": 39.59999999999942, "Episode length": 604, "Policy Loss": 0.6150358319282532, "Value Loss": 16.53404998779297, "_runtime": 317.69949650764465, "_timestamp": 1585509396.1202261, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9263243675231934, "Value Loss": 0.009107399731874466, "_runtime": 319.1988162994385, "_timestamp": 1585509397.619546, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9363813400268555, "Value Loss": 0.009316208772361279, "_runtime": 320.6938798427582, "_timestamp": 1585509399.1146095, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9423354864120483, "Value Loss": 0.009401547722518444, "_runtime": 322.2215678691864, "_timestamp": 1585509400.6422975, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9377509951591492, "Value Loss": 0.009373602457344532, "_runtime": 323.7496156692505, "_timestamp": 1585509402.1703453, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9310190081596375, "Value Loss": 0.009244095534086227, "_runtime": 324.6738531589508, "_timestamp": 1585509403.0945828, "_step": 235}
{"Episode reward": 40.19999999999943, "Episode length": 598, "Policy Loss": 0.6308073401451111, "Value Loss": 16.69964027404785, "_runtime": 325.8205122947693, "_timestamp": 1585509404.241242, "_step": 236}
{"Episode reward": 25.242522376775725, "Episode length": 749, "Policy Loss": 0.4033379852771759, "Value Loss": 13.334814071655273, "_runtime": 327.22346568107605, "_timestamp": 1585509405.6441953, "_step": 237}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": 0.14223016798496246, "Value Loss": 10.953130722045898, "_runtime": 328.72672510147095, "_timestamp": 1585509407.1474547, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9132630825042725, "Value Loss": 0.008799550123512745, "_runtime": 330.2436146736145, "_timestamp": 1585509408.6643443, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9062074422836304, "Value Loss": 0.008663143962621689, "_runtime": 331.77081418037415, "_timestamp": 1585509410.1915438, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8937767148017883, "Value Loss": 0.008444517850875854, "_runtime": 333.30262064933777, "_timestamp": 1585509411.7233503, "_step": 241}
{"Episode reward": -99.800074768065, "Episode length": 999, "Policy Loss": -0.8769609928131104, "Value Loss": 0.008147988468408585, "_runtime": 334.83439111709595, "_timestamp": 1585509413.2551208, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8568364381790161, "Value Loss": 0.007810262031853199, "_runtime": 336.3721466064453, "_timestamp": 1585509414.7928762, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.836239755153656, "Value Loss": 0.007418898865580559, "_runtime": 337.9527449607849, "_timestamp": 1585509416.3734746, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8086971640586853, "Value Loss": 0.006993175018578768, "_runtime": 339.48233819007874, "_timestamp": 1585509417.9030678, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7848231792449951, "Value Loss": 0.0065435669384896755, "_runtime": 340.7686676979065, "_timestamp": 1585509419.1893973, "_step": 246}
{"Episode reward": 16.8160020589833, "Episode length": 832, "Policy Loss": 0.3522164225578308, "Value Loss": 12.00655460357666, "_runtime": 341.5516812801361, "_timestamp": 1585509419.972411, "_step": 247}
{"Episode reward": 50.29999999999957, "Episode length": 497, "Policy Loss": 1.1510016918182373, "Value Loss": 20.096033096313477, "_runtime": 343.08811926841736, "_timestamp": 1585509421.508849, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7174626588821411, "Value Loss": 0.005496040917932987, "_runtime": 344.62428402900696, "_timestamp": 1585509423.0450137, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7029680609703064, "Value Loss": 0.005243946332484484, "_runtime": 346.1189525127411, "_timestamp": 1585509424.5396821, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6842830777168274, "Value Loss": 0.004963614046573639, "_runtime": 347.6655945777893, "_timestamp": 1585509426.0863242, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.663716733455658, "Value Loss": 0.0046625141985714436, "_runtime": 348.5357391834259, "_timestamp": 1585509426.9564688, "_step": 252}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 1.3308992385864258, "Value Loss": 17.998586654663086, "_runtime": 350.07069158554077, "_timestamp": 1585509428.4914212, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6240043640136719, "Value Loss": 0.0041572158224880695, "_runtime": 351.603964805603, "_timestamp": 1585509430.0246944, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6106195449829102, "Value Loss": 0.0039427815936505795, "_runtime": 352.6254880428314, "_timestamp": 1585509431.0462177, "_step": 255}
{"Episode reward": 32.399999999999565, "Episode length": 676, "Policy Loss": 0.9116222858428955, "Value Loss": 14.778594970703125, "_runtime": 354.16265058517456, "_timestamp": 1585509432.5833802, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5789934992790222, "Value Loss": 0.003566823899745941, "_runtime": 355.70555901527405, "_timestamp": 1585509434.1262887, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5648333430290222, "Value Loss": 0.0033996698912233114, "_runtime": 356.3445143699646, "_timestamp": 1585509434.765244, "_step": 258}
{"Episode reward": 58.19999999999968, "Episode length": 418, "Policy Loss": 1.6500015258789062, "Value Loss": 23.899520874023438, "_runtime": 357.8801827430725, "_timestamp": 1585509436.3009124, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5477015376091003, "Value Loss": 0.0031691708136349916, "_runtime": 359.42373418807983, "_timestamp": 1585509437.8444638, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5135189294815063, "Value Loss": 0.045491110533475876, "_runtime": 360.04992151260376, "_timestamp": 1585509438.4706511, "_step": 261}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 1.702026128768921, "Value Loss": 24.248281478881836, "_runtime": 361.6196620464325, "_timestamp": 1585509440.0403917, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5322478413581848, "Value Loss": 0.0030192146077752113, "_runtime": 362.7283368110657, "_timestamp": 1585509441.1490664, "_step": 263}
{"Episode reward": 27.89999999999982, "Episode length": 721, "Policy Loss": 0.9149858355522156, "Value Loss": 13.857413291931152, "_runtime": 364.21785831451416, "_timestamp": 1585509442.638588, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5336186289787292, "Value Loss": 0.003054162487387657, "_runtime": 364.9599463939667, "_timestamp": 1585509443.380676, "_step": 265}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 1.4321502447128296, "Value Loss": 21.392637252807617, "_runtime": 366.2650487422943, "_timestamp": 1585509444.6857784, "_step": 266}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": 0.5254930853843689, "Value Loss": 11.52420425415039, "_runtime": 367.7987575531006, "_timestamp": 1585509446.2194872, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5587167739868164, "Value Loss": 0.0033023436553776264, "_runtime": 368.87261152267456, "_timestamp": 1585509447.2933412, "_step": 268}
{"Episode reward": 28.658111041784068, "Episode length": 714, "Policy Loss": 0.7323276996612549, "Value Loss": 13.993800163269043, "_runtime": 369.64777517318726, "_timestamp": 1585509448.0685048, "_step": 269}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": 1.648140549659729, "Value Loss": 20.06003761291504, "_runtime": 370.2255880832672, "_timestamp": 1585509448.6463177, "_step": 270}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.878627061843872, "Value Loss": 26.924942016601562, "_runtime": 371.3945269584656, "_timestamp": 1585509449.8152566, "_step": 271}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.5785492062568665, "Value Loss": 12.710436820983887, "_runtime": 372.8726279735565, "_timestamp": 1585509451.2933576, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6493735909461975, "Value Loss": 0.004487902857363224, "_runtime": 374.35340213775635, "_timestamp": 1585509452.7741318, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6685529947280884, "Value Loss": 0.004795708227902651, "_runtime": 375.8623163700104, "_timestamp": 1585509454.283046, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.688951849937439, "Value Loss": 0.005025218240916729, "_runtime": 377.4023413658142, "_timestamp": 1585509455.823071, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6974875330924988, "Value Loss": 0.005177719984203577, "_runtime": 378.7647957801819, "_timestamp": 1585509457.1855254, "_step": 276}
{"Episode reward": 11.100000000000776, "Episode length": 889, "Policy Loss": 0.38129353523254395, "Value Loss": 11.237515449523926, "_runtime": 379.63592505455017, "_timestamp": 1585509458.0566547, "_step": 277}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 1.022066593170166, "Value Loss": 17.9646053314209, "_runtime": 381.08409094810486, "_timestamp": 1585509459.5048206, "_step": 278}
{"Episode reward": 5.800000000001077, "Episode length": 942, "Policy Loss": 0.259034126996994, "Value Loss": 10.605457305908203, "_runtime": 382.61810636520386, "_timestamp": 1585509461.038836, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7340571284294128, "Value Loss": 0.0057489932514727116, "_runtime": 384.07542157173157, "_timestamp": 1585509462.4961512, "_step": 280}
{"Episode reward": 5.6000000000010886, "Episode length": 944, "Policy Loss": 0.25557664036750793, "Value Loss": 10.582862854003906, "_runtime": 385.43816328048706, "_timestamp": 1585509463.858893, "_step": 281}
{"Episode reward": 11.400000000000759, "Episode length": 886, "Policy Loss": 0.3055688440799713, "Value Loss": 11.275191307067871, "_runtime": 386.8919608592987, "_timestamp": 1585509465.3126905, "_step": 282}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": 0.32794100046157837, "Value Loss": 10.493861198425293, "_runtime": 388.422171831131, "_timestamp": 1585509466.8429015, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7646750211715698, "Value Loss": 0.006309937220066786, "_runtime": 389.35229110717773, "_timestamp": 1585509467.7730207, "_step": 284}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.8578298091888428, "Value Loss": 16.563669204711914, "_runtime": 390.1245982646942, "_timestamp": 1585509468.545328, "_step": 285}
{"Episode reward": 50.69999999999958, "Episode length": 493, "Policy Loss": 1.0858217477798462, "Value Loss": 20.257732391357422, "_runtime": 391.6548881530762, "_timestamp": 1585509470.0756178, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.788724422454834, "Value Loss": 0.006783824879676104, "_runtime": 393.1484172344208, "_timestamp": 1585509471.5691469, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.795939564704895, "Value Loss": 0.006934063509106636, "_runtime": 394.6464500427246, "_timestamp": 1585509473.0671797, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8015857338905334, "Value Loss": 0.006989184767007828, "_runtime": 396.1864912509918, "_timestamp": 1585509474.607221, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7981459498405457, "Value Loss": 0.0069572171196341515, "_runtime": 397.7183485031128, "_timestamp": 1585509476.1390781, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7890446782112122, "Value Loss": 0.006847396958619356, "_runtime": 399.25726413726807, "_timestamp": 1585509477.6779938, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7774306535720825, "Value Loss": 0.0066698044538497925, "_runtime": 400.6018419265747, "_timestamp": 1585509479.0225716, "_step": 292}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": 0.2662793695926666, "Value Loss": 11.442830085754395, "_runtime": 402.15135169029236, "_timestamp": 1585509480.5720813, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7521888613700867, "Value Loss": 0.006257849745452404, "_runtime": 403.6973912715912, "_timestamp": 1585509482.118121, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7393718361854553, "Value Loss": 0.0060282014310359955, "_runtime": 405.2238154411316, "_timestamp": 1585509483.644545, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7192338109016418, "Value Loss": 0.005755394231528044, "_runtime": 406.79364562034607, "_timestamp": 1585509485.2143753, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6975963115692139, "Value Loss": 0.005448812618851662, "_runtime": 407.6510317325592, "_timestamp": 1585509486.0717614, "_step": 297}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 1.022078514099121, "Value Loss": 18.26048469543457, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058, 0.005229627713561058]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005229627713561058, 0.008509465493261814, 0.022248558700084686, 0.03598765283823013, 0.04972674697637558, 0.06346583366394043, 0.07720492780208588, 0.09094402194023132, 0.10468311607837677, 0.11842221021652222, 0.13216130435466766, 0.1459003984928131, 0.15963949263095856, 0.173378586769104, 0.18711768090724945, 0.2008567750453949, 0.21459586918354034, 0.2283349633216858, 0.24207405745983124, 0.2558131515979767, 0.26955223083496094, 0.2832913398742676, 0.29703041911125183, 0.31076952815055847, 0.3245086073875427, 0.33824771642684937, 0.3519867956638336, 0.36572590470314026, 0.3794649839401245, 0.39320409297943115, 0.4069431722164154, 0.42068228125572205, 0.4344213604927063, 0.44816043972969055, 0.4618995487689972, 0.47563862800598145, 0.4893777370452881, 0.50311678647995, 0.5168558955192566, 0.5305950045585632, 0.5443340539932251, 0.5580731630325317, 0.5718122720718384, 0.585551381111145, 0.5992904305458069, 0.6130295395851135, 0.6267686486244202, 0.6405077576637268, 0.6542468070983887, 0.6679859161376953, 0.681725025177002, 0.6954640746116638, 0.7092031836509705, 0.7229422926902771, 0.7366814017295837, 0.7504204511642456, 0.7641595602035522, 0.7778986692428589, 0.7916377782821655, 0.8053768277168274, 0.819115936756134, 0.8328550457954407, 0.8465941548347473, 0.8603332042694092, 0.8740723133087158]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [0.0, 0.00029119185637682676, 0.0005823837127536535, 0.0008735755691304803, 0.001164767425507307, 0.0014559592818841338, 0.0017471511382609606, 0.0020383428782224655, 0.002329534851014614, 0.0026207268238067627, 0.0029119185637682676, 0.0032031103037297726, 0.003494302276521921, 0.0037854942493140697, 0.004076685756444931, 0.00436787772923708, 0.004659069702029228, 0.004950261674821377, 0.005241453647613525, 0.005532645154744387, 0.005823837127536535, 0.006115029100328684, 0.006406220607459545, 0.006697412580251694, 0.006988604553043842, 0.007279796525835991, 0.0075709884986281395, 0.007862180471420288, 0.008153371512889862, 0.00844456348568201, 0.00873575545847416, 0.009026947431266308, 0.009318139404058456, 0.009609331376850605, 0.009900523349642754, 0.010191715322434902, 0.01048290729522705, 0.010774098336696625, 0.011065290309488773, 0.011356482282280922, 0.01164767425507307, 0.011938866227865219, 0.012230058200657368, 0.012521250173449516, 0.01281244121491909, 0.013103633187711239, 0.013394825160503387, 0.013686017133295536, 0.013977209106087685, 0.014268401078879833, 0.014559593051671982, 0.01485078502446413, 0.015141976997256279, 0.015433168038725853, 0.015724360942840576, 0.01601555198431015, 0.016306743025779724, 0.016597935929894447, 0.01688912697136402, 0.017180319875478745, 0.01747151091694832, 0.01776270382106304, 0.018053894862532616, 0.01834508776664734, 0.018636278808116913]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [30.0, 6.0, 31.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 224.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 8.0, 12.0, 9.0, 18.0, 10.0, 14.0, 4.0, 10.0, 9.0, 6.0, 10.0, 5.0, 7.0, 11.0, 5.0, 3.0, 9.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 0.0, 2.0], "bins": [-0.01850493997335434, -0.016869351267814636, -0.015233763493597507, -0.013598174788057804, -0.011962587013840675, -0.010326998308300972, -0.008691409602761269, -0.00705582182854414, -0.0054202331230044365, -0.003784644417464733, -0.0021490566432476044, -0.000513467937707901, 0.0011221207678318024, 0.0027577094733715057, 0.00439329631626606, 0.006028885021805763, 0.007664473727345467, 0.00930006243288517, 0.010935651138424873, 0.012571237981319427, 0.01420682668685913, 0.015842415392398834, 0.017478004097938538, 0.01911359280347824, 0.020749181509017944, 0.022384770214557648, 0.02402035892009735, 0.025655943900346756, 0.02729153260588646, 0.028927121311426163, 0.030562710016965866, 0.03219829872250557, 0.03383388742804527, 0.035469476133584976, 0.03710506483912468, 0.03874065354466438, 0.040376242250204086, 0.04201183095574379, 0.043647415935993195, 0.0452830046415329, 0.0469185933470726, 0.048554182052612305, 0.05018977075815201, 0.05182535946369171, 0.053460948169231415, 0.05509653687477112, 0.05673212558031082, 0.058367714285850525, 0.06000330299139023, 0.06163889169692993, 0.06327448040246964, 0.06491006910800934, 0.06654565781354904, 0.06818124651908875, 0.06981682777404785, 0.07145241647958755, 0.07308800518512726, 0.07472359389066696, 0.07635918259620667, 0.07799477130174637, 0.07963036000728607, 0.08126594871282578, 0.08290153741836548, 0.08453712612390518, 0.08617271482944489]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 6.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.21684399247169495, -0.20736095309257507, -0.1978779137134552, -0.18839487433433533, -0.17891183495521545, -0.16942879557609558, -0.15994574129581451, -0.15046270191669464, -0.14097966253757477, -0.1314966231584549, -0.12201358377933502, -0.11253053694963455, -0.10304749757051468, -0.0935644581913948, -0.08408141136169434, -0.07459837198257446, -0.06511533260345459, -0.05563229322433472, -0.046149253845214844, -0.03666621446609497, -0.027183175086975098, -0.01770012080669403, -0.008217081427574158, 0.0012659579515457153, 0.010748997330665588, 0.02023203670978546, 0.029715076088905334, 0.0391981303691864, 0.048681169748306274, 0.05816420912742615, 0.06764724850654602, 0.0771302878856659, 0.08661332726478577, 0.09609636664390564, 0.10557940602302551, 0.11506244540214539, 0.12454548478126526, 0.13402852416038513, 0.143511563539505, 0.15299460291862488, 0.16247764229774475, 0.171960711479187, 0.18144375085830688, 0.19092679023742676, 0.20040982961654663, 0.2098928689956665, 0.21937590837478638, 0.22885894775390625, 0.23834198713302612, 0.247825026512146, 0.25730806589126587, 0.26679110527038574, 0.2762741446495056, 0.2857572138309479, 0.29524025321006775, 0.3047232925891876, 0.3142063319683075, 0.32368937134742737, 0.33317241072654724, 0.3426554501056671, 0.352138489484787, 0.36162152886390686, 0.37110456824302673, 0.3805876076221466, 0.3900706470012665]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 10.0, 11.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16540466248989105, -0.1613784283399582, -0.15735219419002533, -0.15332596004009247, -0.1492997258901596, -0.14527349174022675, -0.14124725759029388, -0.13722102344036102, -0.13319478929042816, -0.1291685551404953, -0.12514232099056244, -0.12111608684062958, -0.11708985269069672, -0.11306361854076385, -0.109037384390831, -0.10501115024089813, -0.10098491609096527, -0.09695868194103241, -0.09293244779109955, -0.08890621364116669, -0.08487997949123383, -0.08085374534130096, -0.0768275111913681, -0.07280127704143524, -0.06877504289150238, -0.06474880874156952, -0.06072257459163666, -0.056696340441703796, -0.052670106291770935, -0.048643872141838074, -0.04461763799190521, -0.04059140384197235, -0.03656516969203949, -0.03253893554210663, -0.028512701392173767, -0.024486467242240906, -0.020460233092308044, -0.016433998942375183, -0.012407764792442322, -0.00838153064250946, -0.004355296492576599, -0.0003290623426437378, 0.0036971718072891235, 0.007723405957221985, 0.011749640107154846, 0.015775874257087708, 0.01980210840702057, 0.02382834255695343, 0.02785457670688629, 0.03188081085681915, 0.035907045006752014, 0.039933279156684875, 0.04395951330661774, 0.0479857474565506, 0.05201198160648346, 0.05603821575641632, 0.06006444990634918, 0.06409068405628204, 0.0681169182062149, 0.07214315235614777, 0.07616938650608063, 0.08019562065601349, 0.08422185480594635, 0.08824808895587921, 0.09227432310581207]}, "_runtime": 408.8294355869293, "_timestamp": 1585509487.2501652, "_step": 298}
{"Episode reward": 23.0000000000001, "Episode length": 770, "Policy Loss": 0.5157771706581116, "Value Loss": 12.973714828491211, "_runtime": 409.7583518028259, "_timestamp": 1585509488.1790814, "_step": 299}
{"Episode reward": 40.799999999999436, "Episode length": 592, "Policy Loss": 0.8522619605064392, "Value Loss": 16.873292922973633, "_runtime": 411.15044045448303, "_timestamp": 1585509489.57117, "_step": 300}
{"Episode reward": 6.700000000001026, "Episode length": 933, "Policy Loss": 0.5070828199386597, "Value Loss": 10.708088874816895, "_runtime": 412.6501877307892, "_timestamp": 1585509491.0709174, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6510686874389648, "Value Loss": 0.004768043290823698, "_runtime": 414.1487171649933, "_timestamp": 1585509492.5694468, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.643559455871582, "Value Loss": 0.004715279676020145, "_runtime": 415.5156285762787, "_timestamp": 1585509493.9363582, "_step": 303}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": 0.3919760584831238, "Value Loss": 11.07603645324707, "_runtime": 417.0416362285614, "_timestamp": 1585509495.4623659, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6327168941497803, "Value Loss": 0.004555204417556524, "_runtime": 418.568345785141, "_timestamp": 1585509496.9890754, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6256542801856995, "Value Loss": 0.0044501605443656445, "_runtime": 420.0787100791931, "_timestamp": 1585509498.4994397, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6162298917770386, "Value Loss": 0.004304290283471346, "_runtime": 420.78083634376526, "_timestamp": 1585509499.201566, "_step": 307}
{"Episode reward": 54.899999999999636, "Episode length": 451, "Policy Loss": 1.3633452653884888, "Value Loss": 22.148591995239258, "_runtime": 421.12596321105957, "_timestamp": 1585509499.5466928, "_step": 308}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": 3.9658915996551514, "Value Loss": 48.96100616455078, "_runtime": 422.63017749786377, "_timestamp": 1585509501.0509071, "_step": 309}
{"Episode reward": 0.10000000000140119, "Episode length": 999, "Policy Loss": 0.39998531341552734, "Value Loss": 10.001126289367676, "_runtime": 423.7027361392975, "_timestamp": 1585509502.1234658, "_step": 310}
{"Episode reward": 26.399999999999906, "Episode length": 736, "Policy Loss": 0.5993775725364685, "Value Loss": 13.57307243347168, "_runtime": 425.14197182655334, "_timestamp": 1585509503.5627015, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6589882969856262, "Value Loss": 0.004994535818696022, "_runtime": 426.65071988105774, "_timestamp": 1585509505.0714495, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6774086952209473, "Value Loss": 0.0052403234876692295, "_runtime": 428.14714550971985, "_timestamp": 1585509506.5678751, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6833126544952393, "Value Loss": 0.00540462089702487, "_runtime": 429.6970782279968, "_timestamp": 1585509508.1178079, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6919772624969482, "Value Loss": 0.005491096060723066, "_runtime": 430.9495601654053, "_timestamp": 1585509509.3702898, "_step": 315}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.3852490186691284, "Value Loss": 12.123441696166992, "_runtime": 432.2354929447174, "_timestamp": 1585509510.6562226, "_step": 316}
{"Episode reward": 15.197450613976073, "Episode length": 849, "Policy Loss": 0.3642607629299164, "Value Loss": 11.766568183898926, "_runtime": 433.75776529312134, "_timestamp": 1585509512.178495, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.698267936706543, "Value Loss": 0.005645446944981813, "_runtime": 435.25690960884094, "_timestamp": 1585509513.6776392, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7006111741065979, "Value Loss": 0.0056575993075966835, "_runtime": 436.7667381763458, "_timestamp": 1585509515.1874678, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6991291046142578, "Value Loss": 0.005602250806987286, "_runtime": 438.2856481075287, "_timestamp": 1585509516.7063777, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6868321299552917, "Value Loss": 0.005487279500812292, "_runtime": 439.82129549980164, "_timestamp": 1585509518.2420251, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6782177686691284, "Value Loss": 0.005320990923792124, "_runtime": 441.3510344028473, "_timestamp": 1585509519.771764, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6617540717124939, "Value Loss": 0.0051117828115820885, "_runtime": 442.8848648071289, "_timestamp": 1585509521.3055944, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6462037563323975, "Value Loss": 0.004867898765951395, "_runtime": 443.39128708839417, "_timestamp": 1585509521.8120167, "_step": 324}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 2.3284714221954346, "Value Loss": 32.218936920166016, "_runtime": 444.9081470966339, "_timestamp": 1585509523.3288767, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6289066076278687, "Value Loss": 0.004561677575111389, "_runtime": 446.43845558166504, "_timestamp": 1585509524.8591852, "_step": 326}
{"Episode reward": -99.80306420922139, "Episode length": 999, "Policy Loss": -0.6204314231872559, "Value Loss": 0.004473021719604731, "_runtime": 447.90764927864075, "_timestamp": 1585509526.328379, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6100499629974365, "Value Loss": 0.004348762799054384, "_runtime": 449.4298324584961, "_timestamp": 1585509527.850562, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5993801355361938, "Value Loss": 0.004184901248663664, "_runtime": 450.9595060348511, "_timestamp": 1585509529.3802357, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5881319046020508, "Value Loss": 0.003991738893091679, "_runtime": 452.5158097743988, "_timestamp": 1585509530.9365394, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5699355602264404, "Value Loss": 0.0037757237441837788, "_runtime": 454.04994201660156, "_timestamp": 1585509532.4706717, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.551347553730011, "Value Loss": 0.0035429978743195534, "_runtime": 455.5861258506775, "_timestamp": 1585509534.0068555, "_step": 332}
{"Episode reward": -99.89713988900046, "Episode length": 999, "Policy Loss": -0.5321006178855896, "Value Loss": 0.0032987897284328938, "_runtime": 456.30564546585083, "_timestamp": 1585509534.726375, "_step": 333}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 1.4048829078674316, "Value Loss": 21.718168258666992, "_runtime": 457.8227686882019, "_timestamp": 1585509536.2434983, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5015114545822144, "Value Loss": 0.0029356423765420914, "_runtime": 458.3087565898895, "_timestamp": 1585509536.7294862, "_step": 335}
{"Episode reward": 70.49999999999986, "Episode length": 295, "Policy Loss": 2.628070831298828, "Value Loss": 33.86522674560547, "_runtime": 459.7774655818939, "_timestamp": 1585509538.1981952, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4933468997478485, "Value Loss": 0.0028602788224816322, "_runtime": 461.30268025398254, "_timestamp": 1585509539.72341, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4987923800945282, "Value Loss": 0.0028803078457713127, "_runtime": 462.7688479423523, "_timestamp": 1585509541.1895776, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49605733156204224, "Value Loss": 0.002864666050300002, "_runtime": 464.29468178749084, "_timestamp": 1585509542.7154114, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49401918053627014, "Value Loss": 0.002817140193656087, "_runtime": 465.8148260116577, "_timestamp": 1585509544.2355556, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.487213671207428, "Value Loss": 0.0027418748941272497, "_runtime": 467.31727385520935, "_timestamp": 1585509545.7380035, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4786761701107025, "Value Loss": 0.0026431549340486526, "_runtime": 468.84943151474, "_timestamp": 1585509547.2701612, "_step": 342}
{"Episode reward": -99.80296249985555, "Episode length": 999, "Policy Loss": -0.4661613404750824, "Value Loss": 0.0025248276069760323, "_runtime": 470.3835458755493, "_timestamp": 1585509548.8042755, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45583686232566833, "Value Loss": 0.0023921083193272352, "_runtime": 470.64256048202515, "_timestamp": 1585509549.06329, "_step": 344}
{"Episode reward": 86.90000000000003, "Episode length": 131, "Policy Loss": 6.446826934814453, "Value Loss": 76.26573944091797, "_runtime": 471.5788745880127, "_timestamp": 1585509549.9996042, "_step": 345}
{"Episode reward": 38.3999999999994, "Episode length": 616, "Policy Loss": 0.963019609451294, "Value Loss": 16.22002410888672, "_runtime": 473.095486164093, "_timestamp": 1585509551.5162158, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4935619831085205, "Value Loss": 0.0028253975324332714, "_runtime": 474.5473222732544, "_timestamp": 1585509552.968052, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5166007876396179, "Value Loss": 0.003092014230787754, "_runtime": 475.6367075443268, "_timestamp": 1585509554.0574372, "_step": 348}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.7737135291099548, "Value Loss": 14.191506385803223, "_runtime": 476.7333953380585, "_timestamp": 1585509555.154125, "_step": 349}
{"Episode reward": 27.699999999999832, "Episode length": 723, "Policy Loss": 0.6658366322517395, "Value Loss": 13.818329811096191, "_runtime": 477.33955121040344, "_timestamp": 1585509555.7602808, "_step": 350}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 1.702201008796692, "Value Loss": 25.67886734008789, "_runtime": 478.8264787197113, "_timestamp": 1585509557.2472084, "_step": 351}
{"Episode reward": -99.83921523690084, "Episode length": 999, "Policy Loss": -0.6050440669059753, "Value Loss": 0.004262981936335564, "_runtime": 480.32329964637756, "_timestamp": 1585509558.7440293, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6298232078552246, "Value Loss": 0.004607164766639471, "_runtime": 481.794358253479, "_timestamp": 1585509560.215088, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.648264467716217, "Value Loss": 0.004871860146522522, "_runtime": 482.7841007709503, "_timestamp": 1585509561.2048304, "_step": 354}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.6719261407852173, "Value Loss": 15.250510215759277, "_runtime": 484.30502009391785, "_timestamp": 1585509562.7257497, "_step": 355}
{"Episode reward": -99.84413033127645, "Episode length": 999, "Policy Loss": -0.6755646467208862, "Value Loss": 0.005295748356729746, "_runtime": 485.82548427581787, "_timestamp": 1585509564.246214, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6828598976135254, "Value Loss": 0.005461206194013357, "_runtime": 486.38001704216003, "_timestamp": 1585509564.8007467, "_step": 357}
{"Episode reward": 63.69999999999976, "Episode length": 363, "Policy Loss": 1.7339102029800415, "Value Loss": 27.51274299621582, "_runtime": 486.92796325683594, "_timestamp": 1585509565.348693, "_step": 358}
{"Episode reward": 64.99999999999977, "Episode length": 350, "Policy Loss": 1.8943431377410889, "Value Loss": 28.533735275268555, "_runtime": 487.17494344711304, "_timestamp": 1585509565.595673, "_step": 359}
{"Episode reward": 86.40000000000003, "Episode length": 136, "Policy Loss": 6.767289638519287, "Value Loss": 73.41983032226562, "_runtime": 487.7372393608093, "_timestamp": 1585509566.157969, "_step": 360}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.4663976430892944, "Value Loss": 25.47422981262207, "_runtime": 489.17444133758545, "_timestamp": 1585509567.595171, "_step": 361}
{"Episode reward": -99.8940369606004, "Episode length": 999, "Policy Loss": -0.8335539698600769, "Value Loss": 0.00818595103919506, "_runtime": 490.62103033065796, "_timestamp": 1585509569.04176, "_step": 362}
{"Episode reward": -99.83166809677938, "Episode length": 999, "Policy Loss": -0.8824036121368408, "Value Loss": 0.009101144969463348, "_runtime": 491.59071135520935, "_timestamp": 1585509570.011441, "_step": 363}
{"Episode reward": 33.69999999999949, "Episode length": 663, "Policy Loss": 0.45909687876701355, "Value Loss": 15.062849044799805, "_runtime": 493.0821671485901, "_timestamp": 1585509571.5028968, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9566267728805542, "Value Loss": 0.0106620779260993, "_runtime": 494.5916283130646, "_timestamp": 1585509573.012358, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9860128164291382, "Value Loss": 0.011273463256657124, "_runtime": 496.0776596069336, "_timestamp": 1585509574.4983892, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0117340087890625, "Value Loss": 0.011716583743691444, "_runtime": 496.55063366889954, "_timestamp": 1585509574.9713633, "_step": 367}
{"Episode reward": 71.19999999999987, "Episode length": 288, "Policy Loss": 2.015446662902832, "Value Loss": 34.658145904541016, "_runtime": 498.0918745994568, "_timestamp": 1585509576.5126042, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0392155647277832, "Value Loss": 0.012530511245131493, "_runtime": 499.60250997543335, "_timestamp": 1585509578.0232396, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.049533486366272, "Value Loss": 0.012886463664472103, "_runtime": 500.5057168006897, "_timestamp": 1585509578.9264464, "_step": 370}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.3753474950790405, "Value Loss": 16.183443069458008, "_runtime": 502.0167188644409, "_timestamp": 1585509580.4374485, "_step": 371}
{"Episode reward": -99.80002596378186, "Episode length": 999, "Policy Loss": -1.073501706123352, "Value Loss": 0.013289435766637325, "_runtime": 502.6293568611145, "_timestamp": 1585509581.0500865, "_step": 372}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 1.207552433013916, "Value Loss": 25.39983367919922, "_runtime": 503.6866464614868, "_timestamp": 1585509582.107376, "_step": 373}
{"Episode reward": 27.89999999999982, "Episode length": 721, "Policy Loss": 0.1331610381603241, "Value Loss": 13.850878715515137, "_runtime": 505.20290303230286, "_timestamp": 1585509583.6236327, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0900789499282837, "Value Loss": 0.01383570022881031, "_runtime": 505.8909978866577, "_timestamp": 1585509584.3117275, "_step": 375}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 0.8439114689826965, "Value Loss": 21.70174789428711, "_runtime": 506.73058342933655, "_timestamp": 1585509585.151313, "_step": 376}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 0.4519069194793701, "Value Loss": 17.828815460205078, "_runtime": 508.2334129810333, "_timestamp": 1585509586.6541426, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1109299659729004, "Value Loss": 0.01433352567255497, "_runtime": 509.707373380661, "_timestamp": 1585509588.128103, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1093640327453613, "Value Loss": 0.014402122236788273, "_runtime": 510.48177123069763, "_timestamp": 1585509588.9025009, "_step": 379}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 0.6602795720100403, "Value Loss": 19.460861206054688, "_runtime": 511.36169600486755, "_timestamp": 1585509589.7824256, "_step": 380}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 0.40099555253982544, "Value Loss": 17.394243240356445, "_runtime": 512.8770916461945, "_timestamp": 1585509591.2978213, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1065798997879028, "Value Loss": 0.014406553469598293, "_runtime": 513.6808423995972, "_timestamp": 1585509592.101572, "_step": 382}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": 0.5181800127029419, "Value Loss": 18.66119384765625, "_runtime": 514.608047246933, "_timestamp": 1585509593.028777, "_step": 383}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 0.49685153365135193, "Value Loss": 15.874534606933594, "_runtime": 516.1098885536194, "_timestamp": 1585509594.5306182, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1003363132476807, "Value Loss": 0.014404061250388622, "_runtime": 517.5908529758453, "_timestamp": 1585509596.0115826, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0920175313949585, "Value Loss": 0.014307340607047081, "_runtime": 519.0671780109406, "_timestamp": 1585509597.4879076, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0688881874084473, "Value Loss": 0.014069106429815292, "_runtime": 520.0222890377045, "_timestamp": 1585509598.4430187, "_step": 387}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": 0.32285717129707336, "Value Loss": 16.07906150817871, "_runtime": 521.5681302547455, "_timestamp": 1585509599.98886, "_step": 388}
{"Episode reward": -99.80262794494489, "Episode length": 999, "Policy Loss": -1.0502851009368896, "Value Loss": 0.01342746801674366, "_runtime": 523.082921743393, "_timestamp": 1585509601.5036514, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0377496480941772, "Value Loss": 0.013060430996119976, "_runtime": 524.5447280406952, "_timestamp": 1585509602.9654577, "_step": 390}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": -0.12742270529270172, "Value Loss": 10.152393341064453, "_runtime": 526.0739295482635, "_timestamp": 1585509604.4946592, "_step": 391}
{"Episode reward": -99.83571929931502, "Episode length": 999, "Policy Loss": -0.9960591793060303, "Value Loss": 0.01214306429028511, "_runtime": 527.2693908214569, "_timestamp": 1585509605.6901205, "_step": 392}
{"Episode reward": 21.60000000000018, "Episode length": 784, "Policy Loss": 0.13559675216674805, "Value Loss": 12.739225387573242, "_runtime": 528.8075425624847, "_timestamp": 1585509607.2282722, "_step": 393}
{"Episode reward": -99.82510998397926, "Episode length": 999, "Policy Loss": -0.9517340064048767, "Value Loss": 0.011204464361071587, "_runtime": 530.3420603275299, "_timestamp": 1585509608.76279, "_step": 394}
{"Episode reward": -99.81819139122823, "Episode length": 999, "Policy Loss": -0.9283992648124695, "Value Loss": 0.01070842519402504, "_runtime": 531.0967328548431, "_timestamp": 1585509609.5174625, "_step": 395}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 0.9602904915809631, "Value Loss": 20.672332763671875, "_runtime": 532.6331973075867, "_timestamp": 1585509611.053927, "_step": 396}
{"Episode reward": -99.83749170303204, "Episode length": 999, "Policy Loss": -0.8876467347145081, "Value Loss": 0.009790794923901558, "_runtime": 533.9615440368652, "_timestamp": 1585509612.3822737, "_step": 397}
{"Episode reward": 13.416939204931907, "Episode length": 866, "Policy Loss": 0.5626132488250732, "Value Loss": 11.534366607666016, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953, 0.0035869621206074953]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.003587936982512474, 0.004421648569405079, 0.012431234121322632, 0.02044081874191761, 0.028450405225157738, 0.036459989845752716, 0.044469572603702545, 0.05247916281223297, 0.0604887455701828, 0.06849832832813263, 0.07650791853666306, 0.08451750129461288, 0.09252708405256271, 0.10053667426109314, 0.10854625701904297, 0.1165558472275734, 0.12456542998552322, 0.13257502019405365, 0.14058460295200348, 0.1485942006111145, 0.15660378336906433, 0.16461336612701416, 0.172622948884964, 0.18063253164291382, 0.18864211440086365, 0.19665171205997467, 0.2046612948179245, 0.21267087757587433, 0.22068046033382416, 0.228690043091774, 0.236699640750885, 0.24470922350883484, 0.25271880626678467, 0.2607283890247345, 0.2687379717826843, 0.27674755454063416, 0.284757137298584, 0.2927667200565338, 0.30077633261680603, 0.30878591537475586, 0.3167954981327057, 0.3248050808906555, 0.33281466364860535, 0.3408242464065552, 0.348833829164505, 0.35684341192245483, 0.36485299468040466, 0.3728625774383545, 0.3808721601963043, 0.38888177275657654, 0.39689135551452637, 0.4049009382724762, 0.412910521030426, 0.42092010378837585, 0.4289296865463257, 0.4369392693042755, 0.44494885206222534, 0.45295843482017517, 0.460968017578125, 0.4689776301383972, 0.47698721289634705, 0.4849967956542969, 0.4930063784122467, 0.5010159015655518, 0.509025514125824]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.3421661151369335e-06, 0.0001820852339733392, 0.0003655126492958516, 0.0005489400355145335, 0.0007323674508370459, 0.0009157948661595583, 0.0010992222232744098, 0.001282649696804583, 0.0014660770539194345, 0.001649504411034286, 0.0018329318845644593, 0.002016359241679311, 0.0021997864823788404, 0.0023832139559090137, 0.002566641429439187, 0.0027500686701387167, 0.00293349614366889, 0.0031169236171990633, 0.003300350857898593, 0.0034837783314287663, 0.0036672058049589396, 0.003850633045658469, 0.00403406098484993, 0.0042174882255494595, 0.004400915466248989, 0.004584343172609806, 0.004767770413309336, 0.004951197654008865, 0.005134625360369682, 0.005318052601069212, 0.005501479841768742, 0.0056849075481295586, 0.005868334788829088, 0.006051762029528618, 0.006235189735889435, 0.0064186169765889645, 0.006602044217288494, 0.006785471923649311, 0.006968899164348841, 0.00715232640504837, 0.007335754111409187, 0.007519181352108717, 0.007702608592808247, 0.007886036299169064, 0.00806946400552988, 0.008252890780568123, 0.00843631848692894, 0.008619746193289757, 0.008803172968327999, 0.008986600674688816, 0.009170028381049633, 0.009353455156087875, 0.009536882862448692, 0.00972031056880951, 0.009903737343847752, 0.010087165050208569, 0.010270592756569386, 0.010454019531607628, 0.010637447237968445, 0.010820874944329262, 0.011004301719367504, 0.011187729425728321, 0.011371157132089138, 0.01155458390712738, 0.011738011613488197]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [17.0, 14.0, 14.0, 29.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 288.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 4.0, 5.0, 5.0, 12.0, 4.0, 9.0, 9.0, 5.0, 8.0, 7.0, 7.0, 8.0, 12.0, 1.0, 4.0, 7.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0], "bins": [-0.011614738963544369, -0.010709778405725956, -0.009804817847907543, -0.008899856358766556, -0.007994895800948143, -0.0070899357087910175, -0.0061849746853113174, -0.005280014127492905, -0.004375053569674492, -0.003470093011856079, -0.0025651324540376663, -0.0016601718962192535, -0.0007552104070782661, 0.00014975015074014664, 0.0010547107085585594, 0.001959671266376972, 0.002864631824195385, 0.0037695923820137978, 0.0046745529398322105, 0.005579513497650623, 0.006484474055469036, 0.007389434613287449, 0.008294395171105862, 0.009199355728924274, 0.010104318149387836, 0.01100927870720625, 0.011914239265024662, 0.012819199822843075, 0.013724160380661488, 0.0146291209384799, 0.015534081496298313, 0.0164390429854393, 0.017344001680612564, 0.018248964101076126, 0.01915392279624939, 0.02005888521671295, 0.020963843911886215, 0.021868806332349777, 0.02277376502752304, 0.023678727447986603, 0.024583686143159866, 0.02548864856362343, 0.026393607258796692, 0.027298569679260254, 0.028203528374433517, 0.02910849079489708, 0.030013449490070343, 0.030918411910533905, 0.03182337433099747, 0.03272833302617073, 0.03363329544663429, 0.034538254141807556, 0.03544321656227112, 0.03634817525744438, 0.037253137677907944, 0.03815809637308121, 0.03906305879354477, 0.03996801748871803, 0.040872979909181595, 0.04177793860435486, 0.04268290102481842, 0.043587859719991684, 0.044492822140455246, 0.04539778083562851, 0.04630274325609207]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.15475864708423615, -0.1492989957332611, -0.14383932948112488, -0.13837966322898865, -0.1329200118780136, -0.12746036052703857, -0.12200069427490234, -0.11654103547334671, -0.11108137667179108, -0.10562171787023544, -0.10016205906867981, -0.09470240026712418, -0.08924274146556854, -0.08378308266401291, -0.07832342386245728, -0.07286376506090164, -0.06740410625934601, -0.061944447457790375, -0.05648478865623474, -0.05102512985467911, -0.045565471053123474, -0.04010581225156784, -0.03464615345001221, -0.02918650209903717, -0.02372683584690094, -0.01826716959476471, -0.012807518243789673, -0.007347866892814636, -0.0018882006406784058, 0.0035714656114578247, 0.009031116962432861, 0.014490768313407898, 0.01995043456554413, 0.02541010081768036, 0.030869752168655396, 0.03632940351963043, 0.04178906977176666, 0.04724873602390289, 0.05270838737487793, 0.058168038725852966, 0.0636277049779892, 0.06908737123012543, 0.07454702258110046, 0.0800066739320755, 0.08546634018421173, 0.09092600643634796, 0.0963856428861618, 0.10184530913829803, 0.10730497539043427, 0.1127646416425705, 0.11822430789470673, 0.12368394434452057, 0.1291436105966568, 0.13460327684879303, 0.14006291329860687, 0.1455225795507431, 0.15098224580287933, 0.15644191205501556, 0.1619015783071518, 0.16736121475696564, 0.17282088100910187, 0.1782805472612381, 0.18374018371105194, 0.18919984996318817, 0.1946595162153244]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 5.0, 5.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.011230556294322014, -0.010918217711150646, -0.010605880059301853, -0.010293541476130486, -0.009981203824281693, -0.009668865241110325, -0.009356527589261532, -0.009044189006090164, -0.008731851354241371, -0.008419512771070004, -0.008107174187898636, -0.007794836536049843, -0.007482497952878475, -0.007170159835368395, -0.0068578217178583145, -0.006545483600348234, -0.006233145482838154, -0.0059208073653280735, -0.005608469247817993, -0.005296131130307913, -0.0049837930127978325, -0.004671454429626465, -0.0043591163121163845, -0.004046778194606304, -0.003734440077096224, -0.0034221019595861435, -0.003109763376414776, -0.002797425724565983, -0.002485087141394615, -0.002172749489545822, -0.0018604109063744545, -0.0015480732545256615, -0.0012357346713542938, -0.0009233960881829262, -0.0006110584363341331, -0.0002987198531627655, 1.3617798686027527e-05, 0.00032595638185739517, 0.0006382940337061882, 0.0009506326168775558, 0.0012629702687263489, 0.0015753088518977165, 0.0018876474350690842, 0.002199985086917877, 0.002512323670089245, 0.002824661321938038, 0.0031369999051094055, 0.0034493375569581985, 0.003761676140129566, 0.004074014723300934, 0.004386352375149727, 0.00469869002699852, 0.005011029541492462, 0.005323367193341255, 0.005635704845190048, 0.005948042497038841, 0.0062603820115327835, 0.0065727196633815765, 0.00688505731523037, 0.007197396829724312, 0.007509734481573105, 0.007822072133421898, 0.008134409785270691, 0.008446749299764633, 0.008759086951613426]}, "_runtime": 535.4459502696991, "_timestamp": 1585509613.86668, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8573018312454224, "Value Loss": 0.009008039720356464, "_runtime": 536.4425950050354, "_timestamp": 1585509614.8633246, "_step": 399}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.5741533041000366, "Value Loss": 15.507761001586914, "_runtime": 537.217390537262, "_timestamp": 1585509615.6381202, "_step": 400}
{"Episode reward": 50.39999999999957, "Episode length": 496, "Policy Loss": 0.9121476411819458, "Value Loss": 20.13283348083496, "_runtime": 538.7455947399139, "_timestamp": 1585509617.1663244, "_step": 401}
{"Episode reward": -99.81262712627509, "Episode length": 999, "Policy Loss": -0.8222110271453857, "Value Loss": 0.008121317252516747, "_runtime": 539.9638278484344, "_timestamp": 1585509618.3845575, "_step": 402}
{"Episode reward": 19.586065381765664, "Episode length": 805, "Policy Loss": 0.772666335105896, "Value Loss": 12.408166885375977, "_runtime": 541.4543035030365, "_timestamp": 1585509619.8750331, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8104807138442993, "Value Loss": 0.007727677468210459, "_runtime": 542.9805126190186, "_timestamp": 1585509621.4012423, "_step": 404}
{"Episode reward": -99.82628564834455, "Episode length": 999, "Policy Loss": -0.8013420104980469, "Value Loss": 0.007485401351004839, "_runtime": 544.5221996307373, "_timestamp": 1585509622.9429293, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.78663569688797, "Value Loss": 0.007204817607998848, "_runtime": 545.4395225048065, "_timestamp": 1585509623.8602521, "_step": 406}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 0.7443774938583374, "Value Loss": 16.59062385559082, "_runtime": 546.9776284694672, "_timestamp": 1585509625.398358, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7620454430580139, "Value Loss": 0.00665557524189353, "_runtime": 548.5269479751587, "_timestamp": 1585509626.9476776, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7497044205665588, "Value Loss": 0.006391029339283705, "_runtime": 549.9072470664978, "_timestamp": 1585509628.3279767, "_step": 409}
{"Episode reward": 8.300000000000935, "Episode length": 917, "Policy Loss": 0.2334931194782257, "Value Loss": 10.894181251525879, "_runtime": 551.4346933364868, "_timestamp": 1585509629.855423, "_step": 410}
{"Episode reward": -99.84484682679036, "Episode length": 999, "Policy Loss": -0.721223771572113, "Value Loss": 0.005844614468514919, "_runtime": 552.2779698371887, "_timestamp": 1585509630.6986995, "_step": 411}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 1.1886627674102783, "Value Loss": 18.326801300048828, "_runtime": 553.7851002216339, "_timestamp": 1585509632.2058299, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6951701641082764, "Value Loss": 0.005421883426606655, "_runtime": 555.3136744499207, "_timestamp": 1585509633.734404, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6820924878120422, "Value Loss": 0.005226730834692717, "_runtime": 556.8016591072083, "_timestamp": 1585509635.2223887, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6700498461723328, "Value Loss": 0.004998279735445976, "_runtime": 558.3334271907806, "_timestamp": 1585509636.7541568, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.653963029384613, "Value Loss": 0.004743678495287895, "_runtime": 559.8672571182251, "_timestamp": 1585509638.2879868, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6350653171539307, "Value Loss": 0.004469714593142271, "_runtime": 561.3958804607391, "_timestamp": 1585509639.81661, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6145549416542053, "Value Loss": 0.004182593431323767, "_runtime": 562.9234941005707, "_timestamp": 1585509641.3442237, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5944300293922424, "Value Loss": 0.0038879141211509705, "_runtime": 564.1345403194427, "_timestamp": 1585509642.55527, "_step": 419}
{"Episode reward": 20.885261052847127, "Episode length": 793, "Policy Loss": 0.6551803350448608, "Value Loss": 12.598831176757812, "_runtime": 565.3113737106323, "_timestamp": 1585509643.7321033, "_step": 420}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.7815113663673401, "Value Loss": 13.060053825378418, "_runtime": 565.9978771209717, "_timestamp": 1585509644.4186068, "_step": 421}
{"Episode reward": 56.79999999999966, "Episode length": 432, "Policy Loss": 1.6425584554672241, "Value Loss": 23.125045776367188, "_runtime": 567.5360085964203, "_timestamp": 1585509645.9567382, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5433971285820007, "Value Loss": 0.0032119436655193567, "_runtime": 568.1833529472351, "_timestamp": 1585509646.6040826, "_step": 423}
{"Episode reward": 58.7986833333966, "Episode length": 413, "Policy Loss": 1.8670283555984497, "Value Loss": 24.188987731933594, "_runtime": 569.6686654090881, "_timestamp": 1585509648.089395, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5450451970100403, "Value Loss": 0.003227092558518052, "_runtime": 571.2089321613312, "_timestamp": 1585509649.6296618, "_step": 425}
{"Episode reward": -99.82073183655599, "Episode length": 999, "Policy Loss": -0.5487236380577087, "Value Loss": 0.0032503327820450068, "_runtime": 571.9036641120911, "_timestamp": 1585509650.3243937, "_step": 426}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.4457207918167114, "Value Loss": 21.48411750793457, "_runtime": 572.5573885440826, "_timestamp": 1585509650.9781182, "_step": 427}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.6479471921920776, "Value Loss": 23.956457138061523, "_runtime": 573.9596943855286, "_timestamp": 1585509652.380424, "_step": 428}
{"Episode reward": 7.400000000000986, "Episode length": 926, "Policy Loss": 0.4131205081939697, "Value Loss": 10.789857864379883, "_runtime": 575.1995060443878, "_timestamp": 1585509653.6202357, "_step": 429}
{"Episode reward": 16.400000000000475, "Episode length": 836, "Policy Loss": 0.5063856840133667, "Value Loss": 11.950833320617676, "_runtime": 576.0519864559174, "_timestamp": 1585509654.472716, "_step": 430}
{"Episode reward": 42.69999999999946, "Episode length": 573, "Policy Loss": 0.9903832674026489, "Value Loss": 17.433956146240234, "_runtime": 577.561765909195, "_timestamp": 1585509655.9824955, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6312612295150757, "Value Loss": 0.004282696172595024, "_runtime": 579.0737426280975, "_timestamp": 1585509657.4944723, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6517303586006165, "Value Loss": 0.0045157973654568195, "_runtime": 580.2988831996918, "_timestamp": 1585509658.7196128, "_step": 433}
{"Episode reward": 18.300000000000367, "Episode length": 817, "Policy Loss": 0.47847047448158264, "Value Loss": 12.22784423828125, "_runtime": 581.1691768169403, "_timestamp": 1585509659.5899065, "_step": 434}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 0.9982811808586121, "Value Loss": 17.86898422241211, "_runtime": 581.7627873420715, "_timestamp": 1585509660.183517, "_step": 435}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 1.7676016092300415, "Value Loss": 26.848302841186523, "_runtime": 582.8428440093994, "_timestamp": 1585509661.2635736, "_step": 436}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.554755449295044, "Value Loss": 13.835359573364258, "_runtime": 584.335923910141, "_timestamp": 1585509662.7566535, "_step": 437}
{"Episode reward": -99.80392032265523, "Episode length": 999, "Policy Loss": -0.7432496547698975, "Value Loss": 0.005958526860922575, "_runtime": 585.0116546154022, "_timestamp": 1585509663.4323843, "_step": 438}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 1.310461401939392, "Value Loss": 22.35027503967285, "_runtime": 586.5071451663971, "_timestamp": 1585509664.9278748, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7852645516395569, "Value Loss": 0.006730105262249708, "_runtime": 588.0278956890106, "_timestamp": 1585509666.4486253, "_step": 440}
{"Episode reward": -99.85110015869, "Episode length": 999, "Policy Loss": -0.8050937056541443, "Value Loss": 0.007051791064441204, "_runtime": 589.5182847976685, "_timestamp": 1585509667.9390144, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.813262403011322, "Value Loss": 0.0072803795337677, "_runtime": 591.0823488235474, "_timestamp": 1585509669.5030785, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.81880784034729, "Value Loss": 0.007403107360005379, "_runtime": 591.6966054439545, "_timestamp": 1585509670.117335, "_step": 443}
{"Episode reward": 61.6193248689172, "Episode length": 384, "Policy Loss": 1.5277833938598633, "Value Loss": 26.004194259643555, "_runtime": 593.2199382781982, "_timestamp": 1585509671.640668, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8323692679405212, "Value Loss": 0.0076259043999016285, "_runtime": 594.7631998062134, "_timestamp": 1585509673.1839294, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8342377543449402, "Value Loss": 0.0077174752950668335, "_runtime": 595.3856239318848, "_timestamp": 1585509673.8063536, "_step": 446}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 1.3992042541503906, "Value Loss": 24.295879364013672, "_runtime": 596.9193172454834, "_timestamp": 1585509675.340047, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8420049548149109, "Value Loss": 0.00786440260708332, "_runtime": 598.4582147598267, "_timestamp": 1585509676.8789444, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.841121256351471, "Value Loss": 0.00791291892528534, "_runtime": 599.9521269798279, "_timestamp": 1585509678.3728566, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8441957235336304, "Value Loss": 0.007869774475693703, "_runtime": 601.4850208759308, "_timestamp": 1585509679.9057505, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8351426720619202, "Value Loss": 0.007744934409856796, "_runtime": 602.8461451530457, "_timestamp": 1585509681.2668748, "_step": 451}
{"Episode reward": 11.500000000000753, "Episode length": 885, "Policy Loss": 0.18994715809822083, "Value Loss": 11.28736400604248, "_runtime": 603.8183741569519, "_timestamp": 1585509682.2391038, "_step": 452}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.6597930192947388, "Value Loss": 15.70365047454834, "_runtime": 605.3493666648865, "_timestamp": 1585509683.7700963, "_step": 453}
{"Episode reward": -99.8447161257253, "Episode length": 999, "Policy Loss": -0.8102491497993469, "Value Loss": 0.007326845079660416, "_runtime": 606.4392375946045, "_timestamp": 1585509684.8599672, "_step": 454}
{"Episode reward": 29.399999999999736, "Episode length": 706, "Policy Loss": 0.46230655908584595, "Value Loss": 14.14745807647705, "_runtime": 606.6883409023285, "_timestamp": 1585509685.1090705, "_step": 455}
{"Episode reward": 86.20000000000005, "Episode length": 138, "Policy Loss": 5.657492160797119, "Value Loss": 72.34856414794922, "_runtime": 608.2048327922821, "_timestamp": 1585509686.6255624, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8258607387542725, "Value Loss": 0.0076460083946585655, "_runtime": 609.7149448394775, "_timestamp": 1585509688.1356745, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8447818756103516, "Value Loss": 0.008049274794757366, "_runtime": 611.1686053276062, "_timestamp": 1585509689.589335, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8583603501319885, "Value Loss": 0.00833385344594717, "_runtime": 612.7049541473389, "_timestamp": 1585509691.1256838, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8685860633850098, "Value Loss": 0.008504398167133331, "_runtime": 614.269941329956, "_timestamp": 1585509692.690671, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8666287064552307, "Value Loss": 0.008568177931010723, "_runtime": 615.7882149219513, "_timestamp": 1585509694.2089446, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8669366240501404, "Value Loss": 0.008534340187907219, "_runtime": 617.3270027637482, "_timestamp": 1585509695.7477324, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.857657790184021, "Value Loss": 0.0084132244810462, "_runtime": 617.840274810791, "_timestamp": 1585509696.2610044, "_step": 463}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 2.2200663089752197, "Value Loss": 32.207763671875, "_runtime": 618.9173204898834, "_timestamp": 1585509697.3380501, "_step": 464}
{"Episode reward": 29.243309688567862, "Episode length": 708, "Policy Loss": 0.4014394283294678, "Value Loss": 14.106856346130371, "_runtime": 620.4487066268921, "_timestamp": 1585509698.8694363, "_step": 465}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": 0.06316784769296646, "Value Loss": 10.020123481750488, "_runtime": 621.0584344863892, "_timestamp": 1585509699.4791641, "_step": 466}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 1.3504915237426758, "Value Loss": 24.59374237060547, "_runtime": 622.4382500648499, "_timestamp": 1585509700.8589797, "_step": 467}
{"Episode reward": 7.300000000000992, "Episode length": 927, "Policy Loss": 0.11506699025630951, "Value Loss": 10.776074409484863, "_runtime": 623.9740817546844, "_timestamp": 1585509702.3948114, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8806467056274414, "Value Loss": 0.008912312798202038, "_runtime": 625.4619388580322, "_timestamp": 1585509703.8826685, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8837962746620178, "Value Loss": 0.009025725536048412, "_runtime": 626.418999671936, "_timestamp": 1585509704.8397293, "_step": 470}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.6945669651031494, "Value Loss": 16.133405685424805, "_runtime": 627.9566552639008, "_timestamp": 1585509706.377385, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8874340653419495, "Value Loss": 0.009104907512664795, "_runtime": 628.8076865673065, "_timestamp": 1585509707.2284162, "_step": 472}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.7769283652305603, "Value Loss": 18.255773544311523, "_runtime": 630.3200385570526, "_timestamp": 1585509708.7407682, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.894043505191803, "Value Loss": 0.009135440923273563, "_runtime": 631.722891330719, "_timestamp": 1585509710.143621, "_step": 474}
{"Episode reward": 9.000000000000895, "Episode length": 910, "Policy Loss": 0.07514939457178116, "Value Loss": 10.977134704589844, "_runtime": 633.2238764762878, "_timestamp": 1585509711.644606, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8831375241279602, "Value Loss": 0.009070280939340591, "_runtime": 634.7518239021301, "_timestamp": 1585509713.1725535, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.876804530620575, "Value Loss": 0.00895245373249054, "_runtime": 635.6642589569092, "_timestamp": 1585509714.0849886, "_step": 477}
{"Episode reward": 41.09999999999944, "Episode length": 589, "Policy Loss": 0.6248229146003723, "Value Loss": 16.95491600036621, "_runtime": 637.0491812229156, "_timestamp": 1585509715.4699109, "_step": 478}
{"Episode reward": 12.100000000000719, "Episode length": 879, "Policy Loss": 0.12953020632266998, "Value Loss": 11.364056587219238, "_runtime": 638.5899341106415, "_timestamp": 1585509717.0106637, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8583347201347351, "Value Loss": 0.008576699532568455, "_runtime": 639.1189701557159, "_timestamp": 1585509717.5396998, "_step": 480}
{"Episode reward": 66.19999999999979, "Episode length": 338, "Policy Loss": 1.72041654586792, "Value Loss": 29.539949417114258, "_runtime": 640.2729067802429, "_timestamp": 1585509718.6936364, "_step": 481}
{"Episode reward": 23.200000000000088, "Episode length": 768, "Policy Loss": 0.2904984652996063, "Value Loss": 13.005340576171875, "_runtime": 641.378448009491, "_timestamp": 1585509719.7991776, "_step": 482}
{"Episode reward": 28.291373962163732, "Episode length": 718, "Policy Loss": 0.37055477499961853, "Value Loss": 13.910356521606445, "_runtime": 642.1411464214325, "_timestamp": 1585509720.561876, "_step": 483}
{"Episode reward": 48.89999999999955, "Episode length": 511, "Policy Loss": 0.8364148736000061, "Value Loss": 19.541667938232422, "_runtime": 643.633225440979, "_timestamp": 1585509722.053955, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8654787540435791, "Value Loss": 0.008930862881243229, "_runtime": 645.1310591697693, "_timestamp": 1585509723.5517888, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8679395914077759, "Value Loss": 0.00903722457587719, "_runtime": 646.3709652423859, "_timestamp": 1585509724.7916949, "_step": 486}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.1697288155555725, "Value Loss": 12.019834518432617, "_runtime": 647.8958783149719, "_timestamp": 1585509726.316608, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8643551468849182, "Value Loss": 0.009060291573405266, "_runtime": 649.4190576076508, "_timestamp": 1585509727.8397872, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8567434549331665, "Value Loss": 0.008984607644379139, "_runtime": 650.934079170227, "_timestamp": 1585509729.3548088, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8417710065841675, "Value Loss": 0.00882029626518488, "_runtime": 651.6352016925812, "_timestamp": 1585509730.0559313, "_step": 490}
{"Episode reward": 55.79999999999965, "Episode length": 442, "Policy Loss": 1.2904733419418335, "Value Loss": 22.59111785888672, "_runtime": 652.9273271560669, "_timestamp": 1585509731.3480568, "_step": 491}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.3054446280002594, "Value Loss": 11.821011543273926, "_runtime": 653.359934091568, "_timestamp": 1585509731.7806637, "_step": 492}
{"Episode reward": 74.29999999999991, "Episode length": 257, "Policy Loss": 2.5845417976379395, "Value Loss": 38.8474235534668, "_runtime": 654.8502886295319, "_timestamp": 1585509733.2710183, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8398508429527283, "Value Loss": 0.00870506651699543, "_runtime": 656.3767943382263, "_timestamp": 1585509734.797524, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8454779982566833, "Value Loss": 0.008842064067721367, "_runtime": 657.8520114421844, "_timestamp": 1585509736.272741, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8513883948326111, "Value Loss": 0.00887077022343874, "_runtime": 658.8550744056702, "_timestamp": 1585509737.275804, "_step": 496}
{"Episode reward": 34.09999999999947, "Episode length": 659, "Policy Loss": 0.44658806920051575, "Value Loss": 15.154837608337402, "_runtime": 660.4232547283173, "_timestamp": 1585509738.8439844, "_step": 497}
{"Episode reward": -99.80851169228414, "Episode length": 999, "Policy Loss": -0.8467420339584351, "Value Loss": 0.008788085542619228, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692, 0.05375545844435692]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.054112713783979416, 0.05776458606123924, 0.1696418821811676, 0.28151920437812805, 0.3933964967727661, 0.5052737593650818, 0.6171510815620422, 0.7290283441543579, 0.8409056663513184, 0.952782928943634, 1.0646603107452393, 1.1765376329421997, 1.2884149551391602, 1.4002922773361206, 1.5121694803237915, 1.624046802520752, 1.7359241247177124, 1.8478014469146729, 1.9596786499023438, 2.0715560913085938, 2.1834332942962646, 2.2953107357025146, 2.4071879386901855, 2.5190651416778564, 2.6309425830841064, 2.7428197860717773, 2.8546972274780273, 2.9665744304656982, 3.078451633453369, 3.190329074859619, 3.30220627784729, 3.41408371925354, 3.525960922241211, 3.637838125228882, 3.749715566635132, 3.8615927696228027, 3.9734699726104736, 4.0853471755981445, 4.1972246170043945, 4.309101581573486, 4.420979022979736, 4.532856464385986, 4.644733905792236, 4.756610870361328, 4.868488311767578, 4.980365753173828, 5.09224271774292, 5.20412015914917, 5.31599760055542, 5.427874565124512, 5.539752006530762, 5.651629447937012, 5.763506889343262, 5.8753838539123535, 5.9872612953186035, 6.0991387367248535, 6.211015701293945, 6.322893142700195, 6.434770584106445, 6.546647548675537, 6.658524990081787, 6.770402431488037, 6.882279872894287, 6.994156837463379, 7.106034278869629]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.3732460502069443e-05, 0.002665120642632246, 0.005343973636627197, 0.008022827096283436, 0.0107016796246171, 0.013380532152950764, 0.016059385612607002, 0.018738238140940666, 0.02141709066927433, 0.024095943197607994, 0.026774795725941658, 0.02945365011692047, 0.032132506370544434, 0.0348113588988781, 0.03749021142721176, 0.040169063955545425, 0.04284791648387909, 0.04552676901221275, 0.04820562154054642, 0.05088447406888008, 0.053563326597213745, 0.05624218285083771, 0.05892103537917137, 0.061599887907505035, 0.064278744161129, 0.06695759296417236, 0.06963644921779633, 0.07231529802083969, 0.07499415427446365, 0.07767300307750702, 0.08035185933113098, 0.08303070813417435, 0.08570956438779831, 0.08838842064142227, 0.09106726944446564, 0.0937461256980896, 0.09642497450113297, 0.09910383075475693, 0.10178267955780029, 0.10446153581142426, 0.10714038461446762, 0.10981924086809158, 0.11249809712171555, 0.11517694592475891, 0.11785580217838287, 0.12053465098142624, 0.1232135072350502, 0.12589235603809357, 0.12857121229171753, 0.1312500536441803, 0.13392890989780426, 0.13660776615142822, 0.13928662240505219, 0.14196546375751495, 0.14464432001113892, 0.14732317626476288, 0.15000203251838684, 0.1526808887720108, 0.15535973012447357, 0.15803858637809753, 0.1607174426317215, 0.16339629888534546, 0.16607514023780823, 0.1687539964914322, 0.17143285274505615]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [18.0, 16.0, 9.0, 26.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 288.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 5.0, 3.0, 5.0, 4.0, 3.0, 11.0, 4.0, 10.0, 8.0, 3.0, 13.0, 4.0, 5.0, 10.0, 5.0, 4.0, 4.0, 7.0, 3.0, 0.0, 5.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.17001385986804962, -0.15616652369499207, -0.14231917262077332, -0.12847183644771576, -0.1146245002746582, -0.10077716410160065, -0.0869298204779625, -0.07308247685432434, -0.059235140681266785, -0.04538780450820923, -0.03154046833515167, -0.017693117260932922, -0.003845781087875366, 0.01000155508518219, 0.02384890615940094, 0.037696242332458496, 0.05154357850551605, 0.06539091467857361, 0.07923825085163116, 0.09308560192584991, 0.10693292319774628, 0.12078027427196503, 0.13462762534618378, 0.14847494661808014, 0.1623222976922989, 0.17616964876651764, 0.190016970038414, 0.20386432111263275, 0.2177116721868515, 0.23155899345874786, 0.2454063445329666, 0.25925368070602417, 0.2731010317802429, 0.28694838285446167, 0.30079567432403564, 0.3146430253982544, 0.32849037647247314, 0.3423377275466919, 0.35618507862091064, 0.3700324296951294, 0.38387972116470337, 0.3977270722389221, 0.41157442331314087, 0.4254217743873596, 0.43926912546157837, 0.4531164765357971, 0.4669637680053711, 0.48081111907958984, 0.4946584701538086, 0.5085058212280273, 0.5223531723022461, 0.5362004637718201, 0.5500478148460388, 0.5638951659202576, 0.5777425169944763, 0.5915898680686951, 0.6054372191429138, 0.6192845106124878, 0.6331318616867065, 0.6469792127609253, 0.660826563835144, 0.6746739149093628, 0.6885212063789368, 0.7023685574531555, 0.7162159085273743]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-1.5925554037094116, -1.5245670080184937, -1.4565786123275757, -1.3885902166366577, -1.3206018209457397, -1.2526134252548218, -1.1846250295639038, -1.1166366338729858, -1.0486482381820679, -0.9806598424911499, -0.9126714468002319, -0.844683051109314, -0.776694655418396, -0.708706259727478, -0.6407178640365601, -0.5727294683456421, -0.5047410726547241, -0.43675267696380615, -0.3687642812728882, -0.3007758855819702, -0.23278748989105225, -0.16479909420013428, -0.09681069850921631, -0.02882230281829834, 0.03916609287261963, 0.1071544885635376, 0.17514288425445557, 0.24313127994537354, 0.3111196756362915, 0.3791080713272095, 0.44709646701812744, 0.5150848627090454, 0.5830732583999634, 0.6510616540908813, 0.7190500497817993, 0.7870384454727173, 0.8550268411636353, 0.9230152368545532, 0.9910036325454712, 1.0589920282363892, 1.1269804239273071, 1.194968819618225, 1.262957215309143, 1.330945611000061, 1.398934006690979, 1.466922402381897, 1.534910798072815, 1.602899193763733, 1.6708875894546509, 1.7388759851455688, 1.8068643808364868, 1.8748527765274048, 1.9428411722183228, 2.010829448699951, 2.078817844390869, 2.146806240081787, 2.214794635772705, 2.282783031463623, 2.350771427154541, 2.418759822845459, 2.486748218536377, 2.554736614227295, 2.622725009918213, 2.690713405609131, 2.758701801300049]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 18.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.8952882289886475, -0.8731889724731445, -0.8510896563529968, -0.8289903998374939, -0.806891143321991, -0.7847918272018433, -0.7626925706863403, -0.7405933141708374, -0.7184940576553345, -0.6963947415351868, -0.6742954850196838, -0.6521961688995361, -0.6300969123840332, -0.6079976558685303, -0.5858983993530273, -0.5637991428375244, -0.5416998267173767, -0.519600510597229, -0.49750128388404846, -0.47540199756622314, -0.4533027410507202, -0.4312034547328949, -0.4091041684150696, -0.38700491189956665, -0.36490559577941895, -0.342806339263916, -0.3207070827484131, -0.29860782623291016, -0.27650851011276245, -0.2544092535972595, -0.2323099970817566, -0.2102106809616089, -0.18811142444610596, -0.16601216793060303, -0.14391285181045532, -0.12181359529495239, -0.09971433877944946, -0.07761502265930176, -0.05551576614379883, -0.0334165096282959, -0.011317253112792969, 0.010782063007354736, 0.032881319522857666, 0.054980576038360596, 0.0770798921585083, 0.09917914867401123, 0.12127840518951416, 0.1433776617050171, 0.16547703742980957, 0.1875762939453125, 0.20967555046081543, 0.23177480697631836, 0.2538740634918213, 0.2759733200073242, 0.29807257652282715, 0.32017195224761963, 0.34227120876312256, 0.3643704652786255, 0.3864697217941284, 0.40856897830963135, 0.4306682348251343, 0.45276761054992676, 0.4748668670654297, 0.4969661235809326, 0.5190653800964355]}, "_runtime": 661.460024356842, "_timestamp": 1585509739.880754, "_step": 498}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.41536134481430054, "Value Loss": 14.81782054901123, "_runtime": 661.460024356842, "_timestamp": 1585509739.880754, "_step": 499}
