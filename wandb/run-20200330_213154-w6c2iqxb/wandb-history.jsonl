{"Episode reward": -51.76457707949836, "Episode length": 999, "Policy Loss": -0.05628226324915886, "Value Loss": 0.05836353823542595, "_runtime": 6562.996865272522, "_timestamp": 1585603932.6297348, "_step": 0}
{"Episode reward": 56.95464654413121, "Episode length": 458, "Policy Loss": -34.166908264160156, "Value Loss": 707.5256958007812, "_runtime": 6564.4467759132385, "_timestamp": 1585603934.0796454, "_step": 1}
{"Episode reward": 10.844870104887576, "Episode length": 975, "Policy Loss": -13.876842498779297, "Value Loss": 977.9143676757812, "_runtime": 6566.013178825378, "_timestamp": 1585603935.6460483, "_step": 2}
{"Episode reward": -84.78962758715213, "Episode length": 999, "Policy Loss": 6.213927745819092, "Value Loss": 2482.289306640625, "_runtime": 6567.535571813583, "_timestamp": 1585603937.1684413, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.231830596923828, "Value Loss": 248.08798217773438, "_runtime": 6569.067178964615, "_timestamp": 1585603938.7000484, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.253503799438477, "Value Loss": 46.96229934692383, "_runtime": 6570.636999845505, "_timestamp": 1585603940.2698693, "_step": 5}
{"Episode reward": -99.88227997396244, "Episode length": 999, "Policy Loss": -0.7102950215339661, "Value Loss": 0.7298886775970459, "_runtime": 6572.1795926094055, "_timestamp": 1585603941.812462, "_step": 6}
{"Episode reward": -97.09103340978209, "Episode length": 999, "Policy Loss": -0.24420170485973358, "Value Loss": 4.6473565101623535, "_runtime": 6572.9559762477875, "_timestamp": 1585603942.5888457, "_step": 7}
{"Episode reward": 60.44028477789639, "Episode length": 493, "Policy Loss": 2.4394760131835938, "Value Loss": 125.93627166748047, "_runtime": 6574.300395488739, "_timestamp": 1585603943.933265, "_step": 8}
{"Episode reward": 20.511091322586154, "Episode length": 858, "Policy Loss": 0.5764756798744202, "Value Loss": 34.85104751586914, "_runtime": 6575.873660802841, "_timestamp": 1585603945.5065303, "_step": 9}
{"Episode reward": -96.74000588445168, "Episode length": 999, "Policy Loss": -0.024829888716340065, "Value Loss": 8.577994346618652, "_runtime": 6577.385798692703, "_timestamp": 1585603947.0186682, "_step": 10}
{"Episode reward": -96.62832229388619, "Episode length": 999, "Policy Loss": -0.16710035502910614, "Value Loss": 24.14539337158203, "_runtime": 6578.949326276779, "_timestamp": 1585603948.5821958, "_step": 11}
{"Episode reward": -97.11162870593957, "Episode length": 999, "Policy Loss": 0.2703437805175781, "Value Loss": 2.984327793121338, "_runtime": 6580.530822515488, "_timestamp": 1585603950.163692, "_step": 12}
{"Episode reward": -97.58212092066428, "Episode length": 999, "Policy Loss": 0.5162155628204346, "Value Loss": 97.35379791259766, "_runtime": 6581.162718057632, "_timestamp": 1585603950.7955875, "_step": 13}
{"Episode reward": 65.401377615444, "Episode length": 357, "Policy Loss": 10.16804313659668, "Value Loss": 306.9976806640625, "_runtime": 6582.473137378693, "_timestamp": 1585603952.1060069, "_step": 14}
{"Episode reward": 18.751426974883998, "Episode length": 835, "Policy Loss": 1.3793911933898926, "Value Loss": 14.368454933166504, "_runtime": 6584.05309510231, "_timestamp": 1585603953.6859646, "_step": 15}
{"Episode reward": -99.04011210471046, "Episode length": 999, "Policy Loss": 0.4684506952762604, "Value Loss": 0.5805790424346924, "_runtime": 6585.571127653122, "_timestamp": 1585603955.2039971, "_step": 16}
{"Episode reward": -99.11692554064949, "Episode length": 999, "Policy Loss": 0.5488157272338867, "Value Loss": 1.20381760597229, "_runtime": 6587.136093854904, "_timestamp": 1585603956.7689633, "_step": 17}
{"Episode reward": -98.25325686044704, "Episode length": 999, "Policy Loss": 0.5930814743041992, "Value Loss": 0.9506670832633972, "_runtime": 6588.710876703262, "_timestamp": 1585603958.3437462, "_step": 18}
{"Episode reward": -99.10251395417482, "Episode length": 999, "Policy Loss": 0.6193327903747559, "Value Loss": 0.22389547526836395, "_runtime": 6590.265946865082, "_timestamp": 1585603959.8988163, "_step": 19}
{"Episode reward": -98.84243165740712, "Episode length": 999, "Policy Loss": 0.6656715273857117, "Value Loss": 0.15422117710113525, "_runtime": 6591.859032869339, "_timestamp": 1585603961.4919024, "_step": 20}
{"Episode reward": -98.94378102661052, "Episode length": 999, "Policy Loss": 0.6611325144767761, "Value Loss": 1.5291913747787476, "_runtime": 6593.4350962638855, "_timestamp": 1585603963.0679657, "_step": 21}
{"Episode reward": -98.96617902153386, "Episode length": 999, "Policy Loss": 0.6841599345207214, "Value Loss": 1.7883586883544922, "_runtime": 6595.001811742783, "_timestamp": 1585603964.6346812, "_step": 22}
{"Episode reward": -98.25367706919833, "Episode length": 999, "Policy Loss": 0.38476666808128357, "Value Loss": 1.0392513275146484, "_runtime": 6596.596493244171, "_timestamp": 1585603966.2293627, "_step": 23}
{"Episode reward": -99.31700665453225, "Episode length": 999, "Policy Loss": 0.6761157512664795, "Value Loss": 0.04506107419729233, "_runtime": 6598.18602848053, "_timestamp": 1585603967.818898, "_step": 24}
{"Episode reward": -99.37967678523282, "Episode length": 999, "Policy Loss": 0.6722808480262756, "Value Loss": 1.6893024444580078, "_runtime": 6599.767557382584, "_timestamp": 1585603969.4004269, "_step": 25}
{"Episode reward": -99.18600767853505, "Episode length": 999, "Policy Loss": 0.6715577244758606, "Value Loss": 0.8435875773429871, "_runtime": 6601.3581211566925, "_timestamp": 1585603970.9909906, "_step": 26}
{"Episode reward": -97.95141912052705, "Episode length": 999, "Policy Loss": 1.1784473657608032, "Value Loss": 1.598389983177185, "_runtime": 6602.25830578804, "_timestamp": 1585603971.8911753, "_step": 27}
{"Episode reward": 45.30908925192747, "Episode length": 551, "Policy Loss": 1.6880593299865723, "Value Loss": 18.15247917175293, "_runtime": 6603.834792137146, "_timestamp": 1585603973.4676616, "_step": 28}
{"Episode reward": -99.31922778499148, "Episode length": 999, "Policy Loss": 0.8547051548957825, "Value Loss": 2.0376124382019043, "_runtime": 6604.841989994049, "_timestamp": 1585603974.4748595, "_step": 29}
{"Episode reward": 39.85960018075508, "Episode length": 608, "Policy Loss": 1.8046631813049316, "Value Loss": 18.60146141052246, "_runtime": 6606.397794485092, "_timestamp": 1585603976.030664, "_step": 30}
{"Episode reward": -99.22094430287406, "Episode length": 999, "Policy Loss": 0.7665470838546753, "Value Loss": 0.2504047453403473, "_runtime": 6607.977553606033, "_timestamp": 1585603977.610423, "_step": 31}
{"Episode reward": -99.31364841468177, "Episode length": 999, "Policy Loss": 0.5636182427406311, "Value Loss": 0.23734258115291595, "_runtime": 6608.952878713608, "_timestamp": 1585603978.5857482, "_step": 32}
{"Episode reward": 38.259362315903985, "Episode length": 621, "Policy Loss": 1.4675097465515137, "Value Loss": 17.285236358642578, "_runtime": 6610.514636516571, "_timestamp": 1585603980.147506, "_step": 33}
{"Episode reward": -99.44632925171618, "Episode length": 999, "Policy Loss": 0.45856350660324097, "Value Loss": 1.2567346096038818, "_runtime": 6612.094655990601, "_timestamp": 1585603981.7275255, "_step": 34}
{"Episode reward": -99.19933071702698, "Episode length": 999, "Policy Loss": 0.626952588558197, "Value Loss": 0.03149033337831497, "_runtime": 6612.65979385376, "_timestamp": 1585603982.2926633, "_step": 35}
{"Episode reward": 65.214137513167, "Episode length": 348, "Policy Loss": 2.429996967315674, "Value Loss": 28.65723991394043, "_runtime": 6614.2360227108, "_timestamp": 1585603983.8688922, "_step": 36}
{"Episode reward": -99.51701415178256, "Episode length": 999, "Policy Loss": 0.8004493117332458, "Value Loss": 0.6318795680999756, "_runtime": 6615.808975696564, "_timestamp": 1585603985.4418452, "_step": 37}
{"Episode reward": -99.71513534318517, "Episode length": 999, "Policy Loss": 0.841232419013977, "Value Loss": 0.9907558560371399, "_runtime": 6617.224881410599, "_timestamp": 1585603986.857751, "_step": 38}
{"Episode reward": 6.608747476558648, "Episode length": 939, "Policy Loss": 1.2574033737182617, "Value Loss": 10.591317176818848, "_runtime": 6618.815824270248, "_timestamp": 1585603988.4486938, "_step": 39}
{"Episode reward": -99.54725474171435, "Episode length": 999, "Policy Loss": 0.5512166023254395, "Value Loss": 0.0630185678601265, "_runtime": 6619.226847648621, "_timestamp": 1585603988.8597171, "_step": 40}
{"Episode reward": 77.49459002468353, "Episode length": 226, "Policy Loss": 3.061018228530884, "Value Loss": 45.717613220214844, "_runtime": 6620.019009113312, "_timestamp": 1585603989.6518786, "_step": 41}
{"Episode reward": 49.978201824206124, "Episode length": 502, "Policy Loss": 1.833265781402588, "Value Loss": 19.929813385009766, "_runtime": 6621.604462623596, "_timestamp": 1585603991.237332, "_step": 42}
{"Episode reward": -99.83290098405419, "Episode length": 999, "Policy Loss": 0.6289633512496948, "Value Loss": 0.20454221963882446, "_runtime": 6622.420171737671, "_timestamp": 1585603992.0530412, "_step": 43}
{"Episode reward": 46.17123150649519, "Episode length": 540, "Policy Loss": 2.0861990451812744, "Value Loss": 19.099510192871094, "_runtime": 6623.272164821625, "_timestamp": 1585603992.9050343, "_step": 44}
{"Episode reward": 44.980345056968005, "Episode length": 552, "Policy Loss": 2.2728657722473145, "Value Loss": 19.396007537841797, "_runtime": 6624.834391117096, "_timestamp": 1585603994.4672606, "_step": 45}
{"Episode reward": -99.7253857045886, "Episode length": 999, "Policy Loss": 0.5392864942550659, "Value Loss": 0.050426993519067764, "_runtime": 6626.353839874268, "_timestamp": 1585603995.9867094, "_step": 46}
{"Episode reward": -99.64249555609283, "Episode length": 999, "Policy Loss": 0.3953191339969635, "Value Loss": 0.1978965699672699, "_runtime": 6627.416853189468, "_timestamp": 1585603997.0497227, "_step": 47}
{"Episode reward": 31.240471213819546, "Episode length": 689, "Policy Loss": 1.51432204246521, "Value Loss": 15.9815673828125, "_runtime": 6628.698818445206, "_timestamp": 1585603998.331688, "_step": 48}
{"Episode reward": 19.01827737746676, "Episode length": 812, "Policy Loss": 0.9360315203666687, "Value Loss": 13.7319974899292, "_runtime": 6630.293700933456, "_timestamp": 1585603999.9265704, "_step": 49}
{"Episode reward": -99.6892487194841, "Episode length": 999, "Policy Loss": 0.40945592522621155, "Value Loss": 0.01814878359436989, "_runtime": 6631.826320886612, "_timestamp": 1585604001.4591904, "_step": 50}
{"Episode reward": -99.48279600980466, "Episode length": 999, "Policy Loss": 0.5148053765296936, "Value Loss": 0.12149912863969803, "_runtime": 6633.387067079544, "_timestamp": 1585604003.0199366, "_step": 51}
{"Episode reward": -99.50351966502939, "Episode length": 999, "Policy Loss": 0.5477585196495056, "Value Loss": 0.41837215423583984, "_runtime": 6634.035009860992, "_timestamp": 1585604003.6678793, "_step": 52}
{"Episode reward": 60.942478899190334, "Episode length": 391, "Policy Loss": 2.3303937911987305, "Value Loss": 25.691001892089844, "_runtime": 6635.595970153809, "_timestamp": 1585604005.2288396, "_step": 53}
{"Episode reward": -99.48538946437628, "Episode length": 999, "Policy Loss": 0.3865576982498169, "Value Loss": 0.07559604942798615, "_runtime": 6636.840853691101, "_timestamp": 1585604006.4737232, "_step": 54}
{"Episode reward": 21.558654505647596, "Episode length": 786, "Policy Loss": 1.1406561136245728, "Value Loss": 12.601998329162598, "_runtime": 6638.36031794548, "_timestamp": 1585604007.9931874, "_step": 55}
{"Episode reward": -99.75199874910038, "Episode length": 999, "Policy Loss": 0.339260458946228, "Value Loss": 0.026855990290641785, "_runtime": 6639.928305149078, "_timestamp": 1585604009.5611746, "_step": 56}
{"Episode reward": -99.61632078700211, "Episode length": 999, "Policy Loss": 0.3600497245788574, "Value Loss": 0.03757243975996971, "_runtime": 6641.152538537979, "_timestamp": 1585604010.785408, "_step": 57}
{"Episode reward": 23.113885792950256, "Episode length": 773, "Policy Loss": 1.0516648292541504, "Value Loss": 12.925212860107422, "_runtime": 6642.664905309677, "_timestamp": 1585604012.2977748, "_step": 58}
{"Episode reward": 2.1000000000012875, "Episode length": 979, "Policy Loss": 0.8596094250679016, "Value Loss": 10.237264633178711, "_runtime": 6644.247471809387, "_timestamp": 1585604013.8803413, "_step": 59}
{"Episode reward": -99.56653197340682, "Episode length": 999, "Policy Loss": 0.23599039018154144, "Value Loss": 0.003392332000657916, "_runtime": 6645.809791088104, "_timestamp": 1585604015.4426606, "_step": 60}
{"Episode reward": -99.46321729792552, "Episode length": 999, "Policy Loss": 0.21546877920627594, "Value Loss": 0.0033749935682862997, "_runtime": 6647.385960102081, "_timestamp": 1585604017.0188296, "_step": 61}
{"Episode reward": -99.64450829733839, "Episode length": 999, "Policy Loss": 0.21203121542930603, "Value Loss": 0.0017220353474840522, "_runtime": 6648.962157249451, "_timestamp": 1585604018.5950267, "_step": 62}
{"Episode reward": -99.85169619547528, "Episode length": 999, "Policy Loss": 0.2002132385969162, "Value Loss": 0.0012793340720236301, "_runtime": 6650.112837791443, "_timestamp": 1585604019.7457073, "_step": 63}
{"Episode reward": 28.175048423184293, "Episode length": 719, "Policy Loss": 1.0109310150146484, "Value Loss": 13.934524536132812, "_runtime": 6651.293286323547, "_timestamp": 1585604020.9261558, "_step": 64}
{"Episode reward": 25.310082951931662, "Episode length": 747, "Policy Loss": 0.9735469222068787, "Value Loss": 13.384621620178223, "_runtime": 6652.911379814148, "_timestamp": 1585604022.5442493, "_step": 65}
{"Episode reward": -99.41847788427704, "Episode length": 999, "Policy Loss": 0.16354265809059143, "Value Loss": 0.0009756879881024361, "_runtime": 6653.311533212662, "_timestamp": 1585604022.9444027, "_step": 66}
{"Episode reward": 76.39999999999995, "Episode length": 236, "Policy Loss": 2.895995855331421, "Value Loss": 42.06449890136719, "_runtime": 6654.871646642685, "_timestamp": 1585604024.5045161, "_step": 67}
{"Episode reward": -99.55917953639882, "Episode length": 999, "Policy Loss": 0.20506305992603302, "Value Loss": 0.06533592939376831, "_runtime": 6655.53600358963, "_timestamp": 1585604025.168873, "_step": 68}
{"Episode reward": 60.03347477698051, "Episode length": 400, "Policy Loss": 1.6606465578079224, "Value Loss": 24.724964141845703, "_runtime": 6657.053795576096, "_timestamp": 1585604026.686665, "_step": 69}
{"Episode reward": -99.71282307051449, "Episode length": 999, "Policy Loss": 0.12675748765468597, "Value Loss": 0.07831188291311264, "_runtime": 6658.643543481827, "_timestamp": 1585604028.276413, "_step": 70}
{"Episode reward": -99.65154769640655, "Episode length": 999, "Policy Loss": 0.10461747646331787, "Value Loss": 0.047686122357845306, "_runtime": 6659.7025628089905, "_timestamp": 1585604029.3354323, "_step": 71}
{"Episode reward": 29.977293223373707, "Episode length": 703, "Policy Loss": 1.1486161947250366, "Value Loss": 14.272741317749023, "_runtime": 6661.026907682419, "_timestamp": 1585604030.6597772, "_step": 72}
{"Episode reward": 15.546479800151957, "Episode length": 845, "Policy Loss": 0.8665037751197815, "Value Loss": 11.968914985656738, "_runtime": 6662.612750053406, "_timestamp": 1585604032.2456195, "_step": 73}
{"Episode reward": -99.76171087208101, "Episode length": 999, "Policy Loss": 0.08064540475606918, "Value Loss": 0.10975513607263565, "_runtime": 6664.1442630290985, "_timestamp": 1585604033.7771325, "_step": 74}
{"Episode reward": -99.37673877285427, "Episode length": 999, "Policy Loss": 0.021035388112068176, "Value Loss": 0.013864453881978989, "_runtime": 6665.697561264038, "_timestamp": 1585604035.3304307, "_step": 75}
{"Episode reward": -99.46777089516883, "Episode length": 999, "Policy Loss": 0.05896393582224846, "Value Loss": 0.07634986191987991, "_runtime": 6667.265962839127, "_timestamp": 1585604036.8988323, "_step": 76}
{"Episode reward": -99.81733992481465, "Episode length": 999, "Policy Loss": -0.014814399182796478, "Value Loss": 1.2261906704225112e-05, "_runtime": 6668.834062576294, "_timestamp": 1585604038.466932, "_step": 77}
{"Episode reward": -99.67723867454195, "Episode length": 999, "Policy Loss": -0.024022677913308144, "Value Loss": 0.00010347275383537635, "_runtime": 6670.399973630905, "_timestamp": 1585604040.032843, "_step": 78}
{"Episode reward": -99.6414095642686, "Episode length": 999, "Policy Loss": -0.02348596788942814, "Value Loss": 0.0044748857617378235, "_runtime": 6671.973964214325, "_timestamp": 1585604041.6068337, "_step": 79}
{"Episode reward": -99.52244805432281, "Episode length": 999, "Policy Loss": -0.035652823746204376, "Value Loss": 0.002405594103038311, "_runtime": 6672.908181428909, "_timestamp": 1585604042.541051, "_step": 80}
{"Episode reward": 42.07441825204823, "Episode length": 581, "Policy Loss": 1.3526743650436401, "Value Loss": 17.165908813476562, "_runtime": 6674.478974580765, "_timestamp": 1585604044.111844, "_step": 81}
{"Episode reward": -99.49235037468033, "Episode length": 999, "Policy Loss": -0.05438044294714928, "Value Loss": 0.001260633347555995, "_runtime": 6675.544571638107, "_timestamp": 1585604045.1774411, "_step": 82}
{"Episode reward": 32.582634098395204, "Episode length": 676, "Policy Loss": 0.8864299058914185, "Value Loss": 14.733650207519531, "_runtime": 6676.470597982407, "_timestamp": 1585604046.1034675, "_step": 83}
{"Episode reward": 43.23792363998311, "Episode length": 570, "Policy Loss": 1.2330033779144287, "Value Loss": 17.445995330810547, "_runtime": 6678.032654285431, "_timestamp": 1585604047.6655238, "_step": 84}
{"Episode reward": -99.51015488047713, "Episode length": 999, "Policy Loss": -0.08686497807502747, "Value Loss": 0.0002251414261991158, "_runtime": 6678.842674732208, "_timestamp": 1585604048.4755442, "_step": 85}
{"Episode reward": 49.33170714321269, "Episode length": 510, "Policy Loss": 1.0574878454208374, "Value Loss": 19.568960189819336, "_runtime": 6679.74568939209, "_timestamp": 1585604049.3785589, "_step": 86}
{"Episode reward": 42.12090907114125, "Episode length": 581, "Policy Loss": 0.9056899547576904, "Value Loss": 17.16975212097168, "_runtime": 6681.266008138657, "_timestamp": 1585604050.8988776, "_step": 87}
{"Episode reward": 2.5072851404312075, "Episode length": 977, "Policy Loss": 0.5041524171829224, "Value Loss": 10.218073844909668, "_runtime": 6682.655982971191, "_timestamp": 1585604052.2888525, "_step": 88}
{"Episode reward": 9.506027144971227, "Episode length": 909, "Policy Loss": 0.5373247861862183, "Value Loss": 10.901810646057129, "_runtime": 6684.179770231247, "_timestamp": 1585604053.8126397, "_step": 89}
{"Episode reward": -99.76257060461073, "Episode length": 999, "Policy Loss": -0.14790600538253784, "Value Loss": 0.000546974886674434, "_runtime": 6685.737109899521, "_timestamp": 1585604055.3699794, "_step": 90}
{"Episode reward": -99.7104639390295, "Episode length": 999, "Policy Loss": -0.1591254472732544, "Value Loss": 0.0006337760132737458, "_runtime": 6686.493327140808, "_timestamp": 1585604056.1261966, "_step": 91}
{"Episode reward": 53.53657584500832, "Episode length": 467, "Policy Loss": 1.69319748878479, "Value Loss": 21.192052841186523, "_runtime": 6687.1061453819275, "_timestamp": 1585604056.7390149, "_step": 92}
{"Episode reward": 62.91563256380589, "Episode length": 372, "Policy Loss": 1.4279944896697998, "Value Loss": 26.659053802490234, "_runtime": 6688.657548904419, "_timestamp": 1585604058.2904184, "_step": 93}
{"Episode reward": -99.61653909399035, "Episode length": 999, "Policy Loss": -0.19245187938213348, "Value Loss": 0.0009413048974238336, "_runtime": 6690.179677248001, "_timestamp": 1585604059.8125467, "_step": 94}
{"Episode reward": -99.74430180508504, "Episode length": 999, "Policy Loss": -0.20633764564990997, "Value Loss": 0.001064683892764151, "_runtime": 6691.675576686859, "_timestamp": 1585604061.3084462, "_step": 95}
{"Episode reward": -99.55883179014062, "Episode length": 999, "Policy Loss": -0.2149415761232376, "Value Loss": 0.001180727151222527, "_runtime": 6693.241685628891, "_timestamp": 1585604062.874555, "_step": 96}
{"Episode reward": -99.81461776420916, "Episode length": 999, "Policy Loss": -0.22026890516281128, "Value Loss": 0.006260804366320372, "_runtime": 6694.119957685471, "_timestamp": 1585604063.7528272, "_step": 97}
{"Episode reward": 45.19029855355571, "Episode length": 549, "Policy Loss": 0.8556904792785645, "Value Loss": 18.02583122253418, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845, -1.7025638818740845]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-66.21265411376953, -65.1514663696289, -64.09028625488281, -63.02909851074219, -61.96791458129883, -60.90673065185547, -59.84554672241211, -58.78436279296875, -57.723175048828125, -56.661991119384766, -55.600807189941406, -54.53961944580078, -53.47843933105469, -52.41725158691406, -51.3560676574707, -50.294883728027344, -49.23369598388672, -48.172515869140625, -47.111328125, -46.05014419555664, -44.98896026611328, -43.927772521972656, -42.8665885925293, -41.80540466308594, -40.74422073364258, -39.68303680419922, -38.621849060058594, -37.560665130615234, -36.499481201171875, -35.43829345703125, -34.377113342285156, -33.31592559814453, -32.25474166870117, -31.193557739257812, -30.132373809814453, -29.071186065673828, -28.01000213623047, -26.94881820678711, -25.88763427734375, -24.826446533203125, -23.765262603759766, -22.704078674316406, -21.642894744873047, -20.581710815429688, -19.520523071289062, -18.459339141845703, -17.398155212402344, -16.336971282958984, -15.275787353515625, -14.214599609375, -13.15341567993164, -12.092231750488281, -11.031047821044922, -9.969860076904297, -8.908676147460938, -7.847492218017578, -6.786308288574219, -5.725124359130859, -4.663936614990234, -3.602752685546875, -2.5415687561035156, -1.4803848266601562, -0.41919708251953125, 0.6419830322265625, 1.7031707763671875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.010582685470581, -2.8897502422332764, -2.7689175605773926, -2.648085117340088, -2.527252435684204, -2.4064199924468994, -2.2855873107910156, -2.164754867553711, -2.0439224243164062, -1.9230897426605225, -1.8022571802139282, -1.681424617767334, -1.5605921745300293, -1.439759612083435, -1.3189270496368408, -1.1980944871902466, -1.0772619247436523, -0.9564294815063477, -0.8355967998504639, -0.7147643566131592, -0.5939316749572754, -0.4730992317199707, -0.3522665500640869, -0.23143410682678223, -0.11060166358947754, 0.01023101806640625, 0.13106346130371094, 0.2518961429595947, 0.3727285861968994, 0.4935612678527832, 0.6143937110900879, 0.7352263927459717, 0.8560588359832764, 0.976891279220581, 1.0977237224578857, 1.2185566425323486, 1.3393890857696533, 1.460221529006958, 1.5810539722442627, 1.7018868923187256, 1.8227193355560303, 1.943551778793335, 2.0643842220306396, 2.1852166652679443, 2.3060495853424072, 2.426882028579712, 2.5477144718170166, 2.6685469150543213, 2.789379358291626, 2.910212278366089, 3.0310447216033936, 3.1518771648406982, 3.272709608078003, 3.393542528152466, 3.5143749713897705, 3.635207414627075, 3.75603985786438, 3.8768723011016846, 3.9977052211761475, 4.118537902832031, 4.239370346069336, 4.360202789306641, 4.481035232543945, 4.60186767578125, 4.722700119018555]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 3.0, 2.0, 2.0, 6.0, 3.0, 11.0, 1.0, 11.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 11.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 2.0, 32.0, 58.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-14.49787712097168, -13.915990829467773, -13.334105491638184, -12.752219200134277, -12.170333862304688, -11.588447570800781, -11.006561279296875, -10.424675941467285, -9.842790603637695, -9.260904312133789, -8.679018020629883, -8.097132682800293, -7.515246391296387, -6.933360576629639, -6.351474761962891, -5.769589424133301, -5.1877031326293945, -4.605816841125488, -4.023931503295898, -3.442045211791992, -2.8601598739624023, -2.278273582458496, -1.6963882446289062, -1.114501953125, -0.5326156616210938, 0.049269676208496094, 0.6311559677124023, 1.2130413055419922, 1.7949275970458984, 2.3768138885498047, 2.958698272705078, 3.5405845642089844, 4.122470855712891, 4.704357147216797, 5.286243438720703, 5.868127822875977, 6.450014114379883, 7.031900405883789, 7.613786697387695, 8.195671081542969, 8.777557373046875, 9.359443664550781, 9.941329956054688, 10.523216247558594, 11.105100631713867, 11.686986923217773, 12.26887321472168, 12.850759506225586, 13.432645797729492, 14.014530181884766, 14.596416473388672, 15.178302764892578, 15.760189056396484, 16.342073440551758, 16.923959732055664, 17.50584602355957, 18.087732315063477, 18.669618606567383, 19.25150489807129, 19.833391189575195, 20.415273666381836, 20.997159957885742, 21.57904624938965, 22.160932540893555, 22.74281883239746]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 6.0, 11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-30.153491973876953, -29.266483306884766, -28.379474639892578, -27.49246597290039, -26.60545539855957, -25.718446731567383, -24.831438064575195, -23.944429397583008, -23.057418823242188, -22.17041015625, -21.283401489257812, -20.396392822265625, -19.509384155273438, -18.62237548828125, -17.735366821289062, -16.848356246948242, -15.961347579956055, -15.074338912963867, -14.187329292297363, -13.30031967163086, -12.413311004638672, -11.526302337646484, -10.639293670654297, -9.75228500366211, -8.865276336669922, -7.978265762329102, -7.091257095336914, -6.204248428344727, -5.317239761352539, -4.430231094360352, -3.5432205200195312, -2.6562118530273438, -1.7692031860351562, -0.8821945190429688, 0.00481414794921875, 0.8918247222900391, 1.7788333892822266, 2.6658401489257812, 3.5528526306152344, 4.439861297607422, 5.326869964599609, 6.213878631591797, 7.100887298583984, 7.987895965576172, 8.87490463256836, 9.761913299560547, 10.648921966552734, 11.535930633544922, 12.42293930053711, 13.309951782226562, 14.19696044921875, 15.083969116210938, 15.970977783203125, 16.857986450195312, 17.7449951171875, 18.632003784179688, 19.519012451171875, 20.406021118164062, 21.29302978515625, 22.180042266845703, 23.06705093383789, 23.954059600830078, 24.841068267822266, 25.728076934814453, 26.61508560180664]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 34.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-14.653985023498535, -14.162410736083984, -13.670836448669434, -13.179262161254883, -12.687687873840332, -12.196113586425781, -11.704540252685547, -11.21296501159668, -10.721391677856445, -10.229816436767578, -9.738243103027344, -9.246667861938477, -8.755094528198242, -8.263520240783691, -7.771945953369141, -7.28037166595459, -6.788797378540039, -6.297223091125488, -5.8056488037109375, -5.314074516296387, -4.822500228881836, -4.330925941467285, -3.8393516540527344, -3.3477773666381836, -2.856204032897949, -2.3646297454833984, -1.8730554580688477, -1.3814811706542969, -0.8899068832397461, -0.3983325958251953, 0.09324169158935547, 0.5848159790039062, 1.076390266418457, 1.5679636001586914, 2.0595388412475586, 2.551112174987793, 3.04268741607666, 3.5342607498168945, 4.025835990905762, 4.517409324645996, 5.008984565734863, 5.500557899475098, 5.992133140563965, 6.483706474304199, 6.975281715393066, 7.466855049133301, 7.958430290222168, 8.450003623962402, 8.941576957702637, 9.433152198791504, 9.924725532531738, 10.416300773620605, 10.90787410736084, 11.399449348449707, 11.891022682189941, 12.382597923278809, 12.874171257019043, 13.36574649810791, 13.857319831848145, 14.348895072937012, 14.840468406677246, 15.332043647766113, 15.823616981506348, 16.31519317626953, 16.806766510009766]}, "_runtime": 6695.232047319412, "_timestamp": 1585604064.8649168, "_step": 98}
{"Episode reward": 28.029673585429364, "Episode length": 721, "Policy Loss": 0.7302491664886475, "Value Loss": 13.771974563598633, "_runtime": 6696.340025424957, "_timestamp": 1585604065.972895, "_step": 99}
{"Episode reward": 28.724768474645458, "Episode length": 714, "Policy Loss": 0.6254779100418091, "Value Loss": 13.767278671264648, "_runtime": 6697.865869045258, "_timestamp": 1585604067.4987385, "_step": 100}
{"Episode reward": -99.52704624158079, "Episode length": 999, "Policy Loss": -0.2564751207828522, "Value Loss": 0.0035037663765251637, "_runtime": 6698.8116619586945, "_timestamp": 1585604068.4445314, "_step": 101}
{"Episode reward": 39.22705726908658, "Episode length": 609, "Policy Loss": 0.7184293866157532, "Value Loss": 16.153457641601562, "_runtime": 6700.210160017014, "_timestamp": 1585604069.8430295, "_step": 102}
{"Episode reward": 10.927426946815885, "Episode length": 891, "Policy Loss": 0.4455295503139496, "Value Loss": 11.112059593200684, "_runtime": 6701.757360458374, "_timestamp": 1585604071.39023, "_step": 103}
{"Episode reward": 0.9960443376111243, "Episode length": 992, "Policy Loss": 0.38697054982185364, "Value Loss": 9.859515190124512, "_runtime": 6703.276083707809, "_timestamp": 1585604072.9089532, "_step": 104}
{"Episode reward": -99.62065527753882, "Episode length": 999, "Policy Loss": -0.3010409474372864, "Value Loss": 0.002259290311485529, "_runtime": 6704.820961475372, "_timestamp": 1585604074.453831, "_step": 105}
{"Episode reward": -99.54739609046236, "Episode length": 999, "Policy Loss": -0.3101445734500885, "Value Loss": 0.0023853855673223734, "_runtime": 6705.59442615509, "_timestamp": 1585604075.2272956, "_step": 106}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 0.9884112477302551, "Value Loss": 20.508747100830078, "_runtime": 6706.606141090393, "_timestamp": 1585604076.2390106, "_step": 107}
{"Episode reward": 34.946064761926536, "Episode length": 652, "Policy Loss": 0.679000973701477, "Value Loss": 15.191487312316895, "_runtime": 6708.151927471161, "_timestamp": 1585604077.784797, "_step": 108}
{"Episode reward": -99.83048533867702, "Episode length": 999, "Policy Loss": -0.3231031000614166, "Value Loss": 0.02101767249405384, "_runtime": 6709.651331186295, "_timestamp": 1585604079.2842007, "_step": 109}
{"Episode reward": 1.411203585833789, "Episode length": 988, "Policy Loss": 0.29841580986976624, "Value Loss": 9.973392486572266, "_runtime": 6710.975498199463, "_timestamp": 1585604080.6083677, "_step": 110}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 0.40299099683761597, "Value Loss": 11.335076332092285, "_runtime": 6712.526403665543, "_timestamp": 1585604082.1592731, "_step": 111}
{"Episode reward": -99.71591154788482, "Episode length": 999, "Policy Loss": -0.35485997796058655, "Value Loss": 0.003139945212751627, "_runtime": 6714.084437131882, "_timestamp": 1585604083.7173066, "_step": 112}
{"Episode reward": -99.72546390707, "Episode length": 999, "Policy Loss": -0.2968650460243225, "Value Loss": 0.045045867562294006, "_runtime": 6715.617269515991, "_timestamp": 1585604085.250139, "_step": 113}
{"Episode reward": 1.080633874884981, "Episode length": 994, "Policy Loss": 0.31060564517974854, "Value Loss": 9.856437683105469, "_runtime": 6716.81346821785, "_timestamp": 1585604086.4463377, "_step": 114}
{"Episode reward": 23.694639205488855, "Episode length": 764, "Policy Loss": 0.4514235556125641, "Value Loss": 12.957387924194336, "_runtime": 6717.4786722660065, "_timestamp": 1585604087.1115417, "_step": 115}
{"Episode reward": 59.1999999999997, "Episode length": 408, "Policy Loss": 1.093812346458435, "Value Loss": 24.073701858520508, "_runtime": 6718.775161027908, "_timestamp": 1585604088.4080305, "_step": 116}
{"Episode reward": 16.277818923522617, "Episode length": 839, "Policy Loss": 0.5068451166152954, "Value Loss": 11.695701599121094, "_runtime": 6719.307286262512, "_timestamp": 1585604088.9401557, "_step": 117}
{"Episode reward": 67.69578229735762, "Episode length": 325, "Policy Loss": 1.4349067211151123, "Value Loss": 30.340166091918945, "_runtime": 6720.304686784744, "_timestamp": 1585604089.9375563, "_step": 118}
{"Episode reward": 33.28518379693803, "Episode length": 668, "Policy Loss": 0.5427857637405396, "Value Loss": 14.676749229431152, "_runtime": 6721.839999437332, "_timestamp": 1585604091.472869, "_step": 119}
{"Episode reward": -99.6363856817582, "Episode length": 999, "Policy Loss": -0.4121818542480469, "Value Loss": 0.004399620927870274, "_runtime": 6723.369327068329, "_timestamp": 1585604093.0021966, "_step": 120}
{"Episode reward": -99.7757974382898, "Episode length": 999, "Policy Loss": -0.38846203684806824, "Value Loss": 0.050130270421504974, "_runtime": 6724.897853374481, "_timestamp": 1585604094.5307229, "_step": 121}
{"Episode reward": -99.80057860067906, "Episode length": 999, "Policy Loss": -0.43376797437667847, "Value Loss": 0.004710021894425154, "_runtime": 6726.4625248909, "_timestamp": 1585604096.0953944, "_step": 122}
{"Episode reward": -99.48991862796692, "Episode length": 999, "Policy Loss": -0.4157712757587433, "Value Loss": 0.05845595896244049, "_runtime": 6728.014550209045, "_timestamp": 1585604097.6474197, "_step": 123}
{"Episode reward": -99.6588295734008, "Episode length": 999, "Policy Loss": -0.43925657868385315, "Value Loss": 0.004831194411963224, "_runtime": 6729.580926895142, "_timestamp": 1585604099.2137964, "_step": 124}
{"Episode reward": -99.71901825283575, "Episode length": 999, "Policy Loss": -0.4402947425842285, "Value Loss": 0.006353388074785471, "_runtime": 6731.1503484249115, "_timestamp": 1585604100.783218, "_step": 125}
{"Episode reward": -99.37501265080216, "Episode length": 999, "Policy Loss": -0.443733811378479, "Value Loss": 0.004891490563750267, "_runtime": 6732.170248031616, "_timestamp": 1585604101.8031175, "_step": 126}
{"Episode reward": 35.467441288171656, "Episode length": 646, "Policy Loss": 0.5331400036811829, "Value Loss": 15.055377006530762, "_runtime": 6733.732417583466, "_timestamp": 1585604103.365287, "_step": 127}
{"Episode reward": -99.5376885426246, "Episode length": 999, "Policy Loss": -0.4382263422012329, "Value Loss": 0.042747583240270615, "_runtime": 6735.2998378276825, "_timestamp": 1585604104.9327073, "_step": 128}
{"Episode reward": -99.5044375605227, "Episode length": 999, "Policy Loss": -0.44498759508132935, "Value Loss": 0.004917690064758062, "_runtime": 6735.818778514862, "_timestamp": 1585604105.451648, "_step": 129}
{"Episode reward": 68.09999999999982, "Episode length": 319, "Policy Loss": 1.4678502082824707, "Value Loss": 30.551071166992188, "_runtime": 6737.375103235245, "_timestamp": 1585604107.0079727, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4492781162261963, "Value Loss": 0.004983474966138601, "_runtime": 6738.932425022125, "_timestamp": 1585604108.5652945, "_step": 131}
{"Episode reward": -99.56145814760684, "Episode length": 999, "Policy Loss": -0.4374998211860657, "Value Loss": 0.041970379650592804, "_runtime": 6740.394180774689, "_timestamp": 1585604110.0270503, "_step": 132}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.1901417374610901, "Value Loss": 10.009769439697266, "_runtime": 6741.968108892441, "_timestamp": 1585604111.6009784, "_step": 133}
{"Episode reward": -99.61800617889828, "Episode length": 999, "Policy Loss": -0.44906628131866455, "Value Loss": 0.00501663563773036, "_runtime": 6743.540427684784, "_timestamp": 1585604113.1732972, "_step": 134}
{"Episode reward": -99.77222487098048, "Episode length": 999, "Policy Loss": -0.44825413823127747, "Value Loss": 0.0050111436285078526, "_runtime": 6745.087374210358, "_timestamp": 1585604114.7202437, "_step": 135}
{"Episode reward": -99.72960594764307, "Episode length": 999, "Policy Loss": -0.44642511010169983, "Value Loss": 0.006202735006809235, "_runtime": 6746.701318025589, "_timestamp": 1585604116.3341875, "_step": 136}
{"Episode reward": -99.81542973446055, "Episode length": 999, "Policy Loss": -0.44620251655578613, "Value Loss": 0.004915622994303703, "_runtime": 6747.198210954666, "_timestamp": 1585604116.8310804, "_step": 137}
{"Episode reward": 71.09999999999987, "Episode length": 289, "Policy Loss": 1.6846604347229004, "Value Loss": 33.62070083618164, "_runtime": 6748.7468521595, "_timestamp": 1585604118.3797216, "_step": 138}
{"Episode reward": -99.7817255298884, "Episode length": 999, "Policy Loss": -0.44272565841674805, "Value Loss": 0.004863316193223, "_runtime": 6750.223402500153, "_timestamp": 1585604119.856272, "_step": 139}
{"Episode reward": 6.789519860619762, "Episode length": 938, "Policy Loss": 0.23086020350456238, "Value Loss": 10.178502082824707, "_runtime": 6750.86391043663, "_timestamp": 1585604120.49678, "_step": 140}
{"Episode reward": 57.909413806209024, "Episode length": 422, "Policy Loss": 1.0195410251617432, "Value Loss": 22.94829559326172, "_runtime": 6752.4279725551605, "_timestamp": 1585604122.060842, "_step": 141}
{"Episode reward": -99.43540914760533, "Episode length": 999, "Policy Loss": -0.4453571140766144, "Value Loss": 0.00495195435360074, "_runtime": 6753.87001490593, "_timestamp": 1585604123.5028844, "_step": 142}
{"Episode reward": 8.162977707014434, "Episode length": 919, "Policy Loss": 0.37646445631980896, "Value Loss": 10.161849021911621, "_runtime": 6755.106503009796, "_timestamp": 1585604124.7393725, "_step": 143}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.33592697978019714, "Value Loss": 11.765084266662598, "_runtime": 6756.658450603485, "_timestamp": 1585604126.29132, "_step": 144}
{"Episode reward": -99.58354654297007, "Episode length": 999, "Policy Loss": -0.4562285542488098, "Value Loss": 0.0051249172538518906, "_runtime": 6758.214796066284, "_timestamp": 1585604127.8476655, "_step": 145}
{"Episode reward": -99.67266184189218, "Episode length": 999, "Policy Loss": -0.45669400691986084, "Value Loss": 0.00515758665278554, "_runtime": 6759.733217000961, "_timestamp": 1585604129.3660865, "_step": 146}
{"Episode reward": -99.10502165090594, "Episode length": 999, "Policy Loss": -0.31364893913269043, "Value Loss": 0.3858422636985779, "_runtime": 6761.081857919693, "_timestamp": 1585604130.7147274, "_step": 147}
{"Episode reward": 13.938967356732505, "Episode length": 863, "Policy Loss": 0.27010366320610046, "Value Loss": 11.345582962036133, "_runtime": 6762.648022413254, "_timestamp": 1585604132.280892, "_step": 148}
{"Episode reward": -99.55590903612763, "Episode length": 999, "Policy Loss": -0.45405393838882446, "Value Loss": 0.00511745922267437, "_runtime": 6763.762943267822, "_timestamp": 1585604133.3958127, "_step": 149}
{"Episode reward": 29.787602618778777, "Episode length": 706, "Policy Loss": 0.4372834861278534, "Value Loss": 13.684198379516602, "_runtime": 6765.315146684647, "_timestamp": 1585604134.9480162, "_step": 150}
{"Episode reward": -99.52767619301602, "Episode length": 999, "Policy Loss": -0.45413169264793396, "Value Loss": 0.005073171108961105, "_runtime": 6766.8953647613525, "_timestamp": 1585604136.5282342, "_step": 151}
{"Episode reward": -99.59566177254172, "Episode length": 999, "Policy Loss": -0.4505871534347534, "Value Loss": 0.005051806569099426, "_runtime": 6768.432930231094, "_timestamp": 1585604138.0657997, "_step": 152}
{"Episode reward": -99.82240968318516, "Episode length": 999, "Policy Loss": -0.4510646462440491, "Value Loss": 0.005005308892577887, "_runtime": 6769.668028354645, "_timestamp": 1585604139.3008978, "_step": 153}
{"Episode reward": 21.826260437279586, "Episode length": 784, "Policy Loss": 0.31699782609939575, "Value Loss": 12.539480209350586, "_runtime": 6770.837527036667, "_timestamp": 1585604140.4703965, "_step": 154}
{"Episode reward": 28.37808809843243, "Episode length": 717, "Policy Loss": 0.38410478830337524, "Value Loss": 13.548952102661133, "_runtime": 6771.731902837753, "_timestamp": 1585604141.3647723, "_step": 155}
{"Episode reward": 44.02851460999175, "Episode length": 561, "Policy Loss": 0.7648505568504333, "Value Loss": 17.31449317932129, "_runtime": 6772.795866727829, "_timestamp": 1585604142.4287362, "_step": 156}
{"Episode reward": 32.08256463499232, "Episode length": 680, "Policy Loss": 0.4185926914215088, "Value Loss": 14.264265060424805, "_runtime": 6774.34698843956, "_timestamp": 1585604143.979858, "_step": 157}
{"Episode reward": -99.68598826374516, "Episode length": 999, "Policy Loss": -0.44649457931518555, "Value Loss": 0.00494948448613286, "_runtime": 6775.336920261383, "_timestamp": 1585604144.9697897, "_step": 158}
{"Episode reward": 35.8494930739741, "Episode length": 645, "Policy Loss": 0.5033097267150879, "Value Loss": 14.490962982177734, "_runtime": 6776.431915044785, "_timestamp": 1585604146.0647845, "_step": 159}
{"Episode reward": 29.751279795722155, "Episode length": 705, "Policy Loss": 0.5451340079307556, "Value Loss": 13.536237716674805, "_runtime": 6777.663129806519, "_timestamp": 1585604147.2959993, "_step": 160}
{"Episode reward": 21.88261760091426, "Episode length": 783, "Policy Loss": 0.43345803022384644, "Value Loss": 12.14018440246582, "_runtime": 6779.196025133133, "_timestamp": 1585604148.8288946, "_step": 161}
{"Episode reward": -99.58932746763318, "Episode length": 999, "Policy Loss": -0.4551609456539154, "Value Loss": 0.005185197107493877, "_runtime": 6780.7353048324585, "_timestamp": 1585604150.3681743, "_step": 162}
{"Episode reward": -99.68752329810965, "Episode length": 999, "Policy Loss": -0.4579924941062927, "Value Loss": 0.005239545833319426, "_runtime": 6782.300565242767, "_timestamp": 1585604151.9334347, "_step": 163}
{"Episode reward": -99.623116622241, "Episode length": 999, "Policy Loss": -0.4598640203475952, "Value Loss": 0.005250176880508661, "_runtime": 6783.865083694458, "_timestamp": 1585604153.4979532, "_step": 164}
{"Episode reward": -99.82543105343798, "Episode length": 999, "Policy Loss": -0.46336671710014343, "Value Loss": 0.005243681836873293, "_runtime": 6784.583430290222, "_timestamp": 1585604154.2162998, "_step": 165}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 0.9317557215690613, "Value Loss": 21.206905364990234, "_runtime": 6785.713224887848, "_timestamp": 1585604155.3460944, "_step": 166}
{"Episode reward": 28.289640386480983, "Episode length": 718, "Policy Loss": 0.4007188677787781, "Value Loss": 12.848320007324219, "_runtime": 6787.083460569382, "_timestamp": 1585604156.71633, "_step": 167}
{"Episode reward": 12.303436360973109, "Episode length": 879, "Policy Loss": 0.20845957100391388, "Value Loss": 10.497138023376465, "_runtime": 6788.598073959351, "_timestamp": 1585604158.2309434, "_step": 168}
{"Episode reward": -99.79820258340195, "Episode length": 999, "Policy Loss": -0.46437904238700867, "Value Loss": 0.005328334867954254, "_runtime": 6790.138854026794, "_timestamp": 1585604159.7717235, "_step": 169}
{"Episode reward": -99.56467033362576, "Episode length": 999, "Policy Loss": -0.463460773229599, "Value Loss": 0.005336420144885778, "_runtime": 6791.689461231232, "_timestamp": 1585604161.3223307, "_step": 170}
{"Episode reward": -99.522856653914, "Episode length": 999, "Policy Loss": -0.46155864000320435, "Value Loss": 0.005340674426406622, "_runtime": 6793.248936414719, "_timestamp": 1585604162.881806, "_step": 171}
{"Episode reward": -99.74231484500203, "Episode length": 999, "Policy Loss": -0.4582616090774536, "Value Loss": 0.009615708142518997, "_runtime": 6794.707393884659, "_timestamp": 1585604164.3402634, "_step": 172}
{"Episode reward": 7.084439066204766, "Episode length": 932, "Policy Loss": 0.19319884479045868, "Value Loss": 10.256439208984375, "_runtime": 6795.270222663879, "_timestamp": 1585604164.9030921, "_step": 173}
{"Episode reward": 66.05537183676441, "Episode length": 340, "Policy Loss": 1.3845288753509521, "Value Loss": 27.28420066833496, "_runtime": 6796.233804702759, "_timestamp": 1585604165.8666742, "_step": 174}
{"Episode reward": 41.43227565603974, "Episode length": 587, "Policy Loss": 0.5534448623657227, "Value Loss": 16.11403465270996, "_runtime": 6797.815262794495, "_timestamp": 1585604167.4481323, "_step": 175}
{"Episode reward": -99.85555748627381, "Episode length": 999, "Policy Loss": -0.46388664841651917, "Value Loss": 0.005336509086191654, "_runtime": 6798.795395374298, "_timestamp": 1585604168.4282649, "_step": 176}
{"Episode reward": 35.080444670700814, "Episode length": 651, "Policy Loss": 0.4702889919281006, "Value Loss": 14.653534889221191, "_runtime": 6800.3147666454315, "_timestamp": 1585604169.9476361, "_step": 177}
{"Episode reward": -99.76049042444653, "Episode length": 999, "Policy Loss": -0.4680636525154114, "Value Loss": 0.005457350984215736, "_runtime": 6801.878457307816, "_timestamp": 1585604171.5113268, "_step": 178}
{"Episode reward": -99.63828406432738, "Episode length": 999, "Policy Loss": -0.4711136221885681, "Value Loss": 0.005485100671648979, "_runtime": 6803.400537014008, "_timestamp": 1585604173.0334065, "_step": 179}
{"Episode reward": -99.44773865055039, "Episode length": 999, "Policy Loss": -0.4687213897705078, "Value Loss": 0.005510630086064339, "_runtime": 6804.958937168121, "_timestamp": 1585604174.5918067, "_step": 180}
{"Episode reward": -99.55358941028688, "Episode length": 999, "Policy Loss": -0.46886971592903137, "Value Loss": 0.005459579173475504, "_runtime": 6806.527052640915, "_timestamp": 1585604176.1599221, "_step": 181}
{"Episode reward": -99.49231117620228, "Episode length": 999, "Policy Loss": -0.4693264067173004, "Value Loss": 0.005391047801822424, "_runtime": 6807.250288724899, "_timestamp": 1585604176.8831582, "_step": 182}
{"Episode reward": 54.68762186668864, "Episode length": 454, "Policy Loss": 0.7841596007347107, "Value Loss": 20.630041122436523, "_runtime": 6808.797705888748, "_timestamp": 1585604178.4305754, "_step": 183}
{"Episode reward": -99.49981492623346, "Episode length": 999, "Policy Loss": -0.4596486985683441, "Value Loss": 0.005295866634696722, "_runtime": 6810.357428073883, "_timestamp": 1585604179.9902976, "_step": 184}
{"Episode reward": -99.6695810917111, "Episode length": 999, "Policy Loss": -0.46159589290618896, "Value Loss": 0.005266392137855291, "_runtime": 6811.356278896332, "_timestamp": 1585604180.9891484, "_step": 185}
{"Episode reward": 33.53995064311698, "Episode length": 667, "Policy Loss": 0.44341474771499634, "Value Loss": 14.19930362701416, "_runtime": 6812.630156517029, "_timestamp": 1585604182.263026, "_step": 186}
{"Episode reward": 17.95936538409481, "Episode length": 822, "Policy Loss": 0.3994844853878021, "Value Loss": 11.706339836120605, "_runtime": 6814.174731254578, "_timestamp": 1585604183.8076007, "_step": 187}
{"Episode reward": -99.70931594415894, "Episode length": 999, "Policy Loss": -0.4557655155658722, "Value Loss": 0.005157838575541973, "_runtime": 6814.784324169159, "_timestamp": 1585604184.4171937, "_step": 188}
{"Episode reward": 61.20832097346838, "Episode length": 390, "Policy Loss": 1.9069534540176392, "Value Loss": 24.185274124145508, "_runtime": 6815.870394229889, "_timestamp": 1585604185.5032637, "_step": 189}
{"Episode reward": 29.42162600117709, "Episode length": 707, "Policy Loss": 0.37841394543647766, "Value Loss": 12.787968635559082, "_runtime": 6817.036171913147, "_timestamp": 1585604186.6690414, "_step": 190}
{"Episode reward": 24.700000000000003, "Episode length": 753, "Policy Loss": 0.31198516488075256, "Value Loss": 12.331512451171875, "_runtime": 6818.2069346904755, "_timestamp": 1585604187.8398042, "_step": 191}
{"Episode reward": 21.78790955067943, "Episode length": 784, "Policy Loss": 1.0907723903656006, "Value Loss": 11.257147789001465, "_runtime": 6819.754926681519, "_timestamp": 1585604189.3877962, "_step": 192}
{"Episode reward": -99.72551998269489, "Episode length": 999, "Policy Loss": -0.4645833373069763, "Value Loss": 0.005422569345682859, "_runtime": 6821.289816379547, "_timestamp": 1585604190.9226859, "_step": 193}
{"Episode reward": -99.5742983310135, "Episode length": 999, "Policy Loss": -0.47107160091400146, "Value Loss": 0.005483824759721756, "_runtime": 6822.185245990753, "_timestamp": 1585604191.8181155, "_step": 194}
{"Episode reward": 42.66845977934373, "Episode length": 575, "Policy Loss": 0.6242704391479492, "Value Loss": 16.119768142700195, "_runtime": 6823.736968278885, "_timestamp": 1585604193.3698378, "_step": 195}
{"Episode reward": -99.59929492713863, "Episode length": 999, "Policy Loss": -0.46917790174484253, "Value Loss": 0.00980231910943985, "_runtime": 6825.300733804703, "_timestamp": 1585604194.9336033, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47679322957992554, "Value Loss": 0.005603249650448561, "_runtime": 6826.8171536922455, "_timestamp": 1585604196.4500232, "_step": 197}
{"Episode reward": -99.83543170401687, "Episode length": 999, "Policy Loss": -0.47423577308654785, "Value Loss": 0.005579465534538031, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945, 0.0056064072996377945]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0061880312860012054, 0.0017581414431333542, 0.009704314172267914, 0.017650486901402473, 0.025596659630537033, 0.033542830497026443, 0.04148900508880615, 0.04943517968058586, 0.05738135054707527, 0.06532752513885498, 0.0732736885547638, 0.0812198668718338, 0.08916604518890381, 0.09711220860481262, 0.10505838692188263, 0.11300456523895264, 0.12095072865486145, 0.12889690697193146, 0.13684307038784027, 0.14478924870491028, 0.1527354121208191, 0.1606815904378891, 0.1686277687549591, 0.17657393217086792, 0.18452011048793793, 0.19246628880500793, 0.20041245222091675, 0.20835863053798676, 0.21630480885505676, 0.22425097227096558, 0.23219715058803558, 0.2401433140039444, 0.2480894923210144, 0.2560356557369232, 0.2639818489551544, 0.27192801237106323, 0.27987417578697205, 0.28782036900520325, 0.29576653242111206, 0.3037126958370209, 0.3116588592529297, 0.3196050524711609, 0.3275512158870697, 0.3354973793029785, 0.3434435725212097, 0.35138973593711853, 0.35933589935302734, 0.36728209257125854, 0.37522825598716736, 0.38317441940307617, 0.3911206126213074, 0.3990667760372162, 0.407012939453125, 0.4149591326713562, 0.422905296087265, 0.43085145950317383, 0.43879765272140503, 0.44674381613731384, 0.45468997955322266, 0.46263614296913147, 0.47058233618736267, 0.4785284996032715, 0.4864746630191803, 0.4944208264350891, 0.5023670196533203]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.015557605773210526, -0.015159606002271175, -0.014761606231331825, -0.01436360739171505, -0.0139656076207757, -0.01356760784983635, -0.013169608078897, -0.01277160830795765, -0.012373609468340874, -0.011975609697401524, -0.011577609926462173, -0.011179610155522823, -0.010781610384583473, -0.010383611544966698, -0.009985610842704773, -0.009587612003087997, -0.009189612232148647, -0.008791612461209297, -0.008393613621592522, -0.007995612919330597, -0.007597614079713821, -0.007199614308774471, -0.006801614537835121, -0.006403614766895771, -0.006005614995956421, -0.005607616156339645, -0.005209616385400295, -0.004811616614460945, -0.004413616843521595, -0.004015617072582245, -0.0036176182329654694, -0.0032196184620261192, -0.002821618691086769, -0.002423618920147419, -0.002025619149208069, -0.0016276203095912933, -0.0012296205386519432, -0.0008316207677125931, -0.00043362099677324295, -3.562122583389282e-05, 0.0003623776137828827, 0.0007603783160448074, 0.001158377155661583, 0.0015563759952783585, 0.001954376697540283, 0.0023523755371570587, 0.0027503762394189835, 0.003148375079035759, 0.0035463757812976837, 0.003944374620914459, 0.004342373460531235, 0.0047403741627931595, 0.005138373002409935, 0.00553637370467186, 0.005934372544288635, 0.006332371383905411, 0.0067303720861673355, 0.007128370925784111, 0.007526371628046036, 0.007924370467662811, 0.008322369307279587, 0.008720370009541512, 0.009118368849158287, 0.009516369551420212, 0.009914368391036987]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 29.0, 47.0, 24.0, 325.0, 4.0, 2.0, 2.0, 6.0, 14.0, 4.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08898154646158218, -0.08607111871242523, -0.08316069096326828, -0.08025026321411133, -0.07733983546495438, -0.07442940771579742, -0.07151898741722107, -0.06860855221748352, -0.06569813191890717, -0.06278769671916962, -0.05987727269530296, -0.05696684494614601, -0.05405642092227936, -0.051145993173122406, -0.048235565423965454, -0.0453251376748085, -0.04241470992565155, -0.0395042821764946, -0.036593854427337646, -0.033683426678180695, -0.030772998929023743, -0.02786257490515709, -0.02495214343070984, -0.022041715681552887, -0.019131295382976532, -0.01622086763381958, -0.013310439884662628, -0.010400012135505676, -0.007489584386348724, -0.0045791566371917725, -0.0016687288880348206, 0.0012416988611221313, 0.004152126610279083, 0.007062554359436035, 0.009972982108592987, 0.012883409857749939, 0.01579383760690689, 0.018704265356063843, 0.021614693105220795, 0.024525120854377747, 0.0274355486035347, 0.030345968902111053, 0.033256396651268005, 0.03616682440042496, 0.039077259600162506, 0.04198767989873886, 0.04489811509847641, 0.047808535397052765, 0.05071895569562912, 0.05362939089536667, 0.056539811193943024, 0.05945024639368057, 0.06236066669225693, 0.06527110189199448, 0.06818152219057083, 0.07109195739030838, 0.07400237768888474, 0.07691281288862228, 0.07982323318719864, 0.08273366838693619, 0.08564408868551254, 0.08855452388525009, 0.09146494418382645, 0.094375379383564, 0.09728579968214035]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 5.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09032328426837921, -0.08660141378641129, -0.08287954330444336, -0.07915766537189484, -0.07543579488992691, -0.07171392440795898, -0.06799205392599106, -0.06427018344402313, -0.06054830551147461, -0.05682643502950668, -0.05310456454753876, -0.04938269034028053, -0.04566081985831261, -0.04193894565105438, -0.038217075169086456, -0.03449520096182823, -0.030773330479860306, -0.02705145627260208, -0.023329585790634155, -0.01960771530866623, -0.015885844826698303, -0.01216396689414978, -0.008442096412181854, -0.004720225930213928, -0.0009983554482460022, 0.002723515033721924, 0.006445392966270447, 0.010167263448238373, 0.013889133930206299, 0.017611004412174225, 0.021332882344722748, 0.025054752826690674, 0.0287766233086586, 0.032498493790626526, 0.03622037172317505, 0.03994223475456238, 0.0436641126871109, 0.047385990619659424, 0.05110785365104675, 0.054829731583595276, 0.058551594614982605, 0.06227347254753113, 0.06599535048007965, 0.06971721351146698, 0.0734390914440155, 0.07716095447540283, 0.08088283240795135, 0.08460471034049988, 0.08832657337188721, 0.09204845130443573, 0.09577031433582306, 0.09949219226837158, 0.1032140702009201, 0.10693593323230743, 0.11065781116485596, 0.11437968909740448, 0.11810155212879181, 0.12182343006134033, 0.12554529309272766, 0.12926717102527618, 0.1329890489578247, 0.13671091198921204, 0.14043278992176056, 0.1441546529531479, 0.1478765308856964]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 29.0, 5.0, 2.0, 4.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1973893642425537, -0.19077594578266144, -0.18416252732276917, -0.1775491088628769, -0.17093569040298462, -0.16432227194309235, -0.15770885348320007, -0.1510954201221466, -0.14448201656341553, -0.13786858320236206, -0.13125517964363098, -0.12464175373315811, -0.11802832782268524, -0.11141490936279297, -0.1048014909029007, -0.09818807244300842, -0.09157465398311615, -0.08496123552322388, -0.0783478170633316, -0.07173439860343933, -0.06512098014354706, -0.058507561683654785, -0.05189414322376251, -0.04528072476387024, -0.03866729140281677, -0.0320538729429245, -0.025440454483032227, -0.018827036023139954, -0.01221361756324768, -0.005600199103355408, 0.0010132193565368652, 0.007626637816429138, 0.014240056276321411, 0.020853474736213684, 0.027466893196105957, 0.03408031165599823, 0.0406937301158905, 0.047307148575782776, 0.05392056703567505, 0.060534000396728516, 0.0671474039554596, 0.07376083731651306, 0.08037424087524414, 0.08698767423629761, 0.09360107779502869, 0.10021451115608215, 0.10682791471481323, 0.1134413480758667, 0.12005478143692017, 0.12666818499565125, 0.1332816183567047, 0.1398950219154358, 0.14650845527648926, 0.15312185883522034, 0.1597352921962738, 0.16634869575500488, 0.17296212911605835, 0.17957553267478943, 0.1861889660358429, 0.19280236959457397, 0.19941580295562744, 0.20602920651435852, 0.212642639875412, 0.21925604343414307, 0.22586947679519653]}, "_runtime": 6828.38359951973, "_timestamp": 1585604198.016469, "_step": 198}
{"Episode reward": -99.89105427414039, "Episode length": 999, "Policy Loss": -0.473119854927063, "Value Loss": 0.005532786250114441, "_runtime": 6829.944096803665, "_timestamp": 1585604199.5769663, "_step": 199}
{"Episode reward": -99.75595146047277, "Episode length": 999, "Policy Loss": -0.46922847628593445, "Value Loss": 0.00544351851567626, "_runtime": 6830.826028108597, "_timestamp": 1585604200.4588976, "_step": 200}
{"Episode reward": 44.89414386201483, "Episode length": 553, "Policy Loss": 0.5721884965896606, "Value Loss": 16.381723403930664, "_runtime": 6832.387347698212, "_timestamp": 1585604202.0202172, "_step": 201}
{"Episode reward": -99.79695693142864, "Episode length": 999, "Policy Loss": -0.46203362941741943, "Value Loss": 0.005298560950905085, "_runtime": 6832.785305976868, "_timestamp": 1585604202.4181755, "_step": 202}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 2.1046142578125, "Value Loss": 40.779659271240234, "_runtime": 6834.313388586044, "_timestamp": 1585604203.946258, "_step": 203}
{"Episode reward": -99.40853522060068, "Episode length": 999, "Policy Loss": -0.4620051681995392, "Value Loss": 0.005307980813086033, "_runtime": 6835.877490758896, "_timestamp": 1585604205.5103602, "_step": 204}
{"Episode reward": -99.63871922432891, "Episode length": 999, "Policy Loss": -0.46701839566230774, "Value Loss": 0.005381978116929531, "_runtime": 6836.901746511459, "_timestamp": 1585604206.534616, "_step": 205}
{"Episode reward": 30.915574212977305, "Episode length": 692, "Policy Loss": 0.597999632358551, "Value Loss": 16.123825073242188, "_runtime": 6838.456080198288, "_timestamp": 1585604208.0889497, "_step": 206}
{"Episode reward": -99.6692394398721, "Episode length": 999, "Policy Loss": -0.47052890062332153, "Value Loss": 0.005435478407889605, "_runtime": 6839.693972110748, "_timestamp": 1585604209.3268416, "_step": 207}
{"Episode reward": 20.884361077319994, "Episode length": 795, "Policy Loss": 0.29067832231521606, "Value Loss": 11.17631721496582, "_runtime": 6841.178502321243, "_timestamp": 1585604210.8113718, "_step": 208}
{"Episode reward": 2.3587483967201592, "Episode length": 979, "Policy Loss": 0.1430564671754837, "Value Loss": 9.751567840576172, "_runtime": 6842.749738931656, "_timestamp": 1585604212.3826084, "_step": 209}
{"Episode reward": -99.53476587957564, "Episode length": 999, "Policy Loss": -0.4671145975589752, "Value Loss": 0.005454163998365402, "_runtime": 6844.326610088348, "_timestamp": 1585604213.9594796, "_step": 210}
{"Episode reward": -99.39293725109174, "Episode length": 999, "Policy Loss": -0.46970972418785095, "Value Loss": 0.005432892125099897, "_runtime": 6845.874860286713, "_timestamp": 1585604215.5077298, "_step": 211}
{"Episode reward": -99.6875165424354, "Episode length": 999, "Policy Loss": -0.46622544527053833, "Value Loss": 0.0054029677994549274, "_runtime": 6847.441992998123, "_timestamp": 1585604217.0748625, "_step": 212}
{"Episode reward": -99.26501797948593, "Episode length": 999, "Policy Loss": -0.4616469442844391, "Value Loss": 0.005306052044034004, "_runtime": 6849.01105260849, "_timestamp": 1585604218.643922, "_step": 213}
{"Episode reward": -99.80228635478275, "Episode length": 999, "Policy Loss": -0.4596582353115082, "Value Loss": 0.0052394443191587925, "_runtime": 6850.251804351807, "_timestamp": 1585604219.8846738, "_step": 214}
{"Episode reward": 20.179243144300102, "Episode length": 799, "Policy Loss": 0.2957248389720917, "Value Loss": 12.502750396728516, "_runtime": 6851.826364278793, "_timestamp": 1585604221.4592338, "_step": 215}
{"Episode reward": -99.66858323310596, "Episode length": 999, "Policy Loss": -0.4499272108078003, "Value Loss": 0.005023936741054058, "_runtime": 6853.102997303009, "_timestamp": 1585604222.7358668, "_step": 216}
{"Episode reward": 18.277611183911006, "Episode length": 819, "Policy Loss": 0.34480366110801697, "Value Loss": 12.197783470153809, "_runtime": 6854.649069547653, "_timestamp": 1585604224.281939, "_step": 217}
{"Episode reward": -99.70482409084077, "Episode length": 999, "Policy Loss": -0.4409925639629364, "Value Loss": 0.004849365446716547, "_runtime": 6856.2237956523895, "_timestamp": 1585604225.8566651, "_step": 218}
{"Episode reward": -99.4656948585897, "Episode length": 999, "Policy Loss": -0.43508124351501465, "Value Loss": 0.004735661670565605, "_runtime": 6857.214753627777, "_timestamp": 1585604226.847623, "_step": 219}
{"Episode reward": 37.59868193231462, "Episode length": 625, "Policy Loss": 0.8310896754264832, "Value Loss": 15.982845306396484, "_runtime": 6858.027183532715, "_timestamp": 1585604227.660053, "_step": 220}
{"Episode reward": 48.56645174580581, "Episode length": 516, "Policy Loss": 0.7489973902702332, "Value Loss": 19.35817527770996, "_runtime": 6859.580280542374, "_timestamp": 1585604229.21315, "_step": 221}
{"Episode reward": -99.44922801384682, "Episode length": 999, "Policy Loss": -0.4289948344230652, "Value Loss": 0.0045587471686303616, "_runtime": 6861.114454984665, "_timestamp": 1585604230.7473245, "_step": 222}
{"Episode reward": -99.6336577739378, "Episode length": 999, "Policy Loss": -0.4282376170158386, "Value Loss": 0.004538706038147211, "_runtime": 6861.931334733963, "_timestamp": 1585604231.5642042, "_step": 223}
{"Episode reward": 47.426226285116975, "Episode length": 528, "Policy Loss": 0.7052860260009766, "Value Loss": 18.918716430664062, "_runtime": 6863.493056297302, "_timestamp": 1585604233.1259258, "_step": 224}
{"Episode reward": -99.5217843259205, "Episode length": 999, "Policy Loss": -0.4230298399925232, "Value Loss": 0.0044762976467609406, "_runtime": 6864.513454198837, "_timestamp": 1585604234.1463237, "_step": 225}
{"Episode reward": 35.73948900387232, "Episode length": 644, "Policy Loss": 0.6156964302062988, "Value Loss": 15.511661529541016, "_runtime": 6865.955594301224, "_timestamp": 1585604235.5884638, "_step": 226}
{"Episode reward": 5.18290410354787, "Episode length": 951, "Policy Loss": 0.21789725124835968, "Value Loss": 10.505655288696289, "_runtime": 6866.832008838654, "_timestamp": 1585604236.4648783, "_step": 227}
{"Episode reward": 45.65024191018698, "Episode length": 547, "Policy Loss": 0.875884473323822, "Value Loss": 18.26146697998047, "_runtime": 6868.426594734192, "_timestamp": 1585604238.0594642, "_step": 228}
{"Episode reward": -99.77880883349431, "Episode length": 999, "Policy Loss": -0.43001025915145874, "Value Loss": 0.004579887259751558, "_runtime": 6869.640260219574, "_timestamp": 1585604239.2731297, "_step": 229}
{"Episode reward": 23.275965028256266, "Episode length": 769, "Policy Loss": 0.3269754946231842, "Value Loss": 12.99083423614502, "_runtime": 6871.172543525696, "_timestamp": 1585604240.805413, "_step": 230}
{"Episode reward": -99.62307181240037, "Episode length": 999, "Policy Loss": -0.43262550234794617, "Value Loss": 0.004683079198002815, "_runtime": 6872.747239351273, "_timestamp": 1585604242.3801088, "_step": 231}
{"Episode reward": -99.6539103018921, "Episode length": 999, "Policy Loss": -0.43523067235946655, "Value Loss": 0.004706432577222586, "_runtime": 6874.2898206710815, "_timestamp": 1585604243.9226902, "_step": 232}
{"Episode reward": -99.4551714510294, "Episode length": 999, "Policy Loss": -0.4318254888057709, "Value Loss": 0.004692842252552509, "_runtime": 6875.315491676331, "_timestamp": 1585604244.9483612, "_step": 233}
{"Episode reward": 35.85537976793648, "Episode length": 643, "Policy Loss": 0.6282267570495605, "Value Loss": 15.535496711730957, "_runtime": 6876.6787757873535, "_timestamp": 1585604246.3116453, "_step": 234}
{"Episode reward": 13.134431729662836, "Episode length": 875, "Policy Loss": 0.23532433807849884, "Value Loss": 11.41783618927002, "_runtime": 6878.252859115601, "_timestamp": 1585604247.8857286, "_step": 235}
{"Episode reward": -99.80870329225296, "Episode length": 999, "Policy Loss": -0.43598848581314087, "Value Loss": 0.004712609574198723, "_runtime": 6879.790571212769, "_timestamp": 1585604249.4234407, "_step": 236}
{"Episode reward": -99.77044528094564, "Episode length": 999, "Policy Loss": -0.4366004467010498, "Value Loss": 0.004702628590166569, "_runtime": 6881.353303909302, "_timestamp": 1585604250.9861734, "_step": 237}
{"Episode reward": -99.8184354822894, "Episode length": 999, "Policy Loss": -0.43402722477912903, "Value Loss": 0.004669250454753637, "_runtime": 6882.919835329056, "_timestamp": 1585604252.5527048, "_step": 238}
{"Episode reward": -99.57679205175963, "Episode length": 999, "Policy Loss": -0.4306040108203888, "Value Loss": 0.004593376070261002, "_runtime": 6883.552541732788, "_timestamp": 1585604253.1854112, "_step": 239}
{"Episode reward": 61.879637428359736, "Episode length": 383, "Policy Loss": 1.0968130826950073, "Value Loss": 26.079084396362305, "_runtime": 6885.129037618637, "_timestamp": 1585604254.761907, "_step": 240}
{"Episode reward": -99.51036351695521, "Episode length": 999, "Policy Loss": -0.42489194869995117, "Value Loss": 0.0045127179473638535, "_runtime": 6886.700073957443, "_timestamp": 1585604256.3329434, "_step": 241}
{"Episode reward": -99.81431457905424, "Episode length": 999, "Policy Loss": -0.4262615442276001, "Value Loss": 0.004502271302044392, "_runtime": 6887.0695033073425, "_timestamp": 1585604256.7023728, "_step": 242}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 2.1776468753814697, "Value Loss": 44.58770751953125, "_runtime": 6888.004189014435, "_timestamp": 1585604257.6370585, "_step": 243}
{"Episode reward": 41.192405911906995, "Episode length": 589, "Policy Loss": 0.5938920974731445, "Value Loss": 16.959535598754883, "_runtime": 6889.330007076263, "_timestamp": 1585604258.9628766, "_step": 244}
{"Episode reward": 15.85607185580352, "Episode length": 842, "Policy Loss": 0.4015471041202545, "Value Loss": 11.864869117736816, "_runtime": 6890.861805438995, "_timestamp": 1585604260.494675, "_step": 245}
{"Episode reward": -99.39412138802446, "Episode length": 999, "Policy Loss": -0.4433968961238861, "Value Loss": 0.004880811553448439, "_runtime": 6891.826793909073, "_timestamp": 1585604261.4596634, "_step": 246}
{"Episode reward": 38.71114544521347, "Episode length": 615, "Policy Loss": 0.5392343401908875, "Value Loss": 16.242097854614258, "_runtime": 6892.6203672885895, "_timestamp": 1585604262.2532368, "_step": 247}
{"Episode reward": 50.39999999999957, "Episode length": 496, "Policy Loss": 0.7278538346290588, "Value Loss": 20.13742446899414, "_runtime": 6894.182425022125, "_timestamp": 1585604263.8152945, "_step": 248}
{"Episode reward": -99.41987706537338, "Episode length": 999, "Policy Loss": -0.4647400975227356, "Value Loss": 0.00535420561209321, "_runtime": 6895.726099252701, "_timestamp": 1585604265.3589687, "_step": 249}
{"Episode reward": -99.59882135761879, "Episode length": 999, "Policy Loss": -0.47236233949661255, "Value Loss": 0.005517893470823765, "_runtime": 6896.135228395462, "_timestamp": 1585604265.7680979, "_step": 250}
{"Episode reward": 75.39899835137177, "Episode length": 247, "Policy Loss": 1.9121675491333008, "Value Loss": 40.43067932128906, "_runtime": 6897.686645030975, "_timestamp": 1585604267.3195145, "_step": 251}
{"Episode reward": -99.55748171743916, "Episode length": 999, "Policy Loss": -0.48897987604141235, "Value Loss": 0.005872608162462711, "_runtime": 6899.022223472595, "_timestamp": 1585604268.655093, "_step": 252}
{"Episode reward": 14.424595046553293, "Episode length": 859, "Policy Loss": 0.40335094928741455, "Value Loss": 11.629326820373535, "_runtime": 6900.525256156921, "_timestamp": 1585604270.1581256, "_step": 253}
{"Episode reward": -99.65638131715684, "Episode length": 999, "Policy Loss": -0.5022484064102173, "Value Loss": 0.006270854268223047, "_runtime": 6901.042921066284, "_timestamp": 1585604270.6757905, "_step": 254}
{"Episode reward": 69.15161558518832, "Episode length": 309, "Policy Loss": 1.962336540222168, "Value Loss": 32.317039489746094, "_runtime": 6902.593631982803, "_timestamp": 1585604272.2265015, "_step": 255}
{"Episode reward": -99.74310554638949, "Episode length": 999, "Policy Loss": -0.5172406435012817, "Value Loss": 0.0066758072935044765, "_runtime": 6904.1587018966675, "_timestamp": 1585604273.7915714, "_step": 256}
{"Episode reward": -99.52753704449141, "Episode length": 999, "Policy Loss": -0.521369218826294, "Value Loss": 0.00685362471267581, "_runtime": 6905.671356201172, "_timestamp": 1585604275.3042257, "_step": 257}
{"Episode reward": -99.01086284278438, "Episode length": 999, "Policy Loss": -0.52406245470047, "Value Loss": 0.006938861217349768, "_runtime": 6907.243832588196, "_timestamp": 1585604276.876702, "_step": 258}
{"Episode reward": -99.62849957181467, "Episode length": 999, "Policy Loss": -0.5325304865837097, "Value Loss": 0.007061690557748079, "_runtime": 6908.818784236908, "_timestamp": 1585604278.4516537, "_step": 259}
{"Episode reward": -99.87198669053474, "Episode length": 999, "Policy Loss": -0.5344676375389099, "Value Loss": 0.007097433786839247, "_runtime": 6910.385608673096, "_timestamp": 1585604280.0184782, "_step": 260}
{"Episode reward": -99.65186058663392, "Episode length": 999, "Policy Loss": -0.5311335325241089, "Value Loss": 0.007048462051898241, "_runtime": 6911.98179936409, "_timestamp": 1585604281.6146688, "_step": 261}
{"Episode reward": -99.80687925426615, "Episode length": 999, "Policy Loss": -0.5331769585609436, "Value Loss": 0.006990666966885328, "_runtime": 6913.563009738922, "_timestamp": 1585604283.1958792, "_step": 262}
{"Episode reward": -99.82745302030676, "Episode length": 999, "Policy Loss": -0.5257230401039124, "Value Loss": 0.006878668442368507, "_runtime": 6915.162651538849, "_timestamp": 1585604284.795521, "_step": 263}
{"Episode reward": -99.74534453367967, "Episode length": 999, "Policy Loss": -0.520887017250061, "Value Loss": 0.006727068684995174, "_runtime": 6916.756346940994, "_timestamp": 1585604286.3892164, "_step": 264}
{"Episode reward": -99.64914520082391, "Episode length": 999, "Policy Loss": -0.513252317905426, "Value Loss": 0.0065433490090072155, "_runtime": 6917.79153752327, "_timestamp": 1585604287.424407, "_step": 265}
{"Episode reward": 34.87122713788355, "Episode length": 653, "Policy Loss": 0.42349866032600403, "Value Loss": 15.295868873596191, "_runtime": 6919.364628076553, "_timestamp": 1585604288.9974976, "_step": 266}
{"Episode reward": -99.7945156565155, "Episode length": 999, "Policy Loss": -0.5048231482505798, "Value Loss": 0.006222008261829615, "_runtime": 6920.504801273346, "_timestamp": 1585604290.1376708, "_step": 267}
{"Episode reward": 29.34667014802919, "Episode length": 709, "Policy Loss": 0.4096703827381134, "Value Loss": 14.088438987731934, "_runtime": 6922.066453933716, "_timestamp": 1585604291.6993234, "_step": 268}
{"Episode reward": -99.84694307232135, "Episode length": 999, "Policy Loss": -0.4908900260925293, "Value Loss": 0.005948634352535009, "_runtime": 6923.626995563507, "_timestamp": 1585604293.259865, "_step": 269}
{"Episode reward": -99.8270448183918, "Episode length": 999, "Policy Loss": -0.48332488536834717, "Value Loss": 0.005805494729429483, "_runtime": 6925.167969226837, "_timestamp": 1585604294.8008387, "_step": 270}
{"Episode reward": -99.80660269711959, "Episode length": 999, "Policy Loss": -0.4780425727367401, "Value Loss": 0.005641148425638676, "_runtime": 6926.731201887131, "_timestamp": 1585604296.3640714, "_step": 271}
{"Episode reward": -99.51771981549689, "Episode length": 999, "Policy Loss": -0.46754348278045654, "Value Loss": 0.005442239344120026, "_runtime": 6928.283150434494, "_timestamp": 1585604297.91602, "_step": 272}
{"Episode reward": -99.62986228454835, "Episode length": 999, "Policy Loss": -0.45865845680236816, "Value Loss": 0.005253314971923828, "_runtime": 6929.854053735733, "_timestamp": 1585604299.4869232, "_step": 273}
{"Episode reward": -99.76938047385636, "Episode length": 999, "Policy Loss": -0.45341140031814575, "Value Loss": 0.00504604447633028, "_runtime": 6930.740151643753, "_timestamp": 1585604300.3730211, "_step": 274}
{"Episode reward": 43.7086646431819, "Episode length": 564, "Policy Loss": 0.596049427986145, "Value Loss": 17.71065330505371, "_runtime": 6932.290833473206, "_timestamp": 1585604301.923703, "_step": 275}
{"Episode reward": -99.60363517145748, "Episode length": 999, "Policy Loss": -0.43559467792510986, "Value Loss": 0.004681384656578302, "_runtime": 6933.852199792862, "_timestamp": 1585604303.4850693, "_step": 276}
{"Episode reward": -99.25010734523684, "Episode length": 999, "Policy Loss": -0.42515912652015686, "Value Loss": 0.004503282252699137, "_runtime": 6934.849207401276, "_timestamp": 1585604304.482077, "_step": 277}
{"Episode reward": 35.459996824844836, "Episode length": 647, "Policy Loss": 0.4798159599304199, "Value Loss": 15.439865112304688, "_runtime": 6936.4070019721985, "_timestamp": 1585604306.0398715, "_step": 278}
{"Episode reward": -99.54285724524387, "Episode length": 999, "Policy Loss": -0.4134972095489502, "Value Loss": 0.004239242058247328, "_runtime": 6936.960036993027, "_timestamp": 1585604306.5929065, "_step": 279}
{"Episode reward": 67.446443276014, "Episode length": 327, "Policy Loss": 1.420109748840332, "Value Loss": 30.54584503173828, "_runtime": 6938.530673742294, "_timestamp": 1585604308.1635432, "_step": 280}
{"Episode reward": -99.60573306542508, "Episode length": 999, "Policy Loss": -0.40681368112564087, "Value Loss": 0.004102915525436401, "_runtime": 6940.093928813934, "_timestamp": 1585604309.7267983, "_step": 281}
{"Episode reward": -99.73052366094642, "Episode length": 999, "Policy Loss": -0.4060242474079132, "Value Loss": 0.004068966023623943, "_runtime": 6941.59065246582, "_timestamp": 1585604311.223522, "_step": 282}
{"Episode reward": -99.5097822354336, "Episode length": 999, "Policy Loss": -0.40205830335617065, "Value Loss": 0.004004335030913353, "_runtime": 6943.160628080368, "_timestamp": 1585604312.7934976, "_step": 283}
{"Episode reward": -99.57303692735157, "Episode length": 999, "Policy Loss": -0.3961431086063385, "Value Loss": 0.003926559817045927, "_runtime": 6944.725830316544, "_timestamp": 1585604314.3586998, "_step": 284}
{"Episode reward": -99.84504329639464, "Episode length": 999, "Policy Loss": -0.3930168151855469, "Value Loss": 0.0038407195825129747, "_runtime": 6946.26494550705, "_timestamp": 1585604315.897815, "_step": 285}
{"Episode reward": -99.525560069141, "Episode length": 999, "Policy Loss": -0.38742756843566895, "Value Loss": 0.0037216604687273502, "_runtime": 6947.842547178268, "_timestamp": 1585604317.4754167, "_step": 286}
{"Episode reward": -99.74083791861636, "Episode length": 999, "Policy Loss": -0.38049253821372986, "Value Loss": 0.003600803203880787, "_runtime": 6948.6118330955505, "_timestamp": 1585604318.2447026, "_step": 287}
{"Episode reward": 52.77079665604357, "Episode length": 474, "Policy Loss": 0.8903560638427734, "Value Loss": 21.07568359375, "_runtime": 6950.159063100815, "_timestamp": 1585604319.7919326, "_step": 288}
{"Episode reward": -99.7204394993242, "Episode length": 999, "Policy Loss": -0.3692515194416046, "Value Loss": 0.0034024103078991175, "_runtime": 6951.1424441337585, "_timestamp": 1585604320.7753136, "_step": 289}
{"Episode reward": 38.99906095255661, "Episode length": 612, "Policy Loss": 0.8514817357063293, "Value Loss": 16.32430076599121, "_runtime": 6952.669699907303, "_timestamp": 1585604322.3025694, "_step": 290}
{"Episode reward": -99.26146526874992, "Episode length": 999, "Policy Loss": -0.362709105014801, "Value Loss": 0.00328660081140697, "_runtime": 6952.945680856705, "_timestamp": 1585604322.5785503, "_step": 291}
{"Episode reward": 86.60000000000004, "Episode length": 134, "Policy Loss": 4.042830944061279, "Value Loss": 74.54481506347656, "_runtime": 6954.471725463867, "_timestamp": 1585604324.104595, "_step": 292}
{"Episode reward": -99.84945779035193, "Episode length": 999, "Policy Loss": -0.3742094337940216, "Value Loss": 0.003485127119347453, "_runtime": 6955.4795134067535, "_timestamp": 1585604325.112383, "_step": 293}
{"Episode reward": 36.65401806435513, "Episode length": 636, "Policy Loss": 0.5982565879821777, "Value Loss": 15.708138465881348, "_runtime": 6956.957589387894, "_timestamp": 1585604326.5904589, "_step": 294}
{"Episode reward": -99.5945783134827, "Episode length": 999, "Policy Loss": -0.3989666998386383, "Value Loss": 0.003870976623147726, "_runtime": 6958.112677097321, "_timestamp": 1585604327.7455466, "_step": 295}
{"Episode reward": 26.952555939937753, "Episode length": 732, "Policy Loss": 0.40420618653297424, "Value Loss": 13.647862434387207, "_runtime": 6959.651992321014, "_timestamp": 1585604329.2848618, "_step": 296}
{"Episode reward": -99.69062101634196, "Episode length": 999, "Policy Loss": -0.4102814495563507, "Value Loss": 0.004229740239679813, "_runtime": 6960.904228448868, "_timestamp": 1585604330.537098, "_step": 297}
{"Episode reward": 18.8276708152556, "Episode length": 813, "Policy Loss": 0.3147446811199188, "Value Loss": 12.288191795349121, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822, 0.0401519238948822]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.040959298610687256, -0.02558891288936138, -0.010218527168035507, 0.005151860415935516, 0.02052224427461624, 0.03589262813329697, 0.05126301944255829, 0.06663340330123901, 0.08200378715991974, 0.09737417101860046, 0.11274455487728119, 0.12811493873596191, 0.14348533749580383, 0.15885572135448456, 0.17422610521316528, 0.189596489071846, 0.20496687293052673, 0.22033727169036865, 0.23570764064788818, 0.2510780394077301, 0.26644840836524963, 0.28181880712509155, 0.2971891760826111, 0.312559574842453, 0.3279299736022949, 0.34330034255981445, 0.35867074131965637, 0.3740411102771759, 0.3894115090370178, 0.40478187799453735, 0.4201522767543793, 0.4355226457118988, 0.4508930444717407, 0.46626341342926025, 0.48163384199142456, 0.4970042109489441, 0.5123745799064636, 0.5277449488639832, 0.5431153774261475, 0.558485746383667, 0.5738561153411865, 0.5892265439033508, 0.6045969128608704, 0.6199672818183899, 0.6353376507759094, 0.6507080793380737, 0.6660784482955933, 0.6814488172531128, 0.6968192458152771, 0.7121896147727966, 0.7275599837303162, 0.7429303526878357, 0.75830078125, 0.7736711502075195, 0.7890415191650391, 0.8044118881225586, 0.8197823166847229, 0.8351526856422424, 0.850523054599762, 0.8658934831619263, 0.8812638521194458, 0.8966342210769653, 0.9120045900344849, 0.9273750185966492, 0.9427453875541687]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.11140190064907074, -0.1085517406463623, -0.10570158064365387, -0.10285142064094543, -0.100001260638237, -0.09715110063552856, -0.09430094063282013, -0.0914507806301117, -0.08860062062740326, -0.08575046062469482, -0.08290030062198639, -0.08005014061927795, -0.07719997316598892, -0.07434981316328049, -0.07149965316057205, -0.06864949315786362, -0.06579933315515518, -0.06294917315244675, -0.06009901314973831, -0.05724885314702988, -0.05439869314432144, -0.05154852941632271, -0.04869837313890457, -0.045848213136196136, -0.042998045682907104, -0.04014788568019867, -0.037297725677490234, -0.0344475656747818, -0.031597405672073364, -0.02874724566936493, -0.025897085666656494, -0.02304692566394806, -0.020196765661239624, -0.01734660565853119, -0.014496445655822754, -0.011646285653114319, -0.008796125650405884, -0.005945965647697449, -0.0030958056449890137, -0.0002456456422805786, 0.0026045143604278564, 0.005454681813716888, 0.008304841816425323, 0.011155001819133759, 0.014005154371261597, 0.016855314373970032, 0.019705474376678467, 0.022555634379386902, 0.02540580928325653, 0.028255969285964966, 0.0311061292886734, 0.033956289291381836, 0.03680644929409027, 0.039656609296798706, 0.04250676929950714, 0.045356929302215576, 0.04820708930492401, 0.051057249307632446, 0.05390740931034088, 0.056757569313049316, 0.05960772931575775, 0.062457889318466187, 0.06530804932117462, 0.06815820932388306, 0.07100836932659149]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 34.0, 8.0, 4.0, 2.0, 288.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 19.0, 1.0, 1.0, 4.0, 1.0, 6.0, 4.0, 12.0, 6.0, 3.0, 4.0, 8.0, 4.0, 5.0, 3.0, 3.0, 1.0, 1.0], "bins": [-0.5410199165344238, -0.527178168296814, -0.5133364796638489, -0.499494731426239, -0.48565301299095154, -0.47181129455566406, -0.4579695463180542, -0.4441278278827667, -0.43028610944747925, -0.4164443910121918, -0.4026026725769043, -0.38876092433929443, -0.37491920590400696, -0.3610774874687195, -0.3472357392311096, -0.33339402079582214, -0.31955230236053467, -0.3057105839252472, -0.2918688654899597, -0.27802711725234985, -0.2641853988170624, -0.2503436803817749, -0.23650193214416504, -0.22266021370887756, -0.2088184952735901, -0.1949767768383026, -0.18113505840301514, -0.16729331016540527, -0.1534515917301178, -0.13960987329483032, -0.12576812505722046, -0.11192640662193298, -0.09808468818664551, -0.08424296975135803, -0.07040125131607056, -0.05655950307846069, -0.04271778464317322, -0.028876066207885742, -0.015034317970275879, -0.001192629337310791, 0.012649118900299072, 0.026490867137908936, 0.04033255577087402, 0.05417430400848389, 0.06801605224609375, 0.08185774087905884, 0.0956994891166687, 0.10954117774963379, 0.12338292598724365, 0.13722467422485352, 0.1510663628578186, 0.16490811109542847, 0.17874979972839355, 0.19259154796600342, 0.20643329620361328, 0.22027498483657837, 0.23411673307418823, 0.2479584813117981, 0.2618001699447632, 0.27564191818237305, 0.2894836664199829, 0.303325355052948, 0.31716710329055786, 0.33100879192352295, 0.3448505401611328]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 6.0, 9.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4809977412223816, -0.4634850323200226, -0.4459722936153412, -0.4284595847129822, -0.4109468460083008, -0.3934341371059418, -0.37592142820358276, -0.35840868949890137, -0.34089598059654236, -0.32338327169418335, -0.30587053298950195, -0.28835782408714294, -0.27084511518478394, -0.25333237648010254, -0.23581966757774353, -0.21830692887306213, -0.20079421997070312, -0.18328151106834412, -0.16576877236366272, -0.1482560634613037, -0.13074332475662231, -0.1132306158542633, -0.0957179069519043, -0.0782051682472229, -0.06069245934486389, -0.04317975044250488, -0.025667011737823486, -0.008154302835464478, 0.009358406066894531, 0.026871144771575928, 0.044383883476257324, 0.061896562576293945, 0.07940930128097534, 0.09692203998565674, 0.11443471908569336, 0.13194745779037476, 0.14946019649505615, 0.16697287559509277, 0.18448561429977417, 0.20199835300445557, 0.21951109170913696, 0.23702377080917358, 0.254536509513855, 0.2720492482185364, 0.289561927318573, 0.3070746660232544, 0.3245874047279358, 0.3421000838279724, 0.3596128225326538, 0.3771255612373352, 0.3946382403373718, 0.4121509790420532, 0.4296637177467346, 0.44717639684677124, 0.46468913555145264, 0.48220187425613403, 0.49971455335617065, 0.517227292060852, 0.5347400307655334, 0.5522527098655701, 0.5697655081748962, 0.5872781872749329, 0.6047908663749695, 0.6223036646842957, 0.6398163437843323]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 4.0, 15.0, 19.0, 1.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.5543871521949768, -0.5394109487533569, -0.5244348049163818, -0.509458601474762, -0.4944824278354645, -0.479506254196167, -0.4645300805568695, -0.449553906917572, -0.43457773327827454, -0.41960155963897705, -0.4046253561973572, -0.3896492123603821, -0.3746730089187622, -0.3596968352794647, -0.34472066164016724, -0.32974445819854736, -0.31476831436157227, -0.2997921109199524, -0.2848159372806549, -0.2698397636413574, -0.25486359000205994, -0.23988741636276245, -0.22491124272346497, -0.2099350392818451, -0.1949588656425476, -0.17998269200325012, -0.16500651836395264, -0.15003034472465515, -0.13505417108535767, -0.12007796764373779, -0.10510179400444031, -0.09012562036514282, -0.07514944672584534, -0.06017327308654785, -0.04519706964492798, -0.03022092580795288, -0.015244722366333008, -0.00026857852935791016, 0.014707624912261963, 0.029683828353881836, 0.044659972190856934, 0.05963617563247681, 0.0746123194694519, 0.08958852291107178, 0.10456466674804688, 0.11954087018966675, 0.13451707363128662, 0.14949321746826172, 0.1644694209098816, 0.1794455647468567, 0.19442176818847656, 0.20939791202545166, 0.22437411546707153, 0.2393503189086914, 0.2543264627456665, 0.2693026661872864, 0.2842788100242615, 0.29925501346588135, 0.3142312169075012, 0.3292073607444763, 0.3441835641860962, 0.3591597080230713, 0.37413591146469116, 0.38911205530166626, 0.40408825874328613]}, "_runtime": 6962.442444801331, "_timestamp": 1585604332.0753143, "_step": 298}
{"Episode reward": -99.38559372044413, "Episode length": 999, "Policy Loss": -0.4257580041885376, "Value Loss": 0.0045084841549396515, "_runtime": 6963.081438779831, "_timestamp": 1585604332.7143083, "_step": 299}
{"Episode reward": 61.22219396780683, "Episode length": 389, "Policy Loss": 1.072379469871521, "Value Loss": 25.6765193939209, "_runtime": 6964.648778676987, "_timestamp": 1585604334.2816482, "_step": 300}
{"Episode reward": -99.65089680824755, "Episode length": 999, "Policy Loss": -0.4392866790294647, "Value Loss": 0.004829375073313713, "_runtime": 6965.515748739243, "_timestamp": 1585604335.1486182, "_step": 301}
{"Episode reward": 46.08999129714744, "Episode length": 541, "Policy Loss": 0.6310130953788757, "Value Loss": 18.463151931762695, "_runtime": 6967.023141384125, "_timestamp": 1585604336.6560109, "_step": 302}
{"Episode reward": -99.79231958038152, "Episode length": 999, "Policy Loss": -0.45693475008010864, "Value Loss": 0.00516258692368865, "_runtime": 6968.1959862709045, "_timestamp": 1585604337.8288558, "_step": 303}
{"Episode reward": 25.212572510330915, "Episode length": 749, "Policy Loss": 0.33365464210510254, "Value Loss": 13.33696460723877, "_runtime": 6968.8516726493835, "_timestamp": 1585604338.4845421, "_step": 304}
{"Episode reward": 58.344955642154, "Episode length": 419, "Policy Loss": 0.9461649060249329, "Value Loss": 23.836524963378906, "_runtime": 6970.405243396759, "_timestamp": 1585604340.0381129, "_step": 305}
{"Episode reward": -99.49248868283657, "Episode length": 999, "Policy Loss": -0.47575029730796814, "Value Loss": 0.005650500301271677, "_runtime": 6971.703341722488, "_timestamp": 1585604341.3362112, "_step": 306}
{"Episode reward": 15.669215787703223, "Episode length": 846, "Policy Loss": 0.27727729082107544, "Value Loss": 11.808110237121582, "_runtime": 6973.204711675644, "_timestamp": 1585604342.8375812, "_step": 307}
{"Episode reward": -99.52705883622593, "Episode length": 999, "Policy Loss": -0.48958638310432434, "Value Loss": 0.005988685414195061, "_runtime": 6974.756954669952, "_timestamp": 1585604344.3898242, "_step": 308}
{"Episode reward": -99.61173562847988, "Episode length": 999, "Policy Loss": -0.4969451427459717, "Value Loss": 0.0061075277626514435, "_runtime": 6976.295507907867, "_timestamp": 1585604345.9283774, "_step": 309}
{"Episode reward": -99.65703488569714, "Episode length": 999, "Policy Loss": -0.5031480193138123, "Value Loss": 0.006175338756293058, "_runtime": 6977.848821878433, "_timestamp": 1585604347.4816914, "_step": 310}
{"Episode reward": -99.67609197522987, "Episode length": 999, "Policy Loss": -0.4995172321796417, "Value Loss": 0.006196914240717888, "_runtime": 6978.79784989357, "_timestamp": 1585604348.4307194, "_step": 311}
{"Episode reward": 40.014534363649155, "Episode length": 602, "Policy Loss": 0.47338739037513733, "Value Loss": 16.591291427612305, "_runtime": 6980.36012172699, "_timestamp": 1585604349.9929912, "_step": 312}
{"Episode reward": -99.73157439793437, "Episode length": 999, "Policy Loss": -0.4980613589286804, "Value Loss": 0.006200962234288454, "_runtime": 6980.756515264511, "_timestamp": 1585604350.3893847, "_step": 313}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 2.156576156616211, "Value Loss": 45.38923645019531, "_runtime": 6982.287771224976, "_timestamp": 1585604351.9206407, "_step": 314}
{"Episode reward": -99.70099154609349, "Episode length": 999, "Policy Loss": -0.5061058402061462, "Value Loss": 0.006361006293445826, "_runtime": 6983.839823484421, "_timestamp": 1585604353.472693, "_step": 315}
{"Episode reward": -99.41070675846284, "Episode length": 999, "Policy Loss": -0.5084306001663208, "Value Loss": 0.0064532021060585976, "_runtime": 6984.933772325516, "_timestamp": 1585604354.5666418, "_step": 316}
{"Episode reward": 26.348255634422742, "Episode length": 738, "Policy Loss": 0.2961937189102173, "Value Loss": 13.534735679626465, "_runtime": 6985.3115446567535, "_timestamp": 1585604354.9444141, "_step": 317}
{"Episode reward": 79.28786465963347, "Episode length": 208, "Policy Loss": 2.4938697814941406, "Value Loss": 48.005149841308594, "_runtime": 6986.864004611969, "_timestamp": 1585604356.496874, "_step": 318}
{"Episode reward": -99.73790557407634, "Episode length": 999, "Policy Loss": -0.5332708358764648, "Value Loss": 0.006940807681530714, "_runtime": 6988.423834323883, "_timestamp": 1585604358.0567038, "_step": 319}
{"Episode reward": -99.41827192601204, "Episode length": 999, "Policy Loss": -0.5318388342857361, "Value Loss": 0.0071390713565051556, "_runtime": 6989.9071617126465, "_timestamp": 1585604359.5400312, "_step": 320}
{"Episode reward": -99.65620456347685, "Episode length": 999, "Policy Loss": -0.5420176982879639, "Value Loss": 0.00732502480968833, "_runtime": 6991.485780715942, "_timestamp": 1585604361.1186502, "_step": 321}
{"Episode reward": -99.72205633314303, "Episode length": 999, "Policy Loss": -0.5457662343978882, "Value Loss": 0.007426699623465538, "_runtime": 6993.031898021698, "_timestamp": 1585604362.6647675, "_step": 322}
{"Episode reward": -99.81019462069823, "Episode length": 999, "Policy Loss": -0.5475932359695435, "Value Loss": 0.007476761471480131, "_runtime": 6994.561341285706, "_timestamp": 1585604364.1942108, "_step": 323}
{"Episode reward": -99.65763520418993, "Episode length": 999, "Policy Loss": -0.5468195080757141, "Value Loss": 0.007449503988027573, "_runtime": 6996.134448766708, "_timestamp": 1585604365.7673182, "_step": 324}
{"Episode reward": -99.63665345324561, "Episode length": 999, "Policy Loss": -0.5474712252616882, "Value Loss": 0.007384928409010172, "_runtime": 6997.689343452454, "_timestamp": 1585604367.322213, "_step": 325}
{"Episode reward": -99.70825910927385, "Episode length": 999, "Policy Loss": -0.5403910875320435, "Value Loss": 0.007283960003405809, "_runtime": 6999.232942342758, "_timestamp": 1585604368.8658118, "_step": 326}
{"Episode reward": -99.44062707135899, "Episode length": 999, "Policy Loss": -0.5383328795433044, "Value Loss": 0.007123761344701052, "_runtime": 7000.30393075943, "_timestamp": 1585604369.9368002, "_step": 327}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": 0.4228402376174927, "Value Loss": 14.840988159179688, "_runtime": 7001.786344766617, "_timestamp": 1585604371.4192142, "_step": 328}
{"Episode reward": 5.519637048152433, "Episode length": 945, "Policy Loss": 0.09532248973846436, "Value Loss": 10.571337699890137, "_runtime": 7002.63995885849, "_timestamp": 1585604372.2728283, "_step": 329}
{"Episode reward": 46.435483336448186, "Episode length": 536, "Policy Loss": 0.6093301773071289, "Value Loss": 18.632783889770508, "_runtime": 7004.186926841736, "_timestamp": 1585604373.8197963, "_step": 330}
{"Episode reward": -99.54575505170949, "Episode length": 999, "Policy Loss": -0.5222352743148804, "Value Loss": 0.006718181539326906, "_runtime": 7005.749203443527, "_timestamp": 1585604375.382073, "_step": 331}
{"Episode reward": -99.81618804931502, "Episode length": 999, "Policy Loss": -0.5177825689315796, "Value Loss": 0.006669102236628532, "_runtime": 7007.265473842621, "_timestamp": 1585604376.8983433, "_step": 332}
{"Episode reward": -99.59472863648996, "Episode length": 999, "Policy Loss": -0.5134046077728271, "Value Loss": 0.006545923184603453, "_runtime": 7008.421516180038, "_timestamp": 1585604378.0543857, "_step": 333}
{"Episode reward": 26.520614655964422, "Episode length": 736, "Policy Loss": 0.28224503993988037, "Value Loss": 13.5715970993042, "_runtime": 7009.97479057312, "_timestamp": 1585604379.60766, "_step": 334}
{"Episode reward": -99.85345882123663, "Episode length": 999, "Policy Loss": -0.508360743522644, "Value Loss": 0.006331078242510557, "_runtime": 7011.107100009918, "_timestamp": 1585604380.7399695, "_step": 335}
{"Episode reward": 29.543786615133016, "Episode length": 705, "Policy Loss": 0.47579774260520935, "Value Loss": 14.168255805969238, "_runtime": 7012.654778957367, "_timestamp": 1585604382.2876484, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5006768107414246, "Value Loss": 0.006130179390311241, "_runtime": 7014.220442771912, "_timestamp": 1585604383.8533123, "_step": 337}
{"Episode reward": -99.56152436122655, "Episode length": 999, "Policy Loss": -0.4933083951473236, "Value Loss": 0.0059916358441114426, "_runtime": 7015.740521907806, "_timestamp": 1585604385.3733914, "_step": 338}
{"Episode reward": -99.46723785516669, "Episode length": 999, "Policy Loss": -0.4849912226200104, "Value Loss": 0.005842454265803099, "_runtime": 7016.719614028931, "_timestamp": 1585604386.3524835, "_step": 339}
{"Episode reward": 38.997372777827835, "Episode length": 613, "Policy Loss": 0.47261154651641846, "Value Loss": 16.29425048828125, "_runtime": 7017.310604333878, "_timestamp": 1585604386.9434738, "_step": 340}
{"Episode reward": 64.5850768420743, "Episode length": 356, "Policy Loss": 1.240372657775879, "Value Loss": 28.340553283691406, "_runtime": 7018.85261964798, "_timestamp": 1585604388.4854891, "_step": 341}
{"Episode reward": -99.66057209603031, "Episode length": 999, "Policy Loss": -0.4799381196498871, "Value Loss": 0.0056073302403092384, "_runtime": 7020.397012710571, "_timestamp": 1585604390.0298822, "_step": 342}
{"Episode reward": -99.72043344208947, "Episode length": 999, "Policy Loss": -0.48259541392326355, "Value Loss": 0.005587723571807146, "_runtime": 7021.895508527756, "_timestamp": 1585604391.528378, "_step": 343}
{"Episode reward": -99.75656210942985, "Episode length": 999, "Policy Loss": -0.4826195240020752, "Value Loss": 0.005526273511350155, "_runtime": 7023.463054418564, "_timestamp": 1585604393.095924, "_step": 344}
{"Episode reward": -99.83588181102975, "Episode length": 999, "Policy Loss": -0.4841889441013336, "Value Loss": 0.00544351851567626, "_runtime": 7025.038647174835, "_timestamp": 1585604394.6715167, "_step": 345}
{"Episode reward": -99.66510473512905, "Episode length": 999, "Policy Loss": -0.4832497537136078, "Value Loss": 0.005311892833560705, "_runtime": 7026.568667173386, "_timestamp": 1585604396.2015367, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4796525239944458, "Value Loss": 0.005188331473618746, "_runtime": 7027.718662023544, "_timestamp": 1585604397.3515315, "_step": 347}
{"Episode reward": 26.437670594081183, "Episode length": 736, "Policy Loss": 0.5721778273582458, "Value Loss": 13.572709083557129, "_runtime": 7029.287353992462, "_timestamp": 1585604398.9202235, "_step": 348}
{"Episode reward": -99.8094900774057, "Episode length": 999, "Policy Loss": -0.47132277488708496, "Value Loss": 0.004910418298095465, "_runtime": 7030.404825687408, "_timestamp": 1585604400.0376952, "_step": 349}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 0.48429372906684875, "Value Loss": 14.030304908752441, "_runtime": 7031.191996097565, "_timestamp": 1585604400.8248656, "_step": 350}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 0.8062199354171753, "Value Loss": 19.740474700927734, "_runtime": 7032.341270208359, "_timestamp": 1585604401.9741397, "_step": 351}
{"Episode reward": 27.58208592128925, "Episode length": 730, "Policy Loss": 0.40322592854499817, "Value Loss": 13.684539794921875, "_runtime": 7033.916902303696, "_timestamp": 1585604403.5497718, "_step": 352}
{"Episode reward": -99.82318777525657, "Episode length": 999, "Policy Loss": -0.4682568311691284, "Value Loss": 0.004695297218859196, "_runtime": 7034.885197877884, "_timestamp": 1585604404.5180674, "_step": 353}
{"Episode reward": 37.17896553834373, "Episode length": 629, "Policy Loss": 0.6843511462211609, "Value Loss": 15.881178855895996, "_runtime": 7036.415624856949, "_timestamp": 1585604406.0484943, "_step": 354}
{"Episode reward": -99.73860062744795, "Episode length": 999, "Policy Loss": -0.4629046320915222, "Value Loss": 0.0047051808796823025, "_runtime": 7037.1742696762085, "_timestamp": 1585604406.8071392, "_step": 355}
{"Episode reward": 52.92653771208094, "Episode length": 471, "Policy Loss": 0.8898390531539917, "Value Loss": 21.207000732421875, "_runtime": 7038.707777500153, "_timestamp": 1585604408.340647, "_step": 356}
{"Episode reward": -99.80068928303523, "Episode length": 999, "Policy Loss": -0.474856436252594, "Value Loss": 0.004767475184053183, "_runtime": 7040.274421215057, "_timestamp": 1585604409.9072907, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4810374677181244, "Value Loss": 0.004795345477759838, "_runtime": 7041.7822597026825, "_timestamp": 1585604411.4151292, "_step": 358}
{"Episode reward": -99.8015466491212, "Episode length": 999, "Policy Loss": -0.47684618830680847, "Value Loss": 0.004778576083481312, "_runtime": 7043.326569318771, "_timestamp": 1585604412.9594388, "_step": 359}
{"Episode reward": -99.6819811445647, "Episode length": 999, "Policy Loss": -0.47525954246520996, "Value Loss": 0.004728637170046568, "_runtime": 7043.999812364578, "_timestamp": 1585604413.6326818, "_step": 360}
{"Episode reward": 59.083780010696195, "Episode length": 410, "Policy Loss": 1.1359113454818726, "Value Loss": 24.361583709716797, "_runtime": 7045.200234174728, "_timestamp": 1585604414.8331037, "_step": 361}
{"Episode reward": 23.943096538423603, "Episode length": 762, "Policy Loss": 0.37411123514175415, "Value Loss": 13.11008071899414, "_runtime": 7045.980638504028, "_timestamp": 1585604415.613508, "_step": 362}
{"Episode reward": 52.062238734960154, "Episode length": 480, "Policy Loss": 1.1623761653900146, "Value Loss": 20.809389114379883, "_runtime": 7047.5012550354, "_timestamp": 1585604417.1341245, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48827579617500305, "Value Loss": 0.004846400581300259, "_runtime": 7048.32887506485, "_timestamp": 1585604417.9617445, "_step": 364}
{"Episode reward": 47.69996040910436, "Episode length": 524, "Policy Loss": 1.1891993284225464, "Value Loss": 19.062118530273438, "_runtime": 7049.839281320572, "_timestamp": 1585604419.4721508, "_step": 365}
{"Episode reward": -99.7071687305565, "Episode length": 999, "Policy Loss": -0.4948031008243561, "Value Loss": 0.005024747457355261, "_runtime": 7051.384744882584, "_timestamp": 1585604421.0176144, "_step": 366}
{"Episode reward": -99.7070493819411, "Episode length": 999, "Policy Loss": -0.4978877604007721, "Value Loss": 0.0050987438298761845, "_runtime": 7052.896491527557, "_timestamp": 1585604422.529361, "_step": 367}
{"Episode reward": -99.59033116635263, "Episode length": 999, "Policy Loss": -0.4944698214530945, "Value Loss": 0.0051218802109360695, "_runtime": 7054.457672834396, "_timestamp": 1585604424.0905423, "_step": 368}
{"Episode reward": -99.84367335000867, "Episode length": 999, "Policy Loss": -0.4955579340457916, "Value Loss": 0.005126909352838993, "_runtime": 7056.020791292191, "_timestamp": 1585604425.6536608, "_step": 369}
{"Episode reward": -99.42486701581954, "Episode length": 999, "Policy Loss": -0.49627208709716797, "Value Loss": 0.005060852505266666, "_runtime": 7057.617960691452, "_timestamp": 1585604427.2508302, "_step": 370}
{"Episode reward": -99.66262302633702, "Episode length": 999, "Policy Loss": -0.49206939339637756, "Value Loss": 0.004999247379601002, "_runtime": 7058.436897516251, "_timestamp": 1585604428.069767, "_step": 371}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 0.8712925314903259, "Value Loss": 19.208717346191406, "_runtime": 7060.0024082660675, "_timestamp": 1585604429.6352777, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4889143705368042, "Value Loss": 0.004885246977210045, "_runtime": 7061.56907749176, "_timestamp": 1585604431.201947, "_step": 373}
{"Episode reward": -99.70730492547015, "Episode length": 999, "Policy Loss": -0.4850599467754364, "Value Loss": 0.004815861117094755, "_runtime": 7062.601143121719, "_timestamp": 1585604432.2340126, "_step": 374}
{"Episode reward": 32.96604576371564, "Episode length": 671, "Policy Loss": 0.493380606174469, "Value Loss": 14.887357711791992, "_runtime": 7064.1623656749725, "_timestamp": 1585604433.7952352, "_step": 375}
{"Episode reward": -99.82211737541807, "Episode length": 999, "Policy Loss": -0.47741174697875977, "Value Loss": 0.004691107198596001, "_runtime": 7065.307276725769, "_timestamp": 1585604434.9401462, "_step": 376}
{"Episode reward": 27.233881192654238, "Episode length": 729, "Policy Loss": 0.463596373796463, "Value Loss": 13.703390121459961, "_runtime": 7066.178761005402, "_timestamp": 1585604435.8116305, "_step": 377}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 0.7002419829368591, "Value Loss": 17.837535858154297, "_runtime": 7067.73818731308, "_timestamp": 1585604437.3710568, "_step": 378}
{"Episode reward": -99.81593366265157, "Episode length": 999, "Policy Loss": -0.4733538031578064, "Value Loss": 0.004621842876076698, "_runtime": 7069.275424718857, "_timestamp": 1585604438.9082942, "_step": 379}
{"Episode reward": -99.75170768992835, "Episode length": 999, "Policy Loss": -0.4773445129394531, "Value Loss": 0.004609465599060059, "_runtime": 7070.742860078812, "_timestamp": 1585604440.3757296, "_step": 380}
{"Episode reward": 3.4813746882381906, "Episode length": 967, "Policy Loss": 0.4391290843486786, "Value Loss": 10.33184814453125, "_runtime": 7072.3100254535675, "_timestamp": 1585604441.942895, "_step": 381}
{"Episode reward": -99.66765671942709, "Episode length": 999, "Policy Loss": -0.47072479128837585, "Value Loss": 0.004548497963696718, "_runtime": 7073.471670389175, "_timestamp": 1585604443.1045399, "_step": 382}
{"Episode reward": 26.399999999999906, "Episode length": 736, "Policy Loss": 0.41099387407302856, "Value Loss": 13.573225975036621, "_runtime": 7075.022021055222, "_timestamp": 1585604444.6548905, "_step": 383}
{"Episode reward": -99.65075943807466, "Episode length": 999, "Policy Loss": -0.4670109450817108, "Value Loss": 0.004485149867832661, "_runtime": 7075.966042041779, "_timestamp": 1585604445.5989115, "_step": 384}
{"Episode reward": 40.790059509407165, "Episode length": 595, "Policy Loss": 0.6419040560722351, "Value Loss": 16.788745880126953, "_runtime": 7077.503389120102, "_timestamp": 1585604447.1362586, "_step": 385}
{"Episode reward": -99.84110262393811, "Episode length": 999, "Policy Loss": -0.46581515669822693, "Value Loss": 0.004464919678866863, "_runtime": 7078.638494253159, "_timestamp": 1585604448.2713637, "_step": 386}
{"Episode reward": 27.52234952514975, "Episode length": 725, "Policy Loss": 0.854083776473999, "Value Loss": 13.779176712036133, "_runtime": 7079.838743686676, "_timestamp": 1585604449.4716132, "_step": 387}
{"Episode reward": 21.618106006249036, "Episode length": 784, "Policy Loss": 0.3626313805580139, "Value Loss": 12.742546081542969, "_runtime": 7080.676402330399, "_timestamp": 1585604450.3092718, "_step": 388}
{"Episode reward": 50.24115096181588, "Episode length": 498, "Policy Loss": 0.8459738492965698, "Value Loss": 20.057891845703125, "_runtime": 7082.207190275192, "_timestamp": 1585604451.8400598, "_step": 389}
{"Episode reward": -99.6870830154964, "Episode length": 999, "Policy Loss": -0.47023332118988037, "Value Loss": 0.004590734839439392, "_runtime": 7083.7436628341675, "_timestamp": 1585604453.3765323, "_step": 390}
{"Episode reward": -99.80033833421628, "Episode length": 999, "Policy Loss": -0.4784765839576721, "Value Loss": 0.004661956802010536, "_runtime": 7084.991803884506, "_timestamp": 1585604454.6246734, "_step": 391}
{"Episode reward": 17.69883353989613, "Episode length": 825, "Policy Loss": 0.4099920988082886, "Value Loss": 12.109305381774902, "_runtime": 7086.554551362991, "_timestamp": 1585604456.1874208, "_step": 392}
{"Episode reward": -99.74654689999157, "Episode length": 999, "Policy Loss": -0.4842909872531891, "Value Loss": 0.004723411053419113, "_runtime": 7088.104001998901, "_timestamp": 1585604457.7368715, "_step": 393}
{"Episode reward": -99.75234748099325, "Episode length": 999, "Policy Loss": -0.4804006516933441, "Value Loss": 0.004730073735117912, "_runtime": 7089.639307975769, "_timestamp": 1585604459.2721775, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4813613295555115, "Value Loss": 0.004710661247372627, "_runtime": 7090.432604312897, "_timestamp": 1585604460.0654738, "_step": 395}
{"Episode reward": 49.934920349344175, "Episode length": 502, "Policy Loss": 0.9106861352920532, "Value Loss": 19.897798538208008, "_runtime": 7091.993252754211, "_timestamp": 1585604461.6261222, "_step": 396}
{"Episode reward": -99.86554040908673, "Episode length": 999, "Policy Loss": -0.4783720374107361, "Value Loss": 0.004660128615796566, "_runtime": 7093.555691957474, "_timestamp": 1585604463.1885614, "_step": 397}
{"Episode reward": -99.80114087015251, "Episode length": 999, "Policy Loss": -0.4782741069793701, "Value Loss": 0.004636991769075394, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657, 0.453347384929657]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.453347384929657, -0.12475782632827759, 0.2038317322731018, 0.5324212908744812, 0.8610108494758606, 1.1896004676818848, 1.5181899070739746, 1.8467795848846436, 2.1753690242767334, 2.5039584636688232, 2.832548141479492, 3.161137819290161, 3.489727258682251, 3.818316698074341, 4.146906852722168, 4.475496292114258, 4.804085731506348, 5.1326751708984375, 5.461264610290527, 5.789854526519775, 6.118443965911865, 6.447033405303955, 6.775623321533203, 7.104212760925293, 7.432802200317383, 7.761391639709473, 8.089981079101562, 8.418570518493652, 8.747160911560059, 9.075750350952148, 9.404339790344238, 9.732929229736328, 10.061518669128418, 10.390108108520508, 10.718697547912598, 11.047286987304688, 11.375876426696777, 11.704466819763184, 12.033056259155273, 12.361645698547363, 12.690235137939453, 13.018824577331543, 13.347414016723633, 13.676003456115723, 14.004593849182129, 14.333183288574219, 14.661772727966309, 14.990362167358398, 15.318951606750488, 15.647541999816895, 15.976130485534668, 16.304719924926758, 16.63330841064453, 16.961898803710938, 17.29048728942871, 17.619077682495117, 17.947668075561523, 18.276256561279297, 18.604846954345703, 18.933435440063477, 19.262025833129883, 19.590614318847656, 19.919204711914062, 20.247793197631836, 20.576383590698242]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.021554600447416306, 0.009599164128303528, 0.04075292870402336, 0.0719066858291626, 0.10306045413017273, 0.13421422243118286, 0.1653679758310318, 0.19652174413204193, 0.22767551243305206, 0.2588292956352234, 0.2899830639362335, 0.32113683223724365, 0.3522905707359314, 0.38344433903694153, 0.41459810733795166, 0.4457518756389618, 0.4769056439399719, 0.5080593824386597, 0.5392131805419922, 0.5703669190406799, 0.6015207171440125, 0.6326744556427002, 0.6638282537460327, 0.6949819922447205, 0.7261357307434082, 0.7572895288467407, 0.7884432673454285, 0.819597065448761, 0.8507508039474487, 0.8819046020507812, 0.913058340549469, 0.9442121386528015, 0.9753658771514893, 1.0065196752548218, 1.0376733541488647, 1.0688271522521973, 1.0999809503555298, 1.1311347484588623, 1.1622884273529053, 1.1934422254562378, 1.2245960235595703, 1.2557497024536133, 1.2869035005569458, 1.3180572986602783, 1.3492110967636108, 1.3803647756576538, 1.4115185737609863, 1.4426723718643188, 1.4738260507583618, 1.5049798488616943, 1.5361336469650269, 1.5672874450683594, 1.5984411239624023, 1.6295949220657349, 1.6607487201690674, 1.6919025182724, 1.7230561971664429, 1.7542099952697754, 1.785363793373108, 1.8165174722671509, 1.8476712703704834, 1.878825068473816, 1.9099788665771484, 1.9411325454711914, 1.972286343574524]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [16.0, 4.0, 0.0, 0.0, 0.0, 0.0, 14.0, 43.0, 23.0, 0.0, 8.0, 344.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 4.0, 3.0, 8.0, 6.0, 5.0, 5.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.955739140510559, -1.7824143171310425, -1.6090893745422363, -1.4357645511627197, -1.2624397277832031, -1.089114785194397, -0.9157899618148804, -0.7424650192260742, -0.5691401958465576, -0.395815372467041, -0.22249042987823486, -0.04916560649871826, 0.12415921688079834, 0.29748404026031494, 0.47080910205841064, 0.6441339254379272, 0.8174587488174438, 0.9907835721969604, 1.164108395576477, 1.3374334573745728, 1.5107582807540894, 1.684083104133606, 1.8574079275131226, 2.0307326316833496, 2.2040576934814453, 2.377382755279541, 2.5507073402404785, 2.724032402038574, 2.89735746383667, 3.0706820487976074, 3.244007110595703, 3.4173316955566406, 3.5906567573547363, 3.763981819152832, 3.9373064041137695, 4.110631465911865, 4.283956050872803, 4.457281112670898, 4.630606174468994, 4.803930759429932, 4.977255821228027, 5.150580406188965, 5.3239054679870605, 5.497230529785156, 5.670555114746094, 5.8438801765441895, 6.017204761505127, 6.190529823303223, 6.36385440826416, 6.537179946899414, 6.710504531860352, 6.883829116821289, 7.057153701782227, 7.2304792404174805, 7.403803825378418, 7.5771284103393555, 7.750453948974609, 7.923778533935547, 8.097103118896484, 8.270428657531738, 8.443753242492676, 8.617077827453613, 8.79040241241455, 8.963727951049805, 9.137052536010742]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8242661356925964, -0.7225854396820068, -0.620904803276062, -0.5192241072654724, -0.4175434410572052, -0.315862774848938, -0.2141820788383484, -0.11250144243240356, -0.010820746421813965, 0.09085994958877563, 0.19254058599472046, 0.2942212224006653, 0.39590197801589966, 0.4975826144218445, 0.5992632508277893, 0.7009440064430237, 0.8026246428489685, 0.9043052792549133, 1.005985975265503, 1.1076667308807373, 1.2093472480773926, 1.311028003692627, 1.4127085208892822, 1.5143892765045166, 1.616070032119751, 1.7177505493164062, 1.8194313049316406, 1.921112060546875, 2.0227925777435303, 2.1244733333587646, 2.226154088973999, 2.3278346061706543, 2.4295153617858887, 2.531196117401123, 2.6328766345977783, 2.7345573902130127, 2.836238145828247, 2.9379186630249023, 3.0395994186401367, 3.141280174255371, 3.2429606914520264, 3.3446414470672607, 3.446322202682495, 3.5480029582977295, 3.6496832370758057, 3.75136399269104, 3.8530447483062744, 3.954725503921509, 4.056406497955322, 4.158087253570557, 4.259767532348633, 4.361448287963867, 4.463129043579102, 4.564809799194336, 4.66649055480957, 4.768171310424805, 4.869851589202881, 4.971532344818115, 5.07321310043335, 5.174893856048584, 5.276574611663818, 5.378255367279053, 5.479935646057129, 5.581616401672363, 5.683297157287598]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 26.0, 12.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], "bins": [-2.2103333473205566, -2.169938087463379, -2.129542827606201, -2.0891475677490234, -2.0487523078918457, -2.008357048034668, -1.9679619073867798, -1.927566647529602, -1.8871715068817139, -1.8467762470245361, -1.8063809871673584, -1.7659857273101807, -1.725590467453003, -1.6851952075958252, -1.6447999477386475, -1.6044048070907593, -1.5640095472335815, -1.5236142873764038, -1.4832191467285156, -1.442823886871338, -1.4024286270141602, -1.3620333671569824, -1.3216381072998047, -1.281242847442627, -1.2408475875854492, -1.200452446937561, -1.1600571870803833, -1.1196619272232056, -1.0792666673660278, -1.03887140750885, -0.9984762668609619, -0.9580810070037842, -0.9176857471466064, -0.8772904872894287, -0.836895227432251, -0.7965000867843628, -0.7561048269271851, -0.7157095670700073, -0.6753143072128296, -0.6349190473556519, -0.5945239067077637, -0.5541286468505859, -0.5137333869934082, -0.47333812713623047, -0.43294286727905273, -0.392547607421875, -0.3521524667739868, -0.3117572069168091, -0.27136194705963135, -0.2309666872024536, -0.19057154655456543, -0.1501762866973877, -0.10978102684020996, -0.06938576698303223, -0.028990507125854492, 0.011404752731323242, 0.05180001258850098, 0.09219527244567871, 0.13259053230285645, 0.17298555374145508, 0.2133808135986328, 0.25377607345581055, 0.2941713333129883, 0.334566593170166, 0.37496185302734375]}, "_runtime": 7094.315772771835, "_timestamp": 1585604463.9486423, "_step": 398}
{"Episode reward": 51.15466134548146, "Episode length": 489, "Policy Loss": 0.9023919701576233, "Value Loss": 20.426790237426758, "_runtime": 7094.861626625061, "_timestamp": 1585604464.494496, "_step": 399}
{"Episode reward": 67.22658217167464, "Episode length": 328, "Policy Loss": 1.7203850746154785, "Value Loss": 30.451045989990234, "_runtime": 7096.0241758823395, "_timestamp": 1585604465.6570454, "_step": 400}
{"Episode reward": 24.944531006342714, "Episode length": 752, "Policy Loss": 0.5096468925476074, "Value Loss": 13.284296989440918, "_runtime": 7097.55216050148, "_timestamp": 1585604467.18503, "_step": 401}
{"Episode reward": -99.80000150212878, "Episode length": 999, "Policy Loss": -0.487058162689209, "Value Loss": 0.0048897890374064445, "_runtime": 7098.00124168396, "_timestamp": 1585604467.6341112, "_step": 402}
{"Episode reward": 71.39999999999986, "Episode length": 286, "Policy Loss": 1.8592934608459473, "Value Loss": 34.92058181762695, "_runtime": 7099.520332574844, "_timestamp": 1585604469.153202, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5055484771728516, "Value Loss": 0.005239496473222971, "_runtime": 7101.060331106186, "_timestamp": 1585604470.6932006, "_step": 404}
{"Episode reward": -99.73364775928064, "Episode length": 999, "Policy Loss": -0.5118798613548279, "Value Loss": 0.0054115112870931625, "_runtime": 7101.92945933342, "_timestamp": 1585604471.5623288, "_step": 405}
{"Episode reward": 41.925186243839015, "Episode length": 583, "Policy Loss": 0.8508152365684509, "Value Loss": 17.132638931274414, "_runtime": 7103.470976829529, "_timestamp": 1585604473.1038463, "_step": 406}
{"Episode reward": -99.70403527496244, "Episode length": 999, "Policy Loss": -0.5271880030632019, "Value Loss": 0.005702299065887928, "_runtime": 7104.3878173828125, "_timestamp": 1585604474.0206869, "_step": 407}
{"Episode reward": 44.81120204953426, "Episode length": 553, "Policy Loss": 0.7179438471794128, "Value Loss": 18.061376571655273, "_runtime": 7105.906952381134, "_timestamp": 1585604475.5398219, "_step": 408}
{"Episode reward": -99.68600477068546, "Episode length": 999, "Policy Loss": -0.5369343757629395, "Value Loss": 0.005973779130727053, "_runtime": 7107.464331626892, "_timestamp": 1585604477.097201, "_step": 409}
{"Episode reward": -99.57834492719127, "Episode length": 999, "Policy Loss": -0.5465523600578308, "Value Loss": 0.00606926204636693, "_runtime": 7108.838558673859, "_timestamp": 1585604478.4714282, "_step": 410}
{"Episode reward": 9.493690349069368, "Episode length": 906, "Policy Loss": 0.23559491336345673, "Value Loss": 11.026351928710938, "_runtime": 7110.391007184982, "_timestamp": 1585604480.0238767, "_step": 411}
{"Episode reward": -99.88595872486336, "Episode length": 999, "Policy Loss": -0.549656867980957, "Value Loss": 0.006205953657627106, "_runtime": 7111.960960149765, "_timestamp": 1585604481.5938296, "_step": 412}
{"Episode reward": -99.75562033848698, "Episode length": 999, "Policy Loss": -0.5570569634437561, "Value Loss": 0.0062081716023385525, "_runtime": 7113.465556144714, "_timestamp": 1585604483.0984256, "_step": 413}
{"Episode reward": 2.734776377935276, "Episode length": 974, "Policy Loss": 0.14021259546279907, "Value Loss": 10.256950378417969, "_runtime": 7114.251026630402, "_timestamp": 1585604483.883896, "_step": 414}
{"Episode reward": 51.42172424187842, "Episode length": 488, "Policy Loss": 0.9065151810646057, "Value Loss": 20.46573829650879, "_runtime": 7115.818236589432, "_timestamp": 1585604485.451106, "_step": 415}
{"Episode reward": -99.48498587943476, "Episode length": 999, "Policy Loss": -0.5493462085723877, "Value Loss": 0.006198425777256489, "_runtime": 7116.632462263107, "_timestamp": 1585604486.2653317, "_step": 416}
{"Episode reward": 49.419841887335785, "Episode length": 507, "Policy Loss": 0.793684184551239, "Value Loss": 19.698904037475586, "_runtime": 7117.433240175247, "_timestamp": 1585604487.0661097, "_step": 417}
{"Episode reward": 47.170264614186706, "Episode length": 530, "Policy Loss": 0.7408124804496765, "Value Loss": 18.84420394897461, "_runtime": 7118.993482589722, "_timestamp": 1585604488.626352, "_step": 418}
{"Episode reward": -99.71310980468849, "Episode length": 999, "Policy Loss": -0.56186443567276, "Value Loss": 0.006427065469324589, "_runtime": 7119.896713733673, "_timestamp": 1585604489.5295832, "_step": 419}
{"Episode reward": 41.454583226795684, "Episode length": 586, "Policy Loss": 1.3988428115844727, "Value Loss": 17.043819427490234, "_runtime": 7121.402787685394, "_timestamp": 1585604491.0356572, "_step": 420}
{"Episode reward": -99.72330044305279, "Episode length": 999, "Policy Loss": -0.568941056728363, "Value Loss": 0.0066150822676718235, "_runtime": 7122.957655906677, "_timestamp": 1585604492.5905254, "_step": 421}
{"Episode reward": -99.84822719246009, "Episode length": 999, "Policy Loss": -0.5733922123908997, "Value Loss": 0.006684737745672464, "_runtime": 7124.212558507919, "_timestamp": 1585604493.845428, "_step": 422}
{"Episode reward": 17.649552204832844, "Episode length": 824, "Policy Loss": 0.21948471665382385, "Value Loss": 12.122761726379395, "_runtime": 7125.758054733276, "_timestamp": 1585604495.3909242, "_step": 423}
{"Episode reward": -99.7046649989658, "Episode length": 999, "Policy Loss": -0.5713940262794495, "Value Loss": 0.006710469722747803, "_runtime": 7126.727733373642, "_timestamp": 1585604496.3606029, "_step": 424}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 0.5236809253692627, "Value Loss": 16.481346130371094, "_runtime": 7128.226227760315, "_timestamp": 1585604497.8590972, "_step": 425}
{"Episode reward": 5.6000000000010886, "Episode length": 944, "Policy Loss": 0.19566725194454193, "Value Loss": 10.582572937011719, "_runtime": 7129.770864248276, "_timestamp": 1585604499.4037337, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5802604556083679, "Value Loss": 0.00676900427788496, "_runtime": 7131.297530412674, "_timestamp": 1585604500.9304, "_step": 427}
{"Episode reward": -99.74850999284396, "Episode length": 999, "Policy Loss": -0.575515627861023, "Value Loss": 0.006743237841874361, "_runtime": 7132.850234270096, "_timestamp": 1585604502.4831038, "_step": 428}
{"Episode reward": -99.69815089490591, "Episode length": 999, "Policy Loss": -0.5669203996658325, "Value Loss": 0.006678347010165453, "_runtime": 7134.391856431961, "_timestamp": 1585604504.024726, "_step": 429}
{"Episode reward": -99.8848222562098, "Episode length": 999, "Policy Loss": -0.5694801807403564, "Value Loss": 0.00658810418099165, "_runtime": 7135.884318828583, "_timestamp": 1585604505.5171883, "_step": 430}
{"Episode reward": 4.077912753821593, "Episode length": 960, "Policy Loss": 0.17286555469036102, "Value Loss": 10.406387329101562, "_runtime": 7137.185328722, "_timestamp": 1585604506.8181982, "_step": 431}
{"Episode reward": 17.20000000000043, "Episode length": 828, "Policy Loss": 0.24976502358913422, "Value Loss": 12.064373016357422, "_runtime": 7138.748923540115, "_timestamp": 1585604508.381793, "_step": 432}
{"Episode reward": -99.76606047153335, "Episode length": 999, "Policy Loss": -0.5571106672286987, "Value Loss": 0.0062499623745679855, "_runtime": 7140.315190792084, "_timestamp": 1585604509.9480603, "_step": 433}
{"Episode reward": -99.76063140975172, "Episode length": 999, "Policy Loss": -0.5493464469909668, "Value Loss": 0.006137099117040634, "_runtime": 7140.956198453903, "_timestamp": 1585604510.589068, "_step": 434}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.2889130115509033, "Value Loss": 25.283226013183594, "_runtime": 7142.50044465065, "_timestamp": 1585604512.1333141, "_step": 435}
{"Episode reward": -99.74007759806561, "Episode length": 999, "Policy Loss": -0.5409426093101501, "Value Loss": 0.005960190203040838, "_runtime": 7143.3699831962585, "_timestamp": 1585604513.0028527, "_step": 436}
{"Episode reward": 46.05646166966714, "Episode length": 540, "Policy Loss": 0.6831238865852356, "Value Loss": 18.495960235595703, "_runtime": 7144.881162643433, "_timestamp": 1585604514.5140321, "_step": 437}
{"Episode reward": -99.85899728843802, "Episode length": 999, "Policy Loss": -0.538525402545929, "Value Loss": 0.0058930483646690845, "_runtime": 7146.450115203857, "_timestamp": 1585604516.0829847, "_step": 438}
{"Episode reward": -99.51348645598492, "Episode length": 999, "Policy Loss": -0.5322115421295166, "Value Loss": 0.005825221538543701, "_runtime": 7147.972703695297, "_timestamp": 1585604517.6055732, "_step": 439}
{"Episode reward": -99.7293156576329, "Episode length": 999, "Policy Loss": -0.5347625017166138, "Value Loss": 0.005756707396358252, "_runtime": 7149.524867773056, "_timestamp": 1585604519.1577373, "_step": 440}
{"Episode reward": -99.71857188700093, "Episode length": 999, "Policy Loss": -0.5275924205780029, "Value Loss": 0.005637528840452433, "_runtime": 7150.704293489456, "_timestamp": 1585604520.337163, "_step": 441}
{"Episode reward": 27.598838172852837, "Episode length": 725, "Policy Loss": 0.43640053272247314, "Value Loss": 13.778156280517578, "_runtime": 7151.706743717194, "_timestamp": 1585604521.3396132, "_step": 442}
{"Episode reward": 36.09999999999937, "Episode length": 639, "Policy Loss": 0.5084571242332458, "Value Loss": 15.631878852844238, "_runtime": 7153.2660665512085, "_timestamp": 1585604522.898936, "_step": 443}
{"Episode reward": -99.87782267862791, "Episode length": 999, "Policy Loss": -0.5172926783561707, "Value Loss": 0.005365636199712753, "_runtime": 7154.802404642105, "_timestamp": 1585604524.4352741, "_step": 444}
{"Episode reward": -99.81957025527814, "Episode length": 999, "Policy Loss": -0.5074321031570435, "Value Loss": 0.0052874451503157616, "_runtime": 7156.194369792938, "_timestamp": 1585604525.8272393, "_step": 445}
{"Episode reward": 8.391681296286166, "Episode length": 917, "Policy Loss": 0.23564647138118744, "Value Loss": 10.894585609436035, "_runtime": 7157.754271745682, "_timestamp": 1585604527.3871412, "_step": 446}
{"Episode reward": -99.80335947014251, "Episode length": 999, "Policy Loss": -0.4981857240200043, "Value Loss": 0.005105968564748764, "_runtime": 7159.318283557892, "_timestamp": 1585604528.951153, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5015773177146912, "Value Loss": 0.0050051575526595116, "_runtime": 7160.86722445488, "_timestamp": 1585604530.500094, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48628345131874084, "Value Loss": 0.004874257370829582, "_runtime": 7161.3380382061005, "_timestamp": 1585604530.9709077, "_step": 449}
{"Episode reward": 72.89999999999989, "Episode length": 271, "Policy Loss": 2.1928372383117676, "Value Loss": 36.854393005371094, "_runtime": 7162.762882471085, "_timestamp": 1585604532.395752, "_step": 450}
{"Episode reward": 8.677601144743136, "Episode length": 915, "Policy Loss": 0.24411214888095856, "Value Loss": 10.918652534484863, "_runtime": 7164.319598436356, "_timestamp": 1585604533.952468, "_step": 451}
{"Episode reward": -99.68070989756241, "Episode length": 999, "Policy Loss": -0.4869513213634491, "Value Loss": 0.004765237681567669, "_runtime": 7165.81368470192, "_timestamp": 1585604535.4465542, "_step": 452}
{"Episode reward": -99.74979911334674, "Episode length": 999, "Policy Loss": -0.4819453954696655, "Value Loss": 0.004766687750816345, "_runtime": 7166.761999368668, "_timestamp": 1585604536.3948689, "_step": 453}
{"Episode reward": 39.406357081024325, "Episode length": 607, "Policy Loss": 0.5933100581169128, "Value Loss": 16.45652198791504, "_runtime": 7168.318481206894, "_timestamp": 1585604537.9513507, "_step": 454}
{"Episode reward": -99.64126330623264, "Episode length": 999, "Policy Loss": -0.48587897419929504, "Value Loss": 0.004741855897009373, "_runtime": 7169.858451128006, "_timestamp": 1585604539.4913206, "_step": 455}
{"Episode reward": -99.82235335428128, "Episode length": 999, "Policy Loss": -0.48338189721107483, "Value Loss": 0.004728284664452076, "_runtime": 7171.082993268967, "_timestamp": 1585604540.7158628, "_step": 456}
{"Episode reward": 19.385660345084347, "Episode length": 807, "Policy Loss": 0.44176149368286133, "Value Loss": 12.379301071166992, "_runtime": 7172.643745660782, "_timestamp": 1585604542.2766151, "_step": 457}
{"Episode reward": -99.69376592850175, "Episode length": 999, "Policy Loss": -0.48282843828201294, "Value Loss": 0.004644806031137705, "_runtime": 7174.120829105377, "_timestamp": 1585604543.7536986, "_step": 458}
{"Episode reward": 7.533163586911783, "Episode length": 925, "Policy Loss": 0.5472254157066345, "Value Loss": 10.800753593444824, "_runtime": 7175.659783601761, "_timestamp": 1585604545.292653, "_step": 459}
{"Episode reward": -99.72963009162201, "Episode length": 999, "Policy Loss": -0.4763651192188263, "Value Loss": 0.004572389647364616, "_runtime": 7176.747328042984, "_timestamp": 1585604546.3801975, "_step": 460}
{"Episode reward": 31.895532165653606, "Episode length": 684, "Policy Loss": 0.5090632438659668, "Value Loss": 14.604736328125, "_runtime": 7178.2806606292725, "_timestamp": 1585604547.91353, "_step": 461}
{"Episode reward": -99.62137979990663, "Episode length": 999, "Policy Loss": -0.4703691005706787, "Value Loss": 0.004499150440096855, "_runtime": 7179.846283912659, "_timestamp": 1585604549.4791534, "_step": 462}
{"Episode reward": -99.61680519971858, "Episode length": 999, "Policy Loss": -0.4683932960033417, "Value Loss": 0.00444832956418395, "_runtime": 7181.382341623306, "_timestamp": 1585604551.015211, "_step": 463}
{"Episode reward": -99.82686616408033, "Episode length": 999, "Policy Loss": -0.46295151114463806, "Value Loss": 0.0043884203769266605, "_runtime": 7182.909346818924, "_timestamp": 1585604552.5422163, "_step": 464}
{"Episode reward": 0.9529690682901588, "Episode length": 991, "Policy Loss": 0.23712916672229767, "Value Loss": 10.081860542297363, "_runtime": 7183.787416934967, "_timestamp": 1585604553.4202864, "_step": 465}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 0.7704185843467712, "Value Loss": 18.3289852142334, "_runtime": 7185.270350694656, "_timestamp": 1585604554.9032202, "_step": 466}
{"Episode reward": 4.877966543544275, "Episode length": 954, "Policy Loss": 0.2836030125617981, "Value Loss": 10.472747802734375, "_runtime": 7186.835490465164, "_timestamp": 1585604556.46836, "_step": 467}
{"Episode reward": -99.82696891175443, "Episode length": 999, "Policy Loss": -0.4538896679878235, "Value Loss": 0.004230684135109186, "_runtime": 7188.346796989441, "_timestamp": 1585604557.9796665, "_step": 468}
{"Episode reward": -99.87909314371505, "Episode length": 999, "Policy Loss": -0.454328715801239, "Value Loss": 0.004215755965560675, "_runtime": 7189.906914949417, "_timestamp": 1585604559.5397844, "_step": 469}
{"Episode reward": -99.62200528038528, "Episode length": 999, "Policy Loss": -0.4482780396938324, "Value Loss": 0.004160174634307623, "_runtime": 7191.4673483371735, "_timestamp": 1585604561.1002178, "_step": 470}
{"Episode reward": -99.75951610526397, "Episode length": 999, "Policy Loss": -0.44398465752601624, "Value Loss": 0.004088534973561764, "_runtime": 7193.027146577835, "_timestamp": 1585604562.660016, "_step": 471}
{"Episode reward": -99.62926911834954, "Episode length": 999, "Policy Loss": -0.4405653178691864, "Value Loss": 0.003985727671533823, "_runtime": 7194.601207017899, "_timestamp": 1585604564.2340765, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43810194730758667, "Value Loss": 0.0038827129174023867, "_runtime": 7196.167781114578, "_timestamp": 1585604565.8006506, "_step": 473}
{"Episode reward": -99.76681386087881, "Episode length": 999, "Policy Loss": -0.43079903721809387, "Value Loss": 0.0037441160529851913, "_runtime": 7197.70654964447, "_timestamp": 1585604567.3394191, "_step": 474}
{"Episode reward": 4.200000000001168, "Episode length": 958, "Policy Loss": 0.6187335848808289, "Value Loss": 10.429500579833984, "_runtime": 7199.2572700977325, "_timestamp": 1585604568.8901396, "_step": 475}
{"Episode reward": -99.68534357372998, "Episode length": 999, "Policy Loss": -0.41233524680137634, "Value Loss": 0.0034881546162068844, "_runtime": 7200.142107486725, "_timestamp": 1585604569.774977, "_step": 476}
{"Episode reward": 44.915876149176114, "Episode length": 551, "Policy Loss": 0.7774724960327148, "Value Loss": 18.13109016418457, "_runtime": 7200.8766477108, "_timestamp": 1585604570.5095172, "_step": 477}
{"Episode reward": 54.453955333213884, "Episode length": 457, "Policy Loss": 1.0921849012374878, "Value Loss": 21.859907150268555, "_runtime": 7202.441860198975, "_timestamp": 1585604572.0747297, "_step": 478}
{"Episode reward": -99.81022680112952, "Episode length": 999, "Policy Loss": -0.4049997329711914, "Value Loss": 0.003340094815939665, "_runtime": 7203.9634346961975, "_timestamp": 1585604573.5963042, "_step": 479}
{"Episode reward": -99.78390634842077, "Episode length": 999, "Policy Loss": -0.40400996804237366, "Value Loss": 0.0033331946469843388, "_runtime": 7205.474266290665, "_timestamp": 1585604575.1071358, "_step": 480}
{"Episode reward": -99.64585446053978, "Episode length": 999, "Policy Loss": -0.4037606716156006, "Value Loss": 0.003300329903140664, "_runtime": 7206.091384887695, "_timestamp": 1585604575.7242544, "_step": 481}
{"Episode reward": 62.88509674333011, "Episode length": 372, "Policy Loss": 1.5398874282836914, "Value Loss": 26.85427474975586, "_runtime": 7207.640960931778, "_timestamp": 1585604577.2738304, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39909157156944275, "Value Loss": 0.003301576478406787, "_runtime": 7209.187738656998, "_timestamp": 1585604578.8206081, "_step": 483}
{"Episode reward": -99.70926475096354, "Episode length": 999, "Policy Loss": -0.40032514929771423, "Value Loss": 0.0033096810802817345, "_runtime": 7210.595862865448, "_timestamp": 1585604580.2287323, "_step": 484}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": 0.28843754529953003, "Value Loss": 10.674764633178711, "_runtime": 7211.953399181366, "_timestamp": 1585604581.5862687, "_step": 485}
{"Episode reward": 13.009862001054657, "Episode length": 871, "Policy Loss": 0.35319313406944275, "Value Loss": 11.471128463745117, "_runtime": 7213.517519712448, "_timestamp": 1585604583.1503892, "_step": 486}
{"Episode reward": -99.77261249292502, "Episode length": 999, "Policy Loss": -0.4059276878833771, "Value Loss": 0.003352243220433593, "_runtime": 7215.069052219391, "_timestamp": 1585604584.7019217, "_step": 487}
{"Episode reward": -99.86001958399872, "Episode length": 999, "Policy Loss": -0.4080100357532501, "Value Loss": 0.0033609443344175816, "_runtime": 7216.621817588806, "_timestamp": 1585604586.254687, "_step": 488}
{"Episode reward": -99.73182727165847, "Episode length": 999, "Policy Loss": -0.4061589539051056, "Value Loss": 0.0033357366919517517, "_runtime": 7218.1769461631775, "_timestamp": 1585604587.8098156, "_step": 489}
{"Episode reward": -99.81636067500665, "Episode length": 999, "Policy Loss": -0.4009391665458679, "Value Loss": 0.003296193666756153, "_runtime": 7219.718252658844, "_timestamp": 1585604589.3511221, "_step": 490}
{"Episode reward": -99.71483085406804, "Episode length": 999, "Policy Loss": -0.39820364117622375, "Value Loss": 0.0032294916454702616, "_runtime": 7220.577708244324, "_timestamp": 1585604590.2105777, "_step": 491}
{"Episode reward": 46.93530531143722, "Episode length": 533, "Policy Loss": 0.9346336126327515, "Value Loss": 18.743770599365234, "_runtime": 7221.276452541351, "_timestamp": 1585604590.909322, "_step": 492}
{"Episode reward": 58.991246217395805, "Episode length": 411, "Policy Loss": 1.2477169036865234, "Value Loss": 24.306737899780273, "_runtime": 7222.8335037231445, "_timestamp": 1585604592.4663732, "_step": 493}
{"Episode reward": -99.65013742167365, "Episode length": 999, "Policy Loss": -0.39553001523017883, "Value Loss": 0.003198095830157399, "_runtime": 7224.367091178894, "_timestamp": 1585604593.9999607, "_step": 494}
{"Episode reward": -99.83722683051461, "Episode length": 999, "Policy Loss": -0.39701011776924133, "Value Loss": 0.00324341026134789, "_runtime": 7225.871626853943, "_timestamp": 1585604595.5044963, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40142467617988586, "Value Loss": 0.0032546210568398237, "_runtime": 7227.430825710297, "_timestamp": 1585604597.0636952, "_step": 496}
{"Episode reward": -99.59061225382473, "Episode length": 999, "Policy Loss": -0.39972805976867676, "Value Loss": 0.0032263912726193666, "_runtime": 7228.456221342087, "_timestamp": 1585604598.0890908, "_step": 497}
{"Episode reward": 35.408447082875625, "Episode length": 646, "Policy Loss": 0.6678056120872498, "Value Loss": 15.465559005737305, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284, 0.1241426169872284]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12474927306175232, -0.034679993987083435, 0.05538928508758545, 0.14545854926109314, 0.23552784323692322, 0.3255971372127533, 0.4156663715839386, 0.5057356357574463, 0.5958049297332764, 0.6858742237091064, 0.7759435176849365, 0.8660128116607666, 0.9560819864273071, 1.0461512804031372, 1.1362205743789673, 1.2262898683547974, 1.3163591623306274, 1.4064284563064575, 1.4964977502822876, 1.5865670442581177, 1.6766363382339478, 1.7667055130004883, 1.8567748069763184, 1.946844220161438, 2.0369133949279785, 2.1269826889038086, 2.2170519828796387, 2.3071212768554688, 2.397190570831299, 2.487259864807129, 2.577329158782959, 2.667398452758789, 2.757467746734619, 2.847537040710449, 2.9376063346862793, 3.0276756286621094, 3.1177449226379395, 3.2078142166137695, 3.2978835105895996, 3.3879528045654297, 3.4780220985412598, 3.5680911540985107, 3.658160448074341, 3.748229742050171, 3.838299036026001, 3.92836856842041, 4.01843786239624, 4.10850715637207, 4.198575973510742, 4.288645267486572, 4.378714561462402, 4.468783855438232, 4.5588531494140625, 4.648922443389893, 4.738991737365723, 4.829061031341553, 4.919130325317383, 5.009199619293213, 5.099268913269043, 5.189338207244873, 5.279407501220703, 5.369476795196533, 5.459546089172363, 5.549615383148193, 5.639684677124023]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.022480666637420654, -0.014019870199263096, -0.005559073761105537, 0.0029017217457294464, 0.01136251911520958, 0.019823316484689713, 0.028284110128879547, 0.03674490749835968, 0.04520570486783981, 0.053666502237319946, 0.06212729960680008, 0.07058809697628021, 0.07904888689517975, 0.08750968426465988, 0.09597048163414001, 0.10443128645420074, 0.11289207637310028, 0.12135286629199982, 0.12981367111206055, 0.13827446103096008, 0.1467352658510208, 0.15519605576992035, 0.16365686058998108, 0.17211765050888062, 0.18057844042778015, 0.18903924524784088, 0.19750003516674042, 0.20596083998680115, 0.21442162990570068, 0.2228824347257614, 0.23134323954582214, 0.23980402946472168, 0.24826481938362122, 0.25672560930252075, 0.2651863992214203, 0.2736472189426422, 0.28210800886154175, 0.2905687987804413, 0.2990295886993408, 0.30749040842056274, 0.3159511983394623, 0.3244119882583618, 0.33287277817726135, 0.3413335680961609, 0.3497943878173828, 0.35825517773628235, 0.3667159676551819, 0.3751767575740814, 0.38363754749298096, 0.3920983672142029, 0.4005591571331024, 0.40901994705200195, 0.4174807369709015, 0.4259415566921234, 0.43440234661102295, 0.4428631365299225, 0.451323926448822, 0.45978471636772156, 0.4682455360889435, 0.476706326007843, 0.48516714572906494, 0.4936279058456421, 0.502088725566864, 0.5105494856834412, 0.5190103054046631]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [16.0, 4.0, 0.0, 0.0, 0.0, 0.0, 14.0, 38.0, 28.0, 6.0, 5.0, 333.0, 8.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 4.0, 6.0, 4.0, 5.0, 5.0, 7.0, 1.0, 4.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5144028663635254, -0.4692986309528351, -0.4241943955421448, -0.37909016013145447, -0.33398592472076416, -0.28888168931007385, -0.24377745389938354, -0.19867321848869324, -0.15356898307800293, -0.10846474766731262, -0.06336051225662231, -0.018256276845932007, 0.0268479585647583, 0.071952223777771, 0.11705642938613892, 0.16216063499450684, 0.20726490020751953, 0.2523691654205322, 0.29747337102890015, 0.34257757663726807, 0.38768184185028076, 0.43278610706329346, 0.4778903126716614, 0.5229945182800293, 0.568098783493042, 0.6132030487060547, 0.6583073139190674, 0.7034114599227905, 0.7485157251358032, 0.7936199903488159, 0.8387241363525391, 0.8838284015655518, 0.9289326667785645, 0.9740369319915771, 1.0191411972045898, 1.064245343208313, 1.1093496084213257, 1.1544538736343384, 1.1995580196380615, 1.2446622848510742, 1.289766550064087, 1.3348708152770996, 1.3799750804901123, 1.4250792264938354, 1.4701834917068481, 1.5152876377105713, 1.560391902923584, 1.6054961681365967, 1.6506004333496094, 1.695704698562622, 1.7408089637756348, 1.7859132289886475, 1.8310174942016602, 1.8761215209960938, 1.9212257862091064, 1.9663300514221191, 2.011434316635132, 2.0565385818481445, 2.1016428470611572, 2.14674711227417, 2.1918511390686035, 2.236955404281616, 2.282059669494629, 2.3271639347076416, 2.3722681999206543]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 6.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2162027359008789, -0.18814565241336823, -0.16008856892585754, -0.13203150033950806, -0.10397441685199738, -0.0759173333644867, -0.04786026477813721, -0.019803181290626526, 0.008253902196884155, 0.03631097078323364, 0.06436806917190552, 0.092425137758255, 0.12048220634460449, 0.14853930473327637, 0.17659637331962585, 0.20465347170829773, 0.23271054029464722, 0.2607676088809967, 0.2888246774673462, 0.31688177585601807, 0.34493887424468994, 0.37299591302871704, 0.4010530114173889, 0.4291101098060608, 0.4571671485900879, 0.48522424697875977, 0.5132813453674316, 0.5413384437561035, 0.5693954825401306, 0.5974525809288025, 0.6255096793174744, 0.6535667181015015, 0.6816238164901733, 0.7096809148788452, 0.7377379536628723, 0.7657950520515442, 0.7938520908355713, 0.8219091892242432, 0.849966287612915, 0.8780233860015869, 0.9060804843902588, 0.9341375827789307, 0.962194561958313, 0.9902516603469849, 1.0183087587356567, 1.0463658571243286, 1.0744229555130005, 1.1024800539016724, 1.1305370330810547, 1.1585941314697266, 1.1866512298583984, 1.2147083282470703, 1.2427654266357422, 1.270822525024414, 1.298879623413086, 1.3269366025924683, 1.3549937009811401, 1.383050799369812, 1.4111078977584839, 1.4391649961471558, 1.4672220945358276, 1.49527907371521, 1.5233361721038818, 1.5513932704925537, 1.5794503688812256]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 11.0, 14.0, 7.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0], "bins": [-0.4895174205303192, -0.47995850443840027, -0.4703996181488037, -0.46084070205688477, -0.4512817859649658, -0.4417228698730469, -0.4321639835834503, -0.42260506749153137, -0.4130461812019348, -0.40348726511001587, -0.3939283490180969, -0.384369432926178, -0.3748105466365814, -0.3652516305446625, -0.3556927442550659, -0.346133828163147, -0.336574912071228, -0.3270159959793091, -0.31745707988739014, -0.3078981935977936, -0.29833927750587463, -0.2887803912162781, -0.27922147512435913, -0.2696625590324402, -0.26010364294052124, -0.2505447566509247, -0.24098584055900574, -0.2314269244670868, -0.22186803817749023, -0.2123091220855713, -0.20275020599365234, -0.1931913197040558, -0.18363240361213684, -0.1740734875202179, -0.16451460123062134, -0.1549556851387024, -0.14539676904678345, -0.1358378827571869, -0.12627896666526794, -0.116720050573349, -0.10716113448143005, -0.0976022481918335, -0.08804333209991455, -0.0784844160079956, -0.06892552971839905, -0.0593666136264801, -0.04980769753456116, -0.0402488112449646, -0.030689895153045654, -0.02113097906112671, -0.011572092771530151, -0.002013176679611206, 0.007545739412307739, 0.017104655504226685, 0.02666357159614563, 0.0362224280834198, 0.045781344175338745, 0.05534026026725769, 0.06489917635917664, 0.07445809245109558, 0.08401700854301453, 0.0935758650302887, 0.10313478112220764, 0.11269369721412659, 0.12225261330604553]}, "_runtime": 7229.310089826584, "_timestamp": 1585604598.9429593, "_step": 498}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 0.9999887943267822, "Value Loss": 18.50074577331543, "_runtime": 7229.310089826584, "_timestamp": 1585604598.9429593, "_step": 499}
