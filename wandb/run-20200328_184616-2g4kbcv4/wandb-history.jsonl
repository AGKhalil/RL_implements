{"Episode reward": -99.19182192748637, "Episode length": 999, "Policy Loss": -0.13357219099998474, "Value Loss": 0.02831573225557804, "_runtime": 20.596146821975708, "_timestamp": 1585421195.441739, "_step": 0}
{"Episode reward": -91.39773514360873, "Episode length": 999, "Policy Loss": -0.1291256546974182, "Value Loss": 0.02452794834971428, "_runtime": 22.112443447113037, "_timestamp": 1585421196.9580357, "_step": 1}
{"Episode reward": -105.44552753447917, "Episode length": 999, "Policy Loss": -0.1551848202943802, "Value Loss": 0.03186507150530815, "_runtime": 23.739923238754272, "_timestamp": 1585421198.5855155, "_step": 2}
{"Episode reward": -101.16894895452597, "Episode length": 999, "Policy Loss": -0.14000408351421356, "Value Loss": 0.034124113619327545, "_runtime": 25.290695190429688, "_timestamp": 1585421200.1362875, "_step": 3}
{"Episode reward": -102.42838354676014, "Episode length": 999, "Policy Loss": -0.1434071809053421, "Value Loss": 0.02997015230357647, "_runtime": 27.053550720214844, "_timestamp": 1585421201.899143, "_step": 4}
{"Episode reward": -106.2596078985057, "Episode length": 999, "Policy Loss": -0.14184148609638214, "Value Loss": 0.03526280075311661, "_runtime": 28.68920397758484, "_timestamp": 1585421203.5347962, "_step": 5}
{"Episode reward": -104.14767116538783, "Episode length": 999, "Policy Loss": -0.1419428288936615, "Value Loss": 0.0316736213862896, "_runtime": 30.52620530128479, "_timestamp": 1585421205.3717976, "_step": 6}
{"Episode reward": -99.83675208023064, "Episode length": 999, "Policy Loss": -0.14457280933856964, "Value Loss": 0.028672536835074425, "_runtime": 32.11951279640198, "_timestamp": 1585421206.965105, "_step": 7}
{"Episode reward": -107.41769989956647, "Episode length": 999, "Policy Loss": -0.14618737995624542, "Value Loss": 0.03296159580349922, "_runtime": 33.69905090332031, "_timestamp": 1585421208.5446432, "_step": 8}
{"Episode reward": -105.42938982827292, "Episode length": 999, "Policy Loss": -0.15399585664272308, "Value Loss": 0.034121204167604446, "_runtime": 35.257745027542114, "_timestamp": 1585421210.1033373, "_step": 9}
{"Episode reward": -104.22811265805697, "Episode length": 999, "Policy Loss": -0.14512589573860168, "Value Loss": 0.034768298268318176, "_runtime": 36.87423825263977, "_timestamp": 1585421211.7198305, "_step": 10}
{"Episode reward": -107.73742322663631, "Episode length": 999, "Policy Loss": -0.16058598458766937, "Value Loss": 0.03937901556491852, "_runtime": 38.584654569625854, "_timestamp": 1585421213.4302468, "_step": 11}
{"Episode reward": -101.91410885561277, "Episode length": 999, "Policy Loss": -0.14135481417179108, "Value Loss": 0.028857966884970665, "_runtime": 40.302653312683105, "_timestamp": 1585421215.1482456, "_step": 12}
{"Episode reward": -93.43506074448455, "Episode length": 999, "Policy Loss": -0.1280432492494583, "Value Loss": 0.026273485273122787, "_runtime": 42.0611412525177, "_timestamp": 1585421216.9067335, "_step": 13}
{"Episode reward": -109.43384378871077, "Episode length": 999, "Policy Loss": -0.15377159416675568, "Value Loss": 0.034307811409235, "_runtime": 43.82286500930786, "_timestamp": 1585421218.6684573, "_step": 14}
{"Episode reward": -97.55888736346294, "Episode length": 999, "Policy Loss": -0.12766019999980927, "Value Loss": 0.02841685526072979, "_runtime": 45.433921337127686, "_timestamp": 1585421220.2795136, "_step": 15}
{"Episode reward": -99.37806603804121, "Episode length": 999, "Policy Loss": -0.13927680253982544, "Value Loss": 0.028512626886367798, "_runtime": 46.91335916519165, "_timestamp": 1585421221.7589514, "_step": 16}
{"Episode reward": -100.57778844839143, "Episode length": 999, "Policy Loss": -0.13983657956123352, "Value Loss": 0.03387927636504173, "_runtime": 48.667481660842896, "_timestamp": 1585421223.513074, "_step": 17}
{"Episode reward": -103.0934884102372, "Episode length": 999, "Policy Loss": -0.1500655710697174, "Value Loss": 0.029958441853523254, "_runtime": 50.31550884246826, "_timestamp": 1585421225.161101, "_step": 18}
{"Episode reward": -99.72823699801197, "Episode length": 999, "Policy Loss": -0.13328415155410767, "Value Loss": 0.03279354050755501, "_runtime": 52.07977104187012, "_timestamp": 1585421226.9253633, "_step": 19}
{"Episode reward": -97.411744662359, "Episode length": 999, "Policy Loss": -0.13152249157428741, "Value Loss": 0.026544390246272087, "_runtime": 53.63112449645996, "_timestamp": 1585421228.4767168, "_step": 20}
{"Episode reward": -103.58602459346376, "Episode length": 999, "Policy Loss": -0.13877856731414795, "Value Loss": 0.03903272747993469, "_runtime": 55.11228561401367, "_timestamp": 1585421229.9578779, "_step": 21}
{"Episode reward": -107.26224059325281, "Episode length": 999, "Policy Loss": -0.1509207785129547, "Value Loss": 0.030331335961818695, "_runtime": 56.778136014938354, "_timestamp": 1585421231.6237283, "_step": 22}
{"Episode reward": -103.69951471477222, "Episode length": 999, "Policy Loss": -0.1519431471824646, "Value Loss": 0.030020931735634804, "_runtime": 58.34956240653992, "_timestamp": 1585421233.1951547, "_step": 23}
{"Episode reward": -111.28720973144067, "Episode length": 999, "Policy Loss": -0.15189267694950104, "Value Loss": 0.03730926662683487, "_runtime": 60.074352502822876, "_timestamp": 1585421234.9199448, "_step": 24}
{"Episode reward": -106.03856813253333, "Episode length": 999, "Policy Loss": -0.1467674821615219, "Value Loss": 0.03633206710219383, "_runtime": 61.714813470840454, "_timestamp": 1585421236.5604057, "_step": 25}
{"Episode reward": -113.28810792975237, "Episode length": 999, "Policy Loss": -0.16840815544128418, "Value Loss": 0.03802355378866196, "_runtime": 63.28270697593689, "_timestamp": 1585421238.1282992, "_step": 26}
{"Episode reward": -108.42550901182794, "Episode length": 999, "Policy Loss": -0.15347327291965485, "Value Loss": 0.035900283604860306, "_runtime": 64.81258368492126, "_timestamp": 1585421239.658176, "_step": 27}
{"Episode reward": -105.44824814716557, "Episode length": 999, "Policy Loss": -0.1560484766960144, "Value Loss": 0.03303663060069084, "_runtime": 66.54165387153625, "_timestamp": 1585421241.3872461, "_step": 28}
{"Episode reward": -111.25398866077357, "Episode length": 999, "Policy Loss": -0.1604640781879425, "Value Loss": 0.04044221341609955, "_runtime": 68.15792798995972, "_timestamp": 1585421243.0035203, "_step": 29}
{"Episode reward": -104.9176540606799, "Episode length": 999, "Policy Loss": -0.14493049681186676, "Value Loss": 0.033299922943115234, "_runtime": 69.83557224273682, "_timestamp": 1585421244.6811645, "_step": 30}
{"Episode reward": -101.11714910451227, "Episode length": 999, "Policy Loss": -0.13222096860408783, "Value Loss": 0.03428027033805847, "_runtime": 71.05562973022461, "_timestamp": 1585421245.901222, "_step": 31}
{"Episode reward": 21.90891429258828, "Episode length": 718, "Policy Loss": -0.030151356011629105, "Value Loss": 13.984101295471191, "_runtime": 72.81387186050415, "_timestamp": 1585421247.6594641, "_step": 32}
{"Episode reward": -107.3991890508033, "Episode length": 999, "Policy Loss": -0.15110333263874054, "Value Loss": 0.03509246185421944, "_runtime": 74.4653389453888, "_timestamp": 1585421249.3109312, "_step": 33}
{"Episode reward": -103.87472990625875, "Episode length": 999, "Policy Loss": -0.14563238620758057, "Value Loss": 0.03310925513505936, "_runtime": 76.11984395980835, "_timestamp": 1585421250.9654362, "_step": 34}
{"Episode reward": -106.4712374537837, "Episode length": 999, "Policy Loss": -0.15207020938396454, "Value Loss": 0.032641056925058365, "_runtime": 77.72473859786987, "_timestamp": 1585421252.5703309, "_step": 35}
{"Episode reward": -102.59388056584723, "Episode length": 999, "Policy Loss": -0.1465229094028473, "Value Loss": 0.03302103281021118, "_runtime": 79.49000573158264, "_timestamp": 1585421254.335598, "_step": 36}
{"Episode reward": -108.52165212471759, "Episode length": 999, "Policy Loss": -0.1580900400876999, "Value Loss": 0.035485923290252686, "_runtime": 81.17879128456116, "_timestamp": 1585421256.0243835, "_step": 37}
{"Episode reward": -101.52580166374393, "Episode length": 999, "Policy Loss": -0.1488218903541565, "Value Loss": 0.03151002526283264, "_runtime": 82.83447670936584, "_timestamp": 1585421257.680069, "_step": 38}
{"Episode reward": -100.61556510079052, "Episode length": 999, "Policy Loss": -0.13707485795021057, "Value Loss": 0.029969170689582825, "_runtime": 84.37171626091003, "_timestamp": 1585421259.2173085, "_step": 39}
{"Episode reward": -100.08418651008645, "Episode length": 999, "Policy Loss": -0.14386950433254242, "Value Loss": 0.02948666736483574, "_runtime": 86.05807447433472, "_timestamp": 1585421260.9036667, "_step": 40}
{"Episode reward": -0.9304272138482617, "Episode length": 978, "Policy Loss": 0.002947614761069417, "Value Loss": 10.190393447875977, "_runtime": 87.67456769943237, "_timestamp": 1585421262.52016, "_step": 41}
{"Episode reward": -102.05346923604361, "Episode length": 999, "Policy Loss": -0.15091508626937866, "Value Loss": 0.03206510841846466, "_runtime": 89.37015175819397, "_timestamp": 1585421264.215744, "_step": 42}
{"Episode reward": -101.25790618020302, "Episode length": 999, "Policy Loss": -0.14321108162403107, "Value Loss": 0.035429880023002625, "_runtime": 91.08169889450073, "_timestamp": 1585421265.9272912, "_step": 43}
{"Episode reward": -99.91993276898506, "Episode length": 999, "Policy Loss": -0.14272910356521606, "Value Loss": 0.03045072592794895, "_runtime": 92.70686388015747, "_timestamp": 1585421267.5524561, "_step": 44}
{"Episode reward": -110.55503397831862, "Episode length": 999, "Policy Loss": -0.1572432965040207, "Value Loss": 0.03446142002940178, "_runtime": 94.30650329589844, "_timestamp": 1585421269.1520956, "_step": 45}
{"Episode reward": -102.41065284972925, "Episode length": 999, "Policy Loss": -0.14295350015163422, "Value Loss": 0.03418607637286186, "_runtime": 95.86624598503113, "_timestamp": 1585421270.7118382, "_step": 46}
{"Episode reward": -101.6835500910466, "Episode length": 999, "Policy Loss": -0.14024703204631805, "Value Loss": 0.03383297100663185, "_runtime": 97.49189114570618, "_timestamp": 1585421272.3374834, "_step": 47}
{"Episode reward": -93.09506815837419, "Episode length": 999, "Policy Loss": -0.12170259654521942, "Value Loss": 0.029064534232020378, "_runtime": 99.16575145721436, "_timestamp": 1585421274.0113437, "_step": 48}
{"Episode reward": -99.97808223057412, "Episode length": 999, "Policy Loss": -0.13799019157886505, "Value Loss": 0.030116356909275055, "_runtime": 100.81814885139465, "_timestamp": 1585421275.663741, "_step": 49}
{"Episode reward": -102.2397637836118, "Episode length": 999, "Policy Loss": -0.13830351829528809, "Value Loss": 0.032910533249378204, "_runtime": 102.52287769317627, "_timestamp": 1585421277.36847, "_step": 50}
{"Episode reward": -98.63522754164202, "Episode length": 999, "Policy Loss": -0.13205556571483612, "Value Loss": 0.030253341421484947, "_runtime": 104.22427034378052, "_timestamp": 1585421279.0698626, "_step": 51}
{"Episode reward": -97.04382886509069, "Episode length": 999, "Policy Loss": -0.13191233575344086, "Value Loss": 0.031061965972185135, "_runtime": 105.86605334281921, "_timestamp": 1585421280.7116456, "_step": 52}
{"Episode reward": -93.55709687996682, "Episode length": 999, "Policy Loss": -0.12270743399858475, "Value Loss": 0.027567891404032707, "_runtime": 107.47615504264832, "_timestamp": 1585421282.3217473, "_step": 53}
{"Episode reward": -100.3007941562365, "Episode length": 999, "Policy Loss": -0.13483206927776337, "Value Loss": 0.029144473373889923, "_runtime": 109.15540146827698, "_timestamp": 1585421284.0009937, "_step": 54}
{"Episode reward": -100.31062239480674, "Episode length": 999, "Policy Loss": -0.13700367510318756, "Value Loss": 0.029223034158349037, "_runtime": 111.20805597305298, "_timestamp": 1585421286.0536482, "_step": 55}
{"Episode reward": -105.23222712858059, "Episode length": 999, "Policy Loss": -0.14224553108215332, "Value Loss": 0.029048705473542213, "_runtime": 112.84260153770447, "_timestamp": 1585421287.6881938, "_step": 56}
{"Episode reward": -105.168594423855, "Episode length": 999, "Policy Loss": -0.14277499914169312, "Value Loss": 0.03669755533337593, "_runtime": 114.42827606201172, "_timestamp": 1585421289.2738683, "_step": 57}
{"Episode reward": -107.16274524460655, "Episode length": 999, "Policy Loss": -0.15128782391548157, "Value Loss": 0.03310573473572731, "_runtime": 116.00989651679993, "_timestamp": 1585421290.8554888, "_step": 58}
{"Episode reward": -102.89919129844716, "Episode length": 999, "Policy Loss": -0.14584331214427948, "Value Loss": 0.03053366392850876, "_runtime": 117.54660248756409, "_timestamp": 1585421292.3921947, "_step": 59}
{"Episode reward": -106.88987924437792, "Episode length": 999, "Policy Loss": -0.14372222125530243, "Value Loss": 0.0353725291788578, "_runtime": 119.30455279350281, "_timestamp": 1585421294.150145, "_step": 60}
{"Episode reward": -99.10610313248108, "Episode length": 999, "Policy Loss": -0.13048474490642548, "Value Loss": 0.031550172716379166, "_runtime": 121.03629851341248, "_timestamp": 1585421295.8818908, "_step": 61}
{"Episode reward": -101.36321667199744, "Episode length": 999, "Policy Loss": -0.14210101962089539, "Value Loss": 0.0296019297093153, "_runtime": 122.66915798187256, "_timestamp": 1585421297.5147502, "_step": 62}
{"Episode reward": -96.77051629113767, "Episode length": 999, "Policy Loss": -0.13302698731422424, "Value Loss": 0.0272139273583889, "_runtime": 124.34477090835571, "_timestamp": 1585421299.1903632, "_step": 63}
{"Episode reward": -96.82517000955725, "Episode length": 999, "Policy Loss": -0.12395820021629333, "Value Loss": 0.02605367638170719, "_runtime": 125.9805326461792, "_timestamp": 1585421300.826125, "_step": 64}
{"Episode reward": -99.32873255643759, "Episode length": 999, "Policy Loss": -0.13478770852088928, "Value Loss": 0.03104904107749462, "_runtime": 127.5048315525055, "_timestamp": 1585421302.3504238, "_step": 65}
{"Episode reward": -95.13966506674572, "Episode length": 999, "Policy Loss": -0.1279512643814087, "Value Loss": 0.02483811229467392, "_runtime": 129.21137642860413, "_timestamp": 1585421304.0569687, "_step": 66}
{"Episode reward": -101.02518573394742, "Episode length": 999, "Policy Loss": -0.1337621957063675, "Value Loss": 0.02863645926117897, "_runtime": 130.93790435791016, "_timestamp": 1585421305.7834966, "_step": 67}
{"Episode reward": -95.13000367982154, "Episode length": 999, "Policy Loss": -0.1342802792787552, "Value Loss": 0.027464747428894043, "_runtime": 132.52964425086975, "_timestamp": 1585421307.3752365, "_step": 68}
{"Episode reward": -101.7261176776805, "Episode length": 999, "Policy Loss": -0.13534803688526154, "Value Loss": 0.03129803016781807, "_runtime": 134.19600367546082, "_timestamp": 1585421309.041596, "_step": 69}
{"Episode reward": -105.8129424100636, "Episode length": 999, "Policy Loss": -0.14153282344341278, "Value Loss": 0.02903861366212368, "_runtime": 135.76012802124023, "_timestamp": 1585421310.6057203, "_step": 70}
{"Episode reward": -96.3990272050042, "Episode length": 999, "Policy Loss": -0.13813656568527222, "Value Loss": 0.027222637087106705, "_runtime": 137.2741734981537, "_timestamp": 1585421312.1197658, "_step": 71}
{"Episode reward": -103.90385792606195, "Episode length": 999, "Policy Loss": -0.14138242602348328, "Value Loss": 0.031587790697813034, "_runtime": 139.10576367378235, "_timestamp": 1585421313.951356, "_step": 72}
{"Episode reward": -98.00168438856664, "Episode length": 999, "Policy Loss": -0.12654992938041687, "Value Loss": 0.02984039857983589, "_runtime": 140.73229598999023, "_timestamp": 1585421315.5778883, "_step": 73}
{"Episode reward": -103.62842644321498, "Episode length": 999, "Policy Loss": -0.147428959608078, "Value Loss": 0.03329527750611305, "_runtime": 142.3377251625061, "_timestamp": 1585421317.1833174, "_step": 74}
{"Episode reward": -103.67470641087633, "Episode length": 999, "Policy Loss": -0.1377149075269699, "Value Loss": 0.030754389241337776, "_runtime": 144.04077243804932, "_timestamp": 1585421318.8863647, "_step": 75}
{"Episode reward": -101.80602983116648, "Episode length": 999, "Policy Loss": -0.13634352385997772, "Value Loss": 0.036476511508226395, "_runtime": 145.58068823814392, "_timestamp": 1585421320.4262805, "_step": 76}
{"Episode reward": -107.08681520458907, "Episode length": 999, "Policy Loss": -0.15246471762657166, "Value Loss": 0.03354857116937637, "_runtime": 147.11903262138367, "_timestamp": 1585421321.964625, "_step": 77}
{"Episode reward": -94.13872164092217, "Episode length": 999, "Policy Loss": -0.11984492838382721, "Value Loss": 0.025941286236047745, "_runtime": 148.85097360610962, "_timestamp": 1585421323.6965659, "_step": 78}
{"Episode reward": -106.31096271302346, "Episode length": 999, "Policy Loss": -0.1497957557439804, "Value Loss": 0.03705812618136406, "_runtime": 150.4770951271057, "_timestamp": 1585421325.3226874, "_step": 79}
{"Episode reward": -101.70083475645572, "Episode length": 999, "Policy Loss": -0.14058677852153778, "Value Loss": 0.029519058763980865, "_runtime": 152.20502090454102, "_timestamp": 1585421327.0506132, "_step": 80}
{"Episode reward": -102.02814544464506, "Episode length": 999, "Policy Loss": -0.1364908218383789, "Value Loss": 0.03283018246293068, "_runtime": 153.84850811958313, "_timestamp": 1585421328.6941004, "_step": 81}
{"Episode reward": -99.9210268990406, "Episode length": 999, "Policy Loss": -0.14186541736125946, "Value Loss": 0.03048308938741684, "_runtime": 155.53532791137695, "_timestamp": 1585421330.3809202, "_step": 82}
{"Episode reward": -100.33166996092976, "Episode length": 999, "Policy Loss": -0.13123895227909088, "Value Loss": 0.03153078630566597, "_runtime": 157.22623372077942, "_timestamp": 1585421332.071826, "_step": 83}
{"Episode reward": -98.07260515809175, "Episode length": 999, "Policy Loss": -0.12956881523132324, "Value Loss": 0.030107416212558746, "_runtime": 158.85829639434814, "_timestamp": 1585421333.7038887, "_step": 84}
{"Episode reward": -105.8098258189405, "Episode length": 999, "Policy Loss": -0.14470696449279785, "Value Loss": 0.03504720702767372, "_runtime": 160.50357055664062, "_timestamp": 1585421335.3491628, "_step": 85}
{"Episode reward": -104.30935754296696, "Episode length": 999, "Policy Loss": -0.14308808743953705, "Value Loss": 0.03244980424642563, "_runtime": 162.16987919807434, "_timestamp": 1585421337.0154715, "_step": 86}
{"Episode reward": -102.91795635585004, "Episode length": 999, "Policy Loss": -0.15536001324653625, "Value Loss": 0.03235486522316933, "_runtime": 163.80330562591553, "_timestamp": 1585421338.648898, "_step": 87}
{"Episode reward": -107.82177841009124, "Episode length": 999, "Policy Loss": -0.1489635705947876, "Value Loss": 0.03441279008984566, "_runtime": 165.36655402183533, "_timestamp": 1585421340.2121463, "_step": 88}
{"Episode reward": -106.72123231934819, "Episode length": 999, "Policy Loss": -0.1487341821193695, "Value Loss": 0.036004506051540375, "_runtime": 167.0217146873474, "_timestamp": 1585421341.867307, "_step": 89}
{"Episode reward": -104.43108259605094, "Episode length": 999, "Policy Loss": -0.13379736244678497, "Value Loss": 0.03367793187499046, "_runtime": 168.65083408355713, "_timestamp": 1585421343.4964263, "_step": 90}
{"Episode reward": -96.73046056720007, "Episode length": 999, "Policy Loss": -0.13046784698963165, "Value Loss": 0.0293068028986454, "_runtime": 170.26932644844055, "_timestamp": 1585421345.1149187, "_step": 91}
{"Episode reward": -111.07444696035542, "Episode length": 999, "Policy Loss": -0.16471779346466064, "Value Loss": 0.03656096011400223, "_runtime": 171.84379291534424, "_timestamp": 1585421346.6893852, "_step": 92}
{"Episode reward": -93.98732590183499, "Episode length": 999, "Policy Loss": -0.1195235401391983, "Value Loss": 0.0291137658059597, "_runtime": 173.50100946426392, "_timestamp": 1585421348.3466017, "_step": 93}
{"Episode reward": -113.25026821620938, "Episode length": 999, "Policy Loss": -0.1574172079563141, "Value Loss": 0.03674155846238136, "_runtime": 175.09590697288513, "_timestamp": 1585421349.9414992, "_step": 94}
{"Episode reward": -96.89555727427927, "Episode length": 999, "Policy Loss": -0.13223183155059814, "Value Loss": 0.02795381098985672, "_runtime": 176.66927552223206, "_timestamp": 1585421351.5148678, "_step": 95}
{"Episode reward": -95.24799972169112, "Episode length": 999, "Policy Loss": -0.12865722179412842, "Value Loss": 0.026948679238557816, "_runtime": 178.30927801132202, "_timestamp": 1585421353.1548703, "_step": 96}
{"Episode reward": -103.67381101796755, "Episode length": 999, "Policy Loss": -0.14849625527858734, "Value Loss": 0.02944161556661129, "_runtime": 179.92812705039978, "_timestamp": 1585421354.7737193, "_step": 97}
{"Episode reward": -95.91143547869679, "Episode length": 999, "Policy Loss": -0.12944331765174866, "Value Loss": 0.02774014137685299, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242, 7.926481246948242]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.383358001708984, -4.200338363647461, -4.0173187255859375, -3.834299087524414, -3.6512794494628906, -3.468259811401367, -3.2852399349212646, -3.102220296859741, -2.9192006587982178, -2.7361810207366943, -2.553161382675171, -2.3701417446136475, -2.187121868133545, -2.0041022300720215, -1.821082592010498, -1.6380629539489746, -1.4550433158874512, -1.2720236778259277, -1.0890040397644043, -0.9059844017028809, -0.7229647636413574, -0.5399448871612549, -0.35692548751831055, -0.1739058494567871, 0.009114265441894531, 0.19213390350341797, 0.3751535415649414, 0.5581731796264648, 0.7411928176879883, 0.9242124557495117, 1.1072320938110352, 1.2902517318725586, 1.473271369934082, 1.6562910079956055, 1.839310646057129, 2.0223302841186523, 2.205349922180176, 2.388369560241699, 2.5713891983032227, 2.754408836364746, 2.9374284744262695, 3.120448589324951, 3.3034682273864746, 3.486487865447998, 3.6695070266723633, 3.8525266647338867, 4.03554630279541, 4.218565940856934, 4.401586532592773, 4.584606170654297, 4.76762580871582, 4.950645446777344, 5.133665084838867, 5.316684722900391, 5.499704360961914, 5.6827239990234375, 5.865743637084961, 6.048763275146484, 6.231782913208008, 6.414802551269531, 6.597822189331055, 6.780841827392578, 6.963861465454102, 7.146881103515625, 7.329900741577148]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.168785572052002, -4.044682025909424, -3.9205784797668457, -3.7964749336242676, -3.6723713874816895, -3.5482678413391113, -3.4241645336151123, -3.300060987472534, -3.175957441329956, -3.051853895187378, -2.9277503490448, -2.803647041320801, -2.6795434951782227, -2.5554399490356445, -2.4313364028930664, -2.3072328567504883, -2.18312931060791, -2.059025764465332, -1.934922218322754, -1.8108186721801758, -1.6867151260375977, -1.5626118183135986, -1.4385082721710205, -1.3144047260284424, -1.1903011798858643, -1.0661976337432861, -0.942094087600708, -0.8179905414581299, -0.6938872337341309, -0.5697836875915527, -0.4456801414489746, -0.3215765953063965, -0.19747304916381836, -0.07336950302124023, 0.05073404312133789, 0.17483758926391602, 0.29894113540649414, 0.42304468154907227, 0.5471482276916504, 0.6712517738342285, 0.7953553199768066, 0.9194583892822266, 1.0435619354248047, 1.1676654815673828, 1.291769027709961, 1.415872573852539, 1.5399761199951172, 1.6640796661376953, 1.7881832122802734, 1.9122867584228516, 2.0363903045654297, 2.160493850708008, 2.284597396850586, 2.408700942993164, 2.532804489135742, 2.6569080352783203, 2.7810111045837402, 2.9051146507263184, 3.0292181968688965, 3.1533217430114746, 3.2774252891540527, 3.401528835296631, 3.525632381439209, 3.649735927581787, 3.7738394737243652]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 5.0, 9.0, 4.0, 9.0, 4.0, 6.0, 12.0, 12.0, 14.0, 9.0, 8.0, 13.0, 19.0, 18.0, 37.0, 49.0, 34.0, 36.0, 39.0, 17.0, 27.0, 30.0, 10.0, 10.0, 18.0, 6.0, 6.0, 2.0, 3.0, 6.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-3.4123740196228027, -3.310788631439209, -3.2092034816741943, -3.1076180934906006, -3.006032943725586, -2.904447555541992, -2.8028621673583984, -2.7012767791748047, -2.59969162940979, -2.4981064796447754, -2.3965210914611816, -2.294935703277588, -2.193350315093994, -2.0917651653289795, -1.9901797771453857, -1.8885945081710815, -1.7870092391967773, -1.6854239702224731, -1.583838701248169, -1.4822533130645752, -1.3806681632995605, -1.2790827751159668, -1.177497386932373, -1.0759122371673584, -0.9743268489837646, -0.8727414608001709, -0.7711563110351562, -0.6695709228515625, -0.5679855346679688, -0.4664003849029541, -0.36481499671936035, -0.2632298469543457, -0.16164445877075195, -0.0600590705871582, 0.041526079177856445, 0.1431114673614502, 0.24469661712646484, 0.3462820053100586, 0.44786739349365234, 0.549452543258667, 0.6510376930236816, 0.7526230812072754, 0.8542084693908691, 0.9557938575744629, 1.0573792457580566, 1.1589646339416504, 1.260549545288086, 1.3621349334716797, 1.4637203216552734, 1.5653057098388672, 1.666891098022461, 1.7684760093688965, 1.8700613975524902, 1.971646785736084, 2.0732321739196777, 2.1748175621032715, 2.2764029502868652, 2.377987861633301, 2.4795732498168945, 2.5811586380004883, 2.682744026184082, 2.784329414367676, 2.8859143257141113, 2.987499713897705, 3.089085102081299]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.703404426574707, -1.6316527128219604, -1.5599009990692139, -1.4881492853164673, -1.4163975715637207, -1.3446459770202637, -1.272894263267517, -1.2011425495147705, -1.129390835762024, -1.0576391220092773, -0.9858874082565308, -0.914135754108429, -0.8423840403556824, -0.7706323266029358, -0.698880672454834, -0.6271289587020874, -0.5553772449493408, -0.48362553119659424, -0.41187381744384766, -0.3401221036911011, -0.2683703899383545, -0.19661879539489746, -0.12486708164215088, -0.0531153678894043, 0.018636345863342285, 0.09038805961608887, 0.16213977336883545, 0.23389148712158203, 0.30564308166503906, 0.3773949146270752, 0.4491465091705322, 0.5208983421325684, 0.5926499366760254, 0.6644015312194824, 0.7361533641815186, 0.8079049587249756, 0.8796567916870117, 0.9514083862304688, 1.0231602191925049, 1.094911813735962, 1.166663646697998, 1.238415241241455, 1.310166835784912, 1.3819186687469482, 1.4536702632904053, 1.5254220962524414, 1.5971736907958984, 1.6689255237579346, 1.7406771183013916, 1.8124287128448486, 1.8841805458068848, 1.9559321403503418, 2.027683973312378, 2.099435567855835, 2.171187400817871, 2.242938995361328, 2.314690589904785, 2.386442184448242, 2.4581942558288574, 2.5299458503723145, 2.6016974449157715, 2.6734490394592285, 2.7452011108398438, 2.816952705383301, 2.888704299926758]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 32.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.3161332607269287, -1.2834646701812744, -1.2507959604263306, -1.2181272506713867, -1.1854586601257324, -1.1527900695800781, -1.1201213598251343, -1.0874526500701904, -1.0547840595245361, -1.0221154689788818, -0.989446759223938, -0.9567781090736389, -0.9241094589233398, -0.8914408087730408, -0.8587721586227417, -0.8261035084724426, -0.7934348583221436, -0.7607662081718445, -0.7280975580215454, -0.6954289078712463, -0.6627602577209473, -0.6300916075706482, -0.5974229574203491, -0.56475430727005, -0.532085657119751, -0.4994170069694519, -0.46674835681915283, -0.43407970666885376, -0.4014110565185547, -0.3687424063682556, -0.33607375621795654, -0.3034050464630127, -0.2707364559173584, -0.2380678653717041, -0.20539915561676025, -0.1727304458618164, -0.1400618553161621, -0.10739326477050781, -0.07472455501556396, -0.04205584526062012, -0.00938725471496582, 0.023281335830688477, 0.055950045585632324, 0.08861875534057617, 0.12128734588623047, 0.15395593643188477, 0.1866246461868286, 0.21929335594177246, 0.25196194648742676, 0.28463053703308105, 0.3172992467880249, 0.34996795654296875, 0.38263654708862305, 0.41530513763427734, 0.4479738473892212, 0.48064255714416504, 0.5133111476898193, 0.5459797382354736, 0.5786484479904175, 0.6113171577453613, 0.6439857482910156, 0.6766543388366699, 0.7093231678009033, 0.7419917583465576, 0.7746603488922119]}, "_runtime": 181.57988357543945, "_timestamp": 1585421356.4254758, "_step": 98}
{"Episode reward": -96.55595540999812, "Episode length": 999, "Policy Loss": -0.1357099562883377, "Value Loss": 0.026774317026138306, "_runtime": 181.57988357543945, "_timestamp": 1585421356.4254758, "_step": 99}
