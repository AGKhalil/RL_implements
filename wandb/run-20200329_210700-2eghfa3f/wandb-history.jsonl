{"Episode reward": -41.74668730496144, "Episode length": 999, "Policy Loss": -0.02811925858259201, "Value Loss": 0.12585966289043427, "_runtime": 6961.162533521652, "_timestamp": 1585516039.5832632, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.965304136276245, "Value Loss": 8.682677268981934, "_runtime": 6962.655239105225, "_timestamp": 1585516041.0759687, "_step": 1}
{"Episode reward": -95.60843537273327, "Episode length": 999, "Policy Loss": -0.3618754744529724, "Value Loss": 0.6687101721763611, "_runtime": 6963.237129449844, "_timestamp": 1585516041.657859, "_step": 2}
{"Episode reward": 68.44989235883696, "Episode length": 342, "Policy Loss": 0.27897125482559204, "Value Loss": 36.84280014038086, "_runtime": 6964.7904551029205, "_timestamp": 1585516043.2111847, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3858978748321533, "Value Loss": 1.2114416360855103, "_runtime": 6966.322672367096, "_timestamp": 1585516044.743402, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4109280109405518, "Value Loss": 1.720897912979126, "_runtime": 6967.830372571945, "_timestamp": 1585516046.2511022, "_step": 5}
{"Episode reward": -99.27202658973702, "Episode length": 999, "Policy Loss": -0.8076338768005371, "Value Loss": 0.31513848900794983, "_runtime": 6969.391363859177, "_timestamp": 1585516047.8120935, "_step": 6}
{"Episode reward": -99.63382866929649, "Episode length": 999, "Policy Loss": -0.9881944060325623, "Value Loss": 0.6448489427566528, "_runtime": 6970.9348566532135, "_timestamp": 1585516049.3555863, "_step": 7}
{"Episode reward": -99.40139972931044, "Episode length": 999, "Policy Loss": -2.2419867515563965, "Value Loss": 1.6743234395980835, "_runtime": 6971.772261619568, "_timestamp": 1585516050.1929913, "_step": 8}
{"Episode reward": 46.72413081891682, "Episode length": 534, "Policy Loss": 0.3095673620700836, "Value Loss": 18.692651748657227, "_runtime": 6972.137678384781, "_timestamp": 1585516050.558408, "_step": 9}
{"Episode reward": 80.68861534018069, "Episode length": 196, "Policy Loss": 3.6364223957061768, "Value Loss": 53.33403778076172, "_runtime": 6972.469835996628, "_timestamp": 1585516050.8905656, "_step": 10}
{"Episode reward": 81.4, "Episode length": 186, "Policy Loss": 3.584665536880493, "Value Loss": 54.0920295715332, "_runtime": 6972.679661035538, "_timestamp": 1585516051.1003907, "_step": 11}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 4.917629241943359, "Value Loss": 83.65156555175781, "_runtime": 6973.171436548233, "_timestamp": 1585516051.5921662, "_step": 12}
{"Episode reward": 66.94256434296508, "Episode length": 333, "Policy Loss": 1.38142991065979, "Value Loss": 30.61927604675293, "_runtime": 6973.360630989075, "_timestamp": 1585516051.7813606, "_step": 13}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": 1.7443480491638184, "Value Loss": 82.3148422241211, "_runtime": 6973.652816534042, "_timestamp": 1585516052.0735462, "_step": 14}
{"Episode reward": 80.3, "Episode length": 197, "Policy Loss": 2.529139757156372, "Value Loss": 49.79123306274414, "_runtime": 6973.855263710022, "_timestamp": 1585516052.2759933, "_step": 15}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": 5.15865421295166, "Value Loss": 82.03203582763672, "_runtime": 6974.388679027557, "_timestamp": 1585516052.8094087, "_step": 16}
{"Episode reward": 63.86852566746506, "Episode length": 362, "Policy Loss": 0.3895074725151062, "Value Loss": 26.575685501098633, "_runtime": 6974.709197998047, "_timestamp": 1585516053.1299276, "_step": 17}
{"Episode reward": 78.98839039122683, "Episode length": 211, "Policy Loss": 2.3956146240234375, "Value Loss": 46.82276916503906, "_runtime": 6975.11877655983, "_timestamp": 1585516053.5395062, "_step": 18}
{"Episode reward": 72.39348098998877, "Episode length": 278, "Policy Loss": 0.9087213277816772, "Value Loss": 34.228946685791016, "_runtime": 6975.536185503006, "_timestamp": 1585516053.9569151, "_step": 19}
{"Episode reward": 72.7999999999999, "Episode length": 272, "Policy Loss": 0.9759273529052734, "Value Loss": 34.28668975830078, "_runtime": 6975.722535610199, "_timestamp": 1585516054.1432652, "_step": 20}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 5.192517280578613, "Value Loss": 82.42688751220703, "_runtime": 6976.5674386024475, "_timestamp": 1585516054.9881682, "_step": 21}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": -2.5936379432678223, "Value Loss": 18.31183433532715, "_runtime": 6978.0972011089325, "_timestamp": 1585516056.5179307, "_step": 22}
{"Episode reward": -99.78350443933019, "Episode length": 999, "Policy Loss": -2.622401237487793, "Value Loss": 0.2694053053855896, "_runtime": 6979.015852928162, "_timestamp": 1585516057.4365826, "_step": 23}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": -2.063239097595215, "Value Loss": 15.54163646697998, "_runtime": 6979.979619979858, "_timestamp": 1585516058.4003496, "_step": 24}
{"Episode reward": 37.79726032241536, "Episode length": 623, "Policy Loss": -2.056178569793701, "Value Loss": 15.242687225341797, "_runtime": 6981.545804262161, "_timestamp": 1585516059.966534, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7116453647613525, "Value Loss": 0.18790026009082794, "_runtime": 6982.267054319382, "_timestamp": 1585516060.687784, "_step": 26}
{"Episode reward": 53.564216835586905, "Episode length": 465, "Policy Loss": -1.0989110469818115, "Value Loss": 20.834869384765625, "_runtime": 6983.549857616425, "_timestamp": 1585516061.9705873, "_step": 27}
{"Episode reward": 16.810228307452505, "Episode length": 832, "Policy Loss": -1.7529505491256714, "Value Loss": 11.63326358795166, "_runtime": 6984.736645936966, "_timestamp": 1585516063.1573756, "_step": 28}
{"Episode reward": 24.900682425498957, "Episode length": 751, "Policy Loss": -1.7220113277435303, "Value Loss": 12.458558082580566, "_runtime": 6985.227041482925, "_timestamp": 1585516063.6477711, "_step": 29}
{"Episode reward": 69.1922044388017, "Episode length": 309, "Policy Loss": 0.14898447692394257, "Value Loss": 31.058828353881836, "_runtime": 6986.783484458923, "_timestamp": 1585516065.204214, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.695310354232788, "Value Loss": 0.17543183267116547, "_runtime": 6987.5224668979645, "_timestamp": 1585516065.9431965, "_step": 31}
{"Episode reward": 53.69999999999962, "Episode length": 463, "Policy Loss": -1.2169634103775024, "Value Loss": 21.179523468017578, "_runtime": 6988.8795337677, "_timestamp": 1585516067.3002634, "_step": 32}
{"Episode reward": 10.222659146414031, "Episode length": 899, "Policy Loss": -1.8390917778015137, "Value Loss": 10.748029708862305, "_runtime": 6989.494901418686, "_timestamp": 1585516067.915631, "_step": 33}
{"Episode reward": 62.599999999999746, "Episode length": 374, "Policy Loss": -0.9608134627342224, "Value Loss": 24.96047592163086, "_runtime": 6990.449493169785, "_timestamp": 1585516068.8702228, "_step": 34}
{"Episode reward": 37.394490455283346, "Episode length": 627, "Policy Loss": -1.350672960281372, "Value Loss": 14.601372718811035, "_runtime": 6992.056044578552, "_timestamp": 1585516070.4767742, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5238993167877197, "Value Loss": 0.3988405168056488, "_runtime": 6993.254337310791, "_timestamp": 1585516071.675067, "_step": 36}
{"Episode reward": 21.284919501003074, "Episode length": 788, "Policy Loss": -1.1712117195129395, "Value Loss": 11.727344512939453, "_runtime": 6994.347878694534, "_timestamp": 1585516072.7686083, "_step": 37}
{"Episode reward": 29.8718576504846, "Episode length": 702, "Policy Loss": -1.3057212829589844, "Value Loss": 12.838339805603027, "_runtime": 6995.901504039764, "_timestamp": 1585516074.3222337, "_step": 38}
{"Episode reward": -99.85609446801105, "Episode length": 999, "Policy Loss": -2.5298569202423096, "Value Loss": 0.17617447674274445, "_runtime": 6996.4899225234985, "_timestamp": 1585516074.9106522, "_step": 39}
{"Episode reward": 64.26128006838239, "Episode length": 358, "Policy Loss": -0.02712158113718033, "Value Loss": 25.464569091796875, "_runtime": 6997.198698282242, "_timestamp": 1585516075.619428, "_step": 40}
{"Episode reward": 55.083777555272334, "Episode length": 451, "Policy Loss": -0.4671272337436676, "Value Loss": 20.051015853881836, "_runtime": 6997.839870452881, "_timestamp": 1585516076.2606, "_step": 41}
{"Episode reward": 61.24794426821145, "Episode length": 388, "Policy Loss": 0.3091164827346802, "Value Loss": 23.07575225830078, "_runtime": 6999.355237483978, "_timestamp": 1585516077.7759671, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.507056713104248, "Value Loss": 0.11699546128511429, "_runtime": 7000.878940105438, "_timestamp": 1585516079.2996697, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.428394317626953, "Value Loss": 0.2837156653404236, "_runtime": 7001.473702907562, "_timestamp": 1585516079.8944325, "_step": 44}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 0.6627089381217957, "Value Loss": 23.150426864624023, "_runtime": 7003.032128810883, "_timestamp": 1585516081.4528584, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.518688201904297, "Value Loss": 0.14986874163150787, "_runtime": 7004.611180782318, "_timestamp": 1585516083.0319104, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.549142837524414, "Value Loss": 0.25587502121925354, "_runtime": 7005.65268778801, "_timestamp": 1585516084.0734174, "_step": 47}
{"Episode reward": 31.949278722609918, "Episode length": 681, "Policy Loss": -1.7512288093566895, "Value Loss": 14.062567710876465, "_runtime": 7006.277393579483, "_timestamp": 1585516084.6981232, "_step": 48}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": -0.6409656405448914, "Value Loss": 23.556726455688477, "_runtime": 7007.839319467545, "_timestamp": 1585516086.260049, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7210819721221924, "Value Loss": 0.13497330248355865, "_runtime": 7009.385196685791, "_timestamp": 1585516087.8059263, "_step": 50}
{"Episode reward": -99.83520318902889, "Episode length": 999, "Policy Loss": -2.85239839553833, "Value Loss": 0.2622544467449188, "_runtime": 7009.709395170212, "_timestamp": 1585516088.1301248, "_step": 51}
{"Episode reward": 80.68162592612207, "Episode length": 194, "Policy Loss": 2.903780698776245, "Value Loss": 58.4755859375, "_runtime": 7010.212629318237, "_timestamp": 1585516088.633359, "_step": 52}
{"Episode reward": 70.25376099608823, "Episode length": 298, "Policy Loss": -0.4342154264450073, "Value Loss": 29.941274642944336, "_runtime": 7010.775043487549, "_timestamp": 1585516089.1957731, "_step": 53}
{"Episode reward": 65.77116446346024, "Episode length": 343, "Policy Loss": -0.7544794082641602, "Value Loss": 31.022069931030273, "_runtime": 7011.080810546875, "_timestamp": 1585516089.5015402, "_step": 54}
{"Episode reward": 80.0, "Episode length": 200, "Policy Loss": 0.5091260075569153, "Value Loss": 55.45899963378906, "_runtime": 7011.844132900238, "_timestamp": 1585516090.2648625, "_step": 55}
{"Episode reward": 49.29999999999956, "Episode length": 507, "Policy Loss": 0.4801902174949646, "Value Loss": 19.56361198425293, "_runtime": 7013.359752655029, "_timestamp": 1585516091.7804823, "_step": 56}
{"Episode reward": -99.85663058543437, "Episode length": 999, "Policy Loss": -1.212161660194397, "Value Loss": 0.30056628584861755, "_runtime": 7014.2261662483215, "_timestamp": 1585516092.646896, "_step": 57}
{"Episode reward": 42.49923073910123, "Episode length": 576, "Policy Loss": 1.1088571548461914, "Value Loss": 18.243581771850586, "_runtime": 7015.4131462574005, "_timestamp": 1585516093.833876, "_step": 58}
{"Episode reward": 22.079323707521112, "Episode length": 780, "Policy Loss": 0.06653054803609848, "Value Loss": 12.589231491088867, "_runtime": 7016.181894779205, "_timestamp": 1585516094.6026244, "_step": 59}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": 0.5562088489532471, "Value Loss": 20.413387298583984, "_runtime": 7016.873979091644, "_timestamp": 1585516095.2947087, "_step": 60}
{"Episode reward": 55.39999999999964, "Episode length": 446, "Policy Loss": -0.2337622344493866, "Value Loss": 21.51580238342285, "_runtime": 7017.708930969238, "_timestamp": 1585516096.1296606, "_step": 61}
{"Episode reward": 49.705215799435535, "Episode length": 503, "Policy Loss": -0.7689533233642578, "Value Loss": 19.257165908813477, "_runtime": 7018.9114463329315, "_timestamp": 1585516097.332176, "_step": 62}
{"Episode reward": 21.679173567518774, "Episode length": 784, "Policy Loss": -1.0990484952926636, "Value Loss": 12.475061416625977, "_runtime": 7020.435311079025, "_timestamp": 1585516098.8560407, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1226108074188232, "Value Loss": 0.3561413288116455, "_runtime": 7021.980288982391, "_timestamp": 1585516100.4010186, "_step": 64}
{"Episode reward": -99.80596642643073, "Episode length": 999, "Policy Loss": -2.2234928607940674, "Value Loss": 0.5125877261161804, "_runtime": 7023.540361404419, "_timestamp": 1585516101.961091, "_step": 65}
{"Episode reward": -99.87088275104621, "Episode length": 999, "Policy Loss": -2.221492290496826, "Value Loss": 0.49689188599586487, "_runtime": 7024.530947685242, "_timestamp": 1585516102.9516773, "_step": 66}
{"Episode reward": 38.06256806850373, "Episode length": 620, "Policy Loss": -1.0700751543045044, "Value Loss": 16.08188247680664, "_runtime": 7026.107177019119, "_timestamp": 1585516104.5279067, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.414438247680664, "Value Loss": 0.11256718635559082, "_runtime": 7027.682254076004, "_timestamp": 1585516106.1029837, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3062705993652344, "Value Loss": 0.48369598388671875, "_runtime": 7029.215612411499, "_timestamp": 1585516107.636342, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3638577461242676, "Value Loss": 0.1537722945213318, "_runtime": 7030.482592582703, "_timestamp": 1585516108.9033222, "_step": 70}
{"Episode reward": 19.900000000000276, "Episode length": 801, "Policy Loss": -1.468580961227417, "Value Loss": 12.110140800476074, "_runtime": 7032.063285827637, "_timestamp": 1585516110.4840155, "_step": 71}
{"Episode reward": -99.8396752357469, "Episode length": 999, "Policy Loss": -2.3865697383880615, "Value Loss": 0.12129023671150208, "_runtime": 7033.644495248795, "_timestamp": 1585516112.065225, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4536983966827393, "Value Loss": 0.27841079235076904, "_runtime": 7034.516087293625, "_timestamp": 1585516112.936817, "_step": 73}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": -0.9869163036346436, "Value Loss": 17.832632064819336, "_runtime": 7036.104575395584, "_timestamp": 1585516114.525305, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3387367725372314, "Value Loss": 0.1243976503610611, "_runtime": 7037.687704801559, "_timestamp": 1585516116.1084344, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3563895225524902, "Value Loss": 0.18377476930618286, "_runtime": 7039.0359098911285, "_timestamp": 1585516117.4566395, "_step": 76}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": -1.4229180812835693, "Value Loss": 10.747907638549805, "_runtime": 7040.654601097107, "_timestamp": 1585516119.0753307, "_step": 77}
{"Episode reward": -99.8019638299928, "Episode length": 999, "Policy Loss": -2.420987367630005, "Value Loss": 0.25713273882865906, "_runtime": 7041.825585365295, "_timestamp": 1585516120.246315, "_step": 78}
{"Episode reward": 26.460968011617567, "Episode length": 736, "Policy Loss": -1.295445442199707, "Value Loss": 12.86121940612793, "_runtime": 7043.128043889999, "_timestamp": 1585516121.5487735, "_step": 79}
{"Episode reward": 17.100000000000435, "Episode length": 829, "Policy Loss": -0.8825740814208984, "Value Loss": 11.438873291015625, "_runtime": 7044.658831357956, "_timestamp": 1585516123.079561, "_step": 80}
{"Episode reward": 3.900000000001185, "Episode length": 961, "Policy Loss": -1.5023887157440186, "Value Loss": 9.945364952087402, "_runtime": 7046.20747590065, "_timestamp": 1585516124.6282055, "_step": 81}
{"Episode reward": -99.81684785820404, "Episode length": 999, "Policy Loss": -2.314708709716797, "Value Loss": 0.13413836061954498, "_runtime": 7047.444863796234, "_timestamp": 1585516125.8655934, "_step": 82}
{"Episode reward": 21.800000000000168, "Episode length": 782, "Policy Loss": -1.259371042251587, "Value Loss": 12.360878944396973, "_runtime": 7049.028662204742, "_timestamp": 1585516127.4493918, "_step": 83}
{"Episode reward": -99.80744013525405, "Episode length": 999, "Policy Loss": -2.2104320526123047, "Value Loss": 0.2061496376991272, "_runtime": 7050.087618350983, "_timestamp": 1585516128.508348, "_step": 84}
{"Episode reward": 32.99999999999953, "Episode length": 670, "Policy Loss": -1.028006672859192, "Value Loss": 13.995776176452637, "_runtime": 7051.6202166080475, "_timestamp": 1585516130.0409462, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.241748332977295, "Value Loss": 0.08129642903804779, "_runtime": 7053.194003105164, "_timestamp": 1585516131.6147327, "_step": 86}
{"Episode reward": -99.86059725433448, "Episode length": 999, "Policy Loss": -2.2136030197143555, "Value Loss": 0.06514271348714828, "_runtime": 7053.824524879456, "_timestamp": 1585516132.2452545, "_step": 87}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": -0.1460174322128296, "Value Loss": 23.887874603271484, "_runtime": 7055.38485455513, "_timestamp": 1585516133.8055842, "_step": 88}
{"Episode reward": -99.80464730858664, "Episode length": 999, "Policy Loss": -2.1598188877105713, "Value Loss": 0.06909820437431335, "_runtime": 7056.954637527466, "_timestamp": 1585516135.3753672, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2561612129211426, "Value Loss": 0.7772121429443359, "_runtime": 7058.4630353450775, "_timestamp": 1585516136.883765, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1297805309295654, "Value Loss": 0.09276432543992996, "_runtime": 7060.0336220264435, "_timestamp": 1585516138.4543517, "_step": 91}
{"Episode reward": -99.85409214645485, "Episode length": 999, "Policy Loss": -2.1111226081848145, "Value Loss": 0.06120496243238449, "_runtime": 7061.614897012711, "_timestamp": 1585516140.0356266, "_step": 92}
{"Episode reward": -99.80597835928062, "Episode length": 999, "Policy Loss": -2.0928707122802734, "Value Loss": 0.05751322582364082, "_runtime": 7063.154507637024, "_timestamp": 1585516141.5752373, "_step": 93}
{"Episode reward": -99.80407160669425, "Episode length": 999, "Policy Loss": -2.0606586933135986, "Value Loss": 0.10696984827518463, "_runtime": 7064.176896810532, "_timestamp": 1585516142.5976264, "_step": 94}
{"Episode reward": 38.699999999999406, "Episode length": 613, "Policy Loss": -0.504996120929718, "Value Loss": 15.680288314819336, "_runtime": 7064.916081190109, "_timestamp": 1585516143.3368108, "_step": 95}
{"Episode reward": 54.69999999999963, "Episode length": 453, "Policy Loss": 0.5417982935905457, "Value Loss": 20.710527420043945, "_runtime": 7066.220415592194, "_timestamp": 1585516144.6411452, "_step": 96}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": -0.7438163757324219, "Value Loss": 11.764991760253906, "_runtime": 7067.75280046463, "_timestamp": 1585516146.17353, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.958235263824463, "Value Loss": 0.06972891092300415, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775, 0.04600924625992775]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16139954328536987, 0.022563785314559937, 0.20652711391448975, 0.39049047231674194, 0.5744537711143494, 0.7584170699119568, 0.9423804879188538, 1.1263437271118164, 1.3103070259094238, 1.4942703247070312, 1.6782336235046387, 1.862196922302246, 2.0461604595184326, 2.23012375831604, 2.4140870571136475, 2.598050355911255, 2.7820136547088623, 2.9659769535064697, 3.149940252304077, 3.3339035511016846, 3.517866849899292, 3.7018303871154785, 3.885793447494507, 4.069756984710693, 4.253720760345459, 4.437684059143066, 4.621647357940674, 4.805610656738281, 4.989573955535889, 5.173537254333496, 5.3575005531311035, 5.541463851928711, 5.725427150726318, 5.909390449523926, 6.093353748321533, 6.277317047119141, 6.461280345916748, 6.6452436447143555, 6.829206943511963, 7.01317024230957, 7.197133541107178, 7.381097316741943, 7.565060615539551, 7.749023914337158, 7.932986736297607, 8.116950035095215, 8.300912857055664, 8.48487663269043, 8.668840408325195, 8.852803230285645, 9.03676700592041, 9.22072982788086, 9.404693603515625, 9.588656425476074, 9.77262020111084, 9.956583023071289, 10.140546798706055, 10.324509620666504, 10.50847339630127, 10.692436218261719, 10.876399993896484, 11.060362815856934, 11.2443265914917, 11.428289413452148, 11.612253189086914]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0025756300892680883, 0.005151260178536177, 0.007726890034973621, 0.010302520357072353, 0.012878150679171085, 0.015453780069947243, 0.018029410392045975, 0.020605040714144707, 0.02318067103624344, 0.02575630135834217, 0.028331931680440903, 0.030907560139894485, 0.03348319232463837, 0.03605882078409195, 0.03863445296883583, 0.04121008142828941, 0.043785709887742996, 0.04636134207248688, 0.04893697053194046, 0.05151260271668434, 0.054088231176137924, 0.056663863360881805, 0.05923949182033539, 0.06181512027978897, 0.06439074873924255, 0.06696638464927673, 0.06954201310873032, 0.0721176415681839, 0.07469327002763748, 0.07726890593767166, 0.07984453439712524, 0.08242016285657883, 0.08499579131603241, 0.08757141977548599, 0.09014705568552017, 0.09272268414497375, 0.09529831260442734, 0.09787394106388092, 0.1004495769739151, 0.10302520543336868, 0.10560083389282227, 0.10817646235227585, 0.11075209081172943, 0.11332772672176361, 0.1159033551812172, 0.11847898364067078, 0.12105461210012436, 0.12363024055957794, 0.12620587646961212, 0.1287814974784851, 0.1313571333885193, 0.13393276929855347, 0.13650839030742645, 0.13908402621746063, 0.1416596621274948, 0.1442352831363678, 0.14681091904640198, 0.14938654005527496, 0.15196217596530914, 0.15453781187534332, 0.1571134328842163, 0.1596890687942505, 0.16226468980312347, 0.16484032571315765]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [9.0, 13.0, 10.0, 20.0, 26.0, 32.0, 2.0, 0.0, 322.0, 3.0, 4.0, 3.0, 4.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 3.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.16401860117912292, -0.1445668488740921, -0.12511508166790009, -0.10566332936286926, -0.08621156960725784, -0.06675980985164642, -0.0473080575466156, -0.027856290340423584, -0.008404538035392761, 0.011047214269638062, 0.030498981475830078, 0.0499507337808609, 0.06940248608589172, 0.08885425329208374, 0.10830602049827576, 0.12775775790214539, 0.1472095251083374, 0.16666129231452942, 0.18611302971839905, 0.20556479692459106, 0.22501656413078308, 0.2444683015346527, 0.2639200687408447, 0.28337183594703674, 0.30282357335090637, 0.3222753405570984, 0.3417271077632904, 0.36117884516716003, 0.38063064217567444, 0.40008237957954407, 0.4195341169834137, 0.4389859139919281, 0.45843765139579773, 0.47788938879966736, 0.49734118580818176, 0.516792893409729, 0.5362446308135986, 0.5556964874267578, 0.5751482248306274, 0.5945999622344971, 0.6140516996383667, 0.6335034370422363, 0.652955174446106, 0.6724070310592651, 0.6918587684631348, 0.7113105058670044, 0.730762243270874, 0.7502139806747437, 0.7696657180786133, 0.7891175746917725, 0.8085693120956421, 0.8280210494995117, 0.8474727869033813, 0.866924524307251, 0.8863762617111206, 0.9058279991149902, 0.9252798557281494, 0.944731593132019, 0.9641833305358887, 0.9836350679397583, 1.003086805343628, 1.0225385427474976, 1.0419903993606567, 1.0614421367645264, 1.080893874168396]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6526951789855957, -0.5852364301681519, -0.517777681350708, -0.45031899213790894, -0.3828602433204651, -0.31540149450302124, -0.24794277548789978, -0.18048405647277832, -0.11302530765533447, -0.045566558837890625, 0.021892189979553223, 0.0893508791923523, 0.15680962800979614, 0.22426837682724, 0.29172706604003906, 0.3591858148574829, 0.42664456367492676, 0.4941033124923706, 0.5615620613098145, 0.6290208101272583, 0.6964795589447021, 0.7639381885528564, 0.8313969373703003, 0.8988556861877441, 0.966314435005188, 1.0337731838226318, 1.1012319326400757, 1.1686906814575195, 1.2361493110656738, 1.3036080598831177, 1.3710668087005615, 1.438525676727295, 1.5059843063354492, 1.5734429359436035, 1.640901803970337, 1.7083604335784912, 1.7758193016052246, 1.843277931213379, 1.9107367992401123, 1.9781954288482666, 2.045654296875, 2.1131129264831543, 2.1805715560913086, 2.248030424118042, 2.3154890537261963, 2.3829479217529297, 2.450406551361084, 2.5178654193878174, 2.5853240489959717, 2.652782678604126, 2.7202415466308594, 2.7877001762390137, 2.855159044265747, 2.9226176738739014, 2.9900765419006348, 3.057535171508789, 3.1249938011169434, 3.1924526691436768, 3.259911298751831, 3.3273701667785645, 3.3948287963867188, 3.462287425994873, 3.5297465324401855, 3.59720516204834, 3.664663791656494]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 6.0, 3.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.34130585193634033, -0.32558903098106384, -0.30987218022346497, -0.2941553592681885, -0.278438538312912, -0.2627217173576355, -0.24700486660003662, -0.23128804564476013, -0.21557120978832245, -0.19985437393188477, -0.18413755297660828, -0.1684207171201706, -0.1527038812637329, -0.13698706030845642, -0.12127022445201874, -0.10555340349674225, -0.08983656764030457, -0.07411974668502808, -0.0584028959274292, -0.04268607497215271, -0.02696925401687622, -0.011252403259277344, 0.0044644176959991455, 0.020181238651275635, 0.03589808940887451, 0.051614910364151, 0.06733173131942749, 0.08304855227470398, 0.09876540303230286, 0.11448222398757935, 0.13019904494285583, 0.1459158957004547, 0.1616327166557312, 0.17734956741333008, 0.19306635856628418, 0.20878320932388306, 0.22450006008148193, 0.24021685123443604, 0.2559337019920349, 0.2716505527496338, 0.2873673439025879, 0.30308419466018677, 0.31880104541778564, 0.33451783657073975, 0.3502346873283386, 0.3659515380859375, 0.3816683292388916, 0.3973851799964905, 0.41310203075408936, 0.42881882190704346, 0.44453567266464233, 0.46025246381759644, 0.4759693145751953, 0.4916861653327942, 0.5074029564857483, 0.5231198072433472, 0.538836658000946, 0.5545534491539001, 0.570270299911499, 0.5859871506690979, 0.601703941822052, 0.6174207925796509, 0.6331376433372498, 0.6488544344902039, 0.6645712852478027]}, "_runtime": 7068.800033569336, "_timestamp": 1585516147.2207632, "_step": 98}
{"Episode reward": 31.114010148867592, "Episode length": 689, "Policy Loss": -0.7121630311012268, "Value Loss": 13.939003944396973, "_runtime": 7070.341274738312, "_timestamp": 1585516148.7620044, "_step": 99}
{"Episode reward": -99.78249048143486, "Episode length": 999, "Policy Loss": -1.8933266401290894, "Value Loss": 0.0629168450832367, "_runtime": 7071.8969531059265, "_timestamp": 1585516150.3176827, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9124702215194702, "Value Loss": 0.047115445137023926, "_runtime": 7073.417747735977, "_timestamp": 1585516151.8384774, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8707448244094849, "Value Loss": 0.17484135925769806, "_runtime": 7074.55374789238, "_timestamp": 1585516152.9744775, "_step": 102}
{"Episode reward": 28.09999999999981, "Episode length": 719, "Policy Loss": -0.7127771973609924, "Value Loss": 12.922749519348145, "_runtime": 7076.1204624176025, "_timestamp": 1585516154.541192, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8172529935836792, "Value Loss": 0.04328353330492973, "_runtime": 7077.07090306282, "_timestamp": 1585516155.4916327, "_step": 104}
{"Episode reward": 40.19999999999943, "Episode length": 598, "Policy Loss": -0.5295851826667786, "Value Loss": 15.755937576293945, "_runtime": 7078.606997251511, "_timestamp": 1585516157.027727, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.777671456336975, "Value Loss": 0.054234977811574936, "_runtime": 7080.175857543945, "_timestamp": 1585516158.5965872, "_step": 106}
{"Episode reward": -99.81502130180458, "Episode length": 999, "Policy Loss": -1.7657456398010254, "Value Loss": 0.04443005472421646, "_runtime": 7081.549724817276, "_timestamp": 1585516159.9704545, "_step": 107}
{"Episode reward": 9.900000000000844, "Episode length": 901, "Policy Loss": -0.761874258518219, "Value Loss": 10.879873275756836, "_runtime": 7083.111514568329, "_timestamp": 1585516161.5322442, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7111719846725464, "Value Loss": 0.05295009911060333, "_runtime": 7084.672791957855, "_timestamp": 1585516163.0935216, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.705552339553833, "Value Loss": 0.0391329750418663, "_runtime": 7086.22089099884, "_timestamp": 1585516164.6416206, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7341594696044922, "Value Loss": 0.27128902077674866, "_runtime": 7087.561575651169, "_timestamp": 1585516165.9823053, "_step": 111}
{"Episode reward": 16.800000000000452, "Episode length": 832, "Policy Loss": -0.6850461363792419, "Value Loss": 11.36564826965332, "_runtime": 7089.106439113617, "_timestamp": 1585516167.5271688, "_step": 112}
{"Episode reward": -99.83005427270987, "Episode length": 999, "Policy Loss": -1.6416620016098022, "Value Loss": 0.041856225579977036, "_runtime": 7090.673483133316, "_timestamp": 1585516169.0942128, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6069141626358032, "Value Loss": 0.06349153816699982, "_runtime": 7092.23153924942, "_timestamp": 1585516170.652269, "_step": 114}
{"Episode reward": -99.89056570529797, "Episode length": 999, "Policy Loss": -1.532761812210083, "Value Loss": 0.08642284572124481, "_runtime": 7092.974505186081, "_timestamp": 1585516171.3952348, "_step": 115}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 0.22491773962974548, "Value Loss": 20.68914794921875, "_runtime": 7094.53334903717, "_timestamp": 1585516172.9540787, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5078378915786743, "Value Loss": 0.03996175155043602, "_runtime": 7096.107064247131, "_timestamp": 1585516174.527794, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.46857488155365, "Value Loss": 0.03156345710158348, "_runtime": 7097.613238334656, "_timestamp": 1585516176.033968, "_step": 118}
{"Episode reward": 0.5000000000013785, "Episode length": 995, "Policy Loss": -0.6221455335617065, "Value Loss": 9.571650505065918, "_runtime": 7099.185913801193, "_timestamp": 1585516177.6066434, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4525325298309326, "Value Loss": 0.12561500072479248, "_runtime": 7100.7591235637665, "_timestamp": 1585516179.1798532, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4001067876815796, "Value Loss": 0.033133525401353836, "_runtime": 7102.303318738937, "_timestamp": 1585516180.7240484, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3609181642532349, "Value Loss": 0.027180952951312065, "_runtime": 7103.47104883194, "_timestamp": 1585516181.8917785, "_step": 122}
{"Episode reward": 25.99999999999993, "Episode length": 740, "Policy Loss": 0.028454672545194626, "Value Loss": 12.63476848602295, "_runtime": 7105.043678760529, "_timestamp": 1585516183.4644084, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3312571048736572, "Value Loss": 0.0764351561665535, "_runtime": 7106.605449914932, "_timestamp": 1585516185.0261796, "_step": 124}
{"Episode reward": -99.84604000188271, "Episode length": 999, "Policy Loss": -1.3059492111206055, "Value Loss": 0.04658859223127365, "_runtime": 7108.147725582123, "_timestamp": 1585516186.5684552, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.309836983680725, "Value Loss": 0.16321507096290588, "_runtime": 7109.710149049759, "_timestamp": 1585516188.1308787, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.288098931312561, "Value Loss": 0.04409604147076607, "_runtime": 7111.308877944946, "_timestamp": 1585516189.7296076, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2810299396514893, "Value Loss": 0.037165649235248566, "_runtime": 7112.867918014526, "_timestamp": 1585516191.2886477, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.257352352142334, "Value Loss": 0.04522402584552765, "_runtime": 7113.588528394699, "_timestamp": 1585516192.009258, "_step": 129}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 0.6153467893600464, "Value Loss": 21.1079044342041, "_runtime": 7115.140371084213, "_timestamp": 1585516193.5611007, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.226148009300232, "Value Loss": 0.033470913767814636, "_runtime": 7115.934611082077, "_timestamp": 1585516194.3553407, "_step": 131}
{"Episode reward": 50.09999999999957, "Episode length": 499, "Policy Loss": 0.43701881170272827, "Value Loss": 19.17141342163086, "_runtime": 7116.406880140305, "_timestamp": 1585516194.8276098, "_step": 132}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 1.4207813739776611, "Value Loss": 30.5595760345459, "_runtime": 7117.42737364769, "_timestamp": 1585516195.8481033, "_step": 133}
{"Episode reward": 34.53644064515774, "Episode length": 655, "Policy Loss": 0.12173397839069366, "Value Loss": 14.288838386535645, "_runtime": 7118.946381807327, "_timestamp": 1585516197.3671114, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2242913246154785, "Value Loss": 0.12595798075199127, "_runtime": 7119.828194618225, "_timestamp": 1585516198.2489243, "_step": 135}
{"Episode reward": 40.29999999999943, "Episode length": 597, "Policy Loss": 0.05055537074804306, "Value Loss": 15.211194038391113, "_runtime": 7121.333365440369, "_timestamp": 1585516199.754095, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2438576221466064, "Value Loss": 0.18469750881195068, "_runtime": 7121.8303599357605, "_timestamp": 1585516200.2510896, "_step": 137}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 1.4001120328903198, "Value Loss": 30.345884323120117, "_runtime": 7123.33861041069, "_timestamp": 1585516201.75934, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2788982391357422, "Value Loss": 0.023743269965052605, "_runtime": 7124.885040998459, "_timestamp": 1585516203.3057706, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3813077211380005, "Value Loss": 0.3963012397289276, "_runtime": 7126.329289674759, "_timestamp": 1585516204.7500193, "_step": 140}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": -0.5363428592681885, "Value Loss": 9.567529678344727, "_runtime": 7127.87911939621, "_timestamp": 1585516206.299849, "_step": 141}
{"Episode reward": -99.81152864433685, "Episode length": 999, "Policy Loss": -1.403872013092041, "Value Loss": 0.09656908363103867, "_runtime": 7128.565526723862, "_timestamp": 1585516206.9862564, "_step": 142}
{"Episode reward": 56.899999999999665, "Episode length": 431, "Policy Loss": 0.4992600083351135, "Value Loss": 22.219764709472656, "_runtime": 7130.1150534152985, "_timestamp": 1585516208.535783, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.355898380279541, "Value Loss": 0.15568171441555023, "_runtime": 7131.67494726181, "_timestamp": 1585516210.095677, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4562816619873047, "Value Loss": 0.20659139752388, "_runtime": 7133.174963235855, "_timestamp": 1585516211.5956929, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3860057592391968, "Value Loss": 0.28620463609695435, "_runtime": 7133.9322028160095, "_timestamp": 1585516212.3529325, "_step": 146}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 0.3263058066368103, "Value Loss": 20.305646896362305, "_runtime": 7135.0471251010895, "_timestamp": 1585516213.4678547, "_step": 147}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 0.08356126397848129, "Value Loss": 14.2156982421875, "_runtime": 7135.561099052429, "_timestamp": 1585516213.9818287, "_step": 148}
{"Episode reward": 68.46450801454468, "Episode length": 316, "Policy Loss": 1.8510531187057495, "Value Loss": 30.08639144897461, "_runtime": 7136.350037574768, "_timestamp": 1585516214.7707672, "_step": 149}
{"Episode reward": 47.799999999999535, "Episode length": 522, "Policy Loss": 0.19464914500713348, "Value Loss": 18.050447463989258, "_runtime": 7137.892937660217, "_timestamp": 1585516216.3136673, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1477028131484985, "Value Loss": 0.02152767777442932, "_runtime": 7139.389607667923, "_timestamp": 1585516217.8103373, "_step": 151}
{"Episode reward": -99.82425490356842, "Episode length": 999, "Policy Loss": -1.1560567617416382, "Value Loss": 0.07497287541627884, "_runtime": 7140.730809926987, "_timestamp": 1585516219.1515396, "_step": 152}
{"Episode reward": 11.000000000000782, "Episode length": 890, "Policy Loss": -0.29212525486946106, "Value Loss": 10.834052085876465, "_runtime": 7142.297316789627, "_timestamp": 1585516220.7180464, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0607343912124634, "Value Loss": 0.03403729572892189, "_runtime": 7143.83779168129, "_timestamp": 1585516222.2585213, "_step": 154}
{"Episode reward": -99.8015080511556, "Episode length": 999, "Policy Loss": -1.1332085132598877, "Value Loss": 0.576053261756897, "_runtime": 7145.378728151321, "_timestamp": 1585516223.7994578, "_step": 155}
{"Episode reward": -99.89112417697767, "Episode length": 999, "Policy Loss": -1.017617106437683, "Value Loss": 0.015008890070021152, "_runtime": 7146.942843914032, "_timestamp": 1585516225.3635736, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0047924518585205, "Value Loss": 0.0622243657708168, "_runtime": 7147.8612060546875, "_timestamp": 1585516226.2819357, "_step": 157}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.47815996408462524, "Value Loss": 16.28081512451172, "_runtime": 7149.417883634567, "_timestamp": 1585516227.8386133, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9795148372650146, "Value Loss": 0.01758471690118313, "_runtime": 7150.982985258102, "_timestamp": 1585516229.403715, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9682118892669678, "Value Loss": 0.024755196645855904, "_runtime": 7151.21749329567, "_timestamp": 1585516229.638223, "_step": 160}
{"Episode reward": 87.00000000000003, "Episode length": 130, "Policy Loss": 5.401001453399658, "Value Loss": 72.7876968383789, "_runtime": 7152.759242296219, "_timestamp": 1585516231.179972, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9700443744659424, "Value Loss": 0.1045670211315155, "_runtime": 7154.330153226852, "_timestamp": 1585516232.7508829, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9509660601615906, "Value Loss": 0.02731185406446457, "_runtime": 7155.432111263275, "_timestamp": 1585516233.852841, "_step": 163}
{"Episode reward": 25.199999999999974, "Episode length": 748, "Policy Loss": 0.11001631617546082, "Value Loss": 13.861213684082031, "_runtime": 7156.993767499924, "_timestamp": 1585516235.4144971, "_step": 164}
{"Episode reward": -99.8006103515611, "Episode length": 999, "Policy Loss": -1.0137007236480713, "Value Loss": 0.12456274032592773, "_runtime": 7157.855402708054, "_timestamp": 1585516236.2761323, "_step": 165}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": 0.5876802802085876, "Value Loss": 17.73993682861328, "_runtime": 7158.596938610077, "_timestamp": 1585516237.0176682, "_step": 166}
{"Episode reward": 54.59999999999963, "Episode length": 454, "Policy Loss": 0.744220495223999, "Value Loss": 20.302745819091797, "_runtime": 7160.158967256546, "_timestamp": 1585516238.579697, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9796283841133118, "Value Loss": 0.021010011434555054, "_runtime": 7161.6802842617035, "_timestamp": 1585516240.101014, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0028774738311768, "Value Loss": 0.017720356583595276, "_runtime": 7162.809448003769, "_timestamp": 1585516241.2301776, "_step": 169}
{"Episode reward": 24.999999999999986, "Episode length": 750, "Policy Loss": 0.25025248527526855, "Value Loss": 12.76003360748291, "_runtime": 7164.362185955048, "_timestamp": 1585516242.7829156, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.051789402961731, "Value Loss": 0.12631216645240784, "_runtime": 7165.9206285476685, "_timestamp": 1585516244.3413582, "_step": 171}
{"Episode reward": -99.80719905495503, "Episode length": 999, "Policy Loss": -1.0238451957702637, "Value Loss": 0.05338098853826523, "_runtime": 7166.267248392105, "_timestamp": 1585516244.687978, "_step": 172}
{"Episode reward": 79.29999999999998, "Episode length": 207, "Policy Loss": 2.946704864501953, "Value Loss": 44.292510986328125, "_runtime": 7167.824337005615, "_timestamp": 1585516246.2450666, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0767955780029297, "Value Loss": 0.023462627083063126, "_runtime": 7168.8332397937775, "_timestamp": 1585516247.2539694, "_step": 174}
{"Episode reward": 35.69999999999938, "Episode length": 643, "Policy Loss": 0.16469748318195343, "Value Loss": 14.073726654052734, "_runtime": 7169.816137552261, "_timestamp": 1585516248.2368672, "_step": 175}
{"Episode reward": 33.5999999999995, "Episode length": 664, "Policy Loss": 0.027124250307679176, "Value Loss": 13.813919067382812, "_runtime": 7171.371857643127, "_timestamp": 1585516249.7925873, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1213419437408447, "Value Loss": 0.037076435983181, "_runtime": 7172.886610031128, "_timestamp": 1585516251.3073397, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1581470966339111, "Value Loss": 0.2124607264995575, "_runtime": 7174.400047302246, "_timestamp": 1585516252.820777, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1627229452133179, "Value Loss": 0.03295166417956352, "_runtime": 7175.966213941574, "_timestamp": 1585516254.3869436, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.170319676399231, "Value Loss": 0.0829763114452362, "_runtime": 7177.530244112015, "_timestamp": 1585516255.9509737, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1821168661117554, "Value Loss": 0.07045779377222061, "_runtime": 7179.0715119838715, "_timestamp": 1585516257.4922416, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1704579591751099, "Value Loss": 0.019878249615430832, "_runtime": 7180.645902633667, "_timestamp": 1585516259.0666323, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1741944551467896, "Value Loss": 0.02105807512998581, "_runtime": 7182.243298530579, "_timestamp": 1585516260.6640282, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.16361403465271, "Value Loss": 0.020410537719726562, "_runtime": 7183.734073400497, "_timestamp": 1585516262.154803, "_step": 184}
{"Episode reward": 3.121329683066648, "Episode length": 969, "Policy Loss": -0.36248579621315, "Value Loss": 9.964503288269043, "_runtime": 7184.267762422562, "_timestamp": 1585516262.688492, "_step": 185}
{"Episode reward": 68.69999999999983, "Episode length": 313, "Policy Loss": 1.3585143089294434, "Value Loss": 29.326770782470703, "_runtime": 7185.582866668701, "_timestamp": 1585516264.0035963, "_step": 186}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": -0.13933192193508148, "Value Loss": 11.126168251037598, "_runtime": 7187.13995552063, "_timestamp": 1585516265.5606852, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1741317510604858, "Value Loss": 0.036848440766334534, "_runtime": 7188.6298661231995, "_timestamp": 1585516267.0505958, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2043728828430176, "Value Loss": 0.10629507899284363, "_runtime": 7190.188923835754, "_timestamp": 1585516268.6096535, "_step": 189}
{"Episode reward": -99.77321431524912, "Episode length": 999, "Policy Loss": -1.1474339962005615, "Value Loss": 0.07755584269762039, "_runtime": 7191.742556810379, "_timestamp": 1585516270.1632864, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0120177268981934, "Value Loss": 0.15296603739261627, "_runtime": 7192.798895597458, "_timestamp": 1585516271.2196252, "_step": 191}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.13383017480373383, "Value Loss": 13.829438209533691, "_runtime": 7194.361806631088, "_timestamp": 1585516272.7825363, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0996317863464355, "Value Loss": 0.020846588537096977, "_runtime": 7194.850341081619, "_timestamp": 1585516273.2710707, "_step": 193}
{"Episode reward": 72.09999999999988, "Episode length": 279, "Policy Loss": 1.6849614381790161, "Value Loss": 32.44948196411133, "_runtime": 7196.39662861824, "_timestamp": 1585516274.8173583, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0944573879241943, "Value Loss": 0.01879790425300598, "_runtime": 7197.425413370132, "_timestamp": 1585516275.846143, "_step": 195}
{"Episode reward": 35.79999999999937, "Episode length": 642, "Policy Loss": -0.03421185165643692, "Value Loss": 14.113884925842285, "_runtime": 7198.935470819473, "_timestamp": 1585516277.3562005, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1017967462539673, "Value Loss": 0.029778476804494858, "_runtime": 7200.49919295311, "_timestamp": 1585516278.9199226, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1116979122161865, "Value Loss": 0.04889596998691559, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086, -0.057677287608385086]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-4.51469612121582, -4.4432525634765625, -4.371809482574463, -4.300365924835205, -4.2289228439331055, -4.157479286193848, -4.086036205291748, -4.01459264755249, -3.9431495666503906, -3.871706008911133, -3.800262928009033, -3.7288193702697754, -3.6573760509490967, -3.585932731628418, -3.5144894123077393, -3.4430460929870605, -3.371602773666382, -3.300159454345703, -3.2287161350250244, -3.1572728157043457, -3.085829496383667, -3.0143861770629883, -2.9429426193237305, -2.871499538421631, -2.800055980682373, -2.7286128997802734, -2.6571693420410156, -2.585726261138916, -2.514282703399658, -2.4428393840789795, -2.371396064758301, -2.299952745437622, -2.2285094261169434, -2.1570661067962646, -2.085622787475586, -2.0141794681549072, -1.9427361488342285, -1.8712928295135498, -1.799849510192871, -1.7284061908721924, -1.6569628715515137, -1.5855193138122559, -1.5140759944915771, -1.4426326751708984, -1.3711893558502197, -1.299746036529541, -1.2283027172088623, -1.1568593978881836, -1.0854160785675049, -1.0139727592468262, -0.9425294399261475, -0.8710861206054688, -0.79964280128479, -0.7281994819641113, -0.6567561626434326, -0.5853128433227539, -0.5138692855834961, -0.4424262046813965, -0.37098264694213867, -0.29953956604003906, -0.22809600830078125, -0.15665292739868164, -0.08520936965942383, -0.013766288757324219, 0.057677268981933594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.1604575514793396, -0.15795040130615234, -0.1554432511329651, -0.15293610095977783, -0.15042895078659058, -0.14792180061340332, -0.14541465044021606, -0.1429075002670288, -0.14040035009384155, -0.1378931999206543, -0.13538606464862823, -0.13287891447544098, -0.13037176430225372, -0.12786461412906647, -0.1253574639558792, -0.12285031378269196, -0.1203431636095047, -0.11783601343631744, -0.11532886326313019, -0.11282171308994293, -0.11031456291675568, -0.10780741274356842, -0.10530027002096176, -0.1027931198477745, -0.10028596967458725, -0.0977788195014, -0.09527166932821274, -0.09276451915502548, -0.09025737643241882, -0.08775022625923157, -0.08524307608604431, -0.08273592591285706, -0.0802287757396698, -0.07772162556648254, -0.07521447539329529, -0.07270732522010803, -0.07020017504692078, -0.06769303232431412, -0.06518588215112686, -0.0626787319779396, -0.06017158180475235, -0.057664431631565094, -0.05515728145837784, -0.05265013128519058, -0.05014298856258392, -0.04763583838939667, -0.04512868821620941, -0.042621538043022156, -0.0401143878698349, -0.037607237696647644, -0.03510008752346039, -0.03259293735027313, -0.030085787177085876, -0.02757863700389862, -0.025071486830711365, -0.02256433665752411, -0.020057201385498047, -0.01755005121231079, -0.015042901039123535, -0.01253575086593628, -0.010028600692749023, -0.007521450519561768, -0.005014300346374512, -0.002507150173187256, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 4.0, 4.0, 4.0, 4.0, 1.0, 3.0, 4.0, 3.0, 2.0, 5.0, 0.0, 5.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 0.0, 1.0, 4.0, 6.0, 18.0, 22.0, 19.0, 22.0, 16.0], "bins": [-0.6937400102615356, -0.6804502010345459, -0.6671603918075562, -0.6538705825805664, -0.6405808329582214, -0.6272910237312317, -0.6140012145042419, -0.6007114052772522, -0.5874215960502625, -0.5741318464279175, -0.5608420372009277, -0.547552227973938, -0.5342624187469482, -0.5209726095199585, -0.5076828002929688, -0.4943930208683014, -0.48110324144363403, -0.4678134322166443, -0.45452362298965454, -0.4412338435649872, -0.42794403433799744, -0.4146542251110077, -0.40136444568634033, -0.3880746364593506, -0.37478482723236084, -0.3614950478076935, -0.34820523858070374, -0.334915429353714, -0.32162564992904663, -0.3083358407020569, -0.29504603147506714, -0.2817562520503998, -0.26846644282341003, -0.2551766335964203, -0.24188685417175293, -0.22859704494476318, -0.21530723571777344, -0.20201745629310608, -0.18872767686843872, -0.17543786764144897, -0.16214805841445923, -0.14885824918746948, -0.13556843996047974, -0.12227863073348999, -0.10898888111114502, -0.09569907188415527, -0.08240926265716553, -0.06911945343017578, -0.055829644203186035, -0.04253983497619629, -0.02925008535385132, -0.015960276126861572, -0.002670466899871826, 0.01061934232711792, 0.023909151554107666, 0.03719896078109741, 0.05048871040344238, 0.06377851963043213, 0.07706832885742188, 0.09035813808441162, 0.10364794731140137, 0.11693775653839111, 0.13022750616073608, 0.14351731538772583, 0.15680712461471558]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0], "bins": [-3.465212345123291, -3.4045281410217285, -3.343843936920166, -3.2831597328186035, -3.222475528717041, -3.1617913246154785, -3.101107120513916, -3.0404229164123535, -2.979738712310791, -2.9190545082092285, -2.858370304107666, -2.7976861000061035, -2.737001895904541, -2.6763176918029785, -2.615633487701416, -2.5549492835998535, -2.494265079498291, -2.4335808753967285, -2.372896671295166, -2.3122124671936035, -2.251528263092041, -2.1908440589904785, -2.130159854888916, -2.0694756507873535, -2.00879168510437, -1.9481074810028076, -1.8874232769012451, -1.8267390727996826, -1.7660548686981201, -1.7053706645965576, -1.6446864604949951, -1.5840022563934326, -1.5233180522918701, -1.4626338481903076, -1.4019496440887451, -1.3412654399871826, -1.2805812358856201, -1.2198970317840576, -1.1592128276824951, -1.0985286235809326, -1.0378444194793701, -0.9771602153778076, -0.9164760112762451, -0.8557918071746826, -0.7951076030731201, -0.7344233989715576, -0.6737391948699951, -0.6130549907684326, -0.5523710250854492, -0.4916868209838867, -0.4310026168823242, -0.3703184127807617, -0.3096342086791992, -0.24895000457763672, -0.18826580047607422, -0.12758159637451172, -0.06689739227294922, -0.006213188171386719, 0.05447101593017578, 0.11515522003173828, 0.17583942413330078, 0.23652362823486328, 0.2972078323364258, 0.3578920364379883, 0.4185762405395508]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 5.0, 11.0, 13.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0], "bins": [-1.0451698303222656, -1.02610445022583, -1.0070390701293945, -0.9879737496376038, -0.9689083695411682, -0.9498430490493774, -0.9307776689529419, -0.9117122888565063, -0.8926469087600708, -0.87358158826828, -0.8545162081718445, -0.8354508876800537, -0.8163855075836182, -0.7973201274871826, -0.7782547473907471, -0.7591893672943115, -0.7401240468025208, -0.72105872631073, -0.7019933462142944, -0.6829279661178589, -0.6638625860214233, -0.6447972059249878, -0.625731885433197, -0.6066665053367615, -0.5876011848449707, -0.5685358047485352, -0.5494704246520996, -0.5304050445556641, -0.5113397240638733, -0.49227434396743774, -0.4732089638710022, -0.4541436433792114, -0.4350782632827759, -0.41601288318634033, -0.39694756269454956, -0.377882182598114, -0.35881680250167847, -0.3397514820098877, -0.32068610191345215, -0.3016207218170166, -0.28255534172058105, -0.2634900212287903, -0.24442464113235474, -0.2253592610359192, -0.20629394054412842, -0.18722856044769287, -0.16816318035125732, -0.14909785985946655, -0.130032479763031, -0.11096709966659546, -0.09190177917480469, -0.07283639907836914, -0.053771018981933594, -0.03470563888549805, -0.0156402587890625, 0.003425002098083496, 0.022490382194519043, 0.04155576229095459, 0.06062114238739014, 0.07968652248382568, 0.09875190258026123, 0.11781716346740723, 0.13688254356384277, 0.15594792366027832, 0.17501330375671387]}, "_runtime": 7202.047789812088, "_timestamp": 1585516280.4685194, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1701544523239136, "Value Loss": 0.4710009694099426, "_runtime": 7203.618938446045, "_timestamp": 1585516282.039668, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1484285593032837, "Value Loss": 0.04224421828985214, "_runtime": 7204.613218784332, "_timestamp": 1585516283.0339484, "_step": 200}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.1912653148174286, "Value Loss": 14.264488220214844, "_runtime": 7206.221765041351, "_timestamp": 1585516284.6424947, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1591603755950928, "Value Loss": 0.10582730919122696, "_runtime": 7207.7874965667725, "_timestamp": 1585516286.2082262, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0713292360305786, "Value Loss": 0.23385435342788696, "_runtime": 7208.814245700836, "_timestamp": 1585516287.2349753, "_step": 203}
{"Episode reward": 34.39999999999945, "Episode length": 656, "Policy Loss": 0.18983161449432373, "Value Loss": 14.246959686279297, "_runtime": 7209.518671035767, "_timestamp": 1585516287.9394007, "_step": 204}
{"Episode reward": 56.299999999999656, "Episode length": 437, "Policy Loss": 0.5599775910377502, "Value Loss": 20.059690475463867, "_runtime": 7210.947822809219, "_timestamp": 1585516289.3685524, "_step": 205}
{"Episode reward": 9.684357357026002, "Episode length": 904, "Policy Loss": -0.38476085662841797, "Value Loss": 9.91331958770752, "_runtime": 7211.659187078476, "_timestamp": 1585516290.0799167, "_step": 206}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 0.4497756361961365, "Value Loss": 19.31313705444336, "_runtime": 7212.99081659317, "_timestamp": 1585516291.4115462, "_step": 207}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": -0.1478438377380371, "Value Loss": 11.44987678527832, "_runtime": 7213.744111776352, "_timestamp": 1585516292.1648414, "_step": 208}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 0.45400866866111755, "Value Loss": 19.314105987548828, "_runtime": 7215.267922878265, "_timestamp": 1585516293.6886525, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2457796335220337, "Value Loss": 0.14023245871067047, "_runtime": 7216.81032204628, "_timestamp": 1585516295.2310517, "_step": 210}
{"Episode reward": -99.75829561501602, "Episode length": 999, "Policy Loss": -1.1160873174667358, "Value Loss": 0.13876987993717194, "_runtime": 7218.3334221839905, "_timestamp": 1585516296.7541518, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2108736038208008, "Value Loss": 0.06567102670669556, "_runtime": 7219.9094524383545, "_timestamp": 1585516298.330182, "_step": 212}
{"Episode reward": -99.83331003188947, "Episode length": 999, "Policy Loss": -1.1686248779296875, "Value Loss": 0.03255467116832733, "_runtime": 7221.492453336716, "_timestamp": 1585516299.913183, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1678909063339233, "Value Loss": 0.07782071828842163, "_runtime": 7222.379015922546, "_timestamp": 1585516300.7997456, "_step": 214}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.22449152171611786, "Value Loss": 16.2917423248291, "_runtime": 7223.945212125778, "_timestamp": 1585516302.3659418, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1011782884597778, "Value Loss": 0.0583115890622139, "_runtime": 7225.516882896423, "_timestamp": 1585516303.9376125, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0729219913482666, "Value Loss": 0.03777020797133446, "_runtime": 7226.83410525322, "_timestamp": 1585516305.254835, "_step": 217}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": -0.15466353297233582, "Value Loss": 10.141800880432129, "_runtime": 7228.209114789963, "_timestamp": 1585516306.6298444, "_step": 218}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": -0.16044700145721436, "Value Loss": 10.169196128845215, "_runtime": 7229.8246104717255, "_timestamp": 1585516308.24534, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0972166061401367, "Value Loss": 0.032073553651571274, "_runtime": 7231.3833775520325, "_timestamp": 1585516309.8041072, "_step": 220}
{"Episode reward": -99.85592089295247, "Episode length": 999, "Policy Loss": -1.1391899585723877, "Value Loss": 0.0658530592918396, "_runtime": 7232.022755146027, "_timestamp": 1585516310.4434848, "_step": 221}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 0.866550862789154, "Value Loss": 23.063486099243164, "_runtime": 7233.597203969955, "_timestamp": 1585516312.0179336, "_step": 222}
{"Episode reward": -99.80315027832846, "Episode length": 999, "Policy Loss": -1.1232157945632935, "Value Loss": 0.025275912135839462, "_runtime": 7235.178055047989, "_timestamp": 1585516313.5987847, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1308649778366089, "Value Loss": 0.02560182474553585, "_runtime": 7236.697356462479, "_timestamp": 1585516315.118086, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1375229358673096, "Value Loss": 0.04228682070970535, "_runtime": 7237.511282205582, "_timestamp": 1585516315.9320118, "_step": 225}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": 0.38858717679977417, "Value Loss": 18.258678436279297, "_runtime": 7237.9160442352295, "_timestamp": 1585516316.3367739, "_step": 226}
{"Episode reward": 77.49999999999996, "Episode length": 225, "Policy Loss": 2.0130748748779297, "Value Loss": 38.12834167480469, "_runtime": 7239.47768163681, "_timestamp": 1585516317.8984113, "_step": 227}
{"Episode reward": -99.8015747308717, "Episode length": 999, "Policy Loss": -1.108899712562561, "Value Loss": 0.151015967130661, "_runtime": 7241.0200209617615, "_timestamp": 1585516319.4407506, "_step": 228}
{"Episode reward": -99.85400240421156, "Episode length": 999, "Policy Loss": -0.9920584559440613, "Value Loss": 0.40309059619903564, "_runtime": 7242.522645235062, "_timestamp": 1585516320.9433749, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1227353811264038, "Value Loss": 0.24273920059204102, "_runtime": 7244.092015028, "_timestamp": 1585516322.5127447, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2192164659500122, "Value Loss": 0.0803823471069336, "_runtime": 7245.013011932373, "_timestamp": 1585516323.4337416, "_step": 231}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 0.17889244854450226, "Value Loss": 16.08323097229004, "_runtime": 7246.35165643692, "_timestamp": 1585516324.772386, "_step": 232}
{"Episode reward": 13.497178649902992, "Episode length": 866, "Policy Loss": -0.4081832468509674, "Value Loss": 10.658350944519043, "_runtime": 7247.035884618759, "_timestamp": 1585516325.4566143, "_step": 233}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 0.672084629535675, "Value Loss": 23.918819427490234, "_runtime": 7248.345209121704, "_timestamp": 1585516326.7659388, "_step": 234}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": -0.10274355858564377, "Value Loss": 11.097237586975098, "_runtime": 7249.339434623718, "_timestamp": 1585516327.7601643, "_step": 235}
{"Episode reward": 36.81364753805039, "Episode length": 632, "Policy Loss": 0.2596588134765625, "Value Loss": 15.13280963897705, "_runtime": 7250.171604394913, "_timestamp": 1585516328.592334, "_step": 236}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 0.4434923529624939, "Value Loss": 17.624073028564453, "_runtime": 7251.731828927994, "_timestamp": 1585516330.1525586, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0249511003494263, "Value Loss": 0.035921115428209305, "_runtime": 7252.322806596756, "_timestamp": 1585516330.7435362, "_step": 238}
{"Episode reward": 62.99999999999975, "Episode length": 370, "Policy Loss": 1.1930114030838013, "Value Loss": 24.078645706176758, "_runtime": 7253.874865055084, "_timestamp": 1585516332.2955947, "_step": 239}
{"Episode reward": -99.81317959427695, "Episode length": 999, "Policy Loss": -0.6974722146987915, "Value Loss": 1.4814188480377197, "_runtime": 7254.430234909058, "_timestamp": 1585516332.8509645, "_step": 240}
{"Episode reward": 67.09999999999981, "Episode length": 329, "Policy Loss": 1.4259663820266724, "Value Loss": 28.15456199645996, "_runtime": 7255.94581079483, "_timestamp": 1585516334.3665404, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9736615419387817, "Value Loss": 0.014141662046313286, "_runtime": 7256.863575696945, "_timestamp": 1585516335.2843053, "_step": 242}
{"Episode reward": 42.39999999999946, "Episode length": 576, "Policy Loss": 0.33233559131622314, "Value Loss": 15.65030574798584, "_runtime": 7258.374059915543, "_timestamp": 1585516336.7947896, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.166360855102539, "Value Loss": 0.359392374753952, "_runtime": 7259.086834669113, "_timestamp": 1585516337.5075643, "_step": 244}
{"Episode reward": 56.38920133113827, "Episode length": 437, "Policy Loss": 0.8146167993545532, "Value Loss": 21.9418888092041, "_runtime": 7259.547748327255, "_timestamp": 1585516337.968478, "_step": 245}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 2.257425546646118, "Value Loss": 32.43779373168945, "_runtime": 7261.100479364395, "_timestamp": 1585516339.521209, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0426915884017944, "Value Loss": 0.5147874355316162, "_runtime": 7262.626808643341, "_timestamp": 1585516341.0475383, "_step": 247}
{"Episode reward": -99.80214576721052, "Episode length": 999, "Policy Loss": -0.8939254879951477, "Value Loss": 0.032044414430856705, "_runtime": 7264.08870100975, "_timestamp": 1585516342.5094306, "_step": 248}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.01492428220808506, "Value Loss": 9.973183631896973, "_runtime": 7265.008645772934, "_timestamp": 1585516343.4293754, "_step": 249}
{"Episode reward": 42.799999999999464, "Episode length": 572, "Policy Loss": 0.6407735347747803, "Value Loss": 16.20570182800293, "_runtime": 7266.581644773483, "_timestamp": 1585516345.0023744, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7253901362419128, "Value Loss": 0.16428989171981812, "_runtime": 7268.133285999298, "_timestamp": 1585516346.5540156, "_step": 251}
{"Episode reward": -99.80010862946371, "Episode length": 999, "Policy Loss": -0.6758043169975281, "Value Loss": 0.013145185075700283, "_runtime": 7269.674320459366, "_timestamp": 1585516348.09505, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.657634973526001, "Value Loss": 0.02913009747862816, "_runtime": 7271.202480554581, "_timestamp": 1585516349.6232102, "_step": 253}
{"Episode reward": 3.8469887312513578, "Episode length": 962, "Policy Loss": 0.2295685112476349, "Value Loss": 9.499470710754395, "_runtime": 7272.768822431564, "_timestamp": 1585516351.189552, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6054728627204895, "Value Loss": 0.07804984599351883, "_runtime": 7273.691661596298, "_timestamp": 1585516352.1123912, "_step": 255}
{"Episode reward": 41.399999999999444, "Episode length": 586, "Policy Loss": 0.8343484997749329, "Value Loss": 16.083175659179688, "_runtime": 7275.2610013484955, "_timestamp": 1585516353.681731, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.560185432434082, "Value Loss": 0.03682661056518555, "_runtime": 7276.830610513687, "_timestamp": 1585516355.2513402, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5732866525650024, "Value Loss": 0.018181433901190758, "_runtime": 7278.395637512207, "_timestamp": 1585516356.8163671, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.503150224685669, "Value Loss": 0.04409858211874962, "_runtime": 7279.958654880524, "_timestamp": 1585516358.3793845, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5364803671836853, "Value Loss": 0.014011921361088753, "_runtime": 7280.434874296188, "_timestamp": 1585516358.855604, "_step": 260}
{"Episode reward": 71.89999999999988, "Episode length": 281, "Policy Loss": 2.439384698867798, "Value Loss": 32.89134216308594, "_runtime": 7282.00253534317, "_timestamp": 1585516360.423265, "_step": 261}
{"Episode reward": -99.81690301895001, "Episode length": 999, "Policy Loss": -0.545684278011322, "Value Loss": 0.008060095831751823, "_runtime": 7282.629101753235, "_timestamp": 1585516361.0498314, "_step": 262}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.5505404472351074, "Value Loss": 25.770471572875977, "_runtime": 7284.139914274216, "_timestamp": 1585516362.560644, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5958864688873291, "Value Loss": 0.007098085712641478, "_runtime": 7285.322456359863, "_timestamp": 1585516363.743186, "_step": 264}
{"Episode reward": 24.799999999999997, "Episode length": 752, "Policy Loss": 0.5960991978645325, "Value Loss": 12.353286743164062, "_runtime": 7286.827217102051, "_timestamp": 1585516365.2479467, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6276911497116089, "Value Loss": 0.016147615388035774, "_runtime": 7288.171974897385, "_timestamp": 1585516366.5927045, "_step": 266}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": 0.28423556685447693, "Value Loss": 10.555312156677246, "_runtime": 7289.728693246841, "_timestamp": 1585516368.149423, "_step": 267}
{"Episode reward": -99.87858372330525, "Episode length": 999, "Policy Loss": -0.6685368418693542, "Value Loss": 0.01191441435366869, "_runtime": 7291.041299343109, "_timestamp": 1585516369.462029, "_step": 268}
{"Episode reward": 15.999477767944839, "Episode length": 841, "Policy Loss": 0.2311369627714157, "Value Loss": 10.852364540100098, "_runtime": 7292.515558958054, "_timestamp": 1585516370.9362886, "_step": 269}
{"Episode reward": 4.997489446402724, "Episode length": 951, "Policy Loss": 0.07328162342309952, "Value Loss": 9.813739776611328, "_runtime": 7294.099117517471, "_timestamp": 1585516372.5198472, "_step": 270}
{"Episode reward": -99.8938476562486, "Episode length": 999, "Policy Loss": -0.8318414688110352, "Value Loss": 0.03641004487872124, "_runtime": 7295.653913974762, "_timestamp": 1585516374.0746436, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8705020546913147, "Value Loss": 0.04812341555953026, "_runtime": 7297.220512390137, "_timestamp": 1585516375.641242, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.916390061378479, "Value Loss": 0.021903062239289284, "_runtime": 7298.808085441589, "_timestamp": 1585516377.228815, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.960010290145874, "Value Loss": 0.01676441915333271, "_runtime": 7299.5693616867065, "_timestamp": 1585516377.9900913, "_step": 274}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 0.6582625508308411, "Value Loss": 19.439756393432617, "_runtime": 7301.1751873493195, "_timestamp": 1585516379.595917, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9829099178314209, "Value Loss": 0.034176696091890335, "_runtime": 7302.764853715897, "_timestamp": 1585516381.1855834, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0170280933380127, "Value Loss": 0.028468165546655655, "_runtime": 7304.280780553818, "_timestamp": 1585516382.7015102, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0585486888885498, "Value Loss": 0.015729621052742004, "_runtime": 7304.684787750244, "_timestamp": 1585516383.1055174, "_step": 278}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 2.4259192943573, "Value Loss": 40.14263916015625, "_runtime": 7306.2629816532135, "_timestamp": 1585516384.6837113, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1215603351593018, "Value Loss": 0.059914905577898026, "_runtime": 7307.194429159164, "_timestamp": 1585516385.6151588, "_step": 280}
{"Episode reward": 41.81555395126288, "Episode length": 582, "Policy Loss": 0.15234754979610443, "Value Loss": 15.558672904968262, "_runtime": 7308.5607051849365, "_timestamp": 1585516386.9814348, "_step": 281}
{"Episode reward": 8.20000000000094, "Episode length": 918, "Policy Loss": -0.18704816699028015, "Value Loss": 10.281991004943848, "_runtime": 7309.78831410408, "_timestamp": 1585516388.2090437, "_step": 282}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": -0.2545923888683319, "Value Loss": 11.29115104675293, "_runtime": 7310.435017108917, "_timestamp": 1585516388.8557467, "_step": 283}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 0.993186354637146, "Value Loss": 23.581186294555664, "_runtime": 7311.982179880142, "_timestamp": 1585516390.4029095, "_step": 284}
{"Episode reward": -99.8069394171224, "Episode length": 999, "Policy Loss": -1.2164181470870972, "Value Loss": 0.12635408341884613, "_runtime": 7313.543280363083, "_timestamp": 1585516391.96401, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2007975578308105, "Value Loss": 0.05916881933808327, "_runtime": 7314.744406700134, "_timestamp": 1585516393.1651363, "_step": 286}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": -0.1251424103975296, "Value Loss": 11.437078475952148, "_runtime": 7316.3011655807495, "_timestamp": 1585516394.7218952, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2295658588409424, "Value Loss": 0.05003178119659424, "_runtime": 7317.88499379158, "_timestamp": 1585516396.3057234, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2828826904296875, "Value Loss": 0.08448117226362228, "_runtime": 7318.698390245438, "_timestamp": 1585516397.11912, "_step": 289}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 0.09407605230808258, "Value Loss": 17.0225887298584, "_runtime": 7320.267300128937, "_timestamp": 1585516398.6880298, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2777552604675293, "Value Loss": 0.0457313135266304, "_runtime": 7321.828846216202, "_timestamp": 1585516400.2495759, "_step": 291}
{"Episode reward": 1.9000000000012989, "Episode length": 981, "Policy Loss": -0.5304372906684875, "Value Loss": 8.908795356750488, "_runtime": 7322.212709188461, "_timestamp": 1585516400.6334388, "_step": 292}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 2.0235798358917236, "Value Loss": 37.913021087646484, "_runtime": 7323.4487454891205, "_timestamp": 1585516401.8694751, "_step": 293}
{"Episode reward": 20.300000000000253, "Episode length": 797, "Policy Loss": -0.5796244740486145, "Value Loss": 10.633066177368164, "_runtime": 7325.054199934006, "_timestamp": 1585516403.4749296, "_step": 294}
{"Episode reward": -99.86546137332776, "Episode length": 999, "Policy Loss": -1.5590871572494507, "Value Loss": 0.03815525025129318, "_runtime": 7325.868493556976, "_timestamp": 1585516404.2892232, "_step": 295}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": -0.2107909917831421, "Value Loss": 15.992907524108887, "_runtime": 7327.416503429413, "_timestamp": 1585516405.837233, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6434637308120728, "Value Loss": 0.08188798278570175, "_runtime": 7327.8023681640625, "_timestamp": 1585516406.2230978, "_step": 297}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 1.4431911706924438, "Value Loss": 39.15042495727539, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571, -0.0268850140273571]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.4503321647644043, -3.370713949203491, -3.291095733642578, -3.211477518081665, -3.131859302520752, -3.052241325378418, -2.972622871398926, -2.893004894256592, -2.8133866786956787, -2.7337684631347656, -2.6541502475738525, -2.5745320320129395, -2.4949138164520264, -2.4152956008911133, -2.3356776237487793, -2.256059169769287, -2.176441192626953, -2.096822738647461, -2.017204761505127, -1.9375865459442139, -1.8579683303833008, -1.7783501148223877, -1.6987318992614746, -1.6191136837005615, -1.5394954681396484, -1.459877371788025, -1.3802590370178223, -1.3006410598754883, -1.2210228443145752, -1.141404628753662, -1.061786413192749, -0.9821681976318359, -0.9025499820709229, -0.8229317665100098, -0.7433135509490967, -0.6636953353881836, -0.5840771198272705, -0.5044589042663574, -0.42484092712402344, -0.34522271156311035, -0.26560449600219727, -0.18598628044128418, -0.1063680648803711, -0.026749849319458008, 0.05286836624145508, 0.13248658180236816, 0.21210479736328125, 0.29172301292419434, 0.3713412284851074, 0.4509592056274414, 0.5305774211883545, 0.6101956367492676, 0.6898140907287598, 0.7694320678710938, 0.8490500450134277, 0.9286684989929199, 1.008286476135254, 1.087904930114746, 1.16752290725708, 1.2471413612365723, 1.3267593383789062, 1.4063777923583984, 1.4859957695007324, 1.5656142234802246, 1.6452322006225586]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.08179841935634613, -0.08052031695842743, -0.07924222201108932, -0.07796411961317062, -0.07668601721525192, -0.07540791481733322, -0.07412981986999512, -0.07285171747207642, -0.07157361507415771, -0.07029551267623901, -0.06901741772890091, -0.06773931533098221, -0.06646121293306351, -0.0651831179857254, -0.0639050155878067, -0.062626913189888, -0.0613488145172596, -0.060070715844631195, -0.058792613446712494, -0.05751451104879379, -0.05623641237616539, -0.05495831370353699, -0.053680211305618286, -0.05240211263298988, -0.05112401396036148, -0.04984591156244278, -0.04856781288981438, -0.047289710491895676, -0.04601161181926727, -0.04473350942134857, -0.04345541074872017, -0.04217730835080147, -0.040899209678173065, -0.03962111100554466, -0.03834300860762596, -0.03706490993499756, -0.03578680753707886, -0.034508708864450455, -0.033230606466531754, -0.03195250779390335, -0.03067440539598465, -0.029396306723356247, -0.028118208050727844, -0.026840105652809143, -0.02556200698018074, -0.02428390458226204, -0.023005805909633636, -0.021727703511714935, -0.020449604839086533, -0.01917150616645813, -0.01789340376853943, -0.016615301370620728, -0.015337206423282623, -0.014059104025363922, -0.012781001627445221, -0.01150289922952652, -0.010224804282188416, -0.008946701884269714, -0.007668599486351013, -0.006390504539012909, -0.005112402141094208, -0.0038342997431755066, -0.0025561973452568054, -0.0012781023979187012, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 0.0, 3.0, 323.0, 0.0, 8.0, 27.0, 13.0, 26.0, 17.0, 26.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.5324039459228516, -0.5218083262443542, -0.5112127065658569, -0.5006170868873596, -0.4900214672088623, -0.479425847530365, -0.4688302278518677, -0.458234578371048, -0.44763895869255066, -0.43704333901405334, -0.42644771933555603, -0.4158520996570587, -0.4052564799785614, -0.3946608603000641, -0.3840652108192444, -0.37346959114074707, -0.36287397146224976, -0.35227835178375244, -0.3416827321052551, -0.3310871124267578, -0.3204914927482605, -0.3098958730697632, -0.29930025339126587, -0.28870463371276855, -0.27810901403427124, -0.2675133943557739, -0.2569177746772766, -0.2463221251964569, -0.2357265055179596, -0.22513088583946228, -0.21453526616096497, -0.20393964648246765, -0.19334402680397034, -0.18274840712547302, -0.1721527874469757, -0.1615571677684784, -0.15096154808998108, -0.14036592841148376, -0.12977027893066406, -0.11917465925216675, -0.10857903957366943, -0.09798341989517212, -0.0873878002166748, -0.07679218053817749, -0.06619656085968018, -0.05560094118118286, -0.04500532150268555, -0.03440970182418823, -0.023814082145690918, -0.013218462467193604, -0.002622842788696289, 0.007972776889801025, 0.01856839656829834, 0.029164016246795654, 0.039759695529937744, 0.05035531520843506, 0.06095093488693237, 0.07154655456542969, 0.082142174243927, 0.09273779392242432, 0.10333341360092163, 0.11392903327941895, 0.12452465295791626, 0.13512027263641357, 0.1457158923149109]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0], "bins": [-1.693762183189392, -1.6629070043563843, -1.632051706314087, -1.601196527481079, -1.5703413486480713, -1.539486050605774, -1.5086308717727661, -1.4777755737304688, -1.446920394897461, -1.4160652160644531, -1.3852099180221558, -1.354354739189148, -1.3234994411468506, -1.2926442623138428, -1.261789083480835, -1.2309339046478271, -1.2000786066055298, -1.1692233085632324, -1.1383681297302246, -1.1075129508972168, -1.076657772064209, -1.0458024740219116, -1.0149472951889038, -0.9840920567512512, -0.9532368183135986, -0.922381579875946, -0.8915263414382935, -0.8606711626052856, -0.8298159241676331, -0.7989606857299805, -0.7681055068969727, -0.7372502684593201, -0.7063950300216675, -0.6755398511886597, -0.6446845531463623, -0.6138293743133545, -0.5829740762710571, -0.5521188974380493, -0.5212637186050415, -0.49040842056274414, -0.45955324172973633, -0.4286980628967285, -0.39784276485443115, -0.36698758602142334, -0.3361324071884155, -0.30527710914611816, -0.27442193031311035, -0.243566632270813, -0.21271145343780518, -0.18185627460479736, -0.1510009765625, -0.12014579772949219, -0.08929049968719482, -0.05843532085418701, -0.0275801420211792, 0.003275156021118164, 0.03413033485412598, 0.06498551368713379, 0.09584081172943115, 0.12669599056243896, 0.15755116939544678, 0.18840646743774414, 0.21926164627075195, 0.2501169443130493, 0.28097212314605713]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 13.0, 14.0, 2.0, 5.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0], "bins": [-1.2883604764938354, -1.2649999856948853, -1.241639494895935, -1.2182791233062744, -1.1949186325073242, -1.171558141708374, -1.1481976509094238, -1.1248371601104736, -1.1014766693115234, -1.0781162977218628, -1.0547558069229126, -1.0313953161239624, -1.0080348253250122, -0.9846743941307068, -0.9613139033317566, -0.9379534721374512, -0.914592981338501, -0.8912324905395508, -0.8678720593452454, -0.8445115685462952, -0.8211511373519897, -0.7977906465530396, -0.7744301557540894, -0.7510697245597839, -0.7277092337608337, -0.7043487429618835, -0.6809883117675781, -0.6576278209686279, -0.6342673301696777, -0.6109068989753723, -0.5875464081764221, -0.5641859769821167, -0.5408254861831665, -0.5174649953842163, -0.4941045641899109, -0.4707440733909607, -0.4473836421966553, -0.4240231513977051, -0.4006626605987549, -0.37730222940444946, -0.35394173860549927, -0.3305812478065491, -0.30722081661224365, -0.28386032581329346, -0.26049983501434326, -0.23713934421539307, -0.21377897262573242, -0.19041848182678223, -0.16705799102783203, -0.14369750022888184, -0.12033700942993164, -0.096976637840271, -0.0736161470413208, -0.050255656242370605, -0.02689516544342041, -0.003534674644470215, 0.01982581615447998, 0.043186187744140625, 0.06654667854309082, 0.08990716934204102, 0.11326766014099121, 0.1366281509399414, 0.15998852252960205, 0.18334901332855225, 0.20670950412750244]}, "_runtime": 7329.3288860321045, "_timestamp": 1585516407.7496157, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5856149196624756, "Value Loss": 0.3654029667377472, "_runtime": 7330.322773933411, "_timestamp": 1585516408.7435036, "_step": 299}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": -0.5409747958183289, "Value Loss": 14.027766227722168, "_runtime": 7330.897001981735, "_timestamp": 1585516409.3177316, "_step": 300}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 0.7058696746826172, "Value Loss": 22.183191299438477, "_runtime": 7332.459707021713, "_timestamp": 1585516410.8804367, "_step": 301}
{"Episode reward": -99.81153278946736, "Episode length": 999, "Policy Loss": -1.6479485034942627, "Value Loss": 0.1346392035484314, "_runtime": 7333.3540625572205, "_timestamp": 1585516411.7747922, "_step": 302}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": -0.31568658351898193, "Value Loss": 17.18819808959961, "_runtime": 7334.848144292831, "_timestamp": 1585516413.268874, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7515594959259033, "Value Loss": 0.04551132768392563, "_runtime": 7336.407709121704, "_timestamp": 1585516414.8284388, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.729797124862671, "Value Loss": 0.09520120918750763, "_runtime": 7337.943476200104, "_timestamp": 1585516416.3642058, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6948875188827515, "Value Loss": 0.12707474827766418, "_runtime": 7339.475002288818, "_timestamp": 1585516417.895732, "_step": 306}
{"Episode reward": 1.6986777246011542, "Episode length": 984, "Policy Loss": -0.7709435224533081, "Value Loss": 8.924178123474121, "_runtime": 7340.933413267136, "_timestamp": 1585516419.354143, "_step": 307}
{"Episode reward": 7.900000000000958, "Episode length": 921, "Policy Loss": -0.6806994676589966, "Value Loss": 10.330496788024902, "_runtime": 7342.508309841156, "_timestamp": 1585516420.9290395, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5991945266723633, "Value Loss": 0.06624119728803635, "_runtime": 7344.081196546555, "_timestamp": 1585516422.5019262, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5768049955368042, "Value Loss": 0.03421653062105179, "_runtime": 7345.665065288544, "_timestamp": 1585516424.085795, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5346742868423462, "Value Loss": 0.053034063428640366, "_runtime": 7347.2232234478, "_timestamp": 1585516425.643953, "_step": 311}
{"Episode reward": -99.85118745714286, "Episode length": 999, "Policy Loss": -1.504576563835144, "Value Loss": 0.03984194993972778, "_runtime": 7348.826884269714, "_timestamp": 1585516427.247614, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4098224639892578, "Value Loss": 0.08266445249319077, "_runtime": 7350.406405925751, "_timestamp": 1585516428.8271356, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3853249549865723, "Value Loss": 0.052227068692445755, "_runtime": 7351.98482465744, "_timestamp": 1585516430.4055543, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3406344652175903, "Value Loss": 0.030102966353297234, "_runtime": 7353.310976982117, "_timestamp": 1585516431.7317066, "_step": 315}
{"Episode reward": 15.997178649902835, "Episode length": 841, "Policy Loss": -0.34757131338119507, "Value Loss": 10.74851131439209, "_runtime": 7354.207836151123, "_timestamp": 1585516432.6285658, "_step": 316}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.14327561855316162, "Value Loss": 15.085643768310547, "_runtime": 7355.630345106125, "_timestamp": 1585516434.0510747, "_step": 317}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": -0.31605711579322815, "Value Loss": 9.936406135559082, "_runtime": 7356.329133987427, "_timestamp": 1585516434.7498636, "_step": 318}
{"Episode reward": 56.79999999999966, "Episode length": 432, "Policy Loss": 0.770219087600708, "Value Loss": 22.809980392456055, "_runtime": 7357.205902099609, "_timestamp": 1585516435.6266317, "_step": 319}
{"Episode reward": 42.83552255034393, "Episode length": 572, "Policy Loss": 0.3468496799468994, "Value Loss": 16.002567291259766, "_runtime": 7358.7674350738525, "_timestamp": 1585516437.1881647, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0344971418380737, "Value Loss": 0.21067197620868683, "_runtime": 7359.524767160416, "_timestamp": 1585516437.9454968, "_step": 321}
{"Episode reward": 51.299999999999585, "Episode length": 487, "Policy Loss": 0.57684725522995, "Value Loss": 18.76358985900879, "_runtime": 7360.781099319458, "_timestamp": 1585516439.201829, "_step": 322}
{"Episode reward": 17.100000000000435, "Episode length": 829, "Policy Loss": -0.09047844260931015, "Value Loss": 9.817450523376465, "_runtime": 7362.3465168476105, "_timestamp": 1585516440.7672465, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9730597138404846, "Value Loss": 0.12525898218154907, "_runtime": 7363.86744594574, "_timestamp": 1585516442.2881756, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0310417413711548, "Value Loss": 0.1019396185874939, "_runtime": 7365.109360456467, "_timestamp": 1585516443.53009, "_step": 325}
{"Episode reward": 20.393253533542406, "Episode length": 798, "Policy Loss": -0.29692426323890686, "Value Loss": 11.771122932434082, "_runtime": 7366.250562667847, "_timestamp": 1585516444.6712923, "_step": 326}
{"Episode reward": 28.264295111596397, "Episode length": 719, "Policy Loss": -0.2456800639629364, "Value Loss": 12.544255256652832, "_runtime": 7366.980922222137, "_timestamp": 1585516445.4016519, "_step": 327}
{"Episode reward": 54.49999999999963, "Episode length": 455, "Policy Loss": 0.6448314189910889, "Value Loss": 18.967100143432617, "_runtime": 7368.533077478409, "_timestamp": 1585516446.953807, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2590999603271484, "Value Loss": 0.0510747954249382, "_runtime": 7370.093910932541, "_timestamp": 1585516448.5146406, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2924498319625854, "Value Loss": 0.16348256170749664, "_runtime": 7371.614750146866, "_timestamp": 1585516450.0354798, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1542266607284546, "Value Loss": 0.4723634123802185, "_runtime": 7373.235160827637, "_timestamp": 1585516451.6558905, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2027134895324707, "Value Loss": 0.9072751402854919, "_runtime": 7374.818515062332, "_timestamp": 1585516453.2392447, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2386233806610107, "Value Loss": 0.3453734517097473, "_runtime": 7375.46919298172, "_timestamp": 1585516453.8899226, "_step": 333}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 0.9380887746810913, "Value Loss": 25.73044204711914, "_runtime": 7376.328364849091, "_timestamp": 1585516454.7490945, "_step": 334}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 0.5136393308639526, "Value Loss": 17.963359832763672, "_runtime": 7377.909237146378, "_timestamp": 1585516456.3299668, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0467158555984497, "Value Loss": 0.12316178530454636, "_runtime": 7379.417502641678, "_timestamp": 1585516457.8382323, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0843452215194702, "Value Loss": 0.7249431014060974, "_runtime": 7380.832098722458, "_timestamp": 1585516459.2528284, "_step": 337}
{"Episode reward": 7.709248328209895, "Episode length": 923, "Policy Loss": -0.5326569080352783, "Value Loss": 10.583025932312012, "_runtime": 7382.418357372284, "_timestamp": 1585516460.839087, "_step": 338}
{"Episode reward": -99.80415329672256, "Episode length": 999, "Policy Loss": -0.8159860372543335, "Value Loss": 0.21677739918231964, "_runtime": 7383.800095796585, "_timestamp": 1585516462.2208254, "_step": 339}
{"Episode reward": 11.90000000000073, "Episode length": 881, "Policy Loss": 0.20191404223442078, "Value Loss": 10.017762184143066, "_runtime": 7384.201701402664, "_timestamp": 1585516462.622431, "_step": 340}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 3.2135441303253174, "Value Loss": 40.661556243896484, "_runtime": 7385.774813890457, "_timestamp": 1585516464.1955435, "_step": 341}
{"Episode reward": -99.80000467300275, "Episode length": 999, "Policy Loss": -0.27354609966278076, "Value Loss": 0.0035847891122102737, "_runtime": 7387.343558311462, "_timestamp": 1585516465.764288, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18188533186912537, "Value Loss": 0.024341681972146034, "_runtime": 7388.844240665436, "_timestamp": 1585516467.2649703, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03542981296777725, "Value Loss": 0.10657631605863571, "_runtime": 7389.715564489365, "_timestamp": 1585516468.1362941, "_step": 344}
{"Episode reward": 47.49999999999953, "Episode length": 525, "Policy Loss": 1.5315935611724854, "Value Loss": 16.63430404663086, "_runtime": 7390.899961233139, "_timestamp": 1585516469.3206909, "_step": 345}
{"Episode reward": 24.999999999999986, "Episode length": 750, "Policy Loss": 1.009423017501831, "Value Loss": 12.12200927734375, "_runtime": 7392.257233142853, "_timestamp": 1585516470.6779628, "_step": 346}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.8823086619377136, "Value Loss": 11.291586875915527, "_runtime": 7393.791617870331, "_timestamp": 1585516472.2123475, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06956031173467636, "Value Loss": 0.10248066484928131, "_runtime": 7395.334980726242, "_timestamp": 1585516473.7557104, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02894730307161808, "Value Loss": 0.03261970728635788, "_runtime": 7396.917113780975, "_timestamp": 1585516475.3378434, "_step": 349}
{"Episode reward": -99.8009042635546, "Episode length": 999, "Policy Loss": -0.01165376603603363, "Value Loss": 0.10616472363471985, "_runtime": 7398.472437381744, "_timestamp": 1585516476.893167, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012607298791408539, "Value Loss": 0.024815037846565247, "_runtime": 7399.016233682632, "_timestamp": 1585516477.4369633, "_step": 351}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 2.1639950275421143, "Value Loss": 28.920177459716797, "_runtime": 7400.5891399383545, "_timestamp": 1585516479.0098696, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06651265919208527, "Value Loss": 0.1316627711057663, "_runtime": 7402.001397609711, "_timestamp": 1585516480.4221272, "_step": 353}
{"Episode reward": 10.106912365184058, "Episode length": 900, "Policy Loss": 0.8401046395301819, "Value Loss": 10.120915412902832, "_runtime": 7403.51239657402, "_timestamp": 1585516481.9331262, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03613348677754402, "Value Loss": 0.09049096703529358, "_runtime": 7405.0933837890625, "_timestamp": 1585516483.5141134, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08074846863746643, "Value Loss": 0.07411837577819824, "_runtime": 7405.7640969753265, "_timestamp": 1585516484.1848266, "_step": 356}
{"Episode reward": 58.49999999999969, "Episode length": 415, "Policy Loss": 1.774564266204834, "Value Loss": 21.944211959838867, "_runtime": 7407.1087782382965, "_timestamp": 1585516485.5295079, "_step": 357}
{"Episode reward": 14.100000000000605, "Episode length": 859, "Policy Loss": 1.3791935443878174, "Value Loss": 10.743721961975098, "_runtime": 7408.675839185715, "_timestamp": 1585516487.0965688, "_step": 358}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.8167768120765686, "Value Loss": 9.499119758605957, "_runtime": 7409.982961177826, "_timestamp": 1585516488.4036908, "_step": 359}
{"Episode reward": 14.187879538536677, "Episode length": 859, "Policy Loss": 0.7953518033027649, "Value Loss": 10.136183738708496, "_runtime": 7411.51607298851, "_timestamp": 1585516489.9368026, "_step": 360}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": 0.6599562764167786, "Value Loss": 9.191658973693848, "_runtime": 7412.913456916809, "_timestamp": 1585516491.3341866, "_step": 361}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 0.6309504508972168, "Value Loss": 9.777242660522461, "_runtime": 7414.242273807526, "_timestamp": 1585516492.6630034, "_step": 362}
{"Episode reward": 14.389755624533294, "Episode length": 857, "Policy Loss": 0.6114566922187805, "Value Loss": 10.988730430603027, "_runtime": 7415.810119152069, "_timestamp": 1585516494.2308488, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4254472553730011, "Value Loss": 0.019352881237864494, "_runtime": 7417.367368936539, "_timestamp": 1585516495.7880986, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4778888523578644, "Value Loss": 0.021858541294932365, "_runtime": 7418.9231967926025, "_timestamp": 1585516497.3439264, "_step": 365}
{"Episode reward": -99.89422645568708, "Episode length": 999, "Policy Loss": -0.5365815162658691, "Value Loss": 0.013243147172033787, "_runtime": 7419.831483125687, "_timestamp": 1585516498.2522128, "_step": 366}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 0.7900217175483704, "Value Loss": 16.863019943237305, "_runtime": 7421.41787815094, "_timestamp": 1585516499.8386078, "_step": 367}
{"Episode reward": -99.86932920366385, "Episode length": 999, "Policy Loss": -0.6587027907371521, "Value Loss": 0.008607047609984875, "_runtime": 7422.364029884338, "_timestamp": 1585516500.7847595, "_step": 368}
{"Episode reward": 40.7942521810526, "Episode length": 593, "Policy Loss": 0.37930864095687866, "Value Loss": 14.615863800048828, "_runtime": 7423.5145037174225, "_timestamp": 1585516501.9352334, "_step": 369}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": 0.16516688466072083, "Value Loss": 11.325751304626465, "_runtime": 7424.5287499427795, "_timestamp": 1585516502.9494796, "_step": 370}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.26324784755706787, "Value Loss": 12.865619659423828, "_runtime": 7425.546016931534, "_timestamp": 1585516503.9667466, "_step": 371}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.3564095199108124, "Value Loss": 13.855151176452637, "_runtime": 7427.089710950851, "_timestamp": 1585516505.5104406, "_step": 372}
{"Episode reward": -99.87971315979817, "Episode length": 999, "Policy Loss": -0.887227475643158, "Value Loss": 0.11016395688056946, "_runtime": 7428.637447595596, "_timestamp": 1585516507.0581772, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0058330297470093, "Value Loss": 0.024650100618600845, "_runtime": 7430.176766872406, "_timestamp": 1585516508.5974965, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1026750802993774, "Value Loss": 0.1031835526227951, "_runtime": 7431.5086188316345, "_timestamp": 1585516509.9293485, "_step": 375}
{"Episode reward": 15.061817497015554, "Episode length": 850, "Policy Loss": -0.31806913018226624, "Value Loss": 10.310114860534668, "_runtime": 7433.084690332413, "_timestamp": 1585516511.50542, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1112041473388672, "Value Loss": 0.02792925387620926, "_runtime": 7434.662514209747, "_timestamp": 1585516513.0832438, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.171419382095337, "Value Loss": 0.05599890276789665, "_runtime": 7436.219154596329, "_timestamp": 1585516514.6398842, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1687910556793213, "Value Loss": 0.02095060423016548, "_runtime": 7437.33939909935, "_timestamp": 1585516515.7601287, "_step": 379}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": -0.11550872027873993, "Value Loss": 12.30239200592041, "_runtime": 7438.9072296619415, "_timestamp": 1585516517.3279593, "_step": 380}
{"Episode reward": -99.80066492557386, "Episode length": 999, "Policy Loss": -1.1724835634231567, "Value Loss": 0.5108506679534912, "_runtime": 7440.475539684296, "_timestamp": 1585516518.8962693, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0808112621307373, "Value Loss": 0.05102187767624855, "_runtime": 7441.954376935959, "_timestamp": 1585516520.3751066, "_step": 382}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": -0.22818036377429962, "Value Loss": 9.236637115478516, "_runtime": 7443.136869668961, "_timestamp": 1585516521.5575993, "_step": 383}
{"Episode reward": 27.784492248296573, "Episode length": 723, "Policy Loss": 0.05921921133995056, "Value Loss": 11.96399974822998, "_runtime": 7444.712611198425, "_timestamp": 1585516523.1333408, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9855148792266846, "Value Loss": 0.08953329920768738, "_runtime": 7446.2908453941345, "_timestamp": 1585516524.711575, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.026614785194397, "Value Loss": 0.023065686225891113, "_runtime": 7447.845212936401, "_timestamp": 1585516526.2659426, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9833523035049438, "Value Loss": 0.0918029397726059, "_runtime": 7449.404668807983, "_timestamp": 1585516527.8253984, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9821282029151917, "Value Loss": 0.04097988083958626, "_runtime": 7450.98026061058, "_timestamp": 1585516529.4009902, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9701988697052002, "Value Loss": 0.03253582492470741, "_runtime": 7452.5585861206055, "_timestamp": 1585516530.9793158, "_step": 389}
{"Episode reward": -99.8742937937365, "Episode length": 999, "Policy Loss": -1.0032778978347778, "Value Loss": 0.030688315629959106, "_runtime": 7454.1354196071625, "_timestamp": 1585516532.5561492, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0240706205368042, "Value Loss": 0.10976339131593704, "_runtime": 7455.699617385864, "_timestamp": 1585516534.120347, "_step": 391}
{"Episode reward": -99.8089298248277, "Episode length": 999, "Policy Loss": -0.9963164925575256, "Value Loss": 0.047591038048267365, "_runtime": 7457.271178722382, "_timestamp": 1585516535.6919084, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9474039077758789, "Value Loss": 0.033661287277936935, "_runtime": 7458.2824029922485, "_timestamp": 1585516536.7031326, "_step": 393}
{"Episode reward": 37.261847662925106, "Episode length": 628, "Policy Loss": 0.24307173490524292, "Value Loss": 14.313787460327148, "_runtime": 7459.316242694855, "_timestamp": 1585516537.7369723, "_step": 394}
{"Episode reward": 34.39999999999945, "Episode length": 656, "Policy Loss": 0.29801714420318604, "Value Loss": 13.55971622467041, "_runtime": 7460.894100189209, "_timestamp": 1585516539.3148298, "_step": 395}
{"Episode reward": -99.8503253042684, "Episode length": 999, "Policy Loss": -0.8086856007575989, "Value Loss": 0.015487065538764, "_runtime": 7462.451553821564, "_timestamp": 1585516540.8722835, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7550421357154846, "Value Loss": 0.032615963369607925, "_runtime": 7463.711347579956, "_timestamp": 1585516542.1320772, "_step": 397}
{"Episode reward": 18.837003844976763, "Episode length": 812, "Policy Loss": 0.18052755296230316, "Value Loss": 12.426400184631348, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508, -0.028260469436645508]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 10.0], "bins": [-3.295680522918701, -3.243743896484375, -3.191807270050049, -3.1398708820343018, -3.0879342555999756, -3.0359976291656494, -2.9840610027313232, -2.932124376296997, -2.88018798828125, -2.828251361846924, -2.7763147354125977, -2.7243781089782715, -2.6724414825439453, -2.6205050945281982, -2.568568468093872, -2.516631841659546, -2.4646952152252197, -2.4127588272094727, -2.3608222007751465, -2.3088855743408203, -2.256948947906494, -2.205012321472168, -2.153075695037842, -2.1011390686035156, -2.0492026805877686, -1.9972660541534424, -1.9453295469284058, -1.8933929204940796, -1.8414562940597534, -1.7895197868347168, -1.7375831604003906, -1.685646653175354, -1.6337100267410278, -1.5817734003067017, -1.529836893081665, -1.4779002666473389, -1.4259637594223022, -1.374027132987976, -1.32209050655365, -1.2701539993286133, -1.218217372894287, -1.166280746459961, -1.1143443584442139, -1.0624077320098877, -1.0104711055755615, -0.9585344791412354, -0.9065978527069092, -0.8546614646911621, -0.8027248382568359, -0.7507882118225098, -0.6988515853881836, -0.6469149589538574, -0.5949785709381104, -0.5430419445037842, -0.491105318069458, -0.43916869163513184, -0.38723206520080566, -0.3352956771850586, -0.2833590507507324, -0.23142242431640625, -0.17948579788208008, -0.1275491714477539, -0.07561278343200684, -0.023676156997680664, 0.028260469436645508]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.09418636560440063, -0.09271460026502609, -0.09124282747507095, -0.08977106213569641, -0.08829929679632187, -0.08682752400636673, -0.08535575866699219, -0.08388398587703705, -0.0824122205376625, -0.08094045519828796, -0.07946868240833282, -0.07799691706895828, -0.07652515172958374, -0.0750533789396286, -0.07358161360025406, -0.07210984826087952, -0.07063807547092438, -0.06916631013154984, -0.06769454479217529, -0.06622277200222015, -0.06475100666284561, -0.06327924132347107, -0.06180746853351593, -0.06033569946885109, -0.05886393412947655, -0.05739216506481171, -0.055920396000146866, -0.054448630660772324, -0.05297686159610748, -0.05150509253144264, -0.0500333234667778, -0.04856155812740326, -0.04708978906273842, -0.04561801999807358, -0.044146254658699036, -0.042674485594034195, -0.041202716529369354, -0.039730947464704514, -0.03825918212532997, -0.03678741306066513, -0.03531564399600029, -0.03384387865662575, -0.03237210959196091, -0.030900344252586365, -0.029428571462631226, -0.027956806123256683, -0.026485033333301544, -0.025013267993927002, -0.02354150265455246, -0.02206972986459732, -0.02059796452522278, -0.019126199185848236, -0.017654426395893097, -0.016182661056518555, -0.014710895717144012, -0.013239122927188873, -0.011767357587814331, -0.010295592248439789, -0.00882381945848465, -0.007352054119110107, -0.005880281329154968, -0.004408515989780426, -0.002936750650405884, -0.0014649778604507446, 6.787478923797607e-06]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 3.0, 3.0, 1.0, 4.0, 3.0, 0.0, 1.0, 0.0, 6.0, 4.0, 8.0, 8.0, 5.0, 5.0, 341.0, 9.0, 13.0, 7.0, 4.0, 8.0, 16.0, 9.0, 7.0, 11.0, 6.0], "bins": [-0.526048481464386, -0.5163047313690186, -0.5065609216690063, -0.4968171715736389, -0.4870733916759491, -0.4773296117782593, -0.46758586168289185, -0.457842081785202, -0.4480983018875122, -0.4383545517921448, -0.42861077189445496, -0.41886699199676514, -0.4091232419013977, -0.3993794322013855, -0.38963568210601807, -0.37989190220832825, -0.3701481223106384, -0.360404372215271, -0.3506605923175812, -0.34091681241989136, -0.3311730623245239, -0.3214292824268341, -0.3116855025291443, -0.30194175243377686, -0.29219797253608704, -0.2824541926383972, -0.2727104127407074, -0.26296666264533997, -0.25322288274765015, -0.24347910284996033, -0.2337353229522705, -0.22399157285690308, -0.21424779295921326, -0.20450401306152344, -0.194760262966156, -0.1850164830684662, -0.17527270317077637, -0.16552892327308655, -0.15578517317771912, -0.1460413932800293, -0.13629761338233948, -0.12655386328697205, -0.11681008338928223, -0.10706630349159241, -0.09732252359390259, -0.08757877349853516, -0.07783499360084534, -0.06809121370315552, -0.058347463607788086, -0.04860368371009827, -0.03885990381240845, -0.029116123914718628, -0.01937234401702881, -0.009628593921661377, 0.00011515617370605469, 0.009858965873718262, 0.019602715969085693, 0.029346466064453125, 0.03909027576446533, 0.048834025859832764, 0.05857783555984497, 0.0683215856552124, 0.07806533575057983, 0.08780914545059204, 0.09755289554595947]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0], "bins": [-2.3033270835876465, -2.260080575942993, -2.216834306716919, -2.1735877990722656, -2.1303415298461914, -2.087095022201538, -2.0438485145568848, -2.0006022453308105, -1.9573557376861572, -1.9141093492507935, -1.8708629608154297, -1.8276164531707764, -1.7843701839447021, -1.7411236763000488, -1.697877287864685, -1.6546308994293213, -1.611384391784668, -1.5681381225585938, -1.5248916149139404, -1.4816452264785767, -1.438398838043213, -1.3951523303985596, -1.3519059419631958, -1.308659553527832, -1.2654131650924683, -1.2221667766571045, -1.1789202690124512, -1.1356738805770874, -1.0924274921417236, -1.0491811037063599, -1.0059345960617065, -0.9626882076263428, -0.919441819190979, -0.8761954307556152, -0.8329490423202515, -0.7897025346755981, -0.7464561462402344, -0.7032097578048706, -0.6599633693695068, -0.6167168617248535, -0.5734704732894897, -0.530224084854126, -0.4869776964187622, -0.44373130798339844, -0.4004848003387451, -0.35723841190338135, -0.3139920234680176, -0.27074551582336426, -0.22749924659729004, -0.18425273895263672, -0.1410064697265625, -0.09775996208190918, -0.05451345443725586, -0.01126718521118164, 0.03197932243347168, 0.075225830078125, 0.11847209930419922, 0.16171860694885254, 0.20496487617492676, 0.24821138381958008, 0.2914578914642334, 0.3347041606903076, 0.37795066833496094, 0.42119693756103516, 0.4644434452056885]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 1.0, 0.0, 1.0, 0.0, 1.0, 4.0, 6.0, 1.0, 5.0, 8.0, 10.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0], "bins": [-3.142591953277588, -3.083232879638672, -3.023874044418335, -2.964514970779419, -2.905155897140503, -2.845797061920166, -2.78643798828125, -2.727078914642334, -2.667720079421997, -2.608361005783081, -2.549002170562744, -2.489643096923828, -2.430284023284912, -2.370924949645996, -2.311566114425659, -2.252207040786743, -2.1928482055664062, -2.1334891319274902, -2.074130058288574, -2.014770984649658, -1.9554121494293213, -1.8960530757904053, -1.8366941213607788, -1.7773351669311523, -1.7179760932922363, -1.6586171388626099, -1.5992581844329834, -1.539899230003357, -1.480540156364441, -1.4211812019348145, -1.361822247505188, -1.302463173866272, -1.2431042194366455, -1.183745265007019, -1.1243863105773926, -1.0650272369384766, -1.0056681632995605, -0.9463093280792236, -0.8869502544403076, -0.8275911808013916, -0.7682323455810547, -0.7088732719421387, -0.6495141983032227, -0.5901553630828857, -0.5307962894439697, -0.4714372158050537, -0.4120783805847168, -0.3527193069458008, -0.29336023330688477, -0.23400139808654785, -0.17464232444763184, -0.11528348922729492, -0.055924415588378906, 0.0034346580505371094, 0.06279349327087402, 0.12215256690979004, 0.18151164054870605, 0.24087047576904297, 0.300229549407959, 0.359588623046875, 0.4189474582672119, 0.47830653190612793, 0.537665605545044, 0.5970244407653809, 0.6563835144042969]}, "_runtime": 7464.640922546387, "_timestamp": 1585516543.0616522, "_step": 398}
{"Episode reward": 41.187930482625404, "Episode length": 589, "Policy Loss": 0.7853782773017883, "Value Loss": 15.681290626525879, "_runtime": 7466.13601231575, "_timestamp": 1585516544.556742, "_step": 399}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": 0.5550215840339661, "Value Loss": 10.185698509216309, "_runtime": 7467.7454080581665, "_timestamp": 1585516546.1661377, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2436966896057129, "Value Loss": 0.5121476650238037, "_runtime": 7469.284843444824, "_timestamp": 1585516547.705573, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15611615777015686, "Value Loss": 0.1158987283706665, "_runtime": 7470.847486972809, "_timestamp": 1585516549.2682166, "_step": 402}
{"Episode reward": -99.80589662790159, "Episode length": 999, "Policy Loss": -0.12335275113582611, "Value Loss": 0.2780359089374542, "_runtime": 7471.927134275436, "_timestamp": 1585516550.347864, "_step": 403}
{"Episode reward": 32.99999999999953, "Episode length": 670, "Policy Loss": 1.2405818700790405, "Value Loss": 14.223265647888184, "_runtime": 7473.490594625473, "_timestamp": 1585516551.9113243, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11370507627725601, "Value Loss": 0.3283391296863556, "_runtime": 7474.079309940338, "_timestamp": 1585516552.5000396, "_step": 405}
{"Episode reward": 64.99999999999977, "Episode length": 350, "Policy Loss": 2.085989475250244, "Value Loss": 25.00326919555664, "_runtime": 7475.073744535446, "_timestamp": 1585516553.4944742, "_step": 406}
{"Episode reward": 36.09999999999937, "Episode length": 639, "Policy Loss": 1.3057430982589722, "Value Loss": 14.090962409973145, "_runtime": 7476.653160095215, "_timestamp": 1585516555.0738897, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1646871268749237, "Value Loss": 0.006455443799495697, "_runtime": 7477.505321741104, "_timestamp": 1585516555.9260514, "_step": 408}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 1.1263841390609741, "Value Loss": 16.625396728515625, "_runtime": 7478.607656478882, "_timestamp": 1585516557.028386, "_step": 409}
{"Episode reward": 29.46142425537083, "Episode length": 706, "Policy Loss": 0.6081135869026184, "Value Loss": 12.870122909545898, "_runtime": 7480.089979171753, "_timestamp": 1585516558.5107088, "_step": 410}
{"Episode reward": 6.3975048959265735, "Episode length": 937, "Policy Loss": 0.15075348317623138, "Value Loss": 9.387395858764648, "_runtime": 7480.901084423065, "_timestamp": 1585516559.321814, "_step": 411}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 0.9430512189865112, "Value Loss": 16.110790252685547, "_runtime": 7482.1375415325165, "_timestamp": 1585516560.5582712, "_step": 412}
{"Episode reward": 20.300000000000253, "Episode length": 797, "Policy Loss": 0.1548946052789688, "Value Loss": 11.716065406799316, "_runtime": 7482.892147064209, "_timestamp": 1585516561.3128767, "_step": 413}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 0.8520335555076599, "Value Loss": 19.94565200805664, "_runtime": 7484.422701358795, "_timestamp": 1585516562.843431, "_step": 414}
{"Episode reward": -99.89579706787923, "Episode length": 999, "Policy Loss": -0.8468109965324402, "Value Loss": 0.06869935989379883, "_runtime": 7485.96635556221, "_timestamp": 1585516564.3870852, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.864538311958313, "Value Loss": 0.034894611686468124, "_runtime": 7487.125989437103, "_timestamp": 1585516565.546719, "_step": 416}
{"Episode reward": 24.000000000000043, "Episode length": 760, "Policy Loss": 0.3282301127910614, "Value Loss": 11.805176734924316, "_runtime": 7487.734109163284, "_timestamp": 1585516566.1548388, "_step": 417}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 1.4159327745437622, "Value Loss": 23.40290641784668, "_runtime": 7489.290925741196, "_timestamp": 1585516567.7116554, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7835307717323303, "Value Loss": 0.21966402232646942, "_runtime": 7490.877538204193, "_timestamp": 1585516569.2982678, "_step": 419}
{"Episode reward": -99.84718173891166, "Episode length": 999, "Policy Loss": -0.8036938905715942, "Value Loss": 0.8092998266220093, "_runtime": 7491.477735280991, "_timestamp": 1585516569.898465, "_step": 420}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 1.399115800857544, "Value Loss": 24.26411247253418, "_runtime": 7493.039304018021, "_timestamp": 1585516571.4600337, "_step": 421}
{"Episode reward": -99.73022646456818, "Episode length": 999, "Policy Loss": -0.7338775396347046, "Value Loss": 0.281777024269104, "_runtime": 7494.612955331802, "_timestamp": 1585516573.033685, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7049006223678589, "Value Loss": 0.04557330533862114, "_runtime": 7495.694673299789, "_timestamp": 1585516574.115403, "_step": 423}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.3563864231109619, "Value Loss": 12.052083969116211, "_runtime": 7497.277177810669, "_timestamp": 1585516575.6979074, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.558223307132721, "Value Loss": 0.036672256886959076, "_runtime": 7498.210680961609, "_timestamp": 1585516576.6314106, "_step": 425}
{"Episode reward": 41.791976141556546, "Episode length": 583, "Policy Loss": 0.822954535484314, "Value Loss": 16.004629135131836, "_runtime": 7499.762455463409, "_timestamp": 1585516578.183185, "_step": 426}
{"Episode reward": -99.83068662285665, "Episode length": 999, "Policy Loss": -0.5193049907684326, "Value Loss": 0.08765644580125809, "_runtime": 7501.341353416443, "_timestamp": 1585516579.762083, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47975802421569824, "Value Loss": 0.030687415972352028, "_runtime": 7502.877403497696, "_timestamp": 1585516581.2981331, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40119361877441406, "Value Loss": 0.008414674550294876, "_runtime": 7503.980969667435, "_timestamp": 1585516582.4016993, "_step": 429}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.5593938827514648, "Value Loss": 12.383570671081543, "_runtime": 7505.06153011322, "_timestamp": 1585516583.4822598, "_step": 430}
{"Episode reward": 32.595299911498586, "Episode length": 675, "Policy Loss": 0.67240971326828, "Value Loss": 13.497883796691895, "_runtime": 7506.148423194885, "_timestamp": 1585516584.5691528, "_step": 431}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.7485927939414978, "Value Loss": 13.049040794372559, "_runtime": 7507.680701255798, "_timestamp": 1585516586.101431, "_step": 432}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.5321146249771118, "Value Loss": 9.07750129699707, "_runtime": 7509.223966360092, "_timestamp": 1585516587.644696, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39306461811065674, "Value Loss": 0.014407691545784473, "_runtime": 7510.776942014694, "_timestamp": 1585516589.1976717, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.507158637046814, "Value Loss": 0.105774886906147, "_runtime": 7511.976118564606, "_timestamp": 1585516590.3968482, "_step": 435}
{"Episode reward": 23.88941686004405, "Episode length": 762, "Policy Loss": 0.5877791047096252, "Value Loss": 11.8689603805542, "_runtime": 7512.8080701828, "_timestamp": 1585516591.2287998, "_step": 436}
{"Episode reward": 48.499999999999545, "Episode length": 515, "Policy Loss": 0.9240441918373108, "Value Loss": 16.968908309936523, "_runtime": 7514.372159957886, "_timestamp": 1585516592.7928896, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5567412972450256, "Value Loss": 0.022983334958553314, "_runtime": 7515.963692903519, "_timestamp": 1585516594.3844225, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6427644491195679, "Value Loss": 0.019238818436861038, "_runtime": 7517.498911380768, "_timestamp": 1585516595.919641, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7215371131896973, "Value Loss": 0.014042836613953114, "_runtime": 7519.088923215866, "_timestamp": 1585516597.5096529, "_step": 440}
{"Episode reward": -99.81378011852364, "Episode length": 999, "Policy Loss": -0.7819307446479797, "Value Loss": 0.04354540631175041, "_runtime": 7519.360980510712, "_timestamp": 1585516597.7817101, "_step": 441}
{"Episode reward": 87.00000000000003, "Episode length": 130, "Policy Loss": 6.322806358337402, "Value Loss": 67.4820785522461, "_runtime": 7520.052449464798, "_timestamp": 1585516598.473179, "_step": 442}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 0.6006450653076172, "Value Loss": 19.34947395324707, "_runtime": 7521.640227794647, "_timestamp": 1585516600.0609574, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1088910102844238, "Value Loss": 0.06683158129453659, "_runtime": 7523.143318414688, "_timestamp": 1585516601.564048, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2317620515823364, "Value Loss": 0.042778924107551575, "_runtime": 7524.510581493378, "_timestamp": 1585516602.9313111, "_step": 445}
{"Episode reward": 9.900000000000844, "Episode length": 901, "Policy Loss": -0.3826022744178772, "Value Loss": 9.784192085266113, "_runtime": 7526.103358507156, "_timestamp": 1585516604.5240881, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4741922616958618, "Value Loss": 0.08331222087144852, "_runtime": 7526.633123874664, "_timestamp": 1585516605.0538535, "_step": 447}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 1.0449689626693726, "Value Loss": 30.216676712036133, "_runtime": 7528.139953613281, "_timestamp": 1585516606.5606833, "_step": 448}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": -0.893660306930542, "Value Loss": 8.410258293151855, "_runtime": 7529.1820113658905, "_timestamp": 1585516607.602741, "_step": 449}
{"Episode reward": 35.09319498389901, "Episode length": 650, "Policy Loss": -0.4578878581523895, "Value Loss": 13.042641639709473, "_runtime": 7530.689367055893, "_timestamp": 1585516609.1100967, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7103183269500732, "Value Loss": 0.0619610920548439, "_runtime": 7531.2354645729065, "_timestamp": 1585516609.6561942, "_step": 451}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": 0.8141857981681824, "Value Loss": 29.661273956298828, "_runtime": 7532.297365903854, "_timestamp": 1585516610.7180955, "_step": 452}
{"Episode reward": 31.699999999999605, "Episode length": 683, "Policy Loss": -0.5250534415245056, "Value Loss": 13.218548774719238, "_runtime": 7533.869143247604, "_timestamp": 1585516612.289873, "_step": 453}
{"Episode reward": -99.80040603279927, "Episode length": 999, "Policy Loss": -1.5162028074264526, "Value Loss": 0.29241320490837097, "_runtime": 7535.385107278824, "_timestamp": 1585516613.805837, "_step": 454}
{"Episode reward": -99.82281601577857, "Episode length": 999, "Policy Loss": -1.6335211992263794, "Value Loss": 0.04968525469303131, "_runtime": 7536.06804728508, "_timestamp": 1585516614.488777, "_step": 455}
{"Episode reward": 56.61464288197424, "Episode length": 434, "Policy Loss": 0.3116808831691742, "Value Loss": 21.44277000427246, "_runtime": 7537.59409737587, "_timestamp": 1585516616.014827, "_step": 456}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": -0.3398190438747406, "Value Loss": 9.055733680725098, "_runtime": 7539.184502124786, "_timestamp": 1585516617.6052318, "_step": 457}
{"Episode reward": -99.8042811408625, "Episode length": 999, "Policy Loss": -1.4157829284667969, "Value Loss": 0.029598183929920197, "_runtime": 7540.710177898407, "_timestamp": 1585516619.1309075, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3554601669311523, "Value Loss": 0.028279809281229973, "_runtime": 7542.301235437393, "_timestamp": 1585516620.721965, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.268880844116211, "Value Loss": 0.032171234488487244, "_runtime": 7543.503666400909, "_timestamp": 1585516621.924396, "_step": 460}
{"Episode reward": 23.788004958257133, "Episode length": 764, "Policy Loss": -0.26930567622184753, "Value Loss": 11.02696418762207, "_runtime": 7545.063149213791, "_timestamp": 1585516623.4838789, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1945409774780273, "Value Loss": 0.04330044984817505, "_runtime": 7545.602116107941, "_timestamp": 1585516624.0228457, "_step": 462}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 1.5659741163253784, "Value Loss": 31.695968627929688, "_runtime": 7547.160845756531, "_timestamp": 1585516625.5815754, "_step": 463}
{"Episode reward": -99.81375294327596, "Episode length": 999, "Policy Loss": -1.0325560569763184, "Value Loss": 0.02088545262813568, "_runtime": 7548.740891695023, "_timestamp": 1585516627.1616213, "_step": 464}
{"Episode reward": -99.80128603130439, "Episode length": 999, "Policy Loss": -0.9542314410209656, "Value Loss": 0.017936650663614273, "_runtime": 7549.952572584152, "_timestamp": 1585516628.3733022, "_step": 465}
{"Episode reward": 19.900000000000276, "Episode length": 801, "Policy Loss": 0.2306974232196808, "Value Loss": 11.310723304748535, "_runtime": 7550.7605612277985, "_timestamp": 1585516629.1812909, "_step": 466}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": 0.7867001891136169, "Value Loss": 18.67734718322754, "_runtime": 7552.334243774414, "_timestamp": 1585516630.7549734, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7518492341041565, "Value Loss": 0.012376879341900349, "_runtime": 7553.365964412689, "_timestamp": 1585516631.786694, "_step": 468}
{"Episode reward": 33.89999999999948, "Episode length": 661, "Policy Loss": 0.43724188208580017, "Value Loss": 13.764436721801758, "_runtime": 7554.897067308426, "_timestamp": 1585516633.317797, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7314959764480591, "Value Loss": 0.027073616161942482, "_runtime": 7556.25873708725, "_timestamp": 1585516634.6794667, "_step": 470}
{"Episode reward": 14.099800935015693, "Episode length": 860, "Policy Loss": 0.22292686998844147, "Value Loss": 10.697070121765137, "_runtime": 7557.687574386597, "_timestamp": 1585516636.108304, "_step": 471}
{"Episode reward": 7.605013656617189, "Episode length": 924, "Policy Loss": 0.25129783153533936, "Value Loss": 9.814440727233887, "_runtime": 7558.356621265411, "_timestamp": 1585516636.777351, "_step": 472}
{"Episode reward": 59.099999999999696, "Episode length": 409, "Policy Loss": 1.0082181692123413, "Value Loss": 20.8620548248291, "_runtime": 7559.679975271225, "_timestamp": 1585516638.100705, "_step": 473}
{"Episode reward": 16.10000000000049, "Episode length": 839, "Policy Loss": 0.04711293801665306, "Value Loss": 10.1570405960083, "_runtime": 7560.237241268158, "_timestamp": 1585516638.657971, "_step": 474}
{"Episode reward": 66.4999999999998, "Episode length": 335, "Policy Loss": 1.3323578834533691, "Value Loss": 26.52042007446289, "_runtime": 7561.763127326965, "_timestamp": 1585516640.183857, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0721628665924072, "Value Loss": 0.03689989447593689, "_runtime": 7562.284672260284, "_timestamp": 1585516640.705402, "_step": 476}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 1.0065597295761108, "Value Loss": 27.163209915161133, "_runtime": 7563.54342508316, "_timestamp": 1585516641.9641547, "_step": 477}
{"Episode reward": 19.30000000000031, "Episode length": 807, "Policy Loss": -0.4298357367515564, "Value Loss": 11.482819557189941, "_runtime": 7564.966321706772, "_timestamp": 1585516643.3870513, "_step": 478}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": -0.7463725805282593, "Value Loss": 9.76878833770752, "_runtime": 7566.473005533218, "_timestamp": 1585516644.8937352, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4106358289718628, "Value Loss": 0.17143528163433075, "_runtime": 7568.036301374435, "_timestamp": 1585516646.457031, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.449974536895752, "Value Loss": 0.20897826552391052, "_runtime": 7569.598514556885, "_timestamp": 1585516648.0192442, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.126209020614624, "Value Loss": 0.512385904788971, "_runtime": 7570.890805006027, "_timestamp": 1585516649.3115346, "_step": 482}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": -0.30414560437202454, "Value Loss": 10.648550033569336, "_runtime": 7572.476299285889, "_timestamp": 1585516650.897029, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2360656261444092, "Value Loss": 0.0816919207572937, "_runtime": 7573.675592422485, "_timestamp": 1585516652.096322, "_step": 484}
{"Episode reward": 23.59381088614471, "Episode length": 765, "Policy Loss": -0.08390229940414429, "Value Loss": 11.666434288024902, "_runtime": 7575.236274957657, "_timestamp": 1585516653.6570046, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0807558298110962, "Value Loss": 0.04884980991482735, "_runtime": 7576.738694190979, "_timestamp": 1585516655.1594238, "_step": 486}
{"Episode reward": 5.679962573946611, "Episode length": 944, "Policy Loss": -0.2664121985435486, "Value Loss": 9.85209846496582, "_runtime": 7578.296010494232, "_timestamp": 1585516656.7167401, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9510331749916077, "Value Loss": 0.10413374751806259, "_runtime": 7579.241030454636, "_timestamp": 1585516657.66176, "_step": 488}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": 0.45834478735923767, "Value Loss": 15.914716720581055, "_runtime": 7580.824232816696, "_timestamp": 1585516659.2449625, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7559787631034851, "Value Loss": 0.022491781041026115, "_runtime": 7582.397968053818, "_timestamp": 1585516660.8186977, "_step": 490}
{"Episode reward": -99.85162506699422, "Episode length": 999, "Policy Loss": -0.6906452178955078, "Value Loss": 0.026432029902935028, "_runtime": 7583.93754029274, "_timestamp": 1585516662.35827, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5826165676116943, "Value Loss": 0.007798393722623587, "_runtime": 7584.4415464401245, "_timestamp": 1585516662.862276, "_step": 492}
{"Episode reward": 71.35121168494211, "Episode length": 287, "Policy Loss": 2.5702524185180664, "Value Loss": 30.935152053833008, "_runtime": 7586.0222408771515, "_timestamp": 1585516664.4429705, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4981032609939575, "Value Loss": 0.005354851949959993, "_runtime": 7587.6273765563965, "_timestamp": 1585516666.0481062, "_step": 494}
{"Episode reward": -99.85933061241964, "Episode length": 999, "Policy Loss": -0.4864424467086792, "Value Loss": 0.020670313388109207, "_runtime": 7588.340541362762, "_timestamp": 1585516666.761271, "_step": 495}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 0.8783395290374756, "Value Loss": 16.658592224121094, "_runtime": 7589.514177083969, "_timestamp": 1585516667.9349067, "_step": 496}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": 0.6663743853569031, "Value Loss": 12.158499717712402, "_runtime": 7591.083963871002, "_timestamp": 1585516669.5046935, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8538352847099304, "Value Loss": 0.02003197744488716, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778, -0.18821841478347778]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-36.247047424316406, -35.6777458190918, -35.10844421386719, -34.53914260864258, -33.969844818115234, -33.400543212890625, -32.831241607666016, -32.261940002441406, -31.692638397216797, -31.12333869934082, -30.55403709411621, -29.984737396240234, -29.415435791015625, -28.846134185791016, -28.276832580566406, -27.707530975341797, -27.13823127746582, -26.568931579589844, -25.999629974365234, -25.430328369140625, -24.861026763916016, -24.291725158691406, -23.72242546081543, -23.15312385559082, -22.583824157714844, -22.014522552490234, -21.445220947265625, -20.875919342041016, -20.30661964416504, -19.73731803894043, -19.16801643371582, -18.598716735839844, -18.029415130615234, -17.460113525390625, -16.89081382751465, -16.32151222229004, -15.75221061706543, -15.182910919189453, -14.613609313964844, -14.044307708740234, -13.475006103515625, -12.905706405639648, -12.336404800415039, -11.76710319519043, -11.197803497314453, -10.628501892089844, -10.059200286865234, -9.489900588989258, -8.920598983764648, -8.351297378540039, -7.7819976806640625, -7.212696075439453, -6.643394470214844, -6.074094772338867, -5.504793167114258, -4.935491561889648, -4.366191864013672, -3.7968902587890625, -3.227588653564453, -2.6582870483398438, -2.0889854431152344, -1.5196876525878906, -0.9503860473632812, -0.3810844421386719, 0.1882171630859375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.6449176073074341, -0.6348407864570618, -0.6247639060020447, -0.6146870851516724, -0.6046102643013, -0.5945334434509277, -0.5844565629959106, -0.5743797421455383, -0.564302921295166, -0.5542260408401489, -0.5441492199897766, -0.5340723991394043, -0.523995578289032, -0.5139186978340149, -0.5038418769836426, -0.49376505613327026, -0.48368820548057556, -0.47361135482788086, -0.46353453397750854, -0.45345771312713623, -0.44338086247444153, -0.4333040118217468, -0.4232271909713745, -0.4131503403186798, -0.4030734896659851, -0.3929966688156128, -0.3829198181629181, -0.3728429973125458, -0.3627661466598511, -0.35268932580947876, -0.34261247515678406, -0.33253565430641174, -0.32245880365371704, -0.31238195300102234, -0.30230513215065, -0.2922282814979553, -0.282151460647583, -0.2720746099948883, -0.261997789144516, -0.2519209384918213, -0.24184411764144897, -0.23176726698875427, -0.22169041633605957, -0.21161359548568726, -0.20153674483299255, -0.19145992398262024, -0.18138307332992554, -0.17130625247955322, -0.16122940182685852, -0.15115255117416382, -0.1410757303237915, -0.1309989094734192, -0.1209220290184021, -0.11084520816802979, -0.10076838731765747, -0.09069156646728516, -0.08061468601226807, -0.07053786516189575, -0.06046104431152344, -0.05038416385650635, -0.04030734300613403, -0.03023052215576172, -0.020153701305389404, -0.010076820850372314, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 8.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 1.0, 21.0, 24.0, 23.0, 14.0, 16.0, 9.0], "bins": [-3.7588112354278564, -3.690096855163574, -3.621382474899292, -3.5526680946350098, -3.4839539527893066, -3.4152395725250244, -3.346525192260742, -3.27781081199646, -3.2090964317321777, -3.1403820514678955, -3.0716676712036133, -3.00295352935791, -2.934238910675049, -2.8655247688293457, -2.7968103885650635, -2.7280960083007812, -2.659381628036499, -2.590667247772217, -2.5219528675079346, -2.4532384872436523, -2.384524345397949, -2.315809726715088, -2.2470955848693848, -2.1783812046051025, -2.1096668243408203, -2.040952444076538, -1.9722380638122559, -1.9035238027572632, -1.834809422492981, -1.7660950422286987, -1.697380781173706, -1.6286664009094238, -1.5599520206451416, -1.4912376403808594, -1.4225232601165771, -1.353808879852295, -1.2850944995880127, -1.2163803577423096, -1.1476659774780273, -1.0789515972137451, -1.010237216949463, -0.9415228366851807, -0.8728084564208984, -0.8040940761566162, -0.7353799343109131, -0.6666655540466309, -0.5979511737823486, -0.5292367935180664, -0.4605224132537842, -0.39180803298950195, -0.3230936527252197, -0.2543792724609375, -0.18566489219665527, -0.11695075035095215, -0.04823637008666992, 0.020478010177612305, 0.08919239044189453, 0.15790677070617676, 0.22662115097045898, 0.2953355312347412, 0.36404967308044434, 0.43276429176330566, 0.5014784336090088, 0.5701930522918701, 0.6389071941375732]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 4.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0], "bins": [-15.095038414001465, -14.821817398071289, -14.548596382141113, -14.275375366210938, -14.002155303955078, -13.728934288024902, -13.455713272094727, -13.18249225616455, -12.909271240234375, -12.6360502243042, -12.362829208374023, -12.089609146118164, -11.816387176513672, -11.543167114257812, -11.269946098327637, -10.996725082397461, -10.723504066467285, -10.45028305053711, -10.177062034606934, -9.903841018676758, -9.630620956420898, -9.357398986816406, -9.084178924560547, -8.810957908630371, -8.537736892700195, -8.26451587677002, -7.991294860839844, -7.718074321746826, -7.44485330581665, -7.171632289886475, -6.898411750793457, -6.625190734863281, -6.3519697189331055, -6.07874870300293, -5.805527687072754, -5.532306671142578, -5.259085655212402, -4.985865592956543, -4.712644577026367, -4.439423561096191, -4.166202545166016, -3.89298152923584, -3.619760513305664, -3.3465394973754883, -3.073319435119629, -2.800098419189453, -2.5268774032592773, -2.2536563873291016, -1.9804353713989258, -1.70721435546875, -1.4339933395385742, -1.1607723236083984, -0.8875513076782227, -0.6143312454223633, -0.3411102294921875, -0.06788921356201172, 0.20533180236816406, 0.47855281829833984, 0.7517738342285156, 1.0249948501586914, 1.2982149124145508, 1.571436882019043, 1.8446569442749023, 2.1178789138793945, 2.391098976135254]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 7.0, 4.0, 2.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.716655969619751, -1.6748138666152954, -1.6329717636108398, -1.5911297798156738, -1.5492876768112183, -1.5074455738067627, -1.4656034708023071, -1.4237613677978516, -1.381919264793396, -1.3400771617889404, -1.2982351779937744, -1.2563930749893188, -1.2145509719848633, -1.1727088689804077, -1.1308667659759521, -1.0890247821807861, -1.047182559967041, -1.005340576171875, -0.9634984731674194, -0.9216563701629639, -0.8798142671585083, -0.8379722237586975, -0.7961301207542419, -0.7542880177497864, -0.7124459743499756, -0.67060387134552, -0.6287617683410645, -0.5869196653366089, -0.5450775623321533, -0.5032355785369873, -0.46139347553253174, -0.41955137252807617, -0.3777092695236206, -0.33586716651916504, -0.2940250635147095, -0.2521829605102539, -0.2103409767150879, -0.16849887371063232, -0.12665677070617676, -0.08481466770172119, -0.042972564697265625, -0.0011304616928100586, 0.04071152210235596, 0.08255362510681152, 0.12439572811126709, 0.16623783111572266, 0.20807993412017822, 0.2499220371246338, 0.2917640209197998, 0.3336062431335449, 0.37544822692871094, 0.41729044914245605, 0.45913243293762207, 0.5009744167327881, 0.5428166389465332, 0.5846586227416992, 0.6265008449554443, 0.6683428287506104, 0.7101848125457764, 0.7520270347595215, 0.7938690185546875, 0.8357112407684326, 0.8775532245635986, 0.9193954467773438, 0.9612374305725098]}, "_runtime": 7592.330361366272, "_timestamp": 1585516670.751091, "_step": 498}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": 0.01928732357919216, "Value Loss": 10.788143157958984, "_runtime": 7592.330361366272, "_timestamp": 1585516670.751091, "_step": 499}
