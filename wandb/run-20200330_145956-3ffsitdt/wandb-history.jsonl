{"Episode reward": -64.68986295058335, "Episode length": 999, "Policy Loss": -0.028314169496297836, "Value Loss": 0.023805420845746994, "_runtime": 10499.862385749817, "_timestamp": 1585580415.707019, "_step": 0}
{"Episode reward": 42.06772662760677, "Episode length": 747, "Policy Loss": -0.2636105418205261, "Value Loss": 97.10091400146484, "_runtime": 10500.956211566925, "_timestamp": 1585580416.800845, "_step": 1}
{"Episode reward": 35.06885644436423, "Episode length": 736, "Policy Loss": 2.2302138805389404, "Value Loss": 313.5963134765625, "_runtime": 10502.529230117798, "_timestamp": 1585580418.3738635, "_step": 2}
{"Episode reward": -90.92839740735025, "Episode length": 999, "Policy Loss": 15.669086456298828, "Value Loss": 4509.60302734375, "_runtime": 10503.111849784851, "_timestamp": 1585580418.9564831, "_step": 3}
{"Episode reward": 69.78928414464016, "Episode length": 363, "Policy Loss": 8.359209060668945, "Value Loss": 352.1875305175781, "_runtime": 10503.358974218369, "_timestamp": 1585580419.2036076, "_step": 4}
{"Episode reward": 87.13084826454369, "Episode length": 145, "Policy Loss": -5.437516212463379, "Value Loss": 241.60690307617188, "_runtime": 10503.59674358368, "_timestamp": 1585580419.441377, "_step": 5}
{"Episode reward": 89.12216826486517, "Episode length": 115, "Policy Loss": 0.4485293924808502, "Value Loss": 93.89207458496094, "_runtime": 10503.792862415314, "_timestamp": 1585580419.6374958, "_step": 6}
{"Episode reward": 89.28283228229813, "Episode length": 116, "Policy Loss": 78.84073638916016, "Value Loss": 1255.79833984375, "_runtime": 10505.337488889694, "_timestamp": 1585580421.1821222, "_step": 7}
{"Episode reward": -98.16923879899639, "Episode length": 999, "Policy Loss": 5.8551716804504395, "Value Loss": 10.806356430053711, "_runtime": 10506.829231023788, "_timestamp": 1585580422.6738644, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7575046420097351, "Value Loss": 4.072292327880859, "_runtime": 10507.025221347809, "_timestamp": 1585580422.8698547, "_step": 9}
{"Episode reward": 88.94515686637416, "Episode length": 118, "Policy Loss": 17.76131248474121, "Value Loss": 140.3922119140625, "_runtime": 10507.259120464325, "_timestamp": 1585580423.1037538, "_step": 10}
{"Episode reward": 89.55357849428397, "Episode length": 112, "Policy Loss": 8.546738624572754, "Value Loss": 94.7132797241211, "_runtime": 10507.512242078781, "_timestamp": 1585580423.3568754, "_step": 11}
{"Episode reward": 87.5823057547644, "Episode length": 134, "Policy Loss": -0.953755795955658, "Value Loss": 77.13184356689453, "_runtime": 10507.691092729568, "_timestamp": 1585580423.535726, "_step": 12}
{"Episode reward": 89.18884412822518, "Episode length": 115, "Policy Loss": -18.138553619384766, "Value Loss": 216.3633270263672, "_runtime": 10507.859359741211, "_timestamp": 1585580423.703993, "_step": 13}
{"Episode reward": 89.92041469238373, "Episode length": 109, "Policy Loss": -4.3964433670043945, "Value Loss": 148.9197235107422, "_runtime": 10508.14218711853, "_timestamp": 1585580423.9868205, "_step": 14}
{"Episode reward": 83.65712130711232, "Episode length": 190, "Policy Loss": 2.0585649013519287, "Value Loss": 56.60154724121094, "_runtime": 10508.310330629349, "_timestamp": 1585580424.154964, "_step": 15}
{"Episode reward": 90.93082803590279, "Episode length": 109, "Policy Loss": 6.946649551391602, "Value Loss": 130.64259338378906, "_runtime": 10508.464000940323, "_timestamp": 1585580424.3086343, "_step": 16}
{"Episode reward": 91.2376009414603, "Episode length": 99, "Policy Loss": 4.228549957275391, "Value Loss": 105.26130676269531, "_runtime": 10508.615001440048, "_timestamp": 1585580424.4596348, "_step": 17}
{"Episode reward": 92.58970398590198, "Episode length": 92, "Policy Loss": 2.2523257732391357, "Value Loss": 104.17046356201172, "_runtime": 10508.754756689072, "_timestamp": 1585580424.59939, "_step": 18}
{"Episode reward": 92.91053307641182, "Episode length": 88, "Policy Loss": -1.5961642265319824, "Value Loss": 118.00949096679688, "_runtime": 10508.986269950867, "_timestamp": 1585580424.8309033, "_step": 19}
{"Episode reward": 88.44709333758493, "Episode length": 153, "Policy Loss": -0.03908798098564148, "Value Loss": 21.72614097595215, "_runtime": 10509.228987932205, "_timestamp": 1585580425.0736213, "_step": 20}
{"Episode reward": 87.52732789911761, "Episode length": 161, "Policy Loss": -1.258516788482666, "Value Loss": 100.08130645751953, "_runtime": 10509.460456609726, "_timestamp": 1585580425.30509, "_step": 21}
{"Episode reward": 88.32289827919207, "Episode length": 153, "Policy Loss": -0.2616954743862152, "Value Loss": 30.083471298217773, "_runtime": 10509.598040819168, "_timestamp": 1585580425.4426742, "_step": 22}
{"Episode reward": 93.84917104061434, "Episode length": 84, "Policy Loss": -2.2330074310302734, "Value Loss": 148.3509521484375, "_runtime": 10509.824429750443, "_timestamp": 1585580425.669063, "_step": 23}
{"Episode reward": 89.48081367132585, "Episode length": 147, "Policy Loss": -0.37754037976264954, "Value Loss": 69.4574966430664, "_runtime": 10510.03696846962, "_timestamp": 1585580425.8816018, "_step": 24}
{"Episode reward": 90.01139594793177, "Episode length": 138, "Policy Loss": 0.9527221918106079, "Value Loss": 55.760135650634766, "_runtime": 10510.163625478745, "_timestamp": 1585580426.0082588, "_step": 25}
{"Episode reward": 94.46772040131717, "Episode length": 81, "Policy Loss": 1.315691351890564, "Value Loss": 129.14663696289062, "_runtime": 10510.368201971054, "_timestamp": 1585580426.2128353, "_step": 26}
{"Episode reward": 90.87801372941661, "Episode length": 134, "Policy Loss": 1.530998945236206, "Value Loss": 61.14639663696289, "_runtime": 10510.580582380295, "_timestamp": 1585580426.4252157, "_step": 27}
{"Episode reward": 89.61864801509839, "Episode length": 139, "Policy Loss": -0.21647119522094727, "Value Loss": 49.06525421142578, "_runtime": 10511.01791214943, "_timestamp": 1585580426.8625455, "_step": 28}
{"Episode reward": 86.13762953984761, "Episode length": 299, "Policy Loss": 0.17762215435504913, "Value Loss": 25.438241958618164, "_runtime": 10511.328033685684, "_timestamp": 1585580427.172667, "_step": 29}
{"Episode reward": 88.02720569755019, "Episode length": 209, "Policy Loss": -0.9114506244659424, "Value Loss": 48.138484954833984, "_runtime": 10511.719340085983, "_timestamp": 1585580427.5639734, "_step": 30}
{"Episode reward": 85.37510228954469, "Episode length": 266, "Policy Loss": -0.7143532037734985, "Value Loss": 27.491287231445312, "_runtime": 10511.938358545303, "_timestamp": 1585580427.782992, "_step": 31}
{"Episode reward": 90.94282850448249, "Episode length": 134, "Policy Loss": -0.5338961482048035, "Value Loss": 21.11716651916504, "_runtime": 10512.172966718674, "_timestamp": 1585580428.0176, "_step": 32}
{"Episode reward": 91.12770729335347, "Episode length": 151, "Policy Loss": 0.051832906901836395, "Value Loss": 66.80734252929688, "_runtime": 10512.490253210068, "_timestamp": 1585580428.3348866, "_step": 33}
{"Episode reward": 87.83605725220656, "Episode length": 204, "Policy Loss": 0.5416930317878723, "Value Loss": 31.538095474243164, "_runtime": 10512.701561450958, "_timestamp": 1585580428.5461948, "_step": 34}
{"Episode reward": 90.4170602778339, "Episode length": 137, "Policy Loss": -1.3703910112380981, "Value Loss": 380.18023681640625, "_runtime": 10512.924881458282, "_timestamp": 1585580428.7695148, "_step": 35}
{"Episode reward": 91.35026516242587, "Episode length": 145, "Policy Loss": 2.8721089363098145, "Value Loss": 68.96582794189453, "_runtime": 10513.20219707489, "_timestamp": 1585580429.0468304, "_step": 36}
{"Episode reward": 89.71463512415542, "Episode length": 181, "Policy Loss": 0.4606330096721649, "Value Loss": 55.258766174316406, "_runtime": 10513.550367116928, "_timestamp": 1585580429.3950005, "_step": 37}
{"Episode reward": 85.60163301470043, "Episode length": 232, "Policy Loss": 0.4083603024482727, "Value Loss": 43.20174026489258, "_runtime": 10513.92113161087, "_timestamp": 1585580429.765765, "_step": 38}
{"Episode reward": 83.60073695147463, "Episode length": 248, "Policy Loss": 0.5469977259635925, "Value Loss": 40.417396545410156, "_runtime": 10514.188111066818, "_timestamp": 1585580430.0327444, "_step": 39}
{"Episode reward": 88.35846860217694, "Episode length": 175, "Policy Loss": 1.2004725933074951, "Value Loss": 57.173282623291016, "_runtime": 10514.466431856155, "_timestamp": 1585580430.3110652, "_step": 40}
{"Episode reward": 87.13056131659152, "Episode length": 180, "Policy Loss": 0.8816882371902466, "Value Loss": 55.58932876586914, "_runtime": 10514.747563838959, "_timestamp": 1585580430.5921972, "_step": 41}
{"Episode reward": 86.6658518097002, "Episode length": 181, "Policy Loss": 1.230354905128479, "Value Loss": 55.285953521728516, "_runtime": 10515.013021230698, "_timestamp": 1585580430.8576546, "_step": 42}
{"Episode reward": 88.47284668520062, "Episode length": 174, "Policy Loss": 0.898124635219574, "Value Loss": 57.56509780883789, "_runtime": 10515.295694589615, "_timestamp": 1585580431.140328, "_step": 43}
{"Episode reward": 87.00408485732639, "Episode length": 186, "Policy Loss": 0.7576456665992737, "Value Loss": 53.89918899536133, "_runtime": 10515.469326019287, "_timestamp": 1585580431.3139594, "_step": 44}
{"Episode reward": 92.19883205655773, "Episode length": 109, "Policy Loss": 1.422719955444336, "Value Loss": 91.99662017822266, "_runtime": 10515.814917564392, "_timestamp": 1585580431.659551, "_step": 45}
{"Episode reward": 84.6057101884771, "Episode length": 229, "Policy Loss": 0.7148465514183044, "Value Loss": 43.762977600097656, "_runtime": 10516.213054180145, "_timestamp": 1585580432.0576875, "_step": 46}
{"Episode reward": 82.2700571919367, "Episode length": 264, "Policy Loss": 0.6344788670539856, "Value Loss": 37.91267395019531, "_runtime": 10516.585145235062, "_timestamp": 1585580432.4297786, "_step": 47}
{"Episode reward": 83.7039457868824, "Episode length": 251, "Policy Loss": 0.5972599387168884, "Value Loss": 39.884857177734375, "_runtime": 10516.949649572372, "_timestamp": 1585580432.794283, "_step": 48}
{"Episode reward": 83.72667264441743, "Episode length": 241, "Policy Loss": 1.0827546119689941, "Value Loss": 41.52980422973633, "_runtime": 10517.426783323288, "_timestamp": 1585580433.2714167, "_step": 49}
{"Episode reward": 78.7058540431157, "Episode length": 316, "Policy Loss": 0.62286376953125, "Value Loss": 31.673961639404297, "_runtime": 10517.835168600082, "_timestamp": 1585580433.679802, "_step": 50}
{"Episode reward": 80.72129210640817, "Episode length": 269, "Policy Loss": 0.6366559267044067, "Value Loss": 37.20566940307617, "_runtime": 10518.284727811813, "_timestamp": 1585580434.1293612, "_step": 51}
{"Episode reward": 79.05958892569853, "Episode length": 299, "Policy Loss": 0.5807819962501526, "Value Loss": 33.47260284423828, "_runtime": 10518.573221206665, "_timestamp": 1585580434.4178545, "_step": 52}
{"Episode reward": 87.56062030917509, "Episode length": 184, "Policy Loss": 1.0236386060714722, "Value Loss": 54.421634674072266, "_runtime": 10518.863261461258, "_timestamp": 1585580434.7078948, "_step": 53}
{"Episode reward": 86.50313851667657, "Episode length": 185, "Policy Loss": 0.9292329549789429, "Value Loss": 54.128299713134766, "_runtime": 10519.260719537735, "_timestamp": 1585580435.1053529, "_step": 54}
{"Episode reward": 82.13247605391334, "Episode length": 260, "Policy Loss": 0.6331008672714233, "Value Loss": 38.488807678222656, "_runtime": 10519.529654502869, "_timestamp": 1585580435.3742878, "_step": 55}
{"Episode reward": 87.63664278558936, "Episode length": 176, "Policy Loss": 0.9909996390342712, "Value Loss": 56.85318374633789, "_runtime": 10519.763854265213, "_timestamp": 1585580435.6084876, "_step": 56}
{"Episode reward": 91.18052013915857, "Episode length": 151, "Policy Loss": 0.9163392186164856, "Value Loss": 66.38310241699219, "_runtime": 10520.145907402039, "_timestamp": 1585580435.9905407, "_step": 57}
{"Episode reward": 82.35288785428347, "Episode length": 250, "Policy Loss": 0.5706591010093689, "Value Loss": 40.04113006591797, "_runtime": 10520.425414800644, "_timestamp": 1585580436.2700481, "_step": 58}
{"Episode reward": 87.29180728280039, "Episode length": 183, "Policy Loss": 1.003493309020996, "Value Loss": 54.682403564453125, "_runtime": 10520.69284415245, "_timestamp": 1585580436.5374775, "_step": 59}
{"Episode reward": 87.64518899302946, "Episode length": 176, "Policy Loss": 1.6903159618377686, "Value Loss": 56.87565612792969, "_runtime": 10520.964880466461, "_timestamp": 1585580436.8095138, "_step": 60}
{"Episode reward": 87.49937978972339, "Episode length": 175, "Policy Loss": 0.9500960111618042, "Value Loss": 57.162086486816406, "_runtime": 10521.249071836472, "_timestamp": 1585580437.0937052, "_step": 61}
{"Episode reward": 87.88143138261641, "Episode length": 184, "Policy Loss": 0.7687371969223022, "Value Loss": 54.373870849609375, "_runtime": 10521.643803358078, "_timestamp": 1585580437.4884367, "_step": 62}
{"Episode reward": 81.75629077068338, "Episode length": 263, "Policy Loss": 0.5674785375595093, "Value Loss": 38.03164291381836, "_runtime": 10521.91704082489, "_timestamp": 1585580437.7616742, "_step": 63}
{"Episode reward": 86.83580898151622, "Episode length": 179, "Policy Loss": 1.0215907096862793, "Value Loss": 55.87326431274414, "_runtime": 10522.190976142883, "_timestamp": 1585580438.0356095, "_step": 64}
{"Episode reward": 86.63294234851487, "Episode length": 181, "Policy Loss": 1.2584515810012817, "Value Loss": 55.25714874267578, "_runtime": 10522.51605463028, "_timestamp": 1585580438.360688, "_step": 65}
{"Episode reward": 86.16915939567802, "Episode length": 210, "Policy Loss": 0.6896465420722961, "Value Loss": 47.61948013305664, "_runtime": 10522.796311616898, "_timestamp": 1585580438.640945, "_step": 66}
{"Episode reward": 87.61328540099035, "Episode length": 185, "Policy Loss": 0.9718872308731079, "Value Loss": 54.108463287353516, "_runtime": 10523.078846693039, "_timestamp": 1585580438.92348, "_step": 67}
{"Episode reward": 88.07681965533655, "Episode length": 186, "Policy Loss": 1.3431148529052734, "Value Loss": 53.75581741333008, "_runtime": 10523.340725183487, "_timestamp": 1585580439.1853585, "_step": 68}
{"Episode reward": 88.67734478917916, "Episode length": 170, "Policy Loss": 0.7829152941703796, "Value Loss": 58.890560150146484, "_runtime": 10523.608279705048, "_timestamp": 1585580439.452913, "_step": 69}
{"Episode reward": 87.15012559453379, "Episode length": 175, "Policy Loss": 0.8410698771476746, "Value Loss": 57.17049026489258, "_runtime": 10524.043595075607, "_timestamp": 1585580439.8882284, "_step": 70}
{"Episode reward": 80.35122723287738, "Episode length": 290, "Policy Loss": 0.4136236011981964, "Value Loss": 34.520729064941406, "_runtime": 10524.310518026352, "_timestamp": 1585580440.1551514, "_step": 71}
{"Episode reward": 87.41107761388345, "Episode length": 175, "Policy Loss": 0.9869528412818909, "Value Loss": 57.11711883544922, "_runtime": 10524.711575508118, "_timestamp": 1585580440.5562088, "_step": 72}
{"Episode reward": 81.6862389176157, "Episode length": 269, "Policy Loss": 0.5958245992660522, "Value Loss": 37.15586471557617, "_runtime": 10525.113053798676, "_timestamp": 1585580440.9576871, "_step": 73}
{"Episode reward": 82.33015555840498, "Episode length": 263, "Policy Loss": 0.5188789963722229, "Value Loss": 38.00066375732422, "_runtime": 10525.613406419754, "_timestamp": 1585580441.4580398, "_step": 74}
{"Episode reward": 77.80651705891061, "Episode length": 336, "Policy Loss": 0.5006771683692932, "Value Loss": 29.777393341064453, "_runtime": 10526.02931380272, "_timestamp": 1585580441.8739471, "_step": 75}
{"Episode reward": 80.60254491264993, "Episode length": 275, "Policy Loss": 0.5206090807914734, "Value Loss": 36.33742904663086, "_runtime": 10526.43255496025, "_timestamp": 1585580442.2771883, "_step": 76}
{"Episode reward": 82.02657422099244, "Episode length": 266, "Policy Loss": 0.8133015632629395, "Value Loss": 37.63094711303711, "_runtime": 10526.922053813934, "_timestamp": 1585580442.7666872, "_step": 77}
{"Episode reward": 78.46650270770246, "Episode length": 322, "Policy Loss": 1.1876928806304932, "Value Loss": 31.029687881469727, "_runtime": 10527.408465147018, "_timestamp": 1585580443.2530985, "_step": 78}
{"Episode reward": 78.81994961414777, "Episode length": 322, "Policy Loss": 0.3302408456802368, "Value Loss": 31.02759552001953, "_runtime": 10527.756664514542, "_timestamp": 1585580443.6012979, "_step": 79}
{"Episode reward": 84.26615958054239, "Episode length": 227, "Policy Loss": 0.6418055891990662, "Value Loss": 44.009429931640625, "_runtime": 10528.128316640854, "_timestamp": 1585580443.97295, "_step": 80}
{"Episode reward": 84.4066766929439, "Episode length": 241, "Policy Loss": 0.5168617367744446, "Value Loss": 41.52656173706055, "_runtime": 10528.627167224884, "_timestamp": 1585580444.4718006, "_step": 81}
{"Episode reward": 77.79517272739182, "Episode length": 329, "Policy Loss": 0.6256027221679688, "Value Loss": 30.362102508544922, "_runtime": 10528.908232450485, "_timestamp": 1585580444.7528658, "_step": 82}
{"Episode reward": 87.87972739242824, "Episode length": 182, "Policy Loss": 1.0145596265792847, "Value Loss": 54.96512222290039, "_runtime": 10529.366002082825, "_timestamp": 1585580445.2106354, "_step": 83}
{"Episode reward": 80.71124610552313, "Episode length": 304, "Policy Loss": 0.30868038535118103, "Value Loss": 32.854793548583984, "_runtime": 10529.844127178192, "_timestamp": 1585580445.6887605, "_step": 84}
{"Episode reward": 80.04025841222887, "Episode length": 307, "Policy Loss": 0.27483123540878296, "Value Loss": 32.53194808959961, "_runtime": 10530.227908372879, "_timestamp": 1585580446.0725417, "_step": 85}
{"Episode reward": 83.15703182914837, "Episode length": 249, "Policy Loss": 0.49068912863731384, "Value Loss": 40.16935348510742, "_runtime": 10530.63043642044, "_timestamp": 1585580446.4750698, "_step": 86}
{"Episode reward": 81.84071366359333, "Episode length": 265, "Policy Loss": 0.5132760405540466, "Value Loss": 37.683650970458984, "_runtime": 10530.95326757431, "_timestamp": 1585580446.797901, "_step": 87}
{"Episode reward": 85.47404549908562, "Episode length": 208, "Policy Loss": 0.4471403956413269, "Value Loss": 48.00676727294922, "_runtime": 10531.39034128189, "_timestamp": 1585580447.2349746, "_step": 88}
{"Episode reward": 80.30414863555282, "Episode length": 292, "Policy Loss": 0.3214305341243744, "Value Loss": 34.24076461791992, "_runtime": 10531.672868013382, "_timestamp": 1585580447.5175014, "_step": 89}
{"Episode reward": 88.03876753104312, "Episode length": 182, "Policy Loss": 1.0953524112701416, "Value Loss": 54.8577880859375, "_runtime": 10532.05937218666, "_timestamp": 1585580447.9040055, "_step": 90}
{"Episode reward": 83.58201168072102, "Episode length": 258, "Policy Loss": 0.6378989815711975, "Value Loss": 38.75761413574219, "_runtime": 10532.434731721878, "_timestamp": 1585580448.279365, "_step": 91}
{"Episode reward": 85.32780371608307, "Episode length": 246, "Policy Loss": 0.36495333909988403, "Value Loss": 40.65696716308594, "_runtime": 10532.819543123245, "_timestamp": 1585580448.6641765, "_step": 92}
{"Episode reward": 83.47618620656776, "Episode length": 257, "Policy Loss": 0.3470257520675659, "Value Loss": 38.90816116333008, "_runtime": 10533.09483909607, "_timestamp": 1585580448.9394724, "_step": 93}
{"Episode reward": 87.95051694363903, "Episode length": 178, "Policy Loss": 1.0878807306289673, "Value Loss": 56.189002990722656, "_runtime": 10533.415865898132, "_timestamp": 1585580449.2604992, "_step": 94}
{"Episode reward": 85.72911557824506, "Episode length": 210, "Policy Loss": 0.31914690136909485, "Value Loss": 47.53107452392578, "_runtime": 10533.74324798584, "_timestamp": 1585580449.5878813, "_step": 95}
{"Episode reward": 86.46776673262286, "Episode length": 214, "Policy Loss": 0.5460076332092285, "Value Loss": 46.689945220947266, "_runtime": 10534.279302835464, "_timestamp": 1585580450.1239362, "_step": 96}
{"Episode reward": 76.71083433022679, "Episode length": 362, "Policy Loss": 0.22587406635284424, "Value Loss": 27.572734832763672, "_runtime": 10534.559599399567, "_timestamp": 1585580450.4042327, "_step": 97}
{"Episode reward": 87.63242204700371, "Episode length": 184, "Policy Loss": 0.6835159063339233, "Value Loss": 54.316226959228516, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531, 98.69734191894531]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-83.07317352294922, -80.56333923339844, -78.05351257324219, -75.5436782836914, -73.03384399414062, -70.52401733398438, -68.0141830444336, -65.50434875488281, -62.9945182800293, -60.48468780517578, -57.974853515625, -55.465023040771484, -52.95519256591797, -50.44535827636719, -47.93552780151367, -45.42569351196289, -42.915863037109375, -40.40603256225586, -37.89619827270508, -35.38636779785156, -32.87653350830078, -30.366703033447266, -27.85687255859375, -25.34703826904297, -22.837207794189453, -20.327377319335938, -17.817543029785156, -15.307708740234375, -12.797882080078125, -10.288047790527344, -7.7782135009765625, -5.2683868408203125, -2.7585525512695312, -0.24871826171875, 2.2611083984375, 4.770942687988281, 7.2807769775390625, 9.790603637695312, 12.300437927246094, 14.810272216796875, 17.320106506347656, 19.829933166503906, 22.339767456054688, 24.84960174560547, 27.35942840576172, 29.8692626953125, 32.37909698486328, 34.88892364501953, 37.39875793457031, 39.908592224121094, 42.418418884277344, 44.928260803222656, 47.438087463378906, 49.947914123535156, 52.45775604248047, 54.96758270263672, 57.47740936279297, 59.98725128173828, 62.49707794189453, 65.00690460205078, 67.5167465209961, 70.02657318115234, 72.5363998413086, 75.0462417602539, 77.55606842041016]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-23.137447357177734, -22.279460906982422, -21.42147445678711, -20.563486099243164, -19.70549964904785, -18.84751319885254, -17.989524841308594, -17.13153839111328, -16.27355194091797, -15.415565490722656, -14.557578086853027, -13.699590682983398, -12.841604232788086, -11.983617782592773, -11.125630378723145, -10.267642974853516, -9.409656524658203, -8.55167007446289, -7.693682670593262, -6.835695266723633, -5.97770881652832, -5.119722366333008, -4.2617340087890625, -3.40374755859375, -2.5457611083984375, -1.687774658203125, -0.8297882080078125, 0.028200149536132812, 0.8861865997314453, 1.7441730499267578, 2.602161407470703, 3.4601478576660156, 4.318134307861328, 5.176120758056641, 6.034107208251953, 6.892095565795898, 7.750082015991211, 8.608068466186523, 9.466056823730469, 10.324043273925781, 11.182029724121094, 12.040016174316406, 12.898002624511719, 13.755989074707031, 14.61397933959961, 15.471965789794922, 16.329952239990234, 17.187938690185547, 18.04592514038086, 18.903911590576172, 19.761898040771484, 20.619884490966797, 21.47787094116211, 22.335861206054688, 23.19384765625, 24.051834106445312, 24.909820556640625, 25.767807006835938, 26.62579345703125, 27.483779907226562, 28.34177017211914, 29.199756622314453, 30.057743072509766, 30.915729522705078, 31.77371597290039]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 7.0, 4.0, 7.0, 4.0, 5.0, 4.0, 8.0, 18.0, 27.0, 65.0, 91.0, 97.0, 42.0, 35.0, 16.0, 11.0, 7.0, 7.0, 7.0, 5.0, 2.0, 6.0, 3.0, 4.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-14.765878677368164, -14.218832969665527, -13.671786308288574, -13.124740600585938, -12.577693939208984, -12.030648231506348, -11.483602523803711, -10.936555862426758, -10.389509201049805, -9.842463493347168, -9.295417785644531, -8.748371124267578, -8.201325416564941, -7.6542792320251465, -7.107233047485352, -6.560186386108398, -6.013140678405762, -5.466094970703125, -4.919048309326172, -4.372002601623535, -3.824955940246582, -3.2779102325439453, -2.730863571166992, -2.1838178634643555, -1.6367721557617188, -1.0897254943847656, -0.5426797866821289, 0.004366874694824219, 0.5514125823974609, 1.098459243774414, 1.6455059051513672, 2.1925506591796875, 2.7395973205566406, 3.2866439819335938, 3.833688735961914, 4.380735397338867, 4.92778205871582, 5.474828720092773, 6.021873474121094, 6.568920135498047, 7.115966796875, 7.66301155090332, 8.210058212280273, 8.757104873657227, 9.30415153503418, 9.8511962890625, 10.398242950439453, 10.945289611816406, 11.492334365844727, 12.03938102722168, 12.586427688598633, 13.133474349975586, 13.680519104003906, 14.22756576538086, 14.774612426757812, 15.321659088134766, 15.868703842163086, 16.41575050354004, 16.962797164916992, 17.509843826293945, 18.0568904876709, 18.603933334350586, 19.15097999572754, 19.698026657104492, 20.245073318481445]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-46.12614059448242, -44.19804763793945, -42.26995849609375, -40.34186553955078, -38.41377639770508, -36.48568344116211, -34.557594299316406, -32.62950134277344, -30.7014102935791, -28.773319244384766, -26.84522819519043, -24.917137145996094, -22.989044189453125, -21.06095314025879, -19.132862091064453, -17.204771041870117, -15.276679992675781, -13.348587036132812, -11.42049789428711, -9.49240493774414, -7.5643157958984375, -5.636222839355469, -3.7081336975097656, -1.7800407409667969, 0.14805221557617188, 2.076141357421875, 4.004234313964844, 5.932323455810547, 7.860416412353516, 9.788505554199219, 11.716598510742188, 13.64468765258789, 15.57278060913086, 17.500873565673828, 19.428966522216797, 21.357051849365234, 23.285144805908203, 25.213237762451172, 27.14133071899414, 29.069416046142578, 30.997509002685547, 32.925601959228516, 34.853694915771484, 36.78178787231445, 38.70987319946289, 40.63796615600586, 42.56605911254883, 44.4941520690918, 46.422245025634766, 48.3503303527832, 50.27842330932617, 52.20651626586914, 54.13460922241211, 56.06269454956055, 57.990787506103516, 59.918880462646484, 61.84697341918945, 63.77506637573242, 65.70315551757812, 67.63124084472656, 69.55934143066406, 71.4874267578125, 73.41551208496094, 75.34361267089844, 77.27169799804688]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 4.0, 2.0, 4.0, 6.0, 5.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0], "bins": [-26.61199378967285, -25.951709747314453, -25.291423797607422, -24.631139755249023, -23.970855712890625, -23.310569763183594, -22.650285720825195, -21.990001678466797, -21.329715728759766, -20.669431686401367, -20.00914764404297, -19.348861694335938, -18.68857765197754, -18.02829360961914, -17.36800765991211, -16.707725524902344, -16.047439575195312, -15.387154579162598, -14.7268705368042, -14.066585540771484, -13.406301498413086, -12.746016502380371, -12.085731506347656, -11.425447463989258, -10.765162467956543, -10.104877471923828, -9.44459342956543, -8.784309387207031, -8.1240234375, -7.463739395141602, -6.803455352783203, -6.143169403076172, -5.482885360717773, -4.822601318359375, -4.162315368652344, -3.5020313262939453, -2.841747283935547, -2.1814613342285156, -1.5211772918701172, -0.8608932495117188, -0.2006092071533203, 0.45967674255371094, 1.1199607849121094, 1.7802448272705078, 2.440530776977539, 3.1008148193359375, 3.761098861694336, 4.421384811401367, 5.081668853759766, 5.741952896118164, 6.402238845825195, 7.062520980834961, 7.722806930541992, 8.383092880249023, 9.043375015258789, 9.70366096496582, 10.363946914672852, 11.024229049682617, 11.684514999389648, 12.34480094909668, 13.005083084106445, 13.665369033813477, 14.325654983520508, 14.985937118530273, 15.646223068237305]}, "_runtime": 10534.828974485397, "_timestamp": 1585580450.6736078, "_step": 98}
{"Episode reward": 88.82563391931018, "Episode length": 175, "Policy Loss": 0.5396190285682678, "Value Loss": 57.02281951904297, "_runtime": 10535.389572143555, "_timestamp": 1585580451.2342055, "_step": 99}
{"Episode reward": 76.80890036823945, "Episode length": 371, "Policy Loss": 0.27260154485702515, "Value Loss": 26.95022201538086, "_runtime": 10535.672536849976, "_timestamp": 1585580451.5171702, "_step": 100}
{"Episode reward": 88.11587391342415, "Episode length": 187, "Policy Loss": 0.6762797832489014, "Value Loss": 53.35816955566406, "_runtime": 10536.054135799408, "_timestamp": 1585580451.8987691, "_step": 101}
{"Episode reward": 84.91443431444176, "Episode length": 256, "Policy Loss": 0.2585083544254303, "Value Loss": 38.97597122192383, "_runtime": 10536.407426595688, "_timestamp": 1585580452.25206, "_step": 102}
{"Episode reward": 86.6323847197368, "Episode length": 226, "Policy Loss": 0.2875664532184601, "Value Loss": 44.21282958984375, "_runtime": 10536.829301834106, "_timestamp": 1585580452.6739352, "_step": 103}
{"Episode reward": 83.8944876131978, "Episode length": 283, "Policy Loss": 0.4220970869064331, "Value Loss": 35.296512603759766, "_runtime": 10537.109825134277, "_timestamp": 1585580452.9544585, "_step": 104}
{"Episode reward": 89.36243790669322, "Episode length": 181, "Policy Loss": 0.39104774594306946, "Value Loss": 55.114112854003906, "_runtime": 10537.375393867493, "_timestamp": 1585580453.2200272, "_step": 105}
{"Episode reward": 89.77723038048097, "Episode length": 172, "Policy Loss": 0.43459847569465637, "Value Loss": 58.08170700073242, "_runtime": 10537.809277772903, "_timestamp": 1585580453.653911, "_step": 106}
{"Episode reward": 84.51628361002554, "Episode length": 284, "Policy Loss": 0.15246538817882538, "Value Loss": 35.124935150146484, "_runtime": 10538.192436695099, "_timestamp": 1585580454.03707, "_step": 107}
{"Episode reward": 85.30596350207747, "Episode length": 254, "Policy Loss": 0.26303303241729736, "Value Loss": 39.342803955078125, "_runtime": 10538.59438419342, "_timestamp": 1585580454.4390175, "_step": 108}
{"Episode reward": 83.67772499579287, "Episode length": 269, "Policy Loss": 0.11189086735248566, "Value Loss": 37.0806884765625, "_runtime": 10538.921429157257, "_timestamp": 1585580454.7660625, "_step": 109}
{"Episode reward": 86.77365643973941, "Episode length": 211, "Policy Loss": 0.5086632370948792, "Value Loss": 47.280269622802734, "_runtime": 10539.194408655167, "_timestamp": 1585580455.039042, "_step": 110}
{"Episode reward": 90.65799337901034, "Episode length": 175, "Policy Loss": 0.333208829164505, "Value Loss": 56.98800277709961, "_runtime": 10539.682666540146, "_timestamp": 1585580455.5273, "_step": 111}
{"Episode reward": 82.2979697497029, "Episode length": 323, "Policy Loss": 0.341209352016449, "Value Loss": 30.8785400390625, "_runtime": 10540.034650564194, "_timestamp": 1585580455.879284, "_step": 112}
{"Episode reward": 88.18551580613851, "Episode length": 231, "Policy Loss": 1.402713418006897, "Value Loss": 43.18107986450195, "_runtime": 10540.360219955444, "_timestamp": 1585580456.2048533, "_step": 113}
{"Episode reward": 87.8766464218538, "Episode length": 217, "Policy Loss": 0.17102037370204926, "Value Loss": 46.04344177246094, "_runtime": 10540.789935112, "_timestamp": 1585580456.6345685, "_step": 114}
{"Episode reward": 85.89813615493665, "Episode length": 282, "Policy Loss": 0.06505399942398071, "Value Loss": 35.407596588134766, "_runtime": 10541.070242404938, "_timestamp": 1585580456.9148757, "_step": 115}
{"Episode reward": 89.31301026392792, "Episode length": 181, "Policy Loss": 0.750067949295044, "Value Loss": 55.099273681640625, "_runtime": 10541.354724168777, "_timestamp": 1585580457.1993575, "_step": 116}
{"Episode reward": 89.9689410475298, "Episode length": 185, "Policy Loss": 0.23577789962291718, "Value Loss": 53.9886360168457, "_runtime": 10541.800451755524, "_timestamp": 1585580457.645085, "_step": 117}
{"Episode reward": 84.22986862666552, "Episode length": 294, "Policy Loss": 0.15224997699260712, "Value Loss": 33.96466064453125, "_runtime": 10542.237823486328, "_timestamp": 1585580458.0824568, "_step": 118}
{"Episode reward": 85.00029351278316, "Episode length": 292, "Policy Loss": 0.08944813162088394, "Value Loss": 34.21110916137695, "_runtime": 10542.517216682434, "_timestamp": 1585580458.36185, "_step": 119}
{"Episode reward": 91.08024271414695, "Episode length": 182, "Policy Loss": 0.39221251010894775, "Value Loss": 54.768306732177734, "_runtime": 10542.995725154877, "_timestamp": 1585580458.8403585, "_step": 120}
{"Episode reward": 83.30440870778651, "Episode length": 317, "Policy Loss": 0.03619273006916046, "Value Loss": 31.451557159423828, "_runtime": 10543.320675373077, "_timestamp": 1585580459.1653087, "_step": 121}
{"Episode reward": 89.30773378104297, "Episode length": 210, "Policy Loss": 0.080963134765625, "Value Loss": 47.55173873901367, "_runtime": 10543.577213287354, "_timestamp": 1585580459.4218466, "_step": 122}
{"Episode reward": 91.42432699058371, "Episode length": 167, "Policy Loss": 0.16948780417442322, "Value Loss": 59.77737808227539, "_runtime": 10544.027400016785, "_timestamp": 1585580459.8720334, "_step": 123}
{"Episode reward": 85.20519690851184, "Episode length": 294, "Policy Loss": 0.011411387473344803, "Value Loss": 33.9323844909668, "_runtime": 10544.324711084366, "_timestamp": 1585580460.1693444, "_step": 124}
{"Episode reward": 89.69189704443268, "Episode length": 194, "Policy Loss": 0.2361505776643753, "Value Loss": 51.37147521972656, "_runtime": 10544.558564424515, "_timestamp": 1585580460.4031978, "_step": 125}
{"Episode reward": 92.45707077396732, "Episode length": 152, "Policy Loss": 0.2543128430843353, "Value Loss": 65.5557632446289, "_runtime": 10544.995087623596, "_timestamp": 1585580460.839721, "_step": 126}
{"Episode reward": 87.61798721325175, "Episode length": 286, "Policy Loss": 0.12855671346187592, "Value Loss": 34.90742874145508, "_runtime": 10545.43618631363, "_timestamp": 1585580461.2808197, "_step": 127}
{"Episode reward": 86.39249635934851, "Episode length": 295, "Policy Loss": 0.20873099565505981, "Value Loss": 33.79337692260742, "_runtime": 10545.667252779007, "_timestamp": 1585580461.5118861, "_step": 128}
{"Episode reward": 92.09459243429934, "Episode length": 150, "Policy Loss": 0.19690494239330292, "Value Loss": 66.42105102539062, "_runtime": 10546.09727716446, "_timestamp": 1585580461.9419105, "_step": 129}
{"Episode reward": 87.58694949148115, "Episode length": 282, "Policy Loss": 0.03697607293725014, "Value Loss": 35.36422348022461, "_runtime": 10546.436079025269, "_timestamp": 1585580462.2807124, "_step": 130}
{"Episode reward": 89.32216658433899, "Episode length": 220, "Policy Loss": 0.5468487739562988, "Value Loss": 45.29048156738281, "_runtime": 10546.767893314362, "_timestamp": 1585580462.6125267, "_step": 131}
{"Episode reward": 89.44441458524629, "Episode length": 219, "Policy Loss": -0.0007132587488740683, "Value Loss": 45.56032943725586, "_runtime": 10547.248565912247, "_timestamp": 1585580463.0931993, "_step": 132}
{"Episode reward": 83.91962928341218, "Episode length": 319, "Policy Loss": 0.5844472646713257, "Value Loss": 31.241912841796875, "_runtime": 10547.489244937897, "_timestamp": 1585580463.3338783, "_step": 133}
{"Episode reward": 92.50786098312402, "Episode length": 154, "Policy Loss": 0.1417020708322525, "Value Loss": 64.6807861328125, "_runtime": 10547.83180141449, "_timestamp": 1585580463.6764348, "_step": 134}
{"Episode reward": 88.21665226219875, "Episode length": 226, "Policy Loss": -0.06824469566345215, "Value Loss": 44.155948638916016, "_runtime": 10548.299838542938, "_timestamp": 1585580464.144472, "_step": 135}
{"Episode reward": 85.37164132462884, "Episode length": 307, "Policy Loss": 0.2718454599380493, "Value Loss": 32.45814514160156, "_runtime": 10548.64473414421, "_timestamp": 1585580464.4893675, "_step": 136}
{"Episode reward": 88.11548364398134, "Episode length": 231, "Policy Loss": -0.05914662033319473, "Value Loss": 43.12675094604492, "_runtime": 10548.891664028168, "_timestamp": 1585580464.7362974, "_step": 137}
{"Episode reward": 91.2957881397518, "Episode length": 158, "Policy Loss": 0.1408136785030365, "Value Loss": 63.035736083984375, "_runtime": 10549.271585941315, "_timestamp": 1585580465.1162193, "_step": 138}
{"Episode reward": 85.75808165187166, "Episode length": 246, "Policy Loss": 0.10510154813528061, "Value Loss": 40.498905181884766, "_runtime": 10549.530268907547, "_timestamp": 1585580465.3749022, "_step": 139}
{"Episode reward": 90.57793842990988, "Episode length": 165, "Policy Loss": -0.10932660102844238, "Value Loss": 60.358924865722656, "_runtime": 10549.775794267654, "_timestamp": 1585580465.6204276, "_step": 140}
{"Episode reward": 90.2039471120277, "Episode length": 160, "Policy Loss": -0.1456734836101532, "Value Loss": 62.242950439453125, "_runtime": 10550.859693288803, "_timestamp": 1585580466.7043266, "_step": 141}
{"Episode reward": 59.811203718969416, "Episode length": 717, "Policy Loss": 0.04841746762394905, "Value Loss": 13.920084953308105, "_runtime": 10551.255574941635, "_timestamp": 1585580467.1002083, "_step": 142}
{"Episode reward": 85.07854555164454, "Episode length": 254, "Policy Loss": -0.07087665051221848, "Value Loss": 39.220211029052734, "_runtime": 10552.134720563889, "_timestamp": 1585580467.979354, "_step": 143}
{"Episode reward": 63.114590892491535, "Episode length": 591, "Policy Loss": -0.031006185337901115, "Value Loss": 16.88376808166504, "_runtime": 10553.69111442566, "_timestamp": 1585580469.5357478, "_step": 144}
{"Episode reward": -63.67543421943208, "Episode length": 999, "Policy Loss": -0.11194363981485367, "Value Loss": 0.04692727327346802, "_runtime": 10554.077818155289, "_timestamp": 1585580469.9224515, "_step": 145}
{"Episode reward": 85.67067225403282, "Episode length": 240, "Policy Loss": -0.055142078548669815, "Value Loss": 41.503231048583984, "_runtime": 10554.943188428879, "_timestamp": 1585580470.7878218, "_step": 146}
{"Episode reward": 64.1365164292292, "Episode length": 565, "Policy Loss": -0.15702930092811584, "Value Loss": 17.657936096191406, "_runtime": 10555.740201473236, "_timestamp": 1585580471.5848348, "_step": 147}
{"Episode reward": 67.85838202731142, "Episode length": 489, "Policy Loss": -0.04983925819396973, "Value Loss": 20.4323673248291, "_runtime": 10557.258654117584, "_timestamp": 1585580473.1032875, "_step": 148}
{"Episode reward": -65.88878197353385, "Episode length": 999, "Policy Loss": -0.10260464996099472, "Value Loss": 0.0507485456764698, "_runtime": 10558.807735443115, "_timestamp": 1585580474.6523688, "_step": 149}
{"Episode reward": -64.41863670389297, "Episode length": 999, "Policy Loss": -0.11419794708490372, "Value Loss": 0.050700604915618896, "_runtime": 10560.400247335434, "_timestamp": 1585580476.2448807, "_step": 150}
{"Episode reward": -65.87527906150153, "Episode length": 999, "Policy Loss": -0.10020305961370468, "Value Loss": 0.05172349512577057, "_runtime": 10561.982613563538, "_timestamp": 1585580477.827247, "_step": 151}
{"Episode reward": -69.13041295868183, "Episode length": 999, "Policy Loss": -0.09526451677083969, "Value Loss": 0.05329405143857002, "_runtime": 10563.540449380875, "_timestamp": 1585580479.3850827, "_step": 152}
{"Episode reward": -68.9380304366002, "Episode length": 999, "Policy Loss": -0.09582646191120148, "Value Loss": 0.053328368812799454, "_runtime": 10565.114524364471, "_timestamp": 1585580480.9591577, "_step": 153}
{"Episode reward": -73.41681784954002, "Episode length": 999, "Policy Loss": -0.07710637897253036, "Value Loss": 0.05524090677499771, "_runtime": 10566.706849336624, "_timestamp": 1585580482.5514827, "_step": 154}
{"Episode reward": -73.24264686585224, "Episode length": 999, "Policy Loss": -0.07491908222436905, "Value Loss": 0.055070675909519196, "_runtime": 10568.280624389648, "_timestamp": 1585580484.1252577, "_step": 155}
{"Episode reward": -74.0489441072564, "Episode length": 999, "Policy Loss": -0.07376258820295334, "Value Loss": 0.0552249550819397, "_runtime": 10569.856845378876, "_timestamp": 1585580485.7014787, "_step": 156}
{"Episode reward": -79.7107974305515, "Episode length": 999, "Policy Loss": -0.04820425063371658, "Value Loss": 0.057329993695020676, "_runtime": 10571.442126274109, "_timestamp": 1585580487.2867596, "_step": 157}
{"Episode reward": -82.99171708238981, "Episode length": 999, "Policy Loss": -0.053334224969148636, "Value Loss": 0.058407921344041824, "_runtime": 10573.023725271225, "_timestamp": 1585580488.8683586, "_step": 158}
{"Episode reward": -89.24414728299102, "Episode length": 999, "Policy Loss": -0.04161045327782631, "Value Loss": 0.06060841307044029, "_runtime": 10574.618302106857, "_timestamp": 1585580490.4629354, "_step": 159}
{"Episode reward": -86.77963745207877, "Episode length": 999, "Policy Loss": -0.041165560483932495, "Value Loss": 0.05905977636575699, "_runtime": 10576.206198453903, "_timestamp": 1585580492.0508318, "_step": 160}
{"Episode reward": -91.52674455696112, "Episode length": 999, "Policy Loss": -0.022862013429403305, "Value Loss": 0.06052135303616524, "_runtime": 10577.790307283401, "_timestamp": 1585580493.6349406, "_step": 161}
{"Episode reward": -93.68198044139827, "Episode length": 999, "Policy Loss": -0.018682584166526794, "Value Loss": 0.06082891300320625, "_runtime": 10579.376601696014, "_timestamp": 1585580495.221235, "_step": 162}
{"Episode reward": -93.72900438806852, "Episode length": 999, "Policy Loss": -0.015417870134115219, "Value Loss": 0.060125987976789474, "_runtime": 10580.962953805923, "_timestamp": 1585580496.8075871, "_step": 163}
{"Episode reward": -92.48782150555171, "Episode length": 999, "Policy Loss": -0.004837122280150652, "Value Loss": 0.058839909732341766, "_runtime": 10582.53702878952, "_timestamp": 1585580498.3816621, "_step": 164}
{"Episode reward": -91.32336190793902, "Episode length": 999, "Policy Loss": -0.016497032716870308, "Value Loss": 0.05750838667154312, "_runtime": 10584.172915935516, "_timestamp": 1585580500.0175493, "_step": 165}
{"Episode reward": -93.69225889077269, "Episode length": 999, "Policy Loss": -0.0034504253417253494, "Value Loss": 0.05770423635840416, "_runtime": 10585.766376972198, "_timestamp": 1585580501.6110103, "_step": 166}
{"Episode reward": -92.3073740222077, "Episode length": 999, "Policy Loss": -0.004413300193846226, "Value Loss": 0.05620969831943512, "_runtime": 10587.360167264938, "_timestamp": 1585580503.2048006, "_step": 167}
{"Episode reward": -94.6184333206426, "Episode length": 999, "Policy Loss": -0.00017780219786800444, "Value Loss": 0.056337956339120865, "_runtime": 10588.960048437119, "_timestamp": 1585580504.8046818, "_step": 168}
{"Episode reward": -93.41711757940269, "Episode length": 999, "Policy Loss": -0.0029371657874435186, "Value Loss": 0.054921168833971024, "_runtime": 10590.555560112, "_timestamp": 1585580506.4001935, "_step": 169}
{"Episode reward": -94.11760598072712, "Episode length": 999, "Policy Loss": -0.0007911393186077476, "Value Loss": 0.054260462522506714, "_runtime": 10592.150861024857, "_timestamp": 1585580507.9954944, "_step": 170}
{"Episode reward": -95.93603125647103, "Episode length": 999, "Policy Loss": 0.018978387117385864, "Value Loss": 0.0540611669421196, "_runtime": 10593.737271308899, "_timestamp": 1585580509.5819046, "_step": 171}
{"Episode reward": -95.54496707155076, "Episode length": 999, "Policy Loss": 0.01634063385426998, "Value Loss": 0.052951425313949585, "_runtime": 10595.324777126312, "_timestamp": 1585580511.1694105, "_step": 172}
{"Episode reward": -97.83971179978003, "Episode length": 999, "Policy Loss": 0.012905064970254898, "Value Loss": 0.05291052162647247, "_runtime": 10596.90979719162, "_timestamp": 1585580512.7544305, "_step": 173}
{"Episode reward": -95.50074764353798, "Episode length": 999, "Policy Loss": 0.006867887452244759, "Value Loss": 0.05099564790725708, "_runtime": 10598.50811624527, "_timestamp": 1585580514.3527496, "_step": 174}
{"Episode reward": -95.2774895358578, "Episode length": 999, "Policy Loss": 0.015561944805085659, "Value Loss": 0.04992545396089554, "_runtime": 10600.104398012161, "_timestamp": 1585580515.9490314, "_step": 175}
{"Episode reward": -95.17286055568984, "Episode length": 999, "Policy Loss": 0.010768304578959942, "Value Loss": 0.04894465580582619, "_runtime": 10601.690226078033, "_timestamp": 1585580517.5348594, "_step": 176}
{"Episode reward": -95.30722977507259, "Episode length": 999, "Policy Loss": 0.011175579391419888, "Value Loss": 0.048022523522377014, "_runtime": 10603.290962934494, "_timestamp": 1585580519.1355963, "_step": 177}
{"Episode reward": -98.89805617940816, "Episode length": 999, "Policy Loss": 0.019370436668395996, "Value Loss": 0.04842420667409897, "_runtime": 10604.888953208923, "_timestamp": 1585580520.7335865, "_step": 178}
{"Episode reward": -99.01597017519947, "Episode length": 999, "Policy Loss": 0.03433825075626373, "Value Loss": 0.047494612634181976, "_runtime": 10606.482558250427, "_timestamp": 1585580522.3271916, "_step": 179}
{"Episode reward": -99.5865586819707, "Episode length": 999, "Policy Loss": 0.03468514606356621, "Value Loss": 0.04674680158495903, "_runtime": 10608.110152482986, "_timestamp": 1585580523.9547858, "_step": 180}
{"Episode reward": -99.38850320604787, "Episode length": 999, "Policy Loss": 0.04639028385281563, "Value Loss": 0.0456981435418129, "_runtime": 10609.707540273666, "_timestamp": 1585580525.5521736, "_step": 181}
{"Episode reward": -98.41944418682033, "Episode length": 999, "Policy Loss": 0.052062004804611206, "Value Loss": 0.04437943547964096, "_runtime": 10611.289630174637, "_timestamp": 1585580527.1342635, "_step": 182}
{"Episode reward": -98.39860486072895, "Episode length": 999, "Policy Loss": 0.049201760441064835, "Value Loss": 0.043411530554294586, "_runtime": 10612.889501333237, "_timestamp": 1585580528.7341347, "_step": 183}
{"Episode reward": -99.5223573472465, "Episode length": 999, "Policy Loss": 0.03609224036335945, "Value Loss": 0.04289577156305313, "_runtime": 10614.489475727081, "_timestamp": 1585580530.334109, "_step": 184}
{"Episode reward": -98.9122410342293, "Episode length": 999, "Policy Loss": 0.04035761579871178, "Value Loss": 0.041738614439964294, "_runtime": 10616.0775744915, "_timestamp": 1585580531.9222078, "_step": 185}
{"Episode reward": -98.44652080931255, "Episode length": 999, "Policy Loss": 0.041831593960523605, "Value Loss": 0.040656015276908875, "_runtime": 10617.675788402557, "_timestamp": 1585580533.5204217, "_step": 186}
{"Episode reward": -99.5001322704975, "Episode length": 999, "Policy Loss": 0.0350026898086071, "Value Loss": 0.04012708365917206, "_runtime": 10619.275444746017, "_timestamp": 1585580535.120078, "_step": 187}
{"Episode reward": -97.93690905792234, "Episode length": 999, "Policy Loss": 0.03812029957771301, "Value Loss": 0.03868403658270836, "_runtime": 10620.862596273422, "_timestamp": 1585580536.7072296, "_step": 188}
{"Episode reward": -98.39288692915478, "Episode length": 999, "Policy Loss": 0.029227709397673607, "Value Loss": 0.037958357483148575, "_runtime": 10622.458909749985, "_timestamp": 1585580538.303543, "_step": 189}
{"Episode reward": -98.31320502988392, "Episode length": 999, "Policy Loss": 0.0243056733161211, "Value Loss": 0.03707936406135559, "_runtime": 10624.046637773514, "_timestamp": 1585580539.891271, "_step": 190}
{"Episode reward": -99.218105412703, "Episode length": 999, "Policy Loss": 0.028248963877558708, "Value Loss": 0.036530155688524246, "_runtime": 10625.631641626358, "_timestamp": 1585580541.476275, "_step": 191}
{"Episode reward": -99.34027771126338, "Episode length": 999, "Policy Loss": 0.028093578293919563, "Value Loss": 0.035733841359615326, "_runtime": 10627.234406232834, "_timestamp": 1585580543.0790396, "_step": 192}
{"Episode reward": -99.16725600591849, "Episode length": 999, "Policy Loss": 0.022762620821595192, "Value Loss": 0.03484797105193138, "_runtime": 10628.836520433426, "_timestamp": 1585580544.6811538, "_step": 193}
{"Episode reward": -98.80928004942095, "Episode length": 999, "Policy Loss": 0.032362014055252075, "Value Loss": 0.03391451761126518, "_runtime": 10630.425253629684, "_timestamp": 1585580546.269887, "_step": 194}
{"Episode reward": -97.35306428033938, "Episode length": 999, "Policy Loss": 0.026733551174402237, "Value Loss": 0.0326724536716938, "_runtime": 10632.053316831589, "_timestamp": 1585580547.8979502, "_step": 195}
{"Episode reward": -98.1435133962619, "Episode length": 999, "Policy Loss": 0.032964207231998444, "Value Loss": 0.03212932124733925, "_runtime": 10633.64558172226, "_timestamp": 1585580549.490215, "_step": 196}
{"Episode reward": -99.32007042542654, "Episode length": 999, "Policy Loss": 0.021476682275533676, "Value Loss": 0.0317322202026844, "_runtime": 10635.231230258942, "_timestamp": 1585580551.0758636, "_step": 197}
{"Episode reward": -97.67387717059758, "Episode length": 999, "Policy Loss": 0.026033561676740646, "Value Loss": 0.030475327745079994, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617, -16.060606002807617]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 3.0, 2.0], "bins": [-62.43018341064453, -61.1884651184082, -59.946746826171875, -58.70503234863281, -57.463314056396484, -56.221595764160156, -54.97987747192383, -53.7381591796875, -52.49644470214844, -51.25472640991211, -50.01300811767578, -48.77128982543945, -47.529571533203125, -46.28785705566406, -45.04613494873047, -43.804420471191406, -42.56270217895508, -41.32098388671875, -40.07926940917969, -38.837547302246094, -37.59583282470703, -36.3541145324707, -35.112396240234375, -33.87068176269531, -32.62895965576172, -31.387243270874023, -30.145526885986328, -28.90380859375, -27.662090301513672, -26.420372009277344, -25.17865753173828, -23.936939239501953, -22.695220947265625, -21.453502655029297, -20.21178436279297, -18.970069885253906, -17.728351593017578, -16.48663330078125, -15.244915008544922, -14.003196716308594, -12.761482238769531, -11.519763946533203, -10.278045654296875, -9.036327362060547, -7.794609069824219, -6.552890777587891, -5.311176300048828, -4.0694580078125, -2.827739715576172, -1.5860214233398438, -0.3443031311035156, 0.8974113464355469, 2.139129638671875, 3.3808517456054688, 4.622566223144531, 5.864280700683594, 7.1060028076171875, 8.34771728515625, 9.589439392089844, 10.831153869628906, 12.072868347167969, 13.314590454101562, 14.556304931640625, 15.798027038574219, 17.03974151611328]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.6923648715019226, -0.6405177116394043, -0.588670551776886, -0.5368233919143677, -0.484976202249527, -0.43312904238700867, -0.38128185272216797, -0.32943469285964966, -0.27758753299713135, -0.22574037313461304, -0.17389321327209473, -0.12204605340957642, -0.07019883394241333, -0.01835167407989502, 0.03349548578262329, 0.0853426456451416, 0.1371898055076599, 0.18903696537017822, 0.24088412523269653, 0.29273128509521484, 0.34457844495773315, 0.39642566442489624, 0.4482727646827698, 0.5001199841499329, 0.551967203617096, 0.6038143038749695, 0.6556615233421326, 0.7075086236000061, 0.7593558430671692, 0.8112029433250427, 0.8630501627922058, 0.9148972630500793, 0.9667444825172424, 1.0185916423797607, 1.0704388618469238, 1.122286081314087, 1.174133062362671, 1.225980281829834, 1.277827501296997, 1.329674482345581, 1.3815217018127441, 1.4333689212799072, 1.4852161407470703, 1.5370633602142334, 1.5889103412628174, 1.6407575607299805, 1.6926047801971436, 1.7444519996643066, 1.7962992191314697, 1.8481462001800537, 1.8999934196472168, 1.9518406391143799, 2.003687858581543, 2.055534839630127, 2.10738205909729, 2.159229278564453, 2.211076498031616, 2.2629237174987793, 2.3147706985473633, 2.3666179180145264, 2.4184651374816895, 2.4703123569488525, 2.5221593379974365, 2.5740065574645996, 2.6258537769317627]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 7.0, 9.0, 4.0, 8.0, 6.0, 9.0, 20.0, 17.0, 24.0, 42.0, 51.0, 53.0, 66.0, 41.0, 48.0, 27.0, 16.0, 6.0, 9.0, 8.0, 4.0, 5.0, 3.0, 1.0, 5.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-2.2217726707458496, -2.139192819595337, -2.056612968444824, -1.9740333557128906, -1.891453504562378, -1.8088736534118652, -1.726293921470642, -1.643714189529419, -1.5611343383789062, -1.4785544872283936, -1.3959747552871704, -1.3133950233459473, -1.2308151721954346, -1.1482353210449219, -1.0656555891036987, -0.9830758571624756, -0.9004960060119629, -0.8179161548614502, -0.735336422920227, -0.6527566909790039, -0.5701768398284912, -0.4875969886779785, -0.40501725673675537, -0.3224375247955322, -0.23985767364501953, -0.15727782249450684, -0.07469797134399414, 0.007881641387939453, 0.09046149253845215, 0.17304134368896484, 0.25562095642089844, 0.33820080757141113, 0.42078065872192383, 0.5033605098724365, 0.5859403610229492, 0.6685199737548828, 0.7510998249053955, 0.8336796760559082, 0.9162592887878418, 0.9988391399383545, 1.0814189910888672, 1.1639988422393799, 1.2465786933898926, 1.3291583061218262, 1.4117381572723389, 1.4943180084228516, 1.5768976211547852, 1.6594774723052979, 1.7420573234558105, 1.8246369361877441, 1.907217025756836, 1.9897966384887695, 2.0723767280578613, 2.154956340789795, 2.2375359535217285, 2.3201160430908203, 2.402695655822754, 2.4852752685546875, 2.5678553581237793, 2.650434970855713, 2.7330145835876465, 2.8155946731567383, 2.898174285888672, 2.9807543754577637, 3.0633339881896973]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.500648021697998, -1.4018017053604126, -1.3029553890228271, -1.2041091918945312, -1.1052627563476562, -1.0064165592193604, -0.9075702428817749, -0.8087239265441895, -0.709877610206604, -0.6110312938690186, -0.5121849775314331, -0.41333866119384766, -0.31449246406555176, -0.2156461477279663, -0.11679983139038086, -0.01795351505279541, 0.08089280128479004, 0.1797391176223755, 0.27858543395996094, 0.3774317502975464, 0.47627806663513184, 0.5751242637634277, 0.6739706993103027, 0.7728168964385986, 0.8716630935668945, 0.9705095291137695, 1.0693557262420654, 1.1682021617889404, 1.2670483589172363, 1.3658947944641113, 1.4647409915924072, 1.5635874271392822, 1.6624336242675781, 1.761279821395874, 1.860126256942749, 1.958972454071045, 2.05781888961792, 2.156665086746216, 2.255511522293091, 2.3543577194213867, 2.4532041549682617, 2.5520501136779785, 2.6508965492248535, 2.7497429847717285, 2.8485894203186035, 2.9474353790283203, 3.0462818145751953, 3.1451282501220703, 3.243974208831787, 3.342820644378662, 3.441667079925537, 3.540513515472412, 3.639359474182129, 3.738205909729004, 3.837052345275879, 3.935898780822754, 4.034744739532471, 4.133591175079346, 4.232437610626221, 4.3312835693359375, 4.4301300048828125, 4.5289764404296875, 4.6278228759765625, 4.726668834686279, 4.825515270233154]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0], "bins": [-4.817332744598389, -4.7159953117370605, -4.614657402038574, -4.513319969177246, -4.411982536315918, -4.31064510345459, -4.2093071937561035, -4.107969760894775, -4.006632328033447, -3.90529465675354, -3.803956985473633, -3.7026195526123047, -3.6012818813323975, -3.4999442100524902, -3.398606777191162, -3.297269105911255, -3.1959314346313477, -3.0945940017700195, -2.9932565689086914, -2.891918659210205, -2.790581226348877, -2.689243793487549, -2.5879061222076416, -2.4865684509277344, -2.3852310180664062, -2.283893346786499, -2.182555913925171, -2.0812182426452637, -1.9798805713653564, -1.8785431385040283, -1.777205467224121, -1.675868034362793, -1.5745303630828857, -1.4731926918029785, -1.3718552589416504, -1.2705175876617432, -1.169180154800415, -1.0678424835205078, -0.9665048122406006, -0.8651673793792725, -0.7638297080993652, -0.6624922752380371, -0.561154842376709, -0.45981693267822266, -0.35847949981689453, -0.2571420669555664, -0.15580415725708008, -0.05446672439575195, 0.04687070846557617, 0.1482086181640625, 0.24954605102539062, 0.35088348388671875, 0.4522209167480469, 0.5535588264465332, 0.6548962593078613, 0.7562336921691895, 0.8575716018676758, 0.9589090347290039, 1.060246467590332, 1.1615843772888184, 1.2629218101501465, 1.3642592430114746, 1.4655966758728027, 1.566934585571289, 1.6682720184326172]}, "_runtime": 10636.818256378174, "_timestamp": 1585580552.6628897, "_step": 198}
{"Episode reward": -97.26095605143952, "Episode length": 999, "Policy Loss": 0.012368693016469479, "Value Loss": 0.029619265347719193, "_runtime": 10638.405641078949, "_timestamp": 1585580554.2502744, "_step": 199}
{"Episode reward": -97.298560620355, "Episode length": 999, "Policy Loss": 0.021945804357528687, "Value Loss": 0.028915464878082275, "_runtime": 10639.992736577988, "_timestamp": 1585580555.83737, "_step": 200}
{"Episode reward": -99.0045903027313, "Episode length": 999, "Policy Loss": 0.01907825656235218, "Value Loss": 0.028709007427096367, "_runtime": 10641.587870121002, "_timestamp": 1585580557.4325035, "_step": 201}
{"Episode reward": -97.85930990692057, "Episode length": 999, "Policy Loss": 0.014379862695932388, "Value Loss": 0.027677202597260475, "_runtime": 10643.180198907852, "_timestamp": 1585580559.0248322, "_step": 202}
{"Episode reward": -96.78887414237423, "Episode length": 999, "Policy Loss": 0.01599576137959957, "Value Loss": 0.026716861873865128, "_runtime": 10644.767993450165, "_timestamp": 1585580560.6126268, "_step": 203}
{"Episode reward": -97.36241093830499, "Episode length": 999, "Policy Loss": 0.004516108892858028, "Value Loss": 0.026206430047750473, "_runtime": 10646.360116243362, "_timestamp": 1585580562.2047496, "_step": 204}
{"Episode reward": -96.74635685473181, "Episode length": 999, "Policy Loss": 0.01069282740354538, "Value Loss": 0.02539772540330887, "_runtime": 10647.95341038704, "_timestamp": 1585580563.7980437, "_step": 205}
{"Episode reward": -94.73445365697016, "Episode length": 999, "Policy Loss": 0.013088877312839031, "Value Loss": 0.02425258234143257, "_runtime": 10649.55469918251, "_timestamp": 1585580565.3993325, "_step": 206}
{"Episode reward": -95.8647960629298, "Episode length": 999, "Policy Loss": 0.010844966396689415, "Value Loss": 0.023938311263918877, "_runtime": 10651.14434170723, "_timestamp": 1585580566.988975, "_step": 207}
{"Episode reward": -95.24215399589674, "Episode length": 999, "Policy Loss": 0.011736302636563778, "Value Loss": 0.023164235055446625, "_runtime": 10652.74547791481, "_timestamp": 1585580568.5901113, "_step": 208}
{"Episode reward": -93.9761696646853, "Episode length": 999, "Policy Loss": 0.005676991771906614, "Value Loss": 0.022296534851193428, "_runtime": 10654.38183259964, "_timestamp": 1585580570.226466, "_step": 209}
{"Episode reward": -92.95578104854508, "Episode length": 999, "Policy Loss": 0.003606816055253148, "Value Loss": 0.02149411477148533, "_runtime": 10655.981085538864, "_timestamp": 1585580571.8257189, "_step": 210}
{"Episode reward": -96.95618771851173, "Episode length": 999, "Policy Loss": 0.0015214873710647225, "Value Loss": 0.021882129833102226, "_runtime": 10657.58048248291, "_timestamp": 1585580573.4251158, "_step": 211}
{"Episode reward": -92.3058357097187, "Episode length": 999, "Policy Loss": 0.0024041165597736835, "Value Loss": 0.02027423121035099, "_runtime": 10659.174456357956, "_timestamp": 1585580575.0190897, "_step": 212}
{"Episode reward": -92.06226008713926, "Episode length": 999, "Policy Loss": 0.006254274398088455, "Value Loss": 0.019711283966898918, "_runtime": 10660.762744903564, "_timestamp": 1585580576.6073782, "_step": 213}
{"Episode reward": -92.89463260544461, "Episode length": 999, "Policy Loss": 0.008935562334954739, "Value Loss": 0.01938832923769951, "_runtime": 10662.34941649437, "_timestamp": 1585580578.1940498, "_step": 214}
{"Episode reward": -90.08980669802325, "Episode length": 999, "Policy Loss": 0.0005093183717690408, "Value Loss": 0.018314747139811516, "_runtime": 10663.946962833405, "_timestamp": 1585580579.7915962, "_step": 215}
{"Episode reward": -91.58297311226474, "Episode length": 999, "Policy Loss": 0.0010050638811662793, "Value Loss": 0.018137501552700996, "_runtime": 10665.550000667572, "_timestamp": 1585580581.394634, "_step": 216}
{"Episode reward": -92.82637597948276, "Episode length": 999, "Policy Loss": 0.006887835916131735, "Value Loss": 0.01793128438293934, "_runtime": 10667.13896036148, "_timestamp": 1585580582.9835937, "_step": 217}
{"Episode reward": -95.04811089946905, "Episode length": 999, "Policy Loss": 0.007695149164646864, "Value Loss": 0.017925888299942017, "_runtime": 10668.732516765594, "_timestamp": 1585580584.57715, "_step": 218}
{"Episode reward": -97.96214586935827, "Episode length": 999, "Policy Loss": 0.01032639667391777, "Value Loss": 0.018067138269543648, "_runtime": 10670.330264568329, "_timestamp": 1585580586.174898, "_step": 219}
{"Episode reward": -93.98232457049929, "Episode length": 999, "Policy Loss": 0.007272123824805021, "Value Loss": 0.01682334765791893, "_runtime": 10671.925770998001, "_timestamp": 1585580587.7704043, "_step": 220}
{"Episode reward": -92.76684163238178, "Episode length": 999, "Policy Loss": 0.011007847264409065, "Value Loss": 0.016136126592755318, "_runtime": 10673.51156783104, "_timestamp": 1585580589.3562012, "_step": 221}
{"Episode reward": -97.25368457268367, "Episode length": 999, "Policy Loss": 0.018694784492254257, "Value Loss": 0.016587449237704277, "_runtime": 10675.101185321808, "_timestamp": 1585580590.9458187, "_step": 222}
{"Episode reward": -94.80699732952763, "Episode length": 999, "Policy Loss": 0.02020389772951603, "Value Loss": 0.01568879745900631, "_runtime": 10676.702305316925, "_timestamp": 1585580592.5469387, "_step": 223}
{"Episode reward": -97.48212750848543, "Episode length": 999, "Policy Loss": 0.021563280373811722, "Value Loss": 0.01581263728439808, "_runtime": 10678.334767818451, "_timestamp": 1585580594.1794012, "_step": 224}
{"Episode reward": -97.7982265216773, "Episode length": 999, "Policy Loss": 0.02497587539255619, "Value Loss": 0.015461311675608158, "_runtime": 10679.934343576431, "_timestamp": 1585580595.778977, "_step": 225}
{"Episode reward": -96.99700548107225, "Episode length": 999, "Policy Loss": 0.023962274193763733, "Value Loss": 0.014920592308044434, "_runtime": 10681.532942056656, "_timestamp": 1585580597.3775754, "_step": 226}
{"Episode reward": -99.23785278843454, "Episode length": 999, "Policy Loss": 0.02301003783941269, "Value Loss": 0.014960243366658688, "_runtime": 10683.128628253937, "_timestamp": 1585580598.9732616, "_step": 227}
{"Episode reward": -97.9803261874802, "Episode length": 999, "Policy Loss": 0.02953360415995121, "Value Loss": 0.014334340579807758, "_runtime": 10684.716639757156, "_timestamp": 1585580600.561273, "_step": 228}
{"Episode reward": -99.28894875166766, "Episode length": 999, "Policy Loss": 0.024679483845829964, "Value Loss": 0.014203691855072975, "_runtime": 10686.313867330551, "_timestamp": 1585580602.1585007, "_step": 229}
{"Episode reward": -99.2373308088259, "Episode length": 999, "Policy Loss": 0.026239443570375443, "Value Loss": 0.013823985122144222, "_runtime": 10687.90922498703, "_timestamp": 1585580603.7538583, "_step": 230}
{"Episode reward": -99.58059385496458, "Episode length": 999, "Policy Loss": 0.018447929993271828, "Value Loss": 0.013531090691685677, "_runtime": 10689.507338047028, "_timestamp": 1585580605.3519714, "_step": 231}
{"Episode reward": -99.09733277124649, "Episode length": 999, "Policy Loss": 0.02729206532239914, "Value Loss": 0.013084538280963898, "_runtime": 10691.096680641174, "_timestamp": 1585580606.941314, "_step": 232}
{"Episode reward": -97.46679086649472, "Episode length": 999, "Policy Loss": 0.02184482477605343, "Value Loss": 0.01245083101093769, "_runtime": 10692.682399749756, "_timestamp": 1585580608.527033, "_step": 233}
{"Episode reward": -97.81000236175798, "Episode length": 999, "Policy Loss": 0.020491791889071465, "Value Loss": 0.012175405398011208, "_runtime": 10694.283474445343, "_timestamp": 1585580610.1281078, "_step": 234}
{"Episode reward": -98.72909592886501, "Episode length": 999, "Policy Loss": 0.011974104680120945, "Value Loss": 0.01200592890381813, "_runtime": 10695.881572008133, "_timestamp": 1585580611.7262053, "_step": 235}
{"Episode reward": -98.04680508716196, "Episode length": 999, "Policy Loss": 0.010607333853840828, "Value Loss": 0.011571269482374191, "_runtime": 10697.466516494751, "_timestamp": 1585580613.3111498, "_step": 236}
{"Episode reward": -97.00379239725514, "Episode length": 999, "Policy Loss": 0.012647712603211403, "Value Loss": 0.011091249994933605, "_runtime": 10699.063696622849, "_timestamp": 1585580614.90833, "_step": 237}
{"Episode reward": -98.78843402058592, "Episode length": 999, "Policy Loss": 0.012063078582286835, "Value Loss": 0.011071506887674332, "_runtime": 10700.651880264282, "_timestamp": 1585580616.4965136, "_step": 238}
{"Episode reward": -98.30817465868246, "Episode length": 999, "Policy Loss": 0.005589763168245554, "Value Loss": 0.010698078200221062, "_runtime": 10702.275801420212, "_timestamp": 1585580618.1204348, "_step": 239}
{"Episode reward": -97.02051523784058, "Episode length": 999, "Policy Loss": 0.004818793851882219, "Value Loss": 0.01020784117281437, "_runtime": 10703.873592376709, "_timestamp": 1585580619.7182257, "_step": 240}
{"Episode reward": -95.85941783042813, "Episode length": 999, "Policy Loss": 0.009161262772977352, "Value Loss": 0.009778028354048729, "_runtime": 10705.459636449814, "_timestamp": 1585580621.3042698, "_step": 241}
{"Episode reward": -96.26257101852252, "Episode length": 999, "Policy Loss": 0.0070597645826637745, "Value Loss": 0.009547269903123379, "_runtime": 10707.052465438843, "_timestamp": 1585580622.8970988, "_step": 242}
{"Episode reward": -94.61630432798938, "Episode length": 999, "Policy Loss": 0.010625376366078854, "Value Loss": 0.009064084850251675, "_runtime": 10708.64245223999, "_timestamp": 1585580624.4870856, "_step": 243}
{"Episode reward": -91.81055912220032, "Episode length": 999, "Policy Loss": 0.0032275596167892218, "Value Loss": 0.008471664972603321, "_runtime": 10710.234785318375, "_timestamp": 1585580626.0794187, "_step": 244}
{"Episode reward": -93.23579197057688, "Episode length": 999, "Policy Loss": 0.0062689585611224174, "Value Loss": 0.008408057503402233, "_runtime": 10711.833627223969, "_timestamp": 1585580627.6782606, "_step": 245}
{"Episode reward": -93.12701889973016, "Episode length": 999, "Policy Loss": 0.0013517659390345216, "Value Loss": 0.00814775750041008, "_runtime": 10713.420063734055, "_timestamp": 1585580629.264697, "_step": 246}
{"Episode reward": -91.91507673569201, "Episode length": 999, "Policy Loss": -0.0007727001793682575, "Value Loss": 0.007769542746245861, "_runtime": 10715.017674446106, "_timestamp": 1585580630.8623078, "_step": 247}
{"Episode reward": -92.0457988858682, "Episode length": 999, "Policy Loss": -0.0018825150327757, "Value Loss": 0.007564831990748644, "_runtime": 10716.598316907883, "_timestamp": 1585580632.4429502, "_step": 248}
{"Episode reward": -90.78019651368405, "Episode length": 999, "Policy Loss": -0.006488322280347347, "Value Loss": 0.0071786679327487946, "_runtime": 10718.175915956497, "_timestamp": 1585580634.0205493, "_step": 249}
{"Episode reward": -89.14189963193807, "Episode length": 999, "Policy Loss": -0.0069462633691728115, "Value Loss": 0.00682904152199626, "_runtime": 10719.753704309464, "_timestamp": 1585580635.5983377, "_step": 250}
{"Episode reward": -88.59323341017576, "Episode length": 999, "Policy Loss": -0.011265890672802925, "Value Loss": 0.0065935938619077206, "_runtime": 10721.33768582344, "_timestamp": 1585580637.1823192, "_step": 251}
{"Episode reward": -88.69301169695986, "Episode length": 999, "Policy Loss": -0.008796154521405697, "Value Loss": 0.006403848994523287, "_runtime": 10722.913293361664, "_timestamp": 1585580638.7579267, "_step": 252}
{"Episode reward": -87.80260599766446, "Episode length": 999, "Policy Loss": -0.012778892181813717, "Value Loss": 0.006138887722045183, "_runtime": 10724.488452672958, "_timestamp": 1585580640.333086, "_step": 253}
{"Episode reward": -87.261988420193, "Episode length": 999, "Policy Loss": -0.006997869815677404, "Value Loss": 0.005874027498066425, "_runtime": 10726.10828781128, "_timestamp": 1585580641.9529212, "_step": 254}
{"Episode reward": -84.29288196888068, "Episode length": 999, "Policy Loss": -0.012794236652553082, "Value Loss": 0.005477159284055233, "_runtime": 10727.692766904831, "_timestamp": 1585580643.5374002, "_step": 255}
{"Episode reward": -85.16901834637305, "Episode length": 999, "Policy Loss": -0.011077451519668102, "Value Loss": 0.005397280678153038, "_runtime": 10729.277331113815, "_timestamp": 1585580645.1219645, "_step": 256}
{"Episode reward": -82.84415444962845, "Episode length": 999, "Policy Loss": -0.008984957821667194, "Value Loss": 0.005051169544458389, "_runtime": 10730.84953904152, "_timestamp": 1585580646.6941724, "_step": 257}
{"Episode reward": -80.50125030378715, "Episode length": 999, "Policy Loss": -0.014192969538271427, "Value Loss": 0.00469984719529748, "_runtime": 10732.435218334198, "_timestamp": 1585580648.2798517, "_step": 258}
{"Episode reward": -77.59367439252158, "Episode length": 999, "Policy Loss": -0.015934400260448456, "Value Loss": 0.00439434265717864, "_runtime": 10734.017638921738, "_timestamp": 1585580649.8622723, "_step": 259}
{"Episode reward": -79.83182736645256, "Episode length": 999, "Policy Loss": -0.016090288758277893, "Value Loss": 0.004450380802154541, "_runtime": 10735.601783752441, "_timestamp": 1585580651.446417, "_step": 260}
{"Episode reward": -75.14181499780489, "Episode length": 999, "Policy Loss": -0.017272653058171272, "Value Loss": 0.0039880829863250256, "_runtime": 10737.186750173569, "_timestamp": 1585580653.0313835, "_step": 261}
{"Episode reward": -81.62247982349767, "Episode length": 999, "Policy Loss": -0.01575339399278164, "Value Loss": 0.004248537588864565, "_runtime": 10738.773983478546, "_timestamp": 1585580654.6186168, "_step": 262}
{"Episode reward": -77.55940407546574, "Episode length": 999, "Policy Loss": -0.015395520254969597, "Value Loss": 0.003919323440641165, "_runtime": 10740.357932329178, "_timestamp": 1585580656.2025657, "_step": 263}
{"Episode reward": -76.25188260023991, "Episode length": 999, "Policy Loss": -0.01432516984641552, "Value Loss": 0.0037483256310224533, "_runtime": 10741.941998243332, "_timestamp": 1585580657.7866316, "_step": 264}
{"Episode reward": -73.93431290515309, "Episode length": 999, "Policy Loss": -0.013777941465377808, "Value Loss": 0.003547398839145899, "_runtime": 10743.526335716248, "_timestamp": 1585580659.370969, "_step": 265}
{"Episode reward": -79.55734683254599, "Episode length": 999, "Policy Loss": -0.012806735932826996, "Value Loss": 0.003771596122533083, "_runtime": 10745.110605239868, "_timestamp": 1585580660.9552386, "_step": 266}
{"Episode reward": -75.12934580927005, "Episode length": 999, "Policy Loss": -0.016638372093439102, "Value Loss": 0.003442894434556365, "_runtime": 10746.69041633606, "_timestamp": 1585580662.5350497, "_step": 267}
{"Episode reward": -74.83488529677757, "Episode length": 999, "Policy Loss": -0.015197535045444965, "Value Loss": 0.003282194258645177, "_runtime": 10748.268166542053, "_timestamp": 1585580664.1128, "_step": 268}
{"Episode reward": -74.18276890879062, "Episode length": 999, "Policy Loss": -0.015679020434617996, "Value Loss": 0.003191163996234536, "_runtime": 10749.879345417023, "_timestamp": 1585580665.7239788, "_step": 269}
{"Episode reward": -73.43970185625048, "Episode length": 999, "Policy Loss": -0.016513893380761147, "Value Loss": 0.0031548819970339537, "_runtime": 10751.466971874237, "_timestamp": 1585580667.3116052, "_step": 270}
{"Episode reward": -70.59293118269409, "Episode length": 999, "Policy Loss": -0.01608242839574814, "Value Loss": 0.0029053320176899433, "_runtime": 10753.043602466583, "_timestamp": 1585580668.8882358, "_step": 271}
{"Episode reward": -74.83820809659126, "Episode length": 999, "Policy Loss": -0.015188192948698997, "Value Loss": 0.003033861517906189, "_runtime": 10754.642105340958, "_timestamp": 1585580670.4867387, "_step": 272}
{"Episode reward": -72.37684612548588, "Episode length": 999, "Policy Loss": -0.013530926778912544, "Value Loss": 0.0028956225141882896, "_runtime": 10756.240346431732, "_timestamp": 1585580672.0849798, "_step": 273}
{"Episode reward": -72.00398730629487, "Episode length": 999, "Policy Loss": -0.016652612015604973, "Value Loss": 0.002857239916920662, "_runtime": 10757.838944911957, "_timestamp": 1585580673.6835783, "_step": 274}
{"Episode reward": -71.59618895502851, "Episode length": 999, "Policy Loss": -0.014368310570716858, "Value Loss": 0.0028111750725656748, "_runtime": 10759.434298276901, "_timestamp": 1585580675.2789316, "_step": 275}
{"Episode reward": -72.03310166485424, "Episode length": 999, "Policy Loss": -0.014558865688741207, "Value Loss": 0.0027330657467246056, "_runtime": 10761.028983592987, "_timestamp": 1585580676.873617, "_step": 276}
{"Episode reward": -72.86022245630691, "Episode length": 999, "Policy Loss": -0.014933306723833084, "Value Loss": 0.002662180457264185, "_runtime": 10762.626439094543, "_timestamp": 1585580678.4710724, "_step": 277}
{"Episode reward": -75.71680958226386, "Episode length": 999, "Policy Loss": -0.012289411388337612, "Value Loss": 0.002720861928537488, "_runtime": 10764.211587667465, "_timestamp": 1585580680.056221, "_step": 278}
{"Episode reward": -72.04272542162981, "Episode length": 999, "Policy Loss": -0.013125366531312466, "Value Loss": 0.002578929765149951, "_runtime": 10765.80982041359, "_timestamp": 1585580681.6544538, "_step": 279}
{"Episode reward": -73.09214343032599, "Episode length": 999, "Policy Loss": -0.014919896610081196, "Value Loss": 0.0025279135443270206, "_runtime": 10767.395899057388, "_timestamp": 1585580683.2405324, "_step": 280}
{"Episode reward": -72.829306190569, "Episode length": 999, "Policy Loss": -0.015924876555800438, "Value Loss": 0.0024969344958662987, "_runtime": 10768.992389202118, "_timestamp": 1585580684.8370225, "_step": 281}
{"Episode reward": -73.09216385912168, "Episode length": 999, "Policy Loss": -0.0101223299279809, "Value Loss": 0.0024728032294660807, "_runtime": 10770.579824209213, "_timestamp": 1585580686.4244576, "_step": 282}
{"Episode reward": -71.85644880853731, "Episode length": 999, "Policy Loss": -0.015363641083240509, "Value Loss": 0.002375597134232521, "_runtime": 10772.21277499199, "_timestamp": 1585580688.0574083, "_step": 283}
{"Episode reward": -71.96753310893271, "Episode length": 999, "Policy Loss": -0.0133726317435503, "Value Loss": 0.0023474774789065123, "_runtime": 10773.809689760208, "_timestamp": 1585580689.654323, "_step": 284}
{"Episode reward": -76.90187443922278, "Episode length": 999, "Policy Loss": -0.011048311367630959, "Value Loss": 0.002455504611134529, "_runtime": 10775.397258996964, "_timestamp": 1585580691.2418923, "_step": 285}
{"Episode reward": -73.87019671678335, "Episode length": 999, "Policy Loss": -0.010343734174966812, "Value Loss": 0.002306519076228142, "_runtime": 10776.986343860626, "_timestamp": 1585580692.8309772, "_step": 286}
{"Episode reward": -73.37209675231612, "Episode length": 999, "Policy Loss": -0.014367024414241314, "Value Loss": 0.002342063235118985, "_runtime": 10778.583914279938, "_timestamp": 1585580694.4285476, "_step": 287}
{"Episode reward": -74.73189269950672, "Episode length": 999, "Policy Loss": -0.009196325205266476, "Value Loss": 0.0022580705117434263, "_runtime": 10780.180148601532, "_timestamp": 1585580696.024782, "_step": 288}
{"Episode reward": -74.05928410035796, "Episode length": 999, "Policy Loss": -0.009658480994403362, "Value Loss": 0.002227732678875327, "_runtime": 10781.779110193253, "_timestamp": 1585580697.6237435, "_step": 289}
{"Episode reward": -74.43791724605951, "Episode length": 999, "Policy Loss": -0.012457207776606083, "Value Loss": 0.0022373271640390158, "_runtime": 10783.365257263184, "_timestamp": 1585580699.2098906, "_step": 290}
{"Episode reward": -76.25201667909825, "Episode length": 999, "Policy Loss": -0.008117149583995342, "Value Loss": 0.002225321950390935, "_runtime": 10784.96761584282, "_timestamp": 1585580700.8122492, "_step": 291}
{"Episode reward": -76.13846084989265, "Episode length": 999, "Policy Loss": -0.010957051068544388, "Value Loss": 0.0021724102552980185, "_runtime": 10786.567775011063, "_timestamp": 1585580702.4124084, "_step": 292}
{"Episode reward": -73.57826763284453, "Episode length": 999, "Policy Loss": -0.009624646045267582, "Value Loss": 0.002072956645861268, "_runtime": 10788.1646630764, "_timestamp": 1585580704.0092964, "_step": 293}
{"Episode reward": -75.99947229430677, "Episode length": 999, "Policy Loss": -0.010493394918739796, "Value Loss": 0.0020568568725138903, "_runtime": 10789.764400482178, "_timestamp": 1585580705.6090338, "_step": 294}
{"Episode reward": -76.10281243077966, "Episode length": 999, "Policy Loss": -0.012754415161907673, "Value Loss": 0.002096381736919284, "_runtime": 10791.3621301651, "_timestamp": 1585580707.2067635, "_step": 295}
{"Episode reward": -77.09887947392127, "Episode length": 999, "Policy Loss": -0.010343017056584358, "Value Loss": 0.0020420190412551165, "_runtime": 10792.94732260704, "_timestamp": 1585580708.791956, "_step": 296}
{"Episode reward": -76.6154195528919, "Episode length": 999, "Policy Loss": -0.008865035139024258, "Value Loss": 0.0020300238393247128, "_runtime": 10794.54998922348, "_timestamp": 1585580710.3946226, "_step": 297}
{"Episode reward": -75.5890931111893, "Episode length": 999, "Policy Loss": -0.009946671314537525, "Value Loss": 0.002020464511588216, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895, 4.0510334968566895]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.491135358810425, -3.2240560054779053, -2.9569766521453857, -2.689897060394287, -2.4228177070617676, -2.155738353729248, -1.8886590003967285, -1.621579647064209, -1.3545002937316895, -1.08742094039917, -0.8203415870666504, -0.5532622337341309, -0.2861826419830322, -0.019103288650512695, 0.24797606468200684, 0.5150554180145264, 0.7821347713470459, 1.0492141246795654, 1.316293478012085, 1.5833728313446045, 1.850452184677124, 2.1175315380096436, 2.384610891342163, 2.6516902446746826, 2.9187700748443604, 3.18584942817688, 3.4529287815093994, 3.720008134841919, 3.9870874881744385, 4.254166603088379, 4.521245956420898, 4.788325309753418, 5.0554046630859375, 5.322484016418457, 5.589563369750977, 5.856642723083496, 6.123722076416016, 6.390801429748535, 6.657880783081055, 6.924960136413574, 7.192039489746094, 7.459118843078613, 7.726198196411133, 7.993277549743652, 8.260356903076172, 8.527436256408691, 8.794515609741211, 9.06159496307373, 9.328675270080566, 9.595754623413086, 9.862833976745605, 10.129913330078125, 10.396992683410645, 10.664072036743164, 10.931151390075684, 11.198230743408203, 11.465310096740723, 11.732389450073242, 11.999468803405762, 12.266548156738281, 12.5336275100708, 12.800705909729004, 13.06778621673584, 13.334864616394043, 13.601944923400879]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.7215267419815063, -0.7031508684158325, -0.6847749948501587, -0.6663991808891296, -0.6480233073234558, -0.629647433757782, -0.6112715601921082, -0.5928956866264343, -0.5745198726654053, -0.5561439990997314, -0.5377681255340576, -0.5193922519683838, -0.50101637840271, -0.4826405346393585, -0.4642646610736847, -0.44588881731033325, -0.4275129437446594, -0.4091370701789856, -0.39076122641563416, -0.3723853528499603, -0.3540095090866089, -0.33563363552093506, -0.31725776195526123, -0.2988819181919098, -0.28050604462623596, -0.26213017106056213, -0.2437543272972107, -0.22537845373153687, -0.20700258016586304, -0.1886267066001892, -0.17025089263916016, -0.15187501907348633, -0.1334991455078125, -0.11512327194213867, -0.09674739837646484, -0.07837158441543579, -0.05999571084976196, -0.041619837284088135, -0.023243963718414307, -0.0048680901527404785, 0.013507723808288574, 0.0318835973739624, 0.05025947093963623, 0.06863534450531006, 0.08701121807098389, 0.10538709163665771, 0.12376290559768677, 0.1421387791633606, 0.16051465272903442, 0.17889052629470825, 0.19726639986038208, 0.21564221382141113, 0.23401808738708496, 0.2523939609527588, 0.2707698345184326, 0.28914570808410645, 0.3075215816497803, 0.3258974552154541, 0.34427332878112793, 0.3626490831375122, 0.38102495670318604, 0.39940083026885986, 0.4177767038345337, 0.4361525774002075, 0.45452845096588135]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 8.0, 6.0, 4.0, 7.0, 11.0, 9.0, 13.0, 9.0, 16.0, 20.0, 31.0, 37.0, 41.0, 52.0, 39.0, 35.0, 28.0, 13.0, 15.0, 17.0, 8.0, 8.0, 10.0, 10.0, 9.0, 6.0, 4.0, 3.0, 6.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4886797368526459, -0.4745064079761505, -0.46033307909965515, -0.4461597204208374, -0.43198639154434204, -0.4178130626678467, -0.4036397337913513, -0.38946640491485596, -0.3752930760383606, -0.36111974716186523, -0.3469463884830475, -0.3327730596065521, -0.31859973073005676, -0.304426372051239, -0.29025304317474365, -0.2760797142982483, -0.26190638542175293, -0.24773305654525757, -0.2335597276687622, -0.21938636898994446, -0.2052130401134491, -0.19103971123695374, -0.17686638236045837, -0.162693053483963, -0.14851972460746765, -0.1343463659286499, -0.12017303705215454, -0.10599970817565918, -0.09182637929916382, -0.07765305042266846, -0.06347969174385071, -0.04930636286735535, -0.035133033990859985, -0.020959705114364624, -0.006786376237869263, 0.007386982440948486, 0.02156028151512146, 0.03573361039161682, 0.04990699887275696, 0.06408032774925232, 0.07825365662574768, 0.09242698550224304, 0.1066003143787384, 0.12077364325523376, 0.13494697213172913, 0.1491203010082245, 0.16329362988471985, 0.1774669587612152, 0.19164028763771057, 0.2058136761188507, 0.21998700499534607, 0.23416033387184143, 0.2483336627483368, 0.26250699162483215, 0.2766803205013275, 0.2908536493778229, 0.30502697825431824, 0.3192003071308136, 0.33337363600730896, 0.3475470244884491, 0.36172035336494446, 0.3758936822414398, 0.3900670111179352, 0.40424033999443054, 0.4184136688709259]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7768301367759705, -0.7501640319824219, -0.7234979271888733, -0.6968318223953247, -0.6701657176017761, -0.6434996128082275, -0.616833508014679, -0.5901674032211304, -0.5635012984275818, -0.5368351936340332, -0.5101690292358398, -0.48350295424461365, -0.45683684945106506, -0.4301707446575165, -0.4035046398639679, -0.3768385350704193, -0.3501724302768707, -0.32350632548332214, -0.29684022068977356, -0.2701740860939026, -0.243507981300354, -0.21684187650680542, -0.19017577171325684, -0.16350966691970825, -0.13684356212615967, -0.11017745733261108, -0.0835113525390625, -0.056845247745513916, -0.030179142951965332, -0.003513038158416748, 0.023153066635131836, 0.04981917142868042, 0.076485276222229, 0.10315138101577759, 0.12981748580932617, 0.15648359060287476, 0.18314969539642334, 0.20981580018997192, 0.23648196458816528, 0.2631480097770691, 0.28981417417526245, 0.31648021936416626, 0.3431463837623596, 0.3698124289512634, 0.3964785933494568, 0.4231446385383606, 0.44981080293655396, 0.47647684812545776, 0.5031430125236511, 0.5298090577125549, 0.5564752221107483, 0.5831412672996521, 0.6098074316978455, 0.6364734768867493, 0.6631396412849426, 0.6898056864738464, 0.7164718508720398, 0.7431378960609436, 0.769804060459137, 0.7964701056480408, 0.8231362700462341, 0.8498023152351379, 0.8764684796333313, 0.9031345248222351, 0.9298006892204285]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 5.0, 5.0, 11.0, 2.0, 3.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9482375383377075, -0.9154584407806396, -0.882679283618927, -0.8499001264572144, -0.8171210289001465, -0.7843419313430786, -0.751562774181366, -0.7187836170196533, -0.6860045194625854, -0.6532254219055176, -0.6204462647438049, -0.5876671075820923, -0.5548880100250244, -0.5221089124679565, -0.4893297553062439, -0.45655062794685364, -0.4237715005874634, -0.3909924030303955, -0.35821324586868286, -0.3254340887069702, -0.29265499114990234, -0.2598758935928345, -0.22709673643112183, -0.19431757926940918, -0.1615384817123413, -0.12875938415527344, -0.09598022699356079, -0.06320106983184814, -0.030421972274780273, 0.0023571252822875977, 0.035136282444000244, 0.06791543960571289, 0.10069453716278076, 0.13347363471984863, 0.1662527322769165, 0.19903194904327393, 0.2318110466003418, 0.26459014415740967, 0.2973693609237671, 0.33014845848083496, 0.36292755603790283, 0.3957066535949707, 0.4284857511520386, 0.461264967918396, 0.49404406547546387, 0.5268231630325317, 0.5596023797988892, 0.592381477355957, 0.6251605749130249, 0.6579396724700928, 0.6907187700271606, 0.7234979867935181, 0.7562770843505859, 0.7890561819076538, 0.8218353986740112, 0.8546144962310791, 0.887393593788147, 0.9201726913452148, 0.9529517889022827, 0.9857310056686401, 1.018510103225708, 1.0512892007827759, 1.0840684175491333, 1.1168473958969116, 1.149626612663269]}, "_runtime": 10796.177497386932, "_timestamp": 1585580712.0221307, "_step": 298}
{"Episode reward": -76.07078968893904, "Episode length": 999, "Policy Loss": -0.011770962737500668, "Value Loss": 0.0019749586936086416, "_runtime": 10797.778325557709, "_timestamp": 1585580713.622959, "_step": 299}
{"Episode reward": -75.57124119672034, "Episode length": 999, "Policy Loss": -0.009515880607068539, "Value Loss": 0.0019198482623323798, "_runtime": 10799.3783557415, "_timestamp": 1585580715.222989, "_step": 300}
{"Episode reward": -75.89044136867165, "Episode length": 999, "Policy Loss": -0.009044289588928223, "Value Loss": 0.00189924705773592, "_runtime": 10800.977191209793, "_timestamp": 1585580716.8218246, "_step": 301}
{"Episode reward": -80.26752492894576, "Episode length": 999, "Policy Loss": -0.007087063509970903, "Value Loss": 0.0019470322877168655, "_runtime": 10802.57572388649, "_timestamp": 1585580718.4203572, "_step": 302}
{"Episode reward": -84.87030339727025, "Episode length": 999, "Policy Loss": -0.006200919859111309, "Value Loss": 0.001906363177113235, "_runtime": 10804.161151647568, "_timestamp": 1585580720.005785, "_step": 303}
{"Episode reward": -77.0260753446317, "Episode length": 999, "Policy Loss": -0.006772162858396769, "Value Loss": 0.0018362677656114101, "_runtime": 10805.75237607956, "_timestamp": 1585580721.5970094, "_step": 304}
{"Episode reward": -76.01695404016007, "Episode length": 999, "Policy Loss": -0.01024105865508318, "Value Loss": 0.0018500477308407426, "_runtime": 10807.33693265915, "_timestamp": 1585580723.181566, "_step": 305}
{"Episode reward": -75.39936177744761, "Episode length": 999, "Policy Loss": -0.008941427804529667, "Value Loss": 0.00173507584258914, "_runtime": 10808.922904729843, "_timestamp": 1585580724.767538, "_step": 306}
{"Episode reward": -74.10475385460207, "Episode length": 999, "Policy Loss": -0.008815644308924675, "Value Loss": 0.0017240990418940783, "_runtime": 10810.50895023346, "_timestamp": 1585580726.3535836, "_step": 307}
{"Episode reward": -76.00783487873235, "Episode length": 999, "Policy Loss": -0.008081946521997452, "Value Loss": 0.0017640270525589585, "_runtime": 10812.09153676033, "_timestamp": 1585580727.93617, "_step": 308}
{"Episode reward": -78.45091278592857, "Episode length": 999, "Policy Loss": -0.00788133405148983, "Value Loss": 0.00164855329785496, "_runtime": 10813.678269386292, "_timestamp": 1585580729.5229027, "_step": 309}
{"Episode reward": -75.16871538849308, "Episode length": 999, "Policy Loss": -0.009411578997969627, "Value Loss": 0.001705516711808741, "_runtime": 10815.263659715652, "_timestamp": 1585580731.108293, "_step": 310}
{"Episode reward": -75.40682890956812, "Episode length": 999, "Policy Loss": -0.009257861413061619, "Value Loss": 0.0016382038593292236, "_runtime": 10816.85187125206, "_timestamp": 1585580732.6965046, "_step": 311}
{"Episode reward": -75.97206118832165, "Episode length": 999, "Policy Loss": -0.008398939855396748, "Value Loss": 0.0016498046461492777, "_runtime": 10818.440698385239, "_timestamp": 1585580734.2853317, "_step": 312}
{"Episode reward": -72.71654714924568, "Episode length": 999, "Policy Loss": -0.007634718436747789, "Value Loss": 0.0016550365835428238, "_runtime": 10820.065463066101, "_timestamp": 1585580735.9100964, "_step": 313}
{"Episode reward": -75.6185799227741, "Episode length": 999, "Policy Loss": -0.0078012533485889435, "Value Loss": 0.001613460946828127, "_runtime": 10821.640877723694, "_timestamp": 1585580737.485511, "_step": 314}
{"Episode reward": -73.39530498439076, "Episode length": 999, "Policy Loss": -0.007694811560213566, "Value Loss": 0.0015690196305513382, "_runtime": 10823.245108366013, "_timestamp": 1585580739.0897417, "_step": 315}
{"Episode reward": -76.28189663151107, "Episode length": 999, "Policy Loss": -0.007813605479896069, "Value Loss": 0.0016199853271245956, "_runtime": 10824.821239948273, "_timestamp": 1585580740.6658733, "_step": 316}
{"Episode reward": -76.25642627310746, "Episode length": 999, "Policy Loss": -0.005186568479984999, "Value Loss": 0.0015519550070166588, "_runtime": 10826.395639657974, "_timestamp": 1585580742.240273, "_step": 317}
{"Episode reward": -73.99227085355679, "Episode length": 999, "Policy Loss": -0.007694537285715342, "Value Loss": 0.001549869659356773, "_runtime": 10827.973247289658, "_timestamp": 1585580743.8178806, "_step": 318}
{"Episode reward": -76.95264810104898, "Episode length": 999, "Policy Loss": -0.005150874610990286, "Value Loss": 0.00148776697460562, "_runtime": 10829.562709331512, "_timestamp": 1585580745.4073427, "_step": 319}
{"Episode reward": -76.13017074245384, "Episode length": 999, "Policy Loss": -0.005696278065443039, "Value Loss": 0.0015084631741046906, "_runtime": 10831.147017478943, "_timestamp": 1585580746.9916508, "_step": 320}
{"Episode reward": -76.76583690344377, "Episode length": 999, "Policy Loss": -0.0037867948412895203, "Value Loss": 0.001504856045357883, "_runtime": 10832.735909223557, "_timestamp": 1585580748.5805426, "_step": 321}
{"Episode reward": -75.08798117650056, "Episode length": 999, "Policy Loss": -0.0065993377938866615, "Value Loss": 0.0014758865581825376, "_runtime": 10834.314081907272, "_timestamp": 1585580750.1587152, "_step": 322}
{"Episode reward": -76.18463145830628, "Episode length": 999, "Policy Loss": -0.005476066842675209, "Value Loss": 0.001432513352483511, "_runtime": 10835.900606155396, "_timestamp": 1585580751.7452395, "_step": 323}
{"Episode reward": -79.35443310269785, "Episode length": 999, "Policy Loss": -0.004768344108015299, "Value Loss": 0.0014194457326084375, "_runtime": 10837.490890741348, "_timestamp": 1585580753.335524, "_step": 324}
{"Episode reward": -78.75707722187406, "Episode length": 999, "Policy Loss": -0.005242471117526293, "Value Loss": 0.001396216219291091, "_runtime": 10839.078038215637, "_timestamp": 1585580754.9226716, "_step": 325}
{"Episode reward": -82.2331017778215, "Episode length": 999, "Policy Loss": -0.005136170890182257, "Value Loss": 0.0013396883150562644, "_runtime": 10840.665957212448, "_timestamp": 1585580756.5105906, "_step": 326}
{"Episode reward": -79.33897916218537, "Episode length": 999, "Policy Loss": -0.004224829375743866, "Value Loss": 0.0013689273037016392, "_runtime": 10842.253274917603, "_timestamp": 1585580758.0979083, "_step": 327}
{"Episode reward": -80.79014376357628, "Episode length": 999, "Policy Loss": -0.005633603315800428, "Value Loss": 0.00134191638790071, "_runtime": 10843.882777452469, "_timestamp": 1585580759.7274108, "_step": 328}
{"Episode reward": -77.99159796036551, "Episode length": 999, "Policy Loss": -0.0011718481546267867, "Value Loss": 0.0013161730021238327, "_runtime": 10845.472152233124, "_timestamp": 1585580761.3167856, "_step": 329}
{"Episode reward": -80.43506326137204, "Episode length": 999, "Policy Loss": -0.0040165213868021965, "Value Loss": 0.0013311236398294568, "_runtime": 10847.052917957306, "_timestamp": 1585580762.8975513, "_step": 330}
{"Episode reward": -83.95436179734016, "Episode length": 999, "Policy Loss": -0.005875162780284882, "Value Loss": 0.0012646698160097003, "_runtime": 10848.63172531128, "_timestamp": 1585580764.4763587, "_step": 331}
{"Episode reward": -84.89057910774753, "Episode length": 999, "Policy Loss": -0.003824588842689991, "Value Loss": 0.0012309051817283034, "_runtime": 10850.208826303482, "_timestamp": 1585580766.0534596, "_step": 332}
{"Episode reward": -83.66631462528463, "Episode length": 999, "Policy Loss": -0.005022530909627676, "Value Loss": 0.0012643764493986964, "_runtime": 10851.789935350418, "_timestamp": 1585580767.6345687, "_step": 333}
{"Episode reward": -80.07264529468083, "Episode length": 999, "Policy Loss": -0.002106851665303111, "Value Loss": 0.001318488153629005, "_runtime": 10853.35726761818, "_timestamp": 1585580769.201901, "_step": 334}
{"Episode reward": -79.82433238881339, "Episode length": 999, "Policy Loss": -0.003112285863608122, "Value Loss": 0.001266854233108461, "_runtime": 10854.924988269806, "_timestamp": 1585580770.7696216, "_step": 335}
{"Episode reward": -84.55861919600805, "Episode length": 999, "Policy Loss": -0.005556856747716665, "Value Loss": 0.0011570841306820512, "_runtime": 10856.502817630768, "_timestamp": 1585580772.347451, "_step": 336}
{"Episode reward": -84.56706028250301, "Episode length": 999, "Policy Loss": -0.005771799478679895, "Value Loss": 0.0011961375130340457, "_runtime": 10858.090176582336, "_timestamp": 1585580773.93481, "_step": 337}
{"Episode reward": -86.39262104458234, "Episode length": 999, "Policy Loss": -0.005238724406808615, "Value Loss": 0.0011272297706454992, "_runtime": 10859.676386356354, "_timestamp": 1585580775.5210197, "_step": 338}
{"Episode reward": -85.07294331964228, "Episode length": 999, "Policy Loss": -0.005249595735222101, "Value Loss": 0.0010871158447116613, "_runtime": 10861.257284879684, "_timestamp": 1585580777.1019182, "_step": 339}
{"Episode reward": -82.65448074870679, "Episode length": 999, "Policy Loss": -0.003707515075802803, "Value Loss": 0.0011710586259141564, "_runtime": 10862.83399772644, "_timestamp": 1585580778.678631, "_step": 340}
{"Episode reward": -85.82301709064824, "Episode length": 999, "Policy Loss": -0.004643819760531187, "Value Loss": 0.0011285021901130676, "_runtime": 10864.412008047104, "_timestamp": 1585580780.2566414, "_step": 341}
{"Episode reward": -82.2485558942423, "Episode length": 999, "Policy Loss": -0.0017189737409353256, "Value Loss": 0.0012135496363043785, "_runtime": 10866.028290748596, "_timestamp": 1585580781.872924, "_step": 342}
{"Episode reward": -83.29254416199264, "Episode length": 999, "Policy Loss": -0.004633451346307993, "Value Loss": 0.0011047401931136847, "_runtime": 10867.605588674545, "_timestamp": 1585580783.450222, "_step": 343}
{"Episode reward": -83.38555727005836, "Episode length": 999, "Policy Loss": -0.004137052223086357, "Value Loss": 0.0010996618075296283, "_runtime": 10869.184510707855, "_timestamp": 1585580785.029144, "_step": 344}
{"Episode reward": -86.41053195703503, "Episode length": 999, "Policy Loss": -0.004337811376899481, "Value Loss": 0.001008619088679552, "_runtime": 10870.762857198715, "_timestamp": 1585580786.6074905, "_step": 345}
{"Episode reward": -83.78795779563191, "Episode length": 999, "Policy Loss": -0.004821364302188158, "Value Loss": 0.001057382090948522, "_runtime": 10872.352293491364, "_timestamp": 1585580788.1969268, "_step": 346}
{"Episode reward": -86.61282390893238, "Episode length": 999, "Policy Loss": -0.0037198951467871666, "Value Loss": 0.0010278611443936825, "_runtime": 10873.94016122818, "_timestamp": 1585580789.7847946, "_step": 347}
{"Episode reward": -84.65511614162106, "Episode length": 999, "Policy Loss": -0.0045301890932023525, "Value Loss": 0.0010731236543506384, "_runtime": 10875.530040025711, "_timestamp": 1585580791.3746734, "_step": 348}
{"Episode reward": -87.53806431977999, "Episode length": 999, "Policy Loss": -0.0033579200971871614, "Value Loss": 0.0009684636606834829, "_runtime": 10877.128564119339, "_timestamp": 1585580792.9731975, "_step": 349}
{"Episode reward": -83.57342186552094, "Episode length": 999, "Policy Loss": -0.004941524937748909, "Value Loss": 0.0010925852693617344, "_runtime": 10878.713181257248, "_timestamp": 1585580794.5578146, "_step": 350}
{"Episode reward": -83.17826393956061, "Episode length": 999, "Policy Loss": -0.0030761598609387875, "Value Loss": 0.0010393892880529165, "_runtime": 10880.312405586243, "_timestamp": 1585580796.157039, "_step": 351}
{"Episode reward": -86.3714256123549, "Episode length": 999, "Policy Loss": -0.005107376724481583, "Value Loss": 0.0009336356888525188, "_runtime": 10881.912333488464, "_timestamp": 1585580797.7569668, "_step": 352}
{"Episode reward": -83.33443806727892, "Episode length": 999, "Policy Loss": -0.0020334888249635696, "Value Loss": 0.001032847329042852, "_runtime": 10883.510168790817, "_timestamp": 1585580799.3548021, "_step": 353}
{"Episode reward": -82.86930556968888, "Episode length": 999, "Policy Loss": -0.004175613168627024, "Value Loss": 0.0010008439421653748, "_runtime": 10885.110017061234, "_timestamp": 1585580800.9546504, "_step": 354}
{"Episode reward": -83.6491127857802, "Episode length": 999, "Policy Loss": -0.004569023381918669, "Value Loss": 0.0010020645568147302, "_runtime": 10886.69643497467, "_timestamp": 1585580802.5410683, "_step": 355}
{"Episode reward": -82.38024857063695, "Episode length": 999, "Policy Loss": -0.0031975232996046543, "Value Loss": 0.0009605129016563296, "_runtime": 10888.294862031937, "_timestamp": 1585580804.1394954, "_step": 356}
{"Episode reward": -81.34803700415779, "Episode length": 999, "Policy Loss": -0.004158246796578169, "Value Loss": 0.0009542776388116181, "_runtime": 10889.919525623322, "_timestamp": 1585580805.764159, "_step": 357}
{"Episode reward": -84.16640519498026, "Episode length": 999, "Policy Loss": -0.00199058442376554, "Value Loss": 0.0009215088794007897, "_runtime": 10891.517524719238, "_timestamp": 1585580807.362158, "_step": 358}
{"Episode reward": -84.6139271131277, "Episode length": 999, "Policy Loss": -0.0037521705962717533, "Value Loss": 0.0008371626026928425, "_runtime": 10893.114079236984, "_timestamp": 1585580808.9587126, "_step": 359}
{"Episode reward": -78.67058461063786, "Episode length": 999, "Policy Loss": -0.0019455939764156938, "Value Loss": 0.0010462446371093392, "_runtime": 10894.69982790947, "_timestamp": 1585580810.5444613, "_step": 360}
{"Episode reward": -84.67974835593006, "Episode length": 999, "Policy Loss": -0.0032321021426469088, "Value Loss": 0.0008425974519923329, "_runtime": 10896.268160104752, "_timestamp": 1585580812.1127934, "_step": 361}
{"Episode reward": -83.1795032060782, "Episode length": 999, "Policy Loss": -0.004014487843960524, "Value Loss": 0.000860205851495266, "_runtime": 10897.834164857864, "_timestamp": 1585580813.6787982, "_step": 362}
{"Episode reward": -83.654114846135, "Episode length": 999, "Policy Loss": -0.0035568522289395332, "Value Loss": 0.0008651830721646547, "_runtime": 10899.401306390762, "_timestamp": 1585580815.2459397, "_step": 363}
{"Episode reward": -80.23917512024485, "Episode length": 999, "Policy Loss": -0.0018898847047239542, "Value Loss": 0.001010611653327942, "_runtime": 10900.96762394905, "_timestamp": 1585580816.8122573, "_step": 364}
{"Episode reward": -79.57216324067282, "Episode length": 999, "Policy Loss": -0.000632404931820929, "Value Loss": 0.0009936562273651361, "_runtime": 10902.54469704628, "_timestamp": 1585580818.3893304, "_step": 365}
{"Episode reward": -81.68623718025148, "Episode length": 999, "Policy Loss": -0.002034967066720128, "Value Loss": 0.0009117593872360885, "_runtime": 10904.098621606827, "_timestamp": 1585580819.943255, "_step": 366}
{"Episode reward": -83.20310050898674, "Episode length": 999, "Policy Loss": -0.0030839629471302032, "Value Loss": 0.0008660570601932704, "_runtime": 10905.67393708229, "_timestamp": 1585580821.5185704, "_step": 367}
{"Episode reward": -79.40315656488168, "Episode length": 999, "Policy Loss": -0.002404943108558655, "Value Loss": 0.0009893799433484674, "_runtime": 10907.254071950912, "_timestamp": 1585580823.0987053, "_step": 368}
{"Episode reward": -82.95883893784729, "Episode length": 999, "Policy Loss": -0.0028743857983499765, "Value Loss": 0.0008464179700240493, "_runtime": 10908.829241037369, "_timestamp": 1585580824.6738744, "_step": 369}
{"Episode reward": -82.27029827282797, "Episode length": 999, "Policy Loss": -0.002096642507240176, "Value Loss": 0.0009182639769278467, "_runtime": 10910.4052901268, "_timestamp": 1585580826.2499235, "_step": 370}
{"Episode reward": -82.34171157262672, "Episode length": 999, "Policy Loss": -0.0029091869946569204, "Value Loss": 0.0008446274441666901, "_runtime": 10911.969597101212, "_timestamp": 1585580827.8142304, "_step": 371}
{"Episode reward": -77.41573409214102, "Episode length": 999, "Policy Loss": -5.9531677834456787e-05, "Value Loss": 0.0011015119962394238, "_runtime": 10913.579888105392, "_timestamp": 1585580829.4245214, "_step": 372}
{"Episode reward": -80.24444199439253, "Episode length": 999, "Policy Loss": -0.0019310404313728213, "Value Loss": 0.0010004532523453236, "_runtime": 10915.156522035599, "_timestamp": 1585580831.0011554, "_step": 373}
{"Episode reward": -80.07340721829105, "Episode length": 999, "Policy Loss": -0.0007253243238665164, "Value Loss": 0.0009444909519515932, "_runtime": 10916.732979774475, "_timestamp": 1585580832.577613, "_step": 374}
{"Episode reward": -79.87665348876963, "Episode length": 999, "Policy Loss": -0.0002257627493236214, "Value Loss": 0.0009635752066969872, "_runtime": 10918.309997797012, "_timestamp": 1585580834.1546311, "_step": 375}
{"Episode reward": -85.45324401331081, "Episode length": 999, "Policy Loss": -0.0026425509713590145, "Value Loss": 0.0007922370568849146, "_runtime": 10919.886260509491, "_timestamp": 1585580835.7308939, "_step": 376}
{"Episode reward": -84.14523788815204, "Episode length": 999, "Policy Loss": -0.004698514007031918, "Value Loss": 0.000857389357406646, "_runtime": 10921.452684879303, "_timestamp": 1585580837.2973182, "_step": 377}
{"Episode reward": -85.25669384478806, "Episode length": 999, "Policy Loss": -0.0037213782779872417, "Value Loss": 0.0008075517835095525, "_runtime": 10923.021341085434, "_timestamp": 1585580838.8659744, "_step": 378}
{"Episode reward": -82.56244024475251, "Episode length": 999, "Policy Loss": -0.002901218133047223, "Value Loss": 0.0008953390643000603, "_runtime": 10924.589001893997, "_timestamp": 1585580840.4336352, "_step": 379}
{"Episode reward": -84.50420776036381, "Episode length": 999, "Policy Loss": -0.0027823082637041807, "Value Loss": 0.0008238431764766574, "_runtime": 10926.168137311935, "_timestamp": 1585580842.0127707, "_step": 380}
{"Episode reward": -86.87144045035154, "Episode length": 999, "Policy Loss": -0.0021292923483997583, "Value Loss": 0.0006586913368664682, "_runtime": 10927.748593330383, "_timestamp": 1585580843.5932267, "_step": 381}
{"Episode reward": -87.54095576235409, "Episode length": 999, "Policy Loss": -0.003589414991438389, "Value Loss": 0.0006940761231817305, "_runtime": 10929.323944807053, "_timestamp": 1585580845.1685781, "_step": 382}
{"Episode reward": -83.82415937411085, "Episode length": 999, "Policy Loss": -0.004194875713437796, "Value Loss": 0.000833490863442421, "_runtime": 10930.9008538723, "_timestamp": 1585580846.7454872, "_step": 383}
{"Episode reward": -84.76033418414363, "Episode length": 999, "Policy Loss": -0.001618096954189241, "Value Loss": 0.0008249718230217695, "_runtime": 10932.47737455368, "_timestamp": 1585580848.322008, "_step": 384}
{"Episode reward": -87.18496871208228, "Episode length": 999, "Policy Loss": -0.0020382478833198547, "Value Loss": 0.0006993641145527363, "_runtime": 10934.045308589935, "_timestamp": 1585580849.889942, "_step": 385}
{"Episode reward": -87.81939649168102, "Episode length": 999, "Policy Loss": -0.0028329442720860243, "Value Loss": 0.0007200789405032992, "_runtime": 10935.619924068451, "_timestamp": 1585580851.4645574, "_step": 386}
{"Episode reward": -88.34097091967826, "Episode length": 999, "Policy Loss": -0.0026463977992534637, "Value Loss": 0.0006311986944638193, "_runtime": 10937.23542046547, "_timestamp": 1585580853.0800538, "_step": 387}
{"Episode reward": -89.29497065146579, "Episode length": 999, "Policy Loss": -0.0019943169318139553, "Value Loss": 0.0006157075404189527, "_runtime": 10938.810572385788, "_timestamp": 1585580854.6552057, "_step": 388}
{"Episode reward": -89.42670707868051, "Episode length": 999, "Policy Loss": -0.0018363796407356858, "Value Loss": 0.0006514881970360875, "_runtime": 10940.373146772385, "_timestamp": 1585580856.21778, "_step": 389}
{"Episode reward": -85.7000458165601, "Episode length": 999, "Policy Loss": -0.0024756938219070435, "Value Loss": 0.0007233015494421124, "_runtime": 10941.948678970337, "_timestamp": 1585580857.7933123, "_step": 390}
{"Episode reward": -89.27956038044294, "Episode length": 999, "Policy Loss": -0.002386275678873062, "Value Loss": 0.0006028791540302336, "_runtime": 10943.524522066116, "_timestamp": 1585580859.3691554, "_step": 391}
{"Episode reward": -87.84474301960275, "Episode length": 999, "Policy Loss": -0.0018015342066064477, "Value Loss": 0.0006434104288928211, "_runtime": 10945.095772266388, "_timestamp": 1585580860.9404056, "_step": 392}
{"Episode reward": -84.83222225129941, "Episode length": 999, "Policy Loss": -0.0033745798282325268, "Value Loss": 0.0007872261921875179, "_runtime": 10946.669689893723, "_timestamp": 1585580862.5143232, "_step": 393}
{"Episode reward": -87.4617953780372, "Episode length": 999, "Policy Loss": -0.0020540638361126184, "Value Loss": 0.0006076483987271786, "_runtime": 10948.23612523079, "_timestamp": 1585580864.0807586, "_step": 394}
{"Episode reward": -87.98866657363403, "Episode length": 999, "Policy Loss": -0.0018717637285590172, "Value Loss": 0.0005827888380736113, "_runtime": 10949.808951616287, "_timestamp": 1585580865.653585, "_step": 395}
{"Episode reward": -86.87826980418374, "Episode length": 999, "Policy Loss": -0.0002144907630281523, "Value Loss": 0.0006769411265850067, "_runtime": 10951.385195493698, "_timestamp": 1585580867.2298288, "_step": 396}
{"Episode reward": -86.84382318642979, "Episode length": 999, "Policy Loss": -0.0023470711894333363, "Value Loss": 0.0006836398970335722, "_runtime": 10952.96322274208, "_timestamp": 1585580868.807856, "_step": 397}
{"Episode reward": -89.56621757947609, "Episode length": 999, "Policy Loss": -0.0024217930622398853, "Value Loss": 0.0005688396631740034, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693, -0.9970147609710693]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.8940396308898926, -2.829648971557617, -2.7652580738067627, -2.700867176055908, -2.636476516723633, -2.5720858573913574, -2.507694959640503, -2.4433040618896484, -2.378913402557373, -2.3145227432250977, -2.250131845474243, -2.1857409477233887, -2.1213502883911133, -2.056959629058838, -1.9925687313079834, -1.9281779527664185, -1.8637871742248535, -1.7993963956832886, -1.7350056171417236, -1.6706148386001587, -1.6062240600585938, -1.5418332815170288, -1.4774425029754639, -1.413051724433899, -1.348660945892334, -1.284270167350769, -1.219879388809204, -1.1554886102676392, -1.0910978317260742, -1.0267070531845093, -0.9623162746429443, -0.8979254961013794, -0.8335347175598145, -0.7691440582275391, -0.7047531604766846, -0.6403622627258301, -0.5759716033935547, -0.5115809440612793, -0.4471900463104248, -0.3827991485595703, -0.3184084892272949, -0.25401782989501953, -0.18962693214416504, -0.12523603439331055, -0.060845375061035156, 0.0035452842712402344, 0.06793618202209473, 0.13232707977294922, 0.1967177391052246, 0.2611083984375, 0.3254992961883545, 0.389890193939209, 0.4542808532714844, 0.5186715126037598, 0.5830624103546143, 0.6474533081054688, 0.7118439674377441, 0.7762346267700195, 0.840625524520874, 0.9050164222717285, 0.9694070816040039, 1.0337977409362793, 1.0981886386871338, 1.1625795364379883, 1.2269701957702637]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4571690857410431, -0.44296374917030334, -0.4287584125995636, -0.41455307602882385, -0.4003477394580841, -0.38614240288734436, -0.371937096118927, -0.35773175954818726, -0.3435264229774475, -0.32932108640670776, -0.315115749835968, -0.30091041326522827, -0.2867050766944885, -0.2724997401237488, -0.25829440355300903, -0.2440890669822693, -0.22988373041152954, -0.2156783938407898, -0.20147305727005005, -0.1872677206993103, -0.17306238412857056, -0.1588570475578308, -0.14465171098709106, -0.13044637441635132, -0.11624106764793396, -0.10203573107719421, -0.08783039450645447, -0.07362505793571472, -0.059419721364974976, -0.04521438479423523, -0.031009048223495483, -0.016803711652755737, -0.002598375082015991, 0.011606961488723755, 0.0258122980594635, 0.04001763463020325, 0.05422297120094299, 0.06842830777168274, 0.08263364434242249, 0.09683898091316223, 0.11104431748390198, 0.12524965405464172, 0.13945499062538147, 0.15366032719612122, 0.16786566376686096, 0.1820710003376007, 0.19627633690834045, 0.2104816734790802, 0.22468695044517517, 0.23889228701591492, 0.25309762358665466, 0.2673029601573944, 0.28150829672813416, 0.2957136332988739, 0.30991896986961365, 0.3241243064403534, 0.33832964301109314, 0.3525349795818329, 0.36674031615257263, 0.3809456527233124, 0.3951509892940521, 0.40935632586479187, 0.4235616624355316, 0.43776699900627136, 0.4519723355770111]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 9.0, 9.0, 7.0, 8.0, 13.0, 10.0, 13.0, 27.0, 21.0, 20.0, 36.0, 40.0, 42.0, 26.0, 29.0, 21.0, 14.0, 14.0, 14.0, 8.0, 12.0, 13.0, 5.0, 10.0, 7.0, 5.0, 6.0, 4.0, 2.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.2501947581768036, -0.2423478066921234, -0.23450087010860443, -0.22665393352508545, -0.21880698204040527, -0.2109600305557251, -0.20311309397220612, -0.19526615738868713, -0.18741920590400696, -0.17957225441932678, -0.1717253178358078, -0.16387838125228882, -0.15603142976760864, -0.14818447828292847, -0.14033754169940948, -0.1324906051158905, -0.12464365363121033, -0.11679670214653015, -0.10894976556301117, -0.10110282897949219, -0.09325587749481201, -0.08540892601013184, -0.07756198942661285, -0.06971505284309387, -0.061868101358413696, -0.05402114987373352, -0.04617421329021454, -0.03832727670669556, -0.03048032522201538, -0.022633373737335205, -0.014786437153816223, -0.006939500570297241, 0.0009074509143829346, 0.00875440239906311, 0.016601353883743286, 0.024448275566101074, 0.03229522705078125, 0.040142178535461426, 0.047989100217819214, 0.05583605170249939, 0.06368300318717957, 0.07152995467185974, 0.07937690615653992, 0.0872238278388977, 0.09507077932357788, 0.10291773080825806, 0.11076465249061584, 0.11861160397529602, 0.1264585554599762, 0.13430550694465637, 0.14215245842933655, 0.14999938011169434, 0.1578463315963745, 0.1656932830810547, 0.17354020476341248, 0.18138715624809265, 0.18923410773277283, 0.197081059217453, 0.20492801070213318, 0.21277493238449097, 0.22062188386917114, 0.22846883535385132, 0.2363157570362091, 0.24416270852088928, 0.25200966000556946]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.7300477623939514, -0.7080870866775513, -0.6861264705657959, -0.6641657948493958, -0.6422051191329956, -0.6202445030212402, -0.5982838273048401, -0.5763231515884399, -0.5543625354766846, -0.5324019193649292, -0.510441243648529, -0.4884805679321289, -0.46651992201805115, -0.4445592761039734, -0.42259860038757324, -0.4006379544734955, -0.3786773085594177, -0.35671666264533997, -0.3347560167312622, -0.31279534101486206, -0.2908346951007843, -0.26887404918670654, -0.2469133734703064, -0.22495275735855103, -0.20299208164215088, -0.18103140592575073, -0.15907078981399536, -0.13711011409759521, -0.11514943838119507, -0.0931888222694397, -0.07122814655303955, -0.04926753044128418, -0.027306854724884033, -0.005346179008483887, 0.016614437103271484, 0.03857511281967163, 0.060535728931427, 0.08249640464782715, 0.1044570803642273, 0.12641769647598267, 0.1483783721923828, 0.17033904790878296, 0.19229966402053833, 0.21426033973693848, 0.23622101545333862, 0.258181631565094, 0.28014224767684937, 0.3021029829978943, 0.32406359910964966, 0.34602421522140503, 0.36798495054244995, 0.3899455666542053, 0.4119061827659607, 0.4338669180870056, 0.455827534198761, 0.47778815031051636, 0.4997488856315613, 0.5217095017433167, 0.543670117855072, 0.5656307339668274, 0.5875914692878723, 0.6095520853996277, 0.6315127015113831, 0.653473436832428, 0.6754340529441833]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.5018807649612427, -0.4862399697303772, -0.4705992043018341, -0.454958438873291, -0.43931764364242554, -0.42367684841156006, -0.40803608298301697, -0.3923953175544739, -0.3767545223236084, -0.3611137270927429, -0.34547296166419983, -0.32983219623565674, -0.31419140100479126, -0.2985506057739258, -0.2829098403453827, -0.2672690749168396, -0.2516282796859741, -0.23598748445510864, -0.22034671902656555, -0.20470595359802246, -0.18906515836715698, -0.1734243631362915, -0.1577835977077484, -0.14214283227920532, -0.12650203704833984, -0.11086124181747437, -0.09522047638893127, -0.07957971096038818, -0.0639389157295227, -0.04829812049865723, -0.032657355070114136, -0.017016589641571045, -0.0013757944107055664, 0.014265000820159912, 0.02990579605102539, 0.045546531677246094, 0.06118732690811157, 0.07682812213897705, 0.09246885776519775, 0.10810965299606323, 0.12375044822692871, 0.1393912434577942, 0.15503203868865967, 0.17067277431488037, 0.18631356954574585, 0.20195436477661133, 0.21759510040283203, 0.2332358956336975, 0.248876690864563, 0.26451748609542847, 0.28015828132629395, 0.29579901695251465, 0.3114398121833801, 0.3270806074142456, 0.3427213430404663, 0.3583621382713318, 0.37400293350219727, 0.38964372873306274, 0.4052845239639282, 0.4209252595901489, 0.4365660548210144, 0.4522068500518799, 0.4678475856781006, 0.48348838090896606, 0.49912917613983154]}, "_runtime": 10954.531496047974, "_timestamp": 1585580870.3761294, "_step": 398}
{"Episode reward": -87.0708214333534, "Episode length": 999, "Policy Loss": -0.0010914613958448172, "Value Loss": 0.0006839971174485981, "_runtime": 10956.102639198303, "_timestamp": 1585580871.9472725, "_step": 399}
{"Episode reward": -88.10747716941982, "Episode length": 999, "Policy Loss": -0.0006013704114593565, "Value Loss": 0.0006740371463820338, "_runtime": 10957.68259716034, "_timestamp": 1585580873.5272305, "_step": 400}
{"Episode reward": -91.06482192337818, "Episode length": 999, "Policy Loss": -0.0016129793366417289, "Value Loss": 0.000529712182469666, "_runtime": 10959.26662492752, "_timestamp": 1585580875.1112583, "_step": 401}
{"Episode reward": -86.54573078482964, "Episode length": 999, "Policy Loss": -0.0024235565215349197, "Value Loss": 0.0006882454035803676, "_runtime": 10960.888722658157, "_timestamp": 1585580876.733356, "_step": 402}
{"Episode reward": -89.67017066501559, "Episode length": 999, "Policy Loss": -0.0019174678018316627, "Value Loss": 0.0005797382327727973, "_runtime": 10962.469621658325, "_timestamp": 1585580878.314255, "_step": 403}
{"Episode reward": -88.95141799078144, "Episode length": 999, "Policy Loss": -0.0005048386519774795, "Value Loss": 0.0005829782458022237, "_runtime": 10964.037433385849, "_timestamp": 1585580879.8820667, "_step": 404}
{"Episode reward": -90.45503385637669, "Episode length": 999, "Policy Loss": -0.0016230377368628979, "Value Loss": 0.000515577441547066, "_runtime": 10965.619138479233, "_timestamp": 1585580881.4637718, "_step": 405}
{"Episode reward": -87.84085112346486, "Episode length": 999, "Policy Loss": -0.0012661797227337956, "Value Loss": 0.0006596822640858591, "_runtime": 10967.189645767212, "_timestamp": 1585580883.034279, "_step": 406}
{"Episode reward": -89.33335873024167, "Episode length": 999, "Policy Loss": -0.0026918190997093916, "Value Loss": 0.0005726013332605362, "_runtime": 10968.757321834564, "_timestamp": 1585580884.6019552, "_step": 407}
{"Episode reward": -87.96516787092281, "Episode length": 999, "Policy Loss": -0.0014411347219720483, "Value Loss": 0.0006138811004348099, "_runtime": 10970.328654766083, "_timestamp": 1585580886.173288, "_step": 408}
{"Episode reward": -88.45868438336144, "Episode length": 999, "Policy Loss": -0.0013491171412169933, "Value Loss": 0.0005890050088055432, "_runtime": 10971.909565210342, "_timestamp": 1585580887.7541986, "_step": 409}
{"Episode reward": -87.01438461982094, "Episode length": 999, "Policy Loss": -0.002048729918897152, "Value Loss": 0.000634926778730005, "_runtime": 10973.490290403366, "_timestamp": 1585580889.3349237, "_step": 410}
{"Episode reward": -91.77649905644444, "Episode length": 999, "Policy Loss": -0.001527494052425027, "Value Loss": 0.00046359552652575076, "_runtime": 10975.073003530502, "_timestamp": 1585580890.9176369, "_step": 411}
{"Episode reward": -90.5889317499485, "Episode length": 999, "Policy Loss": -0.0018010931089520454, "Value Loss": 0.0004574834310915321, "_runtime": 10976.65561413765, "_timestamp": 1585580892.5002475, "_step": 412}
{"Episode reward": -87.98973344121953, "Episode length": 999, "Policy Loss": -0.0010076717007905245, "Value Loss": 0.000605184817686677, "_runtime": 10978.214178323746, "_timestamp": 1585580894.0588117, "_step": 413}
{"Episode reward": -91.96851987831218, "Episode length": 999, "Policy Loss": -0.0013077351031824946, "Value Loss": 0.00044427026296034455, "_runtime": 10979.77729845047, "_timestamp": 1585580895.6219318, "_step": 414}
{"Episode reward": -89.81375669953431, "Episode length": 999, "Policy Loss": -0.0010170943569391966, "Value Loss": 0.0004919250495731831, "_runtime": 10981.35571885109, "_timestamp": 1585580897.2003522, "_step": 415}
{"Episode reward": -88.41140365059475, "Episode length": 999, "Policy Loss": -0.0005486963782459497, "Value Loss": 0.0005620478186756372, "_runtime": 10982.976350307465, "_timestamp": 1585580898.8209836, "_step": 416}
{"Episode reward": -90.08200883658836, "Episode length": 999, "Policy Loss": -0.001053576939739287, "Value Loss": 0.0004667128378059715, "_runtime": 10984.559852600098, "_timestamp": 1585580900.404486, "_step": 417}
{"Episode reward": -90.70477773266809, "Episode length": 999, "Policy Loss": -0.0009313949849456549, "Value Loss": 0.00046218684292398393, "_runtime": 10986.142099380493, "_timestamp": 1585580901.9867327, "_step": 418}
{"Episode reward": -89.47899719483232, "Episode length": 999, "Policy Loss": -0.0009657543268986046, "Value Loss": 0.0005460780812427402, "_runtime": 10987.72157907486, "_timestamp": 1585580903.5662124, "_step": 419}
{"Episode reward": -91.82581312574398, "Episode length": 999, "Policy Loss": -0.0004991169553250074, "Value Loss": 0.00040476443246006966, "_runtime": 10989.291426420212, "_timestamp": 1585580905.1360598, "_step": 420}
{"Episode reward": -91.06926415467154, "Episode length": 999, "Policy Loss": -0.0021972579415887594, "Value Loss": 0.0004656763339880854, "_runtime": 10990.875384569168, "_timestamp": 1585580906.720018, "_step": 421}
{"Episode reward": -89.61140145286133, "Episode length": 999, "Policy Loss": -0.0010942694498226047, "Value Loss": 0.0005036327638663352, "_runtime": 10992.45234632492, "_timestamp": 1585580908.2969797, "_step": 422}
{"Episode reward": -90.8717911388107, "Episode length": 999, "Policy Loss": -0.0009112903499044478, "Value Loss": 0.00048013837658800185, "_runtime": 10994.03868341446, "_timestamp": 1585580909.8833168, "_step": 423}
{"Episode reward": -91.21983769480086, "Episode length": 999, "Policy Loss": -0.0010551533196121454, "Value Loss": 0.00044225985766388476, "_runtime": 10995.620409488678, "_timestamp": 1585580911.4650428, "_step": 424}
{"Episode reward": -90.6123917535305, "Episode length": 999, "Policy Loss": -0.0019862656481564045, "Value Loss": 0.0004747933417093009, "_runtime": 10997.200823068619, "_timestamp": 1585580913.0454564, "_step": 425}
{"Episode reward": -92.54141684314594, "Episode length": 999, "Policy Loss": -0.0014630003133788705, "Value Loss": 0.00037832531961612403, "_runtime": 10998.770384788513, "_timestamp": 1585580914.6150181, "_step": 426}
{"Episode reward": -91.77577605693037, "Episode length": 999, "Policy Loss": -0.0013308244524523616, "Value Loss": 0.0004236979584675282, "_runtime": 11000.3530356884, "_timestamp": 1585580916.197669, "_step": 427}
{"Episode reward": -92.52454446077456, "Episode length": 999, "Policy Loss": -0.0007138513028621674, "Value Loss": 0.0003905878111254424, "_runtime": 11001.924945831299, "_timestamp": 1585580917.7695792, "_step": 428}
{"Episode reward": -92.50719620408785, "Episode length": 999, "Policy Loss": -0.0014175204560160637, "Value Loss": 0.00036836028448306024, "_runtime": 11003.506908893585, "_timestamp": 1585580919.3515422, "_step": 429}
{"Episode reward": -92.14709215933436, "Episode length": 999, "Policy Loss": -0.0008421400561928749, "Value Loss": 0.00040803325828164816, "_runtime": 11005.07801771164, "_timestamp": 1585580920.922651, "_step": 430}
{"Episode reward": -91.72589077224902, "Episode length": 999, "Policy Loss": -0.0011596172116696835, "Value Loss": 0.00041209079790860415, "_runtime": 11006.694785833359, "_timestamp": 1585580922.5394192, "_step": 431}
{"Episode reward": -92.18476170789761, "Episode length": 999, "Policy Loss": -0.0010727798799052835, "Value Loss": 0.0003734756610356271, "_runtime": 11008.275896787643, "_timestamp": 1585580924.1205301, "_step": 432}
{"Episode reward": -92.28426864136185, "Episode length": 999, "Policy Loss": 0.00016362863243557513, "Value Loss": 0.0004275743558537215, "_runtime": 11009.856506824493, "_timestamp": 1585580925.7011402, "_step": 433}
{"Episode reward": -93.50775370904823, "Episode length": 999, "Policy Loss": -0.0005846555577591062, "Value Loss": 0.0003321500844322145, "_runtime": 11011.437188386917, "_timestamp": 1585580927.2818217, "_step": 434}
{"Episode reward": -93.63319041575458, "Episode length": 999, "Policy Loss": -0.0010243830038234591, "Value Loss": 0.00034853495890274644, "_runtime": 11013.019525289536, "_timestamp": 1585580928.8641586, "_step": 435}
{"Episode reward": -91.81365762293073, "Episode length": 999, "Policy Loss": -0.0005601760931313038, "Value Loss": 0.0003969318640884012, "_runtime": 11014.600187063217, "_timestamp": 1585580930.4448204, "_step": 436}
{"Episode reward": -93.6056700834831, "Episode length": 999, "Policy Loss": -0.0007128872675821185, "Value Loss": 0.00035768255474977195, "_runtime": 11016.181680679321, "_timestamp": 1585580932.026314, "_step": 437}
{"Episode reward": -90.89530397220133, "Episode length": 999, "Policy Loss": -2.136626972060185e-05, "Value Loss": 0.0004295000107958913, "_runtime": 11017.76634645462, "_timestamp": 1585580933.6109798, "_step": 438}
{"Episode reward": -92.4531857441421, "Episode length": 999, "Policy Loss": -0.0018414105288684368, "Value Loss": 0.0003589887055568397, "_runtime": 11019.358330726624, "_timestamp": 1585580935.202964, "_step": 439}
{"Episode reward": -90.66319897641516, "Episode length": 999, "Policy Loss": -0.000812966376543045, "Value Loss": 0.00041595351649448276, "_runtime": 11020.94897532463, "_timestamp": 1585580936.7936087, "_step": 440}
{"Episode reward": -91.77375994302143, "Episode length": 999, "Policy Loss": -0.0006433918606489897, "Value Loss": 0.00038576676161028445, "_runtime": 11022.541927337646, "_timestamp": 1585580938.3865607, "_step": 441}
{"Episode reward": -91.6436342553765, "Episode length": 999, "Policy Loss": -0.001619379036128521, "Value Loss": 0.0004251004138495773, "_runtime": 11024.141686439514, "_timestamp": 1585580939.9863198, "_step": 442}
{"Episode reward": -93.11582345532496, "Episode length": 999, "Policy Loss": -0.0007017930620349944, "Value Loss": 0.00032035852200351655, "_runtime": 11025.737169742584, "_timestamp": 1585580941.581803, "_step": 443}
{"Episode reward": -93.32815239556983, "Episode length": 999, "Policy Loss": -0.0011935851071029902, "Value Loss": 0.00032733145053498447, "_runtime": 11027.336979866028, "_timestamp": 1585580943.1816132, "_step": 444}
{"Episode reward": -92.27296668736197, "Episode length": 999, "Policy Loss": -0.0010012678103521466, "Value Loss": 0.00040275888750329614, "_runtime": 11028.924548625946, "_timestamp": 1585580944.769182, "_step": 445}
{"Episode reward": -93.47302786243206, "Episode length": 999, "Policy Loss": -0.0008043485577218235, "Value Loss": 0.00030094332760199904, "_runtime": 11030.550882339478, "_timestamp": 1585580946.3955157, "_step": 446}
{"Episode reward": -93.7789725082257, "Episode length": 999, "Policy Loss": -0.0007885807426646352, "Value Loss": 0.0002940793347079307, "_runtime": 11032.1432056427, "_timestamp": 1585580947.987839, "_step": 447}
{"Episode reward": -94.2350440318497, "Episode length": 999, "Policy Loss": -0.0012344460701569915, "Value Loss": 0.00025902045308612287, "_runtime": 11033.73311305046, "_timestamp": 1585580949.5777464, "_step": 448}
{"Episode reward": -94.2465614392435, "Episode length": 999, "Policy Loss": -0.0012078332947567105, "Value Loss": 0.00029109008028171957, "_runtime": 11035.3265106678, "_timestamp": 1585580951.171144, "_step": 449}
{"Episode reward": -94.00052367818624, "Episode length": 999, "Policy Loss": -0.0002001430548261851, "Value Loss": 0.0002731028653215617, "_runtime": 11036.927340269089, "_timestamp": 1585580952.7719736, "_step": 450}
{"Episode reward": -93.22940279622443, "Episode length": 999, "Policy Loss": 0.000532697478774935, "Value Loss": 0.000284985319012776, "_runtime": 11038.53135752678, "_timestamp": 1585580954.3759909, "_step": 451}
{"Episode reward": -94.22733906402463, "Episode length": 999, "Policy Loss": -0.0003784327709581703, "Value Loss": 0.00026726839132606983, "_runtime": 11040.129661560059, "_timestamp": 1585580955.974295, "_step": 452}
{"Episode reward": -92.08814609271919, "Episode length": 999, "Policy Loss": -0.0007319011492654681, "Value Loss": 0.0003575578739400953, "_runtime": 11041.729029417038, "_timestamp": 1585580957.5736628, "_step": 453}
{"Episode reward": -94.5347226366621, "Episode length": 999, "Policy Loss": -0.00019166477432008833, "Value Loss": 0.0002539946581237018, "_runtime": 11043.32943868637, "_timestamp": 1585580959.174072, "_step": 454}
{"Episode reward": -93.1342234192459, "Episode length": 999, "Policy Loss": -0.0002570216602180153, "Value Loss": 0.0003161860804539174, "_runtime": 11044.915784358978, "_timestamp": 1585580960.7604177, "_step": 455}
{"Episode reward": -92.24589914136578, "Episode length": 999, "Policy Loss": -0.0003987251257058233, "Value Loss": 0.00032900131191127, "_runtime": 11046.513529539108, "_timestamp": 1585580962.3581629, "_step": 456}
{"Episode reward": -94.64088846417899, "Episode length": 999, "Policy Loss": -0.00025230832397937775, "Value Loss": 0.00025356592959724367, "_runtime": 11048.114083051682, "_timestamp": 1585580963.9587164, "_step": 457}
{"Episode reward": -94.12101475228604, "Episode length": 999, "Policy Loss": -0.001174595789052546, "Value Loss": 0.0002540693385526538, "_runtime": 11049.712186336517, "_timestamp": 1585580965.5568197, "_step": 458}
{"Episode reward": -94.04488891036603, "Episode length": 999, "Policy Loss": -3.1913237762637436e-05, "Value Loss": 0.00026359324692748487, "_runtime": 11051.30949807167, "_timestamp": 1585580967.1541314, "_step": 459}
{"Episode reward": -93.61923376743746, "Episode length": 999, "Policy Loss": -0.0006732376641593874, "Value Loss": 0.00026677382993511856, "_runtime": 11052.907149076462, "_timestamp": 1585580968.7517824, "_step": 460}
{"Episode reward": -94.05257818168957, "Episode length": 999, "Policy Loss": -0.0007551644230261445, "Value Loss": 0.0002907572197727859, "_runtime": 11054.53274679184, "_timestamp": 1585580970.3773801, "_step": 461}
{"Episode reward": -94.75076886903614, "Episode length": 999, "Policy Loss": -0.0006402306607924402, "Value Loss": 0.00023733850684948266, "_runtime": 11056.12102985382, "_timestamp": 1585580971.9656632, "_step": 462}
{"Episode reward": -92.49909819551378, "Episode length": 999, "Policy Loss": -0.0007972169551067054, "Value Loss": 0.000316148332785815, "_runtime": 11057.717979669571, "_timestamp": 1585580973.562613, "_step": 463}
{"Episode reward": -95.07534256451905, "Episode length": 999, "Policy Loss": -0.000927102577406913, "Value Loss": 0.00022780051222071052, "_runtime": 11059.314600944519, "_timestamp": 1585580975.1592343, "_step": 464}
{"Episode reward": -94.79178823667532, "Episode length": 999, "Policy Loss": -0.000556205864995718, "Value Loss": 0.00022350373910740018, "_runtime": 11060.903736114502, "_timestamp": 1585580976.7483695, "_step": 465}
{"Episode reward": -92.80637652960003, "Episode length": 999, "Policy Loss": -0.0006494875997304916, "Value Loss": 0.0003383807197678834, "_runtime": 11062.504951238632, "_timestamp": 1585580978.3495846, "_step": 466}
{"Episode reward": -94.55059042503683, "Episode length": 999, "Policy Loss": -0.0013159187510609627, "Value Loss": 0.00024235484306700528, "_runtime": 11064.102771520615, "_timestamp": 1585580979.9474049, "_step": 467}
{"Episode reward": -94.13233960987593, "Episode length": 999, "Policy Loss": -0.0004846797382924706, "Value Loss": 0.000238601875025779, "_runtime": 11065.69940495491, "_timestamp": 1585580981.5440383, "_step": 468}
{"Episode reward": -94.67122813139457, "Episode length": 999, "Policy Loss": -0.0010695898672565818, "Value Loss": 0.00023480226809624583, "_runtime": 11067.296238899231, "_timestamp": 1585580983.1408722, "_step": 469}
{"Episode reward": -93.9642292196027, "Episode length": 999, "Policy Loss": -0.0006439639255404472, "Value Loss": 0.0002605346671771258, "_runtime": 11068.892357110977, "_timestamp": 1585580984.7369905, "_step": 470}
{"Episode reward": -94.43076187040953, "Episode length": 999, "Policy Loss": -0.00016953049635048956, "Value Loss": 0.00023667042842134833, "_runtime": 11070.490874290466, "_timestamp": 1585580986.3355076, "_step": 471}
{"Episode reward": -93.52211279334003, "Episode length": 999, "Policy Loss": -0.00047844124492257833, "Value Loss": 0.0002959461126010865, "_runtime": 11072.090141534805, "_timestamp": 1585580987.9347749, "_step": 472}
{"Episode reward": -93.0868180958902, "Episode length": 999, "Policy Loss": -0.0007745702750980854, "Value Loss": 0.00026534669450484216, "_runtime": 11073.687987804413, "_timestamp": 1585580989.5326211, "_step": 473}
{"Episode reward": -93.59381059680231, "Episode length": 999, "Policy Loss": -0.00030517802224494517, "Value Loss": 0.0002668305241968483, "_runtime": 11075.286303043365, "_timestamp": 1585580991.1309364, "_step": 474}
{"Episode reward": -94.5829388603019, "Episode length": 999, "Policy Loss": 0.000517729960847646, "Value Loss": 0.000228017961489968, "_runtime": 11076.921996831894, "_timestamp": 1585580992.7666302, "_step": 475}
{"Episode reward": -94.74522193772972, "Episode length": 999, "Policy Loss": -0.0005046089645475149, "Value Loss": 0.00020355131709948182, "_runtime": 11078.519474983215, "_timestamp": 1585580994.3641083, "_step": 476}
{"Episode reward": -93.75852796734391, "Episode length": 999, "Policy Loss": -0.0004636776284314692, "Value Loss": 0.0002698731259442866, "_runtime": 11080.115193367004, "_timestamp": 1585580995.9598267, "_step": 477}
{"Episode reward": -93.6393715973375, "Episode length": 999, "Policy Loss": -0.0007599747623316944, "Value Loss": 0.0002745010133367032, "_runtime": 11081.712148189545, "_timestamp": 1585580997.5567815, "_step": 478}
{"Episode reward": -92.92515730070444, "Episode length": 999, "Policy Loss": -0.0005803746753372252, "Value Loss": 0.0002804829564411193, "_runtime": 11083.316374063492, "_timestamp": 1585580999.1610074, "_step": 479}
{"Episode reward": -92.3676712053877, "Episode length": 999, "Policy Loss": -0.000928535358980298, "Value Loss": 0.00030655981390736997, "_runtime": 11084.885340929031, "_timestamp": 1585581000.7299743, "_step": 480}
{"Episode reward": -93.48170055651494, "Episode length": 999, "Policy Loss": -0.0005168506177142262, "Value Loss": 0.00027505625621415675, "_runtime": 11086.469051361084, "_timestamp": 1585581002.3136847, "_step": 481}
{"Episode reward": -93.75709082163652, "Episode length": 999, "Policy Loss": -0.0005607408820651472, "Value Loss": 0.00024267997650895268, "_runtime": 11088.04826784134, "_timestamp": 1585581003.8929012, "_step": 482}
{"Episode reward": -94.73868316321925, "Episode length": 999, "Policy Loss": -0.0003389749035704881, "Value Loss": 0.00022982826340012252, "_runtime": 11089.637321710587, "_timestamp": 1585581005.481955, "_step": 483}
{"Episode reward": -94.07274566342123, "Episode length": 999, "Policy Loss": 0.00011177746637258679, "Value Loss": 0.00022195023484528065, "_runtime": 11091.228439569473, "_timestamp": 1585581007.073073, "_step": 484}
{"Episode reward": -93.93426398886592, "Episode length": 999, "Policy Loss": -3.9298894989769906e-05, "Value Loss": 0.0002333066804567352, "_runtime": 11092.819910049438, "_timestamp": 1585581008.6645434, "_step": 485}
{"Episode reward": -95.1026672689625, "Episode length": 999, "Policy Loss": 0.00015942870231810957, "Value Loss": 0.00018079698202200234, "_runtime": 11094.409904956818, "_timestamp": 1585581010.2545383, "_step": 486}
{"Episode reward": -94.08550106663064, "Episode length": 999, "Policy Loss": -0.0009183022775687277, "Value Loss": 0.0002266511000925675, "_runtime": 11096.001149177551, "_timestamp": 1585581011.8457825, "_step": 487}
{"Episode reward": -93.97883795641631, "Episode length": 999, "Policy Loss": 2.2796859411755577e-05, "Value Loss": 0.0002204520278610289, "_runtime": 11097.588476419449, "_timestamp": 1585581013.4331098, "_step": 488}
{"Episode reward": -94.06635650518989, "Episode length": 999, "Policy Loss": -0.00042490119813010097, "Value Loss": 0.00023253538529388607, "_runtime": 11099.172691106796, "_timestamp": 1585581015.0173244, "_step": 489}
{"Episode reward": -93.0536504946538, "Episode length": 999, "Policy Loss": -0.000679737189784646, "Value Loss": 0.00028953340370208025, "_runtime": 11100.79463505745, "_timestamp": 1585581016.6392684, "_step": 490}
{"Episode reward": -94.35833699404105, "Episode length": 999, "Policy Loss": 2.282842979184352e-05, "Value Loss": 0.00019988094572909176, "_runtime": 11102.37218117714, "_timestamp": 1585581018.2168145, "_step": 491}
{"Episode reward": -95.16908488150301, "Episode length": 999, "Policy Loss": -0.0002940334379673004, "Value Loss": 0.00017980561824515462, "_runtime": 11103.954960346222, "_timestamp": 1585581019.7995937, "_step": 492}
{"Episode reward": -93.45555149149888, "Episode length": 999, "Policy Loss": 0.00013858237070962787, "Value Loss": 0.00026034886832349, "_runtime": 11105.538127660751, "_timestamp": 1585581021.382761, "_step": 493}
{"Episode reward": -94.72834340270191, "Episode length": 999, "Policy Loss": -0.00013162197137717158, "Value Loss": 0.00019946617248933762, "_runtime": 11107.120369911194, "_timestamp": 1585581022.9650033, "_step": 494}
{"Episode reward": -94.62514279870908, "Episode length": 999, "Policy Loss": 0.00024146180658135563, "Value Loss": 0.00019518786575645208, "_runtime": 11108.689608812332, "_timestamp": 1585581024.5342422, "_step": 495}
{"Episode reward": -94.63691311882187, "Episode length": 999, "Policy Loss": 0.00024083448806777596, "Value Loss": 0.00019078963669016957, "_runtime": 11110.272387504578, "_timestamp": 1585581026.1170208, "_step": 496}
{"Episode reward": -94.30803607081802, "Episode length": 999, "Policy Loss": -0.00014986703172326088, "Value Loss": 0.00020113673235755414, "_runtime": 11111.830819129944, "_timestamp": 1585581027.6754525, "_step": 497}
{"Episode reward": -93.16712288950968, "Episode length": 999, "Policy Loss": -0.0003043434116989374, "Value Loss": 0.0002444168203510344, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568, 5.452783107757568]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.71816873550415, -4.406158447265625, -4.094147682189941, -3.782137393951416, -3.4701271057128906, -3.158116579055786, -2.8461060523986816, -2.5340957641601562, -2.2220852375030518, -1.9100747108459473, -1.5980644226074219, -1.2860538959503174, -0.9740433692932129, -0.6620330810546875, -0.3500227928161621, -0.038012027740478516, 0.2739982604980469, 0.5860085487365723, 0.8980193138122559, 1.2100296020507812, 1.5220398902893066, 1.8340506553649902, 2.1460609436035156, 2.458071231842041, 2.7700819969177246, 3.08209228515625, 3.3941025733947754, 3.706113338470459, 4.018123149871826, 4.33013391494751, 4.642144680023193, 4.9541544914245605, 5.266165256500244, 5.578176021575928, 5.890185832977295, 6.2021965980529785, 6.514207363128662, 6.826217174530029, 7.138227939605713, 7.4502387046813965, 7.762248516082764, 8.074258804321289, 8.386270523071289, 8.698280334472656, 9.010290145874023, 9.322301864624023, 9.63431167602539, 9.946321487426758, 10.258333206176758, 10.570343017578125, 10.882352828979492, 11.19436264038086, 11.50637435913086, 11.818384170532227, 12.130395889282227, 12.442405700683594, 12.754415512084961, 13.066427230834961, 13.378437042236328, 13.690446853637695, 14.002458572387695, 14.314468383789062, 14.62647819519043, 14.93848991394043, 15.250499725341797]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0], "bins": [-1.1623164415359497, -1.1389235258102417, -1.1155304908752441, -1.0921375751495361, -1.0687445402145386, -1.0453516244888306, -1.021958589553833, -0.998565673828125, -0.9751726984977722, -0.9517797231674194, -0.9283868074417114, -0.9049937725067139, -0.8816008567810059, -0.8582078814506531, -0.8348149061203003, -0.8114219903945923, -0.7880289554595947, -0.7646360397338867, -0.7412430644035339, -0.7178500890731812, -0.6944571137428284, -0.6710641384124756, -0.6476711630821228, -0.6242782473564148, -0.600885272026062, -0.5774922966957092, -0.5540993213653564, -0.5307063460350037, -0.5073133707046509, -0.48392045497894287, -0.4605274796485901, -0.4371345043182373, -0.4137415289878845, -0.39034855365753174, -0.36695557832717896, -0.34356260299682617, -0.32016968727111816, -0.2967767119407654, -0.2733837366104126, -0.24999076128005981, -0.22659778594970703, -0.20320481061935425, -0.17981189489364624, -0.15641891956329346, -0.1330258846282959, -0.10963296890258789, -0.08624005317687988, -0.06284701824188232, -0.039454102516174316, -0.016061067581176758, 0.00733184814453125, 0.03072488307952881, 0.054117798805236816, 0.07751071453094482, 0.10090374946594238, 0.12429666519165039, 0.14768970012664795, 0.17108261585235596, 0.19447553157806396, 0.21786856651306152, 0.24126148223876953, 0.2646545171737671, 0.2880474328994751, 0.31144046783447266, 0.33483338356018066]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 4.0, 8.0, 7.0, 12.0, 10.0, 24.0, 37.0, 38.0, 42.0, 84.0, 58.0, 48.0, 29.0, 26.0, 21.0, 14.0, 7.0, 3.0, 4.0, 4.0, 4.0, 2.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9012982845306396, -0.8760437965393066, -0.8507893085479736, -0.8255348205566406, -0.8002803325653076, -0.7750258445739746, -0.7497713565826416, -0.7245168685913086, -0.6992623805999756, -0.6740078926086426, -0.6487534046173096, -0.6234989166259766, -0.5982444286346436, -0.5729899406433105, -0.5477354526519775, -0.5224809646606445, -0.4972264766693115, -0.4719719886779785, -0.4467175006866455, -0.4214630126953125, -0.3962085247039795, -0.3709540367126465, -0.3456995487213135, -0.32044506072998047, -0.29519057273864746, -0.26993608474731445, -0.24468159675598145, -0.21942710876464844, -0.19417262077331543, -0.16891813278198242, -0.14366364479064941, -0.1184091567993164, -0.0931546688079834, -0.06790018081665039, -0.04264569282531738, -0.017391204833984375, 0.007863283157348633, 0.03311777114868164, 0.05837225914001465, 0.08362674713134766, 0.10888123512268066, 0.13413572311401367, 0.15939021110534668, 0.1846446990966797, 0.2098991870880127, 0.2351536750793457, 0.2604081630706787, 0.2856626510620117, 0.3109171390533447, 0.33617162704467773, 0.36142611503601074, 0.38668060302734375, 0.41193509101867676, 0.43718957901000977, 0.4624440670013428, 0.4876985549926758, 0.5129530429840088, 0.5382075309753418, 0.5634620189666748, 0.5887165069580078, 0.6139709949493408, 0.6392254829406738, 0.6644799709320068, 0.6897344589233398, 0.7149889469146729]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8730526566505432, -0.8411614298820496, -0.8092702627182007, -0.777379035949707, -0.7454878091812134, -0.7135965824127197, -0.6817053556442261, -0.6498141884803772, -0.6179229617118835, -0.5860317349433899, -0.554140567779541, -0.5222493410110474, -0.4903581142425537, -0.45846688747406006, -0.4265756905078888, -0.39468449354171753, -0.3627932667732239, -0.3309020400047302, -0.2990108132362366, -0.2671196460723877, -0.23522841930389404, -0.2033371925354004, -0.1714460253715515, -0.13955479860305786, -0.10766357183456421, -0.07577234506607056, -0.043881118297576904, -0.011989951133728027, 0.019901275634765625, 0.05179250240325928, 0.08368366956710815, 0.1155748963356018, 0.14746612310409546, 0.1793573498725891, 0.21124857664108276, 0.24313980340957642, 0.27503103017807007, 0.30692213773727417, 0.3388133645057678, 0.3707045912742615, 0.4025958180427551, 0.4344870448112488, 0.46637827157974243, 0.4982694983482361, 0.5301606059074402, 0.5620518326759338, 0.5939430594444275, 0.6258342862129211, 0.6577255129814148, 0.6896167397499084, 0.7215079665184021, 0.7533991932868958, 0.7852904200553894, 0.8171815276145935, 0.8490727543830872, 0.8809639811515808, 0.9128552079200745, 0.9447464346885681, 0.9766376614570618, 1.0085289478302002, 1.0404200553894043, 1.0723111629486084, 1.1042025089263916, 1.1360938549041748, 1.167984962463379]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 3.0, 3.0, 4.0, 5.0, 8.0, 8.0, 4.0, 6.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.9533435702323914, -0.9263609647750854, -0.8993784189224243, -0.8723958134651184, -0.8454132676124573, -0.8184306621551514, -0.7914481163024902, -0.7644655108451843, -0.7374829053878784, -0.7105003595352173, -0.6835178136825562, -0.6565352082252502, -0.6295526027679443, -0.6025700569152832, -0.5755874514579773, -0.5486048460006714, -0.5216223001480103, -0.49463972449302673, -0.4676571488380432, -0.4406745433807373, -0.41369199752807617, -0.38670939207077026, -0.35972684621810913, -0.3327442407608032, -0.3057616353034973, -0.2787790894508362, -0.2517964839935303, -0.22481393814086914, -0.19783133268356323, -0.1708487868309021, -0.1438661813735962, -0.11688363552093506, -0.08990103006362915, -0.06291842460632324, -0.03593587875366211, -0.008953273296356201, 0.01802927255630493, 0.04501187801361084, 0.07199448347091675, 0.09897702932357788, 0.125959575176239, 0.1529422402381897, 0.17992478609085083, 0.20690733194351196, 0.2338898777961731, 0.2608725428581238, 0.2878550887107849, 0.31483763456344604, 0.34182029962539673, 0.36880284547805786, 0.395785391330719, 0.4227679371833801, 0.4497506022453308, 0.47673314809799194, 0.5037156939506531, 0.5306982398033142, 0.5576809048652649, 0.584663450717926, 0.6116459965705872, 0.6386286616325378, 0.665611207485199, 0.6925937533378601, 0.7195762991905212, 0.7465589642524719, 0.7735415101051331]}, "_runtime": 11113.413581609726, "_timestamp": 1585581029.258215, "_step": 498}
{"Episode reward": -94.24754121120401, "Episode length": 999, "Policy Loss": -0.00038762640906497836, "Value Loss": 0.0002278133324580267, "_runtime": 11113.413581609726, "_timestamp": 1585581029.258215, "_step": 499}
