{"Episode reward": -33.04346950978307, "Episode length": 999, "Policy Loss": -0.036177217960357666, "Value Loss": 0.0035970560275018215, "_runtime": 19.87229037284851, "_timestamp": 1585594768.888964, "_step": 0}
{"Episode reward": -93.690989775305, "Episode length": 999, "Policy Loss": -0.30413731932640076, "Value Loss": 1.1763765811920166, "_runtime": 21.203593254089355, "_timestamp": 1585594770.2202668, "_step": 1}
{"Episode reward": 10.755795750382433, "Episode length": 914, "Policy Loss": 0.10326997935771942, "Value Loss": 11.416841506958008, "_runtime": 22.694238901138306, "_timestamp": 1585594771.7109125, "_step": 2}
{"Episode reward": -98.7520959788782, "Episode length": 999, "Policy Loss": -0.4332009553909302, "Value Loss": 0.0709681585431099, "_runtime": 23.293328523635864, "_timestamp": 1585594772.310002, "_step": 3}
{"Episode reward": 62.22256182616085, "Episode length": 378, "Policy Loss": 0.7943714261054993, "Value Loss": 26.36121940612793, "_runtime": 23.94705581665039, "_timestamp": 1585594772.9637294, "_step": 4}
{"Episode reward": 56.67917008562329, "Episode length": 434, "Policy Loss": 0.922521710395813, "Value Loss": 22.804027557373047, "_runtime": 25.441974401474, "_timestamp": 1585594774.458648, "_step": 5}
{"Episode reward": -99.59737432279952, "Episode length": 999, "Policy Loss": -0.7019049525260925, "Value Loss": 0.10103420913219452, "_runtime": 26.912003993988037, "_timestamp": 1585594775.9286776, "_step": 6}
{"Episode reward": -99.81027859097672, "Episode length": 999, "Policy Loss": -0.704271137714386, "Value Loss": 0.09230384975671768, "_runtime": 28.3905611038208, "_timestamp": 1585594777.4072347, "_step": 7}
{"Episode reward": -99.65797332946538, "Episode length": 999, "Policy Loss": -0.6562821865081787, "Value Loss": 0.22369927167892456, "_runtime": 29.909587860107422, "_timestamp": 1585594778.9262614, "_step": 8}
{"Episode reward": -99.81956890525622, "Episode length": 999, "Policy Loss": -0.5324694514274597, "Value Loss": 0.46141642332077026, "_runtime": 30.530668258666992, "_timestamp": 1585594779.5473418, "_step": 9}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.1257214546203613, "Value Loss": 25.397401809692383, "_runtime": 32.04062747955322, "_timestamp": 1585594781.057301, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6694785356521606, "Value Loss": 0.08800382912158966, "_runtime": 33.56408905982971, "_timestamp": 1585594782.5807626, "_step": 11}
{"Episode reward": -99.80580649971823, "Episode length": 999, "Policy Loss": -0.7636476159095764, "Value Loss": 0.2955028712749481, "_runtime": 35.035643577575684, "_timestamp": 1585594784.0523171, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7594673037528992, "Value Loss": 0.1182253435254097, "_runtime": 36.561408281326294, "_timestamp": 1585594785.5780818, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.782168447971344, "Value Loss": 0.11067575961351395, "_runtime": 37.52046203613281, "_timestamp": 1585594786.5371356, "_step": 14}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.4367654025554657, "Value Loss": 16.451831817626953, "_runtime": 39.07172393798828, "_timestamp": 1585594788.0883975, "_step": 15}
{"Episode reward": -99.78482201285523, "Episode length": 999, "Policy Loss": -0.7601036429405212, "Value Loss": 0.017495522275567055, "_runtime": 40.6017804145813, "_timestamp": 1585594789.618454, "_step": 16}
{"Episode reward": -99.80615726793044, "Episode length": 999, "Policy Loss": -0.7217434644699097, "Value Loss": 0.01272821519523859, "_runtime": 40.96263527870178, "_timestamp": 1585594789.9793088, "_step": 17}
{"Episode reward": 78.39999999999998, "Episode length": 216, "Policy Loss": 2.771313190460205, "Value Loss": 46.15483856201172, "_runtime": 42.482773542404175, "_timestamp": 1585594791.499447, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.678013265132904, "Value Loss": 0.11972146481275558, "_runtime": 44.019920349121094, "_timestamp": 1585594793.036594, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6170911192893982, "Value Loss": 0.13904225826263428, "_runtime": 45.489113092422485, "_timestamp": 1585594794.5057867, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5876197814941406, "Value Loss": 0.08232225477695465, "_runtime": 46.58393120765686, "_timestamp": 1585594795.6006048, "_step": 21}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.4461391568183899, "Value Loss": 14.000394821166992, "_runtime": 47.871641874313354, "_timestamp": 1585594796.8883154, "_step": 22}
{"Episode reward": 16.000000000000497, "Episode length": 840, "Policy Loss": 0.30303657054901123, "Value Loss": 11.653868675231934, "_runtime": 48.793386697769165, "_timestamp": 1585594797.8100603, "_step": 23}
{"Episode reward": 40.076608985661885, "Episode length": 600, "Policy Loss": 0.6437933444976807, "Value Loss": 16.292875289916992, "_runtime": 49.99454212188721, "_timestamp": 1585594799.0112157, "_step": 24}
{"Episode reward": 20.497790690511707, "Episode length": 797, "Policy Loss": 0.2990153133869171, "Value Loss": 12.440714836120605, "_runtime": 51.506098985672, "_timestamp": 1585594800.5227726, "_step": 25}
{"Episode reward": -99.69641609005491, "Episode length": 999, "Policy Loss": -0.5898805856704712, "Value Loss": 0.039567817002534866, "_runtime": 53.00561857223511, "_timestamp": 1585594802.0222921, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6140973567962646, "Value Loss": 0.023878280073404312, "_runtime": 54.51737880706787, "_timestamp": 1585594803.5340524, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6446042060852051, "Value Loss": 0.023546136915683746, "_runtime": 56.04692196846008, "_timestamp": 1585594805.0635955, "_step": 28}
{"Episode reward": -99.83194347023824, "Episode length": 999, "Policy Loss": -0.6667178273200989, "Value Loss": 0.029824960976839066, "_runtime": 57.076415061950684, "_timestamp": 1585594806.0930886, "_step": 29}
{"Episode reward": 33.4999999999995, "Episode length": 665, "Policy Loss": 0.4387868344783783, "Value Loss": 14.981230735778809, "_runtime": 58.251357316970825, "_timestamp": 1585594807.268031, "_step": 30}
{"Episode reward": 23.27402012310931, "Episode length": 768, "Policy Loss": 0.3055751919746399, "Value Loss": 12.8613920211792, "_runtime": 59.77673316001892, "_timestamp": 1585594808.7934067, "_step": 31}
{"Episode reward": -99.85942938113445, "Episode length": 999, "Policy Loss": -0.6841554045677185, "Value Loss": 0.053044065833091736, "_runtime": 61.307236671447754, "_timestamp": 1585594810.3239102, "_step": 32}
{"Episode reward": -99.81200175881246, "Episode length": 999, "Policy Loss": -0.6765726804733276, "Value Loss": 0.0691361203789711, "_runtime": 62.8205451965332, "_timestamp": 1585594811.8372188, "_step": 33}
{"Episode reward": -99.85860881842534, "Episode length": 999, "Policy Loss": -0.6509423851966858, "Value Loss": 0.49937060475349426, "_runtime": 63.79278779029846, "_timestamp": 1585594812.8094614, "_step": 34}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": 0.56107497215271, "Value Loss": 15.871232986450195, "_runtime": 65.14109754562378, "_timestamp": 1585594814.157771, "_step": 35}
{"Episode reward": 12.065622741636616, "Episode length": 881, "Policy Loss": 0.11599775403738022, "Value Loss": 11.347244262695312, "_runtime": 66.65223598480225, "_timestamp": 1585594815.6689095, "_step": 36}
{"Episode reward": -99.80015187347168, "Episode length": 999, "Policy Loss": -0.6858831644058228, "Value Loss": 0.020989377051591873, "_runtime": 68.16560101509094, "_timestamp": 1585594817.1822746, "_step": 37}
{"Episode reward": -99.6442972810925, "Episode length": 999, "Policy Loss": -0.6848331093788147, "Value Loss": 0.032632239162921906, "_runtime": 69.68478083610535, "_timestamp": 1585594818.7014544, "_step": 38}
{"Episode reward": -99.7417455950738, "Episode length": 999, "Policy Loss": -0.6831006407737732, "Value Loss": 0.012979313731193542, "_runtime": 71.2270576953888, "_timestamp": 1585594820.2437313, "_step": 39}
{"Episode reward": -99.88690918832877, "Episode length": 999, "Policy Loss": -0.6756393313407898, "Value Loss": 0.010628998279571533, "_runtime": 72.39872193336487, "_timestamp": 1585594821.4153955, "_step": 40}
{"Episode reward": 23.870009268727202, "Episode length": 762, "Policy Loss": 0.24714240431785583, "Value Loss": 13.011751174926758, "_runtime": 73.93676376342773, "_timestamp": 1585594822.9534373, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6736227869987488, "Value Loss": 0.016647493466734886, "_runtime": 74.47231960296631, "_timestamp": 1585594823.4889932, "_step": 42}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": 1.3996034860610962, "Value Loss": 30.43025016784668, "_runtime": 75.3149061203003, "_timestamp": 1585594824.3315797, "_step": 43}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.5969678163528442, "Value Loss": 17.79775047302246, "_runtime": 76.37368941307068, "_timestamp": 1585594825.390363, "_step": 44}
{"Episode reward": 30.092394133563786, "Episode length": 700, "Policy Loss": 0.6250015497207642, "Value Loss": 14.075858116149902, "_runtime": 77.0863082408905, "_timestamp": 1585594826.1029818, "_step": 45}
{"Episode reward": 52.199268619995166, "Episode length": 479, "Policy Loss": 0.8078252673149109, "Value Loss": 20.550617218017578, "_runtime": 78.56645059585571, "_timestamp": 1585594827.5831242, "_step": 46}
{"Episode reward": -99.66940578101064, "Episode length": 999, "Policy Loss": -0.7724858522415161, "Value Loss": 0.21894344687461853, "_runtime": 80.05147767066956, "_timestamp": 1585594829.0681512, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8189765810966492, "Value Loss": 0.03171294182538986, "_runtime": 81.5223560333252, "_timestamp": 1585594830.5390296, "_step": 48}
{"Episode reward": -99.80134270721906, "Episode length": 999, "Policy Loss": -0.8350633382797241, "Value Loss": 0.05397159233689308, "_runtime": 81.88291621208191, "_timestamp": 1585594830.8995898, "_step": 49}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": 2.444974184036255, "Value Loss": 46.107383728027344, "_runtime": 83.17542862892151, "_timestamp": 1585594832.1921022, "_step": 50}
{"Episode reward": 13.600000000000634, "Episode length": 864, "Policy Loss": -0.02681167982518673, "Value Loss": 11.811692237854004, "_runtime": 84.2944507598877, "_timestamp": 1585594833.3111243, "_step": 51}
{"Episode reward": 28.347041638940368, "Episode length": 718, "Policy Loss": 0.10019439458847046, "Value Loss": 13.979844093322754, "_runtime": 85.74604773521423, "_timestamp": 1585594834.7627213, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8601540923118591, "Value Loss": 0.020705418661236763, "_runtime": 86.11911630630493, "_timestamp": 1585594835.1357899, "_step": 53}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 3.1783251762390137, "Value Loss": 43.8412971496582, "_runtime": 87.6059582233429, "_timestamp": 1585594836.6226318, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8272408246994019, "Value Loss": 0.01164576131850481, "_runtime": 89.1171727180481, "_timestamp": 1585594838.1338463, "_step": 55}
{"Episode reward": -99.76186016946892, "Episode length": 999, "Policy Loss": -0.833157479763031, "Value Loss": 0.012265307828783989, "_runtime": 90.57212281227112, "_timestamp": 1585594839.5887964, "_step": 56}
{"Episode reward": -99.83873512483994, "Episode length": 999, "Policy Loss": -0.8363932967185974, "Value Loss": 0.011869898065924644, "_runtime": 92.08554911613464, "_timestamp": 1585594841.1022227, "_step": 57}
{"Episode reward": -99.75141905620555, "Episode length": 999, "Policy Loss": -0.8366506099700928, "Value Loss": 0.011760450899600983, "_runtime": 93.60996627807617, "_timestamp": 1585594842.6266398, "_step": 58}
{"Episode reward": -99.81820180564979, "Episode length": 999, "Policy Loss": -0.8372944593429565, "Value Loss": 0.011930549517273903, "_runtime": 95.1295804977417, "_timestamp": 1585594844.146254, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8324980735778809, "Value Loss": 0.014922878704965115, "_runtime": 96.34942507743835, "_timestamp": 1585594845.3660986, "_step": 60}
{"Episode reward": 20.474627374112856, "Episode length": 797, "Policy Loss": 0.18140926957130432, "Value Loss": 12.470706939697266, "_runtime": 97.87575173377991, "_timestamp": 1585594846.8924253, "_step": 61}
{"Episode reward": -99.85030050873617, "Episode length": 999, "Policy Loss": -0.8222227096557617, "Value Loss": 0.01205389853566885, "_runtime": 99.40517735481262, "_timestamp": 1585594848.421851, "_step": 62}
{"Episode reward": -99.86217530406871, "Episode length": 999, "Policy Loss": -0.8294432163238525, "Value Loss": 0.017891734838485718, "_runtime": 100.93574237823486, "_timestamp": 1585594849.952416, "_step": 63}
{"Episode reward": -99.79857616610686, "Episode length": 999, "Policy Loss": -0.8215546607971191, "Value Loss": 0.01351470872759819, "_runtime": 102.19970703125, "_timestamp": 1585594851.2163806, "_step": 64}
{"Episode reward": 18.398511373624572, "Episode length": 817, "Policy Loss": 0.12584137916564941, "Value Loss": 12.144054412841797, "_runtime": 103.36208844184875, "_timestamp": 1585594852.378762, "_step": 65}
{"Episode reward": 24.300000000000026, "Episode length": 757, "Policy Loss": 0.1637302041053772, "Value Loss": 13.103931427001953, "_runtime": 104.8884048461914, "_timestamp": 1585594853.9050784, "_step": 66}
{"Episode reward": -99.74440414048593, "Episode length": 999, "Policy Loss": -0.8162533044815063, "Value Loss": 0.029820837080478668, "_runtime": 106.44449281692505, "_timestamp": 1585594855.4611664, "_step": 67}
{"Episode reward": -99.61001852787892, "Episode length": 999, "Policy Loss": -0.8160472512245178, "Value Loss": 0.023926418274641037, "_runtime": 107.65259337425232, "_timestamp": 1585594856.669267, "_step": 68}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 0.13230296969413757, "Value Loss": 12.463990211486816, "_runtime": 109.17785048484802, "_timestamp": 1585594858.194524, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7980906963348389, "Value Loss": 0.01719617284834385, "_runtime": 110.29186010360718, "_timestamp": 1585594859.3085337, "_step": 70}
{"Episode reward": 28.199999999999804, "Episode length": 718, "Policy Loss": 0.28737378120422363, "Value Loss": 13.686909675598145, "_runtime": 111.81700897216797, "_timestamp": 1585594860.8336825, "_step": 71}
{"Episode reward": -99.84141626357892, "Episode length": 999, "Policy Loss": -0.8104632496833801, "Value Loss": 0.07926901429891586, "_runtime": 113.35742712020874, "_timestamp": 1585594862.3741007, "_step": 72}
{"Episode reward": -99.83643047846714, "Episode length": 999, "Policy Loss": -0.8040921092033386, "Value Loss": 0.09237692505121231, "_runtime": 114.85250735282898, "_timestamp": 1585594863.869181, "_step": 73}
{"Episode reward": -99.81430154442647, "Episode length": 999, "Policy Loss": -0.7729434967041016, "Value Loss": 0.10681892931461334, "_runtime": 116.37354159355164, "_timestamp": 1585594865.3902152, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7308842539787292, "Value Loss": 0.02387649193406105, "_runtime": 117.90645670890808, "_timestamp": 1585594866.9231303, "_step": 75}
{"Episode reward": -99.71908340230445, "Episode length": 999, "Policy Loss": -0.6721253991127014, "Value Loss": 0.016009140759706497, "_runtime": 119.116051197052, "_timestamp": 1585594868.1327248, "_step": 76}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 0.27842262387275696, "Value Loss": 12.589251518249512, "_runtime": 120.15459609031677, "_timestamp": 1585594869.1712697, "_step": 77}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": 0.42525461316108704, "Value Loss": 14.641993522644043, "_runtime": 121.58093738555908, "_timestamp": 1585594870.597611, "_step": 78}
{"Episode reward": 5.575499715657131, "Episode length": 945, "Policy Loss": 0.1719580739736557, "Value Loss": 10.476128578186035, "_runtime": 123.10127210617065, "_timestamp": 1585594872.1179457, "_step": 79}
{"Episode reward": -99.77165618426959, "Episode length": 999, "Policy Loss": -0.6014423966407776, "Value Loss": 0.034868452697992325, "_runtime": 124.32618832588196, "_timestamp": 1585594873.342862, "_step": 80}
{"Episode reward": 18.300000000000367, "Episode length": 817, "Policy Loss": 0.33009493350982666, "Value Loss": 12.024069786071777, "_runtime": 125.21484279632568, "_timestamp": 1585594874.2315164, "_step": 81}
{"Episode reward": 42.30267353793552, "Episode length": 577, "Policy Loss": 0.6890217661857605, "Value Loss": 17.04353141784668, "_runtime": 126.72552514076233, "_timestamp": 1585594875.7421987, "_step": 82}
{"Episode reward": -99.88431709566945, "Episode length": 999, "Policy Loss": -0.6674519777297974, "Value Loss": 0.07189778238534927, "_runtime": 127.32692670822144, "_timestamp": 1585594876.3436003, "_step": 83}
{"Episode reward": 61.799999999999734, "Episode length": 382, "Policy Loss": 1.228158712387085, "Value Loss": 25.40328025817871, "_runtime": 128.7990527153015, "_timestamp": 1585594877.8157263, "_step": 84}
{"Episode reward": -99.80732405334571, "Episode length": 999, "Policy Loss": -0.7355485558509827, "Value Loss": 0.1624825894832611, "_runtime": 130.35985612869263, "_timestamp": 1585594879.3765297, "_step": 85}
{"Episode reward": -99.72940063113208, "Episode length": 999, "Policy Loss": -0.7421379089355469, "Value Loss": 0.19014184176921844, "_runtime": 131.81818866729736, "_timestamp": 1585594880.8348622, "_step": 86}
{"Episode reward": -99.5938339078785, "Episode length": 999, "Policy Loss": -0.739370584487915, "Value Loss": 0.08534958958625793, "_runtime": 133.34984159469604, "_timestamp": 1585594882.3665152, "_step": 87}
{"Episode reward": -99.60959983421353, "Episode length": 999, "Policy Loss": -0.7321683168411255, "Value Loss": 0.05249977484345436, "_runtime": 133.8429937362671, "_timestamp": 1585594882.8596673, "_step": 88}
{"Episode reward": 70.29999999999986, "Episode length": 297, "Policy Loss": 1.6213610172271729, "Value Loss": 32.65287780761719, "_runtime": 135.2516417503357, "_timestamp": 1585594884.2683153, "_step": 89}
{"Episode reward": 5.9999983772646175, "Episode length": 941, "Policy Loss": 0.018432356417179108, "Value Loss": 10.445828437805176, "_runtime": 135.849951505661, "_timestamp": 1585594884.866625, "_step": 90}
{"Episode reward": 62.76896411757891, "Episode length": 374, "Policy Loss": 1.1495401859283447, "Value Loss": 26.03456687927246, "_runtime": 137.0249650478363, "_timestamp": 1585594886.0416386, "_step": 91}
{"Episode reward": 19.198615241051044, "Episode length": 809, "Policy Loss": 0.2603359818458557, "Value Loss": 11.98515510559082, "_runtime": 138.03266549110413, "_timestamp": 1585594887.049339, "_step": 92}
{"Episode reward": 34.0891883502709, "Episode length": 661, "Policy Loss": 0.24493731558322906, "Value Loss": 14.881644248962402, "_runtime": 139.3927185535431, "_timestamp": 1585594888.409392, "_step": 93}
{"Episode reward": 8.997481041961322, "Episode length": 911, "Policy Loss": 0.04969264194369316, "Value Loss": 10.60811996459961, "_runtime": 140.9006588459015, "_timestamp": 1585594889.9173324, "_step": 94}
{"Episode reward": -99.80170683124895, "Episode length": 999, "Policy Loss": -0.8342344760894775, "Value Loss": 0.015846850350499153, "_runtime": 141.53435349464417, "_timestamp": 1585594890.551027, "_step": 95}
{"Episode reward": 59.22010691007569, "Episode length": 408, "Policy Loss": 0.833337664604187, "Value Loss": 23.869178771972656, "_runtime": 142.373925447464, "_timestamp": 1585594891.390599, "_step": 96}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.3420643210411072, "Value Loss": 17.283308029174805, "_runtime": 143.8970606327057, "_timestamp": 1585594892.9137342, "_step": 97}
{"Episode reward": -99.80031052864948, "Episode length": 999, "Policy Loss": -0.9514943957328796, "Value Loss": 0.23802006244659424, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728, -0.05001521855592728]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-2.0469491481781006, -2.01418399810791, -1.9814189672470093, -1.9486539363861084, -1.9158889055252075, -1.8831238746643066, -1.8503587245941162, -1.8175936937332153, -1.7848286628723145, -1.752063512802124, -1.7192984819412231, -1.6865334510803223, -1.6537683010101318, -1.621003270149231, -1.58823823928833, -1.5554730892181396, -1.5227080583572388, -1.489943027496338, -1.4571778774261475, -1.4244128465652466, -1.3916478157043457, -1.3588826656341553, -1.3261176347732544, -1.2933526039123535, -1.260587453842163, -1.2278224229812622, -1.1950573921203613, -1.162292242050171, -1.12952721118927, -1.0967621803283691, -1.0639970302581787, -1.0312319993972778, -0.998466968536377, -0.9657019376754761, -0.9329367876052856, -0.9001717567443848, -0.8674067258834839, -0.8346415758132935, -0.8018765449523926, -0.7691115140914917, -0.7363464832305908, -0.7035813331604004, -0.6708163022994995, -0.6380512714385986, -0.6052861213684082, -0.5725210905075073, -0.5397560596466064, -0.506990909576416, -0.47422587871551514, -0.44146084785461426, -0.40869569778442383, -0.37593066692352295, -0.34316563606262207, -0.31040048599243164, -0.27763545513153076, -0.24487042427062988, -0.21210527420043945, -0.17934024333953857, -0.1465752124786377, -0.11381018161773682, -0.08104503154754639, -0.04828000068664551, -0.015514850616455078, 0.01725006103515625, 0.05001521110534668]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-0.07923877984285355, -0.07800067216157913, -0.07676256448030472, -0.0755244642496109, -0.07428635656833649, -0.07304824888706207, -0.07181014120578766, -0.07057204097509384, -0.06933393329381943, -0.06809582561254501, -0.0668577179312706, -0.06561961770057678, -0.06438151001930237, -0.06314340233802795, -0.06190529465675354, -0.060667190700769424, -0.05942908674478531, -0.058190979063510895, -0.05695287138223648, -0.055714767426252365, -0.05447666347026825, -0.053238555788993835, -0.05200044810771942, -0.050762344151735306, -0.04952423647046089, -0.048286132514476776, -0.04704802483320236, -0.045809920877218246, -0.04457181319594383, -0.04333370923995972, -0.0420956015586853, -0.04085749760270119, -0.03961938992142677, -0.03838128224015236, -0.03714317828416824, -0.03590507060289383, -0.034666966646909714, -0.0334288589656353, -0.032190755009651184, -0.03095264732837677, -0.029714543372392654, -0.02847643569111824, -0.027238331735134125, -0.02600022405385971, -0.024762120097875595, -0.02352401241660118, -0.022285908460617065, -0.02104780077934265, -0.019809693098068237, -0.01857158914208412, -0.017333481460809708, -0.016095377504825592, -0.014857269823551178, -0.013619162142276764, -0.012381061911582947, -0.011142954230308533, -0.009904846549034119, -0.008666738867759705, -0.0074286386370658875, -0.006190530955791473, -0.004952423274517059, -0.0037143155932426453, -0.002476215362548828, -0.001238107681274414, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 5.0, 1.0, 0.0, 1.0, 4.0, 4.0, 13.0, 8.0, 3.0, 5.0, 3.0, 11.0, 20.0, 6.0, 3.0, 7.0, 12.0, 3.0, 2.0, 6.0, 1.0, 6.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 224.0, 0.0, 3.0, 5.0, 1.0, 2.0, 3.0, 7.0, 4.0, 1.0, 5.0, 15.0, 13.0, 18.0, 26.0, 16.0, 11.0, 3.0, 6.0, 2.0, 3.0], "bins": [-0.14829561114311218, -0.1448650360107422, -0.1414344757795334, -0.1380039006471634, -0.1345733404159546, -0.1311427652835846, -0.1277122050523758, -0.1242816299200058, -0.1208510622382164, -0.117420494556427, -0.1139899268746376, -0.1105593591928482, -0.10712879151105881, -0.10369822382926941, -0.10026764869689941, -0.09683708846569061, -0.09340651333332062, -0.08997595310211182, -0.08654537796974182, -0.08311481028795242, -0.07968424260616302, -0.07625367492437363, -0.07282310724258423, -0.06939253956079483, -0.06596197187900543, -0.06253140419721603, -0.059100836515426636, -0.05567026138305664, -0.05223969370126724, -0.048809126019477844, -0.045378558337688446, -0.04194799065589905, -0.03851742297410965, -0.03508685529232025, -0.03165628761053085, -0.028225719928741455, -0.024795152246952057, -0.02136458456516266, -0.017934009432792664, -0.014503449201583862, -0.011072874069213867, -0.007642313838005066, -0.004211738705635071, -0.0007811635732650757, 0.0026493966579437256, 0.006079971790313721, 0.009510532021522522, 0.012941107153892517, 0.01637166738510132, 0.019802242517471313, 0.023232802748680115, 0.02666337788105011, 0.03009393811225891, 0.033524513244628906, 0.0369550883769989, 0.0403856486082077, 0.0438162237405777, 0.0472467839717865, 0.050677359104156494, 0.054107919335365295, 0.05753849446773529, 0.06096905469894409, 0.06439962983131409, 0.06783019006252289, 0.07126076519489288]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0], "bins": [-0.7437766790390015, -0.7296748161315918, -0.7155729532241821, -0.7014710307121277, -0.687369167804718, -0.6732673048973083, -0.6591654419898987, -0.645063579082489, -0.6309616565704346, -0.6168597936630249, -0.6027579307556152, -0.5886560678482056, -0.5745542049407959, -0.5604523420333862, -0.5463504791259766, -0.5322485566139221, -0.5181466937065125, -0.5040448307991028, -0.4899429380893707, -0.47584107518196106, -0.461739182472229, -0.44763731956481934, -0.43353545665740967, -0.4194335639476776, -0.40533170104026794, -0.3912298381328583, -0.3771279454231262, -0.36302608251571655, -0.3489242196083069, -0.33482232689857483, -0.32072046399116516, -0.3066185712814331, -0.29251670837402344, -0.27841484546661377, -0.2643129527568817, -0.25021108984947205, -0.23610919713974, -0.22200733423233032, -0.20790547132492065, -0.193803608417511, -0.17970168590545654, -0.16559982299804688, -0.1514979600906372, -0.13739609718322754, -0.12329423427581787, -0.1091923713684082, -0.09509044885635376, -0.08098858594894409, -0.06688672304153442, -0.052784860134124756, -0.03868299722671509, -0.024581074714660645, -0.010479211807250977, 0.0036226511001586914, 0.01772451400756836, 0.03182637691497803, 0.045928239822387695, 0.06003016233444214, 0.0741320252418518, 0.08823388814926147, 0.10233575105667114, 0.11643761396408081, 0.13053953647613525, 0.14464139938354492, 0.1587432622909546]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 2.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 13.0, 3.0, 6.0, 8.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.018044468015432358, -0.016373706981539726, -0.014702945947647095, -0.013032184913754463, -0.011361423879861832, -0.0096906628459692, -0.008019901812076569, -0.006349140778183937, -0.0046783797442913055, -0.003007618710398674, -0.0013368576765060425, 0.00033390335738658905, 0.0020046643912792206, 0.003675425425171852, 0.005346186459064484, 0.007016947492957115, 0.008687708526849747, 0.010358469560742378, 0.01202923059463501, 0.013699989765882492, 0.015370752662420273, 0.017041515558958054, 0.018712274730205536, 0.020383033901453018, 0.0220537967979908, 0.02372455969452858, 0.025395318865776062, 0.027066078037023544, 0.028736840933561325, 0.030407603830099106, 0.03207836300134659, 0.03374912217259407, 0.03541988506913185, 0.03709064796566963, 0.038761407136917114, 0.0404321663081646, 0.04210292920470238, 0.04377369210124016, 0.04544444754719734, 0.04711521044373512, 0.0487859733402729, 0.050456736236810684, 0.052127499133348465, 0.05379825457930565, 0.05546901747584343, 0.05713978037238121, 0.058810535818338394, 0.060481298714876175, 0.062152061611413956, 0.06382282078266144, 0.06549358367919922, 0.067164346575737, 0.06883510947227478, 0.07050587236881256, 0.07217662036418915, 0.07384738326072693, 0.07551814615726471, 0.07718890905380249, 0.07885967195034027, 0.08053043484687805, 0.08220119774341583, 0.08387196063995361, 0.0855427086353302, 0.08721347153186798, 0.08888423442840576]}, "_runtime": 145.38203978538513, "_timestamp": 1585594894.3987134, "_step": 98}
{"Episode reward": -99.80258736554394, "Episode length": 999, "Policy Loss": -0.9760029911994934, "Value Loss": 0.024219278246164322, "_runtime": 146.86386370658875, "_timestamp": 1585594895.8805373, "_step": 99}
{"Episode reward": -99.8009821982109, "Episode length": 999, "Policy Loss": -1.0040273666381836, "Value Loss": 0.05147001892328262, "_runtime": 147.37170219421387, "_timestamp": 1585594896.3883758, "_step": 100}
{"Episode reward": 68.99067648155598, "Episode length": 311, "Policy Loss": 1.228981852531433, "Value Loss": 30.702993392944336, "_runtime": 148.88318800926208, "_timestamp": 1585594897.8998616, "_step": 101}
{"Episode reward": -99.69642177317154, "Episode length": 999, "Policy Loss": -1.0431233644485474, "Value Loss": 0.02426972985267639, "_runtime": 150.41172170639038, "_timestamp": 1585594899.4283953, "_step": 102}
{"Episode reward": -99.81789066940406, "Episode length": 999, "Policy Loss": -1.0510540008544922, "Value Loss": 0.03371760994195938, "_runtime": 151.8755486011505, "_timestamp": 1585594900.8922222, "_step": 103}
{"Episode reward": -99.89570748070115, "Episode length": 999, "Policy Loss": -1.039962649345398, "Value Loss": 0.12084051221609116, "_runtime": 153.45044493675232, "_timestamp": 1585594902.4671185, "_step": 104}
{"Episode reward": -99.69589106123756, "Episode length": 999, "Policy Loss": -1.0197936296463013, "Value Loss": 0.533409833908081, "_runtime": 154.58236718177795, "_timestamp": 1585594903.5990407, "_step": 105}
{"Episode reward": 26.4999999999999, "Episode length": 735, "Policy Loss": -0.11965008080005646, "Value Loss": 14.548815727233887, "_runtime": 155.80630135536194, "_timestamp": 1585594904.822975, "_step": 106}
{"Episode reward": 19.971764011215697, "Episode length": 802, "Policy Loss": 0.005718930624425411, "Value Loss": 12.673502922058105, "_runtime": 157.33282232284546, "_timestamp": 1585594906.349496, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6603691577911377, "Value Loss": 0.20039308071136475, "_runtime": 158.83237171173096, "_timestamp": 1585594907.8490453, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5863949060440063, "Value Loss": 0.2730662524700165, "_runtime": 160.3444151878357, "_timestamp": 1585594909.3610888, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5354313850402832, "Value Loss": 0.02445106767117977, "_runtime": 161.55060267448425, "_timestamp": 1585594910.5672762, "_step": 110}
{"Episode reward": 21.863009326160125, "Episode length": 783, "Policy Loss": 0.36250463128089905, "Value Loss": 12.743536949157715, "_runtime": 162.50576615333557, "_timestamp": 1585594911.5224397, "_step": 111}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.7432845830917358, "Value Loss": 15.869891166687012, "_runtime": 164.02506518363953, "_timestamp": 1585594913.0417387, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5338366031646729, "Value Loss": 1.2051069736480713, "_runtime": 165.54856538772583, "_timestamp": 1585594914.565239, "_step": 113}
{"Episode reward": -99.67127951539449, "Episode length": 999, "Policy Loss": -0.5313921570777893, "Value Loss": 0.05960572883486748, "_runtime": 166.43373370170593, "_timestamp": 1585594915.4504073, "_step": 114}
{"Episode reward": 41.995421512773646, "Episode length": 581, "Policy Loss": 0.7981486916542053, "Value Loss": 16.91223907470703, "_runtime": 167.96232843399048, "_timestamp": 1585594916.979002, "_step": 115}
{"Episode reward": -99.85624771120352, "Episode length": 999, "Policy Loss": -0.5104319453239441, "Value Loss": 0.01830330863595009, "_runtime": 168.95269989967346, "_timestamp": 1585594917.9693735, "_step": 116}
{"Episode reward": 35.207044398388234, "Episode length": 649, "Policy Loss": 0.987648606300354, "Value Loss": 15.281185150146484, "_runtime": 170.44729042053223, "_timestamp": 1585594919.463964, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5138432383537292, "Value Loss": 0.030296850949525833, "_runtime": 171.9820761680603, "_timestamp": 1585594920.9987497, "_step": 118}
{"Episode reward": -99.77091935053329, "Episode length": 999, "Policy Loss": -0.5184774994850159, "Value Loss": 0.008563676849007607, "_runtime": 173.43777179718018, "_timestamp": 1585594922.4544454, "_step": 119}
{"Episode reward": 3.4000000000012136, "Episode length": 966, "Policy Loss": 0.2670310139656067, "Value Loss": 10.350809097290039, "_runtime": 173.9090142250061, "_timestamp": 1585594922.9256878, "_step": 120}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 2.001302719116211, "Value Loss": 34.133262634277344, "_runtime": 175.4167137145996, "_timestamp": 1585594924.4333873, "_step": 121}
{"Episode reward": -99.83172307610371, "Episode length": 999, "Policy Loss": -0.5345669388771057, "Value Loss": 0.005031153559684753, "_runtime": 176.98157930374146, "_timestamp": 1585594925.9982529, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5524490475654602, "Value Loss": 0.011650225147604942, "_runtime": 178.45613074302673, "_timestamp": 1585594927.4728043, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5625266432762146, "Value Loss": 0.0206130538135767, "_runtime": 179.98488116264343, "_timestamp": 1585594929.0015547, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5794858336448669, "Value Loss": 0.027564486488699913, "_runtime": 181.3595941066742, "_timestamp": 1585594930.3762677, "_step": 125}
{"Episode reward": 10.461018870399215, "Episode length": 897, "Policy Loss": 0.3181394934654236, "Value Loss": 11.087629318237305, "_runtime": 182.8881106376648, "_timestamp": 1585594931.9047842, "_step": 126}
{"Episode reward": -99.74646015651385, "Episode length": 999, "Policy Loss": -0.5670827627182007, "Value Loss": 0.024228306487202644, "_runtime": 184.43307876586914, "_timestamp": 1585594933.4497523, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5599194765090942, "Value Loss": 0.02686809003353119, "_runtime": 185.60944271087646, "_timestamp": 1585594934.6261163, "_step": 128}
{"Episode reward": 22.80000000000011, "Episode length": 772, "Policy Loss": 0.6480532288551331, "Value Loss": 12.900588035583496, "_runtime": 187.1431429386139, "_timestamp": 1585594936.1598165, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5442058444023132, "Value Loss": 0.012523628771305084, "_runtime": 188.6329960823059, "_timestamp": 1585594937.6496696, "_step": 130}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.3724863827228546, "Value Loss": 10.252681732177734, "_runtime": 190.1501681804657, "_timestamp": 1585594939.1668417, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5277489423751831, "Value Loss": 0.008499041199684143, "_runtime": 191.6762397289276, "_timestamp": 1585594940.6929133, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5163403153419495, "Value Loss": 0.005840879399329424, "_runtime": 193.01271104812622, "_timestamp": 1585594942.0293846, "_step": 133}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": 0.7106938362121582, "Value Loss": 11.512652397155762, "_runtime": 193.79346656799316, "_timestamp": 1585594942.8101401, "_step": 134}
{"Episode reward": 50.367754256724886, "Episode length": 498, "Policy Loss": 1.190085768699646, "Value Loss": 19.969728469848633, "_runtime": 195.06994819641113, "_timestamp": 1585594944.0866218, "_step": 135}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.44831910729408264, "Value Loss": 11.757096290588379, "_runtime": 196.59640884399414, "_timestamp": 1585594945.6130824, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5587670803070068, "Value Loss": 0.007690659258514643, "_runtime": 197.8407154083252, "_timestamp": 1585594946.857389, "_step": 137}
{"Episode reward": 16.400000000000475, "Episode length": 836, "Policy Loss": 0.40650424361228943, "Value Loss": 11.822471618652344, "_runtime": 199.38946533203125, "_timestamp": 1585594948.406139, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6227707862854004, "Value Loss": 0.041684024035930634, "_runtime": 200.92473316192627, "_timestamp": 1585594949.9414067, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6724299788475037, "Value Loss": 0.0636356994509697, "_runtime": 202.44014739990234, "_timestamp": 1585594951.456821, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6646065711975098, "Value Loss": 0.0693754330277443, "_runtime": 203.0839502811432, "_timestamp": 1585594952.1006238, "_step": 141}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.3685979843139648, "Value Loss": 24.305910110473633, "_runtime": 204.59985208511353, "_timestamp": 1585594953.6165257, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6806988716125488, "Value Loss": 0.062493231147527695, "_runtime": 206.13210082054138, "_timestamp": 1585594955.1487744, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7005288600921631, "Value Loss": 0.03754010796546936, "_runtime": 207.61285090446472, "_timestamp": 1585594956.6295245, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7024073004722595, "Value Loss": 0.050919778645038605, "_runtime": 208.8031394481659, "_timestamp": 1585594957.819813, "_step": 145}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 0.5174971222877502, "Value Loss": 12.641253471374512, "_runtime": 210.2137486934662, "_timestamp": 1585594959.2304223, "_step": 146}
{"Episode reward": 8.100000000000946, "Episode length": 919, "Policy Loss": 0.261460542678833, "Value Loss": 10.66446590423584, "_runtime": 211.7439308166504, "_timestamp": 1585594960.7606044, "_step": 147}
{"Episode reward": -99.80039368271687, "Episode length": 999, "Policy Loss": -0.6614214181900024, "Value Loss": 0.03455303981900215, "_runtime": 213.2574179172516, "_timestamp": 1585594962.2740915, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6948969960212708, "Value Loss": 0.09223078936338425, "_runtime": 214.77890920639038, "_timestamp": 1585594963.7955828, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6747070550918579, "Value Loss": 0.07145964354276657, "_runtime": 215.85554099082947, "_timestamp": 1585594964.8722146, "_step": 150}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": 0.7215922474861145, "Value Loss": 14.097540855407715, "_runtime": 217.37590646743774, "_timestamp": 1585594966.39258, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6085028648376465, "Value Loss": 0.045120883733034134, "_runtime": 218.17666935920715, "_timestamp": 1585594967.193343, "_step": 152}
{"Episode reward": 48.99999999999955, "Episode length": 510, "Policy Loss": 1.1888922452926636, "Value Loss": 19.359970092773438, "_runtime": 219.68578553199768, "_timestamp": 1585594968.702459, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5974633097648621, "Value Loss": 0.012550483457744122, "_runtime": 221.25344514846802, "_timestamp": 1585594970.2701187, "_step": 154}
{"Episode reward": -99.80149309784035, "Episode length": 999, "Policy Loss": -0.5924796462059021, "Value Loss": 0.006399673409759998, "_runtime": 222.7429714202881, "_timestamp": 1585594971.759645, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5935030579566956, "Value Loss": 0.02254478447139263, "_runtime": 224.2580919265747, "_timestamp": 1585594973.2747655, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.577393651008606, "Value Loss": 0.011548390612006187, "_runtime": 225.28842163085938, "_timestamp": 1585594974.3050952, "_step": 157}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.7289120554924011, "Value Loss": 14.609540939331055, "_runtime": 226.79296946525574, "_timestamp": 1585594975.809643, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5635838508605957, "Value Loss": 0.0061884066089987755, "_runtime": 228.3187620639801, "_timestamp": 1585594977.3354356, "_step": 159}
{"Episode reward": -99.8000186920152, "Episode length": 999, "Policy Loss": -0.5712021589279175, "Value Loss": 0.027290143072605133, "_runtime": 229.2154505252838, "_timestamp": 1585594978.232124, "_step": 160}
{"Episode reward": 40.89999999999944, "Episode length": 591, "Policy Loss": 0.9694075584411621, "Value Loss": 16.748374938964844, "_runtime": 230.39642000198364, "_timestamp": 1585594979.4130936, "_step": 161}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.6141889691352844, "Value Loss": 12.679251670837402, "_runtime": 231.91313099861145, "_timestamp": 1585594980.9298046, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5901868343353271, "Value Loss": 0.07014027237892151, "_runtime": 232.53607988357544, "_timestamp": 1585594981.5527534, "_step": 163}
{"Episode reward": 59.1999999999997, "Episode length": 408, "Policy Loss": 1.8120709657669067, "Value Loss": 24.08273696899414, "_runtime": 234.01655387878418, "_timestamp": 1585594983.0332274, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6559839248657227, "Value Loss": 0.02012116089463234, "_runtime": 235.53752303123474, "_timestamp": 1585594984.5541966, "_step": 165}
{"Episode reward": -99.8138890877352, "Episode length": 999, "Policy Loss": -0.7358435392379761, "Value Loss": 0.08914874494075775, "_runtime": 236.99558186531067, "_timestamp": 1585594986.0122554, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7218759059906006, "Value Loss": 0.09710071980953217, "_runtime": 238.1306812763214, "_timestamp": 1585594987.1473548, "_step": 167}
{"Episode reward": 25.29999999999997, "Episode length": 747, "Policy Loss": 0.47552239894866943, "Value Loss": 13.046874046325684, "_runtime": 239.6518750190735, "_timestamp": 1585594988.6685486, "_step": 168}
{"Episode reward": -99.86581740975241, "Episode length": 999, "Policy Loss": -0.7382163405418396, "Value Loss": 0.14635643362998962, "_runtime": 241.158616065979, "_timestamp": 1585594990.1752896, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7641531825065613, "Value Loss": 0.08458995819091797, "_runtime": 241.64666771888733, "_timestamp": 1585594990.6633413, "_step": 170}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 2.0577502250671387, "Value Loss": 31.129878997802734, "_runtime": 243.1528766155243, "_timestamp": 1585594992.1695502, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7464798092842102, "Value Loss": 0.06065726280212402, "_runtime": 244.70701050758362, "_timestamp": 1585594993.723684, "_step": 172}
{"Episode reward": -99.89670724868634, "Episode length": 999, "Policy Loss": -0.7252720594406128, "Value Loss": 0.02180955372750759, "_runtime": 246.16903972625732, "_timestamp": 1585594995.1857133, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7096224427223206, "Value Loss": 0.03017868660390377, "_runtime": 246.89572882652283, "_timestamp": 1585594995.9124024, "_step": 174}
{"Episode reward": 53.69999999999962, "Episode length": 463, "Policy Loss": 1.201777696609497, "Value Loss": 21.036914825439453, "_runtime": 247.74194264411926, "_timestamp": 1585594996.7586162, "_step": 175}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 0.8260346055030823, "Value Loss": 17.63559913635254, "_runtime": 248.91650485992432, "_timestamp": 1585594997.9331784, "_step": 176}
{"Episode reward": 21.60000000000018, "Episode length": 784, "Policy Loss": 0.28351640701293945, "Value Loss": 12.360686302185059, "_runtime": 250.39247822761536, "_timestamp": 1585594999.4091518, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9011458158493042, "Value Loss": 0.09050212800502777, "_runtime": 250.71185302734375, "_timestamp": 1585594999.7285266, "_step": 178}
{"Episode reward": 80.5, "Episode length": 195, "Policy Loss": 3.5365962982177734, "Value Loss": 48.86792755126953, "_runtime": 252.15108156204224, "_timestamp": 1585595001.1677551, "_step": 179}
{"Episode reward": 2.5000000000012648, "Episode length": 975, "Policy Loss": -0.16646124422550201, "Value Loss": 10.415359497070312, "_runtime": 253.65123558044434, "_timestamp": 1585595002.6679091, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0950887203216553, "Value Loss": 0.2923257648944855, "_runtime": 255.10335516929626, "_timestamp": 1585595004.1200287, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1046453714370728, "Value Loss": 0.11608906835317612, "_runtime": 256.62260389328003, "_timestamp": 1585595005.6392775, "_step": 182}
{"Episode reward": -99.8171852350221, "Episode length": 999, "Policy Loss": -1.092313289642334, "Value Loss": 0.018684139475226402, "_runtime": 258.1375889778137, "_timestamp": 1585595007.1542625, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.059570550918579, "Value Loss": 0.017588229849934578, "_runtime": 258.83157086372375, "_timestamp": 1585595007.8482444, "_step": 184}
{"Episode reward": 55.39999999999964, "Episode length": 446, "Policy Loss": 0.9882588982582092, "Value Loss": 22.10029411315918, "_runtime": 260.34037160873413, "_timestamp": 1585595009.3570452, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.997342586517334, "Value Loss": 0.07164542376995087, "_runtime": 261.86740469932556, "_timestamp": 1585595010.8840783, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9913458824157715, "Value Loss": 0.013811769895255566, "_runtime": 263.34175729751587, "_timestamp": 1585595012.3584309, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9666754007339478, "Value Loss": 0.012769809924066067, "_runtime": 264.8686304092407, "_timestamp": 1585595013.885304, "_step": 188}
{"Episode reward": -99.88372964858868, "Episode length": 999, "Policy Loss": -0.931607186794281, "Value Loss": 0.01604081504046917, "_runtime": 266.3577251434326, "_timestamp": 1585595015.3743987, "_step": 189}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": -0.0037202294915914536, "Value Loss": 10.029438972473145, "_runtime": 267.7433850765228, "_timestamp": 1585595016.7600586, "_step": 190}
{"Episode reward": 11.183614897728745, "Episode length": 889, "Policy Loss": 0.07900278270244598, "Value Loss": 10.941153526306152, "_runtime": 269.27049136161804, "_timestamp": 1585595018.287165, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9235748648643494, "Value Loss": 0.08446189016103745, "_runtime": 270.78720355033875, "_timestamp": 1585595019.803877, "_step": 192}
{"Episode reward": -99.81261845230917, "Episode length": 999, "Policy Loss": -0.880155086517334, "Value Loss": 0.01612154394388199, "_runtime": 271.70107412338257, "_timestamp": 1585595020.7177477, "_step": 193}
{"Episode reward": 39.36808412074984, "Episode length": 607, "Policy Loss": 0.5441778898239136, "Value Loss": 15.91639518737793, "_runtime": 272.43280577659607, "_timestamp": 1585595021.4494793, "_step": 194}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.111128330230713, "Value Loss": 20.4586238861084, "_runtime": 272.80476355552673, "_timestamp": 1585595021.8214371, "_step": 195}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 2.84641695022583, "Value Loss": 43.626155853271484, "_runtime": 273.9807679653168, "_timestamp": 1585595022.9974415, "_step": 196}
{"Episode reward": 19.600000000000293, "Episode length": 804, "Policy Loss": -0.033018533140420914, "Value Loss": 11.931253433227539, "_runtime": 275.39952969551086, "_timestamp": 1585595024.4162033, "_step": 197}
{"Episode reward": 4.088166803122746, "Episode length": 960, "Policy Loss": -0.2721879184246063, "Value Loss": 10.750418663024902, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268, 0.05208773538470268]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 1.0], "bins": [-0.05208773538470268, 0.015283975750207901, 0.08265568315982819, 0.15002739429473877, 0.21739910542964935, 0.2847708463668823, 0.3521425426006317, 0.4195142388343811, 0.4868859648704529, 0.5542576909065247, 0.6216294169425964, 0.6890010833740234, 0.7563728094100952, 0.823744535446167, 0.891116201877594, 0.9584879279136658, 1.0258595943450928, 1.0932313203811646, 1.1606030464172363, 1.227974772453308, 1.2953464984893799, 1.362718105316162, 1.4300898313522339, 1.4974615573883057, 1.5648332834243774, 1.6322050094604492, 1.699576735496521, 1.7669484615325928, 1.834320068359375, 1.9016917943954468, 1.9690635204315186, 2.03643536567688, 2.103806972503662, 2.1711785793304443, 2.2385504245758057, 2.305922031402588, 2.373293876647949, 2.4406654834747314, 2.5080373287200928, 2.575408935546875, 2.6427807807922363, 2.7101523876190186, 2.777523994445801, 2.844895839691162, 2.9122674465179443, 2.9796392917633057, 3.047010898590088, 3.114382743835449, 3.1817543506622314, 3.2491259574890137, 3.316497802734375, 3.3838694095611572, 3.4512412548065186, 3.518612861633301, 3.585984706878662, 3.6533563137054443, 3.7207279205322266, 3.788099765777588, 3.85547137260437, 3.9228432178497314, 3.9902148246765137, 4.057586669921875, 4.124958515167236, 4.1923298835754395, 4.259701728820801]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.518499958474422e-06, 0.0022547603584825993, 0.0045160395093262196, 0.0067773181945085526, 0.009038597345352173, 0.011299876496195793, 0.013561154715716839, 0.015822432935237885, 0.018083712086081505, 0.020344991236925125, 0.022606270387768745, 0.024867549538612366, 0.027128826826810837, 0.029390105977654457, 0.03165138512849808, 0.03391266614198685, 0.03617394343018532, 0.03843522071838379, 0.04069650173187256, 0.04295777902007103, 0.0452190600335598, 0.04748033732175827, 0.04974161833524704, 0.05200289562344551, 0.05426417291164398, 0.05652545392513275, 0.05878673121333122, 0.06104801222681999, 0.06330928951501846, 0.06557057052850723, 0.067831851541996, 0.07009312510490417, 0.07235440611839294, 0.07461568713188171, 0.07687696069478989, 0.07913824170827866, 0.08139952272176743, 0.0836608037352562, 0.08592207729816437, 0.08818335831165314, 0.0904446393251419, 0.09270591288805008, 0.09496719390153885, 0.09722847491502762, 0.09948975592851639, 0.10175102949142456, 0.10401231050491333, 0.1062735915184021, 0.10853486508131027, 0.11079614609479904, 0.11305742710828781, 0.11531870812177658, 0.11757998168468475, 0.11984126269817352, 0.12210254371166229, 0.12436382472515106, 0.12662510573863983, 0.1288863867521286, 0.13114766776561737, 0.13340894877910614, 0.1356702297925949, 0.13793149590492249, 0.14019277691841125, 0.14245405793190002, 0.1447153389453888]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 5.0, 13.0, 14.0, 41.0, 19.0, 19.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 224.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 5.0, 9.0, 7.0, 9.0, 2.0, 6.0, 4.0, 2.0, 4.0, 9.0, 4.0, 9.0, 6.0, 9.0, 10.0, 7.0, 4.0, 3.0, 11.0, 3.0, 3.0, 4.0, 1.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.12476679682731628, -0.11756845563650131, -0.11037012189626694, -0.10317178070545197, -0.09597344696521759, -0.08877510577440262, -0.08157676458358765, -0.07437843084335327, -0.0671800971031189, -0.059981755912303925, -0.05278341472148895, -0.04558508098125458, -0.038386739790439606, -0.03118840605020523, -0.02399006485939026, -0.016791731119155884, -0.009593389928340912, -0.00239504873752594, 0.004803285002708435, 0.01200161874294281, 0.01919996738433838, 0.026398301124572754, 0.03359663486480713, 0.040794968605041504, 0.04799331724643707, 0.05519165098667145, 0.06238998472690582, 0.06958833336830139, 0.07678666710853577, 0.08398500084877014, 0.09118333458900452, 0.09838168323040009, 0.10558001697063446, 0.11277835071086884, 0.1199766993522644, 0.12717503309249878, 0.13437336683273315, 0.14157170057296753, 0.1487700343132019, 0.15596836805343628, 0.16316673159599304, 0.17036506533622742, 0.1775633990764618, 0.18476173281669617, 0.19196006655693054, 0.19915840029716492, 0.2063567340373993, 0.21355509757995605, 0.22075343132019043, 0.2279517650604248, 0.23515009880065918, 0.24234843254089355, 0.24954676628112793, 0.2567451000213623, 0.26394346356391907, 0.27114179730415344, 0.2783401310443878, 0.2855384647846222, 0.29273679852485657, 0.29993513226509094, 0.3071334660053253, 0.3143318295478821, 0.32153016328811646, 0.32872849702835083, 0.3359268307685852]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0], "bins": [-0.9698150753974915, -0.9122957587242126, -0.8547764420509338, -0.7972571849822998, -0.739737868309021, -0.6822185516357422, -0.6246992349624634, -0.5671799182891846, -0.5096606016159058, -0.45214134454727173, -0.3946220278739929, -0.3371027112007141, -0.2795833945274353, -0.2220640778541565, -0.16454482078552246, -0.10702550411224365, -0.049506187438964844, 0.008013129234313965, 0.065532386302948, 0.1230517029762268, 0.18057101964950562, 0.23809033632278442, 0.29560965299606323, 0.35312896966934204, 0.41064828634262085, 0.46816760301589966, 0.5256869196891785, 0.5832061171531677, 0.6407254338264465, 0.6982447504997253, 0.7557640671730042, 0.813283383846283, 0.8708027005195618, 0.9283220171928406, 0.9858413338661194, 1.043360710144043, 1.1008799076080322, 1.1583993434906006, 1.2159185409545898, 1.2734379768371582, 1.3309571743011475, 1.3884766101837158, 1.445995807647705, 1.5035150051116943, 1.5610344409942627, 1.618553638458252, 1.6760730743408203, 1.7335922718048096, 1.791111707687378, 1.8486309051513672, 1.9061503410339355, 1.9636695384979248, 2.021188974380493, 2.0787081718444824, 2.1362273693084717, 2.19374680519104, 2.2512660026550293, 2.3087854385375977, 2.366304636001587, 2.4238240718841553, 2.4813432693481445, 2.538862705230713, 2.596381902694702, 2.6539013385772705, 2.7114205360412598]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0], "bins": [-1.1071269512176514, -1.0585862398147583, -1.0100454092025757, -0.9615046977996826, -0.9129639863967896, -0.8644232153892517, -0.8158824443817139, -0.7673417329788208, -0.718800961971283, -0.6702601909637451, -0.621719479560852, -0.5731787085533142, -0.5246379375457764, -0.4760972261428833, -0.42755645513534546, -0.3790157437324524, -0.33047497272491455, -0.2819342017173767, -0.23339349031448364, -0.1848527193069458, -0.13631200790405273, -0.08777117729187012, -0.03923046588897705, 0.009310245513916016, 0.05785107612609863, 0.1063917875289917, 0.15493249893188477, 0.20347321033477783, 0.25201404094696045, 0.3005547523498535, 0.3490954637527466, 0.3976362943649292, 0.44617700576782227, 0.49471771717071533, 0.543258547782898, 0.591799259185791, 0.6403399705886841, 0.6888808012008667, 0.7374215126037598, 0.7859622240066528, 0.8345029354095459, 0.8830437660217285, 0.9315845966339111, 0.9801251888275146, 1.0286660194396973, 1.0772068500518799, 1.1257474422454834, 1.174288272857666, 1.2228291034698486, 1.2713696956634521, 1.3199105262756348, 1.3684511184692383, 1.416991949081421, 1.4655327796936035, 1.514073371887207, 1.5626142024993896, 1.6111550331115723, 1.6596956253051758, 1.7082364559173584, 1.756777286529541, 1.8053178787231445, 1.8538587093353271, 1.9023995399475098, 1.9509401321411133, 1.999480962753296]}, "_runtime": 276.3258697986603, "_timestamp": 1585595025.3425434, "_step": 198}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.07566241174936295, "Value Loss": 15.514008522033691, "_runtime": 277.81137323379517, "_timestamp": 1585595026.8280468, "_step": 199}
{"Episode reward": -99.84168382286886, "Episode length": 999, "Policy Loss": -0.9984151721000671, "Value Loss": 0.01650994084775448, "_runtime": 279.3109941482544, "_timestamp": 1585595028.3276677, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8992980122566223, "Value Loss": 0.02514936588704586, "_runtime": 280.7924921512604, "_timestamp": 1585595029.8091657, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8094929456710815, "Value Loss": 0.037949346005916595, "_runtime": 281.64750480651855, "_timestamp": 1585595030.6641784, "_step": 202}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 1.081587553024292, "Value Loss": 17.73949432373047, "_runtime": 282.3457772731781, "_timestamp": 1585595031.3624508, "_step": 203}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 1.3198193311691284, "Value Loss": 22.12491798400879, "_runtime": 283.8507332801819, "_timestamp": 1585595032.8674068, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5984472036361694, "Value Loss": 0.008735043928027153, "_runtime": 285.0690200328827, "_timestamp": 1585595034.0856936, "_step": 205}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.5489341616630554, "Value Loss": 11.921794891357422, "_runtime": 286.53713822364807, "_timestamp": 1585595035.5538118, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5308308601379395, "Value Loss": 0.016457276418805122, "_runtime": 287.7523510456085, "_timestamp": 1585595036.7690246, "_step": 207}
{"Episode reward": 20.100000000000264, "Episode length": 799, "Policy Loss": 0.4816347062587738, "Value Loss": 12.324570655822754, "_runtime": 289.24971985816956, "_timestamp": 1585595038.2663934, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6150418519973755, "Value Loss": 0.22032254934310913, "_runtime": 290.4890294075012, "_timestamp": 1585595039.505703, "_step": 209}
{"Episode reward": 21.042275619507038, "Episode length": 790, "Policy Loss": 0.568051278591156, "Value Loss": 12.439844131469727, "_runtime": 291.99965238571167, "_timestamp": 1585595041.016326, "_step": 210}
{"Episode reward": -99.87389450669149, "Episode length": 999, "Policy Loss": -0.6638913750648499, "Value Loss": 0.1305004507303238, "_runtime": 293.51374864578247, "_timestamp": 1585595042.5304222, "_step": 211}
{"Episode reward": -99.89427385926108, "Episode length": 999, "Policy Loss": -0.3739238679409027, "Value Loss": 0.0039094421081244946, "_runtime": 295.0150957107544, "_timestamp": 1585595044.0317693, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32624495029449463, "Value Loss": 0.0015326064312830567, "_runtime": 295.93725633621216, "_timestamp": 1585595044.95393, "_step": 213}
{"Episode reward": 40.19999999999943, "Episode length": 598, "Policy Loss": 1.605992317199707, "Value Loss": 16.876375198364258, "_runtime": 297.1849434375763, "_timestamp": 1585595046.201617, "_step": 214}
{"Episode reward": 17.581450217869545, "Episode length": 825, "Policy Loss": 0.9233793020248413, "Value Loss": 12.163769721984863, "_runtime": 298.40094900131226, "_timestamp": 1585595047.4176226, "_step": 215}
{"Episode reward": 20.100000000000264, "Episode length": 799, "Policy Loss": 0.5594432950019836, "Value Loss": 12.3509521484375, "_runtime": 299.1246931552887, "_timestamp": 1585595048.1413667, "_step": 216}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": 0.793052613735199, "Value Loss": 20.41823959350586, "_runtime": 299.43183493614197, "_timestamp": 1585595048.4485085, "_step": 217}
{"Episode reward": 82.0878814171054, "Episode length": 180, "Policy Loss": -1.0942988395690918, "Value Loss": 53.19705581665039, "_runtime": 299.85965299606323, "_timestamp": 1585595048.8763266, "_step": 218}
{"Episode reward": 72.29999999999988, "Episode length": 277, "Policy Loss": -1.0323429107666016, "Value Loss": 35.21979522705078, "_runtime": 300.2346704006195, "_timestamp": 1585595049.251344, "_step": 219}
{"Episode reward": 74.59999999999991, "Episode length": 254, "Policy Loss": -1.0319839715957642, "Value Loss": 36.63227081298828, "_runtime": 300.593492269516, "_timestamp": 1585595049.6101658, "_step": 220}
{"Episode reward": 74.44491577148429, "Episode length": 256, "Policy Loss": 0.9815601110458374, "Value Loss": 36.246891021728516, "_runtime": 300.860063791275, "_timestamp": 1585595049.8767374, "_step": 221}
{"Episode reward": 81.76292360589689, "Episode length": 183, "Policy Loss": -0.6479140520095825, "Value Loss": 52.01531982421875, "_runtime": 301.3460304737091, "_timestamp": 1585595050.362704, "_step": 222}
{"Episode reward": 65.31343657961692, "Episode length": 347, "Policy Loss": -2.105318069458008, "Value Loss": 25.831588745117188, "_runtime": 301.83858847618103, "_timestamp": 1585595050.855262, "_step": 223}
{"Episode reward": 64.64370965234352, "Episode length": 354, "Policy Loss": -2.7078280448913574, "Value Loss": 25.608356475830078, "_runtime": 302.27856945991516, "_timestamp": 1585595051.295243, "_step": 224}
{"Episode reward": 68.5238321926443, "Episode length": 315, "Policy Loss": -5.13197660446167, "Value Loss": 29.13899040222168, "_runtime": 302.7426874637604, "_timestamp": 1585595051.759361, "_step": 225}
{"Episode reward": 67.19992008408701, "Episode length": 329, "Policy Loss": -3.722867012023926, "Value Loss": 28.082075119018555, "_runtime": 303.6181390285492, "_timestamp": 1585595052.6348126, "_step": 226}
{"Episode reward": 37.89515054225861, "Episode length": 622, "Policy Loss": -4.731546401977539, "Value Loss": 15.399996757507324, "_runtime": 304.15359902381897, "_timestamp": 1585595053.1702726, "_step": 227}
{"Episode reward": 63.29487135017637, "Episode length": 368, "Policy Loss": -6.125667572021484, "Value Loss": 27.4047794342041, "_runtime": 304.683646440506, "_timestamp": 1585595053.70032, "_step": 228}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": -0.37208235263824463, "Value Loss": 26.362964630126953, "_runtime": 305.27333521842957, "_timestamp": 1585595054.2900088, "_step": 229}
{"Episode reward": 59.099999999999696, "Episode length": 409, "Policy Loss": 7.815741062164307, "Value Loss": 25.36745262145996, "_runtime": 306.1257688999176, "_timestamp": 1585595055.1424425, "_step": 230}
{"Episode reward": 39.673501132428065, "Episode length": 604, "Policy Loss": -0.339964359998703, "Value Loss": 16.08277130126953, "_runtime": 306.4875783920288, "_timestamp": 1585595055.504252, "_step": 231}
{"Episode reward": 76.09627320015909, "Episode length": 240, "Policy Loss": -0.1297077089548111, "Value Loss": 40.343223571777344, "_runtime": 306.9578700065613, "_timestamp": 1585595055.9745436, "_step": 232}
{"Episode reward": 67.29999999999981, "Episode length": 327, "Policy Loss": -3.121455430984497, "Value Loss": 29.77743911743164, "_runtime": 307.3194670677185, "_timestamp": 1585595056.3361406, "_step": 233}
{"Episode reward": 75.69999999999993, "Episode length": 243, "Policy Loss": 3.4755170345306396, "Value Loss": 39.92366409301758, "_runtime": 307.64004588127136, "_timestamp": 1585595056.6567194, "_step": 234}
{"Episode reward": 77.39999999999995, "Episode length": 226, "Policy Loss": 6.41628885269165, "Value Loss": 43.39219665527344, "_runtime": 307.8851454257965, "_timestamp": 1585595056.901819, "_step": 235}
{"Episode reward": 83.20000000000005, "Episode length": 168, "Policy Loss": -0.9813401103019714, "Value Loss": 56.48857879638672, "_runtime": 308.22348642349243, "_timestamp": 1585595057.24016, "_step": 236}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": -7.721729278564453, "Value Loss": 41.5675163269043, "_runtime": 308.45195508003235, "_timestamp": 1585595057.4686286, "_step": 237}
{"Episode reward": 84.10000000000005, "Episode length": 159, "Policy Loss": -4.83815336227417, "Value Loss": 59.66366195678711, "_runtime": 308.790851354599, "_timestamp": 1585595057.807525, "_step": 238}
{"Episode reward": 75.49999999999993, "Episode length": 245, "Policy Loss": -5.387476444244385, "Value Loss": 39.548316955566406, "_runtime": 309.0757677555084, "_timestamp": 1585595058.0924413, "_step": 239}
{"Episode reward": 79.89999999999999, "Episode length": 201, "Policy Loss": 2.7278709411621094, "Value Loss": 48.23943328857422, "_runtime": 309.50208950042725, "_timestamp": 1585595058.518763, "_step": 240}
{"Episode reward": 68.89999999999984, "Episode length": 311, "Policy Loss": 5.218124866485596, "Value Loss": 31.841873168945312, "_runtime": 309.91242814064026, "_timestamp": 1585595058.9291017, "_step": 241}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 4.842517375946045, "Value Loss": 32.56714630126953, "_runtime": 310.15325713157654, "_timestamp": 1585595059.1699307, "_step": 242}
{"Episode reward": 83.40000000000003, "Episode length": 166, "Policy Loss": 0.8075757026672363, "Value Loss": 57.33168411254883, "_runtime": 311.3197441101074, "_timestamp": 1585595060.3364177, "_step": 243}
{"Episode reward": 16.600000000000463, "Episode length": 834, "Policy Loss": -1.6303564310073853, "Value Loss": 11.741683959960938, "_runtime": 312.5684423446655, "_timestamp": 1585595061.585116, "_step": 244}
{"Episode reward": 12.80000000000068, "Episode length": 872, "Policy Loss": -8.835846900939941, "Value Loss": 17.32640838623047, "_runtime": 314.00477290153503, "_timestamp": 1585595063.0214465, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030250033363699913, "Value Loss": 1.2188493013381958, "_runtime": 315.4869556427002, "_timestamp": 1585595064.5036292, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.6236371994018555, "Value Loss": 1.5163005590438843, "_runtime": 317.0119786262512, "_timestamp": 1585595066.0286522, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2320452779531479, "Value Loss": 0.12005790323019028, "_runtime": 318.50669145584106, "_timestamp": 1585595067.523365, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.130570411682129, "Value Loss": 0.47850310802459717, "_runtime": 320.0260338783264, "_timestamp": 1585595069.0427074, "_step": 249}
{"Episode reward": -99.80231760854227, "Episode length": 999, "Policy Loss": -2.641430377960205, "Value Loss": 0.26103371381759644, "_runtime": 321.54825592041016, "_timestamp": 1585595070.5649295, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7511489391326904, "Value Loss": 0.03650039806962013, "_runtime": 323.0588655471802, "_timestamp": 1585595072.075539, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7566313147544861, "Value Loss": 0.19517011940479279, "_runtime": 324.57632541656494, "_timestamp": 1585595073.592999, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.121718883514404, "Value Loss": 1.2250539064407349, "_runtime": 326.0835497379303, "_timestamp": 1585595075.1002233, "_step": 253}
{"Episode reward": -99.69559140709615, "Episode length": 999, "Policy Loss": 2.037238836288452, "Value Loss": 0.1795167624950409, "_runtime": 327.6131417751312, "_timestamp": 1585595076.6298153, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2473533153533936, "Value Loss": 0.8325824737548828, "_runtime": 329.143728017807, "_timestamp": 1585595078.1604016, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3671154975891113, "Value Loss": 0.2429770529270172, "_runtime": 330.67530846595764, "_timestamp": 1585595079.691982, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4344265460968018, "Value Loss": 1.2925487756729126, "_runtime": 332.19595289230347, "_timestamp": 1585595081.2126265, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.716278553009033, "Value Loss": 0.11251406371593475, "_runtime": 333.71891498565674, "_timestamp": 1585595082.7355886, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8452260494232178, "Value Loss": 0.37187525629997253, "_runtime": 335.24322748184204, "_timestamp": 1585595084.259901, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.897219657897949, "Value Loss": 0.1064542680978775, "_runtime": 336.7650487422943, "_timestamp": 1585595085.7817223, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9182281494140625, "Value Loss": 0.6448301672935486, "_runtime": 338.29088306427, "_timestamp": 1585595087.3075566, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8022828102111816, "Value Loss": 0.07308536767959595, "_runtime": 339.87103819847107, "_timestamp": 1585595088.8877118, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.671788215637207, "Value Loss": 0.07401643693447113, "_runtime": 341.3850841522217, "_timestamp": 1585595090.4017577, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5241479873657227, "Value Loss": 0.07518625259399414, "_runtime": 342.9080617427826, "_timestamp": 1585595091.9247353, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.370551347732544, "Value Loss": 0.05255405604839325, "_runtime": 344.42054414749146, "_timestamp": 1585595093.4372177, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.208062171936035, "Value Loss": 0.10853838175535202, "_runtime": 345.93062448501587, "_timestamp": 1585595094.947298, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0682361125946045, "Value Loss": 0.08888068050146103, "_runtime": 347.44350266456604, "_timestamp": 1585595096.4601762, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.914346694946289, "Value Loss": 0.06310097873210907, "_runtime": 348.9675250053406, "_timestamp": 1585595097.9841986, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7713267803192139, "Value Loss": 0.06150134280323982, "_runtime": 350.4985897541046, "_timestamp": 1585595099.5152633, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6361217498779297, "Value Loss": 0.040623001754283905, "_runtime": 352.0341148376465, "_timestamp": 1585595101.0507884, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.504425048828125, "Value Loss": 0.17271743714809418, "_runtime": 353.5612189769745, "_timestamp": 1585595102.5778925, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.370291829109192, "Value Loss": 0.07687617093324661, "_runtime": 355.0757303237915, "_timestamp": 1585595104.092404, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2493255138397217, "Value Loss": 0.13249540328979492, "_runtime": 356.6019859313965, "_timestamp": 1585595105.6186595, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1474711894989014, "Value Loss": 0.030601972714066505, "_runtime": 358.13804173469543, "_timestamp": 1585595107.1547153, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0463792085647583, "Value Loss": 0.02391641028225422, "_runtime": 359.661691904068, "_timestamp": 1585595108.6783655, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9490562677383423, "Value Loss": 0.09049561619758606, "_runtime": 361.1993317604065, "_timestamp": 1585595110.2160053, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8630593419075012, "Value Loss": 0.006893569137901068, "_runtime": 362.77142667770386, "_timestamp": 1585595111.7881002, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7782835364341736, "Value Loss": 0.006499817594885826, "_runtime": 364.29709815979004, "_timestamp": 1585595113.3137717, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.696088969707489, "Value Loss": 0.00443416740745306, "_runtime": 365.8255138397217, "_timestamp": 1585595114.8421874, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6171785593032837, "Value Loss": 0.005423178896307945, "_runtime": 367.36145544052124, "_timestamp": 1585595116.378129, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5391391515731812, "Value Loss": 0.014324644580483437, "_runtime": 368.8981375694275, "_timestamp": 1585595117.9148111, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.46897533535957336, "Value Loss": 0.006365887820720673, "_runtime": 370.42208981513977, "_timestamp": 1585595119.4387634, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39712879061698914, "Value Loss": 0.005549928639084101, "_runtime": 371.95886039733887, "_timestamp": 1585595120.975534, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.333545982837677, "Value Loss": 0.005693526938557625, "_runtime": 373.49743723869324, "_timestamp": 1585595122.5141108, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2661936283111572, "Value Loss": 0.00214166147634387, "_runtime": 375.02241492271423, "_timestamp": 1585595124.0390885, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21438519656658173, "Value Loss": 0.0005311801796779037, "_runtime": 376.5451867580414, "_timestamp": 1585595125.5618603, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1600811779499054, "Value Loss": 0.024288360029459, "_runtime": 378.08128929138184, "_timestamp": 1585595127.0979629, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11774123460054398, "Value Loss": 0.009429150260984898, "_runtime": 379.6064965724945, "_timestamp": 1585595128.6231701, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06927616894245148, "Value Loss": 0.0003201269719284028, "_runtime": 381.13265204429626, "_timestamp": 1585595130.1493256, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03932778537273407, "Value Loss": 0.010860249400138855, "_runtime": 382.6715831756592, "_timestamp": 1585595131.6882567, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0023455657064914703, "Value Loss": 0.04094754904508591, "_runtime": 384.205082654953, "_timestamp": 1585595133.2217562, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02405553124845028, "Value Loss": 0.011288944631814957, "_runtime": 385.77780318260193, "_timestamp": 1585595134.7944767, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.053364720195531845, "Value Loss": 0.1001848578453064, "_runtime": 387.29287600517273, "_timestamp": 1585595136.3095496, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06680163741111755, "Value Loss": 0.0024034567177295685, "_runtime": 388.82006001472473, "_timestamp": 1585595137.8367336, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08042282611131668, "Value Loss": 0.001904709148220718, "_runtime": 390.3578689098358, "_timestamp": 1585595139.3745425, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09494413435459137, "Value Loss": 0.0021757003851234913, "_runtime": 391.88278818130493, "_timestamp": 1585595140.8994617, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10219014436006546, "Value Loss": 0.013291977345943451, "_runtime": 393.39745903015137, "_timestamp": 1585595142.4141326, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10893286764621735, "Value Loss": 0.00017986576131079346, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 394.92531991004944, "_timestamp": 1585595143.9419935, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.116350919008255, "Value Loss": 0.009431914426386356, "_runtime": 396.45330333709717, "_timestamp": 1585595145.469977, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11317172646522522, "Value Loss": 0.004295901861041784, "_runtime": 397.9815480709076, "_timestamp": 1585595146.9982216, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11131123453378677, "Value Loss": 0.0010946636321023107, "_runtime": 399.50929284095764, "_timestamp": 1585595148.5259664, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10978154838085175, "Value Loss": 0.00016452468116767704, "_runtime": 401.04850673675537, "_timestamp": 1585595150.0651803, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10561949014663696, "Value Loss": 0.002929867245256901, "_runtime": 402.59272956848145, "_timestamp": 1585595151.6094031, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09974480420351028, "Value Loss": 0.002285397844389081, "_runtime": 404.14167046546936, "_timestamp": 1585595153.158344, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09205348789691925, "Value Loss": 0.0013743825256824493, "_runtime": 405.6824674606323, "_timestamp": 1585595154.699141, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08380130678415298, "Value Loss": 0.0001975392224267125, "_runtime": 407.256272315979, "_timestamp": 1585595156.272946, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07641968131065369, "Value Loss": 0.0037367495242506266, "_runtime": 408.80146074295044, "_timestamp": 1585595157.8181343, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06882115453481674, "Value Loss": 0.006041886750608683, "_runtime": 410.35046911239624, "_timestamp": 1585595159.3671427, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06206294149160385, "Value Loss": 0.0001712399098323658, "_runtime": 411.9039399623871, "_timestamp": 1585595160.9206135, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0566084124147892, "Value Loss": 0.00036121145240031183, "_runtime": 413.4517481327057, "_timestamp": 1585595162.4684217, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05231752619147301, "Value Loss": 0.00031653791666030884, "_runtime": 414.99974632263184, "_timestamp": 1585595164.01642, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04813424497842789, "Value Loss": 0.004768027924001217, "_runtime": 416.54860496520996, "_timestamp": 1585595165.5652785, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043664753437042236, "Value Loss": 0.0037230791058391333, "_runtime": 418.0948944091797, "_timestamp": 1585595167.111568, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.040622882544994354, "Value Loss": 0.00023839219647925347, "_runtime": 419.64467549324036, "_timestamp": 1585595168.661349, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03922547772526741, "Value Loss": 0.00016968310228548944, "_runtime": 421.19277811050415, "_timestamp": 1585595170.2094517, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.037076324224472046, "Value Loss": 0.0004350248782429844, "_runtime": 422.74155354499817, "_timestamp": 1585595171.758227, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.033598680049180984, "Value Loss": 0.0007617261726409197, "_runtime": 424.28695487976074, "_timestamp": 1585595173.3036284, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03045710362493992, "Value Loss": 5.618517752736807e-05, "_runtime": 425.82673144340515, "_timestamp": 1585595174.843405, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02804415486752987, "Value Loss": 0.004085288383066654, "_runtime": 427.37504053115845, "_timestamp": 1585595176.391714, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023972148075699806, "Value Loss": 1.3076765753794461e-05, "_runtime": 428.91281723976135, "_timestamp": 1585595177.9294908, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02082071825861931, "Value Loss": 0.00485581997781992, "_runtime": 430.4972105026245, "_timestamp": 1585595179.513884, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01715647056698799, "Value Loss": 3.429012940614484e-05, "_runtime": 432.03080916404724, "_timestamp": 1585595181.0474827, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014854495413601398, "Value Loss": 0.001961113652214408, "_runtime": 433.5681986808777, "_timestamp": 1585595182.5848722, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01182616874575615, "Value Loss": 8.008461009012535e-05, "_runtime": 435.09427881240845, "_timestamp": 1585595184.1109524, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009679707698523998, "Value Loss": 0.0005497582023963332, "_runtime": 436.6285951137543, "_timestamp": 1585595185.6452687, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007613999769091606, "Value Loss": 7.156579613365466e-06, "_runtime": 438.16556763648987, "_timestamp": 1585595187.1822412, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005972717888653278, "Value Loss": 8.475939830532297e-05, "_runtime": 439.7127718925476, "_timestamp": 1585595188.7294455, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00517293531447649, "Value Loss": 0.0005237035220488906, "_runtime": 441.24910974502563, "_timestamp": 1585595190.2657833, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029150452464818954, "Value Loss": 5.510942355613224e-05, "_runtime": 442.78564620018005, "_timestamp": 1585595191.8023198, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018622574862092733, "Value Loss": 0.00010530704457778484, "_runtime": 444.33062648773193, "_timestamp": 1585595193.3473, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007228300673887134, "Value Loss": 0.00017062568804249167, "_runtime": 445.8665533065796, "_timestamp": 1585595194.8832269, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001281257253140211, "Value Loss": 5.020848766434938e-05, "_runtime": 447.41256284713745, "_timestamp": 1585595196.4292364, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0031122141517698765, "Value Loss": 3.970877514802851e-05, "_runtime": 448.94779896736145, "_timestamp": 1585595197.9644725, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005245570093393326, "Value Loss": 1.1341721801727545e-05, "_runtime": 450.4954180717468, "_timestamp": 1585595199.5120916, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005549849476665258, "Value Loss": 0.0001316196285188198, "_runtime": 452.030775308609, "_timestamp": 1585595201.0474489, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0077109569683671, "Value Loss": 0.0002887967275455594, "_runtime": 453.6014099121094, "_timestamp": 1585595202.6180835, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009614192880690098, "Value Loss": 8.22323709144257e-05, "_runtime": 455.14846444129944, "_timestamp": 1585595204.165138, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010244962759315968, "Value Loss": 0.00011375296162441373, "_runtime": 456.69722533226013, "_timestamp": 1585595205.713899, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012509576976299286, "Value Loss": 7.586099673062563e-05, "_runtime": 458.2466220855713, "_timestamp": 1585595207.2632957, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012968773953616619, "Value Loss": 4.694375820690766e-05, "_runtime": 459.7959520816803, "_timestamp": 1585595208.8126256, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015291621908545494, "Value Loss": 3.0724265798198758e-06, "_runtime": 461.34423089027405, "_timestamp": 1585595210.3609045, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016067074611783028, "Value Loss": 0.00015298744256142527, "_runtime": 462.8771255016327, "_timestamp": 1585595211.893799, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015929125249385834, "Value Loss": 0.00011279481259407476, "_runtime": 464.42472672462463, "_timestamp": 1585595213.4414003, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01795911230146885, "Value Loss": 2.1056062905699946e-05, "_runtime": 465.9738676548004, "_timestamp": 1585595214.9905412, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0181494802236557, "Value Loss": 0.00012126186629757285, "_runtime": 467.5088291168213, "_timestamp": 1585595216.5255027, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01829100213944912, "Value Loss": 0.00024465276510454714, "_runtime": 469.05568194389343, "_timestamp": 1585595218.0723555, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01839568465948105, "Value Loss": 0.00019883166532963514, "_runtime": 470.604341506958, "_timestamp": 1585595219.621015, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018434731289744377, "Value Loss": 0.00020499421225395054, "_runtime": 472.1535482406616, "_timestamp": 1585595221.1702218, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01873316802084446, "Value Loss": 3.3546326449140906e-05, "_runtime": 473.6917884349823, "_timestamp": 1585595222.708462, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01863115280866623, "Value Loss": 3.1884992495179176e-05, "_runtime": 475.2283606529236, "_timestamp": 1585595224.2450342, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01794540137052536, "Value Loss": 3.544836363289505e-05, "_runtime": 476.80205631256104, "_timestamp": 1585595225.8187299, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01741717755794525, "Value Loss": 3.0351331588462926e-05, "_runtime": 478.3379728794098, "_timestamp": 1585595227.3546464, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01634971797466278, "Value Loss": 1.3663694517163094e-05, "_runtime": 479.8739421367645, "_timestamp": 1585595228.8906157, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015143666416406631, "Value Loss": 7.228858885355294e-05, "_runtime": 481.42160272598267, "_timestamp": 1585595230.4382763, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01490339357405901, "Value Loss": 2.3944665372255258e-05, "_runtime": 482.95817041397095, "_timestamp": 1585595231.974844, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013396547175943851, "Value Loss": 9.04632979654707e-05, "_runtime": 484.4831392765045, "_timestamp": 1585595233.4998128, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012831119820475578, "Value Loss": 1.1794331840064842e-05, "_runtime": 486.01961398124695, "_timestamp": 1585595235.0362875, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011001883074641228, "Value Loss": 5.4371073929360136e-05, "_runtime": 487.56420278549194, "_timestamp": 1585595236.5808764, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010164106264710426, "Value Loss": 2.0392539227032103e-05, "_runtime": 489.11371660232544, "_timestamp": 1585595238.1303902, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009405908174812794, "Value Loss": 4.228445959597593e-06, "_runtime": 490.660099029541, "_timestamp": 1585595239.6767726, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007456717547029257, "Value Loss": 0.00010361168824601918, "_runtime": 492.20737743377686, "_timestamp": 1585595241.224051, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006229070480912924, "Value Loss": 4.9831582145998254e-05, "_runtime": 493.75081634521484, "_timestamp": 1585595242.76749, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005569772329181433, "Value Loss": 2.6365216399426572e-05, "_runtime": 495.2850375175476, "_timestamp": 1585595244.301711, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0038893320597708225, "Value Loss": 4.442170029506087e-05, "_runtime": 496.82972049713135, "_timestamp": 1585595245.846394, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003376313950866461, "Value Loss": 2.3490877083531814e-06, "_runtime": 498.3829183578491, "_timestamp": 1585595247.399592, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0019857515580952168, "Value Loss": 8.465487553621642e-06, "_runtime": 499.97516441345215, "_timestamp": 1585595248.991838, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004941978841088712, "Value Loss": 6.459598080255091e-05, "_runtime": 501.52392053604126, "_timestamp": 1585595250.540594, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001486659311922267, "Value Loss": 8.109656846500002e-06, "_runtime": 503.0695290565491, "_timestamp": 1585595252.0862026, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006192592554725707, "Value Loss": 2.0601202777470462e-05, "_runtime": 504.615092754364, "_timestamp": 1585595253.6317663, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001062738592736423, "Value Loss": 1.2175984011264518e-05, "_runtime": 506.1394534111023, "_timestamp": 1585595255.156127, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001702639041468501, "Value Loss": 6.047249371476937e-06, "_runtime": 507.67463874816895, "_timestamp": 1585595256.6913123, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0019876225851476192, "Value Loss": 1.5305276974686421e-06, "_runtime": 509.2214939594269, "_timestamp": 1585595258.2381675, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0028681799303740263, "Value Loss": 2.9649965654243715e-05, "_runtime": 510.7663607597351, "_timestamp": 1585595259.7830343, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002808429766446352, "Value Loss": 1.8111890085492632e-06, "_runtime": 512.3126113414764, "_timestamp": 1585595261.329285, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034401488956063986, "Value Loss": 1.5541623724857345e-05, "_runtime": 513.8486325740814, "_timestamp": 1585595262.8653061, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0038717964198440313, "Value Loss": 4.367460132925771e-05, "_runtime": 515.3751010894775, "_timestamp": 1585595264.3917747, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003743113949894905, "Value Loss": 1.386001349601429e-05, "_runtime": 516.9079971313477, "_timestamp": 1585595265.9246707, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004155758302658796, "Value Loss": 3.742676926776767e-05, "_runtime": 518.4539635181427, "_timestamp": 1585595267.470637, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035290149971842766, "Value Loss": 3.934142569050891e-06, "_runtime": 520.0038106441498, "_timestamp": 1585595269.0204842, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004336058162152767, "Value Loss": 5.4557345720240846e-05, "_runtime": 521.5924446582794, "_timestamp": 1585595270.6091182, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034048533998429775, "Value Loss": 4.938075335303438e-07, "_runtime": 523.1272583007812, "_timestamp": 1585595272.1439319, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0038606005255132914, "Value Loss": 6.175503949634731e-05, "_runtime": 524.6607708930969, "_timestamp": 1585595273.6774445, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029936963692307472, "Value Loss": 1.207122750201961e-05, "_runtime": 526.1937968730927, "_timestamp": 1585595275.2104704, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0020500521641224623, "Value Loss": 1.2740273405142943e-06, "_runtime": 527.72531914711, "_timestamp": 1585595276.7419927, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017531653866171837, "Value Loss": 3.417048446863191e-06, "_runtime": 529.2575354576111, "_timestamp": 1585595278.274209, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017937503289431334, "Value Loss": 1.8926111806649715e-05, "_runtime": 530.8012399673462, "_timestamp": 1585595279.8179135, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001037910464219749, "Value Loss": 9.840038046604604e-07, "_runtime": 532.3494594097137, "_timestamp": 1585595281.366133, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006190671119838953, "Value Loss": 2.463547389197629e-06, "_runtime": 533.8970632553101, "_timestamp": 1585595282.9137368, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00021780062525067478, "Value Loss": 9.397885150974616e-06, "_runtime": 535.4392082691193, "_timestamp": 1585595284.4558818, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00012799425167031586, "Value Loss": 5.758262432209449e-06, "_runtime": 536.9844512939453, "_timestamp": 1585595286.0011249, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00011662699398584664, "Value Loss": 2.197770845668856e-05, "_runtime": 538.5192284584045, "_timestamp": 1585595287.535902, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.295488891628338e-05, "Value Loss": 5.3449748520506546e-05, "_runtime": 540.052031993866, "_timestamp": 1585595289.0687056, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.035802936006803e-05, "Value Loss": 1.62031010404462e-05, "_runtime": 541.6005761623383, "_timestamp": 1585595290.6172497, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011225186754018068, "Value Loss": 8.760569016885711e-07, "_runtime": 543.1451621055603, "_timestamp": 1585595292.1618357, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001163679757155478, "Value Loss": 6.201303676789394e-06, "_runtime": 544.7267923355103, "_timestamp": 1585595293.743466, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004762867174576968, "Value Loss": 7.293987437151372e-05, "_runtime": 546.2694313526154, "_timestamp": 1585595295.286105, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014398846542462707, "Value Loss": 4.304709364078008e-06, "_runtime": 547.8134069442749, "_timestamp": 1585595296.8300805, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000715963076800108, "Value Loss": 5.781007348559797e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 549.3344144821167, "_timestamp": 1585595298.351088, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0017429811414331198, "Value Loss": 1.0155090421903878e-06, "_runtime": 550.8781113624573, "_timestamp": 1585595299.894785, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001614491338841617, "Value Loss": 7.1386648414772935e-06, "_runtime": 552.4253578186035, "_timestamp": 1585595301.4420314, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014760702615603805, "Value Loss": 2.155424954253249e-05, "_runtime": 553.9609696865082, "_timestamp": 1585595302.9776433, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018535807030275464, "Value Loss": 1.4883095218465314e-06, "_runtime": 555.4974856376648, "_timestamp": 1585595304.5141592, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018235844327136874, "Value Loss": 2.00587874132907e-06, "_runtime": 557.0429604053497, "_timestamp": 1585595306.059634, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016742611769586802, "Value Loss": 7.880435987317469e-06, "_runtime": 558.5906000137329, "_timestamp": 1585595307.6072736, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0017240087036043406, "Value Loss": 9.970457313102088e-07, "_runtime": 560.1250350475311, "_timestamp": 1585595309.1417086, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010556995403021574, "Value Loss": 3.62380851584021e-05, "_runtime": 561.6700928211212, "_timestamp": 1585595310.6867664, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006130394176580012, "Value Loss": 3.150999691570178e-05, "_runtime": 563.2013227939606, "_timestamp": 1585595312.2179964, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001202727435156703, "Value Loss": 7.180515694926726e-06, "_runtime": 564.7486536502838, "_timestamp": 1585595313.7653272, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004959775833413005, "Value Loss": 3.1501029297942296e-05, "_runtime": 566.2919566631317, "_timestamp": 1585595315.3086302, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005139390123076737, "Value Loss": 7.417357846861705e-05, "_runtime": 567.8695771694183, "_timestamp": 1585595316.8862507, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013365669874474406, "Value Loss": 8.59075316839153e-06, "_runtime": 569.4177625179291, "_timestamp": 1585595318.434436, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001194839016534388, "Value Loss": 4.6762875172134954e-06, "_runtime": 570.9523372650146, "_timestamp": 1585595319.9690108, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014074816135689616, "Value Loss": 2.5839285626716446e-06, "_runtime": 572.4819810390472, "_timestamp": 1585595321.4986546, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006861488800495863, "Value Loss": 2.2599670046474785e-05, "_runtime": 574.0212178230286, "_timestamp": 1585595323.0378914, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001027746475301683, "Value Loss": 2.3078380763763562e-05, "_runtime": 575.5558879375458, "_timestamp": 1585595324.5725615, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001682483358308673, "Value Loss": 1.0442788607178954e-06, "_runtime": 577.0915989875793, "_timestamp": 1585595326.1082726, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014860216761007905, "Value Loss": 9.126652003033087e-06, "_runtime": 578.6286630630493, "_timestamp": 1585595327.6453366, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006940675666555762, "Value Loss": 1.5289027942344546e-05, "_runtime": 580.1650004386902, "_timestamp": 1585595329.181674, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013021818595007062, "Value Loss": 5.191069249121938e-06, "_runtime": 581.6911509037018, "_timestamp": 1585595330.7078245, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008902763947844505, "Value Loss": 3.084672425757162e-05, "_runtime": 583.2179591655731, "_timestamp": 1585595332.2346327, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009403470903635025, "Value Loss": 1.611520565347746e-05, "_runtime": 584.7531199455261, "_timestamp": 1585595333.7697935, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014943246496841311, "Value Loss": 8.075475079749594e-07, "_runtime": 586.2885196208954, "_timestamp": 1585595335.3051932, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012195559684187174, "Value Loss": 2.3239645088324323e-06, "_runtime": 587.8156635761261, "_timestamp": 1585595336.8323371, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014004023978486657, "Value Loss": 1.7830751630754094e-06, "_runtime": 589.3407392501831, "_timestamp": 1585595338.3574128, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001016814261674881, "Value Loss": 7.143533821363235e-06, "_runtime": 590.9137387275696, "_timestamp": 1585595339.9304123, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0003989402612205595, "Value Loss": 1.510154743300518e-05, "_runtime": 592.439439535141, "_timestamp": 1585595341.456113, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012496126582846045, "Value Loss": 5.933045486017363e-07, "_runtime": 593.9766712188721, "_timestamp": 1585595342.9933448, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00024213327560573816, "Value Loss": 2.2333870219881646e-05, "_runtime": 595.491984128952, "_timestamp": 1585595344.5086577, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007018143078312278, "Value Loss": 1.217911449202802e-05, "_runtime": 597.0297341346741, "_timestamp": 1585595346.0464077, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008128687040880322, "Value Loss": 9.209497875417583e-06, "_runtime": 598.5657966136932, "_timestamp": 1585595347.5824702, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000521149835549295, "Value Loss": 3.9864741552264604e-07, "_runtime": 600.1033623218536, "_timestamp": 1585595349.120036, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002623294712975621, "Value Loss": 4.847160653298488e-06, "_runtime": 601.6502876281738, "_timestamp": 1585595350.6669612, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006348741590045393, "Value Loss": 4.415541752678109e-06, "_runtime": 603.186295747757, "_timestamp": 1585595352.2029693, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00023347639944404364, "Value Loss": 6.40749785816297e-05, "_runtime": 604.7113399505615, "_timestamp": 1585595353.7280135, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00010977021884173155, "Value Loss": 3.5374039271118818e-06, "_runtime": 606.2475323677063, "_timestamp": 1585595355.264206, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00021231920982245356, "Value Loss": 1.4870248378429096e-05, "_runtime": 607.7949705123901, "_timestamp": 1585595356.811644, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00041641623829491436, "Value Loss": 1.0745557119662408e-05, "_runtime": 609.3426866531372, "_timestamp": 1585595358.3593602, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004109144792892039, "Value Loss": 1.662245995248668e-05, "_runtime": 610.8895423412323, "_timestamp": 1585595359.906216, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.297343523125164e-05, "Value Loss": 5.3125339036341757e-05, "_runtime": 612.4727003574371, "_timestamp": 1585595361.489374, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00018483128224033862, "Value Loss": 2.7521791707840748e-05, "_runtime": 614.0095367431641, "_timestamp": 1585595363.0262103, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006665693945251405, "Value Loss": 9.580595360603184e-06, "_runtime": 615.5577356815338, "_timestamp": 1585595364.5744092, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006853396771475673, "Value Loss": 9.530970601190347e-06, "_runtime": 617.1022870540619, "_timestamp": 1585595366.1189606, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006037149578332901, "Value Loss": 2.9953357625345234e-06, "_runtime": 618.6485757827759, "_timestamp": 1585595367.6652493, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002210975653724745, "Value Loss": 4.842697308049537e-06, "_runtime": 620.1964042186737, "_timestamp": 1585595369.2130778, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00047632752102799714, "Value Loss": 3.758508910323144e-06, "_runtime": 621.7443408966064, "_timestamp": 1585595370.7610145, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007074270979501307, "Value Loss": 1.554122235347677e-07, "_runtime": 623.2907257080078, "_timestamp": 1585595372.3073993, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.848728662589565e-05, "Value Loss": 1.777629404386971e-05, "_runtime": 624.8355655670166, "_timestamp": 1585595373.8522391, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006766625447198749, "Value Loss": 5.788438670606411e-07, "_runtime": 626.3802230358124, "_timestamp": 1585595375.3968966, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.954939453862607e-05, "Value Loss": 3.589783955249004e-05, "_runtime": 627.936930179596, "_timestamp": 1585595376.9536037, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00046645707334391773, "Value Loss": 8.35012997413287e-06, "_runtime": 629.4846212863922, "_timestamp": 1585595378.5012949, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00030982171301729977, "Value Loss": 1.5054560208227485e-05, "_runtime": 631.0183653831482, "_timestamp": 1585595380.035039, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004746387421619147, "Value Loss": 7.803135304129682e-06, "_runtime": 632.5669295787811, "_timestamp": 1585595381.5836031, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006598238251172006, "Value Loss": 3.055157264952868e-07, "_runtime": 634.1132106781006, "_timestamp": 1585595383.1298842, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001706725306576118, "Value Loss": 6.967790341150248e-06, "_runtime": 635.6938655376434, "_timestamp": 1585595384.710539, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004334065306466073, "Value Loss": 6.6804964262701105e-06, "_runtime": 637.2406361103058, "_timestamp": 1585595386.2573097, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001527516869828105, "Value Loss": 4.201378487778129e-06, "_runtime": 638.7773630619049, "_timestamp": 1585595387.7940366, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0003294720081612468, "Value Loss": 4.093525785719976e-05, "_runtime": 640.3250217437744, "_timestamp": 1585595389.3416953, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0002618750149849802, "Value Loss": 3.144739457638934e-05, "_runtime": 641.8633971214294, "_timestamp": 1585595390.8800707, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005505997687578201, "Value Loss": 4.440757095380832e-07, "_runtime": 643.3889226913452, "_timestamp": 1585595392.4055963, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008836619672365487, "Value Loss": 1.6607161512638413e-07, "_runtime": 644.9258615970612, "_timestamp": 1585595393.9425352, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005203002947382629, "Value Loss": 5.221717856329633e-06, "_runtime": 646.4658675193787, "_timestamp": 1585595395.482541, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005548271001316607, "Value Loss": 1.0185158316744491e-05, "_runtime": 648.006053686142, "_timestamp": 1585595397.0227273, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00016559578943997622, "Value Loss": 2.1405718143796548e-05, "_runtime": 649.5424764156342, "_timestamp": 1585595398.55915, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011774137383326888, "Value Loss": 6.407677233255527e-07, "_runtime": 651.0915138721466, "_timestamp": 1585595400.1081874, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000415688002249226, "Value Loss": 1.4669677511847112e-05, "_runtime": 652.6282742023468, "_timestamp": 1585595401.6449478, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008755208109505475, "Value Loss": 1.0067205039376859e-05, "_runtime": 654.177797794342, "_timestamp": 1585595403.1944714, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006204625242389739, "Value Loss": 3.992213896708563e-05, "_runtime": 655.7147364616394, "_timestamp": 1585595404.73141, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001135119586251676, "Value Loss": 6.423812919820193e-06, "_runtime": 657.2622916698456, "_timestamp": 1585595406.2789652, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004176197398919612, "Value Loss": 1.3805059097649064e-05, "_runtime": 658.8458139896393, "_timestamp": 1585595407.8624876, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013643484562635422, "Value Loss": 6.24811718807905e-07, "_runtime": 660.3982169628143, "_timestamp": 1585595409.4148905, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00042676206794567406, "Value Loss": 8.300969057017937e-06, "_runtime": 661.946218252182, "_timestamp": 1585595410.9628918, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008132124785333872, "Value Loss": 1.7558715626364574e-05, "_runtime": 663.4845898151398, "_timestamp": 1585595412.5012634, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008801930816844106, "Value Loss": 1.5162938780122204e-06, "_runtime": 665.0227634906769, "_timestamp": 1585595414.039437, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00033951422665268183, "Value Loss": 5.341069118003361e-05, "_runtime": 666.5701735019684, "_timestamp": 1585595415.586847, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005266715888865292, "Value Loss": 4.1465729736955836e-05, "_runtime": 668.1082985401154, "_timestamp": 1585595417.124972, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001128101022914052, "Value Loss": 7.795255442033522e-06, "_runtime": 669.6577475070953, "_timestamp": 1585595418.674421, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007495392928831279, "Value Loss": 8.467211046081502e-06, "_runtime": 671.2048945426941, "_timestamp": 1585595420.221568, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013288910267874599, "Value Loss": 4.4820751554652816e-07, "_runtime": 672.753368139267, "_timestamp": 1585595421.7700417, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011162683367729187, "Value Loss": 8.401916034017631e-07, "_runtime": 674.293107509613, "_timestamp": 1585595423.309781, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012259274953976274, "Value Loss": 5.526210316020297e-06, "_runtime": 675.8220994472504, "_timestamp": 1585595424.838773, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012720843078568578, "Value Loss": 1.0874166491703363e-06, "_runtime": 677.3599324226379, "_timestamp": 1585595426.376606, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007015714072622359, "Value Loss": 3.160072083119303e-05, "_runtime": 678.8991165161133, "_timestamp": 1585595427.91579, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011751381680369377, "Value Loss": 7.369779950749944e-07, "_runtime": 680.4377131462097, "_timestamp": 1585595429.4543867, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006009844364598393, "Value Loss": 5.104863703309093e-06, "_runtime": 682.0223922729492, "_timestamp": 1585595431.0390658, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00044808100210502744, "Value Loss": 4.105827247258276e-05, "_runtime": 683.5699167251587, "_timestamp": 1585595432.5865903, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011378807248547673, "Value Loss": 6.497720050901989e-07, "_runtime": 685.0938458442688, "_timestamp": 1585595434.1105194, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00026948991580866277, "Value Loss": 2.9917935535195284e-05, "_runtime": 686.6311085224152, "_timestamp": 1585595435.647782, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00019145543046761304, "Value Loss": 2.0285737264202908e-05, "_runtime": 688.1792171001434, "_timestamp": 1585595437.1958907, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009173594880849123, "Value Loss": 6.931134521437343e-06, "_runtime": 689.725165605545, "_timestamp": 1585595438.7418392, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009189371485263109, "Value Loss": 8.80970765138045e-06, "_runtime": 691.2744426727295, "_timestamp": 1585595440.2911162, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008689875830896199, "Value Loss": 6.831040991528425e-06, "_runtime": 692.821683883667, "_timestamp": 1585595441.8383574, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00010648318129824474, "Value Loss": 2.8139826099504717e-05, "_runtime": 694.3538155555725, "_timestamp": 1585595443.3704891, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00044569437159225345, "Value Loss": 2.097171454806812e-05, "_runtime": 695.8986160755157, "_timestamp": 1585595444.9152896, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006012372323311865, "Value Loss": 1.2189410654173116e-06, "_runtime": 697.4327824115753, "_timestamp": 1585595446.449456, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010051231365650892, "Value Loss": 3.0169803721946664e-07, "_runtime": 698.9781548976898, "_timestamp": 1585595447.9948285, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010239641414955258, "Value Loss": 3.316831680422183e-07, "_runtime": 700.5230975151062, "_timestamp": 1585595449.539771, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008795358007773757, "Value Loss": 4.469597570277983e-06, "_runtime": 702.0567984580994, "_timestamp": 1585595451.073472, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006773400236852467, "Value Loss": 3.548051154211862e-06, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 703.5815725326538, "_timestamp": 1585595452.598246, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007026334060356021, "Value Loss": 7.3219202931795735e-06, "_runtime": 703.5815725326538, "_timestamp": 1585595452.598246, "_step": 499}
