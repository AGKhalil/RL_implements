{"Episode reward": -76.63068802083674, "Episode length": 999, "Policy Loss": -0.021432098001241684, "Value Loss": 0.0063938843086361885, "_runtime": 12519.039442300797, "_timestamp": 1585609888.6723118, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1207623481750488, "Value Loss": 145.80511474609375, "_runtime": 12520.573686122894, "_timestamp": 1585609890.2065556, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3145840167999268, "Value Loss": 1.185716152191162, "_runtime": 12522.170107603073, "_timestamp": 1585609891.802977, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.175689697265625, "Value Loss": 312.5887756347656, "_runtime": 12523.72999739647, "_timestamp": 1585609893.3628669, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.711336135864258, "Value Loss": 5.354380130767822, "_runtime": 12525.289244413376, "_timestamp": 1585609894.922114, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6828439235687256, "Value Loss": 82.03092956542969, "_runtime": 12526.896995067596, "_timestamp": 1585609896.5298645, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2950431108474731, "Value Loss": 65.69457244873047, "_runtime": 12528.480977773666, "_timestamp": 1585609898.1138473, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5510342121124268, "Value Loss": 7.664913654327393, "_runtime": 12530.023629665375, "_timestamp": 1585609899.6564991, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1357176303863525, "Value Loss": 16.26229476928711, "_runtime": 12531.608993530273, "_timestamp": 1585609901.241863, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.518413245677948, "Value Loss": 9.345491409301758, "_runtime": 12533.202580451965, "_timestamp": 1585609902.83545, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.172460556030273, "Value Loss": 5.967034339904785, "_runtime": 12534.806643009186, "_timestamp": 1585609904.4395125, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.775644302368164, "Value Loss": 247.99761962890625, "_runtime": 12536.402458190918, "_timestamp": 1585609906.0353277, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.664482116699219, "Value Loss": 2846.04833984375, "_runtime": 12538.00117945671, "_timestamp": 1585609907.634049, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4003822803497314, "Value Loss": 58.24936294555664, "_runtime": 12539.570724725723, "_timestamp": 1585609909.2035942, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.824769020080566, "Value Loss": 113.45401000976562, "_runtime": 12541.179171562195, "_timestamp": 1585609910.812041, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.708337783813477, "Value Loss": 74.38373565673828, "_runtime": 12542.778229951859, "_timestamp": 1585609912.4110994, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -19.12051773071289, "Value Loss": 124.78998565673828, "_runtime": 12544.361670255661, "_timestamp": 1585609913.9945397, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -20.478574752807617, "Value Loss": 15.885896682739258, "_runtime": 12545.970038175583, "_timestamp": 1585609915.6029077, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -19.78670310974121, "Value Loss": 404.1025390625, "_runtime": 12547.569346427917, "_timestamp": 1585609917.202216, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -19.87436294555664, "Value Loss": 460.8948669433594, "_runtime": 12549.158631801605, "_timestamp": 1585609918.7915013, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.700348854064941, "Value Loss": 167.716552734375, "_runtime": 12550.765683412552, "_timestamp": 1585609920.398553, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4300720691680908, "Value Loss": 595.1654663085938, "_runtime": 12552.35371184349, "_timestamp": 1585609921.9865813, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.45665168762207, "Value Loss": 14.494142532348633, "_runtime": 12553.94633436203, "_timestamp": 1585609923.5792038, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 26.500932693481445, "Value Loss": 77.18042755126953, "_runtime": 12555.549812316895, "_timestamp": 1585609925.1826818, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 38.789817810058594, "Value Loss": 181.00730895996094, "_runtime": 12557.140684366226, "_timestamp": 1585609926.7735538, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 47.88850402832031, "Value Loss": 2224.66650390625, "_runtime": 12558.770502567291, "_timestamp": 1585609928.403372, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 42.23316955566406, "Value Loss": 300.3202819824219, "_runtime": 12560.361859083176, "_timestamp": 1585609929.9947286, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 35.92789840698242, "Value Loss": 469.677734375, "_runtime": 12561.954236507416, "_timestamp": 1585609931.587106, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 27.00043296813965, "Value Loss": 6.855520725250244, "_runtime": 12563.547729492188, "_timestamp": 1585609933.180599, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.775466918945312, "Value Loss": 536.6085205078125, "_runtime": 12565.150232315063, "_timestamp": 1585609934.7831018, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.563368797302246, "Value Loss": 16.10878562927246, "_runtime": 12566.739414215088, "_timestamp": 1585609936.3722837, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.536587715148926, "Value Loss": 214.2047119140625, "_runtime": 12568.319441318512, "_timestamp": 1585609937.9523108, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6396849751472473, "Value Loss": 35.073089599609375, "_runtime": 12569.920087099075, "_timestamp": 1585609939.5529566, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.03663444519043, "Value Loss": 27.834983825683594, "_runtime": 12571.520081996918, "_timestamp": 1585609941.1529515, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.211190223693848, "Value Loss": 218.7904510498047, "_runtime": 12573.111919164658, "_timestamp": 1585609942.7447886, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.841535568237305, "Value Loss": 47.63629913330078, "_runtime": 12574.713186264038, "_timestamp": 1585609944.3460557, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -18.498249053955078, "Value Loss": 502.6666564941406, "_runtime": 12576.313988924026, "_timestamp": 1585609945.9468584, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.438613891601562, "Value Loss": 30.73833656311035, "_runtime": 12577.905724287033, "_timestamp": 1585609947.5385938, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.36680793762207, "Value Loss": 105.83268737792969, "_runtime": 12579.505195379257, "_timestamp": 1585609949.1380649, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.33926010131836, "Value Loss": 3.125431537628174, "_runtime": 12581.108050107956, "_timestamp": 1585609950.7409196, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.440133094787598, "Value Loss": 10.882770538330078, "_runtime": 12582.740005970001, "_timestamp": 1585609952.3728755, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.56973934173584, "Value Loss": 1.3264031410217285, "_runtime": 12584.342551231384, "_timestamp": 1585609953.9754207, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.772109031677246, "Value Loss": 0.966357946395874, "_runtime": 12585.945721149445, "_timestamp": 1585609955.5785906, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.0540618896484375, "Value Loss": 1.7332534790039062, "_runtime": 12587.544318675995, "_timestamp": 1585609957.1771882, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.446424961090088, "Value Loss": 11.114408493041992, "_runtime": 12589.13704752922, "_timestamp": 1585609958.769917, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.9555160999298096, "Value Loss": 4.2098541259765625, "_runtime": 12590.731136322021, "_timestamp": 1585609960.3640058, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6164357662200928, "Value Loss": 1.8822788000106812, "_runtime": 12592.31804394722, "_timestamp": 1585609961.9509134, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.290466070175171, "Value Loss": 8.103370666503906, "_runtime": 12593.925969600677, "_timestamp": 1585609963.558839, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08157817274332047, "Value Loss": 7.957580089569092, "_runtime": 12595.518425941467, "_timestamp": 1585609965.1512954, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1888060569763184, "Value Loss": 5.237473011016846, "_runtime": 12597.106152296066, "_timestamp": 1585609966.7390218, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3791816234588623, "Value Loss": 3.065084457397461, "_runtime": 12598.708005666733, "_timestamp": 1585609968.3408751, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.493690013885498, "Value Loss": 0.11012241244316101, "_runtime": 12600.310516357422, "_timestamp": 1585609969.9433858, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.535529613494873, "Value Loss": 0.3918282389640808, "_runtime": 12601.908339262009, "_timestamp": 1585609971.5412087, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.457369327545166, "Value Loss": 0.7287003993988037, "_runtime": 12603.499560594559, "_timestamp": 1585609973.13243, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.3630290031433105, "Value Loss": 2.3640034198760986, "_runtime": 12605.090522766113, "_timestamp": 1585609974.7233922, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.143578052520752, "Value Loss": 2.184425115585327, "_runtime": 12606.728228092194, "_timestamp": 1585609976.3610976, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.921907901763916, "Value Loss": 4.506839275360107, "_runtime": 12608.330456495285, "_timestamp": 1585609977.963326, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.566368103027344, "Value Loss": 1.138293981552124, "_runtime": 12609.921010494232, "_timestamp": 1585609979.55388, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.176844596862793, "Value Loss": 1.0582222938537598, "_runtime": 12611.506628274918, "_timestamp": 1585609981.1394978, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.647464752197266, "Value Loss": 5.675347328186035, "_runtime": 12613.107474327087, "_timestamp": 1585609982.7403438, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.843314170837402, "Value Loss": 2.5917580127716064, "_runtime": 12614.707605838776, "_timestamp": 1585609984.3404753, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.932647705078125, "Value Loss": 2.677119016647339, "_runtime": 12616.304195404053, "_timestamp": 1585609985.937065, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.992682456970215, "Value Loss": 5.14778995513916, "_runtime": 12617.902643918991, "_timestamp": 1585609987.5355134, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.98597240447998, "Value Loss": 1.4916369915008545, "_runtime": 12619.503408432007, "_timestamp": 1585609989.136278, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.933354377746582, "Value Loss": 2.127915620803833, "_runtime": 12621.099730014801, "_timestamp": 1585609990.7325995, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.788976669311523, "Value Loss": 2.7816708087921143, "_runtime": 12622.70203256607, "_timestamp": 1585609992.334902, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.597966194152832, "Value Loss": 2.6457862854003906, "_runtime": 12624.291916131973, "_timestamp": 1585609993.9247856, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.373457908630371, "Value Loss": 3.5373146533966064, "_runtime": 12625.877978801727, "_timestamp": 1585609995.5108483, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.979772567749023, "Value Loss": 3.5173754692077637, "_runtime": 12627.46704030037, "_timestamp": 1585609997.0999098, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.452139854431152, "Value Loss": 0.6725417375564575, "_runtime": 12629.096507072449, "_timestamp": 1585609998.7293766, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.9858012199401855, "Value Loss": 1.277466058731079, "_runtime": 12630.683589220047, "_timestamp": 1585610000.3164587, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.462734699249268, "Value Loss": 1.137881875038147, "_runtime": 12632.285804986954, "_timestamp": 1585610001.9186745, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.9795122146606445, "Value Loss": 2.559253215789795, "_runtime": 12633.885754346848, "_timestamp": 1585610003.5186238, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.447300434112549, "Value Loss": 1.2451764345169067, "_runtime": 12635.463641643524, "_timestamp": 1585610005.0965111, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.94398832321167, "Value Loss": 1.1281057596206665, "_runtime": 12637.04827427864, "_timestamp": 1585610006.6811438, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.526170253753662, "Value Loss": 1.289027452468872, "_runtime": 12638.632737636566, "_timestamp": 1585610008.265607, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.201799392700195, "Value Loss": 2.8232266902923584, "_runtime": 12640.20188331604, "_timestamp": 1585610009.8347528, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.035157203674316, "Value Loss": 1.4001189470291138, "_runtime": 12641.785291671753, "_timestamp": 1585610011.4181612, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.963871955871582, "Value Loss": 0.33378127217292786, "_runtime": 12643.366508960724, "_timestamp": 1585610012.9993784, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.9028401374816895, "Value Loss": 1.1517784595489502, "_runtime": 12644.94485616684, "_timestamp": 1585610014.5777256, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.884567737579346, "Value Loss": 1.4148907661437988, "_runtime": 12646.530831575394, "_timestamp": 1585610016.163701, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.979019641876221, "Value Loss": 0.27560773491859436, "_runtime": 12648.114006757736, "_timestamp": 1585610017.7468762, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.079474925994873, "Value Loss": 0.4839133322238922, "_runtime": 12649.690759897232, "_timestamp": 1585610019.3236294, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.174483776092529, "Value Loss": 0.2945072054862976, "_runtime": 12651.27504324913, "_timestamp": 1585610020.9079127, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.247421741485596, "Value Loss": 0.25189703702926636, "_runtime": 12652.895770311356, "_timestamp": 1585610022.5286398, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.330458164215088, "Value Loss": 0.3070966601371765, "_runtime": 12654.462875127792, "_timestamp": 1585610024.0957446, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.34352445602417, "Value Loss": 0.3262508511543274, "_runtime": 12656.046616792679, "_timestamp": 1585610025.6794863, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.283143520355225, "Value Loss": 0.4013698101043701, "_runtime": 12657.628636837006, "_timestamp": 1585610027.2615063, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.172575950622559, "Value Loss": 1.0571129322052002, "_runtime": 12659.19629573822, "_timestamp": 1585610028.8291652, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.0464301109313965, "Value Loss": 0.9293285608291626, "_runtime": 12660.767795562744, "_timestamp": 1585610030.400665, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.862749099731445, "Value Loss": 0.8196539878845215, "_runtime": 12662.341740369797, "_timestamp": 1585610031.9746099, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.675344944000244, "Value Loss": 0.5344336032867432, "_runtime": 12663.920004844666, "_timestamp": 1585610033.5528743, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.421630382537842, "Value Loss": 0.3744034171104431, "_runtime": 12665.49364733696, "_timestamp": 1585610035.1265168, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.150885581970215, "Value Loss": 0.36725708842277527, "_runtime": 12667.067026615143, "_timestamp": 1585610036.699896, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.8693487644195557, "Value Loss": 0.49644899368286133, "_runtime": 12668.634922504425, "_timestamp": 1585610038.267792, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.582961082458496, "Value Loss": 0.19683648645877838, "_runtime": 12670.208801984787, "_timestamp": 1585610039.8416715, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3351223468780518, "Value Loss": 0.1048552542924881, "_runtime": 12671.7951130867, "_timestamp": 1585610041.4279826, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.090149402618408, "Value Loss": 0.10010033845901489, "_runtime": 12673.379635334015, "_timestamp": 1585610043.0125048, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8455727100372314, "Value Loss": 0.07298371940851212, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 12674.96046090126, "_timestamp": 1585610044.5933304, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.631784200668335, "Value Loss": 0.11520322412252426, "_runtime": 12676.570997953415, "_timestamp": 1585610046.2038674, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.437223196029663, "Value Loss": 0.2014138549566269, "_runtime": 12678.140892267227, "_timestamp": 1585610047.7737617, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.288757085800171, "Value Loss": 0.1690872609615326, "_runtime": 12679.722703456879, "_timestamp": 1585610049.355573, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1762473583221436, "Value Loss": 0.10558825731277466, "_runtime": 12681.296689033508, "_timestamp": 1585610050.9295585, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.093757152557373, "Value Loss": 0.10188810527324677, "_runtime": 12682.877255916595, "_timestamp": 1585610052.5101254, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.030357837677002, "Value Loss": 0.06299247592687607, "_runtime": 12684.44958782196, "_timestamp": 1585610054.0824573, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9676884412765503, "Value Loss": 0.057629551738500595, "_runtime": 12686.025466918945, "_timestamp": 1585610055.6583364, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9165095090866089, "Value Loss": 0.24519413709640503, "_runtime": 12687.605437278748, "_timestamp": 1585610057.2383068, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8506261110305786, "Value Loss": 0.0799940824508667, "_runtime": 12689.187158346176, "_timestamp": 1585610058.8200278, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8089094161987305, "Value Loss": 0.033940769731998444, "_runtime": 12690.76973605156, "_timestamp": 1585610060.4026055, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7648130655288696, "Value Loss": 0.04257626831531525, "_runtime": 12692.348281860352, "_timestamp": 1585610061.9811513, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7187285423278809, "Value Loss": 0.043842513114213943, "_runtime": 12693.920424222946, "_timestamp": 1585610063.5532937, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6769686937332153, "Value Loss": 0.08951407670974731, "_runtime": 12695.500666618347, "_timestamp": 1585610065.133536, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6363823413848877, "Value Loss": 0.09949290007352829, "_runtime": 12697.069074630737, "_timestamp": 1585610066.701944, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.540252685546875, "Value Loss": 0.06709360331296921, "_runtime": 12698.652732849121, "_timestamp": 1585610068.2856023, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4675909280776978, "Value Loss": 0.05962743982672691, "_runtime": 12700.272969722748, "_timestamp": 1585610069.9058392, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3838965892791748, "Value Loss": 0.026090804487466812, "_runtime": 12701.849427461624, "_timestamp": 1585610071.482297, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.287994384765625, "Value Loss": 0.019910968840122223, "_runtime": 12703.418930053711, "_timestamp": 1585610073.0517995, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.208128809928894, "Value Loss": 0.031079202890396118, "_runtime": 12704.997714996338, "_timestamp": 1585610074.6305845, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1358662843704224, "Value Loss": 0.04657396301627159, "_runtime": 12706.575231552124, "_timestamp": 1585610076.208101, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.082845687866211, "Value Loss": 0.13769784569740295, "_runtime": 12708.15558218956, "_timestamp": 1585610077.7884517, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0497256517410278, "Value Loss": 0.1575479805469513, "_runtime": 12709.735483169556, "_timestamp": 1585610079.3683527, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0228506326675415, "Value Loss": 0.020544392988085747, "_runtime": 12711.302156925201, "_timestamp": 1585610080.9350264, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0083197355270386, "Value Loss": 0.05093926191329956, "_runtime": 12712.883400201797, "_timestamp": 1585610082.5162697, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9634947776794434, "Value Loss": 0.0764542669057846, "_runtime": 12714.45257306099, "_timestamp": 1585610084.0854425, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9310197234153748, "Value Loss": 0.014506252482533455, "_runtime": 12716.018193483353, "_timestamp": 1585610085.651063, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8760669827461243, "Value Loss": 0.11550045758485794, "_runtime": 12717.587545394897, "_timestamp": 1585610087.2204149, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8056547045707703, "Value Loss": 0.03832998499274254, "_runtime": 12719.164481401443, "_timestamp": 1585610088.797351, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7464891076087952, "Value Loss": 0.03660198301076889, "_runtime": 12720.73159480095, "_timestamp": 1585610090.3644643, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6982991099357605, "Value Loss": 0.05525140091776848, "_runtime": 12722.312331676483, "_timestamp": 1585610091.9452012, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6499409675598145, "Value Loss": 0.06369838863611221, "_runtime": 12723.932686328888, "_timestamp": 1585610093.5655558, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5757236480712891, "Value Loss": 0.007145436480641365, "_runtime": 12725.513583660126, "_timestamp": 1585610095.1464531, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5233888626098633, "Value Loss": 0.07336020469665527, "_runtime": 12727.096514463425, "_timestamp": 1585610096.729384, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.46713921427726746, "Value Loss": 0.04167133942246437, "_runtime": 12728.667009353638, "_timestamp": 1585610098.2998788, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40476617217063904, "Value Loss": 0.011178247630596161, "_runtime": 12730.250313282013, "_timestamp": 1585610099.8831828, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.35595449805259705, "Value Loss": 0.012833505868911743, "_runtime": 12731.833310365677, "_timestamp": 1585610101.4661798, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3118969202041626, "Value Loss": 0.003014342626556754, "_runtime": 12733.40588593483, "_timestamp": 1585610103.0387554, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.28275254368782043, "Value Loss": 0.014478294178843498, "_runtime": 12734.98325920105, "_timestamp": 1585610104.6161287, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26335370540618896, "Value Loss": 0.01398166362196207, "_runtime": 12736.556231975555, "_timestamp": 1585610106.1891015, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25046882033348083, "Value Loss": 0.0014173561939969659, "_runtime": 12738.139642953873, "_timestamp": 1585610107.7725124, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23088331520557404, "Value Loss": 0.0007022280478850007, "_runtime": 12739.71711564064, "_timestamp": 1585610109.3499851, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23266293108463287, "Value Loss": 0.007951642386615276, "_runtime": 12741.280163288116, "_timestamp": 1585610110.9130328, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21334555745124817, "Value Loss": 0.003511524759232998, "_runtime": 12742.86489200592, "_timestamp": 1585610112.4977615, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20813795924186707, "Value Loss": 0.004513863939791918, "_runtime": 12744.445216178894, "_timestamp": 1585610114.0780857, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20111913979053497, "Value Loss": 0.0021090826485306025, "_runtime": 12746.06469655037, "_timestamp": 1585610115.697566, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21926014125347137, "Value Loss": 0.040115032345056534, "_runtime": 12747.639415025711, "_timestamp": 1585610117.2722845, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23415540158748627, "Value Loss": 0.013663407415151596, "_runtime": 12749.21859574318, "_timestamp": 1585610118.8514652, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24657444655895233, "Value Loss": 0.002637180732563138, "_runtime": 12750.799574613571, "_timestamp": 1585610120.432444, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2751079499721527, "Value Loss": 0.02174443006515503, "_runtime": 12752.371378183365, "_timestamp": 1585610122.0042477, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2808574438095093, "Value Loss": 0.00183523737359792, "_runtime": 12753.939063072205, "_timestamp": 1585610123.5719326, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29683375358581543, "Value Loss": 0.009594401344656944, "_runtime": 12755.521857738495, "_timestamp": 1585610125.1547272, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30498242378234863, "Value Loss": 0.008656881749629974, "_runtime": 12757.09236073494, "_timestamp": 1585610126.7252302, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2988230586051941, "Value Loss": 0.0031996516045182943, "_runtime": 12758.672573328018, "_timestamp": 1585610128.3054428, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2878017723560333, "Value Loss": 0.007420670706778765, "_runtime": 12760.264763355255, "_timestamp": 1585610129.8976328, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2849527895450592, "Value Loss": 0.013221362605690956, "_runtime": 12761.853313922882, "_timestamp": 1585610131.4861834, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2548454999923706, "Value Loss": 0.0049008834175765514, "_runtime": 12763.432732105255, "_timestamp": 1585610133.0656016, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23248529434204102, "Value Loss": 0.0010273033985868096, "_runtime": 12765.013591527939, "_timestamp": 1585610134.646461, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22562552988529205, "Value Loss": 0.008670484647154808, "_runtime": 12766.601951122284, "_timestamp": 1585610136.2348206, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19810551404953003, "Value Loss": 0.003121430054306984, "_runtime": 12768.192968606949, "_timestamp": 1585610137.825838, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19171388447284698, "Value Loss": 0.021064063534140587, "_runtime": 12769.818612575531, "_timestamp": 1585610139.451482, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17379960417747498, "Value Loss": 0.011346828192472458, "_runtime": 12771.402429819107, "_timestamp": 1585610141.0352993, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1650044023990631, "Value Loss": 0.006855236366391182, "_runtime": 12772.992110729218, "_timestamp": 1585610142.6249802, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14383502304553986, "Value Loss": 0.00033281187643297017, "_runtime": 12774.585052728653, "_timestamp": 1585610144.2179222, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14322951436042786, "Value Loss": 0.0013101132353767753, "_runtime": 12776.173001527786, "_timestamp": 1585610145.805871, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14205802977085114, "Value Loss": 0.006816062610596418, "_runtime": 12777.75796842575, "_timestamp": 1585610147.390838, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13907505571842194, "Value Loss": 0.019640950486063957, "_runtime": 12779.34759759903, "_timestamp": 1585610148.980467, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12119034677743912, "Value Loss": 0.0042409044690430164, "_runtime": 12780.935419559479, "_timestamp": 1585610150.568289, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11591989547014236, "Value Loss": 0.0013350078370422125, "_runtime": 12782.514874696732, "_timestamp": 1585610152.1477442, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1086968258023262, "Value Loss": 0.002680998994037509, "_runtime": 12784.096779584885, "_timestamp": 1585610153.729649, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09551671892404556, "Value Loss": 0.001722947577945888, "_runtime": 12785.676946640015, "_timestamp": 1585610155.3098161, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09569868445396423, "Value Loss": 0.006804196629673243, "_runtime": 12787.264899492264, "_timestamp": 1585610156.897769, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08676495403051376, "Value Loss": 0.0011859702644869685, "_runtime": 12788.855125665665, "_timestamp": 1585610158.4879951, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10128238797187805, "Value Loss": 0.023968171328306198, "_runtime": 12790.435657262802, "_timestamp": 1585610160.0685267, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0936727449297905, "Value Loss": 0.0035467171110212803, "_runtime": 12792.022116661072, "_timestamp": 1585610161.6549861, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10004892200231552, "Value Loss": 0.00594276562333107, "_runtime": 12793.65216088295, "_timestamp": 1585610163.2850304, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10248252004384995, "Value Loss": 0.006923290900886059, "_runtime": 12795.24247598648, "_timestamp": 1585610164.8753455, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10934094339609146, "Value Loss": 0.005089347716420889, "_runtime": 12796.830157995224, "_timestamp": 1585610166.4630275, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11009342223405838, "Value Loss": 0.0005753646837547421, "_runtime": 12798.422459363937, "_timestamp": 1585610168.0553288, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12434634566307068, "Value Loss": 0.0030992773827165365, "_runtime": 12800.01472234726, "_timestamp": 1585610169.6475918, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12581174075603485, "Value Loss": 0.0036827365402132273, "_runtime": 12801.596784114838, "_timestamp": 1585610171.2296536, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14060881733894348, "Value Loss": 0.003874792717397213, "_runtime": 12803.171530723572, "_timestamp": 1585610172.8044002, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13132837414741516, "Value Loss": 0.002778354799374938, "_runtime": 12804.75291466713, "_timestamp": 1585610174.3857841, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1277317851781845, "Value Loss": 0.0003236700431443751, "_runtime": 12806.311404705048, "_timestamp": 1585610175.9442742, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14026516675949097, "Value Loss": 0.010496414266526699, "_runtime": 12807.89528298378, "_timestamp": 1585610177.5281525, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13428132236003876, "Value Loss": 0.0017252828693017364, "_runtime": 12809.476567745209, "_timestamp": 1585610179.1094372, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14819374680519104, "Value Loss": 0.014502938836812973, "_runtime": 12811.056310892105, "_timestamp": 1585610180.6891804, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1467469036579132, "Value Loss": 0.008427685126662254, "_runtime": 12812.638765096664, "_timestamp": 1585610182.2716346, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1487462818622589, "Value Loss": 0.00662692217156291, "_runtime": 12814.219115495682, "_timestamp": 1585610183.851985, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15540437400341034, "Value Loss": 0.009182889945805073, "_runtime": 12815.797594070435, "_timestamp": 1585610185.4304636, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1464402675628662, "Value Loss": 0.006228265352547169, "_runtime": 12817.40775847435, "_timestamp": 1585610187.040628, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15695783495903015, "Value Loss": 0.01501344982534647, "_runtime": 12818.9759953022, "_timestamp": 1585610188.6088648, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14477719366550446, "Value Loss": 0.006427542306482792, "_runtime": 12820.546386957169, "_timestamp": 1585610190.1792564, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1524975597858429, "Value Loss": 0.01420813798904419, "_runtime": 12822.11655831337, "_timestamp": 1585610191.7494278, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14003336429595947, "Value Loss": 0.003454056102782488, "_runtime": 12823.68489766121, "_timestamp": 1585610193.3177671, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13050757348537445, "Value Loss": 0.0004438555333763361, "_runtime": 12825.261787891388, "_timestamp": 1585610194.8946574, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1321273148059845, "Value Loss": 0.002363503212109208, "_runtime": 12826.831069946289, "_timestamp": 1585610196.4639394, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13870835304260254, "Value Loss": 0.014099514111876488, "_runtime": 12828.409339427948, "_timestamp": 1585610198.042209, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1330217570066452, "Value Loss": 0.005986056290566921, "_runtime": 12829.98682808876, "_timestamp": 1585610199.6196976, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1351659595966339, "Value Loss": 0.001656299689784646, "_runtime": 12831.554739713669, "_timestamp": 1585610201.1876092, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13857169449329376, "Value Loss": 0.0029933806508779526, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 12833.13342833519, "_timestamp": 1585610202.7662978, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15108130872249603, "Value Loss": 0.014468447305262089, "_runtime": 12834.719661951065, "_timestamp": 1585610204.3525314, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13970038294792175, "Value Loss": 0.0050270045176148415, "_runtime": 12836.299814224243, "_timestamp": 1585610205.9326837, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13840103149414062, "Value Loss": 0.003932406660169363, "_runtime": 12837.866106510162, "_timestamp": 1585610207.498976, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14670895040035248, "Value Loss": 0.009974491782486439, "_runtime": 12839.46868944168, "_timestamp": 1585610209.101559, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13134008646011353, "Value Loss": 0.0014123317087069154, "_runtime": 12841.026394844055, "_timestamp": 1585610210.6592643, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12775857746601105, "Value Loss": 0.0006972228875383735, "_runtime": 12842.593516349792, "_timestamp": 1585610212.2263858, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13434267044067383, "Value Loss": 0.025978934019804, "_runtime": 12844.154018640518, "_timestamp": 1585610213.7868881, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13499470055103302, "Value Loss": 0.0141501659527421, "_runtime": 12845.714197397232, "_timestamp": 1585610215.3470669, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15469734370708466, "Value Loss": 0.011436909437179565, "_runtime": 12847.2789914608, "_timestamp": 1585610216.911861, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1709730476140976, "Value Loss": 0.014450805261731148, "_runtime": 12848.844348669052, "_timestamp": 1585610218.4772182, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.178897425532341, "Value Loss": 0.0055429572239518166, "_runtime": 12850.41187119484, "_timestamp": 1585610220.0447407, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1996248960494995, "Value Loss": 0.007486273534595966, "_runtime": 12851.976397752762, "_timestamp": 1585610221.6092672, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19231171905994415, "Value Loss": 0.0013780798763036728, "_runtime": 12853.54319858551, "_timestamp": 1585610223.176068, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21677419543266296, "Value Loss": 0.012562242336571217, "_runtime": 12855.101992607117, "_timestamp": 1585610224.734862, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2083558589220047, "Value Loss": 0.006126836407929659, "_runtime": 12856.661979913712, "_timestamp": 1585610226.2948494, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20723043382167816, "Value Loss": 0.0032534082420170307, "_runtime": 12858.216722488403, "_timestamp": 1585610227.849592, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20256587862968445, "Value Loss": 0.002681494690477848, "_runtime": 12859.784063339233, "_timestamp": 1585610229.4169328, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1974022388458252, "Value Loss": 0.01954507827758789, "_runtime": 12861.35357618332, "_timestamp": 1585610230.9864457, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1891781985759735, "Value Loss": 0.010732353664934635, "_runtime": 12862.95590519905, "_timestamp": 1585610232.5887747, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1753655970096588, "Value Loss": 0.003586631501093507, "_runtime": 12864.52448606491, "_timestamp": 1585610234.1573555, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15881364047527313, "Value Loss": 0.0017064576968550682, "_runtime": 12866.100641727448, "_timestamp": 1585610235.7335112, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15480878949165344, "Value Loss": 0.011941380798816681, "_runtime": 12867.665127277374, "_timestamp": 1585610237.2979968, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1421314775943756, "Value Loss": 0.013448282144963741, "_runtime": 12869.230293512344, "_timestamp": 1585610238.863163, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11807112395763397, "Value Loss": 0.005495466757565737, "_runtime": 12870.786348342896, "_timestamp": 1585610240.4192178, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11563191562891006, "Value Loss": 0.028448473662137985, "_runtime": 12872.350494861603, "_timestamp": 1585610241.9833643, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11151371151208878, "Value Loss": 0.0028904667124152184, "_runtime": 12873.9199051857, "_timestamp": 1585610243.5527747, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12536261975765228, "Value Loss": 0.0017210418591275811, "_runtime": 12875.486914396286, "_timestamp": 1585610245.1197839, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13916133344173431, "Value Loss": 0.0015364636201411486, "_runtime": 12877.051054000854, "_timestamp": 1585610246.6839235, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1611611694097519, "Value Loss": 0.013855883851647377, "_runtime": 12878.621473312378, "_timestamp": 1585610248.2543428, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16602587699890137, "Value Loss": 0.0018905621254816651, "_runtime": 12880.188915014267, "_timestamp": 1585610249.8217845, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1948341280221939, "Value Loss": 0.046671271324157715, "_runtime": 12881.744934082031, "_timestamp": 1585610251.3778036, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2096867710351944, "Value Loss": 0.007684802170842886, "_runtime": 12883.311733961105, "_timestamp": 1585610252.9446034, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2240418791770935, "Value Loss": 0.005457807797938585, "_runtime": 12884.88263463974, "_timestamp": 1585610254.5155041, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22325992584228516, "Value Loss": 0.01363265048712492, "_runtime": 12886.475035190582, "_timestamp": 1585610256.1079047, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24355754256248474, "Value Loss": 0.03017166629433632, "_runtime": 12888.04658651352, "_timestamp": 1585610257.679456, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23919349908828735, "Value Loss": 0.008930481038987637, "_runtime": 12889.618681907654, "_timestamp": 1585610259.2515514, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24936643242835999, "Value Loss": 0.011187057010829449, "_runtime": 12891.176704406738, "_timestamp": 1585610260.809574, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23054829239845276, "Value Loss": 0.0029603466391563416, "_runtime": 12892.735599279404, "_timestamp": 1585610262.3684688, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22952894866466522, "Value Loss": 0.007616708986461163, "_runtime": 12894.302953004837, "_timestamp": 1585610263.9358225, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21281276643276215, "Value Loss": 0.02213497832417488, "_runtime": 12895.870700120926, "_timestamp": 1585610265.5035696, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18146221339702606, "Value Loss": 0.005122374277561903, "_runtime": 12897.440485715866, "_timestamp": 1585610267.0733552, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15480467677116394, "Value Loss": 0.015667185187339783, "_runtime": 12899.009734869003, "_timestamp": 1585610268.6426044, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1078295186161995, "Value Loss": 0.005128342192620039, "_runtime": 12900.580653905869, "_timestamp": 1585610270.2135234, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08417551964521408, "Value Loss": 0.014584559015929699, "_runtime": 12902.159995794296, "_timestamp": 1585610271.7928653, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06423613429069519, "Value Loss": 0.021460801362991333, "_runtime": 12903.736435890198, "_timestamp": 1585610273.3693054, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.042776767164468765, "Value Loss": 0.01011652685701847, "_runtime": 12905.307224750519, "_timestamp": 1585610274.9400942, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04513023793697357, "Value Loss": 0.016961093991994858, "_runtime": 12906.877888202667, "_timestamp": 1585610276.5107577, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029781591147184372, "Value Loss": 0.0449824295938015, "_runtime": 12908.447409152985, "_timestamp": 1585610278.0802786, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03389600291848183, "Value Loss": 0.04192125052213669, "_runtime": 12910.052032709122, "_timestamp": 1585610279.6849022, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.046302542090415955, "Value Loss": 0.015161302872002125, "_runtime": 12911.623546600342, "_timestamp": 1585610281.256416, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08950768411159515, "Value Loss": 0.007194919511675835, "_runtime": 12913.190683841705, "_timestamp": 1585610282.8235533, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13910821080207825, "Value Loss": 0.011919940821826458, "_runtime": 12914.745048999786, "_timestamp": 1585610284.3779185, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16185252368450165, "Value Loss": 0.0011772910365834832, "_runtime": 12916.310187101364, "_timestamp": 1585610285.9430566, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20296679437160492, "Value Loss": 0.0162547267973423, "_runtime": 12917.879239797592, "_timestamp": 1585610287.5121093, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22852656245231628, "Value Loss": 0.003782859770581126, "_runtime": 12919.445992231369, "_timestamp": 1585610289.0788617, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2365017533302307, "Value Loss": 0.010087202303111553, "_runtime": 12921.015954256058, "_timestamp": 1585610290.6488237, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24903598427772522, "Value Loss": 0.012570466846227646, "_runtime": 12922.581964731216, "_timestamp": 1585610292.2148342, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26785802841186523, "Value Loss": 0.010475928895175457, "_runtime": 12924.13598895073, "_timestamp": 1585610293.7688584, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26318952441215515, "Value Loss": 0.02938804030418396, "_runtime": 12925.695568084717, "_timestamp": 1585610295.3284376, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23619726300239563, "Value Loss": 0.017196374014019966, "_runtime": 12927.263327360153, "_timestamp": 1585610296.8961968, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21608172357082367, "Value Loss": 0.0033650873228907585, "_runtime": 12928.828798294067, "_timestamp": 1585610298.4616678, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17941315472126007, "Value Loss": 0.007927348837256432, "_runtime": 12930.393900871277, "_timestamp": 1585610300.0267704, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16842283308506012, "Value Loss": 0.03419311344623566, "_runtime": 12931.948898553848, "_timestamp": 1585610301.581768, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1132628321647644, "Value Loss": 0.003112910548225045, "_runtime": 12933.557843446732, "_timestamp": 1585610303.190713, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05489340424537659, "Value Loss": 0.009143330156803131, "_runtime": 12935.127609014511, "_timestamp": 1585610304.7604785, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01728551834821701, "Value Loss": 0.007568148896098137, "_runtime": 12936.698576927185, "_timestamp": 1585610306.3314464, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029192892834544182, "Value Loss": 0.002960370620712638, "_runtime": 12938.274031162262, "_timestamp": 1585610307.9069006, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06068520247936249, "Value Loss": 0.0010419826721772552, "_runtime": 12939.85613656044, "_timestamp": 1585610309.489006, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07199636846780777, "Value Loss": 0.0337505005300045, "_runtime": 12941.439724445343, "_timestamp": 1585610311.072594, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09563738107681274, "Value Loss": 0.007549655623733997, "_runtime": 12943.020194768906, "_timestamp": 1585610312.6530643, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10270000249147415, "Value Loss": 0.0056740902364254, "_runtime": 12944.603239536285, "_timestamp": 1585610314.236109, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08903483301401138, "Value Loss": 0.017567623406648636, "_runtime": 12946.183082342148, "_timestamp": 1585610315.8159518, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09420252591371536, "Value Loss": 0.007869882509112358, "_runtime": 12947.752789497375, "_timestamp": 1585610317.385659, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0688127726316452, "Value Loss": 0.00918867439031601, "_runtime": 12949.33309173584, "_timestamp": 1585610318.9659612, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06711774319410324, "Value Loss": 0.0032115012872964144, "_runtime": 12950.91506934166, "_timestamp": 1585610320.5479388, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.055936265736818314, "Value Loss": 0.0008807951817288995, "_runtime": 12952.496223688126, "_timestamp": 1585610322.1290932, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02820182964205742, "Value Loss": 0.006343262270092964, "_runtime": 12954.07916355133, "_timestamp": 1585610323.712033, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020767247304320335, "Value Loss": 8.106976019917056e-05, "_runtime": 12955.691054821014, "_timestamp": 1585610325.3239243, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025174899492412806, "Value Loss": 0.00025923564680851996, "_runtime": 12957.262338638306, "_timestamp": 1585610326.8952081, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025533564388751984, "Value Loss": 0.017841333523392677, "_runtime": 12958.839149236679, "_timestamp": 1585610328.4720187, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05606042966246605, "Value Loss": 0.013071146793663502, "_runtime": 12960.41045832634, "_timestamp": 1585610330.0433278, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09147569537162781, "Value Loss": 0.0008031449979171157, "_runtime": 12961.993595123291, "_timestamp": 1585610331.6264646, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12591391801834106, "Value Loss": 0.0009428720804862678, "_runtime": 12963.566758394241, "_timestamp": 1585610333.1996279, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15443582832813263, "Value Loss": 0.0009669414721429348, "_runtime": 12965.147837638855, "_timestamp": 1585610334.7807071, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18314017355442047, "Value Loss": 0.002091342583298683, "_runtime": 12966.71794962883, "_timestamp": 1585610336.350819, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21725749969482422, "Value Loss": 0.0046930136159062386, "_runtime": 12968.289114236832, "_timestamp": 1585610337.9219837, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.230070099234581, "Value Loss": 0.013383678160607815, "_runtime": 12969.868917226791, "_timestamp": 1585610339.5017867, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20984791219234467, "Value Loss": 0.0004937126068398356, "_runtime": 12971.438242912292, "_timestamp": 1585610341.0711124, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2070949822664261, "Value Loss": 0.020351311191916466, "_runtime": 12973.018222808838, "_timestamp": 1585610342.6510923, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20032407343387604, "Value Loss": 0.02154606021940708, "_runtime": 12974.598984956741, "_timestamp": 1585610344.2318544, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16253791749477386, "Value Loss": 0.006439534015953541, "_runtime": 12976.178487539291, "_timestamp": 1585610345.811357, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1273086965084076, "Value Loss": 0.006043697707355022, "_runtime": 12977.759815216064, "_timestamp": 1585610347.3926847, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08358193933963776, "Value Loss": 0.00357527076266706, "_runtime": 12979.376500606537, "_timestamp": 1585610349.00937, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05866221338510513, "Value Loss": 0.0329870730638504, "_runtime": 12980.956137180328, "_timestamp": 1585610350.5890067, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024723149836063385, "Value Loss": 0.0011570892529562116, "_runtime": 12982.524489402771, "_timestamp": 1585610352.157359, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008499532006680965, "Value Loss": 0.003108856501057744, "_runtime": 12984.10582113266, "_timestamp": 1585610353.7386906, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0024440137203782797, "Value Loss": 0.014563431032001972, "_runtime": 12985.684805870056, "_timestamp": 1585610355.3176754, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019830375909805298, "Value Loss": 0.020430518314242363, "_runtime": 12987.249243736267, "_timestamp": 1585610356.8821132, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0255452748388052, "Value Loss": 0.023333381861448288, "_runtime": 12988.83005976677, "_timestamp": 1585610358.4629292, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.046419259160757065, "Value Loss": 0.0025641636457294226, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 12990.4058406353, "_timestamp": 1585610360.03871, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08374752849340439, "Value Loss": 0.0016187718138098717, "_runtime": 12991.98718047142, "_timestamp": 1585610361.62005, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11279633641242981, "Value Loss": 0.001070073340088129, "_runtime": 12993.568194627762, "_timestamp": 1585610363.201064, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14513035118579865, "Value Loss": 0.016471270471811295, "_runtime": 12995.134706735611, "_timestamp": 1585610364.7675762, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15531609952449799, "Value Loss": 0.01051388494670391, "_runtime": 12996.708716154099, "_timestamp": 1585610366.3415856, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14973251521587372, "Value Loss": 0.0356379933655262, "_runtime": 12998.269000291824, "_timestamp": 1585610367.9018698, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1311877816915512, "Value Loss": 0.004786523059010506, "_runtime": 12999.838744163513, "_timestamp": 1585610369.4716136, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10686513781547546, "Value Loss": 0.007555181626230478, "_runtime": 13001.419075489044, "_timestamp": 1585610371.051945, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09329144656658173, "Value Loss": 0.017027610912919044, "_runtime": 13003.040296077728, "_timestamp": 1585610372.6731656, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08551635593175888, "Value Loss": 0.03336093947291374, "_runtime": 13004.623006105423, "_timestamp": 1585610374.2558756, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0921948179602623, "Value Loss": 0.03007006272673607, "_runtime": 13006.19675540924, "_timestamp": 1585610375.829625, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06443671882152557, "Value Loss": 0.005840670317411423, "_runtime": 13007.756118059158, "_timestamp": 1585610377.3889875, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04272715374827385, "Value Loss": 0.016698485240340233, "_runtime": 13009.334922552109, "_timestamp": 1585610378.967792, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03201702609658241, "Value Loss": 0.009898551739752293, "_runtime": 13010.91703748703, "_timestamp": 1585610380.549907, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030753202736377716, "Value Loss": 0.019650515168905258, "_runtime": 13012.49686574936, "_timestamp": 1585610382.1297352, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03136850520968437, "Value Loss": 0.0018209746340289712, "_runtime": 13014.077204227448, "_timestamp": 1585610383.7100737, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02488137036561966, "Value Loss": 0.015185622498393059, "_runtime": 13015.660545110703, "_timestamp": 1585610385.2934146, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023953335359692574, "Value Loss": 0.003894689492881298, "_runtime": 13017.243654727936, "_timestamp": 1585610386.8765242, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02329251915216446, "Value Loss": 0.0021134852431714535, "_runtime": 13018.82522058487, "_timestamp": 1585610388.45809, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028406251221895218, "Value Loss": 0.0007714913226664066, "_runtime": 13020.395091295242, "_timestamp": 1585610390.0279608, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027859218418598175, "Value Loss": 0.0004650906485039741, "_runtime": 13021.976335048676, "_timestamp": 1585610391.6092045, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.040162164717912674, "Value Loss": 0.0074336472898721695, "_runtime": 13023.557200193405, "_timestamp": 1585610393.1900697, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05809866264462471, "Value Loss": 0.01437409408390522, "_runtime": 13025.13896894455, "_timestamp": 1585610394.7718384, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0691906288266182, "Value Loss": 0.0007329619838856161, "_runtime": 13026.760478973389, "_timestamp": 1585610396.3933485, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07844248414039612, "Value Loss": 0.0021693434100598097, "_runtime": 13028.3253262043, "_timestamp": 1585610397.9581957, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0864977240562439, "Value Loss": 0.0006184857338666916, "_runtime": 13029.896614551544, "_timestamp": 1585610399.529484, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09171852469444275, "Value Loss": 0.0027774423360824585, "_runtime": 13031.464230298996, "_timestamp": 1585610401.0970998, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09970065206289291, "Value Loss": 0.001024350756779313, "_runtime": 13033.043841838837, "_timestamp": 1585610402.6767113, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09835906326770782, "Value Loss": 0.0007973183528520167, "_runtime": 13034.614120006561, "_timestamp": 1585610404.2469895, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10698605328798294, "Value Loss": 0.01719222031533718, "_runtime": 13036.19324016571, "_timestamp": 1585610405.8261096, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12254355847835541, "Value Loss": 0.020194491371512413, "_runtime": 13037.771384716034, "_timestamp": 1585610407.4042542, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11755002290010452, "Value Loss": 0.00019215719657950103, "_runtime": 13039.349647045135, "_timestamp": 1585610408.9825165, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1266627460718155, "Value Loss": 0.003690320998430252, "_runtime": 13040.930738210678, "_timestamp": 1585610410.5636077, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11837383359670639, "Value Loss": 0.004819577094167471, "_runtime": 13042.508846759796, "_timestamp": 1585610412.1417162, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12317371368408203, "Value Loss": 0.028134504333138466, "_runtime": 13044.08724284172, "_timestamp": 1585610413.7201123, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11900337785482407, "Value Loss": 0.002305863657966256, "_runtime": 13045.666277885437, "_timestamp": 1585610415.2991474, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08505157381296158, "Value Loss": 0.00823170319199562, "_runtime": 13047.246281147003, "_timestamp": 1585610416.8791506, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04093916714191437, "Value Loss": 0.0011394397588446736, "_runtime": 13048.868964195251, "_timestamp": 1585610418.5018337, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01061286311596632, "Value Loss": 0.0008276983280666173, "_runtime": 13050.4474568367, "_timestamp": 1585610420.0803263, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024188052862882614, "Value Loss": 0.0016408930532634258, "_runtime": 13052.02544426918, "_timestamp": 1585610421.6583138, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05250081419944763, "Value Loss": 0.00491379015147686, "_runtime": 13053.595430850983, "_timestamp": 1585610423.2283003, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08229266107082367, "Value Loss": 0.0011886368738487363, "_runtime": 13055.175759792328, "_timestamp": 1585610424.8086293, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10347120463848114, "Value Loss": 0.010889277793467045, "_runtime": 13056.752781629562, "_timestamp": 1585610426.385651, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12408272176980972, "Value Loss": 0.025073092430830002, "_runtime": 13058.332848072052, "_timestamp": 1585610427.9657176, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12181784957647324, "Value Loss": 0.07273492962121964, "_runtime": 13059.91102528572, "_timestamp": 1585610429.5438948, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08406227827072144, "Value Loss": 0.010943659581243992, "_runtime": 13061.490112304688, "_timestamp": 1585610431.1229818, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03512398153543472, "Value Loss": 0.031049132347106934, "_runtime": 13063.064488172531, "_timestamp": 1585610432.6973577, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018235734896734357, "Value Loss": 0.0009588738903403282, "_runtime": 13064.636012554169, "_timestamp": 1585610434.268882, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048332758247852325, "Value Loss": 0.016239499673247337, "_runtime": 13066.203770160675, "_timestamp": 1585610435.8366396, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08747629076242447, "Value Loss": 0.000367808504961431, "_runtime": 13067.786497116089, "_timestamp": 1585610437.4193666, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14284050464630127, "Value Loss": 0.0921081155538559, "_runtime": 13069.355292797089, "_timestamp": 1585610438.9881623, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16784074902534485, "Value Loss": 0.00651266286149621, "_runtime": 13070.93361568451, "_timestamp": 1585610440.5664852, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19216488301753998, "Value Loss": 0.05493023619055748, "_runtime": 13072.541170835495, "_timestamp": 1585610442.1740403, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15993593633174896, "Value Loss": 0.010553868487477303, "_runtime": 13074.122800588608, "_timestamp": 1585610443.75567, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15039806067943573, "Value Loss": 0.0014813324669376016, "_runtime": 13075.70067191124, "_timestamp": 1585610445.3335414, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13548409938812256, "Value Loss": 0.1951397806406021, "_runtime": 13077.293963432312, "_timestamp": 1585610446.926833, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10460596531629562, "Value Loss": 0.0020000948570668697, "_runtime": 13078.893154621124, "_timestamp": 1585610448.526024, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09761221706867218, "Value Loss": 0.0031166498083621264, "_runtime": 13080.486942768097, "_timestamp": 1585610450.1198123, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08714009076356888, "Value Loss": 0.038609202951192856, "_runtime": 13082.085138559341, "_timestamp": 1585610451.718008, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08476841449737549, "Value Loss": 0.3270123600959778, "_runtime": 13083.681521892548, "_timestamp": 1585610453.3143914, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.056849405169487, "Value Loss": 0.011623703874647617, "_runtime": 13085.279295444489, "_timestamp": 1585610454.912165, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017064912244677544, "Value Loss": 0.018635708838701248, "_runtime": 13086.875427484512, "_timestamp": 1585610456.508297, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010799956507980824, "Value Loss": 0.13893170654773712, "_runtime": 13088.473237991333, "_timestamp": 1585610458.1061075, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04363073408603668, "Value Loss": 0.02040773630142212, "_runtime": 13090.069220781326, "_timestamp": 1585610459.7020903, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07545065879821777, "Value Loss": 0.03790317475795746, "_runtime": 13091.66670036316, "_timestamp": 1585610461.2995698, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08057066053152084, "Value Loss": 0.005019261036068201, "_runtime": 13093.263860940933, "_timestamp": 1585610462.8967304, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08179070055484772, "Value Loss": 0.0010332857491448522, "_runtime": 13094.84707403183, "_timestamp": 1585610464.4799435, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08419274538755417, "Value Loss": 0.0012567571830004454, "_runtime": 13096.4799990654, "_timestamp": 1585610466.1128685, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07978781312704086, "Value Loss": 0.004736440256237984, "_runtime": 13098.077392816544, "_timestamp": 1585610467.7102623, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06775599718093872, "Value Loss": 0.017249735072255135, "_runtime": 13099.674383878708, "_timestamp": 1585610469.3072534, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03325910493731499, "Value Loss": 0.01746436581015587, "_runtime": 13101.274007081985, "_timestamp": 1585610470.9068766, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.035171762108802795, "Value Loss": 0.017435844987630844, "_runtime": 13102.866565942764, "_timestamp": 1585610472.4994354, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02923993393778801, "Value Loss": 0.012745997868478298, "_runtime": 13104.452068805695, "_timestamp": 1585610474.0849383, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.040869373828172684, "Value Loss": 0.016030674800276756, "_runtime": 13106.04327583313, "_timestamp": 1585610475.6761453, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03350525721907616, "Value Loss": 0.0009272526949644089, "_runtime": 13107.633734703064, "_timestamp": 1585610477.2666042, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006405527703464031, "Value Loss": 0.005054503213614225, "_runtime": 13109.232086658478, "_timestamp": 1585610478.8649561, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0010829044040292501, "Value Loss": 0.0016670109471306205, "_runtime": 13110.822385549545, "_timestamp": 1585610480.455255, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009101426228880882, "Value Loss": 0.0033117833081632853, "_runtime": 13112.421662092209, "_timestamp": 1585610482.0545316, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019972188398241997, "Value Loss": 0.025213059037923813, "_runtime": 13114.019766330719, "_timestamp": 1585610483.6526358, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02156781405210495, "Value Loss": 0.04705207049846649, "_runtime": 13115.619924783707, "_timestamp": 1585610485.2527943, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008367926813662052, "Value Loss": 0.0004920621868222952, "_runtime": 13117.221024751663, "_timestamp": 1585610486.8538942, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029716655611991882, "Value Loss": 0.0011495794169604778, "_runtime": 13118.818489074707, "_timestamp": 1585610488.4513586, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03609862178564072, "Value Loss": 0.0323258638381958, "_runtime": 13120.456010341644, "_timestamp": 1585610490.0888798, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011460230685770512, "Value Loss": 0.03690728172659874, "_runtime": 13122.052181243896, "_timestamp": 1585610491.6850507, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030543744564056396, "Value Loss": 0.00013232350465841591, "_runtime": 13123.637390375137, "_timestamp": 1585610493.2702599, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07954350858926773, "Value Loss": 0.002019484993070364, "_runtime": 13125.227364301682, "_timestamp": 1585610494.8602338, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10752839595079422, "Value Loss": 0.010680757462978363, "_runtime": 13126.800880432129, "_timestamp": 1585610496.43375, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13184426724910736, "Value Loss": 0.015895765274763107, "_runtime": 13128.387048244476, "_timestamp": 1585610498.0199177, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11672167479991913, "Value Loss": 0.0004001088673248887, "_runtime": 13129.970462322235, "_timestamp": 1585610499.6033318, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12251034379005432, "Value Loss": 0.0009792469209060073, "_runtime": 13131.56726527214, "_timestamp": 1585610501.2001348, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11049872636795044, "Value Loss": 0.00295848585665226, "_runtime": 13133.16261935234, "_timestamp": 1585610502.7954888, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09944180399179459, "Value Loss": 0.00047182737034745514, "_runtime": 13134.7542552948, "_timestamp": 1585610504.3871248, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09233599901199341, "Value Loss": 0.003966357558965683, "_runtime": 13136.33487701416, "_timestamp": 1585610505.9677465, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07042238861322403, "Value Loss": 0.00027248248807154596, "_runtime": 13137.917028665543, "_timestamp": 1585610507.5498981, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05860115587711334, "Value Loss": 0.058164387941360474, "_runtime": 13139.490675926208, "_timestamp": 1585610509.1235454, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04241538792848587, "Value Loss": 0.004115361254662275, "_runtime": 13141.068029403687, "_timestamp": 1585610510.700899, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014972050674259663, "Value Loss": 0.0035160304978489876, "_runtime": 13142.64397931099, "_timestamp": 1585610512.2768488, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017563769593834877, "Value Loss": 0.0106881158426404, "_runtime": 13144.257969379425, "_timestamp": 1585610513.8908389, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01061286497861147, "Value Loss": 0.0006698090001009405, "_runtime": 13145.844665050507, "_timestamp": 1585610515.4775345, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.039262332022190094, "Value Loss": 0.025087807327508926, "_runtime": 13147.418201208115, "_timestamp": 1585610517.0510707, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03223911300301552, "Value Loss": 0.12637090682983398, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 13149.004882097244, "_timestamp": 1585610518.6377516, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.050227705389261246, "Value Loss": 0.002664332976564765, "_runtime": 13150.58341550827, "_timestamp": 1585610520.216285, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.053411826491355896, "Value Loss": 0.016135303303599358, "_runtime": 13152.16927075386, "_timestamp": 1585610521.8021402, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03817620500922203, "Value Loss": 0.04100507125258446, "_runtime": 13153.760594844818, "_timestamp": 1585610523.3934643, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024918457493185997, "Value Loss": 0.418743759393692, "_runtime": 13155.347594738007, "_timestamp": 1585610524.9804642, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15667414665222168, "Value Loss": 0.044923219829797745, "_runtime": 13156.921435117722, "_timestamp": 1585610526.5543046, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2632935643196106, "Value Loss": 0.013234773650765419, "_runtime": 13158.494598388672, "_timestamp": 1585610528.1274679, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3468347489833832, "Value Loss": 0.7401042580604553, "_runtime": 13160.065294504166, "_timestamp": 1585610529.698164, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27745330333709717, "Value Loss": 0.3391677141189575, "_runtime": 13161.63661122322, "_timestamp": 1585610531.2694807, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17070625722408295, "Value Loss": 0.006431047338992357, "_runtime": 13163.209477424622, "_timestamp": 1585610532.842347, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07086320221424103, "Value Loss": 0.1372556984424591, "_runtime": 13164.780082464218, "_timestamp": 1585610534.412952, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04627317935228348, "Value Loss": 0.9929199814796448, "_runtime": 13166.385400056839, "_timestamp": 1585610536.0182695, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29223838448524475, "Value Loss": 0.3877098858356476, "_runtime": 13167.957071781158, "_timestamp": 1585610537.5899413, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5139544010162354, "Value Loss": 0.006379107479006052, "_runtime": 13169.528866052628, "_timestamp": 1585610539.1617355, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7026069164276123, "Value Loss": 0.018701087683439255, "_runtime": 13171.100345134735, "_timestamp": 1585610540.7332146, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8711288571357727, "Value Loss": 0.18915267288684845, "_runtime": 13172.671057462692, "_timestamp": 1585610542.303927, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9853511452674866, "Value Loss": 0.05340054631233215, "_runtime": 13174.231263160706, "_timestamp": 1585610543.8641326, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0556209087371826, "Value Loss": 0.27038881182670593, "_runtime": 13175.792046546936, "_timestamp": 1585610545.424916, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0124666690826416, "Value Loss": 1.2385605573654175, "_runtime": 13177.361877202988, "_timestamp": 1585610546.9947467, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7378128170967102, "Value Loss": 3.5119714736938477, "_runtime": 13178.934883594513, "_timestamp": 1585610548.567753, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37779700756073, "Value Loss": 0.08145489543676376, "_runtime": 13180.500776052475, "_timestamp": 1585610550.1336455, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00537522928789258, "Value Loss": 0.6447308659553528, "_runtime": 13182.068734884262, "_timestamp": 1585610551.7016044, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44725608825683594, "Value Loss": 0.11419154703617096, "_runtime": 13183.640711784363, "_timestamp": 1585610553.2735813, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9040034413337708, "Value Loss": 0.743987500667572, "_runtime": 13185.210808992386, "_timestamp": 1585610554.8436785, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2722065448760986, "Value Loss": 4.156603813171387, "_runtime": 13186.78183722496, "_timestamp": 1585610556.4147067, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4778388738632202, "Value Loss": 0.6577605605125427, "_runtime": 13188.351287603378, "_timestamp": 1585610557.984157, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5741311311721802, "Value Loss": 0.22698825597763062, "_runtime": 13189.947713851929, "_timestamp": 1585610559.5805833, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6609578132629395, "Value Loss": 2.7522153854370117, "_runtime": 13191.514142513275, "_timestamp": 1585610561.147012, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.459572434425354, "Value Loss": 0.6311501860618591, "_runtime": 13193.082884550095, "_timestamp": 1585610562.715754, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1141587495803833, "Value Loss": 25.056058883666992, "_runtime": 13194.637650251389, "_timestamp": 1585610564.2705197, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5641610026359558, "Value Loss": 0.28384554386138916, "_runtime": 13196.204701900482, "_timestamp": 1585610565.8375714, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05926389992237091, "Value Loss": 2.085489511489868, "_runtime": 13197.785632371902, "_timestamp": 1585610567.4185019, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5089358687400818, "Value Loss": 8.894094467163086, "_runtime": 13199.362628698349, "_timestamp": 1585610568.9954982, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5667393207550049, "Value Loss": 1.5686019659042358, "_runtime": 13200.94285082817, "_timestamp": 1585610570.5757203, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44594764709472656, "Value Loss": 0.782712459564209, "_runtime": 13202.520705223083, "_timestamp": 1585610572.1535747, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3126195967197418, "Value Loss": 0.19467581808567047, "_runtime": 13204.09691119194, "_timestamp": 1585610573.7297807, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15225476026535034, "Value Loss": 0.011434962041676044, "_runtime": 13205.67323589325, "_timestamp": 1585610575.3061054, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0001777939178282395, "Value Loss": 1.2521172761917114, "_runtime": 13207.254732370377, "_timestamp": 1585610576.8876019, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17530091106891632, "Value Loss": 0.24530909955501556, "_runtime": 13208.821103334427, "_timestamp": 1585610578.4539728, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40804722905158997, "Value Loss": 0.43160736560821533, "_runtime": 13210.402826309204, "_timestamp": 1585610580.0356958, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6014032959938049, "Value Loss": 1.0402576923370361, "_runtime": 13211.972091197968, "_timestamp": 1585610581.6049607, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7245363593101501, "Value Loss": 0.04602167010307312, "_runtime": 13213.587601661682, "_timestamp": 1585610583.2204711, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8515169024467468, "Value Loss": 0.007608081214129925, "_runtime": 13215.168898105621, "_timestamp": 1585610584.8017676, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9569883942604065, "Value Loss": 0.018909823149442673, "_runtime": 13216.750205755234, "_timestamp": 1585610586.3830752, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0307995080947876, "Value Loss": 0.018097560852766037, "_runtime": 13218.319819450378, "_timestamp": 1585610587.952689, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1022323369979858, "Value Loss": 1.1494131088256836, "_runtime": 13219.904016256332, "_timestamp": 1585610589.5368857, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1709011793136597, "Value Loss": 1.5084630250930786, "_runtime": 13221.485199928284, "_timestamp": 1585610591.1180694, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0304266214370728, "Value Loss": 0.03657742589712143, "_runtime": 13223.045050144196, "_timestamp": 1585610592.6779196, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8739351630210876, "Value Loss": 0.009640456177294254, "_runtime": 13224.617591381073, "_timestamp": 1585610594.2504609, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.729417622089386, "Value Loss": 0.015542139299213886, "_runtime": 13226.20498585701, "_timestamp": 1585610595.8378553, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.580178439617157, "Value Loss": 0.05037067085504532, "_runtime": 13227.802942276001, "_timestamp": 1585610597.4358118, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42272189259529114, "Value Loss": 0.1857348531484604, "_runtime": 13229.403929233551, "_timestamp": 1585610599.0367987, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27331048250198364, "Value Loss": 0.10116254538297653, "_runtime": 13231.00336933136, "_timestamp": 1585610600.6362388, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1519385725259781, "Value Loss": 0.030568890273571014, "_runtime": 13232.598618745804, "_timestamp": 1585610602.2314882, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026083819568157196, "Value Loss": 0.014381871558725834, "_runtime": 13234.2016851902, "_timestamp": 1585610603.8345547, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06881444156169891, "Value Loss": 0.16557443141937256, "_runtime": 13235.80017733574, "_timestamp": 1585610605.4330468, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08099114894866943, "Value Loss": 0.3130018711090088, "_runtime": 13237.436196804047, "_timestamp": 1585610607.0690663, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009145996533334255, "Value Loss": 0.025607876479625702, "_runtime": 13239.02347612381, "_timestamp": 1585610608.6563456, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07668288052082062, "Value Loss": 0.025269843637943268, "_runtime": 13240.62017917633, "_timestamp": 1585610610.2530487, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17875699698925018, "Value Loss": 0.007173159159719944, "_runtime": 13242.205933570862, "_timestamp": 1585610611.838803, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2713836133480072, "Value Loss": 0.034340932965278625, "_runtime": 13243.804533958435, "_timestamp": 1585610613.4374034, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3471466898918152, "Value Loss": 0.019235802814364433, "_runtime": 13245.401715278625, "_timestamp": 1585610615.0345848, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4284667670726776, "Value Loss": 0.00484446482732892, "_runtime": 13246.987497806549, "_timestamp": 1585610616.6203673, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5011150240898132, "Value Loss": 0.3462502956390381, "_runtime": 13248.56380534172, "_timestamp": 1585610618.1966748, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4760762155056, "Value Loss": 0.04808838292956352, "_runtime": 13250.152426719666, "_timestamp": 1585610619.7852962, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40600448846817017, "Value Loss": 0.09828750044107437, "_runtime": 13251.735848426819, "_timestamp": 1585610621.368718, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.31706690788269043, "Value Loss": 0.20042115449905396, "_runtime": 13253.334585666656, "_timestamp": 1585610622.9674551, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17671529948711395, "Value Loss": 0.11897199600934982, "_runtime": 13254.919385433197, "_timestamp": 1585610624.552255, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06556805223226547, "Value Loss": 0.012858997099101543, "_runtime": 13256.513930559158, "_timestamp": 1585610626.1468, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04130648449063301, "Value Loss": 0.004837637767195702, "_runtime": 13258.11198759079, "_timestamp": 1585610627.744857, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.138306125998497, "Value Loss": 0.028941703960299492, "_runtime": 13259.746802568436, "_timestamp": 1585610629.379672, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21028102934360504, "Value Loss": 0.01668494939804077, "_runtime": 13261.34321641922, "_timestamp": 1585610630.976086, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.27237409353256226, "Value Loss": 0.00820248480886221, "_runtime": 13262.93979024887, "_timestamp": 1585610632.5726597, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32609570026397705, "Value Loss": 0.03232932463288307, "_runtime": 13264.525587320328, "_timestamp": 1585610634.1584568, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3519476652145386, "Value Loss": 0.19268324971199036, "_runtime": 13266.12121963501, "_timestamp": 1585610635.754089, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34983909130096436, "Value Loss": 0.11704006046056747, "_runtime": 13267.71593952179, "_timestamp": 1585610637.348809, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3578217923641205, "Value Loss": 0.31815603375434875, "_runtime": 13269.31210398674, "_timestamp": 1585610638.9449735, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36230307817459106, "Value Loss": 0.019912157207727432, "_runtime": 13270.895410060883, "_timestamp": 1585610640.5282795, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.350683331489563, "Value Loss": 0.07603419572114944, "_runtime": 13272.482393026352, "_timestamp": 1585610642.1152625, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30807194113731384, "Value Loss": 0.04174487292766571, "_runtime": 13274.069051027298, "_timestamp": 1585610643.7019205, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2341175228357315, "Value Loss": 0.052021004259586334, "_runtime": 13275.664831399918, "_timestamp": 1585610645.297701, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12179029732942581, "Value Loss": 0.013029367662966251, "_runtime": 13277.251819610596, "_timestamp": 1585610646.884689, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016052697319537401, "Value Loss": 0.002321824198588729, "_runtime": 13278.836888313293, "_timestamp": 1585610648.4697578, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1170181930065155, "Value Loss": 0.06331023573875427, "_runtime": 13280.422539949417, "_timestamp": 1585610650.0554094, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20524951815605164, "Value Loss": 0.02504996955394745, "_runtime": 13282.014462947845, "_timestamp": 1585610651.6473324, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30198436975479126, "Value Loss": 0.07558681070804596, "_runtime": 13283.63713979721, "_timestamp": 1585610653.2700093, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3965564966201782, "Value Loss": 0.03587879240512848, "_runtime": 13285.234210729599, "_timestamp": 1585610654.8670802, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.47721371054649353, "Value Loss": 0.06209776550531387, "_runtime": 13286.811267852783, "_timestamp": 1585610656.4441373, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4939132332801819, "Value Loss": 0.012494629248976707, "_runtime": 13288.408532857895, "_timestamp": 1585610658.0414023, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49069833755493164, "Value Loss": 0.004897702485322952, "_runtime": 13289.994660139084, "_timestamp": 1585610659.6275296, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.48661550879478455, "Value Loss": 0.032344426959753036, "_runtime": 13291.590551614761, "_timestamp": 1585610661.223421, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44418132305145264, "Value Loss": 0.04314999654889107, "_runtime": 13293.187097072601, "_timestamp": 1585610662.8199666, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3759256601333618, "Value Loss": 0.007911921478807926, "_runtime": 13294.761225700378, "_timestamp": 1585610664.3940952, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32339560985565186, "Value Loss": 0.11997228860855103, "_runtime": 13296.35819363594, "_timestamp": 1585610665.991063, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27333864569664, "Value Loss": 0.026304475963115692, "_runtime": 13297.942717790604, "_timestamp": 1585610667.5755873, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21240943670272827, "Value Loss": 0.0015180852496996522, "_runtime": 13299.536560058594, "_timestamp": 1585610669.1694295, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1473681628704071, "Value Loss": 0.027043292298913002, "_runtime": 13301.13328075409, "_timestamp": 1585610670.7661502, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07859624177217484, "Value Loss": 0.01943708211183548, "_runtime": 13302.719714641571, "_timestamp": 1585610672.3525841, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01964007131755352, "Value Loss": 0.007343437522649765, "_runtime": 13304.304070711136, "_timestamp": 1585610673.9369402, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02437879890203476, "Value Loss": 0.004023238085210323, "_runtime": 13305.903683423996, "_timestamp": 1585610675.536553, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.056990984827280045, "Value Loss": 0.0003163196088280529, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 13307.527937412262, "_timestamp": 1585610677.160807, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08292412012815475, "Value Loss": 0.004310227930545807, "_runtime": 13307.527937412262, "_timestamp": 1585610677.160807, "_step": 499}
