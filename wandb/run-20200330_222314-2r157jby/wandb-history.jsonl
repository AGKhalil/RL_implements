{"Episode reward": 81.21285082568642, "Episode length": 503, "Policy Loss": 0.43337470293045044, "Value Loss": 19.8802433013916, "_runtime": 9635.634052991867, "_timestamp": 1585607005.2669225, "_step": 0}
{"Episode reward": -95.72311383589908, "Episode length": 999, "Policy Loss": -1.341681957244873, "Value Loss": 186.01419067382812, "_runtime": 9636.967296600342, "_timestamp": 1585607006.600166, "_step": 1}
{"Episode reward": 14.142494719676293, "Episode length": 884, "Policy Loss": 0.9266718626022339, "Value Loss": 98.29219818115234, "_runtime": 9637.671784162521, "_timestamp": 1585607007.3046536, "_step": 2}
{"Episode reward": 56.166227388897475, "Episode length": 446, "Policy Loss": 0.017141111195087433, "Value Loss": 49.08021926879883, "_runtime": 9639.263633966446, "_timestamp": 1585607008.8965034, "_step": 3}
{"Episode reward": -97.14358418953076, "Episode length": 999, "Policy Loss": -2.2452406883239746, "Value Loss": 62.89497756958008, "_runtime": 9640.826402902603, "_timestamp": 1585607010.4592724, "_step": 4}
{"Episode reward": -96.09759379918653, "Episode length": 999, "Policy Loss": -0.8424541354179382, "Value Loss": 2.680875539779663, "_runtime": 9642.379989862442, "_timestamp": 1585607012.0128593, "_step": 5}
{"Episode reward": -95.41999824000867, "Episode length": 999, "Policy Loss": -2.018878936767578, "Value Loss": 5.198677062988281, "_runtime": 9643.972481489182, "_timestamp": 1585607013.605351, "_step": 6}
{"Episode reward": -96.65630955805828, "Episode length": 999, "Policy Loss": -1.4081887006759644, "Value Loss": 5.638675689697266, "_runtime": 9645.578510046005, "_timestamp": 1585607015.2113795, "_step": 7}
{"Episode reward": -98.85841693973154, "Episode length": 999, "Policy Loss": -1.6827545166015625, "Value Loss": 3.3784098625183105, "_runtime": 9647.155527114868, "_timestamp": 1585607016.7883966, "_step": 8}
{"Episode reward": -96.98296952882433, "Episode length": 999, "Policy Loss": -1.8419214487075806, "Value Loss": 4.130342960357666, "_runtime": 9648.744933366776, "_timestamp": 1585607018.3778028, "_step": 9}
{"Episode reward": -98.51120073983022, "Episode length": 999, "Policy Loss": -1.2928032875061035, "Value Loss": 3.7406539916992188, "_runtime": 9650.319707632065, "_timestamp": 1585607019.952577, "_step": 10}
{"Episode reward": -97.30720390193909, "Episode length": 999, "Policy Loss": 4.98365592956543, "Value Loss": 52.35990905761719, "_runtime": 9651.91324877739, "_timestamp": 1585607021.5461183, "_step": 11}
{"Episode reward": -98.72124707650678, "Episode length": 999, "Policy Loss": -2.032728672027588, "Value Loss": 6.693416118621826, "_runtime": 9653.50650715828, "_timestamp": 1585607023.1393766, "_step": 12}
{"Episode reward": -97.66791963644008, "Episode length": 999, "Policy Loss": -44.809532165527344, "Value Loss": 887.3880615234375, "_runtime": 9655.089527606964, "_timestamp": 1585607024.722397, "_step": 13}
{"Episode reward": -97.91267128339298, "Episode length": 999, "Policy Loss": 0.801302969455719, "Value Loss": 16.635578155517578, "_runtime": 9656.687362909317, "_timestamp": 1585607026.3202324, "_step": 14}
{"Episode reward": -97.53551757275919, "Episode length": 999, "Policy Loss": 21.928512573242188, "Value Loss": 443.8749694824219, "_runtime": 9658.285345077515, "_timestamp": 1585607027.9182146, "_step": 15}
{"Episode reward": -98.26273960696282, "Episode length": 999, "Policy Loss": 9.836775779724121, "Value Loss": 178.97279357910156, "_runtime": 9659.882946491241, "_timestamp": 1585607029.515816, "_step": 16}
{"Episode reward": -98.88182516832735, "Episode length": 999, "Policy Loss": 2.90266489982605, "Value Loss": 38.64149856567383, "_runtime": 9661.241373062134, "_timestamp": 1585607030.8742425, "_step": 17}
{"Episode reward": 15.392875112443335, "Episode length": 852, "Policy Loss": 38.93113327026367, "Value Loss": 255.43426513671875, "_runtime": 9662.14402103424, "_timestamp": 1585607031.7768905, "_step": 18}
{"Episode reward": 45.28574502856723, "Episode length": 550, "Policy Loss": 3.921630859375, "Value Loss": 40.105224609375, "_runtime": 9663.727332353592, "_timestamp": 1585607033.3602018, "_step": 19}
{"Episode reward": -99.07354402497376, "Episode length": 999, "Policy Loss": -0.1366635262966156, "Value Loss": 18.664609909057617, "_runtime": 9664.425244569778, "_timestamp": 1585607034.058114, "_step": 20}
{"Episode reward": 57.82546521400646, "Episode length": 422, "Policy Loss": -50.194732666015625, "Value Loss": 512.6199951171875, "_runtime": 9664.871389627457, "_timestamp": 1585607034.504259, "_step": 21}
{"Episode reward": 72.96656873371877, "Episode length": 272, "Policy Loss": -52.958988189697266, "Value Loss": 326.747802734375, "_runtime": 9665.369195699692, "_timestamp": 1585607035.0020652, "_step": 22}
{"Episode reward": 70.89999999999986, "Episode length": 291, "Policy Loss": 3.4117867946624756, "Value Loss": 189.1436004638672, "_runtime": 9666.514494657516, "_timestamp": 1585607036.1473641, "_step": 23}
{"Episode reward": 25.801081426166746, "Episode length": 748, "Policy Loss": 3.662275552749634, "Value Loss": 59.40687561035156, "_runtime": 9668.04076719284, "_timestamp": 1585607037.6736367, "_step": 24}
{"Episode reward": -99.7251036312781, "Episode length": 999, "Policy Loss": 0.1804264336824417, "Value Loss": 5.91181755065918, "_runtime": 9669.59591960907, "_timestamp": 1585607039.228789, "_step": 25}
{"Episode reward": -99.67891685952208, "Episode length": 999, "Policy Loss": 0.1424037665128708, "Value Loss": 9.576255798339844, "_runtime": 9671.160515069962, "_timestamp": 1585607040.7933846, "_step": 26}
{"Episode reward": -99.63469540647937, "Episode length": 999, "Policy Loss": 0.624871551990509, "Value Loss": 22.622447967529297, "_runtime": 9672.496200561523, "_timestamp": 1585607042.12907, "_step": 27}
{"Episode reward": 15.837414991332253, "Episode length": 845, "Policy Loss": 1.739465355873108, "Value Loss": 47.76435470581055, "_runtime": 9674.074061870575, "_timestamp": 1585607043.7069314, "_step": 28}
{"Episode reward": -99.62060744907801, "Episode length": 999, "Policy Loss": -0.2103084772825241, "Value Loss": 4.56306266784668, "_runtime": 9675.66168498993, "_timestamp": 1585607045.2945545, "_step": 29}
{"Episode reward": -99.49363369351349, "Episode length": 999, "Policy Loss": 0.08682138472795486, "Value Loss": 10.97485065460205, "_runtime": 9676.321493387222, "_timestamp": 1585607045.9543629, "_step": 30}
{"Episode reward": 59.34178535395738, "Episode length": 407, "Policy Loss": 2.0301146507263184, "Value Loss": 43.53398895263672, "_runtime": 9677.908343076706, "_timestamp": 1585607047.5412126, "_step": 31}
{"Episode reward": -99.58270217525285, "Episode length": 999, "Policy Loss": 0.016613580286502838, "Value Loss": 5.396006107330322, "_runtime": 9679.497930049896, "_timestamp": 1585607049.1307995, "_step": 32}
{"Episode reward": -99.71801841577987, "Episode length": 999, "Policy Loss": -0.3727555274963379, "Value Loss": 4.88348913192749, "_runtime": 9681.036528348923, "_timestamp": 1585607050.6693978, "_step": 33}
{"Episode reward": -99.53297393478287, "Episode length": 999, "Policy Loss": -0.6980544328689575, "Value Loss": 3.1559553146362305, "_runtime": 9682.616505384445, "_timestamp": 1585607052.2493749, "_step": 34}
{"Episode reward": -98.98511603402304, "Episode length": 999, "Policy Loss": -0.8577669858932495, "Value Loss": 2.1430232524871826, "_runtime": 9684.208222389221, "_timestamp": 1585607053.8410919, "_step": 35}
{"Episode reward": -99.4033366691191, "Episode length": 999, "Policy Loss": -0.6426841616630554, "Value Loss": 3.324343681335449, "_runtime": 9685.786254882812, "_timestamp": 1585607055.4191244, "_step": 36}
{"Episode reward": -99.30848233134465, "Episode length": 999, "Policy Loss": -0.6791961789131165, "Value Loss": 1.5978789329528809, "_runtime": 9687.387315034866, "_timestamp": 1585607057.0201845, "_step": 37}
{"Episode reward": -99.7435236656326, "Episode length": 999, "Policy Loss": -0.6524965167045593, "Value Loss": 0.01237465813755989, "_runtime": 9688.97991991043, "_timestamp": 1585607058.6127894, "_step": 38}
{"Episode reward": -99.74465339893803, "Episode length": 999, "Policy Loss": -0.591335654258728, "Value Loss": 0.2567756175994873, "_runtime": 9690.5735039711, "_timestamp": 1585607060.2063735, "_step": 39}
{"Episode reward": -99.63258169969639, "Episode length": 999, "Policy Loss": -0.6064523458480835, "Value Loss": 2.0877583026885986, "_runtime": 9691.466534376144, "_timestamp": 1585607061.0994039, "_step": 40}
{"Episode reward": 45.77274250629658, "Episode length": 543, "Policy Loss": 0.4057289958000183, "Value Loss": 20.29355239868164, "_runtime": 9693.085230112076, "_timestamp": 1585607062.7180996, "_step": 41}
{"Episode reward": -99.40128114964908, "Episode length": 999, "Policy Loss": -0.46900415420532227, "Value Loss": 1.9500980377197266, "_runtime": 9694.231460571289, "_timestamp": 1585607063.86433, "_step": 42}
{"Episode reward": 28.825436387012928, "Episode length": 714, "Policy Loss": 0.29199036955833435, "Value Loss": 13.762651443481445, "_runtime": 9695.308269023895, "_timestamp": 1585607064.9411385, "_step": 43}
{"Episode reward": 31.538920378865058, "Episode length": 686, "Policy Loss": 0.2870495319366455, "Value Loss": 14.369629859924316, "_runtime": 9695.801072359085, "_timestamp": 1585607065.4339418, "_step": 44}
{"Episode reward": 71.99999999999989, "Episode length": 280, "Policy Loss": 1.5093454122543335, "Value Loss": 35.23825454711914, "_runtime": 9696.301293611526, "_timestamp": 1585607065.934163, "_step": 45}
{"Episode reward": 69.36382806293534, "Episode length": 308, "Policy Loss": 1.2957042455673218, "Value Loss": 32.29737854003906, "_runtime": 9697.867637634277, "_timestamp": 1585607067.500507, "_step": 46}
{"Episode reward": -99.8000246291093, "Episode length": 999, "Policy Loss": -0.6291776299476624, "Value Loss": 0.011842258274555206, "_runtime": 9699.38603925705, "_timestamp": 1585607069.0189087, "_step": 47}
{"Episode reward": -99.80672089168662, "Episode length": 999, "Policy Loss": -0.6408326029777527, "Value Loss": 0.01148171629756689, "_runtime": 9700.903824090958, "_timestamp": 1585607070.5366936, "_step": 48}
{"Episode reward": -99.5735305903582, "Episode length": 999, "Policy Loss": -0.6341875791549683, "Value Loss": 0.010761784389615059, "_runtime": 9702.495380878448, "_timestamp": 1585607072.1282504, "_step": 49}
{"Episode reward": -99.6870425494432, "Episode length": 999, "Policy Loss": -0.6376133561134338, "Value Loss": 0.010882856324315071, "_runtime": 9703.004321575165, "_timestamp": 1585607072.637191, "_step": 50}
{"Episode reward": 69.97296344199552, "Episode length": 302, "Policy Loss": 1.3321717977523804, "Value Loss": 33.06586837768555, "_runtime": 9704.566176652908, "_timestamp": 1585607074.1990461, "_step": 51}
{"Episode reward": -99.39912409915569, "Episode length": 999, "Policy Loss": -0.6157956123352051, "Value Loss": 0.013305113650858402, "_runtime": 9706.141366958618, "_timestamp": 1585607075.7742364, "_step": 52}
{"Episode reward": 1.7163092117653207, "Episode length": 985, "Policy Loss": -0.029303351417183876, "Value Loss": 10.07491683959961, "_runtime": 9707.160341024399, "_timestamp": 1585607076.7932105, "_step": 53}
{"Episode reward": 33.29548233497724, "Episode length": 668, "Policy Loss": 0.2912156879901886, "Value Loss": 14.799223899841309, "_runtime": 9708.734956741333, "_timestamp": 1585607078.3678262, "_step": 54}
{"Episode reward": -99.57929948249229, "Episode length": 999, "Policy Loss": -0.6110723614692688, "Value Loss": 0.17669470608234406, "_runtime": 9710.329523563385, "_timestamp": 1585607079.962393, "_step": 55}
{"Episode reward": -99.81810104134935, "Episode length": 999, "Policy Loss": -0.5745618939399719, "Value Loss": 0.14520655572414398, "_runtime": 9711.352945327759, "_timestamp": 1585607080.9858148, "_step": 56}
{"Episode reward": 34.793793417623405, "Episode length": 654, "Policy Loss": 0.27665001153945923, "Value Loss": 15.100236892700195, "_runtime": 9712.929123878479, "_timestamp": 1585607082.5619934, "_step": 57}
{"Episode reward": -99.66119377877193, "Episode length": 999, "Policy Loss": -0.5685595273971558, "Value Loss": 0.03315157815814018, "_runtime": 9713.81608247757, "_timestamp": 1585607083.448952, "_step": 58}
{"Episode reward": 46.322223308070775, "Episode length": 538, "Policy Loss": 0.43689703941345215, "Value Loss": 18.547895431518555, "_runtime": 9715.360805511475, "_timestamp": 1585607084.993675, "_step": 59}
{"Episode reward": -99.5999523351479, "Episode length": 999, "Policy Loss": -0.5892572402954102, "Value Loss": 0.09307732433080673, "_runtime": 9716.004394054413, "_timestamp": 1585607085.6372635, "_step": 60}
{"Episode reward": 61.75476021973273, "Episode length": 385, "Policy Loss": 0.9482876062393188, "Value Loss": 25.583253860473633, "_runtime": 9717.576850891113, "_timestamp": 1585607087.2097204, "_step": 61}
{"Episode reward": -99.7883680007232, "Episode length": 999, "Policy Loss": -0.6044113636016846, "Value Loss": 0.049100350588560104, "_runtime": 9719.16092824936, "_timestamp": 1585607088.7937977, "_step": 62}
{"Episode reward": -99.35276344952152, "Episode length": 999, "Policy Loss": -0.5888051986694336, "Value Loss": 0.014778723008930683, "_runtime": 9720.327303886414, "_timestamp": 1585607089.9601734, "_step": 63}
{"Episode reward": 23.000658691069205, "Episode length": 775, "Policy Loss": 0.1305769979953766, "Value Loss": 12.831969261169434, "_runtime": 9721.9043135643, "_timestamp": 1585607091.537183, "_step": 64}
{"Episode reward": -99.48600692687769, "Episode length": 999, "Policy Loss": -0.6033003926277161, "Value Loss": 0.030852342024445534, "_runtime": 9723.477320194244, "_timestamp": 1585607093.1101897, "_step": 65}
{"Episode reward": -99.48686496078598, "Episode length": 999, "Policy Loss": -0.6004617810249329, "Value Loss": 0.01190195232629776, "_runtime": 9725.021442651749, "_timestamp": 1585607094.6543121, "_step": 66}
{"Episode reward": -99.41021066921975, "Episode length": 999, "Policy Loss": -0.6132121682167053, "Value Loss": 0.021914323791861534, "_runtime": 9726.091840744019, "_timestamp": 1585607095.7247102, "_step": 67}
{"Episode reward": 33.8898737999489, "Episode length": 665, "Policy Loss": 0.24093949794769287, "Value Loss": 14.961705207824707, "_runtime": 9726.878032445908, "_timestamp": 1585607096.510902, "_step": 68}
{"Episode reward": 52.089344756997484, "Episode length": 481, "Policy Loss": 0.6021580696105957, "Value Loss": 20.681663513183594, "_runtime": 9728.45033788681, "_timestamp": 1585607098.0832074, "_step": 69}
{"Episode reward": -99.80181315234955, "Episode length": 999, "Policy Loss": -0.6014942526817322, "Value Loss": 0.0260805394500494, "_runtime": 9729.78497004509, "_timestamp": 1585607099.4178395, "_step": 70}
{"Episode reward": 14.930990244745601, "Episode length": 854, "Policy Loss": 0.07453233748674393, "Value Loss": 11.602195739746094, "_runtime": 9731.311220884323, "_timestamp": 1585607100.9440904, "_step": 71}
{"Episode reward": -99.59850637878269, "Episode length": 999, "Policy Loss": -0.5826491117477417, "Value Loss": 0.018541568890213966, "_runtime": 9732.224931001663, "_timestamp": 1585607101.8578005, "_step": 72}
{"Episode reward": 43.6530851507496, "Episode length": 564, "Policy Loss": 0.470326691865921, "Value Loss": 17.550209045410156, "_runtime": 9733.810317277908, "_timestamp": 1585607103.4431868, "_step": 73}
{"Episode reward": -99.64920727753058, "Episode length": 999, "Policy Loss": -0.5899598598480225, "Value Loss": 0.13017107546329498, "_runtime": 9735.38929605484, "_timestamp": 1585607105.0221655, "_step": 74}
{"Episode reward": -99.64653326298438, "Episode length": 999, "Policy Loss": -0.5690674781799316, "Value Loss": 0.07167845219373703, "_runtime": 9736.915044784546, "_timestamp": 1585607106.5479143, "_step": 75}
{"Episode reward": -99.54463091458173, "Episode length": 999, "Policy Loss": -0.5701846480369568, "Value Loss": 0.06667438894510269, "_runtime": 9738.499447107315, "_timestamp": 1585607108.1323166, "_step": 76}
{"Episode reward": -99.70145065786643, "Episode length": 999, "Policy Loss": -0.5568950772285461, "Value Loss": 0.02693573199212551, "_runtime": 9740.090200424194, "_timestamp": 1585607109.72307, "_step": 77}
{"Episode reward": -99.78923225188488, "Episode length": 999, "Policy Loss": -0.5639795660972595, "Value Loss": 0.031146729364991188, "_runtime": 9741.704102993011, "_timestamp": 1585607111.3369725, "_step": 78}
{"Episode reward": -99.67318129336788, "Episode length": 999, "Policy Loss": -0.5765456557273865, "Value Loss": 0.03861028701066971, "_runtime": 9743.310986757278, "_timestamp": 1585607112.9438562, "_step": 79}
{"Episode reward": -99.83339771754551, "Episode length": 999, "Policy Loss": -0.5718300342559814, "Value Loss": 0.016839414834976196, "_runtime": 9744.896142482758, "_timestamp": 1585607114.529012, "_step": 80}
{"Episode reward": -99.64318214506937, "Episode length": 999, "Policy Loss": -0.566572368144989, "Value Loss": 0.022027060389518738, "_runtime": 9746.476898908615, "_timestamp": 1585607116.1097684, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5624575018882751, "Value Loss": 0.00979712512344122, "_runtime": 9748.000545740128, "_timestamp": 1585607117.6334152, "_step": 82}
{"Episode reward": 5.104387306062222, "Episode length": 951, "Policy Loss": 0.04425005242228508, "Value Loss": 10.481048583984375, "_runtime": 9749.595497131348, "_timestamp": 1585607119.2283666, "_step": 83}
{"Episode reward": -99.20155452551418, "Episode length": 999, "Policy Loss": -0.5596967935562134, "Value Loss": 0.008566954173147678, "_runtime": 9751.1733314991, "_timestamp": 1585607120.806201, "_step": 84}
{"Episode reward": -99.5088536501208, "Episode length": 999, "Policy Loss": -0.5566011071205139, "Value Loss": 0.008351273834705353, "_runtime": 9752.753523349762, "_timestamp": 1585607122.3863928, "_step": 85}
{"Episode reward": -99.54838867623337, "Episode length": 999, "Policy Loss": -0.5531227588653564, "Value Loss": 0.008135472424328327, "_runtime": 9753.292185544968, "_timestamp": 1585607122.925055, "_step": 86}
{"Episode reward": 68.99296134875605, "Episode length": 311, "Policy Loss": 1.4162921905517578, "Value Loss": 32.126243591308594, "_runtime": 9754.36866569519, "_timestamp": 1585607124.0015352, "_step": 87}
{"Episode reward": 31.637729004089095, "Episode length": 685, "Policy Loss": 0.33905160427093506, "Value Loss": 14.538665771484375, "_runtime": 9755.95054769516, "_timestamp": 1585607125.5834172, "_step": 88}
{"Episode reward": -99.71833273128584, "Episode length": 999, "Policy Loss": -0.509928822517395, "Value Loss": 0.008568065240979195, "_runtime": 9757.472328662872, "_timestamp": 1585607127.1051981, "_step": 89}
{"Episode reward": -99.27360399805339, "Episode length": 999, "Policy Loss": -0.48452404141426086, "Value Loss": 0.031606417149305344, "_runtime": 9759.015626430511, "_timestamp": 1585607128.648496, "_step": 90}
{"Episode reward": -99.81837603613245, "Episode length": 999, "Policy Loss": -0.4745439887046814, "Value Loss": 0.02432756870985031, "_runtime": 9760.599091529846, "_timestamp": 1585607130.231961, "_step": 91}
{"Episode reward": -99.59468757434377, "Episode length": 999, "Policy Loss": -0.4523945450782776, "Value Loss": 0.034603774547576904, "_runtime": 9762.172736883163, "_timestamp": 1585607131.8056064, "_step": 92}
{"Episode reward": -99.66429456840713, "Episode length": 999, "Policy Loss": -0.4640332758426666, "Value Loss": 0.07295858860015869, "_runtime": 9763.749027729034, "_timestamp": 1585607133.3818972, "_step": 93}
{"Episode reward": -99.68362249057836, "Episode length": 999, "Policy Loss": -0.45274442434310913, "Value Loss": 0.17669688165187836, "_runtime": 9765.38352894783, "_timestamp": 1585607135.0163984, "_step": 94}
{"Episode reward": -99.4892318144194, "Episode length": 999, "Policy Loss": -0.42976194620132446, "Value Loss": 0.02180449105799198, "_runtime": 9766.702591180801, "_timestamp": 1585607136.3354607, "_step": 95}
{"Episode reward": 16.86643791844881, "Episode length": 834, "Policy Loss": 0.22316057980060577, "Value Loss": 11.903416633605957, "_runtime": 9768.115743875504, "_timestamp": 1585607137.7486134, "_step": 96}
{"Episode reward": 11.325085098128369, "Episode length": 888, "Policy Loss": 0.277976930141449, "Value Loss": 11.215696334838867, "_runtime": 9769.711015939713, "_timestamp": 1585607139.3438854, "_step": 97}
{"Episode reward": -99.5525889041878, "Episode length": 999, "Policy Loss": -0.4525618851184845, "Value Loss": 0.0582176111638546, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674, 0.7892847657203674]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0], "bins": [-2.407758951187134, -1.942976474761963, -1.478193998336792, -1.0134114027023315, -0.5486289262771606, -0.0838463306427002, 0.3809361457824707, 0.8457186222076416, 1.3105010986328125, 1.7752835750579834, 2.2400662899017334, 2.704848527908325, 3.169631242752075, 3.634413480758667, 4.099196434020996, 4.56397819519043, 5.02876091003418, 5.49354362487793, 5.95832633972168, 6.42310905456543, 6.88789176940918, 7.352673530578613, 7.817456245422363, 8.282238960266113, 8.747021675109863, 9.211804389953613, 9.676586151123047, 10.141368865966797, 10.606151580810547, 11.070934295654297, 11.53571605682373, 12.00049877166748, 12.46528148651123, 12.93006420135498, 13.39484691619873, 13.859628677368164, 14.324411392211914, 14.789194107055664, 15.253976821899414, 15.718759536743164, 16.183542251586914, 16.648324966430664, 17.11310577392578, 17.57788848876953, 18.04267120361328, 18.50745391845703, 18.97223663330078, 19.43701934814453, 19.90180206298828, 20.36658477783203, 20.83136749267578, 21.2961483001709, 21.76093101501465, 22.2257137298584, 22.69049644470215, 23.1552791595459, 23.62006187438965, 24.0848445892334, 24.54962730407715, 25.0144100189209, 25.479190826416016, 25.943973541259766, 26.408756256103516, 26.873538970947266, 27.338321685791016]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06904584914445877, -0.053416747599840164, -0.03778764605522156, -0.02215854451060295, -0.0065294429659843445, 0.009099654853343964, 0.02472876012325287, 0.040357865393161774, 0.05598696321249008, 0.07161606103181839, 0.0872451588511467, 0.1028742715716362, 0.11850336939096451, 0.1341324746608734, 0.14976158738136292, 0.16539067029953003, 0.18101978302001953, 0.19664889574050903, 0.21227797865867615, 0.22790709137916565, 0.24353617429733276, 0.25916528701782227, 0.27479439973831177, 0.2904234826564789, 0.3060525953769684, 0.3216817080974579, 0.337310791015625, 0.3529399037361145, 0.368569016456604, 0.3841980993747711, 0.3998272120952606, 0.41545629501342773, 0.43108540773391724, 0.44671452045440674, 0.46234363317489624, 0.47797268629074097, 0.49360179901123047, 0.50923091173172, 0.5248600244522095, 0.540489137172699, 0.5561181902885437, 0.5717473030090332, 0.5873764157295227, 0.6030055284500122, 0.6186346411705017, 0.6342637538909912, 0.6498928070068359, 0.6655219197273254, 0.6811510324478149, 0.6967801451683044, 0.712409257888794, 0.7280383110046387, 0.7436674237251282, 0.7592965364456177, 0.7749256491661072, 0.7905547618865967, 0.8061838746070862, 0.8218129277229309, 0.8374420404434204, 0.8530711531639099, 0.8687002658843994, 0.8843293786048889, 0.8999584317207336, 0.9155875444412231, 0.9312166571617126]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 4.0, 3.0, 6.0, 9.0, 8.0, 12.0, 6.0, 5.0, 6.0, 4.0, 3.0, 7.0, 5.0, 12.0, 7.0, 28.0, 301.0, 21.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 0.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.7871556282043457, -0.7416608929634094, -0.6961661577224731, -0.6506713628768921, -0.6051766872406006, -0.5596818923950195, -0.5141871571540833, -0.468692421913147, -0.4231976866722107, -0.3777029514312744, -0.33220821619033813, -0.28671348094940186, -0.2412186861038208, -0.19572395086288452, -0.15022921562194824, -0.10473448038101196, -0.059239745140075684, -0.013745009899139404, 0.031749725341796875, 0.07724446058273315, 0.12273919582366943, 0.1682339906692505, 0.213728666305542, 0.25922346115112305, 0.3047182559967041, 0.3502129316329956, 0.39570772647857666, 0.44120240211486816, 0.4866971969604492, 0.5321918725967407, 0.5776866674423218, 0.6231813430786133, 0.6686761379241943, 0.7141709327697754, 0.7596656084060669, 0.805160403251648, 0.8506550788879395, 0.8961498737335205, 0.941644549369812, 0.9871393442153931, 1.0326340198516846, 1.0781288146972656, 1.1236236095428467, 1.1691182851791382, 1.2146129608154297, 1.2601077556610107, 1.3056025505065918, 1.3510973453521729, 1.396592140197754, 1.4420866966247559, 1.487581491470337, 1.533076286315918, 1.578571081161499, 1.624065637588501, 1.669560432434082, 1.715055227279663, 1.7605500221252441, 1.8060448169708252, 1.8515393733978271, 1.8970341682434082, 1.9425289630889893, 1.9880237579345703, 2.0335183143615723, 2.0790131092071533, 2.1245079040527344]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 3.0, 5.0, 1.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.2854561805725098, -2.113223075866699, -1.9409902095794678, -1.7687571048736572, -1.5965241193771362, -1.4242911338806152, -1.2520580291748047, -1.0798250436782837, -0.9075920581817627, -0.7353590726852417, -0.5631260871887207, -0.39089298248291016, -0.2186598777770996, -0.046427011489868164, 0.12580609321594238, 0.29803895950317383, 0.4702720642089844, 0.6425051689147949, 0.8147380352020264, 0.9869711399078369, 1.1592040061950684, 1.331437110900879, 1.5036702156066895, 1.675903081893921, 1.8481364250183105, 2.020369052886963, 2.1926021575927734, 2.364835262298584, 2.5370683670043945, 2.709301471710205, 2.8815340995788574, 3.053767204284668, 3.2260003089904785, 3.398233413696289, 3.5704665184020996, 3.742699146270752, 3.9149322509765625, 4.087165355682373, 4.259398460388184, 4.431631565093994, 4.6038641929626465, 4.776097297668457, 4.948330402374268, 5.120563507080078, 5.292796611785889, 5.465029716491699, 5.637262344360352, 5.809495449066162, 5.981729030609131, 6.153961658477783, 6.3261942863464355, 6.498427867889404, 6.670660495758057, 6.842894077301025, 7.015126705169678, 7.18735933303833, 7.359592914581299, 7.531825542449951, 7.70405912399292, 7.876291751861572, 8.048524856567383, 8.220758438110352, 8.392990112304688, 8.565223693847656, 8.737457275390625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 24.0, 5.0, 3.0, 4.0, 6.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-4.352500915527344, -4.265201568603516, -4.177901744842529, -4.090602397918701, -4.003303050994873, -3.916003465652466, -3.8287038803100586, -3.7414045333862305, -3.6541049480438232, -3.566805362701416, -3.479506015777588, -3.3922064304351807, -3.3049068450927734, -3.2176074981689453, -3.130307912826538, -3.043008327484131, -2.9557089805603027, -2.8684093952178955, -2.7811098098754883, -2.69381046295166, -2.606510877609253, -2.5192112922668457, -2.4319119453430176, -2.3446123600006104, -2.257312774658203, -2.170013427734375, -2.0827138423919678, -1.9954142570495605, -1.9081149101257324, -1.8208153247833252, -1.733515739440918, -1.6462163925170898, -1.5589168071746826, -1.4716172218322754, -1.3843178749084473, -1.29701828956604, -1.2097187042236328, -1.1224193572998047, -1.0351197719573975, -0.9478201866149902, -0.8605208396911621, -0.7732212543487549, -0.6859216690063477, -0.5986223220825195, -0.5113227367401123, -0.4240231513977051, -0.33672380447387695, -0.24942445755004883, -0.1621246337890625, -0.07482528686523438, 0.01247406005859375, 0.09977388381958008, 0.1870732307434082, 0.27437257766723633, 0.36167240142822266, 0.4489717483520508, 0.5362710952758789, 0.6235709190368652, 0.7108702659606934, 0.7981696128845215, 0.8854694366455078, 0.9727687835693359, 1.060068130493164, 1.1473679542541504, 1.2346673011779785]}, "_runtime": 9770.455786466599, "_timestamp": 1585607140.088656, "_step": 98}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 0.8787980079650879, "Value Loss": 21.204957962036133, "_runtime": 9772.030976772308, "_timestamp": 1585607141.6638463, "_step": 99}
{"Episode reward": -99.8515381358608, "Episode length": 999, "Policy Loss": -0.45904049277305603, "Value Loss": 0.04254111647605896, "_runtime": 9773.62506365776, "_timestamp": 1585607143.2579331, "_step": 100}
{"Episode reward": -99.32476267914616, "Episode length": 999, "Policy Loss": -0.4644644856452942, "Value Loss": 0.04850725084543228, "_runtime": 9774.908523321152, "_timestamp": 1585607144.5413928, "_step": 101}
{"Episode reward": 16.23131975950139, "Episode length": 839, "Policy Loss": 0.23856569826602936, "Value Loss": 11.838340759277344, "_runtime": 9776.496263504028, "_timestamp": 1585607146.129133, "_step": 102}
{"Episode reward": -99.47021917400279, "Episode length": 999, "Policy Loss": -0.45955488085746765, "Value Loss": 0.00966239720582962, "_runtime": 9778.087618350983, "_timestamp": 1585607147.7204878, "_step": 103}
{"Episode reward": -99.72028807778123, "Episode length": 999, "Policy Loss": -0.4616522490978241, "Value Loss": 0.006119039840996265, "_runtime": 9779.576751232147, "_timestamp": 1585607149.2096207, "_step": 104}
{"Episode reward": 4.611773752346622, "Episode length": 956, "Policy Loss": 0.18532253801822662, "Value Loss": 10.423357009887695, "_runtime": 9780.582717180252, "_timestamp": 1585607150.2155867, "_step": 105}
{"Episode reward": 37.069111358251504, "Episode length": 632, "Policy Loss": 0.4450477957725525, "Value Loss": 15.765179634094238, "_runtime": 9782.172683954239, "_timestamp": 1585607151.8055534, "_step": 106}
{"Episode reward": -99.68413176089386, "Episode length": 999, "Policy Loss": -0.4608336389064789, "Value Loss": 0.008368159644305706, "_runtime": 9783.634430408478, "_timestamp": 1585607153.2673, "_step": 107}
{"Episode reward": 7.415955043724779, "Episode length": 931, "Policy Loss": 0.22718529403209686, "Value Loss": 10.673641204833984, "_runtime": 9785.027390003204, "_timestamp": 1585607154.6602595, "_step": 108}
{"Episode reward": 10.102772427578131, "Episode length": 900, "Policy Loss": 0.25876131653785706, "Value Loss": 11.029839515686035, "_runtime": 9786.60910153389, "_timestamp": 1585607156.241971, "_step": 109}
{"Episode reward": -99.29867458184462, "Episode length": 999, "Policy Loss": -0.423797607421875, "Value Loss": 0.028846953064203262, "_runtime": 9788.214476585388, "_timestamp": 1585607157.847346, "_step": 110}
{"Episode reward": -99.78580292819395, "Episode length": 999, "Policy Loss": -0.4323101043701172, "Value Loss": 0.06333622336387634, "_runtime": 9789.778898239136, "_timestamp": 1585607159.4117677, "_step": 111}
{"Episode reward": -99.80336366659473, "Episode length": 999, "Policy Loss": -0.443669855594635, "Value Loss": 0.06410112231969833, "_runtime": 9790.432902097702, "_timestamp": 1585607160.0657716, "_step": 112}
{"Episode reward": 61.155188891285526, "Episode length": 390, "Policy Loss": 1.0484868288040161, "Value Loss": 25.33956527709961, "_runtime": 9791.995307207108, "_timestamp": 1585607161.6281767, "_step": 113}
{"Episode reward": -99.69299984419929, "Episode length": 999, "Policy Loss": -0.4058137536048889, "Value Loss": 0.028609588742256165, "_runtime": 9793.57979631424, "_timestamp": 1585607163.2126658, "_step": 114}
{"Episode reward": -99.63042614688608, "Episode length": 999, "Policy Loss": -0.3912986218929291, "Value Loss": 0.009712090715765953, "_runtime": 9795.104441642761, "_timestamp": 1585607164.7373111, "_step": 115}
{"Episode reward": -99.56640951376619, "Episode length": 999, "Policy Loss": -0.3952009379863739, "Value Loss": 0.030678436160087585, "_runtime": 9796.698378801346, "_timestamp": 1585607166.3312483, "_step": 116}
{"Episode reward": -99.7670506292067, "Episode length": 999, "Policy Loss": -0.39891064167022705, "Value Loss": 0.035482462495565414, "_runtime": 9798.285662651062, "_timestamp": 1585607167.9185321, "_step": 117}
{"Episode reward": -99.56657588801906, "Episode length": 999, "Policy Loss": -0.38728559017181396, "Value Loss": 0.028356507420539856, "_runtime": 9799.528131723404, "_timestamp": 1585607169.1610012, "_step": 118}
{"Episode reward": 21.707330005464783, "Episode length": 786, "Policy Loss": 0.37508952617645264, "Value Loss": 12.551115036010742, "_runtime": 9801.123076200485, "_timestamp": 1585607170.7559457, "_step": 119}
{"Episode reward": -99.58915558022426, "Episode length": 999, "Policy Loss": -0.3872145116329193, "Value Loss": 0.04463079944252968, "_runtime": 9801.935748577118, "_timestamp": 1585607171.568618, "_step": 120}
{"Episode reward": 50.29999999999957, "Episode length": 497, "Policy Loss": 0.7487689852714539, "Value Loss": 19.82032012939453, "_runtime": 9803.429441452026, "_timestamp": 1585607173.062311, "_step": 121}
{"Episode reward": 4.665457527951773, "Episode length": 958, "Policy Loss": 0.29450464248657227, "Value Loss": 10.302522659301758, "_runtime": 9804.259821414948, "_timestamp": 1585607173.892691, "_step": 122}
{"Episode reward": 49.53216994815113, "Episode length": 510, "Policy Loss": 0.7255861163139343, "Value Loss": 19.32662010192871, "_runtime": 9804.841582536697, "_timestamp": 1585607174.474452, "_step": 123}
{"Episode reward": 62.19999999999974, "Episode length": 378, "Policy Loss": 1.2171483039855957, "Value Loss": 25.902538299560547, "_runtime": 9805.83997964859, "_timestamp": 1585607175.4728491, "_step": 124}
{"Episode reward": 36.23694886158856, "Episode length": 639, "Policy Loss": 0.8869979381561279, "Value Loss": 15.356927871704102, "_runtime": 9807.378681182861, "_timestamp": 1585607177.0115507, "_step": 125}
{"Episode reward": -99.61782039526013, "Episode length": 999, "Policy Loss": -0.40811672806739807, "Value Loss": 0.5778471827507019, "_runtime": 9808.894747018814, "_timestamp": 1585607178.5276165, "_step": 126}
{"Episode reward": -99.58413216235795, "Episode length": 999, "Policy Loss": -0.32312023639678955, "Value Loss": 0.048736222088336945, "_runtime": 9809.244487524033, "_timestamp": 1585607178.877357, "_step": 127}
{"Episode reward": 79.94085377076989, "Episode length": 201, "Policy Loss": 2.540980339050293, "Value Loss": 48.446800231933594, "_runtime": 9810.802818059921, "_timestamp": 1585607180.4356875, "_step": 128}
{"Episode reward": -99.63510618085137, "Episode length": 999, "Policy Loss": -0.34474441409111023, "Value Loss": 0.3616810441017151, "_runtime": 9811.525973558426, "_timestamp": 1585607181.158843, "_step": 129}
{"Episode reward": 55.17954321991383, "Episode length": 450, "Policy Loss": 1.3757383823394775, "Value Loss": 22.065631866455078, "_runtime": 9813.065082073212, "_timestamp": 1585607182.6979516, "_step": 130}
{"Episode reward": -99.4929702603652, "Episode length": 999, "Policy Loss": -0.33864304423332214, "Value Loss": 0.015757691115140915, "_runtime": 9814.652205467224, "_timestamp": 1585607184.285075, "_step": 131}
{"Episode reward": -99.6309836590998, "Episode length": 999, "Policy Loss": -0.3915930688381195, "Value Loss": 0.29348230361938477, "_runtime": 9815.97457575798, "_timestamp": 1585607185.6074452, "_step": 132}
{"Episode reward": 13.487511329248719, "Episode length": 866, "Policy Loss": 0.2390887439250946, "Value Loss": 11.408007621765137, "_runtime": 9817.528504610062, "_timestamp": 1585607187.161374, "_step": 133}
{"Episode reward": -99.62197858528677, "Episode length": 999, "Policy Loss": -0.45100048184394836, "Value Loss": 0.09449422359466553, "_runtime": 9817.963563203812, "_timestamp": 1585607187.5964327, "_step": 134}
{"Episode reward": 75.19999999999993, "Episode length": 248, "Policy Loss": 1.8725371360778809, "Value Loss": 39.76310348510742, "_runtime": 9819.08967590332, "_timestamp": 1585607188.7225454, "_step": 135}
{"Episode reward": 27.908706125395653, "Episode length": 723, "Policy Loss": 0.4030205011367798, "Value Loss": 13.613937377929688, "_runtime": 9819.662819385529, "_timestamp": 1585607189.2956889, "_step": 136}
{"Episode reward": 65.26600368552587, "Episode length": 349, "Policy Loss": 1.6585839986801147, "Value Loss": 28.310504913330078, "_runtime": 9820.54918551445, "_timestamp": 1585607190.182055, "_step": 137}
{"Episode reward": 40.89864826024803, "Episode length": 592, "Policy Loss": 0.4789082705974579, "Value Loss": 16.696231842041016, "_runtime": 9822.110838651657, "_timestamp": 1585607191.7437081, "_step": 138}
{"Episode reward": -99.68928129201383, "Episode length": 999, "Policy Loss": -0.4699864983558655, "Value Loss": 0.02726959064602852, "_runtime": 9823.284775018692, "_timestamp": 1585607192.9176445, "_step": 139}
{"Episode reward": 22.94752634182815, "Episode length": 774, "Policy Loss": 0.2771536707878113, "Value Loss": 12.768208503723145, "_runtime": 9824.801400184631, "_timestamp": 1585607194.4342697, "_step": 140}
{"Episode reward": -99.6551105853622, "Episode length": 999, "Policy Loss": -0.4593055248260498, "Value Loss": 0.012444792315363884, "_runtime": 9826.377622127533, "_timestamp": 1585607196.0104916, "_step": 141}
{"Episode reward": -99.6254897336229, "Episode length": 999, "Policy Loss": -0.4889070987701416, "Value Loss": 0.11116331815719604, "_runtime": 9827.923671722412, "_timestamp": 1585607197.5565412, "_step": 142}
{"Episode reward": -99.66643872120628, "Episode length": 999, "Policy Loss": -0.46274274587631226, "Value Loss": 0.012929178774356842, "_runtime": 9829.498322486877, "_timestamp": 1585607199.131192, "_step": 143}
{"Episode reward": -99.80491080640209, "Episode length": 999, "Policy Loss": -0.48045602440834045, "Value Loss": 0.08827542513608932, "_runtime": 9830.39157128334, "_timestamp": 1585607200.0244408, "_step": 144}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": 0.5438838601112366, "Value Loss": 17.694616317749023, "_runtime": 9831.960367679596, "_timestamp": 1585607201.5932372, "_step": 145}
{"Episode reward": -99.81071259612078, "Episode length": 999, "Policy Loss": -0.5022236108779907, "Value Loss": 0.209084153175354, "_runtime": 9832.914929389954, "_timestamp": 1585607202.5477989, "_step": 146}
{"Episode reward": 40.229555924026656, "Episode length": 598, "Policy Loss": 0.43590018153190613, "Value Loss": 16.121118545532227, "_runtime": 9834.458511829376, "_timestamp": 1585607204.0913813, "_step": 147}
{"Episode reward": -99.57048010425504, "Episode length": 999, "Policy Loss": -0.5248884558677673, "Value Loss": 0.1676817238330841, "_runtime": 9836.069457530975, "_timestamp": 1585607205.702327, "_step": 148}
{"Episode reward": -99.51702181442388, "Episode length": 999, "Policy Loss": -0.5214266180992126, "Value Loss": 0.04259944707155228, "_runtime": 9837.610493421555, "_timestamp": 1585607207.243363, "_step": 149}
{"Episode reward": -99.5561115448582, "Episode length": 999, "Policy Loss": -0.5387090444564819, "Value Loss": 0.020516423508524895, "_runtime": 9838.919116735458, "_timestamp": 1585607208.5519862, "_step": 150}
{"Episode reward": 17.91072989018906, "Episode length": 825, "Policy Loss": 0.18242470920085907, "Value Loss": 11.879019737243652, "_runtime": 9839.845798015594, "_timestamp": 1585607209.4786675, "_step": 151}
{"Episode reward": 42.97731813814554, "Episode length": 575, "Policy Loss": 0.6426820755004883, "Value Loss": 17.168729782104492, "_runtime": 9841.408910989761, "_timestamp": 1585607211.0417805, "_step": 152}
{"Episode reward": -99.52285967423676, "Episode length": 999, "Policy Loss": -0.5550613403320312, "Value Loss": 0.018852319568395615, "_runtime": 9842.975763082504, "_timestamp": 1585607212.6086326, "_step": 153}
{"Episode reward": -99.54578894605955, "Episode length": 999, "Policy Loss": -0.5779231786727905, "Value Loss": 0.08181252330541611, "_runtime": 9844.517747879028, "_timestamp": 1585607214.1506174, "_step": 154}
{"Episode reward": -99.2628464840688, "Episode length": 999, "Policy Loss": -0.5532007217407227, "Value Loss": 0.012191546149551868, "_runtime": 9846.089659452438, "_timestamp": 1585607215.722529, "_step": 155}
{"Episode reward": -99.46386716602, "Episode length": 999, "Policy Loss": -0.5593463182449341, "Value Loss": 0.009124712087213993, "_runtime": 9847.035297632217, "_timestamp": 1585607216.668167, "_step": 156}
{"Episode reward": 40.67275445461217, "Episode length": 594, "Policy Loss": 0.3327461779117584, "Value Loss": 16.074146270751953, "_runtime": 9848.599641561508, "_timestamp": 1585607218.232511, "_step": 157}
{"Episode reward": -99.39992976353251, "Episode length": 999, "Policy Loss": -0.5588590502738953, "Value Loss": 0.009393660351634026, "_runtime": 9850.17566895485, "_timestamp": 1585607219.8085384, "_step": 158}
{"Episode reward": -99.52369955646436, "Episode length": 999, "Policy Loss": -0.5548802018165588, "Value Loss": 0.009040847420692444, "_runtime": 9851.516657114029, "_timestamp": 1585607221.1495266, "_step": 159}
{"Episode reward": 13.581018592225789, "Episode length": 865, "Policy Loss": 0.08669647574424744, "Value Loss": 11.017033576965332, "_runtime": 9853.08950805664, "_timestamp": 1585607222.7223775, "_step": 160}
{"Episode reward": -99.47844992085456, "Episode length": 999, "Policy Loss": -0.558522641658783, "Value Loss": 0.012976874597370625, "_runtime": 9854.67676782608, "_timestamp": 1585607224.3096373, "_step": 161}
{"Episode reward": -99.73274647449585, "Episode length": 999, "Policy Loss": -0.5547313094139099, "Value Loss": 0.020772630348801613, "_runtime": 9856.239259243011, "_timestamp": 1585607225.8721287, "_step": 162}
{"Episode reward": -99.38901456111205, "Episode length": 999, "Policy Loss": -0.5471022725105286, "Value Loss": 0.008011899888515472, "_runtime": 9856.981210708618, "_timestamp": 1585607226.6140802, "_step": 163}
{"Episode reward": 54.9000061030496, "Episode length": 452, "Policy Loss": 0.7564246654510498, "Value Loss": 20.99724006652832, "_runtime": 9858.55129480362, "_timestamp": 1585607228.1841643, "_step": 164}
{"Episode reward": -99.60003572051508, "Episode length": 999, "Policy Loss": -0.5405392050743103, "Value Loss": 0.0077706677839159966, "_runtime": 9860.17384815216, "_timestamp": 1585607229.8067176, "_step": 165}
{"Episode reward": -99.64290607059817, "Episode length": 999, "Policy Loss": -0.5361436009407043, "Value Loss": 0.008437720127403736, "_runtime": 9861.704617023468, "_timestamp": 1585607231.3374865, "_step": 166}
{"Episode reward": -99.81095053686157, "Episode length": 999, "Policy Loss": -0.5315736532211304, "Value Loss": 0.009134944528341293, "_runtime": 9862.594543218613, "_timestamp": 1585607232.2274127, "_step": 167}
{"Episode reward": 45.68884557199732, "Episode length": 547, "Policy Loss": 0.403080552816391, "Value Loss": 18.199230194091797, "_runtime": 9863.706407546997, "_timestamp": 1585607233.339277, "_step": 168}
{"Episode reward": 30.13007006748782, "Episode length": 703, "Policy Loss": 0.2791498899459839, "Value Loss": 13.726531982421875, "_runtime": 9865.27946305275, "_timestamp": 1585607234.9123325, "_step": 169}
{"Episode reward": -99.52480119480614, "Episode length": 999, "Policy Loss": -0.5321946740150452, "Value Loss": 0.007424948737025261, "_runtime": 9866.399275779724, "_timestamp": 1585607236.0321453, "_step": 170}
{"Episode reward": 27.499999999999844, "Episode length": 725, "Policy Loss": 0.381479412317276, "Value Loss": 13.789804458618164, "_runtime": 9867.951407432556, "_timestamp": 1585607237.584277, "_step": 171}
{"Episode reward": -99.70811112712116, "Episode length": 999, "Policy Loss": -0.5205023288726807, "Value Loss": 0.007250685710459948, "_runtime": 9869.513454198837, "_timestamp": 1585607239.1463237, "_step": 172}
{"Episode reward": -99.67264396653489, "Episode length": 999, "Policy Loss": -0.5154135227203369, "Value Loss": 0.00704859709367156, "_runtime": 9871.06464266777, "_timestamp": 1585607240.6975121, "_step": 173}
{"Episode reward": -99.8832976215505, "Episode length": 999, "Policy Loss": -0.5086145401000977, "Value Loss": 0.006930329836905003, "_runtime": 9872.100450992584, "_timestamp": 1585607241.7333205, "_step": 174}
{"Episode reward": 35.08830496929528, "Episode length": 650, "Policy Loss": 0.4805481433868408, "Value Loss": 15.332856178283691, "_runtime": 9873.671600341797, "_timestamp": 1585607243.3044698, "_step": 175}
{"Episode reward": -99.42270678320065, "Episode length": 999, "Policy Loss": -0.4855881929397583, "Value Loss": 0.007243259344249964, "_runtime": 9875.239310503006, "_timestamp": 1585607244.87218, "_step": 176}
{"Episode reward": -99.52162349482975, "Episode length": 999, "Policy Loss": -0.46761712431907654, "Value Loss": 0.009094650857150555, "_runtime": 9876.792380809784, "_timestamp": 1585607246.4252503, "_step": 177}
{"Episode reward": -99.62989768396226, "Episode length": 999, "Policy Loss": -0.452114462852478, "Value Loss": 0.00663233594968915, "_runtime": 9877.449090957642, "_timestamp": 1585607247.0819604, "_step": 178}
{"Episode reward": 60.33538279642788, "Episode length": 397, "Policy Loss": 1.090686321258545, "Value Loss": 24.9458065032959, "_runtime": 9878.71328663826, "_timestamp": 1585607248.3461561, "_step": 179}
{"Episode reward": 19.30620590582288, "Episode length": 811, "Policy Loss": 0.28035616874694824, "Value Loss": 12.18031120300293, "_runtime": 9880.292281866074, "_timestamp": 1585607249.9251513, "_step": 180}
{"Episode reward": -99.89180713528627, "Episode length": 999, "Policy Loss": -0.4077131748199463, "Value Loss": 0.03635818511247635, "_runtime": 9881.816243886948, "_timestamp": 1585607251.4491134, "_step": 181}
{"Episode reward": -99.68114038613136, "Episode length": 999, "Policy Loss": -0.36982661485671997, "Value Loss": 0.013065027073025703, "_runtime": 9883.407817840576, "_timestamp": 1585607253.0406873, "_step": 182}
{"Episode reward": -99.72266844952107, "Episode length": 999, "Policy Loss": -0.36197900772094727, "Value Loss": 0.0513082891702652, "_runtime": 9884.941663265228, "_timestamp": 1585607254.5745327, "_step": 183}
{"Episode reward": 3.098005980190436, "Episode length": 973, "Policy Loss": 0.3455711603164673, "Value Loss": 10.08188533782959, "_runtime": 9886.515013217926, "_timestamp": 1585607256.1478827, "_step": 184}
{"Episode reward": -99.62209072680423, "Episode length": 999, "Policy Loss": -0.3428399860858917, "Value Loss": 0.08267778158187866, "_runtime": 9888.013160943985, "_timestamp": 1585607257.6460304, "_step": 185}
{"Episode reward": 5.88190609903647, "Episode length": 942, "Policy Loss": 0.310858815908432, "Value Loss": 10.461596488952637, "_runtime": 9889.589353084564, "_timestamp": 1585607259.2222226, "_step": 186}
{"Episode reward": -99.76026484694891, "Episode length": 999, "Policy Loss": -0.3373517394065857, "Value Loss": 0.17405687272548676, "_runtime": 9890.41181230545, "_timestamp": 1585607260.0446818, "_step": 187}
{"Episode reward": 48.80628828844011, "Episode length": 512, "Policy Loss": 1.1271802186965942, "Value Loss": 19.321718215942383, "_runtime": 9891.893826007843, "_timestamp": 1585607261.5266955, "_step": 188}
{"Episode reward": 5.922252441798236, "Episode length": 944, "Policy Loss": 0.2983478903770447, "Value Loss": 10.46561050415039, "_runtime": 9893.48429107666, "_timestamp": 1585607263.1171606, "_step": 189}
{"Episode reward": -99.67698594468973, "Episode length": 999, "Policy Loss": -0.3370509147644043, "Value Loss": 0.0795472115278244, "_runtime": 9894.393805503845, "_timestamp": 1585607264.026675, "_step": 190}
{"Episode reward": 41.79838790295125, "Episode length": 583, "Policy Loss": 0.6668098568916321, "Value Loss": 16.83599281311035, "_runtime": 9895.646392583847, "_timestamp": 1585607265.279262, "_step": 191}
{"Episode reward": 21.061633938265942, "Episode length": 792, "Policy Loss": 0.3322577476501465, "Value Loss": 12.470660209655762, "_runtime": 9896.612138271332, "_timestamp": 1585607266.2450078, "_step": 192}
{"Episode reward": 39.82312092585431, "Episode length": 603, "Policy Loss": 0.6222724914550781, "Value Loss": 16.381492614746094, "_runtime": 9898.148531675339, "_timestamp": 1585607267.7814012, "_step": 193}
{"Episode reward": -99.69215240830532, "Episode length": 999, "Policy Loss": -0.35200950503349304, "Value Loss": 0.01700599491596222, "_runtime": 9899.116015434265, "_timestamp": 1585607268.748885, "_step": 194}
{"Episode reward": 38.89999999999941, "Episode length": 611, "Policy Loss": 0.692666232585907, "Value Loss": 16.10616111755371, "_runtime": 9900.659174203873, "_timestamp": 1585607270.2920437, "_step": 195}
{"Episode reward": -99.51165857165915, "Episode length": 999, "Policy Loss": -0.4010085165500641, "Value Loss": 0.13198909163475037, "_runtime": 9902.24182510376, "_timestamp": 1585607271.8746946, "_step": 196}
{"Episode reward": -99.61929663941709, "Episode length": 999, "Policy Loss": -0.38343146443367004, "Value Loss": 0.023196052759885788, "_runtime": 9903.789562940598, "_timestamp": 1585607273.4224324, "_step": 197}
{"Episode reward": -99.4705089756041, "Episode length": 999, "Policy Loss": -0.41350409388542175, "Value Loss": 0.04608415067195892, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799, 0.006508451420813799]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0], "bins": [-0.056763675063848495, -0.05189891532063484, -0.04703415930271149, -0.04216939955949783, -0.03730463981628418, -0.032439883798360825, -0.02757512405514717, -0.022710368037223816, -0.017845608294010162, -0.012980848550796509, -0.008116092532873154, -0.0032513327896595, 0.0016134269535541534, 0.006478186696767807, 0.011342938989400864, 0.016207698732614517, 0.02107245847582817, 0.025937218219041824, 0.030801977962255478, 0.035666730254888535, 0.04053148999810219, 0.04539624974131584, 0.050261009484529495, 0.05512576922774315, 0.0599905289709568, 0.06485527753829956, 0.06972004473209381, 0.07458479702472687, 0.07944954931735992, 0.08431431651115417, 0.08917906880378723, 0.09404383599758148, 0.09890858829021454, 0.1037733405828476, 0.10863810777664185, 0.1135028600692749, 0.11836762726306915, 0.12323237955570221, 0.12809713184833527, 0.13296189904212952, 0.13782665133476257, 0.14269141852855682, 0.14755617082118988, 0.15242092311382294, 0.1572856903076172, 0.16215044260025024, 0.1670152097940445, 0.17187996208667755, 0.1767447292804718, 0.18160948157310486, 0.18647423386573792, 0.19133900105953217, 0.19620376825332642, 0.20106852054595947, 0.20593327283859253, 0.21079802513122559, 0.21566277742385864, 0.2205275595188141, 0.22539231181144714, 0.2302570641040802, 0.23512181639671326, 0.2399865686893463, 0.24485135078430176, 0.24971610307693481, 0.25458085536956787]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.015263277105987072, -0.014904830604791641, -0.01454638410359621, -0.01418793760240078, -0.013829490169882774, -0.013471043668687344, -0.013112597167491913, -0.012754150666296482, -0.012395704165101051, -0.012037256732583046, -0.01167881116271019, -0.011320363730192184, -0.010961917228996754, -0.010603470727801323, -0.010245024226605892, -0.009886577725410461, -0.009528130292892456, -0.0091696847230196, -0.008811237290501595, -0.008452790789306164, -0.008094344288110733, -0.007735897321254015, -0.0073774512857198715, -0.007019003853201866, -0.006660557352006435, -0.006302110850811005, -0.005943664349615574, -0.005585217848420143, -0.005226771347224712, -0.004868323914706707, -0.004509877413511276, -0.0041514309123158455, -0.0037929844111204147, -0.003434537909924984, -0.0030760914087295532, -0.0027176449075341225, -0.002359197475016117, -0.0020007509738206863, -0.0016423044726252556, -0.0012838579714298248, -0.0009254114702343941, -0.0005669649690389633, -0.00020851753652095795, 0.0001499289646744728, 0.000508374534547329, 0.0008668219670653343, 0.0012252693995833397, 0.0015837149694561958, 0.0019421624019742012, 0.0023006079718470573, 0.0026590554043650627, 0.003017500974237919, 0.0033759484067559242, 0.0037343958392739296, 0.004092841409146786, 0.004451288841664791, 0.004809734411537647, 0.005168181844055653, 0.005526629276573658, 0.005885074846446514, 0.0062435222789645195, 0.006601967848837376, 0.006960415281355381, 0.007318860851228237, 0.0076773082837462425]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 9.0, 15.0, 17.0, 14.0, 8.0, 5.0, 28.0, 31.0, 280.0, 10.0, 11.0, 10.0, 7.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 6.0, 6.0, 4.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.028286466374993324, -0.027525590732693672, -0.02676471509039402, -0.02600383758544922, -0.025242961943149567, -0.024482086300849915, -0.023721210658550262, -0.02296033501625061, -0.022199459373950958, -0.021438583731651306, -0.020677708089351654, -0.019916832447052002, -0.0191559549421072, -0.01839507929980755, -0.017634203657507896, -0.016873326152563095, -0.016112450510263443, -0.015351575799286366, -0.014590699225664139, -0.013829823583364487, -0.013068947941064835, -0.012308072298765182, -0.01154719665646553, -0.010786319151520729, -0.010025443509221077, -0.009264567866921425, -0.008503692224621773, -0.007742816582322121, -0.006981940940022469, -0.006221063435077667, -0.005460187792778015, -0.004699312150478363, -0.003938436508178711, -0.003177560865879059, -0.0024166852235794067, -0.0016558095812797546, -0.0008949320763349533, -0.0001340564340353012, 0.0006268192082643509, 0.001387694850564003, 0.002148570492863655, 0.002909446135163307, 0.0036703217774629593, 0.004431197419762611, 0.0051920730620622635, 0.005952952429652214, 0.006713828071951866, 0.007474703714251518, 0.00823557935655117, 0.008996454998850822, 0.009757330641150475, 0.010518206283450127, 0.011279081925749779, 0.01203995756804943, 0.012800833210349083, 0.013561708852648735, 0.014322584494948387, 0.01508346013724804, 0.01584433950483799, 0.016605215147137642, 0.017366090789437294, 0.018126966431736946, 0.018887842074036598, 0.01964871771633625, 0.020409593358635902]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.05085732042789459, -0.04862760379910469, -0.04639788717031479, -0.044168174266815186, -0.041938457638025284, -0.03970874100923538, -0.03747902810573578, -0.03524931147694588, -0.033019594848155975, -0.030789878219366074, -0.02856016345322132, -0.02633044868707657, -0.024100732058286667, -0.021871015429496765, -0.019641300663352013, -0.01741158589720726, -0.015181869268417358, -0.012952152639627457, -0.010722436010837555, -0.008492723107337952, -0.00626300647854805, -0.004033289849758148, -0.001803576946258545, 0.0004261396825313568, 0.0026558563113212585, 0.00488557294011116, 0.007115289568901062, 0.009345002472400665, 0.011574719101190567, 0.013804435729980469, 0.016034148633480072, 0.018263868987560272, 0.020493581891059875, 0.02272329479455948, 0.02495301514863968, 0.027182728052139282, 0.029412448406219482, 0.031642161309719086, 0.03387187421321869, 0.03610159456729889, 0.03833130747079849, 0.040561020374298096, 0.042790740728378296, 0.0450204536318779, 0.0472501665353775, 0.0494798868894577, 0.051709599792957306, 0.053939320147037506, 0.05616903305053711, 0.05839874595403671, 0.06062846630811691, 0.06285817921161652, 0.06508789956569672, 0.06731761246919632, 0.06954732537269592, 0.07177704572677612, 0.07400675863027573, 0.07623647153377533, 0.07846619188785553, 0.08069591224193573, 0.08292561769485474, 0.08515533804893494, 0.08738505840301514, 0.08961476385593414, 0.09184448421001434]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 2.0, 4.0, 2.0, 2.0, 4.0, 9.0, 5.0, 3.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 2.0], "bins": [-0.08706441521644592, -0.08534208685159683, -0.08361975848674774, -0.08189743012189865, -0.08017510175704956, -0.07845277339220047, -0.07673044502735138, -0.07500811666250229, -0.0732857882976532, -0.07156345993280411, -0.06984113156795502, -0.06811880320310593, -0.06639647483825684, -0.06467414647340775, -0.06295181810855865, -0.061229489743709564, -0.059507161378860474, -0.05778483301401138, -0.05606250464916229, -0.0543401762843132, -0.05261784791946411, -0.05089551955461502, -0.04917319118976593, -0.04745086282491684, -0.04572853446006775, -0.04400620609521866, -0.04228387773036957, -0.04056154936552048, -0.03883922100067139, -0.037116892635822296, -0.035394564270973206, -0.033672235906124115, -0.031949907541275024, -0.030227579176425934, -0.028505250811576843, -0.026782922446727753, -0.025060594081878662, -0.02333826571702957, -0.02161593735218048, -0.01989360898733139, -0.0181712806224823, -0.01644895225763321, -0.014726623892784119, -0.013004295527935028, -0.011281967163085938, -0.009559638798236847, -0.007837310433387756, -0.006114982068538666, -0.004392653703689575, -0.0026703253388404846, -0.000947996973991394, 0.0007743313908576965, 0.002496659755706787, 0.004218988120555878, 0.005941316485404968, 0.007663644850254059, 0.00938597321510315, 0.01110830157995224, 0.01283062994480133, 0.014552958309650421, 0.01627528667449951, 0.017997615039348602, 0.019719943404197693, 0.021442271769046783, 0.023164600133895874]}, "_runtime": 9905.378608942032, "_timestamp": 1585607275.0114784, "_step": 198}
{"Episode reward": -99.65095854672698, "Episode length": 999, "Policy Loss": -0.408220499753952, "Value Loss": 0.008096780627965927, "_runtime": 9906.950849056244, "_timestamp": 1585607276.5837185, "_step": 199}
{"Episode reward": -99.65166213714262, "Episode length": 999, "Policy Loss": -0.4252401888370514, "Value Loss": 0.02691219560801983, "_runtime": 9907.897781848907, "_timestamp": 1585607277.5306513, "_step": 200}
{"Episode reward": 43.50370287065691, "Episode length": 566, "Policy Loss": 0.6112996935844421, "Value Loss": 17.499977111816406, "_runtime": 9909.48474240303, "_timestamp": 1585607279.117612, "_step": 201}
{"Episode reward": -99.66876798692836, "Episode length": 999, "Policy Loss": -0.4380810856819153, "Value Loss": 0.01200217753648758, "_runtime": 9910.100448131561, "_timestamp": 1585607279.7333176, "_step": 202}
{"Episode reward": 63.585153765184565, "Episode length": 366, "Policy Loss": 1.1039308309555054, "Value Loss": 27.076980590820312, "_runtime": 9911.648079872131, "_timestamp": 1585607281.2809494, "_step": 203}
{"Episode reward": -99.72596708624485, "Episode length": 999, "Policy Loss": -0.4354039132595062, "Value Loss": 0.007523592095822096, "_runtime": 9913.224699020386, "_timestamp": 1585607282.8575685, "_step": 204}
{"Episode reward": -99.84229881169601, "Episode length": 999, "Policy Loss": -0.4216591417789459, "Value Loss": 0.006164222490042448, "_runtime": 9914.740389823914, "_timestamp": 1585607284.3732593, "_step": 205}
{"Episode reward": -99.63452247966059, "Episode length": 999, "Policy Loss": -0.41892844438552856, "Value Loss": 0.011775306425988674, "_runtime": 9916.321492910385, "_timestamp": 1585607285.9543624, "_step": 206}
{"Episode reward": -99.454164621186, "Episode length": 999, "Policy Loss": -0.411323219537735, "Value Loss": 0.008860543370246887, "_runtime": 9917.199706077576, "_timestamp": 1585607286.8325756, "_step": 207}
{"Episode reward": 45.89074953244368, "Episode length": 542, "Policy Loss": 0.764790415763855, "Value Loss": 18.209272384643555, "_runtime": 9917.846277952194, "_timestamp": 1585607287.4791474, "_step": 208}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.1255226135253906, "Value Loss": 24.352779388427734, "_runtime": 9919.415309429169, "_timestamp": 1585607289.048179, "_step": 209}
{"Episode reward": -99.77601800706331, "Episode length": 999, "Policy Loss": -0.4019465446472168, "Value Loss": 0.06812945008277893, "_runtime": 9920.912909507751, "_timestamp": 1585607290.545779, "_step": 210}
{"Episode reward": 3.8487760150875374, "Episode length": 968, "Policy Loss": 0.2234596163034439, "Value Loss": 10.252140998840332, "_runtime": 9921.916162490845, "_timestamp": 1585607291.549032, "_step": 211}
{"Episode reward": 34.36566729335409, "Episode length": 658, "Policy Loss": 0.57425856590271, "Value Loss": 14.925619125366211, "_runtime": 9923.49541425705, "_timestamp": 1585607293.1282837, "_step": 212}
{"Episode reward": -99.49430880769368, "Episode length": 999, "Policy Loss": -0.35477134585380554, "Value Loss": 0.016243137419223785, "_runtime": 9925.070550203323, "_timestamp": 1585607294.7034197, "_step": 213}
{"Episode reward": -99.5543751820035, "Episode length": 999, "Policy Loss": -0.3475717306137085, "Value Loss": 0.020281752571463585, "_runtime": 9925.801795959473, "_timestamp": 1585607295.4346654, "_step": 214}
{"Episode reward": 53.1285239118846, "Episode length": 470, "Policy Loss": 0.8312109112739563, "Value Loss": 20.853229522705078, "_runtime": 9927.371522665024, "_timestamp": 1585607297.0043921, "_step": 215}
{"Episode reward": -99.71476453044895, "Episode length": 999, "Policy Loss": -0.3448507785797119, "Value Loss": 0.05093061551451683, "_runtime": 9928.738902568817, "_timestamp": 1585607298.371772, "_step": 216}
{"Episode reward": 13.540251905599789, "Episode length": 867, "Policy Loss": 0.3470689058303833, "Value Loss": 11.470043182373047, "_runtime": 9929.57326054573, "_timestamp": 1585607299.20613, "_step": 217}
{"Episode reward": 46.70846784314442, "Episode length": 536, "Policy Loss": 0.7753833532333374, "Value Loss": 18.190509796142578, "_runtime": 9930.63672208786, "_timestamp": 1585607300.2695916, "_step": 218}
{"Episode reward": 32.61586419144251, "Episode length": 678, "Policy Loss": 0.517208993434906, "Value Loss": 14.406878471374512, "_runtime": 9931.396512746811, "_timestamp": 1585607301.0293822, "_step": 219}
{"Episode reward": 53.422703524503945, "Episode length": 470, "Policy Loss": 0.9181011319160461, "Value Loss": 20.749650955200195, "_runtime": 9931.767566680908, "_timestamp": 1585607301.4004362, "_step": 220}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 2.11820387840271, "Value Loss": 43.50673294067383, "_runtime": 9933.352260351181, "_timestamp": 1585607302.9851298, "_step": 221}
{"Episode reward": -99.66336783292799, "Episode length": 999, "Policy Loss": -0.3284873068332672, "Value Loss": 0.03919760510325432, "_runtime": 9934.883655548096, "_timestamp": 1585607304.516525, "_step": 222}
{"Episode reward": -99.55453041804586, "Episode length": 999, "Policy Loss": -0.3460317552089691, "Value Loss": 0.15410304069519043, "_runtime": 9935.944635868073, "_timestamp": 1585607305.5775054, "_step": 223}
{"Episode reward": 29.550091186776726, "Episode length": 709, "Policy Loss": 0.5220279097557068, "Value Loss": 13.916781425476074, "_runtime": 9937.514092206955, "_timestamp": 1585607307.1469617, "_step": 224}
{"Episode reward": -99.71649952154118, "Episode length": 999, "Policy Loss": -0.3456299304962158, "Value Loss": 0.18902094662189484, "_runtime": 9939.07672905922, "_timestamp": 1585607308.7095985, "_step": 225}
{"Episode reward": -99.6352141202821, "Episode length": 999, "Policy Loss": -0.3705034852027893, "Value Loss": 0.22612561285495758, "_runtime": 9940.606055021286, "_timestamp": 1585607310.2389245, "_step": 226}
{"Episode reward": -99.48483179974, "Episode length": 999, "Policy Loss": -0.3648611009120941, "Value Loss": 0.06129315495491028, "_runtime": 9941.892618656158, "_timestamp": 1585607311.5254881, "_step": 227}
{"Episode reward": 18.799541006982665, "Episode length": 813, "Policy Loss": 0.3648441433906555, "Value Loss": 12.069503784179688, "_runtime": 9942.41379237175, "_timestamp": 1585607312.0466619, "_step": 228}
{"Episode reward": 69.94588994127102, "Episode length": 303, "Policy Loss": 1.451289176940918, "Value Loss": 32.20964050292969, "_runtime": 9942.928010940552, "_timestamp": 1585607312.5608804, "_step": 229}
{"Episode reward": 68.59919908784197, "Episode length": 315, "Policy Loss": 1.5530073642730713, "Value Loss": 30.932546615600586, "_runtime": 9943.341509580612, "_timestamp": 1585607312.974379, "_step": 230}
{"Episode reward": 75.69097920553169, "Episode length": 244, "Policy Loss": 2.8860418796539307, "Value Loss": 39.99130630493164, "_runtime": 9944.86523604393, "_timestamp": 1585607314.4981055, "_step": 231}
{"Episode reward": -99.51324945661918, "Episode length": 999, "Policy Loss": -0.4311237037181854, "Value Loss": 0.20152591168880463, "_runtime": 9945.56011724472, "_timestamp": 1585607315.1929867, "_step": 232}
{"Episode reward": 55.36733363753847, "Episode length": 450, "Policy Loss": 0.8813103437423706, "Value Loss": 21.563514709472656, "_runtime": 9946.504668474197, "_timestamp": 1585607316.137538, "_step": 233}
{"Episode reward": 36.75641323336105, "Episode length": 635, "Policy Loss": 0.4537702798843384, "Value Loss": 15.351988792419434, "_runtime": 9948.078169345856, "_timestamp": 1585607317.7110388, "_step": 234}
{"Episode reward": -99.71140608604043, "Episode length": 999, "Policy Loss": -0.42480573058128357, "Value Loss": 0.007731242571026087, "_runtime": 9948.910403966904, "_timestamp": 1585607318.5432734, "_step": 235}
{"Episode reward": 46.19317984969772, "Episode length": 539, "Policy Loss": 0.5339689254760742, "Value Loss": 18.135543823242188, "_runtime": 9950.440381765366, "_timestamp": 1585607320.0732512, "_step": 236}
{"Episode reward": -99.39792934694422, "Episode length": 999, "Policy Loss": -0.46747922897338867, "Value Loss": 0.14892785251140594, "_runtime": 9952.034504175186, "_timestamp": 1585607321.6673737, "_step": 237}
{"Episode reward": -99.6634366639061, "Episode length": 999, "Policy Loss": -0.4696309566497803, "Value Loss": 0.0818263590335846, "_runtime": 9953.57614994049, "_timestamp": 1585607323.2090194, "_step": 238}
{"Episode reward": -99.54845714216798, "Episode length": 999, "Policy Loss": -0.45936164259910583, "Value Loss": 0.009664780460298061, "_runtime": 9954.836246490479, "_timestamp": 1585607324.469116, "_step": 239}
{"Episode reward": 20.851839488267643, "Episode length": 793, "Policy Loss": 0.27492207288742065, "Value Loss": 12.275724411010742, "_runtime": 9956.447373628616, "_timestamp": 1585607326.080243, "_step": 240}
{"Episode reward": 1.2938505163662342, "Episode length": 993, "Policy Loss": 0.10884340852499008, "Value Loss": 9.77730941772461, "_runtime": 9958.020562887192, "_timestamp": 1585607327.6534324, "_step": 241}
{"Episode reward": -99.45687188152085, "Episode length": 999, "Policy Loss": -0.4761498272418976, "Value Loss": 0.014637090265750885, "_runtime": 9959.571656227112, "_timestamp": 1585607329.2045257, "_step": 242}
{"Episode reward": -99.44505814558225, "Episode length": 999, "Policy Loss": -0.4878508448600769, "Value Loss": 0.0435672327876091, "_runtime": 9961.141052484512, "_timestamp": 1585607330.773922, "_step": 243}
{"Episode reward": -99.73282834075368, "Episode length": 999, "Policy Loss": -0.48089131712913513, "Value Loss": 0.01922628842294216, "_runtime": 9962.703038454056, "_timestamp": 1585607332.335908, "_step": 244}
{"Episode reward": -99.63293958677538, "Episode length": 999, "Policy Loss": -0.4772753417491913, "Value Loss": 0.018600942566990852, "_runtime": 9963.96286201477, "_timestamp": 1585607333.5957315, "_step": 245}
{"Episode reward": 19.805525190581378, "Episode length": 807, "Policy Loss": 0.2908228635787964, "Value Loss": 12.135516166687012, "_runtime": 9965.252167224884, "_timestamp": 1585607334.8850367, "_step": 246}
{"Episode reward": 17.978738187672946, "Episode length": 822, "Policy Loss": 0.1945735067129135, "Value Loss": 11.751832962036133, "_runtime": 9966.59959769249, "_timestamp": 1585607336.2324672, "_step": 247}
{"Episode reward": 14.402193388983719, "Episode length": 857, "Policy Loss": 0.20607909560203552, "Value Loss": 11.482049942016602, "_runtime": 9967.643255233765, "_timestamp": 1585607337.2761247, "_step": 248}
{"Episode reward": 33.112248303845504, "Episode length": 672, "Policy Loss": 0.3489157259464264, "Value Loss": 14.599154472351074, "_runtime": 9969.200666189194, "_timestamp": 1585607338.8335357, "_step": 249}
{"Episode reward": -99.7105330617677, "Episode length": 999, "Policy Loss": -0.4822033941745758, "Value Loss": 0.021280257031321526, "_runtime": 9970.75648856163, "_timestamp": 1585607340.389358, "_step": 250}
{"Episode reward": -99.78049212305201, "Episode length": 999, "Policy Loss": -0.4840455651283264, "Value Loss": 0.013305540196597576, "_runtime": 9972.011373758316, "_timestamp": 1585607341.6442432, "_step": 251}
{"Episode reward": 18.41168001925142, "Episode length": 817, "Policy Loss": 0.20778635144233704, "Value Loss": 11.83365535736084, "_runtime": 9973.569400072098, "_timestamp": 1585607343.2022696, "_step": 252}
{"Episode reward": -99.63043550174778, "Episode length": 999, "Policy Loss": -0.47091934084892273, "Value Loss": 0.010502361692488194, "_runtime": 9975.129593610764, "_timestamp": 1585607344.762463, "_step": 253}
{"Episode reward": -99.74493368058909, "Episode length": 999, "Policy Loss": -0.4724710285663605, "Value Loss": 0.03865707665681839, "_runtime": 9976.64405632019, "_timestamp": 1585607346.2769258, "_step": 254}
{"Episode reward": 2.1000000000012875, "Episode length": 979, "Policy Loss": 0.181834876537323, "Value Loss": 9.966903686523438, "_runtime": 9978.21810245514, "_timestamp": 1585607347.850972, "_step": 255}
{"Episode reward": -99.37535299995079, "Episode length": 999, "Policy Loss": -0.4753666818141937, "Value Loss": 0.05095775052905083, "_runtime": 9979.821118831635, "_timestamp": 1585607349.4539883, "_step": 256}
{"Episode reward": -99.36738835618459, "Episode length": 999, "Policy Loss": -0.45984676480293274, "Value Loss": 0.01621531881392002, "_runtime": 9981.137552976608, "_timestamp": 1585607350.7704225, "_step": 257}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": 0.1664663553237915, "Value Loss": 11.479304313659668, "_runtime": 9982.714758872986, "_timestamp": 1585607352.3476284, "_step": 258}
{"Episode reward": -99.73154012659658, "Episode length": 999, "Policy Loss": -0.45209357142448425, "Value Loss": 0.020075924694538116, "_runtime": 9984.27918434143, "_timestamp": 1585607353.9120538, "_step": 259}
{"Episode reward": -99.66819376695064, "Episode length": 999, "Policy Loss": -0.4420519173145294, "Value Loss": 0.07532989233732224, "_runtime": 9984.995416402817, "_timestamp": 1585607354.628286, "_step": 260}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 0.9436370730400085, "Value Loss": 21.432741165161133, "_runtime": 9986.361924171448, "_timestamp": 1585607355.9947937, "_step": 261}
{"Episode reward": 12.76002027374993, "Episode length": 874, "Policy Loss": 0.21224184334278107, "Value Loss": 11.175948143005371, "_runtime": 9986.758898496628, "_timestamp": 1585607356.391768, "_step": 262}
{"Episode reward": 77.63647705416656, "Episode length": 225, "Policy Loss": 2.0361735820770264, "Value Loss": 43.272579193115234, "_runtime": 9987.957710266113, "_timestamp": 1585607357.5905797, "_step": 263}
{"Episode reward": 21.581794516690024, "Episode length": 787, "Policy Loss": 0.24648591876029968, "Value Loss": 12.304144859313965, "_runtime": 9989.510244131088, "_timestamp": 1585607359.1431136, "_step": 264}
{"Episode reward": -99.62647197437917, "Episode length": 999, "Policy Loss": -0.44098761677742004, "Value Loss": 0.03707375004887581, "_runtime": 9990.926902532578, "_timestamp": 1585607360.559772, "_step": 265}
{"Episode reward": 5.006021142676431, "Episode length": 952, "Policy Loss": 0.37556493282318115, "Value Loss": 10.220993995666504, "_runtime": 9992.202580928802, "_timestamp": 1585607361.8354504, "_step": 266}
{"Episode reward": 18.179751718580164, "Episode length": 820, "Policy Loss": 0.23693758249282837, "Value Loss": 11.876425743103027, "_runtime": 9993.772552251816, "_timestamp": 1585607363.4054217, "_step": 267}
{"Episode reward": -99.63627337590303, "Episode length": 999, "Policy Loss": -0.44633516669273376, "Value Loss": 0.017918661236763, "_runtime": 9994.9849588871, "_timestamp": 1585607364.6178284, "_step": 268}
{"Episode reward": 21.14509437950349, "Episode length": 790, "Policy Loss": 0.30128681659698486, "Value Loss": 12.501729011535645, "_runtime": 9996.53821182251, "_timestamp": 1585607366.1710813, "_step": 269}
{"Episode reward": -99.80515963926305, "Episode length": 999, "Policy Loss": -0.47522804141044617, "Value Loss": 0.21169060468673706, "_runtime": 9998.005961179733, "_timestamp": 1585607367.6388307, "_step": 270}
{"Episode reward": 6.748904732982481, "Episode length": 934, "Policy Loss": 0.16923686861991882, "Value Loss": 10.478449821472168, "_runtime": 9998.71585059166, "_timestamp": 1585607368.34872, "_step": 271}
{"Episode reward": 54.8881211080934, "Episode length": 453, "Policy Loss": 0.7635602951049805, "Value Loss": 21.55527114868164, "_runtime": 10000.270688056946, "_timestamp": 1585607369.9035575, "_step": 272}
{"Episode reward": -99.7100999067116, "Episode length": 999, "Policy Loss": -0.4604344666004181, "Value Loss": 0.04425773024559021, "_runtime": 10001.069904565811, "_timestamp": 1585607370.702774, "_step": 273}
{"Episode reward": 50.09924936136188, "Episode length": 500, "Policy Loss": 0.9875452518463135, "Value Loss": 19.704021453857422, "_runtime": 10001.997233629227, "_timestamp": 1585607371.630103, "_step": 274}
{"Episode reward": 39.45353752621973, "Episode length": 610, "Policy Loss": 0.6146186590194702, "Value Loss": 16.007949829101562, "_runtime": 10003.589990615845, "_timestamp": 1585607373.22286, "_step": 275}
{"Episode reward": -99.68425999303442, "Episode length": 999, "Policy Loss": -0.4730185866355896, "Value Loss": 0.04435949772596359, "_runtime": 10004.701827764511, "_timestamp": 1585607374.3346972, "_step": 276}
{"Episode reward": 27.299805381661145, "Episode length": 729, "Policy Loss": 0.3230234682559967, "Value Loss": 13.310470581054688, "_runtime": 10006.23403263092, "_timestamp": 1585607375.866902, "_step": 277}
{"Episode reward": -99.33196593199837, "Episode length": 999, "Policy Loss": -0.46963822841644287, "Value Loss": 0.10943237692117691, "_runtime": 10007.814065217972, "_timestamp": 1585607377.4469347, "_step": 278}
{"Episode reward": -99.54739220404743, "Episode length": 999, "Policy Loss": -0.5084987282752991, "Value Loss": 0.22765673696994781, "_runtime": 10009.360324144363, "_timestamp": 1585607378.9931936, "_step": 279}
{"Episode reward": -99.45204460907125, "Episode length": 999, "Policy Loss": -0.49215659499168396, "Value Loss": 0.00923911202698946, "_runtime": 10010.586917161942, "_timestamp": 1585607380.2197866, "_step": 280}
{"Episode reward": 22.627507799270205, "Episode length": 778, "Policy Loss": 0.20600749552249908, "Value Loss": 12.547165870666504, "_runtime": 10011.661898612976, "_timestamp": 1585607381.294768, "_step": 281}
{"Episode reward": 32.62497777144263, "Episode length": 675, "Policy Loss": 0.29473406076431274, "Value Loss": 14.369379043579102, "_runtime": 10013.065149784088, "_timestamp": 1585607382.6980193, "_step": 282}
{"Episode reward": 10.50992879014892, "Episode length": 895, "Policy Loss": 0.11840301752090454, "Value Loss": 10.93387222290039, "_runtime": 10014.624019861221, "_timestamp": 1585607384.2568893, "_step": 283}
{"Episode reward": -99.88150469348626, "Episode length": 999, "Policy Loss": -0.505813479423523, "Value Loss": 0.014241044409573078, "_runtime": 10015.27066206932, "_timestamp": 1585607384.9035316, "_step": 284}
{"Episode reward": 59.20999269818391, "Episode length": 409, "Policy Loss": 0.908764660358429, "Value Loss": 23.84677505493164, "_runtime": 10016.761214733124, "_timestamp": 1585607386.3940842, "_step": 285}
{"Episode reward": 5.206311487023427, "Episode length": 951, "Policy Loss": 0.1698828488588333, "Value Loss": 10.334115982055664, "_runtime": 10018.331194400787, "_timestamp": 1585607387.964064, "_step": 286}
{"Episode reward": -99.70860558951833, "Episode length": 999, "Policy Loss": -0.5149434208869934, "Value Loss": 0.008685510605573654, "_runtime": 10018.91654920578, "_timestamp": 1585607388.5494187, "_step": 287}
{"Episode reward": 63.21161365566634, "Episode length": 369, "Policy Loss": 0.9976345300674438, "Value Loss": 26.091665267944336, "_runtime": 10020.475406169891, "_timestamp": 1585607390.1082757, "_step": 288}
{"Episode reward": -99.70730524587424, "Episode length": 999, "Policy Loss": -0.5182844400405884, "Value Loss": 0.009196124970912933, "_runtime": 10022.053426980972, "_timestamp": 1585607391.6862965, "_step": 289}
{"Episode reward": -99.54443218257371, "Episode length": 999, "Policy Loss": -0.5173300504684448, "Value Loss": 0.09196456521749496, "_runtime": 10022.673027038574, "_timestamp": 1585607392.3058965, "_step": 290}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.0408976078033447, "Value Loss": 24.85310173034668, "_runtime": 10024.235373020172, "_timestamp": 1585607393.8682425, "_step": 291}
{"Episode reward": -99.63910559591466, "Episode length": 999, "Policy Loss": -0.5476342439651489, "Value Loss": 0.12792222201824188, "_runtime": 10025.604980707169, "_timestamp": 1585607395.2378502, "_step": 292}
{"Episode reward": 13.101376303256913, "Episode length": 870, "Policy Loss": 0.11410318315029144, "Value Loss": 11.063764572143555, "_runtime": 10026.76256108284, "_timestamp": 1585607396.3954306, "_step": 293}
{"Episode reward": 25.944188537687225, "Episode length": 744, "Policy Loss": 0.21857674419879913, "Value Loss": 13.009785652160645, "_runtime": 10028.331342458725, "_timestamp": 1585607397.964212, "_step": 294}
{"Episode reward": -99.62146651350638, "Episode length": 999, "Policy Loss": -0.5278998613357544, "Value Loss": 0.04142516478896141, "_runtime": 10029.087838888168, "_timestamp": 1585607398.7207084, "_step": 295}
{"Episode reward": 53.28077182317463, "Episode length": 468, "Policy Loss": 0.8201060891151428, "Value Loss": 20.90784454345703, "_runtime": 10030.635632514954, "_timestamp": 1585607400.268502, "_step": 296}
{"Episode reward": -99.5839110759073, "Episode length": 999, "Policy Loss": -0.5205605626106262, "Value Loss": 0.01833447627723217, "_runtime": 10031.962367534637, "_timestamp": 1585607401.595237, "_step": 297}
{"Episode reward": 16.41393266051938, "Episode length": 840, "Policy Loss": 0.1337161809206009, "Value Loss": 11.628260612487793, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854, -2.4073259830474854]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 10.0], "bins": [-78.94512939453125, -77.65660858154297, -76.36808776855469, -75.0795669555664, -73.79104614257812, -72.50252532958984, -71.21400451660156, -69.92548370361328, -68.636962890625, -67.34844207763672, -66.05992126464844, -64.77140045166016, -63.482879638671875, -62.194358825683594, -60.90583801269531, -59.61731719970703, -58.32879638671875, -57.04027557373047, -55.75175476074219, -54.463233947753906, -53.174713134765625, -51.886192321777344, -50.59767150878906, -49.30915069580078, -48.0206298828125, -46.73210906982422, -45.44358825683594, -44.155067443847656, -42.866546630859375, -41.578025817871094, -40.28950500488281, -39.00098419189453, -37.71246337890625, -36.42394256591797, -35.13542175292969, -33.846900939941406, -32.558380126953125, -31.269859313964844, -29.981338500976562, -28.69281768798828, -27.404296875, -26.11577606201172, -24.827255249023438, -23.538734436035156, -22.250213623046875, -20.961692810058594, -19.673171997070312, -18.38465118408203, -17.09613037109375, -15.807609558105469, -14.519088745117188, -13.230567932128906, -11.942047119140625, -10.653526306152344, -9.365005493164062, -8.076484680175781, -6.7879638671875, -5.499443054199219, -4.2109222412109375, -2.9224014282226562, -1.633880615234375, -0.34535980224609375, 0.9431610107421875, 2.2316818237304688, 3.52020263671875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 1.0], "bins": [-2.839627742767334, -2.794113874435425, -2.7486000061035156, -2.7030861377716064, -2.6575722694396973, -2.612058401107788, -2.566544532775879, -2.5210306644439697, -2.4755167961120605, -2.4300029277801514, -2.384489059448242, -2.338975191116333, -2.293461322784424, -2.2479474544525146, -2.2024335861206055, -2.1569197177886963, -2.111405849456787, -2.065891981124878, -2.0203781127929688, -1.9748642444610596, -1.9293503761291504, -1.8838365077972412, -1.8383225202560425, -1.7928086519241333, -1.7472947835922241, -1.701780915260315, -1.6562670469284058, -1.6107531785964966, -1.5652393102645874, -1.5197254419326782, -1.474211573600769, -1.4286977052688599, -1.3831838369369507, -1.3376699686050415, -1.2921561002731323, -1.2466422319412231, -1.201128363609314, -1.1556144952774048, -1.1101006269454956, -1.0645867586135864, -1.0190728902816772, -0.9735590219497681, -0.9280451536178589, -0.8825312852859497, -0.837017297744751, -0.7915034294128418, -0.7459895610809326, -0.7004756927490234, -0.6549618244171143, -0.6094479560852051, -0.5639340877532959, -0.5184202194213867, -0.47290635108947754, -0.42739248275756836, -0.3818786144256592, -0.33636474609375, -0.2908508777618408, -0.24533700942993164, -0.19982314109802246, -0.15430927276611328, -0.1087954044342041, -0.06328153610229492, -0.017767667770385742, 0.027746200561523438, 0.07326006889343262]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 5.0, 2.0, 4.0, 1.0, 1.0, 83.0, 268.0, 8.0, 9.0, 6.0, 6.0, 5.0, 5.0, 2.0, 5.0, 3.0, 10.0, 7.0, 8.0, 10.0, 6.0, 2.0, 6.0, 4.0], "bins": [-5.962213039398193, -5.832643032073975, -5.703073024749756, -5.573503017425537, -5.443933486938477, -5.314363479614258, -5.184793472290039, -5.05522346496582, -4.925653457641602, -4.796083450317383, -4.666513442993164, -4.536943435668945, -4.407373428344727, -4.277803421020508, -4.148233890533447, -4.0186638832092285, -3.8890938758850098, -3.759523868560791, -3.6299538612365723, -3.5003840923309326, -3.370814085006714, -3.241244077682495, -3.1116743087768555, -2.9821043014526367, -2.852534294128418, -2.722964286804199, -2.5933942794799805, -2.463824510574341, -2.334254503250122, -2.2046844959259033, -2.0751147270202637, -1.945544719696045, -1.8159747123718262, -1.6864047050476074, -1.5568346977233887, -1.42726469039917, -1.2976946830749512, -1.1681251525878906, -1.0385551452636719, -0.9089851379394531, -0.7794151306152344, -0.6498451232910156, -0.5202751159667969, -0.3907051086425781, -0.2611355781555176, -0.13156557083129883, -0.001995563507080078, 0.12757444381713867, 0.2571444511413574, 0.38671445846557617, 0.5162844657897949, 0.6458544731140137, 0.7754244804382324, 0.904994010925293, 1.0345640182495117, 1.1641340255737305, 1.2937040328979492, 1.423274040222168, 1.5528440475463867, 1.6824140548706055, 1.811983585357666, 1.9415535926818848, 2.0711236000061035, 2.2006936073303223, 2.330263614654541]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 2.0, 5.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-25.908153533935547, -25.395540237426758, -24.88292694091797, -24.37031364440918, -23.85770034790039, -23.3450870513916, -22.832473754882812, -22.319862365722656, -21.807247161865234, -21.294635772705078, -20.782020568847656, -20.2694091796875, -19.75679588317871, -19.244182586669922, -18.731569290161133, -18.218955993652344, -17.706342697143555, -17.193729400634766, -16.681116104125977, -16.168502807617188, -15.655889511108398, -15.143277168273926, -14.630663871765137, -14.118050575256348, -13.605437278747559, -13.09282398223877, -12.58021068572998, -12.067597389221191, -11.554985046386719, -11.04237174987793, -10.52975845336914, -10.017145156860352, -9.504531860351562, -8.991918563842773, -8.479305267333984, -7.966691970825195, -7.454078674316406, -6.941465377807617, -6.428852081298828, -5.916238784790039, -5.40362548828125, -4.891014099121094, -4.378400802612305, -3.8657875061035156, -3.3531742095947266, -2.8405609130859375, -2.3279476165771484, -1.8153343200683594, -1.3027210235595703, -0.7901077270507812, -0.2774944305419922, 0.23511886596679688, 0.7477321624755859, 1.260345458984375, 1.772958755493164, 2.285572052001953, 2.7981834411621094, 3.3107967376708984, 3.8234100341796875, 4.336023330688477, 4.848636627197266, 5.361249923706055, 5.873863220214844, 6.386478424072266, 6.899089813232422]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 19.0, 6.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.5763497352600098, -2.385215997695923, -2.194082260131836, -2.002948522567749, -1.811814785003662, -1.6206810474395752, -1.4295473098754883, -1.2384135723114014, -1.0472798347473145, -0.8561460971832275, -0.6650123596191406, -0.4738786220550537, -0.2827448844909668, -0.09161114692687988, 0.09952259063720703, 0.29065632820129395, 0.48179006576538086, 0.6729238033294678, 0.8640575408935547, 1.0551912784576416, 1.2463250160217285, 1.4374585151672363, 1.6285924911499023, 1.8197264671325684, 2.010859966278076, 2.201993465423584, 2.39312744140625, 2.584261417388916, 2.775394916534424, 2.9665284156799316, 3.1576623916625977, 3.3487963676452637, 3.5399298667907715, 3.7310633659362793, 3.9221973419189453, 4.113331317901611, 4.304464817047119, 4.495598316192627, 4.686732292175293, 4.877866268157959, 5.068999767303467, 5.260133266448975, 5.451266765594482, 5.642401218414307, 5.8335347175598145, 6.024668216705322, 6.2158026695251465, 6.406936168670654, 6.598069667816162, 6.78920316696167, 6.980336666107178, 7.171471118927002, 7.36260461807251, 7.553738117218018, 7.744872570037842, 7.93600606918335, 8.127140045166016, 8.318273544311523, 8.509407043457031, 8.700540542602539, 8.891674041748047, 9.082807540893555, 9.273942947387695, 9.465076446533203, 9.656209945678711]}, "_runtime": 10032.97854232788, "_timestamp": 1585607402.6114118, "_step": 298}
{"Episode reward": 34.46653632597244, "Episode length": 658, "Policy Loss": 0.5124061703681946, "Value Loss": 14.75632381439209, "_runtime": 10034.004600524902, "_timestamp": 1585607403.63747, "_step": 299}
{"Episode reward": 35.998092289181024, "Episode length": 644, "Policy Loss": 0.31297174096107483, "Value Loss": 14.970294952392578, "_runtime": 10034.900019168854, "_timestamp": 1585607404.5328887, "_step": 300}
{"Episode reward": 44.06951654448588, "Episode length": 561, "Policy Loss": 0.41458815336227417, "Value Loss": 17.551799774169922, "_runtime": 10036.449484348297, "_timestamp": 1585607406.0823538, "_step": 301}
{"Episode reward": -99.80012963752239, "Episode length": 999, "Policy Loss": -0.5260334014892578, "Value Loss": 0.07352381944656372, "_runtime": 10037.99276971817, "_timestamp": 1585607407.6256392, "_step": 302}
{"Episode reward": -99.77881715407572, "Episode length": 999, "Policy Loss": -0.5200031399726868, "Value Loss": 0.013049636036157608, "_runtime": 10039.530847072601, "_timestamp": 1585607409.1637166, "_step": 303}
{"Episode reward": -99.71094589101128, "Episode length": 999, "Policy Loss": -0.5140676498413086, "Value Loss": 0.00958206970244646, "_runtime": 10040.960220813751, "_timestamp": 1585607410.5930903, "_step": 304}
{"Episode reward": 9.305844118045357, "Episode length": 908, "Policy Loss": 0.21818529069423676, "Value Loss": 10.841083526611328, "_runtime": 10042.540745019913, "_timestamp": 1585607412.1736145, "_step": 305}
{"Episode reward": -99.68837178867405, "Episode length": 999, "Policy Loss": -0.5235772728919983, "Value Loss": 0.1271853744983673, "_runtime": 10044.064153909683, "_timestamp": 1585607413.6970234, "_step": 306}
{"Episode reward": 3.250019953441864, "Episode length": 969, "Policy Loss": 0.056686777621507645, "Value Loss": 10.122869491577148, "_runtime": 10045.631291866302, "_timestamp": 1585607415.2641613, "_step": 307}
{"Episode reward": -99.65469787300542, "Episode length": 999, "Policy Loss": -0.5299981832504272, "Value Loss": 0.04315992817282677, "_runtime": 10046.918591976166, "_timestamp": 1585607416.5514615, "_step": 308}
{"Episode reward": 19.218746895378302, "Episode length": 809, "Policy Loss": 0.1841595321893692, "Value Loss": 12.062112808227539, "_runtime": 10048.502471923828, "_timestamp": 1585607418.1353414, "_step": 309}
{"Episode reward": -99.76591449238337, "Episode length": 999, "Policy Loss": -0.4781172275543213, "Value Loss": 0.042271312326192856, "_runtime": 10050.016460418701, "_timestamp": 1585607419.64933, "_step": 310}
{"Episode reward": 4.51117454477469, "Episode length": 959, "Policy Loss": 0.09580538421869278, "Value Loss": 10.181154251098633, "_runtime": 10051.618988990784, "_timestamp": 1585607421.2518585, "_step": 311}
{"Episode reward": -99.63912598969043, "Episode length": 999, "Policy Loss": -0.48762500286102295, "Value Loss": 0.016082415357232094, "_runtime": 10053.19608616829, "_timestamp": 1585607422.8289557, "_step": 312}
{"Episode reward": -99.76175574998348, "Episode length": 999, "Policy Loss": -0.47496530413627625, "Value Loss": 0.02202177792787552, "_runtime": 10054.405410528183, "_timestamp": 1585607424.03828, "_step": 313}
{"Episode reward": 23.0000000000001, "Episode length": 770, "Policy Loss": 0.23908770084381104, "Value Loss": 12.612585067749023, "_runtime": 10055.978029727936, "_timestamp": 1585607425.6108992, "_step": 314}
{"Episode reward": -99.58705026456599, "Episode length": 999, "Policy Loss": -0.48452961444854736, "Value Loss": 0.04434727132320404, "_runtime": 10057.494833230972, "_timestamp": 1585607427.1277027, "_step": 315}
{"Episode reward": 4.368446540728911, "Episode length": 958, "Policy Loss": 0.0985390767455101, "Value Loss": 10.213065147399902, "_runtime": 10058.11865401268, "_timestamp": 1585607427.7515235, "_step": 316}
{"Episode reward": 61.799999999999734, "Episode length": 382, "Policy Loss": 1.0042920112609863, "Value Loss": 25.04138946533203, "_runtime": 10059.681733369827, "_timestamp": 1585607429.3146029, "_step": 317}
{"Episode reward": -99.64159763439537, "Episode length": 999, "Policy Loss": -0.4542023837566376, "Value Loss": 0.006361482664942741, "_runtime": 10060.560809850693, "_timestamp": 1585607430.1936793, "_step": 318}
{"Episode reward": 46.11064563738133, "Episode length": 542, "Policy Loss": 0.6865624189376831, "Value Loss": 17.995756149291992, "_runtime": 10062.090138673782, "_timestamp": 1585607431.7230082, "_step": 319}
{"Episode reward": -99.65184195296467, "Episode length": 999, "Policy Loss": -0.4553624093532562, "Value Loss": 0.03040681593120098, "_runtime": 10063.670070886612, "_timestamp": 1585607433.3029404, "_step": 320}
{"Episode reward": -99.55584993443198, "Episode length": 999, "Policy Loss": -0.45430243015289307, "Value Loss": 0.0431525781750679, "_runtime": 10064.83535027504, "_timestamp": 1585607434.4682198, "_step": 321}
{"Episode reward": 24.55118651911036, "Episode length": 756, "Policy Loss": 0.40479233860969543, "Value Loss": 13.043177604675293, "_runtime": 10066.41919875145, "_timestamp": 1585607436.0520682, "_step": 322}
{"Episode reward": -99.29957353393411, "Episode length": 999, "Policy Loss": -0.4497957229614258, "Value Loss": 0.03473404049873352, "_runtime": 10068.012436151505, "_timestamp": 1585607437.6453056, "_step": 323}
{"Episode reward": -99.69977278358282, "Episode length": 999, "Policy Loss": -0.4395122230052948, "Value Loss": 0.017194362357258797, "_runtime": 10068.820643663406, "_timestamp": 1585607438.4535131, "_step": 324}
{"Episode reward": 50.06905946056315, "Episode length": 501, "Policy Loss": 0.7139478921890259, "Value Loss": 19.093578338623047, "_runtime": 10070.383424520493, "_timestamp": 1585607440.016294, "_step": 325}
{"Episode reward": -99.34772535526291, "Episode length": 999, "Policy Loss": -0.46008867025375366, "Value Loss": 0.15366823971271515, "_runtime": 10071.680475711823, "_timestamp": 1585607441.3133452, "_step": 326}
{"Episode reward": 19.222041989647863, "Episode length": 810, "Policy Loss": 0.21422122418880463, "Value Loss": 12.017108917236328, "_runtime": 10073.007361412048, "_timestamp": 1585607442.640231, "_step": 327}
{"Episode reward": 15.161606727052089, "Episode length": 851, "Policy Loss": 0.27331364154815674, "Value Loss": 11.480154037475586, "_runtime": 10074.624799489975, "_timestamp": 1585607444.257669, "_step": 328}
{"Episode reward": -99.82354772770637, "Episode length": 999, "Policy Loss": -0.43956243991851807, "Value Loss": 0.046662501990795135, "_runtime": 10076.200961589813, "_timestamp": 1585607445.833831, "_step": 329}
{"Episode reward": -99.74359746498965, "Episode length": 999, "Policy Loss": -0.43269845843315125, "Value Loss": 0.07488343864679337, "_runtime": 10076.911559820175, "_timestamp": 1585607446.5444293, "_step": 330}
{"Episode reward": 55.66122468623181, "Episode length": 444, "Policy Loss": 1.0098012685775757, "Value Loss": 21.904348373413086, "_runtime": 10078.490378856659, "_timestamp": 1585607448.1232483, "_step": 331}
{"Episode reward": -99.57841985966523, "Episode length": 999, "Policy Loss": -0.43372347950935364, "Value Loss": 0.023854751139879227, "_runtime": 10080.078659296036, "_timestamp": 1585607449.7115288, "_step": 332}
{"Episode reward": -99.36071111966022, "Episode length": 999, "Policy Loss": -0.43416067957878113, "Value Loss": 0.01712701842188835, "_runtime": 10080.574748277664, "_timestamp": 1585607450.2076178, "_step": 333}
{"Episode reward": 69.76422963269854, "Episode length": 305, "Policy Loss": 1.3538450002670288, "Value Loss": 31.21278190612793, "_runtime": 10081.42358326912, "_timestamp": 1585607451.0564528, "_step": 334}
{"Episode reward": 47.224094311281334, "Episode length": 528, "Policy Loss": 0.8339006900787354, "Value Loss": 18.322134017944336, "_runtime": 10082.253240585327, "_timestamp": 1585607451.88611, "_step": 335}
{"Episode reward": 49.20681193395823, "Episode length": 508, "Policy Loss": 0.6303585171699524, "Value Loss": 19.070323944091797, "_runtime": 10083.381383419037, "_timestamp": 1585607453.014253, "_step": 336}
{"Episode reward": 26.266704670118557, "Episode length": 739, "Policy Loss": 0.2519434690475464, "Value Loss": 13.155803680419922, "_runtime": 10084.92235326767, "_timestamp": 1585607454.5552227, "_step": 337}
{"Episode reward": -99.33180367864416, "Episode length": 999, "Policy Loss": -0.45611247420310974, "Value Loss": 0.24391686916351318, "_runtime": 10086.459571838379, "_timestamp": 1585607456.0924413, "_step": 338}
{"Episode reward": -99.5621323634682, "Episode length": 999, "Policy Loss": -0.46787869930267334, "Value Loss": 0.04274769127368927, "_runtime": 10088.017968893051, "_timestamp": 1585607457.6508384, "_step": 339}
{"Episode reward": -99.62230596543385, "Episode length": 999, "Policy Loss": -0.4573446214199066, "Value Loss": 0.019198879599571228, "_runtime": 10089.486232042313, "_timestamp": 1585607459.1191015, "_step": 340}
{"Episode reward": 7.953452455177683, "Episode length": 924, "Policy Loss": 0.18294863402843475, "Value Loss": 10.615029335021973, "_runtime": 10090.71738743782, "_timestamp": 1585607460.350257, "_step": 341}
{"Episode reward": 22.88124592504475, "Episode length": 773, "Policy Loss": 0.2247404307126999, "Value Loss": 12.677730560302734, "_runtime": 10091.470587015152, "_timestamp": 1585607461.1034565, "_step": 342}
{"Episode reward": 53.74821408434616, "Episode length": 465, "Policy Loss": 0.8370438814163208, "Value Loss": 20.220138549804688, "_runtime": 10093.045337438583, "_timestamp": 1585607462.678207, "_step": 343}
{"Episode reward": -99.74895252931026, "Episode length": 999, "Policy Loss": -0.4820719063282013, "Value Loss": 0.021640393882989883, "_runtime": 10094.102268457413, "_timestamp": 1585607463.735138, "_step": 344}
{"Episode reward": 33.538546980445474, "Episode length": 667, "Policy Loss": 0.41480422019958496, "Value Loss": 14.383837699890137, "_runtime": 10095.637024641037, "_timestamp": 1585607465.2698941, "_step": 345}
{"Episode reward": -99.28494246528, "Episode length": 999, "Policy Loss": -0.4931015968322754, "Value Loss": 0.01170384231954813, "_runtime": 10097.226377010345, "_timestamp": 1585607466.8592465, "_step": 346}
{"Episode reward": -99.52128401315282, "Episode length": 999, "Policy Loss": -0.4823647737503052, "Value Loss": 0.07913903146982193, "_runtime": 10098.367135047913, "_timestamp": 1585607468.0000045, "_step": 347}
{"Episode reward": 30.138286192452924, "Episode length": 701, "Policy Loss": 0.35995006561279297, "Value Loss": 13.88157844543457, "_runtime": 10099.942061185837, "_timestamp": 1585607469.5749307, "_step": 348}
{"Episode reward": -99.58011933772802, "Episode length": 999, "Policy Loss": -0.4682779312133789, "Value Loss": 0.20287394523620605, "_runtime": 10101.533810377121, "_timestamp": 1585607471.1666799, "_step": 349}
{"Episode reward": -99.51465155783669, "Episode length": 999, "Policy Loss": -0.49594566226005554, "Value Loss": 0.04360000789165497, "_runtime": 10103.088337182999, "_timestamp": 1585607472.7212067, "_step": 350}
{"Episode reward": -99.55502600476473, "Episode length": 999, "Policy Loss": -0.5049155950546265, "Value Loss": 0.014121070504188538, "_runtime": 10103.992606163025, "_timestamp": 1585607473.6254756, "_step": 351}
{"Episode reward": 44.28881127307489, "Episode length": 558, "Policy Loss": 0.5363413095474243, "Value Loss": 17.284635543823242, "_runtime": 10105.573634386063, "_timestamp": 1585607475.2065039, "_step": 352}
{"Episode reward": -99.54210505305537, "Episode length": 999, "Policy Loss": -0.5104256868362427, "Value Loss": 0.013904835097491741, "_runtime": 10107.168934822083, "_timestamp": 1585607476.8018043, "_step": 353}
{"Episode reward": -99.6210669169538, "Episode length": 999, "Policy Loss": -0.5069294571876526, "Value Loss": 0.010727738961577415, "_runtime": 10108.0718729496, "_timestamp": 1585607477.7047424, "_step": 354}
{"Episode reward": 41.865383719599954, "Episode length": 582, "Policy Loss": 0.5735685229301453, "Value Loss": 16.45746421813965, "_runtime": 10109.66108250618, "_timestamp": 1585607479.293952, "_step": 355}
{"Episode reward": -99.69901096259571, "Episode length": 999, "Policy Loss": -0.5029851794242859, "Value Loss": 0.02026522532105446, "_runtime": 10111.247024774551, "_timestamp": 1585607480.8798943, "_step": 356}
{"Episode reward": -99.56381442082792, "Episode length": 999, "Policy Loss": -0.5012045502662659, "Value Loss": 0.0906878188252449, "_runtime": 10112.796666622162, "_timestamp": 1585607482.429536, "_step": 357}
{"Episode reward": -99.66394538823958, "Episode length": 999, "Policy Loss": -0.5131754279136658, "Value Loss": 0.25262197852134705, "_runtime": 10113.537868738174, "_timestamp": 1585607483.1707382, "_step": 358}
{"Episode reward": 54.54895545518338, "Episode length": 455, "Policy Loss": 0.77250075340271, "Value Loss": 20.965961456298828, "_runtime": 10115.126014471054, "_timestamp": 1585607484.758884, "_step": 359}
{"Episode reward": 0.6964960383381396, "Episode length": 996, "Policy Loss": 0.05654440075159073, "Value Loss": 9.68388843536377, "_runtime": 10116.721997261047, "_timestamp": 1585607486.3548667, "_step": 360}
{"Episode reward": -99.55426194036124, "Episode length": 999, "Policy Loss": -0.5043955445289612, "Value Loss": 0.050428733229637146, "_runtime": 10117.684198617935, "_timestamp": 1585607487.317068, "_step": 361}
{"Episode reward": 37.798968183149675, "Episode length": 624, "Policy Loss": 0.28549841046333313, "Value Loss": 16.146562576293945, "_runtime": 10119.259990215302, "_timestamp": 1585607488.8928597, "_step": 362}
{"Episode reward": -99.62772172236444, "Episode length": 999, "Policy Loss": -0.4855287969112396, "Value Loss": 0.011180889792740345, "_runtime": 10119.979952096939, "_timestamp": 1585607489.6128216, "_step": 363}
{"Episode reward": 55.69861074843758, "Episode length": 444, "Policy Loss": 0.9302975535392761, "Value Loss": 21.914491653442383, "_runtime": 10121.527899742126, "_timestamp": 1585607491.1607692, "_step": 364}
{"Episode reward": -99.80630881543482, "Episode length": 999, "Policy Loss": -0.4989348351955414, "Value Loss": 0.013664918020367622, "_runtime": 10123.1514544487, "_timestamp": 1585607492.784324, "_step": 365}
{"Episode reward": -99.30279951750865, "Episode length": 999, "Policy Loss": -0.46876174211502075, "Value Loss": 0.10545738786458969, "_runtime": 10123.720580339432, "_timestamp": 1585607493.3534498, "_step": 366}
{"Episode reward": 63.73062823386257, "Episode length": 364, "Policy Loss": 1.0593161582946777, "Value Loss": 26.804363250732422, "_runtime": 10125.299445152283, "_timestamp": 1585607494.9323146, "_step": 367}
{"Episode reward": -99.63871187926713, "Episode length": 999, "Policy Loss": -0.4839073717594147, "Value Loss": 0.06926736235618591, "_runtime": 10126.878551483154, "_timestamp": 1585607496.511421, "_step": 368}
{"Episode reward": -99.72692818863294, "Episode length": 999, "Policy Loss": -0.4981302320957184, "Value Loss": 0.050237275660037994, "_runtime": 10128.39216041565, "_timestamp": 1585607498.02503, "_step": 369}
{"Episode reward": -99.79695697743307, "Episode length": 999, "Policy Loss": -0.508458137512207, "Value Loss": 0.0162153709679842, "_runtime": 10129.52643752098, "_timestamp": 1585607499.159307, "_step": 370}
{"Episode reward": 29.02587818315928, "Episode length": 712, "Policy Loss": 0.3464176654815674, "Value Loss": 13.661123275756836, "_runtime": 10130.28440284729, "_timestamp": 1585607499.9172723, "_step": 371}
{"Episode reward": 53.5469930949035, "Episode length": 467, "Policy Loss": 0.8701272010803223, "Value Loss": 20.487924575805664, "_runtime": 10131.55081987381, "_timestamp": 1585607501.1836894, "_step": 372}
{"Episode reward": 18.68197311255534, "Episode length": 815, "Policy Loss": 0.1637466847896576, "Value Loss": 11.829442024230957, "_runtime": 10132.682446718216, "_timestamp": 1585607502.3153162, "_step": 373}
{"Episode reward": 27.4059272893994, "Episode length": 729, "Policy Loss": 0.45555946230888367, "Value Loss": 13.137940406799316, "_runtime": 10134.208226919174, "_timestamp": 1585607503.8410964, "_step": 374}
{"Episode reward": -99.48885081219932, "Episode length": 999, "Policy Loss": -0.510303258895874, "Value Loss": 0.012568652629852295, "_runtime": 10135.776498317719, "_timestamp": 1585607505.4093678, "_step": 375}
{"Episode reward": -99.51113240623243, "Episode length": 999, "Policy Loss": -0.5105584263801575, "Value Loss": 0.1282944232225418, "_runtime": 10137.339816570282, "_timestamp": 1585607506.972686, "_step": 376}
{"Episode reward": -99.5977136218732, "Episode length": 999, "Policy Loss": -0.5871685743331909, "Value Loss": 0.4752562642097473, "_runtime": 10138.22767496109, "_timestamp": 1585607507.8605444, "_step": 377}
{"Episode reward": 45.292182396281945, "Episode length": 550, "Policy Loss": 0.47326478362083435, "Value Loss": 17.548398971557617, "_runtime": 10139.807440757751, "_timestamp": 1585607509.4403102, "_step": 378}
{"Episode reward": -99.42660368697116, "Episode length": 999, "Policy Loss": -0.5169846415519714, "Value Loss": 0.022686105221509933, "_runtime": 10141.378612995148, "_timestamp": 1585607511.0114825, "_step": 379}
{"Episode reward": -99.63055575124314, "Episode length": 999, "Policy Loss": -0.5150840878486633, "Value Loss": 0.05838252231478691, "_runtime": 10141.984009504318, "_timestamp": 1585607511.616879, "_step": 380}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 0.922548770904541, "Value Loss": 25.6848087310791, "_runtime": 10143.554580926895, "_timestamp": 1585607513.1874504, "_step": 381}
{"Episode reward": -99.52156360875095, "Episode length": 999, "Policy Loss": -0.5218758583068848, "Value Loss": 0.07464892417192459, "_runtime": 10145.138969898224, "_timestamp": 1585607514.7718394, "_step": 382}
{"Episode reward": -99.58128965898511, "Episode length": 999, "Policy Loss": -0.5334504246711731, "Value Loss": 0.035989534109830856, "_runtime": 10146.401187896729, "_timestamp": 1585607516.0340574, "_step": 383}
{"Episode reward": 19.598482708784587, "Episode length": 807, "Policy Loss": 0.22718201577663422, "Value Loss": 11.848457336425781, "_runtime": 10147.983800888062, "_timestamp": 1585607517.6166704, "_step": 384}
{"Episode reward": -99.77399352660146, "Episode length": 999, "Policy Loss": -0.5214265584945679, "Value Loss": 0.031108874827623367, "_runtime": 10149.570698738098, "_timestamp": 1585607519.2035682, "_step": 385}
{"Episode reward": -99.71811327953917, "Episode length": 999, "Policy Loss": -0.5020418763160706, "Value Loss": 0.029437759891152382, "_runtime": 10150.050150632858, "_timestamp": 1585607519.68302, "_step": 386}
{"Episode reward": 71.85712625271978, "Episode length": 284, "Policy Loss": 1.4854644536972046, "Value Loss": 33.38434600830078, "_runtime": 10151.62423658371, "_timestamp": 1585607521.257106, "_step": 387}
{"Episode reward": -99.32930001478971, "Episode length": 999, "Policy Loss": -0.49996042251586914, "Value Loss": 0.01350497081875801, "_runtime": 10153.081575393677, "_timestamp": 1585607522.7144449, "_step": 388}
{"Episode reward": 9.308384424326647, "Episode length": 910, "Policy Loss": 0.10233816504478455, "Value Loss": 10.480400085449219, "_runtime": 10153.59966635704, "_timestamp": 1585607523.2325358, "_step": 389}
{"Episode reward": 66.9999999999998, "Episode length": 330, "Policy Loss": 1.256525993347168, "Value Loss": 28.51654815673828, "_runtime": 10155.183092355728, "_timestamp": 1585607524.8159618, "_step": 390}
{"Episode reward": -99.48496482121271, "Episode length": 999, "Policy Loss": -0.5279450416564941, "Value Loss": 0.3474644720554352, "_runtime": 10156.277786493301, "_timestamp": 1585607525.910656, "_step": 391}
{"Episode reward": 31.508600596664095, "Episode length": 687, "Policy Loss": 0.32772988080978394, "Value Loss": 14.203582763671875, "_runtime": 10157.801899433136, "_timestamp": 1585607527.434769, "_step": 392}
{"Episode reward": -99.33787747457254, "Episode length": 999, "Policy Loss": -0.4875764548778534, "Value Loss": 0.03683632239699364, "_runtime": 10159.386589050293, "_timestamp": 1585607529.0194585, "_step": 393}
{"Episode reward": -99.57242778964437, "Episode length": 999, "Policy Loss": -0.48987990617752075, "Value Loss": 0.03705954924225807, "_runtime": 10160.205997943878, "_timestamp": 1585607529.8388674, "_step": 394}
{"Episode reward": 48.97930665271661, "Episode length": 513, "Policy Loss": 0.7207087278366089, "Value Loss": 18.59377098083496, "_runtime": 10160.925116539001, "_timestamp": 1585607530.557986, "_step": 395}
{"Episode reward": 55.74828332363942, "Episode length": 443, "Policy Loss": 0.9192614555358887, "Value Loss": 21.44550895690918, "_runtime": 10162.468450307846, "_timestamp": 1585607532.1013198, "_step": 396}
{"Episode reward": 1.965903558100237, "Episode length": 984, "Policy Loss": 0.05661066621541977, "Value Loss": 9.981760025024414, "_runtime": 10164.014855861664, "_timestamp": 1585607533.6477253, "_step": 397}
{"Episode reward": -99.83312359386916, "Episode length": 999, "Policy Loss": -0.5500785112380981, "Value Loss": 0.26417046785354614, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853, 0.07494940608739853]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.0749492347240448, -0.04012111946940422, -0.005293004214763641, 0.029535114765167236, 0.06436322629451752, 0.0991913378238678, 0.13401946425437927, 0.16884757578372955, 0.20367568731307983, 0.2385038137435913, 0.2733319103717804, 0.30816003680229187, 0.34298816323280334, 0.37781625986099243, 0.4126443862915039, 0.447472482919693, 0.48230060935020447, 0.5171287059783936, 0.5519568920135498, 0.5867849588394165, 0.6216130256652832, 0.6564412117004395, 0.6912692785263062, 0.7260974645614624, 0.7609255313873291, 0.7957535982131958, 0.830581784248352, 0.8654098510742188, 0.900238037109375, 0.9350661039352417, 0.9698941707611084, 1.0047223567962646, 1.0395504236221313, 1.074378490447998, 1.1092066764831543, 1.144034743309021, 1.1788629293441772, 1.213690996170044, 1.2485190629959106, 1.283347249031067, 1.3181753158569336, 1.3530035018920898, 1.3878315687179565, 1.4226596355438232, 1.4574878215789795, 1.4923158884048462, 1.5271440744400024, 1.5619721412658691, 1.5968003273010254, 1.631628394126892, 1.6664564609527588, 1.701284646987915, 1.7361127138137817, 1.770940899848938, 1.8057689666748047, 1.8405970335006714, 1.8754252195358276, 1.9102532863616943, 1.9450814723968506, 1.9799094200134277, 2.014737606048584, 2.0495657920837402, 2.0843939781188965, 2.1192219257354736, 2.15405011177063]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0010363294277340174, 0.0003612370928749442, 0.0017588036134839058, 0.003156370250508189, 0.004553936421871185, 0.005951503291726112, 0.007349070161581039, 0.008746636100113392, 0.010144202969968319, 0.011541769839823246, 0.012939335778355598, 0.014336902648210526, 0.015734469518065453, 0.01713203638792038, 0.018529601395130157, 0.019927168264985085, 0.02132473513484001, 0.02272230200469494, 0.024119868874549866, 0.025517433881759644, 0.02691500075161457, 0.028312567621469498, 0.029710134491324425, 0.031107699498534203, 0.03250526636838913, 0.03390283137559891, 0.035300400108098984, 0.03669796511530876, 0.03809553012251854, 0.039493098855018616, 0.040890663862228394, 0.04228823259472847, 0.04368579760193825, 0.045083362609148026, 0.0464809313416481, 0.04787849634885788, 0.049276065081357956, 0.050673630088567734, 0.05207119509577751, 0.05346876382827759, 0.054866328835487366, 0.05626389756798744, 0.05766146257519722, 0.059059027582407, 0.060456596314907074, 0.06185416132211685, 0.06325172632932663, 0.064649298787117, 0.06604686379432678, 0.06744442880153656, 0.06884199380874634, 0.07023955881595612, 0.07163713127374649, 0.07303469628095627, 0.07443226128816605, 0.07582982629537582, 0.0772273913025856, 0.07862496376037598, 0.08002252876758575, 0.08142009377479553, 0.08281765878200531, 0.08421522378921509, 0.08561279624700546, 0.08701036125421524, 0.08840792626142502]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 3.0, 7.0, 5.0, 9.0, 10.0, 12.0, 8.0, 6.0, 9.0, 4.0, 3.0, 3.0, 4.0, 4.0, 5.0, 14.0, 4.0, 3.0, 312.0, 17.0, 4.0, 3.0, 1.0, 3.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 5.0, 1.0, 6.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.0764521062374115, -0.07256189733743668, -0.06867168843746185, -0.06478148698806763, -0.060891278088092804, -0.05700106918811798, -0.05311086028814316, -0.049220651388168335, -0.04533044621348381, -0.04144023731350899, -0.03755003213882446, -0.03365982323884964, -0.029769614338874817, -0.025879409164190292, -0.02198920026421547, -0.018098995089530945, -0.014208786189556122, -0.010318577289581299, -0.006428368389606476, -0.0025381669402122498, 0.0013520419597625732, 0.005242250859737396, 0.00913245975971222, 0.013022668659687042, 0.016912877559661865, 0.02080307900905609, 0.024693287909030914, 0.028583496809005737, 0.03247370570898056, 0.03636391460895538, 0.04025411605834961, 0.04414432495832443, 0.048034533858299255, 0.05192473530769348, 0.0558149516582489, 0.05970515310764313, 0.06359536945819855, 0.06748557090759277, 0.071375772356987, 0.07526598870754242, 0.07915619015693665, 0.08304640650749207, 0.08693660795688629, 0.09082680940628052, 0.09471702575683594, 0.09860722720623016, 0.10249744355678558, 0.10638764500617981, 0.11027786135673523, 0.11416806280612946, 0.11805826425552368, 0.1219484806060791, 0.12583868205547333, 0.12972889840602875, 0.13361909985542297, 0.1375093013048172, 0.14139951765537262, 0.14528971910476685, 0.14917993545532227, 0.1530701369047165, 0.15696033835411072, 0.16085055470466614, 0.16474075615406036, 0.16863097250461578, 0.17252117395401]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 6.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.287156879901886, -0.2713146209716797, -0.2554723620414734, -0.2396300733089447, -0.2237878143787384, -0.2079455554485321, -0.1921032816171646, -0.17626100778579712, -0.16041874885559082, -0.14457648992538452, -0.12873421609401703, -0.11289194226264954, -0.09704968333244324, -0.08120742440223694, -0.06536515057086945, -0.04952287673950195, -0.033680617809295654, -0.017838358879089355, -0.0019960999488830566, 0.01384618878364563, 0.02968844771385193, 0.04553070664405823, 0.061372995376586914, 0.07721525430679321, 0.09305751323699951, 0.10889977216720581, 0.12474203109741211, 0.1405843198299408, 0.1564265787601471, 0.1722688376903534, 0.18811112642288208, 0.20395338535308838, 0.21979564428329468, 0.23563790321350098, 0.2514801621437073, 0.2673224210739136, 0.2831646800041199, 0.29900699853897095, 0.31484925746917725, 0.33069151639938354, 0.34653377532958984, 0.36237603425979614, 0.37821829319000244, 0.39406055212020874, 0.4099028706550598, 0.4257451295852661, 0.4415873885154724, 0.4574296474456787, 0.473271906375885, 0.4891141653060913, 0.5049564242362976, 0.5207986831665039, 0.5366409420967102, 0.5524832606315613, 0.5683255195617676, 0.5841677784919739, 0.6000100374221802, 0.6158522963523865, 0.6316945552825928, 0.6475368142127991, 0.6633791327476501, 0.6792213916778564, 0.6950636506080627, 0.710905909538269, 0.7267481684684753]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.030114004388451576, -0.02864016778767109, -0.027166329324245453, -0.025692492723464966, -0.02421865612268448, -0.02274481952190399, -0.021270982921123505, -0.01979714445769787, -0.01832330785691738, -0.016849471256136894, -0.015375633724033833, -0.013901796191930771, -0.012427959591150284, -0.010954122990369797, -0.00948028452694416, -0.008006447926163673, -0.006532611325383186, -0.005058774724602699, -0.0035849381238222122, -0.002111099660396576, -0.0006372630596160889, 0.0008365735411643982, 0.0023104120045900345, 0.0037842486053705215, 0.005258085206151009, 0.006731921806931496, 0.008205758407711983, 0.00967959500849247, 0.011153435334563255, 0.012627271935343742, 0.01410110853612423, 0.015574945136904716, 0.017048781737685204, 0.01852261833846569, 0.019996454939246178, 0.021470291540026665, 0.022944128140807152, 0.024417968466877937, 0.025891805067658424, 0.02736564166843891, 0.0288394782692194, 0.030313314869999886, 0.03178714960813522, 0.03326099365949631, 0.034734830260276794, 0.03620866686105728, 0.03768250346183777, 0.039156340062618256, 0.04063017666339874, 0.04210401326417923, 0.04357784986495972, 0.045051686465740204, 0.04652552306652069, 0.04799935966730118, 0.049473196268081665, 0.05094703286886215, 0.052420876920223236, 0.05389471352100372, 0.05536855012178421, 0.0568423867225647, 0.058316223323345184, 0.05979005992412567, 0.06126389652490616, 0.06273773312568665, 0.06421156972646713]}, "_runtime": 10165.546637773514, "_timestamp": 1585607535.1795073, "_step": 398}
{"Episode reward": -99.66178985734449, "Episode length": 999, "Policy Loss": -0.49646857380867004, "Value Loss": 0.04570187255740166, "_runtime": 10167.13764333725, "_timestamp": 1585607536.7705128, "_step": 399}
{"Episode reward": -99.73612445700425, "Episode length": 999, "Policy Loss": -0.493023544549942, "Value Loss": 0.0322270542383194, "_runtime": 10168.730662345886, "_timestamp": 1585607538.3635318, "_step": 400}
{"Episode reward": -99.41126817477496, "Episode length": 999, "Policy Loss": -0.4880715310573578, "Value Loss": 0.019532177597284317, "_runtime": 10170.356128692627, "_timestamp": 1585607539.9889982, "_step": 401}
{"Episode reward": -99.23941695615514, "Episode length": 999, "Policy Loss": -0.48335397243499756, "Value Loss": 0.07978665083646774, "_runtime": 10171.947882652283, "_timestamp": 1585607541.5807521, "_step": 402}
{"Episode reward": -99.80016288889898, "Episode length": 999, "Policy Loss": -0.4989582300186157, "Value Loss": 0.09428133815526962, "_runtime": 10173.533765077591, "_timestamp": 1585607543.1666346, "_step": 403}
{"Episode reward": -99.2453107348164, "Episode length": 999, "Policy Loss": -0.4792303740978241, "Value Loss": 0.025516996160149574, "_runtime": 10174.982327222824, "_timestamp": 1585607544.6151967, "_step": 404}
{"Episode reward": 8.512225252338439, "Episode length": 916, "Policy Loss": 0.20340941846370697, "Value Loss": 10.495457649230957, "_runtime": 10176.58519244194, "_timestamp": 1585607546.218062, "_step": 405}
{"Episode reward": -99.43190475113667, "Episode length": 999, "Policy Loss": -0.45109665393829346, "Value Loss": 0.014749147929251194, "_runtime": 10178.17118859291, "_timestamp": 1585607547.804058, "_step": 406}
{"Episode reward": -99.66262728044391, "Episode length": 999, "Policy Loss": -0.4369867146015167, "Value Loss": 0.01552671194076538, "_runtime": 10179.545162677765, "_timestamp": 1585607549.1780322, "_step": 407}
{"Episode reward": 13.51740127549337, "Episode length": 867, "Policy Loss": 0.1874653697013855, "Value Loss": 11.04122543334961, "_runtime": 10181.136647939682, "_timestamp": 1585607550.7695174, "_step": 408}
{"Episode reward": -99.62918762297929, "Episode length": 999, "Policy Loss": -0.42204850912094116, "Value Loss": 0.010758230462670326, "_runtime": 10182.737814426422, "_timestamp": 1585607552.370684, "_step": 409}
{"Episode reward": -99.59782951087553, "Episode length": 999, "Policy Loss": -0.418659508228302, "Value Loss": 0.010977537371218204, "_runtime": 10184.300158262253, "_timestamp": 1585607553.9330277, "_step": 410}
{"Episode reward": -99.75956889786617, "Episode length": 999, "Policy Loss": -0.41679897904396057, "Value Loss": 0.0868508368730545, "_runtime": 10185.890674114227, "_timestamp": 1585607555.5235436, "_step": 411}
{"Episode reward": -99.63060765609704, "Episode length": 999, "Policy Loss": -0.40208712220191956, "Value Loss": 0.00699540926143527, "_runtime": 10187.471715450287, "_timestamp": 1585607557.104585, "_step": 412}
{"Episode reward": -99.83541535535338, "Episode length": 999, "Policy Loss": -0.39939606189727783, "Value Loss": 0.08367931097745895, "_runtime": 10189.055709600449, "_timestamp": 1585607558.688579, "_step": 413}
{"Episode reward": -99.4362103379376, "Episode length": 999, "Policy Loss": -0.4015274941921234, "Value Loss": 0.07902249693870544, "_runtime": 10190.176991224289, "_timestamp": 1585607559.8098607, "_step": 414}
{"Episode reward": 30.78037051553804, "Episode length": 694, "Policy Loss": 0.5885282158851624, "Value Loss": 13.638352394104004, "_runtime": 10191.76875758171, "_timestamp": 1585607561.401627, "_step": 415}
{"Episode reward": -99.52024710940758, "Episode length": 999, "Policy Loss": -0.3643624484539032, "Value Loss": 0.007493775803595781, "_runtime": 10193.362392187119, "_timestamp": 1585607562.9952617, "_step": 416}
{"Episode reward": -99.64055563439476, "Episode length": 999, "Policy Loss": -0.3433286249637604, "Value Loss": 0.0239005908370018, "_runtime": 10194.967893600464, "_timestamp": 1585607564.600763, "_step": 417}
{"Episode reward": -99.65674763015566, "Episode length": 999, "Policy Loss": -0.3590148091316223, "Value Loss": 0.03156999498605728, "_runtime": 10196.561854362488, "_timestamp": 1585607566.1947238, "_step": 418}
{"Episode reward": -99.51184448426218, "Episode length": 999, "Policy Loss": -0.3369280695915222, "Value Loss": 0.08066806942224503, "_runtime": 10198.150177240372, "_timestamp": 1585607567.7830467, "_step": 419}
{"Episode reward": -99.77919971754751, "Episode length": 999, "Policy Loss": -0.32825222611427307, "Value Loss": 0.01550977025181055, "_runtime": 10199.73750281334, "_timestamp": 1585607569.3703723, "_step": 420}
{"Episode reward": -99.43728043339661, "Episode length": 999, "Policy Loss": -0.3268117606639862, "Value Loss": 0.056067030876874924, "_runtime": 10201.095160484314, "_timestamp": 1585607570.72803, "_step": 421}
{"Episode reward": 15.502760690119416, "Episode length": 850, "Policy Loss": 0.37199947237968445, "Value Loss": 11.431181907653809, "_runtime": 10202.691637516022, "_timestamp": 1585607572.324507, "_step": 422}
{"Episode reward": -99.86937622051197, "Episode length": 999, "Policy Loss": -0.3055298924446106, "Value Loss": 0.008904381655156612, "_runtime": 10204.06988811493, "_timestamp": 1585607573.7027576, "_step": 423}
{"Episode reward": 13.832537762058806, "Episode length": 865, "Policy Loss": 0.40222737193107605, "Value Loss": 10.971447944641113, "_runtime": 10205.658659696579, "_timestamp": 1585607575.2915292, "_step": 424}
{"Episode reward": -99.42107675062589, "Episode length": 999, "Policy Loss": -0.27283909916877747, "Value Loss": 0.019336024299263954, "_runtime": 10207.06410741806, "_timestamp": 1585607576.696977, "_step": 425}
{"Episode reward": 12.132054911368314, "Episode length": 881, "Policy Loss": 0.3556704521179199, "Value Loss": 10.798943519592285, "_runtime": 10208.656045675278, "_timestamp": 1585607578.2889152, "_step": 426}
{"Episode reward": -99.58244839591067, "Episode length": 999, "Policy Loss": -0.28043854236602783, "Value Loss": 0.06261815130710602, "_runtime": 10209.997236967087, "_timestamp": 1585607579.6301064, "_step": 427}
{"Episode reward": 16.517712122999825, "Episode length": 838, "Policy Loss": 0.3786064684391022, "Value Loss": 11.293224334716797, "_runtime": 10211.584252595901, "_timestamp": 1585607581.217122, "_step": 428}
{"Episode reward": -99.32259014163147, "Episode length": 999, "Policy Loss": -0.2630615532398224, "Value Loss": 0.007594492752104998, "_runtime": 10213.181974887848, "_timestamp": 1585607582.8148444, "_step": 429}
{"Episode reward": -99.5169498449294, "Episode length": 999, "Policy Loss": -0.30077657103538513, "Value Loss": 0.37100666761398315, "_runtime": 10214.75451016426, "_timestamp": 1585607584.3873796, "_step": 430}
{"Episode reward": -99.7996738100003, "Episode length": 999, "Policy Loss": -0.26504001021385193, "Value Loss": 0.0025918809697031975, "_runtime": 10216.3534450531, "_timestamp": 1585607585.9863145, "_step": 431}
{"Episode reward": -99.73035907532181, "Episode length": 999, "Policy Loss": -0.2623894512653351, "Value Loss": 0.005515750497579575, "_runtime": 10217.992687940598, "_timestamp": 1585607587.6255574, "_step": 432}
{"Episode reward": -99.55783732546122, "Episode length": 999, "Policy Loss": -0.253961980342865, "Value Loss": 0.022677535191178322, "_runtime": 10219.263369321823, "_timestamp": 1585607588.8962388, "_step": 433}
{"Episode reward": 20.394970473781243, "Episode length": 797, "Policy Loss": 0.5605995655059814, "Value Loss": 12.18441390991211, "_runtime": 10220.858870744705, "_timestamp": 1585607590.4917402, "_step": 434}
{"Episode reward": -99.7360180052391, "Episode length": 999, "Policy Loss": -0.26402926445007324, "Value Loss": 0.04099343344569206, "_runtime": 10222.458835601807, "_timestamp": 1585607592.091705, "_step": 435}
{"Episode reward": -99.46746053275864, "Episode length": 999, "Policy Loss": -0.22149309515953064, "Value Loss": 0.09912854433059692, "_runtime": 10224.02234530449, "_timestamp": 1585607593.6552148, "_step": 436}
{"Episode reward": -99.84016885757306, "Episode length": 999, "Policy Loss": -0.2535405158996582, "Value Loss": 0.044548727571964264, "_runtime": 10225.1591629982, "_timestamp": 1585607594.7920325, "_step": 437}
{"Episode reward": 29.596615687652687, "Episode length": 705, "Policy Loss": 0.5836650729179382, "Value Loss": 13.520286560058594, "_runtime": 10226.300013065338, "_timestamp": 1585607595.9328825, "_step": 438}
{"Episode reward": 28.89053248385875, "Episode length": 714, "Policy Loss": 0.6525905132293701, "Value Loss": 13.585515975952148, "_runtime": 10227.892385721207, "_timestamp": 1585607597.5252552, "_step": 439}
{"Episode reward": -99.63347029047878, "Episode length": 999, "Policy Loss": -0.24019953608512878, "Value Loss": 0.03252683952450752, "_runtime": 10229.446340799332, "_timestamp": 1585607599.0792103, "_step": 440}
{"Episode reward": -99.79835966682155, "Episode length": 999, "Policy Loss": -0.24261435866355896, "Value Loss": 0.00165751192253083, "_runtime": 10231.015886545181, "_timestamp": 1585607600.648756, "_step": 441}
{"Episode reward": -99.60163443476637, "Episode length": 999, "Policy Loss": -0.24250651895999908, "Value Loss": 0.011875723488628864, "_runtime": 10232.607491493225, "_timestamp": 1585607602.240361, "_step": 442}
{"Episode reward": -99.62054400081841, "Episode length": 999, "Policy Loss": -0.2413620948791504, "Value Loss": 0.012292110361158848, "_runtime": 10233.847027540207, "_timestamp": 1585607603.479897, "_step": 443}
{"Episode reward": 22.352635105321085, "Episode length": 779, "Policy Loss": 0.46051275730133057, "Value Loss": 12.116297721862793, "_runtime": 10234.400163173676, "_timestamp": 1585607604.0330327, "_step": 444}
{"Episode reward": 66.50387133266757, "Episode length": 335, "Policy Loss": 1.7206546068191528, "Value Loss": 28.406370162963867, "_runtime": 10235.071607589722, "_timestamp": 1585607604.704477, "_step": 445}
{"Episode reward": 58.78782209819152, "Episode length": 413, "Policy Loss": 1.020856499671936, "Value Loss": 23.292619705200195, "_runtime": 10235.602679729462, "_timestamp": 1585607605.2355492, "_step": 446}
{"Episode reward": 67.79999999999981, "Episode length": 322, "Policy Loss": 1.3533040285110474, "Value Loss": 29.864120483398438, "_runtime": 10237.12828207016, "_timestamp": 1585607606.7611516, "_step": 447}
{"Episode reward": -99.66692222882854, "Episode length": 999, "Policy Loss": -0.26613086462020874, "Value Loss": 0.027654865756630898, "_runtime": 10238.356767416, "_timestamp": 1585607607.989637, "_step": 448}
{"Episode reward": 19.59629711270712, "Episode length": 806, "Policy Loss": 0.5032976269721985, "Value Loss": 11.991668701171875, "_runtime": 10239.865723609924, "_timestamp": 1585607609.498593, "_step": 449}
{"Episode reward": -99.61560735238463, "Episode length": 999, "Policy Loss": -0.28595611453056335, "Value Loss": 0.11838117241859436, "_runtime": 10241.468979358673, "_timestamp": 1585607611.1018488, "_step": 450}
{"Episode reward": -99.5920901781982, "Episode length": 999, "Policy Loss": -0.30395713448524475, "Value Loss": 0.12535227835178375, "_runtime": 10243.02598643303, "_timestamp": 1585607612.658856, "_step": 451}
{"Episode reward": -99.41976318795213, "Episode length": 999, "Policy Loss": -0.2972303330898285, "Value Loss": 0.12540824711322784, "_runtime": 10244.579787015915, "_timestamp": 1585607614.2126565, "_step": 452}
{"Episode reward": -99.53470145628532, "Episode length": 999, "Policy Loss": -0.28528422117233276, "Value Loss": 0.11403799802064896, "_runtime": 10245.25970029831, "_timestamp": 1585607614.8925698, "_step": 453}
{"Episode reward": 59.14693169173521, "Episode length": 411, "Policy Loss": 1.069614052772522, "Value Loss": 23.493684768676758, "_runtime": 10246.84465956688, "_timestamp": 1585607616.477529, "_step": 454}
{"Episode reward": -99.36128910553971, "Episode length": 999, "Policy Loss": -0.3672070801258087, "Value Loss": 0.10429005324840546, "_runtime": 10248.412224769592, "_timestamp": 1585607618.0450943, "_step": 455}
{"Episode reward": -99.7495866459373, "Episode length": 999, "Policy Loss": -0.34650373458862305, "Value Loss": 0.028529148548841476, "_runtime": 10249.93797826767, "_timestamp": 1585607619.5708477, "_step": 456}
{"Episode reward": -99.81553841219726, "Episode length": 999, "Policy Loss": -0.347845196723938, "Value Loss": 0.016860121861100197, "_runtime": 10251.509418725967, "_timestamp": 1585607621.1422882, "_step": 457}
{"Episode reward": -99.75922218789206, "Episode length": 999, "Policy Loss": -0.371576189994812, "Value Loss": 0.08457038551568985, "_runtime": 10253.079155683517, "_timestamp": 1585607622.7120252, "_step": 458}
{"Episode reward": -99.36055526557475, "Episode length": 999, "Policy Loss": -0.3714753985404968, "Value Loss": 0.12394114583730698, "_runtime": 10254.233291864395, "_timestamp": 1585607623.8661613, "_step": 459}
{"Episode reward": 26.93483394730707, "Episode length": 734, "Policy Loss": 0.39723819494247437, "Value Loss": 13.377246856689453, "_runtime": 10255.819785118103, "_timestamp": 1585607625.4526546, "_step": 460}
{"Episode reward": -99.47924990210312, "Episode length": 999, "Policy Loss": -0.38893967866897583, "Value Loss": 0.21258339285850525, "_runtime": 10256.47649860382, "_timestamp": 1585607626.109368, "_step": 461}
{"Episode reward": 60.885747984907084, "Episode length": 394, "Policy Loss": 1.2540853023529053, "Value Loss": 23.751150131225586, "_runtime": 10257.338397026062, "_timestamp": 1585607626.9712665, "_step": 462}
{"Episode reward": 45.03126783490829, "Episode length": 551, "Policy Loss": 0.7507117986679077, "Value Loss": 17.327980041503906, "_runtime": 10258.910396814346, "_timestamp": 1585607628.5432663, "_step": 463}
{"Episode reward": -99.48341536698145, "Episode length": 999, "Policy Loss": -0.37621915340423584, "Value Loss": 0.006314785685390234, "_runtime": 10260.432666301727, "_timestamp": 1585607630.0655358, "_step": 464}
{"Episode reward": -99.67141288716674, "Episode length": 999, "Policy Loss": -0.37377363443374634, "Value Loss": 0.039821431040763855, "_runtime": 10261.968747377396, "_timestamp": 1585607631.6016169, "_step": 465}
{"Episode reward": -99.65357404767279, "Episode length": 999, "Policy Loss": -0.3797323405742645, "Value Loss": 0.03320745378732681, "_runtime": 10263.551457881927, "_timestamp": 1585607633.1843274, "_step": 466}
{"Episode reward": -99.41007561471642, "Episode length": 999, "Policy Loss": -0.37717440724372864, "Value Loss": 0.059211425483226776, "_runtime": 10264.562967300415, "_timestamp": 1585607634.1958368, "_step": 467}
{"Episode reward": 36.499999999999375, "Episode length": 635, "Policy Loss": 0.467571884393692, "Value Loss": 14.840385437011719, "_runtime": 10266.177399396896, "_timestamp": 1585607635.8102689, "_step": 468}
{"Episode reward": -99.67180614498655, "Episode length": 999, "Policy Loss": -0.38652095198631287, "Value Loss": 0.19652964174747467, "_runtime": 10266.810784816742, "_timestamp": 1585607636.4436543, "_step": 469}
{"Episode reward": 61.55363016778111, "Episode length": 385, "Policy Loss": 1.010780930519104, "Value Loss": 24.862567901611328, "_runtime": 10267.49953365326, "_timestamp": 1585607637.1324031, "_step": 470}
{"Episode reward": 55.96793246562558, "Episode length": 442, "Policy Loss": 0.8820400238037109, "Value Loss": 21.6458683013916, "_runtime": 10269.066001653671, "_timestamp": 1585607638.6988711, "_step": 471}
{"Episode reward": -99.69418129979029, "Episode length": 999, "Policy Loss": -0.39035168290138245, "Value Loss": 0.04341978207230568, "_runtime": 10270.17579460144, "_timestamp": 1585607639.808664, "_step": 472}
{"Episode reward": 27.565623006573716, "Episode length": 725, "Policy Loss": 0.34136199951171875, "Value Loss": 13.040133476257324, "_runtime": 10270.709218740463, "_timestamp": 1585607640.3420882, "_step": 473}
{"Episode reward": 66.74750050042039, "Episode length": 336, "Policy Loss": 0.9840580224990845, "Value Loss": 30.602975845336914, "_runtime": 10272.01562333107, "_timestamp": 1585607641.6484928, "_step": 474}
{"Episode reward": 16.582273581973723, "Episode length": 838, "Policy Loss": 0.266854852437973, "Value Loss": 11.417448043823242, "_runtime": 10273.547047138214, "_timestamp": 1585607643.1799166, "_step": 475}
{"Episode reward": -99.62435211335402, "Episode length": 999, "Policy Loss": -0.4084673523902893, "Value Loss": 0.18899430334568024, "_runtime": 10275.058900117874, "_timestamp": 1585607644.6917696, "_step": 476}
{"Episode reward": -99.12539106799387, "Episode length": 999, "Policy Loss": -0.41664552688598633, "Value Loss": 0.34623268246650696, "_runtime": 10276.627298116684, "_timestamp": 1585607646.2601676, "_step": 477}
{"Episode reward": -99.54593021732732, "Episode length": 999, "Policy Loss": -0.3977571725845337, "Value Loss": 0.5642229914665222, "_runtime": 10277.674179553986, "_timestamp": 1585607647.307049, "_step": 478}
{"Episode reward": 34.54224304277976, "Episode length": 658, "Policy Loss": 0.4692208468914032, "Value Loss": 15.337648391723633, "_runtime": 10279.218102693558, "_timestamp": 1585607648.8509722, "_step": 479}
{"Episode reward": -99.70354976954266, "Episode length": 999, "Policy Loss": -0.48301148414611816, "Value Loss": 0.027363616973161697, "_runtime": 10280.808940887451, "_timestamp": 1585607650.4418104, "_step": 480}
{"Episode reward": -99.51931450384299, "Episode length": 999, "Policy Loss": -0.49219810962677, "Value Loss": 0.03714751452207565, "_runtime": 10282.354788064957, "_timestamp": 1585607651.9876575, "_step": 481}
{"Episode reward": -99.73873368648789, "Episode length": 999, "Policy Loss": -0.5265008807182312, "Value Loss": 0.01297768484801054, "_runtime": 10283.913095235825, "_timestamp": 1585607653.5459647, "_step": 482}
{"Episode reward": -99.65029380257336, "Episode length": 999, "Policy Loss": -0.5386053919792175, "Value Loss": 0.01580285094678402, "_runtime": 10285.494495153427, "_timestamp": 1585607655.1273646, "_step": 483}
{"Episode reward": -99.52766695351899, "Episode length": 999, "Policy Loss": -0.555387556552887, "Value Loss": 0.016670584678649902, "_runtime": 10287.078750371933, "_timestamp": 1585607656.7116199, "_step": 484}
{"Episode reward": -99.87537883242918, "Episode length": 999, "Policy Loss": -0.5652807354927063, "Value Loss": 0.053341612219810486, "_runtime": 10288.25354886055, "_timestamp": 1585607657.8864183, "_step": 485}
{"Episode reward": 28.450236370548154, "Episode length": 716, "Policy Loss": 0.22460941970348358, "Value Loss": 13.698954582214355, "_runtime": 10289.81884932518, "_timestamp": 1585607659.4517188, "_step": 486}
{"Episode reward": -99.47144227467805, "Episode length": 999, "Policy Loss": -0.5781123042106628, "Value Loss": 0.02007168158888817, "_runtime": 10291.392244815826, "_timestamp": 1585607661.0251143, "_step": 487}
{"Episode reward": -99.60399662693243, "Episode length": 999, "Policy Loss": -0.5918523073196411, "Value Loss": 0.08467751741409302, "_runtime": 10292.340933084488, "_timestamp": 1585607661.9738026, "_step": 488}
{"Episode reward": 40.71341451238784, "Episode length": 595, "Policy Loss": 0.3434971570968628, "Value Loss": 16.342967987060547, "_runtime": 10293.131166696548, "_timestamp": 1585607662.7640362, "_step": 489}
{"Episode reward": 51.531959151906946, "Episode length": 487, "Policy Loss": 0.5722790360450745, "Value Loss": 20.10081672668457, "_runtime": 10294.086560726166, "_timestamp": 1585607663.7194302, "_step": 490}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 0.3851136565208435, "Value Loss": 16.34914779663086, "_runtime": 10295.641497135162, "_timestamp": 1585607665.2743666, "_step": 491}
{"Episode reward": -99.67911549752905, "Episode length": 999, "Policy Loss": -0.5933763384819031, "Value Loss": 0.05441749095916748, "_runtime": 10297.175926923752, "_timestamp": 1585607666.8087964, "_step": 492}
{"Episode reward": -99.40839154872093, "Episode length": 999, "Policy Loss": -0.6058735251426697, "Value Loss": 0.07671120017766953, "_runtime": 10298.335522174835, "_timestamp": 1585607667.9683917, "_step": 493}
{"Episode reward": 25.47497671760499, "Episode length": 749, "Policy Loss": 0.18351273238658905, "Value Loss": 13.051948547363281, "_runtime": 10299.765070438385, "_timestamp": 1585607669.39794, "_step": 494}
{"Episode reward": 9.226526419091684, "Episode length": 909, "Policy Loss": 0.31751567125320435, "Value Loss": 10.628658294677734, "_runtime": 10300.284076213837, "_timestamp": 1585607669.9169457, "_step": 495}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 1.2236521244049072, "Value Loss": 31.62873077392578, "_runtime": 10301.83774805069, "_timestamp": 1585607671.4706175, "_step": 496}
{"Episode reward": -99.54953127743073, "Episode length": 999, "Policy Loss": -0.5736854672431946, "Value Loss": 0.05212187021970749, "_runtime": 10303.414496660233, "_timestamp": 1585607673.0473661, "_step": 497}
{"Episode reward": -99.79763109022029, "Episode length": 999, "Policy Loss": -0.5678427219390869, "Value Loss": 0.04213935136795044, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228, 0.02417275868356228]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.024172615259885788, -0.0126963434740901, -0.0012200716882944107, 0.010256201028823853, 0.021732471883296967, 0.03320874273777008, 0.04468501731753349, 0.05616128817200661, 0.06763756275177002, 0.07911382615566254, 0.09059010446071625, 0.10206636786460876, 0.11354264616966248, 0.125018909573555, 0.1364951878786087, 0.14797145128250122, 0.15944772958755493, 0.17092400789260864, 0.18240027129650116, 0.19387654960155487, 0.2053528130054474, 0.2168290913105011, 0.22830535471439362, 0.23978163301944733, 0.25125792622566223, 0.26273420453071594, 0.27421045303344727, 0.285686731338501, 0.2971630096435547, 0.3086392879486084, 0.3201155364513397, 0.33159181475639343, 0.34306809306144714, 0.35454437136650085, 0.36602064967155457, 0.3774968981742859, 0.3889731764793396, 0.4004494547843933, 0.411925733089447, 0.42340198159217834, 0.43487825989723206, 0.44635453820228577, 0.4578308165073395, 0.4693070948123932, 0.4807833433151245, 0.4922596216201782, 0.5037358999252319, 0.5152121782302856, 0.5266884565353394, 0.5381647348403931, 0.5496410131454468, 0.5611172318458557, 0.5725935101509094, 0.5840697884559631, 0.5955460667610168, 0.6070223450660706, 0.6184986233711243, 0.629974901676178, 0.6414511799812317, 0.6529274582862854, 0.6644036769866943, 0.675879955291748, 0.6873562335968018, 0.6988325119018555, 0.7103087902069092]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0014212734531611204, -0.0009535521967336535, -0.0004858309985138476, -1.8109800294041634e-05, 0.00044961145613342524, 0.0009173327125608921, 0.0013850538525730371, 0.0018527752254158258, 0.002320496365427971, 0.002788217505440116, 0.0032559388782829046, 0.0037236602511256933, 0.004191380925476551, 0.00465910229831934, 0.0051268236711621284, 0.005594545044004917, 0.006062266416847706, 0.00652998685836792, 0.006997708231210709, 0.007465429604053497, 0.007933150976896286, 0.008400872349739075, 0.008868593722581863, 0.009336314164102077, 0.009804035536944866, 0.010271756909787655, 0.010739478282630444, 0.011207199655473232, 0.011674921028316021, 0.012142641469836235, 0.012610362842679024, 0.013078084215521812, 0.013545805588364601, 0.01401352696120739, 0.014481247402727604, 0.014948968775570393, 0.015416690148413181, 0.015884412452578545, 0.016352133825421333, 0.016819855198264122, 0.01728757657110691, 0.0177552979439497, 0.018223019316792488, 0.018690740689635277, 0.019158462062478065, 0.019626181572675705, 0.020093902945518494, 0.020561624318361282, 0.02102934569120407, 0.02149706706404686, 0.02196478843688965, 0.022432509809732437, 0.022900231182575226, 0.023367952555418015, 0.023835673928260803, 0.024303395301103592, 0.02477111667394638, 0.02523883804678917, 0.02570655755698681, 0.026174278929829597, 0.026642000302672386, 0.027109721675515175, 0.027577443048357964, 0.028045164421200752, 0.02851288579404354]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 4.0, 4.0, 7.0, 6.0, 14.0, 10.0, 11.0, 5.0, 7.0, 1.0, 4.0, 5.0, 5.0, 5.0, 4.0, 2.0, 14.0, 9.0, 21.0, 273.0, 22.0, 9.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 4.0, 2.0, 5.0, 1.0, 3.0, 2.0, 3.0, 4.0, 1.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.023358281701803207, -0.022220877930521965, -0.021083474159240723, -0.01994607038795948, -0.018808666616678238, -0.017671262845396996, -0.016533859074115753, -0.01539645530283451, -0.014259051531553268, -0.013121647760272026, -0.011984243988990784, -0.010846840217709541, -0.009709436446428299, -0.008572032675147057, -0.007434628903865814, -0.006297225132584572, -0.0051598213613033295, -0.004022417590022087, -0.0028850138187408447, -0.0017476100474596024, -0.00061020627617836, 0.0005271974951028824, 0.0016646012663841248, 0.002802005037665367, 0.0039394088089466095, 0.005076812580227852, 0.006214216351509094, 0.007351620122790337, 0.008489023894071579, 0.00962642952799797, 0.010763831436634064, 0.011901233345270157, 0.013038638979196548, 0.01417604461312294, 0.015313446521759033, 0.016450848430395126, 0.017588254064321518, 0.01872565969824791, 0.019863061606884003, 0.021000463515520096, 0.022137869149446487, 0.02327527478337288, 0.024412676692008972, 0.025550078600645065, 0.026687484234571457, 0.02782488986849785, 0.02896229177713394, 0.030099693685770035, 0.031237099319696426, 0.03237450495362282, 0.03351190686225891, 0.034649308770895004, 0.035786714404821396, 0.03692412003874779, 0.03806152194738388, 0.039198923856019974, 0.040336329489946365, 0.04147373512387276, 0.04261114075779915, 0.04374853894114494, 0.044885944575071335, 0.046023350208997726, 0.04716074839234352, 0.04829815402626991, 0.049435559660196304]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.08850062638521194, -0.08338368684053421, -0.07826673984527588, -0.07314980030059814, -0.06803286075592041, -0.06291592121124268, -0.05779897794127464, -0.05268203467130661, -0.047565095126628876, -0.04244815558195114, -0.03733121231198311, -0.032214269042015076, -0.02709732949733734, -0.021980389952659607, -0.016863442957401276, -0.011746503412723541, -0.006629563868045807, -0.0015126243233680725, 0.003604315221309662, 0.008721262216567993, 0.013838201761245728, 0.018955141305923462, 0.024072088301181793, 0.029189027845859528, 0.03430596739053726, 0.039422906935214996, 0.04453984647989273, 0.049656786024570465, 0.05477374047040939, 0.05989068001508713, 0.06500761955976486, 0.0701245591044426, 0.07524149864912033, 0.08035843819379807, 0.0854753777384758, 0.09059231728315353, 0.09570925682783127, 0.1008262112736702, 0.10594315081834793, 0.11106009036302567, 0.1161770299077034, 0.12129396945238113, 0.12641090154647827, 0.131527841091156, 0.13664481043815613, 0.14176174998283386, 0.1468786895275116, 0.15199562907218933, 0.15711256861686707, 0.1622295081615448, 0.16734644770622253, 0.17246338725090027, 0.177580326795578, 0.18269726634025574, 0.18781420588493347, 0.1929311454296112, 0.19804811477661133, 0.20316505432128906, 0.2082819938659668, 0.21339893341064453, 0.21851587295532227, 0.2236328125, 0.22874975204467773, 0.23386669158935547, 0.2389836311340332]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 5.0, 2.0, 4.0, 3.0, 4.0, 9.0, 10.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.018488584086298943, -0.01737014763057232, -0.016251709312200546, -0.015133272856473923, -0.0140148364007473, -0.012896399013698101, -0.011777961626648903, -0.01065952517092228, -0.009541087783873081, -0.008422650396823883, -0.0073042139410972595, -0.006185776554048061, -0.005067339166998863, -0.00394890271127224, -0.002830466255545616, -0.0017120279371738434, -0.0005935914814472198, 0.0005248449742794037, 0.0016432832926511765, 0.0027617197483778, 0.0038801562041044235, 0.004998594522476196, 0.00611703097820282, 0.007235467433929443, 0.008353905752301216, 0.00947234220802784, 0.010590778663754463, 0.011709215119481087, 0.01282765157520771, 0.013946091756224632, 0.015064528211951256, 0.01618296466767788, 0.017301401123404503, 0.018419837579131126, 0.01953827403485775, 0.020656710490584373, 0.021775150671601295, 0.02289358712732792, 0.024012023583054543, 0.025130460038781166, 0.02624889649450779, 0.027367332950234413, 0.028485773131251335, 0.02960420958697796, 0.030722646042704582, 0.031841084361076355, 0.03295952081680298, 0.0340779572725296, 0.035196393728256226, 0.03631483018398285, 0.03743326663970947, 0.038551703095436096, 0.03967013955116272, 0.04078857600688934, 0.04190701246261597, 0.04302545636892319, 0.044143885374069214, 0.04526232182979584, 0.04638076573610306, 0.04749920219182968, 0.048617638647556305, 0.04973607510328293, 0.05085451155900955, 0.051972948014736176, 0.0530913844704628]}, "_runtime": 10304.921224832535, "_timestamp": 1585607674.5540943, "_step": 498}
{"Episode reward": -99.82522710646013, "Episode length": 999, "Policy Loss": -0.560990035533905, "Value Loss": 0.02234717085957527, "_runtime": 10304.921224832535, "_timestamp": 1585607674.5540943, "_step": 499}
