{"Episode reward": -45.78961528225231, "Episode length": 999, "Policy Loss": -0.05583757907152176, "Value Loss": 0.011638477444648743, "_runtime": 3277.948538541794, "_timestamp": 1585600647.581408, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1403529644012451, "Value Loss": 4.625554084777832, "_runtime": 3279.4226751327515, "_timestamp": 1585600649.0555446, "_step": 1}
{"Episode reward": -97.99274375525695, "Episode length": 999, "Policy Loss": 33.99789810180664, "Value Loss": 5579.57275390625, "_runtime": 3279.711024284363, "_timestamp": 1585600649.3438938, "_step": 2}
{"Episode reward": 86.15338341688107, "Episode length": 140, "Policy Loss": -407.61279296875, "Value Loss": 16298.1572265625, "_runtime": 3281.235366344452, "_timestamp": 1585600650.8682358, "_step": 3}
{"Episode reward": -99.47908815534181, "Episode length": 999, "Policy Loss": -6.899379253387451, "Value Loss": 318.57196044921875, "_runtime": 3282.758964776993, "_timestamp": 1585600652.3918343, "_step": 4}
{"Episode reward": -99.50558320342104, "Episode length": 999, "Policy Loss": 2.14072322845459, "Value Loss": 1208.3936767578125, "_runtime": 3284.2246437072754, "_timestamp": 1585600653.8575132, "_step": 5}
{"Episode reward": -99.4982792061522, "Episode length": 999, "Policy Loss": 19.913713455200195, "Value Loss": 5241.66357421875, "_runtime": 3285.784344434738, "_timestamp": 1585600655.417214, "_step": 6}
{"Episode reward": -99.49536191743678, "Episode length": 999, "Policy Loss": -14.488051414489746, "Value Loss": 2790.556884765625, "_runtime": 3287.327654838562, "_timestamp": 1585600656.9605243, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.623333930969238, "Value Loss": 1076.918701171875, "_runtime": 3288.881761789322, "_timestamp": 1585600658.5146313, "_step": 8}
{"Episode reward": -99.55148662354298, "Episode length": 999, "Policy Loss": 25.080554962158203, "Value Loss": 1386.9013671875, "_runtime": 3290.450874567032, "_timestamp": 1585600660.083744, "_step": 9}
{"Episode reward": -98.8793039293908, "Episode length": 999, "Policy Loss": 56.07415008544922, "Value Loss": 5146.267578125, "_runtime": 3291.9799313545227, "_timestamp": 1585600661.6128008, "_step": 10}
{"Episode reward": -99.76415768610174, "Episode length": 999, "Policy Loss": 3.6205856800079346, "Value Loss": 688.8224487304688, "_runtime": 3293.5084040164948, "_timestamp": 1585600663.1412735, "_step": 11}
{"Episode reward": -99.61904481237296, "Episode length": 999, "Policy Loss": -12.280989646911621, "Value Loss": 582.9815673828125, "_runtime": 3295.0662336349487, "_timestamp": 1585600664.699103, "_step": 12}
{"Episode reward": -99.0853660343352, "Episode length": 999, "Policy Loss": -16.560131072998047, "Value Loss": 395.6091613769531, "_runtime": 3296.6183891296387, "_timestamp": 1585600666.2512586, "_step": 13}
{"Episode reward": -99.8743779912577, "Episode length": 999, "Policy Loss": -13.814623832702637, "Value Loss": 85.96263122558594, "_runtime": 3298.159337282181, "_timestamp": 1585600667.7922068, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.347604751586914, "Value Loss": 186.45730590820312, "_runtime": 3299.7275235652924, "_timestamp": 1585600669.360393, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.64914894104004, "Value Loss": 1649.8240966796875, "_runtime": 3301.287138938904, "_timestamp": 1585600670.9200084, "_step": 16}
{"Episode reward": -99.87766661085048, "Episode length": 999, "Policy Loss": -16.491037368774414, "Value Loss": 1047.6741943359375, "_runtime": 3302.8369705677032, "_timestamp": 1585600672.46984, "_step": 17}
{"Episode reward": -99.79571064719791, "Episode length": 999, "Policy Loss": -19.462656021118164, "Value Loss": 293.1016845703125, "_runtime": 3304.3999285697937, "_timestamp": 1585600674.032798, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -32.07725524902344, "Value Loss": 528.670166015625, "_runtime": 3305.962484359741, "_timestamp": 1585600675.5953538, "_step": 19}
{"Episode reward": -99.67799951685454, "Episode length": 999, "Policy Loss": -33.16041946411133, "Value Loss": 1077.5916748046875, "_runtime": 3307.5106558799744, "_timestamp": 1585600677.1435254, "_step": 20}
{"Episode reward": -99.60393295985347, "Episode length": 999, "Policy Loss": -49.355751037597656, "Value Loss": 1024.306884765625, "_runtime": 3307.9019227027893, "_timestamp": 1585600677.5347922, "_step": 21}
{"Episode reward": 77.89999999999996, "Episode length": 221, "Policy Loss": -21.5203857421875, "Value Loss": 93.24404907226562, "_runtime": 3309.459928035736, "_timestamp": 1585600679.0927975, "_step": 22}
{"Episode reward": -99.6385487481524, "Episode length": 999, "Policy Loss": -21.083473205566406, "Value Loss": 121.73722076416016, "_runtime": 3311.011553287506, "_timestamp": 1585600680.6444228, "_step": 23}
{"Episode reward": -99.77354846615205, "Episode length": 999, "Policy Loss": -0.5969010591506958, "Value Loss": 651.477294921875, "_runtime": 3312.52060174942, "_timestamp": 1585600682.1534712, "_step": 24}
{"Episode reward": -99.88167596496501, "Episode length": 999, "Policy Loss": -16.612430572509766, "Value Loss": 1176.501708984375, "_runtime": 3314.0685188770294, "_timestamp": 1585600683.7013884, "_step": 25}
{"Episode reward": -99.81695822030166, "Episode length": 999, "Policy Loss": -12.654648780822754, "Value Loss": 1233.3779296875, "_runtime": 3315.4253499507904, "_timestamp": 1585600685.0582194, "_step": 26}
{"Episode reward": 12.058000360430015, "Episode length": 880, "Policy Loss": -10.004130363464355, "Value Loss": 47.037479400634766, "_runtime": 3316.95334815979, "_timestamp": 1585600686.5862176, "_step": 27}
{"Episode reward": -99.81060698032239, "Episode length": 999, "Policy Loss": -3.407984495162964, "Value Loss": 70.86231231689453, "_runtime": 3317.3910484313965, "_timestamp": 1585600687.023918, "_step": 28}
{"Episode reward": 75.49999999999993, "Episode length": 245, "Policy Loss": 9.621573448181152, "Value Loss": 538.2941284179688, "_runtime": 3318.252406358719, "_timestamp": 1585600687.8852758, "_step": 29}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 12.952876091003418, "Value Loss": 384.0928039550781, "_runtime": 3319.7865018844604, "_timestamp": 1585600689.4193714, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 24.358686447143555, "Value Loss": 25.354248046875, "_runtime": 3321.263304233551, "_timestamp": 1585600690.8961737, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 34.4714469909668, "Value Loss": 460.90631103515625, "_runtime": 3322.7709658145905, "_timestamp": 1585600692.4038353, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 37.58727264404297, "Value Loss": 511.56793212890625, "_runtime": 3324.315440893173, "_timestamp": 1585600693.9483104, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 36.52582931518555, "Value Loss": 271.4248046875, "_runtime": 3325.7591660022736, "_timestamp": 1585600695.3920355, "_step": 34}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": 37.07640075683594, "Value Loss": 286.9059753417969, "_runtime": 3327.3113696575165, "_timestamp": 1585600696.9442391, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 30.020353317260742, "Value Loss": 31.857158660888672, "_runtime": 3328.092232942581, "_timestamp": 1585600697.7251024, "_step": 36}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 24.90930938720703, "Value Loss": 395.6727600097656, "_runtime": 3328.688390016556, "_timestamp": 1585600698.3212595, "_step": 37}
{"Episode reward": 63.09999999999975, "Episode length": 369, "Policy Loss": 24.35270118713379, "Value Loss": 316.9136962890625, "_runtime": 3330.1428022384644, "_timestamp": 1585600699.7756717, "_step": 38}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 19.607669830322266, "Value Loss": 376.1417541503906, "_runtime": 3331.649243593216, "_timestamp": 1585600701.282113, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.551462173461914, "Value Loss": 64.50325012207031, "_runtime": 3333.1328561306, "_timestamp": 1585600702.7657256, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.76006507873535, "Value Loss": 13.482470512390137, "_runtime": 3334.3610265254974, "_timestamp": 1585600703.993896, "_step": 41}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 20.461788177490234, "Value Loss": 53.79220962524414, "_runtime": 3335.731716156006, "_timestamp": 1585600705.3645856, "_step": 42}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": 18.711965560913086, "Value Loss": 60.67892837524414, "_runtime": 3337.2682690620422, "_timestamp": 1585600706.9011385, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 16.007450103759766, "Value Loss": 77.20220947265625, "_runtime": 3338.3787145614624, "_timestamp": 1585600708.011584, "_step": 44}
{"Episode reward": 28.299999999999798, "Episode length": 717, "Policy Loss": 15.166560173034668, "Value Loss": 130.49578857421875, "_runtime": 3339.920730113983, "_timestamp": 1585600709.5535996, "_step": 45}
{"Episode reward": -99.80358924865583, "Episode length": 999, "Policy Loss": 8.244145393371582, "Value Loss": 33.104270935058594, "_runtime": 3340.676463842392, "_timestamp": 1585600710.3093333, "_step": 46}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": 6.682260036468506, "Value Loss": 51.54893493652344, "_runtime": 3342.2125220298767, "_timestamp": 1585600711.8453915, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1797893047332764, "Value Loss": 1.417482614517212, "_runtime": 3343.5662093162537, "_timestamp": 1585600713.1990788, "_step": 48}
{"Episode reward": 12.80000000000068, "Episode length": 872, "Policy Loss": -6.83868932723999, "Value Loss": 38.42129898071289, "_runtime": 3345.063272714615, "_timestamp": 1585600714.6961422, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.877030372619629, "Value Loss": 24.734834671020508, "_runtime": 3345.5495715141296, "_timestamp": 1585600715.182441, "_step": 50}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": -11.916038513183594, "Value Loss": 186.15538024902344, "_runtime": 3347.0812039375305, "_timestamp": 1585600716.7140734, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.739767074584961, "Value Loss": 108.5417251586914, "_runtime": 3348.622694015503, "_timestamp": 1585600718.2555635, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.931442260742188, "Value Loss": 10.465429306030273, "_runtime": 3350.10103225708, "_timestamp": 1585600719.7339017, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.938295364379883, "Value Loss": 10.566471099853516, "_runtime": 3351.660298347473, "_timestamp": 1585600721.2931678, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.838968276977539, "Value Loss": 2.0133960247039795, "_runtime": 3353.210392475128, "_timestamp": 1585600722.843262, "_step": 55}
{"Episode reward": -99.85716925263266, "Episode length": 999, "Policy Loss": -5.016022205352783, "Value Loss": 1.083489179611206, "_runtime": 3354.7346811294556, "_timestamp": 1585600724.3675506, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.253561496734619, "Value Loss": 0.8222276568412781, "_runtime": 3356.195292234421, "_timestamp": 1585600725.8281617, "_step": 57}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": -0.48372870683670044, "Value Loss": 12.309232711791992, "_runtime": 3357.5683488845825, "_timestamp": 1585600727.2012184, "_step": 58}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": 0.9331322312355042, "Value Loss": 15.3024263381958, "_runtime": 3359.108060359955, "_timestamp": 1585600728.7409298, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7419187426567078, "Value Loss": 0.8988851308822632, "_runtime": 3360.673200368881, "_timestamp": 1585600730.3060699, "_step": 60}
{"Episode reward": -99.8190126657472, "Episode length": 999, "Policy Loss": 1.6338622570037842, "Value Loss": 1.500557541847229, "_runtime": 3362.208998441696, "_timestamp": 1585600731.841868, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.232118606567383, "Value Loss": 2.3801259994506836, "_runtime": 3363.752781867981, "_timestamp": 1585600733.3856514, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8788557052612305, "Value Loss": 3.6501784324645996, "_runtime": 3364.4075927734375, "_timestamp": 1585600734.0404623, "_step": 63}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 6.9138264656066895, "Value Loss": 53.767784118652344, "_runtime": 3365.82267165184, "_timestamp": 1585600735.4555411, "_step": 64}
{"Episode reward": 9.600000000000861, "Episode length": 904, "Policy Loss": 4.197657585144043, "Value Loss": 21.30219268798828, "_runtime": 3366.8749616146088, "_timestamp": 1585600736.507831, "_step": 65}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 4.404172420501709, "Value Loss": 31.81670379638672, "_runtime": 3368.3691856861115, "_timestamp": 1585600738.0020552, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6143680214881897, "Value Loss": 1.1379952430725098, "_runtime": 3369.8132722377777, "_timestamp": 1585600739.4461417, "_step": 67}
{"Episode reward": 7.375534224511185, "Episode length": 927, "Policy Loss": 0.5829895734786987, "Value Loss": 13.224285125732422, "_runtime": 3371.3283388614655, "_timestamp": 1585600740.9612083, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2479000091552734, "Value Loss": 0.5648965239524841, "_runtime": 3372.871255874634, "_timestamp": 1585600742.5041254, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5048065185546875, "Value Loss": 0.5216840505599976, "_runtime": 3374.057590007782, "_timestamp": 1585600743.6904595, "_step": 70}
{"Episode reward": 23.800000000000054, "Episode length": 762, "Policy Loss": -3.490253210067749, "Value Loss": 13.973685264587402, "_runtime": 3375.170730829239, "_timestamp": 1585600744.8036003, "_step": 71}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": -4.1599440574646, "Value Loss": 19.57900619506836, "_runtime": 3376.084434747696, "_timestamp": 1585600745.7173042, "_step": 72}
{"Episode reward": 41.79999999999945, "Episode length": 582, "Policy Loss": -5.1923604011535645, "Value Loss": 27.076173782348633, "_runtime": 3377.5561470985413, "_timestamp": 1585600747.1890166, "_step": 73}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": -5.5934367179870605, "Value Loss": 15.91820240020752, "_runtime": 3379.07333612442, "_timestamp": 1585600748.7062056, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.330124378204346, "Value Loss": 3.2246828079223633, "_runtime": 3379.7974665164948, "_timestamp": 1585600749.430336, "_step": 75}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": -4.677109241485596, "Value Loss": 27.347854614257812, "_runtime": 3381.3915996551514, "_timestamp": 1585600751.0244691, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.749516010284424, "Value Loss": 3.130523204803467, "_runtime": 3382.9500617980957, "_timestamp": 1585600752.5829313, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.355906009674072, "Value Loss": 0.4687855839729309, "_runtime": 3384.4397628307343, "_timestamp": 1585600754.0726323, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.957024097442627, "Value Loss": 0.42701631784439087, "_runtime": 3385.7594170570374, "_timestamp": 1585600755.3922865, "_step": 79}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": -3.517786741256714, "Value Loss": 12.11287784576416, "_runtime": 3387.3121728897095, "_timestamp": 1585600756.9450424, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.185232639312744, "Value Loss": 0.2607137858867645, "_runtime": 3388.852021217346, "_timestamp": 1585600758.4848907, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.9031825065612793, "Value Loss": 1.3698171377182007, "_runtime": 3390.41357254982, "_timestamp": 1585600760.046442, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4673376083374023, "Value Loss": 0.265279620885849, "_runtime": 3391.9785585403442, "_timestamp": 1585600761.611428, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.134232997894287, "Value Loss": 0.38081225752830505, "_runtime": 3393.5349140167236, "_timestamp": 1585600763.1677835, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.765960931777954, "Value Loss": 0.1088676005601883, "_runtime": 3394.646348953247, "_timestamp": 1585600764.2792184, "_step": 85}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": -1.0814076662063599, "Value Loss": 14.07672119140625, "_runtime": 3396.2016208171844, "_timestamp": 1585600765.8344903, "_step": 86}
{"Episode reward": -99.80016424655774, "Episode length": 999, "Policy Loss": -2.1343941688537598, "Value Loss": 0.10695787519216537, "_runtime": 3396.820823907852, "_timestamp": 1585600766.4536934, "_step": 87}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 0.9367078542709351, "Value Loss": 26.467044830322266, "_runtime": 3398.3412380218506, "_timestamp": 1585600767.9741075, "_step": 88}
{"Episode reward": 1.00000000000135, "Episode length": 990, "Policy Loss": -0.7093870043754578, "Value Loss": 10.173748016357422, "_runtime": 3399.7649505138397, "_timestamp": 1585600769.39782, "_step": 89}
{"Episode reward": 9.600000000000861, "Episode length": 904, "Policy Loss": -0.35659468173980713, "Value Loss": 11.059772491455078, "_runtime": 3401.0539679527283, "_timestamp": 1585600770.6868374, "_step": 90}
{"Episode reward": 14.000682425499576, "Episode length": 860, "Policy Loss": -0.1937352418899536, "Value Loss": 11.60533618927002, "_runtime": 3401.557477235794, "_timestamp": 1585600771.1903467, "_step": 91}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 2.2692153453826904, "Value Loss": 33.925228118896484, "_runtime": 3403.119200229645, "_timestamp": 1585600772.7520697, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1536656618118286, "Value Loss": 0.03929358720779419, "_runtime": 3404.7068972587585, "_timestamp": 1585600774.3397667, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1123261451721191, "Value Loss": 0.06521426141262054, "_runtime": 3406.188019514084, "_timestamp": 1585600775.820889, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.100370168685913, "Value Loss": 0.09647950530052185, "_runtime": 3407.34100151062, "_timestamp": 1585600776.973871, "_step": 95}
{"Episode reward": 27.39999999999985, "Episode length": 726, "Policy Loss": 0.33153387904167175, "Value Loss": 13.787055969238281, "_runtime": 3408.3417625427246, "_timestamp": 1585600777.974632, "_step": 96}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.5293702483177185, "Value Loss": 15.775737762451172, "_runtime": 3409.8778595924377, "_timestamp": 1585600779.510729, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0285556316375732, "Value Loss": 0.1636321246623993, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503, 0.0011702030897140503]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.0011702794581651688, 0.004128292202949524, 0.009426863864064217, 0.01472543552517891, 0.020024007186293602, 0.025322578847408295, 0.030621150508522987, 0.03591972589492798, 0.04121829569339752, 0.046516865491867065, 0.05181543529033661, 0.05711401253938675, 0.06241258233785629, 0.06771115213632584, 0.07300972938537598, 0.07830829918384552, 0.08360686898231506, 0.0889054387807846, 0.09420400857925415, 0.09950258582830429, 0.10480115562677383, 0.11009972542524338, 0.11539830267429352, 0.12069687247276306, 0.1259954422712326, 0.13129401206970215, 0.1365925818681717, 0.14189115166664124, 0.14718973636627197, 0.15248830616474152, 0.15778687596321106, 0.1630854457616806, 0.16838401556015015, 0.1736825853586197, 0.17898115515708923, 0.18427972495555878, 0.18957829475402832, 0.19487687945365906, 0.2001754492521286, 0.20547401905059814, 0.2107725888490677, 0.21607115864753723, 0.22136972844600677, 0.22666829824447632, 0.23196688294410706, 0.2372654527425766, 0.24256402254104614, 0.24786259233951569, 0.25316116213798523, 0.25845974683761597, 0.2637583017349243, 0.26905688643455505, 0.2743554413318634, 0.27965402603149414, 0.2849525809288025, 0.2902511656284332, 0.29554975032806396, 0.3008483052253723, 0.30614688992500305, 0.3114454448223114, 0.31674402952194214, 0.3220425844192505, 0.3273411691188812, 0.3326397240161896, 0.3379383087158203]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-8.243571159027852e-08, 6.223928357940167e-05, 0.00012456100375857204, 0.0001868827239377424, 0.000249204458668828, 0.0003115261788479984, 0.00037384789902716875, 0.0004361696192063391, 0.0004984913393855095, 0.0005608130595646799, 0.0006231347797438502, 0.0006854564999230206, 0.000747778220102191, 0.0008100999402813613, 0.0008724216604605317, 0.0009347433806397021, 0.0009970651008188725, 0.0010593868792057037, 0.0011217085411772132, 0.0011840302031487226, 0.001246351981535554, 0.0013086737599223852, 0.0013709954218938947, 0.0014333170838654041, 0.0014956388622522354, 0.0015579606406390667, 0.0016202823026105762, 0.0016826039645820856, 0.001744925742968917, 0.0018072475213557482, 0.0018695691833272576, 0.001931890845298767, 0.0019942126236855984, 0.0020565344020724297, 0.002118856180459261, 0.0021811777260154486, 0.00224349950440228, 0.002305821282789111, 0.0023681428283452988, 0.00243046460673213, 0.0024927863851189613, 0.0025551081635057926, 0.002617429941892624, 0.0026797514874488115, 0.002742073265835643, 0.002804395044222474, 0.0028667165897786617, 0.002929038368165493, 0.0029913601465523243, 0.0030536819249391556, 0.003116003703325987, 0.0031783252488821745, 0.0032406470272690058, 0.003302968805655837, 0.0033652903512120247, 0.003427612129598856, 0.0034899339079856873, 0.0035522556863725185, 0.00361457746475935, 0.0036768990103155375, 0.0037392207887023687, 0.0038015425670892, 0.0038638641126453876, 0.003926185891032219, 0.00398850766941905]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [41.0, 15.0, 16.0, 1.0, 85.0, 2.0, 3.0, 1.0, 164.0, 4.0, 1.0, 1.0, 5.0, 3.0, 1.0, 9.0, 5.0, 5.0, 15.0, 12.0, 4.0, 8.0, 9.0, 9.0, 4.0, 3.0, 8.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 5.0, 3.0, 1.0, 3.0, 5.0, 2.0, 5.0, 3.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 5.0, 2.0, 0.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.0039526126347482204, -0.003467951435595751, -0.0029832900036126375, -0.002498628804460168, -0.0020139673724770546, -0.001529306173324585, -0.0010446449741721153, -0.000559983542189002, -7.53223430365324e-05, 0.0004093390889465809, 0.0008940002880990505, 0.0013786614872515202, 0.0018633226864039898, 0.0023479838855564594, 0.0028326455503702164, 0.003317306749522686, 0.0038019679486751556, 0.004286629613488913, 0.004771290812641382, 0.005255952011793852, 0.0057406132109463215, 0.006225274410098791, 0.006709935609251261, 0.00719459680840373, 0.0076792580075562, 0.008163919672369957, 0.008648579940199852, 0.009133242070674896, 0.00961790420114994, 0.010102564468979836, 0.01058722659945488, 0.011071886867284775, 0.011556548997759819, 0.012041209265589714, 0.012525871396064758, 0.013010531663894653, 0.013495193794369698, 0.013979854062199593, 0.014464516192674637, 0.014949176460504532, 0.015433838590979576, 0.01591849885880947, 0.016403160989284515, 0.01688782311975956, 0.017372483387589455, 0.0178571455180645, 0.018341805785894394, 0.018826467916369438, 0.019311128184199333, 0.019795790314674377, 0.020280450582504272, 0.020765112712979317, 0.02124977298080921, 0.021734435111284256, 0.0222190972417593, 0.022703757509589195, 0.02318841964006424, 0.023673079907894135, 0.02415774203836918, 0.024642402306199074, 0.025127064436674118, 0.025611724704504013, 0.026096386834979057, 0.026581047102808952, 0.027065709233283997]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [13.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.001359210698865354, -0.00015282595995813608, 0.001053558778949082, 0.0022599436342716217, 0.003466328140348196, 0.004672713112086058, 0.005879097618162632, 0.007085482124239206, 0.008291867561638355, 0.009498252533376217, 0.010704637505114079, 0.011911021545529366, 0.013117406517267227, 0.014323790557682514, 0.015530175529420376, 0.016736559569835663, 0.017942944541573524, 0.019149329513311386, 0.020355714485049248, 0.02156209945678711, 0.02276848442852497, 0.023974867537617683, 0.025181252509355545, 0.026387637481093407, 0.02759402245283127, 0.02880040742456913, 0.030006790533661842, 0.031213177368044853, 0.032419562339782715, 0.033625949174165726, 0.03483233228325844, 0.03603871911764145, 0.03724510222673416, 0.038451485335826874, 0.039657872170209885, 0.0408642552793026, 0.04207064211368561, 0.04327702522277832, 0.04448341205716133, 0.045689795166254044, 0.046896182000637054, 0.04810256510972977, 0.04930894821882248, 0.05051533505320549, 0.0517217181622982, 0.05292810499668121, 0.054134488105773926, 0.05534087494015694, 0.05654725804924965, 0.05775364115834236, 0.05896002799272537, 0.060166411101818085, 0.0613727942109108, 0.0625791847705841, 0.06378556787967682, 0.06499195098876953, 0.06619833409786224, 0.06740471720695496, 0.06861110776662827, 0.06981749087572098, 0.07102387398481369, 0.0722302570939064, 0.07343664765357971, 0.07464303076267242, 0.07584941387176514]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 25.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.056563686579465866, -0.05505958944559097, -0.05355548858642578, -0.05205138772726059, -0.050547290593385696, -0.0490431934595108, -0.04753909260034561, -0.04603499174118042, -0.04453089460730553, -0.043026797473430634, -0.04152269661426544, -0.04001859575510025, -0.03851449862122536, -0.037010401487350464, -0.03550630062818527, -0.03400219976902008, -0.03249810263514519, -0.030994003638625145, -0.029489904642105103, -0.02798580564558506, -0.026481706649065018, -0.024977605789899826, -0.023473508656024933, -0.02196941152215004, -0.020465310662984848, -0.018961209803819656, -0.017457112669944763, -0.01595301553606987, -0.014448914676904678, -0.012944813817739487, -0.011440716683864594, -0.0099366195499897, -0.008432518690824509, -0.006928417831659317, -0.005424320697784424, -0.003920223563909531, -0.002416122704744339, -0.0009120218455791473, 0.0005920752882957458, 0.002096172422170639, 0.0036002732813358307, 0.005104374140501022, 0.006608474999666214, 0.008112568408250809, 0.009616669267416, 0.011120770126581192, 0.012624863535165787, 0.014128964394330978, 0.01563306525349617, 0.01713716611266136, 0.018641266971826553, 0.020145360380411148, 0.02164946123957634, 0.02315356209874153, 0.024657655507326126, 0.026161756366491318, 0.02766585722565651, 0.0291699580848217, 0.030674058943986893, 0.03217815235257149, 0.03368225321173668, 0.03518635407090187, 0.036690447479486465, 0.03819454833865166, 0.03969864919781685]}, "_runtime": 3410.755898475647, "_timestamp": 1585600780.388768, "_step": 98}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 0.7492577433586121, "Value Loss": 17.694713592529297, "_runtime": 3412.3036036491394, "_timestamp": 1585600781.9364731, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2079795598983765, "Value Loss": 0.2010825127363205, "_runtime": 3413.8561596870422, "_timestamp": 1585600783.4890292, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2847367525100708, "Value Loss": 0.06594937294721603, "_runtime": 3415.373749256134, "_timestamp": 1585600785.0066187, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3669320344924927, "Value Loss": 0.0407966785132885, "_runtime": 3416.3278279304504, "_timestamp": 1585600785.9606974, "_step": 102}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 0.21976420283317566, "Value Loss": 16.27461814880371, "_runtime": 3417.881579875946, "_timestamp": 1585600787.5144494, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4585682153701782, "Value Loss": 0.12548139691352844, "_runtime": 3419.443591594696, "_timestamp": 1585600789.076461, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5185835361480713, "Value Loss": 0.05487190559506416, "_runtime": 3420.4341111183167, "_timestamp": 1585600790.0669806, "_step": 105}
{"Episode reward": 36.6695563316339, "Episode length": 634, "Policy Loss": 0.14098677039146423, "Value Loss": 15.564497947692871, "_runtime": 3421.9824545383453, "_timestamp": 1585600791.615324, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.631323218345642, "Value Loss": 0.043404217809438705, "_runtime": 3423.5453221797943, "_timestamp": 1585600793.1781917, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6836122274398804, "Value Loss": 0.05899490788578987, "_runtime": 3425.0585839748383, "_timestamp": 1585600794.6914535, "_step": 108}
{"Episode reward": 0.8000000000013614, "Episode length": 992, "Policy Loss": -0.7643997669219971, "Value Loss": 9.998723983764648, "_runtime": 3426.245379924774, "_timestamp": 1585600795.8782494, "_step": 109}
{"Episode reward": 23.600000000000065, "Episode length": 764, "Policy Loss": -0.48827865719795227, "Value Loss": 12.943230628967285, "_runtime": 3427.844141960144, "_timestamp": 1585600797.4770114, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7930610179901123, "Value Loss": 0.07249483466148376, "_runtime": 3428.449238538742, "_timestamp": 1585600798.082108, "_step": 111}
{"Episode reward": 63.09999999999975, "Episode length": 369, "Policy Loss": 0.7828157544136047, "Value Loss": 26.489437103271484, "_runtime": 3429.982533454895, "_timestamp": 1585600799.615403, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.884889006614685, "Value Loss": 0.053420379757881165, "_runtime": 3431.545923233032, "_timestamp": 1585600801.1787927, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9076478481292725, "Value Loss": 0.07260730117559433, "_runtime": 3433.0267629623413, "_timestamp": 1585600802.6596324, "_step": 114}
{"Episode reward": -99.80750353336194, "Episode length": 999, "Policy Loss": -1.9586962461471558, "Value Loss": 0.05224153399467468, "_runtime": 3434.592832326889, "_timestamp": 1585600804.2257018, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9877874851226807, "Value Loss": 0.05089781805872917, "_runtime": 3436.0185623168945, "_timestamp": 1585600805.6514318, "_step": 116}
{"Episode reward": 9.200000000000884, "Episode length": 908, "Policy Loss": -0.8693891167640686, "Value Loss": 10.834009170532227, "_runtime": 3437.5616018772125, "_timestamp": 1585600807.1944714, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.029839038848877, "Value Loss": 0.05402486398816109, "_runtime": 3439.1357836723328, "_timestamp": 1585600808.7686532, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0751078128814697, "Value Loss": 0.23611345887184143, "_runtime": 3440.7108938694, "_timestamp": 1585600810.3437634, "_step": 119}
{"Episode reward": -99.84477694034437, "Episode length": 999, "Policy Loss": -2.024217128753662, "Value Loss": 0.13765692710876465, "_runtime": 3442.2683436870575, "_timestamp": 1585600811.9012132, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.996829628944397, "Value Loss": 0.07857278734445572, "_runtime": 3443.829795360565, "_timestamp": 1585600813.4626648, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9637631177902222, "Value Loss": 0.08392270654439926, "_runtime": 3445.407354593277, "_timestamp": 1585600815.040224, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9124130010604858, "Value Loss": 0.08382169157266617, "_runtime": 3446.9031312465668, "_timestamp": 1585600816.5360007, "_step": 123}
{"Episode reward": 3.7000000000011966, "Episode length": 963, "Policy Loss": -0.872648298740387, "Value Loss": 10.208967208862305, "_runtime": 3448.476579427719, "_timestamp": 1585600818.109449, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8159327507019043, "Value Loss": 0.038962364196777344, "_runtime": 3449.9197986125946, "_timestamp": 1585600819.552668, "_step": 125}
{"Episode reward": 7.8000000000009635, "Episode length": 922, "Policy Loss": -0.5737897157669067, "Value Loss": 10.651944160461426, "_runtime": 3450.9505879879, "_timestamp": 1585600820.5834575, "_step": 126}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": -0.23745355010032654, "Value Loss": 15.602229118347168, "_runtime": 3451.5854053497314, "_timestamp": 1585600821.2182748, "_step": 127}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 0.7343484163284302, "Value Loss": 25.418664932250977, "_runtime": 3452.1626613140106, "_timestamp": 1585600821.7955308, "_step": 128}
{"Episode reward": 64.29999999999977, "Episode length": 357, "Policy Loss": 1.1578664779663086, "Value Loss": 27.32065200805664, "_runtime": 3452.6240932941437, "_timestamp": 1585600822.2569628, "_step": 129}
{"Episode reward": 70.89999999999986, "Episode length": 291, "Policy Loss": 1.6924372911453247, "Value Loss": 33.519168853759766, "_runtime": 3453.7413511276245, "_timestamp": 1585600823.3742206, "_step": 130}
{"Episode reward": 25.59999999999995, "Episode length": 744, "Policy Loss": -0.16922666132450104, "Value Loss": 13.117463111877441, "_runtime": 3455.129908323288, "_timestamp": 1585600824.7627778, "_step": 131}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": -0.6005833148956299, "Value Loss": 10.648807525634766, "_runtime": 3456.56413769722, "_timestamp": 1585600826.1970072, "_step": 132}
{"Episode reward": 3.800000000001191, "Episode length": 962, "Policy Loss": -0.6333352327346802, "Value Loss": 10.220185279846191, "_runtime": 3457.6955506801605, "_timestamp": 1585600827.3284202, "_step": 133}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": -0.3192635476589203, "Value Loss": 13.36954402923584, "_runtime": 3458.769321203232, "_timestamp": 1585600828.4021907, "_step": 134}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": -0.2730596363544464, "Value Loss": 14.3467435836792, "_runtime": 3460.266583919525, "_timestamp": 1585600829.8994534, "_step": 135}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": -0.6305713057518005, "Value Loss": 10.105305671691895, "_runtime": 3461.8046538829803, "_timestamp": 1585600831.4375234, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5419012308120728, "Value Loss": 0.04987683519721031, "_runtime": 3462.7820036411285, "_timestamp": 1585600832.4148731, "_step": 137}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": 0.05924716591835022, "Value Loss": 15.457880973815918, "_runtime": 3464.3200073242188, "_timestamp": 1585600833.9528768, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5218545198440552, "Value Loss": 0.09130337834358215, "_runtime": 3465.6871449947357, "_timestamp": 1585600835.3200145, "_step": 139}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": -0.4132278263568878, "Value Loss": 11.38486385345459, "_runtime": 3467.2113568782806, "_timestamp": 1585600836.8442264, "_step": 140}
{"Episode reward": -99.86389067172864, "Episode length": 999, "Policy Loss": -1.4318400621414185, "Value Loss": 0.049121301621198654, "_runtime": 3468.6517827510834, "_timestamp": 1585600838.2846522, "_step": 141}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": -0.3921174108982086, "Value Loss": 10.496818542480469, "_runtime": 3469.866559743881, "_timestamp": 1585600839.4994292, "_step": 142}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": -0.15314441919326782, "Value Loss": 12.629332542419434, "_runtime": 3471.406963825226, "_timestamp": 1585600841.0398333, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.333196759223938, "Value Loss": 0.039461322128772736, "_runtime": 3472.964264392853, "_timestamp": 1585600842.5971339, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2906595468521118, "Value Loss": 0.030185947194695473, "_runtime": 3473.860235452652, "_timestamp": 1585600843.493105, "_step": 145}
{"Episode reward": 43.19999999999947, "Episode length": 568, "Policy Loss": 0.404622882604599, "Value Loss": 17.21860122680664, "_runtime": 3474.6549019813538, "_timestamp": 1585600844.2877715, "_step": 146}
{"Episode reward": 52.699999999999605, "Episode length": 473, "Policy Loss": 0.7157572507858276, "Value Loss": 20.639156341552734, "_runtime": 3476.2072257995605, "_timestamp": 1585600845.8400953, "_step": 147}
{"Episode reward": -99.841605019568, "Episode length": 999, "Policy Loss": -1.3392181396484375, "Value Loss": 0.2315848171710968, "_runtime": 3477.7262206077576, "_timestamp": 1585600847.35909, "_step": 148}
{"Episode reward": -99.82490243911603, "Episode length": 999, "Policy Loss": -1.248744249343872, "Value Loss": 0.029135195538401604, "_runtime": 3479.1506435871124, "_timestamp": 1585600848.783513, "_step": 149}
{"Episode reward": 5.300000000001106, "Episode length": 947, "Policy Loss": -0.23821532726287842, "Value Loss": 10.341046333312988, "_runtime": 3480.259327173233, "_timestamp": 1585600849.8921967, "_step": 150}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": 0.4074975252151489, "Value Loss": 13.803871154785156, "_runtime": 3481.814457178116, "_timestamp": 1585600851.4473267, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1400253772735596, "Value Loss": 0.037804681807756424, "_runtime": 3483.363850593567, "_timestamp": 1585600852.99672, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134584903717041, "Value Loss": 0.019718846306204796, "_runtime": 3484.888814687729, "_timestamp": 1585600854.5216842, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1216024160385132, "Value Loss": 0.08530967682600021, "_runtime": 3485.5016193389893, "_timestamp": 1585600855.1344888, "_step": 154}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 1.390316367149353, "Value Loss": 26.186283111572266, "_runtime": 3486.625469684601, "_timestamp": 1585600856.2583392, "_step": 155}
{"Episode reward": 26.899999999999878, "Episode length": 731, "Policy Loss": 0.2602809965610504, "Value Loss": 13.236139297485352, "_runtime": 3488.1731781959534, "_timestamp": 1585600857.8060477, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1014935970306396, "Value Loss": 0.018105454742908478, "_runtime": 3489.6602478027344, "_timestamp": 1585600859.2931173, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1078304052352905, "Value Loss": 0.015813371166586876, "_runtime": 3491.1853959560394, "_timestamp": 1585600860.8182654, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1224876642227173, "Value Loss": 0.05059653893113136, "_runtime": 3492.11719417572, "_timestamp": 1585600861.7500637, "_step": 159}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": 0.433574914932251, "Value Loss": 16.572479248046875, "_runtime": 3493.6517918109894, "_timestamp": 1585600863.2846613, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.092400312423706, "Value Loss": 0.028188105672597885, "_runtime": 3495.2084171772003, "_timestamp": 1585600864.8412867, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1002620458602905, "Value Loss": 0.0913207158446312, "_runtime": 3496.718202829361, "_timestamp": 1585600866.3510723, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0688533782958984, "Value Loss": 0.0520506389439106, "_runtime": 3497.3815608024597, "_timestamp": 1585600867.0144303, "_step": 163}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 1.359915018081665, "Value Loss": 25.34307098388672, "_runtime": 3498.654619216919, "_timestamp": 1585600868.2874887, "_step": 164}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": 0.18262365460395813, "Value Loss": 11.944547653198242, "_runtime": 3499.0630061626434, "_timestamp": 1585600868.6958756, "_step": 165}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": 3.256013870239258, "Value Loss": 42.053279876708984, "_runtime": 3500.464456796646, "_timestamp": 1585600870.0973263, "_step": 166}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": -0.10788638889789581, "Value Loss": 10.389945983886719, "_runtime": 3501.99738240242, "_timestamp": 1585600871.630252, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1870346069335938, "Value Loss": 0.015953009948134422, "_runtime": 3502.628238916397, "_timestamp": 1585600872.2611084, "_step": 168}
{"Episode reward": 57.39999999999967, "Episode length": 426, "Policy Loss": 1.04569673538208, "Value Loss": 22.790132522583008, "_runtime": 3504.15953540802, "_timestamp": 1585600873.792405, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3199971914291382, "Value Loss": 0.0711522027850151, "_runtime": 3505.7111003398895, "_timestamp": 1585600875.3439698, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.430725336074829, "Value Loss": 0.02560071088373661, "_runtime": 3507.192704439163, "_timestamp": 1585600876.825574, "_step": 171}
{"Episode reward": -99.80444946288922, "Episode length": 999, "Policy Loss": -1.5110738277435303, "Value Loss": 0.18747703731060028, "_runtime": 3507.707709789276, "_timestamp": 1585600877.3405793, "_step": 172}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 2.5530436038970947, "Value Loss": 31.533206939697266, "_runtime": 3509.2243642807007, "_timestamp": 1585600878.8572338, "_step": 173}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": -0.5932735800743103, "Value Loss": 9.811110496520996, "_runtime": 3510.1493134498596, "_timestamp": 1585600879.782183, "_step": 174}
{"Episode reward": 39.78203697204532, "Episode length": 603, "Policy Loss": 0.5747597813606262, "Value Loss": 16.18976593017578, "_runtime": 3511.641695022583, "_timestamp": 1585600881.2745645, "_step": 175}
{"Episode reward": -99.802103066443, "Episode length": 999, "Policy Loss": -1.555803894996643, "Value Loss": 0.04643502086400986, "_runtime": 3513.200058221817, "_timestamp": 1585600882.8329277, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5501066446304321, "Value Loss": 0.03140956163406372, "_runtime": 3513.774979829788, "_timestamp": 1585600883.4078493, "_step": 177}
{"Episode reward": 63.39999999999976, "Episode length": 366, "Policy Loss": 0.9801528453826904, "Value Loss": 26.431283950805664, "_runtime": 3514.8255038261414, "_timestamp": 1585600884.4583733, "_step": 178}
{"Episode reward": 32.399999999999565, "Episode length": 676, "Policy Loss": -0.18053112924098969, "Value Loss": 14.31192398071289, "_runtime": 3516.4002797603607, "_timestamp": 1585600886.0331492, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5154497623443604, "Value Loss": 0.05656089261174202, "_runtime": 3517.452248096466, "_timestamp": 1585600887.0851176, "_step": 180}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": -0.24936076998710632, "Value Loss": 13.754667282104492, "_runtime": 3518.9614226818085, "_timestamp": 1585600888.5942922, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5679672956466675, "Value Loss": 0.30000215768814087, "_runtime": 3520.5197105407715, "_timestamp": 1585600890.15258, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.444645881652832, "Value Loss": 0.047752998769283295, "_runtime": 3521.4123685359955, "_timestamp": 1585600891.045238, "_step": 183}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.25172972679138184, "Value Loss": 17.364221572875977, "_runtime": 3522.950029373169, "_timestamp": 1585600892.5828989, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3522193431854248, "Value Loss": 0.033770449459552765, "_runtime": 3524.5193452835083, "_timestamp": 1585600894.1522148, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3112295866012573, "Value Loss": 0.03041098453104496, "_runtime": 3526.0237998962402, "_timestamp": 1585600895.6566694, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.271005630493164, "Value Loss": 0.05483138933777809, "_runtime": 3527.3246641159058, "_timestamp": 1585600896.9575336, "_step": 187}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": -0.09321442246437073, "Value Loss": 11.526464462280273, "_runtime": 3528.8793013095856, "_timestamp": 1585600898.5121708, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2083700895309448, "Value Loss": 0.14423218369483948, "_runtime": 3530.426835536957, "_timestamp": 1585600900.059705, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0774589776992798, "Value Loss": 0.029490450397133827, "_runtime": 3531.889650583267, "_timestamp": 1585600901.52252, "_step": 190}
{"Episode reward": 5.704870837927942, "Episode length": 943, "Policy Loss": -0.04959932342171669, "Value Loss": 10.330889701843262, "_runtime": 3533.4601833820343, "_timestamp": 1585600903.0930529, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9243953824043274, "Value Loss": 0.021451357752084732, "_runtime": 3535.0257523059845, "_timestamp": 1585600904.6586218, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8484126329421997, "Value Loss": 0.01367331575602293, "_runtime": 3536.040295124054, "_timestamp": 1585600905.6731646, "_step": 193}
{"Episode reward": 35.79999999999937, "Episode length": 642, "Policy Loss": 0.6393107175827026, "Value Loss": 14.957963943481445, "_runtime": 3537.6141736507416, "_timestamp": 1585600907.2470431, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7320182919502258, "Value Loss": 0.007643958553671837, "_runtime": 3539.1743683815002, "_timestamp": 1585600908.8072379, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6934398412704468, "Value Loss": 0.033687837421894073, "_runtime": 3539.9038186073303, "_timestamp": 1585600909.536688, "_step": 196}
{"Episode reward": 53.79999999999962, "Episode length": 462, "Policy Loss": 1.385485053062439, "Value Loss": 21.055259704589844, "_runtime": 3541.478355407715, "_timestamp": 1585600911.111225, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.629870593547821, "Value Loss": 0.01021882425993681, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934, -0.015485710464417934]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-6.417021751403809, -6.316403865814209, -6.215785980224609, -6.11516809463501, -6.01455020904541, -5.9139323234558105, -5.813314437866211, -5.712696552276611, -5.612078666687012, -5.511460781097412, -5.4108428955078125, -5.310225009918213, -5.209607124328613, -5.1089887619018555, -5.008371353149414, -4.907752990722656, -4.807135581970215, -4.706517219543457, -4.605899810791016, -4.505281448364258, -4.404664039611816, -4.304045677185059, -4.203428268432617, -4.102809906005859, -4.00219202041626, -3.90157413482666, -3.8009562492370605, -3.700338363647461, -3.5997204780578613, -3.4991025924682617, -3.398484706878662, -3.2978668212890625, -3.197248935699463, -3.0966310501098633, -2.9960131645202637, -2.895395278930664, -2.7947773933410645, -2.694159507751465, -2.5935416221618652, -2.4929237365722656, -2.392305850982666, -2.2916879653930664, -2.191070079803467, -2.090452194213867, -1.9898343086242676, -1.889216423034668, -1.7885985374450684, -1.6879806518554688, -1.587362289428711, -1.4867444038391113, -1.3861265182495117, -1.285508632659912, -1.1848907470703125, -1.084272861480713, -0.9836549758911133, -0.8830370903015137, -0.7824192047119141, -0.6818013191223145, -0.5811834335327148, -0.48056554794311523, -0.3799476623535156, -0.279329776763916, -0.1787118911743164, -0.0780940055847168, 0.022523880004882812]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0], "bins": [-0.05279288440942764, -0.05194675922393799, -0.051100634038448334, -0.05025450885295868, -0.049408383667469025, -0.04856225475668907, -0.04771612957119942, -0.04687000438570976, -0.04602387920022011, -0.045177754014730453, -0.0443316288292408, -0.043485499918460846, -0.04263937473297119, -0.04179324954748154, -0.04094712436199188, -0.04010099917650223, -0.03925487399101257, -0.03840874880552292, -0.037562623620033264, -0.03671649843454361, -0.035870373249053955, -0.0350242480635643, -0.03417811915278435, -0.03333199396729469, -0.03248586878180504, -0.031639743596315384, -0.03079361841082573, -0.029947491362690926, -0.02910136617720127, -0.028255240991711617, -0.027409113943576813, -0.026562988758087158, -0.025716863572597504, -0.02487073838710785, -0.024024613201618195, -0.02317848615348339, -0.022332360967993736, -0.021486233919858932, -0.020640108734369278, -0.019793983548879623, -0.01894785836338997, -0.018101733177900314, -0.01725560799241066, -0.016409482806921005, -0.015563353896141052, -0.014717228710651398, -0.013871103525161743, -0.013024978339672089, -0.012178853154182434, -0.01133272796869278, -0.010486602783203125, -0.00964047759771347, -0.008794352412223816, -0.007948223501443863, -0.007102098315954208, -0.006255973130464554, -0.005409847944974899, -0.004563722759485245, -0.00371759757399559, -0.0028714723885059357, -0.0020253434777259827, -0.0011792182922363281, -0.0003330931067466736, 0.000513032078742981, 0.0013591572642326355]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 5.0, 5.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 2.0, 3.0, 1.0, 5.0, 2.0, 5.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 291.0, 29.0, 0.0, 0.0, 0.0, 22.0, 34.0, 44.0, 14.0], "bins": [-0.41677752137184143, -0.40926188230514526, -0.4017462730407715, -0.3942306339740753, -0.38671499490737915, -0.37919938564300537, -0.3716837465763092, -0.36416810750961304, -0.35665246844291687, -0.3491368591785431, -0.3416212201118469, -0.33410558104515076, -0.3265899419784546, -0.3190743327140808, -0.31155869364738464, -0.3040430545806885, -0.2965274453163147, -0.28901180624961853, -0.28149616718292236, -0.2739805579185486, -0.2664649188518524, -0.25894927978515625, -0.25143367052078247, -0.2439180314540863, -0.23640239238739014, -0.22888676822185516, -0.221371129155159, -0.21385550498962402, -0.20633988082408905, -0.19882424175739288, -0.1913086175918579, -0.18379297852516174, -0.17627735435962677, -0.1687617301940918, -0.16124609112739563, -0.15373045206069946, -0.14621484279632568, -0.13869920372962952, -0.13118356466293335, -0.12366795539855957, -0.1161523163318634, -0.10863667726516724, -0.10112103819847107, -0.09360542893409729, -0.08608978986740112, -0.07857415080070496, -0.07105854153633118, -0.06354290246963501, -0.05602726340293884, -0.048511654138565063, -0.040996015071868896, -0.03348037600517273, -0.025964736938476562, -0.018449127674102783, -0.010933488607406616, -0.0034178495407104492, 0.00409775972366333, 0.011613398790359497, 0.019129037857055664, 0.026644647121429443, 0.03416028618812561, 0.04167592525482178, 0.049191564321517944, 0.056707173585891724, 0.06422281265258789]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 15.0], "bins": [-1.1857932806015015, -1.1670223474502563, -1.1482512950897217, -1.1294803619384766, -1.1107094287872314, -1.0919383764266968, -1.0731674432754517, -1.054396390914917, -1.0356254577636719, -1.0168545246124268, -0.9980835318565369, -0.979312539100647, -0.9605416059494019, -0.941770613193512, -0.9229996204376221, -0.9042286276817322, -0.8854576349258423, -0.8666867017745972, -0.8479157090187073, -0.8291447162628174, -0.8103737831115723, -0.7916027903556824, -0.7728317975997925, -0.7540608644485474, -0.7352898716926575, -0.7165188789367676, -0.6977479457855225, -0.6789769530296326, -0.6602059602737427, -0.6414349675178528, -0.6226639747619629, -0.6038930416107178, -0.5851220488548279, -0.566351056098938, -0.5475801229476929, -0.528809130191803, -0.5100381374359131, -0.4912671446800232, -0.4724962115287781, -0.4537252187728882, -0.4349542260169983, -0.4161832928657532, -0.3974123001098633, -0.3786413073539734, -0.3598703145980835, -0.3410993814468384, -0.3223283886909485, -0.3035573959350586, -0.2847864627838135, -0.2660154700279236, -0.2472444772720337, -0.2284734845161438, -0.20970255136489868, -0.1909315586090088, -0.17216062545776367, -0.153389573097229, -0.1346186399459839, -0.11584770679473877, -0.0970766544342041, -0.07830572128295898, -0.059534668922424316, -0.0407637357711792, -0.021992802619934082, -0.003221750259399414, 0.015549182891845703]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 2.0, 1.0, 3.0, 1.0, 15.0, 15.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-0.05437520518898964, -0.04535224288702011, -0.036329276859760284, -0.027306314557790756, -0.018283352255821228, -0.0092603899538517, -0.00023742392659187317, 0.008785534650087357, 0.017808500677347183, 0.02683146670460701, 0.03585442528128624, 0.044877391308546066, 0.05390035733580589, 0.06292331218719482, 0.07194627821445465, 0.08096924424171448, 0.0899922102689743, 0.09901517629623413, 0.10803814232349396, 0.11706109344959259, 0.12608405947685242, 0.13510702550411224, 0.14412999153137207, 0.1531529575586319, 0.16217592358589172, 0.17119887471199036, 0.18022184073925018, 0.18924480676651, 0.19826775789260864, 0.20729073882102966, 0.2163136899471283, 0.22533667087554932, 0.23435962200164795, 0.24338257312774658, 0.2524055540561676, 0.26142850518226624, 0.27045148611068726, 0.2794744372367859, 0.2884973883628845, 0.29752036929130554, 0.3065433204174042, 0.3155663013458252, 0.32458925247192383, 0.33361220359802246, 0.3426351845264435, 0.3516581356525421, 0.36068111658096313, 0.36970406770706177, 0.3787270486354828, 0.3877499997615814, 0.39677295088768005, 0.4057959318161011, 0.4148188829421997, 0.4238418638706207, 0.43286481499671936, 0.441887766122818, 0.4509107172489166, 0.45993372797966003, 0.46895667910575867, 0.4779796302318573, 0.48700258135795593, 0.49602553248405457, 0.5050485134124756, 0.5140714645385742, 0.5230944156646729]}, "_runtime": 3542.3594653606415, "_timestamp": 1585600911.9923348, "_step": 198}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 1.1453373432159424, "Value Loss": 17.74248504638672, "_runtime": 3543.878851890564, "_timestamp": 1585600913.5117214, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6603493690490723, "Value Loss": 0.015785671770572662, "_runtime": 3545.4832565784454, "_timestamp": 1585600915.116126, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6768890023231506, "Value Loss": 0.011468231678009033, "_runtime": 3547.002449274063, "_timestamp": 1585600916.6353188, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7134267687797546, "Value Loss": 0.03227323666214943, "_runtime": 3548.5662002563477, "_timestamp": 1585600918.1990697, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7063692808151245, "Value Loss": 0.019132100045681, "_runtime": 3550.1407701969147, "_timestamp": 1585600919.7736397, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7129232883453369, "Value Loss": 0.020128779113292694, "_runtime": 3551.7016491889954, "_timestamp": 1585600921.3345187, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7066822052001953, "Value Loss": 0.016716210171580315, "_runtime": 3553.272338628769, "_timestamp": 1585600922.905208, "_step": 205}
{"Episode reward": -99.86769239902357, "Episode length": 999, "Policy Loss": -0.689121425151825, "Value Loss": 0.015283423475921154, "_runtime": 3554.8412346839905, "_timestamp": 1585600924.4741042, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6725423336029053, "Value Loss": 0.02027261070907116, "_runtime": 3555.947201013565, "_timestamp": 1585600925.5800705, "_step": 207}
{"Episode reward": 29.9999999999997, "Episode length": 700, "Policy Loss": 0.7272140979766846, "Value Loss": 13.889281272888184, "_runtime": 3557.298014163971, "_timestamp": 1585600926.9308836, "_step": 208}
{"Episode reward": 13.000000000000668, "Episode length": 870, "Policy Loss": 0.4912036061286926, "Value Loss": 11.224979400634766, "_runtime": 3558.412624359131, "_timestamp": 1585600928.0454938, "_step": 209}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.6144536137580872, "Value Loss": 13.889288902282715, "_runtime": 3559.268481492996, "_timestamp": 1585600928.901351, "_step": 210}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 1.0291776657104492, "Value Loss": 17.947269439697266, "_runtime": 3560.8075659275055, "_timestamp": 1585600930.4404354, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7623966336250305, "Value Loss": 0.011037101969122887, "_runtime": 3561.1920216083527, "_timestamp": 1585600930.824891, "_step": 212}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": 3.331784725189209, "Value Loss": 43.38219451904297, "_runtime": 3562.7279722690582, "_timestamp": 1585600932.3608418, "_step": 213}
{"Episode reward": -99.8005728006349, "Episode length": 999, "Policy Loss": -0.9174326062202454, "Value Loss": 0.011017180979251862, "_runtime": 3564.2903683185577, "_timestamp": 1585600933.9232378, "_step": 214}
{"Episode reward": -99.80272378921369, "Episode length": 999, "Policy Loss": -1.031049132347107, "Value Loss": 0.016557417809963226, "_runtime": 3565.773009777069, "_timestamp": 1585600935.4058793, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1386466026306152, "Value Loss": 0.048461467027664185, "_runtime": 3567.3430886268616, "_timestamp": 1585600936.975958, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.183624029159546, "Value Loss": 0.021207574754953384, "_runtime": 3568.3696732521057, "_timestamp": 1585600938.0025427, "_step": 217}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.2357952892780304, "Value Loss": 15.41328239440918, "_runtime": 3569.8762028217316, "_timestamp": 1585600939.5090723, "_step": 218}
{"Episode reward": 1.7000000000013102, "Episode length": 983, "Policy Loss": -0.4130880534648895, "Value Loss": 9.862751960754395, "_runtime": 3570.7112679481506, "_timestamp": 1585600940.3441374, "_step": 219}
{"Episode reward": 48.19999999999954, "Episode length": 518, "Policy Loss": 0.40679246187210083, "Value Loss": 18.51664161682129, "_runtime": 3572.2616271972656, "_timestamp": 1585600941.8944967, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3910493850708008, "Value Loss": 0.022023610770702362, "_runtime": 3573.804484128952, "_timestamp": 1585600943.4373536, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4300278425216675, "Value Loss": 0.050721392035484314, "_runtime": 3575.322184085846, "_timestamp": 1585600944.9550536, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.437028169631958, "Value Loss": 0.047782715409994125, "_runtime": 3576.003728866577, "_timestamp": 1585600945.6365983, "_step": 223}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 0.7468008995056152, "Value Loss": 23.26378631591797, "_runtime": 3577.028783082962, "_timestamp": 1585600946.6616526, "_step": 224}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": -0.08188547939062119, "Value Loss": 14.86582088470459, "_runtime": 3577.9970388412476, "_timestamp": 1585600947.6299083, "_step": 225}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 0.09471932053565979, "Value Loss": 15.590645790100098, "_runtime": 3578.523805141449, "_timestamp": 1585600948.1566746, "_step": 226}
{"Episode reward": 66.19999999999979, "Episode length": 338, "Policy Loss": 1.1465297937393188, "Value Loss": 29.011138916015625, "_runtime": 3579.614135980606, "_timestamp": 1585600949.2470055, "_step": 227}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": -0.19213466346263885, "Value Loss": 13.658617973327637, "_runtime": 3581.1475942134857, "_timestamp": 1585600950.7804637, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.330548882484436, "Value Loss": 0.07405920326709747, "_runtime": 3582.64027094841, "_timestamp": 1585600952.2731404, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2425717115402222, "Value Loss": 0.03240061178803444, "_runtime": 3584.171542406082, "_timestamp": 1585600953.804412, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1709774732589722, "Value Loss": 0.052976347506046295, "_runtime": 3585.7337353229523, "_timestamp": 1585600955.3666048, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0675629377365112, "Value Loss": 0.030857326462864876, "_runtime": 3586.42587184906, "_timestamp": 1585600956.0587413, "_step": 232}
{"Episode reward": 55.99999999999965, "Episode length": 440, "Policy Loss": 1.1889803409576416, "Value Loss": 22.026330947875977, "_runtime": 3587.551013946533, "_timestamp": 1585600957.1838834, "_step": 233}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": 0.3120955228805542, "Value Loss": 13.608677864074707, "_runtime": 3588.3170104026794, "_timestamp": 1585600957.94988, "_step": 234}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 1.0913891792297363, "Value Loss": 20.442474365234375, "_runtime": 3589.031266450882, "_timestamp": 1585600958.664136, "_step": 235}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.2269248962402344, "Value Loss": 20.782930374145508, "_runtime": 3590.5690190792084, "_timestamp": 1585600960.2018886, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8453250527381897, "Value Loss": 0.038179539144039154, "_runtime": 3591.0741777420044, "_timestamp": 1585600960.7070472, "_step": 237}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 1.969017744064331, "Value Loss": 30.331472396850586, "_runtime": 3592.147522211075, "_timestamp": 1585600961.7803917, "_step": 238}
{"Episode reward": 28.59999999999978, "Episode length": 714, "Policy Loss": 0.5027021765708923, "Value Loss": 13.49177074432373, "_runtime": 3593.7256078720093, "_timestamp": 1585600963.3584774, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8718582391738892, "Value Loss": 0.040313638746738434, "_runtime": 3595.2182836532593, "_timestamp": 1585600964.8511531, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.879080593585968, "Value Loss": 0.009462797082960606, "_runtime": 3596.750657081604, "_timestamp": 1585600966.3835266, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.884684681892395, "Value Loss": 0.011933227069675922, "_runtime": 3598.317889690399, "_timestamp": 1585600967.9507592, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9172894954681396, "Value Loss": 0.0816924199461937, "_runtime": 3599.611036300659, "_timestamp": 1585600969.2439058, "_step": 243}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.2048049420118332, "Value Loss": 11.518842697143555, "_runtime": 3601.162887573242, "_timestamp": 1585600970.795757, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8635349869728088, "Value Loss": 0.031800128519535065, "_runtime": 3602.7216732501984, "_timestamp": 1585600972.3545427, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.839224100112915, "Value Loss": 0.03298508748412132, "_runtime": 3603.479343175888, "_timestamp": 1585600973.1122127, "_step": 246}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 1.2411009073257446, "Value Loss": 20.084827423095703, "_runtime": 3604.942631483078, "_timestamp": 1585600974.575501, "_step": 247}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": 0.13887593150138855, "Value Loss": 10.0829496383667, "_runtime": 3606.4587473869324, "_timestamp": 1585600976.0916169, "_step": 248}
{"Episode reward": 3.1000000000012307, "Episode length": 969, "Policy Loss": 0.2455439269542694, "Value Loss": 10.076818466186523, "_runtime": 3607.629054546356, "_timestamp": 1585600977.261924, "_step": 249}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": 0.5278239250183105, "Value Loss": 12.301460266113281, "_runtime": 3609.1842815876007, "_timestamp": 1585600978.817151, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6869322657585144, "Value Loss": 0.021357858553528786, "_runtime": 3610.729667663574, "_timestamp": 1585600980.3625371, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6529880166053772, "Value Loss": 0.005617402493953705, "_runtime": 3611.361496925354, "_timestamp": 1585600980.9943664, "_step": 252}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.7191426753997803, "Value Loss": 23.662662506103516, "_runtime": 3612.9153215885162, "_timestamp": 1585600982.548191, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6359359622001648, "Value Loss": 0.008371676318347454, "_runtime": 3613.9827330112457, "_timestamp": 1585600983.6156025, "_step": 254}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 0.7355778217315674, "Value Loss": 14.13045883178711, "_runtime": 3614.467071056366, "_timestamp": 1585600984.0999405, "_step": 255}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 2.2357213497161865, "Value Loss": 30.906314849853516, "_runtime": 3616.054455280304, "_timestamp": 1585600985.6873248, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7392075061798096, "Value Loss": 0.030213532969355583, "_runtime": 3616.6706640720367, "_timestamp": 1585600986.3035336, "_step": 257}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.5413856506347656, "Value Loss": 24.40998649597168, "_runtime": 3618.1616549491882, "_timestamp": 1585600987.7945244, "_step": 258}
{"Episode reward": -99.8717693567262, "Episode length": 999, "Policy Loss": -0.8579705953598022, "Value Loss": 0.01585950329899788, "_runtime": 3619.1466834545135, "_timestamp": 1585600988.779553, "_step": 259}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.5475366115570068, "Value Loss": 15.339920997619629, "_runtime": 3620.6584343910217, "_timestamp": 1585600990.2913039, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0895168781280518, "Value Loss": 0.3407670259475708, "_runtime": 3621.6595146656036, "_timestamp": 1585600991.2923841, "_step": 261}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": 0.4944245219230652, "Value Loss": 14.908269882202148, "_runtime": 3623.189499616623, "_timestamp": 1585600992.822369, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0164462327957153, "Value Loss": 0.027499135583639145, "_runtime": 3624.7370932102203, "_timestamp": 1585600994.3699627, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0192277431488037, "Value Loss": 0.028199758380651474, "_runtime": 3626.266493320465, "_timestamp": 1585600995.8993628, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0072882175445557, "Value Loss": 0.05280500277876854, "_runtime": 3627.8317999839783, "_timestamp": 1585600997.4646695, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9874561429023743, "Value Loss": 0.0312509685754776, "_runtime": 3628.9780757427216, "_timestamp": 1585600998.6109452, "_step": 266}
{"Episode reward": 26.199999999999918, "Episode length": 738, "Policy Loss": 0.2589084208011627, "Value Loss": 13.039056777954102, "_runtime": 3629.9082610607147, "_timestamp": 1585600999.5411305, "_step": 267}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 0.598328709602356, "Value Loss": 15.970468521118164, "_runtime": 3631.475296497345, "_timestamp": 1585601001.108166, "_step": 268}
{"Episode reward": -99.88848672509054, "Episode length": 999, "Policy Loss": -0.880866289138794, "Value Loss": 0.014867279678583145, "_runtime": 3633.0267407894135, "_timestamp": 1585601002.6596103, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8390849232673645, "Value Loss": 0.01418038085103035, "_runtime": 3634.548386335373, "_timestamp": 1585601004.1812558, "_step": 270}
{"Episode reward": -99.82729654311994, "Episode length": 999, "Policy Loss": -0.8026742339134216, "Value Loss": 0.010994615033268929, "_runtime": 3636.109877347946, "_timestamp": 1585601005.7427468, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7547380328178406, "Value Loss": 0.00723403412848711, "_runtime": 3637.677473783493, "_timestamp": 1585601007.3103433, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7145110964775085, "Value Loss": 0.012294015847146511, "_runtime": 3639.2792105674744, "_timestamp": 1585601008.91208, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6734857559204102, "Value Loss": 0.00988741498440504, "_runtime": 3640.841145992279, "_timestamp": 1585601010.4740155, "_step": 274}
{"Episode reward": -99.80139627456525, "Episode length": 999, "Policy Loss": -0.6328097581863403, "Value Loss": 0.00622942578047514, "_runtime": 3642.4145267009735, "_timestamp": 1585601012.0473962, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.608218252658844, "Value Loss": 0.02843843214213848, "_runtime": 3643.9875769615173, "_timestamp": 1585601013.6204464, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5468246936798096, "Value Loss": 0.0049773454666137695, "_runtime": 3645.5317208766937, "_timestamp": 1585601015.1645904, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.507383406162262, "Value Loss": 0.006664933171123266, "_runtime": 3647.091470718384, "_timestamp": 1585601016.7243402, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46506884694099426, "Value Loss": 0.030422737821936607, "_runtime": 3648.648452281952, "_timestamp": 1585601018.2813218, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42953360080718994, "Value Loss": 0.02320634014904499, "_runtime": 3649.5976870059967, "_timestamp": 1585601019.2305565, "_step": 280}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 1.164935827255249, "Value Loss": 16.108549118041992, "_runtime": 3650.9071192741394, "_timestamp": 1585601020.5399888, "_step": 281}
{"Episode reward": 15.418224716187055, "Episode length": 846, "Policy Loss": 0.8246535062789917, "Value Loss": 11.467934608459473, "_runtime": 3652.4625709056854, "_timestamp": 1585601022.0954404, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36143118143081665, "Value Loss": 0.0040245046839118, "_runtime": 3653.990411758423, "_timestamp": 1585601023.6232812, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.371219277381897, "Value Loss": 0.003555336268618703, "_runtime": 3655.523216485977, "_timestamp": 1585601025.156086, "_step": 284}
{"Episode reward": -99.85603048801282, "Episode length": 999, "Policy Loss": -0.4117114841938019, "Value Loss": 0.08098874986171722, "_runtime": 3656.1881823539734, "_timestamp": 1585601025.8210518, "_step": 285}
{"Episode reward": 57.99999999999968, "Episode length": 420, "Policy Loss": 1.8120676279067993, "Value Loss": 22.90170669555664, "_runtime": 3657.742571115494, "_timestamp": 1585601027.3754406, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3989652395248413, "Value Loss": 0.04401734098792076, "_runtime": 3659.2982020378113, "_timestamp": 1585601028.9310715, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38144999742507935, "Value Loss": 0.0068160779774188995, "_runtime": 3660.7936973571777, "_timestamp": 1585601030.4265668, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3918044865131378, "Value Loss": 0.04089823737740517, "_runtime": 3662.3703060150146, "_timestamp": 1585601032.0031755, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3671274781227112, "Value Loss": 0.014817649498581886, "_runtime": 3663.9266674518585, "_timestamp": 1585601033.559537, "_step": 290}
{"Episode reward": -99.86987915038922, "Episode length": 999, "Policy Loss": -0.3341083526611328, "Value Loss": 0.004044516943395138, "_runtime": 3665.455010175705, "_timestamp": 1585601035.0878797, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3264877498149872, "Value Loss": 0.007922747172415257, "_runtime": 3667.018280506134, "_timestamp": 1585601036.65115, "_step": 292}
{"Episode reward": -99.80774621963361, "Episode length": 999, "Policy Loss": -0.3120150864124298, "Value Loss": 0.032326120883226395, "_runtime": 3668.579142808914, "_timestamp": 1585601038.2120123, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3062739372253418, "Value Loss": 0.03820426017045975, "_runtime": 3670.126575946808, "_timestamp": 1585601039.7594454, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22999076545238495, "Value Loss": 0.018913554027676582, "_runtime": 3671.0362465381622, "_timestamp": 1585601040.669116, "_step": 295}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 1.4707945585250854, "Value Loss": 16.977590560913086, "_runtime": 3672.5974373817444, "_timestamp": 1585601042.2303069, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15273083746433258, "Value Loss": 0.0013620351674035192, "_runtime": 3674.1479845046997, "_timestamp": 1585601043.780854, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15388798713684082, "Value Loss": 0.01626807637512684, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853, -0.00020512471382971853]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.0439845472574234, -0.04329408332705498, -0.042603619396686554, -0.04191315174102783, -0.04122268781065941, -0.040532223880290985, -0.03984175994992256, -0.03915129601955414, -0.038460828363895416, -0.03777036443352699, -0.03707990050315857, -0.036389436572790146, -0.03569897264242172, -0.035008504986763, -0.034318044781684875, -0.033627577126026154, -0.03293711319565773, -0.03224664926528931, -0.031556181609630585, -0.03086571954190731, -0.030175253748893738, -0.029484789818525314, -0.02879432588815689, -0.028103860095143318, -0.027413396164774895, -0.02672293223440647, -0.0260324664413929, -0.025342002511024475, -0.02465153858065605, -0.02396107278764248, -0.023270608857274055, -0.022580143064260483, -0.02188967913389206, -0.021199215203523636, -0.020508749410510063, -0.01981828548014164, -0.019127819687128067, -0.018437355756759644, -0.01774689182639122, -0.017056426033377647, -0.016365962103009224, -0.0156754981726408, -0.014985032379627228, -0.014294568449258804, -0.01360410451889038, -0.012913638725876808, -0.012223172932863235, -0.011532709002494812, -0.010842245072126389, -0.010151781141757965, -0.009461317211389542, -0.00877084955573082, -0.008080385625362396, -0.007389921694993973, -0.006699457764625549, -0.006008993834257126, -0.005318529903888702, -0.0046280622482299805, -0.003937598317861557, -0.0032471343874931335, -0.00255667045712471, -0.0018662065267562866, -0.0011757388710975647, -0.00048527494072914124, 0.00020518898963928223]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.0006992959533818066, -0.000688367523252964, -0.0006774390349164605, -0.0006665106047876179, -0.0006555821164511144, -0.0006446536863222718, -0.0006337251979857683, -0.0006227967678569257, -0.0006118682795204222, -0.0006009398493915796, -0.0005900113610550761, -0.0005790829309262335, -0.00056815444258973, -0.0005572260124608874, -0.0005462975241243839, -0.0005353690939955413, -0.0005244406056590378, -0.0005135121755301952, -0.0005025836871936917, -0.0004916552570648491, -0.00048072676872834563, -0.00046979833859950304, -0.00045886985026299953, -0.00044794142013415694, -0.0004370129609014839, -0.00042608450166881084, -0.0004151560424361378, -0.00040422758320346475, -0.0003932991239707917, -0.00038237066473811865, -0.0003714422055054456, -0.00036051374627277255, -0.0003495852870400995, -0.00033865682780742645, -0.0003277283685747534, -0.00031679990934208035, -0.0003058714501094073, -0.00029494299087673426, -0.0002840145316440612, -0.00027308607241138816, -0.0002621576131787151, -0.00025122915394604206, -0.000240300694713369, -0.00022937223548069596, -0.00021844377624802291, -0.00020751531701534986, -0.00019658688688650727, -0.00018565839855000377, -0.00017472996842116117, -0.00016380148008465767, -0.00015287304995581508, -0.00014194456161931157, -0.00013101613149046898, -0.00012008764315396547, -0.00010915921302512288, -9.823072468861938e-05, -8.730229455977678e-05, -7.637380622327328e-05, -6.544537609443069e-05, -5.451688775792718e-05, -4.358845762908459e-05, -3.265996929258108e-05, -2.173153916373849e-05, -1.0803050827234983e-05, 1.253793016076088e-07]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 2.0, 6.0, 6.0, 326.0, 6.0, 6.0, 0.0, 4.0, 3.0, 55.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 4.0, 2.0, 0.0, 2.0], "bins": [-0.00455517740920186, -0.0044538225047290325, -0.004352467134594917, -0.004251112230122089, -0.0041497573256492615, -0.004048401955515146, -0.003947047051042318, -0.0038456921465694904, -0.003744337009266019, -0.0036429818719625473, -0.0035416269674897194, -0.003440271830186248, -0.0033389166928827763, -0.0032375617884099483, -0.003136206651106477, -0.0030348515138030052, -0.0029334966093301773, -0.0028321414720267057, -0.002730786334723234, -0.0026294314302504063, -0.0025280762929469347, -0.002426721155643463, -0.0023253662511706352, -0.0022240111138671637, -0.002122655976563692, -0.002021301072090864, -0.0019199459347873926, -0.001818590797483921, -0.0017172358930110931, -0.0016158807557076216, -0.00151452561840415, -0.001413170713931322, -0.0013118155766278505, -0.001210460439324379, -0.001109105534851551, -0.0010077503975480795, -0.0009063952602446079, -0.00080504035577178, -0.0007036852184683084, -0.0006023300811648369, -0.000500975176692009, -0.00039962027221918106, -0.00029826490208506584, -0.00019690999761223793, -9.555509313941002e-05, 5.8002769947052e-06, 0.00010715518146753311, 0.00020851008594036102, 0.00030986545607447624, 0.00041122036054730415, 0.0005125752650201321, 0.0006139306351542473, 0.0007152855396270752, 0.0008166404440999031, 0.0009179958142340183, 0.0010193507187068462, 0.0011207056231796741, 0.0012220609933137894, 0.0013234158977866173, 0.0014247708022594452, 0.0015261261723935604, 0.0016274810768663883, 0.0017288359813392162, 0.0018301913514733315, 0.0019315462559461594]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.015525642782449722, -0.014839314855635166, -0.014152987860143185, -0.013466659933328629, -0.012780332006514072, -0.012094004079699516, -0.011407677084207535, -0.010721349157392979, -0.010035021230578423, -0.009348694235086441, -0.008662366308271885, -0.007976038381457329, -0.007289711385965347, -0.006603383459150791, -0.005917055532336235, -0.0052307285368442535, -0.004544400610029697, -0.0038580726832151413, -0.00317174568772316, -0.0024854177609086037, -0.0017990898340940475, -0.001112762838602066, -0.0004264349117875099, 0.0002598930150270462, 0.0009462200105190277, 0.0016325488686561584, 0.00231887586414814, 0.0030052028596401215, 0.003691531717777252, 0.004377858713269234, 0.005064185708761215, 0.005750514566898346, 0.0064368415623903275, 0.007123168557882309, 0.00780949741601944, 0.008495824411511421, 0.009182151407003403, 0.009868480265140533, 0.010554807260632515, 0.011241134256124496, 0.011927463114261627, 0.012613790109753609, 0.01330011710524559, 0.013986445963382721, 0.014672772958874702, 0.015359099954366684, 0.016045428812503815, 0.016731757670640945, 0.017418082803487778, 0.01810441166162491, 0.01879074051976204, 0.01947706565260887, 0.020163394510746002, 0.020849723368883133, 0.021536048501729965, 0.022222377359867096, 0.022908706218004227, 0.02359503135085106, 0.02428136020898819, 0.02496768906712532, 0.025654014199972153, 0.026340343058109283, 0.027026671916246414, 0.027712997049093246, 0.028399325907230377]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01838858425617218, -0.0179615318775177, -0.01753447949886322, -0.01710742712020874, -0.01668037660419941, -0.01625332422554493, -0.01582627184689045, -0.01539921946823597, -0.01497216708958149, -0.014545115642249584, -0.014118063263595104, -0.013691011816263199, -0.013263959437608719, -0.012836907058954239, -0.012409854680299759, -0.011982802301645279, -0.011555750854313374, -0.011128699406981468, -0.010701647028326988, -0.010274594649672508, -0.009847542271018028, -0.009420490823686123, -0.008993438445031643, -0.008566386066377163, -0.008139334619045258, -0.007712282240390778, -0.007285229861736298, -0.006858177483081818, -0.006431126035749912, -0.006004073657095432, -0.005577021278440952, -0.005149969831109047, -0.004722917452454567, -0.004295865073800087, -0.0038688136264681816, -0.0034417612478137016, -0.0030147088691592216, -0.0025876574218273163, -0.0021606050431728363, -0.0017335526645183563, -0.0013065002858638763, -0.0008794479072093964, -0.0004523973912000656, -2.5345012545585632e-05, 0.00040170736610889435, 0.0008287597447633743, 0.0012558121234178543, 0.0016828645020723343, 0.002109915018081665, 0.002536967396736145, 0.002964019775390625, 0.003391072154045105, 0.003818124532699585, 0.004245176911354065, 0.004672229290008545, 0.005099279806017876, 0.005526332184672356, 0.005953384563326836, 0.006380436941981316, 0.006807489320635796, 0.007234541699290276, 0.007661592215299606, 0.008088644593954086, 0.008515696972608566, 0.008942749351263046]}, "_runtime": 3675.6628210544586, "_timestamp": 1585601045.2956905, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1145763099193573, "Value Loss": 0.0029507698491215706, "_runtime": 3677.2152042388916, "_timestamp": 1585601046.8480737, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10590766370296478, "Value Loss": 0.01445902232080698, "_runtime": 3678.7561523914337, "_timestamp": 1585601048.3890219, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08469495922327042, "Value Loss": 0.004529921803623438, "_runtime": 3680.306736946106, "_timestamp": 1585601049.9396064, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06695802509784698, "Value Loss": 0.0027682643849402666, "_runtime": 3681.50713968277, "_timestamp": 1585601051.1400092, "_step": 302}
{"Episode reward": 22.700000000000117, "Episode length": 773, "Policy Loss": 1.1670567989349365, "Value Loss": 12.311562538146973, "_runtime": 3682.6466851234436, "_timestamp": 1585601052.2795546, "_step": 303}
{"Episode reward": 27.099999999999866, "Episode length": 729, "Policy Loss": 1.2387546300888062, "Value Loss": 13.263046264648438, "_runtime": 3683.632740020752, "_timestamp": 1585601053.2656095, "_step": 304}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 1.3119302988052368, "Value Loss": 15.073506355285645, "_runtime": 3685.163365125656, "_timestamp": 1585601054.7962346, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12060436606407166, "Value Loss": 0.006171731278300285, "_runtime": 3686.6631960868835, "_timestamp": 1585601056.2960656, "_step": 306}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": 0.8766791224479675, "Value Loss": 9.904821395874023, "_runtime": 3688.1763668060303, "_timestamp": 1585601057.8092363, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19777843356132507, "Value Loss": 0.015478645451366901, "_runtime": 3689.293783426285, "_timestamp": 1585601058.926653, "_step": 308}
{"Episode reward": 28.197308349609187, "Episode length": 719, "Policy Loss": 1.2807962894439697, "Value Loss": 13.3571138381958, "_runtime": 3690.83069729805, "_timestamp": 1585601060.4635668, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31415703892707825, "Value Loss": 0.06874347478151321, "_runtime": 3692.379974603653, "_timestamp": 1585601062.012844, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31970515847206116, "Value Loss": 0.024737972766160965, "_runtime": 3693.908085823059, "_timestamp": 1585601063.5409553, "_step": 311}
{"Episode reward": -99.80184259414533, "Episode length": 999, "Policy Loss": -0.2943466305732727, "Value Loss": 0.00931914895772934, "_runtime": 3694.5472555160522, "_timestamp": 1585601064.180125, "_step": 312}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 2.0344903469085693, "Value Loss": 24.321453094482422, "_runtime": 3696.088746547699, "_timestamp": 1585601065.721616, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3360816538333893, "Value Loss": 0.004669231828302145, "_runtime": 3697.6326899528503, "_timestamp": 1585601067.2655594, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40073370933532715, "Value Loss": 0.04233311861753464, "_runtime": 3698.840338945389, "_timestamp": 1585601068.4732084, "_step": 315}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 0.7005025744438171, "Value Loss": 11.928235054016113, "_runtime": 3700.398764371872, "_timestamp": 1585601070.0316339, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41095277667045593, "Value Loss": 0.00578838586807251, "_runtime": 3701.9549713134766, "_timestamp": 1585601071.5878408, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40813180804252625, "Value Loss": 0.022162869572639465, "_runtime": 3703.469462633133, "_timestamp": 1585601073.102332, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41391465067863464, "Value Loss": 0.013470050878822803, "_runtime": 3704.9410288333893, "_timestamp": 1585601074.5738983, "_step": 319}
{"Episode reward": 5.100000000001117, "Episode length": 949, "Policy Loss": 0.5013790726661682, "Value Loss": 9.752927780151367, "_runtime": 3705.804974794388, "_timestamp": 1585601075.4378443, "_step": 320}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 1.3088387250900269, "Value Loss": 17.12912368774414, "_runtime": 3707.3486528396606, "_timestamp": 1585601076.9815223, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26401543617248535, "Value Loss": 0.014072025194764137, "_runtime": 3708.9399721622467, "_timestamp": 1585601078.5728416, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19468198716640472, "Value Loss": 0.001895477413199842, "_runtime": 3709.69118642807, "_timestamp": 1585601079.324056, "_step": 323}
{"Episode reward": 51.39999999999959, "Episode length": 486, "Policy Loss": 1.7458652257919312, "Value Loss": 19.929569244384766, "_runtime": 3711.250657081604, "_timestamp": 1585601080.8835266, "_step": 324}
{"Episode reward": -99.84756823181966, "Episode length": 999, "Policy Loss": -0.11813969165086746, "Value Loss": 0.020579250529408455, "_runtime": 3712.16374707222, "_timestamp": 1585601081.7966166, "_step": 325}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 1.6599297523498535, "Value Loss": 16.587186813354492, "_runtime": 3713.576914548874, "_timestamp": 1585601083.209784, "_step": 326}
{"Episode reward": 5.300000000001106, "Episode length": 947, "Policy Loss": 1.0109741687774658, "Value Loss": 10.181403160095215, "_runtime": 3714.7708098888397, "_timestamp": 1585601084.4036794, "_step": 327}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 1.0699310302734375, "Value Loss": 12.246451377868652, "_runtime": 3716.267848968506, "_timestamp": 1585601085.9007185, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.153291717171669, "Value Loss": 0.007194166537374258, "_runtime": 3717.8020963668823, "_timestamp": 1585601087.4349658, "_step": 329}
{"Episode reward": -99.80620126724104, "Episode length": 999, "Policy Loss": -0.19242005050182343, "Value Loss": 0.0044148871675133705, "_runtime": 3719.315805196762, "_timestamp": 1585601088.9486747, "_step": 330}
{"Episode reward": -99.80008583068708, "Episode length": 999, "Policy Loss": -0.23322318494319916, "Value Loss": 0.00521136075258255, "_runtime": 3720.1717216968536, "_timestamp": 1585601089.8045912, "_step": 331}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 1.522359013557434, "Value Loss": 17.292936325073242, "_runtime": 3721.7099492549896, "_timestamp": 1585601091.3428187, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33300989866256714, "Value Loss": 0.019083714112639427, "_runtime": 3723.2473998069763, "_timestamp": 1585601092.8802693, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3874448537826538, "Value Loss": 0.0309896357357502, "_runtime": 3724.739121198654, "_timestamp": 1585601094.3719907, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4235703945159912, "Value Loss": 0.049763891845941544, "_runtime": 3725.8443059921265, "_timestamp": 1585601095.4771755, "_step": 335}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.8722259998321533, "Value Loss": 13.353591918945312, "_runtime": 3726.7295548915863, "_timestamp": 1585601096.3624244, "_step": 336}
{"Episode reward": 42.99999999999947, "Episode length": 570, "Policy Loss": 1.1421070098876953, "Value Loss": 16.90512466430664, "_runtime": 3728.2509677410126, "_timestamp": 1585601097.8838372, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44327932596206665, "Value Loss": 0.007577443961054087, "_runtime": 3729.569347381592, "_timestamp": 1585601099.2022169, "_step": 338}
{"Episode reward": 14.100000000000605, "Episode length": 859, "Policy Loss": 0.5930224657058716, "Value Loss": 11.191475868225098, "_runtime": 3730.5714781284332, "_timestamp": 1585601100.2043476, "_step": 339}
{"Episode reward": 33.89999999999948, "Episode length": 661, "Policy Loss": 1.1469465494155884, "Value Loss": 14.7991943359375, "_runtime": 3732.141998529434, "_timestamp": 1585601101.774868, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47508054971694946, "Value Loss": 0.0023921795655041933, "_runtime": 3733.6753945350647, "_timestamp": 1585601103.308264, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49211764335632324, "Value Loss": 0.026981212198734283, "_runtime": 3735.186858654022, "_timestamp": 1585601104.8197281, "_step": 342}
{"Episode reward": -99.85854341983655, "Episode length": 999, "Policy Loss": -0.4802800118923187, "Value Loss": 0.008868886157870293, "_runtime": 3736.147881269455, "_timestamp": 1585601105.7807508, "_step": 343}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 1.0667455196380615, "Value Loss": 15.477532386779785, "_runtime": 3737.5237317085266, "_timestamp": 1585601107.1566012, "_step": 344}
{"Episode reward": 11.20000000000077, "Episode length": 888, "Policy Loss": 0.5682491660118103, "Value Loss": 10.730663299560547, "_runtime": 3739.055256843567, "_timestamp": 1585601108.6881263, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5057971477508545, "Value Loss": 0.013367479667067528, "_runtime": 3739.3216977119446, "_timestamp": 1585601108.9545672, "_step": 346}
{"Episode reward": 85.40000000000003, "Episode length": 146, "Policy Loss": 5.846218109130859, "Value Loss": 66.49515533447266, "_runtime": 3740.867740869522, "_timestamp": 1585601110.5006104, "_step": 347}
{"Episode reward": -99.84520723819593, "Episode length": 999, "Policy Loss": -0.6414631009101868, "Value Loss": 0.19014890491962433, "_runtime": 3742.158871650696, "_timestamp": 1585601111.7917411, "_step": 348}
{"Episode reward": 15.917605376244097, "Episode length": 841, "Policy Loss": 0.775310218334198, "Value Loss": 11.224213600158691, "_runtime": 3743.6128902435303, "_timestamp": 1585601113.2457597, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5909402370452881, "Value Loss": 0.02578182891011238, "_runtime": 3744.607471704483, "_timestamp": 1585601114.2403412, "_step": 350}
{"Episode reward": 37.199999999999385, "Episode length": 628, "Policy Loss": 0.8433612585067749, "Value Loss": 15.569046974182129, "_runtime": 3746.1389157772064, "_timestamp": 1585601115.7717853, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5779494643211365, "Value Loss": 0.008314358070492744, "_runtime": 3747.6661138534546, "_timestamp": 1585601117.2989833, "_step": 352}
{"Episode reward": -99.82070960998395, "Episode length": 999, "Policy Loss": -0.5606504082679749, "Value Loss": 0.00511391693726182, "_runtime": 3749.032947540283, "_timestamp": 1585601118.665817, "_step": 353}
{"Episode reward": 9.400000000000873, "Episode length": 906, "Policy Loss": 0.42096757888793945, "Value Loss": 10.38983154296875, "_runtime": 3749.543481349945, "_timestamp": 1585601119.1763508, "_step": 354}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 2.347686767578125, "Value Loss": 31.059803009033203, "_runtime": 3751.075549840927, "_timestamp": 1585601120.7084193, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5569623708724976, "Value Loss": 0.018176710233092308, "_runtime": 3751.482756614685, "_timestamp": 1585601121.115626, "_step": 356}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": 3.3154218196868896, "Value Loss": 40.708953857421875, "_runtime": 3751.8522827625275, "_timestamp": 1585601121.4851522, "_step": 357}
{"Episode reward": 75.93142089843744, "Episode length": 241, "Policy Loss": 2.8894245624542236, "Value Loss": 38.23384475708008, "_runtime": 3753.393018245697, "_timestamp": 1585601123.0258877, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6902024149894714, "Value Loss": 0.12905001640319824, "_runtime": 3754.9066236019135, "_timestamp": 1585601124.539493, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6582595705986023, "Value Loss": 0.09748479723930359, "_runtime": 3756.3753089904785, "_timestamp": 1585601126.0081785, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5740211009979248, "Value Loss": 0.007070316467434168, "_runtime": 3757.9116592407227, "_timestamp": 1585601127.5445287, "_step": 361}
{"Episode reward": -99.8282226562486, "Episode length": 999, "Policy Loss": -0.5318204164505005, "Value Loss": 0.014434180222451687, "_runtime": 3759.4350261688232, "_timestamp": 1585601129.0678957, "_step": 362}
{"Episode reward": -99.80331709384778, "Episode length": 999, "Policy Loss": -0.4864920675754547, "Value Loss": 0.010478314012289047, "_runtime": 3759.9799711704254, "_timestamp": 1585601129.6128407, "_step": 363}
{"Episode reward": 66.5999999999998, "Episode length": 334, "Policy Loss": 2.311803102493286, "Value Loss": 27.75480079650879, "_runtime": 3760.8730788230896, "_timestamp": 1585601130.5059483, "_step": 364}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 1.2688220739364624, "Value Loss": 16.911376953125, "_runtime": 3762.4178235530853, "_timestamp": 1585601132.050693, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16212055087089539, "Value Loss": 0.0031748218461871147, "_runtime": 3763.338932275772, "_timestamp": 1585601132.9718018, "_step": 366}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": 1.3676564693450928, "Value Loss": 14.683122634887695, "_runtime": 3764.828155517578, "_timestamp": 1585601134.461025, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06233565881848335, "Value Loss": 0.014437424018979073, "_runtime": 3766.365178823471, "_timestamp": 1585601135.9980483, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16059914231300354, "Value Loss": 0.004887649789452553, "_runtime": 3767.4405183792114, "_timestamp": 1585601137.0733879, "_step": 369}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 1.516040563583374, "Value Loss": 12.908736228942871, "_runtime": 3768.9829144477844, "_timestamp": 1585601138.615784, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3206949234008789, "Value Loss": 0.025194216519594193, "_runtime": 3770.3271267414093, "_timestamp": 1585601139.9599962, "_step": 371}
{"Episode reward": 12.500000000000696, "Episode length": 875, "Policy Loss": 1.385524034500122, "Value Loss": 10.998918533325195, "_runtime": 3771.748357772827, "_timestamp": 1585601141.3812273, "_step": 372}
{"Episode reward": 6.2000000000010544, "Episode length": 938, "Policy Loss": 1.3079184293746948, "Value Loss": 10.171052932739258, "_runtime": 3773.2977499961853, "_timestamp": 1585601142.9306195, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2904050052165985, "Value Loss": 0.008494526147842407, "_runtime": 3774.8308234214783, "_timestamp": 1585601144.463693, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24365746974945068, "Value Loss": 0.009805350564420223, "_runtime": 3776.364530801773, "_timestamp": 1585601145.9974003, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20597857236862183, "Value Loss": 0.006547735538333654, "_runtime": 3777.947438955307, "_timestamp": 1585601147.5803084, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17333738505840302, "Value Loss": 0.006183307617902756, "_runtime": 3779.4970943927765, "_timestamp": 1585601149.1299639, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10455735772848129, "Value Loss": 0.0363423153758049, "_runtime": 3781.0366685390472, "_timestamp": 1585601150.669538, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10717041790485382, "Value Loss": 0.0022431041579693556, "_runtime": 3782.5914521217346, "_timestamp": 1585601152.2243216, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07687266916036606, "Value Loss": 0.007137438748031855, "_runtime": 3784.1381556987762, "_timestamp": 1585601153.7710252, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.046143051236867905, "Value Loss": 0.006617415230721235, "_runtime": 3785.6820392608643, "_timestamp": 1585601155.3149087, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029425470158457756, "Value Loss": 0.0022350423969328403, "_runtime": 3787.2421431541443, "_timestamp": 1585601156.8750126, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005641260650008917, "Value Loss": 0.001111706136725843, "_runtime": 3788.7927243709564, "_timestamp": 1585601158.4255939, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01449674367904663, "Value Loss": 0.0009194082813337445, "_runtime": 3790.3480138778687, "_timestamp": 1585601159.9808834, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05984923616051674, "Value Loss": 0.03886156156659126, "_runtime": 3791.8965520858765, "_timestamp": 1585601161.5294216, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06881499290466309, "Value Loss": 0.039778344333171844, "_runtime": 3793.444547176361, "_timestamp": 1585601163.0774167, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03017454966902733, "Value Loss": 0.0063575939275324345, "_runtime": 3795.000911951065, "_timestamp": 1585601164.6337814, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015488904900848866, "Value Loss": 0.019040703773498535, "_runtime": 3796.5608463287354, "_timestamp": 1585601166.1937158, "_step": 388}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": 1.0129069089889526, "Value Loss": 9.288652420043945, "_runtime": 3798.1165132522583, "_timestamp": 1585601167.7493827, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007671263534575701, "Value Loss": 0.020739488303661346, "_runtime": 3799.677473783493, "_timestamp": 1585601169.3103433, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03430604189634323, "Value Loss": 0.008058001287281513, "_runtime": 3800.444859266281, "_timestamp": 1585601170.0777287, "_step": 391}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 2.33394455909729, "Value Loss": 20.252880096435547, "_runtime": 3801.7546050548553, "_timestamp": 1585601171.3874745, "_step": 392}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": 1.1078163385391235, "Value Loss": 10.93748664855957, "_runtime": 3803.2956647872925, "_timestamp": 1585601172.9285343, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017569921910762787, "Value Loss": 0.0016648437594994903, "_runtime": 3804.79785656929, "_timestamp": 1585601174.430726, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0011038436787202954, "Value Loss": 0.001122600631788373, "_runtime": 3805.3727581501007, "_timestamp": 1585601175.0056276, "_step": 395}
{"Episode reward": 64.49999999999977, "Episode length": 355, "Policy Loss": 2.603485107421875, "Value Loss": 25.409292221069336, "_runtime": 3806.907469034195, "_timestamp": 1585601176.5403385, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007013360969722271, "Value Loss": 0.0041501689702272415, "_runtime": 3807.8693952560425, "_timestamp": 1585601177.5022647, "_step": 397}
{"Episode reward": 38.3999999999994, "Episode length": 616, "Policy Loss": 1.4040509462356567, "Value Loss": 14.517908096313477, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461, 0.0005395316984504461]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0005395484040491283, 0.001350638922303915, 0.0032408263068646193, 0.005131014157086611, 0.007021201308816671, 0.008911387994885445, 0.01080157607793808, 0.01269176322966814, 0.014581950381398201, 0.016472138464450836, 0.018362324684858322, 0.020252512767910957, 0.022142700850963593, 0.02403288707137108, 0.025923075154423714, 0.0278132613748312, 0.029703449457883835, 0.03159363567829132, 0.033483825623989105, 0.03537401184439659, 0.03726419806480408, 0.03915438801050186, 0.04104457423090935, 0.042934760451316833, 0.04482495039701462, 0.046715136617422104, 0.04860532283782959, 0.050495509058237076, 0.05238569900393486, 0.054275885224342346, 0.05616607144474983, 0.05805626139044762, 0.0599464476108551, 0.06183663383126259, 0.06372682005167007, 0.06561700999736786, 0.06750719994306564, 0.06939738243818283, 0.07128757238388062, 0.0731777623295784, 0.07506794482469559, 0.07695813477039337, 0.07884832471609116, 0.08073850721120834, 0.08262869715690613, 0.08451888710260391, 0.0864090695977211, 0.08829925954341888, 0.09018944948911667, 0.09207963198423386, 0.09396982192993164, 0.09586000442504883, 0.09775019437074661, 0.0996403843164444, 0.10153056681156158, 0.10342075675725937, 0.10531094670295715, 0.10720112919807434, 0.10909131914377213, 0.11098150908946991, 0.1128716915845871, 0.11476188153028488, 0.11665207147598267, 0.11854225397109985, 0.12043244391679764]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-3.193303754756016e-08, 2.8708183890557848e-05, 5.744829832110554e-05, 8.618841093266383e-05, 0.00011492853082017973, 0.00014366865798365325, 0.00017240876331925392, 0.00020114888320676982, 0.00022988900309428573, 0.00025862912298180163, 0.00028736924286931753, 0.00031610936275683343, 0.0003448494535405189, 0.0003735895734280348, 0.0004023296933155507, 0.0004310698132030666, 0.0004598099330905825, 0.0004885499947704375, 0.0005172901437617838, 0.0005460302345454693, 0.0005747703835368156, 0.0006035104743205011, 0.0006322506233118474, 0.0006609907140955329, 0.0006897308048792183, 0.0007184709538705647, 0.0007472110446542501, 0.0007759511936455965, 0.000804691284429282, 0.0008334314334206283, 0.0008621715242043138, 0.0008909116731956601, 0.0009196517639793456, 0.000948391854763031, 0.0009771320037543774, 0.0010058721527457237, 0.00103461230173707, 0.0010633524507284164, 0.001092092483304441, 0.0011208326322957873, 0.0011495727812871337, 0.0011783128138631582, 0.0012070529628545046, 0.001235793111845851, 0.0012645332608371973, 0.0012932732934132218, 0.0013220134424045682, 0.0013507535913959146, 0.001379493623971939, 0.0014082337729632854, 0.0014369739219546318, 0.0014657140709459782, 0.0014944541035220027, 0.001523194252513349, 0.0015519344015046954, 0.0015806745504960418, 0.0016094145830720663, 0.0016381547320634127, 0.001666894881054759, 0.0016956349136307836, 0.00172437506262213, 0.0017531152116134763, 0.0017818553606048226, 0.0018105953931808472, 0.0018393355421721935]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [28.0, 45.0, 11.0, 0.0, 16.0, 6.0, 18.0, 42.0, 0.0, 160.0, 4.0, 5.0, 6.0, 2.0, 12.0, 6.0, 5.0, 9.0, 10.0, 5.0, 8.0, 13.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 7.0, 2.0, 4.0, 2.0, 0.0, 0.0, 4.0, 2.0, 5.0, 2.0, 2.0, 3.0, 6.0, 0.0, 2.0, 2.0, 3.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], "bins": [-0.001817845506593585, -0.0016273190267384052, -0.0014367925468832254, -0.0012462660670280457, -0.0010557395871728659, -0.0008652131073176861, -0.0006746866274625063, -0.0004841601476073265, -0.0002936336677521467, -0.00010310718789696693, 8.741929195821285e-05, 0.00027794577181339264, 0.0004684722516685724, 0.0006589987315237522, 0.000849525211378932, 0.0010400516912341118, 0.0012305781710892916, 0.0014211046509444714, 0.0016116311307996511, 0.001802157610654831, 0.0019926840905100107, 0.002183210337534547, 0.0023737370502203703, 0.0025642637629061937, 0.00275479000993073, 0.002945316256955266, 0.0031358429696410894, 0.003326369682326913, 0.003516895929351449, 0.003707422176375985, 0.0038979488890618086, 0.004088475368916988, 0.0042790016159415245, 0.004469527862966061, 0.004660055041313171, 0.0048505812883377075, 0.005041107535362244, 0.00523163378238678, 0.0054221609607338905, 0.005612687207758427, 0.005803213454782963, 0.005993739701807499, 0.006184265948832035, 0.006374793127179146, 0.006565319374203682, 0.006755845621228218, 0.006946372799575329, 0.007136899046599865, 0.007327425293624401, 0.007517951540648937, 0.007708477787673473, 0.007899004966020584, 0.00808953121304512, 0.008280057460069656, 0.008470584638416767, 0.008661110885441303, 0.00885163713246584, 0.009042163379490376, 0.009232689626514912, 0.009423216804862022, 0.009613743051886559, 0.009804269298911095, 0.009994796477258205, 0.010185322724282742, 0.010375848971307278]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0], "bins": [-0.02776639722287655, -0.026808395981788635, -0.025850394740700722, -0.024892393499612808, -0.023934390395879745, -0.022976389154791832, -0.02201838791370392, -0.021060386672616005, -0.02010238543152809, -0.01914438232779503, -0.018186381086707115, -0.0172283798456192, -0.016270378604531288, -0.0153123764321208, -0.014354375191032887, -0.013396373018622398, -0.012438371777534485, -0.011480370536446571, -0.010522369295358658, -0.009564366191625595, -0.008606364950537682, -0.007648363709449768, -0.0066903624683618546, -0.005732361227273941, -0.0047743599861860275, -0.0038163568824529648, -0.0028583556413650513, -0.0019003544002771378, -0.0009423531591892242, 1.564808189868927e-05, 0.000973651185631752, 0.0019316524267196655, 0.002889653667807579, 0.003847656771540642, 0.004805656149983406, 0.005763659253716469, 0.006721658632159233, 0.007679661735892296, 0.008637664839625359, 0.009595664218068123, 0.010553667321801186, 0.01151166670024395, 0.012469669803977013, 0.013427672907710075, 0.01438567228615284, 0.015343675389885902, 0.016301674768328667, 0.01725967787206173, 0.018217677250504494, 0.019175680354237556, 0.02013368345797062, 0.021091682836413383, 0.022049685940146446, 0.02300768531858921, 0.023965688422322273, 0.024923691526055336, 0.0258816909044981, 0.026839694008231163, 0.027797693386673927, 0.02875569649040699, 0.029713699594140053, 0.030671698972582817, 0.03162970393896103, 0.032587699592113495, 0.03354570269584656]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.01683887466788292, -0.01607426628470421, -0.015309659764170647, -0.014545051380991936, -0.0137804439291358, -0.013015836477279663, -0.012251229025423527, -0.01148662157356739, -0.01072201319038868, -0.009957406669855118, -0.009192798286676407, -0.00842819083482027, -0.007663583382964134, -0.006898975931107998, -0.006134367547929287, -0.005369760096073151, -0.004605152644217014, -0.003840545192360878, -0.0030759377405047417, -0.0023113293573260307, -0.0015467219054698944, -0.0007821153849363327, -1.7507001757621765e-05, 0.0007471013814210892, 0.0015117079019546509, 0.002276316285133362, 0.0030409228056669235, 0.0038055311888456345, 0.004570139572024345, 0.005334746092557907, 0.006099354475736618, 0.00686396099627018, 0.007628569379448891, 0.008393177762627602, 0.009157784283161163, 0.009922392666339874, 0.010686999186873436, 0.011451607570052147, 0.012216215953230858, 0.01298082247376442, 0.01374543085694313, 0.014510039240121841, 0.015274643898010254, 0.016039252281188965, 0.016803860664367676, 0.017568469047546387, 0.018333077430725098, 0.01909768208861351, 0.01986229047179222, 0.020626898854970932, 0.021391507238149643, 0.022156115621328354, 0.022920720279216766, 0.023685328662395477, 0.024449937045574188, 0.0252145454287529, 0.02597915381193161, 0.026743758469820023, 0.027508366852998734, 0.028272975236177444, 0.029037583619356155, 0.029802192002534866, 0.03056679666042328, 0.03133140504360199, 0.0320960134267807]}, "_runtime": 3809.3589131832123, "_timestamp": 1585601178.9917827, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.033862996846437454, "Value Loss": 0.005723289214074612, "_runtime": 3810.918581724167, "_timestamp": 1585601180.5514512, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06221108138561249, "Value Loss": 0.0023460728116333485, "_runtime": 3812.427934408188, "_timestamp": 1585601182.060804, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08620045334100723, "Value Loss": 0.003396634478121996, "_runtime": 3813.9564414024353, "_timestamp": 1585601183.589311, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07280711829662323, "Value Loss": 0.033815573900938034, "_runtime": 3814.743927001953, "_timestamp": 1585601184.3767965, "_step": 402}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 1.779063105583191, "Value Loss": 18.187776565551758, "_runtime": 3816.2972316741943, "_timestamp": 1585601185.9301012, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08010467141866684, "Value Loss": 0.004801487550139427, "_runtime": 3817.8409945964813, "_timestamp": 1585601187.473864, "_step": 404}
{"Episode reward": -99.89834673404553, "Episode length": 999, "Policy Loss": 0.006080211140215397, "Value Loss": 0.027762066572904587, "_runtime": 3819.339421749115, "_timestamp": 1585601188.9722912, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006452212110161781, "Value Loss": 0.007324471604079008, "_runtime": 3820.891549348831, "_timestamp": 1585601190.5244188, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03518373891711235, "Value Loss": 0.0041931695304811, "_runtime": 3822.0510301589966, "_timestamp": 1585601191.6838996, "_step": 407}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": 1.2007205486297607, "Value Loss": 12.545317649841309, "_runtime": 3823.593262195587, "_timestamp": 1585601193.2261317, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11539150029420853, "Value Loss": 0.017028117552399635, "_runtime": 3825.199737548828, "_timestamp": 1585601194.832607, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16901443898677826, "Value Loss": 0.010953769087791443, "_runtime": 3826.722503900528, "_timestamp": 1585601196.3553734, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22032414376735687, "Value Loss": 0.007782832719385624, "_runtime": 3827.848781108856, "_timestamp": 1585601197.4816506, "_step": 411}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 1.2938634157180786, "Value Loss": 12.98652172088623, "_runtime": 3828.5525913238525, "_timestamp": 1585601198.1854608, "_step": 412}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 1.6346851587295532, "Value Loss": 20.891498565673828, "_runtime": 3830.107224702835, "_timestamp": 1585601199.7400942, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35477468371391296, "Value Loss": 0.06920868903398514, "_runtime": 3831.6433198451996, "_timestamp": 1585601201.2761893, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30703914165496826, "Value Loss": 0.011781037785112858, "_runtime": 3833.0032012462616, "_timestamp": 1585601202.6360707, "_step": 415}
{"Episode reward": 9.500000000000867, "Episode length": 905, "Policy Loss": 0.5922639966011047, "Value Loss": 9.902203559875488, "_runtime": 3833.922176837921, "_timestamp": 1585601203.5550463, "_step": 416}
{"Episode reward": 40.99999999999944, "Episode length": 590, "Policy Loss": 1.3270748853683472, "Value Loss": 16.090906143188477, "_runtime": 3835.4792783260345, "_timestamp": 1585601205.1121478, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18830911815166473, "Value Loss": 0.02308603748679161, "_runtime": 3837.0145869255066, "_timestamp": 1585601206.6474564, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12136247009038925, "Value Loss": 0.010068165138363838, "_runtime": 3838.525096654892, "_timestamp": 1585601208.1579661, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07641374319791794, "Value Loss": 0.011043362319469452, "_runtime": 3840.05970954895, "_timestamp": 1585601209.692579, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03872738033533096, "Value Loss": 0.0032078088261187077, "_runtime": 3841.5985445976257, "_timestamp": 1585601211.231414, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005204881890676916, "Value Loss": 0.007889826782047749, "_runtime": 3842.69429564476, "_timestamp": 1585601212.3271651, "_step": 422}
{"Episode reward": 29.87078301906557, "Episode length": 702, "Policy Loss": 1.2826486825942993, "Value Loss": 13.24993896484375, "_runtime": 3843.9547667503357, "_timestamp": 1585601213.5876362, "_step": 423}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 1.1398439407348633, "Value Loss": 11.741316795349121, "_runtime": 3845.491542339325, "_timestamp": 1585601215.1244118, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017680911347270012, "Value Loss": 0.0026914882473647594, "_runtime": 3847.0117506980896, "_timestamp": 1585601216.6446202, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.054140105843544006, "Value Loss": 0.0034887685906141996, "_runtime": 3848.5756306648254, "_timestamp": 1585601218.2085001, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11497758328914642, "Value Loss": 0.019239485263824463, "_runtime": 3849.5819845199585, "_timestamp": 1585601219.214854, "_step": 427}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 1.2419430017471313, "Value Loss": 13.889674186706543, "_runtime": 3851.1300477981567, "_timestamp": 1585601220.7629173, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12221523374319077, "Value Loss": 0.0011045754654332995, "_runtime": 3852.4513478279114, "_timestamp": 1585601222.0842173, "_step": 429}
{"Episode reward": 15.000000000000554, "Episode length": 850, "Policy Loss": 0.888748049736023, "Value Loss": 10.64371395111084, "_runtime": 3853.0657455921173, "_timestamp": 1585601222.698615, "_step": 430}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 2.1220862865448, "Value Loss": 23.030515670776367, "_runtime": 3853.8339915275574, "_timestamp": 1585601223.466861, "_step": 431}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 1.6669636964797974, "Value Loss": 19.05536651611328, "_runtime": 3855.3704149723053, "_timestamp": 1585601225.0032845, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2027512937784195, "Value Loss": 0.003942596726119518, "_runtime": 3855.877799510956, "_timestamp": 1585601225.510669, "_step": 433}
{"Episode reward": 67.29999999999981, "Episode length": 327, "Policy Loss": 2.3128576278686523, "Value Loss": 27.64232063293457, "_runtime": 3856.233227968216, "_timestamp": 1585601225.8660975, "_step": 434}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 4.560182094573975, "Value Loss": 41.15394973754883, "_runtime": 3857.7659215927124, "_timestamp": 1585601227.398791, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2641374170780182, "Value Loss": 0.015188020654022694, "_runtime": 3858.796755552292, "_timestamp": 1585601228.429625, "_step": 436}
{"Episode reward": 30.89999999999965, "Episode length": 691, "Policy Loss": 1.110522747039795, "Value Loss": 13.698394775390625, "_runtime": 3859.9391281604767, "_timestamp": 1585601229.5719976, "_step": 437}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": 1.090261459350586, "Value Loss": 12.085729598999023, "_runtime": 3860.507443189621, "_timestamp": 1585601230.1403127, "_step": 438}
{"Episode reward": 65.19999999999979, "Episode length": 348, "Policy Loss": 2.1974434852600098, "Value Loss": 26.24839973449707, "_runtime": 3862.025820016861, "_timestamp": 1585601231.6586895, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2296352982521057, "Value Loss": 0.023751836270093918, "_runtime": 3863.5316631793976, "_timestamp": 1585601233.1645327, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16478216648101807, "Value Loss": 0.0014263553312048316, "_runtime": 3865.010536670685, "_timestamp": 1585601234.6434062, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13070541620254517, "Value Loss": 0.033884335309267044, "_runtime": 3865.548793077469, "_timestamp": 1585601235.1816626, "_step": 442}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 2.418414831161499, "Value Loss": 28.027889251708984, "_runtime": 3867.0862317085266, "_timestamp": 1585601236.7191012, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10839422792196274, "Value Loss": 0.036824051290750504, "_runtime": 3868.624601125717, "_timestamp": 1585601238.2574706, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2243092656135559, "Value Loss": 0.08650440722703934, "_runtime": 3869.31085062027, "_timestamp": 1585601238.94372, "_step": 445}
{"Episode reward": 54.59999999999963, "Episode length": 454, "Policy Loss": 2.3499648571014404, "Value Loss": 21.644689559936523, "_runtime": 3870.864963054657, "_timestamp": 1585601240.4978325, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3319595754146576, "Value Loss": 0.018416523933410645, "_runtime": 3872.2646532058716, "_timestamp": 1585601241.8975227, "_step": 447}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 1.3512808084487915, "Value Loss": 10.768327713012695, "_runtime": 3873.6259384155273, "_timestamp": 1585601243.258808, "_step": 448}
{"Episode reward": 8.600000000000918, "Episode length": 914, "Policy Loss": 1.310770034790039, "Value Loss": 10.3209228515625, "_runtime": 3875.128710269928, "_timestamp": 1585601244.7615798, "_step": 449}
{"Episode reward": 3.0000000000012363, "Episode length": 970, "Policy Loss": 1.2632437944412231, "Value Loss": 9.93736743927002, "_runtime": 3875.640120983124, "_timestamp": 1585601245.2729905, "_step": 450}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 3.111416816711426, "Value Loss": 31.035476684570312, "_runtime": 3876.2417154312134, "_timestamp": 1585601245.874585, "_step": 451}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 2.217113733291626, "Value Loss": 23.4619140625, "_runtime": 3877.3490328788757, "_timestamp": 1585601246.9819024, "_step": 452}
{"Episode reward": 28.199999999999804, "Episode length": 718, "Policy Loss": 1.0072808265686035, "Value Loss": 12.703154563903809, "_runtime": 3878.0090098381042, "_timestamp": 1585601247.6418793, "_step": 453}
{"Episode reward": 55.99999999999965, "Episode length": 440, "Policy Loss": 1.7594594955444336, "Value Loss": 21.1236572265625, "_runtime": 3878.5589306354523, "_timestamp": 1585601248.1918, "_step": 454}
{"Episode reward": 63.79999999999976, "Episode length": 362, "Policy Loss": 1.9556238651275635, "Value Loss": 24.715011596679688, "_runtime": 3879.3746752738953, "_timestamp": 1585601249.0075448, "_step": 455}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 1.0106165409088135, "Value Loss": 16.56499671936035, "_runtime": 3880.8780064582825, "_timestamp": 1585601250.510876, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4944206774234772, "Value Loss": 0.013523864559829235, "_runtime": 3881.891660928726, "_timestamp": 1585601251.5245304, "_step": 457}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.7297897934913635, "Value Loss": 13.405226707458496, "_runtime": 3883.2079174518585, "_timestamp": 1585601252.840787, "_step": 458}
{"Episode reward": 11.90000000000073, "Episode length": 881, "Policy Loss": 0.5013887882232666, "Value Loss": 10.597124099731445, "_runtime": 3884.567782640457, "_timestamp": 1585601254.2006521, "_step": 459}
{"Episode reward": 11.100000000000776, "Episode length": 889, "Policy Loss": 0.6226520538330078, "Value Loss": 10.736428260803223, "_runtime": 3885.0660350322723, "_timestamp": 1585601254.6989045, "_step": 460}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 2.402881622314453, "Value Loss": 29.428403854370117, "_runtime": 3886.5932552814484, "_timestamp": 1585601256.2261248, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23285870254039764, "Value Loss": 0.003627719124779105, "_runtime": 3887.4586617946625, "_timestamp": 1585601257.0915313, "_step": 462}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 1.2892440557479858, "Value Loss": 16.213926315307617, "_runtime": 3888.9427819252014, "_timestamp": 1585601258.5756514, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.045611247420310974, "Value Loss": 0.001448565162718296, "_runtime": 3890.4858882427216, "_timestamp": 1585601260.1187577, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04377962276339531, "Value Loss": 0.006214863620698452, "_runtime": 3891.9892604351044, "_timestamp": 1585601261.62213, "_step": 465}
{"Episode reward": -99.82004835605481, "Episode length": 999, "Policy Loss": 0.1159556433558464, "Value Loss": 0.012989573180675507, "_runtime": 3893.0566251277924, "_timestamp": 1585601262.6894946, "_step": 466}
{"Episode reward": 31.09999999999964, "Episode length": 689, "Policy Loss": 1.4456197023391724, "Value Loss": 13.677738189697266, "_runtime": 3893.5523204803467, "_timestamp": 1585601263.18519, "_step": 467}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 3.3775951862335205, "Value Loss": 30.846986770629883, "_runtime": 3895.0917870998383, "_timestamp": 1585601264.7246566, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15629857778549194, "Value Loss": 0.029726307839155197, "_runtime": 3896.61309671402, "_timestamp": 1585601266.2459662, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10144145786762238, "Value Loss": 0.038139987736940384, "_runtime": 3898.1268813610077, "_timestamp": 1585601267.7597508, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04255271330475807, "Value Loss": 0.03390590101480484, "_runtime": 3899.6827704906464, "_timestamp": 1585601269.31564, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04533672705292702, "Value Loss": 0.009106708690524101, "_runtime": 3900.907700061798, "_timestamp": 1585601270.5405695, "_step": 472}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 1.019339919090271, "Value Loss": 12.054632186889648, "_runtime": 3901.4741213321686, "_timestamp": 1585601271.1069908, "_step": 473}
{"Episode reward": 64.79999999999978, "Episode length": 352, "Policy Loss": 2.349529504776001, "Value Loss": 25.786048889160156, "_runtime": 3903.0149998664856, "_timestamp": 1585601272.6478693, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2434396743774414, "Value Loss": 0.005140182562172413, "_runtime": 3904.2487688064575, "_timestamp": 1585601273.8816383, "_step": 475}
{"Episode reward": 20.00000000000027, "Episode length": 800, "Policy Loss": 0.7474517822265625, "Value Loss": 11.124454498291016, "_runtime": 3905.7306456565857, "_timestamp": 1585601275.3635151, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3603193163871765, "Value Loss": 0.16344039142131805, "_runtime": 3907.288957834244, "_timestamp": 1585601276.9218273, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39092308282852173, "Value Loss": 0.010242392309010029, "_runtime": 3908.816994667053, "_timestamp": 1585601278.4498641, "_step": 478}
{"Episode reward": -99.81215448379376, "Episode length": 999, "Policy Loss": -0.4288461208343506, "Value Loss": 0.0022814518306404352, "_runtime": 3910.3293328285217, "_timestamp": 1585601279.9622023, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4670823812484741, "Value Loss": 0.003007906023412943, "_runtime": 3911.4807608127594, "_timestamp": 1585601281.1136303, "_step": 480}
{"Episode reward": 26.4999999999999, "Episode length": 735, "Policy Loss": 0.641607940196991, "Value Loss": 12.198776245117188, "_runtime": 3913.0339183807373, "_timestamp": 1585601282.6667879, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49835988879203796, "Value Loss": 0.012233643792569637, "_runtime": 3914.4852607250214, "_timestamp": 1585601284.1181302, "_step": 482}
{"Episode reward": 6.2000000000010544, "Episode length": 938, "Policy Loss": 0.7324179410934448, "Value Loss": 9.676748275756836, "_runtime": 3915.593042612076, "_timestamp": 1585601285.225912, "_step": 483}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.6751174926757812, "Value Loss": 12.977057456970215, "_runtime": 3916.5377657413483, "_timestamp": 1585601286.1706352, "_step": 484}
{"Episode reward": 39.999999999999424, "Episode length": 600, "Policy Loss": 1.0203537940979004, "Value Loss": 15.853032112121582, "_runtime": 3917.4420957565308, "_timestamp": 1585601287.0749652, "_step": 485}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 1.1966094970703125, "Value Loss": 16.108699798583984, "_runtime": 3918.32829785347, "_timestamp": 1585601287.9611673, "_step": 486}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": 1.1730597019195557, "Value Loss": 15.848861694335938, "_runtime": 3919.7042248249054, "_timestamp": 1585601289.3370943, "_step": 487}
{"Episode reward": 9.500000000000867, "Episode length": 905, "Policy Loss": 0.8340604305267334, "Value Loss": 10.671955108642578, "_runtime": 3920.6693444252014, "_timestamp": 1585601290.302214, "_step": 488}
{"Episode reward": 35.79999999999937, "Episode length": 642, "Policy Loss": 1.3080310821533203, "Value Loss": 14.547184944152832, "_runtime": 3921.4827723503113, "_timestamp": 1585601291.1156418, "_step": 489}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 1.761885643005371, "Value Loss": 18.316774368286133, "_runtime": 3922.9916667938232, "_timestamp": 1585601292.6245363, "_step": 490}
{"Episode reward": -99.81060698032239, "Episode length": 999, "Policy Loss": 0.03741925582289696, "Value Loss": 0.061661992222070694, "_runtime": 3924.496161699295, "_timestamp": 1585601294.1290312, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029963867738842964, "Value Loss": 0.00465379050001502, "_runtime": 3925.999651193619, "_timestamp": 1585601295.6325207, "_step": 492}
{"Episode reward": -99.83618774413922, "Episode length": 999, "Policy Loss": 0.05060458555817604, "Value Loss": 0.03900698944926262, "_runtime": 3927.548304796219, "_timestamp": 1585601297.1811743, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06465771049261093, "Value Loss": 0.022846644744277, "_runtime": 3929.0958437919617, "_timestamp": 1585601298.7287133, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06871277093887329, "Value Loss": 0.022007787600159645, "_runtime": 3930.6293914318085, "_timestamp": 1585601300.262261, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002665772626642138, "Value Loss": 0.09830693900585175, "_runtime": 3932.165392637253, "_timestamp": 1585601301.7982621, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05292869359254837, "Value Loss": 0.003425932489335537, "_runtime": 3933.7077848911285, "_timestamp": 1585601303.3406544, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05513207986950874, "Value Loss": 0.003837055992335081, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884, -0.0019834889099001884]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-1.347306251525879, -1.3207229375839233, -1.2941397428512573, -1.2675564289093018, -1.2409731149673462, -1.2143898010253906, -1.1878066062927246, -1.161223292350769, -1.1346399784088135, -1.1080567836761475, -1.081473469734192, -1.0548901557922363, -1.0283069610595703, -1.0017236471176147, -0.9751403331756592, -0.9485570788383484, -0.9219738245010376, -0.895390510559082, -0.8688071966171265, -0.8422239422798157, -0.8156406879425049, -0.7890573740005493, -0.7624741196632385, -0.7358908653259277, -0.7093075513839722, -0.6827242970466614, -0.6561409831047058, -0.629557728767395, -0.6029744744300842, -0.5763911604881287, -0.5498079061508179, -0.5232245922088623, -0.4966413378715515, -0.4700580835342407, -0.44347476959228516, -0.41689151525497437, -0.3903082013130188, -0.363724946975708, -0.33714163303375244, -0.3105584383010864, -0.28397512435913086, -0.2573918104171753, -0.23080849647521973, -0.2042253017425537, -0.17764198780059814, -0.15105867385864258, -0.12447547912597656, -0.097892165184021, -0.07130885124206543, -0.044725656509399414, -0.018142342567443848, 0.008440971374511719, 0.035024285316467285, 0.0616074800491333, 0.08819079399108887, 0.11477410793304443, 0.14135730266571045, 0.16794061660766602, 0.19452393054962158, 0.2211071252822876, 0.24769043922424316, 0.27427375316619873, 0.3008570671081543, 0.3274402618408203, 0.3540235757827759]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.011882173828780651, -0.01163558941334486, -0.011389004997909069, -0.011142421513795853, -0.010895837098360062, -0.01064925268292427, -0.01040266826748848, -0.010156083852052689, -0.009909499436616898, -0.009662915021181107, -0.009416330605745316, -0.0091697471216321, -0.008923162706196308, -0.008676578290760517, -0.008429993875324726, -0.008183409459888935, -0.007936825975775719, -0.00769024109467864, -0.007443657144904137, -0.007197072729468346, -0.006950488314032555, -0.006703904364258051, -0.00645731994882226, -0.006210735533386469, -0.005964151583611965, -0.005717567168176174, -0.005470982752740383, -0.005224398337304592, -0.004977814387530088, -0.004731229972094297, -0.004484645556658506, -0.004238061606884003, -0.003991477191448212, -0.0037448927760124207, -0.0034983083605766296, -0.0032517239451408386, -0.0030051404610276222, -0.002758556045591831, -0.00251197163015604, -0.002265387214720249, -0.002018802799284458, -0.0017722183838486671, -0.0015256348997354507, -0.0012790504842996597, -0.0010324660688638687, -0.0007858816534280777, -0.0005392972379922867, -0.00029271282255649567, -4.6129338443279266e-05, 0.00020045507699251175, 0.00044703949242830276, 0.0006936239078640938, 0.0009402083232998848, 0.0011867927387356758, 0.0014333771541714668, 0.0016799606382846832, 0.0019265450537204742, 0.0021731294691562653, 0.0024197138845920563, 0.0026662983000278473, 0.0029128827154636383, 0.0031594661995768547, 0.0034060506150126457, 0.0036526350304484367, 0.0038992194458842278]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [7.0, 7.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 6.0, 5.0, 0.0, 1.0, 3.0, 4.0, 0.0, 3.0, 2.0, 1.0, 6.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 6.0, 25.0, 65.0, 166.0, 6.0, 9.0, 36.0, 44.0, 30.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 0.0, 2.0], "bins": [-0.08406403660774231, -0.08170181512832642, -0.07933959364891052, -0.07697737216949463, -0.07461515069007874, -0.07225292921066284, -0.06989070773124695, -0.06752848625183105, -0.06516626477241516, -0.06280404329299927, -0.06044182553887367, -0.05807960778474808, -0.055717386305332184, -0.05335516482591629, -0.0509929433465004, -0.0486307218670845, -0.04626850038766861, -0.043906278908252716, -0.04154405742883682, -0.03918183594942093, -0.036819614470005035, -0.03445739671587944, -0.03209517523646355, -0.029732953757047653, -0.02737073227763176, -0.025008510798215866, -0.022646289318799973, -0.020284071564674377, -0.017921850085258484, -0.01555962860584259, -0.013197407126426697, -0.010835185647010803, -0.00847296416759491, -0.006110742688179016, -0.0037485212087631226, -0.001386299729347229, 0.0009759217500686646, 0.003338143229484558, 0.005700364708900452, 0.008062586188316345, 0.010424807667732239, 0.012787021696567535, 0.015149243175983429, 0.017511464655399323, 0.019873686134815216, 0.02223590761423111, 0.024598129093647003, 0.026960350573062897, 0.02932257205247879, 0.031684793531894684, 0.03404701501131058, 0.03640923649072647, 0.038771457970142365, 0.04113367199897766, 0.043495893478393555, 0.04585811495780945, 0.04822033643722534, 0.050582557916641235, 0.05294477939605713, 0.05530700087547302, 0.057669222354888916, 0.06003144383430481, 0.0623936653137207, 0.0647558867931366, 0.06711810827255249]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.3049485683441162, -0.2984776794910431, -0.2920067608356476, -0.28553587198257446, -0.27906498312950134, -0.2725940942764282, -0.2661231756210327, -0.2596522867679596, -0.2531813979148865, -0.24671047925949097, -0.24023959040641785, -0.23376868665218353, -0.22729778289794922, -0.2208268940448761, -0.21435599029064178, -0.20788508653640747, -0.20141419768333435, -0.19494330883026123, -0.18847240507602692, -0.1820015013217926, -0.17553061246871948, -0.16905970871448517, -0.16258880496025085, -0.15611791610717773, -0.14964701235294342, -0.1431761085987091, -0.136705219745636, -0.13023431599140167, -0.12376341223716736, -0.11729252338409424, -0.11082161962985992, -0.1043507307767868, -0.09787982702255249, -0.09140892326831818, -0.08493803441524506, -0.07846713066101074, -0.07199624180793762, -0.06552533805370331, -0.059054434299468994, -0.052583545446395874, -0.046112656593322754, -0.039641737937927246, -0.033170849084854126, -0.026699960231781006, -0.020229041576385498, -0.013758152723312378, -0.007287263870239258, -0.00081634521484375, 0.00565454363822937, 0.01212543249130249, 0.018596351146697998, 0.025067239999771118, 0.03153812885284424, 0.038009047508239746, 0.044479936361312866, 0.050950825214385986, 0.057421743869781494, 0.06389263272285461, 0.07036352157592773, 0.07683441042900085, 0.08330532908439636, 0.08977621793746948, 0.0962471067905426, 0.10271802544593811, 0.10918891429901123]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 3.0, 0.0, 1.0, 2.0, 0.0, 3.0, 2.0, 6.0, 17.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.04217296093702316, -0.03802775591611862, -0.03388254716992378, -0.02973734214901924, -0.02559213526546955, -0.02144692838191986, -0.01730172336101532, -0.01315651647746563, -0.00901130959391594, -0.004866104573011398, -0.0007208958268165588, 0.003424309194087982, 0.007569514214992523, 0.011714722961187363, 0.015859927982091904, 0.020005136728286743, 0.024150341749191284, 0.028295546770095825, 0.032440751791000366, 0.036585964262485504, 0.040731169283390045, 0.044876374304294586, 0.04902157932519913, 0.05316678434610367, 0.05731198936700821, 0.06145720183849335, 0.06560240685939789, 0.06974761188030243, 0.07389281690120697, 0.07803802192211151, 0.08218323439359665, 0.08632843941450119, 0.09047364443540573, 0.09461884945631027, 0.09876405447721481, 0.10290925949811935, 0.1070544645190239, 0.11119966953992844, 0.11534488946199417, 0.11949009448289871, 0.12363529950380325, 0.1277804970741272, 0.13192570209503174, 0.13607090711593628, 0.14021611213684082, 0.14436131715774536, 0.1485065221786499, 0.15265172719955444, 0.15679693222045898, 0.1609421670436859, 0.16508737206459045, 0.169232577085495, 0.17337778210639954, 0.17752298712730408, 0.18166819214820862, 0.18581339716911316, 0.1899586021900177, 0.19410380721092224, 0.19824901223182678, 0.20239421725273132, 0.20653942227363586, 0.2106846272945404, 0.21482983231544495, 0.2189750373363495, 0.22312024235725403]}, "_runtime": 3934.552056789398, "_timestamp": 1585601304.1849263, "_step": 498}
{"Episode reward": 47.29999999999953, "Episode length": 527, "Policy Loss": 1.6670042276382446, "Value Loss": 16.919780731201172, "_runtime": 3934.552056789398, "_timestamp": 1585601304.1849263, "_step": 499}
