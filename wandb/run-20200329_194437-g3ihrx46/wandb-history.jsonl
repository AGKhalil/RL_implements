{"Episode reward": -55.94873894156073, "Episode length": 999, "Policy Loss": -0.025526849552989006, "Value Loss": 0.005468955263495445, "_runtime": 2017.9848499298096, "_timestamp": 1585511096.4055796, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6090408563613892, "Value Loss": 50.053009033203125, "_runtime": 2019.457379579544, "_timestamp": 1585511097.8781092, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35523611307144165, "Value Loss": 0.4880305826663971, "_runtime": 2020.9949398040771, "_timestamp": 1585511099.4156694, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4452455043792725, "Value Loss": 163.96617126464844, "_runtime": 2022.506710767746, "_timestamp": 1585511100.9274404, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0445244312286377, "Value Loss": 1.1955842971801758, "_runtime": 2024.0141701698303, "_timestamp": 1585511102.4348998, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5105900764465332, "Value Loss": 158.81808471679688, "_runtime": 2025.6131818294525, "_timestamp": 1585511104.0339115, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.952328085899353, "Value Loss": 1.13511061668396, "_runtime": 2027.137263059616, "_timestamp": 1585511105.5579927, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1202832460403442, "Value Loss": 5.280149936676025, "_runtime": 2028.6539986133575, "_timestamp": 1585511107.0747283, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3800235986709595, "Value Loss": 4.474555492401123, "_runtime": 2030.2169785499573, "_timestamp": 1585511108.6377082, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1692252159118652, "Value Loss": 5.686498165130615, "_runtime": 2031.7655911445618, "_timestamp": 1585511110.1863208, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3140909671783447, "Value Loss": 11.072970390319824, "_runtime": 2033.2910783290863, "_timestamp": 1585511111.711808, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.002302646636963, "Value Loss": 64.18795776367188, "_runtime": 2034.8443160057068, "_timestamp": 1585511113.2650456, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9096929430961609, "Value Loss": 75.27931213378906, "_runtime": 2036.3935782909393, "_timestamp": 1585511114.814308, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.382476568222046, "Value Loss": 35.48787307739258, "_runtime": 2037.9376211166382, "_timestamp": 1585511116.3583508, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.750877320766449, "Value Loss": 26.873050689697266, "_runtime": 2039.4974119663239, "_timestamp": 1585511117.9181416, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40463441610336304, "Value Loss": 10.087894439697266, "_runtime": 2041.0490918159485, "_timestamp": 1585511119.4698215, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1349317580461502, "Value Loss": 0.04761175066232681, "_runtime": 2042.5973675251007, "_timestamp": 1585511121.0180972, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5323911905288696, "Value Loss": 0.01906852424144745, "_runtime": 2044.1551721096039, "_timestamp": 1585511122.5759017, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8583190441131592, "Value Loss": 0.8634232878684998, "_runtime": 2045.7019290924072, "_timestamp": 1585511124.1226587, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.969143807888031, "Value Loss": 3.084179162979126, "_runtime": 2047.2881789207458, "_timestamp": 1585511125.7089086, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8396812677383423, "Value Loss": 0.03626687452197075, "_runtime": 2048.8465609550476, "_timestamp": 1585511127.2672906, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7015240788459778, "Value Loss": 0.11977498978376389, "_runtime": 2050.405341386795, "_timestamp": 1585511128.826071, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6317222714424133, "Value Loss": 0.31791284680366516, "_runtime": 2051.955995798111, "_timestamp": 1585511130.3767254, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6110767722129822, "Value Loss": 0.023477446287870407, "_runtime": 2053.5094199180603, "_timestamp": 1585511131.9301496, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6278499960899353, "Value Loss": 0.4497532248497009, "_runtime": 2055.0580966472626, "_timestamp": 1585511133.4788263, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6581175327301025, "Value Loss": 0.09612105041742325, "_runtime": 2056.612723827362, "_timestamp": 1585511135.0334535, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7339925765991211, "Value Loss": 0.047027237713336945, "_runtime": 2058.1733577251434, "_timestamp": 1585511136.5940874, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7671945095062256, "Value Loss": 0.5737839341163635, "_runtime": 2059.7234342098236, "_timestamp": 1585511138.1441638, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9503124356269836, "Value Loss": 0.057066865265369415, "_runtime": 2061.277044773102, "_timestamp": 1585511139.6977744, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0899908542633057, "Value Loss": 0.03275099769234657, "_runtime": 2062.8374774456024, "_timestamp": 1585511141.258207, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.252270221710205, "Value Loss": 0.031165895983576775, "_runtime": 2064.387968301773, "_timestamp": 1585511142.808698, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3886469602584839, "Value Loss": 0.06064393371343613, "_runtime": 2065.9306144714355, "_timestamp": 1585511144.351344, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4821447134017944, "Value Loss": 0.03778566047549248, "_runtime": 2067.479022502899, "_timestamp": 1585511145.8997521, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5384783744812012, "Value Loss": 0.18213020265102386, "_runtime": 2069.0298459529877, "_timestamp": 1585511147.4505756, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5489146709442139, "Value Loss": 0.1521991491317749, "_runtime": 2070.618376016617, "_timestamp": 1585511149.0391057, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6723231077194214, "Value Loss": 0.3369367718696594, "_runtime": 2072.1779839992523, "_timestamp": 1585511150.5987136, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4139161109924316, "Value Loss": 0.07337672263383865, "_runtime": 2073.7374000549316, "_timestamp": 1585511152.1581297, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2757766246795654, "Value Loss": 0.025981107726693153, "_runtime": 2075.2804832458496, "_timestamp": 1585511153.701213, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0789886713027954, "Value Loss": 0.18068251013755798, "_runtime": 2076.839506626129, "_timestamp": 1585511155.2602363, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0463299751281738, "Value Loss": 0.1579478234052658, "_runtime": 2078.397967815399, "_timestamp": 1585511156.8186975, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9677618145942688, "Value Loss": 0.4103241562843323, "_runtime": 2079.9518659114838, "_timestamp": 1585511158.3725955, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1687769889831543, "Value Loss": 0.05843346565961838, "_runtime": 2081.499008655548, "_timestamp": 1585511159.9197383, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1957050561904907, "Value Loss": 0.03441722318530083, "_runtime": 2083.045222043991, "_timestamp": 1585511161.4659517, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2996057271957397, "Value Loss": 0.19817593693733215, "_runtime": 2084.58970785141, "_timestamp": 1585511163.0104375, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3585028648376465, "Value Loss": 0.06274154037237167, "_runtime": 2086.149794101715, "_timestamp": 1585511164.5705237, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2954379320144653, "Value Loss": 0.025476356968283653, "_runtime": 2087.697932243347, "_timestamp": 1585511166.1186619, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4037721157073975, "Value Loss": 0.16766497492790222, "_runtime": 2089.2530133724213, "_timestamp": 1585511167.673743, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.193738579750061, "Value Loss": 0.1332494020462036, "_runtime": 2090.8150527477264, "_timestamp": 1585511169.2357824, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1049352884292603, "Value Loss": 0.015496675856411457, "_runtime": 2092.3767569065094, "_timestamp": 1585511170.7974865, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9693098068237305, "Value Loss": 0.0370788611471653, "_runtime": 2093.966537475586, "_timestamp": 1585511172.387267, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9212265014648438, "Value Loss": 0.016157299280166626, "_runtime": 2095.525568008423, "_timestamp": 1585511173.9462976, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8682641983032227, "Value Loss": 0.013403910212218761, "_runtime": 2097.0711572170258, "_timestamp": 1585511175.4918869, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7681081295013428, "Value Loss": 0.058179132640361786, "_runtime": 2098.6265001296997, "_timestamp": 1585511177.0472298, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8120871782302856, "Value Loss": 0.01455021183937788, "_runtime": 2100.187392950058, "_timestamp": 1585511178.6081226, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8156383037567139, "Value Loss": 0.010003659874200821, "_runtime": 2101.756161928177, "_timestamp": 1585511180.1768916, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8191779851913452, "Value Loss": 0.011679540388286114, "_runtime": 2103.30695605278, "_timestamp": 1585511181.7276857, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8190950155258179, "Value Loss": 0.03642355278134346, "_runtime": 2104.8525602817535, "_timestamp": 1585511183.27329, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.765671968460083, "Value Loss": 0.020708700641989708, "_runtime": 2106.402297258377, "_timestamp": 1585511184.823027, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7098089456558228, "Value Loss": 0.00842503271996975, "_runtime": 2107.94464302063, "_timestamp": 1585511186.3653727, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6661548614501953, "Value Loss": 0.038315411657094955, "_runtime": 2109.490484237671, "_timestamp": 1585511187.9112139, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6032951474189758, "Value Loss": 0.005399552173912525, "_runtime": 2111.0348885059357, "_timestamp": 1585511189.4556181, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5495132803916931, "Value Loss": 0.010646174661815166, "_runtime": 2112.5781676769257, "_timestamp": 1585511190.9988973, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5151119232177734, "Value Loss": 0.004986062180250883, "_runtime": 2114.126928091049, "_timestamp": 1585511192.5476577, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4629112184047699, "Value Loss": 0.012031681835651398, "_runtime": 2115.6630022525787, "_timestamp": 1585511194.083732, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46338415145874023, "Value Loss": 0.00216145277954638, "_runtime": 2117.227168560028, "_timestamp": 1585511195.6478982, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4411054849624634, "Value Loss": 0.007905538193881512, "_runtime": 2118.773232936859, "_timestamp": 1585511197.1939626, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4339543879032135, "Value Loss": 0.030738970264792442, "_runtime": 2120.310361146927, "_timestamp": 1585511198.7310908, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41091251373291016, "Value Loss": 0.0018364869756624103, "_runtime": 2121.841595888138, "_timestamp": 1585511200.2623255, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37675827741622925, "Value Loss": 0.00849886890500784, "_runtime": 2123.376024723053, "_timestamp": 1585511201.7967544, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3596377372741699, "Value Loss": 0.006541476584970951, "_runtime": 2124.91513133049, "_timestamp": 1585511203.335861, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3662587106227875, "Value Loss": 0.005589452106505632, "_runtime": 2126.4482777118683, "_timestamp": 1585511204.8690073, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3561376929283142, "Value Loss": 0.01576077565550804, "_runtime": 2127.9906697273254, "_timestamp": 1585511206.4113994, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3583536446094513, "Value Loss": 0.014544520527124405, "_runtime": 2129.5358691215515, "_timestamp": 1585511207.9565988, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3345506191253662, "Value Loss": 0.005524670705199242, "_runtime": 2131.0806839466095, "_timestamp": 1585511209.5014136, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3050985038280487, "Value Loss": 0.026372961699962616, "_runtime": 2132.6254618167877, "_timestamp": 1585511211.0461915, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2558914124965668, "Value Loss": 0.013618675991892815, "_runtime": 2134.170690059662, "_timestamp": 1585511212.5914197, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21755874156951904, "Value Loss": 0.0007536611519753933, "_runtime": 2135.7132670879364, "_timestamp": 1585511214.1339967, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1805613934993744, "Value Loss": 0.009284291416406631, "_runtime": 2137.2509026527405, "_timestamp": 1585511215.6716323, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09739166498184204, "Value Loss": 0.03744504228234291, "_runtime": 2138.8484926223755, "_timestamp": 1585511217.2692223, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1368521749973297, "Value Loss": 0.004708272870630026, "_runtime": 2140.4021492004395, "_timestamp": 1585511218.8228788, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13536421954631805, "Value Loss": 0.01680188626050949, "_runtime": 2141.9623272418976, "_timestamp": 1585511220.3830569, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17227989435195923, "Value Loss": 0.012640898115932941, "_runtime": 2143.5215129852295, "_timestamp": 1585511221.9422426, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19785155355930328, "Value Loss": 0.0024565334897488356, "_runtime": 2145.077532529831, "_timestamp": 1585511223.4982622, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19346867501735687, "Value Loss": 0.004833566956222057, "_runtime": 2146.6358604431152, "_timestamp": 1585511225.05659, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20807765424251556, "Value Loss": 0.0034872153773903847, "_runtime": 2148.1829328536987, "_timestamp": 1585511226.6036625, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21917729079723358, "Value Loss": 0.012572959065437317, "_runtime": 2149.7393453121185, "_timestamp": 1585511228.160075, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1988021284341812, "Value Loss": 0.018702875822782516, "_runtime": 2151.3002910614014, "_timestamp": 1585511229.7210207, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1379219889640808, "Value Loss": 0.02234167419373989, "_runtime": 2152.86003780365, "_timestamp": 1585511231.2807674, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05299663171172142, "Value Loss": 0.007394546642899513, "_runtime": 2154.416431427002, "_timestamp": 1585511232.837161, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005672065541148186, "Value Loss": 0.005850944202393293, "_runtime": 2155.975687980652, "_timestamp": 1585511234.3964176, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07067293673753738, "Value Loss": 0.026383502408862114, "_runtime": 2157.536966085434, "_timestamp": 1585511235.9576957, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07059069722890854, "Value Loss": 0.02267930842936039, "_runtime": 2159.0660264492035, "_timestamp": 1585511237.486756, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04162618890404701, "Value Loss": 0.008672346360981464, "_runtime": 2160.6266136169434, "_timestamp": 1585511239.0473433, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026190342381596565, "Value Loss": 0.002811688231304288, "_runtime": 2162.2213604450226, "_timestamp": 1585511240.64209, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00715875206515193, "Value Loss": 0.007280311547219753, "_runtime": 2163.776620864868, "_timestamp": 1585511242.1973505, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0047857388854026794, "Value Loss": 0.00140258704777807, "_runtime": 2165.3520851135254, "_timestamp": 1585511243.7728148, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025496769696474075, "Value Loss": 0.0007837949669919908, "_runtime": 2166.9279482364655, "_timestamp": 1585511245.3486779, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04168221727013588, "Value Loss": 0.0023596370592713356, "_runtime": 2168.498996734619, "_timestamp": 1585511246.9197264, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06042584031820297, "Value Loss": 0.005478407721966505, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875, 8215.421875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-8215.421875, 4218.6123046875, 16652.646484375, 29086.6796875, 41520.71484375, 53954.75, 66388.78125, 78822.8203125, 91256.8515625, 103690.8828125, 116124.921875, 128558.953125, 140992.984375, 153427.015625, 165861.0625, 178295.09375, 190729.125, 203163.15625, 215597.1875, 228031.234375, 240465.265625, 252899.296875, 265333.3125, 277767.375, 290201.375, 302635.4375, 315069.4375, 327503.5, 339937.5625, 352371.5625, 364805.625, 377239.625, 389673.6875, 402107.6875, 414541.75, 426975.75, 439409.8125, 451843.8125, 464277.875, 476711.9375, 489145.9375, 501580.0, 514014.0, 526448.0625, 538882.0625, 551316.125, 563750.125, 576184.1875, 588618.1875, 601052.25, 613486.25, 625920.3125, 638354.3125, 650788.375, 663222.4375, 675656.4375, 688090.5, 700524.5, 712958.5625, 725392.5625, 737826.625, 750260.625, 762694.6875, 775128.6875, 787562.75]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0], "bins": [-14253.9140625, -14031.1962890625, -13808.4794921875, -13585.76171875, -13363.044921875, -13140.3271484375, -12917.609375, -12694.892578125, -12472.1748046875, -12249.45703125, -12026.740234375, -11804.0224609375, -11581.3046875, -11358.587890625, -11135.8701171875, -10913.15234375, -10690.435546875, -10467.71875, -10245.0009765625, -10022.283203125, -9799.56640625, -9576.8486328125, -9354.130859375, -9131.4140625, -8908.6962890625, -8685.978515625, -8463.26171875, -8240.5439453125, -8017.82666015625, -7795.109375, -7572.3916015625, -7349.67431640625, -7126.95703125, -6904.23974609375, -6681.5224609375, -6458.8046875, -6236.08740234375, -6013.3701171875, -5790.65234375, -5567.935546875, -5345.2177734375, -5122.5, -4899.783203125, -4677.0654296875, -4454.34765625, -4231.630859375, -4008.9130859375, -3786.1962890625, -3563.478515625, -3340.7607421875, -3118.0439453125, -2895.326171875, -2672.609375, -2449.8916015625, -2227.173828125, -2004.45703125, -1781.7392578125, -1559.021484375, -1336.3046875, -1113.5869140625, -890.869140625, -668.15234375, -445.4345703125, -222.7177734375, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 8.0, 10.0, 1.0, 14.0, 357.0, 10.0, 41.0, 39.0, 3.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0], "bins": [-318648.0, -311664.21875, -304680.46875, -297696.6875, -290712.90625, -283729.125, -276745.375, -269761.59375, -262777.8125, -255794.0625, -248810.28125, -241826.515625, -234842.75, -227858.96875, -220875.203125, -213891.4375, -206907.65625, -199923.875, -192940.109375, -185956.34375, -178972.5625, -171988.796875, -165005.03125, -158021.25, -151037.484375, -144053.71875, -137069.9375, -130086.171875, -123102.40625, -116118.625, -109134.859375, -102151.078125, -95167.3125, -88183.546875, -81199.765625, -74216.0, -67232.21875, -60248.453125, -53264.6875, -46280.90625, -39297.125, -32313.375, -25329.59375, -18345.8125, -11362.0625, -4378.28125, 2605.5, 9589.25, 16573.03125, 23556.8125, 30540.5625, 37524.34375, 44508.125, 51491.875, 58475.65625, 65459.4375, 72443.1875, 79426.96875, 86410.75, 93394.53125, 100378.28125, 107362.0625, 114345.84375, 121329.59375, 128313.375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-133925.75, -131327.015625, -128728.2734375, -126129.5390625, -123530.796875, -120932.0625, -118333.3203125, -115734.5859375, -113135.84375, -110537.109375, -107938.375, -105339.6328125, -102740.8984375, -100142.15625, -97543.421875, -94944.6875, -92345.9453125, -89747.203125, -87148.46875, -84549.734375, -81950.9921875, -79352.2578125, -76753.515625, -74154.78125, -71556.046875, -68957.3046875, -66358.5703125, -63759.828125, -61161.09375, -58562.3515625, -55963.6171875, -53364.875, -50766.140625, -48167.40625, -45568.6640625, -42969.9296875, -40371.1875, -37772.453125, -35173.7109375, -32574.9765625, -29976.234375, -27377.5, -24778.765625, -22180.0234375, -19581.2890625, -16982.546875, -14383.8125, -11785.0703125, -9186.3359375, -6587.6015625, -3988.859375, -1390.125, 1208.609375, 3807.359375, 6406.09375, 9004.828125, 11603.5625, 14202.296875, 16801.046875, 19399.78125, 21998.515625, 24597.25, 27196.0, 29794.734375, 32393.46875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 5.0, 5.0, 9.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-83954.9375, -66393.84375, -48832.75, -31271.65625, -13710.5625, 3850.53125, 21411.625, 38972.71875, 56533.8125, 74094.90625, 91656.0, 109217.09375, 126778.1875, 144339.28125, 161900.375, 179461.46875, 197022.5625, 214583.65625, 232144.75, 249705.84375, 267266.9375, 284828.03125, 302389.125, 319950.21875, 337511.3125, 355072.40625, 372633.5, 390194.59375, 407755.6875, 425316.78125, 442877.875, 460438.9375, 478000.0625, 495561.1875, 513122.25, 530683.3125, 548244.4375, 565805.5625, 583366.625, 600927.6875, 618488.8125, 636049.9375, 653611.0, 671172.0625, 688733.1875, 706294.3125, 723855.375, 741416.4375, 758977.5625, 776538.6875, 794099.75, 811660.8125, 829221.9375, 846783.0625, 864344.125, 881905.1875, 899466.3125, 917027.4375, 934588.5, 952149.5625, 969710.6875, 987271.8125, 1004832.8125, 1022393.9375, 1039955.0625]}, "_runtime": 2170.072022676468, "_timestamp": 1585511248.4927523, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06344042718410492, "Value Loss": 0.007741245441138744, "_runtime": 2171.6418249607086, "_timestamp": 1585511250.0625546, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06844256073236465, "Value Loss": 0.0040196701884269714, "_runtime": 2173.210821390152, "_timestamp": 1585511251.631551, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05476634204387665, "Value Loss": 0.004948112647980452, "_runtime": 2174.771265745163, "_timestamp": 1585511253.1919954, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05294692516326904, "Value Loss": 0.01523030549287796, "_runtime": 2176.3317205905914, "_timestamp": 1585511254.7524502, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0076821111142635345, "Value Loss": 0.0010599755914881825, "_runtime": 2177.8997898101807, "_timestamp": 1585511256.3205194, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03194033354520798, "Value Loss": 0.006525756791234016, "_runtime": 2179.471275806427, "_timestamp": 1585511257.8920054, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06064353510737419, "Value Loss": 0.014738047495484352, "_runtime": 2181.0450236797333, "_timestamp": 1585511259.4657533, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08588069677352905, "Value Loss": 0.01383568812161684, "_runtime": 2182.614819765091, "_timestamp": 1585511261.0355494, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11418234556913376, "Value Loss": 0.032209135591983795, "_runtime": 2184.1764290332794, "_timestamp": 1585511262.5971587, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.048957258462905884, "Value Loss": 0.0005775306490249932, "_runtime": 2185.7765460014343, "_timestamp": 1585511264.1972756, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015641598030924797, "Value Loss": 0.011824605986475945, "_runtime": 2187.3341143131256, "_timestamp": 1585511265.754844, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009308692999184132, "Value Loss": 0.003063115058466792, "_runtime": 2188.8963820934296, "_timestamp": 1585511267.3171117, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018323887139558792, "Value Loss": 0.016888707876205444, "_runtime": 2190.4684925079346, "_timestamp": 1585511268.8892221, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009772293269634247, "Value Loss": 0.0012536122230812907, "_runtime": 2192.0397160053253, "_timestamp": 1585511270.4604456, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006211312022060156, "Value Loss": 0.0006798535468988121, "_runtime": 2193.600177526474, "_timestamp": 1585511272.0209072, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027701346203684807, "Value Loss": 0.0017471392638981342, "_runtime": 2195.1720747947693, "_timestamp": 1585511273.5928044, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.043268900364637375, "Value Loss": 0.002250582678243518, "_runtime": 2196.742116212845, "_timestamp": 1585511275.1628458, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.053131118416786194, "Value Loss": 0.003477524034678936, "_runtime": 2198.303318500519, "_timestamp": 1585511276.7240481, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06882327795028687, "Value Loss": 0.010597866959869862, "_runtime": 2199.8644227981567, "_timestamp": 1585511278.2851524, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.049644485116004944, "Value Loss": 0.002198530826717615, "_runtime": 2201.4236991405487, "_timestamp": 1585511279.8444288, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03365519642829895, "Value Loss": 0.0013181037502363324, "_runtime": 2202.996199131012, "_timestamp": 1585511281.4169288, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01631251908838749, "Value Loss": 0.0008685289067216218, "_runtime": 2204.5668828487396, "_timestamp": 1585511282.9876125, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00509435823187232, "Value Loss": 0.0024428057949990034, "_runtime": 2206.124812602997, "_timestamp": 1585511284.5455422, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004064357373863459, "Value Loss": 0.006659200415015221, "_runtime": 2207.695241212845, "_timestamp": 1585511286.1159708, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016796384006738663, "Value Loss": 0.0008054267382249236, "_runtime": 2209.2870695590973, "_timestamp": 1585511287.7077992, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002996639581397176, "Value Loss": 0.0026341790799051523, "_runtime": 2210.8488993644714, "_timestamp": 1585511289.269629, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009694707579910755, "Value Loss": 0.005979760549962521, "_runtime": 2212.421637058258, "_timestamp": 1585511290.8423667, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021388716995716095, "Value Loss": 0.005593475420027971, "_runtime": 2213.9923417568207, "_timestamp": 1585511292.4130714, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.039973724633455276, "Value Loss": 0.003733123419806361, "_runtime": 2215.5632717609406, "_timestamp": 1585511293.9840014, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.054963577538728714, "Value Loss": 0.0031124297529459, "_runtime": 2217.1333894729614, "_timestamp": 1585511295.554119, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0653168261051178, "Value Loss": 0.002395365620031953, "_runtime": 2218.710300207138, "_timestamp": 1585511297.1310298, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07323499023914337, "Value Loss": 0.0072744181379675865, "_runtime": 2220.2691547870636, "_timestamp": 1585511298.6898844, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05199457332491875, "Value Loss": 0.0001581604446982965, "_runtime": 2221.839600086212, "_timestamp": 1585511300.2603297, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04111514240503311, "Value Loss": 0.0010446292581036687, "_runtime": 2223.4091432094574, "_timestamp": 1585511301.8298728, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029571227729320526, "Value Loss": 0.006856571417301893, "_runtime": 2224.9680144786835, "_timestamp": 1585511303.388744, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01580115221440792, "Value Loss": 0.0001495574542786926, "_runtime": 2226.52659201622, "_timestamp": 1585511304.9473217, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012089029885828495, "Value Loss": 0.001124106696806848, "_runtime": 2228.099288702011, "_timestamp": 1585511306.5200183, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017748767510056496, "Value Loss": 0.00716883409768343, "_runtime": 2229.6582157611847, "_timestamp": 1585511308.0789454, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023774582892656326, "Value Loss": 0.0014004942495375872, "_runtime": 2231.2200276851654, "_timestamp": 1585511309.6407573, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03077448159456253, "Value Loss": 0.001681334339082241, "_runtime": 2232.824513196945, "_timestamp": 1585511311.2452428, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04325082153081894, "Value Loss": 0.001793085946701467, "_runtime": 2234.3958666324615, "_timestamp": 1585511312.8165963, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04888637736439705, "Value Loss": 0.009332372806966305, "_runtime": 2235.968427658081, "_timestamp": 1585511314.3891573, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03877691924571991, "Value Loss": 0.00686833867803216, "_runtime": 2237.5281496047974, "_timestamp": 1585511315.9488792, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015376974828541279, "Value Loss": 0.0008777544135227799, "_runtime": 2239.088077068329, "_timestamp": 1585511317.5088067, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026382531505078077, "Value Loss": 0.00016260785923805088, "_runtime": 2240.6400537490845, "_timestamp": 1585511319.0607834, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01615123450756073, "Value Loss": 0.0027967842761427164, "_runtime": 2242.187639951706, "_timestamp": 1585511320.6083696, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018111413344740868, "Value Loss": 0.0027499154675751925, "_runtime": 2243.7323985099792, "_timestamp": 1585511322.1531281, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00801884662359953, "Value Loss": 0.010173773393034935, "_runtime": 2245.2769565582275, "_timestamp": 1585511323.6976862, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028785116970539093, "Value Loss": 0.007047602441161871, "_runtime": 2246.833208799362, "_timestamp": 1585511325.2539384, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.045937467366456985, "Value Loss": 0.002110936213284731, "_runtime": 2248.3887932300568, "_timestamp": 1585511326.8095229, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06947539001703262, "Value Loss": 0.006112708710134029, "_runtime": 2249.9433238506317, "_timestamp": 1585511328.3640535, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07142511010169983, "Value Loss": 0.0036934595555067062, "_runtime": 2251.4974455833435, "_timestamp": 1585511329.9181752, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05795128270983696, "Value Loss": 0.001216817763634026, "_runtime": 2253.0499510765076, "_timestamp": 1585511331.4706807, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04433930665254593, "Value Loss": 0.0006280559464357793, "_runtime": 2254.6418867111206, "_timestamp": 1585511333.0626163, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03585844486951828, "Value Loss": 0.00833915825933218, "_runtime": 2256.1870532035828, "_timestamp": 1585511334.6077828, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008021790534257889, "Value Loss": 0.0007465291419066489, "_runtime": 2257.7231488227844, "_timestamp": 1585511336.1438785, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013593379408121109, "Value Loss": 0.0008236251887865365, "_runtime": 2259.2697410583496, "_timestamp": 1585511337.6904707, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025487324222922325, "Value Loss": 0.0155019611120224, "_runtime": 2260.8249056339264, "_timestamp": 1585511339.2456353, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005207126378081739, "Value Loss": 0.0016282310243695974, "_runtime": 2262.3780086040497, "_timestamp": 1585511340.7987382, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027009662240743637, "Value Loss": 0.0027326627168804407, "_runtime": 2263.932700395584, "_timestamp": 1585511342.35343, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.051085859537124634, "Value Loss": 0.0014800389762967825, "_runtime": 2265.489044189453, "_timestamp": 1585511343.9097738, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07212275266647339, "Value Loss": 0.004450195003300905, "_runtime": 2267.0421073436737, "_timestamp": 1585511345.462837, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07790480554103851, "Value Loss": 0.017116792500019073, "_runtime": 2268.5967950820923, "_timestamp": 1585511347.0175247, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04997237026691437, "Value Loss": 0.0011771656572818756, "_runtime": 2270.1507699489594, "_timestamp": 1585511348.5714996, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026537081226706505, "Value Loss": 0.0049377260729670525, "_runtime": 2271.7038567066193, "_timestamp": 1585511350.1245863, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018747886642813683, "Value Loss": 0.00017322313215117902, "_runtime": 2273.261782169342, "_timestamp": 1585511351.6825118, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05034402012825012, "Value Loss": 0.005406128708273172, "_runtime": 2274.8149676322937, "_timestamp": 1585511353.2356973, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06194289028644562, "Value Loss": 0.003330250969156623, "_runtime": 2276.3676402568817, "_timestamp": 1585511354.78837, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07641344517469406, "Value Loss": 0.014130025170743465, "_runtime": 2277.957018136978, "_timestamp": 1585511356.3777478, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.053245898336172104, "Value Loss": 0.011145304888486862, "_runtime": 2279.5110421180725, "_timestamp": 1585511357.9317718, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005845979787409306, "Value Loss": 0.0008263034978881478, "_runtime": 2281.0645842552185, "_timestamp": 1585511359.485314, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06015699356794357, "Value Loss": 0.0018768900772556663, "_runtime": 2282.608913421631, "_timestamp": 1585511361.029643, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10355643928050995, "Value Loss": 0.0014189440989866853, "_runtime": 2284.150068759918, "_timestamp": 1585511362.5707984, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14863090217113495, "Value Loss": 0.01357566099613905, "_runtime": 2285.6949825286865, "_timestamp": 1585511364.1157122, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16052871942520142, "Value Loss": 0.03517766296863556, "_runtime": 2287.2389755249023, "_timestamp": 1585511365.6597052, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15526238083839417, "Value Loss": 0.029502766206860542, "_runtime": 2288.7945783138275, "_timestamp": 1585511367.215308, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09562879800796509, "Value Loss": 0.0038923616521060467, "_runtime": 2290.3483657836914, "_timestamp": 1585511368.7690954, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03680917248129845, "Value Loss": 0.0021649841219186783, "_runtime": 2291.9043443202972, "_timestamp": 1585511370.325074, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012387587688863277, "Value Loss": 0.007231229450553656, "_runtime": 2293.4600677490234, "_timestamp": 1585511371.8807974, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0591416135430336, "Value Loss": 0.0046084304340183735, "_runtime": 2295.014044523239, "_timestamp": 1585511373.4347742, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08759329468011856, "Value Loss": 0.018920201808214188, "_runtime": 2296.5680782794952, "_timestamp": 1585511374.988808, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07278311252593994, "Value Loss": 0.004744142293930054, "_runtime": 2298.099518060684, "_timestamp": 1585511376.5202477, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05603155121207237, "Value Loss": 0.0024985496420413256, "_runtime": 2299.6515607833862, "_timestamp": 1585511378.0722904, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024800827726721764, "Value Loss": 0.0006906555499881506, "_runtime": 2301.221173286438, "_timestamp": 1585511379.641903, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0011808070121333003, "Value Loss": 0.0005346427788026631, "_runtime": 2302.765546321869, "_timestamp": 1585511381.186276, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02662809006869793, "Value Loss": 0.000824652670416981, "_runtime": 2304.308917284012, "_timestamp": 1585511382.729647, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.046457722783088684, "Value Loss": 0.0023696727585047483, "_runtime": 2305.8435106277466, "_timestamp": 1585511384.2642403, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05678986385464668, "Value Loss": 0.002653147093951702, "_runtime": 2307.3966019153595, "_timestamp": 1585511385.8173316, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0607028566300869, "Value Loss": 0.0038148716557770967, "_runtime": 2308.951782464981, "_timestamp": 1585511387.372512, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05078437179327011, "Value Loss": 0.0002112699148710817, "_runtime": 2310.5066509246826, "_timestamp": 1585511388.9273806, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04676418751478195, "Value Loss": 0.00040908707887865603, "_runtime": 2312.059581518173, "_timestamp": 1585511390.4803112, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03934402018785477, "Value Loss": 0.0009500487940385938, "_runtime": 2313.600575685501, "_timestamp": 1585511392.0213053, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026486443355679512, "Value Loss": 4.608460585586727e-05, "_runtime": 2315.1597607135773, "_timestamp": 1585511393.5804904, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015429534018039703, "Value Loss": 0.0027881646528840065, "_runtime": 2316.7212615013123, "_timestamp": 1585511395.1419911, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005667532794177532, "Value Loss": 0.003102169604972005, "_runtime": 2318.282167196274, "_timestamp": 1585511396.7028968, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00439727446064353, "Value Loss": 0.0007957627531141043, "_runtime": 2319.836675643921, "_timestamp": 1585511398.2574053, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009422716102562845, "Value Loss": 0.0005369240534491837, "_runtime": 2321.379160642624, "_timestamp": 1585511399.7998903, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006080891937017441, "Value Loss": 0.002002706518396735, "_runtime": 2322.93439412117, "_timestamp": 1585511401.3551238, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008841117843985558, "Value Loss": 0.002583631779998541, "_runtime": 2324.5230774879456, "_timestamp": 1585511402.9438071, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015243391506373882, "Value Loss": 0.00012027969933114946, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875, 1580.63232421875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-1580.63232421875, 14862.2890625, 31305.2109375, 47748.1328125, 64191.0546875, 80633.9765625, 97076.8984375, 113519.8203125, 129962.7421875, 146405.671875, 162848.59375, 179291.515625, 195734.4375, 212177.359375, 228620.28125, 245063.203125, 261506.125, 277949.0625, 294391.96875, 310834.875, 327277.8125, 343720.75, 360163.65625, 376606.5625, 393049.5, 409492.4375, 425935.34375, 442378.25, 458821.1875, 475264.125, 491707.03125, 508149.9375, 524592.875, 541035.8125, 557478.75, 573921.625, 590364.5625, 606807.5, 623250.375, 639693.3125, 656136.25, 672579.1875, 689022.125, 705465.0, 721907.9375, 738350.875, 754793.75, 771236.6875, 787679.625, 804122.5625, 820565.5, 837008.375, 853451.3125, 869894.25, 886337.125, 902780.0625, 919223.0, 935665.9375, 952108.875, 968551.75, 984994.6875, 1001437.625, 1017880.5, 1034323.4375, 1050766.375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0], "bins": [-2749.71875, -2706.75439453125, -2663.7900390625, -2620.82568359375, -2577.861328125, -2534.89697265625, -2491.9326171875, -2448.96826171875, -2406.00390625, -2363.03955078125, -2320.0751953125, -2277.11083984375, -2234.146484375, -2191.18212890625, -2148.2177734375, -2105.25341796875, -2062.2890625, -2019.32470703125, -1976.3603515625, -1933.39599609375, -1890.431640625, -1847.46728515625, -1804.5029296875, -1761.53857421875, -1718.57421875, -1675.60986328125, -1632.6455078125, -1589.68115234375, -1546.716796875, -1503.75244140625, -1460.7880859375, -1417.82373046875, -1374.859375, -1331.89501953125, -1288.9306640625, -1245.96630859375, -1203.001953125, -1160.03759765625, -1117.0732421875, -1074.10888671875, -1031.14453125, -988.18017578125, -945.2158203125, -902.25146484375, -859.287109375, -816.32275390625, -773.3583984375, -730.39404296875, -687.4296875, -644.46533203125, -601.5009765625, -558.53662109375, -515.572265625, -472.60791015625, -429.6435546875, -386.67919921875, -343.71484375, -300.75048828125, -257.7861328125, -214.82177734375, -171.857421875, -128.89306640625, -85.9287109375, -42.96435546875, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 1.0, 6.0, 7.0, 3.0, 3.0, 6.0, 2.0, 5.0, 3.0, 5.0, 1.0, 6.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 352.0, 64.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0], "bins": [-125123.2734375, -122087.0859375, -119050.890625, -116014.703125, -112978.515625, -109942.3203125, -106906.1328125, -103869.9375, -100833.75, -97797.5625, -94761.3671875, -91725.1796875, -88688.984375, -85652.796875, -82616.609375, -79580.421875, -76544.2265625, -73508.03125, -70471.84375, -67435.65625, -64399.46484375, -61363.2734375, -58327.0859375, -55290.890625, -52254.703125, -49218.515625, -46182.3203125, -43146.1328125, -40109.9453125, -37073.75, -34037.5625, -31001.3671875, -27965.1796875, -24928.9921875, -21892.796875, -18856.609375, -15820.4140625, -12784.2265625, -9748.0390625, -6711.84375, -3675.65625, -639.46875, 2396.7265625, 5432.9140625, 8469.1015625, 11505.2890625, 14541.4921875, 17577.6796875, 20613.8671875, 23650.0546875, 26686.2421875, 29722.4453125, 32758.6328125, 35794.8203125, 38831.0078125, 41867.1953125, 44903.3828125, 47939.5859375, 50975.7734375, 54011.9609375, 57048.1484375, 60084.3359375, 63120.5390625, 66156.7265625, 69192.9140625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 4.0, 7.0, 5.0, 3.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-25898.0, -23972.978515625, -22047.95703125, -20122.935546875, -18197.9140625, -16272.8916015625, -14347.8701171875, -12422.8486328125, -10497.8271484375, -8572.8046875, -6647.783203125, -4722.76171875, -2797.740234375, -872.71875, 1052.302734375, 2977.32421875, 4902.345703125, 6827.3671875, 8752.390625, 10677.41015625, 12602.43359375, 14527.453125, 16452.4765625, 18377.49609375, 20302.51953125, 22227.5390625, 24152.5625, 26077.58203125, 28002.60546875, 29927.625, 31852.6484375, 33777.66796875, 35702.69140625, 37627.71484375, 39552.734375, 41477.7578125, 43402.78125, 45327.796875, 47252.8203125, 49177.84375, 51102.8671875, 53027.8828125, 54952.90625, 56877.9296875, 58802.953125, 60727.96875, 62652.9921875, 64578.015625, 66503.0390625, 68428.0625, 70353.078125, 72278.1015625, 74203.125, 76128.1484375, 78053.1640625, 79978.1875, 81903.2109375, 83828.234375, 85753.25, 87678.2734375, 89603.296875, 91528.3203125, 93453.3359375, 95378.359375, 97303.3828125]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 14.0, 19.0, 7.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-746325.9375, -732422.3125, -718518.625, -704615.0, -690711.375, -676807.75, -662904.0625, -649000.4375, -635096.75, -621193.125, -607289.5, -593385.875, -579482.1875, -565578.5625, -551674.875, -537771.25, -523867.625, -509964.0, -496060.34375, -482156.6875, -468253.0625, -454349.40625, -440445.75, -426542.125, -412638.46875, -398734.8125, -384831.1875, -370927.53125, -357023.875, -343120.25, -329216.59375, -315312.96875, -301409.3125, -287505.65625, -273602.03125, -259698.375, -245794.75, -231891.09375, -217987.4375, -204083.8125, -190180.1875, -176276.5, -162372.875, -148469.25, -134565.5625, -120661.9375, -106758.3125, -92854.625, -78951.0, -65047.375, -51143.6875, -37240.0625, -23336.4375, -9432.75, 4470.875, 18374.5, 32278.1875, 46181.8125, 60085.4375, 73989.0625, 87892.75, 101796.375, 115700.0, 129603.6875, 143507.3125]}, "_runtime": 2326.076798439026, "_timestamp": 1585511404.497528, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024270646274089813, "Value Loss": 0.002146847313269973, "_runtime": 2327.6319880485535, "_timestamp": 1585511406.0527177, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03146575018763542, "Value Loss": 0.0019005541689693928, "_runtime": 2329.1776711940765, "_timestamp": 1585511407.5984008, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02933167666196823, "Value Loss": 0.0031043218914419413, "_runtime": 2330.720088005066, "_timestamp": 1585511409.1408176, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015352671034634113, "Value Loss": 0.0018328455043956637, "_runtime": 2332.267050743103, "_timestamp": 1585511410.6877804, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011391466483473778, "Value Loss": 0.0013638660311698914, "_runtime": 2333.814096927643, "_timestamp": 1585511412.2348266, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009546343237161636, "Value Loss": 0.000774027721490711, "_runtime": 2335.357306957245, "_timestamp": 1585511413.7780366, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009538252837955952, "Value Loss": 0.002012814860790968, "_runtime": 2336.900602579117, "_timestamp": 1585511415.3213322, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010920492932200432, "Value Loss": 0.0013284168671816587, "_runtime": 2338.4573833942413, "_timestamp": 1585511416.878113, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010017693042755127, "Value Loss": 0.0013774127000942826, "_runtime": 2340.0030403137207, "_timestamp": 1585511418.42377, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0034251960460096598, "Value Loss": 0.003084095660597086, "_runtime": 2341.554761171341, "_timestamp": 1585511419.9754908, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00354213360697031, "Value Loss": 0.003924989141523838, "_runtime": 2343.1101746559143, "_timestamp": 1585511421.5309043, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01634453423321247, "Value Loss": 0.0027479452546685934, "_runtime": 2344.664003133774, "_timestamp": 1585511423.0847328, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018623733893036842, "Value Loss": 0.0017855380428954959, "_runtime": 2346.255208015442, "_timestamp": 1585511424.6759377, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014873722568154335, "Value Loss": 5.22939080838114e-05, "_runtime": 2347.810234308243, "_timestamp": 1585511426.230964, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016498083248734474, "Value Loss": 0.0007653115317225456, "_runtime": 2349.365157842636, "_timestamp": 1585511427.7858875, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010942975990474224, "Value Loss": 0.0002928622125182301, "_runtime": 2350.9192204475403, "_timestamp": 1585511429.33995, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026188120245933533, "Value Loss": 3.650931466836482e-05, "_runtime": 2352.4762976169586, "_timestamp": 1585511430.8970273, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0036194229032844305, "Value Loss": 0.00024406098236795515, "_runtime": 2354.0316100120544, "_timestamp": 1585511432.4523396, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00901475828140974, "Value Loss": 5.624589539365843e-05, "_runtime": 2355.591015815735, "_timestamp": 1585511434.0117455, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012214073911309242, "Value Loss": 8.74364995979704e-05, "_runtime": 2357.145124197006, "_timestamp": 1585511435.5658538, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014219436794519424, "Value Loss": 0.0006794971995986998, "_runtime": 2358.69811463356, "_timestamp": 1585511437.1188443, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010552791878581047, "Value Loss": 0.0005365046090446413, "_runtime": 2360.233233690262, "_timestamp": 1585511438.6539633, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003720270935446024, "Value Loss": 0.0015705849509686232, "_runtime": 2361.780363559723, "_timestamp": 1585511440.2010932, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007124111871235073, "Value Loss": 0.0004023791989311576, "_runtime": 2363.3331661224365, "_timestamp": 1585511441.7538958, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005290433764457703, "Value Loss": 0.00016007335216272622, "_runtime": 2364.8870646953583, "_timestamp": 1585511443.3077943, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012456389144062996, "Value Loss": 0.00310677126981318, "_runtime": 2366.4421384334564, "_timestamp": 1585511444.862868, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002974428003653884, "Value Loss": 0.00011259641905780882, "_runtime": 2367.995999097824, "_timestamp": 1585511446.4167287, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001818884047679603, "Value Loss": 0.003440897213295102, "_runtime": 2369.5744602680206, "_timestamp": 1585511447.99519, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006678563542664051, "Value Loss": 0.0014241610188037157, "_runtime": 2371.1219449043274, "_timestamp": 1585511449.5426745, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01057958323508501, "Value Loss": 0.00152658112347126, "_runtime": 2372.6664531230927, "_timestamp": 1585511451.0871828, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00997526478022337, "Value Loss": 2.0537654563668184e-05, "_runtime": 2374.2228894233704, "_timestamp": 1585511452.643619, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005650279577821493, "Value Loss": 0.0008255395223386586, "_runtime": 2375.771623134613, "_timestamp": 1585511454.1923528, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0022291981149464846, "Value Loss": 0.0004310471413191408, "_runtime": 2377.3152551651, "_timestamp": 1585511455.7359848, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0019997810013592243, "Value Loss": 0.00031029217643663287, "_runtime": 2378.8578503131866, "_timestamp": 1585511457.27858, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00605025002732873, "Value Loss": 0.0004199662071187049, "_runtime": 2380.4187157154083, "_timestamp": 1585511458.8394454, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007500921376049519, "Value Loss": 0.0001854478905443102, "_runtime": 2381.9736280441284, "_timestamp": 1585511460.3943577, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008845588192343712, "Value Loss": 0.0004376776050776243, "_runtime": 2383.5174510478973, "_timestamp": 1585511461.9381807, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008459233678877354, "Value Loss": 0.00039252900751307607, "_runtime": 2385.0750980377197, "_timestamp": 1585511463.4958277, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006590763106942177, "Value Loss": 0.0013002021005377173, "_runtime": 2386.6316409111023, "_timestamp": 1585511465.0523705, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004355803597718477, "Value Loss": 0.0014455666532739997, "_runtime": 2388.174099445343, "_timestamp": 1585511466.594829, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011667883954942226, "Value Loss": 0.0016100432258099318, "_runtime": 2389.7294976711273, "_timestamp": 1585511468.1502273, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012298337183892727, "Value Loss": 0.0010653246426954865, "_runtime": 2391.2853951454163, "_timestamp": 1585511469.7061248, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013601643964648247, "Value Loss": 0.00040857784915715456, "_runtime": 2392.8741159439087, "_timestamp": 1585511471.2948456, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012899345718324184, "Value Loss": 4.0077833546092734e-05, "_runtime": 2394.431558609009, "_timestamp": 1585511472.8522882, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012285284698009491, "Value Loss": 0.0004710657231044024, "_runtime": 2395.973839044571, "_timestamp": 1585511474.3945687, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01038820669054985, "Value Loss": 0.00020534350187517703, "_runtime": 2397.515333175659, "_timestamp": 1585511475.9360628, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008582890965044498, "Value Loss": 0.001966144423931837, "_runtime": 2399.070556163788, "_timestamp": 1585511477.4912858, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005828367546200752, "Value Loss": 0.0019836954306811094, "_runtime": 2400.6267323493958, "_timestamp": 1585511479.047462, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004608763847500086, "Value Loss": 8.143307059071958e-05, "_runtime": 2402.1786901950836, "_timestamp": 1585511480.5994198, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006511353421956301, "Value Loss": 0.0013254336081445217, "_runtime": 2403.7348515987396, "_timestamp": 1585511482.1555812, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009329159744083881, "Value Loss": 0.00020552064233925194, "_runtime": 2405.2780401706696, "_timestamp": 1585511483.6987698, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015161784365773201, "Value Loss": 0.001296111848205328, "_runtime": 2406.8301672935486, "_timestamp": 1585511485.250897, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009775900281965733, "Value Loss": 0.00025463494239374995, "_runtime": 2408.385405063629, "_timestamp": 1585511486.8061347, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007201695814728737, "Value Loss": 0.0007265913882292807, "_runtime": 2409.9408435821533, "_timestamp": 1585511488.3615732, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004735895898193121, "Value Loss": 0.000914167903829366, "_runtime": 2411.495167016983, "_timestamp": 1585511489.9158967, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004157485906034708, "Value Loss": 0.00032159005058929324, "_runtime": 2413.0519864559174, "_timestamp": 1585511491.472716, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004369028378278017, "Value Loss": 0.0005915805813856423, "_runtime": 2414.606184720993, "_timestamp": 1585511493.0269144, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0057280841283500195, "Value Loss": 0.00011953616922255605, "_runtime": 2416.180582046509, "_timestamp": 1585511494.6013117, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006758042145520449, "Value Loss": 0.0015177730238065124, "_runtime": 2417.713218688965, "_timestamp": 1585511496.1339483, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009136558510363102, "Value Loss": 0.00015598678146488965, "_runtime": 2419.270201444626, "_timestamp": 1585511497.690931, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009749422781169415, "Value Loss": 0.0003104601928498596, "_runtime": 2420.8251791000366, "_timestamp": 1585511499.2459087, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007508774753659964, "Value Loss": 0.00021629063121508807, "_runtime": 2422.3679008483887, "_timestamp": 1585511500.7886305, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006191438529640436, "Value Loss": 0.00012953266559634358, "_runtime": 2423.914116382599, "_timestamp": 1585511502.334846, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006687569431960583, "Value Loss": 0.0010329766664654016, "_runtime": 2425.4593057632446, "_timestamp": 1585511503.8800354, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003285482758656144, "Value Loss": 0.0011254969285801053, "_runtime": 2427.004983186722, "_timestamp": 1585511505.4257128, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0045025162398815155, "Value Loss": 2.9452412491082214e-05, "_runtime": 2428.559676170349, "_timestamp": 1585511506.9804058, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00949652586132288, "Value Loss": 0.0023243699688464403, "_runtime": 2430.115044593811, "_timestamp": 1585511508.5357742, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010981506668031216, "Value Loss": 0.000488826131913811, "_runtime": 2431.6694848537445, "_timestamp": 1585511510.0902145, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017178766429424286, "Value Loss": 0.001794360694475472, "_runtime": 2433.224520921707, "_timestamp": 1585511511.6452506, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009573720395565033, "Value Loss": 0.0008191440720111132, "_runtime": 2434.7758145332336, "_timestamp": 1585511513.1965442, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005511268507689238, "Value Loss": 4.04558886657469e-05, "_runtime": 2436.331202507019, "_timestamp": 1585511514.7519321, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003497708821669221, "Value Loss": 3.31007395288907e-05, "_runtime": 2437.8627376556396, "_timestamp": 1585511516.2834673, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0047450801357626915, "Value Loss": 0.0009467919589951634, "_runtime": 2439.4511272907257, "_timestamp": 1585511517.871857, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004553043283522129, "Value Loss": 0.00022186824935488403, "_runtime": 2440.9944429397583, "_timestamp": 1585511519.4151726, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004288139753043652, "Value Loss": 0.0007574707851745188, "_runtime": 2442.5410056114197, "_timestamp": 1585511520.9617352, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006392291281372309, "Value Loss": 0.0002554975508246571, "_runtime": 2444.0940885543823, "_timestamp": 1585511522.5148182, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00777113251388073, "Value Loss": 0.000261531095020473, "_runtime": 2445.648400068283, "_timestamp": 1585511524.0691297, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0058183977380394936, "Value Loss": 7.848565292079002e-05, "_runtime": 2447.201395750046, "_timestamp": 1585511525.6221254, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004775439854711294, "Value Loss": 1.1269627066212706e-05, "_runtime": 2448.754716873169, "_timestamp": 1585511527.1754465, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0052542900666594505, "Value Loss": 9.024520113598555e-05, "_runtime": 2450.3097348213196, "_timestamp": 1585511528.7304645, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0040867989882826805, "Value Loss": 0.00015452364459633827, "_runtime": 2451.842237472534, "_timestamp": 1585511530.262967, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003507391782477498, "Value Loss": 0.00100770965218544, "_runtime": 2453.3958060741425, "_timestamp": 1585511531.8165357, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0046442351303994656, "Value Loss": 3.6135434129391797e-06, "_runtime": 2454.9495120048523, "_timestamp": 1585511533.3702416, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008648775517940521, "Value Loss": 0.00038187485188245773, "_runtime": 2456.502277612686, "_timestamp": 1585511534.9230072, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010322336107492447, "Value Loss": 0.0001292260130867362, "_runtime": 2458.053510904312, "_timestamp": 1585511536.4742405, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01022535189986229, "Value Loss": 3.3218591852346435e-05, "_runtime": 2459.5886697769165, "_timestamp": 1585511538.0093994, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013171728700399399, "Value Loss": 0.0015361470868811011, "_runtime": 2461.1798977851868, "_timestamp": 1585511539.6006274, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005826890934258699, "Value Loss": 0.00028193031903356314, "_runtime": 2462.733112335205, "_timestamp": 1585511541.153842, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002391502493992448, "Value Loss": 0.00140251568518579, "_runtime": 2464.2877678871155, "_timestamp": 1585511542.7084975, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016020288458094, "Value Loss": 0.0002043619897449389, "_runtime": 2465.8327968120575, "_timestamp": 1585511544.2535264, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003640567185357213, "Value Loss": 0.0002373607421759516, "_runtime": 2467.3867514133453, "_timestamp": 1585511545.807481, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0035454947501420975, "Value Loss": 0.00016855633293744177, "_runtime": 2468.9426527023315, "_timestamp": 1585511547.3633823, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00403503468260169, "Value Loss": 0.00020151963690295815, "_runtime": 2470.4757554531097, "_timestamp": 1585511548.896485, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003717726096510887, "Value Loss": 0.0006797550013288856, "_runtime": 2472.029512166977, "_timestamp": 1585511550.4502418, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0034671060275286436, "Value Loss": 0.0006934564444236457, "_runtime": 2473.585303544998, "_timestamp": 1585511552.0060332, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0033580539748072624, "Value Loss": 0.0003027259954251349, "_runtime": 2475.138841867447, "_timestamp": 1585511553.5595715, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002675014780834317, "Value Loss": 0.00038353950367309153, "_runtime": 2476.6920926570892, "_timestamp": 1585511555.1128223, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004543889779597521, "Value Loss": 0.0009069445659406483, "_runtime": 2478.2469685077667, "_timestamp": 1585511556.6676981, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0035600627306848764, "Value Loss": 1.2157079254393466e-05, "_runtime": 2479.8013536930084, "_timestamp": 1585511558.2220833, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006163972895592451, "Value Loss": 0.0006915355334058404, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625, 17078.12890625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-17078.12890625, 5173.240234375, 27424.609375, 49675.98046875, 71927.34375, 94178.71875, 116430.09375, 138681.453125, 160932.828125, 183184.203125, 205435.5625, 227686.9375, 249938.3125, 272189.6875, 294441.03125, 316692.40625, 338943.78125, 361195.15625, 383446.53125, 405697.875, 427949.25, 450200.625, 472452.0, 494703.375, 516954.75, 539206.125, 561457.5, 583708.8125, 605960.1875, 628211.5625, 650462.9375, 672714.3125, 694965.6875, 717217.0625, 739468.4375, 761719.8125, 783971.1875, 806222.5625, 828473.875, 850725.25, 872976.625, 895228.0, 917479.375, 939730.75, 961982.125, 984233.5, 1006484.875, 1028736.25, 1050987.625, 1073239.0, 1095490.375, 1117741.75, 1139993.125, 1162244.5, 1184495.75, 1206747.125, 1228998.5, 1251249.875, 1273501.25, 1295752.625, 1318004.0, 1340255.375, 1362506.75, 1384758.125, 1407009.5]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0], "bins": [-30420.677734375, -29945.35546875, -29470.03125, -28994.708984375, -28519.384765625, -28044.0625, -27568.73828125, -27093.416015625, -26618.09375, -26142.76953125, -25667.447265625, -25192.123046875, -24716.80078125, -24241.4765625, -23766.154296875, -23290.83203125, -22815.5078125, -22340.185546875, -21864.86328125, -21389.5390625, -20914.21484375, -20438.892578125, -19963.5703125, -19488.24609375, -19012.923828125, -18537.6015625, -18062.27734375, -17586.953125, -17111.630859375, -16636.30859375, -16160.9853515625, -15685.662109375, -15210.3388671875, -14735.015625, -14259.6923828125, -13784.369140625, -13309.046875, -12833.72265625, -12358.400390625, -11883.078125, -11407.75390625, -10932.431640625, -10457.107421875, -9981.78515625, -9506.4609375, -9031.138671875, -8555.81640625, -8080.4921875, -7605.169921875, -7129.845703125, -6654.5234375, -6179.19921875, -5703.876953125, -5228.5546875, -4753.23046875, -4277.908203125, -3802.583984375, -3327.26171875, -2851.939453125, -2376.615234375, -1901.29296875, -1425.96875, -950.646484375, -475.322265625, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 2.0, 2.0, 5.0, 1.0, 5.0, 1.0, 7.0, 5.0, 1.0, 7.0, 3.0, 0.0, 1.0, 2.0, 5.0, 5.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 352.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 13.0, 44.0, 24.0], "bins": [-171197.609375, -168052.15625, -164906.703125, -161761.234375, -158615.78125, -155470.328125, -152324.875, -149179.421875, -146033.96875, -142888.5, -139743.046875, -136597.59375, -133452.140625, -130306.6796875, -127161.2265625, -124015.765625, -120870.3125, -117724.859375, -114579.3984375, -111433.9453125, -108288.484375, -105143.03125, -101997.578125, -98852.1171875, -95706.6640625, -92561.2109375, -89415.75, -86270.296875, -83124.84375, -79979.3828125, -76833.9296875, -73688.46875, -70543.015625, -67397.5625, -64252.1015625, -61106.6484375, -57961.1875, -54815.734375, -51670.28125, -48524.8203125, -45379.3671875, -42233.9140625, -39088.453125, -35943.0, -32797.546875, -29652.09375, -26506.625, -23361.171875, -20215.71875, -17070.265625, -13924.8125, -10779.34375, -7633.890625, -4488.4375, -1342.984375, 1802.46875, 4947.921875, 8093.390625, 11238.84375, 14384.296875, 17529.75, 20675.203125, 23820.671875, 26966.125, 30111.578125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 3.0, 2.0, 1.0], "bins": [-298905.4375, -293815.4375, -288725.4375, -283635.46875, -278545.46875, -273455.46875, -268365.5, -263275.5, -258185.5, -253095.5, -248005.515625, -242915.53125, -237825.53125, -232735.53125, -227645.546875, -222555.5625, -217465.5625, -212375.5625, -207285.578125, -202195.59375, -197105.59375, -192015.59375, -186925.609375, -181835.625, -176745.625, -171655.625, -166565.640625, -161475.65625, -156385.65625, -151295.65625, -146205.671875, -141115.6875, -136025.6875, -130935.6875, -125845.703125, -120755.71875, -115665.71875, -110575.71875, -105485.734375, -100395.75, -95305.75, -90215.75, -85125.765625, -80035.78125, -74945.78125, -69855.78125, -64765.796875, -59675.8125, -54585.8125, -49495.8125, -44405.828125, -39315.84375, -34225.84375, -29135.84375, -24045.875, -18955.875, -13865.875, -8775.875, -3685.875, 1404.09375, 6494.09375, 11584.09375, 16674.0625, 21764.0625, 26854.0625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 4.0, 22.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-33567.08203125, -27425.599609375, -21284.1171875, -15142.63671875, -9001.154296875, -2859.671875, 3281.80859375, 9423.29296875, 15564.7734375, 21706.25390625, 27847.73828125, 33989.22265625, 40130.69921875, 46272.18359375, 52413.66796875, 58555.14453125, 64696.62890625, 70838.109375, 76979.59375, 83121.078125, 89262.5625, 95404.03125, 101545.53125, 107687.0, 113828.484375, 119969.96875, 126111.453125, 132252.9375, 138394.421875, 144535.890625, 150677.375, 156818.859375, 162960.34375, 169101.828125, 175243.3125, 181384.796875, 187526.265625, 193667.75, 199809.234375, 205950.71875, 212092.203125, 218233.6875, 224375.15625, 230516.640625, 236658.140625, 242799.609375, 248941.078125, 255082.578125, 261224.046875, 267365.53125, 273507.0, 279648.5, 285789.96875, 291931.4375, 298072.9375, 304214.40625, 310355.90625, 316497.375, 322638.84375, 328780.34375, 334921.8125, 341063.3125, 347204.78125, 353346.28125, 359487.75]}, "_runtime": 2481.344098329544, "_timestamp": 1585511559.764828, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006074423901736736, "Value Loss": 0.0007779703591950238, "_runtime": 2482.9005353450775, "_timestamp": 1585511561.321265, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004493326414376497, "Value Loss": 9.565192885929719e-05, "_runtime": 2484.4916677474976, "_timestamp": 1585511562.9123974, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014263318153098226, "Value Loss": 1.6570686057093553e-05, "_runtime": 2486.0444757938385, "_timestamp": 1585511564.4652054, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005319968331605196, "Value Loss": 0.00019106159743387252, "_runtime": 2487.6006684303284, "_timestamp": 1585511566.021398, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002858946332708001, "Value Loss": 1.97013341676211e-05, "_runtime": 2489.15594291687, "_timestamp": 1585511567.5766726, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004116977099329233, "Value Loss": 0.0004226785385981202, "_runtime": 2490.7074370384216, "_timestamp": 1585511569.1281667, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018374696373939514, "Value Loss": 0.001272115157917142, "_runtime": 2492.2416830062866, "_timestamp": 1585511570.6624126, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006239860085770488, "Value Loss": 5.609658273897367e-06, "_runtime": 2493.7975895404816, "_timestamp": 1585511572.2183192, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007063193246722221, "Value Loss": 9.302546095568687e-05, "_runtime": 2495.350127696991, "_timestamp": 1585511573.7708573, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01003765594214201, "Value Loss": 0.0007470108103007078, "_runtime": 2496.904988527298, "_timestamp": 1585511575.3257182, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007058240938931704, "Value Loss": 0.00011444578558439389, "_runtime": 2498.462751865387, "_timestamp": 1585511576.8834815, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004653081297874451, "Value Loss": 0.0006953976699151099, "_runtime": 2500.0170652866364, "_timestamp": 1585511578.437795, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0004207699385005981, "Value Loss": 0.0007448791293427348, "_runtime": 2501.563136816025, "_timestamp": 1585511579.9838665, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002101864432916045, "Value Loss": 0.0003960582544095814, "_runtime": 2503.112421989441, "_timestamp": 1585511581.5331516, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0028648681472986937, "Value Loss": 6.503903568955138e-05, "_runtime": 2504.656460046768, "_timestamp": 1585511583.0771897, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002731895772740245, "Value Loss": 1.8711281882133335e-05, "_runtime": 2506.2018423080444, "_timestamp": 1585511584.622572, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007171521428972483, "Value Loss": 1.979425860554329e-06, "_runtime": 2507.793104171753, "_timestamp": 1585511586.2138338, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009764992282725871, "Value Loss": 0.00017825172108132392, "_runtime": 2509.336108446121, "_timestamp": 1585511587.756838, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00591182429343462, "Value Loss": 0.0011299356119707227, "_runtime": 2510.891478538513, "_timestamp": 1585511589.3122082, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004317713435739279, "Value Loss": 0.00018521700985729694, "_runtime": 2512.437751054764, "_timestamp": 1585511590.8584807, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002686278196051717, "Value Loss": 0.0005872530164197087, "_runtime": 2513.9818379879, "_timestamp": 1585511592.4025676, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004197000991553068, "Value Loss": 0.0009776747319847345, "_runtime": 2515.535094022751, "_timestamp": 1585511593.9558237, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004546235781162977, "Value Loss": 0.0004061661020386964, "_runtime": 2517.0933651924133, "_timestamp": 1585511595.5140948, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00425497954711318, "Value Loss": 0.00012156586308265105, "_runtime": 2518.645398378372, "_timestamp": 1585511597.066128, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0062148491851985455, "Value Loss": 0.0013602072140201926, "_runtime": 2520.200642347336, "_timestamp": 1585511598.621372, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003325499128550291, "Value Loss": 4.5948334445711225e-05, "_runtime": 2521.754047393799, "_timestamp": 1585511600.174777, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018087911885231733, "Value Loss": 0.00011813009041361511, "_runtime": 2523.3088555336, "_timestamp": 1585511601.7295852, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004524522228166461, "Value Loss": 9.088827937375754e-05, "_runtime": 2524.8427987098694, "_timestamp": 1585511603.2635283, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005946976016275585, "Value Loss": 0.0003265668638050556, "_runtime": 2526.3978452682495, "_timestamp": 1585511604.818575, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00040639445069245994, "Value Loss": 0.0010084431851282716, "_runtime": 2527.948837041855, "_timestamp": 1585511606.3695667, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0050309691578149796, "Value Loss": 0.000998724135570228, "_runtime": 2529.49365401268, "_timestamp": 1585511607.9143836, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008323946967720985, "Value Loss": 0.00014221135643310845, "_runtime": 2531.0829026699066, "_timestamp": 1585511609.5036323, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012471730820834637, "Value Loss": 0.001059210393577814, "_runtime": 2532.62411403656, "_timestamp": 1585511611.0448437, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0033275147434324026, "Value Loss": 1.225390315084951e-05, "_runtime": 2534.1799573898315, "_timestamp": 1585511612.600687, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0009925966151058674, "Value Loss": 0.0010386091889813542, "_runtime": 2535.725602865219, "_timestamp": 1585511614.1463325, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005173503886908293, "Value Loss": 0.00022132662707008421, "_runtime": 2537.2788009643555, "_timestamp": 1585511615.6995306, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000832435442134738, "Value Loss": 0.00018034620734397322, "_runtime": 2538.8239030838013, "_timestamp": 1585511617.2446327, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004436984192579985, "Value Loss": 0.00010249069600831717, "_runtime": 2540.37872338295, "_timestamp": 1585511618.799453, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006017286330461502, "Value Loss": 0.0003893696120940149, "_runtime": 2541.932398557663, "_timestamp": 1585511620.3531282, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008429127745330334, "Value Loss": 0.0008620969019830227, "_runtime": 2543.4757401943207, "_timestamp": 1585511621.8964698, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008008060976862907, "Value Loss": 0.0009705538977868855, "_runtime": 2545.0191717147827, "_timestamp": 1585511623.4399014, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005631681066006422, "Value Loss": 0.00014120808918960392, "_runtime": 2546.563242673874, "_timestamp": 1585511624.9839723, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004638876300305128, "Value Loss": 0.00027108346694149077, "_runtime": 2548.1060526371, "_timestamp": 1585511626.5267823, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002140466822311282, "Value Loss": 5.418860018835403e-05, "_runtime": 2549.648956298828, "_timestamp": 1585511628.069686, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000812619982752949, "Value Loss": 0.0005179984145797789, "_runtime": 2551.181261777878, "_timestamp": 1585511629.6019914, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0029133378993719816, "Value Loss": 0.0009395731030963361, "_runtime": 2552.750678539276, "_timestamp": 1585511631.1714082, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005963701289147139, "Value Loss": 0.0005941762938164175, "_runtime": 2554.2930042743683, "_timestamp": 1585511632.713734, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006333466619253159, "Value Loss": 1.4720845683768857e-05, "_runtime": 2555.8324654102325, "_timestamp": 1585511634.253195, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008225439116358757, "Value Loss": 0.00010021391062764451, "_runtime": 2557.3760316371918, "_timestamp": 1585511635.7967613, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006634855642914772, "Value Loss": 9.22290109883761e-06, "_runtime": 2558.9298622608185, "_timestamp": 1585511637.350592, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007180934306234121, "Value Loss": 0.00028697511879727244, "_runtime": 2560.478581905365, "_timestamp": 1585511638.8993115, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004495171830058098, "Value Loss": 0.0004006366361863911, "_runtime": 2562.020728111267, "_timestamp": 1585511640.4414577, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001932850107550621, "Value Loss": 9.1148292995058e-05, "_runtime": 2563.564172744751, "_timestamp": 1585511641.9849024, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5767620425322093e-05, "Value Loss": 7.858200660848524e-06, "_runtime": 2565.0961594581604, "_timestamp": 1585511643.516889, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008856109925545752, "Value Loss": 6.210248830029741e-05, "_runtime": 2566.628886938095, "_timestamp": 1585511645.0496166, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001458893297240138, "Value Loss": 5.068549944553524e-05, "_runtime": 2568.16401553154, "_timestamp": 1585511646.5847452, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0031167028937488794, "Value Loss": 1.993839759961702e-05, "_runtime": 2569.7044146060944, "_timestamp": 1585511648.1251442, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026972086634486914, "Value Loss": 0.00011004183761542663, "_runtime": 2571.2482862472534, "_timestamp": 1585511649.669016, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008296460728161037, "Value Loss": 0.0003866162442136556, "_runtime": 2572.7904148101807, "_timestamp": 1585511651.2111444, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002128956373780966, "Value Loss": 0.0001121399545809254, "_runtime": 2574.3327672481537, "_timestamp": 1585511652.753497, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005882834549993277, "Value Loss": 0.00046585360541939735, "_runtime": 2575.9123780727386, "_timestamp": 1585511654.3331077, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003989189397543669, "Value Loss": 0.00013088285049889237, "_runtime": 2577.448651790619, "_timestamp": 1585511655.8693814, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010916672181338072, "Value Loss": 1.394420337419433e-06, "_runtime": 2578.9912900924683, "_timestamp": 1585511657.4120197, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007187553565017879, "Value Loss": 5.9615027566906065e-05, "_runtime": 2580.5338304042816, "_timestamp": 1585511658.95456, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0037147083785384893, "Value Loss": 1.5020214050309733e-05, "_runtime": 2582.0783789157867, "_timestamp": 1585511660.4991086, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002956580137833953, "Value Loss": 0.0006776556838303804, "_runtime": 2583.6205191612244, "_timestamp": 1585511662.0412488, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0034890470560640097, "Value Loss": 0.00021914950048085302, "_runtime": 2585.163250684738, "_timestamp": 1585511663.5839803, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010809583589434624, "Value Loss": 0.00027653263532556593, "_runtime": 2586.704563140869, "_timestamp": 1585511665.1252928, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012348446995019913, "Value Loss": 0.00020360360213089734, "_runtime": 2588.2454760074615, "_timestamp": 1585511666.6662056, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013232373632490635, "Value Loss": 0.0007999017252586782, "_runtime": 2589.7999489307404, "_timestamp": 1585511668.2206786, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0027305439580231905, "Value Loss": 3.8978173506620806e-06, "_runtime": 2591.355329275131, "_timestamp": 1585511669.776059, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005383742973208427, "Value Loss": 0.00012006940960418433, "_runtime": 2592.9066908359528, "_timestamp": 1585511671.3274205, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009894726797938347, "Value Loss": 0.0009690242004580796, "_runtime": 2594.463744878769, "_timestamp": 1585511672.8844745, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003397034713998437, "Value Loss": 0.0004133225593250245, "_runtime": 2596.017877101898, "_timestamp": 1585511674.4386067, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006562272552400827, "Value Loss": 3.0346471248776652e-05, "_runtime": 2597.570010662079, "_timestamp": 1585511675.9907403, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01529129408299923, "Value Loss": 3.799911792157218e-05, "_runtime": 2599.161814212799, "_timestamp": 1585511677.5825438, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021718375384807587, "Value Loss": 0.0003145000373478979, "_runtime": 2600.707458972931, "_timestamp": 1585511679.1281886, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022983895614743233, "Value Loss": 0.0008777269977144897, "_runtime": 2602.260272026062, "_timestamp": 1585511680.6810017, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015156043693423271, "Value Loss": 4.0955226722871885e-05, "_runtime": 2603.818293571472, "_timestamp": 1585511682.2390232, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005698390770703554, "Value Loss": 0.00014339860354084522, "_runtime": 2605.3687620162964, "_timestamp": 1585511683.7894917, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004469036590307951, "Value Loss": 3.895599365932867e-05, "_runtime": 2606.9236731529236, "_timestamp": 1585511685.3444028, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014475069008767605, "Value Loss": 0.0002933731593657285, "_runtime": 2608.4829530715942, "_timestamp": 1585511686.9036827, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021537013351917267, "Value Loss": 0.00018453637312632054, "_runtime": 2610.025050163269, "_timestamp": 1585511688.4457798, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024948572739958763, "Value Loss": 0.0003490443923510611, "_runtime": 2611.5673961639404, "_timestamp": 1585511689.9881258, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02297581546008587, "Value Loss": 0.0001307467755395919, "_runtime": 2613.109375, "_timestamp": 1585511691.5301046, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019093921408057213, "Value Loss": 0.0003933830885216594, "_runtime": 2614.655872106552, "_timestamp": 1585511693.0766017, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007264991756528616, "Value Loss": 0.0008915309445001185, "_runtime": 2616.2082867622375, "_timestamp": 1585511694.6290164, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009754179045557976, "Value Loss": 0.0002897676604334265, "_runtime": 2617.7627787590027, "_timestamp": 1585511696.1835084, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020329128950834274, "Value Loss": 0.0007046750979498029, "_runtime": 2619.317760705948, "_timestamp": 1585511697.7384903, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02389887347817421, "Value Loss": 0.0009077602881006896, "_runtime": 2620.861760377884, "_timestamp": 1585511699.28249, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013345589861273766, "Value Loss": 0.0009993142448365688, "_runtime": 2622.442563533783, "_timestamp": 1585511700.8632932, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007619586773216724, "Value Loss": 0.00010669665061868727, "_runtime": 2623.997433900833, "_timestamp": 1585511702.4181635, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.026780802756547928, "Value Loss": 0.0021069657523185015, "_runtime": 2625.546251296997, "_timestamp": 1585511703.966981, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019941460341215134, "Value Loss": 0.0002285254158778116, "_runtime": 2627.1025969982147, "_timestamp": 1585511705.5233266, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011569182388484478, "Value Loss": 0.0002225990901933983, "_runtime": 2628.6487350463867, "_timestamp": 1585511707.0694647, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029860215727239847, "Value Loss": 0.0005235393182374537, "_runtime": 2630.1912524700165, "_timestamp": 1585511708.611982, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006043106317520142, "Value Loss": 0.0001096193736884743, "_runtime": 2631.7409291267395, "_timestamp": 1585511710.1616588, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01413813792169094, "Value Loss": 0.000534624035935849, "_runtime": 2633.2746856212616, "_timestamp": 1585511711.6954153, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013543897308409214, "Value Loss": 0.00010102549276780337, "_runtime": 2634.8161828517914, "_timestamp": 1585511713.2369125, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012847214005887508, "Value Loss": 7.923780503915623e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2636.360132932663, "_timestamp": 1585511714.7808626, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011517208069562912, "Value Loss": 0.0006310224998742342, "_runtime": 2637.914877176285, "_timestamp": 1585511716.3356068, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006512411870062351, "Value Loss": 0.0002558933920226991, "_runtime": 2639.468156814575, "_timestamp": 1585511717.8888865, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0034732746426016092, "Value Loss": 0.0003925170167349279, "_runtime": 2641.022944688797, "_timestamp": 1585511719.4436743, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002443852601572871, "Value Loss": 0.0004542883252725005, "_runtime": 2642.5772247314453, "_timestamp": 1585511720.9979544, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000503028801176697, "Value Loss": 8.650888958072755e-06, "_runtime": 2644.128439426422, "_timestamp": 1585511722.549169, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006989085231907666, "Value Loss": 0.000345515989465639, "_runtime": 2645.719571828842, "_timestamp": 1585511724.1403015, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0030560654122382402, "Value Loss": 3.443753666942939e-05, "_runtime": 2647.2722885608673, "_timestamp": 1585511725.6930182, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005348654929548502, "Value Loss": 8.112680370686576e-05, "_runtime": 2648.8263623714447, "_timestamp": 1585511727.247092, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0063978456892073154, "Value Loss": 2.2167563656694256e-05, "_runtime": 2650.359262228012, "_timestamp": 1585511728.7799919, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006328272167593241, "Value Loss": 4.8127803893294185e-06, "_runtime": 2651.903180360794, "_timestamp": 1585511730.32391, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007453725207597017, "Value Loss": 2.2334814275382087e-05, "_runtime": 2653.457404613495, "_timestamp": 1585511731.8781343, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00587613508105278, "Value Loss": 6.668075366178527e-05, "_runtime": 2655.010926961899, "_timestamp": 1585511733.4316566, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004002667032182217, "Value Loss": 4.972655005985871e-05, "_runtime": 2656.5650551319122, "_timestamp": 1585511734.9857848, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016169490991160274, "Value Loss": 1.10039973151288e-05, "_runtime": 2658.102643728256, "_timestamp": 1585511736.5233734, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0022127125412225723, "Value Loss": 0.00036172347608953714, "_runtime": 2659.648505449295, "_timestamp": 1585511738.069235, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0031648220028728247, "Value Loss": 3.6969818211218808e-06, "_runtime": 2661.1914477348328, "_timestamp": 1585511739.6121774, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007195351645350456, "Value Loss": 0.00037725799484178424, "_runtime": 2662.7432351112366, "_timestamp": 1585511741.1639647, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008793565444648266, "Value Loss": 3.605311212595552e-05, "_runtime": 2664.2972371578217, "_timestamp": 1585511742.7179668, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008274580352008343, "Value Loss": 0.0004950379952788353, "_runtime": 2665.851480484009, "_timestamp": 1585511744.2722101, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004326485097408295, "Value Loss": 5.368721394916065e-05, "_runtime": 2667.4388086795807, "_timestamp": 1585511745.8595383, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000722966156899929, "Value Loss": 0.00020877159840893, "_runtime": 2668.9933018684387, "_timestamp": 1585511747.4140315, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017643203027546406, "Value Loss": 0.0005933697684668005, "_runtime": 2670.54776263237, "_timestamp": 1585511748.9684923, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005548863671720028, "Value Loss": 0.00035125785507261753, "_runtime": 2672.0921993255615, "_timestamp": 1585511750.512929, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011701514944434166, "Value Loss": 0.00014316361921373755, "_runtime": 2673.6464207172394, "_timestamp": 1585511752.0671504, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01740887202322483, "Value Loss": 0.0002677783486433327, "_runtime": 2675.1895866394043, "_timestamp": 1585511753.6103163, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01816774718463421, "Value Loss": 0.00018487832858227193, "_runtime": 2676.741385936737, "_timestamp": 1585511755.1621156, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018803754821419716, "Value Loss": 0.0004564868286252022, "_runtime": 2678.286732673645, "_timestamp": 1585511756.7074623, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012717238627374172, "Value Loss": 0.00034640953526832163, "_runtime": 2679.8292853832245, "_timestamp": 1585511758.250015, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005524649168364704, "Value Loss": 0.0002531683712732047, "_runtime": 2681.383177757263, "_timestamp": 1585511759.8039074, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009623833000659943, "Value Loss": 8.199363946914673e-05, "_runtime": 2682.928662776947, "_timestamp": 1585511761.3493924, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018906667828559875, "Value Loss": 0.00013737699191551656, "_runtime": 2684.485146999359, "_timestamp": 1585511762.9058766, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023088468238711357, "Value Loss": 0.0002956524840556085, "_runtime": 2686.03808426857, "_timestamp": 1585511764.458814, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02460644021630287, "Value Loss": 0.0027121268212795258, "_runtime": 2687.5923070907593, "_timestamp": 1585511766.0130367, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003957787062972784, "Value Loss": 2.575072585386806e-06, "_runtime": 2689.1365036964417, "_timestamp": 1585511767.5572333, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.032986339181661606, "Value Loss": 0.0027611262630671263, "_runtime": 2690.725646018982, "_timestamp": 1585511769.1463757, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02545374073088169, "Value Loss": 0.0013880312908440828, "_runtime": 2692.2758417129517, "_timestamp": 1585511770.6965714, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017068430315703154, "Value Loss": 7.328000720008276e-06, "_runtime": 2693.8193287849426, "_timestamp": 1585511772.2400584, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023123379796743393, "Value Loss": 0.0008226969512179494, "_runtime": 2695.3727293014526, "_timestamp": 1585511773.793459, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03134531527757645, "Value Loss": 0.0013443785719573498, "_runtime": 2696.9268584251404, "_timestamp": 1585511775.347588, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024711305275559425, "Value Loss": 0.00022548134438693523, "_runtime": 2698.487427711487, "_timestamp": 1585511776.9081573, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01466694287955761, "Value Loss": 0.001757671358063817, "_runtime": 2700.0432183742523, "_timestamp": 1585511778.463948, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018883856013417244, "Value Loss": 0.00037530294503085315, "_runtime": 2701.598247528076, "_timestamp": 1585511780.0189772, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04240156710147858, "Value Loss": 0.00029155833180993795, "_runtime": 2703.1513061523438, "_timestamp": 1585511781.5720358, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06308148056268692, "Value Loss": 0.003938887733966112, "_runtime": 2704.693006515503, "_timestamp": 1585511783.1137362, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05386018380522728, "Value Loss": 0.0035092411562800407, "_runtime": 2706.2357375621796, "_timestamp": 1585511784.6564672, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027775339782238007, "Value Loss": 0.000380245823180303, "_runtime": 2707.7883701324463, "_timestamp": 1585511786.2090998, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000993898487649858, "Value Loss": 0.0003152051067445427, "_runtime": 2709.341602087021, "_timestamp": 1585511787.7623317, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027630643919110298, "Value Loss": 0.003526957705616951, "_runtime": 2710.8861553668976, "_timestamp": 1585511789.306885, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016131723299622536, "Value Loss": 9.310813038609922e-05, "_runtime": 2712.4301290512085, "_timestamp": 1585511790.8508587, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004451569635421038, "Value Loss": 1.5402409189846367e-05, "_runtime": 2714.0182898044586, "_timestamp": 1585511792.4390194, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007865668274462223, "Value Loss": 1.128676285588881e-05, "_runtime": 2715.5560262203217, "_timestamp": 1585511793.9767559, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01887848973274231, "Value Loss": 0.0013930207351222634, "_runtime": 2717.109795808792, "_timestamp": 1585511795.5305254, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007790309377014637, "Value Loss": 0.0005017973016947508, "_runtime": 2718.664415359497, "_timestamp": 1585511797.085145, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010412990115582943, "Value Loss": 0.0002111449430231005, "_runtime": 2720.217235326767, "_timestamp": 1585511798.637965, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.023970426991581917, "Value Loss": 0.0019372910028323531, "_runtime": 2721.7590985298157, "_timestamp": 1585511800.1798282, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015494996681809425, "Value Loss": 0.0003164355002809316, "_runtime": 2723.313366174698, "_timestamp": 1585511801.7340958, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00024384702555835247, "Value Loss": 2.6048031941172667e-05, "_runtime": 2724.856724500656, "_timestamp": 1585511803.2774541, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014209211803972721, "Value Loss": 3.123285932815634e-05, "_runtime": 2726.3915235996246, "_timestamp": 1585511804.8122532, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02635537087917328, "Value Loss": 0.00021943695901427418, "_runtime": 2727.937436103821, "_timestamp": 1585511806.3581657, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03271389380097389, "Value Loss": 0.002118863398209214, "_runtime": 2729.4911653995514, "_timestamp": 1585511807.911895, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017861997708678246, "Value Loss": 0.0005393561441451311, "_runtime": 2731.0360403060913, "_timestamp": 1585511809.45677, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0052651893347501755, "Value Loss": 0.00016335952386725694, "_runtime": 2732.577175617218, "_timestamp": 1585511810.9979053, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021194180473685265, "Value Loss": 0.00168539397418499, "_runtime": 2734.121312379837, "_timestamp": 1585511812.542042, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013324028812348843, "Value Loss": 0.0001854253641795367, "_runtime": 2735.673840045929, "_timestamp": 1585511814.0945697, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004115094896405935, "Value Loss": 7.520975486841053e-06, "_runtime": 2737.2510344982147, "_timestamp": 1585511815.6717641, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005028979387134314, "Value Loss": 0.0003558384778443724, "_runtime": 2738.8079073429108, "_timestamp": 1585511817.228637, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006193030625581741, "Value Loss": 4.5484237489290535e-05, "_runtime": 2740.3648438453674, "_timestamp": 1585511818.7855735, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005872788839042187, "Value Loss": 6.376186502166092e-05, "_runtime": 2741.9193065166473, "_timestamp": 1585511820.3400362, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002594137331470847, "Value Loss": 0.00012046819756506011, "_runtime": 2743.4669098854065, "_timestamp": 1585511821.8876395, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008239090093411505, "Value Loss": 3.354574801051058e-05, "_runtime": 2745.022975206375, "_timestamp": 1585511823.4437048, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017714427085593343, "Value Loss": 0.00016842572949826717, "_runtime": 2746.5770597457886, "_timestamp": 1585511824.9977894, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002033486030995846, "Value Loss": 0.0001814115239540115, "_runtime": 2748.1219108104706, "_timestamp": 1585511826.5426404, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026982026174664497, "Value Loss": 8.698585588717833e-06, "_runtime": 2749.6768062114716, "_timestamp": 1585511828.0975358, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032289091031998396, "Value Loss": 4.322962195146829e-05, "_runtime": 2751.231155395508, "_timestamp": 1585511829.651885, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029935939237475395, "Value Loss": 1.598795824975241e-05, "_runtime": 2752.778932094574, "_timestamp": 1585511831.1996617, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002823011949658394, "Value Loss": 0.00028612499590963125, "_runtime": 2754.3135447502136, "_timestamp": 1585511832.7342744, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026674766559153795, "Value Loss": 3.408806151128374e-05, "_runtime": 2755.8653757572174, "_timestamp": 1585511834.2861054, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002441354328766465, "Value Loss": 4.0711413021199405e-05, "_runtime": 2757.4216272830963, "_timestamp": 1585511835.842357, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001111529883928597, "Value Loss": 0.00011914377682842314, "_runtime": 2759.000437259674, "_timestamp": 1585511837.421167, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00030024032457731664, "Value Loss": 2.183017204515636e-05, "_runtime": 2760.551971912384, "_timestamp": 1585511838.9727015, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.669401267979993e-07, "Value Loss": 1.213061113958247e-05, "_runtime": 2762.1088297367096, "_timestamp": 1585511840.5295594, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00041149070602841675, "Value Loss": 0.00013789570948574692, "_runtime": 2763.6608810424805, "_timestamp": 1585511842.0816107, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005119265406392515, "Value Loss": 3.970141551690176e-05, "_runtime": 2765.2143619060516, "_timestamp": 1585511843.6350915, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.767059236764908e-05, "Value Loss": 3.883375393343158e-05, "_runtime": 2766.76971578598, "_timestamp": 1585511845.1904454, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0002553500817157328, "Value Loss": 3.9382230170303956e-06, "_runtime": 2768.326076030731, "_timestamp": 1585511846.7468057, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006209113053046167, "Value Loss": 0.00022254977375268936, "_runtime": 2769.8689155578613, "_timestamp": 1585511848.2896452, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016392712714150548, "Value Loss": 5.586017778114183e-06, "_runtime": 2771.423958301544, "_timestamp": 1585511849.844688, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003416872350499034, "Value Loss": 8.852432074490935e-05, "_runtime": 2772.978727579117, "_timestamp": 1585511851.3994572, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0038436860777437687, "Value Loss": 0.00021482229931280017, "_runtime": 2774.531416654587, "_timestamp": 1585511852.9521463, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0028093440923839808, "Value Loss": 3.4758915717247874e-05, "_runtime": 2776.07976269722, "_timestamp": 1585511854.5004923, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0023529327008873224, "Value Loss": 3.0241320928325877e-05, "_runtime": 2777.623471736908, "_timestamp": 1585511856.0442014, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002086293650791049, "Value Loss": 0.0002842852845788002, "_runtime": 2779.1750226020813, "_timestamp": 1585511857.5957522, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003520193975418806, "Value Loss": 6.274138286244124e-05, "_runtime": 2780.717978000641, "_timestamp": 1585511859.1387076, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00529872952029109, "Value Loss": 0.00012861563300248235, "_runtime": 2782.2966845035553, "_timestamp": 1585511860.7174141, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007531905546784401, "Value Loss": 0.0001730440853862092, "_runtime": 2783.8524050712585, "_timestamp": 1585511862.2731347, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005392858292907476, "Value Loss": 2.9784343496430665e-05, "_runtime": 2785.418055534363, "_timestamp": 1585511863.8387852, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018791467882692814, "Value Loss": 1.8561442630016245e-05, "_runtime": 2786.985968351364, "_timestamp": 1585511865.406698, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018578926101326942, "Value Loss": 0.00027022947324439883, "_runtime": 2788.5493733882904, "_timestamp": 1585511866.970103, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0017766183009371161, "Value Loss": 2.7905927709070966e-05, "_runtime": 2790.1134781837463, "_timestamp": 1585511868.5342078, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005494374781847, "Value Loss": 0.0001839507167460397, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375, 5232.86865234375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-5232.86865234375, 848.44873046875, 6929.76611328125, 13011.083984375, 19092.400390625, 25173.716796875, 31255.037109375, 37336.35546875, 43417.671875, 49498.98828125, 55580.3046875, 61661.625, 67742.9453125, 73824.2578125, 79905.578125, 85986.890625, 92068.2109375, 98149.53125, 104230.84375, 110312.1640625, 116393.4765625, 122474.796875, 128556.1171875, 134637.421875, 140718.75, 146800.0625, 152881.375, 158962.6875, 165044.015625, 171125.328125, 177206.640625, 183287.96875, 189369.28125, 195450.59375, 201531.921875, 207613.234375, 213694.546875, 219775.875, 225857.1875, 231938.5, 238019.8125, 244101.140625, 250182.453125, 256263.765625, 262345.09375, 268426.40625, 274507.71875, 280589.03125, 286670.375, 292751.6875, 298833.0, 304914.3125, 310995.625, 317076.9375, 323158.25, 329239.59375, 335320.90625, 341402.21875, 347483.53125, 353564.84375, 359646.15625, 365727.5, 371808.8125, 377890.125, 383971.4375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0], "bins": [-9097.55078125, -8955.4013671875, -8813.251953125, -8671.103515625, -8528.9541015625, -8386.8046875, -8244.6552734375, -8102.50634765625, -7960.35693359375, -7818.2080078125, -7676.05859375, -7533.9091796875, -7391.759765625, -7249.61083984375, -7107.46142578125, -6965.3125, -6823.1630859375, -6681.013671875, -6538.86474609375, -6396.71533203125, -6254.56640625, -6112.4169921875, -5970.267578125, -5828.1181640625, -5685.96923828125, -5543.8203125, -5401.6708984375, -5259.521484375, -5117.3720703125, -4975.22314453125, -4833.07373046875, -4690.9248046875, -4548.775390625, -4406.6259765625, -4264.47705078125, -4122.32763671875, -3980.1787109375, -3838.029296875, -3695.8798828125, -3553.73095703125, -3411.58154296875, -3269.43212890625, -3127.283203125, -2985.1337890625, -2842.984375, -2700.83544921875, -2558.68603515625, -2416.537109375, -2274.3876953125, -2132.23828125, -1990.08935546875, -1847.93994140625, -1705.791015625, -1563.6416015625, -1421.4921875, -1279.34326171875, -1137.19384765625, -995.04443359375, -852.8955078125, -710.74609375, -568.5966796875, -426.447265625, -284.298828125, -142.1494140625, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 6.0, 0.0, 5.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 352.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 8.0, 25.0, 26.0, 20.0], "bins": [-36215.5859375, -35511.06640625, -34806.546875, -34102.02734375, -33397.5078125, -32692.990234375, -31988.470703125, -31283.951171875, -30579.431640625, -29874.912109375, -29170.392578125, -28465.875, -27761.35546875, -27056.8359375, -26352.31640625, -25647.796875, -24943.27734375, -24238.7578125, -23534.23828125, -22829.71875, -22125.19921875, -21420.6796875, -20716.162109375, -20011.642578125, -19307.123046875, -18602.603515625, -17898.083984375, -17193.564453125, -16489.046875, -15784.52734375, -15080.0078125, -14375.48828125, -13670.96875, -12966.44921875, -12261.9296875, -11557.41015625, -10852.890625, -10148.373046875, -9443.853515625, -8739.333984375, -8034.814453125, -7330.294921875, -6625.775390625, -5921.255859375, -5216.73828125, -4512.21875, -3807.69921875, -3103.1796875, -2398.66015625, -1694.140625, -989.62109375, -285.1015625, 419.41796875, 1123.9375, 1828.45703125, 2532.9765625, 3237.4921875, 3942.01171875, 4646.53125, 5351.05078125, 6055.5703125, 6760.08984375, 7464.609375, 8169.12890625, 8873.6484375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0], "bins": [-83451.3515625, -81948.9296875, -80446.5078125, -78944.078125, -77441.65625, -75939.234375, -74436.8125, -72934.390625, -71431.96875, -69929.546875, -68427.1171875, -66924.6953125, -65422.2734375, -63919.8515625, -62417.42578125, -60915.00390625, -59412.578125, -57910.15625, -56407.734375, -54905.3125, -53402.88671875, -51900.46484375, -50398.0390625, -48895.6171875, -47393.1953125, -45890.76953125, -44388.34765625, -42885.92578125, -41383.5, -39881.078125, -38378.65625, -36876.23046875, -35373.80859375, -33871.38671875, -32368.9609375, -30866.5390625, -29364.1171875, -27861.69140625, -26359.26953125, -24856.84765625, -23354.421875, -21852.0, -20349.578125, -18847.15234375, -17344.7265625, -15842.3046875, -14339.8828125, -12837.4609375, -11335.0390625, -9832.6171875, -8330.1875, -6827.765625, -5325.34375, -3822.921875, -2320.5, -818.078125, 684.3515625, 2186.7734375, 3689.1953125, 5191.6171875, 6694.0390625, 8196.4609375, 9698.890625, 11201.3125, 12703.734375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 5.0, 2.0, 8.0, 11.0, 7.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8313.74609375, -7326.123046875, -6338.49951171875, -5350.8759765625, -4363.2529296875, -3375.6298828125, -2388.00634765625, -1400.3828125, -412.759765625, 574.86328125, 1562.486328125, 2550.1103515625, 3537.7333984375, 4525.3564453125, 5512.98046875, 6500.603515625, 7488.2265625, 8475.849609375, 9463.47265625, 10451.095703125, 11438.71875, 12426.34375, 13413.966796875, 14401.58984375, 15389.212890625, 16376.8359375, 17364.458984375, 18352.08203125, 19339.70703125, 20327.330078125, 21314.953125, 22302.576171875, 23290.19921875, 24277.822265625, 25265.4453125, 26253.0703125, 27240.69140625, 28228.31640625, 29215.9375, 30203.5625, 31191.18359375, 32178.80859375, 33166.43359375, 34154.0546875, 35141.6796875, 36129.30078125, 37116.92578125, 38104.546875, 39092.171875, 40079.796875, 41067.41796875, 42055.04296875, 43042.6640625, 44030.2890625, 45017.91015625, 46005.53515625, 46993.16015625, 47980.78125, 48968.40625, 49956.02734375, 50943.65234375, 51931.2734375, 52918.8984375, 53906.51953125, 54894.14453125]}, "_runtime": 2791.677141904831, "_timestamp": 1585511870.0978715, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006670229136943817, "Value Loss": 2.5848505174508318e-05, "_runtime": 2791.677141904831, "_timestamp": 1585511870.0978715, "_step": 499}
