{"Episode reward": -98.91203240537243, "Episode length": 999, "Policy Loss": -12.497285842895508, "Value Loss": 0.02943805791437626, "_runtime": 47.75188374519348, "_timestamp": 1585073558.7516458, "_step": 0}
{"Episode reward": -92.52404923887612, "Episode length": 999, "Policy Loss": -11.766925811767578, "Value Loss": 0.02638418599963188, "_runtime": 48.86801242828369, "_timestamp": 1585073559.8677745, "_step": 1}
{"Episode reward": -106.547999886465, "Episode length": 999, "Policy Loss": -13.940963745117188, "Value Loss": 0.033384211361408234, "_runtime": 49.97181177139282, "_timestamp": 1585073560.9715738, "_step": 2}
{"Episode reward": -99.8773410932657, "Episode length": 999, "Policy Loss": -12.892520904541016, "Value Loss": 0.0336473248898983, "_runtime": 51.09191370010376, "_timestamp": 1585073562.0916758, "_step": 3}
{"Episode reward": -103.95068237610181, "Episode length": 999, "Policy Loss": -13.305822372436523, "Value Loss": 0.030616268515586853, "_runtime": 52.215012073516846, "_timestamp": 1585073563.2147741, "_step": 4}
{"Episode reward": -104.41622754307026, "Episode length": 999, "Policy Loss": -13.501856803894043, "Value Loss": 0.03435901924967766, "_runtime": 53.342907667160034, "_timestamp": 1585073564.3426697, "_step": 5}
{"Episode reward": -104.10074088579066, "Episode length": 999, "Policy Loss": -13.550335884094238, "Value Loss": 0.03086937591433525, "_runtime": 54.489195823669434, "_timestamp": 1585073565.488958, "_step": 6}
{"Episode reward": -99.45888346367168, "Episode length": 999, "Policy Loss": -12.67479133605957, "Value Loss": 0.02838226780295372, "_runtime": 55.66378855705261, "_timestamp": 1585073566.6635506, "_step": 7}
{"Episode reward": -105.23288393344122, "Episode length": 999, "Policy Loss": -13.684637069702148, "Value Loss": 0.03169775381684303, "_runtime": 56.81947064399719, "_timestamp": 1585073567.8192327, "_step": 8}
{"Episode reward": -104.52347930000437, "Episode length": 999, "Policy Loss": -13.51388168334961, "Value Loss": 0.03314794972538948, "_runtime": 57.97783136367798, "_timestamp": 1585073568.9775934, "_step": 9}
{"Episode reward": -102.90409122559568, "Episode length": 999, "Policy Loss": -13.44518756866455, "Value Loss": 0.032810028642416, "_runtime": 59.15197706222534, "_timestamp": 1585073570.1517391, "_step": 10}
{"Episode reward": -108.43477752399124, "Episode length": 999, "Policy Loss": -14.26430892944336, "Value Loss": 0.039701707661151886, "_runtime": 60.280757904052734, "_timestamp": 1585073571.28052, "_step": 11}
{"Episode reward": -103.37627188203817, "Episode length": 999, "Policy Loss": -13.5649995803833, "Value Loss": 0.03033502958714962, "_runtime": 61.42699408531189, "_timestamp": 1585073572.4267561, "_step": 12}
{"Episode reward": -93.78212344252708, "Episode length": 999, "Policy Loss": -11.6677885055542, "Value Loss": 0.026606423780322075, "_runtime": 62.544063568115234, "_timestamp": 1585073573.5438256, "_step": 13}
{"Episode reward": -109.3780347241515, "Episode length": 999, "Policy Loss": -14.59330940246582, "Value Loss": 0.034820202738046646, "_runtime": 63.660645723342896, "_timestamp": 1585073574.6604078, "_step": 14}
{"Episode reward": -96.91246383070892, "Episode length": 999, "Policy Loss": -12.593266487121582, "Value Loss": 0.027080276980996132, "_runtime": 64.80468130111694, "_timestamp": 1585073575.8044434, "_step": 15}
{"Episode reward": -97.76269671682594, "Episode length": 999, "Policy Loss": -12.572591781616211, "Value Loss": 0.028529593721032143, "_runtime": 65.95747470855713, "_timestamp": 1585073576.9572368, "_step": 16}
{"Episode reward": -99.56730771164908, "Episode length": 999, "Policy Loss": -12.739860534667969, "Value Loss": 0.033061303198337555, "_runtime": 67.10675239562988, "_timestamp": 1585073578.1065145, "_step": 17}
{"Episode reward": -101.8183961619189, "Episode length": 999, "Policy Loss": -13.050536155700684, "Value Loss": 0.029637636616826057, "_runtime": 68.23711514472961, "_timestamp": 1585073579.2368772, "_step": 18}
{"Episode reward": -96.0263040423802, "Episode length": 999, "Policy Loss": -12.314666748046875, "Value Loss": 0.03053447976708412, "_runtime": 69.38549590110779, "_timestamp": 1585073580.385258, "_step": 19}
{"Episode reward": -95.5265327388121, "Episode length": 999, "Policy Loss": -12.250768661499023, "Value Loss": 0.026953991502523422, "_runtime": 70.51995706558228, "_timestamp": 1585073581.5197191, "_step": 20}
{"Episode reward": -100.67414792226529, "Episode length": 999, "Policy Loss": -12.95117473602295, "Value Loss": 0.035438768565654755, "_runtime": 71.63873672485352, "_timestamp": 1585073582.6384988, "_step": 21}
{"Episode reward": -103.60373915952644, "Episode length": 999, "Policy Loss": -13.547442436218262, "Value Loss": 0.029059013351798058, "_runtime": 72.76587653160095, "_timestamp": 1585073583.7656386, "_step": 22}
{"Episode reward": -99.09097151716766, "Episode length": 999, "Policy Loss": -12.665908813476562, "Value Loss": 0.027966467663645744, "_runtime": 73.9336929321289, "_timestamp": 1585073584.933455, "_step": 23}
{"Episode reward": -107.06953420971048, "Episode length": 999, "Policy Loss": -14.071609497070312, "Value Loss": 0.03489992022514343, "_runtime": 75.09432220458984, "_timestamp": 1585073586.0940843, "_step": 24}
{"Episode reward": -102.85082115919792, "Episode length": 999, "Policy Loss": -13.521418571472168, "Value Loss": 0.033428359776735306, "_runtime": 76.24219131469727, "_timestamp": 1585073587.2419534, "_step": 25}
{"Episode reward": -108.72566276954674, "Episode length": 999, "Policy Loss": -14.49557113647461, "Value Loss": 0.03608321398496628, "_runtime": 77.38303637504578, "_timestamp": 1585073588.3827984, "_step": 26}
{"Episode reward": -102.67672927289252, "Episode length": 999, "Policy Loss": -13.269357681274414, "Value Loss": 0.03105727955698967, "_runtime": 78.50739765167236, "_timestamp": 1585073589.5071597, "_step": 27}
{"Episode reward": -103.39863385550409, "Episode length": 999, "Policy Loss": -13.450617790222168, "Value Loss": 0.03188405930995941, "_runtime": 79.67436814308167, "_timestamp": 1585073590.6741302, "_step": 28}
{"Episode reward": -108.25376484909741, "Episode length": 999, "Policy Loss": -14.253297805786133, "Value Loss": 0.039585962891578674, "_runtime": 80.79874086380005, "_timestamp": 1585073591.798503, "_step": 29}
{"Episode reward": -99.56220327469818, "Episode length": 999, "Policy Loss": -12.812522888183594, "Value Loss": 0.029280109331011772, "_runtime": 81.92899370193481, "_timestamp": 1585073592.9287558, "_step": 30}
{"Episode reward": -100.86138047153194, "Episode length": 999, "Policy Loss": -12.777543067932129, "Value Loss": 0.033785875886678696, "_runtime": 83.07271814346313, "_timestamp": 1585073594.0724802, "_step": 31}
{"Episode reward": -104.28285715146212, "Episode length": 999, "Policy Loss": -13.488577842712402, "Value Loss": 0.035105619579553604, "_runtime": 84.19096803665161, "_timestamp": 1585073595.19073, "_step": 32}
{"Episode reward": -110.44661158737263, "Episode length": 999, "Policy Loss": -14.712698936462402, "Value Loss": 0.03541488200426102, "_runtime": 85.36924600601196, "_timestamp": 1585073596.369008, "_step": 33}
{"Episode reward": -101.55729092682037, "Episode length": 999, "Policy Loss": -13.257073402404785, "Value Loss": 0.029940137639641762, "_runtime": 86.52930116653442, "_timestamp": 1585073597.5290632, "_step": 34}
{"Episode reward": -102.72014016848797, "Episode length": 999, "Policy Loss": -13.408164024353027, "Value Loss": 0.03262794762849808, "_runtime": 87.65733981132507, "_timestamp": 1585073598.6571019, "_step": 35}
{"Episode reward": -107.0365677429411, "Episode length": 999, "Policy Loss": -14.066656112670898, "Value Loss": 0.03298760950565338, "_runtime": 88.82469344139099, "_timestamp": 1585073599.8244555, "_step": 36}
{"Episode reward": -108.38069123414286, "Episode length": 999, "Policy Loss": -14.391672134399414, "Value Loss": 0.0372394397854805, "_runtime": 90.00241947174072, "_timestamp": 1585073601.0021815, "_step": 37}
{"Episode reward": -98.19761722832101, "Episode length": 999, "Policy Loss": -12.587796211242676, "Value Loss": 0.028832051903009415, "_runtime": 91.18835401535034, "_timestamp": 1585073602.188116, "_step": 38}
{"Episode reward": -97.8435222442413, "Episode length": 999, "Policy Loss": -12.438294410705566, "Value Loss": 0.02814793959259987, "_runtime": 92.35994815826416, "_timestamp": 1585073603.3597102, "_step": 39}
{"Episode reward": -95.74144264385657, "Episode length": 999, "Policy Loss": -12.017284393310547, "Value Loss": 0.02668316289782524, "_runtime": 93.49542999267578, "_timestamp": 1585073604.495192, "_step": 40}
{"Episode reward": -105.14492007813017, "Episode length": 999, "Policy Loss": -13.604333877563477, "Value Loss": 0.03268517553806305, "_runtime": 94.61784291267395, "_timestamp": 1585073605.617605, "_step": 41}
{"Episode reward": -100.06413203142459, "Episode length": 999, "Policy Loss": -12.791190147399902, "Value Loss": 0.03366979584097862, "_runtime": 95.74761915206909, "_timestamp": 1585073606.7473812, "_step": 42}
{"Episode reward": -98.48980374387504, "Episode length": 999, "Policy Loss": -12.53866195678711, "Value Loss": 0.03166484087705612, "_runtime": 96.90464854240417, "_timestamp": 1585073607.9044106, "_step": 43}
{"Episode reward": -103.60424887806649, "Episode length": 999, "Policy Loss": -13.231595039367676, "Value Loss": 0.03082815371453762, "_runtime": 98.07158708572388, "_timestamp": 1585073609.0713491, "_step": 44}
{"Episode reward": -103.77119697070687, "Episode length": 999, "Policy Loss": -13.375407218933105, "Value Loss": 0.03269164264202118, "_runtime": 99.20461392402649, "_timestamp": 1585073610.204376, "_step": 45}
{"Episode reward": -107.32861726125508, "Episode length": 999, "Policy Loss": -14.302705764770508, "Value Loss": 0.03823462128639221, "_runtime": 100.35950255393982, "_timestamp": 1585073611.3592646, "_step": 46}
{"Episode reward": -98.65659000595782, "Episode length": 999, "Policy Loss": -12.67105484008789, "Value Loss": 0.028791792690753937, "_runtime": 101.52640891075134, "_timestamp": 1585073612.526171, "_step": 47}
{"Episode reward": -91.56918984988856, "Episode length": 999, "Policy Loss": -11.537252426147461, "Value Loss": 0.027518149465322495, "_runtime": 102.64502096176147, "_timestamp": 1585073613.644783, "_step": 48}
{"Episode reward": -104.15817564696349, "Episode length": 999, "Policy Loss": -13.780203819274902, "Value Loss": 0.03532122075557709, "_runtime": 103.7684965133667, "_timestamp": 1585073614.7682586, "_step": 49}
{"Episode reward": -102.23990144995935, "Episode length": 999, "Policy Loss": -13.083483695983887, "Value Loss": 0.034679342061281204, "_runtime": 104.88915181159973, "_timestamp": 1585073615.8889139, "_step": 50}
{"Episode reward": -94.93816521551739, "Episode length": 999, "Policy Loss": -11.993792533874512, "Value Loss": 0.027497658506035805, "_runtime": 106.03349924087524, "_timestamp": 1585073617.0332613, "_step": 51}
{"Episode reward": -101.54449573911876, "Episode length": 999, "Policy Loss": -13.193366050720215, "Value Loss": 0.03350912407040596, "_runtime": 107.21368193626404, "_timestamp": 1585073618.213444, "_step": 52}
{"Episode reward": -92.42640211563952, "Episode length": 999, "Policy Loss": -11.711292266845703, "Value Loss": 0.024421026930212975, "_runtime": 108.34791469573975, "_timestamp": 1585073619.3476768, "_step": 53}
{"Episode reward": -99.7670098703356, "Episode length": 999, "Policy Loss": -13.093596458435059, "Value Loss": 0.029692422598600388, "_runtime": 109.48079633712769, "_timestamp": 1585073620.4805584, "_step": 54}
{"Episode reward": -99.35544920599233, "Episode length": 999, "Policy Loss": -12.645406723022461, "Value Loss": 0.028282957151532173, "_runtime": 110.61484456062317, "_timestamp": 1585073621.6146066, "_step": 55}
{"Episode reward": -112.2292833272951, "Episode length": 999, "Policy Loss": -15.126240730285645, "Value Loss": 0.03567957133054733, "_runtime": 111.76919531822205, "_timestamp": 1585073622.7689574, "_step": 56}
{"Episode reward": -101.5345292084767, "Episode length": 999, "Policy Loss": -13.274931907653809, "Value Loss": 0.03067317232489586, "_runtime": 112.89679312705994, "_timestamp": 1585073623.8965552, "_step": 57}
{"Episode reward": -109.20593900229665, "Episode length": 999, "Policy Loss": -14.602173805236816, "Value Loss": 0.03399718180298805, "_runtime": 114.0062198638916, "_timestamp": 1585073625.005982, "_step": 58}
{"Episode reward": -98.3384193724011, "Episode length": 999, "Policy Loss": -12.532984733581543, "Value Loss": 0.02729695476591587, "_runtime": 115.14377975463867, "_timestamp": 1585073626.1435418, "_step": 59}
{"Episode reward": -109.55384647117312, "Episode length": 999, "Policy Loss": -14.958783149719238, "Value Loss": 0.03735651820898056, "_runtime": 116.29768705368042, "_timestamp": 1585073627.297449, "_step": 60}
{"Episode reward": -94.97119050995579, "Episode length": 999, "Policy Loss": -12.027076721191406, "Value Loss": 0.02912047877907753, "_runtime": 117.45504641532898, "_timestamp": 1585073628.4548085, "_step": 61}
{"Episode reward": -104.41900705947504, "Episode length": 999, "Policy Loss": -13.70269775390625, "Value Loss": 0.03105173259973526, "_runtime": 118.56912326812744, "_timestamp": 1585073629.5688853, "_step": 62}
{"Episode reward": -93.9944246607212, "Episode length": 999, "Policy Loss": -11.896803855895996, "Value Loss": 0.025117313489317894, "_runtime": 119.69828534126282, "_timestamp": 1585073630.6980474, "_step": 63}
{"Episode reward": -95.1311313822198, "Episode length": 999, "Policy Loss": -12.224507331848145, "Value Loss": 0.026450062170624733, "_runtime": 120.81594920158386, "_timestamp": 1585073631.8157113, "_step": 64}
{"Episode reward": -100.59189095743298, "Episode length": 999, "Policy Loss": -12.83080768585205, "Value Loss": 0.03144345432519913, "_runtime": 121.94147539138794, "_timestamp": 1585073632.9412374, "_step": 65}
{"Episode reward": -99.29583159561844, "Episode length": 999, "Policy Loss": -12.96854305267334, "Value Loss": 0.027010953053832054, "_runtime": 123.08673143386841, "_timestamp": 1585073634.0864935, "_step": 66}
{"Episode reward": -95.27115200054217, "Episode length": 999, "Policy Loss": -11.907317161560059, "Value Loss": 0.026086267083883286, "_runtime": 124.25326085090637, "_timestamp": 1585073635.253023, "_step": 67}
{"Episode reward": -92.22794091988281, "Episode length": 999, "Policy Loss": -11.41901969909668, "Value Loss": 0.025353001430630684, "_runtime": 125.44322514533997, "_timestamp": 1585073636.4429872, "_step": 68}
{"Episode reward": -103.47391936898752, "Episode length": 999, "Policy Loss": -13.595990180969238, "Value Loss": 0.03207697346806526, "_runtime": 126.59743118286133, "_timestamp": 1585073637.5971932, "_step": 69}
{"Episode reward": -102.20594646600999, "Episode length": 999, "Policy Loss": -13.536240577697754, "Value Loss": 0.028502965345978737, "_runtime": 127.71914267539978, "_timestamp": 1585073638.7189047, "_step": 70}
{"Episode reward": -104.23278483717641, "Episode length": 999, "Policy Loss": -13.666125297546387, "Value Loss": 0.03273924067616463, "_runtime": 128.90544080734253, "_timestamp": 1585073639.9052029, "_step": 71}
{"Episode reward": -98.38376813560777, "Episode length": 999, "Policy Loss": -12.58521556854248, "Value Loss": 0.02948690578341484, "_runtime": 130.0343689918518, "_timestamp": 1585073641.034131, "_step": 72}
{"Episode reward": -98.42522903262831, "Episode length": 999, "Policy Loss": -12.58682918548584, "Value Loss": 0.030479727312922478, "_runtime": 131.266783952713, "_timestamp": 1585073642.266546, "_step": 73}
{"Episode reward": -100.93207506463762, "Episode length": 999, "Policy Loss": -12.940010070800781, "Value Loss": 0.030355030670762062, "_runtime": 132.4349114894867, "_timestamp": 1585073643.4346735, "_step": 74}
{"Episode reward": -103.44866529732738, "Episode length": 999, "Policy Loss": -13.615467071533203, "Value Loss": 0.030591370537877083, "_runtime": 133.57480335235596, "_timestamp": 1585073644.5745654, "_step": 75}
{"Episode reward": -98.63759169080673, "Episode length": 999, "Policy Loss": -12.626659393310547, "Value Loss": 0.03323333337903023, "_runtime": 134.72599506378174, "_timestamp": 1585073645.7257571, "_step": 76}
{"Episode reward": -104.1371210756008, "Episode length": 999, "Policy Loss": -13.566585540771484, "Value Loss": 0.029883775860071182, "_runtime": 135.88169527053833, "_timestamp": 1585073646.8814573, "_step": 77}
{"Episode reward": -96.55151654095941, "Episode length": 999, "Policy Loss": -12.359342575073242, "Value Loss": 0.028177602216601372, "_runtime": 137.07914805412292, "_timestamp": 1585073648.07891, "_step": 78}
{"Episode reward": -107.39634033941046, "Episode length": 999, "Policy Loss": -14.493733406066895, "Value Loss": 0.03520357981324196, "_runtime": 138.21084547042847, "_timestamp": 1585073649.2106075, "_step": 79}
{"Episode reward": -99.57831105218982, "Episode length": 999, "Policy Loss": -12.731945037841797, "Value Loss": 0.030349262058734894, "_runtime": 139.33661603927612, "_timestamp": 1585073650.336378, "_step": 80}
{"Episode reward": -102.29625934743966, "Episode length": 999, "Policy Loss": -13.202428817749023, "Value Loss": 0.030877307057380676, "_runtime": 140.47665643692017, "_timestamp": 1585073651.4764185, "_step": 81}
{"Episode reward": -97.82291771607908, "Episode length": 999, "Policy Loss": -12.612279891967773, "Value Loss": 0.029507221654057503, "_runtime": 141.64868259429932, "_timestamp": 1585073652.6484447, "_step": 82}
{"Episode reward": -105.8752697551411, "Episode length": 999, "Policy Loss": -14.079336166381836, "Value Loss": 0.031505197286605835, "_runtime": 142.77563285827637, "_timestamp": 1585073653.775395, "_step": 83}
{"Episode reward": -92.23907162621597, "Episode length": 999, "Policy Loss": -11.69783878326416, "Value Loss": 0.025198599323630333, "_runtime": 143.88521671295166, "_timestamp": 1585073654.8849788, "_step": 84}
{"Episode reward": -105.72730034859345, "Episode length": 999, "Policy Loss": -13.925582885742188, "Value Loss": 0.03310658782720566, "_runtime": 145.02119970321655, "_timestamp": 1585073656.0209618, "_step": 85}
{"Episode reward": -104.74549202804242, "Episode length": 999, "Policy Loss": -13.831528663635254, "Value Loss": 0.03442096337676048, "_runtime": 146.18012380599976, "_timestamp": 1585073657.1798859, "_step": 86}
{"Episode reward": -105.23047645424184, "Episode length": 999, "Policy Loss": -13.81486988067627, "Value Loss": 0.03224698081612587, "_runtime": 147.33241724967957, "_timestamp": 1585073658.3321793, "_step": 87}
{"Episode reward": -97.92988227015604, "Episode length": 999, "Policy Loss": -12.420567512512207, "Value Loss": 0.02950213849544525, "_runtime": 148.50576043128967, "_timestamp": 1585073659.5055225, "_step": 88}
{"Episode reward": -108.48799609872455, "Episode length": 999, "Policy Loss": -14.420127868652344, "Value Loss": 0.03482341021299362, "_runtime": 149.72841882705688, "_timestamp": 1585073660.728181, "_step": 89}
{"Episode reward": -97.29330665209504, "Episode length": 999, "Policy Loss": -12.298108100891113, "Value Loss": 0.029780959710478783, "_runtime": 150.87665271759033, "_timestamp": 1585073661.8764148, "_step": 90}
{"Episode reward": -105.6923882853223, "Episode length": 999, "Policy Loss": -13.745959281921387, "Value Loss": 0.032041698694229126, "_runtime": 151.99869775772095, "_timestamp": 1585073662.9984598, "_step": 91}
{"Episode reward": -99.57087657268666, "Episode length": 999, "Policy Loss": -12.757697105407715, "Value Loss": 0.03107774257659912, "_runtime": 153.15041947364807, "_timestamp": 1585073664.1501815, "_step": 92}
{"Episode reward": -103.42793182169379, "Episode length": 999, "Policy Loss": -13.700284004211426, "Value Loss": 0.033903300762176514, "_runtime": 154.2944507598877, "_timestamp": 1585073665.2942128, "_step": 93}
{"Episode reward": -105.61198464955007, "Episode length": 999, "Policy Loss": -13.785598754882812, "Value Loss": 0.030971016734838486, "_runtime": 155.45146989822388, "_timestamp": 1585073666.451232, "_step": 94}
{"Episode reward": -95.9217229038958, "Episode length": 999, "Policy Loss": -11.91399097442627, "Value Loss": 0.02646738663315773, "_runtime": 156.5989589691162, "_timestamp": 1585073667.598721, "_step": 95}
{"Episode reward": -94.55959016395676, "Episode length": 999, "Policy Loss": -12.03993034362793, "Value Loss": 0.027143366634845734, "_runtime": 157.7632873058319, "_timestamp": 1585073668.7630494, "_step": 96}
{"Episode reward": -103.61366562710056, "Episode length": 999, "Policy Loss": -13.644695281982422, "Value Loss": 0.031369954347610474, "_runtime": 158.9390504360199, "_timestamp": 1585073669.9388125, "_step": 97}
{"Episode reward": -95.04141710317279, "Episode length": 999, "Policy Loss": -12.194427490234375, "Value Loss": 0.028660226613283157, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562, 535.4873657226562]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-298.7826232910156, -286.03094482421875, -273.2792663574219, -260.527587890625, -247.77593994140625, -235.02426147460938, -222.2725830078125, -209.52090454101562, -196.7692413330078, -184.017578125, -171.26589965820312, -158.51422119140625, -145.76254272460938, -133.01087951660156, -120.25920104980469, -107.50753784179688, -94.755859375, -82.00418090820312, -69.25251770019531, -56.50083923339844, -43.749176025390625, -30.99749755859375, -18.245819091796875, -5.494140625, 7.257537841796875, 20.009185791015625, 32.7608642578125, 45.512542724609375, 58.26422119140625, 71.01589965820312, 83.76754760742188, 96.51922607421875, 109.27090454101562, 122.0225830078125, 134.77426147460938, 147.52590942382812, 160.277587890625, 173.02926635742188, 185.78094482421875, 198.53262329101562, 211.28427124023438, 224.03598022460938, 236.78762817382812, 249.53927612304688, 262.2909851074219, 275.0426330566406, 287.7943420410156, 300.5459899902344, 313.2976989746094, 326.0493469238281, 338.8009948730469, 351.5527038574219, 364.3043518066406, 377.0560607910156, 389.8077087402344, 402.5593566894531, 415.3110656738281, 428.0627136230469, 440.8144226074219, 453.5660705566406, 466.3177185058594, 479.0694274902344, 491.8210754394531, 504.5727844238281, 517.324462890625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-293.504150390625, -284.90948486328125, -276.3148193359375, -267.7201843261719, -259.1255187988281, -250.53085327148438, -241.93618774414062, -233.34152221679688, -224.7468719482422, -216.1522216796875, -207.55755615234375, -198.962890625, -190.36822509765625, -181.77357482910156, -173.1789093017578, -164.58425903320312, -155.98959350585938, -147.39492797851562, -138.80027770996094, -130.2056121826172, -121.6109619140625, -113.01629638671875, -104.421630859375, -95.82698059082031, -87.23231506347656, -78.63764953613281, -70.04299926757812, -61.448333740234375, -52.853668212890625, -44.25901794433594, -35.66436767578125, -27.0697021484375, -18.47503662109375, -9.88037109375, -1.28570556640625, 7.308929443359375, 15.903594970703125, 24.498260498046875, 33.092926025390625, 41.687591552734375, 50.2822265625, 58.87689208984375, 67.4715576171875, 76.06622314453125, 84.660888671875, 93.25555419921875, 101.85018920898438, 110.44485473632812, 119.03952026367188, 127.63418579101562, 136.22885131835938, 144.823486328125, 153.41815185546875, 162.0128173828125, 170.60748291015625, 179.2021484375, 187.79681396484375, 196.39144897460938, 204.98611450195312, 213.58078002929688, 222.1754150390625, 230.77008056640625, 239.36474609375, 247.95941162109375, 256.5540771484375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 8.0, 5.0, 5.0, 8.0, 5.0, 13.0, 11.0, 14.0, 10.0, 13.0, 18.0, 11.0, 25.0, 47.0, 48.0, 40.0, 38.0, 22.0, 29.0, 31.0, 16.0, 15.0, 14.0, 3.0, 7.0, 6.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-258.03009033203125, -250.47421264648438, -242.91835021972656, -235.3624725341797, -227.80661010742188, -220.250732421875, -212.69485473632812, -205.13897705078125, -197.58311462402344, -190.02725219726562, -182.47137451171875, -174.91549682617188, -167.359619140625, -159.8037567138672, -152.2478790283203, -144.6920166015625, -137.13613891601562, -129.58026123046875, -122.02439880371094, -114.46852111816406, -106.91265869140625, -99.35678100585938, -91.8009033203125, -84.24504089355469, -76.68916320800781, -69.13328552246094, -61.577423095703125, -54.02154541015625, -46.465667724609375, -38.90980529785156, -31.353927612304688, -23.798065185546875, -16.2421875, -8.686309814453125, -1.13043212890625, 6.4254150390625, 13.981292724609375, 21.53717041015625, 29.093048095703125, 36.64892578125, 44.20477294921875, 51.760650634765625, 59.3165283203125, 66.87240600585938, 74.42828369140625, 81.98416137695312, 89.54000854492188, 97.09588623046875, 104.65176391601562, 112.2076416015625, 119.76351928710938, 127.31936645507812, 134.875244140625, 142.43112182617188, 149.98699951171875, 157.54287719726562, 165.0987548828125, 172.65460205078125, 180.21047973632812, 187.766357421875, 195.32223510742188, 202.87811279296875, 210.4339599609375, 217.98983764648438, 225.54571533203125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-113.02062225341797, -108.04536437988281, -103.07009887695312, -98.09484100341797, -93.11958312988281, -88.14431762695312, -83.16905975341797, -78.19380187988281, -73.21853637695312, -68.24327850341797, -63.26802062988281, -58.29275894165039, -53.31749725341797, -48.34223937988281, -43.366981506347656, -38.39171600341797, -33.41645812988281, -28.441200256347656, -23.46593475341797, -18.490676879882812, -13.515419006347656, -8.540153503417969, -3.5648956298828125, 1.4103622436523438, 6.385627746582031, 11.360885620117188, 16.336143493652344, 21.31140899658203, 26.286659240722656, 31.261924743652344, 36.23719024658203, 41.212440490722656, 46.187705993652344, 51.16297149658203, 56.138221740722656, 61.113487243652344, 66.08875274658203, 71.06400299072266, 76.03926849365234, 81.01453399658203, 85.98978424072266, 90.96504974365234, 95.94031524658203, 100.91556549072266, 105.89083099365234, 110.86609649658203, 115.84134674072266, 120.81661224365234, 125.79187774658203, 130.76712036132812, 135.74240112304688, 140.7176513671875, 145.69290161132812, 150.66815185546875, 155.6434326171875, 160.61868286132812, 165.59393310546875, 170.5692138671875, 175.54446411132812, 180.51971435546875, 185.4949951171875, 190.47024536132812, 195.44549560546875, 200.4207763671875, 205.39602661132812]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 32.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-135.18345642089844, -131.9251708984375, -128.66688537597656, -125.4085922241211, -122.15029907226562, -118.89201354980469, -115.63372802734375, -112.37544250488281, -109.11714935302734, -105.85885620117188, -102.60057067871094, -99.34228515625, -96.08399963378906, -92.8257064819336, -89.56742095947266, -86.30912780761719, -83.05084228515625, -79.79255676269531, -76.53426361083984, -73.2759780883789, -70.01768493652344, -66.7593994140625, -63.50111389160156, -60.242820739746094, -56.984535217285156, -53.72624969482422, -50.46795654296875, -47.20967102050781, -43.951385498046875, -40.693092346191406, -37.43480682373047, -34.176513671875, -30.918228149414062, -27.659942626953125, -24.401649475097656, -21.14336395263672, -17.88507080078125, -14.626785278320312, -11.368499755859375, -8.110206604003906, -4.8519134521484375, -1.5936279296875, 1.6646575927734375, 4.922943115234375, 8.181228637695312, 11.43951416015625, 14.69781494140625, 17.956100463867188, 21.214385986328125, 24.472671508789062, 27.73095703125, 30.9892578125, 34.24754333496094, 37.505828857421875, 40.76411437988281, 44.02239990234375, 47.28068542480469, 50.53898620605469, 53.797271728515625, 57.05555725097656, 60.3138427734375, 63.57212829589844, 66.83042907714844, 70.08871459960938, 73.34700012207031]}, "_runtime": 160.05644130706787, "_timestamp": 1585073671.0562034, "_step": 98}
{"Episode reward": -98.03665519511998, "Episode length": 999, "Policy Loss": -12.469518661499023, "Value Loss": 0.026004986837506294, "_runtime": 161.21486353874207, "_timestamp": 1585073672.2146256, "_step": 99}
{"Episode reward": -101.02827799192843, "Episode length": 999, "Policy Loss": -13.180051803588867, "Value Loss": 0.03235485404729843, "_runtime": 162.34632658958435, "_timestamp": 1585073673.3460886, "_step": 100}
{"Episode reward": -94.3660973753067, "Episode length": 999, "Policy Loss": -11.701839447021484, "Value Loss": 0.02791137620806694, "_runtime": 163.48571920394897, "_timestamp": 1585073674.4854813, "_step": 101}
{"Episode reward": -95.43978682375666, "Episode length": 999, "Policy Loss": -12.001861572265625, "Value Loss": 0.026916099712252617, "_runtime": 164.64044380187988, "_timestamp": 1585073675.6402059, "_step": 102}
{"Episode reward": -99.49561124853889, "Episode length": 999, "Policy Loss": -12.6923828125, "Value Loss": 0.02853519842028618, "_runtime": 165.79603719711304, "_timestamp": 1585073676.7957993, "_step": 103}
{"Episode reward": -104.44221654270804, "Episode length": 999, "Policy Loss": -13.664365768432617, "Value Loss": 0.03163032978773117, "_runtime": 166.933856010437, "_timestamp": 1585073677.933618, "_step": 104}
{"Episode reward": -99.81291743501092, "Episode length": 999, "Policy Loss": -12.641810417175293, "Value Loss": 0.029749885201454163, "_runtime": 168.1318166255951, "_timestamp": 1585073679.1315787, "_step": 105}
{"Episode reward": -101.39924883171165, "Episode length": 999, "Policy Loss": -13.026782989501953, "Value Loss": 0.030896160751581192, "_runtime": 169.32794070243835, "_timestamp": 1585073680.3277028, "_step": 106}
{"Episode reward": -106.64701460195111, "Episode length": 999, "Policy Loss": -14.090378761291504, "Value Loss": 0.031683873385190964, "_runtime": 170.49483156204224, "_timestamp": 1585073681.4945936, "_step": 107}
{"Episode reward": -105.06842458889216, "Episode length": 999, "Policy Loss": -13.870142936706543, "Value Loss": 0.03355449065566063, "_runtime": 171.64484858512878, "_timestamp": 1585073682.6446106, "_step": 108}
{"Episode reward": -100.82123357911998, "Episode length": 999, "Policy Loss": -12.79680061340332, "Value Loss": 0.02841963991522789, "_runtime": 172.75502729415894, "_timestamp": 1585073683.7547894, "_step": 109}
{"Episode reward": -99.1754003405863, "Episode length": 999, "Policy Loss": -12.59516429901123, "Value Loss": 0.03188673406839371, "_runtime": 173.89653182029724, "_timestamp": 1585073684.8962939, "_step": 110}
{"Episode reward": -96.55492137873442, "Episode length": 999, "Policy Loss": -12.211811065673828, "Value Loss": 0.028686504811048508, "_runtime": 175.02638912200928, "_timestamp": 1585073686.0261512, "_step": 111}
{"Episode reward": -103.91177359665974, "Episode length": 999, "Policy Loss": -13.831869125366211, "Value Loss": 0.03325238823890686, "_runtime": 176.15266513824463, "_timestamp": 1585073687.1524272, "_step": 112}
{"Episode reward": -101.57644097146935, "Episode length": 999, "Policy Loss": -13.358867645263672, "Value Loss": 0.031810663640499115, "_runtime": 177.28932309150696, "_timestamp": 1585073688.2890851, "_step": 113}
{"Episode reward": -97.76394457566566, "Episode length": 999, "Policy Loss": -12.446733474731445, "Value Loss": 0.03075719252228737, "_runtime": 178.41411423683167, "_timestamp": 1585073689.4138763, "_step": 114}
{"Episode reward": -96.63952105422129, "Episode length": 999, "Policy Loss": -12.253263473510742, "Value Loss": 0.026599228382110596, "_runtime": 179.5359423160553, "_timestamp": 1585073690.5357044, "_step": 115}
{"Episode reward": -98.41834109741106, "Episode length": 999, "Policy Loss": -12.62237548828125, "Value Loss": 0.028763260692358017, "_runtime": 180.68407273292542, "_timestamp": 1585073691.6838348, "_step": 116}
{"Episode reward": -92.967539999233, "Episode length": 999, "Policy Loss": -11.627435684204102, "Value Loss": 0.025431770831346512, "_runtime": 181.83648014068604, "_timestamp": 1585073692.8362422, "_step": 117}
{"Episode reward": -108.52843110475318, "Episode length": 999, "Policy Loss": -14.362887382507324, "Value Loss": 0.037354644387960434, "_runtime": 183.01617097854614, "_timestamp": 1585073694.015933, "_step": 118}
{"Episode reward": -103.25697545890642, "Episode length": 999, "Policy Loss": -13.427845001220703, "Value Loss": 0.032987721264362335, "_runtime": 184.12124943733215, "_timestamp": 1585073695.1210115, "_step": 119}
{"Episode reward": -100.06958129133564, "Episode length": 999, "Policy Loss": -12.67492961883545, "Value Loss": 0.03238636627793312, "_runtime": 185.29827570915222, "_timestamp": 1585073696.2980378, "_step": 120}
{"Episode reward": -96.98509838038069, "Episode length": 999, "Policy Loss": -12.325762748718262, "Value Loss": 0.03161139786243439, "_runtime": 186.46075582504272, "_timestamp": 1585073697.460518, "_step": 121}
{"Episode reward": -95.75146704921207, "Episode length": 999, "Policy Loss": -11.907025337219238, "Value Loss": 0.02910591848194599, "_runtime": 187.61675691604614, "_timestamp": 1585073698.616519, "_step": 122}
{"Episode reward": -109.32562356532938, "Episode length": 999, "Policy Loss": -14.518752098083496, "Value Loss": 0.03501376882195473, "_runtime": 188.7570173740387, "_timestamp": 1585073699.7567794, "_step": 123}
{"Episode reward": -94.8863500959866, "Episode length": 999, "Policy Loss": -12.090185165405273, "Value Loss": 0.029029298573732376, "_runtime": 189.86896777153015, "_timestamp": 1585073700.8687298, "_step": 124}
{"Episode reward": -97.89740712682948, "Episode length": 999, "Policy Loss": -12.42098617553711, "Value Loss": 0.028295131400227547, "_runtime": 190.99406337738037, "_timestamp": 1585073701.9938254, "_step": 125}
{"Episode reward": -100.73368559422543, "Episode length": 999, "Policy Loss": -12.933198928833008, "Value Loss": 0.031972501426935196, "_runtime": 192.12887811660767, "_timestamp": 1585073703.1286402, "_step": 126}
{"Episode reward": -98.86502995022643, "Episode length": 999, "Policy Loss": -12.700066566467285, "Value Loss": 0.02797773852944374, "_runtime": 193.28621912002563, "_timestamp": 1585073704.2859812, "_step": 127}
{"Episode reward": -104.43164687982512, "Episode length": 999, "Policy Loss": -13.597286224365234, "Value Loss": 0.03402601554989815, "_runtime": 194.39545464515686, "_timestamp": 1585073705.3952167, "_step": 128}
{"Episode reward": -109.51116069214021, "Episode length": 999, "Policy Loss": -14.2576265335083, "Value Loss": 0.035667285323143005, "_runtime": 195.54555892944336, "_timestamp": 1585073706.545321, "_step": 129}
{"Episode reward": -97.25702431619052, "Episode length": 999, "Policy Loss": -12.452701568603516, "Value Loss": 0.028152287006378174, "_runtime": 196.66943669319153, "_timestamp": 1585073707.6691988, "_step": 130}
{"Episode reward": -103.99444890579815, "Episode length": 999, "Policy Loss": -13.644166946411133, "Value Loss": 0.03438086807727814, "_runtime": 197.81245279312134, "_timestamp": 1585073708.8122149, "_step": 131}
{"Episode reward": -100.35461412626402, "Episode length": 999, "Policy Loss": -13.005993843078613, "Value Loss": 0.03152697533369064, "_runtime": 198.95638918876648, "_timestamp": 1585073709.9561512, "_step": 132}
{"Episode reward": -101.19276818399486, "Episode length": 999, "Policy Loss": -13.257883071899414, "Value Loss": 0.031177161261439323, "_runtime": 200.071270942688, "_timestamp": 1585073711.071033, "_step": 133}
{"Episode reward": -94.10830695510577, "Episode length": 999, "Policy Loss": -11.801726341247559, "Value Loss": 0.02873099595308304, "_runtime": 201.1917383670807, "_timestamp": 1585073712.1915004, "_step": 134}
{"Episode reward": -104.09331541520815, "Episode length": 999, "Policy Loss": -13.616647720336914, "Value Loss": 0.03271535784006119, "_runtime": 202.31923389434814, "_timestamp": 1585073713.318996, "_step": 135}
{"Episode reward": -104.1752710315449, "Episode length": 999, "Policy Loss": -13.387348175048828, "Value Loss": 0.031644463539123535, "_runtime": 203.45067644119263, "_timestamp": 1585073714.4504385, "_step": 136}
{"Episode reward": -109.67162061548142, "Episode length": 999, "Policy Loss": -14.449957847595215, "Value Loss": 0.035077840089797974, "_runtime": 204.59031081199646, "_timestamp": 1585073715.5900729, "_step": 137}
{"Episode reward": -101.75241454513211, "Episode length": 999, "Policy Loss": -13.173636436462402, "Value Loss": 0.028300417587161064, "_runtime": 205.77083945274353, "_timestamp": 1585073716.7706015, "_step": 138}
{"Episode reward": -97.89474172081758, "Episode length": 999, "Policy Loss": -12.23277759552002, "Value Loss": 0.029109934344887733, "_runtime": 206.9414849281311, "_timestamp": 1585073717.941247, "_step": 139}
{"Episode reward": -102.05766498413992, "Episode length": 999, "Policy Loss": -13.449687004089355, "Value Loss": 0.030781785026192665, "_runtime": 208.08327412605286, "_timestamp": 1585073719.0830362, "_step": 140}
{"Episode reward": -104.60799882221542, "Episode length": 999, "Policy Loss": -14.081720352172852, "Value Loss": 0.030274081975221634, "_runtime": 209.19930815696716, "_timestamp": 1585073720.1990702, "_step": 141}
{"Episode reward": -107.54972178879187, "Episode length": 999, "Policy Loss": -14.227043151855469, "Value Loss": 0.035131849348545074, "_runtime": 210.34450602531433, "_timestamp": 1585073721.344268, "_step": 142}
{"Episode reward": -104.64111318078415, "Episode length": 999, "Policy Loss": -13.644713401794434, "Value Loss": 0.03401409089565277, "_runtime": 211.48539304733276, "_timestamp": 1585073722.485155, "_step": 143}
{"Episode reward": -96.76913615777609, "Episode length": 999, "Policy Loss": -12.25986385345459, "Value Loss": 0.026944385841488838, "_runtime": 212.64397835731506, "_timestamp": 1585073723.6437404, "_step": 144}
{"Episode reward": -101.02810201848078, "Episode length": 999, "Policy Loss": -12.924409866333008, "Value Loss": 0.030583061277866364, "_runtime": 213.80634379386902, "_timestamp": 1585073724.8061059, "_step": 145}
{"Episode reward": -97.4411110440845, "Episode length": 999, "Policy Loss": -12.4301176071167, "Value Loss": 0.028305865824222565, "_runtime": 214.96579504013062, "_timestamp": 1585073725.965557, "_step": 146}
{"Episode reward": -98.87705829776601, "Episode length": 999, "Policy Loss": -12.405867576599121, "Value Loss": 0.029968105256557465, "_runtime": 216.1347951889038, "_timestamp": 1585073727.1345572, "_step": 147}
{"Episode reward": -99.36502764533577, "Episode length": 999, "Policy Loss": -12.670308113098145, "Value Loss": 0.02865508757531643, "_runtime": 217.18483924865723, "_timestamp": 1585073728.1846013, "_step": 148}
{"Episode reward": -1.2246231389831763, "Episode length": 905, "Policy Loss": 1.5330644845962524, "Value Loss": 11.105560302734375, "_runtime": 218.29702997207642, "_timestamp": 1585073729.296792, "_step": 149}
{"Episode reward": -108.89102795430678, "Episode length": 999, "Policy Loss": -14.169272422790527, "Value Loss": 0.03623777627944946, "_runtime": 219.43724584579468, "_timestamp": 1585073730.437008, "_step": 150}
{"Episode reward": -98.8028766846204, "Episode length": 999, "Policy Loss": -12.364924430847168, "Value Loss": 0.027978947386145592, "_runtime": 220.57084965705872, "_timestamp": 1585073731.5706117, "_step": 151}
{"Episode reward": -102.76190256901093, "Episode length": 999, "Policy Loss": -13.166200637817383, "Value Loss": 0.028771936893463135, "_runtime": 221.74478912353516, "_timestamp": 1585073732.7445512, "_step": 152}
{"Episode reward": -102.80744921085851, "Episode length": 999, "Policy Loss": -13.520639419555664, "Value Loss": 0.031411878764629364, "_runtime": 222.8608045578003, "_timestamp": 1585073733.8605666, "_step": 153}
{"Episode reward": -102.87302520096488, "Episode length": 999, "Policy Loss": -13.205406188964844, "Value Loss": 0.028633616864681244, "_runtime": 224.0274293422699, "_timestamp": 1585073735.0271914, "_step": 154}
{"Episode reward": -103.07238177544878, "Episode length": 999, "Policy Loss": -13.225006103515625, "Value Loss": 0.031793322414159775, "_runtime": 225.17351174354553, "_timestamp": 1585073736.1732738, "_step": 155}
{"Episode reward": -102.87331495511418, "Episode length": 999, "Policy Loss": -13.458762168884277, "Value Loss": 0.03170742839574814, "_runtime": 226.35946202278137, "_timestamp": 1585073737.359224, "_step": 156}
{"Episode reward": -99.55997020960928, "Episode length": 999, "Policy Loss": -12.82751750946045, "Value Loss": 0.029553327709436417, "_runtime": 227.50436091423035, "_timestamp": 1585073738.504123, "_step": 157}
{"Episode reward": -93.32484179782972, "Episode length": 999, "Policy Loss": -11.687349319458008, "Value Loss": 0.02503419853746891, "_runtime": 228.6420018672943, "_timestamp": 1585073739.641764, "_step": 158}
{"Episode reward": -101.54967408896492, "Episode length": 999, "Policy Loss": -13.074257850646973, "Value Loss": 0.029361730441451073, "_runtime": 229.7648696899414, "_timestamp": 1585073740.7646317, "_step": 159}
{"Episode reward": -106.97098414509915, "Episode length": 999, "Policy Loss": -14.299445152282715, "Value Loss": 0.03298477828502655, "_runtime": 230.8855438232422, "_timestamp": 1585073741.885306, "_step": 160}
{"Episode reward": -90.02924413972633, "Episode length": 999, "Policy Loss": -11.123391151428223, "Value Loss": 0.025752756744623184, "_runtime": 232.00208687782288, "_timestamp": 1585073743.001849, "_step": 161}
{"Episode reward": -98.60925019688061, "Episode length": 999, "Policy Loss": -12.728672981262207, "Value Loss": 0.030885351821780205, "_runtime": 233.13581347465515, "_timestamp": 1585073744.1355755, "_step": 162}
{"Episode reward": -98.27826424795037, "Episode length": 999, "Policy Loss": -12.363880157470703, "Value Loss": 0.029842311516404152, "_runtime": 234.25282883644104, "_timestamp": 1585073745.252591, "_step": 163}
{"Episode reward": -103.63823380158793, "Episode length": 999, "Policy Loss": -13.16471004486084, "Value Loss": 0.03419271484017372, "_runtime": 235.41197419166565, "_timestamp": 1585073746.4117362, "_step": 164}
{"Episode reward": -94.86114803437904, "Episode length": 999, "Policy Loss": -11.799826622009277, "Value Loss": 0.02764347940683365, "_runtime": 236.57782864570618, "_timestamp": 1585073747.5775907, "_step": 165}
{"Episode reward": -107.13817554487052, "Episode length": 999, "Policy Loss": -14.10857105255127, "Value Loss": 0.03340965881943703, "_runtime": 237.71835327148438, "_timestamp": 1585073748.7181153, "_step": 166}
{"Episode reward": -96.37775453326971, "Episode length": 999, "Policy Loss": -12.081332206726074, "Value Loss": 0.026536142453551292, "_runtime": 238.8871521949768, "_timestamp": 1585073749.8869143, "_step": 167}
{"Episode reward": -102.88212758357476, "Episode length": 999, "Policy Loss": -13.432880401611328, "Value Loss": 0.029814165085554123, "_runtime": 240.02123379707336, "_timestamp": 1585073751.0209959, "_step": 168}
{"Episode reward": -101.93749598573733, "Episode length": 999, "Policy Loss": -13.387262344360352, "Value Loss": 0.030734624713659286, "_runtime": 241.18151021003723, "_timestamp": 1585073752.1812723, "_step": 169}
{"Episode reward": -104.51621791825826, "Episode length": 999, "Policy Loss": -13.539125442504883, "Value Loss": 0.03212385252118111, "_runtime": 242.32342314720154, "_timestamp": 1585073753.3231852, "_step": 170}
{"Episode reward": -96.08508287151842, "Episode length": 999, "Policy Loss": -12.388798713684082, "Value Loss": 0.030012182891368866, "_runtime": 243.43697667121887, "_timestamp": 1585073754.4367387, "_step": 171}
{"Episode reward": -92.75117215435716, "Episode length": 999, "Policy Loss": -11.627842903137207, "Value Loss": 0.02821408025920391, "_runtime": 244.59792757034302, "_timestamp": 1585073755.5976896, "_step": 172}
{"Episode reward": -100.20755273055119, "Episode length": 999, "Policy Loss": -12.723715782165527, "Value Loss": 0.0324719101190567, "_runtime": 245.71870064735413, "_timestamp": 1585073756.7184627, "_step": 173}
{"Episode reward": -94.8503971730747, "Episode length": 999, "Policy Loss": -12.019279479980469, "Value Loss": 0.026427876204252243, "_runtime": 246.84264874458313, "_timestamp": 1585073757.8424108, "_step": 174}
{"Episode reward": -110.78614671546116, "Episode length": 999, "Policy Loss": -14.704803466796875, "Value Loss": 0.035937968641519547, "_runtime": 248.00088357925415, "_timestamp": 1585073759.0006456, "_step": 175}
{"Episode reward": -104.2984646501694, "Episode length": 999, "Policy Loss": -13.395561218261719, "Value Loss": 0.0329415500164032, "_runtime": 249.1124563217163, "_timestamp": 1585073760.1122184, "_step": 176}
{"Episode reward": -93.78946391288909, "Episode length": 999, "Policy Loss": -11.753263473510742, "Value Loss": 0.02556603029370308, "_runtime": 250.2422297000885, "_timestamp": 1585073761.2419918, "_step": 177}
{"Episode reward": -93.71052485473197, "Episode length": 999, "Policy Loss": -11.730020523071289, "Value Loss": 0.02741142176091671, "_runtime": 251.39228582382202, "_timestamp": 1585073762.392048, "_step": 178}
{"Episode reward": -95.90379325829583, "Episode length": 999, "Policy Loss": -12.115349769592285, "Value Loss": 0.030224280431866646, "_runtime": 252.51664185523987, "_timestamp": 1585073763.516404, "_step": 179}
{"Episode reward": -100.42334136166025, "Episode length": 999, "Policy Loss": -12.766780853271484, "Value Loss": 0.033575642853975296, "_runtime": 253.631742477417, "_timestamp": 1585073764.6315045, "_step": 180}
{"Episode reward": -98.35369931743095, "Episode length": 999, "Policy Loss": -12.744466781616211, "Value Loss": 0.03138873726129532, "_runtime": 254.80232906341553, "_timestamp": 1585073765.8020911, "_step": 181}
{"Episode reward": -101.05374951358796, "Episode length": 999, "Policy Loss": -12.930357933044434, "Value Loss": 0.030272645875811577, "_runtime": 255.98402214050293, "_timestamp": 1585073766.9837842, "_step": 182}
{"Episode reward": -98.05913279912579, "Episode length": 999, "Policy Loss": -12.514747619628906, "Value Loss": 0.031442828476428986, "_runtime": 257.1740620136261, "_timestamp": 1585073768.173824, "_step": 183}
{"Episode reward": -101.04737385705667, "Episode length": 999, "Policy Loss": -13.19892406463623, "Value Loss": 0.029441583901643753, "_runtime": 258.3065903186798, "_timestamp": 1585073769.3063524, "_step": 184}
{"Episode reward": -103.9272083460218, "Episode length": 999, "Policy Loss": -13.345428466796875, "Value Loss": 0.0332377552986145, "_runtime": 259.43586444854736, "_timestamp": 1585073770.4356265, "_step": 185}
{"Episode reward": -100.5007599506568, "Episode length": 999, "Policy Loss": -12.847829818725586, "Value Loss": 0.02900410257279873, "_runtime": 260.55124068260193, "_timestamp": 1585073771.5510027, "_step": 186}
{"Episode reward": -99.13526841305344, "Episode length": 999, "Policy Loss": -12.65588665008545, "Value Loss": 0.03144466504454613, "_runtime": 261.6860077381134, "_timestamp": 1585073772.6857698, "_step": 187}
{"Episode reward": -110.383907524204, "Episode length": 999, "Policy Loss": -14.69048023223877, "Value Loss": 0.035360004752874374, "_runtime": 262.8110890388489, "_timestamp": 1585073773.810851, "_step": 188}
{"Episode reward": -100.39812192637474, "Episode length": 999, "Policy Loss": -12.718256950378418, "Value Loss": 0.03157571330666542, "_runtime": 263.95811772346497, "_timestamp": 1585073774.9578798, "_step": 189}
{"Episode reward": -98.9857551209122, "Episode length": 999, "Policy Loss": -12.726767539978027, "Value Loss": 0.02874847874045372, "_runtime": 265.0875771045685, "_timestamp": 1585073776.0873392, "_step": 190}
{"Episode reward": -95.69801131881083, "Episode length": 999, "Policy Loss": -12.14523983001709, "Value Loss": 0.028513334691524506, "_runtime": 266.2554783821106, "_timestamp": 1585073777.2552404, "_step": 191}
{"Episode reward": -100.43624653094422, "Episode length": 999, "Policy Loss": -13.073354721069336, "Value Loss": 0.03138900175690651, "_runtime": 267.38557505607605, "_timestamp": 1585073778.385337, "_step": 192}
{"Episode reward": -97.08949495839968, "Episode length": 999, "Policy Loss": -12.300012588500977, "Value Loss": 0.02884560637176037, "_runtime": 268.4958961009979, "_timestamp": 1585073779.4956582, "_step": 193}
{"Episode reward": -101.85675794407186, "Episode length": 999, "Policy Loss": -13.268216133117676, "Value Loss": 0.030443372204899788, "_runtime": 269.62619280815125, "_timestamp": 1585073780.6259549, "_step": 194}
{"Episode reward": -111.69932692492706, "Episode length": 999, "Policy Loss": -15.012537002563477, "Value Loss": 0.03913908079266548, "_runtime": 270.751695394516, "_timestamp": 1585073781.7514575, "_step": 195}
{"Episode reward": -109.52830897971833, "Episode length": 999, "Policy Loss": -14.585792541503906, "Value Loss": 0.03464784845709801, "_runtime": 271.86626410484314, "_timestamp": 1585073782.8660262, "_step": 196}
{"Episode reward": -97.443684362655, "Episode length": 999, "Policy Loss": -12.530203819274902, "Value Loss": 0.027983052656054497, "_runtime": 273.0036292076111, "_timestamp": 1585073784.0033913, "_step": 197}
{"Episode reward": -101.62939407423706, "Episode length": 999, "Policy Loss": -13.057360649108887, "Value Loss": 0.030231814831495285, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812, 151.97512817382812]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-85.59774017333984, -81.93289184570312, -78.2680435180664, -74.60319519042969, -70.93834686279297, -67.27349853515625, -63.608646392822266, -59.94379806518555, -56.27894973754883, -52.61410140991211, -48.94925308227539, -45.28440475463867, -41.61955261230469, -37.95470428466797, -34.28985595703125, -30.62500762939453, -26.960159301757812, -23.295310974121094, -19.630462646484375, -15.965614318847656, -12.300765991210938, -8.635917663574219, -4.9710693359375, -1.3062210083007812, 2.3586349487304688, 6.0234832763671875, 9.688331604003906, 13.353179931640625, 17.018028259277344, 20.682876586914062, 24.34772491455078, 28.0125732421875, 31.67742156982422, 35.34226989746094, 39.007118225097656, 42.671974182128906, 46.336814880371094, 50.001670837402344, 53.66651153564453, 57.33136749267578, 60.99620819091797, 64.66106414794922, 68.3259048461914, 71.99076080322266, 75.65560150146484, 79.3204574584961, 82.98529815673828, 86.65015411376953, 90.31501007080078, 93.97985076904297, 97.64470672607422, 101.3095474243164, 104.97440338134766, 108.63924407958984, 112.3041000366211, 115.96894073486328, 119.63379669189453, 123.29863739013672, 126.96349334716797, 130.62832641601562, 134.29318237304688, 137.95803833007812, 141.62289428710938, 145.2877197265625, 148.95257568359375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-83.3947525024414, -80.95439910888672, -78.51404571533203, -76.07369232177734, -73.63333892822266, -71.19298553466797, -68.75263214111328, -66.3122787475586, -63.871925354003906, -61.43157196044922, -58.99121856689453, -56.550865173339844, -54.110511779785156, -51.67015838623047, -49.22980499267578, -46.789451599121094, -44.349098205566406, -41.90874481201172, -39.46839141845703, -37.028038024902344, -34.587684631347656, -32.14733123779297, -29.70697784423828, -27.266624450683594, -24.826271057128906, -22.38591766357422, -19.94556427001953, -17.505210876464844, -15.064857482910156, -12.624504089355469, -10.184150695800781, -7.743797302246094, -5.303443908691406, -2.8630905151367188, -0.42273712158203125, 2.0176162719726562, 4.457969665527344, 6.898323059082031, 9.338676452636719, 11.779029846191406, 14.219383239746094, 16.65973663330078, 19.10009002685547, 21.540443420410156, 23.980796813964844, 26.42115020751953, 28.86150360107422, 31.301856994628906, 33.742210388183594, 36.18256378173828, 38.62291717529297, 41.063270568847656, 43.503623962402344, 45.94397735595703, 48.38433074951172, 50.824684143066406, 53.265037536621094, 55.70539093017578, 58.14574432373047, 60.586097717285156, 63.026451110839844, 65.46680450439453, 67.90715789794922, 70.3475112915039, 72.7878646850586]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 4.0, 6.0, 6.0, 4.0, 10.0, 4.0, 13.0, 11.0, 13.0, 10.0, 13.0, 17.0, 15.0, 23.0, 50.0, 46.0, 38.0, 37.0, 26.0, 28.0, 28.0, 19.0, 14.0, 14.0, 3.0, 8.0, 6.0, 3.0, 2.0, 4.0, 3.0, 5.0, 5.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-74.13542938232422, -71.96602630615234, -69.79662322998047, -67.62722778320312, -65.45782470703125, -63.288421630859375, -61.1190185546875, -58.949615478515625, -56.780216217041016, -54.610816955566406, -52.44141387939453, -50.272010803222656, -48.10260772705078, -45.93320846557617, -43.7638053894043, -41.59440612792969, -39.42500305175781, -37.25559997558594, -35.08620071411133, -32.91679763793945, -30.747398376464844, -28.57799530029297, -26.408592224121094, -24.239192962646484, -22.06978988647461, -19.900386810302734, -17.730987548828125, -15.56158447265625, -13.392181396484375, -11.222782135009766, -9.053382873535156, -6.883979797363281, -4.714576721191406, -2.5451736450195312, -0.37577056884765625, 1.7936248779296875, 3.9630279541015625, 6.1324310302734375, 8.301834106445312, 10.471237182617188, 12.640632629394531, 14.810035705566406, 16.97943878173828, 19.148841857910156, 21.31824493408203, 23.487648010253906, 25.65704345703125, 27.826446533203125, 29.995849609375, 32.165252685546875, 34.33465576171875, 36.504051208496094, 38.67345428466797, 40.842857360839844, 43.01226043701172, 45.181663513183594, 47.35106658935547, 49.52046203613281, 51.68986511230469, 53.85926818847656, 56.028663635253906, 58.19806671142578, 60.367469787597656, 62.53687286376953, 64.7062759399414]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-32.66212844848633, -31.21288299560547, -29.76363754272461, -28.31439208984375, -26.86514663696289, -25.41590118408203, -23.966657638549805, -22.517412185668945, -21.068166732788086, -19.618921279907227, -18.169675827026367, -16.72043228149414, -15.271186828613281, -13.821941375732422, -12.372695922851562, -10.923450469970703, -9.474205017089844, -8.024959564208984, -6.575714111328125, -5.126468658447266, -3.6772232055664062, -2.2279796600341797, -0.7787342071533203, 0.6705131530761719, 2.1197547912597656, 3.569000244140625, 5.018245697021484, 6.467491149902344, 7.916736602783203, 9.365982055664062, 10.815227508544922, 12.264472961425781, 13.71371841430664, 15.1629638671875, 16.61220932006836, 18.06145477294922, 19.510700225830078, 20.959945678710938, 22.409191131591797, 23.858436584472656, 25.307682037353516, 26.75692367553711, 28.20616912841797, 29.655414581298828, 31.104660034179688, 32.55390548706055, 34.00315475463867, 35.452396392822266, 36.90163803100586, 38.350887298583984, 39.80012893676758, 41.2493782043457, 42.6986198425293, 44.14786911010742, 45.597110748291016, 47.04636001586914, 48.495601654052734, 49.94485092163086, 51.39409255981445, 52.84334182739258, 54.29258346557617, 55.7418327331543, 57.19107437133789, 58.640323638916016, 60.08956527709961]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 7.0, 25.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-41.292110443115234, -40.29023742675781, -39.288360595703125, -38.2864875793457, -37.28461456298828, -36.282737731933594, -35.28086471557617, -34.278987884521484, -33.27711486816406, -32.275238037109375, -31.273365020751953, -30.27149200439453, -29.269617080688477, -28.267742156982422, -27.265869140625, -26.263994216918945, -25.26211929321289, -24.260244369506836, -23.25836944580078, -22.25649642944336, -21.254621505737305, -20.25274658203125, -19.250873565673828, -18.248998641967773, -17.24712371826172, -16.245248794555664, -15.24337387084961, -14.241500854492188, -13.239625930786133, -12.237751007080078, -11.235877990722656, -10.234003067016602, -9.232128143310547, -8.230255126953125, -7.2283782958984375, -6.226505279541016, -5.224628448486328, -4.222755432128906, -3.2208824157714844, -2.219005584716797, -1.217132568359375, -0.21525955200195312, 0.7866172790527344, 1.7884902954101562, 2.790363311767578, 3.7922401428222656, 4.7941131591796875, 5.795989990234375, 6.797863006591797, 7.799736022949219, 8.801612854003906, 9.803485870361328, 10.805362701416016, 11.807235717773438, 12.80910873413086, 13.810985565185547, 14.812858581542969, 15.81473159790039, 16.816608428955078, 17.8184814453125, 18.820354461669922, 19.82223129272461, 20.82410430908203, 21.82598114013672, 22.82785415649414]}, "_runtime": 274.10688757896423, "_timestamp": 1585073785.1066496, "_step": 198}
{"Episode reward": -103.44563280526714, "Episode length": 999, "Policy Loss": -13.330411911010742, "Value Loss": 0.029238469898700714, "_runtime": 275.28367042541504, "_timestamp": 1585073786.2834325, "_step": 199}
{"Episode reward": -101.29297682292446, "Episode length": 999, "Policy Loss": -13.216973304748535, "Value Loss": 0.03177328035235405, "_runtime": 276.4498927593231, "_timestamp": 1585073787.4496548, "_step": 200}
{"Episode reward": -105.23849333262237, "Episode length": 999, "Policy Loss": -13.919310569763184, "Value Loss": 0.03327780216932297, "_runtime": 277.57891511917114, "_timestamp": 1585073788.5786772, "_step": 201}
{"Episode reward": -94.58638014741221, "Episode length": 999, "Policy Loss": -12.12450122833252, "Value Loss": 0.025801049545407295, "_runtime": 278.72693061828613, "_timestamp": 1585073789.7266927, "_step": 202}
{"Episode reward": -111.04779607475768, "Episode length": 999, "Policy Loss": -14.811448097229004, "Value Loss": 0.036761168390512466, "_runtime": 279.85481882095337, "_timestamp": 1585073790.8545809, "_step": 203}
{"Episode reward": -103.33402046257568, "Episode length": 999, "Policy Loss": -13.582901954650879, "Value Loss": 0.033627573400735855, "_runtime": 280.9899010658264, "_timestamp": 1585073791.9896631, "_step": 204}
{"Episode reward": -107.73171091570775, "Episode length": 999, "Policy Loss": -14.288650512695312, "Value Loss": 0.03341270238161087, "_runtime": 282.1127665042877, "_timestamp": 1585073793.1125286, "_step": 205}
{"Episode reward": -105.67452501651762, "Episode length": 999, "Policy Loss": -13.894744873046875, "Value Loss": 0.03437833487987518, "_runtime": 283.26011538505554, "_timestamp": 1585073794.2598774, "_step": 206}
{"Episode reward": -92.60530293086204, "Episode length": 999, "Policy Loss": -11.685340881347656, "Value Loss": 0.024671148508787155, "_runtime": 284.4015083312988, "_timestamp": 1585073795.4012704, "_step": 207}
{"Episode reward": -90.59300661257578, "Episode length": 999, "Policy Loss": -11.194991111755371, "Value Loss": 0.026265505701303482, "_runtime": 285.5715522766113, "_timestamp": 1585073796.5713143, "_step": 208}
{"Episode reward": -100.14973926299793, "Episode length": 999, "Policy Loss": -12.551828384399414, "Value Loss": 0.02813820168375969, "_runtime": 286.73493123054504, "_timestamp": 1585073797.7346933, "_step": 209}
{"Episode reward": -94.22529214962478, "Episode length": 999, "Policy Loss": -11.925423622131348, "Value Loss": 0.027987485751509666, "_runtime": 287.8767988681793, "_timestamp": 1585073798.876561, "_step": 210}
{"Episode reward": -96.39485616428236, "Episode length": 999, "Policy Loss": -12.13365364074707, "Value Loss": 0.027280455455183983, "_runtime": 289.0080738067627, "_timestamp": 1585073800.0078359, "_step": 211}
{"Episode reward": -102.28110125231582, "Episode length": 999, "Policy Loss": -12.983269691467285, "Value Loss": 0.031476326286792755, "_runtime": 290.1462254524231, "_timestamp": 1585073801.1459875, "_step": 212}
{"Episode reward": -99.75701124315502, "Episode length": 999, "Policy Loss": -12.736454010009766, "Value Loss": 0.02881348505616188, "_runtime": 291.2899205684662, "_timestamp": 1585073802.2896826, "_step": 213}
{"Episode reward": -101.95168804470475, "Episode length": 999, "Policy Loss": -13.331335067749023, "Value Loss": 0.03294849768280983, "_runtime": 292.44314885139465, "_timestamp": 1585073803.442911, "_step": 214}
{"Episode reward": -107.4004239407087, "Episode length": 999, "Policy Loss": -14.17507266998291, "Value Loss": 0.03409494832158089, "_runtime": 293.55987548828125, "_timestamp": 1585073804.5596375, "_step": 215}
{"Episode reward": -105.22793979380495, "Episode length": 999, "Policy Loss": -13.647284507751465, "Value Loss": 0.03208550065755844, "_runtime": 294.2895314693451, "_timestamp": 1585073805.2892935, "_step": 216}
{"Episode reward": 32.97424997574447, "Episode length": 646, "Policy Loss": 9.93818473815918, "Value Loss": 15.426626205444336, "_runtime": 295.44393658638, "_timestamp": 1585073806.4436986, "_step": 217}
{"Episode reward": -106.57384037026965, "Episode length": 999, "Policy Loss": -13.965861320495605, "Value Loss": 0.03369937837123871, "_runtime": 296.57869815826416, "_timestamp": 1585073807.5784602, "_step": 218}
{"Episode reward": -101.03655841094678, "Episode length": 999, "Policy Loss": -13.018624305725098, "Value Loss": 0.032025210559368134, "_runtime": 297.70368123054504, "_timestamp": 1585073808.7034433, "_step": 219}
{"Episode reward": -98.78238029972046, "Episode length": 999, "Policy Loss": -12.683475494384766, "Value Loss": 0.028100863099098206, "_runtime": 298.90388536453247, "_timestamp": 1585073809.9036474, "_step": 220}
{"Episode reward": -99.74194839591648, "Episode length": 999, "Policy Loss": -12.721324920654297, "Value Loss": 0.02976052463054657, "_runtime": 300.0351369380951, "_timestamp": 1585073811.034899, "_step": 221}
{"Episode reward": -104.54866937139516, "Episode length": 999, "Policy Loss": -13.548343658447266, "Value Loss": 0.03218722343444824, "_runtime": 301.2462418079376, "_timestamp": 1585073812.2460039, "_step": 222}
{"Episode reward": -107.17743012102659, "Episode length": 999, "Policy Loss": -13.948968887329102, "Value Loss": 0.03587907925248146, "_runtime": 302.47083282470703, "_timestamp": 1585073813.470595, "_step": 223}
{"Episode reward": -101.50404876380885, "Episode length": 999, "Policy Loss": -13.305096626281738, "Value Loss": 0.030877145007252693, "_runtime": 303.61346983909607, "_timestamp": 1585073814.613232, "_step": 224}
{"Episode reward": -101.10044907166825, "Episode length": 999, "Policy Loss": -12.913569450378418, "Value Loss": 0.030944330617785454, "_runtime": 304.8414776325226, "_timestamp": 1585073815.8412397, "_step": 225}
{"Episode reward": -100.93048475454708, "Episode length": 999, "Policy Loss": -12.962173461914062, "Value Loss": 0.03163470700383186, "_runtime": 306.01538252830505, "_timestamp": 1585073817.0151446, "_step": 226}
{"Episode reward": -104.7726194355324, "Episode length": 999, "Policy Loss": -13.822576522827148, "Value Loss": 0.03215145319700241, "_runtime": 307.1932818889618, "_timestamp": 1585073818.193044, "_step": 227}
{"Episode reward": -96.112413502724, "Episode length": 999, "Policy Loss": -12.301262855529785, "Value Loss": 0.027829164639115334, "_runtime": 308.3508985042572, "_timestamp": 1585073819.3506606, "_step": 228}
{"Episode reward": -92.74328234914965, "Episode length": 999, "Policy Loss": -11.767772674560547, "Value Loss": 0.024154996499419212, "_runtime": 309.4940495491028, "_timestamp": 1585073820.4938116, "_step": 229}
{"Episode reward": -100.78713590176677, "Episode length": 999, "Policy Loss": -12.9601469039917, "Value Loss": 0.030550410971045494, "_runtime": 310.627313375473, "_timestamp": 1585073821.6270754, "_step": 230}
{"Episode reward": -100.08156016086338, "Episode length": 999, "Policy Loss": -12.884174346923828, "Value Loss": 0.033776238560676575, "_runtime": 311.72791862487793, "_timestamp": 1585073822.7276807, "_step": 231}
{"Episode reward": -90.84722247707666, "Episode length": 999, "Policy Loss": -11.429841995239258, "Value Loss": 0.026717534288764, "_runtime": 312.8486421108246, "_timestamp": 1585073823.8484042, "_step": 232}
{"Episode reward": -107.2453193059827, "Episode length": 999, "Policy Loss": -14.158215522766113, "Value Loss": 0.03396916016936302, "_runtime": 313.94821667671204, "_timestamp": 1585073824.9479787, "_step": 233}
{"Episode reward": -100.08006103243352, "Episode length": 999, "Policy Loss": -12.982772827148438, "Value Loss": 0.024963101372122765, "_runtime": 315.10134768486023, "_timestamp": 1585073826.1011097, "_step": 234}
{"Episode reward": -104.67796108647791, "Episode length": 999, "Policy Loss": -13.737622261047363, "Value Loss": 0.03407697007060051, "_runtime": 316.2434775829315, "_timestamp": 1585073827.2432396, "_step": 235}
{"Episode reward": -101.6330913055577, "Episode length": 999, "Policy Loss": -13.108161926269531, "Value Loss": 0.03039052151143551, "_runtime": 317.3656623363495, "_timestamp": 1585073828.3654244, "_step": 236}
{"Episode reward": -100.61077436714366, "Episode length": 999, "Policy Loss": -13.00298023223877, "Value Loss": 0.029197942465543747, "_runtime": 318.48200368881226, "_timestamp": 1585073829.4817657, "_step": 237}
{"Episode reward": -95.8119926031843, "Episode length": 999, "Policy Loss": -12.151546478271484, "Value Loss": 0.029401687905192375, "_runtime": 319.62747502326965, "_timestamp": 1585073830.627237, "_step": 238}
{"Episode reward": -103.7860713105829, "Episode length": 999, "Policy Loss": -13.856623649597168, "Value Loss": 0.029090313240885735, "_runtime": 320.80116605758667, "_timestamp": 1585073831.800928, "_step": 239}
{"Episode reward": -105.03895867353643, "Episode length": 999, "Policy Loss": -13.813394546508789, "Value Loss": 0.03265724703669548, "_runtime": 321.9330132007599, "_timestamp": 1585073832.9327753, "_step": 240}
{"Episode reward": -99.38028855089648, "Episode length": 999, "Policy Loss": -12.610007286071777, "Value Loss": 0.02896624058485031, "_runtime": 323.08691215515137, "_timestamp": 1585073834.0866742, "_step": 241}
{"Episode reward": -104.7004368997186, "Episode length": 999, "Policy Loss": -14.090824127197266, "Value Loss": 0.03158820793032646, "_runtime": 324.17413902282715, "_timestamp": 1585073835.173901, "_step": 242}
{"Episode reward": -103.8915169480459, "Episode length": 999, "Policy Loss": -13.478601455688477, "Value Loss": 0.03345133364200592, "_runtime": 325.3379416465759, "_timestamp": 1585073836.3377037, "_step": 243}
{"Episode reward": -105.18037739166846, "Episode length": 999, "Policy Loss": -13.750155448913574, "Value Loss": 0.03303051367402077, "_runtime": 326.490168094635, "_timestamp": 1585073837.4899302, "_step": 244}
{"Episode reward": -108.43229563220302, "Episode length": 999, "Policy Loss": -14.413785934448242, "Value Loss": 0.03377191722393036, "_runtime": 327.6052691936493, "_timestamp": 1585073838.6050313, "_step": 245}
{"Episode reward": -107.41610586395832, "Episode length": 999, "Policy Loss": -14.023537635803223, "Value Loss": 0.035378050059080124, "_runtime": 328.7658383846283, "_timestamp": 1585073839.7656004, "_step": 246}
{"Episode reward": -98.48191748311119, "Episode length": 999, "Policy Loss": -12.633858680725098, "Value Loss": 0.03129513934254646, "_runtime": 329.8856165409088, "_timestamp": 1585073840.8853786, "_step": 247}
{"Episode reward": -93.11475763364098, "Episode length": 999, "Policy Loss": -11.793205261230469, "Value Loss": 0.02698167972266674, "_runtime": 331.00804686546326, "_timestamp": 1585073842.007809, "_step": 248}
{"Episode reward": -103.09486188215702, "Episode length": 999, "Policy Loss": -13.591833114624023, "Value Loss": 0.032088205218315125, "_runtime": 332.12925267219543, "_timestamp": 1585073843.1290147, "_step": 249}
{"Episode reward": -105.32798235316547, "Episode length": 999, "Policy Loss": -13.847811698913574, "Value Loss": 0.03682614117860794, "_runtime": 333.2725877761841, "_timestamp": 1585073844.2723498, "_step": 250}
{"Episode reward": -99.1768468446444, "Episode length": 999, "Policy Loss": -12.908000946044922, "Value Loss": 0.027383482083678246, "_runtime": 334.37490344047546, "_timestamp": 1585073845.3746655, "_step": 251}
{"Episode reward": -97.9412150630654, "Episode length": 999, "Policy Loss": -12.52216625213623, "Value Loss": 0.030129801481962204, "_runtime": 335.528169631958, "_timestamp": 1585073846.5279317, "_step": 252}
{"Episode reward": -91.49879831509318, "Episode length": 999, "Policy Loss": -11.218509674072266, "Value Loss": 0.02519582211971283, "_runtime": 336.65512704849243, "_timestamp": 1585073847.654889, "_step": 253}
{"Episode reward": -96.21374535380966, "Episode length": 999, "Policy Loss": -12.416712760925293, "Value Loss": 0.028448453173041344, "_runtime": 337.7692129611969, "_timestamp": 1585073848.768975, "_step": 254}
{"Episode reward": -99.34402422302806, "Episode length": 999, "Policy Loss": -12.757780075073242, "Value Loss": 0.028218848630785942, "_runtime": 338.9369275569916, "_timestamp": 1585073849.9366896, "_step": 255}
{"Episode reward": -98.417831173595, "Episode length": 999, "Policy Loss": -12.414409637451172, "Value Loss": 0.03116452880203724, "_runtime": 340.06673669815063, "_timestamp": 1585073851.0664988, "_step": 256}
{"Episode reward": -94.20405924387295, "Episode length": 999, "Policy Loss": -12.097481727600098, "Value Loss": 0.027500273659825325, "_runtime": 341.1932907104492, "_timestamp": 1585073852.1930528, "_step": 257}
{"Episode reward": -99.54700072505011, "Episode length": 999, "Policy Loss": -12.852399826049805, "Value Loss": 0.02865941822528839, "_runtime": 342.3506236076355, "_timestamp": 1585073853.3503857, "_step": 258}
{"Episode reward": -99.73585494538818, "Episode length": 999, "Policy Loss": -12.68082332611084, "Value Loss": 0.029892191290855408, "_runtime": 343.46730184555054, "_timestamp": 1585073854.467064, "_step": 259}
{"Episode reward": -99.33037659620193, "Episode length": 999, "Policy Loss": -12.888846397399902, "Value Loss": 0.029954416677355766, "_runtime": 344.6065459251404, "_timestamp": 1585073855.606308, "_step": 260}
{"Episode reward": -105.16630151815554, "Episode length": 999, "Policy Loss": -13.733688354492188, "Value Loss": 0.03479722887277603, "_runtime": 345.7188813686371, "_timestamp": 1585073856.7186434, "_step": 261}
{"Episode reward": -97.4081130093203, "Episode length": 999, "Policy Loss": -12.076200485229492, "Value Loss": 0.030002694576978683, "_runtime": 346.8721399307251, "_timestamp": 1585073857.871902, "_step": 262}
{"Episode reward": -105.59165320076144, "Episode length": 999, "Policy Loss": -13.91679859161377, "Value Loss": 0.03249986097216606, "_runtime": 348.02773427963257, "_timestamp": 1585073859.0274963, "_step": 263}
{"Episode reward": -93.75713585985433, "Episode length": 999, "Policy Loss": -11.885793685913086, "Value Loss": 0.026575522497296333, "_runtime": 349.15227007865906, "_timestamp": 1585073860.1520321, "_step": 264}
{"Episode reward": -96.28965393449373, "Episode length": 999, "Policy Loss": -12.160296440124512, "Value Loss": 0.0295394454151392, "_runtime": 350.33016657829285, "_timestamp": 1585073861.3299286, "_step": 265}
{"Episode reward": -91.99904950916171, "Episode length": 999, "Policy Loss": -11.542377471923828, "Value Loss": 0.023675601929426193, "_runtime": 351.45870327949524, "_timestamp": 1585073862.4584653, "_step": 266}
{"Episode reward": -93.15351063739524, "Episode length": 999, "Policy Loss": -11.540773391723633, "Value Loss": 0.02508298121392727, "_runtime": 352.55049896240234, "_timestamp": 1585073863.550261, "_step": 267}
{"Episode reward": -98.64530721646199, "Episode length": 999, "Policy Loss": -12.764631271362305, "Value Loss": 0.02835780382156372, "_runtime": 353.65672731399536, "_timestamp": 1585073864.6564894, "_step": 268}
{"Episode reward": -105.44370103111788, "Episode length": 999, "Policy Loss": -14.015923500061035, "Value Loss": 0.032605234533548355, "_runtime": 354.7817747592926, "_timestamp": 1585073865.7815368, "_step": 269}
{"Episode reward": -99.23367992175346, "Episode length": 999, "Policy Loss": -12.922189712524414, "Value Loss": 0.030076786875724792, "_runtime": 355.923202753067, "_timestamp": 1585073866.9229648, "_step": 270}
{"Episode reward": -101.41525121394069, "Episode length": 999, "Policy Loss": -12.869281768798828, "Value Loss": 0.030641596764326096, "_runtime": 357.094624042511, "_timestamp": 1585073868.094386, "_step": 271}
{"Episode reward": -106.17301411063495, "Episode length": 999, "Policy Loss": -14.103707313537598, "Value Loss": 0.034137140959501266, "_runtime": 358.20826053619385, "_timestamp": 1585073869.2080226, "_step": 272}
{"Episode reward": -107.927886179535, "Episode length": 999, "Policy Loss": -14.167098045349121, "Value Loss": 0.03716020658612251, "_runtime": 359.37170577049255, "_timestamp": 1585073870.3714678, "_step": 273}
{"Episode reward": -97.61950269452193, "Episode length": 999, "Policy Loss": -12.173480987548828, "Value Loss": 0.02720918133854866, "_runtime": 360.5057876110077, "_timestamp": 1585073871.5055497, "_step": 274}
{"Episode reward": -94.71416578968322, "Episode length": 999, "Policy Loss": -11.786443710327148, "Value Loss": 0.0261697918176651, "_runtime": 361.6177570819855, "_timestamp": 1585073872.6175191, "_step": 275}
{"Episode reward": -98.36895009950777, "Episode length": 999, "Policy Loss": -12.619922637939453, "Value Loss": 0.02646704763174057, "_runtime": 362.73268246650696, "_timestamp": 1585073873.7324445, "_step": 276}
{"Episode reward": -109.5800893349755, "Episode length": 999, "Policy Loss": -14.559337615966797, "Value Loss": 0.038264211267232895, "_runtime": 363.8577206134796, "_timestamp": 1585073874.8574827, "_step": 277}
{"Episode reward": -98.89412881491295, "Episode length": 999, "Policy Loss": -12.59210205078125, "Value Loss": 0.0309738926589489, "_runtime": 364.9803237915039, "_timestamp": 1585073875.9800858, "_step": 278}
{"Episode reward": -95.96013957485476, "Episode length": 999, "Policy Loss": -12.255817413330078, "Value Loss": 0.025561213493347168, "_runtime": 366.10167026519775, "_timestamp": 1585073877.1014323, "_step": 279}
{"Episode reward": -113.00005666251236, "Episode length": 999, "Policy Loss": -15.347737312316895, "Value Loss": 0.03807650879025459, "_runtime": 367.2686867713928, "_timestamp": 1585073878.2684488, "_step": 280}
{"Episode reward": -94.16015689776906, "Episode length": 999, "Policy Loss": -11.72353458404541, "Value Loss": 0.027728548273444176, "_runtime": 368.4040219783783, "_timestamp": 1585073879.403784, "_step": 281}
{"Episode reward": -95.44701782007682, "Episode length": 999, "Policy Loss": -12.216407775878906, "Value Loss": 0.02972996234893799, "_runtime": 369.5173966884613, "_timestamp": 1585073880.5171587, "_step": 282}
{"Episode reward": -96.14953769333839, "Episode length": 999, "Policy Loss": -12.370707511901855, "Value Loss": 0.02759767696261406, "_runtime": 370.64504623413086, "_timestamp": 1585073881.6448083, "_step": 283}
{"Episode reward": -105.44751194139815, "Episode length": 999, "Policy Loss": -13.674596786499023, "Value Loss": 0.031531866639852524, "_runtime": 371.74849128723145, "_timestamp": 1585073882.7482533, "_step": 284}
{"Episode reward": -97.20860877242608, "Episode length": 999, "Policy Loss": -12.389759063720703, "Value Loss": 0.025247842073440552, "_runtime": 372.86571192741394, "_timestamp": 1585073883.865474, "_step": 285}
{"Episode reward": -103.72361588333015, "Episode length": 999, "Policy Loss": -13.502785682678223, "Value Loss": 0.030507629737257957, "_runtime": 373.96226978302, "_timestamp": 1585073884.9620318, "_step": 286}
{"Episode reward": -93.12807603444506, "Episode length": 999, "Policy Loss": -11.71070384979248, "Value Loss": 0.023021984845399857, "_runtime": 375.09608936309814, "_timestamp": 1585073886.0958514, "_step": 287}
{"Episode reward": -97.4201112684084, "Episode length": 999, "Policy Loss": -12.482651710510254, "Value Loss": 0.03040066547691822, "_runtime": 376.2393879890442, "_timestamp": 1585073887.23915, "_step": 288}
{"Episode reward": -95.24392200726855, "Episode length": 999, "Policy Loss": -12.078953742980957, "Value Loss": 0.02629700116813183, "_runtime": 377.3936114311218, "_timestamp": 1585073888.3933735, "_step": 289}
{"Episode reward": -98.57388791885833, "Episode length": 999, "Policy Loss": -12.604652404785156, "Value Loss": 0.026330342516303062, "_runtime": 378.5143961906433, "_timestamp": 1585073889.5141582, "_step": 290}
{"Episode reward": -99.5245551262207, "Episode length": 999, "Policy Loss": -12.68781852722168, "Value Loss": 0.03239764645695686, "_runtime": 379.625545501709, "_timestamp": 1585073890.6253076, "_step": 291}
{"Episode reward": -99.40654148444193, "Episode length": 999, "Policy Loss": -12.826001167297363, "Value Loss": 0.02957765944302082, "_runtime": 380.7396605014801, "_timestamp": 1585073891.7394226, "_step": 292}
{"Episode reward": -100.42991294120364, "Episode length": 999, "Policy Loss": -12.910823822021484, "Value Loss": 0.028106149286031723, "_runtime": 381.840528011322, "_timestamp": 1585073892.84029, "_step": 293}
{"Episode reward": -104.73391139954707, "Episode length": 999, "Policy Loss": -13.789236068725586, "Value Loss": 0.03841128572821617, "_runtime": 382.98651027679443, "_timestamp": 1585073893.9862723, "_step": 294}
{"Episode reward": -99.46959838462524, "Episode length": 999, "Policy Loss": -12.615584373474121, "Value Loss": 0.0316864438354969, "_runtime": 384.12428283691406, "_timestamp": 1585073895.124045, "_step": 295}
{"Episode reward": -100.10381955199055, "Episode length": 999, "Policy Loss": -12.85092544555664, "Value Loss": 0.03024628572165966, "_runtime": 385.3067936897278, "_timestamp": 1585073896.3065557, "_step": 296}
{"Episode reward": -93.43219788256695, "Episode length": 999, "Policy Loss": -11.794224739074707, "Value Loss": 0.024779239669442177, "_runtime": 386.46142625808716, "_timestamp": 1585073897.4611883, "_step": 297}
{"Episode reward": -97.04695599538233, "Episode length": 999, "Policy Loss": -12.549654006958008, "Value Loss": 0.02694302424788475, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531, -102.12068176269531]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-98.7614974975586, -96.33636474609375, -93.9112319946289, -91.48609924316406, -89.06096649169922, -86.63583374023438, -84.21070098876953, -81.78556823730469, -79.36044311523438, -76.935302734375, -74.51017761230469, -72.08504486083984, -69.659912109375, -67.23477935791016, -64.80964660644531, -62.38451385498047, -59.959381103515625, -57.53424835205078, -55.10911560058594, -52.683982849121094, -50.25885009765625, -47.83372116088867, -45.40858840942383, -42.983455657958984, -40.55832290649414, -38.1331901550293, -35.70805740356445, -33.282928466796875, -30.85779571533203, -28.432662963867188, -26.007530212402344, -23.5823974609375, -21.157264709472656, -18.732131958007812, -16.30699920654297, -13.881866455078125, -11.456733703613281, -9.031600952148438, -6.606468200683594, -4.18133544921875, -1.7562026977539062, 0.6689224243164062, 3.09405517578125, 5.519187927246094, 7.9443206787109375, 10.369453430175781, 12.794586181640625, 15.219718933105469, 17.644851684570312, 20.069984436035156, 22.4951171875, 24.920249938964844, 27.345382690429688, 29.77051544189453, 32.195640563964844, 34.62078094482422, 37.04590606689453, 39.471046447753906, 41.89617156982422, 44.321311950683594, 46.746437072753906, 49.17157745361328, 51.596702575683594, 54.02184295654297, 56.44696807861328]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-49.04640197753906, -47.40691375732422, -45.767425537109375, -44.12793731689453, -42.48844909667969, -40.848960876464844, -39.20947265625, -37.569984436035156, -35.93049621582031, -34.29100799560547, -32.651519775390625, -31.012033462524414, -29.372547149658203, -27.73305892944336, -26.093570709228516, -24.454082489013672, -22.814594268798828, -21.175106048583984, -19.53561782836914, -17.896129608154297, -16.256641387939453, -14.61715316772461, -12.977664947509766, -11.338176727294922, -9.698692321777344, -8.0592041015625, -6.419715881347656, -4.7802276611328125, -3.1407394409179688, -1.501251220703125, 0.13823699951171875, 1.7777252197265625, 3.4172134399414062, 5.05670166015625, 6.696189880371094, 8.335678100585938, 9.975166320800781, 11.614654541015625, 13.254142761230469, 14.893630981445312, 16.533119201660156, 18.172607421875, 19.812095642089844, 21.451583862304688, 23.09107208251953, 24.730560302734375, 26.37004852294922, 28.009536743164062, 29.649017333984375, 31.28850555419922, 32.92799377441406, 34.567481994628906, 36.20697021484375, 37.846458435058594, 39.48594665527344, 41.12543487548828, 42.764923095703125, 44.40441131591797, 46.04389953613281, 47.683387756347656, 49.3228759765625, 50.962364196777344, 52.60185241699219, 54.24134063720703, 55.880828857421875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 5.0, 6.0, 3.0, 1.0, 5.0, 3.0, 4.0, 8.0, 4.0, 12.0, 11.0, 19.0, 28.0, 29.0, 29.0, 39.0, 36.0, 43.0, 52.0, 25.0, 15.0, 18.0, 14.0, 9.0, 13.0, 11.0, 13.0, 6.0, 8.0, 4.0, 8.0, 4.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-44.41324996948242, -42.92863464355469, -41.44401550292969, -39.95940017700195, -38.47478485107422, -36.99016571044922, -35.505550384521484, -34.02093505859375, -32.53631591796875, -31.051700592041016, -29.56708335876465, -28.08246612548828, -26.597850799560547, -25.11323356628418, -23.628616333007812, -22.144001007080078, -20.65938377380371, -19.174766540527344, -17.69015121459961, -16.205533981323242, -14.720916748046875, -13.23630142211914, -11.75168228149414, -10.267066955566406, -8.782451629638672, -7.297832489013672, -5.8132171630859375, -4.328601837158203, -2.843982696533203, -1.3593673706054688, 0.12524795532226562, 1.6098670959472656, 3.094482421875, 4.579097747802734, 6.063716888427734, 7.548332214355469, 9.032947540283203, 10.517566680908203, 12.002182006835938, 13.486797332763672, 14.971416473388672, 16.456031799316406, 17.94064712524414, 19.42526626586914, 20.90988540649414, 22.39449691772461, 23.87911605834961, 25.36373519897461, 26.848346710205078, 28.332965850830078, 29.817584991455078, 31.302196502685547, 32.78681564331055, 34.27143478393555, 35.756046295166016, 37.240665435791016, 38.725284576416016, 40.209896087646484, 41.694515228271484, 43.179134368896484, 44.66374588012695, 46.14836502075195, 47.63298416137695, 49.11759567260742, 50.60221481323242]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-39.291072845458984, -38.3571891784668, -37.42330551147461, -36.48942184448242, -35.55553436279297, -34.62165069580078, -33.687767028808594, -32.753883361816406, -31.81999969482422, -30.88611602783203, -29.952232360839844, -29.018346786499023, -28.084463119506836, -27.15057945251465, -26.216693878173828, -25.28281021118164, -24.348926544189453, -23.415042877197266, -22.481159210205078, -21.547273635864258, -20.61338996887207, -19.679506301879883, -18.745620727539062, -17.811737060546875, -16.877853393554688, -15.9439697265625, -15.010086059570312, -14.076200485229492, -13.142316818237305, -12.208433151245117, -11.274547576904297, -10.34066390991211, -9.406780242919922, -8.472896575927734, -7.539012908935547, -6.605129241943359, -5.671245574951172, -4.737358093261719, -3.8034744262695312, -2.8695907592773438, -1.9357070922851562, -1.0018234252929688, -0.06793975830078125, 0.8659439086914062, 1.7998313903808594, 2.733715057373047, 3.6675987243652344, 4.601482391357422, 5.535366058349609, 6.469249725341797, 7.403133392333984, 8.337017059326172, 9.27090072631836, 10.204788208007812, 11.138671875, 12.072555541992188, 13.006439208984375, 13.940322875976562, 14.87420654296875, 15.808090209960938, 16.74197769165039, 17.675861358642578, 18.609745025634766, 19.543628692626953, 20.47751235961914]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 32.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-14.65325927734375, -13.975412368774414, -13.297566413879395, -12.619719505310059, -11.941873550415039, -11.264026641845703, -10.586179733276367, -9.908332824707031, -9.230486869812012, -8.552640914916992, -7.874794006347656, -7.19694709777832, -6.519100189208984, -5.841254234313965, -5.163407325744629, -4.485561370849609, -3.8077144622802734, -3.1298675537109375, -2.452021598815918, -1.774174690246582, -1.0963287353515625, -0.41848182678222656, 0.2593650817871094, 0.9372110366821289, 1.6150588989257812, 2.2929039001464844, 2.9707508087158203, 3.6485977172851562, 4.326444625854492, 5.004291534423828, 5.682136535644531, 6.359983444213867, 7.037830352783203, 7.715677261352539, 8.393524169921875, 9.071369171142578, 9.749216079711914, 10.42706298828125, 11.104909896850586, 11.782756805419922, 12.460601806640625, 13.138448715209961, 13.816295623779297, 14.494142532348633, 15.171989440917969, 15.849836349487305, 16.527681350708008, 17.205528259277344, 17.883377075195312, 18.561222076416016, 19.23906707763672, 19.916915893554688, 20.59476089477539, 21.27260971069336, 21.950454711914062, 22.628299713134766, 23.306148529052734, 23.983993530273438, 24.661842346191406, 25.33968734741211, 26.017532348632812, 26.69538116455078, 27.373226165771484, 28.051074981689453, 28.728919982910156]}, "_runtime": 387.6063458919525, "_timestamp": 1585073898.606108, "_step": 298}
{"Episode reward": -94.79155602527646, "Episode length": 999, "Policy Loss": -11.936505317687988, "Value Loss": 0.028099488466978073, "_runtime": 388.7729034423828, "_timestamp": 1585073899.7726655, "_step": 299}
{"Episode reward": -94.21623250160184, "Episode length": 999, "Policy Loss": -11.912367820739746, "Value Loss": 0.024784591048955917, "_runtime": 389.8936915397644, "_timestamp": 1585073900.8934536, "_step": 300}
{"Episode reward": -106.09582065652774, "Episode length": 999, "Policy Loss": -14.0660400390625, "Value Loss": 0.032181739807128906, "_runtime": 391.0740256309509, "_timestamp": 1585073902.0737877, "_step": 301}
{"Episode reward": -100.92765330388829, "Episode length": 999, "Policy Loss": -12.98408317565918, "Value Loss": 0.028633054345846176, "_runtime": 392.23085498809814, "_timestamp": 1585073903.230617, "_step": 302}
{"Episode reward": -104.19892644303593, "Episode length": 999, "Policy Loss": -13.503191947937012, "Value Loss": 0.03228370472788811, "_runtime": 393.33380484580994, "_timestamp": 1585073904.333567, "_step": 303}
{"Episode reward": -103.47186205175538, "Episode length": 999, "Policy Loss": -13.568933486938477, "Value Loss": 0.032616570591926575, "_runtime": 394.4412319660187, "_timestamp": 1585073905.440994, "_step": 304}
{"Episode reward": -97.22916936083453, "Episode length": 999, "Policy Loss": -12.47478199005127, "Value Loss": 0.028966382145881653, "_runtime": 395.59461641311646, "_timestamp": 1585073906.5943785, "_step": 305}
{"Episode reward": -102.3076361534413, "Episode length": 999, "Policy Loss": -13.48921012878418, "Value Loss": 0.03326161578297615, "_runtime": 396.7519817352295, "_timestamp": 1585073907.7517438, "_step": 306}
{"Episode reward": -103.11676121790458, "Episode length": 999, "Policy Loss": -13.412364959716797, "Value Loss": 0.03121630661189556, "_runtime": 397.9074401855469, "_timestamp": 1585073908.9072022, "_step": 307}
{"Episode reward": -101.40432313387963, "Episode length": 999, "Policy Loss": -13.177891731262207, "Value Loss": 0.03413129225373268, "_runtime": 399.0505738258362, "_timestamp": 1585073910.050336, "_step": 308}
{"Episode reward": -103.93576713628168, "Episode length": 999, "Policy Loss": -13.561224937438965, "Value Loss": 0.03392466530203819, "_runtime": 400.17735505104065, "_timestamp": 1585073911.177117, "_step": 309}
{"Episode reward": -97.96744485286176, "Episode length": 999, "Policy Loss": -12.69200325012207, "Value Loss": 0.028626974672079086, "_runtime": 401.360554933548, "_timestamp": 1585073912.360317, "_step": 310}
{"Episode reward": -104.7171720120589, "Episode length": 999, "Policy Loss": -13.723586082458496, "Value Loss": 0.03243459761142731, "_runtime": 402.4789009094238, "_timestamp": 1585073913.478663, "_step": 311}
{"Episode reward": -98.71226688095052, "Episode length": 999, "Policy Loss": -12.486177444458008, "Value Loss": 0.029188817366957664, "_runtime": 403.6265504360199, "_timestamp": 1585073914.6263125, "_step": 312}
{"Episode reward": -95.83250648565101, "Episode length": 999, "Policy Loss": -12.19910717010498, "Value Loss": 0.024831054732203484, "_runtime": 404.77774715423584, "_timestamp": 1585073915.7775092, "_step": 313}
{"Episode reward": -93.52844087215423, "Episode length": 999, "Policy Loss": -11.92921257019043, "Value Loss": 0.02556232176721096, "_runtime": 405.9163339138031, "_timestamp": 1585073916.916096, "_step": 314}
{"Episode reward": -92.03249056297673, "Episode length": 999, "Policy Loss": -11.671618461608887, "Value Loss": 0.026217687875032425, "_runtime": 407.0898892879486, "_timestamp": 1585073918.0896513, "_step": 315}
{"Episode reward": -89.42299602455489, "Episode length": 999, "Policy Loss": -11.019991874694824, "Value Loss": 0.025979552417993546, "_runtime": 408.2315044403076, "_timestamp": 1585073919.2312665, "_step": 316}
{"Episode reward": -94.85594613196031, "Episode length": 999, "Policy Loss": -11.983586311340332, "Value Loss": 0.026861345395445824, "_runtime": 409.38199734687805, "_timestamp": 1585073920.3817594, "_step": 317}
{"Episode reward": -101.59106101426887, "Episode length": 999, "Policy Loss": -13.320250511169434, "Value Loss": 0.030227571725845337, "_runtime": 410.5404212474823, "_timestamp": 1585073921.5401833, "_step": 318}
{"Episode reward": -92.66644298157681, "Episode length": 999, "Policy Loss": -11.645926475524902, "Value Loss": 0.02478010766208172, "_runtime": 411.66468048095703, "_timestamp": 1585073922.6644425, "_step": 319}
{"Episode reward": -94.31264647355233, "Episode length": 999, "Policy Loss": -12.025803565979004, "Value Loss": 0.02571544423699379, "_runtime": 412.79065704345703, "_timestamp": 1585073923.790419, "_step": 320}
{"Episode reward": -98.66462254260654, "Episode length": 999, "Policy Loss": -12.633051872253418, "Value Loss": 0.03128133714199066, "_runtime": 413.9144742488861, "_timestamp": 1585073924.9142363, "_step": 321}
{"Episode reward": -96.39356089805138, "Episode length": 999, "Policy Loss": -12.301753044128418, "Value Loss": 0.028262656182050705, "_runtime": 415.09255599975586, "_timestamp": 1585073926.092318, "_step": 322}
{"Episode reward": -96.4121550695652, "Episode length": 999, "Policy Loss": -12.510560035705566, "Value Loss": 0.027868840843439102, "_runtime": 416.3041319847107, "_timestamp": 1585073927.303894, "_step": 323}
{"Episode reward": -107.05162925055407, "Episode length": 999, "Policy Loss": -14.128050804138184, "Value Loss": 0.03367167338728905, "_runtime": 417.4581968784332, "_timestamp": 1585073928.457959, "_step": 324}
{"Episode reward": -97.17711183230502, "Episode length": 999, "Policy Loss": -12.399224281311035, "Value Loss": 0.028064630925655365, "_runtime": 418.60459661483765, "_timestamp": 1585073929.6043587, "_step": 325}
{"Episode reward": -100.86655156375228, "Episode length": 999, "Policy Loss": -13.06748104095459, "Value Loss": 0.02866901271045208, "_runtime": 419.7236728668213, "_timestamp": 1585073930.723435, "_step": 326}
{"Episode reward": -102.41631017522221, "Episode length": 999, "Policy Loss": -13.240129470825195, "Value Loss": 0.03183364123106003, "_runtime": 420.8441836833954, "_timestamp": 1585073931.8439457, "_step": 327}
{"Episode reward": -95.51123663191267, "Episode length": 999, "Policy Loss": -12.278982162475586, "Value Loss": 0.026941780000925064, "_runtime": 421.9863202571869, "_timestamp": 1585073932.9860823, "_step": 328}
{"Episode reward": -107.2461792063547, "Episode length": 999, "Policy Loss": -14.125025749206543, "Value Loss": 0.035378020256757736, "_runtime": 423.14413499832153, "_timestamp": 1585073934.143897, "_step": 329}
{"Episode reward": -98.22231993421472, "Episode length": 999, "Policy Loss": -12.50110149383545, "Value Loss": 0.031060989946126938, "_runtime": 424.25580406188965, "_timestamp": 1585073935.2555661, "_step": 330}
{"Episode reward": -97.80325838168682, "Episode length": 999, "Policy Loss": -12.472299575805664, "Value Loss": 0.02885916270315647, "_runtime": 425.44476771354675, "_timestamp": 1585073936.4445298, "_step": 331}
{"Episode reward": -93.66433022788381, "Episode length": 999, "Policy Loss": -11.924958229064941, "Value Loss": 0.025525623932480812, "_runtime": 426.5870244503021, "_timestamp": 1585073937.5867865, "_step": 332}
{"Episode reward": -101.56699085609152, "Episode length": 999, "Policy Loss": -13.142366409301758, "Value Loss": 0.030547356233000755, "_runtime": 427.7768874168396, "_timestamp": 1585073938.7766495, "_step": 333}
{"Episode reward": -95.00720632494709, "Episode length": 999, "Policy Loss": -12.054342269897461, "Value Loss": 0.026380352675914764, "_runtime": 428.9315004348755, "_timestamp": 1585073939.9312625, "_step": 334}
{"Episode reward": -100.37340374989618, "Episode length": 999, "Policy Loss": -12.870057106018066, "Value Loss": 0.03116699308156967, "_runtime": 430.10475516319275, "_timestamp": 1585073941.1045172, "_step": 335}
{"Episode reward": -104.29299737432875, "Episode length": 999, "Policy Loss": -13.591529846191406, "Value Loss": 0.03400687128305435, "_runtime": 431.28996896743774, "_timestamp": 1585073942.289731, "_step": 336}
{"Episode reward": -107.48768107495395, "Episode length": 999, "Policy Loss": -14.322552680969238, "Value Loss": 0.03431185334920883, "_runtime": 432.4066355228424, "_timestamp": 1585073943.4063976, "_step": 337}
{"Episode reward": -102.82184231228103, "Episode length": 999, "Policy Loss": -13.442312240600586, "Value Loss": 0.032564446330070496, "_runtime": 433.51750445365906, "_timestamp": 1585073944.5172665, "_step": 338}
{"Episode reward": -99.01172403456492, "Episode length": 999, "Policy Loss": -12.81761646270752, "Value Loss": 0.027059148997068405, "_runtime": 434.6768116950989, "_timestamp": 1585073945.6765738, "_step": 339}
{"Episode reward": -96.95645080008629, "Episode length": 999, "Policy Loss": -12.259177207946777, "Value Loss": 0.029212018474936485, "_runtime": 435.81238651275635, "_timestamp": 1585073946.8121486, "_step": 340}
{"Episode reward": -106.9471786330348, "Episode length": 999, "Policy Loss": -14.362455368041992, "Value Loss": 0.03342248871922493, "_runtime": 436.98678183555603, "_timestamp": 1585073947.986544, "_step": 341}
{"Episode reward": -97.17120704019146, "Episode length": 999, "Policy Loss": -12.475162506103516, "Value Loss": 0.026243966072797775, "_runtime": 438.120165348053, "_timestamp": 1585073949.1199274, "_step": 342}
{"Episode reward": -93.7490425740511, "Episode length": 999, "Policy Loss": -11.75813102722168, "Value Loss": 0.02715964987874031, "_runtime": 439.2600407600403, "_timestamp": 1585073950.2598028, "_step": 343}
{"Episode reward": -99.96656111523541, "Episode length": 999, "Policy Loss": -13.040607452392578, "Value Loss": 0.03125562146306038, "_runtime": 440.39727878570557, "_timestamp": 1585073951.3970408, "_step": 344}
{"Episode reward": -100.14589248434524, "Episode length": 999, "Policy Loss": -12.863567352294922, "Value Loss": 0.033316902816295624, "_runtime": 441.5579512119293, "_timestamp": 1585073952.5577133, "_step": 345}
{"Episode reward": -103.61010502061673, "Episode length": 999, "Policy Loss": -13.791390419006348, "Value Loss": 0.03150000050663948, "_runtime": 442.674551486969, "_timestamp": 1585073953.6743135, "_step": 346}
{"Episode reward": -102.18030734141404, "Episode length": 999, "Policy Loss": -13.323807716369629, "Value Loss": 0.0316406711935997, "_runtime": 443.8325276374817, "_timestamp": 1585073954.8322897, "_step": 347}
{"Episode reward": -101.61784102490225, "Episode length": 999, "Policy Loss": -13.178411483764648, "Value Loss": 0.03191928192973137, "_runtime": 444.9828553199768, "_timestamp": 1585073955.9826174, "_step": 348}
{"Episode reward": -104.11277986989965, "Episode length": 999, "Policy Loss": -13.818232536315918, "Value Loss": 0.03605783358216286, "_runtime": 446.11401104927063, "_timestamp": 1585073957.113773, "_step": 349}
{"Episode reward": -101.6426441233569, "Episode length": 999, "Policy Loss": -13.070048332214355, "Value Loss": 0.030299032106995583, "_runtime": 447.26826453208923, "_timestamp": 1585073958.2680266, "_step": 350}
{"Episode reward": -103.95943908107569, "Episode length": 999, "Policy Loss": -13.55014419555664, "Value Loss": 0.03154229000210762, "_runtime": 448.4056816101074, "_timestamp": 1585073959.4054437, "_step": 351}
{"Episode reward": -107.79926356492497, "Episode length": 999, "Policy Loss": -13.933311462402344, "Value Loss": 0.03768329694867134, "_runtime": 449.52234530448914, "_timestamp": 1585073960.5221074, "_step": 352}
{"Episode reward": -103.44390275264843, "Episode length": 999, "Policy Loss": -13.677830696105957, "Value Loss": 0.03331353887915611, "_runtime": 450.64133381843567, "_timestamp": 1585073961.6410959, "_step": 353}
{"Episode reward": -102.0187316695338, "Episode length": 999, "Policy Loss": -13.223634719848633, "Value Loss": 0.030057009309530258, "_runtime": 451.75560665130615, "_timestamp": 1585073962.7553687, "_step": 354}
{"Episode reward": -102.33401862638873, "Episode length": 999, "Policy Loss": -13.422085762023926, "Value Loss": 0.03167054429650307, "_runtime": 452.8997037410736, "_timestamp": 1585073963.8994658, "_step": 355}
{"Episode reward": -101.81001485937512, "Episode length": 999, "Policy Loss": -13.234853744506836, "Value Loss": 0.030573245137929916, "_runtime": 454.0733516216278, "_timestamp": 1585073965.0731137, "_step": 356}
{"Episode reward": -96.67196686831369, "Episode length": 999, "Policy Loss": -12.150410652160645, "Value Loss": 0.027055663987994194, "_runtime": 455.22626280784607, "_timestamp": 1585073966.2260249, "_step": 357}
{"Episode reward": -97.21028256212412, "Episode length": 999, "Policy Loss": -12.201348304748535, "Value Loss": 0.029817864298820496, "_runtime": 456.37932205200195, "_timestamp": 1585073967.379084, "_step": 358}
{"Episode reward": -99.47881435822289, "Episode length": 999, "Policy Loss": -12.911050796508789, "Value Loss": 0.028637250885367393, "_runtime": 457.5423421859741, "_timestamp": 1585073968.5421042, "_step": 359}
{"Episode reward": -99.53133597786001, "Episode length": 999, "Policy Loss": -13.051053047180176, "Value Loss": 0.032384827733039856, "_runtime": 458.7175223827362, "_timestamp": 1585073969.7172844, "_step": 360}
{"Episode reward": -98.40552298723921, "Episode length": 999, "Policy Loss": -12.801901817321777, "Value Loss": 0.028779610991477966, "_runtime": 459.8540542125702, "_timestamp": 1585073970.8538163, "_step": 361}
{"Episode reward": -97.03119853863149, "Episode length": 999, "Policy Loss": -12.435736656188965, "Value Loss": 0.02900048904120922, "_runtime": 461.00794196128845, "_timestamp": 1585073972.007704, "_step": 362}
{"Episode reward": -99.84004748439064, "Episode length": 999, "Policy Loss": -12.820326805114746, "Value Loss": 0.03052947111427784, "_runtime": 462.16137313842773, "_timestamp": 1585073973.1611352, "_step": 363}
{"Episode reward": -99.45029495304553, "Episode length": 999, "Policy Loss": -12.831330299377441, "Value Loss": 0.03151591122150421, "_runtime": 463.30886030197144, "_timestamp": 1585073974.3086224, "_step": 364}
{"Episode reward": -100.9653959660775, "Episode length": 999, "Policy Loss": -13.050972938537598, "Value Loss": 0.030947299674153328, "_runtime": 464.4114098548889, "_timestamp": 1585073975.411172, "_step": 365}
{"Episode reward": -99.40948032361962, "Episode length": 999, "Policy Loss": -12.752896308898926, "Value Loss": 0.029849370941519737, "_runtime": 465.572548866272, "_timestamp": 1585073976.572311, "_step": 366}
{"Episode reward": -100.0825994575305, "Episode length": 999, "Policy Loss": -12.736166000366211, "Value Loss": 0.03076542727649212, "_runtime": 466.7240672111511, "_timestamp": 1585073977.7238293, "_step": 367}
{"Episode reward": -97.6662851105286, "Episode length": 999, "Policy Loss": -12.446098327636719, "Value Loss": 0.031591325998306274, "_runtime": 467.8601326942444, "_timestamp": 1585073978.8598948, "_step": 368}
{"Episode reward": -107.6529149521153, "Episode length": 999, "Policy Loss": -13.963738441467285, "Value Loss": 0.03291862830519676, "_runtime": 469.0162513256073, "_timestamp": 1585073980.0160134, "_step": 369}
{"Episode reward": -98.45419155372757, "Episode length": 999, "Policy Loss": -12.797350883483887, "Value Loss": 0.02752171829342842, "_runtime": 470.16391706466675, "_timestamp": 1585073981.1636791, "_step": 370}
{"Episode reward": -103.34056153541113, "Episode length": 999, "Policy Loss": -13.493265151977539, "Value Loss": 0.030133401975035667, "_runtime": 471.3634262084961, "_timestamp": 1585073982.3631883, "_step": 371}
{"Episode reward": -98.35067627832368, "Episode length": 999, "Policy Loss": -12.459553718566895, "Value Loss": 0.028395941480994225, "_runtime": 472.5436406135559, "_timestamp": 1585073983.5434027, "_step": 372}
{"Episode reward": -105.2304736205119, "Episode length": 999, "Policy Loss": -13.775858879089355, "Value Loss": 0.0320691354572773, "_runtime": 473.6691167354584, "_timestamp": 1585073984.6688788, "_step": 373}
{"Episode reward": -91.56033254672887, "Episode length": 999, "Policy Loss": -11.219767570495605, "Value Loss": 0.024256836622953415, "_runtime": 474.8493957519531, "_timestamp": 1585073985.8491578, "_step": 374}
{"Episode reward": -99.60738063451045, "Episode length": 999, "Policy Loss": -12.73538589477539, "Value Loss": 0.030244072899222374, "_runtime": 476.0389201641083, "_timestamp": 1585073987.0386822, "_step": 375}
{"Episode reward": -103.22947181422255, "Episode length": 999, "Policy Loss": -13.255064010620117, "Value Loss": 0.032547999173402786, "_runtime": 477.2146062850952, "_timestamp": 1585073988.2143683, "_step": 376}
{"Episode reward": -106.5553660829252, "Episode length": 999, "Policy Loss": -13.956046104431152, "Value Loss": 0.04217066615819931, "_runtime": 478.3320939540863, "_timestamp": 1585073989.331856, "_step": 377}
{"Episode reward": -100.8271100242373, "Episode length": 999, "Policy Loss": -13.089203834533691, "Value Loss": 0.0301840640604496, "_runtime": 479.4612362384796, "_timestamp": 1585073990.4609983, "_step": 378}
{"Episode reward": -95.89826610110717, "Episode length": 999, "Policy Loss": -12.28286075592041, "Value Loss": 0.027676552534103394, "_runtime": 480.5892086029053, "_timestamp": 1585073991.5889707, "_step": 379}
{"Episode reward": -94.80799108828438, "Episode length": 999, "Policy Loss": -12.182943344116211, "Value Loss": 0.02900424785912037, "_runtime": 481.70728516578674, "_timestamp": 1585073992.7070472, "_step": 380}
{"Episode reward": -96.993013654417, "Episode length": 999, "Policy Loss": -12.122355461120605, "Value Loss": 0.027398794889450073, "_runtime": 482.85654950141907, "_timestamp": 1585073993.8563116, "_step": 381}
{"Episode reward": -100.10188444465217, "Episode length": 999, "Policy Loss": -12.909867286682129, "Value Loss": 0.03197943791747093, "_runtime": 483.9601979255676, "_timestamp": 1585073994.95996, "_step": 382}
{"Episode reward": -98.33371634590675, "Episode length": 999, "Policy Loss": -12.587215423583984, "Value Loss": 0.026888564229011536, "_runtime": 485.11303544044495, "_timestamp": 1585073996.1127975, "_step": 383}
{"Episode reward": -103.96964315467146, "Episode length": 999, "Policy Loss": -13.684225082397461, "Value Loss": 0.03228515014052391, "_runtime": 486.26245307922363, "_timestamp": 1585073997.2622151, "_step": 384}
{"Episode reward": -96.76013408453693, "Episode length": 999, "Policy Loss": -12.053215026855469, "Value Loss": 0.0279855839908123, "_runtime": 487.38836765289307, "_timestamp": 1585073998.3881297, "_step": 385}
{"Episode reward": -96.60072592157226, "Episode length": 999, "Policy Loss": -12.269233703613281, "Value Loss": 0.025921905413269997, "_runtime": 488.51218461990356, "_timestamp": 1585073999.5119467, "_step": 386}
{"Episode reward": -101.74421882522938, "Episode length": 999, "Policy Loss": -13.29642105102539, "Value Loss": 0.03444946929812431, "_runtime": 489.6316947937012, "_timestamp": 1585074000.6314569, "_step": 387}
{"Episode reward": -99.1814933517897, "Episode length": 999, "Policy Loss": -12.566374778747559, "Value Loss": 0.03279384970664978, "_runtime": 490.7769362926483, "_timestamp": 1585074001.7766984, "_step": 388}
{"Episode reward": -102.29411959057069, "Episode length": 999, "Policy Loss": -13.164618492126465, "Value Loss": 0.03184549883008003, "_runtime": 491.9656684398651, "_timestamp": 1585074002.9654305, "_step": 389}
{"Episode reward": -95.04534380073198, "Episode length": 999, "Policy Loss": -11.863180160522461, "Value Loss": 0.024233117699623108, "_runtime": 493.1046199798584, "_timestamp": 1585074004.104382, "_step": 390}
{"Episode reward": -96.14682107771537, "Episode length": 999, "Policy Loss": -12.33171272277832, "Value Loss": 0.0313999205827713, "_runtime": 494.2026734352112, "_timestamp": 1585074005.2024355, "_step": 391}
{"Episode reward": -96.69462383470875, "Episode length": 999, "Policy Loss": -12.417801856994629, "Value Loss": 0.02708282694220543, "_runtime": 495.35336112976074, "_timestamp": 1585074006.3531232, "_step": 392}
{"Episode reward": -103.16766917918046, "Episode length": 999, "Policy Loss": -13.701709747314453, "Value Loss": 0.028351809829473495, "_runtime": 496.48802042007446, "_timestamp": 1585074007.4877825, "_step": 393}
{"Episode reward": -100.29189529565423, "Episode length": 999, "Policy Loss": -12.820032119750977, "Value Loss": 0.033569060266017914, "_runtime": 497.63905787467957, "_timestamp": 1585074008.63882, "_step": 394}
{"Episode reward": -102.44684577504823, "Episode length": 999, "Policy Loss": -13.131607055664062, "Value Loss": 0.02925199829041958, "_runtime": 498.7846496105194, "_timestamp": 1585074009.7844117, "_step": 395}
{"Episode reward": -98.50071940653801, "Episode length": 999, "Policy Loss": -12.846592903137207, "Value Loss": 0.02847776934504509, "_runtime": 499.9064540863037, "_timestamp": 1585074010.9062161, "_step": 396}
{"Episode reward": -98.67844243054255, "Episode length": 999, "Policy Loss": -12.624972343444824, "Value Loss": 0.028652619570493698, "_runtime": 501.0447463989258, "_timestamp": 1585074012.0445085, "_step": 397}
{"Episode reward": -93.26207917514331, "Episode length": 999, "Policy Loss": -11.633602142333984, "Value Loss": 0.026576077565550804, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844, -144.67759704589844]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-138.33551025390625, -134.9204864501953, -131.50547790527344, -128.0904541015625, -124.6754379272461, -121.26042175292969, -117.84539794921875, -114.43038177490234, -111.01536560058594, -107.60034942626953, -104.18533325195312, -100.77030944824219, -97.35529327392578, -93.94027709960938, -90.52525329589844, -87.11023712158203, -83.69522094726562, -80.28020477294922, -76.86518859863281, -73.45016479492188, -70.03514862060547, -66.62013244628906, -63.205108642578125, -59.79009246826172, -56.37507629394531, -52.960060119628906, -49.5450439453125, -46.13002014160156, -42.715003967285156, -39.29998779296875, -35.88496398925781, -32.469947814941406, -29.054931640625, -25.639915466308594, -22.224899291992188, -18.80987548828125, -15.394859313964844, -11.979843139648438, -8.5648193359375, -5.149810791015625, -1.7347869873046875, 1.68023681640625, 5.095245361328125, 8.510269165039062, 11.92529296875, 15.340301513671875, 18.755325317382812, 22.170333862304688, 25.585357666015625, 29.000381469726562, 32.41539001464844, 35.830413818359375, 39.24542236328125, 42.66044616699219, 46.075469970703125, 49.490478515625, 52.90550231933594, 56.320526123046875, 59.73553466796875, 63.15055847167969, 66.56558227539062, 69.9805908203125, 73.39561462402344, 76.81062316894531, 80.22564697265625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-69.31851196289062, -66.99882507324219, -64.67914581298828, -62.35946273803711, -60.03977966308594, -57.720096588134766, -55.400413513183594, -53.08073043823242, -50.76104736328125, -48.44136428833008, -46.121681213378906, -43.801998138427734, -41.48231506347656, -39.16263198852539, -36.84294891357422, -34.52326583862305, -32.203582763671875, -29.883899688720703, -27.56421661376953, -25.24453353881836, -22.924850463867188, -20.605167388916016, -18.285484313964844, -15.965801239013672, -13.6461181640625, -11.326435089111328, -9.006752014160156, -6.687068939208984, -4.3673858642578125, -2.047698974609375, 0.27198028564453125, 2.5916595458984375, 4.911346435546875, 7.2310333251953125, 9.550712585449219, 11.870391845703125, 14.190078735351562, 16.509765625, 18.829444885253906, 21.149124145507812, 23.46881103515625, 25.788497924804688, 28.108177185058594, 30.4278564453125, 32.74754333496094, 35.067230224609375, 37.38690948486328, 39.70658874511719, 42.026275634765625, 44.34596252441406, 46.66564178466797, 48.985321044921875, 51.30500793457031, 53.62469482421875, 55.944374084472656, 58.26405334472656, 60.583740234375, 62.90342712402344, 65.22311401367188, 67.54278564453125, 69.86247253417969, 72.18215942382812, 74.5018310546875, 76.82151794433594, 79.14120483398438]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 8.0, 2.0, 13.0, 16.0, 16.0, 31.0, 29.0, 20.0, 39.0, 43.0, 44.0, 49.0, 21.0, 17.0, 16.0, 13.0, 8.0, 16.0, 10.0, 13.0, 7.0, 7.0, 6.0, 6.0, 7.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-60.96709442138672, -58.926883697509766, -56.88667678833008, -54.846466064453125, -52.80625915527344, -50.766048431396484, -48.72583770751953, -46.685630798339844, -44.64542007446289, -42.60520935058594, -40.56500244140625, -38.5247917175293, -36.484580993652344, -34.444374084472656, -32.4041633605957, -30.363954544067383, -28.323745727539062, -26.28353500366211, -24.243328094482422, -22.20311737060547, -20.16291046142578, -18.122699737548828, -16.082489013671875, -14.042282104492188, -12.002071380615234, -9.961860656738281, -7.921653747558594, -5.881443023681641, -3.8412322998046875, -1.801025390625, 0.23918533325195312, 2.2793922424316406, 4.319602966308594, 6.359809875488281, 8.4000244140625, 10.440231323242188, 12.480438232421875, 14.520652770996094, 16.56085968017578, 18.60106658935547, 20.641273498535156, 22.681488037109375, 24.721694946289062, 26.76190185546875, 28.80211639404297, 30.842323303222656, 32.882530212402344, 34.92274475097656, 36.96295166015625, 39.00315856933594, 41.043373107910156, 43.083580017089844, 45.12378692626953, 47.16400146484375, 49.20420837402344, 51.244415283203125, 53.284629821777344, 55.32483673095703, 57.36504364013672, 59.405250549316406, 61.445465087890625, 63.48567199707031, 65.52587890625, 67.56609344482422, 69.6063003540039]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], "bins": [-54.7999382019043, -53.471012115478516, -52.142086029052734, -50.81315612792969, -49.484230041503906, -48.155303955078125, -46.826377868652344, -45.49745178222656, -44.16852569580078, -42.839595794677734, -41.51066970825195, -40.18174362182617, -38.85281753540039, -37.523887634277344, -36.19496154785156, -34.86603546142578, -33.537109375, -32.20818328857422, -30.879255294799805, -29.550329208374023, -28.22140121459961, -26.892475128173828, -25.563549041748047, -24.234621047973633, -22.90569496154785, -21.576766967773438, -20.247840881347656, -18.918914794921875, -17.589988708496094, -16.261062622070312, -14.932132720947266, -13.603206634521484, -12.274280548095703, -10.945354461669922, -9.61642837524414, -8.287498474121094, -6.9585723876953125, -5.629646301269531, -4.30072021484375, -2.9717941284179688, -1.6428642272949219, -0.3139381408691406, 1.0149879455566406, 2.343914031982422, 3.672840118408203, 5.001766204833984, 6.330696105957031, 7.6596221923828125, 8.988548278808594, 10.31747817993164, 11.646404266357422, 12.975330352783203, 14.304256439208984, 15.633182525634766, 16.962108612060547, 18.291034698486328, 19.61996078491211, 20.94888687133789, 22.277812957763672, 23.606746673583984, 24.935672760009766, 26.264598846435547, 27.593524932861328, 28.92245101928711, 30.25137710571289]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 10.0, 15.0, 7.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-18.403608322143555, -17.58057403564453, -16.75754165649414, -15.934507369995117, -15.111474990844727, -14.288440704345703, -13.465407371520996, -12.642374038696289, -11.819340705871582, -10.996307373046875, -10.173274040222168, -9.350240707397461, -8.527206420898438, -7.7041730880737305, -6.881139755249023, -6.058106422424316, -5.235073089599609, -4.412039756774902, -3.5890064239501953, -2.7659730911254883, -1.9429397583007812, -1.1199054718017578, -0.2968730926513672, 0.5261611938476562, 1.3491954803466797, 2.1722278594970703, 2.9952621459960938, 3.8182945251464844, 4.641328811645508, 5.464361190795898, 6.287395477294922, 7.1104278564453125, 7.933462142944336, 8.75649642944336, 9.57952880859375, 10.402563095092773, 11.225595474243164, 12.048629760742188, 12.871662139892578, 13.694696426391602, 14.517728805541992, 15.340764999389648, 16.16379737854004, 16.98682975769043, 17.80986213684082, 18.632898330688477, 19.455930709838867, 20.278963088989258, 21.101999282836914, 21.925031661987305, 22.748064041137695, 23.571096420288086, 24.394132614135742, 25.217164993286133, 26.040197372436523, 26.863229751586914, 27.68626594543457, 28.50929832458496, 29.33233070373535, 30.155366897583008, 30.9783992767334, 31.80143165588379, 32.62446594238281, 33.44750213623047, 34.270530700683594]}, "_runtime": 502.2103021144867, "_timestamp": 1585074013.2100642, "_step": 398}
{"Episode reward": -99.08631832953346, "Episode length": 999, "Policy Loss": -12.85237979888916, "Value Loss": 0.028982074931263924, "_runtime": 503.38258028030396, "_timestamp": 1585074014.3823423, "_step": 399}
{"Episode reward": -99.75755753883315, "Episode length": 999, "Policy Loss": -12.664628028869629, "Value Loss": 0.029876871034502983, "_runtime": 504.53880071640015, "_timestamp": 1585074015.5385628, "_step": 400}
{"Episode reward": -101.05355406248715, "Episode length": 999, "Policy Loss": -13.313055038452148, "Value Loss": 0.0354708768427372, "_runtime": 505.71806478500366, "_timestamp": 1585074016.7178268, "_step": 401}
{"Episode reward": -95.76383295735153, "Episode length": 999, "Policy Loss": -11.95134162902832, "Value Loss": 0.026084866374731064, "_runtime": 506.86013007164, "_timestamp": 1585074017.8598921, "_step": 402}
{"Episode reward": -98.39561490469444, "Episode length": 999, "Policy Loss": -12.638143539428711, "Value Loss": 0.028548499569296837, "_runtime": 507.9918956756592, "_timestamp": 1585074018.9916577, "_step": 403}
{"Episode reward": -93.63323113679238, "Episode length": 999, "Policy Loss": -11.77099895477295, "Value Loss": 0.029156070202589035, "_runtime": 509.16747069358826, "_timestamp": 1585074020.1672328, "_step": 404}
{"Episode reward": -97.28818117440845, "Episode length": 999, "Policy Loss": -12.3820161819458, "Value Loss": 0.028387701138854027, "_runtime": 510.295467376709, "_timestamp": 1585074021.2952294, "_step": 405}
{"Episode reward": -100.8033353173913, "Episode length": 999, "Policy Loss": -13.071256637573242, "Value Loss": 0.028848178684711456, "_runtime": 511.4989724159241, "_timestamp": 1585074022.4987345, "_step": 406}
{"Episode reward": -92.48223987975607, "Episode length": 999, "Policy Loss": -11.566505432128906, "Value Loss": 0.02466428279876709, "_runtime": 512.6452023983002, "_timestamp": 1585074023.6449645, "_step": 407}
{"Episode reward": -95.43771517860995, "Episode length": 999, "Policy Loss": -12.21267032623291, "Value Loss": 0.027548208832740784, "_runtime": 513.7618577480316, "_timestamp": 1585074024.7616198, "_step": 408}
{"Episode reward": -99.97886317186288, "Episode length": 999, "Policy Loss": -12.841355323791504, "Value Loss": 0.028927074745297432, "_runtime": 514.8808929920197, "_timestamp": 1585074025.880655, "_step": 409}
{"Episode reward": -102.65129064426803, "Episode length": 999, "Policy Loss": -13.388553619384766, "Value Loss": 0.030883658677339554, "_runtime": 516.0238502025604, "_timestamp": 1585074027.0236123, "_step": 410}
{"Episode reward": -92.52591536399373, "Episode length": 999, "Policy Loss": -11.800192832946777, "Value Loss": 0.02637498453259468, "_runtime": 517.1789503097534, "_timestamp": 1585074028.1787124, "_step": 411}
{"Episode reward": -99.99458867655119, "Episode length": 999, "Policy Loss": -12.87919807434082, "Value Loss": 0.02963811159133911, "_runtime": 518.3086557388306, "_timestamp": 1585074029.3084178, "_step": 412}
{"Episode reward": -99.56769387844797, "Episode length": 999, "Policy Loss": -12.96447467803955, "Value Loss": 0.029888436198234558, "_runtime": 519.4372777938843, "_timestamp": 1585074030.4370399, "_step": 413}
{"Episode reward": -96.99307457140584, "Episode length": 999, "Policy Loss": -12.246664047241211, "Value Loss": 0.02868262678384781, "_runtime": 520.5638399124146, "_timestamp": 1585074031.563602, "_step": 414}
{"Episode reward": -102.27211702021638, "Episode length": 999, "Policy Loss": -13.296748161315918, "Value Loss": 0.02975277043879032, "_runtime": 521.7136178016663, "_timestamp": 1585074032.7133799, "_step": 415}
{"Episode reward": -104.71105054679062, "Episode length": 999, "Policy Loss": -13.629047393798828, "Value Loss": 0.03161453828215599, "_runtime": 522.8671443462372, "_timestamp": 1585074033.8669064, "_step": 416}
{"Episode reward": -100.15813320643286, "Episode length": 999, "Policy Loss": -13.143438339233398, "Value Loss": 0.030897485092282295, "_runtime": 523.9791367053986, "_timestamp": 1585074034.9788988, "_step": 417}
{"Episode reward": -92.05068000025699, "Episode length": 999, "Policy Loss": -11.36373519897461, "Value Loss": 0.025638677179813385, "_runtime": 525.1106176376343, "_timestamp": 1585074036.1103797, "_step": 418}
{"Episode reward": -102.36670654634477, "Episode length": 999, "Policy Loss": -13.288642883300781, "Value Loss": 0.030328232795000076, "_runtime": 526.289356470108, "_timestamp": 1585074037.2891185, "_step": 419}
{"Episode reward": -103.33975766113737, "Episode length": 999, "Policy Loss": -13.547783851623535, "Value Loss": 0.034521449357271194, "_runtime": 527.4380927085876, "_timestamp": 1585074038.4378548, "_step": 420}
{"Episode reward": -98.28756991505487, "Episode length": 999, "Policy Loss": -12.831717491149902, "Value Loss": 0.027756856754422188, "_runtime": 528.6228601932526, "_timestamp": 1585074039.6226223, "_step": 421}
{"Episode reward": -96.63650252017221, "Episode length": 999, "Policy Loss": -12.334872245788574, "Value Loss": 0.029940087348222733, "_runtime": 529.7748668193817, "_timestamp": 1585074040.7746289, "_step": 422}
{"Episode reward": -107.09849638610109, "Episode length": 999, "Policy Loss": -14.014453887939453, "Value Loss": 0.038358669728040695, "_runtime": 530.8869214057922, "_timestamp": 1585074041.8866835, "_step": 423}
{"Episode reward": -95.16849490630469, "Episode length": 999, "Policy Loss": -12.070666313171387, "Value Loss": 0.027694523334503174, "_runtime": 532.0111865997314, "_timestamp": 1585074043.0109487, "_step": 424}
{"Episode reward": -99.00136386021424, "Episode length": 999, "Policy Loss": -12.594216346740723, "Value Loss": 0.029000554233789444, "_runtime": 533.1643712520599, "_timestamp": 1585074044.1641333, "_step": 425}
{"Episode reward": -100.3250129462659, "Episode length": 999, "Policy Loss": -12.832073211669922, "Value Loss": 0.030858401209115982, "_runtime": 534.2781858444214, "_timestamp": 1585074045.277948, "_step": 426}
{"Episode reward": -94.1998914784043, "Episode length": 999, "Policy Loss": -11.566805839538574, "Value Loss": 0.02831350453197956, "_runtime": 535.4373421669006, "_timestamp": 1585074046.4371042, "_step": 427}
{"Episode reward": -89.08152007784268, "Episode length": 999, "Policy Loss": -10.90246868133545, "Value Loss": 0.02448209375143051, "_runtime": 536.5601100921631, "_timestamp": 1585074047.5598722, "_step": 428}
{"Episode reward": -103.11849175363501, "Episode length": 999, "Policy Loss": -13.325517654418945, "Value Loss": 0.03150653839111328, "_runtime": 537.7196321487427, "_timestamp": 1585074048.7193942, "_step": 429}
{"Episode reward": -97.44285261599715, "Episode length": 999, "Policy Loss": -12.217778205871582, "Value Loss": 0.030325347557663918, "_runtime": 538.8785791397095, "_timestamp": 1585074049.8783412, "_step": 430}
{"Episode reward": -109.07645696907761, "Episode length": 999, "Policy Loss": -14.450002670288086, "Value Loss": 0.039657771587371826, "_runtime": 539.9952967166901, "_timestamp": 1585074050.9950588, "_step": 431}
{"Episode reward": -102.46145565186859, "Episode length": 999, "Policy Loss": -13.397581100463867, "Value Loss": 0.03149551525712013, "_runtime": 541.1487963199615, "_timestamp": 1585074052.1485584, "_step": 432}
{"Episode reward": -95.5528480801792, "Episode length": 999, "Policy Loss": -12.02565860748291, "Value Loss": 0.0277255829423666, "_runtime": 542.3166682720184, "_timestamp": 1585074053.3164303, "_step": 433}
{"Episode reward": -92.9978148752357, "Episode length": 999, "Policy Loss": -11.736008644104004, "Value Loss": 0.024050114676356316, "_runtime": 543.4234166145325, "_timestamp": 1585074054.4231787, "_step": 434}
{"Episode reward": -106.0415058161145, "Episode length": 999, "Policy Loss": -14.028544425964355, "Value Loss": 0.03344223275780678, "_runtime": 544.540682554245, "_timestamp": 1585074055.5404446, "_step": 435}
{"Episode reward": -101.13755387305783, "Episode length": 999, "Policy Loss": -12.962688446044922, "Value Loss": 0.029544448480010033, "_runtime": 545.6844096183777, "_timestamp": 1585074056.6841717, "_step": 436}
{"Episode reward": -99.95199254361319, "Episode length": 999, "Policy Loss": -12.766374588012695, "Value Loss": 0.02872813120484352, "_runtime": 546.8037123680115, "_timestamp": 1585074057.8034744, "_step": 437}
{"Episode reward": -106.76338746399085, "Episode length": 999, "Policy Loss": -13.919459342956543, "Value Loss": 0.03597545251250267, "_runtime": 547.9553837776184, "_timestamp": 1585074058.9551458, "_step": 438}
{"Episode reward": -101.0996491296839, "Episode length": 999, "Policy Loss": -12.97984790802002, "Value Loss": 0.029941098764538765, "_runtime": 549.1037886142731, "_timestamp": 1585074060.1035507, "_step": 439}
{"Episode reward": -104.26499477259996, "Episode length": 999, "Policy Loss": -13.622179985046387, "Value Loss": 0.03284139186143875, "_runtime": 550.2409591674805, "_timestamp": 1585074061.2407212, "_step": 440}
{"Episode reward": -102.99510925160038, "Episode length": 999, "Policy Loss": -13.435969352722168, "Value Loss": 0.030290620401501656, "_runtime": 551.3990700244904, "_timestamp": 1585074062.398832, "_step": 441}
{"Episode reward": -107.75815643765031, "Episode length": 999, "Policy Loss": -14.155177116394043, "Value Loss": 0.0338345542550087, "_runtime": 552.5257127285004, "_timestamp": 1585074063.5254748, "_step": 442}
{"Episode reward": -97.51202308715236, "Episode length": 999, "Policy Loss": -12.537408828735352, "Value Loss": 0.025555983185768127, "_runtime": 553.6981103420258, "_timestamp": 1585074064.6978724, "_step": 443}
{"Episode reward": -105.05450585848678, "Episode length": 999, "Policy Loss": -13.583992004394531, "Value Loss": 0.035570938140153885, "_runtime": 554.8931500911713, "_timestamp": 1585074065.8929121, "_step": 444}
{"Episode reward": -94.23735434521504, "Episode length": 999, "Policy Loss": -11.888143539428711, "Value Loss": 0.030037878081202507, "_runtime": 556.0715293884277, "_timestamp": 1585074067.0712914, "_step": 445}
{"Episode reward": -98.58691509211314, "Episode length": 999, "Policy Loss": -12.571831703186035, "Value Loss": 0.029466047883033752, "_runtime": 557.235289812088, "_timestamp": 1585074068.2350519, "_step": 446}
{"Episode reward": -93.40506578633946, "Episode length": 999, "Policy Loss": -11.777754783630371, "Value Loss": 0.025386406108736992, "_runtime": 558.3573386669159, "_timestamp": 1585074069.3571007, "_step": 447}
{"Episode reward": -98.65828046817958, "Episode length": 999, "Policy Loss": -12.770590782165527, "Value Loss": 0.027264075353741646, "_runtime": 559.5484621524811, "_timestamp": 1585074070.5482242, "_step": 448}
{"Episode reward": -98.18452839494452, "Episode length": 999, "Policy Loss": -12.65526008605957, "Value Loss": 0.02962246909737587, "_runtime": 560.4997227191925, "_timestamp": 1585074071.4994848, "_step": 449}
{"Episode reward": 18.557572543510062, "Episode length": 794, "Policy Loss": 4.79136848449707, "Value Loss": 12.644500732421875, "_runtime": 561.6225981712341, "_timestamp": 1585074072.6223602, "_step": 450}
{"Episode reward": -94.23610481491588, "Episode length": 999, "Policy Loss": -11.815590858459473, "Value Loss": 0.02531762421131134, "_runtime": 562.7346777915955, "_timestamp": 1585074073.7344398, "_step": 451}
{"Episode reward": -90.93697225986814, "Episode length": 999, "Policy Loss": -11.578120231628418, "Value Loss": 0.028180792927742004, "_runtime": 563.8562326431274, "_timestamp": 1585074074.8559947, "_step": 452}
{"Episode reward": -93.2323084911956, "Episode length": 999, "Policy Loss": -12.015504837036133, "Value Loss": 0.02803891710937023, "_runtime": 564.9801063537598, "_timestamp": 1585074075.9798684, "_step": 453}
{"Episode reward": -96.20044880703033, "Episode length": 999, "Policy Loss": -12.086283683776855, "Value Loss": 0.029279692098498344, "_runtime": 566.1507306098938, "_timestamp": 1585074077.1504927, "_step": 454}
{"Episode reward": -105.07024283499341, "Episode length": 999, "Policy Loss": -13.947667121887207, "Value Loss": 0.033817172050476074, "_runtime": 567.3048658370972, "_timestamp": 1585074078.304628, "_step": 455}
{"Episode reward": -101.58213262863705, "Episode length": 999, "Policy Loss": -13.121625900268555, "Value Loss": 0.029427437111735344, "_runtime": 568.4759979248047, "_timestamp": 1585074079.47576, "_step": 456}
{"Episode reward": -108.162593608893, "Episode length": 999, "Policy Loss": -14.466976165771484, "Value Loss": 0.03676922246813774, "_runtime": 569.633486032486, "_timestamp": 1585074080.633248, "_step": 457}
{"Episode reward": -105.03268046832119, "Episode length": 999, "Policy Loss": -13.59329891204834, "Value Loss": 0.03214553743600845, "_runtime": 570.7689797878265, "_timestamp": 1585074081.7687418, "_step": 458}
{"Episode reward": -95.01082865494242, "Episode length": 999, "Policy Loss": -12.0513277053833, "Value Loss": 0.0297335684299469, "_runtime": 571.8966319561005, "_timestamp": 1585074082.896394, "_step": 459}
{"Episode reward": -101.928704048316, "Episode length": 999, "Policy Loss": -13.426525115966797, "Value Loss": 0.03088000975549221, "_runtime": 573.0590524673462, "_timestamp": 1585074084.0588145, "_step": 460}
{"Episode reward": -98.93541024837937, "Episode length": 999, "Policy Loss": -12.732644081115723, "Value Loss": 0.031117482110857964, "_runtime": 574.2037603855133, "_timestamp": 1585074085.2035224, "_step": 461}
{"Episode reward": -95.71001089384039, "Episode length": 999, "Policy Loss": -12.08281421661377, "Value Loss": 0.02488701045513153, "_runtime": 575.3687345981598, "_timestamp": 1585074086.3684967, "_step": 462}
{"Episode reward": -98.44324210704272, "Episode length": 999, "Policy Loss": -12.638983726501465, "Value Loss": 0.028535543009638786, "_runtime": 576.5130162239075, "_timestamp": 1585074087.5127783, "_step": 463}
{"Episode reward": -95.76506699895026, "Episode length": 999, "Policy Loss": -12.12142276763916, "Value Loss": 0.027113432064652443, "_runtime": 577.646714925766, "_timestamp": 1585074088.646477, "_step": 464}
{"Episode reward": -99.25969866938034, "Episode length": 999, "Policy Loss": -12.78696346282959, "Value Loss": 0.031704384833574295, "_runtime": 578.7978298664093, "_timestamp": 1585074089.797592, "_step": 465}
{"Episode reward": -110.06022094800129, "Episode length": 999, "Policy Loss": -14.6857271194458, "Value Loss": 0.039885103702545166, "_runtime": 579.9151086807251, "_timestamp": 1585074090.9148707, "_step": 466}
{"Episode reward": -99.66693832185348, "Episode length": 999, "Policy Loss": -12.840407371520996, "Value Loss": 0.02900286763906479, "_runtime": 581.0339765548706, "_timestamp": 1585074092.0337386, "_step": 467}
{"Episode reward": -105.36876439576028, "Episode length": 999, "Policy Loss": -13.590733528137207, "Value Loss": 0.033178310841321945, "_runtime": 582.1832127571106, "_timestamp": 1585074093.1829748, "_step": 468}
{"Episode reward": -96.57131281397777, "Episode length": 999, "Policy Loss": -12.192477226257324, "Value Loss": 0.027567820623517036, "_runtime": 583.2901883125305, "_timestamp": 1585074094.2899504, "_step": 469}
{"Episode reward": -98.54198609181238, "Episode length": 999, "Policy Loss": -12.522993087768555, "Value Loss": 0.028264958411455154, "_runtime": 584.4012982845306, "_timestamp": 1585074095.4010603, "_step": 470}
{"Episode reward": -95.48845122057767, "Episode length": 999, "Policy Loss": -12.123547554016113, "Value Loss": 0.02773691713809967, "_runtime": 585.5442481040955, "_timestamp": 1585074096.5440102, "_step": 471}
{"Episode reward": -101.7675232811804, "Episode length": 999, "Policy Loss": -13.128850936889648, "Value Loss": 0.030683590099215508, "_runtime": 586.6994898319244, "_timestamp": 1585074097.699252, "_step": 472}
{"Episode reward": -97.84617509403223, "Episode length": 999, "Policy Loss": -12.60080337524414, "Value Loss": 0.02960575744509697, "_runtime": 587.8607685565948, "_timestamp": 1585074098.8605306, "_step": 473}
{"Episode reward": -93.2249384957335, "Episode length": 999, "Policy Loss": -11.707149505615234, "Value Loss": 0.025379296392202377, "_runtime": 589.0125348567963, "_timestamp": 1585074100.012297, "_step": 474}
{"Episode reward": -97.0443941170486, "Episode length": 999, "Policy Loss": -12.574548721313477, "Value Loss": 0.025630692020058632, "_runtime": 590.132928609848, "_timestamp": 1585074101.1326907, "_step": 475}
{"Episode reward": -91.63567670100421, "Episode length": 999, "Policy Loss": -11.335103034973145, "Value Loss": 0.026287950575351715, "_runtime": 591.2706019878387, "_timestamp": 1585074102.270364, "_step": 476}
{"Episode reward": -91.43394726134599, "Episode length": 999, "Policy Loss": -11.283590316772461, "Value Loss": 0.02582455240190029, "_runtime": 592.4383029937744, "_timestamp": 1585074103.438065, "_step": 477}
{"Episode reward": -92.9120747777581, "Episode length": 999, "Policy Loss": -11.68224811553955, "Value Loss": 0.024146780371665955, "_runtime": 593.5624175071716, "_timestamp": 1585074104.5621796, "_step": 478}
{"Episode reward": -98.6444301352402, "Episode length": 999, "Policy Loss": -12.46654224395752, "Value Loss": 0.029804309830069542, "_runtime": 594.7029960155487, "_timestamp": 1585074105.702758, "_step": 479}
{"Episode reward": -103.36387389197002, "Episode length": 999, "Policy Loss": -13.417614936828613, "Value Loss": 0.0320158377289772, "_runtime": 595.8341822624207, "_timestamp": 1585074106.8339443, "_step": 480}
{"Episode reward": -103.39644356078723, "Episode length": 999, "Policy Loss": -13.622325897216797, "Value Loss": 0.0335007980465889, "_runtime": 596.976220369339, "_timestamp": 1585074107.9759824, "_step": 481}
{"Episode reward": -93.63965279609467, "Episode length": 999, "Policy Loss": -11.742325782775879, "Value Loss": 0.025590328499674797, "_runtime": 598.1386814117432, "_timestamp": 1585074109.1384435, "_step": 482}
{"Episode reward": -85.02189557393903, "Episode length": 999, "Policy Loss": -10.594407081604004, "Value Loss": 0.02068544365465641, "_runtime": 599.2683432102203, "_timestamp": 1585074110.2681053, "_step": 483}
{"Episode reward": -99.51595260573632, "Episode length": 999, "Policy Loss": -12.604283332824707, "Value Loss": 0.02886960096657276, "_runtime": 600.4440634250641, "_timestamp": 1585074111.4438255, "_step": 484}
{"Episode reward": -103.83996272164663, "Episode length": 999, "Policy Loss": -13.500229835510254, "Value Loss": 0.030164198949933052, "_runtime": 601.0319509506226, "_timestamp": 1585074112.031713, "_step": 485}
{"Episode reward": 38.36152137530783, "Episode length": 523, "Policy Loss": 14.372458457946777, "Value Loss": 18.90889549255371, "_runtime": 602.1630854606628, "_timestamp": 1585074113.1628475, "_step": 486}
{"Episode reward": -104.62979582106112, "Episode length": 999, "Policy Loss": -13.766822814941406, "Value Loss": 0.030040115118026733, "_runtime": 603.2746267318726, "_timestamp": 1585074114.2743888, "_step": 487}
{"Episode reward": -101.32309184888575, "Episode length": 999, "Policy Loss": -13.103288650512695, "Value Loss": 0.030276305973529816, "_runtime": 604.3655660152435, "_timestamp": 1585074115.365328, "_step": 488}
{"Episode reward": -107.02740189409425, "Episode length": 999, "Policy Loss": -13.905585289001465, "Value Loss": 0.03609662503004074, "_runtime": 605.5327837467194, "_timestamp": 1585074116.5325458, "_step": 489}
{"Episode reward": -101.83973932646916, "Episode length": 999, "Policy Loss": -13.226018905639648, "Value Loss": 0.030645204707980156, "_runtime": 606.6596956253052, "_timestamp": 1585074117.6594577, "_step": 490}
{"Episode reward": 6.172644167741936, "Episode length": 976, "Policy Loss": 1.4974852800369263, "Value Loss": 10.246575355529785, "_runtime": 607.806467294693, "_timestamp": 1585074118.8062294, "_step": 491}
{"Episode reward": -99.90926531489228, "Episode length": 999, "Policy Loss": -12.904804229736328, "Value Loss": 0.027771012857556343, "_runtime": 608.9481918811798, "_timestamp": 1585074119.947954, "_step": 492}
{"Episode reward": -95.6803237624131, "Episode length": 999, "Policy Loss": -12.237712860107422, "Value Loss": 0.026601517572999, "_runtime": 610.0602803230286, "_timestamp": 1585074121.0600424, "_step": 493}
{"Episode reward": -104.05615606528235, "Episode length": 999, "Policy Loss": -13.798242568969727, "Value Loss": 0.03242398798465729, "_runtime": 611.1887540817261, "_timestamp": 1585074122.1885161, "_step": 494}
{"Episode reward": -95.15266371252687, "Episode length": 999, "Policy Loss": -12.032917022705078, "Value Loss": 0.026862943544983864, "_runtime": 612.3643336296082, "_timestamp": 1585074123.3640957, "_step": 495}
{"Episode reward": -103.92510315898102, "Episode length": 999, "Policy Loss": -13.77456283569336, "Value Loss": 0.03014596737921238, "_runtime": 613.5162146091461, "_timestamp": 1585074124.5159767, "_step": 496}
{"Episode reward": -107.0981037576303, "Episode length": 999, "Policy Loss": -13.985705375671387, "Value Loss": 0.03393770754337311, "_runtime": 614.718649148941, "_timestamp": 1585074125.7184112, "_step": 497}
{"Episode reward": -107.90106322578389, "Episode length": 999, "Policy Loss": -14.582839965820312, "Value Loss": 0.03885539993643761, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125, -541.2001953125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-462.7105712890625, -451.10687255859375, -439.503173828125, -427.89947509765625, -416.2957458496094, -404.6920471191406, -393.0883483886719, -381.4846496582031, -369.88092041015625, -358.2772216796875, -346.67352294921875, -335.06982421875, -323.46612548828125, -311.8624267578125, -300.25872802734375, -288.6549987792969, -277.0513000488281, -265.4476013183594, -253.84388732910156, -242.2401885986328, -230.636474609375, -219.03277587890625, -207.4290771484375, -195.82537841796875, -184.2216796875, -172.61795043945312, -161.01425170898438, -149.41055297851562, -137.80685424804688, -126.20315551757812, -114.59942626953125, -102.9957275390625, -91.39202880859375, -79.788330078125, -68.18463134765625, -56.580902099609375, -44.977203369140625, -33.373504638671875, -21.769805908203125, -10.166107177734375, 1.4376220703125, 13.04132080078125, 24.64501953125, 36.24871826171875, 47.8524169921875, 59.45611572265625, 71.059814453125, 82.66351318359375, 94.2672119140625, 105.8709716796875, 117.47467041015625, 129.078369140625, 140.68206787109375, 152.2857666015625, 163.88946533203125, 175.4931640625, 187.09686279296875, 198.7005615234375, 210.30426025390625, 221.90802001953125, 233.51171875, 245.11541748046875, 256.7191162109375, 268.32281494140625, 279.926513671875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-260.8380126953125, -252.1587371826172, -243.47946166992188, -234.80018615722656, -226.12091064453125, -217.44163513183594, -208.76235961914062, -200.08306884765625, -191.40380859375, -182.72451782226562, -174.04525756835938, -165.365966796875, -156.6866912841797, -148.00741577148438, -139.32814025878906, -130.64886474609375, -121.96958923339844, -113.29031372070312, -104.61103820800781, -95.9317626953125, -87.25248718261719, -78.57321166992188, -69.89393615722656, -61.21466064453125, -52.535369873046875, -43.85609436035156, -35.17681884765625, -26.497543334960938, -17.818267822265625, -9.138992309570312, -0.459716796875, 8.21954345703125, 16.898834228515625, 25.578125, 34.25738525390625, 42.936676025390625, 51.615936279296875, 60.29522705078125, 68.9744873046875, 77.65377807617188, 86.33303833007812, 95.0123291015625, 103.69158935546875, 112.37088012695312, 121.05014038085938, 129.72943115234375, 138.40869140625, 147.08798217773438, 155.76727294921875, 164.446533203125, 173.12582397460938, 181.80508422851562, 190.484375, 199.16363525390625, 207.84292602539062, 216.52218627929688, 225.20147705078125, 233.8807373046875, 242.56002807617188, 251.23931884765625, 259.9185791015625, 268.59783935546875, 277.277099609375, 285.9564208984375, 294.63568115234375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 5.0, 2.0, 3.0, 6.0, 13.0, 12.0, 13.0, 12.0, 32.0, 23.0, 23.0, 37.0, 40.0, 38.0, 47.0, 28.0, 14.0, 21.0, 11.0, 11.0, 9.0, 12.0, 7.0, 12.0, 7.0, 10.0, 3.0, 11.0, 4.0, 4.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-208.1244659423828, -201.19601440429688, -194.267578125, -187.33912658691406, -180.41067504882812, -173.48223876953125, -166.5537872314453, -159.62533569335938, -152.69688415527344, -145.7684326171875, -138.83999633789062, -131.9115447998047, -124.98310089111328, -118.05464935302734, -111.12620544433594, -104.19775390625, -97.2693099975586, -90.34086608886719, -83.41241455078125, -76.48396301269531, -69.55552673339844, -62.6270751953125, -55.69862365722656, -48.770172119140625, -41.84173583984375, -34.91328430175781, -27.984832763671875, -21.056396484375, -14.127944946289062, -7.199493408203125, -0.2710418701171875, 6.6573944091796875, 13.585845947265625, 20.514297485351562, 27.442733764648438, 34.371185302734375, 41.29963684082031, 48.22807312011719, 55.15653991699219, 62.08497619628906, 69.01341247558594, 75.94187927246094, 82.87031555175781, 89.79875183105469, 96.72721862792969, 103.65565490722656, 110.58412170410156, 117.51255798339844, 124.44099426269531, 131.3694610595703, 138.2978973388672, 145.22633361816406, 152.15480041503906, 159.08323669433594, 166.0116729736328, 172.9401397705078, 179.8685760498047, 186.79701232910156, 193.72547912597656, 200.65391540527344, 207.58238220214844, 214.5108184814453, 221.4392547607422, 228.3677215576172, 235.29615783691406]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-208.24313354492188, -203.1132354736328, -197.98333740234375, -192.8534393310547, -187.72354125976562, -182.5936279296875, -177.4637451171875, -172.33383178710938, -167.2039337158203, -162.07403564453125, -156.9441375732422, -151.81423950195312, -146.68434143066406, -141.554443359375, -136.42453002929688, -131.29464721679688, -126.16474151611328, -121.03484344482422, -115.90494537353516, -110.77503967285156, -105.6451416015625, -100.51524353027344, -95.38534545898438, -90.25544738769531, -85.12554931640625, -79.99565124511719, -74.86575317382812, -69.73583984375, -64.60594177246094, -59.476043701171875, -54.34614562988281, -49.21624755859375, -44.08634948730469, -38.956451416015625, -33.82655334472656, -28.6966552734375, -23.566757202148438, -18.436859130859375, -13.30694580078125, -8.177047729492188, -3.047149658203125, 2.0827484130859375, 7.212646484375, 12.342544555664062, 17.472442626953125, 22.602340698242188, 27.73223876953125, 32.86213684082031, 37.992034912109375, 43.1219482421875, 48.2518310546875, 53.381744384765625, 58.511627197265625, 63.64154052734375, 68.77145385742188, 73.90133666992188, 79.03125, 84.1611328125, 89.29104614257812, 94.42092895507812, 99.55084228515625, 104.68072509765625, 109.81063842773438, 114.94052124023438, 120.0704345703125]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 32.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-45.74025344848633, -43.77892303466797, -41.81759262084961, -39.85626220703125, -37.89493179321289, -35.93360137939453, -33.972267150878906, -32.01094055175781, -30.04960823059082, -28.08827781677246, -26.1269474029541, -24.165616989135742, -22.20428466796875, -20.24295425415039, -18.28162384033203, -16.320293426513672, -14.358963012695312, -12.397632598876953, -10.436302185058594, -8.474971771240234, -6.513641357421875, -4.552310943603516, -2.5909805297851562, -0.6296501159667969, 1.3316841125488281, 3.2930145263671875, 5.254344940185547, 7.215675354003906, 9.177005767822266, 11.138336181640625, 13.099666595458984, 15.060997009277344, 17.022327423095703, 18.983661651611328, 20.944988250732422, 22.906322479248047, 24.86764907836914, 26.828983306884766, 28.79030990600586, 30.751644134521484, 32.71297073364258, 34.6743049621582, 36.6356315612793, 38.59696578979492, 40.558292388916016, 42.51962661743164, 44.480953216552734, 46.44228744506836, 48.403621673583984, 50.36494827270508, 52.3262825012207, 54.2876091003418, 56.24894332885742, 58.210269927978516, 60.17160415649414, 62.132930755615234, 64.09426879882812, 66.05558776855469, 68.01692199707031, 69.97825622558594, 71.93959045410156, 73.90090942382812, 75.86224365234375, 77.82357788085938, 79.784912109375]}, "_runtime": 615.8811712265015, "_timestamp": 1585074126.8809333, "_step": 498}
{"Episode reward": -96.61768265765801, "Episode length": 999, "Policy Loss": -12.321667671203613, "Value Loss": 0.027754204347729683, "_runtime": 617.03249335289, "_timestamp": 1585074128.0322554, "_step": 499}
{"Episode reward": -93.46717386850273, "Episode length": 999, "Policy Loss": -11.697504043579102, "Value Loss": 0.025544127449393272, "_runtime": 617.03249335289, "_timestamp": 1585074128.0322554, "_step": 500}
