{"Episode reward": 57.145103896497474, "Episode length": 591, "Policy Loss": 0.13175706565380096, "Value Loss": 16.984251022338867, "_runtime": 2453.129620552063, "_timestamp": 1585599822.76249, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3263778686523438, "Value Loss": 95.97431182861328, "_runtime": 2454.5922038555145, "_timestamp": 1585599824.2250733, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.77934455871582, "Value Loss": 372.7748718261719, "_runtime": 2456.1060802936554, "_timestamp": 1585599825.7389498, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -55.11912155151367, "Value Loss": 90587.953125, "_runtime": 2457.648092985153, "_timestamp": 1585599827.2809625, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -36.309818267822266, "Value Loss": 10624.4619140625, "_runtime": 2459.1483845710754, "_timestamp": 1585599828.781254, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.844670295715332, "Value Loss": 1098.8660888671875, "_runtime": 2460.6863956451416, "_timestamp": 1585599830.3192651, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33094072341918945, "Value Loss": 3.298809051513672, "_runtime": 2462.2393531799316, "_timestamp": 1585599831.8722227, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5739758014678955, "Value Loss": 16.307907104492188, "_runtime": 2463.7459938526154, "_timestamp": 1585599833.3788633, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.865128993988037, "Value Loss": 0.12633751332759857, "_runtime": 2465.344124317169, "_timestamp": 1585599834.9769938, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9289019107818604, "Value Loss": 0.07643473148345947, "_runtime": 2466.902013063431, "_timestamp": 1585599836.5348825, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.992652654647827, "Value Loss": 0.07979828864336014, "_runtime": 2468.4385392665863, "_timestamp": 1585599838.0714087, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0479798316955566, "Value Loss": 0.08277608454227448, "_runtime": 2469.986695289612, "_timestamp": 1585599839.6195648, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0958666801452637, "Value Loss": 0.0853976234793663, "_runtime": 2471.525552749634, "_timestamp": 1585599841.1584222, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.1371896266937256, "Value Loss": 0.0876925066113472, "_runtime": 2473.067464351654, "_timestamp": 1585599842.7003338, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.172609567642212, "Value Loss": 0.08968397229909897, "_runtime": 2474.6144433021545, "_timestamp": 1585599844.2473128, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.202737331390381, "Value Loss": 0.09139534085988998, "_runtime": 2476.173770427704, "_timestamp": 1585599845.80664, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2281177043914795, "Value Loss": 0.09284956008195877, "_runtime": 2477.7193825244904, "_timestamp": 1585599847.352252, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2491538524627686, "Value Loss": 0.09406353533267975, "_runtime": 2479.265246629715, "_timestamp": 1585599848.898116, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.266249418258667, "Value Loss": 0.0950559675693512, "_runtime": 2480.8136024475098, "_timestamp": 1585599850.446472, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2797646522521973, "Value Loss": 0.09584446251392365, "_runtime": 2482.3517274856567, "_timestamp": 1585599851.984597, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.289991617202759, "Value Loss": 0.09644293040037155, "_runtime": 2483.898766040802, "_timestamp": 1585599853.5316355, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2972443103790283, "Value Loss": 0.09686870127916336, "_runtime": 2485.4389188289642, "_timestamp": 1585599855.0717883, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.301710605621338, "Value Loss": 0.09713123738765717, "_runtime": 2486.9861390590668, "_timestamp": 1585599856.6190085, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.303671360015869, "Value Loss": 0.09724660217761993, "_runtime": 2488.5770976543427, "_timestamp": 1585599858.2099671, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.303305149078369, "Value Loss": 0.09722521901130676, "_runtime": 2490.1377353668213, "_timestamp": 1585599859.7706048, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3008017539978027, "Value Loss": 0.09707775712013245, "_runtime": 2491.6871495246887, "_timestamp": 1585599861.320019, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2963342666625977, "Value Loss": 0.09681529551744461, "_runtime": 2493.244175672531, "_timestamp": 1585599862.8770452, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2900311946868896, "Value Loss": 0.09644529968500137, "_runtime": 2494.806543827057, "_timestamp": 1585599864.4394133, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2820682525634766, "Value Loss": 0.09597904980182648, "_runtime": 2496.3457639217377, "_timestamp": 1585599865.9786334, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2725722789764404, "Value Loss": 0.09542439132928848, "_runtime": 2497.890925168991, "_timestamp": 1585599867.5237947, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.261640787124634, "Value Loss": 0.09478800743818283, "_runtime": 2499.4545092582703, "_timestamp": 1585599869.0873787, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2493736743927, "Value Loss": 0.09407642483711243, "_runtime": 2501.00585770607, "_timestamp": 1585599870.6387272, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2359161376953125, "Value Loss": 0.09329883754253387, "_runtime": 2502.551986694336, "_timestamp": 1585599872.1848562, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2213497161865234, "Value Loss": 0.09246062487363815, "_runtime": 2504.1129183769226, "_timestamp": 1585599873.7457879, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2057290077209473, "Value Loss": 0.09156610816717148, "_runtime": 2505.6511986255646, "_timestamp": 1585599875.284068, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.1891610622406006, "Value Loss": 0.09062201529741287, "_runtime": 2507.1870760917664, "_timestamp": 1585599876.8199456, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.171700954437256, "Value Loss": 0.08963251858949661, "_runtime": 2508.7363567352295, "_timestamp": 1585599878.3692262, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.153456687927246, "Value Loss": 0.08860424160957336, "_runtime": 2510.2805786132812, "_timestamp": 1585599879.913448, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.1344408988952637, "Value Loss": 0.0875389575958252, "_runtime": 2511.8724319934845, "_timestamp": 1585599881.5053015, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.114738702774048, "Value Loss": 0.08644197136163712, "_runtime": 2513.4334456920624, "_timestamp": 1585599883.0663152, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0944137573242188, "Value Loss": 0.08531738072633743, "_runtime": 2514.976031780243, "_timestamp": 1585599884.6089013, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0734989643096924, "Value Loss": 0.08416802436113358, "_runtime": 2516.5326199531555, "_timestamp": 1585599886.1654894, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.052039384841919, "Value Loss": 0.08299684524536133, "_runtime": 2518.0931305885315, "_timestamp": 1585599887.726, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.030113458633423, "Value Loss": 0.08180872350931168, "_runtime": 2519.646222114563, "_timestamp": 1585599889.2790916, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.007706642150879, "Value Loss": 0.08060313761234283, "_runtime": 2521.2036368846893, "_timestamp": 1585599890.8365064, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9849138259887695, "Value Loss": 0.07938611507415771, "_runtime": 2522.7655403614044, "_timestamp": 1585599892.3984098, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9617154598236084, "Value Loss": 0.07815703749656677, "_runtime": 2524.308025121689, "_timestamp": 1585599893.9408946, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.93819522857666, "Value Loss": 0.07692059874534607, "_runtime": 2525.8633172512054, "_timestamp": 1585599895.4961867, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9143521785736084, "Value Loss": 0.07567723840475082, "_runtime": 2527.423727273941, "_timestamp": 1585599897.0565968, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.890245199203491, "Value Loss": 0.07443048804998398, "_runtime": 2528.9758393764496, "_timestamp": 1585599898.6087089, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.865858316421509, "Value Loss": 0.07317964732646942, "_runtime": 2530.5334203243256, "_timestamp": 1585599900.1662898, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.84124755859375, "Value Loss": 0.07192813605070114, "_runtime": 2532.082591533661, "_timestamp": 1585599901.715461, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.816431760787964, "Value Loss": 0.07067728042602539, "_runtime": 2533.660732984543, "_timestamp": 1585599903.2936025, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7914364337921143, "Value Loss": 0.06942833960056305, "_runtime": 2535.2161498069763, "_timestamp": 1585599904.8490193, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7662596702575684, "Value Loss": 0.06818161904811859, "_runtime": 2536.7752079963684, "_timestamp": 1585599906.4080775, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7409512996673584, "Value Loss": 0.06693970412015915, "_runtime": 2538.3325579166412, "_timestamp": 1585599907.9654274, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.71551251411438, "Value Loss": 0.0657029002904892, "_runtime": 2539.8878231048584, "_timestamp": 1585599909.5206926, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6899592876434326, "Value Loss": 0.0644722580909729, "_runtime": 2541.4461805820465, "_timestamp": 1585599911.07905, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6643283367156982, "Value Loss": 0.06324944645166397, "_runtime": 2542.9996342658997, "_timestamp": 1585599912.6325037, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6386055946350098, "Value Loss": 0.06203403323888779, "_runtime": 2544.547283411026, "_timestamp": 1585599914.180153, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6128318309783936, "Value Loss": 0.06082809716463089, "_runtime": 2546.103899717331, "_timestamp": 1585599915.7367692, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5869979858398438, "Value Loss": 0.05963120236992836, "_runtime": 2547.655963897705, "_timestamp": 1585599917.2888334, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5611331462860107, "Value Loss": 0.05844476819038391, "_runtime": 2549.2116577625275, "_timestamp": 1585599918.8445272, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5352394580841064, "Value Loss": 0.05726897716522217, "_runtime": 2550.7710540294647, "_timestamp": 1585599920.4039235, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5093350410461426, "Value Loss": 0.05610455945134163, "_runtime": 2552.312837123871, "_timestamp": 1585599921.9457066, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.483429431915283, "Value Loss": 0.054952215403318405, "_runtime": 2553.8677632808685, "_timestamp": 1585599923.5006328, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.457526445388794, "Value Loss": 0.05381177365779877, "_runtime": 2555.4171164035797, "_timestamp": 1585599925.049986, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.431640863418579, "Value Loss": 0.052684180438518524, "_runtime": 2556.9979355335236, "_timestamp": 1585599926.630805, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.405787229537964, "Value Loss": 0.051569823175668716, "_runtime": 2558.543877840042, "_timestamp": 1585599928.1767473, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.379962921142578, "Value Loss": 0.050468653440475464, "_runtime": 2560.0918810367584, "_timestamp": 1585599929.7247505, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.354179859161377, "Value Loss": 0.049381058663129807, "_runtime": 2561.647004365921, "_timestamp": 1585599931.2798738, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3284568786621094, "Value Loss": 0.048307862132787704, "_runtime": 2563.194583415985, "_timestamp": 1585599932.827453, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3027842044830322, "Value Loss": 0.047248490154743195, "_runtime": 2564.7606358528137, "_timestamp": 1585599934.3935053, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.277172565460205, "Value Loss": 0.04620334133505821, "_runtime": 2566.3229365348816, "_timestamp": 1585599935.955806, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.251643419265747, "Value Loss": 0.04517313092947006, "_runtime": 2567.8785405158997, "_timestamp": 1585599937.51141, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2261810302734375, "Value Loss": 0.04415731504559517, "_runtime": 2569.424013376236, "_timestamp": 1585599939.0568829, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2008018493652344, "Value Loss": 0.043156225234270096, "_runtime": 2570.9827709198, "_timestamp": 1585599940.6156404, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.175525426864624, "Value Loss": 0.04217054322361946, "_runtime": 2572.541587114334, "_timestamp": 1585599942.1744566, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.150327444076538, "Value Loss": 0.04119933769106865, "_runtime": 2574.1013877391815, "_timestamp": 1585599943.7342572, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1252405643463135, "Value Loss": 0.04024367779493332, "_runtime": 2575.6553444862366, "_timestamp": 1585599945.288214, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.100257396697998, "Value Loss": 0.03930298984050751, "_runtime": 2577.2121081352234, "_timestamp": 1585599946.8449776, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0753824710845947, "Value Loss": 0.03837752342224121, "_runtime": 2578.7708916664124, "_timestamp": 1585599948.4037611, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0506181716918945, "Value Loss": 0.037467192858457565, "_runtime": 2580.3472261428833, "_timestamp": 1585599949.9800956, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.025977849960327, "Value Loss": 0.036572109907865524, "_runtime": 2581.9035925865173, "_timestamp": 1585599951.536462, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0014569759368896, "Value Loss": 0.03569220006465912, "_runtime": 2583.4503915309906, "_timestamp": 1585599953.083261, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9770575761795044, "Value Loss": 0.03482729569077492, "_runtime": 2584.997376680374, "_timestamp": 1585599954.6302462, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.952799677848816, "Value Loss": 0.03397787734866142, "_runtime": 2586.5543603897095, "_timestamp": 1585599956.1872299, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9286627769470215, "Value Loss": 0.03314315527677536, "_runtime": 2588.1136453151703, "_timestamp": 1585599957.7465148, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9046629667282104, "Value Loss": 0.03232341259717941, "_runtime": 2589.67036652565, "_timestamp": 1585599959.303236, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8808035850524902, "Value Loss": 0.03151869401335716, "_runtime": 2591.218381881714, "_timestamp": 1585599960.8512514, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.857090711593628, "Value Loss": 0.030728956684470177, "_runtime": 2592.7756588459015, "_timestamp": 1585599962.4085283, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8335262537002563, "Value Loss": 0.029954036697745323, "_runtime": 2594.3216845989227, "_timestamp": 1585599963.954554, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8101067543029785, "Value Loss": 0.029193714261054993, "_runtime": 2595.878225326538, "_timestamp": 1585599965.5110948, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7868390083312988, "Value Loss": 0.028448030352592468, "_runtime": 2597.4245109558105, "_timestamp": 1585599967.0573804, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7637224197387695, "Value Loss": 0.02771672047674656, "_runtime": 2598.9793095588684, "_timestamp": 1585599968.612179, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7407678365707397, "Value Loss": 0.026999955996870995, "_runtime": 2600.5357065200806, "_timestamp": 1585599970.168576, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7179654836654663, "Value Loss": 0.026297224685549736, "_runtime": 2602.092696428299, "_timestamp": 1585599971.725566, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6953288316726685, "Value Loss": 0.025608792901039124, "_runtime": 2603.6730082035065, "_timestamp": 1585599973.3058777, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6728487014770508, "Value Loss": 0.024934174492955208, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2605.2296290397644, "_timestamp": 1585599974.8624985, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.650536298751831, "Value Loss": 0.024273451417684555, "_runtime": 2606.784583568573, "_timestamp": 1585599976.417453, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6283848285675049, "Value Loss": 0.023626284673810005, "_runtime": 2608.325105905533, "_timestamp": 1585599977.9579754, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.606406331062317, "Value Loss": 0.022992795333266258, "_runtime": 2609.8820283412933, "_timestamp": 1585599979.5148978, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5845985412597656, "Value Loss": 0.022372744977474213, "_runtime": 2611.438793897629, "_timestamp": 1585599981.0716634, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.562957763671875, "Value Loss": 0.02176583558320999, "_runtime": 2612.9927246570587, "_timestamp": 1585599982.6255941, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5414878129959106, "Value Loss": 0.021171966567635536, "_runtime": 2614.53582906723, "_timestamp": 1585599984.1686985, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.52019464969635, "Value Loss": 0.020591123029589653, "_runtime": 2616.078774690628, "_timestamp": 1585599985.7116442, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4990737438201904, "Value Loss": 0.020022932440042496, "_runtime": 2617.6202297210693, "_timestamp": 1585599987.2530992, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4781330823898315, "Value Loss": 0.019467419013381004, "_runtime": 2619.1661314964294, "_timestamp": 1585599988.799001, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4573662281036377, "Value Loss": 0.01892423816025257, "_runtime": 2620.7197635173798, "_timestamp": 1585599990.352633, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4367778301239014, "Value Loss": 0.01839332841336727, "_runtime": 2622.2502760887146, "_timestamp": 1585599991.8831456, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.416370153427124, "Value Loss": 0.01787451095879078, "_runtime": 2623.798901081085, "_timestamp": 1585599993.4317706, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3961405754089355, "Value Loss": 0.01736758090555668, "_runtime": 2625.391370534897, "_timestamp": 1585599995.02424, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3760906457901, "Value Loss": 0.016872338950634003, "_runtime": 2626.9467585086823, "_timestamp": 1585599996.579628, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3562225103378296, "Value Loss": 0.01638864167034626, "_runtime": 2628.50070810318, "_timestamp": 1585599998.1335776, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3365362882614136, "Value Loss": 0.015916313976049423, "_runtime": 2630.054488182068, "_timestamp": 1585599999.6873577, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.317034363746643, "Value Loss": 0.01545523852109909, "_runtime": 2631.607723236084, "_timestamp": 1585600001.2405927, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2977144718170166, "Value Loss": 0.015005119144916534, "_runtime": 2633.1618218421936, "_timestamp": 1585600002.7946913, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2785799503326416, "Value Loss": 0.014565903693437576, "_runtime": 2634.7165784835815, "_timestamp": 1585600004.349448, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2596269845962524, "Value Loss": 0.014137259684503078, "_runtime": 2636.2575817108154, "_timestamp": 1585600005.8904512, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.240858554840088, "Value Loss": 0.013719114474952221, "_runtime": 2637.811892271042, "_timestamp": 1585600007.4447618, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2222752571105957, "Value Loss": 0.013311265967786312, "_runtime": 2639.366302013397, "_timestamp": 1585600008.9991715, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2038761377334595, "Value Loss": 0.01291352603584528, "_runtime": 2640.9188511371613, "_timestamp": 1585600010.5517206, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1856611967086792, "Value Loss": 0.012525709345936775, "_runtime": 2642.463123559952, "_timestamp": 1585600012.095993, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1676323413848877, "Value Loss": 0.012147675268352032, "_runtime": 2644.006502389908, "_timestamp": 1585600013.6393719, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1497882604599, "Value Loss": 0.011779236607253551, "_runtime": 2645.548916578293, "_timestamp": 1585600015.181786, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1321290731430054, "Value Loss": 0.011420189402997494, "_runtime": 2647.092442035675, "_timestamp": 1585600016.7253115, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1146544218063354, "Value Loss": 0.011070367880165577, "_runtime": 2648.682891368866, "_timestamp": 1585600018.3157609, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0973665714263916, "Value Loss": 0.010729614645242691, "_runtime": 2650.235691308975, "_timestamp": 1585600019.8685608, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0802618265151978, "Value Loss": 0.010397744365036488, "_runtime": 2651.7782237529755, "_timestamp": 1585600021.4110932, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0633416175842285, "Value Loss": 0.010074583813548088, "_runtime": 2653.3163669109344, "_timestamp": 1585600022.9492364, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0466063022613525, "Value Loss": 0.00975995883345604, "_runtime": 2654.867609500885, "_timestamp": 1585600024.500479, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0300543308258057, "Value Loss": 0.009453700855374336, "_runtime": 2656.419903755188, "_timestamp": 1585600026.0527732, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.013687014579773, "Value Loss": 0.009155641309916973, "_runtime": 2657.9731211662292, "_timestamp": 1585600027.6059906, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9975030422210693, "Value Loss": 0.008865623734891415, "_runtime": 2659.523216485977, "_timestamp": 1585600029.156086, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.981501042842865, "Value Loss": 0.00858346652239561, "_runtime": 2661.081876516342, "_timestamp": 1585600030.714746, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9656826257705688, "Value Loss": 0.008309020660817623, "_runtime": 2662.6349816322327, "_timestamp": 1585600032.267851, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9500453472137451, "Value Loss": 0.008042112924158573, "_runtime": 2664.183960199356, "_timestamp": 1585600033.8168297, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9345888495445251, "Value Loss": 0.007782558910548687, "_runtime": 2665.7391033172607, "_timestamp": 1585600035.3719728, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.919313907623291, "Value Loss": 0.007530242670327425, "_runtime": 2667.2895538806915, "_timestamp": 1585600036.9224234, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9042202234268188, "Value Loss": 0.00728499935939908, "_runtime": 2668.849713563919, "_timestamp": 1585600038.482583, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8893048167228699, "Value Loss": 0.007046650629490614, "_runtime": 2670.4104266166687, "_timestamp": 1585600040.043296, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8745694160461426, "Value Loss": 0.006815060041844845, "_runtime": 2672.001546859741, "_timestamp": 1585600041.6344163, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8600118160247803, "Value Loss": 0.006590069737285376, "_runtime": 2673.55415058136, "_timestamp": 1585600043.18702, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8456313014030457, "Value Loss": 0.0063715241849422455, "_runtime": 2675.1148161888123, "_timestamp": 1585600044.7476857, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.831428587436676, "Value Loss": 0.00615930138155818, "_runtime": 2676.6896998882294, "_timestamp": 1585600046.3225694, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8173999786376953, "Value Loss": 0.005953208543360233, "_runtime": 2678.2593944072723, "_timestamp": 1585600047.892264, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8035488128662109, "Value Loss": 0.0057531483471393585, "_runtime": 2679.8317227363586, "_timestamp": 1585600049.4645922, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7898712158203125, "Value Loss": 0.0055589680559933186, "_runtime": 2681.3968534469604, "_timestamp": 1585600051.029723, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7763689160346985, "Value Loss": 0.005370532628148794, "_runtime": 2682.957056045532, "_timestamp": 1585600052.5899255, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7630350589752197, "Value Loss": 0.005187644623219967, "_runtime": 2684.5303835868835, "_timestamp": 1585600054.163253, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7498759031295776, "Value Loss": 0.005010251421481371, "_runtime": 2686.0916862487793, "_timestamp": 1585600055.7245557, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7368851900100708, "Value Loss": 0.004838167689740658, "_runtime": 2687.6530833244324, "_timestamp": 1585600057.2859528, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.724066972732544, "Value Loss": 0.004671306349337101, "_runtime": 2689.2164652347565, "_timestamp": 1585600058.8493347, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7114151120185852, "Value Loss": 0.004509491380304098, "_runtime": 2690.7765316963196, "_timestamp": 1585600060.4094012, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6989325881004333, "Value Loss": 0.0043526291847229, "_runtime": 2692.3272898197174, "_timestamp": 1585600061.9601593, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6866170763969421, "Value Loss": 0.004200586583465338, "_runtime": 2693.88849902153, "_timestamp": 1585600063.5213685, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6744650602340698, "Value Loss": 0.004053219221532345, "_runtime": 2695.4930481910706, "_timestamp": 1585600065.1259177, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6624776124954224, "Value Loss": 0.003910423256456852, "_runtime": 2697.0610711574554, "_timestamp": 1585600066.6939406, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6506543159484863, "Value Loss": 0.003772088559344411, "_runtime": 2698.631364107132, "_timestamp": 1585600068.2642336, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6389927268028259, "Value Loss": 0.0036380880046635866, "_runtime": 2700.201647043228, "_timestamp": 1585600069.8345165, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.627495527267456, "Value Loss": 0.0035083445254713297, "_runtime": 2701.770594358444, "_timestamp": 1585600071.4034638, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6161543726921082, "Value Loss": 0.0033826755825430155, "_runtime": 2703.3322269916534, "_timestamp": 1585600072.9650965, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6049702763557434, "Value Loss": 0.003260987810790539, "_runtime": 2704.9029421806335, "_timestamp": 1585600074.5358117, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5939475297927856, "Value Loss": 0.003143241861835122, "_runtime": 2706.4707317352295, "_timestamp": 1585600076.1036012, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5830814838409424, "Value Loss": 0.003029285231605172, "_runtime": 2708.041193962097, "_timestamp": 1585600077.6740634, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5723671317100525, "Value Loss": 0.00291897589340806, "_runtime": 2709.609782934189, "_timestamp": 1585600079.2426524, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5618095993995667, "Value Loss": 0.002812284044921398, "_runtime": 2711.1794641017914, "_timestamp": 1585600080.8123336, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5514029264450073, "Value Loss": 0.0027090662624686956, "_runtime": 2712.738133907318, "_timestamp": 1585600082.3710034, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5411481857299805, "Value Loss": 0.00260923826135695, "_runtime": 2714.2872071266174, "_timestamp": 1585600083.9200766, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.531045138835907, "Value Loss": 0.002512718550860882, "_runtime": 2715.836991071701, "_timestamp": 1585600085.4698606, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5210887789726257, "Value Loss": 0.0024193800054490566, "_runtime": 2717.4091732501984, "_timestamp": 1585600087.0420427, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5112831592559814, "Value Loss": 0.0023291853722184896, "_runtime": 2719.0150027275085, "_timestamp": 1585600088.6478722, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5016193389892578, "Value Loss": 0.0022419707383960485, "_runtime": 2720.5746562480927, "_timestamp": 1585600090.2075257, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49210232496261597, "Value Loss": 0.002157703274860978, "_runtime": 2722.1468889713287, "_timestamp": 1585600091.7797585, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4827316403388977, "Value Loss": 0.002076312666758895, "_runtime": 2723.7168669700623, "_timestamp": 1585600093.3497365, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4734974801540375, "Value Loss": 0.001997634069994092, "_runtime": 2725.2865631580353, "_timestamp": 1585600094.9194326, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4644091725349426, "Value Loss": 0.0019216879736632109, "_runtime": 2726.8486053943634, "_timestamp": 1585600096.4814749, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4554575979709625, "Value Loss": 0.0018483217572793365, "_runtime": 2728.4175753593445, "_timestamp": 1585600098.0504448, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4466477334499359, "Value Loss": 0.0017775085289031267, "_runtime": 2729.9850318431854, "_timestamp": 1585600099.6179013, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.43797433376312256, "Value Loss": 0.0017091433983296156, "_runtime": 2731.5431609153748, "_timestamp": 1585600101.1760304, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42943206429481506, "Value Loss": 0.0016431227559223771, "_runtime": 2733.105449438095, "_timestamp": 1585600102.738319, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42102617025375366, "Value Loss": 0.001579425996169448, "_runtime": 2734.6749408245087, "_timestamp": 1585600104.3078103, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41275662183761597, "Value Loss": 0.0015179921174421906, "_runtime": 2736.235201358795, "_timestamp": 1585600105.8680708, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40461334586143494, "Value Loss": 0.0014586858451366425, "_runtime": 2737.7965161800385, "_timestamp": 1585600107.4293857, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3966065049171448, "Value Loss": 0.001401526271365583, "_runtime": 2739.355467557907, "_timestamp": 1585600108.988337, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.388721227645874, "Value Loss": 0.0013463485520333052, "_runtime": 2740.9514772892, "_timestamp": 1585600110.5843468, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3809671401977539, "Value Loss": 0.0012931700330227613, "_runtime": 2742.5130586624146, "_timestamp": 1585600112.1459281, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37333905696868896, "Value Loss": 0.0012419037520885468, "_runtime": 2744.0726692676544, "_timestamp": 1585600113.7055387, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3658372163772583, "Value Loss": 0.0011924965074285865, "_runtime": 2745.6469163894653, "_timestamp": 1585600115.2797859, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.35845690965652466, "Value Loss": 0.0011448673903942108, "_runtime": 2747.206274986267, "_timestamp": 1585600116.8391445, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3511978089809418, "Value Loss": 0.0010989676229655743, "_runtime": 2748.7761578559875, "_timestamp": 1585600118.4090273, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.34405985474586487, "Value Loss": 0.0010547491256147623, "_runtime": 2750.3480529785156, "_timestamp": 1585600119.9809225, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3370380699634552, "Value Loss": 0.001012136577628553, "_runtime": 2751.9210271835327, "_timestamp": 1585600121.5538967, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33013761043548584, "Value Loss": 0.0009711164166219532, "_runtime": 2753.4884979724884, "_timestamp": 1585600123.1213675, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32335346937179565, "Value Loss": 0.0009316133800894022, "_runtime": 2755.0665938854218, "_timestamp": 1585600124.6994634, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.31668004393577576, "Value Loss": 0.0008935576770454645, "_runtime": 2756.627691745758, "_timestamp": 1585600126.2605612, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.310123085975647, "Value Loss": 0.0008569383062422276, "_runtime": 2758.1982316970825, "_timestamp": 1585600127.8311012, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3036823570728302, "Value Loss": 0.0008217134163714945, "_runtime": 2759.771040201187, "_timestamp": 1585600129.4039097, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2973475456237793, "Value Loss": 0.0007877894677221775, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2761.331634759903, "_timestamp": 1585600130.9645042, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2911241054534912, "Value Loss": 0.0007551570888608694, "_runtime": 2762.8930113315582, "_timestamp": 1585600132.5258808, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2850065529346466, "Value Loss": 0.000723753881175071, "_runtime": 2764.4902629852295, "_timestamp": 1585600134.1231325, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2790002226829529, "Value Loss": 0.0006935700657777488, "_runtime": 2766.059328317642, "_timestamp": 1585600135.6921978, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.273095041513443, "Value Loss": 0.0006645205430686474, "_runtime": 2767.626906633377, "_timestamp": 1585600137.259776, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26730066537857056, "Value Loss": 0.0006366217858158052, "_runtime": 2769.187020778656, "_timestamp": 1585600138.8198903, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26160240173339844, "Value Loss": 0.000609768379945308, "_runtime": 2770.7603080272675, "_timestamp": 1585600140.3931775, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25600534677505493, "Value Loss": 0.0005839543300680816, "_runtime": 2772.329868555069, "_timestamp": 1585600141.962738, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2505141794681549, "Value Loss": 0.0005591725930571556, "_runtime": 2773.891967535019, "_timestamp": 1585600143.524837, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.245119109749794, "Value Loss": 0.0005353473825380206, "_runtime": 2775.4534265995026, "_timestamp": 1585600145.086296, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2398199737071991, "Value Loss": 0.0005124500021338463, "_runtime": 2777.0243725776672, "_timestamp": 1585600146.657242, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23461680114269257, "Value Loss": 0.0004904551897197962, "_runtime": 2778.58887386322, "_timestamp": 1585600148.2217433, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22950968146324158, "Value Loss": 0.00046933512203395367, "_runtime": 2780.161368370056, "_timestamp": 1585600149.7942379, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22449840605258942, "Value Loss": 0.00044906348921358585, "_runtime": 2781.7217383384705, "_timestamp": 1585600151.3546078, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21957822144031525, "Value Loss": 0.00042959520942531526, "_runtime": 2783.283660888672, "_timestamp": 1585600152.9165304, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21474888920783997, "Value Loss": 0.000410906330216676, "_runtime": 2784.846387863159, "_timestamp": 1585600154.4792573, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21001547574996948, "Value Loss": 0.000392992194974795, "_runtime": 2786.3965408802032, "_timestamp": 1585600156.0294104, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20535792410373688, "Value Loss": 0.00037575417081825435, "_runtime": 2788.004736185074, "_timestamp": 1585600157.6376057, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20080138742923737, "Value Loss": 0.0003592645516619086, "_runtime": 2789.564863204956, "_timestamp": 1585600159.1977327, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19631566107273102, "Value Loss": 0.00034339219564571977, "_runtime": 2791.134164571762, "_timestamp": 1585600160.767034, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19193069636821747, "Value Loss": 0.0003282239777036011, "_runtime": 2792.6958956718445, "_timestamp": 1585600162.3287652, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18761670589447021, "Value Loss": 0.00031363466405309737, "_runtime": 2794.2666625976562, "_timestamp": 1585600163.899532, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18339352309703827, "Value Loss": 0.0002996740222442895, "_runtime": 2795.825208425522, "_timestamp": 1585600165.458078, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17924118041992188, "Value Loss": 0.00028625718550756574, "_runtime": 2797.384034872055, "_timestamp": 1585600167.0169044, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17517957091331482, "Value Loss": 0.0002734313311520964, "_runtime": 2798.9547867774963, "_timestamp": 1585600168.5876563, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1711888313293457, "Value Loss": 0.00026111508486792445, "_runtime": 2800.5211839675903, "_timestamp": 1585600170.1540534, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1672789305448532, "Value Loss": 0.0002493235806468874, "_runtime": 2802.0922117233276, "_timestamp": 1585600171.7250812, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16344980895519257, "Value Loss": 0.00023804005468264222, "_runtime": 2803.6528539657593, "_timestamp": 1585600173.2857234, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15969139337539673, "Value Loss": 0.0002272186247864738, "_runtime": 2805.2232570648193, "_timestamp": 1585600174.8561265, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15600377321243286, "Value Loss": 0.00021684584498871118, "_runtime": 2806.7937366962433, "_timestamp": 1585600176.4266062, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15238672494888306, "Value Loss": 0.00020690725068561733, "_runtime": 2808.353235244751, "_timestamp": 1585600177.9861047, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14885060489177704, "Value Loss": 0.00019741608412005007, "_runtime": 2809.922165632248, "_timestamp": 1585600179.555035, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1453852504491806, "Value Loss": 0.00018833101785276085, "_runtime": 2811.5160648822784, "_timestamp": 1585600181.1489344, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14198046922683716, "Value Loss": 0.00017961321282200515, "_runtime": 2813.074928998947, "_timestamp": 1585600182.7077985, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13864634931087494, "Value Loss": 0.00017127671162597835, "_runtime": 2814.633568048477, "_timestamp": 1585600184.2664375, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13538305461406708, "Value Loss": 0.0001633087667869404, "_runtime": 2816.2045056819916, "_timestamp": 1585600185.8373752, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13219043612480164, "Value Loss": 0.00015569744573440403, "_runtime": 2817.7655239105225, "_timestamp": 1585600187.3983934, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12905840575695038, "Value Loss": 0.0001484068197896704, "_runtime": 2819.3260130882263, "_timestamp": 1585600188.9588826, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12598705291748047, "Value Loss": 0.0001414272264810279, "_runtime": 2820.8974010944366, "_timestamp": 1585600190.5302706, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12298638373613358, "Value Loss": 0.00013477068569045514, "_runtime": 2822.469464302063, "_timestamp": 1585600192.1023338, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12004639208316803, "Value Loss": 0.00012840422277804464, "_runtime": 2824.0388872623444, "_timestamp": 1585600193.6717567, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11715680360794067, "Value Loss": 0.00012229723506607115, "_runtime": 2825.609865427017, "_timestamp": 1585600195.242735, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11433812230825424, "Value Loss": 0.00011648307554423809, "_runtime": 2827.178964138031, "_timestamp": 1585600196.8118336, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1115698292851448, "Value Loss": 0.00011091094347648323, "_runtime": 2828.748090028763, "_timestamp": 1585600198.3809595, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1088721826672554, "Value Loss": 0.00010561246745055541, "_runtime": 2830.297342777252, "_timestamp": 1585600199.9302123, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10622517764568329, "Value Loss": 0.00010053932055598125, "_runtime": 2831.8700489997864, "_timestamp": 1585600201.5029185, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10362865030765533, "Value Loss": 9.568434325046837e-05, "_runtime": 2833.475536584854, "_timestamp": 1585600203.108406, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10109272599220276, "Value Loss": 9.10586750251241e-05, "_runtime": 2835.045808315277, "_timestamp": 1585600204.6786778, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09860735386610031, "Value Loss": 8.663627522764727e-05, "_runtime": 2836.6057720184326, "_timestamp": 1585600206.2386415, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09618259966373444, "Value Loss": 8.242785406764597e-05, "_runtime": 2838.173892259598, "_timestamp": 1585600207.8067617, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0937982127070427, "Value Loss": 7.839177851565182e-05, "_runtime": 2839.7484850883484, "_timestamp": 1585600209.3813546, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09147453308105469, "Value Loss": 7.455575541825965e-05, "_runtime": 2841.318977355957, "_timestamp": 1585600210.9518468, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08920124173164368, "Value Loss": 7.08962616045028e-05, "_runtime": 2842.8804063796997, "_timestamp": 1585600212.5132759, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08697856962680817, "Value Loss": 6.740705430274829e-05, "_runtime": 2844.442661046982, "_timestamp": 1585600214.0755305, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0847962349653244, "Value Loss": 6.406705506378785e-05, "_runtime": 2846.013128042221, "_timestamp": 1585600215.6459975, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08266448974609375, "Value Loss": 6.088625741540454e-05, "_runtime": 2847.5724833011627, "_timestamp": 1585600217.2053528, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08058322966098785, "Value Loss": 5.785890971310437e-05, "_runtime": 2849.127762079239, "_timestamp": 1585600218.7606316, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0785524845123291, "Value Loss": 5.497949678101577e-05, "_runtime": 2850.6829035282135, "_timestamp": 1585600220.315773, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07655206322669983, "Value Loss": 5.221492756390944e-05, "_runtime": 2852.2367577552795, "_timestamp": 1585600221.8696272, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07461224496364594, "Value Loss": 4.960223668604158e-05, "_runtime": 2853.7908730506897, "_timestamp": 1585600223.4237425, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07270270586013794, "Value Loss": 4.709581480710767e-05, "_runtime": 2855.334064722061, "_timestamp": 1585600224.9669342, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07084372639656067, "Value Loss": 4.471815191209316e-05, "_runtime": 2856.9217615127563, "_timestamp": 1585600226.554631, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06902514398097992, "Value Loss": 4.2451792978681624e-05, "_runtime": 2858.4639201164246, "_timestamp": 1585600228.0967896, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06724698841571808, "Value Loss": 4.029273986816406e-05, "_runtime": 2860.0059826374054, "_timestamp": 1585600229.6388521, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06550919264554977, "Value Loss": 3.823718725470826e-05, "_runtime": 2861.548942089081, "_timestamp": 1585600231.1818116, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06381189078092575, "Value Loss": 3.6281409848015755e-05, "_runtime": 2863.105474472046, "_timestamp": 1585600232.738344, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.062154993414878845, "Value Loss": 3.442173692747019e-05, "_runtime": 2864.660249233246, "_timestamp": 1585600234.2931187, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.060528360307216644, "Value Loss": 3.264367478550412e-05, "_runtime": 2866.213198900223, "_timestamp": 1585600235.8460684, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05895223468542099, "Value Loss": 3.09657771140337e-05, "_runtime": 2867.770253419876, "_timestamp": 1585600237.403123, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05739636719226837, "Value Loss": 2.9352830097195692e-05, "_runtime": 2869.3015666007996, "_timestamp": 1585600238.934436, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05589093640446663, "Value Loss": 2.783328091027215e-05, "_runtime": 2870.844729423523, "_timestamp": 1585600240.477599, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05441591888666153, "Value Loss": 2.63835445366567e-05, "_runtime": 2872.394589662552, "_timestamp": 1585600242.0274591, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05297113209962845, "Value Loss": 2.5001136236824095e-05, "_runtime": 2873.9382605552673, "_timestamp": 1585600243.57113, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05156680569052696, "Value Loss": 2.3693077309872024e-05, "_runtime": 2875.4688489437103, "_timestamp": 1585600245.1017184, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05019275099039078, "Value Loss": 2.2447256924351677e-05, "_runtime": 2877.0126481056213, "_timestamp": 1585600246.6455176, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04884900897741318, "Value Loss": 2.1261459551169537e-05, "_runtime": 2878.5675439834595, "_timestamp": 1585600248.2004135, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04753561690449715, "Value Loss": 2.013350422203075e-05, "_runtime": 2880.1564893722534, "_timestamp": 1585600249.7893589, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04626260697841644, "Value Loss": 1.9069590052822605e-05, "_runtime": 2881.7134182453156, "_timestamp": 1585600251.3462877, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04500981792807579, "Value Loss": 1.8050772268907167e-05, "_runtime": 2883.2680315971375, "_timestamp": 1585600252.900901, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.043797411024570465, "Value Loss": 1.7091424524551257e-05, "_runtime": 2884.8229172229767, "_timestamp": 1585600254.4557867, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04260525479912758, "Value Loss": 1.617362977412995e-05, "_runtime": 2886.3653326034546, "_timestamp": 1585600255.998202, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0414433553814888, "Value Loss": 1.5303521649912e-05, "_runtime": 2887.9204428195953, "_timestamp": 1585600257.5533123, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04031183198094368, "Value Loss": 1.4479242963716388e-05, "_runtime": 2889.4710776805878, "_timestamp": 1585600259.1039472, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03921056538820267, "Value Loss": 1.369896017422434e-05, "_runtime": 2891.026128053665, "_timestamp": 1585600260.6589975, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03812951594591141, "Value Loss": 1.2953997611475643e-05, "_runtime": 2892.571214914322, "_timestamp": 1585600262.2040844, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.037078794091939926, "Value Loss": 1.2249887731741183e-05, "_runtime": 2894.1048266887665, "_timestamp": 1585600263.7376962, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0360482819378376, "Value Loss": 1.157843325927388e-05, "_runtime": 2895.6585881710052, "_timestamp": 1585600265.2914577, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03504806011915207, "Value Loss": 1.0944824680336751e-05, "_runtime": 2897.213788509369, "_timestamp": 1585600266.846658, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03407811373472214, "Value Loss": 1.0347434908908326e-05, "_runtime": 2898.755820274353, "_timestamp": 1585600268.3886898, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03312842175364494, "Value Loss": 9.778744242794346e-06, "_runtime": 2900.309149503708, "_timestamp": 1585600269.942019, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0321989580988884, "Value Loss": 9.23771131056128e-06, "_runtime": 2901.8613226413727, "_timestamp": 1585600271.4941921, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03128964453935623, "Value Loss": 8.723339306015987e-06, "_runtime": 2903.4477717876434, "_timestamp": 1585600273.0806413, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030410662293434143, "Value Loss": 8.240112038038205e-06, "_runtime": 2905.0025482177734, "_timestamp": 1585600274.6354177, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029551912099123, "Value Loss": 7.781297426845413e-06, "_runtime": 2906.5555453300476, "_timestamp": 1585600276.1884148, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028713345527648926, "Value Loss": 7.3459523264318705e-06, "_runtime": 2908.0977947711945, "_timestamp": 1585600277.7306643, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02790505811572075, "Value Loss": 6.938210390217137e-06, "_runtime": 2909.6528968811035, "_timestamp": 1585600279.2857664, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027106931433081627, "Value Loss": 6.546991698996862e-06, "_runtime": 2911.2063739299774, "_timestamp": 1585600280.8392434, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026328979060053825, "Value Loss": 6.176590432005469e-06, "_runtime": 2912.7496592998505, "_timestamp": 1585600282.3825288, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025571230798959732, "Value Loss": 5.8261903177481145e-06, "_runtime": 2914.2926881313324, "_timestamp": 1585600283.9255576, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02484380081295967, "Value Loss": 5.499425697053084e-06, "_runtime": 2915.8361666202545, "_timestamp": 1585600285.469036, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024126466363668442, "Value Loss": 5.186434464121703e-06, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2917.3797125816345, "_timestamp": 1585600287.012582, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023429352790117264, "Value Loss": 4.891043317911681e-06, "_runtime": 2918.94171500206, "_timestamp": 1585600288.5745845, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022742338478565216, "Value Loss": 4.6084091991360765e-06, "_runtime": 2920.481508255005, "_timestamp": 1585600290.1143777, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02208562009036541, "Value Loss": 4.346105924923904e-06, "_runtime": 2922.0240075588226, "_timestamp": 1585600291.656877, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02143901214003563, "Value Loss": 4.095348685950739e-06, "_runtime": 2923.5642178058624, "_timestamp": 1585600293.1970873, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02081262692809105, "Value Loss": 3.8595326259383e-06, "_runtime": 2925.1185731887817, "_timestamp": 1585600294.7514427, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020196324214339256, "Value Loss": 3.634340600910946e-06, "_runtime": 2926.7055485248566, "_timestamp": 1585600296.338418, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01960022933781147, "Value Loss": 3.4229751690872945e-06, "_runtime": 2928.26008272171, "_timestamp": 1585600297.8929522, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01902434602379799, "Value Loss": 3.2247844501398504e-06, "_runtime": 2929.816616296768, "_timestamp": 1585600299.4494858, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018458573147654533, "Value Loss": 3.035828513020533e-06, "_runtime": 2931.3684334754944, "_timestamp": 1585600301.001303, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01791299507021904, "Value Loss": 2.8590216061274987e-06, "_runtime": 2932.9222757816315, "_timestamp": 1585600302.5551453, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017377525568008423, "Value Loss": 2.69064867097768e-06, "_runtime": 2934.4664125442505, "_timestamp": 1585600304.099282, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016852157190442085, "Value Loss": 2.530418214519159e-06, "_runtime": 2936.011517047882, "_timestamp": 1585600305.6443865, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016346998512744904, "Value Loss": 2.3809875528968405e-06, "_runtime": 2937.5642008781433, "_timestamp": 1585600307.1970704, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015862051397562027, "Value Loss": 2.241814172521117e-06, "_runtime": 2939.116582632065, "_timestamp": 1585600308.749452, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015377096831798553, "Value Loss": 2.1068301521154353e-06, "_runtime": 2940.6649255752563, "_timestamp": 1585600310.297795, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014912339858710766, "Value Loss": 1.9814035567833344e-06, "_runtime": 2942.2212193012238, "_timestamp": 1585600311.8540888, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014457701705396175, "Value Loss": 1.862427097876207e-06, "_runtime": 2943.7739510536194, "_timestamp": 1585600313.4068205, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0140232527628541, "Value Loss": 1.752181674419262e-06, "_runtime": 2945.3172178268433, "_timestamp": 1585600314.9500873, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013598923571407795, "Value Loss": 1.6477461031172425e-06, "_runtime": 2946.87175488472, "_timestamp": 1585600316.5046244, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01317459624260664, "Value Loss": 1.5465188880625647e-06, "_runtime": 2948.4486372470856, "_timestamp": 1585600318.0815067, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012770467437803745, "Value Loss": 1.4530960470438004e-06, "_runtime": 2950.0007693767548, "_timestamp": 1585600319.6336389, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012376437894999981, "Value Loss": 1.364810259474325e-06, "_runtime": 2951.5563957691193, "_timestamp": 1585600321.1892653, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01199251413345337, "Value Loss": 1.2814496130886255e-06, "_runtime": 2953.109887599945, "_timestamp": 1585600322.742757, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011628800071775913, "Value Loss": 1.2048989219692885e-06, "_runtime": 2954.650072813034, "_timestamp": 1585600324.2829423, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011265076696872711, "Value Loss": 1.130706436924811e-06, "_runtime": 2956.203953027725, "_timestamp": 1585600325.8368225, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010911470279097557, "Value Loss": 1.0608341654005926e-06, "_runtime": 2957.7579040527344, "_timestamp": 1585600327.3907735, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01056796032935381, "Value Loss": 9.950929324986646e-07, "_runtime": 2959.309651851654, "_timestamp": 1585600328.9425213, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010244657285511494, "Value Loss": 9.351390417577932e-07, "_runtime": 2960.8675303459167, "_timestamp": 1585600330.5003998, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009921351447701454, "Value Loss": 8.770477961661527e-07, "_runtime": 2962.4195082187653, "_timestamp": 1585600332.0523777, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009608153253793716, "Value Loss": 8.225474061873683e-07, "_runtime": 2963.9729080200195, "_timestamp": 1585600333.6057775, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009305058978497982, "Value Loss": 7.714704111094761e-07, "_runtime": 2965.5258412361145, "_timestamp": 1585600335.1587107, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009001964703202248, "Value Loss": 7.220302222776809e-07, "_runtime": 2967.070315361023, "_timestamp": 1585600336.7031848, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00871907640248537, "Value Loss": 6.773632321710465e-07, "_runtime": 2968.6224024295807, "_timestamp": 1585600338.255272, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00843618344515562, "Value Loss": 6.341221592265356e-07, "_runtime": 2970.1744995117188, "_timestamp": 1585600339.807369, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008173499256372452, "Value Loss": 5.952468882242101e-07, "_runtime": 2971.751588344574, "_timestamp": 1585600341.3844578, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007910816930234432, "Value Loss": 5.576013677455194e-07, "_runtime": 2973.308562040329, "_timestamp": 1585600342.9414315, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00764812808483839, "Value Loss": 5.211850861996936e-07, "_runtime": 2974.864385843277, "_timestamp": 1585600344.4972553, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007405654992908239, "Value Loss": 4.88661441977456e-07, "_runtime": 2976.4061045646667, "_timestamp": 1585600346.038974, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007163177710026503, "Value Loss": 4.571857630253362e-07, "_runtime": 2977.941929578781, "_timestamp": 1585600347.574799, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00693080248311162, "Value Loss": 4.2800459709724237e-07, "_runtime": 2979.482304573059, "_timestamp": 1585600349.115174, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006708533503115177, "Value Loss": 4.0099257603287697e-07, "_runtime": 2981.036489725113, "_timestamp": 1585600350.6693592, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00648626359179616, "Value Loss": 3.7486094583982776e-07, "_runtime": 2982.579320192337, "_timestamp": 1585600352.2121897, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006274093873798847, "Value Loss": 3.5073838944299496e-07, "_runtime": 2984.133756160736, "_timestamp": 1585600353.7666256, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0060720294713974, "Value Loss": 3.2851048104021174e-07, "_runtime": 2985.6856825351715, "_timestamp": 1585600355.318552, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0058699678629636765, "Value Loss": 3.070099978685903e-07, "_runtime": 2987.240090608597, "_timestamp": 1585600356.87296, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005678005050867796, "Value Loss": 2.872584161650593e-07, "_runtime": 2988.771803379059, "_timestamp": 1585600358.4046729, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005486042704433203, "Value Loss": 2.681636033230461e-07, "_runtime": 2990.3176510334015, "_timestamp": 1585600359.9505205, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005304188001900911, "Value Loss": 2.506794203327445e-07, "_runtime": 2991.870429754257, "_timestamp": 1585600361.5032992, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005122328642755747, "Value Loss": 2.337847604394483e-07, "_runtime": 2993.4246809482574, "_timestamp": 1585600363.0575504, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004950573667883873, "Value Loss": 2.1836964947397064e-07, "_runtime": 2995.001229286194, "_timestamp": 1585600364.6340988, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0047889212146401405, "Value Loss": 2.04341603193825e-07, "_runtime": 2996.555708169937, "_timestamp": 1585600366.1885777, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004627271555364132, "Value Loss": 1.907792182009871e-07, "_runtime": 2998.09934258461, "_timestamp": 1585600367.732212, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004465618636459112, "Value Loss": 1.7768249449545692e-07, "_runtime": 2999.641846895218, "_timestamp": 1585600369.2747164, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004314071498811245, "Value Loss": 1.658273163229751e-07, "_runtime": 3001.1946201324463, "_timestamp": 1585600370.8274896, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004172626417130232, "Value Loss": 1.5513165863012546e-07, "_runtime": 3002.750321865082, "_timestamp": 1585600372.3831913, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004031181801110506, "Value Loss": 1.4479248022780666e-07, "_runtime": 3004.2928166389465, "_timestamp": 1585600373.9256861, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0038897383492439985, "Value Loss": 1.34809866381147e-07, "_runtime": 3005.8338010311127, "_timestamp": 1585600375.4666705, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0037583939265459776, "Value Loss": 1.258595148101449e-07, "_runtime": 3007.388110399246, "_timestamp": 1585600377.02098, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0036270541604608297, "Value Loss": 1.1721659376462412e-07, "_runtime": 3008.9412043094635, "_timestamp": 1585600378.5740738, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003505813190713525, "Value Loss": 1.0951135465120387e-07, "_runtime": 3010.4825427532196, "_timestamp": 1585600380.1154122, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0033845752477645874, "Value Loss": 1.0206805001189423e-07, "_runtime": 3012.0262694358826, "_timestamp": 1585600381.659139, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0032633382361382246, "Value Loss": 9.488666563584047e-08, "_runtime": 3013.5804007053375, "_timestamp": 1585600383.2132702, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0031522007193416357, "Value Loss": 8.853385224938393e-08, "_runtime": 3015.1208741664886, "_timestamp": 1585600384.7537436, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0030410662293434143, "Value Loss": 8.240112236990171e-08, "_runtime": 3016.6632511615753, "_timestamp": 1585600386.2961206, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0029299326706677675, "Value Loss": 7.648847599739383e-08, "_runtime": 3018.2532308101654, "_timestamp": 1585600387.8861003, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0028288979083299637, "Value Loss": 7.130438461899757e-08, "_runtime": 3019.7854075431824, "_timestamp": 1585600389.418277, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0027278675697743893, "Value Loss": 6.630213533753704e-08, "_runtime": 3021.329984664917, "_timestamp": 1585600390.9628541, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026369388215243816, "Value Loss": 6.195568147404629e-08, "_runtime": 3022.8841876983643, "_timestamp": 1585600392.5170572, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0025460103061050177, "Value Loss": 5.7756551541388035e-08, "_runtime": 3024.4380733966827, "_timestamp": 1585600394.0709429, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0024550799280405045, "Value Loss": 5.370474553956228e-08, "_runtime": 3025.9912807941437, "_timestamp": 1585600395.6241503, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002364151179790497, "Value Loss": 4.980029189027846e-08, "_runtime": 3027.5421073436737, "_timestamp": 1585600397.1749768, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00228332681581378, "Value Loss": 4.645335138775408e-08, "_runtime": 3029.0852987766266, "_timestamp": 1585600398.7181683, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0021923978347331285, "Value Loss": 4.282718890635806e-08, "_runtime": 3030.6277329921722, "_timestamp": 1585600400.2606025, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002121675293892622, "Value Loss": 4.0108716348186135e-08, "_runtime": 3032.170049905777, "_timestamp": 1585600401.8029194, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002040848368778825, "Value Loss": 3.7111021811142564e-08, "_runtime": 3033.7237763404846, "_timestamp": 1585600403.3566458, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00197012722492218, "Value Loss": 3.458352892948824e-08, "_runtime": 3035.281837940216, "_timestamp": 1585600404.9147074, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018994034035131335, "Value Loss": 3.2145180739462376e-08, "_runtime": 3036.8352465629578, "_timestamp": 1585600406.468116, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018286816775798798, "Value Loss": 2.9795948819355544e-08, "_runtime": 3038.3868029117584, "_timestamp": 1585600408.0196724, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0017579600680619478, "Value Loss": 2.7535861590877175e-08, "_runtime": 3039.974393606186, "_timestamp": 1585600409.607263, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001697339117527008, "Value Loss": 2.5669578462839127e-08, "_runtime": 3041.527604341507, "_timestamp": 1585600411.1604738, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016367208445444703, "Value Loss": 2.386877895332873e-08, "_runtime": 3043.0702106952667, "_timestamp": 1585600412.7030802, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0015761003596708179, "Value Loss": 2.213346306234598e-08, "_runtime": 3044.6240508556366, "_timestamp": 1585600414.2569203, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0015154819702729583, "Value Loss": 2.0463630789890885e-08, "_runtime": 3046.168830871582, "_timestamp": 1585600415.8017004, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014548625331372023, "Value Loss": 1.885928213596344e-08, "_runtime": 3047.7118990421295, "_timestamp": 1585600417.3447685, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001404346665367484, "Value Loss": 1.757234002752739e-08, "_runtime": 3049.2551102638245, "_timestamp": 1585600418.8879797, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013538304483518004, "Value Loss": 1.63308868650347e-08, "_runtime": 3050.799528837204, "_timestamp": 1585600420.4323983, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001303314813412726, "Value Loss": 1.51349013322033e-08, "_runtime": 3052.3522646427155, "_timestamp": 1585600421.9851341, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012527985963970423, "Value Loss": 1.3984390534460545e-08, "_runtime": 3053.895252227783, "_timestamp": 1585600423.5281217, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012022815644741058, "Value Loss": 1.2879354471806437e-08, "_runtime": 3055.4480724334717, "_timestamp": 1585600425.080942, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011618691496551037, "Value Loss": 1.2028067430946976e-08, "_runtime": 3056.9999582767487, "_timestamp": 1585600426.6328278, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0011113537475466728, "Value Loss": 1.1004885891452432e-08, "_runtime": 3058.5535926818848, "_timestamp": 1585600428.1864622, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010709409834817052, "Value Loss": 1.0219082469120622e-08, "_runtime": 3060.107524871826, "_timestamp": 1585600429.7403944, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001030527870170772, "Value Loss": 9.462382877245545e-09, "_runtime": 3061.659453392029, "_timestamp": 1585600431.2923229, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009901148732751608, "Value Loss": 8.734787115827203e-09, "_runtime": 3063.2408154010773, "_timestamp": 1585600432.873685, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009497017017565668, "Value Loss": 8.036295184865594e-09, "_runtime": 3064.7866446971893, "_timestamp": 1585600434.4195142, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000919392507057637, "Value Loss": 7.531525625381619e-09, "_runtime": 3066.339624404907, "_timestamp": 1585600435.972494, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008789800340309739, "Value Loss": 6.883965397719294e-09, "_runtime": 3067.8832874298096, "_timestamp": 1585600437.516157, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000848669558763504, "Value Loss": 6.417394615709782e-09, "_runtime": 3069.428850889206, "_timestamp": 1585600439.0617204, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008183604222722352, "Value Loss": 5.967194738332182e-09, "_runtime": 3070.9806265830994, "_timestamp": 1585600440.613496, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000777947367168963, "Value Loss": 5.3923940868116915e-09, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3072.5370993614197, "_timestamp": 1585600442.1699688, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007476377068087459, "Value Loss": 4.980392986908555e-09, "_runtime": 3074.0911474227905, "_timestamp": 1585600443.724017, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0007173283956944942, "Value Loss": 4.584762791637331e-09, "_runtime": 3075.6328756809235, "_timestamp": 1585600445.2657452, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000697121664416045, "Value Loss": 4.330104275140911e-09, "_runtime": 3077.1858863830566, "_timestamp": 1585600446.8187559, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006668119458481669, "Value Loss": 3.961758920922875e-09, "_runtime": 3078.738269805908, "_timestamp": 1585600448.3711393, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006365025765262544, "Value Loss": 3.609784471336752e-09, "_runtime": 3080.2901599407196, "_timestamp": 1585600449.9230294, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006162960780784488, "Value Loss": 3.384229785297066e-09, "_runtime": 3081.8342554569244, "_timestamp": 1585600451.467125, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000585986184887588, "Value Loss": 3.0595401767641306e-09, "_runtime": 3083.3862278461456, "_timestamp": 1585600453.0190973, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005657800938934088, "Value Loss": 2.852175384759903e-09, "_runtime": 3084.9387516975403, "_timestamp": 1585600454.5716212, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005455734208226204, "Value Loss": 2.6520865503698587e-09, "_runtime": 3086.5196599960327, "_timestamp": 1585600456.1525295, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005253670969977975, "Value Loss": 2.459273673593998e-09, "_runtime": 3088.0758018493652, "_timestamp": 1585600457.7086713, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005051605403423309, "Value Loss": 2.2737367544323206e-09, "_runtime": 3089.629120349884, "_timestamp": 1585600459.2619898, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004849543038289994, "Value Loss": 2.0954757928848267e-09, "_runtime": 3091.1833832263947, "_timestamp": 1585600460.8162527, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004647476598620415, "Value Loss": 1.924490788951516e-09, "_runtime": 3092.725329875946, "_timestamp": 1585600462.3581994, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00044454142334870994, "Value Loss": 1.760781742632389e-09, "_runtime": 3094.2785954475403, "_timestamp": 1585600463.911465, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000424334779381752, "Value Loss": 1.6043486539274454e-09, "_runtime": 3095.8208870887756, "_timestamp": 1585600465.4537566, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004041285428684205, "Value Loss": 1.4551915228366852e-09, "_runtime": 3097.3672699928284, "_timestamp": 1585600467.0001395, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00039402508991770446, "Value Loss": 1.3833414413966238e-09, "_runtime": 3098.921661376953, "_timestamp": 1585600468.5545309, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00037381885340437293, "Value Loss": 1.2450982467271388e-09, "_runtime": 3100.4778027534485, "_timestamp": 1585600470.1106722, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00035361223854124546, "Value Loss": 1.114131009671837e-09, "_runtime": 3102.031378030777, "_timestamp": 1585600471.6642475, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0003435090184211731, "Value Loss": 1.051375875249505e-09, "_runtime": 3103.5844020843506, "_timestamp": 1585600473.2172716, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00033340597292408347, "Value Loss": 9.904397302307189e-10, "_runtime": 3105.139041662216, "_timestamp": 1585600474.7719111, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00031319964909926057, "Value Loss": 8.74024408403784e-10, "_runtime": 3106.6914660930634, "_timestamp": 1585600476.3243356, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00030309619614854455, "Value Loss": 8.185452315956354e-10, "_runtime": 3108.25204372406, "_timestamp": 1585600477.8849132, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000292993092443794, "Value Loss": 7.648850441910326e-10, "_runtime": 3109.842099428177, "_timestamp": 1585600479.474969, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002727867104113102, "Value Loss": 6.630216375924647e-10, "_runtime": 3111.3872921466827, "_timestamp": 1585600481.0201616, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00026268354849889874, "Value Loss": 6.148184183984995e-10, "_runtime": 3112.931194782257, "_timestamp": 1585600482.5640643, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00025258027017116547, "Value Loss": 5.684341886080801e-10, "_runtime": 3114.4850211143494, "_timestamp": 1585600484.1178906, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002424771519144997, "Value Loss": 5.238689482212067e-10, "_runtime": 3116.026201725006, "_timestamp": 1585600485.6590712, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023237382993102074, "Value Loss": 4.81122697237879e-10, "_runtime": 3117.5783591270447, "_timestamp": 1585600487.2112286, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00022227071167435497, "Value Loss": 4.4019543565809727e-10, "_runtime": 3119.1328060626984, "_timestamp": 1585600488.7656755, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000212167389690876, "Value Loss": 4.0108716348186135e-10, "_runtime": 3120.6764509677887, "_timestamp": 1585600490.3093204, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00020206427143421024, "Value Loss": 3.637978807091713e-10, "_runtime": 3122.2299609184265, "_timestamp": 1585600491.8628304, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00019196094945073128, "Value Loss": 3.283275873400271e-10, "_runtime": 3123.771738052368, "_timestamp": 1585600493.4046075, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00019196094945073128, "Value Loss": 3.283275873400271e-10, "_runtime": 3125.3250439167023, "_timestamp": 1585600494.9579134, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00018185781664215028, "Value Loss": 2.9467628337442875e-10, "_runtime": 3126.8789904117584, "_timestamp": 1585600496.51186, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00017175450921058655, "Value Loss": 2.6284396881237626e-10, "_runtime": 3128.4223034381866, "_timestamp": 1585600498.055173, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001616514491615817, "Value Loss": 2.3283064365386963e-10, "_runtime": 3129.9638442993164, "_timestamp": 1585600499.5967138, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00015154809807427227, "Value Loss": 2.0463630789890885e-10, "_runtime": 3131.5181810855865, "_timestamp": 1585600501.1510506, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00015154809807427227, "Value Loss": 2.0463630789890885e-10, "_runtime": 3133.1068980693817, "_timestamp": 1585600502.7397676, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001414450234733522, "Value Loss": 1.7826096154749393e-10, "_runtime": 3134.638104200363, "_timestamp": 1585600504.2709737, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001414450234733522, "Value Loss": 1.7826096154749393e-10, "_runtime": 3136.1906571388245, "_timestamp": 1585600505.8235266, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00013134177424944937, "Value Loss": 1.5370460459962487e-10, "_runtime": 3137.732943058014, "_timestamp": 1585600507.3658125, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00012123857595724985, "Value Loss": 1.3096723705530167e-10, "_runtime": 3139.2774550914764, "_timestamp": 1585600508.9103246, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00012123857595724985, "Value Loss": 1.3096723705530167e-10, "_runtime": 3140.831736803055, "_timestamp": 1585600510.4646063, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00011113535583717749, "Value Loss": 1.1004885891452432e-10, "_runtime": 3142.3873221874237, "_timestamp": 1585600512.0201917, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00011113535583717749, "Value Loss": 1.1004885891452432e-10, "_runtime": 3143.9310388565063, "_timestamp": 1585600513.5639083, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00010103213571710512, "Value Loss": 9.094947017729282e-11, "_runtime": 3145.4738187789917, "_timestamp": 1585600515.1066883, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00010103213571710512, "Value Loss": 9.094947017729282e-11, "_runtime": 3147.027777671814, "_timestamp": 1585600516.6606472, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 3148.58136343956, "_timestamp": 1585600518.214233, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 3150.139551639557, "_timestamp": 1585600519.7724211, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.082572458079085e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 3151.701314687729, "_timestamp": 1585600521.3341842, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.082572458079085e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 3153.258947134018, "_timestamp": 1585600522.8918166, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.082572458079085e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 3154.866155385971, "_timestamp": 1585600524.4990249, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.07225117366761e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 3156.4285480976105, "_timestamp": 1585600526.0614176, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.07225117366761e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 3157.982319831848, "_timestamp": 1585600527.6151893, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.07225117366761e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 3159.534249305725, "_timestamp": 1585600529.1671188, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3161.0832448005676, "_timestamp": 1585600530.7161143, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3162.6474647521973, "_timestamp": 1585600532.2803342, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3164.200399875641, "_timestamp": 1585600533.8332694, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3165.742712020874, "_timestamp": 1585600535.3755815, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3167.2936832904816, "_timestamp": 1585600536.9265528, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3168.854494571686, "_timestamp": 1585600538.487364, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3170.417390346527, "_timestamp": 1585600540.0502598, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3171.970754146576, "_timestamp": 1585600541.6036236, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3173.5218737125397, "_timestamp": 1585600543.1547432, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3175.0860583782196, "_timestamp": 1585600544.7189279, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3176.6399381160736, "_timestamp": 1585600546.2728076, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3178.2178661823273, "_timestamp": 1585600547.8507357, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3179.7787358760834, "_timestamp": 1585600549.4116054, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3181.3411848545074, "_timestamp": 1585600550.9740543, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3182.9025359153748, "_timestamp": 1585600552.5354054, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3184.4676291942596, "_timestamp": 1585600554.1004987, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3186.0298635959625, "_timestamp": 1585600555.662733, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3187.5902614593506, "_timestamp": 1585600557.223131, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3189.1310243606567, "_timestamp": 1585600558.7638938, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3190.696397781372, "_timestamp": 1585600560.3292673, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3192.2590227127075, "_timestamp": 1585600561.8918922, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3193.8098084926605, "_timestamp": 1585600563.442678, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3195.374230861664, "_timestamp": 1585600565.0071003, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3196.9344630241394, "_timestamp": 1585600566.5673325, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3198.4995834827423, "_timestamp": 1585600568.132453, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3200.062016248703, "_timestamp": 1585600569.6948857, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3201.6607065200806, "_timestamp": 1585600571.293576, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3203.224499464035, "_timestamp": 1585600572.857369, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3204.78387594223, "_timestamp": 1585600574.4167454, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3206.3528378009796, "_timestamp": 1585600575.9857073, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3207.917308330536, "_timestamp": 1585600577.5501778, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3209.4791090488434, "_timestamp": 1585600579.1119785, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3211.037061214447, "_timestamp": 1585600580.6699307, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3212.6022865772247, "_timestamp": 1585600582.235156, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3214.1621372699738, "_timestamp": 1585600583.7950068, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3215.7320861816406, "_timestamp": 1585600585.3649557, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3217.2947504520416, "_timestamp": 1585600586.92762, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3218.855528354645, "_timestamp": 1585600588.4883978, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3220.4156827926636, "_timestamp": 1585600590.0485523, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3221.984079837799, "_timestamp": 1585600591.6169493, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3223.5538759231567, "_timestamp": 1585600593.1867454, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3225.1608715057373, "_timestamp": 1585600594.793741, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3226.733043193817, "_timestamp": 1585600596.3659127, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3228.2945489883423, "_timestamp": 1585600597.9274185, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3228.2945489883423, "_timestamp": 1585600597.9274185, "_step": 499}
