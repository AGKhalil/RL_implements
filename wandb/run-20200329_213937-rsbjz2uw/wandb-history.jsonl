{"Episode reward": 67.34106496260266, "Episode length": 626, "Policy Loss": 0.055088404566049576, "Value Loss": 15.895049095153809, "_runtime": 8911.291274309158, "_timestamp": 1585517989.712004, "_step": 0}
{"Episode reward": 60.14004160915746, "Episode length": 411, "Policy Loss": -0.01757962815463543, "Value Loss": 66.62349700927734, "_runtime": 8912.77208018303, "_timestamp": 1585517991.1928098, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.338462233543396, "Value Loss": 24.49542808532715, "_runtime": 8914.354487419128, "_timestamp": 1585517992.775217, "_step": 2}
{"Episode reward": -99.88614387414474, "Episode length": 999, "Policy Loss": -77.1950912475586, "Value Loss": 6447.48681640625, "_runtime": 8915.870161056519, "_timestamp": 1585517994.2908907, "_step": 3}
{"Episode reward": -98.89577209210523, "Episode length": 999, "Policy Loss": -0.9630195498466492, "Value Loss": 114.97376251220703, "_runtime": 8916.986275196075, "_timestamp": 1585517995.4070048, "_step": 4}
{"Episode reward": 28.589854896060288, "Episode length": 731, "Policy Loss": 19.540931701660156, "Value Loss": 2657.298828125, "_runtime": 8918.549716711044, "_timestamp": 1585517996.9704463, "_step": 5}
{"Episode reward": -99.7910436564344, "Episode length": 999, "Policy Loss": -0.3793324828147888, "Value Loss": 17.501806259155273, "_runtime": 8920.091701507568, "_timestamp": 1585517998.5124311, "_step": 6}
{"Episode reward": -99.6230550921508, "Episode length": 999, "Policy Loss": -0.7411606907844543, "Value Loss": 1.0430853366851807, "_runtime": 8920.698843240738, "_timestamp": 1585517999.1195729, "_step": 7}
{"Episode reward": 61.69685026330381, "Episode length": 384, "Policy Loss": 1.2780741453170776, "Value Loss": 26.503793716430664, "_runtime": 8921.83733677864, "_timestamp": 1585518000.2580664, "_step": 8}
{"Episode reward": 26.991535235801592, "Episode length": 732, "Policy Loss": 0.5538057684898376, "Value Loss": 19.355209350585938, "_runtime": 8923.390791893005, "_timestamp": 1585518001.8115215, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4352239668369293, "Value Loss": 8.98908519744873, "_runtime": 8924.888802528381, "_timestamp": 1585518003.3095322, "_step": 10}
{"Episode reward": -99.78899579078285, "Episode length": 999, "Policy Loss": -1.474810242652893, "Value Loss": 32.817291259765625, "_runtime": 8925.160215377808, "_timestamp": 1585518003.580945, "_step": 11}
{"Episode reward": 86.23908158652488, "Episode length": 139, "Policy Loss": 3.1459429264068604, "Value Loss": 117.70296478271484, "_runtime": 8926.705736875534, "_timestamp": 1585518005.1264665, "_step": 12}
{"Episode reward": -99.81989016271987, "Episode length": 999, "Policy Loss": -0.1890430748462677, "Value Loss": 21.421947479248047, "_runtime": 8928.26178765297, "_timestamp": 1585518006.6825173, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6482368111610413, "Value Loss": 10.041131019592285, "_runtime": 8929.123154878616, "_timestamp": 1585518007.5438845, "_step": 14}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 1.2037171125411987, "Value Loss": 36.51697540283203, "_runtime": 8930.70483160019, "_timestamp": 1585518009.1255612, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9180616736412048, "Value Loss": 1.3288862705230713, "_runtime": 8932.274493694305, "_timestamp": 1585518010.6952233, "_step": 16}
{"Episode reward": -99.79689899235824, "Episode length": 999, "Policy Loss": 0.9951005578041077, "Value Loss": 3.380563259124756, "_runtime": 8933.398848772049, "_timestamp": 1585518011.8195784, "_step": 17}
{"Episode reward": 25.06367627745493, "Episode length": 750, "Policy Loss": 3.5994884967803955, "Value Loss": 38.54896926879883, "_runtime": 8934.788604021072, "_timestamp": 1585518013.2093337, "_step": 18}
{"Episode reward": 12.100000000000719, "Episode length": 879, "Policy Loss": 2.192791223526001, "Value Loss": 24.612241744995117, "_runtime": 8936.39512348175, "_timestamp": 1585518014.815853, "_step": 19}
{"Episode reward": -99.78577709272365, "Episode length": 999, "Policy Loss": 0.9159207344055176, "Value Loss": 0.7229940891265869, "_runtime": 8937.271061182022, "_timestamp": 1585518015.6917908, "_step": 20}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 2.434432029724121, "Value Loss": 27.951473236083984, "_runtime": 8938.379076004028, "_timestamp": 1585518016.7998056, "_step": 21}
{"Episode reward": 29.151535151898614, "Episode length": 709, "Policy Loss": 1.9778245687484741, "Value Loss": 20.674654006958008, "_runtime": 8939.948499441147, "_timestamp": 1585518018.369229, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9469289779663086, "Value Loss": 1.8412957191467285, "_runtime": 8941.477402687073, "_timestamp": 1585518019.8981323, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9156036972999573, "Value Loss": 1.9678584337234497, "_runtime": 8942.371309041977, "_timestamp": 1585518020.7920387, "_step": 24}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 1.7039823532104492, "Value Loss": 22.633140563964844, "_runtime": 8943.93631029129, "_timestamp": 1585518022.35704, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6612805724143982, "Value Loss": 0.3726128339767456, "_runtime": 8945.493738412857, "_timestamp": 1585518023.914468, "_step": 26}
{"Episode reward": -99.84395210891822, "Episode length": 999, "Policy Loss": 0.503079354763031, "Value Loss": 0.28825199604034424, "_runtime": 8947.03543138504, "_timestamp": 1585518025.456161, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04059772193431854, "Value Loss": 9.997633934020996, "_runtime": 8948.612234830856, "_timestamp": 1585518027.0329645, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26669299602508545, "Value Loss": 0.3127133548259735, "_runtime": 8949.92815375328, "_timestamp": 1585518028.3488834, "_step": 29}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": 0.7451961636543274, "Value Loss": 18.453168869018555, "_runtime": 8951.50472688675, "_timestamp": 1585518029.9254565, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005635845009237528, "Value Loss": 0.7068310379981995, "_runtime": 8953.092846632004, "_timestamp": 1585518031.5135763, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05439668148756027, "Value Loss": 0.6913360357284546, "_runtime": 8954.650086164474, "_timestamp": 1585518033.0708158, "_step": 32}
{"Episode reward": -99.8315171495066, "Episode length": 999, "Policy Loss": -0.0421350821852684, "Value Loss": 0.976511538028717, "_runtime": 8955.619044542313, "_timestamp": 1585518034.0397742, "_step": 33}
{"Episode reward": 39.999999999999424, "Episode length": 600, "Policy Loss": 0.6958616375923157, "Value Loss": 18.510818481445312, "_runtime": 8957.029358148575, "_timestamp": 1585518035.4500878, "_step": 34}
{"Episode reward": 11.026879964769662, "Episode length": 890, "Policy Loss": 0.5336517691612244, "Value Loss": 12.342329025268555, "_runtime": 8958.606838464737, "_timestamp": 1585518037.027568, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06382007896900177, "Value Loss": 0.16735009849071503, "_runtime": 8960.177171707153, "_timestamp": 1585518038.5979013, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07984140515327454, "Value Loss": 0.06764326989650726, "_runtime": 8961.15302491188, "_timestamp": 1585518039.5737545, "_step": 37}
{"Episode reward": 39.171543401479134, "Episode length": 609, "Policy Loss": 1.0141761302947998, "Value Loss": 16.072473526000977, "_runtime": 8962.729054927826, "_timestamp": 1585518041.1497846, "_step": 38}
{"Episode reward": -99.89685135483602, "Episode length": 999, "Policy Loss": -0.11125421524047852, "Value Loss": 0.13095884025096893, "_runtime": 8964.312222719193, "_timestamp": 1585518042.7329524, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07799587398767471, "Value Loss": 0.17437204718589783, "_runtime": 8965.721781015396, "_timestamp": 1585518044.1425107, "_step": 40}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": 0.742337703704834, "Value Loss": 11.454197883605957, "_runtime": 8966.348255634308, "_timestamp": 1585518044.7689853, "_step": 41}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 2.0371875762939453, "Value Loss": 25.78557014465332, "_runtime": 8966.831653356552, "_timestamp": 1585518045.252383, "_step": 42}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 2.647191286087036, "Value Loss": 34.5733642578125, "_runtime": 8968.220046758652, "_timestamp": 1585518046.6407764, "_step": 43}
{"Episode reward": 10.600000000000804, "Episode length": 894, "Policy Loss": 0.7056838870048523, "Value Loss": 11.36279010772705, "_runtime": 8969.735158920288, "_timestamp": 1585518048.1558886, "_step": 44}
{"Episode reward": -99.87059527784446, "Episode length": 999, "Policy Loss": -0.25294890999794006, "Value Loss": 0.12615805864334106, "_runtime": 8971.038370370865, "_timestamp": 1585518049.4591, "_step": 45}
{"Episode reward": 13.100000000000662, "Episode length": 869, "Policy Loss": 0.7153050899505615, "Value Loss": 11.692626953125, "_runtime": 8972.03164768219, "_timestamp": 1585518050.4523773, "_step": 46}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.8837581276893616, "Value Loss": 18.43996238708496, "_runtime": 8973.195026874542, "_timestamp": 1585518051.6157565, "_step": 47}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": 0.4420190751552582, "Value Loss": 13.54438304901123, "_runtime": 8974.734730482101, "_timestamp": 1585518053.1554601, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4614050090312958, "Value Loss": 0.12178510427474976, "_runtime": 8976.21491408348, "_timestamp": 1585518054.6356437, "_step": 49}
{"Episode reward": 4.596682906151969, "Episode length": 955, "Policy Loss": 0.2603423595428467, "Value Loss": 10.441160202026367, "_runtime": 8977.749881982803, "_timestamp": 1585518056.1706116, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5454326868057251, "Value Loss": 0.15124790370464325, "_runtime": 8978.864438056946, "_timestamp": 1585518057.2851677, "_step": 51}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.5118383765220642, "Value Loss": 14.103896141052246, "_runtime": 8980.437815666199, "_timestamp": 1585518058.8585453, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6428396701812744, "Value Loss": 0.22197064757347107, "_runtime": 8982.008640766144, "_timestamp": 1585518060.4293704, "_step": 53}
{"Episode reward": -99.827373129128, "Episode length": 999, "Policy Loss": -0.6569149494171143, "Value Loss": 0.2098516970872879, "_runtime": 8983.588277101517, "_timestamp": 1585518062.0090067, "_step": 54}
{"Episode reward": -99.84718173891166, "Episode length": 999, "Policy Loss": -0.651130735874176, "Value Loss": 0.17260167002677917, "_runtime": 8985.162648200989, "_timestamp": 1585518063.5833778, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6420097947120667, "Value Loss": 0.1699715256690979, "_runtime": 8985.821053504944, "_timestamp": 1585518064.2417831, "_step": 56}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.3250086307525635, "Value Loss": 25.107351303100586, "_runtime": 8987.270866394043, "_timestamp": 1585518065.691596, "_step": 57}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": 0.19399109482765198, "Value Loss": 10.820977210998535, "_runtime": 8988.119560718536, "_timestamp": 1585518066.5402904, "_step": 58}
{"Episode reward": 48.099691508709924, "Episode length": 520, "Policy Loss": 0.9146979451179504, "Value Loss": 18.990779876708984, "_runtime": 8989.639466762543, "_timestamp": 1585518068.0601964, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6578376889228821, "Value Loss": 0.0424635224044323, "_runtime": 8991.20661187172, "_timestamp": 1585518069.6273415, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6089931130409241, "Value Loss": 0.02780335769057274, "_runtime": 8992.739777088165, "_timestamp": 1585518071.1605067, "_step": 61}
{"Episode reward": -99.76192775964597, "Episode length": 999, "Policy Loss": -0.6317455768585205, "Value Loss": 0.06339465826749802, "_runtime": 8994.321134328842, "_timestamp": 1585518072.741864, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6558941602706909, "Value Loss": 0.054443005472421646, "_runtime": 8995.902462482452, "_timestamp": 1585518074.3231921, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6446194052696228, "Value Loss": 0.023511625826358795, "_runtime": 8996.802324295044, "_timestamp": 1585518075.223054, "_step": 64}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.8330093026161194, "Value Loss": 17.508533477783203, "_runtime": 8998.37719154358, "_timestamp": 1585518076.7979212, "_step": 65}
{"Episode reward": -99.80950794815877, "Episode length": 999, "Policy Loss": -0.6603890061378479, "Value Loss": 0.0609317347407341, "_runtime": 8999.960631608963, "_timestamp": 1585518078.3813612, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6645046472549438, "Value Loss": 0.05043803155422211, "_runtime": 9001.223532438278, "_timestamp": 1585518079.644262, "_step": 67}
{"Episode reward": 18.135561752319703, "Episode length": 819, "Policy Loss": 0.3637034595012665, "Value Loss": 11.842049598693848, "_runtime": 9002.790863513947, "_timestamp": 1585518081.2115932, "_step": 68}
{"Episode reward": -99.85403829216817, "Episode length": 999, "Policy Loss": -0.6379328370094299, "Value Loss": 0.015510322526097298, "_runtime": 9003.511182308197, "_timestamp": 1585518081.931912, "_step": 69}
{"Episode reward": 56.19905168255757, "Episode length": 439, "Policy Loss": 1.2059884071350098, "Value Loss": 22.35703468322754, "_runtime": 9005.069218873978, "_timestamp": 1585518083.4899485, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6562162041664124, "Value Loss": 0.08608156442642212, "_runtime": 9006.64791560173, "_timestamp": 1585518085.0686452, "_step": 71}
{"Episode reward": -99.82243280410627, "Episode length": 999, "Policy Loss": -0.6510053873062134, "Value Loss": 0.008858759887516499, "_runtime": 9007.359349489212, "_timestamp": 1585518085.7800791, "_step": 72}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.2409974336624146, "Value Loss": 22.448265075683594, "_runtime": 9008.088465929031, "_timestamp": 1585518086.5091956, "_step": 73}
{"Episode reward": 54.799999999999635, "Episode length": 452, "Policy Loss": 1.255699634552002, "Value Loss": 21.36211585998535, "_runtime": 9009.240489959717, "_timestamp": 1585518087.6612196, "_step": 74}
{"Episode reward": 26.999999999999872, "Episode length": 730, "Policy Loss": 0.42059099674224854, "Value Loss": 13.39941120147705, "_runtime": 9010.762405395508, "_timestamp": 1585518089.183135, "_step": 75}
{"Episode reward": -99.84196800142387, "Episode length": 999, "Policy Loss": -0.664476752281189, "Value Loss": 0.006282366346567869, "_runtime": 9012.286630630493, "_timestamp": 1585518090.7073603, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6685689687728882, "Value Loss": 0.006094819400459528, "_runtime": 9013.825214385986, "_timestamp": 1585518092.245944, "_step": 77}
{"Episode reward": -99.76193532496552, "Episode length": 999, "Policy Loss": -0.6740104556083679, "Value Loss": 0.006097568664699793, "_runtime": 9015.396069526672, "_timestamp": 1585518093.8167992, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6769756078720093, "Value Loss": 0.006272663362324238, "_runtime": 9016.27183508873, "_timestamp": 1585518094.6925647, "_step": 79}
{"Episode reward": 45.599999999999504, "Episode length": 544, "Policy Loss": 1.0861560106277466, "Value Loss": 17.873443603515625, "_runtime": 9017.847232580185, "_timestamp": 1585518096.2679622, "_step": 80}
{"Episode reward": -99.73680275082448, "Episode length": 999, "Policy Loss": -0.6673014163970947, "Value Loss": 0.006118666380643845, "_runtime": 9019.428039312363, "_timestamp": 1585518097.848769, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.672904908657074, "Value Loss": 0.007393419276922941, "_runtime": 9020.347904920578, "_timestamp": 1585518098.7686346, "_step": 82}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 0.9226152300834656, "Value Loss": 16.55457878112793, "_runtime": 9021.913204908371, "_timestamp": 1585518100.3339345, "_step": 83}
{"Episode reward": -99.82024560570576, "Episode length": 999, "Policy Loss": -0.6667290329933167, "Value Loss": 0.006022601388394833, "_runtime": 9023.495596408844, "_timestamp": 1585518101.916326, "_step": 84}
{"Episode reward": -99.75812895037095, "Episode length": 999, "Policy Loss": -0.6692180633544922, "Value Loss": 0.021641647443175316, "_runtime": 9025.038338422775, "_timestamp": 1585518103.459068, "_step": 85}
{"Episode reward": -99.81530651002983, "Episode length": 999, "Policy Loss": -0.6642207503318787, "Value Loss": 0.005867544561624527, "_runtime": 9026.619742393494, "_timestamp": 1585518105.040472, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6656469106674194, "Value Loss": 0.017814399674534798, "_runtime": 9028.194879293442, "_timestamp": 1585518106.615609, "_step": 87}
{"Episode reward": -99.80913527011732, "Episode length": 999, "Policy Loss": -0.6400027871131897, "Value Loss": 0.006257094442844391, "_runtime": 9029.761266231537, "_timestamp": 1585518108.1819959, "_step": 88}
{"Episode reward": -99.78574549108605, "Episode length": 999, "Policy Loss": -0.6524547338485718, "Value Loss": 0.017667541280388832, "_runtime": 9031.376232385635, "_timestamp": 1585518109.796962, "_step": 89}
{"Episode reward": -99.71888646632293, "Episode length": 999, "Policy Loss": -0.6350681185722351, "Value Loss": 0.00540239317342639, "_runtime": 9032.947653770447, "_timestamp": 1585518111.3683834, "_step": 90}
{"Episode reward": -99.866075147687, "Episode length": 999, "Policy Loss": -0.623454749584198, "Value Loss": 0.005249102599918842, "_runtime": 9034.058085680008, "_timestamp": 1585518112.4788153, "_step": 91}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.5438264608383179, "Value Loss": 13.950502395629883, "_runtime": 9035.638310670853, "_timestamp": 1585518114.0590403, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6034068465232849, "Value Loss": 0.005079352296888828, "_runtime": 9037.223380804062, "_timestamp": 1585518115.6441104, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6043605804443359, "Value Loss": 0.008483615703880787, "_runtime": 9038.78415799141, "_timestamp": 1585518117.2048876, "_step": 94}
{"Episode reward": -99.81523495651642, "Episode length": 999, "Policy Loss": -0.5842949748039246, "Value Loss": 0.012307056225836277, "_runtime": 9039.79418516159, "_timestamp": 1585518118.2149148, "_step": 95}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 0.744301974773407, "Value Loss": 15.174057960510254, "_runtime": 9041.357235193253, "_timestamp": 1585518119.7779648, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5648428797721863, "Value Loss": 0.004440694581717253, "_runtime": 9042.794028759003, "_timestamp": 1585518121.2147584, "_step": 97}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": 0.28526443243026733, "Value Loss": 10.525819778442383, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654, 0.0035114067140966654]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0035114067140966654, 0.0022073357831686735, 0.007926078513264656, 0.01364482194185257, 0.019363563507795334, 0.025082305073738098, 0.03080105036497116, 0.036519791930913925, 0.04223853349685669, 0.047957275062799454, 0.05367601662874222, 0.05939476191997528, 0.06511350721120834, 0.07083224505186081, 0.07655099034309387, 0.08226972818374634, 0.0879884734749794, 0.09370721876621246, 0.09942595660686493, 0.10514470189809799, 0.11086343973875046, 0.11658218502998352, 0.12230093032121658, 0.12801966071128845, 0.1337384134531021, 0.13945715129375458, 0.14517588913440704, 0.1508946269750595, 0.15661337971687317, 0.16233211755752563, 0.1680508553981781, 0.17376960813999176, 0.17948834598064423, 0.1852070838212967, 0.19092583656311035, 0.19664457440376282, 0.20236331224441528, 0.20808206498622894, 0.2138008028268814, 0.21951954066753387, 0.22523827850818634, 0.23095703125, 0.23667576909065247, 0.24239450693130493, 0.2481132596731186, 0.25383201241493225, 0.2595507502555847, 0.2652694880962372, 0.27098825573921204, 0.2767069935798645, 0.28242573142051697, 0.28814446926116943, 0.2938632071018219, 0.29958194494247437, 0.30530068278312683, 0.3110194504261017, 0.31673818826675415, 0.3224569261074066, 0.3281756639480591, 0.33389440178871155, 0.339613139629364, 0.34533190727233887, 0.35105064511299133, 0.3567693829536438, 0.36248812079429626]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.00016334332758560777, 0.00032668665517121553, 0.0004900299827568233, 0.0006533733103424311, 0.0008167166379280388, 0.0009800599655136466, 0.0011434033513069153, 0.0013067466206848621, 0.001470089890062809, 0.0016334332758560777, 0.0017967766616493464, 0.001960119931027293, 0.00212346320040524, 0.0022868067026138306, 0.0024501499719917774, 0.0026134932413697243, 0.002776836510747671, 0.002940179780125618, 0.0031035232823342085, 0.0032668665517121553, 0.003430209821090102, 0.0035935533232986927, 0.0037568965926766396, 0.003920239862054586, 0.004083583131432533, 0.00424692640081048, 0.004410269670188427, 0.004573613405227661, 0.004736956674605608, 0.004900299943983555, 0.005063643213361502, 0.0052269864827394485, 0.005390329752117395, 0.005553673021495342, 0.005717016290873289, 0.005880359560251236, 0.00604370329529047, 0.006207046564668417, 0.006370389834046364, 0.006533733103424311, 0.0066970763728022575, 0.006860419642180204, 0.007023762911558151, 0.007187106646597385, 0.007350449915975332, 0.007513793185353279, 0.007677136454731226, 0.007840479724109173, 0.008003823459148407, 0.008167166262865067, 0.0083305099979043, 0.00849385280162096, 0.008657196536660194, 0.008820539340376854, 0.008983883075416088, 0.009147226810455322, 0.009310569614171982, 0.009473913349211216, 0.009637256152927876, 0.00980059988796711, 0.00996394269168377, 0.010127286426723003, 0.010290629230439663, 0.010453972965478897]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 3.0, 13.0, 16.0, 10.0, 9.0, 12.0, 17.0, 15.0, 18.0, 36.0, 28.0, 33.0, 174.0, 10.0, 7.0, 2.0, 5.0, 8.0, 4.0, 0.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 1.0, 5.0, 0.0, 1.0, 2.0, 7.0, 1.0, 4.0, 4.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.012029575183987617, -0.011149671860039234, -0.010269769467413425, -0.009389866143465042, -0.008509963750839233, -0.00763006042689085, -0.006750157102942467, -0.005870254244655371, -0.004990351386368275, -0.004110448062419891, -0.0032305456697940826, -0.0023506423458456993, -0.001470739021897316, -0.0005908366292715073, 0.00028906669467687607, 0.0011689690873026848, 0.002048872411251068, 0.0029287757351994514, 0.0038086790591478348, 0.0046885814517736435, 0.005568483844399452, 0.00644838809967041, 0.007328290492296219, 0.008208192884922028, 0.009088097140192986, 0.009967999532818794, 0.010847901925444603, 0.011727804318070412, 0.01260770857334137, 0.013487610965967178, 0.014367513358592987, 0.015247417613863945, 0.016127320006489754, 0.017007222399115562, 0.01788712665438652, 0.01876702904701233, 0.019646933302283287, 0.020526835694909096, 0.021406738087534904, 0.022286640480160713, 0.023166542872786522, 0.02404644526541233, 0.024926351383328438, 0.025806253775954247, 0.026686156168580055, 0.027566058561205864, 0.028445960953831673, 0.02932586334645748, 0.03020576946437359, 0.031085671856999397, 0.031965576112270355, 0.032845474779605865, 0.03372538089752197, 0.03460527956485748, 0.03548518568277359, 0.0363650918006897, 0.03724499046802521, 0.038124896585941315, 0.039004795253276825, 0.03988470137119293, 0.04076460003852844, 0.04164450615644455, 0.04252441227436066, 0.04340431094169617, 0.044284217059612274]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.07123807817697525, -0.06707272678613663, -0.06290736794471741, -0.058742016553878784, -0.054576657712459564, -0.05041130632162094, -0.04624595120549202, -0.0420805960893631, -0.03791524097323418, -0.033749885857105255, -0.029584530740976334, -0.025419175624847412, -0.02125382423400879, -0.017088469117879868, -0.012923114001750946, -0.008757758885622025, -0.004592403769493103, -0.00042705237865448, 0.00373830646276474, 0.007903657853603363, 0.012069016695022583, 0.016234368085861206, 0.020399726927280426, 0.02456507831811905, 0.028730429708957672, 0.03289578855037689, 0.037061139941215515, 0.041226498782634735, 0.04539185017347336, 0.04955720901489258, 0.0537225604057312, 0.05788791924715042, 0.062053270637989044, 0.06621862202882767, 0.07038397341966629, 0.07454933971166611, 0.07871469110250473, 0.08288004249334335, 0.08704539388418198, 0.0912107601761818, 0.09537611156702042, 0.09954146295785904, 0.10370681434869766, 0.10787216573953629, 0.1120375320315361, 0.11620288342237473, 0.12036823481321335, 0.12453358620405197, 0.1286989450454712, 0.13286429643630981, 0.13702964782714844, 0.14119499921798706, 0.14536035060882568, 0.1495257318019867, 0.15369108319282532, 0.15785643458366394, 0.16202178597450256, 0.1661871373653412, 0.1703524887561798, 0.17451784014701843, 0.17868319153785706, 0.18284857273101807, 0.1870139241218567, 0.1911792755126953, 0.19534462690353394]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 8.0, 5.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.05204716697335243, -0.05028986558318138, -0.04853256419301033, -0.04677526280283928, -0.04501796141266823, -0.04326066002249718, -0.04150335490703583, -0.03974605351686478, -0.037988752126693726, -0.036231450736522675, -0.034474149346351624, -0.03271684795618057, -0.03095954656600952, -0.02920224517583847, -0.02744494378566742, -0.02568764239549637, -0.023930341005325317, -0.022173039615154266, -0.020415738224983215, -0.018658436834812164, -0.016901135444641113, -0.015143834054470062, -0.013386532664299011, -0.01162923127412796, -0.00987192615866661, -0.00811462476849556, -0.006357323378324509, -0.004600021988153458, -0.0028427205979824066, -0.0010854192078113556, 0.0006718821823596954, 0.0024291835725307465, 0.0041864849627017975, 0.0059437863528728485, 0.0077010877430438995, 0.00945838913321495, 0.011215690523386002, 0.012972991913557053, 0.014730293303728104, 0.016487594693899155, 0.018244896084070206, 0.020002197474241257, 0.021759498864412308, 0.02351680025458336, 0.02527410164475441, 0.02703140303492546, 0.028788704425096512, 0.030546005815267563, 0.03230331465601921, 0.03406061604619026, 0.03581791743636131, 0.037575218826532364, 0.039332520216703415, 0.041089821606874466, 0.04284712299704552, 0.04460442438721657, 0.04636172577738762, 0.04811902716755867, 0.04987632855772972, 0.05163362994790077, 0.05339093133807182, 0.055148232728242874, 0.056905534118413925, 0.058662835508584976, 0.06042013689875603]}, "_runtime": 9044.325549840927, "_timestamp": 1585518122.7462795, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5584273934364319, "Value Loss": 0.004326865542680025, "_runtime": 9045.381137132645, "_timestamp": 1585518123.8018668, "_step": 99}
{"Episode reward": 33.19999999999952, "Episode length": 668, "Policy Loss": 0.7084015011787415, "Value Loss": 14.558403968811035, "_runtime": 9045.996635913849, "_timestamp": 1585518124.4173656, "_step": 100}
{"Episode reward": 61.799999999999734, "Episode length": 382, "Policy Loss": 1.5321900844573975, "Value Loss": 25.283187866210938, "_runtime": 9047.556416273117, "_timestamp": 1585518125.977146, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5506731867790222, "Value Loss": 0.005392176099121571, "_runtime": 9048.502336740494, "_timestamp": 1585518126.9230664, "_step": 102}
{"Episode reward": 39.41343067847134, "Episode length": 607, "Policy Loss": 0.8205269575119019, "Value Loss": 15.699646949768066, "_runtime": 9050.00499033928, "_timestamp": 1585518128.42572, "_step": 103}
{"Episode reward": -99.86565905213216, "Episode length": 999, "Policy Loss": -0.587375283241272, "Value Loss": 0.1347278654575348, "_runtime": 9051.121332406998, "_timestamp": 1585518129.542062, "_step": 104}
{"Episode reward": 28.99999999999976, "Episode length": 710, "Policy Loss": 0.6458056569099426, "Value Loss": 13.592347145080566, "_runtime": 9052.653154373169, "_timestamp": 1585518131.073884, "_step": 105}
{"Episode reward": -99.83630533218245, "Episode length": 999, "Policy Loss": -0.5528266429901123, "Value Loss": 0.004099467769265175, "_runtime": 9054.206163406372, "_timestamp": 1585518132.626893, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5501502752304077, "Value Loss": 0.00412680534645915, "_runtime": 9055.781924009323, "_timestamp": 1585518134.2026536, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.551122784614563, "Value Loss": 0.0040675741620361805, "_runtime": 9057.262558221817, "_timestamp": 1585518135.6832879, "_step": 108}
{"Episode reward": 5.752931389120548, "Episode length": 943, "Policy Loss": 0.5340885519981384, "Value Loss": 10.039679527282715, "_runtime": 9058.825956821442, "_timestamp": 1585518137.2466865, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.541025698184967, "Value Loss": 0.004188140854239464, "_runtime": 9060.396054506302, "_timestamp": 1585518138.8167841, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5379570126533508, "Value Loss": 0.004413626156747341, "_runtime": 9061.959916353226, "_timestamp": 1585518140.380646, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5370644330978394, "Value Loss": 0.003900765674188733, "_runtime": 9062.764118432999, "_timestamp": 1585518141.184848, "_step": 112}
{"Episode reward": 49.799999999999564, "Episode length": 502, "Policy Loss": 1.0179567337036133, "Value Loss": 18.873321533203125, "_runtime": 9064.32308959961, "_timestamp": 1585518142.7438192, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5520175695419312, "Value Loss": 0.055632226169109344, "_runtime": 9065.83113527298, "_timestamp": 1585518144.251865, "_step": 114}
{"Episode reward": 3.3000000000012193, "Episode length": 967, "Policy Loss": 0.277850866317749, "Value Loss": 9.883566856384277, "_runtime": 9066.307622909546, "_timestamp": 1585518144.7283525, "_step": 115}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 2.0081419944763184, "Value Loss": 31.053037643432617, "_runtime": 9067.874392747879, "_timestamp": 1585518146.2951224, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.526756227016449, "Value Loss": 0.0038101524114608765, "_runtime": 9069.441577911377, "_timestamp": 1585518147.8623075, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5316480398178101, "Value Loss": 0.003848449792712927, "_runtime": 9069.774515390396, "_timestamp": 1585518148.195245, "_step": 118}
{"Episode reward": 79.69999999999999, "Episode length": 203, "Policy Loss": 3.9265635013580322, "Value Loss": 47.09484100341797, "_runtime": 9071.003521203995, "_timestamp": 1585518149.4242508, "_step": 119}
{"Episode reward": 21.800000000000168, "Episode length": 782, "Policy Loss": 0.48466870188713074, "Value Loss": 12.149813652038574, "_runtime": 9072.579023361206, "_timestamp": 1585518150.999753, "_step": 120}
{"Episode reward": -99.88512044548848, "Episode length": 999, "Policy Loss": -0.5564864873886108, "Value Loss": 0.004186299629509449, "_runtime": 9074.079213619232, "_timestamp": 1585518152.4999433, "_step": 121}
{"Episode reward": -99.87837285110588, "Episode length": 999, "Policy Loss": -0.5781536102294922, "Value Loss": 0.009701121598482132, "_runtime": 9075.605036020279, "_timestamp": 1585518154.0257657, "_step": 122}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": 0.26424795389175415, "Value Loss": 9.834745407104492, "_runtime": 9077.181675672531, "_timestamp": 1585518155.6024053, "_step": 123}
{"Episode reward": -99.85732626654068, "Episode length": 999, "Policy Loss": -0.5773058533668518, "Value Loss": 0.008235578425228596, "_runtime": 9077.99164223671, "_timestamp": 1585518156.4123719, "_step": 124}
{"Episode reward": 48.66474367082074, "Episode length": 515, "Policy Loss": 1.0669326782226562, "Value Loss": 18.36366844177246, "_runtime": 9079.592130422592, "_timestamp": 1585518158.01286, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6101682782173157, "Value Loss": 0.06508541107177734, "_runtime": 9080.209042549133, "_timestamp": 1585518158.6297722, "_step": 126}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.5173468589782715, "Value Loss": 25.518722534179688, "_runtime": 9081.72694683075, "_timestamp": 1585518160.1476765, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5903839468955994, "Value Loss": 0.004957086406648159, "_runtime": 9082.567356348038, "_timestamp": 1585518160.988086, "_step": 128}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 0.9224987626075745, "Value Loss": 18.19707679748535, "_runtime": 9084.071322441101, "_timestamp": 1585518162.492052, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6159433722496033, "Value Loss": 0.0051267752423882484, "_runtime": 9085.634384155273, "_timestamp": 1585518164.0551138, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6275709271430969, "Value Loss": 0.005220246501266956, "_runtime": 9086.290608882904, "_timestamp": 1585518164.7113385, "_step": 131}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 1.3296904563903809, "Value Loss": 22.925113677978516, "_runtime": 9087.813835144043, "_timestamp": 1585518166.2345648, "_step": 132}
{"Episode reward": 1.865150809289318, "Episode length": 982, "Policy Loss": 0.18330253660678864, "Value Loss": 9.66547966003418, "_runtime": 9089.070131778717, "_timestamp": 1585518167.4908614, "_step": 133}
{"Episode reward": 20.00000000000027, "Episode length": 800, "Policy Loss": 0.3757174015045166, "Value Loss": 11.610960960388184, "_runtime": 9090.576925754547, "_timestamp": 1585518168.9976554, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6420298218727112, "Value Loss": 0.005650704260915518, "_runtime": 9091.472624063492, "_timestamp": 1585518169.8933537, "_step": 135}
{"Episode reward": 43.39999999999947, "Episode length": 566, "Policy Loss": 0.7528941631317139, "Value Loss": 16.62604331970215, "_runtime": 9093.020740509033, "_timestamp": 1585518171.4414701, "_step": 136}
{"Episode reward": -99.87808673530678, "Episode length": 999, "Policy Loss": -0.6501114368438721, "Value Loss": 0.005848043132573366, "_runtime": 9094.576862335205, "_timestamp": 1585518172.997592, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6589543223381042, "Value Loss": 0.005919099319726229, "_runtime": 9096.09740638733, "_timestamp": 1585518174.518136, "_step": 138}
{"Episode reward": -99.7593571253107, "Episode length": 999, "Policy Loss": -0.659395158290863, "Value Loss": 0.0059449682012200356, "_runtime": 9096.847580432892, "_timestamp": 1585518175.26831, "_step": 139}
{"Episode reward": 53.36955659091434, "Episode length": 468, "Policy Loss": 1.3085476160049438, "Value Loss": 19.80301284790039, "_runtime": 9098.412774085999, "_timestamp": 1585518176.8335037, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6650823950767517, "Value Loss": 0.005999501328915358, "_runtime": 9099.973831892014, "_timestamp": 1585518178.3945615, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6662133932113647, "Value Loss": 0.006017734762281179, "_runtime": 9101.099735736847, "_timestamp": 1585518179.5204654, "_step": 142}
{"Episode reward": 25.699999999999946, "Episode length": 743, "Policy Loss": 0.4188315272331238, "Value Loss": 12.638778686523438, "_runtime": 9101.52017235756, "_timestamp": 1585518179.940902, "_step": 143}
{"Episode reward": 75.59999999999994, "Episode length": 244, "Policy Loss": 3.3647449016571045, "Value Loss": 38.858726501464844, "_runtime": 9102.623702764511, "_timestamp": 1585518181.0444324, "_step": 144}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.5647246837615967, "Value Loss": 13.87256145477295, "_runtime": 9104.164026021957, "_timestamp": 1585518182.5847557, "_step": 145}
{"Episode reward": -99.6988483671085, "Episode length": 999, "Policy Loss": -0.6813958287239075, "Value Loss": 0.006291719153523445, "_runtime": 9105.650041341782, "_timestamp": 1585518184.070771, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6899563670158386, "Value Loss": 0.006417963653802872, "_runtime": 9107.184600353241, "_timestamp": 1585518185.60533, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6859092116355896, "Value Loss": 0.006495518609881401, "_runtime": 9108.735186815262, "_timestamp": 1585518187.1559165, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6936994791030884, "Value Loss": 0.006504722870886326, "_runtime": 9110.269679546356, "_timestamp": 1585518188.6904092, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.69577956199646, "Value Loss": 0.006489351391792297, "_runtime": 9111.84193611145, "_timestamp": 1585518190.2626657, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6807400584220886, "Value Loss": 0.00645871926099062, "_runtime": 9113.308714866638, "_timestamp": 1585518191.7294445, "_step": 151}
{"Episode reward": 7.03400847427649, "Episode length": 931, "Policy Loss": 0.23265670239925385, "Value Loss": 10.793538093566895, "_runtime": 9114.861955404282, "_timestamp": 1585518193.282685, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6739112138748169, "Value Loss": 0.006304269190877676, "_runtime": 9116.432655096054, "_timestamp": 1585518194.8533847, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6692233681678772, "Value Loss": 0.006211373023688793, "_runtime": 9117.080211400986, "_timestamp": 1585518195.500941, "_step": 154}
{"Episode reward": 59.774091626610314, "Episode length": 403, "Policy Loss": 1.5975675582885742, "Value Loss": 22.97362518310547, "_runtime": 9118.380764722824, "_timestamp": 1585518196.8014944, "_step": 155}
{"Episode reward": 16.598948574066625, "Episode length": 835, "Policy Loss": 0.2901522219181061, "Value Loss": 11.191673278808594, "_runtime": 9119.949179172516, "_timestamp": 1585518198.3699088, "_step": 156}
{"Episode reward": -99.83293067365744, "Episode length": 999, "Policy Loss": -0.6651573777198792, "Value Loss": 0.006024692207574844, "_runtime": 9121.457072019577, "_timestamp": 1585518199.8778017, "_step": 157}
{"Episode reward": -99.85659843832114, "Episode length": 999, "Policy Loss": -0.665883481502533, "Value Loss": 0.005982526112347841, "_runtime": 9121.940999031067, "_timestamp": 1585518200.3617287, "_step": 158}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 2.045440912246704, "Value Loss": 32.124237060546875, "_runtime": 9123.499589443207, "_timestamp": 1585518201.920319, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6586887240409851, "Value Loss": 0.00596511410549283, "_runtime": 9124.01435136795, "_timestamp": 1585518202.435081, "_step": 160}
{"Episode reward": 69.29999999999984, "Episode length": 307, "Policy Loss": 1.8801064491271973, "Value Loss": 30.391639709472656, "_runtime": 9125.498138189316, "_timestamp": 1585518203.9188678, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6687194108963013, "Value Loss": 0.006093962583690882, "_runtime": 9126.154080152512, "_timestamp": 1585518204.5748098, "_step": 162}
{"Episode reward": 62.768489703163254, "Episode length": 373, "Policy Loss": 1.8221849203109741, "Value Loss": 25.196807861328125, "_runtime": 9127.267444372177, "_timestamp": 1585518205.688174, "_step": 163}
{"Episode reward": 25.99850092977279, "Episode length": 741, "Policy Loss": 0.4636335074901581, "Value Loss": 12.861763000488281, "_runtime": 9128.829280376434, "_timestamp": 1585518207.25001, "_step": 164}
{"Episode reward": -99.73631792217354, "Episode length": 999, "Policy Loss": -0.6948042511940002, "Value Loss": 0.006425701081752777, "_runtime": 9130.089473724365, "_timestamp": 1585518208.5102034, "_step": 165}
{"Episode reward": 16.700000000000458, "Episode length": 833, "Policy Loss": 0.2506348192691803, "Value Loss": 11.044102668762207, "_runtime": 9131.64053606987, "_timestamp": 1585518210.0612657, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.697250247001648, "Value Loss": 0.006655406206846237, "_runtime": 9133.203600406647, "_timestamp": 1585518211.62433, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.701252818107605, "Value Loss": 0.006714216899126768, "_runtime": 9134.019846439362, "_timestamp": 1585518212.440576, "_step": 168}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 0.8698294162750244, "Value Loss": 17.98857879638672, "_runtime": 9135.597030878067, "_timestamp": 1585518214.0177605, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7038882374763489, "Value Loss": 0.006791133899241686, "_runtime": 9137.171537160873, "_timestamp": 1585518215.5922668, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7015157341957092, "Value Loss": 0.006830234080553055, "_runtime": 9138.388693094254, "_timestamp": 1585518216.8094227, "_step": 171}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.2783496379852295, "Value Loss": 11.561250686645508, "_runtime": 9139.966916561127, "_timestamp": 1585518218.3876462, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7036760449409485, "Value Loss": 0.006787325255572796, "_runtime": 9141.53575372696, "_timestamp": 1585518219.9564834, "_step": 173}
{"Episode reward": -99.80413590073445, "Episode length": 999, "Policy Loss": -0.6990098357200623, "Value Loss": 0.006754884961992502, "_runtime": 9142.478546619415, "_timestamp": 1585518220.8992763, "_step": 174}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": 0.5392822623252869, "Value Loss": 15.363274574279785, "_runtime": 9144.034969329834, "_timestamp": 1585518222.455699, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6898936033248901, "Value Loss": 0.00666314922273159, "_runtime": 9145.615561246872, "_timestamp": 1585518224.036291, "_step": 176}
{"Episode reward": -99.82124633788924, "Episode length": 999, "Policy Loss": -0.6920965313911438, "Value Loss": 0.006576199550181627, "_runtime": 9146.017560720444, "_timestamp": 1585518224.4382904, "_step": 177}
{"Episode reward": 76.29999999999994, "Episode length": 237, "Policy Loss": 2.6125221252441406, "Value Loss": 39.57235336303711, "_runtime": 9147.588829994202, "_timestamp": 1585518226.0095596, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7014858722686768, "Value Loss": 0.008384425193071365, "_runtime": 9149.152818202972, "_timestamp": 1585518227.5735478, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6952841281890869, "Value Loss": 0.006571393925696611, "_runtime": 9150.695835590363, "_timestamp": 1585518229.1165652, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6936265230178833, "Value Loss": 0.006535745691508055, "_runtime": 9152.29081106186, "_timestamp": 1585518230.7115407, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6818763613700867, "Value Loss": 0.006528928875923157, "_runtime": 9152.917156457901, "_timestamp": 1585518231.337886, "_step": 182}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 1.5139002799987793, "Value Loss": 24.57917594909668, "_runtime": 9154.455035448074, "_timestamp": 1585518232.875765, "_step": 183}
{"Episode reward": -99.88620505928853, "Episode length": 999, "Policy Loss": -0.6866868138313293, "Value Loss": 0.006423438433557749, "_runtime": 9156.046843290329, "_timestamp": 1585518234.467573, "_step": 184}
{"Episode reward": -99.85390377379814, "Episode length": 999, "Policy Loss": -0.6868217587471008, "Value Loss": 0.00635710870847106, "_runtime": 9157.568000793457, "_timestamp": 1585518235.9887304, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6785429120063782, "Value Loss": 0.006322880275547504, "_runtime": 9159.136282444, "_timestamp": 1585518237.557012, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6758951544761658, "Value Loss": 0.006201278883963823, "_runtime": 9160.173557758331, "_timestamp": 1585518238.5942874, "_step": 187}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.5573709607124329, "Value Loss": 14.241482734680176, "_runtime": 9161.739954710007, "_timestamp": 1585518240.1606843, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6679167747497559, "Value Loss": 0.006005189847201109, "_runtime": 9162.390640974045, "_timestamp": 1585518240.8113706, "_step": 189}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.7992709875106812, "Value Loss": 23.636411666870117, "_runtime": 9163.957283973694, "_timestamp": 1585518242.3780136, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6543986797332764, "Value Loss": 0.006053607445210218, "_runtime": 9164.950017929077, "_timestamp": 1585518243.3707476, "_step": 191}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.6000952124595642, "Value Loss": 14.32137393951416, "_runtime": 9165.690851449966, "_timestamp": 1585518244.111581, "_step": 192}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 0.915989875793457, "Value Loss": 18.94647979736328, "_runtime": 9167.245814323425, "_timestamp": 1585518245.666544, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6607871055603027, "Value Loss": 0.005870827008038759, "_runtime": 9168.770605564117, "_timestamp": 1585518247.1913352, "_step": 194}
{"Episode reward": -99.80076819062093, "Episode length": 999, "Policy Loss": -0.6576760411262512, "Value Loss": 0.0058794040232896805, "_runtime": 9169.182117938995, "_timestamp": 1585518247.6028476, "_step": 195}
{"Episode reward": 74.09999999999991, "Episode length": 259, "Policy Loss": 2.5761539936065674, "Value Loss": 36.85552215576172, "_runtime": 9170.08618426323, "_timestamp": 1585518248.506914, "_step": 196}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": 0.7613236308097839, "Value Loss": 15.683619499206543, "_runtime": 9171.645099163055, "_timestamp": 1585518250.0658288, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6904882788658142, "Value Loss": 0.020445257425308228, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261, 0.04448879510164261]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04448879510164261, 0.026166893541812897, 0.0968225821852684, 0.1674782633781433, 0.23813396692276, 0.3087896704673767, 0.379445344209671, 0.45010101795196533, 0.520756721496582, 0.5914124250411987, 0.6620681285858154, 0.7327237725257874, 0.803379476070404, 0.8740351796150208, 0.9446908235549927, 1.0153465270996094, 1.086002230644226, 1.1566579341888428, 1.2273136377334595, 1.2979693412780762, 1.3686250448226929, 1.43928062915802, 1.5099363327026367, 1.5805920362472534, 1.6512477397918701, 1.7219034433364868, 1.7925591468811035, 1.8632148504257202, 1.9338704347610474, 2.004526138305664, 2.075181722640991, 2.1458375453948975, 2.2164931297302246, 2.2871487140655518, 2.357804536819458, 2.428460121154785, 2.4991159439086914, 2.5697715282440186, 2.640427350997925, 2.711082935333252, 2.781738758087158, 2.8523943424224854, 2.9230499267578125, 2.9937057495117188, 3.064361333847046, 3.135017156600952, 3.2056727409362793, 3.2763285636901855, 3.3469841480255127, 3.41763973236084, 3.488295555114746, 3.5589511394500732, 3.6296069622039795, 3.7002625465393066, 3.770918369293213, 3.84157395362854, 3.912229537963867, 3.9828853607177734, 4.05354118347168, 4.124196529388428, 4.194852352142334, 4.26550817489624, 4.3361639976501465, 4.4068193435668945, 4.477475166320801]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0017426772974431515, 0.003485354594886303, 0.005228031892329454, 0.006970709189772606, 0.008713386952877045, 0.010456063784658909, 0.012198740616440773, 0.013941418379545212, 0.01568409614264965, 0.01742677390575409, 0.01916944980621338, 0.020912127569317818, 0.022654805332422256, 0.024397481232881546, 0.026140158995985985, 0.027882836759090424, 0.029625514522194862, 0.0313681922852993, 0.03311086818575859, 0.03485354781150818, 0.03659622371196747, 0.03833889961242676, 0.040081579238176346, 0.041824255138635635, 0.043566931039094925, 0.04530961066484451, 0.0470522865653038, 0.04879496246576309, 0.05053764209151268, 0.05228031799197197, 0.05402299761772156, 0.05576567351818085, 0.05750834941864014, 0.059251029044389725, 0.060993704944849014, 0.0627363845705986, 0.06447906047105789, 0.06622173637151718, 0.06796441227197647, 0.06970709562301636, 0.07144977152347565, 0.07319244742393494, 0.07493512332439423, 0.07667779922485352, 0.0784204751253128, 0.08016315847635269, 0.08190583437681198, 0.08364851027727127, 0.08539118617773056, 0.08713386207818985, 0.08887654542922974, 0.09061922132968903, 0.09236189723014832, 0.0941045731306076, 0.0958472490310669, 0.09758992493152618, 0.09933260828256607, 0.10107528418302536, 0.10281796008348465, 0.10456063598394394, 0.10630331188440323, 0.10804599523544312, 0.1097886711359024, 0.1115313470363617]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [10.0, 38.0, 79.0, 33.0, 13.0, 10.0, 36.0, 39.0, 27.0, 50.0, 65.0, 2.0, 0.0, 3.0, 0.0, 3.0, 3.0, 4.0, 3.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 6.0, 2.0, 3.0, 1.0, 5.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 6.0, 3.0, 1.0, 5.0, 4.0, 0.0, 3.0, 1.0, 8.0, 0.0, 6.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0], "bins": [-0.11026273667812347, -0.09933192282915115, -0.08840110898017883, -0.07747029513120651, -0.06653948128223419, -0.05560866743326187, -0.04467785358428955, -0.03374703973531723, -0.02281622588634491, -0.011885412037372589, -0.0009545981884002686, 0.009976215660572052, 0.020907029509544373, 0.031837835907936096, 0.042768657207489014, 0.05369947850704193, 0.06463028490543365, 0.07556109130382538, 0.0864919126033783, 0.09742273390293121, 0.10835354030132294, 0.11928434669971466, 0.13021516799926758, 0.1411459892988205, 0.15207679569721222, 0.16300760209560394, 0.17393840849399567, 0.18486924469470978, 0.1958000510931015, 0.20673085749149323, 0.21766169369220734, 0.22859250009059906, 0.23952330648899078, 0.2504541277885437, 0.26138490438461304, 0.27231574058532715, 0.28324657678604126, 0.2941773533821106, 0.3051081895828247, 0.3160390257835388, 0.32696980237960815, 0.33790063858032227, 0.3488314151763916, 0.3597622513771057, 0.3706930875778198, 0.38162386417388916, 0.39255470037460327, 0.4034854769706726, 0.4144163131713867, 0.42534714937210083, 0.43627792596817017, 0.4472087621688843, 0.4581395387649536, 0.4690703749656677, 0.48000121116638184, 0.49093198776245117, 0.5018628239631653, 0.5127936601638794, 0.5237244367599487, 0.5346552729606628, 0.545586109161377, 0.5565168857574463, 0.5674477219581604, 0.5783784985542297, 0.5893093347549438]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 6.0, 7.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0], "bins": [-1.1157702207565308, -1.0694143772125244, -1.0230586528778076, -0.9767028093338013, -0.9303470253944397, -0.8839912414550781, -0.8376354575157166, -0.791279673576355, -0.7449238300323486, -0.6985681056976318, -0.6522122621536255, -0.6058564782142639, -0.5595006942749023, -0.5131449103355408, -0.4667890667915344, -0.42043328285217285, -0.3740774989128113, -0.3277217149734497, -0.28136593103408813, -0.2350100874900818, -0.18865430355072021, -0.14229851961135864, -0.09594273567199707, -0.04958689212799072, -0.0032311677932739258, 0.04312467575073242, 0.08948040008544922, 0.13583624362945557, 0.18219208717346191, 0.2285478115081787, 0.27490365505218506, 0.32125937938690186, 0.3676152229309082, 0.41397106647491455, 0.46032679080963135, 0.5066826343536377, 0.5530383586883545, 0.5993942022323608, 0.6457500457763672, 0.692105770111084, 0.7384616136550903, 0.7848173379898071, 0.8311731815338135, 0.8775290250778198, 0.9238847494125366, 0.9702404737472534, 1.0165964365005493, 1.0629521608352661, 1.109307885169983, 1.1556638479232788, 1.2020195722579956, 1.2483752965927124, 1.2947310209274292, 1.341086983680725, 1.387442708015442, 1.4337984323501587, 1.4801543951034546, 1.5265101194381714, 1.5728658437728882, 1.619221806526184, 1.6655775308609009, 1.7119332551956177, 1.7582889795303345, 1.8046449422836304, 1.8510006666183472]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 2.0, 4.0, 2.0, 14.0, 13.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-1.5960843563079834, -1.5493296384811401, -1.5025748014450073, -1.455820083618164, -1.4090652465820312, -1.362310528755188, -1.3155558109283447, -1.268800973892212, -1.2220462560653687, -1.1752915382385254, -1.1285367012023926, -1.0817819833755493, -1.035027265548706, -0.9882724285125732, -0.94151771068573, -0.8947629332542419, -0.8480081558227539, -0.8012533783912659, -0.7544986009597778, -0.7077438831329346, -0.6609891057014465, -0.6142343282699585, -0.5674796104431152, -0.5207247734069824, -0.47397005558013916, -0.4272153377532959, -0.3804605007171631, -0.3337057828903198, -0.28695106506347656, -0.24019622802734375, -0.1934415102005005, -0.14668667316436768, -0.09993195533752441, -0.05317723751068115, -0.00642240047454834, 0.04033231735229492, 0.08708715438842773, 0.133841872215271, 0.18059659004211426, 0.22735142707824707, 0.27410614490509033, 0.3208608627319336, 0.3676156997680664, 0.4143705368041992, 0.46112513542175293, 0.5078799724578857, 0.5546348094940186, 0.6013894081115723, 0.6481442451477051, 0.6948990821838379, 0.7416536808013916, 0.7884085178375244, 0.8351633548736572, 0.8819179534912109, 0.9286727905273438, 0.9754276275634766, 1.0221822261810303, 1.068937063217163, 1.115691900253296, 1.1624467372894287, 1.2092013359069824, 1.2559561729431152, 1.302711009979248, 1.3494656085968018, 1.3962204456329346]}, "_runtime": 9172.566092252731, "_timestamp": 1585518250.986822, "_step": 198}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.7065829634666443, "Value Loss": 14.90780258178711, "_runtime": 9173.934710741043, "_timestamp": 1585518252.3554404, "_step": 199}
{"Episode reward": 12.377491971478577, "Episode length": 877, "Policy Loss": 0.2327488511800766, "Value Loss": 10.635405540466309, "_runtime": 9175.045540571213, "_timestamp": 1585518253.4662702, "_step": 200}
{"Episode reward": 28.59999999999978, "Episode length": 714, "Policy Loss": 0.5043420195579529, "Value Loss": 12.965388298034668, "_runtime": 9176.55969119072, "_timestamp": 1585518254.9804208, "_step": 201}
{"Episode reward": -99.87643437981465, "Episode length": 999, "Policy Loss": -0.6807834506034851, "Value Loss": 0.006521651986986399, "_runtime": 9178.10508275032, "_timestamp": 1585518256.5258124, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.700518012046814, "Value Loss": 0.006602047011256218, "_runtime": 9179.637633562088, "_timestamp": 1585518258.0583632, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6951567530632019, "Value Loss": 0.006636215373873711, "_runtime": 9181.189752578735, "_timestamp": 1585518259.6104822, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6952801942825317, "Value Loss": 0.006647349335253239, "_runtime": 9181.69671201706, "_timestamp": 1585518260.1174417, "_step": 205}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 1.899564266204834, "Value Loss": 30.421459197998047, "_runtime": 9183.26577758789, "_timestamp": 1585518261.6865072, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6996790766716003, "Value Loss": 0.00665824580937624, "_runtime": 9184.554190397263, "_timestamp": 1585518262.97492, "_step": 207}
{"Episode reward": 17.300000000000423, "Episode length": 827, "Policy Loss": 0.28692227602005005, "Value Loss": 10.716036796569824, "_runtime": 9186.053590774536, "_timestamp": 1585518264.4743204, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7012192010879517, "Value Loss": 0.0067290435545146465, "_runtime": 9186.823581933975, "_timestamp": 1585518265.2443116, "_step": 209}
{"Episode reward": 52.39948480129202, "Episode length": 477, "Policy Loss": 0.9708053469657898, "Value Loss": 19.51856231689453, "_runtime": 9188.381615161896, "_timestamp": 1585518266.8023448, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7064908742904663, "Value Loss": 0.006788230035454035, "_runtime": 9189.936094760895, "_timestamp": 1585518268.3568244, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7059703469276428, "Value Loss": 0.006789845414459705, "_runtime": 9191.291781663895, "_timestamp": 1585518269.7125113, "_step": 212}
{"Episode reward": 11.154100698233421, "Episode length": 889, "Policy Loss": 0.3082180619239807, "Value Loss": 10.27858829498291, "_runtime": 9192.445267915726, "_timestamp": 1585518270.8659976, "_step": 213}
{"Episode reward": 27.238783511146764, "Episode length": 728, "Policy Loss": 0.4675064980983734, "Value Loss": 12.239913940429688, "_runtime": 9193.590912818909, "_timestamp": 1585518272.0116425, "_step": 214}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.8242663741111755, "Value Loss": 12.38032054901123, "_runtime": 9195.102272510529, "_timestamp": 1585518273.5230021, "_step": 215}
{"Episode reward": 2.7859740972531455, "Episode length": 973, "Policy Loss": 0.0857992023229599, "Value Loss": 9.313241958618164, "_runtime": 9196.69116473198, "_timestamp": 1585518275.1118944, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7059816718101501, "Value Loss": 0.006817753426730633, "_runtime": 9198.22170305252, "_timestamp": 1585518276.6424327, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7070950269699097, "Value Loss": 0.006806158926337957, "_runtime": 9199.46044254303, "_timestamp": 1585518277.8811722, "_step": 218}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.40135934948921204, "Value Loss": 11.008769035339355, "_runtime": 9201.027276277542, "_timestamp": 1585518279.448006, "_step": 219}
{"Episode reward": 0.6049762707217354, "Episode length": 995, "Policy Loss": 0.05803341418504715, "Value Loss": 8.791565895080566, "_runtime": 9202.602376461029, "_timestamp": 1585518281.023106, "_step": 220}
{"Episode reward": -99.85557454973319, "Episode length": 999, "Policy Loss": -0.7123419046401978, "Value Loss": 0.006709343288093805, "_runtime": 9204.115140914917, "_timestamp": 1585518282.5358706, "_step": 221}
{"Episode reward": 3.0000000000012363, "Episode length": 970, "Policy Loss": 0.08736678957939148, "Value Loss": 9.27058219909668, "_runtime": 9205.694165945053, "_timestamp": 1585518284.1148956, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7045921683311462, "Value Loss": 0.006617129314690828, "_runtime": 9207.26945066452, "_timestamp": 1585518285.6901803, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6990261077880859, "Value Loss": 0.0065398626029491425, "_runtime": 9208.83527803421, "_timestamp": 1585518287.2560077, "_step": 224}
{"Episode reward": -99.7744895607219, "Episode length": 999, "Policy Loss": -0.691053032875061, "Value Loss": 0.006421210244297981, "_runtime": 9209.984263420105, "_timestamp": 1585518288.404993, "_step": 225}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.36050763726234436, "Value Loss": 12.138825416564941, "_runtime": 9211.502063035965, "_timestamp": 1585518289.9227927, "_step": 226}
{"Episode reward": 3.500000000001208, "Episode length": 965, "Policy Loss": 0.11462301015853882, "Value Loss": 9.47547435760498, "_runtime": 9212.374715566635, "_timestamp": 1585518290.7954452, "_step": 227}
{"Episode reward": 46.09999999999951, "Episode length": 539, "Policy Loss": 0.7630347609519958, "Value Loss": 16.385469436645508, "_runtime": 9213.922051906586, "_timestamp": 1585518292.3427815, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6744167804718018, "Value Loss": 0.006096270866692066, "_runtime": 9215.49715924263, "_timestamp": 1585518293.9178889, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6873961091041565, "Value Loss": 0.053177058696746826, "_runtime": 9216.579238414764, "_timestamp": 1585518294.999968, "_step": 230}
{"Episode reward": 30.219089156947717, "Episode length": 699, "Policy Loss": 0.4527260959148407, "Value Loss": 13.353551864624023, "_runtime": 9218.159777641296, "_timestamp": 1585518296.5805073, "_step": 231}
{"Episode reward": -99.82508552223304, "Episode length": 999, "Policy Loss": -0.6493747234344482, "Value Loss": 0.0058953771367669106, "_runtime": 9219.46823477745, "_timestamp": 1585518297.8889644, "_step": 232}
{"Episode reward": 17.300000000000423, "Episode length": 827, "Policy Loss": 0.24171213805675507, "Value Loss": 10.396629333496094, "_runtime": 9221.049780845642, "_timestamp": 1585518299.4705105, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6503564715385437, "Value Loss": 0.005745760165154934, "_runtime": 9222.631660699844, "_timestamp": 1585518301.0523903, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6369073390960693, "Value Loss": 0.005662098526954651, "_runtime": 9224.186997413635, "_timestamp": 1585518302.607727, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6423078775405884, "Value Loss": 0.005544534418731928, "_runtime": 9225.456445217133, "_timestamp": 1585518303.8771749, "_step": 236}
{"Episode reward": 19.700000000000287, "Episode length": 803, "Policy Loss": 0.4112285077571869, "Value Loss": 11.149590492248535, "_runtime": 9227.023917198181, "_timestamp": 1585518305.4446468, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6272953152656555, "Value Loss": 0.005310993641614914, "_runtime": 9228.604905605316, "_timestamp": 1585518307.0256352, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6183421015739441, "Value Loss": 0.005192336160689592, "_runtime": 9229.615941762924, "_timestamp": 1585518308.0366714, "_step": 239}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.6035208106040955, "Value Loss": 13.58608627319336, "_runtime": 9230.631831169128, "_timestamp": 1585518309.0525608, "_step": 240}
{"Episode reward": 35.99588393568929, "Episode length": 641, "Policy Loss": 0.6675669550895691, "Value Loss": 13.978466987609863, "_runtime": 9231.407038927078, "_timestamp": 1585518309.8277686, "_step": 241}
{"Episode reward": 52.3999999999996, "Episode length": 476, "Policy Loss": 1.0859862565994263, "Value Loss": 18.514863967895508, "_runtime": 9231.999058246613, "_timestamp": 1585518310.419788, "_step": 242}
{"Episode reward": 63.09999999999975, "Episode length": 369, "Policy Loss": 1.505768060684204, "Value Loss": 23.68552589416504, "_runtime": 9233.49975323677, "_timestamp": 1585518311.9204829, "_step": 243}
{"Episode reward": 2.096312962473732, "Episode length": 980, "Policy Loss": 0.14652606844902039, "Value Loss": 8.711771965026855, "_runtime": 9235.023272514343, "_timestamp": 1585518313.4440022, "_step": 244}
{"Episode reward": -99.83809204101422, "Episode length": 999, "Policy Loss": -0.6122658252716064, "Value Loss": 0.00510733388364315, "_runtime": 9236.487804174423, "_timestamp": 1585518314.9085338, "_step": 245}
{"Episode reward": 2.7000000000012534, "Episode length": 973, "Policy Loss": 0.34452205896377563, "Value Loss": 8.682011604309082, "_runtime": 9238.055442094803, "_timestamp": 1585518316.4761717, "_step": 246}
{"Episode reward": -99.87812988906958, "Episode length": 999, "Policy Loss": -0.6223151087760925, "Value Loss": 0.005221013445407152, "_runtime": 9238.99867773056, "_timestamp": 1585518317.4194074, "_step": 247}
{"Episode reward": 40.9924964666361, "Episode length": 591, "Policy Loss": 0.5838384032249451, "Value Loss": 15.802724838256836, "_runtime": 9239.531193256378, "_timestamp": 1585518317.951923, "_step": 248}
{"Episode reward": 67.89999999999982, "Episode length": 321, "Policy Loss": 1.612159252166748, "Value Loss": 29.061609268188477, "_runtime": 9241.095183849335, "_timestamp": 1585518319.5159135, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6278195381164551, "Value Loss": 0.0054283225908875465, "_runtime": 9242.62981081009, "_timestamp": 1585518321.0505404, "_step": 250}
{"Episode reward": -99.8816428720937, "Episode length": 999, "Policy Loss": -0.6340848803520203, "Value Loss": 0.005517441313713789, "_runtime": 9244.174519062042, "_timestamp": 1585518322.5952487, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6379755139350891, "Value Loss": 0.005566971842199564, "_runtime": 9245.429240942001, "_timestamp": 1585518323.8499706, "_step": 252}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.3540442883968353, "Value Loss": 10.6893310546875, "_runtime": 9247.001246452332, "_timestamp": 1585518325.421976, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6361643075942993, "Value Loss": 0.005614501889795065, "_runtime": 9248.550406694412, "_timestamp": 1585518326.9711363, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6341489553451538, "Value Loss": 0.00560727808624506, "_runtime": 9249.319541454315, "_timestamp": 1585518327.740271, "_step": 255}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 1.0516562461853027, "Value Loss": 18.742279052734375, "_runtime": 9250.105983257294, "_timestamp": 1585518328.526713, "_step": 256}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": 1.1029921770095825, "Value Loss": 18.037214279174805, "_runtime": 9251.229486703873, "_timestamp": 1585518329.6502163, "_step": 257}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.5235916972160339, "Value Loss": 12.396629333496094, "_runtime": 9252.746982812881, "_timestamp": 1585518331.1677125, "_step": 258}
{"Episode reward": -99.84509240537741, "Episode length": 999, "Policy Loss": -0.6498738527297974, "Value Loss": 0.005734700243920088, "_runtime": 9254.24671626091, "_timestamp": 1585518332.667446, "_step": 259}
{"Episode reward": -99.80380516648152, "Episode length": 999, "Policy Loss": -0.649649441242218, "Value Loss": 0.0057859038934111595, "_runtime": 9255.283670663834, "_timestamp": 1585518333.7044003, "_step": 260}
{"Episode reward": 33.299999999999514, "Episode length": 667, "Policy Loss": 0.45591962337493896, "Value Loss": 13.216361999511719, "_runtime": 9256.837583780289, "_timestamp": 1585518335.2583134, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.658111035823822, "Value Loss": 0.005839385557919741, "_runtime": 9258.38425564766, "_timestamp": 1585518336.8049853, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6536241769790649, "Value Loss": 0.005834931042045355, "_runtime": 9259.90964436531, "_timestamp": 1585518338.330374, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6502951979637146, "Value Loss": 0.005802256986498833, "_runtime": 9261.461236476898, "_timestamp": 1585518339.881966, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6420928239822388, "Value Loss": 0.005731730256229639, "_runtime": 9262.253041267395, "_timestamp": 1585518340.673771, "_step": 265}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 0.9461770057678223, "Value Loss": 23.057132720947266, "_runtime": 9263.522967338562, "_timestamp": 1585518341.943697, "_step": 266}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": 0.4310188889503479, "Value Loss": 10.342201232910156, "_runtime": 9264.021846532822, "_timestamp": 1585518342.4425762, "_step": 267}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 2.0330708026885986, "Value Loss": 28.851215362548828, "_runtime": 9264.543160438538, "_timestamp": 1585518342.96389, "_step": 268}
{"Episode reward": 66.19999999999979, "Episode length": 338, "Policy Loss": 2.074958324432373, "Value Loss": 28.39511489868164, "_runtime": 9266.077712535858, "_timestamp": 1585518344.4984422, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6541794538497925, "Value Loss": 0.005834721494466066, "_runtime": 9266.533744096756, "_timestamp": 1585518344.9544737, "_step": 270}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 2.031445264816284, "Value Loss": 30.219837188720703, "_runtime": 9268.014805793762, "_timestamp": 1585518346.4355354, "_step": 271}
{"Episode reward": 2.4000000000012705, "Episode length": 976, "Policy Loss": 0.17317305505275726, "Value Loss": 9.800854682922363, "_runtime": 9269.126611232758, "_timestamp": 1585518347.5473409, "_step": 272}
{"Episode reward": 28.704055014904355, "Episode length": 714, "Policy Loss": 0.46624472737312317, "Value Loss": 13.875, "_runtime": 9270.617641448975, "_timestamp": 1585518349.038371, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6939149498939514, "Value Loss": 0.006676750257611275, "_runtime": 9272.159498691559, "_timestamp": 1585518350.5802283, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7087717056274414, "Value Loss": 0.006852747406810522, "_runtime": 9273.374438762665, "_timestamp": 1585518351.7951684, "_step": 275}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.325379878282547, "Value Loss": 11.913069725036621, "_runtime": 9274.896783351898, "_timestamp": 1585518353.317513, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7110604047775269, "Value Loss": 0.007126276381313801, "_runtime": 9276.452535152435, "_timestamp": 1585518354.8732648, "_step": 277}
{"Episode reward": -99.76526745417948, "Episode length": 999, "Policy Loss": -0.7196741700172424, "Value Loss": 0.007164161652326584, "_runtime": 9277.506843805313, "_timestamp": 1585518355.9275734, "_step": 278}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": 0.6072123050689697, "Value Loss": 12.507439613342285, "_runtime": 9278.329005241394, "_timestamp": 1585518356.7497349, "_step": 279}
{"Episode reward": 47.89999999999954, "Episode length": 521, "Policy Loss": 0.7483230829238892, "Value Loss": 17.10296058654785, "_runtime": 9279.094624042511, "_timestamp": 1585518357.5153537, "_step": 280}
{"Episode reward": 51.97983669899364, "Episode length": 481, "Policy Loss": 0.8380105495452881, "Value Loss": 18.351499557495117, "_runtime": 9280.622383594513, "_timestamp": 1585518359.0431132, "_step": 281}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": -0.09365122020244598, "Value Loss": 8.571002006530762, "_runtime": 9282.132584810257, "_timestamp": 1585518360.5533144, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7487045526504517, "Value Loss": 0.007625594735145569, "_runtime": 9283.501810789108, "_timestamp": 1585518361.9225404, "_step": 283}
{"Episode reward": 9.442609018088262, "Episode length": 906, "Policy Loss": 0.06355161964893341, "Value Loss": 9.990545272827148, "_runtime": 9284.262867689133, "_timestamp": 1585518362.6835973, "_step": 284}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 0.7885161638259888, "Value Loss": 18.746129989624023, "_runtime": 9285.80472612381, "_timestamp": 1585518364.2254558, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7597103118896484, "Value Loss": 0.007885596714913845, "_runtime": 9286.421062707901, "_timestamp": 1585518364.8417923, "_step": 286}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 1.2073297500610352, "Value Loss": 22.76629066467285, "_runtime": 9287.2609436512, "_timestamp": 1585518365.6816733, "_step": 287}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.534788191318512, "Value Loss": 15.380875587463379, "_runtime": 9288.460747241974, "_timestamp": 1585518366.8814769, "_step": 288}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 0.21434485912322998, "Value Loss": 11.506172180175781, "_runtime": 9289.952675580978, "_timestamp": 1585518368.3734052, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7917500138282776, "Value Loss": 0.00838699284940958, "_runtime": 9290.526038885117, "_timestamp": 1585518368.9467685, "_step": 290}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 1.4024544954299927, "Value Loss": 23.324045181274414, "_runtime": 9291.687983036041, "_timestamp": 1585518370.1087127, "_step": 291}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.05867357552051544, "Value Loss": 10.28139591217041, "_runtime": 9292.526435136795, "_timestamp": 1585518370.9471648, "_step": 292}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 0.6302059888839722, "Value Loss": 15.37302017211914, "_runtime": 9294.01356291771, "_timestamp": 1585518372.4342926, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8222130537033081, "Value Loss": 0.009032283909618855, "_runtime": 9295.285101175308, "_timestamp": 1585518373.7058308, "_step": 294}
{"Episode reward": 19.80000000000028, "Episode length": 802, "Policy Loss": 0.16845276951789856, "Value Loss": 11.008872032165527, "_runtime": 9296.797313928604, "_timestamp": 1585518375.2180436, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8285959959030151, "Value Loss": 0.009290208108723164, "_runtime": 9298.335773706436, "_timestamp": 1585518376.7565033, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8224230408668518, "Value Loss": 0.00934929121285677, "_runtime": 9299.881273508072, "_timestamp": 1585518378.3020031, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8297490477561951, "Value Loss": 0.009343704208731651, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968, -0.015092957764863968]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1285359859466553, -2.0884885787963867, -2.048441171646118, -2.0083937644958496, -1.9683462381362915, -1.9282987117767334, -1.8882513046264648, -1.8482038974761963, -1.8081563711166382, -1.7681089639663696, -1.7280614376068115, -1.688014030456543, -1.6479666233062744, -1.6079192161560059, -1.5678716897964478, -1.5278242826461792, -1.487776756286621, -1.4477293491363525, -1.407681941986084, -1.3676345348358154, -1.3275870084762573, -1.2875396013259888, -1.2474920749664307, -1.207444667816162, -1.1673972606658936, -1.1273497343063354, -1.087302327156067, -1.0472549200057983, -1.0072073936462402, -0.9671599864959717, -0.9271125793457031, -0.887065052986145, -0.8470176458358765, -0.8069702386856079, -0.7669227123260498, -0.7268753051757812, -0.6868278980255127, -0.6467803716659546, -0.606732964515686, -0.5666855573654175, -0.5266380310058594, -0.4865906238555908, -0.44654321670532227, -0.40649569034576416, -0.3664482831954956, -0.32640087604522705, -0.28635334968566895, -0.2463059425354004, -0.20625853538513184, -0.16621100902557373, -0.12616348266601562, -0.08611607551574707, -0.046068668365478516, -0.006021261215209961, 0.034026145935058594, 0.07407355308532715, 0.1141211986541748, 0.15416860580444336, 0.19421601295471191, 0.23426342010498047, 0.274310827255249, 0.3143582344055176, 0.35440587997436523, 0.3944532871246338, 0.43450069427490234]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.06924010068178177, -0.06741877645254135, -0.06559744477272034, -0.06377612054347992, -0.061954788863658905, -0.06013346463441849, -0.05831213295459747, -0.056490808725357056, -0.05466948077082634, -0.052848152816295624, -0.05102682486176491, -0.04920549690723419, -0.047384168952703476, -0.04556284099817276, -0.04374151676893234, -0.04192018508911133, -0.04009886085987091, -0.038277529180049896, -0.03645620495080948, -0.03463487699627876, -0.03281354904174805, -0.03099222108721733, -0.029170893132686615, -0.0273495651781559, -0.025528237223625183, -0.023706909269094467, -0.02188558131456375, -0.020064257085323334, -0.018242929130792618, -0.016421601176261902, -0.014600273221731186, -0.01277894526720047, -0.010957617312669754, -0.009136289358139038, -0.007314961403608322, -0.005493633449077606, -0.0036723092198371887, -0.0018509775400161743, -2.9653310775756836e-05, 0.0017916783690452576, 0.003613002598285675, 0.0054343342781066895, 0.007255658507347107, 0.009076982736587524, 0.010898314416408539, 0.012719638645648956, 0.01454097032546997, 0.016362294554710388, 0.018183626234531403, 0.02000495046377182, 0.021826282143592834, 0.023647606372833252, 0.025468938052654266, 0.027290262281894684, 0.0291115865111351, 0.030932918190956116, 0.03275424242019653, 0.03457557410001755, 0.036396898329257965, 0.03821823000907898, 0.0400395542383194, 0.04186088591814041, 0.04368221014738083, 0.04550354182720184, 0.04732486605644226]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 13.0, 28.0, 27.0, 84.0, 94.0, 50.0, 46.0, 64.0, 52.0, 19.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5415927767753601, -0.5275368094444275, -0.5134808421134949, -0.49942490458488464, -0.485368937253952, -0.4713129699230194, -0.4572570323944092, -0.44320106506347656, -0.42914509773254395, -0.41508913040161133, -0.4010331630706787, -0.3869772255420685, -0.37292125821113586, -0.35886529088020325, -0.344809353351593, -0.3307533860206604, -0.3166974186897278, -0.30264145135879517, -0.28858548402786255, -0.2745295464992523, -0.2604735791683197, -0.24641761183738708, -0.23236167430877686, -0.21830570697784424, -0.20424973964691162, -0.190193772315979, -0.1761378049850464, -0.16208186745643616, -0.14802590012550354, -0.13396993279457092, -0.1199139952659607, -0.10585802793502808, -0.09180206060409546, -0.07774609327316284, -0.06369012594223022, -0.049634188413619995, -0.03557819128036499, -0.02152228355407715, -0.007466316223144531, 0.006589651107788086, 0.020645618438720703, 0.03470158576965332, 0.04875755310058594, 0.06281352043151855, 0.0768694281578064, 0.09092539548873901, 0.10498136281967163, 0.11903733015060425, 0.13309329748153687, 0.14714926481246948, 0.1612052321434021, 0.17526119947433472, 0.18931716680526733, 0.20337307453155518, 0.2174290418624878, 0.2314850091934204, 0.24554097652435303, 0.25959694385528564, 0.27365291118621826, 0.2877088785171509, 0.3017647862434387, 0.31582075357437134, 0.32987672090530396, 0.3439326882362366, 0.3579886555671692]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 11.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.5465278625488281, -1.501959204673767, -1.457390546798706, -1.4128217697143555, -1.3682531118392944, -1.3236844539642334, -1.2791156768798828, -1.2345470190048218, -1.1899783611297607, -1.1454097032546997, -1.1008410453796387, -1.056272268295288, -1.011703610420227, -0.967134952545166, -0.9225662350654602, -0.8779975175857544, -0.8334288597106934, -0.7888602018356323, -0.7442914843559265, -0.6997227668762207, -0.6551541090011597, -0.6105854511260986, -0.5660167336463928, -0.521448016166687, -0.476879358291626, -0.43231070041656494, -0.3877420425415039, -0.3431732654571533, -0.2986046075820923, -0.25403594970703125, -0.20946717262268066, -0.16489851474761963, -0.1203298568725586, -0.07576119899749756, -0.031192541122436523, 0.013376235961914062, 0.0579448938369751, 0.10251355171203613, 0.14708232879638672, 0.19165098667144775, 0.2362196445465088, 0.2807883024215698, 0.32535696029663086, 0.36992573738098145, 0.4144943952560425, 0.4590630531311035, 0.5036318302154541, 0.5482003688812256, 0.5927691459655762, 0.6373379230499268, 0.6819064617156982, 0.7264752388000488, 0.7710437774658203, 0.8156125545501709, 0.8601813316345215, 0.904749870300293, 0.9493186473846436, 0.9938874244689941, 1.0384559631347656, 1.0830247402191162, 1.1275935173034668, 1.1721620559692383, 1.2167308330535889, 1.2612993717193604, 1.305868148803711]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 16.0, 12.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.2169950008392334, -2.1571755409240723, -2.0973563194274902, -2.037536859512329, -1.977717399597168, -1.9178980588912964, -1.8580787181854248, -1.7982592582702637, -1.738439917564392, -1.6786205768585205, -1.6188011169433594, -1.5589817762374878, -1.4991624355316162, -1.439342975616455, -1.3795236349105835, -1.319704294204712, -1.2598848342895508, -1.2000654935836792, -1.140246033668518, -1.0804266929626465, -1.0206072330474854, -0.9607878923416138, -0.9009685516357422, -0.841149091720581, -0.7813297510147095, -0.7215104103088379, -0.6616909503936768, -0.6018716096878052, -0.5420522689819336, -0.48223280906677246, -0.4224134683609009, -0.36259400844573975, -0.30277466773986816, -0.24295532703399658, -0.183135986328125, -0.12331652641296387, -0.06349706649780273, -0.003677845001220703, 0.05614161491394043, 0.11596107482910156, 0.1757805347442627, 0.23559975624084473, 0.29541921615600586, 0.355238676071167, 0.415057897567749, 0.47487735748291016, 0.5346968173980713, 0.5945160388946533, 0.6543354988098145, 0.7141549587249756, 0.7739741802215576, 0.8337936401367188, 0.8936131000518799, 0.9534323215484619, 1.013251781463623, 1.0730712413787842, 1.1328904628753662, 1.1927099227905273, 1.2525293827056885, 1.3123488426208496, 1.3721680641174316, 1.4319875240325928, 1.491806983947754, 1.551626205444336, 1.611445665359497]}, "_runtime": 9300.487382173538, "_timestamp": 1585518378.9081118, "_step": 298}
{"Episode reward": 62.58337188325797, "Episode length": 375, "Policy Loss": 0.9648865461349487, "Value Loss": 20.891342163085938, "_runtime": 9300.997394323349, "_timestamp": 1585518379.418124, "_step": 299}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 1.653799295425415, "Value Loss": 26.18736457824707, "_runtime": 9301.983661174774, "_timestamp": 1585518380.4043908, "_step": 300}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": 0.3236854374408722, "Value Loss": 12.712638854980469, "_runtime": 9303.502106666565, "_timestamp": 1585518381.9228363, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.838781476020813, "Value Loss": 0.00959212239831686, "_runtime": 9305.00649523735, "_timestamp": 1585518383.4272249, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8294917941093445, "Value Loss": 0.009656193666160107, "_runtime": 9306.543752670288, "_timestamp": 1585518384.9644823, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8460546135902405, "Value Loss": 0.009657856076955795, "_runtime": 9308.113055467606, "_timestamp": 1585518386.533785, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8423016667366028, "Value Loss": 0.009613962844014168, "_runtime": 9308.920875787735, "_timestamp": 1585518387.3416054, "_step": 305}
{"Episode reward": 49.59042417854027, "Episode length": 505, "Policy Loss": 0.6273322701454163, "Value Loss": 16.62630271911621, "_runtime": 9310.489948034286, "_timestamp": 1585518388.9106777, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8345266580581665, "Value Loss": 0.00944383256137371, "_runtime": 9312.072565555573, "_timestamp": 1585518390.4932952, "_step": 307}
{"Episode reward": -99.80000182539085, "Episode length": 999, "Policy Loss": -0.8281503319740295, "Value Loss": 0.009332839399576187, "_runtime": 9313.600077867508, "_timestamp": 1585518392.0208075, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8179786205291748, "Value Loss": 0.009190983138978481, "_runtime": 9315.182736873627, "_timestamp": 1585518393.6034665, "_step": 309}
{"Episode reward": -99.80285425186017, "Episode length": 999, "Policy Loss": -0.823472261428833, "Value Loss": 0.008988901972770691, "_runtime": 9316.643094062805, "_timestamp": 1585518395.0638237, "_step": 310}
{"Episode reward": 7.700000000000969, "Episode length": 923, "Policy Loss": 0.05228004977107048, "Value Loss": 10.608839988708496, "_runtime": 9317.131427764893, "_timestamp": 1585518395.5521574, "_step": 311}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 1.6548871994018555, "Value Loss": 26.76350975036621, "_runtime": 9318.110734701157, "_timestamp": 1585518396.5314643, "_step": 312}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": 0.3487780690193176, "Value Loss": 12.793745994567871, "_runtime": 9319.707086086273, "_timestamp": 1585518398.1278157, "_step": 313}
{"Episode reward": -99.88111429810384, "Episode length": 999, "Policy Loss": -0.7964451909065247, "Value Loss": 0.008471108041703701, "_runtime": 9321.213013887405, "_timestamp": 1585518399.6337435, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7855817079544067, "Value Loss": 0.008391648530960083, "_runtime": 9322.430027008057, "_timestamp": 1585518400.8507566, "_step": 315}
{"Episode reward": 21.5965843617918, "Episode length": 785, "Policy Loss": 0.26224231719970703, "Value Loss": 10.99845027923584, "_runtime": 9323.992603063583, "_timestamp": 1585518402.4133327, "_step": 316}
{"Episode reward": -99.84379847980897, "Episode length": 999, "Policy Loss": -0.7808760404586792, "Value Loss": 0.008160465396940708, "_runtime": 9324.606434106827, "_timestamp": 1585518403.0271637, "_step": 317}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 1.3647196292877197, "Value Loss": 23.87973403930664, "_runtime": 9326.144140481949, "_timestamp": 1585518404.56487, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7679179310798645, "Value Loss": 0.008002066984772682, "_runtime": 9327.712994098663, "_timestamp": 1585518406.1337237, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7639548778533936, "Value Loss": 0.007929783314466476, "_runtime": 9328.526329040527, "_timestamp": 1585518406.9470587, "_step": 320}
{"Episode reward": 46.84791784286451, "Episode length": 532, "Policy Loss": 0.6755451560020447, "Value Loss": 16.420473098754883, "_runtime": 9330.087125778198, "_timestamp": 1585518408.5078554, "_step": 321}
{"Episode reward": -99.80617697238782, "Episode length": 999, "Policy Loss": -0.7500609755516052, "Value Loss": 0.007741796318441629, "_runtime": 9331.647411108017, "_timestamp": 1585518410.0681407, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7453951239585876, "Value Loss": 0.007648021448403597, "_runtime": 9333.169897317886, "_timestamp": 1585518411.590627, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7445573210716248, "Value Loss": 0.007509042043238878, "_runtime": 9334.636371850967, "_timestamp": 1585518413.0571015, "_step": 324}
{"Episode reward": 7.000000000001009, "Episode length": 930, "Policy Loss": -0.057681649923324585, "Value Loss": 8.982280731201172, "_runtime": 9336.22105884552, "_timestamp": 1585518414.6417885, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7198468446731567, "Value Loss": 0.007187218405306339, "_runtime": 9337.79220533371, "_timestamp": 1585518416.212935, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7195388674736023, "Value Loss": 0.007003849372267723, "_runtime": 9339.364573001862, "_timestamp": 1585518417.7853026, "_step": 327}
{"Episode reward": -99.85876779556135, "Episode length": 999, "Policy Loss": -0.7135330438613892, "Value Loss": 0.006792751606553793, "_runtime": 9339.778741121292, "_timestamp": 1585518418.1994708, "_step": 328}
{"Episode reward": 77.39999999999995, "Episode length": 226, "Policy Loss": 3.0058040618896484, "Value Loss": 39.01398849487305, "_runtime": 9340.481970310211, "_timestamp": 1585518418.9027, "_step": 329}
{"Episode reward": 56.299999999999656, "Episode length": 437, "Policy Loss": 0.6456157565116882, "Value Loss": 17.336618423461914, "_runtime": 9341.22836279869, "_timestamp": 1585518419.6490924, "_step": 330}
{"Episode reward": 54.38543644091077, "Episode length": 457, "Policy Loss": 1.4792636632919312, "Value Loss": 19.334514617919922, "_runtime": 9341.839227199554, "_timestamp": 1585518420.2599568, "_step": 331}
{"Episode reward": 59.5999999999997, "Episode length": 404, "Policy Loss": 1.3511724472045898, "Value Loss": 19.5261173248291, "_runtime": 9342.795080423355, "_timestamp": 1585518421.21581, "_step": 332}
{"Episode reward": 37.6871900320047, "Episode length": 624, "Policy Loss": 0.5913423895835876, "Value Loss": 14.04876708984375, "_runtime": 9344.263823986053, "_timestamp": 1585518422.6845536, "_step": 333}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.12452217936515808, "Value Loss": 9.043498039245605, "_runtime": 9345.772230386734, "_timestamp": 1585518424.19296, "_step": 334}
{"Episode reward": -99.77765499353269, "Episode length": 999, "Policy Loss": -0.7205274105072021, "Value Loss": 0.007022792007774115, "_runtime": 9347.301548480988, "_timestamp": 1585518425.722278, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7246956825256348, "Value Loss": 0.007137674372643232, "_runtime": 9348.859469413757, "_timestamp": 1585518427.280199, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7284180521965027, "Value Loss": 0.007170387078076601, "_runtime": 9350.412011146545, "_timestamp": 1585518428.8327408, "_step": 337}
{"Episode reward": -99.82236347794392, "Episode length": 999, "Policy Loss": -0.728191077709198, "Value Loss": 0.007154848892241716, "_runtime": 9351.987895965576, "_timestamp": 1585518430.4086256, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.720338761806488, "Value Loss": 0.007109122816473246, "_runtime": 9353.568566322327, "_timestamp": 1585518431.989296, "_step": 339}
{"Episode reward": -99.80228012949088, "Episode length": 999, "Policy Loss": -0.7214964628219604, "Value Loss": 0.007010421250015497, "_runtime": 9355.098547935486, "_timestamp": 1585518433.5192776, "_step": 340}
{"Episode reward": 3.1000000000012307, "Episode length": 969, "Policy Loss": 0.005839447025209665, "Value Loss": 8.13199520111084, "_runtime": 9356.6765396595, "_timestamp": 1585518435.0972693, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6973581910133362, "Value Loss": 0.006781083066016436, "_runtime": 9358.261507511139, "_timestamp": 1585518436.6822371, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6977489590644836, "Value Loss": 0.00663771340623498, "_runtime": 9358.938294410706, "_timestamp": 1585518437.359024, "_step": 343}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": 1.126077651977539, "Value Loss": 21.539508819580078, "_runtime": 9360.518352746964, "_timestamp": 1585518438.9390824, "_step": 344}
{"Episode reward": -99.81203561425069, "Episode length": 999, "Policy Loss": -0.6897318363189697, "Value Loss": 0.006377832498401403, "_runtime": 9362.091441631317, "_timestamp": 1585518440.5121713, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6796192526817322, "Value Loss": 0.006267534103244543, "_runtime": 9363.610692977905, "_timestamp": 1585518442.0314226, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6708822846412659, "Value Loss": 0.006123797968029976, "_runtime": 9364.777982234955, "_timestamp": 1585518443.1987119, "_step": 347}
{"Episode reward": 27.072156259044874, "Episode length": 730, "Policy Loss": 0.3644368350505829, "Value Loss": 11.48355770111084, "_runtime": 9366.388550758362, "_timestamp": 1585518444.8092804, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6623654961585999, "Value Loss": 0.005832575727254152, "_runtime": 9367.944275140762, "_timestamp": 1585518446.3650048, "_step": 349}
{"Episode reward": -99.82833279557386, "Episode length": 999, "Policy Loss": -0.6451361179351807, "Value Loss": 0.00568304443731904, "_runtime": 9368.716585159302, "_timestamp": 1585518447.1373148, "_step": 350}
{"Episode reward": 51.59999999999959, "Episode length": 484, "Policy Loss": 0.9998487234115601, "Value Loss": 16.630037307739258, "_runtime": 9370.256806612015, "_timestamp": 1585518448.6775362, "_step": 351}
{"Episode reward": 2.374718450011102, "Episode length": 977, "Policy Loss": 0.14024226367473602, "Value Loss": 8.67636775970459, "_runtime": 9371.03841328621, "_timestamp": 1585518449.459143, "_step": 352}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 0.8092309236526489, "Value Loss": 16.155597686767578, "_runtime": 9372.56689119339, "_timestamp": 1585518450.9876208, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6230579614639282, "Value Loss": 0.0053308564238250256, "_runtime": 9374.116295337677, "_timestamp": 1585518452.537025, "_step": 354}
{"Episode reward": 1.7991906151188601, "Episode length": 983, "Policy Loss": 0.0841677263379097, "Value Loss": 8.12258529663086, "_runtime": 9375.640228271484, "_timestamp": 1585518454.060958, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6228538751602173, "Value Loss": 0.00524415448307991, "_runtime": 9377.203961610794, "_timestamp": 1585518455.6246912, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6250221729278564, "Value Loss": 0.005176842678338289, "_runtime": 9378.790600299835, "_timestamp": 1585518457.21133, "_step": 357}
{"Episode reward": -99.88905027843872, "Episode length": 999, "Policy Loss": -0.6081264019012451, "Value Loss": 0.005083249881863594, "_runtime": 9380.350153684616, "_timestamp": 1585518458.7708833, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6018823385238647, "Value Loss": 0.00496774772182107, "_runtime": 9380.857541561127, "_timestamp": 1585518459.2782712, "_step": 359}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 1.4688870906829834, "Value Loss": 27.48917579650879, "_runtime": 9382.415712356567, "_timestamp": 1585518460.836442, "_step": 360}
{"Episode reward": -99.65926893986622, "Episode length": 999, "Policy Loss": -0.5860013365745544, "Value Loss": 0.004774930886924267, "_runtime": 9383.982122659683, "_timestamp": 1585518462.4028523, "_step": 361}
{"Episode reward": -99.81113621750707, "Episode length": 999, "Policy Loss": -0.5914154648780823, "Value Loss": 0.004711942281574011, "_runtime": 9385.490626335144, "_timestamp": 1585518463.911356, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5842848420143127, "Value Loss": 0.004622321110218763, "_runtime": 9387.075336694717, "_timestamp": 1585518465.4960663, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5731495022773743, "Value Loss": 0.004510535858571529, "_runtime": 9388.655426979065, "_timestamp": 1585518467.0761566, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5738583207130432, "Value Loss": 0.004379294812679291, "_runtime": 9390.257784128189, "_timestamp": 1585518468.6785138, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5536964535713196, "Value Loss": 0.00423613702878356, "_runtime": 9391.852793455124, "_timestamp": 1585518470.273523, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5469783544540405, "Value Loss": 0.004081851802766323, "_runtime": 9393.43884921074, "_timestamp": 1585518471.8595788, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5337050557136536, "Value Loss": 0.003919514361768961, "_runtime": 9394.413598537445, "_timestamp": 1585518472.8343282, "_step": 368}
{"Episode reward": 38.99999999999941, "Episode length": 610, "Policy Loss": 1.0486608743667603, "Value Loss": 16.367324829101562, "_runtime": 9395.987419605255, "_timestamp": 1585518474.4081492, "_step": 369}
{"Episode reward": -99.81964593082526, "Episode length": 999, "Policy Loss": -0.5204538106918335, "Value Loss": 0.003639223985373974, "_runtime": 9397.569360256195, "_timestamp": 1585518475.99009, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5057163238525391, "Value Loss": 0.003523673629388213, "_runtime": 9399.106045484543, "_timestamp": 1585518477.5267751, "_step": 371}
{"Episode reward": -99.84836292415717, "Episode length": 999, "Policy Loss": -0.5024529695510864, "Value Loss": 0.003390744561329484, "_runtime": 9400.68815946579, "_timestamp": 1585518479.108889, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48556116223335266, "Value Loss": 0.0032590781338512897, "_runtime": 9401.677148342133, "_timestamp": 1585518480.097878, "_step": 373}
{"Episode reward": 38.3999999999994, "Episode length": 616, "Policy Loss": 0.9066072702407837, "Value Loss": 16.218791961669922, "_runtime": 9402.32076215744, "_timestamp": 1585518480.7414918, "_step": 374}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 2.1429359912872314, "Value Loss": 25.48515510559082, "_runtime": 9403.89246582985, "_timestamp": 1585518482.3131955, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4729774296283722, "Value Loss": 0.003027345985174179, "_runtime": 9404.534683704376, "_timestamp": 1585518482.9554133, "_step": 376}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 1.600176453590393, "Value Loss": 25.038190841674805, "_runtime": 9406.049120903015, "_timestamp": 1585518484.4698505, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47482040524482727, "Value Loss": 0.0030521403532475233, "_runtime": 9406.992498636246, "_timestamp": 1585518485.4132283, "_step": 378}
{"Episode reward": 41.499999999999446, "Episode length": 585, "Policy Loss": 0.9741840958595276, "Value Loss": 17.078136444091797, "_runtime": 9408.178036689758, "_timestamp": 1585518486.5987663, "_step": 379}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": 0.6510361433029175, "Value Loss": 12.792887687683105, "_runtime": 9409.732486009598, "_timestamp": 1585518488.1532156, "_step": 380}
{"Episode reward": -99.88385256267945, "Episode length": 999, "Policy Loss": -0.4884922504425049, "Value Loss": 0.0032238957937806845, "_runtime": 9411.275042533875, "_timestamp": 1585518489.6957722, "_step": 381}
{"Episode reward": -99.80064320713142, "Episode length": 999, "Policy Loss": -0.4872185289859772, "Value Loss": 0.0032799181062728167, "_runtime": 9412.680858135223, "_timestamp": 1585518491.1015878, "_step": 382}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": 0.46085894107818604, "Value Loss": 10.943599700927734, "_runtime": 9414.282889604568, "_timestamp": 1585518492.7036192, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49996617436408997, "Value Loss": 0.0033561475574970245, "_runtime": 9415.863599300385, "_timestamp": 1585518494.284329, "_step": 384}
{"Episode reward": -99.8930216923342, "Episode length": 999, "Policy Loss": -0.5026079416275024, "Value Loss": 0.0033751812297850847, "_runtime": 9416.873403549194, "_timestamp": 1585518495.2941332, "_step": 385}
{"Episode reward": 36.58835917562184, "Episode length": 635, "Policy Loss": 0.8581320643424988, "Value Loss": 15.733107566833496, "_runtime": 9418.446187496185, "_timestamp": 1585518496.8669171, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5036102533340454, "Value Loss": 0.003405780764296651, "_runtime": 9420.03216123581, "_timestamp": 1585518498.4528909, "_step": 387}
{"Episode reward": -99.8470141902552, "Episode length": 999, "Policy Loss": -0.4991184175014496, "Value Loss": 0.0034109053667634726, "_runtime": 9420.908257961273, "_timestamp": 1585518499.3289876, "_step": 388}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 1.0693707466125488, "Value Loss": 17.871742248535156, "_runtime": 9422.293335437775, "_timestamp": 1585518500.714065, "_step": 389}
{"Episode reward": 12.000000000000725, "Episode length": 880, "Policy Loss": 0.47311320900917053, "Value Loss": 11.353836059570312, "_runtime": 9423.876366138458, "_timestamp": 1585518502.2970958, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5101920366287231, "Value Loss": 0.003483549691736698, "_runtime": 9424.890164613724, "_timestamp": 1585518503.3108943, "_step": 391}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": 1.0182610750198364, "Value Loss": 15.369929313659668, "_runtime": 9426.445683717728, "_timestamp": 1585518504.8664134, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.508403480052948, "Value Loss": 0.003565083723515272, "_runtime": 9428.017632484436, "_timestamp": 1585518506.4383621, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5121517777442932, "Value Loss": 0.003594278357923031, "_runtime": 9429.556925296783, "_timestamp": 1585518507.977655, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5138481855392456, "Value Loss": 0.0035969498567283154, "_runtime": 9431.077954292297, "_timestamp": 1585518509.498684, "_step": 395}
{"Episode reward": 3.1176496922982153, "Episode length": 969, "Policy Loss": 0.4069642126560211, "Value Loss": 10.311168670654297, "_runtime": 9432.665038347244, "_timestamp": 1585518511.085768, "_step": 396}
{"Episode reward": -99.84907009340684, "Episode length": 999, "Policy Loss": -0.5102231502532959, "Value Loss": 0.0035762961488217115, "_runtime": 9434.229394197464, "_timestamp": 1585518512.6501238, "_step": 397}
{"Episode reward": -99.81295357532659, "Episode length": 999, "Policy Loss": -0.5106164216995239, "Value Loss": 0.0035437671467661858, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426, -0.0013104042736813426]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 6.0], "bins": [-0.1424570530653, -0.14021068811416626, -0.13796432316303253, -0.1357179582118988, -0.13347157835960388, -0.13122521340847015, -0.12897884845733643, -0.1267324835062027, -0.12448611855506897, -0.12223975360393524, -0.11999338865280151, -0.11774701625108719, -0.11550065129995346, -0.11325428634881973, -0.11100791394710541, -0.10876154899597168, -0.10651518404483795, -0.10426881909370422, -0.1020224541425705, -0.09977608174085617, -0.09752971678972244, -0.09528335183858871, -0.09303697943687439, -0.09079061448574066, -0.08854424953460693, -0.0862978845834732, -0.08405151963233948, -0.08180514723062515, -0.07955878227949142, -0.0773124173283577, -0.07506604492664337, -0.07281967997550964, -0.07057331502437592, -0.06832695007324219, -0.06608058512210846, -0.06383421272039413, -0.061587847769260406, -0.05934148281812668, -0.057095110416412354, -0.054848745465278625, -0.0526023805141449, -0.05035601556301117, -0.04810965061187744, -0.045863278210163116, -0.04361691325902939, -0.04137054830789566, -0.039124175906181335, -0.03687781095504761, -0.03463144600391388, -0.03238508105278015, -0.030138716101646423, -0.0278923436999321, -0.02564597874879837, -0.023399613797664642, -0.021153241395950317, -0.01890687644481659, -0.01666051149368286, -0.014414146542549133, -0.012167781591415405, -0.009921416640281677, -0.007675036787986755, -0.005428671836853027, -0.0031823068857192993, -0.0009359419345855713, 0.0013104230165481567]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0], "bins": [-0.003901515621691942, -0.003840553807094693, -0.003779591992497444, -0.0037186304107308388, -0.0036576685961335897, -0.0035967067815363407, -0.0035357449669390917, -0.0034747831523418427, -0.0034138215705752373, -0.0033528597559779882, -0.003291897941380739, -0.00323093612678349, -0.003169974312186241, -0.0031090127304196358, -0.003048050682991743, -0.0029870891012251377, -0.0029261272866278887, -0.0028651654720306396, -0.0028042038902640343, -0.0027432418428361416, -0.002682280261069536, -0.002621318446472287, -0.002560356631875038, -0.0024993950501084328, -0.00243843300268054, -0.0023774714209139347, -0.0023165096063166857, -0.0022555477917194366, -0.0021945859771221876, -0.0021336241625249386, -0.002072662580758333, -0.002011700766161084, -0.0019507389515638351, -0.0018897771369665861, -0.001828815322369337, -0.0017678537406027317, -0.0017068919260054827, -0.0016459301114082336, -0.0015849682968109846, -0.0015240064822137356, -0.0014630449004471302, -0.0014020830858498812, -0.0013411212712526321, -0.0012801594566553831, -0.001219197642058134, -0.001158235827460885, -0.0010972742456942797, -0.0010363124310970306, -0.0009753506164997816, -0.0009143888019025326, -0.0008534269873052835, -0.0007924654055386782, -0.0007315035909414291, -0.0006705417763441801, -0.0006095799617469311, -0.000548618147149682, -0.000487656332552433, -0.00042669475078582764, -0.0003657329361885786, -0.0003047711215913296, -0.00024380930699408054, -0.0001828474923968315, -0.00012188591063022614, -6.0924096032977104e-05, 3.771856427192688e-08]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 6.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 0.0, 0.0, 7.0, 216.0, 10.0, 0.0, 2.0, 5.0, 6.0, 5.0, 25.0, 30.0, 53.0, 31.0, 33.0], "bins": [-0.018229542300105095, -0.017884237691760063, -0.01753893308341503, -0.01719362847507, -0.016848325729370117, -0.016503021121025085, -0.016157716512680054, -0.015812411904335022, -0.01546710729598999, -0.015121802687644958, -0.014776499010622501, -0.01443119440227747, -0.014085890725255013, -0.01374058611690998, -0.013395281508564949, -0.013049976900219917, -0.012704672291874886, -0.012359368614852428, -0.012014064006507397, -0.01166876032948494, -0.011323455721139908, -0.010978151112794876, -0.010632846504449844, -0.010287541896104813, -0.009942238219082355, -0.009596933610737324, -0.009251629002392292, -0.008906325325369835, -0.008561020717024803, -0.008215716108679771, -0.00787041150033474, -0.0075251078233122826, -0.007179803214967251, -0.006834498606622219, -0.006489194929599762, -0.00614389032125473, -0.0057985857129096985, -0.005453281104564667, -0.00510797742754221, -0.004762672819197178, -0.004417368210852146, -0.004072064533829689, -0.0037267599254846573, -0.0033814553171396255, -0.003036150708794594, -0.0026908470317721367, -0.0023455414921045303, -0.002000238746404648, -0.001654934138059616, -0.0013096295297145844, -0.0009643249213695526, -0.0006190203130245209, -0.00027371570467948914, 7.15889036655426e-05, 0.0004168916493654251, 0.0007621962577104568, 0.0011075008660554886, 0.0014528054744005203, 0.001798110082745552, 0.002143414691090584, 0.0024887192994356155, 0.002834022045135498, 0.00317932665348053, 0.0035246312618255615, 0.0038699358701705933]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.07884250581264496, -0.07702253013849258, -0.07520254701375961, -0.07338257133960724, -0.07156259566545486, -0.0697426125407219, -0.06792263686656952, -0.06610266119241714, -0.06428267806768417, -0.0624627023935318, -0.06064272299408913, -0.058822743594646454, -0.05700276792049408, -0.05518278852105141, -0.053362809121608734, -0.05154283344745636, -0.04972285404801369, -0.047902874648571014, -0.04608289897441864, -0.04426291957497597, -0.042442940175533295, -0.04062296450138092, -0.03880298510193825, -0.036983005702495575, -0.0351630300283432, -0.03334305062890053, -0.031523071229457855, -0.029703091830015182, -0.027883116155862808, -0.026063136756420135, -0.024243157356977463, -0.02242318168282509, -0.020603202283382416, -0.018783222883939743, -0.01696324720978737, -0.015143267810344696, -0.013323292136192322, -0.01150330901145935, -0.009683333337306976, -0.007863357663154602, -0.006043374538421631, -0.004223398864269257, -0.0024034231901168823, -0.0005834400653839111, 0.0012365356087684631, 0.0030565112829208374, 0.004876494407653809, 0.006696470081806183, 0.008516445755958557, 0.010336428880691528, 0.012156404554843903, 0.013976387679576874, 0.015796363353729248, 0.017616339027881622, 0.019436322152614594, 0.021256297826766968, 0.023076273500919342, 0.024896256625652313, 0.026716232299804688, 0.028536207973957062, 0.030356191098690033, 0.03217616677284241, 0.03399614244699478, 0.03581612557172775, 0.03763610124588013]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 0.0, 5.0, 11.0, 4.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.009370456449687481, -0.0090019004419446, -0.008633345365524292, -0.00826478935778141, -0.007896233350038528, -0.007527678273618221, -0.0071591222658753395, -0.006790566723793745, -0.006422011181712151, -0.006053455639630556, -0.005684900097548962, -0.00531634408980608, -0.004947788547724485, -0.004579233005642891, -0.004210676997900009, -0.0038421214558184147, -0.0034735659137368202, -0.0031050103716552258, -0.0027364548295736313, -0.0023678988218307495, -0.001999343279749155, -0.0016307877376675606, -0.0012622317299246788, -0.0008936766535043716, -0.0005251206457614899, -0.0001565646380186081, 0.00021199043840169907, 0.0005805464461445808, 0.0009491024538874626, 0.0013176575303077698, 0.0016862135380506516, 0.0020547686144709587, 0.0024233246222138405, 0.0027918806299567223, 0.0031604357063770294, 0.003528991714119911, 0.0038975467905402184, 0.0042661027982831, 0.004634658806025982, 0.005003213882446289, 0.005371769890189171, 0.005740325897932053, 0.00610888097435236, 0.0064774369820952415, 0.006845992989838123, 0.007214548997581005, 0.007583103142678738, 0.00795165915042162, 0.008320215158164501, 0.008688771165907383, 0.009057327173650265, 0.009425881318747997, 0.009794437326490879, 0.01016299333423376, 0.010531549341976643, 0.010900105349719524, 0.011268661357462406, 0.011637215502560139, 0.01200577151030302, 0.012374327518045902, 0.012742883525788784, 0.013111439533531666, 0.013479993678629398, 0.01384854968637228, 0.014217105694115162]}, "_runtime": 9435.807784557343, "_timestamp": 1585518514.2285142, "_step": 398}
{"Episode reward": -99.86404688358168, "Episode length": 999, "Policy Loss": -0.5097437500953674, "Value Loss": 0.003499103942885995, "_runtime": 9437.430493593216, "_timestamp": 1585518515.8512232, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5069446563720703, "Value Loss": 0.0034377549309283495, "_runtime": 9439.010897636414, "_timestamp": 1585518517.4316273, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4985913634300232, "Value Loss": 0.0033576672431081533, "_runtime": 9440.433834314346, "_timestamp": 1585518518.854564, "_step": 401}
{"Episode reward": 9.79002729505386, "Episode length": 903, "Policy Loss": 0.5222833752632141, "Value Loss": 11.064835548400879, "_runtime": 9442.022564888, "_timestamp": 1585518520.4432945, "_step": 402}
{"Episode reward": -99.83004758097091, "Episode length": 999, "Policy Loss": -0.4857458770275116, "Value Loss": 0.0031991498544812202, "_runtime": 9442.778064250946, "_timestamp": 1585518521.198794, "_step": 403}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 1.4686022996902466, "Value Loss": 21.67084312438965, "_runtime": 9444.354474306107, "_timestamp": 1585518522.775204, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47713741660118103, "Value Loss": 0.0031153704039752483, "_runtime": 9445.942231416702, "_timestamp": 1585518524.362961, "_step": 405}
{"Episode reward": -99.8138799905763, "Episode length": 999, "Policy Loss": -0.47911784052848816, "Value Loss": 0.003085331292822957, "_runtime": 9447.470288276672, "_timestamp": 1585518525.891018, "_step": 406}
{"Episode reward": -99.83326504826407, "Episode length": 999, "Policy Loss": -0.476514995098114, "Value Loss": 0.0030351087916642427, "_runtime": 9449.049941301346, "_timestamp": 1585518527.470671, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47024357318878174, "Value Loss": 0.0029787898529320955, "_runtime": 9450.627350330353, "_timestamp": 1585518529.04808, "_step": 408}
{"Episode reward": -99.79192809015373, "Episode length": 999, "Policy Loss": -0.4639268219470978, "Value Loss": 0.00290144351311028, "_runtime": 9451.600115776062, "_timestamp": 1585518530.0208454, "_step": 409}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 2.1109917163848877, "Value Loss": 16.432748794555664, "_runtime": 9452.365432977676, "_timestamp": 1585518530.7861626, "_step": 410}
{"Episode reward": 53.19999999999961, "Episode length": 468, "Policy Loss": 1.4337871074676514, "Value Loss": 21.347797393798828, "_runtime": 9453.946460485458, "_timestamp": 1585518532.3671901, "_step": 411}
{"Episode reward": -99.80696516632894, "Episode length": 999, "Policy Loss": -0.45289796590805054, "Value Loss": 0.002805152675136924, "_runtime": 9455.499648809433, "_timestamp": 1585518533.9203784, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44877931475639343, "Value Loss": 0.0028113913722336292, "_runtime": 9457.026266336441, "_timestamp": 1585518535.446996, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4540450870990753, "Value Loss": 0.0027927968185395002, "_runtime": 9458.607508659363, "_timestamp": 1585518537.0282383, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4471307098865509, "Value Loss": 0.0027616526931524277, "_runtime": 9459.46618437767, "_timestamp": 1585518537.886914, "_step": 415}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 1.5261144638061523, "Value Loss": 18.744966506958008, "_runtime": 9459.988353729248, "_timestamp": 1585518538.4090834, "_step": 416}
{"Episode reward": 68.89999999999984, "Episode length": 311, "Policy Loss": 2.220249891281128, "Value Loss": 32.12356185913086, "_runtime": 9461.594912528992, "_timestamp": 1585518540.0156422, "_step": 417}
{"Episode reward": -99.87953887581685, "Episode length": 999, "Policy Loss": -0.453543484210968, "Value Loss": 0.002812042133882642, "_runtime": 9462.60392165184, "_timestamp": 1585518541.0246513, "_step": 418}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.8312114477157593, "Value Loss": 15.442268371582031, "_runtime": 9464.110554218292, "_timestamp": 1585518542.5312839, "_step": 419}
{"Episode reward": -99.8217102304087, "Episode length": 999, "Policy Loss": -0.4652825593948364, "Value Loss": 0.0029853780288249254, "_runtime": 9465.686744689941, "_timestamp": 1585518544.1074743, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.477218359708786, "Value Loss": 0.0030576379504054785, "_runtime": 9467.227632284164, "_timestamp": 1585518545.648362, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47561416029930115, "Value Loss": 0.003104067174717784, "_runtime": 9468.790457487106, "_timestamp": 1585518547.2111871, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4822142422199249, "Value Loss": 0.0031232181936502457, "_runtime": 9470.375329256058, "_timestamp": 1585518548.796059, "_step": 423}
{"Episode reward": -99.80911314636329, "Episode length": 999, "Policy Loss": -0.4750877618789673, "Value Loss": 0.003124580020084977, "_runtime": 9471.583519220352, "_timestamp": 1585518550.0042489, "_step": 424}
{"Episode reward": 23.30927158445128, "Episode length": 767, "Policy Loss": 0.651002824306488, "Value Loss": 13.026397705078125, "_runtime": 9473.117841959, "_timestamp": 1585518551.5385716, "_step": 425}
{"Episode reward": -99.79813383407752, "Episode length": 999, "Policy Loss": -0.47942638397216797, "Value Loss": 0.0031076164450496435, "_runtime": 9474.692214012146, "_timestamp": 1585518553.1129436, "_step": 426}
{"Episode reward": -99.8965512547628, "Episode length": 999, "Policy Loss": -0.4783385694026947, "Value Loss": 0.0031024739146232605, "_runtime": 9475.73829460144, "_timestamp": 1585518554.1590242, "_step": 427}
{"Episode reward": 33.391582422609886, "Episode length": 667, "Policy Loss": 0.8256187438964844, "Value Loss": 14.979105949401855, "_runtime": 9477.29516863823, "_timestamp": 1585518555.7158983, "_step": 428}
{"Episode reward": -99.85546540170768, "Episode length": 999, "Policy Loss": -0.4750444293022156, "Value Loss": 0.0030586514621973038, "_runtime": 9478.870992183685, "_timestamp": 1585518557.2917218, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4753952920436859, "Value Loss": 0.0030455656815320253, "_runtime": 9480.40357875824, "_timestamp": 1585518558.8243084, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47687143087387085, "Value Loss": 0.003010730491951108, "_runtime": 9480.919834852219, "_timestamp": 1585518559.3405645, "_step": 431}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": 2.773529052734375, "Value Loss": 32.970401763916016, "_runtime": 9482.479101419449, "_timestamp": 1585518560.899831, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47173216938972473, "Value Loss": 0.0030141850002110004, "_runtime": 9484.041627168655, "_timestamp": 1585518562.4623568, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4729613959789276, "Value Loss": 0.0030443992000073195, "_runtime": 9485.57548046112, "_timestamp": 1585518563.99621, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46713903546333313, "Value Loss": 0.0030506050679832697, "_runtime": 9486.463440656662, "_timestamp": 1585518564.8841703, "_step": 435}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 1.0744160413742065, "Value Loss": 18.06629753112793, "_runtime": 9488.01581120491, "_timestamp": 1585518566.4365408, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4740995764732361, "Value Loss": 0.0030687116086483, "_runtime": 9489.553361177444, "_timestamp": 1585518567.9740908, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4823479950428009, "Value Loss": 0.04350365698337555, "_runtime": 9490.90858078003, "_timestamp": 1585518569.3293104, "_step": 438}
{"Episode reward": 11.100000000000776, "Episode length": 889, "Policy Loss": 0.4880255162715912, "Value Loss": 11.239206314086914, "_runtime": 9492.479463815689, "_timestamp": 1585518570.9001935, "_step": 439}
{"Episode reward": -99.86836697794357, "Episode length": 999, "Policy Loss": -0.4722507894039154, "Value Loss": 0.00307399220764637, "_runtime": 9494.036687612534, "_timestamp": 1585518572.4574172, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4733162522315979, "Value Loss": 0.003065169556066394, "_runtime": 9494.954752206802, "_timestamp": 1585518573.3754818, "_step": 441}
{"Episode reward": 41.59999999999945, "Episode length": 584, "Policy Loss": 1.081552505493164, "Value Loss": 17.107460021972656, "_runtime": 9496.523621797562, "_timestamp": 1585518574.9443514, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4789150357246399, "Value Loss": 0.003049566177651286, "_runtime": 9497.760857343674, "_timestamp": 1585518576.181587, "_step": 443}
{"Episode reward": 20.85173889249586, "Episode length": 792, "Policy Loss": 0.6831544637680054, "Value Loss": 12.615368843078613, "_runtime": 9499.284074783325, "_timestamp": 1585518577.7048044, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4721173644065857, "Value Loss": 0.003063821466639638, "_runtime": 9500.617537021637, "_timestamp": 1585518579.0382667, "_step": 445}
{"Episode reward": 14.500000000000583, "Episode length": 855, "Policy Loss": 0.6842964887619019, "Value Loss": 11.686030387878418, "_runtime": 9502.151556491852, "_timestamp": 1585518580.5722861, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48018985986709595, "Value Loss": 0.0030825070571154356, "_runtime": 9503.70099401474, "_timestamp": 1585518582.1217237, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48089855909347534, "Value Loss": 0.0030807768926024437, "_runtime": 9505.248986244202, "_timestamp": 1585518583.669716, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47176089882850647, "Value Loss": 0.0030584344640374184, "_runtime": 9506.338048696518, "_timestamp": 1585518584.7587783, "_step": 449}
{"Episode reward": 30.099999999999696, "Episode length": 699, "Policy Loss": 1.093664288520813, "Value Loss": 14.293450355529785, "_runtime": 9507.688354730606, "_timestamp": 1585518586.1090844, "_step": 450}
{"Episode reward": 12.761666488648146, "Episode length": 873, "Policy Loss": 0.5076444745063782, "Value Loss": 11.445196151733398, "_runtime": 9508.465310573578, "_timestamp": 1585518586.8860402, "_step": 451}
{"Episode reward": 54.47176437228881, "Episode length": 456, "Policy Loss": 1.3984806537628174, "Value Loss": 21.908706665039062, "_runtime": 9509.997416973114, "_timestamp": 1585518588.4181466, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47952064871788025, "Value Loss": 0.0031115117017179728, "_runtime": 9510.977165222168, "_timestamp": 1585518589.3978949, "_step": 453}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 1.012833595275879, "Value Loss": 16.14007568359375, "_runtime": 9511.787180185318, "_timestamp": 1585518590.2079098, "_step": 454}
{"Episode reward": 47.099999999999525, "Episode length": 529, "Policy Loss": 1.115368366241455, "Value Loss": 18.88528823852539, "_runtime": 9513.33871459961, "_timestamp": 1585518591.7594442, "_step": 455}
{"Episode reward": -99.88887757211783, "Episode length": 999, "Policy Loss": -0.4953743815422058, "Value Loss": 0.0033778201323002577, "_runtime": 9514.865072011948, "_timestamp": 1585518593.2858016, "_step": 456}
{"Episode reward": -99.87605066299298, "Episode length": 999, "Policy Loss": -0.507083535194397, "Value Loss": 0.003472688840702176, "_runtime": 9515.691356658936, "_timestamp": 1585518594.1120863, "_step": 457}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": 1.057814598083496, "Value Loss": 18.67291831970215, "_runtime": 9517.232763767242, "_timestamp": 1585518595.6534934, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5200737714767456, "Value Loss": 0.0036493923980742693, "_runtime": 9518.791559457779, "_timestamp": 1585518597.212289, "_step": 459}
{"Episode reward": -99.80009842067817, "Episode length": 999, "Policy Loss": -0.5210211873054504, "Value Loss": 0.0037266246508806944, "_runtime": 9519.275456905365, "_timestamp": 1585518597.6961865, "_step": 460}
{"Episode reward": 70.01451877951607, "Episode length": 300, "Policy Loss": 2.318727731704712, "Value Loss": 33.29627990722656, "_runtime": 9520.824516534805, "_timestamp": 1585518599.2452462, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5347694754600525, "Value Loss": 0.0039214808493852615, "_runtime": 9522.352013587952, "_timestamp": 1585518600.7727432, "_step": 462}
{"Episode reward": 2.038036274538726, "Episode length": 980, "Policy Loss": 0.3179577589035034, "Value Loss": 10.195149421691895, "_runtime": 9523.839716911316, "_timestamp": 1585518602.2604465, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5499557256698608, "Value Loss": 0.004155208822339773, "_runtime": 9525.397374629974, "_timestamp": 1585518603.8181043, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5570170879364014, "Value Loss": 0.004236617125570774, "_runtime": 9526.213602781296, "_timestamp": 1585518604.6343324, "_step": 465}
{"Episode reward": 49.39743108600334, "Episode length": 507, "Policy Loss": 1.1336137056350708, "Value Loss": 19.70234489440918, "_runtime": 9526.589261054993, "_timestamp": 1585518605.0099907, "_step": 466}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": 3.409947395324707, "Value Loss": 46.67146301269531, "_runtime": 9527.823100090027, "_timestamp": 1585518606.2438297, "_step": 467}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.5006363987922668, "Value Loss": 12.550365447998047, "_runtime": 9528.653673410416, "_timestamp": 1585518607.074403, "_step": 468}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 1.2456004619598389, "Value Loss": 18.497451782226562, "_runtime": 9529.200661420822, "_timestamp": 1585518607.621391, "_step": 469}
{"Episode reward": 63.39999999999976, "Episode length": 366, "Policy Loss": 1.7058945894241333, "Value Loss": 27.28814125061035, "_runtime": 9530.714196443558, "_timestamp": 1585518609.134926, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6469531059265137, "Value Loss": 0.005622288677841425, "_runtime": 9532.26156926155, "_timestamp": 1585518610.682299, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6651929020881653, "Value Loss": 0.005945380311459303, "_runtime": 9533.583287715912, "_timestamp": 1585518612.0040174, "_step": 472}
{"Episode reward": 10.300000000000821, "Episode length": 897, "Policy Loss": 0.26629340648651123, "Value Loss": 11.136916160583496, "_runtime": 9535.13829088211, "_timestamp": 1585518613.5590205, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.686717689037323, "Value Loss": 0.0064520868472754955, "_runtime": 9536.686744689941, "_timestamp": 1585518615.1074743, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6987299919128418, "Value Loss": 0.006640714127570391, "_runtime": 9538.2095413208, "_timestamp": 1585518616.630271, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.698158860206604, "Value Loss": 0.006768988445401192, "_runtime": 9539.236251115799, "_timestamp": 1585518617.6569808, "_step": 476}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.6855073571205139, "Value Loss": 15.461138725280762, "_runtime": 9540.110676527023, "_timestamp": 1585518618.5314062, "_step": 477}
{"Episode reward": 45.29869590960393, "Episode length": 548, "Policy Loss": 0.8314200639724731, "Value Loss": 18.224706649780273, "_runtime": 9541.655137777328, "_timestamp": 1585518620.0758674, "_step": 478}
{"Episode reward": -99.83821268081526, "Episode length": 999, "Policy Loss": -0.719447910785675, "Value Loss": 0.007085349410772324, "_runtime": 9543.189375638962, "_timestamp": 1585518621.6101053, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7304354310035706, "Value Loss": 0.007183717098087072, "_runtime": 9543.987545967102, "_timestamp": 1585518622.4082756, "_step": 480}
{"Episode reward": 48.499999999999545, "Episode length": 515, "Policy Loss": 0.9374865889549255, "Value Loss": 19.391733169555664, "_runtime": 9545.527886629105, "_timestamp": 1585518623.9486163, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7292532920837402, "Value Loss": 0.007306374609470367, "_runtime": 9546.573511838913, "_timestamp": 1585518624.9942415, "_step": 482}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": 0.7029986381530762, "Value Loss": 15.365632057189941, "_runtime": 9548.087750196457, "_timestamp": 1585518626.5084798, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7369177937507629, "Value Loss": 0.007406982593238354, "_runtime": 9549.631092071533, "_timestamp": 1585518628.0518217, "_step": 484}
{"Episode reward": -99.83737967051427, "Episode length": 999, "Policy Loss": -0.7359172701835632, "Value Loss": 0.007413716521114111, "_runtime": 9551.150733232498, "_timestamp": 1585518629.5714629, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7335152626037598, "Value Loss": 0.007382742129266262, "_runtime": 9552.687194108963, "_timestamp": 1585518631.1079237, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7333735823631287, "Value Loss": 0.007302871905267239, "_runtime": 9554.228563070297, "_timestamp": 1585518632.6492927, "_step": 487}
{"Episode reward": -99.83084912896017, "Episode length": 999, "Policy Loss": -0.716234564781189, "Value Loss": 0.007171547040343285, "_runtime": 9555.402130842209, "_timestamp": 1585518633.8228605, "_step": 488}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.5078438520431519, "Value Loss": 13.872654914855957, "_runtime": 9556.479015111923, "_timestamp": 1585518634.8997447, "_step": 489}
{"Episode reward": 31.699999999999605, "Episode length": 683, "Policy Loss": 0.7408864498138428, "Value Loss": 14.623866081237793, "_runtime": 9558.037504911423, "_timestamp": 1585518636.4582345, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7042617797851562, "Value Loss": 0.0068486654199659824, "_runtime": 9558.84423327446, "_timestamp": 1585518637.264963, "_step": 491}
{"Episode reward": 48.89999999999955, "Episode length": 511, "Policy Loss": 0.9792584180831909, "Value Loss": 19.54408073425293, "_runtime": 9559.75136256218, "_timestamp": 1585518638.1720922, "_step": 492}
{"Episode reward": 41.83069112300818, "Episode length": 582, "Policy Loss": 0.7356879115104675, "Value Loss": 17.16071891784668, "_runtime": 9561.209166288376, "_timestamp": 1585518639.629896, "_step": 493}
{"Episode reward": 5.632703733352173, "Episode length": 944, "Policy Loss": 0.2112157642841339, "Value Loss": 10.582579612731934, "_runtime": 9562.315280914307, "_timestamp": 1585518640.7360106, "_step": 494}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.48323869705200195, "Value Loss": 13.8344087600708, "_runtime": 9563.822115182877, "_timestamp": 1585518642.2428448, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7078165411949158, "Value Loss": 0.006837042048573494, "_runtime": 9565.369020938873, "_timestamp": 1585518643.7897506, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7112284898757935, "Value Loss": 0.006847143638879061, "_runtime": 9566.272523641586, "_timestamp": 1585518644.6932533, "_step": 497}
{"Episode reward": 42.099999999999454, "Episode length": 579, "Policy Loss": 1.1889941692352295, "Value Loss": 17.249486923217773, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816, -0.005769146140664816]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0], "bins": [-0.45839303731918335, -0.45103952288627625, -0.44368600845336914, -0.4363325238227844, -0.4289790093898773, -0.4216254949569702, -0.4142719805240631, -0.406918466091156, -0.3995649814605713, -0.3922114670276642, -0.3848579525947571, -0.37750443816185, -0.37015092372894287, -0.36279743909835815, -0.35544389486312866, -0.34809041023254395, -0.34073689579963684, -0.33338338136672974, -0.326029896736145, -0.3186763525009155, -0.3113228678703308, -0.3039693534374237, -0.2966158390045166, -0.2892623543739319, -0.2819088101387024, -0.2745553255081177, -0.26720181107521057, -0.25984829664230347, -0.25249478220939636, -0.24514128267765045, -0.23778776824474335, -0.23043426871299744, -0.22308075428009033, -0.21572723984718323, -0.20837372541427612, -0.2010202407836914, -0.1936667263507843, -0.1863132119178772, -0.1789596974849701, -0.171606183052063, -0.16425269842147827, -0.15689918398857117, -0.14954566955566406, -0.14219215512275696, -0.13483864068984985, -0.12748512625694275, -0.12013164162635803, -0.11277812719345093, -0.10542461276054382, -0.09807109832763672, -0.09071758389472961, -0.0833640992641449, -0.07601058483123779, -0.06865707039833069, -0.061303555965423584, -0.05395004153251648, -0.046596527099609375, -0.03924304246902466, -0.031889528036117554, -0.02453601360321045, -0.017182499170303345, -0.00982898473739624, -0.0024755001068115234, 0.004878014326095581, 0.012231528759002686]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.017256634309887886, -0.016940400004386902, -0.01662416383624077, -0.016307929530739784, -0.01599169336259365, -0.015675459057092667, -0.015359222888946533, -0.015042988583445549, -0.014726752415299416, -0.014410518109798431, -0.014094281941652298, -0.013778047636151314, -0.013461812399327755, -0.013145577162504196, -0.012829341925680637, -0.012513106688857079, -0.01219687145203352, -0.011880636215209961, -0.011564400978386402, -0.011248165741562843, -0.010931930504739285, -0.010615695267915726, -0.010299460962414742, -0.009983224794268608, -0.009666990488767624, -0.009350755251944065, -0.009034520015120506, -0.008718284778296947, -0.008402049541473389, -0.00808581430464983, -0.007769579067826271, -0.007453343831002712, -0.0071371085941791534, -0.006820873357355595, -0.006504638120532036, -0.006188402883708477, -0.005872167646884918, -0.005555932410061359, -0.005239697173237801, -0.004923461936414242, -0.004607226699590683, -0.004290992394089699, -0.00397475715726614, -0.003658521920442581, -0.0033422866836190224, -0.0030260514467954636, -0.0027098162099719048, -0.002393580973148346, -0.002077345736324787, -0.0017611104995012283, -0.0014448761940002441, -0.0011286400258541107, -0.0008124057203531265, -0.0004961695522069931, -0.0001799352467060089, 0.0001363009214401245, 0.0004525352269411087, 0.0007687713950872421, 0.0010850057005882263, 0.0014012418687343597, 0.001717476174235344, 0.0020337123423814774, 0.0023499466478824615, 0.002666182816028595, 0.002982417121529579]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 5.0, 4.0, 5.0, 1.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 4.0, 2.0, 4.0, 8.0, 2.0, 3.0, 5.0, 4.0, 2.0, 2.0, 8.0, 14.0, 42.0, 95.0, 31.0, 23.0, 20.0, 21.0, 32.0, 18.0, 18.0, 32.0, 30.0, 34.0, 4.0, 1.0], "bins": [-0.08677740395069122, -0.08510445058345795, -0.08343149721622467, -0.08175855129957199, -0.08008559793233871, -0.07841264456510544, -0.07673969119787216, -0.07506674528121948, -0.0733937919139862, -0.07172083854675293, -0.07004788517951965, -0.06837493181228638, -0.0667019858956337, -0.06502903252840042, -0.06335607916116714, -0.06168312951922417, -0.06001017987728119, -0.05833722651004791, -0.056664273142814636, -0.05499132350087166, -0.05331837013363838, -0.051645420491695404, -0.04997246712446213, -0.04829951748251915, -0.04662656411528587, -0.044953614473342896, -0.04328066110610962, -0.04160771146416664, -0.039934758096933365, -0.03826180845499039, -0.03658885508775711, -0.03491590544581413, -0.033242952078580856, -0.03156999871134758, -0.029897049069404602, -0.028224095702171326, -0.026551146060228348, -0.02487819269299507, -0.023205243051052094, -0.021532289683818817, -0.01985933631658554, -0.01818639039993286, -0.016513437032699585, -0.014840483665466309, -0.013167530298233032, -0.011494584381580353, -0.009821631014347076, -0.0081486776471138, -0.006475724279880524, -0.004802770912647247, -0.003129824995994568, -0.0014568716287612915, 0.00021608173847198486, 0.0018890351057052612, 0.0035619810223579407, 0.005234934389591217, 0.006907887756824493, 0.00858084112405777, 0.01025378704071045, 0.011926740407943726, 0.013599693775177002, 0.015272647142410278, 0.016945593059062958, 0.018618546426296234, 0.02029149979352951]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.32101970911026, -0.31274867057800293, -0.30447763204574585, -0.29620659351348877, -0.2879355251789093, -0.2796644866466522, -0.27139344811439514, -0.26312240958213806, -0.254851371049881, -0.2465803176164627, -0.23830927908420563, -0.23003822565078735, -0.22176718711853027, -0.2134961485862732, -0.2052251100540161, -0.19695407152175903, -0.18868301808834076, -0.18041197955608368, -0.1721409261226654, -0.16386988759040833, -0.15559884905815125, -0.14732779562473297, -0.1390567570924759, -0.1307857185602188, -0.12251466512680054, -0.11424362659454346, -0.10597258806228638, -0.0977015495300293, -0.08943049609661102, -0.08115945756435394, -0.07288841903209686, -0.06461736559867859, -0.05634632706642151, -0.04807528853416443, -0.03980425000190735, -0.03153321146965027, -0.0232621431350708, -0.01499110460281372, -0.006720066070556641, 0.0015509724617004395, 0.00982201099395752, 0.0180930495262146, 0.026364117860794067, 0.03463515639305115, 0.04290619492530823, 0.05117723345756531, 0.05944827198982239, 0.06771931052207947, 0.07599037885665894, 0.08426141738891602, 0.0925324559211731, 0.10080349445343018, 0.10907453298568726, 0.11734557151794434, 0.12561661005020142, 0.13388767838478088, 0.14215871691703796, 0.15042975544929504, 0.15870079398155212, 0.1669718325138092, 0.17524287104606628, 0.18351393938064575, 0.19178497791290283, 0.2000560164451599, 0.208327054977417]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.1273629069328308, -0.12412416189908981, -0.12088542431592941, -0.11764667928218842, -0.11440794169902802, -0.11116919666528702, -0.10793045163154602, -0.10469171404838562, -0.10145297646522522, -0.09821423143148422, -0.09497548639774323, -0.09173674881458282, -0.08849800378084183, -0.08525925874710083, -0.08202052116394043, -0.07878178358078003, -0.07554303854703903, -0.07230429351329803, -0.06906555593013763, -0.06582681834697723, -0.06258807331323624, -0.05934932827949524, -0.05611059069633484, -0.05287184566259384, -0.049633100628852844, -0.046394363045692444, -0.04315561801195145, -0.039916880428791046, -0.03667813539505005, -0.03343939781188965, -0.03020065277814865, -0.02696191519498825, -0.023723170161247253, -0.020484425127506256, -0.017245687544345856, -0.014006942510604858, -0.010768204927444458, -0.007529459893703461, -0.00429072231054306, -0.001051977276802063, 0.0021867603063583374, 0.005425512790679932, 0.008664250373840332, 0.011902987957000732, 0.015141725540161133, 0.018380478024482727, 0.021619215607643127, 0.024857953190803528, 0.028096705675125122, 0.03133544325828552, 0.03457418084144592, 0.03781291842460632, 0.04105167090892792, 0.04429040849208832, 0.04752914607524872, 0.05076788365840912, 0.05400663614273071, 0.05724537372589111, 0.060484111309051514, 0.06372286379337311, 0.06696160137653351, 0.07020033895969391, 0.07343907654285431, 0.0766778290271759, 0.0799165666103363]}, "_runtime": 9567.81311750412, "_timestamp": 1585518646.2338471, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7079201936721802, "Value Loss": 0.006835857406258583, "_runtime": 9567.81311750412, "_timestamp": 1585518646.2338471, "_step": 499}
