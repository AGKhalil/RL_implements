{"Episode reward": -99.1597630745542, "Episode length": 999, "Policy Loss": -12.535578727722168, "Value Loss": 0.028512218967080116, "_runtime": 12.41772723197937, "_timestamp": 1585076266.7631905, "_step": 0}
{"Episode reward": -92.51488855157871, "Episode length": 999, "Policy Loss": -11.765924453735352, "Value Loss": 0.026331109926104546, "_runtime": 13.498632669448853, "_timestamp": 1585076267.844096, "_step": 1}
{"Episode reward": -106.28930070210863, "Episode length": 999, "Policy Loss": -13.906222343444824, "Value Loss": 0.03266719728708267, "_runtime": 14.63779878616333, "_timestamp": 1585076268.983262, "_step": 2}
{"Episode reward": -100.01058822508195, "Episode length": 999, "Policy Loss": -12.913352012634277, "Value Loss": 0.032252922654151917, "_runtime": 15.778876781463623, "_timestamp": 1585076270.12434, "_step": 3}
{"Episode reward": -103.9124477139741, "Episode length": 999, "Policy Loss": -13.303854942321777, "Value Loss": 0.030727336183190346, "_runtime": 16.89939045906067, "_timestamp": 1585076271.2448537, "_step": 4}
{"Episode reward": -104.42056771757532, "Episode length": 999, "Policy Loss": -13.507209777832031, "Value Loss": 0.03477737680077553, "_runtime": 18.09753680229187, "_timestamp": 1585076272.443, "_step": 5}
{"Episode reward": -104.18896680134031, "Episode length": 999, "Policy Loss": -13.562154769897461, "Value Loss": 0.030473731458187103, "_runtime": 19.201739072799683, "_timestamp": 1585076273.5472023, "_step": 6}
{"Episode reward": -99.44757429633495, "Episode length": 999, "Policy Loss": -12.672737121582031, "Value Loss": 0.028305400162935257, "_runtime": 20.314302444458008, "_timestamp": 1585076274.6597657, "_step": 7}
{"Episode reward": -105.27783804714628, "Episode length": 999, "Policy Loss": -13.691277503967285, "Value Loss": 0.03175126388669014, "_runtime": 21.439518690109253, "_timestamp": 1585076275.784982, "_step": 8}
{"Episode reward": -104.55947906364958, "Episode length": 999, "Policy Loss": -13.517549514770508, "Value Loss": 0.03273716941475868, "_runtime": 22.591293573379517, "_timestamp": 1585076276.9367568, "_step": 9}
{"Episode reward": -103.03693154884574, "Episode length": 999, "Policy Loss": -13.465875625610352, "Value Loss": 0.03324584662914276, "_runtime": 23.7506844997406, "_timestamp": 1585076278.0961478, "_step": 10}
{"Episode reward": -108.30083577006835, "Episode length": 999, "Policy Loss": -14.2400541305542, "Value Loss": 0.04027184844017029, "_runtime": 24.9123375415802, "_timestamp": 1585076279.2578008, "_step": 11}
{"Episode reward": -103.27740301059086, "Episode length": 999, "Policy Loss": -13.54881763458252, "Value Loss": 0.030419105663895607, "_runtime": 26.067367792129517, "_timestamp": 1585076280.412831, "_step": 12}
{"Episode reward": -93.76411232637912, "Episode length": 999, "Policy Loss": -11.66608715057373, "Value Loss": 0.02663702890276909, "_runtime": 27.191826820373535, "_timestamp": 1585076281.53729, "_step": 13}
{"Episode reward": -109.46076542533642, "Episode length": 999, "Policy Loss": -14.605613708496094, "Value Loss": 0.03481592237949371, "_runtime": 28.336498975753784, "_timestamp": 1585076282.6819623, "_step": 14}
{"Episode reward": -97.03470010174425, "Episode length": 999, "Policy Loss": -12.615216255187988, "Value Loss": 0.027107497677206993, "_runtime": 29.485255241394043, "_timestamp": 1585076283.8307185, "_step": 15}
{"Episode reward": -97.810882603932, "Episode length": 999, "Policy Loss": -12.575584411621094, "Value Loss": 0.028276346623897552, "_runtime": 30.599467992782593, "_timestamp": 1585076284.9449313, "_step": 16}
{"Episode reward": -99.57512539353553, "Episode length": 999, "Policy Loss": -12.741025924682617, "Value Loss": 0.03305364027619362, "_runtime": 31.759926557540894, "_timestamp": 1585076286.1053898, "_step": 17}
{"Episode reward": -101.79159252935193, "Episode length": 999, "Policy Loss": -13.046557426452637, "Value Loss": 0.029656294733285904, "_runtime": 32.94690132141113, "_timestamp": 1585076287.2923646, "_step": 18}
{"Episode reward": -96.07191907748708, "Episode length": 999, "Policy Loss": -12.319894790649414, "Value Loss": 0.030553678050637245, "_runtime": 34.09506630897522, "_timestamp": 1585076288.4405296, "_step": 19}
{"Episode reward": -95.54129023222256, "Episode length": 999, "Policy Loss": -12.252571105957031, "Value Loss": 0.027093157172203064, "_runtime": 35.21850371360779, "_timestamp": 1585076289.563967, "_step": 20}
{"Episode reward": -100.59426235343716, "Episode length": 999, "Policy Loss": -12.941915512084961, "Value Loss": 0.03582229092717171, "_runtime": 36.38806962966919, "_timestamp": 1585076290.733533, "_step": 21}
{"Episode reward": -103.78467996064163, "Episode length": 999, "Policy Loss": -13.568970680236816, "Value Loss": 0.02899797447025776, "_runtime": 37.52163338661194, "_timestamp": 1585076291.8670967, "_step": 22}
{"Episode reward": -99.18759580494397, "Episode length": 999, "Policy Loss": -12.679742813110352, "Value Loss": 0.027569586411118507, "_runtime": 38.68676733970642, "_timestamp": 1585076293.0322306, "_step": 23}
{"Episode reward": -107.0892601259905, "Episode length": 999, "Policy Loss": -14.07446575164795, "Value Loss": 0.034912239760160446, "_runtime": 39.825796365737915, "_timestamp": 1585076294.1712596, "_step": 24}
{"Episode reward": -102.942126027893, "Episode length": 999, "Policy Loss": -13.534117698669434, "Value Loss": 0.032724760472774506, "_runtime": 40.928940534591675, "_timestamp": 1585076295.2744038, "_step": 25}
{"Episode reward": -108.7914102381273, "Episode length": 999, "Policy Loss": -14.501224517822266, "Value Loss": 0.03578479215502739, "_runtime": 42.097476959228516, "_timestamp": 1585076296.4429402, "_step": 26}
{"Episode reward": -102.89181939974853, "Episode length": 999, "Policy Loss": -13.301153182983398, "Value Loss": 0.03152722120285034, "_runtime": 43.221197843551636, "_timestamp": 1585076297.5666611, "_step": 27}
{"Episode reward": -103.46467678817218, "Episode length": 999, "Policy Loss": -13.458796501159668, "Value Loss": 0.03233835846185684, "_runtime": 44.354904890060425, "_timestamp": 1585076298.7003682, "_step": 28}
{"Episode reward": -108.43892015025286, "Episode length": 999, "Policy Loss": -14.27311897277832, "Value Loss": 0.039781052619218826, "_runtime": 45.53121876716614, "_timestamp": 1585076299.876682, "_step": 29}
{"Episode reward": -99.53961621727458, "Episode length": 999, "Policy Loss": -12.810307502746582, "Value Loss": 0.028550853952765465, "_runtime": 46.640533685684204, "_timestamp": 1585076300.985997, "_step": 30}
{"Episode reward": -101.17588774235806, "Episode length": 999, "Policy Loss": -12.82120132446289, "Value Loss": 0.034001003950834274, "_runtime": 47.77335715293884, "_timestamp": 1585076302.1188204, "_step": 31}
{"Episode reward": -104.45832308476335, "Episode length": 999, "Policy Loss": -13.512018203735352, "Value Loss": 0.03445575758814812, "_runtime": 48.91873526573181, "_timestamp": 1585076303.2641985, "_step": 32}
{"Episode reward": -110.52418214927748, "Episode length": 999, "Policy Loss": -14.720476150512695, "Value Loss": 0.0359710231423378, "_runtime": 50.0326189994812, "_timestamp": 1585076304.3780823, "_step": 33}
{"Episode reward": -101.57183322190636, "Episode length": 999, "Policy Loss": -13.258374214172363, "Value Loss": 0.02992274798452854, "_runtime": 51.154417276382446, "_timestamp": 1585076305.4998806, "_step": 34}
{"Episode reward": -102.39656747572451, "Episode length": 999, "Policy Loss": -13.361349105834961, "Value Loss": 0.03198583796620369, "_runtime": 52.311537742614746, "_timestamp": 1585076306.657001, "_step": 35}
{"Episode reward": -106.9286028266476, "Episode length": 999, "Policy Loss": -14.054044723510742, "Value Loss": 0.0331885926425457, "_runtime": 53.437904357910156, "_timestamp": 1585076307.7833676, "_step": 36}
{"Episode reward": -108.25442189331542, "Episode length": 999, "Policy Loss": -14.372894287109375, "Value Loss": 0.03765613213181496, "_runtime": 54.612056493759155, "_timestamp": 1585076308.9575198, "_step": 37}
{"Episode reward": -98.23889196328109, "Episode length": 999, "Policy Loss": -12.593116760253906, "Value Loss": 0.028743693605065346, "_runtime": 55.811769247055054, "_timestamp": 1585076310.1572325, "_step": 38}
{"Episode reward": -97.86450763786, "Episode length": 999, "Policy Loss": -12.440275192260742, "Value Loss": 0.028049945831298828, "_runtime": 56.95381188392639, "_timestamp": 1585076311.2992752, "_step": 39}
{"Episode reward": -95.87925959254804, "Episode length": 999, "Policy Loss": -12.036513328552246, "Value Loss": 0.026378778740763664, "_runtime": 58.10453820228577, "_timestamp": 1585076312.4500015, "_step": 40}
{"Episode reward": -104.81626071211743, "Episode length": 999, "Policy Loss": -13.556997299194336, "Value Loss": 0.03346537426114082, "_runtime": 59.261070728302, "_timestamp": 1585076313.606534, "_step": 41}
{"Episode reward": -100.05147794681479, "Episode length": 999, "Policy Loss": -12.788008689880371, "Value Loss": 0.03423186019062996, "_runtime": 60.39372253417969, "_timestamp": 1585076314.7391858, "_step": 42}
{"Episode reward": -98.49832854557613, "Episode length": 999, "Policy Loss": -12.539052963256836, "Value Loss": 0.03157398849725723, "_runtime": 61.53887748718262, "_timestamp": 1585076315.8843408, "_step": 43}
{"Episode reward": -103.57600747489552, "Episode length": 999, "Policy Loss": -13.22718620300293, "Value Loss": 0.030769886448979378, "_runtime": 62.680378913879395, "_timestamp": 1585076317.0258422, "_step": 44}
{"Episode reward": -103.80918682300782, "Episode length": 999, "Policy Loss": -13.383125305175781, "Value Loss": 0.03163328394293785, "_runtime": 63.86894655227661, "_timestamp": 1585076318.2144098, "_step": 45}
{"Episode reward": -107.31612742430472, "Episode length": 999, "Policy Loss": -14.30099105834961, "Value Loss": 0.03822559490799904, "_runtime": 65.01748156547546, "_timestamp": 1585076319.3629448, "_step": 46}
{"Episode reward": -98.73591826343483, "Episode length": 999, "Policy Loss": -12.677884101867676, "Value Loss": 0.029406363144516945, "_runtime": 66.16429805755615, "_timestamp": 1585076320.5097613, "_step": 47}
{"Episode reward": -90.93935422641988, "Episode length": 999, "Policy Loss": -11.448272705078125, "Value Loss": 0.026666786521673203, "_runtime": 66.83652687072754, "_timestamp": 1585076321.1819901, "_step": 48}
{"Episode reward": 40.30167581816303, "Episode length": 588, "Policy Loss": 12.356062889099121, "Value Loss": 16.95854377746582, "_runtime": 67.98399925231934, "_timestamp": 1585076322.3294625, "_step": 49}
{"Episode reward": -104.19373300649403, "Episode length": 999, "Policy Loss": -13.427328109741211, "Value Loss": 0.0339515246450901, "_runtime": 69.1009156703949, "_timestamp": 1585076323.446379, "_step": 50}
{"Episode reward": -100.2526795962636, "Episode length": 999, "Policy Loss": -12.842606544494629, "Value Loss": 0.03200051933526993, "_runtime": 70.20295286178589, "_timestamp": 1585076324.5484161, "_step": 51}
{"Episode reward": -93.36421237181231, "Episode length": 999, "Policy Loss": -11.850184440612793, "Value Loss": 0.02912096679210663, "_runtime": 71.32836484909058, "_timestamp": 1585076325.6738281, "_step": 52}
{"Episode reward": -95.69726560776454, "Episode length": 999, "Policy Loss": -11.979423522949219, "Value Loss": 0.028520606458187103, "_runtime": 72.4611542224884, "_timestamp": 1585076326.8066175, "_step": 53}
{"Episode reward": -98.15611345399215, "Episode length": 999, "Policy Loss": -12.522717475891113, "Value Loss": 0.02777390368282795, "_runtime": 73.60914254188538, "_timestamp": 1585076327.9546058, "_step": 54}
{"Episode reward": -103.65626792628792, "Episode length": 999, "Policy Loss": -13.416316032409668, "Value Loss": 0.03128700703382492, "_runtime": 74.78813076019287, "_timestamp": 1585076329.133594, "_step": 55}
{"Episode reward": -101.25655201644321, "Episode length": 999, "Policy Loss": -13.275368690490723, "Value Loss": 0.027551105245947838, "_runtime": 75.9180371761322, "_timestamp": 1585076330.2635005, "_step": 56}
{"Episode reward": -108.7983635547665, "Episode length": 999, "Policy Loss": -14.222500801086426, "Value Loss": 0.03684932738542557, "_runtime": 77.08226585388184, "_timestamp": 1585076331.4277291, "_step": 57}
{"Episode reward": -103.87321108953786, "Episode length": 999, "Policy Loss": -13.636247634887695, "Value Loss": 0.029729600995779037, "_runtime": 78.29163026809692, "_timestamp": 1585076332.6370935, "_step": 58}
{"Episode reward": -101.7015254987061, "Episode length": 999, "Policy Loss": -13.047845840454102, "Value Loss": 0.02948751114308834, "_runtime": 79.42192363739014, "_timestamp": 1585076333.767387, "_step": 59}
{"Episode reward": -106.83613439780964, "Episode length": 999, "Policy Loss": -14.162620544433594, "Value Loss": 0.03506144508719444, "_runtime": 80.54659366607666, "_timestamp": 1585076334.892057, "_step": 60}
{"Episode reward": -99.97244969519609, "Episode length": 999, "Policy Loss": -12.889544486999512, "Value Loss": 0.03160630539059639, "_runtime": 81.69002175331116, "_timestamp": 1585076336.035485, "_step": 61}
{"Episode reward": -100.49260402245326, "Episode length": 999, "Policy Loss": -12.840031623840332, "Value Loss": 0.02954462543129921, "_runtime": 82.82495021820068, "_timestamp": 1585076337.1704135, "_step": 62}
{"Episode reward": -97.43484064623689, "Episode length": 999, "Policy Loss": -12.26059627532959, "Value Loss": 0.027704397216439247, "_runtime": 84.00096154212952, "_timestamp": 1585076338.3464248, "_step": 63}
{"Episode reward": -96.27254874986912, "Episode length": 999, "Policy Loss": -12.156906127929688, "Value Loss": 0.025621462613344193, "_runtime": 85.11650967597961, "_timestamp": 1585076339.461973, "_step": 64}
{"Episode reward": -99.86219075609256, "Episode length": 999, "Policy Loss": -12.884027481079102, "Value Loss": 0.030487971380352974, "_runtime": 86.24982786178589, "_timestamp": 1585076340.5952911, "_step": 65}
{"Episode reward": -91.73256368221716, "Episode length": 999, "Policy Loss": -11.39932632446289, "Value Loss": 0.02347610332071781, "_runtime": 87.3875060081482, "_timestamp": 1585076341.7329693, "_step": 66}
{"Episode reward": -102.63388329825821, "Episode length": 999, "Policy Loss": -13.251094818115234, "Value Loss": 0.02934582345187664, "_runtime": 88.53745102882385, "_timestamp": 1585076342.8829143, "_step": 67}
{"Episode reward": -92.81018343906737, "Episode length": 999, "Policy Loss": -11.607368469238281, "Value Loss": 0.02457905374467373, "_runtime": 89.65941214561462, "_timestamp": 1585076344.0048754, "_step": 68}
{"Episode reward": -103.73065393186172, "Episode length": 999, "Policy Loss": -13.511478424072266, "Value Loss": 0.0336761549115181, "_runtime": 90.7646222114563, "_timestamp": 1585076345.1100855, "_step": 69}
{"Episode reward": -105.27730181053462, "Episode length": 999, "Policy Loss": -14.0359525680542, "Value Loss": 0.028715617954730988, "_runtime": 91.93223738670349, "_timestamp": 1585076346.2777007, "_step": 70}
{"Episode reward": -94.50223568256213, "Episode length": 999, "Policy Loss": -11.931954383850098, "Value Loss": 0.026350582018494606, "_runtime": 93.08528089523315, "_timestamp": 1585076347.4307442, "_step": 71}
{"Episode reward": -104.31437260494035, "Episode length": 999, "Policy Loss": -13.650785446166992, "Value Loss": 0.030539248138666153, "_runtime": 94.25257301330566, "_timestamp": 1585076348.5980363, "_step": 72}
{"Episode reward": -93.21246214629258, "Episode length": 999, "Policy Loss": -11.85068130493164, "Value Loss": 0.027713576331734657, "_runtime": 95.41295790672302, "_timestamp": 1585076349.7584212, "_step": 73}
{"Episode reward": -100.828438649924, "Episode length": 999, "Policy Loss": -12.939007759094238, "Value Loss": 0.03045591525733471, "_runtime": 96.52797770500183, "_timestamp": 1585076350.873441, "_step": 74}
{"Episode reward": -103.8971061071037, "Episode length": 999, "Policy Loss": -13.345611572265625, "Value Loss": 0.030743176117539406, "_runtime": 97.65875148773193, "_timestamp": 1585076352.0042148, "_step": 75}
{"Episode reward": -103.3470875327798, "Episode length": 999, "Policy Loss": -13.334748268127441, "Value Loss": 0.035461243242025375, "_runtime": 98.79049229621887, "_timestamp": 1585076353.1359556, "_step": 76}
{"Episode reward": -104.46872684602299, "Episode length": 999, "Policy Loss": -13.961235046386719, "Value Loss": 0.031721118837594986, "_runtime": 99.9101095199585, "_timestamp": 1585076354.2555728, "_step": 77}
{"Episode reward": -93.46975987432202, "Episode length": 999, "Policy Loss": -11.702106475830078, "Value Loss": 0.02585398592054844, "_runtime": 101.01842546463013, "_timestamp": 1585076355.3638887, "_step": 78}
{"Episode reward": -105.35135901849225, "Episode length": 999, "Policy Loss": -14.086990356445312, "Value Loss": 0.035614512860774994, "_runtime": 102.16692686080933, "_timestamp": 1585076356.5123901, "_step": 79}
{"Episode reward": -100.17389388230856, "Episode length": 999, "Policy Loss": -12.91307258605957, "Value Loss": 0.029076987877488136, "_runtime": 103.28212690353394, "_timestamp": 1585076357.6275902, "_step": 80}
{"Episode reward": -105.67784579857671, "Episode length": 999, "Policy Loss": -13.846470832824707, "Value Loss": 0.034477975219488144, "_runtime": 104.40891361236572, "_timestamp": 1585076358.754377, "_step": 81}
{"Episode reward": -96.16749130862833, "Episode length": 999, "Policy Loss": -12.412763595581055, "Value Loss": 0.028674155473709106, "_runtime": 105.60102915763855, "_timestamp": 1585076359.9464924, "_step": 82}
{"Episode reward": -99.21565200608741, "Episode length": 999, "Policy Loss": -12.674032211303711, "Value Loss": 0.02997872792184353, "_runtime": 106.73058772087097, "_timestamp": 1585076361.076051, "_step": 83}
{"Episode reward": -99.82243471142735, "Episode length": 999, "Policy Loss": -12.811323165893555, "Value Loss": 0.029123010113835335, "_runtime": 107.87475609779358, "_timestamp": 1585076362.2202194, "_step": 84}
{"Episode reward": -103.19088825327522, "Episode length": 999, "Policy Loss": -13.668973922729492, "Value Loss": 0.030206194147467613, "_runtime": 109.01645350456238, "_timestamp": 1585076363.3619168, "_step": 85}
{"Episode reward": -101.88198713813945, "Episode length": 999, "Policy Loss": -13.2244234085083, "Value Loss": 0.030364075675606728, "_runtime": 110.13504433631897, "_timestamp": 1585076364.4805076, "_step": 86}
{"Episode reward": -105.01332597223961, "Episode length": 999, "Policy Loss": -13.728364944458008, "Value Loss": 0.03477984294295311, "_runtime": 111.2709608078003, "_timestamp": 1585076365.616424, "_step": 87}
{"Episode reward": -102.24572584353517, "Episode length": 999, "Policy Loss": -13.538616180419922, "Value Loss": 0.03189265727996826, "_runtime": 112.45863270759583, "_timestamp": 1585076366.804096, "_step": 88}
{"Episode reward": -104.7059987712659, "Episode length": 999, "Policy Loss": -13.748204231262207, "Value Loss": 0.033814385533332825, "_runtime": 113.59952902793884, "_timestamp": 1585076367.9449923, "_step": 89}
{"Episode reward": -103.58498829302889, "Episode length": 999, "Policy Loss": -13.46014404296875, "Value Loss": 0.0345720537006855, "_runtime": 114.75339245796204, "_timestamp": 1585076369.0988557, "_step": 90}
{"Episode reward": -96.57326470216694, "Episode length": 999, "Policy Loss": -12.323112487792969, "Value Loss": 0.02879967726767063, "_runtime": 115.89346837997437, "_timestamp": 1585076370.2389317, "_step": 91}
{"Episode reward": -107.99415547641902, "Episode length": 999, "Policy Loss": -14.449191093444824, "Value Loss": 0.03408563882112503, "_runtime": 117.0238208770752, "_timestamp": 1585076371.3692842, "_step": 92}
{"Episode reward": -91.92695841742855, "Episode length": 999, "Policy Loss": -11.418179512023926, "Value Loss": 0.03017519786953926, "_runtime": 118.16356754302979, "_timestamp": 1585076372.5090308, "_step": 93}
{"Episode reward": -111.68367147253784, "Episode length": 999, "Policy Loss": -15.101014137268066, "Value Loss": 0.0348968431353569, "_runtime": 119.31673049926758, "_timestamp": 1585076373.6621938, "_step": 94}
{"Episode reward": -99.69167890806612, "Episode length": 999, "Policy Loss": -12.835040092468262, "Value Loss": 0.0301823727786541, "_runtime": 120.45636248588562, "_timestamp": 1585076374.8018258, "_step": 95}
{"Episode reward": -94.69174228724546, "Episode length": 999, "Policy Loss": -12.10512924194336, "Value Loss": 0.026948021724820137, "_runtime": 121.60703182220459, "_timestamp": 1585076375.952495, "_step": 96}
{"Episode reward": -101.2944770162633, "Episode length": 999, "Policy Loss": -13.175726890563965, "Value Loss": 0.028294837102293968, "_runtime": 122.74481391906738, "_timestamp": 1585076377.0902772, "_step": 97}
{"Episode reward": -93.51075776800849, "Episode length": 999, "Policy Loss": -11.726953506469727, "Value Loss": 0.025238363072276115, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906, 249.66456604003906]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-135.482666015625, -129.83497619628906, -124.18728637695312, -118.53960418701172, -112.89191436767578, -107.24422454833984, -101.59654235839844, -95.9488525390625, -90.30116271972656, -84.65347290039062, -79.00578308105469, -73.35810089111328, -67.71041107177734, -62.062721252441406, -56.4150390625, -50.76734924316406, -45.119659423828125, -39.47196960449219, -33.82427978515625, -28.176597595214844, -22.528907775878906, -16.88121795654297, -11.233535766601562, -5.585845947265625, 0.0618438720703125, 5.70953369140625, 11.357223510742188, 17.004913330078125, 22.652587890625, 28.300277709960938, 33.947967529296875, 39.59565734863281, 45.24334716796875, 50.89103698730469, 56.538726806640625, 62.18641662597656, 67.8341064453125, 73.48178100585938, 79.12947082519531, 84.77716064453125, 90.42485046386719, 96.07254028320312, 101.72023010253906, 107.367919921875, 113.01559448242188, 118.66328430175781, 124.31097412109375, 129.95867919921875, 135.60635375976562, 141.2540283203125, 146.9017333984375, 152.54940795898438, 158.19711303710938, 163.84478759765625, 169.49249267578125, 175.14016723632812, 180.787841796875, 186.435546875, 192.08322143554688, 197.73092651367188, 203.37860107421875, 209.02630615234375, 214.67398071289062, 220.32168579101562, 225.9693603515625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-136.8514862060547, -132.8407440185547, -128.8300018310547, -124.81925201416016, -120.80850982666016, -116.79776763916016, -112.78701782226562, -108.77627563476562, -104.76553344726562, -100.75479125976562, -96.74404907226562, -92.7332992553711, -88.7225570678711, -84.7118148803711, -80.70106506347656, -76.69032287597656, -72.67958068847656, -68.66883850097656, -64.65809631347656, -60.64734649658203, -56.63660430908203, -52.62586212158203, -48.6151123046875, -44.6043701171875, -40.5936279296875, -36.5828857421875, -32.5721435546875, -28.56139373779297, -24.55065155029297, -20.53990936279297, -16.529159545898438, -12.518417358398438, -8.507675170898438, -4.4969329833984375, -0.4861907958984375, 3.5245513916015625, 7.5352935791015625, 11.546051025390625, 15.556793212890625, 19.567535400390625, 23.578277587890625, 27.589019775390625, 31.599761962890625, 35.610504150390625, 39.62126159667969, 43.63200378417969, 47.64274597167969, 51.65348815917969, 55.66423034667969, 59.67497253417969, 63.68571472167969, 67.69645690917969, 71.70719909667969, 75.71795654296875, 79.72869873046875, 83.73944091796875, 87.75018310546875, 91.76092529296875, 95.77166748046875, 99.78240966796875, 103.79316711425781, 107.80390930175781, 111.81465148925781, 115.82539367675781, 119.83613586425781]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 6.0, 9.0, 3.0, 10.0, 4.0, 9.0, 15.0, 11.0, 10.0, 10.0, 8.0, 20.0, 16.0, 19.0, 49.0, 42.0, 42.0, 36.0, 23.0, 23.0, 32.0, 18.0, 8.0, 13.0, 15.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 7.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-110.74413299560547, -107.49851989746094, -104.25291442871094, -101.00730895996094, -97.7616958618164, -94.51608276367188, -91.27047729492188, -88.02487182617188, -84.77925872802734, -81.53364562988281, -78.28804016113281, -75.04243469238281, -71.79682159423828, -68.55120849609375, -65.30560302734375, -62.059993743896484, -58.81438446044922, -55.56877517700195, -52.32316589355469, -49.07755661010742, -45.831947326660156, -42.586341857910156, -39.340728759765625, -36.095115661621094, -32.849510192871094, -29.603904724121094, -26.358291625976562, -23.11267852783203, -19.86707305908203, -16.62146759033203, -13.3758544921875, -10.130241394042969, -6.884635925292969, -3.6390304565429688, -0.3934173583984375, 2.8521957397460938, 6.097801208496094, 9.343406677246094, 12.589019775390625, 15.834632873535156, 19.080238342285156, 22.325843811035156, 25.571449279785156, 28.81707000732422, 32.06267547607422, 35.30828094482422, 38.55390167236328, 41.79950714111328, 45.04511260986328, 48.29071807861328, 51.53632354736328, 54.781944274902344, 58.027549743652344, 61.273155212402344, 64.5187759399414, 67.7643814086914, 71.0099868774414, 74.2555923461914, 77.5011978149414, 80.74681854248047, 83.99242401123047, 87.23802947998047, 90.48365020751953, 93.72925567626953, 96.97486114501953]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-58.23847579956055, -55.783348083496094, -53.328216552734375, -50.87308883666992, -48.41796112060547, -45.962833404541016, -43.50770568847656, -41.052574157714844, -38.59744644165039, -36.14231872558594, -33.68718719482422, -31.232059478759766, -28.776931762695312, -26.32180404663086, -23.86667251586914, -21.411544799804688, -18.956417083740234, -16.50128936767578, -14.046161651611328, -11.59103012084961, -9.135902404785156, -6.680774688720703, -4.225643157958984, -1.7705154418945312, 0.6846122741699219, 3.139739990234375, 5.594867706298828, 8.049999237060547, 10.505130767822266, 12.960254669189453, 15.415386199951172, 17.87051010131836, 20.325641632080078, 22.780773162841797, 25.235897064208984, 27.691028594970703, 30.14615249633789, 32.60128402709961, 35.05641555786133, 37.511539459228516, 39.966670989990234, 42.42180252075195, 44.87692642211914, 47.33205795288086, 49.78718948364258, 52.242313385009766, 54.697444915771484, 57.15256881713867, 59.60770034790039, 62.06283187866211, 64.51795959472656, 66.97308349609375, 69.42820739746094, 71.88334655761719, 74.33847045898438, 76.79359436035156, 79.24873352050781, 81.703857421875, 84.15898132324219, 86.61410522460938, 89.06924438476562, 91.52436828613281, 93.9794921875, 96.43463134765625, 98.88975524902344]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 11.0, 18.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-43.12310791015625, -42.05158996582031, -40.98007583618164, -39.9085578918457, -38.83704376220703, -37.765525817871094, -36.694007873535156, -35.622493743896484, -34.55097579956055, -33.479461669921875, -32.40794372558594, -31.33642578125, -30.264909744262695, -29.19339370727539, -28.121875762939453, -27.05035972595215, -25.978843688964844, -24.90732765197754, -23.835811614990234, -22.764293670654297, -21.692777633666992, -20.621261596679688, -19.54974365234375, -18.478227615356445, -17.40671157836914, -16.335195541381836, -15.263679504394531, -14.192161560058594, -13.120645523071289, -12.049129486083984, -10.977611541748047, -9.906097412109375, -8.834579467773438, -7.7630615234375, -6.691547393798828, -5.620029449462891, -4.548515319824219, -3.4769973754882812, -2.4054794311523438, -1.3339653015136719, -0.2624473571777344, 0.8090705871582031, 1.880584716796875, 2.9521026611328125, 4.02362060546875, 5.095134735107422, 6.166652679443359, 7.238166809082031, 8.309684753417969, 9.381202697753906, 10.452716827392578, 11.524234771728516, 12.595748901367188, 13.667266845703125, 14.738784790039062, 15.810298919677734, 16.881816864013672, 17.95333480834961, 19.02484893798828, 20.09636688232422, 21.167884826660156, 22.239402770996094, 23.3109130859375, 24.382431030273438, 25.453948974609375]}, "_runtime": 123.93381404876709, "_timestamp": 1585076378.2792773, "_step": 98}
{"Episode reward": -97.90764326451017, "Episode length": 999, "Policy Loss": -12.350218772888184, "Value Loss": 0.027937425300478935, "_runtime": 125.05035018920898, "_timestamp": 1585076379.3958135, "_step": 99}
{"Episode reward": -100.4697362679438, "Episode length": 999, "Policy Loss": -12.904309272766113, "Value Loss": 0.03156246989965439, "_runtime": 125.64119529724121, "_timestamp": 1585076379.9866586, "_step": 100}
{"Episode reward": 48.599214779351804, "Episode length": 480, "Policy Loss": 17.359521865844727, "Value Loss": 20.89682960510254, "_runtime": 126.73918795585632, "_timestamp": 1585076381.0846512, "_step": 101}
{"Episode reward": -93.42360130965635, "Episode length": 999, "Policy Loss": -11.654075622558594, "Value Loss": 0.026074642315506935, "_runtime": 127.91983103752136, "_timestamp": 1585076382.2652943, "_step": 102}
{"Episode reward": -95.97374812095786, "Episode length": 999, "Policy Loss": -12.08144760131836, "Value Loss": 0.027615079656243324, "_runtime": 129.01314759254456, "_timestamp": 1585076383.3586109, "_step": 103}
{"Episode reward": -98.83807158887369, "Episode length": 999, "Policy Loss": -12.677923202514648, "Value Loss": 0.027977995574474335, "_runtime": 130.14035058021545, "_timestamp": 1585076384.4858139, "_step": 104}
{"Episode reward": -104.79119380911136, "Episode length": 999, "Policy Loss": -13.783920288085938, "Value Loss": 0.031501371413469315, "_runtime": 131.29043769836426, "_timestamp": 1585076385.635901, "_step": 105}
{"Episode reward": -98.514875971071, "Episode length": 999, "Policy Loss": -12.54859733581543, "Value Loss": 0.03037516213953495, "_runtime": 132.42237854003906, "_timestamp": 1585076386.7678418, "_step": 106}
{"Episode reward": -102.48406556681903, "Episode length": 999, "Policy Loss": -13.123607635498047, "Value Loss": 0.031883325427770615, "_runtime": 133.58908414840698, "_timestamp": 1585076387.9345474, "_step": 107}
{"Episode reward": -105.16520052550086, "Episode length": 999, "Policy Loss": -13.952598571777344, "Value Loss": 0.032442595809698105, "_runtime": 134.7397780418396, "_timestamp": 1585076389.0852413, "_step": 108}
{"Episode reward": -106.1956664056428, "Episode length": 999, "Policy Loss": -13.919906616210938, "Value Loss": 0.03448377922177315, "_runtime": 135.9093873500824, "_timestamp": 1585076390.2548506, "_step": 109}
{"Episode reward": -102.28583772925741, "Episode length": 999, "Policy Loss": -13.015013694763184, "Value Loss": 0.030212732031941414, "_runtime": 137.06639504432678, "_timestamp": 1585076391.4118583, "_step": 110}
{"Episode reward": -96.02454888724786, "Episode length": 999, "Policy Loss": -12.442544937133789, "Value Loss": 0.027130993083119392, "_runtime": 138.21213221549988, "_timestamp": 1585076392.5575955, "_step": 111}
{"Episode reward": -94.77580855271064, "Episode length": 999, "Policy Loss": -11.717371940612793, "Value Loss": 0.028020653873682022, "_runtime": 139.3646936416626, "_timestamp": 1585076393.710157, "_step": 112}
{"Episode reward": -104.89823620464269, "Episode length": 999, "Policy Loss": -13.952733039855957, "Value Loss": 0.03495939448475838, "_runtime": 140.48286843299866, "_timestamp": 1585076394.8283317, "_step": 113}
{"Episode reward": -100.95666823647925, "Episode length": 999, "Policy Loss": -13.337682723999023, "Value Loss": 0.03039701282978058, "_runtime": 141.60858154296875, "_timestamp": 1585076395.9540448, "_step": 114}
{"Episode reward": -98.67181935358708, "Episode length": 999, "Policy Loss": -12.578466415405273, "Value Loss": 0.03129874914884567, "_runtime": 142.74406147003174, "_timestamp": 1585076397.0895247, "_step": 115}
{"Episode reward": -95.36860554572876, "Episode length": 999, "Policy Loss": -12.163824081420898, "Value Loss": 0.0257757268846035, "_runtime": 143.88551330566406, "_timestamp": 1585076398.2309766, "_step": 116}
{"Episode reward": -97.49333580876069, "Episode length": 999, "Policy Loss": -12.505117416381836, "Value Loss": 0.02770807221531868, "_runtime": 145.00635886192322, "_timestamp": 1585076399.3518221, "_step": 117}
{"Episode reward": -94.46475909999556, "Episode length": 999, "Policy Loss": -11.790472030639648, "Value Loss": 0.02675476111471653, "_runtime": 146.1621413230896, "_timestamp": 1585076400.5076046, "_step": 118}
{"Episode reward": -107.5093853237424, "Episode length": 999, "Policy Loss": -14.12922477722168, "Value Loss": 0.03665543347597122, "_runtime": 147.30371379852295, "_timestamp": 1585076401.649177, "_step": 119}
{"Episode reward": -105.32933302681134, "Episode length": 999, "Policy Loss": -13.669978141784668, "Value Loss": 0.036456309258937836, "_runtime": 148.46673202514648, "_timestamp": 1585076402.8121953, "_step": 120}
{"Episode reward": -95.54294407329259, "Episode length": 999, "Policy Loss": -12.184104919433594, "Value Loss": 0.027042221277952194, "_runtime": 149.61656022071838, "_timestamp": 1585076403.9620235, "_step": 121}
{"Episode reward": -98.80590919082483, "Episode length": 999, "Policy Loss": -12.390746116638184, "Value Loss": 0.032005418092012405, "_runtime": 150.76124382019043, "_timestamp": 1585076405.106707, "_step": 122}
{"Episode reward": -93.61934623427766, "Episode length": 999, "Policy Loss": -11.64162540435791, "Value Loss": 0.027243006974458694, "_runtime": 151.9482548236847, "_timestamp": 1585076406.293718, "_step": 123}
{"Episode reward": -106.56060909629717, "Episode length": 999, "Policy Loss": -13.998934745788574, "Value Loss": 0.03392777964472771, "_runtime": 153.11726641654968, "_timestamp": 1585076407.4627297, "_step": 124}
{"Episode reward": -97.4304542182024, "Episode length": 999, "Policy Loss": -12.415751457214355, "Value Loss": 0.029438721016049385, "_runtime": 154.23830580711365, "_timestamp": 1585076408.583769, "_step": 125}
{"Episode reward": -97.64501182444985, "Episode length": 999, "Policy Loss": -12.537225723266602, "Value Loss": 0.028890125453472137, "_runtime": 155.38424587249756, "_timestamp": 1585076409.7297091, "_step": 126}
{"Episode reward": -99.616725829967, "Episode length": 999, "Policy Loss": -12.803731918334961, "Value Loss": 0.030589645728468895, "_runtime": 156.4967679977417, "_timestamp": 1585076410.8422313, "_step": 127}
{"Episode reward": -98.69104389379828, "Episode length": 999, "Policy Loss": -12.743735313415527, "Value Loss": 0.02827572077512741, "_runtime": 157.61664605140686, "_timestamp": 1585076411.9621093, "_step": 128}
{"Episode reward": -105.76599484546173, "Episode length": 999, "Policy Loss": -13.719700813293457, "Value Loss": 0.03369584679603577, "_runtime": 158.80181097984314, "_timestamp": 1585076413.1472743, "_step": 129}
{"Episode reward": -105.90876795869093, "Episode length": 999, "Policy Loss": -13.761019706726074, "Value Loss": 0.03382354602217674, "_runtime": 159.96719694137573, "_timestamp": 1585076414.3126602, "_step": 130}
{"Episode reward": -96.83064125634388, "Episode length": 999, "Policy Loss": -12.399017333984375, "Value Loss": 0.028374439105391502, "_runtime": 161.09703946113586, "_timestamp": 1585076415.4425027, "_step": 131}
{"Episode reward": -102.80556224851355, "Episode length": 999, "Policy Loss": -13.479022026062012, "Value Loss": 0.033674731850624084, "_runtime": 162.26815366744995, "_timestamp": 1585076416.613617, "_step": 132}
{"Episode reward": -100.48802616312406, "Episode length": 999, "Policy Loss": -12.938237190246582, "Value Loss": 0.03129616752266884, "_runtime": 163.42896246910095, "_timestamp": 1585076417.7744257, "_step": 133}
{"Episode reward": -100.19325660312029, "Episode length": 999, "Policy Loss": -13.168045997619629, "Value Loss": 0.030631449073553085, "_runtime": 164.62398624420166, "_timestamp": 1585076418.9694495, "_step": 134}
{"Episode reward": -94.54272992202107, "Episode length": 999, "Policy Loss": -11.972354888916016, "Value Loss": 0.027902929112315178, "_runtime": 165.7562017440796, "_timestamp": 1585076420.101665, "_step": 135}
{"Episode reward": -104.96913513069458, "Episode length": 999, "Policy Loss": -13.895881652832031, "Value Loss": 0.0329737588763237, "_runtime": 166.9231834411621, "_timestamp": 1585076421.2686467, "_step": 136}
{"Episode reward": -102.36886533285201, "Episode length": 999, "Policy Loss": -13.121331214904785, "Value Loss": 0.033058296889066696, "_runtime": 168.07767701148987, "_timestamp": 1585076422.4231403, "_step": 137}
{"Episode reward": -108.20941579541132, "Episode length": 999, "Policy Loss": -14.08120059967041, "Value Loss": 0.034288544207811356, "_runtime": 169.1903693675995, "_timestamp": 1585076423.5358326, "_step": 138}
{"Episode reward": -103.72799053209454, "Episode length": 999, "Policy Loss": -13.422978401184082, "Value Loss": 0.029594209045171738, "_runtime": 170.3719458580017, "_timestamp": 1585076424.7174091, "_step": 139}
{"Episode reward": -95.22162729310108, "Episode length": 999, "Policy Loss": -12.002495765686035, "Value Loss": 0.027085110545158386, "_runtime": 171.52867531776428, "_timestamp": 1585076425.8741386, "_step": 140}
{"Episode reward": -99.38500723172011, "Episode length": 999, "Policy Loss": -12.973785400390625, "Value Loss": 0.02896372228860855, "_runtime": 172.6801962852478, "_timestamp": 1585076427.0256596, "_step": 141}
{"Episode reward": -107.64078237784786, "Episode length": 999, "Policy Loss": -14.381500244140625, "Value Loss": 0.03168661147356033, "_runtime": 173.8646056652069, "_timestamp": 1585076428.210069, "_step": 142}
{"Episode reward": -106.208159174699, "Episode length": 999, "Policy Loss": -13.918397903442383, "Value Loss": 0.03380368649959564, "_runtime": 175.01764726638794, "_timestamp": 1585076429.3631105, "_step": 143}
{"Episode reward": -105.17117218405528, "Episode length": 999, "Policy Loss": -13.61085033416748, "Value Loss": 0.03647245466709137, "_runtime": 176.1486520767212, "_timestamp": 1585076430.4941154, "_step": 144}
{"Episode reward": -96.32002048675041, "Episode length": 999, "Policy Loss": -12.278707504272461, "Value Loss": 0.02723277546465397, "_runtime": 177.2910873889923, "_timestamp": 1585076431.6365507, "_step": 145}
{"Episode reward": -100.56545144477265, "Episode length": 999, "Policy Loss": -12.878852844238281, "Value Loss": 0.03131367638707161, "_runtime": 178.42209839820862, "_timestamp": 1585076432.7675617, "_step": 146}
{"Episode reward": -98.08136025869044, "Episode length": 999, "Policy Loss": -12.598443984985352, "Value Loss": 0.028751617297530174, "_runtime": 179.59026455879211, "_timestamp": 1585076433.9357278, "_step": 147}
{"Episode reward": -98.41438639380148, "Episode length": 999, "Policy Loss": -12.368473052978516, "Value Loss": 0.028643669560551643, "_runtime": 180.7359721660614, "_timestamp": 1585076435.0814354, "_step": 148}
{"Episode reward": -96.03868338595103, "Episode length": 999, "Policy Loss": -12.379424095153809, "Value Loss": 0.02760152332484722, "_runtime": 181.9018156528473, "_timestamp": 1585076436.247279, "_step": 149}
{"Episode reward": -113.88099960544761, "Episode length": 999, "Policy Loss": -15.450600624084473, "Value Loss": 0.040712978690862656, "_runtime": 183.0623881816864, "_timestamp": 1585076437.4078515, "_step": 150}
{"Episode reward": -105.81727796850788, "Episode length": 999, "Policy Loss": -13.782632827758789, "Value Loss": 0.033216748386621475, "_runtime": 184.21795678138733, "_timestamp": 1585076438.56342, "_step": 151}
{"Episode reward": -98.81410560314369, "Episode length": 999, "Policy Loss": -12.737746238708496, "Value Loss": 0.029011934995651245, "_runtime": 185.37701106071472, "_timestamp": 1585076439.7224743, "_step": 152}
{"Episode reward": -99.60183139682147, "Episode length": 999, "Policy Loss": -12.791321754455566, "Value Loss": 0.02666609175503254, "_runtime": 186.52255725860596, "_timestamp": 1585076440.8680205, "_step": 153}
{"Episode reward": -102.85828924646282, "Episode length": 999, "Policy Loss": -13.31828784942627, "Value Loss": 0.030031422153115273, "_runtime": 187.70450377464294, "_timestamp": 1585076442.049967, "_step": 154}
{"Episode reward": -102.67635811401797, "Episode length": 999, "Policy Loss": -13.205531120300293, "Value Loss": 0.03085295669734478, "_runtime": 188.88895797729492, "_timestamp": 1585076443.2344213, "_step": 155}
{"Episode reward": -100.98412015471568, "Episode length": 999, "Policy Loss": -12.983413696289062, "Value Loss": 0.027515802532434464, "_runtime": 189.9944064617157, "_timestamp": 1585076444.3398697, "_step": 156}
{"Episode reward": -102.87577500853956, "Episode length": 999, "Policy Loss": -13.093832969665527, "Value Loss": 0.03213116526603699, "_runtime": 191.1099317073822, "_timestamp": 1585076445.455395, "_step": 157}
{"Episode reward": -99.06115092535221, "Episode length": 999, "Policy Loss": -12.39687728881836, "Value Loss": 0.029923787340521812, "_runtime": 192.28031158447266, "_timestamp": 1585076446.6257749, "_step": 158}
{"Episode reward": -97.61245545644502, "Episode length": 999, "Policy Loss": -12.282438278198242, "Value Loss": 0.028446923941373825, "_runtime": 193.43640756607056, "_timestamp": 1585076447.7818708, "_step": 159}
{"Episode reward": -96.72822869177187, "Episode length": 999, "Policy Loss": -12.321001052856445, "Value Loss": 0.026707755401730537, "_runtime": 194.60963940620422, "_timestamp": 1585076448.9551027, "_step": 160}
{"Episode reward": -109.27520640039887, "Episode length": 999, "Policy Loss": -14.20777416229248, "Value Loss": 0.03568825125694275, "_runtime": 195.74483346939087, "_timestamp": 1585076450.0902967, "_step": 161}
{"Episode reward": -88.95122157537843, "Episode length": 999, "Policy Loss": -11.028631210327148, "Value Loss": 0.0245575662702322, "_runtime": 196.79402351379395, "_timestamp": 1585076451.1394868, "_step": 162}
{"Episode reward": 4.708522419206204, "Episode length": 926, "Policy Loss": 2.982964515686035, "Value Loss": 10.8272066116333, "_runtime": 197.94207382202148, "_timestamp": 1585076452.287537, "_step": 163}
{"Episode reward": -97.02594794820898, "Episode length": 999, "Policy Loss": -12.453937530517578, "Value Loss": 0.02984759397804737, "_runtime": 199.09018683433533, "_timestamp": 1585076453.43565, "_step": 164}
{"Episode reward": -102.89213965573339, "Episode length": 999, "Policy Loss": -13.044936180114746, "Value Loss": 0.03220265358686447, "_runtime": 200.21100616455078, "_timestamp": 1585076454.5564694, "_step": 165}
{"Episode reward": -94.13647314615716, "Episode length": 999, "Policy Loss": -11.733278274536133, "Value Loss": 0.027405209839344025, "_runtime": 201.36118578910828, "_timestamp": 1585076455.706649, "_step": 166}
{"Episode reward": -107.8802657072753, "Episode length": 999, "Policy Loss": -14.206477165222168, "Value Loss": 0.03404255211353302, "_runtime": 202.55605936050415, "_timestamp": 1585076456.9015226, "_step": 167}
{"Episode reward": -96.337622274057, "Episode length": 999, "Policy Loss": -12.125138282775879, "Value Loss": 0.02648863196372986, "_runtime": 203.73013925552368, "_timestamp": 1585076458.0756025, "_step": 168}
{"Episode reward": -102.16689092271191, "Episode length": 999, "Policy Loss": -13.386171340942383, "Value Loss": 0.029295094311237335, "_runtime": 204.9022023677826, "_timestamp": 1585076459.2476656, "_step": 169}
{"Episode reward": -103.12689477307681, "Episode length": 999, "Policy Loss": -13.525132179260254, "Value Loss": 0.031738702207803726, "_runtime": 206.04314374923706, "_timestamp": 1585076460.388607, "_step": 170}
{"Episode reward": -102.62516951928446, "Episode length": 999, "Policy Loss": -13.18883991241455, "Value Loss": 0.030954215675592422, "_runtime": 207.19046473503113, "_timestamp": 1585076461.535928, "_step": 171}
{"Episode reward": -97.0792017656575, "Episode length": 999, "Policy Loss": -12.488935470581055, "Value Loss": 0.029744664207100868, "_runtime": 208.40616822242737, "_timestamp": 1585076462.7516315, "_step": 172}
{"Episode reward": -96.41584784863691, "Episode length": 999, "Policy Loss": -12.15107250213623, "Value Loss": 0.0299794003367424, "_runtime": 209.55330634117126, "_timestamp": 1585076463.8987696, "_step": 173}
{"Episode reward": -96.01804215741414, "Episode length": 999, "Policy Loss": -12.500438690185547, "Value Loss": 0.02960972674190998, "_runtime": 210.667644739151, "_timestamp": 1585076465.013108, "_step": 174}
{"Episode reward": -97.99142531340885, "Episode length": 999, "Policy Loss": -12.382123947143555, "Value Loss": 0.02728251740336418, "_runtime": 211.84478855133057, "_timestamp": 1585076466.1902518, "_step": 175}
{"Episode reward": -110.0161558863803, "Episode length": 999, "Policy Loss": -14.471181869506836, "Value Loss": 0.035499218851327896, "_runtime": 213.00553584098816, "_timestamp": 1585076467.350999, "_step": 176}
{"Episode reward": -102.40657767268891, "Episode length": 999, "Policy Loss": -13.130611419677734, "Value Loss": 0.032395172864198685, "_runtime": 214.18829584121704, "_timestamp": 1585076468.533759, "_step": 177}
{"Episode reward": -96.10454697960755, "Episode length": 999, "Policy Loss": -12.186025619506836, "Value Loss": 0.026895927265286446, "_runtime": 215.3885636329651, "_timestamp": 1585076469.734027, "_step": 178}
{"Episode reward": -92.36584760084143, "Episode length": 999, "Policy Loss": -11.611526489257812, "Value Loss": 0.026364384219050407, "_runtime": 216.51612997055054, "_timestamp": 1585076470.8615932, "_step": 179}
{"Episode reward": -96.45564506773161, "Episode length": 999, "Policy Loss": -12.315272331237793, "Value Loss": 0.030757803469896317, "_runtime": 217.63172316551208, "_timestamp": 1585076471.9771864, "_step": 180}
{"Episode reward": -97.92681573815227, "Episode length": 999, "Policy Loss": -12.286128044128418, "Value Loss": 0.03204184025526047, "_runtime": 218.78436589241028, "_timestamp": 1585076473.1298292, "_step": 181}
{"Episode reward": -99.98257693443429, "Episode length": 999, "Policy Loss": -12.982454299926758, "Value Loss": 0.03207622841000557, "_runtime": 219.92241549491882, "_timestamp": 1585076474.2678788, "_step": 182}
{"Episode reward": -100.20951106539475, "Episode length": 999, "Policy Loss": -12.63196849822998, "Value Loss": 0.031636953353881836, "_runtime": 221.0743989944458, "_timestamp": 1585076475.4198623, "_step": 183}
{"Episode reward": -97.65615953703507, "Episode length": 999, "Policy Loss": -12.489358901977539, "Value Loss": 0.030781468376517296, "_runtime": 222.2573118209839, "_timestamp": 1585076476.602775, "_step": 184}
{"Episode reward": -104.42617664810979, "Episode length": 999, "Policy Loss": -13.84555435180664, "Value Loss": 0.03236093372106552, "_runtime": 223.38713550567627, "_timestamp": 1585076477.7325988, "_step": 185}
{"Episode reward": -101.55974560241992, "Episode length": 999, "Policy Loss": -13.087408065795898, "Value Loss": 0.030986499041318893, "_runtime": 224.57582306861877, "_timestamp": 1585076478.9212863, "_step": 186}
{"Episode reward": -99.78535636386115, "Episode length": 999, "Policy Loss": -12.66805648803711, "Value Loss": 0.029095008969306946, "_runtime": 225.76086902618408, "_timestamp": 1585076480.1063323, "_step": 187}
{"Episode reward": -100.80533509015727, "Episode length": 999, "Policy Loss": -12.67042350769043, "Value Loss": 0.032506220042705536, "_runtime": 226.90029573440552, "_timestamp": 1585076481.245759, "_step": 188}
{"Episode reward": -111.2440828362386, "Episode length": 999, "Policy Loss": -14.68813419342041, "Value Loss": 0.03621806204319, "_runtime": 228.1156349182129, "_timestamp": 1585076482.4610982, "_step": 189}
{"Episode reward": -96.91917863792894, "Episode length": 999, "Policy Loss": -12.50616455078125, "Value Loss": 0.02861812897026539, "_runtime": 229.26045775413513, "_timestamp": 1585076483.605921, "_step": 190}
{"Episode reward": -99.97744052782843, "Episode length": 999, "Policy Loss": -13.028404235839844, "Value Loss": 0.030897680670022964, "_runtime": 230.43472743034363, "_timestamp": 1585076484.7801907, "_step": 191}
{"Episode reward": -94.34612728893535, "Episode length": 999, "Policy Loss": -11.813667297363281, "Value Loss": 0.026948107406497, "_runtime": 231.58264017105103, "_timestamp": 1585076485.9281034, "_step": 192}
{"Episode reward": -101.90548302889485, "Episode length": 999, "Policy Loss": -13.270947456359863, "Value Loss": 0.03357867896556854, "_runtime": 232.78063321113586, "_timestamp": 1585076487.1260965, "_step": 193}
{"Episode reward": -97.9572075944143, "Episode length": 999, "Policy Loss": -12.404996871948242, "Value Loss": 0.028985992074012756, "_runtime": 233.95470881462097, "_timestamp": 1585076488.300172, "_step": 194}
{"Episode reward": -103.49611653975637, "Episode length": 999, "Policy Loss": -13.695332527160645, "Value Loss": 0.031832609325647354, "_runtime": 235.12484884262085, "_timestamp": 1585076489.470312, "_step": 195}
{"Episode reward": -108.51521578043348, "Episode length": 999, "Policy Loss": -14.49481201171875, "Value Loss": 0.03554750233888626, "_runtime": 236.27625274658203, "_timestamp": 1585076490.621716, "_step": 196}
{"Episode reward": -108.48213772950396, "Episode length": 999, "Policy Loss": -14.209174156188965, "Value Loss": 0.03365650773048401, "_runtime": 237.3932101726532, "_timestamp": 1585076491.7386734, "_step": 197}
{"Episode reward": -100.14528722822851, "Episode length": 999, "Policy Loss": -12.863092422485352, "Value Loss": 0.03072136826813221, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594, 195.04368591308594]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-110.38677978515625, -105.61139678955078, -100.83601379394531, -96.06063079833984, -91.28524780273438, -86.5098648071289, -81.73448181152344, -76.95909881591797, -72.1837158203125, -67.40833282470703, -62.63294982910156, -57.857566833496094, -53.082183837890625, -48.306800842285156, -43.53141784667969, -38.75603485107422, -33.98065185546875, -29.20526885986328, -24.429885864257812, -19.654502868652344, -14.879119873046875, -10.103736877441406, -5.3283538818359375, -0.5529708862304688, 4.222412109375, 8.997795104980469, 13.773178100585938, 18.548553466796875, 23.323944091796875, 28.099334716796875, 32.87471008300781, 37.65008544921875, 42.42547607421875, 47.20086669921875, 51.97624206542969, 56.751617431640625, 61.527008056640625, 66.30239868164062, 71.07777404785156, 75.8531494140625, 80.6285400390625, 85.4039306640625, 90.17930603027344, 94.95468139648438, 99.73007202148438, 104.50546264648438, 109.28083801269531, 114.05621337890625, 118.83160400390625, 123.60699462890625, 128.3823699951172, 133.15774536132812, 137.93313598632812, 142.70852661132812, 147.48388671875, 152.25927734375, 157.03466796875, 161.81005859375, 166.58544921875, 171.36080932617188, 176.13619995117188, 180.91159057617188, 185.68695068359375, 190.46234130859375, 195.23773193359375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-107.07765197753906, -103.94304656982422, -100.80844116210938, -97.673828125, -94.53922271728516, -91.40461730957031, -88.27001190185547, -85.13540649414062, -82.00079345703125, -78.8661880493164, -75.73158264160156, -72.59697723388672, -69.46237182617188, -66.3277587890625, -63.19315719604492, -60.05854797363281, -56.92394256591797, -53.789337158203125, -50.654727935791016, -47.52012252807617, -44.38551330566406, -41.25090789794922, -38.116302490234375, -34.98169708251953, -31.847091674804688, -28.712478637695312, -25.57787322998047, -22.443267822265625, -19.30866241455078, -16.174057006835938, -13.039443969726562, -9.904838562011719, -6.770233154296875, -3.6356277465820312, -0.5010223388671875, 2.6335906982421875, 5.768196105957031, 8.902801513671875, 12.037406921386719, 15.172012329101562, 18.306625366210938, 21.44122314453125, 24.575836181640625, 27.71044921875, 30.845046997070312, 33.97966003417969, 37.1142578125, 40.248870849609375, 43.38346862792969, 46.51808166503906, 49.65269470214844, 52.78729248046875, 55.921905517578125, 59.05650329589844, 62.19111633300781, 65.32572937011719, 68.4603271484375, 71.59494018554688, 74.72953796386719, 77.86415100097656, 80.99876403808594, 84.13336181640625, 87.26797485351562, 90.40257263183594, 93.53718566894531]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 8.0, 5.0, 5.0, 8.0, 13.0, 11.0, 10.0, 9.0, 16.0, 16.0, 20.0, 23.0, 48.0, 46.0, 35.0, 38.0, 29.0, 34.0, 28.0, 17.0, 16.0, 9.0, 4.0, 6.0, 6.0, 5.0, 2.0, 0.0, 4.0, 7.0, 5.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0], "bins": [-98.7026596069336, -95.81321716308594, -92.92378234863281, -90.03433990478516, -87.1448974609375, -84.25546264648438, -81.36602020263672, -78.47657775878906, -75.58714294433594, -72.69770050048828, -69.80825805664062, -66.9188232421875, -64.02938079833984, -61.13994216918945, -58.25050354003906, -55.361061096191406, -52.471622467041016, -49.582183837890625, -46.69274139404297, -43.80330276489258, -40.91386413574219, -38.02442169189453, -35.13498306274414, -32.24554443359375, -29.356101989746094, -26.46666717529297, -23.577224731445312, -20.687782287597656, -17.79834747314453, -14.908905029296875, -12.019462585449219, -9.130027770996094, -6.2405853271484375, -3.3511428833007812, -0.46170806884765625, 2.427734375, 5.317176818847656, 8.206611633300781, 11.096054077148438, 13.985496520996094, 16.87493133544922, 19.764373779296875, 22.65381622314453, 25.543251037597656, 28.432693481445312, 31.32213592529297, 34.211570739746094, 37.10100555419922, 39.990455627441406, 42.87989044189453, 45.769325256347656, 48.658775329589844, 51.54821014404297, 54.437644958496094, 57.32709503173828, 60.216529846191406, 63.10596466064453, 65.99541473388672, 68.88484954833984, 71.77428436279297, 74.66373443603516, 77.55316925048828, 80.4426040649414, 83.3320541381836, 86.22148895263672]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-38.425472259521484, -36.672672271728516, -34.91986846923828, -33.16706848144531, -31.41426658630371, -29.66146469116211, -27.90866470336914, -26.15586280822754, -24.403060913085938, -22.650259017944336, -20.897457122802734, -19.144657135009766, -17.391855239868164, -15.639053344726562, -13.886253356933594, -12.133451461791992, -10.38064956665039, -8.627847671508789, -6.8750457763671875, -5.122245788574219, -3.3694419860839844, -1.6166419982910156, 0.13615798950195312, 1.8889617919921875, 3.6417617797851562, 5.394561767578125, 7.147365570068359, 8.900165557861328, 10.652965545654297, 12.405769348144531, 14.1585693359375, 15.911373138427734, 17.664173126220703, 19.416973114013672, 21.169776916503906, 22.922576904296875, 24.67538070678711, 26.428180694580078, 28.180980682373047, 29.933780670166016, 31.686588287353516, 33.439388275146484, 35.19218826293945, 36.94498825073242, 38.69778823852539, 40.45058822631836, 42.20339584350586, 43.95619583129883, 45.7089958190918, 47.461795806884766, 49.214595794677734, 50.967403411865234, 52.7202033996582, 54.47300338745117, 56.22580337524414, 57.97860336303711, 59.73140335083008, 61.48421096801758, 63.23701095581055, 64.98980712890625, 66.74261474609375, 68.49540710449219, 70.24821472167969, 72.00102233886719, 73.75381469726562]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 8.0, 16.0, 9.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0], "bins": [-61.232120513916016, -59.79808044433594, -58.36404037475586, -56.93000030517578, -55.49595642089844, -54.06191635131836, -52.62787628173828, -51.1938362121582, -49.759796142578125, -48.32575225830078, -46.8917121887207, -45.457672119140625, -44.02363204956055, -42.58959197998047, -41.155548095703125, -39.72150802612305, -38.28746795654297, -36.85342788696289, -35.41938781738281, -33.98534393310547, -32.55130386352539, -31.117263793945312, -29.683223724365234, -28.249183654785156, -26.815143585205078, -25.381099700927734, -23.947059631347656, -22.513019561767578, -21.0789794921875, -19.644939422607422, -18.210895538330078, -16.77685546875, -15.342815399169922, -13.908775329589844, -12.474735260009766, -11.040691375732422, -9.606651306152344, -8.172611236572266, -6.7385711669921875, -5.304531097412109, -3.8704872131347656, -2.4364471435546875, -1.0024070739746094, 0.43163299560546875, 1.8656730651855469, 3.2997169494628906, 4.733753204345703, 6.167797088623047, 7.601833343505859, 9.035877227783203, 10.469921112060547, 11.90395736694336, 13.338001251220703, 14.772037506103516, 16.20608139038086, 17.640125274658203, 19.074161529541016, 20.50820541381836, 21.942241668701172, 23.376285552978516, 24.81032943725586, 26.244365692138672, 27.678409576416016, 29.112445831298828, 30.546489715576172]}, "_runtime": 238.52074527740479, "_timestamp": 1585076492.8662086, "_step": 198}
{"Episode reward": -104.13525475694952, "Episode length": 999, "Policy Loss": -13.568916320800781, "Value Loss": 0.03264325112104416, "_runtime": 239.6642370223999, "_timestamp": 1585076494.0097003, "_step": 199}
{"Episode reward": -101.57405395858645, "Episode length": 999, "Policy Loss": -12.976873397827148, "Value Loss": 0.02807379513978958, "_runtime": 240.78363370895386, "_timestamp": 1585076495.129097, "_step": 200}
{"Episode reward": -98.87676233353902, "Episode length": 999, "Policy Loss": -12.809603691101074, "Value Loss": 0.030599374324083328, "_runtime": 241.94566297531128, "_timestamp": 1585076496.2911263, "_step": 201}
{"Episode reward": -103.45219725669088, "Episode length": 999, "Policy Loss": -13.586797714233398, "Value Loss": 0.031878512352705, "_runtime": 243.13686847686768, "_timestamp": 1585076497.4823318, "_step": 202}
{"Episode reward": -99.05726537566672, "Episode length": 999, "Policy Loss": -12.731673240661621, "Value Loss": 0.027785049751400948, "_runtime": 244.279541015625, "_timestamp": 1585076498.6250043, "_step": 203}
{"Episode reward": -108.75698480658596, "Episode length": 999, "Policy Loss": -14.551193237304688, "Value Loss": 0.03558920696377754, "_runtime": 245.46321558952332, "_timestamp": 1585076499.8086789, "_step": 204}
{"Episode reward": -104.54014475547021, "Episode length": 999, "Policy Loss": -13.499711990356445, "Value Loss": 0.03374321386218071, "_runtime": 246.62184834480286, "_timestamp": 1585076500.9673116, "_step": 205}
{"Episode reward": -107.90914413281412, "Episode length": 999, "Policy Loss": -14.295178413391113, "Value Loss": 0.03393831476569176, "_runtime": 247.7979474067688, "_timestamp": 1585076502.1434107, "_step": 206}
{"Episode reward": -103.70701996154821, "Episode length": 999, "Policy Loss": -13.582967758178711, "Value Loss": 0.03409483656287193, "_runtime": 248.94428157806396, "_timestamp": 1585076503.2897449, "_step": 207}
{"Episode reward": -91.57852322463096, "Episode length": 999, "Policy Loss": -11.573521614074707, "Value Loss": 0.02526388317346573, "_runtime": 250.04847049713135, "_timestamp": 1585076504.3939338, "_step": 208}
{"Episode reward": -94.9689808178384, "Episode length": 999, "Policy Loss": -11.716266632080078, "Value Loss": 0.02789856120944023, "_runtime": 251.1558337211609, "_timestamp": 1585076505.501297, "_step": 209}
{"Episode reward": -96.18831856233717, "Episode length": 999, "Policy Loss": -12.061314582824707, "Value Loss": 0.02558489516377449, "_runtime": 252.31466341018677, "_timestamp": 1585076506.6601267, "_step": 210}
{"Episode reward": -96.62445545850203, "Episode length": 999, "Policy Loss": -12.123466491699219, "Value Loss": 0.027597744017839432, "_runtime": 253.46502351760864, "_timestamp": 1585076507.8104868, "_step": 211}
{"Episode reward": -97.9619072104464, "Episode length": 999, "Policy Loss": -12.61893367767334, "Value Loss": 0.028332766145467758, "_runtime": 254.65762758255005, "_timestamp": 1585076509.0030909, "_step": 212}
{"Episode reward": -99.91273788350408, "Episode length": 999, "Policy Loss": -12.841363906860352, "Value Loss": 0.03014594502747059, "_runtime": 255.81773900985718, "_timestamp": 1585076510.1632023, "_step": 213}
{"Episode reward": -98.93257841357023, "Episode length": 999, "Policy Loss": -12.555912971496582, "Value Loss": 0.02898445725440979, "_runtime": 256.9952163696289, "_timestamp": 1585076511.3406796, "_step": 214}
{"Episode reward": -102.09018475578443, "Episode length": 999, "Policy Loss": -13.078429222106934, "Value Loss": 0.032897934317588806, "_runtime": 258.15474104881287, "_timestamp": 1585076512.5002043, "_step": 215}
{"Episode reward": -109.65791532504623, "Episode length": 999, "Policy Loss": -14.463497161865234, "Value Loss": 0.03731699287891388, "_runtime": 259.27588629722595, "_timestamp": 1585076513.6213496, "_step": 216}
{"Episode reward": -104.09281113835425, "Episode length": 999, "Policy Loss": -13.534213066101074, "Value Loss": 0.031200945377349854, "_runtime": 259.91236186027527, "_timestamp": 1585076514.2578251, "_step": 217}
{"Episode reward": 42.780185483533636, "Episode length": 555, "Policy Loss": 13.669259071350098, "Value Loss": 17.985977172851562, "_runtime": 261.0461916923523, "_timestamp": 1585076515.391655, "_step": 218}
{"Episode reward": -107.37661308302718, "Episode length": 999, "Policy Loss": -14.056053161621094, "Value Loss": 0.033625371754169464, "_runtime": 262.23305201530457, "_timestamp": 1585076516.5785153, "_step": 219}
{"Episode reward": -101.14908146132218, "Episode length": 999, "Policy Loss": -13.034506797790527, "Value Loss": 0.032595571130514145, "_runtime": 263.3452787399292, "_timestamp": 1585076517.690742, "_step": 220}
{"Episode reward": -98.54262366891226, "Episode length": 999, "Policy Loss": -12.655973434448242, "Value Loss": 0.02792058326303959, "_runtime": 264.5106723308563, "_timestamp": 1585076518.8561356, "_step": 221}
{"Episode reward": -99.99452979185976, "Episode length": 999, "Policy Loss": -12.74024486541748, "Value Loss": 0.029867297038435936, "_runtime": 265.66294145584106, "_timestamp": 1585076520.0084047, "_step": 222}
{"Episode reward": -104.38780781658515, "Episode length": 999, "Policy Loss": -13.5412015914917, "Value Loss": 0.03286733105778694, "_runtime": 266.8708145618439, "_timestamp": 1585076521.2162778, "_step": 223}
{"Episode reward": -107.05232397992796, "Episode length": 999, "Policy Loss": -13.941644668579102, "Value Loss": 0.035824283957481384, "_runtime": 268.06266593933105, "_timestamp": 1585076522.4081292, "_step": 224}
{"Episode reward": -101.30292257824465, "Episode length": 999, "Policy Loss": -13.274145126342773, "Value Loss": 0.03120557591319084, "_runtime": 269.1957519054413, "_timestamp": 1585076523.5412152, "_step": 225}
{"Episode reward": -101.23477352232008, "Episode length": 999, "Policy Loss": -12.913541793823242, "Value Loss": 0.03160364553332329, "_runtime": 270.3484265804291, "_timestamp": 1585076524.6938899, "_step": 226}
{"Episode reward": -100.34374282155827, "Episode length": 999, "Policy Loss": -12.886815071105957, "Value Loss": 0.028825975954532623, "_runtime": 271.4774658679962, "_timestamp": 1585076525.8229291, "_step": 227}
{"Episode reward": -104.91696013651311, "Episode length": 999, "Policy Loss": -13.835370063781738, "Value Loss": 0.03239709138870239, "_runtime": 272.65755891799927, "_timestamp": 1585076527.0030222, "_step": 228}
{"Episode reward": -96.01084915984288, "Episode length": 999, "Policy Loss": -12.29356861114502, "Value Loss": 0.028353745117783546, "_runtime": 273.8571546077728, "_timestamp": 1585076528.202618, "_step": 229}
{"Episode reward": -92.9247097126018, "Episode length": 999, "Policy Loss": -11.779393196105957, "Value Loss": 0.025618240237236023, "_runtime": 275.0484480857849, "_timestamp": 1585076529.3939114, "_step": 230}
{"Episode reward": -101.96719797029843, "Episode length": 999, "Policy Loss": -13.13123607635498, "Value Loss": 0.03207291290163994, "_runtime": 276.1904752254486, "_timestamp": 1585076530.5359385, "_step": 231}
{"Episode reward": -100.47203489057506, "Episode length": 999, "Policy Loss": -12.945862770080566, "Value Loss": 0.03360806033015251, "_runtime": 277.33222579956055, "_timestamp": 1585076531.677689, "_step": 232}
{"Episode reward": -91.01955839419801, "Episode length": 999, "Policy Loss": -11.454170227050781, "Value Loss": 0.026617402210831642, "_runtime": 278.46392369270325, "_timestamp": 1585076532.809387, "_step": 233}
{"Episode reward": -107.02628998495513, "Episode length": 999, "Policy Loss": -14.131476402282715, "Value Loss": 0.03377378359436989, "_runtime": 279.6028687953949, "_timestamp": 1585076533.948332, "_step": 234}
{"Episode reward": -100.33884702248687, "Episode length": 999, "Policy Loss": -13.004207611083984, "Value Loss": 0.025008616968989372, "_runtime": 280.72568011283875, "_timestamp": 1585076535.0711434, "_step": 235}
{"Episode reward": -104.60424519125911, "Episode length": 999, "Policy Loss": -13.738846778869629, "Value Loss": 0.03386301174759865, "_runtime": 281.90625977516174, "_timestamp": 1585076536.251723, "_step": 236}
{"Episode reward": -102.22892242689984, "Episode length": 999, "Policy Loss": -13.19931411743164, "Value Loss": 0.030810866504907608, "_runtime": 283.0511269569397, "_timestamp": 1585076537.3965902, "_step": 237}
{"Episode reward": -100.52686231029536, "Episode length": 999, "Policy Loss": -13.00092601776123, "Value Loss": 0.029364338144659996, "_runtime": 284.16364669799805, "_timestamp": 1585076538.50911, "_step": 238}
{"Episode reward": -95.34289921985807, "Episode length": 999, "Policy Loss": -12.086385726928711, "Value Loss": 0.029110446572303772, "_runtime": 285.3408250808716, "_timestamp": 1585076539.6862884, "_step": 239}
{"Episode reward": -103.7914940793102, "Episode length": 999, "Policy Loss": -13.85793685913086, "Value Loss": 0.029421905055642128, "_runtime": 286.45210671424866, "_timestamp": 1585076540.79757, "_step": 240}
{"Episode reward": -105.32300252231595, "Episode length": 999, "Policy Loss": -13.864115715026855, "Value Loss": 0.0349600687623024, "_runtime": 287.5655462741852, "_timestamp": 1585076541.9110096, "_step": 241}
{"Episode reward": -99.55146715362083, "Episode length": 999, "Policy Loss": -12.629714965820312, "Value Loss": 0.030909748747944832, "_runtime": 288.71355390548706, "_timestamp": 1585076543.0590172, "_step": 242}
{"Episode reward": -104.70741525024002, "Episode length": 999, "Policy Loss": -14.095868110656738, "Value Loss": 0.03185540810227394, "_runtime": 289.84102392196655, "_timestamp": 1585076544.1864872, "_step": 243}
{"Episode reward": -103.0733661672133, "Episode length": 999, "Policy Loss": -13.348855018615723, "Value Loss": 0.03267937898635864, "_runtime": 290.95664739608765, "_timestamp": 1585076545.3021107, "_step": 244}
{"Episode reward": -106.14342041415905, "Episode length": 999, "Policy Loss": -13.820587158203125, "Value Loss": 0.03405814245343208, "_runtime": 292.10203528404236, "_timestamp": 1585076546.4474986, "_step": 245}
{"Episode reward": -108.50387679128514, "Episode length": 999, "Policy Loss": -14.426263809204102, "Value Loss": 0.03429267182946205, "_runtime": 293.2339961528778, "_timestamp": 1585076547.5794594, "_step": 246}
{"Episode reward": -106.34657504867393, "Episode length": 999, "Policy Loss": -13.857504844665527, "Value Loss": 0.033701010048389435, "_runtime": 294.3630156517029, "_timestamp": 1585076548.708479, "_step": 247}
{"Episode reward": -99.72818422312065, "Episode length": 999, "Policy Loss": -12.721569061279297, "Value Loss": 0.0326681025326252, "_runtime": 295.52744007110596, "_timestamp": 1585076549.8729033, "_step": 248}
{"Episode reward": -92.85154849538077, "Episode length": 999, "Policy Loss": -11.759530067443848, "Value Loss": 0.02690410427749157, "_runtime": 296.64666771888733, "_timestamp": 1585076550.992131, "_step": 249}
{"Episode reward": -103.07754410598207, "Episode length": 999, "Policy Loss": -13.566683769226074, "Value Loss": 0.033293772488832474, "_runtime": 297.7680764198303, "_timestamp": 1585076552.1135397, "_step": 250}
{"Episode reward": -105.22371954883766, "Episode length": 999, "Policy Loss": -13.83886432647705, "Value Loss": 0.03703806549310684, "_runtime": 298.91750407218933, "_timestamp": 1585076553.2629673, "_step": 251}
{"Episode reward": -99.02498024865818, "Episode length": 999, "Policy Loss": -12.883427619934082, "Value Loss": 0.02647850476205349, "_runtime": 300.0346703529358, "_timestamp": 1585076554.3801336, "_step": 252}
{"Episode reward": -97.83414630054688, "Episode length": 999, "Policy Loss": -12.507951736450195, "Value Loss": 0.02922353707253933, "_runtime": 301.1449143886566, "_timestamp": 1585076555.4903777, "_step": 253}
{"Episode reward": -91.59180601818598, "Episode length": 999, "Policy Loss": -11.216822624206543, "Value Loss": 0.024859247729182243, "_runtime": 302.29926919937134, "_timestamp": 1585076556.6447325, "_step": 254}
{"Episode reward": -96.38130075782247, "Episode length": 999, "Policy Loss": -12.424150466918945, "Value Loss": 0.028551293537020683, "_runtime": 303.42166805267334, "_timestamp": 1585076557.7671313, "_step": 255}
{"Episode reward": -98.72174096218652, "Episode length": 999, "Policy Loss": -12.670961380004883, "Value Loss": 0.0269467793405056, "_runtime": 304.62454652786255, "_timestamp": 1585076558.9700098, "_step": 256}
{"Episode reward": -98.70744109998063, "Episode length": 999, "Policy Loss": -12.462958335876465, "Value Loss": 0.032349854707717896, "_runtime": 305.73728036880493, "_timestamp": 1585076560.0827436, "_step": 257}
{"Episode reward": -94.29795231225312, "Episode length": 999, "Policy Loss": -12.092775344848633, "Value Loss": 0.027485240250825882, "_runtime": 306.85377621650696, "_timestamp": 1585076561.1992395, "_step": 258}
{"Episode reward": -99.48421917286453, "Episode length": 999, "Policy Loss": -12.842391014099121, "Value Loss": 0.028847405686974525, "_runtime": 308.01376700401306, "_timestamp": 1585076562.3592303, "_step": 259}
{"Episode reward": -99.3400585110065, "Episode length": 999, "Policy Loss": -12.625872611999512, "Value Loss": 0.029918216168880463, "_runtime": 309.14127802848816, "_timestamp": 1585076563.4867413, "_step": 260}
{"Episode reward": -99.56396001952567, "Episode length": 999, "Policy Loss": -12.89378833770752, "Value Loss": 0.0288536436855793, "_runtime": 310.26192021369934, "_timestamp": 1585076564.6073835, "_step": 261}
{"Episode reward": -105.48144294380278, "Episode length": 999, "Policy Loss": -13.75236701965332, "Value Loss": 0.035094328224658966, "_runtime": 311.4037449359894, "_timestamp": 1585076565.7492082, "_step": 262}
{"Episode reward": -97.50592042641222, "Episode length": 999, "Policy Loss": -12.098103523254395, "Value Loss": 0.030182387679815292, "_runtime": 312.5886993408203, "_timestamp": 1585076566.9341626, "_step": 263}
{"Episode reward": -105.51883071796502, "Episode length": 999, "Policy Loss": -13.91123104095459, "Value Loss": 0.03145907074213028, "_runtime": 313.7792332172394, "_timestamp": 1585076568.1246965, "_step": 264}
{"Episode reward": -93.59627182045703, "Episode length": 999, "Policy Loss": -11.871313095092773, "Value Loss": 0.02645527757704258, "_runtime": 314.9348204135895, "_timestamp": 1585076569.2802837, "_step": 265}
{"Episode reward": -96.48231887610699, "Episode length": 999, "Policy Loss": -12.185498237609863, "Value Loss": 0.029590874910354614, "_runtime": 316.0674126148224, "_timestamp": 1585076570.412876, "_step": 266}
{"Episode reward": -91.54150453517042, "Episode length": 999, "Policy Loss": -11.484659194946289, "Value Loss": 0.02377605065703392, "_runtime": 317.21453833580017, "_timestamp": 1585076571.5600016, "_step": 267}
{"Episode reward": -93.25289265475145, "Episode length": 999, "Policy Loss": -11.518712997436523, "Value Loss": 0.02524041011929512, "_runtime": 318.32506918907166, "_timestamp": 1585076572.6705325, "_step": 268}
{"Episode reward": -99.18428407714241, "Episode length": 999, "Policy Loss": -12.808479309082031, "Value Loss": 0.028952885419130325, "_runtime": 319.4556875228882, "_timestamp": 1585076573.8011508, "_step": 269}
{"Episode reward": -105.91810606917784, "Episode length": 999, "Policy Loss": -14.087675094604492, "Value Loss": 0.03354032710194588, "_runtime": 320.5780601501465, "_timestamp": 1585076574.9235234, "_step": 270}
{"Episode reward": -99.20313414027468, "Episode length": 999, "Policy Loss": -12.917389869689941, "Value Loss": 0.03020877204835415, "_runtime": 321.77910566329956, "_timestamp": 1585076576.124569, "_step": 271}
{"Episode reward": -100.95952405871402, "Episode length": 999, "Policy Loss": -12.80734634399414, "Value Loss": 0.030700435861945152, "_runtime": 322.97925662994385, "_timestamp": 1585076577.32472, "_step": 272}
{"Episode reward": -106.74997032414204, "Episode length": 999, "Policy Loss": -14.149481773376465, "Value Loss": 0.03456813097000122, "_runtime": 324.0972800254822, "_timestamp": 1585076578.4427433, "_step": 273}
{"Episode reward": -107.98744193013214, "Episode length": 999, "Policy Loss": -14.17945671081543, "Value Loss": 0.03710024431347847, "_runtime": 325.2340705394745, "_timestamp": 1585076579.5795338, "_step": 274}
{"Episode reward": -97.36951147452963, "Episode length": 999, "Policy Loss": -12.152987480163574, "Value Loss": 0.0273300651460886, "_runtime": 326.37738060951233, "_timestamp": 1585076580.722844, "_step": 275}
{"Episode reward": -94.81753133561823, "Episode length": 999, "Policy Loss": -11.788789749145508, "Value Loss": 0.026200925931334496, "_runtime": 327.4910640716553, "_timestamp": 1585076581.8365273, "_step": 276}
{"Episode reward": -98.47358019357861, "Episode length": 999, "Policy Loss": -12.638165473937988, "Value Loss": 0.026425393298268318, "_runtime": 328.62414360046387, "_timestamp": 1585076582.9696069, "_step": 277}
{"Episode reward": -109.70910937174644, "Episode length": 999, "Policy Loss": -14.579345703125, "Value Loss": 0.038473863154649734, "_runtime": 329.7665493488312, "_timestamp": 1585076584.1120126, "_step": 278}
{"Episode reward": -98.62437227887101, "Episode length": 999, "Policy Loss": -12.561363220214844, "Value Loss": 0.03095022402703762, "_runtime": 330.87142992019653, "_timestamp": 1585076585.2168932, "_step": 279}
{"Episode reward": -95.61312214216098, "Episode length": 999, "Policy Loss": -12.1873197555542, "Value Loss": 0.02541959099471569, "_runtime": 332.03917050361633, "_timestamp": 1585076586.3846338, "_step": 280}
{"Episode reward": -113.57140163360936, "Episode length": 999, "Policy Loss": -15.39101791381836, "Value Loss": 0.03863665089011192, "_runtime": 333.1834120750427, "_timestamp": 1585076587.5288754, "_step": 281}
{"Episode reward": -94.1468521261451, "Episode length": 999, "Policy Loss": -11.724363327026367, "Value Loss": 0.02688855677843094, "_runtime": 334.30788683891296, "_timestamp": 1585076588.65335, "_step": 282}
{"Episode reward": -95.35223584484606, "Episode length": 999, "Policy Loss": -12.222288131713867, "Value Loss": 0.030065665021538734, "_runtime": 335.35800766944885, "_timestamp": 1585076589.703471, "_step": 283}
{"Episode reward": 12.012304736642392, "Episode length": 906, "Policy Loss": 3.1808083057403564, "Value Loss": 11.059995651245117, "_runtime": 336.47495889663696, "_timestamp": 1585076590.8204222, "_step": 284}
{"Episode reward": -104.97360939519585, "Episode length": 999, "Policy Loss": -13.856058120727539, "Value Loss": 0.03165864944458008, "_runtime": 337.59838008880615, "_timestamp": 1585076591.9438434, "_step": 285}
{"Episode reward": -92.09441892599992, "Episode length": 999, "Policy Loss": -11.6028413772583, "Value Loss": 0.02258913218975067, "_runtime": 338.7305123806, "_timestamp": 1585076593.0759757, "_step": 286}
{"Episode reward": -106.32108090492142, "Episode length": 999, "Policy Loss": -13.780693054199219, "Value Loss": 0.0319787971675396, "_runtime": 339.8573589324951, "_timestamp": 1585076594.2028222, "_step": 287}
{"Episode reward": -93.89166841508846, "Episode length": 999, "Policy Loss": -11.740089416503906, "Value Loss": 0.024430103600025177, "_runtime": 340.9827778339386, "_timestamp": 1585076595.328241, "_step": 288}
{"Episode reward": -99.06037128094168, "Episode length": 999, "Policy Loss": -12.713603973388672, "Value Loss": 0.031271275132894516, "_runtime": 342.18117356300354, "_timestamp": 1585076596.5266368, "_step": 289}
{"Episode reward": -95.01975178930607, "Episode length": 999, "Policy Loss": -12.103072166442871, "Value Loss": 0.024906128644943237, "_runtime": 343.35084104537964, "_timestamp": 1585076597.6963043, "_step": 290}
{"Episode reward": -97.31840012412057, "Episode length": 999, "Policy Loss": -12.497869491577148, "Value Loss": 0.026540953665971756, "_runtime": 344.51846265792847, "_timestamp": 1585076598.863926, "_step": 291}
{"Episode reward": -99.33519918097196, "Episode length": 999, "Policy Loss": -12.641263961791992, "Value Loss": 0.03322286158800125, "_runtime": 345.66112518310547, "_timestamp": 1585076600.0065885, "_step": 292}
{"Episode reward": -99.64814782152887, "Episode length": 999, "Policy Loss": -12.679388999938965, "Value Loss": 0.030357016250491142, "_runtime": 346.77964878082275, "_timestamp": 1585076601.125112, "_step": 293}
{"Episode reward": -100.77900614588275, "Episode length": 999, "Policy Loss": -12.928927421569824, "Value Loss": 0.02723693661391735, "_runtime": 347.9210629463196, "_timestamp": 1585076602.2665262, "_step": 294}
{"Episode reward": -103.54304045843803, "Episode length": 999, "Policy Loss": -13.624293327331543, "Value Loss": 0.037648916244506836, "_runtime": 349.03689312934875, "_timestamp": 1585076603.3823564, "_step": 295}
{"Episode reward": -99.05461667507439, "Episode length": 999, "Policy Loss": -12.565281867980957, "Value Loss": 0.030979495495557785, "_runtime": 350.1588776111603, "_timestamp": 1585076604.504341, "_step": 296}
{"Episode reward": -102.88185713311927, "Episode length": 999, "Policy Loss": -13.240753173828125, "Value Loss": 0.032401688396930695, "_runtime": 351.3055455684662, "_timestamp": 1585076605.6510088, "_step": 297}
{"Episode reward": -93.2700400360326, "Episode length": 999, "Policy Loss": -11.732725143432617, "Value Loss": 0.026260538026690483, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625, 163.10064697265625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-87.84524536132812, -84.16889953613281, -80.49256134033203, -76.81621551513672, -73.13987731933594, -69.46353149414062, -65.78719329833984, -62.11084747314453, -58.43450927734375, -54.75816345214844, -51.08182144165039, -47.405479431152344, -43.7291374206543, -40.05279541015625, -36.3764533996582, -32.700111389160156, -29.02376937866211, -25.347427368164062, -21.67108154296875, -17.99474334716797, -14.318397521972656, -10.642059326171875, -6.9657135009765625, -3.2893753051757812, 0.38697052001953125, 4.0633087158203125, 7.739654541015625, 11.415992736816406, 15.092338562011719, 18.7686767578125, 22.445022583007812, 26.121360778808594, 29.797706604003906, 33.47405242919922, 37.150390625, 40.82673645019531, 44.503082275390625, 48.179412841796875, 51.85575866699219, 55.5321044921875, 59.20845031738281, 62.88478088378906, 66.56112670898438, 70.23747253417969, 73.913818359375, 77.59014892578125, 81.26649475097656, 84.94284057617188, 88.61918640136719, 92.2955322265625, 95.97186279296875, 99.64820861816406, 103.32455444335938, 107.00090026855469, 110.67723083496094, 114.35357666015625, 118.02992248535156, 121.70626831054688, 125.38259887695312, 129.05894470214844, 132.73529052734375, 136.41163635253906, 140.0879669189453, 143.76431274414062, 147.44065856933594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-89.2281494140625, -86.6085205078125, -83.9888916015625, -81.3692626953125, -78.7496337890625, -76.1300048828125, -73.5103759765625, -70.8907470703125, -68.2711181640625, -65.6514892578125, -63.031864166259766, -60.41223907470703, -57.79261016845703, -55.17298126220703, -52.55335235595703, -49.93372344970703, -47.31409454345703, -44.69446563720703, -42.07483673095703, -39.45520782470703, -36.83557891845703, -34.2159538269043, -31.596324920654297, -28.976696014404297, -26.357067108154297, -23.737442016601562, -21.117813110351562, -18.498184204101562, -15.878555297851562, -13.258926391601562, -10.639297485351562, -8.019668579101562, -5.4000396728515625, -2.7804107666015625, -0.1607818603515625, 2.4588470458984375, 5.0784759521484375, 7.6981048583984375, 10.317733764648438, 12.937362670898438, 15.556991577148438, 18.176612854003906, 20.796241760253906, 23.415870666503906, 26.035499572753906, 28.655128479003906, 31.274757385253906, 33.894386291503906, 36.514015197753906, 39.133636474609375, 41.753265380859375, 44.372894287109375, 46.992523193359375, 49.612152099609375, 52.231781005859375, 54.851409912109375, 57.471038818359375, 60.090667724609375, 62.710296630859375, 65.32992553710938, 67.94955444335938, 70.56918334960938, 73.18881225585938, 75.80844116210938, 78.42807006835938]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 5.0, 10.0, 3.0, 10.0, 3.0, 7.0, 17.0, 11.0, 11.0, 10.0, 10.0, 21.0, 13.0, 25.0, 46.0, 37.0, 46.0, 37.0, 23.0, 24.0, 33.0, 15.0, 13.0, 15.0, 6.0, 7.0, 4.0, 4.0, 4.0, 1.0, 4.0, 5.0, 5.0, 4.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-73.20341491699219, -71.05415344238281, -68.90489196777344, -66.75563049316406, -64.60636901855469, -62.45710372924805, -60.307838439941406, -58.15857696533203, -56.009315490722656, -53.86005401611328, -51.710792541503906, -49.561527252197266, -47.41226577758789, -45.263004302978516, -43.113739013671875, -40.9644775390625, -38.815216064453125, -36.66595458984375, -34.516693115234375, -32.367427825927734, -30.21816635131836, -28.068904876708984, -25.919639587402344, -23.77037811279297, -21.621116638183594, -19.47185516357422, -17.322593688964844, -15.173328399658203, -13.024066925048828, -10.874805450439453, -8.725540161132812, -6.5762786865234375, -4.4270172119140625, -2.2777557373046875, -0.1284942626953125, 2.0207672119140625, 4.1700286865234375, 6.319297790527344, 8.468559265136719, 10.617820739746094, 12.767082214355469, 14.916343688964844, 17.06560516357422, 19.214866638183594, 21.3641357421875, 23.513397216796875, 25.66265869140625, 27.811920166015625, 29.961181640625, 32.110443115234375, 34.25970458984375, 36.408966064453125, 38.5582275390625, 40.707496643066406, 42.85675811767578, 45.006019592285156, 47.15528106689453, 49.304542541503906, 51.45380401611328, 53.603065490722656, 55.75233459472656, 57.90159606933594, 60.05085754394531, 62.20011901855469, 64.34938049316406]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-36.616615295410156, -35.06537628173828, -33.51413345336914, -31.962894439697266, -30.41165542602539, -28.860414505004883, -27.309173583984375, -25.7579345703125, -24.206695556640625, -22.655454635620117, -21.10421371459961, -19.552974700927734, -18.001733779907227, -16.45049476623535, -14.899253845214844, -13.348014831542969, -11.796773910522461, -10.245532989501953, -8.694293975830078, -7.14305305480957, -5.591814041137695, -4.0405731201171875, -2.4893341064453125, -0.9380950927734375, 0.6131477355957031, 2.164386749267578, 3.715625762939453, 5.266868591308594, 6.818107604980469, 8.369346618652344, 9.920585632324219, 11.47182846069336, 13.023067474365234, 14.57430648803711, 16.12554931640625, 17.676788330078125, 19.22802734375, 20.779266357421875, 22.330509185791016, 23.88174819946289, 25.432987213134766, 26.984230041503906, 28.53546905517578, 30.086708068847656, 31.63794708251953, 33.189186096191406, 34.74042510986328, 36.29167175292969, 37.84291076660156, 39.39414978027344, 40.94538879394531, 42.49662780761719, 44.04786682128906, 45.59910583496094, 47.150352478027344, 48.70159149169922, 50.252830505371094, 51.80406951904297, 53.355308532714844, 54.90654754638672, 56.457786560058594, 58.009033203125, 59.560272216796875, 61.11151123046875, 62.662750244140625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 8.0, 7.0, 13.0, 7.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-30.36146354675293, -29.628000259399414, -28.89453887939453, -28.161075592041016, -27.427614212036133, -26.694150924682617, -25.960689544677734, -25.22722625732422, -24.493762969970703, -23.76030158996582, -23.026838302612305, -22.293376922607422, -21.559913635253906, -20.82645034790039, -20.092987060546875, -19.359525680541992, -18.62606430053711, -17.892601013183594, -17.159137725830078, -16.425674438476562, -15.69221305847168, -14.95875072479248, -14.225288391113281, -13.491825103759766, -12.758363723754883, -12.024900436401367, -11.291439056396484, -10.557975769042969, -9.824512481689453, -9.09105110168457, -8.357587814331055, -7.624126434326172, -6.890663146972656, -6.157199859619141, -5.423738479614258, -4.690275192260742, -3.9568138122558594, -3.2233505249023438, -2.489887237548828, -1.7564258575439453, -1.0229625701904297, -0.2895011901855469, 0.44396209716796875, 1.1774253845214844, 1.9108867645263672, 2.644350051879883, 3.3778133392333984, 4.111272811889648, 4.844736099243164, 5.57819938659668, 6.311662673950195, 7.045125961303711, 7.778585433959961, 8.512048721313477, 9.245512008666992, 9.978975296020508, 10.712438583374023, 11.445898056030273, 12.179361343383789, 12.912824630737305, 13.64628791809082, 14.379751205444336, 15.113210678100586, 15.846673965454102, 16.580137252807617]}, "_runtime": 352.4301700592041, "_timestamp": 1585076606.7756333, "_step": 298}
{"Episode reward": -97.85474665867078, "Episode length": 999, "Policy Loss": -12.524184226989746, "Value Loss": 0.027879610657691956, "_runtime": 353.59627294540405, "_timestamp": 1585076607.9417362, "_step": 299}
{"Episode reward": -94.26075042836867, "Episode length": 999, "Policy Loss": -11.853214263916016, "Value Loss": 0.027714887633919716, "_runtime": 354.7628128528595, "_timestamp": 1585076609.1082761, "_step": 300}
{"Episode reward": -93.65209417625917, "Episode length": 999, "Policy Loss": -11.774871826171875, "Value Loss": 0.024441951885819435, "_runtime": 355.8959712982178, "_timestamp": 1585076610.2414346, "_step": 301}
{"Episode reward": -107.20171524003237, "Episode length": 999, "Policy Loss": -14.31203556060791, "Value Loss": 0.03240082040429115, "_runtime": 357.0422923564911, "_timestamp": 1585076611.3877556, "_step": 302}
{"Episode reward": -98.32889727575498, "Episode length": 999, "Policy Loss": -12.681058883666992, "Value Loss": 0.026812568306922913, "_runtime": 358.2077522277832, "_timestamp": 1585076612.5532155, "_step": 303}
{"Episode reward": -102.47357002356169, "Episode length": 999, "Policy Loss": -13.24111270904541, "Value Loss": 0.030992582440376282, "_runtime": 359.38318610191345, "_timestamp": 1585076613.7286494, "_step": 304}
{"Episode reward": -103.48971931951259, "Episode length": 999, "Policy Loss": -13.4432954788208, "Value Loss": 0.033047132194042206, "_runtime": 360.508065700531, "_timestamp": 1585076614.853529, "_step": 305}
{"Episode reward": -99.43286729883351, "Episode length": 999, "Policy Loss": -12.578709602355957, "Value Loss": 0.0292652640491724, "_runtime": 361.70793056488037, "_timestamp": 1585076616.0533938, "_step": 306}
{"Episode reward": -102.3049085606202, "Episode length": 999, "Policy Loss": -13.41494083404541, "Value Loss": 0.03355046734213829, "_runtime": 362.857045173645, "_timestamp": 1585076617.2025084, "_step": 307}
{"Episode reward": -103.98107051332215, "Episode length": 999, "Policy Loss": -13.601032257080078, "Value Loss": 0.030937686562538147, "_runtime": 364.0331974029541, "_timestamp": 1585076618.3786607, "_step": 308}
{"Episode reward": -103.20687300176229, "Episode length": 999, "Policy Loss": -13.471667289733887, "Value Loss": 0.035130731761455536, "_runtime": 365.18179202079773, "_timestamp": 1585076619.5272553, "_step": 309}
{"Episode reward": -101.67302364976172, "Episode length": 999, "Policy Loss": -13.32643985748291, "Value Loss": 0.0317922905087471, "_runtime": 366.37244844436646, "_timestamp": 1585076620.7179117, "_step": 310}
{"Episode reward": -99.35528718106508, "Episode length": 999, "Policy Loss": -12.809052467346191, "Value Loss": 0.030550332739949226, "_runtime": 367.5052273273468, "_timestamp": 1585076621.8506906, "_step": 311}
{"Episode reward": -103.92825952899143, "Episode length": 999, "Policy Loss": -13.585447311401367, "Value Loss": 0.0319502130150795, "_runtime": 368.67111802101135, "_timestamp": 1585076623.0165813, "_step": 312}
{"Episode reward": -99.10327317004116, "Episode length": 999, "Policy Loss": -12.677509307861328, "Value Loss": 0.028763679787516594, "_runtime": 369.8435535430908, "_timestamp": 1585076624.1890168, "_step": 313}
{"Episode reward": -96.65147062247885, "Episode length": 999, "Policy Loss": -12.262484550476074, "Value Loss": 0.026052867993712425, "_runtime": 371.0080397129059, "_timestamp": 1585076625.353503, "_step": 314}
{"Episode reward": -94.10466557860332, "Episode length": 999, "Policy Loss": -11.89648151397705, "Value Loss": 0.025525683537125587, "_runtime": 372.2031455039978, "_timestamp": 1585076626.5486088, "_step": 315}
{"Episode reward": -91.82401913339442, "Episode length": 999, "Policy Loss": -11.601033210754395, "Value Loss": 0.025944393128156662, "_runtime": 373.3579683303833, "_timestamp": 1585076627.7034316, "_step": 316}
{"Episode reward": -88.00491921493455, "Episode length": 999, "Policy Loss": -10.836734771728516, "Value Loss": 0.025493592023849487, "_runtime": 374.5447907447815, "_timestamp": 1585076628.890254, "_step": 317}
{"Episode reward": -96.27049444938272, "Episode length": 999, "Policy Loss": -12.104110717773438, "Value Loss": 0.02859817072749138, "_runtime": 375.7067975997925, "_timestamp": 1585076630.0522609, "_step": 318}
{"Episode reward": -99.96863500431891, "Episode length": 999, "Policy Loss": -12.974994659423828, "Value Loss": 0.03130270168185234, "_runtime": 376.86439538002014, "_timestamp": 1585076631.2098587, "_step": 319}
{"Episode reward": -95.67604777623252, "Episode length": 999, "Policy Loss": -12.023173332214355, "Value Loss": 0.02650807984173298, "_runtime": 378.03571224212646, "_timestamp": 1585076632.3811755, "_step": 320}
{"Episode reward": -92.18737589431053, "Episode length": 999, "Policy Loss": -11.669757843017578, "Value Loss": 0.024233810603618622, "_runtime": 379.17023754119873, "_timestamp": 1585076633.5157008, "_step": 321}
{"Episode reward": -98.52507773760082, "Episode length": 999, "Policy Loss": -12.494402885437012, "Value Loss": 0.030870700255036354, "_runtime": 380.3510718345642, "_timestamp": 1585076634.696535, "_step": 322}
{"Episode reward": -99.43782687843256, "Episode length": 999, "Policy Loss": -12.686861038208008, "Value Loss": 0.029584627598524094, "_runtime": 381.53138542175293, "_timestamp": 1585076635.8768487, "_step": 323}
{"Episode reward": -95.91571874809456, "Episode length": 999, "Policy Loss": -12.458089828491211, "Value Loss": 0.02808355540037155, "_runtime": 382.7255220413208, "_timestamp": 1585076637.0709853, "_step": 324}
{"Episode reward": -105.23275254026032, "Episode length": 999, "Policy Loss": -13.932044982910156, "Value Loss": 0.03387196362018585, "_runtime": 383.9729850292206, "_timestamp": 1585076638.3184483, "_step": 325}
{"Episode reward": -98.39927207300263, "Episode length": 999, "Policy Loss": -12.611388206481934, "Value Loss": 0.029046138748526573, "_runtime": 385.1743154525757, "_timestamp": 1585076639.5197787, "_step": 326}
{"Episode reward": -101.4317180203953, "Episode length": 999, "Policy Loss": -13.262158393859863, "Value Loss": 0.028426753357052803, "_runtime": 386.31453824043274, "_timestamp": 1585076640.6600015, "_step": 327}
{"Episode reward": -99.88402000911111, "Episode length": 999, "Policy Loss": -13.045477867126465, "Value Loss": 0.031839579343795776, "_runtime": 387.4652063846588, "_timestamp": 1585076641.8106697, "_step": 328}
{"Episode reward": -96.29556374458605, "Episode length": 999, "Policy Loss": -12.159175872802734, "Value Loss": 0.02795085497200489, "_runtime": 388.63753938674927, "_timestamp": 1585076642.9830027, "_step": 329}
{"Episode reward": -107.27857737373145, "Episode length": 999, "Policy Loss": -14.295883178710938, "Value Loss": 0.03583253175020218, "_runtime": 389.8037221431732, "_timestamp": 1585076644.1491854, "_step": 330}
{"Episode reward": -98.18652518243259, "Episode length": 999, "Policy Loss": -12.497615814208984, "Value Loss": 0.031456783413887024, "_runtime": 390.92578768730164, "_timestamp": 1585076645.271251, "_step": 331}
{"Episode reward": -99.39233414553799, "Episode length": 999, "Policy Loss": -12.680517196655273, "Value Loss": 0.029723387211561203, "_runtime": 392.11963272094727, "_timestamp": 1585076646.465096, "_step": 332}
{"Episode reward": -93.18262348957553, "Episode length": 999, "Policy Loss": -11.704588890075684, "Value Loss": 0.02543250471353531, "_runtime": 393.2646379470825, "_timestamp": 1585076647.6101012, "_step": 333}
{"Episode reward": -99.68245405632806, "Episode length": 999, "Policy Loss": -12.826674461364746, "Value Loss": 0.029320621863007545, "_runtime": 394.49165773391724, "_timestamp": 1585076648.837121, "_step": 334}
{"Episode reward": -95.62882895980815, "Episode length": 999, "Policy Loss": -12.026909828186035, "Value Loss": 0.02570607140660286, "_runtime": 395.66068601608276, "_timestamp": 1585076650.0061493, "_step": 335}
{"Episode reward": -100.52947740513424, "Episode length": 999, "Policy Loss": -12.890560150146484, "Value Loss": 0.031234929338097572, "_runtime": 396.8051290512085, "_timestamp": 1585076651.1505923, "_step": 336}
{"Episode reward": -104.81388023006161, "Episode length": 999, "Policy Loss": -13.987481117248535, "Value Loss": 0.03404281288385391, "_runtime": 397.9596679210663, "_timestamp": 1585076652.3051312, "_step": 337}
{"Episode reward": -107.78870359868891, "Episode length": 999, "Policy Loss": -14.359664916992188, "Value Loss": 0.03399316221475601, "_runtime": 399.1154525279999, "_timestamp": 1585076653.4609158, "_step": 338}
{"Episode reward": -103.75630151333955, "Episode length": 999, "Policy Loss": -13.645485877990723, "Value Loss": 0.03353530541062355, "_runtime": 400.2835898399353, "_timestamp": 1585076654.629053, "_step": 339}
{"Episode reward": -98.57253158559487, "Episode length": 999, "Policy Loss": -12.870810508728027, "Value Loss": 0.02619713731110096, "_runtime": 401.43599486351013, "_timestamp": 1585076655.7814581, "_step": 340}
{"Episode reward": -95.01754594744096, "Episode length": 999, "Policy Loss": -12.165745735168457, "Value Loss": 0.028142837807536125, "_runtime": 402.580614566803, "_timestamp": 1585076656.9260778, "_step": 341}
{"Episode reward": -106.88567611213043, "Episode length": 999, "Policy Loss": -14.256976127624512, "Value Loss": 0.03243909031152725, "_runtime": 403.75997734069824, "_timestamp": 1585076658.1054406, "_step": 342}
{"Episode reward": -94.73555469174698, "Episode length": 999, "Policy Loss": -11.880773544311523, "Value Loss": 0.024778233841061592, "_runtime": 404.8965005874634, "_timestamp": 1585076659.2419639, "_step": 343}
{"Episode reward": -98.22570578318863, "Episode length": 999, "Policy Loss": -12.276867866516113, "Value Loss": 0.032470088452100754, "_runtime": 406.06306886672974, "_timestamp": 1585076660.4085321, "_step": 344}
{"Episode reward": -99.2127709755197, "Episode length": 999, "Policy Loss": -12.988269805908203, "Value Loss": 0.03075469844043255, "_runtime": 407.23053884506226, "_timestamp": 1585076661.5760021, "_step": 345}
{"Episode reward": -98.58045900752887, "Episode length": 999, "Policy Loss": -12.7227201461792, "Value Loss": 0.03143690526485443, "_runtime": 408.36801743507385, "_timestamp": 1585076662.7134807, "_step": 346}
{"Episode reward": -105.3219276804353, "Episode length": 999, "Policy Loss": -13.976814270019531, "Value Loss": 0.03347042202949524, "_runtime": 409.5156843662262, "_timestamp": 1585076663.8611476, "_step": 347}
{"Episode reward": -101.23859591307378, "Episode length": 999, "Policy Loss": -13.215250015258789, "Value Loss": 0.03153716400265694, "_runtime": 410.63315987586975, "_timestamp": 1585076664.9786232, "_step": 348}
{"Episode reward": -100.23451416013076, "Episode length": 999, "Policy Loss": -12.954243659973145, "Value Loss": 0.031733665615320206, "_runtime": 411.76483511924744, "_timestamp": 1585076666.1102984, "_step": 349}
{"Episode reward": -104.03675426098066, "Episode length": 999, "Policy Loss": -13.627223014831543, "Value Loss": 0.03515757620334625, "_runtime": 412.9327893257141, "_timestamp": 1585076667.2782526, "_step": 350}
{"Episode reward": -102.22307879338153, "Episode length": 999, "Policy Loss": -13.143908500671387, "Value Loss": 0.030561992898583412, "_runtime": 414.097026348114, "_timestamp": 1585076668.4424896, "_step": 351}
{"Episode reward": -105.929291786399, "Episode length": 999, "Policy Loss": -13.847509384155273, "Value Loss": 0.032845303416252136, "_runtime": 415.22057247161865, "_timestamp": 1585076669.5660357, "_step": 352}
{"Episode reward": -101.03549806490055, "Episode length": 999, "Policy Loss": -13.058927536010742, "Value Loss": 0.03242765739560127, "_runtime": 416.347624540329, "_timestamp": 1585076670.6930878, "_step": 353}
{"Episode reward": -107.80614204184462, "Episode length": 999, "Policy Loss": -13.888389587402344, "Value Loss": 0.03639059141278267, "_runtime": 417.47903871536255, "_timestamp": 1585076671.824502, "_step": 354}
{"Episode reward": -99.7784806940695, "Episode length": 999, "Policy Loss": -12.801820755004883, "Value Loss": 0.02908926084637642, "_runtime": 418.6088695526123, "_timestamp": 1585076672.9543328, "_step": 355}
{"Episode reward": -103.70022281195753, "Episode length": 999, "Policy Loss": -13.529407501220703, "Value Loss": 0.0325893834233284, "_runtime": 419.8059298992157, "_timestamp": 1585076674.1513932, "_step": 356}
{"Episode reward": -103.30713146863788, "Episode length": 999, "Policy Loss": -13.410687446594238, "Value Loss": 0.03068697825074196, "_runtime": 420.94139409065247, "_timestamp": 1585076675.2868574, "_step": 357}
{"Episode reward": -96.31550920472549, "Episode length": 999, "Policy Loss": -12.274015426635742, "Value Loss": 0.027651986107230186, "_runtime": 422.1064133644104, "_timestamp": 1585076676.4518766, "_step": 358}
{"Episode reward": -96.3043635303123, "Episode length": 999, "Policy Loss": -12.247735977172852, "Value Loss": 0.0286155603826046, "_runtime": 423.2898910045624, "_timestamp": 1585076677.6353543, "_step": 359}
{"Episode reward": -100.87915952729472, "Episode length": 999, "Policy Loss": -12.943653106689453, "Value Loss": 0.029536472633481026, "_runtime": 424.4969162940979, "_timestamp": 1585076678.8423796, "_step": 360}
{"Episode reward": -100.22598583776427, "Episode length": 999, "Policy Loss": -13.078795433044434, "Value Loss": 0.03218872845172882, "_runtime": 425.68553495407104, "_timestamp": 1585076680.0309982, "_step": 361}
{"Episode reward": -97.89870913249939, "Episode length": 999, "Policy Loss": -12.673442840576172, "Value Loss": 0.027807557955384254, "_runtime": 426.8056411743164, "_timestamp": 1585076681.1511045, "_step": 362}
{"Episode reward": -97.75648082381187, "Episode length": 999, "Policy Loss": -12.378133773803711, "Value Loss": 0.0314004011452198, "_runtime": 427.9556403160095, "_timestamp": 1585076682.3011036, "_step": 363}
{"Episode reward": -97.26730728894655, "Episode length": 999, "Policy Loss": -12.457576751708984, "Value Loss": 0.029481513425707817, "_runtime": 429.09180331230164, "_timestamp": 1585076683.4372666, "_step": 364}
{"Episode reward": -102.57815423853218, "Episode length": 999, "Policy Loss": -13.271110534667969, "Value Loss": 0.03298475965857506, "_runtime": 430.2183961868286, "_timestamp": 1585076684.5638595, "_step": 365}
{"Episode reward": -97.96187354132604, "Episode length": 999, "Policy Loss": -12.664904594421387, "Value Loss": 0.02988165058195591, "_runtime": 431.36702728271484, "_timestamp": 1585076685.7124906, "_step": 366}
{"Episode reward": -101.82759038401447, "Episode length": 999, "Policy Loss": -13.118911743164062, "Value Loss": 0.02992171049118042, "_runtime": 432.51491355895996, "_timestamp": 1585076686.8603768, "_step": 367}
{"Episode reward": -98.71676532824284, "Episode length": 999, "Policy Loss": -12.63037395477295, "Value Loss": 0.029993537813425064, "_runtime": 433.67115020751953, "_timestamp": 1585076688.0166135, "_step": 368}
{"Episode reward": -95.23600021766333, "Episode length": 999, "Policy Loss": -11.944857597351074, "Value Loss": 0.0295447688549757, "_runtime": 434.8233530521393, "_timestamp": 1585076689.1688163, "_step": 369}
{"Episode reward": -111.14312735747325, "Episode length": 999, "Policy Loss": -14.647153854370117, "Value Loss": 0.03586549311876297, "_runtime": 435.9692907333374, "_timestamp": 1585076690.314754, "_step": 370}
{"Episode reward": -98.29991926866916, "Episode length": 999, "Policy Loss": -12.648505210876465, "Value Loss": 0.028008675202727318, "_runtime": 437.127562046051, "_timestamp": 1585076691.4730253, "_step": 371}
{"Episode reward": -104.09833943533584, "Episode length": 999, "Policy Loss": -13.66873550415039, "Value Loss": 0.03070727176964283, "_runtime": 438.32409930229187, "_timestamp": 1585076692.6695626, "_step": 372}
{"Episode reward": -97.44482349812891, "Episode length": 999, "Policy Loss": -12.427599906921387, "Value Loss": 0.02694879285991192, "_runtime": 439.4987337589264, "_timestamp": 1585076693.844197, "_step": 373}
{"Episode reward": -105.77849099157824, "Episode length": 999, "Policy Loss": -13.92188835144043, "Value Loss": 0.03282351791858673, "_runtime": 440.62848448753357, "_timestamp": 1585076694.9739478, "_step": 374}
{"Episode reward": -91.45425790469807, "Episode length": 999, "Policy Loss": -11.363986015319824, "Value Loss": 0.02516183629631996, "_runtime": 441.82304406166077, "_timestamp": 1585076696.1685073, "_step": 375}
{"Episode reward": -100.68812591591654, "Episode length": 999, "Policy Loss": -12.909052848815918, "Value Loss": 0.031837526708841324, "_runtime": 442.9108111858368, "_timestamp": 1585076697.2562745, "_step": 376}
{"Episode reward": 5.965350209675265, "Episode length": 928, "Policy Loss": 3.1900196075439453, "Value Loss": 10.80124568939209, "_runtime": 444.05647468566895, "_timestamp": 1585076698.401938, "_step": 377}
{"Episode reward": -108.78395451739284, "Episode length": 999, "Policy Loss": -14.439570426940918, "Value Loss": 0.04255663603544235, "_runtime": 445.1877017021179, "_timestamp": 1585076699.533165, "_step": 378}
{"Episode reward": -100.56657151521625, "Episode length": 999, "Policy Loss": -13.15334701538086, "Value Loss": 0.03449694439768791, "_runtime": 446.3426356315613, "_timestamp": 1585076700.688099, "_step": 379}
{"Episode reward": -95.0527968159902, "Episode length": 999, "Policy Loss": -11.938300132751465, "Value Loss": 0.025678936392068863, "_runtime": 447.51839876174927, "_timestamp": 1585076701.863862, "_step": 380}
{"Episode reward": -92.13188993182743, "Episode length": 999, "Policy Loss": -11.452077865600586, "Value Loss": 0.027540024369955063, "_runtime": 448.6982047557831, "_timestamp": 1585076703.043668, "_step": 381}
{"Episode reward": -102.19710408909881, "Episode length": 999, "Policy Loss": -13.013113021850586, "Value Loss": 0.030501944944262505, "_runtime": 449.8521099090576, "_timestamp": 1585076704.1975732, "_step": 382}
{"Episode reward": -96.15175851960495, "Episode length": 999, "Policy Loss": -12.254332542419434, "Value Loss": 0.028918784111738205, "_runtime": 451.01979327201843, "_timestamp": 1585076705.3652565, "_step": 383}
{"Episode reward": -101.5974360708194, "Episode length": 999, "Policy Loss": -12.952469825744629, "Value Loss": 0.030368102714419365, "_runtime": 452.19168496131897, "_timestamp": 1585076706.5371482, "_step": 384}
{"Episode reward": -100.06654847481636, "Episode length": 999, "Policy Loss": -12.956931114196777, "Value Loss": 0.028981180861592293, "_runtime": 453.3192546367645, "_timestamp": 1585076707.664718, "_step": 385}
{"Episode reward": -100.162128092125, "Episode length": 999, "Policy Loss": -12.718029975891113, "Value Loss": 0.0291591789573431, "_runtime": 454.4815876483917, "_timestamp": 1585076708.827051, "_step": 386}
{"Episode reward": -94.31226420459043, "Episode length": 999, "Policy Loss": -11.953032493591309, "Value Loss": 0.025744274258613586, "_runtime": 455.6661150455475, "_timestamp": 1585076710.0115783, "_step": 387}
{"Episode reward": -100.46020354332454, "Episode length": 999, "Policy Loss": -12.835689544677734, "Value Loss": 0.03204036131501198, "_runtime": 456.7875819206238, "_timestamp": 1585076711.1330452, "_step": 388}
{"Episode reward": -103.4900338351743, "Episode length": 999, "Policy Loss": -13.326399803161621, "Value Loss": 0.03518139570951462, "_runtime": 457.9709622859955, "_timestamp": 1585076712.3164256, "_step": 389}
{"Episode reward": -96.14789493832062, "Episode length": 999, "Policy Loss": -12.33234977722168, "Value Loss": 0.028622452169656754, "_runtime": 459.08227157592773, "_timestamp": 1585076713.4277349, "_step": 390}
{"Episode reward": -98.96926208853596, "Episode length": 999, "Policy Loss": -12.383993148803711, "Value Loss": 0.027298681437969208, "_runtime": 460.2093777656555, "_timestamp": 1585076714.554841, "_step": 391}
{"Episode reward": -95.27584674254472, "Episode length": 999, "Policy Loss": -12.113061904907227, "Value Loss": 0.029219120740890503, "_runtime": 461.3702440261841, "_timestamp": 1585076715.7157073, "_step": 392}
{"Episode reward": -98.68406114543113, "Episode length": 999, "Policy Loss": -12.657842636108398, "Value Loss": 0.029539229348301888, "_runtime": 462.54838490486145, "_timestamp": 1585076716.8938482, "_step": 393}
{"Episode reward": -100.63602236994237, "Episode length": 999, "Policy Loss": -12.98730754852295, "Value Loss": 0.027043091133236885, "_runtime": 463.71216082572937, "_timestamp": 1585076718.057624, "_step": 394}
{"Episode reward": -97.78621988587022, "Episode length": 999, "Policy Loss": -12.33070182800293, "Value Loss": 0.02873395010828972, "_runtime": 464.9040267467499, "_timestamp": 1585076719.24949, "_step": 395}
{"Episode reward": -102.73295212174921, "Episode length": 999, "Policy Loss": -13.268712997436523, "Value Loss": 0.03138932213187218, "_runtime": 466.0189754962921, "_timestamp": 1585076720.3644388, "_step": 396}
{"Episode reward": -99.30719544915468, "Episode length": 999, "Policy Loss": -12.60814094543457, "Value Loss": 0.028281616047024727, "_runtime": 467.16475224494934, "_timestamp": 1585076721.5102155, "_step": 397}
{"Episode reward": -98.12018280440849, "Episode length": 999, "Policy Loss": -12.54401969909668, "Value Loss": 0.029851308092474937, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297, -201.9518280029297]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-176.58187866210938, -172.13345336914062, -167.68502807617188, -163.2366180419922, -158.78819274902344, -154.3397674560547, -149.891357421875, -145.44293212890625, -140.9945068359375, -136.54608154296875, -132.09765625, -127.64924621582031, -123.20082092285156, -118.75239562988281, -114.3039779663086, -109.85556030273438, -105.40713500976562, -100.95870971679688, -96.51029205322266, -92.06187438964844, -87.61344909667969, -83.16502380371094, -78.71660614013672, -74.2681884765625, -69.81976318359375, -65.371337890625, -60.92292022705078, -56.47450256347656, -52.02607727050781, -47.57765197753906, -43.129241943359375, -38.680816650390625, -34.232391357421875, -29.783966064453125, -25.335540771484375, -20.887130737304688, -16.438705444335938, -11.990280151367188, -7.5418701171875, -3.09344482421875, 1.35498046875, 5.80340576171875, 10.2518310546875, 14.700241088867188, 19.148666381835938, 23.597091674804688, 28.045501708984375, 32.493927001953125, 36.942352294921875, 41.390777587890625, 45.839202880859375, 50.28761291503906, 54.73603820800781, 59.18446350097656, 63.63287353515625, 68.081298828125, 72.52972412109375, 76.9781494140625, 81.42657470703125, 85.875, 90.32339477539062, 94.77182006835938, 99.22024536132812, 103.66867065429688, 108.11709594726562]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-96.97180938720703, -93.73018646240234, -90.48855590820312, -87.24693298339844, -84.00531005859375, -80.76368713378906, -77.52205657958984, -74.28043365478516, -71.03881072998047, -67.79718017578125, -64.55555725097656, -61.313934326171875, -58.07230758666992, -54.830684661865234, -51.58905792236328, -48.347434997558594, -45.10580825805664, -41.86418151855469, -38.62255859375, -35.38093185424805, -32.139305114746094, -28.897682189941406, -25.65605926513672, -22.41443634033203, -19.172805786132812, -15.931182861328125, -12.689559936523438, -9.447929382324219, -6.206306457519531, -2.9646835327148438, 0.27693939208984375, 3.5185699462890625, 6.76019287109375, 10.001815795898438, 13.243446350097656, 16.485069274902344, 19.72669219970703, 22.96831512451172, 26.209945678710938, 29.451568603515625, 32.693199157714844, 35.93482208251953, 39.17644500732422, 42.418067932128906, 45.659690856933594, 48.90131378173828, 52.14293670654297, 55.38457489013672, 58.626197814941406, 61.867820739746094, 65.10944366455078, 68.35106658935547, 71.59268951416016, 74.83431243896484, 78.0759506225586, 81.31757354736328, 84.55919647216797, 87.80081939697266, 91.04244232177734, 94.28406524658203, 97.52568817138672, 100.76732635498047, 104.00894927978516, 107.25057220458984, 110.49219512939453]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 4.0, 2.0, 4.0, 5.0, 1.0, 5.0, 3.0, 4.0, 4.0, 4.0, 12.0, 10.0, 10.0, 13.0, 16.0, 33.0, 21.0, 28.0, 32.0, 35.0, 39.0, 50.0, 21.0, 19.0, 18.0, 9.0, 11.0, 10.0, 13.0, 9.0, 11.0, 3.0, 10.0, 4.0, 11.0, 6.0, 4.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-75.60652923583984, -73.07911682128906, -70.55169677734375, -68.02428436279297, -65.49687194824219, -62.969459533691406, -60.44204330444336, -57.91462707519531, -55.38721466064453, -52.85980224609375, -50.3323860168457, -47.804969787597656, -45.277557373046875, -42.750144958496094, -40.22272872924805, -37.6953125, -35.16790008544922, -32.64048767089844, -30.11307144165039, -27.585655212402344, -25.058242797851562, -22.53083038330078, -20.003414154052734, -17.475997924804688, -14.948585510253906, -12.421173095703125, -9.893760681152344, -7.366340637207031, -4.83892822265625, -2.3115158081054688, 0.21590423583984375, 2.743316650390625, 5.270729064941406, 7.7981414794921875, 10.325553894042969, 12.852973937988281, 15.380386352539062, 17.907798767089844, 20.435218811035156, 22.962631225585938, 25.49004364013672, 28.0174560546875, 30.54486846923828, 33.072288513183594, 35.599700927734375, 38.127113342285156, 40.65453338623047, 43.18194580078125, 45.70935821533203, 48.23677062988281, 50.764183044433594, 53.291603088378906, 55.819007873535156, 58.34642791748047, 60.87384796142578, 63.40125274658203, 65.92867279052734, 68.45609283447266, 70.9834976196289, 73.51091766357422, 76.03833770751953, 78.56574249267578, 81.0931625366211, 83.62056732177734, 86.14798736572266]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-80.6273422241211, -78.60289764404297, -76.57846069335938, -74.55401611328125, -72.52957153320312, -70.505126953125, -68.4806900024414, -66.45624542236328, -64.43180847167969, -62.40736389160156, -60.38291931152344, -58.35847854614258, -56.33403778076172, -54.309593200683594, -52.285152435302734, -50.260711669921875, -48.23626708984375, -46.21182632446289, -44.187381744384766, -42.162940979003906, -40.13849639892578, -38.11405563354492, -36.08961486816406, -34.06517028808594, -32.04072952270508, -30.01628875732422, -27.991844177246094, -25.967403411865234, -23.942962646484375, -21.91851806640625, -19.89407730102539, -17.869632720947266, -15.845191955566406, -13.820747375488281, -11.796310424804688, -9.771865844726562, -7.7474212646484375, -5.722984313964844, -3.6985397338867188, -1.6740951538085938, 0.35034942626953125, 2.374786376953125, 4.39923095703125, 6.423675537109375, 8.448112487792969, 10.472557067871094, 12.497001647949219, 14.521438598632812, 16.545883178710938, 18.570327758789062, 20.594764709472656, 22.61920928955078, 24.643653869628906, 26.6680908203125, 28.692535400390625, 30.71697998046875, 32.741416931152344, 34.76586151123047, 36.790306091308594, 38.81475067138672, 40.83918762207031, 42.86363220214844, 44.88807678222656, 46.912513732910156, 48.93695831298828]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 15.0, 16.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-16.20833969116211, -15.561279296875, -14.914219856262207, -14.267159461975098, -13.620100021362305, -12.973039627075195, -12.325979232788086, -11.678919792175293, -11.0318603515625, -10.38479995727539, -9.737739562988281, -9.090680122375488, -8.443619728088379, -7.796560287475586, -7.149499893188477, -6.502440452575684, -5.855380058288574, -5.208319664001465, -4.561260223388672, -3.9141998291015625, -3.2671403884887695, -2.62007999420166, -1.9730205535888672, -1.3259601593017578, -0.6788997650146484, -0.03183937072753906, 0.6152191162109375, 1.2622795104980469, 1.9093399047851562, 2.5564002990722656, 3.203458786010742, 3.8505191802978516, 4.497579574584961, 5.14463996887207, 5.79170036315918, 6.438758850097656, 7.085819244384766, 7.732879638671875, 8.379940032958984, 9.026998519897461, 9.67405891418457, 10.32111930847168, 10.968179702758789, 11.615240097045898, 12.262298583984375, 12.909358978271484, 13.556419372558594, 14.203479766845703, 14.850540161132812, 15.497598648071289, 16.14466094970703, 16.791717529296875, 17.438777923583984, 18.085838317871094, 18.732898712158203, 19.379959106445312, 20.027019500732422, 20.67407989501953, 21.32114028930664, 21.96820068359375, 22.615257263183594, 23.262317657470703, 23.909378051757812, 24.556438446044922, 25.20349884033203]}, "_runtime": 468.30356884002686, "_timestamp": 1585076722.649032, "_step": 398}
{"Episode reward": -95.71816928183108, "Episode length": 999, "Policy Loss": -12.115654945373535, "Value Loss": 0.02714734710752964, "_runtime": 469.4277970790863, "_timestamp": 1585076723.7732604, "_step": 399}
{"Episode reward": -96.7923038593372, "Episode length": 999, "Policy Loss": -12.4426851272583, "Value Loss": 0.02719097025692463, "_runtime": 470.5542085170746, "_timestamp": 1585076724.8996718, "_step": 400}
{"Episode reward": -99.76855361415124, "Episode length": 999, "Policy Loss": -12.601560592651367, "Value Loss": 0.030995026230812073, "_runtime": 471.7454557418823, "_timestamp": 1585076726.090919, "_step": 401}
{"Episode reward": -100.47639871804738, "Episode length": 999, "Policy Loss": -13.005754470825195, "Value Loss": 0.0364501066505909, "_runtime": 472.88458943367004, "_timestamp": 1585076727.2300527, "_step": 402}
{"Episode reward": -95.63765391448732, "Episode length": 999, "Policy Loss": -12.02856159210205, "Value Loss": 0.026593126356601715, "_runtime": 474.0123791694641, "_timestamp": 1585076728.3578424, "_step": 403}
{"Episode reward": -99.57271431314473, "Episode length": 999, "Policy Loss": -12.86740779876709, "Value Loss": 0.028547385707497597, "_runtime": 475.13191866874695, "_timestamp": 1585076729.477382, "_step": 404}
{"Episode reward": -94.78948521024942, "Episode length": 999, "Policy Loss": -12.080131530761719, "Value Loss": 0.029437024146318436, "_runtime": 476.2794008255005, "_timestamp": 1585076730.624864, "_step": 405}
{"Episode reward": -96.45698602666447, "Episode length": 999, "Policy Loss": -12.462924003601074, "Value Loss": 0.029072724282741547, "_runtime": 477.43509435653687, "_timestamp": 1585076731.7805576, "_step": 406}
{"Episode reward": -98.76126288506167, "Episode length": 999, "Policy Loss": -12.825272560119629, "Value Loss": 0.029712075367569923, "_runtime": 478.5641543865204, "_timestamp": 1585076732.9096177, "_step": 407}
{"Episode reward": -94.30611232858955, "Episode length": 999, "Policy Loss": -11.707290649414062, "Value Loss": 0.025242364034056664, "_runtime": 479.7333149909973, "_timestamp": 1585076734.0787783, "_step": 408}
{"Episode reward": -93.77702757384117, "Episode length": 999, "Policy Loss": -11.87719440460205, "Value Loss": 0.026894068345427513, "_runtime": 480.8514041900635, "_timestamp": 1585076735.1968675, "_step": 409}
{"Episode reward": -102.24908291530247, "Episode length": 999, "Policy Loss": -13.384284019470215, "Value Loss": 0.03007734939455986, "_runtime": 482.0100758075714, "_timestamp": 1585076736.355539, "_step": 410}
{"Episode reward": -99.18202022185136, "Episode length": 999, "Policy Loss": -12.851861953735352, "Value Loss": 0.028417980298399925, "_runtime": 483.15902185440063, "_timestamp": 1585076737.5044851, "_step": 411}
{"Episode reward": -93.76583131180101, "Episode length": 999, "Policy Loss": -11.750109672546387, "Value Loss": 0.02694944106042385, "_runtime": 484.29744243621826, "_timestamp": 1585076738.6429057, "_step": 412}
{"Episode reward": -98.43919584871549, "Episode length": 999, "Policy Loss": -12.586060523986816, "Value Loss": 0.02731327712535858, "_runtime": 485.44708013534546, "_timestamp": 1585076739.7925434, "_step": 413}
{"Episode reward": -96.49117376399285, "Episode length": 999, "Policy Loss": -12.086318969726562, "Value Loss": 0.027821602299809456, "_runtime": 486.57558512687683, "_timestamp": 1585076740.9210484, "_step": 414}
{"Episode reward": -102.45375492152893, "Episode length": 999, "Policy Loss": -13.021584510803223, "Value Loss": 0.03391208499670029, "_runtime": 487.7036476135254, "_timestamp": 1585076742.049111, "_step": 415}
{"Episode reward": -100.54912207165793, "Episode length": 999, "Policy Loss": -13.124810218811035, "Value Loss": 0.03052688203752041, "_runtime": 488.8434100151062, "_timestamp": 1585076743.1888733, "_step": 416}
{"Episode reward": -106.43103336066783, "Episode length": 999, "Policy Loss": -14.07689380645752, "Value Loss": 0.031490787863731384, "_runtime": 489.96721506118774, "_timestamp": 1585076744.3126783, "_step": 417}
{"Episode reward": -98.16809935174548, "Episode length": 999, "Policy Loss": -12.585601806640625, "Value Loss": 0.030751744285225868, "_runtime": 491.0871093273163, "_timestamp": 1585076745.4325726, "_step": 418}
{"Episode reward": -94.61694896606961, "Episode length": 999, "Policy Loss": -11.592145919799805, "Value Loss": 0.02741612307727337, "_runtime": 492.2610409259796, "_timestamp": 1585076746.6065042, "_step": 419}
{"Episode reward": -102.59578384300093, "Episode length": 999, "Policy Loss": -13.345165252685547, "Value Loss": 0.03032742626965046, "_runtime": 493.3793113231659, "_timestamp": 1585076747.7247746, "_step": 420}
{"Episode reward": -101.50910251636584, "Episode length": 999, "Policy Loss": -13.268664360046387, "Value Loss": 0.0327618233859539, "_runtime": 494.52618503570557, "_timestamp": 1585076748.8716483, "_step": 421}
{"Episode reward": -101.121124686126, "Episode length": 999, "Policy Loss": -13.078780174255371, "Value Loss": 0.031340308487415314, "_runtime": 495.697979927063, "_timestamp": 1585076750.0434432, "_step": 422}
{"Episode reward": -97.03197904259585, "Episode length": 999, "Policy Loss": -12.403215408325195, "Value Loss": 0.030656225979328156, "_runtime": 496.8506908416748, "_timestamp": 1585076751.196154, "_step": 423}
{"Episode reward": -105.2104686677023, "Episode length": 999, "Policy Loss": -13.951794624328613, "Value Loss": 0.036551594734191895, "_runtime": 498.006315946579, "_timestamp": 1585076752.3517792, "_step": 424}
{"Episode reward": -94.7120754472012, "Episode length": 999, "Policy Loss": -11.898370742797852, "Value Loss": 0.02667044661939144, "_runtime": 499.1346273422241, "_timestamp": 1585076753.4800906, "_step": 425}
{"Episode reward": -96.46744616702416, "Episode length": 999, "Policy Loss": -12.216413497924805, "Value Loss": 0.02781384438276291, "_runtime": 500.2505648136139, "_timestamp": 1585076754.596028, "_step": 426}
{"Episode reward": -101.06082434299093, "Episode length": 999, "Policy Loss": -12.816399574279785, "Value Loss": 0.03174489364027977, "_runtime": 501.41071248054504, "_timestamp": 1585076755.7561758, "_step": 427}
{"Episode reward": -96.4984329539015, "Episode length": 999, "Policy Loss": -12.165199279785156, "Value Loss": 0.02888687513768673, "_runtime": 502.59014678001404, "_timestamp": 1585076756.93561, "_step": 428}
{"Episode reward": -89.48602643010706, "Episode length": 999, "Policy Loss": -10.978290557861328, "Value Loss": 0.02562858536839485, "_runtime": 503.7468740940094, "_timestamp": 1585076758.0923374, "_step": 429}
{"Episode reward": -102.23490566909236, "Episode length": 999, "Policy Loss": -13.264225006103516, "Value Loss": 0.03128490969538689, "_runtime": 504.90862488746643, "_timestamp": 1585076759.2540882, "_step": 430}
{"Episode reward": -100.39607376265526, "Episode length": 999, "Policy Loss": -12.941120147705078, "Value Loss": 0.0334884449839592, "_runtime": 506.0592849254608, "_timestamp": 1585076760.4047482, "_step": 431}
{"Episode reward": -105.00011767926429, "Episode length": 999, "Policy Loss": -14.047479629516602, "Value Loss": 0.03566620871424675, "_runtime": 507.1893970966339, "_timestamp": 1585076761.5348604, "_step": 432}
{"Episode reward": -102.9864297448578, "Episode length": 999, "Policy Loss": -13.332609176635742, "Value Loss": 0.03247014805674553, "_runtime": 508.32588624954224, "_timestamp": 1585076762.6713495, "_step": 433}
{"Episode reward": -101.0771504851972, "Episode length": 999, "Policy Loss": -13.004252433776855, "Value Loss": 0.030105888843536377, "_runtime": 509.4752776622772, "_timestamp": 1585076763.820741, "_step": 434}
{"Episode reward": -87.31044376614692, "Episode length": 999, "Policy Loss": -10.708548545837402, "Value Loss": 0.021123871207237244, "_runtime": 510.5904121398926, "_timestamp": 1585076764.9358754, "_step": 435}
{"Episode reward": -104.93482437651087, "Episode length": 999, "Policy Loss": -13.701560974121094, "Value Loss": 0.03197556361556053, "_runtime": 511.7746551036835, "_timestamp": 1585076766.1201184, "_step": 436}
{"Episode reward": -101.81396659520945, "Episode length": 999, "Policy Loss": -12.983874320983887, "Value Loss": 0.029125822708010674, "_runtime": 512.9196503162384, "_timestamp": 1585076767.2651136, "_step": 437}
{"Episode reward": -101.67968359949253, "Episode length": 999, "Policy Loss": -12.936521530151367, "Value Loss": 0.03085191734135151, "_runtime": 514.0548231601715, "_timestamp": 1585076768.4002864, "_step": 438}
{"Episode reward": -103.10297628341294, "Episode length": 999, "Policy Loss": -13.515198707580566, "Value Loss": 0.03213852643966675, "_runtime": 515.2140510082245, "_timestamp": 1585076769.5595143, "_step": 439}
{"Episode reward": -106.53596911169595, "Episode length": 999, "Policy Loss": -13.835925102233887, "Value Loss": 0.03550510108470917, "_runtime": 516.3524279594421, "_timestamp": 1585076770.6978912, "_step": 440}
{"Episode reward": -104.81993376641083, "Episode length": 999, "Policy Loss": -13.792460441589355, "Value Loss": 0.03282276540994644, "_runtime": 517.4786694049835, "_timestamp": 1585076771.8241327, "_step": 441}
{"Episode reward": -103.02555340365915, "Episode length": 999, "Policy Loss": -13.555606842041016, "Value Loss": 0.029749153181910515, "_runtime": 518.6327631473541, "_timestamp": 1585076772.9782264, "_step": 442}
{"Episode reward": -106.05851494400405, "Episode length": 999, "Policy Loss": -14.041535377502441, "Value Loss": 0.03262710943818092, "_runtime": 519.7679433822632, "_timestamp": 1585076774.1134067, "_step": 443}
{"Episode reward": -98.13892433329647, "Episode length": 999, "Policy Loss": -12.470961570739746, "Value Loss": 0.026779459789395332, "_runtime": 520.8816387653351, "_timestamp": 1585076775.227102, "_step": 444}
{"Episode reward": -107.75261532806614, "Episode length": 999, "Policy Loss": -14.257172584533691, "Value Loss": 0.035234082490205765, "_runtime": 522.0490455627441, "_timestamp": 1585076776.3945088, "_step": 445}
{"Episode reward": -94.88232282045942, "Episode length": 999, "Policy Loss": -12.158060073852539, "Value Loss": 0.029790598899126053, "_runtime": 523.0520033836365, "_timestamp": 1585076777.3974667, "_step": 446}
{"Episode reward": 15.222552919637138, "Episode length": 881, "Policy Loss": 4.104527473449707, "Value Loss": 11.397211074829102, "_runtime": 524.165896654129, "_timestamp": 1585076778.51136, "_step": 447}
{"Episode reward": -94.72828319934048, "Episode length": 999, "Policy Loss": -11.88349723815918, "Value Loss": 0.024726493284106255, "_runtime": 525.3045454025269, "_timestamp": 1585076779.6500087, "_step": 448}
{"Episode reward": -94.62140926392229, "Episode length": 999, "Policy Loss": -11.989717483520508, "Value Loss": 0.02558251842856407, "_runtime": 526.4557476043701, "_timestamp": 1585076780.8012109, "_step": 449}
{"Episode reward": -100.64876499474941, "Episode length": 999, "Policy Loss": -12.808943748474121, "Value Loss": 0.029923535883426666, "_runtime": 527.6158635616302, "_timestamp": 1585076781.9613268, "_step": 450}
{"Episode reward": -102.1126717656193, "Episode length": 999, "Policy Loss": -13.297760963439941, "Value Loss": 0.03147494047880173, "_runtime": 528.7811603546143, "_timestamp": 1585076783.1266236, "_step": 451}
{"Episode reward": -93.82475401618487, "Episode length": 999, "Policy Loss": -11.800668716430664, "Value Loss": 0.02533496543765068, "_runtime": 529.8991770744324, "_timestamp": 1585076784.2446404, "_step": 452}
{"Episode reward": -89.67569537482309, "Episode length": 999, "Policy Loss": -11.180720329284668, "Value Loss": 0.025565795600414276, "_runtime": 531.0320355892181, "_timestamp": 1585076785.3774989, "_step": 453}
{"Episode reward": -95.91935307703655, "Episode length": 999, "Policy Loss": -12.132311820983887, "Value Loss": 0.03226641193032265, "_runtime": 532.2153265476227, "_timestamp": 1585076786.5607898, "_step": 454}
{"Episode reward": -96.45978058827932, "Episode length": 999, "Policy Loss": -12.235352516174316, "Value Loss": 0.029112353920936584, "_runtime": 533.3535196781158, "_timestamp": 1585076787.698983, "_step": 455}
{"Episode reward": -104.0100656764281, "Episode length": 999, "Policy Loss": -13.81904125213623, "Value Loss": 0.033398326486349106, "_runtime": 534.549134016037, "_timestamp": 1585076788.8945973, "_step": 456}
{"Episode reward": -101.32358701376414, "Episode length": 999, "Policy Loss": -13.072505950927734, "Value Loss": 0.028338588774204254, "_runtime": 535.7119555473328, "_timestamp": 1585076790.0574188, "_step": 457}
{"Episode reward": -106.9471316005929, "Episode length": 999, "Policy Loss": -14.196978569030762, "Value Loss": 0.036173660308122635, "_runtime": 536.8823823928833, "_timestamp": 1585076791.2278457, "_step": 458}
{"Episode reward": -105.53647558392919, "Episode length": 999, "Policy Loss": -13.646636009216309, "Value Loss": 0.032164961099624634, "_runtime": 538.0281960964203, "_timestamp": 1585076792.3736594, "_step": 459}
{"Episode reward": -97.18273109783156, "Episode length": 999, "Policy Loss": -12.379878044128418, "Value Loss": 0.03045787289738655, "_runtime": 539.1634633541107, "_timestamp": 1585076793.5089266, "_step": 460}
{"Episode reward": -98.56363017229239, "Episode length": 999, "Policy Loss": -12.822378158569336, "Value Loss": 0.028058217838406563, "_runtime": 540.335385799408, "_timestamp": 1585076794.680849, "_step": 461}
{"Episode reward": -101.68153302287357, "Episode length": 999, "Policy Loss": -13.120400428771973, "Value Loss": 0.03340158611536026, "_runtime": 541.4798741340637, "_timestamp": 1585076795.8253374, "_step": 462}
{"Episode reward": -93.51475601962794, "Episode length": 999, "Policy Loss": -11.863319396972656, "Value Loss": 0.02409091778099537, "_runtime": 542.6141278743744, "_timestamp": 1585076796.9595912, "_step": 463}
{"Episode reward": -100.6086315968398, "Episode length": 999, "Policy Loss": -12.922245025634766, "Value Loss": 0.02914620190858841, "_runtime": 543.8050429821014, "_timestamp": 1585076798.1505063, "_step": 464}
{"Episode reward": -94.79301066248179, "Episode length": 999, "Policy Loss": -12.065864562988281, "Value Loss": 0.026713777333498, "_runtime": 544.9319498538971, "_timestamp": 1585076799.2774131, "_step": 465}
{"Episode reward": -98.23262614987172, "Episode length": 999, "Policy Loss": -12.524801254272461, "Value Loss": 0.030586285516619682, "_runtime": 546.037299156189, "_timestamp": 1585076800.3827624, "_step": 466}
{"Episode reward": -108.79394303059448, "Episode length": 999, "Policy Loss": -14.476569175720215, "Value Loss": 0.03839040547609329, "_runtime": 547.189923286438, "_timestamp": 1585076801.5353866, "_step": 467}
{"Episode reward": -100.50828010938821, "Episode length": 999, "Policy Loss": -12.889516830444336, "Value Loss": 0.02915022149682045, "_runtime": 548.3133165836334, "_timestamp": 1585076802.6587799, "_step": 468}
{"Episode reward": -104.3210627696354, "Episode length": 999, "Policy Loss": -13.568448066711426, "Value Loss": 0.0332362987101078, "_runtime": 549.4362123012543, "_timestamp": 1585076803.7816756, "_step": 469}
{"Episode reward": -98.99633639961398, "Episode length": 999, "Policy Loss": -12.576753616333008, "Value Loss": 0.02888943813741207, "_runtime": 550.5930650234222, "_timestamp": 1585076804.9385283, "_step": 470}
{"Episode reward": -96.29279829251595, "Episode length": 999, "Policy Loss": -12.221997261047363, "Value Loss": 0.026512615382671356, "_runtime": 551.7581923007965, "_timestamp": 1585076806.1036556, "_step": 471}
{"Episode reward": -95.84476594641495, "Episode length": 999, "Policy Loss": -12.08875560760498, "Value Loss": 0.026883382350206375, "_runtime": 552.9436254501343, "_timestamp": 1585076807.2890887, "_step": 472}
{"Episode reward": -102.36516078440422, "Episode length": 999, "Policy Loss": -13.316709518432617, "Value Loss": 0.0315396822988987, "_runtime": 554.0725145339966, "_timestamp": 1585076808.4179778, "_step": 473}
{"Episode reward": -97.88060202970908, "Episode length": 999, "Policy Loss": -12.542407989501953, "Value Loss": 0.029481425881385803, "_runtime": 555.1950488090515, "_timestamp": 1585076809.540512, "_step": 474}
{"Episode reward": -94.71513512478889, "Episode length": 999, "Policy Loss": -11.957283020019531, "Value Loss": 0.026159392669796944, "_runtime": 556.3387060165405, "_timestamp": 1585076810.6841693, "_step": 475}
{"Episode reward": -94.40994349415664, "Episode length": 999, "Policy Loss": -12.10972785949707, "Value Loss": 0.024769652634859085, "_runtime": 557.5242409706116, "_timestamp": 1585076811.8697042, "_step": 476}
{"Episode reward": -93.56616421765204, "Episode length": 999, "Policy Loss": -11.64403247833252, "Value Loss": 0.027219783514738083, "_runtime": 558.678156375885, "_timestamp": 1585076813.0236197, "_step": 477}
{"Episode reward": -92.10152127190192, "Episode length": 999, "Policy Loss": -11.422099113464355, "Value Loss": 0.026585916057229042, "_runtime": 559.8184287548065, "_timestamp": 1585076814.163892, "_step": 478}
{"Episode reward": -92.53968691138284, "Episode length": 999, "Policy Loss": -11.647765159606934, "Value Loss": 0.024303650483489037, "_runtime": 560.9372642040253, "_timestamp": 1585076815.2827275, "_step": 479}
{"Episode reward": -97.60710158321841, "Episode length": 999, "Policy Loss": -12.464288711547852, "Value Loss": 0.02882789634168148, "_runtime": 562.105396270752, "_timestamp": 1585076816.4508595, "_step": 480}
{"Episode reward": -106.65826655071461, "Episode length": 999, "Policy Loss": -13.983250617980957, "Value Loss": 0.033162571489810944, "_runtime": 563.2625210285187, "_timestamp": 1585076817.6079843, "_step": 481}
{"Episode reward": -99.85212981658506, "Episode length": 999, "Policy Loss": -13.149235725402832, "Value Loss": 0.03230999782681465, "_runtime": 564.4329857826233, "_timestamp": 1585076818.778449, "_step": 482}
{"Episode reward": -94.94435872347727, "Episode length": 999, "Policy Loss": -11.818180084228516, "Value Loss": 0.0259513258934021, "_runtime": 565.6072494983673, "_timestamp": 1585076819.9527128, "_step": 483}
{"Episode reward": -86.45528744177726, "Episode length": 999, "Policy Loss": -10.58768081665039, "Value Loss": 0.02165491320192814, "_runtime": 566.7969064712524, "_timestamp": 1585076821.1423697, "_step": 484}
{"Episode reward": -97.89277258632633, "Episode length": 999, "Policy Loss": -12.648279190063477, "Value Loss": 0.028074461966753006, "_runtime": 567.9798600673676, "_timestamp": 1585076822.3253233, "_step": 485}
{"Episode reward": -101.13525424070288, "Episode length": 999, "Policy Loss": -13.05940055847168, "Value Loss": 0.02935614064335823, "_runtime": 568.8849413394928, "_timestamp": 1585076823.2304046, "_step": 486}
{"Episode reward": 11.15765204222292, "Episode length": 796, "Policy Loss": 2.659823179244995, "Value Loss": 12.590570449829102, "_runtime": 570.0352301597595, "_timestamp": 1585076824.3806934, "_step": 487}
{"Episode reward": -105.69860264871707, "Episode length": 999, "Policy Loss": -13.827019691467285, "Value Loss": 0.03169141709804535, "_runtime": 571.2261290550232, "_timestamp": 1585076825.5715923, "_step": 488}
{"Episode reward": -104.41093718844287, "Episode length": 999, "Policy Loss": -13.56195068359375, "Value Loss": 0.032973043620586395, "_runtime": 572.4180014133453, "_timestamp": 1585076826.7634647, "_step": 489}
{"Episode reward": -103.21965523990846, "Episode length": 999, "Policy Loss": -13.372653007507324, "Value Loss": 0.029049387201666832, "_runtime": 573.5764548778534, "_timestamp": 1585076827.9219182, "_step": 490}
{"Episode reward": -98.98867605466714, "Episode length": 999, "Policy Loss": -12.697301864624023, "Value Loss": 0.029852978885173798, "_runtime": 574.7513971328735, "_timestamp": 1585076829.0968604, "_step": 491}
{"Episode reward": -96.83667013085082, "Episode length": 999, "Policy Loss": -12.160116195678711, "Value Loss": 0.026922449469566345, "_runtime": 575.9046788215637, "_timestamp": 1585076830.250142, "_step": 492}
{"Episode reward": -99.20580762901201, "Episode length": 999, "Policy Loss": -12.733214378356934, "Value Loss": 0.028542794287204742, "_runtime": 577.0778150558472, "_timestamp": 1585076831.4232783, "_step": 493}
{"Episode reward": -91.91713841682987, "Episode length": 999, "Policy Loss": -11.388819694519043, "Value Loss": 0.023976663127541542, "_runtime": 578.2234661579132, "_timestamp": 1585076832.5689294, "_step": 494}
{"Episode reward": -106.1080752942512, "Episode length": 999, "Policy Loss": -13.805909156799316, "Value Loss": 0.0335005447268486, "_runtime": 579.3845472335815, "_timestamp": 1585076833.7300105, "_step": 495}
{"Episode reward": -95.77879698152903, "Episode length": 999, "Policy Loss": -12.010663986206055, "Value Loss": 0.028026217594742775, "_runtime": 580.6127631664276, "_timestamp": 1585076834.9582264, "_step": 496}
{"Episode reward": -106.57812006352975, "Episode length": 999, "Policy Loss": -13.831113815307617, "Value Loss": 0.03179624676704407, "_runtime": 581.7591807842255, "_timestamp": 1585076836.104644, "_step": 497}
{"Episode reward": -102.78698387645294, "Episode length": 999, "Policy Loss": -13.309539794921875, "Value Loss": 0.03138238936662674, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594, -486.9173278808594]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-444.64874267578125, -433.6449279785156, -422.64111328125, -411.6373291015625, -400.6335144042969, -389.62969970703125, -378.6258850097656, -367.6220703125, -356.6182861328125, -345.6144714355469, -334.61065673828125, -323.60687255859375, -312.60302734375, -301.5992431640625, -290.5954284667969, -279.59161376953125, -268.58782958984375, -257.583984375, -246.5802001953125, -235.57638549804688, -224.5725860595703, -213.5687713623047, -202.56497192382812, -191.5611572265625, -180.55734252929688, -169.55352783203125, -158.54974365234375, -147.54592895507812, -136.5421142578125, -125.53829956054688, -114.53451538085938, -103.53070068359375, -92.52688598632812, -81.5230712890625, -70.51925659179688, -59.515472412109375, -48.51165771484375, -37.507843017578125, -26.5040283203125, -15.500244140625, -4.496429443359375, 6.50738525390625, 17.511199951171875, 28.5150146484375, 39.518798828125, 50.522613525390625, 61.52642822265625, 72.53021240234375, 83.5340576171875, 94.537841796875, 105.54168701171875, 116.54547119140625, 127.54925537109375, 138.5531005859375, 149.556884765625, 160.5606689453125, 171.56451416015625, 182.56829833984375, 193.5721435546875, 204.575927734375, 215.5797119140625, 226.58355712890625, 237.58734130859375, 248.5911865234375, 259.594970703125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-234.7506561279297, -226.9407958984375, -219.1309356689453, -211.32107543945312, -203.51121520996094, -195.70135498046875, -187.8914794921875, -180.08163452148438, -172.27175903320312, -164.4619140625, -156.65203857421875, -148.84219360351562, -141.03231811523438, -133.2224578857422, -125.41259765625, -117.60273742675781, -109.79287719726562, -101.98301696777344, -94.17315673828125, -86.36329650878906, -78.55343627929688, -70.74357604980469, -62.9337158203125, -55.12385559082031, -47.31398010253906, -39.504119873046875, -31.694259643554688, -23.8843994140625, -16.074539184570312, -8.264678955078125, -0.4548187255859375, 7.35504150390625, 15.164901733398438, 22.974777221679688, 30.784622192382812, 38.59449768066406, 46.40434265136719, 54.21421813964844, 62.02406311035156, 69.83393859863281, 77.64378356933594, 85.45365905761719, 93.26350402832031, 101.07337951660156, 108.88322448730469, 116.69309997558594, 124.50294494628906, 132.3128204345703, 140.12269592285156, 147.9325408935547, 155.74241638183594, 163.55226135253906, 171.3621368408203, 179.17198181152344, 186.9818572998047, 194.7917022705078, 202.60157775878906, 210.4114227294922, 218.22129821777344, 226.03114318847656, 233.8410186767578, 241.65086364746094, 249.4607391357422, 257.27056884765625, 265.0804443359375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 5.0, 7.0, 5.0, 9.0, 16.0, 11.0, 33.0, 29.0, 21.0, 38.0, 43.0, 43.0, 45.0, 25.0, 18.0, 20.0, 10.0, 11.0, 13.0, 11.0, 15.0, 5.0, 7.0, 7.0, 4.0, 7.0, 7.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-203.82867431640625, -197.04763793945312, -190.26661682128906, -183.48558044433594, -176.7045440673828, -169.92352294921875, -163.14248657226562, -156.3614501953125, -149.58041381835938, -142.7993927001953, -136.0183563232422, -129.23733520507812, -122.456298828125, -115.67526245117188, -108.89423370361328, -102.11319732666016, -95.33216857910156, -88.55113983154297, -81.77010345458984, -74.98907470703125, -68.20803833007812, -61.42701721191406, -54.64598083496094, -47.86494445800781, -41.08392333984375, -34.302886962890625, -27.5218505859375, -20.740814208984375, -13.959793090820312, -7.1787567138671875, -0.3977203369140625, 6.38330078125, 13.164337158203125, 19.94537353515625, 26.726394653320312, 33.50743103027344, 40.28846740722656, 47.069488525390625, 53.85052490234375, 60.631561279296875, 67.41259765625, 74.19363403320312, 80.97463989257812, 87.75567626953125, 94.53671264648438, 101.3177490234375, 108.09878540039062, 114.87982177734375, 121.66082763671875, 128.44186401367188, 135.222900390625, 142.00393676757812, 148.78497314453125, 155.56600952148438, 162.3470458984375, 169.1280517578125, 175.90908813476562, 182.69012451171875, 189.47116088867188, 196.252197265625, 203.03323364257812, 209.81423950195312, 216.59527587890625, 223.37631225585938, 230.1573486328125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-194.5703125, -189.87899780273438, -185.18768310546875, -180.49636840820312, -175.8050537109375, -171.11375427246094, -166.4224395751953, -161.7311248779297, -157.03981018066406, -152.34849548339844, -147.6571807861328, -142.96588134765625, -138.27456665039062, -133.583251953125, -128.89193725585938, -124.20062255859375, -119.50930786132812, -114.8179931640625, -110.12667846679688, -105.43537139892578, -100.74405670166016, -96.05274200439453, -91.36143493652344, -86.67012023925781, -81.97880554199219, -77.28749084472656, -72.59617614746094, -67.90486907958984, -63.21356201171875, -58.522247314453125, -53.8309326171875, -49.139617919921875, -44.44830322265625, -39.756988525390625, -35.065673828125, -30.374359130859375, -25.68304443359375, -20.991744995117188, -16.300430297851562, -11.609115600585938, -6.9178009033203125, -2.2264862060546875, 2.4648284912109375, 7.1561431884765625, 11.847442626953125, 16.53875732421875, 21.230072021484375, 25.92138671875, 30.612701416015625, 35.30401611328125, 39.995330810546875, 44.6866455078125, 49.377960205078125, 54.06925964355469, 58.76057434082031, 63.451904296875, 68.1431884765625, 72.83450317382812, 77.52581787109375, 82.21713256835938, 86.908447265625, 91.59976196289062, 96.29107666015625, 100.98239135742188, 105.6737060546875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 32.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-62.48890686035156, -59.7178955078125, -56.94688415527344, -54.17587661743164, -51.40486526489258, -48.633853912353516, -45.86284637451172, -43.091835021972656, -40.320823669433594, -37.54981231689453, -34.77880096435547, -32.00779342651367, -29.23678207397461, -26.465770721435547, -23.69476318359375, -20.923751831054688, -18.152740478515625, -15.381729125976562, -12.6107177734375, -9.839710235595703, -7.068698883056641, -4.297687530517578, -1.5266799926757812, 1.2443313598632812, 4.015342712402344, 6.786354064941406, 9.557365417480469, 12.328376770019531, 15.099380493164062, 17.870391845703125, 20.641403198242188, 23.41241455078125, 26.183425903320312, 28.954437255859375, 31.725448608398438, 34.4964599609375, 37.26747131347656, 40.038475036621094, 42.809486389160156, 45.58049774169922, 48.35150909423828, 51.122520446777344, 53.893531799316406, 56.66454315185547, 59.435546875, 62.20655822753906, 64.97756958007812, 67.74858093261719, 70.51959228515625, 73.29060363769531, 76.06161499023438, 78.83262634277344, 81.6036376953125, 84.37464904785156, 87.14566040039062, 89.91667175292969, 92.68766784667969, 95.45867919921875, 98.22969055175781, 101.00070190429688, 103.77171325683594, 106.542724609375, 109.31373596191406, 112.08474731445312, 114.85575866699219]}, "_runtime": 582.9449858665466, "_timestamp": 1585076837.2904491, "_step": 498}
{"Episode reward": -108.82990597601984, "Episode length": 999, "Policy Loss": -14.664793968200684, "Value Loss": 0.038304876536130905, "_runtime": 584.0755248069763, "_timestamp": 1585076838.420988, "_step": 499}
{"Episode reward": -94.70612298608403, "Episode length": 999, "Policy Loss": -12.019124984741211, "Value Loss": 0.02672458253800869, "_runtime": 584.0755248069763, "_timestamp": 1585076838.420988, "_step": 500}
