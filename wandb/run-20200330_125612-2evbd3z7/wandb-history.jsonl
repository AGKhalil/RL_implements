{"Episode reward": -97.55464829097787, "Episode length": 999, "Policy Loss": -0.010378175415098667, "Value Loss": 0.05111042037606239, "_runtime": 3076.150118112564, "_timestamp": 1585572991.9947515, "_step": 0}
{"Episode reward": -95.85003625506579, "Episode length": 999, "Policy Loss": 0.06505744159221649, "Value Loss": 89.3226089477539, "_runtime": 3077.6317331790924, "_timestamp": 1585572993.4763665, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 222.09666442871094, "Value Loss": 10008.7607421875, "_runtime": 3079.1991262435913, "_timestamp": 1585572995.0437596, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.158707618713379, "Value Loss": 15505.53125, "_runtime": 3080.737540960312, "_timestamp": 1585572996.5821743, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.928692102432251, "Value Loss": 2064.3076171875, "_runtime": 3082.2580420970917, "_timestamp": 1585572998.1026754, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.889019250869751, "Value Loss": 142.8115997314453, "_runtime": 3083.8307297229767, "_timestamp": 1585572999.675363, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.337625026702881, "Value Loss": 204.6782989501953, "_runtime": 3085.3908698558807, "_timestamp": 1585573001.2355032, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.22936725616455, "Value Loss": 450.71124267578125, "_runtime": 3086.926933288574, "_timestamp": 1585573002.7715666, "_step": 7}
{"Episode reward": -99.85753004199297, "Episode length": 999, "Policy Loss": -10.819619178771973, "Value Loss": 1437.301513671875, "_runtime": 3088.5060937404633, "_timestamp": 1585573004.350727, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.56622886657715, "Value Loss": 117.40625762939453, "_runtime": 3090.068037748337, "_timestamp": 1585573005.912671, "_step": 9}
{"Episode reward": -99.69823371358129, "Episode length": 999, "Policy Loss": 18.860069274902344, "Value Loss": 50.649169921875, "_runtime": 3091.6248545646667, "_timestamp": 1585573007.469488, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 20.610496520996094, "Value Loss": 41.34099197387695, "_runtime": 3093.213226079941, "_timestamp": 1585573009.0578594, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 20.748414993286133, "Value Loss": 153.2595672607422, "_runtime": 3094.813660144806, "_timestamp": 1585573010.6582935, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 31.928518295288086, "Value Loss": 740.7891235351562, "_runtime": 3096.3780605793, "_timestamp": 1585573012.222694, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 29.356273651123047, "Value Loss": 83.2820816040039, "_runtime": 3097.9641823768616, "_timestamp": 1585573013.8088157, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 26.94289779663086, "Value Loss": 782.6257934570312, "_runtime": 3099.532939195633, "_timestamp": 1585573015.3775725, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 34.742950439453125, "Value Loss": 85.85995483398438, "_runtime": 3101.1022691726685, "_timestamp": 1585573016.9469025, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 41.03540802001953, "Value Loss": 3253.047607421875, "_runtime": 3102.6948153972626, "_timestamp": 1585573018.5394487, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 32.7876091003418, "Value Loss": 499.4184875488281, "_runtime": 3104.265248298645, "_timestamp": 1585573020.1098816, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 22.43596839904785, "Value Loss": 768.0110473632812, "_runtime": 3105.8348574638367, "_timestamp": 1585573021.6794908, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.512085914611816, "Value Loss": 303.9801330566406, "_runtime": 3107.4108171463013, "_timestamp": 1585573023.2554505, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.201580047607422, "Value Loss": 2791.513427734375, "_runtime": 3108.995225429535, "_timestamp": 1585573024.8398588, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5919122695922852, "Value Loss": 4.062484264373779, "_runtime": 3110.5672063827515, "_timestamp": 1585573026.4118397, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002096074866130948, "Value Loss": 189.10498046875, "_runtime": 3112.1543843746185, "_timestamp": 1585573027.9990177, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9356381893157959, "Value Loss": 0.007800044491887093, "_runtime": 3113.7359521389008, "_timestamp": 1585573029.5805855, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0057752132415771, "Value Loss": 0.009013275615870953, "_runtime": 3115.3011004924774, "_timestamp": 1585573031.1457338, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0688279867172241, "Value Loss": 0.010178885422647, "_runtime": 3116.884868621826, "_timestamp": 1585573032.729502, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.341355562210083, "Value Loss": 41.966552734375, "_runtime": 3118.5075509548187, "_timestamp": 1585573034.3521843, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1758729219436646, "Value Loss": 0.012319741770625114, "_runtime": 3120.078985452652, "_timestamp": 1585573035.9236188, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2208720445632935, "Value Loss": 0.013280720449984074, "_runtime": 3121.661409854889, "_timestamp": 1585573037.5060432, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2607799768447876, "Value Loss": 0.014163141138851643, "_runtime": 3123.2225284576416, "_timestamp": 1585573039.0671618, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2959588766098022, "Value Loss": 0.014964548870921135, "_runtime": 3124.7994866371155, "_timestamp": 1585573040.64412, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3268349170684814, "Value Loss": 0.015686094760894775, "_runtime": 3126.370804309845, "_timestamp": 1585573042.2154377, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3537100553512573, "Value Loss": 0.01632797345519066, "_runtime": 3127.9423055648804, "_timestamp": 1585573043.786939, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3768855333328247, "Value Loss": 0.01689184457063675, "_runtime": 3129.505027770996, "_timestamp": 1585573045.349661, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3966883420944214, "Value Loss": 0.017381222918629646, "_runtime": 3131.08562040329, "_timestamp": 1585573046.9302537, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4133789539337158, "Value Loss": 0.017799116671085358, "_runtime": 3132.6576998233795, "_timestamp": 1585573048.5023332, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4271795749664307, "Value Loss": 0.01814841665327549, "_runtime": 3134.232476711273, "_timestamp": 1585573050.07711, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4383139610290527, "Value Loss": 0.018432676792144775, "_runtime": 3135.8038425445557, "_timestamp": 1585573051.648476, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.447022557258606, "Value Loss": 0.018656564876437187, "_runtime": 3137.3747606277466, "_timestamp": 1585573053.219394, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4534685611724854, "Value Loss": 0.018823152408003807, "_runtime": 3138.9381551742554, "_timestamp": 1585573054.7827885, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4578527212142944, "Value Loss": 0.018936891108751297, "_runtime": 3140.518773317337, "_timestamp": 1585573056.3634067, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4603384733200073, "Value Loss": 0.019001511856913567, "_runtime": 3142.1266293525696, "_timestamp": 1585573057.9712627, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.461063265800476, "Value Loss": 0.019020378589630127, "_runtime": 3143.7009942531586, "_timestamp": 1585573059.5456276, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4601292610168457, "Value Loss": 0.01899975724518299, "_runtime": 3145.284111022949, "_timestamp": 1585573061.1287444, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.45779287815094, "Value Loss": 0.018935326486825943, "_runtime": 3146.8636429309845, "_timestamp": 1585573062.7082763, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4540718793869019, "Value Loss": 0.018838783726096153, "_runtime": 3148.4309911727905, "_timestamp": 1585573064.2756245, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.449083924293518, "Value Loss": 0.01870974898338318, "_runtime": 3150.0128173828125, "_timestamp": 1585573065.8574507, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4429616928100586, "Value Loss": 0.018551988527178764, "_runtime": 3151.582630634308, "_timestamp": 1585573067.427264, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.435697078704834, "Value Loss": 0.01838248036801815, "_runtime": 3153.148857116699, "_timestamp": 1585573068.9934905, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4145631790161133, "Value Loss": 1.1471179723739624, "_runtime": 3154.7212722301483, "_timestamp": 1585573070.5659056, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4180467128753662, "Value Loss": 0.01791686937212944, "_runtime": 3156.304922580719, "_timestamp": 1585573072.149556, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4077008962631226, "Value Loss": 0.017656387761235237, "_runtime": 3157.8799970149994, "_timestamp": 1585573073.7246304, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3966681957244873, "Value Loss": 0.01738070696592331, "_runtime": 3159.4504947662354, "_timestamp": 1585573075.295128, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.385009527206421, "Value Loss": 0.017091749235987663, "_runtime": 3161.0325696468353, "_timestamp": 1585573076.877203, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.372804045677185, "Value Loss": 0.016791852191090584, "_runtime": 3162.607086658478, "_timestamp": 1585573078.45172, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3600742816925049, "Value Loss": 0.016481870785355568, "_runtime": 3164.226470708847, "_timestamp": 1585573080.071104, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3468999862670898, "Value Loss": 0.016164105385541916, "_runtime": 3165.8079142570496, "_timestamp": 1585573081.6525476, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3333210945129395, "Value Loss": 0.01583983562886715, "_runtime": 3167.3742246627808, "_timestamp": 1585573083.218858, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3193585872650146, "Value Loss": 0.015509813092648983, "_runtime": 3168.9434609413147, "_timestamp": 1585573084.7880943, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.305052399635315, "Value Loss": 0.015175280161201954, "_runtime": 3170.506362438202, "_timestamp": 1585573086.3509958, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2904624938964844, "Value Loss": 0.014837896451354027, "_runtime": 3172.066431045532, "_timestamp": 1585573087.9110644, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.275631308555603, "Value Loss": 0.01449879352003336, "_runtime": 3173.632788181305, "_timestamp": 1585573089.4774215, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2605371475219727, "Value Loss": 0.014157701283693314, "_runtime": 3175.1963810920715, "_timestamp": 1585573091.0410144, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2452616691589355, "Value Loss": 0.013816634193062782, "_runtime": 3176.7577378749847, "_timestamp": 1585573092.6023712, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2298038005828857, "Value Loss": 0.01347574032843113, "_runtime": 3178.323724269867, "_timestamp": 1585573094.1683576, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.21420419216156, "Value Loss": 0.01313603762537241, "_runtime": 3179.891424179077, "_timestamp": 1585573095.7360575, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1984829902648926, "Value Loss": 0.012798101641237736, "_runtime": 3181.4431109428406, "_timestamp": 1585573097.2877443, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1826612949371338, "Value Loss": 0.012462418526411057, "_runtime": 3183.010086774826, "_timestamp": 1585573098.85472, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1667391061782837, "Value Loss": 0.012129098176956177, "_runtime": 3184.5647580623627, "_timestamp": 1585573100.4093914, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1507759094238281, "Value Loss": 0.011799484491348267, "_runtime": 3186.11417555809, "_timestamp": 1585573101.958809, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1347525119781494, "Value Loss": 0.011473167687654495, "_runtime": 3187.7020580768585, "_timestamp": 1585573103.5466914, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1186881065368652, "Value Loss": 0.01115062739700079, "_runtime": 3189.2661197185516, "_timestamp": 1585573105.110753, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1026246547698975, "Value Loss": 0.010832687839865685, "_runtime": 3190.8157563209534, "_timestamp": 1585573106.6603897, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0865596532821655, "Value Loss": 0.010519344359636307, "_runtime": 3192.373373746872, "_timestamp": 1585573108.218007, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0704962015151978, "Value Loss": 0.010210605338215828, "_runtime": 3193.9366846084595, "_timestamp": 1585573109.781318, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0544523000717163, "Value Loss": 0.009906831197440624, "_runtime": 3195.4983007907867, "_timestamp": 1585573111.3429341, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.038468837738037, "Value Loss": 0.009608779102563858, "_runtime": 3197.0606849193573, "_timestamp": 1585573112.9053183, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0225063562393188, "Value Loss": 0.009315638802945614, "_runtime": 3198.625904083252, "_timestamp": 1585573114.4705374, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0066239833831787, "Value Loss": 0.00902849342674017, "_runtime": 3200.1851603984833, "_timestamp": 1585573116.0297937, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9907817244529724, "Value Loss": 0.008746551349759102, "_runtime": 3201.7489252090454, "_timestamp": 1585573117.5935585, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9750210046768188, "Value Loss": 0.00847049430012703, "_runtime": 3203.3008925914764, "_timestamp": 1585573119.145526, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9593407511711121, "Value Loss": 0.008200245909392834, "_runtime": 3204.861439704895, "_timestamp": 1585573120.706073, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9437616467475891, "Value Loss": 0.007936072535812855, "_runtime": 3206.427426099777, "_timestamp": 1585573122.2720594, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9282630681991577, "Value Loss": 0.007677558343857527, "_runtime": 3207.9830491542816, "_timestamp": 1585573123.8276825, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9128658771514893, "Value Loss": 0.007424976211041212, "_runtime": 3209.5443971157074, "_timestamp": 1585573125.3890305, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8975892663002014, "Value Loss": 0.007178550586104393, "_runtime": 3211.1450374126434, "_timestamp": 1585573126.9896708, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8824141621589661, "Value Loss": 0.006937877275049686, "_runtime": 3212.711011171341, "_timestamp": 1585573128.5556445, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8673609495162964, "Value Loss": 0.006703181657940149, "_runtime": 3214.2608730793, "_timestamp": 1585573130.1055064, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8524080514907837, "Value Loss": 0.006474052090197802, "_runtime": 3215.8275094032288, "_timestamp": 1585573131.6721427, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8376175761222839, "Value Loss": 0.006251323968172073, "_runtime": 3217.381702899933, "_timestamp": 1585573133.2263362, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8229271173477173, "Value Loss": 0.0060339756309986115, "_runtime": 3218.9434762001038, "_timestamp": 1585573134.7881095, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8083987832069397, "Value Loss": 0.005822803359478712, "_runtime": 3220.5084624290466, "_timestamp": 1585573136.3530958, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7939912676811218, "Value Loss": 0.005617107264697552, "_runtime": 3222.0738892555237, "_timestamp": 1585573137.9185226, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7797258496284485, "Value Loss": 0.005417072679847479, "_runtime": 3223.6263399124146, "_timestamp": 1585573139.4709733, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7656015753746033, "Value Loss": 0.0052225952968001366, "_runtime": 3225.1845104694366, "_timestamp": 1585573141.0291438, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7516189813613892, "Value Loss": 0.005033567547798157, "_runtime": 3226.7507259845734, "_timestamp": 1585573142.5953593, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7377969622612, "Value Loss": 0.0048501514829695225, "_runtime": 3228.302318572998, "_timestamp": 1585573144.146952, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7241172790527344, "Value Loss": 0.00467196200042963, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3229.870171546936, "_timestamp": 1585573145.714805, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.710578978061676, "Value Loss": 0.004498898983001709, "_runtime": 3231.4354543685913, "_timestamp": 1585573147.2800877, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6972026228904724, "Value Loss": 0.004331110045313835, "_runtime": 3232.9841380119324, "_timestamp": 1585573148.8287714, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6839871406555176, "Value Loss": 0.004168479237705469, "_runtime": 3234.589896440506, "_timestamp": 1585573150.4345298, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6709343194961548, "Value Loss": 0.0040108924731612206, "_runtime": 3236.1417684555054, "_timestamp": 1585573151.9864018, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6580220460891724, "Value Loss": 0.0038580012042075396, "_runtime": 3237.700443506241, "_timestamp": 1585573153.5450768, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6452919840812683, "Value Loss": 0.0037101723719388247, "_runtime": 3239.2623834609985, "_timestamp": 1585573155.1070168, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6326934099197388, "Value Loss": 0.0035667116753757, "_runtime": 3240.8251552581787, "_timestamp": 1585573156.6697886, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6202663779258728, "Value Loss": 0.0034279765095561743, "_runtime": 3242.3723645210266, "_timestamp": 1585573158.2169979, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6080012321472168, "Value Loss": 0.003293745219707489, "_runtime": 3243.934507369995, "_timestamp": 1585573159.7791407, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5958975553512573, "Value Loss": 0.003163910936564207, "_runtime": 3245.4877038002014, "_timestamp": 1585573161.3323371, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5839559435844421, "Value Loss": 0.0030383714474737644, "_runtime": 3247.033402442932, "_timestamp": 1585573162.8780358, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5721753835678101, "Value Loss": 0.002917019883170724, "_runtime": 3248.586340904236, "_timestamp": 1585573164.4309742, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5605564117431641, "Value Loss": 0.0027997561264783144, "_runtime": 3250.1395049095154, "_timestamp": 1585573165.9841383, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5490994453430176, "Value Loss": 0.002686477964743972, "_runtime": 3251.692489385605, "_timestamp": 1585573167.5371227, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5378037095069885, "Value Loss": 0.00257708877325058, "_runtime": 3253.2431490421295, "_timestamp": 1585573169.0877824, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5266703963279724, "Value Loss": 0.002471490763127804, "_runtime": 3254.796527147293, "_timestamp": 1585573170.6411605, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5156983137130737, "Value Loss": 0.0023695866111665964, "_runtime": 3256.3924791812897, "_timestamp": 1585573172.2371125, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5048877596855164, "Value Loss": 0.0022712815552949905, "_runtime": 3257.953859806061, "_timestamp": 1585573173.7984931, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49423882365226746, "Value Loss": 0.0021764831617474556, "_runtime": 3259.515033006668, "_timestamp": 1585573175.3596663, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48375216126441956, "Value Loss": 0.0020850987639278173, "_runtime": 3261.0732007026672, "_timestamp": 1585573176.917834, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4734265208244324, "Value Loss": 0.0019970377907156944, "_runtime": 3262.6357975006104, "_timestamp": 1585573178.4804308, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46325236558914185, "Value Loss": 0.0019121273653581738, "_runtime": 3264.1830563545227, "_timestamp": 1585573180.0276897, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45324042439460754, "Value Loss": 0.0018303662072867155, "_runtime": 3265.742503643036, "_timestamp": 1585573181.587137, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4433896839618683, "Value Loss": 0.0017516689840704203, "_runtime": 3267.294234275818, "_timestamp": 1585573183.1388676, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43369024991989136, "Value Loss": 0.001675872947089374, "_runtime": 3268.8566539287567, "_timestamp": 1585573184.7012873, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42415329813957214, "Value Loss": 0.001602974021807313, "_runtime": 3270.4161949157715, "_timestamp": 1585573186.2608283, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4147672653198242, "Value Loss": 0.0015328152803704143, "_runtime": 3271.9766829013824, "_timestamp": 1585573187.8213162, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40554308891296387, "Value Loss": 0.0014653957914561033, "_runtime": 3273.5374953746796, "_timestamp": 1585573189.3821287, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3964602053165436, "Value Loss": 0.0014004906406626105, "_runtime": 3275.0967469215393, "_timestamp": 1585573190.9413803, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38753899931907654, "Value Loss": 0.0013381721219047904, "_runtime": 3276.657418012619, "_timestamp": 1585573192.5020514, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3787696957588196, "Value Loss": 0.001278294948861003, "_runtime": 3278.2185168266296, "_timestamp": 1585573194.0631502, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37014129757881165, "Value Loss": 0.0012207204708829522, "_runtime": 3279.8113424777985, "_timestamp": 1585573195.6559758, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3616647720336914, "Value Loss": 0.0011654490372166038, "_runtime": 3281.371508836746, "_timestamp": 1585573197.2161422, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3533397614955902, "Value Loss": 0.001112413126975298, "_runtime": 3282.9328660964966, "_timestamp": 1585573198.7774994, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34516605734825134, "Value Loss": 0.0010615434730425477, "_runtime": 3284.490747451782, "_timestamp": 1585573200.3353808, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3371239900588989, "Value Loss": 0.001012653112411499, "_runtime": 3286.053240299225, "_timestamp": 1585573201.8978736, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32923319935798645, "Value Loss": 0.0009658040944486856, "_runtime": 3287.614626646042, "_timestamp": 1585573203.45926, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32148417830467224, "Value Loss": 0.0009208749979734421, "_runtime": 3289.16161942482, "_timestamp": 1585573205.0062528, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31387650966644287, "Value Loss": 0.0008778067422099411, "_runtime": 3290.7131605148315, "_timestamp": 1585573206.5577939, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30641013383865356, "Value Loss": 0.000836542050819844, "_runtime": 3292.2549657821655, "_timestamp": 1585573208.0995991, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.299075186252594, "Value Loss": 0.0007969704456627369, "_runtime": 3293.8015916347504, "_timestamp": 1585573209.646225, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29188182950019836, "Value Loss": 0.0007590930908918381, "_runtime": 3295.353238582611, "_timestamp": 1585573211.197872, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2848297655582428, "Value Loss": 0.0007228560862131417, "_runtime": 3296.91477560997, "_timestamp": 1585573212.759409, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.277898907661438, "Value Loss": 0.0006881054723635316, "_runtime": 3298.4546434879303, "_timestamp": 1585573214.2992768, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2711096405982971, "Value Loss": 0.0006548940436914563, "_runtime": 3300.0177178382874, "_timestamp": 1585573215.8623512, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26445165276527405, "Value Loss": 0.0006231224979273975, "_runtime": 3301.567728996277, "_timestamp": 1585573217.4123623, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25792503356933594, "Value Loss": 0.0005927448510192335, "_runtime": 3303.1486341953278, "_timestamp": 1585573218.9932675, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2515196204185486, "Value Loss": 0.0005636693676933646, "_runtime": 3304.711904525757, "_timestamp": 1585573220.5565379, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24524538218975067, "Value Loss": 0.0005358989583328366, "_runtime": 3306.263217687607, "_timestamp": 1585573222.107851, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23909243941307068, "Value Loss": 0.0005093459622003138, "_runtime": 3307.823324918747, "_timestamp": 1585573223.6679583, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23306089639663696, "Value Loss": 0.0004839718749281019, "_runtime": 3309.386967897415, "_timestamp": 1585573225.2316012, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22715051472187042, "Value Loss": 0.00045973615488037467, "_runtime": 3310.9480240345, "_timestamp": 1585573226.7926574, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22137156128883362, "Value Loss": 0.0004366411885712296, "_runtime": 3312.5069403648376, "_timestamp": 1585573228.3515737, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21570348739624023, "Value Loss": 0.0004145681450609118, "_runtime": 3314.069211244583, "_timestamp": 1585573229.9138446, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21014685928821564, "Value Loss": 0.0003934837586712092, "_runtime": 3315.6225233078003, "_timestamp": 1585573231.4671566, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20471131801605225, "Value Loss": 0.00037339175469242036, "_runtime": 3317.1884961128235, "_timestamp": 1585573233.0331295, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19938695430755615, "Value Loss": 0.00035422114888206124, "_runtime": 3318.759132385254, "_timestamp": 1585573234.6037657, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.194183811545372, "Value Loss": 0.00033597485162317753, "_runtime": 3320.3261575698853, "_timestamp": 1585573236.170791, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18908166885375977, "Value Loss": 0.00031855155248194933, "_runtime": 3321.9019589424133, "_timestamp": 1585573237.7465923, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18409062922000885, "Value Loss": 0.00030195657745935023, "_runtime": 3323.4814977645874, "_timestamp": 1585573239.326131, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17921072244644165, "Value Loss": 0.00028616038616746664, "_runtime": 3325.049372434616, "_timestamp": 1585573240.8940058, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1744319647550583, "Value Loss": 0.0002711024135351181, "_runtime": 3326.6606755256653, "_timestamp": 1585573242.5053089, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16976438462734222, "Value Loss": 0.0002567874325904995, "_runtime": 3328.2386345863342, "_timestamp": 1585573244.083268, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1651875376701355, "Value Loss": 0.00024312830646522343, "_runtime": 3329.817011833191, "_timestamp": 1585573245.6616452, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16072191298007965, "Value Loss": 0.000230160920182243, "_runtime": 3331.3707847595215, "_timestamp": 1585573247.215418, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1563573032617569, "Value Loss": 0.0002178299182560295, "_runtime": 3332.949377298355, "_timestamp": 1585573248.7940106, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15208368003368378, "Value Loss": 0.00020608493650797755, "_runtime": 3334.518443584442, "_timestamp": 1585573250.363077, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14791099727153778, "Value Loss": 0.00019493160652928054, "_runtime": 3336.0935473442078, "_timestamp": 1585573251.9381807, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1438293308019638, "Value Loss": 0.00018432164506521076, "_runtime": 3337.659013032913, "_timestamp": 1585573253.5036464, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1398385912179947, "Value Loss": 0.00017423497047275305, "_runtime": 3339.237844467163, "_timestamp": 1585573255.0824778, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13594892621040344, "Value Loss": 0.00016467661771457642, "_runtime": 3340.8149189949036, "_timestamp": 1585573256.6595523, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1321399062871933, "Value Loss": 0.000155578411067836, "_runtime": 3342.373113632202, "_timestamp": 1585573258.217747, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12842197716236115, "Value Loss": 0.00014694654964841902, "_runtime": 3343.939273118973, "_timestamp": 1585573259.7839065, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12479490041732788, "Value Loss": 0.00013876330922357738, "_runtime": 3345.5168669223785, "_timestamp": 1585573261.3615003, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12124866247177124, "Value Loss": 0.00013098916679155082, "_runtime": 3347.0919892787933, "_timestamp": 1585573262.9366226, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11779332160949707, "Value Loss": 0.00012362973939161748, "_runtime": 3348.669545650482, "_timestamp": 1585573264.514179, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11441890150308609, "Value Loss": 0.00011664784688036889, "_runtime": 3350.2813074588776, "_timestamp": 1585573266.1259408, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11111516505479813, "Value Loss": 0.00011000879021594301, "_runtime": 3351.8585567474365, "_timestamp": 1585573267.70319, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10790228843688965, "Value Loss": 0.00010373913391958922, "_runtime": 3353.428288459778, "_timestamp": 1585573269.2729218, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10476018488407135, "Value Loss": 9.778539970284328e-05, "_runtime": 3355.0053730010986, "_timestamp": 1585573270.8500063, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10169894248247147, "Value Loss": 9.215394675265998e-05, "_runtime": 3356.582011461258, "_timestamp": 1585573272.4266448, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09871845692396164, "Value Loss": 8.68316346895881e-05, "_runtime": 3358.1610600948334, "_timestamp": 1585573274.0056934, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09580874443054199, "Value Loss": 8.178837015293539e-05, "_runtime": 3359.7276680469513, "_timestamp": 1585573275.5723014, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09296973794698715, "Value Loss": 7.70131591707468e-05, "_runtime": 3361.305376768112, "_timestamp": 1585573277.15001, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09020145982503891, "Value Loss": 7.249507325468585e-05, "_runtime": 3362.881640434265, "_timestamp": 1585573278.7262738, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08750390261411667, "Value Loss": 6.82238387526013e-05, "_runtime": 3364.4477953910828, "_timestamp": 1585573280.2924287, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08486700803041458, "Value Loss": 6.417393160518259e-05, "_runtime": 3366.027207136154, "_timestamp": 1585573281.8718405, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08231090754270554, "Value Loss": 6.036644845153205e-05, "_runtime": 3367.6088557243347, "_timestamp": 1585573283.453489, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07981540262699127, "Value Loss": 5.676155706169084e-05, "_runtime": 3369.175921201706, "_timestamp": 1585573285.0205545, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07738048583269119, "Value Loss": 5.3351192036643624e-05, "_runtime": 3370.7535178661346, "_timestamp": 1585573286.5981512, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07500623166561127, "Value Loss": 5.0127506256103516e-05, "_runtime": 3372.3553488254547, "_timestamp": 1585573288.1999822, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07270270586013794, "Value Loss": 4.709581480710767e-05, "_runtime": 3373.918788433075, "_timestamp": 1585573289.7634218, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07045980542898178, "Value Loss": 4.423479185788892e-05, "_runtime": 3375.4886610507965, "_timestamp": 1585573291.3332944, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06826743483543396, "Value Loss": 4.152485416852869e-05, "_runtime": 3377.0576388835907, "_timestamp": 1585573292.9022722, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06613566726446152, "Value Loss": 3.8971949834376574e-05, "_runtime": 3378.624430656433, "_timestamp": 1585573294.469064, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06406449526548386, "Value Loss": 3.656919579952955e-05, "_runtime": 3380.187218427658, "_timestamp": 1585573296.0318518, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.062043800950050354, "Value Loss": 3.429875141591765e-05, "_runtime": 3381.756677865982, "_timestamp": 1585573297.6013112, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06008383631706238, "Value Loss": 3.216590630472638e-05, "_runtime": 3383.3229455947876, "_timestamp": 1585573299.167579, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05817428231239319, "Value Loss": 3.0153902116580866e-05, "_runtime": 3384.9021904468536, "_timestamp": 1585573300.7468238, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.056315310299396515, "Value Loss": 2.8257536541786976e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3386.4819264411926, "_timestamp": 1585573302.3265598, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05451691523194313, "Value Loss": 2.6481580789550208e-05, "_runtime": 3388.0583822727203, "_timestamp": 1585573303.9030156, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05275895074009895, "Value Loss": 2.4801276595098898e-05, "_runtime": 3389.6386563777924, "_timestamp": 1585573305.4832897, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.051051534712314606, "Value Loss": 2.322194450243842e-05, "_runtime": 3391.2026908397675, "_timestamp": 1585573307.0473242, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04938448965549469, "Value Loss": 2.173013854189776e-05, "_runtime": 3392.7810077667236, "_timestamp": 1585573308.625641, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04777810722589493, "Value Loss": 2.03394429263426e-05, "_runtime": 3394.36066198349, "_timestamp": 1585573310.2052953, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04621207341551781, "Value Loss": 1.9027975213248283e-05, "_runtime": 3395.9741444587708, "_timestamp": 1585573311.8187778, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.044686511158943176, "Value Loss": 1.7792383005144075e-05, "_runtime": 3397.550330400467, "_timestamp": 1585573313.3949637, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043201327323913574, "Value Loss": 1.6629353922326118e-05, "_runtime": 3399.116364002228, "_timestamp": 1585573314.9609973, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041766680777072906, "Value Loss": 1.554321715957485e-05, "_runtime": 3400.693657875061, "_timestamp": 1585573316.5382912, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04037243500351906, "Value Loss": 1.4522820492857136e-05, "_runtime": 3402.2563905715942, "_timestamp": 1585573318.101024, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03901860490441322, "Value Loss": 1.356514712824719e-05, "_runtime": 3403.8339726924896, "_timestamp": 1585573319.678606, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03769510239362717, "Value Loss": 1.2660494576266501e-05, "_runtime": 3405.398358821869, "_timestamp": 1585573321.2429922, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.036422088742256165, "Value Loss": 1.1819816791103221e-05, "_runtime": 3406.9629406929016, "_timestamp": 1585573322.807574, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03517938032746315, "Value Loss": 1.102700480259955e-05, "_runtime": 3408.539759874344, "_timestamp": 1585573324.3843932, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03397710621356964, "Value Loss": 1.0286174983775709e-05, "_runtime": 3410.1166582107544, "_timestamp": 1585573325.9612916, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032805148512125015, "Value Loss": 9.588811735739e-06, "_runtime": 3411.6821961402893, "_timestamp": 1585573327.5268295, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03167356178164482, "Value Loss": 8.93871947482694e-06, "_runtime": 3413.246232032776, "_timestamp": 1585573329.0908654, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030582426115870476, "Value Loss": 8.333455298270565e-06, "_runtime": 3414.826026916504, "_timestamp": 1585573330.6706603, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029511502012610435, "Value Loss": 7.760028893244453e-06, "_runtime": 3416.391149997711, "_timestamp": 1585573332.2357833, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02848094515502453, "Value Loss": 7.227539754239842e-06, "_runtime": 3417.970479249954, "_timestamp": 1585573333.8151126, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02748074010014534, "Value Loss": 6.728805601596832e-06, "_runtime": 3419.5607476234436, "_timestamp": 1585573335.405381, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.026510830968618393, "Value Loss": 6.2622129917144775e-06, "_runtime": 3421.124669075012, "_timestamp": 1585573336.9693024, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025571230798959732, "Value Loss": 5.8261903177481145e-06, "_runtime": 3422.7033326625824, "_timestamp": 1585573338.547966, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02465183474123478, "Value Loss": 5.4147676564753056e-06, "_runtime": 3424.2587893009186, "_timestamp": 1585573340.1034226, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02377285808324814, "Value Loss": 5.035517006035661e-06, "_runtime": 3425.8365228176117, "_timestamp": 1585573341.6811562, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0229140967130661, "Value Loss": 4.6782820390944835e-06, "_runtime": 3427.392786502838, "_timestamp": 1585573343.2374198, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02208562009036541, "Value Loss": 4.346105924923904e-06, "_runtime": 3428.958614587784, "_timestamp": 1585573344.803248, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02128746546804905, "Value Loss": 4.0376553442911245e-06, "_runtime": 3430.5335495471954, "_timestamp": 1585573346.378183, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020509522408246994, "Value Loss": 3.7479344427993055e-06, "_runtime": 3432.112135410309, "_timestamp": 1585573347.9567688, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019761884585022926, "Value Loss": 3.4796687486959854e-06, "_runtime": 3433.6762948036194, "_timestamp": 1585573349.5209281, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019034452736377716, "Value Loss": 3.2282116535498062e-06, "_runtime": 3435.23765873909, "_timestamp": 1585573351.082292, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01832723803818226, "Value Loss": 2.992778718180489e-06, "_runtime": 3436.8176403045654, "_timestamp": 1585573352.6622736, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017640214413404465, "Value Loss": 2.772608013401623e-06, "_runtime": 3438.394669532776, "_timestamp": 1585573354.2393029, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016983505338430405, "Value Loss": 2.5700142032292206e-06, "_runtime": 3439.969714164734, "_timestamp": 1585573355.8143475, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016346998512744904, "Value Loss": 2.3809875528968405e-06, "_runtime": 3441.546263694763, "_timestamp": 1585573357.390897, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015730706974864006, "Value Loss": 2.2048411665309686e-06, "_runtime": 3443.1521689891815, "_timestamp": 1585573358.9968023, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01513461209833622, "Value Loss": 2.0409104308782844e-06, "_runtime": 3444.728464126587, "_timestamp": 1585573360.5730975, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014558731578290462, "Value Loss": 1.8885481267716386e-06, "_runtime": 3446.293200969696, "_timestamp": 1585573362.1378343, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014003044925630093, "Value Loss": 1.7471359115006635e-06, "_runtime": 3447.871268749237, "_timestamp": 1585573363.715902, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013467582874000072, "Value Loss": 1.6160707900780835e-06, "_runtime": 3449.4345569610596, "_timestamp": 1585573365.2791903, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012942216359078884, "Value Loss": 1.4924446531949798e-06, "_runtime": 3450.9997754096985, "_timestamp": 1585573366.8444088, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012447156943380833, "Value Loss": 1.3804527725369553e-06, "_runtime": 3452.5760419368744, "_timestamp": 1585573368.4206753, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011962203308939934, "Value Loss": 1.27498060464859e-06, "_runtime": 3454.139837026596, "_timestamp": 1585573369.9844704, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011487351730465889, "Value Loss": 1.1757662150557735e-06, "_runtime": 3455.7171523571014, "_timestamp": 1585573371.5617857, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011042810045182705, "Value Loss": 1.086526481230976e-06, "_runtime": 3457.2707340717316, "_timestamp": 1585573373.1153674, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01059827022254467, "Value Loss": 1.0008085382651188e-06, "_runtime": 3458.8363876342773, "_timestamp": 1585573374.681021, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01018404122442007, "Value Loss": 9.241048246622086e-07, "_runtime": 3460.413944721222, "_timestamp": 1585573376.258578, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009769805707037449, "Value Loss": 8.504582069690514e-07, "_runtime": 3461.980028152466, "_timestamp": 1585573377.8246615, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009385885670781136, "Value Loss": 7.849308190088777e-07, "_runtime": 3463.5555713176727, "_timestamp": 1585573379.4002047, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009001964703202248, "Value Loss": 7.220302791210997e-07, "_runtime": 3465.16787815094, "_timestamp": 1585573381.0125115, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008638246916234493, "Value Loss": 6.648630801464606e-07, "_runtime": 3466.7464442253113, "_timestamp": 1585573382.5910776, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008284631185233593, "Value Loss": 6.115441237852792e-07, "_runtime": 3468.313163280487, "_timestamp": 1585573384.1577966, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007951228879392147, "Value Loss": 5.633128807858157e-07, "_runtime": 3469.888024330139, "_timestamp": 1585573385.7326577, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007627882994711399, "Value Loss": 5.184293740967405e-07, "_runtime": 3471.4648501873016, "_timestamp": 1585573387.3094835, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007304623257368803, "Value Loss": 4.7541919911964214e-07, "_runtime": 3473.037961959839, "_timestamp": 1585573388.8825953, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007001522462815046, "Value Loss": 4.367839778751659e-07, "_runtime": 3474.6173901557922, "_timestamp": 1585573390.4620235, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006708533503115177, "Value Loss": 4.0099257603287697e-07, "_runtime": 3476.1993491649628, "_timestamp": 1585573392.0439825, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0064357491210103035, "Value Loss": 3.6904469880028046e-07, "_runtime": 3477.76996922493, "_timestamp": 1585573393.6146026, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006162959150969982, "Value Loss": 3.3842300695141603e-07, "_runtime": 3479.333300590515, "_timestamp": 1585573395.177934, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005900278687477112, "Value Loss": 3.1018865342957724e-07, "_runtime": 3480.886538743973, "_timestamp": 1585573396.731172, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005647694226354361, "Value Loss": 2.841998139047064e-07, "_runtime": 3482.4383034706116, "_timestamp": 1585573398.2829368, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00540521927177906, "Value Loss": 2.603202062800847e-07, "_runtime": 3483.9934482574463, "_timestamp": 1585573399.8380816, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005172846373170614, "Value Loss": 2.384185791015625e-07, "_runtime": 3485.5458176136017, "_timestamp": 1585573401.390451, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004950573667883873, "Value Loss": 2.1836964947397064e-07, "_runtime": 3487.0973682403564, "_timestamp": 1585573402.9420016, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004738405346870422, "Value Loss": 2.0005342094009393e-07, "_runtime": 3488.68874335289, "_timestamp": 1585573404.5333767, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00452624075114727, "Value Loss": 1.825392246246338e-07, "_runtime": 3490.2518084049225, "_timestamp": 1585573406.0964417, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004334278404712677, "Value Loss": 1.6738437125241035e-07, "_runtime": 3491.81361579895, "_timestamp": 1585573407.6582491, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0041423155926167965, "Value Loss": 1.528860309463198e-07, "_runtime": 3493.3777227401733, "_timestamp": 1585573409.222356, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003960459493100643, "Value Loss": 1.3975659385323524e-07, "_runtime": 3494.9408020973206, "_timestamp": 1585573410.7854354, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0037786010652780533, "Value Loss": 1.2721645248348068e-07, "_runtime": 3496.503429889679, "_timestamp": 1585573412.3480632, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0036068474873900414, "Value Loss": 1.1591418314083057e-07, "_runtime": 3498.0779337882996, "_timestamp": 1585573413.9225671, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034451945684850216, "Value Loss": 1.0575696052228523e-07, "_runtime": 3499.6558043956757, "_timestamp": 1585573415.5004377, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00329364906065166, "Value Loss": 9.665743050391029e-08, "_runtime": 3501.2205517292023, "_timestamp": 1585573417.065185, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003142098430544138, "Value Loss": 8.796722994475203e-08, "_runtime": 3502.79598069191, "_timestamp": 1585573418.640614, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003000654513016343, "Value Loss": 8.022561104326087e-08, "_runtime": 3504.3727192878723, "_timestamp": 1585573420.2173526, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00285920943133533, "Value Loss": 7.284051406486469e-08, "_runtime": 3505.9500114917755, "_timestamp": 1585573421.7946448, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027278675697743893, "Value Loss": 6.630213533753704e-08, "_runtime": 3507.51554107666, "_timestamp": 1585573423.3601744, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002606609370559454, "Value Loss": 6.053867451782935e-08, "_runtime": 3509.0937588214874, "_timestamp": 1585573424.9383922, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0024752868339419365, "Value Loss": 5.459241236849266e-08, "_runtime": 3510.662366628647, "_timestamp": 1585573426.507, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002364151179790497, "Value Loss": 4.980029189027846e-08, "_runtime": 3512.2618565559387, "_timestamp": 1585573428.10649, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00225301762111485, "Value Loss": 4.522825491903859e-08, "_runtime": 3513.826658964157, "_timestamp": 1585573429.6712923, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0021418819669634104, "Value Loss": 4.087632987648249e-08, "_runtime": 3515.3858058452606, "_timestamp": 1585573431.2304392, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002040848368778825, "Value Loss": 3.7111021811142564e-08, "_runtime": 3516.952353477478, "_timestamp": 1585573432.7969868, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0019398172153159976, "Value Loss": 3.3527612686157227e-08, "_runtime": 3518.505114555359, "_timestamp": 1585573434.349748, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018488882342353463, "Value Loss": 3.0458060962246236e-08, "_runtime": 3520.068745136261, "_timestamp": 1585573435.9133785, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017579600680619478, "Value Loss": 2.7535861590877175e-08, "_runtime": 3521.6322631835938, "_timestamp": 1585573437.4768965, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0016771333757787943, "Value Loss": 2.506203600205481e-08, "_runtime": 3523.1934773921967, "_timestamp": 1585573439.0381107, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0015862049767747521, "Value Loss": 2.241813135128723e-08, "_runtime": 3524.754604101181, "_timestamp": 1585573440.5992374, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0015154819702729583, "Value Loss": 2.0463630789890885e-08, "_runtime": 3526.317372560501, "_timestamp": 1585573442.162006, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014346567913889885, "Value Loss": 1.8339051166549325e-08, "_runtime": 3527.8718497753143, "_timestamp": 1585573443.716483, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001363933552056551, "Value Loss": 1.6575643968508302e-08, "_runtime": 3529.418280363083, "_timestamp": 1585573445.2629137, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0012932115932926536, "Value Loss": 1.4901161193847656e-08, "_runtime": 3530.9825751781464, "_timestamp": 1585573446.8272085, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0012325921561568975, "Value Loss": 1.3536919141188264e-08, "_runtime": 3532.5473716259003, "_timestamp": 1585573448.392005, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0011618691496551037, "Value Loss": 1.2028067430946976e-08, "_runtime": 3534.108716249466, "_timestamp": 1585573449.9533496, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0011113537475466728, "Value Loss": 1.1004885891452432e-08, "_runtime": 3535.7082035541534, "_timestamp": 1585573451.552837, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001050734193995595, "Value Loss": 9.837094694375992e-09, "_runtime": 3537.268172979355, "_timestamp": 1585573453.1128063, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0009901148732751608, "Value Loss": 8.734787115827203e-09, "_runtime": 3538.827686548233, "_timestamp": 1585573454.67232, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0009395984816364944, "Value Loss": 7.866219675634056e-09, "_runtime": 3540.3657512664795, "_timestamp": 1585573456.2103846, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008890828466974199, "Value Loss": 7.043126970529556e-09, "_runtime": 3541.926277399063, "_timestamp": 1585573457.7709107, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000848669558763504, "Value Loss": 6.417394615709782e-09, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3543.4871878623962, "_timestamp": 1585573459.3318212, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007981542148627341, "Value Loss": 5.676156433764845e-09, "_runtime": 3545.051347255707, "_timestamp": 1585573460.8959806, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007577409851364791, "Value Loss": 5.115907697472721e-09, "_runtime": 3546.620236635208, "_timestamp": 1585573462.46487, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007173283956944942, "Value Loss": 4.584762791637331e-09, "_runtime": 3548.1900386810303, "_timestamp": 1585573464.034672, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006769152241759002, "Value Loss": 4.082721716258675e-09, "_runtime": 3549.7606344223022, "_timestamp": 1585573465.6052678, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006365025765262544, "Value Loss": 3.609784471336752e-09, "_runtime": 3551.321739435196, "_timestamp": 1585573467.1663728, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006061923922970891, "Value Loss": 3.2741809263825417e-09, "_runtime": 3552.8909888267517, "_timestamp": 1585573468.7356222, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005657800938934088, "Value Loss": 2.852175384759903e-09, "_runtime": 3554.4642448425293, "_timestamp": 1585573470.3088782, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005354704917408526, "Value Loss": 2.5547706172801554e-09, "_runtime": 3556.0436668395996, "_timestamp": 1585573471.8883002, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005051605403423309, "Value Loss": 2.2737367544323206e-09, "_runtime": 3557.6242644786835, "_timestamp": 1585573473.4688978, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0004748508508782834, "Value Loss": 2.0090737962163985e-09, "_runtime": 3559.222645998001, "_timestamp": 1585573475.0672793, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00045464449794963, "Value Loss": 1.8417267710901797e-09, "_runtime": 3560.7896778583527, "_timestamp": 1585573476.6343112, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000424334779381752, "Value Loss": 1.6043486539274454e-09, "_runtime": 3562.34263586998, "_timestamp": 1585573478.1872692, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0004041285428684205, "Value Loss": 1.4551915228366852e-09, "_runtime": 3563.907605409622, "_timestamp": 1585573479.7522388, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00037381885340437293, "Value Loss": 1.2450982467271388e-09, "_runtime": 3565.4598290920258, "_timestamp": 1585573481.3044624, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00035361223854124546, "Value Loss": 1.114131009671837e-09, "_runtime": 3567.0129523277283, "_timestamp": 1585573482.8575857, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00033340597292408347, "Value Loss": 9.904397302307189e-10, "_runtime": 3568.5676879882812, "_timestamp": 1585573484.4123213, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00031319964909926057, "Value Loss": 8.74024408403784e-10, "_runtime": 3570.118432044983, "_timestamp": 1585573485.9630654, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000292993092443794, "Value Loss": 7.648850441910326e-10, "_runtime": 3571.6675939559937, "_timestamp": 1585573487.5122273, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0002727867104113102, "Value Loss": 6.630216375924647e-10, "_runtime": 3573.219630241394, "_timestamp": 1585573489.0642636, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00025258027017116547, "Value Loss": 5.684341886080801e-10, "_runtime": 3574.784968852997, "_timestamp": 1585573490.6296022, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0002424771519144997, "Value Loss": 5.238689482212067e-10, "_runtime": 3576.347349882126, "_timestamp": 1585573492.1919832, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00022227071167435497, "Value Loss": 4.4019543565809727e-10, "_runtime": 3577.912333726883, "_timestamp": 1585573493.756967, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000212167389690876, "Value Loss": 4.0108716348186135e-10, "_runtime": 3579.475697040558, "_timestamp": 1585573495.3203304, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00020206427143421024, "Value Loss": 3.637978807091713e-10, "_runtime": 3581.075006008148, "_timestamp": 1585573496.9196393, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00018185781664215028, "Value Loss": 2.9467628337442875e-10, "_runtime": 3582.6396672725677, "_timestamp": 1585573498.4843006, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00017175450921058655, "Value Loss": 2.6284396881237626e-10, "_runtime": 3584.1938140392303, "_timestamp": 1585573500.0384474, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0001616514491615817, "Value Loss": 2.3283064365386963e-10, "_runtime": 3585.756122112274, "_timestamp": 1585573501.6007555, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00015154809807427227, "Value Loss": 2.0463630789890885e-10, "_runtime": 3587.3220431804657, "_timestamp": 1585573503.1666765, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0001414450234733522, "Value Loss": 1.7826096154749393e-10, "_runtime": 3588.887652158737, "_timestamp": 1585573504.7322855, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00013134177424944937, "Value Loss": 1.5370460459962487e-10, "_runtime": 3590.4492938518524, "_timestamp": 1585573506.2939272, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00012123857595724985, "Value Loss": 1.3096723705530167e-10, "_runtime": 3592.0134439468384, "_timestamp": 1585573507.8580773, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00011113535583717749, "Value Loss": 1.1004885891452432e-10, "_runtime": 3593.5776855945587, "_timestamp": 1585573509.422319, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00010103213571710512, "Value Loss": 9.094947017729282e-11, "_runtime": 3595.131110906601, "_timestamp": 1585573510.9757442, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 3596.6955959796906, "_timestamp": 1585573512.5402293, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 3598.260184764862, "_timestamp": 1585573514.104818, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.082572458079085e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 3599.8213183879852, "_timestamp": 1585573515.6659517, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.07225117366761e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 3601.386521100998, "_timestamp": 1585573517.2311544, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.07225117366761e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 3602.9512293338776, "_timestamp": 1585573518.7958627, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3604.546501159668, "_timestamp": 1585573520.3911345, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 3606.111760854721, "_timestamp": 1585573521.9563942, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3607.673134326935, "_timestamp": 1585573523.5177677, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 3609.2385075092316, "_timestamp": 1585573525.0831409, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.464295525110959e-11, "_runtime": 3610.790054798126, "_timestamp": 1585573526.6346881, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3612.351548910141, "_timestamp": 1585573528.1961823, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 3613.900087594986, "_timestamp": 1585573529.744721, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3615.4634165763855, "_timestamp": 1585573531.30805, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3617.0285897254944, "_timestamp": 1585573532.873223, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 3618.5867927074432, "_timestamp": 1585573534.431426, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3620.149968147278, "_timestamp": 1585573535.9946015, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3621.7030568122864, "_timestamp": 1585573537.5476902, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3623.2617762088776, "_timestamp": 1585573539.1064095, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3624.812522649765, "_timestamp": 1585573540.657156, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 3626.374409675598, "_timestamp": 1585573542.219043, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3627.971386194229, "_timestamp": 1585573543.8160195, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3629.5254373550415, "_timestamp": 1585573545.3700707, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3631.0904080867767, "_timestamp": 1585573546.9350414, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3632.64071393013, "_timestamp": 1585573548.4853473, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3634.2063825130463, "_timestamp": 1585573550.0510159, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3635.750044107437, "_timestamp": 1585573551.5946774, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3637.29918384552, "_timestamp": 1585573553.1438172, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3638.8640053272247, "_timestamp": 1585573554.7086387, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3640.4275362491608, "_timestamp": 1585573556.2721696, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3641.989904165268, "_timestamp": 1585573557.8345375, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3643.553995370865, "_timestamp": 1585573559.3986287, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.283240749053361e-15, "_runtime": 3645.123258829117, "_timestamp": 1585573560.9678922, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3646.684049844742, "_timestamp": 1585573562.5286832, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3648.255884408951, "_timestamp": 1585573564.1005177, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3649.8290140628815, "_timestamp": 1585573565.6736474, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3651.4358389377594, "_timestamp": 1585573567.2804723, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.829483995814776e-14, "_runtime": 3653.0171570777893, "_timestamp": 1585573568.8617904, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3654.581428050995, "_timestamp": 1585573570.4260614, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3656.1409916877747, "_timestamp": 1585573571.985625, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3657.7132484912872, "_timestamp": 1585573573.5578818, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3659.28812623024, "_timestamp": 1585573575.1327596, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3660.849128484726, "_timestamp": 1585573576.6937618, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3662.425306081772, "_timestamp": 1585573578.2699394, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3664.003720998764, "_timestamp": 1585573579.8483543, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3665.571435689926, "_timestamp": 1585573581.416069, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3667.13942861557, "_timestamp": 1585573582.984062, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3668.7084622383118, "_timestamp": 1585573584.5530956, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3670.275258541107, "_timestamp": 1585573586.119892, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3671.860600233078, "_timestamp": 1585573587.7052336, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3673.466069459915, "_timestamp": 1585573589.3107028, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3675.0330526828766, "_timestamp": 1585573590.877686, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3676.600604057312, "_timestamp": 1585573592.4452374, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3678.178243637085, "_timestamp": 1585573594.022877, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3679.7559344768524, "_timestamp": 1585573595.6005678, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 3681.336880683899, "_timestamp": 1585573597.181514, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103214663104154e-05, "Value Loss": 9.823270669118145e-13, "_runtime": 3682.9091386795044, "_timestamp": 1585573598.753772, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3684.476094007492, "_timestamp": 1585573600.3207273, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3686.0482766628265, "_timestamp": 1585573601.89291, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3687.6108984947205, "_timestamp": 1585573603.4555318, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3689.1792080402374, "_timestamp": 1585573605.0238414, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3690.750242471695, "_timestamp": 1585573606.5948758, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3692.3241295814514, "_timestamp": 1585573608.168763, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3693.8924763202667, "_timestamp": 1585573609.7371097, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3695.4630386829376, "_timestamp": 1585573611.307672, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0226652353017016e-08, "Value Loss": 8.557808324829996e-14, "_runtime": 3697.076143503189, "_timestamp": 1585573612.9207768, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3698.641766309738, "_timestamp": 1585573614.4863997, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.283240579646771e-14, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3700.217702150345, "_timestamp": 1585573616.0623355, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3701.7961699962616, "_timestamp": 1585573617.6408033, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3703.3738627433777, "_timestamp": 1585573619.218496, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3704.9527871608734, "_timestamp": 1585573620.7974205, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3706.531195640564, "_timestamp": 1585573622.375829, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3708.0964772701263, "_timestamp": 1585573623.9411106, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 4.1878633671782114e-14, "_runtime": 3709.664827823639, "_timestamp": 1585573625.5094612, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3711.244350194931, "_timestamp": 1585573627.0889835, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3712.8204386234283, "_timestamp": 1585573628.665072, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3714.392506122589, "_timestamp": 1585573630.2371395, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3715.9537489414215, "_timestamp": 1585573631.7983823, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3717.5241293907166, "_timestamp": 1585573633.3687627, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3719.096253633499, "_timestamp": 1585573634.940887, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3720.6871106624603, "_timestamp": 1585573636.531744, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3722.245805501938, "_timestamp": 1585573638.0904388, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3723.821120262146, "_timestamp": 1585573639.6657536, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3725.3964788913727, "_timestamp": 1585573641.2411122, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0226652353017016e-08, "Value Loss": 8.557808324829996e-14, "_runtime": 3726.969715356827, "_timestamp": 1585573642.8143487, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3728.544118642807, "_timestamp": 1585573644.388752, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.64740308296756e-14, "_runtime": 3730.1168553829193, "_timestamp": 1585573645.9614887, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.64740308296756e-14, "_runtime": 3731.67817401886, "_timestamp": 1585573647.5228074, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3733.25319981575, "_timestamp": 1585573649.0978332, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3734.8166642189026, "_timestamp": 1585573650.6612976, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3736.3898220062256, "_timestamp": 1585573652.2344553, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3737.963134288788, "_timestamp": 1585573653.8077676, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.465322170120345e-14, "_runtime": 3739.539146900177, "_timestamp": 1585573655.3837802, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3741.1116831302643, "_timestamp": 1585573656.9563165, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3742.674416065216, "_timestamp": 1585573658.5190494, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.283240579646771e-14, "_runtime": 3744.284313440323, "_timestamp": 1585573660.1289468, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3745.853369951248, "_timestamp": 1585573661.6980033, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3747.4247765541077, "_timestamp": 1585573663.26941, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3748.9752855300903, "_timestamp": 1585573664.8199189, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3750.5342762470245, "_timestamp": 1585573666.3789096, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3752.0945978164673, "_timestamp": 1585573667.9392312, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3753.64715218544, "_timestamp": 1585573669.4917855, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3755.2112624645233, "_timestamp": 1585573671.0558958, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.829483995814776e-14, "_runtime": 3756.7731046676636, "_timestamp": 1585573672.617738, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.283240579646771e-14, "_runtime": 3758.334693670273, "_timestamp": 1585573674.179327, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3759.8854253292084, "_timestamp": 1585573675.7300587, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3761.446635246277, "_timestamp": 1585573677.2912686, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3763.0087237358093, "_timestamp": 1585573678.853357, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3764.557583808899, "_timestamp": 1585573680.4022171, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3766.110736846924, "_timestamp": 1585573681.9553702, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3767.710214138031, "_timestamp": 1585573683.5548475, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3769.2710206508636, "_timestamp": 1585573685.115654, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.64740308296756e-14, "_runtime": 3770.831473827362, "_timestamp": 1585573686.6761072, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3772.385053396225, "_timestamp": 1585573688.2296867, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3773.94544005394, "_timestamp": 1585573689.7900734, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3775.4908213615417, "_timestamp": 1585573691.3354547, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3777.05486369133, "_timestamp": 1585573692.899497, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3778.6190712451935, "_timestamp": 1585573694.4637046, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3780.1632583141327, "_timestamp": 1585573696.0078917, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3781.7167789936066, "_timestamp": 1585573697.5614123, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3783.281096458435, "_timestamp": 1585573699.1257298, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3784.8437790870667, "_timestamp": 1585573700.6884124, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 4.5520255316858216e-14, "_runtime": 3786.4079620838165, "_timestamp": 1585573702.2525954, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3787.969956636429, "_timestamp": 1585573703.81459, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3789.5698053836823, "_timestamp": 1585573705.4144387, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3791.122547864914, "_timestamp": 1585573706.9671812, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3792.6838850975037, "_timestamp": 1585573708.5285184, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3794.2481508255005, "_timestamp": 1585573710.0927842, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3795.7925312519073, "_timestamp": 1585573711.6371646, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3797.343406677246, "_timestamp": 1585573713.18804, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3798.8955805301666, "_timestamp": 1585573714.7402139, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3800.4506628513336, "_timestamp": 1585573716.2952962, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3802.0029635429382, "_timestamp": 1585573717.847597, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3803.5580327510834, "_timestamp": 1585573719.402666, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3805.123681306839, "_timestamp": 1585573720.9683146, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3806.6848146915436, "_timestamp": 1585573722.529448, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.465322170120345e-14, "_runtime": 3808.241009235382, "_timestamp": 1585573724.0856426, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3809.8031058311462, "_timestamp": 1585573725.6477392, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3811.366504907608, "_timestamp": 1585573727.2111382, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3812.9534578323364, "_timestamp": 1585573728.7980912, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.465322170120345e-14, "_runtime": 3814.5054371356964, "_timestamp": 1585573730.3500705, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3816.068301677704, "_timestamp": 1585573731.912935, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3817.631153345108, "_timestamp": 1585573733.4757867, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3819.19553732872, "_timestamp": 1585573735.0401707, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3820.7560453414917, "_timestamp": 1585573736.6006787, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3822.3208906650543, "_timestamp": 1585573738.165524, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3823.8821737766266, "_timestamp": 1585573739.726807, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3825.4448108673096, "_timestamp": 1585573741.2894442, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3827.0064582824707, "_timestamp": 1585573742.8510916, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3828.5686407089233, "_timestamp": 1585573744.413274, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3830.1227650642395, "_timestamp": 1585573745.9673984, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3831.683454275131, "_timestamp": 1585573747.5280876, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3833.24653506279, "_timestamp": 1585573749.0911684, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3834.798084974289, "_timestamp": 1585573750.6427183, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3836.398422718048, "_timestamp": 1585573752.243056, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3837.962485074997, "_timestamp": 1585573753.8071184, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3839.52646279335, "_timestamp": 1585573755.3710961, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3841.079909801483, "_timestamp": 1585573756.9245431, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3842.633005619049, "_timestamp": 1585573758.477639, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3844.1734421253204, "_timestamp": 1585573760.0180755, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3845.714941263199, "_timestamp": 1585573761.5595746, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.829483995814776e-14, "_runtime": 3847.279611349106, "_timestamp": 1585573763.1242447, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3848.841377258301, "_timestamp": 1585573764.6860106, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3850.4068093299866, "_timestamp": 1585573766.2514427, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.283240579646771e-14, "_runtime": 3851.9712052345276, "_timestamp": 1585573767.8158386, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3853.5381722450256, "_timestamp": 1585573769.3828056, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 7.101159666799556e-14, "_runtime": 3855.09233045578, "_timestamp": 1585573770.9369638, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 3856.6478912830353, "_timestamp": 1585573772.4925246, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 3856.6478912830353, "_timestamp": 1585573772.4925246, "_step": 499}
