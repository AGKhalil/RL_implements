{"Episode reward": -49.80143537227411, "Episode length": 999, "Policy Loss": -0.06833813339471817, "Value Loss": 0.009695840068161488, "_runtime": 13265.644378900528, "_timestamp": 1585583181.4890122, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5377926826477051, "Value Loss": 0.44529733061790466, "_runtime": 13267.185916423798, "_timestamp": 1585583183.0305498, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.6356418132781982, "Value Loss": 96.8550796508789, "_runtime": 13268.788540840149, "_timestamp": 1585583184.6331742, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8370635509490967, "Value Loss": 110.32537841796875, "_runtime": 13270.369222640991, "_timestamp": 1585583186.213856, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1942052841186523, "Value Loss": 327.7616271972656, "_runtime": 13271.92962694168, "_timestamp": 1585583187.7742603, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3175954818725586, "Value Loss": 183.42697143554688, "_runtime": 13273.534834861755, "_timestamp": 1585583189.3794682, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 22.310100555419922, "Value Loss": 5936.001953125, "_runtime": 13275.122302293777, "_timestamp": 1585583190.9669356, "_step": 6}
{"Episode reward": -99.02589695825141, "Episode length": 999, "Policy Loss": -0.26235735416412354, "Value Loss": 3426.62890625, "_runtime": 13276.683033943176, "_timestamp": 1585583192.5276673, "_step": 7}
{"Episode reward": -79.72067975256708, "Episode length": 999, "Policy Loss": -37.05293655395508, "Value Loss": 13956.6591796875, "_runtime": 13278.277868032455, "_timestamp": 1585583194.1225014, "_step": 8}
{"Episode reward": -71.52399824550854, "Episode length": 999, "Policy Loss": 2.964322805404663, "Value Loss": 294.9328308105469, "_runtime": 13279.878461360931, "_timestamp": 1585583195.7230947, "_step": 9}
{"Episode reward": -71.68553633214856, "Episode length": 999, "Policy Loss": -4.769531726837158, "Value Loss": 688.0172119140625, "_runtime": 13281.433002233505, "_timestamp": 1585583197.2776356, "_step": 10}
{"Episode reward": -71.60770874617481, "Episode length": 999, "Policy Loss": 6.023797988891602, "Value Loss": 630.9828491210938, "_runtime": 13283.03577208519, "_timestamp": 1585583198.8804054, "_step": 11}
{"Episode reward": -69.75631146239638, "Episode length": 999, "Policy Loss": -12.520554542541504, "Value Loss": 4240.41455078125, "_runtime": 13284.666429281235, "_timestamp": 1585583200.5110626, "_step": 12}
{"Episode reward": -69.3754967878851, "Episode length": 999, "Policy Loss": 66.26815795898438, "Value Loss": 7568.70947265625, "_runtime": 13286.250075101852, "_timestamp": 1585583202.0947084, "_step": 13}
{"Episode reward": -66.62198200775214, "Episode length": 999, "Policy Loss": -3.8942039012908936, "Value Loss": 1273.0982666015625, "_runtime": 13287.860105276108, "_timestamp": 1585583203.7047386, "_step": 14}
{"Episode reward": -65.75248496484328, "Episode length": 999, "Policy Loss": 3.8221120834350586, "Value Loss": 1195.5008544921875, "_runtime": 13289.44732952118, "_timestamp": 1585583205.2919629, "_step": 15}
{"Episode reward": -62.4369965076274, "Episode length": 999, "Policy Loss": -5.189544677734375, "Value Loss": 986.8339233398438, "_runtime": 13291.042868852615, "_timestamp": 1585583206.8875022, "_step": 16}
{"Episode reward": -58.00443539442667, "Episode length": 999, "Policy Loss": -40.92988586425781, "Value Loss": 7276.54443359375, "_runtime": 13292.653076410294, "_timestamp": 1585583208.4977098, "_step": 17}
{"Episode reward": -56.53557515795718, "Episode length": 999, "Policy Loss": 2.501361608505249, "Value Loss": 697.7907104492188, "_runtime": 13294.253380298615, "_timestamp": 1585583210.0980136, "_step": 18}
{"Episode reward": -59.15608549971751, "Episode length": 999, "Policy Loss": -12.893383026123047, "Value Loss": 2130.032470703125, "_runtime": 13295.840036153793, "_timestamp": 1585583211.6846695, "_step": 19}
{"Episode reward": -63.70465771599672, "Episode length": 999, "Policy Loss": -8.07791519165039, "Value Loss": 1386.87646484375, "_runtime": 13297.436927556992, "_timestamp": 1585583213.281561, "_step": 20}
{"Episode reward": -59.85154413404271, "Episode length": 999, "Policy Loss": 0.7703948616981506, "Value Loss": 7765.81494140625, "_runtime": 13299.04246544838, "_timestamp": 1585583214.8870988, "_step": 21}
{"Episode reward": -63.37072499371577, "Episode length": 999, "Policy Loss": -2.270195245742798, "Value Loss": 694.083251953125, "_runtime": 13300.617332935333, "_timestamp": 1585583216.4619663, "_step": 22}
{"Episode reward": -64.09834495149202, "Episode length": 999, "Policy Loss": -10.254633903503418, "Value Loss": 1701.9879150390625, "_runtime": 13302.213061571121, "_timestamp": 1585583218.057695, "_step": 23}
{"Episode reward": -64.28552022912959, "Episode length": 999, "Policy Loss": 5.169638156890869, "Value Loss": 457.0096740722656, "_runtime": 13303.807690143585, "_timestamp": 1585583219.6523235, "_step": 24}
{"Episode reward": -62.32608832950461, "Episode length": 999, "Policy Loss": 11.50683879852295, "Value Loss": 2238.25830078125, "_runtime": 13305.40560412407, "_timestamp": 1585583221.2502375, "_step": 25}
{"Episode reward": -66.1084144239023, "Episode length": 999, "Policy Loss": 5.54677677154541, "Value Loss": 380.1002197265625, "_runtime": 13307.038269519806, "_timestamp": 1585583222.8829029, "_step": 26}
{"Episode reward": -65.26500180769176, "Episode length": 999, "Policy Loss": 0.6727650165557861, "Value Loss": 357.2839660644531, "_runtime": 13308.635957956314, "_timestamp": 1585583224.4805913, "_step": 27}
{"Episode reward": -67.12759062997763, "Episode length": 999, "Policy Loss": -4.780239105224609, "Value Loss": 220.50540161132812, "_runtime": 13310.22730922699, "_timestamp": 1585583226.0719426, "_step": 28}
{"Episode reward": -62.88338623392655, "Episode length": 999, "Policy Loss": -4.321776390075684, "Value Loss": 213.45877075195312, "_runtime": 13311.81668639183, "_timestamp": 1585583227.6613197, "_step": 29}
{"Episode reward": -65.03542602277787, "Episode length": 999, "Policy Loss": -1.754789113998413, "Value Loss": 92.92887878417969, "_runtime": 13313.409439086914, "_timestamp": 1585583229.2540724, "_step": 30}
{"Episode reward": -63.98952824638043, "Episode length": 999, "Policy Loss": -9.29767894744873, "Value Loss": 244.47775268554688, "_runtime": 13315.006129264832, "_timestamp": 1585583230.8507626, "_step": 31}
{"Episode reward": -67.11951625391418, "Episode length": 999, "Policy Loss": -4.191640853881836, "Value Loss": 302.8603210449219, "_runtime": 13316.617386579514, "_timestamp": 1585583232.46202, "_step": 32}
{"Episode reward": -63.56372181765114, "Episode length": 999, "Policy Loss": -6.802773475646973, "Value Loss": 226.49876403808594, "_runtime": 13318.22928404808, "_timestamp": 1585583234.0739174, "_step": 33}
{"Episode reward": -67.14747188699025, "Episode length": 999, "Policy Loss": 0.2017688900232315, "Value Loss": 42.14476776123047, "_runtime": 13319.826651573181, "_timestamp": 1585583235.671285, "_step": 34}
{"Episode reward": -65.26805630813293, "Episode length": 999, "Policy Loss": -1.3441126346588135, "Value Loss": 54.20854949951172, "_runtime": 13321.426778554916, "_timestamp": 1585583237.271412, "_step": 35}
{"Episode reward": -71.22463710665382, "Episode length": 999, "Policy Loss": -0.1599540263414383, "Value Loss": 6.087996959686279, "_runtime": 13323.032463788986, "_timestamp": 1585583238.8770971, "_step": 36}
{"Episode reward": -69.30557293147031, "Episode length": 999, "Policy Loss": -0.7858840823173523, "Value Loss": 6.131597995758057, "_runtime": 13324.622795820236, "_timestamp": 1585583240.4674292, "_step": 37}
{"Episode reward": -66.3699831181272, "Episode length": 999, "Policy Loss": -0.219795823097229, "Value Loss": 0.5019591450691223, "_runtime": 13326.22766661644, "_timestamp": 1585583242.0723, "_step": 38}
{"Episode reward": -67.71365041271412, "Episode length": 999, "Policy Loss": -0.4300842583179474, "Value Loss": 0.24037720263004303, "_runtime": 13327.833325386047, "_timestamp": 1585583243.6779587, "_step": 39}
{"Episode reward": -71.28663757388244, "Episode length": 999, "Policy Loss": 0.14953844249248505, "Value Loss": 5.830202102661133, "_runtime": 13329.411812067032, "_timestamp": 1585583245.2564454, "_step": 40}
{"Episode reward": -69.78308254079961, "Episode length": 999, "Policy Loss": 0.06438075006008148, "Value Loss": 18.46175193786621, "_runtime": 13331.054567098618, "_timestamp": 1585583246.8992004, "_step": 41}
{"Episode reward": -71.57711807841729, "Episode length": 999, "Policy Loss": -0.05173990875482559, "Value Loss": 15.228549003601074, "_runtime": 13332.660210847855, "_timestamp": 1585583248.5048442, "_step": 42}
{"Episode reward": -71.52273439489547, "Episode length": 999, "Policy Loss": 0.17194519937038422, "Value Loss": 39.800411224365234, "_runtime": 13334.25827741623, "_timestamp": 1585583250.1029108, "_step": 43}
{"Episode reward": -68.76244011531377, "Episode length": 999, "Policy Loss": -1.3824739456176758, "Value Loss": 29.085182189941406, "_runtime": 13335.855631828308, "_timestamp": 1585583251.7002652, "_step": 44}
{"Episode reward": -76.93676057277284, "Episode length": 999, "Policy Loss": -0.3794556260108948, "Value Loss": 20.33414077758789, "_runtime": 13337.447759866714, "_timestamp": 1585583253.2923932, "_step": 45}
{"Episode reward": -72.40711001698462, "Episode length": 999, "Policy Loss": 0.9250467419624329, "Value Loss": 55.715110778808594, "_runtime": 13339.03443479538, "_timestamp": 1585583254.8790681, "_step": 46}
{"Episode reward": -73.0785320637404, "Episode length": 999, "Policy Loss": -0.82662433385849, "Value Loss": 18.841638565063477, "_runtime": 13340.626054048538, "_timestamp": 1585583256.4706874, "_step": 47}
{"Episode reward": -76.98688280885209, "Episode length": 999, "Policy Loss": -0.24899616837501526, "Value Loss": 21.697986602783203, "_runtime": 13342.222463607788, "_timestamp": 1585583258.067097, "_step": 48}
{"Episode reward": -68.05027036291064, "Episode length": 999, "Policy Loss": 0.4305267930030823, "Value Loss": 16.02478790283203, "_runtime": 13343.816646814346, "_timestamp": 1585583259.6612802, "_step": 49}
{"Episode reward": -66.74506817720783, "Episode length": 999, "Policy Loss": 0.4893953204154968, "Value Loss": 13.714360237121582, "_runtime": 13345.410739421844, "_timestamp": 1585583261.2553728, "_step": 50}
{"Episode reward": -77.72399233104403, "Episode length": 999, "Policy Loss": -0.5040624737739563, "Value Loss": 36.932464599609375, "_runtime": 13347.004579782486, "_timestamp": 1585583262.8492131, "_step": 51}
{"Episode reward": -77.03429958094837, "Episode length": 999, "Policy Loss": -0.602506160736084, "Value Loss": 13.708792686462402, "_runtime": 13348.61059832573, "_timestamp": 1585583264.4552317, "_step": 52}
{"Episode reward": -73.84432515226975, "Episode length": 999, "Policy Loss": 1.953660011291504, "Value Loss": 50.741233825683594, "_runtime": 13350.20694231987, "_timestamp": 1585583266.0515757, "_step": 53}
{"Episode reward": -70.18542569467479, "Episode length": 999, "Policy Loss": 3.2066328525543213, "Value Loss": 134.91053771972656, "_runtime": 13351.79943060875, "_timestamp": 1585583267.644064, "_step": 54}
{"Episode reward": -72.56199722389569, "Episode length": 999, "Policy Loss": -0.41688427329063416, "Value Loss": 16.00092315673828, "_runtime": 13353.395678520203, "_timestamp": 1585583269.2403119, "_step": 55}
{"Episode reward": -69.2646207429387, "Episode length": 999, "Policy Loss": 2.448869228363037, "Value Loss": 85.4423828125, "_runtime": 13355.03830575943, "_timestamp": 1585583270.882939, "_step": 56}
{"Episode reward": -69.64612027907336, "Episode length": 999, "Policy Loss": 4.124611854553223, "Value Loss": 114.51146697998047, "_runtime": 13356.646297454834, "_timestamp": 1585583272.4909308, "_step": 57}
{"Episode reward": -68.71235400710445, "Episode length": 999, "Policy Loss": 3.0074610710144043, "Value Loss": 46.8039665222168, "_runtime": 13358.247648477554, "_timestamp": 1585583274.0922818, "_step": 58}
{"Episode reward": -70.15929427624266, "Episode length": 999, "Policy Loss": 1.6002837419509888, "Value Loss": 25.116844177246094, "_runtime": 13359.852966070175, "_timestamp": 1585583275.6975994, "_step": 59}
{"Episode reward": -70.75417402692719, "Episode length": 999, "Policy Loss": 2.112748622894287, "Value Loss": 30.697864532470703, "_runtime": 13361.438441038132, "_timestamp": 1585583277.2830744, "_step": 60}
{"Episode reward": -69.54304208184011, "Episode length": 999, "Policy Loss": 0.45529064536094666, "Value Loss": 5.070854187011719, "_runtime": 13363.02949500084, "_timestamp": 1585583278.8741283, "_step": 61}
{"Episode reward": -68.75548099529097, "Episode length": 999, "Policy Loss": -0.25144270062446594, "Value Loss": 5.033482074737549, "_runtime": 13364.630836725235, "_timestamp": 1585583280.47547, "_step": 62}
{"Episode reward": -69.20730657427524, "Episode length": 999, "Policy Loss": 0.018791314214468002, "Value Loss": 1.3036762475967407, "_runtime": 13366.227079629898, "_timestamp": 1585583282.071713, "_step": 63}
{"Episode reward": -71.66074216111404, "Episode length": 999, "Policy Loss": 1.4591749906539917, "Value Loss": 9.004703521728516, "_runtime": 13367.830683231354, "_timestamp": 1585583283.6753166, "_step": 64}
{"Episode reward": -75.66768417558227, "Episode length": 999, "Policy Loss": 0.6426946520805359, "Value Loss": 4.278702735900879, "_runtime": 13369.425760030746, "_timestamp": 1585583285.2703934, "_step": 65}
{"Episode reward": -74.03565211308194, "Episode length": 999, "Policy Loss": 0.3886776864528656, "Value Loss": 2.2533929347991943, "_runtime": 13371.01934504509, "_timestamp": 1585583286.8639784, "_step": 66}
{"Episode reward": -80.23694952282192, "Episode length": 999, "Policy Loss": 0.4149015247821808, "Value Loss": 0.9608050584793091, "_runtime": 13372.609740018845, "_timestamp": 1585583288.4543734, "_step": 67}
{"Episode reward": -72.77876291585736, "Episode length": 999, "Policy Loss": 0.6018578410148621, "Value Loss": 1.3416450023651123, "_runtime": 13374.213509559631, "_timestamp": 1585583290.058143, "_step": 68}
{"Episode reward": -76.97025119419621, "Episode length": 999, "Policy Loss": 0.43167397379875183, "Value Loss": 0.30223533511161804, "_runtime": 13375.810647249222, "_timestamp": 1585583291.6552806, "_step": 69}
{"Episode reward": -72.22126868101586, "Episode length": 999, "Policy Loss": 0.6792072057723999, "Value Loss": 0.5255224108695984, "_runtime": 13377.395166158676, "_timestamp": 1585583293.2397995, "_step": 70}
{"Episode reward": -72.02080191914841, "Episode length": 999, "Policy Loss": 0.41918087005615234, "Value Loss": 0.08644197881221771, "_runtime": 13379.030530452728, "_timestamp": 1585583294.8751638, "_step": 71}
{"Episode reward": -74.79165754031118, "Episode length": 999, "Policy Loss": 0.4206627607345581, "Value Loss": 0.052623312920331955, "_runtime": 13380.622370004654, "_timestamp": 1585583296.4670033, "_step": 72}
{"Episode reward": -75.16909173335897, "Episode length": 999, "Policy Loss": 0.4496579170227051, "Value Loss": 0.05412907153367996, "_runtime": 13382.218772888184, "_timestamp": 1585583298.0634062, "_step": 73}
{"Episode reward": -77.33735428163013, "Episode length": 999, "Policy Loss": 0.4753996431827545, "Value Loss": 0.06722144037485123, "_runtime": 13383.824289560318, "_timestamp": 1585583299.668923, "_step": 74}
{"Episode reward": -72.82704100280522, "Episode length": 999, "Policy Loss": 0.4463784396648407, "Value Loss": 0.1528395265340805, "_runtime": 13385.413999080658, "_timestamp": 1585583301.2586324, "_step": 75}
{"Episode reward": -72.60300332366175, "Episode length": 999, "Policy Loss": 0.3958888351917267, "Value Loss": 0.24213270843029022, "_runtime": 13387.002952098846, "_timestamp": 1585583302.8475854, "_step": 76}
{"Episode reward": -73.5664026335636, "Episode length": 999, "Policy Loss": 0.3876667618751526, "Value Loss": 0.18142017722129822, "_runtime": 13388.596784114838, "_timestamp": 1585583304.4414175, "_step": 77}
{"Episode reward": -76.91155081800324, "Episode length": 999, "Policy Loss": 0.38554859161376953, "Value Loss": 0.3800967037677765, "_runtime": 13390.19747209549, "_timestamp": 1585583306.0421054, "_step": 78}
{"Episode reward": -72.92651854237195, "Episode length": 999, "Policy Loss": 0.5035445094108582, "Value Loss": 0.35551512241363525, "_runtime": 13391.780561447144, "_timestamp": 1585583307.6251948, "_step": 79}
{"Episode reward": -76.0935665558658, "Episode length": 999, "Policy Loss": 0.5363086462020874, "Value Loss": 0.24297542870044708, "_runtime": 13393.369822978973, "_timestamp": 1585583309.2144563, "_step": 80}
{"Episode reward": -70.50288354864355, "Episode length": 999, "Policy Loss": 0.3683474361896515, "Value Loss": 0.2229483425617218, "_runtime": 13394.975533008575, "_timestamp": 1585583310.8201663, "_step": 81}
{"Episode reward": -74.19731431586516, "Episode length": 999, "Policy Loss": 0.16697059571743011, "Value Loss": 0.6569309830665588, "_runtime": 13396.573888778687, "_timestamp": 1585583312.4185221, "_step": 82}
{"Episode reward": -68.55612478880586, "Episode length": 999, "Policy Loss": 0.55794358253479, "Value Loss": 0.22832708060741425, "_runtime": 13398.163397789001, "_timestamp": 1585583314.0080311, "_step": 83}
{"Episode reward": -72.75837591474989, "Episode length": 999, "Policy Loss": 0.45745959877967834, "Value Loss": 0.41607755422592163, "_runtime": 13399.76845407486, "_timestamp": 1585583315.6130874, "_step": 84}
{"Episode reward": -74.24306239310107, "Episode length": 999, "Policy Loss": 0.28336095809936523, "Value Loss": 0.38099637627601624, "_runtime": 13401.370746850967, "_timestamp": 1585583317.2153802, "_step": 85}
{"Episode reward": -71.68849551891172, "Episode length": 999, "Policy Loss": 0.0017679600277915597, "Value Loss": 0.9847154021263123, "_runtime": 13403.01541852951, "_timestamp": 1585583318.8600519, "_step": 86}
{"Episode reward": -71.02900682038363, "Episode length": 999, "Policy Loss": -0.0719631016254425, "Value Loss": 1.0904040336608887, "_runtime": 13404.620070934296, "_timestamp": 1585583320.4647043, "_step": 87}
{"Episode reward": -75.3068886996445, "Episode length": 999, "Policy Loss": 0.25943925976753235, "Value Loss": 0.33292853832244873, "_runtime": 13406.222858428955, "_timestamp": 1585583322.0674918, "_step": 88}
{"Episode reward": -77.63659212376052, "Episode length": 999, "Policy Loss": 0.3228931427001953, "Value Loss": 0.17565202713012695, "_runtime": 13407.828618764877, "_timestamp": 1585583323.673252, "_step": 89}
{"Episode reward": -75.49850440131961, "Episode length": 999, "Policy Loss": 0.24651192128658295, "Value Loss": 0.5836668610572815, "_runtime": 13409.419014930725, "_timestamp": 1585583325.2636483, "_step": 90}
{"Episode reward": -79.16385287578512, "Episode length": 999, "Policy Loss": 0.273688942193985, "Value Loss": 0.26911044120788574, "_runtime": 13411.018862247467, "_timestamp": 1585583326.8634956, "_step": 91}
{"Episode reward": -76.33703877654644, "Episode length": 999, "Policy Loss": 0.07931329309940338, "Value Loss": 0.5276921987533569, "_runtime": 13412.611133098602, "_timestamp": 1585583328.4557664, "_step": 92}
{"Episode reward": -72.78108860599934, "Episode length": 999, "Policy Loss": 0.17596718668937683, "Value Loss": 0.23345665633678436, "_runtime": 13414.200966358185, "_timestamp": 1585583330.0455997, "_step": 93}
{"Episode reward": -73.67949290130056, "Episode length": 999, "Policy Loss": 0.13555680215358734, "Value Loss": 0.6190301775932312, "_runtime": 13415.80748128891, "_timestamp": 1585583331.6521146, "_step": 94}
{"Episode reward": -75.66165020862947, "Episode length": 999, "Policy Loss": 0.06094115227460861, "Value Loss": 0.27733051776885986, "_runtime": 13417.395755529404, "_timestamp": 1585583333.2403889, "_step": 95}
{"Episode reward": -76.42890124248653, "Episode length": 999, "Policy Loss": 0.171791210770607, "Value Loss": 0.27950525283813477, "_runtime": 13418.998221874237, "_timestamp": 1585583334.8428552, "_step": 96}
{"Episode reward": -77.88358569389163, "Episode length": 999, "Policy Loss": -0.02742951549589634, "Value Loss": 0.6484339237213135, "_runtime": 13420.581830263138, "_timestamp": 1585583336.4264636, "_step": 97}
{"Episode reward": -74.01920556162321, "Episode length": 999, "Policy Loss": -0.0014717740705236793, "Value Loss": 0.24741756916046143, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918, 22.19062614440918]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-18.609312057495117, -14.627873420715332, -10.646434783935547, -6.664995193481445, -2.68355655670166, 1.297882080078125, 5.279321670532227, 9.260759353637695, 13.242198944091797, 17.2236385345459, 21.205076217651367, 25.186513900756836, 29.16795539855957, 33.149391174316406, 37.130828857421875, 41.112274169921875, 45.093711853027344, 49.07514953613281, 53.05658721923828, 57.03802490234375, 61.01946258544922, 65.00090026855469, 68.98233795166016, 72.96378326416016, 76.94522094726562, 80.9266586303711, 84.90809631347656, 88.88953399658203, 92.8709716796875, 96.8524169921875, 100.83385467529297, 104.81529235839844, 108.7967300415039, 112.77816772460938, 116.75961303710938, 120.74104309082031, 124.72248840332031, 128.70391845703125, 132.68536376953125, 136.66680908203125, 140.6482391357422, 144.6296844482422, 148.61111450195312, 152.59255981445312, 156.57398986816406, 160.55543518066406, 164.53688049316406, 168.518310546875, 172.499755859375, 176.48118591308594, 180.46263122558594, 184.44406127929688, 188.42550659179688, 192.40695190429688, 196.3883819580078, 200.3698272705078, 204.35125732421875, 208.33270263671875, 212.31414794921875, 216.2955780029297, 220.2770233154297, 224.25845336914062, 228.23989868164062, 232.22132873535156, 236.20277404785156]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-12.866230010986328, -12.527361869812012, -12.188494682312012, -11.849626541137695, -11.510759353637695, -11.171891212463379, -10.833023071289062, -10.494155883789062, -10.155288696289062, -9.816420555114746, -9.47755241394043, -9.13868522644043, -8.799817085266113, -8.460948944091797, -8.122081756591797, -7.783214092254639, -7.4443464279174805, -7.105478763580322, -6.766611099243164, -6.427743434906006, -6.088875770568848, -5.750007629394531, -5.411139965057373, -5.072272300720215, -4.733404159545898, -4.394536972045898, -4.055668830871582, -3.716801643371582, -3.3779335021972656, -3.0390663146972656, -2.700198173522949, -2.361330986022949, -2.022462844848633, -1.6835947036743164, -1.3447275161743164, -1.005859375, -0.6669921875, -0.3281240463256836, 0.010743141174316406, 0.3496112823486328, 0.6884784698486328, 1.0273466110229492, 1.3662147521972656, 1.7050819396972656, 2.043950080871582, 2.382817268371582, 2.7216854095458984, 3.0605525970458984, 3.3994216918945312, 3.7382888793945312, 4.077156066894531, 4.416023254394531, 4.754892349243164, 5.093759536743164, 5.432626724243164, 5.771493911743164, 6.110363006591797, 6.449230194091797, 6.788097381591797, 7.12696647644043, 7.46583366394043, 7.80470085144043, 8.14356803894043, 8.482437133789062, 8.821304321289062]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 4.0, 2.0, 0.0, 4.0, 7.0, 5.0, 6.0, 13.0, 6.0, 10.0, 23.0, 20.0, 24.0, 33.0, 52.0, 62.0, 46.0, 38.0, 22.0, 27.0, 19.0, 17.0, 7.0, 12.0, 8.0, 5.0, 7.0, 3.0, 6.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-17.366836547851562, -16.904003143310547, -16.441171646118164, -15.978338241577148, -15.51550579071045, -15.052672386169434, -14.589839935302734, -14.127006530761719, -13.66417407989502, -13.20134162902832, -12.738508224487305, -12.275675773620605, -11.812843322753906, -11.35000991821289, -10.887177467346191, -10.424345016479492, -9.961511611938477, -9.498679161071777, -9.035846710205078, -8.573013305664062, -8.110180854797363, -7.647348403930664, -7.184514999389648, -6.721682548522949, -6.25885009765625, -5.796016693115234, -5.333184242248535, -4.870351791381836, -4.40751838684082, -3.944685935974121, -3.481853485107422, -3.0190200805664062, -2.556187629699707, -2.093355178833008, -1.6305217742919922, -1.1676883697509766, -0.7048568725585938, -0.24202346801757812, 0.2208099365234375, 0.6836414337158203, 1.146474838256836, 1.6093082427978516, 2.0721397399902344, 2.53497314453125, 2.9978065490722656, 3.4606380462646484, 3.923471450805664, 4.38630485534668, 4.8491363525390625, 5.311969757080078, 5.774803161621094, 6.237634658813477, 6.700468063354492, 7.163301467895508, 7.626132965087891, 8.088966369628906, 8.551799774169922, 9.014631271362305, 9.47746467590332, 9.940298080444336, 10.403129577636719, 10.865962982177734, 11.32879638671875, 11.791627883911133, 12.254461288452148]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-19.639127731323242, -18.82598114013672, -18.012834548950195, -17.199687957763672, -16.38654136657715, -15.573394775390625, -14.760248184204102, -13.947101593017578, -13.133955001831055, -12.320808410644531, -11.507661819458008, -10.694515228271484, -9.881368637084961, -9.068222045898438, -8.255075454711914, -7.441928863525391, -6.628782272338867, -5.815635681152344, -5.00248908996582, -4.189342498779297, -3.3761959075927734, -2.56304931640625, -1.7499027252197266, -0.9367561340332031, -0.12360954284667969, 0.6895370483398438, 1.5026836395263672, 2.3158302307128906, 3.128976821899414, 3.9421234130859375, 4.755270004272461, 5.568416595458984, 6.381563186645508, 7.194709777832031, 8.007856369018555, 8.821002960205078, 9.634149551391602, 10.447296142578125, 11.260442733764648, 12.073589324951172, 12.886735916137695, 13.699884414672852, 14.513029098510742, 15.326173782348633, 16.13932228088379, 16.952470779418945, 17.765615463256836, 18.578760147094727, 19.391908645629883, 20.20505714416504, 21.01820182800293, 21.83134651184082, 22.644495010375977, 23.457643508911133, 24.270788192749023, 25.083932876586914, 25.89708137512207, 26.710229873657227, 27.523374557495117, 28.336519241333008, 29.149667739868164, 29.96281623840332, 30.77596092224121, 31.5891056060791, 32.402252197265625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 9.0, 5.0, 12.0, 6.0, 2.0, 2.0, 0.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.11778450012207, -10.842119216918945, -10.566452980041504, -10.290787696838379, -10.015121459960938, -9.739456176757812, -9.463789939880371, -9.188124656677246, -8.912458419799805, -8.63679313659668, -8.361127853393555, -8.085461616516113, -7.809796333312988, -7.534130096435547, -7.258464813232422, -6.982799053192139, -6.7071332931518555, -6.431467533111572, -6.155801773071289, -5.880136013031006, -5.604470252990723, -5.328804969787598, -5.0531392097473145, -4.777473449707031, -4.501807689666748, -4.226141929626465, -3.9504761695861816, -3.6748104095458984, -3.3991451263427734, -3.1234793663024902, -2.847813606262207, -2.5721473693847656, -2.2964820861816406, -2.0208168029785156, -1.7451505661010742, -1.4694852828979492, -1.1938190460205078, -0.9181537628173828, -0.6424875259399414, -0.3668222427368164, -0.091156005859375, 0.18450927734375, 0.460174560546875, 0.7358407974243164, 1.0115060806274414, 1.2871723175048828, 1.5628376007080078, 1.8385038375854492, 2.114169120788574, 2.389834403991699, 2.6655006408691406, 2.9411659240722656, 3.216832160949707, 3.492497444152832, 3.7681636810302734, 4.043828964233398, 4.319494247436523, 4.595160484313965, 4.87082576751709, 5.146492004394531, 5.422157287597656, 5.697822570800781, 5.973489761352539, 6.249155044555664, 6.524820327758789]}, "_runtime": 13422.186674833298, "_timestamp": 1585583338.0313082, "_step": 98}
{"Episode reward": -76.36996787740283, "Episode length": 999, "Policy Loss": 0.03990018740296364, "Value Loss": 0.29541653394699097, "_runtime": 13423.785837650299, "_timestamp": 1585583339.630471, "_step": 99}
{"Episode reward": -76.24866915336392, "Episode length": 999, "Policy Loss": 0.0805789902806282, "Value Loss": 0.15852728486061096, "_runtime": 13425.413689136505, "_timestamp": 1585583341.2583225, "_step": 100}
{"Episode reward": -75.23420274731893, "Episode length": 999, "Policy Loss": -0.14176172018051147, "Value Loss": 0.599647045135498, "_runtime": 13427.010162353516, "_timestamp": 1585583342.8547957, "_step": 101}
{"Episode reward": -80.26516778278604, "Episode length": 999, "Policy Loss": -0.004066120833158493, "Value Loss": 0.1695825308561325, "_runtime": 13428.612068653107, "_timestamp": 1585583344.456702, "_step": 102}
{"Episode reward": -76.93081135447444, "Episode length": 999, "Policy Loss": -0.08172952383756638, "Value Loss": 0.5292072296142578, "_runtime": 13430.209131717682, "_timestamp": 1585583346.053765, "_step": 103}
{"Episode reward": -70.96771511173064, "Episode length": 999, "Policy Loss": -0.17117205262184143, "Value Loss": 0.8698285818099976, "_runtime": 13431.801095247269, "_timestamp": 1585583347.6457286, "_step": 104}
{"Episode reward": -76.76822598914447, "Episode length": 999, "Policy Loss": -0.00789888296276331, "Value Loss": 0.10105715692043304, "_runtime": 13433.402124404907, "_timestamp": 1585583349.2467577, "_step": 105}
{"Episode reward": -75.55641210583336, "Episode length": 999, "Policy Loss": -0.09351036697626114, "Value Loss": 0.13024531304836273, "_runtime": 13435.017033815384, "_timestamp": 1585583350.8616672, "_step": 106}
{"Episode reward": -70.2978773397157, "Episode length": 999, "Policy Loss": 0.04217923805117607, "Value Loss": 0.26398178935050964, "_runtime": 13436.610402822495, "_timestamp": 1585583352.4550362, "_step": 107}
{"Episode reward": -79.51579509184228, "Episode length": 999, "Policy Loss": -0.16158561408519745, "Value Loss": 0.2894885838031769, "_runtime": 13438.208926916122, "_timestamp": 1585583354.0535603, "_step": 108}
{"Episode reward": -78.30621414416945, "Episode length": 999, "Policy Loss": -0.11847797781229019, "Value Loss": 0.1223163828253746, "_runtime": 13439.781940460205, "_timestamp": 1585583355.6265738, "_step": 109}
{"Episode reward": -75.0383940539009, "Episode length": 999, "Policy Loss": -0.23339158296585083, "Value Loss": 0.31782034039497375, "_runtime": 13441.35872220993, "_timestamp": 1585583357.2033556, "_step": 110}
{"Episode reward": -76.79913901342738, "Episode length": 999, "Policy Loss": -0.4299965798854828, "Value Loss": 0.6705095767974854, "_runtime": 13442.944338798523, "_timestamp": 1585583358.7889721, "_step": 111}
{"Episode reward": -76.58244209526298, "Episode length": 999, "Policy Loss": -0.250394344329834, "Value Loss": 0.35655754804611206, "_runtime": 13444.52338886261, "_timestamp": 1585583360.3680222, "_step": 112}
{"Episode reward": -73.99076371713801, "Episode length": 999, "Policy Loss": -0.28206825256347656, "Value Loss": 0.22758853435516357, "_runtime": 13446.11987709999, "_timestamp": 1585583361.9645104, "_step": 113}
{"Episode reward": -75.57415876555295, "Episode length": 999, "Policy Loss": -0.10787763446569443, "Value Loss": 0.10280992835760117, "_runtime": 13447.709748744965, "_timestamp": 1585583363.554382, "_step": 114}
{"Episode reward": -76.56168535608371, "Episode length": 999, "Policy Loss": -0.22299934923648834, "Value Loss": 0.13171377778053284, "_runtime": 13449.33847618103, "_timestamp": 1585583365.1831095, "_step": 115}
{"Episode reward": -74.4864106827081, "Episode length": 999, "Policy Loss": -0.11772134155035019, "Value Loss": 0.10281399637460709, "_runtime": 13450.926836252213, "_timestamp": 1585583366.7714696, "_step": 116}
{"Episode reward": -80.83365645556395, "Episode length": 999, "Policy Loss": -0.23437127470970154, "Value Loss": 0.2062244862318039, "_runtime": 13452.506207466125, "_timestamp": 1585583368.3508408, "_step": 117}
{"Episode reward": -74.65982917693042, "Episode length": 999, "Policy Loss": -0.27897125482559204, "Value Loss": 0.3545835316181183, "_runtime": 13454.096870660782, "_timestamp": 1585583369.941504, "_step": 118}
{"Episode reward": -76.9369428596242, "Episode length": 999, "Policy Loss": -0.2603139877319336, "Value Loss": 0.1845674067735672, "_runtime": 13455.679033041, "_timestamp": 1585583371.5236664, "_step": 119}
{"Episode reward": -82.95884410866763, "Episode length": 999, "Policy Loss": -0.17651934921741486, "Value Loss": 0.0501050166785717, "_runtime": 13457.263884782791, "_timestamp": 1585583373.1085181, "_step": 120}
{"Episode reward": -71.22884334864743, "Episode length": 999, "Policy Loss": -0.12855254113674164, "Value Loss": 0.035474613308906555, "_runtime": 13458.831783533096, "_timestamp": 1585583374.6764169, "_step": 121}
{"Episode reward": -74.9169575038146, "Episode length": 999, "Policy Loss": -0.19753868877887726, "Value Loss": 0.21124456822872162, "_runtime": 13460.41041135788, "_timestamp": 1585583376.2550447, "_step": 122}
{"Episode reward": -77.53787985893788, "Episode length": 999, "Policy Loss": -0.21252916753292084, "Value Loss": 0.14637750387191772, "_runtime": 13461.99824666977, "_timestamp": 1585583377.84288, "_step": 123}
{"Episode reward": -69.17993302452709, "Episode length": 999, "Policy Loss": -0.24965208768844604, "Value Loss": 0.346819669008255, "_runtime": 13463.585788488388, "_timestamp": 1585583379.4304218, "_step": 124}
{"Episode reward": -75.83715498982507, "Episode length": 999, "Policy Loss": -0.13876327872276306, "Value Loss": 0.082855723798275, "_runtime": 13465.168367147446, "_timestamp": 1585583381.0130005, "_step": 125}
{"Episode reward": -73.41176632489976, "Episode length": 999, "Policy Loss": -0.18694187700748444, "Value Loss": 0.1498977094888687, "_runtime": 13466.751273155212, "_timestamp": 1585583382.5959065, "_step": 126}
{"Episode reward": -76.7336408407319, "Episode length": 999, "Policy Loss": -0.1418037712574005, "Value Loss": 0.06258537620306015, "_runtime": 13468.334739208221, "_timestamp": 1585583384.1793725, "_step": 127}
{"Episode reward": -79.16311712939452, "Episode length": 999, "Policy Loss": -0.14538352191448212, "Value Loss": 0.0278906412422657, "_runtime": 13469.922421216965, "_timestamp": 1585583385.7670546, "_step": 128}
{"Episode reward": -72.74321597835373, "Episode length": 999, "Policy Loss": -0.11170521378517151, "Value Loss": 0.06731335818767548, "_runtime": 13471.509682893753, "_timestamp": 1585583387.3543162, "_step": 129}
{"Episode reward": -76.96555691046889, "Episode length": 999, "Policy Loss": -0.2304195910692215, "Value Loss": 0.14196181297302246, "_runtime": 13473.129619121552, "_timestamp": 1585583388.9742525, "_step": 130}
{"Episode reward": -77.02112755323427, "Episode length": 999, "Policy Loss": -0.17968429625034332, "Value Loss": 0.11151675134897232, "_runtime": 13474.706925153732, "_timestamp": 1585583390.5515585, "_step": 131}
{"Episode reward": -72.2884872684571, "Episode length": 999, "Policy Loss": -0.18812204897403717, "Value Loss": 0.15969379246234894, "_runtime": 13476.274909734726, "_timestamp": 1585583392.119543, "_step": 132}
{"Episode reward": -73.02264065956388, "Episode length": 999, "Policy Loss": -0.07936697453260422, "Value Loss": 0.01751062087714672, "_runtime": 13477.854140520096, "_timestamp": 1585583393.6987739, "_step": 133}
{"Episode reward": -73.2100118090607, "Episode length": 999, "Policy Loss": -0.12601381540298462, "Value Loss": 0.0723407194018364, "_runtime": 13479.4494638443, "_timestamp": 1585583395.2940972, "_step": 134}
{"Episode reward": -78.84038724837909, "Episode length": 999, "Policy Loss": -0.16937436163425446, "Value Loss": 0.07936123013496399, "_runtime": 13481.03460597992, "_timestamp": 1585583396.8792393, "_step": 135}
{"Episode reward": -74.07887936857978, "Episode length": 999, "Policy Loss": -0.08319808542728424, "Value Loss": 0.025352995842695236, "_runtime": 13482.630485534668, "_timestamp": 1585583398.4751189, "_step": 136}
{"Episode reward": -72.17240174561758, "Episode length": 999, "Policy Loss": -0.1034284234046936, "Value Loss": 0.08334876596927643, "_runtime": 13484.231781721115, "_timestamp": 1585583400.076415, "_step": 137}
{"Episode reward": -76.33627153424895, "Episode length": 999, "Policy Loss": -0.08185677230358124, "Value Loss": 0.008650694042444229, "_runtime": 13485.825944662094, "_timestamp": 1585583401.670578, "_step": 138}
{"Episode reward": -78.85109003860296, "Episode length": 999, "Policy Loss": -0.15175804495811462, "Value Loss": 0.05363766849040985, "_runtime": 13487.432559013367, "_timestamp": 1585583403.2771924, "_step": 139}
{"Episode reward": -76.26876895857842, "Episode length": 999, "Policy Loss": -0.11478245258331299, "Value Loss": 0.032192546874284744, "_runtime": 13489.022036075592, "_timestamp": 1585583404.8666694, "_step": 140}
{"Episode reward": -78.42980909014189, "Episode length": 999, "Policy Loss": -0.08032384514808655, "Value Loss": 0.033341988921165466, "_runtime": 13490.621989011765, "_timestamp": 1585583406.4666224, "_step": 141}
{"Episode reward": -75.15812926258377, "Episode length": 999, "Policy Loss": -0.1454324722290039, "Value Loss": 0.06182778626680374, "_runtime": 13492.209238052368, "_timestamp": 1585583408.0538714, "_step": 142}
{"Episode reward": -77.48517608860229, "Episode length": 999, "Policy Loss": -0.06610450893640518, "Value Loss": 0.008784342557191849, "_runtime": 13493.800564289093, "_timestamp": 1585583409.6451976, "_step": 143}
{"Episode reward": -76.53304678958033, "Episode length": 999, "Policy Loss": -0.05806596577167511, "Value Loss": 0.017628666013479233, "_runtime": 13495.39011144638, "_timestamp": 1585583411.2347448, "_step": 144}
{"Episode reward": -71.81877240076201, "Episode length": 999, "Policy Loss": -0.0815965011715889, "Value Loss": 0.014094020240008831, "_runtime": 13497.01420712471, "_timestamp": 1585583412.8588405, "_step": 145}
{"Episode reward": -75.75466315403031, "Episode length": 999, "Policy Loss": -0.09467626363039017, "Value Loss": 0.022235404700040817, "_runtime": 13498.602988243103, "_timestamp": 1585583414.4476216, "_step": 146}
{"Episode reward": -72.23424288442772, "Episode length": 999, "Policy Loss": -0.03131949156522751, "Value Loss": 0.02220640704035759, "_runtime": 13500.183948516846, "_timestamp": 1585583416.0285819, "_step": 147}
{"Episode reward": -78.03828659084404, "Episode length": 999, "Policy Loss": -0.03752467781305313, "Value Loss": 0.004297412931919098, "_runtime": 13501.765165805817, "_timestamp": 1585583417.6097991, "_step": 148}
{"Episode reward": -74.99843921873881, "Episode length": 999, "Policy Loss": -0.05616319179534912, "Value Loss": 0.026283420622348785, "_runtime": 13503.34958577156, "_timestamp": 1585583419.194219, "_step": 149}
{"Episode reward": -75.32029412645626, "Episode length": 999, "Policy Loss": -0.03403292968869209, "Value Loss": 0.011056747287511826, "_runtime": 13504.92301940918, "_timestamp": 1585583420.7676528, "_step": 150}
{"Episode reward": -76.7198697246591, "Episode length": 999, "Policy Loss": -0.03712425008416176, "Value Loss": 0.009916876442730427, "_runtime": 13506.507419347763, "_timestamp": 1585583422.3520527, "_step": 151}
{"Episode reward": -76.4404959996561, "Episode length": 999, "Policy Loss": -0.018015673384070396, "Value Loss": 0.009551392868161201, "_runtime": 13508.110287427902, "_timestamp": 1585583423.9549208, "_step": 152}
{"Episode reward": -72.87162100436353, "Episode length": 999, "Policy Loss": -0.027356576174497604, "Value Loss": 0.01751728355884552, "_runtime": 13509.713884353638, "_timestamp": 1585583425.5585177, "_step": 153}
{"Episode reward": -78.59190666895776, "Episode length": 999, "Policy Loss": -0.02461038902401924, "Value Loss": 0.004385989625006914, "_runtime": 13511.318691015244, "_timestamp": 1585583427.1633244, "_step": 154}
{"Episode reward": -77.16879312643641, "Episode length": 999, "Policy Loss": -0.027698660269379616, "Value Loss": 0.008379334583878517, "_runtime": 13512.916588783264, "_timestamp": 1585583428.7612221, "_step": 155}
{"Episode reward": -77.16585517880236, "Episode length": 999, "Policy Loss": -0.02107979729771614, "Value Loss": 0.005541387014091015, "_runtime": 13514.503558635712, "_timestamp": 1585583430.348192, "_step": 156}
{"Episode reward": -73.83496068050025, "Episode length": 999, "Policy Loss": -0.036176323890686035, "Value Loss": 0.00906904973089695, "_runtime": 13516.100804805756, "_timestamp": 1585583431.9454381, "_step": 157}
{"Episode reward": -77.44748790644388, "Episode length": 999, "Policy Loss": -0.012421669438481331, "Value Loss": 0.002013541990891099, "_runtime": 13517.695349693298, "_timestamp": 1585583433.539983, "_step": 158}
{"Episode reward": -75.35314505023992, "Episode length": 999, "Policy Loss": -0.017970677465200424, "Value Loss": 0.003894390072673559, "_runtime": 13519.307669878006, "_timestamp": 1585583435.1523032, "_step": 159}
{"Episode reward": -77.14286065360356, "Episode length": 999, "Policy Loss": -0.015943340957164764, "Value Loss": 0.003047669306397438, "_runtime": 13520.914323806763, "_timestamp": 1585583436.7589571, "_step": 160}
{"Episode reward": -72.53540015468144, "Episode length": 999, "Policy Loss": -0.0032575088553130627, "Value Loss": 0.0020426944829523563, "_runtime": 13522.529067516327, "_timestamp": 1585583438.3737009, "_step": 161}
{"Episode reward": -81.59669318477836, "Episode length": 999, "Policy Loss": -0.01593662053346634, "Value Loss": 0.0026078978553414345, "_runtime": 13524.130003213882, "_timestamp": 1585583439.9746366, "_step": 162}
{"Episode reward": -71.28872185211263, "Episode length": 999, "Policy Loss": -0.02903028018772602, "Value Loss": 0.0161289032548666, "_runtime": 13525.720384120941, "_timestamp": 1585583441.5650175, "_step": 163}
{"Episode reward": -72.28828883872063, "Episode length": 999, "Policy Loss": -0.0002927861351054162, "Value Loss": 0.007750125136226416, "_runtime": 13527.31468963623, "_timestamp": 1585583443.159323, "_step": 164}
{"Episode reward": -80.02780655202392, "Episode length": 999, "Policy Loss": -0.024070540443062782, "Value Loss": 0.005076301284134388, "_runtime": 13528.922893762589, "_timestamp": 1585583444.767527, "_step": 165}
{"Episode reward": -71.39997435487693, "Episode length": 999, "Policy Loss": -0.0028034402057528496, "Value Loss": 0.007392831612378359, "_runtime": 13530.510244131088, "_timestamp": 1585583446.3548775, "_step": 166}
{"Episode reward": -73.15391831620322, "Episode length": 999, "Policy Loss": 0.0045967199839651585, "Value Loss": 0.0030236716847866774, "_runtime": 13532.096502542496, "_timestamp": 1585583447.941136, "_step": 167}
{"Episode reward": -75.21299768677139, "Episode length": 999, "Policy Loss": -0.01841876283288002, "Value Loss": 0.0050993748009204865, "_runtime": 13533.691001415253, "_timestamp": 1585583449.5356348, "_step": 168}
{"Episode reward": -75.84687212697153, "Episode length": 999, "Policy Loss": -0.0068810065276920795, "Value Loss": 0.0022132007870823145, "_runtime": 13535.291874408722, "_timestamp": 1585583451.1365077, "_step": 169}
{"Episode reward": -80.5489480256862, "Episode length": 999, "Policy Loss": -0.013916456140577793, "Value Loss": 0.002567160641774535, "_runtime": 13536.897117614746, "_timestamp": 1585583452.741751, "_step": 170}
{"Episode reward": -72.39456679377322, "Episode length": 999, "Policy Loss": -0.005807551089674234, "Value Loss": 0.0064634764567017555, "_runtime": 13538.494411468506, "_timestamp": 1585583454.3390448, "_step": 171}
{"Episode reward": -75.55544243603075, "Episode length": 999, "Policy Loss": -0.021819086745381355, "Value Loss": 0.005525605753064156, "_runtime": 13540.092115163803, "_timestamp": 1585583455.9367485, "_step": 172}
{"Episode reward": -70.48114178051264, "Episode length": 999, "Policy Loss": -0.005351771600544453, "Value Loss": 0.0065833404660224915, "_runtime": 13541.696796417236, "_timestamp": 1585583457.5414298, "_step": 173}
{"Episode reward": -77.18298411057754, "Episode length": 999, "Policy Loss": -0.007758907042443752, "Value Loss": 0.001965019851922989, "_runtime": 13543.332972049713, "_timestamp": 1585583459.1776054, "_step": 174}
{"Episode reward": -70.72846118064776, "Episode length": 999, "Policy Loss": 0.002169705694541335, "Value Loss": 0.002018152503296733, "_runtime": 13544.925924062729, "_timestamp": 1585583460.7705574, "_step": 175}
{"Episode reward": -76.13099986592508, "Episode length": 999, "Policy Loss": -0.010960889980196953, "Value Loss": 0.002831346821039915, "_runtime": 13546.523096561432, "_timestamp": 1585583462.36773, "_step": 176}
{"Episode reward": -76.39516180275746, "Episode length": 999, "Policy Loss": -0.004778055939823389, "Value Loss": 0.0015728361904621124, "_runtime": 13548.112078666687, "_timestamp": 1585583463.956712, "_step": 177}
{"Episode reward": -72.9351550087376, "Episode length": 999, "Policy Loss": -0.007707204204052687, "Value Loss": 0.0020393484737724066, "_runtime": 13549.714267730713, "_timestamp": 1585583465.558901, "_step": 178}
{"Episode reward": -72.49706082641094, "Episode length": 999, "Policy Loss": -0.0016063490184023976, "Value Loss": 0.001566880731843412, "_runtime": 13551.31560754776, "_timestamp": 1585583467.160241, "_step": 179}
{"Episode reward": -75.99461914332109, "Episode length": 999, "Policy Loss": -0.010387921705842018, "Value Loss": 0.0022986107505857944, "_runtime": 13552.90727686882, "_timestamp": 1585583468.7519102, "_step": 180}
{"Episode reward": -74.876500873862, "Episode length": 999, "Policy Loss": -0.006591437850147486, "Value Loss": 0.0020433920435607433, "_runtime": 13554.518147945404, "_timestamp": 1585583470.3627813, "_step": 181}
{"Episode reward": -77.94628159968227, "Episode length": 999, "Policy Loss": -0.00946730561554432, "Value Loss": 0.0014917099615558982, "_runtime": 13556.11810016632, "_timestamp": 1585583471.9627335, "_step": 182}
{"Episode reward": -77.15559669885396, "Episode length": 999, "Policy Loss": -0.00998426228761673, "Value Loss": 0.0016455530421808362, "_runtime": 13557.709969758987, "_timestamp": 1585583473.554603, "_step": 183}
{"Episode reward": -79.47604418758931, "Episode length": 999, "Policy Loss": -0.015413696877658367, "Value Loss": 0.0015165361110121012, "_runtime": 13559.30719256401, "_timestamp": 1585583475.151826, "_step": 184}
{"Episode reward": -77.35746409794106, "Episode length": 999, "Policy Loss": -0.012818089686334133, "Value Loss": 0.0016778059070929885, "_runtime": 13560.914365768433, "_timestamp": 1585583476.758999, "_step": 185}
{"Episode reward": -74.37291609299412, "Episode length": 999, "Policy Loss": -0.013032290153205395, "Value Loss": 0.002199701964855194, "_runtime": 13562.513929843903, "_timestamp": 1585583478.3585632, "_step": 186}
{"Episode reward": -77.19315444682442, "Episode length": 999, "Policy Loss": -0.017055844888091087, "Value Loss": 0.0018489437643438578, "_runtime": 13564.11037826538, "_timestamp": 1585583479.9550116, "_step": 187}
{"Episode reward": -78.11157593394881, "Episode length": 999, "Policy Loss": -0.017345840111374855, "Value Loss": 0.0019329132046550512, "_runtime": 13565.716465711594, "_timestamp": 1585583481.561099, "_step": 188}
{"Episode reward": -78.13512085809059, "Episode length": 999, "Policy Loss": -0.012318698689341545, "Value Loss": 0.0014340576017275453, "_runtime": 13567.363167762756, "_timestamp": 1585583483.207801, "_step": 189}
{"Episode reward": -79.37138936349314, "Episode length": 999, "Policy Loss": -0.012849098071455956, "Value Loss": 0.001454753801226616, "_runtime": 13568.947763442993, "_timestamp": 1585583484.7923968, "_step": 190}
{"Episode reward": -75.27594829609824, "Episode length": 999, "Policy Loss": -0.00866920780390501, "Value Loss": 0.0015901633305475116, "_runtime": 13570.542801618576, "_timestamp": 1585583486.387435, "_step": 191}
{"Episode reward": -74.0432351187023, "Episode length": 999, "Policy Loss": -0.009941576048731804, "Value Loss": 0.0019845415372401476, "_runtime": 13572.14187002182, "_timestamp": 1585583487.9865034, "_step": 192}
{"Episode reward": -80.73233848024486, "Episode length": 999, "Policy Loss": -0.015414942055940628, "Value Loss": 0.0013564841356128454, "_runtime": 13573.731237888336, "_timestamp": 1585583489.5758712, "_step": 193}
{"Episode reward": -81.10742368181408, "Episode length": 999, "Policy Loss": -0.01681363582611084, "Value Loss": 0.0012967168586328626, "_runtime": 13575.32738494873, "_timestamp": 1585583491.1720183, "_step": 194}
{"Episode reward": -73.32281843418463, "Episode length": 999, "Policy Loss": -0.002832600614055991, "Value Loss": 0.0016875657020136714, "_runtime": 13576.91457104683, "_timestamp": 1585583492.7592044, "_step": 195}
{"Episode reward": -75.46778403021536, "Episode length": 999, "Policy Loss": -0.006910842377692461, "Value Loss": 0.0014658663421869278, "_runtime": 13578.510905504227, "_timestamp": 1585583494.3555388, "_step": 196}
{"Episode reward": -70.95437360283037, "Episode length": 999, "Policy Loss": -0.0012416194658726454, "Value Loss": 0.0020252929534763098, "_runtime": 13580.128548383713, "_timestamp": 1585583495.9731817, "_step": 197}
{"Episode reward": -78.47535131678833, "Episode length": 999, "Policy Loss": -0.01210982445627451, "Value Loss": 0.0013665808364748955, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303, -2.5664937496185303]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-16.003437042236328, -15.718626022338867, -15.43381404876709, -15.149003028869629, -14.864192008972168, -14.579380989074707, -14.29456901550293, -14.009757995605469, -13.724946975708008, -13.440135955810547, -13.15532398223877, -12.870512962341309, -12.585700988769531, -12.30088996887207, -12.01607894897461, -11.731267929077148, -11.446456909179688, -11.16164493560791, -10.87683391571045, -10.592021942138672, -10.307210922241211, -10.02239990234375, -9.737588882446289, -9.452777862548828, -9.16796588897705, -8.88315486907959, -8.598342895507812, -8.313531875610352, -8.02872085571289, -7.74390983581543, -7.459098815917969, -7.174286842346191, -6.8894758224487305, -6.6046648025512695, -6.319852828979492, -6.035041809082031, -5.75023078918457, -5.465419769287109, -5.180607795715332, -4.895796775817871, -4.61098575592041, -4.326173782348633, -4.041362762451172, -3.756551742553711, -3.47174072265625, -3.1869287490844727, -2.9021177291870117, -2.617306709289551, -2.3324947357177734, -2.0476837158203125, -1.7628726959228516, -1.4780616760253906, -1.1932497024536133, -0.9084386825561523, -0.6236276626586914, -0.33881664276123047, -0.054004669189453125, 0.2308063507080078, 0.5156173706054688, 0.8004283905029297, 1.0852394104003906, 1.3700523376464844, 1.6548633575439453, 1.9396743774414062, 2.224485397338867]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0780442953109741, -1.0386521816253662, -0.9992599487304688, -0.9598677754402161, -0.9204756021499634, -0.8810834884643555, -0.8416913151741028, -0.8022991418838501, -0.7629069685935974, -0.7235147953033447, -0.684122622013092, -0.6447304487228394, -0.6053383350372314, -0.5659461617469788, -0.5265539884567261, -0.4871618151664734, -0.4477696418762207, -0.408377468585968, -0.36898529529571533, -0.32959312200546265, -0.29020094871520996, -0.25080883502960205, -0.21141666173934937, -0.17202448844909668, -0.132632315158844, -0.09324014186859131, -0.0538480281829834, -0.014455795288085938, 0.024936318397521973, 0.06432855129241943, 0.10372066497802734, 0.1431128978729248, 0.18250501155853271, 0.22189712524414062, 0.2612893581390381, 0.300681471824646, 0.34007370471954346, 0.37946581840515137, 0.41885805130004883, 0.45825016498565674, 0.4976423978805542, 0.5370345115661621, 0.57642662525177, 0.6158188581466675, 0.6552109718322754, 0.6946032047271729, 0.7339953184127808, 0.7733875513076782, 0.8127796649932861, 0.852171778678894, 0.8915640115737915, 0.930956244468689, 0.9703482389450073, 1.0097404718399048, 1.0491327047348022, 1.0885249376296997, 1.127916932106018, 1.1673091650009155, 1.206701397895813, 1.2460933923721313, 1.2854856252670288, 1.3248778581619263, 1.3642700910568237, 1.403662085533142, 1.4430543184280396]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 4.0, 8.0, 5.0, 6.0, 8.0, 18.0, 17.0, 22.0, 24.0, 43.0, 81.0, 77.0, 43.0, 32.0, 24.0, 16.0, 12.0, 9.0, 9.0, 7.0, 2.0, 7.0, 1.0, 2.0, 4.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.1230047941207886, -1.0815244913101196, -1.0400441884994507, -0.9985639452934265, -0.9570837020874023, -0.9156033992767334, -0.8741230964660645, -0.8326427936553955, -0.7911625504493713, -0.7496823072433472, -0.7082020044326782, -0.6667217016220093, -0.6252413988113403, -0.5837611556053162, -0.5422808527946472, -0.500800609588623, -0.4593203067779541, -0.41784000396728516, -0.376359760761261, -0.33487945795059204, -0.29339921474456787, -0.2519189119338989, -0.21043860912322998, -0.1689583659172058, -0.12747806310653687, -0.0859978199005127, -0.04451751708984375, -0.0030372142791748047, 0.03844308853149414, 0.07992339134216309, 0.12140357494354248, 0.16288387775421143, 0.20436418056488037, 0.24584448337554932, 0.28732478618621826, 0.32880496978759766, 0.3702852725982666, 0.41176557540893555, 0.4532458782196045, 0.49472618103027344, 0.5362063646316528, 0.5776866674423218, 0.6191669702529907, 0.6606472730636597, 0.7021275758743286, 0.7436078786849976, 0.785088062286377, 0.8265683650970459, 0.8680486679077148, 0.9095288515090942, 0.9510091543197632, 0.9924894571304321, 1.033969759941101, 1.07545006275177, 1.116930365562439, 1.158410668373108, 1.1998909711837769, 1.2413712739944458, 1.2828515768051147, 1.3243316411972046, 1.3658119440078735, 1.4072922468185425, 1.4487725496292114, 1.4902528524398804, 1.5317331552505493]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-3.662151575088501, -3.5722339153289795, -3.482316255569458, -3.3923985958099365, -3.302481174468994, -3.2125635147094727, -3.122645854949951, -3.0327281951904297, -2.942810535430908, -2.8528928756713867, -2.7629752159118652, -2.6730575561523438, -2.5831398963928223, -2.493222236633301, -2.4033048152923584, -2.313387155532837, -2.2234694957733154, -2.133551836013794, -2.0436341762542725, -1.9537166357040405, -1.863798975944519, -1.7738813161849976, -1.6839637756347656, -1.5940461158752441, -1.5041284561157227, -1.4142107963562012, -1.3242931365966797, -1.2343754768371582, -1.1444580554962158, -1.0545403957366943, -0.9646227359771729, -0.8747050762176514, -0.7847874164581299, -0.6948697566986084, -0.6049520969390869, -0.5150344371795654, -0.42511677742004395, -0.33519935607910156, -0.24528169631958008, -0.1553640365600586, -0.06544637680053711, 0.024471282958984375, 0.11438894271850586, 0.20430660247802734, 0.2942240238189697, 0.3841416835784912, 0.4740593433380127, 0.5639770030975342, 0.6538946628570557, 0.7438123226165771, 0.8337299823760986, 0.9236476421356201, 1.0135653018951416, 1.103482961654663, 1.1934006214141846, 1.283318281173706, 1.3732354640960693, 1.4631531238555908, 1.5530707836151123, 1.6429884433746338, 1.7329061031341553, 1.8228237628936768, 1.9127414226531982, 2.0026590824127197, 2.092576742172241]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 1.0, 4.0, 1.0, 6.0, 3.0, 4.0, 5.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06628188490867615, -0.06332819908857346, -0.06037452071905136, -0.05742083489894867, -0.054467152804136276, -0.05151347070932388, -0.04855978488922119, -0.0456061027944088, -0.042652420699596405, -0.03969873860478401, -0.03674505650997162, -0.03379137068986893, -0.030837688595056534, -0.02788400650024414, -0.02493032068014145, -0.021976638585329056, -0.019022956490516663, -0.01606927439570427, -0.013115592300891876, -0.010161906480789185, -0.007208224385976791, -0.004254542291164398, -0.0013008564710617065, 0.0016528218984603882, 0.00460650771856308, 0.0075601935386657715, 0.010513871908187866, 0.013467557728290558, 0.01642124354839325, 0.019374921917915344, 0.022328607738018036, 0.02528228610754013, 0.028235971927642822, 0.031189657747745514, 0.03414333611726761, 0.0370970219373703, 0.040050700306892395, 0.04300438612699509, 0.04595807194709778, 0.04891175031661987, 0.051865436136722565, 0.054819121956825256, 0.05777280032634735, 0.060726478695869446, 0.06368017196655273, 0.06663385033607483, 0.06958752870559692, 0.07254122197628021, 0.07549490034580231, 0.0784485787153244, 0.08140227198600769, 0.08435595035552979, 0.08730962872505188, 0.09026332199573517, 0.09321700036525726, 0.09617067873477936, 0.09912437200546265, 0.10207805037498474, 0.10503172874450684, 0.10798540711402893, 0.11093910038471222, 0.11389277875423431, 0.11684645712375641, 0.1198001503944397, 0.12275382876396179]}, "_runtime": 13581.73536658287, "_timestamp": 1585583497.58, "_step": 198}
{"Episode reward": -77.13750632820576, "Episode length": 999, "Policy Loss": -0.0078378701582551, "Value Loss": 0.0014273921260610223, "_runtime": 13583.33592581749, "_timestamp": 1585583499.1805592, "_step": 199}
{"Episode reward": -72.15100994923718, "Episode length": 999, "Policy Loss": 0.0018981541506946087, "Value Loss": 0.0016168244183063507, "_runtime": 13584.94800043106, "_timestamp": 1585583500.7926338, "_step": 200}
{"Episode reward": -78.12136120184651, "Episode length": 999, "Policy Loss": -0.008649010211229324, "Value Loss": 0.0013599288649857044, "_runtime": 13586.556196928024, "_timestamp": 1585583502.4008303, "_step": 201}
{"Episode reward": -75.72174767741247, "Episode length": 999, "Policy Loss": -0.005850274581462145, "Value Loss": 0.001345728407613933, "_runtime": 13588.162479162216, "_timestamp": 1585583504.0071125, "_step": 202}
{"Episode reward": -78.12634360760757, "Episode length": 999, "Policy Loss": -0.009816274978220463, "Value Loss": 0.0013561849482357502, "_runtime": 13589.772727489471, "_timestamp": 1585583505.6173608, "_step": 203}
{"Episode reward": -81.95131553932802, "Episode length": 999, "Policy Loss": -0.015207664109766483, "Value Loss": 0.0011998523259535432, "_runtime": 13591.411621809006, "_timestamp": 1585583507.2562551, "_step": 204}
{"Episode reward": -67.63505132331973, "Episode length": 999, "Policy Loss": 0.007251956034451723, "Value Loss": 0.001617959700524807, "_runtime": 13593.010300636292, "_timestamp": 1585583508.854934, "_step": 205}
{"Episode reward": -81.24612916472766, "Episode length": 999, "Policy Loss": -0.014557695016264915, "Value Loss": 0.001208906527608633, "_runtime": 13594.61882686615, "_timestamp": 1585583510.4634602, "_step": 206}
{"Episode reward": -75.63347651819024, "Episode length": 999, "Policy Loss": -0.0028369901701807976, "Value Loss": 0.0014762787614017725, "_runtime": 13596.218240261078, "_timestamp": 1585583512.0628736, "_step": 207}
{"Episode reward": -77.79074648020338, "Episode length": 999, "Policy Loss": -0.00947158969938755, "Value Loss": 0.001307163154706359, "_runtime": 13597.815517902374, "_timestamp": 1585583513.6601512, "_step": 208}
{"Episode reward": -73.47824128474761, "Episode length": 999, "Policy Loss": -0.004342738538980484, "Value Loss": 0.001440152758732438, "_runtime": 13599.418193101883, "_timestamp": 1585583515.2628264, "_step": 209}
{"Episode reward": -75.94671954964919, "Episode length": 999, "Policy Loss": -0.004886574577540159, "Value Loss": 0.0014811060391366482, "_runtime": 13601.01900601387, "_timestamp": 1585583516.8636394, "_step": 210}
{"Episode reward": -76.00099779295977, "Episode length": 999, "Policy Loss": -0.005911572836339474, "Value Loss": 0.001409798045642674, "_runtime": 13602.603193044662, "_timestamp": 1585583518.4478264, "_step": 211}
{"Episode reward": -77.21617949711381, "Episode length": 999, "Policy Loss": -0.004110736772418022, "Value Loss": 0.0012424130691215396, "_runtime": 13604.19897890091, "_timestamp": 1585583520.0436122, "_step": 212}
{"Episode reward": -75.35490218444697, "Episode length": 999, "Policy Loss": -0.0033110196236521006, "Value Loss": 0.001389297773130238, "_runtime": 13605.792145729065, "_timestamp": 1585583521.636779, "_step": 213}
{"Episode reward": -81.38062286475258, "Episode length": 999, "Policy Loss": -0.01277263555675745, "Value Loss": 0.001177976606413722, "_runtime": 13607.395874977112, "_timestamp": 1585583523.2405083, "_step": 214}
{"Episode reward": -73.7092025151735, "Episode length": 999, "Policy Loss": 0.002728091087192297, "Value Loss": 0.0012715902412310243, "_runtime": 13608.99099946022, "_timestamp": 1585583524.8356328, "_step": 215}
{"Episode reward": -74.15572950127147, "Episode length": 999, "Policy Loss": -0.0020583958830684423, "Value Loss": 0.0013635524082928896, "_runtime": 13610.59156537056, "_timestamp": 1585583526.4361987, "_step": 216}
{"Episode reward": -74.18530228948798, "Episode length": 999, "Policy Loss": -0.0015334117924794555, "Value Loss": 0.0015271510928869247, "_runtime": 13612.182790517807, "_timestamp": 1585583528.0274239, "_step": 217}
{"Episode reward": -71.78635211110884, "Episode length": 999, "Policy Loss": 0.004024169407784939, "Value Loss": 0.0012698505306616426, "_runtime": 13613.771357536316, "_timestamp": 1585583529.6159909, "_step": 218}
{"Episode reward": -80.56127942950818, "Episode length": 999, "Policy Loss": -0.011620071716606617, "Value Loss": 0.0011146439937874675, "_runtime": 13615.414662361145, "_timestamp": 1585583531.2592957, "_step": 219}
{"Episode reward": -80.12785338915216, "Episode length": 999, "Policy Loss": -0.010418077930808067, "Value Loss": 0.0011899368837475777, "_runtime": 13617.015252113342, "_timestamp": 1585583532.8598855, "_step": 220}
{"Episode reward": -78.01810589677045, "Episode length": 999, "Policy Loss": -0.006728454027324915, "Value Loss": 0.0012468473287299275, "_runtime": 13618.619869470596, "_timestamp": 1585583534.4645028, "_step": 221}
{"Episode reward": -76.12229894929652, "Episode length": 999, "Policy Loss": -0.003176033264026046, "Value Loss": 0.001316532725468278, "_runtime": 13620.222726345062, "_timestamp": 1585583536.0673597, "_step": 222}
{"Episode reward": -75.56486055445492, "Episode length": 999, "Policy Loss": -0.0021175267174839973, "Value Loss": 0.0012858043191954494, "_runtime": 13621.820047616959, "_timestamp": 1585583537.664681, "_step": 223}
{"Episode reward": -77.45808776648838, "Episode length": 999, "Policy Loss": -0.003546502673998475, "Value Loss": 0.0012997817248106003, "_runtime": 13623.42057299614, "_timestamp": 1585583539.2652063, "_step": 224}
{"Episode reward": -78.28309293555367, "Episode length": 999, "Policy Loss": -0.007308195345103741, "Value Loss": 0.0012488558422774076, "_runtime": 13625.031871557236, "_timestamp": 1585583540.876505, "_step": 225}
{"Episode reward": -76.06103812209008, "Episode length": 999, "Policy Loss": -0.001994237769395113, "Value Loss": 0.0012777821393683553, "_runtime": 13626.62022280693, "_timestamp": 1585583542.4648561, "_step": 226}
{"Episode reward": -78.67993770666754, "Episode length": 999, "Policy Loss": -0.0059950100257992744, "Value Loss": 0.001269026193767786, "_runtime": 13628.224517583847, "_timestamp": 1585583544.069151, "_step": 227}
{"Episode reward": -73.76990104441327, "Episode length": 999, "Policy Loss": -0.0007469355477951467, "Value Loss": 0.0014058040687814355, "_runtime": 13629.830260753632, "_timestamp": 1585583545.674894, "_step": 228}
{"Episode reward": -77.4930929729325, "Episode length": 999, "Policy Loss": -0.004429830238223076, "Value Loss": 0.0012555783614516258, "_runtime": 13631.422882795334, "_timestamp": 1585583547.2675161, "_step": 229}
{"Episode reward": -74.81896850903894, "Episode length": 999, "Policy Loss": -0.0008625476039014757, "Value Loss": 0.0013489928096532822, "_runtime": 13633.024485826492, "_timestamp": 1585583548.8691192, "_step": 230}
{"Episode reward": -78.12048312883665, "Episode length": 999, "Policy Loss": -0.008436025120317936, "Value Loss": 0.0012702075764536858, "_runtime": 13634.624715805054, "_timestamp": 1585583550.4693491, "_step": 231}
{"Episode reward": -75.5287156872059, "Episode length": 999, "Policy Loss": 0.0028784836176782846, "Value Loss": 0.0012629748089239001, "_runtime": 13636.221962928772, "_timestamp": 1585583552.0665963, "_step": 232}
{"Episode reward": -78.92479914642291, "Episode length": 999, "Policy Loss": -0.0049772681668400764, "Value Loss": 0.0012355376966297626, "_runtime": 13637.853622674942, "_timestamp": 1585583553.698256, "_step": 233}
{"Episode reward": -68.514094254769, "Episode length": 999, "Policy Loss": 0.0036132605746388435, "Value Loss": 0.0017214854015037417, "_runtime": 13639.443239688873, "_timestamp": 1585583555.287873, "_step": 234}
{"Episode reward": -72.56160578296605, "Episode length": 999, "Policy Loss": 0.008301720954477787, "Value Loss": 0.0013438524911180139, "_runtime": 13641.017864227295, "_timestamp": 1585583556.8624976, "_step": 235}
{"Episode reward": -77.78443975340352, "Episode length": 999, "Policy Loss": -0.005168661009520292, "Value Loss": 0.001292623346671462, "_runtime": 13642.609246492386, "_timestamp": 1585583558.4538798, "_step": 236}
{"Episode reward": -72.00532443724057, "Episode length": 999, "Policy Loss": 0.0006734494818374515, "Value Loss": 0.001568424515426159, "_runtime": 13644.208981275558, "_timestamp": 1585583560.0536146, "_step": 237}
{"Episode reward": -73.80607849926979, "Episode length": 999, "Policy Loss": 0.0056134238839149475, "Value Loss": 0.0013228754978626966, "_runtime": 13645.796627998352, "_timestamp": 1585583561.6412613, "_step": 238}
{"Episode reward": -76.66189765346562, "Episode length": 999, "Policy Loss": -0.0019361535087227821, "Value Loss": 0.0012753496412187815, "_runtime": 13647.387202739716, "_timestamp": 1585583563.231836, "_step": 239}
{"Episode reward": -75.62392884551825, "Episode length": 999, "Policy Loss": -0.0015008042100816965, "Value Loss": 0.0013118470087647438, "_runtime": 13649.003092765808, "_timestamp": 1585583564.847726, "_step": 240}
{"Episode reward": -75.37985139270329, "Episode length": 999, "Policy Loss": 0.0004455836897250265, "Value Loss": 0.001269812579266727, "_runtime": 13650.605120658875, "_timestamp": 1585583566.449754, "_step": 241}
{"Episode reward": -76.22314064901184, "Episode length": 999, "Policy Loss": -0.0027192800771445036, "Value Loss": 0.0013408833183348179, "_runtime": 13652.194428443909, "_timestamp": 1585583568.0390618, "_step": 242}
{"Episode reward": -70.65649557254095, "Episode length": 999, "Policy Loss": 0.004858244676142931, "Value Loss": 0.0016114831669256091, "_runtime": 13653.803075313568, "_timestamp": 1585583569.6477087, "_step": 243}
{"Episode reward": -77.18887532226722, "Episode length": 999, "Policy Loss": -0.003830165835097432, "Value Loss": 0.001229932066053152, "_runtime": 13655.403863191605, "_timestamp": 1585583571.2484965, "_step": 244}
{"Episode reward": -69.26761352682884, "Episode length": 999, "Policy Loss": 0.0008256179862655699, "Value Loss": 0.0017110200133174658, "_runtime": 13657.010744810104, "_timestamp": 1585583572.8553782, "_step": 245}
{"Episode reward": -71.64596562235248, "Episode length": 999, "Policy Loss": 0.00517041701823473, "Value Loss": 0.0013669787440449, "_runtime": 13658.613323688507, "_timestamp": 1585583574.457957, "_step": 246}
{"Episode reward": -75.41332284018787, "Episode length": 999, "Policy Loss": -0.003136283718049526, "Value Loss": 0.001291333930566907, "_runtime": 13660.211600542068, "_timestamp": 1585583576.056234, "_step": 247}
{"Episode reward": -77.36168748470658, "Episode length": 999, "Policy Loss": -0.007656396832317114, "Value Loss": 0.0012945107882842422, "_runtime": 13661.839895248413, "_timestamp": 1585583577.6845286, "_step": 248}
{"Episode reward": -81.68839826863929, "Episode length": 999, "Policy Loss": -0.015021865256130695, "Value Loss": 0.0011683310149237514, "_runtime": 13663.438404083252, "_timestamp": 1585583579.2830374, "_step": 249}
{"Episode reward": -75.59125418596169, "Episode length": 999, "Policy Loss": -0.0022840159945189953, "Value Loss": 0.0013237078674137592, "_runtime": 13665.035192728043, "_timestamp": 1585583580.879826, "_step": 250}
{"Episode reward": -71.47946235046199, "Episode length": 999, "Policy Loss": 0.008646978996694088, "Value Loss": 0.0012959319865331054, "_runtime": 13666.631756782532, "_timestamp": 1585583582.4763901, "_step": 251}
{"Episode reward": -75.58574036216145, "Episode length": 999, "Policy Loss": -0.005619380623102188, "Value Loss": 0.001319659175351262, "_runtime": 13668.237882375717, "_timestamp": 1585583584.0825157, "_step": 252}
{"Episode reward": -80.19648037085332, "Episode length": 999, "Policy Loss": -0.011320921592414379, "Value Loss": 0.001160099171102047, "_runtime": 13669.821648597717, "_timestamp": 1585583585.666282, "_step": 253}
{"Episode reward": -68.86786025080389, "Episode length": 999, "Policy Loss": 0.014095352962613106, "Value Loss": 0.0014064265415072441, "_runtime": 13671.426444530487, "_timestamp": 1585583587.2710779, "_step": 254}
{"Episode reward": -73.64234309310973, "Episode length": 999, "Policy Loss": -0.0014400711515918374, "Value Loss": 0.0014211961533874273, "_runtime": 13673.020480155945, "_timestamp": 1585583588.8651135, "_step": 255}
{"Episode reward": -73.05126201663984, "Episode length": 999, "Policy Loss": 0.0022334912791848183, "Value Loss": 0.0013717731926590204, "_runtime": 13674.606496572495, "_timestamp": 1585583590.45113, "_step": 256}
{"Episode reward": -71.86250293768671, "Episode length": 999, "Policy Loss": -0.0009914010297507048, "Value Loss": 0.0015583460917696357, "_runtime": 13676.206155061722, "_timestamp": 1585583592.0507884, "_step": 257}
{"Episode reward": -71.1283152500693, "Episode length": 999, "Policy Loss": -0.0009450415964238346, "Value Loss": 0.0015902137383818626, "_runtime": 13677.80584692955, "_timestamp": 1585583593.6504803, "_step": 258}
{"Episode reward": -76.92717909354167, "Episode length": 999, "Policy Loss": -0.00736513826996088, "Value Loss": 0.0012376753147691488, "_runtime": 13679.40424823761, "_timestamp": 1585583595.2488816, "_step": 259}
{"Episode reward": -78.56923447559345, "Episode length": 999, "Policy Loss": -0.009185127913951874, "Value Loss": 0.0012014491949230433, "_runtime": 13681.005036592484, "_timestamp": 1585583596.84967, "_step": 260}
{"Episode reward": -75.06594444324084, "Episode length": 999, "Policy Loss": -0.0016404958441853523, "Value Loss": 0.0012627326650545, "_runtime": 13682.59492278099, "_timestamp": 1585583598.4395561, "_step": 261}
{"Episode reward": -73.70513964025386, "Episode length": 999, "Policy Loss": -0.004763017874211073, "Value Loss": 0.0014413994504138827, "_runtime": 13684.183780670166, "_timestamp": 1585583600.028414, "_step": 262}
{"Episode reward": -71.6147802151143, "Episode length": 999, "Policy Loss": 0.00482752313837409, "Value Loss": 0.0012254046741873026, "_runtime": 13685.80273103714, "_timestamp": 1585583601.6473644, "_step": 263}
{"Episode reward": -73.26136350612971, "Episode length": 999, "Policy Loss": 0.0017746122321113944, "Value Loss": 0.001280826167203486, "_runtime": 13687.399359941483, "_timestamp": 1585583603.2439933, "_step": 264}
{"Episode reward": -70.16085120623043, "Episode length": 999, "Policy Loss": -0.0005261331680230796, "Value Loss": 0.0016094387974590063, "_runtime": 13689.00140786171, "_timestamp": 1585583604.8460412, "_step": 265}
{"Episode reward": -74.97107713516186, "Episode length": 999, "Policy Loss": -0.005620477255433798, "Value Loss": 0.0013880113838240504, "_runtime": 13690.59512090683, "_timestamp": 1585583606.4397542, "_step": 266}
{"Episode reward": -74.82189385460791, "Episode length": 999, "Policy Loss": -0.0035490081645548344, "Value Loss": 0.0013555786572396755, "_runtime": 13692.18929696083, "_timestamp": 1585583608.0339303, "_step": 267}
{"Episode reward": -71.85778710649552, "Episode length": 999, "Policy Loss": -0.001892662257887423, "Value Loss": 0.0015415418893098831, "_runtime": 13693.784255981445, "_timestamp": 1585583609.6288893, "_step": 268}
{"Episode reward": -72.58863109979804, "Episode length": 999, "Policy Loss": 0.004865368828177452, "Value Loss": 0.0012378026731312275, "_runtime": 13695.386802434921, "_timestamp": 1585583611.2314358, "_step": 269}
{"Episode reward": -72.91052484676617, "Episode length": 999, "Policy Loss": -0.00709997583180666, "Value Loss": 0.0015352569753304124, "_runtime": 13696.97711777687, "_timestamp": 1585583612.821751, "_step": 270}
{"Episode reward": -75.65895528654558, "Episode length": 999, "Policy Loss": -0.005679616238921881, "Value Loss": 0.0012424075976014137, "_runtime": 13698.582755804062, "_timestamp": 1585583614.4273891, "_step": 271}
{"Episode reward": -80.18899238770761, "Episode length": 999, "Policy Loss": -0.013909938745200634, "Value Loss": 0.001211522496305406, "_runtime": 13700.16293168068, "_timestamp": 1585583616.007565, "_step": 272}
{"Episode reward": -79.3039546626543, "Episode length": 999, "Policy Loss": -0.01398218423128128, "Value Loss": 0.0012300972593948245, "_runtime": 13701.770351409912, "_timestamp": 1585583617.6149848, "_step": 273}
{"Episode reward": -75.0365161405575, "Episode length": 999, "Policy Loss": -0.0009112386615015566, "Value Loss": 0.0013729825150221586, "_runtime": 13703.366191387177, "_timestamp": 1585583619.2108247, "_step": 274}
{"Episode reward": -74.76742962739226, "Episode length": 999, "Policy Loss": -0.004088813904672861, "Value Loss": 0.0013110341969877481, "_runtime": 13704.974766016006, "_timestamp": 1585583620.8193994, "_step": 275}
{"Episode reward": -70.21911030303869, "Episode length": 999, "Policy Loss": 0.010188315995037556, "Value Loss": 0.001283660065382719, "_runtime": 13706.577308177948, "_timestamp": 1585583622.4219415, "_step": 276}
{"Episode reward": -75.20999068289483, "Episode length": 999, "Policy Loss": -0.0029485542327165604, "Value Loss": 0.001217759563587606, "_runtime": 13708.166872739792, "_timestamp": 1585583624.011506, "_step": 277}
{"Episode reward": -80.71600959891099, "Episode length": 999, "Policy Loss": -0.014541498385369778, "Value Loss": 0.0011842207750305533, "_runtime": 13709.808317661285, "_timestamp": 1585583625.652951, "_step": 278}
{"Episode reward": -76.9251255528745, "Episode length": 999, "Policy Loss": -0.005194293335080147, "Value Loss": 0.0012500296579673886, "_runtime": 13711.397373914719, "_timestamp": 1585583627.2420073, "_step": 279}
{"Episode reward": -72.63389012610831, "Episode length": 999, "Policy Loss": -0.002367153763771057, "Value Loss": 0.001443522167392075, "_runtime": 13713.005722045898, "_timestamp": 1585583628.8503554, "_step": 280}
{"Episode reward": -81.58187071167131, "Episode length": 999, "Policy Loss": -0.01392776146531105, "Value Loss": 0.001103767310269177, "_runtime": 13714.606167078018, "_timestamp": 1585583630.4508004, "_step": 281}
{"Episode reward": -71.67031888091017, "Episode length": 999, "Policy Loss": -0.0009076697169803083, "Value Loss": 0.0014680096646770835, "_runtime": 13716.202489852905, "_timestamp": 1585583632.0471232, "_step": 282}
{"Episode reward": -74.28393961077067, "Episode length": 999, "Policy Loss": -0.005085178185254335, "Value Loss": 0.0014693847624585032, "_runtime": 13717.788631916046, "_timestamp": 1585583633.6332653, "_step": 283}
{"Episode reward": -77.83715590149993, "Episode length": 999, "Policy Loss": -0.0068620676174759865, "Value Loss": 0.001243563718162477, "_runtime": 13719.391954183578, "_timestamp": 1585583635.2365875, "_step": 284}
{"Episode reward": -82.23650017248727, "Episode length": 999, "Policy Loss": -0.014696707017719746, "Value Loss": 0.001152878045104444, "_runtime": 13720.989676713943, "_timestamp": 1585583636.83431, "_step": 285}
{"Episode reward": -75.96068389957205, "Episode length": 999, "Policy Loss": -0.004698446020483971, "Value Loss": 0.0012576283188536763, "_runtime": 13722.587939500809, "_timestamp": 1585583638.4325728, "_step": 286}
{"Episode reward": -75.32410622003671, "Episode length": 999, "Policy Loss": -0.0015360470861196518, "Value Loss": 0.0013428042875602841, "_runtime": 13724.19215965271, "_timestamp": 1585583640.036793, "_step": 287}
{"Episode reward": -75.76879635140885, "Episode length": 999, "Policy Loss": -0.00045514872181229293, "Value Loss": 0.0012732946779578924, "_runtime": 13725.78946352005, "_timestamp": 1585583641.6340969, "_step": 288}
{"Episode reward": -80.41176960074012, "Episode length": 999, "Policy Loss": -0.011887672357261181, "Value Loss": 0.0012345771538093686, "_runtime": 13727.388190031052, "_timestamp": 1585583643.2328234, "_step": 289}
{"Episode reward": -76.92523899715943, "Episode length": 999, "Policy Loss": -0.0035743308253586292, "Value Loss": 0.0012178237084299326, "_runtime": 13728.982360601425, "_timestamp": 1585583644.826994, "_step": 290}
{"Episode reward": -72.85044534276531, "Episode length": 999, "Policy Loss": 0.008836565539240837, "Value Loss": 0.0013399694580584764, "_runtime": 13730.57731461525, "_timestamp": 1585583646.421948, "_step": 291}
{"Episode reward": -75.93716658855271, "Episode length": 999, "Policy Loss": 0.0021416025701910257, "Value Loss": 0.0012703711399808526, "_runtime": 13732.199607610703, "_timestamp": 1585583648.044241, "_step": 292}
{"Episode reward": -78.7333275728883, "Episode length": 999, "Policy Loss": -0.0035447166301310062, "Value Loss": 0.0011802149238064885, "_runtime": 13733.787192106247, "_timestamp": 1585583649.6318254, "_step": 293}
{"Episode reward": -74.92663878737191, "Episode length": 999, "Policy Loss": -8.758134754316416e-06, "Value Loss": 0.0013469366822391748, "_runtime": 13735.369324445724, "_timestamp": 1585583651.2139578, "_step": 294}
{"Episode reward": -80.97544584214069, "Episode length": 999, "Policy Loss": -0.008354716002941132, "Value Loss": 0.0011851040180772543, "_runtime": 13736.946843385696, "_timestamp": 1585583652.7914767, "_step": 295}
{"Episode reward": -79.48313572394311, "Episode length": 999, "Policy Loss": -0.006573924329131842, "Value Loss": 0.0011779817286878824, "_runtime": 13738.54001903534, "_timestamp": 1585583654.3846524, "_step": 296}
{"Episode reward": -75.52967003527874, "Episode length": 999, "Policy Loss": -0.002687434433028102, "Value Loss": 0.0013407127698883414, "_runtime": 13740.119970321655, "_timestamp": 1585583655.9646037, "_step": 297}
{"Episode reward": -78.27374978240735, "Episode length": 999, "Policy Loss": -0.0038981963880360126, "Value Loss": 0.0012639211490750313, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487, -0.2361287772655487]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.756152153015137, -6.646742343902588, -6.537332534790039, -6.427923202514648, -6.3185133934021, -6.209103584289551, -6.099693775177002, -5.990283966064453, -5.880874156951904, -5.7714643478393555, -5.662055015563965, -5.552645206451416, -5.443235397338867, -5.333825588226318, -5.2244157791137695, -5.115005970001221, -5.005596160888672, -4.896186828613281, -4.786777019500732, -4.677367210388184, -4.567957401275635, -4.458547592163086, -4.349138259887695, -4.239727973937988, -4.130318641662598, -4.020908832550049, -3.9114990234375, -3.802089214324951, -3.6926796436309814, -3.5832698345184326, -3.473860025405884, -3.364450454711914, -3.2550406455993652, -3.1456308364868164, -3.0362212657928467, -2.926811456680298, -2.817401647567749, -2.7079920768737793, -2.5985822677612305, -2.4891724586486816, -2.379762649536133, -2.270352840423584, -2.1609435081481934, -2.0515336990356445, -1.9421238899230957, -1.8327140808105469, -1.723304271697998, -1.6138944625854492, -1.5044851303100586, -1.3950753211975098, -1.285665512084961, -1.176255702972412, -1.0668458938598633, -0.9574360847473145, -0.8480262756347656, -0.738616943359375, -0.6292071342468262, -0.5197973251342773, -0.4103875160217285, -0.3009777069091797, -0.19156789779663086, -0.08215856552124023, 0.027251243591308594, 0.13666105270385742, 0.24607086181640625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15806645154953003, -0.151345893740654, -0.14462532103061676, -0.13790476322174072, -0.1311841905117035, -0.12446363270282745, -0.11774305999279022, -0.11102250218391418, -0.10430192947387695, -0.09758137166500092, -0.09086080640554428, -0.08414024114608765, -0.07741967588663101, -0.07069911062717438, -0.06397854536771774, -0.05725798010826111, -0.050537414848804474, -0.04381684958934784, -0.037096284329891205, -0.03037571907043457, -0.023655161261558533, -0.0169345885515213, -0.010214030742645264, -0.0034934580326080322, 0.0032270997762680054, 0.009947672486305237, 0.016668230295181274, 0.023388803005218506, 0.030109360814094543, 0.036829933524131775, 0.04355049133300781, 0.050271064043045044, 0.05699162185192108, 0.06371217966079712, 0.07043275237083435, 0.07715331017971039, 0.08387388288974762, 0.09059444069862366, 0.09731501340866089, 0.10403558611869812, 0.11075612902641296, 0.1174767017364502, 0.12419727444648743, 0.13091784715652466, 0.1376383900642395, 0.14435896277427673, 0.15107953548431396, 0.1578001081943512, 0.16452065110206604, 0.17124122381210327, 0.1779617965221405, 0.18468233942985535, 0.19140291213989258, 0.1981234848499298, 0.20484405755996704, 0.21156460046768188, 0.21828517317771912, 0.22500574588775635, 0.23172631859779358, 0.23844686150550842, 0.24516743421554565, 0.2518880069255829, 0.2586085796356201, 0.26532912254333496, 0.2720496952533722]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 2.0, 1.0, 5.0, 8.0, 12.0, 4.0, 5.0, 12.0, 15.0, 17.0, 16.0, 25.0, 37.0, 26.0, 48.0, 76.0, 33.0, 35.0, 19.0, 25.0, 14.0, 16.0, 4.0, 9.0, 8.0, 2.0, 7.0, 5.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.35528871417045593, -0.34167855978012085, -0.32806840538978577, -0.3144582509994507, -0.3008480966091156, -0.2872379422187805, -0.2736278176307678, -0.26001763343811035, -0.24640749394893646, -0.23279733955860138, -0.2191871851682663, -0.2055770307779312, -0.19196689128875732, -0.17835673689842224, -0.16474658250808716, -0.15113642811775208, -0.137526273727417, -0.12391611933708191, -0.11030596494674683, -0.09669581055641174, -0.08308565616607666, -0.06947550177574158, -0.055865347385406494, -0.04225519299507141, -0.028645068407058716, -0.015034914016723633, -0.0014247596263885498, 0.012185394763946533, 0.025795549154281616, 0.0394057035446167, 0.05301585793495178, 0.06662601232528687, 0.08023616671562195, 0.09384632110595703, 0.10745647549629211, 0.1210666298866272, 0.13467678427696228, 0.14828690886497498, 0.16189709305763245, 0.17550721764564514, 0.1891174018383026, 0.2027275264263153, 0.21633771061897278, 0.22994783520698547, 0.24355801939964294, 0.25716814398765564, 0.2707783281803131, 0.2843884527683258, 0.2979985773563385, 0.31160876154899597, 0.32521888613700867, 0.33882907032966614, 0.35243919491767883, 0.3660493791103363, 0.379659503698349, 0.39326968789100647, 0.40687981247901917, 0.42048999667167664, 0.43410012125968933, 0.4477103054523468, 0.4613204300403595, 0.47493061423301697, 0.48854073882102966, 0.5021508932113647, 0.5157610177993774]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5133233666419983, -0.49775227904319763, -0.48218122124671936, -0.4666101336479187, -0.45103907585144043, -0.43546798825263977, -0.4198969006538391, -0.40432584285736084, -0.38875478506088257, -0.3731836974620819, -0.35761260986328125, -0.342041552066803, -0.3264704644680023, -0.31089937686920166, -0.2953283190727234, -0.2797572612762451, -0.26418617367744446, -0.2486150860786438, -0.23304402828216553, -0.21747294068336487, -0.2019018828868866, -0.18633079528808594, -0.17075973749160767, -0.155188649892807, -0.13961756229400635, -0.12404650449752808, -0.10847541689872742, -0.09290435910224915, -0.07733327150344849, -0.061762213706970215, -0.046191126108169556, -0.030620068311691284, -0.015048980712890625, 0.0005220770835876465, 0.016093194484710693, 0.031664252281188965, 0.047235310077667236, 0.06280636787414551, 0.07837748527526855, 0.09394854307174683, 0.1095196008682251, 0.12509071826934814, 0.14066177606582642, 0.1562328338623047, 0.17180389165878296, 0.187375009059906, 0.20294606685638428, 0.21851712465286255, 0.2340882420539856, 0.24965929985046387, 0.26523035764694214, 0.2808014154434204, 0.29637253284454346, 0.31194359064102173, 0.3275146484375, 0.34308570623397827, 0.3586568236351013, 0.3742278814315796, 0.38979893922805786, 0.4053700566291809, 0.4209411144256592, 0.43651217222213745, 0.4520832300186157, 0.46765434741973877, 0.48322540521621704]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 6.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.6161729097366333, -0.5937446355819702, -0.5713163018226624, -0.5488880276679993, -0.5264597535133362, -0.5040314197540283, -0.48160314559936523, -0.45917484164237976, -0.4367465376853943, -0.4143182635307312, -0.3918899595737457, -0.36946165561676025, -0.34703338146209717, -0.3246050775051117, -0.3021767735481262, -0.27974849939346313, -0.25732019543647766, -0.2348918914794922, -0.2124636173248291, -0.19003531336784363, -0.16760700941085815, -0.14517873525619507, -0.1227504312992096, -0.10032212734222412, -0.07789385318756104, -0.055465519428253174, -0.03303724527359009, -0.010608971118927002, 0.01181936264038086, 0.034247636795043945, 0.05667591094970703, 0.07910424470901489, 0.10153251886367798, 0.12396079301834106, 0.14638912677764893, 0.168817400932312, 0.1912456750869751, 0.21367400884628296, 0.23610228300094604, 0.25853055715560913, 0.280958890914917, 0.3033871650695801, 0.32581543922424316, 0.348243772983551, 0.3706720471382141, 0.393100380897522, 0.41552865505218506, 0.43795692920684814, 0.46038520336151123, 0.4828134775161743, 0.505241870880127, 0.52767014503479, 0.5500984191894531, 0.5725266933441162, 0.5949549674987793, 0.6173832416534424, 0.639811635017395, 0.6622399091720581, 0.6846681833267212, 0.7070964574813843, 0.7295247316360474, 0.7519530057907104, 0.7743813991546631, 0.7968096733093262, 0.8192379474639893]}, "_runtime": 13741.747101545334, "_timestamp": 1585583657.591735, "_step": 298}
{"Episode reward": -73.49565588346998, "Episode length": 999, "Policy Loss": 0.00688078673556447, "Value Loss": 0.0014583738520741463, "_runtime": 13743.338265895844, "_timestamp": 1585583659.1828992, "_step": 299}
{"Episode reward": -83.00596895506702, "Episode length": 999, "Policy Loss": -0.013187169097363949, "Value Loss": 0.001064157229848206, "_runtime": 13744.923676252365, "_timestamp": 1585583660.7683096, "_step": 300}
{"Episode reward": -78.30708344616735, "Episode length": 999, "Policy Loss": -0.0024331994354724884, "Value Loss": 0.0012301482493057847, "_runtime": 13746.524932146072, "_timestamp": 1585583662.3695655, "_step": 301}
{"Episode reward": -71.51312040471568, "Episode length": 999, "Policy Loss": 0.011044627986848354, "Value Loss": 0.0015669148415327072, "_runtime": 13748.117495059967, "_timestamp": 1585583663.9621284, "_step": 302}
{"Episode reward": -73.50641497894412, "Episode length": 999, "Policy Loss": 0.003923203330487013, "Value Loss": 0.0014772219583392143, "_runtime": 13749.725239276886, "_timestamp": 1585583665.5698726, "_step": 303}
{"Episode reward": -74.16775583136315, "Episode length": 999, "Policy Loss": -0.0003141713095828891, "Value Loss": 0.001318557420745492, "_runtime": 13751.312754154205, "_timestamp": 1585583667.1573875, "_step": 304}
{"Episode reward": -74.71426582100742, "Episode length": 999, "Policy Loss": 0.00038336406578309834, "Value Loss": 0.0013389760861173272, "_runtime": 13752.908280611038, "_timestamp": 1585583668.752914, "_step": 305}
{"Episode reward": -81.95968736237202, "Episode length": 999, "Policy Loss": -0.008740018121898174, "Value Loss": 0.0011373837478458881, "_runtime": 13754.510443687439, "_timestamp": 1585583670.355077, "_step": 306}
{"Episode reward": -73.19587709258289, "Episode length": 999, "Policy Loss": 0.0017800332279875875, "Value Loss": 0.00146871292963624, "_runtime": 13756.138294696808, "_timestamp": 1585583671.982928, "_step": 307}
{"Episode reward": -69.9525723202344, "Episode length": 999, "Policy Loss": 0.006696219090372324, "Value Loss": 0.001650823513045907, "_runtime": 13757.742013454437, "_timestamp": 1585583673.5866468, "_step": 308}
{"Episode reward": -77.3778105654452, "Episode length": 999, "Policy Loss": -0.0030054147355258465, "Value Loss": 0.0012580124894157052, "_runtime": 13759.339699029922, "_timestamp": 1585583675.1843324, "_step": 309}
{"Episode reward": -70.36666510572874, "Episode length": 999, "Policy Loss": 0.006481716874986887, "Value Loss": 0.001520212390460074, "_runtime": 13760.940065383911, "_timestamp": 1585583676.7846987, "_step": 310}
{"Episode reward": -76.53871250454112, "Episode length": 999, "Policy Loss": -0.003929690457880497, "Value Loss": 0.0013050218112766743, "_runtime": 13762.544706821442, "_timestamp": 1585583678.3893402, "_step": 311}
{"Episode reward": -74.39496603745764, "Episode length": 999, "Policy Loss": -0.0014181259321048856, "Value Loss": 0.0014454082120209932, "_runtime": 13764.124094486237, "_timestamp": 1585583679.9687278, "_step": 312}
{"Episode reward": -73.2514167448226, "Episode length": 999, "Policy Loss": 0.003042126540094614, "Value Loss": 0.0013584318803623319, "_runtime": 13765.70828795433, "_timestamp": 1585583681.5529213, "_step": 313}
{"Episode reward": -73.90573796813733, "Episode length": 999, "Policy Loss": 0.00322250509634614, "Value Loss": 0.0013474716106429696, "_runtime": 13767.311534404755, "_timestamp": 1585583683.1561677, "_step": 314}
{"Episode reward": -77.65706178187129, "Episode length": 999, "Policy Loss": -0.005850002635270357, "Value Loss": 0.0012021649163216352, "_runtime": 13768.912847042084, "_timestamp": 1585583684.7574804, "_step": 315}
{"Episode reward": -76.36624228994621, "Episode length": 999, "Policy Loss": -0.003528906498104334, "Value Loss": 0.0013104818062856793, "_runtime": 13770.514012813568, "_timestamp": 1585583686.3586462, "_step": 316}
{"Episode reward": -76.64766080470268, "Episode length": 999, "Policy Loss": -0.003124358132481575, "Value Loss": 0.001252354122698307, "_runtime": 13772.117862939835, "_timestamp": 1585583687.9624963, "_step": 317}
{"Episode reward": -81.46689226628719, "Episode length": 999, "Policy Loss": -0.011980993673205376, "Value Loss": 0.0011406998382881284, "_runtime": 13773.721599340439, "_timestamp": 1585583689.5662327, "_step": 318}
{"Episode reward": -76.76701978194349, "Episode length": 999, "Policy Loss": -0.006191318389028311, "Value Loss": 0.0012933574616909027, "_runtime": 13775.315227985382, "_timestamp": 1585583691.1598613, "_step": 319}
{"Episode reward": -80.91516557749915, "Episode length": 999, "Policy Loss": -0.013244189321994781, "Value Loss": 0.0011525236768648028, "_runtime": 13776.924947738647, "_timestamp": 1585583692.769581, "_step": 320}
{"Episode reward": -78.72380372883426, "Episode length": 999, "Policy Loss": -0.00940691214054823, "Value Loss": 0.0012575866421684623, "_runtime": 13778.519386291504, "_timestamp": 1585583694.3640196, "_step": 321}
{"Episode reward": -79.22082725303312, "Episode length": 999, "Policy Loss": -0.00775170000270009, "Value Loss": 0.0011742457281798124, "_runtime": 13780.14119887352, "_timestamp": 1585583695.9858322, "_step": 322}
{"Episode reward": -72.80820281327314, "Episode length": 999, "Policy Loss": -0.0021325384732335806, "Value Loss": 0.001521168276667595, "_runtime": 13781.750507831573, "_timestamp": 1585583697.5951412, "_step": 323}
{"Episode reward": -74.01186253657472, "Episode length": 999, "Policy Loss": 0.004913679324090481, "Value Loss": 0.001253779511898756, "_runtime": 13783.337798595428, "_timestamp": 1585583699.182432, "_step": 324}
{"Episode reward": -77.39573621985556, "Episode length": 999, "Policy Loss": -0.00440839771181345, "Value Loss": 0.0012086661299690604, "_runtime": 13784.92780137062, "_timestamp": 1585583700.7724347, "_step": 325}
{"Episode reward": -76.89443126158635, "Episode length": 999, "Policy Loss": -0.0032027154229581356, "Value Loss": 0.0012833073269575834, "_runtime": 13786.52196264267, "_timestamp": 1585583702.366596, "_step": 326}
{"Episode reward": -74.36755140236377, "Episode length": 999, "Policy Loss": 0.0025436722207814455, "Value Loss": 0.0013954596361145377, "_runtime": 13788.127174854279, "_timestamp": 1585583703.9718082, "_step": 327}
{"Episode reward": -68.80754700678877, "Episode length": 999, "Policy Loss": 0.012531893327832222, "Value Loss": 0.0015215253224596381, "_runtime": 13789.732232093811, "_timestamp": 1585583705.5768654, "_step": 328}
{"Episode reward": -75.16621482848436, "Episode length": 999, "Policy Loss": -0.0022778711281716824, "Value Loss": 0.0013386121718212962, "_runtime": 13791.341574668884, "_timestamp": 1585583707.186208, "_step": 329}
{"Episode reward": -77.58390558310383, "Episode length": 999, "Policy Loss": -0.004757306072860956, "Value Loss": 0.0012797173112630844, "_runtime": 13792.948726892471, "_timestamp": 1585583708.7933602, "_step": 330}
{"Episode reward": -74.92849489187478, "Episode length": 999, "Policy Loss": 0.0003002835437655449, "Value Loss": 0.001320629264228046, "_runtime": 13794.548925876617, "_timestamp": 1585583710.3935592, "_step": 331}
{"Episode reward": -78.24927003056521, "Episode length": 999, "Policy Loss": -0.004974648356437683, "Value Loss": 0.0012475022813305259, "_runtime": 13796.156609535217, "_timestamp": 1585583712.0012429, "_step": 332}
{"Episode reward": -77.0082531865678, "Episode length": 999, "Policy Loss": -0.005454536527395248, "Value Loss": 0.0012648875126615167, "_runtime": 13797.759252548218, "_timestamp": 1585583713.603886, "_step": 333}
{"Episode reward": -75.29229459166723, "Episode length": 999, "Policy Loss": 0.0007028040708974004, "Value Loss": 0.0013106277910992503, "_runtime": 13799.363020181656, "_timestamp": 1585583715.2076535, "_step": 334}
{"Episode reward": -80.90853178753504, "Episode length": 999, "Policy Loss": -0.010465670377016068, "Value Loss": 0.0011631535599008203, "_runtime": 13800.961203575134, "_timestamp": 1585583716.805837, "_step": 335}
{"Episode reward": -74.28918261206566, "Episode length": 999, "Policy Loss": -0.00041330637759529054, "Value Loss": 0.0012717072386294603, "_runtime": 13802.561529874802, "_timestamp": 1585583718.4061632, "_step": 336}
{"Episode reward": -74.4475901388472, "Episode length": 999, "Policy Loss": -0.0014420526567846537, "Value Loss": 0.0013939525233581662, "_runtime": 13804.186657190323, "_timestamp": 1585583720.0312905, "_step": 337}
{"Episode reward": -70.03896275558392, "Episode length": 999, "Policy Loss": 0.015917791053652763, "Value Loss": 0.0013555411715060472, "_runtime": 13805.78712964058, "_timestamp": 1585583721.631763, "_step": 338}
{"Episode reward": -75.66434584606942, "Episode length": 999, "Policy Loss": -0.0006975861033424735, "Value Loss": 0.0013230562908574939, "_runtime": 13807.382476329803, "_timestamp": 1585583723.2271097, "_step": 339}
{"Episode reward": -75.57193858006157, "Episode length": 999, "Policy Loss": -0.00011394089233363047, "Value Loss": 0.001298738643527031, "_runtime": 13808.973480463028, "_timestamp": 1585583724.8181138, "_step": 340}
{"Episode reward": -78.19582197388623, "Episode length": 999, "Policy Loss": -0.0037765856832265854, "Value Loss": 0.0012099603191018105, "_runtime": 13810.56442451477, "_timestamp": 1585583726.4090579, "_step": 341}
{"Episode reward": -72.33080673252324, "Episode length": 999, "Policy Loss": -0.0008690088288858533, "Value Loss": 0.001527183223515749, "_runtime": 13812.150689840317, "_timestamp": 1585583727.9953232, "_step": 342}
{"Episode reward": -71.0845197240685, "Episode length": 999, "Policy Loss": -0.003795695025473833, "Value Loss": 0.0015868772752583027, "_runtime": 13813.743477582932, "_timestamp": 1585583729.588111, "_step": 343}
{"Episode reward": -73.47757049425488, "Episode length": 999, "Policy Loss": -0.0010905967792496085, "Value Loss": 0.0014902175171300769, "_runtime": 13815.346605300903, "_timestamp": 1585583731.1912386, "_step": 344}
{"Episode reward": -71.81847913989374, "Episode length": 999, "Policy Loss": 0.0056336065754294395, "Value Loss": 0.0014505601720884442, "_runtime": 13816.95387339592, "_timestamp": 1585583732.7985067, "_step": 345}
{"Episode reward": -73.83574494602338, "Episode length": 999, "Policy Loss": -0.0034840393345803022, "Value Loss": 0.0014505055733025074, "_runtime": 13818.557600021362, "_timestamp": 1585583734.4022334, "_step": 346}
{"Episode reward": -76.83796277689227, "Episode length": 999, "Policy Loss": -0.004492161795496941, "Value Loss": 0.0012528907973319292, "_runtime": 13820.159134149551, "_timestamp": 1585583736.0037675, "_step": 347}
{"Episode reward": -72.95548811516949, "Episode length": 999, "Policy Loss": 0.003193377749994397, "Value Loss": 0.0014188005588948727, "_runtime": 13821.758736610413, "_timestamp": 1585583737.60337, "_step": 348}
{"Episode reward": -83.33041820186071, "Episode length": 999, "Policy Loss": -0.017757853493094444, "Value Loss": 0.001080619520507753, "_runtime": 13823.357879400253, "_timestamp": 1585583739.2025127, "_step": 349}
{"Episode reward": -74.87354363765265, "Episode length": 999, "Policy Loss": -0.002908517373725772, "Value Loss": 0.0013941318029537797, "_runtime": 13824.972207307816, "_timestamp": 1585583740.8168406, "_step": 350}
{"Episode reward": -69.8201906636755, "Episode length": 999, "Policy Loss": 0.003570921253412962, "Value Loss": 0.001630055601708591, "_runtime": 13826.56976723671, "_timestamp": 1585583742.4144006, "_step": 351}
{"Episode reward": -78.37612141014151, "Episode length": 999, "Policy Loss": -0.009989792481064796, "Value Loss": 0.001239559962414205, "_runtime": 13828.207637548447, "_timestamp": 1585583744.052271, "_step": 352}
{"Episode reward": -76.36247135873545, "Episode length": 999, "Policy Loss": -0.006141796708106995, "Value Loss": 0.0013458894100040197, "_runtime": 13829.803082942963, "_timestamp": 1585583745.6477163, "_step": 353}
{"Episode reward": -77.25777599594177, "Episode length": 999, "Policy Loss": -0.009527965448796749, "Value Loss": 0.001261978643015027, "_runtime": 13831.40058684349, "_timestamp": 1585583747.2452202, "_step": 354}
{"Episode reward": -75.75291005061362, "Episode length": 999, "Policy Loss": -0.006454620976001024, "Value Loss": 0.0014409194700419903, "_runtime": 13832.994370222092, "_timestamp": 1585583748.8390036, "_step": 355}
{"Episode reward": -75.36139303579246, "Episode length": 999, "Policy Loss": -0.006252748891711235, "Value Loss": 0.001425144961103797, "_runtime": 13834.597624540329, "_timestamp": 1585583750.442258, "_step": 356}
{"Episode reward": -81.21510473281877, "Episode length": 999, "Policy Loss": -0.014069415628910065, "Value Loss": 0.0011793298181146383, "_runtime": 13836.19877743721, "_timestamp": 1585583752.0434108, "_step": 357}
{"Episode reward": -78.23414658562753, "Episode length": 999, "Policy Loss": -0.008736126124858856, "Value Loss": 0.0012004096060991287, "_runtime": 13837.79957318306, "_timestamp": 1585583753.6442065, "_step": 358}
{"Episode reward": -74.10368264639284, "Episode length": 999, "Policy Loss": -0.0021355601493269205, "Value Loss": 0.0013648151652887464, "_runtime": 13839.405928134918, "_timestamp": 1585583755.2505615, "_step": 359}
{"Episode reward": -78.98955805479497, "Episode length": 999, "Policy Loss": -0.010652136988937855, "Value Loss": 0.0012714118929579854, "_runtime": 13841.00034570694, "_timestamp": 1585583756.844979, "_step": 360}
{"Episode reward": -74.77278263242684, "Episode length": 999, "Policy Loss": 0.0016626041615381837, "Value Loss": 0.0012204560916870832, "_runtime": 13842.600599765778, "_timestamp": 1585583758.445233, "_step": 361}
{"Episode reward": -75.42908499864224, "Episode length": 999, "Policy Loss": 0.0017582944128662348, "Value Loss": 0.0012675843900069594, "_runtime": 13844.20878624916, "_timestamp": 1585583760.0534196, "_step": 362}
{"Episode reward": -82.09203620797355, "Episode length": 999, "Policy Loss": -0.013446192257106304, "Value Loss": 0.0011099363910034299, "_runtime": 13845.812544822693, "_timestamp": 1585583761.6571782, "_step": 363}
{"Episode reward": -75.28483105340253, "Episode length": 999, "Policy Loss": -0.0011055459035560489, "Value Loss": 0.0013302110601216555, "_runtime": 13847.393099784851, "_timestamp": 1585583763.2377331, "_step": 364}
{"Episode reward": -74.91071816767723, "Episode length": 999, "Policy Loss": 0.004298150539398193, "Value Loss": 0.0011953734792768955, "_runtime": 13848.979317426682, "_timestamp": 1585583764.8239508, "_step": 365}
{"Episode reward": -72.33724764826583, "Episode length": 999, "Policy Loss": 0.00856632087379694, "Value Loss": 0.0012711207382380962, "_runtime": 13850.609143018723, "_timestamp": 1585583766.4537764, "_step": 366}
{"Episode reward": -75.14260394377683, "Episode length": 999, "Policy Loss": 0.000470282364403829, "Value Loss": 0.0013296282850205898, "_runtime": 13852.200966119766, "_timestamp": 1585583768.0455995, "_step": 367}
{"Episode reward": -79.75238633498215, "Episode length": 999, "Policy Loss": -0.00704166479408741, "Value Loss": 0.0011973751243203878, "_runtime": 13853.795427799225, "_timestamp": 1585583769.6400611, "_step": 368}
{"Episode reward": -78.80578047957131, "Episode length": 999, "Policy Loss": -0.007280303630977869, "Value Loss": 0.0012288398575037718, "_runtime": 13855.390375614166, "_timestamp": 1585583771.235009, "_step": 369}
{"Episode reward": -81.48217079921727, "Episode length": 999, "Policy Loss": -0.009653299115598202, "Value Loss": 0.0011748119723051786, "_runtime": 13856.992520332336, "_timestamp": 1585583772.8371537, "_step": 370}
{"Episode reward": -72.90581285106366, "Episode length": 999, "Policy Loss": 0.003140089102089405, "Value Loss": 0.001343317679129541, "_runtime": 13858.585437774658, "_timestamp": 1585583774.430071, "_step": 371}
{"Episode reward": -76.94271035397367, "Episode length": 999, "Policy Loss": -0.002162304939702153, "Value Loss": 0.0012747658183798194, "_runtime": 13860.187599658966, "_timestamp": 1585583776.032233, "_step": 372}
{"Episode reward": -75.46560780024487, "Episode length": 999, "Policy Loss": -0.003347336780279875, "Value Loss": 0.0013861010083928704, "_runtime": 13861.792087554932, "_timestamp": 1585583777.636721, "_step": 373}
{"Episode reward": -72.44833068047504, "Episode length": 999, "Policy Loss": 0.008288313634693623, "Value Loss": 0.0013200341491028666, "_runtime": 13863.39105463028, "_timestamp": 1585583779.235688, "_step": 374}
{"Episode reward": -74.19951640402735, "Episode length": 999, "Policy Loss": 0.0033183093182742596, "Value Loss": 0.0013860533945262432, "_runtime": 13864.988530397415, "_timestamp": 1585583780.8331637, "_step": 375}
{"Episode reward": -71.33055846171948, "Episode length": 999, "Policy Loss": -5.544832310988568e-05, "Value Loss": 0.0015895097749307752, "_runtime": 13866.601271152496, "_timestamp": 1585583782.4459045, "_step": 376}
{"Episode reward": -77.62766870605086, "Episode length": 999, "Policy Loss": -0.005961958318948746, "Value Loss": 0.00131471105851233, "_runtime": 13868.204081773758, "_timestamp": 1585583784.048715, "_step": 377}
{"Episode reward": -79.51295443605453, "Episode length": 999, "Policy Loss": -0.005965817254036665, "Value Loss": 0.0012737715151160955, "_runtime": 13869.809338331223, "_timestamp": 1585583785.6539717, "_step": 378}
{"Episode reward": -75.99910383113114, "Episode length": 999, "Policy Loss": -0.0005259584868326783, "Value Loss": 0.0013355795526877046, "_runtime": 13871.406225681305, "_timestamp": 1585583787.250859, "_step": 379}
{"Episode reward": -75.92269137781146, "Episode length": 999, "Policy Loss": -0.0004773881519213319, "Value Loss": 0.0012959102168679237, "_runtime": 13872.987716913223, "_timestamp": 1585583788.8323503, "_step": 380}
{"Episode reward": -70.38284701662619, "Episode length": 999, "Policy Loss": 0.0011401085648685694, "Value Loss": 0.001527737476862967, "_runtime": 13874.623994588852, "_timestamp": 1585583790.468628, "_step": 381}
{"Episode reward": -74.38701476318718, "Episode length": 999, "Policy Loss": -0.0005313692381605506, "Value Loss": 0.001391674275510013, "_runtime": 13876.228070259094, "_timestamp": 1585583792.0727036, "_step": 382}
{"Episode reward": -74.94461016315208, "Episode length": 999, "Policy Loss": 0.0012870054924860597, "Value Loss": 0.0013042818754911423, "_runtime": 13877.829113960266, "_timestamp": 1585583793.6737473, "_step": 383}
{"Episode reward": -75.08574761353574, "Episode length": 999, "Policy Loss": 0.0015576701844111085, "Value Loss": 0.0013077271869406104, "_runtime": 13879.431084871292, "_timestamp": 1585583795.2757182, "_step": 384}
{"Episode reward": -73.22959555291132, "Episode length": 999, "Policy Loss": -0.00041628573671914637, "Value Loss": 0.0014529881300404668, "_runtime": 13881.027567148209, "_timestamp": 1585583796.8722005, "_step": 385}
{"Episode reward": -79.5131368273457, "Episode length": 999, "Policy Loss": -0.00938726682215929, "Value Loss": 0.001193007337860763, "_runtime": 13882.618667602539, "_timestamp": 1585583798.463301, "_step": 386}
{"Episode reward": -71.71607606064002, "Episode length": 999, "Policy Loss": 0.008055528625845909, "Value Loss": 0.0014604558236896992, "_runtime": 13884.211139678955, "_timestamp": 1585583800.055773, "_step": 387}
{"Episode reward": -75.78241321786774, "Episode length": 999, "Policy Loss": -0.0036647820379585028, "Value Loss": 0.0014085969887673855, "_runtime": 13885.811733484268, "_timestamp": 1585583801.6563668, "_step": 388}
{"Episode reward": -78.99570899135749, "Episode length": 999, "Policy Loss": -0.008549124002456665, "Value Loss": 0.0011627187486737967, "_runtime": 13887.415839910507, "_timestamp": 1585583803.2604733, "_step": 389}
{"Episode reward": -80.92595119866482, "Episode length": 999, "Policy Loss": -0.012045023031532764, "Value Loss": 0.0011712413979694247, "_runtime": 13889.021327733994, "_timestamp": 1585583804.865961, "_step": 390}
{"Episode reward": -75.7354520827447, "Episode length": 999, "Policy Loss": -0.00010408173693576828, "Value Loss": 0.0011957971146330237, "_runtime": 13890.618810892105, "_timestamp": 1585583806.4634442, "_step": 391}
{"Episode reward": -75.67463603003024, "Episode length": 999, "Policy Loss": -0.0026531226467341185, "Value Loss": 0.0013360166922211647, "_runtime": 13892.222716331482, "_timestamp": 1585583808.0673497, "_step": 392}
{"Episode reward": -78.338106422745, "Episode length": 999, "Policy Loss": -0.006679975427687168, "Value Loss": 0.001233008923009038, "_runtime": 13893.819099903107, "_timestamp": 1585583809.6637332, "_step": 393}
{"Episode reward": -73.6130741331525, "Episode length": 999, "Policy Loss": -0.0013093131128698587, "Value Loss": 0.0014622170710936189, "_runtime": 13895.405307292938, "_timestamp": 1585583811.2499406, "_step": 394}
{"Episode reward": -73.02001556789162, "Episode length": 999, "Policy Loss": 0.0037768660113215446, "Value Loss": 0.0013070089044049382, "_runtime": 13897.010001897812, "_timestamp": 1585583812.8546352, "_step": 395}
{"Episode reward": -77.26052343657832, "Episode length": 999, "Policy Loss": -0.00462682731449604, "Value Loss": 0.0013123941607773304, "_runtime": 13898.65230679512, "_timestamp": 1585583814.4969401, "_step": 396}
{"Episode reward": -70.91029047193985, "Episode length": 999, "Policy Loss": 0.006649693474173546, "Value Loss": 0.00145911134313792, "_runtime": 13900.23351430893, "_timestamp": 1585583816.0781476, "_step": 397}
{"Episode reward": -74.12504307838304, "Episode length": 999, "Policy Loss": -0.004805834498256445, "Value Loss": 0.001372586702927947, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146, 1.6223450899124146]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3438968658447266, -1.2569211721420288, -1.1699453592300415, -1.0829696655273438, -0.9959939122200012, -0.9090181589126587, -0.8220424652099609, -0.7350667119026184, -0.6480909585952759, -0.5611152052879333, -0.4741394519805908, -0.38716375827789307, -0.3001880645751953, -0.213212251663208, -0.12623655796051025, -0.03926074504852295, 0.047714948654174805, 0.13469064235687256, 0.22166645526885986, 0.3086421489715576, 0.3956179618835449, 0.4825936555862427, 0.5695693492889404, 0.6565451622009277, 0.7435207366943359, 0.8304965496063232, 0.9174723625183105, 1.0044481754302979, 1.091423749923706, 1.1783995628356934, 1.2653753757476807, 1.3523509502410889, 1.4393267631530762, 1.5263025760650635, 1.6132781505584717, 1.700253963470459, 1.7872297763824463, 1.8742053508758545, 1.9611811637878418, 2.048156976699829, 2.1351327896118164, 2.2221083641052246, 2.309084177017212, 2.396059989929199, 2.4830355644226074, 2.5700113773345947, 2.656987190246582, 2.7439627647399902, 2.8309383392333984, 2.917914390563965, 3.004889965057373, 3.0918660163879395, 3.1788415908813477, 3.265817165374756, 3.3527932167053223, 3.4397687911987305, 3.5267443656921387, 3.613720417022705, 3.7006959915161133, 3.7876715660095215, 3.874647617340088, 3.961623191833496, 4.048598766326904, 4.135574817657471, 4.222550392150879]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6260172128677368, -0.6091833710670471, -0.5923495292663574, -0.575515627861023, -0.5586817860603333, -0.5418479442596436, -0.5250140428543091, -0.5081802010536194, -0.4913463592529297, -0.47451251745224, -0.4576786458492279, -0.4408447742462158, -0.4240109324455261, -0.4071770906448364, -0.39034321904182434, -0.37350934743881226, -0.35667550563812256, -0.33984166383743286, -0.3230077922344208, -0.3061739206314087, -0.289340078830719, -0.2725062370300293, -0.2556723654270172, -0.23883849382400513, -0.22200465202331543, -0.20517081022262573, -0.18833693861961365, -0.17150306701660156, -0.15466922521591187, -0.13783538341522217, -0.1210014820098877, -0.104167640209198, -0.0873337984085083, -0.0704999566078186, -0.053666114807128906, -0.036832213401794434, -0.019998371601104736, -0.003164529800415039, 0.013669371604919434, 0.03050321340560913, 0.04733705520629883, 0.06417089700698853, 0.08100473880767822, 0.0978386402130127, 0.11467248201370239, 0.1315063238143921, 0.14834022521972656, 0.16517406702041626, 0.18200790882110596, 0.19884175062179565, 0.21567559242248535, 0.23250949382781982, 0.24934333562850952, 0.2661771774291992, 0.2830110788345337, 0.2998449206352234, 0.3166787624359131, 0.3335126042366028, 0.3503464460372925, 0.36718034744262695, 0.3840142488479614, 0.40084803104400635, 0.4176819324493408, 0.43451571464538574, 0.4513496160507202]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 6.0, 7.0, 7.0, 11.0, 10.0, 19.0, 13.0, 39.0, 34.0, 54.0, 74.0, 60.0, 41.0, 23.0, 22.0, 16.0, 6.0, 7.0, 9.0, 11.0, 1.0, 6.0, 3.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.5889955163002014, -0.573219358921051, -0.5574432611465454, -0.541667103767395, -0.5258909463882446, -0.510114848613739, -0.4943386912345886, -0.4785625636577606, -0.4627864360809326, -0.4470103085041046, -0.4312341809272766, -0.4154580235481262, -0.3996818959712982, -0.3839057683944702, -0.3681296110153198, -0.3523534834384918, -0.3365773558616638, -0.3208012282848358, -0.3050251007080078, -0.2892489433288574, -0.2734728157520294, -0.2576966881752014, -0.24192053079605103, -0.22614440321922302, -0.21036827564239502, -0.19459214806556702, -0.178816020488739, -0.16303986310958862, -0.14726373553276062, -0.13148760795593262, -0.11571145057678223, -0.09993532299995422, -0.08415919542312622, -0.06838303804397583, -0.052606940269470215, -0.036830782890319824, -0.02105468511581421, -0.005278527736663818, 0.010497629642486572, 0.026273727416992188, 0.04204988479614258, 0.05782604217529297, 0.07360213994979858, 0.08937829732894897, 0.10515445470809937, 0.12093055248260498, 0.13670670986175537, 0.152482807636261, 0.16825896501541138, 0.18403512239456177, 0.19981122016906738, 0.21558737754821777, 0.2313634753227234, 0.24713963270187378, 0.26291579008102417, 0.2786918878555298, 0.2944680452346802, 0.31024420261383057, 0.3260203003883362, 0.3417964577674866, 0.35757261514663696, 0.3733487129211426, 0.38912487030029297, 0.4049009680747986, 0.420677125453949]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.8949556350708008, -0.8555328249931335, -0.8161100149154663, -0.7766871452331543, -0.7372643351554871, -0.6978415250778198, -0.6584186553955078, -0.6189958453178406, -0.5795730352401733, -0.5401502251625061, -0.5007274150848389, -0.46130454540252686, -0.4218817353248596, -0.3824589252471924, -0.34303605556488037, -0.30361324548721313, -0.2641904354095459, -0.22476762533187866, -0.18534481525421143, -0.14592194557189941, -0.10649913549423218, -0.06707632541656494, -0.02765345573425293, 0.011769354343414307, 0.05119216442108154, 0.09061497449874878, 0.13003778457641602, 0.16946065425872803, 0.20888352394104004, 0.2483062744140625, 0.2877291440963745, 0.327151894569397, 0.366574764251709, 0.405997633934021, 0.44542038440704346, 0.48484325408935547, 0.5242660045623779, 0.5636888742446899, 0.603111743927002, 0.6425344944000244, 0.6819573640823364, 0.7213802337646484, 0.7608029842376709, 0.8002258539199829, 0.8396487236022949, 0.8790714740753174, 0.9184943437576294, 0.9579170942306519, 0.9973399639129639, 1.0367628335952759, 1.0761855840682983, 1.1156084537506104, 1.1550312042236328, 1.1944541931152344, 1.2338769435882568, 1.2732996940612793, 1.3127226829528809, 1.3521454334259033, 1.3915681838989258, 1.4309909343719482, 1.4704139232635498, 1.5098366737365723, 1.5492594242095947, 1.5886824131011963, 1.6281051635742188]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 14.0, 7.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2631527781486511, -0.25311604142189026, -0.2430793046951294, -0.23304256796836853, -0.22300583124160767, -0.2129690945148468, -0.20293237268924713, -0.19289563596248627, -0.1828588992357254, -0.17282216250896454, -0.16278542578220367, -0.152748703956604, -0.14271196722984314, -0.13267523050308228, -0.12263849377632141, -0.11260175704956055, -0.10256502032279968, -0.09252828359603882, -0.08249154686927795, -0.07245481014251709, -0.062418073415756226, -0.052381351590156555, -0.04234461486339569, -0.03230787813663483, -0.022271141409873962, -0.012234419584274292, -0.0021976828575134277, 0.007839053869247437, 0.0178757905960083, 0.027912527322769165, 0.03794926404953003, 0.047986000776290894, 0.05802273750305176, 0.06805947422981262, 0.07809621095657349, 0.08813294768333435, 0.09816968441009521, 0.10820642113685608, 0.11824315786361694, 0.1282798945903778, 0.13831663131713867, 0.14835333824157715, 0.158390074968338, 0.16842681169509888, 0.17846354842185974, 0.1885002851486206, 0.19853702187538147, 0.20857375860214233, 0.2186104953289032, 0.22864723205566406, 0.23868393898010254, 0.2487207055091858, 0.25875741243362427, 0.2687941789627075, 0.278830885887146, 0.28886765241622925, 0.2989043593406677, 0.308941125869751, 0.31897783279418945, 0.3290145993232727, 0.3390513062477112, 0.34908807277679443, 0.3591247797012329, 0.36916154623031616, 0.37919825315475464]}, "_runtime": 13901.840452432632, "_timestamp": 1585583817.6850858, "_step": 398}
{"Episode reward": -71.96752135296299, "Episode length": 999, "Policy Loss": 0.0037204325199127197, "Value Loss": 0.0014770053094252944, "_runtime": 13903.449920654297, "_timestamp": 1585583819.294554, "_step": 399}
{"Episode reward": -69.30793118075404, "Episode length": 999, "Policy Loss": 0.008852489292621613, "Value Loss": 0.0016417036531493068, "_runtime": 13905.053825616837, "_timestamp": 1585583820.898459, "_step": 400}
{"Episode reward": -74.54453759441998, "Episode length": 999, "Policy Loss": -0.004606857895851135, "Value Loss": 0.0014130573254078627, "_runtime": 13906.660808563232, "_timestamp": 1585583822.505442, "_step": 401}
{"Episode reward": -77.96328748761951, "Episode length": 999, "Policy Loss": -0.007145203184336424, "Value Loss": 0.0012627154355868697, "_runtime": 13908.270835876465, "_timestamp": 1585583824.1154692, "_step": 402}
{"Episode reward": -78.81883854210005, "Episode length": 999, "Policy Loss": -0.009490463882684708, "Value Loss": 0.0012059741420671344, "_runtime": 13909.880414485931, "_timestamp": 1585583825.7250478, "_step": 403}
{"Episode reward": -76.68277700615194, "Episode length": 999, "Policy Loss": -0.00522072147578001, "Value Loss": 0.001258702133782208, "_runtime": 13911.478150129318, "_timestamp": 1585583827.3227835, "_step": 404}
{"Episode reward": -74.48213629807913, "Episode length": 999, "Policy Loss": -0.0014091430930420756, "Value Loss": 0.001392057165503502, "_runtime": 13913.075583696365, "_timestamp": 1585583828.920217, "_step": 405}
{"Episode reward": -72.0414595982657, "Episode length": 999, "Policy Loss": 0.007768027018755674, "Value Loss": 0.0012553943088278174, "_runtime": 13914.670849323273, "_timestamp": 1585583830.5154827, "_step": 406}
{"Episode reward": -76.33910310738815, "Episode length": 999, "Policy Loss": -0.00822940468788147, "Value Loss": 0.0013500407803803682, "_runtime": 13916.25841999054, "_timestamp": 1585583832.1030533, "_step": 407}
{"Episode reward": -75.39781745157595, "Episode length": 999, "Policy Loss": -0.0011510613840073347, "Value Loss": 0.0013692656066268682, "_runtime": 13917.8560256958, "_timestamp": 1585583833.700659, "_step": 408}
{"Episode reward": -73.39283692519605, "Episode length": 999, "Policy Loss": -0.0030001390259712934, "Value Loss": 0.001415554783307016, "_runtime": 13919.459931135178, "_timestamp": 1585583835.3045645, "_step": 409}
{"Episode reward": -71.28144893325549, "Episode length": 999, "Policy Loss": -0.0007566891144961119, "Value Loss": 0.001564801437780261, "_runtime": 13921.061358690262, "_timestamp": 1585583836.905992, "_step": 410}
{"Episode reward": -79.58733673849409, "Episode length": 999, "Policy Loss": -0.011167606338858604, "Value Loss": 0.0011839414946734905, "_runtime": 13922.687470912933, "_timestamp": 1585583838.5321043, "_step": 411}
{"Episode reward": -81.17849401483534, "Episode length": 999, "Policy Loss": -0.014684837311506271, "Value Loss": 0.001176308374851942, "_runtime": 13924.289916753769, "_timestamp": 1585583840.13455, "_step": 412}
{"Episode reward": -73.32115481589916, "Episode length": 999, "Policy Loss": 0.002869032323360443, "Value Loss": 0.0012677571503445506, "_runtime": 13925.891692638397, "_timestamp": 1585583841.736326, "_step": 413}
{"Episode reward": -78.99572820213656, "Episode length": 999, "Policy Loss": -0.009669063612818718, "Value Loss": 0.0012666560942307115, "_runtime": 13927.492839097977, "_timestamp": 1585583843.3374724, "_step": 414}
{"Episode reward": -76.69026600364667, "Episode length": 999, "Policy Loss": -0.0062947762198746204, "Value Loss": 0.0012732726754620671, "_runtime": 13929.090982913971, "_timestamp": 1585583844.9356163, "_step": 415}
{"Episode reward": -69.70335352379594, "Episode length": 999, "Policy Loss": 0.010112657211720943, "Value Loss": 0.0014887625584378839, "_runtime": 13930.683249235153, "_timestamp": 1585583846.5278826, "_step": 416}
{"Episode reward": -74.8210304255788, "Episode length": 999, "Policy Loss": -0.002893815515562892, "Value Loss": 0.0014261744217947125, "_runtime": 13932.288775920868, "_timestamp": 1585583848.1334093, "_step": 417}
{"Episode reward": -79.18561926599982, "Episode length": 999, "Policy Loss": -0.008971299044787884, "Value Loss": 0.001251434558071196, "_runtime": 13933.904556274414, "_timestamp": 1585583849.7491896, "_step": 418}
{"Episode reward": -73.04321860380544, "Episode length": 999, "Policy Loss": -0.002611721633002162, "Value Loss": 0.0014970072079449892, "_runtime": 13935.502737522125, "_timestamp": 1585583851.3473709, "_step": 419}
{"Episode reward": -76.17940102813077, "Episode length": 999, "Policy Loss": -0.005129681900143623, "Value Loss": 0.0013447962701320648, "_runtime": 13937.100805521011, "_timestamp": 1585583852.9454389, "_step": 420}
{"Episode reward": -71.9250159663801, "Episode length": 999, "Policy Loss": 0.0018229612614959478, "Value Loss": 0.0015093775000423193, "_runtime": 13938.699440717697, "_timestamp": 1585583854.544074, "_step": 421}
{"Episode reward": -79.03694522656481, "Episode length": 999, "Policy Loss": -0.010232389904558659, "Value Loss": 0.0012679389910772443, "_runtime": 13940.290053367615, "_timestamp": 1585583856.1346867, "_step": 422}
{"Episode reward": -75.39288239782482, "Episode length": 999, "Policy Loss": -0.00012183483340777457, "Value Loss": 0.0012873141095042229, "_runtime": 13941.882670879364, "_timestamp": 1585583857.7273042, "_step": 423}
{"Episode reward": -80.2521254637209, "Episode length": 999, "Policy Loss": -0.011757885105907917, "Value Loss": 0.0012187568936496973, "_runtime": 13943.481443881989, "_timestamp": 1585583859.3260772, "_step": 424}
{"Episode reward": -78.80834256235951, "Episode length": 999, "Policy Loss": -0.008605068549513817, "Value Loss": 0.0012738533550873399, "_runtime": 13945.109508037567, "_timestamp": 1585583860.9541414, "_step": 425}
{"Episode reward": -73.39314489239108, "Episode length": 999, "Policy Loss": 0.0052405307069420815, "Value Loss": 0.0013351780362427235, "_runtime": 13946.699314117432, "_timestamp": 1585583862.5439475, "_step": 426}
{"Episode reward": -78.7497349750586, "Episode length": 999, "Policy Loss": -0.00862080231308937, "Value Loss": 0.001253766007721424, "_runtime": 13948.28763961792, "_timestamp": 1585583864.132273, "_step": 427}
{"Episode reward": -70.78869366264267, "Episode length": 999, "Policy Loss": 0.010329742915928364, "Value Loss": 0.0014533470384776592, "_runtime": 13949.891162633896, "_timestamp": 1585583865.735796, "_step": 428}
{"Episode reward": -76.18944561244466, "Episode length": 999, "Policy Loss": -0.0027621460612863302, "Value Loss": 0.0013530377764254808, "_runtime": 13951.481766462326, "_timestamp": 1585583867.3263998, "_step": 429}
{"Episode reward": -72.92277959297033, "Episode length": 999, "Policy Loss": 0.0028382577002048492, "Value Loss": 0.001426038914360106, "_runtime": 13953.082855939865, "_timestamp": 1585583868.9274893, "_step": 430}
{"Episode reward": -69.79789203514265, "Episode length": 999, "Policy Loss": 0.003928564954549074, "Value Loss": 0.0016240483382716775, "_runtime": 13954.67335820198, "_timestamp": 1585583870.5179915, "_step": 431}
{"Episode reward": -78.89241667348807, "Episode length": 999, "Policy Loss": -0.007062449119985104, "Value Loss": 0.0012023051967844367, "_runtime": 13956.276288509369, "_timestamp": 1585583872.1209219, "_step": 432}
{"Episode reward": -69.51637552897193, "Episode length": 999, "Policy Loss": 0.0031528319232165813, "Value Loss": 0.0017361360369250178, "_runtime": 13957.879286766052, "_timestamp": 1585583873.72392, "_step": 433}
{"Episode reward": -74.44985937778443, "Episode length": 999, "Policy Loss": -0.007068186067044735, "Value Loss": 0.001404422684572637, "_runtime": 13959.485455989838, "_timestamp": 1585583875.3300893, "_step": 434}
{"Episode reward": -74.36602283269978, "Episode length": 999, "Policy Loss": -0.003708411240950227, "Value Loss": 0.0013548537390306592, "_runtime": 13961.09514093399, "_timestamp": 1585583876.9397743, "_step": 435}
{"Episode reward": -74.51266157579455, "Episode length": 999, "Policy Loss": -0.004706647712737322, "Value Loss": 0.001483011874370277, "_runtime": 13962.68419599533, "_timestamp": 1585583878.5288293, "_step": 436}
{"Episode reward": -75.14919558477487, "Episode length": 999, "Policy Loss": -0.0036479488480836153, "Value Loss": 0.00133699516300112, "_runtime": 13964.285640716553, "_timestamp": 1585583880.130274, "_step": 437}
{"Episode reward": -77.53005222367462, "Episode length": 999, "Policy Loss": -0.007813086733222008, "Value Loss": 0.001320555922575295, "_runtime": 13965.886828899384, "_timestamp": 1585583881.7314622, "_step": 438}
{"Episode reward": -75.60929750885326, "Episode length": 999, "Policy Loss": -0.004840335808694363, "Value Loss": 0.0012796934461221099, "_runtime": 13967.4904088974, "_timestamp": 1585583883.3350422, "_step": 439}
{"Episode reward": -80.83032005292317, "Episode length": 999, "Policy Loss": -0.013212828896939754, "Value Loss": 0.0011482355184853077, "_runtime": 13969.125579357147, "_timestamp": 1585583884.9702127, "_step": 440}
{"Episode reward": -78.41448716564535, "Episode length": 999, "Policy Loss": -0.008794515393674374, "Value Loss": 0.0012530647218227386, "_runtime": 13970.724752187729, "_timestamp": 1585583886.5693855, "_step": 441}
{"Episode reward": -78.528811399628, "Episode length": 999, "Policy Loss": -0.010865220800042152, "Value Loss": 0.001262037898413837, "_runtime": 13972.320657253265, "_timestamp": 1585583888.1652906, "_step": 442}
{"Episode reward": -77.10100509610713, "Episode length": 999, "Policy Loss": -0.007113044615834951, "Value Loss": 0.0012950706295669079, "_runtime": 13973.927525043488, "_timestamp": 1585583889.7721584, "_step": 443}
{"Episode reward": -79.83499547552235, "Episode length": 999, "Policy Loss": -0.012122869491577148, "Value Loss": 0.001266533276066184, "_runtime": 13975.532619953156, "_timestamp": 1585583891.3772533, "_step": 444}
{"Episode reward": -76.3185328288445, "Episode length": 999, "Policy Loss": -0.004387069493532181, "Value Loss": 0.001252641435712576, "_runtime": 13977.131694078445, "_timestamp": 1585583892.9763274, "_step": 445}
{"Episode reward": -75.75437733469366, "Episode length": 999, "Policy Loss": -0.0022181877866387367, "Value Loss": 0.001357921282760799, "_runtime": 13978.728800296783, "_timestamp": 1585583894.5734336, "_step": 446}
{"Episode reward": -74.58746330338718, "Episode length": 999, "Policy Loss": -0.0016251421766355634, "Value Loss": 0.0014487459557130933, "_runtime": 13980.348961114883, "_timestamp": 1585583896.1935945, "_step": 447}
{"Episode reward": -80.58058885246817, "Episode length": 999, "Policy Loss": -0.010400211438536644, "Value Loss": 0.0011855399934574962, "_runtime": 13981.947424173355, "_timestamp": 1585583897.7920575, "_step": 448}
{"Episode reward": -77.9529749045184, "Episode length": 999, "Policy Loss": -0.004404282197356224, "Value Loss": 0.001236588228493929, "_runtime": 13983.53328537941, "_timestamp": 1585583899.3779187, "_step": 449}
{"Episode reward": -77.16655767758391, "Episode length": 999, "Policy Loss": -0.0027021917048841715, "Value Loss": 0.0012606083182618022, "_runtime": 13985.130344867706, "_timestamp": 1585583900.9749782, "_step": 450}
{"Episode reward": -77.18854644675125, "Episode length": 999, "Policy Loss": -0.0048586041666567326, "Value Loss": 0.0012811728520318866, "_runtime": 13986.724805355072, "_timestamp": 1585583902.5694387, "_step": 451}
{"Episode reward": -72.90022680485231, "Episode length": 999, "Policy Loss": 0.005120724905282259, "Value Loss": 0.001314295339398086, "_runtime": 13988.32194185257, "_timestamp": 1585583904.1665752, "_step": 452}
{"Episode reward": -72.58658334457378, "Episode length": 999, "Policy Loss": 0.003249978646636009, "Value Loss": 0.0014581477735191584, "_runtime": 13989.930368185043, "_timestamp": 1585583905.7750015, "_step": 453}
{"Episode reward": -76.7609454792933, "Episode length": 999, "Policy Loss": 0.0012187629472464323, "Value Loss": 0.0011661035241559148, "_runtime": 13991.530870199203, "_timestamp": 1585583907.3755035, "_step": 454}
{"Episode reward": -77.6520470454966, "Episode length": 999, "Policy Loss": -0.003628986421972513, "Value Loss": 0.0013203802518546581, "_runtime": 13993.173384904861, "_timestamp": 1585583909.0180182, "_step": 455}
{"Episode reward": -80.17864560002388, "Episode length": 999, "Policy Loss": -0.006723285187035799, "Value Loss": 0.0011857193894684315, "_runtime": 13994.767129182816, "_timestamp": 1585583910.6117625, "_step": 456}
{"Episode reward": -75.41735358343236, "Episode length": 999, "Policy Loss": 0.0031792239751666784, "Value Loss": 0.0013110372237861156, "_runtime": 13996.355957269669, "_timestamp": 1585583912.2005906, "_step": 457}
{"Episode reward": -75.70071777100809, "Episode length": 999, "Policy Loss": -0.0010095764882862568, "Value Loss": 0.0013259834377095103, "_runtime": 13997.965761899948, "_timestamp": 1585583913.8103952, "_step": 458}
{"Episode reward": -77.96351410467275, "Episode length": 999, "Policy Loss": -0.007347183767706156, "Value Loss": 0.001273101894184947, "_runtime": 13999.562138795853, "_timestamp": 1585583915.4067721, "_step": 459}
{"Episode reward": -80.51662947673584, "Episode length": 999, "Policy Loss": -0.007781628519296646, "Value Loss": 0.0012025698088109493, "_runtime": 14001.174371004105, "_timestamp": 1585583917.0190043, "_step": 460}
{"Episode reward": -75.29873788195187, "Episode length": 999, "Policy Loss": 0.0022447837982326746, "Value Loss": 0.0012176096206530929, "_runtime": 14002.777870178223, "_timestamp": 1585583918.6225035, "_step": 461}
{"Episode reward": -72.15612609760414, "Episode length": 999, "Policy Loss": 0.01244041882455349, "Value Loss": 0.0013828848022967577, "_runtime": 14004.3802318573, "_timestamp": 1585583920.2248652, "_step": 462}
{"Episode reward": -77.70962330695619, "Episode length": 999, "Policy Loss": -0.002686075633391738, "Value Loss": 0.0012736027128994465, "_runtime": 14005.982861995697, "_timestamp": 1585583921.8274953, "_step": 463}
{"Episode reward": -76.45153868663974, "Episode length": 999, "Policy Loss": 0.001873320434242487, "Value Loss": 0.0012160880723968148, "_runtime": 14007.58963227272, "_timestamp": 1585583923.4342656, "_step": 464}
{"Episode reward": -74.95799367701974, "Episode length": 999, "Policy Loss": 0.004750175401568413, "Value Loss": 0.0012966745998710394, "_runtime": 14009.18517613411, "_timestamp": 1585583925.0298095, "_step": 465}
{"Episode reward": -78.41872603501471, "Episode length": 999, "Policy Loss": -0.004121276084333658, "Value Loss": 0.001237235963344574, "_runtime": 14010.780145168304, "_timestamp": 1585583926.6247785, "_step": 466}
{"Episode reward": -78.44956888273785, "Episode length": 999, "Policy Loss": -0.0032088696025311947, "Value Loss": 0.0012247166596353054, "_runtime": 14012.388581037521, "_timestamp": 1585583928.2332144, "_step": 467}
{"Episode reward": -70.22095116321786, "Episode length": 999, "Policy Loss": 0.016564957797527313, "Value Loss": 0.0013705603778362274, "_runtime": 14013.995045423508, "_timestamp": 1585583929.8396788, "_step": 468}
{"Episode reward": -76.32516752398125, "Episode length": 999, "Policy Loss": 0.0008457167423330247, "Value Loss": 0.0012531126849353313, "_runtime": 14015.58493757248, "_timestamp": 1585583931.429571, "_step": 469}
{"Episode reward": -77.3649403719212, "Episode length": 999, "Policy Loss": -0.0026578831020742655, "Value Loss": 0.0012220435310155153, "_runtime": 14017.229146957397, "_timestamp": 1585583933.0737803, "_step": 470}
{"Episode reward": -75.61223440940198, "Episode length": 999, "Policy Loss": -0.0032000751234591007, "Value Loss": 0.0013336824486032128, "_runtime": 14018.83907365799, "_timestamp": 1585583934.683707, "_step": 471}
{"Episode reward": -78.23810522692737, "Episode length": 999, "Policy Loss": -0.004470973741263151, "Value Loss": 0.001205572159960866, "_runtime": 14020.437446117401, "_timestamp": 1585583936.2820795, "_step": 472}
{"Episode reward": -79.67120622542897, "Episode length": 999, "Policy Loss": -0.0068137431517243385, "Value Loss": 0.001219223951920867, "_runtime": 14022.027081727982, "_timestamp": 1585583937.871715, "_step": 473}
{"Episode reward": -71.67434556298845, "Episode length": 999, "Policy Loss": 0.010264578275382519, "Value Loss": 0.0013616274809464812, "_runtime": 14023.627019166946, "_timestamp": 1585583939.4716525, "_step": 474}
{"Episode reward": -74.12373410150917, "Episode length": 999, "Policy Loss": 0.0009785167640075088, "Value Loss": 0.0014201804297044873, "_runtime": 14025.225253105164, "_timestamp": 1585583941.0698864, "_step": 475}
{"Episode reward": -78.01937883877612, "Episode length": 999, "Policy Loss": -0.0049867392517626286, "Value Loss": 0.00124179117847234, "_runtime": 14026.830305099487, "_timestamp": 1585583942.6749384, "_step": 476}
{"Episode reward": -79.32460316808962, "Episode length": 999, "Policy Loss": -0.008371646516025066, "Value Loss": 0.0012337097432464361, "_runtime": 14028.424885988235, "_timestamp": 1585583944.2695193, "_step": 477}
{"Episode reward": -78.47211535046851, "Episode length": 999, "Policy Loss": -0.006595598999410868, "Value Loss": 0.0012611655984073877, "_runtime": 14030.01049399376, "_timestamp": 1585583945.8551273, "_step": 478}
{"Episode reward": -79.66625184778421, "Episode length": 999, "Policy Loss": -0.008297658525407314, "Value Loss": 0.0011963038705289364, "_runtime": 14031.60244512558, "_timestamp": 1585583947.4470785, "_step": 479}
{"Episode reward": -69.6288377952517, "Episode length": 999, "Policy Loss": 0.004177297465503216, "Value Loss": 0.0017164885066449642, "_runtime": 14033.198036432266, "_timestamp": 1585583949.0426698, "_step": 480}
{"Episode reward": -73.50094068850866, "Episode length": 999, "Policy Loss": -0.00014815382019151002, "Value Loss": 0.0014541257405653596, "_runtime": 14034.788672924042, "_timestamp": 1585583950.6333063, "_step": 481}
{"Episode reward": -74.97241593128012, "Episode length": 999, "Policy Loss": 1.837852323660627e-05, "Value Loss": 0.0012626565294340253, "_runtime": 14036.3924639225, "_timestamp": 1585583952.2370973, "_step": 482}
{"Episode reward": -76.17915741528118, "Episode length": 999, "Policy Loss": -0.002249254146590829, "Value Loss": 0.0012970991665497422, "_runtime": 14037.981590747833, "_timestamp": 1585583953.826224, "_step": 483}
{"Episode reward": -74.38632019385503, "Episode length": 999, "Policy Loss": -0.001831627800129354, "Value Loss": 0.0014461041428148746, "_runtime": 14039.584654092789, "_timestamp": 1585583955.4292874, "_step": 484}
{"Episode reward": -79.97940982738288, "Episode length": 999, "Policy Loss": -0.010028909891843796, "Value Loss": 0.0011770731071010232, "_runtime": 14041.223101854324, "_timestamp": 1585583957.0677352, "_step": 485}
{"Episode reward": -74.6950163373699, "Episode length": 999, "Policy Loss": 0.0011456127976998687, "Value Loss": 0.001203007996082306, "_runtime": 14042.827185153961, "_timestamp": 1585583958.6718185, "_step": 486}
{"Episode reward": -80.79949591058387, "Episode length": 999, "Policy Loss": -0.011403645388782024, "Value Loss": 0.0011589849600568414, "_runtime": 14044.427124261856, "_timestamp": 1585583960.2717576, "_step": 487}
{"Episode reward": -75.0699782119637, "Episode length": 999, "Policy Loss": -0.003556617069989443, "Value Loss": 0.001401670859195292, "_runtime": 14046.032539844513, "_timestamp": 1585583961.8771732, "_step": 488}
{"Episode reward": -73.25886846671334, "Episode length": 999, "Policy Loss": -0.0003761440748348832, "Value Loss": 0.0015595926670357585, "_runtime": 14047.632306337357, "_timestamp": 1585583963.4769397, "_step": 489}
{"Episode reward": -75.39245282591939, "Episode length": 999, "Policy Loss": -0.002330197487026453, "Value Loss": 0.001419002073816955, "_runtime": 14049.231510162354, "_timestamp": 1585583965.0761435, "_step": 490}
{"Episode reward": -72.2058284395976, "Episode length": 999, "Policy Loss": 0.00993898045271635, "Value Loss": 0.0012258265633136034, "_runtime": 14050.829515218735, "_timestamp": 1585583966.6741486, "_step": 491}
{"Episode reward": -79.97927993350667, "Episode length": 999, "Policy Loss": -0.010553259402513504, "Value Loss": 0.0011522050481289625, "_runtime": 14052.43409705162, "_timestamp": 1585583968.2787304, "_step": 492}
{"Episode reward": -78.67161089882755, "Episode length": 999, "Policy Loss": -0.0072344643995165825, "Value Loss": 0.0012387982569634914, "_runtime": 14054.042716503143, "_timestamp": 1585583969.8873498, "_step": 493}
{"Episode reward": -78.29616467621831, "Episode length": 999, "Policy Loss": -0.007380486465990543, "Value Loss": 0.0012712936149910092, "_runtime": 14055.640431404114, "_timestamp": 1585583971.4850647, "_step": 494}
{"Episode reward": -76.97982604023106, "Episode length": 999, "Policy Loss": -0.005244322586804628, "Value Loss": 0.001314943889155984, "_runtime": 14057.246343135834, "_timestamp": 1585583973.0909765, "_step": 495}
{"Episode reward": -76.79334970611856, "Episode length": 999, "Policy Loss": -0.0037139304913580418, "Value Loss": 0.001251882640644908, "_runtime": 14058.847633838654, "_timestamp": 1585583974.6922672, "_step": 496}
{"Episode reward": -74.3020886071887, "Episode length": 999, "Policy Loss": 0.004255032166838646, "Value Loss": 0.0013155137421563268, "_runtime": 14060.451025724411, "_timestamp": 1585583976.295659, "_step": 497}
{"Episode reward": -71.92582874651046, "Episode length": 999, "Policy Loss": 0.005909126251935959, "Value Loss": 0.0015064021572470665, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737, -1.2622803449630737]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.46168598532676697, 0.5837241411209106, 0.7057623267173767, 0.8278005123138428, 0.9498386383056641, 1.071876883506775, 1.1939150094985962, 1.3159531354904175, 1.4379913806915283, 1.5600295066833496, 1.6820677518844604, 1.8041058778762817, 1.926144003868103, 2.048182249069214, 2.170220375061035, 2.2922585010528564, 2.4142966270446777, 2.536334753036499, 2.6583728790283203, 2.7804112434387207, 2.902449369430542, 3.0244874954223633, 3.1465256214141846, 3.268563747406006, 3.390601873397827, 3.5126402378082275, 3.634678363800049, 3.75671648979187, 3.8787546157836914, 4.000792980194092, 4.122831344604492, 4.244869232177734, 4.366907596588135, 4.488945960998535, 4.610983848571777, 4.733022212982178, 4.85506010055542, 4.97709846496582, 5.099136829376221, 5.221174716949463, 5.343213081359863, 5.4652509689331055, 5.587289333343506, 5.709327697753906, 5.831365585327148, 5.953403949737549, 6.075441837310791, 6.197480201721191, 6.319518089294434, 6.441556453704834, 6.563594818115234, 6.685632705688477, 6.807671070098877, 6.929708957672119, 7.0517473220825195, 7.17378568649292, 7.295823574066162, 7.4178619384765625, 7.539899826049805, 7.661938190460205, 7.7839765548706055, 7.906014442443848, 8.02805233001709, 8.150090217590332, 8.27212905883789]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.6144461035728455, -0.5951629281044006, -0.575879693031311, -0.5565965175628662, -0.5373133420944214, -0.5180301666259766, -0.49874693155288696, -0.47946375608444214, -0.4601805806159973, -0.4408973753452301, -0.4216141700744629, -0.40233099460601807, -0.38304778933525085, -0.36376461386680603, -0.3444814085960388, -0.325198233127594, -0.3059150278568268, -0.28663182258605957, -0.26734864711761475, -0.24806544184684753, -0.2287822663784027, -0.2094990611076355, -0.19021588563919067, -0.17093268036842346, -0.15164947509765625, -0.13236629962921143, -0.1130831241607666, -0.093799889087677, -0.07451671361923218, -0.055233538150787354, -0.03595036268234253, -0.01666712760925293, 0.0026160478591918945, 0.02189922332763672, 0.04118245840072632, 0.06046563386917114, 0.07974880933761597, 0.09903198480606079, 0.11831521987915039, 0.13759839534759521, 0.15688157081604004, 0.17616480588912964, 0.19544798135757446, 0.2147311568260193, 0.2340143322944641, 0.2532975673675537, 0.27258074283599854, 0.29186391830444336, 0.31114715337753296, 0.3304303288459778, 0.3497135043144226, 0.36899667978286743, 0.38827985525131226, 0.4075630307197571, 0.42684632539749146, 0.4461295008659363, 0.4654126763343811, 0.4846958518028259, 0.5039790272712708, 0.5232622027397156, 0.5425453782081604, 0.5618286728858948, 0.5811118483543396, 0.6003950238227844, 0.6196781992912292]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 6.0, 2.0, 2.0, 5.0, 0.0, 1.0, 4.0, 8.0, 7.0, 6.0, 11.0, 13.0, 11.0, 5.0, 18.0, 28.0, 24.0, 31.0, 36.0, 37.0, 40.0, 28.0, 18.0, 20.0, 16.0, 14.0, 11.0, 13.0, 8.0, 9.0, 5.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 6.0, 3.0, 3.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.5019303560256958, -0.48698320984840393, -0.47203606367111206, -0.4570889174938202, -0.4421417713165283, -0.42719462513923645, -0.4122474789619446, -0.3973003327846527, -0.38235318660736084, -0.36740607023239136, -0.3524588942527771, -0.3375117778778076, -0.32256460189819336, -0.3076174855232239, -0.2926703095436096, -0.27772319316864014, -0.2627760171890259, -0.2478289008140564, -0.23288175463676453, -0.21793460845947266, -0.2029874622821808, -0.18804031610488892, -0.17309316992759705, -0.15814602375030518, -0.1431988775730133, -0.12825173139572144, -0.11330458521842957, -0.0983574390411377, -0.08341029286384583, -0.06846314668655396, -0.053516000509262085, -0.038568854331970215, -0.023621708154678345, -0.008674561977386475, 0.006272554397583008, 0.021219730377197266, 0.03616684675216675, 0.051114022731781006, 0.06606113910675049, 0.08100831508636475, 0.09595543146133423, 0.11090260744094849, 0.12584972381591797, 0.14079689979553223, 0.1557440161705017, 0.17069119215011597, 0.18563830852508545, 0.2005854845046997, 0.2155326008796692, 0.23047977685928345, 0.24542689323425293, 0.2603740692138672, 0.27532118558883667, 0.2902683615684509, 0.3052154779434204, 0.32016265392303467, 0.33510977029800415, 0.3500569462776184, 0.3650040626525879, 0.37995123863220215, 0.39489835500717163, 0.4098455309867859, 0.42479264736175537, 0.43973982334136963, 0.4546869397163391]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.8883768320083618, -1.8368359804153442, -1.785295009613037, -1.7337541580200195, -1.6822131872177124, -1.6306723356246948, -1.5791313648223877, -1.5275905132293701, -1.4760496616363525, -1.4245086908340454, -1.3729677200317383, -1.3214268684387207, -1.2698860168457031, -1.2183451652526855, -1.1668041944503784, -1.1152632236480713, -1.0637223720550537, -1.0121815204620361, -0.960640549659729, -0.9090996384620667, -0.8575587272644043, -0.8060178756713867, -0.7544769048690796, -0.702936053276062, -0.6513952016830444, -0.5998542308807373, -0.5483133792877197, -0.4967724084854126, -0.445231556892395, -0.3936905860900879, -0.3421497344970703, -0.2906087636947632, -0.2390679121017456, -0.18752706050872803, -0.1359860897064209, -0.08444523811340332, -0.03290426731109619, 0.018636584281921387, 0.07017755508422852, 0.12171852588653564, 0.17325937747955322, 0.2248002290725708, 0.2763410806655884, 0.32788193225860596, 0.37942302227020264, 0.4309638738632202, 0.4825047254562378, 0.5340455770492554, 0.585586428642273, 0.6371275186538696, 0.6886683702468872, 0.7402092218399048, 0.7917500734329224, 0.843291163444519, 0.8948320150375366, 0.9463728666305542, 0.9979137182235718, 1.0494545698165894, 1.100995659828186, 1.1525365114212036, 1.2040773630142212, 1.2556182146072388, 1.3071593046188354, 1.358700156211853, 1.4102410078048706]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 4.0, 6.0, 3.0, 3.0, 5.0, 1.0, 1.0, 1.0, 1.0, 2.0, 6.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], "bins": [-1.0326868295669556, -1.007367730140686, -0.9820486903190613, -0.9567296504974365, -0.9314106106758118, -0.9060915112495422, -0.8807724714279175, -0.855453372001648, -0.8301343321800232, -0.8048152923583984, -0.7794961929321289, -0.7541771531105042, -0.7288581132888794, -0.7035390138626099, -0.6782199740409851, -0.6529009342193604, -0.6275818347930908, -0.6022627949714661, -0.5769437551498413, -0.5516246557235718, -0.526305615901947, -0.5009865760803223, -0.47566747665405273, -0.450348436832428, -0.4250293970108032, -0.3997102975845337, -0.37439125776290894, -0.3490722179412842, -0.32375311851501465, -0.2984340786933899, -0.27311503887176514, -0.2477959394454956, -0.22247689962387085, -0.1971578598022461, -0.17183876037597656, -0.1465197205543518, -0.12120068073272705, -0.09588158130645752, -0.07056254148483276, -0.04524350166320801, -0.019924402236938477, 0.005394697189331055, 0.030713677406311035, 0.056032776832580566, 0.0813518762588501, 0.10667085647583008, 0.1319899559020996, 0.15730905532836914, 0.18262803554534912, 0.20794713497161865, 0.23326623439788818, 0.25858521461486816, 0.2839043140411377, 0.3092234134674072, 0.3345423936843872, 0.35986149311065674, 0.38518059253692627, 0.41049957275390625, 0.4358186721801758, 0.4611377716064453, 0.4864567518234253, 0.5117758512496948, 0.5370949506759644, 0.5624139308929443, 0.5877330303192139]}, "_runtime": 14062.049268960953, "_timestamp": 1585583977.8939023, "_step": 498}
{"Episode reward": -72.00289529026826, "Episode length": 999, "Policy Loss": -0.0013828949304297566, "Value Loss": 0.0013638794189319015, "_runtime": 14062.049268960953, "_timestamp": 1585583977.8939023, "_step": 499}
