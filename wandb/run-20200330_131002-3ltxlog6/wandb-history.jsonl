{"Episode reward": -57.792611746552915, "Episode length": 999, "Policy Loss": -0.023978503420948982, "Value Loss": 0.014634029008448124, "_runtime": 3905.8701498508453, "_timestamp": 1585573821.7147832, "_step": 0}
{"Episode reward": 11.2406309662029, "Episode length": 979, "Policy Loss": -4.003046989440918, "Value Loss": 140.78074645996094, "_runtime": 3907.187885761261, "_timestamp": 1585573823.032519, "_step": 1}
{"Episode reward": 12.574737957986756, "Episode length": 880, "Policy Loss": -13.15917682647705, "Value Loss": 592.9059448242188, "_runtime": 3908.764986038208, "_timestamp": 1585573824.6096194, "_step": 2}
{"Episode reward": -99.70093967618747, "Episode length": 999, "Policy Loss": 45.485008239746094, "Value Loss": 23216.26171875, "_runtime": 3909.4403965473175, "_timestamp": 1585573825.28503, "_step": 3}
{"Episode reward": 58.31763775852029, "Episode length": 418, "Policy Loss": 23.820520401000977, "Value Loss": 253.32894897460938, "_runtime": 3910.96884226799, "_timestamp": 1585573826.8134756, "_step": 4}
{"Episode reward": -99.53620140863477, "Episode length": 999, "Policy Loss": -0.7419081330299377, "Value Loss": 0.760930061340332, "_runtime": 3912.557742357254, "_timestamp": 1585573828.4023757, "_step": 5}
{"Episode reward": -99.62290974774413, "Episode length": 999, "Policy Loss": 5.674068927764893, "Value Loss": 9.96629810333252, "_runtime": 3914.073947906494, "_timestamp": 1585573829.9185812, "_step": 6}
{"Episode reward": -99.76725688971395, "Episode length": 999, "Policy Loss": 4.700918674468994, "Value Loss": 5.634109973907471, "_runtime": 3915.6240091323853, "_timestamp": 1585573831.4686425, "_step": 7}
{"Episode reward": -99.86208164985301, "Episode length": 999, "Policy Loss": 4.883975028991699, "Value Loss": 2.2784626483917236, "_runtime": 3917.191892147064, "_timestamp": 1585573833.0365255, "_step": 8}
{"Episode reward": -99.26567133078194, "Episode length": 999, "Policy Loss": 5.278412818908691, "Value Loss": 8.222311019897461, "_runtime": 3918.753313779831, "_timestamp": 1585573834.5979471, "_step": 9}
{"Episode reward": -99.35031884882574, "Episode length": 999, "Policy Loss": 8.271541595458984, "Value Loss": 17.627731323242188, "_runtime": 3920.322641849518, "_timestamp": 1585573836.1672752, "_step": 10}
{"Episode reward": -98.3508577793986, "Episode length": 999, "Policy Loss": 7.094113826751709, "Value Loss": 9.14137077331543, "_runtime": 3921.917035341263, "_timestamp": 1585573837.7616687, "_step": 11}
{"Episode reward": -98.8008724162549, "Episode length": 999, "Policy Loss": 9.398448944091797, "Value Loss": 18.136646270751953, "_runtime": 3923.51966547966, "_timestamp": 1585573839.3642988, "_step": 12}
{"Episode reward": -98.3972225483368, "Episode length": 999, "Policy Loss": 8.564536094665527, "Value Loss": 36.8046989440918, "_runtime": 3925.0836429595947, "_timestamp": 1585573840.9282763, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -33.03581619262695, "Value Loss": 3004.2470703125, "_runtime": 3926.664899587631, "_timestamp": 1585573842.509533, "_step": 14}
{"Episode reward": -98.91248050574136, "Episode length": 999, "Policy Loss": -4.850829601287842, "Value Loss": 13.397527694702148, "_runtime": 3928.235761642456, "_timestamp": 1585573844.080395, "_step": 15}
{"Episode reward": -99.52985077583027, "Episode length": 999, "Policy Loss": -4.115757942199707, "Value Loss": 8.278918266296387, "_runtime": 3929.800618648529, "_timestamp": 1585573845.645252, "_step": 16}
{"Episode reward": -99.49783004242127, "Episode length": 999, "Policy Loss": -5.369149684906006, "Value Loss": 43.44837188720703, "_runtime": 3931.380590200424, "_timestamp": 1585573847.2252235, "_step": 17}
{"Episode reward": -99.60973131551224, "Episode length": 999, "Policy Loss": -9.805011749267578, "Value Loss": 302.5949401855469, "_runtime": 3932.9564831256866, "_timestamp": 1585573848.8011165, "_step": 18}
{"Episode reward": -99.7635976796767, "Episode length": 999, "Policy Loss": -9.131638526916504, "Value Loss": 626.2874145507812, "_runtime": 3934.5227377414703, "_timestamp": 1585573850.367371, "_step": 19}
{"Episode reward": -99.76842982955635, "Episode length": 999, "Policy Loss": -5.443274021148682, "Value Loss": 177.36952209472656, "_runtime": 3936.1038296222687, "_timestamp": 1585573851.948463, "_step": 20}
{"Episode reward": -99.79115369973502, "Episode length": 999, "Policy Loss": -5.523963451385498, "Value Loss": 122.02997589111328, "_runtime": 3937.6810500621796, "_timestamp": 1585573853.5256834, "_step": 21}
{"Episode reward": -99.7015682173056, "Episode length": 999, "Policy Loss": -2.7793493270874023, "Value Loss": 65.47457885742188, "_runtime": 3939.258062362671, "_timestamp": 1585573855.1026957, "_step": 22}
{"Episode reward": -99.86040261024469, "Episode length": 999, "Policy Loss": -1.6891069412231445, "Value Loss": 42.45820617675781, "_runtime": 3940.837653398514, "_timestamp": 1585573856.6822867, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4535219967365265, "Value Loss": 37.72403335571289, "_runtime": 3942.4198200702667, "_timestamp": 1585573858.2644534, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43918460607528687, "Value Loss": 47.39503860473633, "_runtime": 3943.9997510910034, "_timestamp": 1585573859.8443844, "_step": 25}
{"Episode reward": -99.82883553653815, "Episode length": 999, "Policy Loss": -1.9445537328720093, "Value Loss": 72.30996704101562, "_runtime": 3945.5769305229187, "_timestamp": 1585573861.4215639, "_step": 26}
{"Episode reward": -99.7021044419686, "Episode length": 999, "Policy Loss": -0.4726504385471344, "Value Loss": 63.96636199951172, "_runtime": 3947.1944694519043, "_timestamp": 1585573863.0391028, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9901372790336609, "Value Loss": 31.04409408569336, "_runtime": 3948.7782418727875, "_timestamp": 1585573864.6228752, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02216300182044506, "Value Loss": 50.053890228271484, "_runtime": 3950.356678724289, "_timestamp": 1585573866.201312, "_step": 29}
{"Episode reward": -99.80691294453837, "Episode length": 999, "Policy Loss": -1.8487646579742432, "Value Loss": 52.48466491699219, "_runtime": 3951.934880256653, "_timestamp": 1585573867.7795136, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.913247585296631, "Value Loss": 97.00457000732422, "_runtime": 3953.5068032741547, "_timestamp": 1585573869.3514366, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3882335424423218, "Value Loss": 55.365657806396484, "_runtime": 3955.0893063545227, "_timestamp": 1585573870.9339397, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7001911997795105, "Value Loss": 24.374284744262695, "_runtime": 3956.670616865158, "_timestamp": 1585573872.5152502, "_step": 33}
{"Episode reward": -99.8361290216432, "Episode length": 999, "Policy Loss": 3.3311750888824463, "Value Loss": 52.86201477050781, "_runtime": 3958.240042924881, "_timestamp": 1585573874.0846763, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.581845998764038, "Value Loss": 36.59962463378906, "_runtime": 3959.82027387619, "_timestamp": 1585573875.6649072, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22872516512870789, "Value Loss": 24.859418869018555, "_runtime": 3961.409860610962, "_timestamp": 1585573877.254494, "_step": 36}
{"Episode reward": -99.88989462238247, "Episode length": 999, "Policy Loss": -0.1625431925058365, "Value Loss": 39.288570404052734, "_runtime": 3962.9920313358307, "_timestamp": 1585573878.8366647, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2963978052139282, "Value Loss": 72.2672119140625, "_runtime": 3964.5849874019623, "_timestamp": 1585573880.4296207, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5797158479690552, "Value Loss": 25.249465942382812, "_runtime": 3966.165918111801, "_timestamp": 1585573882.0105515, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1042940616607666, "Value Loss": 77.10311889648438, "_runtime": 3967.7470767498016, "_timestamp": 1585573883.59171, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3346511125564575, "Value Loss": 49.189998626708984, "_runtime": 3969.363497018814, "_timestamp": 1585573885.2081304, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.507533550262451, "Value Loss": 17.623720169067383, "_runtime": 3970.9523503780365, "_timestamp": 1585573886.7969837, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.791986465454102, "Value Loss": 35.361419677734375, "_runtime": 3972.534567594528, "_timestamp": 1585573888.379201, "_step": 43}
{"Episode reward": -99.86596139591317, "Episode length": 999, "Policy Loss": -5.260279178619385, "Value Loss": 58.954498291015625, "_runtime": 3974.125144004822, "_timestamp": 1585573889.9697773, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.13292121887207, "Value Loss": 96.9848861694336, "_runtime": 3975.704984664917, "_timestamp": 1585573891.549618, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.994315147399902, "Value Loss": 100.92218780517578, "_runtime": 3977.273264169693, "_timestamp": 1585573893.1178975, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -28.782451629638672, "Value Loss": 80.02790832519531, "_runtime": 3978.855241537094, "_timestamp": 1585573894.6998749, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.354632377624512, "Value Loss": 30.116472244262695, "_runtime": 3980.4337890148163, "_timestamp": 1585573896.2784224, "_step": 48}
{"Episode reward": -99.81706399917462, "Episode length": 999, "Policy Loss": -8.239616394042969, "Value Loss": 24.7738037109375, "_runtime": 3982.005763530731, "_timestamp": 1585573897.8503969, "_step": 49}
{"Episode reward": -99.84803241230408, "Episode length": 999, "Policy Loss": -15.168465614318848, "Value Loss": 33.77461242675781, "_runtime": 3983.585709810257, "_timestamp": 1585573899.4303432, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -41.558658599853516, "Value Loss": 110.4931869506836, "_runtime": 3985.1516897678375, "_timestamp": 1585573900.996323, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.708725452423096, "Value Loss": 5.0227556228637695, "_runtime": 3986.726044178009, "_timestamp": 1585573902.5706775, "_step": 52}
{"Episode reward": -99.83090889363554, "Episode length": 999, "Policy Loss": -10.908072471618652, "Value Loss": 15.538071632385254, "_runtime": 3988.3018498420715, "_timestamp": 1585573904.1464832, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.48867130279541, "Value Loss": 11.023439407348633, "_runtime": 3989.8796033859253, "_timestamp": 1585573905.7242367, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.066226959228516, "Value Loss": 3.410426378250122, "_runtime": 3991.455418586731, "_timestamp": 1585573907.300052, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.3583269119262695, "Value Loss": 5.701326370239258, "_runtime": 3993.0653829574585, "_timestamp": 1585573908.9100163, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.301605701446533, "Value Loss": 2.3502230644226074, "_runtime": 3994.6475117206573, "_timestamp": 1585573910.492145, "_step": 57}
{"Episode reward": -99.7558448808211, "Episode length": 999, "Policy Loss": -4.46433687210083, "Value Loss": 2.0484421253204346, "_runtime": 3996.2176299095154, "_timestamp": 1585573912.0622633, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.107120037078857, "Value Loss": 2.5799942016601562, "_runtime": 3996.6441497802734, "_timestamp": 1585573912.4887831, "_step": 59}
{"Episode reward": 76.39999999999995, "Episode length": 236, "Policy Loss": -1.096600890159607, "Value Loss": 42.19388198852539, "_runtime": 3998.208187818527, "_timestamp": 1585573914.0528212, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.828336238861084, "Value Loss": 0.6618717312812805, "_runtime": 3999.7768919467926, "_timestamp": 1585573915.6215253, "_step": 61}
{"Episode reward": 0.6000000000013728, "Episode length": 994, "Policy Loss": -3.696939706802368, "Value Loss": 10.649272918701172, "_runtime": 4001.2734570503235, "_timestamp": 1585573917.1180904, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.670294761657715, "Value Loss": 0.8043259978294373, "_runtime": 4002.8522601127625, "_timestamp": 1585573918.6968935, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.828094482421875, "Value Loss": 0.3385903239250183, "_runtime": 4004.172090291977, "_timestamp": 1585573920.0167236, "_step": 64}
{"Episode reward": 16.600000000000463, "Episode length": 834, "Policy Loss": -3.3076796531677246, "Value Loss": 12.526883125305176, "_runtime": 4005.7463009357452, "_timestamp": 1585573921.5909343, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.706125259399414, "Value Loss": 0.3638365864753723, "_runtime": 4007.340781211853, "_timestamp": 1585573923.1854146, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.7469482421875, "Value Loss": 0.23780575394630432, "_runtime": 4008.9123747348785, "_timestamp": 1585573924.757008, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.675258159637451, "Value Loss": 0.2499537318944931, "_runtime": 4010.1590909957886, "_timestamp": 1585573926.0037243, "_step": 68}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": -3.3273489475250244, "Value Loss": 12.8521728515625, "_runtime": 4011.733924150467, "_timestamp": 1585573927.5785575, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.644847869873047, "Value Loss": 0.20838890969753265, "_runtime": 4012.5157754421234, "_timestamp": 1585573928.3604088, "_step": 70}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": -2.3657426834106445, "Value Loss": 21.06382942199707, "_runtime": 4013.5346806049347, "_timestamp": 1585573929.379314, "_step": 71}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": -2.8460140228271484, "Value Loss": 15.495962142944336, "_runtime": 4015.125287771225, "_timestamp": 1585573930.969921, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.476984024047852, "Value Loss": 0.1952541321516037, "_runtime": 4016.688719511032, "_timestamp": 1585573932.5333529, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.345061779022217, "Value Loss": 0.1829296499490738, "_runtime": 4017.5684111118317, "_timestamp": 1585573933.4130445, "_step": 74}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": -2.446918487548828, "Value Loss": 17.835824966430664, "_runtime": 4019.1564588546753, "_timestamp": 1585573935.0010922, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.315729141235352, "Value Loss": 0.28187891840934753, "_runtime": 4020.7387788295746, "_timestamp": 1585573936.5834122, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.145632743835449, "Value Loss": 0.193942591547966, "_runtime": 4022.280294895172, "_timestamp": 1585573938.1249282, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.030533790588379, "Value Loss": 0.20547813177108765, "_runtime": 4023.83154630661, "_timestamp": 1585573939.6761796, "_step": 78}
{"Episode reward": 2.1000000000012875, "Episode length": 979, "Policy Loss": -3.0626022815704346, "Value Loss": 10.443431854248047, "_runtime": 4024.628409385681, "_timestamp": 1585573940.4730427, "_step": 79}
{"Episode reward": 51.39999999999959, "Episode length": 486, "Policy Loss": -2.016828775405884, "Value Loss": 20.68485450744629, "_runtime": 4026.2033591270447, "_timestamp": 1585573942.0479925, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.839118719100952, "Value Loss": 0.20894066989421844, "_runtime": 4027.0803225040436, "_timestamp": 1585573942.9249558, "_step": 81}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": -2.003270149230957, "Value Loss": 18.55424690246582, "_runtime": 4028.269634246826, "_timestamp": 1585573944.1142676, "_step": 82}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": -2.452199697494507, "Value Loss": 13.384202003479004, "_runtime": 4028.8738701343536, "_timestamp": 1585573944.7185035, "_step": 83}
{"Episode reward": 63.899999999999764, "Episode length": 361, "Policy Loss": -0.6291844248771667, "Value Loss": 27.619199752807617, "_runtime": 4029.839123725891, "_timestamp": 1585573945.683757, "_step": 84}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": -2.2034175395965576, "Value Loss": 16.16721534729004, "_runtime": 4031.1784479618073, "_timestamp": 1585573947.0230813, "_step": 85}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": -2.491117000579834, "Value Loss": 11.794898986816406, "_runtime": 4032.689982175827, "_timestamp": 1585573948.5346155, "_step": 86}
{"Episode reward": -99.81808741092541, "Episode length": 999, "Policy Loss": -3.641650915145874, "Value Loss": 0.7331143021583557, "_runtime": 4033.5202572345734, "_timestamp": 1585573949.3648906, "_step": 87}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": -1.5246285200119019, "Value Loss": 19.461654663085938, "_runtime": 4034.388683795929, "_timestamp": 1585573950.2333171, "_step": 88}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": -1.7459217309951782, "Value Loss": 18.682754516601562, "_runtime": 4035.93328666687, "_timestamp": 1585573951.77792, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2162630558013916, "Value Loss": 0.282116562128067, "_runtime": 4037.4633078575134, "_timestamp": 1585573953.3079412, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.094900608062744, "Value Loss": 0.2509640157222748, "_runtime": 4038.9920284748077, "_timestamp": 1585573954.8366618, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0100033283233643, "Value Loss": 0.14854981005191803, "_runtime": 4040.603238105774, "_timestamp": 1585573956.4478714, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.064542531967163, "Value Loss": 0.3738081455230713, "_runtime": 4041.446991920471, "_timestamp": 1585573957.2916253, "_step": 93}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": -1.0011241436004639, "Value Loss": 18.725936889648438, "_runtime": 4043.016499042511, "_timestamp": 1585573958.8611324, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7793047428131104, "Value Loss": 0.1254257708787918, "_runtime": 4044.5853176116943, "_timestamp": 1585573960.429951, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8040430545806885, "Value Loss": 0.1465083360671997, "_runtime": 4046.118868112564, "_timestamp": 1585573961.9635015, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6289477348327637, "Value Loss": 0.0906151831150055, "_runtime": 4047.6803138256073, "_timestamp": 1585573963.5249472, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6429717540740967, "Value Loss": 0.14133353531360626, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452, 0.0017301887273788452]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.415274053812027, -0.39837926626205444, -0.3814844787120819, -0.3645896911621094, -0.34769490361213684, -0.3308001160621643, -0.31390535831451416, -0.29701054096221924, -0.2801157832145691, -0.26322096586227417, -0.24632619321346283, -0.2294314056634903, -0.21253663301467896, -0.19564184546470642, -0.1787470579147339, -0.16185227036476135, -0.14495748281478882, -0.12806269526481628, -0.11116790771484375, -0.09427312016487122, -0.07737833261489868, -0.06048354506492615, -0.04358875751495361, -0.02669396996498108, -0.009799212217330933, 0.0070955753326416016, 0.023990362882614136, 0.04088515043258667, 0.057779937982559204, 0.07467472553253174, 0.09156951308250427, 0.1084643304347992, 0.12535908818244934, 0.1422538459300995, 0.1591486632823944, 0.17604342103004456, 0.19293823838233948, 0.20983299612998962, 0.22672781348228455, 0.2436225712299347, 0.2605173885822296, 0.27741214632987976, 0.2943069636821747, 0.31120172142982483, 0.32809653878211975, 0.3449912965297699, 0.3618861138820648, 0.37878087162971497, 0.3956756293773651, 0.41257044672966003, 0.4294652044773102, 0.4463600218296051, 0.46325477957725525, 0.48014959692955017, 0.4970443546772003, 0.5139391422271729, 0.5308339595794678, 0.5477287769317627, 0.5646234750747681, 0.581518292427063, 0.5984131097793579, 0.6153079271316528, 0.6322027444839478, 0.6490974426269531, 0.665992259979248]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0009200147469528019, -0.0006975664291530848, -0.0004751180822495371, -0.00025266973534598947, -3.0221417546272278e-05, 0.0001922269002534449, 0.000414675276260823, 0.0006371235358528793, 0.0008595719118602574, 0.0010820203460752964, 0.0013044686056673527, 0.001526916865259409, 0.0017493653576821089, 0.001971813617274165, 0.0021942618768662214, 0.0024167103692889214, 0.0026391586288809776, 0.002861606888473034, 0.003084055380895734, 0.00330650364048779, 0.0035289519000798464, 0.0037514001596719027, 0.003973848186433315, 0.004196296911686659, 0.004418745171278715, 0.004641193430870771, 0.004863641690462828, 0.005086089950054884, 0.00530853820964694, 0.005530986934900284, 0.00575343519449234, 0.005975883454084396, 0.006198331713676453, 0.006420779973268509, 0.006643228232860565, 0.0068656764924526215, 0.007088125217705965, 0.007310573477298021, 0.007533021736890078, 0.007755469996482134, 0.007977918721735477, 0.008200366981327534, 0.00842281524091959, 0.008645263500511646, 0.008867711760103703, 0.009090160951018333, 0.00931260921061039, 0.009535057470202446, 0.009757505729794502, 0.009979953989386559, 0.010202402248978615, 0.010424850508570671, 0.010647298768162727, 0.010869747027754784, 0.01109219528734684, 0.011314643546938896, 0.011537091806530952, 0.011759540066123009, 0.01198198925703764, 0.012204437516629696, 0.012426885776221752, 0.012649334035813808, 0.012871782295405865, 0.013094230554997921, 0.013316678814589977]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 6.0, 10.0, 2.0, 8.0, 5.0, 44.0, 85.0, 103.0, 105.0, 6.0, 0.0, 0.0, 1.0, 3.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 7.0, 6.0, 6.0, 8.0, 2.0, 11.0, 5.0, 7.0, 3.0, 5.0, 2.0, 10.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.03121778555214405, -0.02777749113738537, -0.024337196722626686, -0.020896902307868004, -0.01745660789310932, -0.01401631347835064, -0.010576019063591957, -0.007135724648833275, -0.0036954302340745926, -0.00025513581931591034, 0.003185158595442772, 0.006625453010201454, 0.010065747424960136, 0.013506041839718819, 0.0169463362544775, 0.020386630669236183, 0.023826925083994865, 0.027267219498753548, 0.03070751391351223, 0.03414781391620636, 0.037588104605674744, 0.04102839529514313, 0.04446869343519211, 0.04790899157524109, 0.05134928226470947, 0.054789572954177856, 0.05822987109422684, 0.06167016923427582, 0.0651104599237442, 0.06855075061321259, 0.07199104875326157, 0.07543134689331055, 0.07887163758277893, 0.08231192827224731, 0.0857522264122963, 0.08919252455234528, 0.09263281524181366, 0.09607310593128204, 0.09951341152191162, 0.10295370221138, 0.10639399290084839, 0.10983428359031677, 0.11327457427978516, 0.11671487987041473, 0.12015517055988312, 0.1235954612493515, 0.12703576683998108, 0.13047605752944946, 0.13391634821891785, 0.13735663890838623, 0.14079692959785461, 0.1442372351884842, 0.14767752587795258, 0.15111781656742096, 0.15455812215805054, 0.15799841284751892, 0.1614387035369873, 0.1648789942264557, 0.16831928491592407, 0.17175959050655365, 0.17519988119602203, 0.17864017188549042, 0.18208047747612, 0.18552076816558838, 0.18896105885505676]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2635270655155182, -0.2529119849205017, -0.24229691922664642, -0.23168185353279114, -0.22106678783893585, -0.21045172214508057, -0.1998366415500641, -0.1892215758562088, -0.17860651016235352, -0.16799142956733704, -0.15737636387348175, -0.14676129817962646, -0.13614621758460999, -0.1255311518907547, -0.11491608619689941, -0.10430100560188293, -0.09368593990802765, -0.08307087421417236, -0.07245579361915588, -0.0618407279253006, -0.05122566223144531, -0.04061058163642883, -0.029995515942573547, -0.01938045024871826, -0.008765369653701782, 0.0018496811389923096, 0.012464761734008789, 0.02307984232902527, 0.03369489312171936, 0.04430997371673584, 0.05492505431175232, 0.06554010510444641, 0.07615518569946289, 0.08677026629447937, 0.09738531708717346, 0.10800039768218994, 0.11861547827720642, 0.1292305290699005, 0.139845609664917, 0.15046069025993347, 0.16107574105262756, 0.17169082164764404, 0.18230590224266052, 0.19292095303535461, 0.2035360336303711, 0.21415111422538757, 0.22476616501808167, 0.23538124561309814, 0.24599632620811462, 0.2566113770008087, 0.2672264277935028, 0.2778415381908417, 0.28845658898353577, 0.29907163977622986, 0.3096867501735687, 0.3203018009662628, 0.3309168517589569, 0.3415319621562958, 0.35214701294898987, 0.36276206374168396, 0.3733771741390228, 0.3839922249317169, 0.394607275724411, 0.4052223861217499, 0.41583743691444397]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 4.0, 14.0, 4.0, 5.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.4293050765991211, -0.4198431372642517, -0.4103811979293823, -0.40091925859451294, -0.39145731925964355, -0.3819953501224518, -0.3725334107875824, -0.363071471452713, -0.35360953211784363, -0.34414759278297424, -0.33468565344810486, -0.3252236843109131, -0.3157617449760437, -0.3062998056411743, -0.29683786630630493, -0.28737592697143555, -0.27791398763656616, -0.2684520483016968, -0.2589901089668274, -0.24952815473079681, -0.24006621539592743, -0.23060427606105804, -0.22114232182502747, -0.21168038249015808, -0.2022184431552887, -0.1927565038204193, -0.18329456448554993, -0.17383262515068054, -0.16437065601348877, -0.15490871667861938, -0.14544677734375, -0.13598483800888062, -0.12652289867401123, -0.11706095933914185, -0.10759902000427246, -0.09813708066940308, -0.08867514133453369, -0.07921317219734192, -0.06975123286247253, -0.06028929352760315, -0.050827354192733765, -0.04136541485786438, -0.031903475522994995, -0.02244153618812561, -0.012979567050933838, -0.003517627716064453, 0.005944311618804932, 0.015406250953674316, 0.0248681902885437, 0.034330129623413086, 0.04379206895828247, 0.053254008293151855, 0.06271594762802124, 0.07217788696289062, 0.08163982629776001, 0.0911017656326294, 0.10056376457214355, 0.11002570390701294, 0.11948764324188232, 0.1289495825767517, 0.1384115219116211, 0.14787346124649048, 0.15733540058135986, 0.16679733991622925, 0.17625927925109863]}, "_runtime": 4049.2420387268066, "_timestamp": 1585573965.086672, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.599349021911621, "Value Loss": 0.15931683778762817, "_runtime": 4050.813090324402, "_timestamp": 1585573966.6577237, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5036814212799072, "Value Loss": 0.13291673362255096, "_runtime": 4051.9397585392, "_timestamp": 1585573967.7843919, "_step": 100}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": -0.8333455920219421, "Value Loss": 14.118269920349121, "_runtime": 4053.1373040676117, "_timestamp": 1585573968.9819374, "_step": 101}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": -0.9843961596488953, "Value Loss": 13.099048614501953, "_runtime": 4053.6327378749847, "_timestamp": 1585573969.4773712, "_step": 102}
{"Episode reward": 71.19999999999987, "Episode length": 288, "Policy Loss": 1.2159395217895508, "Value Loss": 34.34932327270508, "_runtime": 4054.8994011878967, "_timestamp": 1585573970.7440345, "_step": 103}
{"Episode reward": 18.25845794677771, "Episode length": 818, "Policy Loss": -0.9736625552177429, "Value Loss": 12.193808555603027, "_runtime": 4056.447834253311, "_timestamp": 1585573972.2924676, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2032124996185303, "Value Loss": 0.09894856810569763, "_runtime": 4057.949620246887, "_timestamp": 1585573973.7942536, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.084606170654297, "Value Loss": 0.05096821486949921, "_runtime": 4059.5095586776733, "_timestamp": 1585573975.354192, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0565197467803955, "Value Loss": 0.07532443851232529, "_runtime": 4061.083813905716, "_timestamp": 1585573976.9284472, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0376839637756348, "Value Loss": 0.06439109146595001, "_runtime": 4062.6350479125977, "_timestamp": 1585573978.4796813, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9280369281768799, "Value Loss": 0.04118557274341583, "_runtime": 4064.2473526000977, "_timestamp": 1585573980.091986, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8848267793655396, "Value Loss": 0.044684816151857376, "_runtime": 4065.8293211460114, "_timestamp": 1585573981.6739545, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8732329607009888, "Value Loss": 0.06589985638856888, "_runtime": 4066.7083642482758, "_timestamp": 1585573982.5529976, "_step": 111}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": 0.14424456655979156, "Value Loss": 18.129758834838867, "_runtime": 4068.275883436203, "_timestamp": 1585573984.1205168, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7254037857055664, "Value Loss": 0.03778380528092384, "_runtime": 4069.3334727287292, "_timestamp": 1585573985.178106, "_step": 113}
{"Episode reward": 33.5999999999995, "Episode length": 664, "Policy Loss": 0.08339187502861023, "Value Loss": 14.996001243591309, "_runtime": 4070.8869602680206, "_timestamp": 1585573986.7315936, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6260911226272583, "Value Loss": 0.025947265326976776, "_runtime": 4072.4658126831055, "_timestamp": 1585573988.310446, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6498929262161255, "Value Loss": 0.0464680939912796, "_runtime": 4073.3819677829742, "_timestamp": 1585573989.2266011, "_step": 116}
{"Episode reward": 41.79999999999945, "Episode length": 582, "Policy Loss": 0.20404450595378876, "Value Loss": 17.093597412109375, "_runtime": 4074.9609265327454, "_timestamp": 1585573990.8055599, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5175690650939941, "Value Loss": 0.03311074897646904, "_runtime": 4076.555840730667, "_timestamp": 1585573992.400474, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.474549412727356, "Value Loss": 0.030746376141905785, "_runtime": 4077.261219263077, "_timestamp": 1585573993.1058526, "_step": 119}
{"Episode reward": 54.899999999999636, "Episode length": 451, "Policy Loss": 0.9140083193778992, "Value Loss": 22.025053024291992, "_runtime": 4078.2790112495422, "_timestamp": 1585573994.1236446, "_step": 120}
{"Episode reward": 36.09999999999937, "Episode length": 639, "Policy Loss": 0.2688678205013275, "Value Loss": 15.570931434631348, "_runtime": 4079.548104286194, "_timestamp": 1585573995.3927376, "_step": 121}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": -0.09285122901201248, "Value Loss": 12.503265380859375, "_runtime": 4080.0426630973816, "_timestamp": 1585573995.8872964, "_step": 122}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 2.1378862857818604, "Value Loss": 31.6593074798584, "_runtime": 4081.5769271850586, "_timestamp": 1585573997.4215605, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3031011819839478, "Value Loss": 0.019017262384295464, "_runtime": 4083.1416535377502, "_timestamp": 1585573998.9862869, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3001213073730469, "Value Loss": 0.02342669852077961, "_runtime": 4084.65483546257, "_timestamp": 1585574000.4994688, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2896915674209595, "Value Loss": 0.02483562007546425, "_runtime": 4086.2292127609253, "_timestamp": 1585574002.073846, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2381010055541992, "Value Loss": 0.01604607328772545, "_runtime": 4087.818701982498, "_timestamp": 1585574003.6633353, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2184679508209229, "Value Loss": 0.015639150515198708, "_runtime": 4089.3798036575317, "_timestamp": 1585574005.224437, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2446930408477783, "Value Loss": 0.031175505369901657, "_runtime": 4090.999769449234, "_timestamp": 1585574006.8444028, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1905847787857056, "Value Loss": 0.025864647701382637, "_runtime": 4092.5880131721497, "_timestamp": 1585574008.4326465, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.151807188987732, "Value Loss": 0.02316572144627571, "_runtime": 4094.1566710472107, "_timestamp": 1585574010.0013044, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.156866431236267, "Value Loss": 0.028623351827263832, "_runtime": 4095.5957894325256, "_timestamp": 1585574011.4404228, "_step": 132}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": 0.051642656326293945, "Value Loss": 11.020984649658203, "_runtime": 4096.8055057525635, "_timestamp": 1585574012.650139, "_step": 133}
{"Episode reward": 23.47014615535744, "Episode length": 766, "Policy Loss": 0.2936735153198242, "Value Loss": 12.99772834777832, "_runtime": 4098.367008924484, "_timestamp": 1585574014.2116423, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0423411130905151, "Value Loss": 0.02121536247432232, "_runtime": 4099.953714132309, "_timestamp": 1585574015.7983475, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0501209497451782, "Value Loss": 0.030639462172985077, "_runtime": 4101.522700071335, "_timestamp": 1585574017.3673334, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9683976769447327, "Value Loss": 0.010166005231440067, "_runtime": 4103.094938993454, "_timestamp": 1585574018.9395723, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9637660384178162, "Value Loss": 0.012206447310745716, "_runtime": 4104.673845529556, "_timestamp": 1585574020.5184789, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9443766474723816, "Value Loss": 0.01680086925625801, "_runtime": 4106.257266521454, "_timestamp": 1585574022.1018999, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9026899933815002, "Value Loss": 0.01245962269604206, "_runtime": 4107.834923028946, "_timestamp": 1585574023.6795564, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8960250020027161, "Value Loss": 0.011872771196067333, "_runtime": 4108.6747970581055, "_timestamp": 1585574024.5194304, "_step": 141}
{"Episode reward": 48.399999999999544, "Episode length": 516, "Policy Loss": 1.1135177612304688, "Value Loss": 19.28462028503418, "_runtime": 4109.366020679474, "_timestamp": 1585574025.210654, "_step": 142}
{"Episode reward": 58.09999999999968, "Episode length": 419, "Policy Loss": 1.6262104511260986, "Value Loss": 23.723499298095703, "_runtime": 4110.952627897263, "_timestamp": 1585574026.7972612, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8208836317062378, "Value Loss": 0.013917756266891956, "_runtime": 4112.002270460129, "_timestamp": 1585574027.8469038, "_step": 144}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 1.0109291076660156, "Value Loss": 14.642569541931152, "_runtime": 4113.515989303589, "_timestamp": 1585574029.3606226, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.781799852848053, "Value Loss": 0.009708945639431477, "_runtime": 4115.138101816177, "_timestamp": 1585574030.9827352, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7843608856201172, "Value Loss": 0.013999713584780693, "_runtime": 4116.689567804337, "_timestamp": 1585574032.5342011, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7626648545265198, "Value Loss": 0.013008777983486652, "_runtime": 4118.257182836533, "_timestamp": 1585574034.1018162, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7709976434707642, "Value Loss": 0.018649639561772346, "_runtime": 4119.135653734207, "_timestamp": 1585574034.980287, "_step": 149}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 1.1889536380767822, "Value Loss": 18.53687286376953, "_runtime": 4120.7224152088165, "_timestamp": 1585574036.5670485, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7228441834449768, "Value Loss": 0.009845761582255363, "_runtime": 4121.898107051849, "_timestamp": 1585574037.7427404, "_step": 151}
{"Episode reward": 25.199999999999974, "Episode length": 748, "Policy Loss": 0.692908525466919, "Value Loss": 13.28915786743164, "_runtime": 4123.45455789566, "_timestamp": 1585574039.2991912, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7198909521102905, "Value Loss": 0.012855703011155128, "_runtime": 4125.047799348831, "_timestamp": 1585574040.8924327, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6945252418518066, "Value Loss": 0.007712977472692728, "_runtime": 4126.60928106308, "_timestamp": 1585574042.4539144, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6736563444137573, "Value Loss": 0.010959213599562645, "_runtime": 4127.8705496788025, "_timestamp": 1585574043.715183, "_step": 155}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.5850959420204163, "Value Loss": 12.50614070892334, "_runtime": 4128.680583953857, "_timestamp": 1585574044.5252173, "_step": 156}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 1.7028511762619019, "Value Loss": 19.6942138671875, "_runtime": 4130.267220020294, "_timestamp": 1585574046.1118534, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6556717157363892, "Value Loss": 0.006307033821940422, "_runtime": 4131.835458755493, "_timestamp": 1585574047.680092, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6866373419761658, "Value Loss": 0.017301516607403755, "_runtime": 4133.363362789154, "_timestamp": 1585574049.2079961, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.648430585861206, "Value Loss": 0.006186504848301411, "_runtime": 4134.764014005661, "_timestamp": 1585574050.6086473, "_step": 160}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 0.8939608931541443, "Value Loss": 11.274258613586426, "_runtime": 4136.34703707695, "_timestamp": 1585574052.1916704, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6245799660682678, "Value Loss": 0.006306745111942291, "_runtime": 4137.125376701355, "_timestamp": 1585574052.97001, "_step": 162}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 1.541237473487854, "Value Loss": 20.96175765991211, "_runtime": 4138.264847040176, "_timestamp": 1585574054.1094804, "_step": 163}
{"Episode reward": 30.043088889121705, "Episode length": 700, "Policy Loss": 1.0073009729385376, "Value Loss": 14.218900680541992, "_runtime": 4139.851729154587, "_timestamp": 1585574055.6963625, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.658477246761322, "Value Loss": 0.02096218802034855, "_runtime": 4140.359002828598, "_timestamp": 1585574056.2036362, "_step": 165}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 2.9199419021606445, "Value Loss": 31.66234588623047, "_runtime": 4141.222868442535, "_timestamp": 1585574057.0675018, "_step": 166}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 1.4229055643081665, "Value Loss": 18.032390594482422, "_runtime": 4142.481372594833, "_timestamp": 1585574058.326006, "_step": 167}
{"Episode reward": 20.50000000000024, "Episode length": 795, "Policy Loss": 0.6934777498245239, "Value Loss": 12.49669075012207, "_runtime": 4143.38960146904, "_timestamp": 1585574059.2342348, "_step": 168}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 0.9725990891456604, "Value Loss": 16.524702072143555, "_runtime": 4144.927399158478, "_timestamp": 1585574060.7720325, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7241814732551575, "Value Loss": 0.01721460558474064, "_runtime": 4145.942440748215, "_timestamp": 1585574061.787074, "_step": 170}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.8478003144264221, "Value Loss": 15.386713027954102, "_runtime": 4147.476075410843, "_timestamp": 1585574063.3207088, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7306731343269348, "Value Loss": 0.016745254397392273, "_runtime": 4149.043351888657, "_timestamp": 1585574064.8879852, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7772807478904724, "Value Loss": 0.03052463009953499, "_runtime": 4150.590096473694, "_timestamp": 1585574066.4347298, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7918154001235962, "Value Loss": 0.035922709852457047, "_runtime": 4151.710144281387, "_timestamp": 1585574067.5547776, "_step": 174}
{"Episode reward": 29.199999999999747, "Episode length": 708, "Policy Loss": 0.6482530832290649, "Value Loss": 14.040345191955566, "_runtime": 4153.293347120285, "_timestamp": 1585574069.1379805, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7639104127883911, "Value Loss": 0.023274481296539307, "_runtime": 4154.880034446716, "_timestamp": 1585574070.7246678, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7549160122871399, "Value Loss": 0.008023325353860855, "_runtime": 4155.39496421814, "_timestamp": 1585574071.2395976, "_step": 177}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 2.628328800201416, "Value Loss": 32.10260772705078, "_runtime": 4156.962157487869, "_timestamp": 1585574072.8067908, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7451068758964539, "Value Loss": 0.012867345474660397, "_runtime": 4157.943599224091, "_timestamp": 1585574073.7882326, "_step": 179}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": 0.8958714604377747, "Value Loss": 16.003652572631836, "_runtime": 4159.342707872391, "_timestamp": 1585574075.1873412, "_step": 180}
{"Episode reward": 7.900000000000958, "Episode length": 921, "Policy Loss": 0.34466907382011414, "Value Loss": 10.7709321975708, "_runtime": 4160.934477329254, "_timestamp": 1585574076.7791107, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8266450762748718, "Value Loss": 0.023877227678894997, "_runtime": 4162.36256814003, "_timestamp": 1585574078.2072015, "_step": 182}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": 0.6027430891990662, "Value Loss": 11.06078052520752, "_runtime": 4163.931385755539, "_timestamp": 1585574079.776019, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.826698362827301, "Value Loss": 0.016650957986712456, "_runtime": 4165.526484251022, "_timestamp": 1585574081.3711176, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8533291220664978, "Value Loss": 0.034089311957359314, "_runtime": 4166.206334352493, "_timestamp": 1585574082.0509677, "_step": 185}
{"Episode reward": 58.399999999999686, "Episode length": 416, "Policy Loss": 2.019360303878784, "Value Loss": 23.833253860473633, "_runtime": 4167.776001214981, "_timestamp": 1585574083.6206346, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8291538953781128, "Value Loss": 0.023702144622802734, "_runtime": 4169.371814727783, "_timestamp": 1585574085.216448, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8571298718452454, "Value Loss": 0.034585095942020416, "_runtime": 4170.73432803154, "_timestamp": 1585574086.5789614, "_step": 188}
{"Episode reward": 10.700000000000799, "Episode length": 893, "Policy Loss": 0.44806045293807983, "Value Loss": 11.111993789672852, "_runtime": 4172.310411691666, "_timestamp": 1585574088.155045, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.815571129322052, "Value Loss": 0.013780763372778893, "_runtime": 4173.223339557648, "_timestamp": 1585574089.067973, "_step": 190}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 1.0723214149475098, "Value Loss": 17.583614349365234, "_runtime": 4174.774239778519, "_timestamp": 1585574090.6188731, "_step": 191}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.23106835782527924, "Value Loss": 9.997281074523926, "_runtime": 4176.3654243946075, "_timestamp": 1585574092.2100577, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8250516057014465, "Value Loss": 0.013068550266325474, "_runtime": 4177.283206701279, "_timestamp": 1585574093.12784, "_step": 193}
{"Episode reward": 41.499999999999446, "Episode length": 585, "Policy Loss": 1.1728161573410034, "Value Loss": 16.95110321044922, "_runtime": 4178.853919267654, "_timestamp": 1585574094.6985526, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8909385800361633, "Value Loss": 0.04297006130218506, "_runtime": 4180.441438436508, "_timestamp": 1585574096.2860718, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8474922776222229, "Value Loss": 0.020312106236815453, "_runtime": 4181.199549436569, "_timestamp": 1585574097.0441828, "_step": 196}
{"Episode reward": 52.2999999999996, "Episode length": 477, "Policy Loss": 1.2998201847076416, "Value Loss": 20.81157684326172, "_runtime": 4182.773036003113, "_timestamp": 1585574098.6176693, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8356568217277527, "Value Loss": 0.022069182246923447, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034, 0.0003517348668538034]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.030896823853254318, -0.026652922853827477, -0.022409021854400635, -0.018165122717618942, -0.0139212217181921, -0.009677320718765259, -0.005433421581983566, -0.0011895205825567245, 0.003054380416870117, 0.00729827955365181, 0.0115421824157238, 0.015786081552505493, 0.020029980689287186, 0.024273883551359177, 0.02851778268814087, 0.03276168182492256, 0.03700558468699455, 0.041249487549066544, 0.04549338296055794, 0.04973728582262993, 0.05398118868470192, 0.058225084096193314, 0.062468986958265305, 0.066712886095047, 0.07095678150653839, 0.07520069181919098, 0.07944458723068237, 0.08368849754333496, 0.08793239295482635, 0.09217628836631775, 0.09642018377780914, 0.10066409409046173, 0.10490798950195312, 0.10915188491344452, 0.1133957952260971, 0.1176396906375885, 0.1218835860490799, 0.12612749636173248, 0.13037139177322388, 0.13461528718471527, 0.13885919749736786, 0.14310309290885925, 0.14734698832035065, 0.15159089863300323, 0.15583479404449463, 0.16007868945598602, 0.1643225997686386, 0.16856649518013, 0.1728103905916214, 0.177054300904274, 0.18129819631576538, 0.18554210662841797, 0.18978600203990936, 0.19402989745140076, 0.19827380776405334, 0.20251770317554474, 0.20676159858703613, 0.21100550889968872, 0.21524940431118011, 0.2194933146238327, 0.2237371951341629, 0.2279811054468155, 0.23222501575946808, 0.23646889626979828, 0.24071280658245087]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.000745293335057795, -0.0006706436397507787, -0.0005959939444437623, -0.0005213442491367459, -0.00044669455382972956, -0.0003720448585227132, -0.0002973951632156968, -0.00022274546790868044, -0.00014809577260166407, -7.34460772946477e-05, 1.203618012368679e-06, 7.585331331938505e-05, 0.00015050300862640142, 0.0002251527039334178, 0.00029980239924043417, 0.00037445209454745054, 0.0004491017898544669, 0.0005237514851614833, 0.0005984011804684997, 0.000673050875775516, 0.0007477005710825324, 0.0008223502663895488, 0.0008969999616965652, 0.0009716496570035815, 0.001046299352310598, 0.0011209490476176143, 0.0011955987429246306, 0.001270248438231647, 0.0013448981335386634, 0.0014195478288456798, 0.0014941975241526961, 0.0015688472194597125, 0.0016434969147667289, 0.0017181466100737453, 0.0017927963053807616, 0.001867446000687778, 0.0019420956959947944, 0.0020167455077171326, 0.002091395203024149, 0.0021660448983311653, 0.0022406945936381817, 0.002315344288945198, 0.0023899939842522144, 0.002464643679559231, 0.002539293374866247, 0.0026139430701732635, 0.00268859276548028, 0.0027632424607872963, 0.0028378921560943127, 0.002912541851401329, 0.0029871915467083454, 0.003061841242015362, 0.003136490937322378, 0.0032111406326293945, 0.003285790327936411, 0.0033604400232434273, 0.0034350897185504436, 0.00350973941385746, 0.0035843891091644764, 0.0036590388044714928, 0.003733688499778509, 0.0038083381950855255, 0.003882987890392542, 0.003957637585699558, 0.004032287281006575]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 7.0, 15.0, 9.0, 16.0, 3.0, 47.0, 46.0, 81.0, 116.0, 16.0, 10.0, 20.0, 18.0, 19.0, 10.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 4.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.00555389141663909, -0.0049552577547729015, -0.004356623627245426, -0.003757989965379238, -0.00315935630351305, -0.002560722641646862, -0.0019620887469500303, -0.0013634548522531986, -0.0007648211903870106, -0.00016618752852082253, 0.0004324461333453655, 0.0010310802608728409, 0.001629713922739029, 0.002228347584605217, 0.0028269817121326923, 0.0034256153739988804, 0.0040242490358650684, 0.0046228826977312565, 0.0052215163595974445, 0.005820150021463633, 0.006418783683329821, 0.007017418276518583, 0.007616051938384771, 0.008214686065912247, 0.008813319727778435, 0.009411953389644623, 0.01001058705151081, 0.010609220713376999, 0.011207854375243187, 0.011806488037109375, 0.012405121698975563, 0.013003755360841751, 0.01360238902270794, 0.014201022684574127, 0.014799656346440315, 0.015398290008306503, 0.01599692367017269, 0.01659555733203888, 0.017194190993905067, 0.017792824655771255, 0.018391458317637444, 0.01899009384214878, 0.01958872750401497, 0.020187361165881157, 0.020785994827747345, 0.021384628489613533, 0.02198326215147972, 0.02258189581334591, 0.023180529475212097, 0.023779163137078285, 0.024377796798944473, 0.02497643046081066, 0.02557506412267685, 0.026173697784543037, 0.026772333309054375, 0.027370965108275414, 0.02796960063278675, 0.02856823243200779, 0.029166867956519127, 0.029765499755740166, 0.030364135280251503, 0.030962767079472542, 0.03156140446662903, 0.03216003626585007, 0.032758671790361404]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07229961454868317, -0.0674622431397438, -0.06262487918138504, -0.05778750777244568, -0.05295013636350632, -0.048112768679857254, -0.04327540099620819, -0.03843802958726883, -0.033600661903619766, -0.028763294219970703, -0.02392592281103134, -0.01908855512738228, -0.014251187443733215, -0.009413816034793854, -0.004576444625854492, 0.00026091933250427246, 0.005098290741443634, 0.009935662150382996, 0.01477302610874176, 0.019610397517681122, 0.024447768926620483, 0.029285132884979248, 0.03412250429391861, 0.03895987570285797, 0.043797239661216736, 0.0486346110701561, 0.05347198247909546, 0.058309346437454224, 0.06314672529697418, 0.06798408925533295, 0.07282145321369171, 0.07765883207321167, 0.08249619603157043, 0.0873335599899292, 0.09217093884944916, 0.09700830280780792, 0.10184566676616669, 0.10668304562568665, 0.11152040958404541, 0.11635777354240417, 0.12119515240192413, 0.1260325163602829, 0.13086988031864166, 0.13570725917816162, 0.14054462313652039, 0.14538198709487915, 0.1502193659543991, 0.15505672991275787, 0.15989409387111664, 0.1647314727306366, 0.16956883668899536, 0.17440621554851532, 0.17924357950687408, 0.18408094346523285, 0.1889183074235916, 0.19375567138195038, 0.19859306514263153, 0.2034304291009903, 0.20826779305934906, 0.21310515701770782, 0.2179425209760666, 0.22277988493442535, 0.2276172786951065, 0.23245464265346527, 0.23729200661182404]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 11.0, 4.0, 7.0, 2.0, 4.0, 3.0, 1.0, 7.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.05985656753182411, -0.05860261991620064, -0.057348672300577164, -0.05609472468495369, -0.054840780794620514, -0.05358683317899704, -0.052332885563373566, -0.05107893794775009, -0.04982499033212662, -0.04857104271650314, -0.04731709510087967, -0.046063147485256195, -0.04480919986963272, -0.04355525225400925, -0.04230130836367607, -0.0410473607480526, -0.03979341313242912, -0.03853946551680565, -0.037285517901182175, -0.036031574010849, -0.034777626395225525, -0.03352367877960205, -0.03226973116397858, -0.031015783548355103, -0.02976183593273163, -0.028507888317108154, -0.02725394070148468, -0.025999993085861206, -0.02474604919552803, -0.023492101579904556, -0.022238153964281082, -0.020984206348657608, -0.019730258733034134, -0.01847631111741066, -0.017222363501787186, -0.01596841588616371, -0.014714468270540237, -0.013460524380207062, -0.012206576764583588, -0.010952629148960114, -0.00969868153333664, -0.008444733917713165, -0.007190786302089691, -0.005936838686466217, -0.004682894796133041, -0.0034289471805095673, -0.002174999564886093, -0.000921051949262619, 0.0003328956663608551, 0.0015868432819843292, 0.0028407908976078033, 0.0040947385132312775, 0.005348686128854752, 0.006602633744478226, 0.0078565813601017, 0.009110528975725174, 0.010364469140768051, 0.011618416756391525, 0.012872364372015, 0.014126311987638474, 0.015380259603261948, 0.016634207218885422, 0.017888154834508896, 0.01914210245013237, 0.020396050065755844]}, "_runtime": 4184.3641901016235, "_timestamp": 1585574100.2088234, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8052560091018677, "Value Loss": 0.014593423344194889, "_runtime": 4185.135049104691, "_timestamp": 1585574100.9796824, "_step": 199}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 1.3821690082550049, "Value Loss": 20.385169982910156, "_runtime": 4186.747408628464, "_timestamp": 1585574102.592042, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8817318081855774, "Value Loss": 0.05148354917764664, "_runtime": 4188.315039396286, "_timestamp": 1585574104.1596727, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8442956209182739, "Value Loss": 0.044732898473739624, "_runtime": 4189.851188659668, "_timestamp": 1585574105.695822, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8046071529388428, "Value Loss": 0.016206417232751846, "_runtime": 4191.434070587158, "_timestamp": 1585574107.278704, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7893145680427551, "Value Loss": 0.02304529957473278, "_runtime": 4193.016410112381, "_timestamp": 1585574108.8610435, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8238936066627502, "Value Loss": 0.040560897439718246, "_runtime": 4193.6761882305145, "_timestamp": 1585574109.5208216, "_step": 205}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.7740978002548218, "Value Loss": 24.641565322875977, "_runtime": 4195.256559848785, "_timestamp": 1585574111.1011932, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7974702715873718, "Value Loss": 0.044498857110738754, "_runtime": 4196.84601688385, "_timestamp": 1585574112.6906502, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7708739042282104, "Value Loss": 0.013146961107850075, "_runtime": 4198.373094797134, "_timestamp": 1585574114.2177281, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7648523449897766, "Value Loss": 0.01615888625383377, "_runtime": 4198.688002824783, "_timestamp": 1585574114.5326362, "_step": 209}
{"Episode reward": 84.20000000000005, "Episode length": 158, "Policy Loss": 5.729711532592773, "Value Loss": 62.78899383544922, "_runtime": 4200.270256996155, "_timestamp": 1585574116.1148903, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8009956479072571, "Value Loss": 0.020468702539801598, "_runtime": 4201.817980051041, "_timestamp": 1585574117.6626134, "_step": 211}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": 0.2799474000930786, "Value Loss": 10.067755699157715, "_runtime": 4203.326100587845, "_timestamp": 1585574119.170734, "_step": 212}
{"Episode reward": -99.86257057189802, "Episode length": 999, "Policy Loss": -0.8184223175048828, "Value Loss": 0.04319789260625839, "_runtime": 4204.521452903748, "_timestamp": 1585574120.3660862, "_step": 213}
{"Episode reward": 25.199999999999974, "Episode length": 748, "Policy Loss": 0.5503769516944885, "Value Loss": 13.27103042602539, "_runtime": 4205.159821033478, "_timestamp": 1585574121.0044544, "_step": 214}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.981278419494629, "Value Loss": 25.73944091796875, "_runtime": 4206.712125778198, "_timestamp": 1585574122.556759, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8688971996307373, "Value Loss": 0.04601970314979553, "_runtime": 4208.281524658203, "_timestamp": 1585574124.126158, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8580247163772583, "Value Loss": 0.02590140886604786, "_runtime": 4209.466002941132, "_timestamp": 1585574125.3106363, "_step": 217}
{"Episode reward": 22.200000000000145, "Episode length": 778, "Policy Loss": 0.4866791069507599, "Value Loss": 12.71865463256836, "_runtime": 4211.070962190628, "_timestamp": 1585574126.9155955, "_step": 218}
{"Episode reward": -99.80004615783552, "Episode length": 999, "Policy Loss": -0.8288471102714539, "Value Loss": 0.017467359080910683, "_runtime": 4212.544242620468, "_timestamp": 1585574128.388876, "_step": 219}
{"Episode reward": 7.100000000001003, "Episode length": 929, "Policy Loss": 0.24393431842327118, "Value Loss": 10.681269645690918, "_runtime": 4214.097366333008, "_timestamp": 1585574129.9419997, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.868085503578186, "Value Loss": 0.030368804931640625, "_runtime": 4215.663583993912, "_timestamp": 1585574131.5082173, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8861317038536072, "Value Loss": 0.04086378589272499, "_runtime": 4217.245244503021, "_timestamp": 1585574133.0898778, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8303548693656921, "Value Loss": 0.02728382684290409, "_runtime": 4218.821290016174, "_timestamp": 1585574134.6659234, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8721990585327148, "Value Loss": 0.0353010930120945, "_runtime": 4220.404264211655, "_timestamp": 1585574136.2488976, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8112431168556213, "Value Loss": 0.029687272384762764, "_runtime": 4221.323174953461, "_timestamp": 1585574137.1678083, "_step": 225}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 1.0577386617660522, "Value Loss": 17.527599334716797, "_runtime": 4222.588001012802, "_timestamp": 1585574138.4326344, "_step": 226}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.4975526034832001, "Value Loss": 12.465749740600586, "_runtime": 4224.16336107254, "_timestamp": 1585574140.0079944, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8000149726867676, "Value Loss": 0.02807566337287426, "_runtime": 4225.701950311661, "_timestamp": 1585574141.5465837, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8146465420722961, "Value Loss": 0.01714870147407055, "_runtime": 4227.271287441254, "_timestamp": 1585574143.1159208, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8265976905822754, "Value Loss": 0.03111550770699978, "_runtime": 4228.077944278717, "_timestamp": 1585574143.9225776, "_step": 230}
{"Episode reward": 50.599999999999575, "Episode length": 494, "Policy Loss": 1.2404160499572754, "Value Loss": 20.033035278320312, "_runtime": 4229.067193508148, "_timestamp": 1585574144.9118268, "_step": 231}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": 1.0185661315917969, "Value Loss": 15.96216869354248, "_runtime": 4230.645337104797, "_timestamp": 1585574146.4899704, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.773030698299408, "Value Loss": 0.0315367616713047, "_runtime": 4232.183105707169, "_timestamp": 1585574148.027739, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7662685513496399, "Value Loss": 0.013890145346522331, "_runtime": 4233.773920297623, "_timestamp": 1585574149.6185536, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7688060998916626, "Value Loss": 0.011484058573842049, "_runtime": 4235.35489320755, "_timestamp": 1585574151.1995265, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7713006138801575, "Value Loss": 0.015597045421600342, "_runtime": 4236.382036685944, "_timestamp": 1585574152.22667, "_step": 236}
{"Episode reward": 35.69999999999938, "Episode length": 643, "Policy Loss": 0.8202843070030212, "Value Loss": 15.457282066345215, "_runtime": 4237.95480132103, "_timestamp": 1585574153.7994347, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7673043608665466, "Value Loss": 0.01437829714268446, "_runtime": 4238.667667627335, "_timestamp": 1585574154.512301, "_step": 238}
{"Episode reward": 57.19999999999967, "Episode length": 428, "Policy Loss": 1.5563359260559082, "Value Loss": 23.14697265625, "_runtime": 4239.171901702881, "_timestamp": 1585574155.016535, "_step": 239}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 2.6726903915405273, "Value Loss": 33.21260070800781, "_runtime": 4240.744751691818, "_timestamp": 1585574156.589385, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7800775170326233, "Value Loss": 0.02361038327217102, "_runtime": 4241.369994163513, "_timestamp": 1585574157.2146275, "_step": 241}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.7941350936889648, "Value Loss": 24.979509353637695, "_runtime": 4242.8859877586365, "_timestamp": 1585574158.730621, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7862314581871033, "Value Loss": 0.01983090303838253, "_runtime": 4244.245633363724, "_timestamp": 1585574160.0902667, "_step": 243}
{"Episode reward": 14.000000000000611, "Episode length": 860, "Policy Loss": 0.38274502754211426, "Value Loss": 11.50035572052002, "_runtime": 4245.773245096207, "_timestamp": 1585574161.6178784, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8187443614006042, "Value Loss": 0.060863740742206573, "_runtime": 4246.782770395279, "_timestamp": 1585574162.6274037, "_step": 245}
{"Episode reward": 36.29999999999937, "Episode length": 637, "Policy Loss": 0.9167475700378418, "Value Loss": 15.561076164245605, "_runtime": 4248.339150667191, "_timestamp": 1585574164.183784, "_step": 246}
{"Episode reward": -99.80232830643514, "Episode length": 999, "Policy Loss": -0.8056510090827942, "Value Loss": 0.01919620670378208, "_runtime": 4249.918357849121, "_timestamp": 1585574165.7629912, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8237557411193848, "Value Loss": 0.022543184459209442, "_runtime": 4251.098068475723, "_timestamp": 1585574166.9427018, "_step": 248}
{"Episode reward": 24.100000000000037, "Episode length": 759, "Policy Loss": 0.6699408292770386, "Value Loss": 13.092225074768066, "_runtime": 4252.602165460587, "_timestamp": 1585574168.4467988, "_step": 249}
{"Episode reward": 4.600000000001145, "Episode length": 954, "Policy Loss": 0.2939265966415405, "Value Loss": 10.392080307006836, "_runtime": 4254.185201406479, "_timestamp": 1585574170.0298347, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8223298788070679, "Value Loss": 0.03288082405924797, "_runtime": 4255.7438905239105, "_timestamp": 1585574171.5885239, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8294746279716492, "Value Loss": 0.018674155697226524, "_runtime": 4256.727049589157, "_timestamp": 1585574172.571683, "_step": 252}
{"Episode reward": 38.1999999999994, "Episode length": 618, "Policy Loss": 1.157352328300476, "Value Loss": 16.032119750976562, "_runtime": 4258.350963354111, "_timestamp": 1585574174.1955967, "_step": 253}
{"Episode reward": -99.8583194732652, "Episode length": 999, "Policy Loss": -0.8983890414237976, "Value Loss": 0.08673326671123505, "_runtime": 4259.617527723312, "_timestamp": 1585574175.462161, "_step": 254}
{"Episode reward": 19.900000000000276, "Episode length": 801, "Policy Loss": 0.4320202171802521, "Value Loss": 12.350188255310059, "_runtime": 4261.170641422272, "_timestamp": 1585574177.0152748, "_step": 255}
{"Episode reward": -99.8062499999986, "Episode length": 999, "Policy Loss": -0.8907759189605713, "Value Loss": 0.05402939021587372, "_runtime": 4262.624202489853, "_timestamp": 1585574178.4688358, "_step": 256}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": 0.42254719138145447, "Value Loss": 10.872908592224121, "_runtime": 4264.188248872757, "_timestamp": 1585574180.0328822, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8261128067970276, "Value Loss": 0.015836266800761223, "_runtime": 4265.682286500931, "_timestamp": 1585574181.5269198, "_step": 258}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.23868796229362488, "Value Loss": 10.535135269165039, "_runtime": 4266.493103027344, "_timestamp": 1585574182.3377364, "_step": 259}
{"Episode reward": 49.99999999999957, "Episode length": 500, "Policy Loss": 1.1438778638839722, "Value Loss": 19.840003967285156, "_runtime": 4268.079241037369, "_timestamp": 1585574183.9238744, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8775411248207092, "Value Loss": 0.06183042377233505, "_runtime": 4269.654979705811, "_timestamp": 1585574185.499613, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8398192524909973, "Value Loss": 0.029449965804815292, "_runtime": 4271.197119951248, "_timestamp": 1585574187.0417533, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8656332492828369, "Value Loss": 0.041734591126441956, "_runtime": 4272.247631788254, "_timestamp": 1585574188.0922651, "_step": 263}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 0.9532448053359985, "Value Loss": 15.192052841186523, "_runtime": 4273.82589840889, "_timestamp": 1585574189.6705317, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8139009475708008, "Value Loss": 0.037437696009874344, "_runtime": 4275.399209022522, "_timestamp": 1585574191.2438424, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7970209121704102, "Value Loss": 0.019006257876753807, "_runtime": 4276.956920385361, "_timestamp": 1585574192.8015537, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7759230136871338, "Value Loss": 0.018081028014421463, "_runtime": 4277.732457637787, "_timestamp": 1585574193.577091, "_step": 267}
{"Episode reward": 52.699999999999605, "Episode length": 473, "Policy Loss": 1.4013080596923828, "Value Loss": 20.943035125732422, "_runtime": 4279.306811571121, "_timestamp": 1585574195.151445, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7777771353721619, "Value Loss": 0.01470274105668068, "_runtime": 4279.9488530159, "_timestamp": 1585574195.7934864, "_step": 269}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 1.8749263286590576, "Value Loss": 25.65363311767578, "_runtime": 4281.13436460495, "_timestamp": 1585574196.978998, "_step": 270}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.5705273747444153, "Value Loss": 13.016016006469727, "_runtime": 4282.75811958313, "_timestamp": 1585574198.602753, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7614001035690308, "Value Loss": 0.025039760395884514, "_runtime": 4283.508057117462, "_timestamp": 1585574199.3526905, "_step": 272}
{"Episode reward": 51.09999999999958, "Episode length": 489, "Policy Loss": 1.3577767610549927, "Value Loss": 20.24224281311035, "_runtime": 4285.048296689987, "_timestamp": 1585574200.89293, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7935572862625122, "Value Loss": 0.043883826583623886, "_runtime": 4286.616599321365, "_timestamp": 1585574202.4612327, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7794655561447144, "Value Loss": 0.02716568112373352, "_runtime": 4288.138154029846, "_timestamp": 1585574203.9827874, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7933990359306335, "Value Loss": 0.026902327314019203, "_runtime": 4289.712035655975, "_timestamp": 1585574205.556669, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7850494384765625, "Value Loss": 0.01498408243060112, "_runtime": 4291.285870313644, "_timestamp": 1585574207.1305037, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7421974539756775, "Value Loss": 0.0233513992279768, "_runtime": 4291.899685144424, "_timestamp": 1585574207.7443185, "_step": 278}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 1.911108136177063, "Value Loss": 26.299474716186523, "_runtime": 4292.713589668274, "_timestamp": 1585574208.558223, "_step": 279}
{"Episode reward": 48.99999999999955, "Episode length": 510, "Policy Loss": 1.2230359315872192, "Value Loss": 19.372941970825195, "_runtime": 4294.2822279930115, "_timestamp": 1585574210.1268613, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.807629406452179, "Value Loss": 0.03091123327612877, "_runtime": 4295.616698980331, "_timestamp": 1585574211.4613323, "_step": 281}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 0.46972325444221497, "Value Loss": 11.23487663269043, "_runtime": 4297.139048337936, "_timestamp": 1585574212.9836817, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7775445580482483, "Value Loss": 0.021156517788767815, "_runtime": 4298.7107038497925, "_timestamp": 1585574214.5553372, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.781173825263977, "Value Loss": 0.011599849909543991, "_runtime": 4300.261995077133, "_timestamp": 1585574216.1066284, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7753155827522278, "Value Loss": 0.022808613255620003, "_runtime": 4301.836058616638, "_timestamp": 1585574217.680692, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7819194793701172, "Value Loss": 0.03732999786734581, "_runtime": 4302.907915830612, "_timestamp": 1585574218.7525492, "_step": 286}
{"Episode reward": 33.299999999999514, "Episode length": 667, "Policy Loss": 0.9125347137451172, "Value Loss": 14.882000923156738, "_runtime": 4304.48129940033, "_timestamp": 1585574220.3259327, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7581905722618103, "Value Loss": 0.0141523452475667, "_runtime": 4306.10661482811, "_timestamp": 1585574221.9512482, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7162933945655823, "Value Loss": 0.0216364748775959, "_runtime": 4307.458108186722, "_timestamp": 1585574223.3027415, "_step": 289}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 0.44450995326042175, "Value Loss": 11.418728828430176, "_runtime": 4308.659835100174, "_timestamp": 1585574224.5044684, "_step": 290}
{"Episode reward": 24.300000000000026, "Episode length": 757, "Policy Loss": 0.6892850995063782, "Value Loss": 13.09373664855957, "_runtime": 4310.23623585701, "_timestamp": 1585574226.0808692, "_step": 291}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.2549492120742798, "Value Loss": 9.962557792663574, "_runtime": 4311.811265707016, "_timestamp": 1585574227.655899, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7780845165252686, "Value Loss": 0.041026100516319275, "_runtime": 4313.015425682068, "_timestamp": 1585574228.860059, "_step": 293}
{"Episode reward": 23.400000000000077, "Episode length": 766, "Policy Loss": 0.7096790075302124, "Value Loss": 12.944070816040039, "_runtime": 4314.591970920563, "_timestamp": 1585574230.4366043, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7156584858894348, "Value Loss": 0.04990294575691223, "_runtime": 4315.7151045799255, "_timestamp": 1585574231.559738, "_step": 295}
{"Episode reward": 29.69999999999972, "Episode length": 703, "Policy Loss": 0.645811140537262, "Value Loss": 14.075973510742188, "_runtime": 4317.278292655945, "_timestamp": 1585574233.122926, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6807422041893005, "Value Loss": 0.022694207727909088, "_runtime": 4318.859671115875, "_timestamp": 1585574234.7043045, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7753846049308777, "Value Loss": 0.05208178609609604, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846, -0.0010832902044057846]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.54277503490448, -0.5324305295944214, -0.5220860242843628, -0.5117415189743042, -0.5013969540596008, -0.4910524785518646, -0.48070794343948364, -0.47036343812942505, -0.46001893281936646, -0.44967442750930786, -0.4393298923969269, -0.4289853870868683, -0.4186408519744873, -0.4082963466644287, -0.3979518413543701, -0.3876073360443115, -0.37726283073425293, -0.36691829562187195, -0.35657379031181335, -0.3462292551994324, -0.3358847498893738, -0.3255402445793152, -0.3151957392692566, -0.304851233959198, -0.294506698846817, -0.2841621935367584, -0.27381768822669983, -0.26347315311431885, -0.25312864780426025, -0.24278414249420166, -0.23243963718414307, -0.22209510207176208, -0.2117505967617035, -0.2014060914516449, -0.19106155633926392, -0.18071705102920532, -0.17037254571914673, -0.16002804040908813, -0.14968350529670715, -0.13933899998664856, -0.12899449467658997, -0.11864995956420898, -0.10830545425415039, -0.0979609489440918, -0.0876164436340332, -0.07727190852165222, -0.06692740321159363, -0.056582897901535034, -0.04623836278915405, -0.03589385747909546, -0.025549352169036865, -0.015204846858978271, -0.004860341548919678, 0.005484163761138916, 0.015828728675842285, 0.02617323398590088, 0.03651773929595947, 0.046862244606018066, 0.05720674991607666, 0.06755125522613525, 0.07789576053619385, 0.08824032545089722, 0.09858483076095581, 0.1089293360710144, 0.119273841381073]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.005963060073554516, -0.0058431136421859264, -0.005723167676478624, -0.005603221245110035, -0.005483275279402733, -0.0053633288480341434, -0.005243382416665554, -0.005123436450958252, -0.0050034900195896626, -0.0048835440538823605, -0.004763597622513771, -0.004643651656806469, -0.0045237052254378796, -0.00440375879406929, -0.004283812828361988, -0.004163866396993399, -0.004043920431286097, -0.003923973999917507, -0.0038040278013795614, -0.0036840816028416157, -0.00356413540430367, -0.003444189205765724, -0.0033242430072277784, -0.003204296575859189, -0.0030843503773212433, -0.0029644041787832975, -0.002844457980245352, -0.002724511781707406, -0.0026045655831694603, -0.002484619151800871, -0.002364672953262925, -0.0022447267547249794, -0.0021247805561870337, -0.002004834357649088, -0.0018848879262804985, -0.0017649419605731964, -0.001644995529204607, -0.001525049563497305, -0.0014051031321287155, -0.0012851567007601261, -0.001165210735052824, -0.0010452643036842346, -0.0009253183379769325, -0.0008053719066083431, -0.000685425940901041, -0.0005654795095324516, -0.00044553307816386223, -0.00032558711245656013, -0.00020564068108797073, -8.569471538066864e-05, 3.425171598792076e-05, 0.00015419768169522285, 0.00027414411306381226, 0.00039409054443240166, 0.0005140365101397038, 0.0006339829415082932, 0.0007539289072155952, 0.0008738753385841846, 0.000993821769952774, 0.0011137677356600761, 0.0012337141670286655, 0.0013536601327359676, 0.001473606564104557, 0.0015935525298118591, 0.0017134989611804485]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 2.0, 12.0, 9.0, 13.0, 2.0, 11.0, 6.0, 7.0, 10.0, 21.0, 17.0, 8.0, 20.0, 35.0, 40.0, 70.0, 63.0, 58.0, 30.0, 8.0, 9.0, 4.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0], "bins": [-0.06162805110216141, -0.06043771654367447, -0.05924737825989723, -0.058057043701410294, -0.056866709142923355, -0.05567637458443642, -0.05448603630065918, -0.05329570174217224, -0.0521053671836853, -0.050915032625198364, -0.04972469434142113, -0.04853435978293419, -0.04734402149915695, -0.04615368694067001, -0.044963352382183075, -0.043773017823696136, -0.0425826832652092, -0.04139234498143196, -0.04020201042294502, -0.039011672139167786, -0.03782133758068085, -0.03663100302219391, -0.03544066846370697, -0.03425033390522003, -0.033059995621442795, -0.031869661062955856, -0.03067932464182377, -0.02948898822069168, -0.028298653662204742, -0.027108319103717804, -0.025917984545230865, -0.02472764626145363, -0.02353731170296669, -0.02234697714447975, -0.021156638860702515, -0.019966304302215576, -0.018775969743728638, -0.0175856351852417, -0.016395296901464462, -0.015204962342977524, -0.014014627784490585, -0.012824289500713348, -0.01163395494222641, -0.010443620383739471, -0.009253285825252533, -0.008062947541475296, -0.0068726129829883575, -0.005682278424501419, -0.004491940140724182, -0.0033016055822372437, -0.002111271023750305, -0.0009209364652633667, 0.00026940181851387024, 0.0014597326517105103, 0.0026500746607780457, 0.003840409219264984, 0.005030743777751923, 0.006221078336238861, 0.0074114128947257996, 0.008601747453212738, 0.009792082011699677, 0.010982424020767212, 0.01217275857925415, 0.013363093137741089, 0.014553427696228027]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-0.22469554841518402, -0.21967962384223938, -0.21466368436813354, -0.2096477597951889, -0.20463183522224426, -0.19961589574813843, -0.1945999711751938, -0.18958404660224915, -0.1845681071281433, -0.17955218255519867, -0.17453625798225403, -0.1695203185081482, -0.16450439393520355, -0.1594884693622589, -0.15447252988815308, -0.14945660531520844, -0.1444406807422638, -0.13942474126815796, -0.13440881669521332, -0.12939289212226868, -0.12437695264816284, -0.1193610280752182, -0.11434509605169296, -0.10932916402816772, -0.10431323945522308, -0.09929729998111725, -0.09428137540817261, -0.08926545083522797, -0.08424951136112213, -0.07923358678817749, -0.07421766221523285, -0.06920172274112701, -0.06418579816818237, -0.05916987359523773, -0.0541539341211319, -0.049138009548187256, -0.044122084975242615, -0.03910614550113678, -0.03409022092819214, -0.029074296355247498, -0.024058356881141663, -0.01904243230819702, -0.01402650773525238, -0.009010568261146545, -0.003994643688201904, 0.0010212808847427368, 0.006037220358848572, 0.011053144931793213, 0.016069069504737854, 0.02108500897884369, 0.026100948452949524, 0.03111685812473297, 0.036132797598838806, 0.04114873707294464, 0.04616464674472809, 0.05118058621883392, 0.05619652569293976, 0.061212435364723206, 0.06622837483882904, 0.07124431431293488, 0.07626022398471832, 0.08127616345882416, 0.08629210293292999, 0.09130801260471344, 0.09632395207881927]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 6.0, 6.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.047212112694978714, -0.0453241802752018, -0.04343624785542488, -0.041548315435647964, -0.03966038301587105, -0.03777245059609413, -0.03588452190160751, -0.0339965894818306, -0.03210865706205368, -0.030220722779631615, -0.028332790359854698, -0.02644485794007778, -0.024556927382946014, -0.022668994963169098, -0.02078106254339218, -0.018893130123615265, -0.01700519770383835, -0.015117265284061432, -0.013229332864284515, -0.011341400444507599, -0.009453468024730682, -0.007565535604953766, -0.005677603185176849, -0.003789670765399933, -0.0019017420709133148, -1.3809651136398315e-05, 0.0018741227686405182, 0.0037620551884174347, 0.005649987608194351, 0.007537920027971268, 0.009425852447748184, 0.0113137848675251, 0.013201717287302017, 0.015089649707078934, 0.01697758212685585, 0.018865514546632767, 0.020753446966409683, 0.0226413793861866, 0.024529311805963516, 0.026417244225740433, 0.02830517664551735, 0.030193109065294266, 0.03208104148507118, 0.0339689739048481, 0.035856906324625015, 0.03774483874440193, 0.03963277116417885, 0.041520703583955765, 0.043408628553152084, 0.045296560972929, 0.04718449339270592, 0.049072425812482834, 0.05096035823225975, 0.05284829065203667, 0.05473622307181358, 0.0566241554915905, 0.058512087911367416, 0.06040002033114433, 0.06228795275092125, 0.06417588889598846, 0.06606382131576538, 0.0679517537355423, 0.06983968615531921, 0.07172761857509613, 0.07361555099487305]}, "_runtime": 4320.419068813324, "_timestamp": 1585574236.2637022, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7009916305541992, "Value Loss": 0.027714895084500313, "_runtime": 4321.933112859726, "_timestamp": 1585574237.7777462, "_step": 299}
{"Episode reward": 4.3000000000011624, "Episode length": 957, "Policy Loss": 0.35980868339538574, "Value Loss": 10.324803352355957, "_runtime": 4322.8223741054535, "_timestamp": 1585574238.6670074, "_step": 300}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 1.1840858459472656, "Value Loss": 17.956085205078125, "_runtime": 4323.433733701706, "_timestamp": 1585574239.278367, "_step": 301}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 2.0812227725982666, "Value Loss": 26.88551902770996, "_runtime": 4324.99643778801, "_timestamp": 1585574240.8410711, "_step": 302}
{"Episode reward": -99.89912302493909, "Episode length": 999, "Policy Loss": -0.729684591293335, "Value Loss": 0.032821204513311386, "_runtime": 4326.545192241669, "_timestamp": 1585574242.3898256, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7095254063606262, "Value Loss": 0.01698526181280613, "_runtime": 4327.596210241318, "_timestamp": 1585574243.4408436, "_step": 304}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.8014172315597534, "Value Loss": 14.445082664489746, "_runtime": 4328.64150929451, "_timestamp": 1585574244.4861426, "_step": 305}
{"Episode reward": 34.29999999999946, "Episode length": 657, "Policy Loss": 0.8013864159584045, "Value Loss": 15.084333419799805, "_runtime": 4330.2485246658325, "_timestamp": 1585574246.093158, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7672725915908813, "Value Loss": 0.03633513301610947, "_runtime": 4331.795784473419, "_timestamp": 1585574247.6404178, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7787840962409973, "Value Loss": 0.03770364075899124, "_runtime": 4332.517958402634, "_timestamp": 1585574248.3625917, "_step": 308}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 1.6689404249191284, "Value Loss": 21.916919708251953, "_runtime": 4333.524677038193, "_timestamp": 1585574249.3693104, "_step": 309}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 0.9903769493103027, "Value Loss": 15.722908973693848, "_runtime": 4335.099992275238, "_timestamp": 1585574250.9446256, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7641862630844116, "Value Loss": 0.02235875464975834, "_runtime": 4336.447588682175, "_timestamp": 1585574252.292222, "_step": 311}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": 0.38416630029678345, "Value Loss": 11.278851509094238, "_runtime": 4337.998402357101, "_timestamp": 1585574253.8430357, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7913975715637207, "Value Loss": 0.02235610969364643, "_runtime": 4338.743319034576, "_timestamp": 1585574254.5879524, "_step": 313}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 1.3993446826934814, "Value Loss": 21.598480224609375, "_runtime": 4340.016068696976, "_timestamp": 1585574255.860702, "_step": 314}
{"Episode reward": 18.60000000000035, "Episode length": 814, "Policy Loss": 0.4205552041530609, "Value Loss": 12.163179397583008, "_runtime": 4341.597595453262, "_timestamp": 1585574257.4422288, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8057066798210144, "Value Loss": 0.024321388453245163, "_runtime": 4343.133054971695, "_timestamp": 1585574258.9776883, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8122530579566956, "Value Loss": 0.029355892911553383, "_runtime": 4344.697563409805, "_timestamp": 1585574260.5421968, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8021210432052612, "Value Loss": 0.022331099957227707, "_runtime": 4345.8503675460815, "_timestamp": 1585574261.695001, "_step": 318}
{"Episode reward": 27.746427321433856, "Episode length": 723, "Policy Loss": 0.5674870014190674, "Value Loss": 13.68639087677002, "_runtime": 4347.415609836578, "_timestamp": 1585574263.2602432, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8142319321632385, "Value Loss": 0.03425174206495285, "_runtime": 4349.008599996567, "_timestamp": 1585574264.8532333, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.863754391670227, "Value Loss": 0.039761729538440704, "_runtime": 4350.574249744415, "_timestamp": 1585574266.418883, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7912375926971436, "Value Loss": 0.015886813402175903, "_runtime": 4352.160050153732, "_timestamp": 1585574268.0046835, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8017939925193787, "Value Loss": 0.027248887345194817, "_runtime": 4352.540011167526, "_timestamp": 1585574268.3846445, "_step": 323}
{"Episode reward": 78.89999999999998, "Episode length": 211, "Policy Loss": 3.9628868103027344, "Value Loss": 46.6655387878418, "_runtime": 4354.157428026199, "_timestamp": 1585574270.0020614, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8950295448303223, "Value Loss": 0.07511470466852188, "_runtime": 4355.733409881592, "_timestamp": 1585574271.5780432, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7849963903427124, "Value Loss": 0.046724554151296616, "_runtime": 4357.242509365082, "_timestamp": 1585574273.0871427, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8226028084754944, "Value Loss": 0.02603774704039097, "_runtime": 4358.094832897186, "_timestamp": 1585574273.9394662, "_step": 327}
{"Episode reward": 47.699999999999534, "Episode length": 523, "Policy Loss": 1.1866201162338257, "Value Loss": 18.864336013793945, "_runtime": 4359.6738040447235, "_timestamp": 1585574275.5184374, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8142144083976746, "Value Loss": 0.016663135960698128, "_runtime": 4360.635232448578, "_timestamp": 1585574276.4798658, "_step": 329}
{"Episode reward": 39.49999999999942, "Episode length": 605, "Policy Loss": 0.9006315469741821, "Value Loss": 16.299726486206055, "_runtime": 4361.264163732529, "_timestamp": 1585574277.108797, "_step": 330}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 1.8269857168197632, "Value Loss": 24.695707321166992, "_runtime": 4362.849621772766, "_timestamp": 1585574278.694255, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7912368178367615, "Value Loss": 0.056215379387140274, "_runtime": 4364.391680717468, "_timestamp": 1585574280.236314, "_step": 332}
{"Episode reward": -99.80364496707777, "Episode length": 999, "Policy Loss": -0.8908405303955078, "Value Loss": 0.041311293840408325, "_runtime": 4365.020478963852, "_timestamp": 1585574280.8651123, "_step": 333}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.8473538160324097, "Value Loss": 24.637351989746094, "_runtime": 4366.041818380356, "_timestamp": 1585574281.8864517, "_step": 334}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": 0.7850121855735779, "Value Loss": 15.670684814453125, "_runtime": 4367.601557254791, "_timestamp": 1585574283.4461906, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9068924784660339, "Value Loss": 0.08188159018754959, "_runtime": 4369.114706277847, "_timestamp": 1585574284.9593396, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8687249422073364, "Value Loss": 0.08486606925725937, "_runtime": 4370.655091762543, "_timestamp": 1585574286.499725, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.848659336566925, "Value Loss": 0.0503624863922596, "_runtime": 4372.215427875519, "_timestamp": 1585574288.0600612, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9365140199661255, "Value Loss": 0.06411907076835632, "_runtime": 4373.771710157394, "_timestamp": 1585574289.6163435, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8477869629859924, "Value Loss": 0.02574506215751171, "_runtime": 4375.347607851028, "_timestamp": 1585574291.1922412, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8546833992004395, "Value Loss": 0.09019910544157028, "_runtime": 4376.564848184586, "_timestamp": 1585574292.4094815, "_step": 341}
{"Episode reward": 24.999999999999986, "Episode length": 750, "Policy Loss": 0.584247887134552, "Value Loss": 13.197295188903809, "_runtime": 4377.498767614365, "_timestamp": 1585574293.343401, "_step": 342}
{"Episode reward": 40.799999999999436, "Episode length": 592, "Policy Loss": 0.883019745349884, "Value Loss": 16.64942741394043, "_runtime": 4379.0732316970825, "_timestamp": 1585574294.917865, "_step": 343}
{"Episode reward": -99.89517679214337, "Episode length": 999, "Policy Loss": -0.8011792302131653, "Value Loss": 0.03134310990571976, "_runtime": 4379.553694725037, "_timestamp": 1585574295.398328, "_step": 344}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 2.710096597671509, "Value Loss": 33.76812744140625, "_runtime": 4381.102970838547, "_timestamp": 1585574296.9476042, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8341703414916992, "Value Loss": 0.017014097422361374, "_runtime": 4382.675322294235, "_timestamp": 1585574298.5199556, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8476043343544006, "Value Loss": 0.03749218210577965, "_runtime": 4384.176495552063, "_timestamp": 1585574300.021129, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8765538930892944, "Value Loss": 0.07480807602405548, "_runtime": 4385.746769666672, "_timestamp": 1585574301.591403, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8722823262214661, "Value Loss": 0.07173854857683182, "_runtime": 4387.32882809639, "_timestamp": 1585574303.1734614, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8424146771430969, "Value Loss": 0.04411108046770096, "_runtime": 4388.525985956192, "_timestamp": 1585574304.3706193, "_step": 350}
{"Episode reward": 23.70000000000006, "Episode length": 763, "Policy Loss": 0.6020262837409973, "Value Loss": 12.927517890930176, "_runtime": 4390.102710485458, "_timestamp": 1585574305.9473438, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8156462907791138, "Value Loss": 0.05576247349381447, "_runtime": 4391.688935756683, "_timestamp": 1585574307.533569, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7762892842292786, "Value Loss": 0.06299980729818344, "_runtime": 4393.228687286377, "_timestamp": 1585574309.0733206, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8028866052627563, "Value Loss": 0.036606743931770325, "_runtime": 4394.813029527664, "_timestamp": 1585574310.6576629, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.737320065498352, "Value Loss": 0.04269678145647049, "_runtime": 4396.402564287186, "_timestamp": 1585574312.2471976, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7328907251358032, "Value Loss": 0.012727306224405766, "_runtime": 4397.457568883896, "_timestamp": 1585574313.3022022, "_step": 356}
{"Episode reward": 33.999999999999474, "Episode length": 660, "Policy Loss": 0.9146904349327087, "Value Loss": 14.969160079956055, "_runtime": 4399.0351486206055, "_timestamp": 1585574314.879782, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6831272840499878, "Value Loss": 0.018878841772675514, "_runtime": 4400.671651363373, "_timestamp": 1585574316.5162847, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6815040707588196, "Value Loss": 0.024018190801143646, "_runtime": 4402.027851343155, "_timestamp": 1585574317.8724847, "_step": 359}
{"Episode reward": 12.200000000000713, "Episode length": 878, "Policy Loss": 0.4562503397464752, "Value Loss": 11.254008293151855, "_runtime": 4403.233327865601, "_timestamp": 1585574319.0779612, "_step": 360}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": 0.6893061995506287, "Value Loss": 12.870676040649414, "_runtime": 4404.815492153168, "_timestamp": 1585574320.6601255, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.674441397190094, "Value Loss": 0.022051988169550896, "_runtime": 4406.125622749329, "_timestamp": 1585574321.970256, "_step": 362}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": 0.5823025107383728, "Value Loss": 11.751575469970703, "_runtime": 4407.674071311951, "_timestamp": 1585574323.5187047, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6113576292991638, "Value Loss": 0.013090327382087708, "_runtime": 4409.255235910416, "_timestamp": 1585574325.0998693, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6149489879608154, "Value Loss": 0.03543427214026451, "_runtime": 4410.80734205246, "_timestamp": 1585574326.6519754, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6244230270385742, "Value Loss": 0.038462571799755096, "_runtime": 4411.659918546677, "_timestamp": 1585574327.504552, "_step": 366}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 1.2719448804855347, "Value Loss": 18.4725284576416, "_runtime": 4413.24054813385, "_timestamp": 1585574329.0851815, "_step": 367}
{"Episode reward": -99.8016241312013, "Episode length": 999, "Policy Loss": -0.5740516781806946, "Value Loss": 0.016615083441138268, "_runtime": 4414.426844835281, "_timestamp": 1585574330.2714782, "_step": 368}
{"Episode reward": 24.100000000000037, "Episode length": 759, "Policy Loss": 0.7589012384414673, "Value Loss": 13.025935173034668, "_runtime": 4415.957722425461, "_timestamp": 1585574331.8023558, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.56364506483078, "Value Loss": 0.010164288803935051, "_runtime": 4416.454039335251, "_timestamp": 1585574332.2986727, "_step": 370}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 4.189995288848877, "Value Loss": 33.523563385009766, "_runtime": 4418.021619558334, "_timestamp": 1585574333.866253, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5788919925689697, "Value Loss": 0.0184771865606308, "_runtime": 4419.415439605713, "_timestamp": 1585574335.260073, "_step": 372}
{"Episode reward": 11.90000000000073, "Episode length": 881, "Policy Loss": 0.6065396070480347, "Value Loss": 11.227285385131836, "_runtime": 4420.933018445969, "_timestamp": 1585574336.7776518, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6280795931816101, "Value Loss": 0.03238213434815407, "_runtime": 4422.519973039627, "_timestamp": 1585574338.3646064, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6126806735992432, "Value Loss": 0.03633284568786621, "_runtime": 4423.435689687729, "_timestamp": 1585574339.280323, "_step": 375}
{"Episode reward": 42.69999999999946, "Episode length": 573, "Policy Loss": 1.1147570610046387, "Value Loss": 17.27128028869629, "_runtime": 4425.041618585587, "_timestamp": 1585574340.886252, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5998570919036865, "Value Loss": 0.024645255878567696, "_runtime": 4426.639960765839, "_timestamp": 1585574342.484594, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6820862293243408, "Value Loss": 0.046976346522569656, "_runtime": 4428.189237833023, "_timestamp": 1585574344.0338712, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6206871271133423, "Value Loss": 0.023122791200876236, "_runtime": 4429.776997566223, "_timestamp": 1585574345.621631, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6499923467636108, "Value Loss": 0.07777711004018784, "_runtime": 4430.677699565887, "_timestamp": 1585574346.522333, "_step": 380}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 1.3742671012878418, "Value Loss": 17.881811141967773, "_runtime": 4431.257471084595, "_timestamp": 1585574347.1021044, "_step": 381}
{"Episode reward": 65.29999999999978, "Episode length": 347, "Policy Loss": 2.3156518936157227, "Value Loss": 28.457805633544922, "_runtime": 4432.764156341553, "_timestamp": 1585574348.6087897, "_step": 382}
{"Episode reward": 3.544115614892263, "Episode length": 965, "Policy Loss": 0.413583368062973, "Value Loss": 10.243456840515137, "_runtime": 4434.313157320023, "_timestamp": 1585574350.1577907, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6339939832687378, "Value Loss": 0.035394687205553055, "_runtime": 4435.837739706039, "_timestamp": 1585574351.682373, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6810483932495117, "Value Loss": 0.022707903757691383, "_runtime": 4437.415090799332, "_timestamp": 1585574353.2597241, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6701419949531555, "Value Loss": 0.09258852899074554, "_runtime": 4438.481613636017, "_timestamp": 1585574354.326247, "_step": 386}
{"Episode reward": 33.19999999999952, "Episode length": 668, "Policy Loss": 0.8255630731582642, "Value Loss": 14.83033275604248, "_runtime": 4439.252848625183, "_timestamp": 1585574355.097482, "_step": 387}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 1.4363722801208496, "Value Loss": 20.642221450805664, "_runtime": 4440.824152231216, "_timestamp": 1585574356.6687856, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6680343151092529, "Value Loss": 0.06241380050778389, "_runtime": 4442.045742273331, "_timestamp": 1585574357.8903756, "_step": 389}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.6842279434204102, "Value Loss": 12.76142406463623, "_runtime": 4443.574665307999, "_timestamp": 1585574359.4192986, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7107563018798828, "Value Loss": 0.05015778914093971, "_runtime": 4444.986014127731, "_timestamp": 1585574360.8306475, "_step": 391}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.3924080431461334, "Value Loss": 11.021306991577148, "_runtime": 4446.549115419388, "_timestamp": 1585574362.3937488, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7479021549224854, "Value Loss": 0.020628640428185463, "_runtime": 4448.150517702103, "_timestamp": 1585574363.995151, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7298286557197571, "Value Loss": 0.016799839213490486, "_runtime": 4449.715526819229, "_timestamp": 1585574365.5601602, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7673205137252808, "Value Loss": 0.019886523485183716, "_runtime": 4451.307092905045, "_timestamp": 1585574367.1517262, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.757710874080658, "Value Loss": 0.02926238626241684, "_runtime": 4452.113402843475, "_timestamp": 1585574367.9580362, "_step": 396}
{"Episode reward": 50.37770574092822, "Episode length": 497, "Policy Loss": 1.3813668489456177, "Value Loss": 19.910842895507812, "_runtime": 4452.778857469559, "_timestamp": 1585574368.6234908, "_step": 397}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 2.0206661224365234, "Value Loss": 24.552961349487305, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848, 0.008270511403679848]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.033313579857349396, 0.031531721353530884, 0.09637702256441116, 0.16122233867645264, 0.22606763243675232, 0.290912926197052, 0.3557582497596741, 0.42060354351997375, 0.48544883728027344, 0.5502941608428955, 0.6151394248008728, 0.6799847483634949, 0.7448300719261169, 0.8096753358840942, 0.8745206594467163, 0.9393659234046936, 1.004211187362671, 1.069056510925293, 1.133901834487915, 1.1987470388412476, 1.2635923624038696, 1.3284376859664917, 1.3932830095291138, 1.4581283330917358, 1.522973656654358, 1.5878188610076904, 1.6526641845703125, 1.7175095081329346, 1.7823548316955566, 1.8472001552581787, 1.9120453596115112, 1.9768906831741333, 2.041736125946045, 2.106581449508667, 2.171426773071289, 2.236272096633911, 2.301117420196533, 2.3659627437591553, 2.4308078289031982, 2.4956531524658203, 2.5604984760284424, 2.6253437995910645, 2.6901891231536865, 2.7550344467163086, 2.8198797702789307, 2.8847250938415527, 2.949570417404175, 3.014415740966797, 3.079261064529419, 3.144106149673462, 3.208951473236084, 3.273796796798706, 3.338642120361328, 3.40348744392395, 3.4683327674865723, 3.5331780910491943, 3.5980234146118164, 3.6628687381744385, 3.7277140617370605, 3.7925591468811035, 3.8574044704437256, 3.9222497940063477, 3.9870951175689697, 4.051940441131592, 4.116785526275635]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.001332801184616983, -0.0004967307322658598, 0.00033933972008526325, 0.0011754102306440473, 0.0020114807412028313, 0.00284755090251565, 0.0036836215294897556, 0.004519691690802574, 0.00535576231777668, 0.006191832944750786, 0.007027903106063604, 0.007863974198698997, 0.008700044825673103, 0.00953611545264721, 0.01037218514829874, 0.011208255775272846, 0.012044326402246952, 0.012880397029221058, 0.013716467656195164, 0.014552537351846695, 0.0153886079788208, 0.016224678605794907, 0.017060749232769012, 0.01789681985974312, 0.018732890486717224, 0.01956896111369133, 0.020405031740665436, 0.021241100504994392, 0.022077171131968498, 0.022913241758942604, 0.02374931238591671, 0.024585383012890816, 0.02542145363986492, 0.026257524266839027, 0.027093594893813133, 0.02792966552078724, 0.028765736147761345, 0.02960180677473545, 0.030437875539064407, 0.03127394616603851, 0.03211001679301262, 0.032946087419986725, 0.03378215804696083, 0.034618228673934937, 0.03545429930090904, 0.03629036992788315, 0.037126440554857254, 0.03796251118183136, 0.038798581808805466, 0.03963465243577957, 0.04047072306275368, 0.04130679368972778, 0.04214286431670189, 0.042978934943675995, 0.0438150018453598, 0.04465107247233391, 0.045487143099308014, 0.04632321372628212, 0.047159284353256226, 0.04799535498023033, 0.04883142560720444, 0.04966749623417854, 0.05050356686115265, 0.051339637488126755, 0.05217570811510086]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [7.0, 43.0, 16.0, 9.0, 16.0, 68.0, 240.0, 26.0, 2.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 6.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.04740326479077339, -0.03978143632411957, -0.032159607857465744, -0.02453777752816677, -0.016915949061512947, -0.009294118732213974, -0.0016722902655601501, 0.005949538201093674, 0.013571366667747498, 0.02119319513440132, 0.028815027326345444, 0.03643685206770897, 0.04405868425965309, 0.05168050900101662, 0.05930234119296074, 0.06692416965961456, 0.07454599440097809, 0.08216783404350281, 0.08978965878486633, 0.09741148352622986, 0.10503332316875458, 0.1126551479101181, 0.12027697265148163, 0.12789879739284515, 0.13552063703536987, 0.1431424617767334, 0.15076428651809692, 0.15838612616062164, 0.16600795090198517, 0.1736297756433487, 0.18125160038471222, 0.18887344002723694, 0.19649526476860046, 0.20411710441112518, 0.2117389291524887, 0.21936075389385223, 0.22698257863521576, 0.23460440337657928, 0.2422262281179428, 0.24984805285930634, 0.25746989250183105, 0.2650917172431946, 0.2727135419845581, 0.28033536672592163, 0.28795719146728516, 0.2955790162086487, 0.3032008409500122, 0.3108226954936981, 0.31844452023506165, 0.32606634497642517, 0.3336881697177887, 0.3413099944591522, 0.34893181920051575, 0.3565536439418793, 0.3641754984855652, 0.3717973232269287, 0.37941914796829224, 0.38704097270965576, 0.3946627974510193, 0.4022846221923828, 0.40990644693374634, 0.41752830147743225, 0.4251501262187958, 0.4327719509601593, 0.4403937757015228]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.088394045829773, -1.0125224590301514, -0.9366507530212402, -0.8607791066169739, -0.7849074602127075, -0.7090358138084412, -0.6331641674041748, -0.5572925209999084, -0.4814208745956421, -0.40554922819137573, -0.3296775817871094, -0.253805935382843, -0.17793428897857666, -0.1020626425743103, -0.026190996170043945, 0.04968059062957764, 0.12555229663848877, 0.2014240026473999, 0.2772955894470215, 0.35316717624664307, 0.4290388822555542, 0.5049105882644653, 0.5807821750640869, 0.6566537618637085, 0.7325254678726196, 0.8083971738815308, 0.8842687606811523, 0.9601403474807739, 1.036012053489685, 1.1118837594985962, 1.1877552270889282, 1.2636269330978394, 1.3394986391067505, 1.4153703451156616, 1.4912420511245728, 1.5671135187149048, 1.642985224723816, 1.718856930732727, 1.794728398323059, 1.8706001043319702, 1.9464718103408813, 2.022343635559082, 2.098215103149414, 2.174086570739746, 2.2499585151672363, 2.3258299827575684, 2.4017014503479004, 2.4775733947753906, 2.5534448623657227, 2.629316806793213, 2.705188274383545, 2.781059741973877, 2.856931686401367, 2.932803153991699, 3.0086746215820312, 3.0845465660095215, 3.1604180335998535, 3.2362895011901855, 3.312161445617676, 3.388032913208008, 3.46390438079834, 3.53977632522583, 3.615647792816162, 3.6915197372436523, 3.7673912048339844]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 14.0, 16.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], "bins": [-1.8849644660949707, -1.8459211587905884, -1.806877851486206, -1.7678345441818237, -1.7287912368774414, -1.689747929573059, -1.6507046222686768, -1.6116613149642944, -1.572618007659912, -1.5335747003555298, -1.4945313930511475, -1.4554880857467651, -1.4164447784423828, -1.377401351928711, -1.3383581638336182, -1.2993147373199463, -1.2602715492248535, -1.2212281227111816, -1.1821849346160889, -1.143141508102417, -1.1040983200073242, -1.0650548934936523, -1.0260117053985596, -0.9869683384895325, -0.9479249715805054, -0.908881664276123, -0.8698383569717407, -0.8307950496673584, -0.7917517423629761, -0.7527084350585938, -0.7136651277542114, -0.6746218204498291, -0.6355785131454468, -0.5965352058410645, -0.5574918985366821, -0.5184485912322998, -0.4794052839279175, -0.44036197662353516, -0.40131866931915283, -0.3622753620147705, -0.3232320547103882, -0.28418874740600586, -0.24514544010162354, -0.2061021327972412, -0.1670588254928589, -0.12801551818847656, -0.08897221088409424, -0.049928903579711914, -0.010885477066040039, 0.028157830238342285, 0.06720113754272461, 0.10624444484710693, 0.14528775215148926, 0.18433094024658203, 0.2233743667602539, 0.2624175548553467, 0.30146098136901855, 0.34050416946411133, 0.3795475959777832, 0.418590784072876, 0.45763421058654785, 0.4966773986816406, 0.5357208251953125, 0.5747640132904053, 0.6138074398040771]}, "_runtime": 4453.179290294647, "_timestamp": 1585574369.0239236, "_step": 398}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": 3.801689624786377, "Value Loss": 44.15651321411133, "_runtime": 4453.997336387634, "_timestamp": 1585574369.8419697, "_step": 399}
{"Episode reward": 46.999999999999524, "Episode length": 530, "Policy Loss": 1.1860862970352173, "Value Loss": 18.605852127075195, "_runtime": 4455.539305686951, "_timestamp": 1585574371.383939, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8105472326278687, "Value Loss": 0.07575789093971252, "_runtime": 4457.048928976059, "_timestamp": 1585574372.8935623, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8955520987510681, "Value Loss": 0.03621731325984001, "_runtime": 4458.586521625519, "_timestamp": 1585574374.431155, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8406926393508911, "Value Loss": 0.025053679943084717, "_runtime": 4460.162871837616, "_timestamp": 1585574376.0075052, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8499325513839722, "Value Loss": 0.0714862123131752, "_runtime": 4461.72438621521, "_timestamp": 1585574377.5690196, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9341252446174622, "Value Loss": 0.1825467348098755, "_runtime": 4463.31423997879, "_timestamp": 1585574379.1588733, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9003117084503174, "Value Loss": 0.07887903600931168, "_runtime": 4464.575565099716, "_timestamp": 1585574380.4201984, "_step": 406}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.3656231462955475, "Value Loss": 12.464327812194824, "_runtime": 4465.1832184791565, "_timestamp": 1585574381.0278518, "_step": 407}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 1.8820205926895142, "Value Loss": 26.75461196899414, "_runtime": 4466.745952606201, "_timestamp": 1585574382.590586, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9338907599449158, "Value Loss": 0.08048607409000397, "_runtime": 4468.097898721695, "_timestamp": 1585574383.942532, "_step": 409}
{"Episode reward": 14.000000000000611, "Episode length": 860, "Policy Loss": 0.2736162543296814, "Value Loss": 11.495075225830078, "_runtime": 4469.6220717430115, "_timestamp": 1585574385.466705, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9032613635063171, "Value Loss": 0.049634065479040146, "_runtime": 4471.1948137283325, "_timestamp": 1585574387.039447, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9129883646965027, "Value Loss": 0.07941345125436783, "_runtime": 4472.80370426178, "_timestamp": 1585574388.6483376, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9184736013412476, "Value Loss": 0.022562548518180847, "_runtime": 4473.865879058838, "_timestamp": 1585574389.7105124, "_step": 413}
{"Episode reward": 33.099999999999525, "Episode length": 669, "Policy Loss": 0.6171177625656128, "Value Loss": 14.840559005737305, "_runtime": 4475.446305513382, "_timestamp": 1585574391.2909389, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8612886667251587, "Value Loss": 0.06000131741166115, "_runtime": 4477.037481546402, "_timestamp": 1585574392.882115, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8701828122138977, "Value Loss": 0.0120115727186203, "_runtime": 4478.584527254105, "_timestamp": 1585574394.4291606, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.864751398563385, "Value Loss": 0.0540468692779541, "_runtime": 4479.900389671326, "_timestamp": 1585574395.745023, "_step": 417}
{"Episode reward": 17.400000000000418, "Episode length": 826, "Policy Loss": 0.38095250725746155, "Value Loss": 11.977899551391602, "_runtime": 4481.468972444534, "_timestamp": 1585574397.3136058, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8682044744491577, "Value Loss": 0.0429435670375824, "_runtime": 4483.0392463207245, "_timestamp": 1585574398.8838797, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8269808292388916, "Value Loss": 0.015921810641884804, "_runtime": 4484.214050769806, "_timestamp": 1585574400.058684, "_step": 420}
{"Episode reward": 26.399999999999906, "Episode length": 736, "Policy Loss": 0.6156260967254639, "Value Loss": 13.398698806762695, "_runtime": 4485.80471944809, "_timestamp": 1585574401.6493528, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7910553216934204, "Value Loss": 0.013521802611649036, "_runtime": 4486.936815500259, "_timestamp": 1585574402.7814488, "_step": 422}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 0.6971282362937927, "Value Loss": 13.906538963317871, "_runtime": 4487.943672418594, "_timestamp": 1585574403.7883058, "_step": 423}
{"Episode reward": 36.499999999999375, "Episode length": 635, "Policy Loss": 0.8783934712409973, "Value Loss": 15.537933349609375, "_runtime": 4489.183772087097, "_timestamp": 1585574405.0284054, "_step": 424}
{"Episode reward": 22.30000000000014, "Episode length": 777, "Policy Loss": 0.7205484509468079, "Value Loss": 12.767772674560547, "_runtime": 4490.0573716163635, "_timestamp": 1585574405.902005, "_step": 425}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 1.7673263549804688, "Value Loss": 17.61268424987793, "_runtime": 4491.039015054703, "_timestamp": 1585574406.8836484, "_step": 426}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.8544190526008606, "Value Loss": 15.800952911376953, "_runtime": 4492.5935208797455, "_timestamp": 1585574408.4381542, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.781838595867157, "Value Loss": 0.026720307767391205, "_runtime": 4494.132814884186, "_timestamp": 1585574409.9774482, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7856470346450806, "Value Loss": 0.02537578158080578, "_runtime": 4495.195013046265, "_timestamp": 1585574411.0396464, "_step": 429}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.7162985801696777, "Value Loss": 14.538999557495117, "_runtime": 4496.8106009960175, "_timestamp": 1585574412.6552343, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8012621402740479, "Value Loss": 0.01769794151186943, "_runtime": 4498.389833211899, "_timestamp": 1585574414.2344666, "_step": 431}
{"Episode reward": -99.8015624999986, "Episode length": 999, "Policy Loss": -0.7938571572303772, "Value Loss": 0.021792074665427208, "_runtime": 4499.944300174713, "_timestamp": 1585574415.7889335, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7941324710845947, "Value Loss": 0.025539729744195938, "_runtime": 4500.733045578003, "_timestamp": 1585574416.577679, "_step": 433}
{"Episode reward": 51.59999999999959, "Episode length": 484, "Policy Loss": 1.3506605625152588, "Value Loss": 20.341655731201172, "_runtime": 4501.816169500351, "_timestamp": 1585574417.6608028, "_step": 434}
{"Episode reward": 31.899999999999594, "Episode length": 681, "Policy Loss": 0.6500508189201355, "Value Loss": 14.467677116394043, "_runtime": 4503.398935079575, "_timestamp": 1585574419.2435684, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7579149007797241, "Value Loss": 0.043782562017440796, "_runtime": 4504.937519311905, "_timestamp": 1585574420.7821527, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7627725601196289, "Value Loss": 0.010140993632376194, "_runtime": 4506.491692781448, "_timestamp": 1585574422.3363261, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8040957450866699, "Value Loss": 0.031592320650815964, "_runtime": 4507.993420124054, "_timestamp": 1585574423.8380535, "_step": 438}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 0.3004117012023926, "Value Loss": 10.383576393127441, "_runtime": 4509.5709726810455, "_timestamp": 1585574425.415606, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8196365237236023, "Value Loss": 0.04582013934850693, "_runtime": 4511.155958414078, "_timestamp": 1585574427.0005918, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.765898585319519, "Value Loss": 0.045653391629457474, "_runtime": 4512.39862036705, "_timestamp": 1585574428.2432537, "_step": 441}
{"Episode reward": 22.154133772850187, "Episode length": 779, "Policy Loss": 0.5009725689888, "Value Loss": 12.700243949890137, "_runtime": 4513.307574272156, "_timestamp": 1585574429.1522076, "_step": 442}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 0.9920185208320618, "Value Loss": 17.239154815673828, "_runtime": 4514.8809270858765, "_timestamp": 1585574430.7255604, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7718530297279358, "Value Loss": 0.04157257452607155, "_runtime": 4516.456129312515, "_timestamp": 1585574432.3007627, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7287740707397461, "Value Loss": 0.038778096437454224, "_runtime": 4517.315903186798, "_timestamp": 1585574433.1605365, "_step": 445}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": 1.1243270635604858, "Value Loss": 18.049959182739258, "_runtime": 4518.280446052551, "_timestamp": 1585574434.1250794, "_step": 446}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 1.2374976873397827, "Value Loss": 16.304750442504883, "_runtime": 4519.157434463501, "_timestamp": 1585574435.0020678, "_step": 447}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 1.1713004112243652, "Value Loss": 18.104156494140625, "_runtime": 4519.830107927322, "_timestamp": 1585574435.6747413, "_step": 448}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.8031681776046753, "Value Loss": 24.571517944335938, "_runtime": 4520.628402471542, "_timestamp": 1585574436.4730358, "_step": 449}
{"Episode reward": 48.99999999999955, "Episode length": 510, "Policy Loss": 1.204232096672058, "Value Loss": 19.326162338256836, "_runtime": 4522.154577970505, "_timestamp": 1585574437.9992113, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8194547295570374, "Value Loss": 0.06947138905525208, "_runtime": 4523.674634218216, "_timestamp": 1585574439.5192676, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7940656542778015, "Value Loss": 0.01587461680173874, "_runtime": 4525.201723575592, "_timestamp": 1585574441.046357, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7915793657302856, "Value Loss": 0.01278757769614458, "_runtime": 4526.779330730438, "_timestamp": 1585574442.623964, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8296189308166504, "Value Loss": 0.019484534859657288, "_runtime": 4528.348587036133, "_timestamp": 1585574444.1932204, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8689666986465454, "Value Loss": 0.06071094051003456, "_runtime": 4529.253840923309, "_timestamp": 1585574445.0984743, "_step": 455}
{"Episode reward": 42.69999999999946, "Episode length": 573, "Policy Loss": 1.0242902040481567, "Value Loss": 17.30543327331543, "_runtime": 4530.832405328751, "_timestamp": 1585574446.6770387, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.817270040512085, "Value Loss": 0.04453100264072418, "_runtime": 4532.407475471497, "_timestamp": 1585574448.2521088, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8015850186347961, "Value Loss": 0.023500364273786545, "_runtime": 4533.951344490051, "_timestamp": 1585574449.7959778, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8211154937744141, "Value Loss": 0.06283976882696152, "_runtime": 4535.161059617996, "_timestamp": 1585574451.005693, "_step": 459}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.614130437374115, "Value Loss": 12.939719200134277, "_runtime": 4536.379103183746, "_timestamp": 1585574452.2237365, "_step": 460}
{"Episode reward": 23.0000000000001, "Episode length": 770, "Policy Loss": 0.5424216985702515, "Value Loss": 12.808801651000977, "_runtime": 4537.128197431564, "_timestamp": 1585574452.9728308, "_step": 461}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.3379206657409668, "Value Loss": 21.131254196166992, "_runtime": 4538.6872301101685, "_timestamp": 1585574454.5318635, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.828779399394989, "Value Loss": 0.05576597899198532, "_runtime": 4540.247565507889, "_timestamp": 1585574456.0921988, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8075242042541504, "Value Loss": 0.03142626956105232, "_runtime": 4541.778834104538, "_timestamp": 1585574457.6234674, "_step": 464}
{"Episode reward": -99.81666297912457, "Episode length": 999, "Policy Loss": -0.7813348174095154, "Value Loss": 0.024853257462382317, "_runtime": 4543.4034152030945, "_timestamp": 1585574459.2480485, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7781438827514648, "Value Loss": 0.0068148281425237656, "_runtime": 4544.184421300888, "_timestamp": 1585574460.0290546, "_step": 466}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 1.356026530265808, "Value Loss": 20.594409942626953, "_runtime": 4545.7409760952, "_timestamp": 1585574461.5856094, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7917220592498779, "Value Loss": 0.022228170186281204, "_runtime": 4547.319644451141, "_timestamp": 1585574463.1642778, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7600436210632324, "Value Loss": 0.009598576463758945, "_runtime": 4547.8137328624725, "_timestamp": 1585574463.6583662, "_step": 469}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 2.7432732582092285, "Value Loss": 32.57505416870117, "_runtime": 4549.377901554108, "_timestamp": 1585574465.222535, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.745159387588501, "Value Loss": 0.010763565078377724, "_runtime": 4550.944604635239, "_timestamp": 1585574466.789238, "_step": 471}
{"Episode reward": -99.87494757175305, "Episode length": 999, "Policy Loss": -0.757461667060852, "Value Loss": 0.02348817139863968, "_runtime": 4552.46195101738, "_timestamp": 1585574468.3065844, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7675724625587463, "Value Loss": 0.01474915724247694, "_runtime": 4554.0453107357025, "_timestamp": 1585574469.889944, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7300299406051636, "Value Loss": 0.011084001511335373, "_runtime": 4555.62864279747, "_timestamp": 1585574471.4732761, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7261746525764465, "Value Loss": 0.008128844201564789, "_runtime": 4556.849984407425, "_timestamp": 1585574472.6946177, "_step": 475}
{"Episode reward": 22.000000000000156, "Episode length": 780, "Policy Loss": 0.6880635619163513, "Value Loss": 12.730761528015137, "_runtime": 4557.885174512863, "_timestamp": 1585574473.7298079, "_step": 476}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.9062422513961792, "Value Loss": 15.228287696838379, "_runtime": 4559.467576503754, "_timestamp": 1585574475.3122098, "_step": 477}
{"Episode reward": -99.81041700839856, "Episode length": 999, "Policy Loss": -0.7305275201797485, "Value Loss": 0.019657375290989876, "_runtime": 4561.0232100486755, "_timestamp": 1585574476.8678434, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.72078937292099, "Value Loss": 0.01621800847351551, "_runtime": 4562.576590538025, "_timestamp": 1585574478.4212239, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6839677095413208, "Value Loss": 0.009458009153604507, "_runtime": 4563.410377264023, "_timestamp": 1585574479.2550106, "_step": 480}
{"Episode reward": 48.89999999999955, "Episode length": 511, "Policy Loss": 1.2891005277633667, "Value Loss": 19.280014038085938, "_runtime": 4564.990635633469, "_timestamp": 1585574480.835269, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6783931851387024, "Value Loss": 0.008690510876476765, "_runtime": 4566.575425863266, "_timestamp": 1585574482.4200592, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.655997097492218, "Value Loss": 0.016078166663646698, "_runtime": 4567.331832647324, "_timestamp": 1585574483.176466, "_step": 483}
{"Episode reward": 54.49999999999963, "Episode length": 455, "Policy Loss": 1.6322531700134277, "Value Loss": 21.610279083251953, "_runtime": 4568.531133174896, "_timestamp": 1585574484.3757665, "_step": 484}
{"Episode reward": 24.000000000000043, "Episode length": 760, "Policy Loss": 0.6293725371360779, "Value Loss": 13.059688568115234, "_runtime": 4570.11550951004, "_timestamp": 1585574485.9601429, "_step": 485}
{"Episode reward": -99.86922760009625, "Episode length": 999, "Policy Loss": -0.6749926805496216, "Value Loss": 0.016062306240200996, "_runtime": 4571.650019407272, "_timestamp": 1585574487.4946527, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6842302680015564, "Value Loss": 0.0514327697455883, "_runtime": 4573.206175804138, "_timestamp": 1585574489.0508091, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6816548705101013, "Value Loss": 0.0501047819852829, "_runtime": 4574.78549861908, "_timestamp": 1585574490.630132, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7181524634361267, "Value Loss": 0.08851835131645203, "_runtime": 4576.362426280975, "_timestamp": 1585574492.2070596, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6816263198852539, "Value Loss": 0.05547965317964554, "_runtime": 4577.481123924255, "_timestamp": 1585574493.3257573, "_step": 490}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.8113580942153931, "Value Loss": 13.953179359436035, "_runtime": 4578.369837999344, "_timestamp": 1585574494.2144713, "_step": 491}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 1.1795233488082886, "Value Loss": 17.8501033782959, "_runtime": 4579.951123714447, "_timestamp": 1585574495.795757, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6185990571975708, "Value Loss": 0.04321262612938881, "_runtime": 4581.131901502609, "_timestamp": 1585574496.9765348, "_step": 493}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.7051782011985779, "Value Loss": 12.994280815124512, "_runtime": 4582.671303510666, "_timestamp": 1585574498.5159369, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.635109007358551, "Value Loss": 0.013927741907536983, "_runtime": 4583.546750545502, "_timestamp": 1585574499.391384, "_step": 495}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 1.4343496561050415, "Value Loss": 18.170080184936523, "_runtime": 4585.063326120377, "_timestamp": 1585574500.9079595, "_step": 496}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": 0.4445910155773163, "Value Loss": 10.123342514038086, "_runtime": 4586.268221378326, "_timestamp": 1585574502.1128547, "_step": 497}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.7064576745033264, "Value Loss": 12.888385772705078, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05, 1.7620963262743317e-05]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.2297152727842331, -0.22315913438796997, -0.21660299599170685, -0.21004685759544373, -0.2034907191991806, -0.19693458080291748, -0.19037844240665436, -0.18382230401039124, -0.1772661656141281, -0.170710027217865, -0.16415387392044067, -0.15759775042533875, -0.15104159712791443, -0.1444854736328125, -0.13792932033538818, -0.13137319684028625, -0.12481705099344254, -0.11826091259717941, -0.11170477420091629, -0.10514863580465317, -0.09859248995780945, -0.09203635156154633, -0.0854802131652832, -0.07892407476902008, -0.07236793637275696, -0.06581179797649384, -0.05925565958023071, -0.05269952118396759, -0.04614338278770447, -0.039587244391441345, -0.03303110599517822, -0.0264749675989151, -0.019918829202651978, -0.013362690806388855, -0.006806552410125732, -0.00025041401386260986, 0.006305724382400513, 0.012861862778663635, 0.019418001174926758, 0.02597413957118988, 0.0325302928686142, 0.039086416363716125, 0.04564256966114044, 0.05219869315624237, 0.05875484645366669, 0.06531096994876862, 0.07186712324619293, 0.07842324674129486, 0.08497940003871918, 0.0915355235338211, 0.09809167683124542, 0.10464780032634735, 0.11120395362377167, 0.1177600771188736, 0.12431623041629791, 0.13087235391139984, 0.13742850720882416, 0.1439846307039261, 0.1505407840013504, 0.15709690749645233, 0.16365306079387665, 0.17020918428897858, 0.1767653375864029, 0.18332146108150482, 0.18987761437892914]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0019892039708793163, -0.001923907082527876, -0.0018586101941764355, -0.001793313305824995, -0.0017280164174735546, -0.0016627195291221142, -0.0015974226407706738, -0.0015321257524192333, -0.001466828864067793, -0.0014015319757163525, -0.001336235087364912, -0.0012709381990134716, -0.0012056413106620312, -0.0011403444223105907, -0.0010750475339591503, -0.0010097506456077099, -0.0009444537572562695, -0.000879156868904829, -0.0008138599805533886, -0.0007485630922019482, -0.0006832662038505077, -0.0006179693154990673, -0.0005526724271476269, -0.00048737553879618645, -0.000422078650444746, -0.0003567817620933056, -0.00029148487374186516, -0.00022618798539042473, -0.0001608910970389843, -9.559420868754387e-05, -3.029732033610344e-05, 3.499956801533699e-05, 0.00010029645636677742, 0.00016559334471821785, 0.00023089023306965828, 0.0002961871214210987, 0.00036148400977253914, 0.00042678089812397957, 0.00049207778647542, 0.0005573746748268604, 0.0006226715631783009, 0.0006879684515297413, 0.0007532653398811817, 0.0008185622282326221, 0.0008838591165840626, 0.000949156004935503, 0.0010144528932869434, 0.0010797497816383839, 0.0011450466699898243, 0.0012103435583412647, 0.0012756404466927052, 0.0013409373350441456, 0.001406234223395586, 0.0014715311117470264, 0.0015368280000984669, 0.0016021248884499073, 0.0016674217768013477, 0.0017327186651527882, 0.0017980155535042286, 0.001863312441855669, 0.0019286093302071095, 0.00199390621855855, 0.0020592031069099903, 0.0021244999952614307, 0.002189796883612871]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 6.0, 4.0, 5.0, 3.0, 1.0, 4.0, 4.0, 3.0, 0.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 5.0, 1.0, 4.0, 7.0, 8.0, 4.0, 7.0, 21.0, 18.0, 24.0, 44.0, 52.0, 65.0, 48.0, 49.0, 22.0, 26.0, 13.0, 18.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], "bins": [-0.0173611119389534, -0.01680082641541958, -0.016240540891885757, -0.015680255368351936, -0.01511997077614069, -0.014559685252606869, -0.013999400660395622, -0.013439115136861801, -0.01287882961332798, -0.012318544089794159, -0.011758258566260338, -0.011197973974049091, -0.01063768845051527, -0.010077402926981449, -0.009517118334770203, -0.008956832811236382, -0.00839654728770256, -0.00783626176416874, -0.007275976240634918, -0.006715691648423672, -0.006155406124889851, -0.0055951206013560295, -0.005034836009144783, -0.004474550485610962, -0.003914264962077141, -0.0033539794385433197, -0.0027936939150094986, -0.002233409322798252, -0.0016731247305870056, -0.0011128392070531845, -0.0005525536835193634, 7.731840014457703e-06, 0.0005680173635482788, 0.0011283028870821, 0.001688588410615921, 0.002248873934149742, 0.0028091594576835632, 0.003369443118572235, 0.003929728642106056, 0.004490014165639877, 0.005050299689173698, 0.0056105852127075195, 0.006170870736241341, 0.006731156259775162, 0.007291439920663834, 0.007851725444197655, 0.008412010967731476, 0.008972296491265297, 0.009532582014799118, 0.01009286753833294, 0.01065315306186676, 0.011213438585400581, 0.011773724108934402, 0.012334007769823074, 0.012894293293356895, 0.013454578816890717, 0.014014862477779388, 0.014575149863958359, 0.01513543352484703, 0.015695720911026, 0.016256004571914673, 0.016816291958093643, 0.017376575618982315, 0.017936863005161285, 0.018497146666049957]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.13029062747955322, -0.12677748501300812, -0.12326434254646301, -0.11975120007991791, -0.1162380576133728, -0.1127249151468277, -0.109211765229702, -0.10569862276315689, -0.10218548029661179, -0.09867233783006668, -0.09515919536352158, -0.09164604544639587, -0.08813290297985077, -0.08461976051330566, -0.08110661804676056, -0.07759347558021545, -0.07408033311367035, -0.07056719064712524, -0.06705404818058014, -0.06354090571403503, -0.06002776324748993, -0.05651461333036423, -0.05300147086381912, -0.04948832839727402, -0.04597518593072891, -0.04246204346418381, -0.0389489009976387, -0.0354357585310936, -0.031922608613967896, -0.02840946614742279, -0.024896323680877686, -0.02138318121433258, -0.017870038747787476, -0.01435689628124237, -0.010843753814697266, -0.007330611348152161, -0.0038174688816070557, -0.0003043264150619507, 0.0032088160514831543, 0.006721958518028259, 0.010235100984573364, 0.013748258352279663, 0.017261400818824768, 0.020774543285369873, 0.024287685751914978, 0.027800828218460083, 0.03131397068500519, 0.03482711315155029, 0.0383402556180954, 0.0418533980846405, 0.04536654055118561, 0.04887968301773071, 0.05239282548427582, 0.05590596795082092, 0.05941911041736603, 0.06293225288391113, 0.06644541025161743, 0.06995855271816254, 0.07347169518470764, 0.07698483765125275, 0.08049798011779785, 0.08401112258434296, 0.08752426505088806, 0.09103740751743317, 0.09455054998397827]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 8.0, 5.0, 4.0, 3.0, 2.0, 9.0, 4.0, 0.0, 0.0, 2.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01946852169930935, -0.0179262887686491, -0.016384055837988853, -0.01484182383865118, -0.013299590907990932, -0.011757357977330685, -0.010215125977993011, -0.008672893047332764, -0.007130660116672516, -0.005588427186012268, -0.00404619425535202, -0.0025039613246917725, -0.0009617302566766739, 0.0005805026739835739, 0.0021227356046438217, 0.0036649685353040695, 0.005207201465964317, 0.006749434396624565, 0.008291667327284813, 0.00983390025794506, 0.011376133188605309, 0.012918366119265556, 0.014460599049925804, 0.016002831980586052, 0.017545061185956, 0.01908729411661625, 0.020629527047276497, 0.022171759977936745, 0.023713992908596992, 0.02525622583925724, 0.026798458769917488, 0.028340691700577736, 0.029882924631237984, 0.03142515569925308, 0.03296738862991333, 0.03450962156057358, 0.036051854491233826, 0.037594087421894073, 0.03913632035255432, 0.04067855328321457, 0.04222078621387482, 0.043763019144535065, 0.04530525207519531, 0.04684748500585556, 0.04838971793651581, 0.049931950867176056, 0.051474183797836304, 0.05301641672849655, 0.0545586422085762, 0.05610087513923645, 0.0576431080698967, 0.059185341000556946, 0.060727573931217194, 0.06226980686187744, 0.06381203979253769, 0.06535427272319794, 0.06689650565385818, 0.06843873858451843, 0.06998097151517868, 0.07152320444583893, 0.07306543737649918, 0.07460767030715942, 0.07614990323781967, 0.07769213616847992, 0.07923436909914017]}, "_runtime": 4587.808057308197, "_timestamp": 1585574503.6526906, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6434062123298645, "Value Loss": 0.008647209033370018, "_runtime": 4587.808057308197, "_timestamp": 1585574503.6526906, "_step": 499}
