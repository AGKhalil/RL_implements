{"Episode reward": 74.39296147227893, "Episode length": 387, "Policy Loss": 0.511140763759613, "Value Loss": 25.608030319213867, "_runtime": 5745.369850158691, "_timestamp": 1585603115.0027196, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3060433864593506, "Value Loss": 0.17201991379261017, "_runtime": 5746.854407072067, "_timestamp": 1585603116.4872766, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1822904348373413, "Value Loss": 52.755558013916016, "_runtime": 5748.370527744293, "_timestamp": 1585603118.0033972, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.211263179779053, "Value Loss": 77.15966796875, "_runtime": 5749.923068284988, "_timestamp": 1585603119.5559378, "_step": 3}
{"Episode reward": -99.73004772460285, "Episode length": 999, "Policy Loss": 1.1507734060287476, "Value Loss": 151.24314880371094, "_runtime": 5751.440832614899, "_timestamp": 1585603121.073702, "_step": 4}
{"Episode reward": -99.12087066746801, "Episode length": 999, "Policy Loss": -3.292322874069214, "Value Loss": 83.17730712890625, "_runtime": 5752.988490581512, "_timestamp": 1585603122.62136, "_step": 5}
{"Episode reward": -69.12511784230225, "Episode length": 999, "Policy Loss": 0.2889110743999481, "Value Loss": 12.246959686279297, "_runtime": 5754.543092012405, "_timestamp": 1585603124.1759615, "_step": 6}
{"Episode reward": -36.81464018141454, "Episode length": 999, "Policy Loss": 0.7671387195587158, "Value Loss": 40.84103775024414, "_runtime": 5756.118623971939, "_timestamp": 1585603125.7514935, "_step": 7}
{"Episode reward": -59.87145982789417, "Episode length": 999, "Policy Loss": 1.652040719985962, "Value Loss": 16562.833984375, "_runtime": 5757.485314130783, "_timestamp": 1585603127.1181836, "_step": 8}
{"Episode reward": 48.01370740115133, "Episode length": 880, "Policy Loss": -185.18692016601562, "Value Loss": 18674.779296875, "_runtime": 5757.932060003281, "_timestamp": 1585603127.5649295, "_step": 9}
{"Episode reward": 86.64096181397362, "Episode length": 252, "Policy Loss": -3.068413257598877, "Value Loss": 1267.14013671875, "_runtime": 5759.027811288834, "_timestamp": 1585603128.6606808, "_step": 10}
{"Episode reward": 53.72220738850161, "Episode length": 713, "Policy Loss": 1.6150113344192505, "Value Loss": 192.93724060058594, "_runtime": 5760.567588806152, "_timestamp": 1585603130.2004583, "_step": 11}
{"Episode reward": -69.08939838289075, "Episode length": 999, "Policy Loss": -2.7947189807891846, "Value Loss": 688.8773803710938, "_runtime": 5762.056934833527, "_timestamp": 1585603131.6898043, "_step": 12}
{"Episode reward": -74.76759759154031, "Episode length": 999, "Policy Loss": 1.0968791246414185, "Value Loss": 238.97140502929688, "_runtime": 5763.583576202393, "_timestamp": 1585603133.2164457, "_step": 13}
{"Episode reward": -79.51825806400859, "Episode length": 999, "Policy Loss": 0.9587541222572327, "Value Loss": 1022.6199340820312, "_runtime": 5765.133778333664, "_timestamp": 1585603134.7666478, "_step": 14}
{"Episode reward": -82.61373082757643, "Episode length": 999, "Policy Loss": -4.300497055053711, "Value Loss": 2657.835205078125, "_runtime": 5766.679480791092, "_timestamp": 1585603136.3123503, "_step": 15}
{"Episode reward": -88.62369300896856, "Episode length": 999, "Policy Loss": 2.285212516784668, "Value Loss": 204.3452911376953, "_runtime": 5767.851588726044, "_timestamp": 1585603137.4844582, "_step": 16}
{"Episode reward": 33.26854577582331, "Episode length": 744, "Policy Loss": 1.4236022233963013, "Value Loss": 312.59674072265625, "_runtime": 5769.403372764587, "_timestamp": 1585603139.0362422, "_step": 17}
{"Episode reward": -90.48862781021941, "Episode length": 999, "Policy Loss": 2.7452852725982666, "Value Loss": 1.3901784420013428, "_runtime": 5770.520794630051, "_timestamp": 1585603140.153664, "_step": 18}
{"Episode reward": 35.35879780102077, "Episode length": 720, "Policy Loss": 6.049510955810547, "Value Loss": 183.50062561035156, "_runtime": 5772.062583684921, "_timestamp": 1585603141.6954532, "_step": 19}
{"Episode reward": -89.1712051601737, "Episode length": 999, "Policy Loss": 2.568821907043457, "Value Loss": 54.721290588378906, "_runtime": 5773.627898931503, "_timestamp": 1585603143.2607684, "_step": 20}
{"Episode reward": -92.80728955528997, "Episode length": 999, "Policy Loss": 7.043960094451904, "Value Loss": 717.8072509765625, "_runtime": 5775.156929731369, "_timestamp": 1585603144.7897992, "_step": 21}
{"Episode reward": -94.15381944767479, "Episode length": 999, "Policy Loss": 0.8532702326774597, "Value Loss": 14.487946510314941, "_runtime": 5776.713240623474, "_timestamp": 1585603146.34611, "_step": 22}
{"Episode reward": -91.73630715496144, "Episode length": 999, "Policy Loss": 3.35052752494812, "Value Loss": 209.21749877929688, "_runtime": 5778.268643140793, "_timestamp": 1585603147.9015126, "_step": 23}
{"Episode reward": -92.77790060632152, "Episode length": 999, "Policy Loss": 1.0902622938156128, "Value Loss": 21.884227752685547, "_runtime": 5779.864064455032, "_timestamp": 1585603149.496934, "_step": 24}
{"Episode reward": -93.94560409857286, "Episode length": 999, "Policy Loss": -0.9571723341941833, "Value Loss": 2.504545211791992, "_runtime": 5781.417871236801, "_timestamp": 1585603151.0507407, "_step": 25}
{"Episode reward": -94.29608762310811, "Episode length": 999, "Policy Loss": -2.1271395683288574, "Value Loss": 43.552452087402344, "_runtime": 5782.991334438324, "_timestamp": 1585603152.624204, "_step": 26}
{"Episode reward": -95.36502416224745, "Episode length": 999, "Policy Loss": -5.699624538421631, "Value Loss": 259.50372314453125, "_runtime": 5784.551793813705, "_timestamp": 1585603154.1846633, "_step": 27}
{"Episode reward": -95.06934009332997, "Episode length": 999, "Policy Loss": -5.219798564910889, "Value Loss": 185.81591796875, "_runtime": 5786.117567539215, "_timestamp": 1585603155.750437, "_step": 28}
{"Episode reward": -93.72570785666015, "Episode length": 999, "Policy Loss": -5.0926289558410645, "Value Loss": 96.89572143554688, "_runtime": 5787.687111854553, "_timestamp": 1585603157.3199813, "_step": 29}
{"Episode reward": -94.31568513561218, "Episode length": 999, "Policy Loss": -2.2499356269836426, "Value Loss": 13.098806381225586, "_runtime": 5789.2514407634735, "_timestamp": 1585603158.8843102, "_step": 30}
{"Episode reward": -96.38648982048373, "Episode length": 999, "Policy Loss": -2.110724449157715, "Value Loss": 0.6405602097511292, "_runtime": 5790.808490037918, "_timestamp": 1585603160.4413595, "_step": 31}
{"Episode reward": -94.61047650315771, "Episode length": 999, "Policy Loss": -1.715694785118103, "Value Loss": 11.813530921936035, "_runtime": 5792.368748664856, "_timestamp": 1585603162.0016181, "_step": 32}
{"Episode reward": -90.34794898708765, "Episode length": 999, "Policy Loss": -3.0017049312591553, "Value Loss": 94.3541030883789, "_runtime": 5793.92579460144, "_timestamp": 1585603163.558664, "_step": 33}
{"Episode reward": -95.48751790454179, "Episode length": 999, "Policy Loss": -0.15606658160686493, "Value Loss": 80.92150115966797, "_runtime": 5795.483137369156, "_timestamp": 1585603165.1160069, "_step": 34}
{"Episode reward": -93.14656934727077, "Episode length": 999, "Policy Loss": -2.0636565685272217, "Value Loss": 47.17427444458008, "_runtime": 5797.032310009003, "_timestamp": 1585603166.6651795, "_step": 35}
{"Episode reward": -96.15364176186732, "Episode length": 999, "Policy Loss": -2.677457571029663, "Value Loss": 2.767019510269165, "_runtime": 5798.590056180954, "_timestamp": 1585603168.2229257, "_step": 36}
{"Episode reward": -96.32285974507964, "Episode length": 999, "Policy Loss": -2.1239471435546875, "Value Loss": 11.962684631347656, "_runtime": 5800.146628141403, "_timestamp": 1585603169.7794976, "_step": 37}
{"Episode reward": -94.98092309962082, "Episode length": 999, "Policy Loss": -3.1479082107543945, "Value Loss": 8.007173538208008, "_runtime": 5801.741847753525, "_timestamp": 1585603171.3747172, "_step": 38}
{"Episode reward": -91.43630758539047, "Episode length": 999, "Policy Loss": -4.523717880249023, "Value Loss": 10.127230644226074, "_runtime": 5803.302630901337, "_timestamp": 1585603172.9355004, "_step": 39}
{"Episode reward": -93.98915177620447, "Episode length": 999, "Policy Loss": -3.774453639984131, "Value Loss": 15.12327766418457, "_runtime": 5804.8598549366, "_timestamp": 1585603174.4927244, "_step": 40}
{"Episode reward": -95.07493292668673, "Episode length": 999, "Policy Loss": -4.086879253387451, "Value Loss": 22.56125831604004, "_runtime": 5806.429016113281, "_timestamp": 1585603176.0618856, "_step": 41}
{"Episode reward": -96.86571558232382, "Episode length": 999, "Policy Loss": -3.483729124069214, "Value Loss": 7.53983736038208, "_runtime": 5807.9956958293915, "_timestamp": 1585603177.6285653, "_step": 42}
{"Episode reward": -96.23481314111312, "Episode length": 999, "Policy Loss": -3.3993358612060547, "Value Loss": 1.6049580574035645, "_runtime": 5809.5653195381165, "_timestamp": 1585603179.198189, "_step": 43}
{"Episode reward": -96.55041137675629, "Episode length": 999, "Policy Loss": -3.4419808387756348, "Value Loss": 2.0774552822113037, "_runtime": 5811.13667678833, "_timestamp": 1585603180.7695463, "_step": 44}
{"Episode reward": -96.02828073174942, "Episode length": 999, "Policy Loss": -3.377501964569092, "Value Loss": 2.0161471366882324, "_runtime": 5812.704235076904, "_timestamp": 1585603182.3371046, "_step": 45}
{"Episode reward": -96.65506372996451, "Episode length": 999, "Policy Loss": -3.3693184852600098, "Value Loss": 1.0134912729263306, "_runtime": 5813.499785423279, "_timestamp": 1585603183.132655, "_step": 46}
{"Episode reward": 54.22320797480935, "Episode length": 491, "Policy Loss": -4.824551105499268, "Value Loss": 30.637893676757812, "_runtime": 5815.069675922394, "_timestamp": 1585603184.7025454, "_step": 47}
{"Episode reward": -96.6170881749505, "Episode length": 999, "Policy Loss": -3.1222634315490723, "Value Loss": 2.742816209793091, "_runtime": 5816.648827791214, "_timestamp": 1585603186.2816973, "_step": 48}
{"Episode reward": -96.94662840407156, "Episode length": 999, "Policy Loss": -2.9060938358306885, "Value Loss": 5.544571876525879, "_runtime": 5818.162464141846, "_timestamp": 1585603187.7953336, "_step": 49}
{"Episode reward": -92.59346063499734, "Episode length": 999, "Policy Loss": -2.590970277786255, "Value Loss": 10.15981674194336, "_runtime": 5819.7225387096405, "_timestamp": 1585603189.3554082, "_step": 50}
{"Episode reward": -96.39682891584665, "Episode length": 999, "Policy Loss": -3.1935060024261475, "Value Loss": 1.25478994846344, "_runtime": 5821.2773604393005, "_timestamp": 1585603190.91023, "_step": 51}
{"Episode reward": -96.77241998058763, "Episode length": 999, "Policy Loss": -3.0697479248046875, "Value Loss": 1.224166750907898, "_runtime": 5822.836646080017, "_timestamp": 1585603192.4695156, "_step": 52}
{"Episode reward": -96.52685602958283, "Episode length": 999, "Policy Loss": -3.048394203186035, "Value Loss": 1.0082401037216187, "_runtime": 5824.409555196762, "_timestamp": 1585603194.0424247, "_step": 53}
{"Episode reward": -94.85020844450705, "Episode length": 999, "Policy Loss": -3.8553237915039062, "Value Loss": 5.207971572875977, "_runtime": 5826.0074207782745, "_timestamp": 1585603195.6402903, "_step": 54}
{"Episode reward": -96.63038841068285, "Episode length": 999, "Policy Loss": -2.9396684169769287, "Value Loss": 0.8195875883102417, "_runtime": 5827.560108661652, "_timestamp": 1585603197.1929781, "_step": 55}
{"Episode reward": -96.88886323335764, "Episode length": 999, "Policy Loss": -2.9580044746398926, "Value Loss": 0.6361949443817139, "_runtime": 5829.135003089905, "_timestamp": 1585603198.7678726, "_step": 56}
{"Episode reward": -96.81922179505891, "Episode length": 999, "Policy Loss": -2.8351285457611084, "Value Loss": 2.029719352722168, "_runtime": 5830.703894853592, "_timestamp": 1585603200.3367643, "_step": 57}
{"Episode reward": -89.2966407421562, "Episode length": 999, "Policy Loss": -1.5949313640594482, "Value Loss": 6.149154186248779, "_runtime": 5832.269336462021, "_timestamp": 1585603201.902206, "_step": 58}
{"Episode reward": -96.39624503096691, "Episode length": 999, "Policy Loss": -2.922342300415039, "Value Loss": 1.1251111030578613, "_runtime": 5833.839618206024, "_timestamp": 1585603203.4724877, "_step": 59}
{"Episode reward": -94.94071869856734, "Episode length": 999, "Policy Loss": -3.0820910930633545, "Value Loss": 3.4136552810668945, "_runtime": 5835.4080629348755, "_timestamp": 1585603205.0409324, "_step": 60}
{"Episode reward": -96.96318156128521, "Episode length": 999, "Policy Loss": -2.5800254344940186, "Value Loss": 0.8003356456756592, "_runtime": 5836.9731459617615, "_timestamp": 1585603206.6060154, "_step": 61}
{"Episode reward": -96.82832329561288, "Episode length": 999, "Policy Loss": -2.624732732772827, "Value Loss": 1.0574719905853271, "_runtime": 5838.545270204544, "_timestamp": 1585603208.1781397, "_step": 62}
{"Episode reward": -96.76568303438303, "Episode length": 999, "Policy Loss": -2.6898040771484375, "Value Loss": 0.8734573125839233, "_runtime": 5840.11758351326, "_timestamp": 1585603209.750453, "_step": 63}
{"Episode reward": -96.56900809298438, "Episode length": 999, "Policy Loss": -2.6247565746307373, "Value Loss": 0.5955384373664856, "_runtime": 5841.673218727112, "_timestamp": 1585603211.3060882, "_step": 64}
{"Episode reward": -88.08337539032371, "Episode length": 999, "Policy Loss": -1.7344934940338135, "Value Loss": 2.796369791030884, "_runtime": 5843.245274305344, "_timestamp": 1585603212.8781438, "_step": 65}
{"Episode reward": -96.30246182196063, "Episode length": 999, "Policy Loss": -2.5257022380828857, "Value Loss": 0.49414166808128357, "_runtime": 5844.815368890762, "_timestamp": 1585603214.4482384, "_step": 66}
{"Episode reward": -96.83498123283587, "Episode length": 999, "Policy Loss": -2.4645702838897705, "Value Loss": 0.5896021723747253, "_runtime": 5846.3630900383, "_timestamp": 1585603215.9959595, "_step": 67}
{"Episode reward": -96.9471281862566, "Episode length": 999, "Policy Loss": -2.416524648666382, "Value Loss": 0.6850830316543579, "_runtime": 5847.937233924866, "_timestamp": 1585603217.5701034, "_step": 68}
{"Episode reward": -94.40553047547091, "Episode length": 999, "Policy Loss": -2.7868831157684326, "Value Loss": 2.2532641887664795, "_runtime": 5849.5339295864105, "_timestamp": 1585603219.166799, "_step": 69}
{"Episode reward": -94.32046091358282, "Episode length": 999, "Policy Loss": -2.3951656818389893, "Value Loss": 2.022088050842285, "_runtime": 5851.079902410507, "_timestamp": 1585603220.712772, "_step": 70}
{"Episode reward": -96.77868355689111, "Episode length": 999, "Policy Loss": -2.320659637451172, "Value Loss": 0.5694859027862549, "_runtime": 5852.649695158005, "_timestamp": 1585603222.2825646, "_step": 71}
{"Episode reward": -96.31309116975689, "Episode length": 999, "Policy Loss": -2.308812141418457, "Value Loss": 1.0069289207458496, "_runtime": 5854.2073340415955, "_timestamp": 1585603223.8402035, "_step": 72}
{"Episode reward": -97.35937878243054, "Episode length": 999, "Policy Loss": -2.1474292278289795, "Value Loss": 2.3701424598693848, "_runtime": 5855.77499461174, "_timestamp": 1585603225.407864, "_step": 73}
{"Episode reward": -94.39583421470637, "Episode length": 999, "Policy Loss": -1.5809614658355713, "Value Loss": 5.209878444671631, "_runtime": 5857.332479476929, "_timestamp": 1585603226.965349, "_step": 74}
{"Episode reward": -95.205473721729, "Episode length": 999, "Policy Loss": -1.8560467958450317, "Value Loss": 2.7828733921051025, "_runtime": 5858.914989948273, "_timestamp": 1585603228.5478594, "_step": 75}
{"Episode reward": -96.18459311159287, "Episode length": 999, "Policy Loss": -2.085750102996826, "Value Loss": 0.420223593711853, "_runtime": 5860.481077671051, "_timestamp": 1585603230.1139472, "_step": 76}
{"Episode reward": -91.9930120702, "Episode length": 999, "Policy Loss": -3.2123770713806152, "Value Loss": 10.789436340332031, "_runtime": 5862.05766415596, "_timestamp": 1585603231.6905336, "_step": 77}
{"Episode reward": -95.27155237981857, "Episode length": 999, "Policy Loss": -2.048764705657959, "Value Loss": 0.6604717969894409, "_runtime": 5863.448383808136, "_timestamp": 1585603233.0812533, "_step": 78}
{"Episode reward": 19.386088761590756, "Episode length": 880, "Policy Loss": -1.5370469093322754, "Value Loss": 12.252367973327637, "_runtime": 5865.024642705917, "_timestamp": 1585603234.6575122, "_step": 79}
{"Episode reward": -96.50016314955045, "Episode length": 999, "Policy Loss": -1.8261544704437256, "Value Loss": 0.5669280290603638, "_runtime": 5866.594032526016, "_timestamp": 1585603236.226902, "_step": 80}
{"Episode reward": -96.08646896593811, "Episode length": 999, "Policy Loss": -1.5370442867279053, "Value Loss": 1.899019479751587, "_runtime": 5868.166051387787, "_timestamp": 1585603237.7989209, "_step": 81}
{"Episode reward": -95.29496905417929, "Episode length": 999, "Policy Loss": -1.4195525646209717, "Value Loss": 1.482252836227417, "_runtime": 5869.738185405731, "_timestamp": 1585603239.371055, "_step": 82}
{"Episode reward": -96.51224196847015, "Episode length": 999, "Policy Loss": -1.7791184186935425, "Value Loss": 0.36968696117401123, "_runtime": 5871.344834089279, "_timestamp": 1585603240.9777036, "_step": 83}
{"Episode reward": -92.80664095134745, "Episode length": 999, "Policy Loss": -1.6559314727783203, "Value Loss": 2.1852471828460693, "_runtime": 5872.920208692551, "_timestamp": 1585603242.5530782, "_step": 84}
{"Episode reward": -96.65604615226758, "Episode length": 999, "Policy Loss": -1.6041226387023926, "Value Loss": 1.2145414352416992, "_runtime": 5874.486512184143, "_timestamp": 1585603244.1193817, "_step": 85}
{"Episode reward": -92.23617447349154, "Episode length": 999, "Policy Loss": -1.5520350933074951, "Value Loss": 0.6196845173835754, "_runtime": 5876.066734313965, "_timestamp": 1585603245.6996038, "_step": 86}
{"Episode reward": -91.85522858324433, "Episode length": 999, "Policy Loss": -1.4248989820480347, "Value Loss": 0.4663759171962738, "_runtime": 5877.6467542648315, "_timestamp": 1585603247.2796237, "_step": 87}
{"Episode reward": -95.98365886404078, "Episode length": 999, "Policy Loss": -1.576968789100647, "Value Loss": 0.28787940740585327, "_runtime": 5879.224713087082, "_timestamp": 1585603248.8575826, "_step": 88}
{"Episode reward": -96.95261404846357, "Episode length": 999, "Policy Loss": -1.619300127029419, "Value Loss": 0.5545943975448608, "_runtime": 5880.804735422134, "_timestamp": 1585603250.437605, "_step": 89}
{"Episode reward": -96.8844482975515, "Episode length": 999, "Policy Loss": -1.5408223867416382, "Value Loss": 1.4366586208343506, "_runtime": 5882.385764837265, "_timestamp": 1585603252.0186343, "_step": 90}
{"Episode reward": -95.97678709286507, "Episode length": 999, "Policy Loss": -1.4770253896713257, "Value Loss": 0.7195332050323486, "_runtime": 5883.951684713364, "_timestamp": 1585603253.5845542, "_step": 91}
{"Episode reward": -97.13201320901689, "Episode length": 999, "Policy Loss": -1.4741106033325195, "Value Loss": 0.24728964269161224, "_runtime": 5885.533629894257, "_timestamp": 1585603255.1664994, "_step": 92}
{"Episode reward": -92.45947409377283, "Episode length": 999, "Policy Loss": -1.900370717048645, "Value Loss": 1.919662356376648, "_runtime": 5887.1111624240875, "_timestamp": 1585603256.744032, "_step": 93}
{"Episode reward": -96.6844532515899, "Episode length": 999, "Policy Loss": -1.4540375471115112, "Value Loss": 0.21243637800216675, "_runtime": 5888.677349090576, "_timestamp": 1585603258.3102186, "_step": 94}
{"Episode reward": -96.39809003170828, "Episode length": 999, "Policy Loss": -1.434872031211853, "Value Loss": 0.1744297295808792, "_runtime": 5890.247301340103, "_timestamp": 1585603259.8801708, "_step": 95}
{"Episode reward": -96.06950894249485, "Episode length": 999, "Policy Loss": -1.4299399852752686, "Value Loss": 0.15964655578136444, "_runtime": 5891.828544855118, "_timestamp": 1585603261.4614143, "_step": 96}
{"Episode reward": -91.5003951358584, "Episode length": 999, "Policy Loss": -0.7098253965377808, "Value Loss": 1.0173873901367188, "_runtime": 5893.4100596904755, "_timestamp": 1585603263.0429292, "_step": 97}
{"Episode reward": -93.23113565733036, "Episode length": 999, "Policy Loss": -0.977531373500824, "Value Loss": 0.6995967030525208, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645, 12.291768074035645]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.2261481285095215, -1.6785540580749512, -0.13095998764038086, 1.4166340827941895, 2.9642281532287598, 4.51182222366333, 6.0594162940979, 7.607010364532471, 9.154603958129883, 10.702198028564453, 12.249792098999023, 13.797386169433594, 15.344980239868164, 16.892574310302734, 18.440168380737305, 19.987762451171875, 21.535356521606445, 23.082950592041016, 24.630544662475586, 26.178138732910156, 27.725732803344727, 29.273324966430664, 30.820920944213867, 32.3685188293457, 33.91611099243164, 35.46370315551758, 37.01129913330078, 38.558895111083984, 40.10648727416992, 41.65407943725586, 43.20167541503906, 44.749271392822266, 46.2968635559082, 47.84445571899414, 49.392051696777344, 50.93964767456055, 52.487239837646484, 54.03483200073242, 55.582427978515625, 57.13002395629883, 58.677616119384766, 60.2252082824707, 61.77280044555664, 63.32040023803711, 64.86798858642578, 66.41558074951172, 67.96318054199219, 69.51077270507812, 71.05836486816406, 72.60595703125, 74.15354919433594, 75.7011489868164, 77.24874114990234, 78.79633331298828, 80.34393310546875, 81.89152526855469, 83.43911743164062, 84.98670959472656, 86.5343017578125, 88.08190155029297, 89.6294937133789, 91.17708587646484, 92.72468566894531, 94.27227783203125, 95.81986999511719]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.499946355819702, -2.3582828044891357, -2.2166194915771484, -2.074955940246582, -1.9332926273345947, -1.7916290760040283, -1.6499656438827515, -1.5083022117614746, -1.3666387796401978, -1.224975347518921, -1.083311915397644, -0.9416484832763672, -0.7999849319458008, -0.6583214998245239, -0.5166580677032471, -0.37499475479125977, -0.23333120346069336, -0.09166765213012695, 0.04999566078186035, 0.19165921211242676, 0.33332252502441406, 0.47498607635498047, 0.6166493892669678, 0.7583129405975342, 0.8999764919281006, 1.041639804840088, 1.1833033561706543, 1.3249666690826416, 1.466630220413208, 1.6082937717437744, 1.7499568462371826, 1.891620397567749, 2.0332839488983154, 2.174947500228882, 2.3166110515594482, 2.4582741260528564, 2.599937677383423, 2.7416012287139893, 2.8832647800445557, 3.024927854537964, 3.1665914058685303, 3.3082549571990967, 3.449918508529663, 3.5915820598602295, 3.7332451343536377, 3.874908685684204, 4.016571998596191, 4.158235549926758, 4.299899101257324, 4.441562652587891, 4.583226203918457, 4.724889755249023, 4.86655330657959, 5.00821590423584, 5.149879455566406, 5.291543006896973, 5.433206558227539, 5.5748701095581055, 5.716533660888672, 5.858197212219238, 5.999859809875488, 6.141523361206055, 6.283186912536621, 6.4248504638671875, 6.566514015197754]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 5.0, 1.0, 5.0, 1.0, 0.0, 5.0, 7.0, 4.0, 7.0, 5.0, 14.0, 11.0, 19.0, 18.0, 23.0, 22.0, 26.0, 40.0, 62.0, 57.0, 22.0, 30.0, 18.0, 20.0, 18.0, 11.0, 6.0, 12.0, 7.0, 5.0, 3.0, 3.0, 2.0, 4.0, 0.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-4.386096954345703, -4.174880027770996, -3.963663339614868, -3.752446413040161, -3.541229486465454, -3.330012798309326, -3.118795871734619, -2.907578945159912, -2.696362018585205, -2.485145330429077, -2.27392840385437, -2.062711477279663, -1.8514947891235352, -1.6402778625488281, -1.429060935974121, -1.2178442478179932, -1.0066273212432861, -0.7954103946685791, -0.5841937065124512, -0.37297677993774414, -0.1617598533630371, 0.04945707321166992, 0.26067399978637695, 0.4718904495239258, 0.6831073760986328, 0.8943243026733398, 1.1055412292480469, 1.316758155822754, 1.527975082397461, 1.7391915321350098, 1.9504084587097168, 2.161625385284424, 2.372842311859131, 2.584059238433838, 2.795276165008545, 3.006493091583252, 3.217709541320801, 3.428926467895508, 3.640143394470215, 3.851360321044922, 4.062577247619629, 4.273794174194336, 4.485011100769043, 4.69622802734375, 4.907444953918457, 5.118660926818848, 5.329877853393555, 5.541094779968262, 5.752311706542969, 5.963528633117676, 6.174745559692383, 6.38596248626709, 6.597179412841797, 6.808396339416504, 7.019613265991211, 7.230830192565918, 7.442047119140625, 7.653264045715332, 7.864480018615723, 8.07569694519043, 8.286913871765137, 8.498130798339844, 8.70934772491455, 8.920564651489258, 9.131781578063965]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-17.737796783447266, -17.059879302978516, -16.3819637298584, -15.704046249389648, -15.026129722595215, -14.348213195800781, -13.670295715332031, -12.992379188537598, -12.314462661743164, -11.63654613494873, -10.958629608154297, -10.280712127685547, -9.602795600891113, -8.92487907409668, -8.24696159362793, -7.569045066833496, -6.8911285400390625, -6.213212013244629, -5.535295486450195, -4.857378005981445, -4.179461479187012, -3.501544952392578, -2.823627471923828, -2.1457109451293945, -1.467794418334961, -0.7898769378662109, -0.11196136474609375, 0.5659561157226562, 1.2438735961914062, 1.9217891693115234, 2.5997066497802734, 3.2776222229003906, 3.9555397033691406, 4.633457183837891, 5.311372756958008, 5.989290237426758, 6.667205810546875, 7.345123291015625, 8.023040771484375, 8.700956344604492, 9.378873825073242, 10.056791305541992, 10.73470687866211, 11.41262435913086, 12.09054183959961, 12.768457412719727, 13.446374893188477, 14.124290466308594, 14.802207946777344, 15.480125427246094, 16.158042907714844, 16.835956573486328, 17.513874053955078, 18.191791534423828, 18.869709014892578, 19.547626495361328, 20.225543975830078, 20.903457641601562, 21.581375122070312, 22.259292602539062, 22.937210083007812, 23.615127563476562, 24.293041229248047, 24.970958709716797, 25.648876190185547]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 3.0, 2.0, 0.0, 4.0, 3.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0], "bins": [-16.9476375579834, -16.490842819213867, -16.034048080444336, -15.577252388000488, -15.120457649230957, -14.663662910461426, -14.206867218017578, -13.750072479248047, -13.293277740478516, -12.836483001708984, -12.379688262939453, -11.922892570495605, -11.466097831726074, -11.009303092956543, -10.552507400512695, -10.095712661743164, -9.638917922973633, -9.182123184204102, -8.72532844543457, -8.268532752990723, -7.811738014221191, -7.35494327545166, -6.8981475830078125, -6.441352844238281, -5.98455810546875, -5.527763366699219, -5.0709686279296875, -4.61417293548584, -4.157378196716309, -3.7005834579467773, -3.2437877655029297, -2.7869930267333984, -2.330198287963867, -1.873403549194336, -1.4166088104248047, -0.959813117980957, -0.5030193328857422, -0.046222686767578125, 0.4105720520019531, 0.8673667907714844, 1.3241615295410156, 1.7809562683105469, 2.237751007080078, 2.6945457458496094, 3.1513423919677734, 3.6081371307373047, 4.064931869506836, 4.521726608276367, 4.978521347045898, 5.43531608581543, 5.892110824584961, 6.348905563354492, 6.805700302124023, 7.2624969482421875, 7.719291687011719, 8.17608642578125, 8.632881164550781, 9.089675903320312, 9.546470642089844, 10.003265380859375, 10.460062026977539, 10.91685676574707, 11.373651504516602, 11.830446243286133, 12.287240982055664]}, "_runtime": 5895.015951395035, "_timestamp": 1585603264.6488209, "_step": 98}
{"Episode reward": -91.56105336534199, "Episode length": 999, "Policy Loss": -1.7387592792510986, "Value Loss": 0.934921145439148, "_runtime": 5896.594172239304, "_timestamp": 1585603266.2270417, "_step": 99}
{"Episode reward": -96.93810488365142, "Episode length": 999, "Policy Loss": -1.3540438413619995, "Value Loss": 0.1562681943178177, "_runtime": 5898.166595220566, "_timestamp": 1585603267.7994647, "_step": 100}
{"Episode reward": -96.53706596862821, "Episode length": 999, "Policy Loss": -1.3115928173065186, "Value Loss": 0.20964154601097107, "_runtime": 5899.733845710754, "_timestamp": 1585603269.3667152, "_step": 101}
{"Episode reward": -94.20597445772334, "Episode length": 999, "Policy Loss": -1.299412488937378, "Value Loss": 0.31716811656951904, "_runtime": 5901.309727430344, "_timestamp": 1585603270.942597, "_step": 102}
{"Episode reward": -97.37185627725187, "Episode length": 999, "Policy Loss": -1.2955163717269897, "Value Loss": 0.1308804452419281, "_runtime": 5902.873899936676, "_timestamp": 1585603272.5067694, "_step": 103}
{"Episode reward": -94.39248909627715, "Episode length": 999, "Policy Loss": -0.9946292042732239, "Value Loss": 0.39038264751434326, "_runtime": 5904.444349765778, "_timestamp": 1585603274.0772192, "_step": 104}
{"Episode reward": -97.52898688511706, "Episode length": 999, "Policy Loss": -1.2545329332351685, "Value Loss": 0.12972821295261383, "_runtime": 5906.001053094864, "_timestamp": 1585603275.6339226, "_step": 105}
{"Episode reward": -95.78663918918645, "Episode length": 999, "Policy Loss": -1.2110143899917603, "Value Loss": 0.15945415198802948, "_runtime": 5906.938690662384, "_timestamp": 1585603276.5715601, "_step": 106}
{"Episode reward": 48.43794364532062, "Episode length": 588, "Policy Loss": -0.28341805934906006, "Value Loss": 17.193994522094727, "_runtime": 5908.491856575012, "_timestamp": 1585603278.124726, "_step": 107}
{"Episode reward": -96.59263931502345, "Episode length": 999, "Policy Loss": -1.2216594219207764, "Value Loss": 0.26649120450019836, "_runtime": 5910.059332847595, "_timestamp": 1585603279.6922023, "_step": 108}
{"Episode reward": -92.4161830376691, "Episode length": 999, "Policy Loss": -1.502296805381775, "Value Loss": 0.8044883608818054, "_runtime": 5911.572949886322, "_timestamp": 1585603281.2058194, "_step": 109}
{"Episode reward": -96.48690540571363, "Episode length": 999, "Policy Loss": -1.1561145782470703, "Value Loss": 0.23063775897026062, "_runtime": 5913.131467819214, "_timestamp": 1585603282.7643373, "_step": 110}
{"Episode reward": -96.81623347543712, "Episode length": 999, "Policy Loss": -1.1298216581344604, "Value Loss": 0.11031138896942139, "_runtime": 5914.699159860611, "_timestamp": 1585603284.3320293, "_step": 111}
{"Episode reward": -96.183574873157, "Episode length": 999, "Policy Loss": -1.0661569833755493, "Value Loss": 0.27918070554733276, "_runtime": 5916.255130290985, "_timestamp": 1585603285.8879998, "_step": 112}
{"Episode reward": -92.4723799578542, "Episode length": 999, "Policy Loss": -0.4183112680912018, "Value Loss": 1.7932125329971313, "_runtime": 5917.813200473785, "_timestamp": 1585603287.44607, "_step": 113}
{"Episode reward": -96.8754180915093, "Episode length": 999, "Policy Loss": -1.070572018623352, "Value Loss": 0.12121991813182831, "_runtime": 5919.417723894119, "_timestamp": 1585603289.0505934, "_step": 114}
{"Episode reward": -96.50716103123219, "Episode length": 999, "Policy Loss": -1.065941333770752, "Value Loss": 0.16684266924858093, "_runtime": 5920.982008457184, "_timestamp": 1585603290.614878, "_step": 115}
{"Episode reward": -97.13687059815183, "Episode length": 999, "Policy Loss": -1.086124300956726, "Value Loss": 0.3052670359611511, "_runtime": 5922.553116083145, "_timestamp": 1585603292.1859856, "_step": 116}
{"Episode reward": -96.4443065804178, "Episode length": 999, "Policy Loss": -1.1598103046417236, "Value Loss": 1.3188281059265137, "_runtime": 5924.12051653862, "_timestamp": 1585603293.753386, "_step": 117}
{"Episode reward": -93.96286123110431, "Episode length": 999, "Policy Loss": -1.5251060724258423, "Value Loss": 2.910290479660034, "_runtime": 5925.674067020416, "_timestamp": 1585603295.3069365, "_step": 118}
{"Episode reward": -93.32813325345617, "Episode length": 999, "Policy Loss": -0.8132106065750122, "Value Loss": 0.29467740654945374, "_runtime": 5927.237228155136, "_timestamp": 1585603296.8700976, "_step": 119}
{"Episode reward": -94.915615602254, "Episode length": 999, "Policy Loss": -0.4602273404598236, "Value Loss": 2.6177070140838623, "_runtime": 5928.7829604148865, "_timestamp": 1585603298.41583, "_step": 120}
{"Episode reward": -94.40056688404562, "Episode length": 999, "Policy Loss": -0.323596715927124, "Value Loss": 3.330526828765869, "_runtime": 5930.349072933197, "_timestamp": 1585603299.9819424, "_step": 121}
{"Episode reward": -96.21708699442296, "Episode length": 999, "Policy Loss": -1.0431309938430786, "Value Loss": 0.13844098150730133, "_runtime": 5931.917835712433, "_timestamp": 1585603301.5507052, "_step": 122}
{"Episode reward": -97.31085852591728, "Episode length": 999, "Policy Loss": -1.03629732131958, "Value Loss": 0.718639612197876, "_runtime": 5933.488101243973, "_timestamp": 1585603303.1209707, "_step": 123}
{"Episode reward": -89.86836807888787, "Episode length": 999, "Policy Loss": -2.7684149742126465, "Value Loss": 13.648076057434082, "_runtime": 5935.044498920441, "_timestamp": 1585603304.6773684, "_step": 124}
{"Episode reward": -96.55102050976438, "Episode length": 999, "Policy Loss": -1.1291112899780273, "Value Loss": 0.5829645991325378, "_runtime": 5936.603006601334, "_timestamp": 1585603306.235876, "_step": 125}
{"Episode reward": -94.38274656180536, "Episode length": 999, "Policy Loss": -0.3631097078323364, "Value Loss": 5.2621917724609375, "_runtime": 5938.164314746857, "_timestamp": 1585603307.7971842, "_step": 126}
{"Episode reward": -91.05452054459558, "Episode length": 999, "Policy Loss": 0.9181714057922363, "Value Loss": 17.089303970336914, "_runtime": 5939.745911121368, "_timestamp": 1585603309.3787806, "_step": 127}
{"Episode reward": -90.85145628864414, "Episode length": 999, "Policy Loss": -0.7779419422149658, "Value Loss": 0.13097354769706726, "_runtime": 5941.35352730751, "_timestamp": 1585603310.9863968, "_step": 128}
{"Episode reward": -94.38640399643648, "Episode length": 999, "Policy Loss": -1.387005090713501, "Value Loss": 13.179876327514648, "_runtime": 5942.933712244034, "_timestamp": 1585603312.5665817, "_step": 129}
{"Episode reward": -97.29286726240986, "Episode length": 999, "Policy Loss": -0.7568036913871765, "Value Loss": 0.9617815017700195, "_runtime": 5944.511954784393, "_timestamp": 1585603314.1448243, "_step": 130}
{"Episode reward": -95.85242829733116, "Episode length": 999, "Policy Loss": -0.9502087831497192, "Value Loss": 2.1992709636688232, "_runtime": 5946.081608772278, "_timestamp": 1585603315.7144783, "_step": 131}
{"Episode reward": -95.36454317921722, "Episode length": 999, "Policy Loss": -0.9419965744018555, "Value Loss": 0.24000224471092224, "_runtime": 5947.66287112236, "_timestamp": 1585603317.2957406, "_step": 132}
{"Episode reward": -96.1213842159399, "Episode length": 999, "Policy Loss": -0.8871095180511475, "Value Loss": 0.6359425783157349, "_runtime": 5949.241413593292, "_timestamp": 1585603318.874283, "_step": 133}
{"Episode reward": -96.84999483965578, "Episode length": 999, "Policy Loss": -0.9677522778511047, "Value Loss": 2.6099936962127686, "_runtime": 5950.823863267899, "_timestamp": 1585603320.4567327, "_step": 134}
{"Episode reward": -97.39455531642805, "Episode length": 999, "Policy Loss": -0.786244809627533, "Value Loss": 2.3876914978027344, "_runtime": 5952.402963638306, "_timestamp": 1585603322.0358331, "_step": 135}
{"Episode reward": -96.89211750319011, "Episode length": 999, "Policy Loss": -0.8135088086128235, "Value Loss": 0.30773645639419556, "_runtime": 5953.9677946567535, "_timestamp": 1585603323.6006641, "_step": 136}
{"Episode reward": -96.69847580691496, "Episode length": 999, "Policy Loss": -0.8364235758781433, "Value Loss": 1.575556993484497, "_runtime": 5955.552582979202, "_timestamp": 1585603325.1854525, "_step": 137}
{"Episode reward": -97.23070131691279, "Episode length": 999, "Policy Loss": -0.7163177132606506, "Value Loss": 1.3222694396972656, "_runtime": 5957.1182742118835, "_timestamp": 1585603326.7511437, "_step": 138}
{"Episode reward": -90.7952232001279, "Episode length": 999, "Policy Loss": 0.20426972210407257, "Value Loss": 1.5181448459625244, "_runtime": 5958.701694726944, "_timestamp": 1585603328.3345642, "_step": 139}
{"Episode reward": -96.87922436093565, "Episode length": 999, "Policy Loss": -0.6168681979179382, "Value Loss": 0.6626271605491638, "_runtime": 5960.285753965378, "_timestamp": 1585603329.9186234, "_step": 140}
{"Episode reward": -96.92083992895999, "Episode length": 999, "Policy Loss": -0.5634923577308655, "Value Loss": 1.4083998203277588, "_runtime": 5961.870832443237, "_timestamp": 1585603331.503702, "_step": 141}
{"Episode reward": -92.61931764545376, "Episode length": 999, "Policy Loss": -3.0902717113494873, "Value Loss": 28.324237823486328, "_runtime": 5963.4547028541565, "_timestamp": 1585603333.0875723, "_step": 142}
{"Episode reward": -96.23598259163033, "Episode length": 999, "Policy Loss": -0.7615523934364319, "Value Loss": 1.7227180004119873, "_runtime": 5965.073137760162, "_timestamp": 1585603334.7060072, "_step": 143}
{"Episode reward": -95.01777244362768, "Episode length": 999, "Policy Loss": 0.037630315870046616, "Value Loss": 3.318796157836914, "_runtime": 5966.65734577179, "_timestamp": 1585603336.2902153, "_step": 144}
{"Episode reward": -96.83160717710759, "Episode length": 999, "Policy Loss": -0.2758314609527588, "Value Loss": 3.9682703018188477, "_runtime": 5968.229608535767, "_timestamp": 1585603337.862478, "_step": 145}
{"Episode reward": -96.37828585045419, "Episode length": 999, "Policy Loss": -0.594634473323822, "Value Loss": 0.7996858954429626, "_runtime": 5969.818590641022, "_timestamp": 1585603339.4514601, "_step": 146}
{"Episode reward": -96.59406661605306, "Episode length": 999, "Policy Loss": -0.5203563570976257, "Value Loss": 8.374155044555664, "_runtime": 5971.402235031128, "_timestamp": 1585603341.0351045, "_step": 147}
{"Episode reward": -88.74963526956509, "Episode length": 999, "Policy Loss": 5.33186674118042, "Value Loss": 61.15658950805664, "_runtime": 5972.977494955063, "_timestamp": 1585603342.6103644, "_step": 148}
{"Episode reward": -92.65992771261827, "Episode length": 999, "Policy Loss": -3.1051671504974365, "Value Loss": 15.128713607788086, "_runtime": 5974.5550055503845, "_timestamp": 1585603344.187875, "_step": 149}
{"Episode reward": -96.65846615445493, "Episode length": 999, "Policy Loss": -0.30539536476135254, "Value Loss": 14.25876235961914, "_runtime": 5976.132120609283, "_timestamp": 1585603345.76499, "_step": 150}
{"Episode reward": -96.6784863199417, "Episode length": 999, "Policy Loss": -0.6029915809631348, "Value Loss": 17.344053268432617, "_runtime": 5977.707816123962, "_timestamp": 1585603347.3406856, "_step": 151}
{"Episode reward": -96.16559795902701, "Episode length": 999, "Policy Loss": -0.6750010251998901, "Value Loss": 2.000576972961426, "_runtime": 5979.276894330978, "_timestamp": 1585603348.9097638, "_step": 152}
{"Episode reward": -97.71482178569748, "Episode length": 999, "Policy Loss": -1.1445096731185913, "Value Loss": 16.75661277770996, "_runtime": 5980.845765590668, "_timestamp": 1585603350.478635, "_step": 153}
{"Episode reward": -96.32589238846272, "Episode length": 999, "Policy Loss": -0.9351212382316589, "Value Loss": 8.514341354370117, "_runtime": 5982.411869525909, "_timestamp": 1585603352.044739, "_step": 154}
{"Episode reward": -96.60565231487074, "Episode length": 999, "Policy Loss": -0.6343226432800293, "Value Loss": 0.6225764751434326, "_runtime": 5983.969361782074, "_timestamp": 1585603353.6022313, "_step": 155}
{"Episode reward": -96.17181841696761, "Episode length": 999, "Policy Loss": -0.5052635669708252, "Value Loss": 5.553041458129883, "_runtime": 5985.549632072449, "_timestamp": 1585603355.1825016, "_step": 156}
{"Episode reward": -97.15419883859812, "Episode length": 999, "Policy Loss": -0.7729443907737732, "Value Loss": 0.6743305921554565, "_runtime": 5987.120750427246, "_timestamp": 1585603356.75362, "_step": 157}
{"Episode reward": -97.53932768326713, "Episode length": 999, "Policy Loss": -0.4925905466079712, "Value Loss": 3.684412956237793, "_runtime": 5988.724838972092, "_timestamp": 1585603358.3577085, "_step": 158}
{"Episode reward": -89.84062204455329, "Episode length": 999, "Policy Loss": 0.14809927344322205, "Value Loss": 4.462830066680908, "_runtime": 5990.294216632843, "_timestamp": 1585603359.927086, "_step": 159}
{"Episode reward": -96.52944390579577, "Episode length": 999, "Policy Loss": -0.9090339541435242, "Value Loss": 1.435880422592163, "_runtime": 5991.38626241684, "_timestamp": 1585603361.019132, "_step": 160}
{"Episode reward": 37.28813610762, "Episode length": 690, "Policy Loss": 0.3947798013687134, "Value Loss": 18.606271743774414, "_runtime": 5992.95251083374, "_timestamp": 1585603362.5853803, "_step": 161}
{"Episode reward": -93.01192349625347, "Episode length": 999, "Policy Loss": -0.7444574236869812, "Value Loss": 2.414740800857544, "_runtime": 5994.5204157829285, "_timestamp": 1585603364.1532853, "_step": 162}
{"Episode reward": -97.23199050127157, "Episode length": 999, "Policy Loss": -0.839397668838501, "Value Loss": 0.27792471647262573, "_runtime": 5996.066771030426, "_timestamp": 1585603365.6996405, "_step": 163}
{"Episode reward": -96.17657771941866, "Episode length": 999, "Policy Loss": -1.0473648309707642, "Value Loss": 2.103476047515869, "_runtime": 5997.621800899506, "_timestamp": 1585603367.2546704, "_step": 164}
{"Episode reward": -96.98534001706969, "Episode length": 999, "Policy Loss": -0.8091212511062622, "Value Loss": 1.0515550374984741, "_runtime": 5999.191070318222, "_timestamp": 1585603368.8239398, "_step": 165}
{"Episode reward": -96.58110508598625, "Episode length": 999, "Policy Loss": -0.7097762227058411, "Value Loss": 1.347753643989563, "_runtime": 6000.742132663727, "_timestamp": 1585603370.3750021, "_step": 166}
{"Episode reward": -96.89265824811068, "Episode length": 999, "Policy Loss": -1.0433152914047241, "Value Loss": 2.4427237510681152, "_runtime": 6002.308121681213, "_timestamp": 1585603371.9409912, "_step": 167}
{"Episode reward": -96.26244413310854, "Episode length": 999, "Policy Loss": -0.9120323061943054, "Value Loss": 3.252203941345215, "_runtime": 6003.876036167145, "_timestamp": 1585603373.5089056, "_step": 168}
{"Episode reward": -95.91296400182236, "Episode length": 999, "Policy Loss": -0.9012729525566101, "Value Loss": 1.7302311658859253, "_runtime": 6005.432299613953, "_timestamp": 1585603375.065169, "_step": 169}
{"Episode reward": -95.98901934783807, "Episode length": 999, "Policy Loss": -0.7855578064918518, "Value Loss": 0.8741995096206665, "_runtime": 6006.998661994934, "_timestamp": 1585603376.6315315, "_step": 170}
{"Episode reward": -96.59628891740542, "Episode length": 999, "Policy Loss": -0.7422325611114502, "Value Loss": 0.2542482018470764, "_runtime": 6008.555118560791, "_timestamp": 1585603378.187988, "_step": 171}
{"Episode reward": -91.93223630535726, "Episode length": 999, "Policy Loss": -1.5081363916397095, "Value Loss": 3.8833978176116943, "_runtime": 6010.122092247009, "_timestamp": 1585603379.7549617, "_step": 172}
{"Episode reward": -96.86430516261956, "Episode length": 999, "Policy Loss": -0.6780370473861694, "Value Loss": 0.2857499420642853, "_runtime": 6011.732710599899, "_timestamp": 1585603381.36558, "_step": 173}
{"Episode reward": -97.40907908576474, "Episode length": 999, "Policy Loss": -0.52205491065979, "Value Loss": 1.7530663013458252, "_runtime": 6013.28980588913, "_timestamp": 1585603382.9226754, "_step": 174}
{"Episode reward": -94.95512163723097, "Episode length": 999, "Policy Loss": -0.19433937966823578, "Value Loss": 8.20979118347168, "_runtime": 6014.472058773041, "_timestamp": 1585603384.1049283, "_step": 175}
{"Episode reward": 31.505692383388492, "Episode length": 750, "Policy Loss": 1.433754563331604, "Value Loss": 26.15472984313965, "_runtime": 6016.039427042007, "_timestamp": 1585603385.6722965, "_step": 176}
{"Episode reward": -91.19829536743939, "Episode length": 999, "Policy Loss": -0.5161741375923157, "Value Loss": 4.627288818359375, "_runtime": 6017.609171628952, "_timestamp": 1585603387.242041, "_step": 177}
{"Episode reward": -96.8327998818973, "Episode length": 999, "Policy Loss": -0.41678300499916077, "Value Loss": 0.23590116202831268, "_runtime": 6019.158821582794, "_timestamp": 1585603388.791691, "_step": 178}
{"Episode reward": -95.7879583573006, "Episode length": 999, "Policy Loss": -0.4013806879520416, "Value Loss": 0.3006521761417389, "_runtime": 6020.728219032288, "_timestamp": 1585603390.3610885, "_step": 179}
{"Episode reward": -97.44537101552177, "Episode length": 999, "Policy Loss": -0.42547354102134705, "Value Loss": 2.281193971633911, "_runtime": 6022.294735193253, "_timestamp": 1585603391.9276047, "_step": 180}
{"Episode reward": -96.3868771508829, "Episode length": 999, "Policy Loss": -0.8327151536941528, "Value Loss": 8.826871871948242, "_runtime": 6023.8496952056885, "_timestamp": 1585603393.4825647, "_step": 181}
{"Episode reward": -96.34238693604146, "Episode length": 999, "Policy Loss": -0.5843530893325806, "Value Loss": 10.515235900878906, "_runtime": 6025.213645458221, "_timestamp": 1585603394.846515, "_step": 182}
{"Episode reward": 16.768715240271234, "Episode length": 873, "Policy Loss": -0.7058544754981995, "Value Loss": 23.550395965576172, "_runtime": 6026.368619680405, "_timestamp": 1585603396.0014892, "_step": 183}
{"Episode reward": 30.073714666963227, "Episode length": 737, "Policy Loss": -1.2571996450424194, "Value Loss": 23.075443267822266, "_runtime": 6027.931508302689, "_timestamp": 1585603397.5643778, "_step": 184}
{"Episode reward": -94.01762877402248, "Episode length": 999, "Policy Loss": -1.0334765911102295, "Value Loss": 3.0524682998657227, "_runtime": 6029.493131637573, "_timestamp": 1585603399.1260011, "_step": 185}
{"Episode reward": -96.39989954068398, "Episode length": 999, "Policy Loss": -0.2436189502477646, "Value Loss": 1.083808183670044, "_runtime": 6031.02965593338, "_timestamp": 1585603400.6625254, "_step": 186}
{"Episode reward": -95.2538773351147, "Episode length": 999, "Policy Loss": 0.7589817047119141, "Value Loss": 12.035638809204102, "_runtime": 6032.582767009735, "_timestamp": 1585603402.2156365, "_step": 187}
{"Episode reward": -96.04820843001893, "Episode length": 999, "Policy Loss": 0.624826192855835, "Value Loss": 16.359527587890625, "_runtime": 6034.183737754822, "_timestamp": 1585603403.8166072, "_step": 188}
{"Episode reward": -96.75424003278216, "Episode length": 999, "Policy Loss": -0.08606202900409698, "Value Loss": 3.1603710651397705, "_runtime": 6035.750072479248, "_timestamp": 1585603405.382942, "_step": 189}
{"Episode reward": -96.77292114837624, "Episode length": 999, "Policy Loss": -0.2279769331216812, "Value Loss": 2.668762683868408, "_runtime": 6037.315420150757, "_timestamp": 1585603406.9482896, "_step": 190}
{"Episode reward": -97.12591919856442, "Episode length": 999, "Policy Loss": -0.12309468537569046, "Value Loss": 4.001039505004883, "_runtime": 6038.872116327286, "_timestamp": 1585603408.5049858, "_step": 191}
{"Episode reward": -96.73060977637313, "Episode length": 999, "Policy Loss": 0.2825064957141876, "Value Loss": 2.935332775115967, "_runtime": 6040.428843736649, "_timestamp": 1585603410.0617132, "_step": 192}
{"Episode reward": -96.52445839975445, "Episode length": 999, "Policy Loss": 0.3448159098625183, "Value Loss": 2.3082988262176514, "_runtime": 6041.986078977585, "_timestamp": 1585603411.6189485, "_step": 193}
{"Episode reward": -97.00712556842265, "Episode length": 999, "Policy Loss": 0.5832619071006775, "Value Loss": 2.4302661418914795, "_runtime": 6043.5469789505005, "_timestamp": 1585603413.1798484, "_step": 194}
{"Episode reward": -96.97031604390604, "Episode length": 999, "Policy Loss": 0.21142324805259705, "Value Loss": 0.38811513781547546, "_runtime": 6045.096872806549, "_timestamp": 1585603414.7297423, "_step": 195}
{"Episode reward": -96.5334773294977, "Episode length": 999, "Policy Loss": 0.1408761739730835, "Value Loss": 1.1705702543258667, "_runtime": 6046.654569149017, "_timestamp": 1585603416.2874386, "_step": 196}
{"Episode reward": -96.93643542379283, "Episode length": 999, "Policy Loss": 0.2368580847978592, "Value Loss": 2.9873743057250977, "_runtime": 6048.224819421768, "_timestamp": 1585603417.857689, "_step": 197}
{"Episode reward": -95.96789475173107, "Episode length": 999, "Policy Loss": 0.4419584274291992, "Value Loss": 1.7614021301269531, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789, 9.062173843383789]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-49.756404876708984, -48.61858367919922, -47.48075866699219, -46.34293746948242, -45.205116271972656, -44.06729507446289, -42.929473876953125, -41.791648864746094, -40.65382766723633, -39.51600646972656, -38.37818145751953, -37.240360260009766, -36.1025390625, -34.964717864990234, -33.82689666748047, -32.68907165527344, -31.551250457763672, -30.413429260253906, -29.275606155395508, -28.13778305053711, -26.999961853027344, -25.862140655517578, -24.72431755065918, -23.58649444580078, -22.448673248291016, -21.31085205078125, -20.17302894592285, -19.035205841064453, -17.897384643554688, -16.759563446044922, -15.62173843383789, -14.483917236328125, -13.34609603881836, -12.208274841308594, -11.070453643798828, -9.932628631591797, -8.794807434082031, -7.656986236572266, -6.519161224365234, -5.381340026855469, -4.243518829345703, -3.1056976318359375, -1.9678764343261719, -0.8300514221191406, 0.307769775390625, 1.4455909729003906, 2.583415985107422, 3.7212371826171875, 4.859058380126953, 5.996879577636719, 7.134700775146484, 8.272525787353516, 9.410346984863281, 10.548168182373047, 11.685993194580078, 12.823814392089844, 13.96163558959961, 15.09946060180664, 16.23727798461914, 17.375102996826172, 18.512928009033203, 19.650745391845703, 20.788570404052734, 21.926387786865234, 23.064212799072266]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15505383908748627, -0.0339985266327858, 0.08705678582191467, 0.20811210572719574, 0.3291674256324768, 0.4502227306365967, 0.5712780356407166, 0.6923333406448364, 0.8133886456489563, 0.9344439506530762, 1.0554993152618408, 1.176554560661316, 1.2976099252700806, 1.4186651706695557, 1.5397205352783203, 1.6607757806777954, 1.78183114528656, 1.9028863906860352, 2.0239417552948, 2.1449971199035645, 2.266052484512329, 2.3871076107025146, 2.5081629753112793, 2.629218339920044, 2.7502737045288086, 2.8713290691375732, 2.992384195327759, 3.1134395599365234, 3.234494924545288, 3.3555502891540527, 3.4766054153442383, 3.597660779953003, 3.7187161445617676, 3.8397715091705322, 3.9608266353607178, 4.081882476806641, 4.202937602996826, 4.323992729187012, 4.4450483322143555, 4.566103458404541, 4.687159061431885, 4.80821418762207, 4.929269313812256, 5.0503249168396, 5.171380043029785, 5.292435646057129, 5.4134907722473145, 5.5345458984375, 5.655601501464844, 5.776656627655029, 5.897712230682373, 6.018767356872559, 6.139822483062744, 6.260878086090088, 6.381933212280273, 6.502988338470459, 6.624043941497803, 6.745099067687988, 6.866154670715332, 6.987209796905518, 7.108264923095703, 7.229320526123047, 7.350375652313232, 7.471431255340576, 7.592486381530762]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 6.0, 5.0, 3.0, 4.0, 2.0, 3.0, 11.0, 10.0, 11.0, 4.0, 18.0, 18.0, 12.0, 15.0, 25.0, 30.0, 48.0, 107.0, 52.0, 19.0, 20.0, 16.0, 7.0, 5.0, 5.0, 8.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-5.904716491699219, -5.700159549713135, -5.495602130889893, -5.291045188903809, -5.086488246917725, -4.881931304931641, -4.677373886108398, -4.4728169441223145, -4.2682600021362305, -4.063702583312988, -3.8591456413269043, -3.654588460922241, -3.450031280517578, -3.245474338531494, -3.040917158126831, -2.836360216140747, -2.631803035736084, -2.427245855331421, -2.222688913345337, -2.018131732940674, -1.8135747909545898, -1.6090173721313477, -1.4044604301452637, -1.1999034881591797, -0.9953460693359375, -0.7907891273498535, -0.5862321853637695, -0.38167524337768555, -0.17711782455444336, 0.027439117431640625, 0.2319960594177246, 0.4365534782409668, 0.6411104202270508, 0.8456673622131348, 1.050224781036377, 1.254781723022461, 1.459338665008545, 1.663896083831787, 1.868453025817871, 2.073009967803955, 2.277566909790039, 2.4821243286132812, 2.6866817474365234, 2.891238212585449, 3.0957956314086914, 3.3003530502319336, 3.5049095153808594, 3.7094669342041016, 3.9140243530273438, 4.1185808181762695, 4.323138236999512, 4.5276947021484375, 4.73225212097168, 4.936809539794922, 5.141366004943848, 5.34592342376709, 5.550480842590332, 5.755037307739258, 5.9595947265625, 6.164152145385742, 6.368708610534668, 6.57326602935791, 6.777823448181152, 6.982379913330078, 7.18693733215332]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0], "bins": [-40.80648422241211, -39.683433532714844, -38.56038284301758, -37.43732833862305, -36.31427764892578, -35.191226959228516, -34.06817626953125, -32.94512176513672, -31.822071075439453, -30.699020385742188, -29.575969696044922, -28.452917098999023, -27.329866409301758, -26.20681381225586, -25.083763122558594, -23.960710525512695, -22.83765983581543, -21.714609146118164, -20.591556549072266, -19.468505859375, -18.3454532623291, -17.222402572631836, -16.099349975585938, -14.976299285888672, -13.853248596191406, -12.730195999145508, -11.607145309448242, -10.484092712402344, -9.361042022705078, -8.237991333007812, -7.114936828613281, -5.991886138916016, -4.86883544921875, -3.7457847595214844, -2.6227340698242188, -1.4996795654296875, -0.3766288757324219, 0.7464218139648438, 1.8694725036621094, 2.9925270080566406, 4.115577697753906, 5.238628387451172, 6.3616790771484375, 7.484729766845703, 8.607784271240234, 9.7308349609375, 10.853885650634766, 11.976936340332031, 13.099987030029297, 14.223041534423828, 15.346092224121094, 16.46914291381836, 17.592193603515625, 18.715248107910156, 19.838298797607422, 20.961349487304688, 22.084400177001953, 23.207454681396484, 24.330501556396484, 25.453556060791016, 26.576610565185547, 27.699657440185547, 28.822711944580078, 29.945758819580078, 31.06881332397461]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-22.194860458374023, -21.52188491821289, -20.848909378051758, -20.175933837890625, -19.502958297729492, -18.82998275756836, -18.157005310058594, -17.48402976989746, -16.811054229736328, -16.138078689575195, -15.465103149414062, -14.79212760925293, -14.119152069091797, -13.446176528930664, -12.773200035095215, -12.100224494934082, -11.42724895477295, -10.754273414611816, -10.081297874450684, -9.408321380615234, -8.735345840454102, -8.062370300292969, -7.389394760131836, -6.716419219970703, -6.04344367980957, -5.3704681396484375, -4.697492599487305, -4.024515151977539, -3.3515396118164062, -2.6785640716552734, -2.0055885314941406, -1.3326129913330078, -0.659637451171875, 0.013338088989257812, 0.6863136291503906, 1.3592891693115234, 2.0322647094726562, 2.705240249633789, 3.3782176971435547, 4.0511932373046875, 4.72416877746582, 5.397144317626953, 6.070119857788086, 6.743095397949219, 7.416070938110352, 8.089046478271484, 8.762022018432617, 9.43499755859375, 10.107973098754883, 10.780950546264648, 11.453924179077148, 12.126901626586914, 12.799875259399414, 13.47285270690918, 14.145830154418945, 14.818803787231445, 15.491781234741211, 16.16475486755371, 16.837732315063477, 17.510705947875977, 18.183683395385742, 18.856657028198242, 19.529634475708008, 20.202608108520508, 20.875585556030273]}, "_runtime": 6049.795867443085, "_timestamp": 1585603419.428737, "_step": 198}
{"Episode reward": -96.60388464646613, "Episode length": 999, "Policy Loss": 0.0983375683426857, "Value Loss": 2.56854510307312, "_runtime": 6051.354723215103, "_timestamp": 1585603420.9875927, "_step": 199}
{"Episode reward": -96.76670115081598, "Episode length": 999, "Policy Loss": -0.056500520557165146, "Value Loss": 2.808032751083374, "_runtime": 6052.915971755981, "_timestamp": 1585603422.5488412, "_step": 200}
{"Episode reward": -95.98773123984232, "Episode length": 999, "Policy Loss": 0.037253059446811676, "Value Loss": 1.613236665725708, "_runtime": 6054.486343622208, "_timestamp": 1585603424.119213, "_step": 201}
{"Episode reward": -93.79028455514987, "Episode length": 999, "Policy Loss": -0.549095630645752, "Value Loss": 3.1420505046844482, "_runtime": 6056.04295873642, "_timestamp": 1585603425.6758282, "_step": 202}
{"Episode reward": -93.50237623797106, "Episode length": 999, "Policy Loss": 0.24486497044563293, "Value Loss": 0.37808525562286377, "_runtime": 6057.647077798843, "_timestamp": 1585603427.2799473, "_step": 203}
{"Episode reward": -94.55741778466171, "Episode length": 999, "Policy Loss": 0.6894652247428894, "Value Loss": 1.166602611541748, "_runtime": 6059.203656196594, "_timestamp": 1585603428.8365257, "_step": 204}
{"Episode reward": -96.44814831884341, "Episode length": 999, "Policy Loss": 0.5730180144309998, "Value Loss": 1.2749897241592407, "_runtime": 6060.770705699921, "_timestamp": 1585603430.4035752, "_step": 205}
{"Episode reward": -94.0352849743531, "Episode length": 999, "Policy Loss": 0.485438734292984, "Value Loss": 3.162320852279663, "_runtime": 6062.348777770996, "_timestamp": 1585603431.9816473, "_step": 206}
{"Episode reward": -95.72154091376413, "Episode length": 999, "Policy Loss": 0.38786032795906067, "Value Loss": 1.8447051048278809, "_runtime": 6063.91340303421, "_timestamp": 1585603433.5462725, "_step": 207}
{"Episode reward": -95.5399157324475, "Episode length": 999, "Policy Loss": 0.6046781539916992, "Value Loss": 1.5058916807174683, "_runtime": 6065.479647159576, "_timestamp": 1585603435.1125166, "_step": 208}
{"Episode reward": -95.82088390749612, "Episode length": 999, "Policy Loss": 0.3211950361728668, "Value Loss": 0.12646082043647766, "_runtime": 6067.036511182785, "_timestamp": 1585603436.6693807, "_step": 209}
{"Episode reward": -96.99735071594989, "Episode length": 999, "Policy Loss": 0.7282896041870117, "Value Loss": 2.0082149505615234, "_runtime": 6068.604167461395, "_timestamp": 1585603438.237037, "_step": 210}
{"Episode reward": -97.21260749340735, "Episode length": 999, "Policy Loss": 0.3024206757545471, "Value Loss": 0.3577333390712738, "_runtime": 6069.593510150909, "_timestamp": 1585603439.2263796, "_step": 211}
{"Episode reward": 39.972851862560326, "Episode length": 621, "Policy Loss": 0.7893615961074829, "Value Loss": 17.960819244384766, "_runtime": 6071.156816244125, "_timestamp": 1585603440.7896857, "_step": 212}
{"Episode reward": -95.9760547584954, "Episode length": 999, "Policy Loss": 0.5158124566078186, "Value Loss": 0.6251593232154846, "_runtime": 6072.700214147568, "_timestamp": 1585603442.3330836, "_step": 213}
{"Episode reward": -96.87217178582416, "Episode length": 999, "Policy Loss": 0.5820244550704956, "Value Loss": 1.288832664489746, "_runtime": 6074.229893684387, "_timestamp": 1585603443.8627632, "_step": 214}
{"Episode reward": -93.67561336654589, "Episode length": 999, "Policy Loss": -0.1374073624610901, "Value Loss": 2.9423370361328125, "_runtime": 6075.786536455154, "_timestamp": 1585603445.419406, "_step": 215}
{"Episode reward": -96.38569057972221, "Episode length": 999, "Policy Loss": 0.2201964110136032, "Value Loss": 0.461155503988266, "_runtime": 6077.359474658966, "_timestamp": 1585603446.9923441, "_step": 216}
{"Episode reward": -94.2106058518831, "Episode length": 999, "Policy Loss": -0.5316317081451416, "Value Loss": 3.014749526977539, "_runtime": 6078.930150508881, "_timestamp": 1585603448.56302, "_step": 217}
{"Episode reward": -96.67414633114184, "Episode length": 999, "Policy Loss": 0.21298372745513916, "Value Loss": 0.3514266014099121, "_runtime": 6080.5492379665375, "_timestamp": 1585603450.1821074, "_step": 218}
{"Episode reward": -95.87731122086912, "Episode length": 999, "Policy Loss": 0.12721922993659973, "Value Loss": 0.6945695877075195, "_runtime": 6082.114140987396, "_timestamp": 1585603451.7470105, "_step": 219}
{"Episode reward": -96.92298994785605, "Episode length": 999, "Policy Loss": -0.09306460618972778, "Value Loss": 1.7893866300582886, "_runtime": 6083.679721832275, "_timestamp": 1585603453.3125913, "_step": 220}
{"Episode reward": -96.6822471274299, "Episode length": 999, "Policy Loss": -0.030187232419848442, "Value Loss": 1.9722298383712769, "_runtime": 6085.247287511826, "_timestamp": 1585603454.880157, "_step": 221}
{"Episode reward": -94.95441271745312, "Episode length": 999, "Policy Loss": 0.41760993003845215, "Value Loss": 3.89608097076416, "_runtime": 6086.819865226746, "_timestamp": 1585603456.4527347, "_step": 222}
{"Episode reward": -92.8106782942881, "Episode length": 999, "Policy Loss": 0.21927976608276367, "Value Loss": 1.4655381441116333, "_runtime": 6088.371970415115, "_timestamp": 1585603458.00484, "_step": 223}
{"Episode reward": -96.54314528802969, "Episode length": 999, "Policy Loss": 0.13826978206634521, "Value Loss": 0.33978691697120667, "_runtime": 6089.941544055939, "_timestamp": 1585603459.5744135, "_step": 224}
{"Episode reward": -94.39600008606804, "Episode length": 999, "Policy Loss": 0.4997115731239319, "Value Loss": 1.7007784843444824, "_runtime": 6091.487439155579, "_timestamp": 1585603461.1203086, "_step": 225}
{"Episode reward": -93.22748168055193, "Episode length": 999, "Policy Loss": 1.0857418775558472, "Value Loss": 3.8941752910614014, "_runtime": 6093.0435836315155, "_timestamp": 1585603462.676453, "_step": 226}
{"Episode reward": -94.30518362040092, "Episode length": 999, "Policy Loss": 0.3733196556568146, "Value Loss": 3.1146349906921387, "_runtime": 6094.602998495102, "_timestamp": 1585603464.235868, "_step": 227}
{"Episode reward": -95.96997563939928, "Episode length": 999, "Policy Loss": 0.21315059065818787, "Value Loss": 0.7566443681716919, "_runtime": 6096.163906097412, "_timestamp": 1585603465.7967756, "_step": 228}
{"Episode reward": -96.82917725251745, "Episode length": 999, "Policy Loss": 0.05872436985373497, "Value Loss": 0.29512470960617065, "_runtime": 6097.723153352737, "_timestamp": 1585603467.3560228, "_step": 229}
{"Episode reward": -97.29984168758183, "Episode length": 999, "Policy Loss": 0.1164902001619339, "Value Loss": 0.1660517454147339, "_runtime": 6099.281850099564, "_timestamp": 1585603468.9147196, "_step": 230}
{"Episode reward": -96.00321479779983, "Episode length": 999, "Policy Loss": -0.07953529059886932, "Value Loss": 1.6073094606399536, "_runtime": 6100.842053890228, "_timestamp": 1585603470.4749234, "_step": 231}
{"Episode reward": -95.35199752096062, "Episode length": 999, "Policy Loss": -0.21384117007255554, "Value Loss": 1.88154137134552, "_runtime": 6102.40363907814, "_timestamp": 1585603472.0365086, "_step": 232}
{"Episode reward": -92.41885704588687, "Episode length": 999, "Policy Loss": -0.7407082915306091, "Value Loss": 2.5044288635253906, "_runtime": 6104.0063552856445, "_timestamp": 1585603473.6392248, "_step": 233}
{"Episode reward": -96.0947753420334, "Episode length": 999, "Policy Loss": 0.04816277325153351, "Value Loss": 0.22531519830226898, "_runtime": 6105.577252149582, "_timestamp": 1585603475.2101216, "_step": 234}
{"Episode reward": -95.36860015264193, "Episode length": 999, "Policy Loss": 0.018661269918084145, "Value Loss": 1.0920071601867676, "_runtime": 6107.123787641525, "_timestamp": 1585603476.7566571, "_step": 235}
{"Episode reward": -97.33273990753558, "Episode length": 999, "Policy Loss": -0.14621146023273468, "Value Loss": 0.8362122774124146, "_runtime": 6108.694939613342, "_timestamp": 1585603478.327809, "_step": 236}
{"Episode reward": -96.12192411960368, "Episode length": 999, "Policy Loss": 0.1053081676363945, "Value Loss": 0.25460928678512573, "_runtime": 6110.264651298523, "_timestamp": 1585603479.8975208, "_step": 237}
{"Episode reward": -93.84277005878332, "Episode length": 999, "Policy Loss": 0.17502769827842712, "Value Loss": 1.9014883041381836, "_runtime": 6111.833441019058, "_timestamp": 1585603481.4663105, "_step": 238}
{"Episode reward": -95.94408412100084, "Episode length": 999, "Policy Loss": 0.18521951138973236, "Value Loss": 0.4770980775356293, "_runtime": 6113.404050588608, "_timestamp": 1585603483.03692, "_step": 239}
{"Episode reward": -96.44437731924675, "Episode length": 999, "Policy Loss": 0.041460007429122925, "Value Loss": 0.06480228900909424, "_runtime": 6114.972140550613, "_timestamp": 1585603484.60501, "_step": 240}
{"Episode reward": -95.81993270477906, "Episode length": 999, "Policy Loss": 0.15874996781349182, "Value Loss": 0.5155922770500183, "_runtime": 6116.542080163956, "_timestamp": 1585603486.1749496, "_step": 241}
{"Episode reward": -95.95002413576131, "Episode length": 999, "Policy Loss": 0.04409714415669441, "Value Loss": 0.1064390167593956, "_runtime": 6118.108740329742, "_timestamp": 1585603487.7416098, "_step": 242}
{"Episode reward": -96.69840531596695, "Episode length": 999, "Policy Loss": 0.07361442595720291, "Value Loss": 0.2769061028957367, "_runtime": 6119.676979541779, "_timestamp": 1585603489.309849, "_step": 243}
{"Episode reward": -95.75271138832159, "Episode length": 999, "Policy Loss": 0.13027335703372955, "Value Loss": 0.5084855556488037, "_runtime": 6121.243956327438, "_timestamp": 1585603490.8768258, "_step": 244}
{"Episode reward": -94.10988502483205, "Episode length": 999, "Policy Loss": 0.11396057158708572, "Value Loss": 1.018562912940979, "_runtime": 6122.8054893016815, "_timestamp": 1585603492.4383588, "_step": 245}
{"Episode reward": -95.06253649798454, "Episode length": 999, "Policy Loss": 0.11111040413379669, "Value Loss": 0.4685676097869873, "_runtime": 6124.375867843628, "_timestamp": 1585603494.0087373, "_step": 246}
{"Episode reward": -95.85086679680984, "Episode length": 999, "Policy Loss": 0.01387543510645628, "Value Loss": 0.09524049609899521, "_runtime": 6125.950206518173, "_timestamp": 1585603495.583076, "_step": 247}
{"Episode reward": -95.41038743507605, "Episode length": 999, "Policy Loss": -0.0397513210773468, "Value Loss": 0.13739071786403656, "_runtime": 6127.557344675064, "_timestamp": 1585603497.1902142, "_step": 248}
{"Episode reward": -95.94005451991899, "Episode length": 999, "Policy Loss": -0.11668556928634644, "Value Loss": 0.21824315190315247, "_runtime": 6129.104288101196, "_timestamp": 1585603498.7371576, "_step": 249}
{"Episode reward": -95.12868810945399, "Episode length": 999, "Policy Loss": -0.19073016941547394, "Value Loss": 0.4924412667751312, "_runtime": 6130.670007228851, "_timestamp": 1585603500.3028767, "_step": 250}
{"Episode reward": -95.91059967487459, "Episode length": 999, "Policy Loss": 0.013809257186949253, "Value Loss": 0.16843144595623016, "_runtime": 6132.227448940277, "_timestamp": 1585603501.8603184, "_step": 251}
{"Episode reward": -96.25914998379989, "Episode length": 999, "Policy Loss": -0.1801924854516983, "Value Loss": 0.7223413586616516, "_runtime": 6133.797941684723, "_timestamp": 1585603503.4308112, "_step": 252}
{"Episode reward": -95.95049509610182, "Episode length": 999, "Policy Loss": -0.04180063679814339, "Value Loss": 0.10810913145542145, "_runtime": 6135.364624500275, "_timestamp": 1585603504.997494, "_step": 253}
{"Episode reward": -93.81479535809098, "Episode length": 999, "Policy Loss": 0.037765856832265854, "Value Loss": 0.08913631737232208, "_runtime": 6136.934772491455, "_timestamp": 1585603506.567642, "_step": 254}
{"Episode reward": -95.71464984075516, "Episode length": 999, "Policy Loss": 0.032441645860672, "Value Loss": 0.022448552772402763, "_runtime": 6138.50243139267, "_timestamp": 1585603508.1353009, "_step": 255}
{"Episode reward": -94.43061927161963, "Episode length": 999, "Policy Loss": 0.14981545507907867, "Value Loss": 0.08227314054965973, "_runtime": 6140.0722942352295, "_timestamp": 1585603509.7051637, "_step": 256}
{"Episode reward": -96.6420611588225, "Episode length": 999, "Policy Loss": 0.02321934700012207, "Value Loss": 0.015277002938091755, "_runtime": 6141.63995051384, "_timestamp": 1585603511.27282, "_step": 257}
{"Episode reward": -97.25971448585081, "Episode length": 999, "Policy Loss": 0.014588091522455215, "Value Loss": 0.019994094967842102, "_runtime": 6143.197926998138, "_timestamp": 1585603512.8307965, "_step": 258}
{"Episode reward": -96.30418641750367, "Episode length": 999, "Policy Loss": 0.05574342608451843, "Value Loss": 0.09932173043489456, "_runtime": 6144.764554738998, "_timestamp": 1585603514.3974242, "_step": 259}
{"Episode reward": -97.23820514935302, "Episode length": 999, "Policy Loss": 0.043586522340774536, "Value Loss": 0.1065254956483841, "_runtime": 6146.333717107773, "_timestamp": 1585603515.9665866, "_step": 260}
{"Episode reward": -95.60766401437117, "Episode length": 999, "Policy Loss": 0.09908470511436462, "Value Loss": 0.15943801403045654, "_runtime": 6147.8914630413055, "_timestamp": 1585603517.5243325, "_step": 261}
{"Episode reward": -95.59187243728003, "Episode length": 999, "Policy Loss": 0.0838434025645256, "Value Loss": 0.3981972336769104, "_runtime": 6149.456519126892, "_timestamp": 1585603519.0893886, "_step": 262}
{"Episode reward": -96.01082663630598, "Episode length": 999, "Policy Loss": 0.04964175075292587, "Value Loss": 0.14268213510513306, "_runtime": 6151.063253164291, "_timestamp": 1585603520.6961226, "_step": 263}
{"Episode reward": -94.91256647096596, "Episode length": 999, "Policy Loss": 0.0402020700275898, "Value Loss": 0.17507971823215485, "_runtime": 6152.630877017975, "_timestamp": 1585603522.2637465, "_step": 264}
{"Episode reward": -95.61584823337252, "Episode length": 999, "Policy Loss": 0.027384482324123383, "Value Loss": 0.0330638587474823, "_runtime": 6154.187478303909, "_timestamp": 1585603523.8203478, "_step": 265}
{"Episode reward": -94.31455975373157, "Episode length": 999, "Policy Loss": 0.0009894223185256124, "Value Loss": 0.024740995839238167, "_runtime": 6155.755342245102, "_timestamp": 1585603525.3882117, "_step": 266}
{"Episode reward": -97.11135811705945, "Episode length": 999, "Policy Loss": -0.02384304441511631, "Value Loss": 0.0464264452457428, "_runtime": 6157.312910318375, "_timestamp": 1585603526.9457798, "_step": 267}
{"Episode reward": -92.90156977967796, "Episode length": 999, "Policy Loss": 0.09533867239952087, "Value Loss": 0.10644567012786865, "_runtime": 6158.879778385162, "_timestamp": 1585603528.5126479, "_step": 268}
{"Episode reward": -95.71691940090336, "Episode length": 999, "Policy Loss": 0.07222724705934525, "Value Loss": 0.07442007213830948, "_runtime": 6160.4497153759, "_timestamp": 1585603530.0825849, "_step": 269}
{"Episode reward": -97.0306877725528, "Episode length": 999, "Policy Loss": 0.01192411594092846, "Value Loss": 0.03977777808904648, "_runtime": 6162.00589966774, "_timestamp": 1585603531.6387691, "_step": 270}
{"Episode reward": -97.1780944105339, "Episode length": 999, "Policy Loss": -0.09138943254947662, "Value Loss": 0.20295076072216034, "_runtime": 6163.562070846558, "_timestamp": 1585603533.1949403, "_step": 271}
{"Episode reward": -95.87469718195074, "Episode length": 999, "Policy Loss": -0.1828894019126892, "Value Loss": 0.3420815169811249, "_runtime": 6165.120424747467, "_timestamp": 1585603534.7532942, "_step": 272}
{"Episode reward": -96.18569771117512, "Episode length": 999, "Policy Loss": -0.017858970910310745, "Value Loss": 0.06820912659168243, "_runtime": 6166.6928861141205, "_timestamp": 1585603536.3257556, "_step": 273}
{"Episode reward": -94.41348136582002, "Episode length": 999, "Policy Loss": -0.129550963640213, "Value Loss": 0.10256443172693253, "_runtime": 6168.249408960342, "_timestamp": 1585603537.8822784, "_step": 274}
{"Episode reward": -95.74801253929124, "Episode length": 999, "Policy Loss": -0.02646462619304657, "Value Loss": 0.013968094252049923, "_runtime": 6169.819688081741, "_timestamp": 1585603539.4525576, "_step": 275}
{"Episode reward": -96.22727044824029, "Episode length": 999, "Policy Loss": -0.016792844980955124, "Value Loss": 0.0039008778985589743, "_runtime": 6171.372923612595, "_timestamp": 1585603541.005793, "_step": 276}
{"Episode reward": -94.764313027022, "Episode length": 999, "Policy Loss": 0.015038683079183102, "Value Loss": 0.025907840579748154, "_runtime": 6172.94025015831, "_timestamp": 1585603542.5731196, "_step": 277}
{"Episode reward": -95.88536174442748, "Episode length": 999, "Policy Loss": 0.008412596769630909, "Value Loss": 0.042915187776088715, "_runtime": 6174.548947095871, "_timestamp": 1585603544.1818166, "_step": 278}
{"Episode reward": -96.42250920509818, "Episode length": 999, "Policy Loss": -0.023577382788062096, "Value Loss": 0.02686655893921852, "_runtime": 6176.107166528702, "_timestamp": 1585603545.740036, "_step": 279}
{"Episode reward": -95.93242392180836, "Episode length": 999, "Policy Loss": -0.03584278002381325, "Value Loss": 0.015714848414063454, "_runtime": 6177.676115274429, "_timestamp": 1585603547.3089848, "_step": 280}
{"Episode reward": -94.54487112378098, "Episode length": 999, "Policy Loss": 0.16215848922729492, "Value Loss": 0.2535077631473541, "_runtime": 6179.244941949844, "_timestamp": 1585603548.8778114, "_step": 281}
{"Episode reward": -97.37514016238507, "Episode length": 999, "Policy Loss": 0.018416063860058784, "Value Loss": 0.07179351896047592, "_runtime": 6180.812286138535, "_timestamp": 1585603550.4451556, "_step": 282}
{"Episode reward": -95.95280846333937, "Episode length": 999, "Policy Loss": -0.020681258291006088, "Value Loss": 0.025079945102334023, "_runtime": 6182.370440006256, "_timestamp": 1585603552.0033095, "_step": 283}
{"Episode reward": -94.17620349259334, "Episode length": 999, "Policy Loss": 0.021869182586669922, "Value Loss": 0.036436889320611954, "_runtime": 6183.939655542374, "_timestamp": 1585603553.572525, "_step": 284}
{"Episode reward": -96.52092686875106, "Episode length": 999, "Policy Loss": -0.039370760321617126, "Value Loss": 0.001646663062274456, "_runtime": 6185.501615285873, "_timestamp": 1585603555.1344848, "_step": 285}
{"Episode reward": -91.95525455649525, "Episode length": 999, "Policy Loss": -0.033322978764772415, "Value Loss": 0.011062996461987495, "_runtime": 6187.055150270462, "_timestamp": 1585603556.6880198, "_step": 286}
{"Episode reward": -95.25720491324395, "Episode length": 999, "Policy Loss": -0.05753597244620323, "Value Loss": 0.018038161098957062, "_runtime": 6188.62571978569, "_timestamp": 1585603558.2585893, "_step": 287}
{"Episode reward": -92.99341265774717, "Episode length": 999, "Policy Loss": -0.06280136853456497, "Value Loss": 0.03904830664396286, "_runtime": 6190.185003757477, "_timestamp": 1585603559.8178732, "_step": 288}
{"Episode reward": -97.28320246183019, "Episode length": 999, "Policy Loss": -0.06733705848455429, "Value Loss": 0.030451804399490356, "_runtime": 6191.742864847183, "_timestamp": 1585603561.3757343, "_step": 289}
{"Episode reward": -95.57614408471788, "Episode length": 999, "Policy Loss": -0.09928540885448456, "Value Loss": 0.0648794025182724, "_runtime": 6193.3134779930115, "_timestamp": 1585603562.9463475, "_step": 290}
{"Episode reward": -96.16411534408715, "Episode length": 999, "Policy Loss": -0.04880564659833908, "Value Loss": 0.04693325608968735, "_runtime": 6194.885708093643, "_timestamp": 1585603564.5185776, "_step": 291}
{"Episode reward": -95.74157646260802, "Episode length": 999, "Policy Loss": -0.08840727806091309, "Value Loss": 0.0857708603143692, "_runtime": 6196.488871574402, "_timestamp": 1585603566.121741, "_step": 292}
{"Episode reward": -94.70134007595902, "Episode length": 999, "Policy Loss": -0.13006190955638885, "Value Loss": 0.057586830109357834, "_runtime": 6198.049564361572, "_timestamp": 1585603567.6824338, "_step": 293}
{"Episode reward": -96.40323998987935, "Episode length": 999, "Policy Loss": -0.06493056565523148, "Value Loss": 0.012217658571898937, "_runtime": 6199.618553638458, "_timestamp": 1585603569.2514231, "_step": 294}
{"Episode reward": -95.30560889965736, "Episode length": 999, "Policy Loss": -0.030950620770454407, "Value Loss": 0.013455853797495365, "_runtime": 6201.186838150024, "_timestamp": 1585603570.8197076, "_step": 295}
{"Episode reward": -95.92086889907971, "Episode length": 999, "Policy Loss": -0.06422398239374161, "Value Loss": 0.016498420387506485, "_runtime": 6202.757490873337, "_timestamp": 1585603572.3903604, "_step": 296}
{"Episode reward": -95.52585684421088, "Episode length": 999, "Policy Loss": 0.01283947192132473, "Value Loss": 0.04559293016791344, "_runtime": 6204.312798500061, "_timestamp": 1585603573.945668, "_step": 297}
{"Episode reward": -96.27744127335531, "Episode length": 999, "Policy Loss": -0.06069176271557808, "Value Loss": 0.013104649260640144, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026, -0.8254719376564026]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0], "bins": [-1.982946515083313, -1.9390735626220703, -1.8952006101608276, -1.851327657699585, -1.8074547052383423, -1.7635817527770996, -1.7197086811065674, -1.6758358478546143, -1.631962776184082, -1.588089942932129, -1.5442168712615967, -1.500343918800354, -1.4564709663391113, -1.4125980138778687, -1.368725061416626, -1.3248521089553833, -1.2809791564941406, -1.237106204032898, -1.1932332515716553, -1.1493602991104126, -1.10548734664917, -1.0616142749786377, -1.0177414417266846, -0.9738684892654419, -0.9299954175949097, -0.886122465133667, -0.8422495126724243, -0.7983765602111816, -0.754503607749939, -0.7106306552886963, -0.6667577028274536, -0.6228847503662109, -0.5790117979049683, -0.5351388454437256, -0.4912658929824829, -0.44739294052124023, -0.40351998805999756, -0.3596470355987549, -0.3157740831375122, -0.27190113067626953, -0.22802817821502686, -0.18415510654449463, -0.14028215408325195, -0.09640920162200928, -0.0525362491607666, -0.008663296699523926, 0.0352095365524292, 0.07908260822296143, 0.12295567989349365, 0.16682851314544678, 0.210701584815979, 0.25457441806793213, 0.29844748973846436, 0.3423203229904175, 0.3861933946609497, 0.43006622791290283, 0.47393929958343506, 0.5178121328353882, 0.5616852045059204, 0.6055580377578735, 0.6494311094284058, 0.6933039426803589, 0.7371770143508911, 0.7810498476028442, 0.8249229192733765]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 5.0], "bins": [-0.5232718586921692, -0.5149998664855957, -0.5067278742790222, -0.49845588207244873, -0.49018388986587524, -0.48191192746162415, -0.47363993525505066, -0.4653679430484772, -0.4570959508419037, -0.4488239586353302, -0.4405519664287567, -0.4322800040245056, -0.42400801181793213, -0.41573601961135864, -0.40746402740478516, -0.39919203519821167, -0.3909200429916382, -0.3826480507850647, -0.3743760585784912, -0.3661040663719177, -0.35783207416534424, -0.34956008195877075, -0.34128811955451965, -0.33301612734794617, -0.3247441351413727, -0.3164721429347992, -0.3082001507282257, -0.2999281883239746, -0.2916561961174011, -0.28338420391082764, -0.27511221170425415, -0.26684021949768066, -0.2585682272911072, -0.2502962350845337, -0.2420242428779602, -0.23375225067138672, -0.22548025846481323, -0.21720829606056213, -0.20893630385398865, -0.20066431164741516, -0.19239231944084167, -0.1841203272342682, -0.1758483350276947, -0.16757634282112122, -0.15930438041687012, -0.15103238821029663, -0.14276039600372314, -0.13448840379714966, -0.12621641159057617, -0.11794441938400269, -0.1096724271774292, -0.10140043497085571, -0.09312844276428223, -0.08485648036003113, -0.07658448815345764, -0.06831249594688416, -0.06004050374031067, -0.05176851153373718, -0.043496519327163696, -0.03522452712059021, -0.02695256471633911, -0.018680572509765625, -0.010408580303192139, -0.0021365880966186523, 0.006135404109954834]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 8.0, 11.0, 5.0, 10.0, 17.0, 16.0, 23.0, 198.0, 26.0, 37.0, 25.0, 16.0, 18.0, 8.0, 9.0, 5.0, 4.0, 3.0, 8.0, 7.0, 2.0, 5.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0], "bins": [-0.7477512955665588, -0.7289037108421326, -0.7100561261177063, -0.6912084817886353, -0.672360897064209, -0.6535133123397827, -0.6346657276153564, -0.6158181428909302, -0.5969704985618591, -0.5781229138374329, -0.5592753291130066, -0.5404276847839355, -0.5215801000595093, -0.502732515335083, -0.48388493061065674, -0.4650373160839081, -0.4461897313594818, -0.42734214663505554, -0.4084945321083069, -0.3896469473838806, -0.37079933285713196, -0.3519517481327057, -0.33310413360595703, -0.31425654888153076, -0.2954089641571045, -0.27656134963035583, -0.25771376490592957, -0.2388661503791809, -0.22001856565475464, -0.20117098093032837, -0.18232333660125732, -0.16347575187683105, -0.14462816715240479, -0.12578058242797852, -0.10693299770355225, -0.0880853533744812, -0.06923776865005493, -0.05039018392562866, -0.03154259920120239, -0.012694954872131348, 0.006152629852294922, 0.02500021457672119, 0.04384779930114746, 0.06269538402557373, 0.08154302835464478, 0.10039061307907104, 0.11923819780349731, 0.13808578252792358, 0.15693336725234985, 0.1757810115814209, 0.19462859630584717, 0.21347618103027344, 0.2323237657546997, 0.25117141008377075, 0.270018994808197, 0.2888665795326233, 0.30771416425704956, 0.32656174898147583, 0.3454093337059021, 0.36425691843032837, 0.3831046223640442, 0.40195220708847046, 0.42079979181289673, 0.439647376537323, 0.45849496126174927]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-2.5545268058776855, -2.4765193462371826, -2.3985118865966797, -2.3205044269561768, -2.242496967315674, -2.164489507675171, -2.086482048034668, -2.008474588394165, -1.930467128753662, -1.8524596691131592, -1.7744522094726562, -1.6964447498321533, -1.6184372901916504, -1.5404298305511475, -1.4624223709106445, -1.3844149112701416, -1.3064074516296387, -1.2283999919891357, -1.1503925323486328, -1.0723850727081299, -0.994377613067627, -0.916370153427124, -0.8383626937866211, -0.7603552341461182, -0.6823477745056152, -0.6043403148651123, -0.5263328552246094, -0.44832539558410645, -0.3703179359436035, -0.2923104763031006, -0.21430301666259766, -0.13629555702209473, -0.0582880973815918, 0.019719362258911133, 0.09772682189941406, 0.175734281539917, 0.2537417411804199, 0.33174920082092285, 0.4097566604614258, 0.4877641201019287, 0.5657715797424316, 0.6437790393829346, 0.7217864990234375, 0.7997939586639404, 0.8778014183044434, 0.9558088779449463, 1.0338163375854492, 1.1118237972259521, 1.189831256866455, 1.267838716506958, 1.345846176147461, 1.4238536357879639, 1.5018610954284668, 1.5798687934875488, 1.6578760147094727, 1.7358832359313965, 1.8138909339904785, 1.8918986320495605, 1.9699058532714844, 2.047913074493408, 2.1259207725524902, 2.2039284706115723, 2.281935691833496, 2.35994291305542, 2.437950611114502]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 4.0, 1.0, 6.0, 1.0, 3.0, 4.0, 0.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-1.1868842840194702, -1.1507737636566162, -1.1146633625030518, -1.0785528421401978, -1.0424424409866333, -1.0063319206237793, -0.9702214598655701, -0.9341109991073608, -0.8980004787445068, -0.8618900775909424, -0.8257795572280884, -0.7896690964698792, -0.7535586357116699, -0.7174481153488159, -0.6813376545906067, -0.6452271938323975, -0.6091167330741882, -0.573006272315979, -0.5368958115577698, -0.5007852911949158, -0.46467483043670654, -0.4285643696784973, -0.3924539089202881, -0.35634344816207886, -0.32023298740386963, -0.2841224670410156, -0.2480120062828064, -0.21190154552459717, -0.17579102516174316, -0.1396806240081787, -0.10357010364532471, -0.06745970249176025, -0.03134918212890625, 0.004761338233947754, 0.04087173938751221, 0.07698225975036621, 0.11309266090393066, 0.14920318126678467, 0.18531370162963867, 0.22142410278320312, 0.25753462314605713, 0.2936450242996216, 0.3297555446624756, 0.3658660650253296, 0.40197646617889404, 0.43808698654174805, 0.4741973876953125, 0.5103079080581665, 0.546418309211731, 0.582528829574585, 0.618639349937439, 0.6547497510910034, 0.6908602714538574, 0.7269706726074219, 0.7630811929702759, 0.7991917133331299, 0.8353022336959839, 0.8714126348495483, 0.9075230360031128, 0.9436336755752563, 0.9797440767288208, 1.0158544778823853, 1.0519648790359497, 1.0880755186080933, 1.1241859197616577]}, "_runtime": 6205.880752325058, "_timestamp": 1585603575.5136218, "_step": 298}
{"Episode reward": -96.1652116607785, "Episode length": 999, "Policy Loss": -0.0409887470304966, "Value Loss": 0.015271463431417942, "_runtime": 6207.4496603012085, "_timestamp": 1585603577.0825298, "_step": 299}
{"Episode reward": -92.4960010275469, "Episode length": 999, "Policy Loss": 0.0669717863202095, "Value Loss": 0.10523669421672821, "_runtime": 6209.006434440613, "_timestamp": 1585603578.639304, "_step": 300}
{"Episode reward": -96.4071831742059, "Episode length": 999, "Policy Loss": -0.04866485297679901, "Value Loss": 0.012152510695159435, "_runtime": 6210.573890686035, "_timestamp": 1585603580.2067602, "_step": 301}
{"Episode reward": -95.25691919014925, "Episode length": 999, "Policy Loss": -0.007245873566716909, "Value Loss": 0.0280467439442873, "_runtime": 6212.144569635391, "_timestamp": 1585603581.777439, "_step": 302}
{"Episode reward": -95.47050575679677, "Episode length": 999, "Policy Loss": -0.051793500781059265, "Value Loss": 0.002149401232600212, "_runtime": 6213.711120605469, "_timestamp": 1585603583.34399, "_step": 303}
{"Episode reward": -94.60195064610448, "Episode length": 999, "Policy Loss": -0.06718558818101883, "Value Loss": 0.03270912542939186, "_runtime": 6215.279177904129, "_timestamp": 1585603584.9120474, "_step": 304}
{"Episode reward": -96.65498305735886, "Episode length": 999, "Policy Loss": -0.05898062512278557, "Value Loss": 0.004223423078656197, "_runtime": 6216.846343040466, "_timestamp": 1585603586.4792125, "_step": 305}
{"Episode reward": -96.36751609993905, "Episode length": 999, "Policy Loss": -0.084190234541893, "Value Loss": 0.026409683749079704, "_runtime": 6218.414007663727, "_timestamp": 1585603588.0468771, "_step": 306}
{"Episode reward": -97.91489245861987, "Episode length": 999, "Policy Loss": -0.0576639324426651, "Value Loss": 0.0017405491089448333, "_runtime": 6219.994183063507, "_timestamp": 1585603589.6270525, "_step": 307}
{"Episode reward": -97.020283119979, "Episode length": 999, "Policy Loss": -0.07352238148450851, "Value Loss": 0.013980134390294552, "_runtime": 6221.563168764114, "_timestamp": 1585603591.1960382, "_step": 308}
{"Episode reward": -92.70973709946261, "Episode length": 999, "Policy Loss": -0.11111155152320862, "Value Loss": 0.040983960032463074, "_runtime": 6223.120028495789, "_timestamp": 1585603592.752898, "_step": 309}
{"Episode reward": -95.86425052375081, "Episode length": 999, "Policy Loss": -0.1037278100848198, "Value Loss": 0.034546226263046265, "_runtime": 6224.6735763549805, "_timestamp": 1585603594.3064458, "_step": 310}
{"Episode reward": -93.02038362942594, "Episode length": 999, "Policy Loss": -0.07835308462381363, "Value Loss": 0.019209669902920723, "_runtime": 6226.2400279045105, "_timestamp": 1585603595.8728974, "_step": 311}
{"Episode reward": -97.14492510068551, "Episode length": 999, "Policy Loss": -0.05352066457271576, "Value Loss": 0.0015295719495043159, "_runtime": 6227.808328151703, "_timestamp": 1585603597.4411976, "_step": 312}
{"Episode reward": -95.664143248005, "Episode length": 999, "Policy Loss": -0.05621352419257164, "Value Loss": 0.0046264659613370895, "_runtime": 6229.37575006485, "_timestamp": 1585603599.0086195, "_step": 313}
{"Episode reward": -97.31831042674983, "Episode length": 999, "Policy Loss": -0.056346189230680466, "Value Loss": 0.0007654993678443134, "_runtime": 6230.934401273727, "_timestamp": 1585603600.5672708, "_step": 314}
{"Episode reward": -97.01529383488266, "Episode length": 999, "Policy Loss": -0.04491712152957916, "Value Loss": 0.007172700949013233, "_runtime": 6232.496478796005, "_timestamp": 1585603602.1293483, "_step": 315}
{"Episode reward": -96.06023851819243, "Episode length": 999, "Policy Loss": -0.04776633530855179, "Value Loss": 0.007879860699176788, "_runtime": 6234.0624759197235, "_timestamp": 1585603603.6953454, "_step": 316}
{"Episode reward": -95.56611263626036, "Episode length": 999, "Policy Loss": 0.004906101617962122, "Value Loss": 0.03086112067103386, "_runtime": 6235.61921954155, "_timestamp": 1585603605.252089, "_step": 317}
{"Episode reward": -95.65770954152079, "Episode length": 999, "Policy Loss": -0.03314100578427315, "Value Loss": 0.013358987867832184, "_runtime": 6237.184435844421, "_timestamp": 1585603606.8173053, "_step": 318}
{"Episode reward": -95.96736735406017, "Episode length": 999, "Policy Loss": -0.02370678260922432, "Value Loss": 0.012604579329490662, "_runtime": 6238.748335599899, "_timestamp": 1585603608.381205, "_step": 319}
{"Episode reward": -96.73515384481786, "Episode length": 999, "Policy Loss": -0.04794861376285553, "Value Loss": 0.0019012276316061616, "_runtime": 6240.307812213898, "_timestamp": 1585603609.9406817, "_step": 320}
{"Episode reward": -96.03877434055147, "Episode length": 999, "Policy Loss": -0.039412982761859894, "Value Loss": 0.004068891983479261, "_runtime": 6241.864752292633, "_timestamp": 1585603611.4976218, "_step": 321}
{"Episode reward": -97.0029353866587, "Episode length": 999, "Policy Loss": -0.04958780109882355, "Value Loss": 0.0012349465396255255, "_runtime": 6243.460674285889, "_timestamp": 1585603613.0935438, "_step": 322}
{"Episode reward": -95.88213880880122, "Episode length": 999, "Policy Loss": -0.04239536449313164, "Value Loss": 0.001843600650317967, "_runtime": 6245.032651901245, "_timestamp": 1585603614.6655214, "_step": 323}
{"Episode reward": -93.27079049378725, "Episode length": 999, "Policy Loss": -0.0765320211648941, "Value Loss": 0.021042054519057274, "_runtime": 6246.599833011627, "_timestamp": 1585603616.2327025, "_step": 324}
{"Episode reward": -97.21277925792262, "Episode length": 999, "Policy Loss": -0.04476678743958473, "Value Loss": 0.0021055941469967365, "_runtime": 6248.167004108429, "_timestamp": 1585603617.7998736, "_step": 325}
{"Episode reward": -96.05715739220929, "Episode length": 999, "Policy Loss": -0.05613328516483307, "Value Loss": 0.009181035682559013, "_runtime": 6249.737992763519, "_timestamp": 1585603619.3708622, "_step": 326}
{"Episode reward": -96.23053297474216, "Episode length": 999, "Policy Loss": -0.04239625111222267, "Value Loss": 0.003267404157668352, "_runtime": 6251.294273614883, "_timestamp": 1585603620.927143, "_step": 327}
{"Episode reward": -95.91685762859969, "Episode length": 999, "Policy Loss": -0.043474793434143066, "Value Loss": 0.00507441395893693, "_runtime": 6252.86354136467, "_timestamp": 1585603622.4964108, "_step": 328}
{"Episode reward": -96.70432971535578, "Episode length": 999, "Policy Loss": -0.04717477783560753, "Value Loss": 0.008178259246051311, "_runtime": 6254.430790185928, "_timestamp": 1585603624.0636597, "_step": 329}
{"Episode reward": -97.2018565377607, "Episode length": 999, "Policy Loss": -0.03974658250808716, "Value Loss": 0.002177885500714183, "_runtime": 6255.995533943176, "_timestamp": 1585603625.6284034, "_step": 330}
{"Episode reward": -95.93352230994861, "Episode length": 999, "Policy Loss": -0.05577833205461502, "Value Loss": 0.008363211527466774, "_runtime": 6257.561603784561, "_timestamp": 1585603627.1944733, "_step": 331}
{"Episode reward": -95.5388231771907, "Episode length": 999, "Policy Loss": -0.04570088908076286, "Value Loss": 0.005701231304556131, "_runtime": 6259.130373954773, "_timestamp": 1585603628.7632434, "_step": 332}
{"Episode reward": -95.08097326872976, "Episode length": 999, "Policy Loss": -0.02971355989575386, "Value Loss": 0.004017524886876345, "_runtime": 6260.696991205215, "_timestamp": 1585603630.3298607, "_step": 333}
{"Episode reward": -97.10549582426184, "Episode length": 999, "Policy Loss": -0.040391597896814346, "Value Loss": 0.0005383876268751919, "_runtime": 6262.26268696785, "_timestamp": 1585603631.8955564, "_step": 334}
{"Episode reward": -96.92965209661062, "Episode length": 999, "Policy Loss": -0.03798452392220497, "Value Loss": 0.0008568585617467761, "_runtime": 6263.830114364624, "_timestamp": 1585603633.4629838, "_step": 335}
{"Episode reward": -96.5230106282694, "Episode length": 999, "Policy Loss": -0.03330114856362343, "Value Loss": 0.0019218428060412407, "_runtime": 6265.396847724915, "_timestamp": 1585603635.0297172, "_step": 336}
{"Episode reward": -94.88617505501846, "Episode length": 999, "Policy Loss": -0.006561459973454475, "Value Loss": 0.02369161695241928, "_runtime": 6267.000769615173, "_timestamp": 1585603636.633639, "_step": 337}
{"Episode reward": -94.98488968767195, "Episode length": 999, "Policy Loss": -0.03564276546239853, "Value Loss": 0.010517794638872147, "_runtime": 6268.560475111008, "_timestamp": 1585603638.1933446, "_step": 338}
{"Episode reward": -95.78824760086101, "Episode length": 999, "Policy Loss": -0.031894098967313766, "Value Loss": 0.000872389180585742, "_runtime": 6270.1269364356995, "_timestamp": 1585603639.759806, "_step": 339}
{"Episode reward": -95.42134864774049, "Episode length": 999, "Policy Loss": -0.007026852108538151, "Value Loss": 0.011321377009153366, "_runtime": 6271.691865444183, "_timestamp": 1585603641.324735, "_step": 340}
{"Episode reward": -96.42000516740917, "Episode length": 999, "Policy Loss": -0.03606444224715233, "Value Loss": 0.0009858091361820698, "_runtime": 6273.255532979965, "_timestamp": 1585603642.8884025, "_step": 341}
{"Episode reward": -93.41042360500339, "Episode length": 999, "Policy Loss": -0.026421621441841125, "Value Loss": 0.005031867418438196, "_runtime": 6274.82531785965, "_timestamp": 1585603644.4581873, "_step": 342}
{"Episode reward": -96.89901285617596, "Episode length": 999, "Policy Loss": -0.040387045592069626, "Value Loss": 0.0019054829608649015, "_runtime": 6276.389079809189, "_timestamp": 1585603646.0219493, "_step": 343}
{"Episode reward": -96.57967135803808, "Episode length": 999, "Policy Loss": -0.04821601137518883, "Value Loss": 0.0067813643254339695, "_runtime": 6277.947314023972, "_timestamp": 1585603647.5801835, "_step": 344}
{"Episode reward": -96.84322987209079, "Episode length": 999, "Policy Loss": -0.035176511853933334, "Value Loss": 0.0012305768905207515, "_runtime": 6279.513263225555, "_timestamp": 1585603649.1461327, "_step": 345}
{"Episode reward": -96.6240301104366, "Episode length": 999, "Policy Loss": -0.039102986454963684, "Value Loss": 0.0025940416380763054, "_runtime": 6281.068168878555, "_timestamp": 1585603650.7010384, "_step": 346}
{"Episode reward": -95.86541029700618, "Episode length": 999, "Policy Loss": -0.05030270293354988, "Value Loss": 0.008815008215606213, "_runtime": 6282.626046895981, "_timestamp": 1585603652.2589164, "_step": 347}
{"Episode reward": -93.63891399264264, "Episode length": 999, "Policy Loss": -0.039305951446294785, "Value Loss": 0.005931492894887924, "_runtime": 6284.192705154419, "_timestamp": 1585603653.8255746, "_step": 348}
{"Episode reward": -95.82900080029825, "Episode length": 999, "Policy Loss": -0.033036936074495316, "Value Loss": 0.002811518730595708, "_runtime": 6285.758061885834, "_timestamp": 1585603655.3909314, "_step": 349}
{"Episode reward": -97.16752972725153, "Episode length": 999, "Policy Loss": -0.0377875491976738, "Value Loss": 0.0014202184975147247, "_runtime": 6287.32937836647, "_timestamp": 1585603656.9622478, "_step": 350}
{"Episode reward": -94.56128636721728, "Episode length": 999, "Policy Loss": -0.036884065717458725, "Value Loss": 0.004492128733545542, "_runtime": 6288.932242870331, "_timestamp": 1585603658.5651124, "_step": 351}
{"Episode reward": -96.63495960498254, "Episode length": 999, "Policy Loss": -0.03948598727583885, "Value Loss": 0.0013159489026293159, "_runtime": 6290.496831178665, "_timestamp": 1585603660.1297007, "_step": 352}
{"Episode reward": -91.90521904791972, "Episode length": 999, "Policy Loss": -0.026618998497724533, "Value Loss": 0.03474424034357071, "_runtime": 6292.063890218735, "_timestamp": 1585603661.6967597, "_step": 353}
{"Episode reward": -95.90941945261267, "Episode length": 999, "Policy Loss": -0.04027058184146881, "Value Loss": 0.002754818182438612, "_runtime": 6293.627439498901, "_timestamp": 1585603663.260309, "_step": 354}
{"Episode reward": -95.86964492832583, "Episode length": 999, "Policy Loss": -0.032416678965091705, "Value Loss": 0.00479493523016572, "_runtime": 6295.192993402481, "_timestamp": 1585603664.825863, "_step": 355}
{"Episode reward": -96.95954975752424, "Episode length": 999, "Policy Loss": -0.04330924153327942, "Value Loss": 0.0018132267287001014, "_runtime": 6296.761143684387, "_timestamp": 1585603666.3940132, "_step": 356}
{"Episode reward": -96.92932396930323, "Episode length": 999, "Policy Loss": -0.03948974609375, "Value Loss": 0.0054330360144376755, "_runtime": 6298.329117059708, "_timestamp": 1585603667.9619865, "_step": 357}
{"Episode reward": -96.34181765124659, "Episode length": 999, "Policy Loss": -0.026281800121068954, "Value Loss": 0.0036205558571964502, "_runtime": 6299.89368224144, "_timestamp": 1585603669.5265517, "_step": 358}
{"Episode reward": -97.17378617149912, "Episode length": 999, "Policy Loss": -0.05660918727517128, "Value Loss": 0.009017638862133026, "_runtime": 6301.46076798439, "_timestamp": 1585603671.0936375, "_step": 359}
{"Episode reward": -96.47160620753309, "Episode length": 999, "Policy Loss": -0.044076040387153625, "Value Loss": 0.0036532990634441376, "_runtime": 6303.026974201202, "_timestamp": 1585603672.6598437, "_step": 360}
{"Episode reward": -94.31753365988877, "Episode length": 999, "Policy Loss": -0.017532147467136383, "Value Loss": 0.006749869789928198, "_runtime": 6304.58026766777, "_timestamp": 1585603674.2131371, "_step": 361}
{"Episode reward": -95.6147444953834, "Episode length": 999, "Policy Loss": -0.005810090806335211, "Value Loss": 0.015461636707186699, "_runtime": 6306.147721290588, "_timestamp": 1585603675.7805908, "_step": 362}
{"Episode reward": -95.96218755465489, "Episode length": 999, "Policy Loss": -0.04035426676273346, "Value Loss": 0.001879506860859692, "_runtime": 6307.703502416611, "_timestamp": 1585603677.336372, "_step": 363}
{"Episode reward": -97.31107097684011, "Episode length": 999, "Policy Loss": -0.04607564955949783, "Value Loss": 0.0017058042576536536, "_runtime": 6309.268620014191, "_timestamp": 1585603678.9014895, "_step": 364}
{"Episode reward": -94.97150706078048, "Episode length": 999, "Policy Loss": -0.04121001437306404, "Value Loss": 0.007285294588655233, "_runtime": 6310.835893630981, "_timestamp": 1585603680.468763, "_step": 365}
{"Episode reward": -95.89045669478485, "Episode length": 999, "Policy Loss": -0.058251455426216125, "Value Loss": 0.007788411341607571, "_runtime": 6312.4372498989105, "_timestamp": 1585603682.0701194, "_step": 366}
{"Episode reward": -94.38766658578587, "Episode length": 999, "Policy Loss": -0.05520092695951462, "Value Loss": 0.008227762766182423, "_runtime": 6314.004184961319, "_timestamp": 1585603683.6370544, "_step": 367}
{"Episode reward": -94.8300507594918, "Episode length": 999, "Policy Loss": -0.0523080974817276, "Value Loss": 0.007457745727151632, "_runtime": 6315.559569835663, "_timestamp": 1585603685.1924393, "_step": 368}
{"Episode reward": -93.46349356204362, "Episode length": 999, "Policy Loss": -0.04634201526641846, "Value Loss": 0.005538922734558582, "_runtime": 6317.139028787613, "_timestamp": 1585603686.7718983, "_step": 369}
{"Episode reward": -93.6459735746113, "Episode length": 999, "Policy Loss": -0.029840970411896706, "Value Loss": 0.0057130432687699795, "_runtime": 6318.699127674103, "_timestamp": 1585603688.3319972, "_step": 370}
{"Episode reward": -95.75458092039331, "Episode length": 999, "Policy Loss": -0.04069292172789574, "Value Loss": 0.007006824482232332, "_runtime": 6320.252895832062, "_timestamp": 1585603689.8857653, "_step": 371}
{"Episode reward": -95.78454583776829, "Episode length": 999, "Policy Loss": -0.026740428060293198, "Value Loss": 0.007832598872482777, "_runtime": 6321.796748161316, "_timestamp": 1585603691.4296176, "_step": 372}
{"Episode reward": -95.2863275888166, "Episode length": 999, "Policy Loss": -0.03777002915740013, "Value Loss": 0.0021947422064840794, "_runtime": 6323.33695936203, "_timestamp": 1585603692.9698288, "_step": 373}
{"Episode reward": -95.36376125801922, "Episode length": 999, "Policy Loss": -0.051905982196331024, "Value Loss": 0.007347733713686466, "_runtime": 6324.890743017197, "_timestamp": 1585603694.5236125, "_step": 374}
{"Episode reward": -93.18310201837184, "Episode length": 999, "Policy Loss": -0.044844165444374084, "Value Loss": 0.007778860162943602, "_runtime": 6326.445795297623, "_timestamp": 1585603696.0786648, "_step": 375}
{"Episode reward": -96.46388588756076, "Episode length": 999, "Policy Loss": -0.045635294169187546, "Value Loss": 0.0014320783084258437, "_runtime": 6327.996955633163, "_timestamp": 1585603697.629825, "_step": 376}
{"Episode reward": -92.2439673849618, "Episode length": 999, "Policy Loss": -0.04831433296203613, "Value Loss": 0.01057698018848896, "_runtime": 6329.555684804916, "_timestamp": 1585603699.1885543, "_step": 377}
{"Episode reward": -96.66300695050862, "Episode length": 999, "Policy Loss": -0.04200970008969307, "Value Loss": 0.0007267419714480639, "_runtime": 6331.1122941970825, "_timestamp": 1585603700.7451637, "_step": 378}
{"Episode reward": -94.80505825548775, "Episode length": 999, "Policy Loss": -0.034951258450746536, "Value Loss": 0.0036179127637296915, "_runtime": 6331.747596740723, "_timestamp": 1585603701.3804662, "_step": 379}
{"Episode reward": 62.89591307177651, "Episode length": 397, "Policy Loss": 0.8666324019432068, "Value Loss": 25.24818992614746, "_runtime": 6333.298740386963, "_timestamp": 1585603702.9316099, "_step": 380}
{"Episode reward": -93.94701331466814, "Episode length": 999, "Policy Loss": -0.05819800868630409, "Value Loss": 0.013823623768985271, "_runtime": 6334.85009431839, "_timestamp": 1585603704.4829638, "_step": 381}
{"Episode reward": -95.74067839318676, "Episode length": 999, "Policy Loss": -0.1060359850525856, "Value Loss": 0.08898913115262985, "_runtime": 6336.377893686295, "_timestamp": 1585603706.0107632, "_step": 382}
{"Episode reward": -96.34728777459719, "Episode length": 999, "Policy Loss": -0.07992120832204819, "Value Loss": 0.02546892687678337, "_runtime": 6337.929024934769, "_timestamp": 1585603707.5618944, "_step": 383}
{"Episode reward": -95.22158132162194, "Episode length": 999, "Policy Loss": -0.19159859418869019, "Value Loss": 0.1364486813545227, "_runtime": 6339.470361471176, "_timestamp": 1585603709.103231, "_step": 384}
{"Episode reward": -95.94291703200552, "Episode length": 999, "Policy Loss": -0.17093032598495483, "Value Loss": 0.10119801759719849, "_runtime": 6341.021834373474, "_timestamp": 1585603710.6547039, "_step": 385}
{"Episode reward": -97.01696739743974, "Episode length": 999, "Policy Loss": -0.15433688461780548, "Value Loss": 0.06575404107570648, "_runtime": 6342.592676401138, "_timestamp": 1585603712.225546, "_step": 386}
{"Episode reward": -94.73693939381741, "Episode length": 999, "Policy Loss": -0.17043247818946838, "Value Loss": 0.050437916070222855, "_runtime": 6344.162136793137, "_timestamp": 1585603713.7950063, "_step": 387}
{"Episode reward": -95.67130195118816, "Episode length": 999, "Policy Loss": -0.18371230363845825, "Value Loss": 0.02613416686654091, "_runtime": 6345.707150936127, "_timestamp": 1585603715.3400204, "_step": 388}
{"Episode reward": -96.80905861028089, "Episode length": 999, "Policy Loss": -0.14323535561561584, "Value Loss": 0.004770104773342609, "_runtime": 6347.265244722366, "_timestamp": 1585603716.8981142, "_step": 389}
{"Episode reward": -95.63362339570028, "Episode length": 999, "Policy Loss": -0.1300068348646164, "Value Loss": 0.01332306582480669, "_runtime": 6348.820649385452, "_timestamp": 1585603718.4535189, "_step": 390}
{"Episode reward": -96.56618978427295, "Episode length": 999, "Policy Loss": -0.14756722748279572, "Value Loss": 0.007660449016839266, "_runtime": 6350.387911081314, "_timestamp": 1585603720.0207806, "_step": 391}
{"Episode reward": -92.2867287149555, "Episode length": 999, "Policy Loss": 0.018941767513751984, "Value Loss": 0.15731379389762878, "_runtime": 6351.96223449707, "_timestamp": 1585603721.595104, "_step": 392}
{"Episode reward": -96.8311460386336, "Episode length": 999, "Policy Loss": -0.14378251135349274, "Value Loss": 0.042987287044525146, "_runtime": 6353.52979016304, "_timestamp": 1585603723.1626596, "_step": 393}
{"Episode reward": -96.90239274480172, "Episode length": 999, "Policy Loss": -0.13812851905822754, "Value Loss": 0.027201298624277115, "_runtime": 6355.082437038422, "_timestamp": 1585603724.7153065, "_step": 394}
{"Episode reward": -95.79163894588771, "Episode length": 999, "Policy Loss": -0.06551184505224228, "Value Loss": 0.08604279160499573, "_runtime": 6356.633368730545, "_timestamp": 1585603726.2662382, "_step": 395}
{"Episode reward": -94.94421314690294, "Episode length": 999, "Policy Loss": -0.13896478712558746, "Value Loss": 0.009736324660480022, "_runtime": 6358.229119062424, "_timestamp": 1585603727.8619885, "_step": 396}
{"Episode reward": -94.9593632927135, "Episode length": 999, "Policy Loss": -0.12909306585788727, "Value Loss": 0.011861991137266159, "_runtime": 6359.792255401611, "_timestamp": 1585603729.425125, "_step": 397}
{"Episode reward": -95.10252803750487, "Episode length": 999, "Policy Loss": -0.15818828344345093, "Value Loss": 0.008595307357609272, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779, -6.194076061248779]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0], "bins": [-17.746814727783203, -17.434118270874023, -17.121421813964844, -16.80872344970703, -16.49602699279785, -16.183330535888672, -15.870634078979492, -15.557937622070312, -15.245240211486816, -14.932543754577637, -14.61984634399414, -14.307149887084961, -13.994453430175781, -13.681756973266602, -13.369059562683105, -13.056363105773926, -12.74366569519043, -12.43096923828125, -12.11827278137207, -11.80557632446289, -11.492878913879395, -11.180182456970215, -10.867485046386719, -10.554788589477539, -10.24209213256836, -9.92939567565918, -9.616698265075684, -9.304001808166504, -8.991304397583008, -8.678607940673828, -8.365911483764648, -8.053214073181152, -7.740517616271973, -7.427821159362793, -7.115123748779297, -6.802427291870117, -6.4897308349609375, -6.177033424377441, -5.864336967468262, -5.551640510559082, -5.238943099975586, -4.926246643066406, -4.613550186157227, -4.3008527755737305, -3.988156318664551, -3.675459861755371, -3.362762451171875, -3.0500659942626953, -2.7373695373535156, -2.4246721267700195, -2.11197566986084, -1.7992782592773438, -1.486581802368164, -1.1738853454589844, -0.8611888885498047, -0.548492431640625, -0.2357940673828125, 0.07690238952636719, 0.3895988464355469, 0.7022953033447266, 1.0149917602539062, 1.327688217163086, 1.6403865814208984, 1.9530830383300781, 2.265779495239258]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.189396858215332, -2.1427478790283203, -2.0960988998413086, -2.0494496822357178, -2.002800703048706, -1.9561517238616943, -1.9095027446746826, -1.862853765487671, -1.8162046670913696, -1.7695555686950684, -1.7229065895080566, -1.676257610321045, -1.6296086311340332, -1.582959532737732, -1.5363105535507202, -1.489661455154419, -1.4430124759674072, -1.3963634967803955, -1.3497143983840942, -1.3030654191970825, -1.2564163208007812, -1.2097673416137695, -1.1631183624267578, -1.1164692640304565, -1.0698202848434448, -1.023171305656433, -0.9765222072601318, -0.9298732280731201, -0.8832242488861084, -0.8365751504898071, -0.7899261713027954, -0.7432770729064941, -0.6966280937194824, -0.6499791145324707, -0.6033300161361694, -0.5566810369491577, -0.5100319385528564, -0.4633829593658447, -0.416733980178833, -0.37008488178253174, -0.32343590259552, -0.2767869234085083, -0.23013782501220703, -0.1834888458251953, -0.1368398666381836, -0.09019088745117188, -0.043541669845581055, 0.003107309341430664, 0.04975628852844238, 0.0964052677154541, 0.14305424690246582, 0.18970346450805664, 0.23635244369506836, 0.2830014228820801, 0.3296504020690918, 0.3762993812561035, 0.42294836044311523, 0.46959757804870605, 0.5162465572357178, 0.5628955364227295, 0.6095445156097412, 0.6561934947967529, 0.7028427124023438, 0.7494916915893555, 0.7961406707763672]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 6.0, 7.0, 13.0, 8.0, 5.0, 17.0, 27.0, 47.0, 34.0, 43.0, 49.0, 37.0, 28.0, 34.0, 23.0, 13.0, 8.0, 12.0, 8.0, 8.0, 9.0, 3.0, 12.0, 4.0, 7.0, 3.0, 3.0, 6.0, 2.0, 1.0, 0.0, 4.0, 1.0, 2.0], "bins": [-2.757169246673584, -2.6883180141448975, -2.61946702003479, -2.5506157875061035, -2.481764793395996, -2.4129135608673096, -2.344062328338623, -2.2752113342285156, -2.206360101699829, -2.1375088691711426, -2.068657875061035, -1.9998066425323486, -1.9309555292129517, -1.8621044158935547, -1.7932531833648682, -1.7244020700454712, -1.6555509567260742, -1.5866998434066772, -1.5178487300872803, -1.4489974975585938, -1.3801463842391968, -1.3112952709197998, -1.2424440383911133, -1.1735929250717163, -1.1047418117523193, -1.0358906984329224, -0.9670395851135254, -0.8981883525848389, -0.8293372392654419, -0.7604861259460449, -0.6916348934173584, -0.622783899307251, -0.5539326667785645, -0.48508143424987793, -0.4162304401397705, -0.347379207611084, -0.27852821350097656, -0.20967698097229004, -0.14082574844360352, -0.0719747543334961, -0.0031235218048095703, 0.06572771072387695, 0.13457870483398438, 0.2034299373626709, 0.2722811698913574, 0.34113216400146484, 0.40998339653015137, 0.4788343906402588, 0.5476856231689453, 0.6165368556976318, 0.6853878498077393, 0.7542390823364258, 0.8230900764465332, 0.8919413089752197, 0.9607925415039062, 1.0296435356140137, 1.0984947681427002, 1.1673460006713867, 1.2361969947814941, 1.3050479888916016, 1.3738994598388672, 1.4427504539489746, 1.511601448059082, 1.5804529190063477, 1.649303913116455]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.001631736755371, -10.66614055633545, -10.330649375915527, -9.995159149169922, -9.65966796875, -9.324176788330078, -8.988685607910156, -8.653194427490234, -8.317703247070312, -7.982213020324707, -7.646721839904785, -7.311230659484863, -6.975739479064941, -6.640248775482178, -6.304757595062256, -5.969266891479492, -5.63377571105957, -5.298284530639648, -4.962793827056885, -4.627302646636963, -4.291811943054199, -3.9563207626342773, -3.6208295822143555, -3.285338878631592, -2.9498472213745117, -2.6143569946289062, -2.2788658142089844, -1.9433746337890625, -1.6078834533691406, -1.2723922729492188, -0.9369020462036133, -0.6014108657836914, -0.26591968536376953, 0.06957149505615234, 0.4050626754760742, 0.7405529022216797, 1.0760440826416016, 1.4115352630615234, 1.7470264434814453, 2.082517623901367, 2.4180078506469727, 2.7534990310668945, 3.0889902114868164, 3.4244813919067383, 3.75997257232666, 4.095463752746582, 4.4309539794921875, 4.766445159912109, 5.101937294006348, 5.437426567077637, 5.772917747497559, 6.1084089279174805, 6.443900108337402, 6.779391288757324, 7.114882469177246, 7.450373649597168, 7.78586483001709, 8.121356010437012, 8.456847190856934, 8.792336463928223, 9.127827644348145, 9.463318824768066, 9.798810005187988, 10.13430118560791, 10.469792366027832]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.495075702667236, -7.2495574951171875, -7.0040388107299805, -6.758520603179932, -6.513002395629883, -6.267483711242676, -6.021965503692627, -5.776447296142578, -5.530928611755371, -5.285409927368164, -5.039891719818115, -4.794373512268066, -4.548854827880859, -4.3033366203308105, -4.057818412780762, -3.812299966812134, -3.566781520843506, -3.321263313293457, -3.07574462890625, -2.830226421356201, -2.584707736968994, -2.3391895294189453, -2.0936713218688965, -1.8481526374816895, -1.6026344299316406, -1.3571162223815918, -1.1115975379943848, -0.8660793304443359, -0.6205611228942871, -0.3750424385070801, -0.12952423095703125, 0.11599445343017578, 0.3615126609802246, 0.6070313453674316, 0.8525490760803223, 1.0980677604675293, 1.3435864448547363, 1.589104175567627, 1.834622859954834, 2.080141544342041, 2.325660228729248, 2.5711779594421387, 2.8166966438293457, 3.0622153282165527, 3.3077330589294434, 3.5532517433166504, 3.7987704277038574, 4.044288158416748, 4.289806842803955, 4.535325527191162, 4.780843257904053, 5.02636194229126, 5.271880626678467, 5.517398357391357, 5.7629170417785645, 6.0084357261657715, 6.253953456878662, 6.499472141265869, 6.744990825653076, 6.990509510040283, 7.236027240753174, 7.481545925140381, 7.727064609527588, 7.9725823402404785, 8.218101501464844]}, "_runtime": 6361.363219499588, "_timestamp": 1585603730.996089, "_step": 398}
{"Episode reward": -95.14773296510442, "Episode length": 999, "Policy Loss": -0.20437709987163544, "Value Loss": 0.036315299570560455, "_runtime": 6362.933754682541, "_timestamp": 1585603732.5666242, "_step": 399}
{"Episode reward": -93.91306351270934, "Episode length": 999, "Policy Loss": -0.16510385274887085, "Value Loss": 0.023653240874409676, "_runtime": 6364.497853040695, "_timestamp": 1585603734.1307225, "_step": 400}
{"Episode reward": -96.508364684655, "Episode length": 999, "Policy Loss": -0.183049738407135, "Value Loss": 0.032330743968486786, "_runtime": 6366.068973064423, "_timestamp": 1585603735.7018425, "_step": 401}
{"Episode reward": -96.9185573761257, "Episode length": 999, "Policy Loss": -0.1611897051334381, "Value Loss": 0.011971942149102688, "_runtime": 6367.626687049866, "_timestamp": 1585603737.2595565, "_step": 402}
{"Episode reward": -96.24464175049818, "Episode length": 999, "Policy Loss": -0.14824160933494568, "Value Loss": 0.011438286863267422, "_runtime": 6369.183266878128, "_timestamp": 1585603738.8161364, "_step": 403}
{"Episode reward": -95.02400860815712, "Episode length": 999, "Policy Loss": -0.17289839684963226, "Value Loss": 0.030283212661743164, "_runtime": 6370.731399297714, "_timestamp": 1585603740.3642688, "_step": 404}
{"Episode reward": -95.93999419457896, "Episode length": 999, "Policy Loss": -0.12889303267002106, "Value Loss": 0.008833030238747597, "_runtime": 6372.291131496429, "_timestamp": 1585603741.924001, "_step": 405}
{"Episode reward": -96.48533841823138, "Episode length": 999, "Policy Loss": -0.12835240364074707, "Value Loss": 0.017906079068779945, "_runtime": 6373.856085300446, "_timestamp": 1585603743.4889548, "_step": 406}
{"Episode reward": -96.07580099382368, "Episode length": 999, "Policy Loss": -0.11595161259174347, "Value Loss": 0.004818709101527929, "_runtime": 6375.424424409866, "_timestamp": 1585603745.057294, "_step": 407}
{"Episode reward": -95.77154608568917, "Episode length": 999, "Policy Loss": -0.09956113994121552, "Value Loss": 0.01877496764063835, "_runtime": 6376.993103504181, "_timestamp": 1585603746.625973, "_step": 408}
{"Episode reward": -97.29665812747263, "Episode length": 999, "Policy Loss": -0.1154945120215416, "Value Loss": 0.003784489119425416, "_runtime": 6378.557344913483, "_timestamp": 1585603748.1902144, "_step": 409}
{"Episode reward": -96.48773707475523, "Episode length": 999, "Policy Loss": -0.09077467024326324, "Value Loss": 0.009541590698063374, "_runtime": 6380.1254234313965, "_timestamp": 1585603749.758293, "_step": 410}
{"Episode reward": -94.95913541059647, "Episode length": 999, "Policy Loss": -0.06364310532808304, "Value Loss": 0.019542725756764412, "_runtime": 6381.731817007065, "_timestamp": 1585603751.3646865, "_step": 411}
{"Episode reward": -95.47560436376943, "Episode length": 999, "Policy Loss": -0.09403171390295029, "Value Loss": 0.01675304025411606, "_runtime": 6383.295581817627, "_timestamp": 1585603752.9284513, "_step": 412}
{"Episode reward": -96.86783066019814, "Episode length": 999, "Policy Loss": -0.08998321741819382, "Value Loss": 0.013031292706727982, "_runtime": 6384.874558210373, "_timestamp": 1585603754.5074277, "_step": 413}
{"Episode reward": -96.61208458761209, "Episode length": 999, "Policy Loss": -0.09056293219327927, "Value Loss": 0.0033652838319540024, "_runtime": 6386.438561201096, "_timestamp": 1585603756.0714307, "_step": 414}
{"Episode reward": -91.31631088595105, "Episode length": 999, "Policy Loss": -0.05156200751662254, "Value Loss": 0.01790575124323368, "_runtime": 6387.9851450920105, "_timestamp": 1585603757.6180146, "_step": 415}
{"Episode reward": -94.72923888803206, "Episode length": 999, "Policy Loss": -0.06990396231412888, "Value Loss": 0.004485265351831913, "_runtime": 6389.541231870651, "_timestamp": 1585603759.1741014, "_step": 416}
{"Episode reward": -95.74948218440099, "Episode length": 999, "Policy Loss": -0.07001667469739914, "Value Loss": 0.0010478179901838303, "_runtime": 6391.090132713318, "_timestamp": 1585603760.7230022, "_step": 417}
{"Episode reward": -96.72024034466095, "Episode length": 999, "Policy Loss": -0.08285534381866455, "Value Loss": 0.008612536825239658, "_runtime": 6392.6296536922455, "_timestamp": 1585603762.2625232, "_step": 418}
{"Episode reward": -94.46605925446298, "Episode length": 999, "Policy Loss": -0.09732339531183243, "Value Loss": 0.02236327715218067, "_runtime": 6394.178668498993, "_timestamp": 1585603763.811538, "_step": 419}
{"Episode reward": -94.20999471447796, "Episode length": 999, "Policy Loss": -0.08788259327411652, "Value Loss": 0.012988505885004997, "_runtime": 6395.734487295151, "_timestamp": 1585603765.3673568, "_step": 420}
{"Episode reward": -95.76184480602693, "Episode length": 999, "Policy Loss": -0.0764232948422432, "Value Loss": 0.0074190180748701096, "_runtime": 6397.277169466019, "_timestamp": 1585603766.910039, "_step": 421}
{"Episode reward": -94.7777735720027, "Episode length": 999, "Policy Loss": -0.06728043407201767, "Value Loss": 0.008453898131847382, "_runtime": 6398.824933767319, "_timestamp": 1585603768.4578032, "_step": 422}
{"Episode reward": -97.81215470354731, "Episode length": 999, "Policy Loss": -0.05787576362490654, "Value Loss": 0.0052290200255811214, "_runtime": 6400.379693031311, "_timestamp": 1585603770.0125625, "_step": 423}
{"Episode reward": -96.0169244591403, "Episode length": 999, "Policy Loss": -0.03137160837650299, "Value Loss": 0.0022471630945801735, "_runtime": 6401.931781291962, "_timestamp": 1585603771.5646508, "_step": 424}
{"Episode reward": -93.67709050685727, "Episode length": 999, "Policy Loss": -0.016394075006246567, "Value Loss": 0.010129397734999657, "_runtime": 6403.4891884326935, "_timestamp": 1585603773.122058, "_step": 425}
{"Episode reward": -96.74188067915581, "Episode length": 999, "Policy Loss": -0.02980077639222145, "Value Loss": 0.0031206419225782156, "_runtime": 6405.071129322052, "_timestamp": 1585603774.7039988, "_step": 426}
{"Episode reward": -95.38162177969937, "Episode length": 999, "Policy Loss": 0.0013380348682403564, "Value Loss": 0.010303735733032227, "_runtime": 6406.627117395401, "_timestamp": 1585603776.2599869, "_step": 427}
{"Episode reward": -94.80225867241771, "Episode length": 999, "Policy Loss": -0.004456339869648218, "Value Loss": 0.00677781505510211, "_runtime": 6408.183304309845, "_timestamp": 1585603777.8161738, "_step": 428}
{"Episode reward": -97.0754202543545, "Episode length": 999, "Policy Loss": -0.02117597497999668, "Value Loss": 0.000840911059640348, "_runtime": 6409.738978862762, "_timestamp": 1585603779.3718483, "_step": 429}
{"Episode reward": -96.3909215500425, "Episode length": 999, "Policy Loss": -0.01490542758256197, "Value Loss": 0.0007110901060514152, "_runtime": 6411.291254997253, "_timestamp": 1585603780.9241245, "_step": 430}
{"Episode reward": -97.19739756435638, "Episode length": 999, "Policy Loss": -0.01158731896430254, "Value Loss": 0.0017764908261597157, "_runtime": 6412.85894203186, "_timestamp": 1585603782.4918115, "_step": 431}
{"Episode reward": -96.60999630225474, "Episode length": 999, "Policy Loss": -0.007146040443331003, "Value Loss": 0.0019702622666954994, "_runtime": 6414.416134357452, "_timestamp": 1585603784.0490038, "_step": 432}
{"Episode reward": -95.96077108802046, "Episode length": 999, "Policy Loss": -0.002748844912275672, "Value Loss": 0.0036918888799846172, "_runtime": 6415.981102705002, "_timestamp": 1585603785.6139722, "_step": 433}
{"Episode reward": -96.08815733482773, "Episode length": 999, "Policy Loss": -0.013337858952581882, "Value Loss": 0.004964430350810289, "_runtime": 6417.551174879074, "_timestamp": 1585603787.1840444, "_step": 434}
{"Episode reward": -94.29149937581842, "Episode length": 999, "Policy Loss": -0.005757882259786129, "Value Loss": 0.014069818891584873, "_runtime": 6419.120604753494, "_timestamp": 1585603788.7534742, "_step": 435}
{"Episode reward": -95.1201428491147, "Episode length": 999, "Policy Loss": -0.012225463055074215, "Value Loss": 0.005242492537945509, "_runtime": 6420.675583362579, "_timestamp": 1585603790.3084528, "_step": 436}
{"Episode reward": -94.15963801708628, "Episode length": 999, "Policy Loss": -0.0094457333907485, "Value Loss": 0.0048578581772744656, "_runtime": 6422.235734701157, "_timestamp": 1585603791.8686042, "_step": 437}
{"Episode reward": -95.25548084832178, "Episode length": 999, "Policy Loss": -0.0017293852288275957, "Value Loss": 0.005365207325667143, "_runtime": 6423.794725418091, "_timestamp": 1585603793.427595, "_step": 438}
{"Episode reward": -96.32489879290588, "Episode length": 999, "Policy Loss": 0.004377978388220072, "Value Loss": 0.0018215191084891558, "_runtime": 6425.359261035919, "_timestamp": 1585603794.9921305, "_step": 439}
{"Episode reward": -96.57613792118227, "Episode length": 999, "Policy Loss": -1.554802838654723e-05, "Value Loss": 0.0035421052016317844, "_runtime": 6426.926281929016, "_timestamp": 1585603796.5591514, "_step": 440}
{"Episode reward": -96.76350979188256, "Episode length": 999, "Policy Loss": 0.005144462920725346, "Value Loss": 0.0030581254977732897, "_runtime": 6428.538662910461, "_timestamp": 1585603798.1715324, "_step": 441}
{"Episode reward": -97.56659291375907, "Episode length": 999, "Policy Loss": 0.0008979878039099276, "Value Loss": 0.011802364140748978, "_runtime": 6430.105175256729, "_timestamp": 1585603799.7380447, "_step": 442}
{"Episode reward": -95.51079172401238, "Episode length": 999, "Policy Loss": 0.01901615783572197, "Value Loss": 0.003835738403722644, "_runtime": 6431.6746599674225, "_timestamp": 1585603801.3075294, "_step": 443}
{"Episode reward": -94.12977777184074, "Episode length": 999, "Policy Loss": 0.08738933503627777, "Value Loss": 0.038430552929639816, "_runtime": 6433.23317694664, "_timestamp": 1585603802.8660464, "_step": 444}
{"Episode reward": -92.24513069122068, "Episode length": 999, "Policy Loss": 0.02652059867978096, "Value Loss": 0.009123295545578003, "_runtime": 6434.796993732452, "_timestamp": 1585603804.4298632, "_step": 445}
{"Episode reward": -92.62029657527421, "Episode length": 999, "Policy Loss": 0.016057079657912254, "Value Loss": 0.006264126393944025, "_runtime": 6436.3671979904175, "_timestamp": 1585603806.0000675, "_step": 446}
{"Episode reward": -96.55189403929867, "Episode length": 999, "Policy Loss": 0.009827564470469952, "Value Loss": 0.0033236707095056772, "_runtime": 6437.937917232513, "_timestamp": 1585603807.5707867, "_step": 447}
{"Episode reward": -96.61030318461614, "Episode length": 999, "Policy Loss": 0.009642226621508598, "Value Loss": 0.006286602467298508, "_runtime": 6439.501253604889, "_timestamp": 1585603809.134123, "_step": 448}
{"Episode reward": -96.58198114625316, "Episode length": 999, "Policy Loss": 0.02389579452574253, "Value Loss": 0.004555815830826759, "_runtime": 6441.071901082993, "_timestamp": 1585603810.7047706, "_step": 449}
{"Episode reward": -96.85120701030363, "Episode length": 999, "Policy Loss": 0.003343880409374833, "Value Loss": 0.015094544738531113, "_runtime": 6442.628561258316, "_timestamp": 1585603812.2614307, "_step": 450}
{"Episode reward": -95.58939945263224, "Episode length": 999, "Policy Loss": -0.03523499518632889, "Value Loss": 0.04228648170828819, "_runtime": 6444.184052705765, "_timestamp": 1585603813.8169222, "_step": 451}
{"Episode reward": -96.14200062803259, "Episode length": 999, "Policy Loss": 0.01327366754412651, "Value Loss": 0.008850584737956524, "_runtime": 6445.756280183792, "_timestamp": 1585603815.3891497, "_step": 452}
{"Episode reward": -94.48715893897273, "Episode length": 999, "Policy Loss": -0.01285472046583891, "Value Loss": 0.012013586238026619, "_runtime": 6447.324898958206, "_timestamp": 1585603816.9577684, "_step": 453}
{"Episode reward": -96.47098000299496, "Episode length": 999, "Policy Loss": 0.00675984239205718, "Value Loss": 0.0028028972446918488, "_runtime": 6448.892199516296, "_timestamp": 1585603818.525069, "_step": 454}
{"Episode reward": -95.00097375864928, "Episode length": 999, "Policy Loss": 0.0034189156722277403, "Value Loss": 0.003466271795332432, "_runtime": 6450.463864564896, "_timestamp": 1585603820.096734, "_step": 455}
{"Episode reward": -96.18958736475865, "Episode length": 999, "Policy Loss": 0.0019500738708302379, "Value Loss": 0.0062348805367946625, "_runtime": 6452.0603902339935, "_timestamp": 1585603821.6932597, "_step": 456}
{"Episode reward": -96.86485574505612, "Episode length": 999, "Policy Loss": 0.005194666795432568, "Value Loss": 0.007733511738479137, "_runtime": 6453.613902807236, "_timestamp": 1585603823.2467723, "_step": 457}
{"Episode reward": -96.28864187672318, "Episode length": 999, "Policy Loss": 0.016275912523269653, "Value Loss": 0.002311267424374819, "_runtime": 6455.183984518051, "_timestamp": 1585603824.816854, "_step": 458}
{"Episode reward": -95.72546412956619, "Episode length": 999, "Policy Loss": 0.05691353604197502, "Value Loss": 0.02029864490032196, "_runtime": 6456.740064382553, "_timestamp": 1585603826.3729339, "_step": 459}
{"Episode reward": -96.65306319969528, "Episode length": 999, "Policy Loss": 0.024004025384783745, "Value Loss": 0.005004608538001776, "_runtime": 6458.304749965668, "_timestamp": 1585603827.9376194, "_step": 460}
{"Episode reward": -96.31864623065647, "Episode length": 999, "Policy Loss": 0.04448605328798294, "Value Loss": 0.012194528244435787, "_runtime": 6459.852620840073, "_timestamp": 1585603829.4854903, "_step": 461}
{"Episode reward": -95.85571497164906, "Episode length": 999, "Policy Loss": 0.017905671149492264, "Value Loss": 0.0023231245577335358, "_runtime": 6461.398579120636, "_timestamp": 1585603831.0314486, "_step": 462}
{"Episode reward": -96.65538197377296, "Episode length": 999, "Policy Loss": 0.012351587414741516, "Value Loss": 0.0022442806512117386, "_runtime": 6462.953605890274, "_timestamp": 1585603832.5864754, "_step": 463}
{"Episode reward": -98.06367560103838, "Episode length": 999, "Policy Loss": 0.008611428551375866, "Value Loss": 0.0006911626551300287, "_runtime": 6464.519729375839, "_timestamp": 1585603834.1525989, "_step": 464}
{"Episode reward": -96.38378710070897, "Episode length": 999, "Policy Loss": 0.016984829679131508, "Value Loss": 0.0020983251743018627, "_runtime": 6466.087252140045, "_timestamp": 1585603835.7201216, "_step": 465}
{"Episode reward": -95.96560021782493, "Episode length": 999, "Policy Loss": -0.0016250086482614279, "Value Loss": 0.015574587509036064, "_runtime": 6467.651031255722, "_timestamp": 1585603837.2839007, "_step": 466}
{"Episode reward": -96.28787819039812, "Episode length": 999, "Policy Loss": 0.020383939146995544, "Value Loss": 0.0045601362362504005, "_runtime": 6469.2212591171265, "_timestamp": 1585603838.8541286, "_step": 467}
{"Episode reward": -96.36260676408673, "Episode length": 999, "Policy Loss": 0.005772797856479883, "Value Loss": 0.006272301543504, "_runtime": 6470.7894859313965, "_timestamp": 1585603840.4223554, "_step": 468}
{"Episode reward": -96.2491592623228, "Episode length": 999, "Policy Loss": -0.008182757534086704, "Value Loss": 0.007280157413333654, "_runtime": 6472.362775802612, "_timestamp": 1585603841.9956453, "_step": 469}
{"Episode reward": -95.31192760102951, "Episode length": 999, "Policy Loss": 0.0004803930060006678, "Value Loss": 0.004754849709570408, "_runtime": 6473.966705322266, "_timestamp": 1585603843.5995748, "_step": 470}
{"Episode reward": -97.60650442984554, "Episode length": 999, "Policy Loss": 0.006110717076808214, "Value Loss": 0.0011151599464938045, "_runtime": 6475.523486614227, "_timestamp": 1585603845.156356, "_step": 471}
{"Episode reward": -96.23234481936073, "Episode length": 999, "Policy Loss": 0.012179763056337833, "Value Loss": 0.0012165505904704332, "_runtime": 6477.090710401535, "_timestamp": 1585603846.72358, "_step": 472}
{"Episode reward": -94.49879396792957, "Episode length": 999, "Policy Loss": 0.04724370688199997, "Value Loss": 0.009202532470226288, "_runtime": 6478.658575057983, "_timestamp": 1585603848.2914445, "_step": 473}
{"Episode reward": -92.91544501834451, "Episode length": 999, "Policy Loss": 0.06527477502822876, "Value Loss": 0.015470126643776894, "_runtime": 6480.228478193283, "_timestamp": 1585603849.8613477, "_step": 474}
{"Episode reward": -96.6720852392017, "Episode length": 999, "Policy Loss": 0.025014234706759453, "Value Loss": 0.0053387852385640144, "_runtime": 6481.792025089264, "_timestamp": 1585603851.4248946, "_step": 475}
{"Episode reward": -96.90610589118614, "Episode length": 999, "Policy Loss": 0.010725652799010277, "Value Loss": 0.001410632161423564, "_runtime": 6483.360637426376, "_timestamp": 1585603852.993507, "_step": 476}
{"Episode reward": -96.51321899194406, "Episode length": 999, "Policy Loss": 0.010617741383612156, "Value Loss": 0.000979679636657238, "_runtime": 6484.931620359421, "_timestamp": 1585603854.5644898, "_step": 477}
{"Episode reward": -94.69615359519187, "Episode length": 999, "Policy Loss": 0.010245352983474731, "Value Loss": 0.0019542996305972338, "_runtime": 6486.497745513916, "_timestamp": 1585603856.130615, "_step": 478}
{"Episode reward": -94.90266705553307, "Episode length": 999, "Policy Loss": -0.00560717424377799, "Value Loss": 0.005287326406687498, "_runtime": 6488.067793369293, "_timestamp": 1585603857.7006629, "_step": 479}
{"Episode reward": -97.00665708110989, "Episode length": 999, "Policy Loss": 0.002554827369749546, "Value Loss": 0.001971850171685219, "_runtime": 6489.634888887405, "_timestamp": 1585603859.2677584, "_step": 480}
{"Episode reward": -95.88282056577162, "Episode length": 999, "Policy Loss": -0.005723925307393074, "Value Loss": 0.006567979697138071, "_runtime": 6491.192259788513, "_timestamp": 1585603860.8251293, "_step": 481}
{"Episode reward": -96.46768225063818, "Episode length": 999, "Policy Loss": -0.003956535831093788, "Value Loss": 0.0025868865195661783, "_runtime": 6492.7488424777985, "_timestamp": 1585603862.381712, "_step": 482}
{"Episode reward": -97.16437907584212, "Episode length": 999, "Policy Loss": 0.0018707320559769869, "Value Loss": 0.0009828070178627968, "_runtime": 6494.308246850967, "_timestamp": 1585603863.9411163, "_step": 483}
{"Episode reward": -96.74664119088123, "Episode length": 999, "Policy Loss": 0.0025275119114667177, "Value Loss": 0.0009754243073984981, "_runtime": 6495.865447759628, "_timestamp": 1585603865.4983172, "_step": 484}
{"Episode reward": -94.09809485396858, "Episode length": 999, "Policy Loss": 0.008129524067044258, "Value Loss": 0.0027231224812567234, "_runtime": 6497.461351156235, "_timestamp": 1585603867.0942206, "_step": 485}
{"Episode reward": -95.98885355835195, "Episode length": 999, "Policy Loss": 0.006750811822712421, "Value Loss": 0.001074863481335342, "_runtime": 6499.030180931091, "_timestamp": 1585603868.6630504, "_step": 486}
{"Episode reward": -95.91640922336315, "Episode length": 999, "Policy Loss": 0.0039048183243721724, "Value Loss": 0.000771267048548907, "_runtime": 6500.596049547195, "_timestamp": 1585603870.228919, "_step": 487}
{"Episode reward": -95.7901066275786, "Episode length": 999, "Policy Loss": 0.0091356560587883, "Value Loss": 0.0011323943035677075, "_runtime": 6502.165141105652, "_timestamp": 1585603871.7980106, "_step": 488}
{"Episode reward": -96.67527494611376, "Episode length": 999, "Policy Loss": 0.003135493490844965, "Value Loss": 0.00046735236537642777, "_runtime": 6503.7356860637665, "_timestamp": 1585603873.3685555, "_step": 489}
{"Episode reward": -96.51094562642227, "Episode length": 999, "Policy Loss": 0.004038766957819462, "Value Loss": 0.0006311869947239757, "_runtime": 6505.303251504898, "_timestamp": 1585603874.936121, "_step": 490}
{"Episode reward": -94.17194228513813, "Episode length": 999, "Policy Loss": 0.017625246196985245, "Value Loss": 0.0037276041693985462, "_runtime": 6506.869058609009, "_timestamp": 1585603876.501928, "_step": 491}
{"Episode reward": -94.70048207201992, "Episode length": 999, "Policy Loss": 0.016956767067313194, "Value Loss": 0.003049780149012804, "_runtime": 6508.438053846359, "_timestamp": 1585603878.0709233, "_step": 492}
{"Episode reward": -96.57048451067723, "Episode length": 999, "Policy Loss": 0.0020743110217154026, "Value Loss": 0.0004150882305111736, "_runtime": 6509.9921662807465, "_timestamp": 1585603879.6250358, "_step": 493}
{"Episode reward": -97.0074068989454, "Episode length": 999, "Policy Loss": 0.00034655636409297585, "Value Loss": 0.0006195118185132742, "_runtime": 6511.560282707214, "_timestamp": 1585603881.1931522, "_step": 494}
{"Episode reward": -95.90374062187263, "Episode length": 999, "Policy Loss": 0.005801209714263678, "Value Loss": 0.0010368842631578445, "_runtime": 6513.128367185593, "_timestamp": 1585603882.7612367, "_step": 495}
{"Episode reward": -95.84634636531923, "Episode length": 999, "Policy Loss": -4.967809945810586e-05, "Value Loss": 0.001540115219540894, "_runtime": 6514.690163850784, "_timestamp": 1585603884.3230333, "_step": 496}
{"Episode reward": -97.5701166923002, "Episode length": 999, "Policy Loss": -0.0005943867145106196, "Value Loss": 0.0004878812760580331, "_runtime": 6516.259148836136, "_timestamp": 1585603885.8920183, "_step": 497}
{"Episode reward": -95.80853084357881, "Episode length": 999, "Policy Loss": 0.001401296816766262, "Value Loss": 0.001716811559163034, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285, 0.10478366911411285]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5997979044914246, -0.5599462389945984, -0.5200945138931274, -0.48024284839630127, -0.4403911232948303, -0.40053945779800415, -0.3606877624988556, -0.32083606719970703, -0.28098437190055847, -0.2411326766014099, -0.20128098130226135, -0.1614292860031128, -0.12157762050628662, -0.08172589540481567, -0.0418742299079895, -0.0020225048065185547, 0.03782916069030762, 0.07768082618713379, 0.11753255128860474, 0.1573842167854309, 0.19723594188690186, 0.23708760738372803, 0.276939332485199, 0.31679099798202515, 0.3566426634788513, 0.39649438858032227, 0.4363461136817932, 0.4761977791786194, 0.5160494446754456, 0.5559011101722717, 0.5957528948783875, 0.6356045603752136, 0.6754562258720398, 0.715307891368866, 0.7551595568656921, 0.7950113415718079, 0.834863007068634, 0.8747146725654602, 0.9145663380622864, 0.9544181227684021, 0.9942697882652283, 1.0341215133666992, 1.0739731788635254, 1.1138248443603516, 1.1536765098571777, 1.193528175354004, 1.23337984085083, 1.2732315063476562, 1.3130831718444824, 1.3529350757598877, 1.3927867412567139, 1.43263840675354, 1.4724900722503662, 1.5123417377471924, 1.5521934032440186, 1.5920450687408447, 1.631896734237671, 1.671748399734497, 1.7116000652313232, 1.7514517307281494, 1.7913036346435547, 1.8311553001403809, 1.871006965637207, 1.9108586311340332, 1.9507102966308594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1538017839193344, -0.14788946509361267, -0.14197714626789093, -0.1360648274421692, -0.13015249371528625, -0.12424018234014511, -0.11832785606384277, -0.11241553723812103, -0.10650321841239929, -0.10059089958667755, -0.09467858076095581, -0.08876625448465347, -0.08285393565893173, -0.07694161683320999, -0.07102929055690765, -0.06511697173118591, -0.05920465290546417, -0.05329233407974243, -0.04738001525402069, -0.04146768897771835, -0.03555537015199661, -0.029643051326274872, -0.023730725049972534, -0.017818406224250793, -0.011906087398529053, -0.005993768572807312, -8.144974708557129e-05, 0.005830869078636169, 0.011743202805519104, 0.017655521631240845, 0.023567840456962585, 0.029480159282684326, 0.03539247810840607, 0.04130479693412781, 0.04721711575984955, 0.05312943458557129, 0.05904175341129303, 0.06495408713817596, 0.0708664059638977, 0.07677872478961945, 0.08269104361534119, 0.08860336244106293, 0.09451568126678467, 0.10042800009250641, 0.10634033381938934, 0.11225263774394989, 0.11816497147083282, 0.12407727539539337, 0.1299896091222763, 0.13590194284915924, 0.1418142467737198, 0.14772658050060272, 0.15363888442516327, 0.1595512181520462, 0.16546352207660675, 0.17137585580348969, 0.17728818953037262, 0.18320049345493317, 0.1891128271818161, 0.19502513110637665, 0.20093746483325958, 0.20684976875782013, 0.21276210248470306, 0.2186744064092636, 0.22458674013614655]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 7.0, 5.0, 2.0, 0.0, 10.0, 9.0, 8.0, 5.0, 10.0, 18.0, 16.0, 23.0, 31.0, 47.0, 46.0, 42.0, 48.0, 26.0, 25.0, 37.0, 25.0, 18.0, 14.0, 4.0, 6.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.2488754242658615, -0.2395554631948471, -0.2302354872226715, -0.2209155261516571, -0.2115955650806427, -0.2022756040096283, -0.1929556280374527, -0.1836356669664383, -0.1743156909942627, -0.1649957299232483, -0.1556757688522339, -0.14635580778121948, -0.13703583180904388, -0.12771587073802948, -0.11839590966701508, -0.10907593369483948, -0.09975597262382507, -0.09043601155281067, -0.08111603558063507, -0.07179607450962067, -0.06247611343860626, -0.053156137466430664, -0.04383617639541626, -0.034516215324401855, -0.025196239352226257, -0.015876278281211853, -0.006556317210197449, 0.0027636438608169556, 0.01208360493183136, 0.021403595805168152, 0.030723556876182556, 0.04004351794719696, 0.049363479018211365, 0.05868344008922577, 0.06800340116024017, 0.07732336223125458, 0.08664335310459137, 0.09596331417560577, 0.10528327524662018, 0.11460323631763458, 0.12392319738864899, 0.1332431584596634, 0.14256314933300018, 0.1518831104040146, 0.161203071475029, 0.1705230325460434, 0.1798429936170578, 0.1891629546880722, 0.198482945561409, 0.2078029066324234, 0.2171228677034378, 0.2264428287744522, 0.2357627898454666, 0.24508275091648102, 0.25440269708633423, 0.26372265815734863, 0.27304261922836304, 0.28236258029937744, 0.2916826009750366, 0.301002562046051, 0.31032252311706543, 0.31964248418807983, 0.32896244525909424, 0.33828240633010864, 0.34760236740112305]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.0976823568344116, -1.0682481527328491, -1.0388140678405762, -1.0093798637390137, -0.979945719242096, -0.9505115747451782, -0.9210774302482605, -0.8916432857513428, -0.8622090816497803, -0.8327749967575073, -0.8033407926559448, -0.7739066481590271, -0.7444725036621094, -0.7150382995605469, -0.6856042146682739, -0.6561700105667114, -0.6267358660697937, -0.597301721572876, -0.5678675770759583, -0.5384333729743958, -0.508999228477478, -0.4795650839805603, -0.4501309394836426, -0.42069679498672485, -0.39126265048980713, -0.36182844638824463, -0.3323943018913269, -0.3029601573944092, -0.27352601289749146, -0.24409186840057373, -0.21465766429901123, -0.1852235198020935, -0.15578937530517578, -0.12635523080825806, -0.09692108631134033, -0.06748688220977783, -0.03805279731750488, -0.008618593215942383, 0.020815610885620117, 0.050249695777893066, 0.07968389987945557, 0.10911798477172852, 0.13855218887329102, 0.16798639297485352, 0.19742047786712646, 0.22685468196868896, 0.2562887668609619, 0.2857229709625244, 0.31515705585479736, 0.34459125995635986, 0.37402546405792236, 0.4034595489501953, 0.4328937530517578, 0.46232783794403076, 0.49176204204559326, 0.5211962461471558, 0.5506303310394287, 0.5800645351409912, 0.6094986200332642, 0.6389328241348267, 0.6683670282363892, 0.6978011131286621, 0.7272353172302246, 0.7566694021224976, 0.7861036062240601]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2144198417663574, -1.1798195838928223, -1.1452194452285767, -1.110619306564331, -1.076019048690796, -1.0414187908172607, -1.0068186521530151, -0.9722184538841248, -0.9376182556152344, -0.903018057346344, -0.8684178590774536, -0.8338176608085632, -0.7992174625396729, -0.7646172642707825, -0.7300170660018921, -0.6954168677330017, -0.6608166694641113, -0.626216471195221, -0.5916162729263306, -0.5570160746574402, -0.5224158763885498, -0.4878156781196594, -0.45321547985076904, -0.41861528158187866, -0.3840150833129883, -0.3494148850440979, -0.3148146867752075, -0.28021448850631714, -0.24561429023742676, -0.2110140323638916, -0.176413893699646, -0.1418137550354004, -0.10721349716186523, -0.07261323928833008, -0.03801310062408447, -0.003412961959838867, 0.03118729591369629, 0.06578755378723145, 0.10038769245147705, 0.13498783111572266, 0.1695880889892578, 0.20418834686279297, 0.23878848552703857, 0.2733886241912842, 0.30798888206481934, 0.3425891399383545, 0.3771892786026001, 0.4117894172668457, 0.44638967514038086, 0.480989933013916, 0.5155900716781616, 0.5501902103424072, 0.5847904682159424, 0.6193907260894775, 0.6539908647537231, 0.6885910034179688, 0.7231912612915039, 0.7577915191650391, 0.7923917770385742, 0.8269917964935303, 0.8615920543670654, 0.8961923122406006, 0.9307923316955566, 0.9653925895690918, 0.999992847442627]}, "_runtime": 6517.826195001602, "_timestamp": 1585603887.4590645, "_step": 498}
{"Episode reward": -95.19124085928537, "Episode length": 999, "Policy Loss": 0.0032816447783261538, "Value Loss": 0.001977704931050539, "_runtime": 6517.826195001602, "_timestamp": 1585603887.4590645, "_step": 499}
