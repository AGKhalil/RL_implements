{"Episode reward": -76.78998607475971, "Episode length": 999, "Policy Loss": -0.1426992267370224, "Value Loss": 0.05506747215986252, "_runtime": 15678.934466123581, "_timestamp": 1585585594.7790995, "_step": 0}
{"Episode reward": 45.36729964501511, "Episode length": 639, "Policy Loss": 0.4373757243156433, "Value Loss": 43.80846405029297, "_runtime": 15679.60491657257, "_timestamp": 1585585595.44955, "_step": 1}
{"Episode reward": 60.41866973237485, "Episode length": 458, "Policy Loss": 0.9103914499282837, "Value Loss": 294.71026611328125, "_runtime": 15680.767232179642, "_timestamp": 1585585596.6118655, "_step": 2}
{"Episode reward": 34.98463161129369, "Episode length": 728, "Policy Loss": 0.5181664824485779, "Value Loss": 43.21711349487305, "_runtime": 15681.654742717743, "_timestamp": 1585585597.499376, "_step": 3}
{"Episode reward": 48.26797844410468, "Episode length": 573, "Policy Loss": 0.26499900221824646, "Value Loss": 111.60364532470703, "_runtime": 15683.17521739006, "_timestamp": 1585585599.0198507, "_step": 4}
{"Episode reward": -92.49982809036533, "Episode length": 999, "Policy Loss": 0.15112006664276123, "Value Loss": 4.552905559539795, "_runtime": 15684.22279381752, "_timestamp": 1585585600.0674272, "_step": 5}
{"Episode reward": 37.861229820108264, "Episode length": 667, "Policy Loss": 1.5589691400527954, "Value Loss": 129.2084197998047, "_runtime": 15685.762830734253, "_timestamp": 1585585601.607464, "_step": 6}
{"Episode reward": -92.98101800718158, "Episode length": 999, "Policy Loss": 1.228513479232788, "Value Loss": 26.87803840637207, "_runtime": 15686.387912750244, "_timestamp": 1585585602.232546, "_step": 7}
{"Episode reward": 63.97269778793956, "Episode length": 385, "Policy Loss": 1.1579294204711914, "Value Loss": 29.1271915435791, "_runtime": 15687.93432378769, "_timestamp": 1585585603.7789571, "_step": 8}
{"Episode reward": -95.031143866161, "Episode length": 999, "Policy Loss": -0.10167372226715088, "Value Loss": 12.36520004272461, "_runtime": 15689.42900967598, "_timestamp": 1585585605.273643, "_step": 9}
{"Episode reward": 9.944472943424842, "Episode length": 944, "Policy Loss": 0.6817552447319031, "Value Loss": 16.65732192993164, "_runtime": 15690.488579750061, "_timestamp": 1585585606.333213, "_step": 10}
{"Episode reward": 31.576982153170235, "Episode length": 712, "Policy Loss": 0.04375844448804855, "Value Loss": 21.14269256591797, "_runtime": 15691.976325035095, "_timestamp": 1585585607.8209584, "_step": 11}
{"Episode reward": 13.26780481657731, "Episode length": 911, "Policy Loss": -0.3549388349056244, "Value Loss": 17.92232894897461, "_runtime": 15693.271977424622, "_timestamp": 1585585609.1166108, "_step": 12}
{"Episode reward": 21.550579326619754, "Episode length": 820, "Policy Loss": -0.574066698551178, "Value Loss": 12.243632316589355, "_runtime": 15694.038509130478, "_timestamp": 1585585609.8831425, "_step": 13}
{"Episode reward": 51.798895686121625, "Episode length": 501, "Policy Loss": -0.4200073778629303, "Value Loss": 20.577390670776367, "_runtime": 15695.60845375061, "_timestamp": 1585585611.453087, "_step": 14}
{"Episode reward": -96.30527865350209, "Episode length": 999, "Policy Loss": -1.1181529760360718, "Value Loss": 3.3563742637634277, "_runtime": 15697.16958642006, "_timestamp": 1585585613.0142198, "_step": 15}
{"Episode reward": -95.26085011876387, "Episode length": 999, "Policy Loss": -1.1360862255096436, "Value Loss": 5.793054103851318, "_runtime": 15698.103555440903, "_timestamp": 1585585613.9481888, "_step": 16}
{"Episode reward": 41.25235853004698, "Episode length": 610, "Policy Loss": -0.6006522178649902, "Value Loss": 21.53724479675293, "_runtime": 15698.670323133469, "_timestamp": 1585585614.5149565, "_step": 17}
{"Episode reward": 67.22503731961845, "Episode length": 340, "Policy Loss": 0.2481442242860794, "Value Loss": 29.72234535217285, "_runtime": 15700.24616599083, "_timestamp": 1585585616.0907993, "_step": 18}
{"Episode reward": -96.1331476135462, "Episode length": 999, "Policy Loss": -0.9990209937095642, "Value Loss": 1.2695955038070679, "_runtime": 15701.326494932175, "_timestamp": 1585585617.1711283, "_step": 19}
{"Episode reward": 32.54196647920227, "Episode length": 700, "Policy Loss": -0.4851604402065277, "Value Loss": 13.754385948181152, "_runtime": 15702.762721300125, "_timestamp": 1585585618.6073546, "_step": 20}
{"Episode reward": 8.313768950422897, "Episode length": 953, "Policy Loss": -0.23414009809494019, "Value Loss": 11.173744201660156, "_runtime": 15704.309622049332, "_timestamp": 1585585620.1542554, "_step": 21}
{"Episode reward": 5.676858787534044, "Episode length": 973, "Policy Loss": -0.4954058825969696, "Value Loss": 10.745741844177246, "_runtime": 15705.857622623444, "_timestamp": 1585585621.702256, "_step": 22}
{"Episode reward": -96.99301216290114, "Episode length": 999, "Policy Loss": -0.8238145709037781, "Value Loss": 0.20804396271705627, "_runtime": 15707.40881228447, "_timestamp": 1585585623.2534456, "_step": 23}
{"Episode reward": -96.91314940504468, "Episode length": 999, "Policy Loss": -0.79456627368927, "Value Loss": 0.08954411000013351, "_runtime": 15707.88493514061, "_timestamp": 1585585623.7295685, "_step": 24}
{"Episode reward": 73.49745950879695, "Episode length": 270, "Policy Loss": 0.6362419128417969, "Value Loss": 36.574405670166016, "_runtime": 15708.81456565857, "_timestamp": 1585585624.659199, "_step": 25}
{"Episode reward": 44.15018942190158, "Episode length": 585, "Policy Loss": -0.19385600090026855, "Value Loss": 16.935649871826172, "_runtime": 15710.372084379196, "_timestamp": 1585585626.2167177, "_step": 26}
{"Episode reward": -97.31859539154893, "Episode length": 999, "Policy Loss": -0.7573775053024292, "Value Loss": 0.13747364282608032, "_runtime": 15711.50046801567, "_timestamp": 1585585627.3451014, "_step": 27}
{"Episode reward": 27.047423541404143, "Episode length": 750, "Policy Loss": -0.2853012979030609, "Value Loss": 13.21716022491455, "_runtime": 15713.036432504654, "_timestamp": 1585585628.8810658, "_step": 28}
{"Episode reward": -97.15193246124514, "Episode length": 999, "Policy Loss": -0.7391024827957153, "Value Loss": 0.04848027229309082, "_runtime": 15714.446333169937, "_timestamp": 1585585630.2909665, "_step": 29}
{"Episode reward": 12.08684023566795, "Episode length": 895, "Policy Loss": -0.23388172686100006, "Value Loss": 11.12504768371582, "_runtime": 15714.991316080093, "_timestamp": 1585585630.8359494, "_step": 30}
{"Episode reward": 67.30973787576258, "Episode length": 333, "Policy Loss": 0.8239142298698425, "Value Loss": 29.945907592773438, "_runtime": 15715.872385501862, "_timestamp": 1585585631.7170188, "_step": 31}
{"Episode reward": 46.15092222421197, "Episode length": 553, "Policy Loss": -0.06137715280056, "Value Loss": 18.098039627075195, "_runtime": 15717.48091673851, "_timestamp": 1585585633.32555, "_step": 32}
{"Episode reward": -97.52973387927325, "Episode length": 999, "Policy Loss": -0.7092852592468262, "Value Loss": 0.04046160355210304, "_runtime": 15718.99254322052, "_timestamp": 1585585634.8371766, "_step": 33}
{"Episode reward": -97.6340842828365, "Episode length": 999, "Policy Loss": -0.7070755362510681, "Value Loss": 0.03787112981081009, "_runtime": 15720.5297062397, "_timestamp": 1585585636.3743396, "_step": 34}
{"Episode reward": -97.7051052709125, "Episode length": 999, "Policy Loss": -0.6966441869735718, "Value Loss": 0.07134702056646347, "_runtime": 15722.11195397377, "_timestamp": 1585585637.9565873, "_step": 35}
{"Episode reward": -97.29164042832447, "Episode length": 999, "Policy Loss": -0.7017244100570679, "Value Loss": 0.05037134513258934, "_runtime": 15723.67973780632, "_timestamp": 1585585639.5243711, "_step": 36}
{"Episode reward": -96.40292815349977, "Episode length": 999, "Policy Loss": -0.68306565284729, "Value Loss": 0.04527916759252548, "_runtime": 15725.252569437027, "_timestamp": 1585585641.0972028, "_step": 37}
{"Episode reward": -97.83380446129988, "Episode length": 999, "Policy Loss": -0.6812381148338318, "Value Loss": 0.0779561698436737, "_runtime": 15726.812855243683, "_timestamp": 1585585642.6574886, "_step": 38}
{"Episode reward": -98.02333391732006, "Episode length": 999, "Policy Loss": -0.6667343974113464, "Value Loss": 0.03528687357902527, "_runtime": 15727.603873491287, "_timestamp": 1585585643.4485068, "_step": 39}
{"Episode reward": 52.79828454943014, "Episode length": 487, "Policy Loss": 0.15113112330436707, "Value Loss": 20.202842712402344, "_runtime": 15729.174886465073, "_timestamp": 1585585645.0195198, "_step": 40}
{"Episode reward": -97.70549811778874, "Episode length": 999, "Policy Loss": -0.6599863767623901, "Value Loss": 0.03762587532401085, "_runtime": 15730.758977174759, "_timestamp": 1585585646.6036105, "_step": 41}
{"Episode reward": -97.83040261643855, "Episode length": 999, "Policy Loss": -0.6495773792266846, "Value Loss": 0.037473566830158234, "_runtime": 15732.288525819778, "_timestamp": 1585585648.1331592, "_step": 42}
{"Episode reward": -98.29990104132173, "Episode length": 999, "Policy Loss": -0.6394665837287903, "Value Loss": 0.028478994965553284, "_runtime": 15733.865806818008, "_timestamp": 1585585649.7104402, "_step": 43}
{"Episode reward": -97.65600376120192, "Episode length": 999, "Policy Loss": -0.6311391592025757, "Value Loss": 0.02687900885939598, "_runtime": 15735.44999551773, "_timestamp": 1585585651.2946289, "_step": 44}
{"Episode reward": -97.68884640672177, "Episode length": 999, "Policy Loss": -0.6227954626083374, "Value Loss": 0.026466304436326027, "_runtime": 15736.65978217125, "_timestamp": 1585585652.5044155, "_step": 45}
{"Episode reward": 24.81776895497633, "Episode length": 769, "Policy Loss": 0.10950316488742828, "Value Loss": 27.16748046875, "_runtime": 15738.243796825409, "_timestamp": 1585585654.0884302, "_step": 46}
{"Episode reward": -98.26817376624872, "Episode length": 999, "Policy Loss": -0.6034958958625793, "Value Loss": 0.029287252575159073, "_runtime": 15739.86796927452, "_timestamp": 1585585655.7126026, "_step": 47}
{"Episode reward": -97.25710136283382, "Episode length": 999, "Policy Loss": -0.5867168307304382, "Value Loss": 0.03313687443733215, "_runtime": 15740.626525878906, "_timestamp": 1585585656.4711592, "_step": 48}
{"Episode reward": 53.981705381063236, "Episode length": 471, "Policy Loss": 0.19168877601623535, "Value Loss": 21.041034698486328, "_runtime": 15741.045943021774, "_timestamp": 1585585656.8905764, "_step": 49}
{"Episode reward": 77.15938450679246, "Episode length": 232, "Policy Loss": 1.447043538093567, "Value Loss": 42.4083137512207, "_runtime": 15742.158724546432, "_timestamp": 1585585658.003358, "_step": 50}
{"Episode reward": 31.683151112203234, "Episode length": 703, "Policy Loss": 0.024289235472679138, "Value Loss": 13.957399368286133, "_runtime": 15743.598520994186, "_timestamp": 1585585659.4431543, "_step": 51}
{"Episode reward": 8.946560653864509, "Episode length": 931, "Policy Loss": -0.021343274042010307, "Value Loss": 10.85573959350586, "_runtime": 15745.095998764038, "_timestamp": 1585585660.940632, "_step": 52}
{"Episode reward": -97.85763705768477, "Episode length": 999, "Policy Loss": -0.5333016514778137, "Value Loss": 0.10720399767160416, "_runtime": 15745.858647584915, "_timestamp": 1585585661.703281, "_step": 53}
{"Episode reward": 53.75565517423874, "Episode length": 477, "Policy Loss": 0.21306012570858002, "Value Loss": 20.579940795898438, "_runtime": 15747.423448085785, "_timestamp": 1585585663.2680814, "_step": 54}
{"Episode reward": -97.96844229506024, "Episode length": 999, "Policy Loss": -0.5704687833786011, "Value Loss": 0.29436272382736206, "_runtime": 15748.205879449844, "_timestamp": 1585585664.0505128, "_step": 55}
{"Episode reward": 51.256278957964106, "Episode length": 492, "Policy Loss": 0.15585070848464966, "Value Loss": 19.902013778686523, "_runtime": 15749.728967666626, "_timestamp": 1585585665.573601, "_step": 56}
{"Episode reward": -97.54487364549716, "Episode length": 999, "Policy Loss": -0.5318511724472046, "Value Loss": 0.35295477509498596, "_runtime": 15751.308445692062, "_timestamp": 1585585667.153079, "_step": 57}
{"Episode reward": -97.92189990852432, "Episode length": 999, "Policy Loss": -0.5303317904472351, "Value Loss": 0.032761454582214355, "_runtime": 15752.53555393219, "_timestamp": 1585585668.3801873, "_step": 58}
{"Episode reward": 20.721038402013562, "Episode length": 808, "Policy Loss": -0.07855222374200821, "Value Loss": 12.208446502685547, "_runtime": 15754.09297132492, "_timestamp": 1585585669.9376047, "_step": 59}
{"Episode reward": -97.48231953880263, "Episode length": 999, "Policy Loss": -0.5290906429290771, "Value Loss": 0.02335224486887455, "_runtime": 15755.674234867096, "_timestamp": 1585585671.5188682, "_step": 60}
{"Episode reward": -98.24498001507136, "Episode length": 999, "Policy Loss": -0.5400566458702087, "Value Loss": 0.05241335183382034, "_runtime": 15757.214470863342, "_timestamp": 1585585673.0591042, "_step": 61}
{"Episode reward": -98.4067264115966, "Episode length": 999, "Policy Loss": -0.5350554585456848, "Value Loss": 0.056573186069726944, "_runtime": 15758.786187410355, "_timestamp": 1585585674.6308208, "_step": 62}
{"Episode reward": -97.88423653303427, "Episode length": 999, "Policy Loss": -0.5222299695014954, "Value Loss": 0.08826109021902084, "_runtime": 15760.37511086464, "_timestamp": 1585585676.2197442, "_step": 63}
{"Episode reward": -97.41605691490005, "Episode length": 999, "Policy Loss": -0.5169054269790649, "Value Loss": 0.04731302708387375, "_runtime": 15761.952551603317, "_timestamp": 1585585677.797185, "_step": 64}
{"Episode reward": -97.72288401855432, "Episode length": 999, "Policy Loss": -0.4980676472187042, "Value Loss": 0.11259622126817703, "_runtime": 15763.56379032135, "_timestamp": 1585585679.4084237, "_step": 65}
{"Episode reward": -97.6154794634561, "Episode length": 999, "Policy Loss": -0.4994361698627472, "Value Loss": 0.03103465400636196, "_runtime": 15765.156439781189, "_timestamp": 1585585681.0010731, "_step": 66}
{"Episode reward": -98.18397828792375, "Episode length": 999, "Policy Loss": -0.4868590235710144, "Value Loss": 0.016093801707029343, "_runtime": 15766.736090183258, "_timestamp": 1585585682.5807235, "_step": 67}
{"Episode reward": -98.3275608217802, "Episode length": 999, "Policy Loss": -0.4843076765537262, "Value Loss": 0.024135347455739975, "_runtime": 15767.985463619232, "_timestamp": 1585585683.830097, "_step": 68}
{"Episode reward": 22.505853275944318, "Episode length": 788, "Policy Loss": 0.01959311217069626, "Value Loss": 12.747127532958984, "_runtime": 15769.573432922363, "_timestamp": 1585585685.4180663, "_step": 69}
{"Episode reward": -98.32937245824203, "Episode length": 999, "Policy Loss": -0.4574800431728363, "Value Loss": 0.037861503660678864, "_runtime": 15771.148213624954, "_timestamp": 1585585686.992847, "_step": 70}
{"Episode reward": -97.6471650128081, "Episode length": 999, "Policy Loss": -0.4463649094104767, "Value Loss": 0.05510995164513588, "_runtime": 15772.7095079422, "_timestamp": 1585585688.5541413, "_step": 71}
{"Episode reward": -97.77249629817035, "Episode length": 999, "Policy Loss": -0.4345815181732178, "Value Loss": 0.03511054068803787, "_runtime": 15773.121156930923, "_timestamp": 1585585688.9657903, "_step": 72}
{"Episode reward": 77.95090562708688, "Episode length": 223, "Policy Loss": 1.2503993511199951, "Value Loss": 43.75309753417969, "_runtime": 15773.893182754517, "_timestamp": 1585585689.737816, "_step": 73}
{"Episode reward": 52.36522250823479, "Episode length": 481, "Policy Loss": 0.3570745289325714, "Value Loss": 20.76931381225586, "_runtime": 15775.48606801033, "_timestamp": 1585585691.3307014, "_step": 74}
{"Episode reward": -97.67162083664257, "Episode length": 999, "Policy Loss": -0.40908002853393555, "Value Loss": 0.19253094494342804, "_runtime": 15777.003470182419, "_timestamp": 1585585692.8481035, "_step": 75}
{"Episode reward": -97.99522315614523, "Episode length": 999, "Policy Loss": -0.38790062069892883, "Value Loss": 0.5132686495780945, "_runtime": 15778.543333053589, "_timestamp": 1585585694.3879664, "_step": 76}
{"Episode reward": -98.64819043721376, "Episode length": 999, "Policy Loss": -0.4099092185497284, "Value Loss": 0.10937273502349854, "_runtime": 15780.080309867859, "_timestamp": 1585585695.9249432, "_step": 77}
{"Episode reward": 5.538748026094581, "Episode length": 968, "Policy Loss": -0.009762602858245373, "Value Loss": 10.128717422485352, "_runtime": 15781.4451816082, "_timestamp": 1585585697.289815, "_step": 78}
{"Episode reward": 15.174986813522352, "Episode length": 873, "Policy Loss": 0.020836740732192993, "Value Loss": 11.342002868652344, "_runtime": 15783.01785826683, "_timestamp": 1585585698.8624916, "_step": 79}
{"Episode reward": -98.22951792488401, "Episode length": 999, "Policy Loss": -0.40391457080841064, "Value Loss": 0.029569251462817192, "_runtime": 15783.92021560669, "_timestamp": 1585585699.764849, "_step": 80}
{"Episode reward": 45.66135287017275, "Episode length": 556, "Policy Loss": 0.5411052107810974, "Value Loss": 17.932512283325195, "_runtime": 15784.794526576996, "_timestamp": 1585585700.63916, "_step": 81}
{"Episode reward": 46.12954382826835, "Episode length": 548, "Policy Loss": 0.2856598198413849, "Value Loss": 18.10489845275879, "_runtime": 15785.416532993317, "_timestamp": 1585585701.2611663, "_step": 82}
{"Episode reward": 63.361332292703295, "Episode length": 372, "Policy Loss": 0.62532639503479, "Value Loss": 26.385915756225586, "_runtime": 15786.956634044647, "_timestamp": 1585585702.8012674, "_step": 83}
{"Episode reward": -97.06095628329896, "Episode length": 999, "Policy Loss": -0.3826996386051178, "Value Loss": 0.0244144294410944, "_runtime": 15788.495391130447, "_timestamp": 1585585704.3400245, "_step": 84}
{"Episode reward": -96.58865620830068, "Episode length": 999, "Policy Loss": -0.3640422224998474, "Value Loss": 0.07085450738668442, "_runtime": 15790.050191640854, "_timestamp": 1585585705.894825, "_step": 85}
{"Episode reward": -97.35039107513403, "Episode length": 999, "Policy Loss": -0.37453725934028625, "Value Loss": 0.09694471955299377, "_runtime": 15791.624551773071, "_timestamp": 1585585707.469185, "_step": 86}
{"Episode reward": -97.62984437245477, "Episode length": 999, "Policy Loss": -0.3797159790992737, "Value Loss": 1.3778820037841797, "_runtime": 15792.508203744888, "_timestamp": 1585585708.352837, "_step": 87}
{"Episode reward": 46.46099906528705, "Episode length": 550, "Policy Loss": 0.389726459980011, "Value Loss": 17.52128028869629, "_runtime": 15793.589141368866, "_timestamp": 1585585709.4337747, "_step": 88}
{"Episode reward": 33.40978371788174, "Episode length": 677, "Policy Loss": 0.2064206302165985, "Value Loss": 14.174213409423828, "_runtime": 15795.164800405502, "_timestamp": 1585585711.0094337, "_step": 89}
{"Episode reward": -97.48401548687393, "Episode length": 999, "Policy Loss": -0.36552733182907104, "Value Loss": 0.009924405254423618, "_runtime": 15796.695824861526, "_timestamp": 1585585712.5404582, "_step": 90}
{"Episode reward": -97.94148556687925, "Episode length": 999, "Policy Loss": -0.37047654390335083, "Value Loss": 0.008307313546538353, "_runtime": 15797.641821146011, "_timestamp": 1585585713.4864545, "_step": 91}
{"Episode reward": 41.46525647780254, "Episode length": 601, "Policy Loss": 0.25105705857276917, "Value Loss": 16.284912109375, "_runtime": 15799.215999603271, "_timestamp": 1585585715.060633, "_step": 92}
{"Episode reward": -98.0667946658894, "Episode length": 999, "Policy Loss": -0.36611148715019226, "Value Loss": 0.00822788942605257, "_runtime": 15800.795066356659, "_timestamp": 1585585716.6396997, "_step": 93}
{"Episode reward": -97.5080222875833, "Episode length": 999, "Policy Loss": -0.355417937040329, "Value Loss": 0.008223396725952625, "_runtime": 15802.338039398193, "_timestamp": 1585585718.1826727, "_step": 94}
{"Episode reward": -97.32580330383051, "Episode length": 999, "Policy Loss": -0.3499220013618469, "Value Loss": 0.007572523318231106, "_runtime": 15803.913469791412, "_timestamp": 1585585719.7581031, "_step": 95}
{"Episode reward": -97.80400817102701, "Episode length": 999, "Policy Loss": -0.3481903374195099, "Value Loss": 0.007348765153437853, "_runtime": 15805.476666688919, "_timestamp": 1585585721.3213, "_step": 96}
{"Episode reward": -97.8756372212828, "Episode length": 999, "Policy Loss": -0.34190428256988525, "Value Loss": 0.007129827979952097, "_runtime": 15807.053780317307, "_timestamp": 1585585722.8984137, "_step": 97}
{"Episode reward": -96.92067512246699, "Episode length": 999, "Policy Loss": -0.33331745862960815, "Value Loss": 0.006798832211643457, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673, 0.05754275619983673]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.053857624530792236, -0.049352675676345825, -0.044847726821899414, -0.040342774242162704, -0.03583782538771629, -0.03133287653326988, -0.026827925816178322, -0.02232297509908676, -0.01781802624464035, -0.01331307739019394, -0.008808128535747528, -0.0043031759560108185, 0.00020177289843559265, 0.004706721752882004, 0.009211674332618713, 0.013716623187065125, 0.018221572041511536, 0.022726520895957947, 0.027231469750404358, 0.03173641860485077, 0.03624136745929718, 0.04074632376432419, 0.0452512726187706, 0.04975622147321701, 0.05426117032766342, 0.05876611918210983, 0.06327106803655624, 0.06777601689100266, 0.07228097319602966, 0.07678592205047607, 0.08129087090492249, 0.0857958197593689, 0.09030076861381531, 0.09480571746826172, 0.09931066632270813, 0.10381561517715454, 0.10832056403160095, 0.11282551288604736, 0.11733046174049377, 0.12183541059494019, 0.1263403594493866, 0.1308453232049942, 0.1353502720594406, 0.13985522091388702, 0.14436016976833344, 0.14886511862277985, 0.15337006747722626, 0.15787501633167267, 0.16237996518611908, 0.1668849140405655, 0.1713898628950119, 0.1758948117494583, 0.18039976060390472, 0.18490470945835114, 0.18940965831279755, 0.19391460716724396, 0.19841957092285156, 0.20292451977729797, 0.20742946863174438, 0.2119344174861908, 0.2164393663406372, 0.22094431519508362, 0.22544926404953003, 0.22995421290397644, 0.23445916175842285]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005125730764120817, -0.004431616980582476, -0.0037375029642134905, -0.0030433889478445053, -0.002349275164306164, -0.0016551613807678223, -0.0009610471315681934, -0.0002669333480298519, 0.0004271804355084896, 0.0011212942190468311, 0.0018154080025851727, 0.0025095222517848015, 0.0032036365009844303, 0.003897750284522772, 0.004591864068061113, 0.005285977851599455, 0.005980091635137796, 0.006674205418676138, 0.0073683192022144794, 0.008062433451414108, 0.008756546303629875, 0.009450661018490791, 0.010144775733351707, 0.010838888585567474, 0.01153300330042839, 0.012227116152644157, 0.012921230867505074, 0.01361534371972084, 0.014309458434581757, 0.015003571286797523, 0.01569768600165844, 0.016391798853874207, 0.017085913568735123, 0.01778002828359604, 0.018474141135811806, 0.019168255850672722, 0.01986236870288849, 0.020556483417749405, 0.021250596269965172, 0.021944710984826088, 0.022638823837041855, 0.02333293855190277, 0.024027053266763687, 0.024721166118979454, 0.02541528083384037, 0.026109393686056137, 0.026803508400917053, 0.02749762311577797, 0.028191737830638885, 0.028885848820209503, 0.02957996353507042, 0.030274078249931335, 0.03096819296479225, 0.03166230395436287, 0.032356418669223785, 0.0330505333840847, 0.03374464809894562, 0.034438762813806534, 0.03513287380337715, 0.03582698851823807, 0.036521103233098984, 0.0372152179479599, 0.03790932893753052, 0.038603443652391434, 0.03929755836725235]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 5.0, 3.0, 7.0, 11.0, 9.0, 8.0, 9.0, 10.0, 8.0, 8.0, 8.0, 12.0, 25.0, 67.0, 84.0, 89.0, 38.0, 6.0, 6.0, 6.0, 4.0, 8.0, 6.0, 7.0, 7.0, 5.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 3.0, 4.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.030796470120549202, -0.029494712129235268, -0.028192954137921333, -0.0268911961466074, -0.025589438155293465, -0.02428768016397953, -0.022985920310020447, -0.021684162318706512, -0.020382404327392578, -0.019080646336078644, -0.01777888834476471, -0.016477130353450775, -0.01517537236213684, -0.013873614370822906, -0.012571856379508972, -0.011270098388195038, -0.009968340396881104, -0.00866658240556717, -0.007364824414253235, -0.0060630664229393005, -0.004761308431625366, -0.003459550440311432, -0.0021577924489974976, -0.0008560344576835632, 0.0004457253962755203, 0.0017474833875894547, 0.003049241378903389, 0.004350999370217323, 0.005652757361531258, 0.006954515352845192, 0.008256273344159126, 0.00955803133547306, 0.010859789326786995, 0.01216154731810093, 0.013463305309414864, 0.014765063300728798, 0.016066821292042732, 0.017368579283356667, 0.0186703372746706, 0.019972095265984535, 0.02127385325729847, 0.022575611248612404, 0.023877369239926338, 0.025179127231240273, 0.026480885222554207, 0.02778264321386814, 0.029084401205182076, 0.03038615919649601, 0.03168792277574539, 0.032989680767059326, 0.03429143875837326, 0.035593196749687195, 0.03689495474100113, 0.038196712732315063, 0.039498470723629, 0.04080022871494293, 0.042101986706256866, 0.0434037446975708, 0.044705502688884735, 0.04600726068019867, 0.047309018671512604, 0.04861077666282654, 0.04991253465414047, 0.05121429264545441, 0.05251605063676834]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.05613696947693825, -0.05428972467780113, -0.052442483603954315, -0.0505952388048172, -0.048747994005680084, -0.04690075293183327, -0.04505350813269615, -0.043206267058849335, -0.04135902225971222, -0.039511777460575104, -0.03766453638672829, -0.03581729158759117, -0.033970050513744354, -0.03212280571460724, -0.030275560915470123, -0.028428317978978157, -0.02658107504248619, -0.024733830243349075, -0.02288658916950226, -0.021039344370365143, -0.019192103296518326, -0.01734485849738121, -0.015497613698244095, -0.013650372624397278, -0.011803127825260162, -0.009955883026123047, -0.00810864195227623, -0.006261397153139114, -0.004414152354001999, -0.002566911280155182, -0.0007196664810180664, 0.0011275745928287506, 0.002974819391965866, 0.004822064191102982, 0.006669308990240097, 0.008516546338796616, 0.010363791137933731, 0.012211035937070847, 0.014058280736207962, 0.015905525535345078, 0.017752762883901596, 0.01960000768303871, 0.021447252482175827, 0.023294497281312943, 0.025141742080450058, 0.026988986879587173, 0.028836224228143692, 0.030683469027280807, 0.03253071382641792, 0.03437795862555504, 0.036225203424692154, 0.03807244077324867, 0.03991968557238579, 0.0417669303715229, 0.04361417517066002, 0.045461419969797134, 0.04730866476893425, 0.04915590211749077, 0.051003146916627884, 0.052850391715765, 0.054697636514902115, 0.05654488131403923, 0.05839211866259575, 0.060239363461732864, 0.06208660826086998]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.035337962210178375, -0.03386102616786957, -0.03238409012556076, -0.030907152220606804, -0.029430214315652847, -0.02795327827334404, -0.026476342231035233, -0.024999406188726425, -0.02352246828377247, -0.022045530378818512, -0.020568594336509705, -0.019091658294200897, -0.01761472225189209, -0.016137784346938133, -0.014660848304629326, -0.01318391039967537, -0.011706974357366562, -0.010230038315057755, -0.008753100410103798, -0.0072761643677949905, -0.005799226462841034, -0.0043222904205322266, -0.002845354378223419, -0.0013684183359146118, 0.00010851770639419556, 0.0015854574739933014, 0.0030623935163021088, 0.004539329558610916, 0.0060162656009197235, 0.007493201643228531, 0.008970141410827637, 0.010447077453136444, 0.011924013495445251, 0.013400949537754059, 0.014877885580062866, 0.016354825347661972, 0.01783176138997078, 0.019308697432279587, 0.020785633474588394, 0.0222625695168972, 0.023739509284496307, 0.025216445326805115, 0.026693381369113922, 0.02817031741142273, 0.029647253453731537, 0.031124189496040344, 0.03260112553834915, 0.03407806158065796, 0.035554997622966766, 0.03703194111585617, 0.03850887715816498, 0.039985813200473785, 0.04146274924278259, 0.0429396852850914, 0.04441662132740021, 0.045893557369709015, 0.04737049341201782, 0.04884742945432663, 0.05032436549663544, 0.05180130898952484, 0.05327824503183365, 0.054755181074142456, 0.05623211711645126, 0.05770905315876007, 0.05918598920106888]}, "_runtime": 15808.645956277847, "_timestamp": 1585585724.4905896, "_step": 98}
{"Episode reward": -97.01690933901348, "Episode length": 999, "Policy Loss": -0.32503482699394226, "Value Loss": 0.006557953078299761, "_runtime": 15809.322914600372, "_timestamp": 1585585725.167548, "_step": 99}
{"Episode reward": 59.9729597221184, "Episode length": 411, "Policy Loss": 0.6538729071617126, "Value Loss": 24.17740249633789, "_runtime": 15810.260704278946, "_timestamp": 1585585726.1053376, "_step": 100}
{"Episode reward": 42.96004823481027, "Episode length": 590, "Policy Loss": 0.5107356905937195, "Value Loss": 16.812101364135742, "_runtime": 15811.840476512909, "_timestamp": 1585585727.6851099, "_step": 101}
{"Episode reward": -96.83353761923854, "Episode length": 999, "Policy Loss": -0.3107186257839203, "Value Loss": 0.006394228897988796, "_runtime": 15812.561702251434, "_timestamp": 1585585728.4063356, "_step": 102}
{"Episode reward": 54.47528142262344, "Episode length": 462, "Policy Loss": 0.565360963344574, "Value Loss": 21.10186004638672, "_runtime": 15814.066562891006, "_timestamp": 1585585729.9111962, "_step": 103}
{"Episode reward": 6.343279282513066, "Episode length": 955, "Policy Loss": 0.15350143611431122, "Value Loss": 10.044873237609863, "_runtime": 15814.521696567535, "_timestamp": 1585585730.36633, "_step": 104}
{"Episode reward": 73.66607176949992, "Episode length": 267, "Policy Loss": 1.1057909727096558, "Value Loss": 35.58131408691406, "_runtime": 15815.44715309143, "_timestamp": 1585585731.2917864, "_step": 105}
{"Episode reward": 40.43219815923228, "Episode length": 609, "Policy Loss": 0.4164433181285858, "Value Loss": 15.513667106628418, "_runtime": 15817.01458787918, "_timestamp": 1585585732.8592212, "_step": 106}
{"Episode reward": -97.8377681825088, "Episode length": 999, "Policy Loss": -0.3094083070755005, "Value Loss": 0.04169275984168053, "_runtime": 15817.491189479828, "_timestamp": 1585585733.3358228, "_step": 107}
{"Episode reward": 70.18299027249599, "Episode length": 305, "Policy Loss": 0.865208089351654, "Value Loss": 33.024635314941406, "_runtime": 15818.86880159378, "_timestamp": 1585585734.713435, "_step": 108}
{"Episode reward": 12.204518840846774, "Episode length": 904, "Policy Loss": 0.09910575300455093, "Value Loss": 11.399569511413574, "_runtime": 15820.43323802948, "_timestamp": 1585585736.2778714, "_step": 109}
{"Episode reward": -98.5357139919898, "Episode length": 999, "Policy Loss": -0.3168244957923889, "Value Loss": 0.014242206700146198, "_runtime": 15821.702570199966, "_timestamp": 1585585737.5472035, "_step": 110}
{"Episode reward": 17.647746709549423, "Episode length": 846, "Policy Loss": 0.12506432831287384, "Value Loss": 11.472281455993652, "_runtime": 15823.259634494781, "_timestamp": 1585585739.1042678, "_step": 111}
{"Episode reward": -97.31724015100876, "Episode length": 999, "Policy Loss": -0.3215092718601227, "Value Loss": 0.008065293543040752, "_runtime": 15824.82767701149, "_timestamp": 1585585740.6723104, "_step": 112}
{"Episode reward": -97.41847284445187, "Episode length": 999, "Policy Loss": -0.3249405026435852, "Value Loss": 0.008433974348008633, "_runtime": 15826.355637788773, "_timestamp": 1585585742.2002711, "_step": 113}
{"Episode reward": -97.48181806996192, "Episode length": 999, "Policy Loss": -0.3277709484100342, "Value Loss": 0.007441360037773848, "_runtime": 15827.942640304565, "_timestamp": 1585585743.7872736, "_step": 114}
{"Episode reward": -97.43945243996995, "Episode length": 999, "Policy Loss": -0.3272347152233124, "Value Loss": 0.00861252099275589, "_runtime": 15829.528540372849, "_timestamp": 1585585745.3731737, "_step": 115}
{"Episode reward": -97.69933420436439, "Episode length": 999, "Policy Loss": -0.32670482993125916, "Value Loss": 0.010516020469367504, "_runtime": 15831.097571134567, "_timestamp": 1585585746.9422045, "_step": 116}
{"Episode reward": -97.21278960984013, "Episode length": 999, "Policy Loss": -0.3267788589000702, "Value Loss": 0.009708194062113762, "_runtime": 15832.685287475586, "_timestamp": 1585585748.5299208, "_step": 117}
{"Episode reward": -97.96958544930848, "Episode length": 999, "Policy Loss": -0.3275010287761688, "Value Loss": 0.007215718273073435, "_runtime": 15834.274310827255, "_timestamp": 1585585750.1189442, "_step": 118}
{"Episode reward": -97.54500428552576, "Episode length": 999, "Policy Loss": -0.3228538930416107, "Value Loss": 0.006952863186597824, "_runtime": 15835.851865768433, "_timestamp": 1585585751.696499, "_step": 119}
{"Episode reward": -98.0469660880545, "Episode length": 999, "Policy Loss": -0.3217877745628357, "Value Loss": 0.007221471052616835, "_runtime": 15837.48221874237, "_timestamp": 1585585753.326852, "_step": 120}
{"Episode reward": -97.98529485999295, "Episode length": 999, "Policy Loss": -0.3146824836730957, "Value Loss": 0.007051807828247547, "_runtime": 15839.060072660446, "_timestamp": 1585585754.904706, "_step": 121}
{"Episode reward": -98.33896042686199, "Episode length": 999, "Policy Loss": -0.3130824565887451, "Value Loss": 0.0066908891312778, "_runtime": 15840.625872135162, "_timestamp": 1585585756.4705055, "_step": 122}
{"Episode reward": -98.016988344073, "Episode length": 999, "Policy Loss": -0.3097999393939972, "Value Loss": 0.0058302986435592175, "_runtime": 15842.20122885704, "_timestamp": 1585585758.0458622, "_step": 123}
{"Episode reward": -97.84176308267186, "Episode length": 999, "Policy Loss": -0.30061665177345276, "Value Loss": 0.0056916517205536366, "_runtime": 15842.74314403534, "_timestamp": 1585585758.5877774, "_step": 124}
{"Episode reward": 69.66242175096099, "Episode length": 311, "Policy Loss": 0.9003608822822571, "Value Loss": 32.10813903808594, "_runtime": 15844.32305264473, "_timestamp": 1585585760.167686, "_step": 125}
{"Episode reward": -97.2017060272001, "Episode length": 999, "Policy Loss": -0.28893521428108215, "Value Loss": 0.0052838679403066635, "_runtime": 15845.414752483368, "_timestamp": 1585585761.2593858, "_step": 126}
{"Episode reward": 33.1041580315259, "Episode length": 681, "Policy Loss": 0.2427693009376526, "Value Loss": 14.667190551757812, "_runtime": 15846.94056558609, "_timestamp": 1585585762.785199, "_step": 127}
{"Episode reward": -97.43943723061507, "Episode length": 999, "Policy Loss": -0.28444135189056396, "Value Loss": 0.005141315050423145, "_runtime": 15848.533525943756, "_timestamp": 1585585764.3781593, "_step": 128}
{"Episode reward": -97.85963513040652, "Episode length": 999, "Policy Loss": -0.28468433022499084, "Value Loss": 0.005114842671900988, "_runtime": 15850.086862564087, "_timestamp": 1585585765.931496, "_step": 129}
{"Episode reward": -97.78657772609185, "Episode length": 999, "Policy Loss": -0.27895787358283997, "Value Loss": 0.004950099624693394, "_runtime": 15851.641471862793, "_timestamp": 1585585767.4861052, "_step": 130}
{"Episode reward": -97.37292903881789, "Episode length": 999, "Policy Loss": -0.27666833996772766, "Value Loss": 0.004813777282834053, "_runtime": 15852.857444763184, "_timestamp": 1585585768.702078, "_step": 131}
{"Episode reward": 24.903908049790772, "Episode length": 766, "Policy Loss": 0.24205626547336578, "Value Loss": 13.040963172912598, "_runtime": 15853.72422671318, "_timestamp": 1585585769.56886, "_step": 132}
{"Episode reward": 47.307975692516436, "Episode length": 537, "Policy Loss": 0.4058153033256531, "Value Loss": 18.60041618347168, "_runtime": 15855.282652139664, "_timestamp": 1585585771.1272855, "_step": 133}
{"Episode reward": -98.2056426717955, "Episode length": 999, "Policy Loss": -0.26901787519454956, "Value Loss": 0.0045709614641964436, "_runtime": 15856.105664253235, "_timestamp": 1585585771.9502976, "_step": 134}
{"Episode reward": 49.41388800322977, "Episode length": 523, "Policy Loss": 0.429923415184021, "Value Loss": 19.097917556762695, "_runtime": 15857.639452457428, "_timestamp": 1585585773.4840858, "_step": 135}
{"Episode reward": -97.15946351097705, "Episode length": 999, "Policy Loss": -0.26339954137802124, "Value Loss": 0.004453151486814022, "_runtime": 15859.215785741806, "_timestamp": 1585585775.060419, "_step": 136}
{"Episode reward": -97.6679142546115, "Episode length": 999, "Policy Loss": -0.2622606158256531, "Value Loss": 0.004425704479217529, "_runtime": 15860.199916124344, "_timestamp": 1585585776.0445495, "_step": 137}
{"Episode reward": 37.96323371368566, "Episode length": 638, "Policy Loss": 0.33201003074645996, "Value Loss": 15.656049728393555, "_runtime": 15861.346879005432, "_timestamp": 1585585777.1915123, "_step": 138}
{"Episode reward": 30.776423713148347, "Episode length": 711, "Policy Loss": 0.2900535464286804, "Value Loss": 14.04893684387207, "_runtime": 15862.912024497986, "_timestamp": 1585585778.7566578, "_step": 139}
{"Episode reward": -97.56531864164413, "Episode length": 999, "Policy Loss": -0.2595127820968628, "Value Loss": 0.004382892977446318, "_runtime": 15864.294745922089, "_timestamp": 1585585780.1393793, "_step": 140}
{"Episode reward": 12.361551200277233, "Episode length": 896, "Policy Loss": 0.27682608366012573, "Value Loss": 11.148696899414062, "_runtime": 15865.846041202545, "_timestamp": 1585585781.6906745, "_step": 141}
{"Episode reward": -97.5739710829602, "Episode length": 999, "Policy Loss": -0.25527748465538025, "Value Loss": 0.004418255295604467, "_runtime": 15867.427187919617, "_timestamp": 1585585783.2718213, "_step": 142}
{"Episode reward": -97.65232341845996, "Episode length": 999, "Policy Loss": -0.2505001723766327, "Value Loss": 0.004688785877078772, "_runtime": 15868.446275472641, "_timestamp": 1585585784.2909088, "_step": 143}
{"Episode reward": 38.01418172537645, "Episode length": 645, "Policy Loss": 0.493900328874588, "Value Loss": 15.48248291015625, "_runtime": 15869.79223394394, "_timestamp": 1585585785.6368673, "_step": 144}
{"Episode reward": 16.5343569429823, "Episode length": 857, "Policy Loss": 0.17598064243793488, "Value Loss": 11.654535293579102, "_runtime": 15871.164141893387, "_timestamp": 1585585787.0087752, "_step": 145}
{"Episode reward": 15.433493469356605, "Episode length": 867, "Policy Loss": 0.24167002737522125, "Value Loss": 11.54367733001709, "_runtime": 15872.26120376587, "_timestamp": 1585585788.105837, "_step": 146}
{"Episode reward": 31.994687303441992, "Episode length": 698, "Policy Loss": 0.35305631160736084, "Value Loss": 14.308884620666504, "_runtime": 15873.835625648499, "_timestamp": 1585585789.680259, "_step": 147}
{"Episode reward": -97.87740805485134, "Episode length": 999, "Policy Loss": -0.25363895297050476, "Value Loss": 0.004835843108594418, "_runtime": 15875.406291723251, "_timestamp": 1585585791.250925, "_step": 148}
{"Episode reward": -97.64544050412789, "Episode length": 999, "Policy Loss": -0.2549661695957184, "Value Loss": 0.004635684657841921, "_runtime": 15876.961848020554, "_timestamp": 1585585792.8064814, "_step": 149}
{"Episode reward": -97.03312333541703, "Episode length": 999, "Policy Loss": -0.2506997287273407, "Value Loss": 0.004545662552118301, "_runtime": 15878.542704820633, "_timestamp": 1585585794.3873382, "_step": 150}
{"Episode reward": -97.36602528990981, "Episode length": 999, "Policy Loss": -0.25181055068969727, "Value Loss": 0.005700696725398302, "_runtime": 15880.11352610588, "_timestamp": 1585585795.9581594, "_step": 151}
{"Episode reward": -97.63692464655223, "Episode length": 999, "Policy Loss": -0.25126248598098755, "Value Loss": 0.005012761801481247, "_runtime": 15881.621265411377, "_timestamp": 1585585797.4658988, "_step": 152}
{"Episode reward": 7.053530926419597, "Episode length": 959, "Policy Loss": 0.1282648742198944, "Value Loss": 10.41136646270752, "_runtime": 15882.5379383564, "_timestamp": 1585585798.3825717, "_step": 153}
{"Episode reward": 44.72996771678276, "Episode length": 572, "Policy Loss": 0.4148305356502533, "Value Loss": 17.448625564575195, "_runtime": 15883.728461503983, "_timestamp": 1585585799.5730948, "_step": 154}
{"Episode reward": 26.17538253207151, "Episode length": 755, "Policy Loss": 0.31600484251976013, "Value Loss": 13.222514152526855, "_runtime": 15885.34559416771, "_timestamp": 1585585801.1902275, "_step": 155}
{"Episode reward": -96.80482063759985, "Episode length": 999, "Policy Loss": -0.243367999792099, "Value Loss": 0.004895782098174095, "_runtime": 15886.884238243103, "_timestamp": 1585585802.7288716, "_step": 156}
{"Episode reward": -97.07604217553657, "Episode length": 999, "Policy Loss": -0.24481098353862762, "Value Loss": 0.006572025828063488, "_runtime": 15888.021986246109, "_timestamp": 1585585803.8666196, "_step": 157}
{"Episode reward": 29.464756913662043, "Episode length": 722, "Policy Loss": 0.2646794617176056, "Value Loss": 13.812697410583496, "_runtime": 15889.48968243599, "_timestamp": 1585585805.3343158, "_step": 158}
{"Episode reward": 10.011308640698545, "Episode length": 928, "Policy Loss": 0.13222695887088776, "Value Loss": 10.754690170288086, "_runtime": 15890.664464712143, "_timestamp": 1585585806.509098, "_step": 159}
{"Episode reward": 27.43146719860981, "Episode length": 742, "Policy Loss": 0.2521972358226776, "Value Loss": 13.441798210144043, "_runtime": 15892.209825754166, "_timestamp": 1585585808.054459, "_step": 160}
{"Episode reward": -97.6276015991999, "Episode length": 999, "Policy Loss": -0.24105702340602875, "Value Loss": 0.007887596264481544, "_runtime": 15893.775560379028, "_timestamp": 1585585809.6201937, "_step": 161}
{"Episode reward": -97.2566136668838, "Episode length": 999, "Policy Loss": -0.23731766641139984, "Value Loss": 0.004785364959388971, "_runtime": 15895.32902932167, "_timestamp": 1585585811.1736627, "_step": 162}
{"Episode reward": -96.0647889039279, "Episode length": 999, "Policy Loss": -0.22962848842144012, "Value Loss": 0.009636170230805874, "_runtime": 15896.904811620712, "_timestamp": 1585585812.749445, "_step": 163}
{"Episode reward": -96.54977987957817, "Episode length": 999, "Policy Loss": -0.2336757332086563, "Value Loss": 0.011182078160345554, "_runtime": 15898.48366522789, "_timestamp": 1585585814.3282986, "_step": 164}
{"Episode reward": -97.2972052260909, "Episode length": 999, "Policy Loss": -0.2352525293827057, "Value Loss": 0.0049809664487838745, "_runtime": 15899.610722541809, "_timestamp": 1585585815.455356, "_step": 165}
{"Episode reward": 31.150696913813576, "Episode length": 708, "Policy Loss": 0.24908044934272766, "Value Loss": 14.079855918884277, "_runtime": 15901.185307979584, "_timestamp": 1585585817.0299413, "_step": 166}
{"Episode reward": -96.98314755714999, "Episode length": 999, "Policy Loss": -0.22827737033367157, "Value Loss": 0.010606938973069191, "_runtime": 15902.007265329361, "_timestamp": 1585585817.8518987, "_step": 167}
{"Episode reward": 49.59654908434533, "Episode length": 515, "Policy Loss": 0.5158526301383972, "Value Loss": 19.310583114624023, "_runtime": 15902.512772321701, "_timestamp": 1585585818.3574057, "_step": 168}
{"Episode reward": 69.81892820787691, "Episode length": 307, "Policy Loss": 0.8670729994773865, "Value Loss": 32.355308532714844, "_runtime": 15903.919650316238, "_timestamp": 1585585819.7642837, "_step": 169}
{"Episode reward": 12.734888785661099, "Episode length": 898, "Policy Loss": 0.20541737973690033, "Value Loss": 11.047403335571289, "_runtime": 15904.848167419434, "_timestamp": 1585585820.6928008, "_step": 170}
{"Episode reward": 41.618970866963274, "Episode length": 603, "Policy Loss": 0.3507179915904999, "Value Loss": 16.474849700927734, "_runtime": 15906.34217953682, "_timestamp": 1585585822.1868129, "_step": 171}
{"Episode reward": 3.505956193417731, "Episode length": 993, "Policy Loss": 0.1491573452949524, "Value Loss": 10.004252433776855, "_runtime": 15907.93532037735, "_timestamp": 1585585823.7799537, "_step": 172}
{"Episode reward": -97.38134788081047, "Episode length": 999, "Policy Loss": -0.21787159144878387, "Value Loss": 0.04968585446476936, "_runtime": 15909.266711711884, "_timestamp": 1585585825.111345, "_step": 173}
{"Episode reward": 16.58725599419776, "Episode length": 869, "Policy Loss": 0.2153465896844864, "Value Loss": 11.4334135055542, "_runtime": 15909.94986629486, "_timestamp": 1585585825.7944996, "_step": 174}
{"Episode reward": 58.74552787446434, "Episode length": 426, "Policy Loss": 0.5463610887527466, "Value Loss": 23.173046112060547, "_runtime": 15911.34017944336, "_timestamp": 1585585827.1848128, "_step": 175}
{"Episode reward": 14.026773387851918, "Episode length": 889, "Policy Loss": 0.1458573341369629, "Value Loss": 11.128939628601074, "_runtime": 15912.572824716568, "_timestamp": 1585585828.417458, "_step": 176}
{"Episode reward": 24.19872972841779, "Episode length": 787, "Policy Loss": 0.20419281721115112, "Value Loss": 12.4920072555542, "_runtime": 15914.084051132202, "_timestamp": 1585585829.9286845, "_step": 177}
{"Episode reward": -95.80364643197142, "Episode length": 999, "Policy Loss": -0.24017056822776794, "Value Loss": 0.12987221777439117, "_runtime": 15915.646026849747, "_timestamp": 1585585831.4906602, "_step": 178}
{"Episode reward": -97.40884855014494, "Episode length": 999, "Policy Loss": -0.22596001625061035, "Value Loss": 0.08286144584417343, "_runtime": 15917.196089029312, "_timestamp": 1585585833.0407224, "_step": 179}
{"Episode reward": -96.89313099495502, "Episode length": 999, "Policy Loss": -0.23702538013458252, "Value Loss": 0.05406532809138298, "_runtime": 15918.739040613174, "_timestamp": 1585585834.583674, "_step": 180}
{"Episode reward": -96.78618843388838, "Episode length": 999, "Policy Loss": -0.23674508929252625, "Value Loss": 0.07027418166399002, "_runtime": 15920.32903623581, "_timestamp": 1585585836.1736696, "_step": 181}
{"Episode reward": -96.58392695823994, "Episode length": 999, "Policy Loss": -0.22846734523773193, "Value Loss": 0.14940205216407776, "_runtime": 15921.910059452057, "_timestamp": 1585585837.7546928, "_step": 182}
{"Episode reward": -96.26384772701269, "Episode length": 999, "Policy Loss": -0.23984648287296295, "Value Loss": 0.12113218754529953, "_runtime": 15923.469364881516, "_timestamp": 1585585839.3139982, "_step": 183}
{"Episode reward": -96.17151098856279, "Episode length": 999, "Policy Loss": -0.2511611580848694, "Value Loss": 0.10940577834844589, "_runtime": 15924.901270866394, "_timestamp": 1585585840.7459042, "_step": 184}
{"Episode reward": 12.951169023094565, "Episode length": 904, "Policy Loss": 0.23674415051937103, "Value Loss": 11.048623085021973, "_runtime": 15926.472870826721, "_timestamp": 1585585842.3175042, "_step": 185}
{"Episode reward": -97.7159454561051, "Episode length": 999, "Policy Loss": -0.26123929023742676, "Value Loss": 0.023934118449687958, "_runtime": 15927.929799079895, "_timestamp": 1585585843.7744324, "_step": 186}
{"Episode reward": 10.82682546130276, "Episode length": 923, "Policy Loss": 0.0837637186050415, "Value Loss": 10.759830474853516, "_runtime": 15928.710597991943, "_timestamp": 1585585844.5552313, "_step": 187}
{"Episode reward": 54.32733075236785, "Episode length": 483, "Policy Loss": 0.6027017831802368, "Value Loss": 20.56564712524414, "_runtime": 15929.230510234833, "_timestamp": 1585585845.0751436, "_step": 188}
{"Episode reward": 70.19324471527611, "Episode length": 308, "Policy Loss": 0.9586598873138428, "Value Loss": 32.29302215576172, "_runtime": 15930.791796922684, "_timestamp": 1585585846.6364303, "_step": 189}
{"Episode reward": -96.68353478012686, "Episode length": 999, "Policy Loss": -0.27297672629356384, "Value Loss": 0.009258297272026539, "_runtime": 15931.391800642014, "_timestamp": 1585585847.236434, "_step": 190}
{"Episode reward": 63.19052213976814, "Episode length": 385, "Policy Loss": 0.5611507892608643, "Value Loss": 25.82634925842285, "_runtime": 15932.88976240158, "_timestamp": 1585585848.7343957, "_step": 191}
{"Episode reward": -96.60281467345695, "Episode length": 999, "Policy Loss": -0.2747860848903656, "Value Loss": 0.008247505873441696, "_runtime": 15933.625720500946, "_timestamp": 1585585849.4703538, "_step": 192}
{"Episode reward": 56.17298324401511, "Episode length": 450, "Policy Loss": 0.4157225787639618, "Value Loss": 22.086946487426758, "_runtime": 15935.203196525574, "_timestamp": 1585585851.0478299, "_step": 193}
{"Episode reward": -96.39483706111263, "Episode length": 999, "Policy Loss": -0.2741182744503021, "Value Loss": 0.020570313557982445, "_runtime": 15936.247256040573, "_timestamp": 1585585852.0918894, "_step": 194}
{"Episode reward": 36.66771128685942, "Episode length": 664, "Policy Loss": 0.3061290979385376, "Value Loss": 14.943194389343262, "_runtime": 15937.762964487076, "_timestamp": 1585585853.6075978, "_step": 195}
{"Episode reward": -95.86281026172847, "Episode length": 999, "Policy Loss": -0.27546241879463196, "Value Loss": 0.025982694700360298, "_runtime": 15939.32982134819, "_timestamp": 1585585855.1744547, "_step": 196}
{"Episode reward": -96.37137962980425, "Episode length": 999, "Policy Loss": -0.27586764097213745, "Value Loss": 0.012460337020456791, "_runtime": 15940.867114067078, "_timestamp": 1585585856.7117474, "_step": 197}
{"Episode reward": -95.63389136477001, "Episode length": 999, "Policy Loss": -0.2732485830783844, "Value Loss": 0.021939177066087723, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305, 11.794904708862305]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-10.694554328918457, -10.02811336517334, -9.361671447753906, -8.695230484008789, -8.028789520263672, -7.362348556518555, -6.695907115936279, -6.029465675354004, -5.363024711608887, -4.6965837478637695, -4.030142307281494, -3.3637008666992188, -2.6972599029541016, -2.0308189392089844, -1.3643770217895508, -0.6979360580444336, -0.031495094299316406, 0.6349458694458008, 1.301386833190918, 1.9678287506103516, 2.6342697143554688, 3.300710678100586, 3.9671525955200195, 4.633593559265137, 5.300034523010254, 5.966475486755371, 6.632916450500488, 7.2993574142456055, 7.9658002853393555, 8.632241249084473, 9.29868221282959, 9.965123176574707, 10.631564140319824, 11.298005104064941, 11.964446067810059, 12.630887031555176, 13.297327995300293, 13.963770866394043, 14.63021183013916, 15.296652793884277, 15.963093757629395, 16.629535675048828, 17.295974731445312, 17.962417602539062, 18.628860473632812, 19.295299530029297, 19.961742401123047, 20.62818145751953, 21.29462432861328, 21.96106719970703, 22.627506256103516, 23.293949127197266, 23.96038818359375, 24.6268310546875, 25.293270111083984, 25.959712982177734, 26.626155853271484, 27.29259490966797, 27.95903778076172, 28.625476837158203, 29.291919708251953, 29.958358764648438, 30.624801635742188, 31.291240692138672, 31.957683563232422]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9928707480430603, -0.8694859743118286, -0.7461011409759521, -0.6227163672447205, -0.4993315637111664, -0.3759467601776123, -0.2525619864463806, -0.12917715311050415, -0.005792379379272461, 0.11759239435195923, 0.2409772276878357, 0.36436206102371216, 0.4877467751502991, 0.6111316084861755, 0.734516441822052, 0.8579011559486389, 0.9812859892845154, 1.104670763015747, 1.228055477142334, 1.3514404296875, 1.474825143814087, 1.5982098579406738, 1.7215948104858398, 1.8449795246124268, 1.9683642387390137, 2.0917491912841797, 2.2151339054107666, 2.3385186195373535, 2.4619035720825195, 2.5852882862091064, 2.7086730003356934, 2.8320579528808594, 2.9554426670074463, 3.078827381134033, 3.202212333679199, 3.3255972862243652, 3.448981761932373, 3.572366714477539, 3.695751667022705, 3.819136142730713, 3.942521095275879, 4.065906047821045, 4.189290523529053, 4.312675476074219, 4.436060428619385, 4.559444904327393, 4.682829856872559, 4.806214809417725, 4.929599285125732, 5.052984237670898, 5.1763691902160645, 5.299753665924072, 5.423138618469238, 5.546523571014404, 5.669908046722412, 5.793292999267578, 5.916677951812744, 6.040062427520752, 6.163447380065918, 6.286832332611084, 6.410216808319092, 6.533601760864258, 6.656986713409424, 6.780371189117432, 6.903756141662598]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 4.0, 3.0, 6.0, 8.0, 5.0, 8.0, 5.0, 8.0, 1.0, 8.0, 6.0, 7.0, 6.0, 6.0, 9.0, 10.0, 29.0, 51.0, 46.0, 40.0, 16.0, 64.0, 37.0, 7.0, 5.0, 9.0, 3.0, 7.0, 10.0, 7.0, 7.0, 8.0, 5.0, 6.0, 3.0, 5.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.85233211517334, -3.702363967895508, -3.552395820617676, -3.4024276733398438, -3.2524595260620117, -3.1024913787841797, -2.9525229930877686, -2.8025548458099365, -2.6525866985321045, -2.5026185512542725, -2.3526504039764404, -2.2026820182800293, -2.0527138710021973, -1.9027458429336548, -1.7527775764465332, -1.6028094291687012, -1.4528412818908691, -1.302873134613037, -1.152904987335205, -1.002936840057373, -0.852968692779541, -0.7030003070831299, -0.5530321598052979, -0.4030640125274658, -0.2530958652496338, -0.10312771797180176, 0.04684042930603027, 0.1968088150024414, 0.34677696228027344, 0.49674510955810547, 0.6467132568359375, 0.7966814041137695, 0.9466495513916016, 1.0966176986694336, 1.2465858459472656, 1.3965539932250977, 1.5465221405029297, 1.6964902877807617, 1.8464584350585938, 1.9964265823364258, 2.146394729614258, 2.296363353729248, 2.44633150100708, 2.596299648284912, 2.746267795562744, 2.896235942840576, 3.046204090118408, 3.1961722373962402, 3.3461403846740723, 3.4961085319519043, 3.6460766792297363, 3.7960448265075684, 3.9460129737854004, 4.095981121063232, 4.245949745178223, 4.395917892456055, 4.545886039733887, 4.695854187011719, 4.845822334289551, 4.995790481567383, 5.145758628845215, 5.295726776123047, 5.445694923400879, 5.595663070678711, 5.745631217956543]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-4.8772430419921875, -4.668468475341797, -4.459693908691406, -4.250919342041016, -4.042144775390625, -3.8333702087402344, -3.624595880508423, -3.4158213138580322, -3.2070467472076416, -2.998272180557251, -2.7894976139068604, -2.5807230472564697, -2.371948719024658, -2.1631741523742676, -1.954399585723877, -1.7456250190734863, -1.5368504524230957, -1.328075885772705, -1.1193013191223145, -0.9105267524719238, -0.7017521858215332, -0.4929776191711426, -0.28420305252075195, -0.07542848587036133, 0.1333456039428711, 0.3421201705932617, 0.5508947372436523, 0.759669303894043, 0.9684438705444336, 1.1772184371948242, 1.3859930038452148, 1.5947675704956055, 1.803542137145996, 2.0123167037963867, 2.2210912704467773, 2.429865837097168, 2.6386404037475586, 2.847414970397949, 3.05618953704834, 3.2649641036987305, 3.473738670349121, 3.6825132369995117, 3.8912878036499023, 4.100062370300293, 4.308836936950684, 4.517611503601074, 4.726386070251465, 4.9351606369018555, 5.14393424987793, 5.35270881652832, 5.561483383178711, 5.770257949829102, 5.979032516479492, 6.187807083129883, 6.396581649780273, 6.605356216430664, 6.814130783081055, 7.022905349731445, 7.231679916381836, 7.440454483032227, 7.649229049682617, 7.858003616333008, 8.066778182983398, 8.275552749633789, 8.48432731628418]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 16.0, 12.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0], "bins": [-4.103715896606445, -4.0034942626953125, -3.9032726287841797, -3.803050994873047, -3.702829360961914, -3.6026077270507812, -3.5023860931396484, -3.4021644592285156, -3.301942825317383, -3.20172119140625, -3.101499557495117, -3.0012779235839844, -2.9010562896728516, -2.8008346557617188, -2.700613021850586, -2.600391387939453, -2.5001697540283203, -2.3999481201171875, -2.2997264862060547, -2.199504852294922, -2.099283218383789, -1.9990615844726562, -1.8988399505615234, -1.7986183166503906, -1.6983966827392578, -1.598175048828125, -1.4979534149169922, -1.3977317810058594, -1.2975101470947266, -1.1972885131835938, -1.097066879272461, -0.9968452453613281, -0.8966236114501953, -0.7964019775390625, -0.6961803436279297, -0.5959587097167969, -0.49573707580566406, -0.39551544189453125, -0.29529380798339844, -0.19507217407226562, -0.09485054016113281, 0.00537109375, 0.10559272766113281, 0.20581436157226562, 0.30603599548339844, 0.40625762939453125, 0.5064792633056641, 0.6067008972167969, 0.7069225311279297, 0.8071441650390625, 0.9073657989501953, 1.0075874328613281, 1.107809066772461, 1.2080307006835938, 1.3082523345947266, 1.4084739685058594, 1.5086956024169922, 1.608917236328125, 1.7091388702392578, 1.8093605041503906, 1.9095821380615234, 2.0098037719726562, 2.110025405883789, 2.210247039794922, 2.3104686737060547]}, "_runtime": 15941.928142547607, "_timestamp": 1585585857.772776, "_step": 198}
{"Episode reward": 34.81576972412661, "Episode length": 674, "Policy Loss": 0.24939435720443726, "Value Loss": 14.681707382202148, "_runtime": 15942.915318727493, "_timestamp": 1585585858.759952, "_step": 199}
{"Episode reward": 40.620253874681175, "Episode length": 617, "Policy Loss": 0.2101844996213913, "Value Loss": 16.03795051574707, "_runtime": 15944.150084018707, "_timestamp": 1585585859.9947174, "_step": 200}
{"Episode reward": 24.697807988577367, "Episode length": 785, "Policy Loss": 0.1292598694562912, "Value Loss": 12.598857879638672, "_runtime": 15945.69429397583, "_timestamp": 1585585861.5389273, "_step": 201}
{"Episode reward": -94.68579982681933, "Episode length": 999, "Policy Loss": -0.26439163088798523, "Value Loss": 0.05235515534877777, "_runtime": 15946.520697593689, "_timestamp": 1585585862.365331, "_step": 202}
{"Episode reward": 50.10045931716554, "Episode length": 523, "Policy Loss": 0.3212723135948181, "Value Loss": 18.841856002807617, "_runtime": 15947.069680213928, "_timestamp": 1585585862.9143136, "_step": 203}
{"Episode reward": 67.87701796348176, "Episode length": 334, "Policy Loss": 0.837298572063446, "Value Loss": 29.533832550048828, "_runtime": 15948.267430305481, "_timestamp": 1585585864.1120636, "_step": 204}
{"Episode reward": 26.28785757661211, "Episode length": 771, "Policy Loss": 0.12793000042438507, "Value Loss": 12.777641296386719, "_runtime": 15948.904013872147, "_timestamp": 1585585864.7486472, "_step": 205}
{"Episode reward": 61.59602378951904, "Episode length": 405, "Policy Loss": 0.47485166788101196, "Value Loss": 24.345870971679688, "_runtime": 15950.413787603378, "_timestamp": 1585585866.258421, "_step": 206}
{"Episode reward": -95.65639256468445, "Episode length": 999, "Policy Loss": -0.26602065563201904, "Value Loss": 0.026180481538176537, "_runtime": 15951.929641723633, "_timestamp": 1585585867.774275, "_step": 207}
{"Episode reward": 7.353309765067081, "Episode length": 976, "Policy Loss": 0.03673141077160835, "Value Loss": 10.201778411865234, "_runtime": 15953.44240283966, "_timestamp": 1585585869.2870362, "_step": 208}
{"Episode reward": -95.80951544811143, "Episode length": 999, "Policy Loss": -0.2840447425842285, "Value Loss": 0.14148497581481934, "_runtime": 15955.010626077652, "_timestamp": 1585585870.8552594, "_step": 209}
{"Episode reward": -95.63469594848559, "Episode length": 999, "Policy Loss": -0.26583972573280334, "Value Loss": 0.10443897545337677, "_runtime": 15955.42210149765, "_timestamp": 1585585871.2667348, "_step": 210}
{"Episode reward": 78.14729123575847, "Episode length": 228, "Policy Loss": 0.9940674901008606, "Value Loss": 42.88019943237305, "_runtime": 15956.986011505127, "_timestamp": 1585585872.8306448, "_step": 211}
{"Episode reward": -94.55505895107274, "Episode length": 999, "Policy Loss": -0.28222548961639404, "Value Loss": 0.014769485220313072, "_runtime": 15958.599530935287, "_timestamp": 1585585874.4441643, "_step": 212}
{"Episode reward": -94.69026008996228, "Episode length": 999, "Policy Loss": -0.2822323143482208, "Value Loss": 0.04207048565149307, "_runtime": 15960.098058700562, "_timestamp": 1585585875.942692, "_step": 213}
{"Episode reward": -94.74470182279337, "Episode length": 999, "Policy Loss": -0.29525026679039, "Value Loss": 0.044735152274370193, "_runtime": 15961.681926727295, "_timestamp": 1585585877.52656, "_step": 214}
{"Episode reward": -94.71957857623886, "Episode length": 999, "Policy Loss": -0.28734469413757324, "Value Loss": 0.06262952089309692, "_runtime": 15963.248982191086, "_timestamp": 1585585879.0936155, "_step": 215}
{"Episode reward": -95.17429415562216, "Episode length": 999, "Policy Loss": -0.28810492157936096, "Value Loss": 0.10801944881677628, "_runtime": 15964.797889232635, "_timestamp": 1585585880.6425226, "_step": 216}
{"Episode reward": -94.36048799413174, "Episode length": 999, "Policy Loss": -0.2974042296409607, "Value Loss": 0.08249455690383911, "_runtime": 15965.826171159744, "_timestamp": 1585585881.6708045, "_step": 217}
{"Episode reward": 39.31978635289148, "Episode length": 641, "Policy Loss": 0.2211804986000061, "Value Loss": 15.33984661102295, "_runtime": 15966.233511686325, "_timestamp": 1585585882.078145, "_step": 218}
{"Episode reward": 78.65540799461755, "Episode length": 223, "Policy Loss": 0.9794299006462097, "Value Loss": 44.0303955078125, "_runtime": 15967.22906947136, "_timestamp": 1585585883.0737028, "_step": 219}
{"Episode reward": 39.90036925682491, "Episode length": 639, "Policy Loss": 0.16509820520877838, "Value Loss": 15.433517456054688, "_runtime": 15968.785536050797, "_timestamp": 1585585884.6301694, "_step": 220}
{"Episode reward": -94.07408337030327, "Episode length": 999, "Policy Loss": -0.2980203330516815, "Value Loss": 0.044555578380823135, "_runtime": 15970.286395549774, "_timestamp": 1585585886.131029, "_step": 221}
{"Episode reward": -94.14558833870885, "Episode length": 999, "Policy Loss": -0.2697892487049103, "Value Loss": 0.23130826652050018, "_runtime": 15971.826386451721, "_timestamp": 1585585887.6710198, "_step": 222}
{"Episode reward": -94.60432850814614, "Episode length": 999, "Policy Loss": -0.304301917552948, "Value Loss": 0.0449233204126358, "_runtime": 15972.953588724136, "_timestamp": 1585585888.798222, "_step": 223}
{"Episode reward": 33.006126407656, "Episode length": 707, "Policy Loss": 0.1074288859963417, "Value Loss": 13.878120422363281, "_runtime": 15974.498992919922, "_timestamp": 1585585890.3436263, "_step": 224}
{"Episode reward": -94.03442974582238, "Episode length": 999, "Policy Loss": -0.27414166927337646, "Value Loss": 0.18527144193649292, "_runtime": 15976.077930927277, "_timestamp": 1585585891.9225643, "_step": 225}
{"Episode reward": -93.58606976445803, "Episode length": 999, "Policy Loss": -0.29500722885131836, "Value Loss": 0.015163690783083439, "_runtime": 15977.277561664581, "_timestamp": 1585585893.122195, "_step": 226}
{"Episode reward": 28.901475352098487, "Episode length": 767, "Policy Loss": 0.07592087239027023, "Value Loss": 12.827653884887695, "_runtime": 15978.760436534882, "_timestamp": 1585585894.6050699, "_step": 227}
{"Episode reward": 11.48283079449213, "Episode length": 951, "Policy Loss": 0.025396494194865227, "Value Loss": 10.418322563171387, "_runtime": 15980.338642597198, "_timestamp": 1585585896.183276, "_step": 228}
{"Episode reward": -93.48748505515151, "Episode length": 999, "Policy Loss": -0.2883644104003906, "Value Loss": 0.015471193939447403, "_runtime": 15981.938214302063, "_timestamp": 1585585897.7828476, "_step": 229}
{"Episode reward": -93.9676774152969, "Episode length": 999, "Policy Loss": -0.28093597292900085, "Value Loss": 0.03099771775305271, "_runtime": 15983.496070623398, "_timestamp": 1585585899.340704, "_step": 230}
{"Episode reward": -93.67628648660609, "Episode length": 999, "Policy Loss": -0.2658773362636566, "Value Loss": 0.0617489330470562, "_runtime": 15984.15500497818, "_timestamp": 1585585899.9996383, "_step": 231}
{"Episode reward": 61.955416514533816, "Episode length": 399, "Policy Loss": 0.3344198763370514, "Value Loss": 24.701231002807617, "_runtime": 15985.738471031189, "_timestamp": 1585585901.5831044, "_step": 232}
{"Episode reward": -93.47817591343885, "Episode length": 999, "Policy Loss": -0.26900434494018555, "Value Loss": 0.03088480606675148, "_runtime": 15987.31632733345, "_timestamp": 1585585903.1609607, "_step": 233}
{"Episode reward": -93.39970675899907, "Episode length": 999, "Policy Loss": -0.2744658887386322, "Value Loss": 0.013768944889307022, "_runtime": 15988.834410905838, "_timestamp": 1585585904.6790442, "_step": 234}
{"Episode reward": -93.33585074587673, "Episode length": 999, "Policy Loss": -0.26638397574424744, "Value Loss": 0.014015477150678635, "_runtime": 15990.421723127365, "_timestamp": 1585585906.2663565, "_step": 235}
{"Episode reward": -92.87150938107374, "Episode length": 999, "Policy Loss": -0.2603791356086731, "Value Loss": 0.01212493795901537, "_runtime": 15991.998616695404, "_timestamp": 1585585907.84325, "_step": 236}
{"Episode reward": -92.8080882256792, "Episode length": 999, "Policy Loss": -0.25761327147483826, "Value Loss": 0.010698508471250534, "_runtime": 15993.555834293365, "_timestamp": 1585585909.4004676, "_step": 237}
{"Episode reward": -92.75165063927835, "Episode length": 999, "Policy Loss": -0.2530413269996643, "Value Loss": 0.010480279102921486, "_runtime": 15994.526609659195, "_timestamp": 1585585910.371243, "_step": 238}
{"Episode reward": 43.95307727087154, "Episode length": 601, "Policy Loss": 0.1940155327320099, "Value Loss": 16.462018966674805, "_runtime": 15995.432018995285, "_timestamp": 1585585911.2766523, "_step": 239}
{"Episode reward": 47.100176373595744, "Episode length": 563, "Policy Loss": 0.21568216383457184, "Value Loss": 17.552627563476562, "_runtime": 15997.000284671783, "_timestamp": 1585585912.844918, "_step": 240}
{"Episode reward": -93.15540233307064, "Episode length": 999, "Policy Loss": -0.2407311350107193, "Value Loss": 0.008298804052174091, "_runtime": 15998.158824205399, "_timestamp": 1585585914.0034575, "_step": 241}
{"Episode reward": 31.09346221306464, "Episode length": 744, "Policy Loss": 0.09734218567609787, "Value Loss": 13.247496604919434, "_runtime": 15999.044767141342, "_timestamp": 1585585914.8894005, "_step": 242}
{"Episode reward": 48.26249413842304, "Episode length": 570, "Policy Loss": 0.23194949328899384, "Value Loss": 17.26130485534668, "_runtime": 16000.61568236351, "_timestamp": 1585585916.4603157, "_step": 243}
{"Episode reward": -91.66832819054056, "Episode length": 999, "Policy Loss": -0.2180875837802887, "Value Loss": 0.027202805504202843, "_runtime": 16001.867918014526, "_timestamp": 1585585917.7125514, "_step": 244}
{"Episode reward": 25.84453009715098, "Episode length": 799, "Policy Loss": 0.09905500710010529, "Value Loss": 12.29638385772705, "_runtime": 16003.397971391678, "_timestamp": 1585585919.2426047, "_step": 245}
{"Episode reward": -90.8632958558473, "Episode length": 999, "Policy Loss": -0.1968192756175995, "Value Loss": 0.06853652000427246, "_runtime": 16004.962902069092, "_timestamp": 1585585920.8075354, "_step": 246}
{"Episode reward": -90.33069225338339, "Episode length": 999, "Policy Loss": -0.1976514458656311, "Value Loss": 0.0551307313144207, "_runtime": 16006.147896528244, "_timestamp": 1585585921.9925299, "_step": 247}
{"Episode reward": 33.298399371510826, "Episode length": 726, "Policy Loss": 0.2510891854763031, "Value Loss": 13.582198143005371, "_runtime": 16007.71789097786, "_timestamp": 1585585923.5625243, "_step": 248}
{"Episode reward": -90.43687600008273, "Episode length": 999, "Policy Loss": -0.18678171932697296, "Value Loss": 0.07661662995815277, "_runtime": 16008.819088935852, "_timestamp": 1585585924.6637223, "_step": 249}
{"Episode reward": 38.008785422883044, "Episode length": 691, "Policy Loss": 0.14963111281394958, "Value Loss": 14.220465660095215, "_runtime": 16010.38708114624, "_timestamp": 1585585926.2317145, "_step": 250}
{"Episode reward": -90.0846324762005, "Episode length": 999, "Policy Loss": -0.16859082877635956, "Value Loss": 0.11835461854934692, "_runtime": 16011.964696407318, "_timestamp": 1585585927.8093297, "_step": 251}
{"Episode reward": -89.30988848343303, "Episode length": 999, "Policy Loss": -0.19346603751182556, "Value Loss": 0.05302298069000244, "_runtime": 16013.511134147644, "_timestamp": 1585585929.3557675, "_step": 252}
{"Episode reward": -90.17083857132097, "Episode length": 999, "Policy Loss": -0.1866893619298935, "Value Loss": 0.023129776120185852, "_runtime": 16015.077129364014, "_timestamp": 1585585930.9217627, "_step": 253}
{"Episode reward": -90.89212430466647, "Episode length": 999, "Policy Loss": -0.19437763094902039, "Value Loss": 0.008708898909389973, "_runtime": 16016.650388717651, "_timestamp": 1585585932.495022, "_step": 254}
{"Episode reward": -88.99325646555299, "Episode length": 999, "Policy Loss": -0.19150452315807343, "Value Loss": 0.012255032546818256, "_runtime": 16017.625734329224, "_timestamp": 1585585933.4703677, "_step": 255}
{"Episode reward": 45.06453257538531, "Episode length": 610, "Policy Loss": 0.2642377018928528, "Value Loss": 16.321001052856445, "_runtime": 16018.893247127533, "_timestamp": 1585585934.7378805, "_step": 256}
{"Episode reward": 29.070793107821842, "Episode length": 799, "Policy Loss": 0.11975107342004776, "Value Loss": 12.453972816467285, "_runtime": 16020.471942901611, "_timestamp": 1585585936.3165762, "_step": 257}
{"Episode reward": -88.42734900664998, "Episode length": 999, "Policy Loss": -0.18898214399814606, "Value Loss": 0.026484036818146706, "_runtime": 16021.634224891663, "_timestamp": 1585585937.4788582, "_step": 258}
{"Episode reward": 33.35140790401492, "Episode length": 747, "Policy Loss": 0.10214213281869888, "Value Loss": 13.296342849731445, "_runtime": 16023.197134494781, "_timestamp": 1585585939.0417678, "_step": 259}
{"Episode reward": -89.3486124302063, "Episode length": 999, "Policy Loss": -0.17678937315940857, "Value Loss": 0.010788127779960632, "_runtime": 16024.775562047958, "_timestamp": 1585585940.6201954, "_step": 260}
{"Episode reward": -88.996886062664, "Episode length": 999, "Policy Loss": -0.18090952932834625, "Value Loss": 0.018774809315800667, "_runtime": 16025.637430906296, "_timestamp": 1585585941.4820642, "_step": 261}
{"Episode reward": 51.694256731063206, "Episode length": 541, "Policy Loss": 0.5842987895011902, "Value Loss": 18.243743896484375, "_runtime": 16027.213825464249, "_timestamp": 1585585943.0584588, "_step": 262}
{"Episode reward": -89.42006542154067, "Episode length": 999, "Policy Loss": -0.1707776039838791, "Value Loss": 0.009612824767827988, "_runtime": 16028.259291410446, "_timestamp": 1585585944.1039248, "_step": 263}
{"Episode reward": 41.249119194010035, "Episode length": 652, "Policy Loss": 0.218514546751976, "Value Loss": 15.096095085144043, "_runtime": 16029.840270996094, "_timestamp": 1585585945.6849043, "_step": 264}
{"Episode reward": -88.20043849485455, "Episode length": 999, "Policy Loss": -0.16609078645706177, "Value Loss": 0.00944786611944437, "_runtime": 16030.69905591011, "_timestamp": 1585585946.5436893, "_step": 265}
{"Episode reward": 52.60228535536903, "Episode length": 528, "Policy Loss": 0.2599085867404938, "Value Loss": 18.480527877807617, "_runtime": 16032.26611995697, "_timestamp": 1585585948.1107533, "_step": 266}
{"Episode reward": -88.63572313766443, "Episode length": 999, "Policy Loss": -0.16203078627586365, "Value Loss": 0.10002781450748444, "_runtime": 16033.297401189804, "_timestamp": 1585585949.1420345, "_step": 267}
{"Episode reward": 41.429243349010214, "Episode length": 645, "Policy Loss": 0.33772754669189453, "Value Loss": 15.151700019836426, "_runtime": 16034.848345518112, "_timestamp": 1585585950.6929789, "_step": 268}
{"Episode reward": -90.79937302726701, "Episode length": 999, "Policy Loss": -0.14311645925045013, "Value Loss": 0.1440380960702896, "_runtime": 16036.433158874512, "_timestamp": 1585585952.2777922, "_step": 269}
{"Episode reward": -90.03810298168682, "Episode length": 999, "Policy Loss": -0.17823202908039093, "Value Loss": 0.005383469630032778, "_runtime": 16037.982193470001, "_timestamp": 1585585953.8268268, "_step": 270}
{"Episode reward": -91.60938725082686, "Episode length": 999, "Policy Loss": -0.18685998022556305, "Value Loss": 0.005341523792594671, "_runtime": 16039.569580078125, "_timestamp": 1585585955.4142134, "_step": 271}
{"Episode reward": -92.36679620758079, "Episode length": 999, "Policy Loss": -0.18748719990253448, "Value Loss": 0.0192615557461977, "_runtime": 16041.165145635605, "_timestamp": 1585585957.009779, "_step": 272}
{"Episode reward": -92.27260680195043, "Episode length": 999, "Policy Loss": -0.18842165172100067, "Value Loss": 0.0052084545604884624, "_runtime": 16042.622037649155, "_timestamp": 1585585958.466671, "_step": 273}
{"Episode reward": 14.863772176710938, "Episode length": 917, "Policy Loss": 0.22927597165107727, "Value Loss": 10.808646202087402, "_runtime": 16044.155520915985, "_timestamp": 1585585960.0001543, "_step": 274}
{"Episode reward": 11.041978710678123, "Episode length": 971, "Policy Loss": 0.05291413143277168, "Value Loss": 10.200186729431152, "_runtime": 16045.75307059288, "_timestamp": 1585585961.597704, "_step": 275}
{"Episode reward": -92.86174459870888, "Episode length": 999, "Policy Loss": -0.1927587240934372, "Value Loss": 0.004995823837816715, "_runtime": 16046.245489358902, "_timestamp": 1585585962.0901227, "_step": 276}
{"Episode reward": 73.59779600431042, "Episode length": 285, "Policy Loss": 0.6686940789222717, "Value Loss": 34.435218811035156, "_runtime": 16047.330209493637, "_timestamp": 1585585963.1748428, "_step": 277}
{"Episode reward": 35.98386161178524, "Episode length": 684, "Policy Loss": 0.1742517054080963, "Value Loss": 14.085099220275879, "_runtime": 16048.925200462341, "_timestamp": 1585585964.7698338, "_step": 278}
{"Episode reward": -93.12434791592597, "Episode length": 999, "Policy Loss": -0.19549882411956787, "Value Loss": 0.033607903867959976, "_runtime": 16050.093561887741, "_timestamp": 1585585965.9381952, "_step": 279}
{"Episode reward": 27.320434343136412, "Episode length": 770, "Policy Loss": 0.1525765359401703, "Value Loss": 12.858267784118652, "_runtime": 16050.699501514435, "_timestamp": 1585585966.5441349, "_step": 280}
{"Episode reward": 65.47009811569302, "Episode length": 373, "Policy Loss": 0.588671863079071, "Value Loss": 26.667638778686523, "_runtime": 16052.28441119194, "_timestamp": 1585585968.1290445, "_step": 281}
{"Episode reward": -91.89947172087254, "Episode length": 999, "Policy Loss": -0.2039748728275299, "Value Loss": 0.00529180932790041, "_runtime": 16053.883037805557, "_timestamp": 1585585969.7276711, "_step": 282}
{"Episode reward": -93.46726905435357, "Episode length": 999, "Policy Loss": -0.20955277979373932, "Value Loss": 0.00583546981215477, "_runtime": 16055.299088716507, "_timestamp": 1585585971.143722, "_step": 283}
{"Episode reward": 13.593502204558149, "Episode length": 928, "Policy Loss": 0.05118655413389206, "Value Loss": 10.713604927062988, "_runtime": 16056.906242370605, "_timestamp": 1585585972.7508757, "_step": 284}
{"Episode reward": -91.78213493900687, "Episode length": 999, "Policy Loss": -0.20953702926635742, "Value Loss": 0.005461909342557192, "_runtime": 16057.961831331253, "_timestamp": 1585585973.8064647, "_step": 285}
{"Episode reward": 38.0828817230381, "Episode length": 661, "Policy Loss": 0.29412952065467834, "Value Loss": 15.110567092895508, "_runtime": 16059.532999753952, "_timestamp": 1585585975.377633, "_step": 286}
{"Episode reward": -92.47329106527684, "Episode length": 999, "Policy Loss": -0.20726360380649567, "Value Loss": 0.005567679647356272, "_runtime": 16061.137364149094, "_timestamp": 1585585976.9819975, "_step": 287}
{"Episode reward": -93.0840314715778, "Episode length": 999, "Policy Loss": -0.2097460776567459, "Value Loss": 0.0056425100192427635, "_runtime": 16062.677470684052, "_timestamp": 1585585978.522104, "_step": 288}
{"Episode reward": -93.16032753232167, "Episode length": 999, "Policy Loss": -0.2100641280412674, "Value Loss": 0.005616802256554365, "_runtime": 16063.223793268204, "_timestamp": 1585585979.0684266, "_step": 289}
{"Episode reward": 70.72275338246303, "Episode length": 318, "Policy Loss": 0.5738356709480286, "Value Loss": 31.402936935424805, "_runtime": 16064.816057920456, "_timestamp": 1585585980.6606913, "_step": 290}
{"Episode reward": -92.61840017529697, "Episode length": 999, "Policy Loss": -0.21159300208091736, "Value Loss": 0.005600667558610439, "_runtime": 16065.896911621094, "_timestamp": 1585585981.741545, "_step": 291}
{"Episode reward": 36.70684236822757, "Episode length": 678, "Policy Loss": 0.1758272349834442, "Value Loss": 14.731730461120605, "_runtime": 16067.417555093765, "_timestamp": 1585585983.2621884, "_step": 292}
{"Episode reward": -93.48527326326045, "Episode length": 999, "Policy Loss": -0.21201543509960175, "Value Loss": 0.005746900569647551, "_runtime": 16068.24687051773, "_timestamp": 1585585984.0915039, "_step": 293}
{"Episode reward": 53.01680082862698, "Episode length": 507, "Policy Loss": 0.2702449560165405, "Value Loss": 19.698278427124023, "_runtime": 16069.814706802368, "_timestamp": 1585585985.6593401, "_step": 294}
{"Episode reward": -90.32805609005591, "Episode length": 999, "Policy Loss": -0.20356081426143646, "Value Loss": 0.0056344009935855865, "_runtime": 16071.3007376194, "_timestamp": 1585585987.145371, "_step": 295}
{"Episode reward": 14.602600188183786, "Episode length": 939, "Policy Loss": 0.03897862508893013, "Value Loss": 10.638218879699707, "_runtime": 16072.84053325653, "_timestamp": 1585585988.6851666, "_step": 296}
{"Episode reward": -91.65076691502901, "Episode length": 999, "Policy Loss": -0.2052387148141861, "Value Loss": 0.0058154151774942875, "_runtime": 16074.084403038025, "_timestamp": 1585585989.9290364, "_step": 297}
{"Episode reward": 29.595593649787347, "Episode length": 775, "Policy Loss": 0.1380217969417572, "Value Loss": 12.88814640045166, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205, -12.87426471710205]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0], "bins": [-14.882450103759766, -14.48615550994873, -14.089859962463379, -13.693565368652344, -13.297269821166992, -12.900975227355957, -12.504680633544922, -12.10838508605957, -11.712090492248535, -11.3157958984375, -10.919500350952148, -10.523205757141113, -10.126911163330078, -9.730615615844727, -9.334321022033691, -8.938026428222656, -8.541730880737305, -8.145435333251953, -7.749140739440918, -7.352846145629883, -6.9565510749816895, -6.560256004333496, -6.163961410522461, -5.767665863037109, -5.371371269226074, -4.975076675415039, -4.5787811279296875, -4.182486534118652, -3.786191940307617, -3.3898963928222656, -2.9936017990112305, -2.597306251525879, -2.2010116577148438, -1.8047170639038086, -1.408421516418457, -1.0121269226074219, -0.6158313751220703, -0.21953678131103516, 0.1767578125, 0.5730533599853516, 0.9693479537963867, 1.3656425476074219, 1.7619380950927734, 2.158233642578125, 2.5545272827148438, 2.9508228302001953, 3.347118377685547, 3.7434120178222656, 4.139707565307617, 4.536003112792969, 4.9322967529296875, 5.328592300415039, 5.724887847900391, 6.121181488037109, 6.517477035522461, 6.9137725830078125, 7.310066223144531, 7.706361770629883, 8.102657318115234, 8.498952865600586, 8.895246505737305, 9.291542053222656, 9.687837600708008, 10.084131240844727, 10.480426788330078]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0], "bins": [-6.278592586517334, -6.150118827819824, -6.021644592285156, -5.8931708335876465, -5.7646965980529785, -5.636222839355469, -5.507748603820801, -5.379274845123291, -5.250801086425781, -5.122326850891113, -4.993852615356445, -4.8653788566589355, -4.736905097961426, -4.608430862426758, -4.479957103729248, -4.351483345031738, -4.22300910949707, -4.094534873962402, -3.9660611152648926, -3.8375871181488037, -3.709113121032715, -3.580639362335205, -3.452165365219116, -3.3236913681030273, -3.1952173709869385, -3.0667433738708496, -2.9382693767547607, -2.809795379638672, -2.681321620941162, -2.5528476238250732, -2.4243736267089844, -2.2958996295928955, -2.1674256324768066, -2.038951873779297, -1.910477638244629, -1.7820038795471191, -1.6535296440124512, -1.5250558853149414, -1.3965816497802734, -1.2681078910827637, -1.1396336555480957, -1.011159896850586, -0.8826861381530762, -0.7542119026184082, -0.6257381439208984, -0.49726390838623047, -0.3687901496887207, -0.24031591415405273, -0.11184215545654297, 0.016631603240966797, 0.14510583877563477, 0.27357959747314453, 0.4020538330078125, 0.5305275917053223, 0.6590018272399902, 0.7874755859375, 0.9159493446350098, 1.0444235801696777, 1.1728973388671875, 1.3013715744018555, 1.4298453330993652, 1.5583195686340332, 1.686793327331543, 1.8152670860290527, 1.9437413215637207]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 5.0, 1.0, 6.0, 2.0, 3.0, 2.0, 4.0, 3.0, 5.0, 3.0, 3.0, 3.0, 7.0, 10.0, 11.0, 16.0, 24.0, 25.0, 38.0, 25.0, 30.0, 21.0, 44.0, 28.0, 29.0, 27.0, 22.0, 14.0, 17.0, 8.0, 8.0, 5.0, 6.0, 6.0, 7.0, 4.0, 4.0, 6.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0], "bins": [-4.219777584075928, -4.107693195343018, -3.995608329772949, -3.88352370262146, -3.7714390754699707, -3.6593544483184814, -3.547269821166992, -3.435185194015503, -3.3231005668640137, -3.2110161781311035, -3.098931312561035, -2.986846923828125, -2.8747620582580566, -2.7626776695251465, -2.650592803955078, -2.538508415222168, -2.4264235496520996, -2.3143391609191895, -2.2022545337677, -2.090169906616211, -1.9780852794647217, -1.8660006523132324, -1.7539160251617432, -1.641831398010254, -1.5297467708587646, -1.4176621437072754, -1.3055775165557861, -1.1934928894042969, -1.0814082622528076, -0.9693236351013184, -0.8572390079498291, -0.7451543807983398, -0.6330697536468506, -0.5209851264953613, -0.40890049934387207, -0.2968158721923828, -0.18473148345947266, -0.0726466178894043, 0.03943777084350586, 0.15152263641357422, 0.2636070251464844, 0.37569189071655273, 0.4877762794494629, 0.5998611450195312, 0.7119455337524414, 0.8240303993225098, 0.9361147880554199, 1.0481996536254883, 1.1602840423583984, 1.2723689079284668, 1.384453296661377, 1.4965381622314453, 1.6086225509643555, 1.7207074165344238, 1.832791805267334, 1.9448766708374023, 2.0569610595703125, 2.169045925140381, 2.281130313873291, 2.3932151794433594, 2.5052995681762695, 2.617384433746338, 2.729468822479248, 2.8415536880493164, 2.9536380767822266]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-6.5133819580078125, -6.342332363128662, -6.171282768249512, -6.0002336502075195, -5.829184055328369, -5.658134460449219, -5.487084865570068, -5.316035270690918, -5.144985675811768, -4.973936080932617, -4.802886962890625, -4.631837368011475, -4.460787773132324, -4.289738178253174, -4.118688583374023, -3.947639226913452, -3.7765896320343018, -3.6055400371551514, -3.43449068069458, -3.2634410858154297, -3.0923914909362793, -2.921342134475708, -2.7502925395965576, -2.5792429447174072, -2.408193588256836, -2.2371439933776855, -2.066094398498535, -1.8950448036193848, -1.7239952087402344, -1.5529460906982422, -1.3818964958190918, -1.2108469009399414, -1.039797306060791, -0.8687477111816406, -0.6976981163024902, -0.5266485214233398, -0.35559940338134766, -0.18454980850219727, -0.013500213623046875, 0.15754938125610352, 0.3285989761352539, 0.4996485710144043, 0.6706976890563965, 0.8417472839355469, 1.0127968788146973, 1.1838464736938477, 1.354896068572998, 1.5259456634521484, 1.6969947814941406, 1.8680448532104492, 2.0390939712524414, 2.21014404296875, 2.381193161010742, 2.5522422790527344, 2.723292350769043, 2.894341468811035, 3.0653915405273438, 3.236440658569336, 3.407489776611328, 3.5785398483276367, 3.749588966369629, 3.9206390380859375, 4.09168815612793, 4.262738227844238, 4.4337873458862305]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 11.0, 15.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-2.3100521564483643, -2.2215988636016846, -2.133145570755005, -2.044692277908325, -1.9562389850616455, -1.8677856922149658, -1.7793322801589966, -1.690878987312317, -1.6024256944656372, -1.5139724016189575, -1.4255191087722778, -1.3370656967163086, -1.248612403869629, -1.1601591110229492, -1.0717058181762695, -0.9832525253295898, -0.8947992324829102, -0.8063459396362305, -0.7178926467895508, -0.6294393539428711, -0.5409860610961914, -0.45253264904022217, -0.3640793561935425, -0.27562618255615234, -0.18717265129089355, -0.09871935844421387, -0.01026606559753418, 0.07818722724914551, 0.1666405200958252, 0.2550938129425049, 0.34354710578918457, 0.43200039863586426, 0.520453691482544, 0.6089069843292236, 0.6973602771759033, 0.785813570022583, 0.8742668628692627, 0.9627201557159424, 1.051173448562622, 1.1396267414093018, 1.2280800342559814, 1.3165335655212402, 1.40498685836792, 1.4934401512145996, 1.5818934440612793, 1.670346736907959, 1.7587997913360596, 1.8472530841827393, 1.9357068538665771, 2.024160146713257, 2.1126134395599365, 2.201066732406616, 2.289520025253296, 2.3779733180999756, 2.4664266109466553, 2.554879903793335, 2.6433331966400146, 2.7317864894866943, 2.820239782333374, 2.9086930751800537, 2.9971463680267334, 3.085599660873413, 3.1740529537200928, 3.2625062465667725, 3.350959539413452]}, "_runtime": 16075.199913024902, "_timestamp": 1585585991.0445464, "_step": 298}
{"Episode reward": 35.174951712841235, "Episode length": 701, "Policy Loss": 0.15410959720611572, "Value Loss": 14.24819564819336, "_runtime": 16076.771240711212, "_timestamp": 1585585992.615874, "_step": 299}
{"Episode reward": -91.65888267845992, "Episode length": 999, "Policy Loss": -0.20287968218326569, "Value Loss": 0.005961263552308083, "_runtime": 16078.384330749512, "_timestamp": 1585585994.228964, "_step": 300}
{"Episode reward": -90.22240901688782, "Episode length": 999, "Policy Loss": -0.19588197767734528, "Value Loss": 0.005879318807274103, "_runtime": 16079.66822218895, "_timestamp": 1585585995.5128555, "_step": 301}
{"Episode reward": 24.609820390074788, "Episode length": 820, "Policy Loss": 0.12143849581480026, "Value Loss": 12.181197166442871, "_runtime": 16080.6494743824, "_timestamp": 1585585996.4941077, "_step": 302}
{"Episode reward": 44.268152397746604, "Episode length": 614, "Policy Loss": 0.148739755153656, "Value Loss": 16.265958786010742, "_runtime": 16082.240614414215, "_timestamp": 1585585998.0852478, "_step": 303}
{"Episode reward": -90.9010942728302, "Episode length": 999, "Policy Loss": -0.19402652978897095, "Value Loss": 0.005978685338050127, "_runtime": 16083.810726642609, "_timestamp": 1585585999.65536, "_step": 304}
{"Episode reward": -89.61959134486293, "Episode length": 999, "Policy Loss": -0.19279435276985168, "Value Loss": 0.0058863358572125435, "_runtime": 16084.554349660873, "_timestamp": 1585586000.398983, "_step": 305}
{"Episode reward": 58.76747908396194, "Episode length": 463, "Policy Loss": 1.0342435836791992, "Value Loss": 21.568666458129883, "_runtime": 16086.14735174179, "_timestamp": 1585586001.991985, "_step": 306}
{"Episode reward": -91.39828399142866, "Episode length": 999, "Policy Loss": -0.20400398969650269, "Value Loss": 0.006047316826879978, "_runtime": 16087.7433218956, "_timestamp": 1585586003.5879552, "_step": 307}
{"Episode reward": -92.07499944833266, "Episode length": 999, "Policy Loss": -0.20993690192699432, "Value Loss": 0.0061530680395662785, "_runtime": 16089.279351949692, "_timestamp": 1585586005.1239853, "_step": 308}
{"Episode reward": -91.87788732063034, "Episode length": 999, "Policy Loss": -0.21288363635540009, "Value Loss": 0.006119134835898876, "_runtime": 16090.875855922699, "_timestamp": 1585586006.7204893, "_step": 309}
{"Episode reward": -92.65480650408927, "Episode length": 999, "Policy Loss": -0.21613258123397827, "Value Loss": 0.006069518160074949, "_runtime": 16092.001264095306, "_timestamp": 1585586007.8458974, "_step": 310}
{"Episode reward": 33.52353221056984, "Episode length": 711, "Policy Loss": 0.579062819480896, "Value Loss": 14.047891616821289, "_runtime": 16093.576304197311, "_timestamp": 1585586009.4209375, "_step": 311}
{"Episode reward": -92.22637685470104, "Episode length": 999, "Policy Loss": -0.21857918798923492, "Value Loss": 0.005895712878555059, "_runtime": 16095.159813404083, "_timestamp": 1585586011.0044467, "_step": 312}
{"Episode reward": -94.36978326623948, "Episode length": 999, "Policy Loss": -0.22967229783535004, "Value Loss": 0.005949825048446655, "_runtime": 16096.727358102798, "_timestamp": 1585586012.5719914, "_step": 313}
{"Episode reward": -93.66419353154588, "Episode length": 999, "Policy Loss": -0.22914433479309082, "Value Loss": 0.005751900374889374, "_runtime": 16098.309930562973, "_timestamp": 1585586014.154564, "_step": 314}
{"Episode reward": -94.50121945986113, "Episode length": 999, "Policy Loss": -0.23255418241024017, "Value Loss": 0.005675328895449638, "_runtime": 16099.91297674179, "_timestamp": 1585586015.75761, "_step": 315}
{"Episode reward": -95.4347080596833, "Episode length": 999, "Policy Loss": -0.2340194433927536, "Value Loss": 0.005571763962507248, "_runtime": 16101.545649528503, "_timestamp": 1585586017.3902829, "_step": 316}
{"Episode reward": -95.78206630389545, "Episode length": 999, "Policy Loss": -0.23155821859836578, "Value Loss": 0.005371389910578728, "_runtime": 16103.145505189896, "_timestamp": 1585586018.9901385, "_step": 317}
{"Episode reward": -95.6397363509398, "Episode length": 999, "Policy Loss": -0.2258201241493225, "Value Loss": 0.0051634288392961025, "_runtime": 16103.892520427704, "_timestamp": 1585586019.7371538, "_step": 318}
{"Episode reward": 57.160026836677524, "Episode length": 454, "Policy Loss": 0.4933646023273468, "Value Loss": 21.999460220336914, "_runtime": 16104.531466722488, "_timestamp": 1585586020.3761, "_step": 319}
{"Episode reward": 63.601828881757605, "Episode length": 384, "Policy Loss": 0.50419682264328, "Value Loss": 26.009096145629883, "_runtime": 16105.994704723358, "_timestamp": 1585586021.839338, "_step": 320}
{"Episode reward": 12.618167885494557, "Episode length": 922, "Policy Loss": 0.11161237955093384, "Value Loss": 10.835241317749023, "_runtime": 16107.54905128479, "_timestamp": 1585586023.3936846, "_step": 321}
{"Episode reward": -94.95063637553304, "Episode length": 999, "Policy Loss": -0.22466222941875458, "Value Loss": 0.004786643199622631, "_runtime": 16109.076880455017, "_timestamp": 1585586024.9215138, "_step": 322}
{"Episode reward": -94.73035754530927, "Episode length": 999, "Policy Loss": -0.22201043367385864, "Value Loss": 0.004751776810735464, "_runtime": 16110.665910720825, "_timestamp": 1585586026.510544, "_step": 323}
{"Episode reward": -95.30619126994989, "Episode length": 999, "Policy Loss": -0.22372636198997498, "Value Loss": 0.004739486146718264, "_runtime": 16112.24006485939, "_timestamp": 1585586028.0846982, "_step": 324}
{"Episode reward": -95.73428731338066, "Episode length": 999, "Policy Loss": -0.22584864497184753, "Value Loss": 0.004685316700488329, "_runtime": 16113.307819128036, "_timestamp": 1585586029.1524525, "_step": 325}
{"Episode reward": 35.17969269381824, "Episode length": 674, "Policy Loss": 0.568949818611145, "Value Loss": 14.820759773254395, "_runtime": 16114.893340587616, "_timestamp": 1585586030.737974, "_step": 326}
{"Episode reward": -96.01405197567486, "Episode length": 999, "Policy Loss": -0.22617609798908234, "Value Loss": 0.004545338451862335, "_runtime": 16116.487873077393, "_timestamp": 1585586032.3325064, "_step": 327}
{"Episode reward": -96.36481238869735, "Episode length": 999, "Policy Loss": -0.226292684674263, "Value Loss": 0.004486015997827053, "_runtime": 16118.042049884796, "_timestamp": 1585586033.8866832, "_step": 328}
{"Episode reward": -95.46734653255864, "Episode length": 999, "Policy Loss": -0.21938803791999817, "Value Loss": 0.004320092964917421, "_runtime": 16119.619285106659, "_timestamp": 1585586035.4639184, "_step": 329}
{"Episode reward": -96.59950976298902, "Episode length": 999, "Policy Loss": -0.2228740006685257, "Value Loss": 0.0042434269562363625, "_runtime": 16121.200092792511, "_timestamp": 1585586037.0447261, "_step": 330}
{"Episode reward": -96.52078279999789, "Episode length": 999, "Policy Loss": -0.22123269736766815, "Value Loss": 0.004122429993003607, "_runtime": 16122.775283813477, "_timestamp": 1585586038.6199172, "_step": 331}
{"Episode reward": -96.40341090068674, "Episode length": 999, "Policy Loss": -0.21497084200382233, "Value Loss": 0.003951758146286011, "_runtime": 16124.35398364067, "_timestamp": 1585586040.198617, "_step": 332}
{"Episode reward": -95.61598643729414, "Episode length": 999, "Policy Loss": -0.21292607486248016, "Value Loss": 0.003767600515857339, "_runtime": 16125.96691942215, "_timestamp": 1585586041.8115528, "_step": 333}
{"Episode reward": -96.6287471582331, "Episode length": 999, "Policy Loss": -0.20984399318695068, "Value Loss": 0.0036245756782591343, "_runtime": 16127.02548956871, "_timestamp": 1585586042.870123, "_step": 334}
{"Episode reward": 35.549063698188604, "Episode length": 668, "Policy Loss": 0.2868495583534241, "Value Loss": 14.955605506896973, "_runtime": 16128.443530321121, "_timestamp": 1585586044.2881637, "_step": 335}
{"Episode reward": 12.509087560477184, "Episode length": 901, "Policy Loss": 0.18952420353889465, "Value Loss": 11.089066505432129, "_runtime": 16130.023753166199, "_timestamp": 1585586045.8683865, "_step": 336}
{"Episode reward": -96.36326612686325, "Episode length": 999, "Policy Loss": -0.19634173810482025, "Value Loss": 0.00324219255708158, "_runtime": 16130.521558761597, "_timestamp": 1585586046.366192, "_step": 337}
{"Episode reward": 71.03324046112564, "Episode length": 300, "Policy Loss": 0.9107387065887451, "Value Loss": 33.29826354980469, "_runtime": 16132.091662406921, "_timestamp": 1585586047.9362957, "_step": 338}
{"Episode reward": -95.70572567680964, "Episode length": 999, "Policy Loss": -0.19249282777309418, "Value Loss": 0.003162587294355035, "_runtime": 16133.675688743591, "_timestamp": 1585586049.520322, "_step": 339}
{"Episode reward": -96.0381651431894, "Episode length": 999, "Policy Loss": -0.19510219991207123, "Value Loss": 0.0031952732242643833, "_runtime": 16134.161407232285, "_timestamp": 1585586050.0060406, "_step": 340}
{"Episode reward": 69.38232517746603, "Episode length": 311, "Policy Loss": 0.8347397446632385, "Value Loss": 32.12057113647461, "_runtime": 16135.738796710968, "_timestamp": 1585586051.58343, "_step": 341}
{"Episode reward": -95.44851323626195, "Episode length": 999, "Policy Loss": -0.19823215901851654, "Value Loss": 0.0032718093134462833, "_runtime": 16137.308094501495, "_timestamp": 1585586053.1527278, "_step": 342}
{"Episode reward": -96.56125083331032, "Episode length": 999, "Policy Loss": -0.20485441386699677, "Value Loss": 0.0033516492694616318, "_runtime": 16138.380521774292, "_timestamp": 1585586054.225155, "_step": 343}
{"Episode reward": 31.829179316013366, "Episode length": 713, "Policy Loss": 0.2843294143676758, "Value Loss": 14.011954307556152, "_runtime": 16139.36543726921, "_timestamp": 1585586055.2100706, "_step": 344}
{"Episode reward": 40.559986587059285, "Episode length": 614, "Policy Loss": 0.34742236137390137, "Value Loss": 16.27056121826172, "_runtime": 16140.424900054932, "_timestamp": 1585586056.2695334, "_step": 345}
{"Episode reward": 35.52225085038964, "Episode length": 671, "Policy Loss": 0.2714974582195282, "Value Loss": 14.888497352600098, "_runtime": 16141.971393585205, "_timestamp": 1585586057.816027, "_step": 346}
{"Episode reward": -96.12796291226547, "Episode length": 999, "Policy Loss": -0.21160255372524261, "Value Loss": 0.003720503766089678, "_runtime": 16143.503543615341, "_timestamp": 1585586059.348177, "_step": 347}
{"Episode reward": -96.04077827367726, "Episode length": 999, "Policy Loss": -0.214498370885849, "Value Loss": 0.003802793798968196, "_runtime": 16144.268835544586, "_timestamp": 1585586060.113469, "_step": 348}
{"Episode reward": 53.607651301737995, "Episode length": 481, "Policy Loss": 0.5027122497558594, "Value Loss": 20.767372131347656, "_runtime": 16145.82827949524, "_timestamp": 1585586061.6729128, "_step": 349}
{"Episode reward": -95.89350773654739, "Episode length": 999, "Policy Loss": -0.22030895948410034, "Value Loss": 0.0040082731284201145, "_runtime": 16147.409358263016, "_timestamp": 1585586063.2539916, "_step": 350}
{"Episode reward": -96.3486082310902, "Episode length": 999, "Policy Loss": -0.22143606841564178, "Value Loss": 0.004142017103731632, "_runtime": 16148.972477912903, "_timestamp": 1585586064.8171113, "_step": 351}
{"Episode reward": -95.47989032416508, "Episode length": 999, "Policy Loss": -0.2216442972421646, "Value Loss": 0.004136720672249794, "_runtime": 16150.239282608032, "_timestamp": 1585586066.083916, "_step": 352}
{"Episode reward": 23.62079934123146, "Episode length": 799, "Policy Loss": 0.2778681516647339, "Value Loss": 12.503186225891113, "_runtime": 16151.80950665474, "_timestamp": 1585586067.65414, "_step": 353}
{"Episode reward": -95.24015764369626, "Episode length": 999, "Policy Loss": -0.22148826718330383, "Value Loss": 0.004179761745035648, "_runtime": 16153.381170034409, "_timestamp": 1585586069.2258034, "_step": 354}
{"Episode reward": -96.80636390771454, "Episode length": 999, "Policy Loss": -0.22928987443447113, "Value Loss": 0.004280576016753912, "_runtime": 16154.643712759018, "_timestamp": 1585586070.488346, "_step": 355}
{"Episode reward": 22.369788934355498, "Episode length": 802, "Policy Loss": 0.16231873631477356, "Value Loss": 12.456367492675781, "_runtime": 16156.224803447723, "_timestamp": 1585586072.0694368, "_step": 356}
{"Episode reward": -95.77095607839685, "Episode length": 999, "Policy Loss": -0.22574414312839508, "Value Loss": 0.004233361687511206, "_runtime": 16157.207303524017, "_timestamp": 1585586073.0519369, "_step": 357}
{"Episode reward": 40.36124007954204, "Episode length": 618, "Policy Loss": 0.2765899896621704, "Value Loss": 16.163949966430664, "_runtime": 16158.760023117065, "_timestamp": 1585586074.6046565, "_step": 358}
{"Episode reward": -96.0849866209944, "Episode length": 999, "Policy Loss": -0.22668540477752686, "Value Loss": 0.0042395512573421, "_runtime": 16160.344787597656, "_timestamp": 1585586076.189421, "_step": 359}
{"Episode reward": -94.66410441537165, "Episode length": 999, "Policy Loss": -0.22019396722316742, "Value Loss": 0.004186027683317661, "_runtime": 16161.891835451126, "_timestamp": 1585586077.7364688, "_step": 360}
{"Episode reward": -96.37065616803456, "Episode length": 999, "Policy Loss": -0.22298766672611237, "Value Loss": 0.004237207118421793, "_runtime": 16162.848864078522, "_timestamp": 1585586078.6934974, "_step": 361}
{"Episode reward": 42.533552458348844, "Episode length": 592, "Policy Loss": 0.5211139917373657, "Value Loss": 16.873695373535156, "_runtime": 16164.44246673584, "_timestamp": 1585586080.2871, "_step": 362}
{"Episode reward": -96.71492458448691, "Episode length": 999, "Policy Loss": -0.2252197116613388, "Value Loss": 0.004187935497611761, "_runtime": 16166.027168273926, "_timestamp": 1585586081.8718016, "_step": 363}
{"Episode reward": -96.30367888755971, "Episode length": 999, "Policy Loss": -0.22464445233345032, "Value Loss": 0.004126421175897121, "_runtime": 16167.570127725601, "_timestamp": 1585586083.414761, "_step": 364}
{"Episode reward": -96.34088357844824, "Episode length": 999, "Policy Loss": -0.22184304893016815, "Value Loss": 0.004061696585267782, "_runtime": 16169.159233808517, "_timestamp": 1585586085.0038671, "_step": 365}
{"Episode reward": -96.15467132511661, "Episode length": 999, "Policy Loss": -0.21715791523456573, "Value Loss": 0.003977542277425528, "_runtime": 16170.738020658493, "_timestamp": 1585586086.582654, "_step": 366}
{"Episode reward": -96.08700116876754, "Episode length": 999, "Policy Loss": -0.21548302471637726, "Value Loss": 0.003874665591865778, "_runtime": 16172.03302359581, "_timestamp": 1585586087.877657, "_step": 367}
{"Episode reward": 21.91777522716272, "Episode length": 815, "Policy Loss": 0.4768863916397095, "Value Loss": 12.258269309997559, "_runtime": 16173.659043312073, "_timestamp": 1585586089.5036767, "_step": 368}
{"Episode reward": -95.97190530335789, "Episode length": 999, "Policy Loss": -0.21131008863449097, "Value Loss": 0.003661565249785781, "_runtime": 16175.240586280823, "_timestamp": 1585586091.0852196, "_step": 369}
{"Episode reward": -95.87868839935925, "Episode length": 999, "Policy Loss": -0.20665395259857178, "Value Loss": 0.0035457354970276356, "_runtime": 16176.819293737411, "_timestamp": 1585586092.663927, "_step": 370}
{"Episode reward": -96.6031464829411, "Episode length": 999, "Policy Loss": -0.2062305510044098, "Value Loss": 0.003466622903943062, "_runtime": 16178.406163930893, "_timestamp": 1585586094.2507973, "_step": 371}
{"Episode reward": -96.72053483638437, "Episode length": 999, "Policy Loss": -0.20434759557247162, "Value Loss": 0.003361128270626068, "_runtime": 16179.991402387619, "_timestamp": 1585586095.8360357, "_step": 372}
{"Episode reward": -96.53997645612031, "Episode length": 999, "Policy Loss": -0.2011084109544754, "Value Loss": 0.0031925998628139496, "_runtime": 16181.569267749786, "_timestamp": 1585586097.413901, "_step": 373}
{"Episode reward": -96.14388706015863, "Episode length": 999, "Policy Loss": -0.1940985918045044, "Value Loss": 0.0030492155347019434, "_runtime": 16182.727663040161, "_timestamp": 1585586098.5722964, "_step": 374}
{"Episode reward": 29.96149434345132, "Episode length": 722, "Policy Loss": 0.2520512342453003, "Value Loss": 13.83803653717041, "_runtime": 16184.296352863312, "_timestamp": 1585586100.1409862, "_step": 375}
{"Episode reward": -96.20563160732694, "Episode length": 999, "Policy Loss": -0.1874278485774994, "Value Loss": 0.0027905970346182585, "_runtime": 16185.87652516365, "_timestamp": 1585586101.7211585, "_step": 376}
{"Episode reward": -96.383484651156, "Episode length": 999, "Policy Loss": -0.1822737753391266, "Value Loss": 0.0027168833184987307, "_runtime": 16187.440899133682, "_timestamp": 1585586103.2855325, "_step": 377}
{"Episode reward": -96.52821105587363, "Episode length": 999, "Policy Loss": -0.17995072901248932, "Value Loss": 0.002600693376734853, "_runtime": 16189.028105974197, "_timestamp": 1585586104.8727393, "_step": 378}
{"Episode reward": -96.37209546589541, "Episode length": 999, "Policy Loss": -0.17525336146354675, "Value Loss": 0.0024853709619492292, "_runtime": 16189.683512210846, "_timestamp": 1585586105.5281456, "_step": 379}
{"Episode reward": 62.071995726340916, "Episode length": 392, "Policy Loss": 0.7405321002006531, "Value Loss": 25.48727798461914, "_runtime": 16191.119704723358, "_timestamp": 1585586106.964338, "_step": 380}
{"Episode reward": 13.079773915830387, "Episode length": 908, "Policy Loss": 0.39624330401420593, "Value Loss": 11.004630088806152, "_runtime": 16192.319154262543, "_timestamp": 1585586108.1637876, "_step": 381}
{"Episode reward": 28.64255381540704, "Episode length": 735, "Policy Loss": 0.32755738496780396, "Value Loss": 13.59439468383789, "_runtime": 16193.846581697464, "_timestamp": 1585586109.691215, "_step": 382}
{"Episode reward": -96.65221164638618, "Episode length": 999, "Policy Loss": -0.17227531969547272, "Value Loss": 0.0023788725957274437, "_runtime": 16195.416999578476, "_timestamp": 1585586111.261633, "_step": 383}
{"Episode reward": -98.04450746676737, "Episode length": 999, "Policy Loss": -0.18081603944301605, "Value Loss": 0.0024129594676196575, "_runtime": 16196.221728563309, "_timestamp": 1585586112.066362, "_step": 384}
{"Episode reward": 52.97120126365487, "Episode length": 486, "Policy Loss": 0.4911178946495056, "Value Loss": 20.55789566040039, "_runtime": 16197.774965047836, "_timestamp": 1585586113.6195984, "_step": 385}
{"Episode reward": -97.18533940737166, "Episode length": 999, "Policy Loss": -0.1760505586862564, "Value Loss": 0.0024393133353441954, "_runtime": 16199.339009046555, "_timestamp": 1585586115.1836424, "_step": 386}
{"Episode reward": -96.29026649845294, "Episode length": 999, "Policy Loss": -0.17619934678077698, "Value Loss": 0.0024622140917927027, "_runtime": 16200.867406845093, "_timestamp": 1585586116.7120402, "_step": 387}
{"Episode reward": -96.86553464824387, "Episode length": 999, "Policy Loss": -0.1801026314496994, "Value Loss": 0.0024806319270282984, "_runtime": 16202.438172101974, "_timestamp": 1585586118.2828054, "_step": 388}
{"Episode reward": -97.2755724998096, "Episode length": 999, "Policy Loss": -0.18235427141189575, "Value Loss": 0.0024815485812723637, "_runtime": 16204.007252454758, "_timestamp": 1585586119.8518858, "_step": 389}
{"Episode reward": -97.44800790086478, "Episode length": 999, "Policy Loss": -0.18100474774837494, "Value Loss": 0.0024263726081699133, "_runtime": 16205.579815387726, "_timestamp": 1585586121.4244487, "_step": 390}
{"Episode reward": -97.12139740242107, "Episode length": 999, "Policy Loss": -0.17846214771270752, "Value Loss": 0.0024077966809272766, "_runtime": 16206.834013938904, "_timestamp": 1585586122.6786473, "_step": 391}
{"Episode reward": 22.588572698079716, "Episode length": 798, "Policy Loss": 0.37947556376457214, "Value Loss": 12.521347045898438, "_runtime": 16208.423861026764, "_timestamp": 1585586124.2684944, "_step": 392}
{"Episode reward": -96.51133162569683, "Episode length": 999, "Policy Loss": -0.17285650968551636, "Value Loss": 0.002316870493814349, "_runtime": 16209.761001825333, "_timestamp": 1585586125.6056352, "_step": 393}
{"Episode reward": 16.844247757005604, "Episode length": 856, "Policy Loss": 0.20885178446769714, "Value Loss": 11.673201560974121, "_runtime": 16211.316019773483, "_timestamp": 1585586127.160653, "_step": 394}
{"Episode reward": -96.75884098352634, "Episode length": 999, "Policy Loss": -0.17327648401260376, "Value Loss": 0.002287703100591898, "_runtime": 16212.285720348358, "_timestamp": 1585586128.1303537, "_step": 395}
{"Episode reward": 41.55762492004788, "Episode length": 602, "Policy Loss": 0.7163050174713135, "Value Loss": 16.597488403320312, "_runtime": 16213.860102415085, "_timestamp": 1585586129.7047358, "_step": 396}
{"Episode reward": -97.84537489501562, "Episode length": 999, "Policy Loss": -0.17490723729133606, "Value Loss": 0.002310402924194932, "_runtime": 16214.588497638702, "_timestamp": 1585586130.433131, "_step": 397}
{"Episode reward": 56.38404860334797, "Episode length": 448, "Policy Loss": 0.5602832436561584, "Value Loss": 22.302017211914062, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305, -0.039916496723890305]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0], "bins": [-0.04809883236885071, -0.04673748090863228, -0.04537613317370415, -0.04401478171348572, -0.04265343397855759, -0.04129208251833916, -0.03993073105812073, -0.038569383323192596, -0.037208035588264465, -0.035846684128046036, -0.034485332667827606, -0.033123984932899475, -0.031762633472681046, -0.030401283875107765, -0.029039934277534485, -0.027678584679961205, -0.026317235082387924, -0.024955885484814644, -0.023594535887241364, -0.022233186289668083, -0.020871836692094803, -0.019510485231876373, -0.018149135634303093, -0.016787786036729813, -0.015426434576511383, -0.014065086841583252, -0.012703735381364822, -0.011342387646436691, -0.009981036186218262, -0.00861968845129013, -0.007258336991071701, -0.00589698925614357, -0.00453563779592514, -0.003174286335706711, -0.0018129386007785797, -0.00045158714056015015, 0.000909760594367981, 0.0022711120545864105, 0.0036324597895145416, 0.004993811249732971, 0.006355158984661102, 0.007716510444879532, 0.009077861905097961, 0.010439209640026093, 0.011800561100244522, 0.013161908835172653, 0.014523260295391083, 0.015884608030319214, 0.017245963215827942, 0.018607310950756073, 0.019968658685684204, 0.021330006420612335, 0.022691361606121063, 0.024052709341049194, 0.025414057075977325, 0.026775404810905457, 0.028136759996414185, 0.029498107731342316, 0.030859455466270447, 0.032220810651779175, 0.033582158386707306, 0.03494350612163544, 0.03630485385656357, 0.037666209042072296, 0.03902755677700043]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02393505908548832, -0.02347518317401409, -0.023015307262539864, -0.022555429488420486, -0.02209555357694626, -0.02163567766547203, -0.021175801753997803, -0.020715925842523575, -0.020256049931049347, -0.01979617215692997, -0.019336296245455742, -0.018876420333981514, -0.018416544422507286, -0.01795666664838791, -0.01749679073691368, -0.017036914825439453, -0.016577038913965225, -0.016117163002490997, -0.01565728709101677, -0.015197410248219967, -0.014737533405423164, -0.014277657493948936, -0.013817781582474709, -0.013357904739677906, -0.012898028828203678, -0.01243815291672945, -0.011978276073932648, -0.01151840016245842, -0.011058524250984192, -0.01059864740818739, -0.010138771496713161, -0.009678894653916359, -0.009219018742442131, -0.008759142830967903, -0.008299266919493675, -0.007839389145374298, -0.00737951323390007, -0.006919637322425842, -0.006459761410951614, -0.0059998854994773865, -0.005540007725358009, -0.005080131813883781, -0.0046202559024095535, -0.004160379990935326, -0.0037005040794610977, -0.00324062816798687, -0.0027807503938674927, -0.0023208744823932648, -0.0018609985709190369, -0.001401122659444809, -0.0009412467479705811, -0.0004813689738512039, -2.1493062376976013e-05, 0.0004383828490972519, 0.0008982587605714798, 0.0013581346720457077, 0.0018180105835199356, 0.0022778883576393127, 0.0027377642691135406, 0.0031976401805877686, 0.0036575160920619965, 0.004117392003536224, 0.0045772697776556015, 0.005037145689129829, 0.005497021600604057]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 4.0, 8.0, 3.0, 4.0, 7.0, 3.0, 7.0, 22.0, 69.0, 100.0, 67.0, 39.0, 22.0, 16.0, 12.0, 9.0, 11.0, 9.0, 7.0, 7.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.03500663489103317, -0.03402665629982948, -0.033046673983335495, -0.032066695392131805, -0.031086716800928116, -0.030106736347079277, -0.029126755893230438, -0.02814677730202675, -0.02716679684817791, -0.02618681639432907, -0.02520683780312538, -0.024226857349276543, -0.023246876895427704, -0.022266898304224014, -0.021286917850375175, -0.020306937396526337, -0.019326958805322647, -0.01834697835147381, -0.01736699976027012, -0.01638701930642128, -0.01540704071521759, -0.014427060261368752, -0.013447079807519913, -0.012467101216316223, -0.011487120762467384, -0.010507140308618546, -0.009527161717414856, -0.008547181263566017, -0.007567200809717178, -0.006587222218513489, -0.00560724176466465, -0.00462726317346096, -0.0036472827196121216, -0.002667304128408432, -0.001687321811914444, -0.0007073432207107544, 0.0002726353704929352, 0.0012526176869869232, 0.002232596278190613, 0.0032125748693943024, 0.004192553460597992, 0.00517253577709198, 0.0061525143682956696, 0.007132492959499359, 0.008112475275993347, 0.009092453867197037, 0.010072432458400726, 0.011052414774894714, 0.012032393366098404, 0.013012371957302094, 0.013992354273796082, 0.014972332864999771, 0.01595231145620346, 0.01693229377269745, 0.01791227236390114, 0.018892250955104828, 0.019872233271598816, 0.020852211862802505, 0.021832190454006195, 0.022812169045209885, 0.023792151361703873, 0.024772129952907562, 0.025752108544111252, 0.02673209086060524, 0.02771206945180893]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03835742548108101, -0.03720741346478462, -0.036057405173778534, -0.03490739315748215, -0.03375738114118576, -0.03260737285017967, -0.031457360833883286, -0.030307350680232048, -0.02915734052658081, -0.028007330372929573, -0.026857320219278336, -0.02570730820298195, -0.02455729804933071, -0.023407287895679474, -0.022257275879383087, -0.02110726572573185, -0.019957255572080612, -0.018807245418429375, -0.017657235264778137, -0.01650722324848175, -0.015357213094830513, -0.014207202941179276, -0.013057190924882889, -0.011907180771231651, -0.010757170617580414, -0.009607160463929176, -0.008457150310277939, -0.007307138293981552, -0.006157126277685165, -0.005007117986679077, -0.0038571059703826904, -0.002707097679376602, -0.0015570856630802155, -0.00040707364678382874, 0.0007429346442222595, 0.0018929466605186462, 0.0030429549515247345, 0.004192966967821121, 0.005342978984117508, 0.006492987275123596, 0.007642999291419983, 0.00879301130771637, 0.009943019598722458, 0.011093031615018845, 0.012243043631315231, 0.01339305192232132, 0.014543063938617706, 0.015693072229623795, 0.01684308424592018, 0.017993096262216568, 0.019143104553222656, 0.020293116569519043, 0.02144312486052513, 0.022593136876821518, 0.023743148893117905, 0.02489316090941429, 0.026043172925710678, 0.027193177491426468, 0.028343189507722855, 0.02949320152401924, 0.030643213540315628, 0.031793225556612015, 0.032943230122327805, 0.03409324213862419, 0.03524325415492058]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.0717652440071106, -0.06847325712442398, -0.06518126279115677, -0.061889275908470154, -0.05859728157520294, -0.05530529469251633, -0.05201330408453941, -0.0487213134765625, -0.04542932286858559, -0.04213733226060867, -0.03884534165263176, -0.035553351044654846, -0.03226136416196823, -0.028969373553991318, -0.025677382946014404, -0.02238539233803749, -0.019093401730060577, -0.015801411122083664, -0.01250942051410675, -0.009217433631420135, -0.005925439298152924, -0.0026334524154663086, 0.0006585419178009033, 0.003950528800487518, 0.007242515683174133, 0.010534510016441345, 0.01382649689912796, 0.017118491232395172, 0.020410478115081787, 0.023702472448349, 0.026994459331035614, 0.030286453664302826, 0.03357844054698944, 0.036870427429676056, 0.04016242176294327, 0.04345440864562988, 0.046746402978897095, 0.05003838986158371, 0.053330376744270325, 0.05662237107753754, 0.05991436541080475, 0.06320634484291077, 0.06649833917617798, 0.06979033350944519, 0.0730823278427124, 0.07637430727481842, 0.07966630160808563, 0.08295829594135284, 0.08625027537345886, 0.08954226970672607, 0.09283426403999329, 0.0961262583732605, 0.09941823780536652, 0.10271023213863373, 0.10600222647190094, 0.10929422080516815, 0.11258620023727417, 0.11587819457054138, 0.1191701889038086, 0.12246216833591461, 0.12575416266918182, 0.12904615700244904, 0.13233815133571625, 0.13563013076782227, 0.13892212510108948]}, "_runtime": 16216.144641399384, "_timestamp": 1585586131.9892747, "_step": 398}
{"Episode reward": -95.86244464522612, "Episode length": 999, "Policy Loss": -0.17264235019683838, "Value Loss": 0.002362902043387294, "_runtime": 16217.732651948929, "_timestamp": 1585586133.5772853, "_step": 399}
{"Episode reward": -96.64645587191224, "Episode length": 999, "Policy Loss": -0.17730890214443207, "Value Loss": 0.0024187234230339527, "_runtime": 16219.257434368134, "_timestamp": 1585586135.1020677, "_step": 400}
{"Episode reward": -96.64480319904033, "Episode length": 999, "Policy Loss": -0.17966294288635254, "Value Loss": 0.0024471599608659744, "_runtime": 16220.315251350403, "_timestamp": 1585586136.1598847, "_step": 401}
{"Episode reward": 38.193702729964066, "Episode length": 634, "Policy Loss": 0.3733992278575897, "Value Loss": 15.759468078613281, "_runtime": 16221.888711690903, "_timestamp": 1585586137.733345, "_step": 402}
{"Episode reward": -97.73155943451124, "Episode length": 999, "Policy Loss": -0.1874321550130844, "Value Loss": 0.0025149937719106674, "_runtime": 16223.461100816727, "_timestamp": 1585586139.3057342, "_step": 403}
{"Episode reward": -97.26829077713323, "Episode length": 999, "Policy Loss": -0.18408693373203278, "Value Loss": 0.002548563526943326, "_runtime": 16224.805632829666, "_timestamp": 1585586140.6502662, "_step": 404}
{"Episode reward": 15.083354370683907, "Episode length": 870, "Policy Loss": 0.19407476484775543, "Value Loss": 11.485077857971191, "_runtime": 16226.130907535553, "_timestamp": 1585586141.9755409, "_step": 405}
{"Episode reward": 18.29415691989361, "Episode length": 839, "Policy Loss": 0.21809029579162598, "Value Loss": 11.909149169921875, "_runtime": 16227.706019163132, "_timestamp": 1585586143.5506525, "_step": 406}
{"Episode reward": -96.77404747726514, "Episode length": 999, "Policy Loss": -0.18335998058319092, "Value Loss": 0.002628732705488801, "_runtime": 16229.267477750778, "_timestamp": 1585586145.112111, "_step": 407}
{"Episode reward": -96.29089403077589, "Episode length": 999, "Policy Loss": -0.18168778717517853, "Value Loss": 0.0026271177921444178, "_runtime": 16230.819963216782, "_timestamp": 1585586146.6645966, "_step": 408}
{"Episode reward": -97.03132511299582, "Episode length": 999, "Policy Loss": -0.18671151995658875, "Value Loss": 0.002653475385159254, "_runtime": 16231.357011318207, "_timestamp": 1585586147.2016447, "_step": 409}
{"Episode reward": 69.77462322425066, "Episode length": 315, "Policy Loss": 1.1246986389160156, "Value Loss": 31.71554183959961, "_runtime": 16232.738684892654, "_timestamp": 1585586148.5833182, "_step": 410}
{"Episode reward": 14.296431085976437, "Episode length": 882, "Policy Loss": 0.17255932092666626, "Value Loss": 11.328567504882812, "_runtime": 16234.310594797134, "_timestamp": 1585586150.1552281, "_step": 411}
{"Episode reward": -95.74101285485358, "Episode length": 999, "Policy Loss": -0.18824955821037292, "Value Loss": 0.0028367445338517427, "_runtime": 16235.815524578094, "_timestamp": 1585586151.660158, "_step": 412}
{"Episode reward": -97.18333954043055, "Episode length": 999, "Policy Loss": -0.19340315461158752, "Value Loss": 0.002951360307633877, "_runtime": 16237.38747882843, "_timestamp": 1585586153.2321122, "_step": 413}
{"Episode reward": -96.46847381416211, "Episode length": 999, "Policy Loss": -0.19185620546340942, "Value Loss": 0.0030096827540546656, "_runtime": 16238.956727266312, "_timestamp": 1585586154.8013606, "_step": 414}
{"Episode reward": -97.0555821369921, "Episode length": 999, "Policy Loss": -0.19402067363262177, "Value Loss": 0.0030556891579180956, "_runtime": 16240.520091056824, "_timestamp": 1585586156.3647244, "_step": 415}
{"Episode reward": -97.05529348904588, "Episode length": 999, "Policy Loss": -0.1947941780090332, "Value Loss": 0.0030475561507046223, "_runtime": 16241.801906108856, "_timestamp": 1585586157.6465394, "_step": 416}
{"Episode reward": 22.232062020972776, "Episode length": 802, "Policy Loss": 0.19649046659469604, "Value Loss": 12.457915306091309, "_runtime": 16243.432981491089, "_timestamp": 1585586159.2776148, "_step": 417}
{"Episode reward": -96.71800209010293, "Episode length": 999, "Policy Loss": -0.1931392103433609, "Value Loss": 0.0030239480547606945, "_runtime": 16245.016528129578, "_timestamp": 1585586160.8611615, "_step": 418}
{"Episode reward": -95.69083059397443, "Episode length": 999, "Policy Loss": -0.18751706182956696, "Value Loss": 0.002998846583068371, "_runtime": 16246.588047981262, "_timestamp": 1585586162.4326813, "_step": 419}
{"Episode reward": -95.86198304253843, "Episode length": 999, "Policy Loss": -0.18485544621944427, "Value Loss": 0.0029557435773313046, "_runtime": 16248.177677154541, "_timestamp": 1585586164.0223105, "_step": 420}
{"Episode reward": -96.20469780203673, "Episode length": 999, "Policy Loss": -0.1850029081106186, "Value Loss": 0.002902215113863349, "_runtime": 16249.322614431381, "_timestamp": 1585586165.1672478, "_step": 421}
{"Episode reward": 31.2664332996696, "Episode length": 719, "Policy Loss": 0.28132370114326477, "Value Loss": 13.89587688446045, "_runtime": 16250.912251234055, "_timestamp": 1585586166.7568846, "_step": 422}
{"Episode reward": -95.87430257229603, "Episode length": 999, "Policy Loss": -0.1788269281387329, "Value Loss": 0.0027985216584056616, "_runtime": 16252.516473293304, "_timestamp": 1585586168.3611066, "_step": 423}
{"Episode reward": -95.91390736873366, "Episode length": 999, "Policy Loss": -0.17911694943904877, "Value Loss": 0.002778110094368458, "_runtime": 16254.08114027977, "_timestamp": 1585586169.9257736, "_step": 424}
{"Episode reward": -97.28823082527776, "Episode length": 999, "Policy Loss": -0.18185949325561523, "Value Loss": 0.002734380541369319, "_runtime": 16255.677207708359, "_timestamp": 1585586171.521841, "_step": 425}
{"Episode reward": -96.3350176115909, "Episode length": 999, "Policy Loss": -0.1736070066690445, "Value Loss": 0.002640553517267108, "_runtime": 16257.2716755867, "_timestamp": 1585586173.116309, "_step": 426}
{"Episode reward": -95.76546436392258, "Episode length": 999, "Policy Loss": -0.167202889919281, "Value Loss": 0.002544910181313753, "_runtime": 16258.653367757797, "_timestamp": 1585586174.498001, "_step": 427}
{"Episode reward": 16.05192088809936, "Episode length": 872, "Policy Loss": 0.17938879132270813, "Value Loss": 11.458566665649414, "_runtime": 16260.25432419777, "_timestamp": 1585586176.0989575, "_step": 428}
{"Episode reward": -96.27911995416937, "Episode length": 999, "Policy Loss": -0.16444352269172668, "Value Loss": 0.0024120297748595476, "_runtime": 16260.775273561478, "_timestamp": 1585586176.619907, "_step": 429}
{"Episode reward": 71.47442450828846, "Episode length": 297, "Policy Loss": 0.9617891907691956, "Value Loss": 33.63828659057617, "_runtime": 16262.27292728424, "_timestamp": 1585586178.1175606, "_step": 430}
{"Episode reward": 7.941833469660281, "Episode length": 952, "Policy Loss": 0.1502777338027954, "Value Loss": 10.495336532592773, "_runtime": 16263.871506929398, "_timestamp": 1585586179.7161403, "_step": 431}
{"Episode reward": -96.33264836580935, "Episode length": 999, "Policy Loss": -0.16596083343029022, "Value Loss": 0.0024608143139630556, "_runtime": 16265.39640212059, "_timestamp": 1585586181.2410355, "_step": 432}
{"Episode reward": -96.26081215540074, "Episode length": 999, "Policy Loss": -0.1640370488166809, "Value Loss": 0.0025000094901770353, "_runtime": 16267.0406396389, "_timestamp": 1585586182.885273, "_step": 433}
{"Episode reward": -96.4239076410224, "Episode length": 999, "Policy Loss": -0.16423483192920685, "Value Loss": 0.0025361471343785524, "_runtime": 16268.587819576263, "_timestamp": 1585586184.432453, "_step": 434}
{"Episode reward": 7.026715793222692, "Episode length": 971, "Policy Loss": 0.15523742139339447, "Value Loss": 10.290337562561035, "_runtime": 16270.020013093948, "_timestamp": 1585586185.8646464, "_step": 435}
{"Episode reward": 13.247856162856621, "Episode length": 907, "Policy Loss": 0.2150876522064209, "Value Loss": 11.016390800476074, "_runtime": 16271.379410982132, "_timestamp": 1585586187.2240443, "_step": 436}
{"Episode reward": 17.610029682562228, "Episode length": 860, "Policy Loss": 0.26271989941596985, "Value Loss": 11.618281364440918, "_runtime": 16272.98238325119, "_timestamp": 1585586188.8270166, "_step": 437}
{"Episode reward": -95.22392292103785, "Episode length": 999, "Policy Loss": -0.1644390970468521, "Value Loss": 0.0026518243830651045, "_runtime": 16274.087424516678, "_timestamp": 1585586189.9320579, "_step": 438}
{"Episode reward": 32.8454442445111, "Episode length": 695, "Policy Loss": 0.24571430683135986, "Value Loss": 14.375641822814941, "_runtime": 16275.674520015717, "_timestamp": 1585586191.5191534, "_step": 439}
{"Episode reward": -96.02246651154502, "Episode length": 999, "Policy Loss": -0.16870051622390747, "Value Loss": 0.0027844293508678675, "_runtime": 16277.04931473732, "_timestamp": 1585586192.893948, "_step": 440}
{"Episode reward": 18.217081831904395, "Episode length": 862, "Policy Loss": 0.16730375587940216, "Value Loss": 11.590943336486816, "_runtime": 16278.606712579727, "_timestamp": 1585586194.451346, "_step": 441}
{"Episode reward": -94.81470144299877, "Episode length": 999, "Policy Loss": -0.16973745822906494, "Value Loss": 0.0028910785913467407, "_runtime": 16280.19620680809, "_timestamp": 1585586196.0408401, "_step": 442}
{"Episode reward": -95.149924890881, "Episode length": 999, "Policy Loss": -0.16933095455169678, "Value Loss": 0.0029505607672035694, "_runtime": 16281.775579929352, "_timestamp": 1585586197.6202133, "_step": 443}
{"Episode reward": -94.89519353611871, "Episode length": 999, "Policy Loss": -0.16949766874313354, "Value Loss": 0.002950131194666028, "_runtime": 16283.365121126175, "_timestamp": 1585586199.2097545, "_step": 444}
{"Episode reward": -95.5328245825304, "Episode length": 999, "Policy Loss": -0.17060081660747528, "Value Loss": 0.0029766664374619722, "_runtime": 16284.7237906456, "_timestamp": 1585586200.568424, "_step": 445}
{"Episode reward": 18.892732659654243, "Episode length": 851, "Policy Loss": 0.18963298201560974, "Value Loss": 11.740674018859863, "_runtime": 16286.324391365051, "_timestamp": 1585586202.1690247, "_step": 446}
{"Episode reward": -94.85451698346341, "Episode length": 999, "Policy Loss": -0.16800463199615479, "Value Loss": 0.0029418664053082466, "_runtime": 16287.918136358261, "_timestamp": 1585586203.7627697, "_step": 447}
{"Episode reward": -94.62053908793125, "Episode length": 999, "Policy Loss": -0.16580672562122345, "Value Loss": 0.0029308635275810957, "_runtime": 16289.496824741364, "_timestamp": 1585586205.341458, "_step": 448}
{"Episode reward": -95.8356337467542, "Episode length": 999, "Policy Loss": -0.16735224425792694, "Value Loss": 0.002917797537520528, "_runtime": 16291.019012928009, "_timestamp": 1585586206.8636463, "_step": 449}
{"Episode reward": 11.443293018011971, "Episode length": 927, "Policy Loss": 0.12476173788309097, "Value Loss": 10.799110412597656, "_runtime": 16291.801678419113, "_timestamp": 1585586207.6463118, "_step": 450}
{"Episode reward": 55.42064668476347, "Episode length": 477, "Policy Loss": 0.4110695719718933, "Value Loss": 20.943727493286133, "_runtime": 16293.120854616165, "_timestamp": 1585586208.965488, "_step": 451}
{"Episode reward": 21.96227311345305, "Episode length": 824, "Policy Loss": 0.16780120134353638, "Value Loss": 12.123445510864258, "_runtime": 16294.70554113388, "_timestamp": 1585586210.5501745, "_step": 452}
{"Episode reward": -94.29800741481115, "Episode length": 999, "Policy Loss": -0.1615626960992813, "Value Loss": 0.0029051091987639666, "_runtime": 16295.97052359581, "_timestamp": 1585586211.815157, "_step": 453}
{"Episode reward": 22.760927318189303, "Episode length": 821, "Policy Loss": 0.17680522799491882, "Value Loss": 12.163514137268066, "_runtime": 16297.547438621521, "_timestamp": 1585586213.392072, "_step": 454}
{"Episode reward": -95.35938308851314, "Episode length": 999, "Policy Loss": -0.16902078688144684, "Value Loss": 0.003070116275921464, "_runtime": 16299.054778814316, "_timestamp": 1585586214.8994122, "_step": 455}
{"Episode reward": 10.496996495242058, "Episode length": 945, "Policy Loss": 0.1576841175556183, "Value Loss": 10.57066822052002, "_runtime": 16300.616387367249, "_timestamp": 1585586216.4610207, "_step": 456}
{"Episode reward": -94.96374825026501, "Episode length": 999, "Policy Loss": -0.1667238473892212, "Value Loss": 0.003151143668219447, "_runtime": 16302.20650100708, "_timestamp": 1585586218.0511343, "_step": 457}
{"Episode reward": -94.00396801166848, "Episode length": 999, "Policy Loss": -0.1638074666261673, "Value Loss": 0.0031751678325235844, "_runtime": 16303.794523000717, "_timestamp": 1585586219.6391563, "_step": 458}
{"Episode reward": -95.52024112609766, "Episode length": 999, "Policy Loss": -0.16898781061172485, "Value Loss": 0.003218257101252675, "_runtime": 16305.38328242302, "_timestamp": 1585586221.2279158, "_step": 459}
{"Episode reward": -92.58739210610084, "Episode length": 999, "Policy Loss": -0.15839393436908722, "Value Loss": 0.003122895723208785, "_runtime": 16306.974002361298, "_timestamp": 1585586222.8186357, "_step": 460}
{"Episode reward": -94.29725185322594, "Episode length": 999, "Policy Loss": -0.16153444349765778, "Value Loss": 0.0031226896680891514, "_runtime": 16308.576963424683, "_timestamp": 1585586224.4215968, "_step": 461}
{"Episode reward": -94.12670195725828, "Episode length": 999, "Policy Loss": -0.15769335627555847, "Value Loss": 0.00306705548427999, "_runtime": 16309.872211694717, "_timestamp": 1585586225.716845, "_step": 462}
{"Episode reward": 23.065935474331127, "Episode length": 811, "Policy Loss": 0.14627434313297272, "Value Loss": 12.279180526733398, "_runtime": 16311.472569465637, "_timestamp": 1585586227.3172028, "_step": 463}
{"Episode reward": -93.87513936253545, "Episode length": 999, "Policy Loss": -0.15079183876514435, "Value Loss": 0.0030948312487453222, "_runtime": 16313.076919794083, "_timestamp": 1585586228.9215531, "_step": 464}
{"Episode reward": -93.61779463017695, "Episode length": 999, "Policy Loss": -0.14885751903057098, "Value Loss": 0.004945655353367329, "_runtime": 16314.690384149551, "_timestamp": 1585586230.5350175, "_step": 465}
{"Episode reward": -92.73629343833733, "Episode length": 999, "Policy Loss": -0.14266303181648254, "Value Loss": 0.011693711392581463, "_runtime": 16315.215851545334, "_timestamp": 1585586231.060485, "_step": 466}
{"Episode reward": 72.16666963208513, "Episode length": 301, "Policy Loss": 1.2264673709869385, "Value Loss": 32.81186294555664, "_runtime": 16316.129212617874, "_timestamp": 1585586231.973846, "_step": 467}
{"Episode reward": 47.44229345563891, "Episode length": 569, "Policy Loss": 0.4387339651584625, "Value Loss": 17.298675537109375, "_runtime": 16317.476451396942, "_timestamp": 1585586233.3210847, "_step": 468}
{"Episode reward": 20.975163270431565, "Episode length": 851, "Policy Loss": 0.35189202427864075, "Value Loss": 11.616869926452637, "_runtime": 16318.831958532333, "_timestamp": 1585586234.6765919, "_step": 469}
{"Episode reward": 15.697742996268616, "Episode length": 892, "Policy Loss": 0.3802330493927002, "Value Loss": 11.187431335449219, "_runtime": 16320.384214639664, "_timestamp": 1585586236.228848, "_step": 470}
{"Episode reward": -92.4390069763221, "Episode length": 999, "Policy Loss": -0.10967893153429031, "Value Loss": 0.25078094005584717, "_runtime": 16321.960642337799, "_timestamp": 1585586237.8052757, "_step": 471}
{"Episode reward": -93.3706991729147, "Episode length": 999, "Policy Loss": -0.08413328975439072, "Value Loss": 0.35494816303253174, "_runtime": 16322.491943359375, "_timestamp": 1585586238.3365767, "_step": 472}
{"Episode reward": 69.64875069476243, "Episode length": 318, "Policy Loss": 0.7131438255310059, "Value Loss": 30.89510154724121, "_runtime": 16324.064596891403, "_timestamp": 1585586239.9092302, "_step": 473}
{"Episode reward": -94.06205562880291, "Episode length": 999, "Policy Loss": -0.15891042351722717, "Value Loss": 0.025522105395793915, "_runtime": 16325.48227071762, "_timestamp": 1585586241.326904, "_step": 474}
{"Episode reward": 17.02414490552455, "Episode length": 885, "Policy Loss": 0.5460203886032104, "Value Loss": 11.132925033569336, "_runtime": 16327.005793333054, "_timestamp": 1585586242.8504267, "_step": 475}
{"Episode reward": -93.26798456167143, "Episode length": 999, "Policy Loss": -0.18144963681697845, "Value Loss": 0.018390655517578125, "_runtime": 16328.592291116714, "_timestamp": 1585586244.4369245, "_step": 476}
{"Episode reward": -94.10709997599194, "Episode length": 999, "Policy Loss": -0.1878015398979187, "Value Loss": 0.005617731250822544, "_runtime": 16330.181073665619, "_timestamp": 1585586246.025707, "_step": 477}
{"Episode reward": -96.13234096189848, "Episode length": 999, "Policy Loss": -0.20170356333255768, "Value Loss": 0.004760328214615583, "_runtime": 16331.743281841278, "_timestamp": 1585586247.5879152, "_step": 478}
{"Episode reward": -94.44077107337725, "Episode length": 999, "Policy Loss": -0.19804997742176056, "Value Loss": 0.007693744730204344, "_runtime": 16333.338100194931, "_timestamp": 1585586249.1827335, "_step": 479}
{"Episode reward": -94.31251768290257, "Episode length": 999, "Policy Loss": -0.203441321849823, "Value Loss": 0.004186548758298159, "_runtime": 16334.685165405273, "_timestamp": 1585586250.5297987, "_step": 480}
{"Episode reward": 20.469549476529906, "Episode length": 839, "Policy Loss": 0.5087330341339111, "Value Loss": 11.868781089782715, "_runtime": 16335.529472589493, "_timestamp": 1585586251.374106, "_step": 481}
{"Episode reward": 50.834030251521504, "Episode length": 509, "Policy Loss": 0.3971801698207855, "Value Loss": 19.564620971679688, "_runtime": 16337.11404466629, "_timestamp": 1585586252.958678, "_step": 482}
{"Episode reward": -95.66687855699035, "Episode length": 999, "Policy Loss": -0.2200443595647812, "Value Loss": 0.004239068366587162, "_runtime": 16338.21562051773, "_timestamp": 1585586254.0602539, "_step": 483}
{"Episode reward": 35.17845656660347, "Episode length": 674, "Policy Loss": 0.31773656606674194, "Value Loss": 14.736540794372559, "_runtime": 16339.745875597, "_timestamp": 1585586255.590509, "_step": 484}
{"Episode reward": -95.76312970063648, "Episode length": 999, "Policy Loss": -0.23029737174510956, "Value Loss": 0.005723122041672468, "_runtime": 16341.135210752487, "_timestamp": 1585586256.979844, "_step": 485}
{"Episode reward": 15.589062410856357, "Episode length": 879, "Policy Loss": 0.23070675134658813, "Value Loss": 11.247225761413574, "_runtime": 16341.98157954216, "_timestamp": 1585586257.826213, "_step": 486}
{"Episode reward": 47.003849245739936, "Episode length": 545, "Policy Loss": 0.36163896322250366, "Value Loss": 18.126209259033203, "_runtime": 16343.558380365372, "_timestamp": 1585586259.4030137, "_step": 487}
{"Episode reward": -97.46211260985623, "Episode length": 999, "Policy Loss": -0.2530418038368225, "Value Loss": 0.005113916005939245, "_runtime": 16345.14145731926, "_timestamp": 1585586260.9860907, "_step": 488}
{"Episode reward": -96.0418570915963, "Episode length": 999, "Policy Loss": -0.23994562029838562, "Value Loss": 0.11260554194450378, "_runtime": 16346.622094154358, "_timestamp": 1585586262.4667275, "_step": 489}
{"Episode reward": 6.725487613228722, "Episode length": 968, "Policy Loss": 0.22325652837753296, "Value Loss": 10.378706932067871, "_runtime": 16347.844399929047, "_timestamp": 1585586263.6890333, "_step": 490}
{"Episode reward": 23.86616697385587, "Episode length": 785, "Policy Loss": 0.15859150886535645, "Value Loss": 12.49055290222168, "_runtime": 16349.306912183762, "_timestamp": 1585586265.1515455, "_step": 491}
{"Episode reward": 9.322162946744768, "Episode length": 931, "Policy Loss": 0.32023942470550537, "Value Loss": 10.590184211730957, "_runtime": 16350.873004198074, "_timestamp": 1585586266.7176375, "_step": 492}
{"Episode reward": -96.8862163910438, "Episode length": 999, "Policy Loss": -0.2728419899940491, "Value Loss": 0.005138272885233164, "_runtime": 16351.83138012886, "_timestamp": 1585586267.6760135, "_step": 493}
{"Episode reward": 39.85188392878305, "Episode length": 615, "Policy Loss": 0.2747594118118286, "Value Loss": 16.094318389892578, "_runtime": 16353.408026695251, "_timestamp": 1585586269.25266, "_step": 494}
{"Episode reward": -97.52180258471348, "Episode length": 999, "Policy Loss": -0.28637006878852844, "Value Loss": 0.005345989018678665, "_runtime": 16354.980621814728, "_timestamp": 1585586270.8252552, "_step": 495}
{"Episode reward": -97.70068145537563, "Episode length": 999, "Policy Loss": -0.2882314920425415, "Value Loss": 0.005396055523306131, "_runtime": 16356.518678426743, "_timestamp": 1585586272.3633118, "_step": 496}
{"Episode reward": -97.63572997986961, "Episode length": 999, "Policy Loss": -0.29238149523735046, "Value Loss": 0.005398788023740053, "_runtime": 16358.098973989487, "_timestamp": 1585586273.9436073, "_step": 497}
{"Episode reward": -96.9366217773711, "Episode length": 999, "Policy Loss": -0.28788232803344727, "Value Loss": 0.005306164268404245, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375, -8.533050537109375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0], "bins": [-36.498287200927734, -35.79751205444336, -35.09673309326172, -34.395957946777344, -33.69518280029297, -32.99440383911133, -32.29362869262695, -31.592851638793945, -30.892074584960938, -30.19129753112793, -29.490520477294922, -28.789745330810547, -28.08896827697754, -27.38819122314453, -26.687416076660156, -25.98663902282715, -25.28586196899414, -24.585084915161133, -23.884307861328125, -23.18353271484375, -22.482755661010742, -21.781978607177734, -21.08120346069336, -20.38042640686035, -19.679649353027344, -18.978872299194336, -18.278095245361328, -17.577320098876953, -16.876543045043945, -16.175765991210938, -15.474990844726562, -14.774213790893555, -14.073436737060547, -13.372659683227539, -12.671882629394531, -11.971107482910156, -11.270330429077148, -10.56955337524414, -9.868778228759766, -9.168001174926758, -8.46722412109375, -7.766447067260742, -7.065670013427734, -6.364894866943359, -5.664117813110352, -4.963340759277344, -4.262565612792969, -3.561786651611328, -2.861011505126953, -2.160236358642578, -1.4594573974609375, -0.7586822509765625, -0.057903289794921875, 0.6428718566894531, 1.3436470031738281, 2.0444259643554688, 2.7452011108398438, 3.4459762573242188, 4.146755218505859, 4.847530364990234, 5.548305511474609, 6.24908447265625, 6.949859619140625, 7.650638580322266, 8.35141372680664]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 1.0, 1.0], "bins": [-5.42297887802124, -5.3322319984436035, -5.241484642028809, -5.150737762451172, -5.059990882873535, -4.969244003295898, -4.8784966468811035, -4.787749767303467, -4.69700288772583, -4.606256008148193, -4.515508651733398, -4.424761772155762, -4.334014892578125, -4.243268013000488, -4.152520656585693, -4.061773777008057, -3.97102689743042, -3.880279779434204, -3.7895326614379883, -3.6987857818603516, -3.608038902282715, -3.517291784286499, -3.426544666290283, -3.3357977867126465, -3.2450506687164307, -3.154303789138794, -3.063556671142578, -2.9728097915649414, -2.8820626735687256, -2.791315793991089, -2.700568675994873, -2.6098217964172363, -2.5190746784210205, -2.4283275604248047, -2.337580680847168, -2.246833562850952, -2.1560866832733154, -2.0653395652770996, -1.974592685699463, -1.883845567703247, -1.7930986881256104, -1.7023515701293945, -1.6116046905517578, -1.520857572555542, -1.4301106929779053, -1.3393635749816895, -1.2486166954040527, -1.157869815826416, -1.067122459411621, -0.9763755798339844, -0.8856287002563477, -0.7948813438415527, -0.704134464263916, -0.6133875846862793, -0.5226407051086426, -0.43189334869384766, -0.34114646911621094, -0.2503995895385742, -0.1596527099609375, -0.06890535354614258, 0.02184152603149414, 0.11258840560913086, 0.20333528518676758, 0.2940826416015625, 0.3848295211791992]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 2.0, 4.0, 7.0, 5.0, 8.0, 8.0, 6.0, 5.0, 10.0, 5.0, 6.0, 6.0, 5.0, 6.0, 5.0, 11.0, 117.0, 113.0, 44.0, 6.0, 2.0, 2.0, 5.0, 5.0, 5.0, 6.0, 4.0, 6.0, 9.0, 7.0, 3.0, 8.0, 4.0, 7.0, 6.0, 5.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0], "bins": [-4.545459270477295, -4.426596641540527, -4.30773401260376, -4.188871383666992, -4.070009231567383, -3.951146364212036, -3.8322839736938477, -3.71342134475708, -3.5945587158203125, -3.475696086883545, -3.3568334579467773, -3.237971067428589, -3.1191084384918213, -3.0002458095550537, -2.8813834190368652, -2.7625207901000977, -2.64365816116333, -2.5247955322265625, -2.405932903289795, -2.2870705127716064, -2.168207883834839, -2.0493452548980713, -1.9304828643798828, -1.8116202354431152, -1.6927576065063477, -1.57389497756958, -1.4550323486328125, -1.336169958114624, -1.2173073291778564, -1.0984447002410889, -0.9795823097229004, -0.8607196807861328, -0.7418570518493652, -0.6229944229125977, -0.5041317939758301, -0.3852691650390625, -0.2664065361022949, -0.14754438400268555, -0.02868175506591797, 0.09018087387084961, 0.2090435028076172, 0.32790613174438477, 0.44676876068115234, 0.5656313896179199, 0.6844935417175293, 0.8033561706542969, 0.9222187995910645, 1.041081428527832, 1.1599440574645996, 1.2788066864013672, 1.3976693153381348, 1.5165319442749023, 1.63539457321167, 1.7542567253112793, 1.8731193542480469, 1.9919819831848145, 2.110844612121582, 2.2297072410583496, 2.348569869995117, 2.4674324989318848, 2.586294651031494, 2.7051572799682617, 2.8240199089050293, 2.942882537841797, 3.0617451667785645]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0], "bins": [-9.533734321594238, -9.313477516174316, -9.093221664428711, -8.872964859008789, -8.652709007263184, -8.432452201843262, -8.212196350097656, -7.991940021514893, -7.771683692932129, -7.551427364349365, -7.331171035766602, -7.11091423034668, -6.890658378601074, -6.670401573181152, -6.450145721435547, -6.229888916015625, -6.0096330642700195, -5.789376258850098, -5.569120407104492, -5.34886360168457, -5.128607273101807, -4.908350944519043, -4.688094615936279, -4.467838287353516, -4.247581958770752, -4.027325630187988, -3.8070693016052246, -3.586812973022461, -3.3665566444396973, -3.1463003158569336, -2.92604398727417, -2.7057876586914062, -2.4855313301086426, -2.265275001525879, -2.0450186729431152, -1.8247623443603516, -1.604506015777588, -1.3842496871948242, -1.1639928817749023, -0.9437370300292969, -0.723480224609375, -0.5032243728637695, -0.28296756744384766, -0.06271171569824219, 0.1575450897216797, 0.37780094146728516, 0.598057746887207, 0.8183135986328125, 1.0385704040527344, 1.2588262557983398, 1.4790830612182617, 1.6993389129638672, 1.919595718383789, 2.1398515701293945, 2.3601083755493164, 2.580364227294922, 2.8006210327148438, 3.020876884460449, 3.241133689880371, 3.4613895416259766, 3.6816463470458984, 3.901902198791504, 4.122159004211426, 4.342414855957031, 4.562671661376953]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 25.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.159122943878174, -2.054152727127075, -1.949182391166687, -1.8442120552062988, -1.7392418384552002, -1.6342716217041016, -1.5293012857437134, -1.4243309497833252, -1.3193607330322266, -1.214390516281128, -1.1094201803207397, -1.0044498443603516, -0.8994796276092529, -0.7945094108581543, -0.6895390748977661, -0.5845687389373779, -0.4795985221862793, -0.37462830543518066, -0.2696579694747925, -0.1646876335144043, -0.059717416763305664, 0.04525279998779297, 0.1502232551574707, 0.25519347190856934, 0.36016368865966797, 0.4651339054107666, 0.5701041221618652, 0.675074577331543, 0.7800447940826416, 0.8850150108337402, 0.989985466003418, 1.0949556827545166, 1.1999258995056152, 1.3048961162567139, 1.4098663330078125, 1.5148367881774902, 1.6198070049285889, 1.7247772216796875, 1.8297476768493652, 1.9347176551818848, 2.0396881103515625, 2.1446585655212402, 2.2496285438537598, 2.3545989990234375, 2.4595694541931152, 2.5645394325256348, 2.6695098876953125, 2.774479866027832, 2.8794503211975098, 2.9844207763671875, 3.089390754699707, 3.1943612098693848, 3.2993311882019043, 3.404301643371582, 3.5092720985412598, 3.6142420768737793, 3.719212532043457, 3.8241829872131348, 3.9291529655456543, 4.034123420715332, 4.13909387588501, 4.244063854217529, 4.349034309387207, 4.454004287719727, 4.558974742889404]}, "_runtime": 16358.999609708786, "_timestamp": 1585586274.844243, "_step": 498}
{"Episode reward": 45.75929289320944, "Episode length": 560, "Policy Loss": 0.4404684603214264, "Value Loss": 17.479583740234375, "_runtime": 16358.999609708786, "_timestamp": 1585586274.844243, "_step": 499}
