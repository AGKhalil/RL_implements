{"Episode reward": 88.2035723387994, "Episode length": 206, "Policy Loss": 0.3715585768222809, "Value Loss": 49.75457000732422, "_runtime": 17109.810701608658, "_timestamp": 1585587025.655335, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.190047264099121, "Value Loss": 4.931853294372559, "_runtime": 17111.335256576538, "_timestamp": 1585587027.17989, "_step": 1}
{"Episode reward": -96.98819064067918, "Episode length": 999, "Policy Loss": 13.541629791259766, "Value Loss": 3286.03662109375, "_runtime": 17111.553248405457, "_timestamp": 1585587027.3978817, "_step": 2}
{"Episode reward": 87.93420369905743, "Episode length": 126, "Policy Loss": 24.243715286254883, "Value Loss": 80042.4765625, "_runtime": 17113.145369052887, "_timestamp": 1585587028.9900024, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.242378234863281, "Value Loss": 1512.49658203125, "_runtime": 17114.731458425522, "_timestamp": 1585587030.5760918, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.566106796264648, "Value Loss": 3492.173583984375, "_runtime": 17116.276957273483, "_timestamp": 1585587032.1215906, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 25.40802764892578, "Value Loss": 176.55618286132812, "_runtime": 17117.886938095093, "_timestamp": 1585587033.7315714, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 44.60093688964844, "Value Loss": 9746.0634765625, "_runtime": 17119.47643637657, "_timestamp": 1585587035.3210697, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 35.29517364501953, "Value Loss": 3478.43115234375, "_runtime": 17121.038345336914, "_timestamp": 1585587036.8829787, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 50.708614349365234, "Value Loss": 22736.416015625, "_runtime": 17122.701323986053, "_timestamp": 1585587038.5459573, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 172.15771484375, "Value Loss": 11589.5771484375, "_runtime": 17124.270212173462, "_timestamp": 1585587040.1148455, "_step": 10}
{"Episode reward": -82.92336882101766, "Episode length": 999, "Policy Loss": -1.368801474571228, "Value Loss": 382.2373352050781, "_runtime": 17124.4974796772, "_timestamp": 1585587040.342113, "_step": 11}
{"Episode reward": 89.6422680033749, "Episode length": 110, "Policy Loss": -105.68138885498047, "Value Loss": 30028.25390625, "_runtime": 17124.686666965485, "_timestamp": 1585587040.5313003, "_step": 12}
{"Episode reward": 92.58786086363781, "Episode length": 77, "Policy Loss": 1427.328125, "Value Loss": 141628.03125, "_runtime": 17124.96617770195, "_timestamp": 1585587040.810811, "_step": 13}
{"Episode reward": 85.22681993243754, "Episode length": 148, "Policy Loss": -613.4747314453125, "Value Loss": 22553.28125, "_runtime": 17125.10193991661, "_timestamp": 1585587040.9465733, "_step": 14}
{"Episode reward": 91.76510471127355, "Episode length": 85, "Policy Loss": -979.2286987304688, "Value Loss": 39468.4296875, "_runtime": 17126.6211874485, "_timestamp": 1585587042.4658208, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -18.973039627075195, "Value Loss": 197.48748779296875, "_runtime": 17128.132027626038, "_timestamp": 1585587043.976661, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.576478958129883, "Value Loss": 1114.556884765625, "_runtime": 17129.64076900482, "_timestamp": 1585587045.4854023, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.24363899230957, "Value Loss": 1447.0294189453125, "_runtime": 17131.2147231102, "_timestamp": 1585587047.0593565, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.838953971862793, "Value Loss": 1691.7432861328125, "_runtime": 17132.77575325966, "_timestamp": 1585587048.6203866, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.52173900604248, "Value Loss": 4233.6962890625, "_runtime": 17134.323887586594, "_timestamp": 1585587050.168521, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.679072380065918, "Value Loss": 1794.4720458984375, "_runtime": 17135.906324625015, "_timestamp": 1585587051.750958, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.678935050964355, "Value Loss": 2675.910400390625, "_runtime": 17137.480891942978, "_timestamp": 1585587053.3255253, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.347596168518066, "Value Loss": 703.2634887695312, "_runtime": 17139.0401597023, "_timestamp": 1585587054.884793, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.197986602783203, "Value Loss": 946.6361083984375, "_runtime": 17140.64943575859, "_timestamp": 1585587056.494069, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.921048641204834, "Value Loss": 202.00624084472656, "_runtime": 17142.231880664825, "_timestamp": 1585587058.076514, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.185861110687256, "Value Loss": 193.86903381347656, "_runtime": 17143.815351486206, "_timestamp": 1585587059.6599848, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8978462219238281, "Value Loss": 124.86107635498047, "_runtime": 17145.410670042038, "_timestamp": 1585587061.2553034, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.396043300628662, "Value Loss": 529.9557495117188, "_runtime": 17147.03483772278, "_timestamp": 1585587062.879471, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005199245177209377, "Value Loss": 118.85025024414062, "_runtime": 17148.621519804, "_timestamp": 1585587064.4661531, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0250595808029175, "Value Loss": 62.29609298706055, "_runtime": 17150.216797590256, "_timestamp": 1585587066.061431, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.895567774772644, "Value Loss": 2.797823429107666, "_runtime": 17151.81477212906, "_timestamp": 1585587067.6594055, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8326051235198975, "Value Loss": 5.333001613616943, "_runtime": 17153.407636404037, "_timestamp": 1585587069.2522697, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.592618942260742, "Value Loss": 241.8717041015625, "_runtime": 17155.007986545563, "_timestamp": 1585587070.85262, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.8995718955993652, "Value Loss": 10.562102317810059, "_runtime": 17156.607450723648, "_timestamp": 1585587072.452084, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.440588474273682, "Value Loss": 106.26620483398438, "_runtime": 17158.20895409584, "_timestamp": 1585587074.0535874, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.684757232666016, "Value Loss": 30.47203254699707, "_runtime": 17159.801582574844, "_timestamp": 1585587075.646216, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.064258575439453, "Value Loss": 34.97433090209961, "_runtime": 17161.382188796997, "_timestamp": 1585587077.2268221, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.251197338104248, "Value Loss": 49.94929885864258, "_runtime": 17162.957166194916, "_timestamp": 1585587078.8017995, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.459763526916504, "Value Loss": 2.457146406173706, "_runtime": 17164.54168510437, "_timestamp": 1585587080.3863184, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.295939922332764, "Value Loss": 65.44670104980469, "_runtime": 17166.121154546738, "_timestamp": 1585587081.965788, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.7581868171691895, "Value Loss": 8.631753921508789, "_runtime": 17167.70631670952, "_timestamp": 1585587083.55095, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.963284492492676, "Value Loss": 48.65053176879883, "_runtime": 17169.301170110703, "_timestamp": 1585587085.1458035, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.065232753753662, "Value Loss": 300.7215576171875, "_runtime": 17170.9235329628, "_timestamp": 1585587086.7681663, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.052120208740234, "Value Loss": 250.2720489501953, "_runtime": 17172.50070953369, "_timestamp": 1585587088.3453429, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.835156440734863, "Value Loss": 46.745635986328125, "_runtime": 17174.098093748093, "_timestamp": 1585587089.942727, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.618505477905273, "Value Loss": 2.5040431022644043, "_runtime": 17175.679851055145, "_timestamp": 1585587091.5244844, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.338693141937256, "Value Loss": 38.201847076416016, "_runtime": 17177.255871772766, "_timestamp": 1585587093.100505, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.094714164733887, "Value Loss": 24.97283172607422, "_runtime": 17178.85062479973, "_timestamp": 1585587094.6952581, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.156701564788818, "Value Loss": 39.982276916503906, "_runtime": 17180.431084394455, "_timestamp": 1585587096.2757177, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.003550052642822, "Value Loss": 36.0685920715332, "_runtime": 17182.016264915466, "_timestamp": 1585587097.8608983, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.77058744430542, "Value Loss": 94.24882507324219, "_runtime": 17183.60017323494, "_timestamp": 1585587099.4448066, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.522035598754883, "Value Loss": 51.422428131103516, "_runtime": 17185.183888673782, "_timestamp": 1585587101.028522, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.3931660652160645, "Value Loss": 3.8701155185699463, "_runtime": 17186.762024879456, "_timestamp": 1585587102.6066582, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.145223617553711, "Value Loss": 3.8997414112091064, "_runtime": 17188.345820903778, "_timestamp": 1585587104.1904542, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.9127004146575928, "Value Loss": 47.63909149169922, "_runtime": 17189.92712211609, "_timestamp": 1585587105.7717555, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.717921733856201, "Value Loss": 34.57078170776367, "_runtime": 17191.516996383667, "_timestamp": 1585587107.3616297, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3955142498016357, "Value Loss": 8.077425956726074, "_runtime": 17193.14044213295, "_timestamp": 1585587108.9850755, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.251344919204712, "Value Loss": 1.7634148597717285, "_runtime": 17194.723567724228, "_timestamp": 1585587110.568201, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0240559577941895, "Value Loss": 0.5491144061088562, "_runtime": 17196.31172299385, "_timestamp": 1585587112.1563563, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8253204822540283, "Value Loss": 0.09702564775943756, "_runtime": 17197.906299829483, "_timestamp": 1585587113.7509332, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.640064001083374, "Value Loss": 0.42925673723220825, "_runtime": 17199.497851133347, "_timestamp": 1585587115.3424845, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4794962406158447, "Value Loss": 1.0271462202072144, "_runtime": 17201.086808681488, "_timestamp": 1585587116.931442, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3311238288879395, "Value Loss": 2.192086696624756, "_runtime": 17202.682687997818, "_timestamp": 1585587118.5273213, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.229705810546875, "Value Loss": 8.296749114990234, "_runtime": 17204.28771018982, "_timestamp": 1585587120.1323435, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0975701808929443, "Value Loss": 4.472193717956543, "_runtime": 17205.877452611923, "_timestamp": 1585587121.722086, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0746853351593018, "Value Loss": 7.125779628753662, "_runtime": 17207.473127365112, "_timestamp": 1585587123.3177607, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.014571189880371, "Value Loss": 8.706344604492188, "_runtime": 17209.075981140137, "_timestamp": 1585587124.9206145, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9850729703903198, "Value Loss": 7.486194610595703, "_runtime": 17210.68823480606, "_timestamp": 1585587126.5328681, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9180912971496582, "Value Loss": 2.0525169372558594, "_runtime": 17212.306284189224, "_timestamp": 1585587128.1509175, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9082860946655273, "Value Loss": 3.7667343616485596, "_runtime": 17213.92169547081, "_timestamp": 1585587129.7663288, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9261361360549927, "Value Loss": 0.6435317993164062, "_runtime": 17215.5354115963, "_timestamp": 1585587131.380045, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.935541033744812, "Value Loss": 4.328484058380127, "_runtime": 17217.182733297348, "_timestamp": 1585587133.0273666, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9115750789642334, "Value Loss": 1.8590306043624878, "_runtime": 17218.78804397583, "_timestamp": 1585587134.6326773, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9106968641281128, "Value Loss": 2.944920063018799, "_runtime": 17220.399528741837, "_timestamp": 1585587136.244162, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.914993405342102, "Value Loss": 11.476377487182617, "_runtime": 17222.01805281639, "_timestamp": 1585587137.8626862, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9131191968917847, "Value Loss": 6.3291335105896, "_runtime": 17223.626044750214, "_timestamp": 1585587139.470678, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9496216773986816, "Value Loss": 5.925476551055908, "_runtime": 17225.227115869522, "_timestamp": 1585587141.0717492, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.006779193878174, "Value Loss": 1.095449686050415, "_runtime": 17226.8433303833, "_timestamp": 1585587142.6879637, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.047267198562622, "Value Loss": 1.15566086769104, "_runtime": 17228.448970079422, "_timestamp": 1585587144.2936034, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.089280843734741, "Value Loss": 0.6134974956512451, "_runtime": 17230.051055192947, "_timestamp": 1585587145.8956885, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1333606243133545, "Value Loss": 1.1979880332946777, "_runtime": 17231.659086704254, "_timestamp": 1585587147.50372, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1647913455963135, "Value Loss": 1.0073214769363403, "_runtime": 17233.26261663437, "_timestamp": 1585587149.10725, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.206256628036499, "Value Loss": 0.553859531879425, "_runtime": 17234.87712264061, "_timestamp": 1585587150.721756, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2298054695129395, "Value Loss": 0.6002482771873474, "_runtime": 17236.482224702835, "_timestamp": 1585587152.326858, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2566158771514893, "Value Loss": 0.7125807404518127, "_runtime": 17238.086353063583, "_timestamp": 1585587153.9309864, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3021788597106934, "Value Loss": 1.5107601881027222, "_runtime": 17239.698255300522, "_timestamp": 1585587155.5428886, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.333028554916382, "Value Loss": 0.13847720623016357, "_runtime": 17241.356979370117, "_timestamp": 1585587157.2016127, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.362781286239624, "Value Loss": 0.05300033465027809, "_runtime": 17242.962438821793, "_timestamp": 1585587158.8070722, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3893513679504395, "Value Loss": 0.10491233319044113, "_runtime": 17244.573786258698, "_timestamp": 1585587160.4184196, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4173381328582764, "Value Loss": 0.1533471643924713, "_runtime": 17246.191390752792, "_timestamp": 1585587162.036024, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.441171884536743, "Value Loss": 0.06236613541841507, "_runtime": 17247.798193216324, "_timestamp": 1585587163.6428266, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4610610008239746, "Value Loss": 0.055532634258270264, "_runtime": 17249.40953874588, "_timestamp": 1585587165.254172, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4764604568481445, "Value Loss": 0.14281539618968964, "_runtime": 17251.027606248856, "_timestamp": 1585587166.8722396, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.491654396057129, "Value Loss": 0.06001494824886322, "_runtime": 17252.641501903534, "_timestamp": 1585587168.4861352, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.506112813949585, "Value Loss": 0.06721410900354385, "_runtime": 17254.244404792786, "_timestamp": 1585587170.0890381, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5106635093688965, "Value Loss": 0.09430022537708282, "_runtime": 17255.863137960434, "_timestamp": 1585587171.7077713, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5142982006073, "Value Loss": 0.4468241035938263, "_runtime": 17257.466908931732, "_timestamp": 1585587173.3115423, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.515432834625244, "Value Loss": 0.1089315265417099, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17259.07075858116, "_timestamp": 1585587174.915392, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.528785467147827, "Value Loss": 0.3060566186904907, "_runtime": 17260.6865234375, "_timestamp": 1585587176.5311568, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.519418239593506, "Value Loss": 0.1893204003572464, "_runtime": 17262.287106990814, "_timestamp": 1585587178.1317403, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5034146308898926, "Value Loss": 0.2760142982006073, "_runtime": 17263.898713827133, "_timestamp": 1585587179.7433472, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5084352493286133, "Value Loss": 0.09540791064500809, "_runtime": 17265.557808876038, "_timestamp": 1585587181.4024422, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.495551586151123, "Value Loss": 0.15278583765029907, "_runtime": 17267.15806245804, "_timestamp": 1585587183.0026958, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4884514808654785, "Value Loss": 0.2215615212917328, "_runtime": 17268.760705709457, "_timestamp": 1585587184.605339, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4761111736297607, "Value Loss": 0.21738745272159576, "_runtime": 17270.3760638237, "_timestamp": 1585587186.2206972, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4554693698883057, "Value Loss": 0.24553894996643066, "_runtime": 17271.97861790657, "_timestamp": 1585587187.8232512, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.444758653640747, "Value Loss": 0.08261231333017349, "_runtime": 17273.588019371033, "_timestamp": 1585587189.4326527, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4260456562042236, "Value Loss": 0.9033552408218384, "_runtime": 17275.204164981842, "_timestamp": 1585587191.0487983, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.413743019104004, "Value Loss": 0.16327250003814697, "_runtime": 17276.806854486465, "_timestamp": 1585587192.6514878, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3936052322387695, "Value Loss": 0.4307820498943329, "_runtime": 17278.418487548828, "_timestamp": 1585587194.263121, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.373298406600952, "Value Loss": 0.14331236481666565, "_runtime": 17280.03258705139, "_timestamp": 1585587195.8772204, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3500561714172363, "Value Loss": 0.12521028518676758, "_runtime": 17281.64758181572, "_timestamp": 1585587197.4922152, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3301053047180176, "Value Loss": 0.20539186894893646, "_runtime": 17283.24737381935, "_timestamp": 1585587199.0920072, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3044917583465576, "Value Loss": 0.24891436100006104, "_runtime": 17284.86426973343, "_timestamp": 1585587200.708903, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2752749919891357, "Value Loss": 0.04696866124868393, "_runtime": 17286.467923402786, "_timestamp": 1585587202.3125567, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2503838539123535, "Value Loss": 0.06275952607393265, "_runtime": 17288.080023527145, "_timestamp": 1585587203.9246569, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2252695560455322, "Value Loss": 0.044576648622751236, "_runtime": 17289.733433008194, "_timestamp": 1585587205.5780663, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2000622749328613, "Value Loss": 0.05411207303404808, "_runtime": 17291.33856368065, "_timestamp": 1585587207.183197, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1793625354766846, "Value Loss": 0.04236369580030441, "_runtime": 17292.92875480652, "_timestamp": 1585587208.7733881, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1577510833740234, "Value Loss": 0.04155009984970093, "_runtime": 17294.542880296707, "_timestamp": 1585587210.3875136, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1368846893310547, "Value Loss": 0.041178274899721146, "_runtime": 17296.144742250443, "_timestamp": 1585587211.9893756, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1172730922698975, "Value Loss": 0.047259312123060226, "_runtime": 17297.75644350052, "_timestamp": 1585587213.6010768, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.098942518234253, "Value Loss": 0.04273643717169762, "_runtime": 17299.36019039154, "_timestamp": 1585587215.2048237, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0815229415893555, "Value Loss": 0.058822743594646454, "_runtime": 17300.974990606308, "_timestamp": 1585587216.819624, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.069498062133789, "Value Loss": 0.1792103499174118, "_runtime": 17302.585797786713, "_timestamp": 1585587218.4304311, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.051328182220459, "Value Loss": 0.04652797058224678, "_runtime": 17304.202769756317, "_timestamp": 1585587220.047403, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0382707118988037, "Value Loss": 0.07488302141427994, "_runtime": 17305.81713938713, "_timestamp": 1585587221.6617727, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0284759998321533, "Value Loss": 0.04528694599866867, "_runtime": 17307.417101621628, "_timestamp": 1585587223.261735, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.015662908554077, "Value Loss": 0.05503105744719505, "_runtime": 17309.02140522003, "_timestamp": 1585587224.8660386, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0058250427246094, "Value Loss": 0.03657401353120804, "_runtime": 17310.623705148697, "_timestamp": 1585587226.4683385, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9958585500717163, "Value Loss": 0.09168738126754761, "_runtime": 17312.262440681458, "_timestamp": 1585587228.107074, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.988660454750061, "Value Loss": 0.07590777426958084, "_runtime": 17313.864589452744, "_timestamp": 1585587229.7092228, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.980936050415039, "Value Loss": 0.04548903554677963, "_runtime": 17315.458339691162, "_timestamp": 1585587231.302973, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9718438386917114, "Value Loss": 0.05663642659783363, "_runtime": 17317.072224855423, "_timestamp": 1585587232.9168582, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9664011001586914, "Value Loss": 0.03473955765366554, "_runtime": 17318.67578101158, "_timestamp": 1585587234.5204144, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9594732522964478, "Value Loss": 0.0378192700445652, "_runtime": 17320.292741775513, "_timestamp": 1585587236.137375, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9521914720535278, "Value Loss": 0.04148291051387787, "_runtime": 17321.89587378502, "_timestamp": 1585587237.7405071, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9458210468292236, "Value Loss": 0.036990970373153687, "_runtime": 17323.497454881668, "_timestamp": 1585587239.3420882, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9398446083068848, "Value Loss": 0.034454096108675, "_runtime": 17325.101987838745, "_timestamp": 1585587240.9466212, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9323731660842896, "Value Loss": 0.036345224827528, "_runtime": 17326.70436644554, "_timestamp": 1585587242.5489998, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9249722957611084, "Value Loss": 0.04538744315505028, "_runtime": 17328.3193962574, "_timestamp": 1585587244.1640296, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.918656587600708, "Value Loss": 0.03281835466623306, "_runtime": 17329.93408226967, "_timestamp": 1585587245.7787156, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9098148345947266, "Value Loss": 0.03900295868515968, "_runtime": 17331.534685134888, "_timestamp": 1585587247.3793185, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9032961130142212, "Value Loss": 0.03227914497256279, "_runtime": 17333.149438619614, "_timestamp": 1585587248.994072, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8950214385986328, "Value Loss": 0.03254525363445282, "_runtime": 17334.763808250427, "_timestamp": 1585587250.6084416, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8866864442825317, "Value Loss": 0.03174610063433647, "_runtime": 17336.412291288376, "_timestamp": 1585587252.2569246, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8780524730682373, "Value Loss": 0.03197472169995308, "_runtime": 17338.018399953842, "_timestamp": 1585587253.8630333, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.869106411933899, "Value Loss": 0.03185975179076195, "_runtime": 17339.620954990387, "_timestamp": 1585587255.4655883, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8579057455062866, "Value Loss": 0.05703636631369591, "_runtime": 17341.221482992172, "_timestamp": 1585587257.0661163, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8499436378479004, "Value Loss": 0.03553983196616173, "_runtime": 17342.827018499374, "_timestamp": 1585587258.6716518, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.839617371559143, "Value Loss": 0.03151079639792442, "_runtime": 17344.42190504074, "_timestamp": 1585587260.2665384, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8267087936401367, "Value Loss": 0.044023219496011734, "_runtime": 17346.023244857788, "_timestamp": 1585587261.8678782, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.816174864768982, "Value Loss": 0.03076316975057125, "_runtime": 17347.64244246483, "_timestamp": 1585587263.4870758, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8058346509933472, "Value Loss": 0.029700912535190582, "_runtime": 17349.257358312607, "_timestamp": 1585587265.1019917, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7956972122192383, "Value Loss": 0.028890999034047127, "_runtime": 17350.858102083206, "_timestamp": 1585587266.7027354, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.784958004951477, "Value Loss": 0.028608551248908043, "_runtime": 17352.46247124672, "_timestamp": 1585587268.3071046, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7741345167160034, "Value Loss": 0.029041187837719917, "_runtime": 17354.06832075119, "_timestamp": 1585587269.912954, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7625962495803833, "Value Loss": 0.027826132252812386, "_runtime": 17355.668711662292, "_timestamp": 1585587271.513345, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7515783309936523, "Value Loss": 0.02755044773221016, "_runtime": 17357.274627923965, "_timestamp": 1585587273.1192613, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7399213314056396, "Value Loss": 0.045776091516017914, "_runtime": 17358.87874007225, "_timestamp": 1585587274.7233734, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.727828860282898, "Value Loss": 0.04117560759186745, "_runtime": 17360.518661260605, "_timestamp": 1585587276.3632946, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7182120084762573, "Value Loss": 0.026334889233112335, "_runtime": 17362.12388062477, "_timestamp": 1585587277.968514, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7071831226348877, "Value Loss": 0.025972139090299606, "_runtime": 17363.727090358734, "_timestamp": 1585587279.5717237, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6962363719940186, "Value Loss": 0.025639213621616364, "_runtime": 17365.336865901947, "_timestamp": 1585587281.1814992, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.684213399887085, "Value Loss": 0.03398184850811958, "_runtime": 17366.952384710312, "_timestamp": 1585587282.797018, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6745980978012085, "Value Loss": 0.02498994581401348, "_runtime": 17368.56446814537, "_timestamp": 1585587284.4091015, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6639072895050049, "Value Loss": 0.024683089926838875, "_runtime": 17370.163676977158, "_timestamp": 1585587286.0083103, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6532719135284424, "Value Loss": 0.024368995800614357, "_runtime": 17371.775798797607, "_timestamp": 1585587287.6204321, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6429147720336914, "Value Loss": 0.024151945486664772, "_runtime": 17373.390689849854, "_timestamp": 1585587289.2353232, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.632361888885498, "Value Loss": 0.02375953458249569, "_runtime": 17375.003128767014, "_timestamp": 1585587290.847762, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6219722032546997, "Value Loss": 0.02354244701564312, "_runtime": 17376.61553812027, "_timestamp": 1585587292.4601715, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6117974519729614, "Value Loss": 0.023173285648226738, "_runtime": 17378.218340158463, "_timestamp": 1585587294.0629735, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6015582084655762, "Value Loss": 0.02332288585603237, "_runtime": 17379.816747426987, "_timestamp": 1585587295.6613808, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5917633771896362, "Value Loss": 0.022590817883610725, "_runtime": 17381.42780160904, "_timestamp": 1585587297.272435, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5817813873291016, "Value Loss": 0.022310175001621246, "_runtime": 17383.041534423828, "_timestamp": 1585587298.8861678, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5718353986740112, "Value Loss": 0.022104056552052498, "_runtime": 17384.692714214325, "_timestamp": 1585587300.5373476, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5621522665023804, "Value Loss": 0.021890589967370033, "_runtime": 17386.306483507156, "_timestamp": 1585587302.1511168, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.552150011062622, "Value Loss": 0.021817633882164955, "_runtime": 17387.92071223259, "_timestamp": 1585587303.7653456, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.542709231376648, "Value Loss": 0.021213224157691002, "_runtime": 17389.519092321396, "_timestamp": 1585587305.3637257, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5329774618148804, "Value Loss": 0.02111630141735077, "_runtime": 17391.122979402542, "_timestamp": 1585587306.9676127, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5237784385681152, "Value Loss": 0.021181579679250717, "_runtime": 17392.738639831543, "_timestamp": 1585587308.5832732, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5142357349395752, "Value Loss": 0.02043987438082695, "_runtime": 17394.334398031235, "_timestamp": 1585587310.1790314, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5047307014465332, "Value Loss": 0.02030898816883564, "_runtime": 17395.93789577484, "_timestamp": 1585587311.782529, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4954931735992432, "Value Loss": 0.020514531061053276, "_runtime": 17397.540942430496, "_timestamp": 1585587313.3855758, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4863002300262451, "Value Loss": 0.01983410120010376, "_runtime": 17399.138867139816, "_timestamp": 1585587314.9835005, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4773986339569092, "Value Loss": 0.019554153084754944, "_runtime": 17400.743221521378, "_timestamp": 1585587316.5878549, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.468371868133545, "Value Loss": 0.01926925778388977, "_runtime": 17402.342691898346, "_timestamp": 1585587318.1873252, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4593828916549683, "Value Loss": 0.019401848316192627, "_runtime": 17403.94190478325, "_timestamp": 1585587319.7865381, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4504029750823975, "Value Loss": 0.018813634291291237, "_runtime": 17405.551475048065, "_timestamp": 1585587321.3961084, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4414986371994019, "Value Loss": 0.01863594725728035, "_runtime": 17407.191506385803, "_timestamp": 1585587323.0361397, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.431936264038086, "Value Loss": 0.024738986045122147, "_runtime": 17408.78045940399, "_timestamp": 1585587324.6250927, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4232186079025269, "Value Loss": 0.03086988627910614, "_runtime": 17410.360463380814, "_timestamp": 1585587326.2050967, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4154384136199951, "Value Loss": 0.017861148342490196, "_runtime": 17411.97412586212, "_timestamp": 1585587327.8187592, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4067254066467285, "Value Loss": 0.017637308686971664, "_runtime": 17413.57296562195, "_timestamp": 1585587329.417599, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3980141878128052, "Value Loss": 0.017415009438991547, "_runtime": 17415.18506169319, "_timestamp": 1585587331.029695, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3892366886138916, "Value Loss": 0.01719648949801922, "_runtime": 17416.790271520615, "_timestamp": 1585587332.6349049, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3804577589035034, "Value Loss": 0.01697964407503605, "_runtime": 17418.40081524849, "_timestamp": 1585587334.2454486, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3716524839401245, "Value Loss": 0.01676398515701294, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17420.00297522545, "_timestamp": 1585587335.8476086, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3628439903259277, "Value Loss": 0.016553962603211403, "_runtime": 17421.6047039032, "_timestamp": 1585587337.4493372, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3539836406707764, "Value Loss": 0.01633465476334095, "_runtime": 17423.20645713806, "_timestamp": 1585587339.0510905, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3451212644577026, "Value Loss": 0.016121825203299522, "_runtime": 17424.80958199501, "_timestamp": 1585587340.6542153, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.336238980293274, "Value Loss": 0.015916995704174042, "_runtime": 17426.39853787422, "_timestamp": 1585587342.2431712, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3265718221664429, "Value Loss": 0.016583068296313286, "_runtime": 17427.998203277588, "_timestamp": 1585587343.8428366, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3186092376708984, "Value Loss": 0.015495494939386845, "_runtime": 17429.59996819496, "_timestamp": 1585587345.4446015, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3097766637802124, "Value Loss": 0.015288359485566616, "_runtime": 17431.24107837677, "_timestamp": 1585587347.0857117, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3009672164916992, "Value Loss": 0.015081937424838543, "_runtime": 17432.850801229477, "_timestamp": 1585587348.6954346, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2921874523162842, "Value Loss": 0.014878475107252598, "_runtime": 17434.46284222603, "_timestamp": 1585587350.3074756, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2833936214447021, "Value Loss": 0.014677814207971096, "_runtime": 17436.065376758575, "_timestamp": 1585587351.91001, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2745959758758545, "Value Loss": 0.014476961456239223, "_runtime": 17437.6774456501, "_timestamp": 1585587353.522079, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2654904127120972, "Value Loss": 0.01443341001868248, "_runtime": 17439.280616998672, "_timestamp": 1585587355.1252503, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.257131576538086, "Value Loss": 0.01408167090266943, "_runtime": 17440.883975744247, "_timestamp": 1585587356.728609, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2484477758407593, "Value Loss": 0.013887523673474789, "_runtime": 17442.47222495079, "_timestamp": 1585587358.3168583, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2397737503051758, "Value Loss": 0.013695194385945797, "_runtime": 17444.076889038086, "_timestamp": 1585587359.9215224, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2311291694641113, "Value Loss": 0.01350507140159607, "_runtime": 17445.69105029106, "_timestamp": 1585587361.5356836, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2225158214569092, "Value Loss": 0.013316663913428783, "_runtime": 17447.291240930557, "_timestamp": 1585587363.1358743, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2139434814453125, "Value Loss": 0.013134888373315334, "_runtime": 17448.902401208878, "_timestamp": 1585587364.7470345, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2053810358047485, "Value Loss": 0.012945947237312794, "_runtime": 17450.50720357895, "_timestamp": 1585587366.351837, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1968656778335571, "Value Loss": 0.012780611403286457, "_runtime": 17452.108021497726, "_timestamp": 1585587367.9526548, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1876447200775146, "Value Loss": 0.014857500791549683, "_runtime": 17453.70975112915, "_timestamp": 1585587369.5543845, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1800816059112549, "Value Loss": 0.01241413876414299, "_runtime": 17455.352522611618, "_timestamp": 1585587371.197156, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.171766996383667, "Value Loss": 0.012236978858709335, "_runtime": 17456.954643011093, "_timestamp": 1585587372.7992764, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1634728908538818, "Value Loss": 0.012064225971698761, "_runtime": 17458.55640244484, "_timestamp": 1585587374.4010358, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.155179500579834, "Value Loss": 0.011900453828275204, "_runtime": 17460.169080734253, "_timestamp": 1585587376.013714, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1469826698303223, "Value Loss": 0.01172707974910736, "_runtime": 17461.757259845734, "_timestamp": 1585587377.6018932, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1379863023757935, "Value Loss": 0.014871480874717236, "_runtime": 17463.368899822235, "_timestamp": 1585587379.2135332, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1298637390136719, "Value Loss": 0.015209351666271687, "_runtime": 17464.98194503784, "_timestamp": 1585587380.8265784, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1226400136947632, "Value Loss": 0.011244621127843857, "_runtime": 17466.57348871231, "_timestamp": 1585587382.418122, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1147706508636475, "Value Loss": 0.011080042459070683, "_runtime": 17468.18036866188, "_timestamp": 1585587384.025002, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1067618131637573, "Value Loss": 0.010926413349807262, "_runtime": 17469.78466963768, "_timestamp": 1585587385.629303, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0988224744796753, "Value Loss": 0.010783413425087929, "_runtime": 17471.385657548904, "_timestamp": 1585587387.230291, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.091005563735962, "Value Loss": 0.010617120191454887, "_runtime": 17472.990220308304, "_timestamp": 1585587388.8348536, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0825010538101196, "Value Loss": 0.0118351299315691, "_runtime": 17474.59731411934, "_timestamp": 1585587390.4419475, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0754824876785278, "Value Loss": 0.010309846140444279, "_runtime": 17476.19860434532, "_timestamp": 1585587392.0432377, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0676566362380981, "Value Loss": 0.010225405916571617, "_runtime": 17477.799223184586, "_timestamp": 1585587393.6438565, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0600812435150146, "Value Loss": 0.010013188235461712, "_runtime": 17479.442404985428, "_timestamp": 1585587395.2870383, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0524100065231323, "Value Loss": 0.00987583864480257, "_runtime": 17481.05309319496, "_timestamp": 1585587396.8977265, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0448259115219116, "Value Loss": 0.00973212718963623, "_runtime": 17482.66585469246, "_timestamp": 1585587398.510488, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.036405324935913, "Value Loss": 0.011828577145934105, "_runtime": 17484.27875328064, "_timestamp": 1585587400.1233866, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0296134948730469, "Value Loss": 0.009458922781050205, "_runtime": 17485.879284143448, "_timestamp": 1585587401.7239175, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0221757888793945, "Value Loss": 0.009311292320489883, "_runtime": 17487.472037553787, "_timestamp": 1585587403.316671, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0146633386611938, "Value Loss": 0.009182685054838657, "_runtime": 17489.08757996559, "_timestamp": 1585587404.9322133, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0072660446166992, "Value Loss": 0.009043270722031593, "_runtime": 17490.676480293274, "_timestamp": 1585587406.5211136, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9998442530632019, "Value Loss": 0.008910776115953922, "_runtime": 17492.279196739197, "_timestamp": 1585587408.12383, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9924554228782654, "Value Loss": 0.008780115284025669, "_runtime": 17493.878603219986, "_timestamp": 1585587409.7232366, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9851115345954895, "Value Loss": 0.008656436577439308, "_runtime": 17495.47988462448, "_timestamp": 1585587411.324518, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9777904152870178, "Value Loss": 0.008519978262484074, "_runtime": 17497.092688322067, "_timestamp": 1585587412.9373217, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9704834818840027, "Value Loss": 0.008395619690418243, "_runtime": 17498.706163167953, "_timestamp": 1585587414.5507965, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9632367491722107, "Value Loss": 0.00826751533895731, "_runtime": 17500.316777467728, "_timestamp": 1585587416.1614108, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9559767842292786, "Value Loss": 0.00814569741487503, "_runtime": 17501.931362867355, "_timestamp": 1585587417.7759962, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9487513303756714, "Value Loss": 0.008036420680582523, "_runtime": 17503.585297346115, "_timestamp": 1585587419.4299307, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9408765435218811, "Value Loss": 0.009423874318599701, "_runtime": 17505.195063829422, "_timestamp": 1585587421.0396972, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9345242977142334, "Value Loss": 0.007784923072904348, "_runtime": 17506.797332763672, "_timestamp": 1585587422.641966, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.927498459815979, "Value Loss": 0.007667382247745991, "_runtime": 17508.400046110153, "_timestamp": 1585587424.2446795, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9204619526863098, "Value Loss": 0.00755205936729908, "_runtime": 17509.998794078827, "_timestamp": 1585587425.8434274, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9134767055511475, "Value Loss": 0.007435766980051994, "_runtime": 17511.61180496216, "_timestamp": 1585587427.4564383, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9064651727676392, "Value Loss": 0.007333472371101379, "_runtime": 17513.221709489822, "_timestamp": 1585587429.0663428, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8995608687400818, "Value Loss": 0.007215650286525488, "_runtime": 17514.834058523178, "_timestamp": 1585587430.6786919, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8926922678947449, "Value Loss": 0.007107729557901621, "_runtime": 17516.436304092407, "_timestamp": 1585587432.2809374, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8856889605522156, "Value Loss": 0.007058286108076572, "_runtime": 17518.04897069931, "_timestamp": 1585587433.893604, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8783397078514099, "Value Loss": 0.008080142550170422, "_runtime": 17519.66025686264, "_timestamp": 1585587435.5048902, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8723242282867432, "Value Loss": 0.006780337542295456, "_runtime": 17521.262504339218, "_timestamp": 1585587437.1071377, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8648744225502014, "Value Loss": 0.0081634521484375, "_runtime": 17522.8521733284, "_timestamp": 1585587438.6968067, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8589779734611511, "Value Loss": 0.006574803963303566, "_runtime": 17524.462841272354, "_timestamp": 1585587440.3074746, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8523262739181519, "Value Loss": 0.006473430432379246, "_runtime": 17526.104644298553, "_timestamp": 1585587441.9492776, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.845716655254364, "Value Loss": 0.006373065058141947, "_runtime": 17527.715500593185, "_timestamp": 1585587443.560134, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8391044735908508, "Value Loss": 0.006274512503296137, "_runtime": 17529.328647613525, "_timestamp": 1585587445.173281, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8325313329696655, "Value Loss": 0.00617756973952055, "_runtime": 17530.93115377426, "_timestamp": 1585587446.775787, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8259938955307007, "Value Loss": 0.006081071216613054, "_runtime": 17532.542412042618, "_timestamp": 1585587448.3870454, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8194919228553772, "Value Loss": 0.005986142437905073, "_runtime": 17534.15309405327, "_timestamp": 1585587449.9977274, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8130008578300476, "Value Loss": 0.005891379434615374, "_runtime": 17535.766965150833, "_timestamp": 1585587451.6115985, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8066220283508301, "Value Loss": 0.005797454621642828, "_runtime": 17537.377939224243, "_timestamp": 1585587453.2225726, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8002083897590637, "Value Loss": 0.005705761257559061, "_runtime": 17538.96901011467, "_timestamp": 1585587454.8136435, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7938249707221985, "Value Loss": 0.00561539176851511, "_runtime": 17540.559943675995, "_timestamp": 1585587456.404577, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7874805331230164, "Value Loss": 0.005526131484657526, "_runtime": 17542.14961862564, "_timestamp": 1585587457.994252, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7811570167541504, "Value Loss": 0.005437218118458986, "_runtime": 17543.748105049133, "_timestamp": 1585587459.5927384, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7748472690582275, "Value Loss": 0.005350963212549686, "_runtime": 17545.34241962433, "_timestamp": 1585587461.187053, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7678545713424683, "Value Loss": 0.02150425687432289, "_runtime": 17546.936128616333, "_timestamp": 1585587462.780762, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7623752951622009, "Value Loss": 0.005180723965167999, "_runtime": 17548.5256152153, "_timestamp": 1585587464.3702486, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7562339901924133, "Value Loss": 0.005095745902508497, "_runtime": 17550.153334617615, "_timestamp": 1585587465.997968, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7501088976860046, "Value Loss": 0.0050138020887970924, "_runtime": 17551.747114896774, "_timestamp": 1585587467.5917482, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7439761757850647, "Value Loss": 0.00493224710226059, "_runtime": 17553.33923792839, "_timestamp": 1585587469.1838713, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7379001975059509, "Value Loss": 0.00485169468447566, "_runtime": 17554.9196767807, "_timestamp": 1585587470.7643101, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7318437099456787, "Value Loss": 0.004775643814355135, "_runtime": 17556.511594057083, "_timestamp": 1585587472.3562274, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7258385419845581, "Value Loss": 0.004695272073149681, "_runtime": 17558.112936735153, "_timestamp": 1585587473.95757, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.719789445400238, "Value Loss": 0.004626618232578039, "_runtime": 17559.70553135872, "_timestamp": 1585587475.5501647, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7138761281967163, "Value Loss": 0.004550778307020664, "_runtime": 17561.29852771759, "_timestamp": 1585587477.143161, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7080124020576477, "Value Loss": 0.004467903636395931, "_runtime": 17562.886605262756, "_timestamp": 1585587478.7312386, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7021201252937317, "Value Loss": 0.0043949345126748085, "_runtime": 17564.480112075806, "_timestamp": 1585587480.3247454, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6962999701499939, "Value Loss": 0.004328118171542883, "_runtime": 17566.07254767418, "_timestamp": 1585587481.917181, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6898153424263, "Value Loss": 0.016585053876042366, "_runtime": 17567.661073446274, "_timestamp": 1585587483.5057068, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6847946643829346, "Value Loss": 0.004203633405268192, "_runtime": 17569.261255025864, "_timestamp": 1585587485.1058884, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6792288422584534, "Value Loss": 0.004117968492209911, "_runtime": 17570.842973947525, "_timestamp": 1585587486.6876073, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.673615574836731, "Value Loss": 0.004055551718920469, "_runtime": 17572.440670251846, "_timestamp": 1585587488.2853036, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6681516766548157, "Value Loss": 0.00398001354187727, "_runtime": 17574.069538354874, "_timestamp": 1585587489.9141717, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6620004773139954, "Value Loss": 0.004655646160244942, "_runtime": 17575.6747341156, "_timestamp": 1585587491.5193675, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6565335988998413, "Value Loss": 0.005015991162508726, "_runtime": 17577.272510766983, "_timestamp": 1585587493.117144, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6518423557281494, "Value Loss": 0.003788341535255313, "_runtime": 17578.86248254776, "_timestamp": 1585587494.707116, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6465247273445129, "Value Loss": 0.0037251876201480627, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17580.46491575241, "_timestamp": 1585587496.309549, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6412061452865601, "Value Loss": 0.003664023708552122, "_runtime": 17582.063867092133, "_timestamp": 1585587497.9085004, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6351907849311829, "Value Loss": 0.005214620381593704, "_runtime": 17583.65338230133, "_timestamp": 1585587499.4980156, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6306489706039429, "Value Loss": 0.003543990897014737, "_runtime": 17585.254469156265, "_timestamp": 1585587501.0991025, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6254209876060486, "Value Loss": 0.003485221415758133, "_runtime": 17586.84267258644, "_timestamp": 1585587502.687306, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6202024221420288, "Value Loss": 0.0034272687043994665, "_runtime": 17588.444752693176, "_timestamp": 1585587504.289386, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6149960160255432, "Value Loss": 0.003370030550286174, "_runtime": 17590.045737981796, "_timestamp": 1585587505.8903713, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6097927093505859, "Value Loss": 0.003313210094347596, "_runtime": 17591.647898197174, "_timestamp": 1585587507.4925315, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.604613184928894, "Value Loss": 0.0032572061754763126, "_runtime": 17593.233196496964, "_timestamp": 1585587509.0778298, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5994508266448975, "Value Loss": 0.0032020227517932653, "_runtime": 17594.81237387657, "_timestamp": 1585587510.6570072, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5943013429641724, "Value Loss": 0.0031471126712858677, "_runtime": 17596.398893594742, "_timestamp": 1585587512.243527, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5884285569190979, "Value Loss": 0.005155233666300774, "_runtime": 17598.029276371002, "_timestamp": 1585587513.8739097, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5840839743614197, "Value Loss": 0.0030397141817957163, "_runtime": 17599.62167930603, "_timestamp": 1585587515.4663126, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5782961249351501, "Value Loss": 0.005320118274539709, "_runtime": 17601.208456993103, "_timestamp": 1585587517.0530903, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5740140080451965, "Value Loss": 0.0029357988387346268, "_runtime": 17602.78612971306, "_timestamp": 1585587518.630763, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5690239667892456, "Value Loss": 0.0028849795926362276, "_runtime": 17604.374512910843, "_timestamp": 1585587520.2191463, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5640565156936646, "Value Loss": 0.0028348283376544714, "_runtime": 17605.949692964554, "_timestamp": 1585587521.7943263, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5591145157814026, "Value Loss": 0.0027853893116116524, "_runtime": 17607.530451774597, "_timestamp": 1585587523.375085, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5541982054710388, "Value Loss": 0.0027366955764591694, "_runtime": 17609.111283779144, "_timestamp": 1585587524.9559171, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5486545562744141, "Value Loss": 0.003779532155022025, "_runtime": 17610.688485622406, "_timestamp": 1585587526.533119, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5444740653038025, "Value Loss": 0.0026418128982186317, "_runtime": 17612.268349170685, "_timestamp": 1585587528.1129825, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.539677619934082, "Value Loss": 0.0025952148716896772, "_runtime": 17613.84396290779, "_timestamp": 1585587529.6885962, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5348982214927673, "Value Loss": 0.002550102537497878, "_runtime": 17615.422990083694, "_timestamp": 1585587531.2676234, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.529468834400177, "Value Loss": 0.004498743452131748, "_runtime": 17617.011857509613, "_timestamp": 1585587532.8564909, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5254653692245483, "Value Loss": 0.002462159376591444, "_runtime": 17618.599987268448, "_timestamp": 1585587534.4446206, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5208261013031006, "Value Loss": 0.0024220971390604973, "_runtime": 17620.239907741547, "_timestamp": 1585587536.084541, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5162513852119446, "Value Loss": 0.0023756176233291626, "_runtime": 17621.830565929413, "_timestamp": 1585587537.6751993, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5116770267486572, "Value Loss": 0.002335230354219675, "_runtime": 17623.42077088356, "_timestamp": 1585587539.2654042, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5065779089927673, "Value Loss": 0.002923124236986041, "_runtime": 17625.010129213333, "_timestamp": 1585587540.8547626, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5027177929878235, "Value Loss": 0.002253626473248005, "_runtime": 17626.611216783524, "_timestamp": 1585587542.4558501, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49830514192581177, "Value Loss": 0.002213485538959503, "_runtime": 17628.19953942299, "_timestamp": 1585587544.0441728, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49392786622047424, "Value Loss": 0.0021741294767707586, "_runtime": 17629.798899888992, "_timestamp": 1585587545.6435332, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.48955193161964417, "Value Loss": 0.0021355089265853167, "_runtime": 17631.39954519272, "_timestamp": 1585587547.2441785, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.48492467403411865, "Value Loss": 0.002215195447206497, "_runtime": 17633.00206565857, "_timestamp": 1585587548.846699, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4809049665927887, "Value Loss": 0.002060628728941083, "_runtime": 17634.588750600815, "_timestamp": 1585587550.433384, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.476618230342865, "Value Loss": 0.0020240626763552427, "_runtime": 17636.17810678482, "_timestamp": 1585587552.0227401, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.47233954071998596, "Value Loss": 0.0019880568142980337, "_runtime": 17637.768668413162, "_timestamp": 1585587553.6133018, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.46808111667633057, "Value Loss": 0.001952197402715683, "_runtime": 17639.360701084137, "_timestamp": 1585587555.2053344, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4638369679450989, "Value Loss": 0.0019169643055647612, "_runtime": 17640.951438188553, "_timestamp": 1585587556.7960715, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.45961323380470276, "Value Loss": 0.0018822075799107552, "_runtime": 17642.54578113556, "_timestamp": 1585587558.3904145, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.45540735125541687, "Value Loss": 0.0018479119753465056, "_runtime": 17644.174620628357, "_timestamp": 1585587560.019254, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4505370557308197, "Value Loss": 0.0036608981899917126, "_runtime": 17645.776961565018, "_timestamp": 1585587561.621595, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4470980763435364, "Value Loss": 0.0017810945864766836, "_runtime": 17647.378676891327, "_timestamp": 1585587563.2233102, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44299250841140747, "Value Loss": 0.001748564071021974, "_runtime": 17648.969381570816, "_timestamp": 1585587564.814015, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4389040768146515, "Value Loss": 0.0017165134195238352, "_runtime": 17650.572016477585, "_timestamp": 1585587566.4166498, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.43484240770339966, "Value Loss": 0.001685233204625547, "_runtime": 17652.15161037445, "_timestamp": 1585587567.9962437, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4308156669139862, "Value Loss": 0.0016544577665627003, "_runtime": 17653.741599321365, "_timestamp": 1585587569.5862327, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4268288314342499, "Value Loss": 0.0016239093383774161, "_runtime": 17655.332695961, "_timestamp": 1585587571.1773293, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4228574335575104, "Value Loss": 0.0015934286639094353, "_runtime": 17656.933640241623, "_timestamp": 1585587572.7782736, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41892209649086, "Value Loss": 0.0015649314736947417, "_runtime": 17658.522869586945, "_timestamp": 1585587574.367503, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41501545906066895, "Value Loss": 0.0015348504530265927, "_runtime": 17660.125242471695, "_timestamp": 1585587575.9698758, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41111963987350464, "Value Loss": 0.0015066770138218999, "_runtime": 17661.727154493332, "_timestamp": 1585587577.5717878, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4070699214935303, "Value Loss": 0.001554542570374906, "_runtime": 17663.32787013054, "_timestamp": 1585587579.1725035, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4034649431705475, "Value Loss": 0.001450477633625269, "_runtime": 17664.918105363846, "_timestamp": 1585587580.7627387, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39968401193618774, "Value Loss": 0.0014237212017178535, "_runtime": 17666.520833730698, "_timestamp": 1585587582.365467, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39527544379234314, "Value Loss": 0.002884508343413472, "_runtime": 17668.158472776413, "_timestamp": 1585587584.003106, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3922346830368042, "Value Loss": 0.0013708454789593816, "_runtime": 17669.761058807373, "_timestamp": 1585587585.6056921, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3879104554653168, "Value Loss": 0.005567904096096754, "_runtime": 17671.352890968323, "_timestamp": 1585587587.1975243, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3849617838859558, "Value Loss": 0.0013226758455857635, "_runtime": 17672.94328022003, "_timestamp": 1585587588.7879136, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3813686966896057, "Value Loss": 0.0012961712200194597, "_runtime": 17674.534044742584, "_timestamp": 1585587590.378678, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37780648469924927, "Value Loss": 0.001272032386623323, "_runtime": 17676.136949777603, "_timestamp": 1585587591.981583, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37363094091415405, "Value Loss": 0.0037797698751091957, "_runtime": 17677.715985059738, "_timestamp": 1585587593.5606184, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3707672953605652, "Value Loss": 0.0012250608997419477, "_runtime": 17679.30692410469, "_timestamp": 1585587595.1515574, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3672808110713959, "Value Loss": 0.0012022509472444654, "_runtime": 17680.910466194153, "_timestamp": 1585587596.7550995, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3638220429420471, "Value Loss": 0.001179484068416059, "_runtime": 17682.500457286835, "_timestamp": 1585587598.3450906, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.36037328839302063, "Value Loss": 0.0011571692302823067, "_runtime": 17684.091572999954, "_timestamp": 1585587599.9362063, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3569158613681793, "Value Loss": 0.0011355278547853231, "_runtime": 17685.694535970688, "_timestamp": 1585587601.5391693, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.353542685508728, "Value Loss": 0.0011137393303215504, "_runtime": 17687.29460644722, "_timestamp": 1585587603.1392398, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3501538634300232, "Value Loss": 0.0010925822425633669, "_runtime": 17688.89296579361, "_timestamp": 1585587604.7375991, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3461572825908661, "Value Loss": 0.0025096142198890448, "_runtime": 17690.49205851555, "_timestamp": 1585587606.3366919, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.34347835183143616, "Value Loss": 0.0010512885637581348, "_runtime": 17692.132226228714, "_timestamp": 1585587607.9768596, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.34018903970718384, "Value Loss": 0.0010311994701623917, "_runtime": 17693.73234820366, "_timestamp": 1585587609.5769815, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.336914598941803, "Value Loss": 0.0010114387841895223, "_runtime": 17695.324407100677, "_timestamp": 1585587611.1690404, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33362770080566406, "Value Loss": 0.01010381244122982, "_runtime": 17696.9224960804, "_timestamp": 1585587612.7671294, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3304845094680786, "Value Loss": 0.0009731657337397337, "_runtime": 17698.514969348907, "_timestamp": 1585587614.3596027, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3267345428466797, "Value Loss": 0.0017249395605176687, "_runtime": 17700.106625795364, "_timestamp": 1585587615.9512591, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3242107033729553, "Value Loss": 0.0009365673176944256, "_runtime": 17701.6973528862, "_timestamp": 1585587617.5419862, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32111239433288574, "Value Loss": 0.0009188387775793672, "_runtime": 17703.277259349823, "_timestamp": 1585587619.1218927, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3180168867111206, "Value Loss": 0.0009011866059154272, "_runtime": 17704.870913743973, "_timestamp": 1585587620.715547, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3149572014808655, "Value Loss": 0.011622332967817783, "_runtime": 17706.46935582161, "_timestamp": 1585587622.3139892, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3119255006313324, "Value Loss": 0.0008672791300341487, "_runtime": 17708.049709796906, "_timestamp": 1585587623.8943431, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3089258074760437, "Value Loss": 0.0008507327875122428, "_runtime": 17709.650736808777, "_timestamp": 1585587625.4953701, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30523747205734253, "Value Loss": 0.0032769162207841873, "_runtime": 17711.238196134567, "_timestamp": 1585587627.0828295, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30291837453842163, "Value Loss": 0.0008219974115490913, "_runtime": 17712.838250398636, "_timestamp": 1585587628.6828837, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29994168877601624, "Value Loss": 0.0008022029069252312, "_runtime": 17714.438445091248, "_timestamp": 1585587630.2830784, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29695525765419006, "Value Loss": 0.0007858160533942282, "_runtime": 17716.068692445755, "_timestamp": 1585587631.9133258, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2937204837799072, "Value Loss": 0.005442983005195856, "_runtime": 17717.66123342514, "_timestamp": 1585587633.5058668, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29102668166160583, "Value Loss": 0.000756805413402617, "_runtime": 17719.25218153, "_timestamp": 1585587635.0968149, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2881339192390442, "Value Loss": 0.0007398209418170154, "_runtime": 17720.841646432877, "_timestamp": 1585587636.6862798, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2852323651313782, "Value Loss": 0.0007251781644299626, "_runtime": 17722.44322490692, "_timestamp": 1585587638.2878582, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2823330760002136, "Value Loss": 0.0007104065152816474, "_runtime": 17724.043165683746, "_timestamp": 1585587639.887799, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2794528603553772, "Value Loss": 0.000695824041031301, "_runtime": 17725.644081115723, "_timestamp": 1585587641.4887145, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27659398317337036, "Value Loss": 0.0006817071116529405, "_runtime": 17727.234835147858, "_timestamp": 1585587643.0794685, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2737625539302826, "Value Loss": 0.000667913060169667, "_runtime": 17728.82470703125, "_timestamp": 1585587644.6693404, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2709601819515228, "Value Loss": 0.000654280767776072, "_runtime": 17730.413279294968, "_timestamp": 1585587646.2579126, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26817217469215393, "Value Loss": 0.0006411331123672426, "_runtime": 17732.016158103943, "_timestamp": 1585587647.8607914, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2648709714412689, "Value Loss": 0.0014694674173370004, "_runtime": 17733.604863405228, "_timestamp": 1585587649.4494967, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2627463936805725, "Value Loss": 0.0006155311712063849, "_runtime": 17735.194370746613, "_timestamp": 1585587651.039004, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25945156812667847, "Value Loss": 0.005610035266727209, "_runtime": 17736.798005104065, "_timestamp": 1585587652.6426384, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2574581801891327, "Value Loss": 0.0005911847692914307, "_runtime": 17738.427728176117, "_timestamp": 1585587654.2723615, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2548573911190033, "Value Loss": 0.0005794918979518116, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17740.01599264145, "_timestamp": 1585587655.860626, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2522861063480377, "Value Loss": 0.000568054208997637, "_runtime": 17741.616533041, "_timestamp": 1585587657.4611664, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24974976480007172, "Value Loss": 0.0005557781551033258, "_runtime": 17743.20834350586, "_timestamp": 1585587659.0529768, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24722008407115936, "Value Loss": 0.0005448000156320632, "_runtime": 17744.81216621399, "_timestamp": 1585587660.6567996, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2446923851966858, "Value Loss": 0.0005350009305402637, "_runtime": 17746.40224504471, "_timestamp": 1585587662.2468784, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24221433699131012, "Value Loss": 0.0005238511366769671, "_runtime": 17748.00226187706, "_timestamp": 1585587663.8468952, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23972941935062408, "Value Loss": 0.0005136916879564524, "_runtime": 17749.60020494461, "_timestamp": 1585587665.4448383, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23734287917613983, "Value Loss": 0.0005019695963710546, "_runtime": 17751.20071196556, "_timestamp": 1585587667.0453453, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23443758487701416, "Value Loss": 0.0008982760482467711, "_runtime": 17752.801641225815, "_timestamp": 1585587668.6462746, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23258399963378906, "Value Loss": 0.0004819954338017851, "_runtime": 17754.390774965286, "_timestamp": 1585587670.2354083, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23024824261665344, "Value Loss": 0.0004723611637018621, "_runtime": 17755.99430704117, "_timestamp": 1585587671.8389404, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22792035341262817, "Value Loss": 0.0004628581809811294, "_runtime": 17757.609393119812, "_timestamp": 1585587673.4540265, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22560423612594604, "Value Loss": 0.0004535056941676885, "_runtime": 17759.207231283188, "_timestamp": 1585587675.0518646, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22329775989055634, "Value Loss": 0.00044430478010326624, "_runtime": 17760.784577846527, "_timestamp": 1585587676.6292112, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22099769115447998, "Value Loss": 0.0004351796815171838, "_runtime": 17762.399957180023, "_timestamp": 1585587678.2445905, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2187168151140213, "Value Loss": 0.000426334619987756, "_runtime": 17763.986364603043, "_timestamp": 1585587679.830998, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21644265949726105, "Value Loss": 0.0004176086513325572, "_runtime": 17765.563341617584, "_timestamp": 1585587681.407975, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.214174285531044, "Value Loss": 0.0004088134446647018, "_runtime": 17767.14075255394, "_timestamp": 1585587682.985386, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21191781759262085, "Value Loss": 0.00040016905404627323, "_runtime": 17768.71727871895, "_timestamp": 1585587684.561912, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20967628061771393, "Value Loss": 0.00039173057302832603, "_runtime": 17770.300813674927, "_timestamp": 1585587686.145447, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2073715329170227, "Value Loss": 0.00038978655356913805, "_runtime": 17771.87943339348, "_timestamp": 1585587687.7240667, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20524586737155914, "Value Loss": 0.0003753472410608083, "_runtime": 17773.465399503708, "_timestamp": 1585587689.3100328, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20305953919887543, "Value Loss": 0.00036741685471497476, "_runtime": 17775.043203353882, "_timestamp": 1585587690.8878367, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20089122653007507, "Value Loss": 0.0003595989546738565, "_runtime": 17776.622040510178, "_timestamp": 1585587692.4666739, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19873911142349243, "Value Loss": 0.00035203967127017677, "_runtime": 17778.196122407913, "_timestamp": 1585587694.0407557, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19660791754722595, "Value Loss": 0.00034447835059836507, "_runtime": 17779.78732585907, "_timestamp": 1585587695.6319592, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19449162483215332, "Value Loss": 0.00033730961149558425, "_runtime": 17781.377997159958, "_timestamp": 1585587697.2226305, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19239820539951324, "Value Loss": 0.0003301725082565099, "_runtime": 17782.980487585068, "_timestamp": 1585587698.825121, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19032816588878632, "Value Loss": 0.0003243788378313184, "_runtime": 17784.569100379944, "_timestamp": 1585587700.4137337, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18828922510147095, "Value Loss": 0.0003159256011713296, "_runtime": 17786.20990395546, "_timestamp": 1585587702.0545373, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18626759946346283, "Value Loss": 0.0003092290717177093, "_runtime": 17787.814126968384, "_timestamp": 1585587703.6587603, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1842583566904068, "Value Loss": 0.00030494696693494916, "_runtime": 17789.41352033615, "_timestamp": 1585587705.2581537, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18227888643741608, "Value Loss": 0.00029778131283819675, "_runtime": 17791.01575756073, "_timestamp": 1585587706.860391, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18036267161369324, "Value Loss": 0.0002899927494581789, "_runtime": 17792.613317012787, "_timestamp": 1585587708.4579504, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1784256100654602, "Value Loss": 0.0002842661051545292, "_runtime": 17794.201597929, "_timestamp": 1585587710.0462313, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1765243411064148, "Value Loss": 0.0002776763867586851, "_runtime": 17795.783645153046, "_timestamp": 1585587711.6282785, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17463073134422302, "Value Loss": 0.0002722400822676718, "_runtime": 17797.38236451149, "_timestamp": 1585587713.2269979, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1727626472711563, "Value Loss": 0.00026614920352585614, "_runtime": 17798.9884121418, "_timestamp": 1585587714.8330455, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17089469730854034, "Value Loss": 0.0002604014880489558, "_runtime": 17800.579703569412, "_timestamp": 1585587716.424337, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16904674470424652, "Value Loss": 0.0002547524345573038, "_runtime": 17802.168748378754, "_timestamp": 1585587718.0133817, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1672128587961197, "Value Loss": 0.00024920288706198335, "_runtime": 17803.771692037582, "_timestamp": 1585587719.6163254, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1653890162706375, "Value Loss": 0.0002443533740006387, "_runtime": 17805.373346567154, "_timestamp": 1585587721.21798, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16358964145183563, "Value Loss": 0.00023847997363191098, "_runtime": 17806.976009845734, "_timestamp": 1585587722.8206432, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16180773079395294, "Value Loss": 0.0002335405588382855, "_runtime": 17808.56304335594, "_timestamp": 1585587724.4076767, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16001926362514496, "Value Loss": 0.00023035334015730768, "_runtime": 17810.204194307327, "_timestamp": 1585587726.0488276, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15828756988048553, "Value Loss": 0.00022527558030560613, "_runtime": 17811.79230737686, "_timestamp": 1585587727.6369407, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15658804774284363, "Value Loss": 0.00021849872427992523, "_runtime": 17813.38256764412, "_timestamp": 1585587729.227201, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15429462492465973, "Value Loss": 0.006947764195501804, "_runtime": 17814.981970071793, "_timestamp": 1585587730.8266034, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15324638783931732, "Value Loss": 0.0002093070070259273, "_runtime": 17816.57568860054, "_timestamp": 1585587732.420322, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1516050100326538, "Value Loss": 0.00020482296531554312, "_runtime": 17818.167063713074, "_timestamp": 1585587734.011697, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14997322857379913, "Value Loss": 0.00020044963457621634, "_runtime": 17819.757601737976, "_timestamp": 1585587735.602235, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14834122359752655, "Value Loss": 0.00019642748520709574, "_runtime": 17821.357046604156, "_timestamp": 1585587737.20168, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1466863453388214, "Value Loss": 0.00019507456454448402, "_runtime": 17822.957196474075, "_timestamp": 1585587738.8018298, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14515356719493866, "Value Loss": 0.00018774229101836681, "_runtime": 17824.5439453125, "_timestamp": 1585587740.3885787, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14357219636440277, "Value Loss": 0.0001836716110119596, "_runtime": 17826.142466306686, "_timestamp": 1585587741.9870996, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14200013875961304, "Value Loss": 0.0001796774595277384, "_runtime": 17827.73170733452, "_timestamp": 1585587743.5763407, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14043952524662018, "Value Loss": 0.0001757478603394702, "_runtime": 17829.32410311699, "_timestamp": 1585587745.1687365, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13888706266880035, "Value Loss": 0.0001719002757454291, "_runtime": 17830.911986112595, "_timestamp": 1585587746.7566195, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13687193393707275, "Value Loss": 0.0005551886861212552, "_runtime": 17832.54007267952, "_timestamp": 1585587748.384706, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13588230311870575, "Value Loss": 0.0001645223965169862, "_runtime": 17834.12738275528, "_timestamp": 1585587749.972016, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1344153732061386, "Value Loss": 0.00016103152302093804, "_runtime": 17835.72575545311, "_timestamp": 1585587751.5703888, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13294869661331177, "Value Loss": 0.00015752569015603513, "_runtime": 17837.31714987755, "_timestamp": 1585587753.1617832, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13149335980415344, "Value Loss": 0.00015415831876453012, "_runtime": 17838.908024787903, "_timestamp": 1585587754.7526581, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13004063069820404, "Value Loss": 0.00015080260345712304, "_runtime": 17840.49570798874, "_timestamp": 1585587756.3403413, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12859246134757996, "Value Loss": 0.0001478654594393447, "_runtime": 17842.09726500511, "_timestamp": 1585587757.9418983, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1271396428346634, "Value Loss": 0.0001440308114979416, "_runtime": 17843.697370290756, "_timestamp": 1585587759.5420036, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1257031410932541, "Value Loss": 0.0001408423704560846, "_runtime": 17845.29549717903, "_timestamp": 1585587761.1401305, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12364593893289566, "Value Loss": 0.0031254782807081938, "_runtime": 17846.896690130234, "_timestamp": 1585587762.7413235, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1228673979640007, "Value Loss": 0.00013478874461725354, "_runtime": 17848.48982357979, "_timestamp": 1585587764.334457, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1214686706662178, "Value Loss": 0.00013150412996765226, "_runtime": 17850.081519126892, "_timestamp": 1585587765.9261525, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12007976323366165, "Value Loss": 0.0001285212201764807, "_runtime": 17851.669592142105, "_timestamp": 1585587767.5142255, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11869864165782928, "Value Loss": 0.000125562961329706, "_runtime": 17853.271322011948, "_timestamp": 1585587769.1159554, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11732904613018036, "Value Loss": 0.00012271699961274862, "_runtime": 17854.86185526848, "_timestamp": 1585587770.7064886, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11596713960170746, "Value Loss": 0.00011982633441220969, "_runtime": 17856.492374181747, "_timestamp": 1585587772.3370075, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11461421102285385, "Value Loss": 0.00011705445649567991, "_runtime": 17858.0854306221, "_timestamp": 1585587773.930064, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11327989399433136, "Value Loss": 0.00011435178748797625, "_runtime": 17859.67867898941, "_timestamp": 1585587775.5233123, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11195580661296844, "Value Loss": 0.0001117803985835053, "_runtime": 17861.273468732834, "_timestamp": 1585587777.118102, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11065669357776642, "Value Loss": 0.00010922324872808531, "_runtime": 17862.86138153076, "_timestamp": 1585587778.7060149, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10936012119054794, "Value Loss": 0.00010679670958779752, "_runtime": 17864.464683532715, "_timestamp": 1585587780.3093169, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10808418691158295, "Value Loss": 0.0001046550678438507, "_runtime": 17866.068276405334, "_timestamp": 1585587781.9129097, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10684311389923096, "Value Loss": 0.00010183887206949294, "_runtime": 17867.649971961975, "_timestamp": 1585587783.4946053, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10515543818473816, "Value Loss": 0.0004505471733864397, "_runtime": 17869.240767002106, "_timestamp": 1585587785.0854003, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10445202142000198, "Value Loss": 9.722079266794026e-05, "_runtime": 17870.841851234436, "_timestamp": 1585587786.6864846, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10329580307006836, "Value Loss": 9.508371294941753e-05, "_runtime": 17872.444861650467, "_timestamp": 1585587788.289495, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1021474152803421, "Value Loss": 9.297283395426348e-05, "_runtime": 17874.045588970184, "_timestamp": 1585587789.8902223, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10100127011537552, "Value Loss": 9.089434752240777e-05, "_runtime": 17875.638016462326, "_timestamp": 1585587791.4826498, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09986210614442825, "Value Loss": 8.888927550287917e-05, "_runtime": 17877.23957324028, "_timestamp": 1585587793.0842066, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09872277081012726, "Value Loss": 8.705002983333543e-05, "_runtime": 17878.839070796967, "_timestamp": 1585587794.6837041, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0975877121090889, "Value Loss": 8.49751231726259e-05, "_runtime": 17880.48119354248, "_timestamp": 1585587796.325827, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0964503213763237, "Value Loss": 8.295864245155826e-05, "_runtime": 17882.083196163177, "_timestamp": 1585587797.9278295, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09531542658805847, "Value Loss": 8.14075829111971e-05, "_runtime": 17883.672013044357, "_timestamp": 1585587799.5166464, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09418846666812897, "Value Loss": 7.907743565738201e-05, "_runtime": 17885.271612882614, "_timestamp": 1585587801.1162462, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09306568652391434, "Value Loss": 7.719246787019074e-05, "_runtime": 17886.874626398087, "_timestamp": 1585587802.7192597, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09195040166378021, "Value Loss": 7.533482130384073e-05, "_runtime": 17888.475865364075, "_timestamp": 1585587804.3204987, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09084806591272354, "Value Loss": 7.35387293389067e-05, "_runtime": 17890.078077554703, "_timestamp": 1585587805.922711, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08974020183086395, "Value Loss": 7.204144640127197e-05, "_runtime": 17891.679441452026, "_timestamp": 1585587807.5240748, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08867325633764267, "Value Loss": 7.006182568147779e-05, "_runtime": 17893.26831150055, "_timestamp": 1585587809.1129448, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08760199695825577, "Value Loss": 6.843918527010828e-05, "_runtime": 17894.873920679092, "_timestamp": 1585587810.718554, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08654195815324783, "Value Loss": 6.688258872600272e-05, "_runtime": 17896.47685432434, "_timestamp": 1585587812.3214877, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08550278842449188, "Value Loss": 6.518539157696068e-05, "_runtime": 17898.076435804367, "_timestamp": 1585587813.9210691, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08447284251451492, "Value Loss": 6.395095260813832e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17899.67706179619, "_timestamp": 1585587815.5216951, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08347156643867493, "Value Loss": 6.232094892766327e-05, "_runtime": 17899.67706179619, "_timestamp": 1585587815.5216951, "_step": 499}
