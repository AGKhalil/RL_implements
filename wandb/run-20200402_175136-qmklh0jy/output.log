/home/user/miniconda/envs/py36/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
  0%|                                                                      | 0/30000 [00:00<?, ?it/s]  0%|                                                                      | 0/30000 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "main_icm_vpg.py", line 119, in <module>
    discounted_rewards = torch.tensor(discounted_rewards).to(device)
ValueError: only one element tensors can be converted to Python scalars
>>> discounted_rewards[0]
tensor([[ 10.5420,  -6.2069, -10.5036,   5.2229,  -1.9946,  -4.5862,  -3.5497,
          -4.2894,  -3.6542, -22.9216,   1.8856,  -9.1688, -22.9437,   3.2335,
           7.8622,  -5.5539, -28.4214,   1.2214,  -2.6683, -15.8911, -26.2724,
          13.0017,  12.2112, -10.7779, -32.0498, -48.6739, -27.7158, -19.8787,
           4.7335,  -0.1786,  -4.7363,  19.1577,  -9.8377, -11.4654, -20.4405,
          17.3558, -22.1600,   4.0156,  -9.4157, -11.2489, -20.0936, -16.0323,
          19.2557,  -4.8487, -36.9096, -22.7491, -20.2064,  -3.5826, -14.8773,
         -26.9936,   2.5697, -50.3168,  -8.5278,   5.6433,  -7.0525, -29.5354,
          -2.5696,  -5.6847, -34.0908,  32.8012, -46.2462,  16.1912, -10.2453,
           1.8584, -13.4082, -44.9910, -20.9161, -28.2547, -25.3224, -33.2476,
          -5.5046,   6.5270, -20.5039,  13.4732,  22.0581,  -1.6766,  -4.9847,
          -1.1615, -13.0577, -10.1423, -28.2260,  -8.2513,  -7.6259,  -7.1612,
         -11.3412,   5.8260,  -8.4081, -36.3560, -12.7539, -21.2545, -16.2643,
         -23.5759,  -4.8352,   3.8748, -10.4371,  -9.1256,  -3.7807,  -7.0615,
         -29.8051,  -1.0374, -36.6717, -12.5051,  21.1412, -15.0546,  -0.1625,
          -7.5128, -12.5806,   0.8494,  27.2164,  11.7696,  -8.4236, -14.2425,
         -17.5491,   1.0218, -32.8749,   6.4877, -27.7671, -27.1751, -17.7185,
         -14.8351, -25.1354, -16.2596, -23.3794, -24.0758,  -5.8995,   9.2941,
          -9.2637,   6.9160]], grad_fn=<AddBackward0>)
>>> discounted_rewards[0]:]2]
[tensor([[ 10.5420,  -6.2069, -10.5036,   5.2229,  -1.9946,  -4.5862,  -3.5497,
          -4.2894,  -3.6542, -22.9216,   1.8856,  -9.1688, -22.9437,   3.2335,
           7.8622,  -5.5539, -28.4214,   1.2214,  -2.6683, -15.8911, -26.2724,
          13.0017,  12.2112, -10.7779, -32.0498, -48.6739, -27.7158, -19.8787,
           4.7335,  -0.1786,  -4.7363,  19.1577,  -9.8377, -11.4654, -20.4405,
          17.3558, -22.1600,   4.0156,  -9.4157, -11.2489, -20.0936, -16.0323,
          19.2557,  -4.8487, -36.9096, -22.7491, -20.2064,  -3.5826, -14.8773,
         -26.9936,   2.5697, -50.3168,  -8.5278,   5.6433,  -7.0525, -29.5354,
          -2.5696,  -5.6847, -34.0908,  32.8012, -46.2462,  16.1912, -10.2453,
           1.8584, -13.4082, -44.9910, -20.9161, -28.2547, -25.3224, -33.2476,
          -5.5046,   6.5270, -20.5039,  13.4732,  22.0581,  -1.6766,  -4.9847,
          -1.1615, -13.0577, -10.1423, -28.2260,  -8.2513,  -7.6259,  -7.1612,
         -11.3412,   5.8260,  -8.4081, -36.3560, -12.7539, -21.2545, -16.2643,
         -23.5759,  -4.8352,   3.8748, -10.4371,  -9.1256,  -3.7807,  -7.0615,
         -29.8051,  -1.0374, -36.6717, -12.5051,  21.1412, -15.0546,  -0.1625,
          -7.5128, -12.5806,   0.8494,  27.2164,  11.7696,  -8.4236, -14.2425,
         -17.5491,   1.0218, -32.8749,   6.4877, -27.7671, -27.1751, -17.7185,
         -14.8351, -25.1354, -16.2596, -23.3794, -24.0758,  -5.8995,   9.2941,
          -9.2637,   6.9160]], grad_fn=<AddBackward0>), tensor([[ 10.4317,  -6.3153, -10.6131,   5.1132,  -2.1058,  -4.6997,  -3.6585,
          -4.3975,  -3.7607, -23.0296,   1.7791,  -9.2780, -23.0535,   3.1258,
           7.7493,  -5.6619, -28.5286,   1.1083,  -2.7778, -15.9983, -26.3834,
          12.8924,  12.1001, -10.8871, -32.1579, -48.7807, -27.8261, -19.9867,
           4.6246,  -0.2882,  -4.8475,  19.0498,  -9.9472, -11.5751, -20.5500,
          17.2522, -22.2720,   3.9073,  -9.5273, -11.3596, -20.2011, -16.1396,
          19.1444,  -4.9579, -37.0163, -22.8583, -20.3146,  -3.6940, -14.9867,
         -27.1034,   2.4593, -50.4226,  -8.6376,   5.5334,  -7.1635, -29.6426,
          -2.6782,  -5.7936, -34.1974,  32.6898, -46.3527,  16.0815, -10.3576,
           1.7486, -13.5173, -45.0997, -21.0246, -28.3623, -25.4277, -33.3558,
          -5.6142,   6.4217, -20.6120,  13.3603,  21.9505,  -1.7830,  -5.0897,
          -1.2695, -13.1670, -10.2498, -28.3355,  -8.3558,  -7.7357,  -7.2748,
         -11.4518,   5.7184,  -8.5130, -36.4642, -12.8646, -21.3637, -16.3745,
         -23.6815,  -4.9424,   3.7655, -10.5449,  -9.2298,  -3.8918,  -7.1669,
         -29.9139,  -1.1435, -36.7776, -12.6148,  21.0348, -15.1630,  -0.2739,
          -7.6191, -12.6910,   0.7437,  27.1071,  11.6627,  -8.5352, -14.3500,
         -17.6562,   0.9108, -32.9813,   6.3807, -27.8780, -27.2862, -17.8287,
         -14.9429, -25.2455, -16.3702, -23.4903, -24.1820,  -6.0103,   9.1851,
          -9.3735,   6.8041]], grad_fn=<AddBackward0>)]
>>> discounted_rewards[0:2][C[C[C[C[Kexit()
