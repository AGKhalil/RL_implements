{"Episode reward": -35.88742060738219, "Episode length": 999, "Policy Loss": -0.03191323205828667, "Value Loss": 0.0026437726337462664, "_runtime": 14111.861454248428, "_timestamp": 1585584027.7060876, "_step": 0}
{"Episode reward": 14.601680726356989, "Episode length": 867, "Policy Loss": -0.00900258868932724, "Value Loss": 194.93540954589844, "_runtime": 14112.7940762043, "_timestamp": 1585584028.6387095, "_step": 1}
{"Episode reward": 38.490256612764775, "Episode length": 618, "Policy Loss": 4.214902877807617, "Value Loss": 314.11712646484375, "_runtime": 14114.394745349884, "_timestamp": 1585584030.2393787, "_step": 2}
{"Episode reward": -99.73573827522202, "Episode length": 999, "Policy Loss": -7.307308673858643, "Value Loss": 4327.66552734375, "_runtime": 14115.961454153061, "_timestamp": 1585584031.8060875, "_step": 3}
{"Episode reward": -99.8026121377931, "Episode length": 999, "Policy Loss": -1.6215009689331055, "Value Loss": 37.20085525512695, "_runtime": 14117.50175523758, "_timestamp": 1585584033.3463886, "_step": 4}
{"Episode reward": -99.70159358838433, "Episode length": 999, "Policy Loss": -0.7695777416229248, "Value Loss": 18.217967987060547, "_runtime": 14118.27723622322, "_timestamp": 1585584034.1218696, "_step": 5}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.42274144291877747, "Value Loss": 62.241455078125, "_runtime": 14119.869907617569, "_timestamp": 1585584035.714541, "_step": 6}
{"Episode reward": -99.79082852043072, "Episode length": 999, "Policy Loss": -0.3687896132469177, "Value Loss": 5.3772735595703125, "_runtime": 14120.645823001862, "_timestamp": 1585584036.4904563, "_step": 7}
{"Episode reward": 51.98816680312116, "Episode length": 481, "Policy Loss": 1.5987319946289062, "Value Loss": 24.603757858276367, "_runtime": 14122.18440413475, "_timestamp": 1585584038.0290375, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1417810171842575, "Value Loss": 1.902221441268921, "_runtime": 14123.782739639282, "_timestamp": 1585584039.627373, "_step": 9}
{"Episode reward": -99.84482230581203, "Episode length": 999, "Policy Loss": 0.3489069938659668, "Value Loss": 1.730064034461975, "_runtime": 14125.31796336174, "_timestamp": 1585584041.1625967, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7793476581573486, "Value Loss": 15.483177185058594, "_runtime": 14125.82231092453, "_timestamp": 1585584041.6669443, "_step": 11}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 5.7494096755981445, "Value Loss": 59.03606033325195, "_runtime": 14127.405373096466, "_timestamp": 1585584043.2500064, "_step": 12}
{"Episode reward": -99.80131666660169, "Episode length": 999, "Policy Loss": 0.5815541744232178, "Value Loss": 1.2949169874191284, "_runtime": 14129.013466835022, "_timestamp": 1585584044.8581002, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5227725505828857, "Value Loss": 4.319816589355469, "_runtime": 14130.530848741531, "_timestamp": 1585584046.375482, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8387173414230347, "Value Loss": 16.781795501708984, "_runtime": 14132.135008096695, "_timestamp": 1585584047.9796414, "_step": 15}
{"Episode reward": -99.80107660889486, "Episode length": 999, "Policy Loss": 3.298288106918335, "Value Loss": 16.277990341186523, "_runtime": 14133.72400546074, "_timestamp": 1585584049.5686388, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.118797302246094, "Value Loss": 21.63344955444336, "_runtime": 14135.283249378204, "_timestamp": 1585584051.1278827, "_step": 17}
{"Episode reward": 1.3998282488448837, "Episode length": 987, "Policy Loss": 12.708025932312012, "Value Loss": 157.15719604492188, "_runtime": 14136.188366651535, "_timestamp": 1585584052.033, "_step": 18}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 6.525261402130127, "Value Loss": 30.675838470458984, "_runtime": 14137.77279829979, "_timestamp": 1585584053.6174316, "_step": 19}
{"Episode reward": -99.87425171285727, "Episode length": 999, "Policy Loss": -0.43049994111061096, "Value Loss": 29.81083869934082, "_runtime": 14139.353204250336, "_timestamp": 1585584055.1978376, "_step": 20}
{"Episode reward": -99.37318750395143, "Episode length": 999, "Policy Loss": 0.38811394572257996, "Value Loss": 19.245731353759766, "_runtime": 14140.90036725998, "_timestamp": 1585584056.7450006, "_step": 21}
{"Episode reward": -99.86280252933362, "Episode length": 999, "Policy Loss": -5.015604019165039, "Value Loss": 40.0537223815918, "_runtime": 14141.528713941574, "_timestamp": 1585584057.3733473, "_step": 22}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 3.0592305660247803, "Value Loss": 34.52924728393555, "_runtime": 14143.008161067963, "_timestamp": 1585584058.8527944, "_step": 23}
{"Episode reward": 5.500000000001094, "Episode length": 945, "Policy Loss": 7.405698299407959, "Value Loss": 117.33244323730469, "_runtime": 14144.407080173492, "_timestamp": 1585584060.2517135, "_step": 24}
{"Episode reward": 12.100000000000719, "Episode length": 879, "Policy Loss": 0.295585036277771, "Value Loss": 17.18406105041504, "_runtime": 14145.937528133392, "_timestamp": 1585584061.7821615, "_step": 25}
{"Episode reward": -99.82612941898266, "Episode length": 999, "Policy Loss": -1.1040937900543213, "Value Loss": 0.7626856565475464, "_runtime": 14147.556345939636, "_timestamp": 1585584063.4009793, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1414623260498047, "Value Loss": 19.82054901123047, "_runtime": 14149.132090091705, "_timestamp": 1585584064.9767234, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6268216967582703, "Value Loss": 8.877740859985352, "_runtime": 14150.704189777374, "_timestamp": 1585584066.548823, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5597704648971558, "Value Loss": 29.577465057373047, "_runtime": 14152.332701206207, "_timestamp": 1585584068.1773345, "_step": 29}
{"Episode reward": -99.80112010389426, "Episode length": 999, "Policy Loss": -0.8456584215164185, "Value Loss": 3.8938844203948975, "_runtime": 14153.361606836319, "_timestamp": 1585584069.2062402, "_step": 30}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.05046772211790085, "Value Loss": 31.840587615966797, "_runtime": 14154.641994953156, "_timestamp": 1585584070.4866283, "_step": 31}
{"Episode reward": 19.04703316092524, "Episode length": 810, "Policy Loss": -0.2637411057949066, "Value Loss": 20.457569122314453, "_runtime": 14156.076249837875, "_timestamp": 1585584071.9208832, "_step": 32}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": -0.6737170815467834, "Value Loss": 17.054447174072266, "_runtime": 14157.31937623024, "_timestamp": 1585584073.1640096, "_step": 33}
{"Episode reward": 20.513840270042664, "Episode length": 795, "Policy Loss": -0.6710566878318787, "Value Loss": 14.129617691040039, "_runtime": 14158.111995220184, "_timestamp": 1585584073.9566286, "_step": 34}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": -0.5607610940933228, "Value Loss": 21.624155044555664, "_runtime": 14159.68043088913, "_timestamp": 1585584075.5250642, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5754032135009766, "Value Loss": 2.5246071815490723, "_runtime": 14161.248747110367, "_timestamp": 1585584077.0933805, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.854205369949341, "Value Loss": 2.534844160079956, "_runtime": 14162.783895015717, "_timestamp": 1585584078.6285284, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1188151836395264, "Value Loss": 4.588639736175537, "_runtime": 14164.371527433395, "_timestamp": 1585584080.2161608, "_step": 38}
{"Episode reward": -99.71391942053893, "Episode length": 999, "Policy Loss": -3.304478883743286, "Value Loss": 4.249767303466797, "_runtime": 14165.032977581024, "_timestamp": 1585584080.877611, "_step": 39}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": -1.109224557876587, "Value Loss": 36.04785919189453, "_runtime": 14166.618539094925, "_timestamp": 1585584082.4631724, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1187541484832764, "Value Loss": 1.7405484914779663, "_runtime": 14168.233550071716, "_timestamp": 1585584084.0781834, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.517698049545288, "Value Loss": 3.2909159660339355, "_runtime": 14169.816044330597, "_timestamp": 1585584085.6606777, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.9347000122070312, "Value Loss": 2.507416009902954, "_runtime": 14171.431316375732, "_timestamp": 1585584087.2759497, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.133302688598633, "Value Loss": 1.429623007774353, "_runtime": 14173.038058519363, "_timestamp": 1585584088.8826919, "_step": 44}
{"Episode reward": -99.82095475792745, "Episode length": 999, "Policy Loss": -2.7729251384735107, "Value Loss": 0.6670100688934326, "_runtime": 14174.596970558167, "_timestamp": 1585584090.441604, "_step": 45}
{"Episode reward": -99.80363099723915, "Episode length": 999, "Policy Loss": -2.5423777103424072, "Value Loss": 0.28603819012641907, "_runtime": 14175.786946296692, "_timestamp": 1585584091.6315796, "_step": 46}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": -0.9315940737724304, "Value Loss": 13.695098876953125, "_runtime": 14176.735532283783, "_timestamp": 1585584092.5801656, "_step": 47}
{"Episode reward": 43.09999999999947, "Episode length": 569, "Policy Loss": -0.2083750069141388, "Value Loss": 17.583255767822266, "_runtime": 14178.303673505783, "_timestamp": 1585584094.1483068, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8332844972610474, "Value Loss": 0.056834205985069275, "_runtime": 14179.870579957962, "_timestamp": 1585584095.7152133, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6562989950180054, "Value Loss": 0.03484531119465828, "_runtime": 14181.406181812286, "_timestamp": 1585584097.2508152, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4600342512130737, "Value Loss": 0.02737458236515522, "_runtime": 14182.685114383698, "_timestamp": 1585584098.5297477, "_step": 51}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": -0.1056850254535675, "Value Loss": 12.290961265563965, "_runtime": 14184.258552789688, "_timestamp": 1585584100.1031861, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0968202352523804, "Value Loss": 0.016185328364372253, "_runtime": 14185.834053993225, "_timestamp": 1585584101.6786873, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9383193850517273, "Value Loss": 0.011416526511311531, "_runtime": 14187.391749382019, "_timestamp": 1585584103.2363827, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7769395709037781, "Value Loss": 0.008346030488610268, "_runtime": 14188.984458208084, "_timestamp": 1585584104.8290915, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6285629868507385, "Value Loss": 0.01215110719203949, "_runtime": 14190.580088853836, "_timestamp": 1585584106.4247222, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5211532115936279, "Value Loss": 0.021954039111733437, "_runtime": 14191.661395549774, "_timestamp": 1585584107.506029, "_step": 57}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 1.0149128437042236, "Value Loss": 14.602590560913086, "_runtime": 14193.25925040245, "_timestamp": 1585584109.1038837, "_step": 58}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": 0.7046322822570801, "Value Loss": 9.981056213378906, "_runtime": 14194.855039596558, "_timestamp": 1585584110.699673, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16420893371105194, "Value Loss": 0.03483330085873604, "_runtime": 14196.417492628098, "_timestamp": 1585584112.262126, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07036346942186356, "Value Loss": 0.0943969190120697, "_runtime": 14197.998236179352, "_timestamp": 1585584113.8428695, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09202760457992554, "Value Loss": 0.10443488508462906, "_runtime": 14199.190731287003, "_timestamp": 1585584115.0353646, "_step": 62}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": 1.3260340690612793, "Value Loss": 13.53256893157959, "_runtime": 14200.805865049362, "_timestamp": 1585584116.6504984, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11158844083547592, "Value Loss": 0.1692437380552292, "_runtime": 14202.398421287537, "_timestamp": 1585584118.2430546, "_step": 64}
{"Episode reward": -99.80002837776998, "Episode length": 999, "Policy Loss": 0.014470870606601238, "Value Loss": 0.05349961295723915, "_runtime": 14203.965141773224, "_timestamp": 1585584119.809775, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012365919537842274, "Value Loss": 0.05131002888083458, "_runtime": 14205.517613172531, "_timestamp": 1585584121.3622465, "_step": 66}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 1.0206453800201416, "Value Loss": 10.210223197937012, "_runtime": 14206.506353855133, "_timestamp": 1585584122.3509872, "_step": 67}
{"Episode reward": 39.09999999999941, "Episode length": 609, "Policy Loss": 1.4965922832489014, "Value Loss": 16.394556045532227, "_runtime": 14208.083861589432, "_timestamp": 1585584123.928495, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02168782241642475, "Value Loss": 0.017359834164381027, "_runtime": 14209.67338347435, "_timestamp": 1585584125.5180168, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023119956254959106, "Value Loss": 0.0029681141022592783, "_runtime": 14211.056606531143, "_timestamp": 1585584126.9012399, "_step": 70}
{"Episode reward": 11.20000000000077, "Episode length": 888, "Policy Loss": 1.030835747718811, "Value Loss": 11.23987102508545, "_runtime": 14212.273857831955, "_timestamp": 1585584128.1184912, "_step": 71}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 1.2381997108459473, "Value Loss": 13.120766639709473, "_runtime": 14213.396797418594, "_timestamp": 1585584129.2414308, "_step": 72}
{"Episode reward": 30.299999999999685, "Episode length": 697, "Policy Loss": 1.2913216352462769, "Value Loss": 14.331993103027344, "_runtime": 14214.956105232239, "_timestamp": 1585584130.8007386, "_step": 73}
{"Episode reward": 1.00000000000135, "Episode length": 990, "Policy Loss": 0.9456926584243774, "Value Loss": 10.085671424865723, "_runtime": 14215.949956417084, "_timestamp": 1585584131.7945898, "_step": 74}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": 1.5148334503173828, "Value Loss": 16.066736221313477, "_runtime": 14217.379588603973, "_timestamp": 1585584133.224222, "_step": 75}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": 0.9743953943252563, "Value Loss": 10.927928924560547, "_runtime": 14218.331491947174, "_timestamp": 1585584134.1761253, "_step": 76}
{"Episode reward": 41.09999999999944, "Episode length": 589, "Policy Loss": 2.1262459754943848, "Value Loss": 16.920616149902344, "_runtime": 14219.884024381638, "_timestamp": 1585584135.7286577, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013050821609795094, "Value Loss": 0.005935626570135355, "_runtime": 14221.455967903137, "_timestamp": 1585584137.3006012, "_step": 78}
{"Episode reward": -99.80045404434064, "Episode length": 999, "Policy Loss": -0.09355073422193527, "Value Loss": 0.09965649992227554, "_runtime": 14223.023554801941, "_timestamp": 1585584138.8681881, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010139863938093185, "Value Loss": 0.030991358682513237, "_runtime": 14224.524772167206, "_timestamp": 1585584140.3694055, "_step": 80}
{"Episode reward": 7.275364869833993, "Episode length": 928, "Policy Loss": 1.2541669607162476, "Value Loss": 10.718436241149902, "_runtime": 14226.107861280441, "_timestamp": 1585584141.9524946, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027638904750347137, "Value Loss": 0.006713381968438625, "_runtime": 14227.589769124985, "_timestamp": 1585584143.4344025, "_step": 82}
{"Episode reward": 6.80000000000102, "Episode length": 932, "Policy Loss": 0.9444694519042969, "Value Loss": 10.700066566467285, "_runtime": 14228.224868774414, "_timestamp": 1585584144.069502, "_step": 83}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": 2.283721446990967, "Value Loss": 25.752092361450195, "_runtime": 14228.644262552261, "_timestamp": 1585584144.488896, "_step": 84}
{"Episode reward": 76.39999999999995, "Episode length": 236, "Policy Loss": 4.181631088256836, "Value Loss": 42.14126205444336, "_runtime": 14230.215297460556, "_timestamp": 1585584146.0599308, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0754755288362503, "Value Loss": 0.0034162027295678854, "_runtime": 14231.538839578629, "_timestamp": 1585584147.383473, "_step": 86}
{"Episode reward": 12.80000000000068, "Episode length": 872, "Policy Loss": 0.9224319458007812, "Value Loss": 11.435711860656738, "_runtime": 14233.029747009277, "_timestamp": 1585584148.8743804, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13579122722148895, "Value Loss": 0.04257480800151825, "_runtime": 14234.607949256897, "_timestamp": 1585584150.4525826, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13973872363567352, "Value Loss": 0.009861874394118786, "_runtime": 14236.121136903763, "_timestamp": 1585584151.9657702, "_step": 89}
{"Episode reward": 3.500000000001208, "Episode length": 965, "Policy Loss": 0.8154139518737793, "Value Loss": 10.421412467956543, "_runtime": 14237.660031318665, "_timestamp": 1585584153.5046647, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19395485520362854, "Value Loss": 0.01694618910551071, "_runtime": 14239.243772506714, "_timestamp": 1585584155.0884058, "_step": 91}
{"Episode reward": -99.8142277777181, "Episode length": 999, "Policy Loss": -0.22359305620193481, "Value Loss": 0.033522773534059525, "_runtime": 14240.814386606216, "_timestamp": 1585584156.65902, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33618178963661194, "Value Loss": 0.03141844645142555, "_runtime": 14242.382031440735, "_timestamp": 1585584158.2266648, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38886788487434387, "Value Loss": 0.028918607160449028, "_runtime": 14243.979264259338, "_timestamp": 1585584159.8238976, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4272884130477905, "Value Loss": 0.011314102448523045, "_runtime": 14245.560831069946, "_timestamp": 1585584161.4054644, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4658937156200409, "Value Loss": 0.006371331866830587, "_runtime": 14247.094070196152, "_timestamp": 1585584162.9387035, "_step": 96}
{"Episode reward": 1.8000000000013046, "Episode length": 982, "Policy Loss": 0.6635245680809021, "Value Loss": 10.172483444213867, "_runtime": 14248.034468889236, "_timestamp": 1585584163.8791022, "_step": 97}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 1.3178660869598389, "Value Loss": 18.002532958984375, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482, 0.01432747021317482]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01432747021317482, 0.1429280936717987, 0.30018365383148193, 0.45743921399116516, 0.6146947741508484, 0.7719503045082092, 0.9292058944702148, 1.0864614248275757, 1.2437169551849365, 1.4009724855422974, 1.5582280158996582, 1.7154836654663086, 1.8727391958236694, 2.0299947261810303, 2.1872503757476807, 2.344505786895752, 2.5017614364624023, 2.6590170860290527, 2.816272497177124, 2.9735281467437744, 3.1307835578918457, 3.288039207458496, 3.4452948570251465, 3.6025502681732178, 3.759805917739868, 3.9170615673065186, 4.07431697845459, 4.23157262802124, 4.388828277587891, 4.546083927154541, 4.703339099884033, 4.860594749450684, 5.017850399017334, 5.175106048583984, 5.332361698150635, 5.489616870880127, 5.646872520446777, 5.804128170013428, 5.961383819580078, 6.1186394691467285, 6.275894641876221, 6.433150291442871, 6.5904059410095215, 6.747661590576172, 6.904917240142822, 7.062172889709473, 7.219428062438965, 7.376683712005615, 7.533939361572266, 7.691195011138916, 7.848450660705566, 8.005706787109375, 8.162961959838867, 8.320218086242676, 8.477473258972168, 8.63472843170166, 8.791984558105469, 8.949239730834961, 9.10649585723877, 9.263751029968262, 9.421006202697754, 9.578262329101562, 9.735517501831055, 9.892773628234863, 10.050028800964355]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [11.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0019505831878632307, 0.0039011663757264614, 0.0058517493307590485, 0.007802332751452923, 0.009752916172146797, 0.011703498661518097, 0.013654082082211971, 0.015604665502905846, 0.017555247992277145, 0.019505832344293594, 0.021456414833664894, 0.023406997323036194, 0.025357581675052643, 0.027308164164423943, 0.02925874851644039, 0.03120933100581169, 0.03315991535782814, 0.03511049598455429, 0.03706108033657074, 0.03901166468858719, 0.04096224531531334, 0.04291282966732979, 0.04486341401934624, 0.04681399464607239, 0.04876457899808884, 0.050715163350105286, 0.052665747702121735, 0.054616328328847885, 0.056566912680864334, 0.05851749703288078, 0.060468077659606934, 0.06241866201162338, 0.06436924636363983, 0.06631983071565628, 0.06827041506767273, 0.07022099196910858, 0.07217157632112503, 0.07412216067314148, 0.07607274502515793, 0.07802332937717438, 0.07997391372919083, 0.08192449063062668, 0.08387507498264313, 0.08582565933465958, 0.08777624368667603, 0.08972682803869247, 0.09167741239070892, 0.09362798929214478, 0.09557857364416122, 0.09752915799617767, 0.09947974234819412, 0.10143032670021057, 0.10338091105222702, 0.10533149540424347, 0.10728207230567932, 0.10923265665769577, 0.11118324100971222, 0.11313382536172867, 0.11508440971374512, 0.11703499406576157, 0.11898557096719742, 0.12093615531921387, 0.12288673967123032, 0.12483732402324677]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [12.0, 3.0, 1.0, 1.0, 1.0, 444.0, 35.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.12455503642559052, -0.10173426568508148, -0.07891349494457245, -0.056092724204063416, -0.03327195346355438, -0.010451182723045349, 0.012369588017463684, 0.03519035875797272, 0.05801112949848175, 0.08083190023899078, 0.10365267097949982, 0.12647344172000885, 0.14929421246051788, 0.17211498320102692, 0.19493575394153595, 0.21775652468204498, 0.24057729542255402, 0.26339805126190186, 0.2862188220024109, 0.3090395927429199, 0.33186036348342896, 0.354681134223938, 0.377501904964447, 0.40032267570495605, 0.4231434464454651, 0.4459642171859741, 0.46878498792648315, 0.4916057586669922, 0.5144265294075012, 0.5372473001480103, 0.5600680708885193, 0.5828888416290283, 0.6057096123695374, 0.6285303831100464, 0.6513511538505554, 0.6741719245910645, 0.6969926953315735, 0.7198134660720825, 0.7426342368125916, 0.7654550075531006, 0.7882757782936096, 0.8110965490341187, 0.8339173197746277, 0.8567380905151367, 0.8795588612556458, 0.90237957239151, 0.9252004027366638, 0.9480212330818176, 0.9708419442176819, 0.9936626553535461, 1.0164835453033447, 1.0393043756484985, 1.0621250867843628, 1.084945797920227, 1.1077666282653809, 1.1305874586105347, 1.153408169746399, 1.1762288808822632, 1.199049711227417, 1.2218705415725708, 1.244691252708435, 1.2675119638442993, 1.2903327941894531, 1.313153624534607, 1.3359743356704712]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 9.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.15148435533046722, -0.13161274790763855, -0.11174113303422928, -0.09186951816082001, -0.07199791073799133, -0.05212630331516266, -0.03225468844175339, -0.012383073568344116, 0.007488533854484558, 0.027360141277313232, 0.04723174870014191, 0.06710337102413177, 0.08697497844696045, 0.10684658586978912, 0.126718208193779, 0.14658980071544647, 0.16646142303943634, 0.1863330453634262, 0.2062046378850937, 0.22607626020908356, 0.24594785273075104, 0.2658194899559021, 0.2856910824775696, 0.30556267499923706, 0.3254343271255493, 0.3453059196472168, 0.3651775121688843, 0.38504910469055176, 0.404920756816864, 0.4247923493385315, 0.444663941860199, 0.46453559398651123, 0.4844071865081787, 0.5042787790298462, 0.5241504311561584, 0.5440220236778259, 0.5638936161994934, 0.5837652683258057, 0.6036368608474731, 0.6235084533691406, 0.6433800458908081, 0.6632516980171204, 0.6831232905387878, 0.7029948830604553, 0.7228665351867676, 0.7427381277084351, 0.7626097202301025, 0.7824813723564148, 0.8023529648780823, 0.8222245573997498, 0.842096209526062, 0.8619678020477295, 0.881839394569397, 0.9017109870910645, 0.9215825796127319, 0.941454291343689, 0.9613258838653564, 0.9811974763870239, 1.0010690689086914, 1.0209406614303589, 1.0408122539520264, 1.0606839656829834, 1.0805555582046509, 1.1004271507263184, 1.1202987432479858]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 18.0, 1.0, 3.0, 3.0, 7.0, 5.0, 2.0, 2.0, 4.0], "bins": [-0.5691839456558228, -0.5588617324829102, -0.5485395789146423, -0.5382173657417297, -0.5278952121734619, -0.5175729990005493, -0.5072507858276367, -0.4969286322593689, -0.4866064190864563, -0.4762842357158661, -0.4659620523452759, -0.4556398391723633, -0.44531768560409546, -0.43499547243118286, -0.42467328906059265, -0.41435110569000244, -0.40402889251708984, -0.393706738948822, -0.3833845257759094, -0.3730623424053192, -0.362740159034729, -0.3524179458618164, -0.3420957624912262, -0.331773579120636, -0.3214513957500458, -0.31112921237945557, -0.30080699920654297, -0.29048481583595276, -0.28016263246536255, -0.26984044909477234, -0.25951823592185974, -0.24919605255126953, -0.23887386918067932, -0.2285516858100891, -0.2182295024394989, -0.2079072892665863, -0.1975851058959961, -0.18726292252540588, -0.17694073915481567, -0.16661852598190308, -0.15629634261131287, -0.14597415924072266, -0.13565197587013245, -0.12532979249954224, -0.11500757932662964, -0.10468539595603943, -0.09436321258544922, -0.08404102921485901, -0.0737188458442688, -0.0633966326713562, -0.05307447910308838, -0.04275226593017578, -0.032430052757263184, -0.02210789918899536, -0.011785686016082764, -0.001463472843170166, 0.008858680725097656, 0.019180893898010254, 0.029503047466278076, 0.039825260639190674, 0.05014747381210327, 0.060469627380371094, 0.07079184055328369, 0.08111399412155151, 0.09143620729446411]}, "_runtime": 14249.556622743607, "_timestamp": 1585584165.401256, "_step": 98}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": 0.4613540470600128, "Value Loss": 10.454380989074707, "_runtime": 14251.143811941147, "_timestamp": 1585584166.9884453, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5051367878913879, "Value Loss": 0.008217647671699524, "_runtime": 14252.696152210236, "_timestamp": 1585584168.5407856, "_step": 100}
{"Episode reward": -99.89163761734822, "Episode length": 999, "Policy Loss": -0.5000449419021606, "Value Loss": 0.011496529914438725, "_runtime": 14254.294773340225, "_timestamp": 1585584170.1394067, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4794103801250458, "Value Loss": 0.033521026372909546, "_runtime": 14255.34390115738, "_timestamp": 1585584171.1885345, "_step": 102}
{"Episode reward": 33.9537800490851, "Episode length": 661, "Policy Loss": 1.0016099214553833, "Value Loss": 15.043614387512207, "_runtime": 14256.921676635742, "_timestamp": 1585584172.76631, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42639121413230896, "Value Loss": 0.033563047647476196, "_runtime": 14257.967863321304, "_timestamp": 1585584173.8124967, "_step": 104}
{"Episode reward": 35.79999999999937, "Episode length": 642, "Policy Loss": 1.0658859014511108, "Value Loss": 15.447478294372559, "_runtime": 14259.532395839691, "_timestamp": 1585584175.3770292, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3792474567890167, "Value Loss": 0.021178454160690308, "_runtime": 14260.117436170578, "_timestamp": 1585584175.9620695, "_step": 106}
{"Episode reward": 65.49999999999979, "Episode length": 345, "Policy Loss": 2.355832576751709, "Value Loss": 28.66786766052246, "_runtime": 14261.234941959381, "_timestamp": 1585584177.0795753, "_step": 107}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 1.135164499282837, "Value Loss": 14.062834739685059, "_runtime": 14262.8513276577, "_timestamp": 1585584178.695961, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25698044896125793, "Value Loss": 0.02438081055879593, "_runtime": 14263.9092066288, "_timestamp": 1585584179.75384, "_step": 109}
{"Episode reward": 30.298705649375606, "Episode length": 698, "Policy Loss": 1.2388843297958374, "Value Loss": 14.255230903625488, "_runtime": 14265.459558963776, "_timestamp": 1585584181.3041923, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2282070517539978, "Value Loss": 0.03532904386520386, "_runtime": 14267.040161132812, "_timestamp": 1585584182.8847945, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.265056312084198, "Value Loss": 0.1999945342540741, "_runtime": 14267.558614253998, "_timestamp": 1585584183.4032476, "_step": 112}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": 2.8010025024414062, "Value Loss": 31.849029541015625, "_runtime": 14269.132174491882, "_timestamp": 1585584184.9768078, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3858969807624817, "Value Loss": 0.13037554919719696, "_runtime": 14270.718861341476, "_timestamp": 1585584186.5634947, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4446285367012024, "Value Loss": 0.043415047228336334, "_runtime": 14272.263894796371, "_timestamp": 1585584188.1085281, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4944719672203064, "Value Loss": 0.02270791307091713, "_runtime": 14273.86446094513, "_timestamp": 1585584189.7090943, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5980614423751831, "Value Loss": 0.04120438173413277, "_runtime": 14275.461839437485, "_timestamp": 1585584191.3064728, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6136453151702881, "Value Loss": 0.01586296781897545, "_runtime": 14276.655138969421, "_timestamp": 1585584192.4997723, "_step": 118}
{"Episode reward": 24.000000000000043, "Episode length": 760, "Policy Loss": 0.5882230997085571, "Value Loss": 13.11056137084961, "_runtime": 14278.259140968323, "_timestamp": 1585584194.1037743, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7583168745040894, "Value Loss": 0.009302233345806599, "_runtime": 14278.657298088074, "_timestamp": 1585584194.5019314, "_step": 120}
{"Episode reward": 78.69999999999997, "Episode length": 213, "Policy Loss": 3.9232699871063232, "Value Loss": 46.71949768066406, "_runtime": 14280.015024662018, "_timestamp": 1585584195.859658, "_step": 121}
{"Episode reward": 12.900000000000674, "Episode length": 871, "Policy Loss": 0.5460747480392456, "Value Loss": 11.449421882629395, "_runtime": 14281.613384008408, "_timestamp": 1585584197.4580173, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7014912962913513, "Value Loss": 0.03244154900312424, "_runtime": 14282.63085603714, "_timestamp": 1585584198.4754894, "_step": 123}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": 0.7219517230987549, "Value Loss": 14.726119041442871, "_runtime": 14284.197233438492, "_timestamp": 1585584200.0418668, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.630329966545105, "Value Loss": 0.032077204436063766, "_runtime": 14285.788526535034, "_timestamp": 1585584201.6331599, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.570181667804718, "Value Loss": 0.02526080049574375, "_runtime": 14287.32959318161, "_timestamp": 1585584203.1742265, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5361021757125854, "Value Loss": 0.06485685706138611, "_runtime": 14288.932406187057, "_timestamp": 1585584204.7770395, "_step": 127}
{"Episode reward": -99.82104426026204, "Episode length": 999, "Policy Loss": -0.4565127193927765, "Value Loss": 0.24365030229091644, "_runtime": 14290.538470029831, "_timestamp": 1585584206.3831034, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6180180311203003, "Value Loss": 0.1805146485567093, "_runtime": 14291.372785806656, "_timestamp": 1585584207.2174191, "_step": 129}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 1.216808795928955, "Value Loss": 19.115665435791016, "_runtime": 14292.95545554161, "_timestamp": 1585584208.800089, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.644112765789032, "Value Loss": 0.01568804308772087, "_runtime": 14294.549382448196, "_timestamp": 1585584210.3940158, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7139275074005127, "Value Loss": 0.03169425204396248, "_runtime": 14296.121706724167, "_timestamp": 1585584211.96634, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7573425769805908, "Value Loss": 0.02564362995326519, "_runtime": 14297.722856521606, "_timestamp": 1585584213.5674899, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7875405550003052, "Value Loss": 0.04568084329366684, "_runtime": 14299.326736927032, "_timestamp": 1585584215.1713703, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8337330222129822, "Value Loss": 0.011137375608086586, "_runtime": 14300.908108234406, "_timestamp": 1585584216.7527416, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8421730995178223, "Value Loss": 0.026758015155792236, "_runtime": 14302.506904125214, "_timestamp": 1585584218.3515375, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8975710272789001, "Value Loss": 0.027074892073869705, "_runtime": 14304.105933904648, "_timestamp": 1585584219.9505672, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9188156127929688, "Value Loss": 0.02053944207727909, "_runtime": 14304.879129648209, "_timestamp": 1585584220.723763, "_step": 138}
{"Episode reward": 52.799999999999606, "Episode length": 472, "Policy Loss": 1.2749124765396118, "Value Loss": 21.203428268432617, "_runtime": 14306.474344015121, "_timestamp": 1585584222.3189774, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9253780841827393, "Value Loss": 0.03892058879137039, "_runtime": 14308.081262350082, "_timestamp": 1585584223.9258957, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9171904921531677, "Value Loss": 0.01713942363858223, "_runtime": 14309.61965584755, "_timestamp": 1585584225.4642892, "_step": 141}
{"Episode reward": -99.80021517276624, "Episode length": 999, "Policy Loss": -0.8647384643554688, "Value Loss": 0.05202079564332962, "_runtime": 14311.201027870178, "_timestamp": 1585584227.0456612, "_step": 142}
{"Episode reward": -99.89931757449963, "Episode length": 999, "Policy Loss": -0.861644983291626, "Value Loss": 0.012305091135203838, "_runtime": 14312.112568616867, "_timestamp": 1585584227.957202, "_step": 143}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.9501506090164185, "Value Loss": 17.883689880371094, "_runtime": 14313.683466672897, "_timestamp": 1585584229.5281, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7578125596046448, "Value Loss": 0.02386915124952793, "_runtime": 14315.275570392609, "_timestamp": 1585584231.1202037, "_step": 145}
{"Episode reward": -99.84201546311239, "Episode length": 999, "Policy Loss": -0.7106273770332336, "Value Loss": 0.017777863889932632, "_runtime": 14316.211426258087, "_timestamp": 1585584232.0560596, "_step": 146}
{"Episode reward": 40.49999999999943, "Episode length": 595, "Policy Loss": 0.910747230052948, "Value Loss": 16.618486404418945, "_runtime": 14317.184794187546, "_timestamp": 1585584233.0294275, "_step": 147}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 0.9342896342277527, "Value Loss": 16.280563354492188, "_runtime": 14318.76373887062, "_timestamp": 1585584234.6083722, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5430846214294434, "Value Loss": 0.08588255196809769, "_runtime": 14320.334654808044, "_timestamp": 1585584236.1792881, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48506489396095276, "Value Loss": 0.02466680482029915, "_runtime": 14321.078570127487, "_timestamp": 1585584236.9232035, "_step": 150}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 1.5368099212646484, "Value Loss": 21.166629791259766, "_runtime": 14321.836644649506, "_timestamp": 1585584237.681278, "_step": 151}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 1.4805738925933838, "Value Loss": 21.452402114868164, "_runtime": 14322.67283821106, "_timestamp": 1585584238.5174716, "_step": 152}
{"Episode reward": 48.399999999999544, "Episode length": 516, "Policy Loss": 1.3175904750823975, "Value Loss": 19.063337326049805, "_runtime": 14323.796472072601, "_timestamp": 1585584239.6411054, "_step": 153}
{"Episode reward": 27.39999999999985, "Episode length": 726, "Policy Loss": 1.082509994506836, "Value Loss": 13.668341636657715, "_runtime": 14325.331730365753, "_timestamp": 1585584241.1763637, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4617488384246826, "Value Loss": 0.13344699144363403, "_runtime": 14326.868589401245, "_timestamp": 1585584242.7132227, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36398983001708984, "Value Loss": 0.20505255460739136, "_runtime": 14328.41124367714, "_timestamp": 1585584244.255877, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4575917422771454, "Value Loss": 0.04712437093257904, "_runtime": 14329.074425935745, "_timestamp": 1585584244.9190593, "_step": 157}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 1.6732865571975708, "Value Loss": 24.849040985107422, "_runtime": 14330.632725000381, "_timestamp": 1585584246.4773583, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5719464421272278, "Value Loss": 0.09084311127662659, "_runtime": 14332.223317146301, "_timestamp": 1585584248.0679505, "_step": 159}
{"Episode reward": -99.80775981545308, "Episode length": 999, "Policy Loss": -0.5878584980964661, "Value Loss": 0.031202955171465874, "_runtime": 14333.749557495117, "_timestamp": 1585584249.5941908, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6754404902458191, "Value Loss": 0.014191560447216034, "_runtime": 14335.331800222397, "_timestamp": 1585584251.1764336, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7780032157897949, "Value Loss": 0.03705790638923645, "_runtime": 14336.935047388077, "_timestamp": 1585584252.7796807, "_step": 162}
{"Episode reward": -99.80009313225607, "Episode length": 999, "Policy Loss": -0.8173810839653015, "Value Loss": 0.03903947398066521, "_runtime": 14338.5131149292, "_timestamp": 1585584254.3577483, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9001157879829407, "Value Loss": 0.01804034225642681, "_runtime": 14340.119266271591, "_timestamp": 1585584255.9638996, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9173071980476379, "Value Loss": 0.03255513682961464, "_runtime": 14341.725887298584, "_timestamp": 1585584257.5705206, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9982094764709473, "Value Loss": 0.017798395827412605, "_runtime": 14343.044533729553, "_timestamp": 1585584258.889167, "_step": 166}
{"Episode reward": 16.440706992149828, "Episode length": 836, "Policy Loss": 0.08584394305944443, "Value Loss": 11.955217361450195, "_runtime": 14344.577224731445, "_timestamp": 1585584260.421858, "_step": 167}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": -0.018366670235991478, "Value Loss": 10.658782958984375, "_runtime": 14346.167173147202, "_timestamp": 1585584262.0118065, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0068435668945312, "Value Loss": 0.023189162835478783, "_runtime": 14347.756705522537, "_timestamp": 1585584263.6013389, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.977603018283844, "Value Loss": 0.02912164106965065, "_runtime": 14349.340218305588, "_timestamp": 1585584265.1848516, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9773801565170288, "Value Loss": 0.012380213476717472, "_runtime": 14350.583181381226, "_timestamp": 1585584266.4278147, "_step": 171}
{"Episode reward": 22.313767945766585, "Episode length": 778, "Policy Loss": 0.5859479904174805, "Value Loss": 12.83397388458252, "_runtime": 14352.154775619507, "_timestamp": 1585584267.999409, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.883497953414917, "Value Loss": 0.011473606340587139, "_runtime": 14353.74949479103, "_timestamp": 1585584269.5941281, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8399158120155334, "Value Loss": 0.00949531327933073, "_runtime": 14355.318899393082, "_timestamp": 1585584271.1635327, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7783293128013611, "Value Loss": 0.016468876972794533, "_runtime": 14356.295628070831, "_timestamp": 1585584272.1402614, "_step": 175}
{"Episode reward": 39.59999999999942, "Episode length": 604, "Policy Loss": 0.7864243388175964, "Value Loss": 16.45221710205078, "_runtime": 14357.393615961075, "_timestamp": 1585584273.2382493, "_step": 176}
{"Episode reward": 31.699999999999605, "Episode length": 683, "Policy Loss": 0.7625519633293152, "Value Loss": 14.521684646606445, "_runtime": 14358.981506824493, "_timestamp": 1585584274.8261402, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6292924880981445, "Value Loss": 0.01160458941012621, "_runtime": 14360.533653736115, "_timestamp": 1585584276.378287, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6040002107620239, "Value Loss": 0.026174934580922127, "_runtime": 14362.092560052872, "_timestamp": 1585584277.9371934, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5929786562919617, "Value Loss": 0.07386066019535065, "_runtime": 14363.683059692383, "_timestamp": 1585584279.527693, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5108385682106018, "Value Loss": 0.10760374367237091, "_runtime": 14365.276647090912, "_timestamp": 1585584281.1212804, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5069697499275208, "Value Loss": 0.010632126592099667, "_runtime": 14366.164355516434, "_timestamp": 1585584282.0089889, "_step": 182}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 1.236966609954834, "Value Loss": 18.56748390197754, "_runtime": 14367.849698781967, "_timestamp": 1585584283.6943321, "_step": 183}
{"Episode reward": 0.5000000000013785, "Episode length": 995, "Policy Loss": 0.38180822134017944, "Value Loss": 10.024401664733887, "_runtime": 14369.235163450241, "_timestamp": 1585584285.0797968, "_step": 184}
{"Episode reward": 15.400000000000531, "Episode length": 846, "Policy Loss": 0.564649224281311, "Value Loss": 11.75872802734375, "_runtime": 14370.190151691437, "_timestamp": 1585584286.034785, "_step": 185}
{"Episode reward": 39.299999999999415, "Episode length": 607, "Policy Loss": 0.9707489013671875, "Value Loss": 16.314950942993164, "_runtime": 14371.78468465805, "_timestamp": 1585584287.629318, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5708001255989075, "Value Loss": 0.009534933604300022, "_runtime": 14373.354643821716, "_timestamp": 1585584289.1992772, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6072940826416016, "Value Loss": 0.03931467607617378, "_runtime": 14374.4242105484, "_timestamp": 1585584290.268844, "_step": 188}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.7586515545845032, "Value Loss": 14.414051055908203, "_runtime": 14376.011895895004, "_timestamp": 1585584291.8565292, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6264574527740479, "Value Loss": 0.00897614099085331, "_runtime": 14376.760803699493, "_timestamp": 1585584292.605437, "_step": 190}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": 1.4385257959365845, "Value Loss": 21.661832809448242, "_runtime": 14378.31244802475, "_timestamp": 1585584294.1570814, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6500820517539978, "Value Loss": 0.010873953811824322, "_runtime": 14379.90600514412, "_timestamp": 1585584295.7506385, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.588586688041687, "Value Loss": 0.0292584877461195, "_runtime": 14381.25283241272, "_timestamp": 1585584297.0974658, "_step": 193}
{"Episode reward": 11.90000000000073, "Episode length": 881, "Policy Loss": 0.39498382806777954, "Value Loss": 11.237675666809082, "_runtime": 14382.849223136902, "_timestamp": 1585584298.6938565, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6618258357048035, "Value Loss": 0.06788308173418045, "_runtime": 14384.436558485031, "_timestamp": 1585584300.2811918, "_step": 195}
{"Episode reward": -99.82057650089125, "Episode length": 999, "Policy Loss": -0.6150519251823425, "Value Loss": 0.032303184270858765, "_runtime": 14385.779722929, "_timestamp": 1585584301.6243563, "_step": 196}
{"Episode reward": 14.300000000000594, "Episode length": 857, "Policy Loss": 0.44790270924568176, "Value Loss": 11.554276466369629, "_runtime": 14387.378777265549, "_timestamp": 1585584303.2234106, "_step": 197}
{"Episode reward": -99.82077632546286, "Episode length": 999, "Policy Loss": -0.6931174993515015, "Value Loss": 0.027313396334648132, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914, -0.006653433199971914]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-1.7935595512390137, -1.762161374092102, -1.73076331615448, -1.6993651390075684, -1.6679669618606567, -1.6365687847137451, -1.605170726776123, -1.5737725496292114, -1.5423743724822998, -1.5109763145446777, -1.4795781373977661, -1.4481799602508545, -1.4167819023132324, -1.3853837251663208, -1.3539855480194092, -1.3225873708724976, -1.291189193725586, -1.2597911357879639, -1.2283929586410522, -1.1969947814941406, -1.1655967235565186, -1.134198546409607, -1.1028003692626953, -1.0714023113250732, -1.0400041341781616, -1.00860595703125, -0.9772078394889832, -0.9458096623420715, -0.9144115447998047, -0.8830133676528931, -0.8516152501106262, -0.8202170729637146, -0.7888189554214478, -0.7574207782745361, -0.7260227203369141, -0.6946245431900024, -0.6632263660430908, -0.6318281888961792, -0.6004301309585571, -0.5690319538116455, -0.5376337766647339, -0.5062357187271118, -0.4748375415802002, -0.4434393644332886, -0.41204118728637695, -0.3806431293487549, -0.34924495220184326, -0.31784677505493164, -0.28644871711730957, -0.25505053997039795, -0.22365236282348633, -0.1922541856765747, -0.16085612773895264, -0.12945795059204102, -0.0980597734451294, -0.06666159629821777, -0.0352635383605957, -0.003865361213684082, 0.02753281593322754, 0.05893087387084961, 0.09032905101776123, 0.12172722816467285, 0.15312540531158447, 0.18452346324920654, 0.21592164039611816]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.05536705628037453, -0.054428666830062866, -0.053490277379751205, -0.052551887929439545, -0.051613498479127884, -0.05067510902881622, -0.04973671957850456, -0.0487983301281929, -0.04785994067788124, -0.04692155122756958, -0.04598316550254822, -0.04504477232694626, -0.044106386601924896, -0.04316799342632294, -0.042229607701301575, -0.041291218250989914, -0.04035282880067825, -0.03941443935036659, -0.03847604990005493, -0.03753766044974327, -0.03659927099943161, -0.03566088154911995, -0.03472249209880829, -0.03378410264849663, -0.03284571319818497, -0.031907323747873306, -0.030968934297561646, -0.030030546709895134, -0.029092157259583473, -0.028153767809271812, -0.02721537835896015, -0.02627698890864849, -0.02533859945833683, -0.02440021000802517, -0.023461822420358658, -0.022523432970046997, -0.021585043519735336, -0.020646654069423676, -0.019708264619112015, -0.018769875168800354, -0.017831485718488693, -0.016893096268177032, -0.01595470681786537, -0.015016317367553711, -0.01407792791724205, -0.01313953846693039, -0.012201149016618729, -0.011262759566307068, -0.010324370115995407, -0.009385980665683746, -0.008447591215372086, -0.007509201765060425, -0.006570812314748764, -0.005632422864437103, -0.004694037139415741, -0.00375564768910408, -0.0028172582387924194, -0.0018788687884807587, -0.0009404793381690979, -2.089887857437134e-06, 0.0009362995624542236, 0.0018746890127658844, 0.002813078463077545, 0.003751467913389206, 0.004689857363700867]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 29.0, 380.0, 15.0, 3.0, 12.0, 10.0, 10.0, 1.0, 1.0, 1.0, 0.0, 8.0], "bins": [-0.2673156261444092, -0.26227450370788574, -0.2572333812713623, -0.25219225883483887, -0.24715115129947662, -0.24211002886295319, -0.23706890642642975, -0.2320277839899063, -0.22698667645454407, -0.22194555401802063, -0.2169044315814972, -0.21186330914497375, -0.20682218670845032, -0.20178106427192688, -0.19673994183540344, -0.1916988343000412, -0.18665771186351776, -0.18161658942699432, -0.17657548189163208, -0.17153435945510864, -0.1664932370185852, -0.16145211458206177, -0.15641099214553833, -0.1513698697090149, -0.14632874727249146, -0.1412876397371292, -0.13624651730060577, -0.13120539486408234, -0.1261642724275589, -0.12112314999103546, -0.11608204245567322, -0.11104092001914978, -0.10599979758262634, -0.1009586751461029, -0.09591755270957947, -0.09087644517421722, -0.08583532273769379, -0.08079420030117035, -0.07575307786464691, -0.07071195542812347, -0.06567084789276123, -0.06062972545623779, -0.055588603019714355, -0.05054748058319092, -0.04550635814666748, -0.04046523571014404, -0.0354241281747818, -0.030383005738258362, -0.025341883301734924, -0.020300760865211487, -0.015259653329849243, -0.010218530893325806, -0.005177408456802368, -0.00013628602027893066, 0.004904836416244507, 0.009945958852767944, 0.014987081289291382, 0.02002820372581482, 0.025069326162338257, 0.030110418796539307, 0.035151541233062744, 0.04019266366958618, 0.04523378610610962, 0.05027490854263306, 0.055316030979156494]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 8.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.43828436732292175, -0.4280007481575012, -0.4177170991897583, -0.40743348002433777, -0.39714986085891724, -0.3868662118911743, -0.3765825927257538, -0.36629897356033325, -0.35601532459259033, -0.3457316756248474, -0.3354480564594269, -0.32516443729400635, -0.3148807883262634, -0.3045971691608429, -0.29431354999542236, -0.28402990102767944, -0.2737462818622589, -0.2634626626968384, -0.25317901372909546, -0.24289539456367493, -0.2326117604970932, -0.22232812643051147, -0.21204450726509094, -0.20176087319850922, -0.1914772391319275, -0.18119361996650696, -0.17090997099876404, -0.1606263518333435, -0.15034273266792297, -0.14005908370018005, -0.12977546453475952, -0.1194918155670166, -0.10920819640159607, -0.09892457723617554, -0.08864092826843262, -0.07835730910301208, -0.06807366013526917, -0.05779004096984863, -0.0475064218044281, -0.03722277283668518, -0.02693915367126465, -0.016655534505844116, -0.006371885538101196, 0.003911733627319336, 0.014195352792739868, 0.024479001760482788, 0.03476262092590332, 0.04504626989364624, 0.05532988905906677, 0.06561353802680969, 0.07589712738990784, 0.08618077635765076, 0.09646442532539368, 0.10674801468849182, 0.11703166365623474, 0.12731531262397766, 0.1375989019870758, 0.14788255095481873, 0.15816619992256165, 0.16844984889030457, 0.1787334382534027, 0.18901708722114563, 0.19930073618888855, 0.2095843255519867, 0.21986797451972961]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 5.0, 2.0, 4.0, 1.0, 17.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07330585271120071, -0.07086622714996338, -0.06842659413814545, -0.06598696857690811, -0.06354734301567078, -0.06110771372914314, -0.05866808444261551, -0.056228458881378174, -0.05378882959485054, -0.051349200308322906, -0.04890957474708557, -0.04646994546055794, -0.044030316174030304, -0.04159069061279297, -0.039151061326265335, -0.036711435765028, -0.034271806478500366, -0.03183217719197273, -0.029392551630735397, -0.026952922344207764, -0.02451329678297043, -0.022073667496442795, -0.01963403820991516, -0.017194412648677826, -0.014754783362150192, -0.012315154075622559, -0.009875528514385223, -0.007435902953147888, -0.004996269941329956, -0.002556644380092621, -0.00011701881885528564, 0.0023226141929626465, 0.004762239754199982, 0.007201865315437317, 0.009641498327255249, 0.012081123888492584, 0.01452074944972992, 0.01696038246154785, 0.019400008022785187, 0.021839633584022522, 0.024279259145259857, 0.02671889215707779, 0.029158517718315125, 0.03159814327955246, 0.03403777629137039, 0.03647740185260773, 0.03891702741384506, 0.041356660425662994, 0.04379628598690033, 0.046235911548137665, 0.0486755445599556, 0.05111517012119293, 0.05355479568243027, 0.0559944286942482, 0.05843404680490494, 0.06087367981672287, 0.0633133128285408, 0.06575293093919754, 0.06819256395101547, 0.0706321969628334, 0.07307181507349014, 0.07551144808530807, 0.07795108109712601, 0.08039069920778275, 0.08283033221960068]}, "_runtime": 14388.976716279984, "_timestamp": 1585584304.8213496, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6524094343185425, "Value Loss": 0.02576926164329052, "_runtime": 14390.546828269958, "_timestamp": 1585584306.3914616, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7113854289054871, "Value Loss": 0.01680697873234749, "_runtime": 14392.17293047905, "_timestamp": 1585584308.0175638, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7266574501991272, "Value Loss": 0.032429762184619904, "_runtime": 14393.757755279541, "_timestamp": 1585584309.6023886, "_step": 201}
{"Episode reward": -99.8569111108766, "Episode length": 999, "Policy Loss": -0.7329689860343933, "Value Loss": 0.02138163521885872, "_runtime": 14395.017747163773, "_timestamp": 1585584310.8623805, "_step": 202}
{"Episode reward": 20.768797302246327, "Episode length": 793, "Policy Loss": 0.4540741741657257, "Value Loss": 12.546500205993652, "_runtime": 14396.593308448792, "_timestamp": 1585584312.4379418, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7676944732666016, "Value Loss": 0.0197908952832222, "_runtime": 14398.189956903458, "_timestamp": 1585584314.0345902, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7810783386230469, "Value Loss": 0.010759769007563591, "_runtime": 14399.754915475845, "_timestamp": 1585584315.5995488, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7943196296691895, "Value Loss": 0.017249517142772675, "_runtime": 14401.341684818268, "_timestamp": 1585584317.1863182, "_step": 206}
{"Episode reward": -99.87053375244001, "Episode length": 999, "Policy Loss": -0.7953304052352905, "Value Loss": 0.013329767622053623, "_runtime": 14402.939810991287, "_timestamp": 1585584318.7844443, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7879741191864014, "Value Loss": 0.01005973108112812, "_runtime": 14404.530915021896, "_timestamp": 1585584320.3755484, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7844458818435669, "Value Loss": 0.00991120096296072, "_runtime": 14404.921333551407, "_timestamp": 1585584320.765967, "_step": 209}
{"Episode reward": 78.99999999999997, "Episode length": 210, "Policy Loss": 3.5499415397644043, "Value Loss": 47.52135467529297, "_runtime": 14406.51622581482, "_timestamp": 1585584322.3608592, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6947448253631592, "Value Loss": 0.006314966361969709, "_runtime": 14407.305678367615, "_timestamp": 1585584323.1503117, "_step": 211}
{"Episode reward": 51.999999999999595, "Episode length": 480, "Policy Loss": 2.112055778503418, "Value Loss": 20.679094314575195, "_runtime": 14408.831058502197, "_timestamp": 1585584324.6756918, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5521442294120789, "Value Loss": 0.034958794713020325, "_runtime": 14410.44590640068, "_timestamp": 1585584326.2905397, "_step": 213}
{"Episode reward": -99.84843086153128, "Episode length": 999, "Policy Loss": -0.4970552623271942, "Value Loss": 0.01709464006125927, "_runtime": 14411.741427898407, "_timestamp": 1585584327.5860612, "_step": 214}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": 0.6872124671936035, "Value Loss": 11.673129081726074, "_runtime": 14413.317715644836, "_timestamp": 1585584329.162349, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4123460650444031, "Value Loss": 0.07503470778465271, "_runtime": 14414.531561136246, "_timestamp": 1585584330.3761945, "_step": 216}
{"Episode reward": 24.300000000000026, "Episode length": 757, "Policy Loss": 0.8995490074157715, "Value Loss": 13.093637466430664, "_runtime": 14416.137585878372, "_timestamp": 1585584331.9822192, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32249897718429565, "Value Loss": 0.10654989629983902, "_runtime": 14417.114319324493, "_timestamp": 1585584332.9589527, "_step": 218}
{"Episode reward": 39.299999999999415, "Episode length": 607, "Policy Loss": 1.2629204988479614, "Value Loss": 16.273956298828125, "_runtime": 14418.031855344772, "_timestamp": 1585584333.8764887, "_step": 219}
{"Episode reward": 42.29999999999946, "Episode length": 577, "Policy Loss": 1.365817904472351, "Value Loss": 17.16797637939453, "_runtime": 14419.620606660843, "_timestamp": 1585584335.46524, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29340675473213196, "Value Loss": 0.021459810435771942, "_runtime": 14420.607991456985, "_timestamp": 1585584336.4526248, "_step": 221}
{"Episode reward": 37.79999999999939, "Episode length": 622, "Policy Loss": 1.7465656995773315, "Value Loss": 15.87023639678955, "_runtime": 14421.558943748474, "_timestamp": 1585584337.403577, "_step": 222}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 1.1748183965682983, "Value Loss": 16.25042152404785, "_runtime": 14423.146993637085, "_timestamp": 1585584338.991627, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4528658986091614, "Value Loss": 0.16027584671974182, "_runtime": 14424.68818473816, "_timestamp": 1585584340.532818, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44569772481918335, "Value Loss": 0.09313896298408508, "_runtime": 14426.249962568283, "_timestamp": 1585584342.094596, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5283117294311523, "Value Loss": 0.07653676718473434, "_runtime": 14427.841136693954, "_timestamp": 1585584343.68577, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5354050397872925, "Value Loss": 0.06359748542308807, "_runtime": 14429.128566741943, "_timestamp": 1585584344.9732, "_step": 227}
{"Episode reward": 19.200000000000315, "Episode length": 808, "Policy Loss": 0.5880586504936218, "Value Loss": 12.259319305419922, "_runtime": 14430.714022159576, "_timestamp": 1585584346.5586555, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6950200796127319, "Value Loss": 0.017454003915190697, "_runtime": 14432.275809049606, "_timestamp": 1585584348.1204424, "_step": 229}
{"Episode reward": 1.1000000000013443, "Episode length": 989, "Policy Loss": 0.2526586353778839, "Value Loss": 10.024815559387207, "_runtime": 14433.842862129211, "_timestamp": 1585584349.6874955, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8204371929168701, "Value Loss": 0.009510673582553864, "_runtime": 14435.425075531006, "_timestamp": 1585584351.2697089, "_step": 231}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.23868291079998016, "Value Loss": 10.021714210510254, "_runtime": 14437.029392957687, "_timestamp": 1585584352.8740263, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8786818385124207, "Value Loss": 0.021368108689785004, "_runtime": 14438.60989522934, "_timestamp": 1585584354.4545286, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8680132031440735, "Value Loss": 0.028138617053627968, "_runtime": 14440.222764492035, "_timestamp": 1585584356.0673978, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9392803907394409, "Value Loss": 0.01719668321311474, "_runtime": 14441.418823480606, "_timestamp": 1585584357.2634568, "_step": 235}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 0.5537410378456116, "Value Loss": 13.321540832519531, "_runtime": 14443.00479888916, "_timestamp": 1585584358.8494322, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9259282350540161, "Value Loss": 0.022683454677462578, "_runtime": 14444.602757453918, "_timestamp": 1585584360.4473908, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9325920343399048, "Value Loss": 0.02256295457482338, "_runtime": 14445.883014440536, "_timestamp": 1585584361.7276478, "_step": 238}
{"Episode reward": 19.400000000000304, "Episode length": 806, "Policy Loss": 0.46633073687553406, "Value Loss": 12.3375244140625, "_runtime": 14447.482068777084, "_timestamp": 1585584363.326702, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8993896245956421, "Value Loss": 0.012827775441110134, "_runtime": 14449.080923557281, "_timestamp": 1585584364.925557, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8819803595542908, "Value Loss": 0.01767837256193161, "_runtime": 14450.6429708004, "_timestamp": 1585584366.4876041, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8719614744186401, "Value Loss": 0.01123217772692442, "_runtime": 14451.401213884354, "_timestamp": 1585584367.2458472, "_step": 242}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 1.331001877784729, "Value Loss": 21.668415069580078, "_runtime": 14452.99753499031, "_timestamp": 1585584368.8421683, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8113112449645996, "Value Loss": 0.015334117226302624, "_runtime": 14454.591331481934, "_timestamp": 1585584370.4359648, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7658982872962952, "Value Loss": 0.0073463222943246365, "_runtime": 14456.110655784607, "_timestamp": 1585584371.9552891, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7226597666740417, "Value Loss": 0.006531025283038616, "_runtime": 14457.69892692566, "_timestamp": 1585584373.5435603, "_step": 246}
{"Episode reward": -99.80676050782064, "Episode length": 999, "Policy Loss": -0.6878767609596252, "Value Loss": 0.031162645667791367, "_runtime": 14459.098247766495, "_timestamp": 1585584374.942881, "_step": 247}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 0.6101396083831787, "Value Loss": 11.213844299316406, "_runtime": 14460.013244390488, "_timestamp": 1585584375.8578777, "_step": 248}
{"Episode reward": 43.01142138838715, "Episode length": 570, "Policy Loss": 1.1689668893814087, "Value Loss": 17.359172821044922, "_runtime": 14461.595499515533, "_timestamp": 1585584377.4401329, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6145501732826233, "Value Loss": 0.10926927626132965, "_runtime": 14463.229615211487, "_timestamp": 1585584379.0742486, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.549323320388794, "Value Loss": 0.010313250124454498, "_runtime": 14464.441005468369, "_timestamp": 1585584380.2856388, "_step": 251}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.8069455027580261, "Value Loss": 12.676125526428223, "_runtime": 14465.96827864647, "_timestamp": 1585584381.812912, "_step": 252}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.5491181015968323, "Value Loss": 10.206095695495605, "_runtime": 14466.615863084793, "_timestamp": 1585584382.4604964, "_step": 253}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 2.0155763626098633, "Value Loss": 25.66933822631836, "_runtime": 14468.18395280838, "_timestamp": 1585584384.0285861, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5127294063568115, "Value Loss": 0.023368576541543007, "_runtime": 14469.779736042023, "_timestamp": 1585584385.6243694, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5703335404396057, "Value Loss": 0.10161183774471283, "_runtime": 14470.714224100113, "_timestamp": 1585584386.5588574, "_step": 256}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": 1.1582163572311401, "Value Loss": 16.04359245300293, "_runtime": 14472.29143500328, "_timestamp": 1585584388.1360683, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.588684618473053, "Value Loss": 0.10417704284191132, "_runtime": 14473.88283920288, "_timestamp": 1585584389.7274725, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5821396708488464, "Value Loss": 0.06889786571264267, "_runtime": 14475.420928478241, "_timestamp": 1585584391.2655618, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5723702907562256, "Value Loss": 0.021879592910408974, "_runtime": 14477.018650531769, "_timestamp": 1585584392.8632839, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6148839592933655, "Value Loss": 0.060589686036109924, "_runtime": 14478.617787361145, "_timestamp": 1585584394.4624207, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6620895266532898, "Value Loss": 0.024137062951922417, "_runtime": 14480.16476726532, "_timestamp": 1585584396.0094006, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6621048450469971, "Value Loss": 0.012733325362205505, "_runtime": 14481.766915798187, "_timestamp": 1585584397.6115491, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7273960709571838, "Value Loss": 0.03532851114869118, "_runtime": 14483.375844240189, "_timestamp": 1585584399.2204776, "_step": 264}
{"Episode reward": -99.848210239409, "Episode length": 999, "Policy Loss": -0.7607185244560242, "Value Loss": 0.00789236556738615, "_runtime": 14484.959557533264, "_timestamp": 1585584400.8041909, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8123836517333984, "Value Loss": 0.015450738370418549, "_runtime": 14485.36944103241, "_timestamp": 1585584401.2140744, "_step": 266}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 3.666099786758423, "Value Loss": 43.5162239074707, "_runtime": 14486.944795846939, "_timestamp": 1585584402.7894292, "_step": 267}
{"Episode reward": 3.1000000000012307, "Episode length": 969, "Policy Loss": 0.38967597484588623, "Value Loss": 10.245134353637695, "_runtime": 14488.460000753403, "_timestamp": 1585584404.304634, "_step": 268}
{"Episode reward": 4.100000000001174, "Episode length": 959, "Policy Loss": 0.2903638482093811, "Value Loss": 10.353865623474121, "_runtime": 14489.310903549194, "_timestamp": 1585584405.155537, "_step": 269}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 1.5671930313110352, "Value Loss": 17.688024520874023, "_runtime": 14490.907355546951, "_timestamp": 1585584406.751989, "_step": 270}
{"Episode reward": -99.80257282852986, "Episode length": 999, "Policy Loss": -0.6822797656059265, "Value Loss": 0.02038823813199997, "_runtime": 14492.480953931808, "_timestamp": 1585584408.3255873, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5769162774085999, "Value Loss": 0.01651163026690483, "_runtime": 14493.750297784805, "_timestamp": 1585584409.5949311, "_step": 272}
{"Episode reward": 16.50000000000047, "Episode length": 835, "Policy Loss": 0.7203497886657715, "Value Loss": 11.820554733276367, "_runtime": 14495.350141763687, "_timestamp": 1585584411.194775, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5052511096000671, "Value Loss": 0.015026847831904888, "_runtime": 14496.949453830719, "_timestamp": 1585584412.7940872, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45821309089660645, "Value Loss": 0.016197554767131805, "_runtime": 14497.704679489136, "_timestamp": 1585584413.5493128, "_step": 275}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": 1.742043137550354, "Value Loss": 20.82101821899414, "_runtime": 14498.305112838745, "_timestamp": 1585584414.1497462, "_step": 276}
{"Episode reward": 64.19999999999976, "Episode length": 358, "Policy Loss": 2.3550896644592285, "Value Loss": 27.492149353027344, "_runtime": 14499.89017701149, "_timestamp": 1585584415.7348104, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39990919828414917, "Value Loss": 0.051020875573158264, "_runtime": 14501.077914714813, "_timestamp": 1585584416.922548, "_step": 278}
{"Episode reward": 23.600000000000065, "Episode length": 764, "Policy Loss": 1.1542483568191528, "Value Loss": 13.13235855102539, "_runtime": 14502.583302497864, "_timestamp": 1585584418.4279358, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4020096957683563, "Value Loss": 0.054549407213926315, "_runtime": 14504.164011716843, "_timestamp": 1585584420.008645, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44246453046798706, "Value Loss": 0.19395984709262848, "_runtime": 14505.083755016327, "_timestamp": 1585584420.9283884, "_step": 281}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 1.511062741279602, "Value Loss": 17.10870361328125, "_runtime": 14505.766644001007, "_timestamp": 1585584421.6112773, "_step": 282}
{"Episode reward": 58.09999999999968, "Episode length": 419, "Policy Loss": 1.9304410219192505, "Value Loss": 23.48166275024414, "_runtime": 14506.269839286804, "_timestamp": 1585584422.1144726, "_step": 283}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 2.87955641746521, "Value Loss": 33.46492385864258, "_runtime": 14507.814485549927, "_timestamp": 1585584423.659119, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6680551171302795, "Value Loss": 0.20598027110099792, "_runtime": 14509.337401151657, "_timestamp": 1585584425.1820345, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.699289858341217, "Value Loss": 0.1646021157503128, "_runtime": 14510.883975505829, "_timestamp": 1585584426.7286088, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7714377045631409, "Value Loss": 0.1361967921257019, "_runtime": 14512.466957569122, "_timestamp": 1585584428.311591, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8392489552497864, "Value Loss": 0.018663059920072556, "_runtime": 14514.040710449219, "_timestamp": 1585584429.8853438, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9469237923622131, "Value Loss": 0.022072939202189445, "_runtime": 14515.600265741348, "_timestamp": 1585584431.444899, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.017577886581421, "Value Loss": 0.01170069258660078, "_runtime": 14517.193858146667, "_timestamp": 1585584433.0384915, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0916543006896973, "Value Loss": 0.015028304420411587, "_runtime": 14518.770369768143, "_timestamp": 1585584434.615003, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1146196126937866, "Value Loss": 0.05957556515932083, "_runtime": 14519.806934595108, "_timestamp": 1585584435.651568, "_step": 292}
{"Episode reward": 35.09999999999941, "Episode length": 649, "Policy Loss": 0.4686044752597809, "Value Loss": 15.257219314575195, "_runtime": 14521.400194644928, "_timestamp": 1585584437.244828, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2314789295196533, "Value Loss": 0.016979051753878593, "_runtime": 14522.990797519684, "_timestamp": 1585584438.8354309, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.254137396812439, "Value Loss": 0.021137341856956482, "_runtime": 14524.1940305233, "_timestamp": 1585584440.0386639, "_step": 295}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.2268611043691635, "Value Loss": 12.816548347473145, "_runtime": 14525.779600381851, "_timestamp": 1585584441.6242337, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2202357053756714, "Value Loss": 0.040441520512104034, "_runtime": 14527.367011547089, "_timestamp": 1585584443.211645, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.241943120956421, "Value Loss": 0.01799743063747883, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212, -0.0003548252279870212]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1621047854423523, -0.15238666534423828, -0.14266854524612427, -0.13295042514801025, -0.12323230504989624, -0.11351418495178223, -0.10379605740308762, -0.0940779373049736, -0.08435981720685959, -0.07464169710874557, -0.06492357701063156, -0.05520545691251755, -0.04548732936382294, -0.03576920926570892, -0.02605108916759491, -0.016332969069480896, -0.006614848971366882, 0.0031032711267471313, 0.012821391224861145, 0.02253951132297516, 0.03225763142108917, 0.041975751519203186, 0.0516938716173172, 0.06141199171543121, 0.07113012671470642, 0.08084824681282043, 0.09056636691093445, 0.10028448700904846, 0.11000260710716248, 0.11972072720527649, 0.1294388473033905, 0.13915696740150452, 0.14887508749961853, 0.15859320759773254, 0.16831132769584656, 0.17802944779396057, 0.18774756789207458, 0.1974656879901886, 0.2071838080883026, 0.21690192818641663, 0.22662004828453064, 0.23633816838264465, 0.24605628848075867, 0.2557744085788727, 0.2654925286769867, 0.2752106487751007, 0.2849287688732147, 0.29464688897132874, 0.30436503887176514, 0.31408315896987915, 0.32380127906799316, 0.3335193991661072, 0.3432375192642212, 0.3529556393623352, 0.3626737594604492, 0.37239187955856323, 0.38210999965667725, 0.39182811975479126, 0.4015462398529053, 0.4112643599510193, 0.4209824800491333, 0.4307006001472473, 0.44041872024536133, 0.45013684034347534, 0.45985496044158936]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0], "bins": [-0.005851845722645521, -0.00576041080057621, -0.005668975412845612, -0.0055775404907763, -0.005486105568706989, -0.005394670180976391, -0.00530323525890708, -0.0052118003368377686, -0.00512036494910717, -0.005028930027037859, -0.0049374946393072605, -0.004846059717237949, -0.004754624795168638, -0.00466318940743804, -0.004571754485368729, -0.00448031909763813, -0.004388884175568819, -0.004297449253499508, -0.0042060138657689095, -0.004114578943699598, -0.004023144021630287, -0.003931708633899689, -0.0038402737118303776, -0.0037488385569304228, -0.0036574036348611116, -0.003565968479961157, -0.003474533325061202, -0.003383098402991891, -0.003291663248091936, -0.0032002280931919813, -0.0031087929382920265, -0.0030173580162227154, -0.0029259228613227606, -0.002834487706422806, -0.0027430527843534946, -0.00265161762945354, -0.002560182474553585, -0.0024687473196536303, -0.002377312397584319, -0.0022858772426843643, -0.0021944420877844095, -0.0021030071657150984, -0.0020115720108151436, -0.0019201370887458324, -0.001828701701015234, -0.0017372667789459229, -0.0016458313912153244, -0.0015543964691460133, -0.0014629615470767021, -0.0013715261593461037, -0.0012800912372767925, -0.0011886563152074814, -0.001097220927476883, -0.0010057860054075718, -0.0009143510833382607, -0.0008229156956076622, -0.0007314807735383511, -0.0006400458514690399, -0.0005486104637384415, -0.0004571755416691303, -0.0003657401539385319, -0.00027430523186922073, -0.0001828703097999096, -9.143492206931114e-05, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 3.0, 0.0, 7.0, 9.0, 13.0, 4.0, 12.0, 13.0, 14.0, 364.0, 0.0, 24.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0648450255393982, -0.06304211169481277, -0.061239197850227356, -0.05943628400564194, -0.05763337016105652, -0.0558304563164711, -0.05402754247188568, -0.05222462862730026, -0.050421714782714844, -0.048618800938129425, -0.046815887093544006, -0.04501297324895859, -0.04321006312966347, -0.04140714928507805, -0.03960423544049263, -0.03780132159590721, -0.03599840775132179, -0.034195493906736374, -0.032392580062150955, -0.030589666217565536, -0.028786752372980118, -0.0269838385283947, -0.02518092468380928, -0.02337801083922386, -0.02157510071992874, -0.019772186875343323, -0.017969273030757904, -0.016166359186172485, -0.014363445341587067, -0.012560531497001648, -0.01075761765241623, -0.00895470380783081, -0.007151789963245392, -0.005348876118659973, -0.0035459622740745544, -0.0017430484294891357, 5.986541509628296e-05, 0.0018627792596817017, 0.0036656931042671204, 0.005468606948852539, 0.007271520793437958, 0.009074434638023376, 0.010877348482608795, 0.012680262327194214, 0.014483176171779633, 0.01628609001636505, 0.01808900386095047, 0.01989191770553589, 0.02169482409954071, 0.02349773794412613, 0.025300651788711548, 0.027103565633296967, 0.028906479477882385, 0.030709393322467804, 0.03251230716705322, 0.03431522101163864, 0.03611813485622406, 0.03792104870080948, 0.0397239625453949, 0.041526876389980316, 0.043329790234565735, 0.045132704079151154, 0.04693561792373657, 0.04873853176832199, 0.05054144561290741]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.03811956197023392, -0.03598020598292351, -0.0338408537209034, -0.03170149773359299, -0.029562143608927727, -0.027422789484262466, -0.025283433496952057, -0.023144079372286797, -0.021004725247621536, -0.018865371122956276, -0.016726016998291016, -0.014586661010980606, -0.012447306886315346, -0.010307952761650085, -0.008168596774339676, -0.006029244512319565, -0.0038898885250091553, -0.0017505325376987457, 0.00038881972432136536, 0.002528175711631775, 0.004667527973651886, 0.0068068839609622955, 0.008946239948272705, 0.011085592210292816, 0.013224948197603226, 0.015364304184913635, 0.017503656446933746, 0.019643012434244156, 0.021782368421554565, 0.023921720683574677, 0.026061072945594788, 0.028200432658195496, 0.030339784920215607, 0.03247913718223572, 0.034618496894836426, 0.03675784915685654, 0.03889720141887665, 0.041036561131477356, 0.04317591339349747, 0.04531526565551758, 0.04745461791753769, 0.0495939776301384, 0.05173332989215851, 0.05387268215417862, 0.05601204186677933, 0.05815139412879944, 0.06029074639081955, 0.06243010610342026, 0.06456945836544037, 0.06670881062746048, 0.06884817034006119, 0.0709875226020813, 0.07312687486410141, 0.07526623457670212, 0.07740558683872223, 0.07954493910074234, 0.08168429881334305, 0.08382365107536316, 0.08596300333738327, 0.08810236304998398, 0.09024170786142349, 0.0923810675740242, 0.09452042728662491, 0.09665977209806442, 0.09879913181066513]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 18.0, 0.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.05374612286686897, -0.05221923813223839, -0.0506923533976078, -0.04916546866297722, -0.04763858765363693, -0.04611170291900635, -0.04458481818437576, -0.04305793344974518, -0.041531048715114594, -0.04000416398048401, -0.038477279245853424, -0.03695039451122284, -0.035423509776592255, -0.03389662504196167, -0.032369744032621384, -0.0308428592979908, -0.029315974563360214, -0.02778908982872963, -0.026262205094099045, -0.02473532222211361, -0.023208437487483025, -0.02168155461549759, -0.020154669880867004, -0.01862778514623642, -0.017100900411605835, -0.01557401567697525, -0.014047130942344666, -0.01252024620771408, -0.010993365198373795, -0.00946648046374321, -0.007939595729112625, -0.00641271099448204, -0.004885826259851456, -0.003358941525220871, -0.0018320567905902863, -0.00030517205595970154, 0.0012217126786708832, 0.0027485936880111694, 0.004275478422641754, 0.005802363157272339, 0.007329247891902924, 0.00885612890124321, 0.010383013635873795, 0.01190989837050438, 0.013436783105134964, 0.014963667839765549, 0.016490552574396133, 0.018017437309026718, 0.019544322043657303, 0.021071206778287888, 0.022598091512918472, 0.024124976247549057, 0.02565186098217964, 0.027178745716810226, 0.02870563045144081, 0.030232515186071396, 0.031759392470121384, 0.03328627720475197, 0.03481316193938255, 0.03634004667401314, 0.03786693140864372, 0.03939381614327431, 0.04092070087790489, 0.04244758561253548, 0.04397447034716606]}, "_runtime": 14528.924977064133, "_timestamp": 1585584444.7696104, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2183345556259155, "Value Loss": 0.02294216863811016, "_runtime": 14530.520372629166, "_timestamp": 1585584446.365006, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1898325681686401, "Value Loss": 0.016932444646954536, "_runtime": 14531.758346557617, "_timestamp": 1585584447.60298, "_step": 300}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.2338111847639084, "Value Loss": 12.80890941619873, "_runtime": 14533.00454878807, "_timestamp": 1585584448.8491821, "_step": 301}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.2577419877052307, "Value Loss": 12.644542694091797, "_runtime": 14534.64066362381, "_timestamp": 1585584450.485297, "_step": 302}
{"Episode reward": -99.85047380924085, "Episode length": 999, "Policy Loss": -1.066593050956726, "Value Loss": 0.016261601820588112, "_runtime": 14535.817418813705, "_timestamp": 1585584451.6620522, "_step": 303}
{"Episode reward": 25.99999999999993, "Episode length": 740, "Policy Loss": 0.4041340947151184, "Value Loss": 13.406950950622559, "_runtime": 14537.384958744049, "_timestamp": 1585584453.229592, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9999542832374573, "Value Loss": 0.0214989110827446, "_runtime": 14538.97533583641, "_timestamp": 1585584454.8199692, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9325564503669739, "Value Loss": 0.00958985649049282, "_runtime": 14540.004097700119, "_timestamp": 1585584455.848731, "_step": 306}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.7514328956604004, "Value Loss": 15.281742095947266, "_runtime": 14541.590560436249, "_timestamp": 1585584457.4351938, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8304846882820129, "Value Loss": 0.011190060526132584, "_runtime": 14543.18547964096, "_timestamp": 1585584459.030113, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8131635189056396, "Value Loss": 0.019445255398750305, "_runtime": 14544.611561536789, "_timestamp": 1585584460.4561949, "_step": 309}
{"Episode reward": 8.20000000000094, "Episode length": 918, "Policy Loss": 0.4668657183647156, "Value Loss": 10.76177978515625, "_runtime": 14545.02863240242, "_timestamp": 1585584460.8732657, "_step": 310}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 3.80950927734375, "Value Loss": 43.2747917175293, "_runtime": 14546.159487009048, "_timestamp": 1585584462.0041203, "_step": 311}
{"Episode reward": 28.99999999999976, "Episode length": 710, "Policy Loss": 0.7404141426086426, "Value Loss": 13.93956470489502, "_runtime": 14546.54502773285, "_timestamp": 1585584462.389661, "_step": 312}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 4.769306182861328, "Value Loss": 44.63469314575195, "_runtime": 14548.057563304901, "_timestamp": 1585584463.9021966, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6129439473152161, "Value Loss": 0.12054610252380371, "_runtime": 14549.619256019592, "_timestamp": 1585584465.4638894, "_step": 314}
{"Episode reward": 0.10000000000140119, "Episode length": 999, "Policy Loss": 0.5302433967590332, "Value Loss": 9.950044631958008, "_runtime": 14551.128098011017, "_timestamp": 1585584466.9727314, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5403527021408081, "Value Loss": 0.0386885404586792, "_runtime": 14552.70788025856, "_timestamp": 1585584468.5525136, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6444222331047058, "Value Loss": 0.17584644258022308, "_runtime": 14554.29370689392, "_timestamp": 1585584470.1383402, "_step": 317}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 0.47987616062164307, "Value Loss": 9.975114822387695, "_runtime": 14555.740428686142, "_timestamp": 1585584471.585062, "_step": 318}
{"Episode reward": 6.700000000001026, "Episode length": 933, "Policy Loss": 0.2585674524307251, "Value Loss": 10.73477840423584, "_runtime": 14556.301210641861, "_timestamp": 1585584472.145844, "_step": 319}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": 2.657773733139038, "Value Loss": 30.43003273010254, "_runtime": 14557.717781543732, "_timestamp": 1585584473.562415, "_step": 320}
{"Episode reward": 10.50000000000081, "Episode length": 895, "Policy Loss": 0.40591269731521606, "Value Loss": 10.975679397583008, "_runtime": 14558.982249736786, "_timestamp": 1585584474.826883, "_step": 321}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.9289873838424683, "Value Loss": 12.658404350280762, "_runtime": 14560.186824083328, "_timestamp": 1585584476.0314574, "_step": 322}
{"Episode reward": 19.900000000000276, "Episode length": 801, "Policy Loss": 0.3620152175426483, "Value Loss": 12.480618476867676, "_runtime": 14561.741003274918, "_timestamp": 1585584477.5856366, "_step": 323}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.027782084420323372, "Value Loss": 10.1506929397583, "_runtime": 14563.302415132523, "_timestamp": 1585584479.1470485, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9348019361495972, "Value Loss": 0.11031481623649597, "_runtime": 14564.859147071838, "_timestamp": 1585584480.7037804, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0447267293930054, "Value Loss": 0.07480639964342117, "_runtime": 14566.44789481163, "_timestamp": 1585584482.2925282, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1779412031173706, "Value Loss": 0.049452174454927444, "_runtime": 14568.033926963806, "_timestamp": 1585584483.8785603, "_step": 327}
{"Episode reward": 0.6000000000013728, "Episode length": 994, "Policy Loss": -0.1319332867860794, "Value Loss": 9.986654281616211, "_runtime": 14569.38890171051, "_timestamp": 1585584485.233535, "_step": 328}
{"Episode reward": 13.900000000000617, "Episode length": 861, "Policy Loss": -0.053079672157764435, "Value Loss": 11.48996353149414, "_runtime": 14570.990112304688, "_timestamp": 1585584486.8347456, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.272881031036377, "Value Loss": 0.02947809360921383, "_runtime": 14572.267795801163, "_timestamp": 1585584488.1124291, "_step": 330}
{"Episode reward": 19.80000000000028, "Episode length": 802, "Policy Loss": 0.1275443285703659, "Value Loss": 12.409116744995117, "_runtime": 14573.84328866005, "_timestamp": 1585584489.687922, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3624167442321777, "Value Loss": 0.03298715129494667, "_runtime": 14574.808979272842, "_timestamp": 1585584490.6536126, "_step": 332}
{"Episode reward": 40.29999999999943, "Episode length": 597, "Policy Loss": 0.3748707175254822, "Value Loss": 16.57903289794922, "_runtime": 14576.382873535156, "_timestamp": 1585584492.2275069, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2896276712417603, "Value Loss": 0.048106350004673004, "_runtime": 14577.964904546738, "_timestamp": 1585584493.809538, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3499505519866943, "Value Loss": 0.01878095045685768, "_runtime": 14579.519811153412, "_timestamp": 1585584495.3644445, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3008822202682495, "Value Loss": 0.026490921154618263, "_runtime": 14581.10964679718, "_timestamp": 1585584496.9542801, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2765460014343262, "Value Loss": 0.031862523406744, "_runtime": 14581.860555887222, "_timestamp": 1585584497.7051892, "_step": 337}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 1.087155818939209, "Value Loss": 21.624935150146484, "_runtime": 14582.910253286362, "_timestamp": 1585584498.7548866, "_step": 338}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 0.44140124320983887, "Value Loss": 15.596570014953613, "_runtime": 14584.506243228912, "_timestamp": 1585584500.3508766, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1199978590011597, "Value Loss": 0.03286822512745857, "_runtime": 14585.183454036713, "_timestamp": 1585584501.0280874, "_step": 340}
{"Episode reward": 57.19999999999967, "Episode length": 428, "Policy Loss": 1.3771519660949707, "Value Loss": 23.095792770385742, "_runtime": 14585.84872841835, "_timestamp": 1585584501.6933618, "_step": 341}
{"Episode reward": 58.49999999999969, "Episode length": 415, "Policy Loss": 1.3730612993240356, "Value Loss": 23.77774429321289, "_runtime": 14587.438101053238, "_timestamp": 1585584503.2827344, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.97185218334198, "Value Loss": 0.03646927699446678, "_runtime": 14588.472831249237, "_timestamp": 1585584504.3174646, "_step": 343}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.5381655097007751, "Value Loss": 14.632739067077637, "_runtime": 14589.179520368576, "_timestamp": 1585584505.0241537, "_step": 344}
{"Episode reward": 54.39999999999963, "Episode length": 456, "Policy Loss": 1.3431339263916016, "Value Loss": 21.54781150817871, "_runtime": 14590.743749380112, "_timestamp": 1585584506.5883827, "_step": 345}
{"Episode reward": -99.80178995132306, "Episode length": 999, "Policy Loss": -0.8002394437789917, "Value Loss": 0.06427814066410065, "_runtime": 14592.271841049194, "_timestamp": 1585584508.1164744, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7464432716369629, "Value Loss": 0.01894371770322323, "_runtime": 14593.439178466797, "_timestamp": 1585584509.2838118, "_step": 347}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.6118414402008057, "Value Loss": 12.956053733825684, "_runtime": 14594.639238595963, "_timestamp": 1585584510.483872, "_step": 348}
{"Episode reward": 24.700000000000003, "Episode length": 753, "Policy Loss": 0.6846444606781006, "Value Loss": 13.058300971984863, "_runtime": 14596.114797353745, "_timestamp": 1585584511.9594307, "_step": 349}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.4097450375556946, "Value Loss": 10.466835975646973, "_runtime": 14597.687170743942, "_timestamp": 1585584513.531804, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7052931785583496, "Value Loss": 0.20328734815120697, "_runtime": 14599.235933542252, "_timestamp": 1585584515.080567, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6493582725524902, "Value Loss": 0.05210358276963234, "_runtime": 14600.797734737396, "_timestamp": 1585584516.642368, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8018355965614319, "Value Loss": 0.1361490786075592, "_runtime": 14602.039494752884, "_timestamp": 1585584517.884128, "_step": 353}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.5884982943534851, "Value Loss": 12.593452453613281, "_runtime": 14603.002447366714, "_timestamp": 1585584518.8470807, "_step": 354}
{"Episode reward": 40.799999999999436, "Episode length": 592, "Policy Loss": 1.0502043962478638, "Value Loss": 16.583133697509766, "_runtime": 14604.591156721115, "_timestamp": 1585584520.43579, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8625322580337524, "Value Loss": 0.3465941846370697, "_runtime": 14606.156825065613, "_timestamp": 1585584522.0014584, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7621335983276367, "Value Loss": 0.021823551505804062, "_runtime": 14606.86152935028, "_timestamp": 1585584522.7061627, "_step": 357}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 1.6210949420928955, "Value Loss": 23.954736709594727, "_runtime": 14607.372309207916, "_timestamp": 1585584523.2169425, "_step": 358}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 2.5793159008026123, "Value Loss": 32.33528137207031, "_runtime": 14608.140656471252, "_timestamp": 1585584523.9852898, "_step": 359}
{"Episode reward": 52.398760604858, "Episode length": 477, "Policy Loss": 1.1922693252563477, "Value Loss": 20.594581604003906, "_runtime": 14609.116910457611, "_timestamp": 1585584524.9615438, "_step": 360}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.5759217739105225, "Value Loss": 15.55147933959961, "_runtime": 14610.224274635315, "_timestamp": 1585584526.068908, "_step": 361}
{"Episode reward": 27.39999999999985, "Episode length": 726, "Policy Loss": 0.310860276222229, "Value Loss": 13.539924621582031, "_runtime": 14611.755486488342, "_timestamp": 1585584527.6001198, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0230555534362793, "Value Loss": 0.027428127825260162, "_runtime": 14613.073489189148, "_timestamp": 1585584528.9181225, "_step": 363}
{"Episode reward": 15.100000000000549, "Episode length": 849, "Policy Loss": 0.06438983976840973, "Value Loss": 11.601977348327637, "_runtime": 14613.869995594025, "_timestamp": 1585584529.714629, "_step": 364}
{"Episode reward": 48.499999999999545, "Episode length": 515, "Policy Loss": 0.8688547611236572, "Value Loss": 19.026931762695312, "_runtime": 14614.547899484634, "_timestamp": 1585584530.3925328, "_step": 365}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.4269731044769287, "Value Loss": 23.538619995117188, "_runtime": 14616.115811109543, "_timestamp": 1585584531.9604445, "_step": 366}
{"Episode reward": -99.80802040099958, "Episode length": 999, "Policy Loss": -1.0897369384765625, "Value Loss": 0.04591786488890648, "_runtime": 14616.851746797562, "_timestamp": 1585584532.6963801, "_step": 367}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.036218523979187, "Value Loss": 20.972427368164062, "_runtime": 14617.481137037277, "_timestamp": 1585584533.3257704, "_step": 368}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 1.713140606880188, "Value Loss": 24.10308265686035, "_runtime": 14619.05340719223, "_timestamp": 1585584534.8980405, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0696173906326294, "Value Loss": 0.2001885175704956, "_runtime": 14620.577984333038, "_timestamp": 1585584536.4226177, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.020904541015625, "Value Loss": 0.3042508661746979, "_runtime": 14621.801264047623, "_timestamp": 1585584537.6458974, "_step": 371}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.1436682790517807, "Value Loss": 12.33922004699707, "_runtime": 14623.395404815674, "_timestamp": 1585584539.2400382, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.042311668395996, "Value Loss": 0.1190740168094635, "_runtime": 14623.906851530075, "_timestamp": 1585584539.7514849, "_step": 373}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 2.085880994796753, "Value Loss": 32.05402374267578, "_runtime": 14624.523787975311, "_timestamp": 1585584540.3684213, "_step": 374}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 1.678037405014038, "Value Loss": 25.15753936767578, "_runtime": 14625.145837545395, "_timestamp": 1585584540.990471, "_step": 375}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.6009299755096436, "Value Loss": 25.80660629272461, "_runtime": 14626.675139188766, "_timestamp": 1585584542.5197725, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1245100498199463, "Value Loss": 0.051712002605199814, "_runtime": 14627.633161783218, "_timestamp": 1585584543.4777951, "_step": 377}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.459557443857193, "Value Loss": 15.70019245147705, "_runtime": 14629.137387990952, "_timestamp": 1585584544.9820213, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1440916061401367, "Value Loss": 0.03450959175825119, "_runtime": 14630.712625265121, "_timestamp": 1585584546.5572586, "_step": 379}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": -0.11917924135923386, "Value Loss": 10.173077583312988, "_runtime": 14632.31125998497, "_timestamp": 1585584548.1558933, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2940099239349365, "Value Loss": 0.3130655884742737, "_runtime": 14633.627851009369, "_timestamp": 1585584549.4724844, "_step": 381}
{"Episode reward": 15.900000000000503, "Episode length": 841, "Policy Loss": 0.10119128227233887, "Value Loss": 11.884910583496094, "_runtime": 14635.209543704987, "_timestamp": 1585584551.054177, "_step": 382}
{"Episode reward": -99.84147913455823, "Episode length": 999, "Policy Loss": -1.3256431818008423, "Value Loss": 0.23088257014751434, "_runtime": 14636.797256708145, "_timestamp": 1585584552.64189, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2821972370147705, "Value Loss": 0.12128530442714691, "_runtime": 14638.3588681221, "_timestamp": 1585584554.2035015, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4228262901306152, "Value Loss": 0.09654927253723145, "_runtime": 14639.448751926422, "_timestamp": 1585584555.2933853, "_step": 385}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.05614970624446869, "Value Loss": 14.608583450317383, "_runtime": 14639.734448671341, "_timestamp": 1585584555.579082, "_step": 386}
{"Episode reward": 86.20000000000005, "Episode length": 138, "Policy Loss": 5.689615726470947, "Value Loss": 71.22502899169922, "_runtime": 14641.30198431015, "_timestamp": 1585584557.1466177, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4371596574783325, "Value Loss": 0.045383647084236145, "_runtime": 14642.85965847969, "_timestamp": 1585584558.7042918, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4000169038772583, "Value Loss": 0.029228370636701584, "_runtime": 14643.445769786835, "_timestamp": 1585584559.2904031, "_step": 389}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 1.211185097694397, "Value Loss": 25.42055892944336, "_runtime": 14644.97694849968, "_timestamp": 1585584560.8215818, "_step": 390}
{"Episode reward": 2.1000000000012875, "Episode length": 979, "Policy Loss": -0.37419140338897705, "Value Loss": 10.080849647521973, "_runtime": 14646.135279655457, "_timestamp": 1585584561.979913, "_step": 391}
{"Episode reward": 27.068797302245954, "Episode length": 730, "Policy Loss": 0.04953814297914505, "Value Loss": 13.510130882263184, "_runtime": 14647.652960300446, "_timestamp": 1585584563.4975936, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2784061431884766, "Value Loss": 0.10998190939426422, "_runtime": 14649.248893022537, "_timestamp": 1585584565.0935264, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1980770826339722, "Value Loss": 0.10061655938625336, "_runtime": 14650.682775497437, "_timestamp": 1585584566.5274088, "_step": 394}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": -0.1322477161884308, "Value Loss": 10.846245765686035, "_runtime": 14651.56588768959, "_timestamp": 1585584567.410521, "_step": 395}
{"Episode reward": 44.199999999999484, "Episode length": 558, "Policy Loss": 0.5426563620567322, "Value Loss": 17.53675079345703, "_runtime": 14653.160281658173, "_timestamp": 1585584569.004915, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1648956537246704, "Value Loss": 0.019734855741262436, "_runtime": 14654.778462171555, "_timestamp": 1585584570.6230955, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0831042528152466, "Value Loss": 0.05277667194604874, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947, 0.006979450583457947]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.45208337903022766, -0.35416534543037415, -0.25624731183052063, -0.15832927823066711, -0.0604112446308136, 0.03750678896903992, 0.13542482256889343, 0.23334285616874695, 0.33126088976860046, 0.429178923368454, 0.5270969867706299, 0.6250150203704834, 0.7229330539703369, 0.8208510875701904, 0.918769121170044, 1.0166871547698975, 1.114605188369751, 1.2125232219696045, 1.310441255569458, 1.4083592891693115, 1.506277322769165, 1.6041953563690186, 1.702113389968872, 1.8000314235687256, 1.897949457168579, 1.9958674907684326, 2.093785524368286, 2.1917035579681396, 2.289621591567993, 2.3875396251678467, 2.4854576587677, 2.5833756923675537, 2.6812937259674072, 2.7792117595672607, 2.8771297931671143, 2.9750478267669678, 3.0729658603668213, 3.170883893966675, 3.2688019275665283, 3.366719961166382, 3.4646379947662354, 3.562556028366089, 3.6604740619659424, 3.758392095565796, 3.8563101291656494, 3.954228162765503, 4.052145957946777, 4.150063991546631, 4.247982025146484, 4.345900058746338, 4.443818092346191, 4.541736125946045, 4.639654159545898, 4.737572193145752, 4.8354902267456055, 4.933408260345459, 5.0313262939453125, 5.129244327545166, 5.2271623611450195, 5.325080394744873, 5.422998428344727, 5.52091646194458, 5.618834495544434, 5.716752529144287, 5.814670562744141]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0062232594937086105, -0.0048128766939044, -0.003402493428438902, -0.001992110162973404, -0.0005817273631691933, 0.0008286554366350174, 0.0022390391677618027, 0.0036494219675660133, 0.005059804767370224, 0.006470187567174435, 0.007880570366978645, 0.00929095409810543, 0.010701337829232216, 0.012111719697713852, 0.013522103428840637, 0.014932485297322273, 0.01634286902844906, 0.017753252759575844, 0.01916363462805748, 0.020574018359184265, 0.0219844002276659, 0.023394783958792686, 0.024805167689919472, 0.026215551421046257, 0.027625935152173042, 0.02903631515800953, 0.030446698889136314, 0.03185708075761795, 0.033267468214035034, 0.03467784821987152, 0.03608822822570801, 0.03749861568212509, 0.03890899568796158, 0.04031938314437866, 0.04172976315021515, 0.043140143156051636, 0.04455053061246872, 0.045960910618305206, 0.04737129807472229, 0.04878167808055878, 0.050192058086395264, 0.05160244554281235, 0.053012825548648834, 0.05442321300506592, 0.055833593010902405, 0.05724397301673889, 0.058654360473155975, 0.06006474047899246, 0.061475127935409546, 0.06288550794124603, 0.06429588794708252, 0.0657062754034996, 0.06711665540933609, 0.06852704286575317, 0.06993742287158966, 0.07134780287742615, 0.07275819033384323, 0.07416857033967972, 0.0755789577960968, 0.07698933780193329, 0.07839971780776978, 0.07981010526418686, 0.08122048527002335, 0.08263087272644043, 0.08404125273227692]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [13.0, 2.0, 0.0, 10.0, 36.0, 11.0, 415.0, 7.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.083860844373703, -0.0701742023229599, -0.0564875565469265, -0.0428009107708931, -0.029114268720149994, -0.015427626669406891, -0.001740977168083191, 0.011945664882659912, 0.025632306933403015, 0.03931894898414612, 0.05300559103488922, 0.06669223308563232, 0.08037889003753662, 0.09406553208827972, 0.10775217413902283, 0.12143881618976593, 0.13512545824050903, 0.14881210029125214, 0.16249874234199524, 0.17618539929389954, 0.18987202644348145, 0.20355868339538574, 0.21724531054496765, 0.23093196749687195, 0.24461862444877625, 0.25830525159835815, 0.27199190855026245, 0.28567853569984436, 0.29936519265174866, 0.31305181980133057, 0.32673847675323486, 0.3404251039028168, 0.35411176085472107, 0.36779841780662537, 0.3814850449562073, 0.3951717019081116, 0.4088583290576935, 0.4225449860095978, 0.4362316429615021, 0.4499182403087616, 0.4636048972606659, 0.4772915542125702, 0.4909782111644745, 0.5046648979187012, 0.5183514356613159, 0.5320380926132202, 0.5457247495651245, 0.5594114065170288, 0.5730980634689331, 0.5867847204208374, 0.6004713773727417, 0.614158034324646, 0.6278446912765503, 0.641531229019165, 0.6552178859710693, 0.6689045429229736, 0.6825911998748779, 0.6962778568267822, 0.7099645137786865, 0.7236511707305908, 0.7373378276824951, 0.7510244846343994, 0.7647110223770142, 0.7783976793289185, 0.7920843362808228]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.2559162378311157, -0.23911364376544952, -0.22231104969978333, -0.20550844073295593, -0.18870584666728973, -0.17190325260162354, -0.15510064363479614, -0.13829804956912994, -0.12149545550346375, -0.10469286143779755, -0.08789026737213135, -0.07108765840530396, -0.054285064339637756, -0.03748247027397156, -0.020679861307144165, -0.00387728214263916, 0.012925326824188232, 0.029727935791015625, 0.04653051495552063, 0.06333312392234802, 0.08013570308685303, 0.09693831205368042, 0.11374092102050781, 0.13054350018501282, 0.1473461091518402, 0.1641487181186676, 0.1809512972831726, 0.19775390625, 0.2145565152168274, 0.2313590943813324, 0.2481616735458374, 0.2649642825126648, 0.2817668914794922, 0.2985695004463196, 0.315372109413147, 0.3321746587753296, 0.348977267742157, 0.3657798767089844, 0.38258248567581177, 0.39938509464263916, 0.4161876440048218, 0.43299025297164917, 0.44979286193847656, 0.46659547090530396, 0.48339807987213135, 0.5002006888389587, 0.5170032382011414, 0.5338058471679688, 0.5506084561347961, 0.5674110651016235, 0.5842136740684509, 0.6010162234306335, 0.6178188323974609, 0.6346214413642883, 0.6514240503311157, 0.6682266592979431, 0.6850292682647705, 0.7018318176269531, 0.7186344265937805, 0.7354370355606079, 0.7522395849227905, 0.7690422534942627, 0.7858448028564453, 0.8026474714279175, 0.8194500207901001]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 18.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 5.0, 3.0, 4.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3562466502189636, -0.34918391704559326, -0.3421211838722229, -0.33505845069885254, -0.3279957175254822, -0.3209330141544342, -0.31387028098106384, -0.3068075478076935, -0.2997448146343231, -0.29268208146095276, -0.2856193482875824, -0.2785566449165344, -0.27149391174316406, -0.2644311785697937, -0.25736844539642334, -0.250305712223053, -0.24324297904968262, -0.23618024587631226, -0.2291175127029419, -0.22205479443073273, -0.21499206125736237, -0.207929328083992, -0.20086660981178284, -0.19380387663841248, -0.18674114346504211, -0.17967841029167175, -0.1726156771183014, -0.16555295884609222, -0.15849022567272186, -0.1514274924993515, -0.14436477422714233, -0.13730204105377197, -0.1302393078804016, -0.12317657470703125, -0.11611384153366089, -0.10905112326145172, -0.10198837518692017, -0.09492567181587219, -0.08786293864250183, -0.08080020546913147, -0.07373747229576111, -0.06667473912239075, -0.059612005949020386, -0.052549272775650024, -0.04548656940460205, -0.03842383623123169, -0.03136110305786133, -0.024298369884490967, -0.017235636711120605, -0.010172903537750244, -0.003110170364379883, 0.0039525628089904785, 0.01101529598236084, 0.018077999353408813, 0.025140732526779175, 0.032203465700149536, 0.0392661988735199, 0.04632893204689026, 0.05339166522026062, 0.06045439839363098, 0.06751710176467896, 0.07457983493804932, 0.08164256811141968, 0.08870530128479004, 0.0957680344581604]}, "_runtime": 14655.265356779099, "_timestamp": 1585584571.1099901, "_step": 398}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 2.213315725326538, "Value Loss": 32.16261672973633, "_runtime": 14656.838494300842, "_timestamp": 1585584572.6831276, "_step": 399}
{"Episode reward": -99.80891523957112, "Episode length": 999, "Policy Loss": -1.0405080318450928, "Value Loss": 0.11385040730237961, "_runtime": 14658.434578418732, "_timestamp": 1585584574.2792118, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0458674430847168, "Value Loss": 0.11284250766038895, "_runtime": 14659.950032711029, "_timestamp": 1585584575.794666, "_step": 401}
{"Episode reward": -99.83992166519025, "Episode length": 999, "Policy Loss": -1.0767755508422852, "Value Loss": 0.031446583569049835, "_runtime": 14660.867734193802, "_timestamp": 1585584576.7123675, "_step": 402}
{"Episode reward": 43.29999999999947, "Episode length": 567, "Policy Loss": 0.5592907667160034, "Value Loss": 17.415571212768555, "_runtime": 14662.451248645782, "_timestamp": 1585584578.295882, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.091607928276062, "Value Loss": 0.20353318750858307, "_runtime": 14664.03071975708, "_timestamp": 1585584579.875353, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.080437183380127, "Value Loss": 0.018553152680397034, "_runtime": 14665.568477869034, "_timestamp": 1585584581.4131112, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.094927430152893, "Value Loss": 0.07688901573419571, "_runtime": 14666.830207586288, "_timestamp": 1585584582.674841, "_step": 406}
{"Episode reward": 20.300000000000253, "Episode length": 797, "Policy Loss": 0.04396027326583862, "Value Loss": 12.38768196105957, "_runtime": 14668.411335468292, "_timestamp": 1585584584.2559688, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134947419166565, "Value Loss": 0.03566215932369232, "_runtime": 14669.992562294006, "_timestamp": 1585584585.8371956, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134619116783142, "Value Loss": 0.050114329904317856, "_runtime": 14671.277912139893, "_timestamp": 1585584587.1225455, "_step": 409}
{"Episode reward": 19.30000000000031, "Episode length": 807, "Policy Loss": 0.07126376032829285, "Value Loss": 12.274727821350098, "_runtime": 14672.849445104599, "_timestamp": 1585584588.6940784, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.174357295036316, "Value Loss": 0.02115030400454998, "_runtime": 14674.434286355972, "_timestamp": 1585584590.2789197, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.141344666481018, "Value Loss": 0.016860561445355415, "_runtime": 14675.424506425858, "_timestamp": 1585584591.2691398, "_step": 412}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.40863099694252014, "Value Loss": 15.91358757019043, "_runtime": 14677.003686666489, "_timestamp": 1585584592.84832, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0807085037231445, "Value Loss": 0.045145586133003235, "_runtime": 14678.634779453278, "_timestamp": 1585584594.4794128, "_step": 414}
{"Episode reward": -99.7953293323503, "Episode length": 999, "Policy Loss": -1.0247483253479004, "Value Loss": 0.014083588495850563, "_runtime": 14680.18868136406, "_timestamp": 1585584596.0333147, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9791684746742249, "Value Loss": 0.011558006517589092, "_runtime": 14680.83245062828, "_timestamp": 1585584596.677084, "_step": 416}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 2.768242835998535, "Value Loss": 26.020431518554688, "_runtime": 14682.419122934341, "_timestamp": 1585584598.2637563, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8589297533035278, "Value Loss": 0.011505866423249245, "_runtime": 14684.007058620453, "_timestamp": 1585584599.851692, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.796899139881134, "Value Loss": 0.008211115375161171, "_runtime": 14685.526914596558, "_timestamp": 1585584601.371548, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7388123273849487, "Value Loss": 0.00930805690586567, "_runtime": 14685.954378843307, "_timestamp": 1585584601.7990122, "_step": 420}
{"Episode reward": 76.79999999999995, "Episode length": 232, "Policy Loss": 3.8217427730560303, "Value Loss": 42.38626480102539, "_runtime": 14686.956645011902, "_timestamp": 1585584602.8012784, "_step": 421}
{"Episode reward": 37.299999999999386, "Episode length": 627, "Policy Loss": 0.9765048027038574, "Value Loss": 15.68043041229248, "_runtime": 14688.52872300148, "_timestamp": 1585584604.3733563, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5628657937049866, "Value Loss": 0.07249300926923752, "_runtime": 14689.380012750626, "_timestamp": 1585584605.224646, "_step": 423}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 1.2533931732177734, "Value Loss": 17.451025009155273, "_runtime": 14690.658884525299, "_timestamp": 1585584606.5035179, "_step": 424}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.823526918888092, "Value Loss": 11.984518051147461, "_runtime": 14691.533732175827, "_timestamp": 1585584607.3783655, "_step": 425}
{"Episode reward": 45.99999999999951, "Episode length": 540, "Policy Loss": 1.522865891456604, "Value Loss": 18.1423397064209, "_runtime": 14692.77179145813, "_timestamp": 1585584608.6164248, "_step": 426}
{"Episode reward": 19.600000000000293, "Episode length": 804, "Policy Loss": 0.8735592365264893, "Value Loss": 12.265308380126953, "_runtime": 14694.18219280243, "_timestamp": 1585584610.0268261, "_step": 427}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.584237277507782, "Value Loss": 11.079298973083496, "_runtime": 14695.72037434578, "_timestamp": 1585584611.5650077, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4250069260597229, "Value Loss": 0.07192706316709518, "_runtime": 14696.670448541641, "_timestamp": 1585584612.515082, "_step": 429}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 1.4072291851043701, "Value Loss": 16.238832473754883, "_runtime": 14697.854485273361, "_timestamp": 1585584613.6991186, "_step": 430}
{"Episode reward": 24.700000000000003, "Episode length": 753, "Policy Loss": 1.0144398212432861, "Value Loss": 12.98243522644043, "_runtime": 14699.231761455536, "_timestamp": 1585584615.0763948, "_step": 431}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": 0.6431068181991577, "Value Loss": 11.146418571472168, "_runtime": 14700.779298305511, "_timestamp": 1585584616.6239316, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5228060483932495, "Value Loss": 0.040587134659290314, "_runtime": 14702.14995765686, "_timestamp": 1585584617.994591, "_step": 433}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.4078168272972107, "Value Loss": 11.135866165161133, "_runtime": 14703.708416938782, "_timestamp": 1585584619.5530503, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7497882843017578, "Value Loss": 0.22301696240901947, "_runtime": 14705.303606748581, "_timestamp": 1585584621.14824, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6746034026145935, "Value Loss": 0.019383085891604424, "_runtime": 14706.908361673355, "_timestamp": 1585584622.752995, "_step": 436}
{"Episode reward": -99.80799276828625, "Episode length": 999, "Policy Loss": -0.7758080959320068, "Value Loss": 0.06896527111530304, "_runtime": 14708.50470995903, "_timestamp": 1585584624.3493433, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8299028873443604, "Value Loss": 0.1220635399222374, "_runtime": 14710.077661514282, "_timestamp": 1585584625.9222949, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9402055144309998, "Value Loss": 0.0425851084291935, "_runtime": 14711.361953258514, "_timestamp": 1585584627.2065866, "_step": 439}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.2700275182723999, "Value Loss": 12.391054153442383, "_runtime": 14712.244114875793, "_timestamp": 1585584628.0887482, "_step": 440}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 0.9093670845031738, "Value Loss": 18.03740692138672, "_runtime": 14713.824859380722, "_timestamp": 1585584629.6694927, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0770518779754639, "Value Loss": 0.08167081326246262, "_runtime": 14715.152075052261, "_timestamp": 1585584630.9967084, "_step": 442}
{"Episode reward": 15.900000000000503, "Episode length": 841, "Policy Loss": 0.3259943127632141, "Value Loss": 11.709165573120117, "_runtime": 14716.693552494049, "_timestamp": 1585584632.5381858, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0958601236343384, "Value Loss": 0.023304929956793785, "_runtime": 14717.37971830368, "_timestamp": 1585584633.2243516, "_step": 444}
{"Episode reward": 58.49999999999969, "Episode length": 415, "Policy Loss": 1.442800521850586, "Value Loss": 23.685468673706055, "_runtime": 14718.695803165436, "_timestamp": 1585584634.5404365, "_step": 445}
{"Episode reward": 16.800000000000452, "Episode length": 832, "Policy Loss": 0.1713394969701767, "Value Loss": 11.782679557800293, "_runtime": 14719.584382772446, "_timestamp": 1585584635.429016, "_step": 446}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 0.7906575798988342, "Value Loss": 17.466379165649414, "_runtime": 14721.121403217316, "_timestamp": 1585584636.9660366, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.008345127105713, "Value Loss": 0.02751016803085804, "_runtime": 14722.698426961899, "_timestamp": 1585584638.5430603, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.049649953842163, "Value Loss": 0.0620342418551445, "_runtime": 14724.243335723877, "_timestamp": 1585584640.087969, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9816756844520569, "Value Loss": 0.024277463555336, "_runtime": 14725.289583444595, "_timestamp": 1585584641.1342168, "_step": 450}
{"Episode reward": 33.999999999999474, "Episode length": 660, "Policy Loss": 0.5162990689277649, "Value Loss": 14.795863151550293, "_runtime": 14725.947883605957, "_timestamp": 1585584641.792517, "_step": 451}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.7370737791061401, "Value Loss": 24.0776424407959, "_runtime": 14727.524119138718, "_timestamp": 1585584643.3687525, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8962720036506653, "Value Loss": 0.08326950669288635, "_runtime": 14727.920838832855, "_timestamp": 1585584643.7654722, "_step": 453}
{"Episode reward": 77.09999999999995, "Episode length": 229, "Policy Loss": 3.609684705734253, "Value Loss": 42.49948501586914, "_runtime": 14729.012628555298, "_timestamp": 1585584644.857262, "_step": 454}
{"Episode reward": 28.899999999999764, "Episode length": 711, "Policy Loss": 0.5969946384429932, "Value Loss": 13.71910285949707, "_runtime": 14730.607439279556, "_timestamp": 1585584646.4520726, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.811856210231781, "Value Loss": 0.06366649270057678, "_runtime": 14732.107205152512, "_timestamp": 1585584647.9518385, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9128336310386658, "Value Loss": 0.3977094888687134, "_runtime": 14732.733459949493, "_timestamp": 1585584648.5780933, "_step": 457}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 1.938432216644287, "Value Loss": 25.67678451538086, "_runtime": 14734.303233861923, "_timestamp": 1585584650.1478672, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8369578719139099, "Value Loss": 0.14542286098003387, "_runtime": 14735.721631288528, "_timestamp": 1585584651.5662646, "_step": 459}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.33405858278274536, "Value Loss": 11.019662857055664, "_runtime": 14737.234696388245, "_timestamp": 1585584653.0793297, "_step": 460}
{"Episode reward": -99.86189648061851, "Episode length": 999, "Policy Loss": -0.8870662450790405, "Value Loss": 0.1609249711036682, "_runtime": 14738.843223810196, "_timestamp": 1585584654.6878572, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0166207551956177, "Value Loss": 0.3479863405227661, "_runtime": 14740.41212797165, "_timestamp": 1585584656.2567613, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9026377201080322, "Value Loss": 0.044897377490997314, "_runtime": 14741.030672073364, "_timestamp": 1585584656.8753054, "_step": 463}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.8389464616775513, "Value Loss": 26.009958267211914, "_runtime": 14742.617070674896, "_timestamp": 1585584658.461704, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9710943698883057, "Value Loss": 0.016144149005413055, "_runtime": 14743.664038181305, "_timestamp": 1585584659.5086715, "_step": 465}
{"Episode reward": 34.29999999999946, "Episode length": 657, "Policy Loss": 0.6891668438911438, "Value Loss": 14.865572929382324, "_runtime": 14744.508881092072, "_timestamp": 1585584660.3535144, "_step": 466}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 1.175663948059082, "Value Loss": 17.674959182739258, "_runtime": 14745.58502793312, "_timestamp": 1585584661.4296613, "_step": 467}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": 0.6852753758430481, "Value Loss": 14.610928535461426, "_runtime": 14747.137556791306, "_timestamp": 1585584662.9821901, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9514037370681763, "Value Loss": 0.14176945388317108, "_runtime": 14747.78797531128, "_timestamp": 1585584663.6326087, "_step": 469}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 1.5176153182983398, "Value Loss": 23.64246368408203, "_runtime": 14749.135212659836, "_timestamp": 1585584664.979846, "_step": 470}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 0.19608479738235474, "Value Loss": 11.214900016784668, "_runtime": 14750.703835725784, "_timestamp": 1585584666.548469, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9404367208480835, "Value Loss": 0.015181953087449074, "_runtime": 14752.045686244965, "_timestamp": 1585584667.8903196, "_step": 472}
{"Episode reward": 11.000000000000782, "Episode length": 890, "Policy Loss": 0.25539082288742065, "Value Loss": 11.009625434875488, "_runtime": 14753.619866371155, "_timestamp": 1585584669.4644997, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9238147735595703, "Value Loss": 0.010751528665423393, "_runtime": 14755.20914554596, "_timestamp": 1585584671.053779, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9066978693008423, "Value Loss": 0.030487462878227234, "_runtime": 14756.76429438591, "_timestamp": 1585584672.6089277, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8699319362640381, "Value Loss": 0.007793305441737175, "_runtime": 14758.123859167099, "_timestamp": 1585584673.9684925, "_step": 476}
{"Episode reward": 15.200000000000543, "Episode length": 848, "Policy Loss": 0.380561888217926, "Value Loss": 11.458168029785156, "_runtime": 14759.030608177185, "_timestamp": 1585584674.8752415, "_step": 477}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 1.012211799621582, "Value Loss": 17.420757293701172, "_runtime": 14760.650336742401, "_timestamp": 1585584676.49497, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7965514659881592, "Value Loss": 0.009929478168487549, "_runtime": 14762.230738639832, "_timestamp": 1585584678.075372, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7760978937149048, "Value Loss": 0.015064285136759281, "_runtime": 14763.298212766647, "_timestamp": 1585584679.142846, "_step": 480}
{"Episode reward": 31.399999999999622, "Episode length": 686, "Policy Loss": 0.7209315896034241, "Value Loss": 14.165573120117188, "_runtime": 14764.876349687576, "_timestamp": 1585584680.720983, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7319218516349792, "Value Loss": 0.017563320696353912, "_runtime": 14765.845702171326, "_timestamp": 1585584681.6903355, "_step": 482}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 1.3327158689498901, "Value Loss": 16.201913833618164, "_runtime": 14766.715073347092, "_timestamp": 1585584682.5597067, "_step": 483}
{"Episode reward": 45.1999999999995, "Episode length": 548, "Policy Loss": 1.2187122106552124, "Value Loss": 17.83564567565918, "_runtime": 14767.369318246841, "_timestamp": 1585584683.2139516, "_step": 484}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 1.7384860515594482, "Value Loss": 23.81253433227539, "_runtime": 14768.020141363144, "_timestamp": 1585584683.8647747, "_step": 485}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.8929898738861084, "Value Loss": 23.72156524658203, "_runtime": 14769.573361158371, "_timestamp": 1585584685.4179945, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7548317313194275, "Value Loss": 0.07057925313711166, "_runtime": 14770.9613301754, "_timestamp": 1585584686.8059635, "_step": 487}
{"Episode reward": 9.400000000000873, "Episode length": 906, "Policy Loss": 0.610550045967102, "Value Loss": 10.587206840515137, "_runtime": 14772.48422908783, "_timestamp": 1585584688.3288624, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7031004428863525, "Value Loss": 0.021401965990662575, "_runtime": 14774.08656668663, "_timestamp": 1585584689.9312, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6705320477485657, "Value Loss": 0.07765556871891022, "_runtime": 14775.324144601822, "_timestamp": 1585584691.168778, "_step": 490}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 0.6429668068885803, "Value Loss": 12.173774719238281, "_runtime": 14776.891328811646, "_timestamp": 1585584692.7359622, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7966371774673462, "Value Loss": 0.0577949620783329, "_runtime": 14777.98616528511, "_timestamp": 1585584693.8307986, "_step": 492}
{"Episode reward": 32.99999999999953, "Episode length": 670, "Policy Loss": 0.7609849572181702, "Value Loss": 14.816888809204102, "_runtime": 14779.564898729324, "_timestamp": 1585584695.409532, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7036350965499878, "Value Loss": 0.02700723335146904, "_runtime": 14781.140381097794, "_timestamp": 1585584696.9850144, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7567384839057922, "Value Loss": 0.06868564337491989, "_runtime": 14781.949803590775, "_timestamp": 1585584697.794437, "_step": 495}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 1.3788988590240479, "Value Loss": 19.12771987915039, "_runtime": 14782.943046569824, "_timestamp": 1585584698.78768, "_step": 496}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": 0.771780788898468, "Value Loss": 15.24564266204834, "_runtime": 14784.556631326675, "_timestamp": 1585584700.4012647, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8069806098937988, "Value Loss": 0.009751727804541588, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427, 0.006924943067133427]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006924943067133427, 0.095163993537426, 0.19725292921066284, 0.2993418574333191, 0.40143078565597534, 0.5035197734832764, 0.6056087017059326, 0.7076976299285889, 0.8097865581512451, 0.9118754863739014, 1.0139644145965576, 1.1160533428192139, 1.2181422710418701, 1.3202311992645264, 1.4223201274871826, 1.5244090557098389, 1.6264979839324951, 1.7285869121551514, 1.8306758403778076, 1.9327647686004639, 2.034853935241699, 2.1369428634643555, 2.2390317916870117, 2.341120719909668, 2.443209648132324, 2.5452985763549805, 2.6473875045776367, 2.749476432800293, 2.851565361022949, 2.9536542892456055, 3.0557432174682617, 3.157832145690918, 3.259921073913574, 3.3620100021362305, 3.4640989303588867, 3.566187858581543, 3.668276786804199, 3.7703657150268555, 3.8724546432495117, 3.974543571472168, 4.076632499694824, 4.1787214279174805, 4.280810356140137, 4.382899284362793, 4.484988212585449, 4.5870771408081055, 4.689166069030762, 4.791254997253418, 4.893343925476074, 4.9954328536987305, 5.097521781921387, 5.199610710144043, 5.301699638366699, 5.4037885665893555, 5.505877494812012, 5.607966423034668, 5.710055351257324, 5.8121442794799805, 5.914233207702637, 6.016322135925293, 6.118411064147949, 6.2204999923706055, 6.322588920593262, 6.424677848815918, 6.526766777038574]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [11.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0013904994120821357, 0.0027809988241642714, 0.004171498119831085, 0.005561997648328543, 0.006952497176826, 0.00834299623966217, 0.009733496233820915, 0.011123995296657085, 0.012514494359493256, 0.013904994353652, 0.01529549341648817, 0.01668599247932434, 0.018076492473483086, 0.01946699246764183, 0.020857490599155426, 0.02224799059331417, 0.023638490587472916, 0.02502898871898651, 0.026419488713145256, 0.027809988707304, 0.029200486838817596, 0.03059098683297634, 0.031981486827135086, 0.03337198495864868, 0.034762486815452576, 0.03615298494696617, 0.03754348307847977, 0.03893398493528366, 0.040324483066797256, 0.04171498119831085, 0.043105483055114746, 0.04449598118662834, 0.04588647931814194, 0.04727698117494583, 0.04866747930645943, 0.05005797743797302, 0.051448479294776917, 0.05283897742629051, 0.05422947555780411, 0.055619977414608, 0.0570104755461216, 0.05840097367763519, 0.05979147553443909, 0.06118197366595268, 0.06257247179746628, 0.06396297365427017, 0.06535347551107407, 0.06674396991729736, 0.06813447177410126, 0.06952497363090515, 0.07091546803712845, 0.07230596989393234, 0.07369647175073624, 0.07508696615695953, 0.07647746801376343, 0.07786796987056732, 0.07925846427679062, 0.08064896613359451, 0.08203946799039841, 0.0834299623966217, 0.0848204642534256, 0.08621096611022949, 0.08760146051645279, 0.08899196237325668]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [9.0, 4.0, 2.0, 0.0, 8.0, 432.0, 29.0, 13.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.08884803205728531, -0.07225143909454346, -0.05565484240651131, -0.039058245718479156, -0.022461652755737305, -0.005865059792995453, 0.010731540620326996, 0.027328133583068848, 0.0439247265458107, 0.06052132695913315, 0.0771179124712944, 0.09371451288461685, 0.1103111132979393, 0.12690770626068115, 0.1435042917728424, 0.16010087728500366, 0.1766974925994873, 0.19329407811164856, 0.2098906934261322, 0.22648727893829346, 0.2430838644504547, 0.25968047976493835, 0.2762770652770996, 0.29287365078926086, 0.3094702661037445, 0.32606685161590576, 0.342663437128067, 0.35926002264022827, 0.3758566379547119, 0.39245322346687317, 0.4090498089790344, 0.4256463944911957, 0.4422430098056793, 0.45883962512016296, 0.47543618083000183, 0.4920327961444855, 0.5086293816566467, 0.5252259373664856, 0.5418225526809692, 0.5584191679954529, 0.5750157237052917, 0.5916123390197754, 0.608208954334259, 0.6248055100440979, 0.6414021253585815, 0.6579987406730652, 0.674595296382904, 0.6911919116973877, 0.7077885270118713, 0.7243850827217102, 0.7409816980361938, 0.7575782537460327, 0.7741748690605164, 0.790771484375, 0.8073680400848389, 0.8239646553993225, 0.8405612707138062, 0.857157826423645, 0.8737544417381287, 0.8903510570526123, 0.9069476127624512, 0.9235442280769348, 0.9401407837867737, 0.9567374587059021, 0.973334014415741]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.21105627715587616, -0.19154107570648193, -0.1720258742570877, -0.15251067280769348, -0.13299548625946045, -0.11348027735948563, -0.093965083360672, -0.07444988191127777, -0.054934680461883545, -0.03541947901248932, -0.015904277563095093, 0.0036109238862991333, 0.023126110434532166, 0.042641326785087585, 0.06215651333332062, 0.08167172968387604, 0.10118691623210907, 0.1207021027803421, 0.14021731913089752, 0.15973250567913055, 0.17924772202968597, 0.198762908577919, 0.21827812492847443, 0.23779331147670746, 0.2573084831237793, 0.2768236994743347, 0.29633891582489014, 0.3158540725708008, 0.3353692889213562, 0.3548845052719116, 0.37439972162246704, 0.3939148783683777, 0.4134300947189331, 0.4329453110694885, 0.45246046781539917, 0.4719756841659546, 0.49149090051651, 0.5110061168670654, 0.5305212736129761, 0.5500364899635315, 0.5695517063140869, 0.5890668630599976, 0.608582079410553, 0.6280972957611084, 0.6476125121116638, 0.6671276688575745, 0.6866428852081299, 0.7061581015586853, 0.725673258304596, 0.7451884746551514, 0.7647036910057068, 0.7842189073562622, 0.8037341237068176, 0.8232492804527283, 0.8427644371986389, 0.8622797131538391, 0.8817948698997498, 0.9013100266456604, 0.9208253026008606, 0.9403404593467712, 0.9598557353019714, 0.9793708920478821, 0.9988860487937927, 1.0184013843536377, 1.0379165410995483]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 22.0, 2.0, 5.0, 6.0, 2.0, 0.0, 1.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0], "bins": [-0.2811533212661743, -0.27545374631881714, -0.26975420117378235, -0.26405462622642517, -0.2583550810813904, -0.2526555061340332, -0.2469559609889984, -0.24125640094280243, -0.23555684089660645, -0.22985728085041046, -0.22415772080421448, -0.2184581458568573, -0.2127586007118225, -0.20705902576446533, -0.20135948061943054, -0.19565990567207336, -0.18996036052703857, -0.1842607855796814, -0.1785612404346466, -0.17286166548728943, -0.16716212034225464, -0.16146254539489746, -0.15576298534870148, -0.1500634253025055, -0.1443638652563095, -0.13866430521011353, -0.13296474516391754, -0.12726518511772156, -0.12156562507152557, -0.11586606502532959, -0.1101665049791336, -0.10446694493293762, -0.09876738488674164, -0.09306782484054565, -0.08736826479434967, -0.08166870474815369, -0.0759691447019577, -0.07026958465576172, -0.06457002460956573, -0.05887046456336975, -0.05317090451717377, -0.04747134447097778, -0.0417717844247818, -0.036072224378585815, -0.030372649431228638, -0.024673104286193848, -0.01897352933883667, -0.01327398419380188, -0.007574409246444702, -0.0018748641014099121, 0.0038247108459472656, 0.009524255990982056, 0.015223830938339233, 0.020923376083374023, 0.0266229510307312, 0.03232249617576599, 0.03802207112312317, 0.04372161626815796, 0.04942119121551514, 0.05512073636054993, 0.060820311307907104, 0.0665198564529419, 0.07221943140029907, 0.07791897654533386, 0.08361855149269104]}, "_runtime": 14785.26554107666, "_timestamp": 1585584701.1101744, "_step": 498}
{"Episode reward": 55.39999999999964, "Episode length": 446, "Policy Loss": 1.59269118309021, "Value Loss": 21.318681716918945, "_runtime": 14785.26554107666, "_timestamp": 1585584701.1101744, "_step": 499}
