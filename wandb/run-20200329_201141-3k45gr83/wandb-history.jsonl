{"Episode reward": -35.09295826876192, "Episode length": 999, "Policy Loss": -0.010475903749465942, "Value Loss": 0.1499186009168625, "_runtime": 3641.774114370346, "_timestamp": 1585512720.194844, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5069968700408936, "Value Loss": 166.79776000976562, "_runtime": 3643.2548830509186, "_timestamp": 1585512721.6756127, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 14.014389991760254, "Value Loss": 7842.984375, "_runtime": 3644.8007011413574, "_timestamp": 1585512723.2214308, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.8718976974487305, "Value Loss": 135.6732940673828, "_runtime": 3646.3636491298676, "_timestamp": 1585512724.7843788, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8161245584487915, "Value Loss": 81.2151107788086, "_runtime": 3647.885509967804, "_timestamp": 1585512726.3062396, "_step": 4}
{"Episode reward": -81.81684045758229, "Episode length": 999, "Policy Loss": -10.01899242401123, "Value Loss": 4046.296630859375, "_runtime": 3649.4497718811035, "_timestamp": 1585512727.8705015, "_step": 5}
{"Episode reward": -99.88094608296274, "Episode length": 999, "Policy Loss": -7.535662651062012, "Value Loss": 20.345394134521484, "_runtime": 3650.9848647117615, "_timestamp": 1585512729.4055943, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8209855556488037, "Value Loss": 215.44927978515625, "_runtime": 3652.5149149894714, "_timestamp": 1585512730.9356446, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.576745986938477, "Value Loss": 146.39767456054688, "_runtime": 3654.0878179073334, "_timestamp": 1585512732.5085475, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.410792350769043, "Value Loss": 140.35081481933594, "_runtime": 3655.6309490203857, "_timestamp": 1585512734.0516787, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.952418327331543, "Value Loss": 2582.22119140625, "_runtime": 3657.165814638138, "_timestamp": 1585512735.5865443, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.81029224395752, "Value Loss": 586.0734252929688, "_runtime": 3658.7350170612335, "_timestamp": 1585512737.1557467, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.68368148803711, "Value Loss": 4654.82763671875, "_runtime": 3660.296772003174, "_timestamp": 1585512738.7175016, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.816768646240234, "Value Loss": 46.653480529785156, "_runtime": 3661.8466897010803, "_timestamp": 1585512740.2674193, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.60461139678955, "Value Loss": 3.109652042388916, "_runtime": 3663.4190180301666, "_timestamp": 1585512741.8397477, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.738768577575684, "Value Loss": 354.45269775390625, "_runtime": 3664.9827315807343, "_timestamp": 1585512743.4034612, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.510278701782227, "Value Loss": 167.25221252441406, "_runtime": 3666.5255970954895, "_timestamp": 1585512744.9463267, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.035205841064453, "Value Loss": 128.0762176513672, "_runtime": 3668.0945932865143, "_timestamp": 1585512746.515323, "_step": 17}
{"Episode reward": -69.64390765861752, "Episode length": 999, "Policy Loss": 4.719756603240967, "Value Loss": 223.28854370117188, "_runtime": 3669.6911022663116, "_timestamp": 1585512748.111832, "_step": 18}
{"Episode reward": -49.42860642133547, "Episode length": 999, "Policy Loss": 0.7643294334411621, "Value Loss": 24.903032302856445, "_runtime": 3671.245106935501, "_timestamp": 1585512749.6658366, "_step": 19}
{"Episode reward": -43.399128126220575, "Episode length": 999, "Policy Loss": 0.7530244588851929, "Value Loss": 29.47600555419922, "_runtime": 3672.8002066612244, "_timestamp": 1585512751.2209363, "_step": 20}
{"Episode reward": -37.69959111729592, "Episode length": 999, "Policy Loss": 0.9860841035842896, "Value Loss": 54.078277587890625, "_runtime": 3674.354431629181, "_timestamp": 1585512752.7751613, "_step": 21}
{"Episode reward": -31.322603115894196, "Episode length": 999, "Policy Loss": 0.6717726588249207, "Value Loss": 5.384905815124512, "_runtime": 3675.911986351013, "_timestamp": 1585512754.332716, "_step": 22}
{"Episode reward": -35.18796491808358, "Episode length": 999, "Policy Loss": 0.542870283126831, "Value Loss": 28.58167266845703, "_runtime": 3677.4776792526245, "_timestamp": 1585512755.898409, "_step": 23}
{"Episode reward": -43.294614231901484, "Episode length": 999, "Policy Loss": 0.45744723081588745, "Value Loss": 21.70035743713379, "_runtime": 3679.0287466049194, "_timestamp": 1585512757.4494762, "_step": 24}
{"Episode reward": -53.107452611537546, "Episode length": 999, "Policy Loss": 0.43509960174560547, "Value Loss": 19.19635009765625, "_runtime": 3680.575819015503, "_timestamp": 1585512758.9965487, "_step": 25}
{"Episode reward": -68.29249349581104, "Episode length": 999, "Policy Loss": 0.5980983972549438, "Value Loss": 70.35929107666016, "_runtime": 3682.144709587097, "_timestamp": 1585512760.5654392, "_step": 26}
{"Episode reward": -79.80467400851725, "Episode length": 999, "Policy Loss": 0.1407438963651657, "Value Loss": 22.32868766784668, "_runtime": 3683.6985218524933, "_timestamp": 1585512762.1192515, "_step": 27}
{"Episode reward": -87.65334610306802, "Episode length": 999, "Policy Loss": 0.1691538244485855, "Value Loss": 24.55719757080078, "_runtime": 3685.2375679016113, "_timestamp": 1585512763.6582975, "_step": 28}
{"Episode reward": -93.84303987703517, "Episode length": 999, "Policy Loss": 0.45514243841171265, "Value Loss": 60.465572357177734, "_runtime": 3686.806367635727, "_timestamp": 1585512765.2270973, "_step": 29}
{"Episode reward": -96.84475673988413, "Episode length": 999, "Policy Loss": 0.2074977159500122, "Value Loss": 48.29544448852539, "_runtime": 3688.3602447509766, "_timestamp": 1585512766.7809744, "_step": 30}
{"Episode reward": -98.46130365305433, "Episode length": 999, "Policy Loss": 0.05378956347703934, "Value Loss": 5.827159404754639, "_runtime": 3689.9258229732513, "_timestamp": 1585512768.3465526, "_step": 31}
{"Episode reward": -98.93620426089483, "Episode length": 999, "Policy Loss": -0.0078220684081316, "Value Loss": 2.463148593902588, "_runtime": 3691.4881896972656, "_timestamp": 1585512769.9089193, "_step": 32}
{"Episode reward": -97.87812515565484, "Episode length": 999, "Policy Loss": -0.20548635721206665, "Value Loss": 4.195084095001221, "_runtime": 3693.0786006450653, "_timestamp": 1585512771.4993303, "_step": 33}
{"Episode reward": -99.1108051166712, "Episode length": 999, "Policy Loss": -0.12920890748500824, "Value Loss": 0.5509594678878784, "_runtime": 3694.6144592761993, "_timestamp": 1585512773.035189, "_step": 34}
{"Episode reward": -98.72870075906133, "Episode length": 999, "Policy Loss": -0.28127890825271606, "Value Loss": 2.000856399536133, "_runtime": 3696.168120622635, "_timestamp": 1585512774.5888503, "_step": 35}
{"Episode reward": -98.42117670722583, "Episode length": 999, "Policy Loss": -0.3941746950149536, "Value Loss": 4.370481014251709, "_runtime": 3697.724537372589, "_timestamp": 1585512776.145267, "_step": 36}
{"Episode reward": -98.6077284280098, "Episode length": 999, "Policy Loss": -0.4291936159133911, "Value Loss": 5.193680763244629, "_runtime": 3699.2652792930603, "_timestamp": 1585512777.686009, "_step": 37}
{"Episode reward": -99.41026630968054, "Episode length": 999, "Policy Loss": -0.5049284100532532, "Value Loss": 2.6654748916625977, "_runtime": 3700.819078683853, "_timestamp": 1585512779.2398083, "_step": 38}
{"Episode reward": -99.71488071584994, "Episode length": 999, "Policy Loss": -0.3683417737483978, "Value Loss": 1.9370534420013428, "_runtime": 3702.36789727211, "_timestamp": 1585512780.788627, "_step": 39}
{"Episode reward": -98.98284851090767, "Episode length": 999, "Policy Loss": -0.6273282170295715, "Value Loss": 4.733297824859619, "_runtime": 3703.9210438728333, "_timestamp": 1585512782.3417735, "_step": 40}
{"Episode reward": -99.37113016034665, "Episode length": 999, "Policy Loss": -0.6273699402809143, "Value Loss": 3.319837808609009, "_runtime": 3705.47731590271, "_timestamp": 1585512783.8980455, "_step": 41}
{"Episode reward": -99.42965356658445, "Episode length": 999, "Policy Loss": -0.4318627119064331, "Value Loss": 2.5111324787139893, "_runtime": 3707.03217625618, "_timestamp": 1585512785.452906, "_step": 42}
{"Episode reward": -99.82156675403913, "Episode length": 999, "Policy Loss": -0.503425121307373, "Value Loss": 1.9845885038375854, "_runtime": 3708.5816733837128, "_timestamp": 1585512787.002403, "_step": 43}
{"Episode reward": -98.81551355935522, "Episode length": 999, "Policy Loss": -0.720793604850769, "Value Loss": 4.852307319641113, "_runtime": 3710.136092185974, "_timestamp": 1585512788.5568218, "_step": 44}
{"Episode reward": -98.41066790303049, "Episode length": 999, "Policy Loss": -0.7224113941192627, "Value Loss": 4.757315158843994, "_runtime": 3711.6899361610413, "_timestamp": 1585512790.1106658, "_step": 45}
{"Episode reward": -99.44950394494309, "Episode length": 999, "Policy Loss": -0.5568238496780396, "Value Loss": 2.765153169631958, "_runtime": 3713.241454601288, "_timestamp": 1585512791.6621842, "_step": 46}
{"Episode reward": -98.9258757214737, "Episode length": 999, "Policy Loss": -0.6415430307388306, "Value Loss": 3.1818015575408936, "_runtime": 3714.8211727142334, "_timestamp": 1585512793.2419024, "_step": 47}
{"Episode reward": -99.3121611438544, "Episode length": 999, "Policy Loss": -0.5056496858596802, "Value Loss": 2.151017665863037, "_runtime": 3716.3863410949707, "_timestamp": 1585512794.8070707, "_step": 48}
{"Episode reward": -99.19834366681052, "Episode length": 999, "Policy Loss": -0.5555735230445862, "Value Loss": 2.2133116722106934, "_runtime": 3717.9348015785217, "_timestamp": 1585512796.3555312, "_step": 49}
{"Episode reward": -99.49622155595236, "Episode length": 999, "Policy Loss": -0.4567497670650482, "Value Loss": 1.3268431425094604, "_runtime": 3719.500525712967, "_timestamp": 1585512797.9212554, "_step": 50}
{"Episode reward": -98.48626844017838, "Episode length": 999, "Policy Loss": -0.5095696449279785, "Value Loss": 1.7924749851226807, "_runtime": 3721.0561232566833, "_timestamp": 1585512799.476853, "_step": 51}
{"Episode reward": -99.38554113191583, "Episode length": 999, "Policy Loss": -0.43366900086402893, "Value Loss": 0.7622045874595642, "_runtime": 3722.616655111313, "_timestamp": 1585512801.0373847, "_step": 52}
{"Episode reward": -98.74121456237381, "Episode length": 999, "Policy Loss": -0.4943513870239258, "Value Loss": 1.2258291244506836, "_runtime": 3724.1837973594666, "_timestamp": 1585512802.604527, "_step": 53}
{"Episode reward": -99.29427314446714, "Episode length": 999, "Policy Loss": -0.35846513509750366, "Value Loss": 0.5026508569717407, "_runtime": 3725.747824192047, "_timestamp": 1585512804.1685538, "_step": 54}
{"Episode reward": -99.62274385258905, "Episode length": 999, "Policy Loss": -0.3367431163787842, "Value Loss": 0.3433580696582794, "_runtime": 3727.2990448474884, "_timestamp": 1585512805.7197745, "_step": 55}
{"Episode reward": -98.16973950669922, "Episode length": 999, "Policy Loss": -0.3633447289466858, "Value Loss": 0.6587958335876465, "_runtime": 3728.863391637802, "_timestamp": 1585512807.2841213, "_step": 56}
{"Episode reward": -99.40063542811198, "Episode length": 999, "Policy Loss": -0.2937273681163788, "Value Loss": 0.20547595620155334, "_runtime": 3730.4298610687256, "_timestamp": 1585512808.8505907, "_step": 57}
{"Episode reward": -99.26576670009882, "Episode length": 999, "Policy Loss": -0.2805365324020386, "Value Loss": 0.16027943789958954, "_runtime": 3731.9906260967255, "_timestamp": 1585512810.4113557, "_step": 58}
{"Episode reward": -98.81614627927924, "Episode length": 999, "Policy Loss": -0.29764628410339355, "Value Loss": 0.25781866908073425, "_runtime": 3733.548406600952, "_timestamp": 1585512811.9691362, "_step": 59}
{"Episode reward": -99.66001271935787, "Episode length": 999, "Policy Loss": -0.21577350795269012, "Value Loss": 0.1348447948694229, "_runtime": 3735.1030473709106, "_timestamp": 1585512813.523777, "_step": 60}
{"Episode reward": -98.2644437964223, "Episode length": 999, "Policy Loss": -0.26212865114212036, "Value Loss": 0.17782814800739288, "_runtime": 3736.654116153717, "_timestamp": 1585512815.0748458, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1926649510860443, "Value Loss": 0.17544837296009064, "_runtime": 3738.2557892799377, "_timestamp": 1585512816.676519, "_step": 62}
{"Episode reward": -98.74760726052149, "Episode length": 999, "Policy Loss": -0.1943807601928711, "Value Loss": 0.10089237242937088, "_runtime": 3739.8187716007233, "_timestamp": 1585512818.2395012, "_step": 63}
{"Episode reward": -98.10999837696541, "Episode length": 999, "Policy Loss": -0.2100328803062439, "Value Loss": 0.11449767649173737, "_runtime": 3741.379934310913, "_timestamp": 1585512819.800664, "_step": 64}
{"Episode reward": -99.64009005306225, "Episode length": 999, "Policy Loss": -0.1611807495355606, "Value Loss": 0.21247632801532745, "_runtime": 3742.944589138031, "_timestamp": 1585512821.3653188, "_step": 65}
{"Episode reward": -98.45768200147505, "Episode length": 999, "Policy Loss": -0.1723511815071106, "Value Loss": 0.10001865774393082, "_runtime": 3744.5081667900085, "_timestamp": 1585512822.9288964, "_step": 66}
{"Episode reward": -99.07906788080291, "Episode length": 999, "Policy Loss": -0.1354903280735016, "Value Loss": 0.14945554733276367, "_runtime": 3746.058955192566, "_timestamp": 1585512824.4796848, "_step": 67}
{"Episode reward": -99.12063942776294, "Episode length": 999, "Policy Loss": -0.11079009622335434, "Value Loss": 0.18420834839344025, "_runtime": 3747.6124861240387, "_timestamp": 1585512826.0332158, "_step": 68}
{"Episode reward": -99.0497461944291, "Episode length": 999, "Policy Loss": -0.10080304741859436, "Value Loss": 0.2170710563659668, "_runtime": 3749.1761655807495, "_timestamp": 1585512827.5968952, "_step": 69}
{"Episode reward": -97.84467900081748, "Episode length": 999, "Policy Loss": -0.15485143661499023, "Value Loss": 0.07035921514034271, "_runtime": 3750.7284440994263, "_timestamp": 1585512829.1491737, "_step": 70}
{"Episode reward": -99.14376730057383, "Episode length": 999, "Policy Loss": -0.07579225301742554, "Value Loss": 0.24973532557487488, "_runtime": 3752.2960493564606, "_timestamp": 1585512830.716779, "_step": 71}
{"Episode reward": -99.46016197209475, "Episode length": 999, "Policy Loss": -0.07310720533132553, "Value Loss": 0.2730725407600403, "_runtime": 3753.8672761917114, "_timestamp": 1585512832.2880058, "_step": 72}
{"Episode reward": -98.79278131800274, "Episode length": 999, "Policy Loss": -0.09555305540561676, "Value Loss": 0.17489111423492432, "_runtime": 3755.4301540851593, "_timestamp": 1585512833.8508837, "_step": 73}
{"Episode reward": -99.53854850624992, "Episode length": 999, "Policy Loss": -0.05894628167152405, "Value Loss": 0.2623060643672943, "_runtime": 3756.972843170166, "_timestamp": 1585512835.3935728, "_step": 74}
{"Episode reward": -99.23747548305286, "Episode length": 999, "Policy Loss": -0.07302346080541611, "Value Loss": 0.21806851029396057, "_runtime": 3758.5137622356415, "_timestamp": 1585512836.9344919, "_step": 75}
{"Episode reward": -99.8688014216273, "Episode length": 999, "Policy Loss": -0.081797294318676, "Value Loss": 0.23678995668888092, "_runtime": 3760.0536646842957, "_timestamp": 1585512838.4743943, "_step": 76}
{"Episode reward": -98.55981949230167, "Episode length": 999, "Policy Loss": -0.08599477261304855, "Value Loss": 0.11109530180692673, "_runtime": 3761.6447937488556, "_timestamp": 1585512840.0655234, "_step": 77}
{"Episode reward": -99.08247980798511, "Episode length": 999, "Policy Loss": -0.08294320106506348, "Value Loss": 0.16550692915916443, "_runtime": 3763.1988427639008, "_timestamp": 1585512841.6195724, "_step": 78}
{"Episode reward": -99.64317485021337, "Episode length": 999, "Policy Loss": -0.06814218312501907, "Value Loss": 0.1729259192943573, "_runtime": 3764.7485361099243, "_timestamp": 1585512843.1692657, "_step": 79}
{"Episode reward": -99.19045098916561, "Episode length": 999, "Policy Loss": -0.08409819006919861, "Value Loss": 0.13702206313610077, "_runtime": 3766.308939218521, "_timestamp": 1585512844.7296689, "_step": 80}
{"Episode reward": -99.23011795152777, "Episode length": 999, "Policy Loss": -0.0899367555975914, "Value Loss": 0.11449486017227173, "_runtime": 3767.859877347946, "_timestamp": 1585512846.280607, "_step": 81}
{"Episode reward": -98.8730159119662, "Episode length": 999, "Policy Loss": -0.09105225652456284, "Value Loss": 0.07611297070980072, "_runtime": 3769.4203391075134, "_timestamp": 1585512847.8410687, "_step": 82}
{"Episode reward": -98.43392884045171, "Episode length": 999, "Policy Loss": -0.10767897218465805, "Value Loss": 0.050275105983018875, "_runtime": 3770.9738581180573, "_timestamp": 1585512849.3945878, "_step": 83}
{"Episode reward": -98.97171126148247, "Episode length": 999, "Policy Loss": -0.10271717607975006, "Value Loss": 0.06542762368917465, "_runtime": 3772.5272223949432, "_timestamp": 1585512850.947952, "_step": 84}
{"Episode reward": -98.60854467851307, "Episode length": 999, "Policy Loss": -0.11400781571865082, "Value Loss": 0.04412080720067024, "_runtime": 3774.0849928855896, "_timestamp": 1585512852.5057225, "_step": 85}
{"Episode reward": -98.6872995599923, "Episode length": 999, "Policy Loss": -0.11193939298391342, "Value Loss": 0.039007849991321564, "_runtime": 3775.6607077121735, "_timestamp": 1585512854.0814373, "_step": 86}
{"Episode reward": -99.60548643964657, "Episode length": 999, "Policy Loss": -0.10073437541723251, "Value Loss": 0.05265795439481735, "_runtime": 3777.2326154708862, "_timestamp": 1585512855.653345, "_step": 87}
{"Episode reward": -98.41548152094748, "Episode length": 999, "Policy Loss": -0.1346983164548874, "Value Loss": 0.04275757819414139, "_runtime": 3778.80287361145, "_timestamp": 1585512857.2236032, "_step": 88}
{"Episode reward": -99.78182672662513, "Episode length": 999, "Policy Loss": -0.09845906496047974, "Value Loss": 0.04268007352948189, "_runtime": 3780.378490447998, "_timestamp": 1585512858.79922, "_step": 89}
{"Episode reward": -99.15433349362051, "Episode length": 999, "Policy Loss": -0.11518462002277374, "Value Loss": 0.03340801224112511, "_runtime": 3781.951131105423, "_timestamp": 1585512860.3718607, "_step": 90}
{"Episode reward": -97.9886857264556, "Episode length": 999, "Policy Loss": -0.13627073168754578, "Value Loss": 0.0389445461332798, "_runtime": 3783.514023065567, "_timestamp": 1585512861.9347527, "_step": 91}
{"Episode reward": -98.21328386114205, "Episode length": 999, "Policy Loss": -0.1246672123670578, "Value Loss": 0.035972077399492264, "_runtime": 3785.103362083435, "_timestamp": 1585512863.5240917, "_step": 92}
{"Episode reward": -99.48719688006427, "Episode length": 999, "Policy Loss": -0.11414992064237595, "Value Loss": 0.028576908633112907, "_runtime": 3786.667984008789, "_timestamp": 1585512865.0887136, "_step": 93}
{"Episode reward": -99.75198057194045, "Episode length": 999, "Policy Loss": -0.10970364511013031, "Value Loss": 0.027455469593405724, "_runtime": 3788.227906703949, "_timestamp": 1585512866.6486363, "_step": 94}
{"Episode reward": -99.133299011106, "Episode length": 999, "Policy Loss": -0.10865209251642227, "Value Loss": 0.025983257219195366, "_runtime": 3789.7939484119415, "_timestamp": 1585512868.214678, "_step": 95}
{"Episode reward": -98.22340005637766, "Episode length": 999, "Policy Loss": -0.12020228803157806, "Value Loss": 0.03830023109912872, "_runtime": 3791.358267068863, "_timestamp": 1585512869.7789967, "_step": 96}
{"Episode reward": -98.28371093197208, "Episode length": 999, "Policy Loss": -0.12204781174659729, "Value Loss": 0.03660125657916069, "_runtime": 3792.921322107315, "_timestamp": 1585512871.3420517, "_step": 97}
{"Episode reward": -99.6091153763879, "Episode length": 999, "Policy Loss": -0.10773200541734695, "Value Loss": 0.023754697293043137, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156, 42.49916076660156]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 13.0], "bins": [-44.9764404296875, -44.9377326965332, -44.899024963378906, -44.86031723022461, -44.82160949707031, -44.782901763916016, -44.74419403076172, -44.705482482910156, -44.66677474975586, -44.62806701660156, -44.589359283447266, -44.55065155029297, -44.51194381713867, -44.473236083984375, -44.43452835083008, -44.39582061767578, -44.357112884521484, -44.31840515136719, -44.27969741821289, -44.240989685058594, -44.20227813720703, -44.163570404052734, -44.12486267089844, -44.08615493774414, -44.047447204589844, -44.00873947143555, -43.97003173828125, -43.93132400512695, -43.892616271972656, -43.85390853881836, -43.81520080566406, -43.776493072509766, -43.73778533935547, -43.699073791503906, -43.66036605834961, -43.62165832519531, -43.582950592041016, -43.54424285888672, -43.50553512573242, -43.466827392578125, -43.42811965942383, -43.38941192626953, -43.350704193115234, -43.31199645996094, -43.27328872680664, -43.234580993652344, -43.19586944580078, -43.157161712646484, -43.11845397949219, -43.07974624633789, -43.041038513183594, -43.0023307800293, -42.963623046875, -42.9249153137207, -42.886207580566406, -42.84749984741211, -42.80879211425781, -42.770084381103516, -42.73137664794922, -42.692665100097656, -42.65395736694336, -42.61524963378906, -42.576541900634766, -42.53783416748047, -42.49912643432617]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 1.0], "bins": [-0.7347648739814758, -0.7229438424110413, -0.7111228108406067, -0.6993018388748169, -0.6874808073043823, -0.6756597757339478, -0.6638387441635132, -0.6520177125930786, -0.640196681022644, -0.6283756494522095, -0.6165546178817749, -0.6047336459159851, -0.5929126143455505, -0.581091582775116, -0.5692705512046814, -0.5574495196342468, -0.545628547668457, -0.5338075160980225, -0.5219864845275879, -0.5101654529571533, -0.49834442138671875, -0.4865233898162842, -0.474702388048172, -0.4628813564777374, -0.45106035470962524, -0.4392393231391907, -0.4274182915687561, -0.41559725999832153, -0.40377625823020935, -0.3919552266597748, -0.3801341950893402, -0.368313193321228, -0.35649216175079346, -0.3446711301803589, -0.3328501284122467, -0.32102909684181213, -0.30920806527137756, -0.2973870635032654, -0.2855660319328308, -0.27374500036239624, -0.26192396879196167, -0.2501029670238495, -0.23828193545341492, -0.22646093368530273, -0.21463990211486816, -0.2028188705444336, -0.19099783897399902, -0.17917680740356445, -0.16735583543777466, -0.1555348038673401, -0.14371377229690552, -0.13189274072647095, -0.12007170915603638, -0.1082506775856018, -0.09642964601516724, -0.08460867404937744, -0.07278764247894287, -0.0609666109085083, -0.04914557933807373, -0.03732454776763916, -0.02550351619720459, -0.013682544231414795, -0.0018615126609802246, 0.009959518909454346, 0.021780550479888916]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 29.0, 388.0, 3.0, 18.0, 29.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 6.0, 0.0, 2.0, 6.0], "bins": [-1.3145711421966553, -1.2833797931671143, -1.2521885633468628, -1.2209973335266113, -1.1898059844970703, -1.1586146354675293, -1.1274234056472778, -1.0962321758270264, -1.0650408267974854, -1.0338494777679443, -1.0026582479476929, -0.9714669585227966, -0.9402756690979004, -0.9090843796730042, -0.8778930902481079, -0.8467018008232117, -0.8155105113983154, -0.7843192219734192, -0.753127932548523, -0.7219366431236267, -0.6907453536987305, -0.6595540642738342, -0.628362774848938, -0.5971714854240417, -0.5659801959991455, -0.5347889065742493, -0.503597617149353, -0.4724063277244568, -0.44121503829956055, -0.4100237488746643, -0.37883245944976807, -0.3476411700248718, -0.3164498805999756, -0.28525853157043457, -0.2540673017501831, -0.22287607192993164, -0.19168472290039062, -0.1604933738708496, -0.12930214405059814, -0.09811091423034668, -0.06691956520080566, -0.03572821617126465, -0.004536986351013184, 0.02665424346923828, 0.0578455924987793, 0.08903694152832031, 0.12022817134857178, 0.15141940116882324, 0.18261075019836426, 0.21380209922790527, 0.24499332904815674, 0.2761845588684082, 0.3073759078979492, 0.33856725692749023, 0.3697584867477417, 0.40094971656799316, 0.4321410655975342, 0.4633324146270752, 0.49452364444732666, 0.5257148742675781, 0.5569062232971191, 0.5880975723266602, 0.6192888021469116, 0.6504800319671631, 0.6816713809967041]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7527053952217102, -0.6914292573928833, -0.6301531791687012, -0.5688770413398743, -0.5076009035110474, -0.44632476568222046, -0.38504865765571594, -0.3237725496292114, -0.2624964118003845, -0.20122027397155762, -0.1399441361427307, -0.07866805791854858, -0.01739192008972168, 0.043884217739105225, 0.10516029596328735, 0.16643643379211426, 0.22771257162094116, 0.2889886498451233, 0.35026484727859497, 0.4115409255027771, 0.4728171229362488, 0.5340932011604309, 0.595369279384613, 0.6566454768180847, 0.7179215550422668, 0.779197633266449, 0.8404738306999207, 0.9017499089241028, 0.9630259871482849, 1.0243022441864014, 1.085578203201294, 1.1468544006347656, 1.2081305980682373, 1.269406795501709, 1.3306827545166016, 1.3919589519500732, 1.453235149383545, 1.5145111083984375, 1.5757873058319092, 1.6370635032653809, 1.6983397006988525, 1.7596156597137451, 1.8208918571472168, 1.8821680545806885, 1.943444013595581, 2.0047202110290527, 2.0659964084625244, 2.127272367477417, 2.1885485649108887, 2.2498247623443604, 2.311100721359253, 2.3723769187927246, 2.4336531162261963, 2.494929075241089, 2.5562052726745605, 2.6174814701080322, 2.678757429122925, 2.7400336265563965, 2.801309823989868, 2.86258602142334, 2.9238619804382324, 2.985138177871704, 3.046414375305176, 3.1076903343200684, 3.16896653175354]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 6.0, 2.0, 3.0, 3.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0, 5.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12110888957977295, -0.11679992079734802, -0.11249095946550369, -0.10818199068307877, -0.10387302190065384, -0.09956406056880951, -0.09525509178638458, -0.09094612300395966, -0.08663715422153473, -0.0823281928896904, -0.07801922410726547, -0.07371026277542114, -0.06940129399299622, -0.06509232521057129, -0.06078336015343666, -0.05647439509630203, -0.052165426313877106, -0.04785645753145218, -0.04354749619960785, -0.03923852741718292, -0.034929558634757996, -0.030620597302913666, -0.02631162852048874, -0.022002659738063812, -0.017693698406219482, -0.013384729623794556, -0.009075760841369629, -0.004766792058944702, -0.0004578307271003723, 0.0038511380553245544, 0.008160099387168884, 0.012469068169593811, 0.016778036952018738, 0.021087005734443665, 0.02539597451686859, 0.029704943299293518, 0.03401389718055725, 0.03832286596298218, 0.042631834745407104, 0.04694080352783203, 0.05124977231025696, 0.055558741092681885, 0.05986769497394562, 0.06417666375637054, 0.06848563253879547, 0.0727946013212204, 0.07710357010364532, 0.08141253888607025, 0.08572149276733398, 0.09003046154975891, 0.09433943033218384, 0.09864839911460876, 0.10295736789703369, 0.10726633667945862, 0.11157530546188354, 0.11588425934314728, 0.1201932281255722, 0.12450219690799713, 0.12881116569042206, 0.1331201195716858, 0.13742908835411072, 0.14173805713653564, 0.14604702591896057, 0.1503559947013855, 0.15466496348381042]}, "_runtime": 3794.475323200226, "_timestamp": 1585512872.8960528, "_step": 98}
{"Episode reward": -98.51322673539164, "Episode length": 999, "Policy Loss": -0.12742610275745392, "Value Loss": 0.03217724338173866, "_runtime": 3796.0265440940857, "_timestamp": 1585512874.4472737, "_step": 99}
{"Episode reward": -98.00130124468853, "Episode length": 999, "Policy Loss": -0.11337858438491821, "Value Loss": 0.03312937542796135, "_runtime": 3797.576984167099, "_timestamp": 1585512875.9977138, "_step": 100}
{"Episode reward": -98.58213494090107, "Episode length": 999, "Policy Loss": -0.1166551262140274, "Value Loss": 0.028377080336213112, "_runtime": 3799.1318640708923, "_timestamp": 1585512877.5525937, "_step": 101}
{"Episode reward": -98.36240358154072, "Episode length": 999, "Policy Loss": -0.11561410129070282, "Value Loss": 0.028050482273101807, "_runtime": 3800.6936802864075, "_timestamp": 1585512879.11441, "_step": 102}
{"Episode reward": -99.24490368473948, "Episode length": 999, "Policy Loss": -0.10089670121669769, "Value Loss": 0.02159237302839756, "_runtime": 3802.253575563431, "_timestamp": 1585512880.6743052, "_step": 103}
{"Episode reward": -98.32449080419121, "Episode length": 999, "Policy Loss": -0.10741215199232101, "Value Loss": 0.027514254674315453, "_runtime": 3803.8186872005463, "_timestamp": 1585512882.2394168, "_step": 104}
{"Episode reward": -99.660033603193, "Episode length": 999, "Policy Loss": -0.101016104221344, "Value Loss": 0.01904401183128357, "_runtime": 3805.3808164596558, "_timestamp": 1585512883.801546, "_step": 105}
{"Episode reward": -97.75036239613311, "Episode length": 999, "Policy Loss": -0.10405926406383514, "Value Loss": 0.025032980367541313, "_runtime": 3806.965482711792, "_timestamp": 1585512885.3862123, "_step": 106}
{"Episode reward": -99.65484272437998, "Episode length": 999, "Policy Loss": -0.09608922153711319, "Value Loss": 0.01744026131927967, "_runtime": 3808.5149476528168, "_timestamp": 1585512886.9356773, "_step": 107}
{"Episode reward": -98.63893157679746, "Episode length": 999, "Policy Loss": -0.09806784242391586, "Value Loss": 0.02036738581955433, "_runtime": 3810.074041366577, "_timestamp": 1585512888.494771, "_step": 108}
{"Episode reward": -98.15479472506809, "Episode length": 999, "Policy Loss": -0.09317248314619064, "Value Loss": 0.021309563890099525, "_runtime": 3811.6390192508698, "_timestamp": 1585512890.059749, "_step": 109}
{"Episode reward": -99.54270767766538, "Episode length": 999, "Policy Loss": -0.08495711535215378, "Value Loss": 0.015066076070070267, "_runtime": 3813.2070546150208, "_timestamp": 1585512891.6277843, "_step": 110}
{"Episode reward": -98.67206780421932, "Episode length": 999, "Policy Loss": -0.08869010210037231, "Value Loss": 0.016526231542229652, "_runtime": 3814.7672414779663, "_timestamp": 1585512893.187971, "_step": 111}
{"Episode reward": -98.23381646426694, "Episode length": 999, "Policy Loss": -0.08907230943441391, "Value Loss": 0.016212735325098038, "_runtime": 3816.326301574707, "_timestamp": 1585512894.7470312, "_step": 112}
{"Episode reward": -98.49035148596049, "Episode length": 999, "Policy Loss": -0.0862732008099556, "Value Loss": 0.014894101768732071, "_runtime": 3817.8845505714417, "_timestamp": 1585512896.3052802, "_step": 113}
{"Episode reward": -99.41454119209119, "Episode length": 999, "Policy Loss": -0.08163260668516159, "Value Loss": 0.012109976261854172, "_runtime": 3819.4429411888123, "_timestamp": 1585512897.8636708, "_step": 114}
{"Episode reward": -98.74665597968965, "Episode length": 999, "Policy Loss": -0.07708355039358139, "Value Loss": 0.012298564426600933, "_runtime": 3821.000855922699, "_timestamp": 1585512899.4215856, "_step": 115}
{"Episode reward": -97.5720540112005, "Episode length": 999, "Policy Loss": -0.0703696459531784, "Value Loss": 0.014119802042841911, "_runtime": 3822.563091993332, "_timestamp": 1585512900.9838216, "_step": 116}
{"Episode reward": -97.58291601395844, "Episode length": 999, "Policy Loss": -0.07831734418869019, "Value Loss": 0.013196439482271671, "_runtime": 3824.1115012168884, "_timestamp": 1585512902.5322309, "_step": 117}
{"Episode reward": -99.47903340484739, "Episode length": 999, "Policy Loss": -0.071182020008564, "Value Loss": 0.009686793200671673, "_runtime": 3825.6706128120422, "_timestamp": 1585512904.0913424, "_step": 118}
{"Episode reward": -98.35485723669849, "Episode length": 999, "Policy Loss": -0.06794974207878113, "Value Loss": 0.010162281803786755, "_runtime": 3827.2314155101776, "_timestamp": 1585512905.6521451, "_step": 119}
{"Episode reward": -99.29151234670847, "Episode length": 999, "Policy Loss": -0.06401327252388, "Value Loss": 0.008821588940918446, "_runtime": 3828.791865825653, "_timestamp": 1585512907.2125955, "_step": 120}
{"Episode reward": -99.06312398029081, "Episode length": 999, "Policy Loss": -0.05979584529995918, "Value Loss": 0.008109703660011292, "_runtime": 3830.3842673301697, "_timestamp": 1585512908.804997, "_step": 121}
{"Episode reward": -98.74016391809045, "Episode length": 999, "Policy Loss": -0.05905972421169281, "Value Loss": 0.007670895662158728, "_runtime": 3831.949143886566, "_timestamp": 1585512910.3698735, "_step": 122}
{"Episode reward": -98.1422157475382, "Episode length": 999, "Policy Loss": -0.06203947588801384, "Value Loss": 0.008425637148320675, "_runtime": 3833.499409198761, "_timestamp": 1585512911.9201388, "_step": 123}
{"Episode reward": -98.41017984414573, "Episode length": 999, "Policy Loss": -0.06008148193359375, "Value Loss": 0.00747552327811718, "_runtime": 3835.0465939044952, "_timestamp": 1585512913.4673235, "_step": 124}
{"Episode reward": -99.86877559882366, "Episode length": 999, "Policy Loss": -0.055196069180965424, "Value Loss": 0.007436269894242287, "_runtime": 3836.608026266098, "_timestamp": 1585512915.028756, "_step": 125}
{"Episode reward": -98.3761472605062, "Episode length": 999, "Policy Loss": -0.05181305482983589, "Value Loss": 0.0074434056878089905, "_runtime": 3838.1670355796814, "_timestamp": 1585512916.5877652, "_step": 126}
{"Episode reward": -98.13295822737213, "Episode length": 999, "Policy Loss": -0.050194770097732544, "Value Loss": 0.008128252811729908, "_runtime": 3839.713322877884, "_timestamp": 1585512918.1340525, "_step": 127}
{"Episode reward": -98.69712909473114, "Episode length": 999, "Policy Loss": -0.049013275653123856, "Value Loss": 0.006078535225242376, "_runtime": 3841.2753989696503, "_timestamp": 1585512919.6961286, "_step": 128}
{"Episode reward": -99.59077420705773, "Episode length": 999, "Policy Loss": -0.04476478323340416, "Value Loss": 0.006451647263020277, "_runtime": 3842.83349108696, "_timestamp": 1585512921.2542207, "_step": 129}
{"Episode reward": -98.67281770328617, "Episode length": 999, "Policy Loss": -0.045987825840711594, "Value Loss": 0.005545161664485931, "_runtime": 3844.380934715271, "_timestamp": 1585512922.8016644, "_step": 130}
{"Episode reward": -98.05043171172522, "Episode length": 999, "Policy Loss": -0.04375017434358597, "Value Loss": 0.006339618936181068, "_runtime": 3845.9203634262085, "_timestamp": 1585512924.341093, "_step": 131}
{"Episode reward": -98.1850922756181, "Episode length": 999, "Policy Loss": -0.04410973936319351, "Value Loss": 0.005562770180404186, "_runtime": 3847.472058057785, "_timestamp": 1585512925.8927877, "_step": 132}
{"Episode reward": -98.96219363336549, "Episode length": 999, "Policy Loss": -0.04173584282398224, "Value Loss": 0.005114096682518721, "_runtime": 3849.019784927368, "_timestamp": 1585512927.4405146, "_step": 133}
{"Episode reward": -98.49492016373019, "Episode length": 999, "Policy Loss": -0.03875042498111725, "Value Loss": 0.0050285314209759235, "_runtime": 3850.5830919742584, "_timestamp": 1585512929.0038216, "_step": 134}
{"Episode reward": -99.71848960798437, "Episode length": 999, "Policy Loss": -0.03890353813767433, "Value Loss": 0.00518169766291976, "_runtime": 3852.1313951015472, "_timestamp": 1585512930.5521247, "_step": 135}
{"Episode reward": -98.77175449583632, "Episode length": 999, "Policy Loss": -0.03811819106340408, "Value Loss": 0.0045026205480098724, "_runtime": 3853.727062702179, "_timestamp": 1585512932.1477923, "_step": 136}
{"Episode reward": -98.89828450110613, "Episode length": 999, "Policy Loss": -0.03751080483198166, "Value Loss": 0.004157966002821922, "_runtime": 3855.2810142040253, "_timestamp": 1585512933.7017438, "_step": 137}
{"Episode reward": -99.6115601511161, "Episode length": 999, "Policy Loss": -0.033963892608881, "Value Loss": 0.00448947586119175, "_runtime": 3856.841655254364, "_timestamp": 1585512935.262385, "_step": 138}
{"Episode reward": -99.21683012588713, "Episode length": 999, "Policy Loss": -0.032578837126493454, "Value Loss": 0.004026810172945261, "_runtime": 3858.39404964447, "_timestamp": 1585512936.8147793, "_step": 139}
{"Episode reward": -99.39198953672488, "Episode length": 999, "Policy Loss": -0.03240540623664856, "Value Loss": 0.003945752512663603, "_runtime": 3859.9456284046173, "_timestamp": 1585512938.366358, "_step": 140}
{"Episode reward": -99.14869120322153, "Episode length": 999, "Policy Loss": -0.03641064837574959, "Value Loss": 0.003563425038009882, "_runtime": 3861.5060238838196, "_timestamp": 1585512939.9267535, "_step": 141}
{"Episode reward": -99.88493518042519, "Episode length": 999, "Policy Loss": -0.034840237349271774, "Value Loss": 0.0036930206697434187, "_runtime": 3863.051181077957, "_timestamp": 1585512941.4719107, "_step": 142}
{"Episode reward": -99.11999466593082, "Episode length": 999, "Policy Loss": -0.032921504229307175, "Value Loss": 0.0032299072481691837, "_runtime": 3864.5936799049377, "_timestamp": 1585512943.0144095, "_step": 143}
{"Episode reward": -98.84722593653781, "Episode length": 999, "Policy Loss": -0.032069768756628036, "Value Loss": 0.002866603434085846, "_runtime": 3866.157373189926, "_timestamp": 1585512944.5781028, "_step": 144}
{"Episode reward": -98.54840121785611, "Episode length": 999, "Policy Loss": -0.03164725750684738, "Value Loss": 0.0030514104291796684, "_runtime": 3867.7178292274475, "_timestamp": 1585512946.1385589, "_step": 145}
{"Episode reward": -98.81321691464785, "Episode length": 999, "Policy Loss": -0.02900678664445877, "Value Loss": 0.0028574145399034023, "_runtime": 3869.2780928611755, "_timestamp": 1585512947.6988225, "_step": 146}
{"Episode reward": -98.65576889009199, "Episode length": 999, "Policy Loss": -0.028124133124947548, "Value Loss": 0.004241292830556631, "_runtime": 3870.8299317359924, "_timestamp": 1585512949.2506614, "_step": 147}
{"Episode reward": -97.84546893167665, "Episode length": 999, "Policy Loss": -0.03389841318130493, "Value Loss": 0.004298349842429161, "_runtime": 3872.390857934952, "_timestamp": 1585512950.8115876, "_step": 148}
{"Episode reward": -99.20040531314335, "Episode length": 999, "Policy Loss": -0.0301058329641819, "Value Loss": 0.0025005743373185396, "_runtime": 3873.9457607269287, "_timestamp": 1585512952.3664904, "_step": 149}
{"Episode reward": -99.21130067631252, "Episode length": 999, "Policy Loss": -0.031056350097060204, "Value Loss": 0.002299564890563488, "_runtime": 3875.5063395500183, "_timestamp": 1585512953.9270692, "_step": 150}
{"Episode reward": -97.8652332285858, "Episode length": 999, "Policy Loss": -0.03401707857847214, "Value Loss": 0.004104466177523136, "_runtime": 3877.100254058838, "_timestamp": 1585512955.5209837, "_step": 151}
{"Episode reward": -98.47409475912431, "Episode length": 999, "Policy Loss": -0.024880442768335342, "Value Loss": 0.0028112560976296663, "_runtime": 3878.6595287323, "_timestamp": 1585512957.0802584, "_step": 152}
{"Episode reward": -98.58776362531806, "Episode length": 999, "Policy Loss": -0.026008982211351395, "Value Loss": 0.002324905479326844, "_runtime": 3880.219892024994, "_timestamp": 1585512958.6406217, "_step": 153}
{"Episode reward": -99.26735613604983, "Episode length": 999, "Policy Loss": -0.027656782418489456, "Value Loss": 0.0018215760355815291, "_runtime": 3881.77986907959, "_timestamp": 1585512960.2005987, "_step": 154}
{"Episode reward": -98.14353204743855, "Episode length": 999, "Policy Loss": -0.023254482075572014, "Value Loss": 0.0026558302342891693, "_runtime": 3883.341747522354, "_timestamp": 1585512961.7624772, "_step": 155}
{"Episode reward": -98.25343307326416, "Episode length": 999, "Policy Loss": -0.02316988818347454, "Value Loss": 0.003091351129114628, "_runtime": 3884.9005930423737, "_timestamp": 1585512963.3213227, "_step": 156}
{"Episode reward": -99.01210709912608, "Episode length": 999, "Policy Loss": -0.026300637051463127, "Value Loss": 0.0016079500783234835, "_runtime": 3886.45801115036, "_timestamp": 1585512964.8787408, "_step": 157}
{"Episode reward": -98.5314967115323, "Episode length": 999, "Policy Loss": -0.02203909493982792, "Value Loss": 0.002373367315158248, "_runtime": 3888.006675004959, "_timestamp": 1585512966.4274046, "_step": 158}
{"Episode reward": -98.50144414462913, "Episode length": 999, "Policy Loss": -0.02325580082833767, "Value Loss": 0.0015045483596622944, "_runtime": 3889.557295560837, "_timestamp": 1585512967.9780252, "_step": 159}
{"Episode reward": -99.20639941635106, "Episode length": 999, "Policy Loss": -0.023520207032561302, "Value Loss": 0.0015238618943840265, "_runtime": 3891.104297876358, "_timestamp": 1585512969.5250275, "_step": 160}
{"Episode reward": -98.25279342235864, "Episode length": 999, "Policy Loss": -0.02115522138774395, "Value Loss": 0.0019060252234339714, "_runtime": 3892.6523835659027, "_timestamp": 1585512971.0731132, "_step": 161}
{"Episode reward": -98.44663558485075, "Episode length": 999, "Policy Loss": -0.022994132712483406, "Value Loss": 0.001406657975167036, "_runtime": 3894.2160053253174, "_timestamp": 1585512972.636735, "_step": 162}
{"Episode reward": -98.19472001310997, "Episode length": 999, "Policy Loss": -0.021553633734583855, "Value Loss": 0.002929743379354477, "_runtime": 3895.7755193710327, "_timestamp": 1585512974.196249, "_step": 163}
{"Episode reward": -99.51051041037205, "Episode length": 999, "Policy Loss": -0.020039411261677742, "Value Loss": 0.0015906918561086059, "_runtime": 3897.3253355026245, "_timestamp": 1585512975.7460651, "_step": 164}
{"Episode reward": -98.77018168410183, "Episode length": 999, "Policy Loss": -0.02144419401884079, "Value Loss": 0.0010469526750966907, "_runtime": 3898.8854353427887, "_timestamp": 1585512977.306165, "_step": 165}
{"Episode reward": -98.17568337879682, "Episode length": 999, "Policy Loss": -0.018448108807206154, "Value Loss": 0.002702943980693817, "_runtime": 3900.4810461997986, "_timestamp": 1585512978.9017758, "_step": 166}
{"Episode reward": -99.71847823285198, "Episode length": 999, "Policy Loss": -0.017459247261285782, "Value Loss": 0.0015253357123583555, "_runtime": 3902.033453941345, "_timestamp": 1585512980.4541836, "_step": 167}
{"Episode reward": -98.22360272434223, "Episode length": 999, "Policy Loss": -0.017276659607887268, "Value Loss": 0.002267078962177038, "_runtime": 3903.5947575569153, "_timestamp": 1585512982.0154872, "_step": 168}
{"Episode reward": -98.61291876072298, "Episode length": 999, "Policy Loss": -0.016805140301585197, "Value Loss": 0.0016268789768218994, "_runtime": 3905.1595964431763, "_timestamp": 1585512983.580326, "_step": 169}
{"Episode reward": -99.55608099707433, "Episode length": 999, "Policy Loss": -0.01734686829149723, "Value Loss": 0.0013373427791520953, "_runtime": 3906.730041742325, "_timestamp": 1585512985.1507714, "_step": 170}
{"Episode reward": -98.96855919492837, "Episode length": 999, "Policy Loss": -0.01798195391893387, "Value Loss": 0.000732245622202754, "_runtime": 3908.2994487285614, "_timestamp": 1585512986.7201784, "_step": 171}
{"Episode reward": -99.39627246322576, "Episode length": 999, "Policy Loss": -0.016580278053879738, "Value Loss": 0.0011450548190623522, "_runtime": 3909.857800245285, "_timestamp": 1585512988.27853, "_step": 172}
{"Episode reward": -98.97518007750989, "Episode length": 999, "Policy Loss": -0.016194941475987434, "Value Loss": 0.0008058057283051312, "_runtime": 3911.4205169677734, "_timestamp": 1585512989.8412466, "_step": 173}
{"Episode reward": -98.12278226497489, "Episode length": 999, "Policy Loss": -0.017311932519078255, "Value Loss": 0.0026957800146192312, "_runtime": 3912.966833591461, "_timestamp": 1585512991.3875632, "_step": 174}
{"Episode reward": -99.70862165988345, "Episode length": 999, "Policy Loss": -0.014908630400896072, "Value Loss": 0.001214982708916068, "_runtime": 3914.5227308273315, "_timestamp": 1585512992.9434605, "_step": 175}
{"Episode reward": -99.6883186468289, "Episode length": 999, "Policy Loss": -0.013334734365344048, "Value Loss": 0.001155232428573072, "_runtime": 3916.0742676258087, "_timestamp": 1585512994.4949973, "_step": 176}
{"Episode reward": -99.79842937523998, "Episode length": 999, "Policy Loss": -0.013744307681918144, "Value Loss": 0.0011602499289438128, "_runtime": 3917.624388217926, "_timestamp": 1585512996.0451179, "_step": 177}
{"Episode reward": -99.49920435403762, "Episode length": 999, "Policy Loss": -0.013334487564861774, "Value Loss": 0.0009935180423781276, "_runtime": 3919.1864080429077, "_timestamp": 1585512997.6071377, "_step": 178}
{"Episode reward": -99.71223024072432, "Episode length": 999, "Policy Loss": -0.012494001537561417, "Value Loss": 0.0010954953031614423, "_runtime": 3920.738389492035, "_timestamp": 1585512999.1591191, "_step": 179}
{"Episode reward": -97.94962446706229, "Episode length": 999, "Policy Loss": -0.011141271330416203, "Value Loss": 0.0020585714373737574, "_runtime": 3922.3342950344086, "_timestamp": 1585513000.7550247, "_step": 180}
{"Episode reward": -99.15813834230914, "Episode length": 999, "Policy Loss": -0.012512537650763988, "Value Loss": 0.0007292916416190565, "_runtime": 3923.882379055023, "_timestamp": 1585513002.3031087, "_step": 181}
{"Episode reward": -98.36634849682618, "Episode length": 999, "Policy Loss": -0.010227762162685394, "Value Loss": 0.0008209609077312052, "_runtime": 3925.436842918396, "_timestamp": 1585513003.8575726, "_step": 182}
{"Episode reward": -98.4922256333175, "Episode length": 999, "Policy Loss": -0.008480358868837357, "Value Loss": 0.0013391189277172089, "_runtime": 3926.9878549575806, "_timestamp": 1585513005.4085846, "_step": 183}
{"Episode reward": -99.72304780950226, "Episode length": 999, "Policy Loss": -0.009916847571730614, "Value Loss": 0.0009727885480970144, "_runtime": 3928.536851167679, "_timestamp": 1585513006.9575808, "_step": 184}
{"Episode reward": -98.26172654158607, "Episode length": 999, "Policy Loss": -0.008092772215604782, "Value Loss": 0.001660705078393221, "_runtime": 3930.080290555954, "_timestamp": 1585513008.5010202, "_step": 185}
{"Episode reward": -99.7992203037722, "Episode length": 999, "Policy Loss": -0.009017715230584145, "Value Loss": 0.0009695005137473345, "_runtime": 3931.6407537460327, "_timestamp": 1585513010.0614834, "_step": 186}
{"Episode reward": -99.60425404057996, "Episode length": 999, "Policy Loss": -0.009501284919679165, "Value Loss": 0.0008917864761315286, "_runtime": 3933.2025096416473, "_timestamp": 1585513011.6232393, "_step": 187}
{"Episode reward": -98.01209801717005, "Episode length": 999, "Policy Loss": -0.006958543322980404, "Value Loss": 0.0016548902494832873, "_runtime": 3934.7552406787872, "_timestamp": 1585513013.1759703, "_step": 188}
{"Episode reward": -99.86155885537842, "Episode length": 999, "Policy Loss": -0.007687722332775593, "Value Loss": 0.000942981627304107, "_runtime": 3936.318296432495, "_timestamp": 1585513014.739026, "_step": 189}
{"Episode reward": -99.57241244245509, "Episode length": 999, "Policy Loss": -0.008993156254291534, "Value Loss": 0.0008021494722925127, "_runtime": 3937.879408597946, "_timestamp": 1585513016.3001382, "_step": 190}
{"Episode reward": -99.11404395202226, "Episode length": 999, "Policy Loss": -0.008492067456245422, "Value Loss": 0.0004892628057859838, "_runtime": 3939.4328677654266, "_timestamp": 1585513017.8535974, "_step": 191}
{"Episode reward": -97.96564029966133, "Episode length": 999, "Policy Loss": -0.005739590153098106, "Value Loss": 0.0021258285269141197, "_runtime": 3940.9837453365326, "_timestamp": 1585513019.404475, "_step": 192}
{"Episode reward": -98.3208783918318, "Episode length": 999, "Policy Loss": -0.00865993369370699, "Value Loss": 0.00192304328083992, "_runtime": 3942.5451471805573, "_timestamp": 1585513020.9658768, "_step": 193}
{"Episode reward": -99.46695893066462, "Episode length": 999, "Policy Loss": -0.006599133834242821, "Value Loss": 0.0007238347898237407, "_runtime": 3944.094353199005, "_timestamp": 1585513022.5150828, "_step": 194}
{"Episode reward": -99.44111490623538, "Episode length": 999, "Policy Loss": -0.007284499704837799, "Value Loss": 0.0006759431562386453, "_runtime": 3945.6911425590515, "_timestamp": 1585513024.1118722, "_step": 195}
{"Episode reward": -99.0069358983897, "Episode length": 999, "Policy Loss": -0.007837122306227684, "Value Loss": 0.0002941985731013119, "_runtime": 3947.24623131752, "_timestamp": 1585513025.666961, "_step": 196}
{"Episode reward": -99.4744263187528, "Episode length": 999, "Policy Loss": -0.006256732624024153, "Value Loss": 0.0007257700781337917, "_runtime": 3948.810248374939, "_timestamp": 1585513027.230978, "_step": 197}
{"Episode reward": -98.25663390033021, "Episode length": 999, "Policy Loss": -0.005766822956502438, "Value Loss": 0.0010749328648671508, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645, -1.9963154792785645]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0], "bins": [-0.03412163257598877, -0.002396106719970703, 0.029329419136047363, 0.06105494499206543, 0.0927804708480835, 0.12450599670410156, 0.15623152256011963, 0.1879570484161377, 0.21968257427215576, 0.25140810012817383, 0.2831336259841919, 0.31485915184020996, 0.346584677696228, 0.3783102035522461, 0.41003572940826416, 0.4417612552642822, 0.4734867811203003, 0.5052123069763184, 0.5369378328323364, 0.5686633586883545, 0.6003888845443726, 0.6321144104003906, 0.6638399362564087, 0.6955654621124268, 0.7272909879684448, 0.7590165138244629, 0.790742039680481, 0.822467565536499, 0.8541930913925171, 0.8859186172485352, 0.9176441431045532, 0.9493696689605713, 0.9810951948165894, 1.0128207206726074, 1.0445462465286255, 1.0762717723846436, 1.1079972982406616, 1.1397228240966797, 1.1714483499526978, 1.2031738758087158, 1.2348994016647339, 1.266624927520752, 1.29835045337677, 1.330075979232788, 1.3618015050888062, 1.3935270309448242, 1.4252525568008423, 1.4569780826568604, 1.4887036085128784, 1.5204291343688965, 1.5521546602249146, 1.5838801860809326, 1.6156057119369507, 1.6473312377929688, 1.6790567636489868, 1.7107822895050049, 1.742507815361023, 1.774233341217041, 1.805958867073059, 1.8376843929290771, 1.8694099187850952, 1.9011354446411133, 1.9328609704971313, 1.9645864963531494, 1.9963120222091675]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 13.0], "bins": [-1.6289030313491821, -1.6031244993209839, -1.577345848083496, -1.5515673160552979, -1.5257887840270996, -1.5000102519989014, -1.4742316007614136, -1.4484530687332153, -1.422674536705017, -1.3968958854675293, -1.371117353439331, -1.3453388214111328, -1.3195602893829346, -1.2937816381454468, -1.2680031061172485, -1.2422245740890503, -1.2164459228515625, -1.1906673908233643, -1.164888858795166, -1.1391103267669678, -1.1133317947387695, -1.0875531435012817, -1.0617746114730835, -1.0359959602355957, -1.0102174282073975, -0.9844388961791992, -0.9586603045463562, -0.932881772518158, -0.9071031808853149, -0.8813246488571167, -0.8555460572242737, -0.8297675251960754, -0.8039889335632324, -0.7782103419303894, -0.7524318099021912, -0.7266532182693481, -0.7008746862411499, -0.6750960946083069, -0.6493175625801086, -0.6235389709472656, -0.5977604389190674, -0.5719817876815796, -0.5462032556533813, -0.5204247236251831, -0.49464619159698486, -0.46886754035949707, -0.44308900833129883, -0.4173104763031006, -0.3915318250656128, -0.36575329303741455, -0.3399747610092163, -0.31419622898101807, -0.2884175777435303, -0.26263904571533203, -0.2368605136871338, -0.21108198165893555, -0.18530333042144775, -0.1595247983932495, -0.13374626636505127, -0.10796761512756348, -0.08218908309936523, -0.05641055107116699, -0.03063201904296875, -0.004853367805480957, 0.020925164222717285]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 416.0, 62.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 11.0], "bins": [-5.16819429397583, -5.062544822692871, -4.956894874572754, -4.851245403289795, -4.745595455169678, -4.639945983886719, -4.534296035766602, -4.428646564483643, -4.322997093200684, -4.217347145080566, -4.111697196960449, -4.00604772567749, -3.9003982543945312, -3.794748306274414, -3.689098834991455, -3.583449125289917, -3.477799415588379, -3.372149705886841, -3.2664999961853027, -3.1608502864837646, -3.0552005767822266, -2.9495511054992676, -2.8439013957977295, -2.7382516860961914, -2.6326019763946533, -2.5269522666931152, -2.421302556991577, -2.315652847290039, -2.21000337600708, -2.104353666305542, -1.998703956604004, -1.8930542469024658, -1.7874045372009277, -1.6817548274993896, -1.5761051177978516, -1.4704554080963135, -1.3648056983947754, -1.2591562271118164, -1.1535062789916992, -1.0478568077087402, -0.942206859588623, -0.8365573883056641, -0.7309079170227051, -0.6252579689025879, -0.5196084976196289, -0.4139585494995117, -0.30830907821655273, -0.20265913009643555, -0.09700965881347656, 0.008639812469482422, 0.11428976058959961, 0.2199392318725586, 0.3255891799926758, 0.43123865127563477, 0.536888599395752, 0.6425380706787109, 0.7481875419616699, 0.8538374900817871, 0.9594869613647461, 1.0651369094848633, 1.1707863807678223, 1.2764363288879395, 1.3820858001708984, 1.4877357482910156, 1.5933852195739746]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 4.0, 0.0, 1.0, 3.0, 0.0, 7.0, 2.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.25141179561615, -1.1414976119995117, -1.031583309173584, -0.9216691255569458, -0.8117549419403076, -0.7018407583236694, -0.5919265151023865, -0.4820122718811035, -0.37209808826446533, -0.26218390464782715, -0.15226972103118896, -0.04235541820526123, 0.06755876541137695, 0.17747294902801514, 0.28738725185394287, 0.39730143547058105, 0.5072156190872192, 0.6171298027038574, 0.7270439863204956, 0.8369582891464233, 0.946872353553772, 1.0567866563796997, 1.1667009592056274, 1.276615023612976, 1.3865293264389038, 1.4964436292648315, 1.6063576936721802, 1.716271996498108, 1.8261862993240356, 1.9361003637313843, 2.0460147857666016, 2.155928611755371, 2.265842914581299, 2.3757572174072266, 2.4856715202331543, 2.595585823059082, 2.7054996490478516, 2.8154139518737793, 2.925328254699707, 3.0352425575256348, 3.1451563835144043, 3.255070686340332, 3.3649849891662598, 3.4748992919921875, 3.5848135948181152, 3.694727897644043, 3.8046417236328125, 3.9145560264587402, 4.024470329284668, 4.134384632110596, 4.244298934936523, 4.354212760925293, 4.464127063751221, 4.574041366577148, 4.683955669403076, 4.793869972229004, 4.903784275054932, 5.013698101043701, 5.123612403869629, 5.233526706695557, 5.343441009521484, 5.453355312347412, 5.563269138336182, 5.673183441162109, 5.783097743988037]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 12.0, 14.0, 12.0, 0.0, 1.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.932342529296875, -3.857492446899414, -3.782642364501953, -3.7077925205230713, -3.6329424381256104, -3.5580923557281494, -3.4832422733306885, -3.4083924293518066, -3.3335423469543457, -3.2586922645568848, -3.183842182159424, -3.108992099761963, -3.034142017364502, -2.95929217338562, -2.884442090988159, -2.8095922470092773, -2.7347421646118164, -2.6598920822143555, -2.5850419998168945, -2.5101919174194336, -2.4353418350219727, -2.3604917526245117, -2.28564190864563, -2.210791826248169, -2.135941743850708, -2.061091899871826, -1.9862416982650757, -1.9113917350769043, -1.8365416526794434, -1.7616915702819824, -1.6868417263031006, -1.6119916439056396, -1.5371415615081787, -1.4622914791107178, -1.3874413967132568, -1.312591552734375, -1.237741470336914, -1.1628913879394531, -1.0880413055419922, -1.0131914615631104, -0.9383413791656494, -0.8634912967681885, -0.7886412143707275, -0.7137911319732666, -0.6389412879943848, -0.5640912055969238, -0.4892411231994629, -0.41439104080200195, -0.339540958404541, -0.2646911144256592, -0.18984103202819824, -0.1149909496307373, -0.04014086723327637, 0.03470897674560547, 0.1095590591430664, 0.18440914154052734, 0.2592592239379883, 0.3341093063354492, 0.40895938873291016, 0.4838094711303711, 0.5586590766906738, 0.6335091590881348, 0.7083592414855957, 0.7832093238830566, 0.8580594062805176]}, "_runtime": 3950.3579359054565, "_timestamp": 1585513028.7786655, "_step": 198}
{"Episode reward": -98.11911440173283, "Episode length": 999, "Policy Loss": -0.005223521497100592, "Value Loss": 0.00140843924600631, "_runtime": 3951.9193682670593, "_timestamp": 1585513030.340098, "_step": 199}
{"Episode reward": -99.79951387696043, "Episode length": 999, "Policy Loss": -0.004877164028584957, "Value Loss": 0.0007871192065067589, "_runtime": 3953.482581138611, "_timestamp": 1585513031.9033108, "_step": 200}
{"Episode reward": -99.63458052821292, "Episode length": 999, "Policy Loss": -0.0045921942219138145, "Value Loss": 0.0007520704530179501, "_runtime": 3955.029839992523, "_timestamp": 1585513033.4505696, "_step": 201}
{"Episode reward": -99.37256412057195, "Episode length": 999, "Policy Loss": -0.004619700834155083, "Value Loss": 0.0006007595220580697, "_runtime": 3956.589485168457, "_timestamp": 1585513035.0102148, "_step": 202}
{"Episode reward": -98.26889364059488, "Episode length": 999, "Policy Loss": -0.0037855852860957384, "Value Loss": 0.0011961853597313166, "_runtime": 3958.1411130428314, "_timestamp": 1585513036.5618427, "_step": 203}
{"Episode reward": -98.55735445536305, "Episode length": 999, "Policy Loss": -0.004485319834202528, "Value Loss": 0.00044255395187065005, "_runtime": 3959.7038419246674, "_timestamp": 1585513038.1245716, "_step": 204}
{"Episode reward": -97.60284934577781, "Episode length": 999, "Policy Loss": -0.006779629737138748, "Value Loss": 0.0020156046375632286, "_runtime": 3961.2545051574707, "_timestamp": 1585513039.6752348, "_step": 205}
{"Episode reward": -99.27079678229387, "Episode length": 999, "Policy Loss": -0.005949459969997406, "Value Loss": 0.00044748856453225017, "_runtime": 3962.8175477981567, "_timestamp": 1585513041.2382774, "_step": 206}
{"Episode reward": -99.1799690676621, "Episode length": 999, "Policy Loss": -0.0046760933473706245, "Value Loss": 0.00035833416040986776, "_runtime": 3964.3677163124084, "_timestamp": 1585513042.788446, "_step": 207}
{"Episode reward": -99.61951990135518, "Episode length": 999, "Policy Loss": -0.0043292115442454815, "Value Loss": 0.0006813202053308487, "_runtime": 3965.9171290397644, "_timestamp": 1585513044.3378587, "_step": 208}
{"Episode reward": -98.68451370643288, "Episode length": 999, "Policy Loss": -0.00382074317894876, "Value Loss": 0.00020793139992747456, "_runtime": 3967.4767904281616, "_timestamp": 1585513045.89752, "_step": 209}
{"Episode reward": -98.18036069220936, "Episode length": 999, "Policy Loss": -0.005621964577585459, "Value Loss": 0.0021739662624895573, "_runtime": 3969.074437856674, "_timestamp": 1585513047.4951675, "_step": 210}
{"Episode reward": -99.34391119624175, "Episode length": 999, "Policy Loss": -0.003237159224227071, "Value Loss": 0.0005611783708445728, "_runtime": 3970.631533384323, "_timestamp": 1585513049.052263, "_step": 211}
{"Episode reward": -98.59615219609417, "Episode length": 999, "Policy Loss": -0.003938122186809778, "Value Loss": 0.00027924019377678633, "_runtime": 3972.1939549446106, "_timestamp": 1585513050.6146846, "_step": 212}
{"Episode reward": -99.12729812931713, "Episode length": 999, "Policy Loss": -0.004329129122197628, "Value Loss": 0.0003362564311828464, "_runtime": 3973.750128507614, "_timestamp": 1585513052.1708581, "_step": 213}
{"Episode reward": -99.1651012774484, "Episode length": 999, "Policy Loss": -0.004306799732148647, "Value Loss": 0.00037160865031182766, "_runtime": 3975.308590888977, "_timestamp": 1585513053.7293205, "_step": 214}
{"Episode reward": -99.76881414952874, "Episode length": 999, "Policy Loss": -0.002583513269200921, "Value Loss": 0.0007085267570801079, "_runtime": 3976.8614597320557, "_timestamp": 1585513055.2821894, "_step": 215}
{"Episode reward": -99.2235382278625, "Episode length": 999, "Policy Loss": -0.004289452917873859, "Value Loss": 0.00035926862619817257, "_runtime": 3978.4147024154663, "_timestamp": 1585513056.835432, "_step": 216}
{"Episode reward": -99.80291536961292, "Episode length": 999, "Policy Loss": -0.0009959181770682335, "Value Loss": 0.0007317849667742848, "_runtime": 3979.9885897636414, "_timestamp": 1585513058.4093194, "_step": 217}
{"Episode reward": -99.12619585085024, "Episode length": 999, "Policy Loss": -0.003824247047305107, "Value Loss": 0.0003382914583198726, "_runtime": 3981.5678782463074, "_timestamp": 1585513059.988608, "_step": 218}
{"Episode reward": -98.00895052905717, "Episode length": 999, "Policy Loss": -0.002131905173882842, "Value Loss": 0.0015195200685411692, "_runtime": 3983.1436779499054, "_timestamp": 1585513061.5644076, "_step": 219}
{"Episode reward": -98.34576166994673, "Episode length": 999, "Policy Loss": -0.003067407291382551, "Value Loss": 0.00024538926663808525, "_runtime": 3984.7209239006042, "_timestamp": 1585513063.1416535, "_step": 220}
{"Episode reward": -99.68571756550445, "Episode length": 999, "Policy Loss": -0.0020560757257044315, "Value Loss": 0.0006803906871937215, "_runtime": 3986.289033651352, "_timestamp": 1585513064.7097633, "_step": 221}
{"Episode reward": -99.47416198290998, "Episode length": 999, "Policy Loss": -0.002939714351668954, "Value Loss": 0.0004652343923225999, "_runtime": 3987.8683030605316, "_timestamp": 1585513066.2890327, "_step": 222}
{"Episode reward": -99.71260755081224, "Episode length": 999, "Policy Loss": -0.0020877597853541374, "Value Loss": 0.000690631743054837, "_runtime": 3989.443464756012, "_timestamp": 1585513067.8641944, "_step": 223}
{"Episode reward": -98.16573792450029, "Episode length": 999, "Policy Loss": -0.002199554117396474, "Value Loss": 0.0014029077719897032, "_runtime": 3991.020544052124, "_timestamp": 1585513069.4412737, "_step": 224}
{"Episode reward": -98.48188239221305, "Episode length": 999, "Policy Loss": -0.0011572515359148383, "Value Loss": 0.0016710790805518627, "_runtime": 3992.6331074237823, "_timestamp": 1585513071.053837, "_step": 225}
{"Episode reward": -99.2760192110312, "Episode length": 999, "Policy Loss": -0.002523065311834216, "Value Loss": 0.0004905218374915421, "_runtime": 3994.19623875618, "_timestamp": 1585513072.6169684, "_step": 226}
{"Episode reward": -98.82559418238566, "Episode length": 999, "Policy Loss": -0.0028495134320110083, "Value Loss": 0.00012618790788110346, "_runtime": 3995.77375459671, "_timestamp": 1585513074.1944842, "_step": 227}
{"Episode reward": -99.63935046215974, "Episode length": 999, "Policy Loss": 0.0004074213211424649, "Value Loss": 0.0006554985302500427, "_runtime": 3997.344178199768, "_timestamp": 1585513075.7649078, "_step": 228}
{"Episode reward": -98.49601501286654, "Episode length": 999, "Policy Loss": -0.001568324863910675, "Value Loss": 0.00023155797680374235, "_runtime": 3998.9090237617493, "_timestamp": 1585513077.3297534, "_step": 229}
{"Episode reward": -98.62912931005566, "Episode length": 999, "Policy Loss": 0.0001480683422414586, "Value Loss": 0.0012592162238433957, "_runtime": 4000.474662542343, "_timestamp": 1585513078.8953922, "_step": 230}
{"Episode reward": -98.4527930025387, "Episode length": 999, "Policy Loss": -0.0018161897314712405, "Value Loss": 0.0002619375882204622, "_runtime": 4002.054319381714, "_timestamp": 1585513080.475049, "_step": 231}
{"Episode reward": -99.81136619727963, "Episode length": 999, "Policy Loss": 0.0004299527790863067, "Value Loss": 0.0007156545761972666, "_runtime": 4003.6296241283417, "_timestamp": 1585513082.0503538, "_step": 232}
{"Episode reward": -98.58658119876321, "Episode length": 999, "Policy Loss": -0.00040363037260249257, "Value Loss": 0.0004050274146720767, "_runtime": 4005.205004453659, "_timestamp": 1585513083.625734, "_step": 233}
{"Episode reward": -99.88202935123124, "Episode length": 999, "Policy Loss": 0.0018502433085814118, "Value Loss": 0.0006918751751072705, "_runtime": 4006.7809777259827, "_timestamp": 1585513085.2017074, "_step": 234}
{"Episode reward": -98.60458124688678, "Episode length": 999, "Policy Loss": 0.00037424161564558744, "Value Loss": 0.0015357877127826214, "_runtime": 4008.345717191696, "_timestamp": 1585513086.7664468, "_step": 235}
{"Episode reward": -98.05345539298662, "Episode length": 999, "Policy Loss": -0.001247213687747717, "Value Loss": 0.0016346542397513986, "_runtime": 4009.921198606491, "_timestamp": 1585513088.3419282, "_step": 236}
{"Episode reward": -99.28565690979713, "Episode length": 999, "Policy Loss": -9.107095684157684e-05, "Value Loss": 0.0004442756180651486, "_runtime": 4011.4864435195923, "_timestamp": 1585513089.9071732, "_step": 237}
{"Episode reward": -99.40043992072178, "Episode length": 999, "Policy Loss": -0.0008441794780083001, "Value Loss": 0.0005247343797236681, "_runtime": 4013.06316113472, "_timestamp": 1585513091.4838908, "_step": 238}
{"Episode reward": -98.69994872443827, "Episode length": 999, "Policy Loss": -0.0014297423185780644, "Value Loss": 0.0001629961479920894, "_runtime": 4014.6762998104095, "_timestamp": 1585513093.0970294, "_step": 239}
{"Episode reward": -99.40495300378144, "Episode length": 999, "Policy Loss": 0.0006888838834129274, "Value Loss": 0.0004674361553043127, "_runtime": 4016.2524106502533, "_timestamp": 1585513094.6731403, "_step": 240}
{"Episode reward": -98.42894118025711, "Episode length": 999, "Policy Loss": -0.0006518451846204698, "Value Loss": 0.00030055808019824326, "_runtime": 4017.827066421509, "_timestamp": 1585513096.247796, "_step": 241}
{"Episode reward": -99.24314610688057, "Episode length": 999, "Policy Loss": 0.0005333515582606196, "Value Loss": 0.00042595062404870987, "_runtime": 4019.392392396927, "_timestamp": 1585513097.813122, "_step": 242}
{"Episode reward": -98.68078870682436, "Episode length": 999, "Policy Loss": -0.0013500649947673082, "Value Loss": 0.00010965191177092493, "_runtime": 4020.9735403060913, "_timestamp": 1585513099.39427, "_step": 243}
{"Episode reward": -98.08586081649358, "Episode length": 999, "Policy Loss": 0.0005933934007771313, "Value Loss": 0.0014312127605080605, "_runtime": 4022.5352334976196, "_timestamp": 1585513100.9559631, "_step": 244}
{"Episode reward": -98.67643675584588, "Episode length": 999, "Policy Loss": -0.001326454454101622, "Value Loss": 0.00010050211858469993, "_runtime": 4024.113674402237, "_timestamp": 1585513102.534404, "_step": 245}
{"Episode reward": -99.04917350477616, "Episode length": 999, "Policy Loss": -0.0012223382946103811, "Value Loss": 9.898334974423051e-05, "_runtime": 4025.6686947345734, "_timestamp": 1585513104.0894244, "_step": 246}
{"Episode reward": -98.0075152584247, "Episode length": 999, "Policy Loss": -0.0020218517165631056, "Value Loss": 0.0021752286702394485, "_runtime": 4027.242713212967, "_timestamp": 1585513105.6634429, "_step": 247}
{"Episode reward": -98.89313586951899, "Episode length": 999, "Policy Loss": -0.0009577288292348385, "Value Loss": 9.49912064243108e-05, "_runtime": 4028.817811489105, "_timestamp": 1585513107.2385411, "_step": 248}
{"Episode reward": -99.40133500090106, "Episode length": 999, "Policy Loss": -0.0002764303353615105, "Value Loss": 0.0003870780928991735, "_runtime": 4030.3841750621796, "_timestamp": 1585513108.8049047, "_step": 249}
{"Episode reward": -98.57801170520597, "Episode length": 999, "Policy Loss": 0.00045319562195800245, "Value Loss": 0.0006275962805375457, "_runtime": 4031.9598093032837, "_timestamp": 1585513110.380539, "_step": 250}
{"Episode reward": -98.243052535038, "Episode length": 999, "Policy Loss": -0.00016691589553374797, "Value Loss": 0.0005802299128845334, "_runtime": 4033.5375866889954, "_timestamp": 1585513111.9583163, "_step": 251}
{"Episode reward": -98.65299400364248, "Episode length": 999, "Policy Loss": 6.390084763552295e-07, "Value Loss": 0.0003339186660014093, "_runtime": 4035.1147994995117, "_timestamp": 1585513113.5355291, "_step": 252}
{"Episode reward": -98.0574818939029, "Episode length": 999, "Policy Loss": 0.0007762101013213396, "Value Loss": 0.0012597359018400311, "_runtime": 4036.688957929611, "_timestamp": 1585513115.1096876, "_step": 253}
{"Episode reward": -99.13182569654246, "Episode length": 999, "Policy Loss": -0.0007095265900716186, "Value Loss": 0.0001083411552826874, "_runtime": 4038.293824672699, "_timestamp": 1585513116.7145543, "_step": 254}
{"Episode reward": -98.20320156172585, "Episode length": 999, "Policy Loss": 0.0028766740579158068, "Value Loss": 0.0009601711062714458, "_runtime": 4039.861321926117, "_timestamp": 1585513118.2820516, "_step": 255}
{"Episode reward": -99.2772344568104, "Episode length": 999, "Policy Loss": -0.0005154086975380778, "Value Loss": 0.00037681663525290787, "_runtime": 4041.4257225990295, "_timestamp": 1585513119.8464522, "_step": 256}
{"Episode reward": -98.27207267069653, "Episode length": 999, "Policy Loss": 0.0017403603997081518, "Value Loss": 0.0010138690704479814, "_runtime": 4042.9938611984253, "_timestamp": 1585513121.4145908, "_step": 257}
{"Episode reward": -99.01016828701111, "Episode length": 999, "Policy Loss": -0.0005954222870059311, "Value Loss": 6.997353921178728e-05, "_runtime": 4044.5745470523834, "_timestamp": 1585513122.9952767, "_step": 258}
{"Episode reward": -98.9013510940968, "Episode length": 999, "Policy Loss": -0.0009599827462807298, "Value Loss": 0.00012783425336237997, "_runtime": 4046.149889230728, "_timestamp": 1585513124.5706189, "_step": 259}
{"Episode reward": -98.80956257590807, "Episode length": 999, "Policy Loss": -0.0007794037228450179, "Value Loss": 9.86617524176836e-05, "_runtime": 4047.7315378189087, "_timestamp": 1585513126.1522675, "_step": 260}
{"Episode reward": -98.70932800726897, "Episode length": 999, "Policy Loss": 0.0006457773852162063, "Value Loss": 0.00018929390353150666, "_runtime": 4049.304610013962, "_timestamp": 1585513127.7253397, "_step": 261}
{"Episode reward": -99.11228014708847, "Episode length": 999, "Policy Loss": 8.835378685034811e-05, "Value Loss": 0.00021112464310135692, "_runtime": 4050.8699157238007, "_timestamp": 1585513129.2906454, "_step": 262}
{"Episode reward": -98.31504480245442, "Episode length": 999, "Policy Loss": -0.0016646155854687095, "Value Loss": 0.0014522562269121408, "_runtime": 4052.4353535175323, "_timestamp": 1585513130.8560832, "_step": 263}
{"Episode reward": -99.7346021278759, "Episode length": 999, "Policy Loss": 0.0012136184377595782, "Value Loss": 0.0006715727504342794, "_runtime": 4054.011300802231, "_timestamp": 1585513132.4320304, "_step": 264}
{"Episode reward": -98.70096553759117, "Episode length": 999, "Policy Loss": 0.00018190380069427192, "Value Loss": 0.00022696312225889415, "_runtime": 4055.5869851112366, "_timestamp": 1585513134.0077147, "_step": 265}
{"Episode reward": -99.35666392256829, "Episode length": 999, "Policy Loss": -3.4973529636772582e-06, "Value Loss": 0.00024142322945408523, "_runtime": 4057.153846025467, "_timestamp": 1585513135.5745757, "_step": 266}
{"Episode reward": -98.12272554114507, "Episode length": 999, "Policy Loss": 0.000496341148391366, "Value Loss": 0.0012483065947890282, "_runtime": 4058.728989124298, "_timestamp": 1585513137.1497188, "_step": 267}
{"Episode reward": -99.51585609468437, "Episode length": 999, "Policy Loss": 0.0004246631870046258, "Value Loss": 0.0005253704730421305, "_runtime": 4060.298558950424, "_timestamp": 1585513138.7192886, "_step": 268}
{"Episode reward": -98.32345467993588, "Episode length": 999, "Policy Loss": 0.0017057547811418772, "Value Loss": 0.000986129161901772, "_runtime": 4061.906896829605, "_timestamp": 1585513140.3276265, "_step": 269}
{"Episode reward": -98.17916511276597, "Episode length": 999, "Policy Loss": 0.002477825852110982, "Value Loss": 0.000976240960881114, "_runtime": 4063.4622910022736, "_timestamp": 1585513141.8830206, "_step": 270}
{"Episode reward": -98.43314587810801, "Episode length": 999, "Policy Loss": 0.0014797894982621074, "Value Loss": 0.00108723237644881, "_runtime": 4065.022171020508, "_timestamp": 1585513143.4429007, "_step": 271}
{"Episode reward": -99.00565072092564, "Episode length": 999, "Policy Loss": 8.010186138562858e-05, "Value Loss": 0.00015195165178738534, "_runtime": 4066.5806691646576, "_timestamp": 1585513145.0013988, "_step": 272}
{"Episode reward": -99.72930963957748, "Episode length": 999, "Policy Loss": 0.0027261078357696533, "Value Loss": 0.0006586825475096703, "_runtime": 4068.135214805603, "_timestamp": 1585513146.5559444, "_step": 273}
{"Episode reward": -98.37988276647813, "Episode length": 999, "Policy Loss": 0.0025999124627560377, "Value Loss": 0.001082050148397684, "_runtime": 4069.696405172348, "_timestamp": 1585513148.1171348, "_step": 274}
{"Episode reward": -98.38024257901593, "Episode length": 999, "Policy Loss": 0.0011153187369927764, "Value Loss": 0.00037911877734586596, "_runtime": 4071.2586975097656, "_timestamp": 1585513149.6794271, "_step": 275}
{"Episode reward": -98.95132965740366, "Episode length": 999, "Policy Loss": -9.814294026000425e-05, "Value Loss": 0.00012568662350531667, "_runtime": 4072.8218801021576, "_timestamp": 1585513151.2426097, "_step": 276}
{"Episode reward": -98.75363111611426, "Episode length": 999, "Policy Loss": 0.001019289018586278, "Value Loss": 0.0001897175534395501, "_runtime": 4074.372063398361, "_timestamp": 1585513152.792793, "_step": 277}
{"Episode reward": -99.4400219110389, "Episode length": 999, "Policy Loss": 0.00036290392745286226, "Value Loss": 0.0004835189029108733, "_runtime": 4075.9239153862, "_timestamp": 1585513154.344645, "_step": 278}
{"Episode reward": -98.30101727635719, "Episode length": 999, "Policy Loss": 0.0029285233467817307, "Value Loss": 0.0012970727402716875, "_runtime": 4077.4844126701355, "_timestamp": 1585513155.9051423, "_step": 279}
{"Episode reward": -98.50860276424955, "Episode length": 999, "Policy Loss": 0.0007620627875439823, "Value Loss": 0.00028106055106036365, "_runtime": 4079.0452778339386, "_timestamp": 1585513157.4660075, "_step": 280}
{"Episode reward": -98.22692306142046, "Episode length": 999, "Policy Loss": 0.0035630648490041494, "Value Loss": 0.0009041423909366131, "_runtime": 4080.6062309741974, "_timestamp": 1585513159.0269606, "_step": 281}
{"Episode reward": -98.90384059881323, "Episode length": 999, "Policy Loss": -3.610016938182525e-05, "Value Loss": 8.281344344140962e-05, "_runtime": 4082.167737007141, "_timestamp": 1585513160.5884666, "_step": 282}
{"Episode reward": -98.41341843040237, "Episode length": 999, "Policy Loss": 0.001808507600799203, "Value Loss": 0.0006717498181387782, "_runtime": 4083.7180964946747, "_timestamp": 1585513162.1388261, "_step": 283}
{"Episode reward": -99.33691003141608, "Episode length": 999, "Policy Loss": 0.0008689993992447853, "Value Loss": 0.00037279739626683295, "_runtime": 4085.295082092285, "_timestamp": 1585513163.7158117, "_step": 284}
{"Episode reward": -98.46980614226851, "Episode length": 999, "Policy Loss": 0.002144088502973318, "Value Loss": 0.0007525071850977838, "_runtime": 4086.8536174297333, "_timestamp": 1585513165.274347, "_step": 285}
{"Episode reward": -98.53129177580854, "Episode length": 999, "Policy Loss": 0.0007106701959855855, "Value Loss": 0.00017711233522277325, "_runtime": 4088.4121494293213, "_timestamp": 1585513166.832879, "_step": 286}
{"Episode reward": -98.53625433990415, "Episode length": 999, "Policy Loss": 0.00093464320525527, "Value Loss": 0.0002596716512925923, "_runtime": 4089.9729719161987, "_timestamp": 1585513168.3937016, "_step": 287}
{"Episode reward": -98.20612017258581, "Episode length": 999, "Policy Loss": 0.0012578096939250827, "Value Loss": 0.0015721620293334126, "_runtime": 4091.5303704738617, "_timestamp": 1585513169.9511, "_step": 288}
{"Episode reward": -98.22596210996548, "Episode length": 999, "Policy Loss": 0.0008934470824897289, "Value Loss": 0.0017640229780226946, "_runtime": 4093.0893325805664, "_timestamp": 1585513171.5100622, "_step": 289}
{"Episode reward": -99.67015765794986, "Episode length": 999, "Policy Loss": 0.0016214220086112618, "Value Loss": 0.000603510532528162, "_runtime": 4094.6529824733734, "_timestamp": 1585513173.073712, "_step": 290}
{"Episode reward": -99.62361927448778, "Episode length": 999, "Policy Loss": 0.0019515856401994824, "Value Loss": 0.0006062276661396027, "_runtime": 4096.204297780991, "_timestamp": 1585513174.6250274, "_step": 291}
{"Episode reward": -99.02656886047407, "Episode length": 999, "Policy Loss": 0.0002132038353011012, "Value Loss": 0.0003317777009215206, "_runtime": 4097.761657714844, "_timestamp": 1585513176.1823874, "_step": 292}
{"Episode reward": -98.07255438113859, "Episode length": 999, "Policy Loss": 0.0016434716526418924, "Value Loss": 0.0015055431285873055, "_runtime": 4099.322093248367, "_timestamp": 1585513177.742823, "_step": 293}
{"Episode reward": -99.02523121751055, "Episode length": 999, "Policy Loss": 6.343066729641578e-07, "Value Loss": 0.00011615257244557142, "_runtime": 4100.8816549777985, "_timestamp": 1585513179.3023846, "_step": 294}
{"Episode reward": -98.5119784643827, "Episode length": 999, "Policy Loss": 0.0009018507553264499, "Value Loss": 0.00025766846374608576, "_runtime": 4102.437032461166, "_timestamp": 1585513180.857762, "_step": 295}
{"Episode reward": -99.81465217366332, "Episode length": 999, "Policy Loss": 0.0026526483707129955, "Value Loss": 0.000665416824631393, "_runtime": 4103.999031543732, "_timestamp": 1585513182.4197612, "_step": 296}
{"Episode reward": -99.64326204627628, "Episode length": 999, "Policy Loss": 0.0024750237353146076, "Value Loss": 0.0006001647561788559, "_runtime": 4105.538961172104, "_timestamp": 1585513183.9596908, "_step": 297}
{"Episode reward": -99.77121657538748, "Episode length": 999, "Policy Loss": 0.002310660434886813, "Value Loss": 0.0006376819219440222, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875, 5.439910888671875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0], "bins": [-10.251986503601074, -10.176797866821289, -10.101609230041504, -10.026420593261719, -9.951231956481934, -9.876043319702148, -9.800854682922363, -9.725666046142578, -9.650477409362793, -9.575288772583008, -9.500100135803223, -9.424911499023438, -9.349722862243652, -9.274534225463867, -9.199345588684082, -9.124156951904297, -9.048968315124512, -8.973779678344727, -8.898591041564941, -8.823402404785156, -8.748213768005371, -8.673025131225586, -8.5978364944458, -8.522647857666016, -8.44745922088623, -8.372270584106445, -8.29708194732666, -8.221893310546875, -8.14670467376709, -8.071516036987305, -7.9963274002075195, -7.921138763427734, -7.845950126647949, -7.770761489868164, -7.695572853088379, -7.620384216308594, -7.545195579528809, -7.470006942749023, -7.394818305969238, -7.319629669189453, -7.244441032409668, -7.169252395629883, -7.094063758850098, -7.0188751220703125, -6.943686485290527, -6.868497848510742, -6.793309211730957, -6.718120574951172, -6.6429314613342285, -6.567742824554443, -6.492554187774658, -6.417365550994873, -6.342176914215088, -6.266988277435303, -6.191799640655518, -6.116611003875732, -6.041422367095947, -5.966233730316162, -5.891045093536377, -5.815856456756592, -5.740667819976807, -5.6654791831970215, -5.590290546417236, -5.515101909637451, -5.439913272857666]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 13.0], "bins": [-2.750276565551758, -2.7066524028778076, -2.6630282402038574, -2.6194040775299072, -2.575779914855957, -2.532155990600586, -2.4885318279266357, -2.4449076652526855, -2.4012835025787354, -2.357659339904785, -2.314035177230835, -2.2704110145568848, -2.2267870903015137, -2.1831626892089844, -2.1395387649536133, -2.095914602279663, -2.052290439605713, -2.0086662769317627, -1.9650421142578125, -1.9214180707931519, -1.8777939081192017, -1.8341697454452515, -1.7905457019805908, -1.7469215393066406, -1.7032973766326904, -1.6596732139587402, -1.61604905128479, -1.5724250078201294, -1.5288008451461792, -1.485176682472229, -1.4415526390075684, -1.3979284763336182, -1.354304313659668, -1.3106801509857178, -1.2670559883117676, -1.223431944847107, -1.1798077821731567, -1.1361836194992065, -1.092559576034546, -1.0489354133605957, -1.0053112506866455, -0.9616870880126953, -0.9180629253387451, -0.8744388818740845, -0.8308147192001343, -0.7871905565261841, -0.7435665130615234, -0.6999423503875732, -0.656318187713623, -0.6126940250396729, -0.5690698623657227, -0.5254456996917725, -0.48182153701782227, -0.43819761276245117, -0.394573450088501, -0.3509492874145508, -0.3073251247406006, -0.2637009620666504, -0.2200767993927002, -0.17645263671875, -0.1328287124633789, -0.08920454978942871, -0.045580387115478516, -0.0019562244415283203, 0.041667938232421875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 425.0, 51.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 6.0, 8.0], "bins": [-7.49251651763916, -7.334095001220703, -7.175673484802246, -7.017251968383789, -6.858829975128174, -6.700408458709717, -6.54198694229126, -6.383565425872803, -6.225143909454346, -6.0667219161987305, -5.908300399780273, -5.749878883361816, -5.591457366943359, -5.433035850524902, -5.274614334106445, -5.116192817687988, -4.957771301269531, -4.799349784851074, -4.640927791595459, -4.482506275177002, -4.324084758758545, -4.16566276550293, -4.007241249084473, -3.8488199710845947, -3.6903982162475586, -3.5319766998291016, -3.3735551834106445, -3.2151336669921875, -3.0567121505737305, -2.8982901573181152, -2.739868640899658, -2.581447124481201, -2.423025608062744, -2.264604091644287, -2.10618257522583, -1.947761058807373, -1.7893390655517578, -1.6309175491333008, -1.4724960327148438, -1.3140745162963867, -1.1556529998779297, -0.9972314834594727, -0.8388094902038574, -0.6803879737854004, -0.5219664573669434, -0.36354494094848633, -0.2051234245300293, -0.046701908111572266, 0.11172008514404297, 0.2701416015625, 0.42856311798095703, 0.5869846343994141, 0.7454061508178711, 0.9038276672363281, 1.0622491836547852, 1.2206707000732422, 1.3790922164916992, 1.5375137329101562, 1.6959362030029297, 1.8543577194213867, 2.0127792358398438, 2.171200752258301, 2.329622268676758, 2.488043785095215, 2.646465301513672]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 5.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1569292545318604, -1.9652034044265747, -1.773477554321289, -1.5817515850067139, -1.3900257349014282, -1.1982998847961426, -1.0065739154815674, -0.8148480653762817, -0.6231222152709961, -0.43139636516571045, -0.2396705150604248, -0.04794454574584961, 0.14378142356872559, 0.3355071544647217, 0.5272331237792969, 0.718958854675293, 0.9106848239898682, 1.1024107933044434, 1.2941365242004395, 1.4858624935150146, 1.6775882244110107, 1.869314432144165, 2.061040163040161, 2.2527658939361572, 2.4444921016693115, 2.6362178325653076, 2.8279435634613037, 3.0196692943573, 3.211395502090454, 3.40312123298645, 3.5948469638824463, 3.7865731716156006, 3.9782989025115967, 4.170024871826172, 4.361750602722168, 4.553476333618164, 4.74520206451416, 4.936928749084473, 5.128654479980469, 5.320380210876465, 5.512105941772461, 5.703831672668457, 5.8955583572387695, 6.087284088134766, 6.279009819030762, 6.470735549926758, 6.662461280822754, 6.85418701171875, 7.0459136962890625, 7.237639427185059, 7.429365158081055, 7.621090888977051, 7.812816619873047, 8.004542350769043, 8.196268081665039, 8.387994766235352, 8.579720497131348, 8.771446228027344, 8.96317195892334, 9.154897689819336, 9.346623420715332, 9.538350105285645, 9.73007583618164, 9.921801567077637, 10.113527297973633]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 6.0, 10.0, 11.0, 10.0, 4.0, 1.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.3842973709106445, -4.3010382652282715, -4.217779159545898, -4.134520053863525, -4.051260948181152, -3.9680018424987793, -3.8847427368164062, -3.801483631134033, -3.71822452545166, -3.634965419769287, -3.551706314086914, -3.468447208404541, -3.385188102722168, -3.301928997039795, -3.218669891357422, -3.135410785675049, -3.052151679992676, -2.9688925743103027, -2.8856334686279297, -2.8023743629455566, -2.7191152572631836, -2.6358561515808105, -2.5525970458984375, -2.4693379402160645, -2.3860788345336914, -2.3028197288513184, -2.2195606231689453, -2.1363015174865723, -2.053042411804199, -1.9697833061218262, -1.8865242004394531, -1.80326509475708, -1.720005989074707, -1.636746883392334, -1.553487777709961, -1.470228672027588, -1.3869695663452148, -1.3037104606628418, -1.2204513549804688, -1.1371922492980957, -1.0539331436157227, -0.9706740379333496, -0.8874149322509766, -0.8041558265686035, -0.7208967208862305, -0.6376376152038574, -0.5543785095214844, -0.47111940383911133, -0.3878602981567383, -0.30460119247436523, -0.2213420867919922, -0.13808298110961914, -0.054823875427246094, 0.028435230255126953, 0.1116943359375, 0.19495344161987305, 0.2782125473022461, 0.36147165298461914, 0.4447307586669922, 0.5279898643493652, 0.6112489700317383, 0.6945080757141113, 0.7777671813964844, 0.8610262870788574, 0.9442853927612305]}, "_runtime": 4107.088911056519, "_timestamp": 1585513185.5096407, "_step": 298}
{"Episode reward": -98.01929456519919, "Episode length": 999, "Policy Loss": 0.0022608740255236626, "Value Loss": 0.0013545654946938157, "_runtime": 4108.688008308411, "_timestamp": 1585513187.108738, "_step": 299}
{"Episode reward": -98.74545777622959, "Episode length": 999, "Policy Loss": 0.0006586232339031994, "Value Loss": 0.00014030323654878885, "_runtime": 4110.238827705383, "_timestamp": 1585513188.6595573, "_step": 300}
{"Episode reward": -99.62162356893538, "Episode length": 999, "Policy Loss": 0.0017749869730323553, "Value Loss": 0.00057114043738693, "_runtime": 4111.789123058319, "_timestamp": 1585513190.2098527, "_step": 301}
{"Episode reward": -98.71194222746007, "Episode length": 999, "Policy Loss": 0.0009540088358335197, "Value Loss": 0.0003051019157283008, "_runtime": 4113.342754602432, "_timestamp": 1585513191.7634842, "_step": 302}
{"Episode reward": -99.02462633968275, "Episode length": 999, "Policy Loss": 0.0007258544210344553, "Value Loss": 0.00023049750598147511, "_runtime": 4114.906011104584, "_timestamp": 1585513193.3267407, "_step": 303}
{"Episode reward": -99.05677964775083, "Episode length": 999, "Policy Loss": 0.0001800472236936912, "Value Loss": 0.00016685083392076194, "_runtime": 4116.464676856995, "_timestamp": 1585513194.8854065, "_step": 304}
{"Episode reward": -99.09725681333397, "Episode length": 999, "Policy Loss": 0.001460831263102591, "Value Loss": 0.0002901886182371527, "_runtime": 4118.027473449707, "_timestamp": 1585513196.448203, "_step": 305}
{"Episode reward": -98.91206769871901, "Episode length": 999, "Policy Loss": 0.00036442032433114946, "Value Loss": 7.975668995641172e-05, "_runtime": 4119.578737258911, "_timestamp": 1585513197.999467, "_step": 306}
{"Episode reward": -98.22390447049624, "Episode length": 999, "Policy Loss": 0.0013961737276986241, "Value Loss": 0.0005802027299068868, "_runtime": 4121.136620521545, "_timestamp": 1585513199.5573502, "_step": 307}
{"Episode reward": -99.48843676765387, "Episode length": 999, "Policy Loss": 0.0019995924085378647, "Value Loss": 0.0005117044202052057, "_runtime": 4122.70108795166, "_timestamp": 1585513201.1218176, "_step": 308}
{"Episode reward": -99.50004671978608, "Episode length": 999, "Policy Loss": 0.0018930337391793728, "Value Loss": 0.0005472778575494885, "_runtime": 4124.242007255554, "_timestamp": 1585513202.662737, "_step": 309}
{"Episode reward": -99.31453438121373, "Episode length": 999, "Policy Loss": 0.0014729289105162024, "Value Loss": 0.0002809444849845022, "_runtime": 4125.800706863403, "_timestamp": 1585513204.2214365, "_step": 310}
{"Episode reward": -98.75324891900537, "Episode length": 999, "Policy Loss": 0.0015373012283816934, "Value Loss": 0.00023085903376340866, "_runtime": 4127.361867189407, "_timestamp": 1585513205.7825968, "_step": 311}
{"Episode reward": -99.84585462189814, "Episode length": 999, "Policy Loss": 0.0029674312099814415, "Value Loss": 0.0006584860966540873, "_runtime": 4128.925884962082, "_timestamp": 1585513207.3466146, "_step": 312}
{"Episode reward": -98.89013173854052, "Episode length": 999, "Policy Loss": 0.00027506836340762675, "Value Loss": 8.460552635369822e-05, "_runtime": 4130.521847248077, "_timestamp": 1585513208.942577, "_step": 313}
{"Episode reward": -98.90123944676057, "Episode length": 999, "Policy Loss": 0.0005413370090536773, "Value Loss": 9.133282583206892e-05, "_runtime": 4132.085265636444, "_timestamp": 1585513210.5059953, "_step": 314}
{"Episode reward": -97.91618231261212, "Episode length": 999, "Policy Loss": -0.0006454137619584799, "Value Loss": 0.0019438817398622632, "_runtime": 4133.644309043884, "_timestamp": 1585513212.0650387, "_step": 315}
{"Episode reward": -98.44485565909922, "Episode length": 999, "Policy Loss": 0.002663005841895938, "Value Loss": 0.000836992752738297, "_runtime": 4135.1908230781555, "_timestamp": 1585513213.6115527, "_step": 316}
{"Episode reward": -99.3689510267756, "Episode length": 999, "Policy Loss": 0.001601204858161509, "Value Loss": 0.000472709012683481, "_runtime": 4136.754473209381, "_timestamp": 1585513215.1752028, "_step": 317}
{"Episode reward": -98.38345181478951, "Episode length": 999, "Policy Loss": 0.0027373970951884985, "Value Loss": 0.0009160228655673563, "_runtime": 4138.316392660141, "_timestamp": 1585513216.7371223, "_step": 318}
{"Episode reward": -98.62479976802116, "Episode length": 999, "Policy Loss": 0.001338366186246276, "Value Loss": 0.0002990263164974749, "_runtime": 4139.8650867938995, "_timestamp": 1585513218.2858164, "_step": 319}
{"Episode reward": -97.84549414276627, "Episode length": 999, "Policy Loss": 0.0013498953776434064, "Value Loss": 0.0017097073141485453, "_runtime": 4141.427882671356, "_timestamp": 1585513219.8486123, "_step": 320}
{"Episode reward": -99.21817250883676, "Episode length": 999, "Policy Loss": 0.00032139680115506053, "Value Loss": 0.000360644276952371, "_runtime": 4142.978538751602, "_timestamp": 1585513221.3992684, "_step": 321}
{"Episode reward": -99.00868372887412, "Episode length": 999, "Policy Loss": 0.0006061154999770224, "Value Loss": 0.00014047941658645868, "_runtime": 4144.530707120895, "_timestamp": 1585513222.9514368, "_step": 322}
{"Episode reward": -99.88856293814841, "Episode length": 999, "Policy Loss": 0.002378032775595784, "Value Loss": 0.0006833812221884727, "_runtime": 4146.0860760211945, "_timestamp": 1585513224.5068057, "_step": 323}
{"Episode reward": -99.6715925798783, "Episode length": 999, "Policy Loss": 0.0026302041951566935, "Value Loss": 0.0006069553783163428, "_runtime": 4147.639302968979, "_timestamp": 1585513226.0600326, "_step": 324}
{"Episode reward": -98.31575152733203, "Episode length": 999, "Policy Loss": 0.0007475069141946733, "Value Loss": 0.0015937071293592453, "_runtime": 4149.190393447876, "_timestamp": 1585513227.611123, "_step": 325}
{"Episode reward": -98.06122508099506, "Episode length": 999, "Policy Loss": -0.0019689032342284918, "Value Loss": 0.00198441743850708, "_runtime": 4150.752009153366, "_timestamp": 1585513229.1727388, "_step": 326}
{"Episode reward": -98.41557716002677, "Episode length": 999, "Policy Loss": 0.0018651426071301103, "Value Loss": 0.0006762720295228064, "_runtime": 4152.314578533173, "_timestamp": 1585513230.7353082, "_step": 327}
{"Episode reward": -99.51713918038999, "Episode length": 999, "Policy Loss": 0.002188033191487193, "Value Loss": 0.0004851067205891013, "_runtime": 4153.898992061615, "_timestamp": 1585513232.3197217, "_step": 328}
{"Episode reward": -98.173159956541, "Episode length": 999, "Policy Loss": 0.0018051023362204432, "Value Loss": 0.0018507284112274647, "_runtime": 4155.462313652039, "_timestamp": 1585513233.8830433, "_step": 329}
{"Episode reward": -98.39429917813301, "Episode length": 999, "Policy Loss": 0.0024609151296317577, "Value Loss": 0.0007450688863173127, "_runtime": 4157.024832725525, "_timestamp": 1585513235.4455624, "_step": 330}
{"Episode reward": -99.88848499818826, "Episode length": 999, "Policy Loss": 0.003199435770511627, "Value Loss": 0.000613941578194499, "_runtime": 4158.582962036133, "_timestamp": 1585513237.0036917, "_step": 331}
{"Episode reward": -98.47173590702545, "Episode length": 999, "Policy Loss": 0.0009059028816409409, "Value Loss": 0.00018585332145448774, "_runtime": 4160.145603895187, "_timestamp": 1585513238.5663335, "_step": 332}
{"Episode reward": -97.95609735449422, "Episode length": 999, "Policy Loss": 0.002478493843227625, "Value Loss": 0.0014780256897211075, "_runtime": 4161.705599784851, "_timestamp": 1585513240.1263294, "_step": 333}
{"Episode reward": -99.5485097331981, "Episode length": 999, "Policy Loss": 0.002267072908580303, "Value Loss": 0.0005356472684070468, "_runtime": 4163.264497041702, "_timestamp": 1585513241.6852267, "_step": 334}
{"Episode reward": -97.92851305319164, "Episode length": 999, "Policy Loss": 0.0024882201105356216, "Value Loss": 0.001727187423966825, "_runtime": 4164.817182064056, "_timestamp": 1585513243.2379117, "_step": 335}
{"Episode reward": -99.22034811782427, "Episode length": 999, "Policy Loss": 0.000731821870431304, "Value Loss": 0.00022527240798808634, "_runtime": 4166.369367599487, "_timestamp": 1585513244.7900972, "_step": 336}
{"Episode reward": -98.52649061058152, "Episode length": 999, "Policy Loss": 0.002321452833712101, "Value Loss": 0.0008815322071313858, "_runtime": 4167.918190479279, "_timestamp": 1585513246.33892, "_step": 337}
{"Episode reward": -98.75287111904323, "Episode length": 999, "Policy Loss": 0.0009570048423483968, "Value Loss": 8.330315904458985e-05, "_runtime": 4169.470901012421, "_timestamp": 1585513247.8916306, "_step": 338}
{"Episode reward": -99.16430474649309, "Episode length": 999, "Policy Loss": 0.0013921507634222507, "Value Loss": 6.770545587642118e-05, "_runtime": 4171.022153139114, "_timestamp": 1585513249.4428828, "_step": 339}
{"Episode reward": -98.23763101302237, "Episode length": 999, "Policy Loss": 0.0018150957766920328, "Value Loss": 0.0011725700460374355, "_runtime": 4172.580010652542, "_timestamp": 1585513251.0007403, "_step": 340}
{"Episode reward": -98.40258472058345, "Episode length": 999, "Policy Loss": 0.00114327238406986, "Value Loss": 0.00021453066437970847, "_runtime": 4174.131156206131, "_timestamp": 1585513252.5518858, "_step": 341}
{"Episode reward": -99.64923462414284, "Episode length": 999, "Policy Loss": 0.0033260195050388575, "Value Loss": 0.0005971062928438187, "_runtime": 4175.68997836113, "_timestamp": 1585513254.110708, "_step": 342}
{"Episode reward": -98.70116448536375, "Episode length": 999, "Policy Loss": 0.0008039575768634677, "Value Loss": 8.802785305306315e-05, "_runtime": 4177.2857711315155, "_timestamp": 1585513255.7065008, "_step": 343}
{"Episode reward": -98.39937054535952, "Episode length": 999, "Policy Loss": 0.0014865078264847398, "Value Loss": 0.0011912761256098747, "_runtime": 4178.837383747101, "_timestamp": 1585513257.2581134, "_step": 344}
{"Episode reward": -99.57896053313783, "Episode length": 999, "Policy Loss": 0.0036231293343007565, "Value Loss": 0.0005630748346447945, "_runtime": 4180.397532224655, "_timestamp": 1585513258.8182619, "_step": 345}
{"Episode reward": -99.33982023404621, "Episode length": 999, "Policy Loss": 0.001954115927219391, "Value Loss": 0.0004395067226141691, "_runtime": 4181.948410749435, "_timestamp": 1585513260.3691404, "_step": 346}
{"Episode reward": -99.87662182108652, "Episode length": 999, "Policy Loss": 0.00231687119230628, "Value Loss": 0.0006128030945546925, "_runtime": 4183.510245323181, "_timestamp": 1585513261.930975, "_step": 347}
{"Episode reward": -99.20108790869563, "Episode length": 999, "Policy Loss": 0.0008376025361940265, "Value Loss": 0.00028993937303312123, "_runtime": 4185.073449373245, "_timestamp": 1585513263.494179, "_step": 348}
{"Episode reward": -99.00064919013188, "Episode length": 999, "Policy Loss": 0.00036289560375735164, "Value Loss": 0.00021411462512332946, "_runtime": 4186.621556758881, "_timestamp": 1585513265.0422864, "_step": 349}
{"Episode reward": -99.57137218028194, "Episode length": 999, "Policy Loss": 0.0033241668716073036, "Value Loss": 0.0005566319450736046, "_runtime": 4188.174302339554, "_timestamp": 1585513266.595032, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0039015363436192274, "Value Loss": 0.0006244612741284072, "_runtime": 4189.725401878357, "_timestamp": 1585513268.1461315, "_step": 351}
{"Episode reward": -99.8530749648376, "Episode length": 999, "Policy Loss": 0.003778022015467286, "Value Loss": 0.0006166348466649652, "_runtime": 4191.286472558975, "_timestamp": 1585513269.7072022, "_step": 352}
{"Episode reward": -99.06980166972014, "Episode length": 999, "Policy Loss": 0.0004687095934059471, "Value Loss": 0.0001625392906134948, "_runtime": 4192.847674131393, "_timestamp": 1585513271.2684038, "_step": 353}
{"Episode reward": -99.37875393128297, "Episode length": 999, "Policy Loss": 0.0006997891468927264, "Value Loss": 0.00038334535202011466, "_runtime": 4194.4097356796265, "_timestamp": 1585513272.8304653, "_step": 354}
{"Episode reward": -99.28634239992564, "Episode length": 999, "Policy Loss": 0.0009930087253451347, "Value Loss": 0.0004229708865750581, "_runtime": 4195.969883441925, "_timestamp": 1585513274.390613, "_step": 355}
{"Episode reward": -97.84806013403308, "Episode length": 999, "Policy Loss": -0.0006670488510280848, "Value Loss": 0.0017211622325703502, "_runtime": 4197.522755622864, "_timestamp": 1585513275.9434853, "_step": 356}
{"Episode reward": -97.72328473274725, "Episode length": 999, "Policy Loss": 0.0007449014810845256, "Value Loss": 0.0015564319910481572, "_runtime": 4199.083559989929, "_timestamp": 1585513277.5042896, "_step": 357}
{"Episode reward": -99.07134814631455, "Episode length": 999, "Policy Loss": 0.001158914528787136, "Value Loss": 0.00021302676759660244, "_runtime": 4200.668683290482, "_timestamp": 1585513279.089413, "_step": 358}
{"Episode reward": -98.46743111392576, "Episode length": 999, "Policy Loss": 0.0009563451167196035, "Value Loss": 0.00018872889631893486, "_runtime": 4202.232131958008, "_timestamp": 1585513280.6528616, "_step": 359}
{"Episode reward": -99.00413830746196, "Episode length": 999, "Policy Loss": 0.0006802566349506378, "Value Loss": 0.00011639378499239683, "_runtime": 4203.78266119957, "_timestamp": 1585513282.2033908, "_step": 360}
{"Episode reward": -98.60253683238825, "Episode length": 999, "Policy Loss": 0.001374871819280088, "Value Loss": 0.00029831487336196005, "_runtime": 4205.341558218002, "_timestamp": 1585513283.7622879, "_step": 361}
{"Episode reward": -98.12883226028347, "Episode length": 999, "Policy Loss": 0.0010954641038551927, "Value Loss": 0.0014848040882498026, "_runtime": 4206.893006563187, "_timestamp": 1585513285.3137362, "_step": 362}
{"Episode reward": -98.3747980586501, "Episode length": 999, "Policy Loss": 0.00224540033377707, "Value Loss": 0.0009258941281586885, "_runtime": 4208.451982021332, "_timestamp": 1585513286.8727117, "_step": 363}
{"Episode reward": -98.37055233674018, "Episode length": 999, "Policy Loss": 0.002419322496280074, "Value Loss": 0.000750478939153254, "_runtime": 4210.003798723221, "_timestamp": 1585513288.4245284, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003901600604876876, "Value Loss": 0.0006209955317899585, "_runtime": 4211.553454875946, "_timestamp": 1585513289.9741845, "_step": 365}
{"Episode reward": -98.24662337156758, "Episode length": 999, "Policy Loss": -0.0013922181678935885, "Value Loss": 0.0019750548526644707, "_runtime": 4213.114817857742, "_timestamp": 1585513291.5355475, "_step": 366}
{"Episode reward": -98.09118295547482, "Episode length": 999, "Policy Loss": -0.00038758417940698564, "Value Loss": 0.001688348944298923, "_runtime": 4214.674927473068, "_timestamp": 1585513293.095657, "_step": 367}
{"Episode reward": -98.8031727093581, "Episode length": 999, "Policy Loss": 0.0008749155094847083, "Value Loss": 0.0001570891181472689, "_runtime": 4216.238032341003, "_timestamp": 1585513294.658762, "_step": 368}
{"Episode reward": -98.1948505398896, "Episode length": 999, "Policy Loss": 0.003508946392685175, "Value Loss": 0.0008451746543869376, "_runtime": 4217.787255048752, "_timestamp": 1585513296.2079847, "_step": 369}
{"Episode reward": -99.82374005129303, "Episode length": 999, "Policy Loss": 0.0031870875973254442, "Value Loss": 0.0006251053418964148, "_runtime": 4219.348455190659, "_timestamp": 1585513297.7691848, "_step": 370}
{"Episode reward": -99.6236354582797, "Episode length": 999, "Policy Loss": 0.0026774180587381124, "Value Loss": 0.0005583493039011955, "_runtime": 4220.911702632904, "_timestamp": 1585513299.3324323, "_step": 371}
{"Episode reward": -98.11762922285904, "Episode length": 999, "Policy Loss": 0.0003461336891632527, "Value Loss": 0.002047040732577443, "_runtime": 4222.501476287842, "_timestamp": 1585513300.922206, "_step": 372}
{"Episode reward": -98.90486313923954, "Episode length": 999, "Policy Loss": 0.0006367567111738026, "Value Loss": 8.461891411570832e-05, "_runtime": 4224.064972162247, "_timestamp": 1585513302.4857018, "_step": 373}
{"Episode reward": -98.6119159315309, "Episode length": 999, "Policy Loss": 0.000361654965672642, "Value Loss": 0.00011255928984610364, "_runtime": 4225.626001834869, "_timestamp": 1585513304.0467315, "_step": 374}
{"Episode reward": -99.04231979750237, "Episode length": 999, "Policy Loss": 0.0007023434736765921, "Value Loss": 8.831752347759902e-05, "_runtime": 4227.1890296936035, "_timestamp": 1585513305.6097593, "_step": 375}
{"Episode reward": -99.16535794776712, "Episode length": 999, "Policy Loss": 0.0012428541667759418, "Value Loss": 6.784404831705615e-05, "_runtime": 4228.751293182373, "_timestamp": 1585513307.1720228, "_step": 376}
{"Episode reward": -98.37005296587436, "Episode length": 999, "Policy Loss": 0.0020172365475445986, "Value Loss": 0.0014638846041634679, "_runtime": 4230.316308259964, "_timestamp": 1585513308.737038, "_step": 377}
{"Episode reward": -99.76258756489527, "Episode length": 999, "Policy Loss": 0.003381074406206608, "Value Loss": 0.0005819425568915904, "_runtime": 4231.877914905548, "_timestamp": 1585513310.2986445, "_step": 378}
{"Episode reward": -98.06056660323495, "Episode length": 999, "Policy Loss": 0.0002853202458936721, "Value Loss": 0.00219159759581089, "_runtime": 4233.423957824707, "_timestamp": 1585513311.8446875, "_step": 379}
{"Episode reward": -97.80505105324526, "Episode length": 999, "Policy Loss": -0.00018090475350618362, "Value Loss": 0.002137743169441819, "_runtime": 4234.986128091812, "_timestamp": 1585513313.4068577, "_step": 380}
{"Episode reward": -97.8125936008167, "Episode length": 999, "Policy Loss": 0.0028206268325448036, "Value Loss": 0.001396968960762024, "_runtime": 4236.548173427582, "_timestamp": 1585513314.968903, "_step": 381}
{"Episode reward": -98.6864774809133, "Episode length": 999, "Policy Loss": 0.0007626942242495716, "Value Loss": 9.481977758696303e-05, "_runtime": 4238.109271287918, "_timestamp": 1585513316.530001, "_step": 382}
{"Episode reward": -99.89193270775704, "Episode length": 999, "Policy Loss": 0.0033843612764030695, "Value Loss": 0.0006387531175278127, "_runtime": 4239.672297239304, "_timestamp": 1585513318.0930269, "_step": 383}
{"Episode reward": -98.10914353931778, "Episode length": 999, "Policy Loss": 0.002843235619366169, "Value Loss": 0.0015630129491910338, "_runtime": 4241.233199834824, "_timestamp": 1585513319.6539295, "_step": 384}
{"Episode reward": -99.40993844085152, "Episode length": 999, "Policy Loss": 0.0014873120235279202, "Value Loss": 0.00035081320675089955, "_runtime": 4242.793745279312, "_timestamp": 1585513321.214475, "_step": 385}
{"Episode reward": -99.00250281311801, "Episode length": 999, "Policy Loss": 0.0013830048264935613, "Value Loss": 0.00016416962898802012, "_runtime": 4244.350172996521, "_timestamp": 1585513322.7709026, "_step": 386}
{"Episode reward": -98.91574709564068, "Episode length": 999, "Policy Loss": 0.0007859538891352713, "Value Loss": 8.170679939212278e-05, "_runtime": 4245.9464745521545, "_timestamp": 1585513324.3672042, "_step": 387}
{"Episode reward": -99.068761880621, "Episode length": 999, "Policy Loss": 0.0011018908116966486, "Value Loss": 0.00019431451801210642, "_runtime": 4247.504227638245, "_timestamp": 1585513325.9249573, "_step": 388}
{"Episode reward": -98.9098546047346, "Episode length": 999, "Policy Loss": 0.0011162302689626813, "Value Loss": 0.0001405366783728823, "_runtime": 4249.054334640503, "_timestamp": 1585513327.4750643, "_step": 389}
{"Episode reward": -98.50219209987976, "Episode length": 999, "Policy Loss": 0.0007271015201695263, "Value Loss": 0.00014248504885472357, "_runtime": 4250.603656053543, "_timestamp": 1585513329.0243857, "_step": 390}
{"Episode reward": -97.87211548447695, "Episode length": 999, "Policy Loss": 0.0012136715231463313, "Value Loss": 0.0018348286394029856, "_runtime": 4252.157297372818, "_timestamp": 1585513330.578027, "_step": 391}
{"Episode reward": -98.27991566600627, "Episode length": 999, "Policy Loss": 0.003350743791088462, "Value Loss": 0.001111236517317593, "_runtime": 4253.706698417664, "_timestamp": 1585513332.127428, "_step": 392}
{"Episode reward": -99.59211764493672, "Episode length": 999, "Policy Loss": 0.003043975681066513, "Value Loss": 0.0005768125411123037, "_runtime": 4255.244610548019, "_timestamp": 1585513333.6653402, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0030138790607452393, "Value Loss": 0.0005813727038912475, "_runtime": 4256.7945291996, "_timestamp": 1585513335.2152588, "_step": 394}
{"Episode reward": -98.52657893629606, "Episode length": 999, "Policy Loss": 0.0024052076041698456, "Value Loss": 0.0005336573231033981, "_runtime": 4258.354713201523, "_timestamp": 1585513336.7754428, "_step": 395}
{"Episode reward": -99.05160243252566, "Episode length": 999, "Policy Loss": 0.0011947507737204432, "Value Loss": 0.0002665771171450615, "_runtime": 4259.917932987213, "_timestamp": 1585513338.3386626, "_step": 396}
{"Episode reward": -98.6008348103644, "Episode length": 999, "Policy Loss": 0.003331281477585435, "Value Loss": 0.0011142715811729431, "_runtime": 4261.475585460663, "_timestamp": 1585513339.896315, "_step": 397}
{"Episode reward": -99.82435025283397, "Episode length": 999, "Policy Loss": 0.0025813314132392406, "Value Loss": 0.0005531042697839439, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449, 4.355349540710449]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 13.0], "bins": [-4.908457279205322, -4.899815082550049, -4.891172409057617, -4.882530212402344, -4.87388801574707, -4.865245342254639, -4.856603145599365, -4.847960948944092, -4.83931827545166, -4.830676078796387, -4.822033882141113, -4.81339168548584, -4.804749011993408, -4.796106815338135, -4.787464618682861, -4.77882194519043, -4.770179748535156, -4.761537551879883, -4.752894878387451, -4.744252681732178, -4.735610485076904, -4.726967811584473, -4.718325614929199, -4.709683418273926, -4.701041221618652, -4.692398548126221, -4.683756351470947, -4.675114154815674, -4.666471481323242, -4.657829284667969, -4.649187088012695, -4.640544414520264, -4.63190221786499, -4.623260021209717, -4.614617347717285, -4.605975151062012, -4.597332954406738, -4.588690280914307, -4.580048084259033, -4.57140588760376, -4.562763214111328, -4.554121017456055, -4.545478820800781, -4.536836624145508, -4.528193950653076, -4.519551753997803, -4.510909557342529, -4.502266883850098, -4.493624687194824, -4.484982490539551, -4.476339817047119, -4.467697620391846, -4.459055423736572, -4.450412750244141, -4.441770553588867, -4.433128356933594, -4.42448616027832, -4.415843486785889, -4.407201290130615, -4.398558616638184, -4.38991641998291, -4.381274223327637, -4.372632026672363, -4.363989353179932, -4.355347156524658]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 1.0], "bins": [-0.26624542474746704, -0.261974960565567, -0.2577044665813446, -0.2534340023994446, -0.24916352331638336, -0.24489304423332214, -0.24062258005142212, -0.2363521009683609, -0.23208162188529968, -0.22781114280223846, -0.22354066371917725, -0.21927019953727722, -0.214999720454216, -0.21072924137115479, -0.20645877718925476, -0.20218829810619354, -0.19791781902313232, -0.1936473399400711, -0.1893768608570099, -0.18510639667510986, -0.18083591759204865, -0.17656543850898743, -0.1722949743270874, -0.16802449524402618, -0.16375401616096497, -0.15948353707790375, -0.15521305799484253, -0.1509425938129425, -0.1466721147298813, -0.14240163564682007, -0.13813117146492004, -0.13386069238185883, -0.1295902132987976, -0.1253197342157364, -0.12104925513267517, -0.11677879095077515, -0.11250831186771393, -0.10823783278465271, -0.10396736860275269, -0.09969688951969147, -0.09542641043663025, -0.09115593135356903, -0.08688545227050781, -0.08261498808860779, -0.07834450900554657, -0.07407402992248535, -0.06980356574058533, -0.06553308665752411, -0.06126260757446289, -0.05699212849140167, -0.052721649408340454, -0.04845118522644043, -0.04418070614337921, -0.03991022706031799, -0.03563976287841797, -0.03136928379535675, -0.027098804712295532, -0.022828325629234314, -0.018557846546173096, -0.014287382364273071, -0.010016918182373047, -0.005746424198150635, -0.0014759600162506104, 0.0027945339679718018, 0.007064998149871826]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 30.0, 396.0, 50.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 4.0, 4.0, 1.0, 4.0, 4.0, 9.0], "bins": [-0.8432636857032776, -0.8260777592658997, -0.8088918328285217, -0.7917059659957886, -0.7745200395584106, -0.7573341131210327, -0.7401481866836548, -0.7229622602462769, -0.7057763338088989, -0.688590407371521, -0.6714044809341431, -0.6542186141014099, -0.637032687664032, -0.619846761226654, -0.6026608347892761, -0.585474967956543, -0.568289041519165, -0.5511031150817871, -0.5339171886444092, -0.5167312622070312, -0.4995453357696533, -0.4823594391345978, -0.46517351269721985, -0.4479875862598419, -0.4308016896247864, -0.41361576318740845, -0.3964298367500305, -0.3792439103126526, -0.36205801367759705, -0.3448720872402191, -0.3276861906051636, -0.31050026416778564, -0.2933143377304077, -0.2761284112930298, -0.25894248485565186, -0.24175655841827393, -0.22457069158554077, -0.20738476514816284, -0.1901988387107849, -0.17301291227340698, -0.15582698583602905, -0.13864105939865112, -0.12145519256591797, -0.10426926612854004, -0.08708333969116211, -0.06989741325378418, -0.05271148681640625, -0.03552556037902832, -0.018339693546295166, -0.0011537671089172363, 0.016032159328460693, 0.03321808576583862, 0.05040401220321655, 0.06758993864059448, 0.08477586507797241, 0.10196173191070557, 0.1191476583480835, 0.13633358478546143, 0.15351951122283936, 0.1707053780555725, 0.18789130449295044, 0.20507723093032837, 0.2222631573677063, 0.23944908380508423, 0.25663501024246216]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 5.0, 3.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2113242745399475, -0.19209951162338257, -0.17287474870681763, -0.1536499708890915, -0.13442520797252655, -0.11520044505596161, -0.09597567468881607, -0.07675090432167053, -0.05752614140510559, -0.03830137848854065, -0.019076615571975708, 0.00014816224575042725, 0.01937292516231537, 0.03859768807888031, 0.057822465896606445, 0.07704722881317139, 0.09627199172973633, 0.11549675464630127, 0.1347215175628662, 0.15394628047943115, 0.1731710433959961, 0.19239583611488342, 0.21162059903144836, 0.2308453619480133, 0.25007012486457825, 0.2692948877811432, 0.28851965069770813, 0.30774444341659546, 0.3269692063331604, 0.34619396924972534, 0.3654187321662903, 0.3846434950828552, 0.40386825799942017, 0.4230930209159851, 0.44231778383255005, 0.461542546749115, 0.48076730966567993, 0.4999920725822449, 0.5192168354988098, 0.5384415984153748, 0.5576663613319397, 0.5768911838531494, 0.5961159467697144, 0.6153407096862793, 0.6345654726028442, 0.6537902355194092, 0.6730149984359741, 0.6922397613525391, 0.711464524269104, 0.730689287185669, 0.7499140501022339, 0.7691388130187988, 0.7883635759353638, 0.8075883984565735, 0.8268131613731384, 0.8460379242897034, 0.8652626872062683, 0.8844874501228333, 0.9037122130393982, 0.9229369759559631, 0.9421617388725281, 0.961386501789093, 0.980611264705658, 0.9998360276222229, 1.0190608501434326]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 4.0, 4.0, 18.0, 17.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4467739462852478, -0.43834537267684937, -0.4299167990684509, -0.4214881956577301, -0.41305962204933167, -0.4046310484409332, -0.3962024748325348, -0.38777390122413635, -0.3793452978134155, -0.3709167242050171, -0.36248815059661865, -0.3540595769882202, -0.3456310033798218, -0.33720242977142334, -0.3287738561630249, -0.3203452527523041, -0.31191667914390564, -0.3034881055355072, -0.2950595021247864, -0.28663092851638794, -0.2782023549079895, -0.26977378129959106, -0.2613452076911926, -0.2529166340827942, -0.24448804557323456, -0.23605947196483612, -0.2276308834552765, -0.21920230984687805, -0.21077373623847961, -0.20234514772891998, -0.19391655921936035, -0.18548798561096191, -0.17705941200256348, -0.16863083839416504, -0.1602022647857666, -0.15177366137504578, -0.14334508776664734, -0.1349165141582489, -0.12648794054985046, -0.11805936694145203, -0.1096307635307312, -0.10120218992233276, -0.09277361631393433, -0.08434504270553589, -0.07591646909713745, -0.06748789548873901, -0.05905929207801819, -0.05063071846961975, -0.042202144861221313, -0.033773571252822876, -0.02534499764442444, -0.016916394233703613, -0.008487820625305176, -5.924701690673828e-05, 0.0083693265914917, 0.016797900199890137, 0.025226473808288574, 0.0336550772190094, 0.04208365082740784, 0.050512224435806274, 0.0589408278465271, 0.06736940145492554, 0.07579797506332397, 0.08422654867172241, 0.09265512228012085]}, "_runtime": 4263.037578821182, "_timestamp": 1585513341.4583085, "_step": 398}
{"Episode reward": -98.46263858112235, "Episode length": 999, "Policy Loss": 0.0007419230532832444, "Value Loss": 0.00021755890338681638, "_runtime": 4264.6087782382965, "_timestamp": 1585513343.0295079, "_step": 399}
{"Episode reward": -98.84182997637457, "Episode length": 999, "Policy Loss": 0.0006088843219913542, "Value Loss": 0.0001453681179555133, "_runtime": 4266.174303770065, "_timestamp": 1585513344.5950334, "_step": 400}
{"Episode reward": -98.90117299659602, "Episode length": 999, "Policy Loss": 0.0008001333335414529, "Value Loss": 8.012576290639117e-05, "_runtime": 4267.737554073334, "_timestamp": 1585513346.1582837, "_step": 401}
{"Episode reward": -98.97283558795208, "Episode length": 999, "Policy Loss": 0.0005545368185266852, "Value Loss": 8.396862540394068e-05, "_runtime": 4269.334458827972, "_timestamp": 1585513347.7551885, "_step": 402}
{"Episode reward": -98.94220373028966, "Episode length": 999, "Policy Loss": 0.0002584017929621041, "Value Loss": 9.810961637413129e-05, "_runtime": 4270.893926143646, "_timestamp": 1585513349.3146558, "_step": 403}
{"Episode reward": -98.26339005113833, "Episode length": 999, "Policy Loss": 0.0036377671640366316, "Value Loss": 0.0011913958005607128, "_runtime": 4272.455536365509, "_timestamp": 1585513350.876266, "_step": 404}
{"Episode reward": -99.11614467403342, "Episode length": 999, "Policy Loss": 0.0010198118397966027, "Value Loss": 0.00025601396919228137, "_runtime": 4274.017361879349, "_timestamp": 1585513352.4380915, "_step": 405}
{"Episode reward": -98.52133869426828, "Episode length": 999, "Policy Loss": 0.0016354296822100878, "Value Loss": 0.00043301007826812565, "_runtime": 4275.579404830933, "_timestamp": 1585513354.0001345, "_step": 406}
{"Episode reward": -98.29897939608193, "Episode length": 999, "Policy Loss": 0.002147461986169219, "Value Loss": 0.0009860225254669785, "_runtime": 4277.144104957581, "_timestamp": 1585513355.5648346, "_step": 407}
{"Episode reward": -99.02940175553482, "Episode length": 999, "Policy Loss": -0.00013682516873814166, "Value Loss": 0.00010513758024899289, "_runtime": 4278.6934649944305, "_timestamp": 1585513357.1141946, "_step": 408}
{"Episode reward": -98.45162626656848, "Episode length": 999, "Policy Loss": 0.0017503565177321434, "Value Loss": 0.0004883166402578354, "_runtime": 4280.25368475914, "_timestamp": 1585513358.6744144, "_step": 409}
{"Episode reward": -98.56290403737083, "Episode length": 999, "Policy Loss": 0.0016398562584072351, "Value Loss": 0.0005585225881077349, "_runtime": 4281.8049602508545, "_timestamp": 1585513360.22569, "_step": 410}
{"Episode reward": -99.18951878730427, "Episode length": 999, "Policy Loss": 0.000922875537071377, "Value Loss": 0.0002628386137075722, "_runtime": 4283.354295969009, "_timestamp": 1585513361.7750256, "_step": 411}
{"Episode reward": -98.91460755555235, "Episode length": 999, "Policy Loss": 0.00030115622212179005, "Value Loss": 8.996162068797275e-05, "_runtime": 4284.915377140045, "_timestamp": 1585513363.3361068, "_step": 412}
{"Episode reward": -99.73197308348732, "Episode length": 999, "Policy Loss": 0.002369916532188654, "Value Loss": 0.0005529138725250959, "_runtime": 4286.478667020798, "_timestamp": 1585513364.8993967, "_step": 413}
{"Episode reward": -99.6303490677891, "Episode length": 999, "Policy Loss": 0.0028683957643806934, "Value Loss": 0.0005699102184735239, "_runtime": 4288.040500402451, "_timestamp": 1585513366.46123, "_step": 414}
{"Episode reward": -99.74925880971284, "Episode length": 999, "Policy Loss": 0.0013468547258526087, "Value Loss": 0.000595732475630939, "_runtime": 4289.599930524826, "_timestamp": 1585513368.0206602, "_step": 415}
{"Episode reward": -98.35881826568813, "Episode length": 999, "Policy Loss": 0.0007102032541297376, "Value Loss": 0.000451741274446249, "_runtime": 4291.162070989609, "_timestamp": 1585513369.5828006, "_step": 416}
{"Episode reward": -99.09006757631154, "Episode length": 999, "Policy Loss": 0.00023684350890107453, "Value Loss": 0.00024304429825861007, "_runtime": 4292.760315418243, "_timestamp": 1585513371.181045, "_step": 417}
{"Episode reward": -99.307532655007, "Episode length": 999, "Policy Loss": 0.0005963172880001366, "Value Loss": 0.0002624310727696866, "_runtime": 4294.307922124863, "_timestamp": 1585513372.7286518, "_step": 418}
{"Episode reward": -98.51840114774836, "Episode length": 999, "Policy Loss": 0.0025670158211141825, "Value Loss": 0.0008260838803835213, "_runtime": 4295.867378234863, "_timestamp": 1585513374.2881079, "_step": 419}
{"Episode reward": -99.56872888765565, "Episode length": 999, "Policy Loss": 0.0024164451751857996, "Value Loss": 0.0005395695334300399, "_runtime": 4297.428580760956, "_timestamp": 1585513375.8493104, "_step": 420}
{"Episode reward": -98.96955893900709, "Episode length": 999, "Policy Loss": 0.0001867160463007167, "Value Loss": 0.0001647226745262742, "_runtime": 4298.976401567459, "_timestamp": 1585513377.3971312, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003083671908825636, "Value Loss": 0.0005709853139705956, "_runtime": 4300.542914152145, "_timestamp": 1585513378.9636438, "_step": 422}
{"Episode reward": -99.42765023884056, "Episode length": 999, "Policy Loss": 0.001265515573322773, "Value Loss": 0.00043066489160992205, "_runtime": 4302.11053943634, "_timestamp": 1585513380.531269, "_step": 423}
{"Episode reward": -98.06274412982481, "Episode length": 999, "Policy Loss": 0.00033738280762918293, "Value Loss": 0.0017005070112645626, "_runtime": 4303.658865690231, "_timestamp": 1585513382.0795953, "_step": 424}
{"Episode reward": -99.11089711554149, "Episode length": 999, "Policy Loss": 0.0006667666602879763, "Value Loss": 8.184042235370725e-05, "_runtime": 4305.220847129822, "_timestamp": 1585513383.6415768, "_step": 425}
{"Episode reward": -99.05008120818648, "Episode length": 999, "Policy Loss": 0.0006502396427094936, "Value Loss": 0.00017168206977657974, "_runtime": 4306.780035018921, "_timestamp": 1585513385.2007647, "_step": 426}
{"Episode reward": -97.76573937574486, "Episode length": 999, "Policy Loss": -0.0006610988057218492, "Value Loss": 0.001839271280914545, "_runtime": 4308.33907699585, "_timestamp": 1585513386.7598066, "_step": 427}
{"Episode reward": -98.407088210153, "Episode length": 999, "Policy Loss": 0.0024191627744585276, "Value Loss": 0.0008369703427888453, "_runtime": 4309.889837265015, "_timestamp": 1585513388.310567, "_step": 428}
{"Episode reward": -99.53275172423787, "Episode length": 999, "Policy Loss": 0.002949480200186372, "Value Loss": 0.0004875222221016884, "_runtime": 4311.452157735825, "_timestamp": 1585513389.8728874, "_step": 429}
{"Episode reward": -98.7464273446596, "Episode length": 999, "Policy Loss": 0.0004321291053202003, "Value Loss": 8.878813241608441e-05, "_runtime": 4313.009942293167, "_timestamp": 1585513391.430672, "_step": 430}
{"Episode reward": -99.6438703581938, "Episode length": 999, "Policy Loss": 0.0021921114530414343, "Value Loss": 0.000540119712240994, "_runtime": 4314.572272539139, "_timestamp": 1585513392.9930022, "_step": 431}
{"Episode reward": -99.40516538071917, "Episode length": 999, "Policy Loss": 0.0010381803149357438, "Value Loss": 0.00042915187077596784, "_runtime": 4316.168014287949, "_timestamp": 1585513394.588744, "_step": 432}
{"Episode reward": -99.25437864495657, "Episode length": 999, "Policy Loss": 0.0008040227112360299, "Value Loss": 0.0002849888405762613, "_runtime": 4317.7263967990875, "_timestamp": 1585513396.1471264, "_step": 433}
{"Episode reward": -98.67754714882793, "Episode length": 999, "Policy Loss": 0.0007907171384431422, "Value Loss": 0.00011517407256178558, "_runtime": 4319.290926218033, "_timestamp": 1585513397.7116559, "_step": 434}
{"Episode reward": -99.61940229756696, "Episode length": 999, "Policy Loss": 0.0033481267746537924, "Value Loss": 0.0005500850966200233, "_runtime": 4320.842116355896, "_timestamp": 1585513399.262846, "_step": 435}
{"Episode reward": -98.19586820537403, "Episode length": 999, "Policy Loss": -0.0011861617676913738, "Value Loss": 0.0017725040670484304, "_runtime": 4322.392373323441, "_timestamp": 1585513400.813103, "_step": 436}
{"Episode reward": -99.64309434566621, "Episode length": 999, "Policy Loss": 0.003020389936864376, "Value Loss": 0.00054874864872545, "_runtime": 4323.951101064682, "_timestamp": 1585513402.3718307, "_step": 437}
{"Episode reward": -99.5953838988998, "Episode length": 999, "Policy Loss": 0.002571470569819212, "Value Loss": 0.0005197296268306673, "_runtime": 4325.513052940369, "_timestamp": 1585513403.9337826, "_step": 438}
{"Episode reward": -98.49159454219522, "Episode length": 999, "Policy Loss": 0.0018870702479034662, "Value Loss": 0.0006839172565378249, "_runtime": 4327.073506593704, "_timestamp": 1585513405.4942362, "_step": 439}
{"Episode reward": -99.11284542506857, "Episode length": 999, "Policy Loss": 0.0002308881375938654, "Value Loss": 0.0001870440464699641, "_runtime": 4328.6354558467865, "_timestamp": 1585513407.0561855, "_step": 440}
{"Episode reward": -98.60960622839656, "Episode length": 999, "Policy Loss": 0.0013710499042645097, "Value Loss": 0.0001480306964367628, "_runtime": 4330.195202112198, "_timestamp": 1585513408.6159317, "_step": 441}
{"Episode reward": -98.83832270963389, "Episode length": 999, "Policy Loss": 0.00028702826239168644, "Value Loss": 0.00012192304711788893, "_runtime": 4331.74485874176, "_timestamp": 1585513410.1655884, "_step": 442}
{"Episode reward": -99.36276968461335, "Episode length": 999, "Policy Loss": 0.001946835545822978, "Value Loss": 0.00044768975931219757, "_runtime": 4333.317106723785, "_timestamp": 1585513411.7378364, "_step": 443}
{"Episode reward": -99.81357320094574, "Episode length": 999, "Policy Loss": 0.0019748094491660595, "Value Loss": 0.0005909819738008082, "_runtime": 4334.88670539856, "_timestamp": 1585513413.307435, "_step": 444}
{"Episode reward": -98.86782477678832, "Episode length": 999, "Policy Loss": 0.0008192380191758275, "Value Loss": 8.3464416093193e-05, "_runtime": 4336.44629573822, "_timestamp": 1585513414.8670254, "_step": 445}
{"Episode reward": -99.05574487296256, "Episode length": 999, "Policy Loss": 0.0006369182374328375, "Value Loss": 0.0001798534649424255, "_runtime": 4338.045086145401, "_timestamp": 1585513416.4658158, "_step": 446}
{"Episode reward": -98.19687772904224, "Episode length": 999, "Policy Loss": 0.0010985599365085363, "Value Loss": 0.0009008315391838551, "_runtime": 4339.59556221962, "_timestamp": 1585513418.0162919, "_step": 447}
{"Episode reward": -98.97531447982321, "Episode length": 999, "Policy Loss": 0.0008171370136551559, "Value Loss": 0.0001762853207765147, "_runtime": 4341.143093109131, "_timestamp": 1585513419.5638227, "_step": 448}
{"Episode reward": -98.22041837786854, "Episode length": 999, "Policy Loss": 0.002061452018097043, "Value Loss": 0.00112956203520298, "_runtime": 4342.695836544037, "_timestamp": 1585513421.1165662, "_step": 449}
{"Episode reward": -98.62349427807, "Episode length": 999, "Policy Loss": 0.0020053519401699305, "Value Loss": 0.00037021993193775415, "_runtime": 4344.258979558945, "_timestamp": 1585513422.6797092, "_step": 450}
{"Episode reward": -97.77859214398752, "Episode length": 999, "Policy Loss": -0.0034345986787229776, "Value Loss": 0.002171629574149847, "_runtime": 4345.808835029602, "_timestamp": 1585513424.2295647, "_step": 451}
{"Episode reward": -99.81583397167725, "Episode length": 999, "Policy Loss": 0.003154080593958497, "Value Loss": 0.0005577764823101461, "_runtime": 4347.360830545425, "_timestamp": 1585513425.7815602, "_step": 452}
{"Episode reward": -98.73158748834267, "Episode length": 999, "Policy Loss": 0.0007102084928192198, "Value Loss": 0.0001950687583303079, "_runtime": 4348.922500610352, "_timestamp": 1585513427.3432302, "_step": 453}
{"Episode reward": -98.96640859066396, "Episode length": 999, "Policy Loss": 0.0008121315622702241, "Value Loss": 0.0001273636589758098, "_runtime": 4350.474082946777, "_timestamp": 1585513428.8948126, "_step": 454}
{"Episode reward": -99.34863051481108, "Episode length": 999, "Policy Loss": 0.001743377884849906, "Value Loss": 0.0003424498427193612, "_runtime": 4352.036786556244, "_timestamp": 1585513430.4575162, "_step": 455}
{"Episode reward": -98.33168503073456, "Episode length": 999, "Policy Loss": 0.0007382275653071702, "Value Loss": 0.001361522707156837, "_runtime": 4353.588706970215, "_timestamp": 1585513432.0094366, "_step": 456}
{"Episode reward": -99.24441271027705, "Episode length": 999, "Policy Loss": 0.0004853017453569919, "Value Loss": 0.0002601032902020961, "_runtime": 4355.1520030498505, "_timestamp": 1585513433.5727327, "_step": 457}
{"Episode reward": -98.64958348938738, "Episode length": 999, "Policy Loss": 0.0007625927100889385, "Value Loss": 0.00015904651081655174, "_runtime": 4356.715528488159, "_timestamp": 1585513435.1362581, "_step": 458}
{"Episode reward": -98.05572922808794, "Episode length": 999, "Policy Loss": 0.0011587304761633277, "Value Loss": 0.00109067652374506, "_runtime": 4358.2765419483185, "_timestamp": 1585513436.6972716, "_step": 459}
{"Episode reward": -98.3975669165317, "Episode length": 999, "Policy Loss": 0.001499814447015524, "Value Loss": 0.00046732471673749387, "_runtime": 4359.826328992844, "_timestamp": 1585513438.2470586, "_step": 460}
{"Episode reward": -99.60904408767114, "Episode length": 999, "Policy Loss": 0.0024055924732238054, "Value Loss": 0.000528056058101356, "_runtime": 4361.418245792389, "_timestamp": 1585513439.8389754, "_step": 461}
{"Episode reward": -97.81321990041933, "Episode length": 999, "Policy Loss": 0.0031353523954749107, "Value Loss": 0.0015041278675198555, "_runtime": 4362.970095157623, "_timestamp": 1585513441.3908248, "_step": 462}
{"Episode reward": -98.45761304299067, "Episode length": 999, "Policy Loss": -0.0003807322937063873, "Value Loss": 0.0021271081641316414, "_runtime": 4364.510185480118, "_timestamp": 1585513442.930915, "_step": 463}
{"Episode reward": -99.09660428302142, "Episode length": 999, "Policy Loss": 0.00048102965229190886, "Value Loss": 0.00021223354269750416, "_runtime": 4366.072912693024, "_timestamp": 1585513444.4936423, "_step": 464}
{"Episode reward": -99.70107357155185, "Episode length": 999, "Policy Loss": 0.002602385589852929, "Value Loss": 0.0005497369566000998, "_runtime": 4367.633296251297, "_timestamp": 1585513446.054026, "_step": 465}
{"Episode reward": -99.42265758928042, "Episode length": 999, "Policy Loss": 0.001107322983443737, "Value Loss": 0.0004043662338517606, "_runtime": 4369.19447016716, "_timestamp": 1585513447.6151998, "_step": 466}
{"Episode reward": -98.72360585022867, "Episode length": 999, "Policy Loss": 0.002790658501908183, "Value Loss": 0.001110675511881709, "_runtime": 4370.756640911102, "_timestamp": 1585513449.1773705, "_step": 467}
{"Episode reward": -99.68396369753668, "Episode length": 999, "Policy Loss": 0.0021183881908655167, "Value Loss": 0.0005401624948717654, "_runtime": 4372.318295001984, "_timestamp": 1585513450.7390246, "_step": 468}
{"Episode reward": -99.64546113423246, "Episode length": 999, "Policy Loss": 0.00237366184592247, "Value Loss": 0.0005045745056122541, "_runtime": 4373.864122867584, "_timestamp": 1585513452.2848525, "_step": 469}
{"Episode reward": -98.95378904899967, "Episode length": 999, "Policy Loss": 0.001108453143388033, "Value Loss": 0.000117523581138812, "_runtime": 4375.412282943726, "_timestamp": 1585513453.8330126, "_step": 470}
{"Episode reward": -98.80192506129453, "Episode length": 999, "Policy Loss": 0.0006549411918967962, "Value Loss": 0.00012784327554982156, "_runtime": 4376.958660364151, "_timestamp": 1585513455.37939, "_step": 471}
{"Episode reward": -98.58779976587573, "Episode length": 999, "Policy Loss": 0.0015938039869070053, "Value Loss": 0.00021757248032372445, "_runtime": 4378.502995967865, "_timestamp": 1585513456.9237256, "_step": 472}
{"Episode reward": -99.39076897969795, "Episode length": 999, "Policy Loss": 0.0013160421513020992, "Value Loss": 0.000317439524224028, "_runtime": 4380.050203323364, "_timestamp": 1585513458.470933, "_step": 473}
{"Episode reward": -98.71384393764697, "Episode length": 999, "Policy Loss": 0.0002961750724352896, "Value Loss": 9.457718260819092e-05, "_runtime": 4381.598231554031, "_timestamp": 1585513460.0189612, "_step": 474}
{"Episode reward": -99.22143400916625, "Episode length": 999, "Policy Loss": 0.0012880639405921102, "Value Loss": 0.00028994845342822373, "_runtime": 4383.142307043076, "_timestamp": 1585513461.5630367, "_step": 475}
{"Episode reward": -98.74644382741975, "Episode length": 999, "Policy Loss": 0.0004497970512602478, "Value Loss": 8.182649617083371e-05, "_runtime": 4384.725747346878, "_timestamp": 1585513463.146477, "_step": 476}
{"Episode reward": -99.46929133640975, "Episode length": 999, "Policy Loss": 0.0009286137064918876, "Value Loss": 0.00021900047431699932, "_runtime": 4386.275692224503, "_timestamp": 1585513464.6964219, "_step": 477}
{"Episode reward": -99.87821999053858, "Episode length": 999, "Policy Loss": 0.0028666402213275433, "Value Loss": 0.000588210008572787, "_runtime": 4387.824239730835, "_timestamp": 1585513466.2449694, "_step": 478}
{"Episode reward": -99.60274385012005, "Episode length": 999, "Policy Loss": 0.002118196338415146, "Value Loss": 0.00046382611617445946, "_runtime": 4389.375897884369, "_timestamp": 1585513467.7966275, "_step": 479}
{"Episode reward": -98.38884769327308, "Episode length": 999, "Policy Loss": 0.0012125199427828193, "Value Loss": 0.0014044687850400805, "_runtime": 4390.924062252045, "_timestamp": 1585513469.344792, "_step": 480}
{"Episode reward": -98.05231059302511, "Episode length": 999, "Policy Loss": -0.0011093433713540435, "Value Loss": 0.001808074419386685, "_runtime": 4392.473358154297, "_timestamp": 1585513470.8940878, "_step": 481}
{"Episode reward": -98.67682700650978, "Episode length": 999, "Policy Loss": 0.00040759597322903574, "Value Loss": 0.00040557747706770897, "_runtime": 4394.012407064438, "_timestamp": 1585513472.4331367, "_step": 482}
{"Episode reward": -99.72064580597498, "Episode length": 999, "Policy Loss": 0.0028120307251811028, "Value Loss": 0.0005382606759667397, "_runtime": 4395.553979635239, "_timestamp": 1585513473.9747093, "_step": 483}
{"Episode reward": -98.2920935878057, "Episode length": 999, "Policy Loss": 0.003229906316846609, "Value Loss": 0.0013562397798523307, "_runtime": 4397.105209827423, "_timestamp": 1585513475.5259395, "_step": 484}
{"Episode reward": -98.09069207187058, "Episode length": 999, "Policy Loss": 0.0028672004118561745, "Value Loss": 0.0012324658455327153, "_runtime": 4398.65696310997, "_timestamp": 1585513477.0776927, "_step": 485}
{"Episode reward": -97.71440056412345, "Episode length": 999, "Policy Loss": -0.00040542366332374513, "Value Loss": 0.0020440726075321436, "_runtime": 4400.20892906189, "_timestamp": 1585513478.6296587, "_step": 486}
{"Episode reward": -98.16555836182421, "Episode length": 999, "Policy Loss": -0.0005159471184015274, "Value Loss": 0.00188719411380589, "_runtime": 4401.756382703781, "_timestamp": 1585513480.1771123, "_step": 487}
{"Episode reward": -98.01643058912266, "Episode length": 999, "Policy Loss": 0.0017774144653230906, "Value Loss": 0.0012244445970281959, "_runtime": 4403.306727170944, "_timestamp": 1585513481.7274568, "_step": 488}
{"Episode reward": -99.27487458964242, "Episode length": 999, "Policy Loss": 0.0011110538616776466, "Value Loss": 0.00020251351816114038, "_runtime": 4404.855587720871, "_timestamp": 1585513483.2763174, "_step": 489}
{"Episode reward": -98.41102764300724, "Episode length": 999, "Policy Loss": 0.0027519664727151394, "Value Loss": 0.00033556585549376905, "_runtime": 4406.403343439102, "_timestamp": 1585513484.824073, "_step": 490}
{"Episode reward": -99.46678503656618, "Episode length": 999, "Policy Loss": 0.0023558815009891987, "Value Loss": 0.00044008492841385305, "_runtime": 4407.990720033646, "_timestamp": 1585513486.4114497, "_step": 491}
{"Episode reward": -98.3019848452626, "Episode length": 999, "Policy Loss": 0.00011906755389645696, "Value Loss": 0.0011092029744759202, "_runtime": 4409.541669845581, "_timestamp": 1585513487.9623995, "_step": 492}
{"Episode reward": -99.21915913188938, "Episode length": 999, "Policy Loss": 0.0011729819234460592, "Value Loss": 0.00021293977624736726, "_runtime": 4411.09069442749, "_timestamp": 1585513489.511424, "_step": 493}
{"Episode reward": -99.80778839618252, "Episode length": 999, "Policy Loss": 0.0032265172339975834, "Value Loss": 0.0005500518600456417, "_runtime": 4412.640691757202, "_timestamp": 1585513491.0614214, "_step": 494}
{"Episode reward": -98.41394298810198, "Episode length": 999, "Policy Loss": 0.0017883694963529706, "Value Loss": 0.00038620876148343086, "_runtime": 4414.178575754166, "_timestamp": 1585513492.5993054, "_step": 495}
{"Episode reward": -99.64622265127316, "Episode length": 999, "Policy Loss": 0.0034681542310863733, "Value Loss": 0.0005325610982254148, "_runtime": 4415.740461587906, "_timestamp": 1585513494.1611912, "_step": 496}
{"Episode reward": -98.47089246330759, "Episode length": 999, "Policy Loss": 0.001768627087585628, "Value Loss": 0.0004211092018522322, "_runtime": 4417.304810285568, "_timestamp": 1585513495.72554, "_step": 497}
{"Episode reward": -98.1972190973642, "Episode length": 999, "Policy Loss": 0.0022510436829179525, "Value Loss": 0.0005701474146917462, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516, -6.962955474853516]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [6.962398529052734, 6.96333646774292, 6.964273929595947, 6.965211868286133, 6.96614933013916, 6.967087268829346, 6.968025207519531, 6.968962669372559, 6.969900608062744, 6.97083854675293, 6.971776008605957, 6.972713947296143, 6.973651885986328, 6.9745893478393555, 6.975527286529541, 6.976464748382568, 6.977402687072754, 6.9783406257629395, 6.979278087615967, 6.980216026306152, 6.98115348815918, 6.982091426849365, 6.983029365539551, 6.983966827392578, 6.984904766082764, 6.985842704772949, 6.986780166625977, 6.987718105316162, 6.988656044006348, 6.989593505859375, 6.9905314445495605, 6.991468906402588, 6.992406845092773, 6.993344783782959, 6.994282245635986, 6.995220184326172, 6.996157646179199, 6.997095584869385, 6.99803352355957, 6.998970985412598, 6.999908924102783, 7.000846862792969, 7.001784324645996, 7.002722263336182, 7.003660202026367, 7.0045976638793945, 7.00553560256958, 7.006473064422607, 7.007411003112793, 7.0083489418029785, 7.009286403656006, 7.010224342346191, 7.011161804199219, 7.012099742889404, 7.01303768157959, 7.013975143432617, 7.014913082122803, 7.015851020812988, 7.016788482666016, 7.017726421356201, 7.018664360046387, 7.019601821899414, 7.0205397605896, 7.021477222442627, 7.0224151611328125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 1.0], "bins": [-0.036306142807006836, -0.03571711853146553, -0.035128094255924225, -0.03453906625509262, -0.033950041979551315, -0.03336101770401001, -0.032771993428468704, -0.0321829691529274, -0.031593941152095795, -0.03100491687655449, -0.030415892601013184, -0.029826868325471878, -0.029237844049930573, -0.028648817911744118, -0.028059793636202812, -0.027470767498016357, -0.026881743222475052, -0.026292718946933746, -0.02570369280874729, -0.025114668533205986, -0.02452564239501953, -0.023936618119478226, -0.02334759384393692, -0.022758569568395615, -0.02216954343020916, -0.021580517292022705, -0.0209914930164814, -0.020402468740940094, -0.01981344446539879, -0.019224418327212334, -0.018635394051671028, -0.018046367913484573, -0.017457343637943268, -0.016868319362401962, -0.016279293224215508, -0.015690268948674202, -0.015101242810487747, -0.014512218534946442, -0.013923194259405136, -0.013334168121218681, -0.012745143845677376, -0.01215611957013607, -0.011567093431949615, -0.01097806915640831, -0.010389044880867004, -0.00980001874268055, -0.009210994467139244, -0.00862196832895279, -0.008032944053411484, -0.007443919777870178, -0.0068548936396837234, -0.006265869364142418, -0.005676843225955963, -0.005087818950414658, -0.004498794674873352, -0.0039097703993320465, -0.003320746123790741, -0.002731718122959137, -0.0021426938474178314, -0.0015536695718765259, -0.0009646452963352203, -0.0003756210207939148, 0.0002134069800376892, 0.0008024312555789948, 0.0013914555311203003]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 478.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 5.0, 7.0, 5.0, 4.0, 1.0], "bins": [-0.2902105450630188, -0.2846880555152893, -0.2791655659675598, -0.2736430764198303, -0.26812058687210083, -0.26259806752204895, -0.25707557797431946, -0.25155308842658997, -0.24603059887886047, -0.24050810933113098, -0.2349856197834015, -0.229463130235672, -0.2239406406879425, -0.21841813623905182, -0.21289564669132233, -0.20737314224243164, -0.20185065269470215, -0.19632816314697266, -0.19080567359924316, -0.18528318405151367, -0.17976069450378418, -0.1742382049560547, -0.168715700507164, -0.1631932109594345, -0.15767072141170502, -0.15214823186397552, -0.14662572741508484, -0.14110323786735535, -0.13558074831962585, -0.13005825877189636, -0.12453575432300568, -0.11901326477527618, -0.11349077522754669, -0.1079682856798172, -0.10244579613208771, -0.09692329168319702, -0.09140080213546753, -0.08587831258773804, -0.08035582304000854, -0.07483331859111786, -0.06931082904338837, -0.06378833949565887, -0.05826584994792938, -0.05274336040019989, -0.047220855951309204, -0.04169836640357971, -0.03617587685585022, -0.030653387308120728, -0.025130897760391235, -0.019608408212661743, -0.014085918664932251, -0.008563399314880371, -0.003040909767150879, 0.0024815797805786133, 0.008004069328308105, 0.013526558876037598, 0.01904904842376709, 0.024571537971496582, 0.030094027519226074, 0.035616517066955566, 0.041139036417007446, 0.04666152596473694, 0.05218401551246643, 0.05770650506019592, 0.06322899460792542]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.035781607031822205, -0.033451732248067856, -0.031121859326958656, -0.028791986405849457, -0.026462111622095108, -0.02413223683834076, -0.02180236391723156, -0.01947249099612236, -0.01714261621236801, -0.014812741428613663, -0.012482868507504463, -0.010152995586395264, -0.007823120802640915, -0.005493246018886566, -0.003163374960422516, -0.0008335001766681671, 0.0014963746070861816, 0.0038262493908405304, 0.006156124174594879, 0.00848599523305893, 0.010815870016813278, 0.013145744800567627, 0.015475615859031677, 0.017805490642786026, 0.020135365426540375, 0.022465240210294724, 0.024795114994049072, 0.027124986052513123, 0.029454857110977173, 0.03178473562002182, 0.03411460667848587, 0.03644448518753052, 0.03877435624599457, 0.04110422730445862, 0.043434105813503265, 0.045763976871967316, 0.04809385538101196, 0.05042372643947601, 0.052753597497940063, 0.05508347600698471, 0.05741334706544876, 0.05974321812391281, 0.06207309663295746, 0.06440296769142151, 0.06673283874988556, 0.0690627172589302, 0.07139258831739426, 0.0737224668264389, 0.07605233788490295, 0.078382208943367, 0.08071208745241165, 0.0830419585108757, 0.08537183701992035, 0.0877017080783844, 0.09003157913684845, 0.0923614501953125, 0.09469132125377655, 0.0970212072134018, 0.09935107827186584, 0.1016809493303299, 0.10401082038879395, 0.106340691447258, 0.10867057740688324, 0.11100044846534729, 0.11333031952381134]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 7.0, 24.0, 10.0, 4.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.45519837737083435, -0.4465484023094177, -0.4378984570503235, -0.42924851179122925, -0.4205985367298126, -0.411948561668396, -0.40329861640930176, -0.3946486711502075, -0.3859986960887909, -0.37734872102737427, -0.36869877576828003, -0.3600488305091858, -0.35139885544776917, -0.34274888038635254, -0.3340989351272583, -0.32544898986816406, -0.31679901480674744, -0.3081490397453308, -0.2994990944862366, -0.29084914922714233, -0.2821991741657257, -0.2735491991043091, -0.26489925384521484, -0.2562493085861206, -0.24759933352470398, -0.23894937336444855, -0.23029941320419312, -0.22164945304393768, -0.21299949288368225, -0.204349547624588, -0.1956995725631714, -0.18704959750175476, -0.17839965224266052, -0.16974970698356628, -0.16109973192214966, -0.15244975686073303, -0.1437998116016388, -0.13514986634254456, -0.12649989128112793, -0.1178499162197113, -0.10919997096061707, -0.10055002570152283, -0.0919000506401062, -0.08325007557868958, -0.07460013031959534, -0.0659501850605011, -0.05730020999908447, -0.04865023493766785, -0.04000028967857361, -0.03135034441947937, -0.022700369358062744, -0.014050394296646118, -0.00540044903755188, 0.0032494962215423584, 0.011899471282958984, 0.02054944634437561, 0.02919939160346985, 0.03784933686256409, 0.046499282121658325, 0.05514928698539734, 0.06379923224449158, 0.07244917750358582, 0.08109918236732483, 0.08974912762641907, 0.0983990728855133]}, "_runtime": 4418.845961809158, "_timestamp": 1585513497.2666914, "_step": 498}
{"Episode reward": -98.73445843138293, "Episode length": 999, "Policy Loss": 0.0018351997714489698, "Value Loss": 0.0002121697907568887, "_runtime": 4418.845961809158, "_timestamp": 1585513497.2666914, "_step": 499}
