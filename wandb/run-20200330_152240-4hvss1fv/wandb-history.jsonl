{"Episode reward": 68.87758955760343, "Episode length": 742, "Policy Loss": 0.04132865369319916, "Value Loss": 13.447614669799805, "_runtime": 11859.839666604996, "_timestamp": 1585581775.6843, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2571213245391846, "Value Loss": 58.99192428588867, "_runtime": 11861.351247549057, "_timestamp": 1585581777.195881, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3980247676372528, "Value Loss": 457.1571350097656, "_runtime": 11862.934064388275, "_timestamp": 1585581778.7786977, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 593.0785522460938, "Value Loss": 212860.65625, "_runtime": 11864.51318693161, "_timestamp": 1585581780.3578203, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12137702852487564, "Value Loss": 50.08894729614258, "_runtime": 11866.055968761444, "_timestamp": 1585581781.900602, "_step": 4}
{"Episode reward": -83.09628200516262, "Episode length": 999, "Policy Loss": 0.2589423358440399, "Value Loss": 45.8095817565918, "_runtime": 11867.65772485733, "_timestamp": 1585581783.5023582, "_step": 5}
{"Episode reward": -43.52901000763354, "Episode length": 999, "Policy Loss": 1.2135183811187744, "Value Loss": 307.4773864746094, "_runtime": 11869.234575271606, "_timestamp": 1585581785.0792086, "_step": 6}
{"Episode reward": -46.773028256076465, "Episode length": 999, "Policy Loss": 1.0726737976074219, "Value Loss": 46.25230026245117, "_runtime": 11870.784583091736, "_timestamp": 1585581786.6292164, "_step": 7}
{"Episode reward": -57.77430221866503, "Episode length": 999, "Policy Loss": 1.1958144903182983, "Value Loss": 763.6885375976562, "_runtime": 11872.392804384232, "_timestamp": 1585581788.2374377, "_step": 8}
{"Episode reward": -53.70315994582418, "Episode length": 999, "Policy Loss": -1.5878307819366455, "Value Loss": 24913.3671875, "_runtime": 11873.989954471588, "_timestamp": 1585581789.8345878, "_step": 9}
{"Episode reward": -55.86393546332746, "Episode length": 999, "Policy Loss": -6.216392993927002, "Value Loss": 4472.87451171875, "_runtime": 11875.538501024246, "_timestamp": 1585581791.3831344, "_step": 10}
{"Episode reward": -66.7141428431822, "Episode length": 999, "Policy Loss": 10.86755657196045, "Value Loss": 1116.85693359375, "_runtime": 11877.148982524872, "_timestamp": 1585581792.9936159, "_step": 11}
{"Episode reward": -84.79164132640607, "Episode length": 999, "Policy Loss": -1.0797830820083618, "Value Loss": 338.40625, "_runtime": 11878.73762011528, "_timestamp": 1585581794.5822535, "_step": 12}
{"Episode reward": -93.78598275716192, "Episode length": 999, "Policy Loss": 3.5335757732391357, "Value Loss": 395.6788330078125, "_runtime": 11880.358197450638, "_timestamp": 1585581796.2028308, "_step": 13}
{"Episode reward": -97.64393618637536, "Episode length": 999, "Policy Loss": -29.201574325561523, "Value Loss": 2156.6865234375, "_runtime": 11881.964807510376, "_timestamp": 1585581797.8094409, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -61.93925857543945, "Value Loss": 2025.4482421875, "_runtime": 11883.567583322525, "_timestamp": 1585581799.4122167, "_step": 15}
{"Episode reward": -97.46271301796222, "Episode length": 999, "Policy Loss": -9.23509693145752, "Value Loss": 100.03606414794922, "_runtime": 11885.150796175003, "_timestamp": 1585581800.9954295, "_step": 16}
{"Episode reward": -94.57337828102021, "Episode length": 999, "Policy Loss": -0.10372241586446762, "Value Loss": 17.194438934326172, "_runtime": 11886.757376432419, "_timestamp": 1585581802.6020098, "_step": 17}
{"Episode reward": -88.99478161793286, "Episode length": 999, "Policy Loss": 10.306380271911621, "Value Loss": 198.01231384277344, "_runtime": 11888.362692117691, "_timestamp": 1585581804.2073255, "_step": 18}
{"Episode reward": -69.85714089587621, "Episode length": 999, "Policy Loss": 8.387138366699219, "Value Loss": 75.20712280273438, "_runtime": 11889.953043937683, "_timestamp": 1585581805.7976773, "_step": 19}
{"Episode reward": -75.03496031688961, "Episode length": 999, "Policy Loss": 14.070965766906738, "Value Loss": 483.3092346191406, "_runtime": 11891.555676221848, "_timestamp": 1585581807.4003096, "_step": 20}
{"Episode reward": -82.81528163342294, "Episode length": 999, "Policy Loss": 19.49492835998535, "Value Loss": 26493.87890625, "_runtime": 11893.14224767685, "_timestamp": 1585581808.986881, "_step": 21}
{"Episode reward": -76.98353453551775, "Episode length": 999, "Policy Loss": -3.426485061645508, "Value Loss": 6818.14892578125, "_runtime": 11894.721316576004, "_timestamp": 1585581810.56595, "_step": 22}
{"Episode reward": -79.18227125102271, "Episode length": 999, "Policy Loss": 14.780396461486816, "Value Loss": 27994.318359375, "_runtime": 11896.325156450272, "_timestamp": 1585581812.1697898, "_step": 23}
{"Episode reward": -88.62407150936785, "Episode length": 999, "Policy Loss": 22.364139556884766, "Value Loss": 981.9581298828125, "_runtime": 11897.368065595627, "_timestamp": 1585581813.212699, "_step": 24}
{"Episode reward": 43.87840811282507, "Episode length": 643, "Policy Loss": 62.51854705810547, "Value Loss": 10717.0009765625, "_runtime": 11897.855202198029, "_timestamp": 1585581813.6998355, "_step": 25}
{"Episode reward": 76.05311793501667, "Episode length": 278, "Policy Loss": 17.670143127441406, "Value Loss": 11843.486328125, "_runtime": 11898.66698718071, "_timestamp": 1585581814.5116205, "_step": 26}
{"Episode reward": 54.230970763183954, "Episode length": 504, "Policy Loss": -7.359981060028076, "Value Loss": 8049.64990234375, "_runtime": 11900.11964225769, "_timestamp": 1585581815.9642756, "_step": 27}
{"Episode reward": 14.281865923499936, "Episode length": 924, "Policy Loss": 12.39138126373291, "Value Loss": 2690.7548828125, "_runtime": 11900.640498876572, "_timestamp": 1585581816.4851322, "_step": 28}
{"Episode reward": 69.90329633827986, "Episode length": 331, "Policy Loss": 32.62122344970703, "Value Loss": 6397.8642578125, "_runtime": 11902.163433074951, "_timestamp": 1585581818.0080664, "_step": 29}
{"Episode reward": -92.42596293199585, "Episode length": 999, "Policy Loss": 22.71354103088379, "Value Loss": 1206.63330078125, "_runtime": 11903.785225391388, "_timestamp": 1585581819.6298587, "_step": 30}
{"Episode reward": -93.50130950239874, "Episode length": 999, "Policy Loss": 18.771394729614258, "Value Loss": 1708.67822265625, "_runtime": 11905.289236307144, "_timestamp": 1585581821.1338696, "_step": 31}
{"Episode reward": -94.81454902635728, "Episode length": 999, "Policy Loss": 14.012699127197266, "Value Loss": 365.0368347167969, "_runtime": 11906.874272346497, "_timestamp": 1585581822.7189057, "_step": 32}
{"Episode reward": -94.89011100456946, "Episode length": 999, "Policy Loss": 15.911087989807129, "Value Loss": 435.4639587402344, "_runtime": 11907.500184297562, "_timestamp": 1585581823.3448176, "_step": 33}
{"Episode reward": 66.6016580423283, "Episode length": 365, "Policy Loss": 24.752609252929688, "Value Loss": 8242.9873046875, "_runtime": 11908.234758615494, "_timestamp": 1585581824.079392, "_step": 34}
{"Episode reward": 58.417015973032264, "Episode length": 459, "Policy Loss": 71.8870849609375, "Value Loss": 5435.9443359375, "_runtime": 11909.172572374344, "_timestamp": 1585581825.0172057, "_step": 35}
{"Episode reward": 46.33973906445607, "Episode length": 584, "Policy Loss": 17.95183563232422, "Value Loss": 535.3809814453125, "_runtime": 11909.753475904465, "_timestamp": 1585581825.5981092, "_step": 36}
{"Episode reward": 65.62769599790462, "Episode length": 371, "Policy Loss": 19.956335067749023, "Value Loss": 376.278564453125, "_runtime": 11911.272680044174, "_timestamp": 1585581827.1173134, "_step": 37}
{"Episode reward": -94.62611279681988, "Episode length": 999, "Policy Loss": 9.231797218322754, "Value Loss": 32.63095474243164, "_runtime": 11912.816234827042, "_timestamp": 1585581828.6608682, "_step": 38}
{"Episode reward": -94.35328564186433, "Episode length": 999, "Policy Loss": 6.774698257446289, "Value Loss": 260.42730712890625, "_runtime": 11914.335891962051, "_timestamp": 1585581830.1805253, "_step": 39}
{"Episode reward": -96.0503476785368, "Episode length": 999, "Policy Loss": 10.908661842346191, "Value Loss": 140.30213928222656, "_runtime": 11915.82668209076, "_timestamp": 1585581831.6713154, "_step": 40}
{"Episode reward": 10.7819719473285, "Episode length": 937, "Policy Loss": 2.690335988998413, "Value Loss": 935.8889770507812, "_runtime": 11916.723955154419, "_timestamp": 1585581832.5685885, "_step": 41}
{"Episode reward": 48.22437750552763, "Episode length": 553, "Policy Loss": 2.0426785945892334, "Value Loss": 752.533203125, "_runtime": 11918.006249666214, "_timestamp": 1585581833.850883, "_step": 42}
{"Episode reward": 22.89745900576102, "Episode length": 813, "Policy Loss": 6.941742420196533, "Value Loss": 339.45404052734375, "_runtime": 11919.594051122665, "_timestamp": 1585581835.4386845, "_step": 43}
{"Episode reward": -95.9403016010183, "Episode length": 999, "Policy Loss": 9.487592697143555, "Value Loss": 88.76673126220703, "_runtime": 11920.855060815811, "_timestamp": 1585581836.6996942, "_step": 44}
{"Episode reward": 23.651026105387388, "Episode length": 813, "Policy Loss": 7.6562042236328125, "Value Loss": 363.34771728515625, "_runtime": 11922.047743082047, "_timestamp": 1585581837.8923764, "_step": 45}
{"Episode reward": 29.878704734896246, "Episode length": 754, "Policy Loss": 10.044342041015625, "Value Loss": 406.7162780761719, "_runtime": 11923.629540681839, "_timestamp": 1585581839.474174, "_step": 46}
{"Episode reward": -96.80689140951495, "Episode length": 999, "Policy Loss": 8.662306785583496, "Value Loss": 9.720146179199219, "_runtime": 11925.193677902222, "_timestamp": 1585581841.0383112, "_step": 47}
{"Episode reward": -96.48772805402146, "Episode length": 999, "Policy Loss": 9.286829948425293, "Value Loss": 37.03415298461914, "_runtime": 11925.804609775543, "_timestamp": 1585581841.649243, "_step": 48}
{"Episode reward": 64.85827137421151, "Episode length": 370, "Policy Loss": 33.096187591552734, "Value Loss": 1320.3387451171875, "_runtime": 11927.424476623535, "_timestamp": 1585581843.26911, "_step": 49}
{"Episode reward": -97.01496471557972, "Episode length": 999, "Policy Loss": 9.401322364807129, "Value Loss": 15.863755226135254, "_runtime": 11928.314346075058, "_timestamp": 1585581844.1589794, "_step": 50}
{"Episode reward": 48.71389207002625, "Episode length": 544, "Policy Loss": 15.040322303771973, "Value Loss": 236.38482666015625, "_runtime": 11929.845616102219, "_timestamp": 1585581845.6902494, "_step": 51}
{"Episode reward": -96.27084352927835, "Episode length": 999, "Policy Loss": 11.338642120361328, "Value Loss": 198.66424560546875, "_runtime": 11931.446514368057, "_timestamp": 1585581847.2911477, "_step": 52}
{"Episode reward": -96.0937673464649, "Episode length": 999, "Policy Loss": 10.175871849060059, "Value Loss": 269.882568359375, "_runtime": 11932.990112781525, "_timestamp": 1585581848.8347461, "_step": 53}
{"Episode reward": -95.56343469519547, "Episode length": 999, "Policy Loss": 6.289079666137695, "Value Loss": 407.490234375, "_runtime": 11934.583396673203, "_timestamp": 1585581850.42803, "_step": 54}
{"Episode reward": -94.17038999900012, "Episode length": 999, "Policy Loss": 14.911821365356445, "Value Loss": 566.8241577148438, "_runtime": 11935.861503124237, "_timestamp": 1585581851.7061365, "_step": 55}
{"Episode reward": 24.373449406241477, "Episode length": 794, "Policy Loss": 7.565903663635254, "Value Loss": 49.8203010559082, "_runtime": 11937.448853492737, "_timestamp": 1585581853.2934868, "_step": 56}
{"Episode reward": -96.93593713495471, "Episode length": 999, "Policy Loss": 4.198268413543701, "Value Loss": 1.8023627996444702, "_runtime": 11938.883969068527, "_timestamp": 1585581854.7286024, "_step": 57}
{"Episode reward": 15.391637165273579, "Episode length": 899, "Policy Loss": 2.2407517433166504, "Value Loss": 76.27581024169922, "_runtime": 11939.605832338333, "_timestamp": 1585581855.4504657, "_step": 58}
{"Episode reward": 59.830729555439184, "Episode length": 444, "Policy Loss": -1.2627381086349487, "Value Loss": 272.1929626464844, "_runtime": 11941.186450242996, "_timestamp": 1585581857.0310836, "_step": 59}
{"Episode reward": 6.214817641201606, "Episode length": 996, "Policy Loss": 0.37678954005241394, "Value Loss": 174.14822387695312, "_runtime": 11942.7775182724, "_timestamp": 1585581858.6221516, "_step": 60}
{"Episode reward": -96.23352281177749, "Episode length": 999, "Policy Loss": -2.6570205688476562, "Value Loss": 80.5409927368164, "_runtime": 11944.30944776535, "_timestamp": 1585581860.154081, "_step": 61}
{"Episode reward": -95.70843089827011, "Episode length": 999, "Policy Loss": -2.9172279834747314, "Value Loss": 26.88276481628418, "_runtime": 11945.759818553925, "_timestamp": 1585581861.604452, "_step": 62}
{"Episode reward": 14.491605744483849, "Episode length": 907, "Policy Loss": 0.116332046687603, "Value Loss": 140.08192443847656, "_runtime": 11946.843102693558, "_timestamp": 1585581862.687736, "_step": 63}
{"Episode reward": 35.136095781852134, "Episode length": 675, "Policy Loss": 0.4657779037952423, "Value Loss": 257.3116760253906, "_runtime": 11948.425530195236, "_timestamp": 1585581864.2701635, "_step": 64}
{"Episode reward": -96.19075391642224, "Episode length": 999, "Policy Loss": -2.407294511795044, "Value Loss": 22.704233169555664, "_runtime": 11950.019129514694, "_timestamp": 1585581865.8637629, "_step": 65}
{"Episode reward": -97.3413561569313, "Episode length": 999, "Policy Loss": -2.376992702484131, "Value Loss": 14.118012428283691, "_runtime": 11950.720855474472, "_timestamp": 1585581866.5654888, "_step": 66}
{"Episode reward": 59.27020164810195, "Episode length": 435, "Policy Loss": -2.26226806640625, "Value Loss": 71.21957397460938, "_runtime": 11951.604012012482, "_timestamp": 1585581867.4486454, "_step": 67}
{"Episode reward": 50.69666461045998, "Episode length": 518, "Policy Loss": -1.040315866470337, "Value Loss": 64.78575897216797, "_runtime": 11952.78710269928, "_timestamp": 1585581868.631736, "_step": 68}
{"Episode reward": 31.68279665960236, "Episode length": 738, "Policy Loss": -0.7708297967910767, "Value Loss": 42.005043029785156, "_runtime": 11954.320517539978, "_timestamp": 1585581870.165151, "_step": 69}
{"Episode reward": -94.36950141404786, "Episode length": 999, "Policy Loss": -0.8802787065505981, "Value Loss": 49.136070251464844, "_runtime": 11955.813652992249, "_timestamp": 1585581871.6582863, "_step": 70}
{"Episode reward": 9.423319895552325, "Episode length": 967, "Policy Loss": -1.8621621131896973, "Value Loss": 41.76941680908203, "_runtime": 11957.376617193222, "_timestamp": 1585581873.2212505, "_step": 71}
{"Episode reward": -94.35504148878682, "Episode length": 999, "Policy Loss": 0.08374262601137161, "Value Loss": 11.58934211730957, "_runtime": 11958.793339967728, "_timestamp": 1585581874.6379733, "_step": 72}
{"Episode reward": 15.211467273889042, "Episode length": 894, "Policy Loss": 0.17074188590049744, "Value Loss": 27.205312728881836, "_runtime": 11959.733736515045, "_timestamp": 1585581875.5783699, "_step": 73}
{"Episode reward": 43.96359054681767, "Episode length": 582, "Policy Loss": 2.188387155532837, "Value Loss": 48.18717575073242, "_runtime": 11960.476548194885, "_timestamp": 1585581876.3211815, "_step": 74}
{"Episode reward": 57.701270984068294, "Episode length": 452, "Policy Loss": 2.079176187515259, "Value Loss": 52.23164749145508, "_runtime": 11961.823779821396, "_timestamp": 1585581877.6684132, "_step": 75}
{"Episode reward": 18.026961118131638, "Episode length": 859, "Policy Loss": 1.8614628314971924, "Value Loss": 50.78765869140625, "_runtime": 11963.31698513031, "_timestamp": 1585581879.1616185, "_step": 76}
{"Episode reward": 8.48398644116331, "Episode length": 964, "Policy Loss": 1.2914589643478394, "Value Loss": 36.971839904785156, "_runtime": 11963.908762216568, "_timestamp": 1585581879.7533956, "_step": 77}
{"Episode reward": 64.97337459050078, "Episode length": 371, "Policy Loss": 3.4605300426483154, "Value Loss": 68.8773422241211, "_runtime": 11964.400411605835, "_timestamp": 1585581880.245045, "_step": 78}
{"Episode reward": 72.89797285217654, "Episode length": 296, "Policy Loss": 4.187828540802002, "Value Loss": 69.53279113769531, "_runtime": 11965.970747232437, "_timestamp": 1585581881.8153806, "_step": 79}
{"Episode reward": -95.58773679556113, "Episode length": 999, "Policy Loss": -1.3071190118789673, "Value Loss": 1.4888908863067627, "_runtime": 11967.499034166336, "_timestamp": 1585581883.3436675, "_step": 80}
{"Episode reward": -95.67543141681016, "Episode length": 999, "Policy Loss": -1.2424930334091187, "Value Loss": 2.3323006629943848, "_runtime": 11968.904395341873, "_timestamp": 1585581884.7490287, "_step": 81}
{"Episode reward": 11.458574446362661, "Episode length": 928, "Policy Loss": 0.2568911612033844, "Value Loss": 20.277685165405273, "_runtime": 11970.389819145203, "_timestamp": 1585581886.2344525, "_step": 82}
{"Episode reward": 10.682432187762572, "Episode length": 935, "Policy Loss": -1.7739847898483276, "Value Loss": 20.733985900878906, "_runtime": 11971.965341329575, "_timestamp": 1585581887.8099747, "_step": 83}
{"Episode reward": -95.90641364978117, "Episode length": 999, "Policy Loss": -1.8722288608551025, "Value Loss": 12.914505958557129, "_runtime": 11973.516624450684, "_timestamp": 1585581889.3612578, "_step": 84}
{"Episode reward": -95.28056449124507, "Episode length": 999, "Policy Loss": -2.2904767990112305, "Value Loss": 15.409744262695312, "_runtime": 11975.09647154808, "_timestamp": 1585581890.941105, "_step": 85}
{"Episode reward": -95.94216038619248, "Episode length": 999, "Policy Loss": -1.6194043159484863, "Value Loss": 6.037482738494873, "_runtime": 11976.263292312622, "_timestamp": 1585581892.1079257, "_step": 86}
{"Episode reward": 33.45026589458881, "Episode length": 714, "Policy Loss": -2.864272117614746, "Value Loss": 34.17909622192383, "_runtime": 11977.830924510956, "_timestamp": 1585581893.6755579, "_step": 87}
{"Episode reward": -95.1478041996576, "Episode length": 999, "Policy Loss": -2.31436824798584, "Value Loss": 9.257554054260254, "_runtime": 11978.860407829285, "_timestamp": 1585581894.7050412, "_step": 88}
{"Episode reward": 41.40673275638403, "Episode length": 639, "Policy Loss": -1.6751575469970703, "Value Loss": 23.537643432617188, "_runtime": 11980.422167778015, "_timestamp": 1585581896.266801, "_step": 89}
{"Episode reward": -95.5679998948201, "Episode length": 999, "Policy Loss": -2.5031216144561768, "Value Loss": 7.005134582519531, "_runtime": 11981.996398448944, "_timestamp": 1585581897.8410318, "_step": 90}
{"Episode reward": -97.45831567204002, "Episode length": 999, "Policy Loss": -2.0105552673339844, "Value Loss": 1.0240715742111206, "_runtime": 11983.54301071167, "_timestamp": 1585581899.387644, "_step": 91}
{"Episode reward": -96.10816815955748, "Episode length": 999, "Policy Loss": -2.1011264324188232, "Value Loss": 1.3590435981750488, "_runtime": 11985.119444131851, "_timestamp": 1585581900.9640775, "_step": 92}
{"Episode reward": -95.86421098050086, "Episode length": 999, "Policy Loss": -1.9579901695251465, "Value Loss": 7.748589515686035, "_runtime": 11986.699392557144, "_timestamp": 1585581902.544026, "_step": 93}
{"Episode reward": -96.6194586022884, "Episode length": 999, "Policy Loss": -1.952723741531372, "Value Loss": 8.636125564575195, "_runtime": 11988.282887458801, "_timestamp": 1585581904.1275208, "_step": 94}
{"Episode reward": -95.89930146085531, "Episode length": 999, "Policy Loss": -2.2892062664031982, "Value Loss": 5.130586624145508, "_runtime": 11989.000827550888, "_timestamp": 1585581904.845461, "_step": 95}
{"Episode reward": 58.10489259918838, "Episode length": 441, "Policy Loss": 4.190530300140381, "Value Loss": 74.06613159179688, "_runtime": 11990.58154463768, "_timestamp": 1585581906.426178, "_step": 96}
{"Episode reward": -96.01147006168374, "Episode length": 999, "Policy Loss": -1.9472837448120117, "Value Loss": 3.39551043510437, "_runtime": 11992.16692352295, "_timestamp": 1585581908.0115569, "_step": 97}
{"Episode reward": -96.88765426918485, "Episode length": 999, "Policy Loss": -1.790419578552246, "Value Loss": 0.6012592315673828, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791, 6.597902774810791]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.5944671630859375, -6.310994625091553, -6.027522563934326, -5.744050025939941, -5.460577964782715, -5.17710542678833, -4.893632888793945, -4.610160827636719, -4.326688289642334, -4.043215751647949, -3.7597436904907227, -3.476271152496338, -3.1927988529205322, -2.9093265533447266, -2.625854015350342, -2.3423819541931152, -2.0589094161987305, -1.7754368782043457, -1.4919648170471191, -1.2084922790527344, -0.9250202178955078, -0.641547679901123, -0.3580751419067383, -0.07460308074951172, 0.20886945724487305, 0.4923419952392578, 0.7758140563964844, 1.0592865943908691, 1.342759132385254, 1.6262311935424805, 1.909703254699707, 2.19317626953125, 2.4766483306884766, 2.760120391845703, 3.043593406677246, 3.3270654678344727, 3.610537528991699, 3.894010543823242, 4.177482604980469, 4.460954666137695, 4.744426727294922, 5.027899742126465, 5.311371803283691, 5.594843864440918, 5.878316879272461, 6.1617889404296875, 6.445261001586914, 6.728734016418457, 7.012206077575684, 7.29567813873291, 7.579151153564453, 7.86262321472168, 8.146095275878906, 8.42956829071045, 8.713040351867676, 8.996512413024902, 9.279985427856445, 9.563457489013672, 9.846929550170898, 10.130401611328125, 10.413873672485352, 10.697347640991211, 10.980819702148438, 11.264291763305664, 11.54776382446289]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.7675414085388184, -3.650897741317749, -3.5342538356781006, -3.4176101684570312, -3.300966501235962, -3.1843228340148926, -3.067678928375244, -2.951035261154175, -2.8343915939331055, -2.717747688293457, -2.6011040210723877, -2.4844603538513184, -2.36781644821167, -2.2511730194091797, -2.1345291137695312, -2.017885446548462, -1.901241660118103, -1.7845978736877441, -1.6679542064666748, -1.5513105392456055, -1.434666633605957, -1.3180229663848877, -1.2013792991638184, -1.084735631942749, -0.9680917263031006, -0.8514480590820312, -0.7348043918609619, -0.6181604862213135, -0.5015168190002441, -0.3848731517791748, -0.26822948455810547, -0.15158557891845703, -0.034941911697387695, 0.08170175552368164, 0.19834566116333008, 0.3149890899658203, 0.43163299560546875, 0.5482769012451172, 0.6649203300476074, 0.7815642356872559, 0.8982081413269043, 1.0148515701293945, 1.131495475769043, 1.2481393814086914, 1.3647828102111816, 1.48142671585083, 1.5980701446533203, 1.7147140502929688, 1.8313579559326172, 1.9480013847351074, 2.064645290374756, 2.1812891960144043, 2.2979326248168945, 2.414576530456543, 2.5312204360961914, 2.6478638648986816, 2.76450777053833, 2.8811516761779785, 2.9977951049804688, 3.114439010620117, 3.2310824394226074, 3.347726345062256, 3.4643702507019043, 3.5810136795043945, 3.697657585144043]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 4.0, 7.0, 1.0, 4.0, 8.0, 9.0, 8.0, 9.0, 14.0, 13.0, 6.0, 7.0, 11.0, 14.0, 20.0, 27.0, 38.0, 120.0, 41.0, 7.0, 8.0, 1.0, 9.0, 8.0, 6.0, 11.0, 11.0, 2.0, 10.0, 10.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 5.0, 10.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0], "bins": [-2.9809632301330566, -2.893493890762329, -2.8060245513916016, -2.718555212020874, -2.6310858726501465, -2.543616771697998, -2.4561474323272705, -2.368678092956543, -2.2812087535858154, -2.193739414215088, -2.1062700748443604, -2.018800735473633, -1.9313315153121948, -1.8438621759414673, -1.7563929557800293, -1.6689236164093018, -1.5814542770385742, -1.4939849376678467, -1.4065155982971191, -1.3190463781356812, -1.2315770387649536, -1.144107699394226, -1.056638479232788, -0.9691691398620605, -0.881699800491333, -0.7942304611206055, -0.7067611217498779, -0.6192917823791504, -0.531822681427002, -0.4443533420562744, -0.3568840026855469, -0.26941466331481934, -0.1819453239440918, -0.09447598457336426, -0.007006645202636719, 0.08046269416809082, 0.16793203353881836, 0.2554011344909668, 0.34287047386169434, 0.4303398132324219, 0.5178091526031494, 0.605278491973877, 0.6927478313446045, 0.780217170715332, 0.8676862716674805, 0.955155611038208, 1.0426249504089355, 1.1300945281982422, 1.2175636291503906, 1.305032730102539, 1.3925023078918457, 1.4799714088439941, 1.5674409866333008, 1.6549100875854492, 1.7423796653747559, 1.8298487663269043, 1.9173178672790527, 2.0047874450683594, 2.092256546020508, 2.1797261238098145, 2.267195224761963, 2.3546648025512695, 2.442133903503418, 2.5296034812927246, 2.617072582244873]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-14.041360855102539, -13.583491325378418, -13.125622749328613, -12.667753219604492, -12.209883689880371, -11.75201416015625, -11.294145584106445, -10.836276054382324, -10.378406524658203, -9.920537948608398, -9.462668418884277, -9.004798889160156, -8.546930313110352, -8.08906078338623, -7.631191730499268, -7.1733222007751465, -6.715453147888184, -6.257584095001221, -5.799715042114258, -5.341845512390137, -4.883975982666016, -4.426107406616211, -3.96823787689209, -3.5103683471679688, -3.052499771118164, -2.594630241394043, -2.136760711669922, -1.6788911819458008, -1.221022605895996, -0.763153076171875, -0.3052835464477539, 0.15258502960205078, 0.6104545593261719, 1.068324089050293, 1.5261926651000977, 1.9840621948242188, 2.4419307708740234, 2.899801254272461, 3.3576698303222656, 3.8155384063720703, 4.273408889770508, 4.7312774658203125, 5.189146041870117, 5.647016525268555, 6.104885101318359, 6.562753677368164, 7.020624160766602, 7.478492736816406, 7.936361312866211, 8.394231796264648, 8.852100372314453, 9.30997085571289, 9.767839431762695, 10.2257080078125, 10.683578491210938, 11.141447067260742, 11.599315643310547, 12.057186126708984, 12.515054702758789, 12.972923278808594, 13.430793762207031, 13.888662338256836, 14.34653091430664, 14.804401397705078, 15.262269973754883]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.717451572418213, -3.5966413021087646, -3.4758310317993164, -3.3550209999084473, -3.234210729598999, -3.113400459289551, -2.9925901889801025, -2.8717799186706543, -2.750969886779785, -2.630159378051758, -2.5093493461608887, -2.3885390758514404, -2.267728805541992, -2.146918773651123, -2.0261082649230957, -1.9052982330322266, -1.7844879627227783, -1.66367769241333, -1.5428674221038818, -1.4220573902130127, -1.3012471199035645, -1.1804368495941162, -1.059626579284668, -0.9388163089752197, -0.8180060386657715, -0.6971960067749023, -0.5763857364654541, -0.45557546615600586, -0.3347651958465576, -0.21395492553710938, -0.09314489364624023, 0.027665376663208008, 0.14847564697265625, 0.2692859172821045, 0.39009618759155273, 0.5109062194824219, 0.6317167282104492, 0.7525267601013184, 0.8733367919921875, 0.9941473007202148, 1.114957332611084, 1.2357678413391113, 1.3565778732299805, 1.4773879051208496, 1.598198413848877, 1.719008445739746, 1.8398189544677734, 1.9606289863586426, 2.08143949508667, 2.202249526977539, 2.323059558868408, 2.4438700675964355, 2.5646800994873047, 2.685490608215332, 2.806300640106201, 2.9271106719970703, 3.0479211807250977, 3.168731212615967, 3.289541721343994, 3.4103517532348633, 3.5311617851257324, 3.6519722938537598, 3.772782325744629, 3.8935928344726562, 4.014402866363525]}, "_runtime": 11993.694131612778, "_timestamp": 1585581909.538765, "_step": 98}
{"Episode reward": -95.46979105479387, "Episode length": 999, "Policy Loss": -1.5418529510498047, "Value Loss": 0.44352564215660095, "_runtime": 11994.685116767883, "_timestamp": 1585581910.52975, "_step": 99}
{"Episode reward": 41.81514838149309, "Episode length": 616, "Policy Loss": -0.5073022842407227, "Value Loss": 17.922264099121094, "_runtime": 11996.13869357109, "_timestamp": 1585581911.983327, "_step": 100}
{"Episode reward": 13.384795669938597, "Episode length": 918, "Policy Loss": -0.7542474865913391, "Value Loss": 12.655862808227539, "_runtime": 11997.708128452301, "_timestamp": 1585581913.5527618, "_step": 101}
{"Episode reward": -97.41424355544241, "Episode length": 999, "Policy Loss": -1.0830119848251343, "Value Loss": 0.34500032663345337, "_runtime": 11998.54601764679, "_timestamp": 1585581914.390651, "_step": 102}
{"Episode reward": 49.074120232552914, "Episode length": 534, "Policy Loss": -0.47374966740608215, "Value Loss": 22.805532455444336, "_runtime": 12000.161236286163, "_timestamp": 1585581916.0058696, "_step": 103}
{"Episode reward": -95.0613823068594, "Episode length": 999, "Policy Loss": -0.3572085201740265, "Value Loss": 2.7188076972961426, "_runtime": 12001.723964452744, "_timestamp": 1585581917.5685978, "_step": 104}
{"Episode reward": -95.7335400853337, "Episode length": 999, "Policy Loss": -1.0362859964370728, "Value Loss": 5.524313449859619, "_runtime": 12003.257013320923, "_timestamp": 1585581919.1016467, "_step": 105}
{"Episode reward": -96.10562433008685, "Episode length": 999, "Policy Loss": -0.8406548500061035, "Value Loss": 2.322604179382324, "_runtime": 12004.369340658188, "_timestamp": 1585581920.213974, "_step": 106}
{"Episode reward": 33.888925226615115, "Episode length": 693, "Policy Loss": -0.5154121518135071, "Value Loss": 19.140222549438477, "_runtime": 12005.943357229233, "_timestamp": 1585581921.7879906, "_step": 107}
{"Episode reward": -95.5129983292183, "Episode length": 999, "Policy Loss": -0.7402356266975403, "Value Loss": 2.153716802597046, "_runtime": 12007.520355939865, "_timestamp": 1585581923.3649893, "_step": 108}
{"Episode reward": -94.30507525970664, "Episode length": 999, "Policy Loss": -0.5688011646270752, "Value Loss": 3.6003737449645996, "_runtime": 12007.897022247314, "_timestamp": 1585581923.7416556, "_step": 109}
{"Episode reward": 79.74945611970081, "Episode length": 221, "Policy Loss": 0.06399711221456528, "Value Loss": 46.465370178222656, "_runtime": 12008.642599582672, "_timestamp": 1585581924.487233, "_step": 110}
{"Episode reward": 57.17521969528651, "Episode length": 461, "Policy Loss": 1.066042184829712, "Value Loss": 26.223772048950195, "_runtime": 12009.524177312851, "_timestamp": 1585581925.3688107, "_step": 111}
{"Episode reward": 48.52443845347487, "Episode length": 545, "Policy Loss": 0.38976651430130005, "Value Loss": 19.131288528442383, "_runtime": 12010.809881448746, "_timestamp": 1585581926.6545148, "_step": 112}
{"Episode reward": 19.23686180202057, "Episode length": 844, "Policy Loss": -0.006148217245936394, "Value Loss": 12.916117668151855, "_runtime": 12012.343079328537, "_timestamp": 1585581928.1877127, "_step": 113}
{"Episode reward": -95.36651094082124, "Episode length": 999, "Policy Loss": -0.9635605216026306, "Value Loss": 0.1170482188463211, "_runtime": 12013.713294744492, "_timestamp": 1585581929.557928, "_step": 114}
{"Episode reward": 16.399991492529907, "Episode length": 886, "Policy Loss": -0.25255170464515686, "Value Loss": 13.619596481323242, "_runtime": 12014.576361894608, "_timestamp": 1585581930.4209952, "_step": 115}
{"Episode reward": 49.59447974887601, "Episode length": 545, "Policy Loss": 0.28219592571258545, "Value Loss": 19.513132095336914, "_runtime": 12016.136708498001, "_timestamp": 1585581931.9813418, "_step": 116}
{"Episode reward": -96.45347733316885, "Episode length": 999, "Policy Loss": -0.972905695438385, "Value Loss": 0.23530951142311096, "_runtime": 12017.456917524338, "_timestamp": 1585581933.3015509, "_step": 117}
{"Episode reward": 20.022570253011153, "Episode length": 854, "Policy Loss": 0.0954839289188385, "Value Loss": 14.808541297912598, "_runtime": 12018.680243968964, "_timestamp": 1585581934.5248773, "_step": 118}
{"Episode reward": 24.89471973618086, "Episode length": 796, "Policy Loss": -0.08482611924409866, "Value Loss": 12.886383056640625, "_runtime": 12020.250487565994, "_timestamp": 1585581936.095121, "_step": 119}
{"Episode reward": -94.50826084592947, "Episode length": 999, "Policy Loss": -0.692451000213623, "Value Loss": 0.5508782863616943, "_runtime": 12021.80864906311, "_timestamp": 1585581937.6532824, "_step": 120}
{"Episode reward": -96.22419201306312, "Episode length": 999, "Policy Loss": -0.6919929385185242, "Value Loss": 0.15110242366790771, "_runtime": 12023.37937784195, "_timestamp": 1585581939.2240112, "_step": 121}
{"Episode reward": -95.1300501192741, "Episode length": 999, "Policy Loss": -0.5327401161193848, "Value Loss": 1.0619633197784424, "_runtime": 12024.456226110458, "_timestamp": 1585581940.3008595, "_step": 122}
{"Episode reward": 35.41363339399352, "Episode length": 678, "Policy Loss": -0.18463274836540222, "Value Loss": 14.71963119506836, "_runtime": 12025.669830560684, "_timestamp": 1585581941.514464, "_step": 123}
{"Episode reward": 28.47135234923229, "Episode length": 766, "Policy Loss": 0.15579219162464142, "Value Loss": 15.27652359008789, "_runtime": 12026.512178659439, "_timestamp": 1585581942.356812, "_step": 124}
{"Episode reward": 49.972908047877134, "Episode length": 527, "Policy Loss": -0.21217067539691925, "Value Loss": 19.754884719848633, "_runtime": 12028.062366485596, "_timestamp": 1585581943.9069998, "_step": 125}
{"Episode reward": -97.03973936860619, "Episode length": 999, "Policy Loss": -0.4368380904197693, "Value Loss": 0.33768218755722046, "_runtime": 12029.617210388184, "_timestamp": 1585581945.4618437, "_step": 126}
{"Episode reward": -94.80425890044658, "Episode length": 999, "Policy Loss": -0.408287912607193, "Value Loss": 1.2991999387741089, "_runtime": 12031.083945274353, "_timestamp": 1585581946.9285786, "_step": 127}
{"Episode reward": 7.981213133685202, "Episode length": 961, "Policy Loss": 0.2817668914794922, "Value Loss": 10.910979270935059, "_runtime": 12032.659187793732, "_timestamp": 1585581948.5038211, "_step": 128}
{"Episode reward": -95.87277516061206, "Episode length": 999, "Policy Loss": -0.5082554221153259, "Value Loss": 0.680848240852356, "_runtime": 12034.225343942642, "_timestamp": 1585581950.0699773, "_step": 129}
{"Episode reward": -96.79002912651484, "Episode length": 999, "Policy Loss": -0.3483411371707916, "Value Loss": 0.09315644949674606, "_runtime": 12035.005136013031, "_timestamp": 1585581950.8497694, "_step": 130}
{"Episode reward": 55.39228399228445, "Episode length": 484, "Policy Loss": 0.8922936916351318, "Value Loss": 23.817035675048828, "_runtime": 12035.613305091858, "_timestamp": 1585581951.4579384, "_step": 131}
{"Episode reward": 66.20958027133477, "Episode length": 366, "Policy Loss": 0.11068825423717499, "Value Loss": 25.74753189086914, "_runtime": 12036.343435525894, "_timestamp": 1585581952.1880689, "_step": 132}
{"Episode reward": 56.78246740576744, "Episode length": 456, "Policy Loss": 0.19142091274261475, "Value Loss": 21.977733612060547, "_runtime": 12037.429929733276, "_timestamp": 1585581953.274563, "_step": 133}
{"Episode reward": 33.487442187758674, "Episode length": 714, "Policy Loss": 0.4579835832118988, "Value Loss": 14.290990829467773, "_runtime": 12038.121927976608, "_timestamp": 1585581953.9665613, "_step": 134}
{"Episode reward": 57.98408754429981, "Episode length": 452, "Policy Loss": 1.4361553192138672, "Value Loss": 24.571971893310547, "_runtime": 12038.460433483124, "_timestamp": 1585581954.3050668, "_step": 135}
{"Episode reward": 80.05047799043038, "Episode length": 213, "Policy Loss": 1.6646252870559692, "Value Loss": 44.78142547607422, "_runtime": 12039.579612255096, "_timestamp": 1585581955.4242456, "_step": 136}
{"Episode reward": 29.920531444235124, "Episode length": 731, "Policy Loss": 0.2375985085964203, "Value Loss": 13.365667343139648, "_runtime": 12041.110321044922, "_timestamp": 1585581956.9549544, "_step": 137}
{"Episode reward": -95.93836278610186, "Episode length": 999, "Policy Loss": -0.5381631851196289, "Value Loss": 0.2049809992313385, "_runtime": 12042.527425765991, "_timestamp": 1585581958.372059, "_step": 138}
{"Episode reward": 12.070021522281792, "Episode length": 944, "Policy Loss": -0.1324317306280136, "Value Loss": 10.276607513427734, "_runtime": 12043.51972079277, "_timestamp": 1585581959.3643541, "_step": 139}
{"Episode reward": 41.88624104776372, "Episode length": 628, "Policy Loss": 0.07048158347606659, "Value Loss": 15.168977737426758, "_runtime": 12045.092819213867, "_timestamp": 1585581960.9374526, "_step": 140}
{"Episode reward": -96.82851159211407, "Episode length": 999, "Policy Loss": -0.5054355263710022, "Value Loss": 0.21978579461574554, "_runtime": 12046.63811159134, "_timestamp": 1585581962.482745, "_step": 141}
{"Episode reward": -95.03294858282307, "Episode length": 999, "Policy Loss": -0.5543765425682068, "Value Loss": 0.5866796970367432, "_runtime": 12048.218658208847, "_timestamp": 1585581964.0632915, "_step": 142}
{"Episode reward": -95.87499393465191, "Episode length": 999, "Policy Loss": -0.4782879948616028, "Value Loss": 0.13124285638332367, "_runtime": 12049.499088287354, "_timestamp": 1585581965.3437216, "_step": 143}
{"Episode reward": 25.853113725174566, "Episode length": 806, "Policy Loss": -0.32888761162757874, "Value Loss": 13.171862602233887, "_runtime": 12051.072942495346, "_timestamp": 1585581966.9175758, "_step": 144}
{"Episode reward": -95.99399870274323, "Episode length": 999, "Policy Loss": -0.6768364906311035, "Value Loss": 0.42847564816474915, "_runtime": 12052.664178848267, "_timestamp": 1585581968.5088122, "_step": 145}
{"Episode reward": -96.33376028373578, "Episode length": 999, "Policy Loss": -0.5336424708366394, "Value Loss": 0.08887119591236115, "_runtime": 12053.896897792816, "_timestamp": 1585581969.7415311, "_step": 146}
{"Episode reward": 25.951863837227393, "Episode length": 778, "Policy Loss": -0.005308619700372219, "Value Loss": 13.405887603759766, "_runtime": 12055.09044265747, "_timestamp": 1585581970.935076, "_step": 147}
{"Episode reward": 27.07626370041112, "Episode length": 765, "Policy Loss": -0.2046748548746109, "Value Loss": 12.552678108215332, "_runtime": 12056.667563199997, "_timestamp": 1585581972.5121965, "_step": 148}
{"Episode reward": -96.29591215842909, "Episode length": 999, "Policy Loss": -0.5854074954986572, "Value Loss": 0.08030607551336288, "_runtime": 12057.275130271912, "_timestamp": 1585581973.1197636, "_step": 149}
{"Episode reward": 65.20314133962391, "Episode length": 369, "Policy Loss": 1.8964099884033203, "Value Loss": 29.689420700073242, "_runtime": 12058.837038993835, "_timestamp": 1585581974.6816723, "_step": 150}
{"Episode reward": -95.64700291042102, "Episode length": 999, "Policy Loss": -0.5671014189720154, "Value Loss": 0.17945268750190735, "_runtime": 12060.428177833557, "_timestamp": 1585581976.2728112, "_step": 151}
{"Episode reward": -97.33699491572631, "Episode length": 999, "Policy Loss": -0.5100780129432678, "Value Loss": 0.06932906061410904, "_runtime": 12061.470052957535, "_timestamp": 1585581977.3146863, "_step": 152}
{"Episode reward": 35.491706245679936, "Episode length": 685, "Policy Loss": 0.037313345819711685, "Value Loss": 14.378825187683105, "_runtime": 12063.053415060043, "_timestamp": 1585581978.8980484, "_step": 153}
{"Episode reward": -96.0412395488699, "Episode length": 999, "Policy Loss": -0.47914743423461914, "Value Loss": 0.23467803001403809, "_runtime": 12064.639620780945, "_timestamp": 1585581980.4842541, "_step": 154}
{"Episode reward": -94.34746670494165, "Episode length": 999, "Policy Loss": -0.5957732200622559, "Value Loss": 0.5307409167289734, "_runtime": 12065.118381261826, "_timestamp": 1585581980.9630146, "_step": 155}
{"Episode reward": 73.23214584887998, "Episode length": 290, "Policy Loss": 1.7508481740951538, "Value Loss": 36.43567657470703, "_runtime": 12065.735496282578, "_timestamp": 1585581981.5801296, "_step": 156}
{"Episode reward": 63.346146541027295, "Episode length": 382, "Policy Loss": 0.08578664809465408, "Value Loss": 24.894615173339844, "_runtime": 12067.302169084549, "_timestamp": 1585581983.1468024, "_step": 157}
{"Episode reward": -96.2409241779947, "Episode length": 999, "Policy Loss": -0.39519888162612915, "Value Loss": 0.22349227964878082, "_runtime": 12068.79867196083, "_timestamp": 1585581984.6433053, "_step": 158}
{"Episode reward": -95.29898778952561, "Episode length": 999, "Policy Loss": -0.41333192586898804, "Value Loss": 0.33547741174697876, "_runtime": 12070.308563232422, "_timestamp": 1585581986.1531966, "_step": 159}
{"Episode reward": -95.66019392675952, "Episode length": 999, "Policy Loss": -0.3960140645503998, "Value Loss": 0.20245708525180817, "_runtime": 12071.920639753342, "_timestamp": 1585581987.765273, "_step": 160}
{"Episode reward": -93.37094927477813, "Episode length": 999, "Policy Loss": -0.511857807636261, "Value Loss": 0.5499312877655029, "_runtime": 12072.533459663391, "_timestamp": 1585581988.378093, "_step": 161}
{"Episode reward": 65.1042971164126, "Episode length": 373, "Policy Loss": 0.27176475524902344, "Value Loss": 25.51947021484375, "_runtime": 12073.324866056442, "_timestamp": 1585581989.1694994, "_step": 162}
{"Episode reward": 52.17109459709992, "Episode length": 505, "Policy Loss": 0.17443948984146118, "Value Loss": 18.325998306274414, "_runtime": 12074.890486001968, "_timestamp": 1585581990.7351193, "_step": 163}
{"Episode reward": -96.0325269858982, "Episode length": 999, "Policy Loss": -0.4644806683063507, "Value Loss": 0.03800328075885773, "_runtime": 12076.396775960922, "_timestamp": 1585581992.2414093, "_step": 164}
{"Episode reward": -95.07767970027713, "Episode length": 999, "Policy Loss": -0.43972247838974, "Value Loss": 0.09107238799333572, "_runtime": 12077.52283668518, "_timestamp": 1585581993.36747, "_step": 165}
{"Episode reward": 29.54826215888609, "Episode length": 736, "Policy Loss": -0.0077647436410188675, "Value Loss": 13.102765083312988, "_runtime": 12079.000433206558, "_timestamp": 1585581994.8450665, "_step": 166}
{"Episode reward": 9.724688308785417, "Episode length": 947, "Policy Loss": 0.23722335696220398, "Value Loss": 10.992538452148438, "_runtime": 12080.277697324753, "_timestamp": 1585581996.1223307, "_step": 167}
{"Episode reward": 23.307046861606736, "Episode length": 812, "Policy Loss": -0.06225446239113808, "Value Loss": 11.523645401000977, "_runtime": 12081.719905853271, "_timestamp": 1585581997.5645392, "_step": 168}
{"Episode reward": 11.608929448931605, "Episode length": 935, "Policy Loss": 0.06251809746026993, "Value Loss": 10.368752479553223, "_runtime": 12082.128253936768, "_timestamp": 1585581997.9728873, "_step": 169}
{"Episode reward": 78.75179235589067, "Episode length": 226, "Policy Loss": 0.6909900903701782, "Value Loss": 44.38481903076172, "_runtime": 12083.15481042862, "_timestamp": 1585581998.9994438, "_step": 170}
{"Episode reward": 36.22634108234654, "Episode length": 662, "Policy Loss": -0.10137142241001129, "Value Loss": 13.393203735351562, "_runtime": 12084.13875412941, "_timestamp": 1585581999.9833875, "_step": 171}
{"Episode reward": 42.55155573480503, "Episode length": 622, "Policy Loss": -0.060716915875673294, "Value Loss": 15.123571395874023, "_runtime": 12084.925482034683, "_timestamp": 1585582000.7701154, "_step": 172}
{"Episode reward": 50.57693866801405, "Episode length": 526, "Policy Loss": 0.03618011623620987, "Value Loss": 18.181400299072266, "_runtime": 12086.349873304367, "_timestamp": 1585582002.1945066, "_step": 173}
{"Episode reward": 12.130248833823813, "Episode length": 932, "Policy Loss": -0.18969979882240295, "Value Loss": 10.750447273254395, "_runtime": 12087.164074420929, "_timestamp": 1585582003.0087078, "_step": 174}
{"Episode reward": 50.67136569071639, "Episode length": 523, "Policy Loss": 0.207264244556427, "Value Loss": 18.168283462524414, "_runtime": 12088.120500564575, "_timestamp": 1585582003.965134, "_step": 175}
{"Episode reward": 40.930561148723285, "Episode length": 625, "Policy Loss": 0.010489431209862232, "Value Loss": 16.205467224121094, "_runtime": 12089.431722640991, "_timestamp": 1585582005.276356, "_step": 176}
{"Episode reward": 20.066745209458162, "Episode length": 842, "Policy Loss": -0.23305267095565796, "Value Loss": 11.202630996704102, "_runtime": 12090.308285951614, "_timestamp": 1585582006.1529193, "_step": 177}
{"Episode reward": 45.94720311175323, "Episode length": 566, "Policy Loss": -0.05579981580376625, "Value Loss": 17.347768783569336, "_runtime": 12091.52901148796, "_timestamp": 1585582007.3736448, "_step": 178}
{"Episode reward": 24.707127153430974, "Episode length": 789, "Policy Loss": -0.19809187948703766, "Value Loss": 12.220656394958496, "_runtime": 12093.07537317276, "_timestamp": 1585582008.9200065, "_step": 179}
{"Episode reward": -94.83356175086215, "Episode length": 999, "Policy Loss": -0.5064540505409241, "Value Loss": 0.39506566524505615, "_runtime": 12094.282222747803, "_timestamp": 1585582010.126856, "_step": 180}
{"Episode reward": 25.338422988321852, "Episode length": 783, "Policy Loss": 0.02793409302830696, "Value Loss": 12.25564193725586, "_runtime": 12095.433178424835, "_timestamp": 1585582011.2778118, "_step": 181}
{"Episode reward": 31.956741033664258, "Episode length": 712, "Policy Loss": 0.3219357132911682, "Value Loss": 14.030261993408203, "_runtime": 12096.051446437836, "_timestamp": 1585582011.8960798, "_step": 182}
{"Episode reward": 65.1980689820771, "Episode length": 369, "Policy Loss": 0.45324981212615967, "Value Loss": 26.365724563598633, "_runtime": 12097.146726608276, "_timestamp": 1585582012.99136, "_step": 183}
{"Episode reward": 34.860438400842725, "Episode length": 708, "Policy Loss": -0.12593349814414978, "Value Loss": 13.475923538208008, "_runtime": 12098.247286558151, "_timestamp": 1585582014.09192, "_step": 184}
{"Episode reward": 33.672641686249605, "Episode length": 707, "Policy Loss": -0.057559411972761154, "Value Loss": 13.158326148986816, "_runtime": 12099.140417098999, "_timestamp": 1585582014.9850504, "_step": 185}
{"Episode reward": 43.84963315474212, "Episode length": 592, "Policy Loss": -0.2618347704410553, "Value Loss": 15.406682014465332, "_runtime": 12100.110622406006, "_timestamp": 1585582015.9552557, "_step": 186}
{"Episode reward": 42.643638344909306, "Episode length": 614, "Policy Loss": -0.09526575356721878, "Value Loss": 15.309303283691406, "_runtime": 12101.654073238373, "_timestamp": 1585582017.4987066, "_step": 187}
{"Episode reward": -96.49054391879082, "Episode length": 999, "Policy Loss": -0.3744666278362274, "Value Loss": 0.0553424172103405, "_runtime": 12103.190229415894, "_timestamp": 1585582019.0348628, "_step": 188}
{"Episode reward": -95.22053912236173, "Episode length": 999, "Policy Loss": -0.34632793068885803, "Value Loss": 0.03494969382882118, "_runtime": 12104.744189500809, "_timestamp": 1585582020.5888228, "_step": 189}
{"Episode reward": -96.32648406005521, "Episode length": 999, "Policy Loss": -0.4088389575481415, "Value Loss": 0.15021103620529175, "_runtime": 12106.330347537994, "_timestamp": 1585582022.1749809, "_step": 190}
{"Episode reward": -96.48094369702757, "Episode length": 999, "Policy Loss": -0.333926260471344, "Value Loss": 0.050272706896066666, "_runtime": 12107.912152767181, "_timestamp": 1585582023.756786, "_step": 191}
{"Episode reward": -96.83665103681244, "Episode length": 999, "Policy Loss": -0.3325420320034027, "Value Loss": 0.07099535316228867, "_runtime": 12108.676276922226, "_timestamp": 1585582024.5209103, "_step": 192}
{"Episode reward": 56.54333041976285, "Episode length": 463, "Policy Loss": -0.004526920150965452, "Value Loss": 21.125503540039062, "_runtime": 12110.267621278763, "_timestamp": 1585582026.1122546, "_step": 193}
{"Episode reward": -93.73354233495428, "Episode length": 999, "Policy Loss": -0.47440996766090393, "Value Loss": 0.39423927664756775, "_runtime": 12111.241645336151, "_timestamp": 1585582027.0862787, "_step": 194}
{"Episode reward": 43.01758992147633, "Episode length": 602, "Policy Loss": -0.009251290000975132, "Value Loss": 15.24819278717041, "_runtime": 12112.778975725174, "_timestamp": 1585582028.623609, "_step": 195}
{"Episode reward": -94.36224013397948, "Episode length": 999, "Policy Loss": -0.3634790778160095, "Value Loss": 0.0783509910106659, "_runtime": 12114.244582414627, "_timestamp": 1585582030.0892158, "_step": 196}
{"Episode reward": 12.317358536625363, "Episode length": 917, "Policy Loss": -0.09396281838417053, "Value Loss": 9.623274803161621, "_runtime": 12115.796092271805, "_timestamp": 1585582031.6407256, "_step": 197}
{"Episode reward": -95.63586833362928, "Episode length": 999, "Policy Loss": -0.34226056933403015, "Value Loss": 0.046545762568712234, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594, -43.52903747558594]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-304.6478271484375, -298.5754699707031, -292.5031433105469, -286.4307861328125, -280.35845947265625, -274.2861022949219, -268.2137756347656, -262.14141845703125, -256.069091796875, -249.99673461914062, -243.9243927001953, -237.85205078125, -231.77969360351562, -225.70736694335938, -219.635009765625, -213.5626678466797, -207.49032592773438, -201.41798400878906, -195.34564208984375, -189.27328491210938, -183.20095825195312, -177.12860107421875, -171.05625915527344, -164.98391723632812, -158.9115753173828, -152.8392333984375, -146.7668914794922, -140.69454956054688, -134.6221923828125, -128.5498504638672, -122.47750854492188, -116.40516662597656, -110.33282470703125, -104.26048278808594, -98.18814086914062, -92.11579895019531, -86.04345703125, -79.97109985351562, -73.89875793457031, -67.826416015625, -61.75407409667969, -55.681732177734375, -49.60939025878906, -43.53704833984375, -37.464691162109375, -31.392364501953125, -25.32000732421875, -19.2476806640625, -13.175323486328125, -7.10296630859375, -1.0306396484375, 5.041717529296875, 11.114044189453125, 17.1864013671875, 23.25872802734375, 29.331085205078125, 35.4034423828125, 41.47576904296875, 47.548126220703125, 53.620452880859375, 59.69281005859375, 65.76513671875, 71.83749389648438, 77.90982055664062, 83.982177734375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-33.59410095214844, -32.331050872802734, -31.06800079345703, -29.80495262145996, -28.541902542114258, -27.278852462768555, -26.015804290771484, -24.75275421142578, -23.489704132080078, -22.226654052734375, -20.963603973388672, -19.7005558013916, -18.4375057220459, -17.174455642700195, -15.911407470703125, -14.648357391357422, -13.385307312011719, -12.122257232666016, -10.859207153320312, -9.596158981323242, -8.333108901977539, -7.070058822631836, -5.807010650634766, -4.5439605712890625, -3.2809104919433594, -2.0178604125976562, -0.7548103332519531, 0.50823974609375, 1.7712860107421875, 3.0343360900878906, 4.297386169433594, 5.560436248779297, 6.823486328125, 8.086536407470703, 9.349586486816406, 10.61263656616211, 11.875686645507812, 13.13873291015625, 14.401782989501953, 15.664833068847656, 16.92788314819336, 18.190933227539062, 19.453983306884766, 20.71703338623047, 21.980079650878906, 23.24312973022461, 24.506179809570312, 25.769229888916016, 27.03227996826172, 28.295330047607422, 29.558380126953125, 30.821426391601562, 32.08448028564453, 33.34752655029297, 34.61058044433594, 35.873626708984375, 37.13667297363281, 38.39972686767578, 39.66277313232422, 40.92582702636719, 42.188873291015625, 43.451927185058594, 44.71497344970703, 45.97802734375, 47.24107360839844]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 3.0, 7.0, 3.0, 5.0, 6.0, 9.0, 12.0, 3.0, 6.0, 8.0, 9.0, 7.0, 5.0, 8.0, 7.0, 3.0, 3.0, 4.0, 16.0, 10.0, 85.0, 92.0, 36.0, 9.0, 6.0, 16.0, 12.0, 9.0, 4.0, 19.0, 21.0, 14.0, 9.0, 5.0, 9.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-47.697975158691406, -45.94635009765625, -44.194725036621094, -42.44309997558594, -40.691471099853516, -38.93984603881836, -37.1882209777832, -35.43659591674805, -33.68497085571289, -31.9333438873291, -30.181718826293945, -28.43009376525879, -26.678466796875, -24.926841735839844, -23.175216674804688, -21.4235897064209, -19.671964645385742, -17.920339584350586, -16.168712615966797, -14.41708755493164, -12.665462493896484, -10.913837432861328, -9.162212371826172, -7.41058349609375, -5.658958435058594, -3.9073333740234375, -2.1557083129882812, -0.404083251953125, 1.3475418090820312, 3.099170684814453, 4.850795745849609, 6.602420806884766, 8.354045867919922, 10.105670928955078, 11.857295989990234, 13.60892105102539, 15.360549926757812, 17.11217498779297, 18.863800048828125, 20.61542510986328, 22.367050170898438, 24.118675231933594, 25.87030029296875, 27.621925354003906, 29.373550415039062, 31.12518310546875, 32.876808166503906, 34.62843322753906, 36.38005828857422, 38.131683349609375, 39.88330841064453, 41.63493347167969, 43.386558532714844, 45.13818359375, 46.889808654785156, 48.64143371582031, 50.39305877685547, 52.144683837890625, 53.89631652832031, 55.64794158935547, 57.399566650390625, 59.15119171142578, 60.90281677246094, 62.654441833496094, 64.40606689453125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-149.45054626464844, -144.97764587402344, -140.5047607421875, -136.0318603515625, -131.5589599609375, -127.0860595703125, -122.61316680908203, -118.14027404785156, -113.66737365722656, -109.19447326660156, -104.7215805053711, -100.24868774414062, -95.77578735351562, -91.30288696289062, -86.82999420166016, -82.35710144042969, -77.88420104980469, -73.41130065917969, -68.93840789794922, -64.46551513671875, -59.99261474609375, -55.51971435546875, -51.04682159423828, -46.57392883300781, -42.10102844238281, -37.62812805175781, -33.155235290527344, -28.682342529296875, -24.209442138671875, -19.736541748046875, -15.263656616210938, -10.790756225585938, -6.3178558349609375, -1.8449554443359375, 2.6279449462890625, 7.100830078125, 11.57373046875, 16.046630859375, 20.519515991210938, 24.992416381835938, 29.465316772460938, 33.93821716308594, 38.41111755371094, 42.884002685546875, 47.356903076171875, 51.829803466796875, 56.30268859863281, 60.77558898925781, 65.24848937988281, 69.72138977050781, 74.19429016113281, 78.66717529296875, 83.14007568359375, 87.61297607421875, 92.08586120605469, 96.55876159667969, 101.03166198730469, 105.50456237792969, 109.97746276855469, 114.45036315917969, 118.92323303222656, 123.39613342285156, 127.86903381347656, 132.34193420410156, 136.81483459472656]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 5.0, 2.0, 3.0, 1.0, 6.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-68.43587493896484, -66.21233367919922, -63.98878479003906, -61.76524353027344, -59.54169845581055, -57.318153381347656, -55.094608306884766, -52.871063232421875, -50.64752197265625, -48.423973083496094, -46.20043182373047, -43.97688674926758, -41.75334167480469, -39.52980041503906, -37.306251525878906, -35.08271026611328, -32.85916519165039, -30.6356201171875, -28.41207504272461, -26.188533782958984, -23.964988708496094, -21.741443634033203, -19.517898559570312, -17.294353485107422, -15.070808410644531, -12.847267150878906, -10.623722076416016, -8.400177001953125, -6.176631927490234, -3.9530868530273438, -1.7295455932617188, 0.4940032958984375, 2.7175445556640625, 4.9410858154296875, 7.164634704589844, 9.388175964355469, 11.611724853515625, 13.83526611328125, 16.058807373046875, 18.28235626220703, 20.505897521972656, 22.729446411132812, 24.952987670898438, 27.176528930664062, 29.40007781982422, 31.623619079589844, 33.84716796875, 36.070709228515625, 38.29425811767578, 40.517799377441406, 42.74134063720703, 44.96488952636719, 47.18843078613281, 49.41197967529297, 51.635520935058594, 53.85906219482422, 56.082611083984375, 58.30615234375, 60.529701232910156, 62.75324249267578, 64.9767837524414, 67.20032501220703, 69.42388153076172, 71.64742279052734, 73.87096405029297]}, "_runtime": 12117.204186439514, "_timestamp": 1585582033.0488198, "_step": 198}
{"Episode reward": 16.049903875507738, "Episode length": 889, "Policy Loss": 0.17801928520202637, "Value Loss": 10.625358581542969, "_runtime": 12118.831471920013, "_timestamp": 1585582034.6761053, "_step": 199}
{"Episode reward": -96.28521479994609, "Episode length": 999, "Policy Loss": -0.32752180099487305, "Value Loss": 0.054786935448646545, "_runtime": 12120.418057918549, "_timestamp": 1585582036.2626913, "_step": 200}
{"Episode reward": -96.20676617567472, "Episode length": 999, "Policy Loss": -0.3565027415752411, "Value Loss": 0.03257623687386513, "_runtime": 12121.806862592697, "_timestamp": 1585582037.651496, "_step": 201}
{"Episode reward": 18.68568837050175, "Episode length": 877, "Policy Loss": 0.05230443552136421, "Value Loss": 11.329391479492188, "_runtime": 12123.39955997467, "_timestamp": 1585582039.2441933, "_step": 202}
{"Episode reward": -96.25256708965846, "Episode length": 999, "Policy Loss": -0.3336166441440582, "Value Loss": 0.03360670804977417, "_runtime": 12124.502583265305, "_timestamp": 1585582040.3472166, "_step": 203}
{"Episode reward": 35.68333625082886, "Episode length": 690, "Policy Loss": 0.279683917760849, "Value Loss": 13.68095588684082, "_runtime": 12125.712993144989, "_timestamp": 1585582041.5576265, "_step": 204}
{"Episode reward": 27.178829454998535, "Episode length": 768, "Policy Loss": 0.048530202358961105, "Value Loss": 11.824089050292969, "_runtime": 12126.500565052032, "_timestamp": 1585582042.3451984, "_step": 205}
{"Episode reward": 55.25924241519502, "Episode length": 480, "Policy Loss": 0.6066727042198181, "Value Loss": 18.558740615844727, "_runtime": 12127.814735174179, "_timestamp": 1585582043.6593685, "_step": 206}
{"Episode reward": 20.968089770864182, "Episode length": 837, "Policy Loss": -0.03162293881177902, "Value Loss": 10.289480209350586, "_runtime": 12128.722069740295, "_timestamp": 1585582044.566703, "_step": 207}
{"Episode reward": 45.60819116696495, "Episode length": 568, "Policy Loss": 0.6206876635551453, "Value Loss": 16.191320419311523, "_runtime": 12130.247313976288, "_timestamp": 1585582046.0919473, "_step": 208}
{"Episode reward": -95.831762917212, "Episode length": 999, "Policy Loss": -0.20291166007518768, "Value Loss": 0.1537865400314331, "_runtime": 12131.816864013672, "_timestamp": 1585582047.6614974, "_step": 209}
{"Episode reward": -96.50706039035897, "Episode length": 999, "Policy Loss": -0.19230690598487854, "Value Loss": 0.1507425457239151, "_runtime": 12133.359560728073, "_timestamp": 1585582049.204194, "_step": 210}
{"Episode reward": -97.07191649485809, "Episode length": 999, "Policy Loss": -0.10734786093235016, "Value Loss": 0.05956624075770378, "_runtime": 12134.94562959671, "_timestamp": 1585582050.790263, "_step": 211}
{"Episode reward": -95.57009018075732, "Episode length": 999, "Policy Loss": -0.09319751709699631, "Value Loss": 0.15256841480731964, "_runtime": 12136.311985254288, "_timestamp": 1585582052.1566186, "_step": 212}
{"Episode reward": 17.250911196467683, "Episode length": 859, "Policy Loss": 0.14781978726387024, "Value Loss": 11.602633476257324, "_runtime": 12137.883430957794, "_timestamp": 1585582053.7280643, "_step": 213}
{"Episode reward": -96.53609721453657, "Episode length": 999, "Policy Loss": -0.11307404190301895, "Value Loss": 0.07872980833053589, "_runtime": 12139.475272893906, "_timestamp": 1585582055.3199062, "_step": 214}
{"Episode reward": -96.0447559789384, "Episode length": 999, "Policy Loss": -0.15457360446453094, "Value Loss": 0.08551476150751114, "_runtime": 12141.050926446915, "_timestamp": 1585582056.8955598, "_step": 215}
{"Episode reward": -97.01434433360909, "Episode length": 999, "Policy Loss": -0.24456177651882172, "Value Loss": 0.21423949301242828, "_runtime": 12142.668581485748, "_timestamp": 1585582058.5132148, "_step": 216}
{"Episode reward": -96.0083702924476, "Episode length": 999, "Policy Loss": -0.17873512208461761, "Value Loss": 0.07234717160463333, "_runtime": 12143.509368896484, "_timestamp": 1585582059.3540022, "_step": 217}
{"Episode reward": 52.154209197859515, "Episode length": 512, "Policy Loss": 0.2737976908683777, "Value Loss": 17.450042724609375, "_runtime": 12144.751935005188, "_timestamp": 1585582060.5965683, "_step": 218}
{"Episode reward": 26.949908000257068, "Episode length": 777, "Policy Loss": 0.14353835582733154, "Value Loss": 11.683877944946289, "_runtime": 12146.33599615097, "_timestamp": 1585582062.1806295, "_step": 219}
{"Episode reward": -95.7893827318796, "Episode length": 999, "Policy Loss": -0.20198000967502594, "Value Loss": 0.011677410453557968, "_runtime": 12147.718797922134, "_timestamp": 1585582063.5634313, "_step": 220}
{"Episode reward": 14.43797356335969, "Episode length": 894, "Policy Loss": 0.12242643535137177, "Value Loss": 10.44804573059082, "_runtime": 12149.302136659622, "_timestamp": 1585582065.14677, "_step": 221}
{"Episode reward": -96.38867864660502, "Episode length": 999, "Policy Loss": -0.22339457273483276, "Value Loss": 0.02578619495034218, "_runtime": 12150.8866918087, "_timestamp": 1585582066.7313251, "_step": 222}
{"Episode reward": -94.19786473571669, "Episode length": 999, "Policy Loss": -0.19464771449565887, "Value Loss": 0.06409142911434174, "_runtime": 12152.420040845871, "_timestamp": 1585582068.2646742, "_step": 223}
{"Episode reward": 9.703883363558646, "Episode length": 971, "Policy Loss": 0.1924392282962799, "Value Loss": 9.848169326782227, "_runtime": 12154.016538143158, "_timestamp": 1585582069.8611715, "_step": 224}
{"Episode reward": -95.12556831783837, "Episode length": 999, "Policy Loss": -0.19899219274520874, "Value Loss": 0.3120194673538208, "_runtime": 12155.593230247498, "_timestamp": 1585582071.4378636, "_step": 225}
{"Episode reward": -96.41076857732371, "Episode length": 999, "Policy Loss": -0.20766320824623108, "Value Loss": 0.017792226746678352, "_runtime": 12156.109416723251, "_timestamp": 1585582071.95405, "_step": 226}
{"Episode reward": 73.39384398501045, "Episode length": 298, "Policy Loss": 0.6747543811798096, "Value Loss": 32.45734786987305, "_runtime": 12157.698634147644, "_timestamp": 1585582073.5432675, "_step": 227}
{"Episode reward": -95.59546578004374, "Episode length": 999, "Policy Loss": -0.21771590411663055, "Value Loss": 0.13452093303203583, "_runtime": 12158.449592113495, "_timestamp": 1585582074.2942255, "_step": 228}
{"Episode reward": 58.25138741927102, "Episode length": 457, "Policy Loss": 0.20946350693702698, "Value Loss": 21.297874450683594, "_runtime": 12159.477374315262, "_timestamp": 1585582075.3220077, "_step": 229}
{"Episode reward": 34.87777570152572, "Episode length": 677, "Policy Loss": 0.24976746737957, "Value Loss": 13.721961975097656, "_runtime": 12161.033738613129, "_timestamp": 1585582076.878372, "_step": 230}
{"Episode reward": -94.9672763420574, "Episode length": 999, "Policy Loss": -0.2979206144809723, "Value Loss": 0.6800714135169983, "_runtime": 12162.093354940414, "_timestamp": 1585582077.9379883, "_step": 231}
{"Episode reward": 34.74993984920769, "Episode length": 691, "Policy Loss": 0.11492562294006348, "Value Loss": 13.058866500854492, "_runtime": 12162.950214862823, "_timestamp": 1585582078.7948482, "_step": 232}
{"Episode reward": 46.351828399000944, "Episode length": 552, "Policy Loss": 0.45017513632774353, "Value Loss": 18.04364776611328, "_runtime": 12164.528101682663, "_timestamp": 1585582080.372735, "_step": 233}
{"Episode reward": -96.361046113528, "Episode length": 999, "Policy Loss": -0.15941576659679413, "Value Loss": 0.016300329938530922, "_runtime": 12166.063725233078, "_timestamp": 1585582081.9083586, "_step": 234}
{"Episode reward": -96.80840343984244, "Episode length": 999, "Policy Loss": -0.1956990659236908, "Value Loss": 0.018394073471426964, "_runtime": 12166.696458816528, "_timestamp": 1585582082.5410922, "_step": 235}
{"Episode reward": 64.73116621230389, "Episode length": 377, "Policy Loss": 0.231477752327919, "Value Loss": 23.99879264831543, "_runtime": 12168.302695989609, "_timestamp": 1585582084.1473293, "_step": 236}
{"Episode reward": -96.55905854892308, "Episode length": 999, "Policy Loss": -0.2503412067890167, "Value Loss": 0.03297095745801926, "_runtime": 12169.91624212265, "_timestamp": 1585582085.7608755, "_step": 237}
{"Episode reward": -96.09343584218946, "Episode length": 999, "Policy Loss": -0.2934326231479645, "Value Loss": 0.08984680473804474, "_runtime": 12170.737726449966, "_timestamp": 1585582086.5823598, "_step": 238}
{"Episode reward": 50.12988981078736, "Episode length": 529, "Policy Loss": 0.01668158918619156, "Value Loss": 18.623260498046875, "_runtime": 12172.09993672371, "_timestamp": 1585582087.94457, "_step": 239}
{"Episode reward": 18.171511935044634, "Episode length": 854, "Policy Loss": 0.00197103270329535, "Value Loss": 10.826112747192383, "_runtime": 12173.695797204971, "_timestamp": 1585582089.5404305, "_step": 240}
{"Episode reward": -95.91536848731074, "Episode length": 999, "Policy Loss": -0.3077736794948578, "Value Loss": 0.030901864171028137, "_runtime": 12174.365657806396, "_timestamp": 1585582090.2102911, "_step": 241}
{"Episode reward": 61.34381687676723, "Episode length": 417, "Policy Loss": 0.32253047823905945, "Value Loss": 22.243507385253906, "_runtime": 12176.001147985458, "_timestamp": 1585582091.8457813, "_step": 242}
{"Episode reward": -95.31145349886243, "Episode length": 999, "Policy Loss": -0.30611473321914673, "Value Loss": 0.020432433113455772, "_runtime": 12177.520441293716, "_timestamp": 1585582093.3650746, "_step": 243}
{"Episode reward": 11.875004538027795, "Episode length": 924, "Policy Loss": -0.010901887901127338, "Value Loss": 10.185422897338867, "_runtime": 12179.101136684418, "_timestamp": 1585582094.94577, "_step": 244}
{"Episode reward": -95.81478122513414, "Episode length": 999, "Policy Loss": -0.3300030827522278, "Value Loss": 0.01973240077495575, "_runtime": 12180.775959730148, "_timestamp": 1585582096.620593, "_step": 245}
{"Episode reward": -95.0825558254584, "Episode length": 999, "Policy Loss": -0.32053035497665405, "Value Loss": 0.07647062093019485, "_runtime": 12181.912627696991, "_timestamp": 1585582097.757261, "_step": 246}
{"Episode reward": 35.655218096314684, "Episode length": 674, "Policy Loss": 0.08784656226634979, "Value Loss": 14.215343475341797, "_runtime": 12183.326089143753, "_timestamp": 1585582099.1707225, "_step": 247}
{"Episode reward": 17.657561748103078, "Episode length": 880, "Policy Loss": 0.01964954100549221, "Value Loss": 10.09922981262207, "_runtime": 12184.928384304047, "_timestamp": 1585582100.7730176, "_step": 248}
{"Episode reward": -96.18292892055933, "Episode length": 999, "Policy Loss": -0.315051406621933, "Value Loss": 0.025617538020014763, "_runtime": 12186.493369579315, "_timestamp": 1585582102.338003, "_step": 249}
{"Episode reward": -94.91276707651924, "Episode length": 999, "Policy Loss": -0.31906917691230774, "Value Loss": 0.0282822847366333, "_runtime": 12186.878873825073, "_timestamp": 1585582102.7235072, "_step": 250}
{"Episode reward": 80.29777946565265, "Episode length": 213, "Policy Loss": 1.3146878480911255, "Value Loss": 46.074485778808594, "_runtime": 12188.449605226517, "_timestamp": 1585582104.2942386, "_step": 251}
{"Episode reward": -95.86125062188289, "Episode length": 999, "Policy Loss": -0.33005034923553467, "Value Loss": 0.05145023763179779, "_runtime": 12190.036347866058, "_timestamp": 1585582105.8809812, "_step": 252}
{"Episode reward": -95.36673615813295, "Episode length": 999, "Policy Loss": -0.36957618594169617, "Value Loss": 0.05751218646764755, "_runtime": 12190.629758834839, "_timestamp": 1585582106.4743922, "_step": 253}
{"Episode reward": 63.546433652223776, "Episode length": 387, "Policy Loss": 0.11312778294086456, "Value Loss": 24.71505355834961, "_runtime": 12192.235695123672, "_timestamp": 1585582108.0803285, "_step": 254}
{"Episode reward": -96.98519013883858, "Episode length": 999, "Policy Loss": -0.387999951839447, "Value Loss": 0.040734075009822845, "_runtime": 12192.714911937714, "_timestamp": 1585582108.5595453, "_step": 255}
{"Episode reward": 74.38234493118111, "Episode length": 274, "Policy Loss": 1.4919894933700562, "Value Loss": 32.60210037231445, "_runtime": 12193.414602518082, "_timestamp": 1585582109.2592359, "_step": 256}
{"Episode reward": 56.90674145387505, "Episode length": 459, "Policy Loss": -0.3930084705352783, "Value Loss": 20.02559471130371, "_runtime": 12194.306881904602, "_timestamp": 1585582110.1515152, "_step": 257}
{"Episode reward": 47.81498589472732, "Episode length": 551, "Policy Loss": 0.018370363861322403, "Value Loss": 15.803766250610352, "_runtime": 12195.824027061462, "_timestamp": 1585582111.6686604, "_step": 258}
{"Episode reward": -96.43151776500494, "Episode length": 999, "Policy Loss": -0.3817141652107239, "Value Loss": 0.01389254443347454, "_runtime": 12196.547453403473, "_timestamp": 1585582112.3920867, "_step": 259}
{"Episode reward": 57.09137146129826, "Episode length": 456, "Policy Loss": -0.048766374588012695, "Value Loss": 19.603557586669922, "_runtime": 12197.169142723083, "_timestamp": 1585582113.013776, "_step": 260}
{"Episode reward": 65.21770585209057, "Episode length": 368, "Policy Loss": 0.10167410224676132, "Value Loss": 24.096803665161133, "_runtime": 12198.804926633835, "_timestamp": 1585582114.64956, "_step": 261}
{"Episode reward": -97.11966182122602, "Episode length": 999, "Policy Loss": -0.3667865991592407, "Value Loss": 0.02508130483329296, "_runtime": 12200.408044099808, "_timestamp": 1585582116.2526774, "_step": 262}
{"Episode reward": -94.91924722448533, "Episode length": 999, "Policy Loss": -0.44015172123908997, "Value Loss": 0.12962952256202698, "_runtime": 12200.986438035965, "_timestamp": 1585582116.8310714, "_step": 263}
{"Episode reward": 67.04799198704396, "Episode length": 359, "Policy Loss": 0.24002878367900848, "Value Loss": 25.83291244506836, "_runtime": 12202.6011800766, "_timestamp": 1585582118.4458134, "_step": 264}
{"Episode reward": -95.93673123526096, "Episode length": 999, "Policy Loss": -0.37190937995910645, "Value Loss": 0.03941698372364044, "_runtime": 12204.222309112549, "_timestamp": 1585582120.0669425, "_step": 265}
{"Episode reward": -95.39033401561831, "Episode length": 999, "Policy Loss": -0.3494293987751007, "Value Loss": 0.019036568701267242, "_runtime": 12205.762066602707, "_timestamp": 1585582121.6067, "_step": 266}
{"Episode reward": -97.13856331461446, "Episode length": 999, "Policy Loss": -0.38257044553756714, "Value Loss": 0.012444034218788147, "_runtime": 12207.325375080109, "_timestamp": 1585582123.1700084, "_step": 267}
{"Episode reward": -96.39945119302679, "Episode length": 999, "Policy Loss": -0.38281407952308655, "Value Loss": 0.04048231244087219, "_runtime": 12208.417468309402, "_timestamp": 1585582124.2621017, "_step": 268}
{"Episode reward": 34.59748591419593, "Episode length": 689, "Policy Loss": -0.2622990608215332, "Value Loss": 13.228970527648926, "_runtime": 12209.979650497437, "_timestamp": 1585582125.8242838, "_step": 269}
{"Episode reward": -93.9923101116747, "Episode length": 999, "Policy Loss": -0.33957648277282715, "Value Loss": 0.03531590849161148, "_runtime": 12211.013260126114, "_timestamp": 1585582126.8578935, "_step": 270}
{"Episode reward": 41.27798522235806, "Episode length": 639, "Policy Loss": -0.07162114977836609, "Value Loss": 14.055500984191895, "_runtime": 12211.66364645958, "_timestamp": 1585582127.5082798, "_step": 271}
{"Episode reward": 64.79741962469306, "Episode length": 376, "Policy Loss": 0.8449538946151733, "Value Loss": 23.215456008911133, "_runtime": 12213.222224473953, "_timestamp": 1585582129.0668578, "_step": 272}
{"Episode reward": -97.2896285189859, "Episode length": 999, "Policy Loss": -0.2843892574310303, "Value Loss": 0.008424054831266403, "_runtime": 12214.386062383652, "_timestamp": 1585582130.2306957, "_step": 273}
{"Episode reward": 29.357299390428878, "Episode length": 745, "Policy Loss": -0.05425725877285004, "Value Loss": 12.365126609802246, "_runtime": 12215.937477588654, "_timestamp": 1585582131.782111, "_step": 274}
{"Episode reward": -94.7561361454471, "Episode length": 999, "Policy Loss": -0.3011387586593628, "Value Loss": 0.21187745034694672, "_runtime": 12217.180979967117, "_timestamp": 1585582133.0256133, "_step": 275}
{"Episode reward": 25.871760184861486, "Episode length": 785, "Policy Loss": -0.13794736564159393, "Value Loss": 11.076874732971191, "_runtime": 12218.547131061554, "_timestamp": 1585582134.3917644, "_step": 276}
{"Episode reward": 16.515037892343926, "Episode length": 887, "Policy Loss": 0.05021185055375099, "Value Loss": 10.072175025939941, "_runtime": 12219.603616952896, "_timestamp": 1585582135.4482503, "_step": 277}
{"Episode reward": 36.449637869047066, "Episode length": 671, "Policy Loss": 0.08273253589868546, "Value Loss": 14.442458152770996, "_runtime": 12221.154084205627, "_timestamp": 1585582136.9987175, "_step": 278}
{"Episode reward": -95.60982774425239, "Episode length": 999, "Policy Loss": -0.2042611837387085, "Value Loss": 0.024008464068174362, "_runtime": 12222.256749391556, "_timestamp": 1585582138.1013827, "_step": 279}
{"Episode reward": 34.56405200097491, "Episode length": 696, "Policy Loss": 0.10009617358446121, "Value Loss": 12.353240966796875, "_runtime": 12222.85007739067, "_timestamp": 1585582138.6947107, "_step": 280}
{"Episode reward": 65.02483100555644, "Episode length": 369, "Policy Loss": 0.32297515869140625, "Value Loss": 25.109792709350586, "_runtime": 12223.320548534393, "_timestamp": 1585582139.1651819, "_step": 281}
{"Episode reward": 74.46874759654162, "Episode length": 283, "Policy Loss": 0.6554601192474365, "Value Loss": 33.003273010253906, "_runtime": 12224.03701543808, "_timestamp": 1585582139.8816488, "_step": 282}
{"Episode reward": 57.29583325979534, "Episode length": 460, "Policy Loss": 0.1255526840686798, "Value Loss": 19.618396759033203, "_runtime": 12225.567172050476, "_timestamp": 1585582141.4118054, "_step": 283}
{"Episode reward": -95.21224843161897, "Episode length": 999, "Policy Loss": -0.19058960676193237, "Value Loss": 0.007966765202581882, "_runtime": 12226.415797948837, "_timestamp": 1585582142.2604313, "_step": 284}
{"Episode reward": 44.98318894214926, "Episode length": 564, "Policy Loss": -0.011947209015488625, "Value Loss": 15.541592597961426, "_runtime": 12227.926812648773, "_timestamp": 1585582143.771446, "_step": 285}
{"Episode reward": -95.7646032835512, "Episode length": 999, "Policy Loss": -0.20291480422019958, "Value Loss": 0.024916892871260643, "_runtime": 12228.798865556717, "_timestamp": 1585582144.643499, "_step": 286}
{"Episode reward": 48.988256263321226, "Episode length": 543, "Policy Loss": 0.26821741461753845, "Value Loss": 16.908681869506836, "_runtime": 12229.710078001022, "_timestamp": 1585582145.5547113, "_step": 287}
{"Episode reward": 43.65445302201681, "Episode length": 596, "Policy Loss": 0.1259790062904358, "Value Loss": 14.398855209350586, "_runtime": 12230.564231157303, "_timestamp": 1585582146.4088645, "_step": 288}
{"Episode reward": 49.047481729708835, "Episode length": 542, "Policy Loss": 0.18152035772800446, "Value Loss": 17.51256561279297, "_runtime": 12231.505769252777, "_timestamp": 1585582147.3504026, "_step": 289}
{"Episode reward": 43.89664979543338, "Episode length": 609, "Policy Loss": 0.20667803287506104, "Value Loss": 14.37366771697998, "_runtime": 12232.350103139877, "_timestamp": 1585582148.1947365, "_step": 290}
{"Episode reward": 48.57070104355216, "Episode length": 535, "Policy Loss": -0.05602502450346947, "Value Loss": 15.69775676727295, "_runtime": 12233.972219705582, "_timestamp": 1585582149.816853, "_step": 291}
{"Episode reward": -94.87711277955178, "Episode length": 999, "Policy Loss": -0.2428167164325714, "Value Loss": 0.043242279440164566, "_runtime": 12235.065520048141, "_timestamp": 1585582150.9101534, "_step": 292}
{"Episode reward": 34.125850383129176, "Episode length": 703, "Policy Loss": 0.10078676789999008, "Value Loss": 12.488658905029297, "_runtime": 12236.502923250198, "_timestamp": 1585582152.3475566, "_step": 293}
{"Episode reward": 12.05480960909162, "Episode length": 938, "Policy Loss": -0.007621585391461849, "Value Loss": 9.480960845947266, "_runtime": 12237.301301240921, "_timestamp": 1585582153.1459346, "_step": 294}
{"Episode reward": 53.20130926061379, "Episode length": 492, "Policy Loss": 0.133317232131958, "Value Loss": 19.477447509765625, "_runtime": 12238.8657848835, "_timestamp": 1585582154.7104182, "_step": 295}
{"Episode reward": -94.48219532460372, "Episode length": 999, "Policy Loss": -0.32128986716270447, "Value Loss": 0.09703731536865234, "_runtime": 12239.75201177597, "_timestamp": 1585582155.596645, "_step": 296}
{"Episode reward": 49.12682507418437, "Episode length": 551, "Policy Loss": 0.09646353125572205, "Value Loss": 16.293161392211914, "_runtime": 12240.60485124588, "_timestamp": 1585582156.4494846, "_step": 297}
{"Episode reward": 48.52882057321832, "Episode length": 547, "Policy Loss": 0.16850610077381134, "Value Loss": 15.9774751663208, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516, -17.748355865478516]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-144.9397735595703, -141.11790466308594, -137.29605102539062, -133.47418212890625, -129.65232849121094, -125.83045959472656, -122.00859832763672, -118.18673706054688, -114.36487579345703, -110.54301452636719, -106.72114562988281, -102.8992919921875, -99.07742309570312, -95.25556182861328, -91.43370056152344, -87.61183166503906, -83.78997802734375, -79.96810913085938, -76.14624786376953, -72.32438659667969, -68.50252532958984, -64.6806640625, -60.858802795410156, -57.03693389892578, -53.21507263183594, -49.393211364746094, -45.57135009765625, -41.749488830566406, -37.92762756347656, -34.10575866699219, -30.283897399902344, -26.4620361328125, -22.640174865722656, -18.818313598632812, -14.996444702148438, -11.174591064453125, -7.35272216796875, -3.5308685302734375, 0.2910003662109375, 4.1128692626953125, 7.934722900390625, 11.756591796875, 15.578445434570312, 19.400314331054688, 23.22216796875, 27.044036865234375, 30.86590576171875, 34.68775939941406, 38.50962829589844, 42.33148193359375, 46.153350830078125, 49.97520446777344, 53.79707336425781, 57.61894226074219, 61.4407958984375, 65.26266479492188, 69.08451843261719, 72.90638732910156, 76.72825622558594, 80.55010986328125, 84.37197875976562, 88.19383239746094, 92.01570129394531, 95.83755493164062, 99.659423828125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-10.574411392211914, -10.036407470703125, -9.498403549194336, -8.960400581359863, -8.422396659851074, -7.884392738342285, -7.346389293670654, -6.808385848999023, -6.270381927490234, -5.732378005981445, -5.1943745613098145, -4.656371116638184, -4.1183671951293945, -3.5803632736206055, -3.0423598289489746, -2.5043563842773438, -1.9663524627685547, -1.4283485412597656, -0.8903446197509766, -0.3523416519165039, 0.18566226959228516, 0.7236661911010742, 1.2616691589355469, 1.799673080444336, 2.337677001953125, 2.875680923461914, 3.413684844970703, 3.951687812805176, 4.489691734313965, 5.027695655822754, 5.565698623657227, 6.103702545166016, 6.641706466674805, 7.179710388183594, 7.717714309692383, 8.255718231201172, 8.793722152709961, 9.331724166870117, 9.869728088378906, 10.407732009887695, 10.945735931396484, 11.483739852905273, 12.021743774414062, 12.559747695922852, 13.097749710083008, 13.635753631591797, 14.173757553100586, 14.711761474609375, 15.249765396118164, 15.787769317626953, 16.325773239135742, 16.86377716064453, 17.40178108215332, 17.939783096313477, 18.477787017822266, 19.015790939331055, 19.553794860839844, 20.091798782348633, 20.629802703857422, 21.16780662536621, 21.705808639526367, 22.24381446838379, 22.781816482543945, 23.319822311401367, 23.857824325561523]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 5.0, 2.0, 11.0, 10.0, 14.0, 9.0, 7.0, 14.0, 21.0, 20.0, 20.0, 38.0, 43.0, 33.0, 48.0, 32.0, 22.0, 14.0, 11.0, 13.0, 10.0, 16.0, 11.0, 13.0, 11.0, 7.0, 8.0, 6.0, 9.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-18.015178680419922, -17.34535789489746, -16.675535202026367, -16.005714416503906, -15.335891723632812, -14.666069984436035, -13.996248245239258, -13.326427459716797, -12.656604766845703, -11.986783981323242, -11.316961288452148, -10.647140502929688, -9.97731876373291, -9.307497024536133, -8.637675285339355, -7.967853546142578, -7.298031806945801, -6.628210067749023, -5.958388328552246, -5.288566589355469, -4.618744850158691, -3.948923110961914, -3.2791013717651367, -2.6092796325683594, -1.9394588470458984, -1.2696361541748047, -0.5998153686523438, 0.07000732421875, 0.7398281097412109, 1.4096508026123047, 2.0794715881347656, 2.7492942810058594, 3.4191150665283203, 4.088935852050781, 4.758758544921875, 5.428579330444336, 6.09840202331543, 6.768222808837891, 7.438045501708984, 8.107866287231445, 8.777688980102539, 9.447509765625, 10.117332458496094, 10.787153244018555, 11.456975936889648, 12.12679672241211, 12.796619415283203, 13.466440200805664, 14.136260986328125, 14.806083679199219, 15.475906372070312, 16.14572525024414, 16.815547943115234, 17.485370635986328, 18.155193328857422, 18.82501220703125, 19.494834899902344, 20.164657592773438, 20.83448028564453, 21.50429916381836, 22.174121856689453, 22.843944549560547, 23.51376724243164, 24.18358612060547, 24.853408813476562]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-44.5657958984375, -43.17100524902344, -41.776214599609375, -40.38142395019531, -38.98663330078125, -37.59184265136719, -36.197052001953125, -34.80226135253906, -33.407470703125, -32.01268005371094, -30.617889404296875, -29.223098754882812, -27.82830810546875, -26.433517456054688, -25.038726806640625, -23.643936157226562, -22.2491455078125, -20.854354858398438, -19.459564208984375, -18.064773559570312, -16.66998291015625, -15.275192260742188, -13.880401611328125, -12.485610961914062, -11.0908203125, -9.696029663085938, -8.301239013671875, -6.9064483642578125, -5.51165771484375, -4.1168670654296875, -2.722076416015625, -1.3272857666015625, 0.0675048828125, 1.4622955322265625, 2.857086181640625, 4.2518768310546875, 5.64666748046875, 7.0414581298828125, 8.436248779296875, 9.831039428710938, 11.225830078125, 12.620620727539062, 14.015411376953125, 15.410202026367188, 16.80499267578125, 18.199783325195312, 19.594573974609375, 20.989364624023438, 22.3841552734375, 23.778945922851562, 25.173736572265625, 26.568527221679688, 27.96331787109375, 29.358108520507812, 30.752899169921875, 32.14768981933594, 33.54248046875, 34.93727111816406, 36.332061767578125, 37.72685241699219, 39.12164306640625, 40.51643371582031, 41.911224365234375, 43.30601501464844, 44.7008056640625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0], "bins": [-109.23175048828125, -106.34700775146484, -103.46227264404297, -100.57752990722656, -97.69279479980469, -94.80805206298828, -91.92330932617188, -89.03857421875, -86.15383911132812, -83.26909637451172, -80.38435363769531, -77.49961853027344, -74.61487579345703, -71.73013305664062, -68.84539794921875, -65.96066284179688, -63.07592010498047, -60.19118118286133, -57.30644226074219, -54.42170333862305, -51.536964416503906, -48.6522216796875, -45.76748275756836, -42.88274383544922, -39.99800109863281, -37.11326599121094, -34.22852325439453, -31.343788146972656, -28.45904541015625, -25.574310302734375, -22.68956756591797, -19.804832458496094, -16.920089721679688, -14.035346984863281, -11.150611877441406, -8.265869140625, -5.381134033203125, -2.4963912963867188, 0.38834381103515625, 3.2730865478515625, 6.1578216552734375, 9.042564392089844, 11.92730712890625, 14.812042236328125, 17.69678497314453, 20.581527709960938, 23.466262817382812, 26.350997924804688, 29.235748291015625, 32.1204833984375, 35.005218505859375, 37.88995361328125, 40.77470397949219, 43.65943908691406, 46.54417419433594, 49.42890930175781, 52.31365966796875, 55.198394775390625, 58.0831298828125, 60.96788024902344, 63.85261535644531, 66.73735046386719, 69.62208557128906, 72.5068359375, 75.39157104492188]}, "_runtime": 12241.454149723053, "_timestamp": 1585582157.298783, "_step": 298}
{"Episode reward": 53.080715686560104, "Episode length": 503, "Policy Loss": -0.04540267586708069, "Value Loss": 16.985021591186523, "_runtime": 12242.660665273666, "_timestamp": 1585582158.5052986, "_step": 299}
{"Episode reward": 26.33111019162638, "Episode length": 786, "Policy Loss": -0.13821688294410706, "Value Loss": 12.605743408203125, "_runtime": 12244.083118200302, "_timestamp": 1585582159.9277515, "_step": 300}
{"Episode reward": 12.785729541696227, "Episode length": 925, "Policy Loss": 0.018597932532429695, "Value Loss": 9.789900779724121, "_runtime": 12245.429568052292, "_timestamp": 1585582161.2742014, "_step": 301}
{"Episode reward": 16.00593175075042, "Episode length": 877, "Policy Loss": -0.000460608396679163, "Value Loss": 9.768343925476074, "_runtime": 12246.521428823471, "_timestamp": 1585582162.3660622, "_step": 302}
{"Episode reward": 34.325797634545424, "Episode length": 693, "Policy Loss": -0.16914121806621552, "Value Loss": 13.948437690734863, "_runtime": 12247.72680926323, "_timestamp": 1585582163.5714426, "_step": 303}
{"Episode reward": 27.25696867396499, "Episode length": 768, "Policy Loss": -0.1435546725988388, "Value Loss": 11.333789825439453, "_runtime": 12249.28476023674, "_timestamp": 1585582165.1293936, "_step": 304}
{"Episode reward": -96.96896631709511, "Episode length": 999, "Policy Loss": -0.39716389775276184, "Value Loss": 0.013476841151714325, "_runtime": 12250.837002754211, "_timestamp": 1585582166.681636, "_step": 305}
{"Episode reward": -94.59532255276315, "Episode length": 999, "Policy Loss": -0.4418008029460907, "Value Loss": 0.09950468689203262, "_runtime": 12252.091495513916, "_timestamp": 1585582167.9361289, "_step": 306}
{"Episode reward": 24.680528940638737, "Episode length": 801, "Policy Loss": 0.21452543139457703, "Value Loss": 10.915616989135742, "_runtime": 12253.661952018738, "_timestamp": 1585582169.5065854, "_step": 307}
{"Episode reward": -97.09453803359264, "Episode length": 999, "Policy Loss": -0.4014005661010742, "Value Loss": 0.01982205919921398, "_runtime": 12254.91392827034, "_timestamp": 1585582170.7585616, "_step": 308}
{"Episode reward": 25.38182229445239, "Episode length": 784, "Policy Loss": -0.09741516411304474, "Value Loss": 10.809886932373047, "_runtime": 12256.479346036911, "_timestamp": 1585582172.3239794, "_step": 309}
{"Episode reward": -94.79754319130626, "Episode length": 999, "Policy Loss": -0.42581498622894287, "Value Loss": 0.3459720313549042, "_runtime": 12258.057653903961, "_timestamp": 1585582173.9022872, "_step": 310}
{"Episode reward": -95.83879366898894, "Episode length": 999, "Policy Loss": -0.362705796957016, "Value Loss": 0.022642774507403374, "_runtime": 12258.78494644165, "_timestamp": 1585582174.6295798, "_step": 311}
{"Episode reward": 58.34785277540804, "Episode length": 451, "Policy Loss": 0.1452033817768097, "Value Loss": 20.37023162841797, "_runtime": 12260.017949104309, "_timestamp": 1585582175.8625824, "_step": 312}
{"Episode reward": 29.386580619385413, "Episode length": 773, "Policy Loss": 0.08023375272750854, "Value Loss": 12.225785255432129, "_runtime": 12261.5944378376, "_timestamp": 1585582177.4390712, "_step": 313}
{"Episode reward": -96.34658922296704, "Episode length": 999, "Policy Loss": -0.3531521260738373, "Value Loss": 0.025261079892516136, "_runtime": 12263.128145456314, "_timestamp": 1585582178.9727788, "_step": 314}
{"Episode reward": -94.67022207625777, "Episode length": 999, "Policy Loss": -0.38082972168922424, "Value Loss": 0.1198195144534111, "_runtime": 12264.323712348938, "_timestamp": 1585582180.1683457, "_step": 315}
{"Episode reward": 28.71862408014583, "Episode length": 756, "Policy Loss": 0.027294235303997993, "Value Loss": 12.08138370513916, "_runtime": 12265.68102478981, "_timestamp": 1585582181.5256581, "_step": 316}
{"Episode reward": 20.611624575058016, "Episode length": 831, "Policy Loss": -0.03361775726079941, "Value Loss": 11.489313125610352, "_runtime": 12267.257182359695, "_timestamp": 1585582183.1018157, "_step": 317}
{"Episode reward": -96.1276340256859, "Episode length": 999, "Policy Loss": -0.3268796503543854, "Value Loss": 0.014514829032123089, "_runtime": 12268.835602521896, "_timestamp": 1585582184.6802359, "_step": 318}
{"Episode reward": -95.95510291992771, "Episode length": 999, "Policy Loss": -0.3320380747318268, "Value Loss": 0.018612772226333618, "_runtime": 12269.81552863121, "_timestamp": 1585582185.660162, "_step": 319}
{"Episode reward": 41.473005891070244, "Episode length": 613, "Policy Loss": 0.06456171721220016, "Value Loss": 14.201691627502441, "_runtime": 12271.130364179611, "_timestamp": 1585582186.9749975, "_step": 320}
{"Episode reward": 21.919990253678904, "Episode length": 830, "Policy Loss": -0.017857521772384644, "Value Loss": 9.993104934692383, "_runtime": 12271.625413894653, "_timestamp": 1585582187.4700472, "_step": 321}
{"Episode reward": 72.49348706657537, "Episode length": 286, "Policy Loss": 0.5860662460327148, "Value Loss": 31.989517211914062, "_runtime": 12272.087180137634, "_timestamp": 1585582187.9318135, "_step": 322}
{"Episode reward": 73.74939157902082, "Episode length": 284, "Policy Loss": 0.5040004253387451, "Value Loss": 30.602149963378906, "_runtime": 12273.426974534988, "_timestamp": 1585582189.2716079, "_step": 323}
{"Episode reward": 17.220714290555094, "Episode length": 862, "Policy Loss": -0.09601568430662155, "Value Loss": 10.002176284790039, "_runtime": 12274.56890821457, "_timestamp": 1585582190.4135416, "_step": 324}
{"Episode reward": 30.087826889422104, "Episode length": 748, "Policy Loss": -0.007626355160027742, "Value Loss": 11.241853713989258, "_runtime": 12276.083825826645, "_timestamp": 1585582191.9284592, "_step": 325}
{"Episode reward": -95.92768467140213, "Episode length": 999, "Policy Loss": -0.29790517687797546, "Value Loss": 0.015056468546390533, "_runtime": 12277.666495800018, "_timestamp": 1585582193.5111291, "_step": 326}
{"Episode reward": -96.76821912633191, "Episode length": 999, "Policy Loss": -0.2935180366039276, "Value Loss": 0.011358717456459999, "_runtime": 12278.833912849426, "_timestamp": 1585582194.6785462, "_step": 327}
{"Episode reward": 28.730163755944204, "Episode length": 751, "Policy Loss": 0.08335213363170624, "Value Loss": 10.932273864746094, "_runtime": 12280.386832237244, "_timestamp": 1585582196.2314656, "_step": 328}
{"Episode reward": -96.74503185407866, "Episode length": 999, "Policy Loss": -0.28756406903266907, "Value Loss": 0.009707444347441196, "_runtime": 12281.989371538162, "_timestamp": 1585582197.8340049, "_step": 329}
{"Episode reward": -96.299547758825, "Episode length": 999, "Policy Loss": -0.28170648217201233, "Value Loss": 0.008672088384628296, "_runtime": 12283.547175645828, "_timestamp": 1585582199.391809, "_step": 330}
{"Episode reward": -97.50182943722683, "Episode length": 999, "Policy Loss": -0.2934117019176483, "Value Loss": 0.015586442314088345, "_runtime": 12284.771926164627, "_timestamp": 1585582200.6165595, "_step": 331}
{"Episode reward": 27.858544804406108, "Episode length": 770, "Policy Loss": 0.07074166089296341, "Value Loss": 10.714812278747559, "_runtime": 12286.359253644943, "_timestamp": 1585582202.203887, "_step": 332}
{"Episode reward": -95.53743010733325, "Episode length": 999, "Policy Loss": -0.3491467833518982, "Value Loss": 0.14724580943584442, "_runtime": 12287.936080694199, "_timestamp": 1585582203.780714, "_step": 333}
{"Episode reward": -94.98422870101089, "Episode length": 999, "Policy Loss": -0.3122459352016449, "Value Loss": 0.3053218126296997, "_runtime": 12289.360815763474, "_timestamp": 1585582205.205449, "_step": 334}
{"Episode reward": 17.815320770758234, "Episode length": 885, "Policy Loss": 0.018119586631655693, "Value Loss": 10.653358459472656, "_runtime": 12289.86312031746, "_timestamp": 1585582205.7077537, "_step": 335}
{"Episode reward": 73.3179500177879, "Episode length": 288, "Policy Loss": 0.9828934073448181, "Value Loss": 30.005727767944336, "_runtime": 12291.437618732452, "_timestamp": 1585582207.282252, "_step": 336}
{"Episode reward": -96.57715205222004, "Episode length": 999, "Policy Loss": -0.2567623257637024, "Value Loss": 0.008064967580139637, "_runtime": 12292.646360635757, "_timestamp": 1585582208.490994, "_step": 337}
{"Episode reward": 28.36884077481548, "Episode length": 765, "Policy Loss": 0.17694726586341858, "Value Loss": 11.558432579040527, "_runtime": 12294.16189289093, "_timestamp": 1585582210.0065262, "_step": 338}
{"Episode reward": -97.51096493014607, "Episode length": 999, "Policy Loss": -0.255082368850708, "Value Loss": 0.0076013654470443726, "_runtime": 12295.74584722519, "_timestamp": 1585582211.5904806, "_step": 339}
{"Episode reward": -94.68722880654957, "Episode length": 999, "Policy Loss": -0.2714916467666626, "Value Loss": 0.05447268486022949, "_runtime": 12297.309881448746, "_timestamp": 1585582213.1545148, "_step": 340}
{"Episode reward": -96.89255170714134, "Episode length": 999, "Policy Loss": -0.2406112104654312, "Value Loss": 0.014700861647725105, "_runtime": 12298.530712127686, "_timestamp": 1585582214.3753455, "_step": 341}
{"Episode reward": 26.710261630130844, "Episode length": 774, "Policy Loss": 0.08013210445642471, "Value Loss": 11.53403091430664, "_runtime": 12299.654426813126, "_timestamp": 1585582215.4990602, "_step": 342}
{"Episode reward": 33.8833946102544, "Episode length": 695, "Policy Loss": 0.0008375071920454502, "Value Loss": 12.693228721618652, "_runtime": 12301.222316503525, "_timestamp": 1585582217.0669498, "_step": 343}
{"Episode reward": -95.66558555339482, "Episode length": 999, "Policy Loss": -0.24851474165916443, "Value Loss": 0.047466255724430084, "_runtime": 12302.780406475067, "_timestamp": 1585582218.6250398, "_step": 344}
{"Episode reward": -95.72645539413594, "Episode length": 999, "Policy Loss": -0.20769724249839783, "Value Loss": 0.01026640459895134, "_runtime": 12304.345844745636, "_timestamp": 1585582220.190478, "_step": 345}
{"Episode reward": -96.00541381631338, "Episode length": 999, "Policy Loss": -0.21284504234790802, "Value Loss": 0.025113901123404503, "_runtime": 12305.671944856644, "_timestamp": 1585582221.5165782, "_step": 346}
{"Episode reward": 19.600116900794447, "Episode length": 835, "Policy Loss": 0.03737323358654976, "Value Loss": 9.942991256713867, "_runtime": 12306.916309833527, "_timestamp": 1585582222.7609432, "_step": 347}
{"Episode reward": 26.917054779933466, "Episode length": 785, "Policy Loss": 0.1479407548904419, "Value Loss": 11.472134590148926, "_runtime": 12307.779618740082, "_timestamp": 1585582223.624252, "_step": 348}
{"Episode reward": 50.28140050786181, "Episode length": 529, "Policy Loss": 0.3128737509250641, "Value Loss": 16.894317626953125, "_runtime": 12308.91183590889, "_timestamp": 1585582224.7564692, "_step": 349}
{"Episode reward": 33.09188523721305, "Episode length": 713, "Policy Loss": 0.18530523777008057, "Value Loss": 12.596282958984375, "_runtime": 12310.477923631668, "_timestamp": 1585582226.322557, "_step": 350}
{"Episode reward": -96.40509384147371, "Episode length": 999, "Policy Loss": -0.21380765736103058, "Value Loss": 0.037998612970113754, "_runtime": 12312.06194806099, "_timestamp": 1585582227.9065814, "_step": 351}
{"Episode reward": -96.50162340211595, "Episode length": 999, "Policy Loss": -0.20157091319561005, "Value Loss": 0.013083014637231827, "_runtime": 12313.535604476929, "_timestamp": 1585582229.3802378, "_step": 352}
{"Episode reward": 11.970716873659228, "Episode length": 939, "Policy Loss": 0.11734223365783691, "Value Loss": 9.166816711425781, "_runtime": 12315.120596885681, "_timestamp": 1585582230.9652302, "_step": 353}
{"Episode reward": -96.03962594146313, "Episode length": 999, "Policy Loss": -0.19404277205467224, "Value Loss": 0.007755033206194639, "_runtime": 12316.485418319702, "_timestamp": 1585582232.3300517, "_step": 354}
{"Episode reward": 18.94706293727468, "Episode length": 863, "Policy Loss": 0.21413905918598175, "Value Loss": 9.862262725830078, "_runtime": 12317.601656913757, "_timestamp": 1585582233.4462903, "_step": 355}
{"Episode reward": 35.27861136046839, "Episode length": 700, "Policy Loss": 0.14212018251419067, "Value Loss": 13.263623237609863, "_runtime": 12319.249324560165, "_timestamp": 1585582235.093958, "_step": 356}
{"Episode reward": -96.31364977744644, "Episode length": 999, "Policy Loss": -0.19281448423862457, "Value Loss": 0.004642784129828215, "_runtime": 12320.835351467133, "_timestamp": 1585582236.6799848, "_step": 357}
{"Episode reward": -95.45709471144892, "Episode length": 999, "Policy Loss": -0.20372411608695984, "Value Loss": 0.027059830725193024, "_runtime": 12322.404802322388, "_timestamp": 1585582238.2494357, "_step": 358}
{"Episode reward": 5.899438265955311, "Episode length": 990, "Policy Loss": -0.004233238752931356, "Value Loss": 9.943769454956055, "_runtime": 12323.646123170853, "_timestamp": 1585582239.4907565, "_step": 359}
{"Episode reward": 28.950692451392896, "Episode length": 766, "Policy Loss": 0.07732284069061279, "Value Loss": 11.70321273803711, "_runtime": 12324.282971858978, "_timestamp": 1585582240.1276052, "_step": 360}
{"Episode reward": 65.32899891174895, "Episode length": 373, "Policy Loss": 0.29776591062545776, "Value Loss": 24.373424530029297, "_runtime": 12325.881961584091, "_timestamp": 1585582241.726595, "_step": 361}
{"Episode reward": -94.93676092449785, "Episode length": 999, "Policy Loss": -0.25118541717529297, "Value Loss": 0.08585719019174576, "_runtime": 12326.382872343063, "_timestamp": 1585582242.2275057, "_step": 362}
{"Episode reward": 72.53621510197857, "Episode length": 290, "Policy Loss": 0.471057653427124, "Value Loss": 28.456939697265625, "_runtime": 12327.916147470474, "_timestamp": 1585582243.7607808, "_step": 363}
{"Episode reward": -96.3001484931903, "Episode length": 999, "Policy Loss": -0.2547704577445984, "Value Loss": 0.00715290755033493, "_runtime": 12329.515466928482, "_timestamp": 1585582245.3601003, "_step": 364}
{"Episode reward": -95.90591146916164, "Episode length": 999, "Policy Loss": -0.26578933000564575, "Value Loss": 0.009571019560098648, "_runtime": 12330.427104711533, "_timestamp": 1585582246.271738, "_step": 365}
{"Episode reward": 43.09356678285931, "Episode length": 599, "Policy Loss": 0.2200983464717865, "Value Loss": 14.584677696228027, "_runtime": 12332.005853652954, "_timestamp": 1585582247.850487, "_step": 366}
{"Episode reward": -96.97101316601864, "Episode length": 999, "Policy Loss": -0.31727924942970276, "Value Loss": 0.023524625226855278, "_runtime": 12332.889753103256, "_timestamp": 1585582248.7343864, "_step": 367}
{"Episode reward": 50.275390161655956, "Episode length": 524, "Policy Loss": 0.2012980878353119, "Value Loss": 15.480779647827148, "_runtime": 12333.582470178604, "_timestamp": 1585582249.4271035, "_step": 368}
{"Episode reward": 58.05251492375088, "Episode length": 441, "Policy Loss": 0.07572095096111298, "Value Loss": 18.458993911743164, "_runtime": 12334.734654903412, "_timestamp": 1585582250.5792882, "_step": 369}
{"Episode reward": 30.567555314875335, "Episode length": 730, "Policy Loss": -0.23834849894046783, "Value Loss": 11.1946439743042, "_runtime": 12335.206935405731, "_timestamp": 1585582251.0515687, "_step": 370}
{"Episode reward": 73.72796535477758, "Episode length": 289, "Policy Loss": 0.4436550438404083, "Value Loss": 30.10174560546875, "_runtime": 12336.766848802567, "_timestamp": 1585582252.6114821, "_step": 371}
{"Episode reward": -95.37199147425201, "Episode length": 999, "Policy Loss": -0.5842005014419556, "Value Loss": 1.3253554105758667, "_runtime": 12338.324969291687, "_timestamp": 1585582254.1696026, "_step": 372}
{"Episode reward": -96.38378273514773, "Episode length": 999, "Policy Loss": -0.36283838748931885, "Value Loss": 0.023636674508452415, "_runtime": 12339.837972640991, "_timestamp": 1585582255.682606, "_step": 373}
{"Episode reward": -95.93429777093469, "Episode length": 999, "Policy Loss": -0.3749425411224365, "Value Loss": 0.028019238263368607, "_runtime": 12340.826163053513, "_timestamp": 1585582256.6707964, "_step": 374}
{"Episode reward": 42.918354956467866, "Episode length": 608, "Policy Loss": 0.09122645109891891, "Value Loss": 16.142053604125977, "_runtime": 12342.219438791275, "_timestamp": 1585582258.0640721, "_step": 375}
{"Episode reward": 16.475278816769773, "Episode length": 879, "Policy Loss": -0.01811545342206955, "Value Loss": 9.935128211975098, "_runtime": 12343.109126091003, "_timestamp": 1585582258.9537594, "_step": 376}
{"Episode reward": 46.262885891189185, "Episode length": 565, "Policy Loss": 0.1433434933423996, "Value Loss": 15.225896835327148, "_runtime": 12343.611785411835, "_timestamp": 1585582259.4564188, "_step": 377}
{"Episode reward": 72.58006665790481, "Episode length": 307, "Policy Loss": 0.40348517894744873, "Value Loss": 30.32154083251953, "_runtime": 12344.899689435959, "_timestamp": 1585582260.7443228, "_step": 378}
{"Episode reward": 22.334026657254242, "Episode length": 824, "Policy Loss": -0.14298392832279205, "Value Loss": 10.133208274841309, "_runtime": 12346.127203941345, "_timestamp": 1585582261.9718373, "_step": 379}
{"Episode reward": 23.163818522047137, "Episode length": 806, "Policy Loss": -0.12663261592388153, "Value Loss": 10.430367469787598, "_runtime": 12347.62924361229, "_timestamp": 1585582263.473877, "_step": 380}
{"Episode reward": -95.88719629611711, "Episode length": 999, "Policy Loss": -0.34720638394355774, "Value Loss": 0.02786414511501789, "_runtime": 12349.201837778091, "_timestamp": 1585582265.046471, "_step": 381}
{"Episode reward": -96.25263019090478, "Episode length": 999, "Policy Loss": -0.4076359272003174, "Value Loss": 0.10341694205999374, "_runtime": 12349.683491945267, "_timestamp": 1585582265.5281253, "_step": 382}
{"Episode reward": 72.44475744353011, "Episode length": 290, "Policy Loss": 0.5370080471038818, "Value Loss": 27.4881649017334, "_runtime": 12350.612826824188, "_timestamp": 1585582266.4574602, "_step": 383}
{"Episode reward": 44.466471747419945, "Episode length": 598, "Policy Loss": -0.20407553017139435, "Value Loss": 13.860983848571777, "_runtime": 12352.185767650604, "_timestamp": 1585582268.030401, "_step": 384}
{"Episode reward": -96.23488574390916, "Episode length": 999, "Policy Loss": -0.42358267307281494, "Value Loss": 0.02054465375840664, "_runtime": 12353.546235322952, "_timestamp": 1585582269.3908687, "_step": 385}
{"Episode reward": 14.089707364322805, "Episode length": 905, "Policy Loss": -0.18475866317749023, "Value Loss": 9.59048080444336, "_runtime": 12355.087295532227, "_timestamp": 1585582270.9319289, "_step": 386}
{"Episode reward": -96.65419850357158, "Episode length": 999, "Policy Loss": -0.4501407742500305, "Value Loss": 0.08778168261051178, "_runtime": 12356.674114704132, "_timestamp": 1585582272.518748, "_step": 387}
{"Episode reward": -96.53199525177514, "Episode length": 999, "Policy Loss": -0.4797368049621582, "Value Loss": 0.033648278564214706, "_runtime": 12358.270586252213, "_timestamp": 1585582274.1152196, "_step": 388}
{"Episode reward": -96.49320159647596, "Episode length": 999, "Policy Loss": -0.496576189994812, "Value Loss": 0.038866426795721054, "_runtime": 12359.890454053879, "_timestamp": 1585582275.7350874, "_step": 389}
{"Episode reward": -96.08215969017073, "Episode length": 999, "Policy Loss": -0.4914636015892029, "Value Loss": 0.09489251673221588, "_runtime": 12361.497170686722, "_timestamp": 1585582277.341804, "_step": 390}
{"Episode reward": -97.25666511092153, "Episode length": 999, "Policy Loss": -0.47391510009765625, "Value Loss": 0.04207071289420128, "_runtime": 12362.310538053513, "_timestamp": 1585582278.1551714, "_step": 391}
{"Episode reward": 54.32574191171602, "Episode length": 497, "Policy Loss": 0.21017611026763916, "Value Loss": 17.757558822631836, "_runtime": 12363.88553738594, "_timestamp": 1585582279.7301707, "_step": 392}
{"Episode reward": -95.41794987674332, "Episode length": 999, "Policy Loss": -0.40913262963294983, "Value Loss": 0.07252504676580429, "_runtime": 12365.034499645233, "_timestamp": 1585582280.879133, "_step": 393}
{"Episode reward": 32.37178487580307, "Episode length": 705, "Policy Loss": 0.18029440939426422, "Value Loss": 11.46176815032959, "_runtime": 12366.578399419785, "_timestamp": 1585582282.4230328, "_step": 394}
{"Episode reward": -93.64421423321954, "Episode length": 999, "Policy Loss": -0.3930855691432953, "Value Loss": 0.47619709372520447, "_runtime": 12368.197091341019, "_timestamp": 1585582284.0417247, "_step": 395}
{"Episode reward": -94.90484927935265, "Episode length": 999, "Policy Loss": -0.2776505947113037, "Value Loss": 0.05409776046872139, "_runtime": 12369.810710430145, "_timestamp": 1585582285.6553438, "_step": 396}
{"Episode reward": -94.87694026797466, "Episode length": 999, "Policy Loss": -0.2348068654537201, "Value Loss": 0.06452242285013199, "_runtime": 12371.47397518158, "_timestamp": 1585582287.3186085, "_step": 397}
{"Episode reward": -96.48447842739927, "Episode length": 999, "Policy Loss": -0.17650984227657318, "Value Loss": 0.031226150691509247, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375, -295.6214599609375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 9.0], "bins": [-2010.352783203125, -1974.4012451171875, -1938.44970703125, -1902.498046875, -1866.5465087890625, -1830.594970703125, -1794.6434326171875, -1758.69189453125, -1722.7403564453125, -1686.788818359375, -1650.837158203125, -1614.8856201171875, -1578.93408203125, -1542.9825439453125, -1507.031005859375, -1471.079345703125, -1435.1279296875, -1399.17626953125, -1363.2247314453125, -1327.273193359375, -1291.3216552734375, -1255.3701171875, -1219.41845703125, -1183.467041015625, -1147.515380859375, -1111.5638427734375, -1075.6123046875, -1039.6607666015625, -1003.7091674804688, -967.757568359375, -931.8060302734375, -895.8544921875, -859.9029541015625, -823.951416015625, -787.9998779296875, -752.04833984375, -716.0966796875, -680.1451416015625, -644.193603515625, -608.2420654296875, -572.29052734375, -536.3389892578125, -500.3873291015625, -464.435791015625, -428.4842529296875, -392.53271484375, -356.5811767578125, -320.629638671875, -284.677978515625, -248.7264404296875, -212.77490234375, -176.8233642578125, -140.871826171875, -104.9202880859375, -68.96875, -33.01708984375, 2.9344482421875, 38.885986328125, 74.837646484375, 110.7890625, 146.74072265625, 182.692138671875, 218.643798828125, 254.59521484375, 290.546875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.214015007019043, -2.7238943576812744, 0.7662262916564941, 4.256346702575684, 7.746467590332031, 11.236588478088379, 14.72670841217041, 18.21683120727539, 21.706951141357422, 25.197071075439453, 28.687191009521484, 32.177310943603516, 35.66743087768555, 39.15755081176758, 42.647674560546875, 46.137794494628906, 49.62791442871094, 53.11803436279297, 56.608154296875, 60.0982780456543, 63.58839797973633, 67.07852172851562, 70.56864166259766, 74.05876159667969, 77.54888153076172, 81.03900146484375, 84.52912139892578, 88.01924896240234, 91.50936889648438, 94.9994888305664, 98.48960876464844, 101.97972869873047, 105.4698486328125, 108.95996856689453, 112.45008850097656, 115.9402084350586, 119.43032836914062, 122.92044830322266, 126.41057586669922, 129.9006805419922, 133.39080810546875, 136.88092041015625, 140.3710479736328, 143.86117553710938, 147.35128784179688, 150.84141540527344, 154.33152770996094, 157.8216552734375, 161.311767578125, 164.80189514160156, 168.29200744628906, 171.78213500976562, 175.27224731445312, 178.7623748779297, 182.25250244140625, 185.74261474609375, 189.2327423095703, 192.7228546142578, 196.21298217773438, 199.70309448242188, 203.19322204589844, 206.68333435058594, 210.1734619140625, 213.66357421875, 217.15370178222656]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 4.0, 1.0, 7.0, 12.0, 113.0, 307.0, 13.0, 7.0, 6.0, 5.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-170.74020385742188, -163.9761505126953, -157.21209716796875, -150.4480438232422, -143.68399047851562, -136.91993713378906, -130.1558837890625, -123.39183044433594, -116.62777709960938, -109.86372375488281, -103.09966278076172, -96.33560943603516, -89.5715560913086, -82.80750274658203, -76.04344940185547, -69.2793960571289, -62.515342712402344, -55.75128936767578, -48.98723602294922, -42.223175048828125, -35.45912170410156, -28.695068359375, -21.931015014648438, -15.166961669921875, -8.402908325195312, -1.63885498046875, 5.1251983642578125, 11.889251708984375, 18.653305053710938, 25.4173583984375, 32.18141174316406, 38.945465087890625, 45.70951843261719, 52.47357177734375, 59.23762512207031, 66.00167846679688, 72.76573181152344, 79.52978515625, 86.29385375976562, 93.05789184570312, 99.82196044921875, 106.58599853515625, 113.35006713867188, 120.11410522460938, 126.878173828125, 133.6422119140625, 140.40628051757812, 147.17031860351562, 153.93438720703125, 160.69842529296875, 167.46249389648438, 174.22653198242188, 180.9906005859375, 187.754638671875, 194.51870727539062, 201.28274536132812, 208.04681396484375, 214.81085205078125, 221.57492065429688, 228.33895874023438, 235.10302734375, 241.8670654296875, 248.63113403320312, 255.39517211914062, 262.15924072265625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-326.9955139160156, -317.310302734375, -307.6251220703125, -297.93994140625, -288.2547302246094, -278.56951904296875, -268.88433837890625, -259.19915771484375, -249.51394653320312, -239.82875061035156, -230.1435546875, -220.45835876464844, -210.77316284179688, -201.0879669189453, -191.40277099609375, -181.7175750732422, -172.03237915039062, -162.34718322753906, -152.6619873046875, -142.97679138183594, -133.29159545898438, -123.60639953613281, -113.92120361328125, -104.23600769042969, -94.55081176757812, -84.86561584472656, -75.180419921875, -65.49520874023438, -55.810028076171875, -46.124847412109375, -36.43963623046875, -26.754425048828125, -17.069244384765625, -7.384063720703125, 2.3011474609375, 11.986358642578125, 21.671539306640625, 31.356719970703125, 41.04193115234375, 50.727142333984375, 60.412322998046875, 70.09750366210938, 79.78271484375, 89.46792602539062, 99.15310668945312, 108.83828735351562, 118.52349853515625, 128.20870971679688, 137.89389038085938, 147.57907104492188, 157.2642822265625, 166.94949340820312, 176.63467407226562, 186.31985473632812, 196.00509643554688, 205.69027709960938, 215.37545776367188, 225.06063842773438, 234.74581909179688, 244.43106079101562, 254.11624145507812, 263.8014221191406, 273.4866638183594, 283.1718444824219, 292.8570251464844]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 6.0, 2.0, 7.0, 6.0, 8.0, 2.0, 6.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-428.92626953125, -415.92254638671875, -402.9188232421875, -389.91510009765625, -376.911376953125, -363.90765380859375, -350.9039306640625, -337.90020751953125, -324.896484375, -311.89276123046875, -298.8890380859375, -285.88531494140625, -272.8815612792969, -259.8778381347656, -246.87411499023438, -233.87039184570312, -220.86666870117188, -207.86294555664062, -194.85922241210938, -181.85549926757812, -168.85177612304688, -155.84805297851562, -142.84432983398438, -129.84060668945312, -116.83685302734375, -103.8331298828125, -90.82940673828125, -77.82568359375, -64.82196044921875, -51.8182373046875, -38.81451416015625, -25.810791015625, -12.80706787109375, 0.1966552734375, 13.20037841796875, 26.2041015625, 39.20782470703125, 52.2115478515625, 65.21527099609375, 78.218994140625, 91.22271728515625, 104.2264404296875, 117.23016357421875, 130.23388671875, 143.23760986328125, 156.2413330078125, 169.24505615234375, 182.248779296875, 195.2525634765625, 208.25628662109375, 221.260009765625, 234.26373291015625, 247.2674560546875, 260.27117919921875, 273.27490234375, 286.27862548828125, 299.2823486328125, 312.28607177734375, 325.289794921875, 338.29351806640625, 351.2972412109375, 364.30096435546875, 377.3046875, 390.30841064453125, 403.3121337890625]}, "_runtime": 12372.386039733887, "_timestamp": 1585582288.230673, "_step": 398}
{"Episode reward": 50.4041541342996, "Episode length": 530, "Policy Loss": -0.2323562204837799, "Value Loss": 17.983312606811523, "_runtime": 12374.0669901371, "_timestamp": 1585582289.9116235, "_step": 399}
{"Episode reward": -97.23845752167358, "Episode length": 999, "Policy Loss": -0.13535094261169434, "Value Loss": 0.06693186610937119, "_runtime": 12375.237190961838, "_timestamp": 1585582291.0818243, "_step": 400}
{"Episode reward": 34.20284354834793, "Episode length": 701, "Policy Loss": 0.08870908617973328, "Value Loss": 11.51569652557373, "_runtime": 12376.554826498032, "_timestamp": 1585582292.3994598, "_step": 401}
{"Episode reward": 18.455626772956464, "Episode length": 857, "Policy Loss": 0.09818445891141891, "Value Loss": 10.03572940826416, "_runtime": 12378.147476911545, "_timestamp": 1585582293.9921103, "_step": 402}
{"Episode reward": -95.57091418931526, "Episode length": 999, "Policy Loss": -0.11944851279258728, "Value Loss": 0.018196118995547295, "_runtime": 12379.752247810364, "_timestamp": 1585582295.5968812, "_step": 403}
{"Episode reward": -92.8374029431317, "Episode length": 999, "Policy Loss": -0.07440488040447235, "Value Loss": 0.04081767052412033, "_runtime": 12380.133781909943, "_timestamp": 1585582295.9784153, "_step": 404}
{"Episode reward": 80.81480850546308, "Episode length": 200, "Policy Loss": 1.4329191446304321, "Value Loss": 45.665077209472656, "_runtime": 12381.406649112701, "_timestamp": 1585582297.2512825, "_step": 405}
{"Episode reward": 28.150480572811716, "Episode length": 748, "Policy Loss": 0.20688779652118683, "Value Loss": 10.371758460998535, "_runtime": 12383.004110574722, "_timestamp": 1585582298.848744, "_step": 406}
{"Episode reward": -95.00571083197602, "Episode length": 999, "Policy Loss": -0.1066163182258606, "Value Loss": 0.02380329556763172, "_runtime": 12384.267685890198, "_timestamp": 1585582300.1123192, "_step": 407}
{"Episode reward": 23.011909612756853, "Episode length": 806, "Policy Loss": 0.2428828477859497, "Value Loss": 10.782598495483398, "_runtime": 12385.871310949326, "_timestamp": 1585582301.7159443, "_step": 408}
{"Episode reward": -95.89567812894681, "Episode length": 999, "Policy Loss": -0.12094461172819138, "Value Loss": 0.018834084272384644, "_runtime": 12387.355679273605, "_timestamp": 1585582303.2003126, "_step": 409}
{"Episode reward": 12.210885359029419, "Episode length": 927, "Policy Loss": 0.048250745981931686, "Value Loss": 8.948238372802734, "_runtime": 12388.903460502625, "_timestamp": 1585582304.7480938, "_step": 410}
{"Episode reward": -94.9785391158344, "Episode length": 999, "Policy Loss": -0.10530565679073334, "Value Loss": 0.030712122097611427, "_runtime": 12389.51484656334, "_timestamp": 1585582305.35948, "_step": 411}
{"Episode reward": 66.54302590567389, "Episode length": 363, "Policy Loss": 0.20617638528347015, "Value Loss": 23.36385726928711, "_runtime": 12391.090098619461, "_timestamp": 1585582306.934732, "_step": 412}
{"Episode reward": -96.7101377118372, "Episode length": 999, "Policy Loss": -0.15608377754688263, "Value Loss": 0.013479683548212051, "_runtime": 12392.433125019073, "_timestamp": 1585582308.2777584, "_step": 413}
{"Episode reward": 18.992222803479507, "Episode length": 862, "Policy Loss": 0.04669516906142235, "Value Loss": 9.972332000732422, "_runtime": 12393.94555926323, "_timestamp": 1585582309.7901926, "_step": 414}
{"Episode reward": -95.11095808285395, "Episode length": 999, "Policy Loss": -0.2032812386751175, "Value Loss": 0.028951849788427353, "_runtime": 12394.925924539566, "_timestamp": 1585582310.7705579, "_step": 415}
{"Episode reward": 42.110711120346984, "Episode length": 607, "Policy Loss": 0.2440602332353592, "Value Loss": 13.449069023132324, "_runtime": 12396.482004880905, "_timestamp": 1585582312.3266382, "_step": 416}
{"Episode reward": -96.38514950266017, "Episode length": 999, "Policy Loss": -0.23275834321975708, "Value Loss": 0.024949396029114723, "_runtime": 12398.04308462143, "_timestamp": 1585582313.887718, "_step": 417}
{"Episode reward": -95.26920729519112, "Episode length": 999, "Policy Loss": -0.14427420496940613, "Value Loss": 0.0711921900510788, "_runtime": 12398.771212816238, "_timestamp": 1585582314.6158462, "_step": 418}
{"Episode reward": 58.22970033417218, "Episode length": 458, "Policy Loss": 0.38411128520965576, "Value Loss": 17.78134536743164, "_runtime": 12399.639636516571, "_timestamp": 1585582315.4842699, "_step": 419}
{"Episode reward": 50.412647562182755, "Episode length": 538, "Policy Loss": 0.06891433894634247, "Value Loss": 14.63316535949707, "_runtime": 12401.202033042908, "_timestamp": 1585582317.0466664, "_step": 420}
{"Episode reward": -96.99507276058081, "Episode length": 999, "Policy Loss": -0.2297872006893158, "Value Loss": 0.010057851672172546, "_runtime": 12402.7322306633, "_timestamp": 1585582318.576864, "_step": 421}
{"Episode reward": -96.2596005354417, "Episode length": 999, "Policy Loss": -0.20811474323272705, "Value Loss": 0.008409932255744934, "_runtime": 12404.264097213745, "_timestamp": 1585582320.1087306, "_step": 422}
{"Episode reward": -96.28257317441077, "Episode length": 999, "Policy Loss": -0.25178855657577515, "Value Loss": 0.056874047964811325, "_runtime": 12405.11769080162, "_timestamp": 1585582320.9623241, "_step": 423}
{"Episode reward": 50.436680492512785, "Episode length": 527, "Policy Loss": 0.058451876044273376, "Value Loss": 17.56787872314453, "_runtime": 12406.679881334305, "_timestamp": 1585582322.5245147, "_step": 424}
{"Episode reward": -96.79278685393317, "Episode length": 999, "Policy Loss": -0.222184419631958, "Value Loss": 0.009178286418318748, "_runtime": 12407.686452627182, "_timestamp": 1585582323.531086, "_step": 425}
{"Episode reward": 42.51989256647442, "Episode length": 610, "Policy Loss": 0.2501468360424042, "Value Loss": 13.866350173950195, "_runtime": 12409.224041700363, "_timestamp": 1585582325.068675, "_step": 426}
{"Episode reward": -94.81905932652731, "Episode length": 999, "Policy Loss": -0.25978022813796997, "Value Loss": 0.02791551873087883, "_runtime": 12410.805751085281, "_timestamp": 1585582326.6503844, "_step": 427}
{"Episode reward": -95.66244028961763, "Episode length": 999, "Policy Loss": -0.28973957896232605, "Value Loss": 0.03879036381840706, "_runtime": 12412.378302812576, "_timestamp": 1585582328.2229362, "_step": 428}
{"Episode reward": -93.16788889769242, "Episode length": 999, "Policy Loss": -0.27986055612564087, "Value Loss": 0.10954825580120087, "_runtime": 12413.01677107811, "_timestamp": 1585582328.8614044, "_step": 429}
{"Episode reward": 65.43723880537081, "Episode length": 388, "Policy Loss": 0.41270533204078674, "Value Loss": 23.597429275512695, "_runtime": 12414.584686040878, "_timestamp": 1585582330.4293194, "_step": 430}
{"Episode reward": -95.17061817629248, "Episode length": 999, "Policy Loss": -0.30812349915504456, "Value Loss": 0.025198671966791153, "_runtime": 12416.155644655228, "_timestamp": 1585582332.000278, "_step": 431}
{"Episode reward": -95.64379546943857, "Episode length": 999, "Policy Loss": -0.30872368812561035, "Value Loss": 0.05788274481892586, "_runtime": 12417.670411109924, "_timestamp": 1585582333.5150445, "_step": 432}
{"Episode reward": 4.985081798757761, "Episode length": 996, "Policy Loss": 0.07913767546415329, "Value Loss": 8.367474555969238, "_runtime": 12418.169217824936, "_timestamp": 1585582334.0138512, "_step": 433}
{"Episode reward": 73.1896078003413, "Episode length": 287, "Policy Loss": 0.4516465365886688, "Value Loss": 27.58004379272461, "_runtime": 12419.741434812546, "_timestamp": 1585582335.5860682, "_step": 434}
{"Episode reward": -95.51527281796403, "Episode length": 999, "Policy Loss": -0.29910001158714294, "Value Loss": 0.11083263903856277, "_runtime": 12421.307270288467, "_timestamp": 1585582337.1519036, "_step": 435}
{"Episode reward": -97.32442025576808, "Episode length": 999, "Policy Loss": -0.28253909945487976, "Value Loss": 0.0063029988668859005, "_runtime": 12422.816187143326, "_timestamp": 1585582338.6608205, "_step": 436}
{"Episode reward": -95.59039576790923, "Episode length": 999, "Policy Loss": -0.29029735922813416, "Value Loss": 0.037869181483983994, "_runtime": 12424.07953119278, "_timestamp": 1585582339.9241645, "_step": 437}
{"Episode reward": 25.05935001291543, "Episode length": 793, "Policy Loss": -0.31967252492904663, "Value Loss": 11.307916641235352, "_runtime": 12425.117605924606, "_timestamp": 1585582340.9622393, "_step": 438}
{"Episode reward": 38.85156884035809, "Episode length": 639, "Policy Loss": 0.10135391354560852, "Value Loss": 11.916955947875977, "_runtime": 12426.66342830658, "_timestamp": 1585582342.5080616, "_step": 439}
{"Episode reward": -96.45375506793812, "Episode length": 999, "Policy Loss": -0.2768141031265259, "Value Loss": 0.024616321548819542, "_runtime": 12428.095581293106, "_timestamp": 1585582343.9402146, "_step": 440}
{"Episode reward": 13.805188262514662, "Episode length": 913, "Policy Loss": -0.08693660795688629, "Value Loss": 9.85445785522461, "_runtime": 12429.635456323624, "_timestamp": 1585582345.4800897, "_step": 441}
{"Episode reward": -96.40377647491364, "Episode length": 999, "Policy Loss": -0.28235530853271484, "Value Loss": 0.02492750994861126, "_runtime": 12431.193063497543, "_timestamp": 1585582347.0376968, "_step": 442}
{"Episode reward": -94.57922299685107, "Episode length": 999, "Policy Loss": -0.27164965867996216, "Value Loss": 0.07446002960205078, "_runtime": 12432.377009868622, "_timestamp": 1585582348.2216432, "_step": 443}
{"Episode reward": 29.890389665780035, "Episode length": 747, "Policy Loss": -0.15829792618751526, "Value Loss": 10.981886863708496, "_runtime": 12433.226134061813, "_timestamp": 1585582349.0707674, "_step": 444}
{"Episode reward": 49.93515460779878, "Episode length": 528, "Policy Loss": 0.3142484426498413, "Value Loss": 15.245004653930664, "_runtime": 12434.075717449188, "_timestamp": 1585582349.9203508, "_step": 445}
{"Episode reward": 51.371669315583695, "Episode length": 533, "Policy Loss": 0.49440571665763855, "Value Loss": 17.33881950378418, "_runtime": 12434.572111845016, "_timestamp": 1585582350.4167452, "_step": 446}
{"Episode reward": 72.42418546098429, "Episode length": 296, "Policy Loss": 0.4777055084705353, "Value Loss": 30.942102432250977, "_runtime": 12435.46775841713, "_timestamp": 1585582351.3123918, "_step": 447}
{"Episode reward": 44.421374271578024, "Episode length": 583, "Policy Loss": 0.14057506620883942, "Value Loss": 13.334311485290527, "_runtime": 12436.553822040558, "_timestamp": 1585582352.3984554, "_step": 448}
{"Episode reward": 36.556713931080544, "Episode length": 682, "Policy Loss": 0.06362735480070114, "Value Loss": 13.281709671020508, "_runtime": 12437.64217877388, "_timestamp": 1585582353.486812, "_step": 449}
{"Episode reward": 33.03592655876557, "Episode length": 726, "Policy Loss": -0.1515485644340515, "Value Loss": 10.819633483886719, "_runtime": 12439.171572685242, "_timestamp": 1585582355.016206, "_step": 450}
{"Episode reward": -97.18481514981956, "Episode length": 999, "Policy Loss": -0.28720661997795105, "Value Loss": 0.0068760705180466175, "_runtime": 12440.703290939331, "_timestamp": 1585582356.5479243, "_step": 451}
{"Episode reward": -96.14549680585394, "Episode length": 999, "Policy Loss": -0.3030836582183838, "Value Loss": 0.027740707620978355, "_runtime": 12441.249124765396, "_timestamp": 1585582357.093758, "_step": 452}
{"Episode reward": 73.06535535229771, "Episode length": 295, "Policy Loss": 0.4505389630794525, "Value Loss": 28.962108612060547, "_runtime": 12442.854187011719, "_timestamp": 1585582358.6988204, "_step": 453}
{"Episode reward": -95.92252667245594, "Episode length": 999, "Policy Loss": -0.32741937041282654, "Value Loss": 0.03370312228798866, "_runtime": 12443.494133472443, "_timestamp": 1585582359.3387668, "_step": 454}
{"Episode reward": 63.31463500415491, "Episode length": 387, "Policy Loss": 0.26468583941459656, "Value Loss": 21.717008590698242, "_runtime": 12444.34930229187, "_timestamp": 1585582360.1939356, "_step": 455}
{"Episode reward": 47.98808277372028, "Episode length": 553, "Policy Loss": -0.12309091538190842, "Value Loss": 14.47363567352295, "_runtime": 12445.60207104683, "_timestamp": 1585582361.4467044, "_step": 456}
{"Episode reward": 27.72983587943409, "Episode length": 783, "Policy Loss": -0.07951623946428299, "Value Loss": 10.542267799377441, "_runtime": 12446.525373458862, "_timestamp": 1585582362.3700068, "_step": 457}
{"Episode reward": 43.1974551052734, "Episode length": 591, "Policy Loss": -0.08517524600028992, "Value Loss": 15.493152618408203, "_runtime": 12448.07396364212, "_timestamp": 1585582363.918597, "_step": 458}
{"Episode reward": -95.14011043335535, "Episode length": 999, "Policy Loss": -0.36468297243118286, "Value Loss": 0.041358400136232376, "_runtime": 12449.10873579979, "_timestamp": 1585582364.9533691, "_step": 459}
{"Episode reward": 40.185701949893044, "Episode length": 646, "Policy Loss": -0.16565732657909393, "Value Loss": 11.638501167297363, "_runtime": 12450.630838871002, "_timestamp": 1585582366.4754722, "_step": 460}
{"Episode reward": -96.56232266486438, "Episode length": 999, "Policy Loss": -0.39282068610191345, "Value Loss": 0.047997113317251205, "_runtime": 12451.714928865433, "_timestamp": 1585582367.5595622, "_step": 461}
{"Episode reward": 34.64785955421381, "Episode length": 685, "Policy Loss": -0.07355313003063202, "Value Loss": 12.575899124145508, "_runtime": 12452.775596141815, "_timestamp": 1585582368.6202295, "_step": 462}
{"Episode reward": 35.791713456116184, "Episode length": 678, "Policy Loss": -0.12212632596492767, "Value Loss": 13.438604354858398, "_runtime": 12453.737612009048, "_timestamp": 1585582369.5822453, "_step": 463}
{"Episode reward": 42.38327661229696, "Episode length": 607, "Policy Loss": -0.09282992780208588, "Value Loss": 15.289112091064453, "_runtime": 12455.28461098671, "_timestamp": 1585582371.1292443, "_step": 464}
{"Episode reward": -97.78721891307163, "Episode length": 999, "Policy Loss": -0.3700284957885742, "Value Loss": 0.011498467065393925, "_runtime": 12456.763115406036, "_timestamp": 1585582372.6077487, "_step": 465}
{"Episode reward": 9.20792905026319, "Episode length": 958, "Policy Loss": 0.22979295253753662, "Value Loss": 8.845949172973633, "_runtime": 12458.280886650085, "_timestamp": 1585582374.12552, "_step": 466}
{"Episode reward": -96.20792388389489, "Episode length": 999, "Policy Loss": -0.36808156967163086, "Value Loss": 0.014762131497263908, "_runtime": 12459.839916944504, "_timestamp": 1585582375.6845503, "_step": 467}
{"Episode reward": -96.51373007569653, "Episode length": 999, "Policy Loss": -0.38066667318344116, "Value Loss": 0.039506927132606506, "_runtime": 12461.458223819733, "_timestamp": 1585582377.3028572, "_step": 468}
{"Episode reward": -95.29428912814355, "Episode length": 999, "Policy Loss": -0.5607986450195312, "Value Loss": 0.733033299446106, "_runtime": 12461.957249641418, "_timestamp": 1585582377.801883, "_step": 469}
{"Episode reward": 73.64005577513528, "Episode length": 288, "Policy Loss": 0.14393146336078644, "Value Loss": 27.369863510131836, "_runtime": 12462.937778949738, "_timestamp": 1585582378.7824123, "_step": 470}
{"Episode reward": 40.6627828267084, "Episode length": 619, "Policy Loss": 0.3649604022502899, "Value Loss": 14.110199928283691, "_runtime": 12463.89361834526, "_timestamp": 1585582379.7382517, "_step": 471}
{"Episode reward": 43.31271737604705, "Episode length": 595, "Policy Loss": 0.027889033779501915, "Value Loss": 14.6318359375, "_runtime": 12465.423555135727, "_timestamp": 1585582381.2681885, "_step": 472}
{"Episode reward": -97.23094613049355, "Episode length": 999, "Policy Loss": -0.3779667913913727, "Value Loss": 0.03889968991279602, "_runtime": 12466.971452474594, "_timestamp": 1585582382.8160858, "_step": 473}
{"Episode reward": -96.11864444134066, "Episode length": 999, "Policy Loss": -0.3862968683242798, "Value Loss": 0.05407507345080376, "_runtime": 12468.520565032959, "_timestamp": 1585582384.3651984, "_step": 474}
{"Episode reward": -95.53195888646785, "Episode length": 999, "Policy Loss": -0.3904847800731659, "Value Loss": 0.06400378048419952, "_runtime": 12469.245062112808, "_timestamp": 1585582385.0896955, "_step": 475}
{"Episode reward": 58.55613603452928, "Episode length": 445, "Policy Loss": 0.37078288197517395, "Value Loss": 19.866107940673828, "_runtime": 12470.825091362, "_timestamp": 1585582386.6697247, "_step": 476}
{"Episode reward": -96.39505989350624, "Episode length": 999, "Policy Loss": -0.2987653315067291, "Value Loss": 0.01276829931885004, "_runtime": 12472.38939332962, "_timestamp": 1585582388.2340267, "_step": 477}
{"Episode reward": 6.127627892601637, "Episode length": 989, "Policy Loss": -0.1684170663356781, "Value Loss": 7.886812210083008, "_runtime": 12473.920859336853, "_timestamp": 1585582389.7654927, "_step": 478}
{"Episode reward": -96.90227419616232, "Episode length": 999, "Policy Loss": -0.27902084589004517, "Value Loss": 0.03148649260401726, "_runtime": 12474.670967817307, "_timestamp": 1585582390.5156012, "_step": 479}
{"Episode reward": 57.059981263496574, "Episode length": 455, "Policy Loss": 0.3016783893108368, "Value Loss": 17.88483428955078, "_runtime": 12476.262907743454, "_timestamp": 1585582392.107541, "_step": 480}
{"Episode reward": -94.63835084295161, "Episode length": 999, "Policy Loss": -0.2630542516708374, "Value Loss": 0.061557184904813766, "_runtime": 12477.842789173126, "_timestamp": 1585582393.6874225, "_step": 481}
{"Episode reward": -97.01646821096905, "Episode length": 999, "Policy Loss": -0.21434317529201508, "Value Loss": 0.010346065275371075, "_runtime": 12479.367966890335, "_timestamp": 1585582395.2126002, "_step": 482}
{"Episode reward": -96.36080785705937, "Episode length": 999, "Policy Loss": -0.21731431782245636, "Value Loss": 0.009663436561822891, "_runtime": 12480.960203886032, "_timestamp": 1585582396.8048372, "_step": 483}
{"Episode reward": -96.25473719177145, "Episode length": 999, "Policy Loss": -0.21765118837356567, "Value Loss": 0.02565053291618824, "_runtime": 12482.546594381332, "_timestamp": 1585582398.3912277, "_step": 484}
{"Episode reward": -95.58591009431849, "Episode length": 999, "Policy Loss": -0.19805169105529785, "Value Loss": 0.020576871931552887, "_runtime": 12484.11439538002, "_timestamp": 1585582399.9590287, "_step": 485}
{"Episode reward": -96.45616475231976, "Episode length": 999, "Policy Loss": -0.20158971846103668, "Value Loss": 0.027317097410559654, "_runtime": 12485.49592423439, "_timestamp": 1585582401.3405576, "_step": 486}
{"Episode reward": 20.805397694483034, "Episode length": 838, "Policy Loss": 0.022634293884038925, "Value Loss": 9.508148193359375, "_runtime": 12487.015650510788, "_timestamp": 1585582402.8602839, "_step": 487}
{"Episode reward": 8.778501392930963, "Episode length": 962, "Policy Loss": 0.025392044335603714, "Value Loss": 8.168885231018066, "_runtime": 12488.25249671936, "_timestamp": 1585582404.09713, "_step": 488}
{"Episode reward": 28.343007847674826, "Episode length": 777, "Policy Loss": 0.048785608261823654, "Value Loss": 11.658330917358398, "_runtime": 12489.831416845322, "_timestamp": 1585582405.6760502, "_step": 489}
{"Episode reward": -97.16759870623996, "Episode length": 999, "Policy Loss": -0.1809868961572647, "Value Loss": 0.010079407133162022, "_runtime": 12491.176654815674, "_timestamp": 1585582407.0212882, "_step": 490}
{"Episode reward": 20.614591372774257, "Episode length": 846, "Policy Loss": 0.1788388341665268, "Value Loss": 9.347465515136719, "_runtime": 12492.508438110352, "_timestamp": 1585582408.3530715, "_step": 491}
{"Episode reward": 20.80275406647131, "Episode length": 850, "Policy Loss": 0.26380157470703125, "Value Loss": 10.25343132019043, "_runtime": 12494.09194946289, "_timestamp": 1585582409.9365828, "_step": 492}
{"Episode reward": -95.43830945561626, "Episode length": 999, "Policy Loss": -0.2171989381313324, "Value Loss": 0.14697512984275818, "_runtime": 12495.664677143097, "_timestamp": 1585582411.5093105, "_step": 493}
{"Episode reward": -96.20448464341136, "Episode length": 999, "Policy Loss": -0.14026543498039246, "Value Loss": 0.042615704238414764, "_runtime": 12497.236082077026, "_timestamp": 1585582413.0807154, "_step": 494}
{"Episode reward": -96.26115460866582, "Episode length": 999, "Policy Loss": -0.138177290558815, "Value Loss": 0.013784956187009811, "_runtime": 12498.823297262192, "_timestamp": 1585582414.6679306, "_step": 495}
{"Episode reward": -95.39893555934802, "Episode length": 999, "Policy Loss": -0.13697828352451324, "Value Loss": 0.006035135127604008, "_runtime": 12500.314725160599, "_timestamp": 1585582416.1593585, "_step": 496}
{"Episode reward": 9.516476483307187, "Episode length": 941, "Policy Loss": -0.1436631679534912, "Value Loss": 9.15575885772705, "_runtime": 12501.442104101181, "_timestamp": 1585582417.2867374, "_step": 497}
{"Episode reward": 32.72975926296532, "Episode length": 707, "Policy Loss": 0.028918523341417313, "Value Loss": 11.332708358764648, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935, 0.07159822434186935]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3333107829093933, -0.3044634759426117, -0.2756161689758301, -0.24676884710788727, -0.21792154014110565, -0.18907423317432404, -0.16022691130638123, -0.1313796043395996, -0.102532297372818, -0.07368499040603638, -0.04483768343925476, -0.015990376472473145, 0.01285696029663086, 0.041704267263412476, 0.07055157423019409, 0.09939888119697571, 0.12824618816375732, 0.15709349513053894, 0.18594080209732056, 0.21478813886642456, 0.2436354160308838, 0.2724827527999878, 0.301330029964447, 0.330177366733551, 0.35902470350265503, 0.38787198066711426, 0.41671931743621826, 0.4455665946006775, 0.4744139313697815, 0.5032612085342407, 0.5321085453033447, 0.560955822467804, 0.589803159236908, 0.618650496006012, 0.6474977731704712, 0.6763450503349304, 0.7051923871040344, 0.7340397238731384, 0.7628870606422424, 0.7917342782020569, 0.8205816149711609, 0.8494289517402649, 0.8782762885093689, 0.9071236252784729, 0.9359708428382874, 0.9648181796073914, 0.9936655163764954, 1.0225129127502441, 1.0513601303100586, 1.080207347869873, 1.1090548038482666, 1.137902021408081, 1.1667494773864746, 1.195596694946289, 1.2244439125061035, 1.253291368484497, 1.2821385860443115, 1.310986042022705, 1.3398332595825195, 1.368680477142334, 1.3975279331207275, 1.426375150680542, 1.4552223682403564, 1.48406982421875, 1.5129170417785645]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.19971981644630432, -0.19409604370594025, -0.18847225606441498, -0.1828484833240509, -0.17722471058368683, -0.17160093784332275, -0.16597715020179749, -0.1603533774614334, -0.15472960472106934, -0.14910581707954407, -0.14348204433918, -0.13785827159881592, -0.13223448395729065, -0.12661071121692657, -0.1209869310259819, -0.11536315828561783, -0.10973937809467316, -0.10411559790372849, -0.09849182516336441, -0.09286804497241974, -0.08724427223205566, -0.08162049204111099, -0.07599671185016632, -0.07037293910980225, -0.06474915146827698, -0.0591253787279129, -0.05350160598754883, -0.04787783324718475, -0.042254045605659485, -0.03663027286529541, -0.031006500124931335, -0.025382712483406067, -0.019758939743041992, -0.014135167002677917, -0.008511379361152649, -0.0028876066207885742, 0.0027361661195755005, 0.008359953761100769, 0.013983726501464844, 0.01960749924182892, 0.025231271982192993, 0.03085505962371826, 0.036478832364082336, 0.04210260510444641, 0.04772639274597168, 0.05335018038749695, 0.05897393822669983, 0.0645977258682251, 0.07022151350975037, 0.07584527134895325, 0.08146905899047852, 0.0870928168296814, 0.09271660447120667, 0.09834039211273193, 0.10396414995193481, 0.10958793759346008, 0.11521172523498535, 0.12083548307418823, 0.1264592707157135, 0.13208305835723877, 0.13770681619644165, 0.14333060383796692, 0.1489543914794922, 0.15457814931869507, 0.16020193696022034]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 11.0, 13.0, 26.0, 19.0, 12.0, 27.0, 18.0, 10.0, 42.0, 92.0, 36.0, 21.0, 13.0, 15.0, 8.0, 6.0, 9.0, 6.0, 14.0, 11.0, 5.0, 9.0, 13.0, 7.0, 4.0, 9.0, 5.0, 2.0, 6.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.3314363956451416, -0.3224276900291443, -0.313418984413147, -0.30441027879714966, -0.29540157318115234, -0.2863928973674774, -0.2773841917514801, -0.2683754861354828, -0.2593667805194855, -0.25035807490348816, -0.24134936928749084, -0.23234067857265472, -0.2233319729566574, -0.2143232673406601, -0.20531457662582397, -0.19630587100982666, -0.18729716539382935, -0.17828845977783203, -0.16927975416183472, -0.1602710634469986, -0.15126235783100128, -0.14225365221500397, -0.13324496150016785, -0.12423625588417053, -0.11522755026817322, -0.1062188446521759, -0.09721013903617859, -0.08820144832134247, -0.07919275760650635, -0.07018405199050903, -0.06117534637451172, -0.052166640758514404, -0.04315793514251709, -0.034149229526519775, -0.02514052391052246, -0.016131818294525146, -0.007123112678527832, 0.0018855631351470947, 0.01089426875114441, 0.019902974367141724, 0.028911679983139038, 0.03792038559913635, 0.04692909121513367, 0.05593779683113098, 0.06494647264480591, 0.07395517826080322, 0.08296388387680054, 0.09197258949279785, 0.10098129510879517, 0.10999000072479248, 0.1189987063407898, 0.1280074119567871, 0.13701611757278442, 0.14602479338645935, 0.15503349900245667, 0.16404220461845398, 0.1730508804321289, 0.18205958604812622, 0.19106829166412354, 0.20007699728012085, 0.20908570289611816, 0.21809440851211548, 0.2271031141281128, 0.2361118197441101, 0.24512052536010742]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4248642027378082, -0.40928903222084045, -0.39371389150619507, -0.3781387209892273, -0.3625635504722595, -0.34698837995529175, -0.331413209438324, -0.3158380687236786, -0.3002628982067108, -0.28468772768974304, -0.26911258697509766, -0.2535374164581299, -0.2379622459411621, -0.22238707542419434, -0.20681191980838776, -0.19123676419258118, -0.1756615936756134, -0.16008642315864563, -0.14451125264167786, -0.12893611192703247, -0.1133609414100647, -0.09778577089309692, -0.08221063017845154, -0.06663545966148376, -0.05106028914451599, -0.03548511862754822, -0.019909948110580444, -0.004334807395935059, 0.011240363121032715, 0.02681553363800049, 0.042390674352645874, 0.05796584486961365, 0.07354101538658142, 0.0891161859035492, 0.10469135642051697, 0.12026652693748474, 0.13584169745445251, 0.1514168083667755, 0.1669919788837433, 0.18256714940071106, 0.19814231991767883, 0.2137174904346466, 0.22929266095161438, 0.24486783146858215, 0.26044294238090515, 0.2760181128978729, 0.2915932834148407, 0.30716845393180847, 0.32274362444877625, 0.338318794965744, 0.3538939654827118, 0.36946913599967957, 0.38504430651664734, 0.40061941742897034, 0.4161945879459381, 0.4317697584629059, 0.44734492897987366, 0.46292009949684143, 0.4784952700138092, 0.494070440530777, 0.5096455812454224, 0.5252207517623901, 0.5407959222793579, 0.5563710927963257, 0.5719462633132935]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.3357571065425873, -0.32511043548583984, -0.3144637644290924, -0.30381709337234497, -0.29317042231559753, -0.2825237512588501, -0.2718770503997803, -0.2612304091453552, -0.2505837082862854, -0.23993705213069916, -0.22929038107395172, -0.2186436951160431, -0.20799702405929565, -0.19735035300254822, -0.18670368194580078, -0.17605701088905334, -0.1654103398323059, -0.15476366877555847, -0.14411699771881104, -0.1334703266620636, -0.12282365560531616, -0.11217696964740753, -0.1015302985906601, -0.09088362753391266, -0.08023694157600403, -0.06959027051925659, -0.058943599462509155, -0.04829692840576172, -0.03765025734901428, -0.027003586292266846, -0.01635691523551941, -0.005710244178771973, 0.004936426877975464, 0.0155830979347229, 0.026229768991470337, 0.03687644004821777, 0.04752311110496521, 0.058169782161712646, 0.06881645321846008, 0.07946312427520752, 0.09010979533195496, 0.10075649619102478, 0.11140316724777222, 0.12204983830451965, 0.1326965093612671, 0.14334318041801453, 0.15398985147476196, 0.1646365225315094, 0.17528322339057922, 0.18592986464500427, 0.1965765655040741, 0.20722320675849915, 0.21786990761756897, 0.22851654887199402, 0.23916324973106384, 0.2498098909854889, 0.2604565918445587, 0.27110323309898376, 0.2817499339580536, 0.29239657521247864, 0.30304327607154846, 0.3136899173259735, 0.32433661818504333, 0.3349832594394684, 0.3456299602985382]}, "_runtime": 12503.024689674377, "_timestamp": 1585582418.869323, "_step": 498}
{"Episode reward": -96.79185819608497, "Episode length": 999, "Policy Loss": -0.12002217769622803, "Value Loss": 0.011407963931560516, "_runtime": 12503.024689674377, "_timestamp": 1585582418.869323, "_step": 499}
