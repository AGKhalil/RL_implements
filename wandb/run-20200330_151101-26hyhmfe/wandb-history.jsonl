{"Episode reward": -33.22674523547787, "Episode length": 999, "Policy Loss": -0.030360786244273186, "Value Loss": 0.003538705874234438, "_runtime": 11165.12056350708, "_timestamp": 1585581080.9651968, "_step": 0}
{"Episode reward": -95.94520513791079, "Episode length": 999, "Policy Loss": -0.004696115851402283, "Value Loss": 8.62039566040039, "_runtime": 11166.630920648575, "_timestamp": 1585581082.475554, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24132251739501953, "Value Loss": 35.57098388671875, "_runtime": 11168.25844502449, "_timestamp": 1585581084.1030784, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.691114902496338, "Value Loss": 2.7457528114318848, "_runtime": 11169.81106042862, "_timestamp": 1585581085.6556938, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.337768793106079, "Value Loss": 0.759091317653656, "_runtime": 11171.355287075043, "_timestamp": 1585581087.1999204, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.462812900543213, "Value Loss": 1.1086812019348145, "_runtime": 11172.93758559227, "_timestamp": 1585581088.782219, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.4928975105285645, "Value Loss": 4.675788879394531, "_runtime": 11173.16197681427, "_timestamp": 1585581089.0066102, "_step": 6}
{"Episode reward": 90.51083231409599, "Episode length": 98, "Policy Loss": 4.103085517883301, "Value Loss": 103.46831512451172, "_runtime": 11173.389262914658, "_timestamp": 1585581089.2338963, "_step": 7}
{"Episode reward": 88.89841024028792, "Episode length": 118, "Policy Loss": 4.914637565612793, "Value Loss": 78.19784545898438, "_runtime": 11173.926398277283, "_timestamp": 1585581089.7710316, "_step": 8}
{"Episode reward": 69.69018136772249, "Episode length": 321, "Policy Loss": -0.8128268718719482, "Value Loss": 30.471572875976562, "_runtime": 11175.443892240524, "_timestamp": 1585581091.2885256, "_step": 9}
{"Episode reward": -74.17652574581503, "Episode length": 999, "Policy Loss": -1.1730259656906128, "Value Loss": 2.7854185104370117, "_runtime": 11176.93655538559, "_timestamp": 1585581092.7811887, "_step": 10}
{"Episode reward": -86.5882224344584, "Episode length": 999, "Policy Loss": -1.552317500114441, "Value Loss": 0.48902449011802673, "_runtime": 11178.448665618896, "_timestamp": 1585581094.293299, "_step": 11}
{"Episode reward": -98.99954644322042, "Episode length": 999, "Policy Loss": -5.840466499328613, "Value Loss": 9.489181518554688, "_runtime": 11180.022629976273, "_timestamp": 1585581095.8672633, "_step": 12}
{"Episode reward": -97.91162914523312, "Episode length": 999, "Policy Loss": -2.0729260444641113, "Value Loss": 3.1865530014038086, "_runtime": 11181.49478816986, "_timestamp": 1585581097.3394215, "_step": 13}
{"Episode reward": 6.317068461310171, "Episode length": 944, "Policy Loss": -1.7765306234359741, "Value Loss": 11.921480178833008, "_runtime": 11182.445511579514, "_timestamp": 1585581098.290145, "_step": 14}
{"Episode reward": 41.09541112702042, "Episode length": 600, "Policy Loss": -2.7532899379730225, "Value Loss": 18.570938110351562, "_runtime": 11183.122410058975, "_timestamp": 1585581098.9670434, "_step": 15}
{"Episode reward": 59.44272798136911, "Episode length": 408, "Policy Loss": -2.016361951828003, "Value Loss": 22.949827194213867, "_runtime": 11184.316187620163, "_timestamp": 1585581100.160821, "_step": 16}
{"Episode reward": 23.953100979605793, "Episode length": 766, "Policy Loss": -1.1569839715957642, "Value Loss": 12.146162986755371, "_runtime": 11185.844815254211, "_timestamp": 1585581101.6894486, "_step": 17}
{"Episode reward": -99.5195453381938, "Episode length": 999, "Policy Loss": -1.1026960611343384, "Value Loss": 0.065268374979496, "_runtime": 11187.360398292542, "_timestamp": 1585581103.2050316, "_step": 18}
{"Episode reward": -99.70955616088911, "Episode length": 999, "Policy Loss": -0.29737627506256104, "Value Loss": 0.5533784627914429, "_runtime": 11188.237320899963, "_timestamp": 1585581104.0819542, "_step": 19}
{"Episode reward": 44.989469185005525, "Episode length": 551, "Policy Loss": 2.0803470611572266, "Value Loss": 18.841651916503906, "_runtime": 11189.340686798096, "_timestamp": 1585581105.1853201, "_step": 20}
{"Episode reward": 29.587860069673283, "Episode length": 705, "Policy Loss": 0.8723849058151245, "Value Loss": 16.89589500427246, "_runtime": 11190.339362382889, "_timestamp": 1585581106.1839957, "_step": 21}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": 0.9718497395515442, "Value Loss": 16.350486755371094, "_runtime": 11191.191606760025, "_timestamp": 1585581107.03624, "_step": 22}
{"Episode reward": 47.82521678588445, "Episode length": 523, "Policy Loss": 0.7469097375869751, "Value Loss": 18.797916412353516, "_runtime": 11192.394750833511, "_timestamp": 1585581108.2393842, "_step": 23}
{"Episode reward": 22.437825621336216, "Episode length": 778, "Policy Loss": -0.2147313952445984, "Value Loss": 12.882317543029785, "_runtime": 11192.95334649086, "_timestamp": 1585581108.7979798, "_step": 24}
{"Episode reward": 65.28833436840111, "Episode length": 348, "Policy Loss": 0.5404586791992188, "Value Loss": 28.68614959716797, "_runtime": 11194.425754070282, "_timestamp": 1585581110.2703874, "_step": 25}
{"Episode reward": 3.2015310415966525, "Episode length": 971, "Policy Loss": -1.2202670574188232, "Value Loss": 10.088590621948242, "_runtime": 11195.75525188446, "_timestamp": 1585581111.5998852, "_step": 26}
{"Episode reward": 13.343006747613558, "Episode length": 869, "Policy Loss": -2.5322909355163574, "Value Loss": 11.326167106628418, "_runtime": 11197.257369756699, "_timestamp": 1585581113.102003, "_step": 27}
{"Episode reward": -99.70300441582083, "Episode length": 999, "Policy Loss": -2.9305591583251953, "Value Loss": 0.479989230632782, "_runtime": 11197.751605033875, "_timestamp": 1585581113.5962384, "_step": 28}
{"Episode reward": 71.68218564742769, "Episode length": 285, "Policy Loss": -1.1545718908309937, "Value Loss": 33.11403274536133, "_runtime": 11199.307034015656, "_timestamp": 1585581115.1516674, "_step": 29}
{"Episode reward": -99.71724414266507, "Episode length": 999, "Policy Loss": -3.139646291732788, "Value Loss": 0.4315737187862396, "_runtime": 11200.870244026184, "_timestamp": 1585581116.7148774, "_step": 30}
{"Episode reward": -99.70324672926078, "Episode length": 999, "Policy Loss": -3.347878932952881, "Value Loss": 0.8225157856941223, "_runtime": 11202.377033233643, "_timestamp": 1585581118.2216666, "_step": 31}
{"Episode reward": -99.79223602488497, "Episode length": 999, "Policy Loss": -3.276824951171875, "Value Loss": 0.44437354803085327, "_runtime": 11203.953612565994, "_timestamp": 1585581119.798246, "_step": 32}
{"Episode reward": -99.55597407072972, "Episode length": 999, "Policy Loss": -2.3894569873809814, "Value Loss": 2.200059413909912, "_runtime": 11205.521652936935, "_timestamp": 1585581121.3662863, "_step": 33}
{"Episode reward": -99.84470796324173, "Episode length": 999, "Policy Loss": -2.9773268699645996, "Value Loss": 0.25009849667549133, "_runtime": 11206.136280536652, "_timestamp": 1585581121.9809139, "_step": 34}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": -0.9500330686569214, "Value Loss": 25.19872283935547, "_runtime": 11207.705353975296, "_timestamp": 1585581123.5499873, "_step": 35}
{"Episode reward": -99.81874217726151, "Episode length": 999, "Policy Loss": -2.6699090003967285, "Value Loss": 0.21695412695407867, "_runtime": 11208.443835496902, "_timestamp": 1585581124.2884688, "_step": 36}
{"Episode reward": 55.13377769934187, "Episode length": 450, "Policy Loss": -3.046217441558838, "Value Loss": 21.28854751586914, "_runtime": 11209.783648252487, "_timestamp": 1585581125.6282816, "_step": 37}
{"Episode reward": 12.060897107236812, "Episode length": 881, "Policy Loss": -1.8550095558166504, "Value Loss": 11.384613037109375, "_runtime": 11210.404867887497, "_timestamp": 1585581126.2495012, "_step": 38}
{"Episode reward": 62.98790240367862, "Episode length": 371, "Policy Loss": -0.8465020060539246, "Value Loss": 26.140167236328125, "_runtime": 11211.93694639206, "_timestamp": 1585581127.7815797, "_step": 39}
{"Episode reward": -99.84380655884603, "Episode length": 999, "Policy Loss": -1.6170454025268555, "Value Loss": 0.172323539853096, "_runtime": 11213.484640836716, "_timestamp": 1585581129.3292742, "_step": 40}
{"Episode reward": -99.88462562560895, "Episode length": 999, "Policy Loss": -1.2200675010681152, "Value Loss": 0.10091641545295715, "_runtime": 11214.497640609741, "_timestamp": 1585581130.342274, "_step": 41}
{"Episode reward": 33.06220330149725, "Episode length": 671, "Policy Loss": -0.03876074030995369, "Value Loss": 14.181795120239258, "_runtime": 11215.603037595749, "_timestamp": 1585581131.447671, "_step": 42}
{"Episode reward": 30.386719254875104, "Episode length": 697, "Policy Loss": 0.31782057881355286, "Value Loss": 13.930896759033203, "_runtime": 11216.248182296753, "_timestamp": 1585581132.0928156, "_step": 43}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 1.2112841606140137, "Value Loss": 24.63160514831543, "_runtime": 11216.704228401184, "_timestamp": 1585581132.5488617, "_step": 44}
{"Episode reward": 71.99999999999989, "Episode length": 280, "Policy Loss": 1.9260445833206177, "Value Loss": 34.250709533691406, "_runtime": 11218.286330461502, "_timestamp": 1585581134.1309638, "_step": 45}
{"Episode reward": -99.7110619836473, "Episode length": 999, "Policy Loss": -0.5522142052650452, "Value Loss": 0.09543508291244507, "_runtime": 11219.801505804062, "_timestamp": 1585581135.6461391, "_step": 46}
{"Episode reward": -99.63440877520944, "Episode length": 999, "Policy Loss": -0.9670526385307312, "Value Loss": 0.7341256141662598, "_runtime": 11221.32376074791, "_timestamp": 1585581137.168394, "_step": 47}
{"Episode reward": -99.808893384038, "Episode length": 999, "Policy Loss": -0.5418053269386292, "Value Loss": 0.03250725939869881, "_runtime": 11222.247893810272, "_timestamp": 1585581138.0925272, "_step": 48}
{"Episode reward": 44.486255904566335, "Episode length": 557, "Policy Loss": 0.4470953941345215, "Value Loss": 17.431564331054688, "_runtime": 11222.981459140778, "_timestamp": 1585581138.8260925, "_step": 49}
{"Episode reward": 55.76998419461271, "Episode length": 443, "Policy Loss": 1.1128941774368286, "Value Loss": 21.245956420898438, "_runtime": 11223.606602668762, "_timestamp": 1585581139.451236, "_step": 50}
{"Episode reward": 61.58966948837015, "Episode length": 385, "Policy Loss": 1.768991231918335, "Value Loss": 24.275487899780273, "_runtime": 11224.62120604515, "_timestamp": 1585581140.4658394, "_step": 51}
{"Episode reward": 34.410491239069415, "Episode length": 656, "Policy Loss": 0.5457069873809814, "Value Loss": 14.23073673248291, "_runtime": 11226.189100027084, "_timestamp": 1585581142.0337334, "_step": 52}
{"Episode reward": -99.82892984194193, "Episode length": 999, "Policy Loss": -0.6975117325782776, "Value Loss": 0.3513955771923065, "_runtime": 11227.541868448257, "_timestamp": 1585581143.3865018, "_step": 53}
{"Episode reward": 10.889634146914673, "Episode length": 892, "Policy Loss": 0.02515237033367157, "Value Loss": 10.699078559875488, "_runtime": 11229.131104707718, "_timestamp": 1585581144.975738, "_step": 54}
{"Episode reward": -99.80007610916952, "Episode length": 999, "Policy Loss": -0.6130762100219727, "Value Loss": 0.018715407699346542, "_runtime": 11230.748587608337, "_timestamp": 1585581146.593221, "_step": 55}
{"Episode reward": -99.84953293539444, "Episode length": 999, "Policy Loss": -0.6466604471206665, "Value Loss": 0.04711044207215309, "_runtime": 11232.352987766266, "_timestamp": 1585581148.197621, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6603541374206543, "Value Loss": 0.03663609176874161, "_runtime": 11233.350922822952, "_timestamp": 1585581149.1955562, "_step": 57}
{"Episode reward": 40.16327879976323, "Episode length": 602, "Policy Loss": -0.2515859007835388, "Value Loss": 16.84005355834961, "_runtime": 11234.973267316818, "_timestamp": 1585581150.8179007, "_step": 58}
{"Episode reward": -99.80241964580351, "Episode length": 999, "Policy Loss": -0.5580040812492371, "Value Loss": 0.16345278918743134, "_runtime": 11236.532739162445, "_timestamp": 1585581152.3773725, "_step": 59}
{"Episode reward": -98.53469229167564, "Episode length": 999, "Policy Loss": -1.1771906614303589, "Value Loss": 0.8546035885810852, "_runtime": 11238.071309566498, "_timestamp": 1585581153.915943, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11309001594781876, "Value Loss": 0.16210462152957916, "_runtime": 11239.654282569885, "_timestamp": 1585581155.498916, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05341188237071037, "Value Loss": 0.02091236785054207, "_runtime": 11241.232573509216, "_timestamp": 1585581157.0772069, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29125040769577026, "Value Loss": 0.03322611376643181, "_runtime": 11242.855930566788, "_timestamp": 1585581158.700564, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.48435720801353455, "Value Loss": 0.005749398376792669, "_runtime": 11244.450931310654, "_timestamp": 1585581160.2955647, "_step": 64}
{"Episode reward": -99.79190428601439, "Episode length": 999, "Policy Loss": 0.675915002822876, "Value Loss": 0.01606784202158451, "_runtime": 11246.035705327988, "_timestamp": 1585581161.8803387, "_step": 65}
{"Episode reward": -99.72274978200299, "Episode length": 999, "Policy Loss": 0.7952733635902405, "Value Loss": 0.08403964340686798, "_runtime": 11247.615777254105, "_timestamp": 1585581163.4604106, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9703255295753479, "Value Loss": 0.04938213527202606, "_runtime": 11248.25178360939, "_timestamp": 1585581164.096417, "_step": 67}
{"Episode reward": 62.209132002293806, "Episode length": 378, "Policy Loss": 3.1411588191986084, "Value Loss": 26.700965881347656, "_runtime": 11249.807064771652, "_timestamp": 1585581165.651698, "_step": 68}
{"Episode reward": -99.85654335021833, "Episode length": 999, "Policy Loss": 1.0256761312484741, "Value Loss": 0.028295671567320824, "_runtime": 11251.392479419708, "_timestamp": 1585581167.2371128, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9063785076141357, "Value Loss": 0.08853623270988464, "_runtime": 11252.912698030472, "_timestamp": 1585581168.7573314, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.878839910030365, "Value Loss": 0.01944987289607525, "_runtime": 11254.480962514877, "_timestamp": 1585581170.3255959, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7875264883041382, "Value Loss": 0.02638282999396324, "_runtime": 11256.066004276276, "_timestamp": 1585581171.9106376, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6739421486854553, "Value Loss": 0.03409567102789879, "_runtime": 11257.303707122803, "_timestamp": 1585581173.1483405, "_step": 73}
{"Episode reward": 21.2354348545896, "Episode length": 789, "Policy Loss": 1.6167616844177246, "Value Loss": 12.659541130065918, "_runtime": 11258.887628793716, "_timestamp": 1585581174.7322621, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4820845127105713, "Value Loss": 0.01602930948138237, "_runtime": 11260.477775335312, "_timestamp": 1585581176.3224087, "_step": 75}
{"Episode reward": -99.80535951889912, "Episode length": 999, "Policy Loss": 0.3861069679260254, "Value Loss": 0.014716162346303463, "_runtime": 11262.024906158447, "_timestamp": 1585581177.8695395, "_step": 76}
{"Episode reward": -99.82332356460255, "Episode length": 999, "Policy Loss": 0.2950235903263092, "Value Loss": 0.012756585143506527, "_runtime": 11263.602385997772, "_timestamp": 1585581179.4470193, "_step": 77}
{"Episode reward": -99.76495097912708, "Episode length": 999, "Policy Loss": 0.1893398016691208, "Value Loss": 0.02428429201245308, "_runtime": 11264.299050569534, "_timestamp": 1585581180.143684, "_step": 78}
{"Episode reward": 57.37543449690533, "Episode length": 427, "Policy Loss": 1.862339973449707, "Value Loss": 23.44900131225586, "_runtime": 11264.949088335037, "_timestamp": 1585581180.7937217, "_step": 79}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 2.1066670417785645, "Value Loss": 25.395124435424805, "_runtime": 11266.048273086548, "_timestamp": 1585581181.8929064, "_step": 80}
{"Episode reward": 32.399999999999565, "Episode length": 676, "Policy Loss": 1.158196210861206, "Value Loss": 14.70923137664795, "_runtime": 11266.825530290604, "_timestamp": 1585581182.6701636, "_step": 81}
{"Episode reward": 49.69999999999956, "Episode length": 503, "Policy Loss": 1.4926644563674927, "Value Loss": 19.652421951293945, "_runtime": 11268.347144126892, "_timestamp": 1585581184.1917775, "_step": 82}
{"Episode reward": -99.80627749599377, "Episode length": 999, "Policy Loss": 0.04438159614801407, "Value Loss": 0.13323967158794403, "_runtime": 11269.09518623352, "_timestamp": 1585581184.9398196, "_step": 83}
{"Episode reward": 52.17110349390965, "Episode length": 480, "Policy Loss": 1.8337205648422241, "Value Loss": 20.63277816772461, "_runtime": 11270.60258936882, "_timestamp": 1585581186.4472227, "_step": 84}
{"Episode reward": -99.80737700611213, "Episode length": 999, "Policy Loss": -0.05975361168384552, "Value Loss": 0.08384604752063751, "_runtime": 11272.149769306183, "_timestamp": 1585581187.9944026, "_step": 85}
{"Episode reward": -99.83095770478108, "Episode length": 999, "Policy Loss": -0.2069569081068039, "Value Loss": 0.08587760478258133, "_runtime": 11273.65459394455, "_timestamp": 1585581189.4992273, "_step": 86}
{"Episode reward": -99.82151727676252, "Episode length": 999, "Policy Loss": -0.44714581966400146, "Value Loss": 0.23941676318645477, "_runtime": 11274.442553043365, "_timestamp": 1585581190.2871864, "_step": 87}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 0.8156703114509583, "Value Loss": 20.069608688354492, "_runtime": 11275.34294462204, "_timestamp": 1585581191.187578, "_step": 88}
{"Episode reward": 42.99999999999947, "Episode length": 570, "Policy Loss": 0.5750592947006226, "Value Loss": 17.44725799560547, "_runtime": 11276.90682554245, "_timestamp": 1585581192.751459, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8470466136932373, "Value Loss": 0.029849478974938393, "_runtime": 11278.433945894241, "_timestamp": 1585581194.2785792, "_step": 90}
{"Episode reward": -99.85162105299393, "Episode length": 999, "Policy Loss": -0.9270623326301575, "Value Loss": 0.03169034793972969, "_runtime": 11279.967149734497, "_timestamp": 1585581195.811783, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0192123651504517, "Value Loss": 0.020871099084615707, "_runtime": 11281.536767244339, "_timestamp": 1585581197.3814006, "_step": 92}
{"Episode reward": -99.73205814696709, "Episode length": 999, "Policy Loss": -1.0294418334960938, "Value Loss": 0.04511500149965286, "_runtime": 11282.866389274597, "_timestamp": 1585581198.7110226, "_step": 93}
{"Episode reward": 15.367868681379136, "Episode length": 847, "Policy Loss": -0.1524111032485962, "Value Loss": 11.80295467376709, "_runtime": 11284.429174900055, "_timestamp": 1585581200.2738082, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0328651666641235, "Value Loss": 0.02822994813323021, "_runtime": 11286.01390171051, "_timestamp": 1585581201.858535, "_step": 95}
{"Episode reward": -99.73046344667534, "Episode length": 999, "Policy Loss": -0.9970356822013855, "Value Loss": 0.02087446115911007, "_runtime": 11287.57543349266, "_timestamp": 1585581203.4200668, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9591346979141235, "Value Loss": 0.015435170382261276, "_runtime": 11289.182611942291, "_timestamp": 1585581205.0272453, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9260715842247009, "Value Loss": 0.026222944259643555, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421, 0.0014059166423976421]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.020189648494124413, -0.018792251124978065, -0.017394855618476868, -0.01599745824933052, -0.014600061811506748, -0.013202665373682976, -0.011805268004536629, -0.010407871566712856, -0.009010475128889084, -0.007613078691065311, -0.006215682253241539, -0.004818284884095192, -0.003420887514948845, -0.002023492008447647, -0.0006260946393013, 0.0007713008671998978, 0.002168698236346245, 0.003566095605492592, 0.00496349111199379, 0.006360888481140137, 0.0077582839876413345, 0.009155681356787682, 0.010553078725934029, 0.011950476095080376, 0.013347873464226723, 0.014745267108082771, 0.01614266447722912, 0.017540061846375465, 0.018937459215521812, 0.02033485658466816, 0.021732250228524208, 0.023129647597670555, 0.024527044966816902, 0.02592444233596325, 0.027321839705109596, 0.028719233348965645, 0.030116630718111992, 0.03151402622461319, 0.032911427319049835, 0.034308820962905884, 0.03570621460676193, 0.03710361570119858, 0.038501009345054626, 0.03989841043949127, 0.04129580408334732, 0.04269319772720337, 0.044090598821640015, 0.04548799246549606, 0.04688539355993271, 0.04828278720378876, 0.049680180847644806, 0.05107758194208145, 0.0524749755859375, 0.053872376680374146, 0.055269770324230194, 0.05666716396808624, 0.05806456506252289, 0.05946195870637894, 0.06085935980081558, 0.06225675344467163, 0.06365414708852768, 0.06505154818296432, 0.06644894182682037, 0.06784634292125702, 0.06924373656511307]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.004427810665220022, -0.004307249095290899, -0.004186687991023064, -0.004066126421093941, -0.003945564851164818, -0.0038250035140663385, -0.0037044419441372156, -0.0035838806070387363, -0.0034633190371096134, -0.003342757700011134, -0.003222196362912655, -0.003101634792983532, -0.002981073223054409, -0.0028605118859559298, -0.0027399505488574505, -0.0026193889789283276, -0.0024988274089992046, -0.0023782660719007254, -0.002257704734802246, -0.002137143164873123, -0.002016581827774644, -0.001896020257845521, -0.0017754589207470417, -0.0016548973508179188, -0.0015343360137194395, -0.0014137744437903166, -0.0012932131066918373, -0.0011726515367627144, -0.0010520901996642351, -0.0009315286297351122, -0.0008109672926366329, -0.00069040572270751, -0.0005698443856090307, -0.00044928304851055145, -0.00032872147858142853, -0.0002081599086523056, -8.759880438446999e-05, 3.296276554465294e-05, 0.00015352433547377586, 0.0002740859054028988, 0.0003946470096707344, 0.0005152085795998573, 0.0006357701495289803, 0.0007563317194581032, 0.0008768928237259388, 0.0009974543936550617, 0.0011180159635841846, 0.0012385775335133076, 0.0013591386377811432, 0.0014797002077102661, 0.001600261777639389, 0.0017208228819072247, 0.0018413844518363476, 0.0019619460217654705, 0.0020825075916945934, 0.002203068695962429, 0.002323630265891552, 0.002444191835820675, 0.002564753405749798, 0.0026853145100176334, 0.0028058760799467564, 0.0029264376498758793, 0.003046999219805002, 0.003167560324072838, 0.0032881218940019608]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 4.0, 5.0, 16.0, 36.0, 20.0, 64.0, 254.0, 4.0, 2.0, 2.0, 8.0, 6.0, 7.0, 4.0, 2.0, 4.0, 3.0, 8.0, 7.0, 8.0, 8.0, 6.0, 6.0, 4.0, 3.0, 3.0, 1.0, 2.0], "bins": [-0.0336131826043129, -0.03281477466225624, -0.03201637044548988, -0.031217962503433228, -0.03041955456137657, -0.029621148481965065, -0.02882274053990841, -0.028024334460496902, -0.027225926518440247, -0.02642752043902874, -0.025629114359617233, -0.024830706417560577, -0.02403229847550392, -0.023233892396092415, -0.022435486316680908, -0.021637078374624252, -0.020838670432567596, -0.02004026435315609, -0.019241858273744583, -0.018443450331687927, -0.01764504425227642, -0.016846636310219765, -0.016048230230808258, -0.015249822288751602, -0.014451416209340096, -0.01365300826728344, -0.012854602187871933, -0.012056194245815277, -0.01125778816640377, -0.010459380224347115, -0.009660974144935608, -0.008862566202878952, -0.008064160123467445, -0.007265754044055939, -0.006467346101999283, -0.005668940022587776, -0.00487053208053112, -0.004072126001119614, -0.0032737180590629578, -0.002475311979651451, -0.0016769059002399445, -0.0008784979581832886, -8.009001612663269e-05, 0.0007183179259300232, 0.0015167221426963806, 0.0023151300847530365, 0.0031135380268096924, 0.003911945968866348, 0.004710350185632706, 0.005508758127689362, 0.0063071660697460175, 0.007105570286512375, 0.00790397822856903, 0.008702386170625687, 0.009500794112682343, 0.0102991983294487, 0.011097606271505356, 0.011896014213562012, 0.012694422155618668, 0.013492826372385025, 0.014291234314441681, 0.015089642256498337, 0.015888050198554993, 0.01668645441532135, 0.017484862357378006]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0], "bins": [-0.06770078092813492, -0.06606750935316086, -0.0644342303276062, -0.06280095875263214, -0.06116768717765808, -0.05953441187739372, -0.057901136577129364, -0.056267865002155304, -0.054634589701890945, -0.05300131440162659, -0.05136804282665253, -0.04973476752638817, -0.04810149222612381, -0.04646822065114975, -0.04483494535088539, -0.04320167005062103, -0.04156839847564697, -0.03993512690067291, -0.038301851600408554, -0.036668576300144196, -0.035035304725170135, -0.03340202942490578, -0.03176875412464142, -0.03013548254966736, -0.028502207249403, -0.02686893194913864, -0.02523566037416458, -0.023602385073900223, -0.021969109773635864, -0.020335838198661804, -0.018702562898397446, -0.017069291323423386, -0.015436016023159027, -0.013802740722894669, -0.012169469147920609, -0.01053619384765625, -0.00890292227268219, -0.007269646972417831, -0.005636371672153473, -0.004003100097179413, -0.002369828522205353, -0.0007365494966506958, 0.0008967220783233643, 0.0025299936532974243, 0.004163272678852081, 0.005796544253826141, 0.007429815828800201, 0.009063094854354858, 0.010696366429328918, 0.012329638004302979, 0.013962917029857635, 0.015596188604831696, 0.017229460179805756, 0.018862739205360413, 0.020496010780334473, 0.022129282355308533, 0.02376256138086319, 0.02539583295583725, 0.02702910453081131, 0.02866237610578537, 0.030295655131340027, 0.03192892670631409, 0.03356219828128815, 0.035195477306842804, 0.036828748881816864]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 6.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "bins": [-0.07435847073793411, -0.07210585474967957, -0.06985323876142502, -0.06760062277317047, -0.06534801423549652, -0.06309539824724197, -0.06084278225898743, -0.05859016627073288, -0.05633755028247833, -0.054084934294223785, -0.05183231830596924, -0.04957970604300499, -0.04732709005475044, -0.045074474066495895, -0.04282186180353165, -0.0405692458152771, -0.03831662982702255, -0.036064013838768005, -0.03381139785051346, -0.03155878558754921, -0.029306169599294662, -0.027053553611040115, -0.024800941348075867, -0.02254832535982132, -0.020295709371566772, -0.018043093383312225, -0.015790477395057678, -0.01353786513209343, -0.011285252869129181, -0.009032636880874634, -0.006780020892620087, -0.0045274049043655396, -0.0022747889161109924, -2.2172927856445312e-05, 0.002230443060398102, 0.004483059048652649, 0.006735675036907196, 0.008988283574581146, 0.011240899562835693, 0.01349351555109024, 0.015746131539344788, 0.017998747527599335, 0.020251363515853882, 0.02250397950410843, 0.02475658804178238, 0.027009204030036926, 0.029261820018291473, 0.03151443600654602, 0.03376705199480057, 0.036019667983055115, 0.03827228397130966, 0.04052489995956421, 0.042777515947818756, 0.045030124485492706, 0.04728274047374725, 0.0495353564620018, 0.05178796499967575, 0.054040588438510895, 0.056293196976184845, 0.05854582041501999, 0.06079842895269394, 0.06305105239152908, 0.06530366092920303, 0.06755628436803818, 0.06980889290571213]}, "_runtime": 11290.745972633362, "_timestamp": 1585581206.590606, "_step": 98}
{"Episode reward": -99.73604483082751, "Episode length": 999, "Policy Loss": -0.8739432096481323, "Value Loss": 0.017660848796367645, "_runtime": 11292.314332962036, "_timestamp": 1585581208.1589663, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8555932641029358, "Value Loss": 0.03554236516356468, "_runtime": 11292.969482421875, "_timestamp": 1585581208.8141158, "_step": 100}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.1102931499481201, "Value Loss": 24.894044876098633, "_runtime": 11294.263303279877, "_timestamp": 1585581210.1079366, "_step": 101}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.14213967323303223, "Value Loss": 11.918363571166992, "_runtime": 11295.839467287064, "_timestamp": 1585581211.6841006, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7130049467086792, "Value Loss": 0.02578410692512989, "_runtime": 11297.358078479767, "_timestamp": 1585581213.2027118, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6769498586654663, "Value Loss": 0.055017463862895966, "_runtime": 11298.730947494507, "_timestamp": 1585581214.5755808, "_step": 104}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.08074625581502914, "Value Loss": 11.188555717468262, "_runtime": 11300.297785758972, "_timestamp": 1585581216.142419, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6392672657966614, "Value Loss": 0.05509371683001518, "_runtime": 11301.361491203308, "_timestamp": 1585581217.2061245, "_step": 106}
{"Episode reward": 32.545301766343954, "Episode length": 677, "Policy Loss": 0.011546253226697445, "Value Loss": 14.730108261108398, "_runtime": 11302.92851638794, "_timestamp": 1585581218.7731497, "_step": 107}
{"Episode reward": -99.85557454973319, "Episode length": 999, "Policy Loss": -0.719093918800354, "Value Loss": 0.06628173589706421, "_runtime": 11304.507582426071, "_timestamp": 1585581220.3522158, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7605502009391785, "Value Loss": 0.06336072087287903, "_runtime": 11306.034945487976, "_timestamp": 1585581221.8795788, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8057950139045715, "Value Loss": 0.0383683517575264, "_runtime": 11307.620035171509, "_timestamp": 1585581223.4646685, "_step": 110}
{"Episode reward": -99.82916751513118, "Episode length": 999, "Policy Loss": -0.8212489485740662, "Value Loss": 0.023480234667658806, "_runtime": 11308.3679625988, "_timestamp": 1585581224.212596, "_step": 111}
{"Episode reward": 54.29558138251267, "Episode length": 458, "Policy Loss": 0.7942178845405579, "Value Loss": 21.535892486572266, "_runtime": 11309.928472042084, "_timestamp": 1585581225.7731054, "_step": 112}
{"Episode reward": -99.84511290052765, "Episode length": 999, "Policy Loss": -0.8783742189407349, "Value Loss": 0.0171036496758461, "_runtime": 11310.715102910995, "_timestamp": 1585581226.5597363, "_step": 113}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 0.6246568560600281, "Value Loss": 20.110654830932617, "_runtime": 11312.252702474594, "_timestamp": 1585581228.0973358, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9328569173812866, "Value Loss": 0.015181210823357105, "_runtime": 11313.869534492493, "_timestamp": 1585581229.7141678, "_step": 115}
{"Episode reward": -99.55230841134342, "Episode length": 999, "Policy Loss": -1.0146106481552124, "Value Loss": 0.04622996971011162, "_runtime": 11315.398115158081, "_timestamp": 1585581231.2427485, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9572730660438538, "Value Loss": 0.0192138459533453, "_runtime": 11316.960799455643, "_timestamp": 1585581232.8054328, "_step": 117}
{"Episode reward": -99.85040445327618, "Episode length": 999, "Policy Loss": -0.9474918246269226, "Value Loss": 0.014770672656595707, "_runtime": 11318.531201601028, "_timestamp": 1585581234.375835, "_step": 118}
{"Episode reward": -99.83407393842796, "Episode length": 999, "Policy Loss": -0.9455421566963196, "Value Loss": 0.03854590281844139, "_runtime": 11320.101733446121, "_timestamp": 1585581235.9463668, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9112994074821472, "Value Loss": 0.026859775185585022, "_runtime": 11321.685805082321, "_timestamp": 1585581237.5304384, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8762900829315186, "Value Loss": 0.028065646067261696, "_runtime": 11322.458954811096, "_timestamp": 1585581238.3035882, "_step": 121}
{"Episode reward": 52.95271758884152, "Episode length": 471, "Policy Loss": 0.6431195735931396, "Value Loss": 20.580154418945312, "_runtime": 11324.01217007637, "_timestamp": 1585581239.8568034, "_step": 122}
{"Episode reward": -99.64387549543615, "Episode length": 999, "Policy Loss": -0.9349367022514343, "Value Loss": 0.16049513220787048, "_runtime": 11324.656178712845, "_timestamp": 1585581240.500812, "_step": 123}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 1.4176751375198364, "Value Loss": 24.97508430480957, "_runtime": 11325.638672590256, "_timestamp": 1585581241.483306, "_step": 124}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.24586430191993713, "Value Loss": 14.757740020751953, "_runtime": 11327.201927661896, "_timestamp": 1585581243.046561, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8766488432884216, "Value Loss": 0.034019775688648224, "_runtime": 11328.715428590775, "_timestamp": 1585581244.560062, "_step": 126}
{"Episode reward": -99.81425080932537, "Episode length": 999, "Policy Loss": -0.9618952870368958, "Value Loss": 0.13394393026828766, "_runtime": 11330.25964307785, "_timestamp": 1585581246.1042764, "_step": 127}
{"Episode reward": -99.74422984309355, "Episode length": 999, "Policy Loss": -0.9372614026069641, "Value Loss": 0.042770884931087494, "_runtime": 11331.841067790985, "_timestamp": 1585581247.6857011, "_step": 128}
{"Episode reward": -99.82606705762306, "Episode length": 999, "Policy Loss": -0.936082124710083, "Value Loss": 0.02183232270181179, "_runtime": 11333.27916765213, "_timestamp": 1585581249.123801, "_step": 129}
{"Episode reward": 9.175251061196406, "Episode length": 917, "Policy Loss": -0.754535436630249, "Value Loss": 11.025105476379395, "_runtime": 11334.046810865402, "_timestamp": 1585581249.8914442, "_step": 130}
{"Episode reward": 52.7991199489679, "Episode length": 473, "Policy Loss": 0.48762592673301697, "Value Loss": 20.347244262695312, "_runtime": 11335.29724240303, "_timestamp": 1585581251.1418757, "_step": 131}
{"Episode reward": 21.188162603602024, "Episode length": 789, "Policy Loss": 0.05120423063635826, "Value Loss": 12.234770774841309, "_runtime": 11336.897654294968, "_timestamp": 1585581252.7422876, "_step": 132}
{"Episode reward": -99.86318037547031, "Episode length": 999, "Policy Loss": -0.711489737033844, "Value Loss": 0.012522118166089058, "_runtime": 11338.419139623642, "_timestamp": 1585581254.263773, "_step": 133}
{"Episode reward": 0.47580008730430734, "Episode length": 997, "Policy Loss": 0.018645869567990303, "Value Loss": 9.627655029296875, "_runtime": 11339.870136022568, "_timestamp": 1585581255.7147694, "_step": 134}
{"Episode reward": 6.696853508800274, "Episode length": 937, "Policy Loss": 0.08120578527450562, "Value Loss": 10.29191780090332, "_runtime": 11340.927685976028, "_timestamp": 1585581256.7723193, "_step": 135}
{"Episode reward": 33.19998457273421, "Episode length": 669, "Policy Loss": 0.42481592297554016, "Value Loss": 14.332334518432617, "_runtime": 11341.815365314484, "_timestamp": 1585581257.6599987, "_step": 136}
{"Episode reward": 44.31909373176698, "Episode length": 558, "Policy Loss": 0.47722315788269043, "Value Loss": 17.170318603515625, "_runtime": 11342.541103601456, "_timestamp": 1585581258.385737, "_step": 137}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 0.8731414675712585, "Value Loss": 20.789535522460938, "_runtime": 11344.088764190674, "_timestamp": 1585581259.9333975, "_step": 138}
{"Episode reward": -99.82011947370925, "Episode length": 999, "Policy Loss": -0.8667868375778198, "Value Loss": 0.13177229464054108, "_runtime": 11345.219092845917, "_timestamp": 1585581261.0637262, "_step": 139}
{"Episode reward": 27.204880716488532, "Episode length": 735, "Policy Loss": -0.9580463171005249, "Value Loss": 14.151187896728516, "_runtime": 11346.525039434433, "_timestamp": 1585581262.3696728, "_step": 140}
{"Episode reward": 13.816303857789066, "Episode length": 862, "Policy Loss": -0.0024986222852021456, "Value Loss": 10.729565620422363, "_runtime": 11348.096118450165, "_timestamp": 1585581263.9407518, "_step": 141}
{"Episode reward": -99.85334062725165, "Episode length": 999, "Policy Loss": -0.7254893779754639, "Value Loss": 0.016740383580327034, "_runtime": 11349.329564332962, "_timestamp": 1585581265.1741977, "_step": 142}
{"Episode reward": 20.432752542518088, "Episode length": 796, "Policy Loss": 0.022190770134329796, "Value Loss": 12.267671585083008, "_runtime": 11350.866253852844, "_timestamp": 1585581266.7108872, "_step": 143}
{"Episode reward": -99.80497117973724, "Episode length": 999, "Policy Loss": -0.583599328994751, "Value Loss": 0.019957037642598152, "_runtime": 11352.44089770317, "_timestamp": 1585581268.285531, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5127418041229248, "Value Loss": 0.04236695170402527, "_runtime": 11353.989371299744, "_timestamp": 1585581269.8340046, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4246080219745636, "Value Loss": 0.07038701325654984, "_runtime": 11355.55610370636, "_timestamp": 1585581271.400737, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35846468806266785, "Value Loss": 0.07012169808149338, "_runtime": 11356.840547323227, "_timestamp": 1585581272.6851807, "_step": 147}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": 0.7113522291183472, "Value Loss": 11.697735786437988, "_runtime": 11358.416656017303, "_timestamp": 1585581274.2612894, "_step": 148}
{"Episode reward": -99.80246434807637, "Episode length": 999, "Policy Loss": -0.2886674404144287, "Value Loss": 0.03211595490574837, "_runtime": 11359.06594157219, "_timestamp": 1585581274.910575, "_step": 149}
{"Episode reward": 61.26656920862706, "Episode length": 388, "Policy Loss": 1.4983775615692139, "Value Loss": 24.967227935791016, "_runtime": 11359.866938114166, "_timestamp": 1585581275.7115715, "_step": 150}
{"Episode reward": 50.44163770888591, "Episode length": 505, "Policy Loss": 0.8699136972427368, "Value Loss": 18.932273864746094, "_runtime": 11361.418146848679, "_timestamp": 1585581277.2627802, "_step": 151}
{"Episode reward": 3.8727512686525216, "Episode length": 962, "Policy Loss": 0.13974249362945557, "Value Loss": 10.140259742736816, "_runtime": 11362.950830936432, "_timestamp": 1585581278.7954643, "_step": 152}
{"Episode reward": -99.83980605639378, "Episode length": 999, "Policy Loss": -0.47853296995162964, "Value Loss": 0.009725403040647507, "_runtime": 11363.563790082932, "_timestamp": 1585581279.4084234, "_step": 153}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.0740031003952026, "Value Loss": 23.86845588684082, "_runtime": 11364.43587565422, "_timestamp": 1585581280.280509, "_step": 154}
{"Episode reward": 45.1999999999995, "Episode length": 548, "Policy Loss": 0.44916313886642456, "Value Loss": 17.16730308532715, "_runtime": 11365.190378427505, "_timestamp": 1585581281.0350118, "_step": 155}
{"Episode reward": 54.01091013096625, "Episode length": 468, "Policy Loss": -0.9725748896598816, "Value Loss": 21.832521438598633, "_runtime": 11366.732963562012, "_timestamp": 1585581282.577597, "_step": 156}
{"Episode reward": -99.83509824806684, "Episode length": 999, "Policy Loss": -0.7938618063926697, "Value Loss": 0.03852318227291107, "_runtime": 11368.272678136826, "_timestamp": 1585581284.1173115, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7531542778015137, "Value Loss": 0.017733164131641388, "_runtime": 11369.007078170776, "_timestamp": 1585581284.8517115, "_step": 158}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 0.8534919619560242, "Value Loss": 20.3074951171875, "_runtime": 11370.583032131195, "_timestamp": 1585581286.4276655, "_step": 159}
{"Episode reward": -99.81340657509723, "Episode length": 999, "Policy Loss": -0.6215525269508362, "Value Loss": 0.18491879105567932, "_runtime": 11371.068189382553, "_timestamp": 1585581286.9128227, "_step": 160}
{"Episode reward": 71.19884080290781, "Episode length": 289, "Policy Loss": 1.9260896444320679, "Value Loss": 32.67577362060547, "_runtime": 11372.60287809372, "_timestamp": 1585581288.4475114, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7411994934082031, "Value Loss": 0.0655151754617691, "_runtime": 11374.18623828888, "_timestamp": 1585581290.0308716, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8391553163528442, "Value Loss": 0.014839357696473598, "_runtime": 11375.703172206879, "_timestamp": 1585581291.5478055, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9055489897727966, "Value Loss": 0.08526154607534409, "_runtime": 11376.915533781052, "_timestamp": 1585581292.7601671, "_step": 164}
{"Episode reward": 23.742412116751126, "Episode length": 764, "Policy Loss": -0.17564839124679565, "Value Loss": 12.037662506103516, "_runtime": 11377.701417684555, "_timestamp": 1585581293.546051, "_step": 165}
{"Episode reward": 52.25526754707058, "Episode length": 478, "Policy Loss": 0.12489262968301773, "Value Loss": 19.986412048339844, "_runtime": 11379.269687652588, "_timestamp": 1585581295.114321, "_step": 166}
{"Episode reward": -99.76147377043823, "Episode length": 999, "Policy Loss": -0.9400336146354675, "Value Loss": 0.36442890763282776, "_runtime": 11380.86846613884, "_timestamp": 1585581296.7130995, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.717504620552063, "Value Loss": 0.030529547482728958, "_runtime": 11382.375057935715, "_timestamp": 1585581298.2196913, "_step": 168}
{"Episode reward": 2.644498481230201, "Episode length": 976, "Policy Loss": 0.04269469529390335, "Value Loss": 9.547798156738281, "_runtime": 11383.566697359085, "_timestamp": 1585581299.4113307, "_step": 169}
{"Episode reward": 25.875306064689042, "Episode length": 751, "Policy Loss": -0.5167800188064575, "Value Loss": 13.567770004272461, "_runtime": 11384.399772644043, "_timestamp": 1585581300.244406, "_step": 170}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 1.1922409534454346, "Value Loss": 19.28192710876465, "_runtime": 11385.982946395874, "_timestamp": 1585581301.8275797, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25162243843078613, "Value Loss": 0.035434287041425705, "_runtime": 11386.612282037735, "_timestamp": 1585581302.4569154, "_step": 172}
{"Episode reward": 61.09955947685348, "Episode length": 390, "Policy Loss": 2.0235958099365234, "Value Loss": 24.883403778076172, "_runtime": 11388.157404899597, "_timestamp": 1585581304.0020382, "_step": 173}
{"Episode reward": -99.81801998354355, "Episode length": 999, "Policy Loss": -0.46871545910835266, "Value Loss": 0.010664690285921097, "_runtime": 11389.739048480988, "_timestamp": 1585581305.5836818, "_step": 174}
{"Episode reward": -99.80150505453209, "Episode length": 999, "Policy Loss": -0.6213704347610474, "Value Loss": 0.023158112540841103, "_runtime": 11390.734311580658, "_timestamp": 1585581306.578945, "_step": 175}
{"Episode reward": 36.01597995181016, "Episode length": 648, "Policy Loss": 0.014643298462033272, "Value Loss": 15.214118957519531, "_runtime": 11392.312677383423, "_timestamp": 1585581308.1573107, "_step": 176}
{"Episode reward": -99.03255552841306, "Episode length": 999, "Policy Loss": -1.0445448160171509, "Value Loss": 0.17794489860534668, "_runtime": 11393.89498758316, "_timestamp": 1585581309.739621, "_step": 177}
{"Episode reward": -99.80202415920654, "Episode length": 999, "Policy Loss": -0.9152490496635437, "Value Loss": 0.05312184616923332, "_runtime": 11395.441566944122, "_timestamp": 1585581311.2862003, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9582464694976807, "Value Loss": 0.0672445148229599, "_runtime": 11396.20250916481, "_timestamp": 1585581312.0471425, "_step": 179}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 1.3957618474960327, "Value Loss": 20.168596267700195, "_runtime": 11397.800646305084, "_timestamp": 1585581313.6452796, "_step": 180}
{"Episode reward": -99.77410385794799, "Episode length": 999, "Policy Loss": -1.1891791820526123, "Value Loss": 0.02565823122859001, "_runtime": 11399.37540769577, "_timestamp": 1585581315.220041, "_step": 181}
{"Episode reward": -99.80030443668225, "Episode length": 999, "Policy Loss": -1.3333253860473633, "Value Loss": 0.037861019372940063, "_runtime": 11400.104824781418, "_timestamp": 1585581315.9494581, "_step": 182}
{"Episode reward": 53.79999999999962, "Episode length": 462, "Policy Loss": -0.1960524618625641, "Value Loss": 20.327425003051758, "_runtime": 11400.885628938675, "_timestamp": 1585581316.7302623, "_step": 183}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": -0.3057157099246979, "Value Loss": 19.965911865234375, "_runtime": 11402.471845149994, "_timestamp": 1585581318.3164785, "_step": 184}
{"Episode reward": -99.81380732059338, "Episode length": 999, "Policy Loss": -1.8452832698822021, "Value Loss": 0.14522898197174072, "_runtime": 11403.066141366959, "_timestamp": 1585581318.9107747, "_step": 185}
{"Episode reward": 62.07474606251318, "Episode length": 380, "Policy Loss": -0.537324070930481, "Value Loss": 24.681324005126953, "_runtime": 11404.595366477966, "_timestamp": 1585581320.4399998, "_step": 186}
{"Episode reward": -99.85577493309835, "Episode length": 999, "Policy Loss": -1.922956109046936, "Value Loss": 0.06428087502717972, "_runtime": 11405.235802173615, "_timestamp": 1585581321.0804355, "_step": 187}
{"Episode reward": 61.59999999999973, "Episode length": 384, "Policy Loss": -0.47188588976860046, "Value Loss": 25.520673751831055, "_runtime": 11406.763911485672, "_timestamp": 1585581322.6085448, "_step": 188}
{"Episode reward": -99.73672688575468, "Episode length": 999, "Policy Loss": -1.828918695449829, "Value Loss": 0.46209442615509033, "_runtime": 11408.346897363663, "_timestamp": 1585581324.1915307, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3409026861190796, "Value Loss": 0.06868638098239899, "_runtime": 11409.908318042755, "_timestamp": 1585581325.7529514, "_step": 190}
{"Episode reward": -99.82748180962959, "Episode length": 999, "Policy Loss": -0.8132449388504028, "Value Loss": 0.5430405735969543, "_runtime": 11411.497565031052, "_timestamp": 1585581327.3421984, "_step": 191}
{"Episode reward": -99.82381802201131, "Episode length": 999, "Policy Loss": -0.635739266872406, "Value Loss": 0.07620570808649063, "_runtime": 11413.094656944275, "_timestamp": 1585581328.9392903, "_step": 192}
{"Episode reward": -99.80150880077714, "Episode length": 999, "Policy Loss": -0.2229829728603363, "Value Loss": 0.10896719247102737, "_runtime": 11414.47449684143, "_timestamp": 1585581330.3191302, "_step": 193}
{"Episode reward": 13.156697912529083, "Episode length": 875, "Policy Loss": 0.8449714779853821, "Value Loss": 11.321480751037598, "_runtime": 11415.522598028183, "_timestamp": 1585581331.3672314, "_step": 194}
{"Episode reward": 35.09999999999941, "Episode length": 649, "Policy Loss": 1.4773943424224854, "Value Loss": 15.186198234558105, "_runtime": 11417.119398117065, "_timestamp": 1585581332.9640315, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5092756748199463, "Value Loss": 0.061910320073366165, "_runtime": 11418.700857639313, "_timestamp": 1585581334.545491, "_step": 196}
{"Episode reward": -99.6058592092232, "Episode length": 999, "Policy Loss": 0.6252464056015015, "Value Loss": 0.09633761644363403, "_runtime": 11420.250473499298, "_timestamp": 1585581336.0951068, "_step": 197}
{"Episode reward": -99.80845480561116, "Episode length": 999, "Policy Loss": 0.5681539177894592, "Value Loss": 0.3717483580112457, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823, 0.08110159635543823]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.6901200413703918, -0.4825526177883148, -0.2749851942062378, -0.06741780042648315, 0.14014965295791626, 0.3477171063423157, 0.5552844405174255, 0.762851893901825, 0.9704193472862244, 1.1779868602752686, 1.385554313659668, 1.5931217670440674, 1.8006889820098877, 2.008256435394287, 2.2158238887786865, 2.423391342163086, 2.6309587955474854, 2.8385262489318848, 3.046093702316284, 3.2536611557006836, 3.461228609085083, 3.6687958240509033, 3.876363515853882, 4.083930492401123, 4.291497707366943, 4.499065399169922, 4.706632614135742, 4.914200305938721, 5.121767520904541, 5.3293352127075195, 5.53690242767334, 5.744470119476318, 5.952037334442139, 6.159604549407959, 6.3671722412109375, 6.574739456176758, 6.782307147979736, 6.989874362945557, 7.197442054748535, 7.405009746551514, 7.612576961517334, 7.820144176483154, 8.027711868286133, 8.235279083251953, 8.44284725189209, 8.65041446685791, 8.85798168182373, 9.06554889678955, 9.273116111755371, 9.480684280395508, 9.688251495361328, 9.895818710327148, 10.103385925292969, 10.310954093933105, 10.518521308898926, 10.726088523864746, 10.933655738830566, 11.141222953796387, 11.348791122436523, 11.556358337402344, 11.763925552368164, 11.971492767333984, 12.179060935974121, 12.386628150939941, 12.594195365905762]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.016529660671949387, -0.013139487244188786, -0.009749313816428185, -0.006359141319990158, -0.002968967892229557, 0.000421205535531044, 0.0038113780319690704, 0.007201552391052246, 0.010591724887490273, 0.013981897383928299, 0.017372071743011475, 0.02076224610209465, 0.024152416735887527, 0.027542591094970703, 0.03093276545405388, 0.034322936087846756, 0.03771311044692993, 0.04110328480601311, 0.044493455439805984, 0.04788363352417946, 0.051273804157972336, 0.05466397479176521, 0.05805415287613869, 0.061444323509931564, 0.06483449041843414, 0.06822466850280762, 0.07161484658718109, 0.07500500977039337, 0.07839518785476685, 0.08178536593914032, 0.0851755291223526, 0.08856570720672607, 0.09195588529109955, 0.09534604847431183, 0.0987362265586853, 0.10212640464305878, 0.10551656782627106, 0.10890674591064453, 0.112296923995018, 0.11568708717823029, 0.11907726526260376, 0.12246744334697723, 0.12585760653018951, 0.129247784614563, 0.13263796269893646, 0.13602812588214874, 0.13941830396652222, 0.1428084820508957, 0.14619864523410797, 0.14958882331848145, 0.15297900140285492, 0.1563691645860672, 0.15975934267044067, 0.16314952075481415, 0.16653968393802643, 0.1699298620223999, 0.17332004010677338, 0.17671020328998566, 0.18010038137435913, 0.1834905594587326, 0.18688072264194489, 0.19027090072631836, 0.19366107881069183, 0.1970512419939041, 0.2004414200782776]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 18.0, 28.0, 20.0, 20.0, 12.0, 14.0, 56.0, 198.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 2.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.2610052824020386, -0.23113465309143066, -0.20126402378082275, -0.17139339447021484, -0.14152276515960693, -0.11165215075016022, -0.08178152143955231, -0.0519108921289444, -0.022040262818336487, 0.00783035159111023, 0.03770098090171814, 0.06757161021232605, 0.09744223952293396, 0.12731286883354187, 0.15718349814414978, 0.1870541274547577, 0.2169247567653656, 0.24679535627365112, 0.27666598558425903, 0.30653661489486694, 0.33640724420547485, 0.36627787351608276, 0.3961485028266907, 0.4260191321372986, 0.4558897614479065, 0.4857603907585144, 0.5156310200691223, 0.5455016493797302, 0.5753722786903381, 0.605242908000946, 0.635113537311554, 0.6649841666221619, 0.6948547959327698, 0.7247254252433777, 0.7545959949493408, 0.7844666242599487, 0.8143372535705566, 0.8442078828811646, 0.8740785121917725, 0.9039491415023804, 0.9338197708129883, 0.9636904001235962, 0.9935610294342041, 1.023431658744812, 1.05330228805542, 1.0831729173660278, 1.1130435466766357, 1.1429141759872437, 1.1727848052978516, 1.2026554346084595, 1.2325260639190674, 1.2623966932296753, 1.2922673225402832, 1.3221379518508911, 1.352008581161499, 1.381879210472107, 1.4117498397827148, 1.4416204690933228, 1.4714910984039307, 1.5013617277145386, 1.5312323570251465, 1.5611029863357544, 1.5909736156463623, 1.6208442449569702, 1.6507148742675781]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-1.200195550918579, -1.144829273223877, -1.0894631147384644, -1.0340968370437622, -0.9787306785583496, -0.9233644008636475, -0.8679982423782349, -0.8126319646835327, -0.7572658061981201, -0.701899528503418, -0.6465333104133606, -0.5911670923233032, -0.5358008742332458, -0.4804346561431885, -0.4250684380531311, -0.36970221996307373, -0.31433600187301636, -0.258969783782959, -0.2036035656929016, -0.14823734760284424, -0.09287106990814209, -0.03750491142272949, 0.017861366271972656, 0.07322752475738525, 0.1285938024520874, 0.1839599609375, 0.23932623863220215, 0.29469239711761475, 0.3500586748123169, 0.4054248332977295, 0.46079111099243164, 0.5161572694778442, 0.5715235471725464, 0.6268898248672485, 0.6822559833526611, 0.7376222610473633, 0.7929884195327759, 0.8483545780181885, 0.9037208557128906, 0.9590871334075928, 1.014453411102295, 1.069819450378418, 1.1251857280731201, 1.1805520057678223, 1.2359182834625244, 1.2912843227386475, 1.3466506004333496, 1.4020168781280518, 1.457383155822754, 1.512749433517456, 1.568115472793579, 1.6234817504882812, 1.6788480281829834, 1.7342143058776855, 1.7895803451538086, 1.8449466228485107, 1.900312900543213, 1.955679178237915, 2.011045217514038, 2.0664114952087402, 2.1217777729034424, 2.1771440505981445, 2.2325100898742676, 2.2878763675689697, 2.343242645263672]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 5.0, 7.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-2.7506914138793945, -2.686777114868164, -2.6228630542755127, -2.5589487552642822, -2.495034694671631, -2.4311203956604004, -2.367206335067749, -2.3032920360565186, -2.239377975463867, -2.1754636764526367, -2.1115493774414062, -2.047635316848755, -1.9837210178375244, -1.919806957244873, -1.8558926582336426, -1.7919784784317017, -1.7280642986297607, -1.6641501188278198, -1.600235939025879, -1.536321759223938, -1.472407579421997, -1.4084932804107666, -1.3445791006088257, -1.2806649208068848, -1.2167507410049438, -1.152836561203003, -1.088922381401062, -1.025008201599121, -0.9610939025878906, -0.8971797227859497, -0.8332655429840088, -0.7693513631820679, -0.705437183380127, -0.6415228843688965, -0.5776088237762451, -0.5136945247650146, -0.4497804641723633, -0.3858661651611328, -0.32195210456848145, -0.258037805557251, -0.1941237449645996, -0.13020944595336914, -0.06629514694213867, -0.0023810863494873047, 0.061533212661743164, 0.12544727325439453, 0.189361572265625, 0.25327563285827637, 0.31718993186950684, 0.3811042308807373, 0.44501829147338867, 0.5089325904846191, 0.5728466510772705, 0.636760950088501, 0.7006750106811523, 0.7645893096923828, 0.8285036087036133, 0.8924176692962646, 0.9563319683074951, 1.0202460289001465, 1.084160327911377, 1.1480743885040283, 1.2119886875152588, 1.2759027481079102, 1.3398170471191406]}, "_runtime": 11420.748251914978, "_timestamp": 1585581336.5928853, "_step": 198}
{"Episode reward": 71.89999999999988, "Episode length": 281, "Policy Loss": 3.4020001888275146, "Value Loss": 35.03960418701172, "_runtime": 11422.263956546783, "_timestamp": 1585581338.10859, "_step": 199}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": 1.3262208700180054, "Value Loss": 10.246223449707031, "_runtime": 11423.853932380676, "_timestamp": 1585581339.6985657, "_step": 200}
{"Episode reward": -99.70695216432075, "Episode length": 999, "Policy Loss": 0.4370232820510864, "Value Loss": 0.03279697895050049, "_runtime": 11425.380907773972, "_timestamp": 1585581341.225541, "_step": 201}
{"Episode reward": -99.75708894878487, "Episode length": 999, "Policy Loss": 0.2774941921234131, "Value Loss": 0.0659957006573677, "_runtime": 11426.970945358276, "_timestamp": 1585581342.8155787, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1189047172665596, "Value Loss": 0.06720831990242004, "_runtime": 11427.641447544098, "_timestamp": 1585581343.486081, "_step": 203}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 1.742486834526062, "Value Loss": 24.381086349487305, "_runtime": 11429.205906867981, "_timestamp": 1585581345.0505402, "_step": 204}
{"Episode reward": -99.8036753270761, "Episode length": 999, "Policy Loss": -0.14312447607517242, "Value Loss": 0.00316692516207695, "_runtime": 11430.81303191185, "_timestamp": 1585581346.6576653, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3033924102783203, "Value Loss": 0.008771185763180256, "_runtime": 11432.203993320465, "_timestamp": 1585581348.0486267, "_step": 206}
{"Episode reward": 8.659690973504254, "Episode length": 915, "Policy Loss": 0.1246972307562828, "Value Loss": 10.756668090820312, "_runtime": 11433.82620716095, "_timestamp": 1585581349.6708405, "_step": 207}
{"Episode reward": -99.77878792472045, "Episode length": 999, "Policy Loss": -0.5780972242355347, "Value Loss": 0.030950969085097313, "_runtime": 11435.429334640503, "_timestamp": 1585581351.273968, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6723027229309082, "Value Loss": 0.029459483921527863, "_runtime": 11436.99552154541, "_timestamp": 1585581352.840155, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7873855829238892, "Value Loss": 0.021980594843626022, "_runtime": 11437.552438497543, "_timestamp": 1585581353.3970718, "_step": 210}
{"Episode reward": 67.87465088926237, "Episode length": 322, "Policy Loss": 1.485860824584961, "Value Loss": 29.772048950195312, "_runtime": 11438.179930210114, "_timestamp": 1585581354.0245636, "_step": 211}
{"Episode reward": 61.899999999999736, "Episode length": 381, "Policy Loss": 0.8629055619239807, "Value Loss": 24.840852737426758, "_runtime": 11438.560994386673, "_timestamp": 1585581354.4056277, "_step": 212}
{"Episode reward": 78.39999999999998, "Episode length": 216, "Policy Loss": 2.3813250064849854, "Value Loss": 43.17048263549805, "_runtime": 11440.08525800705, "_timestamp": 1585581355.9298913, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.386608362197876, "Value Loss": 0.24410437047481537, "_runtime": 11441.619220018387, "_timestamp": 1585581357.4638534, "_step": 214}
{"Episode reward": -99.8033215418444, "Episode length": 999, "Policy Loss": -1.5774012804031372, "Value Loss": 0.21328204870224, "_runtime": 11442.11868262291, "_timestamp": 1585581357.963316, "_step": 215}
{"Episode reward": 67.29205411454878, "Episode length": 328, "Policy Loss": -2.5505809783935547, "Value Loss": 36.76651382446289, "_runtime": 11443.31522679329, "_timestamp": 1585581359.1598601, "_step": 216}
{"Episode reward": 23.783854539540286, "Episode length": 764, "Policy Loss": -0.9573507308959961, "Value Loss": 12.101285934448242, "_runtime": 11444.590454339981, "_timestamp": 1585581360.4350877, "_step": 217}
{"Episode reward": 19.30000000000031, "Episode length": 807, "Policy Loss": -0.061724450439214706, "Value Loss": 12.323506355285645, "_runtime": 11446.10664987564, "_timestamp": 1585581361.9512832, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0401793718338013, "Value Loss": 0.04746701195836067, "_runtime": 11446.834684848785, "_timestamp": 1585581362.6793182, "_step": 219}
{"Episode reward": 54.25524305067919, "Episode length": 458, "Policy Loss": 0.5958406329154968, "Value Loss": 21.643312454223633, "_runtime": 11448.400415182114, "_timestamp": 1585581364.2450485, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2026712894439697, "Value Loss": 0.15592741966247559, "_runtime": 11449.973767518997, "_timestamp": 1585581365.8184009, "_step": 221}
{"Episode reward": -99.84660495556751, "Episode length": 999, "Policy Loss": -1.4394164085388184, "Value Loss": 0.813991129398346, "_runtime": 11451.197571277618, "_timestamp": 1585581367.0422046, "_step": 222}
{"Episode reward": 20.165406159963723, "Episode length": 799, "Policy Loss": -0.6598693132400513, "Value Loss": 12.975595474243164, "_runtime": 11452.791139602661, "_timestamp": 1585581368.635773, "_step": 223}
{"Episode reward": -99.8000107186425, "Episode length": 999, "Policy Loss": -1.1924660205841064, "Value Loss": 0.07018431276082993, "_runtime": 11453.897712230682, "_timestamp": 1585581369.7423456, "_step": 224}
{"Episode reward": 30.461219781264347, "Episode length": 696, "Policy Loss": 0.510071873664856, "Value Loss": 16.43045425415039, "_runtime": 11455.466520309448, "_timestamp": 1585581371.3111537, "_step": 225}
{"Episode reward": -99.8240053047936, "Episode length": 999, "Policy Loss": -1.0665216445922852, "Value Loss": 0.041327137500047684, "_runtime": 11456.726110935211, "_timestamp": 1585581372.5707443, "_step": 226}
{"Episode reward": 24.495372014377836, "Episode length": 763, "Policy Loss": -0.8381724953651428, "Value Loss": 13.413971900939941, "_runtime": 11458.285402536392, "_timestamp": 1585581374.1300359, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3286375999450684, "Value Loss": 0.7929632067680359, "_runtime": 11459.863785743713, "_timestamp": 1585581375.708419, "_step": 228}
{"Episode reward": -99.87681906223158, "Episode length": 999, "Policy Loss": -1.055535078048706, "Value Loss": 0.09290274977684021, "_runtime": 11461.432185649872, "_timestamp": 1585581377.276819, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.864606499671936, "Value Loss": 0.017149437218904495, "_runtime": 11462.71455192566, "_timestamp": 1585581378.5591853, "_step": 230}
{"Episode reward": 19.284983428940492, "Episode length": 808, "Policy Loss": 0.294985294342041, "Value Loss": 12.628599166870117, "_runtime": 11463.705298185349, "_timestamp": 1585581379.5499315, "_step": 231}
{"Episode reward": 38.74126085960101, "Episode length": 613, "Policy Loss": 0.8436399698257446, "Value Loss": 16.89872932434082, "_runtime": 11465.275240659714, "_timestamp": 1585581381.119874, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45728540420532227, "Value Loss": 0.05833619832992554, "_runtime": 11466.215285778046, "_timestamp": 1585581382.059919, "_step": 233}
{"Episode reward": 42.971374177492976, "Episode length": 587, "Policy Loss": 0.984101414680481, "Value Loss": 16.97531509399414, "_runtime": 11467.736762285233, "_timestamp": 1585581383.5813956, "_step": 234}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.3635590076446533, "Value Loss": 10.163896560668945, "_runtime": 11468.248129367828, "_timestamp": 1585581384.0927627, "_step": 235}
{"Episode reward": 70.49614586224766, "Episode length": 296, "Policy Loss": 2.1327693462371826, "Value Loss": 33.33485412597656, "_runtime": 11469.798769950867, "_timestamp": 1585581385.6434033, "_step": 236}
{"Episode reward": -99.80304926968971, "Episode length": 999, "Policy Loss": -0.4309518039226532, "Value Loss": 0.14254939556121826, "_runtime": 11471.046311616898, "_timestamp": 1585581386.890945, "_step": 237}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": 0.6298234462738037, "Value Loss": 12.649197578430176, "_runtime": 11471.588623046875, "_timestamp": 1585581387.4332564, "_step": 238}
{"Episode reward": 66.05867295410977, "Episode length": 348, "Policy Loss": 1.3550931215286255, "Value Loss": 28.51007080078125, "_runtime": 11473.15721154213, "_timestamp": 1585581389.001845, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.279203325510025, "Value Loss": 0.004320592153817415, "_runtime": 11474.724155187607, "_timestamp": 1585581390.5687885, "_step": 240}
{"Episode reward": -99.781007253028, "Episode length": 999, "Policy Loss": -0.24183546006679535, "Value Loss": 0.005337712820619345, "_runtime": 11476.235031366348, "_timestamp": 1585581392.0796647, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2321464717388153, "Value Loss": 0.00872578751295805, "_runtime": 11477.823014259338, "_timestamp": 1585581393.6676476, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20265595614910126, "Value Loss": 0.02968965284526348, "_runtime": 11479.070252895355, "_timestamp": 1585581394.9148862, "_step": 243}
{"Episode reward": 22.30000000000014, "Episode length": 777, "Policy Loss": 1.178199052810669, "Value Loss": 13.240191459655762, "_runtime": 11480.679119586945, "_timestamp": 1585581396.523753, "_step": 244}
{"Episode reward": -99.70580604560534, "Episode length": 999, "Policy Loss": -0.24726487696170807, "Value Loss": 0.050933755934238434, "_runtime": 11482.109952926636, "_timestamp": 1585581397.9545863, "_step": 245}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 0.5164110064506531, "Value Loss": 11.36998462677002, "_runtime": 11483.696017503738, "_timestamp": 1585581399.5406508, "_step": 246}
{"Episode reward": -99.70201229527453, "Episode length": 999, "Policy Loss": -0.5642971396446228, "Value Loss": 0.025315608829259872, "_runtime": 11484.529752254486, "_timestamp": 1585581400.3743856, "_step": 247}
{"Episode reward": 48.59999999999955, "Episode length": 514, "Policy Loss": 1.132886528968811, "Value Loss": 19.227413177490234, "_runtime": 11486.114480495453, "_timestamp": 1585581401.9591138, "_step": 248}
{"Episode reward": -99.81429231315711, "Episode length": 999, "Policy Loss": -0.8084044456481934, "Value Loss": 0.023802248761057854, "_runtime": 11486.864844799042, "_timestamp": 1585581402.7094781, "_step": 249}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 0.5579967498779297, "Value Loss": 21.33965492248535, "_runtime": 11487.2027323246, "_timestamp": 1585581403.0473657, "_step": 250}
{"Episode reward": 80.19999999999999, "Episode length": 198, "Policy Loss": 2.5276455879211426, "Value Loss": 48.97038650512695, "_runtime": 11487.96687746048, "_timestamp": 1585581403.8115108, "_step": 251}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": 0.19434596598148346, "Value Loss": 21.054973602294922, "_runtime": 11489.517500162125, "_timestamp": 1585581405.3621335, "_step": 252}
{"Episode reward": -99.84442274570326, "Episode length": 999, "Policy Loss": -1.4465582370758057, "Value Loss": 0.9997909665107727, "_runtime": 11491.026789665222, "_timestamp": 1585581406.871423, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.033950686454773, "Value Loss": 0.28033310174942017, "_runtime": 11492.566406726837, "_timestamp": 1585581408.41104, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7315906882286072, "Value Loss": 0.023198263719677925, "_runtime": 11494.161847352982, "_timestamp": 1585581410.0064807, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4783916771411896, "Value Loss": 0.007929598912596703, "_runtime": 11495.724403381348, "_timestamp": 1585581411.5690367, "_step": 256}
{"Episode reward": -99.82777053266624, "Episode length": 999, "Policy Loss": -0.23068498075008392, "Value Loss": 0.0039957924745976925, "_runtime": 11497.203643798828, "_timestamp": 1585581413.0482771, "_step": 257}
{"Episode reward": 7.459506783414113, "Episode length": 935, "Policy Loss": 1.2002854347229004, "Value Loss": 10.827693939208984, "_runtime": 11498.605475187302, "_timestamp": 1585581414.4501085, "_step": 258}
{"Episode reward": 12.57845440171728, "Episode length": 875, "Policy Loss": 1.0726100206375122, "Value Loss": 11.534907341003418, "_runtime": 11500.175830841064, "_timestamp": 1585581416.0204642, "_step": 259}
{"Episode reward": -99.89905011802772, "Episode length": 999, "Policy Loss": 0.22861310839653015, "Value Loss": 0.013875352218747139, "_runtime": 11501.768703699112, "_timestamp": 1585581417.613337, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2613762319087982, "Value Loss": 0.004628410097211599, "_runtime": 11503.339174509048, "_timestamp": 1585581419.1838078, "_step": 261}
{"Episode reward": -99.81947855986515, "Episode length": 999, "Policy Loss": 0.30882179737091064, "Value Loss": 0.002772234845906496, "_runtime": 11504.964360237122, "_timestamp": 1585581420.8089936, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3469674587249756, "Value Loss": 0.0035330948885530233, "_runtime": 11506.407006263733, "_timestamp": 1585581422.2516396, "_step": 263}
{"Episode reward": 10.310603574910118, "Episode length": 904, "Policy Loss": 1.3711336851119995, "Value Loss": 11.082536697387695, "_runtime": 11507.981599330902, "_timestamp": 1585581423.8262327, "_step": 264}
{"Episode reward": -99.80203981995443, "Episode length": 999, "Policy Loss": 0.3676072955131531, "Value Loss": 0.021254876628518105, "_runtime": 11509.554478645325, "_timestamp": 1585581425.399112, "_step": 265}
{"Episode reward": 1.1000000000013443, "Episode length": 989, "Policy Loss": 1.0827252864837646, "Value Loss": 10.121562004089355, "_runtime": 11511.138167858124, "_timestamp": 1585581426.9828012, "_step": 266}
{"Episode reward": -99.80109313763538, "Episode length": 999, "Policy Loss": 0.22378283739089966, "Value Loss": 0.10046408325433731, "_runtime": 11511.92444396019, "_timestamp": 1585581427.7690773, "_step": 267}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": 2.4178833961486816, "Value Loss": 20.915536880493164, "_runtime": 11513.51825928688, "_timestamp": 1585581429.3628926, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2560886740684509, "Value Loss": 0.007020948920398951, "_runtime": 11514.324736833572, "_timestamp": 1585581430.1693702, "_step": 269}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 1.6226623058319092, "Value Loss": 20.186079025268555, "_runtime": 11515.883798360825, "_timestamp": 1585581431.7284317, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05826631560921669, "Value Loss": 0.04679349064826965, "_runtime": 11517.483167648315, "_timestamp": 1585581433.327801, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024817056953907013, "Value Loss": 0.026131855323910713, "_runtime": 11518.117258310318, "_timestamp": 1585581433.9618917, "_step": 272}
{"Episode reward": 60.3784813076022, "Episode length": 397, "Policy Loss": 1.7966700792312622, "Value Loss": 24.913734436035156, "_runtime": 11519.684513092041, "_timestamp": 1585581435.5291464, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2776152491569519, "Value Loss": 0.11579162627458572, "_runtime": 11520.332617521286, "_timestamp": 1585581436.1772509, "_step": 274}
{"Episode reward": 61.480063535179674, "Episode length": 386, "Policy Loss": 1.7853273153305054, "Value Loss": 25.584449768066406, "_runtime": 11521.874131441116, "_timestamp": 1585581437.7187648, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5237306356430054, "Value Loss": 0.12127655744552612, "_runtime": 11523.471500635147, "_timestamp": 1585581439.316134, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5748958587646484, "Value Loss": 0.04323853179812431, "_runtime": 11524.995437145233, "_timestamp": 1585581440.8400705, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6799902319908142, "Value Loss": 0.05197814106941223, "_runtime": 11526.599264621735, "_timestamp": 1585581442.443898, "_step": 278}
{"Episode reward": -99.7585907507674, "Episode length": 999, "Policy Loss": -0.7132253646850586, "Value Loss": 0.036205779761075974, "_runtime": 11527.036445617676, "_timestamp": 1585581442.881079, "_step": 279}
{"Episode reward": 76.6197570680459, "Episode length": 240, "Policy Loss": 2.2536544799804688, "Value Loss": 41.22282028198242, "_runtime": 11528.610996484756, "_timestamp": 1585581444.4556298, "_step": 280}
{"Episode reward": -99.75637758858363, "Episode length": 999, "Policy Loss": -0.860746443271637, "Value Loss": 0.03353986516594887, "_runtime": 11530.236754179, "_timestamp": 1585581446.0813875, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9164183139801025, "Value Loss": 0.029906947165727615, "_runtime": 11531.595690011978, "_timestamp": 1585581447.4403234, "_step": 282}
{"Episode reward": 11.024496033143706, "Episode length": 897, "Policy Loss": -0.2034856379032135, "Value Loss": 11.035911560058594, "_runtime": 11532.14321923256, "_timestamp": 1585581447.9878526, "_step": 283}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 2.0472466945648193, "Value Loss": 31.1322078704834, "_runtime": 11532.69285941124, "_timestamp": 1585581448.5374928, "_step": 284}
{"Episode reward": 67.27123325010743, "Episode length": 328, "Policy Loss": 1.371040940284729, "Value Loss": 30.164011001586914, "_runtime": 11533.983724594116, "_timestamp": 1585581449.828358, "_step": 285}
{"Episode reward": 16.400000000000475, "Episode length": 836, "Policy Loss": -0.09055430442094803, "Value Loss": 11.797551155090332, "_runtime": 11535.48266029358, "_timestamp": 1585581451.3272936, "_step": 286}
{"Episode reward": -99.80597239136556, "Episode length": 999, "Policy Loss": -1.3434560298919678, "Value Loss": 0.11573551595211029, "_runtime": 11536.05089879036, "_timestamp": 1585581451.8955321, "_step": 287}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 0.5190392136573792, "Value Loss": 26.33129119873047, "_runtime": 11537.321968078613, "_timestamp": 1585581453.1666014, "_step": 288}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": -0.647862434387207, "Value Loss": 12.185413360595703, "_runtime": 11538.109699249268, "_timestamp": 1585581453.9543326, "_step": 289}
{"Episode reward": 50.499999999999574, "Episode length": 495, "Policy Loss": -0.20276597142219543, "Value Loss": 19.828298568725586, "_runtime": 11538.972306489944, "_timestamp": 1585581454.8169398, "_step": 290}
{"Episode reward": 43.41249068097625, "Episode length": 567, "Policy Loss": -0.372944712638855, "Value Loss": 17.410106658935547, "_runtime": 11540.527734279633, "_timestamp": 1585581456.3723676, "_step": 291}
{"Episode reward": -99.71742028035084, "Episode length": 999, "Policy Loss": -1.6701557636260986, "Value Loss": 0.07771189510822296, "_runtime": 11542.044037342072, "_timestamp": 1585581457.8886707, "_step": 292}
{"Episode reward": -99.86549100614944, "Episode length": 999, "Policy Loss": -1.6962205171585083, "Value Loss": 0.10042537748813629, "_runtime": 11543.05617594719, "_timestamp": 1585581458.9008093, "_step": 293}
{"Episode reward": 34.598205145820415, "Episode length": 655, "Policy Loss": -0.5440121293067932, "Value Loss": 15.03679370880127, "_runtime": 11544.616562366486, "_timestamp": 1585581460.4611957, "_step": 294}
{"Episode reward": -99.82995397485652, "Episode length": 999, "Policy Loss": -1.6603237390518188, "Value Loss": 0.05803970620036125, "_runtime": 11546.155507087708, "_timestamp": 1585581462.0001404, "_step": 295}
{"Episode reward": -99.88889483520622, "Episode length": 999, "Policy Loss": -1.6261757612228394, "Value Loss": 0.04693378508090973, "_runtime": 11546.722302913666, "_timestamp": 1585581462.5669363, "_step": 296}
{"Episode reward": 64.59999999999977, "Episode length": 354, "Policy Loss": 0.6915575265884399, "Value Loss": 27.893442153930664, "_runtime": 11548.288840293884, "_timestamp": 1585581464.1334736, "_step": 297}
{"Episode reward": -99.7224714793251, "Episode length": 999, "Policy Loss": -1.5804320573806763, "Value Loss": 0.0499940887093544, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615, -0.08584995567798615]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 3.0], "bins": [-9.447416305541992, -9.293548583984375, -9.139680862426758, -8.98581314086914, -8.83194637298584, -8.678078651428223, -8.524210929870605, -8.370343208312988, -8.216475486755371, -8.062607765197754, -7.908740520477295, -7.754872798919678, -7.601005554199219, -7.447137832641602, -7.293270111083984, -7.139402389526367, -6.98553466796875, -6.831667423248291, -6.677799701690674, -6.523932456970215, -6.370064735412598, -6.2161970138549805, -6.062329292297363, -5.908461570739746, -5.754594326019287, -5.60072660446167, -5.446858882904053, -5.292991638183594, -5.139123916625977, -4.985256195068359, -4.831388473510742, -4.677521228790283, -4.523653507232666, -4.369785785675049, -4.21591854095459, -4.062050819396973, -3.9081830978393555, -3.7543153762817383, -3.6004481315612793, -3.446580410003662, -3.292712688446045, -3.138845443725586, -2.9849777221679688, -2.8311100006103516, -2.6772422790527344, -2.5233750343322754, -2.369507312774658, -2.215639591217041, -2.061772346496582, -1.9079046249389648, -1.7540369033813477, -1.6001691818237305, -1.4463014602661133, -1.292433738708496, -1.1385669708251953, -0.9846992492675781, -0.8308315277099609, -0.6769638061523438, -0.5230960845947266, -0.3692283630371094, -0.2153606414794922, -0.061493873596191406, 0.09237384796142578, 0.24624156951904297, 0.40010929107666016]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 4.0], "bins": [-0.19551147520542145, -0.19229507446289062, -0.1890786588191986, -0.18586225807666779, -0.18264584243297577, -0.17942944169044495, -0.17621302604675293, -0.1729966253042221, -0.1697802096605301, -0.16656380891799927, -0.16334739327430725, -0.16013099253177643, -0.1569145768880844, -0.1536981761455536, -0.15048176050186157, -0.14726535975933075, -0.14404894411563873, -0.1408325433731079, -0.1376161277294159, -0.13439972698688507, -0.13118332624435425, -0.12796691060066223, -0.12475050240755081, -0.12153409421443939, -0.11831768602132797, -0.11510127782821655, -0.11188486963510513, -0.10866846144199371, -0.1054520532488823, -0.10223564505577087, -0.09901923686265945, -0.09580282866954803, -0.09258642047643661, -0.0893700122833252, -0.08615360409021378, -0.08293719589710236, -0.07972078770399094, -0.07650437951087952, -0.0732879713177681, -0.07007156312465668, -0.06685516238212585, -0.06363874673843384, -0.060422345995903015, -0.057205930352211, -0.053989529609680176, -0.05077311396598816, -0.047556713223457336, -0.04434029757976532, -0.0411238968372345, -0.03790748119354248, -0.03469108045101166, -0.03147466480731964, -0.02825826406478882, -0.025041848421096802, -0.02182544767856598, -0.018609032034873962, -0.01539263129234314, -0.012176215648651123, -0.0089598149061203, -0.005743399262428284, -0.002526998519897461, 0.0006894171237945557, 0.0039058178663253784, 0.007122233510017395, 0.010338634252548218]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 1.0, 5.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 289.0, 33.0, 6.0, 18.0, 10.0, 9.0, 16.0, 24.0, 11.0, 4.0, 4.0], "bins": [-1.1357518434524536, -1.1144474744796753, -1.093143105506897, -1.0718387365341187, -1.0505343675613403, -1.029229998588562, -1.0079256296157837, -0.9866212606430054, -0.965316891670227, -0.9440125226974487, -0.9227081537246704, -0.9014037847518921, -0.8800994157791138, -0.8587950468063354, -0.8374906778335571, -0.8161863088607788, -0.7948819398880005, -0.7735775709152222, -0.7522732019424438, -0.7309688329696655, -0.7096644639968872, -0.6883600950241089, -0.6670557260513306, -0.6457513570785522, -0.6244470477104187, -0.6031426787376404, -0.5818383097648621, -0.5605339407920837, -0.5392295718193054, -0.5179252028465271, -0.4966208338737488, -0.47531646490097046, -0.45401209592819214, -0.4327077269554138, -0.4114033579826355, -0.3900989890098572, -0.36879462003707886, -0.34749025106430054, -0.3261858820915222, -0.3048815131187439, -0.2835771441459656, -0.26227277517318726, -0.24096840620040894, -0.21966403722763062, -0.1983596682548523, -0.17705529928207397, -0.15575093030929565, -0.1344466209411621, -0.11314225196838379, -0.09183788299560547, -0.07053351402282715, -0.04922914505004883, -0.027924776077270508, -0.0066204071044921875, 0.014683961868286133, 0.03598833084106445, 0.05729269981384277, 0.0785970687866211, 0.09990143775939941, 0.12120580673217773, 0.14251017570495605, 0.16381454467773438, 0.1851189136505127, 0.20642328262329102, 0.22772765159606934]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-2.419074773788452, -2.362896203994751, -2.3067173957824707, -2.2505388259887695, -2.1943600177764893, -2.138181447982788, -2.082002639770508, -2.0258240699768066, -1.969645380973816, -1.9134666919708252, -1.8572880029678345, -1.8011093139648438, -1.7449307441711426, -1.6887519359588623, -1.6325733661651611, -1.5763946771621704, -1.5202159881591797, -1.464037299156189, -1.4078586101531982, -1.3516799211502075, -1.2955012321472168, -1.2393226623535156, -1.183143973350525, -1.1269652843475342, -1.0707865953445435, -1.0146079063415527, -0.958429217338562, -0.9022505283355713, -0.8460719585418701, -0.7898932695388794, -0.7337145805358887, -0.677535891532898, -0.6213572025299072, -0.5651785135269165, -0.5089998245239258, -0.45282113552093506, -0.39664244651794434, -0.34046387672424316, -0.2842850685119629, -0.22810649871826172, -0.17192769050598145, -0.11574912071228027, -0.0595705509185791, -0.003391742706298828, 0.052786827087402344, 0.10896563529968262, 0.1651442050933838, 0.22132301330566406, 0.27750158309936523, 0.3336801528930664, 0.3898589611053467, 0.44603753089904785, 0.5022163391113281, 0.5583949089050293, 0.6145737171173096, 0.6707522869110107, 0.7269308567047119, 0.7831096649169922, 0.8392882347106934, 0.8954670429229736, 0.9516456127166748, 1.007824420928955, 1.0640029907226562, 1.1201817989349365, 1.1763603687286377]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 5.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.5264868140220642, -0.5030056238174438, -0.4795244038105011, -0.45604318380355835, -0.432561993598938, -0.40908077359199524, -0.3855995535850525, -0.36211836338043213, -0.3386371433734894, -0.31515592336654663, -0.29167473316192627, -0.2681935131549835, -0.24471229314804077, -0.2212311029434204, -0.19774988293647766, -0.1742686927318573, -0.15078747272491455, -0.1273062527179718, -0.10382506251335144, -0.08034384250640869, -0.05686265230178833, -0.03338143229484558, -0.009900212287902832, 0.01358097791671753, 0.037062227725982666, 0.06054341793060303, 0.08402460813522339, 0.10750579833984375, 0.1309870481491089, 0.15446823835372925, 0.1779494285583496, 0.20143067836761475, 0.2249118685722351, 0.24839305877685547, 0.2718743085861206, 0.29535549879074097, 0.31883668899536133, 0.34231793880462646, 0.3657991290092468, 0.3892803192138672, 0.41276150941848755, 0.4362427592277527, 0.45972394943237305, 0.4832051396369934, 0.5066863894462585, 0.5301676392555237, 0.5536487698554993, 0.5771300196647644, 0.6006112694740295, 0.6240924000740051, 0.6475736498832703, 0.6710547804832458, 0.694536030292511, 0.7180172801017761, 0.7414984107017517, 0.7649796605110168, 0.788460910320282, 0.8119420409202576, 0.8354232907295227, 0.8589045405387878, 0.8823856711387634, 0.9058669209480286, 0.9293481707572937, 0.9528293013572693, 0.9763105511665344]}, "_runtime": 11549.15970492363, "_timestamp": 1585581465.0043383, "_step": 298}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": -0.11509332060813904, "Value Loss": 18.080781936645508, "_runtime": 11550.070353507996, "_timestamp": 1585581465.9149868, "_step": 299}
{"Episode reward": 40.19999999999943, "Episode length": 598, "Policy Loss": -0.30672121047973633, "Value Loss": 16.506620407104492, "_runtime": 11551.522695541382, "_timestamp": 1585581467.367329, "_step": 300}
{"Episode reward": 8.024837832474816, "Episode length": 927, "Policy Loss": -0.8513042330741882, "Value Loss": 10.699931144714355, "_runtime": 11553.047144651413, "_timestamp": 1585581468.891778, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5286941528320312, "Value Loss": 0.06521327048540115, "_runtime": 11554.610308647156, "_timestamp": 1585581470.454942, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4891271591186523, "Value Loss": 0.05965084210038185, "_runtime": 11556.17808008194, "_timestamp": 1585581472.0227134, "_step": 303}
{"Episode reward": -99.74058666312929, "Episode length": 999, "Policy Loss": -1.4305716753005981, "Value Loss": 0.07899384945631027, "_runtime": 11557.748208761215, "_timestamp": 1585581473.592842, "_step": 304}
{"Episode reward": -99.84225317388633, "Episode length": 999, "Policy Loss": -1.4150371551513672, "Value Loss": 0.18532496690750122, "_runtime": 11558.282619714737, "_timestamp": 1585581474.127253, "_step": 305}
{"Episode reward": 68.14057911002665, "Episode length": 319, "Policy Loss": 1.0266129970550537, "Value Loss": 30.67326545715332, "_runtime": 11559.854798078537, "_timestamp": 1585581475.6994314, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2513060569763184, "Value Loss": 0.13289807736873627, "_runtime": 11561.422607660294, "_timestamp": 1585581477.267241, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1247464418411255, "Value Loss": 0.03698504716157913, "_runtime": 11562.517548799515, "_timestamp": 1585581478.3621821, "_step": 308}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": -0.14864236116409302, "Value Loss": 13.703683853149414, "_runtime": 11563.179938077927, "_timestamp": 1585581479.0245714, "_step": 309}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 0.8433271646499634, "Value Loss": 24.30543327331543, "_runtime": 11564.75783610344, "_timestamp": 1585581480.6024694, "_step": 310}
{"Episode reward": -99.778963591157, "Episode length": 999, "Policy Loss": -0.9180735945701599, "Value Loss": 0.022073086351156235, "_runtime": 11566.297903776169, "_timestamp": 1585581482.142537, "_step": 311}
{"Episode reward": -99.75396307185153, "Episode length": 999, "Policy Loss": -0.8817616105079651, "Value Loss": 0.050874192267656326, "_runtime": 11567.811947107315, "_timestamp": 1585581483.6565804, "_step": 312}
{"Episode reward": -99.76732806637743, "Episode length": 999, "Policy Loss": -0.82776939868927, "Value Loss": 0.03419957682490349, "_runtime": 11569.401892900467, "_timestamp": 1585581485.2465262, "_step": 313}
{"Episode reward": -99.83047061562398, "Episode length": 999, "Policy Loss": -0.7695271372795105, "Value Loss": 0.034116242080926895, "_runtime": 11570.972571849823, "_timestamp": 1585581486.8172052, "_step": 314}
{"Episode reward": -99.47449703516746, "Episode length": 999, "Policy Loss": -0.9065590500831604, "Value Loss": 0.1451376974582672, "_runtime": 11571.64764714241, "_timestamp": 1585581487.4922805, "_step": 315}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.0999616384506226, "Value Loss": 23.655778884887695, "_runtime": 11573.215641260147, "_timestamp": 1585581489.0602746, "_step": 316}
{"Episode reward": -99.82678239382663, "Episode length": 999, "Policy Loss": -0.5514000058174133, "Value Loss": 0.009593299590051174, "_runtime": 11574.790616989136, "_timestamp": 1585581490.6352503, "_step": 317}
{"Episode reward": -99.86473255306342, "Episode length": 999, "Policy Loss": -0.5196800231933594, "Value Loss": 0.016465365886688232, "_runtime": 11576.305630207062, "_timestamp": 1585581492.1502635, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45770263671875, "Value Loss": 0.029522279277443886, "_runtime": 11577.925034999847, "_timestamp": 1585581493.7696683, "_step": 319}
{"Episode reward": -99.71271025324101, "Episode length": 999, "Policy Loss": -0.41138818860054016, "Value Loss": 0.031140554696321487, "_runtime": 11578.811991930008, "_timestamp": 1585581494.6566253, "_step": 320}
{"Episode reward": 45.04912447857376, "Episode length": 552, "Policy Loss": 0.9964617490768433, "Value Loss": 18.001020431518555, "_runtime": 11579.713047742844, "_timestamp": 1585581495.557681, "_step": 321}
{"Episode reward": 42.619955130012166, "Episode length": 575, "Policy Loss": 0.9850636124610901, "Value Loss": 17.28829002380371, "_runtime": 11581.04404091835, "_timestamp": 1585581496.8886743, "_step": 322}
{"Episode reward": 15.286869108304913, "Episode length": 848, "Policy Loss": 0.5755543112754822, "Value Loss": 11.666740417480469, "_runtime": 11582.073152542114, "_timestamp": 1585581497.917786, "_step": 323}
{"Episode reward": 34.58706403246836, "Episode length": 664, "Policy Loss": 0.9044818878173828, "Value Loss": 14.95365047454834, "_runtime": 11582.679551839828, "_timestamp": 1585581498.5241852, "_step": 324}
{"Episode reward": 61.77637816928301, "Episode length": 383, "Policy Loss": 2.3140175342559814, "Value Loss": 25.642391204833984, "_runtime": 11584.2331097126, "_timestamp": 1585581500.077743, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4255082905292511, "Value Loss": 0.01053017657250166, "_runtime": 11584.743972539902, "_timestamp": 1585581500.5886059, "_step": 326}
{"Episode reward": 68.69999999999983, "Episode length": 313, "Policy Loss": 1.7282058000564575, "Value Loss": 31.068811416625977, "_runtime": 11586.248660564423, "_timestamp": 1585581502.093294, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6779990792274475, "Value Loss": 0.059570442885160446, "_runtime": 11587.061556339264, "_timestamp": 1585581502.9061897, "_step": 328}
{"Episode reward": 50.62128258404125, "Episode length": 505, "Policy Loss": -1.7235195636749268, "Value Loss": 21.482440948486328, "_runtime": 11588.571061134338, "_timestamp": 1585581504.4156945, "_step": 329}
{"Episode reward": -99.89955608152273, "Episode length": 999, "Policy Loss": -0.7119824886322021, "Value Loss": 0.2252897322177887, "_runtime": 11590.13851928711, "_timestamp": 1585581505.9831526, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3740246295928955, "Value Loss": 0.013755761086940765, "_runtime": 11591.660525560379, "_timestamp": 1585581507.505159, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17798931896686554, "Value Loss": 0.0008596698171459138, "_runtime": 11593.232550621033, "_timestamp": 1585581509.077184, "_step": 332}
{"Episode reward": -99.8126271262751, "Episode length": 999, "Policy Loss": -0.03845881298184395, "Value Loss": 0.00040874918340705335, "_runtime": 11594.801056861877, "_timestamp": 1585581510.6456902, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06635259836912155, "Value Loss": 0.0046106306836009026, "_runtime": 11595.300098657608, "_timestamp": 1585581511.144732, "_step": 334}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 2.5441408157348633, "Value Loss": 33.31793212890625, "_runtime": 11596.021518707275, "_timestamp": 1585581511.866152, "_step": 335}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 1.717494249343872, "Value Loss": 22.269916534423828, "_runtime": 11596.666717290878, "_timestamp": 1585581512.5113506, "_step": 336}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 1.7335925102233887, "Value Loss": 25.50673484802246, "_runtime": 11597.964244365692, "_timestamp": 1585581513.8088777, "_step": 337}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": 0.6926437616348267, "Value Loss": 11.44948673248291, "_runtime": 11598.562508106232, "_timestamp": 1585581514.4071414, "_step": 338}
{"Episode reward": 61.8033247306009, "Episode length": 383, "Policy Loss": 1.5725712776184082, "Value Loss": 25.7329158782959, "_runtime": 11599.932182073593, "_timestamp": 1585581515.7768154, "_step": 339}
{"Episode reward": 9.605575127477636, "Episode length": 915, "Policy Loss": -0.051017921417951584, "Value Loss": 11.29969596862793, "_runtime": 11601.514504432678, "_timestamp": 1585581517.3591378, "_step": 340}
{"Episode reward": -99.8562499999986, "Episode length": 999, "Policy Loss": -0.6686055064201355, "Value Loss": 0.09006652981042862, "_runtime": 11603.023693561554, "_timestamp": 1585581518.868327, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8413290977478027, "Value Loss": 0.1966598927974701, "_runtime": 11604.584150314331, "_timestamp": 1585581520.4287837, "_step": 342}
{"Episode reward": -99.80139843905205, "Episode length": 999, "Policy Loss": -0.9063083529472351, "Value Loss": 0.026159489527344704, "_runtime": 11606.160437822342, "_timestamp": 1585581522.0050712, "_step": 343}
{"Episode reward": -99.80408651474805, "Episode length": 999, "Policy Loss": -0.9363858103752136, "Value Loss": 0.024115150794386864, "_runtime": 11607.578918457031, "_timestamp": 1585581523.4235518, "_step": 344}
{"Episode reward": 8.841371715638687, "Episode length": 913, "Policy Loss": -0.11878284811973572, "Value Loss": 10.898571968078613, "_runtime": 11608.463828802109, "_timestamp": 1585581524.3084621, "_step": 345}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 0.7330708503723145, "Value Loss": 18.01601219177246, "_runtime": 11610.037120342255, "_timestamp": 1585581525.8817537, "_step": 346}
{"Episode reward": -99.80052046924689, "Episode length": 999, "Policy Loss": -0.989043653011322, "Value Loss": 0.01926490105688572, "_runtime": 11610.921651363373, "_timestamp": 1585581526.7662847, "_step": 347}
{"Episode reward": 43.84681972861238, "Episode length": 562, "Policy Loss": 0.8563288450241089, "Value Loss": 17.650930404663086, "_runtime": 11612.438614368439, "_timestamp": 1585581528.2832477, "_step": 348}
{"Episode reward": -99.87340213991561, "Episode length": 999, "Policy Loss": -1.0554255247116089, "Value Loss": 0.0215385090559721, "_runtime": 11614.052782058716, "_timestamp": 1585581529.8974154, "_step": 349}
{"Episode reward": -99.87519083060184, "Episode length": 999, "Policy Loss": -1.0738948583602905, "Value Loss": 0.02269584685564041, "_runtime": 11615.418109178543, "_timestamp": 1585581531.2627425, "_step": 350}
{"Episode reward": 14.300000000000594, "Episode length": 857, "Policy Loss": -0.15072309970855713, "Value Loss": 11.572779655456543, "_runtime": 11616.71453166008, "_timestamp": 1585581532.559165, "_step": 351}
{"Episode reward": 16.991439714789593, "Episode length": 831, "Policy Loss": -0.1857365518808365, "Value Loss": 11.930412292480469, "_runtime": 11618.01814198494, "_timestamp": 1585581533.8627753, "_step": 352}
{"Episode reward": 18.22560621639751, "Episode length": 818, "Policy Loss": -0.22465772926807404, "Value Loss": 12.11694622039795, "_runtime": 11619.602789878845, "_timestamp": 1585581535.4474232, "_step": 353}
{"Episode reward": -99.85641491561988, "Episode length": 999, "Policy Loss": -1.1804455518722534, "Value Loss": 0.05687996372580528, "_runtime": 11621.157429933548, "_timestamp": 1585581537.0020633, "_step": 354}
{"Episode reward": -99.78889121562104, "Episode length": 999, "Policy Loss": -1.1487499475479126, "Value Loss": 0.053233593702316284, "_runtime": 11622.720186710358, "_timestamp": 1585581538.56482, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134889006614685, "Value Loss": 0.050484806299209595, "_runtime": 11624.306719303131, "_timestamp": 1585581540.1513526, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0797523260116577, "Value Loss": 0.04180124029517174, "_runtime": 11625.686704397202, "_timestamp": 1585581541.5313377, "_step": 357}
{"Episode reward": 15.400000000000531, "Episode length": 846, "Policy Loss": -0.1345132291316986, "Value Loss": 11.680971145629883, "_runtime": 11627.26634144783, "_timestamp": 1585581543.1109748, "_step": 358}
{"Episode reward": -99.49794261352955, "Episode length": 999, "Policy Loss": -0.969240128993988, "Value Loss": 0.03699028491973877, "_runtime": 11628.844576835632, "_timestamp": 1585581544.6892102, "_step": 359}
{"Episode reward": -99.80232458263497, "Episode length": 999, "Policy Loss": -0.8879693150520325, "Value Loss": 0.024288611486554146, "_runtime": 11630.412829637527, "_timestamp": 1585581546.257463, "_step": 360}
{"Episode reward": -99.87988763451436, "Episode length": 999, "Policy Loss": -0.8390752077102661, "Value Loss": 0.03895871341228485, "_runtime": 11631.733260631561, "_timestamp": 1585581547.577894, "_step": 361}
{"Episode reward": 18.55206701256766, "Episode length": 819, "Policy Loss": 0.30143922567367554, "Value Loss": 12.0949125289917, "_runtime": 11633.368116378784, "_timestamp": 1585581549.2127497, "_step": 362}
{"Episode reward": -99.72528617754439, "Episode length": 999, "Policy Loss": -0.6677301526069641, "Value Loss": 0.015606305561959743, "_runtime": 11634.987350463867, "_timestamp": 1585581550.8319838, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6004787683486938, "Value Loss": 0.01594434678554535, "_runtime": 11635.396856069565, "_timestamp": 1585581551.2414894, "_step": 364}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 3.5788064002990723, "Value Loss": 45.10222244262695, "_runtime": 11636.98357629776, "_timestamp": 1585581552.8282096, "_step": 365}
{"Episode reward": -99.8006481114761, "Episode length": 999, "Policy Loss": -0.5835216045379639, "Value Loss": 0.010261576622724533, "_runtime": 11638.58228111267, "_timestamp": 1585581554.4269145, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6926183104515076, "Value Loss": 0.07295908778905869, "_runtime": 11640.101512432098, "_timestamp": 1585581555.9461458, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7496898174285889, "Value Loss": 0.10889137536287308, "_runtime": 11641.23021531105, "_timestamp": 1585581557.0748487, "_step": 368}
{"Episode reward": 29.899999999999707, "Episode length": 701, "Policy Loss": 0.4124957025051117, "Value Loss": 14.023715019226074, "_runtime": 11642.829241514206, "_timestamp": 1585581558.6738749, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6367021799087524, "Value Loss": 0.02656867355108261, "_runtime": 11644.394395828247, "_timestamp": 1585581560.2390292, "_step": 370}
{"Episode reward": -99.77817568927864, "Episode length": 999, "Policy Loss": -0.6545991897583008, "Value Loss": 0.04393276572227478, "_runtime": 11645.636444091797, "_timestamp": 1585581561.4810774, "_step": 371}
{"Episode reward": 22.7729143093524, "Episode length": 783, "Policy Loss": 0.08995721489191055, "Value Loss": 12.649251937866211, "_runtime": 11646.527200698853, "_timestamp": 1585581562.371834, "_step": 372}
{"Episode reward": 45.730619966610774, "Episode length": 543, "Policy Loss": 0.7488329410552979, "Value Loss": 18.125633239746094, "_runtime": 11648.10953617096, "_timestamp": 1585581563.9541695, "_step": 373}
{"Episode reward": -99.82402399862045, "Episode length": 999, "Policy Loss": -0.6292693018913269, "Value Loss": 0.02289840579032898, "_runtime": 11649.62244963646, "_timestamp": 1585581565.467083, "_step": 374}
{"Episode reward": 6.98670215014819, "Episode length": 931, "Policy Loss": 0.10379750281572342, "Value Loss": 10.588083267211914, "_runtime": 11650.593408107758, "_timestamp": 1585581566.4380414, "_step": 375}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": 0.4940783679485321, "Value Loss": 15.786988258361816, "_runtime": 11651.46574997902, "_timestamp": 1585581567.3103833, "_step": 376}
{"Episode reward": 46.3915841933335, "Episode length": 537, "Policy Loss": 0.6140273809432983, "Value Loss": 18.070436477661133, "_runtime": 11651.873965740204, "_timestamp": 1585581567.718599, "_step": 377}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": 2.2704975605010986, "Value Loss": 41.64044189453125, "_runtime": 11653.432737350464, "_timestamp": 1585581569.2773707, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0548354387283325, "Value Loss": 0.07654138654470444, "_runtime": 11654.974164247513, "_timestamp": 1585581570.8187976, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2843161821365356, "Value Loss": 0.3372815251350403, "_runtime": 11655.583761692047, "_timestamp": 1585581571.428395, "_step": 380}
{"Episode reward": 60.923692981903294, "Episode length": 398, "Policy Loss": 0.24579527974128723, "Value Loss": 24.57600212097168, "_runtime": 11657.151157140732, "_timestamp": 1585581572.9957905, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5004315376281738, "Value Loss": 0.3638536334037781, "_runtime": 11658.732276916504, "_timestamp": 1585581574.5769103, "_step": 382}
{"Episode reward": -99.84421348983749, "Episode length": 999, "Policy Loss": -1.52460777759552, "Value Loss": 0.4446491003036499, "_runtime": 11660.236671447754, "_timestamp": 1585581576.0813048, "_step": 383}
{"Episode reward": -99.86464419104018, "Episode length": 999, "Policy Loss": -1.380010724067688, "Value Loss": 0.19276736676692963, "_runtime": 11661.840433597565, "_timestamp": 1585581577.685067, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2049410343170166, "Value Loss": 0.032477740198373795, "_runtime": 11663.429889440536, "_timestamp": 1585581579.2745228, "_step": 385}
{"Episode reward": -99.71663344502309, "Episode length": 999, "Policy Loss": -1.0725806951522827, "Value Loss": 0.03085746243596077, "_runtime": 11664.762306928635, "_timestamp": 1585581580.6069403, "_step": 386}
{"Episode reward": 15.483967645348756, "Episode length": 847, "Policy Loss": 0.17504660785198212, "Value Loss": 11.576037406921387, "_runtime": 11666.261293649673, "_timestamp": 1585581582.105927, "_step": 387}
{"Episode reward": 7.372920712880145, "Episode length": 937, "Policy Loss": -0.010256684385240078, "Value Loss": 10.574003219604492, "_runtime": 11667.855472564697, "_timestamp": 1585581583.700106, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7199428677558899, "Value Loss": 0.01105419546365738, "_runtime": 11669.3998939991, "_timestamp": 1585581585.2445273, "_step": 389}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": 0.15706999599933624, "Value Loss": 9.939766883850098, "_runtime": 11670.98945236206, "_timestamp": 1585581586.8340857, "_step": 390}
{"Episode reward": -99.74970056190946, "Episode length": 999, "Policy Loss": -0.556398332118988, "Value Loss": 0.01008274219930172, "_runtime": 11672.615543842316, "_timestamp": 1585581588.4601772, "_step": 391}
{"Episode reward": -99.28527205722509, "Episode length": 999, "Policy Loss": -0.596563994884491, "Value Loss": 0.03209764137864113, "_runtime": 11674.198835372925, "_timestamp": 1585581590.0434687, "_step": 392}
{"Episode reward": -99.80002199746528, "Episode length": 999, "Policy Loss": -0.4262220859527588, "Value Loss": 0.003229287685826421, "_runtime": 11674.98563170433, "_timestamp": 1585581590.830265, "_step": 393}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.2630425691604614, "Value Loss": 20.742570877075195, "_runtime": 11676.589010000229, "_timestamp": 1585581592.4336433, "_step": 394}
{"Episode reward": -99.89745295196632, "Episode length": 999, "Policy Loss": -0.4138891398906708, "Value Loss": 0.002815153216943145, "_runtime": 11678.167375564575, "_timestamp": 1585581594.012009, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4662799537181854, "Value Loss": 0.0038186886813491583, "_runtime": 11679.692080974579, "_timestamp": 1585581595.5367143, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5048344135284424, "Value Loss": 0.005492840893566608, "_runtime": 11681.280546665192, "_timestamp": 1585581597.12518, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7135595679283142, "Value Loss": 0.22571909427642822, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285, 4.6324334144592285]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 7.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.393630027770996, -5.583411693572998, -4.773193359375, -3.962975263595581, -3.152756929397583, -2.342538833618164, -1.532320499420166, -0.722102165222168, 0.08811616897583008, 0.8983345031738281, 1.708552360534668, 2.518771171569824, 3.328989028930664, 4.13920783996582, 4.94942569732666, 5.759644508361816, 6.569862365722656, 7.380080223083496, 8.190299034118652, 9.000516891479492, 9.810734748840332, 10.620953559875488, 11.431172370910645, 12.2413911819458, 13.051608085632324, 13.86182689666748, 14.672045707702637, 15.48226261138916, 16.29248046875, 17.102699279785156, 17.912918090820312, 18.72313690185547, 19.533355712890625, 20.34357452392578, 21.153789520263672, 21.964008331298828, 22.774227142333984, 23.58444595336914, 24.394664764404297, 25.204883575439453, 26.015098571777344, 26.8253173828125, 27.635536193847656, 28.445755004882812, 29.25597381591797, 30.066192626953125, 30.87641143798828, 31.686626434326172, 32.49684524536133, 33.307064056396484, 34.11728286743164, 34.9275016784668, 35.73772048950195, 36.54793930053711, 37.358154296875, 38.168373107910156, 38.97859191894531, 39.78881072998047, 40.599029541015625, 41.40924835205078, 42.21946716308594, 43.02968215942383, 43.839900970458984, 44.65011978149414, 45.4603385925293]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.916419982910156, -7.6808390617370605, -7.445258140563965, -7.209677696228027, -6.974096775054932, -6.738515853881836, -6.502935409545898, -6.267354488372803, -6.031773567199707, -5.796192646026611, -5.560611724853516, -5.325031280517578, -5.089450359344482, -4.853869438171387, -4.618288993835449, -4.3827080726623535, -4.147127151489258, -3.911546230316162, -3.6759653091430664, -3.440384864807129, -3.204803943634033, -2.9692230224609375, -2.733642578125, -2.4980616569519043, -2.2624807357788086, -2.026899814605713, -1.7913188934326172, -1.5557384490966797, -1.320157527923584, -1.0845766067504883, -0.8489961624145508, -0.6134152412414551, -0.3778343200683594, -0.14225339889526367, 0.09332752227783203, 0.32890796661376953, 0.5644893646240234, 0.8000698089599609, 1.0356502532958984, 1.2712316513061523, 1.5068120956420898, 1.7423925399780273, 1.9779739379882812, 2.2135543823242188, 2.4491348266601562, 2.68471622467041, 2.9202966690063477, 3.1558780670166016, 3.391458511352539, 3.6270389556884766, 3.8626203536987305, 4.098200798034668, 4.333782196044922, 4.569362640380859, 4.804943084716797, 5.040524482727051, 5.276104927062988, 5.511685371398926, 5.74726676940918, 5.982847213745117, 6.218427658081055, 6.454009056091309, 6.689589500427246, 6.9251708984375, 7.1607513427734375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 9.0, 6.0, 16.0, 16.0, 31.0, 229.0, 58.0, 26.0, 22.0, 10.0, 13.0, 10.0, 4.0, 4.0, 4.0, 4.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.595415115356445, -8.306168556213379, -8.016921997070312, -7.727675914764404, -7.438429832458496, -7.14918327331543, -6.859936714172363, -6.570690155029297, -6.281444072723389, -5.9921979904174805, -5.702951431274414, -5.413704872131348, -5.124458312988281, -4.835212230682373, -4.545965671539307, -4.256719589233398, -3.967473030090332, -3.6782264709472656, -3.3889803886413574, -3.099733829498291, -2.810487747192383, -2.5212411880493164, -2.23199462890625, -1.9427485466003418, -1.6535019874572754, -1.364255428314209, -1.0750093460083008, -0.7857627868652344, -0.49651622772216797, -0.20726966857910156, 0.08197593688964844, 0.37122249603271484, 0.6604690551757812, 0.9497156143188477, 1.238962173461914, 1.528207778930664, 1.8174543380737305, 2.106700897216797, 2.3959474563598633, 2.6851940155029297, 2.9744396209716797, 3.263686180114746, 3.5529327392578125, 3.842179298400879, 4.131425857543945, 4.420672416687012, 4.709918022155762, 4.999164581298828, 5.2884111404418945, 5.577657699584961, 5.866904258728027, 6.156149864196777, 6.445396423339844, 6.73464298248291, 7.023889541625977, 7.313136100769043, 7.602382659912109, 7.891628265380859, 8.180875778198242, 8.470121383666992, 8.759366989135742, 9.048614501953125, 9.337860107421875, 9.627107620239258, 9.916353225708008]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-57.468528747558594, -55.58930969238281, -53.710086822509766, -51.830867767333984, -49.95164489746094, -48.072425842285156, -46.193206787109375, -44.313987731933594, -42.43476486206055, -40.5555419921875, -38.67632293701172, -36.79710388183594, -34.917884826660156, -33.03866195678711, -31.159442901611328, -29.280221939086914, -27.4010009765625, -25.521780014038086, -23.642559051513672, -21.76333999633789, -19.884117126464844, -18.004898071289062, -16.12567901611328, -14.246456146240234, -12.367237091064453, -10.488018035888672, -8.608795166015625, -6.729576110839844, -4.8503570556640625, -2.9711341857910156, -1.0919151306152344, 0.7873077392578125, 2.6665267944335938, 4.545745849609375, 6.424968719482422, 8.304191589355469, 10.18341064453125, 12.062629699707031, 13.941848754882812, 15.821067810058594, 17.700294494628906, 19.579513549804688, 21.45873260498047, 23.33795166015625, 25.21717071533203, 27.096389770507812, 28.975616455078125, 30.854835510253906, 32.73405456542969, 34.61327362060547, 36.49249267578125, 38.37171936035156, 40.250938415527344, 42.130157470703125, 44.009376525878906, 45.88859558105469, 47.76781463623047, 49.64704132080078, 51.52626037597656, 53.405479431152344, 55.284698486328125, 57.163917541503906, 59.04314422607422, 60.92236328125, 62.80158233642578]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 3.0, 2.0, 10.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0], "bins": [-75.80413818359375, -73.39583587646484, -70.98754119873047, -68.57923889160156, -66.17094421386719, -63.76264190673828, -61.35434341430664, -58.946044921875, -56.537742614746094, -54.12944793701172, -51.72114562988281, -49.31284713745117, -46.90454864501953, -44.496246337890625, -42.087947845458984, -39.679649353027344, -37.2713508605957, -34.86305236816406, -32.45475387573242, -30.046451568603516, -27.638153076171875, -25.229854583740234, -22.821556091308594, -20.413257598876953, -18.004959106445312, -15.596656799316406, -13.188358306884766, -10.780059814453125, -8.371757507324219, -5.963462829589844, -3.5551605224609375, -1.1468658447265625, 1.2614364624023438, 3.66973876953125, 6.078033447265625, 8.486335754394531, 10.894630432128906, 13.302932739257812, 15.711235046386719, 18.119529724121094, 20.52783203125, 22.936126708984375, 25.34442901611328, 27.752731323242188, 30.161026000976562, 32.56932830810547, 34.977622985839844, 37.38592529296875, 39.794219970703125, 42.20252227783203, 44.61082458496094, 47.01911926269531, 49.42742156982422, 51.835716247558594, 54.2440185546875, 56.652313232421875, 59.06062316894531, 61.46891784667969, 63.87721252441406, 66.2855224609375, 68.69381713867188, 71.10211181640625, 73.51040649414062, 75.91871643066406, 78.32701110839844]}, "_runtime": 11682.84674167633, "_timestamp": 1585581598.691375, "_step": 398}
{"Episode reward": 1.351622642061841, "Episode length": 994, "Policy Loss": -0.23967783153057098, "Value Loss": 10.034950256347656, "_runtime": 11684.443777561188, "_timestamp": 1585581600.288411, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31235894560813904, "Value Loss": 0.011991084553301334, "_runtime": 11686.074010133743, "_timestamp": 1585581601.9186435, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16851431131362915, "Value Loss": 0.0023255839478224516, "_runtime": 11687.386913776398, "_timestamp": 1585581603.231547, "_step": 401}
{"Episode reward": 18.800000000000338, "Episode length": 812, "Policy Loss": 0.9718340635299683, "Value Loss": 11.990354537963867, "_runtime": 11688.799484491348, "_timestamp": 1585581604.6441178, "_step": 402}
{"Episode reward": 11.600000000000747, "Episode length": 884, "Policy Loss": 0.7794857025146484, "Value Loss": 11.01223087310791, "_runtime": 11690.254103183746, "_timestamp": 1585581606.0987365, "_step": 403}
{"Episode reward": 9.300000000000878, "Episode length": 907, "Policy Loss": 0.7957293391227722, "Value Loss": 10.615150451660156, "_runtime": 11691.309004545212, "_timestamp": 1585581607.153638, "_step": 404}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.8502873778343201, "Value Loss": 14.522093772888184, "_runtime": 11692.894814491272, "_timestamp": 1585581608.7394478, "_step": 405}
{"Episode reward": -99.80483602620521, "Episode length": 999, "Policy Loss": -0.5160017013549805, "Value Loss": 0.03150958940386772, "_runtime": 11694.503773927689, "_timestamp": 1585581610.3484073, "_step": 406}
{"Episode reward": -99.82786710895458, "Episode length": 999, "Policy Loss": -0.7525694966316223, "Value Loss": 0.024796124547719955, "_runtime": 11695.01546907425, "_timestamp": 1585581610.8601024, "_step": 407}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 1.0706430673599243, "Value Loss": 30.821949005126953, "_runtime": 11696.593901872635, "_timestamp": 1585581612.4385352, "_step": 408}
{"Episode reward": 3.7942785819736002, "Episode length": 973, "Policy Loss": -1.3700262308120728, "Value Loss": 10.793740272521973, "_runtime": 11697.714386224747, "_timestamp": 1585581613.5590196, "_step": 409}
{"Episode reward": 31.39244454791732, "Episode length": 687, "Policy Loss": -0.12126598507165909, "Value Loss": 13.880099296569824, "_runtime": 11699.23939704895, "_timestamp": 1585581615.0840304, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0124062299728394, "Value Loss": 0.10872286558151245, "_runtime": 11700.835152387619, "_timestamp": 1585581616.6797857, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.902202844619751, "Value Loss": 0.2160516083240509, "_runtime": 11702.16523361206, "_timestamp": 1585581618.009867, "_step": 412}
{"Episode reward": 14.916776409373256, "Episode length": 852, "Policy Loss": 0.05205937847495079, "Value Loss": 11.499950408935547, "_runtime": 11703.741807699203, "_timestamp": 1585581619.586441, "_step": 413}
{"Episode reward": -99.77389730103175, "Episode length": 999, "Policy Loss": -0.7597126960754395, "Value Loss": 0.062022414058446884, "_runtime": 11705.335245609283, "_timestamp": 1585581621.179879, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6888611316680908, "Value Loss": 0.010134854353964329, "_runtime": 11706.912868976593, "_timestamp": 1585581622.7575023, "_step": 415}
{"Episode reward": -99.81464052535453, "Episode length": 999, "Policy Loss": -0.5657874941825867, "Value Loss": 0.005643974058330059, "_runtime": 11708.492032289505, "_timestamp": 1585581624.3366656, "_step": 416}
{"Episode reward": -99.83144181109824, "Episode length": 999, "Policy Loss": -0.4818761348724365, "Value Loss": 0.025861911475658417, "_runtime": 11710.082591056824, "_timestamp": 1585581625.9272244, "_step": 417}
{"Episode reward": -99.80297511964896, "Episode length": 999, "Policy Loss": -0.3302718698978424, "Value Loss": 0.005948388017714024, "_runtime": 11711.68516612053, "_timestamp": 1585581627.5297995, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2208835929632187, "Value Loss": 0.007494663819670677, "_runtime": 11713.186135292053, "_timestamp": 1585581629.0307686, "_step": 419}
{"Episode reward": 5.6986324250708975, "Episode length": 944, "Policy Loss": 0.6601758599281311, "Value Loss": 10.321866989135742, "_runtime": 11714.173638343811, "_timestamp": 1585581630.0182717, "_step": 420}
{"Episode reward": 39.49999999999942, "Episode length": 605, "Policy Loss": 1.2120894193649292, "Value Loss": 16.00885581970215, "_runtime": 11715.762483596802, "_timestamp": 1585581631.607117, "_step": 421}
{"Episode reward": -99.82354476600746, "Episode length": 999, "Policy Loss": -0.1703101247549057, "Value Loss": 0.03717363253235817, "_runtime": 11716.413549900055, "_timestamp": 1585581632.2581832, "_step": 422}
{"Episode reward": 60.98994230627986, "Episode length": 391, "Policy Loss": 1.8763456344604492, "Value Loss": 24.95851707458496, "_runtime": 11717.967617034912, "_timestamp": 1585581633.8122504, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3666435480117798, "Value Loss": 0.021046457812190056, "_runtime": 11719.556171894073, "_timestamp": 1585581635.4008052, "_step": 424}
{"Episode reward": -99.7393452923731, "Episode length": 999, "Policy Loss": -0.5355644822120667, "Value Loss": 0.16168104112148285, "_runtime": 11720.83833527565, "_timestamp": 1585581636.6829686, "_step": 425}
{"Episode reward": 18.674611684462178, "Episode length": 814, "Policy Loss": 0.08590535819530487, "Value Loss": 11.92113971710205, "_runtime": 11721.561894416809, "_timestamp": 1585581637.4065278, "_step": 426}
{"Episode reward": 56.87770634510347, "Episode length": 440, "Policy Loss": -0.18490850925445557, "Value Loss": 22.565420150756836, "_runtime": 11722.241055488586, "_timestamp": 1585581638.0856888, "_step": 427}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 1.4518963098526, "Value Loss": 23.550071716308594, "_runtime": 11723.81193614006, "_timestamp": 1585581639.6565695, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49736014008522034, "Value Loss": 0.04750649258494377, "_runtime": 11725.353143453598, "_timestamp": 1585581641.1977768, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4423167109489441, "Value Loss": 0.012840945273637772, "_runtime": 11726.84396648407, "_timestamp": 1585581642.6885998, "_step": 430}
{"Episode reward": 3.171382611209765, "Episode length": 970, "Policy Loss": 0.27884575724601746, "Value Loss": 9.880377769470215, "_runtime": 11728.43146443367, "_timestamp": 1585581644.2760978, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4401693642139435, "Value Loss": 0.005926194600760937, "_runtime": 11730.020811796188, "_timestamp": 1585581645.8654451, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46959808468818665, "Value Loss": 0.028656380251049995, "_runtime": 11731.603297948837, "_timestamp": 1585581647.4479313, "_step": 433}
{"Episode reward": -99.64050492553368, "Episode length": 999, "Policy Loss": -0.6165394186973572, "Value Loss": 0.18577232956886292, "_runtime": 11733.196606397629, "_timestamp": 1585581649.0412397, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3860852122306824, "Value Loss": 0.007267849054187536, "_runtime": 11734.776284217834, "_timestamp": 1585581650.6209176, "_step": 435}
{"Episode reward": -99.85220556408026, "Episode length": 999, "Policy Loss": -0.3112722635269165, "Value Loss": 0.0037427914794534445, "_runtime": 11736.371769428253, "_timestamp": 1585581652.2164028, "_step": 436}
{"Episode reward": -99.68017422258714, "Episode length": 999, "Policy Loss": -0.24688762426376343, "Value Loss": 0.0018590344116091728, "_runtime": 11737.406917572021, "_timestamp": 1585581653.251551, "_step": 437}
{"Episode reward": 34.570399406458634, "Episode length": 655, "Policy Loss": 0.932547390460968, "Value Loss": 14.79289722442627, "_runtime": 11738.97401380539, "_timestamp": 1585581654.8186471, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21523283421993256, "Value Loss": 0.013578900136053562, "_runtime": 11740.56159067154, "_timestamp": 1585581656.406224, "_step": 439}
{"Episode reward": -99.88597191581363, "Episode length": 999, "Policy Loss": -0.22625252604484558, "Value Loss": 0.014060774818062782, "_runtime": 11741.618079900742, "_timestamp": 1585581657.4627132, "_step": 440}
{"Episode reward": 34.412544037041386, "Episode length": 662, "Policy Loss": 0.3638216257095337, "Value Loss": 14.742653846740723, "_runtime": 11743.228328227997, "_timestamp": 1585581659.0729616, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2550031244754791, "Value Loss": 0.001803813735023141, "_runtime": 11744.872559785843, "_timestamp": 1585581660.7171931, "_step": 442}
{"Episode reward": -99.807712282239, "Episode length": 999, "Policy Loss": -0.2706132233142853, "Value Loss": 0.004820343106985092, "_runtime": 11746.444218635559, "_timestamp": 1585581662.288852, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.28280970454216003, "Value Loss": 0.012481389567255974, "_runtime": 11747.255586624146, "_timestamp": 1585581663.10022, "_step": 444}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": 1.022452712059021, "Value Loss": 18.826295852661133, "_runtime": 11748.485045194626, "_timestamp": 1585581664.3296785, "_step": 445}
{"Episode reward": 24.281257822737132, "Episode length": 758, "Policy Loss": 0.4343183636665344, "Value Loss": 12.080503463745117, "_runtime": 11749.301074028015, "_timestamp": 1585581665.1457074, "_step": 446}
{"Episode reward": 50.599999999999575, "Episode length": 494, "Policy Loss": 0.5497915744781494, "Value Loss": 18.38127326965332, "_runtime": 11750.86396932602, "_timestamp": 1585581666.7086027, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9104831218719482, "Value Loss": 0.020189540460705757, "_runtime": 11752.469250917435, "_timestamp": 1585581668.3138843, "_step": 448}
{"Episode reward": -99.82594877630332, "Episode length": 999, "Policy Loss": -1.098418116569519, "Value Loss": 0.025173833593726158, "_runtime": 11754.042936086655, "_timestamp": 1585581669.8875694, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2615973949432373, "Value Loss": 0.034604642540216446, "_runtime": 11755.63367819786, "_timestamp": 1585581671.4783115, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3733816146850586, "Value Loss": 0.03235113248229027, "_runtime": 11757.234199285507, "_timestamp": 1585581673.0788326, "_step": 451}
{"Episode reward": -99.78129296451668, "Episode length": 999, "Policy Loss": -1.4411081075668335, "Value Loss": 0.05182940140366554, "_runtime": 11758.819201946259, "_timestamp": 1585581674.6638353, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5121874809265137, "Value Loss": 0.4320657253265381, "_runtime": 11760.42584681511, "_timestamp": 1585581676.2704802, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4048073291778564, "Value Loss": 0.13391093909740448, "_runtime": 11762.086402893066, "_timestamp": 1585581677.9310362, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2596161365509033, "Value Loss": 0.03183329477906227, "_runtime": 11763.005166769028, "_timestamp": 1585581678.8498, "_step": 455}
{"Episode reward": 43.29999999999947, "Episode length": 567, "Policy Loss": -0.06366079300642014, "Value Loss": 16.226301193237305, "_runtime": 11763.812132120132, "_timestamp": 1585581679.6567655, "_step": 456}
{"Episode reward": 50.89471429001798, "Episode length": 495, "Policy Loss": -0.046973273158073425, "Value Loss": 18.857330322265625, "_runtime": 11765.392691135406, "_timestamp": 1585581681.2373245, "_step": 457}
{"Episode reward": -99.8037565083229, "Episode length": 999, "Policy Loss": -0.8049957752227783, "Value Loss": 0.03755127266049385, "_runtime": 11766.95466184616, "_timestamp": 1585581682.7992952, "_step": 458}
{"Episode reward": -99.70678027048568, "Episode length": 999, "Policy Loss": -0.5559801459312439, "Value Loss": 0.26051756739616394, "_runtime": 11768.53110074997, "_timestamp": 1585581684.375734, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.351215660572052, "Value Loss": 0.42609575390815735, "_runtime": 11769.709305286407, "_timestamp": 1585581685.5539386, "_step": 460}
{"Episode reward": 27.0742436315863, "Episode length": 730, "Policy Loss": 0.946437656879425, "Value Loss": 13.248262405395508, "_runtime": 11771.301172018051, "_timestamp": 1585581687.1458054, "_step": 461}
{"Episode reward": -99.48538470305364, "Episode length": 999, "Policy Loss": -0.10638243705034256, "Value Loss": 0.031172316521406174, "_runtime": 11771.788688898087, "_timestamp": 1585581687.6333222, "_step": 462}
{"Episode reward": 71.49999999999987, "Episode length": 285, "Policy Loss": 3.3267769813537598, "Value Loss": 33.689170837402344, "_runtime": 11773.35668683052, "_timestamp": 1585581689.2013202, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04865293204784393, "Value Loss": 0.016734277829527855, "_runtime": 11774.784548282623, "_timestamp": 1585581690.6291816, "_step": 464}
{"Episode reward": 11.324609811146786, "Episode length": 894, "Policy Loss": 0.2872672975063324, "Value Loss": 11.071409225463867, "_runtime": 11776.307985782623, "_timestamp": 1585581692.1526191, "_step": 465}
{"Episode reward": -99.81869992352883, "Episode length": 999, "Policy Loss": -0.06747237592935562, "Value Loss": 0.0012405529851093888, "_runtime": 11777.073215007782, "_timestamp": 1585581692.9178483, "_step": 466}
{"Episode reward": 53.850552939995744, "Episode length": 462, "Policy Loss": 1.2444236278533936, "Value Loss": 19.942026138305664, "_runtime": 11778.64421749115, "_timestamp": 1585581694.4888508, "_step": 467}
{"Episode reward": -99.80836277156928, "Episode length": 999, "Policy Loss": -0.19819016754627228, "Value Loss": 0.02665274403989315, "_runtime": 11779.594865083694, "_timestamp": 1585581695.4394984, "_step": 468}
{"Episode reward": 40.19999999999943, "Episode length": 598, "Policy Loss": 0.5714954137802124, "Value Loss": 14.858865737915039, "_runtime": 11780.457297325134, "_timestamp": 1585581696.3019307, "_step": 469}
{"Episode reward": 44.60794122219035, "Episode length": 554, "Policy Loss": 0.4232933521270752, "Value Loss": 16.359085083007812, "_runtime": 11782.051438570023, "_timestamp": 1585581697.896072, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4253653585910797, "Value Loss": 0.4674157202243805, "_runtime": 11782.841421842575, "_timestamp": 1585581698.6860552, "_step": 471}
{"Episode reward": 50.29999999999957, "Episode length": 497, "Policy Loss": 0.874550461769104, "Value Loss": 18.508195877075195, "_runtime": 11784.383999586105, "_timestamp": 1585581700.228633, "_step": 472}
{"Episode reward": -99.8104050166891, "Episode length": 999, "Policy Loss": -0.49591192603111267, "Value Loss": 0.1579345464706421, "_runtime": 11785.652223348618, "_timestamp": 1585581701.4968567, "_step": 473}
{"Episode reward": 20.300000000000253, "Episode length": 797, "Policy Loss": 0.26258620619773865, "Value Loss": 11.97938060760498, "_runtime": 11786.39659667015, "_timestamp": 1585581702.24123, "_step": 474}
{"Episode reward": 52.699999999999605, "Episode length": 473, "Policy Loss": 0.6517152786254883, "Value Loss": 18.6204891204834, "_runtime": 11787.966473579407, "_timestamp": 1585581703.811107, "_step": 475}
{"Episode reward": -99.82174437045911, "Episode length": 999, "Policy Loss": -0.45415550470352173, "Value Loss": 0.03227899596095085, "_runtime": 11789.536653995514, "_timestamp": 1585581705.3812873, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2577049434185028, "Value Loss": 0.00997504498809576, "_runtime": 11791.068509817123, "_timestamp": 1585581706.9131432, "_step": 477}
{"Episode reward": -99.89365854263166, "Episode length": 999, "Policy Loss": -0.06996538490056992, "Value Loss": 0.03027969039976597, "_runtime": 11792.69699382782, "_timestamp": 1585581708.5416272, "_step": 478}
{"Episode reward": -99.78320414135092, "Episode length": 999, "Policy Loss": 0.3097873032093048, "Value Loss": 0.0022571885492652655, "_runtime": 11794.284129142761, "_timestamp": 1585581710.1287625, "_step": 479}
{"Episode reward": -99.69009338654439, "Episode length": 999, "Policy Loss": 0.6306706070899963, "Value Loss": 0.006524188444018364, "_runtime": 11795.466462373734, "_timestamp": 1585581711.3110957, "_step": 480}
{"Episode reward": 25.897877415642085, "Episode length": 742, "Policy Loss": 1.9794683456420898, "Value Loss": 13.527969360351562, "_runtime": 11796.020399332047, "_timestamp": 1585581711.8650327, "_step": 481}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": 3.610764265060425, "Value Loss": 30.832672119140625, "_runtime": 11797.610228061676, "_timestamp": 1585581713.4548614, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2654660940170288, "Value Loss": 0.026037022471427917, "_runtime": 11798.81412267685, "_timestamp": 1585581714.658756, "_step": 483}
{"Episode reward": 23.582428029237477, "Episode length": 766, "Policy Loss": 2.4027256965637207, "Value Loss": 13.132204055786133, "_runtime": 11799.438219547272, "_timestamp": 1585581715.282853, "_step": 484}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 3.4971771240234375, "Value Loss": 24.902027130126953, "_runtime": 11801.014003038406, "_timestamp": 1585581716.8586364, "_step": 485}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": 2.0950024127960205, "Value Loss": 10.11036491394043, "_runtime": 11802.19945859909, "_timestamp": 1585581718.044092, "_step": 486}
{"Episode reward": 24.162149535119568, "Episode length": 760, "Policy Loss": 2.1847403049468994, "Value Loss": 13.175370216369629, "_runtime": 11803.716788768768, "_timestamp": 1585581719.561422, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9693663716316223, "Value Loss": 0.02988922782242298, "_runtime": 11805.302242279053, "_timestamp": 1585581721.1468756, "_step": 488}
{"Episode reward": -99.83594274818758, "Episode length": 999, "Policy Loss": 0.8125107288360596, "Value Loss": 0.013039151206612587, "_runtime": 11805.911593198776, "_timestamp": 1585581721.7562265, "_step": 489}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 2.614109992980957, "Value Loss": 26.403919219970703, "_runtime": 11807.455542087555, "_timestamp": 1585581723.3001754, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49055615067481995, "Value Loss": 0.019559398293495178, "_runtime": 11809.038647413254, "_timestamp": 1585581724.8832808, "_step": 491}
{"Episode reward": -99.74609416536846, "Episode length": 999, "Policy Loss": 0.32948413491249084, "Value Loss": 0.029698166996240616, "_runtime": 11810.47304391861, "_timestamp": 1585581726.3176773, "_step": 492}
{"Episode reward": 5.100000000001117, "Episode length": 949, "Policy Loss": 0.9288358092308044, "Value Loss": 10.460862159729004, "_runtime": 11811.503485918045, "_timestamp": 1585581727.3481193, "_step": 493}
{"Episode reward": 35.2026359007164, "Episode length": 648, "Policy Loss": 1.20747709274292, "Value Loss": 15.321943283081055, "_runtime": 11813.074656486511, "_timestamp": 1585581728.9192898, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09664787352085114, "Value Loss": 0.06542694568634033, "_runtime": 11813.945894479752, "_timestamp": 1585581729.7905278, "_step": 495}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 1.0848497152328491, "Value Loss": 18.020700454711914, "_runtime": 11815.480291128159, "_timestamp": 1585581731.3249245, "_step": 496}
{"Episode reward": -99.82076798016065, "Episode length": 999, "Policy Loss": -0.31492942571640015, "Value Loss": 0.0209292434155941, "_runtime": 11817.061363458633, "_timestamp": 1585581732.9059968, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4017832279205322, "Value Loss": 0.016424763947725296, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155, 0.3111119866371155]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.5267917513847351, -0.2726456820964813, -0.01849961280822754, 0.23564642667770386, 0.48979252576828003, 0.7439386248588562, 0.9980846047401428, 1.2522306442260742, 1.5063767433166504, 1.7605228424072266, 2.0146689414978027, 2.268815040588379, 2.522960901260376, 2.777107000350952, 3.0312530994415283, 3.2853991985321045, 3.5395452976226807, 3.793691396713257, 4.047837734222412, 4.301983833312988, 4.5561299324035645, 4.810276031494141, 5.064422130584717, 5.318568229675293, 5.572713851928711, 5.826859951019287, 6.081006050109863, 6.3351521492004395, 6.589298248291016, 6.843444347381592, 7.097590446472168, 7.351736545562744, 7.60588264465332, 7.860028266906738, 8.114174842834473, 8.36832046508789, 8.622467041015625, 8.876612663269043, 9.130759239196777, 9.384904861450195, 9.63905143737793, 9.893197059631348, 10.147343635559082, 10.4014892578125, 10.655635833740234, 10.909781455993652, 11.163928031921387, 11.418073654174805, 11.672219276428223, 11.926365852355957, 12.180511474609375, 12.43465805053711, 12.688803672790527, 12.942950248718262, 13.19709587097168, 13.451242446899414, 13.705388069152832, 13.959534645080566, 14.213680267333984, 14.467826843261719, 14.721972465515137, 14.976119041442871, 15.230264663696289, 15.484410285949707, 15.738556861877441]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.07440361380577087, 0.08113386482000351, 0.08786411583423615, 0.09459436684846878, 0.10132461786270142, 0.10805487632751465, 0.11478511989116669, 0.12151537835597992, 0.12824562191963196, 0.1349758803844452, 0.14170613884925842, 0.14843638241291046, 0.1551666259765625, 0.16189688444137573, 0.16862714290618896, 0.175357386469841, 0.18208763003349304, 0.18881788849830627, 0.1955481469631195, 0.20227839052677155, 0.20900864899158478, 0.21573889255523682, 0.22246915102005005, 0.2291993945837021, 0.23592965304851532, 0.24265989661216736, 0.2493901550769806, 0.25612038373947144, 0.26285064220428467, 0.2695809006690979, 0.27631115913391113, 0.28304141759872437, 0.2897716760635376, 0.29650193452835083, 0.3032321631908417, 0.3099624216556549, 0.31669265031814575, 0.323422908782959, 0.3301531672477722, 0.33688342571258545, 0.3436136841773987, 0.3503439128398895, 0.35707417130470276, 0.363804429769516, 0.3705346882343292, 0.37726491689682007, 0.3839951753616333, 0.39072543382644653, 0.39745569229125977, 0.404185950756073, 0.41091617941856384, 0.4176464378833771, 0.4243766963481903, 0.43110695481300354, 0.4378371834754944, 0.4445674419403076, 0.45129770040512085, 0.4580279588699341, 0.4647581875324249, 0.47148844599723816, 0.4782187044620514, 0.4849489629268646, 0.49167919158935547, 0.4984094500541687, 0.5051397085189819]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [7.0, 3.0, 19.0, 19.0, 13.0, 10.0, 16.0, 23.0, 76.0, 97.0, 85.0, 41.0, 21.0, 11.0, 5.0, 3.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.33311542868614197, -0.2998620569705963, -0.26660865545272827, -0.23335528373718262, -0.20010189712047577, -0.16684851050376892, -0.13359513878822327, -0.10034175217151642, -0.06708836555480957, -0.033834993839263916, -0.000581592321395874, 0.03267177939414978, 0.06592515110969543, 0.09917855262756348, 0.13243192434310913, 0.16568532586097717, 0.19893869757652283, 0.23219206929206848, 0.26544544100761414, 0.29869887232780457, 0.3319522440433502, 0.3652056157588959, 0.39845898747444153, 0.4317123591899872, 0.46496573090553284, 0.49821916222572327, 0.5314725637435913, 0.5647258758544922, 0.5979793071746826, 0.6312326192855835, 0.6644860506057739, 0.6977393627166748, 0.7309927940368652, 0.7642462253570557, 0.7974995374679565, 0.830752968788147, 0.8640062808990479, 0.8972597122192383, 0.9305131435394287, 0.9637664556503296, 0.99701988697052, 1.030273199081421, 1.0635266304016113, 1.0967800617218018, 1.1300333738327026, 1.163286805152893, 1.196540117263794, 1.2297935485839844, 1.2630468606948853, 1.2963002920150757, 1.3295537233352661, 1.362807035446167, 1.3960604667663574, 1.4293137788772583, 1.4625672101974487, 1.4958206415176392, 1.52907395362854, 1.5623273849487305, 1.5955806970596313, 1.6288341283798218, 1.6620875597000122, 1.6953409910202026, 1.728594183921814, 1.7618476152420044, 1.7951010465621948]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.7118446826934814, -2.584105968475342, -2.456367254257202, -2.3286285400390625, -2.200890064239502, -2.073151111602783, -1.9454126358032227, -1.817673921585083, -1.6899352073669434, -1.5621964931488037, -1.434457778930664, -1.306719183921814, -1.1789804697036743, -1.0512417554855347, -0.9235031604766846, -0.7957644462585449, -0.6680257320404053, -0.5402870178222656, -0.412548303604126, -0.28480958938598633, -0.15707087516784668, -0.029332399368286133, 0.09840631484985352, 0.22614502906799316, 0.3538837432861328, 0.48162245750427246, 0.6093611717224121, 0.7370998859405518, 0.8648383617401123, 0.992577075958252, 1.1203157901763916, 1.2480545043945312, 1.375793218612671, 1.5035316944122314, 1.6312706470489502, 1.7590091228485107, 1.8867480754852295, 2.01448655128479, 2.142225503921509, 2.2699639797210693, 2.397702932357788, 2.5254414081573486, 2.653179883956909, 2.780918836593628, 2.9086573123931885, 3.0363962650299072, 3.1641347408294678, 3.2918736934661865, 3.419612169265747, 3.5473506450653076, 3.6750895977020264, 3.802828073501587, 3.9305670261383057, 4.058305740356445, 4.186044692993164, 4.313782691955566, 4.441521644592285, 4.569260597229004, 4.696998596191406, 4.824737548828125, 4.952476501464844, 5.0802154541015625, 5.207953453063965, 5.335692405700684, 5.463431358337402]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 9.0, 12.0, 6.0, 8.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.5917205810546875, -3.490280866622925, -3.388840913772583, -3.2874011993408203, -3.1859614849090576, -3.084521770477295, -2.983081817626953, -2.8816421031951904, -2.7802023887634277, -2.678762435913086, -2.5773227214813232, -2.4758830070495605, -2.3744430541992188, -2.273003339767456, -2.1715636253356934, -2.0701236724853516, -1.9686839580535889, -1.8672441244125366, -1.765804409980774, -1.6643645763397217, -1.562924861907959, -1.4614849090576172, -1.3600451946258545, -1.2586054801940918, -1.15716552734375, -1.0557258129119873, -0.9542860984802246, -0.8528463840484619, -0.7514064311981201, -0.6499667167663574, -0.5485270023345947, -0.44708704948425293, -0.34564733505249023, -0.24420762062072754, -0.14276766777038574, -0.04132795333862305, 0.06011176109313965, 0.16155171394348145, 0.26299142837524414, 0.36443114280700684, 0.46587085723876953, 0.5673108100891113, 0.6687507629394531, 0.7701902389526367, 0.8716301918029785, 0.9730701446533203, 1.074509620666504, 1.1759495735168457, 1.2773895263671875, 1.378829002380371, 1.480268955230713, 1.5817084312438965, 1.6831483840942383, 1.78458833694458, 1.8860278129577637, 1.9874677658081055, 2.0889077186584473, 2.190347194671631, 2.2917871475219727, 2.3932271003723145, 2.494666576385498, 2.59610652923584, 2.6975464820861816, 2.7989859580993652, 2.900425910949707]}, "_runtime": 11818.043811321259, "_timestamp": 1585581733.8884447, "_step": 498}
{"Episode reward": 36.1215244516724, "Episode length": 639, "Policy Loss": 0.6692456603050232, "Value Loss": 15.470726013183594, "_runtime": 11818.043811321259, "_timestamp": 1585581733.8884447, "_step": 499}
