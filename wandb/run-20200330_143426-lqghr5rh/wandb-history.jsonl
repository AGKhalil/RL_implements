{"Episode reward": -46.84240358089841, "Episode length": 999, "Policy Loss": -0.06266490370035172, "Value Loss": 0.004342390224337578, "_runtime": 8969.790928125381, "_timestamp": 1585578885.6355615, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5436134934425354, "Value Loss": 8.22302532196045, "_runtime": 8971.2793238163, "_timestamp": 1585578887.1239572, "_step": 1}
{"Episode reward": -98.77669877916532, "Episode length": 999, "Policy Loss": 2.2519888877868652, "Value Loss": 24343.34375, "_runtime": 8971.565865278244, "_timestamp": 1585578887.4104986, "_step": 2}
{"Episode reward": 86.9893382821617, "Episode length": 133, "Policy Loss": -198.17477416992188, "Value Loss": 25509.8046875, "_runtime": 8971.795042276382, "_timestamp": 1585578887.6396756, "_step": 3}
{"Episode reward": 88.06065984522904, "Episode length": 121, "Policy Loss": 8.672822952270508, "Value Loss": 1387.0146484375, "_runtime": 8972.874915838242, "_timestamp": 1585578888.7195492, "_step": 4}
{"Episode reward": 30.797033581593155, "Episode length": 699, "Policy Loss": -25.958736419677734, "Value Loss": 564.3617553710938, "_runtime": 8973.082726955414, "_timestamp": 1585578888.9273603, "_step": 5}
{"Episode reward": 87.58514721415708, "Episode length": 126, "Policy Loss": -121.21350860595703, "Value Loss": 1351.8599853515625, "_runtime": 8974.2021317482, "_timestamp": 1585578890.046765, "_step": 6}
{"Episode reward": 24.331600861480652, "Episode length": 763, "Policy Loss": -2.36671781539917, "Value Loss": 403.7620849609375, "_runtime": 8975.783412218094, "_timestamp": 1585578891.6280456, "_step": 7}
{"Episode reward": -99.60872640608768, "Episode length": 999, "Policy Loss": -2.218541145324707, "Value Loss": 258.6139831542969, "_runtime": 8976.48904633522, "_timestamp": 1585578892.3336797, "_step": 8}
{"Episode reward": 52.83669452262607, "Episode length": 475, "Policy Loss": 7.5216522216796875, "Value Loss": 1020.9144287109375, "_runtime": 8978.007126808167, "_timestamp": 1585578893.8517601, "_step": 9}
{"Episode reward": -99.68427244319908, "Episode length": 999, "Policy Loss": -6.884801387786865, "Value Loss": 67.7468490600586, "_runtime": 8979.281403064728, "_timestamp": 1585578895.1260364, "_step": 10}
{"Episode reward": 20.218197990209106, "Episode length": 803, "Policy Loss": -13.724308967590332, "Value Loss": 567.4122314453125, "_runtime": 8980.778509140015, "_timestamp": 1585578896.6231425, "_step": 11}
{"Episode reward": -99.87206438938016, "Episode length": 999, "Policy Loss": -14.245195388793945, "Value Loss": 122.94573211669922, "_runtime": 8981.427748203278, "_timestamp": 1585578897.2723815, "_step": 12}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": -12.39937973022461, "Value Loss": 81.91585540771484, "_runtime": 8982.995434999466, "_timestamp": 1585578898.8400683, "_step": 13}
{"Episode reward": -99.80011997530097, "Episode length": 999, "Policy Loss": -15.895427703857422, "Value Loss": 118.17115020751953, "_runtime": 8984.533772230148, "_timestamp": 1585578900.3784056, "_step": 14}
{"Episode reward": -99.82569445408741, "Episode length": 999, "Policy Loss": -16.183809280395508, "Value Loss": 81.87989044189453, "_runtime": 8985.217907190323, "_timestamp": 1585578901.0625405, "_step": 15}
{"Episode reward": 55.79999999999965, "Episode length": 442, "Policy Loss": -13.2261381149292, "Value Loss": 168.64974975585938, "_runtime": 8986.45940065384, "_timestamp": 1585578902.304034, "_step": 16}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": -16.33689308166504, "Value Loss": 86.64749908447266, "_runtime": 8988.009857177734, "_timestamp": 1585578903.8544905, "_step": 17}
{"Episode reward": -99.83028895296016, "Episode length": 999, "Policy Loss": -15.568012237548828, "Value Loss": 199.9607391357422, "_runtime": 8989.16523528099, "_timestamp": 1585578905.0098686, "_step": 18}
{"Episode reward": 23.844407248497063, "Episode length": 762, "Policy Loss": -16.558059692382812, "Value Loss": 437.1673278808594, "_runtime": 8990.52147269249, "_timestamp": 1585578906.366106, "_step": 19}
{"Episode reward": 12.900000000000674, "Episode length": 871, "Policy Loss": -14.025289535522461, "Value Loss": 67.91152954101562, "_runtime": 8992.087971687317, "_timestamp": 1585578907.932605, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -14.646117210388184, "Value Loss": 118.878173828125, "_runtime": 8993.35565161705, "_timestamp": 1585578909.200285, "_step": 21}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": -12.98873519897461, "Value Loss": 140.14031982421875, "_runtime": 8994.41510462761, "_timestamp": 1585578910.259738, "_step": 22}
{"Episode reward": 32.247113087400365, "Episode length": 678, "Policy Loss": -13.07019329071045, "Value Loss": 152.31759643554688, "_runtime": 8995.699957847595, "_timestamp": 1585578911.5445912, "_step": 23}
{"Episode reward": 18.300000000000367, "Episode length": 817, "Policy Loss": -11.185118675231934, "Value Loss": 314.52752685546875, "_runtime": 8996.626734256744, "_timestamp": 1585578912.4713676, "_step": 24}
{"Episode reward": 41.09999999999944, "Episode length": 589, "Policy Loss": -11.765989303588867, "Value Loss": 86.85160827636719, "_runtime": 8998.179494380951, "_timestamp": 1585578914.0241277, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.622005462646484, "Value Loss": 10.11568832397461, "_runtime": 8999.767008066177, "_timestamp": 1585578915.6116414, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.10978889465332, "Value Loss": 6.062449932098389, "_runtime": 9001.298156499863, "_timestamp": 1585578917.1427898, "_step": 27}
{"Episode reward": -99.84545380025962, "Episode length": 999, "Policy Loss": -6.860907077789307, "Value Loss": 4.277035713195801, "_runtime": 9002.318593740463, "_timestamp": 1585578918.163227, "_step": 28}
{"Episode reward": 35.899999999999366, "Episode length": 641, "Policy Loss": -4.7762227058410645, "Value Loss": 58.24032211303711, "_runtime": 9003.88765835762, "_timestamp": 1585578919.7322917, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5145163536071777, "Value Loss": 46.502140045166016, "_runtime": 9004.881628751755, "_timestamp": 1585578920.726262, "_step": 30}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": -2.7541491985321045, "Value Loss": 113.18624877929688, "_runtime": 9006.376900911331, "_timestamp": 1585578922.2215343, "_step": 31}
{"Episode reward": 3.3000000000012193, "Episode length": 967, "Policy Loss": -2.445183515548706, "Value Loss": 62.82889175415039, "_runtime": 9007.91455745697, "_timestamp": 1585578923.7591908, "_step": 32}
{"Episode reward": 2.149340199680424, "Episode length": 980, "Policy Loss": -3.062744140625, "Value Loss": 164.2035369873047, "_runtime": 9009.369220972061, "_timestamp": 1585578925.2138543, "_step": 33}
{"Episode reward": 5.548121927679674, "Episode length": 946, "Policy Loss": -2.4034998416900635, "Value Loss": 40.882293701171875, "_runtime": 9009.760236740112, "_timestamp": 1585578925.60487, "_step": 34}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 3.9241411685943604, "Value Loss": 60.9846076965332, "_runtime": 9011.326939105988, "_timestamp": 1585578927.1715724, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35127007961273193, "Value Loss": 39.985023498535156, "_runtime": 9012.11628293991, "_timestamp": 1585578927.9609163, "_step": 36}
{"Episode reward": 51.09999999999958, "Episode length": 489, "Policy Loss": 0.5013905167579651, "Value Loss": 201.453369140625, "_runtime": 9012.948847532272, "_timestamp": 1585578928.7934809, "_step": 37}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.8601582050323486, "Value Loss": 45.235801696777344, "_runtime": 9014.138226747513, "_timestamp": 1585578929.98286, "_step": 38}
{"Episode reward": 25.353370040655108, "Episode length": 747, "Policy Loss": 0.03132084012031555, "Value Loss": 151.33096313476562, "_runtime": 9015.662355661392, "_timestamp": 1585578931.506989, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6774368286132812, "Value Loss": 24.74083137512207, "_runtime": 9016.623758792877, "_timestamp": 1585578932.4683921, "_step": 40}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.7706786394119263, "Value Loss": 140.61715698242188, "_runtime": 9018.168453454971, "_timestamp": 1585578934.0130868, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4955717623233795, "Value Loss": 4.879598617553711, "_runtime": 9019.404538154602, "_timestamp": 1585578935.2491715, "_step": 42}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 1.885358452796936, "Value Loss": 273.99945068359375, "_runtime": 9020.929545879364, "_timestamp": 1585578936.7741792, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.26897624135017395, "Value Loss": 19.14629364013672, "_runtime": 9022.187197685242, "_timestamp": 1585578938.031831, "_step": 44}
{"Episode reward": 20.876390033588038, "Episode length": 792, "Policy Loss": 0.9562819004058838, "Value Loss": 16.408445358276367, "_runtime": 9022.916308641434, "_timestamp": 1585578938.760942, "_step": 45}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 0.1532602459192276, "Value Loss": 46.04715347290039, "_runtime": 9024.474398612976, "_timestamp": 1585578940.319032, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9815753102302551, "Value Loss": 59.644805908203125, "_runtime": 9026.031504869461, "_timestamp": 1585578941.8761382, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5684973001480103, "Value Loss": 33.85992431640625, "_runtime": 9027.520335197449, "_timestamp": 1585578943.3649685, "_step": 48}
{"Episode reward": 2.493441098929722, "Episode length": 976, "Policy Loss": 0.06057218089699745, "Value Loss": 27.117420196533203, "_runtime": 9029.089094877243, "_timestamp": 1585578944.9337282, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20185586810112, "Value Loss": 0.655847430229187, "_runtime": 9029.919621944427, "_timestamp": 1585578945.7642553, "_step": 50}
{"Episode reward": 48.79999999999955, "Episode length": 512, "Policy Loss": 1.7590439319610596, "Value Loss": 22.2369327545166, "_runtime": 9030.433287143707, "_timestamp": 1585578946.2779205, "_step": 51}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 3.0977911949157715, "Value Loss": 43.20181655883789, "_runtime": 9031.9852206707, "_timestamp": 1585578947.829854, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.657606840133667, "Value Loss": 21.321372985839844, "_runtime": 9033.51646065712, "_timestamp": 1585578949.361094, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3679759502410889, "Value Loss": 8.979759216308594, "_runtime": 9035.02431178093, "_timestamp": 1585578950.8689451, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2753394842147827, "Value Loss": 8.762835502624512, "_runtime": 9035.939188957214, "_timestamp": 1585578951.7838223, "_step": 55}
{"Episode reward": 43.07495114803261, "Episode length": 570, "Policy Loss": 1.103035807609558, "Value Loss": 59.75044631958008, "_runtime": 9037.39384007454, "_timestamp": 1585578953.2384734, "_step": 56}
{"Episode reward": 7.436226361990961, "Episode length": 926, "Policy Loss": 1.260172963142395, "Value Loss": 15.103153228759766, "_runtime": 9038.618938684464, "_timestamp": 1585578954.463572, "_step": 57}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.5523694753646851, "Value Loss": 15.559619903564453, "_runtime": 9039.994681835175, "_timestamp": 1585578955.8393152, "_step": 58}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": 0.08322853595018387, "Value Loss": 14.561909675598145, "_runtime": 9040.61016201973, "_timestamp": 1585578956.4547954, "_step": 59}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 0.741972804069519, "Value Loss": 44.43758773803711, "_runtime": 9041.63380074501, "_timestamp": 1585578957.478434, "_step": 60}
{"Episode reward": 33.799999999999486, "Episode length": 662, "Policy Loss": -0.16396555304527283, "Value Loss": 31.899499893188477, "_runtime": 9043.19622516632, "_timestamp": 1585578959.0408585, "_step": 61}
{"Episode reward": -99.84238022714713, "Episode length": 999, "Policy Loss": -1.8761518001556396, "Value Loss": 5.363724231719971, "_runtime": 9044.703656196594, "_timestamp": 1585578960.5482895, "_step": 62}
{"Episode reward": -99.80020510107138, "Episode length": 999, "Policy Loss": -1.9756968021392822, "Value Loss": 2.4643495082855225, "_runtime": 9046.243653059006, "_timestamp": 1585578962.0882864, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8979777097702026, "Value Loss": 1.9407427310943604, "_runtime": 9047.031600475311, "_timestamp": 1585578962.8762338, "_step": 64}
{"Episode reward": 54.04134444594346, "Episode length": 460, "Policy Loss": -0.27007314562797546, "Value Loss": 22.97115707397461, "_runtime": 9048.593716144562, "_timestamp": 1585578964.4383495, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9984434843063354, "Value Loss": 0.12105678766965866, "_runtime": 9049.341912031174, "_timestamp": 1585578965.1865454, "_step": 66}
{"Episode reward": 53.19999999999961, "Episode length": 468, "Policy Loss": 0.057485830038785934, "Value Loss": 21.0454044342041, "_runtime": 9050.570671081543, "_timestamp": 1585578966.4153044, "_step": 67}
{"Episode reward": 19.895819292962827, "Episode length": 802, "Policy Loss": -0.7362217903137207, "Value Loss": 12.822187423706055, "_runtime": 9052.129014253616, "_timestamp": 1585578967.9736476, "_step": 68}
{"Episode reward": -99.80653391480305, "Episode length": 999, "Policy Loss": -1.8206708431243896, "Value Loss": 0.7408335208892822, "_runtime": 9053.652122020721, "_timestamp": 1585578969.4967554, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8902307748794556, "Value Loss": 1.1194754838943481, "_runtime": 9055.203848361969, "_timestamp": 1585578971.0484817, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8455878496170044, "Value Loss": 4.116659164428711, "_runtime": 9056.296953678131, "_timestamp": 1585578972.141587, "_step": 71}
{"Episode reward": 30.75013902187314, "Episode length": 693, "Policy Loss": -0.7598975300788879, "Value Loss": 17.719858169555664, "_runtime": 9057.861518859863, "_timestamp": 1585578973.7061522, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6745582818984985, "Value Loss": 2.2682740688323975, "_runtime": 9058.903575658798, "_timestamp": 1585578974.748209, "_step": 73}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": -0.8926519155502319, "Value Loss": 17.811870574951172, "_runtime": 9060.444759607315, "_timestamp": 1585578976.289393, "_step": 74}
{"Episode reward": -99.81376199871161, "Episode length": 999, "Policy Loss": -2.160611391067505, "Value Loss": 1.4684481620788574, "_runtime": 9062.018377542496, "_timestamp": 1585578977.863011, "_step": 75}
{"Episode reward": -99.74716441184142, "Episode length": 999, "Policy Loss": -2.132239580154419, "Value Loss": 1.376209020614624, "_runtime": 9063.559304475784, "_timestamp": 1585578979.4039378, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3030338287353516, "Value Loss": 0.2572558522224426, "_runtime": 9064.699560880661, "_timestamp": 1585578980.5441942, "_step": 77}
{"Episode reward": 27.278832362592084, "Episode length": 728, "Policy Loss": -1.1191633939743042, "Value Loss": 13.914789199829102, "_runtime": 9066.273739099503, "_timestamp": 1585578982.1183724, "_step": 78}
{"Episode reward": -99.86569862365583, "Episode length": 999, "Policy Loss": -2.414947509765625, "Value Loss": 0.25327908992767334, "_runtime": 9067.846116304398, "_timestamp": 1585578983.6907496, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3582258224487305, "Value Loss": 0.43124717473983765, "_runtime": 9069.393822669983, "_timestamp": 1585578985.238456, "_step": 80}
{"Episode reward": -99.80557933002571, "Episode length": 999, "Policy Loss": -2.424433469772339, "Value Loss": 0.27647557854652405, "_runtime": 9070.163675069809, "_timestamp": 1585578986.0083084, "_step": 81}
{"Episode reward": 52.799999999999606, "Episode length": 472, "Policy Loss": -0.355180948972702, "Value Loss": 22.4086971282959, "_runtime": 9071.764927387238, "_timestamp": 1585578987.6095607, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1910648345947266, "Value Loss": 0.6873733997344971, "_runtime": 9073.346458435059, "_timestamp": 1585578989.1910918, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.097280740737915, "Value Loss": 0.6103183031082153, "_runtime": 9074.873095989227, "_timestamp": 1585578990.7177293, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1050784587860107, "Value Loss": 0.08354134112596512, "_runtime": 9075.405178546906, "_timestamp": 1585578991.249812, "_step": 85}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 1.1217492818832397, "Value Loss": 33.11544418334961, "_runtime": 9076.084795475006, "_timestamp": 1585578991.9294288, "_step": 86}
{"Episode reward": 57.99999999999968, "Episode length": 420, "Policy Loss": 0.24886012077331543, "Value Loss": 23.851219177246094, "_runtime": 9077.64774441719, "_timestamp": 1585578993.4923778, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5753941535949707, "Value Loss": 0.043808888643980026, "_runtime": 9078.594201087952, "_timestamp": 1585578994.4388344, "_step": 88}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": -0.1352536827325821, "Value Loss": 15.749622344970703, "_runtime": 9079.384959459305, "_timestamp": 1585578995.2295928, "_step": 89}
{"Episode reward": 48.55187448114111, "Episode length": 515, "Policy Loss": 0.2668457329273224, "Value Loss": 19.003463745117188, "_runtime": 9080.930277347565, "_timestamp": 1585578996.7749107, "_step": 90}
{"Episode reward": -99.83169558048108, "Episode length": 999, "Policy Loss": -1.2141362428665161, "Value Loss": 0.52153480052948, "_runtime": 9082.455528974533, "_timestamp": 1585578998.3001623, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0376750230789185, "Value Loss": 0.06212426349520683, "_runtime": 9083.059160470963, "_timestamp": 1585578998.9037938, "_step": 92}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 0.7877771258354187, "Value Loss": 26.109230041503906, "_runtime": 9084.176054239273, "_timestamp": 1585579000.0206876, "_step": 93}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": -0.00207588542252779, "Value Loss": 14.656098365783691, "_runtime": 9085.053065776825, "_timestamp": 1585579000.897699, "_step": 94}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.40628501772880554, "Value Loss": 17.56195068359375, "_runtime": 9086.562865257263, "_timestamp": 1585579002.4074986, "_step": 95}
{"Episode reward": -99.85101293474295, "Episode length": 999, "Policy Loss": -1.1054844856262207, "Value Loss": 0.35921311378479004, "_runtime": 9087.334617376328, "_timestamp": 1585579003.1792507, "_step": 96}
{"Episode reward": 51.47158245891291, "Episode length": 486, "Policy Loss": 0.3532416820526123, "Value Loss": 20.253381729125977, "_runtime": 9087.90369939804, "_timestamp": 1585579003.7483327, "_step": 97}
{"Episode reward": 63.999999999999766, "Episode length": 360, "Policy Loss": 0.9176130294799805, "Value Loss": 26.77830696105957, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868, 0.030060861259698868]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.8270356059074402, -0.7176681160926819, -0.6083006262779236, -0.49893316626548767, -0.38956567645072937, -0.28019821643829346, -0.17083072662353516, -0.061463236808776855, 0.047904253005981445, 0.15727174282073975, 0.26663917303085327, 0.3760066628456116, 0.4853741526603699, 0.5947416424751282, 0.7041091322898865, 0.8134766221046448, 0.9228441119194031, 1.0322115421295166, 1.1415791511535645, 1.2509465217590332, 1.360313892364502, 1.4696815013885498, 1.5790488719940186, 1.6884164810180664, 1.7977838516235352, 1.907151460647583, 2.0165188312530518, 2.1258864402770996, 2.2352538108825684, 2.344621419906616, 2.453988790512085, 2.563356399536133, 2.6727237701416016, 2.7820911407470703, 2.891458749771118, 3.000826120376587, 3.1101937294006348, 3.2195613384246826, 3.3289287090301514, 3.43829607963562, 3.547663450241089, 3.657031297683716, 3.7663986682891846, 3.8757660388946533, 3.985133409500122, 4.094501495361328, 4.203868865966797, 4.313236236572266, 4.422603607177734, 4.531970977783203, 4.64133882522583, 4.750706195831299, 4.860073566436768, 4.969440937042236, 5.078808784484863, 5.188176155090332, 5.297543525695801, 5.4069108963012695, 5.5162787437438965, 5.625646114349365, 5.735013484954834, 5.844380855560303, 5.95374870300293, 6.063116073608398, 6.172483444213867]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.06933621317148209, -0.06669116765260696, -0.06404611468315125, -0.06140106916427612, -0.0587560199201107, -0.05611097067594528, -0.05346592515707016, -0.05082087591290474, -0.04817582666873932, -0.0455307774245739, -0.04288572818040848, -0.040240682661533356, -0.037595633417367935, -0.034950584173202515, -0.03230553865432739, -0.029660489410161972, -0.02701544016599655, -0.02437039092183113, -0.02172534167766571, -0.01908029615879059, -0.016435246914625168, -0.013790197670459747, -0.011145152151584625, -0.008500102907419205, -0.005855053663253784, -0.003210008144378662, -0.0005649551749229431, 0.002080090343952179, 0.004725135862827301, 0.00737018883228302, 0.010015234351158142, 0.012660287320613861, 0.015305332839488983, 0.017950378358364105, 0.020595431327819824, 0.023240476846694946, 0.025885529816150665, 0.028530575335025787, 0.03117562085390091, 0.03382067382335663, 0.03646571934223175, 0.03911076486110687, 0.04175581783056259, 0.044400863349437714, 0.047045908868312836, 0.049690961837768555, 0.05233600735664368, 0.054981060326099396, 0.05762610584497452, 0.06027115136384964, 0.06291619688272476, 0.06556125730276108, 0.0682063028216362, 0.07085134834051132, 0.07349639385938644, 0.07614143937826157, 0.07878648489713669, 0.081431545317173, 0.08407659083604813, 0.08672163635492325, 0.08936668187379837, 0.09201172739267349, 0.09465678781270981, 0.09730183333158493, 0.09994687885046005]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 2.0, 9.0, 11.0, 28.0, 12.0, 15.0, 3.0, 7.0, 318.0, 8.0, 4.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 5.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 10.0, 2.0, 8.0, 4.0, 2.0, 2.0, 2.0], "bins": [-0.5916330218315125, -0.57160884141922, -0.5515846610069275, -0.531560480594635, -0.5115363001823425, -0.49151211977005005, -0.47148793935775757, -0.4514637589454651, -0.4314395785331726, -0.4114153981208801, -0.39139121770858765, -0.37136703729629517, -0.3513428568840027, -0.3313186764717102, -0.3112944960594177, -0.29127031564712524, -0.27124613523483276, -0.2512219548225403, -0.2311977744102478, -0.21117359399795532, -0.19114941358566284, -0.17112523317337036, -0.15110105276107788, -0.1310768723487854, -0.11105269193649292, -0.09102851152420044, -0.07100433111190796, -0.05098015069961548, -0.030955970287322998, -0.010931789875030518, 0.009092390537261963, 0.029116570949554443, 0.049140751361846924, 0.0691649317741394, 0.08918911218643188, 0.10921329259872437, 0.12923747301101685, 0.14926165342330933, 0.1692858338356018, 0.1893100142478943, 0.20933419466018677, 0.22935837507247925, 0.24938255548477173, 0.2694067358970642, 0.2894309163093567, 0.30945509672164917, 0.32947927713394165, 0.34950345754623413, 0.3695276379585266, 0.3895518183708191, 0.4095759987831116, 0.42960017919540405, 0.44962435960769653, 0.469648540019989, 0.4896727204322815, 0.509696900844574, 0.5297210812568665, 0.5497452616691589, 0.5697694420814514, 0.5897936224937439, 0.6098178029060364, 0.6298419833183289, 0.6498661637306213, 0.6698903441429138, 0.6899145245552063]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 7.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6272937059402466, -0.5824662446975708, -0.5376388430595398, -0.492811381816864, -0.4479839503765106, -0.4031565189361572, -0.35832905769348145, -0.31350162625312805, -0.26867419481277466, -0.22384676337242126, -0.17901933193206787, -0.1341918706893921, -0.08936440944671631, -0.0445370078086853, 0.0002904534339904785, 0.045117855072021484, 0.08994531631469727, 0.13477277755737305, 0.17960017919540405, 0.22442764043807983, 0.26925504207611084, 0.3140825033187866, 0.3589099645614624, 0.4037374258041382, 0.44856488704681396, 0.4933922290802002, 0.538219690322876, 0.5830471515655518, 0.6278746128082275, 0.6727020740509033, 0.7175294160842896, 0.7623568773269653, 0.8071843385696411, 0.8520117998123169, 0.8968392610549927, 0.9416666030883789, 0.9864940643310547, 1.0313215255737305, 1.0761489868164062, 1.120976448059082, 1.1658037900924683, 1.210631251335144, 1.2554587125778198, 1.3002861738204956, 1.3451136350631714, 1.3899410963058472, 1.434768557548523, 1.4795960187911987, 1.5244234800338745, 1.5692507028579712, 1.614078164100647, 1.6589056253433228, 1.7037330865859985, 1.7485605478286743, 1.79338800907135, 1.8382154703140259, 1.8830429315567017, 1.9278703927993774, 1.9726978540420532, 2.0175251960754395, 2.0623526573181152, 2.107180118560791, 2.152007579803467, 2.1968350410461426, 2.2416625022888184]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 19.0, 6.0, 2.0, 3.0, 1.0], "bins": [-2.1847712993621826, -2.147961139678955, -2.1111512184143066, -2.074341058731079, -2.0375308990478516, -2.000720739364624, -1.963910698890686, -1.927100658416748, -1.8902904987335205, -1.8534804582595825, -1.816670298576355, -1.779860258102417, -1.7430500984191895, -1.7062400579452515, -1.6694300174713135, -1.632619857788086, -1.5958096981048584, -1.5589996576309204, -1.5221896171569824, -1.4853794574737549, -1.4485692977905273, -1.4117592573165894, -1.3749492168426514, -1.3381390571594238, -1.3013290166854858, -1.2645189762115479, -1.2277088165283203, -1.1908986568450928, -1.1540886163711548, -1.1172784566879272, -1.0804684162139893, -1.0436582565307617, -1.0068482160568237, -0.9700381755828857, -0.9332280158996582, -0.8964179754257202, -0.8596078157424927, -0.8227977752685547, -0.7859876155853271, -0.7491775751113892, -0.7123674154281616, -0.6755573749542236, -0.6387472152709961, -0.6019371747970581, -0.5651270151138306, -0.5283169746398926, -0.49150681495666504, -0.45469677448272705, -0.41788673400878906, -0.3810765743255615, -0.34426653385162354, -0.307456374168396, -0.270646333694458, -0.23383617401123047, -0.19702613353729248, -0.1602160930633545, -0.12340593338012695, -0.08659577369689941, -0.049785614013671875, -0.012975692749023438, 0.0238344669342041, 0.06064462661743164, 0.09745478630065918, 0.13426470756530762, 0.17107486724853516]}, "_runtime": 9088.911643981934, "_timestamp": 1585579004.7562773, "_step": 98}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": -0.21649721264839172, "Value Loss": 15.235103607177734, "_runtime": 9090.43428182602, "_timestamp": 1585579006.2789152, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4598478078842163, "Value Loss": 0.08012668788433075, "_runtime": 9091.940802812576, "_timestamp": 1585579007.7854362, "_step": 100}
{"Episode reward": -99.72926841378073, "Episode length": 999, "Policy Loss": -1.603316068649292, "Value Loss": 0.09275487810373306, "_runtime": 9092.81974196434, "_timestamp": 1585579008.6643753, "_step": 101}
{"Episode reward": 43.79996691793151, "Episode length": 563, "Policy Loss": -0.2671670913696289, "Value Loss": 17.282508850097656, "_runtime": 9093.900210380554, "_timestamp": 1585579009.7448437, "_step": 102}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": -0.5558679699897766, "Value Loss": 14.14816951751709, "_runtime": 9095.052867650986, "_timestamp": 1585579010.897501, "_step": 103}
{"Episode reward": 28.299999999999798, "Episode length": 717, "Policy Loss": -0.7226992249488831, "Value Loss": 13.700410842895508, "_runtime": 9096.57931137085, "_timestamp": 1585579012.4239447, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9200674295425415, "Value Loss": 0.06568796187639236, "_runtime": 9098.113321304321, "_timestamp": 1585579013.9579546, "_step": 105}
{"Episode reward": -99.80515520572523, "Episode length": 999, "Policy Loss": -1.9765806198120117, "Value Loss": 0.05686013028025627, "_runtime": 9099.635008335114, "_timestamp": 1585579015.4796417, "_step": 106}
{"Episode reward": 0.8645719289793306, "Episode length": 992, "Policy Loss": -1.1815593242645264, "Value Loss": 9.874218940734863, "_runtime": 9101.205002784729, "_timestamp": 1585579017.0496361, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.059671640396118, "Value Loss": 0.0678093433380127, "_runtime": 9102.766373872757, "_timestamp": 1585579018.6110072, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.076437473297119, "Value Loss": 0.07326622307300568, "_runtime": 9104.11899113655, "_timestamp": 1585579019.9636245, "_step": 109}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": -1.1346763372421265, "Value Loss": 11.253677368164062, "_runtime": 9105.691256523132, "_timestamp": 1585579021.5358899, "_step": 110}
{"Episode reward": -99.80045076012472, "Episode length": 999, "Policy Loss": -2.0965535640716553, "Value Loss": 0.07044630497694016, "_runtime": 9107.267662763596, "_timestamp": 1585579023.112296, "_step": 111}
{"Episode reward": -99.81310878395894, "Episode length": 999, "Policy Loss": -2.1176764965057373, "Value Loss": 0.1105436459183693, "_runtime": 9107.542408704758, "_timestamp": 1585579023.387042, "_step": 112}
{"Episode reward": 86.20000000000005, "Episode length": 138, "Policy Loss": 3.837069272994995, "Value Loss": 69.99209594726562, "_runtime": 9109.104001522064, "_timestamp": 1585579024.9486349, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0821709632873535, "Value Loss": 0.0952606052160263, "_runtime": 9110.678953170776, "_timestamp": 1585579026.5235865, "_step": 114}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": -1.2843438386917114, "Value Loss": 9.828232765197754, "_runtime": 9112.171398162842, "_timestamp": 1585579028.0160315, "_step": 115}
{"Episode reward": -99.80013952851156, "Episode length": 999, "Policy Loss": -2.0421273708343506, "Value Loss": 0.08051566779613495, "_runtime": 9113.750940322876, "_timestamp": 1585579029.5955737, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0545814037323, "Value Loss": 0.19832593202590942, "_runtime": 9115.32984828949, "_timestamp": 1585579031.1744816, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1438021659851074, "Value Loss": 0.5668666958808899, "_runtime": 9116.272632598877, "_timestamp": 1585579032.117266, "_step": 118}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": -0.7518088817596436, "Value Loss": 16.21992301940918, "_runtime": 9117.038515806198, "_timestamp": 1585579032.8831491, "_step": 119}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": -0.05801739543676376, "Value Loss": 20.725502014160156, "_runtime": 9118.660404205322, "_timestamp": 1585579034.5050375, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0712151527404785, "Value Loss": 0.07972326874732971, "_runtime": 9120.193817615509, "_timestamp": 1585579036.038451, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.102947473526001, "Value Loss": 0.06978444755077362, "_runtime": 9121.730029582977, "_timestamp": 1585579037.574663, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1105284690856934, "Value Loss": 0.08849060535430908, "_runtime": 9123.31698513031, "_timestamp": 1585579039.1616185, "_step": 123}
{"Episode reward": -99.69676883965592, "Episode length": 999, "Policy Loss": -2.1362357139587402, "Value Loss": 0.161010280251503, "_runtime": 9124.034219503403, "_timestamp": 1585579039.8788528, "_step": 124}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": -0.37984389066696167, "Value Loss": 22.493864059448242, "_runtime": 9125.357462644577, "_timestamp": 1585579041.202096, "_step": 125}
{"Episode reward": 15.100000000000549, "Episode length": 849, "Policy Loss": -1.1511693000793457, "Value Loss": 11.444588661193848, "_runtime": 9126.94947719574, "_timestamp": 1585579042.7941105, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0810306072235107, "Value Loss": 0.0874733254313469, "_runtime": 9128.023462057114, "_timestamp": 1585579043.8680954, "_step": 127}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": -0.925563395023346, "Value Loss": 14.002283096313477, "_runtime": 9129.231612682343, "_timestamp": 1585579045.076246, "_step": 128}
{"Episode reward": 22.99357793331157, "Episode length": 771, "Policy Loss": -1.0253217220306396, "Value Loss": 12.70610523223877, "_runtime": 9130.81647348404, "_timestamp": 1585579046.6611068, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9977980852127075, "Value Loss": 0.07185910642147064, "_runtime": 9132.362105607986, "_timestamp": 1585579048.206739, "_step": 130}
{"Episode reward": -99.76001713871817, "Episode length": 999, "Policy Loss": -1.9654672145843506, "Value Loss": 0.0676809772849083, "_runtime": 9133.534254550934, "_timestamp": 1585579049.378888, "_step": 131}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": -0.7973349094390869, "Value Loss": 13.059198379516602, "_runtime": 9135.122861623764, "_timestamp": 1585579050.967495, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.86582350730896, "Value Loss": 0.046795282512903214, "_runtime": 9136.0494556427, "_timestamp": 1585579051.894089, "_step": 133}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": -0.765082061290741, "Value Loss": 54.813758850097656, "_runtime": 9136.814240694046, "_timestamp": 1585579052.658874, "_step": 134}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": -0.14153559505939484, "Value Loss": 20.25188446044922, "_runtime": 9138.400330781937, "_timestamp": 1585579054.2449641, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.03094220161438, "Value Loss": 0.06599048525094986, "_runtime": 9139.332209825516, "_timestamp": 1585579055.1768432, "_step": 136}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": -0.7662527561187744, "Value Loss": 16.2310848236084, "_runtime": 9140.539800167084, "_timestamp": 1585579056.3844335, "_step": 137}
{"Episode reward": 20.578469543159244, "Episode length": 796, "Policy Loss": -0.9935795068740845, "Value Loss": 12.143160820007324, "_runtime": 9141.35952615738, "_timestamp": 1585579057.2041595, "_step": 138}
{"Episode reward": 49.59831304550127, "Episode length": 505, "Policy Loss": -0.626384437084198, "Value Loss": 19.1019344329834, "_runtime": 9142.943697214127, "_timestamp": 1585579058.7883306, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.299553871154785, "Value Loss": 0.10835593938827515, "_runtime": 9143.445053339005, "_timestamp": 1585579059.2896867, "_step": 140}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 0.35568785667419434, "Value Loss": 31.6483211517334, "_runtime": 9144.987562894821, "_timestamp": 1585579060.8321962, "_step": 141}
{"Episode reward": -99.80423934012512, "Episode length": 999, "Policy Loss": -2.338348627090454, "Value Loss": 0.23254640400409698, "_runtime": 9146.31410574913, "_timestamp": 1585579062.158739, "_step": 142}
{"Episode reward": 15.700000000000514, "Episode length": 843, "Policy Loss": -1.4253848791122437, "Value Loss": 11.502351760864258, "_runtime": 9147.413600683212, "_timestamp": 1585579063.258234, "_step": 143}
{"Episode reward": 27.099999999999866, "Episode length": 729, "Policy Loss": -1.435214638710022, "Value Loss": 13.812865257263184, "_runtime": 9148.98237490654, "_timestamp": 1585579064.8270082, "_step": 144}
{"Episode reward": -99.80670349746802, "Episode length": 999, "Policy Loss": -2.4257826805114746, "Value Loss": 0.2992110848426819, "_runtime": 9149.759656190872, "_timestamp": 1585579065.6042895, "_step": 145}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": -0.8740494251251221, "Value Loss": 19.889245986938477, "_runtime": 9150.935750484467, "_timestamp": 1585579066.7803838, "_step": 146}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": -1.4163930416107178, "Value Loss": 12.60947036743164, "_runtime": 9152.517409801483, "_timestamp": 1585579068.3620431, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4439492225646973, "Value Loss": 0.22398516535758972, "_runtime": 9153.641103982925, "_timestamp": 1585579069.4857373, "_step": 148}
{"Episode reward": 27.096031188964716, "Episode length": 730, "Policy Loss": -1.4061801433563232, "Value Loss": 13.29080581665039, "_runtime": 9155.186620950699, "_timestamp": 1585579071.0312543, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5584843158721924, "Value Loss": 0.518721878528595, "_runtime": 9156.473685979843, "_timestamp": 1585579072.3183193, "_step": 150}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": -1.5606082677841187, "Value Loss": 11.979450225830078, "_runtime": 9158.02338385582, "_timestamp": 1585579073.8680172, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5661025047302246, "Value Loss": 0.11994047462940216, "_runtime": 9159.590493917465, "_timestamp": 1585579075.4351273, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5213637351989746, "Value Loss": 0.1751703917980194, "_runtime": 9161.145154714584, "_timestamp": 1585579076.989788, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5932400226593018, "Value Loss": 0.1474767029285431, "_runtime": 9162.7275660038, "_timestamp": 1585579078.5721993, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.553353786468506, "Value Loss": 0.10782930254936218, "_runtime": 9164.304452180862, "_timestamp": 1585579080.1490855, "_step": 155}
{"Episode reward": -99.84825262762466, "Episode length": 999, "Policy Loss": -2.516031503677368, "Value Loss": 0.1461094319820404, "_runtime": 9165.933646440506, "_timestamp": 1585579081.7782798, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4900567531585693, "Value Loss": 0.12815548479557037, "_runtime": 9167.519531488419, "_timestamp": 1585579083.3641648, "_step": 157}
{"Episode reward": -99.81601172089437, "Episode length": 999, "Policy Loss": -2.4550068378448486, "Value Loss": 0.1100524514913559, "_runtime": 9169.105588197708, "_timestamp": 1585579084.9502215, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3614585399627686, "Value Loss": 0.21277739107608795, "_runtime": 9169.862235069275, "_timestamp": 1585579085.7068684, "_step": 159}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": -0.5429267883300781, "Value Loss": 21.705244064331055, "_runtime": 9170.818963766098, "_timestamp": 1585579086.663597, "_step": 160}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": -1.07407808303833, "Value Loss": 17.178434371948242, "_runtime": 9171.415893793106, "_timestamp": 1585579087.2605271, "_step": 161}
{"Episode reward": 64.09999999999977, "Episode length": 359, "Policy Loss": 0.20143407583236694, "Value Loss": 26.79418182373047, "_runtime": 9172.950464010239, "_timestamp": 1585579088.7950974, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9531956911087036, "Value Loss": 0.08338772505521774, "_runtime": 9173.210904359818, "_timestamp": 1585579089.0555377, "_step": 163}
{"Episode reward": 86.30000000000004, "Episode length": 137, "Policy Loss": 4.065109729766846, "Value Loss": 70.10895538330078, "_runtime": 9174.73591208458, "_timestamp": 1585579090.5805454, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7069302797317505, "Value Loss": 0.05320998281240463, "_runtime": 9175.404386281967, "_timestamp": 1585579091.2490196, "_step": 165}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 0.3672903776168823, "Value Loss": 23.5054874420166, "_runtime": 9176.897853851318, "_timestamp": 1585579092.7424872, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5498751401901245, "Value Loss": 0.47519367933273315, "_runtime": 9178.469860315323, "_timestamp": 1585579094.3144937, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4150633811950684, "Value Loss": 0.1317359358072281, "_runtime": 9179.689932823181, "_timestamp": 1585579095.5345662, "_step": 168}
{"Episode reward": 19.900000000000276, "Episode length": 801, "Policy Loss": -0.5749183297157288, "Value Loss": 12.753145217895508, "_runtime": 9181.258525848389, "_timestamp": 1585579097.1031592, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3256542682647705, "Value Loss": 0.19388064742088318, "_runtime": 9182.626296758652, "_timestamp": 1585579098.47093, "_step": 170}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": -0.3112764060497284, "Value Loss": 11.465021133422852, "_runtime": 9184.17699956894, "_timestamp": 1585579100.021633, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4450260400772095, "Value Loss": 0.30576273798942566, "_runtime": 9185.739152431488, "_timestamp": 1585579101.5837858, "_step": 172}
{"Episode reward": -99.81003447919944, "Episode length": 999, "Policy Loss": -1.4067919254302979, "Value Loss": 0.09745173901319504, "_runtime": 9186.799374580383, "_timestamp": 1585579102.644008, "_step": 173}
{"Episode reward": 33.5999999999995, "Episode length": 664, "Policy Loss": -0.20927730202674866, "Value Loss": 14.499314308166504, "_runtime": 9188.373000144958, "_timestamp": 1585579104.2176335, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.51229727268219, "Value Loss": 0.10974153131246567, "_runtime": 9189.988900184631, "_timestamp": 1585579105.8335335, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5227054357528687, "Value Loss": 0.08367994427680969, "_runtime": 9191.53984618187, "_timestamp": 1585579107.3844795, "_step": 176}
{"Episode reward": -99.8320539534078, "Episode length": 999, "Policy Loss": -1.5515316724777222, "Value Loss": 0.049149952828884125, "_runtime": 9192.750165700912, "_timestamp": 1585579108.594799, "_step": 177}
{"Episode reward": 23.0000000000001, "Episode length": 770, "Policy Loss": -0.48824480175971985, "Value Loss": 12.718411445617676, "_runtime": 9194.320132255554, "_timestamp": 1585579110.1647656, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5250152349472046, "Value Loss": 0.09537000209093094, "_runtime": 9195.898227930069, "_timestamp": 1585579111.7428613, "_step": 179}
{"Episode reward": -99.89138071685889, "Episode length": 999, "Policy Loss": -1.5254484415054321, "Value Loss": 0.06910485774278641, "_runtime": 9197.450945854187, "_timestamp": 1585579113.2955792, "_step": 180}
{"Episode reward": -99.89902582168439, "Episode length": 999, "Policy Loss": -1.439884901046753, "Value Loss": 0.168953999876976, "_runtime": 9199.012777805328, "_timestamp": 1585579114.8574111, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3871711492538452, "Value Loss": 0.16122542321681976, "_runtime": 9200.59075808525, "_timestamp": 1585579116.4353914, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3374284505844116, "Value Loss": 0.03734574839472771, "_runtime": 9202.159945964813, "_timestamp": 1585579118.0045793, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2470526695251465, "Value Loss": 0.04085560142993927, "_runtime": 9203.725691080093, "_timestamp": 1585579119.5703244, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1571813821792603, "Value Loss": 0.05037824064493179, "_runtime": 9205.31744980812, "_timestamp": 1585579121.1620831, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0794326066970825, "Value Loss": 0.035611554980278015, "_runtime": 9206.62135887146, "_timestamp": 1585579122.4659922, "_step": 186}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.5748793482780457, "Value Loss": 11.74000358581543, "_runtime": 9207.991319417953, "_timestamp": 1585579123.8359528, "_step": 187}
{"Episode reward": 12.197268146277196, "Episode length": 879, "Policy Loss": -0.00386614678427577, "Value Loss": 11.02123737335205, "_runtime": 9209.559029340744, "_timestamp": 1585579125.4036627, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8404659032821655, "Value Loss": 0.025539668276906013, "_runtime": 9211.10437989235, "_timestamp": 1585579126.9490132, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8454273343086243, "Value Loss": 0.12736618518829346, "_runtime": 9212.650384902954, "_timestamp": 1585579128.4950182, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7350789904594421, "Value Loss": 0.01931300200521946, "_runtime": 9213.925297498703, "_timestamp": 1585579129.7699308, "_step": 191}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": 0.29475173354148865, "Value Loss": 12.440605163574219, "_runtime": 9215.492277860641, "_timestamp": 1585579131.3369112, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6584306955337524, "Value Loss": 0.04449616000056267, "_runtime": 9216.613820791245, "_timestamp": 1585579132.4584541, "_step": 193}
{"Episode reward": 28.59999999999978, "Episode length": 714, "Policy Loss": 0.4415971040725708, "Value Loss": 13.618145942687988, "_runtime": 9218.163400888443, "_timestamp": 1585579134.0080342, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6229572892189026, "Value Loss": 0.053112730383872986, "_runtime": 9219.728405475616, "_timestamp": 1585579135.5730388, "_step": 195}
{"Episode reward": -99.83078136592964, "Episode length": 999, "Policy Loss": -0.66324782371521, "Value Loss": 0.1359221339225769, "_runtime": 9221.260524272919, "_timestamp": 1585579137.1051576, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6209815144538879, "Value Loss": 0.011526371352374554, "_runtime": 9222.817523241043, "_timestamp": 1585579138.6621566, "_step": 197}
{"Episode reward": -99.84215800911048, "Episode length": 999, "Policy Loss": -0.6264740228652954, "Value Loss": 0.01577340066432953, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376, -0.025706514716148376]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.238445281982422, -8.081061363220215, -7.92367696762085, -7.766293048858643, -7.608908653259277, -7.45152473449707, -7.294140815734863, -7.136756896972656, -6.979372501373291, -6.821988105773926, -6.664604187011719, -6.507220268249512, -6.349836349487305, -6.1924519538879395, -6.035068035125732, -5.877683639526367, -5.72029972076416, -5.562915802001953, -5.405531406402588, -5.248147487640381, -5.090763092041016, -4.933379173278809, -4.775995254516602, -4.6186113357543945, -4.461226940155029, -4.303842544555664, -4.146458625793457, -3.98907470703125, -3.831690788269043, -3.6743063926696777, -3.5169224739074707, -3.3595380783081055, -3.2021541595458984, -3.0447702407836914, -2.887385845184326, -2.730001926422119, -2.572617530822754, -2.415233612060547, -2.25784969329834, -2.1004652976989746, -1.9430813789367676, -1.7856974601745605, -1.6283130645751953, -1.4709291458129883, -1.3135452270507812, -1.156160831451416, -0.998776912689209, -0.8413925170898438, -0.6840085983276367, -0.5266246795654297, -0.36924028396606445, -0.21185588836669922, -0.05447196960449219, 0.10291194915771484, 0.2602958679199219, 0.4176797866821289, 0.5750637054443359, 0.7324485778808594, 0.8898324966430664, 1.0472164154052734, 1.2046003341674805, 1.3619842529296875, 1.519369125366211, 1.676753044128418, 1.834136962890625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15918272733688354, -0.1555103063583374, -0.15183787047863007, -0.14816544950008392, -0.1444930136203766, -0.14082059264183044, -0.1371481567621231, -0.13347573578357697, -0.12980329990386963, -0.1261308789253235, -0.12245844304561615, -0.11878602206707001, -0.11511359363794327, -0.11144116520881653, -0.10776873677968979, -0.10409630835056305, -0.10042387992143631, -0.09675145149230957, -0.09307902306318283, -0.08940659463405609, -0.08573416620492935, -0.08206173777580261, -0.07838930934667587, -0.07471688091754913, -0.07104445993900299, -0.06737203150987625, -0.06369960308074951, -0.06002717465162277, -0.05635474622249603, -0.05268231779336929, -0.049009889364242554, -0.045337460935115814, -0.041665032505989075, -0.037992604076862335, -0.034320175647735596, -0.030647754669189453, -0.026975318789482117, -0.023302897810935974, -0.019630461931228638, -0.015958040952682495, -0.012285605072975159, -0.008613184094429016, -0.00494074821472168, -0.0012683272361755371, 0.0024041086435317993, 0.006076529622077942, 0.009748965501785278, 0.013421386480331421, 0.017093807458877563, 0.0207662433385849, 0.024438664317131042, 0.02811110019683838, 0.03178352117538452, 0.03545595705509186, 0.039128378033638, 0.04280081391334534, 0.04647323489189148, 0.050145670771598816, 0.05381809175014496, 0.057490527629852295, 0.06116294860839844, 0.06483538448810577, 0.06850780546665192, 0.07218024134635925, 0.0758526623249054]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 5.0, 3.0, 5.0, 5.0, 6.0, 2.0, 2.0, 3.0, 6.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 6.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 0.0, 6.0, 7.0, 23.0, 289.0, 10.0, 17.0, 24.0, 16.0, 10.0, 6.0, 4.0, 4.0, 4.0, 7.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-1.0006822347640991, -0.9716131687164307, -0.9425441026687622, -0.9134750962257385, -0.8844060301780701, -0.8553369641304016, -0.8262678980827332, -0.7971988916397095, -0.768129825592041, -0.7390607595443726, -0.7099916934967041, -0.6809226274490356, -0.6518535614013672, -0.6227845549583435, -0.593715488910675, -0.5646464824676514, -0.5355774164199829, -0.5065083503723145, -0.477439284324646, -0.44837021827697754, -0.4193011522293091, -0.3902321457862854, -0.36116307973861694, -0.3320940136909485, -0.30302494764328003, -0.2739558815956116, -0.2448868751525879, -0.21581780910491943, -0.18674874305725098, -0.15767967700958252, -0.12861067056655884, -0.09954160451889038, -0.07047253847122192, -0.04140347242355347, -0.01233440637588501, 0.016734600067138672, 0.04580366611480713, 0.07487273216247559, 0.10394179821014404, 0.1330108642578125, 0.16207993030548096, 0.19114899635314941, 0.22021794319152832, 0.24928700923919678, 0.27835607528686523, 0.3074251413345337, 0.33649420738220215, 0.3655632734298706, 0.39463233947753906, 0.4237014055252075, 0.452770471572876, 0.4818394184112549, 0.5109084844589233, 0.5399775505065918, 0.5690466165542603, 0.5981156826019287, 0.6271847486495972, 0.6562538146972656, 0.6853228807449341, 0.7143919467926025, 0.7434608936309814, 0.7725299596786499, 0.8015990257263184, 0.8306680917739868, 0.8597371578216553]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "bins": [-2.4717700481414795, -2.4236793518066406, -2.3755886554718018, -2.327497959136963, -2.279407501220703, -2.2313168048858643, -2.1832261085510254, -2.1351354122161865, -2.0870447158813477, -2.038954019546509, -1.99086332321167, -1.9427727460861206, -1.8946820497512817, -1.8465913534164429, -1.7985007762908936, -1.7504100799560547, -1.7023193836212158, -1.654228687286377, -1.606137990951538, -1.5580474138259888, -1.50995671749115, -1.461866021156311, -1.4137754440307617, -1.3656847476959229, -1.317594051361084, -1.2695033550262451, -1.2214126586914062, -1.173322081565857, -1.125231385231018, -1.0771406888961792, -1.0290501117706299, -0.980959415435791, -0.9328687191009521, -0.8847780227661133, -0.8366873264312744, -0.7885967493057251, -0.7405060529708862, -0.6924153566360474, -0.644324779510498, -0.5962340831756592, -0.5481433868408203, -0.5000526905059814, -0.4519619941711426, -0.4038712978363037, -0.35578083992004395, -0.3076901435852051, -0.2595994472503662, -0.21150875091552734, -0.16341805458068848, -0.11532735824584961, -0.06723666191101074, -0.019145965576171875, 0.028944730758666992, 0.07703518867492676, 0.12512588500976562, 0.1732165813446045, 0.22130727767944336, 0.2693979740142822, 0.3174886703491211, 0.36557936668395996, 0.4136698246002197, 0.4617605209350586, 0.5098512172698975, 0.5579419136047363, 0.6060326099395752]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 0.0, 9.0, 14.0, 15.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3011014461517334, -0.22638848423957825, -0.1516755223274231, -0.07696256041526794, -0.002249598503112793, 0.07246336340904236, 0.1471763253211975, 0.22188925743103027, 0.2966022491455078, 0.37131524085998535, 0.4460281729698181, 0.5207411050796509, 0.5954540967941284, 0.670167088508606, 0.744879961013794, 0.8195929527282715, 0.894305944442749, 0.9690189361572266, 1.043731927871704, 1.118444800376892, 1.1931577920913696, 1.2678707838058472, 1.3425836563110352, 1.4172966480255127, 1.4920096397399902, 1.5667226314544678, 1.6414356231689453, 1.7161486148834229, 1.7908613681793213, 1.8655743598937988, 1.9402873516082764, 2.015000343322754, 2.0897133350372314, 2.164426326751709, 2.2391393184661865, 2.313852310180664, 2.3885653018951416, 2.46327805519104, 2.5379910469055176, 2.612704038619995, 2.6874170303344727, 2.76213002204895, 2.8368430137634277, 2.9115560054779053, 2.9862687587738037, 3.0609817504882812, 3.135694742202759, 3.2104077339172363, 3.285120725631714, 3.3598337173461914, 3.434546709060669, 3.5092597007751465, 3.583972692489624, 3.6586854457855225, 3.733398675918579, 3.8081114292144775, 3.882824182510376, 3.9575374126434326, 4.03225040435791, 4.106963157653809, 4.181675910949707, 4.256389617919922, 4.33110237121582, 4.405815124511719, 4.480527877807617]}, "_runtime": 9223.394650220871, "_timestamp": 1585579139.2392836, "_step": 198}
{"Episode reward": 64.89999999999978, "Episode length": 351, "Policy Loss": 1.750502586364746, "Value Loss": 27.835725784301758, "_runtime": 9224.959913015366, "_timestamp": 1585579140.8045464, "_step": 199}
{"Episode reward": -99.86303491592267, "Episode length": 999, "Policy Loss": -0.6339446902275085, "Value Loss": 0.014905711635947227, "_runtime": 9226.528511762619, "_timestamp": 1585579142.373145, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.648325502872467, "Value Loss": 0.03926395624876022, "_runtime": 9228.026105165482, "_timestamp": 1585579143.8707385, "_step": 201}
{"Episode reward": -99.80764125622669, "Episode length": 999, "Policy Loss": -0.6233787536621094, "Value Loss": 0.013921665959060192, "_runtime": 9229.588601112366, "_timestamp": 1585579145.4332345, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6196062564849854, "Value Loss": 0.01286912988871336, "_runtime": 9230.938650369644, "_timestamp": 1585579146.7832837, "_step": 203}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 0.41066449880599976, "Value Loss": 11.307394981384277, "_runtime": 9232.487577915192, "_timestamp": 1585579148.3322113, "_step": 204}
{"Episode reward": -99.80495758056502, "Episode length": 999, "Policy Loss": -0.5888944268226624, "Value Loss": 0.015672115609049797, "_runtime": 9233.849291563034, "_timestamp": 1585579149.693925, "_step": 205}
{"Episode reward": 13.621610938013234, "Episode length": 864, "Policy Loss": 0.5540964603424072, "Value Loss": 11.30788516998291, "_runtime": 9234.753620147705, "_timestamp": 1585579150.5982535, "_step": 206}
{"Episode reward": 43.39934893697448, "Episode length": 567, "Policy Loss": 0.8985680937767029, "Value Loss": 17.105684280395508, "_runtime": 9236.356092691422, "_timestamp": 1585579152.200726, "_step": 207}
{"Episode reward": -99.81798372864584, "Episode length": 999, "Policy Loss": -0.5078411102294922, "Value Loss": 0.0062624989077448845, "_runtime": 9237.91621518135, "_timestamp": 1585579153.7608485, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5022146105766296, "Value Loss": 0.021936140954494476, "_runtime": 9238.702546834946, "_timestamp": 1585579154.5471802, "_step": 209}
{"Episode reward": 49.99999999999957, "Episode length": 500, "Policy Loss": 1.1027415990829468, "Value Loss": 19.32522201538086, "_runtime": 9239.576753377914, "_timestamp": 1585579155.4213867, "_step": 210}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.9571565389633179, "Value Loss": 17.410356521606445, "_runtime": 9241.145061016083, "_timestamp": 1585579156.9896944, "_step": 211}
{"Episode reward": -99.83842425942281, "Episode length": 999, "Policy Loss": -0.4772639870643616, "Value Loss": 0.028403153643012047, "_runtime": 9242.686398506165, "_timestamp": 1585579158.5310318, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47398045659065247, "Value Loss": 0.02635238505899906, "_runtime": 9244.22758102417, "_timestamp": 1585579160.0722144, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4991280138492584, "Value Loss": 0.053337808698415756, "_runtime": 9245.797304153442, "_timestamp": 1585579161.6419375, "_step": 214}
{"Episode reward": -99.87051324993233, "Episode length": 999, "Policy Loss": -0.5014523267745972, "Value Loss": 0.04660702124238014, "_runtime": 9247.156554698944, "_timestamp": 1585579163.001188, "_step": 215}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": 0.44396477937698364, "Value Loss": 11.282362937927246, "_runtime": 9248.35315990448, "_timestamp": 1585579164.1977932, "_step": 216}
{"Episode reward": 24.385466705262687, "Episode length": 757, "Policy Loss": 0.8360739946365356, "Value Loss": 13.111310958862305, "_runtime": 9249.93674993515, "_timestamp": 1585579165.7813833, "_step": 217}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": 0.1865396946668625, "Value Loss": 9.664047241210938, "_runtime": 9250.563722133636, "_timestamp": 1585579166.4083555, "_step": 218}
{"Episode reward": 61.39999999999973, "Episode length": 386, "Policy Loss": 1.3630529642105103, "Value Loss": 24.83242416381836, "_runtime": 9252.124053239822, "_timestamp": 1585579167.9686866, "_step": 219}
{"Episode reward": -99.8401998102651, "Episode length": 999, "Policy Loss": -0.7774985432624817, "Value Loss": 0.06178050860762596, "_runtime": 9252.881568670273, "_timestamp": 1585579168.726202, "_step": 220}
{"Episode reward": 53.79999999999962, "Episode length": 462, "Policy Loss": 0.9934985041618347, "Value Loss": 20.757116317749023, "_runtime": 9253.964725732803, "_timestamp": 1585579169.809359, "_step": 221}
{"Episode reward": 29.73837213367196, "Episode length": 703, "Policy Loss": 0.23228658735752106, "Value Loss": 13.637473106384277, "_runtime": 9255.546229600906, "_timestamp": 1585579171.390863, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.041495442390442, "Value Loss": 0.07557237893342972, "_runtime": 9256.368998289108, "_timestamp": 1585579172.2136316, "_step": 223}
{"Episode reward": 46.86578564038452, "Episode length": 532, "Policy Loss": 0.42559701204299927, "Value Loss": 18.10114860534668, "_runtime": 9257.915346622467, "_timestamp": 1585579173.75998, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134985089302063, "Value Loss": 0.04117254167795181, "_runtime": 9258.317985534668, "_timestamp": 1585579174.1626189, "_step": 225}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 3.274122714996338, "Value Loss": 43.79106140136719, "_runtime": 9259.865001678467, "_timestamp": 1585579175.709635, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2290130853652954, "Value Loss": 0.0433126762509346, "_runtime": 9260.899219036102, "_timestamp": 1585579176.7438524, "_step": 227}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": -0.18225626647472382, "Value Loss": 16.38705825805664, "_runtime": 9261.686719417572, "_timestamp": 1585579177.5313528, "_step": 228}
{"Episode reward": 47.29999999999953, "Episode length": 527, "Policy Loss": 0.2404652088880539, "Value Loss": 18.09276008605957, "_runtime": 9263.25824713707, "_timestamp": 1585579179.1028805, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3053109645843506, "Value Loss": 0.037349727004766464, "_runtime": 9264.25810098648, "_timestamp": 1585579180.1027343, "_step": 230}
{"Episode reward": 36.39045248841804, "Episode length": 637, "Policy Loss": -0.22708603739738464, "Value Loss": 15.717947006225586, "_runtime": 9265.782248973846, "_timestamp": 1585579181.6268823, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3295451402664185, "Value Loss": 0.061608754098415375, "_runtime": 9266.325608253479, "_timestamp": 1585579182.1702416, "_step": 232}
{"Episode reward": 68.09999999999982, "Episode length": 319, "Policy Loss": 1.5735548734664917, "Value Loss": 30.130733489990234, "_runtime": 9267.321624994278, "_timestamp": 1585579183.1662583, "_step": 233}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": -0.1134703978896141, "Value Loss": 15.205583572387695, "_runtime": 9267.945651769638, "_timestamp": 1585579183.790285, "_step": 234}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 0.8094020485877991, "Value Loss": 24.90108871459961, "_runtime": 9269.188217639923, "_timestamp": 1585579185.032851, "_step": 235}
{"Episode reward": 17.20000000000043, "Episode length": 828, "Policy Loss": -0.32537031173706055, "Value Loss": 11.543423652648926, "_runtime": 9270.737480401993, "_timestamp": 1585579186.5821137, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2759363651275635, "Value Loss": 0.10165863484144211, "_runtime": 9271.473301649094, "_timestamp": 1585579187.317935, "_step": 237}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 0.4403988718986511, "Value Loss": 20.100934982299805, "_runtime": 9272.152995109558, "_timestamp": 1585579187.9976285, "_step": 238}
{"Episode reward": 56.09999999999965, "Episode length": 439, "Policy Loss": 0.5576851963996887, "Value Loss": 21.6396427154541, "_runtime": 9273.719192028046, "_timestamp": 1585579189.5638254, "_step": 239}
{"Episode reward": -99.80773942619422, "Episode length": 999, "Policy Loss": -1.2427349090576172, "Value Loss": 0.11529622972011566, "_runtime": 9275.24846816063, "_timestamp": 1585579191.0931015, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2410215139389038, "Value Loss": 0.08249469846487045, "_runtime": 9276.77152633667, "_timestamp": 1585579192.6161597, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2891989946365356, "Value Loss": 0.237894669175148, "_runtime": 9278.353277921677, "_timestamp": 1585579194.1979113, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2741118669509888, "Value Loss": 0.11614017933607101, "_runtime": 9279.92198562622, "_timestamp": 1585579195.766619, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2517868280410767, "Value Loss": 0.06777402758598328, "_runtime": 9281.487512588501, "_timestamp": 1585579197.332146, "_step": 244}
{"Episode reward": -99.80517184883216, "Episode length": 999, "Policy Loss": -1.2754573822021484, "Value Loss": 0.0671941488981247, "_runtime": 9283.062633514404, "_timestamp": 1585579198.9072669, "_step": 245}
{"Episode reward": -99.70027975588899, "Episode length": 999, "Policy Loss": -1.2717862129211426, "Value Loss": 0.045462097972631454, "_runtime": 9284.686797857285, "_timestamp": 1585579200.5314312, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.29944908618927, "Value Loss": 0.07279802858829498, "_runtime": 9286.284180164337, "_timestamp": 1585579202.1288135, "_step": 247}
{"Episode reward": -99.73770969211917, "Episode length": 999, "Policy Loss": -1.2977311611175537, "Value Loss": 0.06362531334161758, "_runtime": 9287.876157522202, "_timestamp": 1585579203.7207909, "_step": 248}
{"Episode reward": -99.70222077667573, "Episode length": 999, "Policy Loss": -1.2829865217208862, "Value Loss": 0.051866564899683, "_runtime": 9289.45064496994, "_timestamp": 1585579205.2952783, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2899612188339233, "Value Loss": 0.07680906355381012, "_runtime": 9291.027567625046, "_timestamp": 1585579206.872201, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3217276334762573, "Value Loss": 0.23759372532367706, "_runtime": 9292.57580447197, "_timestamp": 1585579208.4204378, "_step": 251}
{"Episode reward": 2.5000000000012648, "Episode length": 975, "Policy Loss": -0.47581326961517334, "Value Loss": 9.885754585266113, "_runtime": 9293.703485965729, "_timestamp": 1585579209.5481193, "_step": 252}
{"Episode reward": 28.99741737209237, "Episode length": 711, "Policy Loss": 0.14787587523460388, "Value Loss": 13.598542213439941, "_runtime": 9295.275988578796, "_timestamp": 1585579211.120622, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.234354853630066, "Value Loss": 0.0792142003774643, "_runtime": 9296.0316426754, "_timestamp": 1585579211.876276, "_step": 254}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 0.6918227672576904, "Value Loss": 20.739253997802734, "_runtime": 9296.663383960724, "_timestamp": 1585579212.5080173, "_step": 255}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 0.7620589137077332, "Value Loss": 24.238527297973633, "_runtime": 9298.230942487717, "_timestamp": 1585579214.0755758, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.131664752960205, "Value Loss": 0.059140704572200775, "_runtime": 9299.002266645432, "_timestamp": 1585579214.8469, "_step": 257}
{"Episode reward": 50.089129005372094, "Episode length": 500, "Policy Loss": 0.5270370244979858, "Value Loss": 19.132654190063477, "_runtime": 9300.511397838593, "_timestamp": 1585579216.3560312, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.024092435836792, "Value Loss": 0.025202851742506027, "_runtime": 9301.500230550766, "_timestamp": 1585579217.344864, "_step": 259}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.4303884208202362, "Value Loss": 15.299698829650879, "_runtime": 9302.13798737526, "_timestamp": 1585579217.9826207, "_step": 260}
{"Episode reward": 58.89354075789421, "Episode length": 412, "Policy Loss": 0.99058997631073, "Value Loss": 23.153362274169922, "_runtime": 9303.693131446838, "_timestamp": 1585579219.5377648, "_step": 261}
{"Episode reward": -99.7475835621343, "Episode length": 999, "Policy Loss": -0.8898932337760925, "Value Loss": 0.04651646688580513, "_runtime": 9304.352834701538, "_timestamp": 1585579220.197468, "_step": 262}
{"Episode reward": 58.19999999999968, "Episode length": 418, "Policy Loss": 1.1579874753952026, "Value Loss": 23.094623565673828, "_runtime": 9305.870123147964, "_timestamp": 1585579221.7147565, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8409548997879028, "Value Loss": 0.06339016556739807, "_runtime": 9307.425387620926, "_timestamp": 1585579223.270021, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8727297782897949, "Value Loss": 0.10552631318569183, "_runtime": 9308.022727489471, "_timestamp": 1585579223.8673608, "_step": 265}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 1.2380234003067017, "Value Loss": 25.20878791809082, "_runtime": 9308.765102863312, "_timestamp": 1585579224.6097362, "_step": 266}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 0.7970402836799622, "Value Loss": 20.426801681518555, "_runtime": 9310.053726434708, "_timestamp": 1585579225.8983598, "_step": 267}
{"Episode reward": 18.35431547015942, "Episode length": 817, "Policy Loss": 0.043741773813962936, "Value Loss": 11.701953887939453, "_runtime": 9311.037251472473, "_timestamp": 1585579226.8818848, "_step": 268}
{"Episode reward": 35.69999999999938, "Episode length": 643, "Policy Loss": 0.14613942801952362, "Value Loss": 14.922021865844727, "_runtime": 9312.561844825745, "_timestamp": 1585579228.4064782, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0581741333007812, "Value Loss": 0.06203681603074074, "_runtime": 9314.121182203293, "_timestamp": 1585579229.9658155, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1367310285568237, "Value Loss": 0.0319669283926487, "_runtime": 9315.684523582458, "_timestamp": 1585579231.529157, "_step": 271}
{"Episode reward": -99.80125029086928, "Episode length": 999, "Policy Loss": -1.1908682584762573, "Value Loss": 0.0808275043964386, "_runtime": 9317.262412071228, "_timestamp": 1585579233.1070454, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.266249656677246, "Value Loss": 0.19462788105010986, "_runtime": 9318.843981027603, "_timestamp": 1585579234.6886144, "_step": 273}
{"Episode reward": -99.88917703628401, "Episode length": 999, "Policy Loss": -1.3054476976394653, "Value Loss": 0.1285238116979599, "_runtime": 9320.411130189896, "_timestamp": 1585579236.2557635, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.309653401374817, "Value Loss": 0.04870517551898956, "_runtime": 9321.739077806473, "_timestamp": 1585579237.5837111, "_step": 275}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": -0.26736143231391907, "Value Loss": 11.429159164428711, "_runtime": 9323.317496299744, "_timestamp": 1585579239.1621296, "_step": 276}
{"Episode reward": -99.72948148995498, "Episode length": 999, "Policy Loss": -1.3507966995239258, "Value Loss": 0.035013165324926376, "_runtime": 9324.657916784286, "_timestamp": 1585579240.5025501, "_step": 277}
{"Episode reward": 15.059730502591094, "Episode length": 850, "Policy Loss": -0.02143530175089836, "Value Loss": 11.520323753356934, "_runtime": 9325.44482922554, "_timestamp": 1585579241.2894626, "_step": 278}
{"Episode reward": 50.499999999999574, "Episode length": 495, "Policy Loss": 0.3401595652103424, "Value Loss": 20.00701904296875, "_runtime": 9326.079273223877, "_timestamp": 1585579241.9239066, "_step": 279}
{"Episode reward": 61.9855132043359, "Episode length": 381, "Policy Loss": 0.887995183467865, "Value Loss": 25.016149520874023, "_runtime": 9327.018972873688, "_timestamp": 1585579242.8636062, "_step": 280}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 0.024194637313485146, "Value Loss": 16.31901741027832, "_runtime": 9328.556735515594, "_timestamp": 1585579244.4013689, "_step": 281}
{"Episode reward": -99.83186073303082, "Episode length": 999, "Policy Loss": -1.072462558746338, "Value Loss": 0.126152902841568, "_runtime": 9330.08334517479, "_timestamp": 1585579245.9279785, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9881061315536499, "Value Loss": 0.05601348355412483, "_runtime": 9331.05040693283, "_timestamp": 1585579246.8950403, "_step": 283}
{"Episode reward": 37.70377233028351, "Episode length": 623, "Policy Loss": 0.14433638751506805, "Value Loss": 15.86627197265625, "_runtime": 9332.623681783676, "_timestamp": 1585579248.4683151, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9098765850067139, "Value Loss": 0.06911821663379669, "_runtime": 9334.187999486923, "_timestamp": 1585579250.0326328, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9105342626571655, "Value Loss": 0.11191937327384949, "_runtime": 9335.494632720947, "_timestamp": 1585579251.339266, "_step": 286}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": 0.05729495361447334, "Value Loss": 11.426259994506836, "_runtime": 9336.64953160286, "_timestamp": 1585579252.494165, "_step": 287}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": 0.2250892072916031, "Value Loss": 13.176976203918457, "_runtime": 9338.263412952423, "_timestamp": 1585579254.1080463, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8727124929428101, "Value Loss": 0.04485362768173218, "_runtime": 9339.069662094116, "_timestamp": 1585579254.9142954, "_step": 289}
{"Episode reward": 49.968974338471455, "Episode length": 501, "Policy Loss": 0.7160622477531433, "Value Loss": 19.209686279296875, "_runtime": 9340.634596824646, "_timestamp": 1585579256.4792302, "_step": 290}
{"Episode reward": -99.82340282350638, "Episode length": 999, "Policy Loss": -0.8567400574684143, "Value Loss": 0.03962128981947899, "_runtime": 9341.015579938889, "_timestamp": 1585579256.8602133, "_step": 291}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 2.8026556968688965, "Value Loss": 44.006351470947266, "_runtime": 9342.519519805908, "_timestamp": 1585579258.3641531, "_step": 292}
{"Episode reward": 2.000000000001293, "Episode length": 980, "Policy Loss": 0.12331777065992355, "Value Loss": 9.86259651184082, "_runtime": 9343.75640821457, "_timestamp": 1585579259.6010416, "_step": 293}
{"Episode reward": 22.750389713049046, "Episode length": 773, "Policy Loss": 0.24104702472686768, "Value Loss": 12.377700805664062, "_runtime": 9344.971507549286, "_timestamp": 1585579260.816141, "_step": 294}
{"Episode reward": 19.480006264150447, "Episode length": 806, "Policy Loss": 0.398794561624527, "Value Loss": 11.919075965881348, "_runtime": 9346.545516967773, "_timestamp": 1585579262.3901503, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7383002042770386, "Value Loss": 0.026723885908722878, "_runtime": 9348.105161905289, "_timestamp": 1585579263.9497952, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6852472424507141, "Value Loss": 0.025189213454723358, "_runtime": 9348.874668598175, "_timestamp": 1585579264.719302, "_step": 297}
{"Episode reward": 51.299999999999585, "Episode length": 487, "Policy Loss": 0.8757855892181396, "Value Loss": 19.81608009338379, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445, -0.01094279158860445]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0], "bins": [-1.3330013751983643, -1.3120023012161255, -1.2910031080245972, -1.2700040340423584, -1.24900484085083, -1.2280057668685913, -1.207006573677063, -1.1860074996948242, -1.165008306503296, -1.1440092325210571, -1.1230101585388184, -1.10201096534729, -1.0810117721557617, -1.060012698173523, -1.0390136241912842, -1.0180144309997559, -0.9970153570175171, -0.9760161638259888, -0.95501708984375, -0.9340179562568665, -0.9130188226699829, -0.8920196890830994, -0.8710205554962158, -0.8500214219093323, -0.8290222883224487, -0.8080231547355652, -0.7870240211486816, -0.7660249471664429, -0.7450258135795593, -0.7240266799926758, -0.7030275464057922, -0.6820284128189087, -0.6610292792320251, -0.6400301456451416, -0.6190310120582581, -0.5980318784713745, -0.577032744884491, -0.5560336112976074, -0.5350345373153687, -0.5140354037284851, -0.49303627014160156, -0.472037136554718, -0.4510380029678345, -0.4300388693809509, -0.4090397357940674, -0.38804060220718384, -0.3670414686203003, -0.34604233503341675, -0.3250432014465332, -0.30404412746429443, -0.2830449342727661, -0.26204586029052734, -0.24104666709899902, -0.22004759311676025, -0.19904851913452148, -0.17804932594299316, -0.1570502519607544, -0.13605105876922607, -0.1150519847869873, -0.09405279159545898, -0.07305371761322021, -0.052054524421691895, -0.031055450439453125, -0.010056257247924805, 0.010942816734313965]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.03638603538274765, -0.035817503929138184, -0.03524897247552872, -0.03468044102191925, -0.034111909568309784, -0.03354337811470032, -0.03297484293580055, -0.032406311482191086, -0.03183778002858162, -0.03126924857497215, -0.030700717121362686, -0.03013218566775322, -0.029563654214143753, -0.028995122760534286, -0.02842659130692482, -0.027858057990670204, -0.027289526537060738, -0.02672099508345127, -0.026152461767196655, -0.02558393031358719, -0.025015398859977722, -0.024446867406368256, -0.02387833595275879, -0.023309804499149323, -0.022741273045539856, -0.02217274159193039, -0.021604208275675774, -0.021035676822066307, -0.02046714536845684, -0.019898613914847374, -0.019330080598592758, -0.01876154914498329, -0.018193017691373825, -0.01762448623776436, -0.017055954784154892, -0.016487421467900276, -0.01591889001429081, -0.015350358560681343, -0.014781827107071877, -0.01421329565346241, -0.013644762337207794, -0.013076230883598328, -0.012507699429988861, -0.011939167976379395, -0.011370636522769928, -0.010802105069160461, -0.010233571752905846, -0.009665040299296379, -0.009096508845686913, -0.008527977392077446, -0.00795944593846798, -0.007390912622213364, -0.006822381168603897, -0.0062538497149944305, -0.005685318261384964, -0.0051167868077754974, -0.004548255354166031, -0.003979723900556564, -0.0034111924469470978, -0.0028426572680473328, -0.002274125814437866, -0.0017055943608283997, -0.001137062907218933, -0.0005685314536094666, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 6.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 11.0, 0.0, 0.0, 2.0, 1.0, 1.0, 324.0, 8.0, 6.0, 13.0, 7.0, 7.0, 7.0, 4.0, 0.0, 4.0, 13.0, 17.0, 10.0], "bins": [-0.15373273193836212, -0.15076576173305511, -0.1477988064289093, -0.1448318362236023, -0.1418648660182953, -0.13889789581298828, -0.13593094050884247, -0.13296397030353546, -0.12999700009822845, -0.12703004479408264, -0.12406307458877563, -0.12109610438346863, -0.11812914162874222, -0.11516217887401581, -0.1121952086687088, -0.10922824591398239, -0.10626128315925598, -0.10329431295394897, -0.10032734274864197, -0.09736038744449615, -0.09439341723918915, -0.09142644703388214, -0.08845948427915573, -0.08549252152442932, -0.08252555131912231, -0.0795585885643959, -0.0765916183590889, -0.07362465560436249, -0.07065769284963608, -0.06769072264432907, -0.06472375988960266, -0.061756789684295654, -0.058789826929569244, -0.055822864174842834, -0.05285589396953583, -0.04988893121480942, -0.04692196100950241, -0.043954998254776, -0.04098803550004959, -0.038021065294742584, -0.035054102540016174, -0.03208713233470917, -0.029120169579982758, -0.026153206825256348, -0.02318623661994934, -0.020219266414642334, -0.01725231111049652, -0.014285340905189514, -0.011318370699882507, -0.008351415395736694, -0.0053844451904296875, -0.0024174749851226807, 0.0005494952201843262, 0.003516450524330139, 0.006483420729637146, 0.009450390934944153, 0.012417346239089966, 0.015384316444396973, 0.01835128664970398, 0.021318241953849792, 0.0242852121591568, 0.027252182364463806, 0.030219152569770813, 0.033186107873916626, 0.03615307807922363]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 6.0, 6.0, 2.0, 2.0], "bins": [-0.7805303931236267, -0.7676766514778137, -0.754822850227356, -0.741969108581543, -0.7291153073310852, -0.7162615656852722, -0.7034077644348145, -0.6905540227890015, -0.6777002215385437, -0.6648464798927307, -0.651992678642273, -0.63913893699646, -0.626285195350647, -0.6134313941001892, -0.6005776524543762, -0.5877238512039185, -0.5748701095581055, -0.5620163083076477, -0.5491625666618347, -0.536308765411377, -0.523455023765564, -0.510601282119751, -0.4977474808692932, -0.48489370942115784, -0.47203993797302246, -0.4591861665248871, -0.4463323950767517, -0.4334786534309387, -0.42062488198280334, -0.40777111053466797, -0.3949173390865326, -0.3820635676383972, -0.36920979619026184, -0.35635602474212646, -0.3435022532939911, -0.3306484818458557, -0.31779471039772034, -0.30494093894958496, -0.292087197303772, -0.2792333960533142, -0.2663796544075012, -0.25352585315704346, -0.24067211151123047, -0.22781836986541748, -0.21496456861495972, -0.20211082696914673, -0.18925702571868896, -0.17640328407287598, -0.1635494828224182, -0.15069574117660522, -0.13784193992614746, -0.12498819828033447, -0.11213439702987671, -0.09928065538406372, -0.08642691373825073, -0.07357311248779297, -0.06071937084197998, -0.04786556959152222, -0.03501182794570923, -0.022158026695251465, -0.009304285049438477, 0.003549516201019287, 0.016403257846832275, 0.02925705909729004, 0.04211080074310303]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 11.0, 7.0, 2.0, 2.0, 5.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.07274281233549118, -0.07060334086418152, -0.06846386939287186, -0.0663243979215622, -0.06418492645025253, -0.06204545497894287, -0.05990598350763321, -0.05776651203632355, -0.055627040565013885, -0.053487569093704224, -0.05134809762239456, -0.0492086261510849, -0.04706915095448494, -0.04492967948317528, -0.042790208011865616, -0.040650736540555954, -0.03851126506924629, -0.03637179359793663, -0.03423232212662697, -0.032092850655317307, -0.029953379184007645, -0.027813907712697983, -0.02567443624138832, -0.02353496477007866, -0.0213954895734787, -0.019256018102169037, -0.017116546630859375, -0.014977075159549713, -0.012837603688240051, -0.01069813221693039, -0.008558660745620728, -0.006419189274311066, -0.004279717803001404, -0.002140246331691742, -7.748603820800781e-07, 0.002138696610927582, 0.004278168082237244, 0.0064176395535469055, 0.008557111024856567, 0.01069658249616623, 0.012836053967475891, 0.014975525438785553, 0.017114996910095215, 0.019254468381404877, 0.02139393985271454, 0.0235334113240242, 0.025672882795333862, 0.027812354266643524, 0.029951833188533783, 0.032091304659843445, 0.03423077613115311, 0.03637024760246277, 0.03850971907377243, 0.04064919054508209, 0.042788662016391754, 0.044928133487701416, 0.04706760495901108, 0.04920707643032074, 0.0513465479016304, 0.05348601192235947, 0.055625490844249725, 0.05776495486497879, 0.05990443378686905, 0.062043897807598114, 0.06418337672948837]}, "_runtime": 9350.45422077179, "_timestamp": 1585579266.298854, "_step": 298}
{"Episode reward": -99.80003626346448, "Episode length": 999, "Policy Loss": -0.6868537664413452, "Value Loss": 0.04875240847468376, "_runtime": 9352.040258646011, "_timestamp": 1585579267.884892, "_step": 299}
{"Episode reward": -99.76971038728813, "Episode length": 999, "Policy Loss": -0.7513248920440674, "Value Loss": 0.2142249494791031, "_runtime": 9353.55913901329, "_timestamp": 1585579269.4037724, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8182284235954285, "Value Loss": 0.19902640581130981, "_runtime": 9354.078916549683, "_timestamp": 1585579269.92355, "_step": 301}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 2.8300774097442627, "Value Loss": 31.756433486938477, "_runtime": 9355.665479898453, "_timestamp": 1585579271.5101132, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8526279926300049, "Value Loss": 0.0416785404086113, "_runtime": 9357.207194328308, "_timestamp": 1585579273.0518277, "_step": 303}
{"Episode reward": 1.560524426401983, "Episode length": 985, "Policy Loss": -0.14628225564956665, "Value Loss": 9.831745147705078, "_runtime": 9358.711812019348, "_timestamp": 1585579274.5564454, "_step": 304}
{"Episode reward": -99.83770127892355, "Episode length": 999, "Policy Loss": -0.9451828598976135, "Value Loss": 0.024410950019955635, "_runtime": 9360.305480718613, "_timestamp": 1585579276.150114, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9540419578552246, "Value Loss": 0.11621356755495071, "_runtime": 9361.528463602066, "_timestamp": 1585579277.373097, "_step": 306}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.08875080943107605, "Value Loss": 12.383111000061035, "_runtime": 9363.134610176086, "_timestamp": 1585579278.9792435, "_step": 307}
{"Episode reward": -99.85980167537788, "Episode length": 999, "Policy Loss": -0.9805933237075806, "Value Loss": 0.0901251882314682, "_runtime": 9363.765968084335, "_timestamp": 1585579279.6106014, "_step": 308}
{"Episode reward": 62.99999999999975, "Episode length": 370, "Policy Loss": 1.1611775159835815, "Value Loss": 25.612281799316406, "_runtime": 9365.332564592361, "_timestamp": 1585579281.177198, "_step": 309}
{"Episode reward": -99.8021961271749, "Episode length": 999, "Policy Loss": -0.9328562617301941, "Value Loss": 0.04579467698931694, "_runtime": 9366.199892520905, "_timestamp": 1585579282.0445259, "_step": 310}
{"Episode reward": 46.09999999999951, "Episode length": 539, "Policy Loss": 0.5848909616470337, "Value Loss": 17.877063751220703, "_runtime": 9366.925219297409, "_timestamp": 1585579282.7698526, "_step": 311}
{"Episode reward": 52.98770038932523, "Episode length": 471, "Policy Loss": 0.6287509799003601, "Value Loss": 20.78892707824707, "_runtime": 9368.268035650253, "_timestamp": 1585579284.112669, "_step": 312}
{"Episode reward": 14.818797725439637, "Episode length": 852, "Policy Loss": 0.021689923480153084, "Value Loss": 11.15250301361084, "_runtime": 9368.79162144661, "_timestamp": 1585579284.6362548, "_step": 313}
{"Episode reward": 67.49999999999982, "Episode length": 325, "Policy Loss": 1.6470011472702026, "Value Loss": 29.135066986083984, "_runtime": 9369.978569984436, "_timestamp": 1585579285.8232033, "_step": 314}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.12599137425422668, "Value Loss": 12.490325927734375, "_runtime": 9371.098287343979, "_timestamp": 1585579286.9429207, "_step": 315}
{"Episode reward": 29.399999999999736, "Episode length": 706, "Policy Loss": 0.30724480748176575, "Value Loss": 13.511259078979492, "_runtime": 9372.448915243149, "_timestamp": 1585579288.2935486, "_step": 316}
{"Episode reward": 10.700000000000799, "Episode length": 893, "Policy Loss": -0.0731307864189148, "Value Loss": 10.646502494812012, "_runtime": 9373.997887134552, "_timestamp": 1585579289.8425205, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9920108914375305, "Value Loss": 0.02617652527987957, "_runtime": 9375.553899049759, "_timestamp": 1585579291.3985324, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0124472379684448, "Value Loss": 0.036917950958013535, "_runtime": 9376.585275888443, "_timestamp": 1585579292.4299092, "_step": 319}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.4208601713180542, "Value Loss": 14.506370544433594, "_runtime": 9378.080051660538, "_timestamp": 1585579293.924685, "_step": 320}
{"Episode reward": 4.400000000001157, "Episode length": 956, "Policy Loss": -0.15837901830673218, "Value Loss": 10.110563278198242, "_runtime": 9379.665927410126, "_timestamp": 1585579295.5105608, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0395293235778809, "Value Loss": 0.03263331204652786, "_runtime": 9381.213330030441, "_timestamp": 1585579297.0579634, "_step": 322}
{"Episode reward": -99.80302586704353, "Episode length": 999, "Policy Loss": -1.0368103981018066, "Value Loss": 0.0484335720539093, "_runtime": 9382.79527592659, "_timestamp": 1585579298.6399093, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.007886290550232, "Value Loss": 0.06880655139684677, "_runtime": 9384.376242876053, "_timestamp": 1585579300.2208762, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9798279404640198, "Value Loss": 0.04430106282234192, "_runtime": 9385.236609458923, "_timestamp": 1585579301.0812428, "_step": 325}
{"Episode reward": 46.09999999999951, "Episode length": 539, "Policy Loss": 0.2894774079322815, "Value Loss": 18.552576065063477, "_runtime": 9386.853859424591, "_timestamp": 1585579302.6984928, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9309149980545044, "Value Loss": 0.04580427706241608, "_runtime": 9388.44835114479, "_timestamp": 1585579304.2929845, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9275003671646118, "Value Loss": 0.08216259628534317, "_runtime": 9389.986756324768, "_timestamp": 1585579305.8313897, "_step": 328}
{"Episode reward": -99.80272781997779, "Episode length": 999, "Policy Loss": -0.9069402813911438, "Value Loss": 0.166614830493927, "_runtime": 9391.568508148193, "_timestamp": 1585579307.4131415, "_step": 329}
{"Episode reward": -99.76031670868257, "Episode length": 999, "Policy Loss": -0.8285433650016785, "Value Loss": 0.04427490383386612, "_runtime": 9393.166105747223, "_timestamp": 1585579309.010739, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7525519132614136, "Value Loss": 0.07299870252609253, "_runtime": 9393.87666964531, "_timestamp": 1585579309.721303, "_step": 331}
{"Episode reward": 56.69999999999966, "Episode length": 433, "Policy Loss": 1.128635048866272, "Value Loss": 22.569828033447266, "_runtime": 9395.459281682968, "_timestamp": 1585579311.303915, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6275569796562195, "Value Loss": 0.014467380940914154, "_runtime": 9397.04349064827, "_timestamp": 1585579312.888124, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4931616187095642, "Value Loss": 0.07037675380706787, "_runtime": 9398.04086303711, "_timestamp": 1585579313.8854964, "_step": 334}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.8156462907791138, "Value Loss": 14.85114574432373, "_runtime": 9399.211102962494, "_timestamp": 1585579315.0557363, "_step": 335}
{"Episode reward": 26.399999999999906, "Episode length": 736, "Policy Loss": 0.6585143804550171, "Value Loss": 13.178006172180176, "_runtime": 9399.978709697723, "_timestamp": 1585579315.823343, "_step": 336}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.4580060243606567, "Value Loss": 20.490293502807617, "_runtime": 9400.864773273468, "_timestamp": 1585579316.7094066, "_step": 337}
{"Episode reward": 42.7922775443638, "Episode length": 573, "Policy Loss": 1.2065694332122803, "Value Loss": 17.04023551940918, "_runtime": 9402.40575671196, "_timestamp": 1585579318.25039, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0785566121339798, "Value Loss": 0.030224395915865898, "_runtime": 9402.895951986313, "_timestamp": 1585579318.7405853, "_step": 339}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": 2.896636962890625, "Value Loss": 31.379108428955078, "_runtime": 9404.04933667183, "_timestamp": 1585579319.89397, "_step": 340}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 1.21491539478302, "Value Loss": 12.749441146850586, "_runtime": 9405.007364273071, "_timestamp": 1585579320.8519976, "_step": 341}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 1.3243974447250366, "Value Loss": 16.091482162475586, "_runtime": 9406.526218175888, "_timestamp": 1585579322.3708515, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02557186409831047, "Value Loss": 0.09487675875425339, "_runtime": 9408.075922966003, "_timestamp": 1585579323.9205563, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07463955134153366, "Value Loss": 0.11886292695999146, "_runtime": 9409.614888906479, "_timestamp": 1585579325.4595222, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10954932123422623, "Value Loss": 0.032201092690229416, "_runtime": 9411.226739883423, "_timestamp": 1585579327.0713732, "_step": 345}
{"Episode reward": -99.81067068576672, "Episode length": 999, "Policy Loss": -0.21544507145881653, "Value Loss": 0.14476951956748962, "_runtime": 9412.821198701859, "_timestamp": 1585579328.665832, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23921102285385132, "Value Loss": 0.082057423889637, "_runtime": 9413.387351751328, "_timestamp": 1585579329.231985, "_step": 347}
{"Episode reward": 66.4999999999998, "Episode length": 335, "Policy Loss": 1.8533380031585693, "Value Loss": 28.358217239379883, "_runtime": 9414.159746170044, "_timestamp": 1585579330.0043795, "_step": 348}
{"Episode reward": 51.39999999999959, "Episode length": 486, "Policy Loss": 1.4031881093978882, "Value Loss": 19.795108795166016, "_runtime": 9414.934435367584, "_timestamp": 1585579330.7790687, "_step": 349}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 0.9467597007751465, "Value Loss": 20.509126663208008, "_runtime": 9416.464870214462, "_timestamp": 1585579332.3095036, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6762340664863586, "Value Loss": 0.027111178264021873, "_runtime": 9417.661700725555, "_timestamp": 1585579333.506334, "_step": 351}
{"Episode reward": 22.279448814317718, "Episode length": 779, "Policy Loss": 0.3543911576271057, "Value Loss": 12.33370590209961, "_runtime": 9419.178704023361, "_timestamp": 1585579335.0233374, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8029603958129883, "Value Loss": 0.08540890365839005, "_runtime": 9420.752892255783, "_timestamp": 1585579336.5975256, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8644682168960571, "Value Loss": 0.0618477538228035, "_runtime": 9422.092603206635, "_timestamp": 1585579337.9372365, "_step": 354}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": 0.07470837980508804, "Value Loss": 11.179621696472168, "_runtime": 9423.667450666428, "_timestamp": 1585579339.512084, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8332675695419312, "Value Loss": 0.04740951955318451, "_runtime": 9424.846779584885, "_timestamp": 1585579340.691413, "_step": 356}
{"Episode reward": 25.57601487636562, "Episode length": 745, "Policy Loss": 0.8551133275032043, "Value Loss": 12.774624824523926, "_runtime": 9425.264909744263, "_timestamp": 1585579341.109543, "_step": 357}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 2.452653169631958, "Value Loss": 39.93057632446289, "_runtime": 9426.461645841599, "_timestamp": 1585579342.3062792, "_step": 358}
{"Episode reward": 23.300000000000082, "Episode length": 767, "Policy Loss": 0.3007337749004364, "Value Loss": 12.281883239746094, "_runtime": 9427.195234537125, "_timestamp": 1585579343.0398679, "_step": 359}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 0.8849346041679382, "Value Loss": 21.235803604125977, "_runtime": 9428.705906867981, "_timestamp": 1585579344.5505402, "_step": 360}
{"Episode reward": -99.81317959427695, "Episode length": 999, "Policy Loss": -0.6555810570716858, "Value Loss": 0.02373252995312214, "_runtime": 9429.841773033142, "_timestamp": 1585579345.6864064, "_step": 361}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.36171215772628784, "Value Loss": 12.920989990234375, "_runtime": 9431.065262317657, "_timestamp": 1585579346.9098957, "_step": 362}
{"Episode reward": 20.100000000000264, "Episode length": 799, "Policy Loss": 0.359971821308136, "Value Loss": 11.763588905334473, "_runtime": 9431.765348672867, "_timestamp": 1585579347.609982, "_step": 363}
{"Episode reward": 56.547812074422495, "Episode length": 435, "Policy Loss": 0.9836975932121277, "Value Loss": 22.193464279174805, "_runtime": 9433.315305948257, "_timestamp": 1585579349.1599393, "_step": 364}
{"Episode reward": -99.76872070580582, "Episode length": 999, "Policy Loss": -0.9259216785430908, "Value Loss": 0.5580517053604126, "_runtime": 9433.961630105972, "_timestamp": 1585579349.8062634, "_step": 365}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.140849232673645, "Value Loss": 23.397937774658203, "_runtime": 9435.049170970917, "_timestamp": 1585579350.8938043, "_step": 366}
{"Episode reward": 27.885531783103772, "Episode length": 722, "Policy Loss": 0.14432655274868011, "Value Loss": 13.083919525146484, "_runtime": 9436.655224323273, "_timestamp": 1585579352.4998577, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.001312017440796, "Value Loss": 0.07384134829044342, "_runtime": 9438.177496671677, "_timestamp": 1585579354.02213, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.05576753616333, "Value Loss": 0.030333925038576126, "_runtime": 9439.397255182266, "_timestamp": 1585579355.2418885, "_step": 369}
{"Episode reward": 21.353203177452286, "Episode length": 787, "Policy Loss": -0.10277114063501358, "Value Loss": 12.607603073120117, "_runtime": 9440.960394859314, "_timestamp": 1585579356.8050282, "_step": 370}
{"Episode reward": -99.83868196159462, "Episode length": 999, "Policy Loss": -1.1032967567443848, "Value Loss": 0.07496019452810287, "_runtime": 9442.534766674042, "_timestamp": 1585579358.3794, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1637227535247803, "Value Loss": 0.4591369926929474, "_runtime": 9443.313279151917, "_timestamp": 1585579359.1579125, "_step": 372}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 0.9043484330177307, "Value Loss": 20.04451560974121, "_runtime": 9444.80142378807, "_timestamp": 1585579360.6460571, "_step": 373}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": -0.21925000846385956, "Value Loss": 10.440802574157715, "_runtime": 9445.860556840897, "_timestamp": 1585579361.7051902, "_step": 374}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.5320688486099243, "Value Loss": 14.235546112060547, "_runtime": 9447.391685962677, "_timestamp": 1585579363.2363193, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8289095163345337, "Value Loss": 0.03953411802649498, "_runtime": 9448.981469869614, "_timestamp": 1585579364.8261032, "_step": 376}
{"Episode reward": -99.80190272927145, "Episode length": 999, "Policy Loss": -0.7452815771102905, "Value Loss": 0.045907579362392426, "_runtime": 9450.081854820251, "_timestamp": 1585579365.9264882, "_step": 377}
{"Episode reward": 29.812132261693193, "Episode length": 702, "Policy Loss": 0.6766667366027832, "Value Loss": 13.493563652038574, "_runtime": 9451.637169361115, "_timestamp": 1585579367.4818027, "_step": 378}
{"Episode reward": -99.84088378548482, "Episode length": 999, "Policy Loss": -0.5684261322021484, "Value Loss": 0.05309145152568817, "_runtime": 9453.22087931633, "_timestamp": 1585579369.0655127, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5210531949996948, "Value Loss": 0.022572742775082588, "_runtime": 9454.771838188171, "_timestamp": 1585579370.6164715, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4656885266304016, "Value Loss": 0.048829492181539536, "_runtime": 9455.633573055267, "_timestamp": 1585579371.4782064, "_step": 381}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 0.7295128703117371, "Value Loss": 19.490745544433594, "_runtime": 9457.214382886887, "_timestamp": 1585579373.0590162, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37755000591278076, "Value Loss": 0.04588622972369194, "_runtime": 9458.800377130508, "_timestamp": 1585579374.6450105, "_step": 383}
{"Episode reward": -99.80557356476643, "Episode length": 999, "Policy Loss": -0.34159961342811584, "Value Loss": 0.00916457362473011, "_runtime": 9459.660643100739, "_timestamp": 1585579375.5052764, "_step": 384}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": 1.4271479845046997, "Value Loss": 17.490324020385742, "_runtime": 9461.27309179306, "_timestamp": 1585579377.1177251, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2594308853149414, "Value Loss": 0.024862729012966156, "_runtime": 9462.861115217209, "_timestamp": 1585579378.7057486, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21450071036815643, "Value Loss": 0.012286179699003696, "_runtime": 9464.405388593674, "_timestamp": 1585579380.250022, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16078254580497742, "Value Loss": 0.15654656291007996, "_runtime": 9465.99278998375, "_timestamp": 1585579381.8374233, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08584780991077423, "Value Loss": 0.007592070382088423, "_runtime": 9466.927503108978, "_timestamp": 1585579382.7721364, "_step": 389}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 1.3999744653701782, "Value Loss": 16.722034454345703, "_runtime": 9468.496709108353, "_timestamp": 1585579384.3413424, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021521922200918198, "Value Loss": 0.03643925487995148, "_runtime": 9470.094271659851, "_timestamp": 1585579385.938905, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10366969555616379, "Value Loss": 0.0023220498114824295, "_runtime": 9470.596967220306, "_timestamp": 1585579386.4416006, "_step": 392}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 2.7354865074157715, "Value Loss": 31.582988739013672, "_runtime": 9472.171691894531, "_timestamp": 1585579388.0163252, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1693868637084961, "Value Loss": 0.018421275541186333, "_runtime": 9473.038891077042, "_timestamp": 1585579388.8835244, "_step": 394}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 1.898070216178894, "Value Loss": 17.94362449645996, "_runtime": 9474.561116218567, "_timestamp": 1585579390.4057496, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1950209140777588, "Value Loss": 0.03781909495592117, "_runtime": 9476.140591144562, "_timestamp": 1585579391.9852245, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19589951634407043, "Value Loss": 0.03582274913787842, "_runtime": 9477.647588253021, "_timestamp": 1585579393.4922216, "_step": 397}
{"Episode reward": 1.1000000000013443, "Episode length": 989, "Policy Loss": 0.9695212244987488, "Value Loss": 9.646864891052246, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983, -0.0036890737246721983]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8280375599861145, -0.8065717816352844, -0.7851060628890991, -0.763640284538269, -0.742174506187439, -0.7207087278366089, -0.6992429494857788, -0.6777772307395935, -0.6563114523887634, -0.6348456740379333, -0.613379955291748, -0.591914176940918, -0.5704483985900879, -0.5489826202392578, -0.5275168418884277, -0.5060511231422424, -0.48458534479141235, -0.4631195664405823, -0.4416538178920746, -0.4201880693435669, -0.3987222909927368, -0.37725651264190674, -0.35579076409339905, -0.33432501554489136, -0.3128592371940613, -0.2913934588432312, -0.2699276804924011, -0.24846196174621582, -0.22699618339538574, -0.20553040504455566, -0.18406468629837036, -0.16259890794754028, -0.1411331295967102, -0.11966735124588013, -0.09820157289505005, -0.07673585414886475, -0.05527007579803467, -0.03380429744720459, -0.012338578701019287, 0.009127199649810791, 0.03059297800064087, 0.05205875635147095, 0.07352453470230103, 0.09499025344848633, 0.1164560317993164, 0.13792181015014648, 0.1593875288963318, 0.18085330724716187, 0.20231908559799194, 0.22378486394882202, 0.2452506422996521, 0.2667164206504822, 0.28818219900131226, 0.3096478581428528, 0.33111363649368286, 0.35257941484451294, 0.374045193195343, 0.3955109715461731, 0.4169767498970032, 0.43844252824783325, 0.4599081873893738, 0.48137396574020386, 0.5028397440910339, 0.524305522441864, 0.5457713007926941]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.012266573496162891, -0.011723324656486511, -0.011180075816810131, -0.010636826977133751, -0.01009357813745737, -0.00955032929778099, -0.009007079526782036, -0.00846383161842823, -0.007920581847429276, -0.007377333473414183, -0.0068340846337378025, -0.006290835794061422, -0.005747586488723755, -0.005204337649047375, -0.004661088809370995, -0.004117839969694614, -0.0035745911300182343, -0.003031342290341854, -0.002488093450665474, -0.0019448446109890938, -0.0014015957713127136, -0.0008583469316363335, -0.0003150980919599533, 0.00022815074771642685, 0.0007714005187153816, 0.0013146493583917618, 0.001857898198068142, 0.002401147037744522, 0.0029443958774209023, 0.003487643785774708, 0.004030893556773663, 0.004574141465127468, 0.005117391236126423, 0.005660641007125378, 0.006203888915479183, 0.006747138686478138, 0.0072903865948319435, 0.007833636365830898, 0.008376884274184704, 0.008920134045183659, 0.009463381953537464, 0.010006631724536419, 0.010549879632890224, 0.01109312940388918, 0.011636377312242985, 0.01217962708324194, 0.012722874991595745, 0.0132661247625947, 0.013809374533593655, 0.01435262244194746, 0.014895872212946415, 0.01543912012130022, 0.01598237082362175, 0.016525618731975555, 0.01706886664032936, 0.017612114548683167, 0.01815536618232727, 0.018698614090681076, 0.01924186199903488, 0.019785113632678986, 0.02032836154103279, 0.020871609449386597, 0.021414857357740402, 0.021958108991384506, 0.022501356899738312]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 2.0, 5.0, 5.0, 4.0, 1.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 5.0, 5.0, 7.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 7.0, 7.0, 6.0, 1.0, 1.0, 294.0, 28.0, 18.0, 17.0, 21.0, 6.0, 2.0, 3.0, 3.0, 7.0, 6.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.11041820794343948, -0.10644509643316269, -0.1024719849228859, -0.0984988734126091, -0.0945257619023323, -0.09055265039205551, -0.08657953888177872, -0.08260642737150192, -0.07863331586122513, -0.07466020435094833, -0.07068709284067154, -0.06671398133039474, -0.06274086982011795, -0.058767758309841156, -0.05479464679956436, -0.05082153528928757, -0.04684842377901077, -0.04287531226873398, -0.038902200758457184, -0.03492908924818039, -0.030955977737903595, -0.0269828662276268, -0.023009754717350006, -0.01903664320707321, -0.015063531696796417, -0.011090420186519623, -0.007117308676242828, -0.003144197165966034, 0.0008289143443107605, 0.004802025854587555, 0.00877513736486435, 0.012748248875141144, 0.016721360385417938, 0.020694471895694733, 0.024667583405971527, 0.02864069491624832, 0.032613806426525116, 0.03658691793680191, 0.040560029447078705, 0.0445331409573555, 0.048506252467632294, 0.05247936397790909, 0.05645247548818588, 0.06042558699846268, 0.06439869850873947, 0.06837181001901627, 0.07234492152929306, 0.07631803303956985, 0.08029114454984665, 0.08426425606012344, 0.08823736757040024, 0.09221047908067703, 0.09618359059095383, 0.10015670210123062, 0.10412981361150742, 0.10810292512178421, 0.112076036632061, 0.1160491481423378, 0.1200222596526146, 0.12399537116289139, 0.12796849012374878, 0.13194158673286438, 0.13591471314430237, 0.13988780975341797, 0.14386093616485596]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.305693119764328, -0.2983144521713257, -0.29093578457832336, -0.28355711698532104, -0.2761784493923187, -0.2687997817993164, -0.2614211142063141, -0.25404244661331177, -0.24666377902030945, -0.23928511142730713, -0.2319064438343048, -0.2245277762413025, -0.21714912354946136, -0.20977045595645905, -0.20239178836345673, -0.1950131207704544, -0.1876344531774521, -0.18025578558444977, -0.17287711799144745, -0.16549845039844513, -0.1581197828054428, -0.1507411152124405, -0.14336244761943817, -0.13598378002643585, -0.12860512733459473, -0.12122645974159241, -0.11384779214859009, -0.10646912455558777, -0.09909045696258545, -0.09171178936958313, -0.08433312177658081, -0.07695445418357849, -0.06957578659057617, -0.06219711899757385, -0.05481845140457153, -0.047439783811569214, -0.040061116218566895, -0.032682448625564575, -0.025303781032562256, -0.017925113439559937, -0.010546445846557617, -0.003167778253555298, 0.0042108893394470215, 0.01158955693244934, 0.01896822452545166, 0.02634689211845398, 0.0337255597114563, 0.04110422730445862, 0.04848286509513855, 0.05586153268814087, 0.06324020028114319, 0.07061886787414551, 0.07799753546714783, 0.08537620306015015, 0.09275487065315247, 0.10013353824615479, 0.1075122058391571, 0.11489087343215942, 0.12226954102516174, 0.12964820861816406, 0.13702687621116638, 0.1444055438041687, 0.15178421139717102, 0.15916287899017334, 0.16654154658317566]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 9.0, 10.0, 7.0, 2.0, 1.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16419288516044617, -0.15265175700187683, -0.1411106437444687, -0.12956951558589935, -0.11802839487791061, -0.10648727416992188, -0.09494614601135254, -0.0834050253033638, -0.07186390459537506, -0.06032278388738632, -0.04878166317939758, -0.03724053502082825, -0.02569940686225891, -0.014158293604850769, -0.002617165446281433, 0.008923947811126709, 0.020465075969696045, 0.03200620412826538, 0.04354731738567352, 0.05508844554424286, 0.066629558801651, 0.07817068696022034, 0.08971181511878967, 0.10125294327735901, 0.11279407143592834, 0.12433516979217529, 0.13587629795074463, 0.14741742610931396, 0.1589585542678833, 0.17049968242645264, 0.18204078078269958, 0.19358190894126892, 0.20512303709983826, 0.2166641652584076, 0.22820529341697693, 0.23974639177322388, 0.2512875199317932, 0.26282864809036255, 0.2743697762489319, 0.2859109044075012, 0.29745200276374817, 0.3089931309223175, 0.32053425908088684, 0.3320753872394562, 0.3436165153980255, 0.35515764355659485, 0.3666987717151642, 0.3782398998737335, 0.38978102803230286, 0.4013220965862274, 0.41286322474479675, 0.4244043529033661, 0.4359454810619354, 0.44748660922050476, 0.4590277373790741, 0.47056886553764343, 0.48210999369621277, 0.4936511218547821, 0.5051922798156738, 0.5167332887649536, 0.528274416923523, 0.5398155450820923, 0.5513566732406616, 0.562897801399231, 0.5744389295578003]}, "_runtime": 9479.201191663742, "_timestamp": 1585579395.045825, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05923835188150406, "Value Loss": 0.19704076647758484, "_runtime": 9480.394055366516, "_timestamp": 1585579396.2386887, "_step": 399}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 0.9456234574317932, "Value Loss": 12.810483932495117, "_runtime": 9481.958461761475, "_timestamp": 1585579397.803095, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06137608736753464, "Value Loss": 0.029590247198939323, "_runtime": 9483.274901390076, "_timestamp": 1585579399.1195347, "_step": 401}
{"Episode reward": 16.353453360498435, "Episode length": 837, "Policy Loss": 0.7273507714271545, "Value Loss": 11.433804512023926, "_runtime": 9484.84279680252, "_timestamp": 1585579400.6874301, "_step": 402}
{"Episode reward": -99.81201868057111, "Episode length": 999, "Policy Loss": -0.2722763419151306, "Value Loss": 0.005573640111833811, "_runtime": 9485.75285410881, "_timestamp": 1585579401.5974874, "_step": 403}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": 1.3904688358306885, "Value Loss": 16.72657012939453, "_runtime": 9487.170830965042, "_timestamp": 1585579403.0154643, "_step": 404}
{"Episode reward": 8.796331690252742, "Episode length": 913, "Policy Loss": 0.42651620507240295, "Value Loss": 10.427959442138672, "_runtime": 9488.674731969833, "_timestamp": 1585579404.5193653, "_step": 405}
{"Episode reward": 3.5655066668999353, "Episode length": 965, "Policy Loss": 0.2900061309337616, "Value Loss": 9.86239242553711, "_runtime": 9490.192236185074, "_timestamp": 1585579406.0368695, "_step": 406}
{"Episode reward": -99.81519210487464, "Episode length": 999, "Policy Loss": -0.6563224792480469, "Value Loss": 0.01885487698018551, "_runtime": 9491.744843244553, "_timestamp": 1585579407.5894766, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.708661675453186, "Value Loss": 0.03341194614768028, "_runtime": 9493.299146413803, "_timestamp": 1585579409.1437798, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7542187571525574, "Value Loss": 0.019865941256284714, "_runtime": 9494.664778709412, "_timestamp": 1585579410.509412, "_step": 409}
{"Episode reward": 12.400000000000702, "Episode length": 876, "Policy Loss": 0.15675869584083557, "Value Loss": 10.812745094299316, "_runtime": 9495.730772972107, "_timestamp": 1585579411.5754063, "_step": 410}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": 0.5461872220039368, "Value Loss": 14.040373802185059, "_runtime": 9497.141723632812, "_timestamp": 1585579412.986357, "_step": 411}
{"Episode reward": 9.59848894924012, "Episode length": 905, "Policy Loss": 0.18894901871681213, "Value Loss": 10.335616111755371, "_runtime": 9498.705528974533, "_timestamp": 1585579414.5501623, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8532269597053528, "Value Loss": 0.17908073961734772, "_runtime": 9499.490465641022, "_timestamp": 1585579415.335099, "_step": 413}
{"Episode reward": 49.899999999999565, "Episode length": 501, "Policy Loss": 0.7414003014564514, "Value Loss": 19.693391799926758, "_runtime": 9501.03806567192, "_timestamp": 1585579416.882699, "_step": 414}
{"Episode reward": -99.76825181394676, "Episode length": 999, "Policy Loss": -0.8514091968536377, "Value Loss": 0.029409604147076607, "_runtime": 9502.072837591171, "_timestamp": 1585579417.917471, "_step": 415}
{"Episode reward": 34.59999999999944, "Episode length": 654, "Policy Loss": -0.11974243819713593, "Value Loss": 17.112836837768555, "_runtime": 9502.419138669968, "_timestamp": 1585579418.263772, "_step": 416}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": 3.179886817932129, "Value Loss": 46.28119659423828, "_runtime": 9503.99000453949, "_timestamp": 1585579419.8346379, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8744347095489502, "Value Loss": 0.030185405164957047, "_runtime": 9504.986253499985, "_timestamp": 1585579420.8308868, "_step": 418}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.4046212136745453, "Value Loss": 15.011905670166016, "_runtime": 9506.480785608292, "_timestamp": 1585579422.325419, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8401683568954468, "Value Loss": 0.04260953143239021, "_runtime": 9508.095159769058, "_timestamp": 1585579423.939793, "_step": 420}
{"Episode reward": -99.87272391915181, "Episode length": 999, "Policy Loss": -0.8225989937782288, "Value Loss": 0.05581469088792801, "_runtime": 9508.764805793762, "_timestamp": 1585579424.6094391, "_step": 421}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.0878419876098633, "Value Loss": 22.80964469909668, "_runtime": 9510.328496932983, "_timestamp": 1585579426.1731303, "_step": 422}
{"Episode reward": -99.82614814191916, "Episode length": 999, "Policy Loss": -0.7819689512252808, "Value Loss": 0.042505405843257904, "_runtime": 9511.464995145798, "_timestamp": 1585579427.3096285, "_step": 423}
{"Episode reward": 28.299999999999798, "Episode length": 717, "Policy Loss": 0.3447619378566742, "Value Loss": 13.230159759521484, "_runtime": 9512.996564149857, "_timestamp": 1585579428.8411975, "_step": 424}
{"Episode reward": -99.86332600265602, "Episode length": 999, "Policy Loss": -0.739662230014801, "Value Loss": 0.02949589118361473, "_runtime": 9514.078768014908, "_timestamp": 1585579429.9234014, "_step": 425}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.4011203944683075, "Value Loss": 13.819676399230957, "_runtime": 9515.634603023529, "_timestamp": 1585579431.4792364, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7124541401863098, "Value Loss": 0.026202868670225143, "_runtime": 9517.208745718002, "_timestamp": 1585579433.053379, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6880791187286377, "Value Loss": 0.025369716808199883, "_runtime": 9518.215832233429, "_timestamp": 1585579434.0604656, "_step": 428}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": 0.43599095940589905, "Value Loss": 15.324353218078613, "_runtime": 9519.799268722534, "_timestamp": 1585579435.643902, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.679678201675415, "Value Loss": 0.041030704975128174, "_runtime": 9520.77553153038, "_timestamp": 1585579436.6201649, "_step": 430}
{"Episode reward": 39.299999999999415, "Episode length": 607, "Policy Loss": 0.8929873704910278, "Value Loss": 15.467548370361328, "_runtime": 9521.944553375244, "_timestamp": 1585579437.7891867, "_step": 431}
{"Episode reward": 25.09999999999998, "Episode length": 749, "Policy Loss": 0.2210199534893036, "Value Loss": 13.970203399658203, "_runtime": 9523.056267023087, "_timestamp": 1585579438.9009004, "_step": 432}
{"Episode reward": 30.299999999999685, "Episode length": 697, "Policy Loss": 0.5486971735954285, "Value Loss": 13.562012672424316, "_runtime": 9524.589225530624, "_timestamp": 1585579440.4338589, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.804161548614502, "Value Loss": 0.012869412079453468, "_runtime": 9526.14401936531, "_timestamp": 1585579441.9886527, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8266267776489258, "Value Loss": 0.03040109947323799, "_runtime": 9527.69123506546, "_timestamp": 1585579443.5358684, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8352888226509094, "Value Loss": 0.08376549929380417, "_runtime": 9528.993861198425, "_timestamp": 1585579444.8384945, "_step": 436}
{"Episode reward": 17.20000000000043, "Episode length": 828, "Policy Loss": 0.8122506141662598, "Value Loss": 11.840238571166992, "_runtime": 9530.573597192764, "_timestamp": 1585579446.4182305, "_step": 437}
{"Episode reward": -99.8904727935777, "Episode length": 999, "Policy Loss": -0.7551524043083191, "Value Loss": 0.061818018555641174, "_runtime": 9531.589411020279, "_timestamp": 1585579447.4340444, "_step": 438}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 0.7534195184707642, "Value Loss": 15.760068893432617, "_runtime": 9533.151234388351, "_timestamp": 1585579448.9958677, "_step": 439}
{"Episode reward": -99.80000501274922, "Episode length": 999, "Policy Loss": -0.611361026763916, "Value Loss": 0.04457903653383255, "_runtime": 9534.741946935654, "_timestamp": 1585579450.5865803, "_step": 440}
{"Episode reward": -99.80104392915824, "Episode length": 999, "Policy Loss": -0.5321400165557861, "Value Loss": 0.017990674823522568, "_runtime": 9536.289386749268, "_timestamp": 1585579452.13402, "_step": 441}
{"Episode reward": -99.80074062496284, "Episode length": 999, "Policy Loss": -0.44989994168281555, "Value Loss": 0.02127763070166111, "_runtime": 9537.458111286163, "_timestamp": 1585579453.3027446, "_step": 442}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": 0.6138488054275513, "Value Loss": 13.185200691223145, "_runtime": 9538.925139665604, "_timestamp": 1585579454.769773, "_step": 443}
{"Episode reward": 7.600000000000975, "Episode length": 924, "Policy Loss": 0.5625336766242981, "Value Loss": 10.236133575439453, "_runtime": 9540.510269403458, "_timestamp": 1585579456.3549027, "_step": 444}
{"Episode reward": -99.89837094694236, "Episode length": 999, "Policy Loss": -0.28424227237701416, "Value Loss": 0.032121457159519196, "_runtime": 9541.550012111664, "_timestamp": 1585579457.3946455, "_step": 445}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 1.0186209678649902, "Value Loss": 14.67861270904541, "_runtime": 9543.129042625427, "_timestamp": 1585579458.973676, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30547189712524414, "Value Loss": 0.15315023064613342, "_runtime": 9544.70853972435, "_timestamp": 1585579460.553173, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2663092613220215, "Value Loss": 0.013508169911801815, "_runtime": 9546.264699697495, "_timestamp": 1585579462.109333, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3101270794868469, "Value Loss": 0.07450670003890991, "_runtime": 9547.204289197922, "_timestamp": 1585579463.0489225, "_step": 449}
{"Episode reward": 41.89999999999945, "Episode length": 581, "Policy Loss": 0.9466390013694763, "Value Loss": 16.571399688720703, "_runtime": 9548.791593551636, "_timestamp": 1585579464.636227, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3972166180610657, "Value Loss": 0.005013032350689173, "_runtime": 9550.380418300629, "_timestamp": 1585579466.2250516, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42348018288612366, "Value Loss": 0.029055947437882423, "_runtime": 9551.925566673279, "_timestamp": 1585579467.7702, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47518137097358704, "Value Loss": 0.008175009861588478, "_runtime": 9553.510726451874, "_timestamp": 1585579469.3553598, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4857209324836731, "Value Loss": 0.017468713223934174, "_runtime": 9554.29943203926, "_timestamp": 1585579470.1440654, "_step": 454}
{"Episode reward": 51.03750665187794, "Episode length": 490, "Policy Loss": 1.2131062746047974, "Value Loss": 19.582551956176758, "_runtime": 9555.499270439148, "_timestamp": 1585579471.3439038, "_step": 455}
{"Episode reward": 26.4999999999999, "Episode length": 735, "Policy Loss": 0.725560188293457, "Value Loss": 13.134842872619629, "_runtime": 9556.16826581955, "_timestamp": 1585579472.0128992, "_step": 456}
{"Episode reward": 59.586463493108454, "Episode length": 405, "Policy Loss": 1.5017778873443604, "Value Loss": 23.955652236938477, "_runtime": 9557.708123207092, "_timestamp": 1585579473.5527565, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4065392017364502, "Value Loss": 0.007966548204421997, "_runtime": 9559.209383487701, "_timestamp": 1585579475.0540168, "_step": 458}
{"Episode reward": 3.8743488416087644, "Episode length": 962, "Policy Loss": 0.3844619691371918, "Value Loss": 9.861345291137695, "_runtime": 9560.596642255783, "_timestamp": 1585579476.4412756, "_step": 459}
{"Episode reward": 8.600000000000918, "Episode length": 914, "Policy Loss": 0.49257320165634155, "Value Loss": 10.35346794128418, "_runtime": 9561.248281240463, "_timestamp": 1585579477.0929146, "_step": 460}
{"Episode reward": 60.59999999999972, "Episode length": 394, "Policy Loss": 1.4255646467208862, "Value Loss": 24.12519645690918, "_runtime": 9562.231164216995, "_timestamp": 1585579478.0757976, "_step": 461}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.727663516998291, "Value Loss": 15.110746383666992, "_runtime": 9563.319350004196, "_timestamp": 1585579479.1639833, "_step": 462}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.5425901412963867, "Value Loss": 13.733736991882324, "_runtime": 9564.847473144531, "_timestamp": 1585579480.6921065, "_step": 463}
{"Episode reward": -99.8008789062486, "Episode length": 999, "Policy Loss": -0.657640814781189, "Value Loss": 0.1334397792816162, "_runtime": 9565.909401655197, "_timestamp": 1585579481.754035, "_step": 464}
{"Episode reward": 32.11585830151992, "Episode length": 680, "Policy Loss": 0.39902380108833313, "Value Loss": 14.685132026672363, "_runtime": 9567.282362222672, "_timestamp": 1585579483.1269956, "_step": 465}
{"Episode reward": 11.100000000000776, "Episode length": 889, "Policy Loss": 0.05299193039536476, "Value Loss": 10.76081657409668, "_runtime": 9568.780113220215, "_timestamp": 1585579484.6247466, "_step": 466}
{"Episode reward": 4.3000000000011624, "Episode length": 957, "Policy Loss": -0.16509434580802917, "Value Loss": 10.08562183380127, "_runtime": 9570.337328910828, "_timestamp": 1585579486.1819623, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1276620626449585, "Value Loss": 0.025754565373063087, "_runtime": 9571.654725074768, "_timestamp": 1585579487.4993584, "_step": 468}
{"Episode reward": 15.200000000000543, "Episode length": 848, "Policy Loss": -0.019321374595165253, "Value Loss": 11.191145896911621, "_runtime": 9573.22423696518, "_timestamp": 1585579489.0688703, "_step": 469}
{"Episode reward": -99.81856818795065, "Episode length": 999, "Policy Loss": -1.3133717775344849, "Value Loss": 0.09203359484672546, "_runtime": 9574.773582696915, "_timestamp": 1585579490.618216, "_step": 470}
{"Episode reward": 1.8000000000013046, "Episode length": 982, "Policy Loss": -0.510357141494751, "Value Loss": 10.418387413024902, "_runtime": 9576.341572523117, "_timestamp": 1585579492.1862059, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2999207973480225, "Value Loss": 0.31533893942832947, "_runtime": 9577.421066761017, "_timestamp": 1585579493.2657, "_step": 472}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.057744890451431274, "Value Loss": 14.24094295501709, "_runtime": 9579.041776418686, "_timestamp": 1585579494.8864098, "_step": 473}
{"Episode reward": -99.88487285524467, "Episode length": 999, "Policy Loss": -1.0785222053527832, "Value Loss": 0.07276781648397446, "_runtime": 9580.621959209442, "_timestamp": 1585579496.4665926, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0013229846954346, "Value Loss": 0.2994040548801422, "_runtime": 9581.328583955765, "_timestamp": 1585579497.1732173, "_step": 475}
{"Episode reward": 55.79999999999965, "Episode length": 442, "Policy Loss": 0.9829811453819275, "Value Loss": 21.07088851928711, "_runtime": 9582.91298365593, "_timestamp": 1585579498.757617, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6420179009437561, "Value Loss": 0.014897695742547512, "_runtime": 9584.017609357834, "_timestamp": 1585579499.8622427, "_step": 477}
{"Episode reward": 30.299999999999685, "Episode length": 697, "Policy Loss": 0.5365902781486511, "Value Loss": 13.415980339050293, "_runtime": 9584.883758068085, "_timestamp": 1585579500.7283914, "_step": 478}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.8998891711235046, "Value Loss": 17.30130386352539, "_runtime": 9585.793347120285, "_timestamp": 1585579501.6379805, "_step": 479}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.837844967842102, "Value Loss": 17.044580459594727, "_runtime": 9587.356117486954, "_timestamp": 1585579503.2007508, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5299000144004822, "Value Loss": 0.049701713025569916, "_runtime": 9588.897188186646, "_timestamp": 1585579504.7418215, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6730769276618958, "Value Loss": 0.24371539056301117, "_runtime": 9590.438463926315, "_timestamp": 1585579506.2830973, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7322193384170532, "Value Loss": 0.013225225731730461, "_runtime": 9592.02591586113, "_timestamp": 1585579507.8705492, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8584469556808472, "Value Loss": 0.03452599048614502, "_runtime": 9593.59949851036, "_timestamp": 1585579509.4441319, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9495832920074463, "Value Loss": 0.029097747057676315, "_runtime": 9594.96818113327, "_timestamp": 1585579510.8128145, "_step": 485}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": -0.1355067938566208, "Value Loss": 10.871173858642578, "_runtime": 9596.557511091232, "_timestamp": 1585579512.4021444, "_step": 486}
{"Episode reward": -99.88301630020003, "Episode length": 999, "Policy Loss": -1.0630006790161133, "Value Loss": 0.11569537967443466, "_runtime": 9598.133291244507, "_timestamp": 1585579513.9779246, "_step": 487}
{"Episode reward": -99.81113825440268, "Episode length": 999, "Policy Loss": -1.0642595291137695, "Value Loss": 0.220854714512825, "_runtime": 9599.70652627945, "_timestamp": 1585579515.5511596, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0588328838348389, "Value Loss": 0.03367188572883606, "_runtime": 9601.29809331894, "_timestamp": 1585579517.1427267, "_step": 489}
{"Episode reward": -99.8089225307093, "Episode length": 999, "Policy Loss": -1.0190836191177368, "Value Loss": 0.07302656024694443, "_runtime": 9602.880474805832, "_timestamp": 1585579518.7251081, "_step": 490}
{"Episode reward": -99.80045569091895, "Episode length": 999, "Policy Loss": -0.969600260257721, "Value Loss": 0.04088444635272026, "_runtime": 9604.49872803688, "_timestamp": 1585579520.3433614, "_step": 491}
{"Episode reward": -99.80001706033805, "Episode length": 999, "Policy Loss": -0.8996727466583252, "Value Loss": 0.020217375829815865, "_runtime": 9606.091628074646, "_timestamp": 1585579521.9362614, "_step": 492}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": -0.08286003023386002, "Value Loss": 9.76873779296875, "_runtime": 9607.679066181183, "_timestamp": 1585579523.5236995, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7262524962425232, "Value Loss": 0.05507797747850418, "_runtime": 9609.259965658188, "_timestamp": 1585579525.104599, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6580525040626526, "Value Loss": 0.033324576914310455, "_runtime": 9610.599005699158, "_timestamp": 1585579526.443639, "_step": 495}
{"Episode reward": 15.900000000000503, "Episode length": 841, "Policy Loss": 0.2210918366909027, "Value Loss": 11.721611976623535, "_runtime": 9612.191232204437, "_timestamp": 1585579528.0358655, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47198572754859924, "Value Loss": 0.03941662982106209, "_runtime": 9613.78590965271, "_timestamp": 1585579529.630543, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41545000672340393, "Value Loss": 0.04439742863178253, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533, -0.0036679445765912533]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.2925799787044525, -0.28795111179351807, -0.2833222448825836, -0.2786933481693268, -0.27406448125839233, -0.2694356143474579, -0.26480674743652344, -0.2601778507232666, -0.25554898381233215, -0.2509201169013977, -0.24629123508930206, -0.24166236817836761, -0.23703348636627197, -0.23240461945533752, -0.22777575254440308, -0.22314687073230743, -0.2185179889202118, -0.21388912200927734, -0.2092602550983429, -0.20463137328624725, -0.2000024914741516, -0.19537362456321716, -0.19074475765228271, -0.18611587584018707, -0.18148700892925262, -0.17685812711715698, -0.17222926020622253, -0.16760039329528809, -0.16297151148319244, -0.1583426296710968, -0.15371376276016235, -0.1490848809480667, -0.14445601403713226, -0.13982714712619781, -0.13519826531410217, -0.13056939840316772, -0.12594051659107208, -0.12131164968013763, -0.11668276786804199, -0.11205390095710754, -0.1074250191450119, -0.10279615223407745, -0.09816727042198181, -0.09353840351104736, -0.08890952169895172, -0.08428065478801727, -0.07965177297592163, -0.07502290606498718, -0.07039403915405273, -0.06576515734195709, -0.061136290431022644, -0.056507408618927, -0.051878541707992554, -0.04724965989589691, -0.04262079298496246, -0.03799191117286682, -0.03336304426193237, -0.028734177350997925, -0.02410528063774109, -0.01947641372680664, -0.014847546815872192, -0.010218679904937744, -0.005589783191680908, -0.00096091628074646, 0.0036679506301879883]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.01593094691634178, -0.015682026743888855, -0.015433104708790779, -0.015184183605015278, -0.014935262501239777, -0.014686341397464275, -0.014437420293688774, -0.014188500121235847, -0.013939578086137772, -0.013690657913684845, -0.013441735878586769, -0.013192815706133842, -0.012943894602358341, -0.01269497349858284, -0.012446052394807339, -0.012197131291031837, -0.011948210187256336, -0.011699289083480835, -0.011450367979705334, -0.011201446875929832, -0.010952525772154331, -0.01070360466837883, -0.010454684495925903, -0.010205762460827827, -0.0099568422883749, -0.009707920253276825, -0.009459000080823898, -0.009210078045725822, -0.008961157873272896, -0.008712236769497395, -0.008463315665721893, -0.008214394561946392, -0.00796547345817089, -0.0077165523543953896, -0.007467631250619888, -0.007218710146844387, -0.006969789043068886, -0.0067208679392933846, -0.006471946835517883, -0.006223025731742382, -0.005974104627966881, -0.005725184455513954, -0.005476263351738453, -0.005227342247962952, -0.00497842114418745, -0.004729500040411949, -0.004480578936636448, -0.004231657832860947, -0.003982736729085445, -0.003733815625309944, -0.003484894521534443, -0.0032359734177589417, -0.0029870523139834404, -0.002738131210207939, -0.002489210106432438, -0.0022402890026569366, -0.00199136883020401, -0.0017424477264285088, -0.0014935266226530075, -0.0012446055188775063, -0.000995684415102005, -0.0007467633113265038, -0.0004978422075510025, -0.00024892017245292664, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 6.0, 6.0, 6.0, 4.0, 0.0, 1.0, 2.0, 7.0, 4.0, 5.0, 1.0, 3.0, 3.0, 328.0, 7.0, 9.0, 7.0, 21.0, 2.0, 3.0, 20.0, 12.0, 8.0, 3.0, 4.0, 4.0], "bins": [-0.06848973780870438, -0.06717110425233841, -0.06585247069597244, -0.06453384459018707, -0.0632152110338211, -0.06189657747745514, -0.06057794392108917, -0.059259310364723206, -0.05794067680835724, -0.05662204697728157, -0.055303413420915604, -0.053984783589839935, -0.05266615003347397, -0.051347516477108, -0.050028882920742035, -0.04871024936437607, -0.0473916195333004, -0.04607298970222473, -0.044754356145858765, -0.0434357225894928, -0.04211708903312683, -0.040798455476760864, -0.039479825645685196, -0.03816119208931923, -0.03684256225824356, -0.035523928701877594, -0.03420529514551163, -0.03288666158914566, -0.03156803175806999, -0.030249398201704025, -0.02893076464533806, -0.02761213481426239, -0.026293501257896423, -0.024974867701530457, -0.023656237870454788, -0.02233760431408882, -0.021018970757722855, -0.019700340926647186, -0.01838170737028122, -0.017063073813915253, -0.015744440257549286, -0.014425810426473618, -0.01310717687010765, -0.011788543313741684, -0.010469913482666016, -0.009151279926300049, -0.007832646369934082, -0.006514016538858414, -0.005195386707782745, -0.0038767531514167786, -0.0025581195950508118, -0.001239486038684845, 7.914751768112183e-05, 0.0013977810740470886, 0.0027164146304130554, 0.004035040736198425, 0.005353674292564392, 0.006672307848930359, 0.007990941405296326, 0.009309574961662292, 0.01062820851802826, 0.01194683462381363, 0.013265468180179596, 0.014584101736545563, 0.01590273529291153]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.25034818053245544, -0.24548028409481049, -0.24061238765716553, -0.23574449121952057, -0.2308765947818756, -0.22600871324539185, -0.2211408019065857, -0.21627292037010193, -0.21140502393245697, -0.206537127494812, -0.20166923105716705, -0.1968013346195221, -0.19193343818187714, -0.18706554174423218, -0.1821976602077484, -0.17732974886894226, -0.1724618673324585, -0.16759395599365234, -0.16272607445716858, -0.15785817801952362, -0.15299028158187866, -0.1481223851442337, -0.14325448870658875, -0.1383865922689438, -0.13351869583129883, -0.12865081429481506, -0.12378290295600891, -0.11891502141952515, -0.11404712498188019, -0.10917922854423523, -0.10431133210659027, -0.09944343566894531, -0.09457553923130035, -0.0897076427936554, -0.08483974635601044, -0.07997184991836548, -0.07510395348072052, -0.07023605704307556, -0.0653681755065918, -0.06050027906894684, -0.05563238263130188, -0.05076448619365692, -0.04589658975601196, -0.041028693318367004, -0.036160796880722046, -0.03129290044307709, -0.02642500400543213, -0.02155710756778717, -0.016689211130142212, -0.011821329593658447, -0.006953433156013489, -0.0020855367183685303, 0.002782374620437622, 0.007650256156921387, 0.012518137693405151, 0.017386049032211304, 0.02225393056869507, 0.02712184190750122, 0.031989723443984985, 0.03685763478279114, 0.0417255163192749, 0.046593427658081055, 0.05146130919456482, 0.05632922053337097, 0.061197102069854736]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 13.0, 7.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.1621999591588974, -0.15920522809028625, -0.1562104970216751, -0.15321575105190277, -0.15022101998329163, -0.14722628891468048, -0.14423155784606934, -0.141236811876297, -0.13824208080768585, -0.1352473497390747, -0.13225261867046356, -0.12925788760185242, -0.12626314163208008, -0.12326841056346893, -0.12027367949485779, -0.11727894097566605, -0.1142842024564743, -0.11128947138786316, -0.10829474031925201, -0.10530000180006027, -0.10230526328086853, -0.09931053221225739, -0.09631580114364624, -0.0933210626244545, -0.09032633155584335, -0.08733159303665161, -0.08433686196804047, -0.08134212344884872, -0.07834739238023758, -0.07535265386104584, -0.07235792279243469, -0.06936318427324295, -0.0663684532046318, -0.06337372213602066, -0.06037898361682892, -0.05738425254821777, -0.05438951402902603, -0.051394782960414886, -0.048400044441223145, -0.045405313372612, -0.04241057485342026, -0.03941584378480911, -0.03642110526561737, -0.033426374197006226, -0.03043164312839508, -0.02743689715862274, -0.024442166090011597, -0.02144743502140045, -0.018452703952789307, -0.015457972884178162, -0.012463226914405823, -0.009468495845794678, -0.006473764777183533, -0.0034790337085723877, -0.00048428773880004883, 0.002510443329811096, 0.005505174398422241, 0.008499905467033386, 0.011494651436805725, 0.01448938250541687, 0.017484113574028015, 0.02047884464263916, 0.0234735906124115, 0.026468321681022644, 0.02946305274963379]}, "_runtime": 9615.369945287704, "_timestamp": 1585579531.2145786, "_step": 498}
{"Episode reward": -99.80999584793905, "Episode length": 999, "Policy Loss": -0.3257284462451935, "Value Loss": 0.0497162789106369, "_runtime": 9615.369945287704, "_timestamp": 1585579531.2145786, "_step": 499}
