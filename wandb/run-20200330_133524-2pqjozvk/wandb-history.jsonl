{"Episode reward": 79.40647137883718, "Episode length": 523, "Policy Loss": 0.04805399850010872, "Value Loss": 19.151025772094727, "_runtime": 5419.714178800583, "_timestamp": 1585575335.5588121, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4712088108062744, "Value Loss": 197.9738006591797, "_runtime": 5421.186846494675, "_timestamp": 1585575337.0314798, "_step": 1}
{"Episode reward": -64.25217174529153, "Episode length": 999, "Policy Loss": -1.7969837188720703, "Value Loss": 1228.4072265625, "_runtime": 5422.712808609009, "_timestamp": 1585575338.557442, "_step": 2}
{"Episode reward": -71.73423830421935, "Episode length": 999, "Policy Loss": -1.8163286447525024, "Value Loss": 205.432861328125, "_runtime": 5424.269492387772, "_timestamp": 1585575340.1141257, "_step": 3}
{"Episode reward": -86.4142526235061, "Episode length": 999, "Policy Loss": -16.659055709838867, "Value Loss": 9312.78515625, "_runtime": 5425.797656536102, "_timestamp": 1585575341.6422899, "_step": 4}
{"Episode reward": -90.17856911744708, "Episode length": 999, "Policy Loss": 4.461958885192871, "Value Loss": 2284.23681640625, "_runtime": 5427.01886343956, "_timestamp": 1585575342.8634968, "_step": 5}
{"Episode reward": 28.88043749224329, "Episode length": 778, "Policy Loss": 15.006917953491211, "Value Loss": 1386.4969482421875, "_runtime": 5427.929461240768, "_timestamp": 1585575343.7740946, "_step": 6}
{"Episode reward": 47.00861825366428, "Episode length": 571, "Policy Loss": -2.569591999053955, "Value Loss": 46295.609375, "_runtime": 5429.262980461121, "_timestamp": 1585575345.1076138, "_step": 7}
{"Episode reward": 17.787028582865844, "Episode length": 875, "Policy Loss": 11.27249813079834, "Value Loss": 420.1000671386719, "_runtime": 5429.912847518921, "_timestamp": 1585575345.7574809, "_step": 8}
{"Episode reward": 61.7617251550346, "Episode length": 406, "Policy Loss": 12.885917663574219, "Value Loss": 4806.8486328125, "_runtime": 5431.407310962677, "_timestamp": 1585575347.2519443, "_step": 9}
{"Episode reward": 7.649357269020996, "Episode length": 971, "Policy Loss": 1.8765562772750854, "Value Loss": 1035.0069580078125, "_runtime": 5432.937383890152, "_timestamp": 1585575348.7820172, "_step": 10}
{"Episode reward": -95.34910347711656, "Episode length": 999, "Policy Loss": -4.268882751464844, "Value Loss": 236.75961303710938, "_runtime": 5434.432936191559, "_timestamp": 1585575350.2775695, "_step": 11}
{"Episode reward": -95.02490848556465, "Episode length": 999, "Policy Loss": -6.1535563468933105, "Value Loss": 11624.3818359375, "_runtime": 5435.78342461586, "_timestamp": 1585575351.628058, "_step": 12}
{"Episode reward": 17.019715011606067, "Episode length": 865, "Policy Loss": -10.31980037689209, "Value Loss": 1607.953857421875, "_runtime": 5437.377876758575, "_timestamp": 1585575353.22251, "_step": 13}
{"Episode reward": -95.42044075162734, "Episode length": 999, "Policy Loss": -6.608875274658203, "Value Loss": 456.9817810058594, "_runtime": 5438.903287887573, "_timestamp": 1585575354.7479212, "_step": 14}
{"Episode reward": -96.35577458688232, "Episode length": 999, "Policy Loss": -6.032017230987549, "Value Loss": 62.96445083618164, "_runtime": 5440.457321643829, "_timestamp": 1585575356.301955, "_step": 15}
{"Episode reward": -95.89523018679816, "Episode length": 999, "Policy Loss": -4.932100772857666, "Value Loss": 397.9797058105469, "_runtime": 5442.006709575653, "_timestamp": 1585575357.851343, "_step": 16}
{"Episode reward": -96.26688491842805, "Episode length": 999, "Policy Loss": -2.4653170108795166, "Value Loss": 343.33538818359375, "_runtime": 5443.04177570343, "_timestamp": 1585575358.886409, "_step": 17}
{"Episode reward": 36.43633486971148, "Episode length": 657, "Policy Loss": -1.2517567873001099, "Value Loss": 1411.124755859375, "_runtime": 5444.611026763916, "_timestamp": 1585575360.45566, "_step": 18}
{"Episode reward": -95.34439855140037, "Episode length": 999, "Policy Loss": 1.4915056228637695, "Value Loss": 209.73712158203125, "_runtime": 5445.74752497673, "_timestamp": 1585575361.5921583, "_step": 19}
{"Episode reward": 31.179927221010246, "Episode length": 723, "Policy Loss": 4.2757463455200195, "Value Loss": 1160.817626953125, "_runtime": 5447.284160375595, "_timestamp": 1585575363.1287937, "_step": 20}
{"Episode reward": -95.83850287453191, "Episode length": 999, "Policy Loss": 2.4812581539154053, "Value Loss": 942.6397705078125, "_runtime": 5448.853012561798, "_timestamp": 1585575364.697646, "_step": 21}
{"Episode reward": -96.12349910298586, "Episode length": 999, "Policy Loss": 6.179609298706055, "Value Loss": 142.2877655029297, "_runtime": 5450.382900238037, "_timestamp": 1585575366.2275336, "_step": 22}
{"Episode reward": -96.05342772690135, "Episode length": 999, "Policy Loss": 6.958483695983887, "Value Loss": 183.08848571777344, "_runtime": 5451.942568778992, "_timestamp": 1585575367.7872021, "_step": 23}
{"Episode reward": -95.66214773332193, "Episode length": 999, "Policy Loss": 8.610016822814941, "Value Loss": 306.66448974609375, "_runtime": 5452.9927270412445, "_timestamp": 1585575368.8373604, "_step": 24}
{"Episode reward": 36.5587509741842, "Episode length": 661, "Policy Loss": 11.965553283691406, "Value Loss": 1477.1778564453125, "_runtime": 5454.097195148468, "_timestamp": 1585575369.9418285, "_step": 25}
{"Episode reward": 32.215958979478756, "Episode length": 702, "Policy Loss": 3.0404179096221924, "Value Loss": 690.9537353515625, "_runtime": 5455.649146318436, "_timestamp": 1585575371.4937797, "_step": 26}
{"Episode reward": -95.71465920058361, "Episode length": 999, "Policy Loss": 0.016319023445248604, "Value Loss": 1241.10888671875, "_runtime": 5457.185076236725, "_timestamp": 1585575373.0297096, "_step": 27}
{"Episode reward": -96.04510287828218, "Episode length": 999, "Policy Loss": 2.4860758781433105, "Value Loss": 541.0250854492188, "_runtime": 5458.699629545212, "_timestamp": 1585575374.544263, "_step": 28}
{"Episode reward": -97.04744731727108, "Episode length": 999, "Policy Loss": 3.384697914123535, "Value Loss": 136.38885498046875, "_runtime": 5460.287389039993, "_timestamp": 1585575376.1320224, "_step": 29}
{"Episode reward": -95.80326225937935, "Episode length": 999, "Policy Loss": 5.381293773651123, "Value Loss": 11.584364891052246, "_runtime": 5461.0721962451935, "_timestamp": 1585575376.9168296, "_step": 30}
{"Episode reward": 53.3770003863173, "Episode length": 480, "Policy Loss": 10.858307838439941, "Value Loss": 619.8372802734375, "_runtime": 5462.545828104019, "_timestamp": 1585575378.3904614, "_step": 31}
{"Episode reward": 9.419471073839304, "Episode length": 947, "Policy Loss": 7.186872482299805, "Value Loss": 119.85125732421875, "_runtime": 5463.741362094879, "_timestamp": 1585575379.5859954, "_step": 32}
{"Episode reward": 25.77391603441717, "Episode length": 771, "Policy Loss": 4.189791202545166, "Value Loss": 77.12519073486328, "_runtime": 5464.3327515125275, "_timestamp": 1585575380.1773849, "_step": 33}
{"Episode reward": 63.17513741636138, "Episode length": 384, "Policy Loss": 3.6209771633148193, "Value Loss": 127.15998077392578, "_runtime": 5465.875463008881, "_timestamp": 1585575381.7200963, "_step": 34}
{"Episode reward": -96.91452654106278, "Episode length": 999, "Policy Loss": 1.8755848407745361, "Value Loss": 107.90020751953125, "_runtime": 5467.400630474091, "_timestamp": 1585575383.2452638, "_step": 35}
{"Episode reward": -96.1779715534572, "Episode length": 999, "Policy Loss": 1.3330234289169312, "Value Loss": 136.83062744140625, "_runtime": 5468.884229898453, "_timestamp": 1585575384.7288632, "_step": 36}
{"Episode reward": -95.40944635669567, "Episode length": 999, "Policy Loss": 0.21831169724464417, "Value Loss": 270.18572998046875, "_runtime": 5470.427159547806, "_timestamp": 1585575386.271793, "_step": 37}
{"Episode reward": -96.75981904497883, "Episode length": 999, "Policy Loss": 1.478197455406189, "Value Loss": 84.8345947265625, "_runtime": 5471.97744178772, "_timestamp": 1585575387.8220751, "_step": 38}
{"Episode reward": -96.46822804705286, "Episode length": 999, "Policy Loss": 2.956458568572998, "Value Loss": 32.82408905029297, "_runtime": 5473.504515886307, "_timestamp": 1585575389.3491492, "_step": 39}
{"Episode reward": -97.05345943492922, "Episode length": 999, "Policy Loss": 3.208469867706299, "Value Loss": 31.529592514038086, "_runtime": 5474.640342235565, "_timestamp": 1585575390.4849756, "_step": 40}
{"Episode reward": 30.374099969889826, "Episode length": 724, "Policy Loss": 5.21780252456665, "Value Loss": 100.87593078613281, "_runtime": 5475.60083937645, "_timestamp": 1585575391.4454727, "_step": 41}
{"Episode reward": 41.16481773973947, "Episode length": 613, "Policy Loss": 4.731362342834473, "Value Loss": 94.0298080444336, "_runtime": 5477.145880937576, "_timestamp": 1585575392.9905143, "_step": 42}
{"Episode reward": -97.30572833512672, "Episode length": 999, "Policy Loss": 5.0992889404296875, "Value Loss": 45.05155563354492, "_runtime": 5478.690957546234, "_timestamp": 1585575394.535591, "_step": 43}
{"Episode reward": -96.51510662612127, "Episode length": 999, "Policy Loss": 3.83682918548584, "Value Loss": 5.667952537536621, "_runtime": 5480.20508146286, "_timestamp": 1585575396.0497148, "_step": 44}
{"Episode reward": -96.76923800491532, "Episode length": 999, "Policy Loss": 3.5093910694122314, "Value Loss": 4.814964771270752, "_runtime": 5481.661339759827, "_timestamp": 1585575397.505973, "_step": 45}
{"Episode reward": 9.012421378006195, "Episode length": 942, "Policy Loss": 3.1726791858673096, "Value Loss": 13.659660339355469, "_runtime": 5482.34653544426, "_timestamp": 1585575398.1911688, "_step": 46}
{"Episode reward": 58.682166869778214, "Episode length": 427, "Policy Loss": 2.586141347885132, "Value Loss": 48.88853454589844, "_runtime": 5482.834702014923, "_timestamp": 1585575398.6793354, "_step": 47}
{"Episode reward": 71.63623375671514, "Episode length": 296, "Policy Loss": 3.0497283935546875, "Value Loss": 54.54378890991211, "_runtime": 5484.419095039368, "_timestamp": 1585575400.2637284, "_step": 48}
{"Episode reward": -95.1580868447641, "Episode length": 999, "Policy Loss": 2.794870376586914, "Value Loss": 2.0542166233062744, "_runtime": 5485.915466070175, "_timestamp": 1585575401.7600994, "_step": 49}
{"Episode reward": -94.81125287461995, "Episode length": 999, "Policy Loss": 3.076154947280884, "Value Loss": 5.2006144523620605, "_runtime": 5487.390501260757, "_timestamp": 1585575403.2351346, "_step": 50}
{"Episode reward": -96.19909321999286, "Episode length": 999, "Policy Loss": 3.052213191986084, "Value Loss": 5.518362045288086, "_runtime": 5488.9397649765015, "_timestamp": 1585575404.7843983, "_step": 51}
{"Episode reward": -96.3818951421797, "Episode length": 999, "Policy Loss": 4.189992427825928, "Value Loss": 26.605623245239258, "_runtime": 5490.4886310100555, "_timestamp": 1585575406.3332644, "_step": 52}
{"Episode reward": -95.9734862773601, "Episode length": 999, "Policy Loss": 2.9556069374084473, "Value Loss": 3.251455545425415, "_runtime": 5491.8204753398895, "_timestamp": 1585575407.6651087, "_step": 53}
{"Episode reward": 16.364939562074255, "Episode length": 877, "Policy Loss": 3.208500385284424, "Value Loss": 18.293184280395508, "_runtime": 5492.705005407333, "_timestamp": 1585575408.5496387, "_step": 54}
{"Episode reward": 46.42030133087109, "Episode length": 559, "Policy Loss": 4.0122880935668945, "Value Loss": 36.92646408081055, "_runtime": 5494.259192228317, "_timestamp": 1585575410.1038256, "_step": 55}
{"Episode reward": -95.77838637469449, "Episode length": 999, "Policy Loss": 2.3510117530822754, "Value Loss": 5.712199687957764, "_runtime": 5494.95813369751, "_timestamp": 1585575410.802767, "_step": 56}
{"Episode reward": 56.95750485825325, "Episode length": 445, "Policy Loss": 2.9725217819213867, "Value Loss": 29.897296905517578, "_runtime": 5496.4012362957, "_timestamp": 1585575412.2458696, "_step": 57}
{"Episode reward": 8.321706441005531, "Episode length": 952, "Policy Loss": 2.1863961219787598, "Value Loss": 16.615060806274414, "_runtime": 5497.311387300491, "_timestamp": 1585575413.1560206, "_step": 58}
{"Episode reward": 45.62161121809139, "Episode length": 574, "Policy Loss": 2.3449018001556396, "Value Loss": 24.799766540527344, "_runtime": 5498.80978512764, "_timestamp": 1585575414.6544185, "_step": 59}
{"Episode reward": -96.25108821612106, "Episode length": 999, "Policy Loss": 1.8616943359375, "Value Loss": 0.424862802028656, "_runtime": 5500.365029811859, "_timestamp": 1585575416.2096632, "_step": 60}
{"Episode reward": -95.93817151921905, "Episode length": 999, "Policy Loss": 1.8779581785202026, "Value Loss": 0.36288490891456604, "_runtime": 5501.876612186432, "_timestamp": 1585575417.7212455, "_step": 61}
{"Episode reward": -96.35282188881335, "Episode length": 999, "Policy Loss": 1.9593485593795776, "Value Loss": 0.8520761132240295, "_runtime": 5502.762786149979, "_timestamp": 1585575418.6074195, "_step": 62}
{"Episode reward": 46.456393027836725, "Episode length": 563, "Policy Loss": 2.3275957107543945, "Value Loss": 18.58747100830078, "_runtime": 5503.884514093399, "_timestamp": 1585575419.7291474, "_step": 63}
{"Episode reward": 31.900433241571363, "Episode length": 716, "Policy Loss": 2.1639373302459717, "Value Loss": 16.22941780090332, "_runtime": 5505.435807228088, "_timestamp": 1585575421.2804406, "_step": 64}
{"Episode reward": -95.94954708977717, "Episode length": 999, "Policy Loss": 1.8528684377670288, "Value Loss": 1.1590734720230103, "_runtime": 5506.710814237595, "_timestamp": 1585575422.5554476, "_step": 65}
{"Episode reward": 21.988627298891643, "Episode length": 818, "Policy Loss": 2.18011212348938, "Value Loss": 13.032350540161133, "_runtime": 5507.2868275642395, "_timestamp": 1585575423.131461, "_step": 66}
{"Episode reward": 65.03911658806943, "Episode length": 365, "Policy Loss": 2.5895142555236816, "Value Loss": 29.126941680908203, "_runtime": 5508.503573417664, "_timestamp": 1585575424.3482068, "_step": 67}
{"Episode reward": 24.393068221091397, "Episode length": 782, "Policy Loss": 2.0247161388397217, "Value Loss": 13.320666313171387, "_runtime": 5509.764817476273, "_timestamp": 1585575425.6094508, "_step": 68}
{"Episode reward": 20.351249171308254, "Episode length": 823, "Policy Loss": 1.9852604866027832, "Value Loss": 16.11883544921875, "_runtime": 5510.8708600997925, "_timestamp": 1585575426.7154934, "_step": 69}
{"Episode reward": 28.467401636788196, "Episode length": 745, "Policy Loss": 2.4374873638153076, "Value Loss": 14.551040649414062, "_runtime": 5511.505788087845, "_timestamp": 1585575427.3504214, "_step": 70}
{"Episode reward": 62.7250987995196, "Episode length": 393, "Policy Loss": 2.491941213607788, "Value Loss": 27.659704208374023, "_runtime": 5512.819019317627, "_timestamp": 1585575428.6636527, "_step": 71}
{"Episode reward": 18.015498478021925, "Episode length": 856, "Policy Loss": 2.0255355834960938, "Value Loss": 13.602792739868164, "_runtime": 5514.3551614284515, "_timestamp": 1585575430.1997948, "_step": 72}
{"Episode reward": -95.231302280214, "Episode length": 999, "Policy Loss": 1.3253172636032104, "Value Loss": 0.6066625714302063, "_runtime": 5515.858127832413, "_timestamp": 1585575431.7027612, "_step": 73}
{"Episode reward": -96.0691695901075, "Episode length": 999, "Policy Loss": 1.334004521369934, "Value Loss": 1.1941487789154053, "_runtime": 5517.402540206909, "_timestamp": 1585575433.2471735, "_step": 74}
{"Episode reward": -95.94865693304506, "Episode length": 999, "Policy Loss": 1.290043830871582, "Value Loss": 0.2689417600631714, "_runtime": 5518.745341539383, "_timestamp": 1585575434.5899749, "_step": 75}
{"Episode reward": 16.94787122236039, "Episode length": 868, "Policy Loss": 1.502825379371643, "Value Loss": 12.727500915527344, "_runtime": 5519.85679101944, "_timestamp": 1585575435.7014244, "_step": 76}
{"Episode reward": 32.52804049527211, "Episode length": 709, "Policy Loss": 1.7658355236053467, "Value Loss": 15.84140396118164, "_runtime": 5521.424378156662, "_timestamp": 1585575437.2690115, "_step": 77}
{"Episode reward": -96.27411855277545, "Episode length": 999, "Policy Loss": 1.257670283317566, "Value Loss": 0.227091446518898, "_runtime": 5522.554879188538, "_timestamp": 1585575438.3995125, "_step": 78}
{"Episode reward": 30.567728170130593, "Episode length": 728, "Policy Loss": 1.680299997329712, "Value Loss": 13.943172454833984, "_runtime": 5523.689533233643, "_timestamp": 1585575439.5341666, "_step": 79}
{"Episode reward": 28.811025598194135, "Episode length": 738, "Policy Loss": 1.764547348022461, "Value Loss": 13.706270217895508, "_runtime": 5525.256600379944, "_timestamp": 1585575441.1012337, "_step": 80}
{"Episode reward": -96.62217291444216, "Episode length": 999, "Policy Loss": 1.386700987815857, "Value Loss": 0.28230857849121094, "_runtime": 5526.780218362808, "_timestamp": 1585575442.6248517, "_step": 81}
{"Episode reward": -96.90369210823654, "Episode length": 999, "Policy Loss": 1.4614099264144897, "Value Loss": 0.42148804664611816, "_runtime": 5527.900338888168, "_timestamp": 1585575443.7449722, "_step": 82}
{"Episode reward": 30.71818660150565, "Episode length": 722, "Policy Loss": 2.0843050479888916, "Value Loss": 14.855323791503906, "_runtime": 5529.489855051041, "_timestamp": 1585575445.3344884, "_step": 83}
{"Episode reward": -95.29650230569037, "Episode length": 999, "Policy Loss": 1.4414771795272827, "Value Loss": 0.46780484914779663, "_runtime": 5531.043730258942, "_timestamp": 1585575446.8883636, "_step": 84}
{"Episode reward": -97.22337041420582, "Episode length": 999, "Policy Loss": 1.4312149286270142, "Value Loss": 0.47519391775131226, "_runtime": 5532.577905416489, "_timestamp": 1585575448.4225388, "_step": 85}
{"Episode reward": -96.00060027261875, "Episode length": 999, "Policy Loss": 1.416020154953003, "Value Loss": 0.8301013708114624, "_runtime": 5534.152097225189, "_timestamp": 1585575449.9967306, "_step": 86}
{"Episode reward": -96.54998058267441, "Episode length": 999, "Policy Loss": 1.281531810760498, "Value Loss": 0.2412712275981903, "_runtime": 5535.713714122772, "_timestamp": 1585575451.5583475, "_step": 87}
{"Episode reward": -95.78996408934887, "Episode length": 999, "Policy Loss": 1.2390376329421997, "Value Loss": 0.1252332627773285, "_runtime": 5537.271272659302, "_timestamp": 1585575453.115906, "_step": 88}
{"Episode reward": -95.85712517601495, "Episode length": 999, "Policy Loss": 1.2193125486373901, "Value Loss": 0.6140251755714417, "_runtime": 5538.096933364868, "_timestamp": 1585575453.9415667, "_step": 89}
{"Episode reward": 49.34695996485499, "Episode length": 520, "Policy Loss": 1.7362557649612427, "Value Loss": 19.53772735595703, "_runtime": 5539.667788028717, "_timestamp": 1585575455.5124214, "_step": 90}
{"Episode reward": -96.49151545673129, "Episode length": 999, "Policy Loss": 1.072731852531433, "Value Loss": 0.4440200626850128, "_runtime": 5540.529335737228, "_timestamp": 1585575456.373969, "_step": 91}
{"Episode reward": 48.659627347869595, "Episode length": 535, "Policy Loss": 1.6768301725387573, "Value Loss": 18.837942123413086, "_runtime": 5541.115026712418, "_timestamp": 1585575456.95966, "_step": 92}
{"Episode reward": 64.16006458479396, "Episode length": 372, "Policy Loss": 1.9139444828033447, "Value Loss": 26.542911529541016, "_runtime": 5542.667833328247, "_timestamp": 1585575458.5124667, "_step": 93}
{"Episode reward": -96.40391996032774, "Episode length": 999, "Policy Loss": 1.0676778554916382, "Value Loss": 0.0887334868311882, "_runtime": 5544.192151784897, "_timestamp": 1585575460.0367851, "_step": 94}
{"Episode reward": -95.71791543551893, "Episode length": 999, "Policy Loss": 1.179287075996399, "Value Loss": 0.48211267590522766, "_runtime": 5545.695153713226, "_timestamp": 1585575461.539787, "_step": 95}
{"Episode reward": -96.81769316042885, "Episode length": 999, "Policy Loss": 1.0956904888153076, "Value Loss": 0.18233679234981537, "_runtime": 5546.332963943481, "_timestamp": 1585575462.1775973, "_step": 96}
{"Episode reward": 62.71277720949973, "Episode length": 384, "Policy Loss": 1.9029542207717896, "Value Loss": 25.250181198120117, "_runtime": 5547.885707855225, "_timestamp": 1585575463.7303412, "_step": 97}
{"Episode reward": -96.44349314063254, "Episode length": 999, "Policy Loss": 1.0585283041000366, "Value Loss": 0.19996322691440582, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793, -2.3254237174987793]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 5.0], "bins": [-7.9427809715271, -7.783370018005371, -7.623958587646484, -7.464547634124756, -7.305136203765869, -7.145725250244141, -6.986313819885254, -6.826902866363525, -6.667491436004639, -6.50808048248291, -6.348669052124023, -6.189258098602295, -6.029847145080566, -5.87043571472168, -5.711024284362793, -5.5516133308410645, -5.392202377319336, -5.232790946960449, -5.0733795166015625, -4.913968563079834, -4.7545576095581055, -4.595146179199219, -4.435734748840332, -4.2763237953186035, -4.116912841796875, -3.9575016498565674, -3.7980904579162598, -3.638679027557373, -3.4792680740356445, -3.319856643676758, -3.1604456901550293, -3.0010342597961426, -2.841623306274414, -2.6822123527526855, -2.522800922393799, -2.3633899688720703, -2.2039785385131836, -2.044567584991455, -1.8851561546325684, -1.7257452011108398, -1.5663337707519531, -1.4069228172302246, -1.247511386871338, -1.0881004333496094, -0.9286890029907227, -0.7692780494689941, -0.6098666191101074, -0.4504556655883789, -0.2910447120666504, -0.13163328170776367, 0.027777671813964844, 0.18718862533569336, 0.3466000556945801, 0.5060114860534668, 0.6654229164123535, 0.8248333930969238, 0.9842448234558105, 1.1436562538146973, 1.303067684173584, 1.4624781608581543, 1.621889591217041, 1.7813010215759277, 1.9407124519348145, 2.1001229286193848, 2.2595343589782715]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.5838457345962524, -1.5544275045394897, -1.5250091552734375, -1.4955909252166748, -1.4661725759506226, -1.4367543458938599, -1.4073359966278076, -1.377917766571045, -1.3484995365142822, -1.31908118724823, -1.2896628379821777, -1.260244607925415, -1.2308263778686523, -1.2014080286026, -1.1719897985458374, -1.1425714492797852, -1.1131532192230225, -1.0837349891662598, -1.0543166399002075, -1.0248982906341553, -0.9954800605773926, -0.9660618305206299, -0.9366435408592224, -0.9072252511978149, -0.8778069615364075, -0.848388671875, -0.8189703822135925, -0.7895520925521851, -0.7601338624954224, -0.7307155728340149, -0.7012972831726074, -0.6718789935112, -0.6424607038497925, -0.613042414188385, -0.5836241245269775, -0.5542058944702148, -0.5247875452041626, -0.4953693151473999, -0.46595096588134766, -0.43653273582458496, -0.4071143865585327, -0.37769615650177, -0.3482779264450073, -0.3188595771789551, -0.2894413471221924, -0.26002299785614014, -0.23060476779937744, -0.2011864185333252, -0.1717681884765625, -0.1423499584197998, -0.11293160915374756, -0.08351337909698486, -0.05409502983093262, -0.024676799774169922, 0.004741549491882324, 0.03415977954864502, 0.06357800960540771, 0.09299635887145996, 0.12241458892822266, 0.1518329381942749, 0.1812511682510376, 0.21066951751708984, 0.24008774757385254, 0.2695060968399048, 0.2989243268966675]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 5.0, 5.0, 5.0, 8.0, 14.0, 26.0, 26.0, 179.0, 123.0, 27.0, 20.0, 9.0, 2.0, 6.0, 6.0, 4.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0], "bins": [-3.051002025604248, -2.978101968765259, -2.9052016735076904, -2.832301616668701, -2.759401321411133, -2.6865012645721436, -2.6136012077331543, -2.540700912475586, -2.4678008556365967, -2.3949005603790283, -2.322000503540039, -2.2491002082824707, -2.1762001514434814, -2.103300094604492, -2.030399799346924, -1.9574997425079346, -1.8845995664596558, -1.811699390411377, -1.7387992143630981, -1.6658991575241089, -1.59299898147583, -1.5200988054275513, -1.4471986293792725, -1.3742984533309937, -1.3013982772827148, -1.2284982204437256, -1.1555980443954468, -1.082697868347168, -1.0097978115081787, -0.9368975162506104, -0.8639974594116211, -0.7910971641540527, -0.7181971073150635, -0.6452970504760742, -0.5723967552185059, -0.4994966983795166, -0.42659640312194824, -0.353696346282959, -0.2807962894439697, -0.20789599418640137, -0.1349959373474121, -0.06209564208984375, 0.010804414749145508, 0.08370447158813477, 0.15660476684570312, 0.22950482368469238, 0.30240511894226074, 0.37530517578125, 0.44820547103881836, 0.5211055278778076, 0.5940055847167969, 0.6669058799743652, 0.7398059368133545, 0.8127062320709229, 0.8856062889099121, 0.9585065841674805, 1.0314064025878906, 1.104306697845459, 1.1772069931030273, 1.2501068115234375, 1.3230071067810059, 1.3959074020385742, 1.4688076972961426, 1.5417075157165527, 1.614607810974121]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.2111446857452393, -3.082124710083008, -2.9531049728393555, -2.824084997177124, -2.6950650215148926, -2.5660452842712402, -2.437025308609009, -2.3080053329467773, -2.178985595703125, -2.0499656200408936, -1.920945644378662, -1.7919257879257202, -1.6629059314727783, -1.5338859558105469, -1.404866099357605, -1.2758461236953735, -1.1468262672424316, -1.0178062915802002, -0.8887865543365479, -0.7597665786743164, -0.630746603012085, -0.5017268657684326, -0.37270689010620117, -0.24368691444396973, -0.11466717720031738, 0.014352798461914062, 0.1433727741241455, 0.27239274978637695, 0.4014124870300293, 0.5304324626922607, 0.6594524383544922, 0.7884721755981445, 0.917492151260376, 1.0465118885040283, 1.1755321025848389, 1.3045518398284912, 1.4335715770721436, 1.562591791152954, 1.6916115283966064, 1.8206312656402588, 1.9496514797210693, 2.0786712169647217, 2.207690954208374, 2.3367111682891846, 2.465730905532837, 2.5947506427764893, 2.7237708568573, 2.852790594100952, 2.9818103313446045, 3.110830545425415, 3.2398502826690674, 3.368870496749878, 3.4978902339935303, 3.6269099712371826, 3.755930185317993, 3.8849499225616455, 4.013969421386719, 4.1429901123046875, 4.27200984954834, 4.401029586791992, 4.5300493240356445, 4.659069061279297, 4.788088798522949, 4.917109489440918, 5.04612922668457]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-3.1197969913482666, -3.03163480758667, -2.943472385406494, -2.8553102016448975, -2.767148017883301, -2.678985595703125, -2.5908234119415283, -2.5026612281799316, -2.414498805999756, -2.32633638381958, -2.2381742000579834, -2.1500120162963867, -2.061849594116211, -1.9736874103546143, -1.8855252265930176, -1.7973629236221313, -1.7092006206512451, -1.6210383176803589, -1.5328760147094727, -1.444713830947876, -1.3565515279769897, -1.2683892250061035, -1.1802270412445068, -1.092064619064331, -1.0039024353027344, -0.9157402515411377, -0.8275778293609619, -0.7394156455993652, -0.6512534618377686, -0.5630910396575928, -0.4749288558959961, -0.3867664337158203, -0.29860424995422363, -0.21044206619262695, -0.12227964401245117, -0.03411746025085449, 0.05404496192932129, 0.14220714569091797, 0.23036932945251465, 0.31853175163269043, 0.4066939353942871, 0.4948561191558838, 0.5830185413360596, 0.6711807250976562, 0.7593429088592529, 0.8475053310394287, 0.9356677532196045, 1.023829698562622, 1.1119921207427979, 1.2001545429229736, 1.2883164882659912, 1.376478910446167, 1.4646413326263428, 1.5528032779693604, 1.6409657001495361, 1.729128122329712, 1.8172900676727295, 1.9054524898529053, 1.993614912033081, 2.081777334213257, 2.1699392795562744, 2.25810170173645, 2.346264123916626, 2.4344260692596436, 2.5225884914398193]}, "_runtime": 5549.435033082962, "_timestamp": 1585575465.2796664, "_step": 98}
{"Episode reward": -96.99428905167731, "Episode length": 999, "Policy Loss": 1.088329553604126, "Value Loss": 0.3431873023509979, "_runtime": 5550.935847520828, "_timestamp": 1585575466.7804809, "_step": 99}
{"Episode reward": -96.45338081236, "Episode length": 999, "Policy Loss": 1.0510121583938599, "Value Loss": 0.20379723608493805, "_runtime": 5552.503905057907, "_timestamp": 1585575468.3485384, "_step": 100}
{"Episode reward": -96.0542099415382, "Episode length": 999, "Policy Loss": 0.979179322719574, "Value Loss": 0.09933840483427048, "_runtime": 5554.10325551033, "_timestamp": 1585575469.9478889, "_step": 101}
{"Episode reward": -96.3067853336244, "Episode length": 999, "Policy Loss": 1.0157573223114014, "Value Loss": 0.507921040058136, "_runtime": 5555.494745969772, "_timestamp": 1585575471.3393793, "_step": 102}
{"Episode reward": 14.145776758931902, "Episode length": 895, "Policy Loss": 1.442427158355713, "Value Loss": 10.96284294128418, "_runtime": 5557.067374706268, "_timestamp": 1585575472.912008, "_step": 103}
{"Episode reward": -95.75758207555668, "Episode length": 999, "Policy Loss": 0.8259243965148926, "Value Loss": 0.09095834940671921, "_runtime": 5557.75989484787, "_timestamp": 1585575473.6045282, "_step": 104}
{"Episode reward": 59.270365431816366, "Episode length": 424, "Policy Loss": 1.6650128364562988, "Value Loss": 23.38484001159668, "_runtime": 5559.300137996674, "_timestamp": 1585575475.1447713, "_step": 105}
{"Episode reward": -96.97627115855889, "Episode length": 999, "Policy Loss": 0.7816077470779419, "Value Loss": 0.05915458872914314, "_runtime": 5560.822750329971, "_timestamp": 1585575476.6673837, "_step": 106}
{"Episode reward": 6.596434766073642, "Episode length": 971, "Policy Loss": 1.0960215330123901, "Value Loss": 10.198465347290039, "_runtime": 5562.330762386322, "_timestamp": 1585575478.1753957, "_step": 107}
{"Episode reward": -95.76453652521067, "Episode length": 999, "Policy Loss": 0.7849333882331848, "Value Loss": 0.07917852699756622, "_runtime": 5563.884300708771, "_timestamp": 1585575479.728934, "_step": 108}
{"Episode reward": -96.32483036415375, "Episode length": 999, "Policy Loss": 0.7931234836578369, "Value Loss": 0.06786282360553741, "_runtime": 5565.403015375137, "_timestamp": 1585575481.2476487, "_step": 109}
{"Episode reward": 5.658779498420515, "Episode length": 967, "Policy Loss": 1.2683782577514648, "Value Loss": 10.371262550354004, "_runtime": 5566.946846246719, "_timestamp": 1585575482.7914796, "_step": 110}
{"Episode reward": -96.7606690492687, "Episode length": 999, "Policy Loss": 0.7730337977409363, "Value Loss": 0.10590465366840363, "_runtime": 5568.512995481491, "_timestamp": 1585575484.3576288, "_step": 111}
{"Episode reward": -96.69000350841698, "Episode length": 999, "Policy Loss": 0.8195050954818726, "Value Loss": 0.13887877762317657, "_runtime": 5570.0671310424805, "_timestamp": 1585575485.9117644, "_step": 112}
{"Episode reward": -96.54175942054253, "Episode length": 999, "Policy Loss": 0.7761277556419373, "Value Loss": 0.06426309049129486, "_runtime": 5571.233045101166, "_timestamp": 1585575487.0776784, "_step": 113}
{"Episode reward": 28.344371698825867, "Episode length": 744, "Policy Loss": 1.20256769657135, "Value Loss": 13.070904731750488, "_runtime": 5572.793595314026, "_timestamp": 1585575488.6382287, "_step": 114}
{"Episode reward": -97.28378758969171, "Episode length": 999, "Policy Loss": 0.792863130569458, "Value Loss": 0.07033606618642807, "_runtime": 5574.374284029007, "_timestamp": 1585575490.2189174, "_step": 115}
{"Episode reward": -97.17167280120773, "Episode length": 999, "Policy Loss": 0.7659688591957092, "Value Loss": 0.08438900858163834, "_runtime": 5575.946925163269, "_timestamp": 1585575491.7915585, "_step": 116}
{"Episode reward": -96.8493034184382, "Episode length": 999, "Policy Loss": 0.7862289547920227, "Value Loss": 0.11364210397005081, "_runtime": 5577.1137709617615, "_timestamp": 1585575492.9584043, "_step": 117}
{"Episode reward": 27.40226112124401, "Episode length": 743, "Policy Loss": 1.217469334602356, "Value Loss": 12.929481506347656, "_runtime": 5577.796820163727, "_timestamp": 1585575493.6414535, "_step": 118}
{"Episode reward": 59.70559131344951, "Episode length": 416, "Policy Loss": 1.6639771461486816, "Value Loss": 22.905296325683594, "_runtime": 5579.193707942963, "_timestamp": 1585575495.0383413, "_step": 119}
{"Episode reward": 13.80204904155039, "Episode length": 894, "Policy Loss": 1.4976941347122192, "Value Loss": 10.713764190673828, "_runtime": 5580.740888595581, "_timestamp": 1585575496.585522, "_step": 120}
{"Episode reward": -97.19242275641267, "Episode length": 999, "Policy Loss": 0.6643705368041992, "Value Loss": 0.03991593047976494, "_runtime": 5581.488440036774, "_timestamp": 1585575497.3330734, "_step": 121}
{"Episode reward": 53.31938077844281, "Episode length": 483, "Policy Loss": 1.5962185859680176, "Value Loss": 20.292875289916992, "_runtime": 5583.031198978424, "_timestamp": 1585575498.8758323, "_step": 122}
{"Episode reward": -97.02741014702544, "Episode length": 999, "Policy Loss": 0.6460328698158264, "Value Loss": 0.15584082901477814, "_runtime": 5583.645127534866, "_timestamp": 1585575499.4897609, "_step": 123}
{"Episode reward": 63.48442438755091, "Episode length": 373, "Policy Loss": 1.5168317556381226, "Value Loss": 25.498708724975586, "_runtime": 5585.160307168961, "_timestamp": 1585575501.0049405, "_step": 124}
{"Episode reward": -96.88214669018436, "Episode length": 999, "Policy Loss": 0.6492015719413757, "Value Loss": 0.07301720976829529, "_runtime": 5586.726619243622, "_timestamp": 1585575502.5712526, "_step": 125}
{"Episode reward": -97.25736110681576, "Episode length": 999, "Policy Loss": 0.6751765012741089, "Value Loss": 0.03563407436013222, "_runtime": 5588.233438968658, "_timestamp": 1585575504.0780723, "_step": 126}
{"Episode reward": -96.16213629509504, "Episode length": 999, "Policy Loss": 0.6940211057662964, "Value Loss": 0.06887134909629822, "_runtime": 5589.0929963588715, "_timestamp": 1585575504.9376297, "_step": 127}
{"Episode reward": 47.98957564373714, "Episode length": 534, "Policy Loss": 1.4485583305358887, "Value Loss": 19.59412384033203, "_runtime": 5590.658941030502, "_timestamp": 1585575506.5035744, "_step": 128}
{"Episode reward": -96.5483839352525, "Episode length": 999, "Policy Loss": 0.6036417484283447, "Value Loss": 0.04309093952178955, "_runtime": 5592.2219524383545, "_timestamp": 1585575508.0665858, "_step": 129}
{"Episode reward": -96.75914890590131, "Episode length": 999, "Policy Loss": 0.5150577425956726, "Value Loss": 0.14608779549598694, "_runtime": 5593.185460805893, "_timestamp": 1585575509.0300941, "_step": 130}
{"Episode reward": 39.81941349211677, "Episode length": 620, "Policy Loss": 0.9397238492965698, "Value Loss": 16.041248321533203, "_runtime": 5594.409011602402, "_timestamp": 1585575510.253645, "_step": 131}
{"Episode reward": 24.712956642995394, "Episode length": 773, "Policy Loss": 1.1431846618652344, "Value Loss": 12.694645881652832, "_runtime": 5595.971775770187, "_timestamp": 1585575511.816409, "_step": 132}
{"Episode reward": -96.66811604261223, "Episode length": 999, "Policy Loss": 0.41054436564445496, "Value Loss": 0.4456368684768677, "_runtime": 5597.089627504349, "_timestamp": 1585575512.9342608, "_step": 133}
{"Episode reward": 30.155681777842517, "Episode length": 722, "Policy Loss": 0.9320182204246521, "Value Loss": 13.751788139343262, "_runtime": 5598.6372718811035, "_timestamp": 1585575514.4819052, "_step": 134}
{"Episode reward": -97.16942262167085, "Episode length": 999, "Policy Loss": 0.5272038578987122, "Value Loss": 0.04381479695439339, "_runtime": 5600.246390104294, "_timestamp": 1585575516.0910234, "_step": 135}
{"Episode reward": -97.73634184229142, "Episode length": 999, "Policy Loss": 0.5741996169090271, "Value Loss": 0.0431988351047039, "_runtime": 5601.794243097305, "_timestamp": 1585575517.6388764, "_step": 136}
{"Episode reward": -97.0940470886452, "Episode length": 999, "Policy Loss": 0.6056703329086304, "Value Loss": 0.046214036643505096, "_runtime": 5603.035681962967, "_timestamp": 1585575518.8803153, "_step": 137}
{"Episode reward": 23.352596056603815, "Episode length": 792, "Policy Loss": 1.0734646320343018, "Value Loss": 12.164032936096191, "_runtime": 5604.4422199726105, "_timestamp": 1585575520.2868533, "_step": 138}
{"Episode reward": 13.730346804343341, "Episode length": 890, "Policy Loss": 1.0333073139190674, "Value Loss": 10.627890586853027, "_runtime": 5605.999839544296, "_timestamp": 1585575521.844473, "_step": 139}
{"Episode reward": -96.32859020730967, "Episode length": 999, "Policy Loss": 0.7004694938659668, "Value Loss": 0.6027587652206421, "_runtime": 5607.562393188477, "_timestamp": 1585575523.4070265, "_step": 140}
{"Episode reward": -96.92700330812667, "Episode length": 999, "Policy Loss": 0.6299213171005249, "Value Loss": 0.13577575981616974, "_runtime": 5608.708738088608, "_timestamp": 1585575524.5533714, "_step": 141}
{"Episode reward": 28.935493730520335, "Episode length": 729, "Policy Loss": 1.085615634918213, "Value Loss": 13.562092781066895, "_runtime": 5609.22155213356, "_timestamp": 1585575525.0661855, "_step": 142}
{"Episode reward": 70.83373416351228, "Episode length": 299, "Policy Loss": 1.7350010871887207, "Value Loss": 31.89317512512207, "_runtime": 5610.132734775543, "_timestamp": 1585575525.977368, "_step": 143}
{"Episode reward": 44.37982823572874, "Episode length": 575, "Policy Loss": 1.0003628730773926, "Value Loss": 16.873971939086914, "_runtime": 5611.681510925293, "_timestamp": 1585575527.5261443, "_step": 144}
{"Episode reward": -97.79219120428363, "Episode length": 999, "Policy Loss": 0.3477797210216522, "Value Loss": 0.053683072328567505, "_runtime": 5613.193035840988, "_timestamp": 1585575529.0376692, "_step": 145}
{"Episode reward": -96.83382959450358, "Episode length": 999, "Policy Loss": 0.29160869121551514, "Value Loss": 0.15160970389842987, "_runtime": 5613.946582555771, "_timestamp": 1585575529.791216, "_step": 146}
{"Episode reward": 53.91941829095691, "Episode length": 475, "Policy Loss": 1.0974692106246948, "Value Loss": 20.46075439453125, "_runtime": 5615.522354841232, "_timestamp": 1585575531.3669882, "_step": 147}
{"Episode reward": -96.84452254770615, "Episode length": 999, "Policy Loss": 0.26224052906036377, "Value Loss": 0.1764339804649353, "_runtime": 5616.960744142532, "_timestamp": 1585575532.8053775, "_step": 148}
{"Episode reward": 9.708514917911671, "Episode length": 930, "Policy Loss": 0.7086482644081116, "Value Loss": 10.647173881530762, "_runtime": 5618.485551357269, "_timestamp": 1585575534.3301847, "_step": 149}
{"Episode reward": -97.40922619961499, "Episode length": 999, "Policy Loss": 0.36059412360191345, "Value Loss": 0.03533698245882988, "_runtime": 5619.105015039444, "_timestamp": 1585575534.9496484, "_step": 150}
{"Episode reward": 62.792694777288126, "Episode length": 381, "Policy Loss": 1.501582145690918, "Value Loss": 25.432126998901367, "_runtime": 5620.17568230629, "_timestamp": 1585575536.0203156, "_step": 151}
{"Episode reward": 34.36010718236864, "Episode length": 684, "Policy Loss": 0.9759433269500732, "Value Loss": 14.375405311584473, "_runtime": 5621.747839689255, "_timestamp": 1585575537.592473, "_step": 152}
{"Episode reward": -97.02220584343044, "Episode length": 999, "Policy Loss": 0.4141691327095032, "Value Loss": 0.14171269536018372, "_runtime": 5623.3029243946075, "_timestamp": 1585575539.1475577, "_step": 153}
{"Episode reward": -97.1142046921733, "Episode length": 999, "Policy Loss": 0.34276413917541504, "Value Loss": 0.05875666067004204, "_runtime": 5624.851374864578, "_timestamp": 1585575540.6960082, "_step": 154}
{"Episode reward": -96.80615691710564, "Episode length": 999, "Policy Loss": 0.28943780064582825, "Value Loss": 0.09180014580488205, "_runtime": 5626.43230009079, "_timestamp": 1585575542.2769334, "_step": 155}
{"Episode reward": -96.87195641692642, "Episode length": 999, "Policy Loss": 0.2609654664993286, "Value Loss": 0.03642839938402176, "_runtime": 5627.990564584732, "_timestamp": 1585575543.835198, "_step": 156}
{"Episode reward": -97.52585591083643, "Episode length": 999, "Policy Loss": 0.21438278257846832, "Value Loss": 0.06078505143523216, "_runtime": 5629.5090873241425, "_timestamp": 1585575545.3537207, "_step": 157}
{"Episode reward": 6.8353782206962705, "Episode length": 964, "Policy Loss": 0.5258740782737732, "Value Loss": 10.014131546020508, "_runtime": 5631.093303203583, "_timestamp": 1585575546.9379365, "_step": 158}
{"Episode reward": -96.78831182246715, "Episode length": 999, "Policy Loss": 0.20518885552883148, "Value Loss": 0.03527051955461502, "_runtime": 5632.668890953064, "_timestamp": 1585575548.5135243, "_step": 159}
{"Episode reward": -96.96857461633098, "Episode length": 999, "Policy Loss": 0.21609166264533997, "Value Loss": 0.11495983600616455, "_runtime": 5634.251488685608, "_timestamp": 1585575550.096122, "_step": 160}
{"Episode reward": -97.12337539398831, "Episode length": 999, "Policy Loss": 0.21977010369300842, "Value Loss": 0.047134239226579666, "_runtime": 5635.355878353119, "_timestamp": 1585575551.2005117, "_step": 161}
{"Episode reward": 33.402447701799716, "Episode length": 690, "Policy Loss": 0.7183026075363159, "Value Loss": 13.544422149658203, "_runtime": 5636.4778690338135, "_timestamp": 1585575552.3225024, "_step": 162}
{"Episode reward": 31.624109648909084, "Episode length": 709, "Policy Loss": 0.7102599740028381, "Value Loss": 13.262490272521973, "_runtime": 5638.059531211853, "_timestamp": 1585575553.9041646, "_step": 163}
{"Episode reward": -97.35259294185451, "Episode length": 999, "Policy Loss": 0.3147244155406952, "Value Loss": 0.19220009446144104, "_runtime": 5639.214271306992, "_timestamp": 1585575555.0589046, "_step": 164}
{"Episode reward": 28.749386013739368, "Episode length": 732, "Policy Loss": 0.8062994480133057, "Value Loss": 13.208881378173828, "_runtime": 5640.0548985004425, "_timestamp": 1585575555.8995318, "_step": 165}
{"Episode reward": 48.80222210190995, "Episode length": 533, "Policy Loss": 1.138657569885254, "Value Loss": 17.400041580200195, "_runtime": 5641.624410867691, "_timestamp": 1585575557.4690442, "_step": 166}
{"Episode reward": -96.67697350027844, "Episode length": 999, "Policy Loss": 0.2663164734840393, "Value Loss": 0.10187047719955444, "_runtime": 5643.179888725281, "_timestamp": 1585575559.024522, "_step": 167}
{"Episode reward": -96.07122788881249, "Episode length": 999, "Policy Loss": 0.24037770926952362, "Value Loss": 0.00824745837599039, "_runtime": 5644.706965208054, "_timestamp": 1585575560.5515985, "_step": 168}
{"Episode reward": -96.60585579847125, "Episode length": 999, "Policy Loss": 0.22174035012722015, "Value Loss": 0.021114060655236244, "_runtime": 5646.289129257202, "_timestamp": 1585575562.1337626, "_step": 169}
{"Episode reward": -96.80475041590348, "Episode length": 999, "Policy Loss": 0.19901490211486816, "Value Loss": 0.040505360811948776, "_runtime": 5647.044765949249, "_timestamp": 1585575562.8893993, "_step": 170}
{"Episode reward": 57.87945978817848, "Episode length": 436, "Policy Loss": 0.926578164100647, "Value Loss": 21.387691497802734, "_runtime": 5648.6180164813995, "_timestamp": 1585575564.4626498, "_step": 171}
{"Episode reward": -96.39936337021568, "Episode length": 999, "Policy Loss": 0.1868133246898651, "Value Loss": 0.030390623956918716, "_runtime": 5650.1854596138, "_timestamp": 1585575566.030093, "_step": 172}
{"Episode reward": -97.03970925931064, "Episode length": 999, "Policy Loss": 0.17620496451854706, "Value Loss": 0.017084641382098198, "_runtime": 5651.367911338806, "_timestamp": 1585575567.2125447, "_step": 173}
{"Episode reward": 25.23095107163411, "Episode length": 776, "Policy Loss": 0.5300348997116089, "Value Loss": 12.180785179138184, "_runtime": 5652.400603055954, "_timestamp": 1585575568.2452364, "_step": 174}
{"Episode reward": 37.52197090775405, "Episode length": 645, "Policy Loss": 0.7117233276367188, "Value Loss": 14.736668586730957, "_runtime": 5653.969438314438, "_timestamp": 1585575569.8140717, "_step": 175}
{"Episode reward": -96.02307550274288, "Episode length": 999, "Policy Loss": 0.18335795402526855, "Value Loss": 0.01097940094769001, "_runtime": 5655.512518405914, "_timestamp": 1585575571.3571517, "_step": 176}
{"Episode reward": -96.63004672489575, "Episode length": 999, "Policy Loss": 0.18109606206417084, "Value Loss": 0.03969269245862961, "_runtime": 5656.870624303818, "_timestamp": 1585575572.7152576, "_step": 177}
{"Episode reward": 14.429943143713771, "Episode length": 883, "Policy Loss": 0.563781201839447, "Value Loss": 11.013569831848145, "_runtime": 5658.447145700455, "_timestamp": 1585575574.291779, "_step": 178}
{"Episode reward": -96.30963751049381, "Episode length": 999, "Policy Loss": 0.1342582255601883, "Value Loss": 0.024280229583382607, "_runtime": 5659.006197452545, "_timestamp": 1585575574.8508308, "_step": 179}
{"Episode reward": 67.75967871595157, "Episode length": 334, "Policy Loss": 1.1116220951080322, "Value Loss": 28.5727596282959, "_runtime": 5660.563795566559, "_timestamp": 1585575576.408429, "_step": 180}
{"Episode reward": -96.36228180836174, "Episode length": 999, "Policy Loss": 0.07865563035011292, "Value Loss": 0.08638758212327957, "_runtime": 5660.911641120911, "_timestamp": 1585575576.7562745, "_step": 181}
{"Episode reward": 82.19056455667979, "Episode length": 182, "Policy Loss": 2.2884576320648193, "Value Loss": 54.21369552612305, "_runtime": 5662.439911842346, "_timestamp": 1585575578.2845452, "_step": 182}
{"Episode reward": -96.71288682360024, "Episode length": 999, "Policy Loss": 0.030464665964245796, "Value Loss": 0.024829085916280746, "_runtime": 5664.021977901459, "_timestamp": 1585575579.8666112, "_step": 183}
{"Episode reward": -96.30112429273838, "Episode length": 999, "Policy Loss": -0.06171444058418274, "Value Loss": 0.46595925092697144, "_runtime": 5665.515513420105, "_timestamp": 1585575581.3601468, "_step": 184}
{"Episode reward": -95.60467996169442, "Episode length": 999, "Policy Loss": -0.020557627081871033, "Value Loss": 0.10480476915836334, "_runtime": 5666.663991451263, "_timestamp": 1585575582.5086248, "_step": 185}
{"Episode reward": 29.470087861439424, "Episode length": 729, "Policy Loss": 0.40976855158805847, "Value Loss": 12.977972030639648, "_runtime": 5667.82319021225, "_timestamp": 1585575583.6678236, "_step": 186}
{"Episode reward": 29.935732938835557, "Episode length": 730, "Policy Loss": 0.5118973851203918, "Value Loss": 12.973340034484863, "_runtime": 5669.379509449005, "_timestamp": 1585575585.2241428, "_step": 187}
{"Episode reward": -96.25262521670498, "Episode length": 999, "Policy Loss": 0.0564141683280468, "Value Loss": 0.037307195365428925, "_runtime": 5670.435114860535, "_timestamp": 1585575586.2797482, "_step": 188}
{"Episode reward": 36.891618998230825, "Episode length": 650, "Policy Loss": 1.1970399618148804, "Value Loss": 14.531262397766113, "_runtime": 5671.988606214523, "_timestamp": 1585575587.8332396, "_step": 189}
{"Episode reward": -96.17454084432214, "Episode length": 999, "Policy Loss": 0.177701935172081, "Value Loss": 0.2042449414730072, "_runtime": 5673.558783531189, "_timestamp": 1585575589.4034169, "_step": 190}
{"Episode reward": -95.73375843567459, "Episode length": 999, "Policy Loss": 0.1156282126903534, "Value Loss": 0.05819094553589821, "_runtime": 5674.586961746216, "_timestamp": 1585575590.431595, "_step": 191}
{"Episode reward": 36.39375683292966, "Episode length": 657, "Policy Loss": 0.754690408706665, "Value Loss": 14.96849250793457, "_runtime": 5675.54364490509, "_timestamp": 1585575591.3882782, "_step": 192}
{"Episode reward": 42.5013055016013, "Episode length": 597, "Policy Loss": 0.6536698341369629, "Value Loss": 16.412879943847656, "_runtime": 5677.104881763458, "_timestamp": 1585575592.949515, "_step": 193}
{"Episode reward": -96.11175913920025, "Episode length": 999, "Policy Loss": -0.06783372163772583, "Value Loss": 0.050691988319158554, "_runtime": 5678.650902748108, "_timestamp": 1585575594.495536, "_step": 194}
{"Episode reward": -95.84153745568825, "Episode length": 999, "Policy Loss": -0.13373325765132904, "Value Loss": 0.13250617682933807, "_runtime": 5680.189705371857, "_timestamp": 1585575596.0343387, "_step": 195}
{"Episode reward": -96.47668215216203, "Episode length": 999, "Policy Loss": -0.1738555133342743, "Value Loss": 0.09530358761548996, "_runtime": 5680.467542886734, "_timestamp": 1585575596.3121762, "_step": 196}
{"Episode reward": 86.18391287197902, "Episode length": 142, "Policy Loss": 2.000771999359131, "Value Loss": 69.48534393310547, "_runtime": 5682.0367522239685, "_timestamp": 1585575597.8813856, "_step": 197}
{"Episode reward": -95.66586391459882, "Episode length": 999, "Policy Loss": -0.13702796399593353, "Value Loss": 0.13682205975055695, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609, -0.9008998870849609]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0], "bins": [-3.3467886447906494, -3.2807276248931885, -3.2146666049957275, -3.1486055850982666, -3.0825443267822266, -3.0164833068847656, -2.9504222869873047, -2.8843612670898438, -2.818300247192383, -2.752239227294922, -2.686178207397461, -2.6201171875, -2.554056167602539, -2.487995147705078, -2.421933889389038, -2.355872869491577, -2.289811849594116, -2.2237508296966553, -2.1576898097991943, -2.0916285514831543, -2.0255675315856934, -1.959506630897522, -1.8934454917907715, -1.8273844718933105, -1.7613234519958496, -1.6952624320983887, -1.6292014122009277, -1.5631402730941772, -1.4970792531967163, -1.4310182332992554, -1.3649570941925049, -1.298896074295044, -1.232835054397583, -1.166774034500122, -1.1007130146026611, -1.0346519947052002, -0.9685909748077393, -0.9025297164916992, -0.8364686965942383, -0.7704076766967773, -0.7043466567993164, -0.6382856369018555, -0.5722246170043945, -0.5061635971069336, -0.44010233879089355, -0.3740413188934326, -0.3079802989959717, -0.24191927909851074, -0.1758582592010498, -0.10979723930358887, -0.04373621940612793, 0.022324800491333008, 0.08838582038879395, 0.15444707870483398, 0.22050809860229492, 0.28656911849975586, 0.3526301383972168, 0.41869115829467773, 0.48475217819213867, 0.5508131980895996, 0.6168744564056396, 0.6829354763031006, 0.7489964962005615, 0.8150575160980225, 0.8811185359954834]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6054717302322388, -0.5941391587257385, -0.5828066468238831, -0.5714740753173828, -0.5601415038108826, -0.5488089323043823, -0.5374764204025269, -0.5261438488960266, -0.5148112773895264, -0.5034787654876709, -0.49214619398117065, -0.4808136224746704, -0.46948108077049255, -0.4581485390663147, -0.44681596755981445, -0.4354834258556366, -0.42415088415145874, -0.4128183126449585, -0.40148574113845825, -0.3901532292366028, -0.37882065773010254, -0.3674880862236023, -0.35615554451942444, -0.3448230028152466, -0.33349043130874634, -0.3221578896045685, -0.31082531809806824, -0.2994927763938904, -0.2881602346897125, -0.2768276631832123, -0.2654951214790344, -0.2541625499725342, -0.24283000826835632, -0.23149746656417847, -0.22016489505767822, -0.20883235335350037, -0.19749978184700012, -0.18616724014282227, -0.1748346984386444, -0.16350212693214417, -0.1521695852279663, -0.14083701372146606, -0.1295044720172882, -0.11817193031311035, -0.10683935880661011, -0.09550678730010986, -0.0841742753982544, -0.07284170389175415, -0.061509132385253906, -0.05017662048339844, -0.03884404897689819, -0.02751147747039795, -0.016178905963897705, -0.004846394062042236, 0.006486177444458008, 0.017818748950958252, 0.02915126085281372, 0.040483832359313965, 0.05181640386581421, 0.06314891576766968, 0.07448148727416992, 0.08581405878067017, 0.09714663028717041, 0.10847914218902588, 0.11981171369552612]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 6.0, 3.0, 9.0, 9.0, 9.0, 13.0, 14.0, 30.0, 94.0, 172.0, 62.0, 18.0, 12.0, 10.0, 4.0, 3.0, 5.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.7557253241539001, -0.7364464998245239, -0.7171676754951477, -0.6978887915611267, -0.6786099672317505, -0.6593311429023743, -0.640052318572998, -0.6207734942436218, -0.6014946699142456, -0.5822157859802246, -0.5629369616508484, -0.5436581373214722, -0.524379312992096, -0.5051004886627197, -0.4858216345310211, -0.4665427803993225, -0.4472639560699463, -0.42798513174057007, -0.40870627760887146, -0.38942745327949524, -0.37014859914779663, -0.3508697748184204, -0.3315909504890442, -0.3123120963573456, -0.29303327202796936, -0.27375444769859314, -0.25447559356689453, -0.2351967692375183, -0.2159179449081421, -0.19663912057876587, -0.17736023664474487, -0.15808141231536865, -0.13880258798599243, -0.11952376365661621, -0.10024493932723999, -0.080966055393219, -0.06168723106384277, -0.04240840673446655, -0.023129582405090332, -0.0038507580757141113, 0.015428125858306885, 0.034706950187683105, 0.053985774517059326, 0.07326459884643555, 0.09254342317581177, 0.11182224750518799, 0.13110113143920898, 0.1503799557685852, 0.16965878009796143, 0.18893760442733765, 0.20821642875671387, 0.22749531269073486, 0.24677413702011108, 0.26605290174484253, 0.2853317856788635, 0.3046106696128845, 0.32388943433761597, 0.34316831827163696, 0.3624470829963684, 0.3817259669303894, 0.4010048508644104, 0.42028361558914185, 0.43956249952316284, 0.4588412642478943, 0.4781201481819153]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1770225763320923, -1.1412960290908813, -1.1055693626403809, -1.06984281539917, -1.0341161489486694, -0.9983896017074585, -0.9626629948616028, -0.9269363880157471, -0.8912097811698914, -0.8554831743240356, -0.8197565674781799, -0.7840299606323242, -0.7483034133911133, -0.7125767469406128, -0.6768501996994019, -0.6411235928535461, -0.6053969860076904, -0.5696703791618347, -0.533943772315979, -0.4982171654701233, -0.4624905586242676, -0.42676401138305664, -0.3910374045372009, -0.3553107976913452, -0.3195841908454895, -0.2838575839996338, -0.24813097715377808, -0.21240437030792236, -0.17667782306671143, -0.14095115661621094, -0.105224609375, -0.06949794292449951, -0.033771395683288574, 0.0019551515579223633, 0.03768181800842285, 0.07340836524963379, 0.10913503170013428, 0.14486157894134521, 0.1805882453918457, 0.21631479263305664, 0.25204145908355713, 0.28776800632476807, 0.323494553565979, 0.3592212200164795, 0.39494776725769043, 0.4306744337081909, 0.46640098094940186, 0.5021276473999023, 0.5378541946411133, 0.5735807418823242, 0.6093074083328247, 0.6450339555740356, 0.6807606220245361, 0.7164871692657471, 0.7522138357162476, 0.7879403829574585, 0.8236669301986694, 0.8593934774398804, 0.8951202630996704, 0.9308468103408813, 0.9665733575820923, 1.0022999048233032, 1.0380266904830933, 1.0737532377243042, 1.1094797849655151]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 2.0, 1.0, 4.0, 2.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.880208969116211, -1.8322285413742065, -1.7842481136322021, -1.7362676858901978, -1.6882872581481934, -1.640306830406189, -1.5923264026641846, -1.5443460941314697, -1.4963655471801758, -1.448385238647461, -1.400404691696167, -1.3524243831634521, -1.3044439554214478, -1.2564635276794434, -1.208483099937439, -1.1605026721954346, -1.1125222444534302, -1.0645418167114258, -1.0165613889694214, -0.968580961227417, -0.9206005334854126, -0.8726201057434082, -0.8246396780014038, -0.7766592502593994, -0.7286789417266846, -0.6806985139846802, -0.6327180862426758, -0.5847376585006714, -0.536757230758667, -0.4887768030166626, -0.4407963752746582, -0.3928159475326538, -0.3448355197906494, -0.296855092048645, -0.24887466430664062, -0.20089423656463623, -0.15291380882263184, -0.10493338108062744, -0.05695295333862305, -0.008972525596618652, 0.03900790214538574, 0.08698821067810059, 0.13496875762939453, 0.18294906616210938, 0.23092961311340332, 0.27890992164611816, 0.3268904685974121, 0.37487077713012695, 0.4228510856628418, 0.47083163261413574, 0.5188119411468506, 0.5667924880981445, 0.6147727966308594, 0.6627533435821533, 0.7107336521148682, 0.7587141990661621, 0.806694507598877, 0.8546750545501709, 0.9026553630828857, 0.9506359100341797, 0.9986162185668945, 1.0465967655181885, 1.0945770740509033, 1.1425576210021973, 1.190537929534912]}, "_runtime": 5683.619735479355, "_timestamp": 1585575599.4643688, "_step": 198}
{"Episode reward": -96.05291189307457, "Episode length": 999, "Policy Loss": 0.02726236917078495, "Value Loss": 0.05228248983621597, "_runtime": 5684.468282461166, "_timestamp": 1585575600.3129158, "_step": 199}
{"Episode reward": 44.96688091974672, "Episode length": 568, "Policy Loss": 0.9593933820724487, "Value Loss": 16.824132919311523, "_runtime": 5686.039212942123, "_timestamp": 1585575601.8838463, "_step": 200}
{"Episode reward": -95.62241553591562, "Episode length": 999, "Policy Loss": 0.1775628626346588, "Value Loss": 0.12420514225959778, "_runtime": 5687.343529701233, "_timestamp": 1585575603.188163, "_step": 201}
{"Episode reward": 21.283009188475802, "Episode length": 822, "Policy Loss": 0.8358563184738159, "Value Loss": 12.24820613861084, "_runtime": 5688.192431211472, "_timestamp": 1585575604.0370646, "_step": 202}
{"Episode reward": 46.78303749891607, "Episode length": 552, "Policy Loss": 0.9145196080207825, "Value Loss": 17.733814239501953, "_runtime": 5689.135236263275, "_timestamp": 1585575604.9798696, "_step": 203}
{"Episode reward": 42.37322121927537, "Episode length": 591, "Policy Loss": 0.8033754825592041, "Value Loss": 16.038240432739258, "_runtime": 5690.189295530319, "_timestamp": 1585575606.0339289, "_step": 204}
{"Episode reward": 35.54221434882638, "Episode length": 670, "Policy Loss": 0.5907863974571228, "Value Loss": 14.664737701416016, "_runtime": 5691.671847105026, "_timestamp": 1585575607.5164804, "_step": 205}
{"Episode reward": 6.504731512255532, "Episode length": 972, "Policy Loss": 0.2325427532196045, "Value Loss": 9.794172286987305, "_runtime": 5692.274751663208, "_timestamp": 1585575608.119385, "_step": 206}
{"Episode reward": 63.10457000549585, "Episode length": 385, "Policy Loss": 0.5770503282546997, "Value Loss": 24.85358428955078, "_runtime": 5693.477152585983, "_timestamp": 1585575609.321786, "_step": 207}
{"Episode reward": 24.693529840501583, "Episode length": 776, "Policy Loss": 0.3302372097969055, "Value Loss": 12.455208778381348, "_runtime": 5695.070525407791, "_timestamp": 1585575610.9151587, "_step": 208}
{"Episode reward": -95.83999430474515, "Episode length": 999, "Policy Loss": -0.2309296578168869, "Value Loss": 0.2596084177494049, "_runtime": 5696.5833349227905, "_timestamp": 1585575612.4279683, "_step": 209}
{"Episode reward": -96.55416939674512, "Episode length": 999, "Policy Loss": -0.2325531542301178, "Value Loss": 0.3011544942855835, "_runtime": 5698.143239021301, "_timestamp": 1585575613.9878724, "_step": 210}
{"Episode reward": -96.36404370969909, "Episode length": 999, "Policy Loss": -0.19479310512542725, "Value Loss": 0.0922311395406723, "_runtime": 5699.714090585709, "_timestamp": 1585575615.558724, "_step": 211}
{"Episode reward": -97.08402735359981, "Episode length": 999, "Policy Loss": -0.13169723749160767, "Value Loss": 0.025653814896941185, "_runtime": 5701.267936468124, "_timestamp": 1585575617.1125698, "_step": 212}
{"Episode reward": -96.97077750536481, "Episode length": 999, "Policy Loss": -0.08620988577604294, "Value Loss": 0.031345807015895844, "_runtime": 5702.857285261154, "_timestamp": 1585575618.7019186, "_step": 213}
{"Episode reward": -97.10197473153022, "Episode length": 999, "Policy Loss": -0.03843914344906807, "Value Loss": 0.008813580498099327, "_runtime": 5704.193613767624, "_timestamp": 1585575620.038247, "_step": 214}
{"Episode reward": 17.92195162028908, "Episode length": 851, "Policy Loss": 0.6722822785377502, "Value Loss": 11.354351043701172, "_runtime": 5705.520595550537, "_timestamp": 1585575621.365229, "_step": 215}
{"Episode reward": 17.565860337237183, "Episode length": 846, "Policy Loss": 0.4227277636528015, "Value Loss": 10.93636417388916, "_runtime": 5706.4651799201965, "_timestamp": 1585575622.3098133, "_step": 216}
{"Episode reward": 42.730533544884835, "Episode length": 588, "Policy Loss": 0.5776610374450684, "Value Loss": 17.287874221801758, "_runtime": 5708.021569013596, "_timestamp": 1585575623.8662024, "_step": 217}
{"Episode reward": -96.81413766241613, "Episode length": 999, "Policy Loss": -0.07532957941293716, "Value Loss": 0.1158006340265274, "_runtime": 5708.543839931488, "_timestamp": 1585575624.3884733, "_step": 218}
{"Episode reward": 68.8743886750309, "Episode length": 318, "Policy Loss": 0.9103372693061829, "Value Loss": 30.00617790222168, "_runtime": 5709.5231194496155, "_timestamp": 1585575625.3677528, "_step": 219}
{"Episode reward": 38.65927238707296, "Episode length": 631, "Policy Loss": 0.23491352796554565, "Value Loss": 15.139493942260742, "_runtime": 5711.088342189789, "_timestamp": 1585575626.9329755, "_step": 220}
{"Episode reward": -97.07769186306915, "Episode length": 999, "Policy Loss": -0.2795645296573639, "Value Loss": 0.35085320472717285, "_runtime": 5712.602690219879, "_timestamp": 1585575628.4473236, "_step": 221}
{"Episode reward": -96.51937963929682, "Episode length": 999, "Policy Loss": -0.24077747762203217, "Value Loss": 0.08545533567667007, "_runtime": 5713.638900518417, "_timestamp": 1585575629.4835339, "_step": 222}
{"Episode reward": 35.86765588336776, "Episode length": 662, "Policy Loss": 0.29141494631767273, "Value Loss": 14.409411430358887, "_runtime": 5714.399260044098, "_timestamp": 1585575630.2438934, "_step": 223}
{"Episode reward": 54.06086849952866, "Episode length": 475, "Policy Loss": 0.5703762173652649, "Value Loss": 19.575450897216797, "_runtime": 5715.093397855759, "_timestamp": 1585575630.9380312, "_step": 224}
{"Episode reward": 57.93848784035385, "Episode length": 436, "Policy Loss": 0.7257577180862427, "Value Loss": 21.364967346191406, "_runtime": 5716.648521184921, "_timestamp": 1585575632.4931545, "_step": 225}
{"Episode reward": -97.70417087134366, "Episode length": 999, "Policy Loss": -0.05129909887909889, "Value Loss": 0.00844495464116335, "_runtime": 5718.1739366054535, "_timestamp": 1585575634.01857, "_step": 226}
{"Episode reward": -96.77649287578984, "Episode length": 999, "Policy Loss": -0.013369536027312279, "Value Loss": 0.06906667351722717, "_runtime": 5719.728367805481, "_timestamp": 1585575635.5730011, "_step": 227}
{"Episode reward": -95.87969666107539, "Episode length": 999, "Policy Loss": 0.09641954302787781, "Value Loss": 0.9282970428466797, "_runtime": 5720.688570737839, "_timestamp": 1585575636.533204, "_step": 228}
{"Episode reward": 42.07910655107409, "Episode length": 598, "Policy Loss": 0.6296753883361816, "Value Loss": 15.859601974487305, "_runtime": 5722.258852720261, "_timestamp": 1585575638.103486, "_step": 229}
{"Episode reward": -96.75667775539051, "Episode length": 999, "Policy Loss": -0.14386653900146484, "Value Loss": 0.00996173731982708, "_runtime": 5723.827564716339, "_timestamp": 1585575639.672198, "_step": 230}
{"Episode reward": -96.42854591871429, "Episode length": 999, "Policy Loss": -0.20319129526615143, "Value Loss": 0.17297933995723724, "_runtime": 5725.371886014938, "_timestamp": 1585575641.2165194, "_step": 231}
{"Episode reward": -97.02262846795598, "Episode length": 999, "Policy Loss": -0.3090686798095703, "Value Loss": 0.44417646527290344, "_runtime": 5726.207495689392, "_timestamp": 1585575642.052129, "_step": 232}
{"Episode reward": 49.41068053811886, "Episode length": 517, "Policy Loss": 0.37653830647468567, "Value Loss": 18.543960571289062, "_runtime": 5727.781629085541, "_timestamp": 1585575643.6262624, "_step": 233}
{"Episode reward": -97.36407331046985, "Episode length": 999, "Policy Loss": -0.199722558259964, "Value Loss": 0.0319836251437664, "_runtime": 5729.362688302994, "_timestamp": 1585575645.2073216, "_step": 234}
{"Episode reward": -97.47691023221451, "Episode length": 999, "Policy Loss": -0.165201798081398, "Value Loss": 0.043129246681928635, "_runtime": 5730.8942494392395, "_timestamp": 1585575646.7388828, "_step": 235}
{"Episode reward": -97.051981004927, "Episode length": 999, "Policy Loss": -0.128263920545578, "Value Loss": 0.025426164269447327, "_runtime": 5731.5732543468475, "_timestamp": 1585575647.4178877, "_step": 236}
{"Episode reward": 60.247838794666826, "Episode length": 410, "Policy Loss": 1.0748374462127686, "Value Loss": 23.74001693725586, "_runtime": 5733.083656311035, "_timestamp": 1585575648.9282897, "_step": 237}
{"Episode reward": 7.393164988076293, "Episode length": 958, "Policy Loss": 0.24548810720443726, "Value Loss": 9.896827697753906, "_runtime": 5734.657135009766, "_timestamp": 1585575650.5017684, "_step": 238}
{"Episode reward": -97.20594919173293, "Episode length": 999, "Policy Loss": -0.1884445995092392, "Value Loss": 0.009115000255405903, "_runtime": 5736.166493177414, "_timestamp": 1585575652.0111265, "_step": 239}
{"Episode reward": -95.90567276186613, "Episode length": 999, "Policy Loss": -0.2334827333688736, "Value Loss": 0.0627211332321167, "_runtime": 5737.746495723724, "_timestamp": 1585575653.591129, "_step": 240}
{"Episode reward": -96.5785690175894, "Episode length": 999, "Policy Loss": -0.27578669786453247, "Value Loss": 0.10401453822851181, "_runtime": 5738.93315577507, "_timestamp": 1585575654.777789, "_step": 241}
{"Episode reward": 26.81540594742252, "Episode length": 751, "Policy Loss": 0.15208792686462402, "Value Loss": 12.693154335021973, "_runtime": 5740.308557510376, "_timestamp": 1585575656.1531909, "_step": 242}
{"Episode reward": 14.303888626657354, "Episode length": 881, "Policy Loss": 0.1938338279724121, "Value Loss": 10.612225532531738, "_runtime": 5741.0517773628235, "_timestamp": 1585575656.8964107, "_step": 243}
{"Episode reward": 55.511077031436905, "Episode length": 453, "Policy Loss": 0.47578680515289307, "Value Loss": 20.21302604675293, "_runtime": 5742.6612050533295, "_timestamp": 1585575658.5058384, "_step": 244}
{"Episode reward": -96.91232150603619, "Episode length": 999, "Policy Loss": -0.13711026310920715, "Value Loss": 0.19457976520061493, "_runtime": 5744.158371925354, "_timestamp": 1585575660.0030053, "_step": 245}
{"Episode reward": 6.625975792574408, "Episode length": 960, "Policy Loss": 0.1979130357503891, "Value Loss": 9.894148826599121, "_runtime": 5745.212384223938, "_timestamp": 1585575661.0570176, "_step": 246}
{"Episode reward": 33.80610349701284, "Episode length": 683, "Policy Loss": 0.504464864730835, "Value Loss": 13.841790199279785, "_runtime": 5746.788993597031, "_timestamp": 1585575662.633627, "_step": 247}
{"Episode reward": -97.1082697132374, "Episode length": 999, "Policy Loss": -0.12364610284566879, "Value Loss": 0.3538396656513214, "_runtime": 5748.361403226852, "_timestamp": 1585575664.2060366, "_step": 248}
{"Episode reward": -96.72868621576133, "Episode length": 999, "Policy Loss": -0.1770431101322174, "Value Loss": 0.023607557639479637, "_runtime": 5749.693310499191, "_timestamp": 1585575665.5379438, "_step": 249}
{"Episode reward": 15.87638655502542, "Episode length": 865, "Policy Loss": 0.15169864892959595, "Value Loss": 10.77016830444336, "_runtime": 5750.985394239426, "_timestamp": 1585575666.8300276, "_step": 250}
{"Episode reward": 20.949255555072256, "Episode length": 816, "Policy Loss": 0.11215861886739731, "Value Loss": 11.784416198730469, "_runtime": 5752.551344394684, "_timestamp": 1585575668.3959777, "_step": 251}
{"Episode reward": -97.29478648558656, "Episode length": 999, "Policy Loss": -0.30697622895240784, "Value Loss": 0.14185793697834015, "_runtime": 5753.153414726257, "_timestamp": 1585575668.998048, "_step": 252}
{"Episode reward": 64.22905137164463, "Episode length": 366, "Policy Loss": 0.6194786429405212, "Value Loss": 26.02728843688965, "_runtime": 5754.718411684036, "_timestamp": 1585575670.563045, "_step": 253}
{"Episode reward": -96.4366985444054, "Episode length": 999, "Policy Loss": -0.2477874457836151, "Value Loss": 0.027456847950816154, "_runtime": 5756.29806137085, "_timestamp": 1585575672.1426947, "_step": 254}
{"Episode reward": -97.54187892798797, "Episode length": 999, "Policy Loss": -0.21708759665489197, "Value Loss": 0.016381878405809402, "_runtime": 5757.751739501953, "_timestamp": 1585575673.5963728, "_step": 255}
{"Episode reward": 7.4195012675216105, "Episode length": 957, "Policy Loss": 0.163350448012352, "Value Loss": 9.715909004211426, "_runtime": 5759.333944320679, "_timestamp": 1585575675.1785777, "_step": 256}
{"Episode reward": -96.14586406424651, "Episode length": 999, "Policy Loss": -0.16948780417442322, "Value Loss": 0.019748885184526443, "_runtime": 5760.559911251068, "_timestamp": 1585575676.4045446, "_step": 257}
{"Episode reward": 25.02002892818119, "Episode length": 773, "Policy Loss": 0.3268641531467438, "Value Loss": 12.342414855957031, "_runtime": 5762.121935129166, "_timestamp": 1585575677.9665685, "_step": 258}
{"Episode reward": -96.99630352929313, "Episode length": 999, "Policy Loss": -0.17603839933872223, "Value Loss": 0.27791962027549744, "_runtime": 5762.6952612400055, "_timestamp": 1585575678.5398946, "_step": 259}
{"Episode reward": 66.98873394376315, "Episode length": 338, "Policy Loss": 0.9125141501426697, "Value Loss": 27.3149471282959, "_runtime": 5764.24564909935, "_timestamp": 1585575680.0902824, "_step": 260}
{"Episode reward": -96.78547079382281, "Episode length": 999, "Policy Loss": -0.23809604346752167, "Value Loss": 0.05597821995615959, "_runtime": 5765.857112407684, "_timestamp": 1585575681.7017457, "_step": 261}
{"Episode reward": -95.54278523637505, "Episode length": 999, "Policy Loss": -0.25797051191329956, "Value Loss": 0.08215656876564026, "_runtime": 5767.336547374725, "_timestamp": 1585575683.1811807, "_step": 262}
{"Episode reward": 5.503944157087631, "Episode length": 976, "Policy Loss": 0.21902596950531006, "Value Loss": 9.384123802185059, "_runtime": 5767.73594212532, "_timestamp": 1585575683.5805755, "_step": 263}
{"Episode reward": 79.43924696891695, "Episode length": 215, "Policy Loss": 1.225490689277649, "Value Loss": 42.96551513671875, "_runtime": 5769.308339357376, "_timestamp": 1585575685.1529727, "_step": 264}
{"Episode reward": -96.11130615877089, "Episode length": 999, "Policy Loss": -0.13226306438446045, "Value Loss": 0.012026246637105942, "_runtime": 5770.876416921616, "_timestamp": 1585575686.7210503, "_step": 265}
{"Episode reward": -96.78361538192938, "Episode length": 999, "Policy Loss": -0.09612433612346649, "Value Loss": 0.03473665565252304, "_runtime": 5772.379045724869, "_timestamp": 1585575688.223679, "_step": 266}
{"Episode reward": -96.16784548339774, "Episode length": 999, "Policy Loss": -0.03986179828643799, "Value Loss": 0.09108991175889969, "_runtime": 5773.932349681854, "_timestamp": 1585575689.776983, "_step": 267}
{"Episode reward": 4.975168412838613, "Episode length": 978, "Policy Loss": 0.4185671806335449, "Value Loss": 10.19781494140625, "_runtime": 5775.315191745758, "_timestamp": 1585575691.159825, "_step": 268}
{"Episode reward": 14.754701742402403, "Episode length": 882, "Policy Loss": 0.3821679651737213, "Value Loss": 10.607474327087402, "_runtime": 5776.86443901062, "_timestamp": 1585575692.7090724, "_step": 269}
{"Episode reward": -96.4682118898321, "Episode length": 999, "Policy Loss": -0.19893726706504822, "Value Loss": 0.013826217502355576, "_runtime": 5778.46053481102, "_timestamp": 1585575694.3051682, "_step": 270}
{"Episode reward": -96.42656013034129, "Episode length": 999, "Policy Loss": -0.28116995096206665, "Value Loss": 0.0604383759200573, "_runtime": 5780.025506258011, "_timestamp": 1585575695.8701396, "_step": 271}
{"Episode reward": -96.6294515637116, "Episode length": 999, "Policy Loss": -0.3489021360874176, "Value Loss": 0.27250975370407104, "_runtime": 5780.525220632553, "_timestamp": 1585575696.369854, "_step": 272}
{"Episode reward": 72.30698428271849, "Episode length": 294, "Policy Loss": 0.8847768306732178, "Value Loss": 33.33962631225586, "_runtime": 5781.6359667778015, "_timestamp": 1585575697.4806, "_step": 273}
{"Episode reward": 31.784430675552372, "Episode length": 705, "Policy Loss": 0.15694783627986908, "Value Loss": 13.500140190124512, "_runtime": 5782.802734851837, "_timestamp": 1585575698.6473682, "_step": 274}
{"Episode reward": 28.390015688094067, "Episode length": 738, "Policy Loss": 0.34952422976493835, "Value Loss": 12.844526290893555, "_runtime": 5784.30966424942, "_timestamp": 1585575700.1542976, "_step": 275}
{"Episode reward": -96.90451080650878, "Episode length": 999, "Policy Loss": -0.05813591554760933, "Value Loss": 0.034809961915016174, "_runtime": 5785.865870952606, "_timestamp": 1585575701.7105043, "_step": 276}
{"Episode reward": -95.48080816818957, "Episode length": 999, "Policy Loss": 0.17690514028072357, "Value Loss": 1.6505417823791504, "_runtime": 5786.622052669525, "_timestamp": 1585575702.466686, "_step": 277}
{"Episode reward": 54.13745490745294, "Episode length": 475, "Policy Loss": 1.2896469831466675, "Value Loss": 21.226606369018555, "_runtime": 5788.184886217117, "_timestamp": 1585575704.0295196, "_step": 278}
{"Episode reward": -96.20936817662329, "Episode length": 999, "Policy Loss": -0.1578235626220703, "Value Loss": 0.1373734176158905, "_runtime": 5789.806035280228, "_timestamp": 1585575705.6506686, "_step": 279}
{"Episode reward": -96.90443632894858, "Episode length": 999, "Policy Loss": -0.3947804868221283, "Value Loss": 0.26506301760673523, "_runtime": 5791.289167642593, "_timestamp": 1585575707.133801, "_step": 280}
{"Episode reward": 5.717279013536853, "Episode length": 978, "Policy Loss": -0.27473050355911255, "Value Loss": 11.55184268951416, "_runtime": 5792.865565776825, "_timestamp": 1585575708.710199, "_step": 281}
{"Episode reward": -97.21331173752183, "Episode length": 999, "Policy Loss": -0.5028402209281921, "Value Loss": 0.6240366101264954, "_runtime": 5793.999048709869, "_timestamp": 1585575709.843682, "_step": 282}
{"Episode reward": 31.129830885193016, "Episode length": 710, "Policy Loss": 0.10741614550352097, "Value Loss": 14.207958221435547, "_runtime": 5795.289952278137, "_timestamp": 1585575711.1345856, "_step": 283}
{"Episode reward": 19.743929646905713, "Episode length": 829, "Policy Loss": 0.0874633938074112, "Value Loss": 11.362690925598145, "_runtime": 5796.854293584824, "_timestamp": 1585575712.698927, "_step": 284}
{"Episode reward": -96.99175689985323, "Episode length": 999, "Policy Loss": -0.15464627742767334, "Value Loss": 0.05325614660978317, "_runtime": 5798.411190032959, "_timestamp": 1585575714.2558234, "_step": 285}
{"Episode reward": -97.1797885401044, "Episode length": 999, "Policy Loss": -0.030293360352516174, "Value Loss": 0.23203663527965546, "_runtime": 5799.773474216461, "_timestamp": 1585575715.6181076, "_step": 286}
{"Episode reward": 16.088000232880077, "Episode length": 870, "Policy Loss": 0.43048912286758423, "Value Loss": 11.588334083557129, "_runtime": 5800.436400413513, "_timestamp": 1585575716.2810338, "_step": 287}
{"Episode reward": 60.25926517318802, "Episode length": 410, "Policy Loss": 0.8635794520378113, "Value Loss": 27.26984405517578, "_runtime": 5802.008809328079, "_timestamp": 1585575717.8534427, "_step": 288}
{"Episode reward": -97.41148932300308, "Episode length": 999, "Policy Loss": -0.26967620849609375, "Value Loss": 0.014954804442822933, "_runtime": 5803.583837509155, "_timestamp": 1585575719.4284708, "_step": 289}
{"Episode reward": -97.29638454399533, "Episode length": 999, "Policy Loss": -0.5179204940795898, "Value Loss": 0.33166396617889404, "_runtime": 5805.104158163071, "_timestamp": 1585575720.9487915, "_step": 290}
{"Episode reward": -96.49402568109439, "Episode length": 999, "Policy Loss": -0.7492852807044983, "Value Loss": 0.6759445071220398, "_runtime": 5806.47092461586, "_timestamp": 1585575722.315558, "_step": 291}
{"Episode reward": 15.57986494057846, "Episode length": 862, "Policy Loss": -0.38396596908569336, "Value Loss": 18.507490158081055, "_runtime": 5807.121512413025, "_timestamp": 1585575722.9661458, "_step": 292}
{"Episode reward": 61.75842285288789, "Episode length": 392, "Policy Loss": -0.026173869147896767, "Value Loss": 31.61916732788086, "_runtime": 5808.274813175201, "_timestamp": 1585575724.1194465, "_step": 293}
{"Episode reward": 27.912135344627472, "Episode length": 741, "Policy Loss": -0.033082012087106705, "Value Loss": 12.980655670166016, "_runtime": 5809.446741342545, "_timestamp": 1585575725.2913747, "_step": 294}
{"Episode reward": 27.37908205618892, "Episode length": 744, "Policy Loss": 0.4190806746482849, "Value Loss": 13.303173065185547, "_runtime": 5810.966008424759, "_timestamp": 1585575726.8106418, "_step": 295}
{"Episode reward": -98.06712744537343, "Episode length": 999, "Policy Loss": 0.21145489811897278, "Value Loss": 0.8946871757507324, "_runtime": 5811.829584121704, "_timestamp": 1585575727.6742175, "_step": 296}
{"Episode reward": 46.25987051657318, "Episode length": 545, "Policy Loss": 1.0820063352584839, "Value Loss": 23.03319549560547, "_runtime": 5813.429085016251, "_timestamp": 1585575729.2737184, "_step": 297}
{"Episode reward": -97.14045916982563, "Episode length": 999, "Policy Loss": 0.39480167627334595, "Value Loss": 0.7015330791473389, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885, -2.6707422733306885]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-16.306455612182617, -15.507291793823242, -14.708128929138184, -13.908966064453125, -13.10980224609375, -12.310638427734375, -11.511475563049316, -10.712312698364258, -9.913148880004883, -9.113985061645508, -8.31482219696045, -7.515659332275391, -6.716495513916016, -5.917331695556641, -5.118168830871582, -4.319005966186523, -3.5198421478271484, -2.7206783294677734, -1.9215154647827148, -1.1223526000976562, -0.32318878173828125, 0.47597503662109375, 1.275136947631836, 2.074300765991211, 2.873464584350586, 3.672628402709961, 4.471792221069336, 5.270954132080078, 6.070117950439453, 6.869281768798828, 7.66844367980957, 8.467607498168945, 9.26677131652832, 10.065935134887695, 10.86509895324707, 11.664260864257812, 12.463424682617188, 13.262588500976562, 14.061750411987305, 14.86091423034668, 15.660078048706055, 16.45924186706543, 17.258405685424805, 18.05756950378418, 18.85672950744629, 19.655893325805664, 20.45505714416504, 21.254220962524414, 22.05338478088379, 22.852548599243164, 23.65171241760254, 24.450876235961914, 25.25004005432129, 26.0492000579834, 26.848363876342773, 27.64752769470215, 28.446691513061523, 29.2458553314209, 30.045019149780273, 30.84418296813965, 31.643342971801758, 32.4425048828125, 33.241668701171875, 34.04083251953125, 34.839996337890625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1.8504704236984253, -1.8146321773529053, -1.7787939310073853, -1.7429555654525757, -1.7071173191070557, -1.6712790727615356, -1.6354408264160156, -1.599602460861206, -1.563764214515686, -1.527925968170166, -1.492087721824646, -1.456249475479126, -1.4204111099243164, -1.3845728635787964, -1.3487346172332764, -1.3128962516784668, -1.2770581245422363, -1.2412197589874268, -1.2053815126419067, -1.1695432662963867, -1.1337049007415771, -1.0978667736053467, -1.062028408050537, -1.026190161705017, -0.9903519153594971, -0.9545136094093323, -0.9186753630638123, -0.8828370571136475, -0.8469988107681274, -0.8111605644226074, -0.7753221988677979, -0.7394839525222778, -0.7036457061767578, -0.6678074598312378, -0.6319692134857178, -0.5961308479309082, -0.5602926015853882, -0.5244543552398682, -0.48861610889434814, -0.4527777433395386, -0.41693949699401855, -0.38110125064849854, -0.3452630043029785, -0.3094247579574585, -0.2735863924026489, -0.2377481460571289, -0.2019098997116089, -0.16607165336608887, -0.13023340702056885, -0.09439504146575928, -0.05855679512023926, -0.02271854877471924, 0.013119697570800781, 0.04895806312561035, 0.08479630947113037, 0.12063455581665039, 0.1564728021621704, 0.19231116771697998, 0.22814929485321045, 0.26398766040802, 0.2998260259628296, 0.33566415309906006, 0.37150251865386963, 0.4073406457901001, 0.44317901134490967]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 4.0, 4.0, 1.0, 0.0, 3.0, 5.0, 4.0, 10.0, 7.0, 15.0, 17.0, 23.0, 28.0, 189.0, 76.0, 38.0, 10.0, 10.0, 4.0, 10.0, 5.0, 0.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0], "bins": [-15.697859764099121, -15.301495552062988, -14.905131340026855, -14.508768081665039, -14.112403869628906, -13.716039657592773, -13.31967544555664, -12.923311233520508, -12.526947021484375, -12.130583763122559, -11.734219551086426, -11.337855339050293, -10.94149112701416, -10.545127868652344, -10.148763656616211, -9.752399444580078, -9.356035232543945, -8.959671020507812, -8.56330680847168, -8.166942596435547, -7.7705793380737305, -7.374215126037598, -6.977850914001465, -6.581486701965332, -6.185122489929199, -5.788759231567383, -5.39239501953125, -4.996030807495117, -4.599666595458984, -4.203302383422852, -3.806939125061035, -3.4105749130249023, -3.0142107009887695, -2.6178464889526367, -2.221482276916504, -1.8251190185546875, -1.4287548065185547, -1.0323905944824219, -0.6360263824462891, -0.23966217041015625, 0.15670108795166016, 0.553065299987793, 0.9494295120239258, 1.3457937240600586, 1.7421579360961914, 2.138522148132324, 2.534886360168457, 2.93125057220459, 3.3276147842407227, 3.7239770889282227, 4.1203413009643555, 4.516705513000488, 4.913069725036621, 5.309433937072754, 5.705798149108887, 6.1021623611450195, 6.498526573181152, 6.894890785217285, 7.291254997253418, 7.687617301940918, 8.08398151397705, 8.480345726013184, 8.876709938049316, 9.27307415008545, 9.669438362121582]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-12.054340362548828, -11.713293075561523, -11.372246742248535, -11.03119945526123, -10.690153121948242, -10.349105834960938, -10.008058547973633, -9.667011260986328, -9.32596492767334, -8.984918594360352, -8.643871307373047, -8.302824020385742, -7.961777210235596, -7.620730400085449, -7.2796831130981445, -6.938636302947998, -6.597589492797852, -6.256542682647705, -5.915495872497559, -5.574448585510254, -5.233401775360107, -4.892354965209961, -4.551307678222656, -4.21026086807251, -3.8692140579223633, -3.5281667709350586, -3.1871204376220703, -2.8460731506347656, -2.505025863647461, -2.1639795303344727, -1.822932243347168, -1.4818859100341797, -1.140838623046875, -0.7997913360595703, -0.45874500274658203, -0.11769771575927734, 0.22334861755371094, 0.5643959045410156, 0.9054431915283203, 1.2464895248413086, 1.5875368118286133, 1.928584098815918, 2.2696304321289062, 2.610677719116211, 2.9517250061035156, 3.292771339416504, 3.6338186264038086, 3.974864959716797, 4.315912246704102, 4.656959533691406, 4.998006820678711, 5.339052200317383, 5.6800994873046875, 6.021146774291992, 6.362194061279297, 6.703241348266602, 7.044288635253906, 7.385334014892578, 7.726381301879883, 8.067428588867188, 8.408475875854492, 8.749523162841797, 9.090568542480469, 9.431615829467773, 9.772663116455078]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 4.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0], "bins": [-21.421958923339844, -20.719907760620117, -20.01785659790039, -19.31580352783203, -18.613752365112305, -17.911701202392578, -17.20965003967285, -16.507598876953125, -15.805546760559082, -15.103494644165039, -14.401443481445312, -13.699392318725586, -12.99734115600586, -12.295289039611816, -11.59323787689209, -10.891185760498047, -10.18913459777832, -9.487083435058594, -8.78503131866455, -8.082980155944824, -7.380928039550781, -6.678876876831055, -5.976825714111328, -5.274774551391602, -4.572723388671875, -3.8706703186035156, -3.168619155883789, -2.4665679931640625, -1.764516830444336, -1.0624656677246094, -0.36041259765625, 0.34163856506347656, 1.0436897277832031, 1.7457408905029297, 2.4477920532226562, 3.1498451232910156, 3.851896286010742, 4.553947448730469, 5.255998611450195, 5.958049774169922, 6.660102844238281, 7.362154006958008, 8.064205169677734, 8.766256332397461, 9.468307495117188, 10.170358657836914, 10.87240982055664, 11.574462890625, 12.276512145996094, 12.978565216064453, 13.680618286132812, 14.382667541503906, 15.084720611572266, 15.78676986694336, 16.48882293701172, 17.190876007080078, 17.892925262451172, 18.59497833251953, 19.297027587890625, 19.999080657958984, 20.701133728027344, 21.403182983398438, 22.105236053466797, 22.80728530883789, 23.50933837890625]}, "_runtime": 5814.989448547363, "_timestamp": 1585575730.834082, "_step": 298}
{"Episode reward": -97.33759381435598, "Episode length": 999, "Policy Loss": 0.4669135510921478, "Value Loss": 9.012227058410645, "_runtime": 5816.520143032074, "_timestamp": 1585575732.3647764, "_step": 299}
{"Episode reward": -96.71706266466218, "Episode length": 999, "Policy Loss": 0.06734856963157654, "Value Loss": 0.676611602306366, "_runtime": 5817.320782661438, "_timestamp": 1585575733.165416, "_step": 300}
{"Episode reward": 51.708576919528376, "Episode length": 492, "Policy Loss": 0.5092180371284485, "Value Loss": 19.118755340576172, "_runtime": 5818.189380407333, "_timestamp": 1585575734.0340137, "_step": 301}
{"Episode reward": 47.451281343887324, "Episode length": 539, "Policy Loss": 0.16822795569896698, "Value Loss": 17.992734909057617, "_runtime": 5819.612989902496, "_timestamp": 1585575735.4576232, "_step": 302}
{"Episode reward": 12.085852421343759, "Episode length": 913, "Policy Loss": -0.1909014880657196, "Value Loss": 15.632333755493164, "_runtime": 5821.144432544708, "_timestamp": 1585575736.989066, "_step": 303}
{"Episode reward": -96.62972245235086, "Episode length": 999, "Policy Loss": -0.6361503601074219, "Value Loss": 0.8777642846107483, "_runtime": 5822.67800617218, "_timestamp": 1585575738.5226395, "_step": 304}
{"Episode reward": -97.76867143851732, "Episode length": 999, "Policy Loss": -0.5200105905532837, "Value Loss": 0.5382663607597351, "_runtime": 5824.242681503296, "_timestamp": 1585575740.0873148, "_step": 305}
{"Episode reward": -96.7683025316866, "Episode length": 999, "Policy Loss": -0.3676738142967224, "Value Loss": 0.1984337866306305, "_runtime": 5825.815673351288, "_timestamp": 1585575741.6603067, "_step": 306}
{"Episode reward": -97.36980933212519, "Episode length": 999, "Policy Loss": -0.1979742795228958, "Value Loss": 0.03860502317547798, "_runtime": 5827.3798859119415, "_timestamp": 1585575743.2245193, "_step": 307}
{"Episode reward": -98.0751649906604, "Episode length": 999, "Policy Loss": -0.06870917230844498, "Value Loss": 0.24739743769168854, "_runtime": 5828.439758300781, "_timestamp": 1585575744.2843916, "_step": 308}
{"Episode reward": 35.49402853753611, "Episode length": 660, "Policy Loss": 0.637496292591095, "Value Loss": 16.49177360534668, "_runtime": 5830.021193265915, "_timestamp": 1585575745.8658266, "_step": 309}
{"Episode reward": -97.51674994916222, "Episode length": 999, "Policy Loss": 0.0056765261106193066, "Value Loss": 0.12475411593914032, "_runtime": 5831.590119361877, "_timestamp": 1585575747.4347527, "_step": 310}
{"Episode reward": -97.54834365398489, "Episode length": 999, "Policy Loss": -0.03790104389190674, "Value Loss": 1.2787667512893677, "_runtime": 5832.639899492264, "_timestamp": 1585575748.4845328, "_step": 311}
{"Episode reward": 34.07426190882617, "Episode length": 674, "Policy Loss": 0.35795557498931885, "Value Loss": 15.07113265991211, "_runtime": 5833.637315273285, "_timestamp": 1585575749.4819486, "_step": 312}
{"Episode reward": 38.771292499705794, "Episode length": 626, "Policy Loss": 0.1582794487476349, "Value Loss": 15.215008735656738, "_runtime": 5835.214380025864, "_timestamp": 1585575751.0590134, "_step": 313}
{"Episode reward": -97.08916919687927, "Episode length": 999, "Policy Loss": -0.5717781186103821, "Value Loss": 0.5948492884635925, "_runtime": 5836.360973596573, "_timestamp": 1585575752.205607, "_step": 314}
{"Episode reward": 28.612641113995565, "Episode length": 735, "Policy Loss": -0.09786491841077805, "Value Loss": 17.1437931060791, "_runtime": 5837.923740148544, "_timestamp": 1585575753.7683735, "_step": 315}
{"Episode reward": -97.94282517100955, "Episode length": 999, "Policy Loss": -0.5218490362167358, "Value Loss": 0.1558714061975479, "_runtime": 5839.491068124771, "_timestamp": 1585575755.3357015, "_step": 316}
{"Episode reward": -97.49343809840897, "Episode length": 999, "Policy Loss": -0.38319647312164307, "Value Loss": 0.42545488476753235, "_runtime": 5840.382087469101, "_timestamp": 1585575756.2267208, "_step": 317}
{"Episode reward": 45.131283664572, "Episode length": 561, "Policy Loss": 0.3944455683231354, "Value Loss": 16.87143325805664, "_runtime": 5841.957907438278, "_timestamp": 1585575757.8025408, "_step": 318}
{"Episode reward": -98.41160521009265, "Episode length": 999, "Policy Loss": -0.07673334330320358, "Value Loss": 0.03441224992275238, "_runtime": 5843.520142555237, "_timestamp": 1585575759.364776, "_step": 319}
{"Episode reward": -97.55658201898726, "Episode length": 999, "Policy Loss": 0.04331694543361664, "Value Loss": 0.7566710710525513, "_runtime": 5844.989178657532, "_timestamp": 1585575760.833812, "_step": 320}
{"Episode reward": 6.504458340747561, "Episode length": 955, "Policy Loss": 0.5261512994766235, "Value Loss": 13.647087097167969, "_runtime": 5846.572199344635, "_timestamp": 1585575762.4168327, "_step": 321}
{"Episode reward": -97.231840282399, "Episode length": 999, "Policy Loss": -0.005553423892706633, "Value Loss": 0.3910352885723114, "_runtime": 5848.021899938583, "_timestamp": 1585575763.8665333, "_step": 322}
{"Episode reward": 11.298383094452248, "Episode length": 913, "Policy Loss": 0.27253061532974243, "Value Loss": 11.07802963256836, "_runtime": 5849.592460870743, "_timestamp": 1585575765.4370942, "_step": 323}
{"Episode reward": -97.74454600529077, "Episode length": 999, "Policy Loss": -0.3297059237957001, "Value Loss": 0.05611874908208847, "_runtime": 5851.168530225754, "_timestamp": 1585575767.0131636, "_step": 324}
{"Episode reward": -98.09896895797225, "Episode length": 999, "Policy Loss": -0.4687197804450989, "Value Loss": 0.28031018376350403, "_runtime": 5852.742720365524, "_timestamp": 1585575768.5873537, "_step": 325}
{"Episode reward": -98.08714798972679, "Episode length": 999, "Policy Loss": -0.6485726833343506, "Value Loss": 2.5788023471832275, "_runtime": 5854.318780422211, "_timestamp": 1585575770.1634138, "_step": 326}
{"Episode reward": -97.90204544463778, "Episode length": 999, "Policy Loss": -0.6157087683677673, "Value Loss": 0.6419485211372375, "_runtime": 5855.887804508209, "_timestamp": 1585575771.7324378, "_step": 327}
{"Episode reward": -97.57527330191536, "Episode length": 999, "Policy Loss": -0.6258231997489929, "Value Loss": 0.4368683695793152, "_runtime": 5857.454707622528, "_timestamp": 1585575773.299341, "_step": 328}
{"Episode reward": -97.87256536590716, "Episode length": 999, "Policy Loss": -0.5399287939071655, "Value Loss": 0.5182969570159912, "_runtime": 5859.031917333603, "_timestamp": 1585575774.8765507, "_step": 329}
{"Episode reward": -97.57426362904755, "Episode length": 999, "Policy Loss": -0.510308027267456, "Value Loss": 0.44277480244636536, "_runtime": 5860.237313270569, "_timestamp": 1585575776.0819466, "_step": 330}
{"Episode reward": 28.22994656805966, "Episode length": 737, "Policy Loss": 0.13254325091838837, "Value Loss": 13.0722017288208, "_runtime": 5861.796627521515, "_timestamp": 1585575777.6412609, "_step": 331}
{"Episode reward": -97.55220471982689, "Episode length": 999, "Policy Loss": -0.2650561034679413, "Value Loss": 0.025217724964022636, "_runtime": 5863.353520154953, "_timestamp": 1585575779.1981535, "_step": 332}
{"Episode reward": -97.52297411847123, "Episode length": 999, "Policy Loss": -0.15836980938911438, "Value Loss": 0.6667757034301758, "_runtime": 5864.906413316727, "_timestamp": 1585575780.7510467, "_step": 333}
{"Episode reward": -97.16704726671463, "Episode length": 999, "Policy Loss": -0.08450677990913391, "Value Loss": 0.020455418154597282, "_runtime": 5866.329247713089, "_timestamp": 1585575782.173881, "_step": 334}
{"Episode reward": 11.463039179015468, "Episode length": 907, "Policy Loss": 0.268794983625412, "Value Loss": 10.871177673339844, "_runtime": 5867.382526874542, "_timestamp": 1585575783.2271602, "_step": 335}
{"Episode reward": 34.904047807680996, "Episode length": 663, "Policy Loss": 0.3200404644012451, "Value Loss": 15.024907112121582, "_runtime": 5868.307307720184, "_timestamp": 1585575784.151941, "_step": 336}
{"Episode reward": 42.806322619296694, "Episode length": 592, "Policy Loss": 0.3948231637477875, "Value Loss": 16.515439987182617, "_runtime": 5869.864145994186, "_timestamp": 1585575785.7087793, "_step": 337}
{"Episode reward": -97.58725346683987, "Episode length": 999, "Policy Loss": -0.31024062633514404, "Value Loss": 0.01478470116853714, "_runtime": 5871.406718254089, "_timestamp": 1585575787.2513516, "_step": 338}
{"Episode reward": -97.62259470729587, "Episode length": 999, "Policy Loss": -0.42543721199035645, "Value Loss": 0.07922691106796265, "_runtime": 5872.93094086647, "_timestamp": 1585575788.7755742, "_step": 339}
{"Episode reward": -96.83507465236346, "Episode length": 999, "Policy Loss": -0.5449070334434509, "Value Loss": 0.38524624705314636, "_runtime": 5873.705374956131, "_timestamp": 1585575789.5500083, "_step": 340}
{"Episode reward": 53.28010548770588, "Episode length": 480, "Policy Loss": 0.17490984499454498, "Value Loss": 21.267663955688477, "_runtime": 5874.702078104019, "_timestamp": 1585575790.5467114, "_step": 341}
{"Episode reward": 38.254505606652245, "Episode length": 635, "Policy Loss": 0.06449766457080841, "Value Loss": 16.328388214111328, "_runtime": 5875.137932062149, "_timestamp": 1585575790.9825654, "_step": 342}
{"Episode reward": 75.28002924477562, "Episode length": 253, "Policy Loss": 1.0207068920135498, "Value Loss": 37.263553619384766, "_runtime": 5876.207816123962, "_timestamp": 1585575792.0524495, "_step": 343}
{"Episode reward": 30.28126135051359, "Episode length": 708, "Policy Loss": 0.28452005982398987, "Value Loss": 13.747382164001465, "_runtime": 5877.062630653381, "_timestamp": 1585575792.907264, "_step": 344}
{"Episode reward": 46.407215379021885, "Episode length": 552, "Policy Loss": 0.5655189752578735, "Value Loss": 17.413259506225586, "_runtime": 5878.416062831879, "_timestamp": 1585575794.2606962, "_step": 345}
{"Episode reward": 11.227516796215, "Episode length": 911, "Policy Loss": 0.36282461881637573, "Value Loss": 13.494271278381348, "_runtime": 5879.945015668869, "_timestamp": 1585575795.789649, "_step": 346}
{"Episode reward": -96.81849530841305, "Episode length": 999, "Policy Loss": -0.10165470093488693, "Value Loss": 0.5430682301521301, "_runtime": 5880.521343231201, "_timestamp": 1585575796.3659766, "_step": 347}
{"Episode reward": 64.31507187721112, "Episode length": 364, "Policy Loss": 0.7854310870170593, "Value Loss": 25.30426025390625, "_runtime": 5882.05203294754, "_timestamp": 1585575797.8966663, "_step": 348}
{"Episode reward": -97.70146532867382, "Episode length": 999, "Policy Loss": -0.4258269667625427, "Value Loss": 0.2021472007036209, "_runtime": 5883.199133872986, "_timestamp": 1585575799.0437672, "_step": 349}
{"Episode reward": 28.72103811192352, "Episode length": 736, "Policy Loss": -0.013282506726682186, "Value Loss": 13.32070255279541, "_runtime": 5884.731701850891, "_timestamp": 1585575800.5763352, "_step": 350}
{"Episode reward": -97.52009155344794, "Episode length": 999, "Policy Loss": -0.5197888612747192, "Value Loss": 0.320038765668869, "_runtime": 5886.279646158218, "_timestamp": 1585575802.1242795, "_step": 351}
{"Episode reward": -96.06142204016456, "Episode length": 999, "Policy Loss": -0.5139338374137878, "Value Loss": 0.48512569069862366, "_runtime": 5886.674801111221, "_timestamp": 1585575802.5194345, "_step": 352}
{"Episode reward": 77.65062121312398, "Episode length": 228, "Policy Loss": 0.9609369039535522, "Value Loss": 41.75871658325195, "_runtime": 5888.224711894989, "_timestamp": 1585575804.0693452, "_step": 353}
{"Episode reward": -97.71913675356895, "Episode length": 999, "Policy Loss": -0.3706555664539337, "Value Loss": 0.06225961819291115, "_runtime": 5889.662655830383, "_timestamp": 1585575805.5072892, "_step": 354}
{"Episode reward": 10.571764828634272, "Episode length": 919, "Policy Loss": 0.1281447559595108, "Value Loss": 10.068567276000977, "_runtime": 5891.136336803436, "_timestamp": 1585575806.9809701, "_step": 355}
{"Episode reward": -97.85287376782418, "Episode length": 999, "Policy Loss": -0.12908713519573212, "Value Loss": 1.0031545162200928, "_runtime": 5892.701240777969, "_timestamp": 1585575808.545874, "_step": 356}
{"Episode reward": -97.51041285784514, "Episode length": 999, "Policy Loss": -0.11895500868558884, "Value Loss": 0.16340139508247375, "_runtime": 5894.261437177658, "_timestamp": 1585575810.1060705, "_step": 357}
{"Episode reward": -96.81066265718847, "Episode length": 999, "Policy Loss": -0.10543091595172882, "Value Loss": 0.15282998979091644, "_runtime": 5895.8104639053345, "_timestamp": 1585575811.6550972, "_step": 358}
{"Episode reward": -97.12563755008405, "Episode length": 999, "Policy Loss": -0.05779555067420006, "Value Loss": 0.7246451377868652, "_runtime": 5896.879484176636, "_timestamp": 1585575812.7241175, "_step": 359}
{"Episode reward": 34.65215263191668, "Episode length": 673, "Policy Loss": 0.30150285363197327, "Value Loss": 14.182700157165527, "_runtime": 5898.096111059189, "_timestamp": 1585575813.9407444, "_step": 360}
{"Episode reward": 24.091995835341237, "Episode length": 782, "Policy Loss": 0.12185530364513397, "Value Loss": 11.736974716186523, "_runtime": 5899.498284101486, "_timestamp": 1585575815.3429174, "_step": 361}
{"Episode reward": 11.476734338064048, "Episode length": 909, "Policy Loss": 0.01797717809677124, "Value Loss": 10.53378677368164, "_runtime": 5901.0369346141815, "_timestamp": 1585575816.881568, "_step": 362}
{"Episode reward": -97.53284322709042, "Episode length": 999, "Policy Loss": -0.43350347876548767, "Value Loss": 0.08077714592218399, "_runtime": 5902.337251186371, "_timestamp": 1585575818.1818845, "_step": 363}
{"Episode reward": 17.81984902425188, "Episode length": 850, "Policy Loss": -0.10625088959932327, "Value Loss": 11.451725959777832, "_runtime": 5903.056383609772, "_timestamp": 1585575818.901017, "_step": 364}
{"Episode reward": 55.8384399274127, "Episode length": 457, "Policy Loss": 0.2084169089794159, "Value Loss": 21.406368255615234, "_runtime": 5903.943253517151, "_timestamp": 1585575819.7878869, "_step": 365}
{"Episode reward": 45.77305248765348, "Episode length": 567, "Policy Loss": 0.2590605318546295, "Value Loss": 16.657941818237305, "_runtime": 5905.456802606583, "_timestamp": 1585575821.301436, "_step": 366}
{"Episode reward": 3.168183958128921, "Episode length": 988, "Policy Loss": 0.00542190857231617, "Value Loss": 9.588266372680664, "_runtime": 5906.954213857651, "_timestamp": 1585575822.7988472, "_step": 367}
{"Episode reward": -97.12713431431409, "Episode length": 999, "Policy Loss": -0.26414820551872253, "Value Loss": 0.0363583043217659, "_runtime": 5908.501735448837, "_timestamp": 1585575824.3463688, "_step": 368}
{"Episode reward": -96.91452048405235, "Episode length": 999, "Policy Loss": -0.17721959948539734, "Value Loss": 0.014556609094142914, "_runtime": 5910.050458431244, "_timestamp": 1585575825.8950918, "_step": 369}
{"Episode reward": -96.88131656039597, "Episode length": 999, "Policy Loss": -0.1056751012802124, "Value Loss": 0.03583841770887375, "_runtime": 5911.092791080475, "_timestamp": 1585575826.9374244, "_step": 370}
{"Episode reward": 34.2959740282342, "Episode length": 675, "Policy Loss": 0.45328381657600403, "Value Loss": 13.958354949951172, "_runtime": 5912.571393489838, "_timestamp": 1585575828.4160268, "_step": 371}
{"Episode reward": 7.166117063517561, "Episode length": 961, "Policy Loss": 0.3564145863056183, "Value Loss": 10.170915603637695, "_runtime": 5914.132178783417, "_timestamp": 1585575829.9768121, "_step": 372}
{"Episode reward": -97.14624730806848, "Episode length": 999, "Policy Loss": -0.12442128360271454, "Value Loss": 0.029400188475847244, "_runtime": 5915.649138689041, "_timestamp": 1585575831.493772, "_step": 373}
{"Episode reward": -96.7165671264896, "Episode length": 999, "Policy Loss": -0.18294882774353027, "Value Loss": 0.005456661805510521, "_runtime": 5917.218407154083, "_timestamp": 1585575833.0630405, "_step": 374}
{"Episode reward": -96.93529354420347, "Episode length": 999, "Policy Loss": -0.234361931681633, "Value Loss": 0.02651694044470787, "_runtime": 5918.780500650406, "_timestamp": 1585575834.625134, "_step": 375}
{"Episode reward": -97.21534160370763, "Episode length": 999, "Policy Loss": -0.2926981449127197, "Value Loss": 0.11281748861074448, "_runtime": 5920.338258981705, "_timestamp": 1585575836.1828923, "_step": 376}
{"Episode reward": -96.63515903687976, "Episode length": 999, "Policy Loss": -0.3023698925971985, "Value Loss": 0.10778981447219849, "_runtime": 5921.817678928375, "_timestamp": 1585575837.6623123, "_step": 377}
{"Episode reward": 7.2871450309331465, "Episode length": 954, "Policy Loss": 0.06980577856302261, "Value Loss": 10.117897987365723, "_runtime": 5923.068348407745, "_timestamp": 1585575838.9129817, "_step": 378}
{"Episode reward": 22.645156435892048, "Episode length": 798, "Policy Loss": 0.21599388122558594, "Value Loss": 11.773338317871094, "_runtime": 5924.633590936661, "_timestamp": 1585575840.4782243, "_step": 379}
{"Episode reward": -96.97964807250497, "Episode length": 999, "Policy Loss": -0.2861373722553253, "Value Loss": 0.045675359666347504, "_runtime": 5926.193255662918, "_timestamp": 1585575842.037889, "_step": 380}
{"Episode reward": -98.00251241681345, "Episode length": 999, "Policy Loss": -0.26739656925201416, "Value Loss": 0.02704295702278614, "_runtime": 5927.753084421158, "_timestamp": 1585575843.5977178, "_step": 381}
{"Episode reward": -96.28003942105506, "Episode length": 999, "Policy Loss": -0.23390784859657288, "Value Loss": 0.030881522223353386, "_runtime": 5929.04577589035, "_timestamp": 1585575844.8904092, "_step": 382}
{"Episode reward": 19.340412166459146, "Episode length": 827, "Policy Loss": 0.2650487720966339, "Value Loss": 11.053833961486816, "_runtime": 5930.650666475296, "_timestamp": 1585575846.4952998, "_step": 383}
{"Episode reward": -96.79240496861148, "Episode length": 999, "Policy Loss": -0.19721777737140656, "Value Loss": 0.012644724920392036, "_runtime": 5932.208525657654, "_timestamp": 1585575848.053159, "_step": 384}
{"Episode reward": -95.57570242225096, "Episode length": 999, "Policy Loss": -0.17323634028434753, "Value Loss": 0.014712563715875149, "_runtime": 5933.753994941711, "_timestamp": 1585575849.5986283, "_step": 385}
{"Episode reward": -96.96775513889465, "Episode length": 999, "Policy Loss": -0.17604465782642365, "Value Loss": 0.014316589571535587, "_runtime": 5935.098142623901, "_timestamp": 1585575850.942776, "_step": 386}
{"Episode reward": 17.353678699249116, "Episode length": 858, "Policy Loss": 0.22204403579235077, "Value Loss": 10.637758255004883, "_runtime": 5936.469591856003, "_timestamp": 1585575852.3142252, "_step": 387}
{"Episode reward": 14.193573342849376, "Episode length": 875, "Policy Loss": 0.23583543300628662, "Value Loss": 10.676831245422363, "_runtime": 5938.034472703934, "_timestamp": 1585575853.879106, "_step": 388}
{"Episode reward": -96.67397895522672, "Episode length": 999, "Policy Loss": -0.20096176862716675, "Value Loss": 0.0653962567448616, "_runtime": 5939.443042039871, "_timestamp": 1585575855.2876754, "_step": 389}
{"Episode reward": 11.855320519865032, "Episode length": 913, "Policy Loss": 0.13901115953922272, "Value Loss": 10.282501220703125, "_runtime": 5940.459460258484, "_timestamp": 1585575856.3040936, "_step": 390}
{"Episode reward": 37.91362439234595, "Episode length": 642, "Policy Loss": 0.19779329001903534, "Value Loss": 14.300178527832031, "_runtime": 5942.021524429321, "_timestamp": 1585575857.8661578, "_step": 391}
{"Episode reward": -96.95550910712953, "Episode length": 999, "Policy Loss": -0.3166063725948334, "Value Loss": 0.15429620444774628, "_runtime": 5943.460962295532, "_timestamp": 1585575859.3055956, "_step": 392}
{"Episode reward": 10.74350433229742, "Episode length": 923, "Policy Loss": 0.1366637498140335, "Value Loss": 10.249127388000488, "_runtime": 5944.99028301239, "_timestamp": 1585575860.8349164, "_step": 393}
{"Episode reward": -97.39820031473025, "Episode length": 999, "Policy Loss": -0.25432059168815613, "Value Loss": 0.019364282488822937, "_runtime": 5946.546366691589, "_timestamp": 1585575862.391, "_step": 394}
{"Episode reward": -95.88590597440616, "Episode length": 999, "Policy Loss": -0.20973049104213715, "Value Loss": 0.02727924846112728, "_runtime": 5948.114352941513, "_timestamp": 1585575863.9589863, "_step": 395}
{"Episode reward": -96.22916281829652, "Episode length": 999, "Policy Loss": -0.19635435938835144, "Value Loss": 0.009305869229137897, "_runtime": 5948.8297345638275, "_timestamp": 1585575864.674368, "_step": 396}
{"Episode reward": 56.85792263306668, "Episode length": 443, "Policy Loss": 0.6933074593544006, "Value Loss": 20.70536994934082, "_runtime": 5950.396240949631, "_timestamp": 1585575866.2408743, "_step": 397}
{"Episode reward": -96.38799535450066, "Episode length": 999, "Policy Loss": -0.1617424339056015, "Value Loss": 0.07063647359609604, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881, 0.07520690560340881]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5223388075828552, -0.5104197263717651, -0.4985005855560303, -0.4865815043449402, -0.4746623933315277, -0.46274328231811523, -0.45082420110702515, -0.43890509009361267, -0.4269859790802002, -0.4150668680667877, -0.40314775705337524, -0.39122867584228516, -0.3793095648288727, -0.3673904538154602, -0.3554713726043701, -0.34355226159095764, -0.33163315057754517, -0.3197140395641327, -0.3077949285507202, -0.2958758473396301, -0.28395673632621765, -0.2720376253128052, -0.2601185441017151, -0.2481994330883026, -0.23628032207489014, -0.22436121106147766, -0.21244210004806519, -0.2005230188369751, -0.18860390782356262, -0.17668479681015015, -0.16476571559906006, -0.15284660458564758, -0.1409274935722351, -0.12900838255882263, -0.11708927154541016, -0.10517019033432007, -0.09325107932090759, -0.08133196830749512, -0.06941288709640503, -0.057493776082992554, -0.04557466506958008, -0.0336555540561676, -0.021736443042755127, -0.009817361831665039, 0.002101719379425049, 0.014020860195159912, 0.02593994140625, 0.03785908222198486, 0.04977816343307495, 0.06169724464416504, 0.0736163854598999, 0.08553546667098999, 0.09745460748672485, 0.10937368869781494, 0.12129276990890503, 0.1332119107246399, 0.14513099193572998, 0.15705007314682007, 0.16896921396255493, 0.18088829517364502, 0.1928073763847351, 0.20472651720046997, 0.21664559841156006, 0.22856473922729492, 0.240483820438385]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.009532095864415169, -0.008606180548667908, -0.007680264767259359, -0.006754348985850811, -0.00582843367010355, -0.004902518354356289, -0.0039766025729477406, -0.003050686791539192, -0.002124771475791931, -0.00119885616004467, -0.00027294084429740906, 0.0006529754027724266, 0.0015788907185196877, 0.0025048060342669487, 0.0034307222813367844, 0.004356637597084045, 0.0052825529128313065, 0.0062084682285785675, 0.0071343835443258286, 0.00806029886007309, 0.00898621417582035, 0.009912131354212761, 0.010838046669960022, 0.011763961985707283, 0.012689877301454544, 0.013615792617201805, 0.014541707932949066, 0.015467623248696327, 0.016393540427088737, 0.017319455742836, 0.01824537105858326, 0.01917128637433052, 0.02009720169007778, 0.021023117005825043, 0.021949032321572304, 0.022874949499964714, 0.023800862953066826, 0.024726780131459236, 0.025652693584561348, 0.026578610762953758, 0.02750452421605587, 0.02843044139444828, 0.02935635857284069, 0.030282272025942802, 0.031208189204335213, 0.032134100794792175, 0.033060021698474884, 0.033985935151576996, 0.03491184860467911, 0.035837769508361816, 0.03676368296146393, 0.03768959641456604, 0.03861550986766815, 0.03954143077135086, 0.04046734422445297, 0.041393257677555084, 0.04231917858123779, 0.043245092034339905, 0.04417100548744202, 0.04509691894054413, 0.04602283984422684, 0.04694875329732895, 0.04787466675043106, 0.04880058020353317, 0.04972650110721588]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 0.0, 3.0, 0.0, 7.0, 5.0, 8.0, 11.0, 13.0, 43.0, 119.0, 150.0, 19.0, 27.0, 19.0, 6.0, 11.0, 4.0, 8.0, 1.0, 1.0, 1.0, 3.0, 6.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0], "bins": [-0.19826433062553406, -0.19095247983932495, -0.18364064395427704, -0.17632879316806793, -0.16901695728302002, -0.1617051064968109, -0.1543932557106018, -0.1470814049243927, -0.1397695690393448, -0.13245773315429688, -0.12514588236808777, -0.11783403158187866, -0.11052218824625015, -0.10321034491062164, -0.09589849412441254, -0.08858665078878403, -0.08127480745315552, -0.07396296411752701, -0.0666511207818985, -0.05933926999568939, -0.05202743411064148, -0.04471558332443237, -0.03740373253822327, -0.030091896653175354, -0.022780045866966248, -0.015468195080757141, -0.008156359195709229, -0.0008445084095001221, 0.006467342376708984, 0.013779178261756897, 0.021091029047966003, 0.028402864933013916, 0.03571471571922302, 0.04302656650543213, 0.05033840239048004, 0.057650238275527954, 0.06496208906173706, 0.07227393984794617, 0.07958579063415527, 0.08689764142036438, 0.0942094624042511, 0.1015213131904602, 0.10883316397666931, 0.11614501476287842, 0.12345686554908752, 0.13076871633529663, 0.13808053731918335, 0.14539238810539246, 0.15270423889160156, 0.16001608967781067, 0.16732794046401978, 0.1746397614479065, 0.1819516122341156, 0.1892634630203247, 0.1965753138065338, 0.20388716459274292, 0.21119901537895203, 0.21851083636283875, 0.22582268714904785, 0.23313453793525696, 0.24044638872146606, 0.24775823950767517, 0.2550700604915619, 0.262381911277771, 0.2696937620639801]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3070847988128662, -0.29870620369911194, -0.29032760858535767, -0.2819490134716034, -0.2735704183578491, -0.26519179344177246, -0.2568132281303406, -0.2484346181154251, -0.24005600810050964, -0.23167741298675537, -0.2232988178730011, -0.21492022275924683, -0.20654162764549255, -0.19816303253173828, -0.189784437417984, -0.18140582740306854, -0.17302723228931427, -0.16464863717556, -0.15627004206180573, -0.14789143204689026, -0.139512836933136, -0.1311342418193817, -0.12275564670562744, -0.11437705159187317, -0.1059984564781189, -0.09761984646320343, -0.08924125134944916, -0.08086265623569489, -0.07248406112194061, -0.06410546600818634, -0.055726855993270874, -0.0473482608795166, -0.03896966576576233, -0.030591070652008057, -0.022212475538253784, -0.013833880424499512, -0.005455285310745239, 0.002923309803009033, 0.011301934719085693, 0.019680529832839966, 0.02805912494659424, 0.03643772006034851, 0.04481631517410278, 0.053194910287857056, 0.06157350540161133, 0.0699521005153656, 0.07833069562911987, 0.08670929074287415, 0.09508788585662842, 0.10346651077270508, 0.11184510588645935, 0.12022370100021362, 0.1286022961139679, 0.13698089122772217, 0.14535948634147644, 0.1537380814552307, 0.16211667656898499, 0.17049527168273926, 0.17887386679649353, 0.1872524917125702, 0.19563108682632446, 0.20400965213775635, 0.212388277053833, 0.2207668423652649, 0.22914546728134155]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.40615352988243103, -0.3945516347885132, -0.38294970989227295, -0.3713478147983551, -0.35974591970443726, -0.348143994808197, -0.3365420997142792, -0.32494020462036133, -0.3133382797241211, -0.30173638463020325, -0.2901344895362854, -0.27853256464004517, -0.2669306695461273, -0.2553287744522095, -0.24372686445713043, -0.23212496936321259, -0.22052305936813354, -0.2089211493730545, -0.19731925427913666, -0.18571734428405762, -0.17411544919013977, -0.16251353919506073, -0.1509116291999817, -0.13930973410606384, -0.1277078092098236, -0.11610591411590576, -0.10450401902198792, -0.09290212392807007, -0.08130019903182983, -0.06969830393791199, -0.05809640884399414, -0.046494483947753906, -0.03489258885383606, -0.023290693759918213, -0.011688768863677979, -8.687376976013184e-05, 0.011515021324157715, 0.02311694622039795, 0.034718841314315796, 0.04632073640823364, 0.05792263150215149, 0.06952455639839172, 0.08112645149230957, 0.09272834658622742, 0.10433027148246765, 0.11593219637870789, 0.12753406167030334, 0.13913598656654358, 0.1507379114627838, 0.16233977675437927, 0.1739417016506195, 0.18554356694221497, 0.1971454918384552, 0.20874741673469543, 0.2203492820262909, 0.23195120692253113, 0.24355313181877136, 0.2551549971103668, 0.26675692200660706, 0.2783588469028473, 0.28996071219444275, 0.301562637090683, 0.3131645619869232, 0.3247664272785187, 0.3363683521747589]}, "_runtime": 5951.974729299545, "_timestamp": 1585575867.8193626, "_step": 398}
{"Episode reward": -96.09571242158498, "Episode length": 999, "Policy Loss": -0.1828707456588745, "Value Loss": 0.01357912179082632, "_runtime": 5953.16826748848, "_timestamp": 1585575869.0129008, "_step": 399}
{"Episode reward": 23.687483612256727, "Episode length": 789, "Policy Loss": 0.40915733575820923, "Value Loss": 11.651803970336914, "_runtime": 5954.770693778992, "_timestamp": 1585575870.6153271, "_step": 400}
{"Episode reward": -97.24110044763616, "Episode length": 999, "Policy Loss": -0.24048855900764465, "Value Loss": 0.03135459125041962, "_runtime": 5956.335017204285, "_timestamp": 1585575872.1796505, "_step": 401}
{"Episode reward": -96.5885405181031, "Episode length": 999, "Policy Loss": -0.2457132786512375, "Value Loss": 0.03575213998556137, "_runtime": 5957.865433931351, "_timestamp": 1585575873.7100673, "_step": 402}
{"Episode reward": -95.86193066250848, "Episode length": 999, "Policy Loss": -0.24313831329345703, "Value Loss": 0.019150903448462486, "_runtime": 5959.421029090881, "_timestamp": 1585575875.2656624, "_step": 403}
{"Episode reward": -96.45699934506392, "Episode length": 999, "Policy Loss": -0.24272757768630981, "Value Loss": 0.04988524690270424, "_runtime": 5960.983967542648, "_timestamp": 1585575876.828601, "_step": 404}
{"Episode reward": -96.6985540913893, "Episode length": 999, "Policy Loss": -0.227595716714859, "Value Loss": 0.011224542744457722, "_runtime": 5962.542644500732, "_timestamp": 1585575878.3872778, "_step": 405}
{"Episode reward": -96.94876680329827, "Episode length": 999, "Policy Loss": -0.21863743662834167, "Value Loss": 0.020675886422395706, "_runtime": 5964.108101129532, "_timestamp": 1585575879.9527345, "_step": 406}
{"Episode reward": -96.15581048035607, "Episode length": 999, "Policy Loss": -0.1817067414522171, "Value Loss": 0.008699129335582256, "_runtime": 5965.680505514145, "_timestamp": 1585575881.5251389, "_step": 407}
{"Episode reward": -96.87509832366631, "Episode length": 999, "Policy Loss": -0.16790169477462769, "Value Loss": 0.0028273274656385183, "_runtime": 5967.24821972847, "_timestamp": 1585575883.092853, "_step": 408}
{"Episode reward": -95.95013962431985, "Episode length": 999, "Policy Loss": -0.1280449479818344, "Value Loss": 0.17976011335849762, "_runtime": 5968.809251070023, "_timestamp": 1585575884.6538844, "_step": 409}
{"Episode reward": -96.92294139221794, "Episode length": 999, "Policy Loss": -0.1661486178636551, "Value Loss": 0.0031250049360096455, "_runtime": 5969.809916734695, "_timestamp": 1585575885.65455, "_step": 410}
{"Episode reward": 37.93060476401065, "Episode length": 635, "Policy Loss": 0.5877830386161804, "Value Loss": 14.666580200195312, "_runtime": 5971.365389347076, "_timestamp": 1585575887.2100227, "_step": 411}
{"Episode reward": -96.99862893448689, "Episode length": 999, "Policy Loss": -0.2038506120443344, "Value Loss": 0.03638748079538345, "_runtime": 5972.2545211315155, "_timestamp": 1585575888.0991545, "_step": 412}
{"Episode reward": 46.38595241551699, "Episode length": 556, "Policy Loss": 0.37584561109542847, "Value Loss": 16.03432846069336, "_runtime": 5973.799372911453, "_timestamp": 1585575889.6440063, "_step": 413}
{"Episode reward": -97.24550051999421, "Episode length": 999, "Policy Loss": -0.2709807753562927, "Value Loss": 0.042556025087833405, "_runtime": 5974.814206838608, "_timestamp": 1585575890.6588402, "_step": 414}
{"Episode reward": 37.583948723810444, "Episode length": 638, "Policy Loss": 0.23092904686927795, "Value Loss": 14.0106840133667, "_runtime": 5975.879946708679, "_timestamp": 1585575891.72458, "_step": 415}
{"Episode reward": 32.859252364369226, "Episode length": 691, "Policy Loss": 0.14105314016342163, "Value Loss": 13.01157283782959, "_runtime": 5977.44370174408, "_timestamp": 1585575893.288335, "_step": 416}
{"Episode reward": -96.65814910389251, "Episode length": 999, "Policy Loss": -0.23705145716667175, "Value Loss": 0.04195595160126686, "_runtime": 5979.012092351913, "_timestamp": 1585575894.8567257, "_step": 417}
{"Episode reward": -97.1494698007016, "Episode length": 999, "Policy Loss": -0.19537240266799927, "Value Loss": 0.010931776836514473, "_runtime": 5979.96058177948, "_timestamp": 1585575895.8052151, "_step": 418}
{"Episode reward": 41.350378292670946, "Episode length": 608, "Policy Loss": 0.5704653859138489, "Value Loss": 14.561927795410156, "_runtime": 5981.509033441544, "_timestamp": 1585575897.3536668, "_step": 419}
{"Episode reward": -96.3415828809336, "Episode length": 999, "Policy Loss": -0.1287531852722168, "Value Loss": 0.005734948441386223, "_runtime": 5982.428260564804, "_timestamp": 1585575898.272894, "_step": 420}
{"Episode reward": 43.519988092856096, "Episode length": 579, "Policy Loss": 0.5759182572364807, "Value Loss": 16.134084701538086, "_runtime": 5983.1473824977875, "_timestamp": 1585575898.9920158, "_step": 421}
{"Episode reward": 55.783928298232716, "Episode length": 460, "Policy Loss": 0.5398049354553223, "Value Loss": 19.446758270263672, "_runtime": 5984.129071474075, "_timestamp": 1585575899.9737048, "_step": 422}
{"Episode reward": 39.349775624798596, "Episode length": 620, "Policy Loss": 0.6726292967796326, "Value Loss": 15.57186508178711, "_runtime": 5985.331689834595, "_timestamp": 1585575901.1763232, "_step": 423}
{"Episode reward": 23.927257034545264, "Episode length": 784, "Policy Loss": 0.2089216113090515, "Value Loss": 11.555537223815918, "_runtime": 5986.839325904846, "_timestamp": 1585575902.6839592, "_step": 424}
{"Episode reward": -97.31117134126525, "Episode length": 999, "Policy Loss": -0.34101468324661255, "Value Loss": 0.4961095452308655, "_runtime": 5988.166877985001, "_timestamp": 1585575904.0115113, "_step": 425}
{"Episode reward": 14.93671309051497, "Episode length": 871, "Policy Loss": -0.012881293892860413, "Value Loss": 11.229194641113281, "_runtime": 5989.706625699997, "_timestamp": 1585575905.551259, "_step": 426}
{"Episode reward": -97.59061977366159, "Episode length": 999, "Policy Loss": -0.29880574345588684, "Value Loss": 0.2097259759902954, "_runtime": 5990.601348638535, "_timestamp": 1585575906.445982, "_step": 427}
{"Episode reward": 44.640513026657885, "Episode length": 567, "Policy Loss": 0.36713942885398865, "Value Loss": 16.084686279296875, "_runtime": 5991.792725563049, "_timestamp": 1585575907.637359, "_step": 428}
{"Episode reward": 24.019728437681664, "Episode length": 782, "Policy Loss": 0.4388153851032257, "Value Loss": 11.918465614318848, "_runtime": 5993.347973585129, "_timestamp": 1585575909.192607, "_step": 429}
{"Episode reward": -97.31298468118288, "Episode length": 999, "Policy Loss": -0.02209208533167839, "Value Loss": 0.02448129653930664, "_runtime": 5994.867878675461, "_timestamp": 1585575910.712512, "_step": 430}
{"Episode reward": -97.18468027845897, "Episode length": 999, "Policy Loss": 0.023284554481506348, "Value Loss": 0.4071827828884125, "_runtime": 5996.153165102005, "_timestamp": 1585575911.9977984, "_step": 431}
{"Episode reward": 18.592083540043987, "Episode length": 831, "Policy Loss": 0.44066038727760315, "Value Loss": 12.123456954956055, "_runtime": 5997.703892707825, "_timestamp": 1585575913.548526, "_step": 432}
{"Episode reward": -97.56974513129632, "Episode length": 999, "Policy Loss": -0.03047446347773075, "Value Loss": 0.061120789498090744, "_runtime": 5999.257056951523, "_timestamp": 1585575915.1016903, "_step": 433}
{"Episode reward": -96.77753500589493, "Episode length": 999, "Policy Loss": -0.14219993352890015, "Value Loss": 0.09851427376270294, "_runtime": 6000.407762289047, "_timestamp": 1585575916.2523956, "_step": 434}
{"Episode reward": 27.67217359265642, "Episode length": 739, "Policy Loss": 0.1680118590593338, "Value Loss": 12.29452896118164, "_runtime": 6002.003609657288, "_timestamp": 1585575917.848243, "_step": 435}
{"Episode reward": -96.68983405535981, "Episode length": 999, "Policy Loss": -0.3475227355957031, "Value Loss": 0.22718259692192078, "_runtime": 6003.555155038834, "_timestamp": 1585575919.3997884, "_step": 436}
{"Episode reward": -97.0397833788733, "Episode length": 999, "Policy Loss": -0.41594597697257996, "Value Loss": 0.5635821223258972, "_runtime": 6005.0963661670685, "_timestamp": 1585575920.9409995, "_step": 437}
{"Episode reward": -96.60748374557733, "Episode length": 999, "Policy Loss": -0.4020375609397888, "Value Loss": 0.38436058163642883, "_runtime": 6006.65517950058, "_timestamp": 1585575922.4998128, "_step": 438}
{"Episode reward": -97.09400365859317, "Episode length": 999, "Policy Loss": -0.3281799852848053, "Value Loss": 0.09977556020021439, "_runtime": 6008.199863195419, "_timestamp": 1585575924.0444965, "_step": 439}
{"Episode reward": -97.72541123413322, "Episode length": 999, "Policy Loss": -0.26205557584762573, "Value Loss": 0.028240246698260307, "_runtime": 6009.765426158905, "_timestamp": 1585575925.6100595, "_step": 440}
{"Episode reward": -97.07590152810702, "Episode length": 999, "Policy Loss": -0.2024022787809372, "Value Loss": 0.010021856054663658, "_runtime": 6011.3294105529785, "_timestamp": 1585575927.174044, "_step": 441}
{"Episode reward": -97.64726115548396, "Episode length": 999, "Policy Loss": -0.1433251053094864, "Value Loss": 0.020241277292370796, "_runtime": 6012.880375385284, "_timestamp": 1585575928.7250087, "_step": 442}
{"Episode reward": -96.46912512218877, "Episode length": 999, "Policy Loss": -0.06243416666984558, "Value Loss": 0.1768639087677002, "_runtime": 6014.443981170654, "_timestamp": 1585575930.2886145, "_step": 443}
{"Episode reward": -97.47873140253252, "Episode length": 999, "Policy Loss": -0.04473191499710083, "Value Loss": 0.2610008418560028, "_runtime": 6015.820966005325, "_timestamp": 1585575931.6655993, "_step": 444}
{"Episode reward": 14.811525386939422, "Episode length": 879, "Policy Loss": 0.4433349370956421, "Value Loss": 11.365023612976074, "_runtime": 6017.025465488434, "_timestamp": 1585575932.8700988, "_step": 445}
{"Episode reward": 25.063491116211438, "Episode length": 768, "Policy Loss": 0.34019458293914795, "Value Loss": 12.13721752166748, "_runtime": 6017.4439578056335, "_timestamp": 1585575933.2885911, "_step": 446}
{"Episode reward": 77.23717189256635, "Episode length": 234, "Policy Loss": 1.1814125776290894, "Value Loss": 39.97881317138672, "_runtime": 6018.772347450256, "_timestamp": 1585575934.6169808, "_step": 447}
{"Episode reward": 15.775931411131722, "Episode length": 863, "Policy Loss": 0.03227532282471657, "Value Loss": 11.082843780517578, "_runtime": 6020.32279419899, "_timestamp": 1585575936.1674275, "_step": 448}
{"Episode reward": -96.83090646178185, "Episode length": 999, "Policy Loss": -0.44911089539527893, "Value Loss": 0.17562510073184967, "_runtime": 6021.809852361679, "_timestamp": 1585575937.6544857, "_step": 449}
{"Episode reward": -97.36125917546076, "Episode length": 999, "Policy Loss": -0.44990089535713196, "Value Loss": 0.3053480088710785, "_runtime": 6023.3631772994995, "_timestamp": 1585575939.2078106, "_step": 450}
{"Episode reward": -97.21653313837244, "Episode length": 999, "Policy Loss": -0.47236284613609314, "Value Loss": 0.40781107544898987, "_runtime": 6024.955438137054, "_timestamp": 1585575940.8000715, "_step": 451}
{"Episode reward": -97.28315118418361, "Episode length": 999, "Policy Loss": -0.43923071026802063, "Value Loss": 0.3772623538970947, "_runtime": 6026.443065166473, "_timestamp": 1585575942.2876985, "_step": 452}
{"Episode reward": 6.761919405827655, "Episode length": 969, "Policy Loss": -0.01653406396508217, "Value Loss": 9.755443572998047, "_runtime": 6028.022422790527, "_timestamp": 1585575943.8670561, "_step": 453}
{"Episode reward": -96.55014534356141, "Episode length": 999, "Policy Loss": -0.21391214430332184, "Value Loss": 0.06443478167057037, "_runtime": 6029.5697548389435, "_timestamp": 1585575945.4143882, "_step": 454}
{"Episode reward": -97.62945817056665, "Episode length": 999, "Policy Loss": -0.10635322332382202, "Value Loss": 0.39545607566833496, "_runtime": 6030.088027954102, "_timestamp": 1585575945.9326613, "_step": 455}
{"Episode reward": 69.52646393389553, "Episode length": 309, "Policy Loss": 0.9139823913574219, "Value Loss": 29.366132736206055, "_runtime": 6031.098970890045, "_timestamp": 1585575946.9436042, "_step": 456}
{"Episode reward": 37.855486596064885, "Episode length": 641, "Policy Loss": 0.4714350700378418, "Value Loss": 15.080016136169434, "_runtime": 6031.965545415878, "_timestamp": 1585575947.8101788, "_step": 457}
{"Episode reward": 47.060359138334455, "Episode length": 541, "Policy Loss": 0.5103559494018555, "Value Loss": 17.183856964111328, "_runtime": 6033.464464187622, "_timestamp": 1585575949.3090975, "_step": 458}
{"Episode reward": -96.04115790861488, "Episode length": 999, "Policy Loss": -0.3798934519290924, "Value Loss": 0.07207289338111877, "_runtime": 6034.772533416748, "_timestamp": 1585575950.6171668, "_step": 459}
{"Episode reward": 16.252033008087395, "Episode length": 864, "Policy Loss": 0.030365634709596634, "Value Loss": 10.923134803771973, "_runtime": 6036.0552225112915, "_timestamp": 1585575951.8998559, "_step": 460}
{"Episode reward": 17.364675749847933, "Episode length": 848, "Policy Loss": -0.13268180191516876, "Value Loss": 11.836097717285156, "_runtime": 6036.9152138233185, "_timestamp": 1585575952.7598472, "_step": 461}
{"Episode reward": 46.33247275081628, "Episode length": 545, "Policy Loss": 0.08225469291210175, "Value Loss": 17.761524200439453, "_runtime": 6038.467366695404, "_timestamp": 1585575954.312, "_step": 462}
{"Episode reward": -96.98996487777464, "Episode length": 999, "Policy Loss": -0.4200700521469116, "Value Loss": 0.06913986802101135, "_runtime": 6040.019741773605, "_timestamp": 1585575955.864375, "_step": 463}
{"Episode reward": -97.06005133354857, "Episode length": 999, "Policy Loss": -0.2599851191043854, "Value Loss": 0.4892497658729553, "_runtime": 6040.737587213516, "_timestamp": 1585575956.5822206, "_step": 464}
{"Episode reward": 55.25374736361483, "Episode length": 460, "Policy Loss": 0.5303047299385071, "Value Loss": 20.39083480834961, "_runtime": 6042.299480438232, "_timestamp": 1585575958.1441138, "_step": 465}
{"Episode reward": -97.17308091141108, "Episode length": 999, "Policy Loss": -0.2171940803527832, "Value Loss": 0.043643560260534286, "_runtime": 6042.995796442032, "_timestamp": 1585575958.8404298, "_step": 466}
{"Episode reward": 58.779431928215914, "Episode length": 429, "Policy Loss": 0.6848216652870178, "Value Loss": 21.272682189941406, "_runtime": 6044.517125368118, "_timestamp": 1585575960.3617587, "_step": 467}
{"Episode reward": -96.41817090018793, "Episode length": 999, "Policy Loss": -0.2250642478466034, "Value Loss": 0.02475626952946186, "_runtime": 6045.513795852661, "_timestamp": 1585575961.3584292, "_step": 468}
{"Episode reward": 38.80861742206656, "Episode length": 629, "Policy Loss": 0.28747421503067017, "Value Loss": 14.587713241577148, "_runtime": 6047.024032592773, "_timestamp": 1585575962.868666, "_step": 469}
{"Episode reward": -96.27722061306275, "Episode length": 999, "Policy Loss": -0.28193408250808716, "Value Loss": 0.00985748041421175, "_runtime": 6048.613397836685, "_timestamp": 1585575964.4580312, "_step": 470}
{"Episode reward": -97.48563247282274, "Episode length": 999, "Policy Loss": -0.33317703008651733, "Value Loss": 0.012774013914167881, "_runtime": 6050.1417372226715, "_timestamp": 1585575965.9863706, "_step": 471}
{"Episode reward": -96.7414929027178, "Episode length": 999, "Policy Loss": -0.3633875250816345, "Value Loss": 0.012624316848814487, "_runtime": 6051.688410520554, "_timestamp": 1585575967.5330439, "_step": 472}
{"Episode reward": -96.39102596857114, "Episode length": 999, "Policy Loss": -0.39043742418289185, "Value Loss": 0.023121630772948265, "_runtime": 6052.930837154388, "_timestamp": 1585575968.7754705, "_step": 473}
{"Episode reward": 22.243823186997332, "Episode length": 791, "Policy Loss": -0.019425829872488976, "Value Loss": 11.180723190307617, "_runtime": 6053.780237197876, "_timestamp": 1585575969.6248705, "_step": 474}
{"Episode reward": 47.791907548871016, "Episode length": 533, "Policy Loss": 0.24112705886363983, "Value Loss": 17.063451766967773, "_runtime": 6055.341025352478, "_timestamp": 1585575971.1856587, "_step": 475}
{"Episode reward": -97.5654654564054, "Episode length": 999, "Policy Loss": -0.3925739526748657, "Value Loss": 0.029091227799654007, "_runtime": 6056.628494501114, "_timestamp": 1585575972.4731278, "_step": 476}
{"Episode reward": 17.813805817745575, "Episode length": 841, "Policy Loss": 0.007756232284009457, "Value Loss": 11.18459701538086, "_runtime": 6057.260162830353, "_timestamp": 1585575973.1047962, "_step": 477}
{"Episode reward": 60.70773074996304, "Episode length": 402, "Policy Loss": 0.5136121511459351, "Value Loss": 21.805316925048828, "_runtime": 6058.815925359726, "_timestamp": 1585575974.6605587, "_step": 478}
{"Episode reward": -96.3676517453676, "Episode length": 999, "Policy Loss": -0.31119218468666077, "Value Loss": 0.037053998559713364, "_runtime": 6060.368668079376, "_timestamp": 1585575976.2133014, "_step": 479}
{"Episode reward": -96.51301739836778, "Episode length": 999, "Policy Loss": -0.30929479002952576, "Value Loss": 0.013474461622536182, "_runtime": 6061.8841462135315, "_timestamp": 1585575977.7287796, "_step": 480}
{"Episode reward": -97.48915353463055, "Episode length": 999, "Policy Loss": -0.29590001702308655, "Value Loss": 0.00932776927947998, "_runtime": 6063.462128400803, "_timestamp": 1585575979.3067617, "_step": 481}
{"Episode reward": -96.17280662013592, "Episode length": 999, "Policy Loss": -0.27044400572776794, "Value Loss": 0.023845946416258812, "_runtime": 6065.04039978981, "_timestamp": 1585575980.8850331, "_step": 482}
{"Episode reward": -97.2237323094196, "Episode length": 999, "Policy Loss": -0.27328407764434814, "Value Loss": 0.009617538191378117, "_runtime": 6066.0813364982605, "_timestamp": 1585575981.9259698, "_step": 483}
{"Episode reward": 35.86055176965394, "Episode length": 654, "Policy Loss": 0.3046098053455353, "Value Loss": 14.692997932434082, "_runtime": 6067.289893627167, "_timestamp": 1585575983.134527, "_step": 484}
{"Episode reward": 24.834201330857454, "Episode length": 772, "Policy Loss": 0.16534873843193054, "Value Loss": 11.458271980285645, "_runtime": 6068.867913484573, "_timestamp": 1585575984.7125468, "_step": 485}
{"Episode reward": -97.44954448030461, "Episode length": 999, "Policy Loss": -0.3590043783187866, "Value Loss": 0.07722555845975876, "_runtime": 6070.151963233948, "_timestamp": 1585575985.9965966, "_step": 486}
{"Episode reward": 19.982640167143174, "Episode length": 831, "Policy Loss": 0.06851456314325333, "Value Loss": 10.80704116821289, "_runtime": 6071.742937326431, "_timestamp": 1585575987.5875707, "_step": 487}
{"Episode reward": -96.69039144876525, "Episode length": 999, "Policy Loss": -0.33944860100746155, "Value Loss": 0.05697531998157501, "_runtime": 6073.301278352737, "_timestamp": 1585575989.1459117, "_step": 488}
{"Episode reward": -97.30400372303916, "Episode length": 999, "Policy Loss": -0.30994537472724915, "Value Loss": 0.040835097432136536, "_runtime": 6073.7154276371, "_timestamp": 1585575989.560061, "_step": 489}
{"Episode reward": 77.0019484815589, "Episode length": 237, "Policy Loss": 1.1860979795455933, "Value Loss": 40.06044006347656, "_runtime": 6075.288316965103, "_timestamp": 1585575991.1329503, "_step": 490}
{"Episode reward": -96.7011339831868, "Episode length": 999, "Policy Loss": -0.24246476590633392, "Value Loss": 0.1197001039981842, "_runtime": 6076.866090774536, "_timestamp": 1585575992.710724, "_step": 491}
{"Episode reward": -96.37166275364783, "Episode length": 999, "Policy Loss": -0.231585294008255, "Value Loss": 0.00738232396543026, "_runtime": 6077.972654104233, "_timestamp": 1585575993.8172874, "_step": 492}
{"Episode reward": 28.001313654692524, "Episode length": 748, "Policy Loss": 0.20501790940761566, "Value Loss": 12.28878402709961, "_runtime": 6078.919348239899, "_timestamp": 1585575994.7639816, "_step": 493}
{"Episode reward": 41.899636916305504, "Episode length": 594, "Policy Loss": 0.32858216762542725, "Value Loss": 14.861512184143066, "_runtime": 6079.741679191589, "_timestamp": 1585575995.5863125, "_step": 494}
{"Episode reward": 50.60743814811448, "Episode length": 511, "Policy Loss": 0.45480185747146606, "Value Loss": 17.958404541015625, "_runtime": 6080.633642911911, "_timestamp": 1585575996.4782763, "_step": 495}
{"Episode reward": 44.07186280308517, "Episode length": 579, "Policy Loss": 0.3782755732536316, "Value Loss": 16.580791473388672, "_runtime": 6082.033971309662, "_timestamp": 1585575997.8786047, "_step": 496}
{"Episode reward": 11.957046202934606, "Episode length": 908, "Policy Loss": 0.08268503844738007, "Value Loss": 10.056060791015625, "_runtime": 6083.545970916748, "_timestamp": 1585575999.3906043, "_step": 497}
{"Episode reward": -97.16664112175476, "Episode length": 999, "Policy Loss": -0.30856651067733765, "Value Loss": 0.10376092046499252, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582, -2.030766487121582]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 6.0], "bins": [-8.836372375488281, -8.667409896850586, -8.498448371887207, -8.329485893249512, -8.160523414611816, -7.991561412811279, -7.822599411010742, -7.653636932373047, -7.48467493057251, -7.3157124519348145, -7.146750450134277, -6.977787971496582, -6.808825969696045, -6.639863967895508, -6.4709014892578125, -6.301939487457275, -6.132977485656738, -5.964015007019043, -5.795052528381348, -5.626091003417969, -5.457128524780273, -5.288166046142578, -5.119204044342041, -4.950242042541504, -4.781279563903809, -4.6123175621032715, -4.443355083465576, -4.274393081665039, -4.105431079864502, -3.9364686012268066, -3.7675065994262695, -3.598544120788574, -3.429582118988037, -3.2606201171875, -3.0916576385498047, -2.9226956367492676, -2.7537331581115723, -2.584771156311035, -2.415809154510498, -2.2468466758728027, -2.0778846740722656, -1.9089221954345703, -1.7399601936340332, -1.570998191833496, -1.4020357131958008, -1.2330737113952637, -1.0641112327575684, -0.8951492309570312, -0.7261867523193359, -0.557225227355957, -0.3882627487182617, -0.2193002700805664, -0.050337791442871094, 0.11862373352050781, 0.2875862121582031, 0.45654869079589844, 0.6255102157592773, 0.7944726943969727, 0.963435173034668, 1.1323966979980469, 1.3013591766357422, 1.4703216552734375, 1.6392841339111328, 1.8082456588745117, 1.977208137512207]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3379590511322021, -1.3130300045013428, -1.2881009578704834, -1.263171911239624, -1.2382428646087646, -1.2133138179779053, -1.188384771347046, -1.1634557247161865, -1.1385266780853271, -1.1135976314544678, -1.0886685848236084, -1.063739538192749, -1.0388104915618896, -1.0138814449310303, -0.9889523983001709, -0.9640233516693115, -0.9390943050384521, -0.9141652584075928, -0.8892362117767334, -0.864307165145874, -0.8393781185150146, -0.8144490718841553, -0.7895200252532959, -0.7645909786224365, -0.7396619319915771, -0.7147328853607178, -0.6898038387298584, -0.664874792098999, -0.6399457454681396, -0.6150166988372803, -0.5900876522064209, -0.5651586055755615, -0.5402295589447021, -0.5153005123138428, -0.4903714656829834, -0.465442419052124, -0.44051337242126465, -0.4155843257904053, -0.3906552791595459, -0.3657262325286865, -0.34079718589782715, -0.3158681392669678, -0.2909390926361084, -0.266010046005249, -0.24108099937438965, -0.21615195274353027, -0.1912229061126709, -0.16629385948181152, -0.14136481285095215, -0.11643576622009277, -0.0915067195892334, -0.06657767295837402, -0.04164862632751465, -0.016719579696655273, 0.008209466934204102, 0.03313851356506348, 0.05806756019592285, 0.08299660682678223, 0.1079256534576416, 0.13285470008850098, 0.15778374671936035, 0.18271279335021973, 0.2076418399810791, 0.23257088661193848, 0.25749993324279785]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 5.0, 4.0, 1.0, 4.0, 0.0, 1.0, 6.0, 4.0, 5.0, 13.0, 14.0, 25.0, 36.0, 213.0, 83.0, 28.0, 10.0, 9.0, 5.0, 4.0, 3.0, 3.0, 1.0, 5.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-3.2696175575256348, -3.189166307449341, -3.108715057373047, -3.028263807296753, -2.947812557220459, -2.867361307144165, -2.786910057067871, -2.706458806991577, -2.626007556915283, -2.5455563068389893, -2.4651050567626953, -2.3846538066864014, -2.3042025566101074, -2.2237510681152344, -2.1433000564575195, -2.0628485679626465, -1.982397437095642, -1.9019461870193481, -1.8214949369430542, -1.7410436868667603, -1.6605924367904663, -1.5801411867141724, -1.4996899366378784, -1.4192386865615845, -1.338787317276001, -1.258336067199707, -1.177884817123413, -1.0974335670471191, -1.0169823169708252, -0.9365310668945312, -0.8560798168182373, -0.7756285667419434, -0.6951773166656494, -0.6147260665893555, -0.5342748165130615, -0.4538235664367676, -0.37337231636047363, -0.2929210662841797, -0.21246981620788574, -0.1320185661315918, -0.05156731605529785, 0.028883934020996094, 0.10933518409729004, 0.18978643417358398, 0.27023768424987793, 0.3506889343261719, 0.4311401844024658, 0.5115914344787598, 0.5920429229736328, 0.6724941730499268, 0.7529454231262207, 0.8333964347839355, 0.9138479232788086, 0.9942989349365234, 1.0747504234313965, 1.1552014350891113, 1.2356529235839844, 1.3161039352416992, 1.3965554237365723, 1.477006435394287, 1.5574579238891602, 1.637908935546875, 1.718360424041748, 1.798811435699463, 1.879262924194336]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.8164258003234863, -2.7132568359375, -2.6100881099700928, -2.5069193840026855, -2.403750419616699, -2.300581455230713, -2.1974127292633057, -2.0942440032958984, -1.991075038909912, -1.8879061937332153, -1.7847373485565186, -1.6815685033798218, -1.578399658203125, -1.4752308130264282, -1.3720619678497314, -1.2688931226730347, -1.165724277496338, -1.0625554323196411, -0.9593865871429443, -0.8562177419662476, -0.7530488967895508, -0.6498799324035645, -0.5467112064361572, -0.44354248046875, -0.34037351608276367, -0.23720455169677734, -0.13403582572937012, -0.03086709976196289, 0.07230186462402344, 0.17547082901000977, 0.278639554977417, 0.3818082809448242, 0.48497724533081055, 0.5881462097167969, 0.6913149356842041, 0.7944836616516113, 0.8976526260375977, 1.000821590423584, 1.1039903163909912, 1.2071590423583984, 1.3103280067443848, 1.413496971130371, 1.5166659355163574, 1.6198344230651855, 1.7230033874511719, 1.8261723518371582, 1.9293408393859863, 2.0325098037719727, 2.135678768157959, 2.2388477325439453, 2.3420166969299316, 2.4451851844787598, 2.548354148864746, 2.6515231132507324, 2.7546916007995605, 2.857860565185547, 2.961029529571533, 3.0641984939575195, 3.167367458343506, 3.270535945892334, 3.3737049102783203, 3.4768738746643066, 3.5800423622131348, 3.683211326599121, 3.7863802909851074]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 5.0, 1.0, 4.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-2.7712159156799316, -2.6733531951904297, -2.5754904747009277, -2.477627754211426, -2.379765033721924, -2.2819020748138428, -2.184039354324341, -2.086176633834839, -1.988313913345337, -1.890451192855835, -1.792588472366333, -1.6947256326675415, -1.5968629121780396, -1.4990001916885376, -1.401137351989746, -1.3032746315002441, -1.2054119110107422, -1.1075491905212402, -1.0096864700317383, -0.9118236303329468, -0.8139609098434448, -0.7160980701446533, -0.6182353496551514, -0.5203726291656494, -0.42250990867614746, -0.3246471881866455, -0.22678446769714355, -0.1289217472076416, -0.031058788299560547, 0.0668039321899414, 0.16466665267944336, 0.2625293731689453, 0.36039209365844727, 0.4582548141479492, 0.5561175346374512, 0.6539802551269531, 0.7518429756164551, 0.8497059345245361, 0.9475686550140381, 1.04543137550354, 1.143294095993042, 1.241157054901123, 1.339019775390625, 1.436882495880127, 1.534745216369629, 1.6326079368591309, 1.7304706573486328, 1.8283333778381348, 1.9261960983276367, 2.0240588188171387, 2.1219215393066406, 2.2197842597961426, 2.3176469802856445, 2.4155097007751465, 2.5133724212646484, 2.6112351417541504, 2.7090983390808105, 2.8069610595703125, 2.9048237800598145, 3.0026865005493164, 3.1005492210388184, 3.1984119415283203, 3.2962746620178223, 3.394137382507324, 3.492000102996826]}, "_runtime": 6084.617686748505, "_timestamp": 1585576000.46232, "_step": 498}
{"Episode reward": 32.74844330634838, "Episode length": 700, "Policy Loss": 0.3231358826160431, "Value Loss": 12.64700984954834, "_runtime": 6084.617686748505, "_timestamp": 1585576000.46232, "_step": 499}
