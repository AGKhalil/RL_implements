{"Episode reward": -51.66829255625446, "Episode length": 999, "Policy Loss": -0.026527510955929756, "Value Loss": 0.006194286048412323, "_runtime": 14062.95942568779, "_timestamp": 1585611432.5922952, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6670786738395691, "Value Loss": 29.74530029296875, "_runtime": 14064.483110189438, "_timestamp": 1585611434.1159797, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.754160761833191, "Value Loss": 163.65789794921875, "_runtime": 14066.084860086441, "_timestamp": 1585611435.7177296, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9325225353240967, "Value Loss": 610.6163940429688, "_runtime": 14067.664592266083, "_timestamp": 1585611437.2974617, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6613953113555908, "Value Loss": 36.075984954833984, "_runtime": 14069.214900016785, "_timestamp": 1585611438.8477695, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8850905299186707, "Value Loss": 35.44004440307617, "_runtime": 14070.822526454926, "_timestamp": 1585611440.455396, "_step": 5}
{"Episode reward": -97.30561183987267, "Episode length": 999, "Policy Loss": -1.7111070156097412, "Value Loss": 292.3163146972656, "_runtime": 14072.410475730896, "_timestamp": 1585611442.0433452, "_step": 6}
{"Episode reward": -67.55414767676183, "Episode length": 999, "Policy Loss": -4.699127197265625, "Value Loss": 81.24798583984375, "_runtime": 14072.899307250977, "_timestamp": 1585611442.5321767, "_step": 7}
{"Episode reward": 81.40641078702247, "Episode length": 294, "Policy Loss": 10.03859806060791, "Value Loss": 290.0954895019531, "_runtime": 14073.296487808228, "_timestamp": 1585611442.9293573, "_step": 8}
{"Episode reward": 85.42558456913625, "Episode length": 222, "Policy Loss": 0.6392409801483154, "Value Loss": 50.99126052856445, "_runtime": 14073.662768125534, "_timestamp": 1585611443.2956376, "_step": 9}
{"Episode reward": 86.99632450948545, "Episode length": 203, "Policy Loss": -1.9390223026275635, "Value Loss": 85.7650375366211, "_runtime": 14074.02265715599, "_timestamp": 1585611443.6555266, "_step": 10}
{"Episode reward": 83.04696545805723, "Episode length": 228, "Policy Loss": -0.7033729553222656, "Value Loss": 78.12922668457031, "_runtime": 14074.421325683594, "_timestamp": 1585611444.0541952, "_step": 11}
{"Episode reward": 85.05505800421822, "Episode length": 261, "Policy Loss": -2.006648063659668, "Value Loss": 68.80403137207031, "_runtime": 14074.849174499512, "_timestamp": 1585611444.482044, "_step": 12}
{"Episode reward": 85.01980129965736, "Episode length": 282, "Policy Loss": 0.6549550294876099, "Value Loss": 36.37495422363281, "_runtime": 14075.385070800781, "_timestamp": 1585611445.0179403, "_step": 13}
{"Episode reward": 85.35618655072213, "Episode length": 353, "Policy Loss": 2.4541661739349365, "Value Loss": 44.004703521728516, "_runtime": 14076.963369131088, "_timestamp": 1585611446.5962386, "_step": 14}
{"Episode reward": -38.66080108380228, "Episode length": 999, "Policy Loss": 0.3821888864040375, "Value Loss": 18.669754028320312, "_runtime": 14078.490745544434, "_timestamp": 1585611448.123615, "_step": 15}
{"Episode reward": -48.37447132976149, "Episode length": 999, "Policy Loss": 0.08979818224906921, "Value Loss": 1.3223466873168945, "_runtime": 14080.04473233223, "_timestamp": 1585611449.6776018, "_step": 16}
{"Episode reward": -57.02584440394018, "Episode length": 999, "Policy Loss": 0.0750725269317627, "Value Loss": 0.4974049925804138, "_runtime": 14081.62974858284, "_timestamp": 1585611451.262618, "_step": 17}
{"Episode reward": -60.75160255696437, "Episode length": 999, "Policy Loss": -0.05023869499564171, "Value Loss": 1.1258596181869507, "_runtime": 14083.208549261093, "_timestamp": 1585611452.8414187, "_step": 18}
{"Episode reward": -66.06637704490026, "Episode length": 999, "Policy Loss": 0.028093133121728897, "Value Loss": 0.1862296164035797, "_runtime": 14084.798248291016, "_timestamp": 1585611454.4311178, "_step": 19}
{"Episode reward": -68.54119532524639, "Episode length": 999, "Policy Loss": 0.024982014670968056, "Value Loss": 0.21816743910312653, "_runtime": 14086.398759365082, "_timestamp": 1585611456.0316288, "_step": 20}
{"Episode reward": -73.41091912207906, "Episode length": 999, "Policy Loss": -0.026032032445073128, "Value Loss": 0.20511433482170105, "_runtime": 14087.989924192429, "_timestamp": 1585611457.6227937, "_step": 21}
{"Episode reward": -75.72462610549083, "Episode length": 999, "Policy Loss": -0.07656742632389069, "Value Loss": 0.12231814861297607, "_runtime": 14089.595538139343, "_timestamp": 1585611459.2284076, "_step": 22}
{"Episode reward": -76.21409242328079, "Episode length": 999, "Policy Loss": -0.10805681347846985, "Value Loss": 0.10661624372005463, "_runtime": 14091.197777032852, "_timestamp": 1585611460.8306465, "_step": 23}
{"Episode reward": -79.74286067346193, "Episode length": 999, "Policy Loss": -0.11502973735332489, "Value Loss": 0.04561229795217514, "_runtime": 14092.808367013931, "_timestamp": 1585611462.4412365, "_step": 24}
{"Episode reward": -80.42060988104215, "Episode length": 999, "Policy Loss": -0.13903704285621643, "Value Loss": 0.01655285432934761, "_runtime": 14094.422594308853, "_timestamp": 1585611464.0554638, "_step": 25}
{"Episode reward": -83.26845758177359, "Episode length": 999, "Policy Loss": -0.15986424684524536, "Value Loss": 0.007280723657459021, "_runtime": 14096.026115179062, "_timestamp": 1585611465.6589847, "_step": 26}
{"Episode reward": -81.55775797364808, "Episode length": 999, "Policy Loss": -0.1758275032043457, "Value Loss": 0.008698529563844204, "_runtime": 14097.628228902817, "_timestamp": 1585611467.2610984, "_step": 27}
{"Episode reward": -82.82497989823962, "Episode length": 999, "Policy Loss": -0.196608766913414, "Value Loss": 0.020812079310417175, "_runtime": 14099.22052025795, "_timestamp": 1585611468.8533897, "_step": 28}
{"Episode reward": -83.28040194713526, "Episode length": 999, "Policy Loss": -0.21419832110404968, "Value Loss": 0.050847359001636505, "_runtime": 14100.8668217659, "_timestamp": 1585611470.4996912, "_step": 29}
{"Episode reward": -85.00990357493333, "Episode length": 999, "Policy Loss": -0.23683598637580872, "Value Loss": 0.047066666185855865, "_runtime": 14102.471197128296, "_timestamp": 1585611472.1040666, "_step": 30}
{"Episode reward": -86.20437237687486, "Episode length": 999, "Policy Loss": -0.1887982338666916, "Value Loss": 0.1657039076089859, "_runtime": 14104.066394329071, "_timestamp": 1585611473.6992638, "_step": 31}
{"Episode reward": -84.60740508043368, "Episode length": 999, "Policy Loss": -0.17803126573562622, "Value Loss": 0.2316863089799881, "_runtime": 14105.672520399094, "_timestamp": 1585611475.30539, "_step": 32}
{"Episode reward": -86.73667829954543, "Episode length": 999, "Policy Loss": -0.23272179067134857, "Value Loss": 0.19224226474761963, "_runtime": 14107.273032426834, "_timestamp": 1585611476.905902, "_step": 33}
{"Episode reward": -87.22031802957063, "Episode length": 999, "Policy Loss": -0.23649191856384277, "Value Loss": 0.22982889413833618, "_runtime": 14108.88225364685, "_timestamp": 1585611478.5151231, "_step": 34}
{"Episode reward": -85.29896918780125, "Episode length": 999, "Policy Loss": -0.25678130984306335, "Value Loss": 0.2921242117881775, "_runtime": 14110.486510515213, "_timestamp": 1585611480.11938, "_step": 35}
{"Episode reward": -86.3131403174319, "Episode length": 999, "Policy Loss": -0.2469521164894104, "Value Loss": 0.23490135371685028, "_runtime": 14112.090663671494, "_timestamp": 1585611481.7235332, "_step": 36}
{"Episode reward": -84.71874207914945, "Episode length": 999, "Policy Loss": -0.14251482486724854, "Value Loss": 0.524508535861969, "_runtime": 14113.69778585434, "_timestamp": 1585611483.3306553, "_step": 37}
{"Episode reward": -87.70903796797629, "Episode length": 999, "Policy Loss": -0.2749825119972229, "Value Loss": 0.1643325239419937, "_runtime": 14115.29982972145, "_timestamp": 1585611484.9326992, "_step": 38}
{"Episode reward": -87.43517350544948, "Episode length": 999, "Policy Loss": -0.24133002758026123, "Value Loss": 0.19525715708732605, "_runtime": 14116.905282974243, "_timestamp": 1585611486.5381525, "_step": 39}
{"Episode reward": -86.55301858332066, "Episode length": 999, "Policy Loss": -0.2662244141101837, "Value Loss": 0.21953435242176056, "_runtime": 14118.523297548294, "_timestamp": 1585611488.156167, "_step": 40}
{"Episode reward": -87.27824464046499, "Episode length": 999, "Policy Loss": -0.18497152626514435, "Value Loss": 0.27574142813682556, "_runtime": 14120.14139175415, "_timestamp": 1585611489.7742612, "_step": 41}
{"Episode reward": -87.52364131842783, "Episode length": 999, "Policy Loss": -0.2050168514251709, "Value Loss": 0.19387832283973694, "_runtime": 14121.755955696106, "_timestamp": 1585611491.3888252, "_step": 42}
{"Episode reward": -85.27700742288651, "Episode length": 999, "Policy Loss": -0.04473768547177315, "Value Loss": 0.41003352403640747, "_runtime": 14123.372308015823, "_timestamp": 1585611493.0051775, "_step": 43}
{"Episode reward": -87.73055393582597, "Episode length": 999, "Policy Loss": -0.1940438151359558, "Value Loss": 0.1448066383600235, "_runtime": 14125.013887166977, "_timestamp": 1585611494.6467566, "_step": 44}
{"Episode reward": -89.62812688081407, "Episode length": 999, "Policy Loss": -0.26698604226112366, "Value Loss": 0.04242075979709625, "_runtime": 14126.620873451233, "_timestamp": 1585611496.253743, "_step": 45}
{"Episode reward": -85.7187813450091, "Episode length": 999, "Policy Loss": -0.05708622559905052, "Value Loss": 0.1963934749364853, "_runtime": 14128.219273328781, "_timestamp": 1585611497.8521428, "_step": 46}
{"Episode reward": -87.45640911107475, "Episode length": 999, "Policy Loss": -0.1450987458229065, "Value Loss": 0.09463097900152206, "_runtime": 14129.835587978363, "_timestamp": 1585611499.4684575, "_step": 47}
{"Episode reward": -85.66527687729614, "Episode length": 999, "Policy Loss": -0.15243060886859894, "Value Loss": 0.030628608539700508, "_runtime": 14131.452745437622, "_timestamp": 1585611501.085615, "_step": 48}
{"Episode reward": -87.0805169249497, "Episode length": 999, "Policy Loss": -0.1269253045320511, "Value Loss": 0.05555042624473572, "_runtime": 14133.06145811081, "_timestamp": 1585611502.6943276, "_step": 49}
{"Episode reward": -85.76345701693083, "Episode length": 999, "Policy Loss": -0.1525643765926361, "Value Loss": 0.015122518874704838, "_runtime": 14134.666132688522, "_timestamp": 1585611504.2990022, "_step": 50}
{"Episode reward": -85.12402520863041, "Episode length": 999, "Policy Loss": -0.06262986361980438, "Value Loss": 0.04052234813570976, "_runtime": 14136.28093123436, "_timestamp": 1585611505.9138007, "_step": 51}
{"Episode reward": -88.86613797663797, "Episode length": 999, "Policy Loss": -0.14114201068878174, "Value Loss": 0.009751230478286743, "_runtime": 14137.898975849152, "_timestamp": 1585611507.5318453, "_step": 52}
{"Episode reward": -89.6818018010218, "Episode length": 999, "Policy Loss": -0.10972518473863602, "Value Loss": 0.008398100733757019, "_runtime": 14139.513717651367, "_timestamp": 1585611509.1465871, "_step": 53}
{"Episode reward": -89.59833859322701, "Episode length": 999, "Policy Loss": -0.10924213379621506, "Value Loss": 0.005242872517555952, "_runtime": 14141.116173505783, "_timestamp": 1585611510.749043, "_step": 54}
{"Episode reward": -89.1425799349286, "Episode length": 999, "Policy Loss": -0.08755231648683548, "Value Loss": 0.005250195041298866, "_runtime": 14142.724261045456, "_timestamp": 1585611512.3571305, "_step": 55}
{"Episode reward": -87.71144865414732, "Episode length": 999, "Policy Loss": -0.0727742537856102, "Value Loss": 0.002183611737564206, "_runtime": 14144.33926320076, "_timestamp": 1585611513.9721327, "_step": 56}
{"Episode reward": -87.32520796578203, "Episode length": 999, "Policy Loss": -0.059803009033203125, "Value Loss": 0.001848332118242979, "_runtime": 14145.943157434464, "_timestamp": 1585611515.576027, "_step": 57}
{"Episode reward": -88.72852273324935, "Episode length": 999, "Policy Loss": -0.05661671608686447, "Value Loss": 0.0012677563354372978, "_runtime": 14147.549860477448, "_timestamp": 1585611517.18273, "_step": 58}
{"Episode reward": -87.85327968945802, "Episode length": 999, "Policy Loss": -0.047503408044576645, "Value Loss": 0.0011874765623360872, "_runtime": 14149.192273378372, "_timestamp": 1585611518.8251429, "_step": 59}
{"Episode reward": -86.88135218922704, "Episode length": 999, "Policy Loss": -0.03615821152925491, "Value Loss": 0.0014129006303846836, "_runtime": 14150.804762601852, "_timestamp": 1585611520.437632, "_step": 60}
{"Episode reward": -89.72473539374127, "Episode length": 999, "Policy Loss": -0.04141869768500328, "Value Loss": 0.0015541169559583068, "_runtime": 14152.423961162567, "_timestamp": 1585611522.0568306, "_step": 61}
{"Episode reward": -88.86166455864051, "Episode length": 999, "Policy Loss": -0.03248390927910805, "Value Loss": 0.0020278701558709145, "_runtime": 14154.030656337738, "_timestamp": 1585611523.6635258, "_step": 62}
{"Episode reward": -89.38791868322457, "Episode length": 999, "Policy Loss": -0.02770378440618515, "Value Loss": 0.0019020600011572242, "_runtime": 14155.64553642273, "_timestamp": 1585611525.278406, "_step": 63}
{"Episode reward": -89.98893784788959, "Episode length": 999, "Policy Loss": -0.015843424946069717, "Value Loss": 0.0013305238680914044, "_runtime": 14157.261857032776, "_timestamp": 1585611526.8947265, "_step": 64}
{"Episode reward": -87.01410673006356, "Episode length": 999, "Policy Loss": 0.0036140901502221823, "Value Loss": 0.002460787771269679, "_runtime": 14158.87753868103, "_timestamp": 1585611528.5104082, "_step": 65}
{"Episode reward": -86.88193588068155, "Episode length": 999, "Policy Loss": -0.0039849355816841125, "Value Loss": 0.0024126616772264242, "_runtime": 14160.47915482521, "_timestamp": 1585611530.1120243, "_step": 66}
{"Episode reward": -86.86577992912724, "Episode length": 999, "Policy Loss": -0.00715777138248086, "Value Loss": 0.00495786452665925, "_runtime": 14162.0743663311, "_timestamp": 1585611531.7072358, "_step": 67}
{"Episode reward": -87.98597947346853, "Episode length": 999, "Policy Loss": 0.0041002449579536915, "Value Loss": 0.005172427278012037, "_runtime": 14163.681792736053, "_timestamp": 1585611533.3146622, "_step": 68}
{"Episode reward": -89.97081372520827, "Episode length": 999, "Policy Loss": 8.893190170056187e-06, "Value Loss": 0.004034303594380617, "_runtime": 14165.274983644485, "_timestamp": 1585611534.9078531, "_step": 69}
{"Episode reward": -89.25802953830487, "Episode length": 999, "Policy Loss": 0.009888887405395508, "Value Loss": 0.005138208623975515, "_runtime": 14166.882864952087, "_timestamp": 1585611536.5157344, "_step": 70}
{"Episode reward": -85.86506807496815, "Episode length": 999, "Policy Loss": 0.012546737678349018, "Value Loss": 0.008872510865330696, "_runtime": 14168.476997375488, "_timestamp": 1585611538.1098669, "_step": 71}
{"Episode reward": -89.08165220875793, "Episode length": 999, "Policy Loss": 0.01572997123003006, "Value Loss": 0.003297173185274005, "_runtime": 14170.07744550705, "_timestamp": 1585611539.710315, "_step": 72}
{"Episode reward": -89.94578010438099, "Episode length": 999, "Policy Loss": 0.012796570546925068, "Value Loss": 0.003075306536629796, "_runtime": 14171.684559822083, "_timestamp": 1585611541.3174293, "_step": 73}
{"Episode reward": -88.58746750832756, "Episode length": 999, "Policy Loss": 0.015936484560370445, "Value Loss": 0.0031209983862936497, "_runtime": 14173.310494184494, "_timestamp": 1585611542.9433637, "_step": 74}
{"Episode reward": -85.7020332893855, "Episode length": 999, "Policy Loss": 0.015748094767332077, "Value Loss": 0.003829549066722393, "_runtime": 14174.906162261963, "_timestamp": 1585611544.5390317, "_step": 75}
{"Episode reward": -87.98744100545949, "Episode length": 999, "Policy Loss": 0.004955357406288385, "Value Loss": 0.004430111963301897, "_runtime": 14176.514492750168, "_timestamp": 1585611546.1473622, "_step": 76}
{"Episode reward": -86.76361316263419, "Episode length": 999, "Policy Loss": 0.015363166108727455, "Value Loss": 0.009942473843693733, "_runtime": 14178.11258649826, "_timestamp": 1585611547.745456, "_step": 77}
{"Episode reward": -89.67890855486338, "Episode length": 999, "Policy Loss": 0.012073122896254063, "Value Loss": 0.0049911560490727425, "_runtime": 14179.709704875946, "_timestamp": 1585611549.3425744, "_step": 78}
{"Episode reward": -86.95621384719878, "Episode length": 999, "Policy Loss": -0.008828770369291306, "Value Loss": 0.008166762068867683, "_runtime": 14181.323519706726, "_timestamp": 1585611550.9563892, "_step": 79}
{"Episode reward": -88.57064387027899, "Episode length": 999, "Policy Loss": 0.02063864842057228, "Value Loss": 0.002205698983743787, "_runtime": 14182.932681560516, "_timestamp": 1585611552.565551, "_step": 80}
{"Episode reward": -89.4915541764596, "Episode length": 999, "Policy Loss": 0.0083664171397686, "Value Loss": 0.005145746283233166, "_runtime": 14184.528414964676, "_timestamp": 1585611554.1612844, "_step": 81}
{"Episode reward": -90.57380342304522, "Episode length": 999, "Policy Loss": 0.006437562871724367, "Value Loss": 0.002847119700163603, "_runtime": 14186.124659538269, "_timestamp": 1585611555.757529, "_step": 82}
{"Episode reward": -87.96152697005452, "Episode length": 999, "Policy Loss": 0.020420154556632042, "Value Loss": 0.002462162170559168, "_runtime": 14187.720132827759, "_timestamp": 1585611557.3530023, "_step": 83}
{"Episode reward": -89.73550245481822, "Episode length": 999, "Policy Loss": 0.013948937878012657, "Value Loss": 0.0024921554140746593, "_runtime": 14189.326543331146, "_timestamp": 1585611558.9594128, "_step": 84}
{"Episode reward": -89.01613527305238, "Episode length": 999, "Policy Loss": 0.005680788308382034, "Value Loss": 0.0039563230238854885, "_runtime": 14190.92551612854, "_timestamp": 1585611560.5583856, "_step": 85}
{"Episode reward": -89.18452382395022, "Episode length": 999, "Policy Loss": 0.009179549291729927, "Value Loss": 0.0018642249051481485, "_runtime": 14192.523393154144, "_timestamp": 1585611562.1562626, "_step": 86}
{"Episode reward": -88.87773479701957, "Episode length": 999, "Policy Loss": 0.003239966928958893, "Value Loss": 0.0045690578408539295, "_runtime": 14194.126347064972, "_timestamp": 1585611563.7592165, "_step": 87}
{"Episode reward": -88.41730361904266, "Episode length": 999, "Policy Loss": -0.0030927234329283237, "Value Loss": 0.005301353055983782, "_runtime": 14195.760615825653, "_timestamp": 1585611565.3934853, "_step": 88}
{"Episode reward": -87.79569254933952, "Episode length": 999, "Policy Loss": -0.006023859605193138, "Value Loss": 0.003924782853573561, "_runtime": 14197.35757279396, "_timestamp": 1585611566.9904423, "_step": 89}
{"Episode reward": -91.25805833769968, "Episode length": 999, "Policy Loss": 0.00021102564642205834, "Value Loss": 0.0011370436986908317, "_runtime": 14198.963653564453, "_timestamp": 1585611568.596523, "_step": 90}
{"Episode reward": -89.76183710331333, "Episode length": 999, "Policy Loss": -0.00763135077431798, "Value Loss": 0.0025491181295365095, "_runtime": 14200.570852041245, "_timestamp": 1585611570.2037215, "_step": 91}
{"Episode reward": -88.11208093018266, "Episode length": 999, "Policy Loss": 0.005013883113861084, "Value Loss": 0.001780778868123889, "_runtime": 14202.180068969727, "_timestamp": 1585611571.8129385, "_step": 92}
{"Episode reward": -89.50951356551755, "Episode length": 999, "Policy Loss": -0.0059608533047139645, "Value Loss": 0.0013420117320492864, "_runtime": 14203.772887706757, "_timestamp": 1585611573.4057572, "_step": 93}
{"Episode reward": -89.40096712957634, "Episode length": 999, "Policy Loss": -0.004142620135098696, "Value Loss": 0.0012816664529964328, "_runtime": 14205.371515989304, "_timestamp": 1585611575.0043855, "_step": 94}
{"Episode reward": -86.93896068628621, "Episode length": 999, "Policy Loss": 0.003276058007031679, "Value Loss": 0.0016302462900057435, "_runtime": 14206.95789527893, "_timestamp": 1585611576.5907648, "_step": 95}
{"Episode reward": -90.55284254424228, "Episode length": 999, "Policy Loss": -0.010220672935247421, "Value Loss": 0.0008536145323887467, "_runtime": 14208.565440177917, "_timestamp": 1585611578.1983097, "_step": 96}
{"Episode reward": -89.62912567404132, "Episode length": 999, "Policy Loss": -0.012084919959306717, "Value Loss": 0.0009196491446346045, "_runtime": 14210.164724588394, "_timestamp": 1585611579.797594, "_step": 97}
{"Episode reward": -89.32420309643824, "Episode length": 999, "Policy Loss": -0.01186553668230772, "Value Loss": 0.0009498490835539997, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724, 0.44140034914016724]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3378242254257202, -0.33090758323669434, -0.32399091124534607, -0.3170742690563202, -0.3101575970649719, -0.30324095487594604, -0.29632431268692017, -0.2894076406955719, -0.282490998506546, -0.27557432651519775, -0.2686576843261719, -0.261741042137146, -0.25482437014579773, -0.24790772795677185, -0.24099105596542358, -0.2340744137763977, -0.22715775668621063, -0.22024109959602356, -0.21332445740699768, -0.2064078003168106, -0.19949114322662354, -0.19257448613643646, -0.1856578290462494, -0.17874117195606232, -0.17182451486587524, -0.16490787267684937, -0.1579912155866623, -0.15107455849647522, -0.14415790140628815, -0.13724124431610107, -0.1303246021270752, -0.12340794503688812, -0.11649128794670105, -0.10957463085651398, -0.1026579737663269, -0.09574133157730103, -0.08882467448711395, -0.08190801739692688, -0.074991375207901, -0.06807470321655273, -0.061158061027526855, -0.05424138903617859, -0.04732474684715271, -0.04040810465812683, -0.033491432666778564, -0.026574790477752686, -0.01965811848640442, -0.01274147629737854, -0.0058248043060302734, 0.0010918378829956055, 0.008008480072021484, 0.014925152063369751, 0.02184179425239563, 0.028758466243743896, 0.035675108432769775, 0.042591750621795654, 0.04950842261314392, 0.0564250648021698, 0.06334173679351807, 0.07025837898254395, 0.07717502117156982, 0.08409169316291809, 0.09100833535194397, 0.09792500734329224, 0.10484164953231812]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09740094095468521, -0.09348538517951965, -0.08956983685493469, -0.08565428107976913, -0.08173872530460358, -0.07782317698001862, -0.07390762120485306, -0.0699920654296875, -0.06607651710510254, -0.06216096132993698, -0.05824540555477142, -0.054329853504896164, -0.050414301455020905, -0.04649874567985535, -0.04258319362998009, -0.03866763785481453, -0.03475208580493927, -0.030836530029773712, -0.02692098170518875, -0.023005425930023193, -0.019089870154857635, -0.015174321830272675, -0.011258766055107117, -0.007343210279941559, -0.003427661955356598, 0.00048789381980895996, 0.004403449594974518, 0.008319005370140076, 0.012234553694725037, 0.016150109469890594, 0.020065665245056152, 0.023981213569641113, 0.02789676934480667, 0.03181231766939163, 0.03572788089513779, 0.03964342921972275, 0.04355897754430771, 0.047474540770053864, 0.051390089094638824, 0.055305637419223785, 0.05922120064496994, 0.0631367489695549, 0.06705229729413986, 0.07096786051988602, 0.07488340884447098, 0.07879895716905594, 0.0827145203948021, 0.08663006871938705, 0.09054561704397202, 0.09446118026971817, 0.09837672859430313, 0.10229229182004929, 0.10620784014463425, 0.11012338846921921, 0.11403895169496536, 0.11795450001955032, 0.12187004834413528, 0.12578561902046204, 0.129701167345047, 0.13361671566963196, 0.13753226399421692, 0.14144781231880188, 0.14536336064338684, 0.1492789387702942, 0.15319448709487915]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 4.0, 1.0, 4.0, 3.0, 6.0, 4.0, 3.0, 13.0, 16.0, 18.0, 25.0, 28.0, 57.0, 86.0, 74.0, 35.0, 26.0, 18.0, 12.0, 13.0, 13.0, 9.0, 5.0, 8.0, 3.0, 3.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09507183730602264, -0.09153073281049728, -0.08798962086439133, -0.08444851636886597, -0.08090740442276001, -0.07736629992723465, -0.07382519543170929, -0.07028408348560333, -0.06674297899007797, -0.06320187449455261, -0.059660762548446655, -0.056119654327631, -0.05257854610681534, -0.04903743788599968, -0.04549633339047432, -0.04195522516965866, -0.038414116948843, -0.034873008728027344, -0.031331904232501984, -0.027790792286396027, -0.024249687790870667, -0.02070857584476471, -0.01716747134923935, -0.01362636685371399, -0.010085254907608032, -0.006544150412082672, -0.003003038465976715, 0.000538066029548645, 0.004079170525074005, 0.007620282471179962, 0.011161386966705322, 0.01470249891281128, 0.01824360340833664, 0.021784707903862, 0.025325819849967957, 0.028866924345493317, 0.03240802884101868, 0.035949140787124634, 0.03949025273323059, 0.043031349778175354, 0.04657246172428131, 0.05011357367038727, 0.053654685616493225, 0.05719578266143799, 0.060736894607543945, 0.0642780065536499, 0.06781910359859467, 0.07136021554470062, 0.07490132749080658, 0.07844242453575134, 0.0819835364818573, 0.08552464842796326, 0.08906576037406921, 0.09260685741901398, 0.09614796936511993, 0.09968908131122589, 0.10323017835617065, 0.10677129030227661, 0.11031240224838257, 0.11385349929332733, 0.11739461123943329, 0.12093572318553925, 0.1244768351316452, 0.12801793217658997, 0.13155904412269592]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3801688253879547, -0.36516669392585754, -0.35016459226608276, -0.3351624608039856, -0.3201603293418884, -0.30515822768211365, -0.2901560962200165, -0.2751539945602417, -0.26015186309814453, -0.24514974653720856, -0.23014762997627258, -0.21514549851417542, -0.20014338195323944, -0.18514126539230347, -0.1701391339302063, -0.15513701736927032, -0.14013490080833435, -0.12513276934623718, -0.1101306676864624, -0.09512853622436523, -0.08012643456459045, -0.06512430310249329, -0.05012217164039612, -0.03512006998062134, -0.02011793851852417, -0.005115807056427002, 0.009886294603347778, 0.024888426065444946, 0.039890557527542114, 0.054892659187316895, 0.06989479064941406, 0.08489689230918884, 0.09989902377128601, 0.11490115523338318, 0.12990328669548035, 0.14490535855293274, 0.1599074900150299, 0.17490962147712708, 0.18991175293922424, 0.2049138844013214, 0.2199159562587738, 0.23491808772087097, 0.24992021918296814, 0.2649223506450653, 0.2799244821071625, 0.29492661356925964, 0.30992868542671204, 0.3249308168888092, 0.33993294835090637, 0.35493507981300354, 0.3699372112751007, 0.3849392831325531, 0.39994141459465027, 0.41494354605674744, 0.4299456775188446, 0.4449478089809418, 0.45994994044303894, 0.47495201230049133, 0.4899541437625885, 0.5049562454223633, 0.5199583768844604, 0.5349605083465576, 0.5499626398086548, 0.564964771270752, 0.5799669027328491]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 1.0, 3.0, 2.0, 7.0, 3.0, 1.0, 1.0, 2.0, 4.0, 5.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07322445511817932, -0.06993360817432404, -0.06664276868104935, -0.06335192173719406, -0.06006108224391937, -0.05677023530006409, -0.0534793958067894, -0.05018854886293411, -0.046897709369659424, -0.04360686242580414, -0.04031601920723915, -0.037025175988674164, -0.03373433277010918, -0.03044348955154419, -0.027152646332979202, -0.023861803114414215, -0.020570959895849228, -0.01728011667728424, -0.013989273458719254, -0.010698430240154266, -0.007407583296298981, -0.004116743803024292, -0.0008258968591690063, 0.0024649426341056824, 0.005755789577960968, 0.009046629071235657, 0.012337476015090942, 0.01562831550836563, 0.018919162452220917, 0.022210001945495605, 0.02550084888935089, 0.02879168838262558, 0.032082535326480865, 0.03537338227033615, 0.03866422176361084, 0.041955068707466125, 0.045245908200740814, 0.0485367551445961, 0.05182759463787079, 0.055118441581726074, 0.05840928852558136, 0.06170012056827545, 0.06499096751213074, 0.06828181445598602, 0.07157266139984131, 0.0748634934425354, 0.07815434038639069, 0.08144518733024597, 0.08473603427410126, 0.08802688121795654, 0.09131771326065063, 0.09460856020450592, 0.0978994071483612, 0.10119025409221649, 0.10448108613491058, 0.10777193307876587, 0.11106278002262115, 0.11435362696647644, 0.11764445900917053, 0.12093530595302582, 0.1242261528968811, 0.1275169998407364, 0.13080783188343048, 0.13409867882728577, 0.13738952577114105]}, "_runtime": 14211.762765169144, "_timestamp": 1585611581.3956347, "_step": 98}
{"Episode reward": -89.51857968255364, "Episode length": 999, "Policy Loss": -0.012449250556528568, "Value Loss": 0.0008838616195134819, "_runtime": 14213.357731819153, "_timestamp": 1585611582.9906013, "_step": 99}
{"Episode reward": -89.37208185555664, "Episode length": 999, "Policy Loss": -0.014653407037258148, "Value Loss": 0.0012224207166582346, "_runtime": 14214.965701341629, "_timestamp": 1585611584.5985708, "_step": 100}
{"Episode reward": -88.02091252570544, "Episode length": 999, "Policy Loss": -0.012390593066811562, "Value Loss": 0.0011968312319368124, "_runtime": 14216.560214281082, "_timestamp": 1585611586.1930838, "_step": 101}
{"Episode reward": -87.9601687909834, "Episode length": 999, "Policy Loss": -0.009917454794049263, "Value Loss": 0.0010969192953780293, "_runtime": 14218.142611503601, "_timestamp": 1585611587.775481, "_step": 102}
{"Episode reward": -87.57548070047817, "Episode length": 999, "Policy Loss": -0.014460532926023006, "Value Loss": 0.001137498184107244, "_runtime": 14219.78433418274, "_timestamp": 1585611589.4172037, "_step": 103}
{"Episode reward": -89.17998957749273, "Episode length": 999, "Policy Loss": -0.017258157953619957, "Value Loss": 0.0009245112305507064, "_runtime": 14221.38046002388, "_timestamp": 1585611591.0133295, "_step": 104}
{"Episode reward": -90.5282315202856, "Episode length": 999, "Policy Loss": -0.0208954606205225, "Value Loss": 0.0008173281676135957, "_runtime": 14222.984501361847, "_timestamp": 1585611592.6173708, "_step": 105}
{"Episode reward": -89.4242522835846, "Episode length": 999, "Policy Loss": -0.018809355795383453, "Value Loss": 0.0008599623688496649, "_runtime": 14224.584958791733, "_timestamp": 1585611594.2178283, "_step": 106}
{"Episode reward": -90.36635225351318, "Episode length": 999, "Policy Loss": -0.02010010927915573, "Value Loss": 0.0008165256585925817, "_runtime": 14226.186264753342, "_timestamp": 1585611595.8191342, "_step": 107}
{"Episode reward": -89.21916564546702, "Episode length": 999, "Policy Loss": -0.01823251321911812, "Value Loss": 0.000827800075057894, "_runtime": 14227.793417930603, "_timestamp": 1585611597.4262874, "_step": 108}
{"Episode reward": -88.23670337210734, "Episode length": 999, "Policy Loss": -0.0167612973600626, "Value Loss": 0.0009000350837595761, "_runtime": 14229.377561092377, "_timestamp": 1585611599.0104306, "_step": 109}
{"Episode reward": -86.56996253027572, "Episode length": 999, "Policy Loss": -0.01503363624215126, "Value Loss": 0.0010170399909839034, "_runtime": 14230.982012748718, "_timestamp": 1585611600.6148822, "_step": 110}
{"Episode reward": -90.68552935317229, "Episode length": 999, "Policy Loss": -0.02291380800306797, "Value Loss": 0.0007153619080781937, "_runtime": 14232.586340427399, "_timestamp": 1585611602.21921, "_step": 111}
{"Episode reward": -89.22071935923755, "Episode length": 999, "Policy Loss": -0.018872881308197975, "Value Loss": 0.0007946529658511281, "_runtime": 14234.18232345581, "_timestamp": 1585611603.815193, "_step": 112}
{"Episode reward": -89.06629458311502, "Episode length": 999, "Policy Loss": -0.019067490473389626, "Value Loss": 0.0007932845619507134, "_runtime": 14235.78841996193, "_timestamp": 1585611605.4212894, "_step": 113}
{"Episode reward": -90.66738244818566, "Episode length": 999, "Policy Loss": -0.023229682818055153, "Value Loss": 0.0007045386591926217, "_runtime": 14237.391394376755, "_timestamp": 1585611607.0242639, "_step": 114}
{"Episode reward": -89.5282217826477, "Episode length": 999, "Policy Loss": -0.020692456513643265, "Value Loss": 0.0008011689642444253, "_runtime": 14238.98981833458, "_timestamp": 1585611608.6226878, "_step": 115}
{"Episode reward": -89.15890566649284, "Episode length": 999, "Policy Loss": -0.01770286075770855, "Value Loss": 0.000774673477280885, "_runtime": 14240.585426330566, "_timestamp": 1585611610.2182958, "_step": 116}
{"Episode reward": -88.84996281630114, "Episode length": 999, "Policy Loss": -0.017314808443188667, "Value Loss": 0.0007930498686619103, "_runtime": 14242.20165348053, "_timestamp": 1585611611.834523, "_step": 117}
{"Episode reward": -89.94902378926923, "Episode length": 999, "Policy Loss": -0.02039082534611225, "Value Loss": 0.0007410201942548156, "_runtime": 14243.844055175781, "_timestamp": 1585611613.4769247, "_step": 118}
{"Episode reward": -88.66768990981001, "Episode length": 999, "Policy Loss": -0.01621904782950878, "Value Loss": 0.0007995102787390351, "_runtime": 14245.448808908463, "_timestamp": 1585611615.0816784, "_step": 119}
{"Episode reward": -88.77767582245468, "Episode length": 999, "Policy Loss": -0.01651606336236, "Value Loss": 0.0007838845485821366, "_runtime": 14247.0645673275, "_timestamp": 1585611616.6974368, "_step": 120}
{"Episode reward": -90.10999155724971, "Episode length": 999, "Policy Loss": -0.019975004717707634, "Value Loss": 0.0007537488709203899, "_runtime": 14248.669392824173, "_timestamp": 1585611618.3022623, "_step": 121}
{"Episode reward": -86.17715087236587, "Episode length": 999, "Policy Loss": -0.01019695308059454, "Value Loss": 0.0009494621772319078, "_runtime": 14250.27923154831, "_timestamp": 1585611619.912101, "_step": 122}
{"Episode reward": -88.04390878306442, "Episode length": 999, "Policy Loss": -0.014533238485455513, "Value Loss": 0.0008151150541380048, "_runtime": 14251.890434980392, "_timestamp": 1585611621.5233045, "_step": 123}
{"Episode reward": -88.04232648442724, "Episode length": 999, "Policy Loss": -0.01285387109965086, "Value Loss": 0.0008412456954829395, "_runtime": 14253.510014772415, "_timestamp": 1585611623.1428843, "_step": 124}
{"Episode reward": -87.34578086375575, "Episode length": 999, "Policy Loss": -0.011936568655073643, "Value Loss": 0.0008477024966850877, "_runtime": 14255.10208272934, "_timestamp": 1585611624.7349522, "_step": 125}
{"Episode reward": -88.00875678360578, "Episode length": 999, "Policy Loss": -0.011694066226482391, "Value Loss": 0.0008310779230669141, "_runtime": 14256.718829631805, "_timestamp": 1585611626.351699, "_step": 126}
{"Episode reward": -87.63884969381152, "Episode length": 999, "Policy Loss": -0.0124476607888937, "Value Loss": 0.000860427157022059, "_runtime": 14258.322761535645, "_timestamp": 1585611627.955631, "_step": 127}
{"Episode reward": -89.37125268910194, "Episode length": 999, "Policy Loss": -0.01448645070195198, "Value Loss": 0.0007833173731341958, "_runtime": 14259.92925286293, "_timestamp": 1585611629.5621223, "_step": 128}
{"Episode reward": -88.34280065835647, "Episode length": 999, "Policy Loss": -0.009839372709393501, "Value Loss": 0.000820107408799231, "_runtime": 14261.53211069107, "_timestamp": 1585611631.1649802, "_step": 129}
{"Episode reward": -89.58420956763439, "Episode length": 999, "Policy Loss": -0.01746109314262867, "Value Loss": 0.0007654620567336679, "_runtime": 14263.136027097702, "_timestamp": 1585611632.7688966, "_step": 130}
{"Episode reward": -86.91375391468596, "Episode length": 999, "Policy Loss": -0.008297712542116642, "Value Loss": 0.000886275025550276, "_runtime": 14264.750703334808, "_timestamp": 1585611634.3835728, "_step": 131}
{"Episode reward": -89.6240291046368, "Episode length": 999, "Policy Loss": -0.013809607364237309, "Value Loss": 0.0007523963577114046, "_runtime": 14266.354056835175, "_timestamp": 1585611635.9869263, "_step": 132}
{"Episode reward": -90.99518583135203, "Episode length": 999, "Policy Loss": -0.016576522961258888, "Value Loss": 0.000674701645039022, "_runtime": 14267.998443603516, "_timestamp": 1585611637.631313, "_step": 133}
{"Episode reward": -88.40353364779322, "Episode length": 999, "Policy Loss": -0.008201912976801395, "Value Loss": 0.0008054161444306374, "_runtime": 14269.613982915878, "_timestamp": 1585611639.2468524, "_step": 134}
{"Episode reward": -88.47290820257663, "Episode length": 999, "Policy Loss": -0.009115931577980518, "Value Loss": 0.0007841283222660422, "_runtime": 14271.218687057495, "_timestamp": 1585611640.8515565, "_step": 135}
{"Episode reward": -88.37696997772929, "Episode length": 999, "Policy Loss": -0.010003362782299519, "Value Loss": 0.0007952728774398565, "_runtime": 14272.820893526077, "_timestamp": 1585611642.453763, "_step": 136}
{"Episode reward": -90.02623586264168, "Episode length": 999, "Policy Loss": -0.014234132133424282, "Value Loss": 0.0006942765903659165, "_runtime": 14274.414978265762, "_timestamp": 1585611644.0478477, "_step": 137}
{"Episode reward": -88.11223930693674, "Episode length": 999, "Policy Loss": -0.007644338067620993, "Value Loss": 0.0008263672352768481, "_runtime": 14276.010734796524, "_timestamp": 1585611645.6436043, "_step": 138}
{"Episode reward": -88.54002942035409, "Episode length": 999, "Policy Loss": -0.006397658493369818, "Value Loss": 0.0007915674359537661, "_runtime": 14277.605675935745, "_timestamp": 1585611647.2385454, "_step": 139}
{"Episode reward": -89.09936804826103, "Episode length": 999, "Policy Loss": -0.00843447633087635, "Value Loss": 0.0007701691356487572, "_runtime": 14279.210983276367, "_timestamp": 1585611648.8438528, "_step": 140}
{"Episode reward": -86.34918763934046, "Episode length": 999, "Policy Loss": -0.0013079510536044836, "Value Loss": 0.0009212963632307947, "_runtime": 14280.815248012543, "_timestamp": 1585611650.4481175, "_step": 141}
{"Episode reward": -88.71711031643693, "Episode length": 999, "Policy Loss": -0.007971656508743763, "Value Loss": 0.0007806412177160382, "_runtime": 14282.42291879654, "_timestamp": 1585611652.0557883, "_step": 142}
{"Episode reward": -89.3923232435496, "Episode length": 999, "Policy Loss": -0.008029245771467686, "Value Loss": 0.0007091649458743632, "_runtime": 14284.02838087082, "_timestamp": 1585611653.6612504, "_step": 143}
{"Episode reward": -88.99298429303103, "Episode length": 999, "Policy Loss": -0.00663005281239748, "Value Loss": 0.0007796842837706208, "_runtime": 14285.61910700798, "_timestamp": 1585611655.2519765, "_step": 144}
{"Episode reward": -88.41503846369332, "Episode length": 999, "Policy Loss": -0.00527715589851141, "Value Loss": 0.0007897606119513512, "_runtime": 14287.214344501495, "_timestamp": 1585611656.847214, "_step": 145}
{"Episode reward": -86.21386259682681, "Episode length": 999, "Policy Loss": -0.0001341501047136262, "Value Loss": 0.0008843353716656566, "_runtime": 14288.808117866516, "_timestamp": 1585611658.4409873, "_step": 146}
{"Episode reward": -89.8934041147902, "Episode length": 999, "Policy Loss": -0.008475125767290592, "Value Loss": 0.0007079542265273631, "_runtime": 14290.451307296753, "_timestamp": 1585611660.0841768, "_step": 147}
{"Episode reward": -87.54187218897326, "Episode length": 999, "Policy Loss": -0.0007320955628529191, "Value Loss": 0.000844052410684526, "_runtime": 14292.04496884346, "_timestamp": 1585611661.6778383, "_step": 148}
{"Episode reward": -87.85451450059345, "Episode length": 999, "Policy Loss": -0.006210679188370705, "Value Loss": 0.0008225208148360252, "_runtime": 14293.649876832962, "_timestamp": 1585611663.2827463, "_step": 149}
{"Episode reward": -88.03120727882303, "Episode length": 999, "Policy Loss": -0.0011769201373681426, "Value Loss": 0.0007828202797099948, "_runtime": 14295.252655029297, "_timestamp": 1585611664.8855245, "_step": 150}
{"Episode reward": -87.66577034330479, "Episode length": 999, "Policy Loss": -0.0016194350318983197, "Value Loss": 0.0008452028851024806, "_runtime": 14296.848582983017, "_timestamp": 1585611666.4814525, "_step": 151}
{"Episode reward": -87.78442368106104, "Episode length": 999, "Policy Loss": 6.827244214946404e-05, "Value Loss": 0.0008084989385679364, "_runtime": 14298.453625679016, "_timestamp": 1585611668.0864952, "_step": 152}
{"Episode reward": -86.97645163477364, "Episode length": 999, "Policy Loss": 0.0005489872419275343, "Value Loss": 0.0009010271169245243, "_runtime": 14300.04773592949, "_timestamp": 1585611669.6806054, "_step": 153}
{"Episode reward": -89.22110635230287, "Episode length": 999, "Policy Loss": -0.004664358217269182, "Value Loss": 0.0007378574809990823, "_runtime": 14301.643446207047, "_timestamp": 1585611671.2763157, "_step": 154}
{"Episode reward": -90.45133136152874, "Episode length": 999, "Policy Loss": -0.006244909018278122, "Value Loss": 0.0006569113465957344, "_runtime": 14303.232800006866, "_timestamp": 1585611672.8656695, "_step": 155}
{"Episode reward": -88.99944414544206, "Episode length": 999, "Policy Loss": -0.002653044182807207, "Value Loss": 0.0007638762472197413, "_runtime": 14304.826616764069, "_timestamp": 1585611674.4594862, "_step": 156}
{"Episode reward": -87.67266333075344, "Episode length": 999, "Policy Loss": -0.001644094125367701, "Value Loss": 0.0008536288514733315, "_runtime": 14306.42238354683, "_timestamp": 1585611676.055253, "_step": 157}
{"Episode reward": -89.68125290850196, "Episode length": 999, "Policy Loss": -0.005075679626315832, "Value Loss": 0.000673423521220684, "_runtime": 14308.02589225769, "_timestamp": 1585611677.6587617, "_step": 158}
{"Episode reward": -88.83317923493365, "Episode length": 999, "Policy Loss": -0.0024296657647937536, "Value Loss": 0.0007798254955559969, "_runtime": 14309.618372678757, "_timestamp": 1585611679.2512422, "_step": 159}
{"Episode reward": -91.16680111927081, "Episode length": 999, "Policy Loss": -0.00848925020545721, "Value Loss": 0.0006263730465434492, "_runtime": 14311.22259926796, "_timestamp": 1585611680.8554688, "_step": 160}
{"Episode reward": -90.87757306836902, "Episode length": 999, "Policy Loss": -0.00796135701239109, "Value Loss": 0.0006677851197309792, "_runtime": 14312.826118469238, "_timestamp": 1585611682.458988, "_step": 161}
{"Episode reward": -86.96059678084495, "Episode length": 999, "Policy Loss": 0.004268738906830549, "Value Loss": 0.0008882979163900018, "_runtime": 14314.455019950867, "_timestamp": 1585611684.0878894, "_step": 162}
{"Episode reward": -88.8239408834664, "Episode length": 999, "Policy Loss": -0.0012351383920758963, "Value Loss": 0.0007682412397116423, "_runtime": 14316.063983678818, "_timestamp": 1585611685.6968532, "_step": 163}
{"Episode reward": -86.9606508476177, "Episode length": 999, "Policy Loss": 0.002389294095337391, "Value Loss": 0.0008754436857998371, "_runtime": 14317.669261693954, "_timestamp": 1585611687.3021312, "_step": 164}
{"Episode reward": -87.9219559748262, "Episode length": 999, "Policy Loss": -6.382066203514114e-05, "Value Loss": 0.0008308221586048603, "_runtime": 14319.262601137161, "_timestamp": 1585611688.8954706, "_step": 165}
{"Episode reward": -88.71040368953176, "Episode length": 999, "Policy Loss": -0.0023153044749051332, "Value Loss": 0.000759306363761425, "_runtime": 14320.8676571846, "_timestamp": 1585611690.5005267, "_step": 166}
{"Episode reward": -89.26373689953478, "Episode length": 999, "Policy Loss": -0.002152209635823965, "Value Loss": 0.0007511512958444655, "_runtime": 14322.460389852524, "_timestamp": 1585611692.0932593, "_step": 167}
{"Episode reward": -89.39346238792398, "Episode length": 999, "Policy Loss": -0.002759569091722369, "Value Loss": 0.0007597581134177744, "_runtime": 14324.055187940598, "_timestamp": 1585611693.6880574, "_step": 168}
{"Episode reward": -88.21639655066106, "Episode length": 999, "Policy Loss": 0.003166437614709139, "Value Loss": 0.0007665795856155455, "_runtime": 14325.658239603043, "_timestamp": 1585611695.291109, "_step": 169}
{"Episode reward": -89.45335497514486, "Episode length": 999, "Policy Loss": -0.0027539576403796673, "Value Loss": 0.000713232671841979, "_runtime": 14327.264094114304, "_timestamp": 1585611696.8969636, "_step": 170}
{"Episode reward": -88.63634574718971, "Episode length": 999, "Policy Loss": -0.0010485034435987473, "Value Loss": 0.0007862041238695383, "_runtime": 14328.86570572853, "_timestamp": 1585611698.4985752, "_step": 171}
{"Episode reward": -91.19167626768316, "Episode length": 999, "Policy Loss": -0.007316294126212597, "Value Loss": 0.0006154929869808257, "_runtime": 14330.469723463058, "_timestamp": 1585611700.102593, "_step": 172}
{"Episode reward": -87.14054059616169, "Episode length": 999, "Policy Loss": 0.004560261033475399, "Value Loss": 0.000840274034999311, "_runtime": 14332.065308570862, "_timestamp": 1585611701.698178, "_step": 173}
{"Episode reward": -88.0750276364588, "Episode length": 999, "Policy Loss": 0.00048327891272492707, "Value Loss": 0.00080592226004228, "_runtime": 14333.670769453049, "_timestamp": 1585611703.303639, "_step": 174}
{"Episode reward": -89.2772663854625, "Episode length": 999, "Policy Loss": -0.0011457985965535045, "Value Loss": 0.0007036466267891228, "_runtime": 14335.276309490204, "_timestamp": 1585611704.909179, "_step": 175}
{"Episode reward": -90.56003088918912, "Episode length": 999, "Policy Loss": -0.004419504199177027, "Value Loss": 0.0006612042780034244, "_runtime": 14336.88045334816, "_timestamp": 1585611706.5133228, "_step": 176}
{"Episode reward": -86.88169503634533, "Episode length": 999, "Policy Loss": 0.005160150118172169, "Value Loss": 0.000867829192429781, "_runtime": 14338.51188325882, "_timestamp": 1585611708.1447527, "_step": 177}
{"Episode reward": -87.46736117280145, "Episode length": 999, "Policy Loss": 0.0006457407725974917, "Value Loss": 0.0008406384149566293, "_runtime": 14340.117628097534, "_timestamp": 1585611709.7504976, "_step": 178}
{"Episode reward": -87.90602300979162, "Episode length": 999, "Policy Loss": 0.001141431974247098, "Value Loss": 0.0008114711963571608, "_runtime": 14341.719999551773, "_timestamp": 1585611711.352869, "_step": 179}
{"Episode reward": -88.97659295914444, "Episode length": 999, "Policy Loss": -0.0007242710562422872, "Value Loss": 0.0007458356558345258, "_runtime": 14343.324437141418, "_timestamp": 1585611712.9573066, "_step": 180}
{"Episode reward": -87.29385586295889, "Episode length": 999, "Policy Loss": 0.001405996736139059, "Value Loss": 0.000887486501596868, "_runtime": 14344.927017450333, "_timestamp": 1585611714.559887, "_step": 181}
{"Episode reward": -88.13069433223761, "Episode length": 999, "Policy Loss": 0.002748776925727725, "Value Loss": 0.0007693241932429373, "_runtime": 14346.520463228226, "_timestamp": 1585611716.1533327, "_step": 182}
{"Episode reward": -88.58002671565903, "Episode length": 999, "Policy Loss": 0.0011820821091532707, "Value Loss": 0.0007896985043771565, "_runtime": 14348.106961250305, "_timestamp": 1585611717.7398307, "_step": 183}
{"Episode reward": -88.2392615129476, "Episode length": 999, "Policy Loss": 0.00262220180593431, "Value Loss": 0.0007895657909102738, "_runtime": 14349.712350130081, "_timestamp": 1585611719.3452196, "_step": 184}
{"Episode reward": -86.65544255519477, "Episode length": 999, "Policy Loss": 0.005362083204090595, "Value Loss": 0.0009092728141695261, "_runtime": 14351.310515880585, "_timestamp": 1585611720.9433854, "_step": 185}
{"Episode reward": -90.94091176117657, "Episode length": 999, "Policy Loss": -0.005917152855545282, "Value Loss": 0.0006379367550835013, "_runtime": 14352.913386583328, "_timestamp": 1585611722.546256, "_step": 186}
{"Episode reward": -86.89206111558113, "Episode length": 999, "Policy Loss": 0.00557683827355504, "Value Loss": 0.0008734168368391693, "_runtime": 14354.50805091858, "_timestamp": 1585611724.1409204, "_step": 187}
{"Episode reward": -89.33885068943422, "Episode length": 999, "Policy Loss": -0.0026980333495885134, "Value Loss": 0.0007303844904527068, "_runtime": 14356.102595329285, "_timestamp": 1585611725.7354648, "_step": 188}
{"Episode reward": -88.03168064913953, "Episode length": 999, "Policy Loss": 0.002646173583343625, "Value Loss": 0.0007895581657066941, "_runtime": 14357.696812152863, "_timestamp": 1585611727.3296816, "_step": 189}
{"Episode reward": -88.68204399846431, "Episode length": 999, "Policy Loss": -0.0024709487333893776, "Value Loss": 0.0007732135127298534, "_runtime": 14359.279689311981, "_timestamp": 1585611728.9125588, "_step": 190}
{"Episode reward": -89.12050880781057, "Episode length": 999, "Policy Loss": -0.0004562839458230883, "Value Loss": 0.000752430350985378, "_runtime": 14360.885672569275, "_timestamp": 1585611730.518542, "_step": 191}
{"Episode reward": -87.69376524234347, "Episode length": 999, "Policy Loss": 0.002192496554926038, "Value Loss": 0.0008342626970261335, "_runtime": 14362.523370981216, "_timestamp": 1585611732.1562405, "_step": 192}
{"Episode reward": -87.02755029882024, "Episode length": 999, "Policy Loss": 0.002443130826577544, "Value Loss": 0.0008906051516532898, "_runtime": 14364.136740207672, "_timestamp": 1585611733.7696097, "_step": 193}
{"Episode reward": -88.34648440140127, "Episode length": 999, "Policy Loss": 0.0005109119229018688, "Value Loss": 0.0008166256593540311, "_runtime": 14365.751809835434, "_timestamp": 1585611735.3846793, "_step": 194}
{"Episode reward": -88.76722892076216, "Episode length": 999, "Policy Loss": -0.0033801193349063396, "Value Loss": 0.0007706295582465827, "_runtime": 14367.364047765732, "_timestamp": 1585611736.9969172, "_step": 195}
{"Episode reward": -89.09584608327988, "Episode length": 999, "Policy Loss": -0.002378283767029643, "Value Loss": 0.000732697662897408, "_runtime": 14368.96730852127, "_timestamp": 1585611738.600178, "_step": 196}
{"Episode reward": -89.7919278573466, "Episode length": 999, "Policy Loss": -0.0033058698754757643, "Value Loss": 0.0007041424396447837, "_runtime": 14370.570638179779, "_timestamp": 1585611740.2035077, "_step": 197}
{"Episode reward": -89.39204518489244, "Episode length": 999, "Policy Loss": -0.0013619046658277512, "Value Loss": 0.0007220514817163348, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177, 0.5117379426956177]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.6756042838096619, -0.6287710070610046, -0.5819376707077026, -0.5351043939590454, -0.4882711172103882, -0.44143781065940857, -0.39460450410842896, -0.34777122735977173, -0.3009379208087921, -0.2541046142578125, -0.20727133750915527, -0.16043806076049805, -0.11360472440719604, -0.06677144765853882, -0.019938170909881592, 0.02689516544342041, 0.07372844219207764, 0.12056171894073486, 0.16739505529403687, 0.2142283320426941, 0.2610616087913513, 0.3078949451446533, 0.35472816228866577, 0.40156155824661255, 0.4483948349952698, 0.495228111743927, 0.5420613884925842, 0.5888946652412415, 0.6357279419898987, 0.6825613379478455, 0.7293946146965027, 0.7762278914451599, 0.8230611681938171, 0.8698944449424744, 0.9167277216911316, 0.9635609984397888, 1.0103943347930908, 1.057227611541748, 1.1040608882904053, 1.1508941650390625, 1.1977274417877197, 1.244560718536377, 1.2913942337036133, 1.3382272720336914, 1.3850605487823486, 1.431894063949585, 1.4787273406982422, 1.5255606174468994, 1.5723938941955566, 1.6192271709442139, 1.666060447692871, 1.7128937244415283, 1.7597270011901855, 1.8065602779388428, 1.8533935546875, 1.9002268314361572, 1.9470601081848145, 1.9938933849334717, 2.040726900100708, 2.0875601768493652, 2.1343934535980225, 2.1812267303466797, 2.228060007095337, 2.274893283843994, 2.3217265605926514]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.025410356000065804, -0.022211696952581406, -0.01901303604245186, -0.01581437699496746, -0.012615717016160488, -0.009417057037353516, -0.006218397989869118, -0.0030197370797395706, 0.00017892196774482727, 0.003377581015229225, 0.006576241925358772, 0.00977490283548832, 0.012973560020327568, 0.016172220930457115, 0.019370881840586662, 0.02256953902542591, 0.025768199935555458, 0.028966860845685005, 0.0321655198931694, 0.03536418080329895, 0.0385628417134285, 0.041761502623558044, 0.04496016353368759, 0.04815881699323654, 0.05135747790336609, 0.054556138813495636, 0.05775479972362518, 0.06095346063375473, 0.06415212154388428, 0.06735077500343323, 0.07054943591356277, 0.07374809682369232, 0.07694675773382187, 0.08014541864395142, 0.08334407955408096, 0.08654274046421051, 0.08974139392375946, 0.09294005483388901, 0.09613871574401855, 0.0993373766541481, 0.10253603756427765, 0.1057346910238266, 0.10893335938453674, 0.1121320128440857, 0.11533068120479584, 0.11852933466434479, 0.12172798812389374, 0.12492665648460388, 0.12812530994415283, 0.13132397830486298, 0.13452263176441193, 0.13772130012512207, 0.14091995358467102, 0.14411860704421997, 0.14731727540493011, 0.15051592886447906, 0.1537145972251892, 0.15691325068473816, 0.1601119041442871, 0.16331057250499725, 0.1665092259645462, 0.16970789432525635, 0.1729065477848053, 0.17610521614551544, 0.1793038696050644]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 2.0, 7.0, 28.0, 60.0, 257.0, 81.0, 17.0, 9.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11406853795051575, -0.10793101042509079, -0.10179349035024643, -0.09565596282482147, -0.08951844274997711, -0.08338091522455215, -0.0772433876991272, -0.07110586762428284, -0.06496834009885788, -0.05883081629872322, -0.05269329249858856, -0.046555764973163605, -0.04041823744773865, -0.03428071737289429, -0.02814318984746933, -0.02200566977262497, -0.015868142247200012, -0.009730614721775055, -0.0035930946469306946, 0.0025444328784942627, 0.008681952953338623, 0.014819487929344177, 0.020957008004188538, 0.027094528079032898, 0.03323206305503845, 0.03936958312988281, 0.04550710320472717, 0.05164462327957153, 0.05778215825557709, 0.06391967833042145, 0.07005719840526581, 0.07619473338127136, 0.08233225345611572, 0.08846977353096008, 0.09460730850696564, 0.10074482858181, 0.10688234865665436, 0.11301988363265991, 0.11915740370750427, 0.12529492378234863, 0.131432443857193, 0.13756996393203735, 0.1437075138092041, 0.14984503388404846, 0.15598255395889282, 0.16212007403373718, 0.16825759410858154, 0.1743951141834259, 0.18053266406059265, 0.186670184135437, 0.19280770421028137, 0.19894522428512573, 0.2050827443599701, 0.21122026443481445, 0.2173577845096588, 0.22349533438682556, 0.22963285446166992, 0.23577037453651428, 0.24190789461135864, 0.248045414686203, 0.25418293476104736, 0.2603204846382141, 0.26645800471305847, 0.27259552478790283, 0.2787330448627472]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.17263361811637878, -0.1665838658809662, -0.1605341136455536, -0.154484361410141, -0.1484346091747284, -0.1423848569393158, -0.1363351047039032, -0.1302853524684906, -0.124235600233078, -0.1181858479976654, -0.11213609576225281, -0.1060863509774208, -0.10003659874200821, -0.09398684650659561, -0.08793709427118301, -0.08188734203577042, -0.07583758980035782, -0.06978783756494522, -0.06373808532953262, -0.057688333094120026, -0.05163858085870743, -0.04558883607387543, -0.03953908383846283, -0.03348933160305023, -0.027439579367637634, -0.021389827132225037, -0.015340074896812439, -0.009290322661399841, -0.0032405704259872437, 0.002809181809425354, 0.008858934044837952, 0.01490868628025055, 0.020958438515663147, 0.027008190751075745, 0.03305794298648834, 0.03910769522190094, 0.04515744745731354, 0.051207199692726135, 0.05725695192813873, 0.06330670416355133, 0.06935645639896393, 0.07540620863437653, 0.08145594596862793, 0.08750569820404053, 0.09355545043945312, 0.09960520267486572, 0.10565495491027832, 0.11170470714569092, 0.11775445938110352, 0.12380421161651611, 0.1298539638519287, 0.1359037160873413, 0.1419534683227539, 0.1480032205581665, 0.1540529727935791, 0.1601027250289917, 0.1661524772644043, 0.1722022294998169, 0.1782519817352295, 0.1843017339706421, 0.1903514862060547, 0.19640123844146729, 0.20245099067687988, 0.20850074291229248, 0.21455049514770508]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0], "bins": [-0.09349974989891052, -0.09138580411672592, -0.08927185833454132, -0.08715792000293732, -0.08504397422075272, -0.08293002843856812, -0.08081608265638351, -0.07870213687419891, -0.07658819109201431, -0.07447424530982971, -0.07236030697822571, -0.07024636119604111, -0.0681324154138565, -0.0660184696316719, -0.0639045238494873, -0.061790581792593, -0.0596766360104084, -0.0575626902282238, -0.0554487481713295, -0.0533348023891449, -0.0512208566069603, -0.049106914550065994, -0.04699296876788139, -0.04487902298569679, -0.04276508092880249, -0.04065113514661789, -0.03853718936443329, -0.03642324358224869, -0.034309301525354385, -0.032195355743169785, -0.030081413686275482, -0.02796746790409088, -0.02585352212190628, -0.02373957633972168, -0.02162563055753708, -0.019511684775352478, -0.017397746443748474, -0.015283800661563873, -0.013169854879379272, -0.011055909097194672, -0.00894196331501007, -0.00682801753282547, -0.004714079201221466, -0.0026001334190368652, -0.0004861876368522644, 0.0016277581453323364, 0.0037417039275169373, 0.005855649709701538, 0.007969588041305542, 0.010083533823490143, 0.012197479605674744, 0.014311425387859344, 0.016425371170043945, 0.018539316952228546, 0.020653262734413147, 0.02276720106601715, 0.02488114684820175, 0.026995092630386353, 0.029109038412570953, 0.031222984194755554, 0.03333692252635956, 0.035450875759124756, 0.03756481409072876, 0.03967876732349396, 0.04179270565509796]}, "_runtime": 14372.183258533478, "_timestamp": 1585611741.816128, "_step": 198}
{"Episode reward": -90.91216591638482, "Episode length": 999, "Policy Loss": -0.007660714443773031, "Value Loss": 0.0006539286114275455, "_runtime": 14373.785439014435, "_timestamp": 1585611743.4183085, "_step": 199}
{"Episode reward": -86.67715629199772, "Episode length": 999, "Policy Loss": 0.0046498277224600315, "Value Loss": 0.0008934952784329653, "_runtime": 14375.390555858612, "_timestamp": 1585611745.0234253, "_step": 200}
{"Episode reward": -89.35478377429294, "Episode length": 999, "Policy Loss": -0.0014357168693095446, "Value Loss": 0.0007420328329317272, "_runtime": 14376.991314649582, "_timestamp": 1585611746.6241841, "_step": 201}
{"Episode reward": -88.71619576207917, "Episode length": 999, "Policy Loss": 0.00021870392083656043, "Value Loss": 0.0007612930494360626, "_runtime": 14378.606625318527, "_timestamp": 1585611748.2394948, "_step": 202}
{"Episode reward": -89.07180004359704, "Episode length": 999, "Policy Loss": -0.0017932986374944448, "Value Loss": 0.000753597472794354, "_runtime": 14380.220462799072, "_timestamp": 1585611749.8533323, "_step": 203}
{"Episode reward": -88.8976518438648, "Episode length": 999, "Policy Loss": -5.1404666010057554e-05, "Value Loss": 0.0007622524281032383, "_runtime": 14381.829327821732, "_timestamp": 1585611751.4621973, "_step": 204}
{"Episode reward": -84.86292713748124, "Episode length": 999, "Policy Loss": 0.011045086197555065, "Value Loss": 0.0009952412219718099, "_runtime": 14383.424018859863, "_timestamp": 1585611753.0568883, "_step": 205}
{"Episode reward": -90.20076249674479, "Episode length": 999, "Policy Loss": -0.00365696894004941, "Value Loss": 0.000660643563605845, "_runtime": 14385.025732278824, "_timestamp": 1585611754.6586018, "_step": 206}
{"Episode reward": -88.88983996415178, "Episode length": 999, "Policy Loss": -0.0011561185820028186, "Value Loss": 0.0007819902384653687, "_runtime": 14386.65857553482, "_timestamp": 1585611756.291445, "_step": 207}
{"Episode reward": -89.16621894942323, "Episode length": 999, "Policy Loss": -0.0015217466279864311, "Value Loss": 0.0007339385920204222, "_runtime": 14388.257479906082, "_timestamp": 1585611757.8903494, "_step": 208}
{"Episode reward": -90.01233137106288, "Episode length": 999, "Policy Loss": -0.002994564129039645, "Value Loss": 0.0006838964181952178, "_runtime": 14389.853188037872, "_timestamp": 1585611759.4860575, "_step": 209}
{"Episode reward": -87.35243503053951, "Episode length": 999, "Policy Loss": 0.00011576293036341667, "Value Loss": 0.0008559041889384389, "_runtime": 14391.460754871368, "_timestamp": 1585611761.0936244, "_step": 210}
{"Episode reward": -88.58000905342105, "Episode length": 999, "Policy Loss": -0.0025998505298048258, "Value Loss": 0.0008173893438652158, "_runtime": 14393.066961050034, "_timestamp": 1585611762.6998305, "_step": 211}
{"Episode reward": -90.43960279914693, "Episode length": 999, "Policy Loss": -0.004363069776445627, "Value Loss": 0.000658883189316839, "_runtime": 14394.671352148056, "_timestamp": 1585611764.3042216, "_step": 212}
{"Episode reward": -88.6269631749501, "Episode length": 999, "Policy Loss": -0.0015589168760925531, "Value Loss": 0.0007668336038477719, "_runtime": 14396.277448892593, "_timestamp": 1585611765.9103184, "_step": 213}
{"Episode reward": -91.23108884522681, "Episode length": 999, "Policy Loss": -0.006627177819609642, "Value Loss": 0.0006166668608784676, "_runtime": 14397.881937026978, "_timestamp": 1585611767.5148065, "_step": 214}
{"Episode reward": -90.39828843058115, "Episode length": 999, "Policy Loss": -0.0033850327599793673, "Value Loss": 0.0006616531172767282, "_runtime": 14399.498474121094, "_timestamp": 1585611769.1313436, "_step": 215}
{"Episode reward": -89.987849423678, "Episode length": 999, "Policy Loss": -0.004319555126130581, "Value Loss": 0.0006845556199550629, "_runtime": 14401.111747026443, "_timestamp": 1585611770.7446165, "_step": 216}
{"Episode reward": -90.18287416326056, "Episode length": 999, "Policy Loss": -0.003940333146601915, "Value Loss": 0.0006935106939636171, "_runtime": 14402.726051568985, "_timestamp": 1585611772.358921, "_step": 217}
{"Episode reward": -90.62933165931747, "Episode length": 999, "Policy Loss": -0.005661024246364832, "Value Loss": 0.0006611743592657149, "_runtime": 14404.341024398804, "_timestamp": 1585611773.973894, "_step": 218}
{"Episode reward": -89.88534543823343, "Episode length": 999, "Policy Loss": -0.004304580856114626, "Value Loss": 0.0007008716347627342, "_runtime": 14405.92898607254, "_timestamp": 1585611775.5618556, "_step": 219}
{"Episode reward": -90.47116078388743, "Episode length": 999, "Policy Loss": -0.005357468035072088, "Value Loss": 0.0006643709493800998, "_runtime": 14407.53598022461, "_timestamp": 1585611777.1688497, "_step": 220}
{"Episode reward": -88.80360233810593, "Episode length": 999, "Policy Loss": -0.00017421333177480847, "Value Loss": 0.0006955456919968128, "_runtime": 14409.175405025482, "_timestamp": 1585611778.8082745, "_step": 221}
{"Episode reward": -86.979158846693, "Episode length": 999, "Policy Loss": 0.006221337243914604, "Value Loss": 0.0008516022353433073, "_runtime": 14410.770786046982, "_timestamp": 1585611780.4036555, "_step": 222}
{"Episode reward": -89.46081019564483, "Episode length": 999, "Policy Loss": -0.0012873782543465495, "Value Loss": 0.0007384882192127407, "_runtime": 14412.376773357391, "_timestamp": 1585611782.0096428, "_step": 223}
{"Episode reward": -89.91758264603918, "Episode length": 999, "Policy Loss": -0.003464248962700367, "Value Loss": 0.0006957677542231977, "_runtime": 14413.98041510582, "_timestamp": 1585611783.6132846, "_step": 224}
{"Episode reward": -90.21365671896557, "Episode length": 999, "Policy Loss": -0.003401293186470866, "Value Loss": 0.0006890172371640801, "_runtime": 14415.573168516159, "_timestamp": 1585611785.206038, "_step": 225}
{"Episode reward": -88.9221228632477, "Episode length": 999, "Policy Loss": 0.00010755983385024592, "Value Loss": 0.0007579619414173067, "_runtime": 14417.17683172226, "_timestamp": 1585611786.8097012, "_step": 226}
{"Episode reward": -87.81628512833659, "Episode length": 999, "Policy Loss": 0.0030200593173503876, "Value Loss": 0.0008293704595416784, "_runtime": 14418.773695230484, "_timestamp": 1585611788.4065647, "_step": 227}
{"Episode reward": -87.67786110833117, "Episode length": 999, "Policy Loss": 0.005490721203386784, "Value Loss": 0.0008305103401653469, "_runtime": 14420.355064868927, "_timestamp": 1585611789.9879344, "_step": 228}
{"Episode reward": -87.31956588282462, "Episode length": 999, "Policy Loss": 0.004042725078761578, "Value Loss": 0.0008464143611490726, "_runtime": 14421.972276449203, "_timestamp": 1585611791.605146, "_step": 229}
{"Episode reward": -85.51340987683396, "Episode length": 999, "Policy Loss": 0.009070622734725475, "Value Loss": 0.0009392571519128978, "_runtime": 14423.593735218048, "_timestamp": 1585611793.2266047, "_step": 230}
{"Episode reward": -91.22924128108764, "Episode length": 999, "Policy Loss": -0.006102030165493488, "Value Loss": 0.0006081137689761817, "_runtime": 14425.20985031128, "_timestamp": 1585611794.8427198, "_step": 231}
{"Episode reward": -89.00213019187072, "Episode length": 999, "Policy Loss": -8.285655349027365e-05, "Value Loss": 0.000758197158575058, "_runtime": 14426.827540636063, "_timestamp": 1585611796.46041, "_step": 232}
{"Episode reward": -90.62768069384282, "Episode length": 999, "Policy Loss": -0.004990208428353071, "Value Loss": 0.0006593092693947256, "_runtime": 14428.431937932968, "_timestamp": 1585611798.0648074, "_step": 233}
{"Episode reward": -88.62328818686775, "Episode length": 999, "Policy Loss": 0.0019617793150246143, "Value Loss": 0.0007799904560670257, "_runtime": 14430.031383037567, "_timestamp": 1585611799.6642525, "_step": 234}
{"Episode reward": -88.4868442471508, "Episode length": 999, "Policy Loss": 0.0020170987118035555, "Value Loss": 0.0007421296904794872, "_runtime": 14431.644883871078, "_timestamp": 1585611801.2777534, "_step": 235}
{"Episode reward": -89.86306276390219, "Episode length": 999, "Policy Loss": -0.0013957731425762177, "Value Loss": 0.0006836856482550502, "_runtime": 14433.297716140747, "_timestamp": 1585611802.9305856, "_step": 236}
{"Episode reward": -88.9908731354706, "Episode length": 999, "Policy Loss": -0.001541492179967463, "Value Loss": 0.0007335119298659265, "_runtime": 14434.904797077179, "_timestamp": 1585611804.5376666, "_step": 237}
{"Episode reward": -89.91857219550748, "Episode length": 999, "Policy Loss": -0.0034703752025961876, "Value Loss": 0.0007084422977641225, "_runtime": 14436.501039743423, "_timestamp": 1585611806.1339092, "_step": 238}
{"Episode reward": -91.1371442776985, "Episode length": 999, "Policy Loss": -0.005942999850958586, "Value Loss": 0.0006234160391613841, "_runtime": 14438.108485937119, "_timestamp": 1585611807.7413554, "_step": 239}
{"Episode reward": -87.95721613771424, "Episode length": 999, "Policy Loss": 0.0024487904738634825, "Value Loss": 0.0008087051683105528, "_runtime": 14439.713453292847, "_timestamp": 1585611809.3463228, "_step": 240}
{"Episode reward": -89.34436432842885, "Episode length": 999, "Policy Loss": -0.0017223053146153688, "Value Loss": 0.0007285891333594918, "_runtime": 14441.318781137466, "_timestamp": 1585611810.9516506, "_step": 241}
{"Episode reward": -90.58647155572547, "Episode length": 999, "Policy Loss": -0.005324758123606443, "Value Loss": 0.0006274153711274266, "_runtime": 14442.926348924637, "_timestamp": 1585611812.5592184, "_step": 242}
{"Episode reward": -87.5647679238889, "Episode length": 999, "Policy Loss": 0.0036930288188159466, "Value Loss": 0.0008345406386069953, "_runtime": 14444.542555570602, "_timestamp": 1585611814.175425, "_step": 243}
{"Episode reward": -90.33742496919373, "Episode length": 999, "Policy Loss": -0.0023311476688832045, "Value Loss": 0.0006669150898233056, "_runtime": 14446.145442962646, "_timestamp": 1585611815.7783124, "_step": 244}
{"Episode reward": -88.00629101048538, "Episode length": 999, "Policy Loss": 0.0014278074959293008, "Value Loss": 0.0008071687771007419, "_runtime": 14447.761005401611, "_timestamp": 1585611817.393875, "_step": 245}
{"Episode reward": -89.47659461205684, "Episode length": 999, "Policy Loss": -0.0006447572959586978, "Value Loss": 0.0006910758092999458, "_runtime": 14449.376862764359, "_timestamp": 1585611819.0097322, "_step": 246}
{"Episode reward": -89.42532672057315, "Episode length": 999, "Policy Loss": -0.0017662771278992295, "Value Loss": 0.0007271236390806735, "_runtime": 14450.99137544632, "_timestamp": 1585611820.624245, "_step": 247}
{"Episode reward": -88.01164076907216, "Episode length": 999, "Policy Loss": 0.00292106787674129, "Value Loss": 0.0008078764076344669, "_runtime": 14452.595345973969, "_timestamp": 1585611822.2282155, "_step": 248}
{"Episode reward": -89.34974983355157, "Episode length": 999, "Policy Loss": -0.0008774634916335344, "Value Loss": 0.0007217538659460843, "_runtime": 14454.199305772781, "_timestamp": 1585611823.8321753, "_step": 249}
{"Episode reward": -89.80112561174245, "Episode length": 999, "Policy Loss": -0.002325878944247961, "Value Loss": 0.0006916329730302095, "_runtime": 14455.820420742035, "_timestamp": 1585611825.4532902, "_step": 250}
{"Episode reward": -89.54302539483113, "Episode length": 999, "Policy Loss": -0.0014186131302267313, "Value Loss": 0.0007129411678761244, "_runtime": 14457.464562892914, "_timestamp": 1585611827.0974324, "_step": 251}
{"Episode reward": -89.45636882780438, "Episode length": 999, "Policy Loss": -0.0021511472295969725, "Value Loss": 0.0007406615768559277, "_runtime": 14459.078761577606, "_timestamp": 1585611828.711631, "_step": 252}
{"Episode reward": -88.83890379300077, "Episode length": 999, "Policy Loss": 0.0007387184305116534, "Value Loss": 0.0007477246690541506, "_runtime": 14460.68396782875, "_timestamp": 1585611830.3168373, "_step": 253}
{"Episode reward": -88.27274863188673, "Episode length": 999, "Policy Loss": 0.0015509078511968255, "Value Loss": 0.0007998620858415961, "_runtime": 14462.289993286133, "_timestamp": 1585611831.9228628, "_step": 254}
{"Episode reward": -90.44647973079752, "Episode length": 999, "Policy Loss": -0.003775357035920024, "Value Loss": 0.0006465690094046295, "_runtime": 14463.894619941711, "_timestamp": 1585611833.5274894, "_step": 255}
{"Episode reward": -88.34648463771053, "Episode length": 999, "Policy Loss": 0.0023778376635164022, "Value Loss": 0.0008179220603778958, "_runtime": 14465.504974842072, "_timestamp": 1585611835.1378443, "_step": 256}
{"Episode reward": -85.89981505940985, "Episode length": 999, "Policy Loss": 0.005849477834999561, "Value Loss": 0.000980005250312388, "_runtime": 14467.121821641922, "_timestamp": 1585611836.7546911, "_step": 257}
{"Episode reward": -87.09107259721137, "Episode length": 999, "Policy Loss": 0.00478296959772706, "Value Loss": 0.0008736676536500454, "_runtime": 14468.728697776794, "_timestamp": 1585611838.3615673, "_step": 258}
{"Episode reward": -87.95047219272418, "Episode length": 999, "Policy Loss": 0.0026856439653784037, "Value Loss": 0.000816988991573453, "_runtime": 14470.3356051445, "_timestamp": 1585611839.9684746, "_step": 259}
{"Episode reward": -87.509782105701, "Episode length": 999, "Policy Loss": 0.004099742043763399, "Value Loss": 0.000821620284114033, "_runtime": 14471.950980186462, "_timestamp": 1585611841.5838497, "_step": 260}
{"Episode reward": -90.72432525776118, "Episode length": 999, "Policy Loss": -0.005488235037773848, "Value Loss": 0.0006393700605258346, "_runtime": 14473.556373119354, "_timestamp": 1585611843.1892426, "_step": 261}
{"Episode reward": -89.45287025699943, "Episode length": 999, "Policy Loss": -0.002068633446469903, "Value Loss": 0.0007229103939607739, "_runtime": 14475.171104431152, "_timestamp": 1585611844.803974, "_step": 262}
{"Episode reward": -88.8843941399728, "Episode length": 999, "Policy Loss": -0.0014108530012890697, "Value Loss": 0.0007713115774095058, "_runtime": 14476.775564908981, "_timestamp": 1585611846.4084344, "_step": 263}
{"Episode reward": -87.6309743131358, "Episode length": 999, "Policy Loss": 0.004292666912078857, "Value Loss": 0.0008496251539327204, "_runtime": 14478.378426551819, "_timestamp": 1585611848.011296, "_step": 264}
{"Episode reward": -88.15321321601076, "Episode length": 999, "Policy Loss": -0.00035822877543978393, "Value Loss": 0.000809389166533947, "_runtime": 14479.994068861008, "_timestamp": 1585611849.6269383, "_step": 265}
{"Episode reward": -87.08419815006764, "Episode length": 999, "Policy Loss": 0.003377841552719474, "Value Loss": 0.0008807237609289587, "_runtime": 14481.638804912567, "_timestamp": 1585611851.2716744, "_step": 266}
{"Episode reward": -87.94078397172225, "Episode length": 999, "Policy Loss": 0.004000106826424599, "Value Loss": 0.0008003299590200186, "_runtime": 14483.24545264244, "_timestamp": 1585611852.8783221, "_step": 267}
{"Episode reward": -88.45040924111132, "Episode length": 999, "Policy Loss": 0.0007025930099189281, "Value Loss": 0.0007721515721641481, "_runtime": 14484.854388237, "_timestamp": 1585611854.4872577, "_step": 268}
{"Episode reward": -88.51114778334053, "Episode length": 999, "Policy Loss": -0.0005322570796124637, "Value Loss": 0.0007881638593971729, "_runtime": 14486.460414409637, "_timestamp": 1585611856.093284, "_step": 269}
{"Episode reward": -89.73602315466445, "Episode length": 999, "Policy Loss": -0.0038215937092900276, "Value Loss": 0.000713419052772224, "_runtime": 14488.06421995163, "_timestamp": 1585611857.6970894, "_step": 270}
{"Episode reward": -90.5177908357675, "Episode length": 999, "Policy Loss": -0.005134242121130228, "Value Loss": 0.0006627793191000819, "_runtime": 14489.66906452179, "_timestamp": 1585611859.301934, "_step": 271}
{"Episode reward": -86.9402745175791, "Episode length": 999, "Policy Loss": 0.0027551883831620216, "Value Loss": 0.0009147956734523177, "_runtime": 14491.275515317917, "_timestamp": 1585611860.9083848, "_step": 272}
{"Episode reward": -88.96673604021625, "Episode length": 999, "Policy Loss": -9.844919986790046e-05, "Value Loss": 0.0007607302977703512, "_runtime": 14492.879556179047, "_timestamp": 1585611862.5124257, "_step": 273}
{"Episode reward": -88.06092661555515, "Episode length": 999, "Policy Loss": 0.0009421745780855417, "Value Loss": 0.000799729663413018, "_runtime": 14494.485608100891, "_timestamp": 1585611864.1184776, "_step": 274}
{"Episode reward": -89.39227293241687, "Episode length": 999, "Policy Loss": -0.000626736378762871, "Value Loss": 0.0007253921357914805, "_runtime": 14496.101847171783, "_timestamp": 1585611865.7347167, "_step": 275}
{"Episode reward": -88.06962283187879, "Episode length": 999, "Policy Loss": 0.0011163839371874928, "Value Loss": 0.0008227801881730556, "_runtime": 14497.708256483078, "_timestamp": 1585611867.341126, "_step": 276}
{"Episode reward": -87.78160472717684, "Episode length": 999, "Policy Loss": 0.002936880337074399, "Value Loss": 0.000805241463240236, "_runtime": 14499.313863515854, "_timestamp": 1585611868.946733, "_step": 277}
{"Episode reward": -87.8940307175567, "Episode length": 999, "Policy Loss": -0.0013930456480011344, "Value Loss": 0.0008394327014684677, "_runtime": 14500.930264234543, "_timestamp": 1585611870.5631337, "_step": 278}
{"Episode reward": -88.74097337138961, "Episode length": 999, "Policy Loss": -0.0012652281438931823, "Value Loss": 0.0007702165748924017, "_runtime": 14502.53406572342, "_timestamp": 1585611872.1669352, "_step": 279}
{"Episode reward": -88.1069222859635, "Episode length": 999, "Policy Loss": 0.0014842045493423939, "Value Loss": 0.0008039693348109722, "_runtime": 14504.189665079117, "_timestamp": 1585611873.8225346, "_step": 280}
{"Episode reward": -87.38079356104849, "Episode length": 999, "Policy Loss": 0.0001166427246062085, "Value Loss": 0.0008313081925734878, "_runtime": 14505.79372882843, "_timestamp": 1585611875.4265983, "_step": 281}
{"Episode reward": -89.06753971553184, "Episode length": 999, "Policy Loss": 0.0006891833036206663, "Value Loss": 0.0007378095760941505, "_runtime": 14507.396442174911, "_timestamp": 1585611877.0293117, "_step": 282}
{"Episode reward": -87.93347753159937, "Episode length": 999, "Policy Loss": -0.00018743699183687568, "Value Loss": 0.0008138794801197946, "_runtime": 14509.010981559753, "_timestamp": 1585611878.643851, "_step": 283}
{"Episode reward": -89.8176366643868, "Episode length": 999, "Policy Loss": -0.0029759565368294716, "Value Loss": 0.000711455475538969, "_runtime": 14510.616055488586, "_timestamp": 1585611880.248925, "_step": 284}
{"Episode reward": -87.20334338877964, "Episode length": 999, "Policy Loss": 0.0031823611352592707, "Value Loss": 0.0008261151961050928, "_runtime": 14512.209748029709, "_timestamp": 1585611881.8426175, "_step": 285}
{"Episode reward": -88.6814730533063, "Episode length": 999, "Policy Loss": -0.0005986680625937879, "Value Loss": 0.0007595957140438259, "_runtime": 14513.825684547424, "_timestamp": 1585611883.458554, "_step": 286}
{"Episode reward": -87.94533546048172, "Episode length": 999, "Policy Loss": 0.0025065827649086714, "Value Loss": 0.0008243144256994128, "_runtime": 14515.442182779312, "_timestamp": 1585611885.0750523, "_step": 287}
{"Episode reward": -88.08231788856452, "Episode length": 999, "Policy Loss": 0.0021499854046851397, "Value Loss": 0.0008252952247858047, "_runtime": 14517.047451257706, "_timestamp": 1585611886.6803207, "_step": 288}
{"Episode reward": -87.53984149528182, "Episode length": 999, "Policy Loss": 0.0020054630003869534, "Value Loss": 0.0008214274421334267, "_runtime": 14518.65489912033, "_timestamp": 1585611888.2877686, "_step": 289}
{"Episode reward": -91.43921068419897, "Episode length": 999, "Policy Loss": -0.007850083522498608, "Value Loss": 0.0006081585306674242, "_runtime": 14520.262104034424, "_timestamp": 1585611889.8949735, "_step": 290}
{"Episode reward": -88.30601793877581, "Episode length": 999, "Policy Loss": 0.0005046545411460102, "Value Loss": 0.0008118577534332871, "_runtime": 14521.874473810196, "_timestamp": 1585611891.5073433, "_step": 291}
{"Episode reward": -88.78398757970146, "Episode length": 999, "Policy Loss": -0.0016039826441556215, "Value Loss": 0.000752131687477231, "_runtime": 14523.478981018066, "_timestamp": 1585611893.1118505, "_step": 292}
{"Episode reward": -89.45332221318318, "Episode length": 999, "Policy Loss": -0.0031847988720983267, "Value Loss": 0.0007385071367025375, "_runtime": 14525.085421800613, "_timestamp": 1585611894.7182913, "_step": 293}
{"Episode reward": -88.38688414125448, "Episode length": 999, "Policy Loss": 0.0012987902155146003, "Value Loss": 0.00078007293632254, "_runtime": 14526.676329374313, "_timestamp": 1585611896.3091989, "_step": 294}
{"Episode reward": -88.63285792810056, "Episode length": 999, "Policy Loss": -0.0011047418229281902, "Value Loss": 0.0007790818926878273, "_runtime": 14528.318216562271, "_timestamp": 1585611897.951086, "_step": 295}
{"Episode reward": -88.31318737914846, "Episode length": 999, "Policy Loss": 0.0008610535878688097, "Value Loss": 0.0007975893677212298, "_runtime": 14529.922864198685, "_timestamp": 1585611899.5557337, "_step": 296}
{"Episode reward": -89.77447021582118, "Episode length": 999, "Policy Loss": -0.0045134457759559155, "Value Loss": 0.0007090105791576207, "_runtime": 14531.539258480072, "_timestamp": 1585611901.172128, "_step": 297}
{"Episode reward": -88.37632710974934, "Episode length": 999, "Policy Loss": 0.0007251857314258814, "Value Loss": 0.0007723139715380967, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823, 0.1680726259946823]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 5.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0], "bins": [-0.24657581746578217, -0.23281434178352356, -0.21905285120010376, -0.20529137551784515, -0.19152989983558655, -0.17776840925216675, -0.16400693356990814, -0.15024545788764954, -0.13648396730422974, -0.12272249162197113, -0.10896101593971252, -0.09519954025745392, -0.08143804967403412, -0.06767657399177551, -0.05391509830951691, -0.04015360772609711, -0.0263921320438385, -0.012630656361579895, 0.0011308342218399048, 0.014892295002937317, 0.028653785586357117, 0.042415276169776917, 0.05617673695087433, 0.06993822753429413, 0.08369971811771393, 0.09746117889881134, 0.11122266948223114, 0.12498416006565094, 0.13874562084674835, 0.15250711143016815, 0.16626860201358795, 0.18003006279468536, 0.19379155337810516, 0.20755304396152496, 0.22131450474262238, 0.23507599532604218, 0.24883748590946198, 0.2625989317893982, 0.2763603925704956, 0.2901219129562378, 0.3038833737373352, 0.3176448345184326, 0.3314063549041748, 0.3451678156852722, 0.35892927646636963, 0.3726907968521118, 0.38645225763320923, 0.40021371841430664, 0.41397523880004883, 0.42773669958114624, 0.44149816036224365, 0.45525968074798584, 0.46902114152908325, 0.48278260231018066, 0.49654412269592285, 0.5103055834770203, 0.5240670442581177, 0.5378285646438599, 0.5515900254249573, 0.5653514862060547, 0.5791130065917969, 0.5928744673728943, 0.6066359281539917, 0.6203974485397339, 0.6341589093208313]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.009317832067608833, -0.008182902820408344, -0.007047973573207855, -0.0059130447916686535, -0.0047781155444681644, -0.0036431862972676754, -0.0025082575157284737, -0.0013733282685279846, -0.00023839902132749557, 0.0008965302258729935, 0.0020314594730734825, 0.0031663887202739716, 0.004301317036151886, 0.005436246283352375, 0.006571175530552864, 0.007706105709075928, 0.008841034024953842, 0.009975962340831757, 0.01111089251935482, 0.012245820835232735, 0.013380751013755798, 0.014515679329633713, 0.015650609508156776, 0.01678553782403469, 0.017920466139912605, 0.01905539631843567, 0.020190324634313583, 0.021325254812836647, 0.02246018312871456, 0.023595111444592476, 0.02473004348576069, 0.025864971801638603, 0.026999900117516518, 0.028134828433394432, 0.029269756749272346, 0.03040468879044056, 0.03153961896896362, 0.03267454355955124, 0.03380947560071945, 0.034944407641887665, 0.03607933223247528, 0.037214264273643494, 0.03834918886423111, 0.03948412090539932, 0.040619052946567535, 0.04175397753715515, 0.042888909578323364, 0.04402383416891098, 0.04515876621007919, 0.046293698251247406, 0.04742862284183502, 0.048563554883003235, 0.04969847947359085, 0.050833411514759064, 0.05196834355592728, 0.05310326814651489, 0.054238200187683105, 0.05537313222885132, 0.056508056819438934, 0.05764298886060715, 0.05877792090177536, 0.059912845492362976, 0.06104777753353119, 0.062182702124118805, 0.06331763416528702]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0, 3.0, 3.0, 4.0, 9.0, 15.0, 39.0, 89.0, 194.0, 60.0, 35.0, 14.0, 5.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04634634777903557, -0.04407120123505592, -0.04179605469107628, -0.03952091187238693, -0.03724576532840729, -0.03497061878442764, -0.032695472240448, -0.030420327559113503, -0.028145181015133858, -0.025870034471154213, -0.023594889789819717, -0.021319743245840073, -0.019044596701860428, -0.016769452020525932, -0.014494307339191437, -0.012219160795211792, -0.009944014251232147, -0.0076688677072525024, -0.005393721163272858, -0.0031185783445835114, -0.0008434318006038666, 0.0014317147433757782, 0.003706861287355423, 0.005982007831335068, 0.008257154375314713, 0.010532297194004059, 0.012807443737983704, 0.015082590281963348, 0.017357733100652695, 0.01963287964463234, 0.021908026188611984, 0.02418317273259163, 0.026458319276571274, 0.02873346582055092, 0.031008612364530563, 0.03328375890851021, 0.03555890545248985, 0.0378340519964695, 0.040109191089868546, 0.04238433763384819, 0.044659484177827835, 0.04693463072180748, 0.049209777265787125, 0.05148492380976677, 0.053760070353746414, 0.05603521689772606, 0.058310363441705704, 0.06058550998568535, 0.0628606528043747, 0.06513579189777374, 0.06741094589233398, 0.06968608498573303, 0.07196123898029327, 0.07423637807369232, 0.07651153206825256, 0.07878667116165161, 0.08106181025505066, 0.0833369642496109, 0.08561210334300995, 0.08788725733757019, 0.09016239643096924, 0.09243755042552948, 0.09471268951892853, 0.09698784351348877, 0.09926298260688782]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.09560538083314896, -0.09344875067472458, -0.0912921279668808, -0.08913549780845642, -0.08697887510061264, -0.08482224494218826, -0.08266562223434448, -0.0805089920759201, -0.07835236936807632, -0.07619573920965195, -0.07403911650180817, -0.07188248634338379, -0.06972585618495941, -0.06756923347711563, -0.06541261076927185, -0.06325598061084747, -0.061099354177713394, -0.058942727744579315, -0.056786101311445236, -0.05462947487831116, -0.05247284844517708, -0.050316222012043, -0.04815959557890892, -0.04600296914577484, -0.043846338987350464, -0.041689712554216385, -0.039533086121082306, -0.03737645968794823, -0.03521983325481415, -0.03306321054697037, -0.03090658038854599, -0.02874995768070221, -0.026593327522277832, -0.024436697363853455, -0.022280074656009674, -0.020123444497585297, -0.017966821789741516, -0.01581019163131714, -0.013653568923473358, -0.01149693876504898, -0.0093403160572052, -0.007183685898780823, -0.005027063190937042, -0.002870433032512665, -0.0007138103246688843, 0.0014428198337554932, 0.0035994425415992737, 0.005756072700023651, 0.007912702858448029, 0.010069325566291809, 0.012225955724716187, 0.014382578432559967, 0.016539208590984344, 0.018695831298828125, 0.020852461457252502, 0.023009084165096283, 0.02516571432352066, 0.02732233703136444, 0.02947895973920822, 0.0316355898976326, 0.033792220056056976, 0.035948850214481354, 0.03810546547174454, 0.040262095630168915, 0.04241872578859329]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 7.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0], "bins": [-0.10789185762405396, -0.10538603365421295, -0.10288020968437195, -0.10037437826395035, -0.09786855429410934, -0.09536273032426834, -0.09285690635442734, -0.09035108238458633, -0.08784525096416473, -0.08533942699432373, -0.08283360302448273, -0.08032777905464172, -0.07782195508480072, -0.07531613111495972, -0.07281030714511871, -0.07030447572469711, -0.06779865175485611, -0.0652928277850151, -0.0627869963645935, -0.0602811761200428, -0.0577753484249115, -0.055269524455070496, -0.05276370048522949, -0.05025787279009819, -0.04775204882025719, -0.045246221125125885, -0.04274039715528488, -0.04023457318544388, -0.037728749215602875, -0.03522292524576187, -0.03271709382534027, -0.030211269855499268, -0.027705445885658264, -0.02519962191581726, -0.022693797945976257, -0.020187966525554657, -0.017682142555713654, -0.01517631858587265, -0.012670494616031647, -0.010164670646190643, -0.007658839225769043, -0.0051530152559280396, -0.002647191286087036, -0.00014136731624603271, 0.0023644566535949707, 0.004870280623435974, 0.0073761120438575745, 0.009881936013698578, 0.012387759983539581, 0.014893583953380585, 0.017399415373802185, 0.01990523934364319, 0.022411063313484192, 0.024916887283325195, 0.0274227112531662, 0.029928535223007202, 0.032434359192848206, 0.03494018316268921, 0.03744600713253021, 0.03995184600353241, 0.04245766997337341, 0.044963493943214417, 0.04746931791305542, 0.04997514188289642, 0.05248096585273743]}, "_runtime": 14533.155817270279, "_timestamp": 1585611902.7886868, "_step": 298}
{"Episode reward": -89.71706827076522, "Episode length": 999, "Policy Loss": -0.0035641591530293226, "Value Loss": 0.0007020700722932816, "_runtime": 14534.772269487381, "_timestamp": 1585611904.405139, "_step": 299}
{"Episode reward": -86.06698776228102, "Episode length": 999, "Policy Loss": 0.008301266469061375, "Value Loss": 0.0009259061771444976, "_runtime": 14536.37680220604, "_timestamp": 1585611906.0096717, "_step": 300}
{"Episode reward": -89.25650379354848, "Episode length": 999, "Policy Loss": -0.0036782333627343178, "Value Loss": 0.0007245532469823956, "_runtime": 14537.98966383934, "_timestamp": 1585611907.6225333, "_step": 301}
{"Episode reward": -89.7801673885532, "Episode length": 999, "Policy Loss": -0.003128906711935997, "Value Loss": 0.0007224769797176123, "_runtime": 14539.585267543793, "_timestamp": 1585611909.218137, "_step": 302}
{"Episode reward": -86.86158198034865, "Episode length": 999, "Policy Loss": 0.00480369757860899, "Value Loss": 0.0008632477838546038, "_runtime": 14541.190733194351, "_timestamp": 1585611910.8236027, "_step": 303}
{"Episode reward": -87.1004288205381, "Episode length": 999, "Policy Loss": 0.004818059038370848, "Value Loss": 0.0009041194571182132, "_runtime": 14542.793270587921, "_timestamp": 1585611912.42614, "_step": 304}
{"Episode reward": -86.74919810248092, "Episode length": 999, "Policy Loss": 0.003595381509512663, "Value Loss": 0.0008882074616849422, "_runtime": 14544.408153057098, "_timestamp": 1585611914.0410225, "_step": 305}
{"Episode reward": -88.2944617872184, "Episode length": 999, "Policy Loss": 0.001241070101968944, "Value Loss": 0.0007879093172959983, "_runtime": 14546.009799718857, "_timestamp": 1585611915.6426692, "_step": 306}
{"Episode reward": -90.33470537774058, "Episode length": 999, "Policy Loss": -0.0044850753620266914, "Value Loss": 0.0006533517153002322, "_runtime": 14547.613252162933, "_timestamp": 1585611917.2461216, "_step": 307}
{"Episode reward": -87.85641797963402, "Episode length": 999, "Policy Loss": 0.0013861818006262183, "Value Loss": 0.0008433446637354791, "_runtime": 14549.227759838104, "_timestamp": 1585611918.8606293, "_step": 308}
{"Episode reward": -89.03965713445655, "Episode length": 999, "Policy Loss": -0.0019131361041218042, "Value Loss": 0.000757588364649564, "_runtime": 14550.839434623718, "_timestamp": 1585611920.472304, "_step": 309}
{"Episode reward": -88.93968432087222, "Episode length": 999, "Policy Loss": -0.0036634188145399094, "Value Loss": 0.000768515863455832, "_runtime": 14552.484597682953, "_timestamp": 1585611922.1174672, "_step": 310}
{"Episode reward": -87.46397888711043, "Episode length": 999, "Policy Loss": 0.0032259912695735693, "Value Loss": 0.0008442673715762794, "_runtime": 14554.100130081177, "_timestamp": 1585611923.7329996, "_step": 311}
{"Episode reward": -88.15379857596045, "Episode length": 999, "Policy Loss": 1.1890590030816384e-05, "Value Loss": 0.0008032083278521895, "_runtime": 14555.69611287117, "_timestamp": 1585611925.3289824, "_step": 312}
{"Episode reward": -86.71239473641815, "Episode length": 999, "Policy Loss": 0.005059561692178249, "Value Loss": 0.0009267019340768456, "_runtime": 14557.295606851578, "_timestamp": 1585611926.9284763, "_step": 313}
{"Episode reward": -88.69954743054991, "Episode length": 999, "Policy Loss": -0.0029319683089852333, "Value Loss": 0.0007607102743349969, "_runtime": 14558.911374092102, "_timestamp": 1585611928.5442436, "_step": 314}
{"Episode reward": -88.41280309720227, "Episode length": 999, "Policy Loss": 0.0011681383475661278, "Value Loss": 0.0008150151697918773, "_runtime": 14560.530654668808, "_timestamp": 1585611930.1635242, "_step": 315}
{"Episode reward": -87.71238608308025, "Episode length": 999, "Policy Loss": 0.0024145222268998623, "Value Loss": 0.0008326703682541847, "_runtime": 14562.136021137238, "_timestamp": 1585611931.7688906, "_step": 316}
{"Episode reward": -88.85589716851514, "Episode length": 999, "Policy Loss": -0.0011336038587614894, "Value Loss": 0.0008091893396340311, "_runtime": 14563.754063367844, "_timestamp": 1585611933.3869328, "_step": 317}
{"Episode reward": -88.21491368059121, "Episode length": 999, "Policy Loss": 0.003286425955593586, "Value Loss": 0.0007681900751776993, "_runtime": 14565.358488559723, "_timestamp": 1585611934.991358, "_step": 318}
{"Episode reward": -87.25184519302435, "Episode length": 999, "Policy Loss": 0.0039961570873856544, "Value Loss": 0.0008733770227991045, "_runtime": 14566.966202497482, "_timestamp": 1585611936.599072, "_step": 319}
{"Episode reward": -87.7146967696881, "Episode length": 999, "Policy Loss": 0.0024986863136291504, "Value Loss": 0.0008307681418955326, "_runtime": 14568.571809768677, "_timestamp": 1585611938.2046793, "_step": 320}
{"Episode reward": -88.92557270957774, "Episode length": 999, "Policy Loss": -0.00177867547608912, "Value Loss": 0.0007317844429053366, "_runtime": 14570.186932086945, "_timestamp": 1585611939.8198016, "_step": 321}
{"Episode reward": -90.01499022367464, "Episode length": 999, "Policy Loss": -0.004467870574444532, "Value Loss": 0.0006893065292388201, "_runtime": 14571.804340362549, "_timestamp": 1585611941.4372098, "_step": 322}
{"Episode reward": -89.05012134664673, "Episode length": 999, "Policy Loss": -0.002509904559701681, "Value Loss": 0.0007491651922464371, "_runtime": 14573.427452802658, "_timestamp": 1585611943.0603223, "_step": 323}
{"Episode reward": -89.18903059756637, "Episode length": 999, "Policy Loss": -0.0028592459857463837, "Value Loss": 0.0007106842240318656, "_runtime": 14575.04478096962, "_timestamp": 1585611944.6776505, "_step": 324}
{"Episode reward": -90.92172910660746, "Episode length": 999, "Policy Loss": -0.008543429896235466, "Value Loss": 0.0006459133001044393, "_runtime": 14576.684205770493, "_timestamp": 1585611946.3170753, "_step": 325}
{"Episode reward": -89.22302558974532, "Episode length": 999, "Policy Loss": -0.0020575937815010548, "Value Loss": 0.0007411750266328454, "_runtime": 14578.287624835968, "_timestamp": 1585611947.9204943, "_step": 326}
{"Episode reward": -87.303804355466, "Episode length": 999, "Policy Loss": 0.0005324675585143268, "Value Loss": 0.0008144846651703119, "_runtime": 14579.895055294037, "_timestamp": 1585611949.5279248, "_step": 327}
{"Episode reward": -87.2993594415553, "Episode length": 999, "Policy Loss": 0.0017838265048339963, "Value Loss": 0.0009093250846490264, "_runtime": 14581.497263908386, "_timestamp": 1585611951.1301334, "_step": 328}
{"Episode reward": -87.03624094614992, "Episode length": 999, "Policy Loss": 0.0023139261174947023, "Value Loss": 0.0008658816805109382, "_runtime": 14583.111746549606, "_timestamp": 1585611952.744616, "_step": 329}
{"Episode reward": -88.4897078343902, "Episode length": 999, "Policy Loss": -0.002341538667678833, "Value Loss": 0.0007960567018017173, "_runtime": 14584.7218272686, "_timestamp": 1585611954.3546968, "_step": 330}
{"Episode reward": -89.52108580477693, "Episode length": 999, "Policy Loss": -0.0031344438903033733, "Value Loss": 0.0007188154268078506, "_runtime": 14586.33694434166, "_timestamp": 1585611955.9698138, "_step": 331}
{"Episode reward": -90.94021031334336, "Episode length": 999, "Policy Loss": -0.007716486696153879, "Value Loss": 0.0006114107673056424, "_runtime": 14587.933162689209, "_timestamp": 1585611957.5660322, "_step": 332}
{"Episode reward": -89.72493629452829, "Episode length": 999, "Policy Loss": -0.0035193029325455427, "Value Loss": 0.000681211007758975, "_runtime": 14589.530091047287, "_timestamp": 1585611959.1629605, "_step": 333}
{"Episode reward": -84.65148653396042, "Episode length": 999, "Policy Loss": 0.006981814280152321, "Value Loss": 0.0010219371179118752, "_runtime": 14591.127272844315, "_timestamp": 1585611960.7601423, "_step": 334}
{"Episode reward": -85.43629354169555, "Episode length": 999, "Policy Loss": 0.006070500239729881, "Value Loss": 0.0009708334691822529, "_runtime": 14592.73194694519, "_timestamp": 1585611962.3648164, "_step": 335}
{"Episode reward": -90.22388365288052, "Episode length": 999, "Policy Loss": -0.005656739231199026, "Value Loss": 0.0006599673070013523, "_runtime": 14594.323636054993, "_timestamp": 1585611963.9565055, "_step": 336}
{"Episode reward": -87.343318632018, "Episode length": 999, "Policy Loss": 0.0013310607755556703, "Value Loss": 0.0008653554250486195, "_runtime": 14595.917695522308, "_timestamp": 1585611965.550565, "_step": 337}
{"Episode reward": -87.09133453794058, "Episode length": 999, "Policy Loss": 0.002736781258136034, "Value Loss": 0.0008606615010648966, "_runtime": 14597.521093606949, "_timestamp": 1585611967.153963, "_step": 338}
{"Episode reward": -89.80066730668722, "Episode length": 999, "Policy Loss": -0.004257346037775278, "Value Loss": 0.0006838259287178516, "_runtime": 14599.132681369781, "_timestamp": 1585611968.7655509, "_step": 339}
{"Episode reward": -86.94078025867907, "Episode length": 999, "Policy Loss": 0.005922671873122454, "Value Loss": 0.0008748409454710782, "_runtime": 14600.782539844513, "_timestamp": 1585611970.4154093, "_step": 340}
{"Episode reward": -89.39849728766937, "Episode length": 999, "Policy Loss": -0.0013141720555722713, "Value Loss": 0.0007372416439466178, "_runtime": 14602.386642932892, "_timestamp": 1585611972.0195124, "_step": 341}
{"Episode reward": -88.28424623609065, "Episode length": 999, "Policy Loss": -0.0002507571771275252, "Value Loss": 0.0007828326779417694, "_runtime": 14603.98570561409, "_timestamp": 1585611973.618575, "_step": 342}
{"Episode reward": -88.53071211867815, "Episode length": 999, "Policy Loss": -0.003060772782191634, "Value Loss": 0.000792285893112421, "_runtime": 14605.585488080978, "_timestamp": 1585611975.2183576, "_step": 343}
{"Episode reward": -86.07996832043953, "Episode length": 999, "Policy Loss": 0.005987049080431461, "Value Loss": 0.0009191213175654411, "_runtime": 14607.18091225624, "_timestamp": 1585611976.8137817, "_step": 344}
{"Episode reward": -87.88428610470855, "Episode length": 999, "Policy Loss": -0.001617109403014183, "Value Loss": 0.0008135861717164516, "_runtime": 14608.775557041168, "_timestamp": 1585611978.4084265, "_step": 345}
{"Episode reward": -88.80975735712715, "Episode length": 999, "Policy Loss": -0.0017035246128216386, "Value Loss": 0.0007582330727018416, "_runtime": 14610.37736749649, "_timestamp": 1585611980.010237, "_step": 346}
{"Episode reward": -89.2442599869835, "Episode length": 999, "Policy Loss": -0.0018263912061229348, "Value Loss": 0.0007400793256238103, "_runtime": 14611.971827745438, "_timestamp": 1585611981.6046972, "_step": 347}
{"Episode reward": -88.44397210743242, "Episode length": 999, "Policy Loss": -0.0012990492396056652, "Value Loss": 0.0008023480186238885, "_runtime": 14613.567507743835, "_timestamp": 1585611983.2003772, "_step": 348}
{"Episode reward": -88.14827533542103, "Episode length": 999, "Policy Loss": 0.0015808148309588432, "Value Loss": 0.0007761187735013664, "_runtime": 14615.160198450089, "_timestamp": 1585611984.793068, "_step": 349}
{"Episode reward": -89.23628087003758, "Episode length": 999, "Policy Loss": -0.0028964115772396326, "Value Loss": 0.0007288402412086725, "_runtime": 14616.757792949677, "_timestamp": 1585611986.3906624, "_step": 350}
{"Episode reward": -89.54809456614468, "Episode length": 999, "Policy Loss": -0.0024304823018610477, "Value Loss": 0.0007363047916442156, "_runtime": 14618.35211443901, "_timestamp": 1585611987.984984, "_step": 351}
{"Episode reward": -89.99250058114599, "Episode length": 999, "Policy Loss": -0.003986854571849108, "Value Loss": 0.000700173492077738, "_runtime": 14619.94849228859, "_timestamp": 1585611989.5813618, "_step": 352}
{"Episode reward": -88.43472371861844, "Episode length": 999, "Policy Loss": 0.001114208484068513, "Value Loss": 0.0007989696459844708, "_runtime": 14621.544595718384, "_timestamp": 1585611991.1774652, "_step": 353}
{"Episode reward": -88.57333968239118, "Episode length": 999, "Policy Loss": -0.001705028349533677, "Value Loss": 0.0007904432713985443, "_runtime": 14623.188296318054, "_timestamp": 1585611992.8211658, "_step": 354}
{"Episode reward": -86.66132845977947, "Episode length": 999, "Policy Loss": 0.0028895349241793156, "Value Loss": 0.0008768499246798456, "_runtime": 14624.811119556427, "_timestamp": 1585611994.443989, "_step": 355}
{"Episode reward": -90.9543515107258, "Episode length": 999, "Policy Loss": -0.007371630985289812, "Value Loss": 0.0006517855799756944, "_runtime": 14626.422322750092, "_timestamp": 1585611996.0551922, "_step": 356}
{"Episode reward": -90.14759237703572, "Episode length": 999, "Policy Loss": -0.005430190823972225, "Value Loss": 0.0006942926556803286, "_runtime": 14628.02517747879, "_timestamp": 1585611997.658047, "_step": 357}
{"Episode reward": -85.83517543011058, "Episode length": 999, "Policy Loss": 0.006818797439336777, "Value Loss": 0.0009462693124078214, "_runtime": 14629.622876405716, "_timestamp": 1585611999.255746, "_step": 358}
{"Episode reward": -91.3274618004889, "Episode length": 999, "Policy Loss": -0.008205917663872242, "Value Loss": 0.0006393658113665879, "_runtime": 14631.216333150864, "_timestamp": 1585612000.8492026, "_step": 359}
{"Episode reward": -87.70630818856924, "Episode length": 999, "Policy Loss": 0.0018363605486229062, "Value Loss": 0.0008003340335562825, "_runtime": 14632.810915708542, "_timestamp": 1585612002.4437852, "_step": 360}
{"Episode reward": -87.85645339688477, "Episode length": 999, "Policy Loss": -0.000135077687446028, "Value Loss": 0.0008592813974246383, "_runtime": 14634.403717041016, "_timestamp": 1585612004.0365865, "_step": 361}
{"Episode reward": -88.79131275548164, "Episode length": 999, "Policy Loss": -0.0008488482562825084, "Value Loss": 0.0007633283967152238, "_runtime": 14636.01091837883, "_timestamp": 1585612005.6437879, "_step": 362}
{"Episode reward": -90.23860272571405, "Episode length": 999, "Policy Loss": -0.004024584777653217, "Value Loss": 0.00067465181928128, "_runtime": 14637.614181518555, "_timestamp": 1585612007.247051, "_step": 363}
{"Episode reward": -88.67148460858856, "Episode length": 999, "Policy Loss": -0.0017785181989893317, "Value Loss": 0.0007537349592894316, "_runtime": 14639.215045928955, "_timestamp": 1585612008.8479154, "_step": 364}
{"Episode reward": -89.4405545054615, "Episode length": 999, "Policy Loss": -0.003855958115309477, "Value Loss": 0.0007217972306534648, "_runtime": 14640.819211244583, "_timestamp": 1585612010.4520807, "_step": 365}
{"Episode reward": -88.80488802323748, "Episode length": 999, "Policy Loss": -0.001418297179043293, "Value Loss": 0.000755664543248713, "_runtime": 14642.414478302002, "_timestamp": 1585612012.0473478, "_step": 366}
{"Episode reward": -89.08021554558846, "Episode length": 999, "Policy Loss": -0.00096243986627087, "Value Loss": 0.0007504596724174917, "_runtime": 14644.017694711685, "_timestamp": 1585612013.6505642, "_step": 367}
{"Episode reward": -90.36877247798716, "Episode length": 999, "Policy Loss": -0.005389377474784851, "Value Loss": 0.0006743700359947979, "_runtime": 14645.612700939178, "_timestamp": 1585612015.2455704, "_step": 368}
{"Episode reward": -87.52218504640597, "Episode length": 999, "Policy Loss": 0.002486602868884802, "Value Loss": 0.0008309704135172069, "_runtime": 14647.253192424774, "_timestamp": 1585612016.886062, "_step": 369}
{"Episode reward": -88.32730852217043, "Episode length": 999, "Policy Loss": -0.0005479060346260667, "Value Loss": 0.0008016492356546223, "_runtime": 14648.856404066086, "_timestamp": 1585612018.4892735, "_step": 370}
{"Episode reward": -87.27157443162355, "Episode length": 999, "Policy Loss": 0.0018596589798107743, "Value Loss": 0.0008662128821015358, "_runtime": 14650.449823141098, "_timestamp": 1585612020.0826926, "_step": 371}
{"Episode reward": -89.68905934303523, "Episode length": 999, "Policy Loss": -0.004153333604335785, "Value Loss": 0.0007176069775596261, "_runtime": 14652.065819978714, "_timestamp": 1585612021.6986895, "_step": 372}
{"Episode reward": -88.48292784194672, "Episode length": 999, "Policy Loss": 0.0005428034346550703, "Value Loss": 0.0007908752886578441, "_runtime": 14653.67141342163, "_timestamp": 1585612023.304283, "_step": 373}
{"Episode reward": -89.12393278764647, "Episode length": 999, "Policy Loss": -0.0005878277006559074, "Value Loss": 0.0007351357489824295, "_runtime": 14655.275670051575, "_timestamp": 1585612024.9085395, "_step": 374}
{"Episode reward": -86.54464108747177, "Episode length": 999, "Policy Loss": 0.0030227957759052515, "Value Loss": 0.0008922368288040161, "_runtime": 14656.881045341492, "_timestamp": 1585612026.5139148, "_step": 375}
{"Episode reward": -89.18798972330829, "Episode length": 999, "Policy Loss": -0.0018365783616900444, "Value Loss": 0.0007544199470430613, "_runtime": 14658.488415718079, "_timestamp": 1585612028.1212852, "_step": 376}
{"Episode reward": -86.57065764138417, "Episode length": 999, "Policy Loss": 0.003916909918189049, "Value Loss": 0.0008903602138161659, "_runtime": 14660.09568285942, "_timestamp": 1585612029.7285523, "_step": 377}
{"Episode reward": -90.94902845046583, "Episode length": 999, "Policy Loss": -0.007096270099282265, "Value Loss": 0.0006298698135651648, "_runtime": 14661.701134443283, "_timestamp": 1585612031.334004, "_step": 378}
{"Episode reward": -87.35893011661466, "Episode length": 999, "Policy Loss": 0.0019588363356888294, "Value Loss": 0.0008440904202871025, "_runtime": 14663.316337108612, "_timestamp": 1585612032.9492066, "_step": 379}
{"Episode reward": -91.42405407644917, "Episode length": 999, "Policy Loss": -0.007424165029078722, "Value Loss": 0.0006075205747038126, "_runtime": 14664.930744886398, "_timestamp": 1585612034.5636144, "_step": 380}
{"Episode reward": -89.9510621324371, "Episode length": 999, "Policy Loss": -0.00237449468113482, "Value Loss": 0.0006953290430828929, "_runtime": 14666.53486251831, "_timestamp": 1585612036.167732, "_step": 381}
{"Episode reward": -88.64476534103402, "Episode length": 999, "Policy Loss": 0.001241549151018262, "Value Loss": 0.0007894799928180873, "_runtime": 14668.140029668808, "_timestamp": 1585612037.7728992, "_step": 382}
{"Episode reward": -90.94963847123296, "Episode length": 999, "Policy Loss": -0.0059961918741464615, "Value Loss": 0.0006534276180900633, "_runtime": 14669.753304958344, "_timestamp": 1585612039.3861744, "_step": 383}
{"Episode reward": -89.20302126878912, "Episode length": 999, "Policy Loss": -0.001485750311985612, "Value Loss": 0.00074446463258937, "_runtime": 14671.407753229141, "_timestamp": 1585612041.0406227, "_step": 384}
{"Episode reward": -89.23847001623439, "Episode length": 999, "Policy Loss": -0.0016579049406573176, "Value Loss": 0.0007247822941280901, "_runtime": 14673.023821115494, "_timestamp": 1585612042.6566906, "_step": 385}
{"Episode reward": -89.02198963776179, "Episode length": 999, "Policy Loss": -0.002901579951867461, "Value Loss": 0.0007746713235974312, "_runtime": 14674.63181734085, "_timestamp": 1585612044.2646868, "_step": 386}
{"Episode reward": -87.99531196536445, "Episode length": 999, "Policy Loss": 0.00010926090908469632, "Value Loss": 0.0008279787143692374, "_runtime": 14676.236695766449, "_timestamp": 1585612045.8695652, "_step": 387}
{"Episode reward": -88.0125473422649, "Episode length": 999, "Policy Loss": 0.0038392923306673765, "Value Loss": 0.0008158072014339268, "_runtime": 14677.840179920197, "_timestamp": 1585612047.4730494, "_step": 388}
{"Episode reward": -87.75926985398299, "Episode length": 999, "Policy Loss": 0.0028072744607925415, "Value Loss": 0.0008320545894093812, "_runtime": 14679.459777355194, "_timestamp": 1585612049.0926468, "_step": 389}
{"Episode reward": -89.04173587248586, "Episode length": 999, "Policy Loss": 0.0008906924049369991, "Value Loss": 0.0007207216694951057, "_runtime": 14681.075258731842, "_timestamp": 1585612050.7081282, "_step": 390}
{"Episode reward": -87.90371479051119, "Episode length": 999, "Policy Loss": 0.0011507355375215411, "Value Loss": 0.0008455318748019636, "_runtime": 14682.68103837967, "_timestamp": 1585612052.3139079, "_step": 391}
{"Episode reward": -87.53704416147929, "Episode length": 999, "Policy Loss": 0.0014748513931408525, "Value Loss": 0.000879297498613596, "_runtime": 14684.286502361298, "_timestamp": 1585612053.9193718, "_step": 392}
{"Episode reward": -88.89040014103588, "Episode length": 999, "Policy Loss": 0.00020278425654396415, "Value Loss": 0.0007280451827682555, "_runtime": 14685.902745485306, "_timestamp": 1585612055.535615, "_step": 393}
{"Episode reward": -89.01512888925612, "Episode length": 999, "Policy Loss": -0.0001385301147820428, "Value Loss": 0.000716640439350158, "_runtime": 14687.510109901428, "_timestamp": 1585612057.1429794, "_step": 394}
{"Episode reward": -89.60345949546621, "Episode length": 999, "Policy Loss": -0.002430450636893511, "Value Loss": 0.0007147997966967523, "_runtime": 14689.117486000061, "_timestamp": 1585612058.7503555, "_step": 395}
{"Episode reward": -86.59912773605103, "Episode length": 999, "Policy Loss": 0.005873912945389748, "Value Loss": 0.0008848963188938797, "_runtime": 14690.724066257477, "_timestamp": 1585612060.3569357, "_step": 396}
{"Episode reward": -90.59327035320005, "Episode length": 999, "Policy Loss": -0.005158168729394674, "Value Loss": 0.0006645487155765295, "_runtime": 14692.332431793213, "_timestamp": 1585612061.9653013, "_step": 397}
{"Episode reward": -88.82169076768926, "Episode length": 999, "Policy Loss": 0.001080413581803441, "Value Loss": 0.0007518699276261032, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097, -0.3516222834587097]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 2.0, 0.0, 3.0], "bins": [-0.6381142139434814, -0.6236649751663208, -0.6092157363891602, -0.5947664976119995, -0.5803172588348389, -0.5658680200576782, -0.5514187216758728, -0.5369694828987122, -0.5225202441215515, -0.5080710053443909, -0.4936217665672302, -0.4791725277900696, -0.46472328901290894, -0.4502740204334259, -0.43582478165626526, -0.4213755130767822, -0.4069262742996216, -0.39247703552246094, -0.3780277967453003, -0.36357855796813965, -0.349129319190979, -0.33468005061149597, -0.3202308118343353, -0.3057815730571747, -0.29133233428001404, -0.2768830955028534, -0.26243382692337036, -0.24798458814620972, -0.23353534936904907, -0.21908611059188843, -0.2046368420124054, -0.19018760323524475, -0.1757383644580841, -0.16128912568092346, -0.14683988690376282, -0.13239061832427979, -0.11794137954711914, -0.1034921407699585, -0.08904290199279785, -0.07459366321563721, -0.06014442443847656, -0.04569518566131592, -0.031245887279510498, -0.016796648502349854, -0.002347409725189209, 0.012101829051971436, 0.02655106782913208, 0.041000306606292725, 0.05544954538345337, 0.06989878416061401, 0.08434802293777466, 0.09879732131958008, 0.11324656009674072, 0.12769579887390137, 0.142145037651062, 0.15659427642822266, 0.1710435152053833, 0.18549275398254395, 0.1999419927597046, 0.21439123153686523, 0.22884052991867065, 0.2432897686958313, 0.25773900747299194, 0.2721882462501526, 0.28663748502731323]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.11787537485361099, -0.11513879150152206, -0.11240220814943314, -0.10966562479734421, -0.10692904144525528, -0.10419245809316635, -0.10145587474107742, -0.0987192913889885, -0.09598270803689957, -0.09324612468481064, -0.09050954133272171, -0.08777295798063278, -0.08503638207912445, -0.08229979872703552, -0.0795632153749466, -0.07682663202285767, -0.07409004867076874, -0.07135346531867981, -0.06861688196659088, -0.06588029861450195, -0.06314371526241302, -0.0604071281850338, -0.05767054483294487, -0.05493396520614624, -0.05219738185405731, -0.049460798501968384, -0.046724215149879456, -0.04398763179779053, -0.0412510484457016, -0.03851446509361267, -0.03577788174152374, -0.033041298389434814, -0.030304715037345886, -0.027568131685256958, -0.02483154833316803, -0.0220949649810791, -0.019358381628990173, -0.016621798276901245, -0.013885214924812317, -0.011148631572723389, -0.00841204822063446, -0.005675464868545532, -0.002938881516456604, -0.00020229816436767578, 0.0025342851877212524, 0.005270868539810181, 0.008007444441318512, 0.01074402779340744, 0.013480611145496368, 0.016217194497585297, 0.018953777849674225, 0.021690361201763153, 0.02442694455385208, 0.02716352790594101, 0.029900111258029938, 0.032636694610118866, 0.035373277962207794, 0.03810986131429672, 0.04084644466638565, 0.04358302801847458, 0.04631961137056351, 0.049056194722652435, 0.051792778074741364, 0.05452936142683029, 0.05726594477891922]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 8.0, 7.0, 16.0, 17.0, 26.0, 34.0, 72.0, 130.0, 55.0, 41.0, 26.0, 19.0, 8.0, 7.0, 4.0, 4.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.131142258644104, -0.1279691755771637, -0.12479608505964279, -0.12162300199270248, -0.11844991892576218, -0.11527682840824127, -0.11210374534130096, -0.10893066227436066, -0.10575757920742035, -0.10258448868989944, -0.09941140562295914, -0.09623831510543823, -0.09306523203849792, -0.08989214897155762, -0.08671906590461731, -0.083545982837677, -0.0803728923201561, -0.07719980180263519, -0.07402671873569489, -0.07085363566875458, -0.06768055260181427, -0.06450746208429337, -0.06133437901735306, -0.05816129595041275, -0.054988205432891846, -0.05181512236595154, -0.04864203929901123, -0.04546895623207092, -0.04229586571455002, -0.03912278264760971, -0.0359496995806694, -0.0327766090631485, -0.02960352599620819, -0.026430442929267883, -0.02325735241174698, -0.02008426934480667, -0.016911186277866364, -0.013738095760345459, -0.010565012693405151, -0.007391929626464844, -0.004218846559524536, -0.0010457634925842285, 0.002127334475517273, 0.005300417542457581, 0.008473500609397888, 0.011646583676338196, 0.014819666743278503, 0.01799274981021881, 0.021165847778320312, 0.02433893084526062, 0.027512013912200928, 0.030685096979141235, 0.03385818004608154, 0.03703126311302185, 0.04020434617996216, 0.04337744414806366, 0.04655052721500397, 0.049723610281944275, 0.05289669334888458, 0.05606977641582489, 0.0592428594827652, 0.0624159574508667, 0.065589040517807, 0.06876212358474731, 0.07193520665168762]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.39327704906463623, -0.3834489583969116, -0.373620867729187, -0.3637927770614624, -0.3539646565914154, -0.3441365659236908, -0.3343084752559662, -0.3244803845882416, -0.31465229392051697, -0.30482417345046997, -0.29499608278274536, -0.28516799211502075, -0.27533990144729614, -0.26551181077957153, -0.2556837201118469, -0.24585561454296112, -0.2360275238752365, -0.2261994332075119, -0.2163713276386261, -0.2065432369709015, -0.19671514630317688, -0.18688704073429108, -0.17705895006656647, -0.16723085939884186, -0.15740275382995605, -0.14757466316223145, -0.13774657249450684, -0.12791848182678223, -0.11809039115905762, -0.10826227068901062, -0.09843418002128601, -0.0886060893535614, -0.07877799868583679, -0.06894990801811218, -0.05912181735038757, -0.049293726682662964, -0.03946560621261597, -0.029637515544891357, -0.019809424877166748, -0.009981334209442139, -0.0001532435417175293, 0.00967484712600708, 0.019502967596054077, 0.029331058263778687, 0.039159148931503296, 0.048987239599227905, 0.058815330266952515, 0.06864342093467712, 0.07847154140472412, 0.08829963207244873, 0.09812772274017334, 0.10795581340789795, 0.11778390407562256, 0.12761199474334717, 0.13744008541107178, 0.1472681760787964, 0.157096266746521, 0.1669243574142456, 0.176752507686615, 0.1865805983543396, 0.1964086890220642, 0.20623677968978882, 0.21606487035751343, 0.22589296102523804, 0.23572105169296265]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04487817361950874, -0.04364214092493057, -0.0424061119556427, -0.04117007926106453, -0.03993404656648636, -0.038698017597198486, -0.037461984902620316, -0.036225952208042145, -0.03498992323875427, -0.0337538905441761, -0.03251785784959793, -0.03128182888031006, -0.030045796185731888, -0.028809763491153717, -0.027573732659220695, -0.026337699964642525, -0.025101669132709503, -0.02386563830077648, -0.02262960560619831, -0.02139357477426529, -0.02015754207968712, -0.018921511247754097, -0.017685480415821075, -0.016449447721242905, -0.015213416889309883, -0.013977386057376862, -0.01274135336279869, -0.01150532066822052, -0.010269291698932648, -0.009033259004354477, -0.007797226309776306, -0.006561197340488434, -0.005325164645910263, -0.004089131951332092, -0.00285310298204422, -0.0016170702874660492, -0.0003810375928878784, 0.0008549913763999939, 0.0020910240709781647, 0.0033270567655563354, 0.004563089460134506, 0.0057991184294223785, 0.007035151124000549, 0.00827118381857872, 0.009507212787866592, 0.010743245482444763, 0.011979278177022934, 0.013215307146310806, 0.014451339840888977, 0.015687372535467148, 0.01692340150475502, 0.01815943792462349, 0.01939546689391136, 0.020631495863199234, 0.021867532283067703, 0.023103561252355576, 0.024339590221643448, 0.025575626641511917, 0.02681165561079979, 0.028047684580087662, 0.02928372099995613, 0.030519749969244003, 0.031755778938531876, 0.032991815358400345, 0.03422784432768822]}, "_runtime": 14693.938326835632, "_timestamp": 1585612063.5711963, "_step": 398}
{"Episode reward": -88.40973018655984, "Episode length": 999, "Policy Loss": 0.0009977123700082302, "Value Loss": 0.0008227413054555655, "_runtime": 14695.585522174835, "_timestamp": 1585612065.2183917, "_step": 399}
{"Episode reward": -88.8331909926335, "Episode length": 999, "Policy Loss": -0.00024140605819411576, "Value Loss": 0.0007548480061814189, "_runtime": 14697.203620195389, "_timestamp": 1585612066.8364897, "_step": 400}
{"Episode reward": -90.76596908737639, "Episode length": 999, "Policy Loss": -0.0059828972443938255, "Value Loss": 0.0006506792851723731, "_runtime": 14698.807335138321, "_timestamp": 1585612068.4402046, "_step": 401}
{"Episode reward": -90.17261746479203, "Episode length": 999, "Policy Loss": -0.0033408862072974443, "Value Loss": 0.0006769523024559021, "_runtime": 14700.410217761993, "_timestamp": 1585612070.0430872, "_step": 402}
{"Episode reward": -88.80731994631358, "Episode length": 999, "Policy Loss": -0.0010427412344142795, "Value Loss": 0.000772014434915036, "_runtime": 14702.024904489517, "_timestamp": 1585612071.657774, "_step": 403}
{"Episode reward": -90.0123805151766, "Episode length": 999, "Policy Loss": -0.0020937665831297636, "Value Loss": 0.0006687217392027378, "_runtime": 14703.642876625061, "_timestamp": 1585612073.275746, "_step": 404}
{"Episode reward": -89.06141287079902, "Episode length": 999, "Policy Loss": -0.0015327857108786702, "Value Loss": 0.000742435222491622, "_runtime": 14705.24668431282, "_timestamp": 1585612074.8795538, "_step": 405}
{"Episode reward": -87.789808604173, "Episode length": 999, "Policy Loss": 0.002347614150494337, "Value Loss": 0.000827333249617368, "_runtime": 14706.851419448853, "_timestamp": 1585612076.484289, "_step": 406}
{"Episode reward": -84.96360407223638, "Episode length": 999, "Policy Loss": 0.012364408932626247, "Value Loss": 0.0009956118883565068, "_runtime": 14708.45748591423, "_timestamp": 1585612078.0903554, "_step": 407}
{"Episode reward": -85.85332086772767, "Episode length": 999, "Policy Loss": 0.007996183820068836, "Value Loss": 0.0009354589274153113, "_runtime": 14710.062192440033, "_timestamp": 1585612079.695062, "_step": 408}
{"Episode reward": -86.96926969093539, "Episode length": 999, "Policy Loss": 0.004061908461153507, "Value Loss": 0.0008757371688261628, "_runtime": 14711.680584430695, "_timestamp": 1585612081.313454, "_step": 409}
{"Episode reward": -86.15213602860841, "Episode length": 999, "Policy Loss": 0.004941556602716446, "Value Loss": 0.0009328433079645038, "_runtime": 14713.272915840149, "_timestamp": 1585612082.9057853, "_step": 410}
{"Episode reward": -88.9787096123642, "Episode length": 999, "Policy Loss": -0.0025373324751853943, "Value Loss": 0.0007486801478080451, "_runtime": 14714.877411842346, "_timestamp": 1585612084.5102813, "_step": 411}
{"Episode reward": -88.86280215363195, "Episode length": 999, "Policy Loss": -0.0008043506531976163, "Value Loss": 0.0008028740994632244, "_runtime": 14716.482102394104, "_timestamp": 1585612086.1149719, "_step": 412}
{"Episode reward": -88.2826867001373, "Episode length": 999, "Policy Loss": -0.0010223324643447995, "Value Loss": 0.0007729331264272332, "_runtime": 14718.124611139297, "_timestamp": 1585612087.7574806, "_step": 413}
{"Episode reward": -90.0430918385175, "Episode length": 999, "Policy Loss": -0.004075782373547554, "Value Loss": 0.0006815615925006568, "_runtime": 14719.728598117828, "_timestamp": 1585612089.3614676, "_step": 414}
{"Episode reward": -90.49701915320618, "Episode length": 999, "Policy Loss": -0.005736507009714842, "Value Loss": 0.0006452021189033985, "_runtime": 14721.344651699066, "_timestamp": 1585612090.9775212, "_step": 415}
{"Episode reward": -88.75498229094183, "Episode length": 999, "Policy Loss": 2.562568806752097e-05, "Value Loss": 0.0007804894703440368, "_runtime": 14722.947401046753, "_timestamp": 1585612092.5802705, "_step": 416}
{"Episode reward": -86.90814479501236, "Episode length": 999, "Policy Loss": 0.0056624626740813255, "Value Loss": 0.0008680099272169173, "_runtime": 14724.548708200455, "_timestamp": 1585612094.1815777, "_step": 417}
{"Episode reward": -87.96852398348946, "Episode length": 999, "Policy Loss": 0.0036390547174960375, "Value Loss": 0.0008143004379235208, "_runtime": 14726.16678762436, "_timestamp": 1585612095.799657, "_step": 418}
{"Episode reward": -86.29949372224819, "Episode length": 999, "Policy Loss": 0.008301385678350925, "Value Loss": 0.0009008487686514854, "_runtime": 14727.773095607758, "_timestamp": 1585612097.405965, "_step": 419}
{"Episode reward": -87.61812541351512, "Episode length": 999, "Policy Loss": 0.0026032577734440565, "Value Loss": 0.0008458981174044311, "_runtime": 14729.376172065735, "_timestamp": 1585612099.0090415, "_step": 420}
{"Episode reward": -88.33903587279546, "Episode length": 999, "Policy Loss": 0.000420906872022897, "Value Loss": 0.0007899418706074357, "_runtime": 14730.98452925682, "_timestamp": 1585612100.6173987, "_step": 421}
{"Episode reward": -89.38743497210481, "Episode length": 999, "Policy Loss": -0.003645713208243251, "Value Loss": 0.0007016285671852529, "_runtime": 14732.587224721909, "_timestamp": 1585612102.2200942, "_step": 422}
{"Episode reward": -88.1862629266358, "Episode length": 999, "Policy Loss": 0.00055758684175089, "Value Loss": 0.0008106884779408574, "_runtime": 14734.184829235077, "_timestamp": 1585612103.8176987, "_step": 423}
{"Episode reward": -90.99475690572481, "Episode length": 999, "Policy Loss": -0.006507956422865391, "Value Loss": 0.0006427380722016096, "_runtime": 14735.781067371368, "_timestamp": 1585612105.4139369, "_step": 424}
{"Episode reward": -88.16279636653348, "Episode length": 999, "Policy Loss": -0.0016178799560293555, "Value Loss": 0.0008043922134675086, "_runtime": 14737.375041007996, "_timestamp": 1585612107.0079105, "_step": 425}
{"Episode reward": -89.45188206155927, "Episode length": 999, "Policy Loss": -0.0041810921393334866, "Value Loss": 0.0007350718369707465, "_runtime": 14738.974605321884, "_timestamp": 1585612108.6074748, "_step": 426}
{"Episode reward": -90.27624548561565, "Episode length": 999, "Policy Loss": -0.004520362708717585, "Value Loss": 0.000680029799696058, "_runtime": 14740.579308271408, "_timestamp": 1585612110.2121778, "_step": 427}
{"Episode reward": -87.7969354836891, "Episode length": 999, "Policy Loss": 0.002855126280337572, "Value Loss": 0.0008166604093275964, "_runtime": 14742.212903738022, "_timestamp": 1585612111.8457732, "_step": 428}
{"Episode reward": -86.26535964861722, "Episode length": 999, "Policy Loss": 0.006968813482671976, "Value Loss": 0.0009377439855597913, "_runtime": 14743.817655086517, "_timestamp": 1585612113.4505246, "_step": 429}
{"Episode reward": -88.14903139509124, "Episode length": 999, "Policy Loss": 0.0002847770228981972, "Value Loss": 0.0008321916102431715, "_runtime": 14745.412704467773, "_timestamp": 1585612115.045574, "_step": 430}
{"Episode reward": -87.57484669642918, "Episode length": 999, "Policy Loss": 0.0018575857393443584, "Value Loss": 0.0008620974258519709, "_runtime": 14747.01726770401, "_timestamp": 1585612116.6501372, "_step": 431}
{"Episode reward": -88.63368129134037, "Episode length": 999, "Policy Loss": -0.0013601320097222924, "Value Loss": 0.0007658349932171404, "_runtime": 14748.609616994858, "_timestamp": 1585612118.2424865, "_step": 432}
{"Episode reward": -87.65118769990944, "Episode length": 999, "Policy Loss": 0.0026665818877518177, "Value Loss": 0.0008191863307729363, "_runtime": 14750.201371908188, "_timestamp": 1585612119.8342414, "_step": 433}
{"Episode reward": -89.21784060244136, "Episode length": 999, "Policy Loss": -0.002643131883814931, "Value Loss": 0.0007320167496800423, "_runtime": 14751.806573152542, "_timestamp": 1585612121.4394426, "_step": 434}
{"Episode reward": -89.15000401033907, "Episode length": 999, "Policy Loss": -0.0033515538088977337, "Value Loss": 0.0007620943360961974, "_runtime": 14753.413183450699, "_timestamp": 1585612123.046053, "_step": 435}
{"Episode reward": -88.42829963814407, "Episode length": 999, "Policy Loss": 0.0016349725192412734, "Value Loss": 0.000797075976151973, "_runtime": 14755.017684459686, "_timestamp": 1585612124.650554, "_step": 436}
{"Episode reward": -88.88581843160688, "Episode length": 999, "Policy Loss": -0.0008447945583611727, "Value Loss": 0.0007350448286160827, "_runtime": 14756.61108160019, "_timestamp": 1585612126.243951, "_step": 437}
{"Episode reward": -87.82604867352602, "Episode length": 999, "Policy Loss": 0.0024768279399722815, "Value Loss": 0.0007815442513674498, "_runtime": 14758.215833902359, "_timestamp": 1585612127.8487034, "_step": 438}
{"Episode reward": -90.33738865382432, "Episode length": 999, "Policy Loss": -0.006435601972043514, "Value Loss": 0.0006665459368377924, "_runtime": 14759.809530258179, "_timestamp": 1585612129.4423997, "_step": 439}
{"Episode reward": -86.04751441594708, "Episode length": 999, "Policy Loss": 0.005194996949285269, "Value Loss": 0.0009011153015308082, "_runtime": 14761.412947416306, "_timestamp": 1585612131.045817, "_step": 440}
{"Episode reward": -87.3000467976295, "Episode length": 999, "Policy Loss": 0.002113256836310029, "Value Loss": 0.0008691065013408661, "_runtime": 14763.009756326675, "_timestamp": 1585612132.6426258, "_step": 441}
{"Episode reward": -89.56663324899783, "Episode length": 999, "Policy Loss": -0.00326324999332428, "Value Loss": 0.0007461360655725002, "_runtime": 14764.593595981598, "_timestamp": 1585612134.2264655, "_step": 442}
{"Episode reward": -88.5967037232164, "Episode length": 999, "Policy Loss": 0.00025245497818104923, "Value Loss": 0.0007819903548806906, "_runtime": 14766.226940870285, "_timestamp": 1585612135.8598104, "_step": 443}
{"Episode reward": -89.03163364295392, "Episode length": 999, "Policy Loss": -0.0034554817248135805, "Value Loss": 0.0007484236848540604, "_runtime": 14767.825845956802, "_timestamp": 1585612137.4587154, "_step": 444}
{"Episode reward": -90.73403987374566, "Episode length": 999, "Policy Loss": -0.006327808368951082, "Value Loss": 0.0006460018339566886, "_runtime": 14769.427732467651, "_timestamp": 1585612139.060602, "_step": 445}
{"Episode reward": -89.1837107018174, "Episode length": 999, "Policy Loss": -0.0015841490821912885, "Value Loss": 0.000774557760450989, "_runtime": 14771.03400683403, "_timestamp": 1585612140.6668763, "_step": 446}
{"Episode reward": -87.88216229055071, "Episode length": 999, "Policy Loss": 0.0033240830525755882, "Value Loss": 0.0007458680775016546, "_runtime": 14772.630881547928, "_timestamp": 1585612142.263751, "_step": 447}
{"Episode reward": -89.865720899295, "Episode length": 999, "Policy Loss": -0.00433287164196372, "Value Loss": 0.0006878701387904584, "_runtime": 14774.223098516464, "_timestamp": 1585612143.855968, "_step": 448}
{"Episode reward": -90.57844056326596, "Episode length": 999, "Policy Loss": -0.005917062517255545, "Value Loss": 0.0006956759025342762, "_runtime": 14775.827081918716, "_timestamp": 1585612145.4599514, "_step": 449}
{"Episode reward": -87.34162945185741, "Episode length": 999, "Policy Loss": 0.0018253427697345614, "Value Loss": 0.0008438138756901026, "_runtime": 14777.420358181, "_timestamp": 1585612147.0532277, "_step": 450}
{"Episode reward": -90.01086891474601, "Episode length": 999, "Policy Loss": -0.0029057515785098076, "Value Loss": 0.0006724420236423612, "_runtime": 14779.016379356384, "_timestamp": 1585612148.6492488, "_step": 451}
{"Episode reward": -88.41067056435097, "Episode length": 999, "Policy Loss": -0.0013484256342053413, "Value Loss": 0.0007862620404921472, "_runtime": 14780.622513532639, "_timestamp": 1585612150.255383, "_step": 452}
{"Episode reward": -87.97820396609657, "Episode length": 999, "Policy Loss": 5.100057023810223e-05, "Value Loss": 0.0007996323984116316, "_runtime": 14782.2286901474, "_timestamp": 1585612151.8615596, "_step": 453}
{"Episode reward": -88.8923969773097, "Episode length": 999, "Policy Loss": 0.0004061587678734213, "Value Loss": 0.0007733344100415707, "_runtime": 14783.823363780975, "_timestamp": 1585612153.4562333, "_step": 454}
{"Episode reward": -89.79251694436604, "Episode length": 999, "Policy Loss": -0.005955142434686422, "Value Loss": 0.0007129842997528613, "_runtime": 14785.417754411697, "_timestamp": 1585612155.050624, "_step": 455}
{"Episode reward": -88.96241997446263, "Episode length": 999, "Policy Loss": -0.0033846988808363676, "Value Loss": 0.0007369188824668527, "_runtime": 14787.023390769958, "_timestamp": 1585612156.6562603, "_step": 456}
{"Episode reward": -88.63841694227722, "Episode length": 999, "Policy Loss": -0.0014152496587485075, "Value Loss": 0.0007649781182408333, "_runtime": 14788.61743736267, "_timestamp": 1585612158.2503068, "_step": 457}
{"Episode reward": -90.08309325417828, "Episode length": 999, "Policy Loss": -0.003131536301225424, "Value Loss": 0.0006862971349619329, "_runtime": 14790.260676383972, "_timestamp": 1585612159.8935459, "_step": 458}
{"Episode reward": -87.34085599323653, "Episode length": 999, "Policy Loss": -0.0001352963299723342, "Value Loss": 0.0008508427417837083, "_runtime": 14791.875872612, "_timestamp": 1585612161.508742, "_step": 459}
{"Episode reward": -88.66620916138835, "Episode length": 999, "Policy Loss": 0.0002652631083037704, "Value Loss": 0.0007864995277486742, "_runtime": 14793.480474710464, "_timestamp": 1585612163.1133442, "_step": 460}
{"Episode reward": -90.68477180145827, "Episode length": 999, "Policy Loss": -0.005594018381088972, "Value Loss": 0.0006608761032111943, "_runtime": 14795.097227573395, "_timestamp": 1585612164.730097, "_step": 461}
{"Episode reward": -90.68555718753925, "Episode length": 999, "Policy Loss": -0.005955508444458246, "Value Loss": 0.0006418309058062732, "_runtime": 14796.70352602005, "_timestamp": 1585612166.3363955, "_step": 462}
{"Episode reward": -89.09827516382427, "Episode length": 999, "Policy Loss": -0.0020375107415020466, "Value Loss": 0.0007377037545666099, "_runtime": 14798.29562330246, "_timestamp": 1585612167.9284928, "_step": 463}
{"Episode reward": -87.89141873402663, "Episode length": 999, "Policy Loss": 0.0030872169882059097, "Value Loss": 0.0008281564223580062, "_runtime": 14799.902100801468, "_timestamp": 1585612169.5349703, "_step": 464}
{"Episode reward": -90.69296086595368, "Episode length": 999, "Policy Loss": -0.005254431627690792, "Value Loss": 0.0006459002033807337, "_runtime": 14801.506606340408, "_timestamp": 1585612171.1394758, "_step": 465}
{"Episode reward": -89.54785259968187, "Episode length": 999, "Policy Loss": -0.001462601707316935, "Value Loss": 0.0007326834020204842, "_runtime": 14803.125366210938, "_timestamp": 1585612172.7582357, "_step": 466}
{"Episode reward": -88.0594791100746, "Episode length": 999, "Policy Loss": 0.0013339039869606495, "Value Loss": 0.0007960466318763793, "_runtime": 14804.731232881546, "_timestamp": 1585612174.3641024, "_step": 467}
{"Episode reward": -89.77860329660705, "Episode length": 999, "Policy Loss": -0.0022444056812673807, "Value Loss": 0.0007080219220370054, "_runtime": 14806.346532583237, "_timestamp": 1585612175.979402, "_step": 468}
{"Episode reward": -87.07201261185521, "Episode length": 999, "Policy Loss": 0.005707536358386278, "Value Loss": 0.0008890326134860516, "_runtime": 14807.960721731186, "_timestamp": 1585612177.5935912, "_step": 469}
{"Episode reward": -88.22413485110756, "Episode length": 999, "Policy Loss": 0.0016791083617135882, "Value Loss": 0.0008001560345292091, "_runtime": 14809.575379133224, "_timestamp": 1585612179.2082486, "_step": 470}
{"Episode reward": -89.94117918044677, "Episode length": 999, "Policy Loss": -0.00209670327603817, "Value Loss": 0.0006895138649269938, "_runtime": 14811.193266391754, "_timestamp": 1585612180.8261359, "_step": 471}
{"Episode reward": -88.26949628786704, "Episode length": 999, "Policy Loss": 0.0019842723850160837, "Value Loss": 0.0008296006126329303, "_runtime": 14812.809092760086, "_timestamp": 1585612182.4419622, "_step": 472}
{"Episode reward": -87.96864684185822, "Episode length": 999, "Policy Loss": 0.0051274471916258335, "Value Loss": 0.0007916647009551525, "_runtime": 14814.454936027527, "_timestamp": 1585612184.0878055, "_step": 473}
{"Episode reward": -87.13484712073529, "Episode length": 999, "Policy Loss": 0.00281210127286613, "Value Loss": 0.0008626032504253089, "_runtime": 14816.060982942581, "_timestamp": 1585612185.6938524, "_step": 474}
{"Episode reward": -86.78779446013704, "Episode length": 999, "Policy Loss": 0.0038140295073390007, "Value Loss": 0.0008833081810735166, "_runtime": 14817.668118476868, "_timestamp": 1585612187.300988, "_step": 475}
{"Episode reward": -86.66325690373426, "Episode length": 999, "Policy Loss": 0.006375052034854889, "Value Loss": 0.0009064361802302301, "_runtime": 14819.282313346863, "_timestamp": 1585612188.9151828, "_step": 476}
{"Episode reward": -86.54313172295424, "Episode length": 999, "Policy Loss": 0.008324614726006985, "Value Loss": 0.0008881537360139191, "_runtime": 14820.888322353363, "_timestamp": 1585612190.5211918, "_step": 477}
{"Episode reward": -89.00489606138147, "Episode length": 999, "Policy Loss": -0.0022024735808372498, "Value Loss": 0.0007092971936799586, "_runtime": 14822.50508570671, "_timestamp": 1585612192.1379552, "_step": 478}
{"Episode reward": -89.33535003163863, "Episode length": 999, "Policy Loss": -0.0016343028983101249, "Value Loss": 0.0007247001049108803, "_runtime": 14824.111005067825, "_timestamp": 1585612193.7438745, "_step": 479}
{"Episode reward": -89.35317378804132, "Episode length": 999, "Policy Loss": -0.0017610711511224508, "Value Loss": 0.0007173509802669287, "_runtime": 14825.715617656708, "_timestamp": 1585612195.3484871, "_step": 480}
{"Episode reward": -89.07766658475899, "Episode length": 999, "Policy Loss": -0.0024374392814934254, "Value Loss": 0.0007506249821744859, "_runtime": 14827.351041078568, "_timestamp": 1585612196.9839106, "_step": 481}
{"Episode reward": -88.13099288457406, "Episode length": 999, "Policy Loss": -0.00035467243287712336, "Value Loss": 0.0008435124764218926, "_runtime": 14828.955127716064, "_timestamp": 1585612198.5879972, "_step": 482}
{"Episode reward": -89.39875423240171, "Episode length": 999, "Policy Loss": -0.0029655711259692907, "Value Loss": 0.0007207000744529068, "_runtime": 14830.550057411194, "_timestamp": 1585612200.182927, "_step": 483}
{"Episode reward": -88.12319557059527, "Episode length": 999, "Policy Loss": 1.3761138689005747e-05, "Value Loss": 0.0008093676879070699, "_runtime": 14832.146376132965, "_timestamp": 1585612201.7792456, "_step": 484}
{"Episode reward": -86.02102063537234, "Episode length": 999, "Policy Loss": 0.007493235170841217, "Value Loss": 0.0009331702603958547, "_runtime": 14833.751530647278, "_timestamp": 1585612203.3844001, "_step": 485}
{"Episode reward": -88.19268097288705, "Episode length": 999, "Policy Loss": 0.0018348000012338161, "Value Loss": 0.0007946244440972805, "_runtime": 14835.356865167618, "_timestamp": 1585612204.9897346, "_step": 486}
{"Episode reward": -88.13008445306549, "Episode length": 999, "Policy Loss": -0.000834807229693979, "Value Loss": 0.0008269057143479586, "_runtime": 14836.987382411957, "_timestamp": 1585612206.620252, "_step": 487}
{"Episode reward": -86.91673871527438, "Episode length": 999, "Policy Loss": 0.004190321546047926, "Value Loss": 0.0008736807503737509, "_runtime": 14838.57847571373, "_timestamp": 1585612208.2113452, "_step": 488}
{"Episode reward": -90.03826209678479, "Episode length": 999, "Policy Loss": -0.0051638237200677395, "Value Loss": 0.000693925132509321, "_runtime": 14840.182092666626, "_timestamp": 1585612209.8149621, "_step": 489}
{"Episode reward": -88.86758333322864, "Episode length": 999, "Policy Loss": -0.0010652244091033936, "Value Loss": 0.0007677535177208483, "_runtime": 14841.786346912384, "_timestamp": 1585612211.4192164, "_step": 490}
{"Episode reward": -88.8897572403912, "Episode length": 999, "Policy Loss": -0.0031201569363474846, "Value Loss": 0.0007501390646211803, "_runtime": 14843.37947845459, "_timestamp": 1585612213.012348, "_step": 491}
{"Episode reward": -88.93509455980563, "Episode length": 999, "Policy Loss": -0.003806525841355324, "Value Loss": 0.0007382702315226197, "_runtime": 14844.98003578186, "_timestamp": 1585612214.6129053, "_step": 492}
{"Episode reward": -88.7927757475645, "Episode length": 999, "Policy Loss": 0.0002831317251548171, "Value Loss": 0.0007204952999018133, "_runtime": 14846.575088262558, "_timestamp": 1585612216.2079577, "_step": 493}
{"Episode reward": -90.80199399032546, "Episode length": 999, "Policy Loss": -0.007337313611060381, "Value Loss": 0.0006491458043456078, "_runtime": 14848.182075500488, "_timestamp": 1585612217.814945, "_step": 494}
{"Episode reward": -87.94553082553006, "Episode length": 999, "Policy Loss": -9.97940733213909e-05, "Value Loss": 0.0008131140493787825, "_runtime": 14849.785863161087, "_timestamp": 1585612219.4187326, "_step": 495}
{"Episode reward": -90.87397852339858, "Episode length": 999, "Policy Loss": -0.00701185641810298, "Value Loss": 0.0006528968224301934, "_runtime": 14851.378682851791, "_timestamp": 1585612221.0115523, "_step": 496}
{"Episode reward": -87.50433980593908, "Episode length": 999, "Policy Loss": 0.0025366919580847025, "Value Loss": 0.0008318086620420218, "_runtime": 14852.973682165146, "_timestamp": 1585612222.6065516, "_step": 497}
{"Episode reward": -87.16613167773444, "Episode length": 999, "Policy Loss": 0.004573117010295391, "Value Loss": 0.0008578345295973122, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913, 0.20423348248004913]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.14857639372348785, -0.13912838697433472, -0.12968039512634277, -0.12023238837718964, -0.1107843890786171, -0.10133638978004456, -0.09188838303089142, -0.08244038373231888, -0.07299238443374634, -0.0635443851351738, -0.05409638583660126, -0.04464837908744812, -0.03520037978887558, -0.02575238049030304, -0.016304373741149902, -0.006856381893157959, 0.0025916248559951782, 0.012039631605148315, 0.02148762345314026, 0.030935630202293396, 0.04038362205028534, 0.04983162879943848, 0.059279635548591614, 0.06872762739658356, 0.0781756341457367, 0.08762364089488983, 0.09707163274288177, 0.10651962459087372, 0.11596764624118805, 0.12541563808918, 0.13486362993717194, 0.14431165158748627, 0.1537596434354782, 0.16320763528347015, 0.17265565693378448, 0.18210364878177643, 0.19155164062976837, 0.2009996622800827, 0.21044765412807465, 0.2198956459760666, 0.22934363782405853, 0.23879165947437286, 0.2482396513223648, 0.25768762826919556, 0.2671356797218323, 0.2765836715698242, 0.28603166341781616, 0.2954796552658081, 0.30492764711380005, 0.314375638961792, 0.3238236904144287, 0.33327168226242065, 0.3427196741104126, 0.35216766595840454, 0.3616156578063965, 0.3710637092590332, 0.38051170110702515, 0.3899596929550171, 0.39940768480300903, 0.408855676651001, 0.4183036684989929, 0.42775171995162964, 0.4371997117996216, 0.4466477036476135, 0.45609569549560547]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03683015704154968, -0.03534754738211632, -0.033864933997392654, -0.03238232433795929, -0.030899712815880775, -0.02941710129380226, -0.027934491634368896, -0.026451880112290382, -0.02496926859021187, -0.023486658930778503, -0.02200404740869999, -0.020521435886621475, -0.01903882622718811, -0.017556214705109596, -0.016073603183031082, -0.014590993523597717, -0.013108382001519203, -0.011625770479440689, -0.010143160820007324, -0.00866054929792881, -0.007177937775850296, -0.005695328116416931, -0.004212714731693268, -0.002730105072259903, -0.001247495412826538, 0.00023511797189712524, 0.0017177276313304901, 0.003200337290763855, 0.004682950675487518, 0.006165560334920883, 0.007648169994354248, 0.009130783379077911, 0.010613393038511276, 0.012096002697944641, 0.013578616082668304, 0.01506122574210167, 0.016543835401535034, 0.018026448786258698, 0.019509058445692062, 0.020991668105125427, 0.02247428148984909, 0.023956891149282455, 0.02543950080871582, 0.026922114193439484, 0.028404727578163147, 0.029887333512306213, 0.03136994689702988, 0.03285256028175354, 0.034335166215896606, 0.03581777960062027, 0.03730039298534393, 0.038782998919487, 0.04026561230421066, 0.041748225688934326, 0.04323083162307739, 0.044713445007801056, 0.04619605839252472, 0.047678664326667786, 0.04916127771139145, 0.05064389109611511, 0.05212649703025818, 0.05360911041498184, 0.055091723799705505, 0.05657432973384857, 0.058056943118572235]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 8.0, 8.0, 7.0, 18.0, 40.0, 61.0, 90.0, 92.0, 41.0, 42.0, 22.0, 10.0, 10.0, 8.0, 6.0, 8.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03260752558708191, -0.031057234853506088, -0.029506942257285118, -0.027956649661064148, -0.026406358927488327, -0.024856068193912506, -0.023305775597691536, -0.021755483001470566, -0.020205192267894745, -0.018654901534318924, -0.017104608938097954, -0.015554316341876984, -0.014004025608301163, -0.012453734874725342, -0.010903442278504372, -0.009353149682283401, -0.007802858948707581, -0.00625256821513176, -0.0047022756189107895, -0.0031519830226898193, -0.0016016922891139984, -5.140155553817749e-05, 0.001498892903327942, 0.003049183636903763, 0.004599474370479584, 0.006149765104055405, 0.007700055837631226, 0.009250350296497345, 0.010800641030073166, 0.012350931763648987, 0.013901226222515106, 0.015451516956090927, 0.017001807689666748, 0.01855209842324257, 0.02010238915681839, 0.02165268361568451, 0.02320297434926033, 0.02475326508283615, 0.02630355954170227, 0.02785385027527809, 0.029404141008853912, 0.030954435467720032, 0.032504722476005554, 0.034055016934871674, 0.03560531139373779, 0.037155598402023315, 0.038705892860889435, 0.04025617986917496, 0.04180647432804108, 0.043356768786907196, 0.04490705579519272, 0.04645735025405884, 0.04800763726234436, 0.04955793172121048, 0.0511082261800766, 0.05265851318836212, 0.05420880764722824, 0.05575910210609436, 0.05730938911437988, 0.058859683573246, 0.06040997803211212, 0.061960265040397644, 0.06351055949926376, 0.06506084650754929, 0.0666111409664154]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12589168548583984, -0.12061192095279694, -0.11533215641975403, -0.11005239933729172, -0.10477263480424881, -0.0994928702712059, -0.09421311318874359, -0.08893334865570068, -0.08365358412265778, -0.07837381958961487, -0.07309405505657196, -0.06781429797410965, -0.06253453344106674, -0.057254768908023834, -0.05197501182556152, -0.046695247292518616, -0.04141548275947571, -0.0361357182264328, -0.030855953693389893, -0.025576196610927582, -0.020296432077884674, -0.015016667544841766, -0.009736910462379456, -0.004457145929336548, 0.0008226186037063599, 0.006102383136749268, 0.011382147669792175, 0.016661912202835083, 0.021941661834716797, 0.027221426367759705, 0.03250119090080261, 0.03778095543384552, 0.04306071996688843, 0.048340484499931335, 0.05362024903297424, 0.05890001356601715, 0.06417977809906006, 0.06945952773094177, 0.07473929226398468, 0.08001905679702759, 0.0852988213300705, 0.0905785858631134, 0.09585835039615631, 0.10113811492919922, 0.10641786456108093, 0.11169762909412384, 0.11697739362716675, 0.12225715816020966, 0.12753692269325256, 0.13281667232513428, 0.13809645175933838, 0.1433762013912201, 0.1486559808254242, 0.1539357304573059, 0.15921550989151, 0.16449525952339172, 0.16977500915527344, 0.17505478858947754, 0.18033453822135925, 0.18561431765556335, 0.19089406728744507, 0.19617384672164917, 0.20145359635353088, 0.20673337578773499, 0.2120131254196167]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.028236975893378258, -0.027185577899217606, -0.026134179905056953, -0.0250827819108963, -0.0240313857793808, -0.022979985922574997, -0.021928589791059494, -0.020877191796898842, -0.01982579380273819, -0.018774395808577538, -0.017722997814416885, -0.016671601682901382, -0.015620202757418156, -0.014568804763257504, -0.013517407700419426, -0.012466009706258774, -0.011414611712098122, -0.01036321371793747, -0.009311815723776817, -0.008260417729616165, -0.007209019735455513, -0.00615762360394001, -0.005106225609779358, -0.004054827615618706, -0.0030034296214580536, -0.0019520316272974014, -0.0009006336331367493, 0.0001507643610239029, 0.0012021604925394058, 0.002253558486700058, 0.00330495648086071, 0.0043563563376665115, 0.0054077524691820145, 0.006459148600697517, 0.007510548457503319, 0.008561944589018822, 0.009613344445824623, 0.010664740577340126, 0.011716140434145927, 0.01276753656566143, 0.013818936422467232, 0.014870332553982735, 0.015921728685498238, 0.01697312854230404, 0.018024524673819542, 0.019075924530625343, 0.020127320662140846, 0.021178720518946648, 0.02223011665046215, 0.023281512781977654, 0.024332912638783455, 0.025384308770298958, 0.02643570862710476, 0.027487104758620262, 0.028538504615426064, 0.029589900746941566, 0.03064129687845707, 0.03169269859790802, 0.03274409472942352, 0.033795490860939026, 0.03484688699245453, 0.03589828312397003, 0.03694968670606613, 0.038001082837581635, 0.03905247896909714]}, "_runtime": 14854.570498943329, "_timestamp": 1585612224.2033684, "_step": 498}
{"Episode reward": -86.49003320632521, "Episode length": 999, "Policy Loss": 0.005767589434981346, "Value Loss": 0.0008909266907721758, "_runtime": 14854.570498943329, "_timestamp": 1585612224.2033684, "_step": 499}
