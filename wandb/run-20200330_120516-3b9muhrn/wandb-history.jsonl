{"Episode reward": 57.54237650020467, "Episode length": 753, "Policy Loss": 0.06771716475486755, "Value Loss": 13.24308967590332, "_runtime": 14.541929006576538, "_timestamp": 1585569930.3865623, "_step": 0}
{"Episode reward": 60.06779316448509, "Episode length": 408, "Policy Loss": -7.676544666290283, "Value Loss": 3691.074951171875, "_runtime": 16.009855270385742, "_timestamp": 1585569931.8544886, "_step": 1}
{"Episode reward": -99.40777216246798, "Episode length": 999, "Policy Loss": -9.578344345092773, "Value Loss": 651.8654174804688, "_runtime": 17.48881959915161, "_timestamp": 1585569933.333453, "_step": 2}
{"Episode reward": -98.37826034229508, "Episode length": 999, "Policy Loss": -20.800344467163086, "Value Loss": 8934.17578125, "_runtime": 18.970394611358643, "_timestamp": 1585569934.815028, "_step": 3}
{"Episode reward": -97.78263393397805, "Episode length": 999, "Policy Loss": 21.822463989257812, "Value Loss": 6767.484375, "_runtime": 20.35856556892395, "_timestamp": 1585569936.203199, "_step": 4}
{"Episode reward": 8.820924609836197, "Episode length": 923, "Policy Loss": -0.1579989343881607, "Value Loss": 11190.05859375, "_runtime": 21.892395496368408, "_timestamp": 1585569937.7370288, "_step": 5}
{"Episode reward": -96.98077608857936, "Episode length": 999, "Policy Loss": -1.9452695846557617, "Value Loss": 1471.82666015625, "_runtime": 23.41554307937622, "_timestamp": 1585569939.2601764, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -17.090763092041016, "Value Loss": 532.0799560546875, "_runtime": 24.70086145401001, "_timestamp": 1585569940.5454948, "_step": 7}
{"Episode reward": 16.955530843991312, "Episode length": 842, "Policy Loss": 22.112253189086914, "Value Loss": 812.4505004882812, "_runtime": 25.676979780197144, "_timestamp": 1585569941.5216131, "_step": 8}
{"Episode reward": 37.11823295491424, "Episode length": 632, "Policy Loss": 38.56844711303711, "Value Loss": 4588.20654296875, "_runtime": 27.188461780548096, "_timestamp": 1585569943.0330951, "_step": 9}
{"Episode reward": -99.55485663828301, "Episode length": 999, "Policy Loss": 32.719730377197266, "Value Loss": 87.75051879882812, "_runtime": 28.699171543121338, "_timestamp": 1585569944.543805, "_step": 10}
{"Episode reward": -99.37665463361635, "Episode length": 999, "Policy Loss": 28.595842361450195, "Value Loss": 237.2871551513672, "_runtime": 30.196924448013306, "_timestamp": 1585569946.0415578, "_step": 11}
{"Episode reward": -99.84458765315217, "Episode length": 999, "Policy Loss": 24.983444213867188, "Value Loss": 120.0975112915039, "_runtime": 31.73205828666687, "_timestamp": 1585569947.5766916, "_step": 12}
{"Episode reward": -99.68734438909311, "Episode length": 999, "Policy Loss": 19.3870792388916, "Value Loss": 215.73251342773438, "_runtime": 33.26884150505066, "_timestamp": 1585569949.1134748, "_step": 13}
{"Episode reward": -99.70670685891389, "Episode length": 999, "Policy Loss": 19.03870391845703, "Value Loss": 451.1370544433594, "_runtime": 34.829602003097534, "_timestamp": 1585569950.6742353, "_step": 14}
{"Episode reward": -99.73902015623614, "Episode length": 999, "Policy Loss": 18.055492401123047, "Value Loss": 54.10107421875, "_runtime": 36.358232736587524, "_timestamp": 1585569952.202866, "_step": 15}
{"Episode reward": -99.80999295359803, "Episode length": 999, "Policy Loss": 17.63825035095215, "Value Loss": 77.34445190429688, "_runtime": 37.89078116416931, "_timestamp": 1585569953.7354145, "_step": 16}
{"Episode reward": -99.70751182308747, "Episode length": 999, "Policy Loss": 17.115549087524414, "Value Loss": 57.52802658081055, "_runtime": 39.43462610244751, "_timestamp": 1585569955.2792594, "_step": 17}
{"Episode reward": -99.69441773788864, "Episode length": 999, "Policy Loss": 16.268505096435547, "Value Loss": 49.11689376831055, "_runtime": 40.44198703765869, "_timestamp": 1585569956.2866204, "_step": 18}
{"Episode reward": 35.14543364148062, "Episode length": 650, "Policy Loss": 17.25282096862793, "Value Loss": 457.43505859375, "_runtime": 41.04832124710083, "_timestamp": 1585569956.8929546, "_step": 19}
{"Episode reward": 62.39300264480964, "Episode length": 377, "Policy Loss": 18.932336807250977, "Value Loss": 1620.31396484375, "_runtime": 42.18760323524475, "_timestamp": 1585569958.0322366, "_step": 20}
{"Episode reward": 24.515060248645042, "Episode length": 758, "Policy Loss": 19.316884994506836, "Value Loss": 1279.158203125, "_runtime": 42.93682384490967, "_timestamp": 1585569958.7814572, "_step": 21}
{"Episode reward": 51.13833827837329, "Episode length": 490, "Policy Loss": 23.964359283447266, "Value Loss": 1741.780029296875, "_runtime": 43.876511335372925, "_timestamp": 1585569959.7211447, "_step": 22}
{"Episode reward": 36.3379414888791, "Episode length": 638, "Policy Loss": 23.653139114379883, "Value Loss": 3988.772705078125, "_runtime": 45.38029360771179, "_timestamp": 1585569961.224927, "_step": 23}
{"Episode reward": -99.54996382349498, "Episode length": 999, "Policy Loss": 26.523469924926758, "Value Loss": 17.500539779663086, "_runtime": 46.866332054138184, "_timestamp": 1585569962.7109654, "_step": 24}
{"Episode reward": -99.65895944940719, "Episode length": 999, "Policy Loss": 27.778762817382812, "Value Loss": 1034.4404296875, "_runtime": 48.114758253097534, "_timestamp": 1585569963.9593916, "_step": 25}
{"Episode reward": 16.408931774134288, "Episode length": 839, "Policy Loss": 25.609542846679688, "Value Loss": 1723.978271484375, "_runtime": 48.88076949119568, "_timestamp": 1585569964.7254028, "_step": 26}
{"Episode reward": 51.52577465606696, "Episode length": 488, "Policy Loss": 20.62763023376465, "Value Loss": 660.942138671875, "_runtime": 50.3909273147583, "_timestamp": 1585569966.2355607, "_step": 27}
{"Episode reward": -99.61485863132846, "Episode length": 999, "Policy Loss": 12.451802253723145, "Value Loss": 84.87617492675781, "_runtime": 51.902533292770386, "_timestamp": 1585569967.7471666, "_step": 28}
{"Episode reward": -99.87911214327765, "Episode length": 999, "Policy Loss": 7.519303321838379, "Value Loss": 104.92962646484375, "_runtime": 53.39096808433533, "_timestamp": 1585569969.2356014, "_step": 29}
{"Episode reward": -99.66990794588207, "Episode length": 999, "Policy Loss": 4.869049549102783, "Value Loss": 56.01871109008789, "_runtime": 54.930997133255005, "_timestamp": 1585569970.7756305, "_step": 30}
{"Episode reward": -99.6685830871095, "Episode length": 999, "Policy Loss": 4.32154655456543, "Value Loss": 122.1282958984375, "_runtime": 55.69210171699524, "_timestamp": 1585569971.536735, "_step": 31}
{"Episode reward": 51.981718686385605, "Episode length": 481, "Policy Loss": 4.8054118156433105, "Value Loss": 134.53347778320312, "_runtime": 56.89934039115906, "_timestamp": 1585569972.7439737, "_step": 32}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": 3.4612743854522705, "Value Loss": 24.231773376464844, "_runtime": 58.46741080284119, "_timestamp": 1585569974.3120441, "_step": 33}
{"Episode reward": -99.75119370962936, "Episode length": 999, "Policy Loss": 3.091813087463379, "Value Loss": 15.32030963897705, "_runtime": 59.966203451156616, "_timestamp": 1585569975.8108368, "_step": 34}
{"Episode reward": -99.72588214375871, "Episode length": 999, "Policy Loss": 2.684211492538452, "Value Loss": 12.368072509765625, "_runtime": 61.467310667037964, "_timestamp": 1585569977.311944, "_step": 35}
{"Episode reward": -99.648977016825, "Episode length": 999, "Policy Loss": 1.4173405170440674, "Value Loss": 39.662132263183594, "_runtime": 62.10549545288086, "_timestamp": 1585569977.9501288, "_step": 36}
{"Episode reward": 60.34961599907809, "Episode length": 400, "Policy Loss": 2.614426374435425, "Value Loss": 144.8092498779297, "_runtime": 62.782482385635376, "_timestamp": 1585569978.6271157, "_step": 37}
{"Episode reward": 56.199999999999655, "Episode length": 438, "Policy Loss": 1.8291410207748413, "Value Loss": 110.7608871459961, "_runtime": 64.17782187461853, "_timestamp": 1585569980.0224552, "_step": 38}
{"Episode reward": 8.091254341766259, "Episode length": 920, "Policy Loss": -1.3659706115722656, "Value Loss": 164.11927795410156, "_runtime": 65.65574789047241, "_timestamp": 1585569981.5003812, "_step": 39}
{"Episode reward": -99.82173441017372, "Episode length": 999, "Policy Loss": -1.9555891752243042, "Value Loss": 114.89599609375, "_runtime": 67.12482237815857, "_timestamp": 1585569982.9694557, "_step": 40}
{"Episode reward": -99.70446561487486, "Episode length": 999, "Policy Loss": -2.790083408355713, "Value Loss": 13.698123931884766, "_runtime": 68.39080929756165, "_timestamp": 1585569984.2354426, "_step": 41}
{"Episode reward": 16.770945482398844, "Episode length": 833, "Policy Loss": -1.0646005868911743, "Value Loss": 58.634769439697266, "_runtime": 69.91738557815552, "_timestamp": 1585569985.762019, "_step": 42}
{"Episode reward": -99.81617086389893, "Episode length": 999, "Policy Loss": -1.256077527999878, "Value Loss": 9.21844482421875, "_runtime": 70.85456252098083, "_timestamp": 1585569986.6991959, "_step": 43}
{"Episode reward": 39.17208539672952, "Episode length": 610, "Policy Loss": 0.9970943331718445, "Value Loss": 17.13072395324707, "_runtime": 72.36182570457458, "_timestamp": 1585569988.206459, "_step": 44}
{"Episode reward": -99.72631637938181, "Episode length": 999, "Policy Loss": 1.308165431022644, "Value Loss": 1.5089126825332642, "_runtime": 73.58780646324158, "_timestamp": 1585569989.4324398, "_step": 45}
{"Episode reward": 20.380852698697964, "Episode length": 797, "Policy Loss": 3.119924306869507, "Value Loss": 24.77756690979004, "_runtime": 75.08362197875977, "_timestamp": 1585569990.9282553, "_step": 46}
{"Episode reward": -99.65553907030124, "Episode length": 999, "Policy Loss": 2.8623735904693604, "Value Loss": 17.50868034362793, "_runtime": 76.61763858795166, "_timestamp": 1585569992.462272, "_step": 47}
{"Episode reward": -99.60685633385881, "Episode length": 999, "Policy Loss": 3.325045347213745, "Value Loss": 18.351123809814453, "_runtime": 78.13128089904785, "_timestamp": 1585569993.9759142, "_step": 48}
{"Episode reward": -99.55867100199548, "Episode length": 999, "Policy Loss": 3.1903791427612305, "Value Loss": 33.467430114746094, "_runtime": 79.66331195831299, "_timestamp": 1585569995.5079453, "_step": 49}
{"Episode reward": -99.66239909271106, "Episode length": 999, "Policy Loss": 3.4211747646331787, "Value Loss": 3.4633326530456543, "_runtime": 81.23744750022888, "_timestamp": 1585569997.0820808, "_step": 50}
{"Episode reward": -99.61676886750362, "Episode length": 999, "Policy Loss": 3.286638021469116, "Value Loss": 7.412580966949463, "_runtime": 82.17878365516663, "_timestamp": 1585569998.023417, "_step": 51}
{"Episode reward": 39.145419207005176, "Episode length": 610, "Policy Loss": 4.88617467880249, "Value Loss": 44.17066955566406, "_runtime": 83.70083284378052, "_timestamp": 1585569999.5454662, "_step": 52}
{"Episode reward": -99.61652486142563, "Episode length": 999, "Policy Loss": 2.875248670578003, "Value Loss": 3.697275161743164, "_runtime": 84.8997049331665, "_timestamp": 1585570000.7443383, "_step": 53}
{"Episode reward": 22.578016163286648, "Episode length": 777, "Policy Loss": 3.5638315677642822, "Value Loss": 39.14654541015625, "_runtime": 86.40035510063171, "_timestamp": 1585570002.2449884, "_step": 54}
{"Episode reward": -99.62033116926185, "Episode length": 999, "Policy Loss": 3.0329785346984863, "Value Loss": 15.001764297485352, "_runtime": 87.92778086662292, "_timestamp": 1585570003.7724142, "_step": 55}
{"Episode reward": -99.6417484080929, "Episode length": 999, "Policy Loss": 1.7998765707015991, "Value Loss": 1.0696576833724976, "_runtime": 88.94460010528564, "_timestamp": 1585570004.7892334, "_step": 56}
{"Episode reward": 33.50870650052043, "Episode length": 667, "Policy Loss": 3.1366939544677734, "Value Loss": 20.90590476989746, "_runtime": 89.67673063278198, "_timestamp": 1585570005.521364, "_step": 57}
{"Episode reward": 53.69999999999962, "Episode length": 463, "Policy Loss": 2.967902898788452, "Value Loss": 23.742586135864258, "_runtime": 90.5596272945404, "_timestamp": 1585570006.4042606, "_step": 58}
{"Episode reward": 42.54855512555024, "Episode length": 575, "Policy Loss": 2.923707962036133, "Value Loss": 24.06744384765625, "_runtime": 91.08434796333313, "_timestamp": 1585570006.9289813, "_step": 59}
{"Episode reward": 67.14913636971596, "Episode length": 332, "Policy Loss": 4.035455703735352, "Value Loss": 39.6142463684082, "_runtime": 92.55943083763123, "_timestamp": 1585570008.4040642, "_step": 60}
{"Episode reward": -99.76215270620166, "Episode length": 999, "Policy Loss": 1.726644515991211, "Value Loss": 0.6438568830490112, "_runtime": 93.43323397636414, "_timestamp": 1585570009.2778673, "_step": 61}
{"Episode reward": 42.39999999999946, "Episode length": 576, "Policy Loss": 3.16886043548584, "Value Loss": 20.806154251098633, "_runtime": 93.80924105644226, "_timestamp": 1585570009.6538744, "_step": 62}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 4.7136640548706055, "Value Loss": 44.143436431884766, "_runtime": 95.30751943588257, "_timestamp": 1585570011.1521528, "_step": 63}
{"Episode reward": -99.67475350508329, "Episode length": 999, "Policy Loss": 2.5410239696502686, "Value Loss": 0.8927249312400818, "_runtime": 96.16482877731323, "_timestamp": 1585570012.009462, "_step": 64}
{"Episode reward": 43.85793932035397, "Episode length": 563, "Policy Loss": 3.842031955718994, "Value Loss": 21.331459045410156, "_runtime": 97.62742280960083, "_timestamp": 1585570013.4720562, "_step": 65}
{"Episode reward": -99.51792245594558, "Episode length": 999, "Policy Loss": 2.9657533168792725, "Value Loss": 3.278472423553467, "_runtime": 99.13145399093628, "_timestamp": 1585570014.9760873, "_step": 66}
{"Episode reward": -99.69044045701018, "Episode length": 999, "Policy Loss": 2.748025417327881, "Value Loss": 3.073253631591797, "_runtime": 100.11767196655273, "_timestamp": 1585570015.9623053, "_step": 67}
{"Episode reward": 34.39999999999945, "Episode length": 656, "Policy Loss": 3.9541447162628174, "Value Loss": 20.08355712890625, "_runtime": 100.73371171951294, "_timestamp": 1585570016.578345, "_step": 68}
{"Episode reward": 60.9987156985092, "Episode length": 391, "Policy Loss": 4.8885817527771, "Value Loss": 28.419946670532227, "_runtime": 102.24464845657349, "_timestamp": 1585570018.0892818, "_step": 69}
{"Episode reward": -99.73895130664903, "Episode length": 999, "Policy Loss": 2.575259208679199, "Value Loss": 3.439594030380249, "_runtime": 103.47979521751404, "_timestamp": 1585570019.3244286, "_step": 70}
{"Episode reward": 17.908827051305366, "Episode length": 823, "Policy Loss": 3.4760730266571045, "Value Loss": 14.053345680236816, "_runtime": 104.2447395324707, "_timestamp": 1585570020.0893729, "_step": 71}
{"Episode reward": 48.75772103385489, "Episode length": 513, "Policy Loss": 3.3399057388305664, "Value Loss": 21.65715980529785, "_runtime": 105.75262570381165, "_timestamp": 1585570021.597259, "_step": 72}
{"Episode reward": -99.56891856822048, "Episode length": 999, "Policy Loss": 1.8901447057724, "Value Loss": 0.9547211527824402, "_runtime": 107.22640442848206, "_timestamp": 1585570023.0710378, "_step": 73}
{"Episode reward": 5.09239277029522, "Episode length": 951, "Policy Loss": 2.0603220462799072, "Value Loss": 10.999258995056152, "_runtime": 107.79379892349243, "_timestamp": 1585570023.6384323, "_step": 74}
{"Episode reward": 63.22137264261231, "Episode length": 370, "Policy Loss": 2.5441315174102783, "Value Loss": 27.236671447753906, "_runtime": 108.38472437858582, "_timestamp": 1585570024.2293577, "_step": 75}
{"Episode reward": 61.799999999999734, "Episode length": 382, "Policy Loss": 2.3084723949432373, "Value Loss": 26.23349380493164, "_runtime": 109.87438178062439, "_timestamp": 1585570025.7190151, "_step": 76}
{"Episode reward": -99.64840210382688, "Episode length": 999, "Policy Loss": 0.30873987078666687, "Value Loss": 0.6653045415878296, "_runtime": 111.34916639328003, "_timestamp": 1585570027.1937997, "_step": 77}
{"Episode reward": -99.73395831347304, "Episode length": 999, "Policy Loss": 0.15187384188175201, "Value Loss": 1.453292965888977, "_runtime": 112.82280898094177, "_timestamp": 1585570028.6674423, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21430711448192596, "Value Loss": 2.425241470336914, "_runtime": 114.34952402114868, "_timestamp": 1585570030.1941574, "_step": 79}
{"Episode reward": -99.71611522684113, "Episode length": 999, "Policy Loss": -0.01750185526907444, "Value Loss": 1.7865666151046753, "_runtime": 115.10153889656067, "_timestamp": 1585570030.9461722, "_step": 80}
{"Episode reward": 52.09999793237035, "Episode length": 480, "Policy Loss": 1.4147695302963257, "Value Loss": 22.213441848754883, "_runtime": 116.62300896644592, "_timestamp": 1585570032.4676423, "_step": 81}
{"Episode reward": -99.8030030833776, "Episode length": 999, "Policy Loss": 0.017613302916288376, "Value Loss": 1.1003910303115845, "_runtime": 117.49658584594727, "_timestamp": 1585570033.3412192, "_step": 82}
{"Episode reward": 44.74138627052111, "Episode length": 554, "Policy Loss": 1.082367181777954, "Value Loss": 17.571060180664062, "_runtime": 118.7300238609314, "_timestamp": 1585570034.5746572, "_step": 83}
{"Episode reward": 17.062894390231378, "Episode length": 833, "Policy Loss": 1.2409449815750122, "Value Loss": 13.245016098022461, "_runtime": 120.04577565193176, "_timestamp": 1585570035.890409, "_step": 84}
{"Episode reward": 14.88573732156712, "Episode length": 853, "Policy Loss": 1.1166398525238037, "Value Loss": 11.608530044555664, "_runtime": 121.07136082649231, "_timestamp": 1585570036.9159942, "_step": 85}
{"Episode reward": 31.609217872912595, "Episode length": 687, "Policy Loss": 1.7027175426483154, "Value Loss": 14.661092758178711, "_runtime": 121.54230070114136, "_timestamp": 1585570037.386934, "_step": 86}
{"Episode reward": 71.09999999999987, "Episode length": 289, "Policy Loss": 2.63124680519104, "Value Loss": 33.60713195800781, "_runtime": 123.05669069290161, "_timestamp": 1585570038.901324, "_step": 87}
{"Episode reward": -99.55754402129102, "Episode length": 999, "Policy Loss": 0.6289101839065552, "Value Loss": 1.310848355293274, "_runtime": 124.56826639175415, "_timestamp": 1585570040.4128997, "_step": 88}
{"Episode reward": -99.73807007791335, "Episode length": 999, "Policy Loss": 0.6124905943870544, "Value Loss": 0.09902504831552505, "_runtime": 126.04932022094727, "_timestamp": 1585570041.8939536, "_step": 89}
{"Episode reward": -99.72750478843088, "Episode length": 999, "Policy Loss": 0.5583489537239075, "Value Loss": 0.520180881023407, "_runtime": 127.59599685668945, "_timestamp": 1585570043.4406302, "_step": 90}
{"Episode reward": -99.54767146679085, "Episode length": 999, "Policy Loss": 0.38452932238578796, "Value Loss": 0.08231671899557114, "_runtime": 129.14555859565735, "_timestamp": 1585570044.990192, "_step": 91}
{"Episode reward": -99.7057578474793, "Episode length": 999, "Policy Loss": 0.2483973354101181, "Value Loss": 0.023154636844992638, "_runtime": 130.45328330993652, "_timestamp": 1585570046.2979167, "_step": 92}
{"Episode reward": 17.446373140904015, "Episode length": 826, "Policy Loss": 1.0967986583709717, "Value Loss": 12.507378578186035, "_runtime": 132.00842952728271, "_timestamp": 1585570047.8530629, "_step": 93}
{"Episode reward": -99.63259781897513, "Episode length": 999, "Policy Loss": 0.0031162940431386232, "Value Loss": 0.011136192828416824, "_runtime": 133.5635163784027, "_timestamp": 1585570049.4081497, "_step": 94}
{"Episode reward": -99.61731314815704, "Episode length": 999, "Policy Loss": -0.05982144922018051, "Value Loss": 0.23311883211135864, "_runtime": 134.2816240787506, "_timestamp": 1585570050.1262574, "_step": 95}
{"Episode reward": 54.79424585224442, "Episode length": 454, "Policy Loss": 1.146408200263977, "Value Loss": 21.103466033935547, "_runtime": 135.82921743392944, "_timestamp": 1585570051.6738508, "_step": 96}
{"Episode reward": -99.55305365571265, "Episode length": 999, "Policy Loss": -0.2779735028743744, "Value Loss": 0.13319675624370575, "_runtime": 136.68946051597595, "_timestamp": 1585570052.5340939, "_step": 97}
{"Episode reward": 45.88499553602111, "Episode length": 544, "Policy Loss": 0.809736430644989, "Value Loss": 18.168508529663086, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186, 0.09075380861759186]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10820012539625168, -0.06105858460068703, -0.013917043805122375, 0.033224500715732574, 0.08036603778600693, 0.12750756740570068, 0.17464911937713623, 0.2217906415462494, 0.26893219351768494, 0.3160737454891205, 0.36321526765823364, 0.4103568196296692, 0.45749837160110474, 0.5046399235725403, 0.551781415939331, 0.5989229679107666, 0.6460645198822021, 0.6932060718536377, 0.7403476238250732, 0.787489116191864, 0.8346306681632996, 0.8817722201347351, 0.9289137721061707, 0.9760553240776062, 1.0231969356536865, 1.070338487625122, 1.1174800395965576, 1.1646214723587036, 1.2117630243301392, 1.2589045763015747, 1.3060461282730103, 1.3531876802444458, 1.4003292322158813, 1.447470784187317, 1.4946123361587524, 1.541753888130188, 1.5888954401016235, 1.636036992073059, 1.683178424835205, 1.7303199768066406, 1.7774615287780762, 1.8246030807495117, 1.8717446327209473, 1.9188861846923828, 1.9660277366638184, 2.013169288635254, 2.0603108406066895, 2.107452392578125, 2.1545939445495605, 2.201735496520996, 2.2488770484924316, 2.296018600463867, 2.3431601524353027, 2.3903017044067383, 2.4374430179595947, 2.4845845699310303, 2.531726121902466, 2.5788676738739014, 2.626009225845337, 2.6731507778167725, 2.720292329788208, 2.7674338817596436, 2.814575433731079, 2.8617169857025146, 2.90885853767395]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07639823108911514, -0.07139569520950317, -0.06639315187931061, -0.06139061599969864, -0.05638808012008667, -0.0513855405151844, -0.046383000910282135, -0.041380465030670166, -0.0363779254257679, -0.03137538582086563, -0.026372849941253662, -0.021370310336351395, -0.016367770731449127, -0.011365234851837158, -0.006362698972225189, -0.0013601556420326233, 0.0036423802375793457, 0.008644916117191315, 0.01364745944738388, 0.01864999532699585, 0.02365253120660782, 0.028655074536800385, 0.033657610416412354, 0.03866014629602432, 0.04366268962621689, 0.04866521805524826, 0.053667761385440826, 0.05867030471563339, 0.06367283314466476, 0.06867537647485733, 0.0736779198050499, 0.07868044823408127, 0.08368299156427383, 0.0886855348944664, 0.09368806332349777, 0.09869060665369034, 0.1036931499838829, 0.10869567841291428, 0.11369822174310684, 0.11870076507329941, 0.12370329350233078, 0.12870582938194275, 0.1337083876132965, 0.13871091604232788, 0.14371344447135925, 0.148716002702713, 0.15371853113174438, 0.15872105956077576, 0.16372361779212952, 0.1687261462211609, 0.17372867465019226, 0.17873123288154602, 0.1837337613105774, 0.18873628973960876, 0.19373884797096252, 0.1987413763999939, 0.20374390482902527, 0.20874646306037903, 0.2137489914894104, 0.21875151991844177, 0.22375407814979553, 0.2287566065788269, 0.23375913500785828, 0.23876169323921204, 0.2437642216682434]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 5.0, 0.0, 9.0, 12.0, 11.0, 11.0, 5.0, 3.0, 0.0, 2.0, 19.0, 358.0, 16.0, 13.0, 10.0, 5.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.3610321283340454, -0.33739179372787476, -0.3137514591217041, -0.29011112451553345, -0.2664707899093628, -0.24283047020435333, -0.21919015049934387, -0.19554981589317322, -0.17190948128700256, -0.1482691466808319, -0.12462881207466125, -0.1009884774684906, -0.07734817266464233, -0.05370783805847168, -0.030067503452301025, -0.006427168846130371, 0.017213165760040283, 0.04085350036621094, 0.06449383497238159, 0.08813416957855225, 0.1117745041847229, 0.13541480898857117, 0.1590551733970642, 0.18269550800323486, 0.20633578300476074, 0.2299761176109314, 0.25361645221710205, 0.2772567868232727, 0.30089712142944336, 0.324537456035614, 0.34817779064178467, 0.3718181252479553, 0.395458459854126, 0.41909879446029663, 0.4427391290664673, 0.46637946367263794, 0.4900197982788086, 0.5136601328849792, 0.5373004674911499, 0.5609408020973206, 0.5845811367034912, 0.6082214117050171, 0.6318617463111877, 0.6555020809173584, 0.6791424751281738, 0.7027827501296997, 0.7264231443405151, 0.750063419342041, 0.7737036943435669, 0.7973440885543823, 0.8209843635559082, 0.8446247577667236, 0.8682650327682495, 0.8919054269790649, 0.9155457019805908, 0.9391860961914062, 0.9628263711929321, 0.9864667654037476, 1.0101070404052734, 1.0337474346160889, 1.0573877096176147, 1.0810281038284302, 1.104668378829956, 1.1283087730407715, 1.1519490480422974]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-1.713539481163025, -1.6634230613708496, -1.6133067607879639, -1.5631903409957886, -1.5130739212036133, -1.4629576206207275, -1.4128412008285522, -1.362724781036377, -1.3126084804534912, -1.262492060661316, -1.2123756408691406, -1.1622593402862549, -1.1121429204940796, -1.0620265007019043, -1.0119102001190186, -0.9617937803268433, -0.9116774201393127, -0.8615610599517822, -0.8114446401596069, -0.7613282799720764, -0.7112119197845459, -0.6610954999923706, -0.6109791994094849, -0.5608627796173096, -0.5107463598251343, -0.46063005924224854, -0.41051363945007324, -0.36039721965789795, -0.3102809190750122, -0.2601644992828369, -0.21004807949066162, -0.15993177890777588, -0.10981535911560059, -0.05969893932342529, -0.00958263874053955, 0.04053378105163574, 0.09065020084381104, 0.14076650142669678, 0.19088292121887207, 0.24099934101104736, 0.2911156415939331, 0.34123194217681885, 0.3913484811782837, 0.44146478176116943, 0.4915810823440552, 0.54169762134552, 0.5918139219284058, 0.6419302225112915, 0.6920467615127563, 0.7421630620956421, 0.7922793626785278, 0.8423959016799927, 0.8925122022628784, 0.9426285028457642, 0.992745041847229, 1.0428613424301147, 1.0929776430130005, 1.1430941820144653, 1.193210482597351, 1.2433267831802368, 1.2934433221817017, 1.3435596227645874, 1.3936759233474731, 1.443792462348938, 1.4939087629318237]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.5039587616920471, -0.4881793260574341, -0.47239992022514343, -0.4566205143928528, -0.44084107875823975, -0.4250616431236267, -0.40928223729133606, -0.3935028314590454, -0.3777233958244324, -0.36194396018981934, -0.3461645543575287, -0.33038514852523804, -0.314605712890625, -0.29882627725601196, -0.2830468714237213, -0.26726746559143066, -0.2514880299568176, -0.2357085943222046, -0.21992918848991394, -0.2041497826576233, -0.18837034702301025, -0.17259091138839722, -0.15681150555610657, -0.14103209972381592, -0.12525266408920288, -0.10947322845458984, -0.0936938226222992, -0.07791441679000854, -0.06213498115539551, -0.04635554552078247, -0.03057613968849182, -0.014796733856201172, 0.0009827017784118652, 0.016762137413024902, 0.03254157304763794, 0.0483209490776062, 0.06410038471221924, 0.07987982034683228, 0.09565919637680054, 0.11143863201141357, 0.1272180676460266, 0.14299750328063965, 0.15877693891525269, 0.17455631494522095, 0.19033575057983398, 0.20611518621444702, 0.22189456224441528, 0.23767399787902832, 0.25345343351364136, 0.2692328691482544, 0.28501230478286743, 0.3007916808128357, 0.31657111644744873, 0.33235055208206177, 0.34812992811203003, 0.36390936374664307, 0.3796887993812561, 0.39546823501586914, 0.4112476706504822, 0.42702704668045044, 0.4428064823150635, 0.4585859179496765, 0.4743652939796448, 0.4901447296142578, 0.5059241652488708]}, "_runtime": 138.18745589256287, "_timestamp": 1585570054.0320892, "_step": 98}
{"Episode reward": -99.74636934006564, "Episode length": 999, "Policy Loss": -0.32499441504478455, "Value Loss": 0.1330905258655548, "_runtime": 139.6016755104065, "_timestamp": 1585570055.4463089, "_step": 99}
{"Episode reward": 8.839121396363211, "Episode length": 915, "Policy Loss": 0.2932024896144867, "Value Loss": 10.579551696777344, "_runtime": 141.09959888458252, "_timestamp": 1585570056.9442322, "_step": 100}
{"Episode reward": -99.81234031477804, "Episode length": 999, "Policy Loss": -0.3984673321247101, "Value Loss": 0.03862256556749344, "_runtime": 142.6363582611084, "_timestamp": 1585570058.4809916, "_step": 101}
{"Episode reward": -99.5188419140745, "Episode length": 999, "Policy Loss": -0.3622322678565979, "Value Loss": 0.058087918907403946, "_runtime": 144.04406356811523, "_timestamp": 1585570059.888697, "_step": 102}
{"Episode reward": 8.14621549116076, "Episode length": 920, "Policy Loss": 0.3467070162296295, "Value Loss": 10.873489379882812, "_runtime": 145.58503365516663, "_timestamp": 1585570061.429667, "_step": 103}
{"Episode reward": -99.61916270941008, "Episode length": 999, "Policy Loss": -0.3527516722679138, "Value Loss": 0.056371912360191345, "_runtime": 146.592182636261, "_timestamp": 1585570062.436816, "_step": 104}
{"Episode reward": 34.6888422399288, "Episode length": 655, "Policy Loss": 0.6571246981620789, "Value Loss": 15.359959602355957, "_runtime": 148.1294448375702, "_timestamp": 1585570063.9740782, "_step": 105}
{"Episode reward": -99.80684328228095, "Episode length": 999, "Policy Loss": -0.36243554949760437, "Value Loss": 0.2237297147512436, "_runtime": 149.67394018173218, "_timestamp": 1585570065.5185735, "_step": 106}
{"Episode reward": -99.8119435627698, "Episode length": 999, "Policy Loss": -0.37257522344589233, "Value Loss": 0.20541173219680786, "_runtime": 151.18522548675537, "_timestamp": 1585570067.0298588, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41027477383613586, "Value Loss": 0.11748311668634415, "_runtime": 152.50150227546692, "_timestamp": 1585570068.3461356, "_step": 108}
{"Episode reward": 14.6085064262856, "Episode length": 857, "Policy Loss": 0.23600605130195618, "Value Loss": 11.61570930480957, "_runtime": 154.07523608207703, "_timestamp": 1585570069.9198694, "_step": 109}
{"Episode reward": -99.29684230655411, "Episode length": 999, "Policy Loss": -0.44489604234695435, "Value Loss": 0.19868551194667816, "_runtime": 155.62244725227356, "_timestamp": 1585570071.4670806, "_step": 110}
{"Episode reward": -99.66416924360534, "Episode length": 999, "Policy Loss": -0.4134136438369751, "Value Loss": 0.39513838291168213, "_runtime": 157.1551685333252, "_timestamp": 1585570072.9998019, "_step": 111}
{"Episode reward": -99.77995443374245, "Episode length": 999, "Policy Loss": -0.5461881160736084, "Value Loss": 0.10681229829788208, "_runtime": 158.26321983337402, "_timestamp": 1585570074.1078532, "_step": 112}
{"Episode reward": 28.859539937518775, "Episode length": 715, "Policy Loss": 0.5456823110580444, "Value Loss": 13.677898406982422, "_runtime": 159.80774688720703, "_timestamp": 1585570075.6523802, "_step": 113}
{"Episode reward": -99.7358785410456, "Episode length": 999, "Policy Loss": -0.5403899550437927, "Value Loss": 0.05152219161391258, "_runtime": 160.65516686439514, "_timestamp": 1585570076.4998002, "_step": 114}
{"Episode reward": 46.3742637353828, "Episode length": 538, "Policy Loss": 0.6064871549606323, "Value Loss": 18.495773315429688, "_runtime": 162.18211913108826, "_timestamp": 1585570078.0267525, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5338075160980225, "Value Loss": 0.021368954330682755, "_runtime": 163.7173912525177, "_timestamp": 1585570079.5620246, "_step": 116}
{"Episode reward": -99.67701858251682, "Episode length": 999, "Policy Loss": -0.5473662614822388, "Value Loss": 0.020872505381703377, "_runtime": 165.1393759250641, "_timestamp": 1585570080.9840093, "_step": 117}
{"Episode reward": 5.808121210937301, "Episode length": 942, "Policy Loss": 0.14162354171276093, "Value Loss": 10.542882919311523, "_runtime": 166.67347240447998, "_timestamp": 1585570082.5181057, "_step": 118}
{"Episode reward": -99.47427490987327, "Episode length": 999, "Policy Loss": -0.5298094153404236, "Value Loss": 0.035547494888305664, "_runtime": 168.22243332862854, "_timestamp": 1585570084.0670667, "_step": 119}
{"Episode reward": -99.5392150898683, "Episode length": 999, "Policy Loss": -0.46983587741851807, "Value Loss": 0.29691872000694275, "_runtime": 169.51385974884033, "_timestamp": 1585570085.358493, "_step": 120}
{"Episode reward": 15.877965072443985, "Episode length": 842, "Policy Loss": 0.2521759271621704, "Value Loss": 12.07499885559082, "_runtime": 171.05941891670227, "_timestamp": 1585570086.9040523, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5838144421577454, "Value Loss": 0.027586407959461212, "_runtime": 172.6114628314972, "_timestamp": 1585570088.4560962, "_step": 122}
{"Episode reward": -99.69643365715608, "Episode length": 999, "Policy Loss": -0.5617219805717468, "Value Loss": 0.09607493132352829, "_runtime": 174.1403844356537, "_timestamp": 1585570089.9850178, "_step": 123}
{"Episode reward": -99.6599525529892, "Episode length": 999, "Policy Loss": -0.6067327260971069, "Value Loss": 0.037444546818733215, "_runtime": 174.80431723594666, "_timestamp": 1585570090.6489506, "_step": 124}
{"Episode reward": 58.59999999999969, "Episode length": 414, "Policy Loss": 1.1805853843688965, "Value Loss": 23.27928352355957, "_runtime": 175.63112878799438, "_timestamp": 1585570091.4757621, "_step": 125}
{"Episode reward": 47.37425883450003, "Episode length": 530, "Policy Loss": 0.5273114442825317, "Value Loss": 18.139278411865234, "_runtime": 176.73534178733826, "_timestamp": 1585570092.5799751, "_step": 126}
{"Episode reward": 30.178948567423205, "Episode length": 700, "Policy Loss": 0.2608467638492584, "Value Loss": 13.858256340026855, "_runtime": 178.2264223098755, "_timestamp": 1585570094.0710557, "_step": 127}
{"Episode reward": -99.56164554830617, "Episode length": 999, "Policy Loss": -0.4656785726547241, "Value Loss": 0.5826883912086487, "_runtime": 179.72523760795593, "_timestamp": 1585570095.569871, "_step": 128}
{"Episode reward": -99.54714377276113, "Episode length": 999, "Policy Loss": -0.5105196833610535, "Value Loss": 0.09808564186096191, "_runtime": 181.23494863510132, "_timestamp": 1585570097.079582, "_step": 129}
{"Episode reward": -99.80050452130241, "Episode length": 999, "Policy Loss": -0.5369894504547119, "Value Loss": 0.06818839907646179, "_runtime": 181.82584261894226, "_timestamp": 1585570097.670476, "_step": 130}
{"Episode reward": 63.38888867750623, "Episode length": 368, "Policy Loss": 1.2503292560577393, "Value Loss": 26.006044387817383, "_runtime": 183.23767113685608, "_timestamp": 1585570099.0823045, "_step": 131}
{"Episode reward": 7.813589800720621, "Episode length": 926, "Policy Loss": 0.23477314412593842, "Value Loss": 11.19662857055664, "_runtime": 184.76641607284546, "_timestamp": 1585570100.6110494, "_step": 132}
{"Episode reward": -99.78097786637817, "Episode length": 999, "Policy Loss": -0.505531370639801, "Value Loss": 0.3867685794830322, "_runtime": 185.6528971195221, "_timestamp": 1585570101.4975305, "_step": 133}
{"Episode reward": 40.9877794622438, "Episode length": 591, "Policy Loss": 0.5862899422645569, "Value Loss": 16.825119018554688, "_runtime": 186.1329152584076, "_timestamp": 1585570101.9775486, "_step": 134}
{"Episode reward": 70.78335321152103, "Episode length": 293, "Policy Loss": 1.4479212760925293, "Value Loss": 33.148136138916016, "_runtime": 186.94503140449524, "_timestamp": 1585570102.7896647, "_step": 135}
{"Episode reward": 46.82383675199187, "Episode length": 535, "Policy Loss": 0.4250471293926239, "Value Loss": 18.121042251586914, "_runtime": 188.43495154380798, "_timestamp": 1585570104.279585, "_step": 136}
{"Episode reward": -99.56284503287031, "Episode length": 999, "Policy Loss": -0.7218559980392456, "Value Loss": 0.23798690736293793, "_runtime": 189.0226480960846, "_timestamp": 1585570104.8672814, "_step": 137}
{"Episode reward": 60.88585746190483, "Episode length": 392, "Policy Loss": 1.0251306295394897, "Value Loss": 24.718917846679688, "_runtime": 190.4989619255066, "_timestamp": 1585570106.3435953, "_step": 138}
{"Episode reward": -99.28030381373692, "Episode length": 999, "Policy Loss": -0.7799204587936401, "Value Loss": 0.17904941737651825, "_runtime": 192.0313401222229, "_timestamp": 1585570107.8759735, "_step": 139}
{"Episode reward": -99.67074593427103, "Episode length": 999, "Policy Loss": -0.7784442901611328, "Value Loss": 0.13382256031036377, "_runtime": 193.09550833702087, "_timestamp": 1585570108.9401417, "_step": 140}
{"Episode reward": 28.549067117995378, "Episode length": 716, "Policy Loss": 0.33624210953712463, "Value Loss": 14.08096694946289, "_runtime": 194.58598732948303, "_timestamp": 1585570110.4306207, "_step": 141}
{"Episode reward": 2.4674064085307634, "Episode length": 977, "Policy Loss": -0.0008662817999720573, "Value Loss": 10.333040237426758, "_runtime": 196.11762881278992, "_timestamp": 1585570111.9622622, "_step": 142}
{"Episode reward": -99.39736406074816, "Episode length": 999, "Policy Loss": -0.7273641228675842, "Value Loss": 0.0264346431940794, "_runtime": 197.61734461784363, "_timestamp": 1585570113.461978, "_step": 143}
{"Episode reward": -99.39580662209056, "Episode length": 999, "Policy Loss": -0.6821413636207581, "Value Loss": 0.04618293419480324, "_runtime": 199.19657516479492, "_timestamp": 1585570115.0412085, "_step": 144}
{"Episode reward": -99.82266216034046, "Episode length": 999, "Policy Loss": -0.5326117277145386, "Value Loss": 0.5666066408157349, "_runtime": 200.24831008911133, "_timestamp": 1585570116.0929434, "_step": 145}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 0.2933315336704254, "Value Loss": 14.892147064208984, "_runtime": 201.78685569763184, "_timestamp": 1585570117.631489, "_step": 146}
{"Episode reward": -99.66859369555466, "Episode length": 999, "Policy Loss": -0.6804704666137695, "Value Loss": 0.04968861863017082, "_runtime": 203.33553171157837, "_timestamp": 1585570119.180165, "_step": 147}
{"Episode reward": -99.68051163677453, "Episode length": 999, "Policy Loss": -0.6555731892585754, "Value Loss": 0.15104708075523376, "_runtime": 204.31503748893738, "_timestamp": 1585570120.1596708, "_step": 148}
{"Episode reward": 36.30037235675201, "Episode length": 638, "Policy Loss": 0.4270790219306946, "Value Loss": 15.634892463684082, "_runtime": 205.85392093658447, "_timestamp": 1585570121.6985543, "_step": 149}
{"Episode reward": -99.76061072950111, "Episode length": 999, "Policy Loss": -0.6793901920318604, "Value Loss": 0.11011669039726257, "_runtime": 206.63401007652283, "_timestamp": 1585570122.4786434, "_step": 150}
{"Episode reward": 51.02985564497607, "Episode length": 492, "Policy Loss": 0.5339816212654114, "Value Loss": 19.573854446411133, "_runtime": 208.14185214042664, "_timestamp": 1585570123.9864855, "_step": 151}
{"Episode reward": -99.82026432608696, "Episode length": 999, "Policy Loss": -0.7003194093704224, "Value Loss": 0.035170335322618484, "_runtime": 208.93918871879578, "_timestamp": 1585570124.783822, "_step": 152}
{"Episode reward": 49.87172868540467, "Episode length": 502, "Policy Loss": 0.5174643993377686, "Value Loss": 19.2668399810791, "_runtime": 210.4475109577179, "_timestamp": 1585570126.2921443, "_step": 153}
{"Episode reward": -99.69512623958734, "Episode length": 999, "Policy Loss": -0.5795814394950867, "Value Loss": 0.4915291368961334, "_runtime": 211.97003602981567, "_timestamp": 1585570127.8146694, "_step": 154}
{"Episode reward": -99.22178531090623, "Episode length": 999, "Policy Loss": -0.6410163640975952, "Value Loss": 0.11911233514547348, "_runtime": 213.4584846496582, "_timestamp": 1585570129.303118, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6579254269599915, "Value Loss": 0.050764672458171844, "_runtime": 214.1645131111145, "_timestamp": 1585570130.0091465, "_step": 156}
{"Episode reward": 55.7680248029643, "Episode length": 446, "Policy Loss": 0.6854161620140076, "Value Loss": 21.44167709350586, "_runtime": 215.7015881538391, "_timestamp": 1585570131.5462215, "_step": 157}
{"Episode reward": -99.84814299901926, "Episode length": 999, "Policy Loss": -0.6352987289428711, "Value Loss": 0.023075509816408157, "_runtime": 217.22862482070923, "_timestamp": 1585570133.0732582, "_step": 158}
{"Episode reward": -99.64956819129155, "Episode length": 999, "Policy Loss": -0.6148615479469299, "Value Loss": 0.02012660726904869, "_runtime": 218.7239260673523, "_timestamp": 1585570134.5685594, "_step": 159}
{"Episode reward": -99.61384689587146, "Episode length": 999, "Policy Loss": -0.5899468064308167, "Value Loss": 0.03908829763531685, "_runtime": 219.94485330581665, "_timestamp": 1585570135.7894866, "_step": 160}
{"Episode reward": 20.799565925647272, "Episode length": 794, "Policy Loss": 0.21287190914154053, "Value Loss": 12.248098373413086, "_runtime": 221.4757993221283, "_timestamp": 1585570137.3204327, "_step": 161}
{"Episode reward": -99.61459751886294, "Episode length": 999, "Policy Loss": -0.5674161911010742, "Value Loss": 0.028487887233495712, "_runtime": 223.04288935661316, "_timestamp": 1585570138.8875227, "_step": 162}
{"Episode reward": -99.70879591862183, "Episode length": 999, "Policy Loss": -0.5372846722602844, "Value Loss": 0.10085532069206238, "_runtime": 223.99923849105835, "_timestamp": 1585570139.8438718, "_step": 163}
{"Episode reward": 38.503264340092706, "Episode length": 617, "Policy Loss": 0.8275816440582275, "Value Loss": 16.992929458618164, "_runtime": 225.514422416687, "_timestamp": 1585570141.3590558, "_step": 164}
{"Episode reward": 1.4266291314283706, "Episode length": 987, "Policy Loss": 0.0034121654462069273, "Value Loss": 9.75601863861084, "_runtime": 227.04051780700684, "_timestamp": 1585570142.8851511, "_step": 165}
{"Episode reward": -99.62851874456253, "Episode length": 999, "Policy Loss": -0.6570714116096497, "Value Loss": 0.02961338683962822, "_runtime": 228.56449246406555, "_timestamp": 1585570144.4091258, "_step": 166}
{"Episode reward": -99.55883319047723, "Episode length": 999, "Policy Loss": -0.6910871267318726, "Value Loss": 0.029664000496268272, "_runtime": 230.09447932243347, "_timestamp": 1585570145.9391127, "_step": 167}
{"Episode reward": -99.58242505310199, "Episode length": 999, "Policy Loss": -0.666383683681488, "Value Loss": 0.15097740292549133, "_runtime": 230.69956064224243, "_timestamp": 1585570146.544194, "_step": 168}
{"Episode reward": 62.576536901038814, "Episode length": 377, "Policy Loss": 1.020871877670288, "Value Loss": 26.303503036499023, "_runtime": 231.48371171951294, "_timestamp": 1585570147.328345, "_step": 169}
{"Episode reward": 49.199459902368794, "Episode length": 509, "Policy Loss": 0.8132349848747253, "Value Loss": 20.497835159301758, "_runtime": 233.0117223262787, "_timestamp": 1585570148.8563557, "_step": 170}
{"Episode reward": -99.72919376586076, "Episode length": 999, "Policy Loss": -0.7343343496322632, "Value Loss": 0.2550497055053711, "_runtime": 234.072767496109, "_timestamp": 1585570149.9174008, "_step": 171}
{"Episode reward": 28.59551368644439, "Episode length": 716, "Policy Loss": -0.048030704259872437, "Value Loss": 13.639636039733887, "_runtime": 234.56147122383118, "_timestamp": 1585570150.4061046, "_step": 172}
{"Episode reward": 69.19834762526152, "Episode length": 313, "Policy Loss": 0.9276710152626038, "Value Loss": 31.3498592376709, "_runtime": 234.85554218292236, "_timestamp": 1585570150.7001755, "_step": 173}
{"Episode reward": 83.15415942807707, "Episode length": 170, "Policy Loss": 3.629617214202881, "Value Loss": 57.1512336730957, "_runtime": 236.3282446861267, "_timestamp": 1585570152.172878, "_step": 174}
{"Episode reward": -99.70056502905071, "Episode length": 999, "Policy Loss": -0.8802617192268372, "Value Loss": 0.024750355631113052, "_runtime": 237.8022689819336, "_timestamp": 1585570153.6469023, "_step": 175}
{"Episode reward": -99.80001220442215, "Episode length": 999, "Policy Loss": -0.9220746755599976, "Value Loss": 0.1156395748257637, "_runtime": 238.7360475063324, "_timestamp": 1585570154.5806808, "_step": 176}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.2714068591594696, "Value Loss": 14.773575782775879, "_runtime": 240.0526282787323, "_timestamp": 1585570155.8972616, "_step": 177}
{"Episode reward": 12.700000000000685, "Episode length": 873, "Policy Loss": -0.15565122663974762, "Value Loss": 11.210898399353027, "_runtime": 240.88884925842285, "_timestamp": 1585570156.7334826, "_step": 178}
{"Episode reward": 45.79999999999951, "Episode length": 542, "Policy Loss": 0.1941855400800705, "Value Loss": 17.727331161499023, "_runtime": 241.35480904579163, "_timestamp": 1585570157.1994424, "_step": 179}
{"Episode reward": 69.306082160957, "Episode length": 309, "Policy Loss": 1.0109821557998657, "Value Loss": 31.361141204833984, "_runtime": 242.83617091178894, "_timestamp": 1585570158.6808043, "_step": 180}
{"Episode reward": -99.85024425024027, "Episode length": 999, "Policy Loss": -1.2578649520874023, "Value Loss": 0.7043782472610474, "_runtime": 244.3082640171051, "_timestamp": 1585570160.1528974, "_step": 181}
{"Episode reward": -99.83255348801472, "Episode length": 999, "Policy Loss": -1.302550196647644, "Value Loss": 0.30275312066078186, "_runtime": 245.50317430496216, "_timestamp": 1585570161.3478076, "_step": 182}
{"Episode reward": 20.811653880775197, "Episode length": 793, "Policy Loss": -0.37252554297447205, "Value Loss": 12.181069374084473, "_runtime": 247.02160787582397, "_timestamp": 1585570162.8662412, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2634930610656738, "Value Loss": 0.1300276517868042, "_runtime": 248.1999535560608, "_timestamp": 1585570164.044587, "_step": 184}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": -0.22059263288974762, "Value Loss": 12.510078430175781, "_runtime": 249.68673300743103, "_timestamp": 1585570165.5313663, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1837807893753052, "Value Loss": 0.05793321505188942, "_runtime": 250.89082646369934, "_timestamp": 1585570166.7354598, "_step": 186}
{"Episode reward": 21.162686285376765, "Episode length": 790, "Policy Loss": -0.3445774018764496, "Value Loss": 12.919087409973145, "_runtime": 251.8805992603302, "_timestamp": 1585570167.7252326, "_step": 187}
{"Episode reward": 35.09999999999941, "Episode length": 649, "Policy Loss": 0.09006404131650925, "Value Loss": 14.691091537475586, "_runtime": 253.22207689285278, "_timestamp": 1585570169.0667102, "_step": 188}
{"Episode reward": 11.500000000000753, "Episode length": 885, "Policy Loss": -0.14009836316108704, "Value Loss": 10.84846305847168, "_runtime": 254.71822333335876, "_timestamp": 1585570170.5628567, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.976374089717865, "Value Loss": 0.041891030967235565, "_runtime": 256.21493339538574, "_timestamp": 1585570172.0595667, "_step": 190}
{"Episode reward": -99.81004221439223, "Episode length": 999, "Policy Loss": -0.8916980624198914, "Value Loss": 0.13837121427059174, "_runtime": 257.72720646858215, "_timestamp": 1585570173.5718398, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8710459470748901, "Value Loss": 0.058263182640075684, "_runtime": 258.5838940143585, "_timestamp": 1585570174.4285274, "_step": 192}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.5753177404403687, "Value Loss": 17.23003387451172, "_runtime": 260.10330986976624, "_timestamp": 1585570175.9479432, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.792914867401123, "Value Loss": 0.15342310070991516, "_runtime": 260.4808280467987, "_timestamp": 1585570176.3254614, "_step": 194}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 3.4067461490631104, "Value Loss": 43.55291748046875, "_runtime": 261.97202467918396, "_timestamp": 1585570177.816658, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8150970339775085, "Value Loss": 0.112702377140522, "_runtime": 263.4972620010376, "_timestamp": 1585570179.3418953, "_step": 196}
{"Episode reward": -99.74936743713776, "Episode length": 999, "Policy Loss": -1.0899755954742432, "Value Loss": 0.430229514837265, "_runtime": 264.9604618549347, "_timestamp": 1585570180.8050952, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2927467823028564, "Value Loss": 0.8799526691436768, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492, -0.008835462853312492]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.143641471862793, -2.0939838886260986, -2.0443263053894043, -1.99466872215271, -1.9450111389160156, -1.8953535556793213, -1.845695972442627, -1.7960383892059326, -1.7463808059692383, -1.696723222732544, -1.6470656394958496, -1.5974080562591553, -1.5477503538131714, -1.498092770576477, -1.4484351873397827, -1.3987776041030884, -1.349120020866394, -1.2994624376296997, -1.2498048543930054, -1.200147271156311, -1.1504896879196167, -1.1008321046829224, -1.051174521446228, -1.0015169382095337, -0.9518592357635498, -0.9022016525268555, -0.8525440692901611, -0.8028864860534668, -0.7532289028167725, -0.7035713195800781, -0.6539137363433838, -0.6042561531066895, -0.5545985698699951, -0.5049409866333008, -0.45528340339660645, -0.4056258201599121, -0.3559682369232178, -0.30631065368652344, -0.2566530704498291, -0.20699548721313477, -0.15733790397644043, -0.1076803207397461, -0.05802273750305176, -0.008365154266357422, 0.041292428970336914, 0.09095001220703125, 0.14060759544372559, 0.19026517868041992, 0.23992300033569336, 0.2895805835723877, 0.33923816680908203, 0.38889575004577637, 0.4385533332824707, 0.48821091651916504, 0.5378684997558594, 0.5875260829925537, 0.637183666229248, 0.6868412494659424, 0.7364988327026367, 0.786156415939331, 0.8358139991760254, 0.8854715824127197, 0.9351291656494141, 0.9847867488861084, 1.0344443321228027]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05670122057199478, -0.05493176355957985, -0.05316230282187462, -0.051392845809459686, -0.049623388797044754, -0.04785393178462982, -0.04608447104692459, -0.04431501403450966, -0.04254555702209473, -0.040776096284389496, -0.039006639271974564, -0.03723718225955963, -0.0354677215218544, -0.03369826450943947, -0.031928807497024536, -0.030159348621964455, -0.028389889746904373, -0.02662043087184429, -0.02485097199678421, -0.023081514984369278, -0.021312057971954346, -0.019542597234249115, -0.017773140221834183, -0.01600368320941925, -0.01423422247171402, -0.012464765459299088, -0.010695308446884155, -0.008925851434469223, -0.007156390696763992, -0.00538693368434906, -0.003617476671934128, -0.001848015934228897, -7.855892181396484e-05, 0.0016908980906009674, 0.003460358828306198, 0.00522981584072113, 0.006999276578426361, 0.008768729865550995, 0.010538190603256226, 0.012307651340961456, 0.01407710462808609, 0.01584656536579132, 0.01761602610349655, 0.019385479390621185, 0.021154940128326416, 0.022924400866031647, 0.02469385415315628, 0.02646331489086151, 0.028232775628566742, 0.030002228915691376, 0.031771689653396606, 0.03354114294052124, 0.03531060367822647, 0.0370800644159317, 0.038849517703056335, 0.040618978440761566, 0.0423884391784668, 0.04415789246559143, 0.04592735320329666, 0.04769681394100189, 0.049466267228126526, 0.05123572796583176, 0.05300518870353699, 0.05477464199066162, 0.05654410272836685]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 4.0, 5.0, 8.0, 9.0, 13.0, 16.0, 304.0, 15.0, 20.0, 14.0, 10.0, 8.0, 10.0, 9.0, 9.0, 8.0, 8.0, 2.0, 2.0, 3.0, 6.0, 1.0, 0.0, 0.0, 3.0], "bins": [-0.28240901231765747, -0.2761383056640625, -0.26986756920814514, -0.26359686255455017, -0.2573261559009552, -0.25105541944503784, -0.24478471279144287, -0.2385140061378479, -0.23224328458309174, -0.22597256302833557, -0.2197018563747406, -0.21343113481998444, -0.20716041326522827, -0.2008897066116333, -0.19461898505687714, -0.18834826350212097, -0.182077556848526, -0.17580685019493103, -0.16953612864017487, -0.1632654070854187, -0.15699470043182373, -0.15072397887706757, -0.1444532573223114, -0.13818255066871643, -0.13191182911396027, -0.1256411075592041, -0.11937040090560913, -0.11309967935085297, -0.1068289577960968, -0.10055825114250183, -0.09428752958774567, -0.0880168229341507, -0.08174610137939453, -0.07547537982463837, -0.0692046731710434, -0.06293395161628723, -0.05666324496269226, -0.050392523407936096, -0.04412180185317993, -0.03785109519958496, -0.03158038854598999, -0.025309652090072632, -0.01903894543647766, -0.01276823878288269, -0.006497502326965332, -0.00022679567337036133, 0.006043910980224609, 0.012314647436141968, 0.01858535408973694, 0.02485606074333191, 0.031126797199249268, 0.03739750385284424, 0.04366821050643921, 0.04993894696235657, 0.05620965361595154, 0.06248036026954651, 0.06875109672546387, 0.07502180337905884, 0.08129251003265381, 0.08756321668624878, 0.09383395314216614, 0.10010465979576111, 0.10637536644935608, 0.11264610290527344, 0.11891680955886841]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.665370523929596, -0.6481810808181763, -0.6309916973114014, -0.6138022541999817, -0.5966128706932068, -0.5794234275817871, -0.5622340440750122, -0.5450446009635925, -0.5278552174568176, -0.510665774345398, -0.49347639083862305, -0.47628694772720337, -0.4590975344181061, -0.4419081211090088, -0.4247187077999115, -0.4075292944908142, -0.3903398811817169, -0.37315046787261963, -0.35596105456352234, -0.33877164125442505, -0.32158222794532776, -0.30439281463623047, -0.2872034013271332, -0.2700139880180359, -0.2528245449066162, -0.23563513159751892, -0.21844571828842163, -0.20125630497932434, -0.18406689167022705, -0.16687747836112976, -0.14968806505203247, -0.13249868154525757, -0.11530923843383789, -0.09811979532241821, -0.08093041181564331, -0.06374096870422363, -0.04655158519744873, -0.029362142086029053, -0.01217275857925415, 0.005016684532165527, 0.02220606803894043, 0.03939551115036011, 0.05658489465713501, 0.07377433776855469, 0.09096372127532959, 0.10815316438674927, 0.12534254789352417, 0.14253199100494385, 0.15972143411636353, 0.17691081762313843, 0.1941002607345581, 0.211289644241333, 0.22847908735275269, 0.2456684708595276, 0.26285791397094727, 0.28004729747772217, 0.29723674058914185, 0.31442612409591675, 0.3316155672073364, 0.3488050103187561, 0.365994393825531, 0.3831837773323059, 0.4003731608390808, 0.41756266355514526, 0.43475204706192017]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 7.0, 1.0, 2.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7130358815193176, -0.6922338604927063, -0.671431839466095, -0.6506298184394836, -0.6298277378082275, -0.6090257167816162, -0.5882236957550049, -0.5674216747283936, -0.5466196537017822, -0.5258176326751709, -0.5050156116485596, -0.48421356081962585, -0.4634115397930145, -0.4426095187664032, -0.4218074679374695, -0.40100544691085815, -0.3802034258842468, -0.3594014048576355, -0.33859938383102417, -0.31779733300209045, -0.2969953119754791, -0.2761932909488678, -0.2553912401199341, -0.23458921909332275, -0.21378719806671143, -0.1929851770401001, -0.17218315601348877, -0.15138113498687744, -0.13057905435562134, -0.10977703332901001, -0.08897501230239868, -0.06817299127578735, -0.047370970249176025, -0.026568949222564697, -0.005766928195953369, 0.015035092830657959, 0.03583711385726929, 0.05663919448852539, 0.07744121551513672, 0.09824323654174805, 0.11904525756835938, 0.1398472785949707, 0.16064929962158203, 0.18145132064819336, 0.20225340127944946, 0.2230554223060608, 0.24385744333267212, 0.26465946435928345, 0.2854614853858948, 0.3062635064125061, 0.32706552743911743, 0.34786754846572876, 0.3686695694923401, 0.3894715905189514, 0.41027361154556274, 0.4310756325721741, 0.45187777280807495, 0.4726797938346863, 0.4934818148612976, 0.5142838358879089, 0.5350858569145203, 0.5558878779411316, 0.5766898989677429, 0.5974919199943542, 0.6182939410209656]}, "_runtime": 266.134192943573, "_timestamp": 1585570181.9788263, "_step": 198}
{"Episode reward": 23.203939901292415, "Episode length": 768, "Policy Loss": -0.11788507550954819, "Value Loss": 12.221894264221191, "_runtime": 267.6588842868805, "_timestamp": 1585570183.5035176, "_step": 199}
{"Episode reward": -99.80225073248009, "Episode length": 999, "Policy Loss": -1.4983494281768799, "Value Loss": 0.8270626664161682, "_runtime": 269.2124526500702, "_timestamp": 1585570185.057086, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.298788070678711, "Value Loss": 0.10598773509263992, "_runtime": 270.72119140625, "_timestamp": 1585570186.5658247, "_step": 201}
{"Episode reward": -99.80587139278511, "Episode length": 999, "Policy Loss": -1.4072054624557495, "Value Loss": 0.26851269602775574, "_runtime": 271.97310519218445, "_timestamp": 1585570187.8177385, "_step": 202}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": -0.16069601476192474, "Value Loss": 11.66434097290039, "_runtime": 273.5010690689087, "_timestamp": 1585570189.3457024, "_step": 203}
{"Episode reward": -99.85260321833053, "Episode length": 999, "Policy Loss": -1.2921968698501587, "Value Loss": 0.11034928262233734, "_runtime": 274.61242389678955, "_timestamp": 1585570190.4570572, "_step": 204}
{"Episode reward": 26.999488736595836, "Episode length": 731, "Policy Loss": -0.24628591537475586, "Value Loss": 13.728691101074219, "_runtime": 276.13308668136597, "_timestamp": 1585570191.97772, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1677402257919312, "Value Loss": 0.031721048057079315, "_runtime": 277.5947103500366, "_timestamp": 1585570193.4393437, "_step": 206}
{"Episode reward": 4.200000000001168, "Episode length": 958, "Policy Loss": -0.3016919791698456, "Value Loss": 9.996682167053223, "_runtime": 279.03355288505554, "_timestamp": 1585570194.8781862, "_step": 207}
{"Episode reward": 4.710589378304988, "Episode length": 953, "Policy Loss": -0.21104371547698975, "Value Loss": 10.416912078857422, "_runtime": 280.5672707557678, "_timestamp": 1585570196.411904, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9822321534156799, "Value Loss": 0.1474090963602066, "_runtime": 282.1026756763458, "_timestamp": 1585570197.947309, "_step": 209}
{"Episode reward": -99.80553329139808, "Episode length": 999, "Policy Loss": -0.8307248950004578, "Value Loss": 0.2325400710105896, "_runtime": 283.39981341362, "_timestamp": 1585570199.2444468, "_step": 210}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": 0.12395936995744705, "Value Loss": 11.559919357299805, "_runtime": 284.93370842933655, "_timestamp": 1585570200.7783418, "_step": 211}
{"Episode reward": -99.75674890428643, "Episode length": 999, "Policy Loss": -0.8315311074256897, "Value Loss": 0.04307843744754791, "_runtime": 286.47259306907654, "_timestamp": 1585570202.3172264, "_step": 212}
{"Episode reward": -99.80660901665547, "Episode length": 999, "Policy Loss": -0.8457459211349487, "Value Loss": 0.04679357632994652, "_runtime": 286.99291038513184, "_timestamp": 1585570202.8375437, "_step": 213}
{"Episode reward": 67.69960093758982, "Episode length": 324, "Policy Loss": 1.6173617839813232, "Value Loss": 29.46050262451172, "_runtime": 287.7209839820862, "_timestamp": 1585570203.5656173, "_step": 214}
{"Episode reward": 52.89039393514356, "Episode length": 472, "Policy Loss": 0.8393222093582153, "Value Loss": 20.001625061035156, "_runtime": 289.239271402359, "_timestamp": 1585570205.0839047, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8567202687263489, "Value Loss": 0.07516676187515259, "_runtime": 290.3050479888916, "_timestamp": 1585570206.1496813, "_step": 216}
{"Episode reward": 27.499999999999844, "Episode length": 725, "Policy Loss": 0.17666849493980408, "Value Loss": 13.061808586120605, "_runtime": 291.20687317848206, "_timestamp": 1585570207.0515065, "_step": 217}
{"Episode reward": 42.07495420267751, "Episode length": 580, "Policy Loss": 0.36352598667144775, "Value Loss": 16.277097702026367, "_runtime": 292.7074785232544, "_timestamp": 1585570208.5521119, "_step": 218}
{"Episode reward": -99.83288165666023, "Episode length": 999, "Policy Loss": -0.9391877055168152, "Value Loss": 0.1243816390633583, "_runtime": 294.06456446647644, "_timestamp": 1585570209.9091978, "_step": 219}
{"Episode reward": 9.200000000000884, "Episode length": 908, "Policy Loss": -0.0649619773030281, "Value Loss": 10.35062026977539, "_runtime": 294.76084876060486, "_timestamp": 1585570210.605482, "_step": 220}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 0.7124893665313721, "Value Loss": 20.34317398071289, "_runtime": 295.93927550315857, "_timestamp": 1585570211.7839088, "_step": 221}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": -0.05007089674472809, "Value Loss": 13.243227005004883, "_runtime": 297.4450612068176, "_timestamp": 1585570213.2896945, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8952410817146301, "Value Loss": 0.21221114695072174, "_runtime": 298.71806168556213, "_timestamp": 1585570214.562695, "_step": 223}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": 0.06577126681804657, "Value Loss": 10.819806098937988, "_runtime": 299.8505349159241, "_timestamp": 1585570215.6951683, "_step": 224}
{"Episode reward": 24.983638001605854, "Episode length": 752, "Policy Loss": 0.005214326083660126, "Value Loss": 13.292454719543457, "_runtime": 301.03204584121704, "_timestamp": 1585570216.8766792, "_step": 225}
{"Episode reward": 22.975934923347197, "Episode length": 772, "Policy Loss": -0.022956607863307, "Value Loss": 12.64460563659668, "_runtime": 301.90907192230225, "_timestamp": 1585570217.7537053, "_step": 226}
{"Episode reward": 41.99999999999945, "Episode length": 580, "Policy Loss": 0.12457095086574554, "Value Loss": 16.77022933959961, "_runtime": 303.40680480003357, "_timestamp": 1585570219.2514381, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0074164867401123, "Value Loss": 0.0342729277908802, "_runtime": 304.90906858444214, "_timestamp": 1585570220.753702, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0751194953918457, "Value Loss": 0.43601641058921814, "_runtime": 306.40014362335205, "_timestamp": 1585570222.244777, "_step": 229}
{"Episode reward": -99.76987863778929, "Episode length": 999, "Policy Loss": -1.005095362663269, "Value Loss": 0.06281846016645432, "_runtime": 307.71950459480286, "_timestamp": 1585570223.564138, "_step": 230}
{"Episode reward": 13.307612985373197, "Episode length": 867, "Policy Loss": -0.009081927128136158, "Value Loss": 11.000309944152832, "_runtime": 309.0101532936096, "_timestamp": 1585570224.8547866, "_step": 231}
{"Episode reward": 15.700000000000514, "Episode length": 843, "Policy Loss": 0.025068238377571106, "Value Loss": 11.324902534484863, "_runtime": 310.4313294887543, "_timestamp": 1585570226.2759628, "_step": 232}
{"Episode reward": 6.500000000001037, "Episode length": 935, "Policy Loss": -0.04793872684240341, "Value Loss": 10.112698554992676, "_runtime": 310.9321143627167, "_timestamp": 1585570226.7767477, "_step": 233}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 1.538535714149475, "Value Loss": 30.12854766845703, "_runtime": 312.43658566474915, "_timestamp": 1585570228.281219, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7552722692489624, "Value Loss": 0.22365577518939972, "_runtime": 313.45857405662537, "_timestamp": 1585570229.3032074, "_step": 235}
{"Episode reward": 33.39999999999951, "Episode length": 666, "Policy Loss": 0.2840091288089752, "Value Loss": 14.286099433898926, "_runtime": 314.96379566192627, "_timestamp": 1585570230.808429, "_step": 236}
{"Episode reward": -99.73059864789109, "Episode length": 999, "Policy Loss": -0.8666437864303589, "Value Loss": 0.03317670896649361, "_runtime": 316.19630908966064, "_timestamp": 1585570232.0409424, "_step": 237}
{"Episode reward": 19.75288718193798, "Episode length": 803, "Policy Loss": 0.21700143814086914, "Value Loss": 11.546520233154297, "_runtime": 317.694509267807, "_timestamp": 1585570233.5391426, "_step": 238}
{"Episode reward": -99.80057372487941, "Episode length": 999, "Policy Loss": -0.8460043668746948, "Value Loss": 0.04299342632293701, "_runtime": 319.21215176582336, "_timestamp": 1585570235.056785, "_step": 239}
{"Episode reward": 0.6000000000013728, "Episode length": 994, "Policy Loss": -0.2404698133468628, "Value Loss": 9.93175983428955, "_runtime": 320.6514377593994, "_timestamp": 1585570236.496071, "_step": 240}
{"Episode reward": 5.100000000001117, "Episode length": 949, "Policy Loss": -0.10991311073303223, "Value Loss": 10.30193042755127, "_runtime": 322.1763017177582, "_timestamp": 1585570238.020935, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9059561491012573, "Value Loss": 0.035732075572013855, "_runtime": 323.7006905078888, "_timestamp": 1585570239.5453238, "_step": 242}
{"Episode reward": -99.80005196863645, "Episode length": 999, "Policy Loss": -0.9438492655754089, "Value Loss": 0.04562443494796753, "_runtime": 325.22560000419617, "_timestamp": 1585570241.0702333, "_step": 243}
{"Episode reward": -99.8309169664965, "Episode length": 999, "Policy Loss": -0.9325423240661621, "Value Loss": 0.025815652683377266, "_runtime": 326.02074575424194, "_timestamp": 1585570241.865379, "_step": 244}
{"Episode reward": 49.26847942387641, "Episode length": 508, "Policy Loss": 0.5002871155738831, "Value Loss": 18.17076301574707, "_runtime": 326.41335344314575, "_timestamp": 1585570242.2579868, "_step": 245}
{"Episode reward": 76.99787830477575, "Episode length": 231, "Policy Loss": 2.0265979766845703, "Value Loss": 40.0432014465332, "_runtime": 327.4421489238739, "_timestamp": 1585570243.2867823, "_step": 246}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.02126535400748253, "Value Loss": 13.81735610961914, "_runtime": 328.07428216934204, "_timestamp": 1585570243.9189155, "_step": 247}
{"Episode reward": 57.29999999999967, "Episode length": 427, "Policy Loss": 0.9071465730667114, "Value Loss": 21.406553268432617, "_runtime": 329.5380766391754, "_timestamp": 1585570245.38271, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9495099186897278, "Value Loss": 0.03950933739542961, "_runtime": 330.1457281112671, "_timestamp": 1585570245.9903615, "_step": 249}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 0.8146676421165466, "Value Loss": 23.172115325927734, "_runtime": 331.6049644947052, "_timestamp": 1585570247.4495978, "_step": 250}
{"Episode reward": -99.82929621338705, "Episode length": 999, "Policy Loss": -1.0235812664031982, "Value Loss": 0.06487365067005157, "_runtime": 332.2940626144409, "_timestamp": 1585570248.138696, "_step": 251}
{"Episode reward": 54.94022664092445, "Episode length": 451, "Policy Loss": 0.5761620402336121, "Value Loss": 20.261611938476562, "_runtime": 333.766455411911, "_timestamp": 1585570249.6110888, "_step": 252}
{"Episode reward": -99.84613115787367, "Episode length": 999, "Policy Loss": -1.128862977027893, "Value Loss": 0.035752490162849426, "_runtime": 335.2778916358948, "_timestamp": 1585570251.122525, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.119307279586792, "Value Loss": 0.06607333570718765, "_runtime": 336.75924730300903, "_timestamp": 1585570252.6038806, "_step": 254}
{"Episode reward": -99.73284000167483, "Episode length": 999, "Policy Loss": -1.0821506977081299, "Value Loss": 0.031874243170022964, "_runtime": 338.13602924346924, "_timestamp": 1585570253.9806626, "_step": 255}
{"Episode reward": 11.49923554947675, "Episode length": 886, "Policy Loss": -0.4517350494861603, "Value Loss": 12.42093276977539, "_runtime": 339.6660125255585, "_timestamp": 1585570255.5106459, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0278962850570679, "Value Loss": 0.019166184589266777, "_runtime": 341.1814284324646, "_timestamp": 1585570257.0260618, "_step": 257}
{"Episode reward": -99.77080021202426, "Episode length": 999, "Policy Loss": -0.9731400012969971, "Value Loss": 0.042297106236219406, "_runtime": 342.703994512558, "_timestamp": 1585570258.5486279, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9925397038459778, "Value Loss": 0.1741766333580017, "_runtime": 344.2522985935211, "_timestamp": 1585570260.096932, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8754711747169495, "Value Loss": 0.022965503856539726, "_runtime": 345.7891671657562, "_timestamp": 1585570261.6338005, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8168039917945862, "Value Loss": 0.01589384861290455, "_runtime": 347.24897480010986, "_timestamp": 1585570263.0936081, "_step": 261}
{"Episode reward": 4.621332806629326, "Episode length": 955, "Policy Loss": 0.1597387045621872, "Value Loss": 9.661222457885742, "_runtime": 348.790105342865, "_timestamp": 1585570264.6347387, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6531110405921936, "Value Loss": 0.09128397703170776, "_runtime": 350.33067631721497, "_timestamp": 1585570266.1753097, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6696932911872864, "Value Loss": 0.19276027381420135, "_runtime": 351.62655568122864, "_timestamp": 1585570267.471189, "_step": 264}
{"Episode reward": 15.100000000000549, "Episode length": 849, "Policy Loss": 0.21459028124809265, "Value Loss": 10.98080825805664, "_runtime": 353.16202878952026, "_timestamp": 1585570269.0066621, "_step": 265}
{"Episode reward": -99.84051776267448, "Episode length": 999, "Policy Loss": -0.6585069298744202, "Value Loss": 0.044425178319215775, "_runtime": 354.70561051368713, "_timestamp": 1585570270.5502439, "_step": 266}
{"Episode reward": -99.80125165618817, "Episode length": 999, "Policy Loss": -0.8447085618972778, "Value Loss": 1.3119947910308838, "_runtime": 356.2145748138428, "_timestamp": 1585570272.0592082, "_step": 267}
{"Episode reward": -99.80744346529106, "Episode length": 999, "Policy Loss": -0.6534830927848816, "Value Loss": 0.09238485246896744, "_runtime": 357.75511288642883, "_timestamp": 1585570273.5997462, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7097322940826416, "Value Loss": 0.14020974934101105, "_runtime": 359.2962429523468, "_timestamp": 1585570275.1408763, "_step": 269}
{"Episode reward": -99.8015245858566, "Episode length": 999, "Policy Loss": -0.6866292953491211, "Value Loss": 0.15901696681976318, "_runtime": 360.3253700733185, "_timestamp": 1585570276.1700034, "_step": 270}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.49401089549064636, "Value Loss": 14.79990005493164, "_runtime": 361.8521234989166, "_timestamp": 1585570277.6967568, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6622250080108643, "Value Loss": 0.17081323266029358, "_runtime": 362.34999203681946, "_timestamp": 1585570278.1946254, "_step": 272}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 2.400977373123169, "Value Loss": 29.972291946411133, "_runtime": 363.8463342189789, "_timestamp": 1585570279.6909676, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7204163074493408, "Value Loss": 0.03866172209382057, "_runtime": 364.41568875312805, "_timestamp": 1585570280.260322, "_step": 274}
{"Episode reward": 64.69999999999978, "Episode length": 353, "Policy Loss": 0.36686545610427856, "Value Loss": 32.431827545166016, "_runtime": 365.88775610923767, "_timestamp": 1585570281.7323895, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7419760227203369, "Value Loss": 0.03384322673082352, "_runtime": 366.75129675865173, "_timestamp": 1585570282.59593, "_step": 276}
{"Episode reward": 44.25502305589565, "Episode length": 559, "Policy Loss": 0.5595594048500061, "Value Loss": 16.811038970947266, "_runtime": 368.2233250141144, "_timestamp": 1585570284.0679584, "_step": 277}
{"Episode reward": -99.79961578845838, "Episode length": 999, "Policy Loss": -0.8472838401794434, "Value Loss": 0.02547498047351837, "_runtime": 369.48998165130615, "_timestamp": 1585570285.334615, "_step": 278}
{"Episode reward": 16.93311917185828, "Episode length": 831, "Policy Loss": 0.21837732195854187, "Value Loss": 11.418646812438965, "_runtime": 370.54860973358154, "_timestamp": 1585570286.393243, "_step": 279}
{"Episode reward": 28.171634493768025, "Episode length": 719, "Policy Loss": 0.17266139388084412, "Value Loss": 13.210638999938965, "_runtime": 371.5092713832855, "_timestamp": 1585570287.3539047, "_step": 280}
{"Episode reward": 36.89064311794875, "Episode length": 632, "Policy Loss": 0.3468928337097168, "Value Loss": 15.043305397033691, "_runtime": 373.02244114875793, "_timestamp": 1585570288.8670745, "_step": 281}
{"Episode reward": -99.81193419098715, "Episode length": 999, "Policy Loss": -0.9252897500991821, "Value Loss": 0.023968353867530823, "_runtime": 374.5228867530823, "_timestamp": 1585570290.36752, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8541460633277893, "Value Loss": 0.1679621934890747, "_runtime": 375.09895420074463, "_timestamp": 1585570290.9435875, "_step": 283}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 1.3661497831344604, "Value Loss": 25.189584732055664, "_runtime": 376.6106901168823, "_timestamp": 1585570292.4553235, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9804922938346863, "Value Loss": 0.02737399749457836, "_runtime": 378.1413838863373, "_timestamp": 1585570293.9860172, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.974918007850647, "Value Loss": 0.038347452878952026, "_runtime": 379.6274070739746, "_timestamp": 1585570295.4720404, "_step": 286}
{"Episode reward": -99.83913883119682, "Episode length": 999, "Policy Loss": -0.9809157848358154, "Value Loss": 0.022582951933145523, "_runtime": 380.84580063819885, "_timestamp": 1585570296.690434, "_step": 287}
{"Episode reward": 20.90000000000022, "Episode length": 791, "Policy Loss": -0.20872466266155243, "Value Loss": 12.375078201293945, "_runtime": 382.3857431411743, "_timestamp": 1585570298.2303765, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9147002100944519, "Value Loss": 0.038062144070863724, "_runtime": 383.58953380584717, "_timestamp": 1585570299.4341671, "_step": 289}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 0.10413632541894913, "Value Loss": 12.137555122375488, "_runtime": 385.11655378341675, "_timestamp": 1585570300.9611871, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8337900042533875, "Value Loss": 0.01822304166853428, "_runtime": 386.66081738471985, "_timestamp": 1585570302.5054507, "_step": 291}
{"Episode reward": -99.80057557560363, "Episode length": 999, "Policy Loss": -0.7987673878669739, "Value Loss": 0.035741131752729416, "_runtime": 388.16607999801636, "_timestamp": 1585570304.0107133, "_step": 292}
{"Episode reward": -99.80181946903328, "Episode length": 999, "Policy Loss": -0.8314900994300842, "Value Loss": 0.2558034062385559, "_runtime": 389.71963238716125, "_timestamp": 1585570305.5642657, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6469455361366272, "Value Loss": 0.012804766185581684, "_runtime": 390.40685963630676, "_timestamp": 1585570306.251493, "_step": 294}
{"Episode reward": 56.89763616882231, "Episode length": 432, "Policy Loss": 1.2687684297561646, "Value Loss": 21.37476348876953, "_runtime": 391.6139440536499, "_timestamp": 1585570307.4585774, "_step": 295}
{"Episode reward": 21.800000000000168, "Episode length": 782, "Policy Loss": 0.3430160880088806, "Value Loss": 12.142815589904785, "_runtime": 393.1458775997162, "_timestamp": 1585570308.990511, "_step": 296}
{"Episode reward": -99.83135289102653, "Episode length": 999, "Policy Loss": -0.840390682220459, "Value Loss": 0.5518162250518799, "_runtime": 394.6435329914093, "_timestamp": 1585570310.4881663, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8298656344413757, "Value Loss": 0.0462120845913887, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647, 0.10613559931516647]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9742763638496399, -0.4876783490180969, -0.001080334186553955, 0.485517680644989, 0.972115695476532, 1.4587137699127197, 1.9453117847442627, 2.4319097995758057, 2.9185078144073486, 3.4051058292388916, 3.8917038440704346, 4.378301620483398, 4.864899635314941, 5.351497650146484, 5.838095664978027, 6.32469367980957, 6.811291694641113, 7.297889709472656, 7.784487724304199, 8.271085739135742, 8.757683753967285, 9.244281768798828, 9.730879783630371, 10.217477798461914, 10.704075813293457, 11.190673828125, 11.677271842956543, 12.163869857788086, 12.650467872619629, 13.137065887451172, 13.623663902282715, 14.110261917114258, 14.5968599319458, 15.08345890045166, 15.570055961608887, 16.05665397644043, 16.54325294494629, 17.02985191345215, 17.516448974609375, 18.0030460357666, 18.48964500427246, 18.97624397277832, 19.462841033935547, 19.949438095092773, 20.436037063598633, 20.922636032104492, 21.40923309326172, 21.895830154418945, 22.382429122924805, 22.869028091430664, 23.35562515258789, 23.842222213745117, 24.328821182250977, 24.815420150756836, 25.302017211914062, 25.78861427307129, 26.27521324157715, 26.761812210083008, 27.248409271240234, 27.73500633239746, 28.22160530090332, 28.70820426940918, 29.194801330566406, 29.681398391723633, 30.167997360229492]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0366365872323513, -0.03104604221880436, -0.025455497205257416, -0.019864952191710472, -0.014274407178163528, -0.008683862164616585, -0.003093317151069641, 0.0024972297251224518, 0.008087772876024246, 0.01367831602692604, 0.019268862903118134, 0.024859409779310226, 0.03044995293021202, 0.036040496081113815, 0.04163104668259621, 0.047221589833498, 0.052812132984399796, 0.05840267613530159, 0.06399321556091309, 0.06958377361297607, 0.07517431676387787, 0.08076485991477966, 0.08635540306568146, 0.09194594621658325, 0.09753648936748505, 0.10312703251838684, 0.10871757566928864, 0.11430811882019043, 0.11989867687225342, 0.1254892200231552, 0.131079763174057, 0.1366703063249588, 0.1422608494758606, 0.1478513926267624, 0.15344193577766418, 0.15903247892856598, 0.16462302207946777, 0.17021358013153076, 0.17580412328243256, 0.18139466643333435, 0.18698520958423615, 0.19257575273513794, 0.19816629588603973, 0.20375683903694153, 0.20934739708900452, 0.21493792533874512, 0.2205284833908081, 0.2261190116405487, 0.2317095696926117, 0.23730012774467468, 0.24289065599441528, 0.24848121404647827, 0.25407174229621887, 0.25966230034828186, 0.26525282859802246, 0.27084338665008545, 0.27643394470214844, 0.28202447295188904, 0.287615031003952, 0.2932055592536926, 0.2987961173057556, 0.3043866455554962, 0.3099772036075592, 0.3155677318572998, 0.3211582899093628]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [7.0, 6.0, 21.0, 15.0, 9.0, 15.0, 52.0, 335.0, 24.0, 4.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.3747190833091736, -0.32535335421562195, -0.2759876251220703, -0.2266218662261963, -0.17725613713264465, -0.12789040803909302, -0.078524649143219, -0.02915892004966736, 0.020206809043884277, 0.06957253813743591, 0.11893826723098755, 0.16830402612686157, 0.2176697850227356, 0.26703548431396484, 0.31640124320983887, 0.3657669425010681, 0.41513270139694214, 0.46449846029281616, 0.5138641595840454, 0.5632299184799194, 0.6125956177711487, 0.6619613766670227, 0.7113271355628967, 0.7606928944587708, 0.8100586533546448, 0.8594242930412292, 0.9087900519371033, 0.9581558108329773, 1.007521629333496, 1.0568873882293701, 1.106252908706665, 1.155618667602539, 1.204984426498413, 1.254350185394287, 1.3037159442901611, 1.3530817031860352, 1.4024474620819092, 1.4518132209777832, 1.5011789798736572, 1.5505447387695312, 1.5999102592468262, 1.6492760181427002, 1.6986417770385742, 1.7480075359344482, 1.7973732948303223, 1.8467390537261963, 1.8961048126220703, 1.9454705715179443, 1.9948363304138184, 2.0442018508911133, 2.0935676097869873, 2.1429333686828613, 2.1922991275787354, 2.2416648864746094, 2.2910306453704834, 2.3403964042663574, 2.3897621631622314, 2.4391279220581055, 2.4884936809539795, 2.5378592014312744, 2.5872249603271484, 2.6365907192230225, 2.6859564781188965, 2.7353222370147705, 2.7846879959106445]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 2.0, 8.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5681565999984741, -0.4905835688114166, -0.41301053762435913, -0.335437536239624, -0.25786450505256653, -0.18029147386550903, -0.10271847248077393, -0.025145411491394043, 0.052427589893341064, 0.13000059127807617, 0.20757365226745605, 0.28514665365219116, 0.36271965503692627, 0.44029271602630615, 0.517865777015686, 0.5954387187957764, 0.6730117797851562, 0.7505848407745361, 0.8281577825546265, 0.9057308435440063, 0.9833039045333862, 1.0608768463134766, 1.1384499073028564, 1.2160229682922363, 1.2935959100723267, 1.3711689710617065, 1.4487420320510864, 1.5263150930404663, 1.6038881540298462, 1.681460976600647, 1.7590340375900269, 1.8366070985794067, 1.9141801595687866, 1.9917532205581665, 2.069326400756836, 2.1468992233276367, 2.2244720458984375, 2.3020453453063965, 2.3796181678771973, 2.4571914672851562, 2.534764289855957, 2.612337589263916, 2.689910411834717, 2.7674832344055176, 2.8450565338134766, 2.9226293563842773, 3.0002026557922363, 3.077775478363037, 3.155348300933838, 3.232921600341797, 3.3104944229125977, 3.3880677223205566, 3.4656405448913574, 3.543213367462158, 3.620786666870117, 3.698359489440918, 3.775932788848877, 3.8535056114196777, 3.9310784339904785, 4.0086517333984375, 4.086224555969238, 4.163797855377197, 4.241370677947998, 4.318943977355957, 4.396516799926758]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 4.0, 4.0, 2.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 4.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], "bins": [-1.2352750301361084, -1.1908150911331177, -1.1463550329208374, -1.1018950939178467, -1.057435154914856, -1.0129752159118652, -0.968515157699585, -0.9240552186965942, -0.8795952200889587, -0.8351352214813232, -0.7906752824783325, -0.746215283870697, -0.7017552852630615, -0.6572953462600708, -0.6128353476524353, -0.5683754086494446, -0.5239154100418091, -0.4794554114341736, -0.43499547243118286, -0.39053547382354736, -0.34607553482055664, -0.30161553621292114, -0.25715553760528564, -0.21269559860229492, -0.16823554039001465, -0.12377560138702393, -0.0793156623840332, -0.03485572338104248, 0.009604334831237793, 0.054064273834228516, 0.09852421283721924, 0.1429842710494995, 0.18744421005249023, 0.23190414905548096, 0.27636420726776123, 0.32082414627075195, 0.3652840852737427, 0.40974414348602295, 0.45420408248901367, 0.4986640214920044, 0.5431239604949951, 0.5875840187072754, 0.6320439577102661, 0.6765038967132568, 0.7209639549255371, 0.7654240131378174, 0.8098838329315186, 0.8543438911437988, 0.8988039493560791, 0.9432637691497803, 0.9877238273620605, 1.0321836471557617, 1.076643705368042, 1.1211037635803223, 1.1655635833740234, 1.2100236415863037, 1.254483699798584, 1.2989435195922852, 1.3434035778045654, 1.3878636360168457, 1.4323234558105469, 1.4767835140228271, 1.5212435722351074, 1.5657033920288086, 1.6101634502410889]}, "_runtime": 395.0364351272583, "_timestamp": 1585570310.8810685, "_step": 298}
{"Episode reward": 76.83708133101459, "Episode length": 232, "Policy Loss": 2.1548044681549072, "Value Loss": 39.8874397277832, "_runtime": 396.0220787525177, "_timestamp": 1585570311.866712, "_step": 299}
{"Episode reward": 35.199999999999406, "Episode length": 648, "Policy Loss": -0.04833391681313515, "Value Loss": 14.907681465148926, "_runtime": 397.5493748188019, "_timestamp": 1585570313.3940082, "_step": 300}
{"Episode reward": -99.7203603386865, "Episode length": 999, "Policy Loss": -1.1179836988449097, "Value Loss": 0.10876169800758362, "_runtime": 399.01465916633606, "_timestamp": 1585570314.8592925, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.154043436050415, "Value Loss": 0.14500218629837036, "_runtime": 400.5220854282379, "_timestamp": 1585570316.3667188, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1759178638458252, "Value Loss": 0.08055222779512405, "_runtime": 401.0742218494415, "_timestamp": 1585570316.9188552, "_step": 303}
{"Episode reward": 65.9999999999998, "Episode length": 340, "Policy Loss": 1.3538696765899658, "Value Loss": 27.85121726989746, "_runtime": 402.592084646225, "_timestamp": 1585570318.436718, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8744463324546814, "Value Loss": 0.09283671528100967, "_runtime": 403.72233629226685, "_timestamp": 1585570319.5669696, "_step": 305}
{"Episode reward": 26.099999999999923, "Episode length": 739, "Policy Loss": 0.3959164023399353, "Value Loss": 12.595880508422852, "_runtime": 405.2171719074249, "_timestamp": 1585570321.0618052, "_step": 306}
{"Episode reward": -99.80108422189811, "Episode length": 999, "Policy Loss": -0.5884455442428589, "Value Loss": 0.03289153426885605, "_runtime": 406.7984154224396, "_timestamp": 1585570322.6430488, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6472517251968384, "Value Loss": 0.2604774832725525, "_runtime": 407.6650574207306, "_timestamp": 1585570323.5096908, "_step": 308}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 0.977063775062561, "Value Loss": 16.552461624145508, "_runtime": 409.20144033432007, "_timestamp": 1585570325.0460737, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42013248801231384, "Value Loss": 0.06193796917796135, "_runtime": 410.7493658065796, "_timestamp": 1585570326.5939991, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5146434307098389, "Value Loss": 0.07572604715824127, "_runtime": 412.2580919265747, "_timestamp": 1585570328.1027253, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5451136231422424, "Value Loss": 0.02067609690129757, "_runtime": 413.08947134017944, "_timestamp": 1585570328.9341047, "_step": 312}
{"Episode reward": 47.19999999999953, "Episode length": 528, "Policy Loss": 0.8589664697647095, "Value Loss": 17.313411712646484, "_runtime": 414.62193989753723, "_timestamp": 1585570330.4665732, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6749790906906128, "Value Loss": 0.016102857887744904, "_runtime": 415.89669156074524, "_timestamp": 1585570331.741325, "_step": 314}
{"Episode reward": 17.400000000000418, "Episode length": 826, "Policy Loss": 0.13188539445400238, "Value Loss": 11.236173629760742, "_runtime": 416.97148394584656, "_timestamp": 1585570332.8161173, "_step": 315}
{"Episode reward": 28.99886953681684, "Episode length": 711, "Policy Loss": 0.19173312187194824, "Value Loss": 13.394750595092773, "_runtime": 417.91454792022705, "_timestamp": 1585570333.7591813, "_step": 316}
{"Episode reward": 39.682799952010974, "Episode length": 605, "Policy Loss": 0.5068035125732422, "Value Loss": 14.944757461547852, "_runtime": 419.43183159828186, "_timestamp": 1585570335.276465, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6589378118515015, "Value Loss": 0.015480979345738888, "_runtime": 420.9454779624939, "_timestamp": 1585570336.7901113, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5972873568534851, "Value Loss": 0.007817085832357407, "_runtime": 422.4542384147644, "_timestamp": 1585570338.2988718, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6682965159416199, "Value Loss": 0.6248828768730164, "_runtime": 423.991397857666, "_timestamp": 1585570339.8360312, "_step": 320}
{"Episode reward": -99.80723348641628, "Episode length": 999, "Policy Loss": -0.4274154603481293, "Value Loss": 0.01795164681971073, "_runtime": 425.2436800003052, "_timestamp": 1585570341.0883133, "_step": 321}
{"Episode reward": 18.100000000000378, "Episode length": 819, "Policy Loss": 0.4066976010799408, "Value Loss": 11.566418647766113, "_runtime": 426.78989267349243, "_timestamp": 1585570342.634526, "_step": 322}
{"Episode reward": -99.80021164829238, "Episode length": 999, "Policy Loss": -0.49012893438339233, "Value Loss": 0.07153517007827759, "_runtime": 427.2694728374481, "_timestamp": 1585570343.1141062, "_step": 323}
{"Episode reward": 71.39999999999986, "Episode length": 286, "Policy Loss": 2.1350595951080322, "Value Loss": 31.85891342163086, "_runtime": 428.0510473251343, "_timestamp": 1585570343.8956807, "_step": 324}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 1.0296993255615234, "Value Loss": 17.68412971496582, "_runtime": 429.6186375617981, "_timestamp": 1585570345.463271, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7252055406570435, "Value Loss": 0.020707739517092705, "_runtime": 431.08994579315186, "_timestamp": 1585570346.9345791, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8211069107055664, "Value Loss": 0.026487188413739204, "_runtime": 431.46561551094055, "_timestamp": 1585570347.3102489, "_step": 327}
{"Episode reward": 76.83392485231155, "Episode length": 232, "Policy Loss": 2.9465436935424805, "Value Loss": 38.785675048828125, "_runtime": 432.03699016571045, "_timestamp": 1585570347.8816235, "_step": 328}
{"Episode reward": 63.55806513389083, "Episode length": 366, "Policy Loss": 1.1140804290771484, "Value Loss": 24.991727828979492, "_runtime": 433.48586869239807, "_timestamp": 1585570349.330502, "_step": 329}
{"Episode reward": 3.200000000001225, "Episode length": 968, "Policy Loss": -0.13962098956108093, "Value Loss": 9.378162384033203, "_runtime": 434.95020031929016, "_timestamp": 1585570350.7948337, "_step": 330}
{"Episode reward": -99.78387887971336, "Episode length": 999, "Policy Loss": -0.8851266503334045, "Value Loss": 0.2810155749320984, "_runtime": 436.2144844532013, "_timestamp": 1585570352.0591178, "_step": 331}
{"Episode reward": 14.054537969455737, "Episode length": 860, "Policy Loss": 0.17109690606594086, "Value Loss": 10.536879539489746, "_runtime": 437.0560839176178, "_timestamp": 1585570352.9007173, "_step": 332}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.681082546710968, "Value Loss": 16.102352142333984, "_runtime": 438.58279943466187, "_timestamp": 1585570354.4274328, "_step": 333}
{"Episode reward": -99.85961302667717, "Episode length": 999, "Policy Loss": -0.6332128047943115, "Value Loss": 0.008336586877703667, "_runtime": 439.74351978302, "_timestamp": 1585570355.5881531, "_step": 334}
{"Episode reward": 23.70000000000006, "Episode length": 763, "Policy Loss": 0.1921960413455963, "Value Loss": 12.01273250579834, "_runtime": 440.0789713859558, "_timestamp": 1585570355.9236047, "_step": 335}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": 2.7778873443603516, "Value Loss": 44.99055480957031, "_runtime": 440.81022095680237, "_timestamp": 1585570356.6548543, "_step": 336}
{"Episode reward": 52.553804564452335, "Episode length": 475, "Policy Loss": 0.2876961827278137, "Value Loss": 27.16681480407715, "_runtime": 441.91265892982483, "_timestamp": 1585570357.7572923, "_step": 337}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": 0.14773313701152802, "Value Loss": 12.342251777648926, "_runtime": 443.38446712493896, "_timestamp": 1585570359.2291005, "_step": 338}
{"Episode reward": -99.82185265757003, "Episode length": 999, "Policy Loss": -1.002540946006775, "Value Loss": 0.05934390425682068, "_runtime": 444.07389998435974, "_timestamp": 1585570359.9185333, "_step": 339}
{"Episode reward": 54.59999999999963, "Episode length": 454, "Policy Loss": 0.6580584049224854, "Value Loss": 20.476770401000977, "_runtime": 445.57812666893005, "_timestamp": 1585570361.42276, "_step": 340}
{"Episode reward": -99.81209497600653, "Episode length": 999, "Policy Loss": -1.14577317237854, "Value Loss": 0.10082003474235535, "_runtime": 447.1065585613251, "_timestamp": 1585570362.951192, "_step": 341}
{"Episode reward": -99.67903752662103, "Episode length": 999, "Policy Loss": -1.053609848022461, "Value Loss": 0.49493759870529175, "_runtime": 448.2147557735443, "_timestamp": 1585570364.059389, "_step": 342}
{"Episode reward": 25.990484522283012, "Episode length": 741, "Policy Loss": 0.2495911419391632, "Value Loss": 13.13434886932373, "_runtime": 449.7377028465271, "_timestamp": 1585570365.5823362, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.044285774230957, "Value Loss": 0.367601215839386, "_runtime": 450.80191349983215, "_timestamp": 1585570366.6465468, "_step": 344}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.4540214538574219, "Value Loss": 14.18738842010498, "_runtime": 452.3205466270447, "_timestamp": 1585570368.16518, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0127826929092407, "Value Loss": 0.1348424106836319, "_runtime": 453.8578898906708, "_timestamp": 1585570369.7025232, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0748225450515747, "Value Loss": 0.07350735366344452, "_runtime": 454.6531481742859, "_timestamp": 1585570370.4977815, "_step": 347}
{"Episode reward": 48.499999999999545, "Episode length": 515, "Policy Loss": 0.43348807096481323, "Value Loss": 18.319868087768555, "_runtime": 455.07645535469055, "_timestamp": 1585570370.9210887, "_step": 348}
{"Episode reward": 74.72602152228347, "Episode length": 253, "Policy Loss": 1.9042309522628784, "Value Loss": 35.125732421875, "_runtime": 456.5917191505432, "_timestamp": 1585570372.4363525, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2274620532989502, "Value Loss": 0.031017620116472244, "_runtime": 457.6337773799896, "_timestamp": 1585570373.4784107, "_step": 350}
{"Episode reward": 30.76358241417877, "Episode length": 693, "Policy Loss": -0.03309508413076401, "Value Loss": 13.246942520141602, "_runtime": 459.1050748825073, "_timestamp": 1585570374.9497082, "_step": 351}
{"Episode reward": -99.84915992030734, "Episode length": 999, "Policy Loss": -1.4535417556762695, "Value Loss": 0.053629856556653976, "_runtime": 460.6455919742584, "_timestamp": 1585570376.4902253, "_step": 352}
{"Episode reward": 1.607706826926588, "Episode length": 984, "Policy Loss": -0.870456874370575, "Value Loss": 9.666446685791016, "_runtime": 461.95169591903687, "_timestamp": 1585570377.7963293, "_step": 353}
{"Episode reward": 13.468331903219863, "Episode length": 866, "Policy Loss": -0.6204923391342163, "Value Loss": 10.934679985046387, "_runtime": 463.029794216156, "_timestamp": 1585570378.8744276, "_step": 354}
{"Episode reward": 28.899999999999764, "Episode length": 711, "Policy Loss": -0.31083256006240845, "Value Loss": 12.892594337463379, "_runtime": 464.5486810207367, "_timestamp": 1585570380.3933144, "_step": 355}
{"Episode reward": -99.81250380361313, "Episode length": 999, "Policy Loss": -1.231332540512085, "Value Loss": 0.10059512406587601, "_runtime": 466.06442165374756, "_timestamp": 1585570381.909055, "_step": 356}
{"Episode reward": -99.80355234145978, "Episode length": 999, "Policy Loss": -1.091814637184143, "Value Loss": 0.09001635015010834, "_runtime": 467.5550775527954, "_timestamp": 1585570383.399711, "_step": 357}
{"Episode reward": -99.8134244594709, "Episode length": 999, "Policy Loss": -1.0891454219818115, "Value Loss": 0.08149988949298859, "_runtime": 469.0709083080292, "_timestamp": 1585570384.9155416, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9609506130218506, "Value Loss": 0.01660551130771637, "_runtime": 470.5966968536377, "_timestamp": 1585570386.4413302, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.925758421421051, "Value Loss": 0.0383603535592556, "_runtime": 471.74303221702576, "_timestamp": 1585570387.5876656, "_step": 360}
{"Episode reward": 25.09999999999998, "Episode length": 749, "Policy Loss": 0.02425684966146946, "Value Loss": 12.251896858215332, "_runtime": 473.27818775177, "_timestamp": 1585570389.122821, "_step": 361}
{"Episode reward": -99.86492912918189, "Episode length": 999, "Policy Loss": -0.9965566396713257, "Value Loss": 0.48955032229423523, "_runtime": 474.80845284461975, "_timestamp": 1585570390.6530862, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8188884258270264, "Value Loss": 0.017820734530687332, "_runtime": 475.84861302375793, "_timestamp": 1585570391.6932464, "_step": 363}
{"Episode reward": 31.96755785345991, "Episode length": 681, "Policy Loss": 0.9809730052947998, "Value Loss": 13.046533584594727, "_runtime": 476.3195586204529, "_timestamp": 1585570392.164192, "_step": 364}
{"Episode reward": 71.49999999999987, "Episode length": 285, "Policy Loss": 1.6869138479232788, "Value Loss": 31.87660789489746, "_runtime": 477.14519000053406, "_timestamp": 1585570392.9898233, "_step": 365}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 0.4728022515773773, "Value Loss": 16.5285587310791, "_runtime": 478.6429522037506, "_timestamp": 1585570394.4875855, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9080732464790344, "Value Loss": 0.03635391592979431, "_runtime": 479.63966941833496, "_timestamp": 1585570395.4843028, "_step": 367}
{"Episode reward": 30.84545802473987, "Episode length": 692, "Policy Loss": 0.30362388491630554, "Value Loss": 13.04269027709961, "_runtime": 481.1222138404846, "_timestamp": 1585570396.9668472, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8621881008148193, "Value Loss": 0.04360304772853851, "_runtime": 481.82876682281494, "_timestamp": 1585570397.6734002, "_step": 369}
{"Episode reward": 54.799999999999635, "Episode length": 452, "Policy Loss": 0.9430960416793823, "Value Loss": 19.92558479309082, "_runtime": 483.3159964084625, "_timestamp": 1585570399.1606297, "_step": 370}
{"Episode reward": 1.7000000000013102, "Episode length": 983, "Policy Loss": 0.024287987500429153, "Value Loss": 9.1068754196167, "_runtime": 484.37495589256287, "_timestamp": 1585570400.2195892, "_step": 371}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": 0.16268374025821686, "Value Loss": 14.381553649902344, "_runtime": 485.85629630088806, "_timestamp": 1585570401.7009296, "_step": 372}
{"Episode reward": -99.80092998146871, "Episode length": 999, "Policy Loss": -0.6653597354888916, "Value Loss": 0.02678191475570202, "_runtime": 487.19267201423645, "_timestamp": 1585570403.0373054, "_step": 373}
{"Episode reward": 12.56073428569431, "Episode length": 876, "Policy Loss": 0.22384506464004517, "Value Loss": 10.66701889038086, "_runtime": 488.4327576160431, "_timestamp": 1585570404.277391, "_step": 374}
{"Episode reward": 17.975684940442832, "Episode length": 821, "Policy Loss": 0.40071773529052734, "Value Loss": 11.086051940917969, "_runtime": 489.946937084198, "_timestamp": 1585570405.7915704, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7415180206298828, "Value Loss": 0.05288984254002571, "_runtime": 491.4610824584961, "_timestamp": 1585570407.3057158, "_step": 376}
{"Episode reward": -99.83508378574486, "Episode length": 999, "Policy Loss": -0.7684061527252197, "Value Loss": 0.023468250408768654, "_runtime": 492.97263741493225, "_timestamp": 1585570408.8172708, "_step": 377}
{"Episode reward": -99.79531659632782, "Episode length": 999, "Policy Loss": -0.7709378600120544, "Value Loss": 0.02992921508848667, "_runtime": 494.4932858943939, "_timestamp": 1585570410.3379192, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7658025026321411, "Value Loss": 0.05014187842607498, "_runtime": 496.0196805000305, "_timestamp": 1585570411.8643138, "_step": 379}
{"Episode reward": -99.80010622888663, "Episode length": 999, "Policy Loss": -0.7264519929885864, "Value Loss": 0.03703761473298073, "_runtime": 497.02587127685547, "_timestamp": 1585570412.8705046, "_step": 380}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.5223806500434875, "Value Loss": 13.714221000671387, "_runtime": 498.5583403110504, "_timestamp": 1585570414.4029737, "_step": 381}
{"Episode reward": -99.71337301814789, "Episode length": 999, "Policy Loss": -0.7611918449401855, "Value Loss": 0.41528186202049255, "_runtime": 499.327196598053, "_timestamp": 1585570415.17183, "_step": 382}
{"Episode reward": 51.299999999999585, "Episode length": 487, "Policy Loss": 0.8487455248832703, "Value Loss": 18.345239639282227, "_runtime": 500.83772897720337, "_timestamp": 1585570416.6823623, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7431883215904236, "Value Loss": 0.3980688452720642, "_runtime": 502.0156741142273, "_timestamp": 1585570417.8603075, "_step": 384}
{"Episode reward": 22.789468422159672, "Episode length": 773, "Policy Loss": 0.32125324010849, "Value Loss": 11.564023971557617, "_runtime": 502.6799530982971, "_timestamp": 1585570418.5245864, "_step": 385}
{"Episode reward": 56.09999999999965, "Episode length": 439, "Policy Loss": 0.927745521068573, "Value Loss": 21.03438377380371, "_runtime": 503.83406591415405, "_timestamp": 1585570419.6786993, "_step": 386}
{"Episode reward": 23.90000000000005, "Episode length": 761, "Policy Loss": 0.5926598906517029, "Value Loss": 11.849300384521484, "_runtime": 504.4904429912567, "_timestamp": 1585570420.3350763, "_step": 387}
{"Episode reward": 57.99999999999968, "Episode length": 420, "Policy Loss": 1.201421856880188, "Value Loss": 21.71065902709961, "_runtime": 505.9532618522644, "_timestamp": 1585570421.7978952, "_step": 388}
{"Episode reward": 3.799801479281186, "Episode length": 963, "Policy Loss": 0.2937120199203491, "Value Loss": 9.499837875366211, "_runtime": 506.61541509628296, "_timestamp": 1585570422.4600484, "_step": 389}
{"Episode reward": 57.29999999999967, "Episode length": 427, "Policy Loss": 0.8015002608299255, "Value Loss": 22.099428176879883, "_runtime": 508.0883138179779, "_timestamp": 1585570423.9329472, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6294202208518982, "Value Loss": 0.02858732081949711, "_runtime": 508.67920875549316, "_timestamp": 1585570424.523842, "_step": 391}
{"Episode reward": 62.599999999999746, "Episode length": 374, "Policy Loss": 1.3642808198928833, "Value Loss": 24.101680755615234, "_runtime": 510.1451983451843, "_timestamp": 1585570425.9898317, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6253408789634705, "Value Loss": 0.06426398456096649, "_runtime": 511.19341802597046, "_timestamp": 1585570427.0380514, "_step": 393}
{"Episode reward": 31.285902589605755, "Episode length": 690, "Policy Loss": 0.5269089341163635, "Value Loss": 12.674290657043457, "_runtime": 512.6349649429321, "_timestamp": 1585570428.4795983, "_step": 394}
{"Episode reward": 1.3981829999959388, "Episode length": 987, "Policy Loss": 0.061609651893377304, "Value Loss": 9.016646385192871, "_runtime": 514.13893699646, "_timestamp": 1585570429.9835703, "_step": 395}
{"Episode reward": -99.8592742100344, "Episode length": 999, "Policy Loss": -0.7458483576774597, "Value Loss": 0.04681304842233658, "_runtime": 515.4338893890381, "_timestamp": 1585570431.2785227, "_step": 396}
{"Episode reward": 13.000000000000668, "Episode length": 870, "Policy Loss": -0.06726452708244324, "Value Loss": 11.095754623413086, "_runtime": 516.5499334335327, "_timestamp": 1585570432.3945668, "_step": 397}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": 0.23957091569900513, "Value Loss": 11.873871803283691, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557, 0.027405615895986557]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 9.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.961707592010498, -0.6254045367240906, -0.2891014814376831, 0.04720163345336914, 0.38350462913513184, 0.7198076248168945, 1.0561108589172363, 1.392413854598999, 1.7287168502807617, 2.0650198459625244, 2.401322841644287, 2.737626075744629, 3.0739293098449707, 3.4102320671081543, 3.746535301208496, 4.08283805847168, 4.4191412925720215, 4.755444526672363, 5.091747283935547, 5.428050518035889, 5.764353275299072, 6.100656509399414, 6.436959743499756, 6.7732625007629395, 7.1095662117004395, 7.445868968963623, 7.782171726226807, 8.118474960327148, 8.454778671264648, 8.791080474853516, 9.127384185791016, 9.463687896728516, 9.799989700317383, 10.136293411254883, 10.472597122192383, 10.80889892578125, 11.14520263671875, 11.48150634765625, 11.817808151245117, 12.154111862182617, 12.490413665771484, 12.826717376708984, 13.163021087646484, 13.499322891235352, 13.835626602172852, 14.171930313110352, 14.508232116699219, 14.844535827636719, 15.180839538574219, 15.517141342163086, 15.853445053100586, 16.189746856689453, 16.526050567626953, 16.862354278564453, 17.19865608215332, 17.53495979309082, 17.87126350402832, 18.207565307617188, 18.543869018554688, 18.880172729492188, 19.216474533081055, 19.552778244018555, 19.889081954956055, 20.225383758544922, 20.561687469482422]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12825782597064972, -0.12487348914146423, -0.12148915976285934, -0.11810482293367386, -0.11472048610448837, -0.11133615672588348, -0.107951819896698, -0.10456748306751251, -0.10118314623832703, -0.09779881685972214, -0.09441448003053665, -0.09103015065193176, -0.08764581382274628, -0.08426147699356079, -0.0808771401643753, -0.07749280333518982, -0.07410847395658493, -0.07072414457798004, -0.06733980774879456, -0.06395547091960907, -0.060571134090423584, -0.057186804711818695, -0.05380246788263321, -0.05041813105344772, -0.047033801674842834, -0.04364946484565735, -0.04026512801647186, -0.03688079118728638, -0.03349646180868149, -0.030112124979496002, -0.026727788150310516, -0.023343458771705627, -0.01995912194252014, -0.016574785113334656, -0.013190455734729767, -0.009806118905544281, -0.006421782076358795, -0.0030374526977539062, 0.0003468841314315796, 0.0037312209606170654, 0.007115557789802551, 0.010499894618988037, 0.013884216547012329, 0.017268553376197815, 0.0206528902053833, 0.024037227034568787, 0.027421563863754272, 0.03080590069293976, 0.03419022262096405, 0.037574559450149536, 0.04095889627933502, 0.04434323310852051, 0.047727569937705994, 0.05111190676689148, 0.054496243596076965, 0.05788056552410126, 0.06126490235328674, 0.06464923918247223, 0.06803357601165771, 0.0714179128408432, 0.07480224967002869, 0.07818657159805298, 0.08157090842723846, 0.08495524525642395, 0.08833958208560944]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 0.0, 10.0, 9.0, 13.0, 15.0, 21.0, 46.0, 309.0, 40.0, 8.0, 6.0, 4.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.25053688883781433, -0.2196183204650879, -0.18869976699352264, -0.1577811986207962, -0.12686264514923096, -0.09594407677650452, -0.06502550840377808, -0.03410695493221283, -0.003188386559486389, 0.027730166912078857, 0.0586487352848053, 0.08956730365753174, 0.12048587203025818, 0.15140444040298462, 0.18232297897338867, 0.2132415473461151, 0.24416011571884155, 0.275078684091568, 0.30599722266197205, 0.3369158208370209, 0.3678343594074249, 0.39875295758247375, 0.4296714961528778, 0.46059003472328186, 0.4915086328983307, 0.5224272012710571, 0.553345799446106, 0.5842642784118652, 0.6151828765869141, 0.6461014747619629, 0.6770199537277222, 0.707938551902771, 0.7388571500778198, 0.7697756290435791, 0.8006942272186279, 0.8316128253936768, 0.862531304359436, 0.8934499025344849, 0.9243685007095337, 0.955286979675293, 0.9862055778503418, 1.0171241760253906, 1.0480427742004395, 1.0789612531661987, 1.1098798513412476, 1.1407984495162964, 1.1717169284820557, 1.2026355266571045, 1.2335541248321533, 1.2644726037979126, 1.2953912019729614, 1.3263098001480103, 1.357228398323059, 1.3881468772888184, 1.4190654754638672, 1.449984073638916, 1.4809025526046753, 1.5118211507797241, 1.542739748954773, 1.5736582279205322, 1.604576826095581, 1.6354954242706299, 1.6664140224456787, 1.697332501411438, 1.7282510995864868]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.0829366445541382, -1.032891035079956, -0.9828454852104187, -0.9327999353408813, -0.8827543258666992, -0.8327087163925171, -0.7826631665229797, -0.7326176166534424, -0.6825720071792603, -0.6325263977050781, -0.5824808478355408, -0.5324352979660034, -0.4823896884918213, -0.43234407901763916, -0.3822985291481018, -0.33225297927856445, -0.2822073698043823, -0.2321617603302002, -0.18211621046066284, -0.1320706605911255, -0.08202505111694336, -0.03197944164276123, 0.018066048622131348, 0.06811165809631348, 0.1181572675704956, 0.16820287704467773, 0.21824848651885986, 0.26829397678375244, 0.31833958625793457, 0.3683851957321167, 0.4184306859970093, 0.4684762954711914, 0.5185219049453735, 0.5685675144195557, 0.6186131238937378, 0.6686586141586304, 0.7187042236328125, 0.7687498331069946, 0.8187953233718872, 0.8688409328460693, 0.9188865423202515, 0.968932032585144, 1.0189777612686157, 1.0690232515335083, 1.1190687417984009, 1.1691144704818726, 1.2191599607467651, 1.2692056894302368, 1.3192511796951294, 1.369296669960022, 1.4193423986434937, 1.4693878889083862, 1.519433617591858, 1.5694791078567505, 1.619524598121643, 1.6695703268051147, 1.7196158170700073, 1.7696613073349, 1.8197070360183716, 1.8697525262832642, 1.9197980165481567, 1.9698437452316284, 2.0198893547058105, 2.069934844970703, 2.1199803352355957]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 6.0, 8.0, 4.0, 7.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0], "bins": [-2.8903112411499023, -2.832388162612915, -2.7744648456573486, -2.7165417671203613, -2.658618450164795, -2.6006953716278076, -2.542772054672241, -2.484848976135254, -2.4269256591796875, -2.3690025806427, -2.311079263687134, -2.2531561851501465, -2.19523286819458, -2.1373097896575928, -2.0793867111206055, -2.021463394165039, -1.9635401964187622, -1.9056169986724854, -1.8476938009262085, -1.7897706031799316, -1.7318474054336548, -1.673924207687378, -1.616001009941101, -1.5580778121948242, -1.500154733657837, -1.44223153591156, -1.3843083381652832, -1.3263851404190063, -1.2684619426727295, -1.2105387449264526, -1.1526155471801758, -1.094692349433899, -1.036769151687622, -0.9788459539413452, -0.9209227561950684, -0.862999677658081, -0.8050763607025146, -0.7471532821655273, -0.6892299652099609, -0.6313068866729736, -0.5733835697174072, -0.5154604911804199, -0.4575371742248535, -0.3996140956878662, -0.3416907787322998, -0.2837677001953125, -0.2258443832397461, -0.1679213047027588, -0.10999822616577148, -0.05207490921020508, 0.0058481693267822266, 0.06377148628234863, 0.12169456481933594, 0.17961788177490234, 0.23754096031188965, 0.29546427726745605, 0.35338735580444336, 0.41131067276000977, 0.46923375129699707, 0.5271570682525635, 0.5850801467895508, 0.6430034637451172, 0.7009265422821045, 0.7588498592376709, 0.8167729377746582]}, "_runtime": 518.0700459480286, "_timestamp": 1585570433.9146793, "_step": 398}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": -0.26643478870391846, "Value Loss": 9.214346885681152, "_runtime": 519.2236022949219, "_timestamp": 1585570435.0682356, "_step": 399}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 0.12070873379707336, "Value Loss": 11.990860939025879, "_runtime": 519.9120230674744, "_timestamp": 1585570435.7566564, "_step": 400}
{"Episode reward": 55.29999999999964, "Episode length": 447, "Policy Loss": 0.848048746585846, "Value Loss": 19.44985008239746, "_runtime": 521.4242269992828, "_timestamp": 1585570437.2688603, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8240727186203003, "Value Loss": 0.020480306819081306, "_runtime": 522.9297258853912, "_timestamp": 1585570438.7743592, "_step": 402}
{"Episode reward": -99.8089225307093, "Episode length": 999, "Policy Loss": -0.7766414880752563, "Value Loss": 0.03317846357822418, "_runtime": 523.6193199157715, "_timestamp": 1585570439.4639533, "_step": 403}
{"Episode reward": 54.099999999999625, "Episode length": 459, "Policy Loss": 0.733299195766449, "Value Loss": 19.561420440673828, "_runtime": 525.1441147327423, "_timestamp": 1585570440.988748, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7241647243499756, "Value Loss": 0.0160084031522274, "_runtime": 526.1775670051575, "_timestamp": 1585570442.0222003, "_step": 405}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": 0.1512008160352707, "Value Loss": 13.463957786560059, "_runtime": 527.2387895584106, "_timestamp": 1585570443.083423, "_step": 406}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.10184353590011597, "Value Loss": 12.847370147705078, "_runtime": 528.7995154857635, "_timestamp": 1585570444.6441488, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8884128332138062, "Value Loss": 0.024063486605882645, "_runtime": 530.2972538471222, "_timestamp": 1585570446.1418872, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9530377984046936, "Value Loss": 0.041066382080316544, "_runtime": 531.7942490577698, "_timestamp": 1585570447.6388824, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9941025972366333, "Value Loss": 0.0399102047085762, "_runtime": 533.3126213550568, "_timestamp": 1585570449.1572547, "_step": 410}
{"Episode reward": -99.8433552801595, "Episode length": 999, "Policy Loss": -0.9799555540084839, "Value Loss": 0.05278237909078598, "_runtime": 534.5825316905975, "_timestamp": 1585570450.427165, "_step": 411}
{"Episode reward": 17.400000000000418, "Episode length": 826, "Policy Loss": -0.05704062432050705, "Value Loss": 10.657167434692383, "_runtime": 536.1227312088013, "_timestamp": 1585570451.9673645, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8947450518608093, "Value Loss": 0.020242787897586823, "_runtime": 537.6719062328339, "_timestamp": 1585570453.5165396, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7739272713661194, "Value Loss": 0.03273686394095421, "_runtime": 538.9969894886017, "_timestamp": 1585570454.8416228, "_step": 414}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": 0.040251292288303375, "Value Loss": 10.324780464172363, "_runtime": 540.0579059123993, "_timestamp": 1585570455.9025393, "_step": 415}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 0.2829696834087372, "Value Loss": 13.087597846984863, "_runtime": 540.8298811912537, "_timestamp": 1585570456.6745145, "_step": 416}
{"Episode reward": 50.82829784667077, "Episode length": 492, "Policy Loss": 0.4054526388645172, "Value Loss": 20.488117218017578, "_runtime": 541.4126536846161, "_timestamp": 1585570457.257287, "_step": 417}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 1.1406710147857666, "Value Loss": 25.17006492614746, "_runtime": 541.9714121818542, "_timestamp": 1585570457.8160455, "_step": 418}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.0579835176467896, "Value Loss": 24.8104305267334, "_runtime": 542.9082081317902, "_timestamp": 1585570458.7528415, "_step": 419}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.25410541892051697, "Value Loss": 14.288893699645996, "_runtime": 544.3712146282196, "_timestamp": 1585570460.215848, "_step": 420}
{"Episode reward": -99.8006065428243, "Episode length": 999, "Policy Loss": -1.0190186500549316, "Value Loss": 0.055690012872219086, "_runtime": 545.4062330722809, "_timestamp": 1585570461.2508664, "_step": 421}
{"Episode reward": 29.899999999999707, "Episode length": 701, "Policy Loss": -0.0932588204741478, "Value Loss": 13.018011093139648, "_runtime": 546.9019780158997, "_timestamp": 1585570462.7466114, "_step": 422}
{"Episode reward": -99.8566972049172, "Episode length": 999, "Policy Loss": -0.687602162361145, "Value Loss": 0.5328935384750366, "_runtime": 548.4337832927704, "_timestamp": 1585570464.2784166, "_step": 423}
{"Episode reward": -99.8171649992452, "Episode length": 999, "Policy Loss": -0.8076483011245728, "Value Loss": 0.3534519672393799, "_runtime": 549.0438425540924, "_timestamp": 1585570464.888476, "_step": 424}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 1.8107376098632812, "Value Loss": 23.03168487548828, "_runtime": 549.6112477779388, "_timestamp": 1585570465.455881, "_step": 425}
{"Episode reward": 63.79999999999976, "Episode length": 362, "Policy Loss": 1.492704153060913, "Value Loss": 25.115493774414062, "_runtime": 550.2400898933411, "_timestamp": 1585570466.0847232, "_step": 426}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.5291645526885986, "Value Loss": 21.799863815307617, "_runtime": 550.8195645809174, "_timestamp": 1585570466.664198, "_step": 427}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.3016446828842163, "Value Loss": 23.467979431152344, "_runtime": 551.9747054576874, "_timestamp": 1585570467.8193388, "_step": 428}
{"Episode reward": 20.39443219751145, "Episode length": 797, "Policy Loss": 0.35518860816955566, "Value Loss": 11.185874938964844, "_runtime": 553.1867823600769, "_timestamp": 1585570469.0314157, "_step": 429}
{"Episode reward": 17.800000000000395, "Episode length": 822, "Policy Loss": 0.08514963835477829, "Value Loss": 10.527057647705078, "_runtime": 553.9897713661194, "_timestamp": 1585570469.8344047, "_step": 430}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 0.25432536005973816, "Value Loss": 16.23438835144043, "_runtime": 555.5109484195709, "_timestamp": 1585570471.3555818, "_step": 431}
{"Episode reward": -99.8324421465383, "Episode length": 999, "Policy Loss": -1.220734715461731, "Value Loss": 0.030665239319205284, "_runtime": 557.0225651264191, "_timestamp": 1585570472.8671985, "_step": 432}
{"Episode reward": -99.8000480119125, "Episode length": 999, "Policy Loss": -1.4287925958633423, "Value Loss": 0.21201445162296295, "_runtime": 558.5202691555023, "_timestamp": 1585570474.3649025, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.43677818775177, "Value Loss": 0.14263816177845, "_runtime": 559.2896573543549, "_timestamp": 1585570475.1342907, "_step": 434}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": -0.20750169456005096, "Value Loss": 19.190221786499023, "_runtime": 560.8144197463989, "_timestamp": 1585570476.659053, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3528059720993042, "Value Loss": 0.3232320547103882, "_runtime": 562.3547730445862, "_timestamp": 1585570478.1994064, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1486802101135254, "Value Loss": 0.12094109505414963, "_runtime": 563.8581819534302, "_timestamp": 1585570479.7028153, "_step": 437}
{"Episode reward": -99.80593664646008, "Episode length": 999, "Policy Loss": -1.0105681419372559, "Value Loss": 0.29461389780044556, "_runtime": 564.5974087715149, "_timestamp": 1585570480.442042, "_step": 438}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 0.6117861270904541, "Value Loss": 19.521013259887695, "_runtime": 565.5352473258972, "_timestamp": 1585570481.3798807, "_step": 439}
{"Episode reward": 38.787358682974585, "Episode length": 613, "Policy Loss": 0.10726084560155869, "Value Loss": 16.076995849609375, "_runtime": 566.1407742500305, "_timestamp": 1585570481.9854076, "_step": 440}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 1.2898516654968262, "Value Loss": 23.12725067138672, "_runtime": 566.8992261886597, "_timestamp": 1585570482.7438595, "_step": 441}
{"Episode reward": 48.59999999999955, "Episode length": 514, "Policy Loss": 0.12102530151605606, "Value Loss": 19.06889533996582, "_runtime": 568.406585931778, "_timestamp": 1585570484.2512193, "_step": 442}
{"Episode reward": -99.71711717918376, "Episode length": 999, "Policy Loss": -0.9838628172874451, "Value Loss": 0.05332646518945694, "_runtime": 569.8944683074951, "_timestamp": 1585570485.7391016, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0848448276519775, "Value Loss": 0.07137507945299149, "_runtime": 571.3780233860016, "_timestamp": 1585570487.2226567, "_step": 444}
{"Episode reward": -99.80033127106587, "Episode length": 999, "Policy Loss": -1.2162792682647705, "Value Loss": 0.09774797409772873, "_runtime": 571.7775070667267, "_timestamp": 1585570487.6221404, "_step": 445}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": 1.9040616750717163, "Value Loss": 39.49262619018555, "_runtime": 572.7877986431122, "_timestamp": 1585570488.632432, "_step": 446}
{"Episode reward": 33.02900415323627, "Episode length": 670, "Policy Loss": 0.29171594977378845, "Value Loss": 14.535966873168945, "_runtime": 574.3027641773224, "_timestamp": 1585570490.1473975, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.006605863571167, "Value Loss": 0.7134691476821899, "_runtime": 575.2869837284088, "_timestamp": 1585570491.131617, "_step": 448}
{"Episode reward": 33.099999999999525, "Episode length": 669, "Policy Loss": 0.10840269923210144, "Value Loss": 13.683865547180176, "_runtime": 576.0094239711761, "_timestamp": 1585570491.8540573, "_step": 449}
{"Episode reward": 52.398093901574214, "Episode length": 477, "Policy Loss": 0.9232359528541565, "Value Loss": 18.691608428955078, "_runtime": 577.5362424850464, "_timestamp": 1585570493.3808758, "_step": 450}
{"Episode reward": -99.80060464292625, "Episode length": 999, "Policy Loss": -0.8244304656982422, "Value Loss": 0.06185932829976082, "_runtime": 578.4897124767303, "_timestamp": 1585570494.3343458, "_step": 451}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.32102930545806885, "Value Loss": 14.888482093811035, "_runtime": 579.9807908535004, "_timestamp": 1585570495.8254242, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7384908199310303, "Value Loss": 0.01673041470348835, "_runtime": 581.5196917057037, "_timestamp": 1585570497.364325, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7095559239387512, "Value Loss": 0.0370931513607502, "_runtime": 581.9813194274902, "_timestamp": 1585570497.8259528, "_step": 454}
{"Episode reward": 70.99999999999986, "Episode length": 290, "Policy Loss": 1.509750247001648, "Value Loss": 30.85698127746582, "_runtime": 583.5048449039459, "_timestamp": 1585570499.3494782, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7892633080482483, "Value Loss": 0.05215118080377579, "_runtime": 585.0485031604767, "_timestamp": 1585570500.8931365, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9268621802330017, "Value Loss": 0.17990437150001526, "_runtime": 586.5305831432343, "_timestamp": 1585570502.3752165, "_step": 457}
{"Episode reward": -99.80125029086926, "Episode length": 999, "Policy Loss": -0.9211432933807373, "Value Loss": 0.020852448418736458, "_runtime": 588.0818481445312, "_timestamp": 1585570503.9264815, "_step": 458}
{"Episode reward": -99.80602620988945, "Episode length": 999, "Policy Loss": -0.9325615763664246, "Value Loss": 0.09795264154672623, "_runtime": 589.4209208488464, "_timestamp": 1585570505.2655542, "_step": 459}
{"Episode reward": 13.005963039398864, "Episode length": 870, "Policy Loss": -0.11689622700214386, "Value Loss": 10.294904708862305, "_runtime": 590.9505617618561, "_timestamp": 1585570506.795195, "_step": 460}
{"Episode reward": -99.80518295913795, "Episode length": 999, "Policy Loss": -0.9096876382827759, "Value Loss": 0.2682923376560211, "_runtime": 591.5814261436462, "_timestamp": 1585570507.4260595, "_step": 461}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.0562493801116943, "Value Loss": 23.217287063598633, "_runtime": 592.6833460330963, "_timestamp": 1585570508.5279794, "_step": 462}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": 0.1100071519613266, "Value Loss": 12.511761665344238, "_runtime": 593.6027903556824, "_timestamp": 1585570509.4474237, "_step": 463}
{"Episode reward": 40.5255772594124, "Episode length": 595, "Policy Loss": 0.9081724286079407, "Value Loss": 16.651893615722656, "_runtime": 595.1021449565887, "_timestamp": 1585570510.9467783, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6758866310119629, "Value Loss": 0.03255441039800644, "_runtime": 596.6175022125244, "_timestamp": 1585570512.4621356, "_step": 465}
{"Episode reward": -99.8127881322042, "Episode length": 999, "Policy Loss": -0.5750550031661987, "Value Loss": 0.1867179274559021, "_runtime": 597.0773305892944, "_timestamp": 1585570512.921964, "_step": 466}
{"Episode reward": 71.29997403621661, "Episode length": 288, "Policy Loss": 2.1009140014648438, "Value Loss": 30.48552131652832, "_runtime": 598.5992255210876, "_timestamp": 1585570514.4438589, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3740670680999756, "Value Loss": 0.3099564015865326, "_runtime": 599.7564604282379, "_timestamp": 1585570515.6010938, "_step": 468}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": 0.6184964776039124, "Value Loss": 12.382526397705078, "_runtime": 601.2732563018799, "_timestamp": 1585570517.1178896, "_step": 469}
{"Episode reward": -99.87700640940899, "Episode length": 999, "Policy Loss": -0.4606526494026184, "Value Loss": 0.1902308315038681, "_runtime": 602.8135702610016, "_timestamp": 1585570518.6582036, "_step": 470}
{"Episode reward": 0.6065488185747228, "Episode length": 995, "Policy Loss": 0.2273523360490799, "Value Loss": 9.209956169128418, "_runtime": 604.3170495033264, "_timestamp": 1585570520.1616828, "_step": 471}
{"Episode reward": -99.76309353150288, "Episode length": 999, "Policy Loss": -0.6362073421478271, "Value Loss": 0.08537556231021881, "_runtime": 605.274534702301, "_timestamp": 1585570521.119168, "_step": 472}
{"Episode reward": 38.19831859013006, "Episode length": 619, "Policy Loss": 0.6239505410194397, "Value Loss": 14.051880836486816, "_runtime": 606.4964897632599, "_timestamp": 1585570522.341123, "_step": 473}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.1606442630290985, "Value Loss": 11.012765884399414, "_runtime": 607.1250648498535, "_timestamp": 1585570522.9696982, "_step": 474}
{"Episode reward": 60.59999999999972, "Episode length": 394, "Policy Loss": 0.9191941618919373, "Value Loss": 23.857791900634766, "_runtime": 607.7259843349457, "_timestamp": 1585570523.5706177, "_step": 475}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 0.9438227415084839, "Value Loss": 21.526660919189453, "_runtime": 608.3640277385712, "_timestamp": 1585570524.208661, "_step": 476}
{"Episode reward": 57.599999999999675, "Episode length": 424, "Policy Loss": 0.48893600702285767, "Value Loss": 25.17901039123535, "_runtime": 609.8287570476532, "_timestamp": 1585570525.6733904, "_step": 477}
{"Episode reward": -99.72782113849978, "Episode length": 999, "Policy Loss": -0.9665018916130066, "Value Loss": 0.022778373211622238, "_runtime": 611.2187006473541, "_timestamp": 1585570527.063334, "_step": 478}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": -0.3020935356616974, "Value Loss": 10.057966232299805, "_runtime": 612.6893472671509, "_timestamp": 1585570528.5339806, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0028408765792847, "Value Loss": 0.09743785113096237, "_runtime": 614.1972374916077, "_timestamp": 1585570530.0418708, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.002699375152588, "Value Loss": 0.06916876137256622, "_runtime": 615.7071101665497, "_timestamp": 1585570531.5517435, "_step": 481}
{"Episode reward": -99.78830166049163, "Episode length": 999, "Policy Loss": -0.8407295346260071, "Value Loss": 0.22735045850276947, "_runtime": 617.2200131416321, "_timestamp": 1585570533.0646465, "_step": 482}
{"Episode reward": -99.77246399866279, "Episode length": 999, "Policy Loss": -0.860912561416626, "Value Loss": 0.410491406917572, "_runtime": 618.7524559497833, "_timestamp": 1585570534.5970893, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8721367716789246, "Value Loss": 0.15696966648101807, "_runtime": 619.4997684955597, "_timestamp": 1585570535.3444018, "_step": 484}
{"Episode reward": 52.2999999999996, "Episode length": 477, "Policy Loss": 0.868705153465271, "Value Loss": 19.321020126342773, "_runtime": 621.0255424976349, "_timestamp": 1585570536.8701758, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8530058264732361, "Value Loss": 0.11843839287757874, "_runtime": 622.3383872509003, "_timestamp": 1585570538.1830206, "_step": 486}
{"Episode reward": 13.931653207168594, "Episode length": 861, "Policy Loss": 0.03347990661859512, "Value Loss": 11.14581298828125, "_runtime": 623.859245300293, "_timestamp": 1585570539.7038786, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7628887295722961, "Value Loss": 0.03264002874493599, "_runtime": 624.7338719367981, "_timestamp": 1585570540.5785053, "_step": 488}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 0.5847337245941162, "Value Loss": 15.8805513381958, "_runtime": 626.2418665885925, "_timestamp": 1585570542.0865, "_step": 489}
{"Episode reward": -99.71775936419006, "Episode length": 999, "Policy Loss": -0.7385368943214417, "Value Loss": 0.04402755945920944, "_runtime": 627.7569167613983, "_timestamp": 1585570543.60155, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7403260469436646, "Value Loss": 0.028745166957378387, "_runtime": 628.816638469696, "_timestamp": 1585570544.6612718, "_step": 491}
{"Episode reward": 29.62211538904785, "Episode length": 704, "Policy Loss": 0.29319605231285095, "Value Loss": 13.545929908752441, "_runtime": 630.3450736999512, "_timestamp": 1585570546.189707, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7250237464904785, "Value Loss": 0.011911539360880852, "_runtime": 631.8685290813446, "_timestamp": 1585570547.7131624, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6944679021835327, "Value Loss": 0.009901268407702446, "_runtime": 632.6926383972168, "_timestamp": 1585570548.5372717, "_step": 494}
{"Episode reward": 46.27876422163051, "Episode length": 539, "Policy Loss": 0.7187772393226624, "Value Loss": 16.348073959350586, "_runtime": 633.3713192939758, "_timestamp": 1585570549.2159526, "_step": 495}
{"Episode reward": 56.49999999999966, "Episode length": 435, "Policy Loss": 1.139269471168518, "Value Loss": 20.653194427490234, "_runtime": 634.8803498744965, "_timestamp": 1585570550.7249832, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.625404953956604, "Value Loss": 0.011824269779026508, "_runtime": 636.3683121204376, "_timestamp": 1585570552.2129455, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.60154128074646, "Value Loss": 0.02110985293984413, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005, -0.08974190056324005]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-3.626253128051758, -3.562509775161743, -3.4987664222717285, -3.435023069381714, -3.371279716491699, -3.3075363636016846, -3.24379301071167, -3.1800498962402344, -3.1163063049316406, -3.052563190460205, -2.9888195991516113, -2.925076484680176, -2.861333131790161, -2.7975897789001465, -2.733846426010132, -2.670103073120117, -2.6063597202301025, -2.542616367340088, -2.4788730144500732, -2.4151296615600586, -2.351386308670044, -2.2876429557800293, -2.2238998413085938, -2.16015625, -2.0964131355285645, -2.0326695442199707, -1.9689263105392456, -1.905182957649231, -1.8414397239685059, -1.7776963710784912, -1.7139530181884766, -1.650209665298462, -1.5864663124084473, -1.5227229595184326, -1.458979606628418, -1.3952362537384033, -1.3314929008483887, -1.267749547958374, -1.2040061950683594, -1.1402628421783447, -1.07651948928833, -1.0127763748168945, -0.9490330219268799, -0.8852896690368652, -0.8215463161468506, -0.7578029632568359, -0.6940596103668213, -0.6303162574768066, -0.566572904586792, -0.5028295516967773, -0.4390861988067627, -0.37534284591674805, -0.3115994930267334, -0.24785614013671875, -0.1841127872467041, -0.12036943435668945, -0.056626319885253906, 0.007117033004760742, 0.07086038589477539, 0.13460373878479004, 0.1983470916748047, 0.26209044456481934, 0.325833797454834, 0.38957738876342773, 0.4533205032348633]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 2.0], "bins": [-0.281872421503067, -0.2773573696613312, -0.27284231781959534, -0.2683272957801819, -0.26381224393844604, -0.2592971920967102, -0.25478214025497437, -0.2502670884132385, -0.24575205147266388, -0.24123701453208923, -0.2367219626903534, -0.23220691084861755, -0.2276918590068817, -0.22317682206630707, -0.21866177022457123, -0.21414673328399658, -0.20963168144226074, -0.2051166296005249, -0.20060159265995026, -0.19608654081821442, -0.19157150387763977, -0.18705645203590393, -0.1825414001941681, -0.17802634835243225, -0.1735113114118576, -0.16899627447128296, -0.16448122262954712, -0.15996617078781128, -0.15545111894607544, -0.1509360820055008, -0.14642103016376495, -0.1419059932231903, -0.13739094138145447, -0.13287588953971863, -0.12836085259914398, -0.12384580075740814, -0.1193307638168335, -0.11481571197509766, -0.11030066013336182, -0.10578562319278717, -0.10127057135105133, -0.09675551950931549, -0.09224048256874084, -0.087725430727005, -0.08321037888526917, -0.07869534194469452, -0.07418029010295868, -0.06966525316238403, -0.0651502013206482, -0.060635149478912354, -0.05612011253833771, -0.05160506069660187, -0.04709002375602722, -0.04257497191429138, -0.03805992007255554, -0.033544883131980896, -0.029029816389083862, -0.02451479434967041, -0.01999974250793457, -0.01548469066619873, -0.01096963882446289, -0.006454586982727051, -0.0019395649433135986, 0.002575486898422241, 0.007090538740158081]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 7.0, 16.0, 317.0, 30.0, 11.0, 15.0, 8.0, 2.0, 3.0, 4.0, 3.0, 4.0, 5.0, 5.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.3916660249233246, -0.3812491297721863, -0.370832234621048, -0.36041533946990967, -0.34999847412109375, -0.33958157896995544, -0.32916468381881714, -0.31874778866767883, -0.3083308935165405, -0.2979139983654022, -0.2874971032142639, -0.277080237865448, -0.2666633129119873, -0.2562464475631714, -0.24582955241203308, -0.23541265726089478, -0.22499576210975647, -0.21457886695861816, -0.20416197180747986, -0.19374509155750275, -0.18332819640636444, -0.17291130125522614, -0.16249442100524902, -0.15207752585411072, -0.1416606307029724, -0.1312437355518341, -0.1208268404006958, -0.1104099452495575, -0.09999307990074158, -0.08957618474960327, -0.07915928959846497, -0.06874239444732666, -0.058325499296188354, -0.04790860414505005, -0.03749170899391174, -0.027074813842773438, -0.016657918691635132, -0.006241053342819214, 0.004175841808319092, 0.014592736959457397, 0.025009632110595703, 0.03542652726173401, 0.045843422412872314, 0.05626031756401062, 0.06667718291282654, 0.07709407806396484, 0.08751097321510315, 0.09792786836624146, 0.10834476351737976, 0.11876162886619568, 0.12917855381965637, 0.1395954191684723, 0.15001234412193298, 0.1604292094707489, 0.1708461344242096, 0.1812629997730255, 0.19167986512184143, 0.20209679007530212, 0.21251365542411804, 0.22293058037757874, 0.23334744572639465, 0.24376437067985535, 0.25418123602867126, 0.26459816098213196, 0.2750150263309479]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-3.2899768352508545, -3.227783679962158, -3.165590286254883, -3.1033968925476074, -3.041203737258911, -2.979010581970215, -2.9168171882629395, -2.854623794555664, -2.7924306392669678, -2.7302374839782715, -2.668044090270996, -2.6058506965637207, -2.5436575412750244, -2.481464385986328, -2.4192709922790527, -2.3570775985717773, -2.294884443283081, -2.2326912879943848, -2.1704978942871094, -2.108304500579834, -2.0461113452911377, -1.9839180707931519, -1.921724796295166, -1.8595315217971802, -1.7973382472991943, -1.7351449728012085, -1.6729516983032227, -1.6107584238052368, -1.548565149307251, -1.4863718748092651, -1.4241786003112793, -1.3619853258132935, -1.2997920513153076, -1.2375986576080322, -1.175405502319336, -1.1132123470306396, -1.0510189533233643, -0.9888255596160889, -0.9266324043273926, -0.8644392490386963, -0.8022458553314209, -0.7400524616241455, -0.6778593063354492, -0.6156661510467529, -0.5534727573394775, -0.49127936363220215, -0.42908620834350586, -0.36689305305480957, -0.3046996593475342, -0.2425062656402588, -0.1803131103515625, -0.11811995506286621, -0.05592656135559082, 0.00626683235168457, 0.06845998764038086, 0.13065314292907715, 0.19284653663635254, 0.25503993034362793, 0.3172330856323242, 0.3794262409210205, 0.4416196346282959, 0.5038130283355713, 0.5660061836242676, 0.6281993389129639, 0.6903927326202393]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 6.0, 8.0, 5.0, 4.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-4.742565631866455, -4.654362678527832, -4.566160202026367, -4.477957248687744, -4.389754295349121, -4.301551818847656, -4.213348865509033, -4.12514591217041, -4.036943435668945, -3.9487404823303223, -3.8605377674102783, -3.7723350524902344, -3.6841320991516113, -3.5959296226501465, -3.5077266693115234, -3.4195239543914795, -3.3313212394714355, -3.2431182861328125, -3.1549155712127686, -3.0667128562927246, -2.9785099029541016, -2.8903071880340576, -2.8021044731140137, -2.7139017581939697, -2.6256988048553467, -2.5374960899353027, -2.449293375015259, -2.3610904216766357, -2.272887706756592, -2.184684991836548, -2.096482276916504, -2.008279323577881, -1.920076608657837, -1.831873893737793, -1.74367094039917, -1.655468225479126, -1.567265510559082, -1.479062795639038, -1.390859842300415, -1.302657127380371, -1.2144544124603271, -1.126251459121704, -1.0380487442016602, -0.9498460292816162, -0.8616433143615723, -0.7734403610229492, -0.6852378845214844, -0.5970349311828613, -0.5088319778442383, -0.42062950134277344, -0.3324265480041504, -0.24422359466552734, -0.1560211181640625, -0.06781816482543945, 0.020384788513183594, 0.10858726501464844, 0.19679021835327148, 0.28499317169189453, 0.3731956481933594, 0.4613986015319824, 0.5496010780334473, 0.6378040313720703, 0.7260069847106934, 0.8142094612121582, 0.9024124145507812]}, "_runtime": 637.224004983902, "_timestamp": 1585570553.0686383, "_step": 498}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": 0.6834765672683716, "Value Loss": 16.555599212646484, "_runtime": 637.224004983902, "_timestamp": 1585570553.0686383, "_step": 499}
