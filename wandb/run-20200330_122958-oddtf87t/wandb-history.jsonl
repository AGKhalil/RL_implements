{"Episode reward": 65.9822268951933, "Episode length": 556, "Policy Loss": 0.2709799110889435, "Value Loss": 17.88482666015625, "_runtime": 1493.9812686443329, "_timestamp": 1585571409.825902, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24858108162879944, "Value Loss": 16.937599182128906, "_runtime": 1495.444727897644, "_timestamp": 1585571411.2893612, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6445572376251221, "Value Loss": 0.03690313547849655, "_runtime": 1496.9488043785095, "_timestamp": 1585571412.7934377, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0951250791549683, "Value Loss": 0.04347894713282585, "_runtime": 1498.5306527614594, "_timestamp": 1585571414.375286, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2490416765213013, "Value Loss": 0.027186023071408272, "_runtime": 1500.0569682121277, "_timestamp": 1585571415.9016016, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.224223256111145, "Value Loss": 0.033931028097867966, "_runtime": 1501.609207391739, "_timestamp": 1585571417.4538407, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.183976173400879, "Value Loss": 0.25006937980651855, "_runtime": 1503.1639170646667, "_timestamp": 1585571419.0085504, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2510801553726196, "Value Loss": 0.05864116549491882, "_runtime": 1504.6823070049286, "_timestamp": 1585571420.5269403, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.268641710281372, "Value Loss": 0.15162251889705658, "_runtime": 1506.2394170761108, "_timestamp": 1585571422.0840504, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2856272459030151, "Value Loss": 0.09793035686016083, "_runtime": 1507.7959191799164, "_timestamp": 1585571423.6405525, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2914257049560547, "Value Loss": 0.6034026145935059, "_runtime": 1509.345297574997, "_timestamp": 1585571425.189931, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3002502918243408, "Value Loss": 0.04863007366657257, "_runtime": 1510.9145922660828, "_timestamp": 1585571426.7592256, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.278511643409729, "Value Loss": 0.09833130240440369, "_runtime": 1512.4687390327454, "_timestamp": 1585571428.3133724, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2428058385849, "Value Loss": 0.018418585881590843, "_runtime": 1514.0192275047302, "_timestamp": 1585571429.8638608, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2053499221801758, "Value Loss": 0.03606467321515083, "_runtime": 1515.589171886444, "_timestamp": 1585571431.4338052, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1791282892227173, "Value Loss": 0.029021630063652992, "_runtime": 1517.1438109874725, "_timestamp": 1585571432.9884443, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1427459716796875, "Value Loss": 0.04431789368391037, "_runtime": 1518.699092388153, "_timestamp": 1585571434.5437257, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1171131134033203, "Value Loss": 0.1861652284860611, "_runtime": 1520.3013198375702, "_timestamp": 1585571436.1459532, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0749658346176147, "Value Loss": 0.014147752895951271, "_runtime": 1521.847410440445, "_timestamp": 1585571437.6920438, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9883043169975281, "Value Loss": 0.022316647693514824, "_runtime": 1523.4067554473877, "_timestamp": 1585571439.2513888, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2211085855960846, "Value Loss": 0.0619032084941864, "_runtime": 1524.9719576835632, "_timestamp": 1585571440.816591, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6009539365768433, "Value Loss": 0.026021631434559822, "_runtime": 1526.5235359668732, "_timestamp": 1585571442.3681693, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29608312249183655, "Value Loss": 0.14362165331840515, "_runtime": 1528.0826952457428, "_timestamp": 1585571443.9273286, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18850168585777283, "Value Loss": 0.1909128874540329, "_runtime": 1528.3106410503387, "_timestamp": 1585571444.1552744, "_step": 23}
{"Episode reward": 90.69178379476409, "Episode length": 99, "Policy Loss": -2.0100064277648926, "Value Loss": 100.8636245727539, "_runtime": 1528.527109861374, "_timestamp": 1585571444.3717432, "_step": 24}
{"Episode reward": 90.27850985245892, "Episode length": 100, "Policy Loss": 5.198645114898682, "Value Loss": 98.55078887939453, "_runtime": 1528.734385728836, "_timestamp": 1585571444.579019, "_step": 25}
{"Episode reward": 90.65044319358654, "Episode length": 96, "Policy Loss": 4.578115940093994, "Value Loss": 101.38909149169922, "_runtime": 1528.98335313797, "_timestamp": 1585571444.8279865, "_step": 26}
{"Episode reward": 83.90909024068382, "Episode length": 170, "Policy Loss": 1.411163091659546, "Value Loss": 56.56640625, "_runtime": 1529.239580631256, "_timestamp": 1585571445.084214, "_step": 27}
{"Episode reward": 83.11372450572884, "Episode length": 178, "Policy Loss": 0.9657281637191772, "Value Loss": 54.125999450683594, "_runtime": 1529.4636867046356, "_timestamp": 1585571445.30832, "_step": 28}
{"Episode reward": 85.52298115493207, "Episode length": 156, "Policy Loss": 0.003678138367831707, "Value Loss": 61.09552001953125, "_runtime": 1529.604964017868, "_timestamp": 1585571445.4495974, "_step": 29}
{"Episode reward": 91.19741113823986, "Episode length": 91, "Policy Loss": 3.857010841369629, "Value Loss": 103.79041290283203, "_runtime": 1529.7374534606934, "_timestamp": 1585571445.5820868, "_step": 30}
{"Episode reward": 92.04859404755916, "Episode length": 84, "Policy Loss": 4.584572792053223, "Value Loss": 111.60963439941406, "_runtime": 1529.8724591732025, "_timestamp": 1585571445.7170925, "_step": 31}
{"Episode reward": 91.63135759765659, "Episode length": 88, "Policy Loss": 4.328676223754883, "Value Loss": 105.898193359375, "_runtime": 1530.104056596756, "_timestamp": 1585571445.94869, "_step": 32}
{"Episode reward": 84.96364448922155, "Episode length": 161, "Policy Loss": -6.6651482582092285, "Value Loss": 65.06768798828125, "_runtime": 1530.229367017746, "_timestamp": 1585571446.0740004, "_step": 33}
{"Episode reward": 92.764456945032, "Episode length": 83, "Policy Loss": -0.44354552030563354, "Value Loss": 111.34362030029297, "_runtime": 1530.4684598445892, "_timestamp": 1585571446.3130932, "_step": 34}
{"Episode reward": 84.47828805742625, "Episode length": 168, "Policy Loss": -4.173877716064453, "Value Loss": 59.75333786010742, "_runtime": 1530.5978608131409, "_timestamp": 1585571446.4424942, "_step": 35}
{"Episode reward": 92.62113466714241, "Episode length": 83, "Policy Loss": 2.0694217681884766, "Value Loss": 111.87843322753906, "_runtime": 1530.8184070587158, "_timestamp": 1585571446.6630404, "_step": 36}
{"Episode reward": 86.16587250780876, "Episode length": 154, "Policy Loss": 2.587146759033203, "Value Loss": 60.53024673461914, "_runtime": 1531.031839132309, "_timestamp": 1585571446.8764725, "_step": 37}
{"Episode reward": 87.25950221591812, "Episode length": 145, "Policy Loss": 3.1896204948425293, "Value Loss": 63.854713439941406, "_runtime": 1531.2538542747498, "_timestamp": 1585571447.0984876, "_step": 38}
{"Episode reward": 86.06319163054361, "Episode length": 157, "Policy Loss": 2.9847874641418457, "Value Loss": 57.90280532836914, "_runtime": 1531.4658041000366, "_timestamp": 1585571447.3104374, "_step": 39}
{"Episode reward": 87.51120550314737, "Episode length": 144, "Policy Loss": 4.12252140045166, "Value Loss": 61.21205139160156, "_runtime": 1531.6888220310211, "_timestamp": 1585571447.5334554, "_step": 40}
{"Episode reward": 86.62932739391981, "Episode length": 153, "Policy Loss": 1.4448127746582031, "Value Loss": 58.29938507080078, "_runtime": 1531.9194815158844, "_timestamp": 1585571447.7641149, "_step": 41}
{"Episode reward": 86.20845844843731, "Episode length": 158, "Policy Loss": 0.9962694048881531, "Value Loss": 55.50475311279297, "_runtime": 1532.1354887485504, "_timestamp": 1585571447.980122, "_step": 42}
{"Episode reward": 87.71334750239147, "Episode length": 148, "Policy Loss": 0.23758256435394287, "Value Loss": 58.94195556640625, "_runtime": 1532.3533282279968, "_timestamp": 1585571448.1979616, "_step": 43}
{"Episode reward": 87.24135790829054, "Episode length": 150, "Policy Loss": 0.49328967928886414, "Value Loss": 56.93393325805664, "_runtime": 1532.482698917389, "_timestamp": 1585571448.3273323, "_step": 44}
{"Episode reward": 93.3522693090751, "Episode length": 83, "Policy Loss": 1.0582389831542969, "Value Loss": 111.20185089111328, "_runtime": 1532.7996141910553, "_timestamp": 1585571448.6442475, "_step": 45}
{"Episode reward": 83.04170856060934, "Episode length": 221, "Policy Loss": -0.2247721254825592, "Value Loss": 37.76578903198242, "_runtime": 1533.0240468978882, "_timestamp": 1585571448.8686802, "_step": 46}
{"Episode reward": 86.27924023295802, "Episode length": 154, "Policy Loss": -0.3143785297870636, "Value Loss": 58.63471603393555, "_runtime": 1533.2364110946655, "_timestamp": 1585571449.0810444, "_step": 47}
{"Episode reward": 87.74955362403882, "Episode length": 148, "Policy Loss": 0.0683583989739418, "Value Loss": 55.18793487548828, "_runtime": 1533.3698041439056, "_timestamp": 1585571449.2144375, "_step": 48}
{"Episode reward": 93.1748983324939, "Episode length": 84, "Policy Loss": 2.9816904067993164, "Value Loss": 97.77730560302734, "_runtime": 1533.4985196590424, "_timestamp": 1585571449.343153, "_step": 49}
{"Episode reward": 92.82884260882012, "Episode length": 83, "Policy Loss": 4.114689826965332, "Value Loss": 99.02562713623047, "_runtime": 1533.7198538780212, "_timestamp": 1585571449.5644872, "_step": 50}
{"Episode reward": 87.19873817762799, "Episode length": 151, "Policy Loss": 1.236675500869751, "Value Loss": 51.66161346435547, "_runtime": 1533.844337940216, "_timestamp": 1585571449.6889713, "_step": 51}
{"Episode reward": 93.31047170426712, "Episode length": 83, "Policy Loss": -1.4540455341339111, "Value Loss": 113.36497497558594, "_runtime": 1534.0695328712463, "_timestamp": 1585571449.9141662, "_step": 52}
{"Episode reward": 86.04363508519164, "Episode length": 158, "Policy Loss": 1.393990397453308, "Value Loss": 47.270286560058594, "_runtime": 1534.1972301006317, "_timestamp": 1585571450.0418634, "_step": 53}
{"Episode reward": 93.85735627191507, "Episode length": 82, "Policy Loss": 2.102415084838867, "Value Loss": 109.35195922851562, "_runtime": 1534.4131791591644, "_timestamp": 1585571450.2578125, "_step": 54}
{"Episode reward": 87.26397430301792, "Episode length": 151, "Policy Loss": 1.7214927673339844, "Value Loss": 50.14937973022461, "_runtime": 1534.6368453502655, "_timestamp": 1585571450.4814787, "_step": 55}
{"Episode reward": 86.7741810221274, "Episode length": 154, "Policy Loss": 0.9433223009109497, "Value Loss": 46.1788330078125, "_runtime": 1534.8691275119781, "_timestamp": 1585571450.7137609, "_step": 56}
{"Episode reward": 85.77735725425369, "Episode length": 162, "Policy Loss": 0.3445184826850891, "Value Loss": 46.084407806396484, "_runtime": 1535.0813851356506, "_timestamp": 1585571450.9260185, "_step": 57}
{"Episode reward": 87.91159401719352, "Episode length": 144, "Policy Loss": 0.07975220680236816, "Value Loss": 50.33451461791992, "_runtime": 1535.3090603351593, "_timestamp": 1585571451.1536937, "_step": 58}
{"Episode reward": 86.81348183807181, "Episode length": 156, "Policy Loss": 1.8497275114059448, "Value Loss": 44.77959060668945, "_runtime": 1535.6367421150208, "_timestamp": 1585571451.4813755, "_step": 59}
{"Episode reward": 83.58354369236652, "Episode length": 228, "Policy Loss": 0.7105053067207336, "Value Loss": 30.673730850219727, "_runtime": 1535.853975534439, "_timestamp": 1585571451.6986089, "_step": 60}
{"Episode reward": 87.80328038650688, "Episode length": 149, "Policy Loss": 0.7979505062103271, "Value Loss": 45.89529800415039, "_runtime": 1536.0676894187927, "_timestamp": 1585571451.9123228, "_step": 61}
{"Episode reward": 87.17516052679703, "Episode length": 146, "Policy Loss": -0.07945920526981354, "Value Loss": 50.43505859375, "_runtime": 1536.2874472141266, "_timestamp": 1585571452.1320806, "_step": 62}
{"Episode reward": 88.07840695647951, "Episode length": 147, "Policy Loss": -0.07602577656507492, "Value Loss": 47.7232780456543, "_runtime": 1536.5055775642395, "_timestamp": 1585571452.350211, "_step": 63}
{"Episode reward": 87.41453580850246, "Episode length": 149, "Policy Loss": 2.118121862411499, "Value Loss": 45.30078125, "_runtime": 1536.7311561107635, "_timestamp": 1585571452.5757895, "_step": 64}
{"Episode reward": 86.92737369273905, "Episode length": 156, "Policy Loss": 2.61627197265625, "Value Loss": 45.36587905883789, "_runtime": 1536.9416012763977, "_timestamp": 1585571452.7862346, "_step": 65}
{"Episode reward": 87.58342085183006, "Episode length": 144, "Policy Loss": 1.3739256858825684, "Value Loss": 39.18869400024414, "_runtime": 1537.162316083908, "_timestamp": 1585571453.0069494, "_step": 66}
{"Episode reward": 88.11909535845616, "Episode length": 151, "Policy Loss": 0.7259494662284851, "Value Loss": 46.22758865356445, "_runtime": 1537.3805005550385, "_timestamp": 1585571453.225134, "_step": 67}
{"Episode reward": 87.47481232356553, "Episode length": 149, "Policy Loss": 1.2490519285202026, "Value Loss": 38.64841842651367, "_runtime": 1537.5086600780487, "_timestamp": 1585571453.3532934, "_step": 68}
{"Episode reward": 93.92706580143026, "Episode length": 83, "Policy Loss": 2.7913572788238525, "Value Loss": 82.26348114013672, "_runtime": 1537.7288217544556, "_timestamp": 1585571453.573455, "_step": 69}
{"Episode reward": 87.57628732237393, "Episode length": 151, "Policy Loss": 1.8506478071212769, "Value Loss": 38.25837326049805, "_runtime": 1537.9484272003174, "_timestamp": 1585571453.7930605, "_step": 70}
{"Episode reward": 87.23593242941637, "Episode length": 151, "Policy Loss": -0.05247260630130768, "Value Loss": 52.599674224853516, "_runtime": 1538.1554143428802, "_timestamp": 1585571454.0000477, "_step": 71}
{"Episode reward": 88.4908715598106, "Episode length": 144, "Policy Loss": -0.5410076975822449, "Value Loss": 63.69276809692383, "_runtime": 1538.3750386238098, "_timestamp": 1585571454.219672, "_step": 72}
{"Episode reward": 87.48762842886188, "Episode length": 150, "Policy Loss": 0.3588637709617615, "Value Loss": 37.66791915893555, "_runtime": 1538.5933330059052, "_timestamp": 1585571454.4379663, "_step": 73}
{"Episode reward": 87.7714808554659, "Episode length": 149, "Policy Loss": 0.5031197667121887, "Value Loss": 48.31513595581055, "_runtime": 1538.8037960529327, "_timestamp": 1585571454.6484294, "_step": 74}
{"Episode reward": 88.46397407819913, "Episode length": 145, "Policy Loss": 1.9736132621765137, "Value Loss": 46.46678161621094, "_runtime": 1539.0203549861908, "_timestamp": 1585571454.8649883, "_step": 75}
{"Episode reward": 87.62409188421422, "Episode length": 148, "Policy Loss": 0.3638896048069, "Value Loss": 41.33366012573242, "_runtime": 1539.236946105957, "_timestamp": 1585571455.0815794, "_step": 76}
{"Episode reward": 87.42692001440552, "Episode length": 149, "Policy Loss": 0.5516597032546997, "Value Loss": 65.9669189453125, "_runtime": 1539.3712713718414, "_timestamp": 1585571455.2159047, "_step": 77}
{"Episode reward": 93.50712710325028, "Episode length": 88, "Policy Loss": -0.5094637870788574, "Value Loss": 114.18274688720703, "_runtime": 1539.5073020458221, "_timestamp": 1585571455.3519354, "_step": 78}
{"Episode reward": 93.32860071084897, "Episode length": 89, "Policy Loss": 0.30903705954551697, "Value Loss": 110.29153442382812, "_runtime": 1539.6350927352905, "_timestamp": 1585571455.479726, "_step": 79}
{"Episode reward": 93.32493174958414, "Episode length": 83, "Policy Loss": 1.6164381504058838, "Value Loss": 114.82027435302734, "_runtime": 1539.8665549755096, "_timestamp": 1585571455.7111883, "_step": 80}
{"Episode reward": 86.35314354319401, "Episode length": 161, "Policy Loss": 2.5782415866851807, "Value Loss": 57.71719741821289, "_runtime": 1539.9873538017273, "_timestamp": 1585571455.8319871, "_step": 81}
{"Episode reward": 93.76985923860246, "Episode length": 80, "Policy Loss": 3.8335399627685547, "Value Loss": 115.80809020996094, "_runtime": 1540.1973886489868, "_timestamp": 1585571456.042022, "_step": 82}
{"Episode reward": 87.77648814427009, "Episode length": 146, "Policy Loss": 1.099958896636963, "Value Loss": 64.17884826660156, "_runtime": 1540.3237798213959, "_timestamp": 1585571456.1684132, "_step": 83}
{"Episode reward": 93.80933605704158, "Episode length": 81, "Policy Loss": 3.7513887882232666, "Value Loss": 121.03540802001953, "_runtime": 1540.530452489853, "_timestamp": 1585571456.3750858, "_step": 84}
{"Episode reward": 88.22079099521856, "Episode length": 144, "Policy Loss": -1.1122252941131592, "Value Loss": 64.84966278076172, "_runtime": 1540.6606185436249, "_timestamp": 1585571456.505252, "_step": 85}
{"Episode reward": 93.32217147871847, "Episode length": 85, "Policy Loss": 4.20090913772583, "Value Loss": 109.96614074707031, "_runtime": 1540.7887768745422, "_timestamp": 1585571456.6334102, "_step": 86}
{"Episode reward": 93.2727218839306, "Episode length": 86, "Policy Loss": 2.15364670753479, "Value Loss": 110.46993255615234, "_runtime": 1541.005874633789, "_timestamp": 1585571456.850508, "_step": 87}
{"Episode reward": 87.74999465627425, "Episode length": 149, "Policy Loss": -1.3128612041473389, "Value Loss": 62.604923248291016, "_runtime": 1541.2172436714172, "_timestamp": 1585571457.061877, "_step": 88}
{"Episode reward": 87.47126355259991, "Episode length": 147, "Policy Loss": -0.9234538078308105, "Value Loss": 64.42533111572266, "_runtime": 1541.4383568763733, "_timestamp": 1585571457.2829902, "_step": 89}
{"Episode reward": 87.01317372445479, "Episode length": 154, "Policy Loss": 0.43210241198539734, "Value Loss": 61.3272705078125, "_runtime": 1541.6744530200958, "_timestamp": 1585571457.5190864, "_step": 90}
{"Episode reward": 85.72203347522513, "Episode length": 163, "Policy Loss": 0.4725513160228729, "Value Loss": 57.679771423339844, "_runtime": 1541.8948347568512, "_timestamp": 1585571457.739468, "_step": 91}
{"Episode reward": 87.2615084998326, "Episode length": 151, "Policy Loss": 1.1934736967086792, "Value Loss": 61.22755813598633, "_runtime": 1542.1348886489868, "_timestamp": 1585571457.979522, "_step": 92}
{"Episode reward": 86.0200071519854, "Episode length": 165, "Policy Loss": 1.4735385179519653, "Value Loss": 55.91214370727539, "_runtime": 1542.355593919754, "_timestamp": 1585571458.2002273, "_step": 93}
{"Episode reward": 87.44318322133623, "Episode length": 151, "Policy Loss": 0.2740251421928406, "Value Loss": 59.5450439453125, "_runtime": 1542.4826955795288, "_timestamp": 1585571458.327329, "_step": 94}
{"Episode reward": 93.48256818417134, "Episode length": 82, "Policy Loss": 3.2912211418151855, "Value Loss": 114.10719299316406, "_runtime": 1542.6085650920868, "_timestamp": 1585571458.4531984, "_step": 95}
{"Episode reward": 93.86964212479232, "Episode length": 78, "Policy Loss": 3.6585514545440674, "Value Loss": 115.1582260131836, "_runtime": 1542.831218957901, "_timestamp": 1585571458.6758523, "_step": 96}
{"Episode reward": 87.66184671925569, "Episode length": 152, "Policy Loss": -0.2764439582824707, "Value Loss": 60.393760681152344, "_runtime": 1542.9549748897552, "_timestamp": 1585571458.7996082, "_step": 97}
{"Episode reward": 93.49910802269633, "Episode length": 83, "Policy Loss": 0.4764470160007477, "Value Loss": 109.48777770996094, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375, 1315.7132568359375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1341.8446044921875, -1268.028564453125, -1194.21240234375, -1120.3963623046875, -1046.580322265625, -972.76416015625, -898.9481201171875, -825.1320190429688, -751.31591796875, -677.4998168945312, -603.6837158203125, -529.86767578125, -456.05157470703125, -382.2354736328125, -308.41943359375, -234.603271484375, -160.7872314453125, -86.97119140625, -13.155029296875, 60.6610107421875, 134.4771728515625, 208.293212890625, 282.1092529296875, 355.9254150390625, 429.741455078125, 503.5574951171875, 577.3736572265625, 651.189697265625, 725.0057373046875, 798.8218994140625, 872.6380615234375, 946.4539794921875, 1020.2701416015625, 1094.0863037109375, 1167.9022216796875, 1241.7183837890625, 1315.5345458984375, 1389.3504638671875, 1463.1666259765625, 1536.9827880859375, 1610.7989501953125, 1684.6148681640625, 1758.4310302734375, 1832.2471923828125, 1906.0631103515625, 1979.8792724609375, 2053.6953125, 2127.51123046875, 2201.32763671875, 2275.1435546875, 2348.95947265625, 2422.77587890625, 2496.591796875, 2570.40771484375, 2644.22412109375, 2718.0400390625, 2791.85595703125, 2865.67236328125, 2939.48828125, 3013.30419921875, 3087.12060546875, 3160.9365234375, 3234.75244140625, 3308.56884765625, 3382.384765625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 10.0], "bins": [-501.6495361328125, -493.739501953125, -485.8294677734375, -477.91943359375, -470.0093688964844, -462.0993347167969, -454.1893005371094, -446.2792663574219, -438.3692321777344, -430.4591979980469, -422.54913330078125, -414.63909912109375, -406.72906494140625, -398.81903076171875, -390.90899658203125, -382.99896240234375, -375.08892822265625, -367.17889404296875, -359.26885986328125, -351.35882568359375, -343.4487609863281, -335.5387268066406, -327.6286926269531, -319.7186584472656, -311.80859375, -303.8985595703125, -295.988525390625, -288.0784912109375, -280.16845703125, -272.2584228515625, -264.348388671875, -256.4383544921875, -248.52830505371094, -240.61825561523438, -232.70822143554688, -224.79818725585938, -216.88815307617188, -208.97811889648438, -201.06808471679688, -193.15805053710938, -185.24798583984375, -177.33795166015625, -169.42791748046875, -161.51788330078125, -153.60784912109375, -145.69781494140625, -137.78778076171875, -129.87771606445312, -121.96768188476562, -114.05764770507812, -106.14761352539062, -98.23757934570312, -90.32754516601562, -82.41751098632812, -74.5074462890625, -66.597412109375, -58.6873779296875, -50.77734375, -42.8673095703125, -34.957275390625, -27.0472412109375, -19.137176513671875, -11.227142333984375, -3.317108154296875, 4.592926025390625]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 377.0, 8.0, 3.0, 5.0, 15.0, 3.0, 4.0, 7.0, 8.0, 2.0, 2.0, 4.0, 9.0, 1.0, 0.0, 2.0, 5.0, 5.0], "bins": [-1270.816162109375, -1243.6640625, -1216.5120849609375, -1189.360107421875, -1162.2080078125, -1135.055908203125, -1107.9039306640625, -1080.751953125, -1053.599853515625, -1026.44775390625, -999.2957763671875, -972.1437377929688, -944.99169921875, -917.8396606445312, -890.6876220703125, -863.5355834960938, -836.383544921875, -809.2315063476562, -782.0794677734375, -754.9274291992188, -727.775390625, -700.6233520507812, -673.4713134765625, -646.3192749023438, -619.167236328125, -592.0151977539062, -564.8631591796875, -537.7111206054688, -510.55908203125, -483.40704345703125, -456.2550048828125, -429.10296630859375, -401.950927734375, -374.79888916015625, -347.6468505859375, -320.49481201171875, -293.3427734375, -266.19073486328125, -239.0386962890625, -211.88671875, -184.734619140625, -157.58251953125, -130.4305419921875, -103.278564453125, -76.12646484375, -48.974365234375, -21.8223876953125, 5.32958984375, 32.481689453125, 59.6337890625, 86.7857666015625, 113.937744140625, 141.08984375, 168.241943359375, 195.3939208984375, 222.5458984375, 249.697998046875, 276.85009765625, 304.0020751953125, 331.154052734375, 358.30615234375, 385.458251953125, 412.6102294921875, 439.76220703125, 466.914306640625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1087.91259765625, -1058.3851318359375, -1028.8577880859375, -999.3303833007812, -969.802978515625, -940.2755126953125, -910.7481079101562, -881.220703125, -851.6932983398438, -822.1658935546875, -792.6384887695312, -763.111083984375, -733.5836181640625, -704.0562744140625, -674.52880859375, -645.0014038085938, -615.4739990234375, -585.9465942382812, -556.419189453125, -526.8917846679688, -497.3643798828125, -467.8369140625, -438.30950927734375, -408.7821044921875, -379.25469970703125, -349.727294921875, -320.19989013671875, -290.6724853515625, -261.14501953125, -231.61761474609375, -202.0902099609375, -172.56280517578125, -143.035400390625, -113.50799560546875, -83.9805908203125, -54.453125, -24.92578125, 4.6016845703125, 34.1290283203125, 63.656494140625, 93.183837890625, 122.7113037109375, 152.23876953125, 181.76611328125, 211.2935791015625, 240.8209228515625, 270.348388671875, 299.875732421875, 329.4031982421875, 358.9306640625, 388.4580078125, 417.9854736328125, 447.5128173828125, 477.040283203125, 506.567626953125, 536.0950927734375, 565.62255859375, 595.14990234375, 624.6773681640625, 654.2047119140625, 683.732177734375, 713.259521484375, 742.7869873046875, 772.3143310546875, 801.841796875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 5.0, 17.0, 16.0, 5.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1206.262939453125, -1161.547119140625, -1116.831298828125, -1072.115478515625, -1027.399658203125, -982.683837890625, -937.968017578125, -893.252197265625, -848.536376953125, -803.820556640625, -759.104736328125, -714.388916015625, -669.673095703125, -624.957275390625, -580.241455078125, -535.525634765625, -490.809814453125, -446.093994140625, -401.378173828125, -356.662353515625, -311.946533203125, -267.230712890625, -222.514892578125, -177.799072265625, -133.083251953125, -88.367431640625, -43.651611328125, 1.064208984375, 45.780029296875, 90.495849609375, 135.211669921875, 179.927490234375, 224.643310546875, 269.359130859375, 314.074951171875, 358.790771484375, 403.506591796875, 448.222412109375, 492.938232421875, 537.654052734375, 582.369873046875, 627.085693359375, 671.801513671875, 716.517333984375, 761.233154296875, 805.948974609375, 850.664794921875, 895.380615234375, 940.096435546875, 984.812255859375, 1029.528076171875, 1074.243896484375, 1118.959716796875, 1163.675537109375, 1208.391357421875, 1253.107177734375, 1297.822998046875, 1342.538818359375, 1387.254638671875, 1431.970458984375, 1476.686279296875, 1521.402099609375, 1566.117919921875, 1610.833740234375, 1655.549560546875]}, "_runtime": 1543.193823337555, "_timestamp": 1585571459.0384567, "_step": 98}
{"Episode reward": 85.3407104464502, "Episode length": 167, "Policy Loss": -3.822542667388916, "Value Loss": 59.449745178222656, "_runtime": 1543.6266777515411, "_timestamp": 1585571459.471311, "_step": 99}
{"Episode reward": 79.08479809125693, "Episode length": 302, "Policy Loss": 0.10159570723772049, "Value Loss": 29.843875885009766, "_runtime": 1543.846159696579, "_timestamp": 1585571459.690793, "_step": 100}
{"Episode reward": 87.97249232714911, "Episode length": 152, "Policy Loss": 0.7634599804878235, "Value Loss": 58.65943145751953, "_runtime": 1543.9729413986206, "_timestamp": 1585571459.8175747, "_step": 101}
{"Episode reward": 93.66640950569011, "Episode length": 80, "Policy Loss": 1.9601243734359741, "Value Loss": 113.65755462646484, "_runtime": 1544.1977729797363, "_timestamp": 1585571460.0424063, "_step": 102}
{"Episode reward": 87.7461500559897, "Episode length": 146, "Policy Loss": 1.8888167142868042, "Value Loss": 58.855106353759766, "_runtime": 1544.32785987854, "_timestamp": 1585571460.1724932, "_step": 103}
{"Episode reward": 94.0609645649755, "Episode length": 84, "Policy Loss": 4.1144280433654785, "Value Loss": 116.1513442993164, "_runtime": 1544.5485656261444, "_timestamp": 1585571460.393199, "_step": 104}
{"Episode reward": 87.81475954670752, "Episode length": 153, "Policy Loss": 1.5015112161636353, "Value Loss": 54.3940315246582, "_runtime": 1544.6711366176605, "_timestamp": 1585571460.51577, "_step": 105}
{"Episode reward": 93.74564210310285, "Episode length": 79, "Policy Loss": 1.3034207820892334, "Value Loss": 115.6219253540039, "_runtime": 1544.8749997615814, "_timestamp": 1585571460.719633, "_step": 106}
{"Episode reward": 87.71574224340027, "Episode length": 141, "Policy Loss": 0.05738172307610512, "Value Loss": 62.59016418457031, "_runtime": 1545.0863726139069, "_timestamp": 1585571460.931006, "_step": 107}
{"Episode reward": 88.53296918002223, "Episode length": 144, "Policy Loss": 0.49506908655166626, "Value Loss": 58.93450927734375, "_runtime": 1545.309773683548, "_timestamp": 1585571461.154407, "_step": 108}
{"Episode reward": 86.94329279660542, "Episode length": 156, "Policy Loss": -0.42542922496795654, "Value Loss": 54.24845886230469, "_runtime": 1545.5204694271088, "_timestamp": 1585571461.3651028, "_step": 109}
{"Episode reward": 88.2892321859099, "Episode length": 144, "Policy Loss": 1.1736257076263428, "Value Loss": 57.67056655883789, "_runtime": 1545.6504409313202, "_timestamp": 1585571461.4950743, "_step": 110}
{"Episode reward": 93.25273486632193, "Episode length": 84, "Policy Loss": 2.108872175216675, "Value Loss": 103.6037826538086, "_runtime": 1545.8656408786774, "_timestamp": 1585571461.7102742, "_step": 111}
{"Episode reward": 87.85065591623221, "Episode length": 147, "Policy Loss": -0.27861806750297546, "Value Loss": 54.090389251708984, "_runtime": 1546.0873608589172, "_timestamp": 1585571461.9319942, "_step": 112}
{"Episode reward": 87.62624304524611, "Episode length": 152, "Policy Loss": -0.13265378773212433, "Value Loss": 53.873287200927734, "_runtime": 1546.2173097133636, "_timestamp": 1585571462.061943, "_step": 113}
{"Episode reward": 93.3589429467895, "Episode length": 86, "Policy Loss": 0.476169228553772, "Value Loss": 101.31873321533203, "_runtime": 1547.5570299625397, "_timestamp": 1585571463.4016633, "_step": 114}
{"Episode reward": 38.461119422976445, "Episode length": 921, "Policy Loss": -0.07143119722604752, "Value Loss": 8.455084800720215, "_runtime": 1547.800473690033, "_timestamp": 1585571463.645107, "_step": 115}
{"Episode reward": 87.00489922502213, "Episode length": 161, "Policy Loss": -0.2702341377735138, "Value Loss": 47.74024963378906, "_runtime": 1548.020852804184, "_timestamp": 1585571463.8654861, "_step": 116}
{"Episode reward": 87.27128997201736, "Episode length": 151, "Policy Loss": -0.5052003860473633, "Value Loss": 47.86747360229492, "_runtime": 1548.2995533943176, "_timestamp": 1585571464.1441867, "_step": 117}
{"Episode reward": 86.22360072844728, "Episode length": 161, "Policy Loss": -3.808180570602417, "Value Loss": 73.5602035522461, "_runtime": 1548.4354085922241, "_timestamp": 1585571464.280042, "_step": 118}
{"Episode reward": 92.77805952357195, "Episode length": 87, "Policy Loss": 0.20128348469734192, "Value Loss": 100.73442077636719, "_runtime": 1548.6463732719421, "_timestamp": 1585571464.4910066, "_step": 119}
{"Episode reward": 88.55000244910173, "Episode length": 143, "Policy Loss": 0.31568264961242676, "Value Loss": 58.95825958251953, "_runtime": 1548.7877366542816, "_timestamp": 1585571464.63237, "_step": 120}
{"Episode reward": 92.7197757956867, "Episode length": 92, "Policy Loss": 0.9898475408554077, "Value Loss": 109.38430786132812, "_runtime": 1549.006130695343, "_timestamp": 1585571464.850764, "_step": 121}
{"Episode reward": 86.59620966698824, "Episode length": 152, "Policy Loss": 1.3610059022903442, "Value Loss": 55.74516296386719, "_runtime": 1549.2306544780731, "_timestamp": 1585571465.0752878, "_step": 122}
{"Episode reward": 86.89794299499957, "Episode length": 154, "Policy Loss": 2.708010196685791, "Value Loss": 52.2489013671875, "_runtime": 1549.3529801368713, "_timestamp": 1585571465.1976135, "_step": 123}
{"Episode reward": 93.82739614372046, "Episode length": 81, "Policy Loss": 1.9379065036773682, "Value Loss": 101.87664031982422, "_runtime": 1549.562353849411, "_timestamp": 1585571465.4069872, "_step": 124}
{"Episode reward": 87.97027533650655, "Episode length": 143, "Policy Loss": 4.497471809387207, "Value Loss": 54.34296417236328, "_runtime": 1549.6837775707245, "_timestamp": 1585571465.528411, "_step": 125}
{"Episode reward": 93.7622390474766, "Episode length": 78, "Policy Loss": 5.931565284729004, "Value Loss": 105.2159423828125, "_runtime": 1549.8059017658234, "_timestamp": 1585571465.650535, "_step": 126}
{"Episode reward": 93.42896886901644, "Episode length": 81, "Policy Loss": 3.3138036727905273, "Value Loss": 88.88104248046875, "_runtime": 1550.0236401557922, "_timestamp": 1585571465.8682735, "_step": 127}
{"Episode reward": 87.69269411677959, "Episode length": 149, "Policy Loss": 0.40697744488716125, "Value Loss": 44.10056686401367, "_runtime": 1550.232472896576, "_timestamp": 1585571466.0771062, "_step": 128}
{"Episode reward": 87.3561277079186, "Episode length": 145, "Policy Loss": -0.6567519903182983, "Value Loss": 56.34832000732422, "_runtime": 1550.4501404762268, "_timestamp": 1585571466.2947738, "_step": 129}
{"Episode reward": 86.53464890479577, "Episode length": 152, "Policy Loss": -0.18372857570648193, "Value Loss": 53.08525466918945, "_runtime": 1550.6827280521393, "_timestamp": 1585571466.5273614, "_step": 130}
{"Episode reward": 86.07436836474334, "Episode length": 160, "Policy Loss": 0.3666667640209198, "Value Loss": 51.983673095703125, "_runtime": 1550.9027955532074, "_timestamp": 1585571466.747429, "_step": 131}
{"Episode reward": 87.45338134280462, "Episode length": 150, "Policy Loss": 1.1205418109893799, "Value Loss": 43.73459243774414, "_runtime": 1551.0333840847015, "_timestamp": 1585571466.8780174, "_step": 132}
{"Episode reward": 93.48532459241206, "Episode length": 84, "Policy Loss": 0.9850342869758606, "Value Loss": 99.03370666503906, "_runtime": 1551.2401280403137, "_timestamp": 1585571467.0847614, "_step": 133}
{"Episode reward": 88.32469503539255, "Episode length": 141, "Policy Loss": 5.462336540222168, "Value Loss": 70.09062957763672, "_runtime": 1551.4607737064362, "_timestamp": 1585571467.305407, "_step": 134}
{"Episode reward": 87.24551185753384, "Episode length": 151, "Policy Loss": 3.508405923843384, "Value Loss": 56.8266487121582, "_runtime": 1551.6830084323883, "_timestamp": 1585571467.5276418, "_step": 135}
{"Episode reward": 86.68514387911792, "Episode length": 155, "Policy Loss": 0.9750145673751831, "Value Loss": 44.12837600708008, "_runtime": 1551.9003539085388, "_timestamp": 1585571467.7449872, "_step": 136}
{"Episode reward": 87.17200118214197, "Episode length": 149, "Policy Loss": 0.3908384442329407, "Value Loss": 46.35341262817383, "_runtime": 1552.1136584281921, "_timestamp": 1585571467.9582918, "_step": 137}
{"Episode reward": 88.71683118478555, "Episode length": 145, "Policy Loss": 0.09306701272726059, "Value Loss": 45.871456146240234, "_runtime": 1552.3496530056, "_timestamp": 1585571468.1942863, "_step": 138}
{"Episode reward": 85.84950582556097, "Episode length": 162, "Policy Loss": -0.1287456750869751, "Value Loss": 48.11529541015625, "_runtime": 1552.5724651813507, "_timestamp": 1585571468.4170985, "_step": 139}
{"Episode reward": 87.07060680823673, "Episode length": 153, "Policy Loss": -0.27950307726860046, "Value Loss": 42.994712829589844, "_runtime": 1552.7860424518585, "_timestamp": 1585571468.6306758, "_step": 140}
{"Episode reward": 88.11240304216938, "Episode length": 145, "Policy Loss": 0.04470272734761238, "Value Loss": 41.40468215942383, "_runtime": 1552.91685628891, "_timestamp": 1585571468.7614896, "_step": 141}
{"Episode reward": 92.92709278985791, "Episode length": 84, "Policy Loss": 0.9123646020889282, "Value Loss": 84.89994812011719, "_runtime": 1553.135172367096, "_timestamp": 1585571468.9798057, "_step": 142}
{"Episode reward": 87.73169496350323, "Episode length": 150, "Policy Loss": 1.5301622152328491, "Value Loss": 53.939693450927734, "_runtime": 1553.263884305954, "_timestamp": 1585571469.1085176, "_step": 143}
{"Episode reward": 93.62940907901398, "Episode length": 83, "Policy Loss": 3.589158773422241, "Value Loss": 79.58137512207031, "_runtime": 1553.3878979682922, "_timestamp": 1585571469.2325313, "_step": 144}
{"Episode reward": 93.87343412172737, "Episode length": 82, "Policy Loss": 1.0113403797149658, "Value Loss": 83.99152374267578, "_runtime": 1553.6106097698212, "_timestamp": 1585571469.455243, "_step": 145}
{"Episode reward": 87.10332022182547, "Episode length": 153, "Policy Loss": 0.05673965811729431, "Value Loss": 36.792694091796875, "_runtime": 1553.7353582382202, "_timestamp": 1585571469.5799916, "_step": 146}
{"Episode reward": 94.17734581098422, "Episode length": 83, "Policy Loss": -0.8538291454315186, "Value Loss": 87.37357330322266, "_runtime": 1553.9490671157837, "_timestamp": 1585571469.7937005, "_step": 147}
{"Episode reward": 87.19447143695075, "Episode length": 149, "Policy Loss": -0.09425676614046097, "Value Loss": 37.347137451171875, "_runtime": 1554.1761775016785, "_timestamp": 1585571470.0208108, "_step": 148}
{"Episode reward": 86.73096966483658, "Episode length": 156, "Policy Loss": 0.42647621035575867, "Value Loss": 35.41896057128906, "_runtime": 1554.4011540412903, "_timestamp": 1585571470.2457874, "_step": 149}
{"Episode reward": 86.8217336876837, "Episode length": 155, "Policy Loss": 0.6278457641601562, "Value Loss": 34.51640319824219, "_runtime": 1554.6331131458282, "_timestamp": 1585571470.4777465, "_step": 150}
{"Episode reward": 86.3399519689348, "Episode length": 158, "Policy Loss": 0.5338610410690308, "Value Loss": 32.76640701293945, "_runtime": 1554.8681161403656, "_timestamp": 1585571470.7127495, "_step": 151}
{"Episode reward": 87.00561038227553, "Episode length": 159, "Policy Loss": 0.386493980884552, "Value Loss": 33.986419677734375, "_runtime": 1555.002466917038, "_timestamp": 1585571470.8471003, "_step": 152}
{"Episode reward": 93.59669773563074, "Episode length": 86, "Policy Loss": -0.9254722595214844, "Value Loss": 85.76090240478516, "_runtime": 1555.1318621635437, "_timestamp": 1585571470.9764955, "_step": 153}
{"Episode reward": 93.54751405624461, "Episode length": 83, "Policy Loss": -0.32285529375076294, "Value Loss": 77.8227310180664, "_runtime": 1555.3683531284332, "_timestamp": 1585571471.2129865, "_step": 154}
{"Episode reward": 85.83295315310514, "Episode length": 161, "Policy Loss": -2.445288896560669, "Value Loss": 49.18414306640625, "_runtime": 1555.581523656845, "_timestamp": 1585571471.426157, "_step": 155}
{"Episode reward": 87.30891350753117, "Episode length": 148, "Policy Loss": 0.2247336059808731, "Value Loss": 34.935768127441406, "_runtime": 1555.708773136139, "_timestamp": 1585571471.5534065, "_step": 156}
{"Episode reward": 93.30930129941248, "Episode length": 85, "Policy Loss": -0.5969648361206055, "Value Loss": 95.91316223144531, "_runtime": 1555.8406398296356, "_timestamp": 1585571471.6852732, "_step": 157}
{"Episode reward": 93.67045745436747, "Episode length": 83, "Policy Loss": 0.6121456027030945, "Value Loss": 63.0595703125, "_runtime": 1556.0624997615814, "_timestamp": 1585571471.907133, "_step": 158}
{"Episode reward": 86.88411273954944, "Episode length": 152, "Policy Loss": 0.9035442471504211, "Value Loss": 28.88518714904785, "_runtime": 1556.1859121322632, "_timestamp": 1585571472.0305455, "_step": 159}
{"Episode reward": 93.89171086690561, "Episode length": 81, "Policy Loss": 1.8910479545593262, "Value Loss": 74.91178894042969, "_runtime": 1556.4112477302551, "_timestamp": 1585571472.255881, "_step": 160}
{"Episode reward": 86.63224173402877, "Episode length": 157, "Policy Loss": 0.3586810529232025, "Value Loss": 31.54642677307129, "_runtime": 1556.638643026352, "_timestamp": 1585571472.4832764, "_step": 161}
{"Episode reward": 86.76187168945948, "Episode length": 156, "Policy Loss": -0.16222800314426422, "Value Loss": 35.92667770385742, "_runtime": 1556.7644600868225, "_timestamp": 1585571472.6090934, "_step": 162}
{"Episode reward": 93.04597081655847, "Episode length": 84, "Policy Loss": -0.5731545090675354, "Value Loss": 88.70884704589844, "_runtime": 1556.9766902923584, "_timestamp": 1585571472.8213236, "_step": 163}
{"Episode reward": 88.55016729376881, "Episode length": 145, "Policy Loss": 0.7502625584602356, "Value Loss": 25.793062210083008, "_runtime": 1557.2010390758514, "_timestamp": 1585571473.0456724, "_step": 164}
{"Episode reward": 87.3975475664581, "Episode length": 153, "Policy Loss": 2.0622313022613525, "Value Loss": 41.498191833496094, "_runtime": 1557.4232637882233, "_timestamp": 1585571473.2678971, "_step": 165}
{"Episode reward": 86.61980965861503, "Episode length": 156, "Policy Loss": 1.0136438608169556, "Value Loss": 23.76765251159668, "_runtime": 1557.6516168117523, "_timestamp": 1585571473.4962502, "_step": 166}
{"Episode reward": 87.5677672335199, "Episode length": 157, "Policy Loss": -0.17989638447761536, "Value Loss": 31.846776962280273, "_runtime": 1557.7860057353973, "_timestamp": 1585571473.630639, "_step": 167}
{"Episode reward": 93.37151026897837, "Episode length": 87, "Policy Loss": -0.3756506145000458, "Value Loss": 84.3647232055664, "_runtime": 1557.9106965065002, "_timestamp": 1585571473.7553298, "_step": 168}
{"Episode reward": 93.55287457735473, "Episode length": 80, "Policy Loss": -0.4843778610229492, "Value Loss": 75.77531433105469, "_runtime": 1558.135735988617, "_timestamp": 1585571473.9803693, "_step": 169}
{"Episode reward": 87.21704664108151, "Episode length": 154, "Policy Loss": 1.4923096895217896, "Value Loss": 31.301557540893555, "_runtime": 1558.345609664917, "_timestamp": 1585571474.190243, "_step": 170}
{"Episode reward": 87.79490329646067, "Episode length": 146, "Policy Loss": 0.9118368029594421, "Value Loss": 24.20281410217285, "_runtime": 1558.5609283447266, "_timestamp": 1585571474.4055617, "_step": 171}
{"Episode reward": 87.38571747865413, "Episode length": 150, "Policy Loss": 0.4112178683280945, "Value Loss": 24.777956008911133, "_runtime": 1558.8037281036377, "_timestamp": 1585571474.6483614, "_step": 172}
{"Episode reward": 86.40799129909655, "Episode length": 167, "Policy Loss": -0.4479216933250427, "Value Loss": 22.939653396606445, "_runtime": 1559.0271394252777, "_timestamp": 1585571474.8717728, "_step": 173}
{"Episode reward": 86.50723993169329, "Episode length": 152, "Policy Loss": -0.08063020557165146, "Value Loss": 28.184988021850586, "_runtime": 1559.1530549526215, "_timestamp": 1585571474.9976883, "_step": 174}
{"Episode reward": 93.3427636892057, "Episode length": 81, "Policy Loss": 0.7966363430023193, "Value Loss": 46.03789138793945, "_runtime": 1559.3959262371063, "_timestamp": 1585571475.2405596, "_step": 175}
{"Episode reward": 85.42611550824094, "Episode length": 167, "Policy Loss": -14.577110290527344, "Value Loss": 437.55169677734375, "_runtime": 1559.6160821914673, "_timestamp": 1585571475.4607155, "_step": 176}
{"Episode reward": 86.90156743909172, "Episode length": 150, "Policy Loss": -0.2858006954193115, "Value Loss": 66.38325500488281, "_runtime": 1559.8282582759857, "_timestamp": 1585571475.6728916, "_step": 177}
{"Episode reward": 88.14315760019298, "Episode length": 148, "Policy Loss": -0.40815913677215576, "Value Loss": 67.34790802001953, "_runtime": 1559.9549992084503, "_timestamp": 1585571475.7996325, "_step": 178}
{"Episode reward": 93.84031579169137, "Episode length": 81, "Policy Loss": -0.9108888506889343, "Value Loss": 123.0896987915039, "_runtime": 1560.1807761192322, "_timestamp": 1585571476.0254095, "_step": 179}
{"Episode reward": 86.77910068408693, "Episode length": 154, "Policy Loss": -0.32191988825798035, "Value Loss": 64.78638458251953, "_runtime": 1560.3079447746277, "_timestamp": 1585571476.152578, "_step": 180}
{"Episode reward": 93.23578384080243, "Episode length": 82, "Policy Loss": 0.7281620502471924, "Value Loss": 121.5504379272461, "_runtime": 1560.524700164795, "_timestamp": 1585571476.3693335, "_step": 181}
{"Episode reward": 87.4756494743374, "Episode length": 151, "Policy Loss": -0.443512886762619, "Value Loss": 65.92708587646484, "_runtime": 1560.7601325511932, "_timestamp": 1585571476.604766, "_step": 182}
{"Episode reward": 85.99530366277914, "Episode length": 163, "Policy Loss": -0.2630922496318817, "Value Loss": 61.05840301513672, "_runtime": 1560.9881491661072, "_timestamp": 1585571476.8327825, "_step": 183}
{"Episode reward": 85.78994568270933, "Episode length": 159, "Policy Loss": -0.54110187292099, "Value Loss": 62.588253021240234, "_runtime": 1561.2166662216187, "_timestamp": 1585571477.0612996, "_step": 184}
{"Episode reward": 86.63436084751461, "Episode length": 156, "Policy Loss": -0.13734889030456543, "Value Loss": 63.787471771240234, "_runtime": 1561.4332118034363, "_timestamp": 1585571477.2778451, "_step": 185}
{"Episode reward": 87.81648838468317, "Episode length": 148, "Policy Loss": -0.6802926659584045, "Value Loss": 67.22885131835938, "_runtime": 1561.651489496231, "_timestamp": 1585571477.4961228, "_step": 186}
{"Episode reward": 87.21935557916329, "Episode length": 150, "Policy Loss": -0.12608537077903748, "Value Loss": 66.33570098876953, "_runtime": 1561.881460905075, "_timestamp": 1585571477.7260942, "_step": 187}
{"Episode reward": 87.79504986027646, "Episode length": 158, "Policy Loss": -0.4715117812156677, "Value Loss": 62.97751998901367, "_runtime": 1562.109376192093, "_timestamp": 1585571477.9540095, "_step": 188}
{"Episode reward": 86.63386720580658, "Episode length": 156, "Policy Loss": -0.14901107549667358, "Value Loss": 63.887752532958984, "_runtime": 1562.3291108608246, "_timestamp": 1585571478.1737442, "_step": 189}
{"Episode reward": 86.9992604427974, "Episode length": 150, "Policy Loss": -0.49450647830963135, "Value Loss": 66.3374252319336, "_runtime": 1562.4532504081726, "_timestamp": 1585571478.2978837, "_step": 190}
{"Episode reward": 93.67492300343679, "Episode length": 79, "Policy Loss": -0.40673011541366577, "Value Loss": 125.8704605102539, "_runtime": 1562.5909461975098, "_timestamp": 1585571478.4355795, "_step": 191}
{"Episode reward": 92.83419539420353, "Episode length": 90, "Policy Loss": -0.6324244141578674, "Value Loss": 110.49655151367188, "_runtime": 1562.818990945816, "_timestamp": 1585571478.6636243, "_step": 192}
{"Episode reward": 86.87315171348672, "Episode length": 155, "Policy Loss": -0.6070337891578674, "Value Loss": 64.19915771484375, "_runtime": 1563.0490934848785, "_timestamp": 1585571478.8937268, "_step": 193}
{"Episode reward": 86.44776540843979, "Episode length": 161, "Policy Loss": -0.5317367911338806, "Value Loss": 61.80951690673828, "_runtime": 1563.255500793457, "_timestamp": 1585571479.1001341, "_step": 194}
{"Episode reward": 88.25405552638787, "Episode length": 144, "Policy Loss": -0.07920631766319275, "Value Loss": 69.09378051757812, "_runtime": 1563.4708251953125, "_timestamp": 1585571479.3154585, "_step": 195}
{"Episode reward": 87.72276904573573, "Episode length": 146, "Policy Loss": -0.6835125684738159, "Value Loss": 68.14949035644531, "_runtime": 1563.6041660308838, "_timestamp": 1585571479.4487994, "_step": 196}
{"Episode reward": 93.3567912363303, "Episode length": 86, "Policy Loss": 1.2061314582824707, "Value Loss": 115.6263656616211, "_runtime": 1563.8240342140198, "_timestamp": 1585571479.6686676, "_step": 197}
{"Episode reward": 86.6800573387989, "Episode length": 151, "Policy Loss": -0.645859956741333, "Value Loss": 65.89725494384766, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406, -185.82154846191406]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0], "bins": [152.8267822265625, 153.34048461914062, 153.85418701171875, 154.36790466308594, 154.88160705566406, 155.3953094482422, 155.9090118408203, 156.4227294921875, 156.93643188476562, 157.45013427734375, 157.96383666992188, 158.4775390625, 158.9912567138672, 159.5049591064453, 160.01866149902344, 160.53236389160156, 161.04608154296875, 161.55978393554688, 162.073486328125, 162.58718872070312, 163.10089111328125, 163.61460876464844, 164.12831115722656, 164.6420135498047, 165.1557159423828, 165.66943359375, 166.18313598632812, 166.69683837890625, 167.21054077148438, 167.7242431640625, 168.2379608154297, 168.7516632080078, 169.26536560058594, 169.77906799316406, 170.29278564453125, 170.80648803710938, 171.3201904296875, 171.83389282226562, 172.34759521484375, 172.86129760742188, 173.37501525878906, 173.8887176513672, 174.4024200439453, 174.91612243652344, 175.42984008789062, 175.94354248046875, 176.45724487304688, 176.970947265625, 177.48464965820312, 177.9983673095703, 178.51206970214844, 179.02577209472656, 179.5394744873047, 180.05319213867188, 180.56689453125, 181.08059692382812, 181.59429931640625, 182.10800170898438, 182.62171936035156, 183.1354217529297, 183.6491241455078, 184.16282653808594, 184.67654418945312, 185.19024658203125, 185.70394897460938]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.0586442947387695, -2.8922722339630127, -2.725900173187256, -2.559528112411499, -2.393156051635742, -2.2267839908599854, -2.0604119300842285, -1.8940398693084717, -1.7276678085327148, -1.561295747756958, -1.3949236869812012, -1.2285516262054443, -1.0621795654296875, -0.8958075046539307, -0.7294354438781738, -0.563063383102417, -0.39669132232666016, -0.23031926155090332, -0.06394720077514648, 0.10242486000061035, 0.2687969207763672, 0.435168981552124, 0.6015410423278809, 0.7679131031036377, 0.9342851638793945, 1.1006574630737305, 1.2670292854309082, 1.433401107788086, 1.5997734069824219, 1.7661457061767578, 1.9325175285339355, 2.0988893508911133, 2.265261650085449, 2.431633949279785, 2.598005771636963, 2.7643775939941406, 2.9307498931884766, 3.0971221923828125, 3.2634940147399902, 3.429865837097168, 3.596238136291504, 3.76261043548584, 3.9289822578430176, 4.095354080200195, 4.261726379394531, 4.428098678588867, 4.594470500946045, 4.760842323303223, 4.927214622497559, 5.0935869216918945, 5.2599592208862305, 5.42633056640625, 5.592702865600586, 5.759075164794922, 5.925446510314941, 6.091818809509277, 6.258191108703613, 6.424563407897949, 6.590935707092285, 6.757307052612305, 6.923679351806641, 7.090051651000977, 7.256422996520996, 7.422795295715332, 7.589167594909668]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 4.0, 9.0, 11.0, 4.0, 1.0, 5.0, 13.0, 20.0, 203.0, 132.0, 24.0, 10.0, 10.0, 7.0, 4.0, 3.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.545576095581055, -6.217832565307617, -5.890089511871338, -5.5623459815979, -5.234602928161621, -4.906859397888184, -4.579115867614746, -4.251372337341309, -3.9236292839050293, -3.595885992050171, -3.2681427001953125, -2.940399169921875, -2.6126558780670166, -2.284912586212158, -1.9571690559387207, -1.6294260025024414, -1.301682472229004, -0.9739389419555664, -0.6461958885192871, -0.3184523582458496, 0.009290695190429688, 0.3370342254638672, 0.6647777557373047, 0.992520809173584, 1.3202643394470215, 1.6480073928833008, 1.9757509231567383, 2.303494453430176, 2.6312379837036133, 2.958981513977051, 3.286724090576172, 3.6144676208496094, 3.942211151123047, 4.269954681396484, 4.597698211669922, 4.925440788269043, 5.2531843185424805, 5.580927848815918, 5.9086713790893555, 6.236414909362793, 6.564157485961914, 6.891901016235352, 7.219644546508789, 7.547388076782227, 7.875131607055664, 8.202875137329102, 8.530617713928223, 8.85836124420166, 9.186104774475098, 9.513847351074219, 9.841590881347656, 10.169334411621094, 10.497077941894531, 10.824821472167969, 11.152565002441406, 11.480308532714844, 11.808052062988281, 12.135795593261719, 12.463539123535156, 12.791280746459961, 13.119024276733398, 13.446767807006836, 13.774511337280273, 14.102254867553711, 14.429998397827148]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-9.961980819702148, -9.66661262512207, -9.371243476867676, -9.075875282287598, -8.78050708770752, -8.485138893127441, -8.189769744873047, -7.894401550292969, -7.599033355712891, -7.303664684295654, -7.008296012878418, -6.71292781829834, -6.4175591468811035, -6.122190475463867, -5.826822280883789, -5.531454086303711, -5.236085414886475, -4.940716743469238, -4.64534854888916, -4.349979877471924, -4.054611682891846, -3.7592430114746094, -3.4638748168945312, -3.168506145477295, -2.8731374740600586, -2.5777692794799805, -2.282400608062744, -1.987032413482666, -1.6916637420654297, -1.3962955474853516, -1.1009273529052734, -0.8055582046508789, -0.5101900100708008, -0.21482181549072266, 0.08054733276367188, 0.37591552734375, 0.6712837219238281, 0.9666519165039062, 1.2620210647583008, 1.557389259338379, 1.852757453918457, 2.1481266021728516, 2.4434947967529297, 2.738862991333008, 3.034231185913086, 3.3296003341674805, 3.6249685287475586, 3.9203367233276367, 4.215705871582031, 4.511074066162109, 4.8064422607421875, 5.101810455322266, 5.39717960357666, 5.692547798156738, 5.987915992736816, 6.283285140991211, 6.578653335571289, 6.874021530151367, 7.169389724731445, 7.464757919311523, 7.760126113891602, 8.055496215820312, 8.35086441040039, 8.646232604980469, 8.941600799560547]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.33089828491211, -10.954618453979492, -10.578337669372559, -10.202057838439941, -9.825778007507324, -9.44949722290039, -9.073217391967773, -8.696937561035156, -8.320657730102539, -7.9443769454956055, -7.568097114562988, -7.191816806793213, -6.8155364990234375, -6.43925666809082, -6.062976360321045, -5.686696529388428, -5.310416221618652, -4.934135913848877, -4.55785608291626, -4.181575775146484, -3.805295944213867, -3.429015636444092, -3.0527353286743164, -2.676455497741699, -2.3001747131347656, -1.9238948822021484, -1.5476150512695312, -1.171335220336914, -0.7950544357299805, -0.4187746047973633, -0.042494773864746094, 0.3337860107421875, 0.7100658416748047, 1.0863456726074219, 1.4626264572143555, 1.8389062881469727, 2.21518611907959, 2.5914669036865234, 2.9677467346191406, 3.344026565551758, 3.720306396484375, 4.096587181091309, 4.472867012023926, 4.849147796630859, 5.225427627563477, 5.601707458496094, 5.977987289428711, 6.354267120361328, 6.730548858642578, 7.106828689575195, 7.4831085205078125, 7.85938835144043, 8.235668182373047, 8.611948013305664, 8.988227844238281, 9.364509582519531, 9.740789413452148, 10.117069244384766, 10.493349075317383, 10.86962890625, 11.245908737182617, 11.622190475463867, 11.998470306396484, 12.374750137329102, 12.751029968261719]}, "_runtime": 1564.0427939891815, "_timestamp": 1585571479.8874273, "_step": 198}
{"Episode reward": 87.91427050412186, "Episode length": 149, "Policy Loss": -0.4801328480243683, "Value Loss": 66.77598571777344, "_runtime": 1564.2609355449677, "_timestamp": 1585571480.105569, "_step": 199}
{"Episode reward": 87.27121939898393, "Episode length": 151, "Policy Loss": 1.1174521446228027, "Value Loss": 65.89404296875, "_runtime": 1564.3889095783234, "_timestamp": 1585571480.233543, "_step": 200}
{"Episode reward": 93.72450262546167, "Episode length": 82, "Policy Loss": -0.6020344495773315, "Value Loss": 121.255859375, "_runtime": 1564.517391204834, "_timestamp": 1585571480.3620245, "_step": 201}
{"Episode reward": 93.00138665636983, "Episode length": 83, "Policy Loss": -0.5728682279586792, "Value Loss": 119.79852294921875, "_runtime": 1564.7524268627167, "_timestamp": 1585571480.5970602, "_step": 202}
{"Episode reward": 85.88316602645718, "Episode length": 162, "Policy Loss": -0.5944881439208984, "Value Loss": 61.42566680908203, "_runtime": 1564.8768072128296, "_timestamp": 1585571480.7214406, "_step": 203}
{"Episode reward": 93.55578188459596, "Episode length": 83, "Policy Loss": 0.8729056715965271, "Value Loss": 119.79054260253906, "_runtime": 1565.0822911262512, "_timestamp": 1585571480.9269245, "_step": 204}
{"Episode reward": 88.06974906092792, "Episode length": 142, "Policy Loss": -0.7245806455612183, "Value Loss": 70.05964660644531, "_runtime": 1565.211929321289, "_timestamp": 1585571481.0565627, "_step": 205}
{"Episode reward": 93.68895553655572, "Episode length": 83, "Policy Loss": -0.7024263739585876, "Value Loss": 119.9969253540039, "_runtime": 1565.436095714569, "_timestamp": 1585571481.280729, "_step": 206}
{"Episode reward": 86.42942671266849, "Episode length": 156, "Policy Loss": -0.2545301914215088, "Value Loss": 63.78092575073242, "_runtime": 1565.561857700348, "_timestamp": 1585571481.406491, "_step": 207}
{"Episode reward": 93.87963987553525, "Episode length": 81, "Policy Loss": -0.5750405192375183, "Value Loss": 122.73472595214844, "_runtime": 1565.7848236560822, "_timestamp": 1585571481.629457, "_step": 208}
{"Episode reward": 86.4786691524989, "Episode length": 156, "Policy Loss": -0.17618297040462494, "Value Loss": 63.77886962890625, "_runtime": 1566.0028750896454, "_timestamp": 1585571481.8475084, "_step": 209}
{"Episode reward": 87.74212732708497, "Episode length": 146, "Policy Loss": 0.12454608827829361, "Value Loss": 68.13772583007812, "_runtime": 1566.1316349506378, "_timestamp": 1585571481.9762683, "_step": 210}
{"Episode reward": 93.06690552082063, "Episode length": 86, "Policy Loss": -0.6653690338134766, "Value Loss": 115.60012817382812, "_runtime": 1566.3581573963165, "_timestamp": 1585571482.2027907, "_step": 211}
{"Episode reward": 87.44625481733009, "Episode length": 155, "Policy Loss": -0.6361750960350037, "Value Loss": 64.1834716796875, "_runtime": 1566.578777551651, "_timestamp": 1585571482.423411, "_step": 212}
{"Episode reward": 88.26923261855205, "Episode length": 152, "Policy Loss": 0.6200242042541504, "Value Loss": 65.44495391845703, "_runtime": 1566.705936908722, "_timestamp": 1585571482.5505702, "_step": 213}
{"Episode reward": 93.40731412118991, "Episode length": 85, "Policy Loss": -0.7107838988304138, "Value Loss": 117.17333221435547, "_runtime": 1566.8338208198547, "_timestamp": 1585571482.6784542, "_step": 214}
{"Episode reward": 93.75858165283282, "Episode length": 82, "Policy Loss": -0.7683457732200623, "Value Loss": 121.22090911865234, "_runtime": 1567.0578982830048, "_timestamp": 1585571482.9025316, "_step": 215}
{"Episode reward": 87.06631743184593, "Episode length": 153, "Policy Loss": -0.34018442034721375, "Value Loss": 65.01927947998047, "_runtime": 1567.281031370163, "_timestamp": 1585571483.1256647, "_step": 216}
{"Episode reward": 86.56512700629732, "Episode length": 155, "Policy Loss": 1.5065475702285767, "Value Loss": 64.18206024169922, "_runtime": 1567.5038900375366, "_timestamp": 1585571483.3485234, "_step": 217}
{"Episode reward": 88.50644510608451, "Episode length": 155, "Policy Loss": 0.152736097574234, "Value Loss": 64.17347717285156, "_runtime": 1567.6349766254425, "_timestamp": 1585571483.47961, "_step": 218}
{"Episode reward": 93.48634417014563, "Episode length": 84, "Policy Loss": -0.2130783647298813, "Value Loss": 118.33290100097656, "_runtime": 1567.762437582016, "_timestamp": 1585571483.607071, "_step": 219}
{"Episode reward": 93.29156344562796, "Episode length": 82, "Policy Loss": -0.8327462077140808, "Value Loss": 121.21053314208984, "_runtime": 1567.9699974060059, "_timestamp": 1585571483.8146307, "_step": 220}
{"Episode reward": 88.32153197752572, "Episode length": 141, "Policy Loss": -0.7299824953079224, "Value Loss": 70.53688049316406, "_runtime": 1568.18589925766, "_timestamp": 1585571484.0305326, "_step": 221}
{"Episode reward": 87.15909825735086, "Episode length": 150, "Policy Loss": -0.5825788974761963, "Value Loss": 66.3119888305664, "_runtime": 1568.402195930481, "_timestamp": 1585571484.2468293, "_step": 222}
{"Episode reward": 87.09402389668698, "Episode length": 151, "Policy Loss": -0.7963349223136902, "Value Loss": 65.99391174316406, "_runtime": 1568.5301053524017, "_timestamp": 1585571484.3747387, "_step": 223}
{"Episode reward": 93.52219134483084, "Episode length": 82, "Policy Loss": -0.726523220539093, "Value Loss": 121.19760131835938, "_runtime": 1568.7605481147766, "_timestamp": 1585571484.6051815, "_step": 224}
{"Episode reward": 86.72492973559137, "Episode length": 159, "Policy Loss": -0.4495159983634949, "Value Loss": 62.560997009277344, "_runtime": 1568.891671180725, "_timestamp": 1585571484.7363045, "_step": 225}
{"Episode reward": 92.99136055772249, "Episode length": 85, "Policy Loss": -0.39323097467422485, "Value Loss": 117.10535430908203, "_runtime": 1569.1017785072327, "_timestamp": 1585571484.9464118, "_step": 226}
{"Episode reward": 87.82939648082666, "Episode length": 146, "Policy Loss": -0.750617265701294, "Value Loss": 68.11884307861328, "_runtime": 1569.316040277481, "_timestamp": 1585571485.1606736, "_step": 227}
{"Episode reward": 87.61734899579132, "Episode length": 145, "Policy Loss": -0.6709338426589966, "Value Loss": 68.58805084228516, "_runtime": 1569.4501144886017, "_timestamp": 1585571485.2947478, "_step": 228}
{"Episode reward": 92.53232108150407, "Episode length": 90, "Policy Loss": -0.756636381149292, "Value Loss": 110.42488861083984, "_runtime": 1569.6693255901337, "_timestamp": 1585571485.513959, "_step": 229}
{"Episode reward": 87.4153484596395, "Episode length": 150, "Policy Loss": -0.6933144330978394, "Value Loss": 66.30284881591797, "_runtime": 1569.890664100647, "_timestamp": 1585571485.7352974, "_step": 230}
{"Episode reward": 87.10229470004623, "Episode length": 152, "Policy Loss": -0.5475408434867859, "Value Loss": 65.43180847167969, "_runtime": 1570.0980322360992, "_timestamp": 1585571485.9426656, "_step": 231}
{"Episode reward": 87.70296481935223, "Episode length": 144, "Policy Loss": -0.498769074678421, "Value Loss": 69.05925750732422, "_runtime": 1570.3265137672424, "_timestamp": 1585571486.171147, "_step": 232}
{"Episode reward": 86.47802492285889, "Episode length": 156, "Policy Loss": -0.7279983162879944, "Value Loss": 63.75663375854492, "_runtime": 1570.4553554058075, "_timestamp": 1585571486.2999887, "_step": 233}
{"Episode reward": 93.32906044755691, "Episode length": 83, "Policy Loss": -0.42767390608787537, "Value Loss": 119.88461303710938, "_runtime": 1570.6785814762115, "_timestamp": 1585571486.5232148, "_step": 234}
{"Episode reward": 87.07686551538247, "Episode length": 153, "Policy Loss": -0.4324253499507904, "Value Loss": 65.00122833251953, "_runtime": 1570.8889355659485, "_timestamp": 1585571486.733569, "_step": 235}
{"Episode reward": 88.39892264104272, "Episode length": 143, "Policy Loss": -0.6268410086631775, "Value Loss": 69.53475189208984, "_runtime": 1571.103785276413, "_timestamp": 1585571486.9484186, "_step": 236}
{"Episode reward": 87.5835689087931, "Episode length": 149, "Policy Loss": -0.6042898893356323, "Value Loss": 66.74030303955078, "_runtime": 1571.2329850196838, "_timestamp": 1585571487.0776184, "_step": 237}
{"Episode reward": 93.85450558351079, "Episode length": 83, "Policy Loss": -0.674968421459198, "Value Loss": 119.74102020263672, "_runtime": 1571.4682340621948, "_timestamp": 1585571487.3128674, "_step": 238}
{"Episode reward": 86.01143341493707, "Episode length": 162, "Policy Loss": -0.16072823107242584, "Value Loss": 61.39566421508789, "_runtime": 1571.6886413097382, "_timestamp": 1585571487.5332747, "_step": 239}
{"Episode reward": 87.81778570845647, "Episode length": 151, "Policy Loss": 0.10745269805192947, "Value Loss": 65.85377502441406, "_runtime": 1571.8244757652283, "_timestamp": 1585571487.669109, "_step": 240}
{"Episode reward": 93.08708920982612, "Episode length": 91, "Policy Loss": -0.2649787962436676, "Value Loss": 109.22885131835938, "_runtime": 1572.0595889091492, "_timestamp": 1585571487.9042222, "_step": 241}
{"Episode reward": 86.13601137011025, "Episode length": 160, "Policy Loss": -0.696251392364502, "Value Loss": 62.159324645996094, "_runtime": 1572.1881654262543, "_timestamp": 1585571488.0327988, "_step": 242}
{"Episode reward": 93.40418976629252, "Episode length": 83, "Policy Loss": -0.7924137115478516, "Value Loss": 119.75479125976562, "_runtime": 1572.3933815956116, "_timestamp": 1585571488.238015, "_step": 243}
{"Episode reward": 88.14044513948478, "Episode length": 141, "Policy Loss": -0.41149601340293884, "Value Loss": 70.51343536376953, "_runtime": 1572.6304421424866, "_timestamp": 1585571488.4750755, "_step": 244}
{"Episode reward": 85.70243176561638, "Episode length": 163, "Policy Loss": -0.6961474418640137, "Value Loss": 61.01652908325195, "_runtime": 1572.7566244602203, "_timestamp": 1585571488.6012578, "_step": 245}
{"Episode reward": 93.45617263889251, "Episode length": 84, "Policy Loss": 1.2812403440475464, "Value Loss": 118.26005554199219, "_runtime": 1572.8787529468536, "_timestamp": 1585571488.7233863, "_step": 246}
{"Episode reward": 94.05475699857733, "Episode length": 80, "Policy Loss": -0.8626910448074341, "Value Loss": 124.16123962402344, "_runtime": 1573.099717617035, "_timestamp": 1585571488.944351, "_step": 247}
{"Episode reward": 87.52052230047106, "Episode length": 150, "Policy Loss": -0.7713923454284668, "Value Loss": 66.28669738769531, "_runtime": 1573.225747346878, "_timestamp": 1585571489.0703807, "_step": 248}
{"Episode reward": 93.97655081429264, "Episode length": 83, "Policy Loss": -0.4043002724647522, "Value Loss": 119.67174530029297, "_runtime": 1573.4427785873413, "_timestamp": 1585571489.287412, "_step": 249}
{"Episode reward": 88.03566863982151, "Episode length": 151, "Policy Loss": -0.7542033195495605, "Value Loss": 65.84407806396484, "_runtime": 1573.577404499054, "_timestamp": 1585571489.4220378, "_step": 250}
{"Episode reward": 92.52410585974872, "Episode length": 87, "Policy Loss": 0.3395739495754242, "Value Loss": 114.18035888671875, "_runtime": 1573.7978079319, "_timestamp": 1585571489.6424413, "_step": 251}
{"Episode reward": 87.41947339681649, "Episode length": 153, "Policy Loss": -0.7540403604507446, "Value Loss": 64.98545837402344, "_runtime": 1574.0240349769592, "_timestamp": 1585571489.8686683, "_step": 252}
{"Episode reward": 87.3878982240889, "Episode length": 153, "Policy Loss": 0.4645864963531494, "Value Loss": 64.9847183227539, "_runtime": 1574.159052848816, "_timestamp": 1585571490.0036862, "_step": 253}
{"Episode reward": 93.50430178728315, "Episode length": 89, "Policy Loss": 0.34245944023132324, "Value Loss": 111.80030822753906, "_runtime": 1574.2825255393982, "_timestamp": 1585571490.1271589, "_step": 254}
{"Episode reward": 93.23488133609577, "Episode length": 78, "Policy Loss": -0.2443663477897644, "Value Loss": 127.3275146484375, "_runtime": 1574.7432174682617, "_timestamp": 1585571490.5878508, "_step": 255}
{"Episode reward": 78.14691867074694, "Episode length": 319, "Policy Loss": -0.35713642835617065, "Value Loss": 31.234540939331055, "_runtime": 1574.9603061676025, "_timestamp": 1585571490.8049395, "_step": 256}
{"Episode reward": 87.95969289542418, "Episode length": 149, "Policy Loss": 0.29223355650901794, "Value Loss": 66.72068786621094, "_runtime": 1575.0819165706635, "_timestamp": 1585571490.92655, "_step": 257}
{"Episode reward": 93.91145927599986, "Episode length": 79, "Policy Loss": -0.6420366168022156, "Value Loss": 125.70252227783203, "_runtime": 1575.3209524154663, "_timestamp": 1585571491.1655858, "_step": 258}
{"Episode reward": 86.60889354999738, "Episode length": 155, "Policy Loss": -0.3155877888202667, "Value Loss": 64.14628601074219, "_runtime": 1575.5400733947754, "_timestamp": 1585571491.3847067, "_step": 259}
{"Episode reward": 87.6001256249239, "Episode length": 148, "Policy Loss": 0.10252778232097626, "Value Loss": 67.17012786865234, "_runtime": 1575.7618000507355, "_timestamp": 1585571491.6064334, "_step": 260}
{"Episode reward": 87.35751486657625, "Episode length": 152, "Policy Loss": -0.8122110366821289, "Value Loss": 65.40543365478516, "_runtime": 1575.9888920783997, "_timestamp": 1585571491.8335254, "_step": 261}
{"Episode reward": 86.89629485021783, "Episode length": 154, "Policy Loss": -0.4635162353515625, "Value Loss": 64.55868530273438, "_runtime": 1576.2175896167755, "_timestamp": 1585571492.062223, "_step": 262}
{"Episode reward": 87.6690683946051, "Episode length": 155, "Policy Loss": -0.5224876403808594, "Value Loss": 64.13843536376953, "_runtime": 1576.436871767044, "_timestamp": 1585571492.281505, "_step": 263}
{"Episode reward": 87.66521005489147, "Episode length": 149, "Policy Loss": 2.508335590362549, "Value Loss": 66.71672058105469, "_runtime": 1576.660694360733, "_timestamp": 1585571492.5053277, "_step": 264}
{"Episode reward": 87.13388103770717, "Episode length": 151, "Policy Loss": -0.772127091884613, "Value Loss": 65.8363265991211, "_runtime": 1576.8725190162659, "_timestamp": 1585571492.7171524, "_step": 265}
{"Episode reward": 87.99721937894704, "Episode length": 143, "Policy Loss": -0.9021092057228088, "Value Loss": 69.50867462158203, "_runtime": 1577.0013477802277, "_timestamp": 1585571492.8459811, "_step": 266}
{"Episode reward": 93.2468617608871, "Episode length": 82, "Policy Loss": -0.6882020235061646, "Value Loss": 121.27018737792969, "_runtime": 1577.2292523384094, "_timestamp": 1585571493.0738857, "_step": 267}
{"Episode reward": 87.32288573311301, "Episode length": 154, "Policy Loss": -0.8485022187232971, "Value Loss": 64.55291748046875, "_runtime": 1577.3557705879211, "_timestamp": 1585571493.200404, "_step": 268}
{"Episode reward": 93.20025303199012, "Episode length": 81, "Policy Loss": 1.0302709341049194, "Value Loss": 122.58348083496094, "_runtime": 1577.5648114681244, "_timestamp": 1585571493.4094448, "_step": 269}
{"Episode reward": 88.14974753970813, "Episode length": 144, "Policy Loss": -0.8089994788169861, "Value Loss": 69.02301025390625, "_runtime": 1577.792120218277, "_timestamp": 1585571493.6367536, "_step": 270}
{"Episode reward": 86.83897170461134, "Episode length": 154, "Policy Loss": 0.26333093643188477, "Value Loss": 64.55342864990234, "_runtime": 1578.0154166221619, "_timestamp": 1585571493.86005, "_step": 271}
{"Episode reward": 86.85026069489177, "Episode length": 154, "Policy Loss": -0.8440726399421692, "Value Loss": 64.55274963378906, "_runtime": 1578.238914012909, "_timestamp": 1585571494.0835474, "_step": 272}
{"Episode reward": 87.99624478185763, "Episode length": 151, "Policy Loss": -0.7067011594772339, "Value Loss": 65.82666778564453, "_runtime": 1578.3656022548676, "_timestamp": 1585571494.2102356, "_step": 273}
{"Episode reward": 93.64631752661258, "Episode length": 81, "Policy Loss": 0.4551912546157837, "Value Loss": 122.5686264038086, "_runtime": 1578.5857858657837, "_timestamp": 1585571494.4304192, "_step": 274}
{"Episode reward": 88.05251829408641, "Episode length": 149, "Policy Loss": 0.8271911144256592, "Value Loss": 66.7072982788086, "_runtime": 1578.7975013256073, "_timestamp": 1585571494.6421347, "_step": 275}
{"Episode reward": 88.34166459034418, "Episode length": 143, "Policy Loss": -0.4141627252101898, "Value Loss": 69.49945831298828, "_runtime": 1579.0150401592255, "_timestamp": 1585571494.8596735, "_step": 276}
{"Episode reward": 88.26019633133485, "Episode length": 151, "Policy Loss": -0.8517877459526062, "Value Loss": 65.82279968261719, "_runtime": 1579.2342569828033, "_timestamp": 1585571495.0788903, "_step": 277}
{"Episode reward": 87.254618725142, "Episode length": 147, "Policy Loss": -0.8618062138557434, "Value Loss": 67.61643981933594, "_runtime": 1579.3705079555511, "_timestamp": 1585571495.2151413, "_step": 278}
{"Episode reward": 92.8473559298335, "Episode length": 88, "Policy Loss": -0.8838697671890259, "Value Loss": 112.82500457763672, "_runtime": 1579.49844622612, "_timestamp": 1585571495.3430796, "_step": 279}
{"Episode reward": 93.71409838610634, "Episode length": 82, "Policy Loss": 5.017475605010986, "Value Loss": 121.06229400634766, "_runtime": 1579.7135779857635, "_timestamp": 1585571495.5582113, "_step": 280}
{"Episode reward": 87.74703459582676, "Episode length": 146, "Policy Loss": -0.8414738178253174, "Value Loss": 68.07344818115234, "_runtime": 1579.947250366211, "_timestamp": 1585571495.7918837, "_step": 281}
{"Episode reward": 86.26928500819182, "Episode length": 161, "Policy Loss": 0.40007153153419495, "Value Loss": 61.74818801879883, "_runtime": 1580.1758353710175, "_timestamp": 1585571496.0204687, "_step": 282}
{"Episode reward": 86.82327622013693, "Episode length": 158, "Policy Loss": -0.8921303153038025, "Value Loss": 63.04164123535156, "_runtime": 1580.3972895145416, "_timestamp": 1585571496.2419229, "_step": 283}
{"Episode reward": 87.01419096604019, "Episode length": 151, "Policy Loss": -0.6518709063529968, "Value Loss": 65.82498931884766, "_runtime": 1580.6231923103333, "_timestamp": 1585571496.4678257, "_step": 284}
{"Episode reward": 87.28129448960257, "Episode length": 153, "Policy Loss": -0.8458012342453003, "Value Loss": 64.96405029296875, "_runtime": 1580.8527629375458, "_timestamp": 1585571496.6973963, "_step": 285}
{"Episode reward": 86.63856938693732, "Episode length": 157, "Policy Loss": -0.8188513517379761, "Value Loss": 63.314659118652344, "_runtime": 1581.063934803009, "_timestamp": 1585571496.9085681, "_step": 286}
{"Episode reward": 87.91765113408593, "Episode length": 142, "Policy Loss": -0.8100369572639465, "Value Loss": 69.98295593261719, "_runtime": 1581.1915528774261, "_timestamp": 1585571497.0361862, "_step": 287}
{"Episode reward": 93.68688924588973, "Episode length": 81, "Policy Loss": -1.1146525144577026, "Value Loss": 122.54022979736328, "_runtime": 1581.3134329319, "_timestamp": 1585571497.1580663, "_step": 288}
{"Episode reward": 93.84247635797975, "Episode length": 77, "Policy Loss": -0.5487347841262817, "Value Loss": 128.8960723876953, "_runtime": 1581.438572883606, "_timestamp": 1585571497.2832062, "_step": 289}
{"Episode reward": 93.72886731514893, "Episode length": 80, "Policy Loss": -0.9026591181755066, "Value Loss": 124.06581115722656, "_runtime": 1581.6501240730286, "_timestamp": 1585571497.4947574, "_step": 290}
{"Episode reward": 87.75684429498772, "Episode length": 146, "Policy Loss": 2.164886951446533, "Value Loss": 68.06700134277344, "_runtime": 1581.8721060752869, "_timestamp": 1585571497.7167394, "_step": 291}
{"Episode reward": 86.98356902259164, "Episode length": 154, "Policy Loss": -0.2011706829071045, "Value Loss": 64.54072570800781, "_runtime": 1582.0063591003418, "_timestamp": 1585571497.8509924, "_step": 292}
{"Episode reward": 92.74630713700662, "Episode length": 90, "Policy Loss": -0.3085523247718811, "Value Loss": 110.35961151123047, "_runtime": 1582.13241648674, "_timestamp": 1585571497.9770498, "_step": 293}
{"Episode reward": 93.20640156854503, "Episode length": 81, "Policy Loss": -0.4469846487045288, "Value Loss": 122.53173065185547, "_runtime": 1582.3468940258026, "_timestamp": 1585571498.1915274, "_step": 294}
{"Episode reward": 88.28574418275609, "Episode length": 144, "Policy Loss": -0.85239577293396, "Value Loss": 69.0047378540039, "_runtime": 1582.575073003769, "_timestamp": 1585571498.4197063, "_step": 295}
{"Episode reward": 86.69754235126982, "Episode length": 155, "Policy Loss": -0.7676798701286316, "Value Loss": 64.1241455078125, "_runtime": 1582.8028588294983, "_timestamp": 1585571498.6474922, "_step": 296}
{"Episode reward": 87.48973000384888, "Episode length": 155, "Policy Loss": -0.526932418346405, "Value Loss": 64.11934661865234, "_runtime": 1582.9416375160217, "_timestamp": 1585571498.7862709, "_step": 297}
{"Episode reward": 93.30566975514705, "Episode length": 84, "Policy Loss": 3.5152478218078613, "Value Loss": 118.15023803710938, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125, 331.7452392578125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-332.6318359375, -331.6453552246094, -330.65887451171875, -329.6723937988281, -328.6858825683594, -327.69940185546875, -326.7129211425781, -325.7264404296875, -324.7399597167969, -323.75347900390625, -322.7669982910156, -321.7804870605469, -320.79400634765625, -319.8075256347656, -318.821044921875, -317.8345642089844, -316.84808349609375, -315.8616027832031, -314.8751220703125, -313.88861083984375, -312.9021301269531, -311.9156494140625, -310.9291687011719, -309.94268798828125, -308.9562072753906, -307.9697265625, -306.98321533203125, -305.9967346191406, -305.01025390625, -304.0237731933594, -303.03729248046875, -302.0508117675781, -301.0643310546875, -300.07781982421875, -299.0913391113281, -298.1048583984375, -297.1183776855469, -296.13189697265625, -295.1454162597656, -294.158935546875, -293.17242431640625, -292.1859436035156, -291.199462890625, -290.2129821777344, -289.22650146484375, -288.2400207519531, -287.2535400390625, -286.26702880859375, -285.2805480957031, -284.2940673828125, -283.3075866699219, -282.32110595703125, -281.3346252441406, -280.34814453125, -279.36163330078125, -278.3751525878906, -277.388671875, -276.4021911621094, -275.41571044921875, -274.4292297363281, -273.4427490234375, -272.45623779296875, -271.4697570800781, -270.4832763671875, -269.4967956542969]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-13.31932258605957, -13.027549743652344, -12.735776901245117, -12.44400405883789, -12.15223217010498, -11.860459327697754, -11.568686485290527, -11.2769136428833, -10.985140800476074, -10.693368911743164, -10.401596069335938, -10.109823226928711, -9.818050384521484, -9.526277542114258, -9.234504699707031, -8.942731857299805, -8.650959014892578, -8.359186172485352, -8.067414283752441, -7.775641441345215, -7.483868598937988, -7.19209623336792, -6.900323390960693, -6.608550548553467, -6.316778182983398, -6.025005340576172, -5.733232498168945, -5.441459655761719, -5.149686813354492, -4.857914924621582, -4.5661420822143555, -4.274369239807129, -3.9825963973999023, -3.690823554992676, -3.399050712585449, -3.1072778701782227, -2.8155059814453125, -2.523733139038086, -2.2319602966308594, -1.9401874542236328, -1.6484146118164062, -1.3566417694091797, -1.0648698806762695, -0.773097038269043, -0.4813241958618164, -0.18955135345458984, 0.10222148895263672, 0.3939943313598633, 0.6857662200927734, 0.9775390625, 1.2693119049072266, 1.5610847473144531, 1.8528575897216797, 2.1446304321289062, 2.436403274536133, 2.7281761169433594, 3.019948959350586, 3.3117218017578125, 3.6034927368164062, 3.895265579223633, 4.187038421630859, 4.478811264038086, 4.7705841064453125, 5.062356948852539, 5.354129791259766]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 4.0, 5.0, 5.0, 7.0, 9.0, 12.0, 15.0, 101.0, 227.0, 26.0, 5.0, 15.0, 5.0, 8.0, 3.0, 4.0, 1.0, 4.0, 5.0, 5.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 3.0, 3.0, 1.0], "bins": [-23.468969345092773, -22.924592971801758, -22.380216598510742, -21.835840225219727, -21.29146385192871, -20.747087478637695, -20.20271110534668, -19.658334732055664, -19.11395835876465, -18.569581985473633, -18.025205612182617, -17.4808292388916, -16.93645477294922, -16.392078399658203, -15.847701072692871, -15.303324699401855, -14.75894832611084, -14.214571952819824, -13.670195579528809, -13.125819206237793, -12.581442832946777, -12.037066459655762, -11.492690086364746, -10.94831371307373, -10.403938293457031, -9.859561920166016, -9.315185546875, -8.770809173583984, -8.226432800292969, -7.682056427001953, -7.1376800537109375, -6.593303680419922, -6.048927307128906, -5.504550933837891, -4.960174560546875, -4.415798187255859, -3.8714218139648438, -3.327045440673828, -2.7826690673828125, -2.238292694091797, -1.6939163208007812, -1.1495399475097656, -0.60516357421875, -0.060787200927734375, 0.48358917236328125, 1.0279655456542969, 1.5723419189453125, 2.116718292236328, 2.661092758178711, 3.2054691314697266, 3.749845504760742, 4.294221878051758, 4.838598251342773, 5.382974624633789, 5.927350997924805, 6.47172737121582, 7.016103744506836, 7.560480117797852, 8.104856491088867, 8.649232864379883, 9.193609237670898, 9.737985610961914, 10.28236198425293, 10.826738357543945, 11.371114730834961]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 4.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-19.3277530670166, -18.717430114746094, -18.107107162475586, -17.496784210205078, -16.88646125793457, -16.276138305664062, -15.665816307067871, -15.055493354797363, -14.445170402526855, -13.834847450256348, -13.22452449798584, -12.614202499389648, -12.00387954711914, -11.393556594848633, -10.783233642578125, -10.172910690307617, -9.56258773803711, -8.952264785766602, -8.341941833496094, -7.731618881225586, -7.121295928955078, -6.510973930358887, -5.900650978088379, -5.290328025817871, -4.680005073547363, -4.0696821212768555, -3.4593591690063477, -2.8490371704101562, -2.2387142181396484, -1.6283912658691406, -1.0180683135986328, -0.407745361328125, 0.2025775909423828, 0.8129005432128906, 1.4232234954833984, 2.0335464477539062, 2.643869400024414, 3.254192352294922, 3.8645153045654297, 4.4748382568359375, 5.085161209106445, 5.69548225402832, 6.305805206298828, 6.916128158569336, 7.526451110839844, 8.136774063110352, 8.74709701538086, 9.357419967651367, 9.967742919921875, 10.578065872192383, 11.18838882446289, 11.798711776733398, 12.409034729003906, 13.019357681274414, 13.629678726196289, 14.24000358581543, 14.850324630737305, 15.460649490356445, 16.07097053527832, 16.68129539489746, 17.291616439819336, 17.901941299438477, 18.51226234436035, 19.122587203979492, 19.732908248901367]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 6.0, 4.0, 3.0, 8.0, 11.0, 2.0, 6.0, 6.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-23.34805679321289, -22.65199089050293, -21.9559268951416, -21.25986099243164, -20.56379508972168, -19.86772918701172, -19.17166519165039, -18.47559928894043, -17.77953338623047, -17.08346939086914, -16.38740348815918, -15.691338539123535, -14.99527359008789, -14.29920768737793, -13.603142738342285, -12.907076835632324, -12.21101188659668, -11.514946937561035, -10.818881034851074, -10.12281608581543, -9.426750183105469, -8.730685234069824, -8.03462028503418, -7.338554382324219, -6.642490386962891, -5.94642448425293, -5.250358581542969, -4.554292678833008, -3.8582286834716797, -3.1621627807617188, -2.466096878051758, -1.7700328826904297, -1.0739669799804688, -0.3779010772705078, 0.3181629180908203, 1.0142288208007812, 1.7102947235107422, 2.4063587188720703, 3.1024246215820312, 3.798490524291992, 4.494556427001953, 5.190620422363281, 5.886686325073242, 6.582752227783203, 7.278816223144531, 7.974882125854492, 8.670948028564453, 9.367012023925781, 10.06307601928711, 10.759143829345703, 11.455207824707031, 12.151275634765625, 12.847339630126953, 13.543403625488281, 14.239471435546875, 14.935535430908203, 15.631599426269531, 16.327667236328125, 17.023731231689453, 17.71979522705078, 18.415863037109375, 19.111927032470703, 19.80799102783203, 20.504058837890625, 21.200122833251953]}, "_runtime": 1583.1624262332916, "_timestamp": 1585571499.0070596, "_step": 298}
{"Episode reward": 87.87170254207201, "Episode length": 150, "Policy Loss": 0.10499682277441025, "Value Loss": 66.24913787841797, "_runtime": 1583.3851425647736, "_timestamp": 1585571499.229776, "_step": 299}
{"Episode reward": 87.4753711558998, "Episode length": 151, "Policy Loss": -0.9280000329017639, "Value Loss": 65.81278991699219, "_runtime": 1583.5886926651, "_timestamp": 1585571499.433326, "_step": 300}
{"Episode reward": 88.80463570914765, "Episode length": 140, "Policy Loss": -0.6376731395721436, "Value Loss": 70.96514892578125, "_runtime": 1583.812567949295, "_timestamp": 1585571499.6572013, "_step": 301}
{"Episode reward": 87.12880060628571, "Episode length": 152, "Policy Loss": -0.2098577618598938, "Value Loss": 65.38157653808594, "_runtime": 1584.026239156723, "_timestamp": 1585571499.8708725, "_step": 302}
{"Episode reward": 88.48319100830308, "Episode length": 146, "Policy Loss": -0.8029811978340149, "Value Loss": 68.05467987060547, "_runtime": 1584.2496490478516, "_timestamp": 1585571500.0942824, "_step": 303}
{"Episode reward": 86.89067904401516, "Episode length": 154, "Policy Loss": -0.6715147495269775, "Value Loss": 64.53453826904297, "_runtime": 1584.3814096450806, "_timestamp": 1585571500.226043, "_step": 304}
{"Episode reward": 93.13457888946814, "Episode length": 86, "Policy Loss": -0.04316336661577225, "Value Loss": 115.43142700195312, "_runtime": 1584.5999553203583, "_timestamp": 1585571500.4445887, "_step": 305}
{"Episode reward": 88.0416979378131, "Episode length": 150, "Policy Loss": -0.9021282196044922, "Value Loss": 66.244384765625, "_runtime": 1584.7272465229034, "_timestamp": 1585571500.5718799, "_step": 306}
{"Episode reward": 93.48338319452328, "Episode length": 82, "Policy Loss": -0.998727560043335, "Value Loss": 121.00968170166016, "_runtime": 1584.9418275356293, "_timestamp": 1585571500.7864609, "_step": 307}
{"Episode reward": 87.83873119796955, "Episode length": 149, "Policy Loss": -0.18097005784511566, "Value Loss": 66.68816375732422, "_runtime": 1585.1549079418182, "_timestamp": 1585571500.9995413, "_step": 308}
{"Episode reward": 88.6205087543455, "Episode length": 146, "Policy Loss": -0.8777039647102356, "Value Loss": 68.05048370361328, "_runtime": 1585.3652884960175, "_timestamp": 1585571501.2099218, "_step": 309}
{"Episode reward": 88.42003449161501, "Episode length": 146, "Policy Loss": -0.950061023235321, "Value Loss": 68.05119323730469, "_runtime": 1585.5818939208984, "_timestamp": 1585571501.4265273, "_step": 310}
{"Episode reward": 88.04486814059742, "Episode length": 148, "Policy Loss": -0.686073899269104, "Value Loss": 67.13510131835938, "_runtime": 1585.7943723201752, "_timestamp": 1585571501.6390057, "_step": 311}
{"Episode reward": 88.76630080270724, "Episode length": 145, "Policy Loss": -0.8461162447929382, "Value Loss": 68.51631164550781, "_runtime": 1586.0045804977417, "_timestamp": 1585571501.8492138, "_step": 312}
{"Episode reward": 87.83826870114866, "Episode length": 144, "Policy Loss": -1.0067670345306396, "Value Loss": 68.9963150024414, "_runtime": 1586.2176959514618, "_timestamp": 1585571502.0623293, "_step": 313}
{"Episode reward": 88.65416864613435, "Episode length": 145, "Policy Loss": -0.9796121716499329, "Value Loss": 68.51605224609375, "_runtime": 1586.34619307518, "_timestamp": 1585571502.1908264, "_step": 314}
{"Episode reward": 93.72863626669805, "Episode length": 83, "Policy Loss": -0.905678927898407, "Value Loss": 119.66874694824219, "_runtime": 1586.5682680606842, "_timestamp": 1585571502.4129014, "_step": 315}
{"Episode reward": 87.37929640972028, "Episode length": 152, "Policy Loss": 1.0077576637268066, "Value Loss": 65.37354278564453, "_runtime": 1586.689374446869, "_timestamp": 1585571502.5340078, "_step": 316}
{"Episode reward": 93.99727157751015, "Episode length": 78, "Policy Loss": -1.0624991655349731, "Value Loss": 127.18383026123047, "_runtime": 1586.912355184555, "_timestamp": 1585571502.7569885, "_step": 317}
{"Episode reward": 87.08196367399806, "Episode length": 156, "Policy Loss": -0.7279887795448303, "Value Loss": 63.70168685913086, "_runtime": 1587.1278381347656, "_timestamp": 1585571502.9724715, "_step": 318}
{"Episode reward": 87.8543057249969, "Episode length": 147, "Policy Loss": 0.1220155730843544, "Value Loss": 67.58796691894531, "_runtime": 1587.3373005390167, "_timestamp": 1585571503.1819339, "_step": 319}
{"Episode reward": 88.31552574610528, "Episode length": 145, "Policy Loss": -0.9306643605232239, "Value Loss": 68.51490783691406, "_runtime": 1587.5470643043518, "_timestamp": 1585571503.3916976, "_step": 320}
{"Episode reward": 87.88779586664147, "Episode length": 143, "Policy Loss": 0.13549594581127167, "Value Loss": 69.47315979003906, "_runtime": 1587.771314382553, "_timestamp": 1585571503.6159477, "_step": 321}
{"Episode reward": 87.24715970231264, "Episode length": 153, "Policy Loss": -0.7642552852630615, "Value Loss": 64.94536590576172, "_runtime": 1587.898987531662, "_timestamp": 1585571503.7436209, "_step": 322}
{"Episode reward": 93.6354818750349, "Episode length": 83, "Policy Loss": -0.9693852663040161, "Value Loss": 119.52430725097656, "_runtime": 1588.1184542179108, "_timestamp": 1585571503.9630876, "_step": 323}
{"Episode reward": 87.5673126863067, "Episode length": 150, "Policy Loss": -0.3459121584892273, "Value Loss": 66.23851776123047, "_runtime": 1588.343921661377, "_timestamp": 1585571504.188555, "_step": 324}
{"Episode reward": 87.07463015795007, "Episode length": 155, "Policy Loss": -0.8028838038444519, "Value Loss": 64.10897064208984, "_runtime": 1588.5773212909698, "_timestamp": 1585571504.4219546, "_step": 325}
{"Episode reward": 86.09354317686856, "Episode length": 163, "Policy Loss": -0.9507615566253662, "Value Loss": 60.97503662109375, "_runtime": 1588.6985507011414, "_timestamp": 1585571504.543184, "_step": 326}
{"Episode reward": 93.64633482875924, "Episode length": 78, "Policy Loss": -0.8265929818153381, "Value Loss": 127.16925811767578, "_runtime": 1588.9140093326569, "_timestamp": 1585571504.7586427, "_step": 327}
{"Episode reward": 88.01719494907289, "Episode length": 146, "Policy Loss": -1.0139954090118408, "Value Loss": 68.04457092285156, "_runtime": 1589.0474517345428, "_timestamp": 1585571504.892085, "_step": 328}
{"Episode reward": 93.57089910427855, "Episode length": 86, "Policy Loss": -0.42729631066322327, "Value Loss": 115.35131072998047, "_runtime": 1589.2781608104706, "_timestamp": 1585571505.1227942, "_step": 329}
{"Episode reward": 86.62745569621796, "Episode length": 154, "Policy Loss": -0.9688536524772644, "Value Loss": 64.52507019042969, "_runtime": 1589.4155292510986, "_timestamp": 1585571505.2601626, "_step": 330}
{"Episode reward": 93.56149799947222, "Episode length": 84, "Policy Loss": -0.5520869493484497, "Value Loss": 118.2690658569336, "_runtime": 1589.6404178142548, "_timestamp": 1585571505.4850512, "_step": 331}
{"Episode reward": 86.47041641756624, "Episode length": 157, "Policy Loss": -0.7685556411743164, "Value Loss": 63.29526901245117, "_runtime": 1589.8474206924438, "_timestamp": 1585571505.692054, "_step": 332}
{"Episode reward": 87.96512441386551, "Episode length": 141, "Policy Loss": -0.9681283831596375, "Value Loss": 70.4496841430664, "_runtime": 1590.054414510727, "_timestamp": 1585571505.8990479, "_step": 333}
{"Episode reward": 87.97282890688493, "Episode length": 144, "Policy Loss": -0.7040757536888123, "Value Loss": 68.98470306396484, "_runtime": 1590.2717499732971, "_timestamp": 1585571506.1163833, "_step": 334}
{"Episode reward": 87.382028142111, "Episode length": 148, "Policy Loss": -0.8550451993942261, "Value Loss": 67.1278076171875, "_runtime": 1590.4819209575653, "_timestamp": 1585571506.3265543, "_step": 335}
{"Episode reward": 88.07780822790559, "Episode length": 144, "Policy Loss": -1.075061321258545, "Value Loss": 68.98306274414062, "_runtime": 1590.6945095062256, "_timestamp": 1585571506.5391428, "_step": 336}
{"Episode reward": 88.07652235075285, "Episode length": 146, "Policy Loss": -0.8423422574996948, "Value Loss": 68.0399169921875, "_runtime": 1590.821771621704, "_timestamp": 1585571506.666405, "_step": 337}
{"Episode reward": 93.8506557015261, "Episode length": 82, "Policy Loss": -0.38471856713294983, "Value Loss": 120.95221710205078, "_runtime": 1591.0305759906769, "_timestamp": 1585571506.8752093, "_step": 338}
{"Episode reward": 88.27135052419248, "Episode length": 142, "Policy Loss": -0.7179779410362244, "Value Loss": 69.94979858398438, "_runtime": 1591.2476234436035, "_timestamp": 1585571507.0922568, "_step": 339}
{"Episode reward": 88.14066296200525, "Episode length": 147, "Policy Loss": -1.0833475589752197, "Value Loss": 67.57646942138672, "_runtime": 1591.4621186256409, "_timestamp": 1585571507.306752, "_step": 340}
{"Episode reward": 87.42398988157741, "Episode length": 150, "Policy Loss": -0.8761000633239746, "Value Loss": 66.2322998046875, "_runtime": 1591.694809436798, "_timestamp": 1585571507.5394428, "_step": 341}
{"Episode reward": 87.24479324812432, "Episode length": 160, "Policy Loss": -1.0131051540374756, "Value Loss": 62.10387420654297, "_runtime": 1591.8215627670288, "_timestamp": 1585571507.666196, "_step": 342}
{"Episode reward": 93.90366836014773, "Episode length": 81, "Policy Loss": 1.2390581369400024, "Value Loss": 122.43478393554688, "_runtime": 1592.0431032180786, "_timestamp": 1585571507.8877366, "_step": 343}
{"Episode reward": 87.16543266273717, "Episode length": 151, "Policy Loss": -0.9202169179916382, "Value Loss": 65.79519653320312, "_runtime": 1592.1639187335968, "_timestamp": 1585571508.008552, "_step": 344}
{"Episode reward": 94.10920997522155, "Episode length": 77, "Policy Loss": -0.3454624116420746, "Value Loss": 128.78057861328125, "_runtime": 1592.3753771781921, "_timestamp": 1585571508.2200105, "_step": 345}
{"Episode reward": 88.0665794978558, "Episode length": 147, "Policy Loss": -0.5235233902931213, "Value Loss": 67.57451629638672, "_runtime": 1592.602123260498, "_timestamp": 1585571508.4467566, "_step": 346}
{"Episode reward": 86.518970305536, "Episode length": 156, "Policy Loss": -0.6070811152458191, "Value Loss": 63.69477462768555, "_runtime": 1592.8163311481476, "_timestamp": 1585571508.6609645, "_step": 347}
{"Episode reward": 87.47668025555181, "Episode length": 149, "Policy Loss": -0.16678376495838165, "Value Loss": 66.67268371582031, "_runtime": 1593.0371367931366, "_timestamp": 1585571508.8817701, "_step": 348}
{"Episode reward": 88.49833835069666, "Episode length": 152, "Policy Loss": -0.9461579322814941, "Value Loss": 65.35337829589844, "_runtime": 1593.2597861289978, "_timestamp": 1585571509.1044195, "_step": 349}
{"Episode reward": 86.75682272371533, "Episode length": 152, "Policy Loss": -0.8132246732711792, "Value Loss": 65.36395263671875, "_runtime": 1593.487918138504, "_timestamp": 1585571509.3325515, "_step": 350}
{"Episode reward": 87.23277306239949, "Episode length": 159, "Policy Loss": -0.9704726934432983, "Value Loss": 62.49079513549805, "_runtime": 1593.6980142593384, "_timestamp": 1585571509.5426476, "_step": 351}
{"Episode reward": 87.938109428212, "Episode length": 144, "Policy Loss": -1.0480432510375977, "Value Loss": 68.97723388671875, "_runtime": 1593.8242354393005, "_timestamp": 1585571509.6688688, "_step": 352}
{"Episode reward": 93.88279810202998, "Episode length": 81, "Policy Loss": -0.924944281578064, "Value Loss": 122.64118957519531, "_runtime": 1594.0424478054047, "_timestamp": 1585571509.8870811, "_step": 353}
{"Episode reward": 87.88729672975946, "Episode length": 149, "Policy Loss": -0.6066070795059204, "Value Loss": 66.66795349121094, "_runtime": 1594.2715229988098, "_timestamp": 1585571510.1161563, "_step": 354}
{"Episode reward": 86.73707943661945, "Episode length": 157, "Policy Loss": -0.9801247715950012, "Value Loss": 63.28666305541992, "_runtime": 1594.3929133415222, "_timestamp": 1585571510.2375467, "_step": 355}
{"Episode reward": 93.6082156197593, "Episode length": 81, "Policy Loss": -0.21155232191085815, "Value Loss": 122.41812896728516, "_runtime": 1594.5210404396057, "_timestamp": 1585571510.3656738, "_step": 356}
{"Episode reward": 93.70793202300159, "Episode length": 83, "Policy Loss": -1.1334882974624634, "Value Loss": 119.46987915039062, "_runtime": 1594.7371048927307, "_timestamp": 1585571510.5817382, "_step": 357}
{"Episode reward": 87.31974044204735, "Episode length": 148, "Policy Loss": -0.6811882853507996, "Value Loss": 67.11953735351562, "_runtime": 1594.8600294589996, "_timestamp": 1585571510.7046628, "_step": 358}
{"Episode reward": 94.016348803052, "Episode length": 82, "Policy Loss": -0.5967510342597961, "Value Loss": 120.9176025390625, "_runtime": 1594.9811346530914, "_timestamp": 1585571510.825768, "_step": 359}
{"Episode reward": 93.52115727219812, "Episode length": 81, "Policy Loss": -1.1186792850494385, "Value Loss": 122.41219329833984, "_runtime": 1595.2065794467926, "_timestamp": 1585571511.0512128, "_step": 360}
{"Episode reward": 87.19163988026953, "Episode length": 154, "Policy Loss": -1.0208381414413452, "Value Loss": 64.5111312866211, "_runtime": 1595.3369057178497, "_timestamp": 1585571511.181539, "_step": 361}
{"Episode reward": 94.00801716566274, "Episode length": 78, "Policy Loss": -1.164270043373108, "Value Loss": 127.31732177734375, "_runtime": 1595.5643174648285, "_timestamp": 1585571511.4089508, "_step": 362}
{"Episode reward": 86.3206468732395, "Episode length": 156, "Policy Loss": -0.7118279933929443, "Value Loss": 63.691261291503906, "_runtime": 1595.7804458141327, "_timestamp": 1585571511.6250792, "_step": 363}
{"Episode reward": 88.02684436841132, "Episode length": 148, "Policy Loss": -0.8668139576911926, "Value Loss": 67.1122817993164, "_runtime": 1595.9855360984802, "_timestamp": 1585571511.8301694, "_step": 364}
{"Episode reward": 87.52006735350359, "Episode length": 143, "Policy Loss": -0.9430443644523621, "Value Loss": 69.45526885986328, "_runtime": 1596.2114267349243, "_timestamp": 1585571512.05606, "_step": 365}
{"Episode reward": 86.88238710055819, "Episode length": 155, "Policy Loss": -0.7072128057479858, "Value Loss": 64.09640502929688, "_runtime": 1596.431587934494, "_timestamp": 1585571512.2762213, "_step": 366}
{"Episode reward": 87.15507548717126, "Episode length": 151, "Policy Loss": -0.8206414580345154, "Value Loss": 65.7871322631836, "_runtime": 1596.6539976596832, "_timestamp": 1585571512.498631, "_step": 367}
{"Episode reward": 86.97617986215732, "Episode length": 153, "Policy Loss": -0.667337954044342, "Value Loss": 64.93069458007812, "_runtime": 1596.8685624599457, "_timestamp": 1585571512.7131958, "_step": 368}
{"Episode reward": 88.01849164307804, "Episode length": 147, "Policy Loss": -0.19519561529159546, "Value Loss": 67.56572723388672, "_runtime": 1597.0749244689941, "_timestamp": 1585571512.9195578, "_step": 369}
{"Episode reward": 88.16229091707497, "Episode length": 140, "Policy Loss": -0.18505680561065674, "Value Loss": 70.93309020996094, "_runtime": 1597.2867758274078, "_timestamp": 1585571513.1314092, "_step": 370}
{"Episode reward": 87.79736363497953, "Episode length": 145, "Policy Loss": -0.8390710949897766, "Value Loss": 68.49589538574219, "_runtime": 1597.5143790245056, "_timestamp": 1585571513.3590124, "_step": 371}
{"Episode reward": 86.80331937668221, "Episode length": 157, "Policy Loss": -0.8704536557197571, "Value Loss": 63.28141784667969, "_runtime": 1597.7277855873108, "_timestamp": 1585571513.572419, "_step": 372}
{"Episode reward": 88.02623717186277, "Episode length": 146, "Policy Loss": -0.7607388496398926, "Value Loss": 68.02603912353516, "_runtime": 1597.9353835582733, "_timestamp": 1585571513.780017, "_step": 373}
{"Episode reward": 87.97623915765891, "Episode length": 142, "Policy Loss": -0.4456205368041992, "Value Loss": 69.93683624267578, "_runtime": 1598.0722725391388, "_timestamp": 1585571513.9169059, "_step": 374}
{"Episode reward": 93.13529926079018, "Episode length": 89, "Policy Loss": 1.563631534576416, "Value Loss": 111.49002838134766, "_runtime": 1598.2846584320068, "_timestamp": 1585571514.1292918, "_step": 375}
{"Episode reward": 87.7823432877295, "Episode length": 145, "Policy Loss": -0.07603985071182251, "Value Loss": 68.49469757080078, "_runtime": 1598.4990553855896, "_timestamp": 1585571514.3436887, "_step": 376}
{"Episode reward": 87.94867085911267, "Episode length": 147, "Policy Loss": 0.3677462637424469, "Value Loss": 67.56401062011719, "_runtime": 1598.7070066928864, "_timestamp": 1585571514.55164, "_step": 377}
{"Episode reward": 88.12217285326088, "Episode length": 145, "Policy Loss": -1.1549667119979858, "Value Loss": 68.49169921875, "_runtime": 1598.9212667942047, "_timestamp": 1585571514.7659001, "_step": 378}
{"Episode reward": 87.53237932067478, "Episode length": 146, "Policy Loss": -0.504554271697998, "Value Loss": 68.02767944335938, "_runtime": 1599.133932352066, "_timestamp": 1585571514.9785657, "_step": 379}
{"Episode reward": 88.12288882574882, "Episode length": 145, "Policy Loss": -1.0744556188583374, "Value Loss": 68.4910888671875, "_runtime": 1599.352412223816, "_timestamp": 1585571515.1970456, "_step": 380}
{"Episode reward": 87.60884450835093, "Episode length": 149, "Policy Loss": -1.073252558708191, "Value Loss": 66.66109466552734, "_runtime": 1599.556455373764, "_timestamp": 1585571515.4010887, "_step": 381}
{"Episode reward": 88.30779166068238, "Episode length": 139, "Policy Loss": -1.1780983209609985, "Value Loss": 71.43709564208984, "_runtime": 1599.7779433727264, "_timestamp": 1585571515.6225767, "_step": 382}
{"Episode reward": 87.44005448593441, "Episode length": 152, "Policy Loss": -0.9739538431167603, "Value Loss": 65.35018920898438, "_runtime": 1599.9954187870026, "_timestamp": 1585571515.8400521, "_step": 383}
{"Episode reward": 87.63864705804258, "Episode length": 149, "Policy Loss": -1.1271337270736694, "Value Loss": 66.66034698486328, "_runtime": 1600.216922044754, "_timestamp": 1585571516.0615554, "_step": 384}
{"Episode reward": 87.24552259498392, "Episode length": 152, "Policy Loss": -0.2305324673652649, "Value Loss": 65.35114288330078, "_runtime": 1600.3447811603546, "_timestamp": 1585571516.1894145, "_step": 385}
{"Episode reward": 93.39961455685972, "Episode length": 82, "Policy Loss": -1.217057704925537, "Value Loss": 121.00078582763672, "_runtime": 1600.5749263763428, "_timestamp": 1585571516.4195597, "_step": 386}
{"Episode reward": 86.290824456092, "Episode length": 158, "Policy Loss": -0.9457592368125916, "Value Loss": 62.88301467895508, "_runtime": 1600.6929547786713, "_timestamp": 1585571516.5375881, "_step": 387}
{"Episode reward": 93.89614125143139, "Episode length": 75, "Policy Loss": -0.9835737347602844, "Value Loss": 132.14231872558594, "_runtime": 1600.9036202430725, "_timestamp": 1585571516.7482536, "_step": 388}
{"Episode reward": 87.67273772808714, "Episode length": 146, "Policy Loss": -1.1079444885253906, "Value Loss": 68.02438354492188, "_runtime": 1601.1247091293335, "_timestamp": 1585571516.9693425, "_step": 389}
{"Episode reward": 87.23902701752327, "Episode length": 150, "Policy Loss": -1.0984982252120972, "Value Loss": 66.21868133544922, "_runtime": 1601.346130847931, "_timestamp": 1585571517.1907642, "_step": 390}
{"Episode reward": 86.92173724854683, "Episode length": 154, "Policy Loss": 0.05644860118627548, "Value Loss": 64.50611114501953, "_runtime": 1601.573899269104, "_timestamp": 1585571517.4185326, "_step": 391}
{"Episode reward": 87.5249456925779, "Episode length": 157, "Policy Loss": -0.08361157774925232, "Value Loss": 63.27326965332031, "_runtime": 1601.7070376873016, "_timestamp": 1585571517.551671, "_step": 392}
{"Episode reward": 93.42806094255026, "Episode length": 86, "Policy Loss": -1.2787775993347168, "Value Loss": 115.26634216308594, "_runtime": 1601.9251680374146, "_timestamp": 1585571517.7698014, "_step": 393}
{"Episode reward": 87.19672448217048, "Episode length": 150, "Policy Loss": -1.1340240240097046, "Value Loss": 66.21818542480469, "_runtime": 1602.134634256363, "_timestamp": 1585571517.9792676, "_step": 394}
{"Episode reward": 87.57340575437944, "Episode length": 142, "Policy Loss": -0.8817864656448364, "Value Loss": 69.933837890625, "_runtime": 1602.264802455902, "_timestamp": 1585571518.1094358, "_step": 395}
{"Episode reward": 93.25098232734456, "Episode length": 86, "Policy Loss": -1.0535401105880737, "Value Loss": 115.26506805419922, "_runtime": 1602.4813437461853, "_timestamp": 1585571518.325977, "_step": 396}
{"Episode reward": 87.45184558678625, "Episode length": 148, "Policy Loss": -1.0368232727050781, "Value Loss": 67.10761260986328, "_runtime": 1602.7068042755127, "_timestamp": 1585571518.5514376, "_step": 397}
{"Episode reward": 86.96698343509607, "Episode length": 155, "Policy Loss": -0.4969159662723541, "Value Loss": 64.08966064453125, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594, 278.9124450683594]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-286.01953125, -285.3529968261719, -284.68646240234375, -284.0198974609375, -283.3533630371094, -282.68682861328125, -282.0202941894531, -281.353759765625, -280.68719482421875, -280.0206604003906, -279.3541259765625, -278.6875915527344, -278.02105712890625, -277.3545227050781, -276.6879577636719, -276.02142333984375, -275.3548889160156, -274.6883544921875, -274.0218200683594, -273.3552551269531, -272.688720703125, -272.0221862792969, -271.35565185546875, -270.6891174316406, -270.0225830078125, -269.35601806640625, -268.6894836425781, -268.02294921875, -267.3564147949219, -266.68988037109375, -266.0233154296875, -265.3567810058594, -264.69024658203125, -264.0237121582031, -263.357177734375, -262.69061279296875, -262.0240783691406, -261.3575439453125, -260.6910095214844, -260.02447509765625, -259.35791015625, -258.6913757324219, -258.02484130859375, -257.3583068847656, -256.6917724609375, -256.0252380371094, -255.3586883544922, -254.692138671875, -254.02560424804688, -253.35906982421875, -252.69252014160156, -252.02598571777344, -251.35943603515625, -250.69290161132812, -250.0263671875, -249.35983276367188, -248.6932830810547, -248.0267333984375, -247.36019897460938, -246.69366455078125, -246.02713012695312, -245.36058044433594, -244.6940460205078, -244.02749633789062, -243.3609619140625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 5.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.97338342666626, -7.7707953453063965, -7.568207263946533, -7.36561918258667, -7.163030624389648, -6.960442543029785, -6.757854461669922, -6.555266380310059, -6.352678298950195, -6.150090217590332, -5.947502136230469, -5.7449140548706055, -5.542325973510742, -5.339737892150879, -5.137149333953857, -4.934561252593994, -4.731973171234131, -4.529385089874268, -4.326797008514404, -4.124208450317383, -3.9216208457946777, -3.7190322875976562, -3.516444206237793, -3.3138561248779297, -3.1112680435180664, -2.908679962158203, -2.70609188079834, -2.5035037994384766, -2.300915241241455, -2.098327159881592, -1.8957390785217285, -1.6931509971618652, -1.490562915802002, -1.2879748344421387, -1.0853867530822754, -0.8827986717224121, -0.6802105903625488, -0.47762203216552734, -0.27503395080566406, -0.07244586944580078, 0.1301417350769043, 0.332730770111084, 0.5353188514709473, 0.7379069328308105, 0.9404950141906738, 1.143083095550537, 1.3456711769104004, 1.5482592582702637, 1.750847339630127, 1.9534354209899902, 2.1560235023498535, 2.358611583709717, 2.56119966506958, 2.7637877464294434, 2.9663758277893066, 3.16896390914917, 3.3715529441833496, 3.574141025543213, 3.776729106903076, 3.9793171882629395, 4.181905269622803, 4.384493350982666, 4.587081432342529, 4.789669513702393, 4.992257595062256]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 5.0, 4.0, 3.0, 12.0, 3.0, 14.0, 29.0, 90.0, 216.0, 66.0, 11.0, 13.0, 9.0, 3.0, 0.0, 0.0, 5.0, 1.0, 5.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-12.569391250610352, -12.250822067260742, -11.932251930236816, -11.613682746887207, -11.295112609863281, -10.976543426513672, -10.657973289489746, -10.339404106140137, -10.020833969116211, -9.702264785766602, -9.383694648742676, -9.065125465393066, -8.74655532836914, -8.427986145019531, -8.109416961669922, -7.790846824645996, -7.4722771644592285, -7.153707504272461, -6.835137844085693, -6.516568183898926, -6.197998523712158, -5.879428863525391, -5.560859203338623, -5.2422895431518555, -4.923720359802246, -4.6051506996154785, -4.286581039428711, -3.968010902404785, -3.649441719055176, -3.33087158203125, -3.0123023986816406, -2.693732261657715, -2.3751630783081055, -2.056593894958496, -1.7380237579345703, -1.419454574584961, -1.1008844375610352, -0.7823152542114258, -0.4637451171875, -0.14517593383789062, 0.17339420318603516, 0.49196338653564453, 0.8105335235595703, 1.1291027069091797, 1.4476728439331055, 1.7662420272827148, 2.0848121643066406, 2.40338134765625, 2.7219505310058594, 3.040520668029785, 3.3590898513793945, 3.6776599884033203, 3.9962291717529297, 4.314798355102539, 4.633369445800781, 4.951938629150391, 5.2705078125, 5.589076995849609, 5.907648086547852, 6.226217269897461, 6.54478645324707, 6.86335563659668, 7.181926727294922, 7.500495910644531, 7.819065093994141]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.82163667678833, -7.548971652984619, -7.27630615234375, -7.003641128540039, -6.730976104736328, -6.458311080932617, -6.185646057128906, -5.912980556488037, -5.640315532684326, -5.367650508880615, -5.094985008239746, -4.822319984436035, -4.549654960632324, -4.276989936828613, -4.004324913024902, -3.731659412384033, -3.4589943885803223, -3.1863293647766113, -2.9136643409729004, -2.6409988403320312, -2.3683338165283203, -2.0956687927246094, -1.8230032920837402, -1.5503382682800293, -1.2776732444763184, -1.0050082206726074, -0.7323431968688965, -0.45967769622802734, -0.1870126724243164, 0.08565235137939453, 0.35831785202026367, 0.6309828758239746, 0.9036478996276855, 1.1763129234313965, 1.4489779472351074, 1.7216429710388184, 1.9943079948425293, 2.2669739723205566, 2.5396389961242676, 2.8123040199279785, 3.0849690437316895, 3.3576340675354004, 3.6302990913391113, 3.9029641151428223, 4.17563009262085, 4.4482951164245605, 4.7209601402282715, 4.993625164031982, 5.266290187835693, 5.538955211639404, 5.811620235443115, 6.084285259246826, 6.356950283050537, 6.6296162605285645, 6.902281284332275, 7.174946308135986, 7.447611331939697, 7.720276355743408, 7.992941379547119, 8.265607833862305, 8.538272857666016, 8.810937881469727, 9.083602905273438, 9.356267929077148, 9.62893295288086]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 0.0, 2.0, 5.0, 3.0, 0.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.268850326538086, -5.123995780944824, -4.9791412353515625, -4.834287166595459, -4.689432621002197, -4.5445780754089355, -4.399723529815674, -4.254868984222412, -4.110014915466309, -3.965160369873047, -3.820305824279785, -3.6754512786865234, -3.5305967330932617, -3.385742425918579, -3.2408878803253174, -3.0960335731506348, -2.951179027557373, -2.8063244819641113, -2.6614701747894287, -2.516615629196167, -2.3717613220214844, -2.2269067764282227, -2.082052230834961, -1.9371979236602783, -1.7923433780670166, -1.6474888324737549, -1.5026345252990723, -1.3577799797058105, -1.2129254341125488, -1.068070888519287, -0.9232168197631836, -0.7783622741699219, -0.6335077285766602, -0.48865318298339844, -0.3437986373901367, -0.1989445686340332, -0.054090023040771484, 0.09076452255249023, 0.23561906814575195, 0.38047361373901367, 0.5253276824951172, 0.6701822280883789, 0.8150367736816406, 0.9598913192749023, 1.104745864868164, 1.2496004104614258, 1.3944544792175293, 1.539309024810791, 1.6841635704040527, 1.8290181159973145, 1.9738726615905762, 2.1187267303466797, 2.2635812759399414, 2.408435821533203, 2.553290367126465, 2.6981449127197266, 2.8429994583129883, 2.98785400390625, 3.1327085494995117, 3.277562141418457, 3.4224166870117188, 3.5672712326049805, 3.712125778198242, 3.856980323791504, 4.001834869384766]}, "_runtime": 1602.9161484241486, "_timestamp": 1585571518.7607818, "_step": 398}
{"Episode reward": 88.03869997652659, "Episode length": 145, "Policy Loss": -0.6517277956008911, "Value Loss": 68.4869384765625, "_runtime": 1603.1388161182404, "_timestamp": 1585571518.9834495, "_step": 399}
{"Episode reward": 86.41870481412013, "Episode length": 152, "Policy Loss": -1.1775890588760376, "Value Loss": 65.35372161865234, "_runtime": 1603.274335861206, "_timestamp": 1585571519.1189692, "_step": 400}
{"Episode reward": 93.20757067565175, "Episode length": 87, "Policy Loss": -1.0426889657974243, "Value Loss": 114.05577850341797, "_runtime": 1603.4836840629578, "_timestamp": 1585571519.3283174, "_step": 401}
{"Episode reward": 87.9893014328612, "Episode length": 144, "Policy Loss": -1.1712746620178223, "Value Loss": 68.96061706542969, "_runtime": 1603.6967208385468, "_timestamp": 1585571519.5413542, "_step": 402}
{"Episode reward": 88.1213544360505, "Episode length": 145, "Policy Loss": -0.2315092384815216, "Value Loss": 68.48539733886719, "_runtime": 1603.9087908267975, "_timestamp": 1585571519.7534242, "_step": 403}
{"Episode reward": 88.58202395948925, "Episode length": 147, "Policy Loss": -1.0615439414978027, "Value Loss": 67.55293273925781, "_runtime": 1604.1613774299622, "_timestamp": 1585571520.0060108, "_step": 404}
{"Episode reward": 87.6523477394089, "Episode length": 147, "Policy Loss": 0.3131127655506134, "Value Loss": 67.5595474243164, "_runtime": 1604.3945989608765, "_timestamp": 1585571520.2392323, "_step": 405}
{"Episode reward": 86.63016650251362, "Episode length": 157, "Policy Loss": -1.0727266073226929, "Value Loss": 63.27706527709961, "_runtime": 1604.6348142623901, "_timestamp": 1585571520.4794476, "_step": 406}
{"Episode reward": 85.76019817870046, "Episode length": 166, "Policy Loss": -1.0314222574234009, "Value Loss": 59.86372375488281, "_runtime": 1604.8544805049896, "_timestamp": 1585571520.6991138, "_step": 407}
{"Episode reward": 87.36875785027938, "Episode length": 150, "Policy Loss": -1.1344285011291504, "Value Loss": 66.214111328125, "_runtime": 1605.075189590454, "_timestamp": 1585571520.919823, "_step": 408}
{"Episode reward": 87.18417088747819, "Episode length": 151, "Policy Loss": -1.1790622472763062, "Value Loss": 65.77822875976562, "_runtime": 1605.2017722129822, "_timestamp": 1585571521.0464056, "_step": 409}
{"Episode reward": 93.4607948404514, "Episode length": 81, "Policy Loss": -1.1852985620498657, "Value Loss": 122.34854888916016, "_runtime": 1605.4129021167755, "_timestamp": 1585571521.2575355, "_step": 410}
{"Episode reward": 87.66880853633432, "Episode length": 144, "Policy Loss": -0.649425745010376, "Value Loss": 68.96109771728516, "_runtime": 1605.6399455070496, "_timestamp": 1585571521.4845788, "_step": 411}
{"Episode reward": 87.81828941456801, "Episode length": 155, "Policy Loss": -1.1170365810394287, "Value Loss": 64.08171081542969, "_runtime": 1605.8526754379272, "_timestamp": 1585571521.6973088, "_step": 412}
{"Episode reward": 87.59595264577338, "Episode length": 148, "Policy Loss": 0.8286964297294617, "Value Loss": 67.103515625, "_runtime": 1606.0653717517853, "_timestamp": 1585571521.910005, "_step": 413}
{"Episode reward": 87.72339089189633, "Episode length": 146, "Policy Loss": -1.0973737239837646, "Value Loss": 68.01847076416016, "_runtime": 1606.2932693958282, "_timestamp": 1585571522.1379027, "_step": 414}
{"Episode reward": 87.06624392575668, "Episode length": 156, "Policy Loss": -0.9797387719154358, "Value Loss": 63.67716979980469, "_runtime": 1606.5029695034027, "_timestamp": 1585571522.3476028, "_step": 415}
{"Episode reward": 88.53489043985263, "Episode length": 144, "Policy Loss": -0.16369791328907013, "Value Loss": 68.95365142822266, "_runtime": 1606.7158920764923, "_timestamp": 1585571522.5605254, "_step": 416}
{"Episode reward": 88.29032138751904, "Episode length": 146, "Policy Loss": -0.5035427808761597, "Value Loss": 68.01380920410156, "_runtime": 1606.9355108737946, "_timestamp": 1585571522.7801442, "_step": 417}
{"Episode reward": 87.18894033518139, "Episode length": 150, "Policy Loss": -1.1767488718032837, "Value Loss": 66.2138900756836, "_runtime": 1607.1604280471802, "_timestamp": 1585571523.0050614, "_step": 418}
{"Episode reward": 87.21393722114689, "Episode length": 155, "Policy Loss": -1.0218786001205444, "Value Loss": 64.08502197265625, "_runtime": 1607.367736339569, "_timestamp": 1585571523.2123697, "_step": 419}
{"Episode reward": 88.16588835449016, "Episode length": 142, "Policy Loss": -1.0214598178863525, "Value Loss": 69.92378997802734, "_runtime": 1607.5806510448456, "_timestamp": 1585571523.4252844, "_step": 420}
{"Episode reward": 87.87050448125646, "Episode length": 146, "Policy Loss": -0.9815016388893127, "Value Loss": 68.0163803100586, "_runtime": 1607.7162063121796, "_timestamp": 1585571523.5608397, "_step": 421}
{"Episode reward": 92.7961083012733, "Episode length": 88, "Policy Loss": -1.1657637357711792, "Value Loss": 112.8291015625, "_runtime": 1607.8359067440033, "_timestamp": 1585571523.68054, "_step": 422}
{"Episode reward": 93.78012796320998, "Episode length": 77, "Policy Loss": -1.1807996034622192, "Value Loss": 128.67575073242188, "_runtime": 1608.0483841896057, "_timestamp": 1585571523.8930175, "_step": 423}
{"Episode reward": 88.22506156533477, "Episode length": 145, "Policy Loss": -0.058516837656497955, "Value Loss": 68.48072052001953, "_runtime": 1608.258831501007, "_timestamp": 1585571524.1034648, "_step": 424}
{"Episode reward": 88.16300809905962, "Episode length": 145, "Policy Loss": -1.113792061805725, "Value Loss": 68.48084259033203, "_runtime": 1608.3773965835571, "_timestamp": 1585571524.22203, "_step": 425}
{"Episode reward": 93.94148862371375, "Episode length": 79, "Policy Loss": -0.5519607067108154, "Value Loss": 125.41814422607422, "_runtime": 1608.5997867584229, "_timestamp": 1585571524.44442, "_step": 426}
{"Episode reward": 87.04117116505016, "Episode length": 153, "Policy Loss": -1.094802975654602, "Value Loss": 64.92008209228516, "_runtime": 1608.8191711902618, "_timestamp": 1585571524.6638045, "_step": 427}
{"Episode reward": 87.33820430575071, "Episode length": 150, "Policy Loss": -0.5903472900390625, "Value Loss": 66.2114486694336, "_runtime": 1608.9461936950684, "_timestamp": 1585571524.790827, "_step": 428}
{"Episode reward": 93.46817847438288, "Episode length": 85, "Policy Loss": -1.1914430856704712, "Value Loss": 116.5840072631836, "_runtime": 1609.1855056285858, "_timestamp": 1585571525.030139, "_step": 429}
{"Episode reward": 86.5325452592297, "Episode length": 156, "Policy Loss": -1.1439058780670166, "Value Loss": 63.67921829223633, "_runtime": 1609.3186237812042, "_timestamp": 1585571525.1632571, "_step": 430}
{"Episode reward": 93.79103809750899, "Episode length": 86, "Policy Loss": -1.0294857025146484, "Value Loss": 115.29293823242188, "_runtime": 1609.5313584804535, "_timestamp": 1585571525.3759918, "_step": 431}
{"Episode reward": 88.08791504932084, "Episode length": 148, "Policy Loss": -1.0056792497634888, "Value Loss": 67.09663391113281, "_runtime": 1609.6575829982758, "_timestamp": 1585571525.5022163, "_step": 432}
{"Episode reward": 93.4754333037687, "Episode length": 82, "Policy Loss": -1.3648053407669067, "Value Loss": 120.90259552001953, "_runtime": 1609.7770597934723, "_timestamp": 1585571525.6216931, "_step": 433}
{"Episode reward": 93.84168143117091, "Episode length": 79, "Policy Loss": -0.9221973419189453, "Value Loss": 125.4883804321289, "_runtime": 1609.898901462555, "_timestamp": 1585571525.7435348, "_step": 434}
{"Episode reward": 93.75231732103867, "Episode length": 78, "Policy Loss": -1.239711880683899, "Value Loss": 127.01236724853516, "_runtime": 1610.109218597412, "_timestamp": 1585571525.953852, "_step": 435}
{"Episode reward": 88.11832363272514, "Episode length": 146, "Policy Loss": -1.1159900426864624, "Value Loss": 68.01116180419922, "_runtime": 1610.330738544464, "_timestamp": 1585571526.175372, "_step": 436}
{"Episode reward": 86.64111979257393, "Episode length": 154, "Policy Loss": -1.1601340770721436, "Value Loss": 64.50126647949219, "_runtime": 1610.5463259220123, "_timestamp": 1585571526.3909593, "_step": 437}
{"Episode reward": 87.10504082680887, "Episode length": 151, "Policy Loss": -1.2802122831344604, "Value Loss": 65.77417755126953, "_runtime": 1610.7551164627075, "_timestamp": 1585571526.5997498, "_step": 438}
{"Episode reward": 87.63046958579761, "Episode length": 142, "Policy Loss": -1.2518150806427002, "Value Loss": 69.92305755615234, "_runtime": 1610.9766957759857, "_timestamp": 1585571526.821329, "_step": 439}
{"Episode reward": 86.88469977305333, "Episode length": 152, "Policy Loss": 0.06022057309746742, "Value Loss": 65.3444595336914, "_runtime": 1611.1961653232574, "_timestamp": 1585571527.0407987, "_step": 440}
{"Episode reward": 87.68578371871399, "Episode length": 150, "Policy Loss": -1.1316866874694824, "Value Loss": 66.20624542236328, "_runtime": 1611.4182069301605, "_timestamp": 1585571527.2628403, "_step": 441}
{"Episode reward": 88.57787747975225, "Episode length": 152, "Policy Loss": -0.5130065083503723, "Value Loss": 65.33157348632812, "_runtime": 1611.6359050273895, "_timestamp": 1585571527.4805384, "_step": 442}
{"Episode reward": 87.95545959933074, "Episode length": 149, "Policy Loss": -1.1834255456924438, "Value Loss": 66.64655303955078, "_runtime": 1611.8519849777222, "_timestamp": 1585571527.6966183, "_step": 443}
{"Episode reward": 87.9078001081805, "Episode length": 148, "Policy Loss": -1.0511294603347778, "Value Loss": 67.09539794921875, "_runtime": 1612.0700051784515, "_timestamp": 1585571527.9146385, "_step": 444}
{"Episode reward": 87.67139568273363, "Episode length": 149, "Policy Loss": -0.7415711283683777, "Value Loss": 66.64856719970703, "_runtime": 1612.2889230251312, "_timestamp": 1585571528.1335564, "_step": 445}
{"Episode reward": 87.39982071498164, "Episode length": 149, "Policy Loss": -1.1149988174438477, "Value Loss": 66.65034484863281, "_runtime": 1612.5094141960144, "_timestamp": 1585571528.3540475, "_step": 446}
{"Episode reward": 87.29706523294054, "Episode length": 151, "Policy Loss": -1.224586009979248, "Value Loss": 65.7716293334961, "_runtime": 1612.6496546268463, "_timestamp": 1585571528.494288, "_step": 447}
{"Episode reward": 92.96648399760818, "Episode length": 92, "Policy Loss": -1.1893290281295776, "Value Loss": 107.7877426147461, "_runtime": 1612.784600019455, "_timestamp": 1585571528.6292334, "_step": 448}
{"Episode reward": 93.24851730821314, "Episode length": 88, "Policy Loss": -0.9008806347846985, "Value Loss": 112.66142272949219, "_runtime": 1613.0011312961578, "_timestamp": 1585571528.8457646, "_step": 449}
{"Episode reward": 87.63047134985793, "Episode length": 148, "Policy Loss": -0.8878110647201538, "Value Loss": 67.09674072265625, "_runtime": 1613.1266610622406, "_timestamp": 1585571528.9712944, "_step": 450}
{"Episode reward": 93.37877474282764, "Episode length": 83, "Policy Loss": -1.2234001159667969, "Value Loss": 119.36175537109375, "_runtime": 1613.338668346405, "_timestamp": 1585571529.1833017, "_step": 451}
{"Episode reward": 87.64888087903238, "Episode length": 147, "Policy Loss": -0.880653440952301, "Value Loss": 67.5509262084961, "_runtime": 1613.4735269546509, "_timestamp": 1585571529.3181603, "_step": 452}
{"Episode reward": 93.3688126727167, "Episode length": 88, "Policy Loss": -0.1763426512479782, "Value Loss": 112.71549987792969, "_runtime": 1613.6962115764618, "_timestamp": 1585571529.540845, "_step": 453}
{"Episode reward": 87.13477386141365, "Episode length": 155, "Policy Loss": -0.8651275634765625, "Value Loss": 64.08138275146484, "_runtime": 1613.931164741516, "_timestamp": 1585571529.775798, "_step": 454}
{"Episode reward": 87.1282508832787, "Episode length": 162, "Policy Loss": -0.07934648543596268, "Value Loss": 61.32367706298828, "_runtime": 1614.1401221752167, "_timestamp": 1585571529.9847555, "_step": 455}
{"Episode reward": 87.93431988386774, "Episode length": 145, "Policy Loss": -1.1732797622680664, "Value Loss": 68.47607421875, "_runtime": 1614.3697638511658, "_timestamp": 1585571530.2143972, "_step": 456}
{"Episode reward": 86.84387085032265, "Episode length": 156, "Policy Loss": -1.1000887155532837, "Value Loss": 63.674198150634766, "_runtime": 1614.5906646251678, "_timestamp": 1585571530.435298, "_step": 457}
{"Episode reward": 87.07790659783237, "Episode length": 151, "Policy Loss": -1.1208195686340332, "Value Loss": 65.77205657958984, "_runtime": 1614.8134841918945, "_timestamp": 1585571530.6581175, "_step": 458}
{"Episode reward": 86.43015853530163, "Episode length": 154, "Policy Loss": -1.2489967346191406, "Value Loss": 64.50067901611328, "_runtime": 1615.034351348877, "_timestamp": 1585571530.8789847, "_step": 459}
{"Episode reward": 87.0196199718491, "Episode length": 151, "Policy Loss": -1.1901832818984985, "Value Loss": 65.77238464355469, "_runtime": 1615.159377336502, "_timestamp": 1585571531.0040107, "_step": 460}
{"Episode reward": 93.87200851981063, "Episode length": 80, "Policy Loss": -1.4165974855422974, "Value Loss": 123.81014251708984, "_runtime": 1615.3681943416595, "_timestamp": 1585571531.2128277, "_step": 461}
{"Episode reward": 88.3511379198654, "Episode length": 143, "Policy Loss": -1.125475525856018, "Value Loss": 69.42597198486328, "_runtime": 1615.586198091507, "_timestamp": 1585571531.4308314, "_step": 462}
{"Episode reward": 88.24300980907243, "Episode length": 149, "Policy Loss": -1.2070231437683105, "Value Loss": 66.64179229736328, "_runtime": 1615.709043264389, "_timestamp": 1585571531.5536766, "_step": 463}
{"Episode reward": 93.65438683491509, "Episode length": 82, "Policy Loss": 0.7620522379875183, "Value Loss": 120.79696655273438, "_runtime": 1615.9189603328705, "_timestamp": 1585571531.7635937, "_step": 464}
{"Episode reward": 88.58744003699367, "Episode length": 143, "Policy Loss": -1.2805492877960205, "Value Loss": 69.42362213134766, "_runtime": 1616.1516580581665, "_timestamp": 1585571531.9962914, "_step": 465}
{"Episode reward": 86.4075068730101, "Episode length": 161, "Policy Loss": 0.0210898295044899, "Value Loss": 61.70784378051758, "_runtime": 1616.3732314109802, "_timestamp": 1585571532.2178648, "_step": 466}
{"Episode reward": 87.3913965583854, "Episode length": 154, "Policy Loss": 0.3740823566913605, "Value Loss": 64.49288177490234, "_runtime": 1616.596759557724, "_timestamp": 1585571532.441393, "_step": 467}
{"Episode reward": 86.743428211739, "Episode length": 154, "Policy Loss": -1.1864392757415771, "Value Loss": 64.497802734375, "_runtime": 1616.842623949051, "_timestamp": 1585571532.6872573, "_step": 468}
{"Episode reward": 85.18537990895241, "Episode length": 169, "Policy Loss": -1.099151849746704, "Value Loss": 58.80795669555664, "_runtime": 1617.0553395748138, "_timestamp": 1585571532.899973, "_step": 469}
{"Episode reward": 87.59917226863104, "Episode length": 146, "Policy Loss": -1.3139952421188354, "Value Loss": 68.01004028320312, "_runtime": 1617.2776968479156, "_timestamp": 1585571533.1223302, "_step": 470}
{"Episode reward": 87.68829413756279, "Episode length": 153, "Policy Loss": -0.7433813810348511, "Value Loss": 64.91011047363281, "_runtime": 1617.4938979148865, "_timestamp": 1585571533.3385313, "_step": 471}
{"Episode reward": 88.67293423583156, "Episode length": 147, "Policy Loss": -1.1901558637619019, "Value Loss": 67.54042053222656, "_runtime": 1617.7309908866882, "_timestamp": 1585571533.5756242, "_step": 472}
{"Episode reward": 86.38605034726652, "Episode length": 164, "Policy Loss": -1.0855592489242554, "Value Loss": 60.58403778076172, "_runtime": 1617.9548773765564, "_timestamp": 1585571533.7995107, "_step": 473}
{"Episode reward": 87.14623813240752, "Episode length": 153, "Policy Loss": -0.4799160361289978, "Value Loss": 64.91423797607422, "_runtime": 1618.1763746738434, "_timestamp": 1585571534.021008, "_step": 474}
{"Episode reward": 87.69845074968383, "Episode length": 151, "Policy Loss": -1.0527507066726685, "Value Loss": 65.76606750488281, "_runtime": 1618.3988056182861, "_timestamp": 1585571534.243439, "_step": 475}
{"Episode reward": 87.24936347507973, "Episode length": 152, "Policy Loss": -1.241316795349121, "Value Loss": 65.4288330078125, "_runtime": 1618.626326084137, "_timestamp": 1585571534.4709594, "_step": 476}
{"Episode reward": 87.32795314153738, "Episode length": 156, "Policy Loss": 1.2718144655227661, "Value Loss": 63.6696662902832, "_runtime": 1618.7513744831085, "_timestamp": 1585571534.5960078, "_step": 477}
{"Episode reward": 94.01648465564702, "Episode length": 80, "Policy Loss": -1.3090269565582275, "Value Loss": 123.79463195800781, "_runtime": 1618.9853246212006, "_timestamp": 1585571534.829958, "_step": 478}
{"Episode reward": 86.27776209463538, "Episode length": 161, "Policy Loss": -1.1479084491729736, "Value Loss": 61.70854949951172, "_runtime": 1619.1998035907745, "_timestamp": 1585571535.044437, "_step": 479}
{"Episode reward": 88.66967426126854, "Episode length": 146, "Policy Loss": -1.22685968875885, "Value Loss": 68.00069427490234, "_runtime": 1619.4107077121735, "_timestamp": 1585571535.255341, "_step": 480}
{"Episode reward": 87.65876574393106, "Episode length": 147, "Policy Loss": -1.3652632236480713, "Value Loss": 67.54803466796875, "_runtime": 1619.5393018722534, "_timestamp": 1585571535.3839352, "_step": 481}
{"Episode reward": 93.89444484415766, "Episode length": 82, "Policy Loss": -1.287766456604004, "Value Loss": 120.7811279296875, "_runtime": 1619.7535543441772, "_timestamp": 1585571535.5981877, "_step": 482}
{"Episode reward": 88.11718394756484, "Episode length": 146, "Policy Loss": -0.9297449588775635, "Value Loss": 68.00476837158203, "_runtime": 1619.8893082141876, "_timestamp": 1585571535.7339416, "_step": 483}
{"Episode reward": 93.44681945070222, "Episode length": 88, "Policy Loss": -1.1021803617477417, "Value Loss": 112.569580078125, "_runtime": 1620.0943710803986, "_timestamp": 1585571535.9390044, "_step": 484}
{"Episode reward": 88.18769004914446, "Episode length": 143, "Policy Loss": -1.318798303604126, "Value Loss": 69.42479705810547, "_runtime": 1620.305861234665, "_timestamp": 1585571536.1504946, "_step": 485}
{"Episode reward": 87.66736444981936, "Episode length": 144, "Policy Loss": -1.0688252449035645, "Value Loss": 68.94880676269531, "_runtime": 1620.5204787254333, "_timestamp": 1585571536.365112, "_step": 486}
{"Episode reward": 88.3803587594652, "Episode length": 149, "Policy Loss": -1.1382607221603394, "Value Loss": 66.63890075683594, "_runtime": 1620.7312641143799, "_timestamp": 1585571536.5758975, "_step": 487}
{"Episode reward": 88.61609350747716, "Episode length": 144, "Policy Loss": -0.911360502243042, "Value Loss": 68.94085693359375, "_runtime": 1620.9436728954315, "_timestamp": 1585571536.7883062, "_step": 488}
{"Episode reward": 89.00992317463488, "Episode length": 145, "Policy Loss": -1.2954936027526855, "Value Loss": 68.46395111083984, "_runtime": 1621.067259311676, "_timestamp": 1585571536.9118927, "_step": 489}
{"Episode reward": 93.81456888410484, "Episode length": 79, "Policy Loss": -1.458282709121704, "Value Loss": 125.35130310058594, "_runtime": 1621.1960501670837, "_timestamp": 1585571537.0406835, "_step": 490}
{"Episode reward": 93.6336826766171, "Episode length": 84, "Policy Loss": -0.6810709834098816, "Value Loss": 117.90843200683594, "_runtime": 1621.3175473213196, "_timestamp": 1585571537.1621807, "_step": 491}
{"Episode reward": 94.45755388061337, "Episode length": 78, "Policy Loss": -0.5330753326416016, "Value Loss": 127.1044921875, "_runtime": 1621.5302274227142, "_timestamp": 1585571537.3748608, "_step": 492}
{"Episode reward": 87.49729971464657, "Episode length": 148, "Policy Loss": -0.6748448014259338, "Value Loss": 67.09375762939453, "_runtime": 1621.6477117538452, "_timestamp": 1585571537.492345, "_step": 493}
{"Episode reward": 94.03406549766468, "Episode length": 78, "Policy Loss": 0.46377068758010864, "Value Loss": 126.94622802734375, "_runtime": 1621.850774049759, "_timestamp": 1585571537.6954074, "_step": 494}
{"Episode reward": 89.3282470123409, "Episode length": 141, "Policy Loss": -0.23849216103553772, "Value Loss": 70.39444732666016, "_runtime": 1622.0656037330627, "_timestamp": 1585571537.910237, "_step": 495}
{"Episode reward": 88.10948873417519, "Episode length": 147, "Policy Loss": -1.325659155845642, "Value Loss": 67.54287719726562, "_runtime": 1622.2682230472565, "_timestamp": 1585571538.1128564, "_step": 496}
{"Episode reward": 88.47303842301075, "Episode length": 141, "Policy Loss": -1.3470512628555298, "Value Loss": 70.4012680053711, "_runtime": 1622.3943464756012, "_timestamp": 1585571538.2389798, "_step": 497}
{"Episode reward": 93.50422742845095, "Episode length": 82, "Policy Loss": -0.8958020806312561, "Value Loss": 120.93495178222656, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438, 248.67440795898438]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-249.98617553710938, -249.7410125732422, -249.495849609375, -249.2506866455078, -249.00552368164062, -248.76036071777344, -248.51519775390625, -248.27003479003906, -248.02487182617188, -247.7797088623047, -247.5345458984375, -247.28939819335938, -247.0442352294922, -246.799072265625, -246.5539093017578, -246.30874633789062, -246.06358337402344, -245.81842041015625, -245.57325744628906, -245.32809448242188, -245.0829315185547, -244.8377685546875, -244.5926055908203, -244.34744262695312, -244.10227966308594, -243.85711669921875, -243.61195373535156, -243.36679077148438, -243.1216278076172, -242.87646484375, -242.6313018798828, -242.38613891601562, -242.1409912109375, -241.8958282470703, -241.65066528320312, -241.40550231933594, -241.16033935546875, -240.91517639160156, -240.67001342773438, -240.4248504638672, -240.1796875, -239.9345245361328, -239.68936157226562, -239.44419860839844, -239.19903564453125, -238.95387268066406, -238.70870971679688, -238.4635467529297, -238.2183837890625, -237.9732208251953, -237.72805786132812, -237.48289489746094, -237.23773193359375, -236.99258422851562, -236.74740600585938, -236.50225830078125, -236.25709533691406, -236.01193237304688, -235.7667694091797, -235.5216064453125, -235.2764434814453, -235.03128051757812, -234.78611755371094, -234.54095458984375, -234.29579162597656]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1468117237091064, -2.0531294345855713, -1.9594472646713257, -1.86576509475708, -1.772082805633545, -1.6784006357192993, -1.5847184658050537, -1.4910361766815186, -1.3973538875579834, -1.3036717176437378, -1.2099895477294922, -1.116307258605957, -1.0226250886917114, -0.9289427995681763, -0.8352606296539307, -0.7415783405303955, -0.6478961706161499, -0.5542140007019043, -0.46053171157836914, -0.36684954166412354, -0.2731672525405884, -0.17948508262634277, -0.08580279350280762, 0.007879495620727539, 0.1015615463256836, 0.19524383544921875, 0.2889261245727539, 0.38260817527770996, 0.4762904644012451, 0.5699727535247803, 0.6636550426483154, 0.7573370933532715, 0.8510193824768066, 0.9447016716003418, 1.0383837223052979, 1.132066011428833, 1.2257483005523682, 1.3194305896759033, 1.4131126403808594, 1.5067949295043945, 1.6004772186279297, 1.6941592693328857, 1.787841558456421, 1.881523847579956, 1.9752061367034912, 2.0688884258270264, 2.1625707149505615, 2.2562525272369385, 2.3499348163604736, 2.443617105484009, 2.537299394607544, 2.630981683731079, 2.7246639728546143, 2.8183462619781494, 2.9120280742645264, 3.0057103633880615, 3.0993926525115967, 3.193074941635132, 3.286757230758667, 3.380439519882202, 3.4741218090057373, 3.5678036212921143, 3.6614859104156494, 3.7551681995391846, 3.8488504886627197]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0, 6.0, 1.0, 2.0, 3.0, 5.0, 6.0, 5.0, 5.0, 19.0, 45.0, 220.0, 83.0, 33.0, 10.0, 12.0, 7.0, 8.0, 3.0, 6.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-3.0020148754119873, -2.8700904846191406, -2.738166093826294, -2.6062417030334473, -2.4743175506591797, -2.342393159866333, -2.2104687690734863, -2.0785443782806396, -1.9466201066970825, -1.8146957159042358, -1.6827714443206787, -1.550847053527832, -1.4189226627349854, -1.2869983911514282, -1.1550740003585815, -1.0231497287750244, -0.8912253379821777, -0.759300947189331, -0.6273765563964844, -0.4954524040222168, -0.3635280132293701, -0.23160362243652344, -0.09967923164367676, 0.03224515914916992, 0.1641695499420166, 0.2960937023162842, 0.42801809310913086, 0.5599424839019775, 0.6918668746948242, 0.8237912654876709, 0.9557154178619385, 1.0876400470733643, 1.2195641994476318, 1.3514883518218994, 1.4834129810333252, 1.6153371334075928, 1.7472617626190186, 1.8791859149932861, 2.0111100673675537, 2.1430346965789795, 2.274958848953247, 2.406883478164673, 2.5388076305389404, 2.670731782913208, 2.802656412124634, 2.9345805644989014, 3.066505193710327, 3.1984293460845947, 3.3303539752960205, 3.462278127670288, 3.5942022800445557, 3.7261269092559814, 3.858051061630249, 3.989975690841675, 4.121899604797363, 4.253824234008789, 4.385748863220215, 4.517672538757324, 4.64959716796875, 4.781521797180176, 4.913445472717285, 5.045370101928711, 5.177294731140137, 5.309218406677246, 5.441143035888672]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.6382694244384766, -1.569748044013977, -1.5012266635894775, -1.432705283164978, -1.3641839027404785, -1.2956624031066895, -1.22714102268219, -1.1586196422576904, -1.090098261833191, -1.0215768814086914, -0.9530555009841919, -0.8845340609550476, -0.8160126805305481, -0.7474913001060486, -0.6789698600769043, -0.6104484796524048, -0.5419270992279053, -0.47340571880340576, -0.40488433837890625, -0.33636295795440674, -0.2678415775299072, -0.19932007789611816, -0.13079869747161865, -0.06227731704711914, 0.006244063377380371, 0.07476544380187988, 0.1432868242263794, 0.2118082046508789, 0.28032970428466797, 0.3488510847091675, 0.417372465133667, 0.48589372634887695, 0.554415225982666, 0.6229367256164551, 0.691457986831665, 0.7599794864654541, 0.8285007476806641, 0.8970222473144531, 0.9655435085296631, 1.0340650081634521, 1.102586269378662, 1.1711077690124512, 1.2396292686462402, 1.3081505298614502, 1.3766720294952393, 1.4451932907104492, 1.5137147903442383, 1.5822360515594482, 1.6507575511932373, 1.7192790508270264, 1.7878003120422363, 1.8563218116760254, 1.9248430728912354, 1.9933645725250244, 2.0618858337402344, 2.1304073333740234, 2.1989288330078125, 2.2674500942230225, 2.3359715938568115, 2.4044928550720215, 2.4730143547058105, 2.5415358543395996, 2.6100568771362305, 2.6785783767700195, 2.7470998764038086]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.4437446892261505, -0.43110305070877075, -0.418461412191391, -0.40581977367401123, -0.3931781053543091, -0.3805364668369293, -0.36789482831954956, -0.3552531898021698, -0.34261155128479004, -0.3299698829650879, -0.31732824444770813, -0.30468660593032837, -0.2920449674129486, -0.27940332889556885, -0.2667616605758667, -0.25412002205848694, -0.24147838354110718, -0.22883674502372742, -0.21619509160518646, -0.2035534530878067, -0.19091179966926575, -0.178270161151886, -0.16562852263450623, -0.15298688411712646, -0.1403452455997467, -0.12770357728004456, -0.1150619387626648, -0.10242030024528503, -0.08977866172790527, -0.07713702321052551, -0.06449535489082336, -0.051853716373443604, -0.03921207785606384, -0.026570439338684082, -0.013928800821304321, -0.0012871325016021729, 0.011354506015777588, 0.02399614453315735, 0.03663778305053711, 0.04927942156791687, 0.06192108988761902, 0.07456269860267639, 0.08720436692237854, 0.09984603524208069, 0.11248764395713806, 0.1251293122768402, 0.13777092099189758, 0.15041258931159973, 0.1630541980266571, 0.17569586634635925, 0.1883375346660614, 0.20097914338111877, 0.21362081170082092, 0.2262624204158783, 0.23890408873558044, 0.2515457570552826, 0.26418736577033997, 0.2768290340900421, 0.2894706428050995, 0.30211231112480164, 0.3147539794445038, 0.32739558815956116, 0.3400372564792633, 0.3526788651943207, 0.3653205335140228]}, "_runtime": 1622.51908826828, "_timestamp": 1585571538.3637216, "_step": 498}
{"Episode reward": 93.55480082838565, "Episode length": 80, "Policy Loss": -0.8560513257980347, "Value Loss": 123.78031158447266, "_runtime": 1622.51908826828, "_timestamp": 1585571538.3637216, "_step": 499}
