{"Episode reward": -63.189908962104624, "Episode length": 999, "Policy Loss": -0.08928866684436798, "Value Loss": 0.044657979160547256, "_runtime": 5047.465139389038, "_timestamp": 1585602417.0980089, "_step": 0}
{"Episode reward": -94.40634093402937, "Episode length": 999, "Policy Loss": -0.3295404613018036, "Value Loss": 0.5248060822486877, "_runtime": 5048.952974319458, "_timestamp": 1585602418.5858438, "_step": 1}
{"Episode reward": -97.54587768024905, "Episode length": 999, "Policy Loss": -0.45254406332969666, "Value Loss": 0.018275927752256393, "_runtime": 5049.841722011566, "_timestamp": 1585602419.4745915, "_step": 2}
{"Episode reward": 44.79158411475823, "Episode length": 566, "Policy Loss": 0.60294109582901, "Value Loss": 18.306594848632812, "_runtime": 5051.371995210648, "_timestamp": 1585602421.0048647, "_step": 3}
{"Episode reward": -99.24850774545784, "Episode length": 999, "Policy Loss": -0.4603300988674164, "Value Loss": 0.11360591650009155, "_runtime": 5051.959773778915, "_timestamp": 1585602421.5926433, "_step": 4}
{"Episode reward": 63.709418648388, "Episode length": 364, "Policy Loss": 1.561314344406128, "Value Loss": 26.87245750427246, "_runtime": 5053.455552101135, "_timestamp": 1585602423.0884216, "_step": 5}
{"Episode reward": -99.28016173332442, "Episode length": 999, "Policy Loss": -0.7392722368240356, "Value Loss": 1.4450514316558838, "_runtime": 5055.013980388641, "_timestamp": 1585602424.6468499, "_step": 6}
{"Episode reward": -99.70110963415797, "Episode length": 999, "Policy Loss": -0.5699318051338196, "Value Loss": 0.01796010695397854, "_runtime": 5056.507429599762, "_timestamp": 1585602426.140299, "_step": 7}
{"Episode reward": -99.64983705650526, "Episode length": 999, "Policy Loss": -0.6016514301300049, "Value Loss": 0.04313875734806061, "_runtime": 5058.047559022903, "_timestamp": 1585602427.6804285, "_step": 8}
{"Episode reward": -99.75010463879887, "Episode length": 999, "Policy Loss": -0.6187889575958252, "Value Loss": 0.0377066396176815, "_runtime": 5059.605576992035, "_timestamp": 1585602429.2384465, "_step": 9}
{"Episode reward": -99.79109411325632, "Episode length": 999, "Policy Loss": -0.5289517045021057, "Value Loss": 0.21693776547908783, "_runtime": 5061.140149593353, "_timestamp": 1585602430.773019, "_step": 10}
{"Episode reward": -99.58642376551732, "Episode length": 999, "Policy Loss": -0.5967918038368225, "Value Loss": 0.011533092707395554, "_runtime": 5062.70431303978, "_timestamp": 1585602432.3371825, "_step": 11}
{"Episode reward": 0.29945231473263334, "Episode length": 999, "Policy Loss": 0.04315342381596565, "Value Loss": 10.058802604675293, "_runtime": 5064.283438444138, "_timestamp": 1585602433.916308, "_step": 12}
{"Episode reward": -99.75728744623092, "Episode length": 999, "Policy Loss": -0.9104739427566528, "Value Loss": 0.44775551557540894, "_runtime": 5065.878853321075, "_timestamp": 1585602435.5117228, "_step": 13}
{"Episode reward": -99.66388724206924, "Episode length": 999, "Policy Loss": -0.5881375074386597, "Value Loss": 0.164169579744339, "_runtime": 5066.804687976837, "_timestamp": 1585602436.4375575, "_step": 14}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 0.6061533689498901, "Value Loss": 17.27755355834961, "_runtime": 5068.381288051605, "_timestamp": 1585602438.0141575, "_step": 15}
{"Episode reward": -99.80019097924092, "Episode length": 999, "Policy Loss": -0.5248390436172485, "Value Loss": 0.01774785853922367, "_runtime": 5069.942763328552, "_timestamp": 1585602439.5756328, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5137982368469238, "Value Loss": 0.06781080365180969, "_runtime": 5071.4704422950745, "_timestamp": 1585602441.1033118, "_step": 17}
{"Episode reward": -99.74434014141886, "Episode length": 999, "Policy Loss": -0.5236210227012634, "Value Loss": 0.011612070724368095, "_runtime": 5073.0403525829315, "_timestamp": 1585602442.673222, "_step": 18}
{"Episode reward": -99.80202592946449, "Episode length": 999, "Policy Loss": -0.5108655095100403, "Value Loss": 0.03965110331773758, "_runtime": 5074.603876590729, "_timestamp": 1585602444.236746, "_step": 19}
{"Episode reward": -99.72962931983498, "Episode length": 999, "Policy Loss": -0.49991336464881897, "Value Loss": 0.01848948933184147, "_runtime": 5076.162230730057, "_timestamp": 1585602445.7951002, "_step": 20}
{"Episode reward": -99.88111704664631, "Episode length": 999, "Policy Loss": -0.4939271807670593, "Value Loss": 0.007201426196843386, "_runtime": 5076.77800822258, "_timestamp": 1585602446.4108777, "_step": 21}
{"Episode reward": 62.30397579036627, "Episode length": 377, "Policy Loss": 1.3078550100326538, "Value Loss": 26.49741554260254, "_runtime": 5078.324780702591, "_timestamp": 1585602447.9576502, "_step": 22}
{"Episode reward": -99.76982639611093, "Episode length": 999, "Policy Loss": -0.4757770299911499, "Value Loss": 0.00551562150940299, "_runtime": 5079.480347633362, "_timestamp": 1585602449.113217, "_step": 23}
{"Episode reward": 26.728943712910294, "Episode length": 733, "Policy Loss": 0.4574454724788666, "Value Loss": 13.542649269104004, "_runtime": 5080.652369022369, "_timestamp": 1585602450.2852385, "_step": 24}
{"Episode reward": 22.099511605128797, "Episode length": 780, "Policy Loss": 0.3476937413215637, "Value Loss": 12.652650833129883, "_runtime": 5082.214259147644, "_timestamp": 1585602451.8471286, "_step": 25}
{"Episode reward": -99.80007385297073, "Episode length": 999, "Policy Loss": -0.47421395778656006, "Value Loss": 0.04796232655644417, "_runtime": 5083.746740818024, "_timestamp": 1585602453.3796103, "_step": 26}
{"Episode reward": -99.73564072409506, "Episode length": 999, "Policy Loss": -0.5126019716262817, "Value Loss": 0.31438255310058594, "_runtime": 5084.6439707279205, "_timestamp": 1585602454.2768402, "_step": 27}
{"Episode reward": 42.59764788427802, "Episode length": 575, "Policy Loss": 0.7051708698272705, "Value Loss": 17.20709991455078, "_runtime": 5086.20205283165, "_timestamp": 1585602455.8349223, "_step": 28}
{"Episode reward": -99.80120163559774, "Episode length": 999, "Policy Loss": -0.40258169174194336, "Value Loss": 0.024217240512371063, "_runtime": 5087.565707683563, "_timestamp": 1585602457.1985772, "_step": 29}
{"Episode reward": 12.406028134190237, "Episode length": 879, "Policy Loss": 0.3850284814834595, "Value Loss": 11.288022994995117, "_runtime": 5089.116062641144, "_timestamp": 1585602458.7489321, "_step": 30}
{"Episode reward": -99.60582269220474, "Episode length": 999, "Policy Loss": -0.3256261348724365, "Value Loss": 0.034546419978141785, "_runtime": 5090.581971168518, "_timestamp": 1585602460.2148407, "_step": 31}
{"Episode reward": 5.723986591306655, "Episode length": 943, "Policy Loss": 0.39998868107795715, "Value Loss": 10.54243278503418, "_runtime": 5091.070104122162, "_timestamp": 1585602460.7029736, "_step": 32}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 1.9186415672302246, "Value Loss": 34.665565490722656, "_runtime": 5091.32837843895, "_timestamp": 1585602460.961248, "_step": 33}
{"Episode reward": 86.60000000000004, "Episode length": 134, "Policy Loss": 4.889453411102295, "Value Loss": 73.80967712402344, "_runtime": 5091.94748044014, "_timestamp": 1585602461.58035, "_step": 34}
{"Episode reward": 61.703909967723035, "Episode length": 385, "Policy Loss": 1.1709418296813965, "Value Loss": 25.43804359436035, "_runtime": 5093.436588764191, "_timestamp": 1585602463.0694582, "_step": 35}
{"Episode reward": -99.80694333643046, "Episode length": 999, "Policy Loss": -0.673274040222168, "Value Loss": 0.3906257748603821, "_runtime": 5094.903748750687, "_timestamp": 1585602464.5366182, "_step": 36}
{"Episode reward": -99.49444464747656, "Episode length": 999, "Policy Loss": -0.7087764739990234, "Value Loss": 0.3333550691604614, "_runtime": 5096.3966591358185, "_timestamp": 1585602466.0295286, "_step": 37}
{"Episode reward": -99.7371662026723, "Episode length": 999, "Policy Loss": -0.7163540124893188, "Value Loss": 0.10475976020097733, "_runtime": 5097.443741798401, "_timestamp": 1585602467.0766113, "_step": 38}
{"Episode reward": 32.99999999999953, "Episode length": 670, "Policy Loss": 0.1651308834552765, "Value Loss": 14.629069328308105, "_runtime": 5098.606387138367, "_timestamp": 1585602468.2392566, "_step": 39}
{"Episode reward": 23.88540390646091, "Episode length": 762, "Policy Loss": 0.032882560044527054, "Value Loss": 13.027424812316895, "_runtime": 5100.146609544754, "_timestamp": 1585602469.779479, "_step": 40}
{"Episode reward": -99.8225365044768, "Episode length": 999, "Policy Loss": -0.8419260382652283, "Value Loss": 0.0610307976603508, "_runtime": 5101.684247970581, "_timestamp": 1585602471.3171175, "_step": 41}
{"Episode reward": -99.71156425878732, "Episode length": 999, "Policy Loss": -0.855617105960846, "Value Loss": 0.03735871985554695, "_runtime": 5102.4118592739105, "_timestamp": 1585602472.0447288, "_step": 42}
{"Episode reward": 53.74952412266246, "Episode length": 464, "Policy Loss": 0.8149021863937378, "Value Loss": 22.782970428466797, "_runtime": 5103.034324169159, "_timestamp": 1585602472.6671937, "_step": 43}
{"Episode reward": 62.350576276238755, "Episode length": 380, "Policy Loss": 1.0258065462112427, "Value Loss": 26.83632469177246, "_runtime": 5103.840894699097, "_timestamp": 1585602473.4737642, "_step": 44}
{"Episode reward": 49.79636368392923, "Episode length": 504, "Policy Loss": 0.43319833278656006, "Value Loss": 19.568241119384766, "_runtime": 5105.212104797363, "_timestamp": 1585602474.8449743, "_step": 45}
{"Episode reward": 8.576447719842875, "Episode length": 917, "Policy Loss": -0.05427154526114464, "Value Loss": 11.363297462463379, "_runtime": 5106.620499610901, "_timestamp": 1585602476.253369, "_step": 46}
{"Episode reward": 5.295004203328801, "Episode length": 949, "Policy Loss": -0.17535297572612762, "Value Loss": 11.307669639587402, "_runtime": 5108.10891866684, "_timestamp": 1585602477.7417881, "_step": 47}
{"Episode reward": -99.73626372341393, "Episode length": 999, "Policy Loss": -0.8068033456802368, "Value Loss": 0.2522566616535187, "_runtime": 5109.257321834564, "_timestamp": 1585602478.8901913, "_step": 48}
{"Episode reward": 24.57072850398255, "Episode length": 755, "Policy Loss": 0.3377190828323364, "Value Loss": 13.151861190795898, "_runtime": 5110.7945120334625, "_timestamp": 1585602480.4273815, "_step": 49}
{"Episode reward": -99.72366545480186, "Episode length": 999, "Policy Loss": -0.5548536777496338, "Value Loss": 0.027927972376346588, "_runtime": 5111.426128387451, "_timestamp": 1585602481.0589979, "_step": 50}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 1.0786961317062378, "Value Loss": 25.018779754638672, "_runtime": 5112.657183885574, "_timestamp": 1585602482.2900534, "_step": 51}
{"Episode reward": 21.591858145222247, "Episode length": 785, "Policy Loss": 0.35771870613098145, "Value Loss": 12.75076675415039, "_runtime": 5113.671856880188, "_timestamp": 1585602483.3047264, "_step": 52}
{"Episode reward": 34.233048771321236, "Episode length": 658, "Policy Loss": 0.8643590807914734, "Value Loss": 15.19136905670166, "_runtime": 5115.152718305588, "_timestamp": 1585602484.7855878, "_step": 53}
{"Episode reward": -99.7547376635936, "Episode length": 999, "Policy Loss": -0.39364007115364075, "Value Loss": 0.00439972709864378, "_runtime": 5116.671098232269, "_timestamp": 1585602486.3039677, "_step": 54}
{"Episode reward": -99.89844663145347, "Episode length": 999, "Policy Loss": -0.3925717771053314, "Value Loss": 0.029179533943533897, "_runtime": 5118.180837154388, "_timestamp": 1585602487.8137066, "_step": 55}
{"Episode reward": -99.64355651812956, "Episode length": 999, "Policy Loss": -0.40558651089668274, "Value Loss": 0.08198758959770203, "_runtime": 5119.304662466049, "_timestamp": 1585602488.937532, "_step": 56}
{"Episode reward": 26.899999999999878, "Episode length": 731, "Policy Loss": 0.4684029817581177, "Value Loss": 13.54891586303711, "_runtime": 5120.839456319809, "_timestamp": 1585602490.4723258, "_step": 57}
{"Episode reward": 1.0898732706685053, "Episode length": 991, "Policy Loss": 0.2550736367702484, "Value Loss": 9.988884925842285, "_runtime": 5121.5498015880585, "_timestamp": 1585602491.182671, "_step": 58}
{"Episode reward": 55.3637779464476, "Episode length": 448, "Policy Loss": 1.027966022491455, "Value Loss": 22.08637046813965, "_runtime": 5122.821977376938, "_timestamp": 1585602492.4548469, "_step": 59}
{"Episode reward": 16.598688471294466, "Episode length": 836, "Policy Loss": 0.4670960307121277, "Value Loss": 11.771349906921387, "_runtime": 5124.36434006691, "_timestamp": 1585602493.9972095, "_step": 60}
{"Episode reward": -99.60782126677084, "Episode length": 999, "Policy Loss": -0.39951997995376587, "Value Loss": 0.27027663588523865, "_runtime": 5125.376575946808, "_timestamp": 1585602495.0094454, "_step": 61}
{"Episode reward": 32.88675022774795, "Episode length": 673, "Policy Loss": 0.5616662502288818, "Value Loss": 14.662553787231445, "_runtime": 5126.895895719528, "_timestamp": 1585602496.5287652, "_step": 62}
{"Episode reward": -99.64069056224406, "Episode length": 999, "Policy Loss": -0.37629935145378113, "Value Loss": 0.04225136339664459, "_runtime": 5128.431132555008, "_timestamp": 1585602498.064002, "_step": 63}
{"Episode reward": -99.70379445927544, "Episode length": 999, "Policy Loss": -0.3527872860431671, "Value Loss": 0.08950357139110565, "_runtime": 5129.944060564041, "_timestamp": 1585602499.57693, "_step": 64}
{"Episode reward": -99.80535457453085, "Episode length": 999, "Policy Loss": -0.32431793212890625, "Value Loss": 0.09732651710510254, "_runtime": 5131.4783663749695, "_timestamp": 1585602501.1112359, "_step": 65}
{"Episode reward": -99.84932052979572, "Episode length": 999, "Policy Loss": -0.3962502181529999, "Value Loss": 0.007514387369155884, "_runtime": 5133.030232429504, "_timestamp": 1585602502.663102, "_step": 66}
{"Episode reward": -99.83746928311744, "Episode length": 999, "Policy Loss": -0.38105398416519165, "Value Loss": 0.02275311015546322, "_runtime": 5133.411934137344, "_timestamp": 1585602503.0448036, "_step": 67}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 2.7073445320129395, "Value Loss": 45.551273345947266, "_runtime": 5134.964794874191, "_timestamp": 1585602504.5976644, "_step": 68}
{"Episode reward": -99.66030913754228, "Episode length": 999, "Policy Loss": -0.41580602526664734, "Value Loss": 0.0047962781973183155, "_runtime": 5136.565676689148, "_timestamp": 1585602506.1985462, "_step": 69}
{"Episode reward": -99.75239120938211, "Episode length": 999, "Policy Loss": -0.4319859743118286, "Value Loss": 0.00947585143148899, "_runtime": 5138.048688173294, "_timestamp": 1585602507.6815577, "_step": 70}
{"Episode reward": -99.53001820950165, "Episode length": 999, "Policy Loss": -0.45548173785209656, "Value Loss": 0.04237154498696327, "_runtime": 5139.617468357086, "_timestamp": 1585602509.2503378, "_step": 71}
{"Episode reward": -99.65700779291663, "Episode length": 999, "Policy Loss": -0.43896475434303284, "Value Loss": 0.024512607604265213, "_runtime": 5140.164436817169, "_timestamp": 1585602509.7973063, "_step": 72}
{"Episode reward": 67.72826139754598, "Episode length": 324, "Policy Loss": 1.4487744569778442, "Value Loss": 30.57208824157715, "_runtime": 5141.694566011429, "_timestamp": 1585602511.3274355, "_step": 73}
{"Episode reward": -99.56369041439473, "Episode length": 999, "Policy Loss": -0.46216070652008057, "Value Loss": 0.019389847293496132, "_runtime": 5143.263032674789, "_timestamp": 1585602512.8959022, "_step": 74}
{"Episode reward": -99.79839040750964, "Episode length": 999, "Policy Loss": -0.4507104158401489, "Value Loss": 0.012436168268322945, "_runtime": 5144.757688045502, "_timestamp": 1585602514.3905575, "_step": 75}
{"Episode reward": -99.4307978254962, "Episode length": 999, "Policy Loss": -0.47071897983551025, "Value Loss": 0.030034448951482773, "_runtime": 5146.3194851875305, "_timestamp": 1585602515.9523547, "_step": 76}
{"Episode reward": -99.76715515546826, "Episode length": 999, "Policy Loss": -0.4841526448726654, "Value Loss": 0.12533798813819885, "_runtime": 5147.8925886154175, "_timestamp": 1585602517.525458, "_step": 77}
{"Episode reward": -99.63466989865853, "Episode length": 999, "Policy Loss": -0.4783877432346344, "Value Loss": 0.023379743099212646, "_runtime": 5149.43660736084, "_timestamp": 1585602519.0694768, "_step": 78}
{"Episode reward": -99.7165713747018, "Episode length": 999, "Policy Loss": -0.47111791372299194, "Value Loss": 0.012590833939611912, "_runtime": 5151.013985157013, "_timestamp": 1585602520.6468546, "_step": 79}
{"Episode reward": -99.80297064855556, "Episode length": 999, "Policy Loss": -0.4631909132003784, "Value Loss": 0.010823719203472137, "_runtime": 5152.601624965668, "_timestamp": 1585602522.2344944, "_step": 80}
{"Episode reward": -99.81139270518766, "Episode length": 999, "Policy Loss": -0.4779697358608246, "Value Loss": 0.011004883795976639, "_runtime": 5153.19712138176, "_timestamp": 1585602522.8299909, "_step": 81}
{"Episode reward": 63.857122062024196, "Episode length": 362, "Policy Loss": 1.270142912864685, "Value Loss": 27.435894012451172, "_runtime": 5154.757923126221, "_timestamp": 1585602524.3907926, "_step": 82}
{"Episode reward": -99.84824164258177, "Episode length": 999, "Policy Loss": -0.46455907821655273, "Value Loss": 0.021514344960451126, "_runtime": 5155.610543966293, "_timestamp": 1585602525.2434134, "_step": 83}
{"Episode reward": 47.87101685840125, "Episode length": 523, "Policy Loss": 1.0926625728607178, "Value Loss": 18.87891387939453, "_runtime": 5156.207989215851, "_timestamp": 1585602525.8408587, "_step": 84}
{"Episode reward": 61.64662824994858, "Episode length": 385, "Policy Loss": 1.107993483543396, "Value Loss": 25.480945587158203, "_runtime": 5157.293493032455, "_timestamp": 1585602526.9263625, "_step": 85}
{"Episode reward": 30.692951155779554, "Episode length": 695, "Policy Loss": 0.3692087233066559, "Value Loss": 14.407095909118652, "_runtime": 5158.442403078079, "_timestamp": 1585602528.0752726, "_step": 86}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": 0.36046165227890015, "Value Loss": 13.012502670288086, "_runtime": 5159.9859845638275, "_timestamp": 1585602529.618854, "_step": 87}
{"Episode reward": -99.84634282076591, "Episode length": 999, "Policy Loss": -0.5492724776268005, "Value Loss": 0.13994266092777252, "_runtime": 5161.534519433975, "_timestamp": 1585602531.167389, "_step": 88}
{"Episode reward": -99.71086546287266, "Episode length": 999, "Policy Loss": -0.5165225863456726, "Value Loss": 0.009812886826694012, "_runtime": 5162.817818403244, "_timestamp": 1585602532.450688, "_step": 89}
{"Episode reward": 17.036396677652817, "Episode length": 832, "Policy Loss": 0.22928486764431, "Value Loss": 11.89491081237793, "_runtime": 5164.367982625961, "_timestamp": 1585602534.000852, "_step": 90}
{"Episode reward": -99.76775768608647, "Episode length": 999, "Policy Loss": -0.5255007147789001, "Value Loss": 0.007057136856019497, "_runtime": 5165.422518730164, "_timestamp": 1585602535.0553882, "_step": 91}
{"Episode reward": 32.43784635120494, "Episode length": 676, "Policy Loss": 0.39692190289497375, "Value Loss": 14.679025650024414, "_runtime": 5165.924207687378, "_timestamp": 1585602535.5570772, "_step": 92}
{"Episode reward": 69.55096529065615, "Episode length": 306, "Policy Loss": 1.4771310091018677, "Value Loss": 32.389251708984375, "_runtime": 5167.26300740242, "_timestamp": 1585602536.895877, "_step": 93}
{"Episode reward": 12.951402471098788, "Episode length": 873, "Policy Loss": 0.3499741852283478, "Value Loss": 11.295140266418457, "_runtime": 5168.79213476181, "_timestamp": 1585602538.4250042, "_step": 94}
{"Episode reward": -99.81808741092543, "Episode length": 999, "Policy Loss": -0.5543563961982727, "Value Loss": 0.057128600776195526, "_runtime": 5169.505287885666, "_timestamp": 1585602539.1381574, "_step": 95}
{"Episode reward": 52.49756716927474, "Episode length": 476, "Policy Loss": 0.6836144328117371, "Value Loss": 20.591001510620117, "_runtime": 5171.04092001915, "_timestamp": 1585602540.6737895, "_step": 96}
{"Episode reward": -99.6032120212666, "Episode length": 999, "Policy Loss": -0.5804983973503113, "Value Loss": 0.1439734548330307, "_runtime": 5171.954971551895, "_timestamp": 1585602541.587841, "_step": 97}
{"Episode reward": 42.284436446777, "Episode length": 579, "Policy Loss": 0.5617784857749939, "Value Loss": 16.65744400024414, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181, 0.07668289542198181]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0], "bins": [-0.07668289542198181, -0.010958671569824219, 0.054765552282333374, 0.12048977613449097, 0.18621399998664856, 0.25193822383880615, 0.31766244769096375, 0.38338667154312134, 0.44911089539527893, 0.5148351192474365, 0.5805593729019165, 0.6462835073471069, 0.7120077610015869, 0.7777320146560669, 0.8434562683105469, 0.9091804027557373, 0.9749046564102173, 1.0406289100646973, 1.1063531637191772, 1.1720772981643677, 1.2378015518188477, 1.3035258054733276, 1.369249939918518, 1.434974193572998, 1.500698447227478, 1.566422700881958, 1.632146954536438, 1.6978710889816284, 1.7635953426361084, 1.8293195962905884, 1.8950437307357788, 1.9607681035995483, 2.0264923572540283, 2.0922164916992188, 2.1579408645629883, 2.2236649990081787, 2.2893893718719482, 2.3551135063171387, 2.420837640762329, 2.4865620136260986, 2.552286148071289, 2.6180102825164795, 2.683734655380249, 2.7494587898254395, 2.81518292427063, 2.8809072971343994, 2.94663143157959, 3.0123558044433594, 3.07807993888855, 3.1438040733337402, 3.2095284461975098, 3.2752525806427, 3.3409769535064697, 3.40670108795166, 3.4724252223968506, 3.53814959526062, 3.6038737297058105, 3.669597864151001, 3.7353222370147705, 3.801046371459961, 3.8667705059051514, 3.932494878768921, 3.9982192516326904, 4.063942909240723, 4.129667282104492]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.1474634010209e-10, 0.0008312839781865478, 0.0016625681892037392, 0.0024938525166362524, 0.0033251368440687656, 0.004156420938670635, 0.004987705033272505, 0.005818989593535662, 0.006650273688137531, 0.007481557782739401, 0.008312842808663845, 0.009144127368927002, 0.009975410997867584, 0.010806695558130741, 0.011637980118393898, 0.01246926374733448, 0.013300548307597637, 0.014131832867860794, 0.014963116496801376, 0.015794401988387108, 0.01662568561732769, 0.017456969246268272, 0.018288254737854004, 0.019119538366794586, 0.01995082199573517, 0.0207821074873209, 0.021613391116261482, 0.022444674745202065, 0.023275960236787796, 0.02410724386572838, 0.02493852749466896, 0.025769812986254692, 0.026601096615195274, 0.027432380244135857, 0.028263665735721588, 0.02909494936466217, 0.029926232993602753, 0.030757518485188484, 0.031588803976774216, 0.0324200876057148, 0.03325137123465538, 0.03408265486359596, 0.034913938492536545, 0.03574522212147713, 0.03657650947570801, 0.03740779310464859, 0.03823907673358917, 0.039070360362529755, 0.03990164399147034, 0.04073292762041092, 0.0415642149746418, 0.04239549860358238, 0.043226782232522964, 0.04405806586146355, 0.04488934949040413, 0.04572063311934471, 0.04655192047357559, 0.047383204102516174, 0.04821448773145676, 0.04904577136039734, 0.04987705498933792, 0.0507083386182785, 0.051539625972509384, 0.052370909601449966, 0.05320219323039055]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 11.0, 11.0, 9.0, 3.0, 4.0, 12.0, 10.0, 4.0, 19.0, 7.0, 12.0, 7.0, 10.0, 1.0, 1.0, 224.0, 1.0, 2.0, 6.0, 2.0, 4.0, 2.0, 2.0, 3.0, 6.0, 1.0, 7.0, 4.0, 5.0, 1.0, 2.0, 9.0, 8.0, 6.0, 1.0, 2.0, 6.0, 5.0, 10.0, 3.0, 4.0, 1.0, 3.0, 1.0, 6.0, 2.0, 4.0, 7.0, 4.0, 2.0, 5.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 0.0, 2.0, 4.0, 0.0, 0.0, 5.0], "bins": [-0.0493563748896122, -0.046408068388700485, -0.04345976188778877, -0.04051145538687706, -0.03756314888596535, -0.034614842385053635, -0.031666532158851624, -0.02871822752058506, -0.025769921019673347, -0.022821614518761635, -0.019873308017849922, -0.01692499965429306, -0.013976693153381348, -0.011028386652469635, -0.008080080151557922, -0.00513177365064621, -0.002183467149734497, 0.0007648393511772156, 0.0037131458520889282, 0.006661452353000641, 0.009609758853912354, 0.012558065354824066, 0.015506375581026077, 0.01845468208193779, 0.021402988582849503, 0.024351295083761215, 0.027299601584672928, 0.03024790808558464, 0.03319621458649635, 0.036144521087408066, 0.03909282758831978, 0.04204113408923149, 0.044989440590143204, 0.047937747091054916, 0.05088605359196663, 0.05383436009287834, 0.056782666593790054, 0.05973097309470177, 0.06267927587032318, 0.06562758982181549, 0.0685758888721466, 0.07152420282363892, 0.07447250187397003, 0.07742081582546234, 0.08036912977695465, 0.08331742882728577, 0.08626574277877808, 0.08921404182910919, 0.0921623557806015, 0.09511065483093262, 0.09805896878242493, 0.10100726783275604, 0.10395558178424835, 0.10690388083457947, 0.10985219478607178, 0.1128004938364029, 0.1157488077878952, 0.11869710683822632, 0.12164542078971863, 0.12459371984004974, 0.12754203379154205, 0.13049033284187317, 0.13343864679336548, 0.1363869458436966, 0.1393352597951889]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.15633226931095123, -0.14519017934799194, -0.13404808938503265, -0.12290600687265396, -0.11176391690969467, -0.10062182694673538, -0.08947974443435669, -0.0783376544713974, -0.06719556450843811, -0.05605347454547882, -0.04491138458251953, -0.03376930207014084, -0.022627219557762146, -0.011485129594802856, -0.0003430396318435669, 0.010799050331115723, 0.021941140294075012, 0.0330832302570343, 0.04422532021999359, 0.05536741018295288, 0.06650950014591217, 0.07765157520771027, 0.08879366517066956, 0.09993575513362885, 0.11107783019542694, 0.12221993505954742, 0.13336201012134552, 0.144504114985466, 0.1556461900472641, 0.16678829491138458, 0.17793036997318268, 0.18907247483730316, 0.20021454989910126, 0.21135662496089935, 0.22249872982501984, 0.23364080488681793, 0.24478290975093842, 0.2559249997138977, 0.2670670747756958, 0.2782091498374939, 0.28935128450393677, 0.30049335956573486, 0.31163543462753296, 0.32277750968933105, 0.33391958475112915, 0.345061719417572, 0.3562037944793701, 0.3673458695411682, 0.3784879446029663, 0.3896300792694092, 0.4007721543312073, 0.41191422939300537, 0.42305630445480347, 0.43419843912124634, 0.44534051418304443, 0.45648258924484253, 0.4676246643066406, 0.4787667393684387, 0.4899088740348816, 0.5010509490966797, 0.5121930241584778, 0.5233350992202759, 0.5344772338867188, 0.5456193089485168, 0.5567613840103149]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 11.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2606161832809448, -0.2554006576538086, -0.25018510222435, -0.24496957659721375, -0.23975405097007751, -0.2345385104417801, -0.22932296991348267, -0.22410744428634644, -0.218891903758049, -0.2136763632297516, -0.20846083760261536, -0.20324529707431793, -0.1980297565460205, -0.19281423091888428, -0.18759869039058685, -0.18238314986228943, -0.1771676242351532, -0.17195209860801697, -0.16673655807971954, -0.16152101755142212, -0.1563054919242859, -0.15108995139598846, -0.14587441086769104, -0.1406588852405548, -0.13544334471225739, -0.13022780418395996, -0.12501227855682373, -0.1197967380285263, -0.11458119750022888, -0.10936567187309265, -0.10415013134479523, -0.098934605717659, -0.09371906518936157, -0.08850352466106415, -0.08328799903392792, -0.0780724585056305, -0.07285693287849426, -0.06764139235019684, -0.062425851821899414, -0.057210326194763184, -0.05199478566646576, -0.046779245138168335, -0.041563719511032104, -0.03634817898273468, -0.031132638454437256, -0.025917112827301025, -0.0207015722990036, -0.01548604667186737, -0.010270506143569946, -0.005054980516433716, 0.00016057491302490234, 0.005376100540161133, 0.010591626167297363, 0.01580718159675598, 0.021022707223892212, 0.026238232851028442, 0.03145378828048706, 0.03666931390762329, 0.04188483953475952, 0.04710036516189575, 0.05231592059135437, 0.0575314462184906, 0.06274697184562683, 0.06796252727508545, 0.07317805290222168]}, "_runtime": 5173.455342769623, "_timestamp": 1585602543.0882123, "_step": 98}
{"Episode reward": -99.62583516174787, "Episode length": 999, "Policy Loss": -0.6095816493034363, "Value Loss": 0.05778123065829277, "_runtime": 5175.003902196884, "_timestamp": 1585602544.6367717, "_step": 99}
{"Episode reward": -99.67660348035722, "Episode length": 999, "Policy Loss": -0.6252033710479736, "Value Loss": 0.0605776272714138, "_runtime": 5176.522475242615, "_timestamp": 1585602546.1553447, "_step": 100}
{"Episode reward": -99.48139189020594, "Episode length": 999, "Policy Loss": -0.6092628836631775, "Value Loss": 0.03234342858195305, "_runtime": 5178.077543497086, "_timestamp": 1585602547.710413, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6011793613433838, "Value Loss": 0.009332516230642796, "_runtime": 5179.646833658218, "_timestamp": 1585602549.2797031, "_step": 102}
{"Episode reward": -99.79305488783726, "Episode length": 999, "Policy Loss": -0.5967415571212769, "Value Loss": 0.012154015712440014, "_runtime": 5181.206827402115, "_timestamp": 1585602550.839697, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5904697775840759, "Value Loss": 0.008658369071781635, "_runtime": 5182.805823564529, "_timestamp": 1585602552.438693, "_step": 104}
{"Episode reward": -99.48268240070765, "Episode length": 999, "Policy Loss": -0.573045551776886, "Value Loss": 0.00857282243669033, "_runtime": 5184.373478412628, "_timestamp": 1585602554.006348, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5682745575904846, "Value Loss": 0.0086479177698493, "_runtime": 5185.063614845276, "_timestamp": 1585602554.6964843, "_step": 106}
{"Episode reward": 58.19999999999968, "Episode length": 418, "Policy Loss": 0.9111952185630798, "Value Loss": 23.76591682434082, "_runtime": 5186.621871709824, "_timestamp": 1585602556.2547412, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5574635863304138, "Value Loss": 0.00738567067310214, "_runtime": 5188.202922105789, "_timestamp": 1585602557.8357916, "_step": 108}
{"Episode reward": -99.71572329208581, "Episode length": 999, "Policy Loss": -0.562189519405365, "Value Loss": 0.010077283717691898, "_runtime": 5189.703982114792, "_timestamp": 1585602559.3368516, "_step": 109}
{"Episode reward": -99.80000010451627, "Episode length": 999, "Policy Loss": -0.5633583664894104, "Value Loss": 0.008725211955606937, "_runtime": 5191.273622512817, "_timestamp": 1585602560.906492, "_step": 110}
{"Episode reward": -99.70237389770779, "Episode length": 999, "Policy Loss": -0.545921266078949, "Value Loss": 0.04022496938705444, "_runtime": 5192.845833778381, "_timestamp": 1585602562.4787033, "_step": 111}
{"Episode reward": 0.7694056331659311, "Episode length": 994, "Policy Loss": 0.08252974599599838, "Value Loss": 9.94325065612793, "_runtime": 5194.4004147052765, "_timestamp": 1585602564.0332842, "_step": 112}
{"Episode reward": -99.80472526335949, "Episode length": 999, "Policy Loss": -0.5597803592681885, "Value Loss": 0.01694246008992195, "_runtime": 5195.969718694687, "_timestamp": 1585602565.6025882, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5426823496818542, "Value Loss": 0.009130971506237984, "_runtime": 5197.416533231735, "_timestamp": 1585602567.0494027, "_step": 114}
{"Episode reward": 8.900451895548926, "Episode length": 912, "Policy Loss": 0.15837329626083374, "Value Loss": 10.652095794677734, "_runtime": 5198.582242965698, "_timestamp": 1585602568.2151124, "_step": 115}
{"Episode reward": 26.092708945274282, "Episode length": 740, "Policy Loss": 0.24583278596401215, "Value Loss": 12.860004425048828, "_runtime": 5199.223779678345, "_timestamp": 1585602568.8566492, "_step": 116}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 0.958666205406189, "Value Loss": 24.658632278442383, "_runtime": 5200.786211013794, "_timestamp": 1585602570.4190805, "_step": 117}
{"Episode reward": -99.54951107075765, "Episode length": 999, "Policy Loss": -0.5240195393562317, "Value Loss": 0.018344024196267128, "_runtime": 5202.341153860092, "_timestamp": 1585602571.9740233, "_step": 118}
{"Episode reward": -99.18237160537257, "Episode length": 999, "Policy Loss": -0.49912819266319275, "Value Loss": 0.007378550712019205, "_runtime": 5203.8547103405, "_timestamp": 1585602573.4875798, "_step": 119}
{"Episode reward": -99.80037691910262, "Episode length": 999, "Policy Loss": -0.48708879947662354, "Value Loss": 0.02497388981282711, "_runtime": 5205.4197607040405, "_timestamp": 1585602575.0526302, "_step": 120}
{"Episode reward": 1.0119370439801827, "Episode length": 992, "Policy Loss": 0.16896408796310425, "Value Loss": 9.62788200378418, "_runtime": 5207.029321908951, "_timestamp": 1585602576.6621914, "_step": 121}
{"Episode reward": -99.8245230869376, "Episode length": 999, "Policy Loss": -0.45794445276260376, "Value Loss": 0.005214876960963011, "_runtime": 5208.548679351807, "_timestamp": 1585602578.1815488, "_step": 122}
{"Episode reward": 2.780229319091987, "Episode length": 976, "Policy Loss": 0.14596953988075256, "Value Loss": 9.524758338928223, "_runtime": 5209.8907923698425, "_timestamp": 1585602579.5236619, "_step": 123}
{"Episode reward": 15.000000000000554, "Episode length": 850, "Policy Loss": 0.27228549122810364, "Value Loss": 11.151580810546875, "_runtime": 5211.467569351196, "_timestamp": 1585602581.1004388, "_step": 124}
{"Episode reward": -99.72618754166622, "Episode length": 999, "Policy Loss": -0.45449575781822205, "Value Loss": 0.006925888825207949, "_runtime": 5213.038542747498, "_timestamp": 1585602582.6714122, "_step": 125}
{"Episode reward": -99.70218179109368, "Episode length": 999, "Policy Loss": -0.46166831254959106, "Value Loss": 0.03859734162688255, "_runtime": 5214.60348534584, "_timestamp": 1585602584.2363548, "_step": 126}
{"Episode reward": -99.70635438477481, "Episode length": 999, "Policy Loss": -0.45628735423088074, "Value Loss": 0.0052630482241511345, "_runtime": 5216.18199300766, "_timestamp": 1585602585.8148625, "_step": 127}
{"Episode reward": -99.6786188603365, "Episode length": 999, "Policy Loss": -0.4567623436450958, "Value Loss": 0.005321590229868889, "_runtime": 5217.143705606461, "_timestamp": 1585602586.776575, "_step": 128}
{"Episode reward": 39.93619924583415, "Episode length": 603, "Policy Loss": 0.3530868887901306, "Value Loss": 22.54310417175293, "_runtime": 5218.720091819763, "_timestamp": 1585602588.3529613, "_step": 129}
{"Episode reward": -99.8159113470975, "Episode length": 999, "Policy Loss": -0.41346117854118347, "Value Loss": 0.00457680644467473, "_runtime": 5220.302006959915, "_timestamp": 1585602589.9348764, "_step": 130}
{"Episode reward": -99.85390641395794, "Episode length": 999, "Policy Loss": -0.3831251561641693, "Value Loss": 0.0034759766422212124, "_runtime": 5221.827783823013, "_timestamp": 1585602591.4606533, "_step": 131}
{"Episode reward": -99.51016127816845, "Episode length": 999, "Policy Loss": -0.36402061581611633, "Value Loss": 0.003579140407964587, "_runtime": 5223.39574098587, "_timestamp": 1585602593.0286105, "_step": 132}
{"Episode reward": -99.8067391006495, "Episode length": 999, "Policy Loss": -0.3563556373119354, "Value Loss": 0.014803954400122166, "_runtime": 5223.937834739685, "_timestamp": 1585602593.5707042, "_step": 133}
{"Episode reward": 68.28223753598851, "Episode length": 318, "Policy Loss": 1.5826462507247925, "Value Loss": 31.284547805786133, "_runtime": 5225.167875289917, "_timestamp": 1585602594.8007448, "_step": 134}
{"Episode reward": 21.45125158908796, "Episode length": 787, "Policy Loss": 0.40125399827957153, "Value Loss": 12.615226745605469, "_runtime": 5226.464922428131, "_timestamp": 1585602596.097792, "_step": 135}
{"Episode reward": 18.09766213772275, "Episode length": 820, "Policy Loss": 0.43689313530921936, "Value Loss": 12.090237617492676, "_runtime": 5227.531062841415, "_timestamp": 1585602597.1639323, "_step": 136}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": 0.5643556118011475, "Value Loss": 13.928757667541504, "_runtime": 5228.341794252396, "_timestamp": 1585602597.9746637, "_step": 137}
{"Episode reward": 49.21611379226043, "Episode length": 509, "Policy Loss": 0.8138017058372498, "Value Loss": 19.35688018798828, "_runtime": 5229.930806398392, "_timestamp": 1585602599.5636759, "_step": 138}
{"Episode reward": -99.75042535980326, "Episode length": 999, "Policy Loss": -0.5418949127197266, "Value Loss": 0.23364534974098206, "_runtime": 5231.0476949214935, "_timestamp": 1585602600.6805644, "_step": 139}
{"Episode reward": 27.72245480294788, "Episode length": 724, "Policy Loss": 0.27625054121017456, "Value Loss": 13.5505952835083, "_runtime": 5231.924921751022, "_timestamp": 1585602601.5577912, "_step": 140}
{"Episode reward": 43.14270607745222, "Episode length": 569, "Policy Loss": 0.7251878976821899, "Value Loss": 17.254697799682617, "_runtime": 5233.48428273201, "_timestamp": 1585602603.1171522, "_step": 141}
{"Episode reward": -99.83656783444319, "Episode length": 999, "Policy Loss": -0.6700995564460754, "Value Loss": 0.08473138511180878, "_runtime": 5235.005566835403, "_timestamp": 1585602604.6384363, "_step": 142}
{"Episode reward": 1.1880702623645334, "Episode length": 990, "Policy Loss": -0.050890542566776276, "Value Loss": 10.026762008666992, "_runtime": 5236.529805183411, "_timestamp": 1585602606.1626747, "_step": 143}
{"Episode reward": -99.6454951499342, "Episode length": 999, "Policy Loss": -0.7280455827713013, "Value Loss": 0.11491863429546356, "_runtime": 5237.104317188263, "_timestamp": 1585602606.7371867, "_step": 144}
{"Episode reward": 65.24284059968755, "Episode length": 350, "Policy Loss": 1.1606570482254028, "Value Loss": 28.188669204711914, "_runtime": 5238.65694642067, "_timestamp": 1585602608.289816, "_step": 145}
{"Episode reward": -99.70309373768839, "Episode length": 999, "Policy Loss": -0.7295721769332886, "Value Loss": 0.015035288408398628, "_runtime": 5239.296938419342, "_timestamp": 1585602608.929808, "_step": 146}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 0.8025859594345093, "Value Loss": 25.446863174438477, "_runtime": 5240.796860933304, "_timestamp": 1585602610.4297304, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7907247543334961, "Value Loss": 0.024092409759759903, "_runtime": 5242.3636972904205, "_timestamp": 1585602611.9965668, "_step": 148}
{"Episode reward": -99.59718039068255, "Episode length": 999, "Policy Loss": -0.806778609752655, "Value Loss": 0.017104147002100945, "_runtime": 5243.8770616054535, "_timestamp": 1585602613.509931, "_step": 149}
{"Episode reward": -99.69547773641395, "Episode length": 999, "Policy Loss": -0.8267667293548584, "Value Loss": 0.022117692977190018, "_runtime": 5245.433340549469, "_timestamp": 1585602615.06621, "_step": 150}
{"Episode reward": -99.63096396874032, "Episode length": 999, "Policy Loss": -0.8445916771888733, "Value Loss": 0.030962908640503883, "_runtime": 5246.187800884247, "_timestamp": 1585602615.8206704, "_step": 151}
{"Episode reward": 53.94108489206955, "Episode length": 462, "Policy Loss": 0.4646374583244324, "Value Loss": 21.19678497314453, "_runtime": 5247.752091884613, "_timestamp": 1585602617.3849614, "_step": 152}
{"Episode reward": -99.66107627337195, "Episode length": 999, "Policy Loss": -0.871861457824707, "Value Loss": 0.03300304338335991, "_runtime": 5249.327527046204, "_timestamp": 1585602618.9603965, "_step": 153}
{"Episode reward": -99.7827479743443, "Episode length": 999, "Policy Loss": -0.8910696506500244, "Value Loss": 0.05249563604593277, "_runtime": 5250.176548242569, "_timestamp": 1585602619.8094177, "_step": 154}
{"Episode reward": 44.92266661215057, "Episode length": 552, "Policy Loss": 0.18568098545074463, "Value Loss": 17.696704864501953, "_runtime": 5251.479925870895, "_timestamp": 1585602621.1127954, "_step": 155}
{"Episode reward": 15.215587433381543, "Episode length": 849, "Policy Loss": -0.22096207737922668, "Value Loss": 11.392423629760742, "_runtime": 5253.021129846573, "_timestamp": 1585602622.6539993, "_step": 156}
{"Episode reward": -99.53130227839436, "Episode length": 999, "Policy Loss": -0.9244227409362793, "Value Loss": 0.13721682131290436, "_runtime": 5254.570554494858, "_timestamp": 1585602624.203424, "_step": 157}
{"Episode reward": -99.36406308559683, "Episode length": 999, "Policy Loss": -0.9690212607383728, "Value Loss": 0.05579506605863571, "_runtime": 5256.111602306366, "_timestamp": 1585602625.7444718, "_step": 158}
{"Episode reward": -99.5937464010655, "Episode length": 999, "Policy Loss": -0.9707615971565247, "Value Loss": 0.04094609618186951, "_runtime": 5257.667549371719, "_timestamp": 1585602627.3004189, "_step": 159}
{"Episode reward": -99.7218796486312, "Episode length": 999, "Policy Loss": -0.9790166020393372, "Value Loss": 0.07159077376127243, "_runtime": 5259.219976902008, "_timestamp": 1585602628.8528464, "_step": 160}
{"Episode reward": -99.82752342084284, "Episode length": 999, "Policy Loss": -0.961556613445282, "Value Loss": 0.028005262836813927, "_runtime": 5260.770639181137, "_timestamp": 1585602630.4035087, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9335657954216003, "Value Loss": 0.05924086272716522, "_runtime": 5261.706848144531, "_timestamp": 1585602631.3397176, "_step": 162}
{"Episode reward": 41.061083173634856, "Episode length": 591, "Policy Loss": 0.12576067447662354, "Value Loss": 16.290658950805664, "_runtime": 5262.863482713699, "_timestamp": 1585602632.4963522, "_step": 163}
{"Episode reward": 25.397318049031284, "Episode length": 747, "Policy Loss": 0.17915916442871094, "Value Loss": 12.98448371887207, "_runtime": 5264.422316789627, "_timestamp": 1585602634.0551863, "_step": 164}
{"Episode reward": -99.65514371606848, "Episode length": 999, "Policy Loss": -0.9050304293632507, "Value Loss": 0.2096245288848877, "_runtime": 5265.944529056549, "_timestamp": 1585602635.5773985, "_step": 165}
{"Episode reward": -99.69155354522961, "Episode length": 999, "Policy Loss": -0.8251183032989502, "Value Loss": 0.019731350243091583, "_runtime": 5267.48793888092, "_timestamp": 1585602637.1208084, "_step": 166}
{"Episode reward": -99.6510177646517, "Episode length": 999, "Policy Loss": -0.7770969867706299, "Value Loss": 0.027355732396245003, "_runtime": 5269.036193609238, "_timestamp": 1585602638.669063, "_step": 167}
{"Episode reward": -99.68514957686281, "Episode length": 999, "Policy Loss": -0.713809072971344, "Value Loss": 0.029743362218141556, "_runtime": 5270.592657804489, "_timestamp": 1585602640.2255273, "_step": 168}
{"Episode reward": -99.76339136150061, "Episode length": 999, "Policy Loss": -0.6816258430480957, "Value Loss": 0.0430583730340004, "_runtime": 5272.153225183487, "_timestamp": 1585602641.7860947, "_step": 169}
{"Episode reward": -99.80450046288176, "Episode length": 999, "Policy Loss": -0.6233097314834595, "Value Loss": 0.013554493896663189, "_runtime": 5273.708178281784, "_timestamp": 1585602643.3410478, "_step": 170}
{"Episode reward": -99.47275049348691, "Episode length": 999, "Policy Loss": -0.5594914555549622, "Value Loss": 0.01515956036746502, "_runtime": 5275.267472028732, "_timestamp": 1585602644.9003415, "_step": 171}
{"Episode reward": -99.76109571242566, "Episode length": 999, "Policy Loss": -0.514626145362854, "Value Loss": 0.01088025327771902, "_runtime": 5276.854457139969, "_timestamp": 1585602646.4873266, "_step": 172}
{"Episode reward": -99.72049881093996, "Episode length": 999, "Policy Loss": -0.438571035861969, "Value Loss": 0.03387277573347092, "_runtime": 5278.186014175415, "_timestamp": 1585602647.8188837, "_step": 173}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": 0.31658437848091125, "Value Loss": 11.163798332214355, "_runtime": 5279.604333400726, "_timestamp": 1585602649.237203, "_step": 174}
{"Episode reward": 9.501468619053185, "Episode length": 908, "Policy Loss": 0.29589492082595825, "Value Loss": 10.405807495117188, "_runtime": 5281.163787841797, "_timestamp": 1585602650.7966573, "_step": 175}
{"Episode reward": -99.63830224023992, "Episode length": 999, "Policy Loss": -0.2592417299747467, "Value Loss": 0.006702500861138105, "_runtime": 5282.714865922928, "_timestamp": 1585602652.3477354, "_step": 176}
{"Episode reward": -99.77974248463148, "Episode length": 999, "Policy Loss": -0.2302321493625641, "Value Loss": 0.0775895044207573, "_runtime": 5284.257661342621, "_timestamp": 1585602653.8905308, "_step": 177}
{"Episode reward": -99.8396540938164, "Episode length": 999, "Policy Loss": -0.1987094283103943, "Value Loss": 0.06802040338516235, "_runtime": 5285.802298069, "_timestamp": 1585602655.4351676, "_step": 178}
{"Episode reward": -99.78150511090506, "Episode length": 999, "Policy Loss": -0.17021022737026215, "Value Loss": 0.04387275502085686, "_runtime": 5287.071382522583, "_timestamp": 1585602656.704252, "_step": 179}
{"Episode reward": 18.038129927008796, "Episode length": 820, "Policy Loss": 0.5498697757720947, "Value Loss": 11.63230037689209, "_runtime": 5288.6274700164795, "_timestamp": 1585602658.2603395, "_step": 180}
{"Episode reward": -99.81612303836597, "Episode length": 999, "Policy Loss": -0.16264788806438446, "Value Loss": 0.026901718229055405, "_runtime": 5290.188325881958, "_timestamp": 1585602659.8211954, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1596524715423584, "Value Loss": 0.23689553141593933, "_runtime": 5291.472142696381, "_timestamp": 1585602661.1050122, "_step": 182}
{"Episode reward": 17.278414720297278, "Episode length": 828, "Policy Loss": 0.5130155086517334, "Value Loss": 11.449913024902344, "_runtime": 5292.686016321182, "_timestamp": 1585602662.3188858, "_step": 183}
{"Episode reward": 21.812360582873396, "Episode length": 782, "Policy Loss": 0.5731257796287537, "Value Loss": 12.282540321350098, "_runtime": 5294.240791082382, "_timestamp": 1585602663.8736606, "_step": 184}
{"Episode reward": -99.3793212753707, "Episode length": 999, "Policy Loss": -0.1664363592863083, "Value Loss": 0.011146115139126778, "_runtime": 5295.245370149612, "_timestamp": 1585602664.8782396, "_step": 185}
{"Episode reward": 35.87184134665232, "Episode length": 642, "Policy Loss": 0.7550067901611328, "Value Loss": 14.520262718200684, "_runtime": 5296.778657436371, "_timestamp": 1585602666.411527, "_step": 186}
{"Episode reward": -99.73140751861362, "Episode length": 999, "Policy Loss": -0.15918852388858795, "Value Loss": 0.012846670113503933, "_runtime": 5298.334590435028, "_timestamp": 1585602667.96746, "_step": 187}
{"Episode reward": -99.73646226965218, "Episode length": 999, "Policy Loss": -0.1660531908273697, "Value Loss": 0.06483416259288788, "_runtime": 5299.740052938461, "_timestamp": 1585602669.3729224, "_step": 188}
{"Episode reward": 10.449924153230043, "Episode length": 897, "Policy Loss": 0.5803987979888916, "Value Loss": 11.179948806762695, "_runtime": 5300.365735530853, "_timestamp": 1585602669.998605, "_step": 189}
{"Episode reward": 61.433686493336886, "Episode length": 386, "Policy Loss": 1.5609183311462402, "Value Loss": 24.309104919433594, "_runtime": 5301.138176441193, "_timestamp": 1585602670.771046, "_step": 190}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 1.5817112922668457, "Value Loss": 19.505962371826172, "_runtime": 5301.765950679779, "_timestamp": 1585602671.3988202, "_step": 191}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.5770212411880493, "Value Loss": 23.82651138305664, "_runtime": 5303.260714292526, "_timestamp": 1585602672.8935838, "_step": 192}
{"Episode reward": -99.72135473978567, "Episode length": 999, "Policy Loss": -0.23746967315673828, "Value Loss": 0.01795319840312004, "_runtime": 5304.223418951035, "_timestamp": 1585602673.8562884, "_step": 193}
{"Episode reward": 36.8167067435331, "Episode length": 633, "Policy Loss": 0.6325170993804932, "Value Loss": 15.792561531066895, "_runtime": 5305.711748600006, "_timestamp": 1585602675.344618, "_step": 194}
{"Episode reward": -99.7252368143804, "Episode length": 999, "Policy Loss": -0.3260074853897095, "Value Loss": 0.015764083713293076, "_runtime": 5307.258226394653, "_timestamp": 1585602676.8910959, "_step": 195}
{"Episode reward": -99.71433878601972, "Episode length": 999, "Policy Loss": -0.3737761378288269, "Value Loss": 0.11314321309328079, "_runtime": 5307.96830034256, "_timestamp": 1585602677.6011698, "_step": 196}
{"Episode reward": 54.6571041906016, "Episode length": 455, "Policy Loss": 0.8307011127471924, "Value Loss": 20.69635009765625, "_runtime": 5309.510717868805, "_timestamp": 1585602679.1435874, "_step": 197}
{"Episode reward": -99.84035959928738, "Episode length": 999, "Policy Loss": -0.4847632348537445, "Value Loss": 0.14777018129825592, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548, 0.1197858601808548]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.1197858601808548, -0.04625363647937775, 0.027278587222099304, 0.10081081092357635, 0.1743430346250534, 0.24787525832653046, 0.3214074969291687, 0.39493972063064575, 0.4684719443321228, 0.5420041680335999, 0.6155363917350769, 0.689068615436554, 0.762600839138031, 0.8361330628395081, 0.9096652865409851, 0.9831975102424622, 1.0567296743392944, 1.1302618980407715, 1.2037941217422485, 1.2773263454437256, 1.3508585691452026, 1.4243907928466797, 1.4979230165481567, 1.5714552402496338, 1.6449874639511108, 1.718519687652588, 1.792051911354065, 1.865584135055542, 1.939116358757019, 2.012648582458496, 2.0861809253692627, 2.1597132682800293, 2.233245372772217, 2.3067774772644043, 2.380309820175171, 2.4538421630859375, 2.527374267578125, 2.6009063720703125, 2.674438714981079, 2.7479710578918457, 2.821503162384033, 2.8950352668762207, 2.9685676097869873, 3.042099952697754, 3.1156320571899414, 3.189164161682129, 3.2626965045928955, 3.336228847503662, 3.4097609519958496, 3.483293056488037, 3.5568253993988037, 3.6303577423095703, 3.703889846801758, 3.7774219512939453, 3.850954294204712, 3.9244866371154785, 3.998018741607666, 4.0715508460998535, 4.145082950592041, 4.218615531921387, 4.292147636413574, 4.365679740905762, 4.439212322235107, 4.512744426727295, 4.586276531219482]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-9.356799779425273e-10, 0.0012952701654285192, 0.002590541262179613, 0.003885812358930707, 0.005181083455681801, 0.006476354785263538, 0.007771625649183989, 0.009066896513104439, 0.010362167842686176, 0.011657439172267914, 0.012952710501849651, 0.014247980900108814, 0.015543252229690552, 0.016838522627949715, 0.018133793026208878, 0.01942906528711319, 0.020724335685372353, 0.022019606083631516, 0.023314878344535828, 0.02461014874279499, 0.025905421003699303, 0.027200691401958466, 0.02849596180021763, 0.02979123406112194, 0.031086504459381104, 0.032381776720285416, 0.03367704898118973, 0.03497232124209404, 0.036267589777708054, 0.037562862038612366, 0.03885813429951668, 0.04015340283513069, 0.041448675096035004, 0.042743947356939316, 0.04403921589255333, 0.04533448815345764, 0.046629760414361954, 0.04792502894997597, 0.04922030121088028, 0.05051557347178459, 0.051810845732688904, 0.05310611426830292, 0.05440138652920723, 0.05569665879011154, 0.056991927325725555, 0.05828719958662987, 0.05958247184753418, 0.06087774038314819, 0.062173012644052505, 0.06346828490495682, 0.06476355344057083, 0.06605882942676544, 0.06735409796237946, 0.06864936649799347, 0.06994464248418808, 0.0712399110198021, 0.07253517955541611, 0.07383045554161072, 0.07512572407722473, 0.07642099261283875, 0.07771626859903336, 0.07901153713464737, 0.08030680567026138, 0.081602081656456, 0.08289735019207001]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 5.0, 8.0, 7.0, 4.0, 5.0, 5.0, 7.0, 10.0, 4.0, 6.0, 14.0, 7.0, 10.0, 5.0, 8.0, 5.0, 2.0, 0.0, 0.0, 224.0, 0.0, 3.0, 5.0, 3.0, 5.0, 8.0, 6.0, 6.0, 8.0, 7.0, 5.0, 5.0, 9.0, 7.0, 4.0, 1.0, 7.0, 6.0, 7.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 5.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 6.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0], "bins": [-0.07125898450613022, -0.06779851764440536, -0.06433804333209991, -0.06087757647037506, -0.05741710960865021, -0.053956642746925354, -0.0504961721599102, -0.04703570157289505, -0.0435752347111702, -0.04011476784944534, -0.03665429726243019, -0.03319382667541504, -0.029733359813690186, -0.026272892951965332, -0.02281242236495018, -0.019351951777935028, -0.015891484916210175, -0.012431018054485321, -0.008970547467470169, -0.005510076880455017, -0.0020496100187301636, 0.00141085684299469, 0.00487133115530014, 0.008331798017024994, 0.011792264878749847, 0.015252731740474701, 0.018713198602199554, 0.022173672914505005, 0.02563413977622986, 0.029094606637954712, 0.03255508095026016, 0.036015547811985016, 0.03947601467370987, 0.04293648153543472, 0.046396948397159576, 0.04985742270946503, 0.05331788957118988, 0.05677836388349533, 0.060238830745220184, 0.06369929760694504, 0.06715976446866989, 0.07062023133039474, 0.0740806981921196, 0.07754116505384445, 0.0810016468167305, 0.08446211367845535, 0.0879225805401802, 0.09138304740190506, 0.09484351426362991, 0.09830398112535477, 0.10176444798707962, 0.10522491484880447, 0.10868538171052933, 0.11214586347341537, 0.11560633033514023, 0.11906679719686508, 0.12252726405858994, 0.12598773837089539, 0.12944820523262024, 0.1329086720943451, 0.13636913895606995, 0.1398296058177948, 0.14329007267951965, 0.1467505395412445, 0.15021100640296936]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.2703199088573456, -0.25266748666763306, -0.23501509428024292, -0.2173626720905304, -0.19971027970314026, -0.18205785751342773, -0.1644054502248764, -0.14675304293632507, -0.12910063564777374, -0.11144822835922241, -0.09379582107067108, -0.07614341378211975, -0.05849099159240723, -0.040838584303855896, -0.023186177015304565, -0.005533784627914429, 0.012118637561798096, 0.02977105975151062, 0.04742345213890076, 0.06507587432861328, 0.08272826671600342, 0.10038068890571594, 0.11803308129310608, 0.1356855034828186, 0.15333792567253113, 0.17099031805992126, 0.1886427402496338, 0.20629513263702393, 0.22394755482673645, 0.2415999472141266, 0.2592523396015167, 0.27690479159355164, 0.2945571839809418, 0.3122095763683319, 0.3298620283603668, 0.34751442074775696, 0.3651668131351471, 0.38281920552253723, 0.40047165751457214, 0.4181240499019623, 0.4357764422893524, 0.45342889428138733, 0.47108128666877747, 0.4887336790561676, 0.5063860416412354, 0.524038553237915, 0.5416909456253052, 0.5593433380126953, 0.5769957304000854, 0.5946481227874756, 0.6123005151748657, 0.6299529075622559, 0.6476054191589355, 0.6652578115463257, 0.6829102039337158, 0.700562596321106, 0.7182149887084961, 0.7358673810958862, 0.7535197734832764, 0.7711721658706665, 0.7888245582580566, 0.8064770698547363, 0.8241294622421265, 0.8417818546295166, 0.8594342470169067]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 13.0, 3.0, 9.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.09626813977956772, -0.08985788375139236, -0.08344762027263641, -0.07703736424446106, -0.0706271082162857, -0.06421684473752975, -0.0578065887093544, -0.05139632895588875, -0.044986069202423096, -0.03857580944895744, -0.03216554969549179, -0.025755293667316437, -0.019345037639141083, -0.012934774160385132, -0.006524518132209778, -0.0001142546534538269, 0.006296001374721527, 0.012706257402896881, 0.019116520881652832, 0.025526776909828186, 0.03193704038858414, 0.03834729641675949, 0.044757552444934845, 0.0511678084731102, 0.05757806450128555, 0.0639883354306221, 0.07039859145879745, 0.07680884748697281, 0.08321910351514816, 0.08962935954332352, 0.09603963047266006, 0.10244988650083542, 0.10886014252901077, 0.11527039855718613, 0.12168065458536148, 0.12809091806411743, 0.13450118899345398, 0.14091143012046814, 0.1473217010498047, 0.15373194217681885, 0.1601422131061554, 0.16655245423316956, 0.1729627251625061, 0.17937299609184265, 0.1857832372188568, 0.19219350814819336, 0.19860374927520752, 0.20501402020454407, 0.21142426133155823, 0.21783453226089478, 0.22424480319023132, 0.23065504431724548, 0.23706531524658203, 0.2434755563735962, 0.24988582730293274, 0.2562960982322693, 0.26270633935928345, 0.26911661028862, 0.27552685141563416, 0.2819371223449707, 0.28834739327430725, 0.2947576344013214, 0.30116790533065796, 0.3075781464576721, 0.31398841738700867]}, "_runtime": 5311.062947034836, "_timestamp": 1585602680.6958165, "_step": 198}
{"Episode reward": -99.5615982966018, "Episode length": 999, "Policy Loss": -0.5355589389801025, "Value Loss": 0.07615070790052414, "_runtime": 5312.152765035629, "_timestamp": 1585602681.7856345, "_step": 199}
{"Episode reward": 27.920363423181513, "Episode length": 722, "Policy Loss": 0.29922378063201904, "Value Loss": 12.932791709899902, "_runtime": 5313.689501047134, "_timestamp": 1585602683.3223705, "_step": 200}
{"Episode reward": -99.80884158464474, "Episode length": 999, "Policy Loss": -0.5141716599464417, "Value Loss": 0.0796922966837883, "_runtime": 5315.2374975681305, "_timestamp": 1585602684.870367, "_step": 201}
{"Episode reward": -99.45549206876174, "Episode length": 999, "Policy Loss": -0.5272713303565979, "Value Loss": 0.07689210772514343, "_runtime": 5315.7298312187195, "_timestamp": 1585602685.3627007, "_step": 202}
{"Episode reward": 69.89088408963273, "Episode length": 302, "Policy Loss": 1.4574309587478638, "Value Loss": 31.56815528869629, "_runtime": 5317.275571107864, "_timestamp": 1585602686.9084406, "_step": 203}
{"Episode reward": -99.60184215155758, "Episode length": 999, "Policy Loss": -0.49913346767425537, "Value Loss": 0.04023408889770508, "_runtime": 5318.831010818481, "_timestamp": 1585602688.4638803, "_step": 204}
{"Episode reward": -99.71669122944446, "Episode length": 999, "Policy Loss": -0.48605260252952576, "Value Loss": 0.05103934928774834, "_runtime": 5320.317099809647, "_timestamp": 1585602689.9499693, "_step": 205}
{"Episode reward": -99.79771649057372, "Episode length": 999, "Policy Loss": -0.4743276834487915, "Value Loss": 0.06845473498106003, "_runtime": 5321.883738517761, "_timestamp": 1585602691.516608, "_step": 206}
{"Episode reward": -99.66562814446958, "Episode length": 999, "Policy Loss": -0.4179820120334625, "Value Loss": 0.024128587916493416, "_runtime": 5323.446137189865, "_timestamp": 1585602693.0790067, "_step": 207}
{"Episode reward": -99.658097922917, "Episode length": 999, "Policy Loss": -0.39274394512176514, "Value Loss": 0.007179546169936657, "_runtime": 5325.016946554184, "_timestamp": 1585602694.649816, "_step": 208}
{"Episode reward": -99.8110163703547, "Episode length": 999, "Policy Loss": -0.3900337517261505, "Value Loss": 0.37211427092552185, "_runtime": 5326.5850303173065, "_timestamp": 1585602696.2178998, "_step": 209}
{"Episode reward": -99.7414892037618, "Episode length": 999, "Policy Loss": -0.276366263628006, "Value Loss": 0.026668230071663857, "_runtime": 5327.575548171997, "_timestamp": 1585602697.2084177, "_step": 210}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.7630060315132141, "Value Loss": 15.233550071716309, "_runtime": 5329.069624900818, "_timestamp": 1585602698.7024944, "_step": 211}
{"Episode reward": 3.790680253856152, "Episode length": 963, "Policy Loss": 0.4870019257068634, "Value Loss": 9.920509338378906, "_runtime": 5330.634421825409, "_timestamp": 1585602700.2672913, "_step": 212}
{"Episode reward": -99.58583773400031, "Episode length": 999, "Policy Loss": -0.22347839176654816, "Value Loss": 0.009697973728179932, "_runtime": 5332.158696174622, "_timestamp": 1585602701.7915657, "_step": 213}
{"Episode reward": -99.51566951589055, "Episode length": 999, "Policy Loss": -0.22846747934818268, "Value Loss": 0.011521738953888416, "_runtime": 5333.702291965485, "_timestamp": 1585602703.3351614, "_step": 214}
{"Episode reward": -99.81652545002149, "Episode length": 999, "Policy Loss": -0.2134590595960617, "Value Loss": 0.01193341612815857, "_runtime": 5335.2665803432465, "_timestamp": 1585602704.8994498, "_step": 215}
{"Episode reward": -99.77839476708183, "Episode length": 999, "Policy Loss": -0.20575907826423645, "Value Loss": 0.02616037055850029, "_runtime": 5336.556961774826, "_timestamp": 1585602706.1898313, "_step": 216}
{"Episode reward": 17.49913090444211, "Episode length": 827, "Policy Loss": 0.5282747745513916, "Value Loss": 11.824278831481934, "_runtime": 5338.102435588837, "_timestamp": 1585602707.735305, "_step": 217}
{"Episode reward": -99.80599601224391, "Episode length": 999, "Policy Loss": -0.20910795032978058, "Value Loss": 0.23457148671150208, "_runtime": 5338.747607946396, "_timestamp": 1585602708.3804774, "_step": 218}
{"Episode reward": 60.873349325661266, "Episode length": 394, "Policy Loss": 1.7085587978363037, "Value Loss": 24.05780601501465, "_runtime": 5339.923048257828, "_timestamp": 1585602709.5559177, "_step": 219}
{"Episode reward": 23.576928264345113, "Episode length": 768, "Policy Loss": 0.7105709910392761, "Value Loss": 12.386029243469238, "_runtime": 5341.47522354126, "_timestamp": 1585602711.108093, "_step": 220}
{"Episode reward": -99.54435343132216, "Episode length": 999, "Policy Loss": -0.20622898638248444, "Value Loss": 0.008064087480306625, "_runtime": 5342.976224184036, "_timestamp": 1585602712.6090937, "_step": 221}
{"Episode reward": -99.72038295382961, "Episode length": 999, "Policy Loss": -0.2306881546974182, "Value Loss": 0.011135761626064777, "_runtime": 5344.514671087265, "_timestamp": 1585602714.1475406, "_step": 222}
{"Episode reward": -99.72383448135085, "Episode length": 999, "Policy Loss": -0.2426835000514984, "Value Loss": 0.01695147342979908, "_runtime": 5346.026985406876, "_timestamp": 1585602715.659855, "_step": 223}
{"Episode reward": 2.382856285154233, "Episode length": 977, "Policy Loss": 0.3788353502750397, "Value Loss": 9.71058464050293, "_runtime": 5347.341095685959, "_timestamp": 1585602716.9739652, "_step": 224}
{"Episode reward": 14.696799146175024, "Episode length": 854, "Policy Loss": 0.48063212633132935, "Value Loss": 11.395541191101074, "_runtime": 5348.877494335175, "_timestamp": 1585602718.5103638, "_step": 225}
{"Episode reward": 3.890385391511984, "Episode length": 965, "Policy Loss": 0.3442125916481018, "Value Loss": 10.281628608703613, "_runtime": 5350.438679695129, "_timestamp": 1585602720.0715492, "_step": 226}
{"Episode reward": -99.80413838364043, "Episode length": 999, "Policy Loss": -0.26902762055397034, "Value Loss": 0.05622111260890961, "_runtime": 5351.974054813385, "_timestamp": 1585602721.6069243, "_step": 227}
{"Episode reward": -99.60558828695656, "Episode length": 999, "Policy Loss": -0.2676275968551636, "Value Loss": 0.040883589535951614, "_runtime": 5353.539838075638, "_timestamp": 1585602723.1727076, "_step": 228}
{"Episode reward": -99.76150423013465, "Episode length": 999, "Policy Loss": -0.24376995861530304, "Value Loss": 0.13737019896507263, "_runtime": 5355.089396476746, "_timestamp": 1585602724.722266, "_step": 229}
{"Episode reward": -99.64697425395578, "Episode length": 999, "Policy Loss": -0.2579687237739563, "Value Loss": 0.03793330118060112, "_runtime": 5355.767433166504, "_timestamp": 1585602725.4003026, "_step": 230}
{"Episode reward": 58.49947034772454, "Episode length": 417, "Policy Loss": 1.294052004814148, "Value Loss": 23.046382904052734, "_runtime": 5357.142332315445, "_timestamp": 1585602726.7752018, "_step": 231}
{"Episode reward": 12.743272918463433, "Episode length": 873, "Policy Loss": 0.39570167660713196, "Value Loss": 10.778828620910645, "_runtime": 5358.697242498398, "_timestamp": 1585602728.330112, "_step": 232}
{"Episode reward": -99.79145084861527, "Episode length": 999, "Policy Loss": -0.30926960706710815, "Value Loss": 0.013926802203059196, "_runtime": 5360.190197467804, "_timestamp": 1585602729.823067, "_step": 233}
{"Episode reward": -99.63365193917278, "Episode length": 999, "Policy Loss": -0.3354777693748474, "Value Loss": 0.018744273111224174, "_runtime": 5360.802015066147, "_timestamp": 1585602730.4348845, "_step": 234}
{"Episode reward": 61.77008262709106, "Episode length": 383, "Policy Loss": 1.4339972734451294, "Value Loss": 24.89434051513672, "_runtime": 5362.349884986877, "_timestamp": 1585602731.9827545, "_step": 235}
{"Episode reward": -99.73624587334204, "Episode length": 999, "Policy Loss": -0.39247867465019226, "Value Loss": 0.02228437550365925, "_runtime": 5363.888506889343, "_timestamp": 1585602733.5213764, "_step": 236}
{"Episode reward": -99.78283753828006, "Episode length": 999, "Policy Loss": -0.430796355009079, "Value Loss": 0.06348311901092529, "_runtime": 5364.4457993507385, "_timestamp": 1585602734.0786688, "_step": 237}
{"Episode reward": 63.25485224702837, "Episode length": 368, "Policy Loss": 1.3656387329101562, "Value Loss": 25.08062744140625, "_runtime": 5365.994755744934, "_timestamp": 1585602735.6276252, "_step": 238}
{"Episode reward": -99.56626408375311, "Episode length": 999, "Policy Loss": -0.5147433876991272, "Value Loss": 0.16567163169384003, "_runtime": 5367.157085895538, "_timestamp": 1585602736.7899554, "_step": 239}
{"Episode reward": 24.702671237150213, "Episode length": 755, "Policy Loss": 0.33695554733276367, "Value Loss": 12.546402931213379, "_runtime": 5368.6387593746185, "_timestamp": 1585602738.2716289, "_step": 240}
{"Episode reward": -99.42461829348913, "Episode length": 999, "Policy Loss": -0.48747292160987854, "Value Loss": 0.10310223698616028, "_runtime": 5369.501970529556, "_timestamp": 1585602739.13484, "_step": 241}
{"Episode reward": 45.24029032809144, "Episode length": 548, "Policy Loss": 0.5588627457618713, "Value Loss": 16.78016471862793, "_runtime": 5370.451750040054, "_timestamp": 1585602740.0846195, "_step": 242}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.3915248215198517, "Value Loss": 15.934499740600586, "_runtime": 5371.366529941559, "_timestamp": 1585602740.9993994, "_step": 243}
{"Episode reward": 42.94238454324606, "Episode length": 571, "Policy Loss": 0.4872305691242218, "Value Loss": 16.64989471435547, "_runtime": 5372.861561059952, "_timestamp": 1585602742.4944305, "_step": 244}
{"Episode reward": -99.79184889106406, "Episode length": 999, "Policy Loss": -0.5933610200881958, "Value Loss": 0.06545552611351013, "_runtime": 5374.279229402542, "_timestamp": 1585602743.912099, "_step": 245}
{"Episode reward": 6.933645431023166, "Episode length": 932, "Policy Loss": 0.35067683458328247, "Value Loss": 10.55374526977539, "_runtime": 5375.603121042252, "_timestamp": 1585602745.2359905, "_step": 246}
{"Episode reward": 12.192545706942454, "Episode length": 879, "Policy Loss": 0.19627124071121216, "Value Loss": 11.11007308959961, "_runtime": 5376.610801696777, "_timestamp": 1585602746.2436712, "_step": 247}
{"Episode reward": 35.76740275728454, "Episode length": 645, "Policy Loss": 0.46204331517219543, "Value Loss": 14.80964183807373, "_runtime": 5378.159389257431, "_timestamp": 1585602747.7922587, "_step": 248}
{"Episode reward": -99.80876733159973, "Episode length": 999, "Policy Loss": -0.47375166416168213, "Value Loss": 0.07039626687765121, "_runtime": 5379.6046760082245, "_timestamp": 1585602749.2375455, "_step": 249}
{"Episode reward": 6.801931500063361, "Episode length": 932, "Policy Loss": 0.1776576191186905, "Value Loss": 10.218619346618652, "_runtime": 5380.888664484024, "_timestamp": 1585602750.521534, "_step": 250}
{"Episode reward": 15.692240685155184, "Episode length": 845, "Policy Loss": 0.3605782985687256, "Value Loss": 11.19316291809082, "_runtime": 5382.4290244579315, "_timestamp": 1585602752.061894, "_step": 251}
{"Episode reward": -99.70721323902113, "Episode length": 999, "Policy Loss": -0.3363826870918274, "Value Loss": 0.34498724341392517, "_runtime": 5383.957522153854, "_timestamp": 1585602753.5903916, "_step": 252}
{"Episode reward": -99.5935449521742, "Episode length": 999, "Policy Loss": -0.26328787207603455, "Value Loss": 0.009546676650643349, "_runtime": 5384.910876274109, "_timestamp": 1585602754.5437458, "_step": 253}
{"Episode reward": 38.668691521789285, "Episode length": 614, "Policy Loss": 0.7105845808982849, "Value Loss": 16.58194923400879, "_runtime": 5386.451390504837, "_timestamp": 1585602756.08426, "_step": 254}
{"Episode reward": -99.66717079417292, "Episode length": 999, "Policy Loss": -0.18227741122245789, "Value Loss": 0.01887943595647812, "_runtime": 5387.995286941528, "_timestamp": 1585602757.6281564, "_step": 255}
{"Episode reward": -99.60237109490998, "Episode length": 999, "Policy Loss": -0.15532557666301727, "Value Loss": 0.028933262452483177, "_runtime": 5388.706885576248, "_timestamp": 1585602758.339755, "_step": 256}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 1.5843250751495361, "Value Loss": 21.39023780822754, "_runtime": 5390.142428159714, "_timestamp": 1585602759.7752976, "_step": 257}
{"Episode reward": 7.371265583858886, "Episode length": 928, "Policy Loss": 0.4954080879688263, "Value Loss": 10.636962890625, "_runtime": 5390.729675531387, "_timestamp": 1585602760.362545, "_step": 258}
{"Episode reward": 63.70253211497305, "Episode length": 364, "Policy Loss": 1.411676049232483, "Value Loss": 26.87412452697754, "_runtime": 5392.238642692566, "_timestamp": 1585602761.8715122, "_step": 259}
{"Episode reward": -99.58200299446332, "Episode length": 999, "Policy Loss": -0.47666531801223755, "Value Loss": 0.005691045429557562, "_runtime": 5393.779667854309, "_timestamp": 1585602763.4125373, "_step": 260}
{"Episode reward": -99.63756632141748, "Episode length": 999, "Policy Loss": -0.6055833101272583, "Value Loss": 0.016266537830233574, "_runtime": 5395.213823318481, "_timestamp": 1585602764.8466928, "_step": 261}
{"Episode reward": 5.824803255476198, "Episode length": 943, "Policy Loss": -0.03392166644334793, "Value Loss": 10.304280281066895, "_runtime": 5396.752899169922, "_timestamp": 1585602766.3857687, "_step": 262}
{"Episode reward": -99.61135013375757, "Episode length": 999, "Policy Loss": -0.8596556186676025, "Value Loss": 0.12856683135032654, "_runtime": 5398.303538799286, "_timestamp": 1585602767.9364083, "_step": 263}
{"Episode reward": -99.68303637886281, "Episode length": 999, "Policy Loss": -0.9164928197860718, "Value Loss": 0.04278445243835449, "_runtime": 5399.783883571625, "_timestamp": 1585602769.416753, "_step": 264}
{"Episode reward": 2.799195823237625, "Episode length": 973, "Policy Loss": -0.38290730118751526, "Value Loss": 9.803220748901367, "_runtime": 5401.339235782623, "_timestamp": 1585602770.9721053, "_step": 265}
{"Episode reward": -99.58132894618764, "Episode length": 999, "Policy Loss": -1.0000267028808594, "Value Loss": 0.05212020128965378, "_runtime": 5402.883348464966, "_timestamp": 1585602772.516218, "_step": 266}
{"Episode reward": -99.80056131044263, "Episode length": 999, "Policy Loss": -1.0224452018737793, "Value Loss": 0.03849523141980171, "_runtime": 5404.421757698059, "_timestamp": 1585602774.0546272, "_step": 267}
{"Episode reward": -99.63772889829568, "Episode length": 999, "Policy Loss": -1.0052486658096313, "Value Loss": 0.11011801660060883, "_runtime": 5405.965220451355, "_timestamp": 1585602775.59809, "_step": 268}
{"Episode reward": -99.77987159611519, "Episode length": 999, "Policy Loss": -0.968839168548584, "Value Loss": 0.029366597533226013, "_runtime": 5406.972699642181, "_timestamp": 1585602776.6055691, "_step": 269}
{"Episode reward": 36.00047887718475, "Episode length": 643, "Policy Loss": -0.021224163472652435, "Value Loss": 14.838887214660645, "_runtime": 5408.5069444179535, "_timestamp": 1585602778.139814, "_step": 270}
{"Episode reward": -99.80188376505255, "Episode length": 999, "Policy Loss": -0.8765444159507751, "Value Loss": 0.030060742050409317, "_runtime": 5408.95498418808, "_timestamp": 1585602778.5878537, "_step": 271}
{"Episode reward": 73.6999999999999, "Episode length": 263, "Policy Loss": 1.554145336151123, "Value Loss": 35.92939376831055, "_runtime": 5410.4927043914795, "_timestamp": 1585602780.1255739, "_step": 272}
{"Episode reward": -99.64957409598726, "Episode length": 999, "Policy Loss": -0.8027359843254089, "Value Loss": 0.027945561334490776, "_runtime": 5412.03714299202, "_timestamp": 1585602781.6700125, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7803646922111511, "Value Loss": 0.02510768733918667, "_runtime": 5413.512941122055, "_timestamp": 1585602783.1458106, "_step": 274}
{"Episode reward": -99.7414874488474, "Episode length": 999, "Policy Loss": -0.7442910671234131, "Value Loss": 0.02444756031036377, "_runtime": 5414.926663637161, "_timestamp": 1585602784.559533, "_step": 275}
{"Episode reward": 9.227318690945111, "Episode length": 910, "Policy Loss": -0.12940290570259094, "Value Loss": 10.682724952697754, "_runtime": 5415.839280128479, "_timestamp": 1585602785.4721496, "_step": 276}
{"Episode reward": 41.69999999999945, "Episode length": 583, "Policy Loss": 0.15656454861164093, "Value Loss": 15.803370475769043, "_runtime": 5416.594921827316, "_timestamp": 1585602786.2277913, "_step": 277}
{"Episode reward": 51.44047835883643, "Episode length": 488, "Policy Loss": 0.2733929753303528, "Value Loss": 19.368284225463867, "_runtime": 5418.17592549324, "_timestamp": 1585602787.808795, "_step": 278}
{"Episode reward": -99.54719342149191, "Episode length": 999, "Policy Loss": -0.9657413363456726, "Value Loss": 0.027570690959692, "_runtime": 5419.6835696697235, "_timestamp": 1585602789.3164392, "_step": 279}
{"Episode reward": -99.81830320628221, "Episode length": 999, "Policy Loss": -0.923342227935791, "Value Loss": 0.2714221179485321, "_runtime": 5420.28914475441, "_timestamp": 1585602789.9220142, "_step": 280}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 0.5225550532341003, "Value Loss": 23.623661041259766, "_runtime": 5421.835487604141, "_timestamp": 1585602791.468357, "_step": 281}
{"Episode reward": -99.4586056163288, "Episode length": 999, "Policy Loss": -1.0152814388275146, "Value Loss": 0.04623345658183098, "_runtime": 5422.62682557106, "_timestamp": 1585602792.259695, "_step": 282}
{"Episode reward": 50.57167348861652, "Episode length": 495, "Policy Loss": 0.2641410529613495, "Value Loss": 19.1092472076416, "_runtime": 5424.123817920685, "_timestamp": 1585602793.7566874, "_step": 283}
{"Episode reward": -99.75050943542598, "Episode length": 999, "Policy Loss": -1.0177810192108154, "Value Loss": 0.07908385246992111, "_runtime": 5425.142252206802, "_timestamp": 1585602794.7751217, "_step": 284}
{"Episode reward": 35.640415009797394, "Episode length": 646, "Policy Loss": -0.1332043707370758, "Value Loss": 14.79335880279541, "_runtime": 5426.655808925629, "_timestamp": 1585602796.2886784, "_step": 285}
{"Episode reward": -99.79444602525187, "Episode length": 999, "Policy Loss": -0.8844707012176514, "Value Loss": 0.11952600628137589, "_runtime": 5427.584559679031, "_timestamp": 1585602797.2174292, "_step": 286}
{"Episode reward": 40.99994872473124, "Episode length": 591, "Policy Loss": 0.2682661712169647, "Value Loss": 15.488364219665527, "_runtime": 5429.029963493347, "_timestamp": 1585602798.662833, "_step": 287}
{"Episode reward": 5.445729807532558, "Episode length": 948, "Policy Loss": -0.07373791933059692, "Value Loss": 9.607845306396484, "_runtime": 5430.580031871796, "_timestamp": 1585602800.2129014, "_step": 288}
{"Episode reward": -99.80204854644695, "Episode length": 999, "Policy Loss": -0.7594462633132935, "Value Loss": 0.03686676174402237, "_runtime": 5430.9332954883575, "_timestamp": 1585602800.566165, "_step": 289}
{"Episode reward": 79.09999999999998, "Episode length": 209, "Policy Loss": 1.9042103290557861, "Value Loss": 43.74055099487305, "_runtime": 5432.475880622864, "_timestamp": 1585602802.10875, "_step": 290}
{"Episode reward": -99.58286743997459, "Episode length": 999, "Policy Loss": -1.089038372039795, "Value Loss": 0.0484384223818779, "_runtime": 5433.526082277298, "_timestamp": 1585602803.1589518, "_step": 291}
{"Episode reward": 33.38217423907433, "Episode length": 669, "Policy Loss": -0.38569384813308716, "Value Loss": 15.258668899536133, "_runtime": 5435.004353523254, "_timestamp": 1585602804.637223, "_step": 292}
{"Episode reward": -99.51697643257656, "Episode length": 999, "Policy Loss": -1.139510154724121, "Value Loss": 0.12199801206588745, "_runtime": 5436.2046048641205, "_timestamp": 1585602805.8374743, "_step": 293}
{"Episode reward": 22.605673979572146, "Episode length": 775, "Policy Loss": -0.2624524235725403, "Value Loss": 11.994462013244629, "_runtime": 5437.731304645538, "_timestamp": 1585602807.3641741, "_step": 294}
{"Episode reward": -99.55682564747846, "Episode length": 999, "Policy Loss": -0.8914672136306763, "Value Loss": 0.05606504902243614, "_runtime": 5439.270151853561, "_timestamp": 1585602808.9030213, "_step": 295}
{"Episode reward": -99.75957434298331, "Episode length": 999, "Policy Loss": -0.777321457862854, "Value Loss": 0.15203669667243958, "_runtime": 5440.806968450546, "_timestamp": 1585602810.439838, "_step": 296}
{"Episode reward": -99.55668230368617, "Episode length": 999, "Policy Loss": -0.6579726934432983, "Value Loss": 0.08930753916501999, "_runtime": 5441.727259635925, "_timestamp": 1585602811.360129, "_step": 297}
{"Episode reward": 44.1056579772145, "Episode length": 559, "Policy Loss": 0.5854337811470032, "Value Loss": 17.263349533081055, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044, 0.072084441781044]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], "bins": [-0.0720844566822052, -0.032655034214258194, 0.006774388253688812, 0.04620380699634552, 0.08563323318958282, 0.12506265938282013, 0.16449207067489624, 0.20392149686813354, 0.24335092306137085, 0.28278034925460815, 0.32220977544784546, 0.36163920164108276, 0.4010685980319977, 0.440498024225235, 0.4799274504184723, 0.5193568468093872, 0.5587862730026245, 0.5982156991958618, 0.6376451253890991, 0.6770745515823364, 0.7165039777755737, 0.755933403968811, 0.7953628301620483, 0.8347922563552856, 0.874221682548523, 0.9136511087417603, 0.9530805349349976, 0.9925099611282349, 1.0319393873214722, 1.0713688135147095, 1.1107982397079468, 1.150227665901184, 1.1896570920944214, 1.2290865182876587, 1.268515944480896, 1.3079453706741333, 1.3473747968673706, 1.386804223060608, 1.4262336492538452, 1.4656630754470825, 1.5050925016403198, 1.5445219278335571, 1.5839513540267944, 1.6233807802200317, 1.662810206413269, 1.7022396326065063, 1.7416690587997437, 1.781098484992981, 1.8205277919769287, 1.859957218170166, 1.8993866443634033, 1.9388160705566406, 1.978245496749878, 2.0176749229431152, 2.0571043491363525, 2.09653377532959, 2.135963201522827, 2.1753926277160645, 2.2148220539093018, 2.254251480102539, 2.2936809062957764, 2.3331103324890137, 2.372539758682251, 2.4119691848754883, 2.4513986110687256]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.269261719817678e-09, 0.0007886816747486591, 0.001577371614985168, 0.002366061322391033, 0.003154751379042864, 0.0039434414356946945, 0.004732131026685238, 0.0055208210833370686, 0.006309511139988899, 0.00709820119664073, 0.00788689125329256, 0.008675580844283104, 0.009464270435273647, 0.010252960957586765, 0.011041650548577309, 0.011830341070890427, 0.01261903066188097, 0.013407720252871513, 0.014196410775184631, 0.014985100366175175, 0.015773791819810867, 0.016562480479478836, 0.017351171001791954, 0.018139861524105072, 0.01892855018377304, 0.01971724070608616, 0.020505931228399277, 0.021294621750712395, 0.022083310410380363, 0.02287200093269348, 0.0236606914550066, 0.024449380114674568, 0.025238070636987686, 0.026026761159300804, 0.026815449818968773, 0.02760414034128189, 0.02839283086359501, 0.029181519523262978, 0.029970210045576096, 0.030758900567889214, 0.03154759109020233, 0.0323362797498703, 0.03312496840953827, 0.033913660794496536, 0.034702349454164505, 0.035491038113832474, 0.03627973049879074, 0.03706841915845871, 0.03785710781812668, 0.038645800203084946, 0.039434488862752914, 0.04022318124771118, 0.04101186990737915, 0.04180055856704712, 0.042589250952005386, 0.043377939611673355, 0.044166628271341324, 0.04495532065629959, 0.04574400931596756, 0.04653269797563553, 0.047321390360593796, 0.048110079020261765, 0.04889876767992973, 0.049687460064888, 0.05047614872455597]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 6.0, 5.0, 5.0, 8.0, 5.0, 2.0, 4.0, 5.0, 6.0, 8.0, 10.0, 10.0, 8.0, 8.0, 6.0, 8.0, 11.0, 3.0, 4.0, 2.0, 0.0, 233.0, 1.0, 2.0, 4.0, 4.0, 5.0, 4.0, 7.0, 7.0, 7.0, 4.0, 5.0, 5.0, 4.0, 7.0, 7.0, 2.0, 5.0, 6.0, 8.0, 3.0, 5.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0], "bins": [-0.043317608535289764, -0.041350577026605606, -0.03938354179263115, -0.03741651028394699, -0.03544947877526283, -0.033482447266578674, -0.03151541203260422, -0.02954838052392006, -0.02758134715259075, -0.025614313781261444, -0.023647282272577286, -0.021680248901247978, -0.01971321552991867, -0.017746184021234512, -0.015779150649905205, -0.013812119141221046, -0.011845085769891739, -0.00987805426120758, -0.007911019027233124, -0.0059439875185489655, -0.003976956009864807, -0.0020099207758903503, -4.2889267206192017e-05, 0.0019241422414779663, 0.003891177475452423, 0.005858208984136581, 0.00782524049282074, 0.009792272001504898, 0.011759307235479355, 0.013726338744163513, 0.01569337025284767, 0.01766040548682213, 0.019627436995506287, 0.021594472229480743, 0.023561500012874603, 0.02552853524684906, 0.027495570480823517, 0.029462598264217377, 0.031429633498191833, 0.03339666873216629, 0.03536369651556015, 0.03733073174953461, 0.039297766983509064, 0.041264794766902924, 0.04323183000087738, 0.04519886523485184, 0.0471658930182457, 0.049132928252220154, 0.05109996348619461, 0.05306699126958847, 0.05503402650356293, 0.05700105428695679, 0.058968089520931244, 0.0609351247549057, 0.06290215253829956, 0.06486918777227402, 0.06683622300624847, 0.06880325078964233, 0.07077028602361679, 0.07273732125759125, 0.07470434904098511, 0.07667138427495956, 0.07863841950893402, 0.08060544729232788, 0.08257248252630234]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.24590376019477844, -0.23351384699344635, -0.22112393379211426, -0.20873400568962097, -0.19634410738945007, -0.1839541792869568, -0.1715642660856247, -0.1591743528842926, -0.1467844396829605, -0.13439452648162842, -0.12200461328029633, -0.10961470007896423, -0.09722477197647095, -0.08483485877513885, -0.07244494557380676, -0.06005503237247467, -0.04766511917114258, -0.035275205969810486, -0.022885292768478394, -0.010495379567146301, 0.001894533634185791, 0.014284461736679077, 0.026674360036849976, 0.03906428813934326, 0.05145421624183655, 0.06384411454200745, 0.07623404264450073, 0.08862394094467163, 0.10101386904716492, 0.11340376734733582, 0.1257936954498291, 0.13818359375, 0.1505735218524933, 0.16296344995498657, 0.17535334825515747, 0.18774327635765076, 0.20013317465782166, 0.21252310276031494, 0.22491300106048584, 0.23730292916297913, 0.24969282746315002, 0.2620827853679657, 0.2744726836681366, 0.2868625819683075, 0.2992524802684784, 0.31164243817329407, 0.32403233647346497, 0.33642223477363586, 0.34881219267845154, 0.36120209097862244, 0.37359198927879333, 0.38598188757896423, 0.3983718454837799, 0.4107617437839508, 0.4231516420841217, 0.4355415403842926, 0.4479314982891083, 0.4603213965892792, 0.4727112948894501, 0.48510125279426575, 0.49749115109443665, 0.5098810195922852, 0.522270917892456, 0.5346609354019165, 0.5470508337020874]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 5.0, 7.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.1924298107624054, -0.1845381259918213, -0.176646426320076, -0.1687547266483307, -0.16086304187774658, -0.15297135710716248, -0.14507965743541718, -0.13718795776367188, -0.12929627299308777, -0.12140458077192307, -0.11351288855075836, -0.10562119632959366, -0.09772950410842896, -0.08983781188726425, -0.08194611966609955, -0.07405442744493484, -0.06616273522377014, -0.058271050453186035, -0.050379350781440735, -0.042487651109695435, -0.03459596633911133, -0.02670428156852722, -0.01881258189678192, -0.010920882225036621, -0.0030291974544525146, 0.004862487316131592, 0.012754186987876892, 0.020645886659622192, 0.0285375714302063, 0.036429256200790405, 0.044320955872535706, 0.052212655544281006, 0.06010434031486511, 0.06799602508544922, 0.07588770985603333, 0.08377942442893982, 0.09167110919952393, 0.09956279397010803, 0.10745450854301453, 0.11534619331359863, 0.12323787808418274, 0.13112956285476685, 0.13902124762535095, 0.14691296219825745, 0.15480464696884155, 0.16269633173942566, 0.17058804631233215, 0.17847973108291626, 0.18637141585350037, 0.19426310062408447, 0.20215478539466858, 0.21004649996757507, 0.21793818473815918, 0.2258298695087433, 0.23372158408164978, 0.2416132688522339, 0.249504953622818, 0.2573966383934021, 0.2652883231639862, 0.2731800377368927, 0.2810717225074768, 0.2889634072780609, 0.2968551218509674, 0.3047468066215515, 0.3126384913921356]}, "_runtime": 5443.2705063819885, "_timestamp": 1585602812.9033759, "_step": 298}
{"Episode reward": -99.6232053910601, "Episode length": 999, "Policy Loss": -0.491512268781662, "Value Loss": 0.07827312499284744, "_runtime": 5443.661488771439, "_timestamp": 1585602813.2943583, "_step": 299}
{"Episode reward": 78.29999999999997, "Episode length": 217, "Policy Loss": 2.373450994491577, "Value Loss": 42.13602066040039, "_runtime": 5445.187586545944, "_timestamp": 1585602814.820456, "_step": 300}
{"Episode reward": -99.80011713823629, "Episode length": 999, "Policy Loss": -0.41562461853027344, "Value Loss": 0.012502639554440975, "_runtime": 5446.722288370132, "_timestamp": 1585602816.3551579, "_step": 301}
{"Episode reward": -99.80011412883037, "Episode length": 999, "Policy Loss": -0.46582481265068054, "Value Loss": 0.12072852998971939, "_runtime": 5447.7096264362335, "_timestamp": 1585602817.342496, "_step": 302}
{"Episode reward": 33.33838498161592, "Episode length": 669, "Policy Loss": 0.4195231795310974, "Value Loss": 15.302300453186035, "_runtime": 5449.272358894348, "_timestamp": 1585602818.9052284, "_step": 303}
{"Episode reward": -99.60238898736286, "Episode length": 999, "Policy Loss": -0.4012947082519531, "Value Loss": 0.024331791326403618, "_runtime": 5450.813186168671, "_timestamp": 1585602820.4460557, "_step": 304}
{"Episode reward": -99.80739442279888, "Episode length": 999, "Policy Loss": -0.35148555040359497, "Value Loss": 0.019438350573182106, "_runtime": 5451.501315832138, "_timestamp": 1585602821.1341853, "_step": 305}
{"Episode reward": 55.799424424394616, "Episode length": 443, "Policy Loss": 1.2603307962417603, "Value Loss": 20.964588165283203, "_runtime": 5452.906729459763, "_timestamp": 1585602822.539599, "_step": 306}
{"Episode reward": 10.392263547238784, "Episode length": 898, "Policy Loss": 0.3693310618400574, "Value Loss": 10.412026405334473, "_runtime": 5454.081117153168, "_timestamp": 1585602823.7139866, "_step": 307}
{"Episode reward": 24.510020000394448, "Episode length": 755, "Policy Loss": 0.5664508938789368, "Value Loss": 12.478846549987793, "_runtime": 5455.578010320663, "_timestamp": 1585602825.2108798, "_step": 308}
{"Episode reward": -99.7503970212522, "Episode length": 999, "Policy Loss": -0.4575340747833252, "Value Loss": 0.045995987951755524, "_runtime": 5457.138371706009, "_timestamp": 1585602826.7712412, "_step": 309}
{"Episode reward": -99.81940253554355, "Episode length": 999, "Policy Loss": -0.5757837295532227, "Value Loss": 0.03651415929198265, "_runtime": 5458.2946763038635, "_timestamp": 1585602827.9275458, "_step": 310}
{"Episode reward": 24.882853133603916, "Episode length": 752, "Policy Loss": 0.13896457850933075, "Value Loss": 11.975744247436523, "_runtime": 5459.7914299964905, "_timestamp": 1585602829.4242995, "_step": 311}
{"Episode reward": 2.3728130800138416, "Episode length": 979, "Policy Loss": -0.09465570747852325, "Value Loss": 9.414329528808594, "_runtime": 5460.89218711853, "_timestamp": 1585602830.5250566, "_step": 312}
{"Episode reward": 30.35621197626429, "Episode length": 699, "Policy Loss": 0.07394614070653915, "Value Loss": 14.460511207580566, "_runtime": 5462.426469087601, "_timestamp": 1585602832.0593386, "_step": 313}
{"Episode reward": -99.76136764550908, "Episode length": 999, "Policy Loss": -0.6505215167999268, "Value Loss": 0.05804518610239029, "_runtime": 5463.960608243942, "_timestamp": 1585602833.5934777, "_step": 314}
{"Episode reward": -99.84453061355605, "Episode length": 999, "Policy Loss": -0.5126151442527771, "Value Loss": 0.08746816217899323, "_runtime": 5465.497058391571, "_timestamp": 1585602835.1299279, "_step": 315}
{"Episode reward": -99.81859318187786, "Episode length": 999, "Policy Loss": -0.4006418287754059, "Value Loss": 0.08976024389266968, "_runtime": 5466.764724731445, "_timestamp": 1585602836.3975942, "_step": 316}
{"Episode reward": 19.326926161884643, "Episode length": 808, "Policy Loss": 0.49666741490364075, "Value Loss": 11.6046724319458, "_runtime": 5468.352188587189, "_timestamp": 1585602837.985058, "_step": 317}
{"Episode reward": -99.77666909217812, "Episode length": 999, "Policy Loss": -0.19275535643100739, "Value Loss": 0.028345564380288124, "_runtime": 5469.346951723099, "_timestamp": 1585602838.9798212, "_step": 318}
{"Episode reward": 37.800120432534584, "Episode length": 625, "Policy Loss": 1.014762043952942, "Value Loss": 15.485982894897461, "_runtime": 5470.892768621445, "_timestamp": 1585602840.525638, "_step": 319}
{"Episode reward": -99.74235531689926, "Episode length": 999, "Policy Loss": -0.11970806121826172, "Value Loss": 0.006334585603326559, "_runtime": 5472.4459500312805, "_timestamp": 1585602842.0788195, "_step": 320}
{"Episode reward": -99.86102561987796, "Episode length": 999, "Policy Loss": -0.12866707146167755, "Value Loss": 0.006498770788311958, "_runtime": 5473.842904806137, "_timestamp": 1585602843.4757743, "_step": 321}
{"Episode reward": 8.5370692269653, "Episode length": 915, "Policy Loss": 0.5902917981147766, "Value Loss": 10.346795082092285, "_runtime": 5475.403327703476, "_timestamp": 1585602845.0361972, "_step": 322}
{"Episode reward": -99.70070320071979, "Episode length": 999, "Policy Loss": -0.16477994620800018, "Value Loss": 0.01290071289986372, "_runtime": 5476.762481212616, "_timestamp": 1585602846.3953507, "_step": 323}
{"Episode reward": 12.695117775223451, "Episode length": 879, "Policy Loss": 0.44374656677246094, "Value Loss": 11.062885284423828, "_runtime": 5477.887633085251, "_timestamp": 1585602847.5205026, "_step": 324}
{"Episode reward": 27.36663005640716, "Episode length": 727, "Policy Loss": 0.632887065410614, "Value Loss": 12.981607437133789, "_runtime": 5479.445412397385, "_timestamp": 1585602849.0782819, "_step": 325}
{"Episode reward": -99.80191791392723, "Episode length": 999, "Policy Loss": -0.33974021673202515, "Value Loss": 0.005424757953733206, "_runtime": 5480.99475812912, "_timestamp": 1585602850.6276276, "_step": 326}
{"Episode reward": -99.64888438717324, "Episode length": 999, "Policy Loss": -0.41257351636886597, "Value Loss": 0.009104667231440544, "_runtime": 5482.527113437653, "_timestamp": 1585602852.159983, "_step": 327}
{"Episode reward": -99.77323788504442, "Episode length": 999, "Policy Loss": -0.45684435963630676, "Value Loss": 0.06245308741927147, "_runtime": 5483.8318428993225, "_timestamp": 1585602853.4647124, "_step": 328}
{"Episode reward": 16.59058513056999, "Episode length": 837, "Policy Loss": 0.2153816521167755, "Value Loss": 11.264840126037598, "_runtime": 5485.388710260391, "_timestamp": 1585602855.0215797, "_step": 329}
{"Episode reward": -99.71025043495327, "Episode length": 999, "Policy Loss": -0.5288323760032654, "Value Loss": 0.14368104934692383, "_runtime": 5486.948351621628, "_timestamp": 1585602856.581221, "_step": 330}
{"Episode reward": -99.63904769723165, "Episode length": 999, "Policy Loss": -0.5595788955688477, "Value Loss": 0.033648524433374405, "_runtime": 5488.030547857285, "_timestamp": 1585602857.6634173, "_step": 331}
{"Episode reward": 30.85466750988236, "Episode length": 692, "Policy Loss": 0.27209189534187317, "Value Loss": 12.893719673156738, "_runtime": 5489.584872961044, "_timestamp": 1585602859.2177424, "_step": 332}
{"Episode reward": -99.71135661240993, "Episode length": 999, "Policy Loss": -0.5438160300254822, "Value Loss": 0.012480323202908039, "_runtime": 5491.185659170151, "_timestamp": 1585602860.8185287, "_step": 333}
{"Episode reward": -99.85447663462115, "Episode length": 999, "Policy Loss": -0.5514488220214844, "Value Loss": 0.14193256199359894, "_runtime": 5492.716015815735, "_timestamp": 1585602862.3488853, "_step": 334}
{"Episode reward": -99.71662175914248, "Episode length": 999, "Policy Loss": -0.5215217471122742, "Value Loss": 0.0937182605266571, "_runtime": 5493.630814790726, "_timestamp": 1585602863.2636843, "_step": 335}
{"Episode reward": 41.82356538097319, "Episode length": 583, "Policy Loss": 0.4302261769771576, "Value Loss": 15.300209999084473, "_runtime": 5494.998601913452, "_timestamp": 1585602864.6314714, "_step": 336}
{"Episode reward": 12.465206872439708, "Episode length": 877, "Policy Loss": 0.07433167099952698, "Value Loss": 11.405902862548828, "_runtime": 5496.551867246628, "_timestamp": 1585602866.1847367, "_step": 337}
{"Episode reward": -99.71924762476563, "Episode length": 999, "Policy Loss": -0.5895928144454956, "Value Loss": 0.08458263427019119, "_runtime": 5498.054035902023, "_timestamp": 1585602867.6869054, "_step": 338}
{"Episode reward": -99.5590113123865, "Episode length": 999, "Policy Loss": -0.5919189453125, "Value Loss": 0.08706070482730865, "_runtime": 5498.561069011688, "_timestamp": 1585602868.1939385, "_step": 339}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 1.6726130247116089, "Value Loss": 31.234590530395508, "_runtime": 5499.365328788757, "_timestamp": 1585602868.9981983, "_step": 340}
{"Episode reward": 48.862544725922184, "Episode length": 512, "Policy Loss": 0.7313547134399414, "Value Loss": 18.49736785888672, "_runtime": 5500.403813123703, "_timestamp": 1585602870.0366826, "_step": 341}
{"Episode reward": 33.22826746706802, "Episode length": 670, "Policy Loss": 0.4705636501312256, "Value Loss": 14.231900215148926, "_runtime": 5501.256217002869, "_timestamp": 1585602870.8890865, "_step": 342}
{"Episode reward": 42.99405703152826, "Episode length": 571, "Policy Loss": 0.45113563537597656, "Value Loss": 16.019495010375977, "_runtime": 5502.312422990799, "_timestamp": 1585602871.9452925, "_step": 343}
{"Episode reward": 30.064604367199053, "Episode length": 701, "Policy Loss": 0.34150373935699463, "Value Loss": 13.056023597717285, "_runtime": 5503.4744527339935, "_timestamp": 1585602873.1073222, "_step": 344}
{"Episode reward": 23.57281519660617, "Episode length": 766, "Policy Loss": 0.07548875361680984, "Value Loss": 11.895724296569824, "_runtime": 5504.919826030731, "_timestamp": 1585602874.5526955, "_step": 345}
{"Episode reward": 3.5441348472389365, "Episode length": 965, "Policy Loss": -0.054531145840883255, "Value Loss": 9.295708656311035, "_runtime": 5505.28008890152, "_timestamp": 1585602874.9129584, "_step": 346}
{"Episode reward": 78.90880006467921, "Episode length": 211, "Policy Loss": 1.907558798789978, "Value Loss": 42.84709167480469, "_runtime": 5506.807771444321, "_timestamp": 1585602876.440641, "_step": 347}
{"Episode reward": -99.7196332359207, "Episode length": 999, "Policy Loss": -0.919584333896637, "Value Loss": 0.7451338768005371, "_runtime": 5508.039388895035, "_timestamp": 1585602877.6722584, "_step": 348}
{"Episode reward": 19.959345135273452, "Episode length": 801, "Policy Loss": -0.1523587554693222, "Value Loss": 12.41714859008789, "_runtime": 5509.513835668564, "_timestamp": 1585602879.1467052, "_step": 349}
{"Episode reward": -99.60446926252777, "Episode length": 999, "Policy Loss": -0.946356475353241, "Value Loss": 0.1404891014099121, "_runtime": 5511.078488111496, "_timestamp": 1585602880.7113576, "_step": 350}
{"Episode reward": -99.52287322447962, "Episode length": 999, "Policy Loss": -0.9072701334953308, "Value Loss": 0.19763970375061035, "_runtime": 5511.906418323517, "_timestamp": 1585602881.5392878, "_step": 351}
{"Episode reward": 47.16946877753315, "Episode length": 530, "Policy Loss": 0.7434412837028503, "Value Loss": 16.81753158569336, "_runtime": 5512.776172637939, "_timestamp": 1585602882.4090421, "_step": 352}
{"Episode reward": 44.0564149293112, "Episode length": 561, "Policy Loss": 0.4132336676120758, "Value Loss": 16.713748931884766, "_runtime": 5513.62171459198, "_timestamp": 1585602883.254584, "_step": 353}
{"Episode reward": 46.97329347268049, "Episode length": 531, "Policy Loss": 0.6128494143486023, "Value Loss": 17.596378326416016, "_runtime": 5515.176911354065, "_timestamp": 1585602884.8097808, "_step": 354}
{"Episode reward": -99.85438207278354, "Episode length": 999, "Policy Loss": -0.3791663646697998, "Value Loss": 0.14564664661884308, "_runtime": 5515.785759925842, "_timestamp": 1585602885.4186294, "_step": 355}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.1658132076263428, "Value Loss": 22.802303314208984, "_runtime": 5517.284196853638, "_timestamp": 1585602886.9170663, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38840046525001526, "Value Loss": 0.0929068848490715, "_runtime": 5518.043590068817, "_timestamp": 1585602887.6764596, "_step": 357}
{"Episode reward": 52.51257211758599, "Episode length": 476, "Policy Loss": 0.623300313949585, "Value Loss": 19.021093368530273, "_runtime": 5519.361788034439, "_timestamp": 1585602888.9946575, "_step": 358}
{"Episode reward": 12.205640915688832, "Episode length": 879, "Policy Loss": 0.00421286653727293, "Value Loss": 10.4705171585083, "_runtime": 5520.693948984146, "_timestamp": 1585602890.3268185, "_step": 359}
{"Episode reward": 13.747778286925211, "Episode length": 865, "Policy Loss": -0.22629867494106293, "Value Loss": 11.078210830688477, "_runtime": 5522.192365884781, "_timestamp": 1585602891.8252354, "_step": 360}
{"Episode reward": -99.66563261365378, "Episode length": 999, "Policy Loss": -1.0357195138931274, "Value Loss": 0.055201705545186996, "_runtime": 5523.723939418793, "_timestamp": 1585602893.356809, "_step": 361}
{"Episode reward": -99.56202915499314, "Episode length": 999, "Policy Loss": -1.1051201820373535, "Value Loss": 0.09983305633068085, "_runtime": 5525.2648549079895, "_timestamp": 1585602894.8977244, "_step": 362}
{"Episode reward": -99.73212903917162, "Episode length": 999, "Policy Loss": -1.1836752891540527, "Value Loss": 0.23208321630954742, "_runtime": 5526.801952362061, "_timestamp": 1585602896.4348218, "_step": 363}
{"Episode reward": -99.61437467813819, "Episode length": 999, "Policy Loss": -0.8819220066070557, "Value Loss": 0.09177471697330475, "_runtime": 5528.213274717331, "_timestamp": 1585602897.8461442, "_step": 364}
{"Episode reward": 9.243604581105473, "Episode length": 911, "Policy Loss": 0.18456022441387177, "Value Loss": 9.763648986816406, "_runtime": 5529.763149023056, "_timestamp": 1585602899.3960185, "_step": 365}
{"Episode reward": -99.85091271931165, "Episode length": 999, "Policy Loss": -0.41404542326927185, "Value Loss": 0.03860548883676529, "_runtime": 5531.318648099899, "_timestamp": 1585602900.9515176, "_step": 366}
{"Episode reward": -99.80322855654966, "Episode length": 999, "Policy Loss": -0.17964307963848114, "Value Loss": 0.17465046048164368, "_runtime": 5532.87188577652, "_timestamp": 1585602902.5047553, "_step": 367}
{"Episode reward": -99.8920324269901, "Episode length": 999, "Policy Loss": 0.014654283411800861, "Value Loss": 0.6949060559272766, "_runtime": 5533.910532236099, "_timestamp": 1585602903.5434017, "_step": 368}
{"Episode reward": 34.34309029146043, "Episode length": 658, "Policy Loss": 1.0125036239624023, "Value Loss": 15.194052696228027, "_runtime": 5535.464493274689, "_timestamp": 1585602905.0973628, "_step": 369}
{"Episode reward": -99.72830264014053, "Episode length": 999, "Policy Loss": 0.08957859128713608, "Value Loss": 0.10565407574176788, "_runtime": 5536.928114891052, "_timestamp": 1585602906.5609844, "_step": 370}
{"Episode reward": 6.509736757493684, "Episode length": 936, "Policy Loss": 0.7567359805107117, "Value Loss": 10.234130859375, "_runtime": 5538.318689584732, "_timestamp": 1585602907.951559, "_step": 371}
{"Episode reward": 12.000000000000725, "Episode length": 880, "Policy Loss": 0.8341307640075684, "Value Loss": 10.773883819580078, "_runtime": 5539.875487327576, "_timestamp": 1585602909.5083568, "_step": 372}
{"Episode reward": -99.69016802527919, "Episode length": 999, "Policy Loss": -0.013193060643970966, "Value Loss": 0.22934137284755707, "_runtime": 5541.418203353882, "_timestamp": 1585602911.0510728, "_step": 373}
{"Episode reward": -99.79603892837046, "Episode length": 999, "Policy Loss": -0.07634402811527252, "Value Loss": 0.0823320597410202, "_runtime": 5542.957749128342, "_timestamp": 1585602912.5906186, "_step": 374}
{"Episode reward": -99.76338178203302, "Episode length": 999, "Policy Loss": -0.08687081187963486, "Value Loss": 0.01846454106271267, "_runtime": 5544.50740647316, "_timestamp": 1585602914.140276, "_step": 375}
{"Episode reward": -99.516421310253, "Episode length": 999, "Policy Loss": -0.1388469785451889, "Value Loss": 0.006914336699992418, "_runtime": 5545.508063554764, "_timestamp": 1585602915.140933, "_step": 376}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.76396244764328, "Value Loss": 14.953595161437988, "_runtime": 5546.833254575729, "_timestamp": 1585602916.466124, "_step": 377}
{"Episode reward": 15.089455543435733, "Episode length": 850, "Policy Loss": 0.664979100227356, "Value Loss": 11.28175163269043, "_runtime": 5548.081069231033, "_timestamp": 1585602917.7139387, "_step": 378}
{"Episode reward": 20.100000000000264, "Episode length": 799, "Policy Loss": 0.7322324514389038, "Value Loss": 11.71528148651123, "_runtime": 5549.589422464371, "_timestamp": 1585602919.222292, "_step": 379}
{"Episode reward": -99.50536015364203, "Episode length": 999, "Policy Loss": -0.17387743294239044, "Value Loss": 0.08372938632965088, "_runtime": 5551.141010284424, "_timestamp": 1585602920.7738798, "_step": 380}
{"Episode reward": -99.76089400139033, "Episode length": 999, "Policy Loss": -0.1691921204328537, "Value Loss": 0.025096377357840538, "_runtime": 5551.872297525406, "_timestamp": 1585602921.505167, "_step": 381}
{"Episode reward": 53.928473171259604, "Episode length": 463, "Policy Loss": 1.228458285331726, "Value Loss": 20.463537216186523, "_runtime": 5553.423398017883, "_timestamp": 1585602923.0562675, "_step": 382}
{"Episode reward": -99.67782133322187, "Episode length": 999, "Policy Loss": -0.24973246455192566, "Value Loss": 0.3304288983345032, "_runtime": 5554.558559894562, "_timestamp": 1585602924.1914294, "_step": 383}
{"Episode reward": 27.89999999999982, "Episode length": 721, "Policy Loss": 0.5169258713722229, "Value Loss": 12.804449081420898, "_runtime": 5556.060014247894, "_timestamp": 1585602925.6928837, "_step": 384}
{"Episode reward": -99.76114182092576, "Episode length": 999, "Policy Loss": -0.5980907678604126, "Value Loss": 0.01608405075967312, "_runtime": 5557.373548030853, "_timestamp": 1585602927.0064175, "_step": 385}
{"Episode reward": 15.93822590725081, "Episode length": 841, "Policy Loss": -0.08627234399318695, "Value Loss": 10.770997047424316, "_runtime": 5558.903148651123, "_timestamp": 1585602928.5360181, "_step": 386}
{"Episode reward": -99.7204381992619, "Episode length": 999, "Policy Loss": -0.9979815483093262, "Value Loss": 0.05267813801765442, "_runtime": 5559.293356180191, "_timestamp": 1585602928.9262257, "_step": 387}
{"Episode reward": 78.23180506519853, "Episode length": 219, "Policy Loss": 1.6019012928009033, "Value Loss": 41.808189392089844, "_runtime": 5560.60119342804, "_timestamp": 1585602930.234063, "_step": 388}
{"Episode reward": 14.700000000000571, "Episode length": 853, "Policy Loss": -0.582172691822052, "Value Loss": 10.705011367797852, "_runtime": 5562.1933157444, "_timestamp": 1585602931.8261852, "_step": 389}
{"Episode reward": -99.68523334546342, "Episode length": 999, "Policy Loss": -1.3089652061462402, "Value Loss": 0.08950518816709518, "_runtime": 5563.261101484299, "_timestamp": 1585602932.893971, "_step": 390}
{"Episode reward": 27.88769871407986, "Episode length": 724, "Policy Loss": -0.6204272508621216, "Value Loss": 13.105416297912598, "_runtime": 5564.567130565643, "_timestamp": 1585602934.2, "_step": 391}
{"Episode reward": 15.100000000000549, "Episode length": 849, "Policy Loss": -0.8740618228912354, "Value Loss": 10.854265213012695, "_runtime": 5565.629948854446, "_timestamp": 1585602935.2628183, "_step": 392}
{"Episode reward": 32.61126361857123, "Episode length": 676, "Policy Loss": -0.7896428108215332, "Value Loss": 15.25497817993164, "_runtime": 5567.138615369797, "_timestamp": 1585602936.7714849, "_step": 393}
{"Episode reward": -99.73704804787272, "Episode length": 999, "Policy Loss": -1.5985593795776367, "Value Loss": 0.2659516930580139, "_runtime": 5568.680536270142, "_timestamp": 1585602938.3134058, "_step": 394}
{"Episode reward": -99.5672552358811, "Episode length": 999, "Policy Loss": -1.5755321979522705, "Value Loss": 0.432068794965744, "_runtime": 5570.202829122543, "_timestamp": 1585602939.8356986, "_step": 395}
{"Episode reward": -99.75435936853616, "Episode length": 999, "Policy Loss": -1.4205271005630493, "Value Loss": 0.9463216662406921, "_runtime": 5571.748478889465, "_timestamp": 1585602941.3813484, "_step": 396}
{"Episode reward": -99.37863433912726, "Episode length": 999, "Policy Loss": -1.1079670190811157, "Value Loss": 0.4159119725227356, "_runtime": 5573.310255527496, "_timestamp": 1585602942.943125, "_step": 397}
{"Episode reward": -99.76664223270352, "Episode length": 999, "Policy Loss": -0.6460025310516357, "Value Loss": 0.2914198935031891, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906, -0.29740333557128906]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-13.524314880371094, -13.308350563049316, -13.092386245727539, -12.876421928405762, -12.660457611083984, -12.444493293762207, -12.22852897644043, -12.012564659118652, -11.796600341796875, -11.580636024475098, -11.36467170715332, -11.148707389831543, -10.932743072509766, -10.716777801513672, -10.500814437866211, -10.284849166870117, -10.068885803222656, -9.852920532226562, -9.636957168579102, -9.420991897583008, -9.205028533935547, -8.989063262939453, -8.773099899291992, -8.557134628295898, -8.341170310974121, -8.125205993652344, -7.909241676330566, -7.693277359008789, -7.477313041687012, -7.261348724365234, -7.045384407043457, -6.82942008972168, -6.613455772399902, -6.397491455078125, -6.181527137756348, -5.96556282043457, -5.749598503112793, -5.533634185791016, -5.317669868469238, -5.101705551147461, -4.885741233825684, -4.669776916503906, -4.453812599182129, -4.237848281860352, -4.021883964538574, -3.805919647216797, -3.5899553298950195, -3.373991012573242, -3.1580257415771484, -2.942061424255371, -2.7260971069335938, -2.5101327896118164, -2.294168472290039, -2.0782041549682617, -1.8622398376464844, -1.646275520324707, -1.4303112030029297, -1.2143468856811523, -0.998382568359375, -0.7824182510375977, -0.5664539337158203, -0.35048961639404297, -0.13452529907226562, 0.08143901824951172, 0.29740333557128906]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0], "bins": [-0.20812465250492096, -0.20487269759178162, -0.20162075757980347, -0.19836880266666412, -0.19511686265468597, -0.19186490774154663, -0.18861296772956848, -0.18536101281642914, -0.182109072804451, -0.17885711789131165, -0.1756051778793335, -0.17235322296619415, -0.1691012680530548, -0.16584932804107666, -0.1625973880290985, -0.15934543311595917, -0.15609347820281982, -0.15284153819084167, -0.14958959817886353, -0.14633764326572418, -0.14308568835258484, -0.1398337483406067, -0.13658180832862854, -0.1333298534154892, -0.13007789850234985, -0.1268259584903717, -0.12357400357723236, -0.12032205611467361, -0.11707010865211487, -0.11381816118955612, -0.11056621372699738, -0.10731426626443863, -0.10406231880187988, -0.10081037133932114, -0.09755842387676239, -0.09430647641420364, -0.0910545289516449, -0.08780258148908615, -0.0845506340265274, -0.08129867911338806, -0.07804673910140991, -0.07479478418827057, -0.07154284417629242, -0.06829088926315308, -0.06503894925117493, -0.061786994338035583, -0.058535054326057434, -0.05528309941291809, -0.05203114449977875, -0.0487792044878006, -0.045527249574661255, -0.042275309562683105, -0.03902335464954376, -0.03577141463756561, -0.03251945972442627, -0.02926751971244812, -0.026015564799308777, -0.022763624787330627, -0.019511669874191284, -0.016259729862213135, -0.013007774949073792, -0.009755834937095642, -0.006503880023956299, -0.0032519400119781494, 1.4901161193847656e-08]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 5.0, 3.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 5.0, 7.0, 6.0, 5.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 3.0, 5.0, 7.0, 2.0, 6.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 4.0, 225.0, 2.0, 4.0, 3.0, 9.0, 6.0, 8.0, 8.0, 11.0, 12.0, 5.0, 11.0, 8.0, 3.0, 5.0, 8.0, 11.0, 7.0, 5.0], "bins": [-0.46343931555747986, -0.45332321524620056, -0.44320714473724365, -0.43309104442596436, -0.42297494411468506, -0.41285884380340576, -0.40274277329444885, -0.39262667298316956, -0.38251060247421265, -0.37239450216293335, -0.36227840185165405, -0.35216230154037476, -0.34204623103141785, -0.33193013072013855, -0.32181406021118164, -0.31169795989990234, -0.30158185958862305, -0.29146575927734375, -0.28134965896606445, -0.27123358845710754, -0.26111748814582825, -0.25100141763687134, -0.24088531732559204, -0.23076921701431274, -0.22065313160419464, -0.21053704619407654, -0.20042094588279724, -0.19030484557151794, -0.18018877506256104, -0.17007267475128174, -0.15995657444000244, -0.14984050393104553, -0.13972440361976624, -0.12960830330848694, -0.11949223279953003, -0.10937613248825073, -0.09926003217697144, -0.08914396166801453, -0.07902786135673523, -0.06891176104545593, -0.058795660734176636, -0.04867959022521973, -0.03856348991394043, -0.028447389602661133, -0.018331319093704224, -0.008215218782424927, 0.0019008815288543701, 0.01201695203781128, 0.022133052349090576, 0.03224915266036987, 0.04236522316932678, 0.05248132348060608, 0.06259742379188538, 0.07271352410316467, 0.08282962441444397, 0.09294566512107849, 0.10306176543235779, 0.11317786574363708, 0.12329396605491638, 0.13341006636619568, 0.14352616667747498, 0.1536422073841095, 0.1637583076953888, 0.1738744080066681, 0.1839905083179474]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-2.245709180831909, -2.2010810375213623, -2.1564528942108154, -2.1118249893188477, -2.067196846008301, -2.022568702697754, -1.977940559387207, -1.9333125352859497, -1.8886845111846924, -1.8440563678741455, -1.7994282245635986, -1.7548002004623413, -1.7101720571517944, -1.665544033050537, -1.6209158897399902, -1.5762877464294434, -1.531659722328186, -1.4870316982269287, -1.4424035549163818, -1.397775411605835, -1.3531473875045776, -1.3085192441940308, -1.2638912200927734, -1.2192630767822266, -1.1746349334716797, -1.1300069093704224, -1.0853787660598755, -1.0407507419586182, -0.9961225986480713, -0.951494574546814, -0.9068664312362671, -0.8622384071350098, -0.8176102638244629, -0.772982120513916, -0.7283540964126587, -0.6837259531021118, -0.6390979290008545, -0.5944697856903076, -0.5498417615890503, -0.5052136182785034, -0.4605855941772461, -0.4159574508666992, -0.37132930755615234, -0.326701283454895, -0.28207314014434814, -0.23744511604309082, -0.19281697273254395, -0.14818882942199707, -0.1035606861114502, -0.05893278121948242, -0.014304637908935547, 0.030323505401611328, 0.0749516487121582, 0.11957955360412598, 0.16420769691467285, 0.20883584022521973, 0.2534639835357666, 0.2980921268463135, 0.34272003173828125, 0.3873481750488281, 0.431976318359375, 0.4766044616699219, 0.5212323665618896, 0.5658605098724365, 0.6104886531829834]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 3.0, 3.0, 0.0, 8.0, 5.0, 3.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.2311946153640747, -0.21470806002616882, -0.19822151958942413, -0.18173497915267944, -0.16524842381477356, -0.14876186847686768, -0.13227532804012299, -0.1157887801527977, -0.09930223226547241, -0.08281567692756653, -0.06632913649082184, -0.04984259605407715, -0.033356040716171265, -0.01686948537826538, -0.0003829449415206909, 0.016103595495224, 0.03259015083312988, 0.04907670617103577, 0.06556326150894165, 0.08204978704452515, 0.09853634238243103, 0.11502289772033691, 0.1315094232559204, 0.1479959785938263, 0.16448253393173218, 0.18096908926963806, 0.19745564460754395, 0.21394217014312744, 0.23042872548103333, 0.2469152808189392, 0.2634018063545227, 0.279888391494751, 0.2963749170303345, 0.31286144256591797, 0.32934802770614624, 0.34583455324172974, 0.362321138381958, 0.3788076639175415, 0.395294189453125, 0.41178077459335327, 0.42826730012893677, 0.44475382566452026, 0.46124041080474854, 0.47772693634033203, 0.4942134618759155, 0.5107000470161438, 0.5271865725517273, 0.5436731576919556, 0.5601596832275391, 0.5766462087631226, 0.5931327939033508, 0.6096193194389343, 0.6261059045791626, 0.6425924301147461, 0.6590789556503296, 0.6755655407905579, 0.6920520663261414, 0.7085385918617249, 0.7250251770019531, 0.7415117025375366, 0.7579982280731201, 0.7744847536087036, 0.7909713983535767, 0.8074579238891602, 0.8239444494247437]}, "_runtime": 5574.044305562973, "_timestamp": 1585602943.677175, "_step": 398}
{"Episode reward": 53.943576559936254, "Episode length": 462, "Policy Loss": 1.4520195722579956, "Value Loss": 21.13636016845703, "_runtime": 5574.69474864006, "_timestamp": 1585602944.3276181, "_step": 399}
{"Episode reward": 59.925860490183986, "Episode length": 402, "Policy Loss": 1.6576178073883057, "Value Loss": 24.31048583984375, "_runtime": 5575.8113424777985, "_timestamp": 1585602945.444212, "_step": 400}
{"Episode reward": 28.101537962793174, "Episode length": 720, "Policy Loss": 1.240441083908081, "Value Loss": 13.436973571777344, "_runtime": 5576.906633138657, "_timestamp": 1585602946.5395026, "_step": 401}
{"Episode reward": 27.802224428742022, "Episode length": 722, "Policy Loss": 1.3118633031845093, "Value Loss": 14.087985038757324, "_runtime": 5577.622249364853, "_timestamp": 1585602947.2551188, "_step": 402}
{"Episode reward": 52.89930672139705, "Episode length": 473, "Policy Loss": 2.6588480472564697, "Value Loss": 20.804018020629883, "_runtime": 5578.7721745967865, "_timestamp": 1585602948.405044, "_step": 403}
{"Episode reward": 24.500000000000014, "Episode length": 755, "Policy Loss": 1.4529691934585571, "Value Loss": 13.198970794677734, "_runtime": 5580.279397249222, "_timestamp": 1585602949.9122667, "_step": 404}
{"Episode reward": 0.5946683364934131, "Episode length": 995, "Policy Loss": 1.2732034921646118, "Value Loss": 10.101776123046875, "_runtime": 5581.727226257324, "_timestamp": 1585602951.3600957, "_step": 405}
{"Episode reward": 3.716515657883164, "Episode length": 966, "Policy Loss": 1.1595067977905273, "Value Loss": 10.212162017822266, "_runtime": 5582.227031946182, "_timestamp": 1585602951.8599014, "_step": 406}
{"Episode reward": 69.33777655959113, "Episode length": 307, "Policy Loss": 3.097278118133545, "Value Loss": 32.04246139526367, "_runtime": 5583.755190610886, "_timestamp": 1585602953.38806, "_step": 407}
{"Episode reward": -99.49670753870022, "Episode length": 999, "Policy Loss": 0.21903130412101746, "Value Loss": 0.07005596160888672, "_runtime": 5585.083368301392, "_timestamp": 1585602954.7162378, "_step": 408}
{"Episode reward": 16.478439258924226, "Episode length": 837, "Policy Loss": 0.779717206954956, "Value Loss": 11.84746265411377, "_runtime": 5586.076752901077, "_timestamp": 1585602955.7096224, "_step": 409}
{"Episode reward": 33.00361060565291, "Episode length": 670, "Policy Loss": 1.2060571908950806, "Value Loss": 14.622845649719238, "_runtime": 5587.470801353455, "_timestamp": 1585602957.1036708, "_step": 410}
{"Episode reward": 10.976917466964423, "Episode length": 894, "Policy Loss": 0.42541688680648804, "Value Loss": 10.79475212097168, "_runtime": 5588.703394174576, "_timestamp": 1585602958.3362637, "_step": 411}
{"Episode reward": 19.986865790537834, "Episode length": 801, "Policy Loss": 0.3568092882633209, "Value Loss": 12.528276443481445, "_runtime": 5590.192124605179, "_timestamp": 1585602959.824994, "_step": 412}
{"Episode reward": -99.72153837727244, "Episode length": 999, "Policy Loss": -0.27449724078178406, "Value Loss": 0.005606881342828274, "_runtime": 5590.952253580093, "_timestamp": 1585602960.585123, "_step": 413}
{"Episode reward": 52.43262986018632, "Episode length": 476, "Policy Loss": 1.0998144149780273, "Value Loss": 20.833362579345703, "_runtime": 5592.478902339935, "_timestamp": 1585602962.1117718, "_step": 414}
{"Episode reward": -99.73386534005263, "Episode length": 999, "Policy Loss": -0.29836249351501465, "Value Loss": 0.0055071949027478695, "_runtime": 5594.018214225769, "_timestamp": 1585602963.6510837, "_step": 415}
{"Episode reward": -99.82326719798009, "Episode length": 999, "Policy Loss": -0.3519637882709503, "Value Loss": 0.0054122162982821465, "_runtime": 5595.509044408798, "_timestamp": 1585602965.141914, "_step": 416}
{"Episode reward": -99.67056129569981, "Episode length": 999, "Policy Loss": -0.4138018488883972, "Value Loss": 0.009564965032041073, "_runtime": 5597.061784982681, "_timestamp": 1585602966.6946545, "_step": 417}
{"Episode reward": -99.5320197334965, "Episode length": 999, "Policy Loss": -0.4741576611995697, "Value Loss": 0.005943933501839638, "_runtime": 5598.602475166321, "_timestamp": 1585602968.2353446, "_step": 418}
{"Episode reward": -99.80008334554591, "Episode length": 999, "Policy Loss": -0.5175199508666992, "Value Loss": 0.006885876879096031, "_runtime": 5600.136704921722, "_timestamp": 1585602969.7695744, "_step": 419}
{"Episode reward": -99.78183477297286, "Episode length": 999, "Policy Loss": -0.55507892370224, "Value Loss": 0.010310632176697254, "_runtime": 5601.644236326218, "_timestamp": 1585602971.2771058, "_step": 420}
{"Episode reward": 3.8560154101299275, "Episode length": 965, "Policy Loss": 0.06495826691389084, "Value Loss": 10.27174186706543, "_runtime": 5603.194742202759, "_timestamp": 1585602972.8276117, "_step": 421}
{"Episode reward": -99.7946061508949, "Episode length": 999, "Policy Loss": -0.6419001817703247, "Value Loss": 0.016189292073249817, "_runtime": 5604.751788854599, "_timestamp": 1585602974.3846583, "_step": 422}
{"Episode reward": -99.66107146367291, "Episode length": 999, "Policy Loss": -0.6871153712272644, "Value Loss": 0.02322438172996044, "_runtime": 5605.443492412567, "_timestamp": 1585602975.076362, "_step": 423}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 0.8151705265045166, "Value Loss": 22.64181900024414, "_runtime": 5607.00150847435, "_timestamp": 1585602976.634378, "_step": 424}
{"Episode reward": -99.8157620674218, "Episode length": 999, "Policy Loss": -0.792171835899353, "Value Loss": 0.019140100106596947, "_runtime": 5608.600337266922, "_timestamp": 1585602978.2332067, "_step": 425}
{"Episode reward": -99.81397445085318, "Episode length": 999, "Policy Loss": -0.9030416011810303, "Value Loss": 0.05995798483490944, "_runtime": 5609.809142827988, "_timestamp": 1585602979.4420123, "_step": 426}
{"Episode reward": 19.889236259390884, "Episode length": 804, "Policy Loss": -0.1910921037197113, "Value Loss": 12.010235786437988, "_runtime": 5611.367923974991, "_timestamp": 1585602981.0007935, "_step": 427}
{"Episode reward": -99.72898442172307, "Episode length": 999, "Policy Loss": -1.0204434394836426, "Value Loss": 0.21171435713768005, "_runtime": 5612.915744543076, "_timestamp": 1585602982.548614, "_step": 428}
{"Episode reward": -99.81877312827716, "Episode length": 999, "Policy Loss": -0.9526783227920532, "Value Loss": 0.07193290442228317, "_runtime": 5614.4419639110565, "_timestamp": 1585602984.0748334, "_step": 429}
{"Episode reward": -99.83104606307903, "Episode length": 999, "Policy Loss": -0.7930352687835693, "Value Loss": 0.04164963960647583, "_runtime": 5616.010166883469, "_timestamp": 1585602985.6430364, "_step": 430}
{"Episode reward": -99.6490426618359, "Episode length": 999, "Policy Loss": -0.6727031469345093, "Value Loss": 0.07604333758354187, "_runtime": 5617.256658315659, "_timestamp": 1585602986.8895278, "_step": 431}
{"Episode reward": 21.473572210874607, "Episode length": 787, "Policy Loss": 0.28528526425361633, "Value Loss": 12.728658676147461, "_runtime": 5618.373771429062, "_timestamp": 1585602988.006641, "_step": 432}
{"Episode reward": 28.588086396083014, "Episode length": 716, "Policy Loss": 0.3370223343372345, "Value Loss": 13.357197761535645, "_runtime": 5619.9450035095215, "_timestamp": 1585602989.577873, "_step": 433}
{"Episode reward": -99.65239143310907, "Episode length": 999, "Policy Loss": -0.7035720348358154, "Value Loss": 0.04424272105097771, "_runtime": 5621.502630233765, "_timestamp": 1585602991.1354997, "_step": 434}
{"Episode reward": -99.77488204620172, "Episode length": 999, "Policy Loss": -0.8028585910797119, "Value Loss": 0.020120296627283096, "_runtime": 5622.664759159088, "_timestamp": 1585602992.2976286, "_step": 435}
{"Episode reward": 25.198972840514017, "Episode length": 749, "Policy Loss": -0.1188075989484787, "Value Loss": 12.656044006347656, "_runtime": 5624.218425750732, "_timestamp": 1585602993.8512952, "_step": 436}
{"Episode reward": -99.456776115716, "Episode length": 999, "Policy Loss": -0.8698077201843262, "Value Loss": 0.02004079893231392, "_runtime": 5625.145577669144, "_timestamp": 1585602994.7784472, "_step": 437}
{"Episode reward": 41.79999999999945, "Episode length": 582, "Policy Loss": 0.14471569657325745, "Value Loss": 16.350997924804688, "_runtime": 5626.700246334076, "_timestamp": 1585602996.3331158, "_step": 438}
{"Episode reward": -99.72687117997417, "Episode length": 999, "Policy Loss": -0.7964653968811035, "Value Loss": 0.03299650922417641, "_runtime": 5628.277002573013, "_timestamp": 1585602997.909872, "_step": 439}
{"Episode reward": -99.57279649765559, "Episode length": 999, "Policy Loss": -0.740149736404419, "Value Loss": 0.016981789842247963, "_runtime": 5629.733203172684, "_timestamp": 1585602999.3660727, "_step": 440}
{"Episode reward": 5.057152407012126, "Episode length": 951, "Policy Loss": -0.051442950963974, "Value Loss": 9.658145904541016, "_runtime": 5630.526045084, "_timestamp": 1585603000.1589146, "_step": 441}
{"Episode reward": 52.67278311988299, "Episode length": 474, "Policy Loss": 0.6348658800125122, "Value Loss": 19.298795700073242, "_runtime": 5632.101639509201, "_timestamp": 1585603001.734509, "_step": 442}
{"Episode reward": -99.77633287797076, "Episode length": 999, "Policy Loss": -0.6042015552520752, "Value Loss": 0.02191382832825184, "_runtime": 5632.899012804031, "_timestamp": 1585603002.5318823, "_step": 443}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": 0.6820403933525085, "Value Loss": 19.435697555541992, "_runtime": 5634.420054197311, "_timestamp": 1585603004.0529237, "_step": 444}
{"Episode reward": -99.52194519077757, "Episode length": 999, "Policy Loss": -0.5475277900695801, "Value Loss": 0.08476445823907852, "_runtime": 5635.995253562927, "_timestamp": 1585603005.628123, "_step": 445}
{"Episode reward": -99.67994924238745, "Episode length": 999, "Policy Loss": -0.5478720664978027, "Value Loss": 0.09868135303258896, "_runtime": 5637.520555973053, "_timestamp": 1585603007.1534255, "_step": 446}
{"Episode reward": -99.65975919621857, "Episode length": 999, "Policy Loss": -0.6422603726387024, "Value Loss": 0.01677052490413189, "_runtime": 5639.027983903885, "_timestamp": 1585603008.6608534, "_step": 447}
{"Episode reward": 3.5551590041676917, "Episode length": 966, "Policy Loss": -0.05113817751407623, "Value Loss": 9.105049133300781, "_runtime": 5640.035314798355, "_timestamp": 1585603009.6681843, "_step": 448}
{"Episode reward": 37.275454156263116, "Episode length": 628, "Policy Loss": 0.23247265815734863, "Value Loss": 14.591214179992676, "_runtime": 5641.589946985245, "_timestamp": 1585603011.2228165, "_step": 449}
{"Episode reward": -99.8353427492301, "Episode length": 999, "Policy Loss": -0.7050895690917969, "Value Loss": 0.06226152181625366, "_runtime": 5643.1459085941315, "_timestamp": 1585603012.778778, "_step": 450}
{"Episode reward": -99.67746654876834, "Episode length": 999, "Policy Loss": -0.6543422341346741, "Value Loss": 0.011510130949318409, "_runtime": 5644.686670541763, "_timestamp": 1585603014.31954, "_step": 451}
{"Episode reward": -99.78744174786704, "Episode length": 999, "Policy Loss": -0.5883380770683289, "Value Loss": 0.032501768320798874, "_runtime": 5645.4184284210205, "_timestamp": 1585603015.051298, "_step": 452}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 0.5232766270637512, "Value Loss": 19.778419494628906, "_runtime": 5646.985147476196, "_timestamp": 1585603016.618017, "_step": 453}
{"Episode reward": -99.61864483812685, "Episode length": 999, "Policy Loss": -0.5563685297966003, "Value Loss": 0.017897222191095352, "_runtime": 5648.036938905716, "_timestamp": 1585603017.6698084, "_step": 454}
{"Episode reward": 34.11290578802529, "Episode length": 659, "Policy Loss": 0.3036307394504547, "Value Loss": 13.59708023071289, "_runtime": 5649.180744886398, "_timestamp": 1585603018.8136144, "_step": 455}
{"Episode reward": 25.219218983873702, "Episode length": 749, "Policy Loss": 0.6109926104545593, "Value Loss": 11.460210800170898, "_runtime": 5649.832270145416, "_timestamp": 1585603019.4651396, "_step": 456}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.0701713562011719, "Value Loss": 23.094694137573242, "_runtime": 5651.0589854717255, "_timestamp": 1585603020.691855, "_step": 457}
{"Episode reward": 20.296433497779333, "Episode length": 798, "Policy Loss": 0.3318030834197998, "Value Loss": 11.078448295593262, "_runtime": 5652.293959617615, "_timestamp": 1585603021.926829, "_step": 458}
{"Episode reward": 20.37308111556365, "Episode length": 798, "Policy Loss": 0.24297717213630676, "Value Loss": 11.16519832611084, "_runtime": 5653.790425539017, "_timestamp": 1585603023.423295, "_step": 459}
{"Episode reward": -99.82882272661523, "Episode length": 999, "Policy Loss": -0.582129180431366, "Value Loss": 0.033051181584596634, "_runtime": 5655.378595590591, "_timestamp": 1585603025.011465, "_step": 460}
{"Episode reward": -99.64393873938688, "Episode length": 999, "Policy Loss": -0.6597973704338074, "Value Loss": 0.018870575353503227, "_runtime": 5656.4611756801605, "_timestamp": 1585603026.0940452, "_step": 461}
{"Episode reward": 30.183921045413868, "Episode length": 699, "Policy Loss": 0.08849775046110153, "Value Loss": 12.761030197143555, "_runtime": 5658.01253080368, "_timestamp": 1585603027.6454003, "_step": 462}
{"Episode reward": -99.7843011192265, "Episode length": 999, "Policy Loss": -0.7692792415618896, "Value Loss": 0.01672389730811119, "_runtime": 5659.589732646942, "_timestamp": 1585603029.2226021, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8009616136550903, "Value Loss": 0.046102870255708694, "_runtime": 5661.128412723541, "_timestamp": 1585603030.7612822, "_step": 464}
{"Episode reward": -99.85725927839381, "Episode length": 999, "Policy Loss": -0.8239903450012207, "Value Loss": 0.10906451940536499, "_runtime": 5662.354354858398, "_timestamp": 1585603031.9872243, "_step": 465}
{"Episode reward": 21.87725642796157, "Episode length": 783, "Policy Loss": -0.02998744696378708, "Value Loss": 11.727471351623535, "_runtime": 5663.9282195568085, "_timestamp": 1585603033.561089, "_step": 466}
{"Episode reward": -99.81800962127605, "Episode length": 999, "Policy Loss": -0.626356840133667, "Value Loss": 0.012960545718669891, "_runtime": 5665.499665260315, "_timestamp": 1585603035.1325347, "_step": 467}
{"Episode reward": -99.79013062368473, "Episode length": 999, "Policy Loss": -0.517987847328186, "Value Loss": 0.018231460824608803, "_runtime": 5667.049668550491, "_timestamp": 1585603036.682538, "_step": 468}
{"Episode reward": -99.65533640491637, "Episode length": 999, "Policy Loss": -0.39692291617393494, "Value Loss": 0.044680189341306686, "_runtime": 5668.627037525177, "_timestamp": 1585603038.259907, "_step": 469}
{"Episode reward": -99.80095439781294, "Episode length": 999, "Policy Loss": -0.31975147128105164, "Value Loss": 0.054189737886190414, "_runtime": 5670.20178103447, "_timestamp": 1585603039.8346505, "_step": 470}
{"Episode reward": -99.52725451092563, "Episode length": 999, "Policy Loss": -0.2562151849269867, "Value Loss": 0.14497864246368408, "_runtime": 5671.2714631557465, "_timestamp": 1585603040.9043326, "_step": 471}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.8151974081993103, "Value Loss": 13.036686897277832, "_runtime": 5672.489771604538, "_timestamp": 1585603042.122641, "_step": 472}
{"Episode reward": 23.02508615718699, "Episode length": 771, "Policy Loss": 0.4914403557777405, "Value Loss": 11.63967514038086, "_runtime": 5674.0597224235535, "_timestamp": 1585603043.692592, "_step": 473}
{"Episode reward": -99.7330971592092, "Episode length": 999, "Policy Loss": -0.2541945278644562, "Value Loss": 0.008151045069098473, "_runtime": 5675.601669549942, "_timestamp": 1585603045.234539, "_step": 474}
{"Episode reward": -99.74976737389667, "Episode length": 999, "Policy Loss": -0.2796049118041992, "Value Loss": 0.04487729072570801, "_runtime": 5677.151308298111, "_timestamp": 1585603046.7841778, "_step": 475}
{"Episode reward": -99.75006007896596, "Episode length": 999, "Policy Loss": -0.24188081920146942, "Value Loss": 0.02935222163796425, "_runtime": 5678.737950563431, "_timestamp": 1585603048.37082, "_step": 476}
{"Episode reward": 1.2318829735055772, "Episode length": 991, "Policy Loss": 0.32858699560165405, "Value Loss": 8.915481567382812, "_runtime": 5680.31450009346, "_timestamp": 1585603049.9473696, "_step": 477}
{"Episode reward": -99.699273370723, "Episode length": 999, "Policy Loss": -0.11415352672338486, "Value Loss": 0.05257689952850342, "_runtime": 5681.891782999039, "_timestamp": 1585603051.5246525, "_step": 478}
{"Episode reward": -99.72877168620332, "Episode length": 999, "Policy Loss": -0.07777513563632965, "Value Loss": 0.07529035210609436, "_runtime": 5683.470679759979, "_timestamp": 1585603053.1035492, "_step": 479}
{"Episode reward": -99.5191902272855, "Episode length": 999, "Policy Loss": -0.011451653204858303, "Value Loss": 0.13572503626346588, "_runtime": 5685.042473077774, "_timestamp": 1585603054.6753426, "_step": 480}
{"Episode reward": -99.66262952743425, "Episode length": 999, "Policy Loss": -0.0718403309583664, "Value Loss": 0.04433278366923332, "_runtime": 5686.603674888611, "_timestamp": 1585603056.2365444, "_step": 481}
{"Episode reward": -99.7810448132907, "Episode length": 999, "Policy Loss": -0.13367152214050293, "Value Loss": 0.019522760063409805, "_runtime": 5688.189732551575, "_timestamp": 1585603057.822602, "_step": 482}
{"Episode reward": -99.56949919620973, "Episode length": 999, "Policy Loss": -0.16170907020568848, "Value Loss": 0.05878526717424393, "_runtime": 5689.2926371097565, "_timestamp": 1585603058.9255066, "_step": 483}
{"Episode reward": 31.067190389142723, "Episode length": 691, "Policy Loss": 0.5878064632415771, "Value Loss": 12.341486930847168, "_runtime": 5690.868758678436, "_timestamp": 1585603060.5016282, "_step": 484}
{"Episode reward": -99.77187333621994, "Episode length": 999, "Policy Loss": -0.13960815966129303, "Value Loss": 0.04048444703221321, "_runtime": 5692.449603557587, "_timestamp": 1585603062.082473, "_step": 485}
{"Episode reward": -99.70384666605248, "Episode length": 999, "Policy Loss": -0.09167347103357315, "Value Loss": 0.03136090561747551, "_runtime": 5694.002440929413, "_timestamp": 1585603063.6353104, "_step": 486}
{"Episode reward": -99.7946391709135, "Episode length": 999, "Policy Loss": -0.05294857174158096, "Value Loss": 0.026837259531021118, "_runtime": 5695.560567140579, "_timestamp": 1585603065.1934366, "_step": 487}
{"Episode reward": 1.4944458709810107, "Episode length": 986, "Policy Loss": 0.56886887550354, "Value Loss": 10.611003875732422, "_runtime": 5697.1000328063965, "_timestamp": 1585603066.7329023, "_step": 488}
{"Episode reward": 1.9000000000012989, "Episode length": 981, "Policy Loss": 0.5823208093643188, "Value Loss": 9.376323699951172, "_runtime": 5698.674939632416, "_timestamp": 1585603068.307809, "_step": 489}
{"Episode reward": -99.76511658739625, "Episode length": 999, "Policy Loss": -0.017066985368728638, "Value Loss": 0.13115635514259338, "_runtime": 5700.252218723297, "_timestamp": 1585603069.8850882, "_step": 490}
{"Episode reward": -99.80212436318257, "Episode length": 999, "Policy Loss": 0.07082255184650421, "Value Loss": 0.11997893452644348, "_runtime": 5701.867775440216, "_timestamp": 1585603071.500645, "_step": 491}
{"Episode reward": -99.71584631691083, "Episode length": 999, "Policy Loss": 0.07414243370294571, "Value Loss": 0.061615195125341415, "_runtime": 5703.431671142578, "_timestamp": 1585603073.0645406, "_step": 492}
{"Episode reward": -99.3179522761596, "Episode length": 999, "Policy Loss": 0.05121319368481636, "Value Loss": 0.022822361439466476, "_runtime": 5704.863934516907, "_timestamp": 1585603074.496804, "_step": 493}
{"Episode reward": 9.079539617524446, "Episode length": 910, "Policy Loss": 0.7851224541664124, "Value Loss": 10.403918266296387, "_runtime": 5705.528592824936, "_timestamp": 1585603075.1614623, "_step": 494}
{"Episode reward": 59.67220434299058, "Episode length": 405, "Policy Loss": 1.584627628326416, "Value Loss": 22.87885093688965, "_runtime": 5707.097762346268, "_timestamp": 1585603076.7306318, "_step": 495}
{"Episode reward": -99.7286089727874, "Episode length": 999, "Policy Loss": -0.06286299228668213, "Value Loss": 0.012321481481194496, "_runtime": 5707.8667957782745, "_timestamp": 1585603077.4996653, "_step": 496}
{"Episode reward": 52.89503970108887, "Episode length": 472, "Policy Loss": 1.1152249574661255, "Value Loss": 19.962751388549805, "_runtime": 5708.629969596863, "_timestamp": 1585603078.262839, "_step": 497}
{"Episode reward": 50.294770386977625, "Episode length": 498, "Policy Loss": 0.9003774523735046, "Value Loss": 18.80057716369629, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533, 0.3402435779571533]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0], "bins": [-0.3402436077594757, -0.07744106650352478, 0.18536147475242615, 0.4481640160083771, 0.7109665870666504, 0.9737691879272461, 1.2365716695785522, 1.4993741512298584, 1.762176752090454, 2.02497935295105, 2.2877819538116455, 2.550584316253662, 2.813386917114258, 3.0761895179748535, 3.33899188041687, 3.601794481277466, 3.8645970821380615, 4.127399444580078, 4.390202045440674, 4.6530046463012695, 4.915807247161865, 5.178609371185303, 5.441411972045898, 5.704214572906494, 5.96701717376709, 6.2298197746276855, 6.492622375488281, 6.755424976348877, 7.0182271003723145, 7.28102970123291, 7.543832302093506, 7.80663537979126, 8.069437980651855, 8.332240104675293, 8.595043182373047, 8.857845306396484, 9.120648384094238, 9.383450508117676, 9.64625358581543, 9.909055709838867, 10.171858787536621, 10.434660911560059, 10.697463035583496, 10.96026611328125, 11.223068237304688, 11.485871315002441, 11.748673439025879, 12.011476516723633, 12.27427864074707, 12.537080764770508, 12.799883842468262, 13.0626859664917, 13.325489044189453, 13.58829116821289, 13.851094245910645, 14.113896369934082, 14.37669849395752, 14.639501571655273, 14.902303695678711, 15.165106773376465, 15.427908897399902, 15.69071102142334, 15.95351505279541, 16.21631622314453, 16.47911834716797]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.667152246426667e-09, 0.003748310264199972, 0.0074966284446418285, 0.011244946159422398, 0.014993264339864254, 0.018741581588983536, 0.022489899769425392, 0.02623821794986725, 0.029986536130309105, 0.03373485431075096, 0.03748317062854767, 0.041231490671634674, 0.04497980698943138, 0.04872812703251839, 0.052476443350315094, 0.0562247633934021, 0.05997307971119881, 0.06372139602899551, 0.06746971607208252, 0.07121803611516953, 0.07496634870767593, 0.07871466875076294, 0.08246298879384995, 0.08621130883693695, 0.08995962142944336, 0.09370794147253036, 0.09745626151561737, 0.10120457410812378, 0.10495289415121078, 0.10870121419429779, 0.1124495342373848, 0.1161978468298912, 0.11994616687297821, 0.12369448691606522, 0.12744279205799103, 0.13119111955165863, 0.13493943214416504, 0.13868774473667145, 0.14243607223033905, 0.14618438482284546, 0.14993269741535187, 0.15368102490901947, 0.15742933750152588, 0.1611776500940323, 0.1649259775876999, 0.1686742901802063, 0.1724226176738739, 0.1761709302663803, 0.17991924285888672, 0.18366757035255432, 0.18741588294506073, 0.19116419553756714, 0.19491252303123474, 0.19866083562374115, 0.20240914821624756, 0.20615747570991516, 0.20990578830242157, 0.21365410089492798, 0.21740242838859558, 0.221150740981102, 0.2248990684747696, 0.228647381067276, 0.2323956936597824, 0.23614402115345, 0.23989233374595642]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 8.0, 11.0, 7.0, 5.0, 5.0, 7.0, 10.0, 5.0, 17.0, 10.0, 10.0, 8.0, 12.0, 5.0, 4.0, 5.0, 225.0, 3.0, 4.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 4.0, 3.0, 8.0, 4.0, 4.0, 4.0, 5.0, 8.0, 6.0, 3.0, 4.0, 3.0, 10.0, 8.0, 3.0, 4.0, 0.0, 3.0, 2.0, 6.0, 5.0, 2.0, 8.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 5.0, 2.0, 0.0, 4.0, 2.0, 0.0, 4.0, 1.0], "bins": [-0.2203180193901062, -0.20796623826026917, -0.19561445713043213, -0.1832626760005951, -0.17091089487075806, -0.15855911374092102, -0.14620733261108398, -0.13385555148124695, -0.12150376290082932, -0.10915198177099228, -0.09680020064115524, -0.08444841206073761, -0.07209663093090057, -0.05974484980106354, -0.0473930686712265, -0.035041287541389465, -0.02268950641155243, -0.010337725281715393, 0.002014055848121643, 0.01436583697795868, 0.026717618107795715, 0.039069414138793945, 0.05142119526863098, 0.06377297639846802, 0.07612475752830505, 0.08847653865814209, 0.10082831978797913, 0.11318010091781616, 0.1255318820476532, 0.13788366317749023, 0.15023544430732727, 0.1625872254371643, 0.17493900656700134, 0.18729078769683838, 0.19964256882667542, 0.21199434995651245, 0.2243461310863495, 0.23669791221618652, 0.24904969334602356, 0.2614014744758606, 0.27375325560569763, 0.28610503673553467, 0.2984568476676941, 0.31080859899520874, 0.32316040992736816, 0.3355121612548828, 0.34786397218704224, 0.3602157235145569, 0.3725675344467163, 0.38491928577423096, 0.3972710967063904, 0.40962284803390503, 0.42197465896606445, 0.4343264102935791, 0.4466782212257385, 0.4590299725532532, 0.4713817834854126, 0.48373353481292725, 0.49608534574508667, 0.5084370970726013, 0.5207889080047607, 0.5331406593322754, 0.5454924702644348, 0.5578442215919495, 0.5701960325241089]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6718437671661377, -0.6199436187744141, -0.5680434703826904, -0.5161433219909668, -0.46424323320388794, -0.4123430848121643, -0.3604429364204407, -0.30854281783103943, -0.2566426694393158, -0.20474252104759216, -0.15284240245819092, -0.10094225406646729, -0.04904210567474365, 0.0028580427169799805, 0.05475813150405884, 0.10665827989578247, 0.1585584282875061, 0.21045857667922974, 0.26235872507095337, 0.3142588138580322, 0.36615896224975586, 0.4180591106414795, 0.4699592590332031, 0.5218594074249268, 0.5737595558166504, 0.625659704208374, 0.6775598526000977, 0.7294598817825317, 0.7813600301742554, 0.833260178565979, 0.8851603269577026, 0.9370604753494263, 0.9889606237411499, 1.0408607721328735, 1.0927609205245972, 1.1446610689163208, 1.1965612173080444, 1.248461365699768, 1.3003613948822021, 1.3522615432739258, 1.4041616916656494, 1.456061840057373, 1.5079619884490967, 1.5598621368408203, 1.611762285232544, 1.6636624336242676, 1.7155625820159912, 1.7674627304077148, 1.8193628787994385, 1.871263027191162, 1.9231631755828857, 1.9750633239746094, 2.026963472366333, 2.0788636207580566, 2.130763530731201, 2.182663679122925, 2.2345638275146484, 2.286463975906372, 2.3383641242980957, 2.3902642726898193, 2.442164421081543, 2.4940645694732666, 2.5459647178649902, 2.597864866256714, 2.6497650146484375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 4.0, 11.0, 7.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.9955458641052246, -1.9541995525360107, -1.9128532409667969, -1.8715070486068726, -1.8301607370376587, -1.7888144254684448, -1.7474682331085205, -1.7061219215393066, -1.6647756099700928, -1.623429298400879, -1.582082986831665, -1.5407367944717407, -1.4993904829025269, -1.458044171333313, -1.4166979789733887, -1.3753516674041748, -1.334005355834961, -1.292659044265747, -1.2513127326965332, -1.2099665403366089, -1.168620228767395, -1.1272739171981812, -1.0859277248382568, -1.044581413269043, -1.003235101699829, -0.9618887901306152, -0.9205424785614014, -0.879196286201477, -0.8378499746322632, -0.7965036630630493, -0.755157470703125, -0.7138111591339111, -0.6724648475646973, -0.6311185359954834, -0.5897722244262695, -0.5484260320663452, -0.5070797204971313, -0.4657334089279175, -0.42438721656799316, -0.3830409049987793, -0.34169459342956543, -0.30034828186035156, -0.2590019702911377, -0.21765577793121338, -0.1763094663619995, -0.13496315479278564, -0.09361696243286133, -0.05227065086364746, -0.010924339294433594, 0.030421972274780273, 0.07176828384399414, 0.11311459541320801, 0.15446090698242188, 0.19580698013305664, 0.2371532917022705, 0.2784996032714844, 0.31984591484069824, 0.3611922264099121, 0.402538537979126, 0.44388484954833984, 0.4852309226989746, 0.5265772342681885, 0.5679235458374023, 0.6092698574066162, 0.6506161689758301]}, "_runtime": 5709.736687421799, "_timestamp": 1585603079.369557, "_step": 498}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": 0.5747218728065491, "Value Loss": 12.702014923095703, "_runtime": 5709.736687421799, "_timestamp": 1585603079.369557, "_step": 499}
