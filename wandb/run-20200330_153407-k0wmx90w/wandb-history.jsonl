{"Episode reward": -37.02939499349993, "Episode length": 999, "Policy Loss": -0.03686583414673805, "Value Loss": 0.004569314420223236, "_runtime": 12551.647513866425, "_timestamp": 1585582467.4921472, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9670224189758301, "Value Loss": 167.15875244140625, "_runtime": 12553.18420791626, "_timestamp": 1585582469.0288413, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8781460523605347, "Value Loss": 92.8194808959961, "_runtime": 12554.797295808792, "_timestamp": 1585582470.6419291, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.499924898147583, "Value Loss": 111.4780044555664, "_runtime": 12556.351809740067, "_timestamp": 1585582472.196443, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.696397066116333, "Value Loss": 15.545321464538574, "_runtime": 12557.92753124237, "_timestamp": 1585582473.7721646, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3682384490966797, "Value Loss": 17.69347381591797, "_runtime": 12559.530890226364, "_timestamp": 1585582475.3755236, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.602654457092285, "Value Loss": 801.6718139648438, "_runtime": 12561.114305496216, "_timestamp": 1585582476.9589388, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.481758952140808, "Value Loss": 87.94564056396484, "_runtime": 12562.642427682877, "_timestamp": 1585582478.487061, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.986442506313324, "Value Loss": 398.1945495605469, "_runtime": 12564.230375289917, "_timestamp": 1585582480.0750086, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.694333791732788, "Value Loss": 8.0437650680542, "_runtime": 12565.815935134888, "_timestamp": 1585582481.6605685, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.474771499633789, "Value Loss": 60.205623626708984, "_runtime": 12567.367893695831, "_timestamp": 1585582483.212527, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.795395851135254, "Value Loss": 134.65858459472656, "_runtime": 12568.950897455215, "_timestamp": 1585582484.7955308, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.874814987182617, "Value Loss": 1201.3123779296875, "_runtime": 12570.519372463226, "_timestamp": 1585582486.3640058, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.8412652015686035, "Value Loss": 3.2746639251708984, "_runtime": 12572.134588003159, "_timestamp": 1585582487.9792213, "_step": 13}
{"Episode reward": -98.62069228336317, "Episode length": 999, "Policy Loss": 50.644309997558594, "Value Loss": 1953.4085693359375, "_runtime": 12572.932224988937, "_timestamp": 1585582488.7768583, "_step": 14}
{"Episode reward": 50.943741858284504, "Episode length": 492, "Policy Loss": -3.8350934982299805, "Value Loss": 153.0191192626953, "_runtime": 12574.038994550705, "_timestamp": 1585582489.883628, "_step": 15}
{"Episode reward": 30.34629031612971, "Episode length": 698, "Policy Loss": -3.072333812713623, "Value Loss": 64.03604125976562, "_runtime": 12574.432394504547, "_timestamp": 1585582490.2770278, "_step": 16}
{"Episode reward": 77.37143585523586, "Episode length": 227, "Policy Loss": 0.9745063781738281, "Value Loss": 100.29937744140625, "_runtime": 12575.271727323532, "_timestamp": 1585582491.1163607, "_step": 17}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 1.3964160680770874, "Value Loss": 147.6736297607422, "_runtime": 12576.815330982208, "_timestamp": 1585582492.6599643, "_step": 18}
{"Episode reward": -99.62578459950025, "Episode length": 999, "Policy Loss": 0.47653236985206604, "Value Loss": 6.668873310089111, "_runtime": 12578.343141794205, "_timestamp": 1585582494.1877751, "_step": 19}
{"Episode reward": -99.80599329210678, "Episode length": 999, "Policy Loss": 2.4483799934387207, "Value Loss": 87.75697326660156, "_runtime": 12579.89683842659, "_timestamp": 1585582495.7414718, "_step": 20}
{"Episode reward": -99.70512514412265, "Episode length": 999, "Policy Loss": 0.8288057446479797, "Value Loss": 31.828609466552734, "_runtime": 12581.506482601166, "_timestamp": 1585582497.351116, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019874969497323036, "Value Loss": 37.37408447265625, "_runtime": 12582.882656097412, "_timestamp": 1585582498.7272894, "_step": 22}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": -1.1743414402008057, "Value Loss": 250.49301147460938, "_runtime": 12583.669094324112, "_timestamp": 1585582499.5137277, "_step": 23}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 2.314452886581421, "Value Loss": 239.8072052001953, "_runtime": 12584.8795337677, "_timestamp": 1585582500.724167, "_step": 24}
{"Episode reward": 25.19817063808439, "Episode length": 749, "Policy Loss": 0.7078966498374939, "Value Loss": 60.009033203125, "_runtime": 12586.461934566498, "_timestamp": 1585582502.306568, "_step": 25}
{"Episode reward": -99.83850753940503, "Episode length": 999, "Policy Loss": -0.8478251695632935, "Value Loss": 32.349998474121094, "_runtime": 12588.033532619476, "_timestamp": 1585582503.878166, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15852363407611847, "Value Loss": 6.203503608703613, "_runtime": 12589.639671087265, "_timestamp": 1585582505.4843044, "_step": 27}
{"Episode reward": -99.8013393290327, "Episode length": 999, "Policy Loss": 0.4063197076320648, "Value Loss": 10.165884017944336, "_runtime": 12591.2432076931, "_timestamp": 1585582507.087841, "_step": 28}
{"Episode reward": -99.78646617680648, "Episode length": 999, "Policy Loss": 1.0915530920028687, "Value Loss": 19.00637435913086, "_runtime": 12592.586823940277, "_timestamp": 1585582508.4314573, "_step": 29}
{"Episode reward": 13.200000000000657, "Episode length": 868, "Policy Loss": 2.7171616554260254, "Value Loss": 217.25277709960938, "_runtime": 12593.105132818222, "_timestamp": 1585582508.9497662, "_step": 30}
{"Episode reward": 69.29999999999984, "Episode length": 307, "Policy Loss": 6.133195400238037, "Value Loss": 255.727294921875, "_runtime": 12593.673419952393, "_timestamp": 1585582509.5180533, "_step": 31}
{"Episode reward": 65.9999999999998, "Episode length": 340, "Policy Loss": 4.815981388092041, "Value Loss": 74.21888732910156, "_runtime": 12595.24182677269, "_timestamp": 1585582511.08646, "_step": 32}
{"Episode reward": -99.83778377212444, "Episode length": 999, "Policy Loss": 3.3876450061798096, "Value Loss": 15.06949520111084, "_runtime": 12596.79637169838, "_timestamp": 1585582512.641005, "_step": 33}
{"Episode reward": -99.70537738576392, "Episode length": 999, "Policy Loss": 4.530093669891357, "Value Loss": 4.824822425842285, "_runtime": 12598.308607578278, "_timestamp": 1585582514.153241, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.531986236572266, "Value Loss": 2.8020875453948975, "_runtime": 12599.883541584015, "_timestamp": 1585582515.728175, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.283918380737305, "Value Loss": 51.30730056762695, "_runtime": 12601.454868078232, "_timestamp": 1585582517.2995014, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.037497520446777, "Value Loss": 96.29041290283203, "_runtime": 12603.015246868134, "_timestamp": 1585582518.8598802, "_step": 37}
{"Episode reward": -99.80087661892036, "Episode length": 999, "Policy Loss": 9.660273551940918, "Value Loss": 13.907515525817871, "_runtime": 12604.597193956375, "_timestamp": 1585582520.4418273, "_step": 38}
{"Episode reward": -99.82285684980313, "Episode length": 999, "Policy Loss": 11.184536933898926, "Value Loss": 36.102413177490234, "_runtime": 12606.178414106369, "_timestamp": 1585582522.0230474, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.646513938903809, "Value Loss": 32.439205169677734, "_runtime": 12607.758459329605, "_timestamp": 1585582523.6030927, "_step": 40}
{"Episode reward": -99.84455331042268, "Episode length": 999, "Policy Loss": 12.06822395324707, "Value Loss": 119.78284454345703, "_runtime": 12609.35086607933, "_timestamp": 1585582525.1954994, "_step": 41}
{"Episode reward": -99.80238452106575, "Episode length": 999, "Policy Loss": 10.938262939453125, "Value Loss": 24.51393699645996, "_runtime": 12610.947980880737, "_timestamp": 1585582526.7926142, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.675078392028809, "Value Loss": 1.5559684038162231, "_runtime": 12611.796043872833, "_timestamp": 1585582527.6406772, "_step": 43}
{"Episode reward": 48.19999999999954, "Episode length": 518, "Policy Loss": 10.387894630432129, "Value Loss": 28.667173385620117, "_runtime": 12612.819251298904, "_timestamp": 1585582528.6638846, "_step": 44}
{"Episode reward": 36.597168388589594, "Episode length": 635, "Policy Loss": 8.525425910949707, "Value Loss": 53.361114501953125, "_runtime": 12614.39930653572, "_timestamp": 1585582530.2439399, "_step": 45}
{"Episode reward": -99.81336191631713, "Episode length": 999, "Policy Loss": 6.94858980178833, "Value Loss": 12.075008392333984, "_runtime": 12615.951083421707, "_timestamp": 1585582531.7957168, "_step": 46}
{"Episode reward": -99.70844507850568, "Episode length": 999, "Policy Loss": 5.173025608062744, "Value Loss": 186.90774536132812, "_runtime": 12617.466115474701, "_timestamp": 1585582533.3107488, "_step": 47}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": 7.35618782043457, "Value Loss": 36.93122100830078, "_runtime": 12619.060983896255, "_timestamp": 1585582534.9056172, "_step": 48}
{"Episode reward": -99.8423325598226, "Episode length": 999, "Policy Loss": 6.577544212341309, "Value Loss": 9.34993839263916, "_runtime": 12620.693206310272, "_timestamp": 1585582536.5378397, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.091089725494385, "Value Loss": 30.75657844543457, "_runtime": 12622.286643505096, "_timestamp": 1585582538.1312768, "_step": 50}
{"Episode reward": -99.88226171135763, "Episode length": 999, "Policy Loss": 6.335096836090088, "Value Loss": 12.759203910827637, "_runtime": 12623.887164592743, "_timestamp": 1585582539.731798, "_step": 51}
{"Episode reward": -99.73920974470535, "Episode length": 999, "Policy Loss": 6.457784175872803, "Value Loss": 52.9240837097168, "_runtime": 12624.83334493637, "_timestamp": 1585582540.6779783, "_step": 52}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 5.970703601837158, "Value Loss": 49.05703353881836, "_runtime": 12625.504644870758, "_timestamp": 1585582541.3492782, "_step": 53}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 5.470538139343262, "Value Loss": 44.11891174316406, "_runtime": 12627.095069408417, "_timestamp": 1585582542.9397027, "_step": 54}
{"Episode reward": -99.86946139968792, "Episode length": 999, "Policy Loss": 2.260138988494873, "Value Loss": 3.907285451889038, "_runtime": 12628.093556404114, "_timestamp": 1585582543.9381897, "_step": 55}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 2.1466710567474365, "Value Loss": 19.762584686279297, "_runtime": 12629.618080615997, "_timestamp": 1585582545.462714, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21447640657424927, "Value Loss": 1.4185495376586914, "_runtime": 12631.205706357956, "_timestamp": 1585582547.0503397, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3678175210952759, "Value Loss": 0.31096774339675903, "_runtime": 12632.65279340744, "_timestamp": 1585582548.4974267, "_step": 58}
{"Episode reward": 7.300000000000992, "Episode length": 927, "Policy Loss": -1.476922631263733, "Value Loss": 12.34461498260498, "_runtime": 12633.628232479095, "_timestamp": 1585582549.4728658, "_step": 59}
{"Episode reward": 39.09999999999941, "Episode length": 609, "Policy Loss": -2.0014402866363525, "Value Loss": 18.12203598022461, "_runtime": 12635.22473359108, "_timestamp": 1585582551.069367, "_step": 60}
{"Episode reward": -99.86253195404866, "Episode length": 999, "Policy Loss": -4.049464702606201, "Value Loss": 0.2916632294654846, "_runtime": 12636.269632816315, "_timestamp": 1585582552.1142662, "_step": 61}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": -3.2856884002685547, "Value Loss": 16.53554344177246, "_runtime": 12637.810845375061, "_timestamp": 1585582553.6554787, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.429982662200928, "Value Loss": 0.5246309041976929, "_runtime": 12639.137229919434, "_timestamp": 1585582554.9818633, "_step": 63}
{"Episode reward": 17.00000000000044, "Episode length": 830, "Policy Loss": -4.9025092124938965, "Value Loss": 13.535872459411621, "_runtime": 12640.693438768387, "_timestamp": 1585582556.538072, "_step": 64}
{"Episode reward": -99.89934190660576, "Episode length": 999, "Policy Loss": -6.589292526245117, "Value Loss": 1.1594611406326294, "_runtime": 12642.274532079697, "_timestamp": 1585582558.1191654, "_step": 65}
{"Episode reward": -99.83350052572646, "Episode length": 999, "Policy Loss": -6.9267659187316895, "Value Loss": 1.5587806701660156, "_runtime": 12643.880717754364, "_timestamp": 1585582559.725351, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.306601047515869, "Value Loss": 2.3961284160614014, "_runtime": 12644.593131303787, "_timestamp": 1585582560.4377646, "_step": 67}
{"Episode reward": 56.79999999999966, "Episode length": 432, "Policy Loss": -5.891574382781982, "Value Loss": 26.396574020385742, "_runtime": 12645.813968658447, "_timestamp": 1585582561.658602, "_step": 68}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": -6.868465423583984, "Value Loss": 16.09649085998535, "_runtime": 12647.396936178207, "_timestamp": 1585582563.2415695, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.774789810180664, "Value Loss": 2.063157320022583, "_runtime": 12648.929863452911, "_timestamp": 1585582564.7744968, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.904852867126465, "Value Loss": 1.915029525756836, "_runtime": 12649.466331243515, "_timestamp": 1585582565.3109646, "_step": 71}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": -5.441923141479492, "Value Loss": 34.652015686035156, "_runtime": 12651.043605566025, "_timestamp": 1585582566.888239, "_step": 72}
{"Episode reward": -99.70039384737471, "Episode length": 999, "Policy Loss": -7.818418502807617, "Value Loss": 1.3580591678619385, "_runtime": 12651.546973228455, "_timestamp": 1585582567.3916066, "_step": 73}
{"Episode reward": 70.89999999999986, "Episode length": 291, "Policy Loss": -5.336997032165527, "Value Loss": 35.693485260009766, "_runtime": 12653.065830469131, "_timestamp": 1585582568.9104638, "_step": 74}
{"Episode reward": -99.83524665869633, "Episode length": 999, "Policy Loss": -7.981645107269287, "Value Loss": 2.875016927719116, "_runtime": 12654.65822505951, "_timestamp": 1585582570.5028584, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.746250152587891, "Value Loss": 2.0845463275909424, "_runtime": 12655.534636735916, "_timestamp": 1585582571.37927, "_step": 76}
{"Episode reward": 42.66392565071529, "Episode length": 576, "Policy Loss": -6.481400489807129, "Value Loss": 20.245281219482422, "_runtime": 12656.547837018967, "_timestamp": 1585582572.3924704, "_step": 77}
{"Episode reward": 36.499999999999375, "Episode length": 635, "Policy Loss": -6.388637065887451, "Value Loss": 18.491697311401367, "_runtime": 12658.12581729889, "_timestamp": 1585582573.9704506, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.245978832244873, "Value Loss": 1.0701570510864258, "_runtime": 12659.551983118057, "_timestamp": 1585582575.3966165, "_step": 79}
{"Episode reward": 7.477224781737718, "Episode length": 926, "Policy Loss": -6.1971917152404785, "Value Loss": 11.748054504394531, "_runtime": 12661.098557710648, "_timestamp": 1585582576.943191, "_step": 80}
{"Episode reward": -99.86765223145345, "Episode length": 999, "Policy Loss": -6.793323516845703, "Value Loss": 0.9065467119216919, "_runtime": 12661.996015310287, "_timestamp": 1585582577.8406487, "_step": 81}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": -4.650892734527588, "Value Loss": 19.552812576293945, "_runtime": 12663.583801269531, "_timestamp": 1585582579.4284346, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.322562217712402, "Value Loss": 0.6409551501274109, "_runtime": 12665.181695461273, "_timestamp": 1585582581.0263288, "_step": 83}
{"Episode reward": -99.70101947672525, "Episode length": 999, "Policy Loss": -6.123320579528809, "Value Loss": 0.6132075786590576, "_runtime": 12666.748748779297, "_timestamp": 1585582582.5933821, "_step": 84}
{"Episode reward": -99.82133646011214, "Episode length": 999, "Policy Loss": -5.916945457458496, "Value Loss": 0.6396616101264954, "_runtime": 12668.357028245926, "_timestamp": 1585582584.2016616, "_step": 85}
{"Episode reward": -99.72101937308769, "Episode length": 999, "Policy Loss": -5.772048473358154, "Value Loss": 0.6698231101036072, "_runtime": 12668.90605521202, "_timestamp": 1585582584.7506886, "_step": 86}
{"Episode reward": 68.39999999999984, "Episode length": 316, "Policy Loss": -3.1568844318389893, "Value Loss": 32.834171295166016, "_runtime": 12670.477760076523, "_timestamp": 1585582586.3223934, "_step": 87}
{"Episode reward": -99.76314572766283, "Episode length": 999, "Policy Loss": -5.428382396697998, "Value Loss": 0.47604134678840637, "_runtime": 12671.112344264984, "_timestamp": 1585582586.9569776, "_step": 88}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": -3.300031900405884, "Value Loss": 26.68854331970215, "_runtime": 12672.218106031418, "_timestamp": 1585582588.0627394, "_step": 89}
{"Episode reward": 27.499890967830865, "Episode length": 726, "Policy Loss": -4.1075968742370605, "Value Loss": 13.81275463104248, "_runtime": 12673.80824136734, "_timestamp": 1585582589.6528747, "_step": 90}
{"Episode reward": -99.78721375018219, "Episode length": 999, "Policy Loss": -5.060698986053467, "Value Loss": 0.8138633370399475, "_runtime": 12675.285067558289, "_timestamp": 1585582591.129701, "_step": 91}
{"Episode reward": 4.600000000001145, "Episode length": 954, "Policy Loss": -4.050421237945557, "Value Loss": 11.4940767288208, "_runtime": 12675.920494318008, "_timestamp": 1585582591.7651277, "_step": 92}
{"Episode reward": 63.999999999999766, "Episode length": 360, "Policy Loss": -2.6703813076019287, "Value Loss": 27.5035457611084, "_runtime": 12677.516982078552, "_timestamp": 1585582593.3616154, "_step": 93}
{"Episode reward": -99.80826394036272, "Episode length": 999, "Policy Loss": -4.537078857421875, "Value Loss": 0.39047521352767944, "_runtime": 12679.099320411682, "_timestamp": 1585582594.9439538, "_step": 94}
{"Episode reward": -99.70002818181972, "Episode length": 999, "Policy Loss": -4.403564929962158, "Value Loss": 0.8385015726089478, "_runtime": 12680.627625703812, "_timestamp": 1585582596.472259, "_step": 95}
{"Episode reward": -99.80630198754231, "Episode length": 999, "Policy Loss": -4.234626293182373, "Value Loss": 0.5618776679039001, "_runtime": 12681.880289077759, "_timestamp": 1585582597.7249224, "_step": 96}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": -3.075754165649414, "Value Loss": 12.877392768859863, "_runtime": 12683.467318058014, "_timestamp": 1585582599.3119514, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.8662943840026855, "Value Loss": 0.2702169418334961, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932, 0.07935218513011932]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1048528403043747, 0.3868827819824219, 0.8786183595657349, 1.3703540563583374, 1.8620896339416504, 2.353825092315674, 2.8455607891082764, 3.3372962474823, 3.8290319442749023, 4.320767879486084, 4.812503337860107, 5.304238796234131, 5.7959747314453125, 6.287710189819336, 6.779445648193359, 7.271181583404541, 7.7629170417785645, 8.254652976989746, 8.74638843536377, 9.238123893737793, 9.729859352111816, 10.22159481048584, 10.713330268859863, 11.205066680908203, 11.696802139282227, 12.18853759765625, 12.680273056030273, 13.172008514404297, 13.66374397277832, 14.15548038482666, 14.647215843200684, 15.138951301574707, 15.63068675994873, 16.12242317199707, 16.614158630371094, 17.105894088745117, 17.59762954711914, 18.089365005493164, 18.581100463867188, 19.07283592224121, 19.564571380615234, 20.056306838989258, 20.54804229736328, 21.039777755737305, 21.531513214111328, 22.023250579833984, 22.514986038208008, 23.00672149658203, 23.498456954956055, 23.990192413330078, 24.4819278717041, 24.973663330078125, 25.46539878845215, 25.957134246826172, 26.448869705200195, 26.94060516357422, 27.432340621948242, 27.924076080322266, 28.415813446044922, 28.907548904418945, 29.39928436279297, 29.891019821166992, 30.382755279541016, 30.87449073791504, 31.366226196289062]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2095668911933899, -0.2014068216085434, -0.1932467520236969, -0.1850866675376892, -0.1769265979528427, -0.16876652836799622, -0.16060644388198853, -0.15244637429714203, -0.14428630471229553, -0.13612623512744904, -0.12796616554260254, -0.11980608105659485, -0.11164601147174835, -0.10348594188690186, -0.09532586485147476, -0.08716578781604767, -0.07900571823120117, -0.07084564864635468, -0.06268557906150818, -0.05452549457550049, -0.04636542499065399, -0.038205355405807495, -0.030045270919799805, -0.021885201334953308, -0.013725131750106812, -0.005565062165260315, 0.0025950074195861816, 0.010755091905593872, 0.01891516149044037, 0.027075231075286865, 0.035235315561294556, 0.04339537024497986, 0.05155545473098755, 0.05971553921699524, 0.06787559390068054, 0.07603567838668823, 0.08419573307037354, 0.09235581755638123, 0.10051590204238892, 0.10867595672607422, 0.11683604121208191, 0.1249961256980896, 0.1331561803817749, 0.1413162648677826, 0.14947634935379028, 0.15763640403747559, 0.16579648852348328, 0.17395654320716858, 0.18211662769317627, 0.19027671217918396, 0.19843676686286926, 0.20659685134887695, 0.21475690603256226, 0.22291699051856995, 0.23107707500457764, 0.23923712968826294, 0.24739721417427063, 0.2555572986602783, 0.2637173533439636, 0.2718774378299713, 0.280037522315979, 0.2881975769996643, 0.2963576316833496, 0.3045177459716797, 0.312677800655365]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 19.0, 1.0, 25.0, 20.0, 387.0, 9.0, 18.0, 7.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-1.9510670900344849, -1.8762620687484741, -1.8014570474624634, -1.7266520261764526, -1.6518468856811523, -1.5770418643951416, -1.5022368431091309, -1.4274318218231201, -1.3526268005371094, -1.2778217792510986, -1.203016757965088, -1.1282117366790771, -1.0534067153930664, -0.9786016345024109, -0.9037965536117554, -0.8289915323257446, -0.7541865110397339, -0.6793814897537231, -0.6045764684677124, -0.5297714471817017, -0.4549664258956909, -0.3801612854003906, -0.3053562641143799, -0.23055124282836914, -0.1557462215423584, -0.08094120025634766, -0.006136178970336914, 0.06866896152496338, 0.14347398281097412, 0.21827900409698486, 0.2930840253829956, 0.36788904666900635, 0.4426940679550171, 0.5174990892410278, 0.5923041105270386, 0.6671091318130493, 0.7419141530990601, 0.8167191743850708, 0.8915241956710815, 0.9663292169570923, 1.041134238243103, 1.1159394979476929, 1.1907445192337036, 1.2655495405197144, 1.340354561805725, 1.4151595830917358, 1.4899646043777466, 1.5647696256637573, 1.639574646949768, 1.7143796682357788, 1.7891846895217896, 1.8639897108078003, 1.938794732093811, 2.0135998725891113, 2.088405132293701, 2.163209915161133, 2.2380151748657227, 2.3128199577331543, 2.387625217437744, 2.462430000305176, 2.5372352600097656, 2.6120400428771973, 2.686845302581787, 2.7616500854492188, 2.8364553451538086]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, 1.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.16341958940029144, -0.14520004391670227, -0.1269804984331131, -0.10876096040010452, -0.09054141491651535, -0.07232186943292618, -0.0541023313999176, -0.03588278591632843, -0.017663240432739258, 0.0005563050508499146, 0.018775850534439087, 0.03699539601802826, 0.05521492660045624, 0.07343447208404541, 0.09165401756763458, 0.10987357795238495, 0.12809310853481293, 0.1463126391172409, 0.16453219950199127, 0.18275173008441925, 0.20097129046916962, 0.2191908210515976, 0.23741038143634796, 0.25562989711761475, 0.2738494277000427, 0.2920690178871155, 0.31028854846954346, 0.32850807905197144, 0.3467276096343994, 0.3649471402168274, 0.38316673040390015, 0.4013862609863281, 0.4196057915687561, 0.4378253221511841, 0.45604485273361206, 0.4742644429206848, 0.4924839735031128, 0.5107035040855408, 0.5289230346679688, 0.5471426248550415, 0.5653621554374695, 0.5835816860198975, 0.6018012166023254, 0.6200207471847534, 0.6382403373718262, 0.6564598679542542, 0.6746793985366821, 0.6928989291191101, 0.7111184597015381, 0.7293380498886108, 0.7475575804710388, 0.7657771110534668, 0.7839966416358948, 0.8022162318229675, 0.8204357624053955, 0.8386553525924683, 0.8568748235702515, 0.8750944137573242, 0.8933138847351074, 0.9115334749221802, 0.9297530651092529, 0.9479725360870361, 0.9661921262741089, 0.9844115972518921, 1.0026311874389648]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 5.0, 9.0, 8.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.29329437017440796, -0.287445604801178, -0.281596839427948, -0.275748074054718, -0.26989930868148804, -0.26405054330825806, -0.2582017779350281, -0.2523530125617981, -0.2465042620897293, -0.24065549671649933, -0.23480673134326935, -0.22895796597003937, -0.2231092005968094, -0.2172604352235794, -0.21141168475151062, -0.20556291937828064, -0.19971415400505066, -0.19386538863182068, -0.1880166232585907, -0.18216785788536072, -0.17631909251213074, -0.17047032713890076, -0.16462156176567078, -0.1587727963924408, -0.15292403101921082, -0.14707526564598083, -0.14122650027275085, -0.13537774980068207, -0.1295289844274521, -0.1236802190542221, -0.11783145368099213, -0.11198268830776215, -0.10613392293453217, -0.10028515756130219, -0.0944363921880722, -0.08858762681484222, -0.08273886144161224, -0.07689009606838226, -0.07104134559631348, -0.0651925802230835, -0.059343814849853516, -0.053495049476623535, -0.047646284103393555, -0.041797518730163574, -0.035948753356933594, -0.030099987983703613, -0.024251222610473633, -0.018402457237243652, -0.012553691864013672, -0.006704926490783691, -0.0008561611175537109, 0.0049926042556762695, 0.01084136962890625, 0.01669013500213623, 0.022538870573043823, 0.028387635946273804, 0.034236401319503784, 0.040085166692733765, 0.045933932065963745, 0.051782697439193726, 0.057631462812423706, 0.06348022818565369, 0.06932899355888367, 0.07517775893211365, 0.08102652430534363]}, "_runtime": 12684.947544336319, "_timestamp": 1585582600.7921777, "_step": 98}
{"Episode reward": 6.10000000000106, "Episode length": 939, "Policy Loss": -2.9234602451324463, "Value Loss": 10.706798553466797, "_runtime": 12685.622760295868, "_timestamp": 1585582601.4673936, "_step": 99}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": -1.608417272567749, "Value Loss": 24.608552932739258, "_runtime": 12686.296199321747, "_timestamp": 1585582602.1408327, "_step": 100}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": -1.566672444343567, "Value Loss": 24.613536834716797, "_runtime": 12687.31200671196, "_timestamp": 1585582603.15664, "_step": 101}
{"Episode reward": 36.09293460510608, "Episode length": 640, "Policy Loss": -2.1569743156433105, "Value Loss": 15.687448501586914, "_runtime": 12688.500508785248, "_timestamp": 1585582604.3451421, "_step": 102}
{"Episode reward": 22.700000000000117, "Episode length": 773, "Policy Loss": -2.23123836517334, "Value Loss": 12.871487617492676, "_runtime": 12689.017230272293, "_timestamp": 1585582604.8618636, "_step": 103}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": -0.5910987257957458, "Value Loss": 30.62218475341797, "_runtime": 12690.490363836288, "_timestamp": 1585582606.3349972, "_step": 104}
{"Episode reward": 4.600000000001145, "Episode length": 954, "Policy Loss": -2.253340482711792, "Value Loss": 10.40450668334961, "_runtime": 12690.894894599915, "_timestamp": 1585582606.739528, "_step": 105}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 0.7294451594352722, "Value Loss": 42.405662536621094, "_runtime": 12691.250943183899, "_timestamp": 1585582607.0955765, "_step": 106}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 1.0738996267318726, "Value Loss": 42.592464447021484, "_runtime": 12692.851920366287, "_timestamp": 1585582608.6965537, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.873142957687378, "Value Loss": 1.0965431928634644, "_runtime": 12694.350631713867, "_timestamp": 1585582610.195265, "_step": 108}
{"Episode reward": -99.65239552147547, "Episode length": 999, "Policy Loss": -2.7960965633392334, "Value Loss": 0.716066837310791, "_runtime": 12695.504799842834, "_timestamp": 1585582611.3494332, "_step": 109}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": -1.3893519639968872, "Value Loss": 12.944192886352539, "_runtime": 12696.430403232574, "_timestamp": 1585582612.2750366, "_step": 110}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": -1.037040114402771, "Value Loss": 16.98851203918457, "_runtime": 12697.998518943787, "_timestamp": 1585582613.8431523, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4906976222991943, "Value Loss": 0.23220650851726532, "_runtime": 12699.545198440552, "_timestamp": 1585582615.3898318, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.408494710922241, "Value Loss": 0.17341823875904083, "_runtime": 12701.092726707458, "_timestamp": 1585582616.93736, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.322148323059082, "Value Loss": 0.24491868913173676, "_runtime": 12701.932423591614, "_timestamp": 1585582617.777057, "_step": 114}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": -0.7651714086532593, "Value Loss": 18.926294326782227, "_runtime": 12703.50920677185, "_timestamp": 1585582619.35384, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.14304518699646, "Value Loss": 0.20065169036388397, "_runtime": 12705.100815057755, "_timestamp": 1585582620.9454484, "_step": 116}
{"Episode reward": -99.87887616790691, "Episode length": 999, "Policy Loss": -2.061129570007324, "Value Loss": 0.13137173652648926, "_runtime": 12705.594799757004, "_timestamp": 1585582621.439433, "_step": 117}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 0.7985027432441711, "Value Loss": 32.9847412109375, "_runtime": 12707.166642665863, "_timestamp": 1585582623.011276, "_step": 118}
{"Episode reward": -99.883819031714, "Episode length": 999, "Policy Loss": -1.9245185852050781, "Value Loss": 0.07103617489337921, "_runtime": 12708.761547803879, "_timestamp": 1585582624.6061811, "_step": 119}
{"Episode reward": -99.78070992529253, "Episode length": 999, "Policy Loss": -1.8751810789108276, "Value Loss": 0.06343656033277512, "_runtime": 12710.276444911957, "_timestamp": 1585582626.1210783, "_step": 120}
{"Episode reward": -99.83367739319662, "Episode length": 999, "Policy Loss": -1.8064321279525757, "Value Loss": 0.08247591555118561, "_runtime": 12711.87597322464, "_timestamp": 1585582627.7206066, "_step": 121}
{"Episode reward": -99.80447524934867, "Episode length": 999, "Policy Loss": -1.75589919090271, "Value Loss": 0.09143787622451782, "_runtime": 12713.458055257797, "_timestamp": 1585582629.3026886, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.679161787033081, "Value Loss": 0.07522473484277725, "_runtime": 12714.096434354782, "_timestamp": 1585582629.9410677, "_step": 123}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 0.3649212419986725, "Value Loss": 25.64027976989746, "_runtime": 12715.675341367722, "_timestamp": 1585582631.5199747, "_step": 124}
{"Episode reward": -99.73896112814406, "Episode length": 999, "Policy Loss": -1.5853341817855835, "Value Loss": 0.05053861439228058, "_runtime": 12717.313986301422, "_timestamp": 1585582633.1586196, "_step": 125}
{"Episode reward": -99.81517783440509, "Episode length": 999, "Policy Loss": -1.5354533195495605, "Value Loss": 0.045790400356054306, "_runtime": 12718.899951696396, "_timestamp": 1585582634.744585, "_step": 126}
{"Episode reward": -99.82736035734276, "Episode length": 999, "Policy Loss": -1.501665711402893, "Value Loss": 0.11332625150680542, "_runtime": 12720.486518621445, "_timestamp": 1585582636.331152, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4630860090255737, "Value Loss": 0.23566576838493347, "_runtime": 12722.07722067833, "_timestamp": 1585582637.921854, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.399833083152771, "Value Loss": 0.10136842727661133, "_runtime": 12723.644988775253, "_timestamp": 1585582639.489622, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3427027463912964, "Value Loss": 0.045671187341213226, "_runtime": 12725.24272942543, "_timestamp": 1585582641.0873628, "_step": 130}
{"Episode reward": -99.83136656284192, "Episode length": 999, "Policy Loss": -1.2815805673599243, "Value Loss": 0.026773180812597275, "_runtime": 12726.84802532196, "_timestamp": 1585582642.6926587, "_step": 131}
{"Episode reward": -99.88591063171485, "Episode length": 999, "Policy Loss": -1.2315473556518555, "Value Loss": 0.02688479982316494, "_runtime": 12727.422830104828, "_timestamp": 1585582643.2674634, "_step": 132}
{"Episode reward": 65.9953842163084, "Episode length": 341, "Policy Loss": 1.1274570226669312, "Value Loss": 29.167070388793945, "_runtime": 12729.003246068954, "_timestamp": 1585582644.8478794, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1345503330230713, "Value Loss": 0.037790507078170776, "_runtime": 12730.601920366287, "_timestamp": 1585582646.4465537, "_step": 134}
{"Episode reward": -99.83262966759364, "Episode length": 999, "Policy Loss": -1.1056745052337646, "Value Loss": 0.0231308676302433, "_runtime": 12731.238664388657, "_timestamp": 1585582647.0832977, "_step": 135}
{"Episode reward": 59.1999999999997, "Episode length": 408, "Policy Loss": 0.7917817831039429, "Value Loss": 24.150876998901367, "_runtime": 12732.815558671951, "_timestamp": 1585582648.660192, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0580116510391235, "Value Loss": 0.04612119495868683, "_runtime": 12733.75486779213, "_timestamp": 1585582649.5995011, "_step": 137}
{"Episode reward": 42.49992556534654, "Episode length": 576, "Policy Loss": 0.28262609243392944, "Value Loss": 17.082059860229492, "_runtime": 12735.285843372345, "_timestamp": 1585582651.1304767, "_step": 138}
{"Episode reward": -99.81451468616584, "Episode length": 999, "Policy Loss": -1.0436371564865112, "Value Loss": 0.24436908960342407, "_runtime": 12736.880894899368, "_timestamp": 1585582652.7255282, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0037171840667725, "Value Loss": 0.07359718531370163, "_runtime": 12738.429505825043, "_timestamp": 1585582654.2741392, "_step": 140}
{"Episode reward": -99.77062975801388, "Episode length": 999, "Policy Loss": -0.9693272709846497, "Value Loss": 0.05438855662941933, "_runtime": 12740.019009113312, "_timestamp": 1585582655.8636425, "_step": 141}
{"Episode reward": -99.8005654335008, "Episode length": 999, "Policy Loss": -0.9230087995529175, "Value Loss": 0.16804730892181396, "_runtime": 12740.70247220993, "_timestamp": 1585582656.5471056, "_step": 142}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 1.0912401676177979, "Value Loss": 25.59360694885254, "_runtime": 12741.338174819946, "_timestamp": 1585582657.1828082, "_step": 143}
{"Episode reward": 60.89999999999972, "Episode length": 391, "Policy Loss": 1.072374701499939, "Value Loss": 25.054744720458984, "_runtime": 12742.914150238037, "_timestamp": 1585582658.7587836, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8647772073745728, "Value Loss": 0.03699195012450218, "_runtime": 12744.415536880493, "_timestamp": 1585582660.2601702, "_step": 145}
{"Episode reward": 1.9166162606341715, "Episode length": 981, "Policy Loss": -0.07376588881015778, "Value Loss": 10.095199584960938, "_runtime": 12745.94902920723, "_timestamp": 1585582661.7936625, "_step": 146}
{"Episode reward": -99.84800703525403, "Episode length": 999, "Policy Loss": -0.8507669568061829, "Value Loss": 0.11390092223882675, "_runtime": 12747.533906936646, "_timestamp": 1585582663.3785403, "_step": 147}
{"Episode reward": -99.7581117451177, "Episode length": 999, "Policy Loss": -0.8257943391799927, "Value Loss": 0.015993807464838028, "_runtime": 12749.137002706528, "_timestamp": 1585582664.981636, "_step": 148}
{"Episode reward": -99.78664207197586, "Episode length": 999, "Policy Loss": -0.8092811703681946, "Value Loss": 0.02448210120201111, "_runtime": 12750.76469039917, "_timestamp": 1585582666.6093237, "_step": 149}
{"Episode reward": -99.80037104040245, "Episode length": 999, "Policy Loss": -0.791016697883606, "Value Loss": 0.01534176804125309, "_runtime": 12752.375428199768, "_timestamp": 1585582668.2200615, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7612766027450562, "Value Loss": 0.015508942306041718, "_runtime": 12753.796715021133, "_timestamp": 1585582669.6413484, "_step": 151}
{"Episode reward": 10.000000000000838, "Episode length": 900, "Policy Loss": 0.1119750365614891, "Value Loss": 10.941903114318848, "_runtime": 12754.534287452698, "_timestamp": 1585582670.3789208, "_step": 152}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 0.961110532283783, "Value Loss": 21.93863296508789, "_runtime": 12756.127851486206, "_timestamp": 1585582671.9724848, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7240025401115417, "Value Loss": 0.04622868075966835, "_runtime": 12757.710720062256, "_timestamp": 1585582673.5553534, "_step": 154}
{"Episode reward": -99.80850813127914, "Episode length": 999, "Policy Loss": -0.7105805277824402, "Value Loss": 0.09297917038202286, "_runtime": 12758.939049959183, "_timestamp": 1585582674.7836833, "_step": 155}
{"Episode reward": 20.18250979781176, "Episode length": 799, "Policy Loss": 0.2786290645599365, "Value Loss": 12.287280082702637, "_runtime": 12759.756160497665, "_timestamp": 1585582675.6007938, "_step": 156}
{"Episode reward": 49.69999999999956, "Episode length": 503, "Policy Loss": 1.0771384239196777, "Value Loss": 19.51386070251465, "_runtime": 12761.331358194351, "_timestamp": 1585582677.1759915, "_step": 157}
{"Episode reward": 1.9000000000012989, "Episode length": 981, "Policy Loss": 0.06236030533909798, "Value Loss": 10.072616577148438, "_runtime": 12762.555269241333, "_timestamp": 1585582678.3999026, "_step": 158}
{"Episode reward": 22.497533735260504, "Episode length": 776, "Policy Loss": 0.29033127427101135, "Value Loss": 12.612040519714355, "_runtime": 12764.14981174469, "_timestamp": 1585582679.994445, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7145113348960876, "Value Loss": 0.05065099149942398, "_runtime": 12765.78752040863, "_timestamp": 1585582681.6321537, "_step": 160}
{"Episode reward": -99.77449882775406, "Episode length": 999, "Policy Loss": -0.7068959474563599, "Value Loss": 0.039264947175979614, "_runtime": 12767.348114490509, "_timestamp": 1585582683.1927478, "_step": 161}
{"Episode reward": -99.76825842410186, "Episode length": 999, "Policy Loss": -0.7104291319847107, "Value Loss": 0.13396069407463074, "_runtime": 12768.931147813797, "_timestamp": 1585582684.7757812, "_step": 162}
{"Episode reward": -99.83658536821464, "Episode length": 999, "Policy Loss": -0.6894592642784119, "Value Loss": 0.1276940554380417, "_runtime": 12770.09838628769, "_timestamp": 1585582685.9430196, "_step": 163}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.35855811834335327, "Value Loss": 13.510093688964844, "_runtime": 12770.750754356384, "_timestamp": 1585582686.5953877, "_step": 164}
{"Episode reward": 60.59999999999972, "Episode length": 394, "Policy Loss": 1.2948963642120361, "Value Loss": 24.83045196533203, "_runtime": 12772.32204914093, "_timestamp": 1585582688.1666825, "_step": 165}
{"Episode reward": -99.80214576721052, "Episode length": 999, "Policy Loss": -0.6604954600334167, "Value Loss": 0.02376111038029194, "_runtime": 12773.497896432877, "_timestamp": 1585582689.3425298, "_step": 166}
{"Episode reward": 24.700000000000003, "Episode length": 753, "Policy Loss": 0.3988063931465149, "Value Loss": 13.082088470458984, "_runtime": 12774.165680646896, "_timestamp": 1585582690.010314, "_step": 167}
{"Episode reward": 57.08676717281308, "Episode length": 430, "Policy Loss": 1.0978375673294067, "Value Loss": 22.86910629272461, "_runtime": 12775.749958515167, "_timestamp": 1585582691.5945919, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6685830950737, "Value Loss": 0.012255731038749218, "_runtime": 12776.982466936111, "_timestamp": 1585582692.8271003, "_step": 169}
{"Episode reward": 22.356516021490236, "Episode length": 777, "Policy Loss": 0.29608404636383057, "Value Loss": 12.622031211853027, "_runtime": 12778.506222486496, "_timestamp": 1585582694.3508558, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6883305311203003, "Value Loss": 0.05332215502858162, "_runtime": 12779.958074569702, "_timestamp": 1585582695.802708, "_step": 171}
{"Episode reward": 8.20000000000094, "Episode length": 918, "Policy Loss": 0.20335878431797028, "Value Loss": 10.609365463256836, "_runtime": 12781.52231836319, "_timestamp": 1585582697.3669517, "_step": 172}
{"Episode reward": -99.76821132637421, "Episode length": 999, "Policy Loss": -0.6933740377426147, "Value Loss": 0.07720436900854111, "_runtime": 12783.098230600357, "_timestamp": 1585582698.942864, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7036862969398499, "Value Loss": 0.03875456750392914, "_runtime": 12784.231195926666, "_timestamp": 1585582700.0758293, "_step": 174}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.4666314423084259, "Value Loss": 13.762125968933105, "_runtime": 12785.762088298798, "_timestamp": 1585582701.6067216, "_step": 175}
{"Episode reward": 3.1000000000012307, "Episode length": 969, "Policy Loss": 0.08627548813819885, "Value Loss": 10.162459373474121, "_runtime": 12787.346402645111, "_timestamp": 1585582703.191036, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6930027008056641, "Value Loss": 0.01065362524241209, "_runtime": 12788.191917657852, "_timestamp": 1585582704.036551, "_step": 177}
{"Episode reward": 49.59999999999956, "Episode length": 504, "Policy Loss": 0.8296996355056763, "Value Loss": 19.48602867126465, "_runtime": 12789.780804872513, "_timestamp": 1585582705.6254382, "_step": 178}
{"Episode reward": -99.8238955322639, "Episode length": 999, "Policy Loss": -0.6976228356361389, "Value Loss": 0.016824183985590935, "_runtime": 12790.817024469376, "_timestamp": 1585582706.6616578, "_step": 179}
{"Episode reward": 35.2999999999994, "Episode length": 647, "Policy Loss": 0.4366896450519562, "Value Loss": 15.117899894714355, "_runtime": 12792.364398002625, "_timestamp": 1585582708.2090313, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7111121416091919, "Value Loss": 0.030581574887037277, "_runtime": 12793.961553573608, "_timestamp": 1585582709.806187, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.720557451248169, "Value Loss": 0.027414396405220032, "_runtime": 12795.514639854431, "_timestamp": 1585582711.3592732, "_step": 182}
{"Episode reward": -99.80037327445903, "Episode length": 999, "Policy Loss": -0.7311387658119202, "Value Loss": 0.07671894133090973, "_runtime": 12797.093531608582, "_timestamp": 1585582712.938165, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7113400101661682, "Value Loss": 0.014541508629918098, "_runtime": 12798.692328453064, "_timestamp": 1585582714.5369618, "_step": 184}
{"Episode reward": -99.81739843040565, "Episode length": 999, "Policy Loss": -0.698137640953064, "Value Loss": 0.014166692271828651, "_runtime": 12799.531012535095, "_timestamp": 1585582715.3756459, "_step": 185}
{"Episode reward": 48.399999999999544, "Episode length": 516, "Policy Loss": 0.8268663883209229, "Value Loss": 19.076515197753906, "_runtime": 12801.115534305573, "_timestamp": 1585582716.9601676, "_step": 186}
{"Episode reward": -99.87571101933578, "Episode length": 999, "Policy Loss": -0.6819818615913391, "Value Loss": 0.016693400219082832, "_runtime": 12802.714137554169, "_timestamp": 1585582718.558771, "_step": 187}
{"Episode reward": -99.77864523902396, "Episode length": 999, "Policy Loss": -0.669181764125824, "Value Loss": 0.04390062764286995, "_runtime": 12804.125600337982, "_timestamp": 1585582719.9702337, "_step": 188}
{"Episode reward": 8.736138596759162, "Episode length": 913, "Policy Loss": 0.27994227409362793, "Value Loss": 10.81889533996582, "_runtime": 12805.719159603119, "_timestamp": 1585582721.563793, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6474091410636902, "Value Loss": 0.016068806871771812, "_runtime": 12807.317115545273, "_timestamp": 1585582723.161749, "_step": 190}
{"Episode reward": -99.82986718565085, "Episode length": 999, "Policy Loss": -0.6474325060844421, "Value Loss": 0.00971862394362688, "_runtime": 12808.899294614792, "_timestamp": 1585582724.743928, "_step": 191}
{"Episode reward": -99.80446750558774, "Episode length": 999, "Policy Loss": -0.6328694820404053, "Value Loss": 0.010167268104851246, "_runtime": 12810.483954906464, "_timestamp": 1585582726.3285882, "_step": 192}
{"Episode reward": -99.8035592470304, "Episode length": 999, "Policy Loss": -0.6147587895393372, "Value Loss": 0.02466183342039585, "_runtime": 12812.114493370056, "_timestamp": 1585582727.9591267, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6074174046516418, "Value Loss": 0.019783316180109978, "_runtime": 12813.706403017044, "_timestamp": 1585582729.5510364, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5980926156044006, "Value Loss": 0.010289972648024559, "_runtime": 12814.32811832428, "_timestamp": 1585582730.1727517, "_step": 195}
{"Episode reward": 62.51691695302699, "Episode length": 375, "Policy Loss": 1.4581058025360107, "Value Loss": 26.298542022705078, "_runtime": 12815.649399280548, "_timestamp": 1585582731.4940326, "_step": 196}
{"Episode reward": 16.878646620735978, "Episode length": 832, "Policy Loss": 0.3160957992076874, "Value Loss": 11.73627758026123, "_runtime": 12817.241519451141, "_timestamp": 1585582733.0861528, "_step": 197}
{"Episode reward": -99.80477448105673, "Episode length": 999, "Policy Loss": -0.6089535355567932, "Value Loss": 0.030978845432400703, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127, 0.17537224292755127]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7734389305114746, 0.4047797918319702, 1.582998514175415, 2.7612171173095703, 3.9394359588623047, 5.117654800415039, 6.295873165130615, 7.47409200668335, 8.652311325073242, 9.830530166625977, 11.008749008178711, 12.186967849731445, 13.365184783935547, 14.543403625488281, 15.721622467041016, 16.89984130859375, 18.078060150146484, 19.25627899169922, 20.434497833251953, 21.612716674804688, 22.790935516357422, 23.969154357910156, 25.14737319946289, 26.325592041015625, 27.503808975219727, 28.68202781677246, 29.860246658325195, 31.03846549987793, 32.2166862487793, 33.39490509033203, 34.573123931884766, 35.7513427734375, 36.929561614990234, 38.10778045654297, 39.2859992980957, 40.46421813964844, 41.64243698120117, 42.820655822753906, 43.99887466430664, 45.177093505859375, 46.35531234741211, 47.533531188964844, 48.71175003051758, 49.88996887207031, 51.06818771362305, 52.24640655517578, 53.424625396728516, 54.60284423828125, 55.78105926513672, 56.95927810668945, 58.13749694824219, 59.31571578979492, 60.493934631347656, 61.67215347290039, 62.850372314453125, 64.02859497070312, 65.2068099975586, 66.3850326538086, 67.56324768066406, 68.74147033691406, 69.91968536376953, 71.09790802001953, 72.276123046875, 73.454345703125, 74.63256072998047]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.47007837891578674, -0.4519333839416504, -0.4337884187698364, -0.4156434237957001, -0.3974984288215637, -0.37935346364974976, -0.3612084686756134, -0.34306347370147705, -0.3249185085296631, -0.3067735433578491, -0.28862854838371277, -0.2704835534095764, -0.25233858823776245, -0.2341935932636261, -0.21604859828948975, -0.19790363311767578, -0.17975863814353943, -0.16161364316940308, -0.1434686779975891, -0.12532368302345276, -0.1071787178516388, -0.08903372287750244, -0.07088872790336609, -0.052743762731552124, -0.03459876775741577, -0.01645377278327942, 0.001691192388534546, 0.0198361873626709, 0.03798118233680725, 0.056126147508621216, 0.07427111268043518, 0.09241613745689392, 0.11056110262870789, 0.12870606780052185, 0.1468510925769806, 0.16499605774879456, 0.18314102292060852, 0.20128604769706726, 0.21943101286888123, 0.2375759780406952, 0.25572094321250916, 0.2738659679889679, 0.29201093316078186, 0.3101558983325958, 0.32830092310905457, 0.34644588828086853, 0.3645908534526825, 0.38273587822914124, 0.4008808434009552, 0.41902580857276917, 0.4371708333492279, 0.45531579852104187, 0.47346076369285583, 0.4916057884693146, 0.5097507238388062, 0.5278956890106201, 0.5460407733917236, 0.5641857385635376, 0.5823307037353516, 0.6004756689071655, 0.6186206340789795, 0.636765718460083, 0.654910683631897, 0.6730556488037109, 0.6912006139755249]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 18.0, 25.0, 398.0, 0.0, 0.0, 25.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-4.419376373291016, -4.247673511505127, -4.07597017288208, -3.9042673110961914, -3.7325642108917236, -3.560861110687256, -3.389158248901367, -3.2174551486968994, -3.0457520484924316, -2.874048948287964, -2.702345848083496, -2.5306429862976074, -2.3589398860931396, -2.187236785888672, -2.015533924102783, -1.8438308238983154, -1.6721277236938477, -1.5004246234893799, -1.328721523284912, -1.1570186614990234, -0.9853155612945557, -0.8136124610900879, -0.6419095993041992, -0.47020649909973145, -0.29850339889526367, -0.126800537109375, 0.044902801513671875, 0.21660566329956055, 0.3883085250854492, 0.5600118637084961, 0.7317147254943848, 0.9034180641174316, 1.0751209259033203, 1.246823787689209, 1.4185271263122559, 1.5902299880981445, 1.7619333267211914, 1.93363618850708, 2.1053390502929688, 2.2770423889160156, 2.4487452507019043, 2.620448112487793, 2.79215145111084, 2.9638543128967285, 3.135557174682617, 3.307260513305664, 3.4789633750915527, 3.6506662368774414, 3.8223695755004883, 3.994072914123535, 4.165775299072266, 4.3374786376953125, 4.509181976318359, 4.68088436126709, 4.852587699890137, 5.024291038513184, 5.195993423461914, 5.367696762084961, 5.539400100708008, 5.711103439331055, 5.882805824279785, 6.054509162902832, 6.226212501525879, 6.397914886474609, 6.569618225097656]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [4.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.5091243982315063, -0.46163564920425415, -0.41414692997932434, -0.36665821075439453, -0.31916946172714233, -0.27168071269989014, -0.22419199347496033, -0.17670327425003052, -0.12921452522277832, -0.08172577619552612, -0.034237056970596313, 0.013251662254333496, 0.06074041128158569, 0.10822916030883789, 0.1557178497314453, 0.2032065987586975, 0.2506953477859497, 0.2981840968132019, 0.3456728458404541, 0.3931615352630615, 0.4406502842903137, 0.4881390333175659, 0.5356277227401733, 0.5831165313720703, 0.6306052207946777, 0.6780939102172852, 0.7255827188491821, 0.7730714082717896, 0.820560097694397, 0.868048906326294, 0.9155375957489014, 0.9630264043807983, 1.0105150938034058, 1.0580037832260132, 1.1054925918579102, 1.1529812812805176, 1.2004700899124146, 1.247958779335022, 1.2954474687576294, 1.3429362773895264, 1.3904249668121338, 1.4379136562347412, 1.4854024648666382, 1.5328911542892456, 1.580379843711853, 1.6278685331344604, 1.675357460975647, 1.7228461503982544, 1.7703348398208618, 1.8178235292434692, 1.8653122186660767, 1.9128011465072632, 1.9602898359298706, 2.0077786445617676, 2.055267333984375, 2.1027560234069824, 2.15024471282959, 2.1977334022521973, 2.2452220916748047, 2.292710781097412, 2.3401994705200195, 2.387688159942627, 2.4351773262023926, 2.482666015625, 2.5301547050476074]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 4.0, 4.0, 0.0, 3.0, 5.0, 3.0, 2.0, 2.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6366246938705444, -0.618878185749054, -0.6011316776275635, -0.583385169506073, -0.5656386613845825, -0.547892153263092, -0.5301456451416016, -0.5123991370201111, -0.4946526288986206, -0.4769061207771301, -0.45915961265563965, -0.44141310453414917, -0.4236666262149811, -0.4059201180934906, -0.3881736099720001, -0.37042710185050964, -0.35268059372901917, -0.3349340856075287, -0.3171875774860382, -0.29944106936454773, -0.28169456124305725, -0.2639480531215668, -0.2462015450000763, -0.22845503687858582, -0.21070855855941772, -0.19296205043792725, -0.17521554231643677, -0.1574690341949463, -0.1397225260734558, -0.12197601795196533, -0.10422950983047485, -0.08648300170898438, -0.0687364935874939, -0.05098998546600342, -0.03324347734451294, -0.015496969223022461, 0.0022495388984680176, 0.019996047019958496, 0.037742555141448975, 0.05548906326293945, 0.07323557138442993, 0.09098207950592041, 0.10872858762741089, 0.12647509574890137, 0.14422160387039185, 0.16196811199188232, 0.1797146201133728, 0.19746112823486328, 0.21520757675170898, 0.23295408487319946, 0.25070059299468994, 0.2684471011161804, 0.2861936092376709, 0.3039401173591614, 0.32168662548065186, 0.33943313360214233, 0.3571796417236328, 0.37492620944976807, 0.39267265796661377, 0.410419225692749, 0.4281656742095947, 0.44591224193573, 0.4636586904525757, 0.48140525817871094, 0.49915170669555664]}, "_runtime": 12817.860262393951, "_timestamp": 1585582733.7048957, "_step": 198}
{"Episode reward": 60.59999999999972, "Episode length": 394, "Policy Loss": 1.3227782249450684, "Value Loss": 24.715770721435547, "_runtime": 12819.178948879242, "_timestamp": 1585582735.0235822, "_step": 199}
{"Episode reward": 15.658826941252272, "Episode length": 845, "Policy Loss": 0.26150181889533997, "Value Loss": 11.550524711608887, "_runtime": 12820.539870500565, "_timestamp": 1585582736.3845038, "_step": 200}
{"Episode reward": 14.500000000000583, "Episode length": 855, "Policy Loss": 0.2471037060022354, "Value Loss": 11.892420768737793, "_runtime": 12821.22298669815, "_timestamp": 1585582737.06762, "_step": 201}
{"Episode reward": 56.137805443629276, "Episode length": 439, "Policy Loss": 1.108293056488037, "Value Loss": 22.49843978881836, "_runtime": 12822.36567401886, "_timestamp": 1585582738.2103074, "_step": 202}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.622762143611908, "Value Loss": 13.815044403076172, "_runtime": 12823.234217643738, "_timestamp": 1585582739.078851, "_step": 203}
{"Episode reward": 45.90906217098187, "Episode length": 541, "Policy Loss": 0.8943586945533752, "Value Loss": 17.91798973083496, "_runtime": 12824.763281106949, "_timestamp": 1585582740.6079144, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.631561815738678, "Value Loss": 0.011264145374298096, "_runtime": 12825.468616724014, "_timestamp": 1585582741.31325, "_step": 205}
{"Episode reward": 56.21414593122865, "Episode length": 438, "Policy Loss": 1.1697423458099365, "Value Loss": 22.450895309448242, "_runtime": 12827.015310525894, "_timestamp": 1585582742.8599439, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6490585207939148, "Value Loss": 0.007360892370343208, "_runtime": 12828.605866909027, "_timestamp": 1585582744.4505002, "_step": 207}
{"Episode reward": -99.8937058031545, "Episode length": 999, "Policy Loss": -0.6640384197235107, "Value Loss": 0.012632792815566063, "_runtime": 12829.212879896164, "_timestamp": 1585582745.0575132, "_step": 208}
{"Episode reward": 61.79649352431271, "Episode length": 383, "Policy Loss": 1.8581044673919678, "Value Loss": 25.690345764160156, "_runtime": 12830.788016319275, "_timestamp": 1585582746.6326497, "_step": 209}
{"Episode reward": -99.86114965081076, "Episode length": 999, "Policy Loss": -0.7041553854942322, "Value Loss": 0.01347083505243063, "_runtime": 12832.35794711113, "_timestamp": 1585582748.2025805, "_step": 210}
{"Episode reward": -99.83359951414027, "Episode length": 999, "Policy Loss": -0.7191777229309082, "Value Loss": 0.036349255591630936, "_runtime": 12833.87393450737, "_timestamp": 1585582749.7185678, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7261289358139038, "Value Loss": 0.03348750248551369, "_runtime": 12835.503293275833, "_timestamp": 1585582751.3479266, "_step": 212}
{"Episode reward": -99.86195411681989, "Episode length": 999, "Policy Loss": -0.747891366481781, "Value Loss": 0.137956902384758, "_runtime": 12837.12559580803, "_timestamp": 1585582752.9702291, "_step": 213}
{"Episode reward": -99.83406814075866, "Episode length": 999, "Policy Loss": -0.7444328665733337, "Value Loss": 0.10955792665481567, "_runtime": 12838.323849201202, "_timestamp": 1585582754.1684825, "_step": 214}
{"Episode reward": 24.566864682361498, "Episode length": 756, "Policy Loss": 0.26726973056793213, "Value Loss": 12.907065391540527, "_runtime": 12838.836356639862, "_timestamp": 1585582754.68099, "_step": 215}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 1.9181991815567017, "Value Loss": 32.29615020751953, "_runtime": 12840.417454004288, "_timestamp": 1585582756.2620873, "_step": 216}
{"Episode reward": -99.80899194516101, "Episode length": 999, "Policy Loss": -0.7565324902534485, "Value Loss": 0.07228755205869675, "_runtime": 12840.997350215912, "_timestamp": 1585582756.8419836, "_step": 217}
{"Episode reward": 64.19999999999976, "Episode length": 358, "Policy Loss": 1.8681811094284058, "Value Loss": 26.986454010009766, "_runtime": 12841.684524059296, "_timestamp": 1585582757.5291574, "_step": 218}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": 0.9429637789726257, "Value Loss": 21.227333068847656, "_runtime": 12842.993965387344, "_timestamp": 1585582758.8385987, "_step": 219}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.3335177004337311, "Value Loss": 11.74705696105957, "_runtime": 12843.524832725525, "_timestamp": 1585582759.369466, "_step": 220}
{"Episode reward": 66.68444895409027, "Episode length": 334, "Policy Loss": 1.574459433555603, "Value Loss": 29.246374130249023, "_runtime": 12845.039659023285, "_timestamp": 1585582760.8842924, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8511534333229065, "Value Loss": 0.11452582478523254, "_runtime": 12846.660547018051, "_timestamp": 1585582762.5051804, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8795616626739502, "Value Loss": 0.04401136934757233, "_runtime": 12848.235431671143, "_timestamp": 1585582764.080065, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9036000967025757, "Value Loss": 0.41948866844177246, "_runtime": 12849.854450464249, "_timestamp": 1585582765.6990838, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.89350426197052, "Value Loss": 0.1980082243680954, "_runtime": 12851.438979387283, "_timestamp": 1585582767.2836127, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8703911900520325, "Value Loss": 0.036216720938682556, "_runtime": 12853.002059698105, "_timestamp": 1585582768.846693, "_step": 226}
{"Episode reward": -99.82845659851888, "Episode length": 999, "Policy Loss": -0.8586520552635193, "Value Loss": 0.018565384671092033, "_runtime": 12854.567456245422, "_timestamp": 1585582770.4120896, "_step": 227}
{"Episode reward": -99.68556376620988, "Episode length": 999, "Policy Loss": -0.8323310613632202, "Value Loss": 0.024585239589214325, "_runtime": 12856.16641664505, "_timestamp": 1585582772.01105, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8083576560020447, "Value Loss": 0.05942739173769951, "_runtime": 12857.32554936409, "_timestamp": 1585582773.1701827, "_step": 229}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.2870197296142578, "Value Loss": 14.06692123413086, "_runtime": 12858.570140600204, "_timestamp": 1585582774.414774, "_step": 230}
{"Episode reward": 21.56014772020299, "Episode length": 785, "Policy Loss": 0.36294862627983093, "Value Loss": 12.879610061645508, "_runtime": 12860.198264837265, "_timestamp": 1585582776.0428982, "_step": 231}
{"Episode reward": -99.80993804074684, "Episode length": 999, "Policy Loss": -0.7999218702316284, "Value Loss": 0.03219614177942276, "_runtime": 12861.778326511383, "_timestamp": 1585582777.6229599, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8094363212585449, "Value Loss": 0.04495331272482872, "_runtime": 12863.345197677612, "_timestamp": 1585582779.189831, "_step": 233}
{"Episode reward": -99.8015916261808, "Episode length": 999, "Policy Loss": -0.8085161447525024, "Value Loss": 0.010649343021214008, "_runtime": 12864.907708883286, "_timestamp": 1585582780.7523422, "_step": 234}
{"Episode reward": 1.7892253860844392, "Episode length": 983, "Policy Loss": 0.11268705129623413, "Value Loss": 9.931512832641602, "_runtime": 12865.45465040207, "_timestamp": 1585582781.2992837, "_step": 235}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 2.476076602935791, "Value Loss": 30.79030990600586, "_runtime": 12867.03185391426, "_timestamp": 1585582782.8764873, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8182159662246704, "Value Loss": 0.142868310213089, "_runtime": 12868.62004995346, "_timestamp": 1585582784.4646833, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8110631108283997, "Value Loss": 0.03410036116838455, "_runtime": 12870.14134478569, "_timestamp": 1585582785.9859781, "_step": 238}
{"Episode reward": -99.80929088741401, "Episode length": 999, "Policy Loss": -0.8045207262039185, "Value Loss": 0.09541667997837067, "_runtime": 12871.739253997803, "_timestamp": 1585582787.5838873, "_step": 239}
{"Episode reward": -99.80290188230434, "Episode length": 999, "Policy Loss": -0.7917770147323608, "Value Loss": 0.13595716655254364, "_runtime": 12873.33653330803, "_timestamp": 1585582789.1811666, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7641878128051758, "Value Loss": 0.17180341482162476, "_runtime": 12874.903326749802, "_timestamp": 1585582790.74796, "_step": 241}
{"Episode reward": -99.74921969212453, "Episode length": 999, "Policy Loss": -0.747063934803009, "Value Loss": 0.07470568269491196, "_runtime": 12876.511605978012, "_timestamp": 1585582792.3562393, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.716355562210083, "Value Loss": 0.008899567648768425, "_runtime": 12878.119900941849, "_timestamp": 1585582793.9645343, "_step": 243}
{"Episode reward": -99.82322599887708, "Episode length": 999, "Policy Loss": -0.6782050132751465, "Value Loss": 0.03790143132209778, "_runtime": 12879.69351553917, "_timestamp": 1585582795.5381489, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6294559240341187, "Value Loss": 0.11833469569683075, "_runtime": 12881.297520637512, "_timestamp": 1585582797.142154, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6209019422531128, "Value Loss": 0.04409344866871834, "_runtime": 12882.301106214523, "_timestamp": 1585582798.1457396, "_step": 246}
{"Episode reward": 38.4999999999994, "Episode length": 615, "Policy Loss": 0.6493245959281921, "Value Loss": 16.188356399536133, "_runtime": 12883.32261967659, "_timestamp": 1585582799.167253, "_step": 247}
{"Episode reward": 38.95988528095127, "Episode length": 611, "Policy Loss": 0.6623780131340027, "Value Loss": 16.112693786621094, "_runtime": 12884.900435686111, "_timestamp": 1585582800.745069, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.614371120929718, "Value Loss": 0.00842828955501318, "_runtime": 12885.548211812973, "_timestamp": 1585582801.3928452, "_step": 249}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 1.4734492301940918, "Value Loss": 23.814565658569336, "_runtime": 12887.083862543106, "_timestamp": 1585582802.928496, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6444188952445984, "Value Loss": 0.10201562941074371, "_runtime": 12888.59296989441, "_timestamp": 1585582804.4376032, "_step": 251}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 0.3266770839691162, "Value Loss": 10.062402725219727, "_runtime": 12890.115832090378, "_timestamp": 1585582805.9604654, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6629260778427124, "Value Loss": 0.22994287312030792, "_runtime": 12891.12399148941, "_timestamp": 1585582806.9686248, "_step": 253}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.5819128155708313, "Value Loss": 16.464426040649414, "_runtime": 12892.698951005936, "_timestamp": 1585582808.5435843, "_step": 254}
{"Episode reward": -99.83856058269599, "Episode length": 999, "Policy Loss": -0.6500158309936523, "Value Loss": 0.09007556736469269, "_runtime": 12893.092945337296, "_timestamp": 1585582808.9375787, "_step": 255}
{"Episode reward": 77.49999999999996, "Episode length": 225, "Policy Loss": 2.862504720687866, "Value Loss": 42.72145462036133, "_runtime": 12894.649978160858, "_timestamp": 1585582810.4946115, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6404061317443848, "Value Loss": 0.125454381108284, "_runtime": 12896.24781537056, "_timestamp": 1585582812.0924487, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6232811808586121, "Value Loss": 0.0878530964255333, "_runtime": 12896.850267410278, "_timestamp": 1585582812.6949008, "_step": 258}
{"Episode reward": 60.59999999999972, "Episode length": 394, "Policy Loss": 1.8247514963150024, "Value Loss": 24.330957412719727, "_runtime": 12898.413454055786, "_timestamp": 1585582814.2580874, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6317899227142334, "Value Loss": 0.05267166718840599, "_runtime": 12899.890253782272, "_timestamp": 1585582815.7348871, "_step": 260}
{"Episode reward": 7.5000000000009805, "Episode length": 925, "Policy Loss": 0.23023287951946259, "Value Loss": 10.560839653015137, "_runtime": 12901.290530204773, "_timestamp": 1585582817.1351635, "_step": 261}
{"Episode reward": 7.855682959781063, "Episode length": 922, "Policy Loss": 0.2594653367996216, "Value Loss": 10.588212013244629, "_runtime": 12901.884941101074, "_timestamp": 1585582817.7295744, "_step": 262}
{"Episode reward": 64.89999999999978, "Episode length": 351, "Policy Loss": 1.5284677743911743, "Value Loss": 27.740678787231445, "_runtime": 12902.24342250824, "_timestamp": 1585582818.0880558, "_step": 263}
{"Episode reward": 79.89999999999999, "Episode length": 201, "Policy Loss": 3.0724310874938965, "Value Loss": 48.02263259887695, "_runtime": 12903.79024362564, "_timestamp": 1585582819.634877, "_step": 264}
{"Episode reward": -99.81959186196188, "Episode length": 999, "Policy Loss": -0.7447298765182495, "Value Loss": 0.019005103036761284, "_runtime": 12905.31486749649, "_timestamp": 1585582821.1595008, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8102922439575195, "Value Loss": 0.2889965772628784, "_runtime": 12906.806822061539, "_timestamp": 1585582822.6514554, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8472903370857239, "Value Loss": 0.45610275864601135, "_runtime": 12908.047979354858, "_timestamp": 1585582823.8926127, "_step": 267}
{"Episode reward": 24.79640030264855, "Episode length": 754, "Policy Loss": 0.22488702833652496, "Value Loss": 13.287195205688477, "_runtime": 12909.054305553436, "_timestamp": 1585582824.898939, "_step": 268}
{"Episode reward": 36.89730634652016, "Episode length": 632, "Policy Loss": 0.31738346815109253, "Value Loss": 15.495339393615723, "_runtime": 12910.614937067032, "_timestamp": 1585582826.4595704, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9078398942947388, "Value Loss": 0.12029832601547241, "_runtime": 12912.18631696701, "_timestamp": 1585582828.0309503, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8999634385108948, "Value Loss": 0.1530543863773346, "_runtime": 12913.73794722557, "_timestamp": 1585582829.5825806, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8784115314483643, "Value Loss": 0.016819361597299576, "_runtime": 12915.32530117035, "_timestamp": 1585582831.1699345, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8514336347579956, "Value Loss": 0.026225369423627853, "_runtime": 12916.704137802124, "_timestamp": 1585582832.5487711, "_step": 273}
{"Episode reward": 13.39713955782419, "Episode length": 867, "Policy Loss": 0.08448343724012375, "Value Loss": 11.181703567504883, "_runtime": 12918.286170482635, "_timestamp": 1585582834.1308038, "_step": 274}
{"Episode reward": -99.80532002784172, "Episode length": 999, "Policy Loss": -0.8445954322814941, "Value Loss": 0.030500590801239014, "_runtime": 12919.872735977173, "_timestamp": 1585582835.7173693, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8267472386360168, "Value Loss": 0.04572276771068573, "_runtime": 12921.454250097275, "_timestamp": 1585582837.2988834, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8125234246253967, "Value Loss": 0.22668620944023132, "_runtime": 12922.870010614395, "_timestamp": 1585582838.714644, "_step": 277}
{"Episode reward": 11.600000000000747, "Episode length": 884, "Policy Loss": 0.09621400386095047, "Value Loss": 11.080644607543945, "_runtime": 12923.365931749344, "_timestamp": 1585582839.210565, "_step": 278}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 1.7500085830688477, "Value Loss": 33.24790954589844, "_runtime": 12924.948595046997, "_timestamp": 1585582840.7932284, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.833725094795227, "Value Loss": 0.12098347395658493, "_runtime": 12925.641500234604, "_timestamp": 1585582841.4861336, "_step": 280}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 1.4988200664520264, "Value Loss": 22.671772003173828, "_runtime": 12926.48813700676, "_timestamp": 1585582842.3327703, "_step": 281}
{"Episode reward": 44.899999999999494, "Episode length": 551, "Policy Loss": 0.4640306830406189, "Value Loss": 17.542051315307617, "_runtime": 12928.07934641838, "_timestamp": 1585582843.9239798, "_step": 282}
{"Episode reward": -99.80068599320808, "Episode length": 999, "Policy Loss": -0.8736701607704163, "Value Loss": 0.9833953380584717, "_runtime": 12929.4810795784, "_timestamp": 1585582845.325713, "_step": 283}
{"Episode reward": 8.685030695424402, "Episode length": 914, "Policy Loss": -0.07469213753938675, "Value Loss": 11.078079223632812, "_runtime": 12931.054422616959, "_timestamp": 1585582846.899056, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8872485756874084, "Value Loss": 0.1849338561296463, "_runtime": 12931.757441997528, "_timestamp": 1585582847.6020753, "_step": 285}
{"Episode reward": 57.49999999999967, "Episode length": 425, "Policy Loss": 1.0858362913131714, "Value Loss": 22.49271583557129, "_runtime": 12933.328560829163, "_timestamp": 1585582849.1731942, "_step": 286}
{"Episode reward": -99.80270167328278, "Episode length": 999, "Policy Loss": -0.8380486965179443, "Value Loss": 0.06021977961063385, "_runtime": 12934.910745382309, "_timestamp": 1585582850.7553787, "_step": 287}
{"Episode reward": -99.82760353088239, "Episode length": 999, "Policy Loss": -0.8285530805587769, "Value Loss": 0.06866931170225143, "_runtime": 12935.564305782318, "_timestamp": 1585582851.4089391, "_step": 288}
{"Episode reward": 58.69999999999969, "Episode length": 413, "Policy Loss": 1.0560929775238037, "Value Loss": 23.730932235717773, "_runtime": 12937.152515649796, "_timestamp": 1585582852.997149, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8339705467224121, "Value Loss": 0.06802656501531601, "_runtime": 12938.557000160217, "_timestamp": 1585582854.4016335, "_step": 290}
{"Episode reward": 11.191972683370892, "Episode length": 889, "Policy Loss": 0.10411106050014496, "Value Loss": 10.905316352844238, "_runtime": 12939.495901107788, "_timestamp": 1585582855.3405344, "_step": 291}
{"Episode reward": 38.89999999999941, "Episode length": 611, "Policy Loss": 0.4086299538612366, "Value Loss": 15.99283504486084, "_runtime": 12940.580402851105, "_timestamp": 1585582856.4250362, "_step": 292}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.9332300424575806, "Value Loss": 14.209746360778809, "_runtime": 12942.154779672623, "_timestamp": 1585582857.999413, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9090479016304016, "Value Loss": 0.017587874084711075, "_runtime": 12943.707954406738, "_timestamp": 1585582859.5525877, "_step": 294}
{"Episode reward": -99.84405737854401, "Episode length": 999, "Policy Loss": -0.9424197673797607, "Value Loss": 0.08453767746686935, "_runtime": 12945.114708423615, "_timestamp": 1585582860.9593418, "_step": 295}
{"Episode reward": 10.398236083985196, "Episode length": 897, "Policy Loss": -0.1024591252207756, "Value Loss": 10.717486381530762, "_runtime": 12946.700367212296, "_timestamp": 1585582862.5450006, "_step": 296}
{"Episode reward": -99.84319467544417, "Episode length": 999, "Policy Loss": -0.9563973546028137, "Value Loss": 0.1441728174686432, "_runtime": 12948.286446094513, "_timestamp": 1585582864.1310794, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9553548097610474, "Value Loss": 0.12441343069076538, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347, 0.08042915165424347]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.812462091445923, -2.13051176071167, -1.448561429977417, -0.7666110992431641, -0.08466076850891113, 0.5972895622253418, 1.2792398929595947, 1.9611899852752686, 2.6431405544281006, 3.3250911235809326, 4.007040977478027, 4.688991546630859, 5.370942115783691, 6.052892684936523, 6.734842300415039, 7.416792869567871, 8.098743438720703, 8.780694007873535, 9.462644577026367, 10.144594192504883, 10.826544761657715, 11.508495330810547, 12.190444946289062, 12.872395515441895, 13.554346084594727, 14.236295700073242, 14.91824722290039, 15.600196838378906, 16.282146453857422, 16.96409797668457, 17.646047592163086, 18.327999114990234, 19.00994873046875, 19.691898345947266, 20.373849868774414, 21.05579948425293, 21.737751007080078, 22.419700622558594, 23.10165023803711, 23.783601760864258, 24.465551376342773, 25.14750099182129, 25.829452514648438, 26.511402130126953, 27.19335174560547, 27.875303268432617, 28.557252883911133, 29.23920440673828, 29.921154022216797, 30.603103637695312, 31.285053253173828, 31.96700668334961, 32.648956298828125, 33.33090591430664, 34.012855529785156, 34.69480514526367, 35.37675476074219, 36.05870819091797, 36.740657806396484, 37.422607421875, 38.104557037353516, 38.78650665283203, 39.46846008300781, 40.15040969848633, 40.832359313964844]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.30487722158432007, -0.2951604127883911, -0.28544360399246216, -0.2757268249988556, -0.26601001620292664, -0.2562932074069977, -0.24657641351222992, -0.23685961961746216, -0.2271428108215332, -0.21742600202560425, -0.2077092081308365, -0.19799241423606873, -0.18827560544013977, -0.17855879664421082, -0.16884200274944305, -0.1591252088546753, -0.14940840005874634, -0.13969159126281738, -0.12997479736804962, -0.12025800347328186, -0.1105411946773529, -0.10082438588142395, -0.09110759198665619, -0.08139079809188843, -0.07167398929595947, -0.06195718050003052, -0.05224037170410156, -0.042523592710494995, -0.03280678391456604, -0.023089975118637085, -0.013373196125030518, -0.0036563873291015625, 0.006060421466827393, 0.015777230262756348, 0.025494039058685303, 0.03521081805229187, 0.044927626848220825, 0.05464443564414978, 0.06436121463775635, 0.0740780234336853, 0.08379483222961426, 0.09351164102554321, 0.10322844982147217, 0.11294522881507874, 0.12266203761100769, 0.13237884640693665, 0.1420956254005432, 0.15181243419647217, 0.16152924299240112, 0.17124605178833008, 0.18096286058425903, 0.1906796395778656, 0.20039647817611694, 0.21011322736740112, 0.21983003616333008, 0.22954684495925903, 0.239263653755188, 0.24898046255111694, 0.2586972713470459, 0.26841408014297485, 0.27813082933425903, 0.287847638130188, 0.29756444692611694, 0.3072812557220459, 0.31699806451797485]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 2.0, 8.0, 10.0, 9.0, 6.0, 5.0, 32.0, 17.0, 22.0, 11.0, 321.0, 17.0, 1.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-2.5155534744262695, -2.4233524799346924, -2.331151247024536, -2.238950252532959, -2.1467490196228027, -2.0545480251312256, -1.9623469114303589, -1.8701457977294922, -1.777944803237915, -1.6857435703277588, -1.5935425758361816, -1.501341462135315, -1.4091403484344482, -1.3169392347335815, -1.2247382402420044, -1.1325371265411377, -1.040336012840271, -0.9481348991394043, -0.8559337854385376, -0.7637327909469604, -0.6715316772460938, -0.579330563545227, -0.48712944984436035, -0.3949284553527832, -0.30272722244262695, -0.2105262279510498, -0.11832499504089355, -0.026124000549316406, 0.06607699394226074, 0.158278226852417, 0.25047922134399414, 0.3426804542541504, 0.43488144874572754, 0.5270824432373047, 0.6192836761474609, 0.7114846706390381, 0.8036859035491943, 0.8958868980407715, 0.9880878925323486, 1.0802891254425049, 1.172490119934082, 1.2646913528442383, 1.3568923473358154, 1.4490933418273926, 1.5412945747375488, 1.633495807647705, 1.7256965637207031, 1.8178977966308594, 1.9100990295410156, 2.0022997856140137, 2.09450101852417, 2.186702251434326, 2.2789034843444824, 2.3711042404174805, 2.4633054733276367, 2.555506706237793, 2.647707462310791, 2.7399086952209473, 2.8321099281311035, 2.9243106842041016, 3.016511917114258, 3.108713150024414, 3.2009143829345703, 3.2931151390075684, 3.3853163719177246]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.3959559202194214, -1.3474818468093872, -1.2990078926086426, -1.2505338191986084, -1.2020597457885742, -1.15358567237854, -1.1051115989685059, -1.0566376447677612, -1.008163571357727, -0.9596894979476929, -0.9112154841423035, -0.8627414703369141, -0.8142673969268799, -0.7657933235168457, -0.7173193097114563, -0.6688452959060669, -0.6203712224960327, -0.5718971490859985, -0.5234231352806091, -0.4749491214752197, -0.42647504806518555, -0.37800097465515137, -0.32952702045440674, -0.28105294704437256, -0.23257887363433838, -0.1841048002243042, -0.13563072681427002, -0.08715677261352539, -0.03868269920349121, 0.009791374206542969, 0.0582653284072876, 0.10673940181732178, 0.15521347522735596, 0.20368754863739014, 0.2521616220474243, 0.30063557624816895, 0.3491096496582031, 0.3975837230682373, 0.44605767726898193, 0.4945317506790161, 0.5430058240890503, 0.5914798974990845, 0.6399539709091187, 0.6884280443191528, 0.7369018793106079, 0.7853759527206421, 0.8338500261306763, 0.8823240995407104, 0.9307981729507446, 0.9792722463607788, 1.027746319770813, 1.0762203931808472, 1.1246944665908813, 1.1731683015823364, 1.2216423749923706, 1.2701164484024048, 1.318590521812439, 1.3670645952224731, 1.4155386686325073, 1.4640127420425415, 1.5124865770339966, 1.5609606504440308, 1.609434723854065, 1.6579087972640991, 1.7063828706741333]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 5.0, 5.0, 7.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.7251752614974976, -1.670922040939331, -1.6166688203811646, -1.562415599822998, -1.5081623792648315, -1.453909158706665, -1.3996559381484985, -1.345402717590332, -1.2911494970321655, -1.236896276473999, -1.1826430559158325, -1.128389835357666, -1.0741366147994995, -1.019883394241333, -0.9656301736831665, -0.911376953125, -0.8571237325668335, -0.802870512008667, -0.7486172914505005, -0.694364070892334, -0.6401108503341675, -0.585857629776001, -0.5316044092178345, -0.47735118865966797, -0.42309796810150146, -0.36884474754333496, -0.31459152698516846, -0.26033830642700195, -0.20608508586883545, -0.15183186531066895, -0.09757864475250244, -0.04332542419433594, 0.010927796363830566, 0.06518101692199707, 0.11943423748016357, 0.17368745803833008, 0.22794067859649658, 0.28219377994537354, 0.3364471197128296, 0.39070045948028564, 0.4449535608291626, 0.49920666217803955, 0.5534600019454956, 0.6077133417129517, 0.6619664430618286, 0.7162195444107056, 0.7704728841781616, 0.8247262239456177, 0.8789793252944946, 0.9332324266433716, 0.9874857664108276, 1.0417391061782837, 1.0959922075271606, 1.1502453088760376, 1.2044986486434937, 1.2587519884109497, 1.3130050897598267, 1.3672581911087036, 1.4215115308761597, 1.4757648706436157, 1.5300179719924927, 1.5842710733413696, 1.6385244131088257, 1.6927777528762817, 1.7470308542251587]}, "_runtime": 12949.283492088318, "_timestamp": 1585582865.1281254, "_step": 298}
{"Episode reward": 37.79999999999939, "Episode length": 622, "Policy Loss": 0.31278669834136963, "Value Loss": 15.390265464782715, "_runtime": 12950.850596427917, "_timestamp": 1585582866.6952298, "_step": 299}
{"Episode reward": -99.70584540702262, "Episode length": 999, "Policy Loss": -0.9487229585647583, "Value Loss": 0.5571489930152893, "_runtime": 12952.248804092407, "_timestamp": 1585582868.0934374, "_step": 300}
{"Episode reward": 12.200000000000713, "Episode length": 878, "Policy Loss": 0.0548681803047657, "Value Loss": 11.37304973602295, "_runtime": 12953.79556941986, "_timestamp": 1585582869.6402028, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8712216019630432, "Value Loss": 0.1873004138469696, "_runtime": 12955.414036273956, "_timestamp": 1585582871.2586696, "_step": 302}
{"Episode reward": -99.70998051464419, "Episode length": 999, "Policy Loss": -0.8361009359359741, "Value Loss": 0.1071833148598671, "_runtime": 12956.986941814423, "_timestamp": 1585582872.8315752, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7911291122436523, "Value Loss": 0.01798166334629059, "_runtime": 12958.115706682205, "_timestamp": 1585582873.96034, "_step": 304}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.4510093629360199, "Value Loss": 13.91025447845459, "_runtime": 12959.194759368896, "_timestamp": 1585582875.0393927, "_step": 305}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": 0.443915992975235, "Value Loss": 15.030729293823242, "_runtime": 12960.77917265892, "_timestamp": 1585582876.623806, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6815596222877502, "Value Loss": 0.21947602927684784, "_runtime": 12962.34114909172, "_timestamp": 1585582878.1857824, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6827471852302551, "Value Loss": 0.1383371353149414, "_runtime": 12963.894154071808, "_timestamp": 1585582879.7387874, "_step": 308}
{"Episode reward": -99.80052488185325, "Episode length": 999, "Policy Loss": -0.6819134950637817, "Value Loss": 0.14380121231079102, "_runtime": 12965.156452178955, "_timestamp": 1585582881.0010855, "_step": 309}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 0.5141382217407227, "Value Loss": 12.386911392211914, "_runtime": 12966.730310201645, "_timestamp": 1585582882.5749435, "_step": 310}
{"Episode reward": -99.85281591750541, "Episode length": 999, "Policy Loss": -0.6868788003921509, "Value Loss": 0.008902579545974731, "_runtime": 12968.077793359756, "_timestamp": 1585582883.9224267, "_step": 311}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": 0.2394515424966812, "Value Loss": 11.67197036743164, "_runtime": 12969.199605464935, "_timestamp": 1585582885.0442388, "_step": 312}
{"Episode reward": 28.99999999999976, "Episode length": 710, "Policy Loss": 0.7502429485321045, "Value Loss": 13.556669235229492, "_runtime": 12970.785641908646, "_timestamp": 1585582886.6302752, "_step": 313}
{"Episode reward": -99.80098249912122, "Episode length": 999, "Policy Loss": -0.6605289578437805, "Value Loss": 0.017414454370737076, "_runtime": 12971.75373005867, "_timestamp": 1585582887.5983634, "_step": 314}
{"Episode reward": 39.5850495811546, "Episode length": 605, "Policy Loss": 0.9345592260360718, "Value Loss": 16.329248428344727, "_runtime": 12973.327495098114, "_timestamp": 1585582889.1721284, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6425825357437134, "Value Loss": 0.10361924022436142, "_runtime": 12973.597113609314, "_timestamp": 1585582889.441747, "_step": 316}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": 5.453523635864258, "Value Loss": 75.99085998535156, "_runtime": 12974.784674406052, "_timestamp": 1585582890.6293077, "_step": 317}
{"Episode reward": 23.600000000000065, "Episode length": 764, "Policy Loss": 0.3861486613750458, "Value Loss": 12.626585006713867, "_runtime": 12976.374086380005, "_timestamp": 1585582892.2187197, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6884284615516663, "Value Loss": 0.0119430311024189, "_runtime": 12977.878734111786, "_timestamp": 1585582893.7233675, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7187848687171936, "Value Loss": 0.04956148564815521, "_runtime": 12979.482161045074, "_timestamp": 1585582895.3267944, "_step": 320}
{"Episode reward": -99.8045218527303, "Episode length": 999, "Policy Loss": -0.7147707343101501, "Value Loss": 0.3722907304763794, "_runtime": 12981.071235656738, "_timestamp": 1585582896.915869, "_step": 321}
{"Episode reward": -99.81783907413343, "Episode length": 999, "Policy Loss": -0.7334939241409302, "Value Loss": 0.011751877143979073, "_runtime": 12982.616908788681, "_timestamp": 1585582898.4615421, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.730545699596405, "Value Loss": 0.015501822344958782, "_runtime": 12984.194139957428, "_timestamp": 1585582900.0387733, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7190822958946228, "Value Loss": 0.030157743021845818, "_runtime": 12985.598340272903, "_timestamp": 1585582901.4429736, "_step": 324}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": 0.2164613902568817, "Value Loss": 11.047073364257812, "_runtime": 12987.169164657593, "_timestamp": 1585582903.013798, "_step": 325}
{"Episode reward": -99.81995554603496, "Episode length": 999, "Policy Loss": -0.7018395662307739, "Value Loss": 0.01784711889922619, "_runtime": 12988.771206617355, "_timestamp": 1585582904.61584, "_step": 326}
{"Episode reward": -99.80291645675759, "Episode length": 999, "Policy Loss": -0.6932908296585083, "Value Loss": 0.06620790809392929, "_runtime": 12990.361356258392, "_timestamp": 1585582906.2059896, "_step": 327}
{"Episode reward": -99.78046055026213, "Episode length": 999, "Policy Loss": -0.6858975291252136, "Value Loss": 0.01453544944524765, "_runtime": 12991.141040802002, "_timestamp": 1585582906.9856741, "_step": 328}
{"Episode reward": 52.06527320705314, "Episode length": 480, "Policy Loss": 0.9254815578460693, "Value Loss": 20.20893096923828, "_runtime": 12992.020816326141, "_timestamp": 1585582907.8654497, "_step": 329}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 0.8010850548744202, "Value Loss": 17.915538787841797, "_runtime": 12993.611614227295, "_timestamp": 1585582909.4562476, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6856744885444641, "Value Loss": 0.03162095323204994, "_runtime": 12995.150353193283, "_timestamp": 1585582910.9949865, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7028380632400513, "Value Loss": 0.02006302773952484, "_runtime": 12996.697063684464, "_timestamp": 1585582912.541697, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7128590941429138, "Value Loss": 0.02553590200841427, "_runtime": 12997.619515419006, "_timestamp": 1585582913.4641488, "_step": 333}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.6668819785118103, "Value Loss": 16.88524055480957, "_runtime": 12999.200104236603, "_timestamp": 1585582915.0447376, "_step": 334}
{"Episode reward": -99.86508660465338, "Episode length": 999, "Policy Loss": -0.6966333389282227, "Value Loss": 0.08458331972360611, "_runtime": 13000.775245428085, "_timestamp": 1585582916.6198788, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7220059633255005, "Value Loss": 0.019720396026968956, "_runtime": 13001.481634378433, "_timestamp": 1585582917.3262677, "_step": 336}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": 1.115983009338379, "Value Loss": 21.58873176574707, "_runtime": 13003.110623836517, "_timestamp": 1585582918.9552572, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7196284532546997, "Value Loss": 0.19848258793354034, "_runtime": 13003.885761737823, "_timestamp": 1585582919.730395, "_step": 338}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 0.9430427551269531, "Value Loss": 20.32451057434082, "_runtime": 13005.42744755745, "_timestamp": 1585582921.272081, "_step": 339}
{"Episode reward": -99.73685255683819, "Episode length": 999, "Policy Loss": -0.7076383233070374, "Value Loss": 0.014676707796752453, "_runtime": 13007.01082277298, "_timestamp": 1585582922.855456, "_step": 340}
{"Episode reward": -99.80874836593726, "Episode length": 999, "Policy Loss": -0.6969680190086365, "Value Loss": 0.010034509003162384, "_runtime": 13008.026539802551, "_timestamp": 1585582923.8711731, "_step": 341}
{"Episode reward": 34.256072166189014, "Episode length": 658, "Policy Loss": 0.49238675832748413, "Value Loss": 14.735578536987305, "_runtime": 13009.58258676529, "_timestamp": 1585582925.42722, "_step": 342}
{"Episode reward": -99.66470289863507, "Episode length": 999, "Policy Loss": -0.6776664853096008, "Value Loss": 0.010987597517669201, "_runtime": 13011.15441942215, "_timestamp": 1585582926.9990528, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6552435159683228, "Value Loss": 0.02483222261071205, "_runtime": 13011.854489803314, "_timestamp": 1585582927.6991231, "_step": 344}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": 1.1719108819961548, "Value Loss": 22.008533477783203, "_runtime": 13013.441368818283, "_timestamp": 1585582929.2860022, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6415093541145325, "Value Loss": 0.04427485540509224, "_runtime": 13015.02598786354, "_timestamp": 1585582930.8706212, "_step": 346}
{"Episode reward": -99.85330497175315, "Episode length": 999, "Policy Loss": -0.6397503614425659, "Value Loss": 0.053429245948791504, "_runtime": 13016.429557800293, "_timestamp": 1585582932.2741911, "_step": 347}
{"Episode reward": 8.636226361990893, "Episode length": 914, "Policy Loss": 0.1667087823152542, "Value Loss": 10.524048805236816, "_runtime": 13017.31384396553, "_timestamp": 1585582933.1584773, "_step": 348}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 0.7536205649375916, "Value Loss": 17.519319534301758, "_runtime": 13018.482359409332, "_timestamp": 1585582934.3269928, "_step": 349}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": 0.3936662971973419, "Value Loss": 13.278721809387207, "_runtime": 13020.055191278458, "_timestamp": 1585582935.8998246, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6985635161399841, "Value Loss": 0.014675408601760864, "_runtime": 13020.820567369461, "_timestamp": 1585582936.6652007, "_step": 351}
{"Episode reward": 51.69999999999959, "Episode length": 483, "Policy Loss": 0.9903234243392944, "Value Loss": 20.197994232177734, "_runtime": 13022.372363328934, "_timestamp": 1585582938.2169967, "_step": 352}
{"Episode reward": -99.85650663971761, "Episode length": 999, "Policy Loss": -0.7235416769981384, "Value Loss": 0.02517113648355007, "_runtime": 13023.67297077179, "_timestamp": 1585582939.517604, "_step": 353}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": 0.22322426736354828, "Value Loss": 11.581875801086426, "_runtime": 13025.217000484467, "_timestamp": 1585582941.0616338, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7197616696357727, "Value Loss": 0.14365079998970032, "_runtime": 13026.79376411438, "_timestamp": 1585582942.6383975, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.722045361995697, "Value Loss": 0.14805571734905243, "_runtime": 13027.550742864609, "_timestamp": 1585582943.3953762, "_step": 356}
{"Episode reward": 55.99724590741063, "Episode length": 441, "Policy Loss": 1.1682944297790527, "Value Loss": 21.657461166381836, "_runtime": 13029.137554645538, "_timestamp": 1585582944.982188, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6984388828277588, "Value Loss": 0.020898662507534027, "_runtime": 13030.012317180634, "_timestamp": 1585582945.8569505, "_step": 358}
{"Episode reward": 45.79999999999951, "Episode length": 542, "Policy Loss": 0.6738995313644409, "Value Loss": 17.63530921936035, "_runtime": 13031.548219203949, "_timestamp": 1585582947.3928525, "_step": 359}
{"Episode reward": -99.89788725525001, "Episode length": 999, "Policy Loss": -0.7044065594673157, "Value Loss": 0.08507613092660904, "_runtime": 13033.138109922409, "_timestamp": 1585582948.9827433, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7082661986351013, "Value Loss": 0.019750749692320824, "_runtime": 13034.13619685173, "_timestamp": 1585582949.9808302, "_step": 361}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.6591456532478333, "Value Loss": 14.99902629852295, "_runtime": 13035.705599308014, "_timestamp": 1585582951.5502326, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7267219424247742, "Value Loss": 0.011585165746510029, "_runtime": 13037.29966211319, "_timestamp": 1585582953.1442955, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7281996011734009, "Value Loss": 0.012782461941242218, "_runtime": 13038.853875160217, "_timestamp": 1585582954.6985085, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7319967150688171, "Value Loss": 0.015245103277266026, "_runtime": 13040.43374967575, "_timestamp": 1585582956.278383, "_step": 365}
{"Episode reward": -99.81508286930482, "Episode length": 999, "Policy Loss": -0.7237879633903503, "Value Loss": 0.05582384020090103, "_runtime": 13041.698839187622, "_timestamp": 1585582957.5434725, "_step": 366}
{"Episode reward": 20.50000000000024, "Episode length": 795, "Policy Loss": 0.30039170384407043, "Value Loss": 12.000075340270996, "_runtime": 13043.284396648407, "_timestamp": 1585582959.12903, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.711015522480011, "Value Loss": 0.03372970595955849, "_runtime": 13043.896451950073, "_timestamp": 1585582959.7410853, "_step": 368}
{"Episode reward": 63.79999999999976, "Episode length": 362, "Policy Loss": 1.4451295137405396, "Value Loss": 26.1239013671875, "_runtime": 13045.00446844101, "_timestamp": 1585582960.8491018, "_step": 369}
{"Episode reward": 29.399999999999736, "Episode length": 706, "Policy Loss": 0.3790557384490967, "Value Loss": 13.384291648864746, "_runtime": 13046.57147693634, "_timestamp": 1585582962.4161103, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7316170930862427, "Value Loss": 0.02138526737689972, "_runtime": 13047.085224866867, "_timestamp": 1585582962.9298582, "_step": 371}
{"Episode reward": 67.79999999999981, "Episode length": 322, "Policy Loss": 1.6397078037261963, "Value Loss": 29.277971267700195, "_runtime": 13048.630853414536, "_timestamp": 1585582964.4754868, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7661112546920776, "Value Loss": 0.050507139414548874, "_runtime": 13050.214515209198, "_timestamp": 1585582966.0591486, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7752413749694824, "Value Loss": 0.08923713117837906, "_runtime": 13050.841342926025, "_timestamp": 1585582966.6859763, "_step": 374}
{"Episode reward": 59.799999999999706, "Episode length": 402, "Policy Loss": 1.257061243057251, "Value Loss": 24.09325408935547, "_runtime": 13052.416972637177, "_timestamp": 1585582968.261606, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7887359261512756, "Value Loss": 0.022277386859059334, "_runtime": 13054.03554224968, "_timestamp": 1585582969.8801756, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7874696254730225, "Value Loss": 0.01336114201694727, "_runtime": 13055.560498476028, "_timestamp": 1585582971.4051318, "_step": 377}
{"Episode reward": -99.83698516487935, "Episode length": 999, "Policy Loss": -0.7712505459785461, "Value Loss": 0.036210138350725174, "_runtime": 13057.157846212387, "_timestamp": 1585582973.0024796, "_step": 378}
{"Episode reward": -99.87152137756208, "Episode length": 999, "Policy Loss": -0.7620649337768555, "Value Loss": 0.028162015601992607, "_runtime": 13058.764662981033, "_timestamp": 1585582974.6092963, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7477704286575317, "Value Loss": 0.29850733280181885, "_runtime": 13060.346035003662, "_timestamp": 1585582976.1906683, "_step": 380}
{"Episode reward": -99.79930256195227, "Episode length": 999, "Policy Loss": -0.722299337387085, "Value Loss": 0.028459951281547546, "_runtime": 13061.810136556625, "_timestamp": 1585582977.65477, "_step": 381}
{"Episode reward": 9.299494394288345, "Episode length": 908, "Policy Loss": 0.33213257789611816, "Value Loss": 10.571844100952148, "_runtime": 13063.412621974945, "_timestamp": 1585582979.2572553, "_step": 382}
{"Episode reward": -99.81178705133358, "Episode length": 999, "Policy Loss": -0.6781189441680908, "Value Loss": 0.03412772715091705, "_runtime": 13064.046065568924, "_timestamp": 1585582979.890699, "_step": 383}
{"Episode reward": 62.19999999999974, "Episode length": 378, "Policy Loss": 1.3779574632644653, "Value Loss": 24.786840438842773, "_runtime": 13065.544275283813, "_timestamp": 1585582981.3889086, "_step": 384}
{"Episode reward": 4.024967861176705, "Episode length": 960, "Policy Loss": 0.13608583807945251, "Value Loss": 10.017065048217773, "_runtime": 13066.042550086975, "_timestamp": 1585582981.8871834, "_step": 385}
{"Episode reward": 71.79999999999987, "Episode length": 282, "Policy Loss": 2.3964390754699707, "Value Loss": 33.499183654785156, "_runtime": 13067.087707281113, "_timestamp": 1585582982.9323406, "_step": 386}
{"Episode reward": 31.683431562408416, "Episode length": 684, "Policy Loss": 0.5291519165039062, "Value Loss": 13.651022911071777, "_runtime": 13068.378602743149, "_timestamp": 1585582984.223236, "_step": 387}
{"Episode reward": 19.05065589211914, "Episode length": 810, "Policy Loss": 0.15224981307983398, "Value Loss": 12.040831565856934, "_runtime": 13069.89444899559, "_timestamp": 1585582985.7390823, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.83875972032547, "Value Loss": 0.02471405453979969, "_runtime": 13071.455996990204, "_timestamp": 1585582987.3006303, "_step": 389}
{"Episode reward": -99.85303793549399, "Episode length": 999, "Policy Loss": -0.8743240237236023, "Value Loss": 0.025687584653496742, "_runtime": 13071.96310377121, "_timestamp": 1585582987.807737, "_step": 390}
{"Episode reward": 70.17902288436875, "Episode length": 299, "Policy Loss": 1.5945698022842407, "Value Loss": 31.209392547607422, "_runtime": 13072.996282815933, "_timestamp": 1585582988.8409162, "_step": 391}
{"Episode reward": 34.59646144956295, "Episode length": 655, "Policy Loss": 0.3425051271915436, "Value Loss": 15.144306182861328, "_runtime": 13073.680446863174, "_timestamp": 1585582989.5250802, "_step": 392}
{"Episode reward": 58.399999999999686, "Episode length": 416, "Policy Loss": 0.8605015277862549, "Value Loss": 23.78949737548828, "_runtime": 13075.225307703018, "_timestamp": 1585582991.069941, "_step": 393}
{"Episode reward": -99.88437875658134, "Episode length": 999, "Policy Loss": -0.8911259770393372, "Value Loss": 0.01789683848619461, "_runtime": 13076.778663873672, "_timestamp": 1585582992.6232972, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8786115050315857, "Value Loss": 0.023656409233808517, "_runtime": 13078.310166358948, "_timestamp": 1585582994.1547997, "_step": 395}
{"Episode reward": -99.82750101089339, "Episode length": 999, "Policy Loss": -0.85055011510849, "Value Loss": 0.11084089428186417, "_runtime": 13079.931230068207, "_timestamp": 1585582995.7758634, "_step": 396}
{"Episode reward": -99.80611040741066, "Episode length": 999, "Policy Loss": -0.8199695944786072, "Value Loss": 0.49352607131004333, "_runtime": 13081.510639667511, "_timestamp": 1585582997.355273, "_step": 397}
{"Episode reward": -99.80394210554519, "Episode length": 999, "Policy Loss": -0.7885771989822388, "Value Loss": 0.1824100911617279, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466, 0.040663786232471466]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.142271488904953, 0.07318639755249023, 0.28864428400993347, 0.5041021108627319, 0.7195600271224976, 0.9350179433822632, 1.1504757404327393, 1.3659336566925049, 1.5813915729522705, 1.7968494892120361, 2.0123074054718018, 2.2277653217315674, 2.443222999572754, 2.6586809158325195, 2.874138832092285, 3.089596748352051, 3.3050546646118164, 3.520512580871582, 3.7359704971313477, 3.9514284133911133, 4.166886329650879, 4.3823442459106445, 4.59780216217041, 4.813260078430176, 5.028717517852783, 5.244175434112549, 5.4596333503723145, 5.67509126663208, 5.890549182891846, 6.106007099151611, 6.321465015411377, 6.536922931671143, 6.752380847930908, 6.967838764190674, 7.1832966804504395, 7.398754596710205, 7.614212512969971, 7.829670429229736, 8.04512882232666, 8.260586738586426, 8.476044654846191, 8.691502571105957, 8.906960487365723, 9.122418403625488, 9.337876319885254, 9.55333423614502, 9.768792152404785, 9.98425006866455, 10.19970703125, 10.415164947509766, 10.630622863769531, 10.846080780029297, 11.061538696289062, 11.276996612548828, 11.492454528808594, 11.70791244506836, 11.923370361328125, 12.13882827758789, 12.354286193847656, 12.569744110107422, 12.785202026367188, 13.000659942626953, 13.216117858886719, 13.431575775146484, 13.64703369140625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07246538996696472, -0.06882891058921814, -0.06519242376089096, -0.06155594065785408, -0.0579194575548172, -0.05428297817707062, -0.05064649134874344, -0.04701001197099686, -0.04337352514266968, -0.039737045764923096, -0.036100562661886215, -0.032464079558849335, -0.028827596455812454, -0.025191113352775574, -0.021554630249738693, -0.017918147146701813, -0.014281664043664932, -0.010645180940628052, -0.00700870156288147, -0.0033722147345542908, 0.00026426464319229126, 0.00390075147151947, 0.007537230849266052, 0.011173717677593231, 0.014810197055339813, 0.018446683883666992, 0.022083163261413574, 0.025719650089740753, 0.029356129467487335, 0.032992616295814514, 0.036629095673561096, 0.040265582501888275, 0.04390206187963486, 0.04753854125738144, 0.05117502808570862, 0.0548115074634552, 0.05844798684120178, 0.06208448112010956, 0.06572096049785614, 0.06935743987560272, 0.0729939192533493, 0.07663041353225708, 0.08026689291000366, 0.08390337228775024, 0.08753985166549683, 0.0911763459444046, 0.09481282532215118, 0.09844930469989777, 0.10208578407764435, 0.10572226345539093, 0.1093587577342987, 0.11299523711204529, 0.11663171648979187, 0.12026819586753845, 0.12390469014644623, 0.1275411695241928, 0.1311776489019394, 0.13481412827968597, 0.13845062255859375, 0.14208710193634033, 0.14572358131408691, 0.1493600606918335, 0.15299655497074127, 0.15663303434848785, 0.16026951372623444]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 4.0, 4.0, 14.0, 13.0, 4.0, 401.0, 15.0, 4.0, 18.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.5674178600311279, -0.5399919748306274, -0.512566089630127, -0.48514023423194885, -0.45771434903144836, -0.4302884638309479, -0.4028626084327698, -0.3754367232322693, -0.3480108380317688, -0.3205849528312683, -0.2931590676307678, -0.2657332122325897, -0.23830732703208923, -0.21088144183158875, -0.18345558643341064, -0.15602970123291016, -0.12860381603240967, -0.10117793083190918, -0.07375204563140869, -0.0463261604309082, -0.018900275230407715, 0.008525550365447998, 0.035951435565948486, 0.06337732076644897, 0.09080320596694946, 0.11822909116744995, 0.14565497636795044, 0.17308086156845093, 0.20050668716430664, 0.22793257236480713, 0.2553584575653076, 0.2827843427658081, 0.3102102279663086, 0.3376361131668091, 0.36506199836730957, 0.39248788356781006, 0.41991376876831055, 0.44733965396881104, 0.4747655391693115, 0.502191424369812, 0.5296173095703125, 0.5570430755615234, 0.5844689607620239, 0.6118948459625244, 0.6393207311630249, 0.6667466163635254, 0.6941725015640259, 0.7215983867645264, 0.7490242719650269, 0.7764501571655273, 0.8038760423660278, 0.8313019275665283, 0.8587278127670288, 0.8861536979675293, 0.9135795831680298, 0.9410054683685303, 0.9684312343597412, 0.9958571195602417, 1.0232830047607422, 1.0507088899612427, 1.0781347751617432, 1.1055606603622437, 1.1329865455627441, 1.1604124307632446, 1.1878383159637451]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.12383978068828583, -0.11162061244249344, -0.09940144419670105, -0.08718228340148926, -0.07496311515569687, -0.06274394690990448, -0.05052478611469269, -0.0383056178689003, -0.02608644962310791, -0.013867281377315521, -0.0016481131315231323, 0.01057104766368866, 0.02279020845890045, 0.03500938415527344, 0.04722854495048523, 0.059447720646858215, 0.07166688144207001, 0.0838860422372818, 0.09610521793365479, 0.10832437872886658, 0.12054355442523956, 0.13276271522045135, 0.14498187601566315, 0.15720103681087494, 0.16942019760608673, 0.1816393882036209, 0.1938585489988327, 0.2060777097940445, 0.2182968705892563, 0.23051603138446808, 0.24273522198200226, 0.25495439767837524, 0.26717352867126465, 0.27939271926879883, 0.29161185026168823, 0.3038310408592224, 0.3160502314567566, 0.328269362449646, 0.3404885530471802, 0.3527076840400696, 0.36492687463760376, 0.37714600563049316, 0.38936519622802734, 0.4015843868255615, 0.4138035178184509, 0.4260227084159851, 0.4382418394088745, 0.4504610300064087, 0.4626801609992981, 0.4748993515968323, 0.48711854219436646, 0.49933767318725586, 0.51155686378479, 0.5237759947776794, 0.5359951853752136, 0.5482143759727478, 0.5604335069656372, 0.5726526975631714, 0.5848718285560608, 0.597091019153595, 0.6093102097511292, 0.6215293407440186, 0.6337485313415527, 0.6459676623344421, 0.6581868529319763]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 5.0, 5.0, 10.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11093016713857651, -0.10463641583919525, -0.0983426570892334, -0.09204890578985214, -0.08575515449047089, -0.07946139574050903, -0.07316764444112778, -0.06687389314174652, -0.060580138117074966, -0.05428638309240341, -0.047992631793022156, -0.0416988804936409, -0.03540512174367905, -0.02911137044429779, -0.022817619144916534, -0.01652386039495468, -0.010230109095573425, -0.003936357796192169, 0.002357400953769684, 0.00865115225315094, 0.014944903552532196, 0.02123866230249405, 0.027532406151294708, 0.03382616490125656, 0.040119923651218414, 0.046413667500019073, 0.052707426249980927, 0.05900118499994278, 0.06529492884874344, 0.07158868759870529, 0.07788244634866714, 0.0841761901974678, 0.09046994894742966, 0.09676370769739151, 0.10305745154619217, 0.10935121029615402, 0.11564496904611588, 0.12193871289491653, 0.12823247909545898, 0.13452622294425964, 0.1408199667930603, 0.14711371064186096, 0.153407484292984, 0.15970122814178467, 0.16599497199058533, 0.17228874564170837, 0.17858248949050903, 0.1848762333393097, 0.19117000699043274, 0.1974637508392334, 0.20375749468803406, 0.2100512683391571, 0.21634501218795776, 0.22263875603675842, 0.22893252968788147, 0.23522627353668213, 0.2415200173854828, 0.24781379103660583, 0.2541075348854065, 0.26040127873420715, 0.2666950523853302, 0.27298879623413086, 0.2792825400829315, 0.28557631373405457, 0.2918700575828552]}, "_runtime": 13083.085338115692, "_timestamp": 1585582998.9299715, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7933055758476257, "Value Loss": 0.39739593863487244, "_runtime": 13084.682338237762, "_timestamp": 1585583000.5269716, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7842934727668762, "Value Loss": 0.28779157996177673, "_runtime": 13085.092643022537, "_timestamp": 1585583000.9372764, "_step": 400}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": 2.724672555923462, "Value Loss": 43.659446716308594, "_runtime": 13086.170676708221, "_timestamp": 1585583002.01531, "_step": 401}
{"Episode reward": 32.21524397581773, "Episode length": 679, "Policy Loss": 0.3570096492767334, "Value Loss": 14.064895629882812, "_runtime": 13087.231339931488, "_timestamp": 1585583003.0759733, "_step": 402}
{"Episode reward": 33.69999999999949, "Episode length": 663, "Policy Loss": 0.31003105640411377, "Value Loss": 14.227749824523926, "_runtime": 13088.744682312012, "_timestamp": 1585583004.5893157, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9204489588737488, "Value Loss": 0.06969960778951645, "_runtime": 13090.306018352509, "_timestamp": 1585583006.1506517, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9517381191253662, "Value Loss": 0.07615862786769867, "_runtime": 13091.863189935684, "_timestamp": 1585583007.7078233, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.966614305973053, "Value Loss": 0.4003836214542389, "_runtime": 13093.364427089691, "_timestamp": 1585583009.2090604, "_step": 406}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": -0.19905534386634827, "Value Loss": 10.63056755065918, "_runtime": 13094.00239443779, "_timestamp": 1585583009.8470278, "_step": 407}
{"Episode reward": 61.39978027343723, "Episode length": 387, "Policy Loss": 1.14834463596344, "Value Loss": 25.093130111694336, "_runtime": 13095.571284770966, "_timestamp": 1585583011.415918, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9433614015579224, "Value Loss": 0.8461987376213074, "_runtime": 13097.155949831009, "_timestamp": 1585583013.0005832, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8133137226104736, "Value Loss": 0.03936806321144104, "_runtime": 13098.11738228798, "_timestamp": 1585583013.9620156, "_step": 410}
{"Episode reward": 37.299999999999386, "Episode length": 627, "Policy Loss": 0.5048438310623169, "Value Loss": 15.386937141418457, "_runtime": 13099.71431517601, "_timestamp": 1585583015.5589485, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6644907593727112, "Value Loss": 0.09286484867334366, "_runtime": 13101.118517875671, "_timestamp": 1585583016.9631512, "_step": 412}
{"Episode reward": 11.36797368526534, "Episode length": 887, "Policy Loss": 0.28118494153022766, "Value Loss": 11.045214653015137, "_runtime": 13102.519522190094, "_timestamp": 1585583018.3641555, "_step": 413}
{"Episode reward": 9.300000000000878, "Episode length": 907, "Policy Loss": 0.32659149169921875, "Value Loss": 10.851717948913574, "_runtime": 13104.157070875168, "_timestamp": 1585583020.0017042, "_step": 414}
{"Episode reward": -99.76523604132095, "Episode length": 999, "Policy Loss": -0.5846946239471436, "Value Loss": 0.10542961955070496, "_runtime": 13105.011373758316, "_timestamp": 1585583020.856007, "_step": 415}
{"Episode reward": 46.09999999999951, "Episode length": 539, "Policy Loss": 0.8678595423698425, "Value Loss": 18.51308250427246, "_runtime": 13106.583945035934, "_timestamp": 1585583022.4285784, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5749152898788452, "Value Loss": 0.07843558490276337, "_runtime": 13108.09603023529, "_timestamp": 1585583023.9406636, "_step": 417}
{"Episode reward": 4.600000000001145, "Episode length": 954, "Policy Loss": 0.24367818236351013, "Value Loss": 10.307615280151367, "_runtime": 13109.527767658234, "_timestamp": 1585583025.372401, "_step": 418}
{"Episode reward": 7.399672232569259, "Episode length": 927, "Policy Loss": 0.2525681257247925, "Value Loss": 10.683279991149902, "_runtime": 13110.201990365982, "_timestamp": 1585583026.0466237, "_step": 419}
{"Episode reward": 59.299508186801965, "Episode length": 408, "Policy Loss": 1.2290445566177368, "Value Loss": 22.91580581665039, "_runtime": 13111.740212917328, "_timestamp": 1585583027.5848463, "_step": 420}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.11170060187578201, "Value Loss": 9.833836555480957, "_runtime": 13112.865414142609, "_timestamp": 1585583028.7100475, "_step": 421}
{"Episode reward": 28.99999999999976, "Episode length": 710, "Policy Loss": 0.4412327706813812, "Value Loss": 13.551182746887207, "_runtime": 13114.38291978836, "_timestamp": 1585583030.2275531, "_step": 422}
{"Episode reward": -99.82778339981893, "Episode length": 999, "Policy Loss": -0.7851325869560242, "Value Loss": 0.05311119928956032, "_runtime": 13115.980212688446, "_timestamp": 1585583031.824846, "_step": 423}
{"Episode reward": -99.80902858711639, "Episode length": 999, "Policy Loss": -0.7961508631706238, "Value Loss": 0.16610972583293915, "_runtime": 13117.537611246109, "_timestamp": 1585583033.3822446, "_step": 424}
{"Episode reward": -99.85819834805885, "Episode length": 999, "Policy Loss": -0.8233563303947449, "Value Loss": 0.15676061809062958, "_runtime": 13118.712943792343, "_timestamp": 1585583034.5575771, "_step": 425}
{"Episode reward": 25.499999999999957, "Episode length": 745, "Policy Loss": 0.28260546922683716, "Value Loss": 14.295384407043457, "_runtime": 13119.962185382843, "_timestamp": 1585583035.8068187, "_step": 426}
{"Episode reward": 22.69355316162121, "Episode length": 774, "Policy Loss": 0.35231563448905945, "Value Loss": 12.495246887207031, "_runtime": 13120.595069646835, "_timestamp": 1585583036.439703, "_step": 427}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.2818663120269775, "Value Loss": 25.01763153076172, "_runtime": 13122.140787124634, "_timestamp": 1585583037.9854205, "_step": 428}
{"Episode reward": -99.89156751781562, "Episode length": 999, "Policy Loss": -0.7108832001686096, "Value Loss": 0.04957515746355057, "_runtime": 13123.722254037857, "_timestamp": 1585583039.5668874, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6782636046409607, "Value Loss": 0.008125652559101582, "_runtime": 13125.249854803085, "_timestamp": 1585583041.0944881, "_step": 430}
{"Episode reward": -99.81577811837056, "Episode length": 999, "Policy Loss": -0.6378776431083679, "Value Loss": 0.013209185563027859, "_runtime": 13126.586567401886, "_timestamp": 1585583042.4312007, "_step": 431}
{"Episode reward": 14.954274206981623, "Episode length": 851, "Policy Loss": 0.299447625875473, "Value Loss": 11.195931434631348, "_runtime": 13128.215822458267, "_timestamp": 1585583044.0604558, "_step": 432}
{"Episode reward": -99.77951769418874, "Episode length": 999, "Policy Loss": -0.5745987892150879, "Value Loss": 0.020188314840197563, "_runtime": 13129.79582977295, "_timestamp": 1585583045.640463, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5577037930488586, "Value Loss": 0.02983880415558815, "_runtime": 13131.369989156723, "_timestamp": 1585583047.2146225, "_step": 434}
{"Episode reward": -99.72584133893112, "Episode length": 999, "Policy Loss": -0.5302596092224121, "Value Loss": 0.03887441009283066, "_runtime": 13132.968575954437, "_timestamp": 1585583048.8132093, "_step": 435}
{"Episode reward": -99.81935064941504, "Episode length": 999, "Policy Loss": -0.501033365726471, "Value Loss": 0.113308846950531, "_runtime": 13134.561267137527, "_timestamp": 1585583050.4059005, "_step": 436}
{"Episode reward": -99.79979116357723, "Episode length": 999, "Policy Loss": -0.4832865297794342, "Value Loss": 0.057892095297575, "_runtime": 13136.071523189545, "_timestamp": 1585583051.9161565, "_step": 437}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": 0.3252739906311035, "Value Loss": 10.014108657836914, "_runtime": 13137.673693656921, "_timestamp": 1585583053.518327, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46886497735977173, "Value Loss": 0.06551054865121841, "_runtime": 13139.2621717453, "_timestamp": 1585583055.106805, "_step": 439}
{"Episode reward": -99.82432107925275, "Episode length": 999, "Policy Loss": -0.462875634431839, "Value Loss": 0.02845492772758007, "_runtime": 13140.847187519073, "_timestamp": 1585583056.6918209, "_step": 440}
{"Episode reward": -99.7371502377079, "Episode length": 999, "Policy Loss": -0.4564850330352783, "Value Loss": 0.06414922326803207, "_runtime": 13142.439882516861, "_timestamp": 1585583058.2845159, "_step": 441}
{"Episode reward": -99.87239118218282, "Episode length": 999, "Policy Loss": -0.4573422968387604, "Value Loss": 0.014090115204453468, "_runtime": 13144.02161860466, "_timestamp": 1585583059.866252, "_step": 442}
{"Episode reward": -99.8895925104604, "Episode length": 999, "Policy Loss": -0.44989722967147827, "Value Loss": 0.007510722614824772, "_runtime": 13145.602694034576, "_timestamp": 1585583061.4473274, "_step": 443}
{"Episode reward": -99.82329664826253, "Episode length": 999, "Policy Loss": -0.4348277449607849, "Value Loss": 0.0403534397482872, "_runtime": 13147.190566062927, "_timestamp": 1585583063.0351994, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42358970642089844, "Value Loss": 0.010742707177996635, "_runtime": 13148.77529335022, "_timestamp": 1585583064.6199267, "_step": 445}
{"Episode reward": -99.8045218527303, "Episode length": 999, "Policy Loss": -0.40802866220474243, "Value Loss": 0.0058145844377577305, "_runtime": 13150.35606765747, "_timestamp": 1585583066.200701, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3792401850223541, "Value Loss": 0.09891442209482193, "_runtime": 13151.994795799255, "_timestamp": 1585583067.8394291, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3705981969833374, "Value Loss": 0.015376483090221882, "_runtime": 13152.64091849327, "_timestamp": 1585583068.4855518, "_step": 448}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.8649213314056396, "Value Loss": 24.67377281188965, "_runtime": 13153.23795247078, "_timestamp": 1585583069.0825858, "_step": 449}
{"Episode reward": 63.999999999999766, "Episode length": 360, "Policy Loss": 1.9195011854171753, "Value Loss": 27.97768783569336, "_runtime": 13153.742774486542, "_timestamp": 1585583069.5874078, "_step": 450}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 2.376796245574951, "Value Loss": 31.494281768798828, "_runtime": 13155.27365231514, "_timestamp": 1585583071.1182857, "_step": 451}
{"Episode reward": -99.85864620543877, "Episode length": 999, "Policy Loss": -0.357042521238327, "Value Loss": 0.0032934267073869705, "_runtime": 13155.854751825333, "_timestamp": 1585583071.6993852, "_step": 452}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 1.8333394527435303, "Value Loss": 25.189048767089844, "_runtime": 13156.934465169907, "_timestamp": 1585583072.7790985, "_step": 453}
{"Episode reward": 27.598713968694057, "Episode length": 725, "Policy Loss": 0.6781761646270752, "Value Loss": 13.025272369384766, "_runtime": 13158.506460666656, "_timestamp": 1585583074.351094, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4865931570529938, "Value Loss": 0.052822552621364594, "_runtime": 13160.025934457779, "_timestamp": 1585583075.8705678, "_step": 455}
{"Episode reward": -99.71822547986964, "Episode length": 999, "Policy Loss": -0.5317434072494507, "Value Loss": 0.030813533812761307, "_runtime": 13161.566349983215, "_timestamp": 1585583077.4109833, "_step": 456}
{"Episode reward": -99.85219674445548, "Episode length": 999, "Policy Loss": -0.5642192959785461, "Value Loss": 0.01259461697191, "_runtime": 13162.824306964874, "_timestamp": 1585583078.6689403, "_step": 457}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": 0.4258216321468353, "Value Loss": 11.924428939819336, "_runtime": 13164.116581916809, "_timestamp": 1585583079.9612153, "_step": 458}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": 0.3323350250720978, "Value Loss": 11.422080039978027, "_runtime": 13165.359963178635, "_timestamp": 1585583081.2045965, "_step": 459}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.33662739396095276, "Value Loss": 11.85759162902832, "_runtime": 13166.179648399353, "_timestamp": 1585583082.0242817, "_step": 460}
{"Episode reward": 48.77273533604994, "Episode length": 513, "Policy Loss": 0.957880973815918, "Value Loss": 18.135820388793945, "_runtime": 13167.404948711395, "_timestamp": 1585583083.249582, "_step": 461}
{"Episode reward": 21.447892884537765, "Episode length": 787, "Policy Loss": 0.3258132338523865, "Value Loss": 12.302294731140137, "_runtime": 13168.96570467949, "_timestamp": 1585583084.810338, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.717313826084137, "Value Loss": 0.01750420220196247, "_runtime": 13169.705974578857, "_timestamp": 1585583085.550608, "_step": 463}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.0218006372451782, "Value Loss": 19.963253021240234, "_runtime": 13170.772365570068, "_timestamp": 1585583086.616999, "_step": 464}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.3972804546356201, "Value Loss": 14.394838333129883, "_runtime": 13171.865582942963, "_timestamp": 1585583087.7102163, "_step": 465}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.2969188392162323, "Value Loss": 13.50491714477539, "_runtime": 13173.396886348724, "_timestamp": 1585583089.2415197, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8116104602813721, "Value Loss": 0.19360369443893433, "_runtime": 13174.516185998917, "_timestamp": 1585583090.3608193, "_step": 467}
{"Episode reward": 27.99847993254643, "Episode length": 721, "Policy Loss": 0.25002267956733704, "Value Loss": 13.192041397094727, "_runtime": 13176.113797664642, "_timestamp": 1585583091.958431, "_step": 468}
{"Episode reward": -99.72948361635068, "Episode length": 999, "Policy Loss": -0.8607649207115173, "Value Loss": 0.0338582806289196, "_runtime": 13177.706218481064, "_timestamp": 1585583093.5508518, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8809196352958679, "Value Loss": 0.1235051155090332, "_runtime": 13179.263505220413, "_timestamp": 1585583095.1081386, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8948277831077576, "Value Loss": 0.025532642379403114, "_runtime": 13180.854276657104, "_timestamp": 1585583096.69891, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8915178775787354, "Value Loss": 0.07803579419851303, "_runtime": 13182.444879293442, "_timestamp": 1585583098.2895126, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8977146148681641, "Value Loss": 0.039623867720365524, "_runtime": 13184.024103879929, "_timestamp": 1585583099.8687372, "_step": 473}
{"Episode reward": -99.82661209702351, "Episode length": 999, "Policy Loss": -0.8819202184677124, "Value Loss": 0.04058610647916794, "_runtime": 13185.626251935959, "_timestamp": 1585583101.4708853, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.869049608707428, "Value Loss": 0.08790779858827591, "_runtime": 13187.217192411423, "_timestamp": 1585583103.0618258, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8647214770317078, "Value Loss": 0.0312239620834589, "_runtime": 13188.814595222473, "_timestamp": 1585583104.6592286, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8520565032958984, "Value Loss": 0.01913810707628727, "_runtime": 13189.832409858704, "_timestamp": 1585583105.6770432, "_step": 477}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 0.3392787575721741, "Value Loss": 14.71445083618164, "_runtime": 13190.712339401245, "_timestamp": 1585583106.5569727, "_step": 478}
{"Episode reward": 45.89999999999951, "Episode length": 541, "Policy Loss": 0.6062297224998474, "Value Loss": 17.11363410949707, "_runtime": 13192.304404497147, "_timestamp": 1585583108.1490378, "_step": 479}
{"Episode reward": -99.81665301471809, "Episode length": 999, "Policy Loss": -0.8305008411407471, "Value Loss": 0.017768824473023415, "_runtime": 13193.870766878128, "_timestamp": 1585583109.7154002, "_step": 480}
{"Episode reward": -99.86986894644657, "Episode length": 999, "Policy Loss": -0.8228333592414856, "Value Loss": 0.0666736289858818, "_runtime": 13195.415679454803, "_timestamp": 1585583111.2603128, "_step": 481}
{"Episode reward": -99.85949998050788, "Episode length": 999, "Policy Loss": -0.8174352049827576, "Value Loss": 0.035413265228271484, "_runtime": 13196.994249105453, "_timestamp": 1585583112.8388824, "_step": 482}
{"Episode reward": 0.810673042760655, "Episode length": 992, "Policy Loss": -0.03059949353337288, "Value Loss": 9.05879020690918, "_runtime": 13198.58066034317, "_timestamp": 1585583114.4252937, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7825025320053101, "Value Loss": 0.01848580874502659, "_runtime": 13200.186462163925, "_timestamp": 1585583116.0310955, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7685166001319885, "Value Loss": 0.06707772612571716, "_runtime": 13200.863754749298, "_timestamp": 1585583116.708388, "_step": 485}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.4213191270828247, "Value Loss": 23.49193572998047, "_runtime": 13201.52107834816, "_timestamp": 1585583117.3657117, "_step": 486}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.3158916234970093, "Value Loss": 23.89018440246582, "_runtime": 13203.085011959076, "_timestamp": 1585583118.9296453, "_step": 487}
{"Episode reward": -99.81644940115372, "Episode length": 999, "Policy Loss": -0.739052414894104, "Value Loss": 0.011317520402371883, "_runtime": 13204.619646072388, "_timestamp": 1585583120.4642794, "_step": 488}
{"Episode reward": -99.80009127892414, "Episode length": 999, "Policy Loss": -0.7369056344032288, "Value Loss": 0.016016585752367973, "_runtime": 13206.150713920593, "_timestamp": 1585583121.9953473, "_step": 489}
{"Episode reward": -99.77950490265947, "Episode length": 999, "Policy Loss": -0.730553925037384, "Value Loss": 0.009457827545702457, "_runtime": 13207.740899085999, "_timestamp": 1585583123.5855324, "_step": 490}
{"Episode reward": -99.63208339437703, "Episode length": 999, "Policy Loss": -0.7197747230529785, "Value Loss": 0.010819549672305584, "_runtime": 13209.323346138, "_timestamp": 1585583125.1679795, "_step": 491}
{"Episode reward": -99.7292671173797, "Episode length": 999, "Policy Loss": -0.697603702545166, "Value Loss": 0.0346345528960228, "_runtime": 13210.243286371231, "_timestamp": 1585583126.0879197, "_step": 492}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.585091769695282, "Value Loss": 16.139989852905273, "_runtime": 13211.83215546608, "_timestamp": 1585583127.6767888, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6747738122940063, "Value Loss": 0.01607067510485649, "_runtime": 13213.343668699265, "_timestamp": 1585583129.188302, "_step": 494}
{"Episode reward": 4.3000000000011624, "Episode length": 957, "Policy Loss": 0.2454913705587387, "Value Loss": 9.85722827911377, "_runtime": 13214.89521408081, "_timestamp": 1585583130.7398474, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6510010361671448, "Value Loss": 0.013798986561596394, "_runtime": 13216.478336811066, "_timestamp": 1585583132.3229702, "_step": 496}
{"Episode reward": -99.80035631805518, "Episode length": 999, "Policy Loss": -0.6290410757064819, "Value Loss": 0.014905283227562904, "_runtime": 13218.076056718826, "_timestamp": 1585583133.92069, "_step": 497}
{"Episode reward": -99.6550964910523, "Episode length": 999, "Policy Loss": -0.6231168508529663, "Value Loss": 0.0458407998085022, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074, -0.00463158218190074]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0], "bins": [-1.3518141508102417, -1.3306196928024292, -1.3094252347946167, -1.2882307767868042, -1.2670363187789917, -1.2458418607711792, -1.2246474027633667, -1.2034528255462646, -1.1822583675384521, -1.1610639095306396, -1.1398694515228271, -1.1186749935150146, -1.0974805355072021, -1.0762860774993896, -1.0550916194915771, -1.0338971614837646, -1.0127027034759521, -0.9915082454681396, -0.9703137874603271, -0.9491193294525146, -0.9279248714447021, -0.9067304134368896, -0.8855358958244324, -0.8643414378166199, -0.8431469798088074, -0.8219525218009949, -0.8007580637931824, -0.7795636057853699, -0.7583690881729126, -0.7371746301651001, -0.7159801721572876, -0.6947857141494751, -0.6735912561416626, -0.6523967981338501, -0.6312023401260376, -0.6100078821182251, -0.5888134241104126, -0.5676189064979553, -0.5464244484901428, -0.5252299904823303, -0.5040355324745178, -0.4828410744667053, -0.4616466164588928, -0.4404521584510803, -0.41925764083862305, -0.39806318283081055, -0.37686872482299805, -0.35567426681518555, -0.33447980880737305, -0.31328535079956055, -0.29209089279174805, -0.27089643478393555, -0.24970197677612305, -0.22850751876831055, -0.20731306076049805, -0.18611860275268555, -0.1649240255355835, -0.143729567527771, -0.1225351095199585, -0.101340651512146, -0.0801461935043335, -0.058951735496520996, -0.037757277488708496, -0.016562819480895996, 0.004631638526916504]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.018254617229104042, -0.017772629857063293, -0.017290640622377396, -0.016808653250336647, -0.01632666401565075, -0.01584467664361, -0.015362687408924103, -0.014880700036883354, -0.014398710802197456, -0.013916723430156708, -0.01343473419547081, -0.012952746823430061, -0.012470758520066738, -0.011988770216703415, -0.011506781913340092, -0.011024793609976768, -0.010542805306613445, -0.010060817003250122, -0.009578828699886799, -0.009096840396523476, -0.008614852093160152, -0.00813286378979683, -0.007650875486433506, -0.007168887183070183, -0.006686899811029434, -0.006204911507666111, -0.005722923204302788, -0.005240934900939465, -0.004758946597576141, -0.004276958294212818, -0.003794969990849495, -0.0033129816874861717, -0.0028309933841228485, -0.0023490060120821, -0.001867016777396202, -0.0013850294053554535, -0.0009030401706695557, -0.00042105279862880707, 6.093643605709076e-05, 0.0005429238080978394, 0.0010249130427837372, 0.0015069004148244858, 0.0019888896495103836, 0.002470877021551132, 0.00295286625623703, 0.0034348536282777786, 0.0039168428629636765, 0.004398830235004425, 0.004880817607045174, 0.0053628068417310715, 0.00584479421377182, 0.006326783448457718, 0.0068087708204984665, 0.007290760055184364, 0.007772747427225113, 0.00825473666191101, 0.00873672403395176, 0.009218713268637657, 0.009700700640678406, 0.010182689875364304, 0.010664677247405052, 0.01114666648209095, 0.011628653854131699, 0.012110643088817596, 0.012592630460858345]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 8.0, 11.0, 3.0, 0.0, 422.0, 7.0, 4.0, 19.0, 2.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.11772724986076355, -0.11462556570768356, -0.11152388155460358, -0.10842220485210419, -0.1053205206990242, -0.10221883654594421, -0.09911715984344482, -0.09601547569036484, -0.09291379153728485, -0.08981210738420486, -0.08671042323112488, -0.08360874652862549, -0.0805070623755455, -0.07740537822246552, -0.07430370151996613, -0.07120201736688614, -0.06810033321380615, -0.06499864906072617, -0.06189696863293648, -0.05879528820514679, -0.0556936040520668, -0.052591919898986816, -0.04949024319648743, -0.04638855904340744, -0.043286874890327454, -0.04018519073724747, -0.03708350658416748, -0.03398182988166809, -0.030880145728588104, -0.027778461575508118, -0.024676784873008728, -0.02157510071992874, -0.018473416566848755, -0.015371732413768768, -0.012270048260688782, -0.009168371558189392, -0.0060666874051094055, -0.002965003252029419, 0.0001366734504699707, 0.0032383576035499573, 0.006340041756629944, 0.009441718459129333, 0.012543410062789917, 0.015645086765289307, 0.018746763467788696, 0.02184845507144928, 0.02495013177394867, 0.028051823377609253, 0.031153500080108643, 0.03425517678260803, 0.037356868386268616, 0.040458545088768005, 0.04356023669242859, 0.04666191339492798, 0.04976359009742737, 0.05286528170108795, 0.05596695840358734, 0.05906863510608673, 0.062170326709747314, 0.0652720034122467, 0.0683736801147461, 0.07147537171840668, 0.07457704842090607, 0.07767874002456665, 0.08078041672706604]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 4.0], "bins": [-0.10591039806604385, -0.10413730889558792, -0.10236421972513199, -0.10059113055467606, -0.09881804138422012, -0.09704495221376419, -0.09527185559272766, -0.09349876642227173, -0.0917256772518158, -0.08995258808135986, -0.08817949891090393, -0.086406409740448, -0.08463332056999207, -0.08286023139953613, -0.0810871422290802, -0.07931405305862427, -0.07754096388816833, -0.0757678747177124, -0.07399478554725647, -0.07222169637680054, -0.0704486072063446, -0.06867551803588867, -0.06690242886543274, -0.06512933224439621, -0.06335624307394028, -0.061583153903484344, -0.05981006473302841, -0.05803697556257248, -0.05626388639211655, -0.054490793496370316, -0.05271770432591438, -0.05094461515545845, -0.04917152598500252, -0.047398436814546585, -0.04562534764409065, -0.04385225847363472, -0.04207916557788849, -0.040306076407432556, -0.038532987236976624, -0.03675989806652069, -0.03498680889606476, -0.033213719725608826, -0.03144063055515289, -0.02966754138469696, -0.027894452214241028, -0.0261213555932045, -0.024348266422748566, -0.022575177252292633, -0.0208020880818367, -0.019028998911380768, -0.017255909740924835, -0.015482820570468903, -0.01370973140001297, -0.011936642229557037, -0.010163553059101105, -0.008390463888645172, -0.0066173747181892395, -0.004844285547733307, -0.0030711889266967773, -0.0012980997562408447, 0.0004749894142150879, 0.0022480785846710205, 0.004021167755126953, 0.005794256925582886, 0.007567346096038818]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 8.0, 26.0, 0.0, 1.0, 5.0], "bins": [-0.03230160102248192, -0.03176183998584747, -0.03122207708656788, -0.030682314187288284, -0.03014255128800869, -0.029602788388729095, -0.02906302735209465, -0.028523264452815056, -0.02798350155353546, -0.027443740516901016, -0.026903977617621422, -0.026364214718341827, -0.025824453681707382, -0.025284690782427788, -0.024744927883148193, -0.024205166846513748, -0.023665403947234154, -0.02312564104795456, -0.022585880011320114, -0.02204611711204052, -0.021506354212760925, -0.02096659317612648, -0.020426830276846886, -0.01988706737756729, -0.019347306340932846, -0.01880754344165325, -0.018267780542373657, -0.017728019505739212, -0.017188256606459618, -0.016648493707180023, -0.01610873080790043, -0.015568969771265984, -0.01502920687198639, -0.014489443972706795, -0.01394968293607235, -0.013409920036792755, -0.01287015713751316, -0.012330396100878716, -0.011790633201599121, -0.011250870302319527, -0.010711107403039932, -0.010171346366405487, -0.009631583467125893, -0.009091820567846298, -0.008552059531211853, -0.008012296631932259, -0.007472533732652664, -0.006932772696018219, -0.006393009796738625, -0.00585324689745903, -0.005313485860824585, -0.0047737229615449905, -0.004233960062265396, -0.003694199025630951, -0.0031544361263513565, -0.002614673227071762, -0.002074912190437317, -0.0015351492911577225, -0.000995386391878128, -0.00045562535524368286, 8.413940668106079e-05, 0.000623900443315506, 0.0011636614799499512, 0.0017034262418746948, 0.00224318727850914]}, "_runtime": 13219.659927368164, "_timestamp": 1585583135.5045607, "_step": 498}
{"Episode reward": -99.80048328973213, "Episode length": 999, "Policy Loss": -0.5953243970870972, "Value Loss": 0.018036404624581337, "_runtime": 13219.659927368164, "_timestamp": 1585583135.5045607, "_step": 499}
