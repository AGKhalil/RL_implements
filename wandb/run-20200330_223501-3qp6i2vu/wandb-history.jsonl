{"Episode reward": -62.833932988047195, "Episode length": 999, "Policy Loss": -0.0946645438671112, "Value Loss": 0.007887073792517185, "_runtime": 10351.466840982437, "_timestamp": 1585607721.0997105, "_step": 0}
{"Episode reward": -96.05656771476087, "Episode length": 999, "Policy Loss": -0.5599409341812134, "Value Loss": 8.032612800598145, "_runtime": 10352.99487066269, "_timestamp": 1585607722.6277401, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2415993213653564, "Value Loss": 1.6485227346420288, "_runtime": 10354.590732812881, "_timestamp": 1585607724.2236023, "_step": 2}
{"Episode reward": -96.90765136255374, "Episode length": 999, "Policy Loss": -5.882408618927002, "Value Loss": 3.578233003616333, "_runtime": 10356.157122850418, "_timestamp": 1585607725.7899923, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.241221308708191, "Value Loss": 0.034433793276548386, "_runtime": 10357.710966348648, "_timestamp": 1585607727.3438358, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3398023843765259, "Value Loss": 0.4936867654323578, "_runtime": 10359.31566119194, "_timestamp": 1585607728.9485307, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3427882194519043, "Value Loss": 0.09599875658750534, "_runtime": 10360.902707576752, "_timestamp": 1585607730.535577, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3021131753921509, "Value Loss": 0.1151447594165802, "_runtime": 10362.441930532455, "_timestamp": 1585607732.0748, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.357276439666748, "Value Loss": 11.925873756408691, "_runtime": 10364.040558338165, "_timestamp": 1585607733.6734278, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1296180486679077, "Value Loss": 0.35525763034820557, "_runtime": 10365.627041578293, "_timestamp": 1585607735.259911, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1389145851135254, "Value Loss": 0.11013560742139816, "_runtime": 10367.189526796341, "_timestamp": 1585607736.8223963, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1441075801849365, "Value Loss": 0.04922369495034218, "_runtime": 10368.787595510483, "_timestamp": 1585607738.420465, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.160789132118225, "Value Loss": 0.02599521353840828, "_runtime": 10370.377989530563, "_timestamp": 1585607740.010859, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1614816188812256, "Value Loss": 0.013492072001099586, "_runtime": 10371.960101366043, "_timestamp": 1585607741.5929708, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1398814916610718, "Value Loss": 0.4038817882537842, "_runtime": 10373.602416992188, "_timestamp": 1585607743.2352865, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1163557767868042, "Value Loss": 0.1218269020318985, "_runtime": 10375.199599027634, "_timestamp": 1585607744.8324685, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2034637928009033, "Value Loss": 0.09140649437904358, "_runtime": 10376.774609327316, "_timestamp": 1585607746.4074788, "_step": 16}
{"Episode reward": -94.65249138019891, "Episode length": 999, "Policy Loss": -0.21504785120487213, "Value Loss": 0.06877567619085312, "_runtime": 10378.380683898926, "_timestamp": 1585607748.0135534, "_step": 17}
{"Episode reward": -94.7553718170393, "Episode length": 999, "Policy Loss": -0.23073090612888336, "Value Loss": 0.0065869782119989395, "_runtime": 10379.98093008995, "_timestamp": 1585607749.6137996, "_step": 18}
{"Episode reward": -96.87377102380172, "Episode length": 999, "Policy Loss": -0.21872253715991974, "Value Loss": 0.007618993986397982, "_runtime": 10381.218851327896, "_timestamp": 1585607750.8517208, "_step": 19}
{"Episode reward": 25.264614853828675, "Episode length": 776, "Policy Loss": 0.31708940863609314, "Value Loss": 13.635722160339355, "_runtime": 10382.81988120079, "_timestamp": 1585607752.4527507, "_step": 20}
{"Episode reward": -97.24174196977178, "Episode length": 999, "Policy Loss": -0.2528451383113861, "Value Loss": 0.02414265088737011, "_runtime": 10384.409556150436, "_timestamp": 1585607754.0424256, "_step": 21}
{"Episode reward": -96.57359964994882, "Episode length": 999, "Policy Loss": -0.29639923572540283, "Value Loss": 0.060002148151397705, "_runtime": 10385.901638746262, "_timestamp": 1585607755.5345082, "_step": 22}
{"Episode reward": 7.956139115593601, "Episode length": 954, "Policy Loss": -1.2089184522628784, "Value Loss": 10.65419864654541, "_runtime": 10387.109524726868, "_timestamp": 1585607756.7423942, "_step": 23}
{"Episode reward": 25.791293662616866, "Episode length": 761, "Policy Loss": 0.15667752921581268, "Value Loss": 13.249154090881348, "_runtime": 10388.46477818489, "_timestamp": 1585607758.0976477, "_step": 24}
{"Episode reward": 15.730108493892445, "Episode length": 852, "Policy Loss": 0.11666850745677948, "Value Loss": 11.649112701416016, "_runtime": 10390.046797513962, "_timestamp": 1585607759.679667, "_step": 25}
{"Episode reward": -98.94542729708675, "Episode length": 999, "Policy Loss": -0.3868456184864044, "Value Loss": 0.14241288602352142, "_runtime": 10391.617440700531, "_timestamp": 1585607761.2503102, "_step": 26}
{"Episode reward": -99.25852314035009, "Episode length": 999, "Policy Loss": -0.450313538312912, "Value Loss": 0.14101850986480713, "_runtime": 10393.19347023964, "_timestamp": 1585607762.8263397, "_step": 27}
{"Episode reward": -99.44784578983683, "Episode length": 999, "Policy Loss": -0.40355587005615234, "Value Loss": 0.20368358492851257, "_runtime": 10394.087163686752, "_timestamp": 1585607763.7200332, "_step": 28}
{"Episode reward": 45.3100712831811, "Episode length": 551, "Policy Loss": 0.32514122128486633, "Value Loss": 18.5957088470459, "_runtime": 10395.679342031479, "_timestamp": 1585607765.3122115, "_step": 29}
{"Episode reward": -99.73846496693884, "Episode length": 999, "Policy Loss": -0.5599656105041504, "Value Loss": 0.09464644640684128, "_runtime": 10396.678408145905, "_timestamp": 1585607766.3112776, "_step": 30}
{"Episode reward": 38.910137026830625, "Episode length": 613, "Policy Loss": 0.42769962549209595, "Value Loss": 16.259063720703125, "_runtime": 10398.250060796738, "_timestamp": 1585607767.8829303, "_step": 31}
{"Episode reward": -99.62091946654117, "Episode length": 999, "Policy Loss": -0.7604162096977234, "Value Loss": 0.5037447214126587, "_runtime": 10399.84847664833, "_timestamp": 1585607769.4813461, "_step": 32}
{"Episode reward": -99.66973440309965, "Episode length": 999, "Policy Loss": -0.8487085700035095, "Value Loss": 0.1369767040014267, "_runtime": 10400.924577236176, "_timestamp": 1585607770.5574467, "_step": 33}
{"Episode reward": 31.68192553319929, "Episode length": 685, "Policy Loss": 0.17822736501693726, "Value Loss": 14.553863525390625, "_runtime": 10402.49987578392, "_timestamp": 1585607772.1327453, "_step": 34}
{"Episode reward": -99.87927780747273, "Episode length": 999, "Policy Loss": -0.747903048992157, "Value Loss": 0.051555562764406204, "_runtime": 10404.100890159607, "_timestamp": 1585607773.7337596, "_step": 35}
{"Episode reward": -99.7383099076557, "Episode length": 999, "Policy Loss": -0.646217942237854, "Value Loss": 0.11171675473451614, "_runtime": 10405.658669948578, "_timestamp": 1585607775.2915394, "_step": 36}
{"Episode reward": -99.61401223610599, "Episode length": 999, "Policy Loss": -0.6288076043128967, "Value Loss": 0.05723141133785248, "_runtime": 10407.003184318542, "_timestamp": 1585607776.6360538, "_step": 37}
{"Episode reward": 15.410783172771858, "Episode length": 847, "Policy Loss": 0.20131362974643707, "Value Loss": 11.951106071472168, "_runtime": 10407.985008955002, "_timestamp": 1585607777.6178784, "_step": 38}
{"Episode reward": 39.59999999999942, "Episode length": 604, "Policy Loss": 0.3880629539489746, "Value Loss": 16.641359329223633, "_runtime": 10409.184128522873, "_timestamp": 1585607778.816998, "_step": 39}
{"Episode reward": 24.28465692205357, "Episode length": 759, "Policy Loss": 0.13379448652267456, "Value Loss": 13.093071937561035, "_runtime": 10410.763384103775, "_timestamp": 1585607780.3962536, "_step": 40}
{"Episode reward": -99.81224401928344, "Episode length": 999, "Policy Loss": -0.7475155591964722, "Value Loss": 0.03650527447462082, "_runtime": 10411.544865131378, "_timestamp": 1585607781.1777346, "_step": 41}
{"Episode reward": 50.99405889129224, "Episode length": 491, "Policy Loss": 0.5039787292480469, "Value Loss": 19.98470115661621, "_runtime": 10413.115105390549, "_timestamp": 1585607782.7479749, "_step": 42}
{"Episode reward": -99.72839408872976, "Episode length": 999, "Policy Loss": -0.8857753872871399, "Value Loss": 0.06466642022132874, "_runtime": 10413.933801651001, "_timestamp": 1585607783.5666711, "_step": 43}
{"Episode reward": 49.19623994193927, "Episode length": 509, "Policy Loss": 0.45470017194747925, "Value Loss": 19.455528259277344, "_runtime": 10415.19392824173, "_timestamp": 1585607784.8267977, "_step": 44}
{"Episode reward": 18.29024676883165, "Episode length": 818, "Policy Loss": -0.059481460601091385, "Value Loss": 12.132842063903809, "_runtime": 10416.707219362259, "_timestamp": 1585607786.3400888, "_step": 45}
{"Episode reward": 5.692664913368574, "Episode length": 945, "Policy Loss": -0.16031508147716522, "Value Loss": 10.737089157104492, "_runtime": 10417.934572219849, "_timestamp": 1585607787.5674417, "_step": 46}
{"Episode reward": 20.399923046585428, "Episode length": 797, "Policy Loss": -0.11963478475809097, "Value Loss": 12.342759132385254, "_runtime": 10419.503493785858, "_timestamp": 1585607789.1363633, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8800264596939087, "Value Loss": 0.05035790801048279, "_runtime": 10420.36067032814, "_timestamp": 1585607789.9935398, "_step": 48}
{"Episode reward": 47.55578384525096, "Episode length": 527, "Policy Loss": 0.40784531831741333, "Value Loss": 18.674083709716797, "_runtime": 10420.982013225555, "_timestamp": 1585607790.6148827, "_step": 49}
{"Episode reward": 62.04571015834782, "Episode length": 380, "Policy Loss": 0.9707865118980408, "Value Loss": 25.969526290893555, "_runtime": 10422.544784545898, "_timestamp": 1585607792.177654, "_step": 50}
{"Episode reward": -99.66933471124946, "Episode length": 999, "Policy Loss": -0.7690179347991943, "Value Loss": 0.013661802746355534, "_runtime": 10424.132149457932, "_timestamp": 1585607793.765019, "_step": 51}
{"Episode reward": -99.81955000983876, "Episode length": 999, "Policy Loss": -0.7412576079368591, "Value Loss": 0.022006334736943245, "_runtime": 10425.646897554398, "_timestamp": 1585607795.279767, "_step": 52}
{"Episode reward": -99.69572416685848, "Episode length": 999, "Policy Loss": -0.7178086638450623, "Value Loss": 0.018597736954689026, "_runtime": 10427.24834728241, "_timestamp": 1585607796.8812168, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.693905234336853, "Value Loss": 0.02570168860256672, "_runtime": 10428.617277622223, "_timestamp": 1585607798.250147, "_step": 54}
{"Episode reward": 14.2000000000006, "Episode length": 858, "Policy Loss": 0.6760125756263733, "Value Loss": 11.6214599609375, "_runtime": 10429.195954799652, "_timestamp": 1585607798.8288243, "_step": 55}
{"Episode reward": 65.6601573522899, "Episode length": 344, "Policy Loss": 1.2110390663146973, "Value Loss": 28.630393981933594, "_runtime": 10430.775367975235, "_timestamp": 1585607800.4082375, "_step": 56}
{"Episode reward": -99.69287031099526, "Episode length": 999, "Policy Loss": -0.6967393755912781, "Value Loss": 0.02136608026921749, "_runtime": 10432.365231513977, "_timestamp": 1585607801.998101, "_step": 57}
{"Episode reward": -99.6208534582737, "Episode length": 999, "Policy Loss": -0.6934403777122498, "Value Loss": 0.05689803510904312, "_runtime": 10433.888098955154, "_timestamp": 1585607803.5209684, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7269914150238037, "Value Loss": 0.03079553134739399, "_runtime": 10435.201041221619, "_timestamp": 1585607804.8339107, "_step": 59}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": 0.08415666967630386, "Value Loss": 11.955368995666504, "_runtime": 10435.998925924301, "_timestamp": 1585607805.6317954, "_step": 60}
{"Episode reward": 51.49745937725488, "Episode length": 486, "Policy Loss": 0.8726067543029785, "Value Loss": 20.210220336914062, "_runtime": 10437.571303844452, "_timestamp": 1585607807.2041733, "_step": 61}
{"Episode reward": -99.69974705513894, "Episode length": 999, "Policy Loss": -0.6967888474464417, "Value Loss": 0.05624432489275932, "_runtime": 10438.809700250626, "_timestamp": 1585607808.4425697, "_step": 62}
{"Episode reward": 22.30000000000014, "Episode length": 777, "Policy Loss": 0.15539132058620453, "Value Loss": 12.514216423034668, "_runtime": 10440.153812408447, "_timestamp": 1585607809.786682, "_step": 63}
{"Episode reward": 12.746622505947698, "Episode length": 873, "Policy Loss": 0.14703579246997833, "Value Loss": 11.221976280212402, "_runtime": 10441.73042845726, "_timestamp": 1585607811.363298, "_step": 64}
{"Episode reward": -99.79917351521878, "Episode length": 999, "Policy Loss": -0.5367359519004822, "Value Loss": 0.4248082935810089, "_runtime": 10443.063799381256, "_timestamp": 1585607812.6966689, "_step": 65}
{"Episode reward": 15.583587802760832, "Episode length": 847, "Policy Loss": 0.18031001091003418, "Value Loss": 11.633435249328613, "_runtime": 10444.629850625992, "_timestamp": 1585607814.26272, "_step": 66}
{"Episode reward": -99.75068288617628, "Episode length": 999, "Policy Loss": -0.6107006072998047, "Value Loss": 0.061047330498695374, "_runtime": 10446.213710784912, "_timestamp": 1585607815.8465803, "_step": 67}
{"Episode reward": -99.8041365213911, "Episode length": 999, "Policy Loss": -0.607973039150238, "Value Loss": 0.03199001029133797, "_runtime": 10447.82855629921, "_timestamp": 1585607817.4614258, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6030533909797668, "Value Loss": 0.01123484130948782, "_runtime": 10449.31411600113, "_timestamp": 1585607818.9469855, "_step": 69}
{"Episode reward": 6.309318087996104, "Episode length": 937, "Policy Loss": 0.2562589645385742, "Value Loss": 10.530777931213379, "_runtime": 10450.910750627518, "_timestamp": 1585607820.54362, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6162425875663757, "Value Loss": 0.03939501568675041, "_runtime": 10452.07100391388, "_timestamp": 1585607821.7038734, "_step": 71}
{"Episode reward": 27.682549340254468, "Episode length": 724, "Policy Loss": 0.33560997247695923, "Value Loss": 13.665897369384766, "_runtime": 10452.841415405273, "_timestamp": 1585607822.474285, "_step": 72}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 0.8535860776901245, "Value Loss": 20.98484230041504, "_runtime": 10454.434479951859, "_timestamp": 1585607824.0673494, "_step": 73}
{"Episode reward": -99.80000900784368, "Episode length": 999, "Policy Loss": -0.5720596313476562, "Value Loss": 0.011235239915549755, "_runtime": 10456.00175523758, "_timestamp": 1585607825.6346247, "_step": 74}
{"Episode reward": -99.82560846377024, "Episode length": 999, "Policy Loss": -0.5615039467811584, "Value Loss": 0.02066037803888321, "_runtime": 10457.540245771408, "_timestamp": 1585607827.1731153, "_step": 75}
{"Episode reward": -99.66172105159939, "Episode length": 999, "Policy Loss": -0.5493592023849487, "Value Loss": 0.04532024636864662, "_runtime": 10459.138108253479, "_timestamp": 1585607828.7709777, "_step": 76}
{"Episode reward": -99.69488172838327, "Episode length": 999, "Policy Loss": -0.5334326028823853, "Value Loss": 0.062449611723423004, "_runtime": 10460.17308139801, "_timestamp": 1585607829.8059509, "_step": 77}
{"Episode reward": 35.93056455729466, "Episode length": 642, "Policy Loss": 0.503932774066925, "Value Loss": 15.279951095581055, "_runtime": 10461.760180711746, "_timestamp": 1585607831.3930502, "_step": 78}
{"Episode reward": -99.77223009902379, "Episode length": 999, "Policy Loss": -0.5432186126708984, "Value Loss": 0.029449883848428726, "_runtime": 10463.180814266205, "_timestamp": 1585607832.8136837, "_step": 79}
{"Episode reward": 10.91697814781297, "Episode length": 893, "Policy Loss": 0.22219903767108917, "Value Loss": 11.052614212036133, "_runtime": 10464.751639127731, "_timestamp": 1585607834.3845086, "_step": 80}
{"Episode reward": -99.80256299686012, "Episode length": 999, "Policy Loss": -0.5765946507453918, "Value Loss": 0.026562334969639778, "_runtime": 10466.203275680542, "_timestamp": 1585607835.8361452, "_step": 81}
{"Episode reward": 9.295409097430252, "Episode length": 908, "Policy Loss": 0.2158488929271698, "Value Loss": 10.761393547058105, "_runtime": 10467.781147241592, "_timestamp": 1585607837.4140167, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6025004982948303, "Value Loss": 0.03515439108014107, "_runtime": 10468.523741483688, "_timestamp": 1585607838.156611, "_step": 83}
{"Episode reward": 54.82093399455734, "Episode length": 452, "Policy Loss": 0.8696417808532715, "Value Loss": 21.536291122436523, "_runtime": 10470.112196207047, "_timestamp": 1585607839.7450657, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6071399450302124, "Value Loss": 0.026919400319457054, "_runtime": 10471.739584684372, "_timestamp": 1585607841.3724542, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6117130517959595, "Value Loss": 0.016335919499397278, "_runtime": 10473.183693885803, "_timestamp": 1585607842.8165634, "_step": 86}
{"Episode reward": 6.2000000000010544, "Episode length": 938, "Policy Loss": 0.18874996900558472, "Value Loss": 10.645957946777344, "_runtime": 10474.383613109589, "_timestamp": 1585607844.0164826, "_step": 87}
{"Episode reward": 24.513115496747204, "Episode length": 756, "Policy Loss": 0.30542752146720886, "Value Loss": 12.820943832397461, "_runtime": 10475.976392507553, "_timestamp": 1585607845.609262, "_step": 88}
{"Episode reward": -99.6857394691077, "Episode length": 999, "Policy Loss": -0.5328879356384277, "Value Loss": 0.039888616651296616, "_runtime": 10477.54555940628, "_timestamp": 1585607847.178429, "_step": 89}
{"Episode reward": -99.84895899295667, "Episode length": 999, "Policy Loss": -0.5293271541595459, "Value Loss": 0.01417007576674223, "_runtime": 10479.115195512772, "_timestamp": 1585607848.748065, "_step": 90}
{"Episode reward": -99.7785792962634, "Episode length": 999, "Policy Loss": -0.48215264081954956, "Value Loss": 0.029108233749866486, "_runtime": 10480.712827682495, "_timestamp": 1585607850.3456972, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47882282733917236, "Value Loss": 0.020851438865065575, "_runtime": 10482.289339065552, "_timestamp": 1585607851.9222085, "_step": 92}
{"Episode reward": -99.72508292230638, "Episode length": 999, "Policy Loss": -0.45670732855796814, "Value Loss": 0.00827622227370739, "_runtime": 10483.262844324112, "_timestamp": 1585607852.8957138, "_step": 93}
{"Episode reward": 40.001487582083215, "Episode length": 601, "Policy Loss": 0.9069896340370178, "Value Loss": 16.127700805664062, "_runtime": 10484.861016273499, "_timestamp": 1585607854.4938858, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4415280818939209, "Value Loss": 0.020723087713122368, "_runtime": 10486.188740730286, "_timestamp": 1585607855.8216102, "_step": 95}
{"Episode reward": 16.99912223778709, "Episode length": 831, "Policy Loss": 0.5827398896217346, "Value Loss": 11.777853965759277, "_runtime": 10487.741960048676, "_timestamp": 1585607857.3748295, "_step": 96}
{"Episode reward": -99.89156167739863, "Episode length": 999, "Policy Loss": -0.4715879261493683, "Value Loss": 0.013087708503007889, "_runtime": 10488.727412223816, "_timestamp": 1585607858.3602817, "_step": 97}
{"Episode reward": 39.44992001717852, "Episode length": 606, "Policy Loss": 0.6336325407028198, "Value Loss": 16.163436889648438, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716, 0.39808398485183716]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.141705870628357, -0.6670892238616943, -0.19247257709503174, 0.28214406967163086, 0.7567607164382935, 1.2313772439956665, 1.7059940099716187, 2.1806106567382812, 2.6552271842956543, 3.1298437118530273, 3.6044602394104004, 4.079077243804932, 4.553693771362305, 5.028310298919678, 5.502927303314209, 5.977543830871582, 6.452160358428955, 6.926777362823486, 7.401393413543701, 7.876010417938232, 8.350626945495605, 8.825243949890137, 9.299860954284668, 9.774477005004883, 10.249094009399414, 10.723711013793945, 11.19832706451416, 11.672944068908691, 12.147561073303223, 12.622177124023438, 13.096794128417969, 13.571410179138184, 14.046027183532715, 14.520644187927246, 14.995261192321777, 15.469876289367676, 15.944493293762207, 16.419109344482422, 16.893726348876953, 17.368343353271484, 17.842958450317383, 18.317575454711914, 18.792192459106445, 19.266809463500977, 19.741426467895508, 20.21604347229004, 20.690658569335938, 21.16527557373047, 21.639892578125, 22.11450958251953, 22.589126586914062, 23.06374168395996, 23.538358688354492, 24.012975692749023, 24.487592697143555, 24.962209701538086, 25.436826705932617, 25.911441802978516, 26.386058807373047, 26.860675811767578, 27.33529281616211, 27.80990982055664, 28.28452491760254, 28.75914192199707, 29.2337589263916]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06804163008928299, -0.05249127745628357, -0.03694092482328415, -0.021390575915575027, -0.005840223282575607, 0.009710125625133514, 0.025260478258132935, 0.040810830891132355, 0.056361183524131775, 0.0719115361571312, 0.08746188133955002, 0.10301224142313004, 0.11856258660554886, 0.13411295413970947, 0.1496632993221283, 0.16521364450454712, 0.18076398968696594, 0.19631436467170715, 0.21186470985412598, 0.2274150550365448, 0.24296540021896362, 0.25851577520370483, 0.27406612038612366, 0.2896164655685425, 0.3051668107509613, 0.3207171559333801, 0.33626753091812134, 0.35181787610054016, 0.367368221282959, 0.3829185664653778, 0.398468941450119, 0.41401928663253784, 0.42956963181495667, 0.4451199769973755, 0.4606703519821167, 0.47622066736221313, 0.49177104234695435, 0.5073214173316956, 0.522871732711792, 0.5384221076965332, 0.5539724230766296, 0.5695227980613708, 0.5850731730461121, 0.6006234884262085, 0.6161738634109497, 0.6317241787910461, 0.6472745537757874, 0.6628249287605286, 0.678375244140625, 0.6939256191253662, 0.7094759345054626, 0.7250263094902039, 0.7405766844749451, 0.7561269998550415, 0.7716773748397827, 0.7872277498245239, 0.8027780652046204, 0.8183284401893616, 0.833878755569458, 0.8494291305541992, 0.8649795055389404, 0.8805298209190369, 0.8960801959037781, 0.9116305112838745, 0.9271808862686157]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 3.0, 5.0, 5.0, 6.0, 8.0, 7.0, 5.0, 17.0, 10.0, 336.0, 40.0, 2.0, 1.0, 2.0, 1.0, 5.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9502986669540405, -0.8817642331123352, -0.8132297992706299, -0.7446954250335693, -0.676160991191864, -0.6076265573501587, -0.5390921831130981, -0.4705577492713928, -0.4020233154296875, -0.3334888815879822, -0.26495444774627686, -0.1964200735092163, -0.127885639667511, -0.059351205825805664, 0.009183168411254883, 0.07771766185760498, 0.14625203609466553, 0.21478641033172607, 0.28332090377807617, 0.3518552780151367, 0.4203897714614868, 0.48892414569854736, 0.5574585199356079, 0.625993013381958, 0.6945273876190186, 0.7630617618560791, 0.8315962553024292, 0.9001306295394897, 0.9686650037765503, 1.0371994972229004, 1.1057339906692505, 1.174268364906311, 1.2428027391433716, 1.3113371133804321, 1.3798714876174927, 1.4484061002731323, 1.5169404745101929, 1.5854748487472534, 1.654009222984314, 1.7225435972213745, 1.7910782098770142, 1.8596125841140747, 1.9281469583511353, 1.9966813325881958, 2.065215587615967, 2.1337499618530273, 2.202284812927246, 2.2708191871643066, 2.339353561401367, 2.4078879356384277, 2.4764223098754883, 2.544956684112549, 2.6134910583496094, 2.68202543258667, 2.7505598068237305, 2.819094181060791, 2.8876285552978516, 2.9561634063720703, 3.024697780609131, 3.0932321548461914, 3.161766529083252, 3.2303009033203125, 3.298835277557373, 3.3673696517944336, 3.435904026031494]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-2.7291600704193115, -2.5782909393310547, -2.427421808242798, -2.276552677154541, -2.125683546066284, -1.9748144149780273, -1.8239452838897705, -1.6730761528015137, -1.5222070217132568, -1.371337890625, -1.2204687595367432, -1.0695996284484863, -0.9187304973602295, -0.7678613662719727, -0.6169922351837158, -0.466123104095459, -0.31525397300720215, -0.1643848419189453, -0.013515710830688477, 0.13735342025756836, 0.2882225513458252, 0.43909168243408203, 0.5899608135223389, 0.7408299446105957, 0.8916990756988525, 1.0425682067871094, 1.1934373378753662, 1.344306230545044, 1.4951756000518799, 1.6460449695587158, 1.7969138622283936, 1.9477827548980713, 2.0986521244049072, 2.249521493911743, 2.400390386581421, 2.5512592792510986, 2.7021286487579346, 2.8529980182647705, 3.0038669109344482, 3.154735803604126, 3.305605173110962, 3.456474542617798, 3.6073434352874756, 3.7582123279571533, 3.9090816974639893, 4.059950828552246, 4.210820198059082, 4.361688613891602, 4.5125579833984375, 4.663427352905273, 4.814296722412109, 4.965165138244629, 5.116034507751465, 5.266903877258301, 5.41777229309082, 5.568641662597656, 5.719511032104492, 5.870380401611328, 6.021249771118164, 6.172118186950684, 6.3229875564575195, 6.4738569259643555, 6.624725341796875, 6.775594711303711, 6.926464080810547]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 4.0, 5.0, 7.0, 9.0, 4.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0], "bins": [-2.9116568565368652, -2.8535311222076416, -2.795405387878418, -2.7372796535491943, -2.6791539192199707, -2.621028423309326, -2.5629026889801025, -2.504776954650879, -2.4466512203216553, -2.3885254859924316, -2.330399751663208, -2.2722740173339844, -2.21414852142334, -2.156022548675537, -2.0978970527648926, -2.039771318435669, -1.9816455841064453, -1.9235198497772217, -1.865394115447998, -1.807268500328064, -1.7491427659988403, -1.6910170316696167, -1.6328914165496826, -1.574765682220459, -1.5166399478912354, -1.4585142135620117, -1.400388479232788, -1.342262864112854, -1.2841371297836304, -1.2260113954544067, -1.1678857803344727, -1.109760046005249, -1.0516343116760254, -0.9935085773468018, -0.9353828430175781, -0.8772571086883545, -0.8191313743591309, -0.7610058784484863, -0.7028801441192627, -0.6447544097900391, -0.5866286754608154, -0.5285029411315918, -0.47037720680236816, -0.41225147247314453, -0.3541259765625, -0.29600024223327637, -0.23787450790405273, -0.1797487735748291, -0.12162303924560547, -0.06349730491638184, -0.005371570587158203, 0.05275416374206543, 0.11087989807128906, 0.1690053939819336, 0.22713112831115723, 0.28525686264038086, 0.3433825969696045, 0.4015083312988281, 0.45963406562805176, 0.5177597999572754, 0.5758852958679199, 0.6340110301971436, 0.6921367645263672, 0.7502624988555908, 0.8083882331848145]}, "_runtime": 10489.936614990234, "_timestamp": 1585607859.5694845, "_step": 98}
{"Episode reward": 23.4839442875237, "Episode length": 766, "Policy Loss": 0.3926287889480591, "Value Loss": 12.564252853393555, "_runtime": 10491.117415904999, "_timestamp": 1585607860.7502854, "_step": 99}
{"Episode reward": 25.165055261715295, "Episode length": 749, "Policy Loss": 0.49162572622299194, "Value Loss": 13.53447151184082, "_runtime": 10492.666245937347, "_timestamp": 1585607862.2991154, "_step": 100}
{"Episode reward": -99.50620579228134, "Episode length": 999, "Policy Loss": -0.4919416904449463, "Value Loss": 0.012896302156150341, "_runtime": 10494.263741016388, "_timestamp": 1585607863.8966105, "_step": 101}
{"Episode reward": -99.70566152203689, "Episode length": 999, "Policy Loss": -0.453733891248703, "Value Loss": 0.00891109462827444, "_runtime": 10495.82419371605, "_timestamp": 1585607865.4570632, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4384610056877136, "Value Loss": 0.029340891167521477, "_runtime": 10497.400073051453, "_timestamp": 1585607867.0329425, "_step": 103}
{"Episode reward": -99.82618448221918, "Episode length": 999, "Policy Loss": -0.40515655279159546, "Value Loss": 0.038687482476234436, "_runtime": 10498.97867321968, "_timestamp": 1585607868.6115427, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3692728579044342, "Value Loss": 0.01768564060330391, "_runtime": 10500.569954156876, "_timestamp": 1585607870.2028236, "_step": 105}
{"Episode reward": -99.78507944829623, "Episode length": 999, "Policy Loss": -0.3623248040676117, "Value Loss": 0.0336601547896862, "_runtime": 10501.229206323624, "_timestamp": 1585607870.8620758, "_step": 106}
{"Episode reward": 60.594933104514794, "Episode length": 395, "Policy Loss": 1.3957685232162476, "Value Loss": 24.992097854614258, "_runtime": 10502.807797670364, "_timestamp": 1585607872.4406672, "_step": 107}
{"Episode reward": -99.49189919794306, "Episode length": 999, "Policy Loss": -0.3404112160205841, "Value Loss": 0.02099950797855854, "_runtime": 10504.40098977089, "_timestamp": 1585607874.0338593, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3527128994464874, "Value Loss": 0.01291448250412941, "_runtime": 10505.928468227386, "_timestamp": 1585607875.5613377, "_step": 109}
{"Episode reward": -99.56801459845016, "Episode length": 999, "Policy Loss": -0.36014461517333984, "Value Loss": 0.01094124000519514, "_runtime": 10507.006764888763, "_timestamp": 1585607876.6396344, "_step": 110}
{"Episode reward": 33.050564535310954, "Episode length": 671, "Policy Loss": 0.6267267465591431, "Value Loss": 14.57252311706543, "_runtime": 10508.599658966064, "_timestamp": 1585607878.2325284, "_step": 111}
{"Episode reward": -99.70749669941003, "Episode length": 999, "Policy Loss": -0.3863660991191864, "Value Loss": 0.01647147722542286, "_runtime": 10510.18473815918, "_timestamp": 1585607879.8176076, "_step": 112}
{"Episode reward": -99.80872130775684, "Episode length": 999, "Policy Loss": -0.406375914812088, "Value Loss": 0.008221154101192951, "_runtime": 10510.62464094162, "_timestamp": 1585607880.2575104, "_step": 113}
{"Episode reward": 74.29999999999991, "Episode length": 257, "Policy Loss": 2.121041774749756, "Value Loss": 37.70907211303711, "_runtime": 10512.212979316711, "_timestamp": 1585607881.8458488, "_step": 114}
{"Episode reward": -99.88733075894275, "Episode length": 999, "Policy Loss": -0.44528087973594666, "Value Loss": 0.06880924105644226, "_runtime": 10512.820586681366, "_timestamp": 1585607882.4534562, "_step": 115}
{"Episode reward": 63.09999999999975, "Episode length": 369, "Policy Loss": 1.2230193614959717, "Value Loss": 25.624311447143555, "_runtime": 10514.28028678894, "_timestamp": 1585607883.9131563, "_step": 116}
{"Episode reward": 3.3908369285997964, "Episode length": 967, "Policy Loss": 0.19494356215000153, "Value Loss": 9.859365463256836, "_runtime": 10514.683053970337, "_timestamp": 1585607884.3159235, "_step": 117}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": 3.236677885055542, "Value Loss": 44.27749252319336, "_runtime": 10516.219754219055, "_timestamp": 1585607885.8526237, "_step": 118}
{"Episode reward": -99.65782604359418, "Episode length": 999, "Policy Loss": -0.5809810757637024, "Value Loss": 0.13481582701206207, "_runtime": 10516.748239994049, "_timestamp": 1585607886.3811095, "_step": 119}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": 1.564379334449768, "Value Loss": 30.21639060974121, "_runtime": 10518.029896497726, "_timestamp": 1585607887.662766, "_step": 120}
{"Episode reward": 17.437513025384817, "Episode length": 827, "Policy Loss": 0.22423548996448517, "Value Loss": 11.423165321350098, "_runtime": 10519.621904850006, "_timestamp": 1585607889.2547743, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.56181800365448, "Value Loss": 0.0215667225420475, "_runtime": 10521.136206626892, "_timestamp": 1585607890.769076, "_step": 122}
{"Episode reward": -99.67504258295382, "Episode length": 999, "Policy Loss": -0.517464816570282, "Value Loss": 0.07281818985939026, "_runtime": 10521.835094213486, "_timestamp": 1585607891.4679637, "_step": 123}
{"Episode reward": 56.59979710429873, "Episode length": 435, "Policy Loss": 1.02826726436615, "Value Loss": 22.22096824645996, "_runtime": 10523.026109218597, "_timestamp": 1585607892.6589787, "_step": 124}
{"Episode reward": 25.512097107036922, "Episode length": 748, "Policy Loss": 0.4141595661640167, "Value Loss": 13.032174110412598, "_runtime": 10524.583061218262, "_timestamp": 1585607894.2159307, "_step": 125}
{"Episode reward": -99.66816157263099, "Episode length": 999, "Policy Loss": -0.5223211646080017, "Value Loss": 0.12551291286945343, "_runtime": 10525.926636457443, "_timestamp": 1585607895.559506, "_step": 126}
{"Episode reward": 11.871526413784167, "Episode length": 883, "Policy Loss": 0.2070574164390564, "Value Loss": 11.374423027038574, "_runtime": 10527.044329166412, "_timestamp": 1585607896.6771986, "_step": 127}
{"Episode reward": 29.468951329495496, "Episode length": 707, "Policy Loss": 0.31285807490348816, "Value Loss": 13.47521686553955, "_runtime": 10527.96831202507, "_timestamp": 1585607897.6011815, "_step": 128}
{"Episode reward": 42.19999927878325, "Episode length": 579, "Policy Loss": 0.4925093352794647, "Value Loss": 16.630586624145508, "_runtime": 10528.728950738907, "_timestamp": 1585607898.3618202, "_step": 129}
{"Episode reward": 51.55296488245908, "Episode length": 485, "Policy Loss": 0.8078112602233887, "Value Loss": 20.336524963378906, "_runtime": 10530.287587881088, "_timestamp": 1585607899.9204574, "_step": 130}
{"Episode reward": -99.800388339533, "Episode length": 999, "Policy Loss": -0.658986508846283, "Value Loss": 0.06573408842086792, "_runtime": 10531.825044631958, "_timestamp": 1585607901.457914, "_step": 131}
{"Episode reward": -99.82058342306269, "Episode length": 999, "Policy Loss": -0.6237017512321472, "Value Loss": 0.08770816773176193, "_runtime": 10533.355581998825, "_timestamp": 1585607902.9884515, "_step": 132}
{"Episode reward": -99.84139695698255, "Episode length": 999, "Policy Loss": -0.5994888544082642, "Value Loss": 0.030368326231837273, "_runtime": 10534.910455226898, "_timestamp": 1585607904.5433247, "_step": 133}
{"Episode reward": 1.5964298054356192, "Episode length": 985, "Policy Loss": 0.1595306098461151, "Value Loss": 9.970200538635254, "_runtime": 10535.963808774948, "_timestamp": 1585607905.5966783, "_step": 134}
{"Episode reward": 33.72012873059087, "Episode length": 663, "Policy Loss": 0.39765629172325134, "Value Loss": 14.79699993133545, "_runtime": 10537.52741241455, "_timestamp": 1585607907.160282, "_step": 135}
{"Episode reward": -99.86068358542258, "Episode length": 999, "Policy Loss": -0.5756409168243408, "Value Loss": 0.010305928066372871, "_runtime": 10537.962019443512, "_timestamp": 1585607907.594889, "_step": 136}
{"Episode reward": 75.79999999999993, "Episode length": 242, "Policy Loss": 2.047941207885742, "Value Loss": 40.89118576049805, "_runtime": 10539.507795333862, "_timestamp": 1585607909.1406648, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6181087493896484, "Value Loss": 0.009353168308734894, "_runtime": 10541.0715341568, "_timestamp": 1585607910.7044036, "_step": 138}
{"Episode reward": -99.6215950961211, "Episode length": 999, "Policy Loss": -0.6548609733581543, "Value Loss": 0.01122624333947897, "_runtime": 10542.59119939804, "_timestamp": 1585607912.2240689, "_step": 139}
{"Episode reward": -99.76765310738563, "Episode length": 999, "Policy Loss": -0.6787013411521912, "Value Loss": 0.01330405194312334, "_runtime": 10543.11042714119, "_timestamp": 1585607912.7432966, "_step": 140}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 1.8555999994277954, "Value Loss": 32.592620849609375, "_runtime": 10543.626346349716, "_timestamp": 1585607913.2592158, "_step": 141}
{"Episode reward": 69.26936839062239, "Episode length": 309, "Policy Loss": 1.35080087184906, "Value Loss": 31.299753189086914, "_runtime": 10545.177106618881, "_timestamp": 1585607914.809976, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8081308007240295, "Value Loss": 0.12816262245178223, "_runtime": 10546.679425239563, "_timestamp": 1585607916.3122947, "_step": 143}
{"Episode reward": -99.80236007906358, "Episode length": 999, "Policy Loss": -0.8960840702056885, "Value Loss": 0.13257822394371033, "_runtime": 10548.177482843399, "_timestamp": 1585607917.8103523, "_step": 144}
{"Episode reward": -99.73807611178933, "Episode length": 999, "Policy Loss": -0.8903177976608276, "Value Loss": 0.3543795347213745, "_runtime": 10549.745175600052, "_timestamp": 1585607919.378045, "_step": 145}
{"Episode reward": -99.83270190749177, "Episode length": 999, "Policy Loss": -0.9699110388755798, "Value Loss": 0.1656229943037033, "_runtime": 10551.006518125534, "_timestamp": 1585607920.6393876, "_step": 146}
{"Episode reward": 18.800000000000338, "Episode length": 812, "Policy Loss": -0.08134956657886505, "Value Loss": 12.386809349060059, "_runtime": 10552.116723537445, "_timestamp": 1585607921.749593, "_step": 147}
{"Episode reward": 28.90782132204599, "Episode length": 712, "Policy Loss": 0.17306111752986908, "Value Loss": 14.634486198425293, "_runtime": 10553.6804292202, "_timestamp": 1585607923.3132987, "_step": 148}
{"Episode reward": -99.80674174290476, "Episode length": 999, "Policy Loss": -0.7601735591888428, "Value Loss": 0.021089792251586914, "_runtime": 10554.181188821793, "_timestamp": 1585607923.8140583, "_step": 149}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 2.407836675643921, "Value Loss": 32.552581787109375, "_runtime": 10555.733142614365, "_timestamp": 1585607925.366012, "_step": 150}
{"Episode reward": -99.8741413072669, "Episode length": 999, "Policy Loss": -0.5183413028717041, "Value Loss": 0.01271953247487545, "_runtime": 10557.33011507988, "_timestamp": 1585607926.9629846, "_step": 151}
{"Episode reward": -99.76214798409352, "Episode length": 999, "Policy Loss": -0.4514175355434418, "Value Loss": 0.038816675543785095, "_runtime": 10558.836727380753, "_timestamp": 1585607928.4695969, "_step": 152}
{"Episode reward": -99.66581962313364, "Episode length": 999, "Policy Loss": -0.3700940012931824, "Value Loss": 0.07179781794548035, "_runtime": 10560.42969584465, "_timestamp": 1585607930.0625653, "_step": 153}
{"Episode reward": -99.61903325908212, "Episode length": 999, "Policy Loss": -0.34714147448539734, "Value Loss": 0.08030842989683151, "_runtime": 10561.206686258316, "_timestamp": 1585607930.8395557, "_step": 154}
{"Episode reward": 53.127895233756476, "Episode length": 471, "Policy Loss": 1.039963722229004, "Value Loss": 20.74421501159668, "_runtime": 10561.686054229736, "_timestamp": 1585607931.3189237, "_step": 155}
{"Episode reward": 70.99999999999986, "Episode length": 290, "Policy Loss": 1.8927760124206543, "Value Loss": 33.3994026184082, "_runtime": 10563.263006448746, "_timestamp": 1585607932.895876, "_step": 156}
{"Episode reward": -99.67812120634925, "Episode length": 999, "Policy Loss": -0.304344117641449, "Value Loss": 0.23235268890857697, "_runtime": 10564.804067134857, "_timestamp": 1585607934.4369366, "_step": 157}
{"Episode reward": -99.74553951085406, "Episode length": 999, "Policy Loss": -0.3717605471611023, "Value Loss": 0.14045198261737823, "_runtime": 10566.357947587967, "_timestamp": 1585607935.990817, "_step": 158}
{"Episode reward": -99.61623693164299, "Episode length": 999, "Policy Loss": -0.3650916516780853, "Value Loss": 0.17554882168769836, "_runtime": 10567.941490411758, "_timestamp": 1585607937.57436, "_step": 159}
{"Episode reward": -99.87423593560094, "Episode length": 999, "Policy Loss": -0.35711967945098877, "Value Loss": 0.17711226642131805, "_runtime": 10569.057953357697, "_timestamp": 1585607938.6908228, "_step": 160}
{"Episode reward": 30.266533573995957, "Episode length": 699, "Policy Loss": 0.6611284017562866, "Value Loss": 13.87152099609375, "_runtime": 10570.04616522789, "_timestamp": 1585607939.6790347, "_step": 161}
{"Episode reward": 37.200911068985555, "Episode length": 630, "Policy Loss": 0.7388821840286255, "Value Loss": 15.406778335571289, "_runtime": 10570.593751907349, "_timestamp": 1585607940.2266214, "_step": 162}
{"Episode reward": 68.41793012486288, "Episode length": 318, "Policy Loss": 2.441253423690796, "Value Loss": 30.0693302154541, "_runtime": 10572.145805358887, "_timestamp": 1585607941.7786748, "_step": 163}
{"Episode reward": -99.87091872626776, "Episode length": 999, "Policy Loss": -0.3483507037162781, "Value Loss": 0.002975018694996834, "_runtime": 10573.013703584671, "_timestamp": 1585607942.646573, "_step": 164}
{"Episode reward": 44.21173693258264, "Episode length": 560, "Policy Loss": 1.0134351253509521, "Value Loss": 16.881141662597656, "_runtime": 10574.522455215454, "_timestamp": 1585607944.1553247, "_step": 165}
{"Episode reward": -99.80156135579897, "Episode length": 999, "Policy Loss": -0.262000173330307, "Value Loss": 0.043186161667108536, "_runtime": 10575.371711492538, "_timestamp": 1585607945.004581, "_step": 166}
{"Episode reward": 48.06335553973867, "Episode length": 520, "Policy Loss": 1.0803823471069336, "Value Loss": 19.050504684448242, "_runtime": 10576.928511619568, "_timestamp": 1585607946.561381, "_step": 167}
{"Episode reward": -99.82948811678077, "Episode length": 999, "Policy Loss": -0.3390205204486847, "Value Loss": 0.021089721471071243, "_runtime": 10578.502065896988, "_timestamp": 1585607948.1349354, "_step": 168}
{"Episode reward": -99.60791546786065, "Episode length": 999, "Policy Loss": -0.43530505895614624, "Value Loss": 0.06839205324649811, "_runtime": 10579.276092529297, "_timestamp": 1585607948.908962, "_step": 169}
{"Episode reward": 51.055292036756455, "Episode length": 490, "Policy Loss": 0.9288075566291809, "Value Loss": 19.228683471679688, "_runtime": 10580.865389347076, "_timestamp": 1585607950.4982588, "_step": 170}
{"Episode reward": -99.8330323250019, "Episode length": 999, "Policy Loss": -0.5856443047523499, "Value Loss": 0.22867721319198608, "_runtime": 10582.444381952286, "_timestamp": 1585607952.0772514, "_step": 171}
{"Episode reward": -99.44083078999401, "Episode length": 999, "Policy Loss": -0.5617976784706116, "Value Loss": 0.03607284650206566, "_runtime": 10583.527776479721, "_timestamp": 1585607953.160646, "_step": 172}
{"Episode reward": 29.91984828328684, "Episode length": 702, "Policy Loss": 0.49942436814308167, "Value Loss": 13.520395278930664, "_runtime": 10585.100558519363, "_timestamp": 1585607954.733428, "_step": 173}
{"Episode reward": -99.70211899475986, "Episode length": 999, "Policy Loss": -0.45091769099235535, "Value Loss": 0.7343758940696716, "_runtime": 10585.698085784912, "_timestamp": 1585607955.3309553, "_step": 174}
{"Episode reward": 64.49999999999977, "Episode length": 355, "Policy Loss": 1.3785016536712646, "Value Loss": 26.024532318115234, "_runtime": 10587.027166366577, "_timestamp": 1585607956.6600358, "_step": 175}
{"Episode reward": 14.142470195424423, "Episode length": 859, "Policy Loss": 0.3419065475463867, "Value Loss": 11.330913543701172, "_runtime": 10587.825824975967, "_timestamp": 1585607957.4586945, "_step": 176}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 1.0347816944122314, "Value Loss": 19.5634822845459, "_runtime": 10589.351709604263, "_timestamp": 1585607958.984579, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5681167840957642, "Value Loss": 0.14571240544319153, "_runtime": 10590.94783949852, "_timestamp": 1585607960.580709, "_step": 178}
{"Episode reward": -99.69004928574293, "Episode length": 999, "Policy Loss": -0.5869044065475464, "Value Loss": 0.025514544919133186, "_runtime": 10592.483495235443, "_timestamp": 1585607962.1163647, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6380702257156372, "Value Loss": 0.06316236406564713, "_runtime": 10594.06163907051, "_timestamp": 1585607963.6945086, "_step": 180}
{"Episode reward": -99.67948682219583, "Episode length": 999, "Policy Loss": -0.6371486783027649, "Value Loss": 0.03316020593047142, "_runtime": 10595.652263641357, "_timestamp": 1585607965.2851331, "_step": 181}
{"Episode reward": -99.74708087751502, "Episode length": 999, "Policy Loss": -0.6774141192436218, "Value Loss": 0.06996477395296097, "_runtime": 10596.317972660065, "_timestamp": 1585607965.9508421, "_step": 182}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.326521396636963, "Value Loss": 24.69078826904297, "_runtime": 10597.90587568283, "_timestamp": 1585607967.5387452, "_step": 183}
{"Episode reward": -99.70202108267556, "Episode length": 999, "Policy Loss": -0.7121410965919495, "Value Loss": 0.11768729239702225, "_runtime": 10599.501822948456, "_timestamp": 1585607969.1346924, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6986339092254639, "Value Loss": 0.019393013790249825, "_runtime": 10599.969317436218, "_timestamp": 1585607969.602187, "_step": 185}
{"Episode reward": 70.50956784030409, "Episode length": 295, "Policy Loss": 1.809279441833496, "Value Loss": 33.16160583496094, "_runtime": 10601.5473818779, "_timestamp": 1585607971.1802514, "_step": 186}
{"Episode reward": -99.79168202150473, "Episode length": 999, "Policy Loss": -0.7214579582214355, "Value Loss": 0.014040425419807434, "_runtime": 10603.14292883873, "_timestamp": 1585607972.7757983, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.745175838470459, "Value Loss": 0.015414079651236534, "_runtime": 10604.66024851799, "_timestamp": 1585607974.293118, "_step": 188}
{"Episode reward": -99.6670885425047, "Episode length": 999, "Policy Loss": -0.7582488059997559, "Value Loss": 0.027887245640158653, "_runtime": 10606.232675552368, "_timestamp": 1585607975.865545, "_step": 189}
{"Episode reward": -99.80167074242932, "Episode length": 999, "Policy Loss": -0.7303648591041565, "Value Loss": 0.10900544375181198, "_runtime": 10607.83139181137, "_timestamp": 1585607977.4642613, "_step": 190}
{"Episode reward": -99.61056365622069, "Episode length": 999, "Policy Loss": -0.7198415994644165, "Value Loss": 0.19668588042259216, "_runtime": 10609.402956724167, "_timestamp": 1585607979.0358262, "_step": 191}
{"Episode reward": -99.69224308628917, "Episode length": 999, "Policy Loss": -0.7637748122215271, "Value Loss": 0.022554825991392136, "_runtime": 10610.99265575409, "_timestamp": 1585607980.6255252, "_step": 192}
{"Episode reward": -99.81423353387369, "Episode length": 999, "Policy Loss": -0.7428510785102844, "Value Loss": 0.06062569096684456, "_runtime": 10612.580135583878, "_timestamp": 1585607982.213005, "_step": 193}
{"Episode reward": -99.80130827575782, "Episode length": 999, "Policy Loss": -0.7423921227455139, "Value Loss": 0.0170527882874012, "_runtime": 10613.71583867073, "_timestamp": 1585607983.3487082, "_step": 194}
{"Episode reward": 31.105240810196477, "Episode length": 691, "Policy Loss": 0.22465921938419342, "Value Loss": 13.600345611572266, "_runtime": 10614.350255727768, "_timestamp": 1585607983.9831252, "_step": 195}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 1.0422366857528687, "Value Loss": 24.485172271728516, "_runtime": 10615.433127641678, "_timestamp": 1585607985.0659971, "_step": 196}
{"Episode reward": 32.17527086874428, "Episode length": 679, "Policy Loss": 0.26265349984169006, "Value Loss": 13.964076042175293, "_runtime": 10616.987516403198, "_timestamp": 1585607986.620386, "_step": 197}
{"Episode reward": -99.75841234775586, "Episode length": 999, "Policy Loss": -0.7615206837654114, "Value Loss": 0.018411124125123024, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612, 0.21038788557052612]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.21038788557052612, 0.11078974604606628, 0.4319673776626587, 0.7531450390815735, 1.0743227005004883, 1.3955001831054688, 1.7166779041290283, 2.037855386734009, 2.3590331077575684, 2.680210828781128, 3.0013883113861084, 3.322566032409668, 3.6437437534332275, 3.964921236038208, 4.286098957061768, 4.607276916503906, 4.928454399108887, 5.249631881713867, 5.570809841156006, 5.891987323760986, 6.213164806365967, 6.5343427658081055, 6.855520248413086, 7.176697731018066, 7.497875690460205, 7.8190531730651855, 8.140230178833008, 8.461407661437988, 8.782585144042969, 9.103763580322266, 9.424941062927246, 9.746118545532227, 10.067296028137207, 10.388473510742188, 10.709650993347168, 11.030828475952148, 11.352006912231445, 11.673184394836426, 11.994361877441406, 12.315539360046387, 12.636716842651367, 12.957894325256348, 13.279072761535645, 13.600250244140625, 13.921427726745605, 14.242605209350586, 14.563782691955566, 14.884960174560547, 15.206138610839844, 15.527316093444824, 15.848493576049805, 16.16967010498047, 16.490848541259766, 16.812026977539062, 17.133203506469727, 17.454381942749023, 17.775558471679688, 18.096736907958984, 18.41791534423828, 18.739091873168945, 19.060270309448242, 19.381446838378906, 19.702625274658203, 20.023801803588867, 20.344980239868164]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0015576828736811876, 0.00612696073949337, 0.013811604119837284, 0.02149624563753605, 0.029180889949202538, 0.036865536123514175, 0.044550176709890366, 0.052234821021556854, 0.05991946533322334, 0.06760410219430923, 0.07528875023126602, 0.08297339081764221, 0.0906580314040184, 0.09834267944097519, 0.10602732002735138, 0.11371196806430817, 0.12139660865068436, 0.12908126413822174, 0.13676589727401733, 0.14445054531097412, 0.1521351933479309, 0.1598198264837265, 0.1675044745206833, 0.17518912255764008, 0.18287375569343567, 0.19055840373039246, 0.19824305176734924, 0.20592769980430603, 0.21361233294010162, 0.2212969809770584, 0.2289816290140152, 0.2366662621498108, 0.24435091018676758, 0.25203555822372437, 0.25972020626068115, 0.26740485429763794, 0.27508947253227234, 0.2827741205692291, 0.2904587686061859, 0.2981434166431427, 0.3058280646800995, 0.3135127127170563, 0.3211973309516907, 0.32888197898864746, 0.33656662702560425, 0.34425127506256104, 0.3519359230995178, 0.3596205711364746, 0.367305189371109, 0.3749898374080658, 0.3826744854450226, 0.39035913348197937, 0.39804378151893616, 0.40572842955589294, 0.41341307759284973, 0.42109769582748413, 0.4287823438644409, 0.4364669919013977, 0.4441516399383545, 0.4518362879753113, 0.45952093601226807, 0.46720555424690247, 0.47489020228385925, 0.48257485032081604, 0.4902594983577728]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 4.0, 5.0, 7.0, 8.0, 2.0, 9.0, 27.0, 48.0, 200.0, 32.0, 32.0, 11.0, 13.0, 5.0, 2.0, 5.0, 4.0, 6.0, 10.0, 3.0, 5.0, 5.0, 4.0, 4.0, 6.0, 2.0, 7.0, 1.0, 5.0, 1.0, 4.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.40184304118156433, -0.3752068877220154, -0.3485707640647888, -0.32193464040756226, -0.2952984869480133, -0.26866233348846436, -0.2420262098312378, -0.21539007127285004, -0.18875393271446228, -0.16211779415607452, -0.13548165559768677, -0.10884550213813782, -0.08220937848091125, -0.05557325482368469, -0.028937101364135742, -0.002300947904586792, 0.02433517575263977, 0.05097129940986633, 0.07760745286941528, 0.10424360632896423, 0.1308797299861908, 0.15751585364341736, 0.1841520369052887, 0.21078816056251526, 0.23742428421974182, 0.2640604078769684, 0.29069653153419495, 0.3173327147960663, 0.34396883845329285, 0.3706049621105194, 0.39724114537239075, 0.4238772690296173, 0.45051339268684387, 0.47714951634407043, 0.5037856101989746, 0.5304218530654907, 0.5570579767227173, 0.5836941003799438, 0.6103302240371704, 0.636966347694397, 0.6636024713516235, 0.6902385950088501, 0.7168747186660767, 0.7435108423233032, 0.7701470851898193, 0.7967832088470459, 0.8234193325042725, 0.850055456161499, 0.8766915798187256, 0.9033277034759521, 0.9299638271331787, 0.9565999507904053, 0.9832360744476318, 1.009872317314148, 1.0365084409713745, 1.063144564628601, 1.0897806882858276, 1.1164168119430542, 1.1430529356002808, 1.1696890592575073, 1.1963253021240234, 1.22296142578125, 1.2495975494384766, 1.2762336730957031, 1.3028697967529297]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-1.1667144298553467, -1.0821802616119385, -0.997646152973175, -0.9131120443344116, -0.8285778760910034, -0.7440437078475952, -0.6595095992088318, -0.5749754905700684, -0.49044132232666016, -0.40590715408325195, -0.3213730454444885, -0.2368389368057251, -0.1523047685623169, -0.06777060031890869, 0.01676344871520996, 0.10129761695861816, 0.18583178520202637, 0.27036595344543457, 0.3549001216888428, 0.4394341707229614, 0.5239683389663696, 0.6085025072097778, 0.6930365562438965, 0.7775707244873047, 0.8621048927307129, 0.9466390609741211, 1.0311732292175293, 1.1157073974609375, 1.2002413272857666, 1.2847754955291748, 1.369309663772583, 1.4538438320159912, 1.5383780002593994, 1.6229121685028076, 1.7074463367462158, 1.791980504989624, 1.8765146732330322, 1.9610486030578613, 2.0455827713012695, 2.1301169395446777, 2.214651107788086, 2.299185276031494, 2.3837194442749023, 2.4682536125183105, 2.5527875423431396, 2.637321710586548, 2.721855878829956, 2.8063900470733643, 2.8909242153167725, 2.9754583835601807, 3.059992551803589, 3.144526720046997, 3.2290608882904053, 3.3135950565338135, 3.3981292247772217, 3.48266339302063, 3.56719708442688, 3.651731252670288, 3.7362654209136963, 3.8207995891571045, 3.9053337574005127, 3.989867925643921, 4.07440185546875, 4.158936500549316, 4.243470191955566]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 6.0, 7.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.87443608045578, -0.826045036315918, -0.7776539325714111, -0.7292628288269043, -0.6808717846870422, -0.6324807405471802, -0.5840896368026733, -0.5356985330581665, -0.48730748891830444, -0.43891641497612, -0.39052534103393555, -0.3421342968940735, -0.29374319314956665, -0.24535208940505981, -0.19696104526519775, -0.1485700011253357, -0.10017889738082886, -0.05178779363632202, -0.003396749496459961, 0.0449942946434021, 0.09338539838790894, 0.14177650213241577, 0.19016748666763306, 0.2385585904121399, 0.28694969415664673, 0.33534079790115356, 0.3837319016456604, 0.4321228861808777, 0.4805139899253845, 0.5289050936698914, 0.5772960782051086, 0.6256871819496155, 0.6740782856941223, 0.7224693894386292, 0.770860493183136, 0.8192514777183533, 0.8676425814628601, 0.9160336852073669, 0.9644246697425842, 1.0128157138824463, 1.0612068176269531, 1.10959792137146, 1.1579890251159668, 1.2063801288604736, 1.2547709941864014, 1.3031620979309082, 1.351553201675415, 1.3999443054199219, 1.4483354091644287, 1.4967265129089355, 1.5451176166534424, 1.5935087203979492, 1.641899824142456, 1.6902906894683838, 1.7386817932128906, 1.7870728969573975, 1.8354640007019043, 1.8838551044464111, 1.932246208190918, 1.9806373119354248, 2.0290281772613525, 2.0774192810058594, 2.125810384750366, 2.174201488494873, 2.22259259223938]}, "_runtime": 10617.97431063652, "_timestamp": 1585607987.60718, "_step": 198}
{"Episode reward": 35.899999999999366, "Episode length": 641, "Policy Loss": 0.30402278900146484, "Value Loss": 14.89074420928955, "_runtime": 10619.528825998306, "_timestamp": 1585607989.1616955, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7613599896430969, "Value Loss": 0.01609303057193756, "_runtime": 10621.116914510727, "_timestamp": 1585607990.749784, "_step": 200}
{"Episode reward": -99.58888388089697, "Episode length": 999, "Policy Loss": -0.7359299659729004, "Value Loss": 0.015678085386753082, "_runtime": 10622.6481051445, "_timestamp": 1585607992.2809746, "_step": 201}
{"Episode reward": -99.62488336388348, "Episode length": 999, "Policy Loss": -0.7268646359443665, "Value Loss": 0.022222453728318214, "_runtime": 10624.238826274872, "_timestamp": 1585607993.8716958, "_step": 202}
{"Episode reward": -99.79240202207446, "Episode length": 999, "Policy Loss": -0.7247409820556641, "Value Loss": 0.06490558385848999, "_runtime": 10625.570423841476, "_timestamp": 1585607995.2032933, "_step": 203}
{"Episode reward": 16.12104215351914, "Episode length": 840, "Policy Loss": 0.047071173787117004, "Value Loss": 10.794322967529297, "_runtime": 10626.804275512695, "_timestamp": 1585607996.437145, "_step": 204}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 0.04511626809835434, "Value Loss": 11.408445358276367, "_runtime": 10628.395743370056, "_timestamp": 1585607998.0286129, "_step": 205}
{"Episode reward": -99.65787203553924, "Episode length": 999, "Policy Loss": -0.7477121353149414, "Value Loss": 0.031174002215266228, "_runtime": 10629.967685699463, "_timestamp": 1585607999.6005552, "_step": 206}
{"Episode reward": -99.73032446587318, "Episode length": 999, "Policy Loss": -0.8108099102973938, "Value Loss": 0.09219459444284439, "_runtime": 10630.49975848198, "_timestamp": 1585608000.132628, "_step": 207}
{"Episode reward": 68.29817970758286, "Episode length": 318, "Policy Loss": 1.7397725582122803, "Value Loss": 30.151119232177734, "_runtime": 10632.080918312073, "_timestamp": 1585608001.7137878, "_step": 208}
{"Episode reward": -99.79815390650043, "Episode length": 999, "Policy Loss": -0.6712740659713745, "Value Loss": 0.0531226247549057, "_runtime": 10633.667736530304, "_timestamp": 1585608003.300606, "_step": 209}
{"Episode reward": -99.82919389167661, "Episode length": 999, "Policy Loss": -0.5832724571228027, "Value Loss": 0.15687616169452667, "_runtime": 10634.189318180084, "_timestamp": 1585608003.8221877, "_step": 210}
{"Episode reward": 66.9999999999998, "Episode length": 330, "Policy Loss": 1.7522636651992798, "Value Loss": 29.057342529296875, "_runtime": 10635.778101205826, "_timestamp": 1585608005.4109707, "_step": 211}
{"Episode reward": -99.6771933139288, "Episode length": 999, "Policy Loss": -0.5638259053230286, "Value Loss": 0.07481234520673752, "_runtime": 10637.375435829163, "_timestamp": 1585608007.0083053, "_step": 212}
{"Episode reward": -99.80982962569549, "Episode length": 999, "Policy Loss": -0.5890740156173706, "Value Loss": 0.031794145703315735, "_runtime": 10638.361491918564, "_timestamp": 1585608007.9943614, "_step": 213}
{"Episode reward": 37.033058759196976, "Episode length": 630, "Policy Loss": 0.43117642402648926, "Value Loss": 15.032125473022461, "_runtime": 10639.531741142273, "_timestamp": 1585608009.1646106, "_step": 214}
{"Episode reward": 26.658915470144606, "Episode length": 735, "Policy Loss": 0.21315577626228333, "Value Loss": 12.476761817932129, "_runtime": 10640.351234674454, "_timestamp": 1585608009.9841042, "_step": 215}
{"Episode reward": 49.989436706527634, "Episode length": 501, "Policy Loss": 0.8438556790351868, "Value Loss": 18.66241455078125, "_runtime": 10641.89225935936, "_timestamp": 1585608011.5251288, "_step": 216}
{"Episode reward": -99.64321066208511, "Episode length": 999, "Policy Loss": -0.7530879378318787, "Value Loss": 0.022478288039565086, "_runtime": 10642.31141424179, "_timestamp": 1585608011.9442837, "_step": 217}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 1.920693039894104, "Value Loss": 39.51030349731445, "_runtime": 10643.861512422562, "_timestamp": 1585608013.494382, "_step": 218}
{"Episode reward": -99.8000492230975, "Episode length": 999, "Policy Loss": -0.7071760296821594, "Value Loss": 0.031243445351719856, "_runtime": 10645.442083835602, "_timestamp": 1585608015.0749533, "_step": 219}
{"Episode reward": -99.79343586116889, "Episode length": 999, "Policy Loss": -0.6277056932449341, "Value Loss": 0.02454751916229725, "_runtime": 10646.626010417938, "_timestamp": 1585608016.25888, "_step": 220}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.35184600949287415, "Value Loss": 11.701201438903809, "_runtime": 10648.218387842178, "_timestamp": 1585608017.8512573, "_step": 221}
{"Episode reward": -99.7410587611827, "Episode length": 999, "Policy Loss": -0.5278208255767822, "Value Loss": 0.13237959146499634, "_runtime": 10649.791559457779, "_timestamp": 1585608019.424429, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5116835832595825, "Value Loss": 0.10270757973194122, "_runtime": 10651.333579301834, "_timestamp": 1585608020.9664488, "_step": 223}
{"Episode reward": -99.8176770360195, "Episode length": 999, "Policy Loss": -0.4954187870025635, "Value Loss": 0.09103106707334518, "_runtime": 10652.470807790756, "_timestamp": 1585608022.1036773, "_step": 224}
{"Episode reward": 29.483248339406884, "Episode length": 707, "Policy Loss": 0.4320589005947113, "Value Loss": 12.96566390991211, "_runtime": 10654.057144880295, "_timestamp": 1585608023.6900144, "_step": 225}
{"Episode reward": -99.81665550554031, "Episode length": 999, "Policy Loss": -0.5144099593162537, "Value Loss": 0.016709038987755775, "_runtime": 10655.643719673157, "_timestamp": 1585608025.2765892, "_step": 226}
{"Episode reward": -99.75607857573638, "Episode length": 999, "Policy Loss": -0.5287407636642456, "Value Loss": 0.023902112618088722, "_runtime": 10657.223024129868, "_timestamp": 1585608026.8558936, "_step": 227}
{"Episode reward": -99.70577688906202, "Episode length": 999, "Policy Loss": -0.54716557264328, "Value Loss": 0.006740107666701078, "_runtime": 10658.373114824295, "_timestamp": 1585608028.0059843, "_step": 228}
{"Episode reward": 28.75870457447577, "Episode length": 715, "Policy Loss": 0.32706451416015625, "Value Loss": 12.734769821166992, "_runtime": 10659.785362482071, "_timestamp": 1585608029.418232, "_step": 229}
{"Episode reward": 10.28792305996258, "Episode length": 898, "Policy Loss": 0.24133671820163727, "Value Loss": 10.56031322479248, "_runtime": 10661.41577911377, "_timestamp": 1585608031.0486486, "_step": 230}
{"Episode reward": -99.81736789345601, "Episode length": 999, "Policy Loss": -0.5527202486991882, "Value Loss": 0.13865838944911957, "_runtime": 10662.483938694, "_timestamp": 1585608032.1168082, "_step": 231}
{"Episode reward": 32.599999999999554, "Episode length": 674, "Policy Loss": 0.569760262966156, "Value Loss": 12.931017875671387, "_runtime": 10662.861001968384, "_timestamp": 1585608032.4938715, "_step": 232}
{"Episode reward": 79.19999999999999, "Episode length": 208, "Policy Loss": 2.6392171382904053, "Value Loss": 40.60276412963867, "_runtime": 10664.443372011185, "_timestamp": 1585608034.0762415, "_step": 233}
{"Episode reward": -99.73934570625285, "Episode length": 999, "Policy Loss": -0.5608707070350647, "Value Loss": 0.018792754039168358, "_runtime": 10665.387466430664, "_timestamp": 1585608035.020336, "_step": 234}
{"Episode reward": 39.795978731568326, "Episode length": 603, "Policy Loss": 0.46749863028526306, "Value Loss": 14.372264862060547, "_runtime": 10666.893331766129, "_timestamp": 1585608036.5262012, "_step": 235}
{"Episode reward": -99.81396881500119, "Episode length": 999, "Policy Loss": -0.570505678653717, "Value Loss": 0.022256765514612198, "_runtime": 10668.482249975204, "_timestamp": 1585608038.1151195, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5885205864906311, "Value Loss": 0.06332600861787796, "_runtime": 10670.028193235397, "_timestamp": 1585608039.6610627, "_step": 237}
{"Episode reward": -99.62372494619203, "Episode length": 999, "Policy Loss": -0.6103440523147583, "Value Loss": 0.11315427720546722, "_runtime": 10670.931550979614, "_timestamp": 1585608040.5644205, "_step": 238}
{"Episode reward": 42.51706283064505, "Episode length": 577, "Policy Loss": 0.7841378450393677, "Value Loss": 17.408174514770508, "_runtime": 10672.436603546143, "_timestamp": 1585608042.069473, "_step": 239}
{"Episode reward": 5.72649115359053, "Episode length": 946, "Policy Loss": 0.20778733491897583, "Value Loss": 9.351141929626465, "_runtime": 10674.010573625565, "_timestamp": 1585608043.643443, "_step": 240}
{"Episode reward": -99.7540077742408, "Episode length": 999, "Policy Loss": -0.4290478527545929, "Value Loss": 0.19651441276073456, "_runtime": 10675.376780986786, "_timestamp": 1585608045.0096505, "_step": 241}
{"Episode reward": 11.299283598527154, "Episode length": 888, "Policy Loss": 0.315362811088562, "Value Loss": 11.309038162231445, "_runtime": 10676.609853506088, "_timestamp": 1585608046.242723, "_step": 242}
{"Episode reward": 22.558052477240693, "Episode length": 775, "Policy Loss": 0.4062318801879883, "Value Loss": 12.147930145263672, "_runtime": 10677.273839950562, "_timestamp": 1585608046.9067094, "_step": 243}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.095703363418579, "Value Loss": 23.561433792114258, "_runtime": 10678.841185569763, "_timestamp": 1585608048.474055, "_step": 244}
{"Episode reward": -99.71377772712009, "Episode length": 999, "Policy Loss": -0.6363199353218079, "Value Loss": 0.03131071850657463, "_runtime": 10680.073726892471, "_timestamp": 1585608049.7065964, "_step": 245}
{"Episode reward": 22.271536889299895, "Episode length": 778, "Policy Loss": 0.21513886749744415, "Value Loss": 11.287955284118652, "_runtime": 10681.605520486832, "_timestamp": 1585608051.23839, "_step": 246}
{"Episode reward": -99.76842048794357, "Episode length": 999, "Policy Loss": -0.8645907640457153, "Value Loss": 0.02354234643280506, "_runtime": 10683.182053804398, "_timestamp": 1585608052.8149233, "_step": 247}
{"Episode reward": 0.8808642308241303, "Episode length": 993, "Policy Loss": -0.3000902235507965, "Value Loss": 8.848475456237793, "_runtime": 10684.30741906166, "_timestamp": 1585608053.9402885, "_step": 248}
{"Episode reward": 29.141629243548707, "Episode length": 709, "Policy Loss": -0.16238078474998474, "Value Loss": 12.678884506225586, "_runtime": 10685.14646267891, "_timestamp": 1585608054.7793322, "_step": 249}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 0.055662527680397034, "Value Loss": 16.126235961914062, "_runtime": 10686.752513885498, "_timestamp": 1585608056.3853834, "_step": 250}
{"Episode reward": -99.70363790721028, "Episode length": 999, "Policy Loss": -1.1866683959960938, "Value Loss": 0.15612412989139557, "_runtime": 10688.329054832458, "_timestamp": 1585608057.9619243, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1907283067703247, "Value Loss": 0.08865739405155182, "_runtime": 10689.86463046074, "_timestamp": 1585608059.4975, "_step": 252}
{"Episode reward": -99.89951231479505, "Episode length": 999, "Policy Loss": -1.202532410621643, "Value Loss": 0.054575394839048386, "_runtime": 10690.654336690903, "_timestamp": 1585608060.2872062, "_step": 253}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": 0.09712071716785431, "Value Loss": 18.58360481262207, "_runtime": 10691.053138256073, "_timestamp": 1585608060.6860077, "_step": 254}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 1.970996618270874, "Value Loss": 40.43125915527344, "_runtime": 10692.632066488266, "_timestamp": 1585608062.264936, "_step": 255}
{"Episode reward": -99.8770653370754, "Episode length": 999, "Policy Loss": -1.2013522386550903, "Value Loss": 0.4448007345199585, "_runtime": 10693.458639860153, "_timestamp": 1585608063.0915093, "_step": 256}
{"Episode reward": 47.2998761042715, "Episode length": 528, "Policy Loss": 0.24909290671348572, "Value Loss": 18.10284423828125, "_runtime": 10694.965732097626, "_timestamp": 1585608064.5986016, "_step": 257}
{"Episode reward": -99.62676584767038, "Episode length": 999, "Policy Loss": -0.7894545793533325, "Value Loss": 0.012941352091729641, "_runtime": 10696.555609464645, "_timestamp": 1585608066.188479, "_step": 258}
{"Episode reward": -99.89343421794335, "Episode length": 999, "Policy Loss": -0.5582954287528992, "Value Loss": 0.36348477005958557, "_runtime": 10697.305591106415, "_timestamp": 1585608066.9384606, "_step": 259}
{"Episode reward": 51.49999999999959, "Episode length": 485, "Policy Loss": 1.0651044845581055, "Value Loss": 20.28377914428711, "_runtime": 10698.329044818878, "_timestamp": 1585608067.9619143, "_step": 260}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.7203185558319092, "Value Loss": 14.673702239990234, "_runtime": 10699.923792600632, "_timestamp": 1585608069.556662, "_step": 261}
{"Episode reward": -99.80290344210668, "Episode length": 999, "Policy Loss": -0.37716421484947205, "Value Loss": 0.028762388974428177, "_runtime": 10701.462678194046, "_timestamp": 1585608071.0955477, "_step": 262}
{"Episode reward": -99.72217697112215, "Episode length": 999, "Policy Loss": -0.3611827790737152, "Value Loss": 0.11471343040466309, "_runtime": 10702.993483066559, "_timestamp": 1585608072.6263525, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4521463215351105, "Value Loss": 0.40022292733192444, "_runtime": 10704.119004011154, "_timestamp": 1585608073.7518735, "_step": 264}
{"Episode reward": 30.099999999999696, "Episode length": 699, "Policy Loss": 0.661076545715332, "Value Loss": 14.167309761047363, "_runtime": 10705.70144534111, "_timestamp": 1585608075.3343148, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16190823912620544, "Value Loss": 0.001058769878000021, "_runtime": 10706.078143119812, "_timestamp": 1585608075.7110126, "_step": 266}
{"Episode reward": 79.62912238752467, "Episode length": 204, "Policy Loss": 3.09116792678833, "Value Loss": 47.36881637573242, "_runtime": 10707.645574092865, "_timestamp": 1585608077.2784436, "_step": 267}
{"Episode reward": -99.68217841910526, "Episode length": 999, "Policy Loss": 0.04907305911183357, "Value Loss": 0.43199393153190613, "_runtime": 10709.23567533493, "_timestamp": 1585608078.8685448, "_step": 268}
{"Episode reward": -99.53981300531748, "Episode length": 999, "Policy Loss": -0.011876897886395454, "Value Loss": 0.2147027999162674, "_runtime": 10710.14459824562, "_timestamp": 1585608079.7774677, "_step": 269}
{"Episode reward": 42.57623352473548, "Episode length": 576, "Policy Loss": 1.3982428312301636, "Value Loss": 17.327537536621094, "_runtime": 10710.909437179565, "_timestamp": 1585608080.5423067, "_step": 270}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 1.1984765529632568, "Value Loss": 20.41570281982422, "_runtime": 10712.501732349396, "_timestamp": 1585608082.1346018, "_step": 271}
{"Episode reward": -99.72103653375386, "Episode length": 999, "Policy Loss": -0.4045189917087555, "Value Loss": 0.031138518825173378, "_runtime": 10712.877064704895, "_timestamp": 1585608082.5099342, "_step": 272}
{"Episode reward": 77.07802734374995, "Episode length": 230, "Policy Loss": 2.459798574447632, "Value Loss": 41.08864212036133, "_runtime": 10713.555993795395, "_timestamp": 1585608083.1888633, "_step": 273}
{"Episode reward": 56.21949700023944, "Episode length": 439, "Policy Loss": 1.2714569568634033, "Value Loss": 23.42164421081543, "_runtime": 10715.142692804337, "_timestamp": 1585608084.7755623, "_step": 274}
{"Episode reward": -99.6420815428705, "Episode length": 999, "Policy Loss": -0.4169544577598572, "Value Loss": 0.011904876679182053, "_runtime": 10716.654870986938, "_timestamp": 1585608086.2877405, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3349096477031708, "Value Loss": 0.12258341908454895, "_runtime": 10718.187569618225, "_timestamp": 1585608087.820439, "_step": 276}
{"Episode reward": -99.74853636212508, "Episode length": 999, "Policy Loss": -0.37140512466430664, "Value Loss": 0.19956514239311218, "_runtime": 10718.69923877716, "_timestamp": 1585608088.3321083, "_step": 277}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 1.8456803560256958, "Value Loss": 32.55523681640625, "_runtime": 10719.200908899307, "_timestamp": 1585608088.8337784, "_step": 278}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 1.8364801406860352, "Value Loss": 32.15462112426758, "_runtime": 10720.771349430084, "_timestamp": 1585608090.404219, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.578445315361023, "Value Loss": 0.008939852006733418, "_runtime": 10722.298192739487, "_timestamp": 1585608091.9310622, "_step": 280}
{"Episode reward": -99.83385650201095, "Episode length": 999, "Policy Loss": -0.7277695536613464, "Value Loss": 0.03310646861791611, "_runtime": 10723.640464305878, "_timestamp": 1585608093.2733338, "_step": 281}
{"Episode reward": 11.783964951406972, "Episode length": 885, "Policy Loss": 0.0815858468413353, "Value Loss": 11.01900577545166, "_runtime": 10725.225596904755, "_timestamp": 1585608094.8584664, "_step": 282}
{"Episode reward": -99.87982763731712, "Episode length": 999, "Policy Loss": -0.8617522716522217, "Value Loss": 0.10503538697957993, "_runtime": 10725.731663227081, "_timestamp": 1585608095.3645327, "_step": 283}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 1.4985700845718384, "Value Loss": 31.73233985900879, "_runtime": 10726.70317029953, "_timestamp": 1585608096.3360398, "_step": 284}
{"Episode reward": 37.51735713919564, "Episode length": 627, "Policy Loss": 0.22155408561229706, "Value Loss": 15.174307823181152, "_runtime": 10728.29281115532, "_timestamp": 1585608097.9256806, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8162674307823181, "Value Loss": 0.14137353003025055, "_runtime": 10729.1308760643, "_timestamp": 1585608098.7637455, "_step": 286}
{"Episode reward": 45.564854728802544, "Episode length": 545, "Policy Loss": 0.7656313180923462, "Value Loss": 17.880687713623047, "_runtime": 10729.499577999115, "_timestamp": 1585608099.1324475, "_step": 287}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 2.3860416412353516, "Value Loss": 41.656837463378906, "_runtime": 10731.082900047302, "_timestamp": 1585608100.7157695, "_step": 288}
{"Episode reward": -99.8040901013636, "Episode length": 999, "Policy Loss": -0.5169442296028137, "Value Loss": 0.07057466357946396, "_runtime": 10732.618701219559, "_timestamp": 1585608102.2515707, "_step": 289}
{"Episode reward": -99.7955411882126, "Episode length": 999, "Policy Loss": -0.3816753327846527, "Value Loss": 0.13608300685882568, "_runtime": 10733.083045005798, "_timestamp": 1585608102.7159145, "_step": 290}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 2.020988702774048, "Value Loss": 31.880172729492188, "_runtime": 10734.225125789642, "_timestamp": 1585608103.8579953, "_step": 291}
{"Episode reward": 28.157948923017642, "Episode length": 719, "Policy Loss": 0.6058154702186584, "Value Loss": 12.136040687561035, "_runtime": 10735.827570676804, "_timestamp": 1585608105.4604402, "_step": 292}
{"Episode reward": -99.87055425792794, "Episode length": 999, "Policy Loss": -0.2654845118522644, "Value Loss": 0.026482075452804565, "_runtime": 10736.708674907684, "_timestamp": 1585608106.3415444, "_step": 293}
{"Episode reward": 42.00255909822827, "Episode length": 580, "Policy Loss": 0.8917859196662903, "Value Loss": 15.53514289855957, "_runtime": 10737.083335876465, "_timestamp": 1585608106.7162054, "_step": 294}
{"Episode reward": 78.49999999999997, "Episode length": 215, "Policy Loss": 2.6076717376708984, "Value Loss": 41.746971130371094, "_runtime": 10737.578828334808, "_timestamp": 1585608107.2116978, "_step": 295}
{"Episode reward": 70.5790480359456, "Episode length": 295, "Policy Loss": 1.8578511476516724, "Value Loss": 29.82269859313965, "_runtime": 10739.11416053772, "_timestamp": 1585608108.74703, "_step": 296}
{"Episode reward": -99.66279702123582, "Episode length": 999, "Policy Loss": -0.393405020236969, "Value Loss": 0.16313646733760834, "_runtime": 10740.62689447403, "_timestamp": 1585608110.259764, "_step": 297}
{"Episode reward": -99.66065586183547, "Episode length": 999, "Policy Loss": -0.42186883091926575, "Value Loss": 0.0629461333155632, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755, 0.6694852113723755]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6694852113723755, 0.11617696285247803, 0.9018391370773315, 1.687501311302185, 2.473163604736328, 3.2588257789611816, 4.044487953186035, 4.830150127410889, 5.615812301635742, 6.401474475860596, 7.187136650085449, 7.972799301147461, 8.758460998535156, 9.544122695922852, 10.329785346984863, 11.115447998046875, 11.90110969543457, 12.686771392822266, 13.472434043884277, 14.258096694946289, 15.043758392333984, 15.82942008972168, 16.615083694458008, 17.400745391845703, 18.1864070892334, 18.972068786621094, 19.75773048400879, 20.543394088745117, 21.329055786132812, 22.114717483520508, 22.900381088256836, 23.68604278564453, 24.471704483032227, 25.257366180419922, 26.043027877807617, 26.828691482543945, 27.61435317993164, 28.400014877319336, 29.185678482055664, 29.97134017944336, 30.757001876831055, 31.542665481567383, 32.32832336425781, 33.11398696899414, 33.89965057373047, 34.68531036376953, 35.47097396850586, 36.25663375854492, 37.04229736328125, 37.82796096801758, 38.61362075805664, 39.39928436279297, 40.18494415283203, 40.97060775756836, 41.75627136230469, 42.54193115234375, 43.32759475708008, 44.113258361816406, 44.89891815185547, 45.6845817565918, 46.470245361328125, 47.25590515136719, 48.041568756103516, 48.82722854614258, 49.612892150878906]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0009065484046004713, 0.023483194410800934, 0.047872934490442276, 0.07226267457008362, 0.09665241837501526, 0.1210421621799469, 0.14543190598487854, 0.16982164978981018, 0.19421139359474182, 0.21860113739967346, 0.2429908812046051, 0.26738059520721436, 0.291770339012146, 0.31616008281707764, 0.3405498266220093, 0.3649395704269409, 0.38932931423187256, 0.4137190580368042, 0.43810880184173584, 0.4624985456466675, 0.4868882894515991, 0.5112780332565308, 0.5356677770614624, 0.560057520866394, 0.5844472646713257, 0.6088370084762573, 0.633226752281189, 0.6576164960861206, 0.6820062398910522, 0.7063959836959839, 0.7307857275009155, 0.7551754713058472, 0.7795652151107788, 0.8039549589157104, 0.8283447027206421, 0.8527344465255737, 0.8771241903305054, 0.901513934135437, 0.9259036779403687, 0.9502934217453003, 0.9746831655502319, 0.9990729093551636, 1.0234625339508057, 1.0478522777557373, 1.072242021560669, 1.0966317653656006, 1.1210215091705322, 1.1454112529754639, 1.1698009967803955, 1.1941907405853271, 1.2185804843902588, 1.2429702281951904, 1.267359972000122, 1.2917497158050537, 1.3161394596099854, 1.340529203414917, 1.3649189472198486, 1.3893086910247803, 1.413698434829712, 1.4380881786346436, 1.4624779224395752, 1.4868676662445068, 1.5112574100494385, 1.5356471538543701, 1.5600368976593018]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 5.0, 3.0, 6.0, 6.0, 4.0, 11.0, 6.0, 15.0, 350.0, 14.0, 8.0, 11.0, 5.0, 2.0, 6.0, 8.0, 1.0, 3.0, 1.0, 4.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1767712831497192, -1.0633773803710938, -0.9499833583831787, -0.8365894556045532, -0.723195493221283, -0.6098015308380127, -0.4964076280593872, -0.38301366567611694, -0.2696197032928467, -0.1562258005142212, -0.04283177852630615, 0.07056212425231934, 0.18395602703094482, 0.29735004901885986, 0.41074395179748535, 0.5241379737854004, 0.6375318765640259, 0.7509257793426514, 0.8643196821212769, 0.9777137041091919, 1.091107726097107, 1.2045015096664429, 1.317895531654358, 1.431289553642273, 1.5446833372116089, 1.658077359199524, 1.771471381187439, 1.884865403175354, 1.99825918674469, 2.1116533279418945, 2.2250471115112305, 2.3384408950805664, 2.4518351554870605, 2.5652289390563965, 2.6786227226257324, 2.7920169830322266, 2.9054107666015625, 3.0188050270080566, 3.1321988105773926, 3.2455925941467285, 3.3589868545532227, 3.4723806381225586, 3.5857744216918945, 3.6991686820983887, 3.8125624656677246, 3.9259562492370605, 4.039350509643555, 4.152744293212891, 4.266138076782227, 4.379532337188721, 4.492926120758057, 4.606320381164551, 4.719714164733887, 4.833107948303223, 4.946502208709717, 5.059895992279053, 5.173289775848389, 5.286684036254883, 5.400077819824219, 5.513471603393555, 5.626865863800049, 5.740259647369385, 5.853653430938721, 5.967047691345215, 6.080441474914551]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-7.083034515380859, -6.786502361297607, -6.4899702072143555, -6.1934380531311035, -5.896905899047852, -5.600374221801758, -5.303842067718506, -5.007309913635254, -4.710777759552002, -4.41424560546875, -4.117713451385498, -3.821181535720825, -3.5246493816375732, -3.2281172275543213, -2.9315853118896484, -2.6350531578063965, -2.3385210037231445, -2.0419888496398926, -1.7454566955566406, -1.4489245414733887, -1.1523923873901367, -0.855860710144043, -0.559328556060791, -0.26279640197753906, 0.03373575210571289, 0.33026790618896484, 0.6268000602722168, 0.9233322143554688, 1.2198638916015625, 1.5163965225219727, 1.8129281997680664, 2.1094608306884766, 2.4059925079345703, 2.702524185180664, 2.999056816101074, 3.295588493347168, 3.592121124267578, 3.888652801513672, 4.185185432434082, 4.481717109680176, 4.778249740600586, 5.07478141784668, 5.371313095092773, 5.667845726013184, 5.964377403259277, 6.2609100341796875, 6.557441711425781, 6.853974342346191, 7.150506019592285, 7.447037696838379, 7.743570327758789, 8.040102005004883, 8.336634635925293, 8.633166313171387, 8.929698944091797, 9.22623062133789, 9.522762298583984, 9.819293975830078, 10.115827560424805, 10.412359237670898, 10.708890914916992, 11.005422592163086, 11.301956176757812, 11.598487854003906, 11.89501953125]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 5.0, 7.0, 3.0, 1.0, 4.0, 6.0, 2.0, 6.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.995871543884277, -4.844459533691406, -4.693047046661377, -4.541634559631348, -4.390222549438477, -4.2388105392456055, -4.087398052215576, -3.935985803604126, -3.784573554992676, -3.6331613063812256, -3.4817490577697754, -3.330336809158325, -3.178924560546875, -3.027512311935425, -2.8761000633239746, -2.7246878147125244, -2.573275566101074, -2.421863317489624, -2.270451068878174, -2.1190388202667236, -1.9676265716552734, -1.8162143230438232, -1.664802074432373, -1.5133898258209229, -1.3619775772094727, -1.2105653285980225, -1.0591530799865723, -0.907740592956543, -0.7563285827636719, -0.6049165725708008, -0.4535040855407715, -0.3020915985107422, -0.1506795883178711, 0.000732421875, 0.1521449089050293, 0.3035573959350586, 0.4549694061279297, 0.6063814163208008, 0.7577939033508301, 0.9092063903808594, 1.0606184005737305, 1.2120304107666016, 1.3634428977966309, 1.5148553848266602, 1.6662673950195312, 1.8176794052124023, 1.9690918922424316, 2.120504379272461, 2.271916389465332, 2.423328399658203, 2.5747408866882324, 2.7261533737182617, 2.877565383911133, 3.028977394104004, 3.1803903579711914, 3.3318023681640625, 3.4832143783569336, 3.6346263885498047, 3.786038398742676, 3.9374513626098633, 4.088863372802734, 4.2402753829956055, 4.391688346862793, 4.543100357055664, 4.694512367248535]}, "_runtime": 10741.435993909836, "_timestamp": 1585608111.0688634, "_step": 298}
{"Episode reward": 47.1344768840582, "Episode length": 529, "Policy Loss": 0.6810775995254517, "Value Loss": 16.67792320251465, "_runtime": 10742.598585605621, "_timestamp": 1585608112.231455, "_step": 299}
{"Episode reward": 27.18472276693197, "Episode length": 730, "Policy Loss": 0.41587260365486145, "Value Loss": 12.77717399597168, "_runtime": 10744.168629646301, "_timestamp": 1585608113.8014991, "_step": 300}
{"Episode reward": -99.68663295043959, "Episode length": 999, "Policy Loss": -0.5382184386253357, "Value Loss": 0.06194120645523071, "_runtime": 10744.877079248428, "_timestamp": 1585608114.5099487, "_step": 301}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 0.984596312046051, "Value Loss": 20.055511474609375, "_runtime": 10746.252216815948, "_timestamp": 1585608115.8850863, "_step": 302}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 0.1937279850244522, "Value Loss": 9.999687194824219, "_runtime": 10747.821851968765, "_timestamp": 1585608117.4547215, "_step": 303}
{"Episode reward": -99.80120361354062, "Episode length": 999, "Policy Loss": -0.5134426951408386, "Value Loss": 0.04418262094259262, "_runtime": 10749.004399061203, "_timestamp": 1585608118.6372685, "_step": 304}
{"Episode reward": 22.600000000000122, "Episode length": 774, "Policy Loss": 0.3287436068058014, "Value Loss": 11.994501113891602, "_runtime": 10749.62334060669, "_timestamp": 1585608119.25621, "_step": 305}
{"Episode reward": 62.73598784189646, "Episode length": 373, "Policy Loss": 1.6980054378509521, "Value Loss": 23.355066299438477, "_runtime": 10751.181802988052, "_timestamp": 1585608120.8146725, "_step": 306}
{"Episode reward": 1.2625891202841188, "Episode length": 989, "Policy Loss": -0.24335671961307526, "Value Loss": 8.938126564025879, "_runtime": 10751.822017669678, "_timestamp": 1585608121.4548872, "_step": 307}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 0.28160879015922546, "Value Loss": 21.676010131835938, "_runtime": 10753.351251840591, "_timestamp": 1585608122.9841213, "_step": 308}
{"Episode reward": -99.80011997530097, "Episode length": 999, "Policy Loss": -1.1971806287765503, "Value Loss": 0.04452783241868019, "_runtime": 10754.748717308044, "_timestamp": 1585608124.3815868, "_step": 309}
{"Episode reward": 11.728347818135092, "Episode length": 884, "Policy Loss": -0.6026886105537415, "Value Loss": 9.494217872619629, "_runtime": 10755.354278802872, "_timestamp": 1585608124.9871483, "_step": 310}
{"Episode reward": 61.69999999999973, "Episode length": 383, "Policy Loss": 0.2575457990169525, "Value Loss": 22.417015075683594, "_runtime": 10756.068865776062, "_timestamp": 1585608125.7017353, "_step": 311}
{"Episode reward": 55.37169459962716, "Episode length": 447, "Policy Loss": -0.36727607250213623, "Value Loss": 18.44832992553711, "_runtime": 10757.637833833694, "_timestamp": 1585608127.2707033, "_step": 312}
{"Episode reward": -99.5146636723527, "Episode length": 999, "Policy Loss": -1.6699715852737427, "Value Loss": 0.06446003913879395, "_runtime": 10759.097762823105, "_timestamp": 1585608128.7306323, "_step": 313}
{"Episode reward": 7.802022766788511, "Episode length": 924, "Policy Loss": -1.1898114681243896, "Value Loss": 9.815398216247559, "_runtime": 10760.114407539368, "_timestamp": 1585608129.747277, "_step": 314}
{"Episode reward": 34.460109180211475, "Episode length": 656, "Policy Loss": -1.0810925960540771, "Value Loss": 14.16352367401123, "_runtime": 10761.361759662628, "_timestamp": 1585608130.9946291, "_step": 315}
{"Episode reward": 21.695556328795092, "Episode length": 784, "Policy Loss": -1.4934357404708862, "Value Loss": 11.916752815246582, "_runtime": 10762.851844072342, "_timestamp": 1585608132.4847136, "_step": 316}
{"Episode reward": 5.468985441281632, "Episode length": 947, "Policy Loss": -1.8369249105453491, "Value Loss": 9.94482707977295, "_runtime": 10764.132828712463, "_timestamp": 1585608133.7656982, "_step": 317}
{"Episode reward": 17.214089368284178, "Episode length": 828, "Policy Loss": -1.9130487442016602, "Value Loss": 11.274504661560059, "_runtime": 10765.697063922882, "_timestamp": 1585608135.3299334, "_step": 318}
{"Episode reward": -99.84796348505049, "Episode length": 999, "Policy Loss": -2.7216694355010986, "Value Loss": 0.8356819748878479, "_runtime": 10767.267844676971, "_timestamp": 1585608136.9007142, "_step": 319}
{"Episode reward": -99.54091169948086, "Episode length": 999, "Policy Loss": -2.798508405685425, "Value Loss": 0.23131239414215088, "_runtime": 10768.583101272583, "_timestamp": 1585608138.2159708, "_step": 320}
{"Episode reward": 15.412484922912498, "Episode length": 847, "Policy Loss": -1.8019556999206543, "Value Loss": 10.851606369018555, "_runtime": 10769.553956747055, "_timestamp": 1585608139.1868262, "_step": 321}
{"Episode reward": 39.91351912161278, "Episode length": 602, "Policy Loss": -1.5460078716278076, "Value Loss": 14.934660911560059, "_runtime": 10771.14237332344, "_timestamp": 1585608140.7752428, "_step": 322}
{"Episode reward": -99.76907934213384, "Episode length": 999, "Policy Loss": -2.5975756645202637, "Value Loss": 0.15076705813407898, "_runtime": 10772.724994897842, "_timestamp": 1585608142.3578644, "_step": 323}
{"Episode reward": -99.81245959186786, "Episode length": 999, "Policy Loss": -2.51566743850708, "Value Loss": 0.15789738297462463, "_runtime": 10774.264828920364, "_timestamp": 1585608143.8976984, "_step": 324}
{"Episode reward": -99.75620427066322, "Episode length": 999, "Policy Loss": -2.434992551803589, "Value Loss": 0.1567004919052124, "_runtime": 10775.85442852974, "_timestamp": 1585608145.487298, "_step": 325}
{"Episode reward": -99.80332710603112, "Episode length": 999, "Policy Loss": -2.3299272060394287, "Value Loss": 0.13023795187473297, "_runtime": 10776.933166265488, "_timestamp": 1585608146.5660357, "_step": 326}
{"Episode reward": 31.72870555967053, "Episode length": 683, "Policy Loss": -1.2941938638687134, "Value Loss": 13.18840217590332, "_runtime": 10777.69237112999, "_timestamp": 1585608147.3252406, "_step": 327}
{"Episode reward": 53.39002729505262, "Episode length": 467, "Policy Loss": -0.6285843253135681, "Value Loss": 20.336475372314453, "_runtime": 10779.27564406395, "_timestamp": 1585608148.9085135, "_step": 328}
{"Episode reward": -99.68909926258355, "Episode length": 999, "Policy Loss": -1.8149601221084595, "Value Loss": 0.5033274292945862, "_runtime": 10780.299983978271, "_timestamp": 1585608149.9328535, "_step": 329}
{"Episode reward": 35.26397544275909, "Episode length": 649, "Policy Loss": -0.6823140978813171, "Value Loss": 13.800487518310547, "_runtime": 10781.824045419693, "_timestamp": 1585608151.456915, "_step": 330}
{"Episode reward": -99.8591755704009, "Episode length": 999, "Policy Loss": -1.572718620300293, "Value Loss": 0.2680816948413849, "_runtime": 10783.434840917587, "_timestamp": 1585608153.0677104, "_step": 331}
{"Episode reward": -99.81542134433845, "Episode length": 999, "Policy Loss": -1.3847243785858154, "Value Loss": 0.2391844093799591, "_runtime": 10783.927114486694, "_timestamp": 1585608153.559984, "_step": 332}
{"Episode reward": 69.56506969237219, "Episode length": 305, "Policy Loss": 0.9072414636611938, "Value Loss": 30.035869598388672, "_runtime": 10784.627517223358, "_timestamp": 1585608154.2603867, "_step": 333}
{"Episode reward": 55.97121360516141, "Episode length": 441, "Policy Loss": 0.3760424554347992, "Value Loss": 19.939420700073242, "_runtime": 10786.087581634521, "_timestamp": 1585608155.720451, "_step": 334}
{"Episode reward": 7.774733792153228, "Episode length": 923, "Policy Loss": -0.2118217647075653, "Value Loss": 9.53671646118164, "_runtime": 10787.206015825272, "_timestamp": 1585608156.8388853, "_step": 335}
{"Episode reward": 26.503472733124994, "Episode length": 735, "Policy Loss": -0.013532905839383602, "Value Loss": 13.017857551574707, "_runtime": 10788.724951982498, "_timestamp": 1585608158.3578215, "_step": 336}
{"Episode reward": -99.89335163980583, "Episode length": 999, "Policy Loss": -1.0613040924072266, "Value Loss": 0.07578711211681366, "_runtime": 10790.289905071259, "_timestamp": 1585608159.9227746, "_step": 337}
{"Episode reward": -99.8278701055781, "Episode length": 999, "Policy Loss": -1.0795093774795532, "Value Loss": 0.3285917639732361, "_runtime": 10791.834222316742, "_timestamp": 1585608161.4670918, "_step": 338}
{"Episode reward": -99.88502452913532, "Episode length": 999, "Policy Loss": -1.203742265701294, "Value Loss": 0.2712581753730774, "_runtime": 10792.552460670471, "_timestamp": 1585608162.1853302, "_step": 339}
{"Episode reward": 55.79999999999965, "Episode length": 442, "Policy Loss": 0.22683946788311005, "Value Loss": 24.104267120361328, "_runtime": 10794.139585733414, "_timestamp": 1585608163.7724552, "_step": 340}
{"Episode reward": -99.81525402106205, "Episode length": 999, "Policy Loss": -1.3586673736572266, "Value Loss": 0.12974171340465546, "_runtime": 10795.109959125519, "_timestamp": 1585608164.7428286, "_step": 341}
{"Episode reward": 38.599999999999405, "Episode length": 614, "Policy Loss": -0.3461858332157135, "Value Loss": 14.257619857788086, "_runtime": 10796.632960319519, "_timestamp": 1585608166.2658298, "_step": 342}
{"Episode reward": -99.81691305786231, "Episode length": 999, "Policy Loss": -1.2804579734802246, "Value Loss": 0.05660180374979973, "_runtime": 10798.218009710312, "_timestamp": 1585608167.8508792, "_step": 343}
{"Episode reward": -99.84022109715595, "Episode length": 999, "Policy Loss": -1.2515616416931152, "Value Loss": 0.03827179968357086, "_runtime": 10799.30162358284, "_timestamp": 1585608168.934493, "_step": 344}
{"Episode reward": 29.970726907159843, "Episode length": 701, "Policy Loss": -0.2949845790863037, "Value Loss": 13.708701133728027, "_runtime": 10800.847929954529, "_timestamp": 1585608170.4807994, "_step": 345}
{"Episode reward": -99.83456871546665, "Episode length": 999, "Policy Loss": -1.2313196659088135, "Value Loss": 0.0316510908305645, "_runtime": 10802.428003072739, "_timestamp": 1585608172.0608726, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2260093688964844, "Value Loss": 0.032556820660829544, "_runtime": 10803.964511156082, "_timestamp": 1585608173.5973806, "_step": 347}
{"Episode reward": -99.84099703961844, "Episode length": 999, "Policy Loss": -1.1561040878295898, "Value Loss": 0.10757074505090714, "_runtime": 10805.160333156586, "_timestamp": 1585608174.7932026, "_step": 348}
{"Episode reward": 23.800000000000054, "Episode length": 762, "Policy Loss": -0.2658568322658539, "Value Loss": 12.580793380737305, "_runtime": 10805.905662059784, "_timestamp": 1585608175.5385315, "_step": 349}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 0.3495602309703827, "Value Loss": 21.047657012939453, "_runtime": 10807.511028051376, "_timestamp": 1585608177.1438975, "_step": 350}
{"Episode reward": -99.82631381908291, "Episode length": 999, "Policy Loss": -1.098822832107544, "Value Loss": 0.03674856200814247, "_runtime": 10809.069839715958, "_timestamp": 1585608178.7027092, "_step": 351}
{"Episode reward": -99.76353875109787, "Episode length": 999, "Policy Loss": -1.0563023090362549, "Value Loss": 0.11742027848958969, "_runtime": 10810.589383602142, "_timestamp": 1585608180.222253, "_step": 352}
{"Episode reward": -99.8177206877605, "Episode length": 999, "Policy Loss": -0.9630126357078552, "Value Loss": 0.23266328871250153, "_runtime": 10812.160843372345, "_timestamp": 1585608181.7937129, "_step": 353}
{"Episode reward": -99.82798645058507, "Episode length": 999, "Policy Loss": -0.9202682375907898, "Value Loss": 0.09047108143568039, "_runtime": 10813.639041900635, "_timestamp": 1585608183.2719114, "_step": 354}
{"Episode reward": 6.374890622777059, "Episode length": 938, "Policy Loss": -0.030620843172073364, "Value Loss": 10.334936141967773, "_runtime": 10815.1112408638, "_timestamp": 1585608184.7441103, "_step": 355}
{"Episode reward": 5.4000000000011, "Episode length": 946, "Policy Loss": -0.09776951372623444, "Value Loss": 10.237760543823242, "_runtime": 10816.41834616661, "_timestamp": 1585608186.0512156, "_step": 356}
{"Episode reward": 18.199736722000324, "Episode length": 820, "Policy Loss": 0.04506675899028778, "Value Loss": 11.919801712036133, "_runtime": 10817.060323238373, "_timestamp": 1585608186.6931927, "_step": 357}
{"Episode reward": 61.35271339183646, "Episode length": 387, "Policy Loss": 0.9129645228385925, "Value Loss": 25.03738784790039, "_runtime": 10818.298690795898, "_timestamp": 1585608187.9315603, "_step": 358}
{"Episode reward": 21.185097489971866, "Episode length": 792, "Policy Loss": 0.041712354868650436, "Value Loss": 12.114326477050781, "_runtime": 10819.314975738525, "_timestamp": 1585608188.9478452, "_step": 359}
{"Episode reward": 36.014073979853954, "Episode length": 641, "Policy Loss": 0.18244558572769165, "Value Loss": 14.834296226501465, "_runtime": 10820.837519168854, "_timestamp": 1585608190.4703887, "_step": 360}
{"Episode reward": -99.71258732238645, "Episode length": 999, "Policy Loss": -0.9187346696853638, "Value Loss": 0.16425539553165436, "_runtime": 10822.397429466248, "_timestamp": 1585608192.030299, "_step": 361}
{"Episode reward": -99.60564958844195, "Episode length": 999, "Policy Loss": -0.9914571642875671, "Value Loss": 0.03698112815618515, "_runtime": 10823.819658994675, "_timestamp": 1585608193.4525285, "_step": 362}
{"Episode reward": 8.458364588931204, "Episode length": 917, "Policy Loss": -0.2793007493019104, "Value Loss": 10.235634803771973, "_runtime": 10825.356185674667, "_timestamp": 1585608194.9890552, "_step": 363}
{"Episode reward": 2.2970101233584614, "Episode length": 978, "Policy Loss": -0.3150542676448822, "Value Loss": 9.386512756347656, "_runtime": 10826.409042358398, "_timestamp": 1585608196.0419118, "_step": 364}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.039953771978616714, "Value Loss": 14.241899490356445, "_runtime": 10827.561601161957, "_timestamp": 1585608197.1944706, "_step": 365}
{"Episode reward": 26.42474035089826, "Episode length": 736, "Policy Loss": -0.16890349984169006, "Value Loss": 12.56604290008545, "_runtime": 10828.559392929077, "_timestamp": 1585608198.1922624, "_step": 366}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": -0.07213585078716278, "Value Loss": 14.218910217285156, "_runtime": 10829.856611013412, "_timestamp": 1585608199.4894805, "_step": 367}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": -0.30560633540153503, "Value Loss": 10.30479621887207, "_runtime": 10831.426185131073, "_timestamp": 1585608201.0590546, "_step": 368}
{"Episode reward": 1.1981449573314222, "Episode length": 989, "Policy Loss": -0.6036113500595093, "Value Loss": 9.087994575500488, "_runtime": 10832.9571352005, "_timestamp": 1585608202.5900047, "_step": 369}
{"Episode reward": -99.75888141123438, "Episode length": 999, "Policy Loss": -1.198280692100525, "Value Loss": 0.3485167920589447, "_runtime": 10834.505645990372, "_timestamp": 1585608204.1385155, "_step": 370}
{"Episode reward": -99.7952783430447, "Episode length": 999, "Policy Loss": -1.21756911277771, "Value Loss": 0.07436256855726242, "_runtime": 10836.065085172653, "_timestamp": 1585608205.6979547, "_step": 371}
{"Episode reward": -99.82774460103688, "Episode length": 999, "Policy Loss": -1.1590694189071655, "Value Loss": 0.05069245025515556, "_runtime": 10837.560815811157, "_timestamp": 1585608207.1936853, "_step": 372}
{"Episode reward": 3.933148616553538, "Episode length": 961, "Policy Loss": -0.43336302042007446, "Value Loss": 9.52474594116211, "_runtime": 10839.134431362152, "_timestamp": 1585608208.7673008, "_step": 373}
{"Episode reward": -99.86802423633495, "Episode length": 999, "Policy Loss": -1.083564281463623, "Value Loss": 0.05078855901956558, "_runtime": 10840.698662519455, "_timestamp": 1585608210.331532, "_step": 374}
{"Episode reward": -99.60226305900002, "Episode length": 999, "Policy Loss": -1.0609381198883057, "Value Loss": 0.06476504355669022, "_runtime": 10842.264324188232, "_timestamp": 1585608211.8971937, "_step": 375}
{"Episode reward": -99.64154831322237, "Episode length": 999, "Policy Loss": -1.0169386863708496, "Value Loss": 0.05167413130402565, "_runtime": 10843.82241511345, "_timestamp": 1585608213.4552846, "_step": 376}
{"Episode reward": -99.74729799404601, "Episode length": 999, "Policy Loss": -0.9527637362480164, "Value Loss": 0.045659519731998444, "_runtime": 10845.293451070786, "_timestamp": 1585608214.9263206, "_step": 377}
{"Episode reward": 5.789739990235461, "Episode length": 943, "Policy Loss": -0.16712936758995056, "Value Loss": 10.234622955322266, "_runtime": 10846.297652482986, "_timestamp": 1585608215.930522, "_step": 378}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 0.18788783252239227, "Value Loss": 14.599692344665527, "_runtime": 10847.877995967865, "_timestamp": 1585608217.5108654, "_step": 379}
{"Episode reward": -99.75364247979456, "Episode length": 999, "Policy Loss": -0.8077647089958191, "Value Loss": 0.11723688989877701, "_runtime": 10849.449892282486, "_timestamp": 1585608219.0827618, "_step": 380}
{"Episode reward": -99.8382332541966, "Episode length": 999, "Policy Loss": -0.7189748287200928, "Value Loss": 0.041218776255846024, "_runtime": 10850.985361814499, "_timestamp": 1585608220.6182313, "_step": 381}
{"Episode reward": -99.80898459143798, "Episode length": 999, "Policy Loss": -0.6767482161521912, "Value Loss": 0.534660279750824, "_runtime": 10852.555027723312, "_timestamp": 1585608222.1878972, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6508414149284363, "Value Loss": 0.2620190680027008, "_runtime": 10853.774918794632, "_timestamp": 1585608223.4077883, "_step": 383}
{"Episode reward": 25.362981420662223, "Episode length": 747, "Policy Loss": 0.3312235474586487, "Value Loss": 12.401620864868164, "_runtime": 10855.334170103073, "_timestamp": 1585608224.9670396, "_step": 384}
{"Episode reward": -99.8818194448934, "Episode length": 999, "Policy Loss": -0.7450215220451355, "Value Loss": 0.27517709136009216, "_runtime": 10856.903301239014, "_timestamp": 1585608226.5361707, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6497046947479248, "Value Loss": 0.03577424958348274, "_runtime": 10858.45496892929, "_timestamp": 1585608228.0878384, "_step": 386}
{"Episode reward": -99.80009803809087, "Episode length": 999, "Policy Loss": -0.6290907263755798, "Value Loss": 0.015814119949936867, "_runtime": 10860.01710653305, "_timestamp": 1585608229.649976, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6140615940093994, "Value Loss": 0.008961093612015247, "_runtime": 10861.596507549286, "_timestamp": 1585608231.229377, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5834242701530457, "Value Loss": 0.011532118543982506, "_runtime": 10862.552735328674, "_timestamp": 1585608232.1856048, "_step": 389}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.5705657005310059, "Value Loss": 15.766358375549316, "_runtime": 10863.061172008514, "_timestamp": 1585608232.6940415, "_step": 390}
{"Episode reward": 70.4269321467726, "Episode length": 296, "Policy Loss": 1.9653691053390503, "Value Loss": 31.150041580200195, "_runtime": 10863.869687080383, "_timestamp": 1585608233.5025566, "_step": 391}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 0.7716512680053711, "Value Loss": 18.379295349121094, "_runtime": 10865.396520614624, "_timestamp": 1585608235.02939, "_step": 392}
{"Episode reward": 0.8860589432543549, "Episode length": 993, "Policy Loss": 0.0630899965763092, "Value Loss": 9.508225440979004, "_runtime": 10866.372102737427, "_timestamp": 1585608236.0049722, "_step": 393}
{"Episode reward": 35.34555714689135, "Episode length": 647, "Policy Loss": 0.10045701265335083, "Value Loss": 14.137956619262695, "_runtime": 10867.886811971664, "_timestamp": 1585608237.5196815, "_step": 394}
{"Episode reward": -99.763685958575, "Episode length": 999, "Policy Loss": -1.0596036911010742, "Value Loss": 0.025153838098049164, "_runtime": 10869.4497256279, "_timestamp": 1585608239.082595, "_step": 395}
{"Episode reward": -99.8157163562472, "Episode length": 999, "Policy Loss": -1.1890922784805298, "Value Loss": 0.028990846127271652, "_runtime": 10870.530059337616, "_timestamp": 1585608240.1629288, "_step": 396}
{"Episode reward": 29.998536216071514, "Episode length": 701, "Policy Loss": -0.35742485523223877, "Value Loss": 12.8870210647583, "_runtime": 10872.075085878372, "_timestamp": 1585608241.7079554, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.367717981338501, "Value Loss": 0.04528733715415001, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776, 0.0022627904545515776]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005181207787245512, 0.009859247133135796, 0.02489970065653324, 0.039940156042575836, 0.05498060956597328, 0.07002106308937073, 0.08506152033805847, 0.10010197013616562, 0.11514242738485336, 0.1301828771829605, 0.14522333443164825, 0.160263791680336, 0.17530424892902374, 0.1903447061777115, 0.20538514852523804, 0.22042560577392578, 0.23546606302261353, 0.25050652027130127, 0.265546977519989, 0.28058743476867676, 0.2956278920173645, 0.31066834926605225, 0.32570880651474, 0.34074926376342773, 0.3557897210121155, 0.3708301782608032, 0.38587063550949097, 0.4009110629558563, 0.41595152020454407, 0.4309919774532318, 0.44603243470191956, 0.4610728919506073, 0.47611334919929504, 0.4911538064479828, 0.5061942338943481, 0.5212346911430359, 0.5362751483917236, 0.5513156056404114, 0.5663560628890991, 0.5813965201377869, 0.5964369773864746, 0.6114774346351624, 0.6265178918838501, 0.6415583491325378, 0.6565988063812256, 0.6716392636299133, 0.6866797208786011, 0.7017201781272888, 0.7167606353759766, 0.7318010926246643, 0.746841549873352, 0.7618820071220398, 0.7769224643707275, 0.7919629216194153, 0.8070033192634583, 0.822043776512146, 0.8370842337608337, 0.8521246910095215, 0.8671651482582092, 0.882205605506897, 0.8972460627555847, 0.9122865200042725, 0.9273269772529602, 0.942367434501648, 0.9574078917503357]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005503427237272263, -0.0051293568685650826, -0.004755286034196615, -0.004381215199828148, -0.004007144831120968, -0.003633074229583144, -0.0032590036280453205, -0.002884933026507497, -0.002510862424969673, -0.0021367918234318495, -0.0017627212218940258, -0.0013886503875255585, -0.0010145800188183784, -0.0006405096501111984, -0.0002664388157427311, 0.00010763201862573624, 0.00048170238733291626, 0.0008557727560400963, 0.0012298435904085636, 0.001603914424777031, 0.001977984793484211, 0.002352055162191391, 0.0027261264622211456, 0.0031001968309283257, 0.0034742671996355057, 0.0038483375683426857, 0.004222407937049866, 0.00459647923707962, 0.0049705496057868, 0.00534461997449398, 0.005718691274523735, 0.006092761643230915, 0.006466832011938095, 0.006840902380645275, 0.007214972749352455, 0.00758904404938221, 0.00796311441808939, 0.00833718478679657, 0.008711256086826324, 0.009085326455533504, 0.009459396824240685, 0.009833467192947865, 0.010207537561655045, 0.0105816088616848, 0.010955680161714554, 0.01132974959909916, 0.011703820899128914, 0.01207789033651352, 0.012451961636543274, 0.012826032936573029, 0.013200102373957634, 0.013574173673987389, 0.013948243111371994, 0.014322314411401749, 0.014696385711431503, 0.015070455148816109, 0.015444526448845863, 0.015818597748875618, 0.016192667186260223, 0.016566738486289978, 0.016940809786319733, 0.017314879223704338, 0.017688950523734093, 0.018063019961118698, 0.018437091261148453]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 13.0, 31.0, 33.0, 221.0, 80.0, 15.0, 14.0, 28.0, 14.0, 10.0, 8.0, 3.0, 1.0, 4.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.17566801607608795, -0.17029522359371185, -0.16492244601249695, -0.15954965353012085, -0.15417686104774475, -0.14880406856536865, -0.14343129098415375, -0.13805849850177765, -0.13268572092056274, -0.12731292843818665, -0.12194013595581055, -0.11656735092401505, -0.11119456589221954, -0.10582177340984344, -0.10044898837804794, -0.09507619589567184, -0.08970341086387634, -0.08433062583208084, -0.07895783334970474, -0.07358504831790924, -0.06821225583553314, -0.06283947080373764, -0.05746668577194214, -0.05209389328956604, -0.046721115708351135, -0.04134832322597504, -0.03597553074359894, -0.03060273826122284, -0.025229960680007935, -0.019857168197631836, -0.014484375715255737, -0.009111598134040833, -0.003738805651664734, 0.0016339868307113647, 0.0070067644119262695, 0.012379556894302368, 0.017752349376678467, 0.02312512695789337, 0.02849791944026947, 0.03387071192264557, 0.03924350440502167, 0.04461628198623657, 0.04998907446861267, 0.05536186695098877, 0.060734644532203674, 0.06610743701457977, 0.07148022949695587, 0.07685302197933197, 0.08222578465938568, 0.08759857714176178, 0.09297136962413788, 0.09834416210651398, 0.10371695458889008, 0.10908974707126617, 0.11446253955364227, 0.11983530223369598, 0.12520809471607208, 0.13058088719844818, 0.13595367968082428, 0.14132647216320038, 0.14669926464557648, 0.1520720273256302, 0.1574448198080063, 0.16281761229038239, 0.16819040477275848]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 7.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10087104886770248, -0.0961230918765068, -0.09137513488531113, -0.08662717789411545, -0.08187922090291977, -0.07713126391172409, -0.07238329946994781, -0.06763534247875214, -0.06288738548755646, -0.05813943222165108, -0.0533914752304554, -0.04864351823925972, -0.04389555752277374, -0.039147600531578064, -0.034399643540382385, -0.029651686549186707, -0.024903729557991028, -0.02015577256679535, -0.01540781557559967, -0.010659858584403992, -0.005911901593208313, -0.0011639446020126343, 0.0035840123891830444, 0.008331969380378723, 0.013079933822154999, 0.017827890813350677, 0.022575847804546356, 0.027323804795742035, 0.032071761786937714, 0.03681971877813339, 0.04156767576932907, 0.04631563276052475, 0.05106358975172043, 0.05581154674291611, 0.060559503734111786, 0.06530746072530746, 0.07005541771650314, 0.07480337470769882, 0.0795513316988945, 0.08429928869009018, 0.08904724568128586, 0.09379520267248154, 0.09854315966367722, 0.1032911166548729, 0.10803907364606857, 0.11278703063726425, 0.11753498762845993, 0.12228294461965561, 0.12703090906143188, 0.13177886605262756, 0.13652682304382324, 0.14127478003501892, 0.1460227370262146, 0.15077069401741028, 0.15551865100860596, 0.16026660799980164, 0.16501456499099731, 0.169762521982193, 0.17451047897338867, 0.17925843596458435, 0.18400639295578003, 0.1887543499469757, 0.1935023069381714, 0.19825026392936707, 0.20299822092056274]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 1.0, 2.0, 5.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5697081685066223, -0.5517160892486572, -0.5337240695953369, -0.5157319903373718, -0.4977399706840515, -0.4797479212284088, -0.4617558717727661, -0.443763792514801, -0.4257717728614807, -0.4077796936035156, -0.3897876739501953, -0.3717955946922302, -0.3538035452365875, -0.3358114957809448, -0.3178194463253021, -0.2998273968696594, -0.2818353474140167, -0.263843297958374, -0.24585124850273132, -0.22785919904708862, -0.20986714959144592, -0.19187510013580322, -0.17388305068016052, -0.15589100122451782, -0.13789892196655273, -0.11990687251091003, -0.10191482305526733, -0.08392277359962463, -0.06593072414398193, -0.04793870449066162, -0.029946625232696533, -0.01195460557937622, 0.006037473678588867, 0.024029552936553955, 0.04202157258987427, 0.060013651847839355, 0.07800567150115967, 0.09599775075912476, 0.11398977041244507, 0.13198184967041016, 0.14997386932373047, 0.16796594858169556, 0.18595796823501587, 0.20395004749298096, 0.22194206714630127, 0.23993414640426636, 0.25792616605758667, 0.27591824531555176, 0.29391032457351685, 0.31190234422683716, 0.32989442348480225, 0.34788644313812256, 0.36587852239608765, 0.38387054204940796, 0.40186262130737305, 0.41985464096069336, 0.43784672021865845, 0.45583873987197876, 0.4738307595252991, 0.49182289838790894, 0.5098149180412292, 0.5278069376945496, 0.5457989573478699, 0.5637910962104797, 0.5817831158638]}, "_runtime": 10873.640831947327, "_timestamp": 1585608243.2737014, "_step": 398}
{"Episode reward": -99.89274228403671, "Episode length": 999, "Policy Loss": -1.4415589570999146, "Value Loss": 0.06369078904390335, "_runtime": 10875.171343564987, "_timestamp": 1585608244.804213, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4936777353286743, "Value Loss": 0.19955402612686157, "_runtime": 10876.151118278503, "_timestamp": 1585608245.7839878, "_step": 400}
{"Episode reward": 37.999999999999396, "Episode length": 620, "Policy Loss": -0.3986421525478363, "Value Loss": 14.294342041015625, "_runtime": 10877.763644218445, "_timestamp": 1585608247.3965137, "_step": 401}
{"Episode reward": -99.86923775710027, "Episode length": 999, "Policy Loss": -1.4052767753601074, "Value Loss": 0.14005139470100403, "_runtime": 10878.524636745453, "_timestamp": 1585608248.1575062, "_step": 402}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": -0.11000397801399231, "Value Loss": 18.36260986328125, "_runtime": 10880.006402492523, "_timestamp": 1585608249.639272, "_step": 403}
{"Episode reward": 4.4900721621478255, "Episode length": 956, "Policy Loss": -0.6945238709449768, "Value Loss": 8.785286903381348, "_runtime": 10881.571776151657, "_timestamp": 1585608251.2046456, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2783794403076172, "Value Loss": 0.40022847056388855, "_runtime": 10883.088012695312, "_timestamp": 1585608252.7208822, "_step": 405}
{"Episode reward": -99.88743345737318, "Episode length": 999, "Policy Loss": -1.0864002704620361, "Value Loss": 0.024832483381032944, "_runtime": 10884.47815823555, "_timestamp": 1585608254.1110277, "_step": 406}
{"Episode reward": 11.466044592764987, "Episode length": 887, "Policy Loss": -0.25099846720695496, "Value Loss": 9.677591323852539, "_runtime": 10885.264346837997, "_timestamp": 1585608254.8972163, "_step": 407}
{"Episode reward": 51.59999999999959, "Episode length": 484, "Policy Loss": 0.7935746908187866, "Value Loss": 17.95551300048828, "_runtime": 10886.78900551796, "_timestamp": 1585608256.421875, "_step": 408}
{"Episode reward": 2.027696145769582, "Episode length": 982, "Policy Loss": -0.04755781590938568, "Value Loss": 8.756874084472656, "_runtime": 10887.8411860466, "_timestamp": 1585608257.4740555, "_step": 409}
{"Episode reward": 33.791148430760444, "Episode length": 663, "Policy Loss": 0.3585183620452881, "Value Loss": 13.54007339477539, "_runtime": 10888.432092666626, "_timestamp": 1585608258.0649621, "_step": 410}
{"Episode reward": 62.54861226063196, "Episode length": 376, "Policy Loss": 1.3077826499938965, "Value Loss": 22.83725929260254, "_runtime": 10889.988467931747, "_timestamp": 1585608259.6213374, "_step": 411}
{"Episode reward": -99.81384817398944, "Episode length": 999, "Policy Loss": -0.4832122325897217, "Value Loss": 0.011122561991214752, "_runtime": 10891.403020858765, "_timestamp": 1585608261.0358903, "_step": 412}
{"Episode reward": 8.40000000000093, "Episode length": 916, "Policy Loss": 0.2801060378551483, "Value Loss": 8.859970092773438, "_runtime": 10892.115501880646, "_timestamp": 1585608261.7483714, "_step": 413}
{"Episode reward": 53.9515776332464, "Episode length": 461, "Policy Loss": 0.6909321546554565, "Value Loss": 18.832284927368164, "_runtime": 10893.665117740631, "_timestamp": 1585608263.2979872, "_step": 414}
{"Episode reward": -99.75232184047205, "Episode length": 999, "Policy Loss": -0.7914522290229797, "Value Loss": 0.013978498987853527, "_runtime": 10894.729500770569, "_timestamp": 1585608264.3623703, "_step": 415}
{"Episode reward": 31.799996812548088, "Episode length": 683, "Policy Loss": 0.03549378737807274, "Value Loss": 12.212165832519531, "_runtime": 10896.247610330582, "_timestamp": 1585608265.8804798, "_step": 416}
{"Episode reward": -99.88668173700431, "Episode length": 999, "Policy Loss": -1.0712201595306396, "Value Loss": 0.04740272834897041, "_runtime": 10897.58105134964, "_timestamp": 1585608267.2139208, "_step": 417}
{"Episode reward": 13.952974673361197, "Episode length": 862, "Policy Loss": -0.40037351846694946, "Value Loss": 10.608098030090332, "_runtime": 10898.770505428314, "_timestamp": 1585608268.403375, "_step": 418}
{"Episode reward": 23.240172362118116, "Episode length": 768, "Policy Loss": -0.4683701992034912, "Value Loss": 10.24468994140625, "_runtime": 10900.315902709961, "_timestamp": 1585608269.9487722, "_step": 419}
{"Episode reward": -99.6446043148856, "Episode length": 999, "Policy Loss": -1.4075514078140259, "Value Loss": 0.19232618808746338, "_runtime": 10901.101978063583, "_timestamp": 1585608270.7348475, "_step": 420}
{"Episode reward": 53.18259775058793, "Episode length": 469, "Policy Loss": -0.23870062828063965, "Value Loss": 16.38394546508789, "_runtime": 10902.66475367546, "_timestamp": 1585608272.2976232, "_step": 421}
{"Episode reward": -99.89735054904455, "Episode length": 999, "Policy Loss": -1.5614076852798462, "Value Loss": 0.10985788702964783, "_runtime": 10904.218929290771, "_timestamp": 1585608273.8517988, "_step": 422}
{"Episode reward": -99.78033806024911, "Episode length": 999, "Policy Loss": -1.6513211727142334, "Value Loss": 0.11393800377845764, "_runtime": 10905.719441890717, "_timestamp": 1585608275.3523114, "_step": 423}
{"Episode reward": -99.5248034754987, "Episode length": 999, "Policy Loss": -1.6560657024383545, "Value Loss": 0.10091561824083328, "_runtime": 10907.306509256363, "_timestamp": 1585608276.9393787, "_step": 424}
{"Episode reward": -99.80008983546728, "Episode length": 999, "Policy Loss": -1.670467734336853, "Value Loss": 0.0785406157374382, "_runtime": 10908.867525577545, "_timestamp": 1585608278.500395, "_step": 425}
{"Episode reward": -99.79116929061571, "Episode length": 999, "Policy Loss": -1.638990044593811, "Value Loss": 0.05980083346366882, "_runtime": 10910.430395364761, "_timestamp": 1585608280.0632648, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5673545598983765, "Value Loss": 0.0841701403260231, "_runtime": 10912.014798402786, "_timestamp": 1585608281.647668, "_step": 427}
{"Episode reward": -99.89958843702776, "Episode length": 999, "Policy Loss": -1.487115740776062, "Value Loss": 0.06476671993732452, "_runtime": 10913.596585988998, "_timestamp": 1585608283.2294555, "_step": 428}
{"Episode reward": -99.81082074278825, "Episode length": 999, "Policy Loss": -1.3890467882156372, "Value Loss": 0.06294994801282883, "_runtime": 10914.895273447037, "_timestamp": 1585608284.528143, "_step": 429}
{"Episode reward": 17.720867205690993, "Episode length": 824, "Policy Loss": -0.3932636082172394, "Value Loss": 10.944971084594727, "_runtime": 10916.430924654007, "_timestamp": 1585608286.0637941, "_step": 430}
{"Episode reward": 2.828973293305694, "Episode length": 972, "Policy Loss": -0.3834036886692047, "Value Loss": 7.903650760650635, "_runtime": 10918.009018659592, "_timestamp": 1585608287.6418881, "_step": 431}
{"Episode reward": -99.32661618026769, "Episode length": 999, "Policy Loss": -1.0261460542678833, "Value Loss": 0.024565493687987328, "_runtime": 10919.553034067154, "_timestamp": 1585608289.1859035, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.923259973526001, "Value Loss": 0.03348308801651001, "_runtime": 10921.1276845932, "_timestamp": 1585608290.760554, "_step": 433}
{"Episode reward": -99.82635140353675, "Episode length": 999, "Policy Loss": -0.8070325255393982, "Value Loss": 0.031219806522130966, "_runtime": 10921.651280879974, "_timestamp": 1585608291.2841504, "_step": 434}
{"Episode reward": 70.35026104913544, "Episode length": 298, "Policy Loss": 1.0973365306854248, "Value Loss": 24.62352752685547, "_runtime": 10922.385913133621, "_timestamp": 1585608292.0187826, "_step": 435}
{"Episode reward": 53.90138676017485, "Episode length": 461, "Policy Loss": 0.7080519795417786, "Value Loss": 19.587425231933594, "_runtime": 10923.960172891617, "_timestamp": 1585608293.5930424, "_step": 436}
{"Episode reward": -99.81365127498144, "Episode length": 999, "Policy Loss": -0.6521002054214478, "Value Loss": 0.07593811303377151, "_runtime": 10925.502380371094, "_timestamp": 1585608295.1352499, "_step": 437}
{"Episode reward": -99.8397271534647, "Episode length": 999, "Policy Loss": -0.6180900931358337, "Value Loss": 0.08075934648513794, "_runtime": 10927.01114153862, "_timestamp": 1585608296.644011, "_step": 438}
{"Episode reward": -99.86115442374582, "Episode length": 999, "Policy Loss": -0.5565930604934692, "Value Loss": 0.34364697337150574, "_runtime": 10927.92344045639, "_timestamp": 1585608297.55631, "_step": 439}
{"Episode reward": 43.18049142714537, "Episode length": 570, "Policy Loss": 0.6096957921981812, "Value Loss": 16.597410202026367, "_runtime": 10929.485605716705, "_timestamp": 1585608299.1184752, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9976896047592163, "Value Loss": 0.18622305989265442, "_runtime": 10931.053750276566, "_timestamp": 1585608300.6866198, "_step": 441}
{"Episode reward": -99.73171481359611, "Episode length": 999, "Policy Loss": -1.4203407764434814, "Value Loss": 0.1628737598657608, "_runtime": 10932.07164812088, "_timestamp": 1585608301.7045176, "_step": 442}
{"Episode reward": 34.38550158655217, "Episode length": 657, "Policy Loss": -0.9451377391815186, "Value Loss": 13.287293434143066, "_runtime": 10933.642115831375, "_timestamp": 1585608303.2749853, "_step": 443}
{"Episode reward": -99.83514888966316, "Episode length": 999, "Policy Loss": -2.1410458087921143, "Value Loss": 0.10064252465963364, "_runtime": 10934.52585864067, "_timestamp": 1585608304.1587281, "_step": 444}
{"Episode reward": 45.192434478457514, "Episode length": 549, "Policy Loss": -1.1823326349258423, "Value Loss": 15.38084888458252, "_runtime": 10935.317037820816, "_timestamp": 1585608304.9499073, "_step": 445}
{"Episode reward": 48.9912010133262, "Episode length": 511, "Policy Loss": -1.3682754039764404, "Value Loss": 17.85746192932129, "_runtime": 10936.882249593735, "_timestamp": 1585608306.515119, "_step": 446}
{"Episode reward": -99.89608701991243, "Episode length": 999, "Policy Loss": -2.7019598484039307, "Value Loss": 0.22591948509216309, "_runtime": 10938.410633563995, "_timestamp": 1585608308.043503, "_step": 447}
{"Episode reward": -99.54453043378751, "Episode length": 999, "Policy Loss": -2.7402000427246094, "Value Loss": 0.3426617980003357, "_runtime": 10938.926322698593, "_timestamp": 1585608308.5591922, "_step": 448}
{"Episode reward": 68.11401014886779, "Episode length": 319, "Policy Loss": -0.7207865118980408, "Value Loss": 28.37063980102539, "_runtime": 10940.44629740715, "_timestamp": 1585608310.079167, "_step": 449}
{"Episode reward": 2.0996746740316894, "Episode length": 980, "Policy Loss": -2.0036799907684326, "Value Loss": 9.386128425598145, "_runtime": 10942.014087677002, "_timestamp": 1585608311.6469572, "_step": 450}
{"Episode reward": -99.72970851280122, "Episode length": 999, "Policy Loss": -2.610649824142456, "Value Loss": 0.1691703200340271, "_runtime": 10942.497934818268, "_timestamp": 1585608312.1308043, "_step": 451}
{"Episode reward": 69.29999999999984, "Episode length": 307, "Policy Loss": -0.41445350646972656, "Value Loss": 28.916900634765625, "_runtime": 10943.844483852386, "_timestamp": 1585608313.4773533, "_step": 452}
{"Episode reward": 13.100456862222146, "Episode length": 870, "Policy Loss": -1.6026471853256226, "Value Loss": 9.824322700500488, "_runtime": 10945.412274360657, "_timestamp": 1585608315.0451438, "_step": 453}
{"Episode reward": -99.30676936255632, "Episode length": 999, "Policy Loss": -2.247722625732422, "Value Loss": 0.15179546177387238, "_runtime": 10946.912031888962, "_timestamp": 1585608316.5449014, "_step": 454}
{"Episode reward": -99.77467274553935, "Episode length": 999, "Policy Loss": -2.0332581996917725, "Value Loss": 0.10097552835941315, "_runtime": 10948.486209392548, "_timestamp": 1585608318.1190789, "_step": 455}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": -1.2060680389404297, "Value Loss": 8.002169609069824, "_runtime": 10950.0585668087, "_timestamp": 1585608319.6914363, "_step": 456}
{"Episode reward": -99.62608811734106, "Episode length": 999, "Policy Loss": -1.570642352104187, "Value Loss": 0.07337673753499985, "_runtime": 10951.596802711487, "_timestamp": 1585608321.2296722, "_step": 457}
{"Episode reward": -99.81324393087858, "Episode length": 999, "Policy Loss": -1.3809504508972168, "Value Loss": 0.05059008672833443, "_runtime": 10953.16493344307, "_timestamp": 1585608322.797803, "_step": 458}
{"Episode reward": -99.67806295100459, "Episode length": 999, "Policy Loss": -1.1986925601959229, "Value Loss": 0.07617013901472092, "_runtime": 10954.733964443207, "_timestamp": 1585608324.366834, "_step": 459}
{"Episode reward": -99.73859507478635, "Episode length": 999, "Policy Loss": -0.9330918192863464, "Value Loss": 0.29424646496772766, "_runtime": 10956.295786380768, "_timestamp": 1585608325.9286559, "_step": 460}
{"Episode reward": -99.81086294650892, "Episode length": 999, "Policy Loss": -0.8030573725700378, "Value Loss": 0.03132301941514015, "_runtime": 10957.257246017456, "_timestamp": 1585608326.8901155, "_step": 461}
{"Episode reward": 39.78632514690923, "Episode length": 604, "Policy Loss": 0.4274509847164154, "Value Loss": 15.559821128845215, "_runtime": 10958.822443008423, "_timestamp": 1585608328.4553125, "_step": 462}
{"Episode reward": -99.74084754588408, "Episode length": 999, "Policy Loss": -0.3699132800102234, "Value Loss": 0.015576504170894623, "_runtime": 10959.87936592102, "_timestamp": 1585608329.5122354, "_step": 463}
{"Episode reward": 33.299999999999514, "Episode length": 667, "Policy Loss": 0.8102285265922546, "Value Loss": 13.093353271484375, "_runtime": 10961.422659873962, "_timestamp": 1585608331.0555294, "_step": 464}
{"Episode reward": -99.696319966855, "Episode length": 999, "Policy Loss": -0.05451911687850952, "Value Loss": 0.3093015253543854, "_runtime": 10963.004565954208, "_timestamp": 1585608332.6374354, "_step": 465}
{"Episode reward": -99.77628007177124, "Episode length": 999, "Policy Loss": 0.1553134322166443, "Value Loss": 0.07420838624238968, "_runtime": 10964.537548065186, "_timestamp": 1585608334.1704175, "_step": 466}
{"Episode reward": -99.78106268662819, "Episode length": 999, "Policy Loss": 0.29343852400779724, "Value Loss": 0.06413222849369049, "_runtime": 10966.096149921417, "_timestamp": 1585608335.7290194, "_step": 467}
{"Episode reward": -99.72251593686967, "Episode length": 999, "Policy Loss": 0.35932064056396484, "Value Loss": 0.18537868559360504, "_runtime": 10967.670140266418, "_timestamp": 1585608337.3030097, "_step": 468}
{"Episode reward": -99.835980593435, "Episode length": 999, "Policy Loss": 0.4446934759616852, "Value Loss": 0.17537447810173035, "_runtime": 10969.24010515213, "_timestamp": 1585608338.8729746, "_step": 469}
{"Episode reward": -99.79862769925828, "Episode length": 999, "Policy Loss": 0.5841278433799744, "Value Loss": 0.030270837247371674, "_runtime": 10969.895555973053, "_timestamp": 1585608339.5284255, "_step": 470}
{"Episode reward": 60.292034816741655, "Episode length": 398, "Policy Loss": 2.284424066543579, "Value Loss": 20.09959602355957, "_runtime": 10970.885662078857, "_timestamp": 1585608340.5185316, "_step": 471}
{"Episode reward": 37.54734426054577, "Episode length": 626, "Policy Loss": 1.7735404968261719, "Value Loss": 12.907504081726074, "_runtime": 10972.481783151627, "_timestamp": 1585608342.1146526, "_step": 472}
{"Episode reward": -99.701788826006, "Episode length": 999, "Policy Loss": 0.5378400087356567, "Value Loss": 0.08914783596992493, "_runtime": 10973.183563232422, "_timestamp": 1585608342.8164327, "_step": 473}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 1.6684719324111938, "Value Loss": 16.763277053833008, "_runtime": 10973.715010404587, "_timestamp": 1585608343.34788, "_step": 474}
{"Episode reward": 66.9999999999998, "Episode length": 330, "Policy Loss": 2.3019139766693115, "Value Loss": 27.96851921081543, "_runtime": 10975.27909898758, "_timestamp": 1585608344.9119685, "_step": 475}
{"Episode reward": -99.71375742156386, "Episode length": 999, "Policy Loss": 0.16040334105491638, "Value Loss": 0.15530088543891907, "_runtime": 10976.793775081635, "_timestamp": 1585608346.4266446, "_step": 476}
{"Episode reward": -99.82324365116516, "Episode length": 999, "Policy Loss": -0.029893673956394196, "Value Loss": 0.021030709147453308, "_runtime": 10977.776760101318, "_timestamp": 1585608347.4096296, "_step": 477}
{"Episode reward": 34.86060108542385, "Episode length": 652, "Policy Loss": 0.7008779048919678, "Value Loss": 12.073729515075684, "_runtime": 10978.958658218384, "_timestamp": 1585608348.5915277, "_step": 478}
{"Episode reward": 24.424072192702468, "Episode length": 758, "Policy Loss": 0.4693007171154022, "Value Loss": 11.258943557739258, "_runtime": 10979.54219865799, "_timestamp": 1585608349.1750681, "_step": 479}
{"Episode reward": 64.39999999999978, "Episode length": 356, "Policy Loss": 1.4601517915725708, "Value Loss": 25.60654640197754, "_runtime": 10981.067508220673, "_timestamp": 1585608350.7003777, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6853158473968506, "Value Loss": 1.0088716745376587, "_runtime": 10982.611157894135, "_timestamp": 1585608352.2440274, "_step": 481}
{"Episode reward": -99.80961418973608, "Episode length": 999, "Policy Loss": -0.5985472798347473, "Value Loss": 0.20588181912899017, "_runtime": 10983.198469161987, "_timestamp": 1585608352.8313386, "_step": 482}
{"Episode reward": 62.24085259726245, "Episode length": 378, "Policy Loss": 0.9090588092803955, "Value Loss": 22.76105499267578, "_runtime": 10984.745072603226, "_timestamp": 1585608354.377942, "_step": 483}
{"Episode reward": -99.72085390174622, "Episode length": 999, "Policy Loss": -0.4453447461128235, "Value Loss": 0.024206530302762985, "_runtime": 10986.315668344498, "_timestamp": 1585608355.9485378, "_step": 484}
{"Episode reward": -99.53504153455005, "Episode length": 999, "Policy Loss": -0.2698250412940979, "Value Loss": 0.12999844551086426, "_runtime": 10987.82095193863, "_timestamp": 1585608357.4538214, "_step": 485}
{"Episode reward": -99.7317375634783, "Episode length": 999, "Policy Loss": -0.1813565194606781, "Value Loss": 0.019546542316675186, "_runtime": 10988.560859680176, "_timestamp": 1585608358.1937292, "_step": 486}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": 1.1808041334152222, "Value Loss": 16.635326385498047, "_runtime": 10989.607647418976, "_timestamp": 1585608359.240517, "_step": 487}
{"Episode reward": 33.176241515576365, "Episode length": 669, "Policy Loss": 0.9080168008804321, "Value Loss": 12.794177055358887, "_runtime": 10990.447397947311, "_timestamp": 1585608360.0802674, "_step": 488}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 1.1923408508300781, "Value Loss": 16.62034034729004, "_runtime": 10991.964901685715, "_timestamp": 1585608361.5977712, "_step": 489}
{"Episode reward": -99.70655170811666, "Episode length": 999, "Policy Loss": -0.08572594076395035, "Value Loss": 0.15177015960216522, "_runtime": 10993.505263090134, "_timestamp": 1585608363.1381326, "_step": 490}
{"Episode reward": -99.8925043836222, "Episode length": 999, "Policy Loss": -0.18981300294399261, "Value Loss": 0.03431668132543564, "_runtime": 10995.025629281998, "_timestamp": 1585608364.6584988, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30454760789871216, "Value Loss": 0.02601989172399044, "_runtime": 10996.617041110992, "_timestamp": 1585608366.2499106, "_step": 492}
{"Episode reward": -99.81457986831525, "Episode length": 999, "Policy Loss": -0.39186063408851624, "Value Loss": 0.2300339937210083, "_runtime": 10998.18210887909, "_timestamp": 1585608367.8149784, "_step": 493}
{"Episode reward": -99.69997094005673, "Episode length": 999, "Policy Loss": -0.4003854990005493, "Value Loss": 0.3424000144004822, "_runtime": 10999.690153121948, "_timestamp": 1585608369.3230226, "_step": 494}
{"Episode reward": 3.3927949098649464, "Episode length": 969, "Policy Loss": 0.23651768267154694, "Value Loss": 9.88598918914795, "_runtime": 11001.252542495728, "_timestamp": 1585608370.885412, "_step": 495}
{"Episode reward": -99.71553453886742, "Episode length": 999, "Policy Loss": -0.47460079193115234, "Value Loss": 2.773512601852417, "_runtime": 11002.829595804214, "_timestamp": 1585608372.4624653, "_step": 496}
{"Episode reward": -99.86349611291521, "Episode length": 999, "Policy Loss": -0.231683611869812, "Value Loss": 0.13172917068004608, "_runtime": 11003.955928325653, "_timestamp": 1585608373.5887978, "_step": 497}
{"Episode reward": 28.594026116933463, "Episode length": 715, "Policy Loss": 0.8139519691467285, "Value Loss": 13.13981819152832, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234, -2.8917598724365234]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0], "bins": [-211.6160125732422, -208.24815368652344, -204.88027954101562, -201.51242065429688, -198.14456176757812, -194.77670288085938, -191.40882873535156, -188.0409698486328, -184.673095703125, -181.30523681640625, -177.9373779296875, -174.56951904296875, -171.20164489746094, -167.8337860107422, -164.46591186523438, -161.09805297851562, -157.73019409179688, -154.36233520507812, -150.99447631835938, -147.62660217285156, -144.2587432861328, -140.890869140625, -137.52301025390625, -134.1551513671875, -130.78729248046875, -127.41941833496094, -124.05155944824219, -120.6836929321289, -117.31582641601562, -113.94796752929688, -110.5801010131836, -107.21224212646484, -103.84437561035156, -100.47650909423828, -97.10865020751953, -93.74078369140625, -90.3729248046875, -87.00505828857422, -83.63719177246094, -80.26933288574219, -76.90147399902344, -73.53359985351562, -70.16574096679688, -66.79788208007812, -63.43000793457031, -60.06214904785156, -56.69429016113281, -53.326416015625, -49.95855712890625, -46.5906982421875, -43.22282409667969, -39.85496520996094, -36.48710632324219, -33.119232177734375, -29.751373291015625, -26.383514404296875, -23.015640258789062, -19.647781372070312, -16.279922485351562, -12.912063598632812, -9.544189453125, -6.17633056640625, -2.8084716796875, 0.5594024658203125, 3.9272613525390625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0], "bins": [-6.7378764152526855, -6.6318278312683105, -6.525778770446777, -6.419730186462402, -6.313681602478027, -6.207633018493652, -6.101583957672119, -5.995535373687744, -5.889486789703369, -5.783437728881836, -5.677389144897461, -5.571340560913086, -5.465291976928711, -5.359242916107178, -5.253194332122803, -5.1471452713012695, -5.0410966873168945, -4.9350481033325195, -4.8289995193481445, -4.7229509353637695, -4.616901874542236, -4.510853290557861, -4.404804229736328, -4.298755645751953, -4.192707061767578, -4.086658477783203, -3.980609655380249, -3.874560832977295, -3.768512010574341, -3.662463426589966, -3.5564146041870117, -3.4503660202026367, -3.3443171977996826, -3.2382683753967285, -3.1322197914123535, -3.0261709690093994, -2.9201223850250244, -2.8140735626220703, -2.7080249786376953, -2.601975917816162, -2.495927333831787, -2.389878749847412, -2.283830165863037, -2.177781105041504, -2.071732521057129, -1.965683937072754, -1.8596348762512207, -1.7535862922668457, -1.6475377082824707, -1.5414886474609375, -1.4354400634765625, -1.3293914794921875, -1.2233428955078125, -1.1172938346862793, -1.0112452507019043, -0.9051966667175293, -0.7991476058959961, -0.6930990219116211, -0.5870504379272461, -0.4810013771057129, -0.3749527931213379, -0.2689042091369629, -0.1628556251525879, -0.05680656433105469, 0.04924201965332031]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 6.0, 4.0, 5.0, 1.0, 1.0, 4.0, 6.0, 4.0, 1.0, 2.0, 1.0, 3.0, 10.0, 386.0, 1.0, 8.0, 3.0, 10.0, 6.0, 6.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0], "bins": [-25.537900924682617, -25.03950309753418, -24.541105270385742, -24.042709350585938, -23.5443115234375, -23.045913696289062, -22.547515869140625, -22.049118041992188, -21.550722122192383, -21.052324295043945, -20.553926467895508, -20.05552864074707, -19.557132720947266, -19.058734893798828, -18.56033706665039, -18.061939239501953, -17.563541412353516, -17.065143585205078, -16.56674575805664, -16.068349838256836, -15.569952011108398, -15.071555137634277, -14.57315731048584, -14.074759483337402, -13.576362609863281, -13.077964782714844, -12.579567909240723, -12.081170082092285, -11.582772254943848, -11.084375381469727, -10.585977554321289, -10.087580680847168, -9.58918285369873, -9.09078598022461, -8.592388153076172, -8.093990325927734, -7.595592498779297, -7.097196578979492, -6.598798751831055, -6.100400924682617, -5.60200309753418, -5.103605270385742, -4.6052093505859375, -4.1068115234375, -3.6084136962890625, -3.110015869140625, -2.6116180419921875, -2.113222122192383, -1.6148242950439453, -1.1164264678955078, -0.6180286407470703, -0.11963081359863281, 0.3787651062011719, 0.8771629333496094, 1.3755607604980469, 1.8739585876464844, 2.372356414794922, 2.8707523345947266, 3.369150161743164, 3.8675479888916016, 4.365945816040039, 4.864343643188477, 5.362739562988281, 5.861137390136719, 6.359535217285156]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-50.42935562133789, -49.27870178222656, -48.12804412841797, -46.977386474609375, -45.82673263549805, -44.67607879638672, -43.525421142578125, -42.37476348876953, -41.2241096496582, -40.073455810546875, -38.92279815673828, -37.77214050292969, -36.62148666381836, -35.47083282470703, -34.32017517089844, -33.169517517089844, -32.018863677978516, -30.868207931518555, -29.717552185058594, -28.566896438598633, -27.416240692138672, -26.26558494567871, -25.11492919921875, -23.96427345275879, -22.813617706298828, -21.662961959838867, -20.512306213378906, -19.361650466918945, -18.210994720458984, -17.06033706665039, -15.909683227539062, -14.759029388427734, -13.60837173461914, -12.457714080810547, -11.307060241699219, -10.15640640258789, -9.005748748779297, -7.855091094970703, -6.704437255859375, -5.553783416748047, -4.403125762939453, -3.2524681091308594, -2.1018142700195312, -0.9511604309082031, 0.19949722290039062, 1.3501548767089844, 2.5008087158203125, 3.6514625549316406, 4.802120208740234, 5.952777862548828, 7.103431701660156, 8.254085540771484, 9.404743194580078, 10.555400848388672, 11.7060546875, 12.856708526611328, 14.007366180419922, 15.158023834228516, 16.30868148803711, 17.459331512451172, 18.609989166259766, 19.76064682006836, 20.911296844482422, 22.061954498291016, 23.21261215209961]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 13.0, 4.0, 8.0, 8.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0], "bins": [-9.100387573242188, -8.628965377807617, -8.157543182373047, -7.68612003326416, -7.21469783782959, -6.7432756423950195, -6.271852970123291, -5.8004302978515625, -5.329008102416992, -4.857585906982422, -4.386163234710693, -3.914740562438965, -3.4433183670043945, -2.971896171569824, -2.5004734992980957, -2.029050827026367, -1.5576286315917969, -1.0862064361572266, -0.6147842407226562, -0.14336109161376953, 0.3280611038208008, 0.7994832992553711, 1.2709064483642578, 1.7423286437988281, 2.2137508392333984, 2.6851730346679688, 3.156595230102539, 3.628018379211426, 4.099440574645996, 4.570862770080566, 5.042285919189453, 5.513708114624023, 5.985130310058594, 6.456552505493164, 6.927974700927734, 7.399396896362305, 7.870819091796875, 8.342243194580078, 8.813665390014648, 9.285087585449219, 9.756509780883789, 10.22793197631836, 10.69935417175293, 11.1707763671875, 11.642200469970703, 12.113622665405273, 12.585044860839844, 13.056467056274414, 13.527889251708984, 13.999311447143555, 14.470733642578125, 14.942155838012695, 15.413578033447266, 15.885002136230469, 16.35642433166504, 16.82784652709961, 17.29926872253418, 17.77069091796875, 18.24211311340332, 18.71353530883789, 19.184959411621094, 19.656381607055664, 20.127803802490234, 20.599225997924805, 21.070648193359375]}, "_runtime": 11005.212839603424, "_timestamp": 1585608374.845709, "_step": 498}
{"Episode reward": 20.235561752319597, "Episode length": 798, "Policy Loss": 1.247329592704773, "Value Loss": 10.180870056152344, "_runtime": 11005.212839603424, "_timestamp": 1585608374.845709, "_step": 499}
