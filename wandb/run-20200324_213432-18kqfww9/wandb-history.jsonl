{"Episode reward": -99.18921421760524, "Episode length": 999, "Policy Loss": -12.5405912399292, "Value Loss": 0.028337253257632256, "_runtime": 12.33173656463623, "_timestamp": 1585085684.4561505, "_step": 0}
{"Episode reward": -92.04402962725669, "Episode length": 999, "Policy Loss": -11.709892272949219, "Value Loss": 0.024862365797162056, "_runtime": 13.408593893051147, "_timestamp": 1585085685.5330079, "_step": 1}
{"Episode reward": -106.36503337352318, "Episode length": 999, "Policy Loss": -13.915802955627441, "Value Loss": 0.03309174254536629, "_runtime": 14.519497394561768, "_timestamp": 1585085686.6439114, "_step": 2}
{"Episode reward": -100.00881237928634, "Episode length": 999, "Policy Loss": -12.91314697265625, "Value Loss": 0.032241977751255035, "_runtime": 15.631919622421265, "_timestamp": 1585085687.7563336, "_step": 3}
{"Episode reward": -103.89947020656534, "Episode length": 999, "Policy Loss": -13.302840232849121, "Value Loss": 0.030744731426239014, "_runtime": 16.762954711914062, "_timestamp": 1585085688.8873687, "_step": 4}
{"Episode reward": -104.33534912743048, "Episode length": 999, "Policy Loss": -13.492175102233887, "Value Loss": 0.03465339168906212, "_runtime": 17.895864486694336, "_timestamp": 1585085690.0202785, "_step": 5}
{"Episode reward": -104.18275468455973, "Episode length": 999, "Policy Loss": -13.561233520507812, "Value Loss": 0.030479740351438522, "_runtime": 19.117419481277466, "_timestamp": 1585085691.2418334, "_step": 6}
{"Episode reward": -99.40447317954242, "Episode length": 999, "Policy Loss": -12.665033340454102, "Value Loss": 0.028161045163869858, "_runtime": 20.28774070739746, "_timestamp": 1585085692.4121547, "_step": 7}
{"Episode reward": -105.27955883095721, "Episode length": 999, "Policy Loss": -13.691485404968262, "Value Loss": 0.03175511956214905, "_runtime": 21.410561561584473, "_timestamp": 1585085693.5349755, "_step": 8}
{"Episode reward": -104.59920925777955, "Episode length": 999, "Policy Loss": -13.522934913635254, "Value Loss": 0.03265152499079704, "_runtime": 22.592944860458374, "_timestamp": 1585085694.7173588, "_step": 9}
{"Episode reward": -102.75916454921706, "Episode length": 999, "Policy Loss": -13.419781684875488, "Value Loss": 0.032080456614494324, "_runtime": 23.7909517288208, "_timestamp": 1585085695.9153657, "_step": 10}
{"Episode reward": -108.54992891217432, "Episode length": 999, "Policy Loss": -14.283490180969238, "Value Loss": 0.03912096098065376, "_runtime": 24.926687240600586, "_timestamp": 1585085697.0511012, "_step": 11}
{"Episode reward": -103.46386436635136, "Episode length": 999, "Policy Loss": -13.578629493713379, "Value Loss": 0.030464911833405495, "_runtime": 26.084997177124023, "_timestamp": 1585085698.2094111, "_step": 12}
{"Episode reward": -93.69558679409727, "Episode length": 999, "Policy Loss": -11.658907890319824, "Value Loss": 0.02670680359005928, "_runtime": 27.24533700942993, "_timestamp": 1585085699.369751, "_step": 13}
{"Episode reward": -109.36086187774801, "Episode length": 999, "Policy Loss": -14.590513229370117, "Value Loss": 0.034839797765016556, "_runtime": 28.528947591781616, "_timestamp": 1585085700.6533616, "_step": 14}
{"Episode reward": -96.91117424943556, "Episode length": 999, "Policy Loss": -12.593138694763184, "Value Loss": 0.02709089405834675, "_runtime": 29.71989941596985, "_timestamp": 1585085701.8443134, "_step": 15}
{"Episode reward": -97.75957157454847, "Episode length": 999, "Policy Loss": -12.57234001159668, "Value Loss": 0.028551341965794563, "_runtime": 30.99498176574707, "_timestamp": 1585085703.1193957, "_step": 16}
{"Episode reward": -99.59982233466998, "Episode length": 999, "Policy Loss": -12.746294975280762, "Value Loss": 0.032921772450208664, "_runtime": 32.23911476135254, "_timestamp": 1585085704.3635287, "_step": 17}
{"Episode reward": -101.80945391533244, "Episode length": 999, "Policy Loss": -13.049206733703613, "Value Loss": 0.029644247144460678, "_runtime": 33.53370237350464, "_timestamp": 1585085705.6581163, "_step": 18}
{"Episode reward": -96.02800697603074, "Episode length": 999, "Policy Loss": -12.314887046813965, "Value Loss": 0.03056894987821579, "_runtime": 34.767542362213135, "_timestamp": 1585085706.8919563, "_step": 19}
{"Episode reward": -95.57122203967761, "Episode length": 999, "Policy Loss": -12.256820678710938, "Value Loss": 0.026726415380835533, "_runtime": 36.01844906806946, "_timestamp": 1585085708.142863, "_step": 20}
{"Episode reward": -100.6447027409109, "Episode length": 999, "Policy Loss": -12.948265075683594, "Value Loss": 0.03568582609295845, "_runtime": 37.19706082344055, "_timestamp": 1585085709.3214748, "_step": 21}
{"Episode reward": -103.61788408188912, "Episode length": 999, "Policy Loss": -13.54899787902832, "Value Loss": 0.029036380350589752, "_runtime": 38.507651567459106, "_timestamp": 1585085710.6320655, "_step": 22}
{"Episode reward": -99.17351699447035, "Episode length": 999, "Policy Loss": -12.677993774414062, "Value Loss": 0.027580522000789642, "_runtime": 39.87266182899475, "_timestamp": 1585085711.9970758, "_step": 23}
{"Episode reward": -107.04445182614504, "Episode length": 999, "Policy Loss": -14.068421363830566, "Value Loss": 0.03491898626089096, "_runtime": 41.202693462371826, "_timestamp": 1585085713.3271074, "_step": 24}
{"Episode reward": -102.93007744917631, "Episode length": 999, "Policy Loss": -13.532551765441895, "Value Loss": 0.03268417716026306, "_runtime": 42.5194776058197, "_timestamp": 1585085714.6438916, "_step": 25}
{"Episode reward": -108.73702589111039, "Episode length": 999, "Policy Loss": -14.491991996765137, "Value Loss": 0.03567589074373245, "_runtime": 43.95976114273071, "_timestamp": 1585085716.084175, "_step": 26}
{"Episode reward": -102.77574928399999, "Episode length": 999, "Policy Loss": -13.283900260925293, "Value Loss": 0.031176356598734856, "_runtime": 45.26877689361572, "_timestamp": 1585085717.3931909, "_step": 27}
{"Episode reward": -103.4495474926818, "Episode length": 999, "Policy Loss": -13.45703125, "Value Loss": 0.032172854989767075, "_runtime": 46.525190114974976, "_timestamp": 1585085718.649604, "_step": 28}
{"Episode reward": -108.23112316335896, "Episode length": 999, "Policy Loss": -14.25110149383545, "Value Loss": 0.03960752487182617, "_runtime": 48.00636601448059, "_timestamp": 1585085720.13078, "_step": 29}
{"Episode reward": -99.53323269880816, "Episode length": 999, "Policy Loss": -12.809210777282715, "Value Loss": 0.028594493865966797, "_runtime": 49.612576961517334, "_timestamp": 1585085721.736991, "_step": 30}
{"Episode reward": -100.33450582950498, "Episode length": 999, "Policy Loss": -12.701340675354004, "Value Loss": 0.03324973210692406, "_runtime": 51.10219407081604, "_timestamp": 1585085723.226608, "_step": 31}
{"Episode reward": -104.46775379649537, "Episode length": 999, "Policy Loss": -13.514188766479492, "Value Loss": 0.034421924501657486, "_runtime": 52.51938509941101, "_timestamp": 1585085724.643799, "_step": 32}
{"Episode reward": -110.53080335921995, "Episode length": 999, "Policy Loss": -14.723124504089355, "Value Loss": 0.035667479038238525, "_runtime": 54.01912188529968, "_timestamp": 1585085726.1435359, "_step": 33}
{"Episode reward": -101.58857509130078, "Episode length": 999, "Policy Loss": -13.261398315429688, "Value Loss": 0.029966406524181366, "_runtime": 55.48356032371521, "_timestamp": 1585085727.6079743, "_step": 34}
{"Episode reward": -102.5653459473877, "Episode length": 999, "Policy Loss": -13.38586139678955, "Value Loss": 0.03240668773651123, "_runtime": 56.78744339942932, "_timestamp": 1585085728.9118574, "_step": 35}
{"Episode reward": -107.01088571855404, "Episode length": 999, "Policy Loss": -14.064167022705078, "Value Loss": 0.033103033900260925, "_runtime": 58.123340129852295, "_timestamp": 1585085730.247754, "_step": 36}
{"Episode reward": -108.1767255558185, "Episode length": 999, "Policy Loss": -14.361954689025879, "Value Loss": 0.03760986402630806, "_runtime": 59.54488968849182, "_timestamp": 1585085731.6693037, "_step": 37}
{"Episode reward": -98.22982882942694, "Episode length": 999, "Policy Loss": -12.591808319091797, "Value Loss": 0.028696052730083466, "_runtime": 60.91410040855408, "_timestamp": 1585085733.0385144, "_step": 38}
{"Episode reward": -97.85705520111813, "Episode length": 999, "Policy Loss": -12.439728736877441, "Value Loss": 0.02804265171289444, "_runtime": 62.27062773704529, "_timestamp": 1585085734.3950417, "_step": 39}
{"Episode reward": -95.86792666949519, "Episode length": 999, "Policy Loss": -12.035149574279785, "Value Loss": 0.02641955576837063, "_runtime": 63.5112521648407, "_timestamp": 1585085735.6356661, "_step": 40}
{"Episode reward": -104.80408068703807, "Episode length": 999, "Policy Loss": -13.555510520935059, "Value Loss": 0.03346441313624382, "_runtime": 64.74847364425659, "_timestamp": 1585085736.8728876, "_step": 41}
{"Episode reward": -100.11912007723494, "Episode length": 999, "Policy Loss": -12.798213005065918, "Value Loss": 0.03344449773430824, "_runtime": 66.08187341690063, "_timestamp": 1585085738.2062874, "_step": 42}
{"Episode reward": -98.49355963020993, "Episode length": 999, "Policy Loss": -12.538749694824219, "Value Loss": 0.03160571679472923, "_runtime": 67.43168520927429, "_timestamp": 1585085739.5560992, "_step": 43}
{"Episode reward": -103.4012630241624, "Episode length": 999, "Policy Loss": -13.201006889343262, "Value Loss": 0.030676504597067833, "_runtime": 68.76845026016235, "_timestamp": 1585085740.8928642, "_step": 44}
{"Episode reward": -103.80456364295125, "Episode length": 999, "Policy Loss": -13.382919311523438, "Value Loss": 0.031194772571325302, "_runtime": 70.19372582435608, "_timestamp": 1585085742.3181398, "_step": 45}
{"Episode reward": -107.04125476362105, "Episode length": 999, "Policy Loss": -14.26482105255127, "Value Loss": 0.038313593715429306, "_runtime": 71.57644963264465, "_timestamp": 1585085743.7008636, "_step": 46}
{"Episode reward": -99.85708239839413, "Episode length": 999, "Policy Loss": -12.828376770019531, "Value Loss": 0.032197851687669754, "_runtime": 72.94669818878174, "_timestamp": 1585085745.0711122, "_step": 47}
{"Episode reward": -91.46773702653681, "Episode length": 999, "Policy Loss": -11.52295207977295, "Value Loss": 0.027601350098848343, "_runtime": 74.22410845756531, "_timestamp": 1585085746.3485224, "_step": 48}
{"Episode reward": -104.08775741826697, "Episode length": 999, "Policy Loss": -13.7726411819458, "Value Loss": 0.035345423966646194, "_runtime": 75.50781798362732, "_timestamp": 1585085747.632232, "_step": 49}
{"Episode reward": -102.34236452058141, "Episode length": 999, "Policy Loss": -13.094193458557129, "Value Loss": 0.03440278023481369, "_runtime": 76.76913666725159, "_timestamp": 1585085748.8935506, "_step": 50}
{"Episode reward": -94.93518620458892, "Episode length": 999, "Policy Loss": -11.993593215942383, "Value Loss": 0.027542712166905403, "_runtime": 78.17742466926575, "_timestamp": 1585085750.3018386, "_step": 51}
{"Episode reward": -101.89139103363111, "Episode length": 999, "Policy Loss": -13.24255657196045, "Value Loss": 0.034061696380376816, "_runtime": 79.81674242019653, "_timestamp": 1585085751.9411564, "_step": 52}
{"Episode reward": -92.42670532567254, "Episode length": 999, "Policy Loss": -11.711286544799805, "Value Loss": 0.024421650916337967, "_runtime": 81.12998008728027, "_timestamp": 1585085753.254394, "_step": 53}
{"Episode reward": -99.88510400758946, "Episode length": 999, "Policy Loss": -13.111397743225098, "Value Loss": 0.029862357303500175, "_runtime": 82.38245224952698, "_timestamp": 1585085754.5068662, "_step": 54}
{"Episode reward": -99.3450861353808, "Episode length": 999, "Policy Loss": -12.643397331237793, "Value Loss": 0.02818891778588295, "_runtime": 83.66583228111267, "_timestamp": 1585085755.7902462, "_step": 55}
{"Episode reward": -112.24577733772539, "Episode length": 999, "Policy Loss": -15.1294527053833, "Value Loss": 0.03562663123011589, "_runtime": 84.98269891738892, "_timestamp": 1585085757.107113, "_step": 56}
{"Episode reward": -101.7979076537296, "Episode length": 999, "Policy Loss": -13.306517601013184, "Value Loss": 0.031884338706731796, "_runtime": 86.2337327003479, "_timestamp": 1585085758.3581467, "_step": 57}
{"Episode reward": -109.16043047093824, "Episode length": 999, "Policy Loss": -14.595372200012207, "Value Loss": 0.033943310379981995, "_runtime": 87.50610184669495, "_timestamp": 1585085759.6305158, "_step": 58}
{"Episode reward": -98.34290853614783, "Episode length": 999, "Policy Loss": -12.533893585205078, "Value Loss": 0.027297774329781532, "_runtime": 88.78380703926086, "_timestamp": 1585085760.908221, "_step": 59}
{"Episode reward": -109.49992393953407, "Episode length": 999, "Policy Loss": -14.950922012329102, "Value Loss": 0.03759819269180298, "_runtime": 90.19602632522583, "_timestamp": 1585085762.3204403, "_step": 60}
{"Episode reward": -95.09173531087794, "Episode length": 999, "Policy Loss": -12.044023513793945, "Value Loss": 0.029605576768517494, "_runtime": 91.5474591255188, "_timestamp": 1585085763.671873, "_step": 61}
{"Episode reward": -104.43796674766233, "Episode length": 999, "Policy Loss": -13.705463409423828, "Value Loss": 0.03108421340584755, "_runtime": 92.92106938362122, "_timestamp": 1585085765.0454834, "_step": 62}
{"Episode reward": -93.94619802164094, "Episode length": 999, "Policy Loss": -11.89013385772705, "Value Loss": 0.024970771744847298, "_runtime": 94.49656248092651, "_timestamp": 1585085766.6209764, "_step": 63}
{"Episode reward": -95.48034810061507, "Episode length": 999, "Policy Loss": -12.273211479187012, "Value Loss": 0.028022145852446556, "_runtime": 95.84221076965332, "_timestamp": 1585085767.9666247, "_step": 64}
{"Episode reward": -100.31808910323323, "Episode length": 999, "Policy Loss": -12.779544830322266, "Value Loss": 0.03258312866091728, "_runtime": 97.50086784362793, "_timestamp": 1585085769.6252818, "_step": 65}
{"Episode reward": -99.30879005717435, "Episode length": 999, "Policy Loss": -12.96963882446289, "Value Loss": 0.026973487809300423, "_runtime": 98.81572532653809, "_timestamp": 1585085770.9401393, "_step": 66}
{"Episode reward": -95.2694149057862, "Episode length": 999, "Policy Loss": -11.907482147216797, "Value Loss": 0.026084354147315025, "_runtime": 100.43247604370117, "_timestamp": 1585085772.55689, "_step": 67}
{"Episode reward": -92.20856766227318, "Episode length": 999, "Policy Loss": -11.416232109069824, "Value Loss": 0.025401484221220016, "_runtime": 101.69943928718567, "_timestamp": 1585085773.8238533, "_step": 68}
{"Episode reward": -103.46414058805229, "Episode length": 999, "Policy Loss": -13.593401908874512, "Value Loss": 0.03209070861339569, "_runtime": 102.98975133895874, "_timestamp": 1585085775.1141653, "_step": 69}
{"Episode reward": -102.60551230194423, "Episode length": 999, "Policy Loss": -13.594335556030273, "Value Loss": 0.029133062809705734, "_runtime": 104.3015444278717, "_timestamp": 1585085776.4259584, "_step": 70}
{"Episode reward": -103.6196686665537, "Episode length": 999, "Policy Loss": -13.57248306274414, "Value Loss": 0.03148859366774559, "_runtime": 105.56170010566711, "_timestamp": 1585085777.686114, "_step": 71}
{"Episode reward": -98.40269182358274, "Episode length": 999, "Policy Loss": -12.587632179260254, "Value Loss": 0.029450226575136185, "_runtime": 106.86041474342346, "_timestamp": 1585085778.9848287, "_step": 72}
{"Episode reward": -98.36548436944508, "Episode length": 999, "Policy Loss": -12.577997207641602, "Value Loss": 0.030461855232715607, "_runtime": 108.231374502182, "_timestamp": 1585085780.3557885, "_step": 73}
{"Episode reward": -100.98158084901782, "Episode length": 999, "Policy Loss": -12.947335243225098, "Value Loss": 0.030404027551412582, "_runtime": 109.7537271976471, "_timestamp": 1585085781.8781412, "_step": 74}
{"Episode reward": -102.92937205673613, "Episode length": 999, "Policy Loss": -13.541596412658691, "Value Loss": 0.030171949416399002, "_runtime": 111.2265522480011, "_timestamp": 1585085783.3509662, "_step": 75}
{"Episode reward": -98.60762396597048, "Episode length": 999, "Policy Loss": -12.622547149658203, "Value Loss": 0.033143557608127594, "_runtime": 112.51783084869385, "_timestamp": 1585085784.6422448, "_step": 76}
{"Episode reward": -104.17882852367364, "Episode length": 999, "Policy Loss": -13.572463989257812, "Value Loss": 0.030028223991394043, "_runtime": 114.21151185035706, "_timestamp": 1585085786.3359258, "_step": 77}
{"Episode reward": -96.49323187035974, "Episode length": 999, "Policy Loss": -12.351839065551758, "Value Loss": 0.028310369700193405, "_runtime": 115.84364676475525, "_timestamp": 1585085787.9680607, "_step": 78}
{"Episode reward": -107.36894910999845, "Episode length": 999, "Policy Loss": -14.490568161010742, "Value Loss": 0.035211194306612015, "_runtime": 117.3142294883728, "_timestamp": 1585085789.4386435, "_step": 79}
{"Episode reward": -99.57806480747286, "Episode length": 999, "Policy Loss": -12.731497764587402, "Value Loss": 0.030346078798174858, "_runtime": 118.71083807945251, "_timestamp": 1585085790.835252, "_step": 80}
{"Episode reward": -102.28675682972066, "Episode length": 999, "Policy Loss": -13.203603744506836, "Value Loss": 0.030833983793854713, "_runtime": 120.08738231658936, "_timestamp": 1585085792.2117963, "_step": 81}
{"Episode reward": -97.78075889534675, "Episode length": 999, "Policy Loss": -12.606608390808105, "Value Loss": 0.02947782352566719, "_runtime": 121.61547875404358, "_timestamp": 1585085793.7398927, "_step": 82}
{"Episode reward": -105.9333428441049, "Episode length": 999, "Policy Loss": -14.087176322937012, "Value Loss": 0.03201405704021454, "_runtime": 123.03202629089355, "_timestamp": 1585085795.1564403, "_step": 83}
{"Episode reward": -92.26502392481426, "Episode length": 999, "Policy Loss": -11.701810836791992, "Value Loss": 0.025249984115362167, "_runtime": 124.59948229789734, "_timestamp": 1585085796.7238963, "_step": 84}
{"Episode reward": -105.49267195115726, "Episode length": 999, "Policy Loss": -13.894937515258789, "Value Loss": 0.03330459073185921, "_runtime": 125.86280727386475, "_timestamp": 1585085797.9872212, "_step": 85}
{"Episode reward": -104.40965756042267, "Episode length": 999, "Policy Loss": -13.781997680664062, "Value Loss": 0.03394371643662453, "_runtime": 127.12002062797546, "_timestamp": 1585085799.2444346, "_step": 86}
{"Episode reward": -105.451622269299, "Episode length": 999, "Policy Loss": -13.852279663085938, "Value Loss": 0.03306139260530472, "_runtime": 128.3905646800995, "_timestamp": 1585085800.5149786, "_step": 87}
{"Episode reward": -97.9305336172187, "Episode length": 999, "Policy Loss": -12.420706748962402, "Value Loss": 0.029504742473363876, "_runtime": 129.81926798820496, "_timestamp": 1585085801.943682, "_step": 88}
{"Episode reward": -108.5162998947379, "Episode length": 999, "Policy Loss": -14.423157691955566, "Value Loss": 0.03496234863996506, "_runtime": 131.18787360191345, "_timestamp": 1585085803.3122876, "_step": 89}
{"Episode reward": -97.24001126268413, "Episode length": 999, "Policy Loss": -12.292887687683105, "Value Loss": 0.029861915856599808, "_runtime": 132.52413725852966, "_timestamp": 1585085804.6485512, "_step": 90}
{"Episode reward": -105.69001253391299, "Episode length": 999, "Policy Loss": -13.74539566040039, "Value Loss": 0.0320858508348465, "_runtime": 133.89181327819824, "_timestamp": 1585085806.0162272, "_step": 91}
{"Episode reward": -99.64602225272353, "Episode length": 999, "Policy Loss": -12.768610954284668, "Value Loss": 0.031269434839487076, "_runtime": 135.16817545890808, "_timestamp": 1585085807.2925894, "_step": 92}
{"Episode reward": -103.41157742463898, "Episode length": 999, "Policy Loss": -13.698195457458496, "Value Loss": 0.03389178588986397, "_runtime": 136.44255566596985, "_timestamp": 1585085808.5669696, "_step": 93}
{"Episode reward": -105.73005992261777, "Episode length": 999, "Policy Loss": -13.801969528198242, "Value Loss": 0.030998511239886284, "_runtime": 137.84003019332886, "_timestamp": 1585085809.9644442, "_step": 94}
{"Episode reward": -95.88133115099971, "Episode length": 999, "Policy Loss": -11.908955574035645, "Value Loss": 0.026310892775654793, "_runtime": 139.08715105056763, "_timestamp": 1585085811.211565, "_step": 95}
{"Episode reward": -94.56682004994894, "Episode length": 999, "Policy Loss": -12.040903091430664, "Value Loss": 0.027203897014260292, "_runtime": 140.5813057422638, "_timestamp": 1585085812.7057197, "_step": 96}
{"Episode reward": -103.68989423805114, "Episode length": 999, "Policy Loss": -13.654586791992188, "Value Loss": 0.031381234526634216, "_runtime": 141.93194913864136, "_timestamp": 1585085814.056363, "_step": 97}
{"Episode reward": -94.58286787527764, "Episode length": 999, "Policy Loss": -12.130212783813477, "Value Loss": 0.028041448444128036, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375, 535.6556396484375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-298.93878173828125, -286.1777038574219, -273.4166564941406, -260.65557861328125, -247.89451599121094, -235.13345336914062, -222.37237548828125, -209.61131286621094, -196.85025024414062, -184.08917236328125, -171.32810974121094, -158.56704711914062, -145.80596923828125, -133.04490661621094, -120.28384399414062, -107.52276611328125, -94.76170349121094, -82.00064086914062, -69.23956298828125, -56.47850036621094, -43.717437744140625, -30.95635986328125, -18.1953125, -5.434234619140625, 7.32684326171875, 20.087890625, 32.848968505859375, 45.61004638671875, 58.37109375, 71.13217163085938, 83.89324951171875, 96.654296875, 109.41537475585938, 122.17645263671875, 134.9375, 147.69857788085938, 160.45965576171875, 173.220703125, 185.98178100585938, 198.74285888671875, 211.50390625, 224.26495361328125, 237.02606201171875, 249.787109375, 262.54815673828125, 275.30926513671875, 288.0703125, 300.83135986328125, 313.59246826171875, 326.353515625, 339.11456298828125, 351.87567138671875, 364.63671875, 377.39776611328125, 390.15887451171875, 402.919921875, 415.68096923828125, 428.44207763671875, 441.203125, 453.96417236328125, 466.72528076171875, 479.486328125, 492.24737548828125, 505.00848388671875, 517.76953125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-293.640625, -285.0423889160156, -276.44415283203125, -267.8459167480469, -259.2476806640625, -250.64942932128906, -242.05117797851562, -233.45294189453125, -224.85470581054688, -216.2564697265625, -207.65823364257812, -199.0599822998047, -190.4617462158203, -181.86351013183594, -173.2652587890625, -164.66702270507812, -156.06878662109375, -147.47055053710938, -138.872314453125, -130.27406311035156, -121.67582702636719, -113.07759094238281, -104.47933959960938, -95.881103515625, -87.28286743164062, -78.68463134765625, -70.08639526367188, -61.48814392089844, -52.88990783691406, -44.29167175292969, -35.69342041015625, -27.095184326171875, -18.4969482421875, -9.898712158203125, -1.30047607421875, 7.297760009765625, 15.89599609375, 24.4942626953125, 33.092498779296875, 41.69073486328125, 50.288970947265625, 58.88720703125, 67.48544311523438, 76.08367919921875, 84.68194580078125, 93.28018188476562, 101.87841796875, 110.47665405273438, 119.07489013671875, 127.67312622070312, 136.2713623046875, 144.86959838867188, 153.46783447265625, 162.06610107421875, 170.66433715820312, 179.2625732421875, 187.86080932617188, 196.45904541015625, 205.05728149414062, 213.655517578125, 222.2537841796875, 230.85198974609375, 239.45025634765625, 248.0484619140625, 256.646728515625]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 4.0, 7.0, 6.0, 5.0, 8.0, 5.0, 12.0, 11.0, 15.0, 10.0, 13.0, 18.0, 11.0, 25.0, 47.0, 48.0, 40.0, 38.0, 22.0, 29.0, 31.0, 16.0, 15.0, 14.0, 3.0, 7.0, 6.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 5.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-258.4031677246094, -250.83673095703125, -243.27029418945312, -235.703857421875, -228.13742065429688, -220.57098388671875, -213.00454711914062, -205.4381103515625, -197.87167358398438, -190.30523681640625, -182.73880004882812, -175.17236328125, -167.6059112548828, -160.0394744873047, -152.47303771972656, -144.90660095214844, -137.3401641845703, -129.7737274169922, -122.20729064941406, -114.64085388183594, -107.07441711425781, -99.50798034667969, -91.94154357910156, -84.37510681152344, -76.80865478515625, -69.24221801757812, -61.67578125, -54.109344482421875, -46.54290771484375, -38.976470947265625, -31.4100341796875, -23.843597412109375, -16.27716064453125, -8.710723876953125, -1.144287109375, 6.422149658203125, 13.98858642578125, 21.555023193359375, 29.1214599609375, 36.687896728515625, 44.25433349609375, 51.820770263671875, 59.38720703125, 66.95364379882812, 74.52008056640625, 82.08651733398438, 89.6529541015625, 97.21939086914062, 104.78585815429688, 112.352294921875, 119.91873168945312, 127.48516845703125, 135.05160522460938, 142.6180419921875, 150.18447875976562, 157.75091552734375, 165.31735229492188, 172.8837890625, 180.45022583007812, 188.01666259765625, 195.58309936523438, 203.1495361328125, 210.71597290039062, 218.28240966796875, 225.84884643554688]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-112.95104217529297, -107.97522735595703, -102.9994125366211, -98.02359771728516, -93.04778289794922, -88.07196807861328, -83.09614562988281, -78.12033081054688, -73.14451599121094, -68.168701171875, -63.19289016723633, -58.21707534790039, -53.24125671386719, -48.26544189453125, -43.28962707519531, -38.313812255859375, -33.33799743652344, -28.3621826171875, -23.386367797851562, -18.410552978515625, -13.434738159179688, -8.45892333984375, -3.4831085205078125, 1.492706298828125, 6.468528747558594, 11.444343566894531, 16.42015838623047, 21.395973205566406, 26.371788024902344, 31.34760284423828, 36.32341766357422, 41.299232482910156, 46.275047302246094, 51.25086212158203, 56.22667694091797, 61.202491760253906, 66.17830657958984, 71.15412139892578, 76.12993621826172, 81.10575103759766, 86.0815658569336, 91.05738067626953, 96.03319549560547, 101.0090103149414, 105.98482513427734, 110.96063995361328, 115.93645477294922, 120.91226959228516, 125.88809967041016, 130.86392211914062, 135.8397216796875, 140.8155517578125, 145.79135131835938, 150.76715087890625, 155.74298095703125, 160.71878051757812, 165.69461059570312, 170.67041015625, 175.646240234375, 180.62203979492188, 185.59786987304688, 190.57366943359375, 195.54949951171875, 200.52529907226562, 205.50112915039062]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 32.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-135.66619873046875, -132.39549255371094, -129.12478637695312, -125.85408782958984, -122.58338165283203, -119.31267547607422, -116.0419692993164, -112.77127075195312, -109.50056457519531, -106.2298583984375, -102.95915222167969, -99.68844604492188, -96.41773986816406, -93.14704132080078, -89.87633514404297, -86.60563659667969, -83.33493041992188, -80.06422424316406, -76.79351806640625, -73.52281188964844, -70.25210571289062, -66.98140716552734, -63.71070098876953, -60.43999481201172, -57.169288635253906, -53.898582458496094, -50.62788391113281, -47.357177734375, -44.08647155761719, -40.815765380859375, -37.545066833496094, -34.27436065673828, -31.00365447998047, -27.732948303222656, -24.462242126464844, -21.191543579101562, -17.92083740234375, -14.650131225585938, -11.379425048828125, -8.108726501464844, -4.8380126953125, -1.5673065185546875, 1.7033843994140625, 4.974090576171875, 8.244796752929688, 11.5155029296875, 14.786209106445312, 18.056915283203125, 21.327621459960938, 24.59832763671875, 27.869033813476562, 31.139724731445312, 34.410430908203125, 37.68113708496094, 40.95184326171875, 44.22254943847656, 47.493255615234375, 50.76396179199219, 54.03466796875, 57.30537414550781, 60.57606506347656, 63.846771240234375, 67.11747741699219, 70.38818359375, 73.65888977050781]}, "_runtime": 143.1713650226593, "_timestamp": 1585085815.295779, "_step": 98}
{"Episode reward": -98.04093697710124, "Episode length": 999, "Policy Loss": -12.470210075378418, "Value Loss": 0.02597213163971901, "_runtime": 144.81818294525146, "_timestamp": 1585085816.942597, "_step": 99}
{"Episode reward": -101.0406899365768, "Episode length": 999, "Policy Loss": -13.181795120239258, "Value Loss": 0.032307218760252, "_runtime": 146.16773056983948, "_timestamp": 1585085818.2921445, "_step": 100}
{"Episode reward": -94.39094530945178, "Episode length": 999, "Policy Loss": -11.700170516967773, "Value Loss": 0.02752472274005413, "_runtime": 147.34760785102844, "_timestamp": 1585085819.4720218, "_step": 101}
{"Episode reward": -95.50688515518644, "Episode length": 999, "Policy Loss": -12.00820541381836, "Value Loss": 0.026791270822286606, "_runtime": 148.5998637676239, "_timestamp": 1585085820.7242777, "_step": 102}
{"Episode reward": -99.53248263617446, "Episode length": 999, "Policy Loss": -12.696928977966309, "Value Loss": 0.028403809294104576, "_runtime": 149.87650561332703, "_timestamp": 1585085822.0009196, "_step": 103}
{"Episode reward": -104.41504547707986, "Episode length": 999, "Policy Loss": -13.660035133361816, "Value Loss": 0.03152595832943916, "_runtime": 151.22240042686462, "_timestamp": 1585085823.3468144, "_step": 104}
{"Episode reward": -99.86298877092973, "Episode length": 999, "Policy Loss": -12.654336929321289, "Value Loss": 0.03010854311287403, "_runtime": 152.54646372795105, "_timestamp": 1585085824.6708777, "_step": 105}
{"Episode reward": -101.41990052491843, "Episode length": 999, "Policy Loss": -13.030572891235352, "Value Loss": 0.030705248937010765, "_runtime": 154.00339913368225, "_timestamp": 1585085826.127813, "_step": 106}
{"Episode reward": -106.89585108381272, "Episode length": 999, "Policy Loss": -14.122559547424316, "Value Loss": 0.032818153500556946, "_runtime": 155.3494427204132, "_timestamp": 1585085827.4738567, "_step": 107}
{"Episode reward": -105.10186428869117, "Episode length": 999, "Policy Loss": -13.874937057495117, "Value Loss": 0.033590514212846756, "_runtime": 156.60136532783508, "_timestamp": 1585085828.7257793, "_step": 108}
{"Episode reward": -100.83142394660814, "Episode length": 999, "Policy Loss": -12.79869556427002, "Value Loss": 0.028532598167657852, "_runtime": 157.86729168891907, "_timestamp": 1585085829.9917057, "_step": 109}
{"Episode reward": -98.69681449085633, "Episode length": 999, "Policy Loss": -12.521814346313477, "Value Loss": 0.0303672906011343, "_runtime": 159.08229637145996, "_timestamp": 1585085831.2067103, "_step": 110}
{"Episode reward": -96.42166228480137, "Episode length": 999, "Policy Loss": -12.193982124328613, "Value Loss": 0.028050901368260384, "_runtime": 160.3939652442932, "_timestamp": 1585085832.5183792, "_step": 111}
{"Episode reward": -103.90503715614973, "Episode length": 999, "Policy Loss": -13.83102035522461, "Value Loss": 0.03324450924992561, "_runtime": 161.779545545578, "_timestamp": 1585085833.9039595, "_step": 112}
{"Episode reward": -101.54732790679776, "Episode length": 999, "Policy Loss": -13.354866981506348, "Value Loss": 0.03178517147898674, "_runtime": 163.04821753501892, "_timestamp": 1585085835.1726315, "_step": 113}
{"Episode reward": -97.74557533699077, "Episode length": 999, "Policy Loss": -12.44394588470459, "Value Loss": 0.03080814518034458, "_runtime": 164.70067310333252, "_timestamp": 1585085836.825087, "_step": 114}
{"Episode reward": -96.63735924208237, "Episode length": 999, "Policy Loss": -12.25616455078125, "Value Loss": 0.026906132698059082, "_runtime": 165.97055792808533, "_timestamp": 1585085838.094972, "_step": 115}
{"Episode reward": -98.41982688721606, "Episode length": 999, "Policy Loss": -12.622819900512695, "Value Loss": 0.028698433190584183, "_runtime": 167.20309805870056, "_timestamp": 1585085839.327512, "_step": 116}
{"Episode reward": -92.94832461133241, "Episode length": 999, "Policy Loss": -11.62550163269043, "Value Loss": 0.025360802188515663, "_runtime": 168.4105408191681, "_timestamp": 1585085840.5349548, "_step": 117}
{"Episode reward": -108.52059247974069, "Episode length": 999, "Policy Loss": -14.361841201782227, "Value Loss": 0.037336912006139755, "_runtime": 169.69496750831604, "_timestamp": 1585085841.8193815, "_step": 118}
{"Episode reward": -103.30543946715522, "Episode length": 999, "Policy Loss": -13.437067985534668, "Value Loss": 0.03270908072590828, "_runtime": 170.96860313415527, "_timestamp": 1585085843.093017, "_step": 119}
{"Episode reward": -100.06188725789578, "Episode length": 999, "Policy Loss": -12.673965454101562, "Value Loss": 0.03246519714593887, "_runtime": 172.28781700134277, "_timestamp": 1585085844.412231, "_step": 120}
{"Episode reward": -97.045562174148, "Episode length": 999, "Policy Loss": -12.333985328674316, "Value Loss": 0.03107612207531929, "_runtime": 173.56865620613098, "_timestamp": 1585085845.6930702, "_step": 121}
{"Episode reward": -95.72790422511267, "Episode length": 999, "Policy Loss": -11.90416431427002, "Value Loss": 0.029098689556121826, "_runtime": 174.83901190757751, "_timestamp": 1585085846.9634259, "_step": 122}
{"Episode reward": -109.48868030255643, "Episode length": 999, "Policy Loss": -14.543152809143066, "Value Loss": 0.034461621195077896, "_runtime": 176.09371304512024, "_timestamp": 1585085848.218127, "_step": 123}
{"Episode reward": -94.47517293268238, "Episode length": 999, "Policy Loss": -12.029594421386719, "Value Loss": 0.02907702326774597, "_runtime": 177.3966932296753, "_timestamp": 1585085849.5211072, "_step": 124}
{"Episode reward": -97.70055285132902, "Episode length": 999, "Policy Loss": -12.395074844360352, "Value Loss": 0.027872737497091293, "_runtime": 178.63796186447144, "_timestamp": 1585085850.7623758, "_step": 125}
{"Episode reward": -100.81763062628951, "Episode length": 999, "Policy Loss": -12.952564239501953, "Value Loss": 0.03008889965713024, "_runtime": 179.95221161842346, "_timestamp": 1585085852.0766256, "_step": 126}
{"Episode reward": -98.9611383967944, "Episode length": 999, "Policy Loss": -12.713578224182129, "Value Loss": 0.027842586860060692, "_runtime": 181.46089053153992, "_timestamp": 1585085853.5853045, "_step": 127}
{"Episode reward": -104.29410268746838, "Episode length": 999, "Policy Loss": -13.579270362854004, "Value Loss": 0.03386859595775604, "_runtime": 182.76033544540405, "_timestamp": 1585085854.8847494, "_step": 128}
{"Episode reward": -109.46788689528067, "Episode length": 999, "Policy Loss": -14.254158020019531, "Value Loss": 0.0356983058154583, "_runtime": 184.0750105381012, "_timestamp": 1585085856.1994245, "_step": 129}
{"Episode reward": -97.17263898252199, "Episode length": 999, "Policy Loss": -12.441414833068848, "Value Loss": 0.02800215221941471, "_runtime": 185.40153050422668, "_timestamp": 1585085857.5259445, "_step": 130}
{"Episode reward": -104.36451627368159, "Episode length": 999, "Policy Loss": -13.698122024536133, "Value Loss": 0.0352979451417923, "_runtime": 186.68685102462769, "_timestamp": 1585085858.811265, "_step": 131}
{"Episode reward": -100.23920527745227, "Episode length": 999, "Policy Loss": -12.9954833984375, "Value Loss": 0.03195095434784889, "_runtime": 187.93701696395874, "_timestamp": 1585085860.061431, "_step": 132}
{"Episode reward": -101.18400213697177, "Episode length": 999, "Policy Loss": -13.257119178771973, "Value Loss": 0.031205080449581146, "_runtime": 189.25519800186157, "_timestamp": 1585085861.379612, "_step": 133}
{"Episode reward": -94.03304210843825, "Episode length": 999, "Policy Loss": -11.783883094787598, "Value Loss": 0.028307130560278893, "_runtime": 190.76551580429077, "_timestamp": 1585085862.8899298, "_step": 134}
{"Episode reward": -104.13717130641386, "Episode length": 999, "Policy Loss": -13.6231689453125, "Value Loss": 0.033030059188604355, "_runtime": 192.284038066864, "_timestamp": 1585085864.408452, "_step": 135}
{"Episode reward": -104.04166136308554, "Episode length": 999, "Policy Loss": -13.37003231048584, "Value Loss": 0.03117801807820797, "_runtime": 193.5208547115326, "_timestamp": 1585085865.6452687, "_step": 136}
{"Episode reward": -109.5647573155702, "Episode length": 999, "Policy Loss": -14.433308601379395, "Value Loss": 0.035131048411130905, "_runtime": 194.9555320739746, "_timestamp": 1585085867.079946, "_step": 137}
{"Episode reward": -102.03438836385594, "Episode length": 999, "Policy Loss": -13.212346076965332, "Value Loss": 0.028861001133918762, "_runtime": 196.37681603431702, "_timestamp": 1585085868.50123, "_step": 138}
{"Episode reward": -97.88789992751148, "Episode length": 999, "Policy Loss": -12.232354164123535, "Value Loss": 0.028704926371574402, "_runtime": 197.7039988040924, "_timestamp": 1585085869.8284128, "_step": 139}
{"Episode reward": -102.16723856204355, "Episode length": 999, "Policy Loss": -13.466164588928223, "Value Loss": 0.030459605157375336, "_runtime": 198.95352220535278, "_timestamp": 1585085871.0779362, "_step": 140}
{"Episode reward": -104.66030936308294, "Episode length": 999, "Policy Loss": -14.088454246520996, "Value Loss": 0.03060813806951046, "_runtime": 200.30149960517883, "_timestamp": 1585085872.4259136, "_step": 141}
{"Episode reward": -107.3859175535089, "Episode length": 999, "Policy Loss": -14.205809593200684, "Value Loss": 0.03476457670331001, "_runtime": 201.5885934829712, "_timestamp": 1585085873.7130075, "_step": 142}
{"Episode reward": -104.38597501103139, "Episode length": 999, "Policy Loss": -13.606633186340332, "Value Loss": 0.03321574628353119, "_runtime": 202.8619315624237, "_timestamp": 1585085874.9863455, "_step": 143}
{"Episode reward": -96.65687891820906, "Episode length": 999, "Policy Loss": -12.243439674377441, "Value Loss": 0.02675248123705387, "_runtime": 204.41512942314148, "_timestamp": 1585085876.5395434, "_step": 144}
{"Episode reward": -100.93831372324468, "Episode length": 999, "Policy Loss": -12.910482406616211, "Value Loss": 0.03087090328335762, "_runtime": 205.69153785705566, "_timestamp": 1585085877.8159518, "_step": 145}
{"Episode reward": -98.14762408585173, "Episode length": 999, "Policy Loss": -12.529279708862305, "Value Loss": 0.030981462448835373, "_runtime": 206.99406242370605, "_timestamp": 1585085879.1184764, "_step": 146}
{"Episode reward": -98.90572266814026, "Episode length": 999, "Policy Loss": -12.41248607635498, "Value Loss": 0.029742715880274773, "_runtime": 208.25728750228882, "_timestamp": 1585085880.3817015, "_step": 147}
{"Episode reward": -99.67263352433542, "Episode length": 999, "Policy Loss": -12.714282989501953, "Value Loss": 0.029316971078515053, "_runtime": 209.45084381103516, "_timestamp": 1585085881.5752578, "_step": 148}
{"Episode reward": -1.1455986869920594, "Episode length": 905, "Policy Loss": 1.543897032737732, "Value Loss": 11.105791091918945, "_runtime": 210.6817388534546, "_timestamp": 1585085882.8061528, "_step": 149}
{"Episode reward": -108.91265952738657, "Episode length": 999, "Policy Loss": -14.171263694763184, "Value Loss": 0.036187686026096344, "_runtime": 212.01189017295837, "_timestamp": 1585085884.1363041, "_step": 150}
{"Episode reward": -98.79057683290091, "Episode length": 999, "Policy Loss": -12.363415718078613, "Value Loss": 0.027968278154730797, "_runtime": 213.24165058135986, "_timestamp": 1585085885.3660645, "_step": 151}
{"Episode reward": -102.69063865055405, "Episode length": 999, "Policy Loss": -13.158112525939941, "Value Loss": 0.028993651270866394, "_runtime": 214.7598226070404, "_timestamp": 1585085886.8842366, "_step": 152}
{"Episode reward": -102.80320296392641, "Episode length": 999, "Policy Loss": -13.52017879486084, "Value Loss": 0.0313945896923542, "_runtime": 216.17639327049255, "_timestamp": 1585085888.3008072, "_step": 153}
{"Episode reward": -102.90192175112165, "Episode length": 999, "Policy Loss": -13.209620475769043, "Value Loss": 0.028661450371146202, "_runtime": 217.513845205307, "_timestamp": 1585085889.6382592, "_step": 154}
{"Episode reward": -103.27623630963114, "Episode length": 999, "Policy Loss": -13.259943962097168, "Value Loss": 0.031161146238446236, "_runtime": 218.82207679748535, "_timestamp": 1585085890.9464908, "_step": 155}
{"Episode reward": -102.80123998347936, "Episode length": 999, "Policy Loss": -13.449563980102539, "Value Loss": 0.03186895698308945, "_runtime": 220.1100971698761, "_timestamp": 1585085892.2345111, "_step": 156}
{"Episode reward": -99.89759444396807, "Episode length": 999, "Policy Loss": -12.868642807006836, "Value Loss": 0.029064452275633812, "_runtime": 221.37277913093567, "_timestamp": 1585085893.497193, "_step": 157}
{"Episode reward": -93.39300485173419, "Episode length": 999, "Policy Loss": -11.697525978088379, "Value Loss": 0.02516816183924675, "_runtime": 222.64973998069763, "_timestamp": 1585085894.774154, "_step": 158}
{"Episode reward": -101.38225303443966, "Episode length": 999, "Policy Loss": -13.049137115478516, "Value Loss": 0.02971808798611164, "_runtime": 223.8836019039154, "_timestamp": 1585085896.0080159, "_step": 159}
{"Episode reward": -107.03883940419091, "Episode length": 999, "Policy Loss": -14.309243202209473, "Value Loss": 0.03284606337547302, "_runtime": 225.2211422920227, "_timestamp": 1585085897.3455563, "_step": 160}
{"Episode reward": -89.96706076516463, "Episode length": 999, "Policy Loss": -11.11033821105957, "Value Loss": 0.02548813447356224, "_runtime": 226.57032775878906, "_timestamp": 1585085898.6947417, "_step": 161}
{"Episode reward": -98.59095266499389, "Episode length": 999, "Policy Loss": -12.725680351257324, "Value Loss": 0.030881764367222786, "_runtime": 228.14362049102783, "_timestamp": 1585085900.2680345, "_step": 162}
{"Episode reward": -98.31198398362041, "Episode length": 999, "Policy Loss": -12.368096351623535, "Value Loss": 0.02983054146170616, "_runtime": 229.7246732711792, "_timestamp": 1585085901.8490872, "_step": 163}
{"Episode reward": -103.73903731582622, "Episode length": 999, "Policy Loss": -13.180118560791016, "Value Loss": 0.034163616597652435, "_runtime": 230.95326709747314, "_timestamp": 1585085903.077681, "_step": 164}
{"Episode reward": -94.85621454187145, "Episode length": 999, "Policy Loss": -11.801426887512207, "Value Loss": 0.02775951288640499, "_runtime": 232.2442169189453, "_timestamp": 1585085904.368631, "_step": 165}
{"Episode reward": -107.148844589162, "Episode length": 999, "Policy Loss": -14.110027313232422, "Value Loss": 0.033539436757564545, "_runtime": 233.46428036689758, "_timestamp": 1585085905.5886943, "_step": 166}
{"Episode reward": -96.42893954147354, "Episode length": 999, "Policy Loss": -12.092669486999512, "Value Loss": 0.026532843708992004, "_runtime": 234.75859355926514, "_timestamp": 1585085906.8830075, "_step": 167}
{"Episode reward": -103.01162589982567, "Episode length": 999, "Policy Loss": -13.452746391296387, "Value Loss": 0.029393041506409645, "_runtime": 236.2904028892517, "_timestamp": 1585085908.4148169, "_step": 168}
{"Episode reward": -102.03157773962643, "Episode length": 999, "Policy Loss": -13.396806716918945, "Value Loss": 0.030960720032453537, "_runtime": 237.61315250396729, "_timestamp": 1585085909.7375665, "_step": 169}
{"Episode reward": -104.54325043857753, "Episode length": 999, "Policy Loss": -13.546289443969727, "Value Loss": 0.03228151425719261, "_runtime": 238.94559717178345, "_timestamp": 1585085911.0700111, "_step": 170}
{"Episode reward": -96.14591166360263, "Episode length": 999, "Policy Loss": -12.395676612854004, "Value Loss": 0.029988056048750877, "_runtime": 240.27851271629333, "_timestamp": 1585085912.4029267, "_step": 171}
{"Episode reward": -92.79555663394005, "Episode length": 999, "Policy Loss": -11.634779930114746, "Value Loss": 0.02772500179708004, "_runtime": 241.60204696655273, "_timestamp": 1585085913.726461, "_step": 172}
{"Episode reward": -100.01533568209028, "Episode length": 999, "Policy Loss": -12.699012756347656, "Value Loss": 0.03161075711250305, "_runtime": 242.839684009552, "_timestamp": 1585085914.964098, "_step": 173}
{"Episode reward": -94.8508751017506, "Episode length": 999, "Policy Loss": -12.018436431884766, "Value Loss": 0.02640390396118164, "_runtime": 244.12766242027283, "_timestamp": 1585085916.2520764, "_step": 174}
{"Episode reward": -110.94148251056934, "Episode length": 999, "Policy Loss": -14.725272178649902, "Value Loss": 0.03549046814441681, "_runtime": 245.46545386314392, "_timestamp": 1585085917.5898678, "_step": 175}
{"Episode reward": -104.21737811673597, "Episode length": 999, "Policy Loss": -13.384581565856934, "Value Loss": 0.032783668488264084, "_runtime": 246.75097036361694, "_timestamp": 1585085918.8753843, "_step": 176}
{"Episode reward": -93.7477959050035, "Episode length": 999, "Policy Loss": -11.748101234436035, "Value Loss": 0.02644742652773857, "_runtime": 248.03455328941345, "_timestamp": 1585085920.1589673, "_step": 177}
{"Episode reward": -93.77255037127865, "Episode length": 999, "Policy Loss": -11.737222671508789, "Value Loss": 0.02768351323902607, "_runtime": 249.56005811691284, "_timestamp": 1585085921.684472, "_step": 178}
{"Episode reward": -95.81850173299104, "Episode length": 999, "Policy Loss": -12.09145450592041, "Value Loss": 0.029851319268345833, "_runtime": 250.87323904037476, "_timestamp": 1585085922.997653, "_step": 179}
{"Episode reward": -100.32917802743137, "Episode length": 999, "Policy Loss": -12.760854721069336, "Value Loss": 0.03391135856509209, "_runtime": 252.23263502120972, "_timestamp": 1585085924.357049, "_step": 180}
{"Episode reward": -100.32917802743137, "Episode length": 999, "Policy Loss": -12.760854721069336, "Value Loss": 0.03391135856509209, "_runtime": 252.23263502120972, "_timestamp": 1585085924.357049, "_step": 180}
