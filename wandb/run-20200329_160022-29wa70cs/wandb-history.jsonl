{"Episode reward": -46.667045014860655, "Episode length": 999, "Policy Loss": -0.038449257612228394, "Value Loss": 0.016686294227838516, "_runtime": 19.30984592437744, "_timestamp": 1585497641.6179447, "_step": 0}
{"Episode reward": -18052.7287283394, "Episode length": 999, "Policy Loss": -72.14793395996094, "Value Loss": 1293.9139404296875, "_runtime": 20.75273561477661, "_timestamp": 1585497643.0608344, "_step": 1}
{"Episode reward": -99.86564300688562, "Episode length": 999, "Policy Loss": -108.35398864746094, "Value Loss": 1083.678466796875, "_runtime": 22.229624032974243, "_timestamp": 1585497644.5377228, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 158.7562255859375, "Value Loss": 11627.8837890625, "_runtime": 23.735232830047607, "_timestamp": 1585497646.0433316, "_step": 3}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 25.241629123687744, "_timestamp": 1585497647.549728, "_step": 4}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 26.771913051605225, "_timestamp": 1585497649.0800118, "_step": 5}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 28.308080434799194, "_timestamp": 1585497650.6161792, "_step": 6}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 29.82815933227539, "_timestamp": 1585497652.1362581, "_step": 7}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 31.374925136566162, "_timestamp": 1585497653.683024, "_step": 8}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 32.91067838668823, "_timestamp": 1585497655.2187772, "_step": 9}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 34.45178246498108, "_timestamp": 1585497656.7598813, "_step": 10}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 36.00961399078369, "_timestamp": 1585497658.3177128, "_step": 11}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 37.56245422363281, "_timestamp": 1585497659.870553, "_step": 12}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 39.11315083503723, "_timestamp": 1585497661.4212496, "_step": 13}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 40.698869705200195, "_timestamp": 1585497663.0069685, "_step": 14}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 42.25381374359131, "_timestamp": 1585497664.5619125, "_step": 15}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 43.80750799179077, "_timestamp": 1585497666.1156068, "_step": 16}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 45.36028695106506, "_timestamp": 1585497667.6683857, "_step": 17}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 46.92198657989502, "_timestamp": 1585497669.2300854, "_step": 18}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 48.46978163719177, "_timestamp": 1585497670.7778804, "_step": 19}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 50.027910470962524, "_timestamp": 1585497672.3360093, "_step": 20}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 51.5869460105896, "_timestamp": 1585497673.8950448, "_step": 21}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 53.135985136032104, "_timestamp": 1585497675.444084, "_step": 22}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 54.69319295883179, "_timestamp": 1585497677.0012918, "_step": 23}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 56.262943267822266, "_timestamp": 1585497678.571042, "_step": 24}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 57.816617488861084, "_timestamp": 1585497680.1247163, "_step": 25}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 59.38057565689087, "_timestamp": 1585497681.6886744, "_step": 26}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 60.932321310043335, "_timestamp": 1585497683.24042, "_step": 27}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 62.476837396621704, "_timestamp": 1585497684.7849362, "_step": 28}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 64.02895879745483, "_timestamp": 1585497686.3370576, "_step": 29}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 65.6124017238617, "_timestamp": 1585497687.9205005, "_step": 30}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 67.1555187702179, "_timestamp": 1585497689.4636176, "_step": 31}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 68.69948387145996, "_timestamp": 1585497691.0075827, "_step": 32}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 70.24077892303467, "_timestamp": 1585497692.5488777, "_step": 33}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 71.78254127502441, "_timestamp": 1585497694.09064, "_step": 34}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 73.33385825157166, "_timestamp": 1585497695.641957, "_step": 35}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 74.87631344795227, "_timestamp": 1585497697.1844122, "_step": 36}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 76.42852973937988, "_timestamp": 1585497698.7366285, "_step": 37}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 77.98655152320862, "_timestamp": 1585497700.2946503, "_step": 38}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 79.54342699050903, "_timestamp": 1585497701.8515258, "_step": 39}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 81.09715008735657, "_timestamp": 1585497703.4052489, "_step": 40}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 82.6459527015686, "_timestamp": 1585497704.9540515, "_step": 41}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 84.19989824295044, "_timestamp": 1585497706.507997, "_step": 42}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 85.75333213806152, "_timestamp": 1585497708.061431, "_step": 43}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 87.30247688293457, "_timestamp": 1585497709.6105757, "_step": 44}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 88.86212182044983, "_timestamp": 1585497711.1702206, "_step": 45}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 90.41686511039734, "_timestamp": 1585497712.724964, "_step": 46}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 92.00412273406982, "_timestamp": 1585497714.3122215, "_step": 47}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 93.55991458892822, "_timestamp": 1585497715.8680134, "_step": 48}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 95.11710333824158, "_timestamp": 1585497717.4252021, "_step": 49}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 96.67319512367249, "_timestamp": 1585497718.981294, "_step": 50}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 98.22041749954224, "_timestamp": 1585497720.5285163, "_step": 51}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 99.77590489387512, "_timestamp": 1585497722.0840037, "_step": 52}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 101.31891179084778, "_timestamp": 1585497723.6270106, "_step": 53}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 102.85339784622192, "_timestamp": 1585497725.1614966, "_step": 54}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 104.38466906547546, "_timestamp": 1585497726.6927679, "_step": 55}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 105.94473242759705, "_timestamp": 1585497728.2528312, "_step": 56}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 107.51291942596436, "_timestamp": 1585497729.8210182, "_step": 57}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 109.05721998214722, "_timestamp": 1585497731.3653188, "_step": 58}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 110.61894202232361, "_timestamp": 1585497732.9270408, "_step": 59}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 112.18330883979797, "_timestamp": 1585497734.4914076, "_step": 60}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 113.74997782707214, "_timestamp": 1585497736.0580766, "_step": 61}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 115.31420969963074, "_timestamp": 1585497737.6223085, "_step": 62}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 116.88339495658875, "_timestamp": 1585497739.1914937, "_step": 63}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 118.45425152778625, "_timestamp": 1585497740.7623503, "_step": 64}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 120.06613564491272, "_timestamp": 1585497742.3742344, "_step": 65}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 121.6213264465332, "_timestamp": 1585497743.9294252, "_step": 66}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 123.1901605129242, "_timestamp": 1585497745.4982593, "_step": 67}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 124.759108543396, "_timestamp": 1585497747.0672073, "_step": 68}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 126.32860279083252, "_timestamp": 1585497748.6367016, "_step": 69}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 127.90205407142639, "_timestamp": 1585497750.2101529, "_step": 70}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 129.45974779129028, "_timestamp": 1585497751.7678466, "_step": 71}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 131.01523447036743, "_timestamp": 1585497753.3233333, "_step": 72}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 132.5728120803833, "_timestamp": 1585497754.8809109, "_step": 73}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 134.14597535133362, "_timestamp": 1585497756.4540741, "_step": 74}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 135.71037912368774, "_timestamp": 1585497758.018478, "_step": 75}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 137.2690052986145, "_timestamp": 1585497759.577104, "_step": 76}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 138.83450293540955, "_timestamp": 1585497761.1426017, "_step": 77}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 140.3938388824463, "_timestamp": 1585497762.7019377, "_step": 78}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 141.94999027252197, "_timestamp": 1585497764.258089, "_step": 79}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 143.5273892879486, "_timestamp": 1585497765.835488, "_step": 80}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 145.08537340164185, "_timestamp": 1585497767.3934722, "_step": 81}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 146.67977595329285, "_timestamp": 1585497768.9878747, "_step": 82}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 148.25312781333923, "_timestamp": 1585497770.5612266, "_step": 83}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 149.8129642009735, "_timestamp": 1585497772.121063, "_step": 84}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 151.38652539253235, "_timestamp": 1585497773.6946242, "_step": 85}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 152.95585775375366, "_timestamp": 1585497775.2639565, "_step": 86}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 154.52671718597412, "_timestamp": 1585497776.834816, "_step": 87}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 156.08958077430725, "_timestamp": 1585497778.3976796, "_step": 88}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 157.66061329841614, "_timestamp": 1585497779.968712, "_step": 89}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 159.23136615753174, "_timestamp": 1585497781.539465, "_step": 90}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 160.7990436553955, "_timestamp": 1585497783.1071424, "_step": 91}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 162.36680150032043, "_timestamp": 1585497784.6749003, "_step": 92}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 163.93410086631775, "_timestamp": 1585497786.2421997, "_step": 93}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 165.50571823120117, "_timestamp": 1585497787.813817, "_step": 94}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 167.07579445838928, "_timestamp": 1585497789.3838933, "_step": 95}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 168.63398551940918, "_timestamp": 1585497790.9420843, "_step": 96}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 170.20288252830505, "_timestamp": 1585497792.5109813, "_step": 97}
{"Episode reward": NaN, "Episode length": 999, "Policy Loss": NaN, "Value Loss": NaN, "_runtime": 170.20288252830505, "_timestamp": 1585497792.5109813, "_step": 98}
