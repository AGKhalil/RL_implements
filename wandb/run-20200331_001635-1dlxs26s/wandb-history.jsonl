{"Episode reward": -43.500314122066285, "Episode length": 999, "Policy Loss": -0.02445106953382492, "Value Loss": 0.005610023159533739, "_runtime": 16445.20219707489, "_timestamp": 1585613814.8350666, "_step": 0}
{"Episode reward": -96.75343036853629, "Episode length": 999, "Policy Loss": -0.8904611468315125, "Value Loss": 310.9028015136719, "_runtime": 16446.755754470825, "_timestamp": 1585613816.388624, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 37.777069091796875, "Value Loss": 3493.706787109375, "_runtime": 16447.55418729782, "_timestamp": 1585613817.1870568, "_step": 2}
{"Episode reward": 58.04257462310171, "Episode length": 475, "Policy Loss": 29.150676727294922, "Value Loss": 51199.62109375, "_runtime": 16447.768889427185, "_timestamp": 1585613817.401759, "_step": 3}
{"Episode reward": 91.48413900666279, "Episode length": 93, "Policy Loss": 221.16030883789062, "Value Loss": 11302.677734375, "_runtime": 16449.333332061768, "_timestamp": 1585613818.9662015, "_step": 4}
{"Episode reward": -93.00112440430183, "Episode length": 999, "Policy Loss": 2.4827733039855957, "Value Loss": 128.9303436279297, "_runtime": 16450.883755922318, "_timestamp": 1585613820.5166254, "_step": 5}
{"Episode reward": -94.21845502373178, "Episode length": 999, "Policy Loss": 1.2754358053207397, "Value Loss": 255.70350646972656, "_runtime": 16452.44802927971, "_timestamp": 1585613822.0808988, "_step": 6}
{"Episode reward": -97.16890143226344, "Episode length": 999, "Policy Loss": 1.1303406953811646, "Value Loss": 221.911865234375, "_runtime": 16454.034324645996, "_timestamp": 1585613823.6671941, "_step": 7}
{"Episode reward": -97.4763648166175, "Episode length": 999, "Policy Loss": 4.789525508880615, "Value Loss": 378.78173828125, "_runtime": 16455.62675857544, "_timestamp": 1585613825.259628, "_step": 8}
{"Episode reward": -97.40615861350366, "Episode length": 999, "Policy Loss": 1.809470534324646, "Value Loss": 186.9630126953125, "_runtime": 16457.193990707397, "_timestamp": 1585613826.8268602, "_step": 9}
{"Episode reward": -97.34813608910632, "Episode length": 999, "Policy Loss": -0.867384135723114, "Value Loss": 78.35201263427734, "_runtime": 16458.791692256927, "_timestamp": 1585613828.4245617, "_step": 10}
{"Episode reward": -96.53964351068004, "Episode length": 999, "Policy Loss": -2.8877973556518555, "Value Loss": 150.7457275390625, "_runtime": 16460.379361629486, "_timestamp": 1585613830.012231, "_step": 11}
{"Episode reward": -97.36814656198236, "Episode length": 999, "Policy Loss": 0.9219419360160828, "Value Loss": 21.12640380859375, "_runtime": 16461.955740451813, "_timestamp": 1585613831.58861, "_step": 12}
{"Episode reward": -97.88555427468717, "Episode length": 999, "Policy Loss": 0.017407333478331566, "Value Loss": 4.567079544067383, "_runtime": 16463.566169023514, "_timestamp": 1585613833.1990385, "_step": 13}
{"Episode reward": -98.2375824424283, "Episode length": 999, "Policy Loss": -0.19426685571670532, "Value Loss": 1.1143630743026733, "_runtime": 16465.171651363373, "_timestamp": 1585613834.8045208, "_step": 14}
{"Episode reward": -98.93984012929631, "Episode length": 999, "Policy Loss": -0.19610601663589478, "Value Loss": 2.706010341644287, "_runtime": 16466.27646803856, "_timestamp": 1585613835.9093375, "_step": 15}
{"Episode reward": 31.609928324893886, "Episode length": 687, "Policy Loss": 0.7885207533836365, "Value Loss": 14.956672668457031, "_runtime": 16467.882586717606, "_timestamp": 1585613837.5154562, "_step": 16}
{"Episode reward": -99.75181433115947, "Episode length": 999, "Policy Loss": -0.3670196831226349, "Value Loss": 0.4100049138069153, "_runtime": 16468.505533218384, "_timestamp": 1585613838.1384027, "_step": 17}
{"Episode reward": 63.75309455655491, "Episode length": 363, "Policy Loss": 0.240481898188591, "Value Loss": 3240.598876953125, "_runtime": 16468.874716997147, "_timestamp": 1585613838.5075865, "_step": 18}
{"Episode reward": 78.63567816230932, "Episode length": 215, "Policy Loss": 3.1350557804107666, "Value Loss": 91.55916595458984, "_runtime": 16470.467677116394, "_timestamp": 1585613840.1005466, "_step": 19}
{"Episode reward": -99.85640001749131, "Episode length": 999, "Policy Loss": -0.16704805195331573, "Value Loss": 54.37027359008789, "_runtime": 16471.441848039627, "_timestamp": 1585613841.0747175, "_step": 20}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.5755807161331177, "Value Loss": 45.06694793701172, "_runtime": 16472.959969997406, "_timestamp": 1585613842.5928395, "_step": 21}
{"Episode reward": -99.75323522707775, "Episode length": 999, "Policy Loss": -0.17041657865047455, "Value Loss": 13.252602577209473, "_runtime": 16473.861344337463, "_timestamp": 1585613843.4942138, "_step": 22}
{"Episode reward": 44.97217315153634, "Episode length": 551, "Policy Loss": 1.1298227310180664, "Value Loss": 18.138425827026367, "_runtime": 16474.60414457321, "_timestamp": 1585613844.237014, "_step": 23}
{"Episode reward": 53.293168687424235, "Episode length": 468, "Policy Loss": 1.3071238994598389, "Value Loss": 52.12353515625, "_runtime": 16476.175383090973, "_timestamp": 1585613845.8082526, "_step": 24}
{"Episode reward": -99.80482931742304, "Episode length": 999, "Policy Loss": -0.16991503536701202, "Value Loss": 0.0006172775174491107, "_runtime": 16477.73952293396, "_timestamp": 1585613847.3723924, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15023650228977203, "Value Loss": 0.00048296540626324713, "_runtime": 16478.75226855278, "_timestamp": 1585613848.385138, "_step": 26}
{"Episode reward": 37.73720550592928, "Episode length": 624, "Policy Loss": 0.9973149299621582, "Value Loss": 16.019779205322266, "_runtime": 16480.344310998917, "_timestamp": 1585613849.9771805, "_step": 27}
{"Episode reward": -99.45076424970038, "Episode length": 999, "Policy Loss": -0.11752814054489136, "Value Loss": 0.0003213313757441938, "_runtime": 16481.934861183167, "_timestamp": 1585613851.5677307, "_step": 28}
{"Episode reward": -99.7307095871293, "Episode length": 999, "Policy Loss": -0.1076497733592987, "Value Loss": 0.00024283523089252412, "_runtime": 16483.499567508698, "_timestamp": 1585613853.132437, "_step": 29}
{"Episode reward": -99.8248643812011, "Episode length": 999, "Policy Loss": -0.09567119181156158, "Value Loss": 0.00018449606432113796, "_runtime": 16485.10269999504, "_timestamp": 1585613854.7355695, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08276829868555069, "Value Loss": 0.00013842653424944729, "_runtime": 16486.703848600388, "_timestamp": 1585613856.336718, "_step": 31}
{"Episode reward": -99.6622142482768, "Episode length": 999, "Policy Loss": -0.0707821175456047, "Value Loss": 0.00011858486686833203, "_runtime": 16488.2995159626, "_timestamp": 1585613857.9323854, "_step": 32}
{"Episode reward": -99.81154315555328, "Episode length": 999, "Policy Loss": -0.06230832636356354, "Value Loss": 8.357344631804153e-05, "_runtime": 16489.899713516235, "_timestamp": 1585613859.532583, "_step": 33}
{"Episode reward": -99.78366937592952, "Episode length": 999, "Policy Loss": -0.052766162902116776, "Value Loss": 6.434401439037174e-05, "_runtime": 16491.504915952682, "_timestamp": 1585613861.1377854, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04453640431165695, "Value Loss": 3.943769843317568e-05, "_runtime": 16493.11385154724, "_timestamp": 1585613862.746721, "_step": 35}
{"Episode reward": -99.71070065656538, "Episode length": 999, "Policy Loss": -0.03624388575553894, "Value Loss": 4.280880239093676e-05, "_runtime": 16494.215491056442, "_timestamp": 1585613863.8483605, "_step": 36}
{"Episode reward": 31.350941334548025, "Episode length": 688, "Policy Loss": 0.9929642081260681, "Value Loss": 14.533702850341797, "_runtime": 16495.81801009178, "_timestamp": 1585613865.4508796, "_step": 37}
{"Episode reward": -99.830668272682, "Episode length": 999, "Policy Loss": -0.024071382358670235, "Value Loss": 1.439565221517114e-05, "_runtime": 16496.350676059723, "_timestamp": 1585613865.9835455, "_step": 38}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 2.2975263595581055, "Value Loss": 33.11074447631836, "_runtime": 16497.801225423813, "_timestamp": 1585613867.434095, "_step": 39}
{"Episode reward": 7.764481987758586, "Episode length": 924, "Policy Loss": 0.7388520836830139, "Value Loss": 10.821950912475586, "_runtime": 16499.418203115463, "_timestamp": 1585613869.0510726, "_step": 40}
{"Episode reward": -99.61065818937355, "Episode length": 999, "Policy Loss": -0.017325887456536293, "Value Loss": 3.373656727490015e-05, "_runtime": 16500.957397699356, "_timestamp": 1585613870.5902672, "_step": 41}
{"Episode reward": -99.69424387039479, "Episode length": 999, "Policy Loss": -0.018405836075544357, "Value Loss": 2.250490251753945e-05, "_runtime": 16502.55235171318, "_timestamp": 1585613872.1852212, "_step": 42}
{"Episode reward": -99.77702028846696, "Episode length": 999, "Policy Loss": -0.019034085795283318, "Value Loss": 1.171714120573597e-05, "_runtime": 16503.390438318253, "_timestamp": 1585613873.0233078, "_step": 43}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": 1.4338610172271729, "Value Loss": 20.788860321044922, "_runtime": 16504.97117638588, "_timestamp": 1585613874.6040459, "_step": 44}
{"Episode reward": -99.72420610101406, "Episode length": 999, "Policy Loss": -0.02089705318212509, "Value Loss": 2.319057057320606e-05, "_runtime": 16506.567028284073, "_timestamp": 1585613876.1998978, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024694515392184258, "Value Loss": 1.1728193385351915e-05, "_runtime": 16508.104305267334, "_timestamp": 1585613877.7371747, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0266860444098711, "Value Loss": 1.3628447959490586e-05, "_runtime": 16509.6951816082, "_timestamp": 1585613879.328051, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02872411161661148, "Value Loss": 1.5423134755110368e-05, "_runtime": 16511.304096221924, "_timestamp": 1585613880.9369657, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030032765120267868, "Value Loss": 1.7107202438637614e-05, "_runtime": 16512.013209581375, "_timestamp": 1585613881.646079, "_step": 49}
{"Episode reward": 57.596153048332454, "Episode length": 425, "Policy Loss": 2.0105974674224854, "Value Loss": 23.52741813659668, "_runtime": 16513.6072807312, "_timestamp": 1585613883.2401502, "_step": 50}
{"Episode reward": -99.80109122404689, "Episode length": 999, "Policy Loss": -0.034722812473773956, "Value Loss": 3.243121682316996e-05, "_runtime": 16515.21459889412, "_timestamp": 1585613884.8474684, "_step": 51}
{"Episode reward": -99.85529961141152, "Episode length": 999, "Policy Loss": -0.03843361511826515, "Value Loss": 3.0043962397030555e-05, "_runtime": 16516.74883890152, "_timestamp": 1585613886.3817084, "_step": 52}
{"Episode reward": -99.75818349458139, "Episode length": 999, "Policy Loss": -0.04165928065776825, "Value Loss": 4.33878849435132e-05, "_runtime": 16517.77134346962, "_timestamp": 1585613887.404213, "_step": 53}
{"Episode reward": 37.293034130986165, "Episode length": 629, "Policy Loss": 1.2208614349365234, "Value Loss": 15.896357536315918, "_runtime": 16519.364498853683, "_timestamp": 1585613888.9973683, "_step": 54}
{"Episode reward": -99.77390003884072, "Episode length": 999, "Policy Loss": -0.048773493617773056, "Value Loss": 5.190842421143316e-05, "_runtime": 16520.95854997635, "_timestamp": 1585613890.5914195, "_step": 55}
{"Episode reward": -99.81691556805605, "Episode length": 999, "Policy Loss": -0.05310117080807686, "Value Loss": 5.8853667724179104e-05, "_runtime": 16522.494777679443, "_timestamp": 1585613892.1276472, "_step": 56}
{"Episode reward": 1.7885778575217302, "Episode length": 983, "Policy Loss": 0.6851580739021301, "Value Loss": 10.171418190002441, "_runtime": 16524.092257261276, "_timestamp": 1585613893.7251267, "_step": 57}
{"Episode reward": -99.81704887486855, "Episode length": 999, "Policy Loss": -0.059234652668237686, "Value Loss": 7.53875938244164e-05, "_runtime": 16525.669061899185, "_timestamp": 1585613895.3019314, "_step": 58}
{"Episode reward": -99.89129321956867, "Episode length": 999, "Policy Loss": -0.06557072699069977, "Value Loss": 7.885408558649942e-05, "_runtime": 16526.214034318924, "_timestamp": 1585613895.8469038, "_step": 59}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 2.13373064994812, "Value Loss": 31.53992462158203, "_runtime": 16527.836518526077, "_timestamp": 1585613897.469388, "_step": 60}
{"Episode reward": -99.74226202014695, "Episode length": 999, "Policy Loss": -0.0743868425488472, "Value Loss": 0.00011195505067007616, "_runtime": 16529.44285583496, "_timestamp": 1585613899.0757253, "_step": 61}
{"Episode reward": -99.71431093290309, "Episode length": 999, "Policy Loss": -0.0806647539138794, "Value Loss": 0.00013733886589761823, "_runtime": 16530.283552885056, "_timestamp": 1585613899.9164224, "_step": 62}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": 1.2900691032409668, "Value Loss": 18.210739135742188, "_runtime": 16531.241480112076, "_timestamp": 1585613900.8743496, "_step": 63}
{"Episode reward": 41.13086377941016, "Episode length": 589, "Policy Loss": 1.1310254335403442, "Value Loss": 16.987564086914062, "_runtime": 16532.8446059227, "_timestamp": 1585613902.4774754, "_step": 64}
{"Episode reward": -99.76276197973499, "Episode length": 999, "Policy Loss": -0.10290739685297012, "Value Loss": 0.00020333639986347407, "_runtime": 16533.33897805214, "_timestamp": 1585613902.9718475, "_step": 65}
{"Episode reward": 70.14297832846627, "Episode length": 299, "Policy Loss": 2.3268439769744873, "Value Loss": 33.43492889404297, "_runtime": 16534.20093345642, "_timestamp": 1585613903.833803, "_step": 66}
{"Episode reward": 44.73020755937272, "Episode length": 553, "Policy Loss": 1.2349343299865723, "Value Loss": 18.077434539794922, "_runtime": 16535.79789209366, "_timestamp": 1585613905.4307616, "_step": 67}
{"Episode reward": -99.66707536745677, "Episode length": 999, "Policy Loss": -0.13133777678012848, "Value Loss": 0.0003450559452176094, "_runtime": 16536.895627737045, "_timestamp": 1585613906.5284972, "_step": 68}
{"Episode reward": 28.07844008164811, "Episode length": 720, "Policy Loss": 0.8563946485519409, "Value Loss": 13.88376235961914, "_runtime": 16537.26998925209, "_timestamp": 1585613906.9028587, "_step": 69}
{"Episode reward": 77.79999999999995, "Episode length": 222, "Policy Loss": 3.097245931625366, "Value Loss": 45.02617645263672, "_runtime": 16538.85592031479, "_timestamp": 1585613908.4887898, "_step": 70}
{"Episode reward": -99.80001163801504, "Episode length": 999, "Policy Loss": -0.17069299519062042, "Value Loss": 0.0005606359336525202, "_runtime": 16540.399208068848, "_timestamp": 1585613910.0320776, "_step": 71}
{"Episode reward": -99.82194977402547, "Episode length": 999, "Policy Loss": -0.1868574321269989, "Value Loss": 0.0006533972918987274, "_runtime": 16541.911509037018, "_timestamp": 1585613911.5443785, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2011593133211136, "Value Loss": 0.0007422142662107944, "_runtime": 16543.509797096252, "_timestamp": 1585613913.1426666, "_step": 73}
{"Episode reward": -99.82100507952133, "Episode length": 999, "Policy Loss": -0.2107086479663849, "Value Loss": 0.0008284774958156049, "_runtime": 16545.1034719944, "_timestamp": 1585613914.7363415, "_step": 74}
{"Episode reward": -99.82042726613442, "Episode length": 999, "Policy Loss": -0.22034886479377747, "Value Loss": 0.0009055995033122599, "_runtime": 16546.649936676025, "_timestamp": 1585613916.2828062, "_step": 75}
{"Episode reward": -99.84858389496664, "Episode length": 999, "Policy Loss": -0.22926682233810425, "Value Loss": 0.0009728999575600028, "_runtime": 16548.130217075348, "_timestamp": 1585613917.7630866, "_step": 76}
{"Episode reward": 8.082589427289562, "Episode length": 920, "Policy Loss": 0.5372962355613708, "Value Loss": 10.863604545593262, "_runtime": 16549.732884645462, "_timestamp": 1585613919.3657541, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2376009225845337, "Value Loss": 0.0011015929048880935, "_runtime": 16551.348161935806, "_timestamp": 1585613920.9810314, "_step": 78}
{"Episode reward": -99.68174488972734, "Episode length": 999, "Policy Loss": -0.25072816014289856, "Value Loss": 0.0011601323494687676, "_runtime": 16552.733993768692, "_timestamp": 1585613922.3668633, "_step": 79}
{"Episode reward": 13.48620883328904, "Episode length": 867, "Policy Loss": 0.5730581879615784, "Value Loss": 11.527213096618652, "_runtime": 16554.325797080994, "_timestamp": 1585613923.9586666, "_step": 80}
{"Episode reward": -99.74647887721518, "Episode length": 999, "Policy Loss": -0.25846627354621887, "Value Loss": 0.0012670347932726145, "_runtime": 16555.55278658867, "_timestamp": 1585613925.185656, "_step": 81}
{"Episode reward": 23.032823323900914, "Episode length": 771, "Policy Loss": 0.7736107110977173, "Value Loss": 12.96207332611084, "_runtime": 16557.13853287697, "_timestamp": 1585613926.7714024, "_step": 82}
{"Episode reward": -99.5670696106551, "Episode length": 999, "Policy Loss": -0.2649102210998535, "Value Loss": 0.00137394480407238, "_runtime": 16558.39135146141, "_timestamp": 1585613928.024221, "_step": 83}
{"Episode reward": 21.809123793849892, "Episode length": 784, "Policy Loss": 0.6484467387199402, "Value Loss": 12.746888160705566, "_runtime": 16559.969398975372, "_timestamp": 1585613929.6022685, "_step": 84}
{"Episode reward": -99.56848645618165, "Episode length": 999, "Policy Loss": -0.27449697256088257, "Value Loss": 0.001479289960116148, "_runtime": 16560.626048326492, "_timestamp": 1585613930.2589178, "_step": 85}
{"Episode reward": 61.20309976671679, "Episode length": 389, "Policy Loss": 2.539074182510376, "Value Loss": 25.688413619995117, "_runtime": 16561.311794042587, "_timestamp": 1585613930.9446635, "_step": 86}
{"Episode reward": 58.299999999999685, "Episode length": 417, "Policy Loss": 1.4381285905838013, "Value Loss": 23.963228225708008, "_runtime": 16562.897189617157, "_timestamp": 1585613932.530059, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3056929409503937, "Value Loss": 0.0017092219786718488, "_runtime": 16564.437245845795, "_timestamp": 1585613934.0701153, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31545427441596985, "Value Loss": 0.0018017550464719534, "_runtime": 16565.976508140564, "_timestamp": 1585613935.6093776, "_step": 89}
{"Episode reward": -99.72499756554468, "Episode length": 999, "Policy Loss": -0.3149898946285248, "Value Loss": 0.0018803321290761232, "_runtime": 16566.608135461807, "_timestamp": 1585613936.241005, "_step": 90}
{"Episode reward": 63.099122265144004, "Episode length": 371, "Policy Loss": 1.574716567993164, "Value Loss": 26.9323673248291, "_runtime": 16568.186604976654, "_timestamp": 1585613937.8194745, "_step": 91}
{"Episode reward": -99.83707430362561, "Episode length": 999, "Policy Loss": -0.33662962913513184, "Value Loss": 0.0020440088119357824, "_runtime": 16569.67547273636, "_timestamp": 1585613939.3083422, "_step": 92}
{"Episode reward": 6.763348149881793, "Episode length": 933, "Policy Loss": 0.4222909212112427, "Value Loss": 10.71034049987793, "_runtime": 16571.196541070938, "_timestamp": 1585613940.8294106, "_step": 93}
{"Episode reward": 1.00000000000135, "Episode length": 990, "Policy Loss": 0.3896719813346863, "Value Loss": 10.093693733215332, "_runtime": 16572.804072856903, "_timestamp": 1585613942.4369423, "_step": 94}
{"Episode reward": -99.84691171387537, "Episode length": 999, "Policy Loss": -0.3545006513595581, "Value Loss": 0.0023145268205553293, "_runtime": 16573.727804660797, "_timestamp": 1585613943.3606741, "_step": 95}
{"Episode reward": 43.06794857226143, "Episode length": 571, "Policy Loss": 0.8973943591117859, "Value Loss": 17.498355865478516, "_runtime": 16575.333703279495, "_timestamp": 1585613944.9665728, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3660329282283783, "Value Loss": 0.00249248999170959, "_runtime": 16576.904404878616, "_timestamp": 1585613946.5372744, "_step": 97}
{"Episode reward": 2.0494275898452656, "Episode length": 983, "Policy Loss": 0.3544205129146576, "Value Loss": 10.165205955505371, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533, 0.006893955636769533]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006893955636769533, -0.0024450100027024746, 0.002003935631364584, 0.0064528812654316425, 0.010901827365159988, 0.015350773930549622, 0.019799718633294106, 0.02424866333603859, 0.028697609901428223, 0.033146556466817856, 0.03759550303220749, 0.042044445872306824, 0.04649339243769646, 0.05094233900308609, 0.055391281843185425, 0.059840232133865356, 0.06428917497396469, 0.06873811781406403, 0.07318706810474396, 0.07763601094484329, 0.08208496123552322, 0.08653390407562256, 0.0909828469157219, 0.09543179720640182, 0.09988074004650116, 0.1043296828866005, 0.10877863317728043, 0.11322757601737976, 0.1176765188574791, 0.12212546914815903, 0.12657441198825836, 0.1310233473777771, 0.13547229766845703, 0.13992124795913696, 0.1443701833486557, 0.14881913363933563, 0.15326808393001556, 0.1577170193195343, 0.16216596961021423, 0.16661491990089417, 0.1710638701915741, 0.17551280558109283, 0.17996175587177277, 0.1844107061624527, 0.18885964155197144, 0.19330859184265137, 0.1977575421333313, 0.20220647752285004, 0.20665542781352997, 0.2111043781042099, 0.21555331349372864, 0.22000226378440857, 0.2244512140750885, 0.22890014946460724, 0.23334909975528717, 0.2377980500459671, 0.24224698543548584, 0.24669593572616577, 0.2511448860168457, 0.25559383630752563, 0.26004278659820557, 0.2644917070865631, 0.26894065737724304, 0.273389607667923, 0.2778385579586029]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.012635013088583946, -0.012222628109157085, -0.011810243129730225, -0.01139785721898079, -0.010985472239553928, -0.010573087260127068, -0.010160701349377632, -0.009748316369950771, -0.00933593139052391, -0.00892354641109705, -0.008511161431670189, -0.008098775520920753, -0.007686390541493893, -0.007274005562067032, -0.006861620116978884, -0.006449234671890736, -0.006036849692463875, -0.005624464713037014, -0.005212079267948866, -0.004799693822860718, -0.004387308843433857, -0.003974923864006996, -0.0035625379532575607, -0.0031501529738307, -0.002737767994403839, -0.0023253830149769783, -0.0019129980355501175, -0.001500612124800682, -0.0010882271453738213, -0.0006758421659469604, -0.000263456255197525, 0.00014892872422933578, 0.0005613137036561966, 0.0009736986830830574, 0.0013860836625099182, 0.0017984695732593536, 0.0022108545526862144, 0.0026232395321130753, 0.0030356254428625107, 0.003448009490966797, 0.0038603954017162323, 0.004272781312465668, 0.004685165360569954, 0.005097551271319389, 0.005509937182068825, 0.005922321230173111, 0.006334707140922546, 0.006747091189026833, 0.007159477099776268, 0.007571863010525703, 0.00798424705862999, 0.008396632969379425, 0.008809017017483711, 0.009221402928233147, 0.009633788838982582, 0.010046172887086868, 0.010458558797836304, 0.01087094470858574, 0.011283328756690025, 0.01169571466743946, 0.012108100578188896, 0.012520484626293182, 0.012932870537042618, 0.013345254585146904, 0.01375764049589634]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 14.0, 6.0, 13.0, 22.0, 9.0, 7.0, 16.0, 25.0, 25.0, 226.0, 25.0, 8.0, 3.0, 7.0, 10.0, 6.0, 4.0, 14.0, 13.0, 8.0, 6.0, 10.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.03926364704966545, -0.037980057299137115, -0.03669647127389908, -0.03541288152337074, -0.03412929177284241, -0.03284570574760437, -0.031562115997076035, -0.030278528109192848, -0.028994940221309662, -0.027711352333426476, -0.02642776444554329, -0.025144174695014954, -0.023860586807131767, -0.02257699891924858, -0.021293409168720245, -0.02000982128083706, -0.018726233392953873, -0.017442645505070686, -0.0161590576171875, -0.014875467866659164, -0.013591879978775978, -0.012308292090892792, -0.011024702340364456, -0.00974111445248127, -0.008457526564598083, -0.007173936814069748, -0.005890350788831711, -0.004606761038303375, -0.0033231712877750397, -0.0020395852625370026, -0.000755995512008667, 0.0005275905132293701, 0.0018111802637577057, 0.0030947700142860413, 0.004378356039524078, 0.005661945790052414, 0.006945531815290451, 0.008229121565818787, 0.009512711316347122, 0.01079629734158516, 0.012079887092113495, 0.01336347684264183, 0.014647062867879868, 0.015930652618408203, 0.01721424236893654, 0.018497828394174576, 0.01978141814470291, 0.02106500416994095, 0.022348593920469284, 0.02363217994570732, 0.024915773421525955, 0.026199359446763992, 0.02748294547200203, 0.028766538947820663, 0.0300501249730587, 0.03133371099829674, 0.03261730447411537, 0.03390089049935341, 0.035184476524591446, 0.03646806254982948, 0.03775165602564812, 0.039035242050886154, 0.04031882807612419, 0.041602421551942825, 0.04288600757718086]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07011986523866653, -0.06701081246137619, -0.06390175968408585, -0.0607927031815052, -0.05768365040421486, -0.054574597626924515, -0.05146554112434387, -0.04835648834705353, -0.045247435569763184, -0.04213838279247284, -0.039029330015182495, -0.03592027351260185, -0.03281122073531151, -0.029702167958021164, -0.02659311145544052, -0.023484058678150177, -0.020375005900859833, -0.01726595312356949, -0.014156900346279144, -0.011047843843698502, -0.007938791066408157, -0.004829734563827515, -0.0017206817865371704, 0.0013883709907531738, 0.004497423768043518, 0.007606476545333862, 0.010715529322624207, 0.01382458209991455, 0.016933642327785492, 0.020042695105075836, 0.02315174788236618, 0.026260800659656525, 0.02936985343694687, 0.03247890621423721, 0.03558795899152756, 0.0386970117688179, 0.041806064546108246, 0.04491512477397919, 0.04802417755126953, 0.051133230328559875, 0.05424228310585022, 0.05735134333372116, 0.060460396111011505, 0.06356944888830185, 0.0666785016655922, 0.06978755444288254, 0.07289660722017288, 0.07600565999746323, 0.07911471277475357, 0.08222376555204391, 0.08533281832933426, 0.0884418711066246, 0.09155092388391495, 0.09465997666120529, 0.09776902943849564, 0.10087808221578598, 0.10398714989423752, 0.10709620267152786, 0.1102052554488182, 0.11331430822610855, 0.1164233610033989, 0.11953241378068924, 0.12264146655797958, 0.12575051188468933, 0.12885957956314087]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0], "bins": [-0.024621283635497093, -0.02385980635881424, -0.023098330944776535, -0.02233685553073883, -0.021575378254055977, -0.020813900977373123, -0.02005242556333542, -0.019290950149297714, -0.01852947287261486, -0.017767995595932007, -0.017006520181894302, -0.016245044767856598, -0.015483567491173744, -0.014722091145813465, -0.013960614800453186, -0.013199138455092907, -0.012437662109732628, -0.011676185764372349, -0.01091470941901207, -0.01015323307365179, -0.009391756728291512, -0.008630281314253807, -0.007868804037570953, -0.0071073267608881, -0.006345851346850395, -0.005584375932812691, -0.004822898656129837, -0.004061421379446983, -0.003299945965409279, -0.0025384705513715744, -0.0017769932746887207, -0.001015515998005867, -0.00025404058396816254, 0.0005074348300695419, 0.0012689121067523956, 0.0020303893834352493, 0.002791864797472954, 0.0035533402115106583, 0.004314817488193512, 0.005076294764876366, 0.00583777017891407, 0.006599245592951775, 0.007360721006989479, 0.008122200146317482, 0.008883675560355186, 0.009645150974392891, 0.010406630113720894, 0.011168105527758598, 0.011929580941796303, 0.012691056355834007, 0.013452531769871712, 0.014214010909199715, 0.014975486323237419, 0.015736961737275124, 0.016498440876603127, 0.01725991629064083, 0.018021391704678535, 0.01878286711871624, 0.019544342532753944, 0.020305821672081947, 0.021067297086119652, 0.021828772500157356, 0.02259025163948536, 0.023351727053523064, 0.024113202467560768]}, "_runtime": 16578.460749149323, "_timestamp": 1585613948.0936186, "_step": 98}
{"Episode reward": -99.74160588849196, "Episode length": 999, "Policy Loss": -0.37564975023269653, "Value Loss": 0.0026534597855061293, "_runtime": 16579.273812294006, "_timestamp": 1585613948.9066818, "_step": 99}
{"Episode reward": 50.20879715026779, "Episode length": 498, "Policy Loss": 1.119054913520813, "Value Loss": 20.062097549438477, "_runtime": 16580.57692360878, "_timestamp": 1585613950.209793, "_step": 100}
{"Episode reward": 19.092853508890002, "Episode length": 810, "Policy Loss": 0.6462790369987488, "Value Loss": 12.33538818359375, "_runtime": 16581.59767460823, "_timestamp": 1585613951.230544, "_step": 101}
{"Episode reward": 35.899999999999366, "Episode length": 641, "Policy Loss": 0.9986742734909058, "Value Loss": 15.586679458618164, "_runtime": 16582.372050523758, "_timestamp": 1585613952.00492, "_step": 102}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 1.2770625352859497, "Value Loss": 20.30582046508789, "_runtime": 16583.60174369812, "_timestamp": 1585613953.2346132, "_step": 103}
{"Episode reward": 22.58589627109481, "Episode length": 775, "Policy Loss": 0.5410634875297546, "Value Loss": 12.891829490661621, "_runtime": 16584.189709186554, "_timestamp": 1585613953.8225787, "_step": 104}
{"Episode reward": 64.12150823017559, "Episode length": 359, "Policy Loss": 1.6645551919937134, "Value Loss": 27.82625389099121, "_runtime": 16585.726612329483, "_timestamp": 1585613955.3594818, "_step": 105}
{"Episode reward": -99.70164673721744, "Episode length": 999, "Policy Loss": -0.42963868379592896, "Value Loss": 0.003544376464560628, "_runtime": 16587.159461259842, "_timestamp": 1585613956.7923307, "_step": 106}
{"Episode reward": 8.782871550392343, "Episode length": 914, "Policy Loss": 0.3663831651210785, "Value Loss": 10.93129825592041, "_runtime": 16588.693146944046, "_timestamp": 1585613958.3260164, "_step": 107}
{"Episode reward": -99.70962420934671, "Episode length": 999, "Policy Loss": -0.4623810350894928, "Value Loss": 0.0038860372733324766, "_runtime": 16589.084679365158, "_timestamp": 1585613958.7175488, "_step": 108}
{"Episode reward": 78.69999999999997, "Episode length": 213, "Policy Loss": 3.03964900970459, "Value Loss": 46.89273452758789, "_runtime": 16590.387165784836, "_timestamp": 1585613960.0200353, "_step": 109}
{"Episode reward": 18.0122809525583, "Episode length": 820, "Policy Loss": 0.3912971317768097, "Value Loss": 12.183425903320312, "_runtime": 16591.971048116684, "_timestamp": 1585613961.6039176, "_step": 110}
{"Episode reward": -99.774460300243, "Episode length": 999, "Policy Loss": -0.4957660734653473, "Value Loss": 0.004521713126450777, "_runtime": 16593.32290506363, "_timestamp": 1585613962.9557745, "_step": 111}
{"Episode reward": 11.255455129966904, "Episode length": 888, "Policy Loss": 0.3830737769603729, "Value Loss": 11.250497817993164, "_runtime": 16594.910382270813, "_timestamp": 1585613964.5432518, "_step": 112}
{"Episode reward": -99.87113991714874, "Episode length": 999, "Policy Loss": -0.5119832754135132, "Value Loss": 0.00494407257065177, "_runtime": 16596.500534057617, "_timestamp": 1585613966.1334035, "_step": 113}
{"Episode reward": -99.83673688704008, "Episode length": 999, "Policy Loss": -0.528318464756012, "Value Loss": 0.00511034345254302, "_runtime": 16598.06387400627, "_timestamp": 1585613967.6967435, "_step": 114}
{"Episode reward": -99.89568359786504, "Episode length": 999, "Policy Loss": -0.536665678024292, "Value Loss": 0.0052451686933636665, "_runtime": 16599.71445083618, "_timestamp": 1585613969.3473203, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5407541394233704, "Value Loss": 0.005340348929166794, "_runtime": 16601.31832766533, "_timestamp": 1585613970.9511971, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5430221557617188, "Value Loss": 0.005401466973125935, "_runtime": 16602.900613069534, "_timestamp": 1585613972.5334826, "_step": 117}
{"Episode reward": -99.70850150957564, "Episode length": 999, "Policy Loss": -0.5418009757995605, "Value Loss": 0.005421672482043505, "_runtime": 16604.234679222107, "_timestamp": 1585613973.8675487, "_step": 118}
{"Episode reward": 16.974255755229834, "Episode length": 834, "Policy Loss": 0.40995851159095764, "Value Loss": 11.9781494140625, "_runtime": 16605.851455450058, "_timestamp": 1585613975.484325, "_step": 119}
{"Episode reward": -99.73125954642752, "Episode length": 999, "Policy Loss": -0.5454854369163513, "Value Loss": 0.005440565291792154, "_runtime": 16606.466002464294, "_timestamp": 1585613976.098872, "_step": 120}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.5467456579208374, "Value Loss": 27.139293670654297, "_runtime": 16607.12102842331, "_timestamp": 1585613976.753898, "_step": 121}
{"Episode reward": 59.5999999999997, "Episode length": 404, "Policy Loss": 1.517898440361023, "Value Loss": 24.72127342224121, "_runtime": 16608.59201192856, "_timestamp": 1585613978.2248814, "_step": 122}
{"Episode reward": 8.537080120662907, "Episode length": 915, "Policy Loss": 0.34662529826164246, "Value Loss": 10.926310539245605, "_runtime": 16609.24081492424, "_timestamp": 1585613978.8736844, "_step": 123}
{"Episode reward": 58.97121278647652, "Episode length": 411, "Policy Loss": 1.373592734336853, "Value Loss": 24.299768447875977, "_runtime": 16610.775126218796, "_timestamp": 1585613980.4079957, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5670903921127319, "Value Loss": 0.005910641048103571, "_runtime": 16612.363117218018, "_timestamp": 1585613981.9959867, "_step": 125}
{"Episode reward": -99.80024623013894, "Episode length": 999, "Policy Loss": -0.5736557245254517, "Value Loss": 0.006032824981957674, "_runtime": 16613.88515138626, "_timestamp": 1585613983.5180209, "_step": 126}
{"Episode reward": -99.59248914215576, "Episode length": 999, "Policy Loss": -0.5762622356414795, "Value Loss": 0.006101876962929964, "_runtime": 16615.00135231018, "_timestamp": 1585613984.6342218, "_step": 127}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.491496205329895, "Value Loss": 14.188382148742676, "_runtime": 16615.504559516907, "_timestamp": 1585613985.137429, "_step": 128}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 1.8904671669006348, "Value Loss": 33.966068267822266, "_runtime": 16617.08429813385, "_timestamp": 1585613986.7171676, "_step": 129}
{"Episode reward": -99.61725159436908, "Episode length": 999, "Policy Loss": -0.5775136351585388, "Value Loss": 0.006387863773852587, "_runtime": 16618.177996873856, "_timestamp": 1585613987.8108664, "_step": 130}
{"Episode reward": 30.47921254485813, "Episode length": 696, "Policy Loss": 0.6584455966949463, "Value Loss": 14.351133346557617, "_runtime": 16619.694090604782, "_timestamp": 1585613989.32696, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5890910029411316, "Value Loss": 0.00666077109053731, "_runtime": 16621.284781694412, "_timestamp": 1585613990.9176512, "_step": 132}
{"Episode reward": -99.86034095920482, "Episode length": 999, "Policy Loss": -0.5972030758857727, "Value Loss": 0.00674435356631875, "_runtime": 16622.854705810547, "_timestamp": 1585613992.4875753, "_step": 133}
{"Episode reward": -99.55190604834212, "Episode length": 999, "Policy Loss": -0.6018531322479248, "Value Loss": 0.006769365631043911, "_runtime": 16624.470676898956, "_timestamp": 1585613994.1035464, "_step": 134}
{"Episode reward": -99.73075074301893, "Episode length": 999, "Policy Loss": -0.6070306301116943, "Value Loss": 0.00679151201620698, "_runtime": 16625.816903829575, "_timestamp": 1585613995.4497733, "_step": 135}
{"Episode reward": 16.19591006407329, "Episode length": 840, "Policy Loss": 0.26211464405059814, "Value Loss": 11.891924858093262, "_runtime": 16627.40647792816, "_timestamp": 1585613997.0393474, "_step": 136}
{"Episode reward": -99.52106303702902, "Episode length": 999, "Policy Loss": -0.6071313619613647, "Value Loss": 0.0067444234155118465, "_runtime": 16628.145243883133, "_timestamp": 1585613997.7781134, "_step": 137}
{"Episode reward": 55.0153392785167, "Episode length": 450, "Policy Loss": 1.0765122175216675, "Value Loss": 22.192493438720703, "_runtime": 16629.31318473816, "_timestamp": 1585613998.9460542, "_step": 138}
{"Episode reward": 26.165679412841484, "Episode length": 739, "Policy Loss": 0.3935929238796234, "Value Loss": 13.516307830810547, "_runtime": 16630.32713866234, "_timestamp": 1585613999.9600081, "_step": 139}
{"Episode reward": 36.6583546175557, "Episode length": 634, "Policy Loss": 0.5539740920066833, "Value Loss": 15.753653526306152, "_runtime": 16631.86280965805, "_timestamp": 1585614001.4956791, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6085044741630554, "Value Loss": 0.006858943961560726, "_runtime": 16633.428862571716, "_timestamp": 1585614003.061732, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6108095645904541, "Value Loss": 0.00688576465472579, "_runtime": 16634.977381706238, "_timestamp": 1585614004.6102512, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5909397006034851, "Value Loss": 0.006874812766909599, "_runtime": 16636.54845547676, "_timestamp": 1585614006.181325, "_step": 143}
{"Episode reward": -99.69077266242681, "Episode length": 999, "Policy Loss": -0.5996620059013367, "Value Loss": 0.006811110302805901, "_runtime": 16637.39898943901, "_timestamp": 1585614007.031859, "_step": 144}
{"Episode reward": 47.74086812834675, "Episode length": 524, "Policy Loss": 0.7746114134788513, "Value Loss": 19.059341430664062, "_runtime": 16638.99042725563, "_timestamp": 1585614008.6232967, "_step": 145}
{"Episode reward": -99.73755890894542, "Episode length": 999, "Policy Loss": -0.6006640791893005, "Value Loss": 0.006719422060996294, "_runtime": 16640.56949543953, "_timestamp": 1585614010.202365, "_step": 146}
{"Episode reward": -99.60869733441949, "Episode length": 999, "Policy Loss": -0.5946921706199646, "Value Loss": 0.006662767846137285, "_runtime": 16642.11172580719, "_timestamp": 1585614011.7445953, "_step": 147}
{"Episode reward": -99.78347965264554, "Episode length": 999, "Policy Loss": -0.5937236547470093, "Value Loss": 0.006586640607565641, "_runtime": 16643.702120780945, "_timestamp": 1585614013.3349903, "_step": 148}
{"Episode reward": -99.86686136461654, "Episode length": 999, "Policy Loss": -0.594082236289978, "Value Loss": 0.006482397671788931, "_runtime": 16645.29310631752, "_timestamp": 1585614014.9259758, "_step": 149}
{"Episode reward": -99.7792913891361, "Episode length": 999, "Policy Loss": -0.5772238373756409, "Value Loss": 0.0063467007130384445, "_runtime": 16646.91807293892, "_timestamp": 1585614016.5509424, "_step": 150}
{"Episode reward": -99.76940321363371, "Episode length": 999, "Policy Loss": -0.5741817951202393, "Value Loss": 0.006194197107106447, "_runtime": 16648.521792650223, "_timestamp": 1585614018.1546621, "_step": 151}
{"Episode reward": -99.80105798563314, "Episode length": 999, "Policy Loss": -0.5709960460662842, "Value Loss": 0.006029236130416393, "_runtime": 16650.10792541504, "_timestamp": 1585614019.740795, "_step": 152}
{"Episode reward": -99.81723460967046, "Episode length": 999, "Policy Loss": -0.5606698393821716, "Value Loss": 0.005854295566678047, "_runtime": 16651.692009449005, "_timestamp": 1585614021.324879, "_step": 153}
{"Episode reward": -99.86655229478934, "Episode length": 999, "Policy Loss": -0.5427557229995728, "Value Loss": 0.0056659867987036705, "_runtime": 16653.28807592392, "_timestamp": 1585614022.9209454, "_step": 154}
{"Episode reward": -99.74342082983209, "Episode length": 999, "Policy Loss": -0.5423979759216309, "Value Loss": 0.005461234133690596, "_runtime": 16654.87498474121, "_timestamp": 1585614024.5078542, "_step": 155}
{"Episode reward": -99.8102443754659, "Episode length": 999, "Policy Loss": -0.5336942076683044, "Value Loss": 0.0052614049054682255, "_runtime": 16656.24416589737, "_timestamp": 1585614025.8770354, "_step": 156}
{"Episode reward": 13.900000000000617, "Episode length": 861, "Policy Loss": 0.29457664489746094, "Value Loss": 11.602932929992676, "_runtime": 16656.921645641327, "_timestamp": 1585614026.5545151, "_step": 157}
{"Episode reward": 59.099999999999696, "Episode length": 409, "Policy Loss": 1.3068852424621582, "Value Loss": 24.420570373535156, "_runtime": 16658.381063222885, "_timestamp": 1585614028.0139327, "_step": 158}
{"Episode reward": 8.473929826078006, "Episode length": 916, "Policy Loss": 0.26486024260520935, "Value Loss": 10.906700134277344, "_runtime": 16659.96973490715, "_timestamp": 1585614029.6026044, "_step": 159}
{"Episode reward": -99.61070445342783, "Episode length": 999, "Policy Loss": -0.49437084794044495, "Value Loss": 0.004728455562144518, "_runtime": 16660.77003312111, "_timestamp": 1585614030.4029026, "_step": 160}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 0.9811111688613892, "Value Loss": 19.32061767578125, "_runtime": 16662.347138166428, "_timestamp": 1585614031.9800076, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4965551793575287, "Value Loss": 0.004638417158275843, "_runtime": 16663.636761903763, "_timestamp": 1585614033.2696314, "_step": 162}
{"Episode reward": 18.827621183498167, "Episode length": 813, "Policy Loss": 0.3949538469314575, "Value Loss": 12.288045883178711, "_runtime": 16665.166545152664, "_timestamp": 1585614034.7994146, "_step": 163}
{"Episode reward": -99.7029258940355, "Episode length": 999, "Policy Loss": -0.4958452880382538, "Value Loss": 0.004560379311442375, "_runtime": 16666.178183078766, "_timestamp": 1585614035.8110526, "_step": 164}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.7774136662483215, "Value Loss": 15.806052207946777, "_runtime": 16667.741151809692, "_timestamp": 1585614037.3740213, "_step": 165}
{"Episode reward": -99.72738817653014, "Episode length": 999, "Policy Loss": -0.4972994029521942, "Value Loss": 0.0045065018348395824, "_runtime": 16669.302505016327, "_timestamp": 1585614038.9353745, "_step": 166}
{"Episode reward": -99.82680232489807, "Episode length": 999, "Policy Loss": -0.4867950975894928, "Value Loss": 0.004476573783904314, "_runtime": 16670.89249944687, "_timestamp": 1585614040.525369, "_step": 167}
{"Episode reward": -99.71388834602992, "Episode length": 999, "Policy Loss": -0.49005043506622314, "Value Loss": 0.004423012025654316, "_runtime": 16672.473183631897, "_timestamp": 1585614042.106053, "_step": 168}
{"Episode reward": -99.6847815620699, "Episode length": 999, "Policy Loss": -0.4858419597148895, "Value Loss": 0.004349660128355026, "_runtime": 16674.05314707756, "_timestamp": 1585614043.6860166, "_step": 169}
{"Episode reward": -99.72464431458944, "Episode length": 999, "Policy Loss": -0.48348739743232727, "Value Loss": 0.004263285081833601, "_runtime": 16675.623628616333, "_timestamp": 1585614045.256498, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4746803343296051, "Value Loss": 0.004168261308223009, "_runtime": 16676.384855031967, "_timestamp": 1585614046.0177245, "_step": 171}
{"Episode reward": 53.54290022950116, "Episode length": 467, "Policy Loss": 1.252210259437561, "Value Loss": 21.390024185180664, "_runtime": 16677.345459461212, "_timestamp": 1585614046.978329, "_step": 172}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.7329608201980591, "Value Loss": 16.56675148010254, "_runtime": 16678.913197517395, "_timestamp": 1585614048.546067, "_step": 173}
{"Episode reward": -99.71104524187254, "Episode length": 999, "Policy Loss": -0.4592483341693878, "Value Loss": 0.00399212259799242, "_runtime": 16680.44610261917, "_timestamp": 1585614050.078972, "_step": 174}
{"Episode reward": -99.64966037709245, "Episode length": 999, "Policy Loss": -0.45429179072380066, "Value Loss": 0.003959187306463718, "_runtime": 16681.90079188347, "_timestamp": 1585614051.5336614, "_step": 175}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": 0.30395469069480896, "Value Loss": 10.62889575958252, "_runtime": 16682.686564445496, "_timestamp": 1585614052.319434, "_step": 176}
{"Episode reward": 51.91439458690543, "Episode length": 481, "Policy Loss": 1.045203685760498, "Value Loss": 20.76796531677246, "_runtime": 16684.270656824112, "_timestamp": 1585614053.9035263, "_step": 177}
{"Episode reward": -99.88163735726708, "Episode length": 999, "Policy Loss": -0.45494601130485535, "Value Loss": 0.00391699094325304, "_runtime": 16685.845756053925, "_timestamp": 1585614055.4786255, "_step": 178}
{"Episode reward": -99.80573319531838, "Episode length": 999, "Policy Loss": -0.4620245099067688, "Value Loss": 0.003917498514056206, "_runtime": 16686.68639564514, "_timestamp": 1585614056.3192651, "_step": 179}
{"Episode reward": 45.94414996355723, "Episode length": 541, "Policy Loss": 0.8619751930236816, "Value Loss": 18.465097427368164, "_runtime": 16687.91062116623, "_timestamp": 1585614057.5434906, "_step": 180}
{"Episode reward": 22.614397410466452, "Episode length": 774, "Policy Loss": 0.46619272232055664, "Value Loss": 12.907631874084473, "_runtime": 16688.657752513885, "_timestamp": 1585614058.290622, "_step": 181}
{"Episode reward": 54.099999999999625, "Episode length": 459, "Policy Loss": 1.280084252357483, "Value Loss": 21.76300811767578, "_runtime": 16689.3765001297, "_timestamp": 1585614059.0093696, "_step": 182}
{"Episode reward": 54.74370421431922, "Episode length": 453, "Policy Loss": 1.585741639137268, "Value Loss": 22.05094337463379, "_runtime": 16690.963631391525, "_timestamp": 1585614060.5965009, "_step": 183}
{"Episode reward": -99.81490325666825, "Episode length": 999, "Policy Loss": -0.478630930185318, "Value Loss": 0.004213727544993162, "_runtime": 16691.868841171265, "_timestamp": 1585614061.5017107, "_step": 184}
{"Episode reward": 42.39999999999946, "Episode length": 576, "Policy Loss": 0.8155859708786011, "Value Loss": 17.342580795288086, "_runtime": 16692.492634534836, "_timestamp": 1585614062.125504, "_step": 185}
{"Episode reward": 60.86127335836618, "Episode length": 393, "Policy Loss": 1.4032235145568848, "Value Loss": 25.415725708007812, "_runtime": 16693.81340122223, "_timestamp": 1585614063.4462707, "_step": 186}
{"Episode reward": 16.700000000000458, "Episode length": 833, "Policy Loss": 0.40398499369621277, "Value Loss": 11.99306583404541, "_runtime": 16694.726645469666, "_timestamp": 1585614064.359515, "_step": 187}
{"Episode reward": 42.233818492642065, "Episode length": 579, "Policy Loss": 0.8394719362258911, "Value Loss": 17.251876831054688, "_runtime": 16696.296504497528, "_timestamp": 1585614065.929374, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5312377214431763, "Value Loss": 0.005123005248606205, "_runtime": 16697.4714949131, "_timestamp": 1585614067.1043644, "_step": 189}
{"Episode reward": 25.310698474268392, "Episode length": 748, "Policy Loss": 0.42196124792099, "Value Loss": 13.354778289794922, "_runtime": 16697.83624148369, "_timestamp": 1585614067.469111, "_step": 190}
{"Episode reward": 78.79712508767841, "Episode length": 213, "Policy Loss": 2.820648431777954, "Value Loss": 46.884193420410156, "_runtime": 16699.407054185867, "_timestamp": 1585614069.0399237, "_step": 191}
{"Episode reward": -99.72677005650337, "Episode length": 999, "Policy Loss": -0.5550616383552551, "Value Loss": 0.005851492285728455, "_runtime": 16700.999357938766, "_timestamp": 1585614070.6322274, "_step": 192}
{"Episode reward": -99.83242803225154, "Episode length": 999, "Policy Loss": -0.5714114308357239, "Value Loss": 0.006149213761091232, "_runtime": 16701.46069741249, "_timestamp": 1585614071.093567, "_step": 193}
{"Episode reward": 70.92485663385582, "Episode length": 292, "Policy Loss": 1.9708456993103027, "Value Loss": 34.19818878173828, "_runtime": 16702.029327869415, "_timestamp": 1585614071.6621974, "_step": 194}
{"Episode reward": 65.69999999999979, "Episode length": 343, "Policy Loss": 1.527033805847168, "Value Loss": 29.113420486450195, "_runtime": 16703.607028722763, "_timestamp": 1585614073.2398982, "_step": 195}
{"Episode reward": -99.7953533835695, "Episode length": 999, "Policy Loss": -0.6217384934425354, "Value Loss": 0.007141588255763054, "_runtime": 16704.936356544495, "_timestamp": 1585614074.569226, "_step": 196}
{"Episode reward": 13.289590869844616, "Episode length": 868, "Policy Loss": 0.2790429890155792, "Value Loss": 11.508289337158203, "_runtime": 16706.470663547516, "_timestamp": 1585614076.103533, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6537459492683411, "Value Loss": 0.007826223969459534, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041, -0.3436586856842041]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-25.704627990722656, -25.29686164855957, -24.88909339904785, -24.481327056884766, -24.073558807373047, -23.66579246520996, -23.258024215698242, -22.850257873535156, -22.442489624023438, -22.03472328186035, -21.626955032348633, -21.219188690185547, -20.811420440673828, -20.403654098510742, -19.995887756347656, -19.588119506835938, -19.18035125732422, -18.772584915161133, -18.364818572998047, -17.957050323486328, -17.54928207397461, -17.141515731811523, -16.733749389648438, -16.32598114013672, -15.918214797973633, -15.51044750213623, -15.102680206298828, -14.694912910461426, -14.287145614624023, -13.879378318786621, -13.471611022949219, -13.063843727111816, -12.656076431274414, -12.248309135437012, -11.84054183959961, -11.432774543762207, -11.025007247924805, -10.617239952087402, -10.20947265625, -9.801705360412598, -9.393938064575195, -8.98617172241211, -8.57840347290039, -8.170637130737305, -7.762868881225586, -7.3551025390625, -6.947334289550781, -6.539567947387695, -6.131801605224609, -5.724033355712891, -5.316267013549805, -4.908498764038086, -4.500732421875, -4.092964172363281, -3.6851978302001953, -3.2774295806884766, -2.8696632385253906, -2.461894989013672, -2.054128646850586, -1.6463603973388672, -1.2385940551757812, -0.8308258056640625, -0.42305946350097656, -0.015291213989257812, 0.3924751281738281]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7255202531814575, -0.7040255069732666, -0.6825308203697205, -0.6610360741615295, -0.6395413279533386, -0.6180466413497925, -0.5965518951416016, -0.5750571489334106, -0.5535624027252197, -0.5320677161216736, -0.5105729699134827, -0.48907825350761414, -0.4675835371017456, -0.4460887908935547, -0.42459407448768616, -0.40309932827949524, -0.3816046118736267, -0.3601098954677582, -0.33861514925956726, -0.31712043285369873, -0.2956256866455078, -0.2741309702396393, -0.25263625383377075, -0.23114150762557983, -0.2096468210220337, -0.18815207481384277, -0.16665732860565186, -0.14516258239746094, -0.1236678957939148, -0.10217314958572388, -0.08067840337753296, -0.059183716773986816, -0.0376889705657959, -0.01619422435760498, 0.005300462245941162, 0.02679520845413208, 0.048289954662323, 0.06978464126586914, 0.09127938747406006, 0.11277413368225098, 0.1342688798904419, 0.15576356649398804, 0.17725831270217896, 0.19875305891036987, 0.22024774551391602, 0.24174249172210693, 0.26323723793029785, 0.28473198413848877, 0.30622661113739014, 0.32772135734558105, 0.349216103553772, 0.3707108497619629, 0.3922055959701538, 0.4137003421783447, 0.43519508838653564, 0.456689715385437, 0.47818446159362793, 0.49967920780181885, 0.5211739540100098, 0.5426687002182007, 0.5641634464263916, 0.585658073425293, 0.6071528196334839, 0.6286475658416748, 0.6501423120498657]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 1.0, 1.0, 7.0, 8.0, 2.0, 13.0, 7.0, 10.0, 5.0, 3.0, 12.0, 6.0, 5.0, 3.0, 4.0, 288.0, 0.0, 2.0, 15.0, 38.0, 28.0, 21.0, 0.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.150840759277344, -4.02786922454834, -3.904898166656494, -3.7819268703460693, -3.6589555740356445, -3.5359840393066406, -3.413012981414795, -3.290041446685791, -3.167070150375366, -3.0440988540649414, -2.9211275577545166, -2.798156261444092, -2.675184965133667, -2.552213668823242, -2.4292421340942383, -2.3062710762023926, -2.1832995414733887, -2.060328245162964, -1.937356948852539, -1.8143856525421143, -1.6914143562316895, -1.5684430599212646, -1.4454717636108398, -1.322500467300415, -1.1995291709899902, -1.0765578746795654, -0.9535865783691406, -0.8306150436401367, -0.7076437473297119, -0.5846724510192871, -0.4617011547088623, -0.3387298583984375, -0.2157585620880127, -0.09278726577758789, 0.030184268951416016, 0.15315532684326172, 0.2761268615722656, 0.39909791946411133, 0.5220694541931152, 0.6450405120849609, 0.7680120468139648, 0.8909831047058105, 1.0139546394348145, 1.1369261741638184, 1.259897232055664, 1.382868766784668, 1.5058398246765137, 1.6288113594055176, 1.7517824172973633, 1.8747539520263672, 1.997725009918213, 2.120696544647217, 2.2436676025390625, 2.3666391372680664, 2.4896106719970703, 2.612581729888916, 2.73555326461792, 2.8585243225097656, 2.9814958572387695, 3.1044669151306152, 3.227438449859619, 3.350409507751465, 3.4733810424804688, 3.5963521003723145, 3.7193236351013184]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.940173149108887, -7.758737564086914, -7.577301502227783, -7.3958659172058105, -7.21442985534668, -7.032994270324707, -6.851558685302734, -6.6701226234436035, -6.488687038421631, -6.3072509765625, -6.125815391540527, -5.944379806518555, -5.762943744659424, -5.581507682800293, -5.40007209777832, -5.218636512756348, -5.037200927734375, -4.855764865875244, -4.674328804016113, -4.492893218994141, -4.311457633972168, -4.130022048950195, -3.9485859870910645, -3.767150402069092, -3.585714340209961, -3.4042787551879883, -3.2228426933288574, -3.0414071083068848, -2.859971523284912, -2.6785354614257812, -2.4970998764038086, -2.3156638145446777, -2.134228229522705, -1.9527926445007324, -1.7713565826416016, -1.589920997619629, -1.408484935760498, -1.2270493507385254, -1.0456137657165527, -0.8641777038574219, -0.6827421188354492, -0.5013060569763184, -0.3198704719543457, -0.13843488693237305, 0.04300117492675781, 0.22443675994873047, 0.4058723449707031, 0.5873088836669922, 0.7687444686889648, 0.9501800537109375, 1.1316156387329102, 1.3130512237548828, 1.4944877624511719, 1.6759233474731445, 1.8573589324951172, 2.03879451751709, 2.2202301025390625, 2.4016666412353516, 2.583102226257324, 2.764537811279297, 2.9459733963012695, 3.127408981323242, 3.3088455200195312, 3.490281105041504, 3.6717166900634766]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 13.0, 8.0, 24.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.9345636367797852, -1.8391422033309937, -1.7437206506729126, -1.648299217224121, -1.55287766456604, -1.4574562311172485, -1.362034797668457, -1.266613245010376, -1.1711918115615845, -1.075770378112793, -0.9803488254547119, -0.8849273920059204, -0.7895059585571289, -0.6940844058990479, -0.5986629724502563, -0.5032414197921753, -0.4078199863433838, -0.3123985528945923, -0.21697700023651123, -0.12155556678771973, -0.026134014129638672, 0.06928730010986328, 0.16470885276794434, 0.2601304054260254, 0.35555171966552734, 0.4509732723236084, 0.5463948249816895, 0.6418163776397705, 0.7372376918792725, 0.8326592445373535, 0.9280807971954346, 1.0235021114349365, 1.1189236640930176, 1.2143452167510986, 1.3097665309906006, 1.4051880836486816, 1.5006096363067627, 1.5960309505462646, 1.6914525032043457, 1.7868740558624268, 1.8822956085205078, 1.9777169227600098, 2.0731382369995117, 2.168560028076172, 2.263981342315674, 2.359402656555176, 2.454824447631836, 2.550245761871338, 2.64566707611084, 2.7410888671875, 2.836510181427002, 2.931931972503662, 3.027353286743164, 3.122774600982666, 3.218196392059326, 3.313617706298828, 3.40903902053833, 3.5044608116149902, 3.599882125854492, 3.695303440093994, 3.7907252311706543, 3.8861465454101562, 3.981567859649658, 4.076989650726318, 4.17241096496582]}, "_runtime": 16707.29161953926, "_timestamp": 1585614076.924489, "_step": 198}
{"Episode reward": 50.8774859954366, "Episode length": 493, "Policy Loss": 0.9553346037864685, "Value Loss": 20.255538940429688, "_runtime": 16708.426780462265, "_timestamp": 1585614078.05965, "_step": 199}
{"Episode reward": 28.470839077140923, "Episode length": 716, "Policy Loss": 0.44346708059310913, "Value Loss": 13.949289321899414, "_runtime": 16710.011568784714, "_timestamp": 1585614079.6444383, "_step": 200}
{"Episode reward": -99.82066241809959, "Episode length": 999, "Policy Loss": -0.6705066561698914, "Value Loss": 0.008675756864249706, "_runtime": 16711.022634744644, "_timestamp": 1585614080.6555042, "_step": 201}
{"Episode reward": 35.458473680912846, "Episode length": 646, "Policy Loss": 0.465248167514801, "Value Loss": 15.459550857543945, "_runtime": 16712.58069896698, "_timestamp": 1585614082.2135684, "_step": 202}
{"Episode reward": -99.83479156494, "Episode length": 999, "Policy Loss": -0.7021864652633667, "Value Loss": 0.009137744084000587, "_runtime": 16713.756881952286, "_timestamp": 1585614083.3897514, "_step": 203}
{"Episode reward": 26.597860884031874, "Episode length": 735, "Policy Loss": 0.38531649112701416, "Value Loss": 13.588513374328613, "_runtime": 16715.302477121353, "_timestamp": 1585614084.9353466, "_step": 204}
{"Episode reward": -99.8265271523022, "Episode length": 999, "Policy Loss": -0.7149091362953186, "Value Loss": 0.009471051394939423, "_runtime": 16716.126541614532, "_timestamp": 1585614085.759411, "_step": 205}
{"Episode reward": 49.2837271177904, "Episode length": 508, "Policy Loss": 0.7358719706535339, "Value Loss": 19.65608787536621, "_runtime": 16716.674993515015, "_timestamp": 1585614086.307863, "_step": 206}
{"Episode reward": 66.97590891002164, "Episode length": 332, "Policy Loss": 1.9107493162155151, "Value Loss": 30.070735931396484, "_runtime": 16718.251353740692, "_timestamp": 1585614087.8842232, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7246074080467224, "Value Loss": 0.009982077404856682, "_runtime": 16719.83333158493, "_timestamp": 1585614089.466201, "_step": 208}
{"Episode reward": -99.67159358963697, "Episode length": 999, "Policy Loss": -0.7447981238365173, "Value Loss": 0.010128731839358807, "_runtime": 16721.286893606186, "_timestamp": 1585614090.919763, "_step": 209}
{"Episode reward": 4.894328949112648, "Episode length": 954, "Policy Loss": 0.0559353269636631, "Value Loss": 10.471141815185547, "_runtime": 16722.886974334717, "_timestamp": 1585614092.5198438, "_step": 210}
{"Episode reward": -99.8002197265611, "Episode length": 999, "Policy Loss": -0.7281321883201599, "Value Loss": 0.0103286262601614, "_runtime": 16724.479503154755, "_timestamp": 1585614094.1123726, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7460655570030212, "Value Loss": 0.010356892831623554, "_runtime": 16726.04129433632, "_timestamp": 1585614095.6741638, "_step": 212}
{"Episode reward": -99.80039005300355, "Episode length": 999, "Policy Loss": -0.7287501692771912, "Value Loss": 0.010300141759216785, "_runtime": 16727.638359308243, "_timestamp": 1585614097.2712288, "_step": 213}
{"Episode reward": -99.84423784373654, "Episode length": 999, "Policy Loss": -0.7385345101356506, "Value Loss": 0.010198312811553478, "_runtime": 16729.222896814346, "_timestamp": 1585614098.8557663, "_step": 214}
{"Episode reward": -99.72886783936852, "Episode length": 999, "Policy Loss": -0.7381702065467834, "Value Loss": 0.010032301768660545, "_runtime": 16730.810893535614, "_timestamp": 1585614100.443763, "_step": 215}
{"Episode reward": -99.81588740581506, "Episode length": 999, "Policy Loss": -0.7385765910148621, "Value Loss": 0.009842762723565102, "_runtime": 16732.33581662178, "_timestamp": 1585614101.968686, "_step": 216}
{"Episode reward": 4.887633702084386, "Episode length": 953, "Policy Loss": 0.1270478516817093, "Value Loss": 10.48220443725586, "_runtime": 16733.921503543854, "_timestamp": 1585614103.554373, "_step": 217}
{"Episode reward": -99.71212009135495, "Episode length": 999, "Policy Loss": -0.7110332250595093, "Value Loss": 0.009383033961057663, "_runtime": 16734.6515045166, "_timestamp": 1585614104.284374, "_step": 218}
{"Episode reward": 55.623690967238154, "Episode length": 444, "Policy Loss": 1.3730497360229492, "Value Loss": 22.488521575927734, "_runtime": 16736.248149871826, "_timestamp": 1585614105.8810194, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6947223544120789, "Value Loss": 0.00902589876204729, "_runtime": 16737.01131629944, "_timestamp": 1585614106.6441858, "_step": 220}
{"Episode reward": 53.9252294044414, "Episode length": 462, "Policy Loss": 1.2381044626235962, "Value Loss": 21.61311149597168, "_runtime": 16738.55399131775, "_timestamp": 1585614108.1868608, "_step": 221}
{"Episode reward": -99.83952212799201, "Episode length": 999, "Policy Loss": -0.678568959236145, "Value Loss": 0.008745783008635044, "_runtime": 16740.142629623413, "_timestamp": 1585614109.775499, "_step": 222}
{"Episode reward": -99.77253921218076, "Episode length": 999, "Policy Loss": -0.6839522123336792, "Value Loss": 0.00860505923628807, "_runtime": 16741.68411755562, "_timestamp": 1585614111.316987, "_step": 223}
{"Episode reward": -99.75680423863675, "Episode length": 999, "Policy Loss": -0.6616091728210449, "Value Loss": 0.008429263718426228, "_runtime": 16742.20358800888, "_timestamp": 1585614111.8364575, "_step": 224}
{"Episode reward": 70.23420510923009, "Episode length": 300, "Policy Loss": 1.9184207916259766, "Value Loss": 33.28095626831055, "_runtime": 16742.613152980804, "_timestamp": 1585614112.2460225, "_step": 225}
{"Episode reward": 76.89999999999995, "Episode length": 231, "Policy Loss": 2.5509214401245117, "Value Loss": 43.219852447509766, "_runtime": 16744.191674232483, "_timestamp": 1585614113.8245437, "_step": 226}
{"Episode reward": -99.80546958597704, "Episode length": 999, "Policy Loss": -0.6625356674194336, "Value Loss": 0.008333317935466766, "_runtime": 16745.760005235672, "_timestamp": 1585614115.3928747, "_step": 227}
{"Episode reward": -99.72430318046688, "Episode length": 999, "Policy Loss": -0.6720130443572998, "Value Loss": 0.008408747613430023, "_runtime": 16747.00828933716, "_timestamp": 1585614116.6411588, "_step": 228}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.19329100847244263, "Value Loss": 12.107397079467773, "_runtime": 16748.449701309204, "_timestamp": 1585614118.0825708, "_step": 229}
{"Episode reward": 9.248784308043255, "Episode length": 910, "Policy Loss": 0.12956541776657104, "Value Loss": 10.9772367477417, "_runtime": 16750.02525305748, "_timestamp": 1585614119.6581225, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6741025447845459, "Value Loss": 0.00853168498724699, "_runtime": 16750.929676294327, "_timestamp": 1585614120.5625458, "_step": 231}
{"Episode reward": 42.69999999999946, "Episode length": 573, "Policy Loss": 0.5608707666397095, "Value Loss": 17.42833137512207, "_runtime": 16752.5148293972, "_timestamp": 1585614122.1476989, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6777635216712952, "Value Loss": 0.008555233478546143, "_runtime": 16754.096129894257, "_timestamp": 1585614123.7289994, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6846827268600464, "Value Loss": 0.008534346707165241, "_runtime": 16755.644429683685, "_timestamp": 1585614125.2772992, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6798319220542908, "Value Loss": 0.008462189696729183, "_runtime": 16757.244928359985, "_timestamp": 1585614126.8777978, "_step": 235}
{"Episode reward": -99.8198833581279, "Episode length": 999, "Policy Loss": -0.6728708744049072, "Value Loss": 0.008336318656802177, "_runtime": 16757.877417564392, "_timestamp": 1585614127.510287, "_step": 236}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": 1.2308048009872437, "Value Loss": 26.626562118530273, "_runtime": 16759.087783813477, "_timestamp": 1585614128.7206533, "_step": 237}
{"Episode reward": 22.58164162039769, "Episode length": 775, "Policy Loss": 0.2766660749912262, "Value Loss": 12.88805866241455, "_runtime": 16760.69193959236, "_timestamp": 1585614130.324809, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6698501706123352, "Value Loss": 0.00813132245093584, "_runtime": 16762.22627902031, "_timestamp": 1585614131.8591485, "_step": 239}
{"Episode reward": -99.80017659077281, "Episode length": 999, "Policy Loss": -0.6652135252952576, "Value Loss": 0.008058483712375164, "_runtime": 16763.795953273773, "_timestamp": 1585614133.4288228, "_step": 240}
{"Episode reward": -99.73505411567027, "Episode length": 999, "Policy Loss": -0.6420748233795166, "Value Loss": 0.007941792719066143, "_runtime": 16765.39609146118, "_timestamp": 1585614135.028961, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6461331248283386, "Value Loss": 0.00780975678935647, "_runtime": 16766.623780965805, "_timestamp": 1585614136.2566504, "_step": 242}
{"Episode reward": 22.471103988675296, "Episode length": 777, "Policy Loss": 0.29993394017219543, "Value Loss": 12.855147361755371, "_runtime": 16768.215865135193, "_timestamp": 1585614137.8487346, "_step": 243}
{"Episode reward": -99.70449245437491, "Episode length": 999, "Policy Loss": -0.6319379806518555, "Value Loss": 0.007470856420695782, "_runtime": 16769.855851888657, "_timestamp": 1585614139.4887214, "_step": 244}
{"Episode reward": -99.5930978847188, "Episode length": 999, "Policy Loss": -0.6139191389083862, "Value Loss": 0.007290483918040991, "_runtime": 16771.000071763992, "_timestamp": 1585614140.6329412, "_step": 245}
{"Episode reward": 27.699999999999832, "Episode length": 723, "Policy Loss": 0.39134424924850464, "Value Loss": 13.815027236938477, "_runtime": 16771.448510169983, "_timestamp": 1585614141.0813797, "_step": 246}
{"Episode reward": 74.79999999999993, "Episode length": 252, "Policy Loss": 2.2648115158081055, "Value Loss": 39.62323760986328, "_runtime": 16773.03347849846, "_timestamp": 1585614142.666348, "_step": 247}
{"Episode reward": -99.63214679760719, "Episode length": 999, "Policy Loss": -0.6134742498397827, "Value Loss": 0.006983757019042969, "_runtime": 16774.59912109375, "_timestamp": 1585614144.2319906, "_step": 248}
{"Episode reward": -99.80386913029803, "Episode length": 999, "Policy Loss": -0.6051344275474548, "Value Loss": 0.006984693463891745, "_runtime": 16776.120630264282, "_timestamp": 1585614145.7534997, "_step": 249}
{"Episode reward": -99.75440246360237, "Episode length": 999, "Policy Loss": -0.6122673153877258, "Value Loss": 0.006921173073351383, "_runtime": 16777.720613002777, "_timestamp": 1585614147.3534825, "_step": 250}
{"Episode reward": -99.81708417534689, "Episode length": 999, "Policy Loss": -0.6075335144996643, "Value Loss": 0.006832581479102373, "_runtime": 16779.32494854927, "_timestamp": 1585614148.957818, "_step": 251}
{"Episode reward": -99.81370206198049, "Episode length": 999, "Policy Loss": -0.5932255387306213, "Value Loss": 0.0067037432454526424, "_runtime": 16780.490110874176, "_timestamp": 1585614150.1229804, "_step": 252}
{"Episode reward": 26.59824418090274, "Episode length": 735, "Policy Loss": 0.3797321319580078, "Value Loss": 13.58997631072998, "_runtime": 16782.074472665787, "_timestamp": 1585614151.7073421, "_step": 253}
{"Episode reward": -99.72393121095234, "Episode length": 999, "Policy Loss": -0.5944544672966003, "Value Loss": 0.006427541375160217, "_runtime": 16783.675415039062, "_timestamp": 1585614153.3082845, "_step": 254}
{"Episode reward": -99.87396666640858, "Episode length": 999, "Policy Loss": -0.5816750526428223, "Value Loss": 0.006294893100857735, "_runtime": 16785.232739925385, "_timestamp": 1585614154.8656094, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5706426501274109, "Value Loss": 0.006131561007350683, "_runtime": 16786.833040237427, "_timestamp": 1585614156.4659097, "_step": 256}
{"Episode reward": -99.80033338218787, "Episode length": 999, "Policy Loss": -0.5613927841186523, "Value Loss": 0.005938389338552952, "_runtime": 16788.423249959946, "_timestamp": 1585614158.0561194, "_step": 257}
{"Episode reward": -99.72514941589768, "Episode length": 999, "Policy Loss": -0.5594255328178406, "Value Loss": 0.005727955140173435, "_runtime": 16789.050699472427, "_timestamp": 1585614158.683569, "_step": 258}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": 1.3350040912628174, "Value Loss": 26.632596969604492, "_runtime": 16790.30110836029, "_timestamp": 1585614159.9339778, "_step": 259}
{"Episode reward": 21.685214322805578, "Episode length": 784, "Policy Loss": 0.3763362467288971, "Value Loss": 12.7417573928833, "_runtime": 16791.091646671295, "_timestamp": 1585614160.7245162, "_step": 260}
{"Episode reward": 52.09958928674419, "Episode length": 480, "Policy Loss": 1.0433763265609741, "Value Loss": 20.80817222595215, "_runtime": 16792.577142715454, "_timestamp": 1585614162.2100122, "_step": 261}
{"Episode reward": 3.471112819570166, "Episode length": 966, "Policy Loss": 0.2196284532546997, "Value Loss": 10.342145919799805, "_runtime": 16794.06699323654, "_timestamp": 1585614163.6998627, "_step": 262}
{"Episode reward": 8.393521236344, "Episode length": 919, "Policy Loss": 0.23926189541816711, "Value Loss": 10.870809555053711, "_runtime": 16795.610522031784, "_timestamp": 1585614165.2433915, "_step": 263}
{"Episode reward": -99.8062446605633, "Episode length": 999, "Policy Loss": -0.5315507054328918, "Value Loss": 0.00541651202365756, "_runtime": 16797.19661974907, "_timestamp": 1585614166.8294892, "_step": 264}
{"Episode reward": -99.8192208174602, "Episode length": 999, "Policy Loss": -0.5425018072128296, "Value Loss": 0.005413702689111233, "_runtime": 16798.781378507614, "_timestamp": 1585614168.414248, "_step": 265}
{"Episode reward": -99.735746193117, "Episode length": 999, "Policy Loss": -0.540153980255127, "Value Loss": 0.005371082108467817, "_runtime": 16800.35309791565, "_timestamp": 1585614169.9859674, "_step": 266}
{"Episode reward": -99.58737438807592, "Episode length": 999, "Policy Loss": -0.5284226536750793, "Value Loss": 0.005286979954689741, "_runtime": 16801.93603873253, "_timestamp": 1585614171.5689082, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5326784253120422, "Value Loss": 0.005214984994381666, "_runtime": 16803.535308599472, "_timestamp": 1585614173.168178, "_step": 268}
{"Episode reward": -99.8180718395845, "Episode length": 999, "Policy Loss": -0.5185291767120361, "Value Loss": 0.005089182406663895, "_runtime": 16805.12964606285, "_timestamp": 1585614174.7625155, "_step": 269}
{"Episode reward": -99.80367298722128, "Episode length": 999, "Policy Loss": -0.5229485630989075, "Value Loss": 0.00494872173294425, "_runtime": 16806.272075414658, "_timestamp": 1585614175.904945, "_step": 270}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.47793519496917725, "Value Loss": 14.0106201171875, "_runtime": 16807.780786037445, "_timestamp": 1585614177.4136555, "_step": 271}
{"Episode reward": 5.682894374407979, "Episode length": 944, "Policy Loss": 0.2614063620567322, "Value Loss": 10.58340835571289, "_runtime": 16809.364443063736, "_timestamp": 1585614178.9973125, "_step": 272}
{"Episode reward": -99.82763990331301, "Episode length": 999, "Policy Loss": -0.4988987147808075, "Value Loss": 0.0045997570268809795, "_runtime": 16810.93054819107, "_timestamp": 1585614180.5634177, "_step": 273}
{"Episode reward": -99.86404803432386, "Episode length": 999, "Policy Loss": -0.4971120357513428, "Value Loss": 0.004500825423747301, "_runtime": 16812.521580696106, "_timestamp": 1585614182.1544502, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49007150530815125, "Value Loss": 0.004384271334856749, "_runtime": 16814.111420869827, "_timestamp": 1585614183.7442904, "_step": 275}
{"Episode reward": -99.66916787638189, "Episode length": 999, "Policy Loss": -0.4688207805156708, "Value Loss": 0.004237220622599125, "_runtime": 16814.650117874146, "_timestamp": 1585614184.2829874, "_step": 276}
{"Episode reward": 68.89716954391753, "Episode length": 312, "Policy Loss": 1.8776257038116455, "Value Loss": 32.01431655883789, "_runtime": 16815.70991230011, "_timestamp": 1585614185.3427818, "_step": 277}
{"Episode reward": 33.39972439742948, "Episode length": 667, "Policy Loss": 0.6317812204360962, "Value Loss": 14.977420806884766, "_runtime": 16817.332931518555, "_timestamp": 1585614186.965801, "_step": 278}
{"Episode reward": -99.7179837726974, "Episode length": 999, "Policy Loss": -0.4692329168319702, "Value Loss": 0.00408606231212616, "_runtime": 16818.862609386444, "_timestamp": 1585614188.4954789, "_step": 279}
{"Episode reward": -99.71001662388305, "Episode length": 999, "Policy Loss": -0.4705502390861511, "Value Loss": 0.004073848482221365, "_runtime": 16820.431071281433, "_timestamp": 1585614190.0639408, "_step": 280}
{"Episode reward": -99.78314210811958, "Episode length": 999, "Policy Loss": -0.4594361484050751, "Value Loss": 0.00403597392141819, "_runtime": 16821.097524642944, "_timestamp": 1585614190.7303941, "_step": 281}
{"Episode reward": 60.499999999999716, "Episode length": 395, "Policy Loss": 1.3618786334991455, "Value Loss": 25.288497924804688, "_runtime": 16821.50443649292, "_timestamp": 1585614191.137306, "_step": 282}
{"Episode reward": 77.17578641045252, "Episode length": 229, "Policy Loss": 2.665177345275879, "Value Loss": 43.61684799194336, "_runtime": 16823.051688432693, "_timestamp": 1585614192.684558, "_step": 283}
{"Episode reward": 1.9000000000012989, "Episode length": 981, "Policy Loss": 0.27562037110328674, "Value Loss": 10.184659957885742, "_runtime": 16824.60294699669, "_timestamp": 1585614194.2358165, "_step": 284}
{"Episode reward": -99.77245502443844, "Episode length": 999, "Policy Loss": -0.4901334345340729, "Value Loss": 0.004366656299680471, "_runtime": 16826.119847774506, "_timestamp": 1585614195.7527173, "_step": 285}
{"Episode reward": -99.81946509340638, "Episode length": 999, "Policy Loss": -0.4952718913555145, "Value Loss": 0.004512384533882141, "_runtime": 16827.713582277298, "_timestamp": 1585614197.3464518, "_step": 286}
{"Episode reward": -99.7135645725925, "Episode length": 999, "Policy Loss": -0.4853561818599701, "Value Loss": 0.004601567983627319, "_runtime": 16829.306353092194, "_timestamp": 1585614198.9392226, "_step": 287}
{"Episode reward": -99.53491040571106, "Episode length": 999, "Policy Loss": -0.4905738830566406, "Value Loss": 0.004654640331864357, "_runtime": 16830.8669154644, "_timestamp": 1585614200.499785, "_step": 288}
{"Episode reward": -99.83060553073743, "Episode length": 999, "Policy Loss": -0.4947688579559326, "Value Loss": 0.004689972382038832, "_runtime": 16832.470893383026, "_timestamp": 1585614202.1037629, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5067110657691956, "Value Loss": 0.004681842401623726, "_runtime": 16833.47272992134, "_timestamp": 1585614203.1055994, "_step": 290}
{"Episode reward": 37.844464119127345, "Episode length": 622, "Policy Loss": 0.6330235004425049, "Value Loss": 16.059917449951172, "_runtime": 16835.050327539444, "_timestamp": 1585614204.683197, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49868953227996826, "Value Loss": 0.004642805550247431, "_runtime": 16836.66261601448, "_timestamp": 1585614206.2954855, "_step": 292}
{"Episode reward": -99.74445813242207, "Episode length": 999, "Policy Loss": -0.4910579025745392, "Value Loss": 0.0046060713939368725, "_runtime": 16838.22007536888, "_timestamp": 1585614207.8529449, "_step": 293}
{"Episode reward": -99.81119127906719, "Episode length": 999, "Policy Loss": -0.49586451053619385, "Value Loss": 0.00455450639128685, "_runtime": 16839.799578666687, "_timestamp": 1585614209.4324481, "_step": 294}
{"Episode reward": -99.801768783106, "Episode length": 999, "Policy Loss": -0.4887220561504364, "Value Loss": 0.004473547916859388, "_runtime": 16841.436189174652, "_timestamp": 1585614211.0690587, "_step": 295}
{"Episode reward": -99.88819988705077, "Episode length": 999, "Policy Loss": -0.48355454206466675, "Value Loss": 0.004372310359030962, "_runtime": 16843.01871228218, "_timestamp": 1585614212.6515818, "_step": 296}
{"Episode reward": -99.70848057139526, "Episode length": 999, "Policy Loss": -0.4767455458641052, "Value Loss": 0.004245218355208635, "_runtime": 16844.598909139633, "_timestamp": 1585614214.2317786, "_step": 297}
{"Episode reward": -99.80055925457133, "Episode length": 999, "Policy Loss": -0.46196189522743225, "Value Loss": 0.004111813381314278, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113, -0.009647762402892113]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 8.0], "bins": [-0.33956196904182434, -0.33410558104515076, -0.3286491632461548, -0.3231927752494812, -0.31773635745048523, -0.31227996945381165, -0.3068235516548157, -0.3013671636581421, -0.2959107458591461, -0.29045435786247253, -0.28499794006347656, -0.279541552066803, -0.2740851640701294, -0.2686287462711334, -0.26317232847213745, -0.25771594047546387, -0.2522595524787903, -0.2468031346797943, -0.24134673178195953, -0.23589032888412476, -0.23043392598628998, -0.2249775230884552, -0.21952113509178162, -0.21406471729278564, -0.20860832929611206, -0.20315192639827728, -0.1976955235004425, -0.19223912060260773, -0.18678271770477295, -0.18132631480693817, -0.1758699119091034, -0.17041350901126862, -0.16495710611343384, -0.15950070321559906, -0.15404430031776428, -0.1485878974199295, -0.14313149452209473, -0.13767509162425995, -0.13221868872642517, -0.1267622858285904, -0.12130588293075562, -0.11584949493408203, -0.11039309203624725, -0.10493668913841248, -0.0994802862405777, -0.09402388334274292, -0.08856746554374695, -0.08311107754707336, -0.07765468955039978, -0.07219827175140381, -0.06674188375473022, -0.06128546595573425, -0.05582907795906067, -0.0503726601600647, -0.04491627216339111, -0.03945985436439514, -0.03400346636772156, -0.028547048568725586, -0.023090660572052002, -0.01763424277305603, -0.012177854776382446, -0.006721436977386475, -0.0012650489807128906, 0.004191368818283081, 0.009647756814956665]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.020160332322120667, -0.01956285908818245, -0.018965383991599083, -0.018367910757660866, -0.0177704356610775, -0.017172962427139282, -0.016575487330555916, -0.0159780140966177, -0.015380539931356907, -0.014783065766096115, -0.014185591600835323, -0.013588117435574532, -0.012990644201636314, -0.012393169105052948, -0.01179569587111473, -0.011198221705853939, -0.010600747540593147, -0.010003273375332355, -0.009405799210071564, -0.008808325044810772, -0.00821085087954998, -0.007613377645611763, -0.007015903480350971, -0.0064184293150901794, -0.005820955149829388, -0.005223480984568596, -0.004626006819307804, -0.004028532654047012, -0.003431059420108795, -0.0028335843235254288, -0.0022361110895872116, -0.0016386359930038452, -0.001041162759065628, -0.0004436895251274109, 0.0001537855714559555, 0.0007512588053941727, 0.001348733901977539, 0.0019462071359157562, 0.0025436822324991226, 0.0031411554664373398, 0.003738630563020706, 0.004336103796958923, 0.0049335770308971405, 0.005531052127480507, 0.006128525361418724, 0.0067260004580020905, 0.007323473691940308, 0.007920948788523674, 0.008518422022461891, 0.009115895256400108, 0.009713370352983475, 0.010310843586921692, 0.010908318683505058, 0.011505793780088425, 0.012103267014026642, 0.012700740247964859, 0.013298213481903076, 0.013895686715841293, 0.014493163675069809, 0.015090636909008026, 0.015688110142946243, 0.01628558337688446, 0.016883060336112976, 0.017480533570051193, 0.01807800680398941]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 6.0, 7.0, 23.0, 12.0, 8.0, 7.0, 14.0, 9.0, 10.0, 259.0, 8.0, 18.0, 27.0, 7.0, 7.0, 29.0, 14.0, 14.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0719146654009819, -0.06978339701890945, -0.06765212118625641, -0.06552085280418396, -0.06338958442211151, -0.061258312314748764, -0.05912704020738602, -0.05699577182531357, -0.05486449971795082, -0.052733227610588074, -0.050601959228515625, -0.04847068712115288, -0.04633941501379013, -0.04420814663171768, -0.042076874524354935, -0.039945606142282486, -0.03781433403491974, -0.03568306192755699, -0.03355179354548454, -0.031420521438121796, -0.029289253056049347, -0.0271579809486866, -0.025026708841323853, -0.022895440459251404, -0.020764168351888657, -0.01863289624452591, -0.01650162786245346, -0.014370355755090714, -0.012239083647727966, -0.010107815265655518, -0.007976546883583069, -0.005845271050930023, -0.0037140026688575745, -0.0015827342867851257, 0.0005485415458679199, 0.0026798099279403687, 0.004811078310012817, 0.006942354142665863, 0.009073622524738312, 0.01120489090681076, 0.01333615928888321, 0.015467435121536255, 0.017598703503608704, 0.019729971885681152, 0.021861247718334198, 0.023992516100406647, 0.026123784482479095, 0.02825506031513214, 0.03038632869720459, 0.03251759707927704, 0.034648872911930084, 0.03678014129400253, 0.03891140967607498, 0.04104268550872803, 0.043173953890800476, 0.045305222272872925, 0.04743649810552597, 0.04956776648759842, 0.05169903486967087, 0.05383030325174332, 0.055961571633815765, 0.05809285491704941, 0.06022412329912186, 0.062355391681194305, 0.06448666006326675]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1991444230079651, -0.193475142121315, -0.18780586123466492, -0.18213658034801483, -0.17646729946136475, -0.17079801857471466, -0.16512873768806458, -0.1594594419002533, -0.1537901759147644, -0.14812088012695312, -0.14245161414146423, -0.13678231835365295, -0.13111303746700287, -0.12544375658035278, -0.1197744756937027, -0.11410519480705261, -0.10843591392040253, -0.10276663303375244, -0.09709735214710236, -0.09142807126045227, -0.08575879037380219, -0.0800895020365715, -0.07442022114992142, -0.06875094771385193, -0.06308165192604065, -0.057412371039390564, -0.05174309015274048, -0.04607380926609039, -0.04040452837944031, -0.03473524749279022, -0.029065966606140137, -0.02339668571949005, -0.017727404832839966, -0.01205812394618988, -0.006388843059539795, -0.0007195621728897095, 0.004949718713760376, 0.010618999600410461, 0.016288280487060547, 0.021957561373710632, 0.027626842260360718, 0.033296138048172, 0.03896541893482208, 0.04463469982147217, 0.05030398070812225, 0.05597326159477234, 0.06164252758026123, 0.06731182336807251, 0.07298111915588379, 0.07865038514137268, 0.08431968092918396, 0.08998894691467285, 0.09565824270248413, 0.10132750868797302, 0.1069968044757843, 0.1126660704612732, 0.11833536624908447, 0.12400463223457336, 0.12967392802238464, 0.13534319400787354, 0.14101248979568481, 0.1466817557811737, 0.15235105156898499, 0.15802031755447388, 0.16368961334228516]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 6.0, 8.0, 1.0, 3.0, 0.0, 6.0, 2.0, 3.0, 1.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.13858561217784882, -0.1349835842847824, -0.131381556391716, -0.1277795284986496, -0.12417750805616379, -0.12057548016309738, -0.11697345227003098, -0.11337143182754517, -0.10976940393447876, -0.10616737604141235, -0.10256534814834595, -0.09896332025527954, -0.09536129236221313, -0.09175927191972733, -0.08815724402666092, -0.08455522358417511, -0.0809531956911087, -0.0773511677980423, -0.07374913990497589, -0.07014711201190948, -0.06654508411884308, -0.06294306367635727, -0.05934103578329086, -0.05573900789022446, -0.05213697999715805, -0.048534952104091644, -0.044932931661605835, -0.04133090376853943, -0.03772887587547302, -0.034126847982406616, -0.030524827539920807, -0.0269227996468544, -0.023320771753787994, -0.019718743860721588, -0.016116715967655182, -0.012514695525169373, -0.008912667632102966, -0.00531063973903656, -0.0017086118459701538, 0.0018934160470962524, 0.005495443940162659, 0.009097471833229065, 0.012699484825134277, 0.016301512718200684, 0.01990354061126709, 0.023505568504333496, 0.027107596397399902, 0.03070962429046631, 0.034311652183532715, 0.03791368007659912, 0.04151570796966553, 0.04511772096157074, 0.048719748854637146, 0.05232177674770355, 0.05592380464076996, 0.059525832533836365, 0.06312786042690277, 0.06672988831996918, 0.07033191621303558, 0.07393394410610199, 0.0775359570980072, 0.08113798499107361, 0.08474001288414001, 0.08834204077720642, 0.09194406867027283]}, "_runtime": 16846.208091020584, "_timestamp": 1585614215.8409605, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4611418545246124, "Value Loss": 0.003964998759329319, "_runtime": 16847.266763210297, "_timestamp": 1585614216.8996327, "_step": 299}
{"Episode reward": 35.086553168296234, "Episode length": 650, "Policy Loss": 0.7380403280258179, "Value Loss": 15.369441032409668, "_runtime": 16848.853826522827, "_timestamp": 1585614218.486696, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4457341432571411, "Value Loss": 0.003703261725604534, "_runtime": 16850.468037366867, "_timestamp": 1585614220.1009068, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44277292490005493, "Value Loss": 0.003586957696825266, "_runtime": 16852.038780212402, "_timestamp": 1585614221.6716497, "_step": 302}
{"Episode reward": -99.85686967829102, "Episode length": 999, "Policy Loss": -0.42863619327545166, "Value Loss": 0.0034558766055852175, "_runtime": 16852.855249643326, "_timestamp": 1585614222.4881191, "_step": 303}
{"Episode reward": 50.6996967408569, "Episode length": 494, "Policy Loss": 1.2832242250442505, "Value Loss": 20.222877502441406, "_runtime": 16854.45159459114, "_timestamp": 1585614224.084464, "_step": 304}
{"Episode reward": -99.86201177984336, "Episode length": 999, "Policy Loss": -0.4210476875305176, "Value Loss": 0.003255911637097597, "_runtime": 16856.04631972313, "_timestamp": 1585614225.6791892, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41688376665115356, "Value Loss": 0.003179647959768772, "_runtime": 16857.600319623947, "_timestamp": 1585614227.233189, "_step": 306}
{"Episode reward": -99.80124177450641, "Episode length": 999, "Policy Loss": -0.3977799117565155, "Value Loss": 0.0030859699472784996, "_runtime": 16858.678713560104, "_timestamp": 1585614228.311583, "_step": 307}
{"Episode reward": 33.72168008186222, "Episode length": 663, "Policy Loss": 0.7324292659759521, "Value Loss": 15.069450378417969, "_runtime": 16860.280782699585, "_timestamp": 1585614229.9136522, "_step": 308}
{"Episode reward": -99.8485040673099, "Episode length": 999, "Policy Loss": -0.38704225420951843, "Value Loss": 0.0029244455508887768, "_runtime": 16861.36623954773, "_timestamp": 1585614230.999109, "_step": 309}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": 0.7830362915992737, "Value Loss": 14.801834106445312, "_runtime": 16862.94079518318, "_timestamp": 1585614232.5736647, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3951346278190613, "Value Loss": 0.002832194324582815, "_runtime": 16863.329374313354, "_timestamp": 1585614232.9622438, "_step": 311}
{"Episode reward": 79.39999999999998, "Episode length": 206, "Policy Loss": 3.112959861755371, "Value Loss": 48.49523162841797, "_runtime": 16864.940712690353, "_timestamp": 1585614234.5735822, "_step": 312}
{"Episode reward": -99.71832013605024, "Episode length": 999, "Policy Loss": -0.38411012291908264, "Value Loss": 0.0029066281858831644, "_runtime": 16865.49066734314, "_timestamp": 1585614235.1235368, "_step": 313}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 1.860404372215271, "Value Loss": 31.514171600341797, "_runtime": 16866.018315076828, "_timestamp": 1585614235.6511846, "_step": 314}
{"Episode reward": 65.49999999999979, "Episode length": 345, "Policy Loss": 1.6310527324676514, "Value Loss": 28.955944061279297, "_runtime": 16867.611493349075, "_timestamp": 1585614237.2443628, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42371395230293274, "Value Loss": 0.00345511082559824, "_runtime": 16869.1485748291, "_timestamp": 1585614238.7814443, "_step": 316}
{"Episode reward": -99.5397472962956, "Episode length": 999, "Policy Loss": -0.43923333287239075, "Value Loss": 0.003669122466817498, "_runtime": 16870.008561611176, "_timestamp": 1585614239.641431, "_step": 317}
{"Episode reward": 44.666746306418865, "Episode length": 554, "Policy Loss": 0.8365724086761475, "Value Loss": 18.03196144104004, "_runtime": 16871.603395462036, "_timestamp": 1585614241.236265, "_step": 318}
{"Episode reward": -99.81667045438522, "Episode length": 999, "Policy Loss": -0.4618748724460602, "Value Loss": 0.004080689512193203, "_runtime": 16873.18304014206, "_timestamp": 1585614242.8159096, "_step": 319}
{"Episode reward": -99.71638006216243, "Episode length": 999, "Policy Loss": -0.4713141620159149, "Value Loss": 0.004249797202646732, "_runtime": 16874.719341516495, "_timestamp": 1585614244.352211, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4848797023296356, "Value Loss": 0.004391032736748457, "_runtime": 16876.307052850723, "_timestamp": 1585614245.9399223, "_step": 321}
{"Episode reward": -99.73067559385532, "Episode length": 999, "Policy Loss": -0.4891830086708069, "Value Loss": 0.004471598658710718, "_runtime": 16877.88734316826, "_timestamp": 1585614247.5202127, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49792882800102234, "Value Loss": 0.004528338555246592, "_runtime": 16879.009516000748, "_timestamp": 1585614248.6423855, "_step": 323}
{"Episode reward": 29.088045766576883, "Episode length": 710, "Policy Loss": 0.8541716933250427, "Value Loss": 14.070069313049316, "_runtime": 16880.59665632248, "_timestamp": 1585614250.2295258, "_step": 324}
{"Episode reward": -99.76480333963269, "Episode length": 999, "Policy Loss": -0.49312078952789307, "Value Loss": 0.004574661608785391, "_runtime": 16882.081481456757, "_timestamp": 1585614251.714351, "_step": 325}
{"Episode reward": 7.299180701003479, "Episode length": 928, "Policy Loss": 0.29752060770988464, "Value Loss": 10.765852928161621, "_runtime": 16882.774689912796, "_timestamp": 1585614252.4075594, "_step": 326}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.1876221895217896, "Value Loss": 23.22882652282715, "_runtime": 16884.281861782074, "_timestamp": 1585614253.9147313, "_step": 327}
{"Episode reward": 5.258108079009631, "Episode length": 948, "Policy Loss": 0.25546708703041077, "Value Loss": 10.538748741149902, "_runtime": 16885.860538959503, "_timestamp": 1585614255.4934084, "_step": 328}
{"Episode reward": -99.63213519574936, "Episode length": 999, "Policy Loss": -0.503424882888794, "Value Loss": 0.004827186465263367, "_runtime": 16886.972766160965, "_timestamp": 1585614256.6056356, "_step": 329}
{"Episode reward": 28.18585498183947, "Episode length": 719, "Policy Loss": 0.4962337613105774, "Value Loss": 13.893614768981934, "_runtime": 16888.59032058716, "_timestamp": 1585614258.22319, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5111849904060364, "Value Loss": 0.005007654428482056, "_runtime": 16890.175847530365, "_timestamp": 1585614259.808717, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5217914581298828, "Value Loss": 0.005060466006398201, "_runtime": 16891.62112903595, "_timestamp": 1585614261.2539985, "_step": 332}
{"Episode reward": 7.366506843619106, "Episode length": 927, "Policy Loss": 0.29806047677993774, "Value Loss": 10.777175903320312, "_runtime": 16893.213318109512, "_timestamp": 1585614262.8461876, "_step": 333}
{"Episode reward": -99.80170683124895, "Episode length": 999, "Policy Loss": -0.5291169285774231, "Value Loss": 0.005096732638776302, "_runtime": 16894.155876874924, "_timestamp": 1585614263.7887464, "_step": 334}
{"Episode reward": 41.8864120761611, "Episode length": 582, "Policy Loss": 0.7128860950469971, "Value Loss": 17.1923770904541, "_runtime": 16895.75068116188, "_timestamp": 1585614265.3835506, "_step": 335}
{"Episode reward": -99.72650367747853, "Episode length": 999, "Policy Loss": -0.5082379579544067, "Value Loss": 0.00512188533321023, "_runtime": 16896.62641429901, "_timestamp": 1585614266.2592838, "_step": 336}
{"Episode reward": 46.99749331325245, "Episode length": 531, "Policy Loss": 0.82448810338974, "Value Loss": 18.810516357421875, "_runtime": 16897.292598485947, "_timestamp": 1585614266.925468, "_step": 337}
{"Episode reward": 58.59999999999969, "Episode length": 414, "Policy Loss": 1.2801231145858765, "Value Loss": 24.124921798706055, "_runtime": 16898.892554044724, "_timestamp": 1585614268.5254235, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5389881134033203, "Value Loss": 0.005342612974345684, "_runtime": 16900.45285177231, "_timestamp": 1585614270.0857213, "_step": 339}
{"Episode reward": -99.80005945572489, "Episode length": 999, "Policy Loss": -0.5415107011795044, "Value Loss": 0.005431533325463533, "_runtime": 16901.646305322647, "_timestamp": 1585614271.2791748, "_step": 340}
{"Episode reward": 22.80000000000011, "Episode length": 772, "Policy Loss": 0.3899572789669037, "Value Loss": 12.939682960510254, "_runtime": 16903.23887181282, "_timestamp": 1585614272.8717413, "_step": 341}
{"Episode reward": -99.61309786215286, "Episode length": 999, "Policy Loss": -0.5478607416152954, "Value Loss": 0.005537951830774546, "_runtime": 16903.89890217781, "_timestamp": 1585614273.5317717, "_step": 342}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.2775603532791138, "Value Loss": 25.156888961791992, "_runtime": 16905.002680540085, "_timestamp": 1585614274.63555, "_step": 343}
{"Episode reward": 29.499842848535366, "Episode length": 706, "Policy Loss": 0.49207231402397156, "Value Loss": 14.148618698120117, "_runtime": 16905.80558490753, "_timestamp": 1585614275.4384544, "_step": 344}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 0.8961454629898071, "Value Loss": 20.29998016357422, "_runtime": 16907.355771303177, "_timestamp": 1585614276.9886408, "_step": 345}
{"Episode reward": -99.76327359620925, "Episode length": 999, "Policy Loss": -0.5611452460289001, "Value Loss": 0.006032187957316637, "_runtime": 16908.905079126358, "_timestamp": 1585614278.5379486, "_step": 346}
{"Episode reward": -99.81826957203309, "Episode length": 999, "Policy Loss": -0.5720889568328857, "Value Loss": 0.006179561372846365, "_runtime": 16910.436958551407, "_timestamp": 1585614280.069828, "_step": 347}
{"Episode reward": -99.81631599813561, "Episode length": 999, "Policy Loss": -0.5823534727096558, "Value Loss": 0.006263141054660082, "_runtime": 16911.837534427643, "_timestamp": 1585614281.470404, "_step": 348}
{"Episode reward": 12.068859703094489, "Episode length": 882, "Policy Loss": 0.2429552674293518, "Value Loss": 11.326130867004395, "_runtime": 16912.64047074318, "_timestamp": 1585614282.2733402, "_step": 349}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 0.9064891934394836, "Value Loss": 20.29913902282715, "_runtime": 16914.25401210785, "_timestamp": 1585614283.8868816, "_step": 350}
{"Episode reward": -99.84754718625778, "Episode length": 999, "Policy Loss": -0.5974217653274536, "Value Loss": 0.006455407477915287, "_runtime": 16915.494782447815, "_timestamp": 1585614285.127652, "_step": 351}
{"Episode reward": 22.143217176239844, "Episode length": 780, "Policy Loss": 0.41145315766334534, "Value Loss": 12.806327819824219, "_runtime": 16917.025094270706, "_timestamp": 1585614286.6579638, "_step": 352}
{"Episode reward": 1.3895923387272546, "Episode length": 988, "Policy Loss": 0.15115974843502045, "Value Loss": 10.111621856689453, "_runtime": 16918.445987939835, "_timestamp": 1585614288.0788574, "_step": 353}
{"Episode reward": 10.50000000000081, "Episode length": 895, "Policy Loss": 0.2133471965789795, "Value Loss": 11.16161060333252, "_runtime": 16920.016781568527, "_timestamp": 1585614289.649651, "_step": 354}
{"Episode reward": -99.89319248506659, "Episode length": 999, "Policy Loss": -0.607571542263031, "Value Loss": 0.006775778718292713, "_runtime": 16921.593594312668, "_timestamp": 1585614291.2264638, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6100296974182129, "Value Loss": 0.006812443025410175, "_runtime": 16923.177427768707, "_timestamp": 1585614292.8102973, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6044914722442627, "Value Loss": 0.006794234737753868, "_runtime": 16924.752294301987, "_timestamp": 1585614294.3851638, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6022481322288513, "Value Loss": 0.006727772764861584, "_runtime": 16926.334153413773, "_timestamp": 1585614295.967023, "_step": 358}
{"Episode reward": -99.89722412563721, "Episode length": 999, "Policy Loss": -0.5938998460769653, "Value Loss": 0.006618204526603222, "_runtime": 16927.925848960876, "_timestamp": 1585614297.5587184, "_step": 359}
{"Episode reward": -99.805665344371, "Episode length": 999, "Policy Loss": -0.5912032723426819, "Value Loss": 0.006462709978222847, "_runtime": 16929.517687559128, "_timestamp": 1585614299.150557, "_step": 360}
{"Episode reward": -99.7331824925947, "Episode length": 999, "Policy Loss": -0.5788365006446838, "Value Loss": 0.006282432470470667, "_runtime": 16931.106850862503, "_timestamp": 1585614300.7397203, "_step": 361}
{"Episode reward": -99.83266502022603, "Episode length": 999, "Policy Loss": -0.5695456266403198, "Value Loss": 0.006084575317800045, "_runtime": 16931.70993757248, "_timestamp": 1585614301.342807, "_step": 362}
{"Episode reward": 64.8769164442781, "Episode length": 352, "Policy Loss": 1.6515320539474487, "Value Loss": 28.371423721313477, "_runtime": 16933.28921031952, "_timestamp": 1585614302.9220798, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.558346688747406, "Value Loss": 0.0057825930416584015, "_runtime": 16933.943743944168, "_timestamp": 1585614303.5766134, "_step": 364}
{"Episode reward": 61.07933480739566, "Episode length": 390, "Policy Loss": 1.3334715366363525, "Value Loss": 25.60809326171875, "_runtime": 16934.655138254166, "_timestamp": 1585614304.2880077, "_step": 365}
{"Episode reward": 53.75189436256004, "Episode length": 464, "Policy Loss": 1.0045280456542969, "Value Loss": 21.52493667602539, "_runtime": 16935.199931144714, "_timestamp": 1585614304.8328006, "_step": 366}
{"Episode reward": 68.35507957003993, "Episode length": 317, "Policy Loss": 2.0375030040740967, "Value Loss": 31.503684997558594, "_runtime": 16936.740940093994, "_timestamp": 1585614306.3738096, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5697420835494995, "Value Loss": 0.005948055535554886, "_runtime": 16937.45552134514, "_timestamp": 1585614307.0883908, "_step": 368}
{"Episode reward": 57.485866457130435, "Episode length": 426, "Policy Loss": 1.1145631074905396, "Value Loss": 23.44359588623047, "_runtime": 16938.97220468521, "_timestamp": 1585614308.6050742, "_step": 369}
{"Episode reward": -99.8397098437869, "Episode length": 999, "Policy Loss": -0.5816774368286133, "Value Loss": 0.00631079962477088, "_runtime": 16940.555339813232, "_timestamp": 1585614310.1882093, "_step": 370}
{"Episode reward": -99.86338915983076, "Episode length": 999, "Policy Loss": -0.5964517593383789, "Value Loss": 0.00646992027759552, "_runtime": 16942.06709909439, "_timestamp": 1585614311.6999686, "_step": 371}
{"Episode reward": 1.8878827256861967, "Episode length": 982, "Policy Loss": 0.1662587970495224, "Value Loss": 10.173368453979492, "_runtime": 16943.64077615738, "_timestamp": 1585614313.2736456, "_step": 372}
{"Episode reward": -99.87948445118823, "Episode length": 999, "Policy Loss": -0.6035042405128479, "Value Loss": 0.006665390450507402, "_runtime": 16945.048909902573, "_timestamp": 1585614314.6817794, "_step": 373}
{"Episode reward": 11.971884244587997, "Episode length": 881, "Policy Loss": 0.3137663006782532, "Value Loss": 11.338851928710938, "_runtime": 16945.726365327835, "_timestamp": 1585614315.3592348, "_step": 374}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": 1.6714775562286377, "Value Loss": 24.35688591003418, "_runtime": 16947.30146074295, "_timestamp": 1585614316.9343302, "_step": 375}
{"Episode reward": -99.80673355618352, "Episode length": 999, "Policy Loss": -0.6111119985580444, "Value Loss": 0.006907247472554445, "_runtime": 16948.350074529648, "_timestamp": 1585614317.982944, "_step": 376}
{"Episode reward": 34.82392745350896, "Episode length": 653, "Policy Loss": 0.7149566411972046, "Value Loss": 15.295283317565918, "_runtime": 16949.890092611313, "_timestamp": 1585614319.522962, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6145644187927246, "Value Loss": 0.007119929417967796, "_runtime": 16951.47948360443, "_timestamp": 1585614321.112353, "_step": 378}
{"Episode reward": -99.81206103712181, "Episode length": 999, "Policy Loss": -0.6208150386810303, "Value Loss": 0.007168775890022516, "_runtime": 16952.845055818558, "_timestamp": 1585614322.4779253, "_step": 379}
{"Episode reward": 12.939695348591286, "Episode length": 872, "Policy Loss": 0.21596165001392365, "Value Loss": 11.455607414245605, "_runtime": 16953.739602327347, "_timestamp": 1585614323.3724718, "_step": 380}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.7109813094139099, "Value Loss": 18.059696197509766, "_runtime": 16955.327652215958, "_timestamp": 1585614324.9605217, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.63295978307724, "Value Loss": 0.007265124935656786, "_runtime": 16956.903778791428, "_timestamp": 1585614326.5366483, "_step": 382}
{"Episode reward": -99.8873050937648, "Episode length": 999, "Policy Loss": -0.619564414024353, "Value Loss": 0.007277148310095072, "_runtime": 16958.447298765182, "_timestamp": 1585614328.0801682, "_step": 383}
{"Episode reward": -99.83862504148716, "Episode length": 999, "Policy Loss": -0.6199161410331726, "Value Loss": 0.007230001967400312, "_runtime": 16960.03407931328, "_timestamp": 1585614329.6669488, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6174222826957703, "Value Loss": 0.007143870927393436, "_runtime": 16961.667912960052, "_timestamp": 1585614331.3007824, "_step": 385}
{"Episode reward": -99.8079101562486, "Episode length": 999, "Policy Loss": -0.6130019426345825, "Value Loss": 0.00699995644390583, "_runtime": 16963.001544952393, "_timestamp": 1585614332.6344144, "_step": 386}
{"Episode reward": 15.892900494393473, "Episode length": 842, "Policy Loss": 0.2454591691493988, "Value Loss": 11.863678932189941, "_runtime": 16964.586762666702, "_timestamp": 1585614334.2196321, "_step": 387}
{"Episode reward": -99.83879592753807, "Episode length": 999, "Policy Loss": -0.6047177910804749, "Value Loss": 0.006692314520478249, "_runtime": 16966.1581492424, "_timestamp": 1585614335.7910187, "_step": 388}
{"Episode reward": 1.7322746942065663, "Episode length": 986, "Policy Loss": 0.25569379329681396, "Value Loss": 10.132119178771973, "_runtime": 16966.77882194519, "_timestamp": 1585614336.4116914, "_step": 389}
{"Episode reward": 62.6965736372161, "Episode length": 374, "Policy Loss": 1.3481839895248413, "Value Loss": 26.70163345336914, "_runtime": 16968.362892389297, "_timestamp": 1585614337.9957619, "_step": 390}
{"Episode reward": -99.64660318617105, "Episode length": 999, "Policy Loss": -0.5807048678398132, "Value Loss": 0.006363304331898689, "_runtime": 16969.169589996338, "_timestamp": 1585614338.8024595, "_step": 391}
{"Episode reward": 51.099999932106165, "Episode length": 490, "Policy Loss": 1.0289298295974731, "Value Loss": 20.381994247436523, "_runtime": 16970.02804517746, "_timestamp": 1585614339.6609147, "_step": 392}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.7600023746490479, "Value Loss": 17.96331787109375, "_runtime": 16971.6008849144, "_timestamp": 1585614341.2337544, "_step": 393}
{"Episode reward": -99.68130948738988, "Episode length": 999, "Policy Loss": -0.5898379683494568, "Value Loss": 0.006419778801500797, "_runtime": 16973.150038719177, "_timestamp": 1585614342.7829082, "_step": 394}
{"Episode reward": -99.75119731880703, "Episode length": 999, "Policy Loss": -0.5863680243492126, "Value Loss": 0.006450311280786991, "_runtime": 16973.668238162994, "_timestamp": 1585614343.3011076, "_step": 395}
{"Episode reward": 68.39999999999984, "Episode length": 316, "Policy Loss": 1.709208607673645, "Value Loss": 31.60126495361328, "_runtime": 16974.787695884705, "_timestamp": 1585614344.4205654, "_step": 396}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.41117241978645325, "Value Loss": 14.188101768493652, "_runtime": 16975.19170308113, "_timestamp": 1585614344.8245726, "_step": 397}
{"Episode reward": 77.5060367787431, "Episode length": 226, "Policy Loss": 2.6973557472229004, "Value Loss": 44.18196105957031, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243, -0.00018937073764391243]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0014619710855185986, 0.004432487767189741, 0.010326946154236794, 0.01622140407562256, 0.022115863859653473, 0.028010323643684387, 0.033904779702425, 0.03979923948645592, 0.04569369927048683, 0.051588159054517746, 0.05748261883854866, 0.06337708234786987, 0.06927153468132019, 0.0751659944653511, 0.08106045424938202, 0.08695491403341293, 0.09284937381744385, 0.09874383360147476, 0.10463829338550568, 0.11053275316953659, 0.1164272129535675, 0.12232166528701782, 0.12821613252162933, 0.13411058485507965, 0.14000503718852997, 0.14589950442314148, 0.1517939567565918, 0.1576884239912033, 0.16358287632465363, 0.16947734355926514, 0.17537179589271545, 0.18126626312732697, 0.18716071546077728, 0.1930551677942276, 0.1989496350288391, 0.20484408736228943, 0.21073855459690094, 0.21663300693035126, 0.22252747416496277, 0.22842192649841309, 0.2343163937330246, 0.24021084606647491, 0.24610529839992523, 0.25199973583221436, 0.25789421796798706, 0.2637886703014374, 0.2696831226348877, 0.275577574968338, 0.28147202730178833, 0.28736650943756104, 0.29326096177101135, 0.29915541410446167, 0.305049866437912, 0.3109443485736847, 0.316838800907135, 0.3227332532405853, 0.32862770557403564, 0.33452215790748596, 0.34041664004325867, 0.346311092376709, 0.3522055447101593, 0.3580999970436096, 0.3639944791793823, 0.36988893151283264, 0.37578338384628296]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.003448085393756628, -0.00330172898247838, -0.003155372804030776, -0.003009016625583172, -0.002862660214304924, -0.002716303803026676, -0.002569947624579072, -0.002423591446131468, -0.00227723503485322, -0.002130878623574972, -0.001984522445127368, -0.001838166150264442, -0.001691809855401516, -0.00154545356053859, -0.001399097265675664, -0.0012527410872280598, -0.001106384675949812, -0.0009600282646715641, -0.0008136720862239599, -0.0006673159077763557, -0.0005209594964981079, -0.0003746030852198601, -0.0002282469067722559, -8.189072832465172e-05, 6.446568295359612e-05, 0.00021082209423184395, 0.00035717827267944813, 0.0005035344511270523, 0.0006498908624053001, 0.000796247273683548, 0.0009426032193005085, 0.0010889596305787563, 0.0012353160418570042, 0.001381672453135252, 0.0015280288644134998, 0.0016743848100304604, 0.0018207412213087082, 0.001967097632586956, 0.0021134535782039165, 0.0022598099894821644, 0.002406166400760412, 0.00255252281203866, 0.002698879223316908, 0.0028452351689338684, 0.0029915915802121162, 0.003137947991490364, 0.0032843039371073246, 0.0034306603483855724, 0.0035770167596638203, 0.003723373170942068, 0.003869729582220316, 0.0040160855278372765, 0.004162441939115524, 0.004308798350393772, 0.004455154296010733, 0.0046015107072889805, 0.004747867118567228, 0.004894223529845476, 0.005040579941123724, 0.005186936352401972, 0.005333291832357645, 0.005479648243635893, 0.005626004654914141, 0.0057723610661923885, 0.005918717477470636]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 6.0, 3.0, 2.0, 7.0, 13.0, 22.0, 17.0, 47.0, 266.0, 21.0, 2.0, 3.0, 2.0, 9.0, 4.0, 5.0, 1.0, 5.0, 6.0, 8.0, 10.0, 7.0, 4.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.05832754820585251, -0.056400757282972336, -0.05447396636009216, -0.05254717171192169, -0.05062038078904152, -0.048693589866161346, -0.046766795217990875, -0.0448400042951107, -0.04291321337223053, -0.04098642244935036, -0.039059631526470184, -0.03713283687829971, -0.03520604595541954, -0.03327925503253937, -0.031352460384368896, -0.029425669461488724, -0.02749887853860855, -0.02557208761572838, -0.023645296692848206, -0.021718502044677734, -0.01979171112179756, -0.01786492019891739, -0.015938125550746918, -0.014011334627866745, -0.012084543704986572, -0.0101577527821064, -0.008230961859226227, -0.006304167211055756, -0.004377376288175583, -0.00245058536529541, -0.000523790717124939, 0.0014030002057552338, 0.0033297911286354065, 0.005256585776805878, 0.007183372974395752, 0.009110167622566223, 0.011036954820156097, 0.012963749468326569, 0.01489054411649704, 0.016817331314086914, 0.018744125962257385, 0.020670920610427856, 0.02259770780801773, 0.024524502456188202, 0.026451297104358673, 0.028378084301948547, 0.03030487895011902, 0.03223166614770889, 0.034158460795879364, 0.036085255444049835, 0.03801204264163971, 0.03993883728981018, 0.041865624487400055, 0.043792419135570526, 0.045719213783741, 0.04764600098133087, 0.04957279562950134, 0.051499590277671814, 0.05342637747526169, 0.05535317212343216, 0.05727996677160263, 0.059206753969192505, 0.061133548617362976, 0.06306033581495285, 0.06498713046312332]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01823447272181511, -0.016813157126307487, -0.015391841530799866, -0.013970525935292244, -0.012549210339784622, -0.011127894744277, -0.009706579148769379, -0.008285263553261757, -0.006863947957754135, -0.005442632362246513, -0.004021316766738892, -0.00260000117123127, -0.001178685575723648, 0.0002426300197839737, 0.0016639456152915955, 0.0030852612107992172, 0.004506576806306839, 0.005927892401814461, 0.0073492079973220825, 0.008770523592829704, 0.010191839188337326, 0.011613154783844948, 0.01303447037935257, 0.014455784112215042, 0.015877101570367813, 0.017298419028520584, 0.018719732761383057, 0.02014104649424553, 0.0215623639523983, 0.02298368141055107, 0.024404995143413544, 0.025826308876276016, 0.027247626334428787, 0.028668943792581558, 0.03009025752544403, 0.0315115712583065, 0.032932888716459274, 0.034354206174612045, 0.03577551990747452, 0.03719683364033699, 0.03861815109848976, 0.04003946855664253, 0.041460782289505005, 0.04288209602236748, 0.04430341348052025, 0.04572473093867302, 0.047146040946245193, 0.048567358404397964, 0.049988675862550735, 0.051409993320703506, 0.05283131077885628, 0.05425262078642845, 0.05567393824458122, 0.057095255702733994, 0.05851656571030617, 0.05993788316845894, 0.06135920062661171, 0.06278051435947418, 0.06420183181762695, 0.06562314927577972, 0.0670444667339325, 0.06846578419208527, 0.06988708674907684, 0.07130840420722961, 0.07272972166538239]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 9.0, 15.0, 10.0, 2.0, 6.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.21043914556503296, -0.20571379363536835, -0.20098845660686493, -0.19626310467720032, -0.1915377676486969, -0.1868124157190323, -0.18208707869052887, -0.17736172676086426, -0.17263638973236084, -0.16791103780269623, -0.16318568587303162, -0.1584603488445282, -0.1537349969148636, -0.14900965988636017, -0.14428430795669556, -0.13955897092819214, -0.13483361899852753, -0.13010826706886292, -0.1253829300403595, -0.12065758556127548, -0.11593224108219147, -0.11120688915252686, -0.10648154467344284, -0.10175620019435883, -0.09703085571527481, -0.0923055112361908, -0.08758016675710678, -0.08285482227802277, -0.07812947034835815, -0.07340413331985474, -0.06867878139019012, -0.0639534443616867, -0.059228092432022095, -0.05450274050235748, -0.049777403473854065, -0.04505205154418945, -0.040326714515686035, -0.03560136258602142, -0.030876025557518005, -0.026150673627853394, -0.021425336599349976, -0.016699984669685364, -0.011974632740020752, -0.007249295711517334, -0.002523943781852722, 0.002201393246650696, 0.006926745176315308, 0.011652082204818726, 0.016377434134483337, 0.02110278606414795, 0.025828123092651367, 0.03055347502231598, 0.0352788120508194, 0.04000416398048401, 0.04472950100898743, 0.049454838037490845, 0.05418020486831665, 0.05890554189682007, 0.06363087892532349, 0.06835624575614929, 0.07308158278465271, 0.07780691981315613, 0.08253225684165955, 0.08725762367248535, 0.09198296070098877]}, "_runtime": 16976.72529554367, "_timestamp": 1585614346.358165, "_step": 398}
{"Episode reward": -99.8983285763287, "Episode length": 999, "Policy Loss": -0.6169435381889343, "Value Loss": 0.007077587302774191, "_runtime": 16977.961503982544, "_timestamp": 1585614347.5943735, "_step": 399}
{"Episode reward": 22.06391315569651, "Episode length": 780, "Policy Loss": 0.4571288228034973, "Value Loss": 12.805889129638672, "_runtime": 16979.254363298416, "_timestamp": 1585614348.8872328, "_step": 400}
{"Episode reward": 14.389991214033799, "Episode length": 858, "Policy Loss": 0.22242334485054016, "Value Loss": 11.6422700881958, "_runtime": 16980.84507369995, "_timestamp": 1585614350.4779432, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6562666893005371, "Value Loss": 0.007933182641863823, "_runtime": 16982.07597875595, "_timestamp": 1585614351.7088482, "_step": 402}
{"Episode reward": 22.07533456645922, "Episode length": 780, "Policy Loss": 0.30375853180885315, "Value Loss": 12.809416770935059, "_runtime": 16983.62267780304, "_timestamp": 1585614353.2555473, "_step": 403}
{"Episode reward": -99.70258888556133, "Episode length": 999, "Policy Loss": -0.6612905263900757, "Value Loss": 0.00832311250269413, "_runtime": 16985.2192299366, "_timestamp": 1585614354.8520994, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6817747950553894, "Value Loss": 0.008464455604553223, "_runtime": 16986.232320547104, "_timestamp": 1585614355.86519, "_step": 405}
{"Episode reward": 36.52049355907303, "Episode length": 636, "Policy Loss": 0.465519517660141, "Value Loss": 15.702765464782715, "_runtime": 16987.827243566513, "_timestamp": 1585614357.460113, "_step": 406}
{"Episode reward": -99.71173592889542, "Episode length": 999, "Policy Loss": -0.682855486869812, "Value Loss": 0.008581133559346199, "_runtime": 16988.894942760468, "_timestamp": 1585614358.5278122, "_step": 407}
{"Episode reward": 33.55847368594209, "Episode length": 665, "Policy Loss": 0.4135119915008545, "Value Loss": 15.018290519714355, "_runtime": 16990.41956758499, "_timestamp": 1585614360.052437, "_step": 408}
{"Episode reward": 2.7842315778148787, "Episode length": 973, "Policy Loss": 0.3191479444503784, "Value Loss": 10.267023086547852, "_runtime": 16991.99559855461, "_timestamp": 1585614361.628468, "_step": 409}
{"Episode reward": -99.75711009374214, "Episode length": 999, "Policy Loss": -0.6839909553527832, "Value Loss": 0.008712172508239746, "_runtime": 16993.559361457825, "_timestamp": 1585614363.192231, "_step": 410}
{"Episode reward": -99.88847524262825, "Episode length": 999, "Policy Loss": -0.6884570121765137, "Value Loss": 0.008709828369319439, "_runtime": 16994.340383291245, "_timestamp": 1585614363.9732528, "_step": 411}
{"Episode reward": 52.57408965797473, "Episode length": 476, "Policy Loss": 0.8481969833374023, "Value Loss": 20.97797966003418, "_runtime": 16995.920711755753, "_timestamp": 1585614365.5535812, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.681397020816803, "Value Loss": 0.008640693500638008, "_runtime": 16997.5160241127, "_timestamp": 1585614367.1488936, "_step": 413}
{"Episode reward": -99.73003988275165, "Episode length": 999, "Policy Loss": -0.6836945414543152, "Value Loss": 0.008566894568502903, "_runtime": 16999.0608792305, "_timestamp": 1585614368.6937487, "_step": 414}
{"Episode reward": -99.7410679251873, "Episode length": 999, "Policy Loss": -0.678933322429657, "Value Loss": 0.008449274115264416, "_runtime": 17000.50355529785, "_timestamp": 1585614370.1364248, "_step": 415}
{"Episode reward": 9.600000000000861, "Episode length": 904, "Policy Loss": 0.11333489418029785, "Value Loss": 11.050070762634277, "_runtime": 17002.0925886631, "_timestamp": 1585614371.7254581, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6510838270187378, "Value Loss": 0.008156409487128258, "_runtime": 17003.188116312027, "_timestamp": 1585614372.8209858, "_step": 417}
{"Episode reward": 31.738706133409465, "Episode length": 687, "Policy Loss": 0.7674803733825684, "Value Loss": 14.537955284118652, "_runtime": 17004.765861272812, "_timestamp": 1585614374.3987308, "_step": 418}
{"Episode reward": -99.80011187195639, "Episode length": 999, "Policy Loss": -0.6588526964187622, "Value Loss": 0.007834223099052906, "_runtime": 17005.69349718094, "_timestamp": 1585614375.3263667, "_step": 419}
{"Episode reward": 42.799999999999464, "Episode length": 572, "Policy Loss": 0.5894754528999329, "Value Loss": 17.459579467773438, "_runtime": 17006.203629493713, "_timestamp": 1585614375.836499, "_step": 420}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": 1.7294503450393677, "Value Loss": 32.63045883178711, "_runtime": 17007.406939268112, "_timestamp": 1585614377.0398088, "_step": 421}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.34360450506210327, "Value Loss": 13.056694030761719, "_runtime": 17008.396856307983, "_timestamp": 1585614378.0297258, "_step": 422}
{"Episode reward": 36.491271480824174, "Episode length": 636, "Policy Loss": 0.4839390814304352, "Value Loss": 15.70333194732666, "_runtime": 17009.62832593918, "_timestamp": 1585614379.2611954, "_step": 423}
{"Episode reward": 18.800000000000338, "Episode length": 812, "Policy Loss": 0.2583392560482025, "Value Loss": 12.301284790039062, "_runtime": 17011.19296193123, "_timestamp": 1585614380.8258314, "_step": 424}
{"Episode reward": -99.76190914260084, "Episode length": 999, "Policy Loss": -0.6583712100982666, "Value Loss": 0.008021501824259758, "_runtime": 17012.784994125366, "_timestamp": 1585614382.4178636, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6629667282104492, "Value Loss": 0.008109088987112045, "_runtime": 17014.329156398773, "_timestamp": 1585614383.962026, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6654018759727478, "Value Loss": 0.008110909722745419, "_runtime": 17015.914382219315, "_timestamp": 1585614385.5472517, "_step": 427}
{"Episode reward": -99.74176961937779, "Episode length": 999, "Policy Loss": -0.6645662784576416, "Value Loss": 0.008033483289182186, "_runtime": 17017.500374794006, "_timestamp": 1585614387.1332443, "_step": 428}
{"Episode reward": -99.79327791771364, "Episode length": 999, "Policy Loss": -0.6487373113632202, "Value Loss": 0.007921065203845501, "_runtime": 17019.088027238846, "_timestamp": 1585614388.7208967, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6396675109863281, "Value Loss": 0.007761878427118063, "_runtime": 17020.60717344284, "_timestamp": 1585614390.240043, "_step": 430}
{"Episode reward": 4.447275840026549, "Episode length": 957, "Policy Loss": 0.1057499423623085, "Value Loss": 10.438711166381836, "_runtime": 17021.48299765587, "_timestamp": 1585614391.1158671, "_step": 431}
{"Episode reward": 46.384224305953346, "Episode length": 537, "Policy Loss": 0.7582613229751587, "Value Loss": 18.59737777709961, "_runtime": 17023.075063467026, "_timestamp": 1585614392.707933, "_step": 432}
{"Episode reward": -99.82205857075611, "Episode length": 999, "Policy Loss": -0.6259182691574097, "Value Loss": 0.007280527148395777, "_runtime": 17024.67673444748, "_timestamp": 1585614394.309604, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6236206293106079, "Value Loss": 0.007151470053941011, "_runtime": 17025.212117671967, "_timestamp": 1585614394.8449872, "_step": 434}
{"Episode reward": 67.54262751191837, "Episode length": 325, "Policy Loss": 1.7499945163726807, "Value Loss": 30.724796295166016, "_runtime": 17026.313296079636, "_timestamp": 1585614395.9461656, "_step": 435}
{"Episode reward": 30.299999999999685, "Episode length": 697, "Policy Loss": 0.5000057816505432, "Value Loss": 14.330214500427246, "_runtime": 17027.8983566761, "_timestamp": 1585614397.5312262, "_step": 436}
{"Episode reward": -99.40441244703696, "Episode length": 999, "Policy Loss": -0.6026363372802734, "Value Loss": 0.006956161465495825, "_runtime": 17029.426385641098, "_timestamp": 1585614399.0592551, "_step": 437}
{"Episode reward": -99.82450201660255, "Episode length": 999, "Policy Loss": -0.6197203397750854, "Value Loss": 0.006959754042327404, "_runtime": 17030.980783224106, "_timestamp": 1585614400.6136527, "_step": 438}
{"Episode reward": -99.80166877070302, "Episode length": 999, "Policy Loss": -0.6010256409645081, "Value Loss": 0.006880178116261959, "_runtime": 17032.036690235138, "_timestamp": 1585614401.6695597, "_step": 439}
{"Episode reward": 34.49968845015336, "Episode length": 656, "Policy Loss": 0.5116158127784729, "Value Loss": 15.225590705871582, "_runtime": 17033.60922718048, "_timestamp": 1585614403.2420967, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6031768321990967, "Value Loss": 0.006694416515529156, "_runtime": 17034.4899020195, "_timestamp": 1585614404.1227715, "_step": 441}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 1.0225095748901367, "Value Loss": 18.563800811767578, "_runtime": 17036.099284172058, "_timestamp": 1585614405.7321537, "_step": 442}
{"Episode reward": -99.85705183260585, "Episode length": 999, "Policy Loss": -0.5830731987953186, "Value Loss": 0.006542449351400137, "_runtime": 17037.691189050674, "_timestamp": 1585614407.3240585, "_step": 443}
{"Episode reward": -99.82180202158493, "Episode length": 999, "Policy Loss": -0.5743683576583862, "Value Loss": 0.006457698065787554, "_runtime": 17039.237832546234, "_timestamp": 1585614408.870702, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.582648754119873, "Value Loss": 0.006340727210044861, "_runtime": 17040.82878279686, "_timestamp": 1585614410.4616523, "_step": 445}
{"Episode reward": -99.80637728953594, "Episode length": 999, "Policy Loss": -0.5789338946342468, "Value Loss": 0.006173000205308199, "_runtime": 17042.424285888672, "_timestamp": 1585614412.0571554, "_step": 446}
{"Episode reward": -99.78737038113037, "Episode length": 999, "Policy Loss": -0.5704795718193054, "Value Loss": 0.005975303705781698, "_runtime": 17043.08368206024, "_timestamp": 1585614412.7165515, "_step": 447}
{"Episode reward": 60.399999999999714, "Episode length": 396, "Policy Loss": 1.4294123649597168, "Value Loss": 25.219953536987305, "_runtime": 17044.68385243416, "_timestamp": 1585614414.316722, "_step": 448}
{"Episode reward": -99.83704526582592, "Episode length": 999, "Policy Loss": -0.5562649965286255, "Value Loss": 0.00567547045648098, "_runtime": 17046.282036542892, "_timestamp": 1585614415.914906, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5294919610023499, "Value Loss": 0.005559111479669809, "_runtime": 17046.786957979202, "_timestamp": 1585614416.4198275, "_step": 450}
{"Episode reward": 68.78174412170758, "Episode length": 313, "Policy Loss": 2.2637643814086914, "Value Loss": 31.907339096069336, "_runtime": 17048.366442918777, "_timestamp": 1585614417.9993124, "_step": 451}
{"Episode reward": -99.8098449403639, "Episode length": 999, "Policy Loss": -0.5354747772216797, "Value Loss": 0.005409013945609331, "_runtime": 17049.95428967476, "_timestamp": 1585614419.5871592, "_step": 452}
{"Episode reward": -99.86009466983238, "Episode length": 999, "Policy Loss": -0.5346905589103699, "Value Loss": 0.005374061409384012, "_runtime": 17051.219588279724, "_timestamp": 1585614420.8524578, "_step": 453}
{"Episode reward": 17.19760984745851, "Episode length": 831, "Policy Loss": 0.33934885263442993, "Value Loss": 12.021419525146484, "_runtime": 17052.707109212875, "_timestamp": 1585614422.3399787, "_step": 454}
{"Episode reward": 7.084057955258601, "Episode length": 931, "Policy Loss": 0.2352398931980133, "Value Loss": 10.730791091918945, "_runtime": 17053.7733168602, "_timestamp": 1585614423.4061863, "_step": 455}
{"Episode reward": 33.58732646515078, "Episode length": 665, "Policy Loss": 0.5347900390625, "Value Loss": 15.021016120910645, "_runtime": 17055.34289741516, "_timestamp": 1585614424.975767, "_step": 456}
{"Episode reward": -99.88519929982583, "Episode length": 999, "Policy Loss": -0.5359563231468201, "Value Loss": 0.005279376171529293, "_runtime": 17055.987038373947, "_timestamp": 1585614425.6199079, "_step": 457}
{"Episode reward": 61.67952926316621, "Episode length": 384, "Policy Loss": 1.406954288482666, "Value Loss": 26.00910758972168, "_runtime": 17057.557312726974, "_timestamp": 1585614427.1901822, "_step": 458}
{"Episode reward": -99.87009967462951, "Episode length": 999, "Policy Loss": -0.5357552170753479, "Value Loss": 0.005362988915294409, "_runtime": 17058.734982013702, "_timestamp": 1585614428.3678515, "_step": 459}
{"Episode reward": 25.991895334981322, "Episode length": 741, "Policy Loss": 0.4743918478488922, "Value Loss": 13.480836868286133, "_runtime": 17060.11869740486, "_timestamp": 1585614429.751567, "_step": 460}
{"Episode reward": 11.620710864075974, "Episode length": 886, "Policy Loss": 0.41111594438552856, "Value Loss": 11.275444984436035, "_runtime": 17060.756569862366, "_timestamp": 1585614430.3894393, "_step": 461}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 1.3694779872894287, "Value Loss": 26.56159782409668, "_runtime": 17061.276015520096, "_timestamp": 1585614430.908885, "_step": 462}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 1.9243978261947632, "Value Loss": 31.20823097229004, "_runtime": 17062.307761907578, "_timestamp": 1585614431.9406314, "_step": 463}
{"Episode reward": 34.19428359882387, "Episode length": 659, "Policy Loss": 0.5461381077766418, "Value Loss": 15.156856536865234, "_runtime": 17062.702330827713, "_timestamp": 1585614432.3352003, "_step": 464}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 2.55615496635437, "Value Loss": 41.4334716796875, "_runtime": 17063.196254968643, "_timestamp": 1585614432.8291245, "_step": 465}
{"Episode reward": 67.89999999999982, "Episode length": 321, "Policy Loss": 1.8080296516418457, "Value Loss": 31.107402801513672, "_runtime": 17063.907666921616, "_timestamp": 1585614433.5405364, "_step": 466}
{"Episode reward": 54.39999999999963, "Episode length": 456, "Policy Loss": 0.9727100133895874, "Value Loss": 21.899009704589844, "_runtime": 17065.212549686432, "_timestamp": 1585614434.8454192, "_step": 467}
{"Episode reward": 14.17538228583932, "Episode length": 859, "Policy Loss": 0.17105017602443695, "Value Loss": 11.628504753112793, "_runtime": 17066.428300857544, "_timestamp": 1585614436.0611703, "_step": 468}
{"Episode reward": 20.114973850123604, "Episode length": 799, "Policy Loss": 0.19343483448028564, "Value Loss": 12.500819206237793, "_runtime": 17067.960582256317, "_timestamp": 1585614437.5934517, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7280665040016174, "Value Loss": 0.009846298955380917, "_runtime": 17068.46953892708, "_timestamp": 1585614438.1024084, "_step": 470}
{"Episode reward": 70.26292211143286, "Episode length": 299, "Policy Loss": 1.6577750444412231, "Value Loss": 33.38695526123047, "_runtime": 17069.120000123978, "_timestamp": 1585614438.7528696, "_step": 471}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 0.9799405336380005, "Value Loss": 24.290668487548828, "_runtime": 17070.174666166306, "_timestamp": 1585614439.8075356, "_step": 472}
{"Episode reward": 33.50815369179422, "Episode length": 666, "Policy Loss": 0.2991781234741211, "Value Loss": 14.994126319885254, "_runtime": 17071.711690187454, "_timestamp": 1585614441.3445597, "_step": 473}
{"Episode reward": -99.78309015408018, "Episode length": 999, "Policy Loss": -0.8339859843254089, "Value Loss": 0.012646740302443504, "_runtime": 17072.895663261414, "_timestamp": 1585614442.5285327, "_step": 474}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": 0.08634715527296066, "Value Loss": 12.987225532531738, "_runtime": 17074.43554830551, "_timestamp": 1585614444.0684178, "_step": 475}
{"Episode reward": -99.72229201398301, "Episode length": 999, "Policy Loss": -0.8469356298446655, "Value Loss": 0.0138174407184124, "_runtime": 17076.018793821335, "_timestamp": 1585614445.6516633, "_step": 476}
{"Episode reward": -99.83771252268785, "Episode length": 999, "Policy Loss": -0.8774583339691162, "Value Loss": 0.014244137331843376, "_runtime": 17077.57985854149, "_timestamp": 1585614447.212728, "_step": 477}
{"Episode reward": -99.85565648116031, "Episode length": 999, "Policy Loss": -0.8752433061599731, "Value Loss": 0.0145055390894413, "_runtime": 17078.557560682297, "_timestamp": 1585614448.1904302, "_step": 478}
{"Episode reward": 39.898445881064404, "Episode length": 602, "Policy Loss": 0.36067017912864685, "Value Loss": 16.585721969604492, "_runtime": 17080.129961013794, "_timestamp": 1585614449.7628305, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8896855711936951, "Value Loss": 0.014781617559492588, "_runtime": 17081.140663146973, "_timestamp": 1585614450.7735326, "_step": 480}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.6127540469169617, "Value Loss": 15.975869178771973, "_runtime": 17082.696625232697, "_timestamp": 1585614452.3294947, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9056219458580017, "Value Loss": 0.014849928207695484, "_runtime": 17083.508823394775, "_timestamp": 1585614453.1416929, "_step": 482}
{"Episode reward": 50.63335195248904, "Episode length": 495, "Policy Loss": 0.553856611251831, "Value Loss": 20.167633056640625, "_runtime": 17085.09544610977, "_timestamp": 1585614454.7283156, "_step": 483}
{"Episode reward": -99.70698248157139, "Episode length": 999, "Policy Loss": -0.8919077515602112, "Value Loss": 0.0147620914503932, "_runtime": 17086.688341856003, "_timestamp": 1585614456.3212113, "_step": 484}
{"Episode reward": -99.79720789061837, "Episode length": 999, "Policy Loss": -0.8711125254631042, "Value Loss": 0.014663326554000378, "_runtime": 17088.23200058937, "_timestamp": 1585614457.86487, "_step": 485}
{"Episode reward": -99.86529481364856, "Episode length": 999, "Policy Loss": -0.8741717338562012, "Value Loss": 0.014459881000220776, "_runtime": 17089.136591911316, "_timestamp": 1585614458.7694614, "_step": 486}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.41194790601730347, "Value Loss": 17.989274978637695, "_runtime": 17090.7206158638, "_timestamp": 1585614460.3534853, "_step": 487}
{"Episode reward": -99.8000338637256, "Episode length": 999, "Policy Loss": -0.8581656217575073, "Value Loss": 0.013926112093031406, "_runtime": 17091.75432395935, "_timestamp": 1585614461.3871934, "_step": 488}
{"Episode reward": 35.34995888322531, "Episode length": 647, "Policy Loss": 0.26632654666900635, "Value Loss": 15.433480262756348, "_runtime": 17093.067484617233, "_timestamp": 1585614462.700354, "_step": 489}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": -0.0001791297981981188, "Value Loss": 11.820330619812012, "_runtime": 17094.656175851822, "_timestamp": 1585614464.2890453, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8499178290367126, "Value Loss": 0.013183172792196274, "_runtime": 17096.213839769363, "_timestamp": 1585614465.8467093, "_step": 491}
{"Episode reward": -99.82064022878045, "Episode length": 999, "Policy Loss": -0.8264075517654419, "Value Loss": 0.012876171618700027, "_runtime": 17097.786067008972, "_timestamp": 1585614467.4189365, "_step": 492}
{"Episode reward": -99.72778244959052, "Episode length": 999, "Policy Loss": -0.8201367259025574, "Value Loss": 0.012496990151703358, "_runtime": 17099.377035856247, "_timestamp": 1585614469.0099053, "_step": 493}
{"Episode reward": -99.81188784874836, "Episode length": 999, "Policy Loss": -0.8051177263259888, "Value Loss": 0.012081452645361423, "_runtime": 17100.958514928818, "_timestamp": 1585614470.5913844, "_step": 494}
{"Episode reward": -99.80767334634298, "Episode length": 999, "Policy Loss": -0.7902563214302063, "Value Loss": 0.011605583131313324, "_runtime": 17102.228086948395, "_timestamp": 1585614471.8609564, "_step": 495}
{"Episode reward": 20.856341774523244, "Episode length": 792, "Policy Loss": 0.13188360631465912, "Value Loss": 12.610722541809082, "_runtime": 17102.726403951645, "_timestamp": 1585614472.3592734, "_step": 496}
{"Episode reward": 71.59999999999988, "Episode length": 284, "Policy Loss": 2.838801860809326, "Value Loss": 35.14921951293945, "_runtime": 17104.306348085403, "_timestamp": 1585614473.9392176, "_step": 497}
{"Episode reward": -99.82330843359092, "Episode length": 999, "Policy Loss": -0.7605940103530884, "Value Loss": 0.010482721030712128, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143, 0.00918474793434143]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.00979168713092804, -0.004902581684291363, -1.3476237654685974e-05, 0.004875629208981991, 0.009764734655618668, 0.01465383917093277, 0.01954294554889202, 0.024432051926851273, 0.029321156442165375, 0.03421026095747948, 0.03909936547279358, 0.04398847371339798, 0.04887757822871208, 0.053766682744026184, 0.058655790984630585, 0.06354489177465439, 0.06843400001525879, 0.07332310825586319, 0.078212209045887, 0.0831013172864914, 0.0879904180765152, 0.0928795263171196, 0.097768634557724, 0.1026577353477478, 0.1075468435883522, 0.1124359518289566, 0.11732505261898041, 0.12221415340900421, 0.1271032691001892, 0.131992369890213, 0.13688147068023682, 0.14177058637142181, 0.14665968716144562, 0.15154878795146942, 0.15643790364265442, 0.16132700443267822, 0.16621610522270203, 0.17110522091388702, 0.17599432170391083, 0.18088342249393463, 0.18577252328395844, 0.19066163897514343, 0.19555073976516724, 0.20043984055519104, 0.20532895624637604, 0.21021805703639984, 0.21510715782642365, 0.21999627351760864, 0.22488537430763245, 0.22977447509765625, 0.23466359078884125, 0.23955269157886505, 0.24444179236888885, 0.24933089315891266, 0.25422000885009766, 0.25910913944244385, 0.26399821043014526, 0.26888734102249146, 0.27377641201019287, 0.27866554260253906, 0.2835546135902405, 0.28844374418258667, 0.29333287477493286, 0.2982219457626343, 0.30311107635498047]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.017215033993124962, -0.016646502539515495, -0.016077972948551178, -0.015509441494941711, -0.01494091097265482, -0.014372380450367928, -0.013803848996758461, -0.013235318474471569, -0.012666787952184677, -0.012098257429897785, -0.011529726907610893, -0.010961195454001427, -0.010392664931714535, -0.009824134409427643, -0.009255602955818176, -0.008687072433531284, -0.008118541911244392, -0.0075500113889575005, -0.0069814808666706085, -0.006412949413061142, -0.00584441889077425, -0.005275888368487358, -0.0047073569148778915, -0.004138826392591, -0.0035702958703041077, -0.0030017653480172157, -0.002433234825730324, -0.0018647033721208572, -0.0012961719185113907, -0.0007276423275470734, -0.0001591108739376068, 0.0004094187170267105, 0.000977950170636177, 0.0015464816242456436, 0.002115011215209961, 0.0026835426688194275, 0.003252072259783745, 0.0038206037133932114, 0.004389135167002678, 0.004957664757966995, 0.005526196211576462, 0.006094727665185928, 0.006663257256150246, 0.007231788709759712, 0.007800320163369179, 0.008368849754333496, 0.008937381207942963, 0.00950591079890728, 0.010074442252516747, 0.010642973706126213, 0.01121150329709053, 0.011780034750699997, 0.012348564341664314, 0.01291709579527378, 0.013485627248883247, 0.014054158702492714, 0.01462269015610218, 0.015191217884421349, 0.015759749338030815, 0.01632828079164028, 0.016896812245249748, 0.017465343698859215, 0.018033871427178383, 0.01860240288078785, 0.019170934334397316]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 18.0, 22.0, 28.0, 5.0, 11.0, 17.0, 23.0, 14.0, 247.0, 9.0, 7.0, 13.0, 7.0, 11.0, 13.0, 22.0, 4.0, 5.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.05972948670387268, -0.05775690823793411, -0.055784329771995544, -0.053811751306056976, -0.05183917284011841, -0.04986659437417984, -0.047894012182950974, -0.045921433717012405, -0.04394885525107384, -0.04197627678513527, -0.0400036983191967, -0.038031116127967834, -0.036058537662029266, -0.0340859591960907, -0.03211338073015213, -0.030140802264213562, -0.028168223798274994, -0.026195645332336426, -0.024223066866397858, -0.02225048840045929, -0.02027790993452072, -0.018305327743291855, -0.016332749277353287, -0.014360170811414719, -0.01238759234547615, -0.010415013879537582, -0.008442435413599014, -0.006469856947660446, -0.00449727475643158, -0.0025246962904930115, -0.0005521178245544434, 0.0014204606413841248, 0.003393039107322693, 0.005365617573261261, 0.007338196039199829, 0.009310774505138397, 0.011283352971076965, 0.013255931437015533, 0.015228509902954102, 0.01720108836889267, 0.019173666834831238, 0.021146252751350403, 0.02311883121728897, 0.02509140968322754, 0.027063988149166107, 0.029036566615104675, 0.031009145081043243, 0.03298172354698181, 0.03495430201292038, 0.03692688047885895, 0.038899458944797516, 0.040872037410736084, 0.04284461587667465, 0.04481719434261322, 0.04678977280855179, 0.048762351274490356, 0.05073493719100952, 0.05270751565694809, 0.05468009412288666, 0.056652672588825226, 0.058625251054763794, 0.06059782952070236, 0.06257040798664093, 0.0645429864525795, 0.06651556491851807]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 6.0, 1.0, 0.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.12102274596691132, -0.11607231944799423, -0.11112190037965775, -0.10617147386074066, -0.10122104734182358, -0.0962706208229065, -0.09132020175457001, -0.08636977523565292, -0.08141934871673584, -0.07646892964839935, -0.07151850312948227, -0.06656807661056519, -0.0616176575422287, -0.056667231023311615, -0.05171680450439453, -0.046766385436058044, -0.04181595891714096, -0.03686553239822388, -0.03191511332988739, -0.026964686810970306, -0.022014260292053223, -0.017063841223716736, -0.012113414704799652, -0.007162988185882568, -0.0022125691175460815, 0.002737857401371002, 0.007688283920288086, 0.012638702988624573, 0.017589136958122253, 0.02253955602645874, 0.027489975094795227, 0.03244040906429291, 0.037390828132629395, 0.04234124720096588, 0.04729168117046356, 0.05224210023880005, 0.057192519307136536, 0.062142953276634216, 0.0670933723449707, 0.07204379141330719, 0.07699422538280487, 0.08194464445114136, 0.08689506351947784, 0.09184549748897552, 0.09679591655731201, 0.1017463356256485, 0.10669676959514618, 0.11164718866348267, 0.11659760773181915, 0.12154804170131683, 0.12649846076965332, 0.1314488798379898, 0.1363993138074875, 0.14134974777698517, 0.14630015194416046, 0.15125058591365814, 0.15620101988315582, 0.16115142405033112, 0.1661018580198288, 0.17105229198932648, 0.17600269615650177, 0.18095313012599945, 0.18590356409549713, 0.19085396826267242, 0.1958044022321701]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 4.0, 4.0, 3.0, 2.0, 0.0, 3.0, 8.0, 9.0, 5.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.10251054167747498, -0.09857810288667679, -0.0946456640958786, -0.09071321785449982, -0.08678077906370163, -0.08284834027290344, -0.07891589403152466, -0.07498345524072647, -0.07105101644992828, -0.0671185776591301, -0.06318613886833191, -0.059253692626953125, -0.05532125383615494, -0.05138881504535675, -0.047456372529268265, -0.04352393001317978, -0.03959149122238159, -0.035659052431583405, -0.03172661364078522, -0.027794167399406433, -0.023861728608608246, -0.01992928981781006, -0.015996843576431274, -0.012064404785633087, -0.0081319659948349, -0.004199527204036713, -0.0002670884132385254, 0.003665357828140259, 0.007597796618938446, 0.011530235409736633, 0.015462681651115417, 0.019395120441913605, 0.023327559232711792, 0.027260005474090576, 0.031192436814308167, 0.03512488305568695, 0.03905731439590454, 0.042989760637283325, 0.04692220687866211, 0.0508546382188797, 0.054787084460258484, 0.05871953070163727, 0.06265196204185486, 0.06658440828323364, 0.07051685452461243, 0.07444928586483002, 0.0783817321062088, 0.08231416344642639, 0.08624660968780518, 0.09017905592918396, 0.09411148726940155, 0.09804393351078033, 0.10197636485099792, 0.10590881109237671, 0.1098412573337555, 0.11377368867397308, 0.11770613491535187, 0.12163858115673065, 0.12557101249694824, 0.12950345873832703, 0.1334359049797058, 0.1373683363199234, 0.14130078256130219, 0.14523321390151978, 0.14916566014289856]}, "_runtime": 17105.8924973011, "_timestamp": 1585614475.5253668, "_step": 498}
{"Episode reward": -99.8164270282942, "Episode length": 999, "Policy Loss": -0.7358596920967102, "Value Loss": 0.010237281210720539, "_runtime": 17105.8924973011, "_timestamp": 1585614475.5253668, "_step": 499}
