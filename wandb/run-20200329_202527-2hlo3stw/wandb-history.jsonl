{"Episode reward": -55.7029412116319, "Episode length": 999, "Policy Loss": -0.023741615936160088, "Value Loss": 0.012534263543784618, "_runtime": 4468.76004242897, "_timestamp": 1585513547.180772, "_step": 0}
{"Episode reward": -93.79646366757858, "Episode length": 999, "Policy Loss": -0.6669308543205261, "Value Loss": 6.374666213989258, "_runtime": 4470.238400936127, "_timestamp": 1585513548.6591306, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3278112411499023, "Value Loss": 1807.9927978515625, "_runtime": 4471.825248003006, "_timestamp": 1585513550.2459776, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 28.929931640625, "Value Loss": 7133.36474609375, "_runtime": 4473.342724323273, "_timestamp": 1585513551.763454, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.700584411621094, "Value Loss": 309.16632080078125, "_runtime": 4474.850921869278, "_timestamp": 1585513553.2716515, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9566261768341064, "Value Loss": 10.317086219787598, "_runtime": 4476.40621805191, "_timestamp": 1585513554.8269477, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29849350452423096, "Value Loss": 5.9717230796813965, "_runtime": 4477.945358276367, "_timestamp": 1585513556.366088, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7201292514801025, "Value Loss": 27.117576599121094, "_runtime": 4479.454119205475, "_timestamp": 1585513557.8748488, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9899733066558838, "Value Loss": 13.299442291259766, "_runtime": 4481.002191781998, "_timestamp": 1585513559.4229214, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6588696241378784, "Value Loss": 0.024172525852918625, "_runtime": 4482.553964138031, "_timestamp": 1585513560.9746938, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6022731065750122, "Value Loss": 1.4707070589065552, "_runtime": 4484.075439214706, "_timestamp": 1585513562.4961689, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6495457291603088, "Value Loss": 0.00422151992097497, "_runtime": 4485.622354984283, "_timestamp": 1585513564.0430846, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4791358709335327, "Value Loss": 4.646617412567139, "_runtime": 4487.171128034592, "_timestamp": 1585513565.5918577, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6026925444602966, "Value Loss": 0.0035939819645136595, "_runtime": 4488.708076715469, "_timestamp": 1585513567.1288064, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5610422492027283, "Value Loss": 0.003120921552181244, "_runtime": 4490.27556347847, "_timestamp": 1585513568.696293, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41116225719451904, "Value Loss": 148.8245086669922, "_runtime": 4491.840745210648, "_timestamp": 1585513570.2614748, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.481251060962677, "Value Loss": 0.002276739338412881, "_runtime": 4493.3945162296295, "_timestamp": 1585513571.8152459, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4383242726325989, "Value Loss": 0.0019080418860539794, "_runtime": 4494.988739490509, "_timestamp": 1585513573.4094691, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3979432284832001, "Value Loss": 0.001591843436472118, "_runtime": 4496.556131362915, "_timestamp": 1585513574.976861, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.366117000579834, "Value Loss": 0.0013213405618444085, "_runtime": 4498.111526727676, "_timestamp": 1585513576.5322564, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3310262858867645, "Value Loss": 0.0010905105154961348, "_runtime": 4499.670176267624, "_timestamp": 1585513578.090906, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.299267441034317, "Value Loss": 0.0008941569831222296, "_runtime": 4501.226412296295, "_timestamp": 1585513579.647142, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2690748870372772, "Value Loss": 0.0007277874974533916, "_runtime": 4502.774294376373, "_timestamp": 1585513581.195024, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24369336664676666, "Value Loss": 0.0005874166381545365, "_runtime": 4504.342059135437, "_timestamp": 1585513582.7627888, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21704351902008057, "Value Loss": 0.0004696035466622561, "_runtime": 4505.890207529068, "_timestamp": 1585513584.3109372, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1921839863061905, "Value Loss": 0.00037129412521608174, "_runtime": 4507.44970703125, "_timestamp": 1585513585.8704367, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17147009074687958, "Value Loss": 0.00028978564660064876, "_runtime": 4509.017377138138, "_timestamp": 1585513587.4381068, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14952431619167328, "Value Loss": 0.00022278414689935744, "_runtime": 4510.573559045792, "_timestamp": 1585513588.9942887, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12994107604026794, "Value Loss": 0.00016822015459183604, "_runtime": 4512.131953716278, "_timestamp": 1585513590.5526834, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11204776912927628, "Value Loss": 0.00012426679313648492, "_runtime": 4513.699067831039, "_timestamp": 1585513592.1197975, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09447015821933746, "Value Loss": 8.933782373787835e-05, "_runtime": 4515.266819000244, "_timestamp": 1585513593.6875486, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07880993187427521, "Value Loss": 6.205263343872502e-05, "_runtime": 4516.814970254898, "_timestamp": 1585513595.2357, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0643329843878746, "Value Loss": 4.11936707678251e-05, "_runtime": 4518.416174650192, "_timestamp": 1585513596.8369043, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05077405273914337, "Value Loss": 2.5682847990537994e-05, "_runtime": 4519.991888999939, "_timestamp": 1585513598.4126186, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038293104618787766, "Value Loss": 1.4595603715861216e-05, "_runtime": 4521.548671007156, "_timestamp": 1585513599.9694006, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.026763319969177246, "Value Loss": 7.145727977331262e-06, "_runtime": 4523.119602203369, "_timestamp": 1585513601.5403318, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01621350273489952, "Value Loss": 2.6191698907496175e-06, "_runtime": 4524.718340396881, "_timestamp": 1585513603.13907, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006518010515719652, "Value Loss": 4.255206533798628e-07, "_runtime": 4526.294150590897, "_timestamp": 1585513604.7148802, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0022950780112296343, "Value Loss": 5.2386894822120667e-08, "_runtime": 4527.860240697861, "_timestamp": 1585513606.2809703, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010336154140532017, "Value Loss": 1.062806063600874e-06, "_runtime": 4529.433152675629, "_timestamp": 1585513607.8538823, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01766488142311573, "Value Loss": 3.0858816444379045e-06, "_runtime": 4531.000501871109, "_timestamp": 1585513609.4212315, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02431425265967846, "Value Loss": 5.812384188175201e-06, "_runtime": 4532.568686723709, "_timestamp": 1585513610.9894164, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030081478878855705, "Value Loss": 8.990125024865847e-06, "_runtime": 4534.141099452972, "_timestamp": 1585513612.561829, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03536444529891014, "Value Loss": 1.2397193131619133e-05, "_runtime": 4535.701317071915, "_timestamp": 1585513614.1220467, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03997178375720978, "Value Loss": 1.5868248738115653e-05, "_runtime": 4537.269873857498, "_timestamp": 1585513615.6906035, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04395502060651779, "Value Loss": 1.9270024495199323e-05, "_runtime": 4538.838777780533, "_timestamp": 1585513617.2595074, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04759599640965462, "Value Loss": 2.2492475181934424e-05, "_runtime": 4540.436504602432, "_timestamp": 1585513618.8572342, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05070788040757179, "Value Loss": 2.5451396140852012e-05, "_runtime": 4542.007522821426, "_timestamp": 1585513620.4282525, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05336223915219307, "Value Loss": 2.8105649107601494e-05, "_runtime": 4543.567394018173, "_timestamp": 1585513621.9881237, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.055323824286460876, "Value Loss": 3.0395287467399612e-05, "_runtime": 4545.1215806007385, "_timestamp": 1585513623.5423102, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05713113397359848, "Value Loss": 3.231754089938477e-05, "_runtime": 4546.672420740128, "_timestamp": 1585513625.0931504, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05853730067610741, "Value Loss": 3.385338277439587e-05, "_runtime": 4548.23332118988, "_timestamp": 1585513626.6540508, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.059389736503362656, "Value Loss": 3.4994809539057314e-05, "_runtime": 4549.786573886871, "_timestamp": 1585513628.2073035, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05988616123795509, "Value Loss": 3.576627932488918e-05, "_runtime": 4551.36022233963, "_timestamp": 1585513629.780952, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06068816035985947, "Value Loss": 3.6189579986967146e-05, "_runtime": 4552.935798406601, "_timestamp": 1585513631.356528, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.060629162937402725, "Value Loss": 3.626993566285819e-05, "_runtime": 4554.49009513855, "_timestamp": 1585513632.9108248, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06010478362441063, "Value Loss": 3.605214078561403e-05, "_runtime": 4556.065686225891, "_timestamp": 1585513634.4864159, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.059824150055646896, "Value Loss": 3.554987415554933e-05, "_runtime": 4557.6406445503235, "_timestamp": 1585513636.0613742, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.059106167405843735, "Value Loss": 3.480324085103348e-05, "_runtime": 4559.206116914749, "_timestamp": 1585513637.6268466, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05837223678827286, "Value Loss": 3.384227238711901e-05, "_runtime": 4560.779933214188, "_timestamp": 1585513639.2006629, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.057419486343860626, "Value Loss": 3.2698153518140316e-05, "_runtime": 4562.354297399521, "_timestamp": 1585513640.775027, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05633829906582832, "Value Loss": 3.139179170830175e-05, "_runtime": 4563.937311172485, "_timestamp": 1585513642.3580408, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05504332855343819, "Value Loss": 2.9965663998154923e-05, "_runtime": 4565.508324384689, "_timestamp": 1585513643.929054, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05343189463019371, "Value Loss": 2.8450553145376034e-05, "_runtime": 4567.062013626099, "_timestamp": 1585513645.4827433, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05229014903306961, "Value Loss": 2.6855888791033067e-05, "_runtime": 4568.612801551819, "_timestamp": 1585513647.0335312, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05037062242627144, "Value Loss": 2.522097565815784e-05, "_runtime": 4570.179845333099, "_timestamp": 1585513648.600575, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04866064712405205, "Value Loss": 2.3563270588056184e-05, "_runtime": 4571.745489597321, "_timestamp": 1585513650.1662192, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.047123510390520096, "Value Loss": 2.189940460084472e-05, "_runtime": 4573.307168245316, "_timestamp": 1585513651.727898, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04528693109750748, "Value Loss": 2.0253501133993268e-05, "_runtime": 4574.8734221458435, "_timestamp": 1585513653.2941518, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.043348152190446854, "Value Loss": 1.8638938854564913e-05, "_runtime": 4576.438864707947, "_timestamp": 1585513654.8595943, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.041307613253593445, "Value Loss": 1.7067774024326354e-05, "_runtime": 4577.988623857498, "_timestamp": 1585513656.4093535, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03974879905581474, "Value Loss": 1.555074777570553e-05, "_runtime": 4579.55375123024, "_timestamp": 1585513657.9744809, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.037737976759672165, "Value Loss": 1.4097140592639334e-05, "_runtime": 4581.120831727982, "_timestamp": 1585513659.5415614, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.035830430686473846, "Value Loss": 1.2714954209513962e-05, "_runtime": 4582.682713270187, "_timestamp": 1585513661.103443, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03393895551562309, "Value Loss": 1.140432505053468e-05, "_runtime": 4584.235920190811, "_timestamp": 1585513662.6566498, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03193029388785362, "Value Loss": 1.0182439837080892e-05, "_runtime": 4585.800989627838, "_timestamp": 1585513664.2217193, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030088165774941444, "Value Loss": 9.035922630573623e-06, "_runtime": 4587.38977098465, "_timestamp": 1585513665.8105006, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028299491852521896, "Value Loss": 7.974013897182886e-06, "_runtime": 4588.946315526962, "_timestamp": 1585513667.3670452, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026671214029192924, "Value Loss": 6.998625849519158e-06, "_runtime": 4590.512528896332, "_timestamp": 1585513668.9332585, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02482091635465622, "Value Loss": 6.105714874138357e-06, "_runtime": 4592.064792633057, "_timestamp": 1585513670.4855223, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023089654743671417, "Value Loss": 5.291208253765944e-06, "_runtime": 4593.622225999832, "_timestamp": 1585513672.0429556, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021414194256067276, "Value Loss": 4.555335181066766e-06, "_runtime": 4595.191471338272, "_timestamp": 1585513673.612201, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019792955368757248, "Value Loss": 3.893328994308831e-06, "_runtime": 4596.756249904633, "_timestamp": 1585513675.1769795, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018291551619768143, "Value Loss": 3.3005787827278255e-06, "_runtime": 4598.322906255722, "_timestamp": 1585513676.743636, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016721174120903015, "Value Loss": 2.7789653813670157e-06, "_runtime": 4599.8803560733795, "_timestamp": 1585513678.3010857, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015334989875555038, "Value Loss": 2.3166796836449066e-06, "_runtime": 4601.444993019104, "_timestamp": 1585513679.8657227, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013924914412200451, "Value Loss": 1.912212837851257e-06, "_runtime": 4603.01774263382, "_timestamp": 1585513681.4384723, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012532860040664673, "Value Loss": 1.5631674159521936e-06, "_runtime": 4604.585168361664, "_timestamp": 1585513683.005898, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011288904584944248, "Value Loss": 1.2620910183613887e-06, "_runtime": 4606.149139165878, "_timestamp": 1585513684.5698688, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010019215755164623, "Value Loss": 1.004803266368981e-06, "_runtime": 4607.715911388397, "_timestamp": 1585513686.136641, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008910425938665867, "Value Loss": 7.883141961428919e-07, "_runtime": 4609.2831292152405, "_timestamp": 1585513687.7038589, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00783291645348072, "Value Loss": 6.085656423238106e-07, "_runtime": 4610.86965918541, "_timestamp": 1585513689.2903888, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006827127188444138, "Value Loss": 4.5857623831579986e-07, "_runtime": 4612.431091308594, "_timestamp": 1585513690.851821, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005849084351211786, "Value Loss": 3.3842295010799717e-07, "_runtime": 4613.9947118759155, "_timestamp": 1585513692.4154415, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004944575484842062, "Value Loss": 2.4127012920871493e-07, "_runtime": 4615.555840730667, "_timestamp": 1585513693.9765704, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004108122084289789, "Value Loss": 1.658273163229751e-07, "_runtime": 4617.124233484268, "_timestamp": 1585513695.5449631, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003301820484921336, "Value Loss": 1.0762596502900124e-07, "_runtime": 4618.697048902512, "_timestamp": 1585513697.1177785, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0025666342116892338, "Value Loss": 6.532412299975476e-08, "_runtime": 4620.2679607868195, "_timestamp": 1585513698.6886904, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018837121315300465, "Value Loss": 3.5296572775678214e-08, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625, 480.21343994140625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-480.21392822265625, -114.871337890625, 250.47125244140625, 615.8139038085938, 981.1564331054688, 1346.4990234375, 1711.841796875, 2077.184326171875, 2442.52685546875, 2807.869384765625, 3173.2119140625, 3538.5546875, 3903.8974609375, 4269.23974609375, 4634.58251953125, 4999.9248046875, 5365.267578125, 5730.6103515625, 6095.95263671875, 6461.29541015625, 6826.6376953125, 7191.98046875, 7557.3232421875, 7922.666015625, 8288.0087890625, 8653.3505859375, 9018.693359375, 9384.0361328125, 9749.37890625, 10114.7216796875, 10480.0634765625, 10845.40625, 11210.7490234375, 11576.091796875, 11941.4345703125, 12306.7763671875, 12672.119140625, 13037.4619140625, 13402.8046875, 13768.1474609375, 14133.4892578125, 14498.83203125, 14864.1748046875, 15229.517578125, 15594.8603515625, 15960.2021484375, 16325.5458984375, 16690.88671875, 17056.23046875, 17421.572265625, 17786.9140625, 18152.2578125, 18517.599609375, 18882.943359375, 19248.28515625, 19613.626953125, 19978.970703125, 20344.3125, 20709.65625, 21074.998046875, 21440.33984375, 21805.68359375, 22171.025390625, 22536.369140625, 22901.7109375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-804.2612915039062, -783.8603515625, -763.45947265625, -743.0585327148438, -722.6576538085938, -702.2567138671875, -681.8558349609375, -661.4548950195312, -641.053955078125, -620.653076171875, -600.252197265625, -579.8512573242188, -559.4503173828125, -539.0494384765625, -518.6484985351562, -498.2475891113281, -477.8466796875, -457.4457702636719, -437.04486083984375, -416.6439514160156, -396.2430419921875, -375.84210205078125, -355.4411926269531, -335.040283203125, -314.6393737792969, -294.23846435546875, -273.8375244140625, -253.4366455078125, -233.03570556640625, -212.63482666015625, -192.23388671875, -171.8330078125, -151.43206787109375, -131.0311279296875, -110.6302490234375, -90.22930908203125, -69.82843017578125, -49.427490234375, -29.026611328125, -8.62567138671875, 11.77520751953125, 32.1761474609375, 52.57708740234375, 72.97796630859375, 93.37890625, 113.77978515625, 134.18072509765625, 154.58160400390625, 174.9825439453125, 195.38348388671875, 215.78436279296875, 236.18524169921875, 256.58624267578125, 276.98712158203125, 297.38800048828125, 317.78887939453125, 338.18988037109375, 358.59075927734375, 378.99163818359375, 399.39263916015625, 419.79351806640625, 440.19439697265625, 460.59527587890625, 480.99627685546875, 501.39715576171875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 20.0, 16.0, 8.0, 1.0, 352.0, 1.0, 6.0, 18.0, 4.0, 10.0, 28.0, 13.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4626.37060546875, -4509.01806640625, -4391.66552734375, -4274.3125, -4156.9599609375, -4039.607421875, -3922.2548828125, -3804.90234375, -3687.5498046875, -3570.197021484375, -3452.844482421875, -3335.49169921875, -3218.13916015625, -3100.78662109375, -2983.43408203125, -2866.08154296875, -2748.728759765625, -2631.3759765625, -2514.0234375, -2396.6708984375, -2279.318359375, -2161.965576171875, -2044.613037109375, -1927.260498046875, -1809.90771484375, -1692.55517578125, -1575.20263671875, -1457.85009765625, -1340.497314453125, -1223.144775390625, -1105.792236328125, -988.439453125, -871.0869140625, -753.734375, -636.381591796875, -519.029296875, -401.67626953125, -284.32373046875, -166.97119140625, -49.61865234375, 67.73388671875, 185.08642578125, 302.439453125, 419.7919921875, 537.14453125, 654.4970703125, 771.849609375, 889.2021484375, 1006.55517578125, 1123.90771484375, 1241.26025390625, 1358.61279296875, 1475.96533203125, 1593.31787109375, 1710.67041015625, 1828.0234375, 1945.3759765625, 2062.728515625, 2180.0810546875, 2297.43359375, 2414.7861328125, 2532.13916015625, 2649.49169921875, 2766.84423828125, 2884.19677734375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3144.057861328125, -3055.059814453125, -2966.06201171875, -2877.06396484375, -2788.06591796875, -2699.06787109375, -2610.06982421875, -2521.072021484375, -2432.073974609375, -2343.075927734375, -2254.078125, -2165.080078125, -2076.08203125, -1987.083984375, -1898.0860595703125, -1809.088134765625, -1720.090087890625, -1631.092041015625, -1542.0941162109375, -1453.09619140625, -1364.09814453125, -1275.10009765625, -1186.1021728515625, -1097.104248046875, -1008.106201171875, -919.108154296875, -830.110107421875, -741.1123046875, -652.1142578125, -563.1162109375, -474.118408203125, -385.120361328125, -296.122314453125, -207.124267578125, -118.126220703125, -29.12841796875, 59.86962890625, 148.86767578125, 237.865478515625, 326.863525390625, 415.861572265625, 504.859619140625, 593.857666015625, 682.85546875, 771.853515625, 860.8515625, 949.849365234375, 1038.847412109375, 1127.845458984375, 1216.843505859375, 1305.841552734375, 1394.839599609375, 1483.837646484375, 1572.835205078125, 1661.833251953125, 1750.831298828125, 1839.829345703125, 1928.827392578125, 2017.825439453125, 2106.823486328125, 2195.821044921875, 2284.819091796875, 2373.817138671875, 2462.815185546875, 2551.813232421875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 7.0, 20.0, 6.0, 2.0, 3.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1887.7249755859375, -1821.887939453125, -1756.0509033203125, -1690.2138671875, -1624.376953125, -1558.539794921875, -1492.702880859375, -1426.8658447265625, -1361.02880859375, -1295.1917724609375, -1229.354736328125, -1163.517822265625, -1097.6806640625, -1031.84375, -966.0067138671875, -900.169677734375, -834.3326416015625, -768.49560546875, -702.6585693359375, -636.821533203125, -570.9844970703125, -505.1475830078125, -439.310546875, -373.4735107421875, -307.636474609375, -241.7994384765625, -175.96240234375, -110.1253662109375, -44.2884521484375, 21.548583984375, 87.3856201171875, 153.22265625, 219.0596923828125, 284.8966064453125, 350.7337646484375, 416.5706787109375, 482.4078369140625, 548.2447509765625, 614.0819091796875, 679.9188232421875, 745.7559814453125, 811.5928955078125, 877.4298095703125, 943.2669677734375, 1009.1038818359375, 1074.9410400390625, 1140.7779541015625, 1206.6151123046875, 1272.4520263671875, 1338.2889404296875, 1404.1260986328125, 1469.9630126953125, 1535.8001708984375, 1601.6370849609375, 1667.4742431640625, 1733.3111572265625, 1799.1480712890625, 1864.9852294921875, 1930.8221435546875, 1996.6593017578125, 2062.49609375, 2128.33349609375, 2194.17041015625, 2260.00732421875, 2325.84423828125]}, "_runtime": 4621.838006734848, "_timestamp": 1585513700.2587364, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0012702879030257463, "Value Loss": 1.58470356836915e-08, "_runtime": 4623.399259328842, "_timestamp": 1585513701.819989, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0006967123481445014, "Value Loss": 4.8825743448333014e-09, "_runtime": 4624.953761816025, "_timestamp": 1585513703.3744915, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001820473262341693, "Value Loss": 3.283275873400271e-10, "_runtime": 4626.505167722702, "_timestamp": 1585513704.9258974, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00028791208751499653, "Value Loss": 8.185452315956354e-10, "_runtime": 4628.05424451828, "_timestamp": 1585513706.4749742, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007177902734838426, "Value Loss": 5.186439722137948e-09, "_runtime": 4629.6037719249725, "_timestamp": 1585513708.0245016, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0010952220764011145, "Value Loss": 1.192536824845547e-08, "_runtime": 4631.154059410095, "_timestamp": 1585513709.574789, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014317464083433151, "Value Loss": 2.0463630789890885e-08, "_runtime": 4632.718955039978, "_timestamp": 1585513711.1396847, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017379546770825982, "Value Loss": 2.979759550214567e-08, "_runtime": 4634.313708782196, "_timestamp": 1585513712.7344384, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0019969274289906025, "Value Loss": 3.934837877750397e-08, "_runtime": 4635.877162218094, "_timestamp": 1585513714.2978919, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002215081825852394, "Value Loss": 4.8564924526317554e-08, "_runtime": 4637.439488887787, "_timestamp": 1585513715.8602185, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0023980692494660616, "Value Loss": 5.6843418860808015e-08, "_runtime": 4639.004201173782, "_timestamp": 1585513717.4249308, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00255028810352087, "Value Loss": 6.483696068926292e-08, "_runtime": 4640.554702997208, "_timestamp": 1585513718.9754326, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026853696908801794, "Value Loss": 7.130438461899757e-08, "_runtime": 4642.104718208313, "_timestamp": 1585513720.5254478, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027756812050938606, "Value Loss": 7.649315136859514e-08, "_runtime": 4643.658349514008, "_timestamp": 1585513722.0790792, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00284199439920485, "Value Loss": 8.081548230620683e-08, "_runtime": 4645.207552909851, "_timestamp": 1585513723.6282825, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002901314524933696, "Value Loss": 8.350187385985919e-08, "_runtime": 4646.756099224091, "_timestamp": 1585513725.1768289, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029244734905660152, "Value Loss": 8.516197169683437e-08, "_runtime": 4648.304584741592, "_timestamp": 1585513726.7253144, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029349818360060453, "Value Loss": 8.516141747350048e-08, "_runtime": 4649.8470067977905, "_timestamp": 1585513728.2677364, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002923892345279455, "Value Loss": 8.463359790766845e-08, "_runtime": 4651.396840572357, "_timestamp": 1585513729.8175702, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002901671454310417, "Value Loss": 8.294952635878872e-08, "_runtime": 4652.936203718185, "_timestamp": 1585513731.3569334, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0028310013003647327, "Value Loss": 8.022561104326087e-08, "_runtime": 4654.484921216965, "_timestamp": 1585513732.9056509, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027858982793986797, "Value Loss": 7.707658511435511e-08, "_runtime": 4656.071139335632, "_timestamp": 1585513734.491869, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027052888181060553, "Value Loss": 7.33562046661973e-08, "_runtime": 4657.620173931122, "_timestamp": 1585513736.0409036, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0026508127339184284, "Value Loss": 6.928176787823759e-08, "_runtime": 4659.168266057968, "_timestamp": 1585513737.5889957, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002555123995989561, "Value Loss": 6.484331294132062e-08, "_runtime": 4660.719392776489, "_timestamp": 1585513739.1401224, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002463466487824917, "Value Loss": 6.007120845197278e-08, "_runtime": 4662.282915353775, "_timestamp": 1585513740.703645, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002352416515350342, "Value Loss": 5.50605037119567e-08, "_runtime": 4663.836157083511, "_timestamp": 1585513742.2568867, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002251425990834832, "Value Loss": 5.0226837799982604e-08, "_runtime": 4665.39065694809, "_timestamp": 1585513743.8113866, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002146677812561393, "Value Loss": 4.563480615615845e-08, "_runtime": 4666.930515050888, "_timestamp": 1585513745.3512447, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002032826654613018, "Value Loss": 4.087632987648249e-08, "_runtime": 4668.490821123123, "_timestamp": 1585513746.9115508, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0019105924293398857, "Value Loss": 3.637978807091713e-08, "_runtime": 4670.053259849548, "_timestamp": 1585513748.4739895, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017991762142628431, "Value Loss": 3.2153323559214186e-08, "_runtime": 4671.618439912796, "_timestamp": 1585513750.0391695, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0016785393236204982, "Value Loss": 2.7853687356582668e-08, "_runtime": 4673.180037021637, "_timestamp": 1585513751.6007667, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001556294271722436, "Value Loss": 2.4164744871768562e-08, "_runtime": 4674.7421996593475, "_timestamp": 1585513753.1629293, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014512658817693591, "Value Loss": 2.073738158969718e-08, "_runtime": 4676.291724920273, "_timestamp": 1585513754.7124546, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013365608174353838, "Value Loss": 1.757234002752739e-08, "_runtime": 4677.842887401581, "_timestamp": 1585513756.263617, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0012292340397834778, "Value Loss": 1.4901161193847656e-08, "_runtime": 4679.431229352951, "_timestamp": 1585513757.851959, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0011106650345027447, "Value Loss": 1.2238648317008938e-08, "_runtime": 4680.989576339722, "_timestamp": 1585513759.410306, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001005516154691577, "Value Loss": 1.0027300767490033e-08, "_runtime": 4682.548581600189, "_timestamp": 1585513760.9693112, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00091262545902282, "Value Loss": 8.208189683500677e-09, "_runtime": 4684.106097459793, "_timestamp": 1585513762.526827, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008151690708473325, "Value Loss": 6.572868027632239e-09, "_runtime": 4685.6635110378265, "_timestamp": 1585513764.0842407, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007222911808639765, "Value Loss": 5.115907697472721e-09, "_runtime": 4687.225951194763, "_timestamp": 1585513765.6466808, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006244371179491282, "Value Loss": 3.842615114990622e-09, "_runtime": 4688.784940958023, "_timestamp": 1585513767.2056706, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.000537992047611624, "Value Loss": 2.852175384759903e-09, "_runtime": 4690.347222805023, "_timestamp": 1585513768.7679524, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00045785875408910215, "Value Loss": 2.0964663338673972e-09, "_runtime": 4691.8995480537415, "_timestamp": 1585513770.3202777, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00038334104465320706, "Value Loss": 1.4551915228366852e-09, "_runtime": 4693.436902523041, "_timestamp": 1585513771.8576322, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00031416816636919975, "Value Loss": 9.904397302307189e-10, "_runtime": 4694.982376098633, "_timestamp": 1585513773.4031057, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00024936808040365577, "Value Loss": 6.538238284115039e-10, "_runtime": 4696.521724939346, "_timestamp": 1585513774.9424546, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00018188945250585675, "Value Loss": 3.6362945987633566e-10, "_runtime": 4698.058238267899, "_timestamp": 1585513776.478968, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0001249889755854383, "Value Loss": 1.54303653188137e-10, "_runtime": 4699.598541975021, "_timestamp": 1585513778.0192716, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.633686618646607e-05, "Value Loss": 1.496077844942434e-10, "_runtime": 4701.138446569443, "_timestamp": 1585513779.5591762, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.883315937651787e-05, "Value Loss": 3.930674188912242e-11, "_runtime": 4702.716433525085, "_timestamp": 1585513781.1371632, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.907050500449259e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4704.266175746918, "_timestamp": 1585513782.6869054, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.7489472965244204e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 4705.8161108493805, "_timestamp": 1585513784.2368405, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.612044621258974e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 4707.357700824738, "_timestamp": 1585513785.7784305, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00012505718041211367, "Value Loss": 1.5370460459962487e-10, "_runtime": 4708.909358501434, "_timestamp": 1585513787.3300881, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00015306747809518129, "Value Loss": 2.3283064365386963e-10, "_runtime": 4710.460250616074, "_timestamp": 1585513788.8809803, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00017315980221610516, "Value Loss": 2.9467628337442875e-10, "_runtime": 4712.011931180954, "_timestamp": 1585513790.4326608, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00019132200395688415, "Value Loss": 3.7214084591674634e-10, "_runtime": 4713.573959827423, "_timestamp": 1585513791.9946895, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00021121519966982305, "Value Loss": 5.21987120194467e-10, "_runtime": 4715.137783765793, "_timestamp": 1585513793.5585134, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00022000253375153989, "Value Loss": 4.81122697237879e-10, "_runtime": 4716.688798904419, "_timestamp": 1585513795.1095285, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023039465304464102, "Value Loss": 5.238689482212067e-10, "_runtime": 4718.254274845123, "_timestamp": 1585513796.6750045, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023927031725179404, "Value Loss": 5.958337156997118e-10, "_runtime": 4719.818283557892, "_timestamp": 1585513798.2390132, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002491643826942891, "Value Loss": 6.152080511689917e-10, "_runtime": 4721.366623878479, "_timestamp": 1585513799.7873535, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002495653461664915, "Value Loss": 6.148184183984995e-10, "_runtime": 4722.914790153503, "_timestamp": 1585513801.3355198, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002495436929166317, "Value Loss": 6.148184183984995e-10, "_runtime": 4724.466688156128, "_timestamp": 1585513802.8874178, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00024921860313043, "Value Loss": 6.148184183984995e-10, "_runtime": 4726.063989162445, "_timestamp": 1585513804.4847188, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00025029495009221137, "Value Loss": 6.148184183984995e-10, "_runtime": 4727.625196695328, "_timestamp": 1585513806.0459263, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023991105263121426, "Value Loss": 5.684341886080801e-10, "_runtime": 4729.186055421829, "_timestamp": 1585513807.606785, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002396196941845119, "Value Loss": 5.68610825091298e-10, "_runtime": 4730.744133234024, "_timestamp": 1585513809.1648629, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00022955283930059522, "Value Loss": 5.238689482212067e-10, "_runtime": 4732.294655799866, "_timestamp": 1585513810.7153854, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00022016707225702703, "Value Loss": 4.81122697237879e-10, "_runtime": 4733.855474948883, "_timestamp": 1585513812.2762046, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00021024313173256814, "Value Loss": 4.4019543565809727e-10, "_runtime": 4735.414211034775, "_timestamp": 1585513813.8349407, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00020176888210698962, "Value Loss": 4.0108716348186135e-10, "_runtime": 4736.972145080566, "_timestamp": 1585513815.3928747, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001911787549033761, "Value Loss": 3.637978807091713e-10, "_runtime": 4738.530932426453, "_timestamp": 1585513816.951662, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001813611015677452, "Value Loss": 3.283275873400271e-10, "_runtime": 4740.079474925995, "_timestamp": 1585513818.5002046, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00017272584955208004, "Value Loss": 3.177058893744089e-10, "_runtime": 4741.63946390152, "_timestamp": 1585513820.0601935, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00016278076509479433, "Value Loss": 2.62996929789594e-10, "_runtime": 4743.199137687683, "_timestamp": 1585513821.6198673, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001531630550744012, "Value Loss": 2.3283064365386963e-10, "_runtime": 4744.756758213043, "_timestamp": 1585513823.1774879, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00014324160292744637, "Value Loss": 2.0653723176167205e-10, "_runtime": 4746.317083120346, "_timestamp": 1585513824.7378128, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001244341256096959, "Value Loss": 1.5370460459962487e-10, "_runtime": 4747.912309646606, "_timestamp": 1585513826.3330393, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001148772644228302, "Value Loss": 1.3096723705530167e-10, "_runtime": 4749.469662427902, "_timestamp": 1585513827.890392, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00010521031799726188, "Value Loss": 1.5340781422956695e-10, "_runtime": 4751.019291639328, "_timestamp": 1585513829.4400213, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.595026494935155e-05, "Value Loss": 9.146840229679043e-11, "_runtime": 4752.575668096542, "_timestamp": 1585513830.9963977, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.599543070886284e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 4754.138727903366, "_timestamp": 1585513832.5594575, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.680212002014741e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 4755.683704614639, "_timestamp": 1585513834.1044343, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.719065277138725e-05, "Value Loss": 4.4565240386873484e-11, "_runtime": 4757.246207714081, "_timestamp": 1585513835.6669374, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.727485040551983e-05, "Value Loss": 3.2741809263825417e-11, "_runtime": 4758.802078485489, "_timestamp": 1585513837.2228081, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.8119210987351835e-05, "Value Loss": 7.421531444951057e-11, "_runtime": 4760.363460302353, "_timestamp": 1585513838.78419, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.83702245017048e-05, "Value Loss": 1.498890941920017e-11, "_runtime": 4761.920763254166, "_timestamp": 1585513840.341493, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8690976250800304e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4763.4703488349915, "_timestamp": 1585513841.8910785, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9111763322143815e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4765.018014907837, "_timestamp": 1585513843.4387445, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.91189883480547e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4766.580308437347, "_timestamp": 1585513845.001038, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.579498509992845e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4768.1385061740875, "_timestamp": 1585513846.5592358, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.748159754963126e-06, "Value Loss": 5.363287591819699e-11, "_runtime": 4769.698646068573, "_timestamp": 1585513848.1193757, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4771.292687416077, "_timestamp": 1585513849.713417, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4772.856093406677, "_timestamp": 1585513851.276823, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.58422060648445e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4774.413872718811, "_timestamp": 1585513852.8346024, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.543588021188043e-06, "Value Loss": 2.351576398884614e-12, "_runtime": 4775.972953081131, "_timestamp": 1585513854.3936827, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8671196812647395e-05, "Value Loss": 3.1686649831774716e-11, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668, 7.20319938659668]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.20319938659668, 1.8177623748779297, 10.838724136352539, 19.85968589782715, 28.880647659301758, 37.901611328125, 46.922569274902344, 55.94353485107422, 64.96449279785156, 73.98545837402344, 83.00641632080078, 92.02737426757812, 101.04833984375, 110.06930541992188, 119.09026336669922, 128.11122131347656, 137.13218688964844, 146.1531524658203, 155.1741180419922, 164.195068359375, 173.21603393554688, 182.23699951171875, 191.25794982910156, 200.27891540527344, 209.2998809814453, 218.3208465576172, 227.34181213378906, 236.36276245117188, 245.38372802734375, 254.40467834472656, 263.4256591796875, 272.4466247558594, 281.46759033203125, 290.4885559082031, 299.509521484375, 308.5304870605469, 317.55145263671875, 326.5723876953125, 335.5933532714844, 344.61431884765625, 353.6352844238281, 362.65625, 371.6772155761719, 380.69818115234375, 389.7191162109375, 398.7400817871094, 407.76104736328125, 416.7820129394531, 425.802978515625, 434.8239440917969, 443.84490966796875, 452.8658752441406, 461.8868408203125, 470.90777587890625, 479.9287414550781, 488.94970703125, 497.9706726074219, 506.99163818359375, 516.0125732421875, 525.0335693359375, 534.0545043945312, 543.0755004882812, 552.096435546875, 561.117431640625, 570.1383666992188]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-12.061565399169922, -11.755475044250488, -11.449385643005371, -11.143295288085938, -10.837204933166504, -10.53111457824707, -10.225025177001953, -9.91893482208252, -9.612844467163086, -9.306755065917969, -9.000664710998535, -8.694574356079102, -8.388484954833984, -8.08239459991455, -7.776304721832275, -7.470214366912842, -7.164124488830566, -6.858034610748291, -6.551944255828857, -6.245854377746582, -5.939764022827148, -5.633674144744873, -5.327584266662598, -5.021493911743164, -4.715404033660889, -4.409314155578613, -4.10322380065918, -3.797133445739746, -3.491044044494629, -3.1849536895751953, -2.8788633346557617, -2.5727739334106445, -2.266683578491211, -1.9605932235717773, -1.6545038223266602, -1.3484134674072266, -1.042323112487793, -0.7362337112426758, -0.4301433563232422, -0.1240530014038086, 0.182037353515625, 0.4881267547607422, 0.7942171096801758, 1.1003074645996094, 1.4063968658447266, 1.7124872207641602, 2.0185775756835938, 2.324666976928711, 2.6307573318481445, 2.936847686767578, 3.2429370880126953, 3.549027442932129, 3.8551177978515625, 4.16120719909668, 4.46729850769043, 4.773387908935547, 5.079477310180664, 5.385568618774414, 5.691658020019531, 5.997747421264648, 6.303838729858398, 6.609928131103516, 6.916017532348633, 7.222108840942383, 7.5281982421875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 19.0, 19.0, 5.0, 357.0, 3.0, 21.0, 0.0, 20.0, 18.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-97.80764770507812, -95.32555389404297, -92.84346008300781, -90.36137390136719, -87.87928009033203, -85.39718627929688, -82.91509246826172, -80.43299865722656, -77.95091247558594, -75.46881866455078, -72.98672485351562, -70.50463104248047, -68.02253723144531, -65.54045104980469, -63.058353424072266, -60.576263427734375, -58.09416961669922, -55.61207580566406, -53.12998580932617, -50.647891998291016, -48.165802001953125, -45.68370819091797, -43.20161437988281, -40.71952438354492, -38.237430572509766, -35.75533676147461, -33.27324676513672, -30.791152954101562, -28.309059143066406, -25.82696533203125, -23.344879150390625, -20.86278533935547, -18.380691528320312, -15.898597717285156, -13.41650390625, -10.934417724609375, -8.452323913574219, -5.9702301025390625, -3.4881362915039062, -1.00604248046875, 1.476043701171875, 3.9581375122070312, 6.4402313232421875, 8.922325134277344, 11.4044189453125, 13.886512756347656, 16.36859893798828, 18.850692749023438, 21.332786560058594, 23.81488037109375, 26.296974182128906, 28.77906036376953, 31.261154174804688, 33.743255615234375, 36.225341796875, 38.707427978515625, 41.18952941894531, 43.67161560058594, 46.153717041015625, 48.63580322265625, 51.117889404296875, 53.59999084472656, 56.08207702636719, 58.564178466796875, 61.0462646484375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-47.10871887207031, -45.7739143371582, -44.439109802246094, -43.104305267333984, -41.769500732421875, -40.4346923828125, -39.09988784790039, -37.76508331298828, -36.43027877807617, -35.09547424316406, -33.76066970825195, -32.425865173339844, -31.0910587310791, -29.756254196166992, -28.42144775390625, -27.08664321899414, -25.75183868408203, -24.417034149169922, -23.082229614257812, -21.74742317199707, -20.41261863708496, -19.07781410217285, -17.74300765991211, -16.408203125, -15.07339859008789, -13.738594055175781, -12.403789520263672, -11.068984985351562, -9.734176635742188, -8.399372100830078, -7.064567565917969, -5.729763031005859, -4.39495849609375, -3.0601539611816406, -1.7253494262695312, -0.3905448913574219, 0.9442596435546875, 2.2790679931640625, 3.613872528076172, 4.948677062988281, 6.283481597900391, 7.6182861328125, 8.95309066772461, 10.287895202636719, 11.622703552246094, 12.957508087158203, 14.292312622070312, 15.627117156982422, 16.96192169189453, 18.296730041503906, 19.63153076171875, 20.966339111328125, 22.30113983154297, 23.635948181152344, 24.970748901367188, 26.305557250976562, 27.640365600585938, 28.97516632080078, 30.309974670410156, 31.644775390625, 32.979583740234375, 34.31438446044922, 35.649192810058594, 36.98399353027344, 38.31880187988281]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 35.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-40.23491668701172, -38.83336639404297, -37.43181610107422, -36.03026580810547, -34.62871551513672, -33.22716522216797, -31.82561492919922, -30.42406463623047, -29.02251434326172, -27.62096405029297, -26.21941375732422, -24.81786346435547, -23.41631317138672, -22.01476287841797, -20.61321258544922, -19.21166229248047, -17.81011199951172, -16.40856170654297, -15.007011413574219, -13.605461120605469, -12.203910827636719, -10.802360534667969, -9.400810241699219, -7.999259948730469, -6.597709655761719, -5.196159362792969, -3.7946090698242188, -2.3930587768554688, -0.9915084838867188, 0.41004180908203125, 1.8115921020507812, 3.2131423950195312, 4.614692687988281, 6.016242980957031, 7.417793273925781, 8.819343566894531, 10.220893859863281, 11.622444152832031, 13.023994445800781, 14.425544738769531, 15.827095031738281, 17.22864532470703, 18.63019561767578, 20.03174591064453, 21.43329620361328, 22.83484649658203, 24.23639678955078, 25.63794708251953, 27.03949737548828, 28.44104766845703, 29.84259796142578, 31.24414825439453, 32.64569854736328, 34.04724884033203, 35.44879913330078, 36.85034942626953, 38.25189971923828, 39.65345001220703, 41.05500030517578, 42.45655059814453, 43.85810089111328, 45.25965118408203, 46.66120147705078, 48.06275177001953, 49.46430206298828]}, "_runtime": 4777.522944927216, "_timestamp": 1585513855.9436746, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.915774555527605e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4779.068502187729, "_timestamp": 1585513857.4892318, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9277489627711475e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4780.633722782135, "_timestamp": 1585513859.0544524, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.911641811602749e-05, "Value Loss": 3.780001919112541e-12, "_runtime": 4782.182771921158, "_timestamp": 1585513860.6035016, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8841846869909205e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4783.741535425186, "_timestamp": 1585513862.162265, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.875911923183594e-05, "Value Loss": 4.693866823002324e-11, "_runtime": 4785.301305055618, "_timestamp": 1585513863.7220347, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8754117010976188e-05, "Value Loss": 1.6189733581528643e-11, "_runtime": 4786.84949016571, "_timestamp": 1585513865.2702198, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8665623176493682e-05, "Value Loss": 1.7225774626150603e-11, "_runtime": 4788.399483203888, "_timestamp": 1585513866.8202128, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8450742320274003e-05, "Value Loss": 9.171238768423962e-11, "_runtime": 4789.9485912323, "_timestamp": 1585513868.3693209, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8812668460886925e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4791.5069761276245, "_timestamp": 1585513869.9277058, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8642632969422266e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4793.064258575439, "_timestamp": 1585513871.4849882, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8831838790210895e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4794.6490252017975, "_timestamp": 1585513873.0697548, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8722233764710836e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4796.21036195755, "_timestamp": 1585513874.6310916, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.871869583032094e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4797.773047924042, "_timestamp": 1585513876.1937776, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8730568374157883e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 4799.335791349411, "_timestamp": 1585513877.756521, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9196641005692072e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4800.902153015137, "_timestamp": 1585513879.3228827, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9080091078649275e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4802.462874174118, "_timestamp": 1585513880.8836038, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9173305190633982e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4804.020836353302, "_timestamp": 1585513882.441566, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9121484001516365e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4805.572494506836, "_timestamp": 1585513883.9932241, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.922094998008106e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4807.125066995621, "_timestamp": 1585513885.5457966, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.907745172502473e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4808.679250001907, "_timestamp": 1585513887.0999796, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8787030057865195e-05, "Value Loss": 7.316015154801292e-11, "_runtime": 4810.228303432465, "_timestamp": 1585513888.649033, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.924831849464681e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 4811.7795317173, "_timestamp": 1585513890.2002614, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.541920007904992e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4813.343517541885, "_timestamp": 1585513891.7642472, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.5892219178495e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4814.90748000145, "_timestamp": 1585513893.3282096, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.561229489918333e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4816.470192193985, "_timestamp": 1585513894.8909218, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.177140782412607e-06, "Value Loss": 7.880102126378574e-11, "_runtime": 4818.056558132172, "_timestamp": 1585513896.4772878, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.619783668313175e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4819.61381649971, "_timestamp": 1585513898.0345461, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.546643013891298e-06, "Value Loss": 1.0733676317556395e-12, "_runtime": 4821.162694692612, "_timestamp": 1585513899.5834243, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.590264198777732e-06, "Value Loss": 9.094947017729282e-13, "_runtime": 4822.72107052803, "_timestamp": 1585513901.1418002, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.306239548805934e-08, "Value Loss": 3.190787911666604e-11, "_runtime": 4824.281233549118, "_timestamp": 1585513902.7019632, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.00134689218612e-09, "Value Loss": 4.8754014714269545e-11, "_runtime": 4825.8404586315155, "_timestamp": 1585513904.2611883, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8475972751730296e-08, "Value Loss": 7.938732679048377e-13, "_runtime": 4827.400933265686, "_timestamp": 1585513905.821663, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4828.955366373062, "_timestamp": 1585513907.376096, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.223683873291975e-09, "Value Loss": 4.078614887232518e-13, "_runtime": 4830.523197650909, "_timestamp": 1585513908.9439273, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4832.090250253677, "_timestamp": 1585513910.51098, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4833.656192302704, "_timestamp": 1585513912.076922, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4835.224490642548, "_timestamp": 1585513913.6452203, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4836.791747331619, "_timestamp": 1585513915.212477, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4838.3618080616, "_timestamp": 1585513916.7825377, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.098458271708296e-08, "Value Loss": 7.217691722072317e-12, "_runtime": 4839.934628248215, "_timestamp": 1585513918.355358, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4841.5338406562805, "_timestamp": 1585513919.9545703, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.97341909269744e-08, "Value Loss": 7.938732679048377e-13, "_runtime": 4843.104511260986, "_timestamp": 1585513921.525241, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4844.665404319763, "_timestamp": 1585513923.086134, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4846.230231761932, "_timestamp": 1585513924.6509614, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4030624662098035e-08, "Value Loss": 5.3895982728841e-13, "_runtime": 4847.786021947861, "_timestamp": 1585513926.2067516, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.7438063316130865e-08, "Value Loss": 4.752314535817759e-13, "_runtime": 4849.336391687393, "_timestamp": 1585513927.7571213, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5004822656882197e-09, "Value Loss": 1.873613677400021e-12, "_runtime": 4850.899320602417, "_timestamp": 1585513929.3200502, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4852.451488494873, "_timestamp": 1585513930.8722181, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.50146167405319e-09, "Value Loss": 1.6605789009485616e-12, "_runtime": 4854.011184930801, "_timestamp": 1585513932.4319146, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.444935098822043e-08, "Value Loss": 1.653295664434673e-12, "_runtime": 4855.572009801865, "_timestamp": 1585513933.9927394, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.863052596870148e-09, "Value Loss": 7.720235041530632e-13, "_runtime": 4857.136658191681, "_timestamp": 1585513935.5573878, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4858.698514223099, "_timestamp": 1585513937.1192439, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4860.258280754089, "_timestamp": 1585513938.6790104, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4861.817719221115, "_timestamp": 1585513940.2384489, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.58414550763564e-09, "Value Loss": 1.5859257266812032e-12, "_runtime": 4863.414084672928, "_timestamp": 1585513941.8348143, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4864.975874423981, "_timestamp": 1585513943.396604, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4866.5333087444305, "_timestamp": 1585513944.9540384, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4868.089675664902, "_timestamp": 1585513946.5104053, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4869.649872779846, "_timestamp": 1585513948.0706024, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4871.197710514069, "_timestamp": 1585513949.6184402, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4872.736231327057, "_timestamp": 1585513951.156961, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4336627600641805e-06, "Value Loss": 5.3797657301180024e-11, "_runtime": 4874.288497686386, "_timestamp": 1585513952.7092273, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4875.84973025322, "_timestamp": 1585513954.27046, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6357722643078887e-06, "Value Loss": 3.9680918273443666e-11, "_runtime": 4877.401950120926, "_timestamp": 1585513955.8226798, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4867638356008683e-06, "Value Loss": 5.3411646633305665e-11, "_runtime": 4878.950604915619, "_timestamp": 1585513957.3713346, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1111890216852771e-06, "Value Loss": 5.28034972517577e-13, "_runtime": 4880.503373861313, "_timestamp": 1585513958.9241035, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4882.063010215759, "_timestamp": 1585513960.4837399, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4883.626081943512, "_timestamp": 1585513962.0468116, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4885.188748598099, "_timestamp": 1585513963.6094782, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4886.78334069252, "_timestamp": 1585513965.2040703, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.300924282077176e-06, "Value Loss": 1.6933534652610605e-12, "_runtime": 4888.328939676285, "_timestamp": 1585513966.7496693, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4889.877811908722, "_timestamp": 1585513968.2985415, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4891.436060190201, "_timestamp": 1585513969.8567898, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4892.984916687012, "_timestamp": 1585513971.4056463, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7025955401095416e-07, "Value Loss": 7.738443539391168e-14, "_runtime": 4894.543656110764, "_timestamp": 1585513972.9643857, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4896.102992773056, "_timestamp": 1585513974.5237224, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.467638619753416e-07, "Value Loss": 4.5065053034740177e-13, "_runtime": 4897.660352945328, "_timestamp": 1585513976.0810826, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2179767736597569e-06, "Value Loss": 5.471534683665347e-12, "_runtime": 4899.2103815078735, "_timestamp": 1585513977.6311111, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3527279634217848e-06, "Value Loss": 2.731215319011493e-13, "_runtime": 4900.767630338669, "_timestamp": 1585513979.18836, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2200320043120882e-06, "Value Loss": 1.4293360332123806e-12, "_runtime": 4902.326199531555, "_timestamp": 1585513980.7469292, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4903.885598182678, "_timestamp": 1585513982.3063278, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4905.446000099182, "_timestamp": 1585513983.8667297, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4907.007127761841, "_timestamp": 1585513985.4278574, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4908.564756393433, "_timestamp": 1585513986.985486, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4910.150940179825, "_timestamp": 1585513988.5716698, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4911.711767196655, "_timestamp": 1585513990.1324968, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4913.262654542923, "_timestamp": 1585513991.6833842, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5966118098731386e-06, "Value Loss": 7.708945981566018e-11, "_runtime": 4914.821349620819, "_timestamp": 1585513993.2420793, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4916.362328052521, "_timestamp": 1585513994.7830577, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.44017747061298e-06, "Value Loss": 3.938230297428902e-11, "_runtime": 4917.91181230545, "_timestamp": 1585513996.332542, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4919.461398839951, "_timestamp": 1585513997.8821285, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0244752957078163e-06, "Value Loss": 4.870667129168449e-13, "_runtime": 4921.025461196899, "_timestamp": 1585513999.4461908, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4922.587030649185, "_timestamp": 1585514001.0077603, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4924.146614789963, "_timestamp": 1585514002.5673444, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.504090374117368e-07, "Value Loss": 3.9602622938818277e-13, "_runtime": 4925.706542253494, "_timestamp": 1585514004.127272, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4927.258513212204, "_timestamp": 1585514005.6792428, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4928.822551250458, "_timestamp": 1585514007.243281, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7043770412783488e-06, "Value Loss": 5.176199399659076e-11, "_runtime": 4930.381462812424, "_timestamp": 1585514008.8021924, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2744328614644473e-06, "Value Loss": 1.6833390150544636e-12, "_runtime": 4931.93514251709, "_timestamp": 1585514010.3558722, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922, 19.354045867919922]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-19.354045867919922, 5.952327728271484, 31.25870132446289, 56.5650749206543, 81.87144470214844, 107.17782592773438, 132.48419189453125, 157.7905731201172, 183.09693908691406, 208.40330505371094, 233.70968627929688, 259.0160827636719, 284.32244873046875, 309.6288146972656, 334.9352111816406, 360.2415771484375, 385.5479431152344, 410.85430908203125, 436.1606750488281, 461.4670715332031, 486.7734375, 512.0797729492188, 537.3861694335938, 562.6925048828125, 587.9989013671875, 613.3052978515625, 638.6116333007812, 663.9180297851562, 689.2244262695312, 714.53076171875, 739.837158203125, 765.1434936523438, 790.4498901367188, 815.7562866210938, 841.0626220703125, 866.3690185546875, 891.6753540039062, 916.9817504882812, 942.2881469726562, 967.594482421875, 992.90087890625, 1018.2072143554688, 1043.513671875, 1068.820068359375, 1094.12646484375, 1119.432861328125, 1144.7391357421875, 1170.0455322265625, 1195.3519287109375, 1220.6583251953125, 1245.9647216796875, 1271.27099609375, 1296.577392578125, 1321.8837890625, 1347.190185546875, 1372.49658203125, 1397.802978515625, 1423.1092529296875, 1448.4156494140625, 1473.7220458984375, 1499.0284423828125, 1524.3348388671875, 1549.64111328125, 1574.947509765625, 1600.25390625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-32.407676696777344, -31.585248947143555, -30.7628231048584, -29.94039535522461, -29.11796760559082, -28.295541763305664, -27.473114013671875, -26.65068817138672, -25.82826042175293, -25.00583267211914, -24.183406829833984, -23.360979080200195, -22.538551330566406, -21.71612548828125, -20.89369773864746, -20.071269989013672, -19.248844146728516, -18.426416397094727, -17.603988647460938, -16.78156280517578, -15.959135055541992, -15.136707305908203, -14.314281463623047, -13.491853713989258, -12.669425964355469, -11.847000122070312, -11.024572372436523, -10.202144622802734, -9.379718780517578, -8.557291030883789, -7.73486328125, -6.912437438964844, -6.090009689331055, -5.267581939697266, -4.445156097412109, -3.6227283477783203, -2.8003005981445312, -1.977874755859375, -1.155447006225586, -0.3330192565917969, 0.4894065856933594, 1.3118324279785156, 2.1342620849609375, 2.9566879272460938, 3.77911376953125, 4.601543426513672, 5.423969268798828, 6.246395111083984, 7.068824768066406, 7.8912506103515625, 8.713676452636719, 9.53610610961914, 10.358531951904297, 11.180957794189453, 12.003387451171875, 12.825813293457031, 13.648239135742188, 14.47066879272461, 15.293094635009766, 16.115520477294922, 16.937950134277344, 17.7603759765625, 18.582801818847656, 19.405231475830078, 20.227657318115234]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 0.0, 2.0, 19.0, 22.0, 4.0, 353.0, 4.0, 19.0, 5.0, 33.0, 1.0, 2.0, 3.0, 3.0, 0.0, 3.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-272.4444580078125, -265.5304870605469, -258.61651611328125, -251.70254516601562, -244.78857421875, -237.87460327148438, -230.96063232421875, -224.04666137695312, -217.1326904296875, -210.21871948242188, -203.30474853515625, -196.39077758789062, -189.47682189941406, -182.56285095214844, -175.6488800048828, -168.7349090576172, -161.82093811035156, -154.90696716308594, -147.9929962158203, -141.0790252685547, -134.16505432128906, -127.25108337402344, -120.33711242675781, -113.42314147949219, -106.50918579101562, -99.59521484375, -92.68124389648438, -85.76727294921875, -78.85330200195312, -71.9393310546875, -65.02536010742188, -58.11138916015625, -51.197418212890625, -44.283447265625, -37.369476318359375, -30.45550537109375, -23.541534423828125, -16.6275634765625, -9.713592529296875, -2.79962158203125, 4.114349365234375, 11.0283203125, 17.942291259765625, 24.85626220703125, 31.770233154296875, 38.6842041015625, 45.598175048828125, 52.51214599609375, 59.42608642578125, 66.34005737304688, 73.2540283203125, 80.16799926757812, 87.08197021484375, 93.99594116210938, 100.909912109375, 107.82388305664062, 114.73785400390625, 121.65182495117188, 128.5657958984375, 135.47976684570312, 142.39373779296875, 149.30770874023438, 156.2216796875, 163.13565063476562, 170.04962158203125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 5.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-121.69319915771484, -118.21984100341797, -114.74647521972656, -111.27311706542969, -107.79975128173828, -104.3263931274414, -100.85302734375, -97.37966918945312, -93.90631103515625, -90.43294525146484, -86.95957946777344, -83.48622131347656, -80.01286315917969, -76.53950500488281, -73.0661392211914, -69.5927734375, -66.11941528320312, -62.646053314208984, -59.172691345214844, -55.69933319091797, -52.22596740722656, -48.75260925292969, -45.27924346923828, -41.805885314941406, -38.33252716064453, -34.859161376953125, -31.38580322265625, -27.912437438964844, -24.43907928466797, -20.965713500976562, -17.492355346679688, -14.018989562988281, -10.545631408691406, -7.072273254394531, -3.598907470703125, -0.12554931640625, 3.3478164672851562, 6.821174621582031, 10.294532775878906, 13.767906188964844, 17.24126434326172, 20.714622497558594, 24.18798065185547, 27.661338806152344, 31.13471221923828, 34.608070373535156, 38.08142852783203, 41.554786682128906, 45.02814483642578, 48.50151824951172, 51.974876403808594, 55.44823455810547, 58.921592712402344, 62.39496612548828, 65.86832427978516, 69.34168243408203, 72.8150405883789, 76.28839874267578, 79.76177215576172, 83.2351303100586, 86.70848846435547, 90.18184661865234, 93.65522003173828, 97.12857818603516, 100.60193634033203]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 10.0, 11.0, 9.0, 5.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-109.4301986694336, -105.60204315185547, -101.77388000488281, -97.94572448730469, -94.11756896972656, -90.28941345214844, -86.46125030517578, -82.63309478759766, -78.804931640625, -74.97677612304688, -71.14862060546875, -67.32046508789062, -63.49230194091797, -59.664146423339844, -55.83598709106445, -52.00783157348633, -48.17967224121094, -44.35151672363281, -40.523353576660156, -36.69519805908203, -32.867042541503906, -29.03887939453125, -25.210723876953125, -21.382568359375, -17.554405212402344, -13.726249694824219, -9.898094177246094, -6.069938659667969, -2.2417755126953125, 1.5863800048828125, 5.4145355224609375, 9.242698669433594, 13.070854187011719, 16.899009704589844, 20.72716522216797, 24.555320739746094, 28.38349151611328, 32.211647033691406, 36.03980255126953, 39.867958068847656, 43.69611358642578, 47.524269104003906, 51.352439880371094, 55.18059539794922, 59.008750915527344, 62.83690643310547, 66.6650619506836, 70.49321746826172, 74.3213882446289, 78.14954376220703, 81.97769927978516, 85.80585479736328, 89.6340103149414, 93.46216583251953, 97.29032135009766, 101.11849212646484, 104.94664764404297, 108.7748031616211, 112.60295867919922, 116.43111419677734, 120.25926971435547, 124.08744049072266, 127.91559600830078, 131.74374389648438, 135.5718994140625]}, "_runtime": 4933.530712604523, "_timestamp": 1585514011.9514422, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.64119012424635e-06, "Value Loss": 4.08862943501731e-11, "_runtime": 4935.096893548965, "_timestamp": 1585514013.5176232, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4936.664932966232, "_timestamp": 1585514015.0856626, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4938.222001552582, "_timestamp": 1585514016.6427312, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4939.790890693665, "_timestamp": 1585514018.2116203, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4941.3598256111145, "_timestamp": 1585514019.7805552, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.880181674911e-07, "Value Loss": 2.776735547223297e-13, "_runtime": 4942.9267518520355, "_timestamp": 1585514021.3474815, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4944.4826765060425, "_timestamp": 1585514022.9034061, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4946.040915727615, "_timestamp": 1585514024.4616454, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4947.600182056427, "_timestamp": 1585514026.0209117, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4949.155043840408, "_timestamp": 1585514027.5757735, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4950.722481012344, "_timestamp": 1585514029.1432106, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0705131217036978e-06, "Value Loss": 5.007228355904947e-13, "_runtime": 4952.289910078049, "_timestamp": 1585514030.7106397, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6685708033037372e-06, "Value Loss": 6.514130901358328e-11, "_runtime": 4953.857588768005, "_timestamp": 1585514032.2783184, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2002354878859478e-06, "Value Loss": 1.1516624242799423e-12, "_runtime": 4955.457540273666, "_timestamp": 1585514033.87827, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4380373158928705e-06, "Value Loss": 2.7755520104477682e-11, "_runtime": 4957.027702093124, "_timestamp": 1585514035.4484317, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4958.599671602249, "_timestamp": 1585514037.0204012, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4960.1558446884155, "_timestamp": 1585514038.5765743, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4961.7249500751495, "_timestamp": 1585514040.1456797, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4963.271870136261, "_timestamp": 1585514041.6925998, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3325012560017058e-06, "Value Loss": 4.023990613378353e-13, "_runtime": 4964.830566167831, "_timestamp": 1585514043.2512958, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4966.399194478989, "_timestamp": 1585514044.819924, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4967.9570748806, "_timestamp": 1585514046.3778045, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0291433909515035e-06, "Value Loss": 4.961707585592057e-13, "_runtime": 4969.515744447708, "_timestamp": 1585514047.936474, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.006526645142003e-06, "Value Loss": 4.688586216321233e-13, "_runtime": 4971.062831401825, "_timestamp": 1585514049.483561, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4972.630692481995, "_timestamp": 1585514051.051422, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4974.189691781998, "_timestamp": 1585514052.6104214, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2219777545396937e-06, "Value Loss": 1.6705933511551585e-12, "_runtime": 4975.756494283676, "_timestamp": 1585514054.177224, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.227758717614051e-07, "Value Loss": 2.9588167311210556e-13, "_runtime": 4977.31951212883, "_timestamp": 1585514055.7402418, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4978.913510799408, "_timestamp": 1585514057.3342404, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4980.461129665375, "_timestamp": 1585514058.8818593, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4982.0224623680115, "_timestamp": 1585514060.443192, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4983.584644794464, "_timestamp": 1585514062.0053744, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4985.149735212326, "_timestamp": 1585514063.5704648, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3370712395044393e-06, "Value Loss": 7.72751827804452e-12, "_runtime": 4986.707790374756, "_timestamp": 1585514065.12852, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8414882561046397e-06, "Value Loss": 9.357143532229273e-11, "_runtime": 4988.2654094696045, "_timestamp": 1585514066.686139, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.230618977388076e-06, "Value Loss": 5.998659034778253e-12, "_runtime": 4989.822119474411, "_timestamp": 1585514068.242849, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4991.38240146637, "_timestamp": 1585514069.803131, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.007936915215396e-07, "Value Loss": 1.974668692450443e-12, "_runtime": 4992.940518856049, "_timestamp": 1585514071.3612485, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4994.499171257019, "_timestamp": 1585514072.919901, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0142946866030798e-08, "Value Loss": 1.529480616593512e-13, "_runtime": 4996.057778596878, "_timestamp": 1585514074.4785082, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 4997.618817806244, "_timestamp": 1585514076.0395474, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6812849718282905e-09, "Value Loss": 1.265463157439778e-13, "_runtime": 4999.175278186798, "_timestamp": 1585514077.5960078, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5000.7344563007355, "_timestamp": 1585514079.155186, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5002.328753709793, "_timestamp": 1585514080.7494833, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.302829890752037e-07, "Value Loss": 1.8517639678583553e-12, "_runtime": 5003.891163825989, "_timestamp": 1585514082.3118935, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.533739108112059e-07, "Value Loss": 1.0041768848736976e-12, "_runtime": 5005.45104598999, "_timestamp": 1585514083.8717756, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5007.012303829193, "_timestamp": 1585514085.4330335, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5008.561038970947, "_timestamp": 1585514086.9817686, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.65473923031368e-09, "Value Loss": 5.589887277016037e-13, "_runtime": 5010.1122851371765, "_timestamp": 1585514088.5330148, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5011.663979291916, "_timestamp": 1585514090.084709, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5101986718946137e-06, "Value Loss": 6.583321388031749e-11, "_runtime": 5013.225439786911, "_timestamp": 1585514091.6461694, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5014.766268491745, "_timestamp": 1585514093.1869981, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5016.320677518845, "_timestamp": 1585514094.7414072, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.740875839270302e-07, "Value Loss": 1.2985107780694172e-11, "_runtime": 5017.871331453323, "_timestamp": 1585514096.292061, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4584377368009882e-06, "Value Loss": 3.711357610125532e-11, "_runtime": 5019.423742771149, "_timestamp": 1585514097.8444724, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7227660126527553e-08, "Value Loss": 8.521391600159467e-13, "_runtime": 5020.979400634766, "_timestamp": 1585514099.4001303, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.565085636291769e-07, "Value Loss": 1.6373635086663896e-11, "_runtime": 5022.531455039978, "_timestamp": 1585514100.9521847, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.319147137721302e-07, "Value Loss": 1.7507090612281506e-12, "_runtime": 5024.092170238495, "_timestamp": 1585514102.5128999, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4586046814812903e-09, "Value Loss": 6.88266284243344e-13, "_runtime": 5025.668183088303, "_timestamp": 1585514104.0889127, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5280843257414745e-08, "Value Loss": 1.4384400246446327e-13, "_runtime": 5027.241846084595, "_timestamp": 1585514105.6625757, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5352283827828614e-08, "Value Loss": 5.790176281147974e-13, "_runtime": 5028.805364847183, "_timestamp": 1585514107.2260945, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5030.375937700272, "_timestamp": 1585514108.7966673, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5031.949440717697, "_timestamp": 1585514110.3701704, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5033.524202346802, "_timestamp": 1585514111.944932, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5035.091886997223, "_timestamp": 1585514113.5126166, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.19488320851724e-08, "Value Loss": 7.082951846565377e-13, "_runtime": 5036.649773597717, "_timestamp": 1585514115.0705032, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.320700407513868e-09, "Value Loss": 2.986128868048138e-13, "_runtime": 5038.21519780159, "_timestamp": 1585514116.6359274, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.628342473253724e-07, "Value Loss": 4.949872543097422e-12, "_runtime": 5039.78427863121, "_timestamp": 1585514118.2050083, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4377857127101379e-08, "Value Loss": 5.262141633891049e-13, "_runtime": 5041.355171203613, "_timestamp": 1585514119.7759008, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5042.923858642578, "_timestamp": 1585514121.3445883, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.993652969962568e-08, "Value Loss": 8.612432056583075e-13, "_runtime": 5044.485764741898, "_timestamp": 1585514122.9064944, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.625927729762225e-08, "Value Loss": 3.605204242779214e-13, "_runtime": 5046.059868097305, "_timestamp": 1585514124.4805977, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5047.6328682899475, "_timestamp": 1585514126.053598, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5049.238002061844, "_timestamp": 1585514127.6587317, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5050.8160235881805, "_timestamp": 1585514129.2367532, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5052.381292104721, "_timestamp": 1585514130.8020217, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5053.946722507477, "_timestamp": 1585514132.3674521, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5055.519762992859, "_timestamp": 1585514133.9404926, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5057.097945928574, "_timestamp": 1585514135.5186756, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5058.664911031723, "_timestamp": 1585514137.0856407, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.160109364827804e-07, "Value Loss": 2.004712151490451e-12, "_runtime": 5060.236943483353, "_timestamp": 1585514138.6576731, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.9172657622922316e-09, "Value Loss": 1.6751453468712846e-13, "_runtime": 5061.815911531448, "_timestamp": 1585514140.2366412, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5063.3922572135925, "_timestamp": 1585514141.8129869, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.237845238705631e-07, "Value Loss": 9.714022121409815e-13, "_runtime": 5064.956354856491, "_timestamp": 1585514143.3770845, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5066.52291893959, "_timestamp": 1585514144.9436486, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5068.090591430664, "_timestamp": 1585514146.511321, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5069.659126520157, "_timestamp": 1585514148.0798562, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5071.275233030319, "_timestamp": 1585514149.6959627, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5072.852125883102, "_timestamp": 1585514151.2728555, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.070468489520863e-09, "Value Loss": 9.286131976218859e-14, "_runtime": 5074.415023326874, "_timestamp": 1585514152.835753, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3168814803066198e-06, "Value Loss": 3.420027802625292e-11, "_runtime": 5075.990913391113, "_timestamp": 1585514154.411643, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5077.558487415314, "_timestamp": 1585514155.979217, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5079.127954244614, "_timestamp": 1585514157.548684, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.6187785212860035e-08, "Value Loss": 8.940178241809149e-13, "_runtime": 5080.6828355789185, "_timestamp": 1585514159.1035652, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.902846732577018e-07, "Value Loss": 6.379208793150237e-12, "_runtime": 5082.247155427933, "_timestamp": 1585514160.667885, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5083.78649687767, "_timestamp": 1585514162.2072265, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1611874697337043e-06, "Value Loss": 5.365017458069943e-11, "_runtime": 5085.347732543945, "_timestamp": 1585514163.7684622, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5086.915055990219, "_timestamp": 1585514165.3357856, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5088.471446752548, "_timestamp": 1585514166.8921764, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.313380721512658e-06, "Value Loss": 4.263700156825756e-11, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 5090.029925584793, "_timestamp": 1585514168.4506552, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5091.579701662064, "_timestamp": 1585514170.0004313, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.235337435900874e-06, "Value Loss": 3.9773778021112705e-11, "_runtime": 5093.140674829483, "_timestamp": 1585514171.5614045, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0219984498435224e-07, "Value Loss": 1.7079199382888377e-12, "_runtime": 5094.740738868713, "_timestamp": 1585514173.1614685, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0976706334986375e-06, "Value Loss": 3.9835686832523365e-11, "_runtime": 5096.300590753555, "_timestamp": 1585514174.7213204, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5097.85618853569, "_timestamp": 1585514176.2769182, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5099.416855573654, "_timestamp": 1585514177.8375852, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5100.9737713336945, "_timestamp": 1585514179.394501, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5102.520805120468, "_timestamp": 1585514180.9415348, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2175562460470246e-06, "Value Loss": 3.562415293312249e-11, "_runtime": 5104.082984924316, "_timestamp": 1585514182.5037146, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.674947883311688e-08, "Value Loss": 8.576015874013632e-13, "_runtime": 5105.633145570755, "_timestamp": 1585514184.0538752, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.44301816362713e-06, "Value Loss": 3.7477736192226274e-11, "_runtime": 5107.191244602203, "_timestamp": 1585514185.6119742, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.324571586446837e-07, "Value Loss": 1.9236860368532227e-12, "_runtime": 5108.737401008606, "_timestamp": 1585514187.1581306, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5110.296343564987, "_timestamp": 1585514188.7170732, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0001970807138605e-08, "Value Loss": 8.72168114639249e-13, "_runtime": 5111.860361099243, "_timestamp": 1585514190.2810907, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5113.399571180344, "_timestamp": 1585514191.8203008, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.360366680586594e-07, "Value Loss": 5.722806343394504e-12, "_runtime": 5114.94859790802, "_timestamp": 1585514193.3693275, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.014314937071049e-09, "Value Loss": 3.222834054749518e-13, "_runtime": 5116.494872808456, "_timestamp": 1585514194.9156024, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5118.093944072723, "_timestamp": 1585514196.5146737, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5119.653968572617, "_timestamp": 1585514198.0746982, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6394173513466512e-09, "Value Loss": 2.184972309419303e-14, "_runtime": 5121.213835477829, "_timestamp": 1585514199.634565, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.1536111439199885e-08, "Value Loss": 8.266478322173365e-13, "_runtime": 5122.776529788971, "_timestamp": 1585514201.1972594, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.51575293836504e-07, "Value Loss": 7.910509920716624e-12, "_runtime": 5124.326344490051, "_timestamp": 1585514202.7470741, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1393187665808e-08, "Value Loss": 1.6751453468712846e-13, "_runtime": 5125.875849246979, "_timestamp": 1585514204.296579, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5127.427788734436, "_timestamp": 1585514205.8485184, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.148159741314885e-07, "Value Loss": 1.9810414159798784e-12, "_runtime": 5128.9847247600555, "_timestamp": 1585514207.4054544, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.194882497974504e-08, "Value Loss": 4.679482170678873e-13, "_runtime": 5130.534832239151, "_timestamp": 1585514208.9555619, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.223673215150939e-09, "Value Loss": 9.468212889066074e-14, "_runtime": 5132.097089767456, "_timestamp": 1585514210.5178194, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5133.646849870682, "_timestamp": 1585514212.0675795, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5135.195437431335, "_timestamp": 1585514213.616167, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.063587983997422e-07, "Value Loss": 1.3377492689981008e-11, "_runtime": 5136.7486300468445, "_timestamp": 1585514215.1693597, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5138.306582212448, "_timestamp": 1585514216.7273118, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5139.8682544231415, "_timestamp": 1585514218.288984, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5141.4678456783295, "_timestamp": 1585514219.8885753, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0956121059280122e-06, "Value Loss": 1.480864909864099e-11, "_runtime": 5143.029613733292, "_timestamp": 1585514221.4503434, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1076175496782525e-06, "Value Loss": 4.353739244122856e-11, "_runtime": 5144.592419862747, "_timestamp": 1585514223.0131495, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1201059351151343e-06, "Value Loss": 3.6305135980851944e-11, "_runtime": 5146.140349149704, "_timestamp": 1585514224.5610788, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5147.702028751373, "_timestamp": 1585514226.1227584, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.5840507450757286e-08, "Value Loss": 7.683818858961189e-13, "_runtime": 5149.258361816406, "_timestamp": 1585514227.6790915, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.368483127516811e-07, "Value Loss": 2.1066774626848916e-12, "_runtime": 5150.822929143906, "_timestamp": 1585514229.2436588, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5152.382805585861, "_timestamp": 1585514230.8035352, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5153.942818641663, "_timestamp": 1585514232.3635483, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.045680376904784e-07, "Value Loss": 5.692945073687561e-11, "_runtime": 5155.503345489502, "_timestamp": 1585514233.9240751, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.007147076848014e-08, "Value Loss": 1.529480616593512e-13, "_runtime": 5157.053285121918, "_timestamp": 1585514235.4740148, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.148389742411382e-06, "Value Loss": 8.114622862542831e-11, "_runtime": 5158.612530469894, "_timestamp": 1585514237.03326, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5160.1751165390015, "_timestamp": 1585514238.5958462, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.299277651080956e-08, "Value Loss": 7.647402676391746e-13, "_runtime": 5161.734466552734, "_timestamp": 1585514240.1551962, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5163.3312730789185, "_timestamp": 1585514241.7520027, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6086755039168565e-08, "Value Loss": 1.3382955225786641e-13, "_runtime": 5164.881046295166, "_timestamp": 1585514243.301776, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5166.441634893417, "_timestamp": 1585514244.8623645, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.625325118936871e-08, "Value Loss": 3.350290693742569e-13, "_runtime": 5167.990045070648, "_timestamp": 1585514246.4107747, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5169.551674365997, "_timestamp": 1585514247.972404, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.695574595814378e-09, "Value Loss": 1.265463157439778e-13, "_runtime": 5171.1145169734955, "_timestamp": 1585514249.5352466, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2921122777574965e-09, "Value Loss": 6.48208429206848e-13, "_runtime": 5172.650951862335, "_timestamp": 1585514251.0716815, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5174.185415029526, "_timestamp": 1585514252.6061447, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5175.7464253902435, "_timestamp": 1585514254.167155, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5177.301165819168, "_timestamp": 1585514255.7218955, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1668997323965868e-08, "Value Loss": 6.773413752624025e-13, "_runtime": 5178.841543674469, "_timestamp": 1585514257.2622733, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0582879212961416e-06, "Value Loss": 3.4637272217086235e-11, "_runtime": 5180.393325090408, "_timestamp": 1585514258.8140547, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1291355122011737e-06, "Value Loss": 3.7412187930963015e-11, "_runtime": 5181.944508552551, "_timestamp": 1585514260.3652382, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5183.494517803192, "_timestamp": 1585514261.9152474, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.340548383410578e-08, "Value Loss": 1.6023129817323983e-13, "_runtime": 5185.047089099884, "_timestamp": 1585514263.4678187, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2154519026807975e-06, "Value Loss": 7.069113350244294e-11, "_runtime": 5186.6311066150665, "_timestamp": 1585514265.0518363, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1468614502518903e-06, "Value Loss": 4.875947562377192e-11, "_runtime": 5188.1837503910065, "_timestamp": 1585514266.60448, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5189.725528717041, "_timestamp": 1585514268.1462584, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.30996550448981e-07, "Value Loss": 1.6569372826916173e-12, "_runtime": 5191.2736485004425, "_timestamp": 1585514269.6943781, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.087805329319963e-07, "Value Loss": 9.978039445038278e-13, "_runtime": 5192.834492683411, "_timestamp": 1585514271.2552223, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5194.381740808487, "_timestamp": 1585514272.8024704, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5195.94113612175, "_timestamp": 1585514274.3618658, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5197.489849567413, "_timestamp": 1585514275.9105792, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5199.048059940338, "_timestamp": 1585514277.4687896, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.927775638767343e-07, "Value Loss": 6.840784015638146e-12, "_runtime": 5200.607932090759, "_timestamp": 1585514279.0286617, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5202.157286643982, "_timestamp": 1585514280.5780163, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.702287115942454e-07, "Value Loss": 5.751211312743365e-11, "_runtime": 5203.704089164734, "_timestamp": 1585514282.1248188, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5205.263984203339, "_timestamp": 1585514283.6847138, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5206.814428806305, "_timestamp": 1585514285.2351584, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5208.373654603958, "_timestamp": 1585514286.7943842, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.99522581473866e-07, "Value Loss": 6.419266593976625e-12, "_runtime": 5209.970108747482, "_timestamp": 1585514288.3908384, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.3779112957054167e-07, "Value Loss": 1.7716483662055804e-12, "_runtime": 5211.531341791153, "_timestamp": 1585514289.9520714, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5213.100862503052, "_timestamp": 1585514291.5215921, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5214.669552087784, "_timestamp": 1585514293.0902817, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5216.231233596802, "_timestamp": 1585514294.6519632, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0172908559979987e-06, "Value Loss": 1.3476726679062523e-11, "_runtime": 5217.794951438904, "_timestamp": 1585514296.215681, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5219.3559947013855, "_timestamp": 1585514297.7767243, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2571911511827238e-08, "Value Loss": 6.700581387485138e-13, "_runtime": 5220.897633075714, "_timestamp": 1585514299.3183627, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5222.45005941391, "_timestamp": 1585514300.870789, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.142540895671118e-06, "Value Loss": 3.381426735837856e-11, "_runtime": 5224.000882863998, "_timestamp": 1585514302.4216125, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5225.56351685524, "_timestamp": 1585514303.9842465, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5227.115601539612, "_timestamp": 1585514305.5363312, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.421925710739742e-07, "Value Loss": 1.541498005630526e-11, "_runtime": 5228.679802417755, "_timestamp": 1585514307.100532, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5230.232672214508, "_timestamp": 1585514308.6534019, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4495263940261793e-06, "Value Loss": 5.6842051898708945e-11, "_runtime": 5231.79741024971, "_timestamp": 1585514310.21814, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5233.395110845566, "_timestamp": 1585514311.8158405, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5325119875342352e-06, "Value Loss": 8.293062070396928e-11, "_runtime": 5234.94593834877, "_timestamp": 1585514313.366668, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5236.492430448532, "_timestamp": 1585514314.91316, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2799787327821832e-06, "Value Loss": 8.939085582859718e-11, "_runtime": 5238.051736116409, "_timestamp": 1585514316.4724658, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.214427470586088e-06, "Value Loss": 5.341346809295544e-11, "_runtime": 5239.609512329102, "_timestamp": 1585514318.030242, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5241.168009519577, "_timestamp": 1585514319.5887392, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 5242.726016283035, "_timestamp": 1585514321.146746, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.348710250378645e-07, "Value Loss": 4.163282565916582e-11, "_runtime": 5244.288174390793, "_timestamp": 1585514322.708904, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.764443074454448e-08, "Value Loss": 5.899424828856303e-13, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477, -0.582077145576477]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [0.582077145576477, 2.0919442176818848, 3.601811408996582, 5.111678123474121, 6.621545314788818, 8.131412506103516, 9.641279220581055, 11.15114688873291, 12.66101360321045, 14.170880317687988, 15.680747985839844, 17.190614700317383, 18.700481414794922, 20.21034812927246, 21.720216751098633, 23.230083465576172, 24.73995018005371, 26.24981689453125, 27.75968360900879, 29.26955223083496, 30.7794189453125, 32.28928756713867, 33.79915237426758, 35.30902099609375, 36.818885803222656, 38.32875442504883, 39.838619232177734, 41.348487854003906, 42.85835647583008, 44.368221282958984, 45.878089904785156, 47.38795471191406, 48.897823333740234, 50.407691955566406, 51.91755676269531, 53.427425384521484, 54.93729019165039, 56.44715881347656, 57.957027435302734, 59.46689224243164, 60.97676086425781, 62.48662567138672, 63.99649429321289, 65.50636291503906, 67.01622772216797, 68.52609252929688, 70.03596496582031, 71.54582977294922, 73.05569458007812, 74.56556701660156, 76.07543182373047, 77.58529663085938, 79.09516143798828, 80.60503387451172, 82.11489868164062, 83.62476348876953, 85.13463592529297, 86.64450073242188, 88.15436553955078, 89.66423797607422, 91.17410278320312, 92.68396759033203, 94.19383239746094, 95.70370483398438, 97.21356964111328]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.6083515286445618, -0.5836168527603149, -0.5588822364807129, -0.5341475605964661, -0.5094128847122192, -0.4846782684326172, -0.45994359254837036, -0.4352089464664459, -0.4104743003845215, -0.38573965430259705, -0.3610050082206726, -0.3362703323364258, -0.31153568625450134, -0.2868010401725769, -0.2620663642883301, -0.23733171820640564, -0.2125970721244812, -0.18786242604255676, -0.16312777996063232, -0.1383931040763855, -0.11365845799446106, -0.08892381191253662, -0.0641891360282898, -0.039454519748687744, -0.014719843864440918, 0.010014832019805908, 0.03474944829940796, 0.059484124183654785, 0.08421880006790161, 0.10895341634750366, 0.1336880922317505, 0.15842270851135254, 0.18315738439559937, 0.2078920602798462, 0.23262667655944824, 0.25736135244369507, 0.2820959687232971, 0.30683064460754395, 0.33156532049179077, 0.3562999367713928, 0.38103461265563965, 0.4057692885398865, 0.4305039048194885, 0.4552385210990906, 0.4799732565879822, 0.5047078728675842, 0.5294424891471863, 0.5541772246360779, 0.5789118409156799, 0.603646457195282, 0.6283811926841736, 0.6531158089637756, 0.6778504252433777, 0.7025851607322693, 0.7273197770118713, 0.7520543932914734, 0.776789128780365, 0.801523745059967, 0.8262583613395691, 0.8509929776191711, 0.8757277131080627, 0.9004623293876648, 0.9251969456672668, 0.9499316811561584, 0.9746662974357605]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 18.0, 20.0, 371.0, 24.0, 4.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0], "bins": [-13.591436386108398, -13.246519088745117, -12.901601791381836, -12.556684494018555, -12.211767196655273, -11.866849899291992, -11.521932601928711, -11.17701530456543, -10.832098007202148, -10.487180709838867, -10.142263412475586, -9.797345161437988, -9.452427864074707, -9.107510566711426, -8.762593269348145, -8.417675971984863, -8.072758674621582, -7.727841377258301, -7.3829240798950195, -7.038006782531738, -6.693089485168457, -6.348171710968018, -6.003254413604736, -5.658337116241455, -5.313419342041016, -4.968502044677734, -4.623584747314453, -4.278667449951172, -3.9337501525878906, -3.5888328552246094, -3.243915557861328, -2.898998260498047, -2.5540809631347656, -2.2091636657714844, -1.8642463684082031, -1.5193290710449219, -1.1744117736816406, -0.8294944763183594, -0.4845771789550781, -0.13965988159179688, 0.20525741577148438, 0.550175666809082, 0.8950929641723633, 1.2400102615356445, 1.5849275588989258, 1.929844856262207, 2.2747621536254883, 2.619678497314453, 2.964597702026367, 3.3095149993896484, 3.6544322967529297, 3.999349594116211, 4.344266891479492, 4.689184188842773, 5.034101486206055, 5.379018783569336, 5.723936080932617, 6.068853378295898, 6.41377067565918, 6.758687973022461, 7.103605270385742, 7.448522567749023, 7.793439865112305, 8.138357162475586, 8.483274459838867]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.3486032485961914, -3.1359448432922363, -2.9232864379882812, -2.710628032684326, -2.497969388961792, -2.285310983657837, -2.072652578353882, -1.8599940538406372, -1.6473356485366821, -1.434677243232727, -1.2220187187194824, -1.0093603134155273, -0.7967019081115723, -0.5840435028076172, -0.371384859085083, -0.15872645378112793, 0.05393195152282715, 0.2665903568267822, 0.4792487621307373, 0.6919074058532715, 0.9045658111572266, 1.1172242164611816, 1.3298826217651367, 1.5425410270690918, 1.7551994323730469, 1.967857837677002, 2.180516242980957, 2.3931751251220703, 2.6058335304260254, 2.8184919357299805, 3.0311503410339355, 3.2438087463378906, 3.4564671516418457, 3.669125556945801, 3.881783962249756, 4.094442367553711, 4.307100772857666, 4.519759178161621, 4.732418060302734, 4.945075988769531, 5.1577348709106445, 5.370392799377441, 5.583051681518555, 5.795710563659668, 6.008368492126465, 6.221027374267578, 6.433685302734375, 6.646344184875488, 6.859002113342285, 7.071660995483398, 7.284318923950195, 7.496977806091309, 7.7096357345581055, 7.922294616699219, 8.134953498840332, 8.347611427307129, 8.560270309448242, 8.772928237915039, 8.985587120056152, 9.19824504852295, 9.410903930664062, 9.62356185913086, 9.836220741271973, 10.04887866973877, 10.261537551879883]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 6.0, 7.0, 7.0, 8.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.357376098632812, -11.032428741455078, -10.70748233795166, -10.382534980773926, -10.057588577270508, -9.732641220092773, -9.407694816589355, -9.082747459411621, -8.757801055908203, -8.432853698730469, -8.107906341552734, -7.782959938049316, -7.458012580871582, -7.133065700531006, -6.80811882019043, -6.4831719398498535, -6.158225059509277, -5.833278179168701, -5.508331298828125, -5.183384418487549, -4.858437538146973, -4.533490180969238, -4.208543300628662, -3.883596420288086, -3.5586495399475098, -3.2337026596069336, -2.908755302429199, -2.5838088989257812, -2.258861541748047, -1.933915138244629, -1.6089677810668945, -1.2840213775634766, -0.9590740203857422, -0.6341266632080078, -0.30918025970458984, 0.01576709747314453, 0.3407135009765625, 0.6656608581542969, 0.9906072616577148, 1.3155546188354492, 1.6405010223388672, 1.9654483795166016, 2.290395736694336, 2.615342140197754, 2.9402894973754883, 3.2652359008789062, 3.5901832580566406, 3.9151296615600586, 4.240077018737793, 4.565024375915527, 4.889970779418945, 5.21491813659668, 5.539865493774414, 5.864810943603516, 6.18975830078125, 6.514705657958984, 6.839653015136719, 7.164600372314453, 7.489545822143555, 7.814493179321289, 8.139440536499023, 8.464387893676758, 8.78933334350586, 9.114280700683594, 9.439228057861328]}, "_runtime": 5245.847583055496, "_timestamp": 1585514324.2683127, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3336043380718365e-08, "Value Loss": 5.462430638022986e-13, "_runtime": 5245.847583055496, "_timestamp": 1585514324.2683127, "_step": 499}
