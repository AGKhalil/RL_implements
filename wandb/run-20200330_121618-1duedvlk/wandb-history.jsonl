{"Episode reward": -74.67413716188199, "Episode length": 999, "Policy Loss": 0.026536203920841217, "Value Loss": 0.029297461733222008, "_runtime": 681.2150719165802, "_timestamp": 1585570597.0597053, "_step": 0}
{"Episode reward": -73.37863957612606, "Episode length": 999, "Policy Loss": -7.117588996887207, "Value Loss": 487.0035095214844, "_runtime": 682.6803431510925, "_timestamp": 1585570598.5249765, "_step": 1}
{"Episode reward": -72.2479741308969, "Episode length": 999, "Policy Loss": 1.6125792264938354, "Value Loss": 48.976985931396484, "_runtime": 684.23672747612, "_timestamp": 1585570600.0813608, "_step": 2}
{"Episode reward": -73.91176827098987, "Episode length": 999, "Policy Loss": -3.6991214752197266, "Value Loss": 286.2442321777344, "_runtime": 685.7514593601227, "_timestamp": 1585570601.5960927, "_step": 3}
{"Episode reward": -73.71464048145046, "Episode length": 999, "Policy Loss": -1.2335875034332275, "Value Loss": 27.74603271484375, "_runtime": 687.2504150867462, "_timestamp": 1585570603.0950484, "_step": 4}
{"Episode reward": -71.48644567033543, "Episode length": 999, "Policy Loss": 1.354954481124878, "Value Loss": 39.97621154785156, "_runtime": 688.7908630371094, "_timestamp": 1585570604.6354964, "_step": 5}
{"Episode reward": -72.08648899566951, "Episode length": 999, "Policy Loss": 2.3536055088043213, "Value Loss": 77.69039916992188, "_runtime": 690.325010061264, "_timestamp": 1585570606.1696434, "_step": 6}
{"Episode reward": -72.40557430162843, "Episode length": 999, "Policy Loss": 0.5534342527389526, "Value Loss": 8.242765426635742, "_runtime": 691.8295245170593, "_timestamp": 1585570607.6741579, "_step": 7}
{"Episode reward": -74.3044135457568, "Episode length": 999, "Policy Loss": -0.11226680874824524, "Value Loss": 0.6236122846603394, "_runtime": 693.3756897449493, "_timestamp": 1585570609.220323, "_step": 8}
{"Episode reward": -73.07525916180872, "Episode length": 999, "Policy Loss": -0.8758394122123718, "Value Loss": 12.41053295135498, "_runtime": 694.9094951152802, "_timestamp": 1585570610.7541285, "_step": 9}
{"Episode reward": -73.07705882625643, "Episode length": 999, "Policy Loss": -0.5887596607208252, "Value Loss": 9.379820823669434, "_runtime": 696.4430832862854, "_timestamp": 1585570612.2877166, "_step": 10}
{"Episode reward": -72.79453942060513, "Episode length": 999, "Policy Loss": -0.2645987570285797, "Value Loss": 1.0601240396499634, "_runtime": 697.9811084270477, "_timestamp": 1585570613.8257418, "_step": 11}
{"Episode reward": -70.88662784140355, "Episode length": 999, "Policy Loss": 0.16224421560764313, "Value Loss": 1.0271364450454712, "_runtime": 699.513671875, "_timestamp": 1585570615.3583052, "_step": 12}
{"Episode reward": -72.5909532233732, "Episode length": 999, "Policy Loss": 0.6318802237510681, "Value Loss": 5.900586128234863, "_runtime": 701.055632352829, "_timestamp": 1585570616.9002657, "_step": 13}
{"Episode reward": -72.52849754193113, "Episode length": 999, "Policy Loss": 0.5992377996444702, "Value Loss": 6.935052394866943, "_runtime": 702.5965394973755, "_timestamp": 1585570618.4411728, "_step": 14}
{"Episode reward": -71.15163505466094, "Episode length": 999, "Policy Loss": 0.44199272990226746, "Value Loss": 4.527595520019531, "_runtime": 704.1343321800232, "_timestamp": 1585570619.9789655, "_step": 15}
{"Episode reward": -73.56089350603952, "Episode length": 999, "Policy Loss": 0.077446848154068, "Value Loss": 0.695315957069397, "_runtime": 705.7141087055206, "_timestamp": 1585570621.558742, "_step": 16}
{"Episode reward": -71.16919035985009, "Episode length": 999, "Policy Loss": -0.25988689064979553, "Value Loss": 0.8145456910133362, "_runtime": 707.2668268680573, "_timestamp": 1585570623.1114602, "_step": 17}
{"Episode reward": -73.08702722935692, "Episode length": 999, "Policy Loss": -0.39585232734680176, "Value Loss": 1.982676386833191, "_runtime": 708.8075032234192, "_timestamp": 1585570624.6521366, "_step": 18}
{"Episode reward": -71.76315706014867, "Episode length": 999, "Policy Loss": 0.7095308899879456, "Value Loss": 25.308250427246094, "_runtime": 710.3365950584412, "_timestamp": 1585570626.1812284, "_step": 19}
{"Episode reward": -73.56120761219721, "Episode length": 999, "Policy Loss": -0.6890705823898315, "Value Loss": 5.84246826171875, "_runtime": 711.8813192844391, "_timestamp": 1585570627.7259526, "_step": 20}
{"Episode reward": -76.29444355953602, "Episode length": 999, "Policy Loss": -0.10898420214653015, "Value Loss": 0.8988253474235535, "_runtime": 713.4137756824493, "_timestamp": 1585570629.258409, "_step": 21}
{"Episode reward": -71.27706969216226, "Episode length": 999, "Policy Loss": -0.1970711201429367, "Value Loss": 0.7256742119789124, "_runtime": 714.9624855518341, "_timestamp": 1585570630.807119, "_step": 22}
{"Episode reward": -73.09170772033211, "Episode length": 999, "Policy Loss": -0.020709970965981483, "Value Loss": 0.053797513246536255, "_runtime": 716.506911277771, "_timestamp": 1585570632.3515446, "_step": 23}
{"Episode reward": -72.73320871389276, "Episode length": 999, "Policy Loss": 0.0401415154337883, "Value Loss": 0.12529553472995758, "_runtime": 718.0591883659363, "_timestamp": 1585570633.9038217, "_step": 24}
{"Episode reward": -72.76861193910683, "Episode length": 999, "Policy Loss": 0.09512319415807724, "Value Loss": 0.30614933371543884, "_runtime": 719.6060259342194, "_timestamp": 1585570635.4506593, "_step": 25}
{"Episode reward": -73.41073818020077, "Episode length": 999, "Policy Loss": 0.1377587765455246, "Value Loss": 0.32919174432754517, "_runtime": 721.147632598877, "_timestamp": 1585570636.992266, "_step": 26}
{"Episode reward": -71.07338678711821, "Episode length": 999, "Policy Loss": 0.13925574719905853, "Value Loss": 0.3361259400844574, "_runtime": 722.6982653141022, "_timestamp": 1585570638.5428987, "_step": 27}
{"Episode reward": -70.33501120444333, "Episode length": 999, "Policy Loss": 0.07732702046632767, "Value Loss": 0.22141514718532562, "_runtime": 724.2484309673309, "_timestamp": 1585570640.0930643, "_step": 28}
{"Episode reward": -73.04476687804834, "Episode length": 999, "Policy Loss": 0.08861682564020157, "Value Loss": 0.22751981019973755, "_runtime": 725.7891392707825, "_timestamp": 1585570641.6337726, "_step": 29}
{"Episode reward": -72.41997713688905, "Episode length": 999, "Policy Loss": -0.11954085528850555, "Value Loss": 0.3541679084300995, "_runtime": 727.3271214962006, "_timestamp": 1585570643.1717548, "_step": 30}
{"Episode reward": -72.99784176498551, "Episode length": 999, "Policy Loss": -0.16944195330142975, "Value Loss": 0.6022921204566956, "_runtime": 728.8918390274048, "_timestamp": 1585570644.7364724, "_step": 31}
{"Episode reward": -72.5252544948272, "Episode length": 999, "Policy Loss": -0.07941972464323044, "Value Loss": 0.25484657287597656, "_runtime": 730.4340267181396, "_timestamp": 1585570646.27866, "_step": 32}
{"Episode reward": -74.86594678408032, "Episode length": 999, "Policy Loss": -0.18585941195487976, "Value Loss": 0.6638971567153931, "_runtime": 731.976155757904, "_timestamp": 1585570647.820789, "_step": 33}
{"Episode reward": -72.03352473814002, "Episode length": 999, "Policy Loss": -0.12780660390853882, "Value Loss": 0.37884148955345154, "_runtime": 733.5150344371796, "_timestamp": 1585570649.3596678, "_step": 34}
{"Episode reward": -73.85889454565883, "Episode length": 999, "Policy Loss": -0.09596075862646103, "Value Loss": 0.20882155001163483, "_runtime": 735.0584232807159, "_timestamp": 1585570650.9030566, "_step": 35}
{"Episode reward": -71.45995697891934, "Episode length": 999, "Policy Loss": -0.025921698659658432, "Value Loss": 0.1126067265868187, "_runtime": 736.6103205680847, "_timestamp": 1585570652.454954, "_step": 36}
{"Episode reward": -72.27708032392323, "Episode length": 999, "Policy Loss": -0.05568363144993782, "Value Loss": 0.12762092053890228, "_runtime": 738.1604256629944, "_timestamp": 1585570654.005059, "_step": 37}
{"Episode reward": -72.4614406636025, "Episode length": 999, "Policy Loss": 0.05923289805650711, "Value Loss": 0.06532991677522659, "_runtime": 739.7157573699951, "_timestamp": 1585570655.5603907, "_step": 38}
{"Episode reward": -72.43660363490613, "Episode length": 999, "Policy Loss": 0.08317160606384277, "Value Loss": 0.11112207919359207, "_runtime": 741.2659306526184, "_timestamp": 1585570657.110564, "_step": 39}
{"Episode reward": -73.19929457580028, "Episode length": 999, "Policy Loss": 0.06903888285160065, "Value Loss": 0.12352127581834793, "_runtime": 742.8153066635132, "_timestamp": 1585570658.65994, "_step": 40}
{"Episode reward": -72.4173878628948, "Episode length": 999, "Policy Loss": 0.10156071186065674, "Value Loss": 0.13634753227233887, "_runtime": 744.3679895401001, "_timestamp": 1585570660.212623, "_step": 41}
{"Episode reward": -73.33827405569444, "Episode length": 999, "Policy Loss": 0.13095812499523163, "Value Loss": 0.18014773726463318, "_runtime": 745.9224078655243, "_timestamp": 1585570661.7670412, "_step": 42}
{"Episode reward": -73.73464776939485, "Episode length": 999, "Policy Loss": 0.07825705409049988, "Value Loss": 0.13543590903282166, "_runtime": 747.4712133407593, "_timestamp": 1585570663.3158467, "_step": 43}
{"Episode reward": -73.35637020073786, "Episode length": 999, "Policy Loss": 0.08526013046503067, "Value Loss": 0.13242000341415405, "_runtime": 749.0221014022827, "_timestamp": 1585570664.8667347, "_step": 44}
{"Episode reward": -72.85091624297021, "Episode length": 999, "Policy Loss": 0.06802400201559067, "Value Loss": 0.06540874391794205, "_runtime": 750.5717718601227, "_timestamp": 1585570666.4164052, "_step": 45}
{"Episode reward": -74.0487903882895, "Episode length": 999, "Policy Loss": 0.026285633444786072, "Value Loss": 0.011561800725758076, "_runtime": 752.156779050827, "_timestamp": 1585570668.0014124, "_step": 46}
{"Episode reward": -70.58846409218619, "Episode length": 999, "Policy Loss": -0.0033990261144936085, "Value Loss": 0.03458123654127121, "_runtime": 753.687492609024, "_timestamp": 1585570669.532126, "_step": 47}
{"Episode reward": -69.80875399284434, "Episode length": 999, "Policy Loss": -0.02596908248960972, "Value Loss": 0.023809386417269707, "_runtime": 755.2409520149231, "_timestamp": 1585570671.0855854, "_step": 48}
{"Episode reward": -70.44522905933982, "Episode length": 999, "Policy Loss": -0.030602548271417618, "Value Loss": 0.05168286710977554, "_runtime": 756.7903401851654, "_timestamp": 1585570672.6349735, "_step": 49}
{"Episode reward": -72.80758521361514, "Episode length": 999, "Policy Loss": -0.06435149163007736, "Value Loss": 0.0742214098572731, "_runtime": 758.3433926105499, "_timestamp": 1585570674.188026, "_step": 50}
{"Episode reward": -70.94390560866017, "Episode length": 999, "Policy Loss": -0.06622083485126495, "Value Loss": 0.06942100822925568, "_runtime": 759.8912267684937, "_timestamp": 1585570675.73586, "_step": 51}
{"Episode reward": -72.61991621597272, "Episode length": 999, "Policy Loss": -0.06201132759451866, "Value Loss": 0.05403587967157364, "_runtime": 761.4252948760986, "_timestamp": 1585570677.2699282, "_step": 52}
{"Episode reward": -72.03920433415098, "Episode length": 999, "Policy Loss": -0.04579831287264824, "Value Loss": 0.037450969219207764, "_runtime": 762.9728722572327, "_timestamp": 1585570678.8175056, "_step": 53}
{"Episode reward": -70.07289379646922, "Episode length": 999, "Policy Loss": 0.0011910698376595974, "Value Loss": 0.02989954873919487, "_runtime": 764.5190529823303, "_timestamp": 1585570680.3636863, "_step": 54}
{"Episode reward": -73.42090110302766, "Episode length": 999, "Policy Loss": -0.007130000274628401, "Value Loss": 0.009379561990499496, "_runtime": 766.0524215698242, "_timestamp": 1585570681.897055, "_step": 55}
{"Episode reward": -72.18241272251284, "Episode length": 999, "Policy Loss": 0.021477723494172096, "Value Loss": 0.023126376792788506, "_runtime": 767.597715139389, "_timestamp": 1585570683.4423485, "_step": 56}
{"Episode reward": -72.19502887573674, "Episode length": 999, "Policy Loss": 0.02649054117500782, "Value Loss": 0.01901663839817047, "_runtime": 769.1470060348511, "_timestamp": 1585570684.9916394, "_step": 57}
{"Episode reward": -71.91480049150367, "Episode length": 999, "Policy Loss": 0.032436273992061615, "Value Loss": 0.032510947436094284, "_runtime": 770.6733748912811, "_timestamp": 1585570686.5180082, "_step": 58}
{"Episode reward": -73.97073650862946, "Episode length": 999, "Policy Loss": 0.03711561858654022, "Value Loss": 0.0291744451969862, "_runtime": 772.225209236145, "_timestamp": 1585570688.0698426, "_step": 59}
{"Episode reward": -70.01359217689661, "Episode length": 999, "Policy Loss": 0.04039307311177254, "Value Loss": 0.029557261615991592, "_runtime": 773.7781810760498, "_timestamp": 1585570689.6228144, "_step": 60}
{"Episode reward": -70.49826596722112, "Episode length": 999, "Policy Loss": 0.029904680326581, "Value Loss": 0.0210658498108387, "_runtime": 775.3512735366821, "_timestamp": 1585570691.1959069, "_step": 61}
{"Episode reward": -74.29459142325514, "Episode length": 999, "Policy Loss": 0.01819244585931301, "Value Loss": 0.008496832102537155, "_runtime": 776.8950371742249, "_timestamp": 1585570692.7396705, "_step": 62}
{"Episode reward": -73.23565283599085, "Episode length": 999, "Policy Loss": -0.0030302531085908413, "Value Loss": 0.005587269086390734, "_runtime": 778.4446499347687, "_timestamp": 1585570694.2892833, "_step": 63}
{"Episode reward": -73.63961631176966, "Episode length": 999, "Policy Loss": -0.008716383017599583, "Value Loss": 0.005104123614728451, "_runtime": 779.9952311515808, "_timestamp": 1585570695.8398645, "_step": 64}
{"Episode reward": -73.44803169576855, "Episode length": 999, "Policy Loss": -0.006752047687768936, "Value Loss": 0.008526650257408619, "_runtime": 781.5467655658722, "_timestamp": 1585570697.391399, "_step": 65}
{"Episode reward": -74.13606602475002, "Episode length": 999, "Policy Loss": -0.0066165742464363575, "Value Loss": 0.009975416585803032, "_runtime": 783.1013877391815, "_timestamp": 1585570698.946021, "_step": 66}
{"Episode reward": -72.95936371656325, "Episode length": 999, "Policy Loss": -0.02905072271823883, "Value Loss": 0.017270900309085846, "_runtime": 784.6528587341309, "_timestamp": 1585570700.497492, "_step": 67}
{"Episode reward": -71.69410405871893, "Episode length": 999, "Policy Loss": -0.005342425778508186, "Value Loss": 0.012265762314200401, "_runtime": 786.2051522731781, "_timestamp": 1585570702.0497856, "_step": 68}
{"Episode reward": -72.57398608469072, "Episode length": 999, "Policy Loss": -0.0146151352673769, "Value Loss": 0.011635329574346542, "_runtime": 787.7481410503387, "_timestamp": 1585570703.5927744, "_step": 69}
{"Episode reward": -72.25566054302098, "Episode length": 999, "Policy Loss": -0.011256969533860683, "Value Loss": 0.007734626531600952, "_runtime": 789.2882030010223, "_timestamp": 1585570705.1328363, "_step": 70}
{"Episode reward": -73.6500149401901, "Episode length": 999, "Policy Loss": -0.002358843572437763, "Value Loss": 0.006193798501044512, "_runtime": 790.8419213294983, "_timestamp": 1585570706.6865547, "_step": 71}
{"Episode reward": -69.15696078696641, "Episode length": 999, "Policy Loss": -0.011517384089529514, "Value Loss": 0.006307312287390232, "_runtime": 792.394407749176, "_timestamp": 1585570708.239041, "_step": 72}
{"Episode reward": -71.73294274678537, "Episode length": 999, "Policy Loss": -0.0029593019280582666, "Value Loss": 0.0038849404081702232, "_runtime": 793.9464831352234, "_timestamp": 1585570709.7911165, "_step": 73}
{"Episode reward": -72.76986530505968, "Episode length": 999, "Policy Loss": -0.006542953196913004, "Value Loss": 0.003939111717045307, "_runtime": 795.5022785663605, "_timestamp": 1585570711.346912, "_step": 74}
{"Episode reward": -71.80110109584747, "Episode length": 999, "Policy Loss": 0.012091394513845444, "Value Loss": 0.006139548495411873, "_runtime": 797.0889112949371, "_timestamp": 1585570712.9335446, "_step": 75}
{"Episode reward": -70.10121111609982, "Episode length": 999, "Policy Loss": 0.0120927719399333, "Value Loss": 0.0063927494920790195, "_runtime": 798.616569519043, "_timestamp": 1585570714.4612029, "_step": 76}
{"Episode reward": -73.49017046445996, "Episode length": 999, "Policy Loss": 0.0024850955232977867, "Value Loss": 0.003859568852931261, "_runtime": 800.1698813438416, "_timestamp": 1585570716.0145147, "_step": 77}
{"Episode reward": -72.1108383179826, "Episode length": 999, "Policy Loss": 0.008112228475511074, "Value Loss": 0.004677042365074158, "_runtime": 801.7201001644135, "_timestamp": 1585570717.5647335, "_step": 78}
{"Episode reward": -71.96006046711722, "Episode length": 999, "Policy Loss": 0.027780141681432724, "Value Loss": 0.012949098832905293, "_runtime": 803.2850029468536, "_timestamp": 1585570719.1296363, "_step": 79}
{"Episode reward": -70.0988530977977, "Episode length": 999, "Policy Loss": 0.014954541809856892, "Value Loss": 0.005858035292476416, "_runtime": 804.8239216804504, "_timestamp": 1585570720.668555, "_step": 80}
{"Episode reward": -70.93211034826112, "Episode length": 999, "Policy Loss": 0.017963606864213943, "Value Loss": 0.007554159499704838, "_runtime": 806.3752629756927, "_timestamp": 1585570722.2198963, "_step": 81}
{"Episode reward": -73.04598364625211, "Episode length": 999, "Policy Loss": 0.01313568465411663, "Value Loss": 0.00904986634850502, "_runtime": 807.9236595630646, "_timestamp": 1585570723.768293, "_step": 82}
{"Episode reward": -73.23753653639689, "Episode length": 999, "Policy Loss": 0.0028649591840803623, "Value Loss": 0.0036140684969723225, "_runtime": 809.4766571521759, "_timestamp": 1585570725.3212905, "_step": 83}
{"Episode reward": -74.7147084013649, "Episode length": 999, "Policy Loss": -0.00414428673684597, "Value Loss": 0.00416654534637928, "_runtime": 811.0283238887787, "_timestamp": 1585570726.8729572, "_step": 84}
{"Episode reward": -70.88687682023117, "Episode length": 999, "Policy Loss": -0.0009678896167315543, "Value Loss": 0.006022333633154631, "_runtime": 812.5781137943268, "_timestamp": 1585570728.4227471, "_step": 85}
{"Episode reward": -72.9768709428606, "Episode length": 999, "Policy Loss": -0.02632462978363037, "Value Loss": 0.010998114012181759, "_runtime": 814.1279289722443, "_timestamp": 1585570729.9725623, "_step": 86}
{"Episode reward": -73.16668576702006, "Episode length": 999, "Policy Loss": -0.025770800188183784, "Value Loss": 0.011465596966445446, "_runtime": 815.6713109016418, "_timestamp": 1585570731.5159442, "_step": 87}
{"Episode reward": -73.52179114630363, "Episode length": 999, "Policy Loss": -0.011757353320717812, "Value Loss": 0.006499665789306164, "_runtime": 817.2221281528473, "_timestamp": 1585570733.0667615, "_step": 88}
{"Episode reward": -71.68601501475347, "Episode length": 999, "Policy Loss": 0.008652285672724247, "Value Loss": 0.005201994441449642, "_runtime": 818.7748816013336, "_timestamp": 1585570734.619515, "_step": 89}
{"Episode reward": -70.71327056417783, "Episode length": 999, "Policy Loss": -0.01703004166483879, "Value Loss": 0.006941924337297678, "_runtime": 820.3532047271729, "_timestamp": 1585570736.197838, "_step": 90}
{"Episode reward": -70.88492887720213, "Episode length": 999, "Policy Loss": -0.012582190334796906, "Value Loss": 0.005098899360746145, "_runtime": 821.9041428565979, "_timestamp": 1585570737.7487762, "_step": 91}
{"Episode reward": -73.65336094254492, "Episode length": 999, "Policy Loss": -0.01032174564898014, "Value Loss": 0.004010825417935848, "_runtime": 823.456437587738, "_timestamp": 1585570739.301071, "_step": 92}
{"Episode reward": -73.31761318935492, "Episode length": 999, "Policy Loss": -0.004385760985314846, "Value Loss": 0.002681650687009096, "_runtime": 824.9998123645782, "_timestamp": 1585570740.8444457, "_step": 93}
{"Episode reward": -73.93724509421155, "Episode length": 999, "Policy Loss": 0.0038886466063559055, "Value Loss": 0.0031958448234945536, "_runtime": 826.5477643013, "_timestamp": 1585570742.3923976, "_step": 94}
{"Episode reward": -71.40197607172385, "Episode length": 999, "Policy Loss": 0.01285548321902752, "Value Loss": 0.004616778809577227, "_runtime": 828.1005597114563, "_timestamp": 1585570743.945193, "_step": 95}
{"Episode reward": -71.6059938488601, "Episode length": 999, "Policy Loss": 0.02277800813317299, "Value Loss": 0.007847233675420284, "_runtime": 829.6509826183319, "_timestamp": 1585570745.495616, "_step": 96}
{"Episode reward": -73.10771953184215, "Episode length": 999, "Policy Loss": 0.022359926253557205, "Value Loss": 0.008691183291375637, "_runtime": 831.2196395397186, "_timestamp": 1585570747.0642729, "_step": 97}
{"Episode reward": -74.06052088794335, "Episode length": 999, "Policy Loss": 0.018874935805797577, "Value Loss": 0.00818509329110384, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583, 1.7481614351272583]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7545751929283142, -0.7113493084907532, -0.6681234240531921, -0.6248975992202759, -0.5816717147827148, -0.5384458303451538, -0.4952199459075928, -0.4519940912723541, -0.4087682068347931, -0.36554232239723206, -0.3223164677619934, -0.2790905833244324, -0.23586469888687134, -0.1926388144493103, -0.14941298961639404, -0.10618710517883301, -0.06296122074127197, -0.019735336303710938, 0.023490548133850098, 0.06671637296676636, 0.10994225740432739, 0.15316814184188843, 0.19639402627944946, 0.2396199107170105, 0.28284579515457153, 0.32607167959213257, 0.3692975640296936, 0.4125233292579651, 0.4557492136955261, 0.49897509813308716, 0.5422009825706482, 0.5854268670082092, 0.6286527514457703, 0.6718786358833313, 0.7151045203208923, 0.7583304047584534, 0.8015562891960144, 0.8447821736335754, 0.8880079388618469, 0.931233823299408, 0.974459707736969, 1.0176856517791748, 1.0609114170074463, 1.1041374206542969, 1.1473631858825684, 1.190589189529419, 1.2338149547576904, 1.277040719985962, 1.3202667236328125, 1.363492488861084, 1.4067184925079346, 1.449944257736206, 1.4931702613830566, 1.5363960266113281, 1.5796217918395996, 1.6228477954864502, 1.6660735607147217, 1.7092995643615723, 1.7525253295898438, 1.7957513332366943, 1.8389770984649658, 1.8822031021118164, 1.925428867340088, 1.9686548709869385, 2.01188063621521]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.4711264371871948, -1.432492971420288, -1.393859624862671, -1.3552261590957642, -1.3165926933288574, -1.2779592275619507, -1.239325761795044, -1.2006924152374268, -1.16205894947052, -1.1234254837036133, -1.084792137145996, -1.0461586713790894, -1.0075252056121826, -0.9688917398452759, -0.9302583336830139, -0.891624927520752, -0.8529914617538452, -0.8143579959869385, -0.7757245898246765, -0.7370911836624146, -0.6984577178955078, -0.6598242521286011, -0.6211908459663391, -0.5825574398040771, -0.5439239740371704, -0.5052905082702637, -0.46665704250335693, -0.42802369594573975, -0.389390230178833, -0.35075676441192627, -0.3121234178543091, -0.27348995208740234, -0.2348564863204956, -0.19622302055358887, -0.15758955478668213, -0.11895620822906494, -0.0803227424621582, -0.041689276695251465, -0.0030559301376342773, 0.03557753562927246, 0.0742110013961792, 0.11284446716308594, 0.15147793292999268, 0.19011127948760986, 0.2287447452545166, 0.26737821102142334, 0.3060115575790405, 0.34464502334594727, 0.383278489112854, 0.42191195487976074, 0.4605454206466675, 0.49917876720428467, 0.537812352180481, 0.5764456987380981, 0.6150790452957153, 0.6537126302719116, 0.6923459768295288, 0.730979323387146, 0.7696129083633423, 0.8082462549209595, 0.8468796014785767, 0.885513186454773, 0.9241465330123901, 0.9627801179885864, 1.0014134645462036]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 5.0, 0.0, 5.0, 4.0, 3.0, 5.0, 2.0, 5.0, 2.0, 5.0, 8.0, 15.0, 14.0, 20.0, 13.0, 24.0, 20.0, 17.0, 24.0, 40.0, 48.0, 19.0, 27.0, 19.0, 19.0, 12.0, 15.0, 9.0, 5.0, 8.0, 12.0, 12.0, 6.0, 6.0, 6.0, 5.0, 4.0, 3.0, 4.0, 6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-1.0566102266311646, -1.0273668766021729, -0.9981236457824707, -0.968880295753479, -0.9396370053291321, -0.9103937149047852, -0.8811504244804382, -0.8519071340560913, -0.8226638436317444, -0.7934205532073975, -0.7641772031784058, -0.7349339723587036, -0.7056906223297119, -0.676447331905365, -0.6472040414810181, -0.6179606914520264, -0.5887174606323242, -0.5594741106033325, -0.5302308201789856, -0.5009875297546387, -0.47174423933029175, -0.4425009489059448, -0.4132576584815979, -0.3840143084526062, -0.3547710180282593, -0.32552772760391235, -0.29628443717956543, -0.2670411467552185, -0.23779785633087158, -0.20855450630187988, -0.17931121587753296, -0.15006792545318604, -0.12082463502883911, -0.09158134460449219, -0.062338054180145264, -0.03309476375579834, -0.0038514137268066406, 0.025391817092895508, 0.05463516712188721, 0.0838785171508789, 0.11312174797058105, 0.14236509799957275, 0.1716083288192749, 0.2008516788482666, 0.23009490966796875, 0.25933825969696045, 0.28858160972595215, 0.3178248405456543, 0.347068190574646, 0.37631142139434814, 0.40555477142333984, 0.434798002243042, 0.4640413522720337, 0.4932847023010254, 0.5225279331207275, 0.5517712831497192, 0.5810145139694214, 0.6102578639984131, 0.6395012140274048, 0.6687444448471069, 0.6979877948760986, 0.7272310256958008, 0.7564743757247925, 0.7857176065444946, 0.8149609565734863]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0], "bins": [-1.0859673023223877, -1.057579517364502, -1.0291917324066162, -1.0008039474487305, -0.9724161624908447, -0.944028377532959, -0.9156405925750732, -0.8872528672218323, -0.8588650822639465, -0.8304772973060608, -0.802089512348175, -0.7737017273902893, -0.7453139424324036, -0.7169261574745178, -0.6885384321212769, -0.6601506471633911, -0.6317628622055054, -0.6033750772476196, -0.5749872922897339, -0.5465995073318481, -0.5182117223739624, -0.48982393741607666, -0.4614361524581909, -0.4330483675003052, -0.40466058254241943, -0.3762727975845337, -0.34788501262664795, -0.319497287273407, -0.29110950231552124, -0.2627217173576355, -0.23433393239974976, -0.205946147441864, -0.17755836248397827, -0.14917057752609253, -0.12078279256820679, -0.09239500761032104, -0.06400728225708008, -0.035619497299194336, -0.007231712341308594, 0.02115607261657715, 0.04954385757446289, 0.07793164253234863, 0.10631942749023438, 0.13470721244812012, 0.16309499740600586, 0.1914827823638916, 0.21987056732177734, 0.24825835227966309, 0.27664613723754883, 0.30503392219543457, 0.3334217071533203, 0.36180949211120605, 0.3901972770690918, 0.41858506202697754, 0.44697272777557373, 0.4753605127334595, 0.5037482976913452, 0.532136082649231, 0.5605238676071167, 0.5889116525650024, 0.6172994375228882, 0.6456872224807739, 0.6740750074386597, 0.7024627923965454, 0.7308505773544312]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 6.0, 1.0, 4.0, 1.0, 0.0, 4.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0194231271743774, -0.986783504486084, -0.9541438817977905, -0.9215042591094971, -0.8888646364212036, -0.8562250137329102, -0.8235853314399719, -0.7909457087516785, -0.758306086063385, -0.7256664633750916, -0.6930268406867981, -0.6603871583938599, -0.6277475357055664, -0.595107913017273, -0.5624682903289795, -0.529828667640686, -0.4971890449523926, -0.4645494222640991, -0.43190979957580566, -0.3992701768875122, -0.36663055419921875, -0.3339908719062805, -0.30135124921798706, -0.2687116265296936, -0.23607200384140015, -0.2034323811531067, -0.17079275846481323, -0.13815313577651978, -0.10551345348358154, -0.07287383079528809, -0.04023420810699463, -0.007594585418701172, 0.025045037269592285, 0.05768465995788574, 0.0903242826461792, 0.12296390533447266, 0.1556035280227661, 0.18824315071105957, 0.22088277339935303, 0.2535223960876465, 0.28616201877593994, 0.31880176067352295, 0.3514413833618164, 0.38408100605010986, 0.4167206287384033, 0.4493602514266968, 0.48199987411499023, 0.5146394968032837, 0.5472791194915771, 0.5799187421798706, 0.6125583648681641, 0.6451979875564575, 0.677837610244751, 0.7104772329330444, 0.7431168556213379, 0.7757564783096313, 0.8083962202072144, 0.8410358428955078, 0.8736754655838013, 0.9063150882720947, 0.9389547109603882, 0.9715943336486816, 1.004233956336975, 1.036873459815979, 1.069513201713562]}, "_runtime": 832.7744228839874, "_timestamp": 1585570748.6190562, "_step": 98}
{"Episode reward": -72.96908401211573, "Episode length": 999, "Policy Loss": 0.0007834287825971842, "Value Loss": 0.002032334916293621, "_runtime": 834.3390529155731, "_timestamp": 1585570750.1836863, "_step": 99}
{"Episode reward": -70.75193487592554, "Episode length": 999, "Policy Loss": 0.004602988250553608, "Value Loss": 0.0021083070896565914, "_runtime": 835.8904640674591, "_timestamp": 1585570751.7350974, "_step": 100}
{"Episode reward": -70.51410343138818, "Episode length": 999, "Policy Loss": 0.011992577463388443, "Value Loss": 0.005483585875481367, "_runtime": 837.4549586772919, "_timestamp": 1585570753.299592, "_step": 101}
{"Episode reward": -70.36317581608297, "Episode length": 999, "Policy Loss": 0.0029556157533079386, "Value Loss": 0.0029585626907646656, "_runtime": 839.0222940444946, "_timestamp": 1585570754.8669274, "_step": 102}
{"Episode reward": -70.67511223656892, "Episode length": 999, "Policy Loss": -0.011858327314257622, "Value Loss": 0.004800815600901842, "_runtime": 840.5846588611603, "_timestamp": 1585570756.4292922, "_step": 103}
{"Episode reward": -73.81472434966506, "Episode length": 999, "Policy Loss": -0.011056732386350632, "Value Loss": 0.007422797381877899, "_runtime": 842.149484872818, "_timestamp": 1585570757.9941182, "_step": 104}
{"Episode reward": -72.90258498244091, "Episode length": 999, "Policy Loss": -0.012394948862493038, "Value Loss": 0.005023720674216747, "_runtime": 843.7244732379913, "_timestamp": 1585570759.5691066, "_step": 105}
{"Episode reward": -73.27018248183342, "Episode length": 999, "Policy Loss": -0.008450577966868877, "Value Loss": 0.0037629646249115467, "_runtime": 845.2839403152466, "_timestamp": 1585570761.1285737, "_step": 106}
{"Episode reward": -73.38711101518702, "Episode length": 999, "Policy Loss": -0.005449988879263401, "Value Loss": 0.0027128937654197216, "_runtime": 846.8318800926208, "_timestamp": 1585570762.6765134, "_step": 107}
{"Episode reward": -71.44975852395828, "Episode length": 999, "Policy Loss": -0.006177891045808792, "Value Loss": 0.0023208598140627146, "_runtime": 848.3843469619751, "_timestamp": 1585570764.2289803, "_step": 108}
{"Episode reward": -71.34037932038297, "Episode length": 999, "Policy Loss": -0.0005618222057819366, "Value Loss": 0.0018032464431598783, "_runtime": 849.936517238617, "_timestamp": 1585570765.7811506, "_step": 109}
{"Episode reward": -70.65053568326408, "Episode length": 999, "Policy Loss": 0.008366229012608528, "Value Loss": 0.002812479855492711, "_runtime": 851.4844348430634, "_timestamp": 1585570767.3290682, "_step": 110}
{"Episode reward": -70.2147817347375, "Episode length": 999, "Policy Loss": 0.0022745775058865547, "Value Loss": 0.0021826138254255056, "_runtime": 853.0225722789764, "_timestamp": 1585570768.8672056, "_step": 111}
{"Episode reward": -73.01697911624056, "Episode length": 999, "Policy Loss": 0.01057586818933487, "Value Loss": 0.00290462514385581, "_runtime": 854.5721378326416, "_timestamp": 1585570770.4167712, "_step": 112}
{"Episode reward": -72.34591401441102, "Episode length": 999, "Policy Loss": 0.014565471559762955, "Value Loss": 0.005102891009300947, "_runtime": 856.1190247535706, "_timestamp": 1585570771.963658, "_step": 113}
{"Episode reward": -71.62014108918069, "Episode length": 999, "Policy Loss": 0.013678078539669514, "Value Loss": 0.005715155508369207, "_runtime": 857.6674537658691, "_timestamp": 1585570773.512087, "_step": 114}
{"Episode reward": -71.95622158982331, "Episode length": 999, "Policy Loss": 0.010392478667199612, "Value Loss": 0.003722218796610832, "_runtime": 859.2154114246368, "_timestamp": 1585570775.0600448, "_step": 115}
{"Episode reward": -73.4888957265322, "Episode length": 999, "Policy Loss": -0.0035584524739533663, "Value Loss": 0.0017140014097094536, "_runtime": 860.7541086673737, "_timestamp": 1585570776.598742, "_step": 116}
{"Episode reward": -72.15489036233404, "Episode length": 999, "Policy Loss": -0.006824810057878494, "Value Loss": 0.0024713650345802307, "_runtime": 862.3035442829132, "_timestamp": 1585570778.1481776, "_step": 117}
{"Episode reward": -71.72964225314635, "Episode length": 999, "Policy Loss": 0.004477555863559246, "Value Loss": 0.0027410557959228754, "_runtime": 863.8542227745056, "_timestamp": 1585570779.698856, "_step": 118}
{"Episode reward": -71.28836836754977, "Episode length": 999, "Policy Loss": 0.005789558403193951, "Value Loss": 0.003450161311775446, "_runtime": 865.3945713043213, "_timestamp": 1585570781.2392046, "_step": 119}
{"Episode reward": -70.9816255033968, "Episode length": 999, "Policy Loss": -0.0068715400993824005, "Value Loss": 0.0023030578158795834, "_runtime": 866.9779403209686, "_timestamp": 1585570782.8225737, "_step": 120}
{"Episode reward": -71.63692917485616, "Episode length": 999, "Policy Loss": -0.011768784373998642, "Value Loss": 0.0036268136464059353, "_runtime": 868.5243630409241, "_timestamp": 1585570784.3689964, "_step": 121}
{"Episode reward": -72.61499526142133, "Episode length": 999, "Policy Loss": 0.0012305123964324594, "Value Loss": 0.002743606921285391, "_runtime": 870.0733592510223, "_timestamp": 1585570785.9179926, "_step": 122}
{"Episode reward": -73.65113444138301, "Episode length": 999, "Policy Loss": 0.003934892360121012, "Value Loss": 0.0029609533958137035, "_runtime": 871.6109189987183, "_timestamp": 1585570787.4555523, "_step": 123}
{"Episode reward": -72.89978126335478, "Episode length": 999, "Policy Loss": -0.008486033417284489, "Value Loss": 0.0025425651110708714, "_runtime": 873.1385087966919, "_timestamp": 1585570788.9831421, "_step": 124}
{"Episode reward": -72.09377564389774, "Episode length": 999, "Policy Loss": 0.003240894991904497, "Value Loss": 0.0016622463008388877, "_runtime": 874.6748819351196, "_timestamp": 1585570790.5195153, "_step": 125}
{"Episode reward": -71.48531401946845, "Episode length": 999, "Policy Loss": 0.005380017217248678, "Value Loss": 0.0019057837780565023, "_runtime": 876.2258567810059, "_timestamp": 1585570792.0704901, "_step": 126}
{"Episode reward": -73.04121731143873, "Episode length": 999, "Policy Loss": 0.0007698748959228396, "Value Loss": 0.0016962158260867, "_runtime": 877.7494251728058, "_timestamp": 1585570793.5940585, "_step": 127}
{"Episode reward": -72.41043299677375, "Episode length": 999, "Policy Loss": 0.00538215134292841, "Value Loss": 0.001651945523917675, "_runtime": 879.2984828948975, "_timestamp": 1585570795.1431162, "_step": 128}
{"Episode reward": -72.66994946502236, "Episode length": 999, "Policy Loss": 0.005111929029226303, "Value Loss": 0.0017782582435756922, "_runtime": 880.8466300964355, "_timestamp": 1585570796.6912634, "_step": 129}
{"Episode reward": -72.97926906597107, "Episode length": 999, "Policy Loss": -0.0020086648873984814, "Value Loss": 0.0017295134020969272, "_runtime": 882.3996512889862, "_timestamp": 1585570798.2442846, "_step": 130}
{"Episode reward": -73.60867987074656, "Episode length": 999, "Policy Loss": 0.0057826261036098, "Value Loss": 0.0018687979318201542, "_runtime": 883.9474449157715, "_timestamp": 1585570799.7920783, "_step": 131}
{"Episode reward": -71.1625353448072, "Episode length": 999, "Policy Loss": 0.010450871661305428, "Value Loss": 0.002796539105474949, "_runtime": 885.4984111785889, "_timestamp": 1585570801.3430445, "_step": 132}
{"Episode reward": -72.01781603117229, "Episode length": 999, "Policy Loss": 0.005430156830698252, "Value Loss": 0.0027409058529883623, "_runtime": 887.0349128246307, "_timestamp": 1585570802.8795462, "_step": 133}
{"Episode reward": -72.3028630016151, "Episode length": 999, "Policy Loss": 0.0006353541975840926, "Value Loss": 0.0016479752957820892, "_runtime": 888.5840294361115, "_timestamp": 1585570804.4286628, "_step": 134}
{"Episode reward": -71.2210870788408, "Episode length": 999, "Policy Loss": 0.0036779677029699087, "Value Loss": 0.0017631453229114413, "_runtime": 890.1701083183289, "_timestamp": 1585570806.0147417, "_step": 135}
{"Episode reward": -74.20365747296712, "Episode length": 999, "Policy Loss": 0.0036007859744131565, "Value Loss": 0.0019373121904209256, "_runtime": 891.7190430164337, "_timestamp": 1585570807.5636764, "_step": 136}
{"Episode reward": -72.15855285867404, "Episode length": 999, "Policy Loss": 0.004522969014942646, "Value Loss": 0.002850505756214261, "_runtime": 893.2677252292633, "_timestamp": 1585570809.1123586, "_step": 137}
{"Episode reward": -70.97603962353064, "Episode length": 999, "Policy Loss": -0.006591524463146925, "Value Loss": 0.002760862233117223, "_runtime": 894.8239645957947, "_timestamp": 1585570810.668598, "_step": 138}
{"Episode reward": -71.9623513847002, "Episode length": 999, "Policy Loss": -0.00011005176202161238, "Value Loss": 0.001868468476459384, "_runtime": 896.3609404563904, "_timestamp": 1585570812.2055738, "_step": 139}
{"Episode reward": -73.49195727921824, "Episode length": 999, "Policy Loss": -0.00847572274506092, "Value Loss": 0.002259097993373871, "_runtime": 897.8981463909149, "_timestamp": 1585570813.7427797, "_step": 140}
{"Episode reward": -69.75875875075161, "Episode length": 999, "Policy Loss": -0.004353675991296768, "Value Loss": 0.001995227299630642, "_runtime": 899.4446330070496, "_timestamp": 1585570815.2892663, "_step": 141}
{"Episode reward": -72.24224854080195, "Episode length": 999, "Policy Loss": -0.00043632712913677096, "Value Loss": 0.0014932918129488826, "_runtime": 900.9795882701874, "_timestamp": 1585570816.8242216, "_step": 142}
{"Episode reward": -70.87264568023407, "Episode length": 999, "Policy Loss": 0.007478916551917791, "Value Loss": 0.001970503246411681, "_runtime": 902.5261285305023, "_timestamp": 1585570818.3707619, "_step": 143}
{"Episode reward": -71.27933663966394, "Episode length": 999, "Policy Loss": 0.007243701722472906, "Value Loss": 0.001939948182553053, "_runtime": 904.0637276172638, "_timestamp": 1585570819.908361, "_step": 144}
{"Episode reward": -70.63850585127787, "Episode length": 999, "Policy Loss": 0.00840764306485653, "Value Loss": 0.0021612634882330894, "_runtime": 905.6149849891663, "_timestamp": 1585570821.4596183, "_step": 145}
{"Episode reward": -72.50646632794704, "Episode length": 999, "Policy Loss": 0.001515313284471631, "Value Loss": 0.0016510714776813984, "_runtime": 907.1641910076141, "_timestamp": 1585570823.0088243, "_step": 146}
{"Episode reward": -74.35135431252543, "Episode length": 999, "Policy Loss": -0.0007990597514435649, "Value Loss": 0.0012037004344165325, "_runtime": 908.7172150611877, "_timestamp": 1585570824.5618484, "_step": 147}
{"Episode reward": -71.8498157827011, "Episode length": 999, "Policy Loss": 0.0027403286658227444, "Value Loss": 0.0012563389027491212, "_runtime": 910.2750105857849, "_timestamp": 1585570826.119644, "_step": 148}
{"Episode reward": -71.1696487028537, "Episode length": 999, "Policy Loss": 0.005784050561487675, "Value Loss": 0.0017262294422835112, "_runtime": 911.8677549362183, "_timestamp": 1585570827.7123883, "_step": 149}
{"Episode reward": -70.91562642862, "Episode length": 999, "Policy Loss": 0.00520798284560442, "Value Loss": 0.0018980690510943532, "_runtime": 913.4259815216064, "_timestamp": 1585570829.2706149, "_step": 150}
{"Episode reward": -70.98619662890808, "Episode length": 999, "Policy Loss": -0.0023503380361944437, "Value Loss": 0.0015918725403025746, "_runtime": 914.9827308654785, "_timestamp": 1585570830.8273642, "_step": 151}
{"Episode reward": -71.02197314440193, "Episode length": 999, "Policy Loss": -0.0009557975572533906, "Value Loss": 0.0013469287659972906, "_runtime": 916.5415954589844, "_timestamp": 1585570832.3862288, "_step": 152}
{"Episode reward": -71.47372423121082, "Episode length": 999, "Policy Loss": -0.0016368326032534242, "Value Loss": 0.0012702483218163252, "_runtime": 918.0992488861084, "_timestamp": 1585570833.9438822, "_step": 153}
{"Episode reward": -74.68598918314761, "Episode length": 999, "Policy Loss": -0.005186121445149183, "Value Loss": 0.0014216183917596936, "_runtime": 919.652116060257, "_timestamp": 1585570835.4967494, "_step": 154}
{"Episode reward": -73.17669902600923, "Episode length": 999, "Policy Loss": -0.002253419253975153, "Value Loss": 0.0013196261133998632, "_runtime": 921.2012829780579, "_timestamp": 1585570837.0459163, "_step": 155}
{"Episode reward": -72.26926157796312, "Episode length": 999, "Policy Loss": 0.003865552367642522, "Value Loss": 0.0011271637631580234, "_runtime": 922.745500087738, "_timestamp": 1585570838.5901334, "_step": 156}
{"Episode reward": -68.44017209897814, "Episode length": 999, "Policy Loss": -0.0006441443110816181, "Value Loss": 0.0019557224586606026, "_runtime": 924.3030958175659, "_timestamp": 1585570840.1477292, "_step": 157}
{"Episode reward": -71.9820542857027, "Episode length": 999, "Policy Loss": 0.0034826118499040604, "Value Loss": 0.00140638358425349, "_runtime": 925.8611650466919, "_timestamp": 1585570841.7057984, "_step": 158}
{"Episode reward": -73.6746839779016, "Episode length": 999, "Policy Loss": 0.003984833601862192, "Value Loss": 0.0011918051168322563, "_runtime": 927.4188456535339, "_timestamp": 1585570843.263479, "_step": 159}
{"Episode reward": -70.48097276907289, "Episode length": 999, "Policy Loss": 0.006537729408591986, "Value Loss": 0.001731897471472621, "_runtime": 928.9783952236176, "_timestamp": 1585570844.8230286, "_step": 160}
{"Episode reward": -70.72226375006113, "Episode length": 999, "Policy Loss": 0.0018034010427072644, "Value Loss": 0.0012850981438532472, "_runtime": 930.525372505188, "_timestamp": 1585570846.3700058, "_step": 161}
{"Episode reward": -72.24949601779153, "Episode length": 999, "Policy Loss": 0.0038907614070922136, "Value Loss": 0.001280758180655539, "_runtime": 932.072674036026, "_timestamp": 1585570847.9173074, "_step": 162}
{"Episode reward": -72.17761180663491, "Episode length": 999, "Policy Loss": 0.0014092351775616407, "Value Loss": 0.0010725532192736864, "_runtime": 933.6202819347382, "_timestamp": 1585570849.4649153, "_step": 163}
{"Episode reward": -70.9618478878114, "Episode length": 999, "Policy Loss": 0.00285635725595057, "Value Loss": 0.001616343972273171, "_runtime": 935.2068545818329, "_timestamp": 1585570851.051488, "_step": 164}
{"Episode reward": -70.66182932826659, "Episode length": 999, "Policy Loss": 0.00202971906401217, "Value Loss": 0.0016241741832345724, "_runtime": 936.7559685707092, "_timestamp": 1585570852.600602, "_step": 165}
{"Episode reward": -73.81323975690002, "Episode length": 999, "Policy Loss": 0.0033944095484912395, "Value Loss": 0.0016258424147963524, "_runtime": 938.2940154075623, "_timestamp": 1585570854.1386487, "_step": 166}
{"Episode reward": -70.72188709349578, "Episode length": 999, "Policy Loss": 0.0029081066604703665, "Value Loss": 0.0017079217359423637, "_runtime": 939.8421626091003, "_timestamp": 1585570855.686796, "_step": 167}
{"Episode reward": -72.96543723553788, "Episode length": 999, "Policy Loss": 3.3886572055052966e-05, "Value Loss": 0.001210990478284657, "_runtime": 941.3907730579376, "_timestamp": 1585570857.2354064, "_step": 168}
{"Episode reward": -73.0651954627071, "Episode length": 999, "Policy Loss": -0.004003055393695831, "Value Loss": 0.001231915084645152, "_runtime": 942.9390058517456, "_timestamp": 1585570858.7836392, "_step": 169}
{"Episode reward": -72.82598425263912, "Episode length": 999, "Policy Loss": -0.005579360295087099, "Value Loss": 0.0014044934650883079, "_runtime": 944.4896788597107, "_timestamp": 1585570860.3343122, "_step": 170}
{"Episode reward": -74.648049587694, "Episode length": 999, "Policy Loss": 0.00024187147209886461, "Value Loss": 0.0011113642249256372, "_runtime": 946.0254817008972, "_timestamp": 1585570861.870115, "_step": 171}
{"Episode reward": -72.69016093714886, "Episode length": 999, "Policy Loss": 0.0038101894315332174, "Value Loss": 0.0013097742339596152, "_runtime": 947.5748829841614, "_timestamp": 1585570863.4195163, "_step": 172}
{"Episode reward": -73.2493895508787, "Episode length": 999, "Policy Loss": 0.0014051093021407723, "Value Loss": 0.001207298832014203, "_runtime": 949.1251909732819, "_timestamp": 1585570864.9698243, "_step": 173}
{"Episode reward": -71.47050703319783, "Episode length": 999, "Policy Loss": 0.0037880828604102135, "Value Loss": 0.0012533612316474319, "_runtime": 950.6715884208679, "_timestamp": 1585570866.5162218, "_step": 174}
{"Episode reward": -72.16190670083995, "Episode length": 999, "Policy Loss": 0.0029666097834706306, "Value Loss": 0.0015231649158522487, "_runtime": 952.2193903923035, "_timestamp": 1585570868.0640237, "_step": 175}
{"Episode reward": -72.79869053828592, "Episode length": 999, "Policy Loss": 0.0016603181138634682, "Value Loss": 0.0012633104342967272, "_runtime": 953.7667315006256, "_timestamp": 1585570869.6113648, "_step": 176}
{"Episode reward": -70.65413003736546, "Episode length": 999, "Policy Loss": 0.0053607807494699955, "Value Loss": 0.0014927147421985865, "_runtime": 955.316251039505, "_timestamp": 1585570871.1608844, "_step": 177}
{"Episode reward": -72.82332408806616, "Episode length": 999, "Policy Loss": 0.005324155557900667, "Value Loss": 0.0018706534756347537, "_runtime": 956.8494589328766, "_timestamp": 1585570872.6940923, "_step": 178}
{"Episode reward": -73.81994817558144, "Episode length": 999, "Policy Loss": -0.002719631651416421, "Value Loss": 0.0012389394687488675, "_runtime": 958.4244997501373, "_timestamp": 1585570874.269133, "_step": 179}
{"Episode reward": -72.9136465316914, "Episode length": 999, "Policy Loss": 0.006024309899657965, "Value Loss": 0.0019029214745387435, "_runtime": 959.9755358695984, "_timestamp": 1585570875.8201692, "_step": 180}
{"Episode reward": -73.39090986268474, "Episode length": 999, "Policy Loss": 0.002988439053297043, "Value Loss": 0.0016840866301208735, "_runtime": 961.514190196991, "_timestamp": 1585570877.3588235, "_step": 181}
{"Episode reward": -70.9174189635053, "Episode length": 999, "Policy Loss": 0.0034870747476816177, "Value Loss": 0.0014798056799918413, "_runtime": 963.0628209114075, "_timestamp": 1585570878.9074543, "_step": 182}
{"Episode reward": -70.59649516169665, "Episode length": 999, "Policy Loss": 0.0036579163279384375, "Value Loss": 0.001427709823474288, "_runtime": 964.6026263237, "_timestamp": 1585570880.4472597, "_step": 183}
{"Episode reward": -73.0309490738752, "Episode length": 999, "Policy Loss": -0.0029885852709412575, "Value Loss": 0.0011695717694237828, "_runtime": 966.1566781997681, "_timestamp": 1585570882.0013115, "_step": 184}
{"Episode reward": -73.36364900517117, "Episode length": 999, "Policy Loss": -0.0026529941242188215, "Value Loss": 0.0013699979754164815, "_runtime": 967.7061789035797, "_timestamp": 1585570883.5508122, "_step": 185}
{"Episode reward": -74.37212806177669, "Episode length": 999, "Policy Loss": 0.003414485137909651, "Value Loss": 0.0014416093472391367, "_runtime": 969.2352163791656, "_timestamp": 1585570885.0798497, "_step": 186}
{"Episode reward": -71.64132888471782, "Episode length": 999, "Policy Loss": 0.0030145500786602497, "Value Loss": 0.0010871728882193565, "_runtime": 970.7730135917664, "_timestamp": 1585570886.617647, "_step": 187}
{"Episode reward": -71.38682775838001, "Episode length": 999, "Policy Loss": 0.004708859603852034, "Value Loss": 0.0018764908891171217, "_runtime": 972.3140597343445, "_timestamp": 1585570888.158693, "_step": 188}
{"Episode reward": -71.90340140955749, "Episode length": 999, "Policy Loss": 0.005109753925353289, "Value Loss": 0.0012432298390194774, "_runtime": 973.8673162460327, "_timestamp": 1585570889.7119496, "_step": 189}
{"Episode reward": -72.15236747561754, "Episode length": 999, "Policy Loss": 0.0013823530171066523, "Value Loss": 0.001181380357593298, "_runtime": 975.4166541099548, "_timestamp": 1585570891.2612875, "_step": 190}
{"Episode reward": -70.55413179874009, "Episode length": 999, "Policy Loss": -0.0007882481440901756, "Value Loss": 0.001414288068190217, "_runtime": 976.9659616947174, "_timestamp": 1585570892.810595, "_step": 191}
{"Episode reward": -73.92596801039315, "Episode length": 999, "Policy Loss": 0.004460655618458986, "Value Loss": 0.0014153256779536605, "_runtime": 978.5054261684418, "_timestamp": 1585570894.3500595, "_step": 192}
{"Episode reward": -71.45890223168558, "Episode length": 999, "Policy Loss": 0.0018639388727024198, "Value Loss": 0.0011603949824348092, "_runtime": 980.0511229038239, "_timestamp": 1585570895.8957562, "_step": 193}
{"Episode reward": -72.58869694096606, "Episode length": 999, "Policy Loss": 0.0024597151204943657, "Value Loss": 0.0009336610091850162, "_runtime": 981.625524520874, "_timestamp": 1585570897.4701579, "_step": 194}
{"Episode reward": -72.04869703952689, "Episode length": 999, "Policy Loss": -0.0004957163473591208, "Value Loss": 0.001506567350588739, "_runtime": 983.1774528026581, "_timestamp": 1585570899.0220861, "_step": 195}
{"Episode reward": -70.68178646207129, "Episode length": 999, "Policy Loss": 0.003402728121727705, "Value Loss": 0.0011457945220172405, "_runtime": 984.7344377040863, "_timestamp": 1585570900.579071, "_step": 196}
{"Episode reward": -72.60115421514456, "Episode length": 999, "Policy Loss": 0.0025922677014023066, "Value Loss": 0.0010275979293510318, "_runtime": 986.2843866348267, "_timestamp": 1585570902.12902, "_step": 197}
{"Episode reward": -71.0597796146699, "Episode length": 999, "Policy Loss": 0.0008949280600063503, "Value Loss": 0.0015029351925477386, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076, 2.6378047466278076]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.245864987373352, -1.185731291770935, -1.125597596168518, -1.065463900566101, -1.005330204963684, -0.9451965093612671, -0.8850627541542053, -0.8249290585517883, -0.7647953629493713, -0.7046616673469543, -0.6445279717445374, -0.5843942761421204, -0.5242605209350586, -0.4641268253326416, -0.4039931297302246, -0.3438594341278076, -0.2837257385253906, -0.22359204292297363, -0.16345834732055664, -0.10332465171813965, -0.043190956115722656, 0.016942739486694336, 0.07707643508911133, 0.13721013069152832, 0.19734394550323486, 0.25747764110565186, 0.31761133670806885, 0.37774503231048584, 0.43787872791290283, 0.4980124235153198, 0.5581461191177368, 0.6182798147201538, 0.6784135103225708, 0.7385472059249878, 0.7986809015274048, 0.8588145971298218, 0.9189482927322388, 0.9790819883346558, 1.0392156839370728, 1.0993493795394897, 1.1594830751419067, 1.2196167707443237, 1.2797504663467407, 1.3398841619491577, 1.4000178575515747, 1.4601515531539917, 1.5202852487564087, 1.5804189443588257, 1.6405528783798218, 1.7006865739822388, 1.7608202695846558, 1.8209539651870728, 1.8810876607894897, 1.9412213563919067, 2.0013551712036133, 2.061488628387451, 2.1216225624084473, 2.181756019592285, 2.2418899536132812, 2.302023410797119, 2.3621573448181152, 2.422290802001953, 2.482424736022949, 2.542558193206787, 2.602692127227783]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-1.4506248235702515, -1.4104098081588745, -1.370194673538208, -1.329979658126831, -1.289764642715454, -1.2495496273040771, -1.2093344926834106, -1.1691194772720337, -1.1289043426513672, -1.0886893272399902, -1.0484743118286133, -1.0082592964172363, -0.9680441617965698, -0.9278291463851929, -0.8876140713691711, -0.8473990559577942, -0.8071839809417725, -0.7669689059257507, -0.7267538905143738, -0.686538815498352, -0.6463238000869751, -0.6061087250709534, -0.5658936500549316, -0.5256786346435547, -0.48546355962753296, -0.44524848461151123, -0.4050334692001343, -0.3648184537887573, -0.3246033191680908, -0.28438830375671387, -0.24417328834533691, -0.2039581537246704, -0.16374313831329346, -0.1235281229019165, -0.08331298828125, -0.04309797286987305, -0.0028829574584960938, 0.03733217716217041, 0.07754719257354736, 0.11776220798492432, 0.15797722339630127, 0.19819235801696777, 0.23840737342834473, 0.2786223888397217, 0.3188375234603882, 0.35905253887176514, 0.3992675542831421, 0.4394826889038086, 0.47969770431518555, 0.5199127197265625, 0.560127854347229, 0.600342869758606, 0.6405578851699829, 0.6807729005813599, 0.7209879159927368, 0.7612031698226929, 0.8014181852340698, 0.8416332006454468, 0.8818482160568237, 0.9220632314682007, 0.9622782468795776, 1.0024935007095337, 1.0427085161209106, 1.0829235315322876, 1.1231385469436646]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 4.0, 4.0, 3.0, 2.0, 6.0, 7.0, 6.0, 7.0, 4.0, 17.0, 13.0, 17.0, 24.0, 23.0, 32.0, 60.0, 49.0, 44.0, 25.0, 22.0, 14.0, 16.0, 10.0, 9.0, 10.0, 3.0, 8.0, 5.0, 6.0, 8.0, 12.0, 3.0, 5.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0], "bins": [-1.448084831237793, -1.407731533050537, -1.3673782348632812, -1.3270249366760254, -1.2866716384887695, -1.2463183403015137, -1.2059650421142578, -1.1656116247177124, -1.1252583265304565, -1.0849050283432007, -1.0445517301559448, -1.004198431968689, -0.9638451337814331, -0.9234918355941772, -0.8831384778022766, -0.8427851796150208, -0.8024318814277649, -0.762078583240509, -0.7217252850532532, -0.6813719272613525, -0.6410186290740967, -0.6006653308868408, -0.560312032699585, -0.5199587345123291, -0.47960543632507324, -0.4392521381378174, -0.3988988399505615, -0.3585454225540161, -0.31819212436676025, -0.2778388261795044, -0.23748552799224854, -0.19713222980499268, -0.15677893161773682, -0.11642563343048096, -0.0760723352432251, -0.03571903705596924, 0.004634261131286621, 0.04498755931854248, 0.08534097671508789, 0.12569427490234375, 0.1660475730895996, 0.20640087127685547, 0.24675416946411133, 0.2871074676513672, 0.32746076583862305, 0.3678140640258789, 0.40816736221313477, 0.4485206604003906, 0.4888739585876465, 0.5292273759841919, 0.5695805549621582, 0.6099338531494141, 0.6502871513366699, 0.6906404495239258, 0.7309939861297607, 0.7713472843170166, 0.8117005825042725, 0.8520538806915283, 0.8924071788787842, 0.93276047706604, 0.9731137752532959, 1.0134670734405518, 1.0538203716278076, 1.0941736698150635, 1.1345269680023193]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.3047490119934082, -1.267998456954956, -1.2312480211257935, -1.1944975852966309, -1.1577470302581787, -1.1209964752197266, -1.084246039390564, -1.0474956035614014, -1.0107450485229492, -0.9739945530891418, -0.9372440576553345, -0.9004935622215271, -0.8637430667877197, -0.8269925713539124, -0.790242075920105, -0.7534915804862976, -0.7167410850524902, -0.6799905896186829, -0.6432400941848755, -0.6064895987510681, -0.5697391033172607, -0.5329886078834534, -0.496238112449646, -0.4594876170158386, -0.42273712158203125, -0.3859866261482239, -0.3492361307144165, -0.31248563528060913, -0.27573513984680176, -0.2389845848083496, -0.202234148979187, -0.16548371315002441, -0.12873315811157227, -0.09198260307312012, -0.05523216724395752, -0.018481731414794922, 0.018268823623657227, 0.055019378662109375, 0.09176981449127197, 0.12852025032043457, 0.16527080535888672, 0.20202136039733887, 0.23877179622650146, 0.27552223205566406, 0.3122727870941162, 0.34902334213256836, 0.38577377796173096, 0.42252421379089355, 0.4592747688293457, 0.49602532386779785, 0.5327757596969604, 0.569526195526123, 0.6062767505645752, 0.6430273056030273, 0.6797777414321899, 0.7165281772613525, 0.7532787322998047, 0.7900292873382568, 0.826779842376709, 0.863530158996582, 0.9002807140350342, 0.9370312690734863, 0.9737815856933594, 1.0105321407318115, 1.0472826957702637]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 5.0, 0.0, 4.0, 6.0, 7.0, 6.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.5717737674713135, -1.5170795917510986, -1.4623852968215942, -1.4076911211013794, -1.352996826171875, -1.2983026504516602, -1.2436084747314453, -1.1889142990112305, -1.134220004081726, -1.0795257091522217, -1.0248315334320068, -0.970137357711792, -0.9154431223869324, -0.8607488870620728, -0.8060547113418579, -0.7513604760169983, -0.6966662406921387, -0.641972005367279, -0.5872777700424194, -0.5325835943222046, -0.4778892993927002, -0.42319512367248535, -0.3685009479522705, -0.3138066530227661, -0.25911247730255127, -0.20441830158233643, -0.14972400665283203, -0.09502983093261719, -0.040335655212402344, 0.01435863971710205, 0.0690528154373169, 0.12374711036682129, 0.17844128608703613, 0.23313546180725098, 0.28782975673675537, 0.3425239324569702, 0.3972182273864746, 0.45191240310668945, 0.5066065788269043, 0.5613007545471191, 0.6159951686859131, 0.6706893444061279, 0.7253835201263428, 0.7800776958465576, 0.8347718715667725, 0.8894660472869873, 0.9441604614257812, 0.9988546371459961, 1.053548812866211, 1.1082429885864258, 1.1629371643066406, 1.2176315784454346, 1.2723257541656494, 1.3270199298858643, 1.381714105606079, 1.436408281326294, 1.4911024570465088, 1.5457968711853027, 1.6004910469055176, 1.6551852226257324, 1.7098793983459473, 1.764573574066162, 1.819267988204956, 1.873962163925171, 1.9286563396453857]}, "_runtime": 987.8415710926056, "_timestamp": 1585570903.6862044, "_step": 198}
{"Episode reward": -72.67796595737856, "Episode length": 999, "Policy Loss": 0.0037170960567891598, "Value Loss": 0.0012854468077421188, "_runtime": 989.3916935920715, "_timestamp": 1585570905.236327, "_step": 199}
{"Episode reward": -70.5812974241044, "Episode length": 999, "Policy Loss": 0.005769041832536459, "Value Loss": 0.0015641956124454737, "_runtime": 990.9410963058472, "_timestamp": 1585570906.7857296, "_step": 200}
{"Episode reward": -69.9120148781897, "Episode length": 999, "Policy Loss": 0.002292478457093239, "Value Loss": 0.001152924494817853, "_runtime": 992.4909954071045, "_timestamp": 1585570908.3356287, "_step": 201}
{"Episode reward": -71.70829798770853, "Episode length": 999, "Policy Loss": 0.00015154546417761594, "Value Loss": 0.0012025436153635383, "_runtime": 994.0284526348114, "_timestamp": 1585570909.873086, "_step": 202}
{"Episode reward": -71.71621332496949, "Episode length": 999, "Policy Loss": -0.0009680907242000103, "Value Loss": 0.0014337560860440135, "_runtime": 995.5801842212677, "_timestamp": 1585570911.4248176, "_step": 203}
{"Episode reward": -73.11102656366157, "Episode length": 999, "Policy Loss": 0.0006280238158069551, "Value Loss": 0.0011023074621334672, "_runtime": 997.1325817108154, "_timestamp": 1585570912.977215, "_step": 204}
{"Episode reward": -72.58459468523681, "Episode length": 999, "Policy Loss": 0.002246743068099022, "Value Loss": 0.0011647091014310718, "_runtime": 998.6760082244873, "_timestamp": 1585570914.5206416, "_step": 205}
{"Episode reward": -73.9326996915589, "Episode length": 999, "Policy Loss": 0.004876225721091032, "Value Loss": 0.0011227659415453672, "_runtime": 1000.2258267402649, "_timestamp": 1585570916.07046, "_step": 206}
{"Episode reward": -70.05194809013297, "Episode length": 999, "Policy Loss": 0.0015513119287788868, "Value Loss": 0.0011559705017134547, "_runtime": 1001.773241519928, "_timestamp": 1585570917.6178749, "_step": 207}
{"Episode reward": -70.7401650292928, "Episode length": 999, "Policy Loss": 0.002026746980845928, "Value Loss": 0.0010742662707343698, "_runtime": 1003.3482291698456, "_timestamp": 1585570919.1928625, "_step": 208}
{"Episode reward": -69.79026521614215, "Episode length": 999, "Policy Loss": -0.0015373288188129663, "Value Loss": 0.0011840873630717397, "_runtime": 1004.8991169929504, "_timestamp": 1585570920.7437503, "_step": 209}
{"Episode reward": -69.5813721532437, "Episode length": 999, "Policy Loss": 8.379364589927718e-05, "Value Loss": 0.0012577869929373264, "_runtime": 1006.449821472168, "_timestamp": 1585570922.2944548, "_step": 210}
{"Episode reward": -70.23241815953506, "Episode length": 999, "Policy Loss": 0.005295220296829939, "Value Loss": 0.0017711594700813293, "_runtime": 1007.9863736629486, "_timestamp": 1585570923.831007, "_step": 211}
{"Episode reward": -70.17955348965168, "Episode length": 999, "Policy Loss": 0.0010718728881329298, "Value Loss": 0.0012797433882951736, "_runtime": 1009.5401220321655, "_timestamp": 1585570925.3847554, "_step": 212}
{"Episode reward": -72.33463477059165, "Episode length": 999, "Policy Loss": 0.00030240093474276364, "Value Loss": 0.0013407384976744652, "_runtime": 1011.0896465778351, "_timestamp": 1585570926.93428, "_step": 213}
{"Episode reward": -75.34175179187024, "Episode length": 999, "Policy Loss": 0.0010756918927654624, "Value Loss": 0.0011054057395085692, "_runtime": 1012.6395418643951, "_timestamp": 1585570928.4841752, "_step": 214}
{"Episode reward": -70.6286196836815, "Episode length": 999, "Policy Loss": 0.0032802235800772905, "Value Loss": 0.0011570218484848738, "_runtime": 1014.18776679039, "_timestamp": 1585570930.0324001, "_step": 215}
{"Episode reward": -72.86765628233039, "Episode length": 999, "Policy Loss": -0.0009827027097344398, "Value Loss": 0.0010419983882457018, "_runtime": 1015.7276585102081, "_timestamp": 1585570931.5722919, "_step": 216}
{"Episode reward": -71.6213243704285, "Episode length": 999, "Policy Loss": 0.0018827718449756503, "Value Loss": 0.0010226964950561523, "_runtime": 1017.2675218582153, "_timestamp": 1585570933.1121552, "_step": 217}
{"Episode reward": -71.3455253434711, "Episode length": 999, "Policy Loss": -1.9509243429638445e-06, "Value Loss": 0.00130722566973418, "_runtime": 1018.820074558258, "_timestamp": 1585570934.664708, "_step": 218}
{"Episode reward": -73.0372082848618, "Episode length": 999, "Policy Loss": 0.0029355420265346766, "Value Loss": 0.001263525802642107, "_runtime": 1020.3692712783813, "_timestamp": 1585570936.2139046, "_step": 219}
{"Episode reward": -73.34476368474114, "Episode length": 999, "Policy Loss": 0.0036306113470345736, "Value Loss": 0.0011593803064897656, "_runtime": 1021.9186809062958, "_timestamp": 1585570937.7633142, "_step": 220}
{"Episode reward": -72.51985932457195, "Episode length": 999, "Policy Loss": 0.002909245667979121, "Value Loss": 0.001007362618111074, "_runtime": 1023.466988325119, "_timestamp": 1585570939.3116217, "_step": 221}
{"Episode reward": -71.94763876753963, "Episode length": 999, "Policy Loss": -0.001412194687873125, "Value Loss": 0.0010484299855306745, "_runtime": 1025.0070021152496, "_timestamp": 1585570940.8516355, "_step": 222}
{"Episode reward": -71.95293922571553, "Episode length": 999, "Policy Loss": -0.001384976552799344, "Value Loss": 0.0013406439684331417, "_runtime": 1026.5946395397186, "_timestamp": 1585570942.4392729, "_step": 223}
{"Episode reward": -72.45147893225031, "Episode length": 999, "Policy Loss": 0.002992799738422036, "Value Loss": 0.0014765855157747865, "_runtime": 1028.1318650245667, "_timestamp": 1585570943.9764984, "_step": 224}
{"Episode reward": -73.48870486401913, "Episode length": 999, "Policy Loss": 6.858337292214856e-05, "Value Loss": 0.0010401085019111633, "_runtime": 1029.682938337326, "_timestamp": 1585570945.5275717, "_step": 225}
{"Episode reward": -72.77053269396322, "Episode length": 999, "Policy Loss": 0.0011399064678698778, "Value Loss": 0.0011639914009720087, "_runtime": 1031.2331192493439, "_timestamp": 1585570947.0777526, "_step": 226}
{"Episode reward": -69.87592198133838, "Episode length": 999, "Policy Loss": 0.0018532107351347804, "Value Loss": 0.0012026452459394932, "_runtime": 1032.7829203605652, "_timestamp": 1585570948.6275537, "_step": 227}
{"Episode reward": -72.29281045513686, "Episode length": 999, "Policy Loss": -0.00020303792553022504, "Value Loss": 0.0013696540845558047, "_runtime": 1034.3337535858154, "_timestamp": 1585570950.178387, "_step": 228}
{"Episode reward": -71.97137052437952, "Episode length": 999, "Policy Loss": 0.005377140827476978, "Value Loss": 0.0014545301673933864, "_runtime": 1035.8733372688293, "_timestamp": 1585570951.7179706, "_step": 229}
{"Episode reward": -72.35042464493544, "Episode length": 999, "Policy Loss": -0.0003617568872869015, "Value Loss": 0.001310978434048593, "_runtime": 1037.4244225025177, "_timestamp": 1585570953.2690558, "_step": 230}
{"Episode reward": -72.53861584565598, "Episode length": 999, "Policy Loss": 0.001661414047703147, "Value Loss": 0.0013317413395270705, "_runtime": 1038.9743757247925, "_timestamp": 1585570954.819009, "_step": 231}
{"Episode reward": -70.14828343712601, "Episode length": 999, "Policy Loss": 0.00582911865785718, "Value Loss": 0.0016532671870663762, "_runtime": 1040.5237231254578, "_timestamp": 1585570956.3683565, "_step": 232}
{"Episode reward": -70.93709417852291, "Episode length": 999, "Policy Loss": 0.0012926158960908651, "Value Loss": 0.0013299467973411083, "_runtime": 1042.0782256126404, "_timestamp": 1585570957.922859, "_step": 233}
{"Episode reward": -72.95587190522453, "Episode length": 999, "Policy Loss": 0.003149837488308549, "Value Loss": 0.0013749655336141586, "_runtime": 1043.628327846527, "_timestamp": 1585570959.4729612, "_step": 234}
{"Episode reward": -71.94046703087565, "Episode length": 999, "Policy Loss": 0.0011332824360579252, "Value Loss": 0.0011988691985607147, "_runtime": 1045.1781759262085, "_timestamp": 1585570961.0228093, "_step": 235}
{"Episode reward": -71.19913187200093, "Episode length": 999, "Policy Loss": 0.0004914415767416358, "Value Loss": 0.0012322847032919526, "_runtime": 1046.717004776001, "_timestamp": 1585570962.561638, "_step": 236}
{"Episode reward": -72.42851091578184, "Episode length": 999, "Policy Loss": 0.003335332963615656, "Value Loss": 0.0011555782984942198, "_runtime": 1048.2669615745544, "_timestamp": 1585570964.111595, "_step": 237}
{"Episode reward": -70.97156567266181, "Episode length": 999, "Policy Loss": -0.0006127310334704816, "Value Loss": 0.0010978808859363198, "_runtime": 1049.8512144088745, "_timestamp": 1585570965.6958477, "_step": 238}
{"Episode reward": -71.2862182463812, "Episode length": 999, "Policy Loss": 0.002941808197647333, "Value Loss": 0.0011310115223750472, "_runtime": 1051.4033796787262, "_timestamp": 1585570967.248013, "_step": 239}
{"Episode reward": -72.16842530637756, "Episode length": 999, "Policy Loss": 0.0004596266080625355, "Value Loss": 0.0012179723707959056, "_runtime": 1052.9392490386963, "_timestamp": 1585570968.7838824, "_step": 240}
{"Episode reward": -72.22991310326397, "Episode length": 999, "Policy Loss": 0.0023199794813990593, "Value Loss": 0.0011135092936456203, "_runtime": 1054.4789607524872, "_timestamp": 1585570970.323594, "_step": 241}
{"Episode reward": -73.883023571091, "Episode length": 999, "Policy Loss": 0.0017907016444951296, "Value Loss": 0.001405406161211431, "_runtime": 1056.029543876648, "_timestamp": 1585570971.8741772, "_step": 242}
{"Episode reward": -71.31661562415245, "Episode length": 999, "Policy Loss": 0.004517864435911179, "Value Loss": 0.0011568020563572645, "_runtime": 1057.581638097763, "_timestamp": 1585570973.4262714, "_step": 243}
{"Episode reward": -71.74935942710987, "Episode length": 999, "Policy Loss": -0.0005797334597446024, "Value Loss": 0.0012029469944536686, "_runtime": 1059.1202788352966, "_timestamp": 1585570974.9649122, "_step": 244}
{"Episode reward": -72.42985852695266, "Episode length": 999, "Policy Loss": 0.003289623651653528, "Value Loss": 0.0010793335968628526, "_runtime": 1060.657879114151, "_timestamp": 1585570976.5025125, "_step": 245}
{"Episode reward": -73.02301504959657, "Episode length": 999, "Policy Loss": 0.0011581595754250884, "Value Loss": 0.0009208833798766136, "_runtime": 1062.2066905498505, "_timestamp": 1585570978.051324, "_step": 246}
{"Episode reward": -73.92195829502603, "Episode length": 999, "Policy Loss": 0.003854598617181182, "Value Loss": 0.0010932334698736668, "_runtime": 1063.756950378418, "_timestamp": 1585570979.6015837, "_step": 247}
{"Episode reward": -72.66669872004125, "Episode length": 999, "Policy Loss": -0.0009403015719726682, "Value Loss": 0.0012423450825735927, "_runtime": 1065.2967991828918, "_timestamp": 1585570981.1414325, "_step": 248}
{"Episode reward": -70.51394828005124, "Episode length": 999, "Policy Loss": -0.000754280190449208, "Value Loss": 0.0011261265026405454, "_runtime": 1066.847085237503, "_timestamp": 1585570982.6917186, "_step": 249}
{"Episode reward": -71.99050820927896, "Episode length": 999, "Policy Loss": 0.0030003050342202187, "Value Loss": 0.0011194655671715736, "_runtime": 1068.396406173706, "_timestamp": 1585570984.2410395, "_step": 250}
{"Episode reward": -72.01083624056702, "Episode length": 999, "Policy Loss": 0.003784894710406661, "Value Loss": 0.0011517544044181705, "_runtime": 1069.952306509018, "_timestamp": 1585570985.7969398, "_step": 251}
{"Episode reward": -72.1146866025762, "Episode length": 999, "Policy Loss": 0.001223485916852951, "Value Loss": 0.0010427199304103851, "_runtime": 1071.5013449192047, "_timestamp": 1585570987.3459783, "_step": 252}
{"Episode reward": -70.74195927532821, "Episode length": 999, "Policy Loss": 0.0005648248479701579, "Value Loss": 0.0009422798175364733, "_runtime": 1073.0734186172485, "_timestamp": 1585570988.918052, "_step": 253}
{"Episode reward": -73.25318004450224, "Episode length": 999, "Policy Loss": -0.00018339790403842926, "Value Loss": 0.0010978918289765716, "_runtime": 1074.6247017383575, "_timestamp": 1585570990.469335, "_step": 254}
{"Episode reward": -71.74748302620574, "Episode length": 999, "Policy Loss": 0.0011176831321790814, "Value Loss": 0.0009972999105229974, "_runtime": 1076.1621074676514, "_timestamp": 1585570992.0067408, "_step": 255}
{"Episode reward": -70.72693313178647, "Episode length": 999, "Policy Loss": 0.001994605641812086, "Value Loss": 0.0011892496841028333, "_runtime": 1077.7111072540283, "_timestamp": 1585570993.5557406, "_step": 256}
{"Episode reward": -71.16990663337656, "Episode length": 999, "Policy Loss": 0.0026759859174489975, "Value Loss": 0.0016512724105268717, "_runtime": 1079.251223564148, "_timestamp": 1585570995.095857, "_step": 257}
{"Episode reward": -74.02254110975439, "Episode length": 999, "Policy Loss": 0.0008600622531957924, "Value Loss": 0.001021839794702828, "_runtime": 1080.787901878357, "_timestamp": 1585570996.6325352, "_step": 258}
{"Episode reward": -72.40405542903332, "Episode length": 999, "Policy Loss": -2.4667073375894688e-05, "Value Loss": 0.0010210524778813124, "_runtime": 1082.3362596035004, "_timestamp": 1585570998.180893, "_step": 259}
{"Episode reward": -72.38774939331647, "Episode length": 999, "Policy Loss": 0.0018408432370051742, "Value Loss": 0.001046239398419857, "_runtime": 1083.8868725299835, "_timestamp": 1585570999.7315059, "_step": 260}
{"Episode reward": -72.27518259761571, "Episode length": 999, "Policy Loss": -0.0005858852528035641, "Value Loss": 0.0011425517732277513, "_runtime": 1085.4269287586212, "_timestamp": 1585571001.271562, "_step": 261}
{"Episode reward": -72.61343622534586, "Episode length": 999, "Policy Loss": 0.003909121733158827, "Value Loss": 0.0013662900310009718, "_runtime": 1086.9754538536072, "_timestamp": 1585571002.8200872, "_step": 262}
{"Episode reward": -72.85897780274198, "Episode length": 999, "Policy Loss": 0.004973142873495817, "Value Loss": 0.00145427486859262, "_runtime": 1088.5266132354736, "_timestamp": 1585571004.3712466, "_step": 263}
{"Episode reward": -72.62911752343192, "Episode length": 999, "Policy Loss": -0.0009425364551134408, "Value Loss": 0.0009761700057424605, "_runtime": 1090.0760633945465, "_timestamp": 1585571005.9206967, "_step": 264}
{"Episode reward": -74.2943022009651, "Episode length": 999, "Policy Loss": 0.003276936011388898, "Value Loss": 0.0011516265803948045, "_runtime": 1091.6231379508972, "_timestamp": 1585571007.4677713, "_step": 265}
{"Episode reward": -71.68791041360798, "Episode length": 999, "Policy Loss": 0.005255908239632845, "Value Loss": 0.0014859357615932822, "_runtime": 1093.1617658138275, "_timestamp": 1585571009.0063992, "_step": 266}
{"Episode reward": -71.4215265260979, "Episode length": 999, "Policy Loss": 0.0025461737532168627, "Value Loss": 0.0012794691137969494, "_runtime": 1094.712189912796, "_timestamp": 1585571010.5568233, "_step": 267}
{"Episode reward": -72.83452266309219, "Episode length": 999, "Policy Loss": -0.00022034386347513646, "Value Loss": 0.0011323211947456002, "_runtime": 1096.286277294159, "_timestamp": 1585571012.1309106, "_step": 268}
{"Episode reward": -74.1777039644884, "Episode length": 999, "Policy Loss": 0.002192283980548382, "Value Loss": 0.001161138410679996, "_runtime": 1097.8248348236084, "_timestamp": 1585571013.6694682, "_step": 269}
{"Episode reward": -72.29059272365667, "Episode length": 999, "Policy Loss": 0.005717001389712095, "Value Loss": 0.0014228697400540113, "_runtime": 1099.3652408123016, "_timestamp": 1585571015.2098742, "_step": 270}
{"Episode reward": -72.3374884541681, "Episode length": 999, "Policy Loss": 0.0006510603125207126, "Value Loss": 0.0011768623953685164, "_runtime": 1100.8929402828217, "_timestamp": 1585571016.7375736, "_step": 271}
{"Episode reward": -72.11906720210432, "Episode length": 999, "Policy Loss": -0.0008355603204108775, "Value Loss": 0.0010424715001136065, "_runtime": 1102.435500383377, "_timestamp": 1585571018.2801337, "_step": 272}
{"Episode reward": -72.62155730957942, "Episode length": 999, "Policy Loss": 0.0015371438348665833, "Value Loss": 0.0010361835593357682, "_runtime": 1103.9914255142212, "_timestamp": 1585571019.8360589, "_step": 273}
{"Episode reward": -73.7770283417725, "Episode length": 999, "Policy Loss": 0.003343992168083787, "Value Loss": 0.0011837056372314692, "_runtime": 1105.5493433475494, "_timestamp": 1585571021.3939767, "_step": 274}
{"Episode reward": -74.35094397053714, "Episode length": 999, "Policy Loss": 0.0009858492994681, "Value Loss": 0.0009761724504642189, "_runtime": 1107.0982353687286, "_timestamp": 1585571022.9428687, "_step": 275}
{"Episode reward": -73.4419925417462, "Episode length": 999, "Policy Loss": 0.0006411655340343714, "Value Loss": 0.000999134499579668, "_runtime": 1108.635775089264, "_timestamp": 1585571024.4804084, "_step": 276}
{"Episode reward": -69.90017892291357, "Episode length": 999, "Policy Loss": 0.004323468543589115, "Value Loss": 0.0014046035939827561, "_runtime": 1110.186075925827, "_timestamp": 1585571026.0307093, "_step": 277}
{"Episode reward": -69.5346466681178, "Episode length": 999, "Policy Loss": 0.001058665569871664, "Value Loss": 0.001024471945129335, "_runtime": 1111.7351806163788, "_timestamp": 1585571027.579814, "_step": 278}
{"Episode reward": -71.80478662036536, "Episode length": 999, "Policy Loss": 0.004505753517150879, "Value Loss": 0.0013697529211640358, "_runtime": 1113.2733125686646, "_timestamp": 1585571029.117946, "_step": 279}
{"Episode reward": -71.21061514924577, "Episode length": 999, "Policy Loss": 0.004141185898333788, "Value Loss": 0.0013479564804583788, "_runtime": 1114.8229343891144, "_timestamp": 1585571030.6675677, "_step": 280}
{"Episode reward": -70.11545319385658, "Episode length": 999, "Policy Loss": 0.0009158016182482243, "Value Loss": 0.0011249392991885543, "_runtime": 1116.3514811992645, "_timestamp": 1585571032.1961145, "_step": 281}
{"Episode reward": -71.69432367794437, "Episode length": 999, "Policy Loss": 0.001720412285067141, "Value Loss": 0.0011018661316484213, "_runtime": 1117.937427997589, "_timestamp": 1585571033.7820613, "_step": 282}
{"Episode reward": -71.24696120927675, "Episode length": 999, "Policy Loss": 0.001279201707802713, "Value Loss": 0.001371511141769588, "_runtime": 1119.4866516590118, "_timestamp": 1585571035.331285, "_step": 283}
{"Episode reward": -71.57441841232212, "Episode length": 999, "Policy Loss": 0.006120874546468258, "Value Loss": 0.0015351322945207357, "_runtime": 1121.0363442897797, "_timestamp": 1585571036.8809776, "_step": 284}
{"Episode reward": -72.6299656112059, "Episode length": 999, "Policy Loss": 0.0023734052665531635, "Value Loss": 0.001195739721879363, "_runtime": 1122.5868954658508, "_timestamp": 1585571038.4315288, "_step": 285}
{"Episode reward": -72.81269067812289, "Episode length": 999, "Policy Loss": 0.0013580581871792674, "Value Loss": 0.001072359154932201, "_runtime": 1124.1259257793427, "_timestamp": 1585571039.9705591, "_step": 286}
{"Episode reward": -71.00221248229626, "Episode length": 999, "Policy Loss": 0.0006895519327372313, "Value Loss": 0.0012969692470505834, "_runtime": 1125.6757621765137, "_timestamp": 1585571041.5203955, "_step": 287}
{"Episode reward": -72.89859431658671, "Episode length": 999, "Policy Loss": 0.004249585792422295, "Value Loss": 0.0012503835605457425, "_runtime": 1127.2152848243713, "_timestamp": 1585571043.0599182, "_step": 288}
{"Episode reward": -71.35613249187853, "Episode length": 999, "Policy Loss": 0.002878298982977867, "Value Loss": 0.0010452832793816924, "_runtime": 1128.7586591243744, "_timestamp": 1585571044.6032925, "_step": 289}
{"Episode reward": -72.41562642522467, "Episode length": 999, "Policy Loss": 0.0030205289367586374, "Value Loss": 0.0011131704086437821, "_runtime": 1130.3073964118958, "_timestamp": 1585571046.1520298, "_step": 290}
{"Episode reward": -70.45163490381383, "Episode length": 999, "Policy Loss": -2.487101846782025e-05, "Value Loss": 0.0011435231426730752, "_runtime": 1131.8539333343506, "_timestamp": 1585571047.6985667, "_step": 291}
{"Episode reward": -74.62838985535201, "Episode length": 999, "Policy Loss": -0.00041832131682895124, "Value Loss": 0.001078764209523797, "_runtime": 1133.4089777469635, "_timestamp": 1585571049.253611, "_step": 292}
{"Episode reward": -70.18842203761749, "Episode length": 999, "Policy Loss": 0.003244629595428705, "Value Loss": 0.0012026451295241714, "_runtime": 1134.9498693943024, "_timestamp": 1585571050.7945027, "_step": 293}
{"Episode reward": -70.92476061075548, "Episode length": 999, "Policy Loss": 0.0012302749091759324, "Value Loss": 0.0010355167323723435, "_runtime": 1136.4999871253967, "_timestamp": 1585571052.3446205, "_step": 294}
{"Episode reward": -73.76030307836177, "Episode length": 999, "Policy Loss": 0.0009228518465533853, "Value Loss": 0.0009583947830833495, "_runtime": 1138.0361473560333, "_timestamp": 1585571053.8807807, "_step": 295}
{"Episode reward": -72.09139578455617, "Episode length": 999, "Policy Loss": 0.0004895819001831114, "Value Loss": 0.0012446939945220947, "_runtime": 1139.58678150177, "_timestamp": 1585571055.4314148, "_step": 296}
{"Episode reward": -72.54111255611818, "Episode length": 999, "Policy Loss": 0.004176658112555742, "Value Loss": 0.0013175931526347995, "_runtime": 1141.1724996566772, "_timestamp": 1585571057.017133, "_step": 297}
{"Episode reward": -72.2860198214784, "Episode length": 999, "Policy Loss": 0.0022275708615779877, "Value Loss": 0.0010726230684667826, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434, -2.1524596214294434]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1009883880615234, -2.0408573150634766, -1.9807263612747192, -1.920595407485962, -1.860464334487915, -1.8003333806991577, -1.7402024269104004, -1.6800713539123535, -1.6199404001235962, -1.5598094463348389, -1.499678373336792, -1.4395474195480347, -1.3794164657592773, -1.3192853927612305, -1.2591544389724731, -1.1990234851837158, -1.138892412185669, -1.0787614583969116, -1.0186303853988647, -0.9584994316101074, -0.8983683586120605, -0.8382374048233032, -0.7781064510345459, -0.717975378036499, -0.6578444242477417, -0.5977134704589844, -0.5375823974609375, -0.4774514436721802, -0.41732048988342285, -0.357189416885376, -0.29705846309661865, -0.23692739009857178, -0.17679643630981445, -0.11666548252105713, -0.056534528732299805, 0.0035965442657470703, 0.06372761726379395, 0.12385845184326172, 0.1839895248413086, 0.24412059783935547, 0.30425167083740234, 0.3643825054168701, 0.424513578414917, 0.48464465141296387, 0.5447754859924316, 0.6049065589904785, 0.6650376319885254, 0.7251684665679932, 0.78529953956604, 0.8454306125640869, 0.9055614471435547, 0.9656925201416016, 1.0258235931396484, 1.0859544277191162, 1.146085500717163, 1.20621657371521, 1.2663474082946777, 1.3264784812927246, 1.3866095542907715, 1.4467406272888184, 1.5068714618682861, 1.567002534866333, 1.6271336078643799, 1.6872644424438477, 1.7473955154418945]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6811277270317078, -0.6519888043403625, -0.6228498816490173, -0.5937109589576721, -0.5645720362663269, -0.5354331135749817, -0.5062942504882812, -0.47715529799461365, -0.44801637530326843, -0.4188774526119232, -0.389738529920578, -0.3605996072292328, -0.33146071434020996, -0.30232179164886475, -0.27318286895751953, -0.24404394626617432, -0.2149050235748291, -0.1857661008834839, -0.15662717819213867, -0.12748825550079346, -0.09834933280944824, -0.06921041011810303, -0.04007148742675781, -0.010932564735412598, 0.018206298351287842, 0.04734522104263306, 0.07648414373397827, 0.10562306642532349, 0.1347619891166687, 0.16390091180801392, 0.19303983449935913, 0.22217875719070435, 0.25131767988204956, 0.2804566025733948, 0.30959552526474, 0.3387344479560852, 0.3678733706474304, 0.39701229333877563, 0.42615121603012085, 0.45529013872146606, 0.4844290614128113, 0.5135679841041565, 0.5427069067955017, 0.5718458294868469, 0.6009847521781921, 0.6301236748695374, 0.6592625975608826, 0.6884015202522278, 0.7175403237342834, 0.7466792464256287, 0.7758181691169739, 0.8049570918083191, 0.8340960144996643, 0.8632349371910095, 0.8923738598823547, 0.9215127825737, 0.9506517052650452, 0.9797906279563904, 1.0089294910430908, 1.0380685329437256, 1.0672073364257812, 1.096346378326416, 1.1254851818084717, 1.1546242237091064, 1.183763027191162]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 5.0, 10.0, 11.0, 5.0, 4.0, 8.0, 10.0, 15.0, 6.0, 6.0, 12.0, 15.0, 16.0, 9.0, 30.0, 26.0, 36.0, 48.0, 39.0, 15.0, 20.0, 27.0, 13.0, 21.0, 17.0, 11.0, 6.0, 5.0, 7.0, 8.0, 3.0, 5.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.9959853887557983, -0.9566072225570679, -0.9172290563583374, -0.8778508901596069, -0.8384727239608765, -0.799094557762146, -0.7597163915634155, -0.7203382253646851, -0.6809600591659546, -0.6415818929672241, -0.6022037267684937, -0.5628255605697632, -0.5234473943710327, -0.48406922817230225, -0.4446910619735718, -0.4053128957748413, -0.36593472957611084, -0.32655656337738037, -0.2871783971786499, -0.24780023097991943, -0.20842206478118896, -0.1690438985824585, -0.12966573238372803, -0.09028756618499756, -0.05090939998626709, -0.011531233787536621, 0.027846932411193848, 0.06722509860992432, 0.10660326480865479, 0.14598143100738525, 0.18535959720611572, 0.2247377634048462, 0.26411592960357666, 0.30349409580230713, 0.3428722620010376, 0.38225042819976807, 0.42162859439849854, 0.461006760597229, 0.5003849267959595, 0.5397630929946899, 0.5791412591934204, 0.6185194253921509, 0.6578975915908813, 0.6972757577896118, 0.7366539239883423, 0.7760320901870728, 0.8154102563858032, 0.8547884225845337, 0.8941665887832642, 0.9335447549819946, 0.9729229211807251, 1.0123010873794556, 1.051679253578186, 1.0910574197769165, 1.130435585975647, 1.1698137521743774, 1.209191918373108, 1.2485700845718384, 1.2879482507705688, 1.3273264169692993, 1.3667045831680298, 1.4060827493667603, 1.4454609155654907, 1.4848390817642212, 1.5242172479629517]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.8746245503425598, -0.8468049168586731, -0.8189853429794312, -0.7911657094955444, -0.7633461356163025, -0.7355265021324158, -0.7077069282531738, -0.6798872947692871, -0.6520676612854004, -0.6242480874061584, -0.5964285135269165, -0.5686088800430298, -0.5407892465591431, -0.5129696130752563, -0.4851500391960144, -0.4573304355144501, -0.42951083183288574, -0.4016912281513214, -0.3738716244697571, -0.34605199098587036, -0.3182324171066284, -0.2904127836227417, -0.26259320974349976, -0.23477357625961304, -0.20695394277572632, -0.17913436889648438, -0.15131473541259766, -0.12349516153335571, -0.095675528049469, -0.06785595417022705, -0.04003632068634033, -0.012216746807098389, 0.01560288667678833, 0.04342252016067505, 0.07124209403991699, 0.09906172752380371, 0.12688130140304565, 0.15470093488693237, 0.1825205683708191, 0.21034008264541626, 0.23815971612930298, 0.2659793496131897, 0.2937989830970764, 0.32161861658096313, 0.3494381308555603, 0.377257764339447, 0.40507739782333374, 0.43289703130722046, 0.4607166647911072, 0.48853617906570435, 0.5163558125495911, 0.5441754460334778, 0.5719950795173645, 0.5998145937919617, 0.6276342272758484, 0.6554538607597351, 0.6832734942436218, 0.7110931277275085, 0.7389126420021057, 0.7667322754859924, 0.7945519089698792, 0.8223715424537659, 0.850191056728363, 0.8780106902122498, 0.9058303236961365]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], "bins": [-1.4505105018615723, -1.4098775386810303, -1.3692444562911987, -1.3286114931106567, -1.2879785299301147, -1.2473454475402832, -1.2067124843597412, -1.1660795211791992, -1.1254464387893677, -1.0848134756088257, -1.0441803932189941, -1.0035474300384521, -0.9629144668579102, -0.9222814440727234, -0.8816484212875366, -0.8410154581069946, -0.8003824353218079, -0.7597494125366211, -0.7191164493560791, -0.6784834265708923, -0.6378504037857056, -0.5972174406051636, -0.5565844178199768, -0.51595139503479, -0.47531843185424805, -0.4346853494644165, -0.3940523862838745, -0.3534194231033325, -0.312786340713501, -0.272153377532959, -0.231520414352417, -0.19088733196258545, -0.15025436878204346, -0.10962140560150146, -0.06898832321166992, -0.02835536003112793, 0.012277603149414062, 0.052910685539245605, 0.0935436487197876, 0.1341766119003296, 0.17480969429016113, 0.21544265747070312, 0.2560756206512451, 0.29670870304107666, 0.33734166622161865, 0.37797462940216064, 0.4186077117919922, 0.4592406749725342, 0.49987363815307617, 0.5405067205429077, 0.5811398029327393, 0.6217727661132812, 0.6624057292938232, 0.7030386924743652, 0.7436716556549072, 0.7843046188354492, 0.8249378204345703, 0.8655707836151123, 0.9062037467956543, 0.9468367099761963, 0.9874696731567383, 1.0281026363372803, 1.0687358379364014, 1.1093688011169434, 1.1500017642974854]}, "_runtime": 1142.722573518753, "_timestamp": 1585571058.5672069, "_step": 298}
{"Episode reward": -74.56698650685868, "Episode length": 999, "Policy Loss": 0.0030560134910047054, "Value Loss": 0.0012488330248743296, "_runtime": 1144.2711324691772, "_timestamp": 1585571060.1157658, "_step": 299}
{"Episode reward": -72.4784819220672, "Episode length": 999, "Policy Loss": -0.00031834025867283344, "Value Loss": 0.0010576548520475626, "_runtime": 1145.8079144954681, "_timestamp": 1585571061.6525478, "_step": 300}
{"Episode reward": -71.83781971659269, "Episode length": 999, "Policy Loss": 0.0027958054561167955, "Value Loss": 0.001088481629267335, "_runtime": 1147.3563928604126, "_timestamp": 1585571063.2010262, "_step": 301}
{"Episode reward": -71.64160169058623, "Episode length": 999, "Policy Loss": -0.0011649199295789003, "Value Loss": 0.0012296793283894658, "_runtime": 1148.8962287902832, "_timestamp": 1585571064.7408621, "_step": 302}
{"Episode reward": -71.98594885842971, "Episode length": 999, "Policy Loss": 0.001367880031466484, "Value Loss": 0.001002682140097022, "_runtime": 1150.4340796470642, "_timestamp": 1585571066.278713, "_step": 303}
{"Episode reward": -70.77321605772465, "Episode length": 999, "Policy Loss": 0.0068023549392819405, "Value Loss": 0.0015683205565437675, "_runtime": 1151.984783411026, "_timestamp": 1585571067.8294168, "_step": 304}
{"Episode reward": -73.28992353187729, "Episode length": 999, "Policy Loss": 0.0008613221580162644, "Value Loss": 0.0010911432327702641, "_runtime": 1153.5262022018433, "_timestamp": 1585571069.3708355, "_step": 305}
{"Episode reward": -72.98183704194479, "Episode length": 999, "Policy Loss": 0.0019051253329962492, "Value Loss": 0.0010527221020311117, "_runtime": 1155.0769023895264, "_timestamp": 1585571070.9215357, "_step": 306}
{"Episode reward": -72.88139386550283, "Episode length": 999, "Policy Loss": 0.0005519342375919223, "Value Loss": 0.0011667802464216948, "_runtime": 1156.6323528289795, "_timestamp": 1585571072.4769862, "_step": 307}
{"Episode reward": -70.48678083998925, "Episode length": 999, "Policy Loss": 9.379186667501926e-05, "Value Loss": 0.001349703990854323, "_runtime": 1158.1721992492676, "_timestamp": 1585571074.0168326, "_step": 308}
{"Episode reward": -72.35384455629932, "Episode length": 999, "Policy Loss": 0.003478115191683173, "Value Loss": 0.0011669225059449673, "_runtime": 1159.7201404571533, "_timestamp": 1585571075.5647738, "_step": 309}
{"Episode reward": -71.86250140205642, "Episode length": 999, "Policy Loss": 0.001353024854324758, "Value Loss": 0.0010097456397488713, "_runtime": 1161.2583639621735, "_timestamp": 1585571077.1029973, "_step": 310}
{"Episode reward": -70.84422988424657, "Episode length": 999, "Policy Loss": 0.0016034594736993313, "Value Loss": 0.0010799012379720807, "_runtime": 1162.800707578659, "_timestamp": 1585571078.645341, "_step": 311}
{"Episode reward": -69.34737421740451, "Episode length": 999, "Policy Loss": 0.002415681490674615, "Value Loss": 0.0012359046377241611, "_runtime": 1164.389568567276, "_timestamp": 1585571080.234202, "_step": 312}
{"Episode reward": -70.69798561543367, "Episode length": 999, "Policy Loss": 0.0007960492512211204, "Value Loss": 0.0011930582113564014, "_runtime": 1165.940388917923, "_timestamp": 1585571081.7850223, "_step": 313}
{"Episode reward": -70.72241281494568, "Episode length": 999, "Policy Loss": 0.003561051096767187, "Value Loss": 0.0010855089640244842, "_runtime": 1167.4909913539886, "_timestamp": 1585571083.3356247, "_step": 314}
{"Episode reward": -72.77090382142448, "Episode length": 999, "Policy Loss": 0.0009877398842945695, "Value Loss": 0.0009579037432558835, "_runtime": 1169.0396649837494, "_timestamp": 1585571084.8842983, "_step": 315}
{"Episode reward": -71.96680935122143, "Episode length": 999, "Policy Loss": 0.0013425645884126425, "Value Loss": 0.001070356578566134, "_runtime": 1170.5683171749115, "_timestamp": 1585571086.4129505, "_step": 316}
{"Episode reward": -74.26043024130911, "Episode length": 999, "Policy Loss": 0.003346783807501197, "Value Loss": 0.0012980885803699493, "_runtime": 1172.1183829307556, "_timestamp": 1585571087.9630163, "_step": 317}
{"Episode reward": -72.58242972429508, "Episode length": 999, "Policy Loss": -0.0003712118195835501, "Value Loss": 0.001145785441622138, "_runtime": 1173.6677458286285, "_timestamp": 1585571089.5123792, "_step": 318}
{"Episode reward": -71.35076141011345, "Episode length": 999, "Policy Loss": -0.0018116211285814643, "Value Loss": 0.0010881111957132816, "_runtime": 1175.2194375991821, "_timestamp": 1585571091.064071, "_step": 319}
{"Episode reward": -71.8941159440347, "Episode length": 999, "Policy Loss": 0.0014639345463365316, "Value Loss": 0.0009493029792793095, "_runtime": 1176.770034790039, "_timestamp": 1585571092.6146681, "_step": 320}
{"Episode reward": -72.43398432916177, "Episode length": 999, "Policy Loss": -0.0006736866198480129, "Value Loss": 0.001107986900024116, "_runtime": 1178.323689699173, "_timestamp": 1585571094.168323, "_step": 321}
{"Episode reward": -73.1765671559208, "Episode length": 999, "Policy Loss": 0.0035482505336403847, "Value Loss": 0.0013533822493627667, "_runtime": 1179.873060464859, "_timestamp": 1585571095.7176938, "_step": 322}
{"Episode reward": -71.29082952646225, "Episode length": 999, "Policy Loss": -0.0003376870881766081, "Value Loss": 0.0012282130774110556, "_runtime": 1181.40189909935, "_timestamp": 1585571097.2465324, "_step": 323}
{"Episode reward": -73.48535919754431, "Episode length": 999, "Policy Loss": 0.003259858349338174, "Value Loss": 0.000969978456851095, "_runtime": 1182.9428679943085, "_timestamp": 1585571098.7875013, "_step": 324}
{"Episode reward": -70.87134851178567, "Episode length": 999, "Policy Loss": 0.0012216942850500345, "Value Loss": 0.0010898301843553782, "_runtime": 1184.4934990406036, "_timestamp": 1585571100.3381324, "_step": 325}
{"Episode reward": -70.65211030232703, "Episode length": 999, "Policy Loss": -0.00035067397402599454, "Value Loss": 0.001062588533386588, "_runtime": 1186.0415744781494, "_timestamp": 1585571101.8862078, "_step": 326}
{"Episode reward": -71.79302122490526, "Episode length": 999, "Policy Loss": -0.00019584622350521386, "Value Loss": 0.0011461444664746523, "_runtime": 1187.625764131546, "_timestamp": 1585571103.4703975, "_step": 327}
{"Episode reward": -74.06055286443062, "Episode length": 999, "Policy Loss": 0.003195081604644656, "Value Loss": 0.00111131661105901, "_runtime": 1189.1791920661926, "_timestamp": 1585571105.0238254, "_step": 328}
{"Episode reward": -73.64566133969134, "Episode length": 999, "Policy Loss": -0.000505985866766423, "Value Loss": 0.0010898234322667122, "_runtime": 1190.7275450229645, "_timestamp": 1585571106.5721784, "_step": 329}
{"Episode reward": -73.36335245202018, "Episode length": 999, "Policy Loss": 0.0026086329016834497, "Value Loss": 0.0009782143170014024, "_runtime": 1192.2649097442627, "_timestamp": 1585571108.109543, "_step": 330}
{"Episode reward": -71.14477344726303, "Episode length": 999, "Policy Loss": 0.0003826935717370361, "Value Loss": 0.0011242126347497106, "_runtime": 1193.815910100937, "_timestamp": 1585571109.6605434, "_step": 331}
{"Episode reward": -70.35239730869004, "Episode length": 999, "Policy Loss": 0.0002803979441523552, "Value Loss": 0.0011868529254570603, "_runtime": 1195.3660066127777, "_timestamp": 1585571111.21064, "_step": 332}
{"Episode reward": -72.68453871955661, "Episode length": 999, "Policy Loss": 0.00245989509858191, "Value Loss": 0.0010362998582422733, "_runtime": 1196.9196982383728, "_timestamp": 1585571112.7643316, "_step": 333}
{"Episode reward": -71.02634624117805, "Episode length": 999, "Policy Loss": -0.0011851998278871179, "Value Loss": 0.0011623785831034184, "_runtime": 1198.471429347992, "_timestamp": 1585571114.3160627, "_step": 334}
{"Episode reward": -70.30583666181255, "Episode length": 999, "Policy Loss": 0.0012915455736219883, "Value Loss": 0.001080881105735898, "_runtime": 1200.0210728645325, "_timestamp": 1585571115.8657062, "_step": 335}
{"Episode reward": -70.7743742868711, "Episode length": 999, "Policy Loss": 0.0006397411343641579, "Value Loss": 0.0012553344713523984, "_runtime": 1201.5625598430634, "_timestamp": 1585571117.4071932, "_step": 336}
{"Episode reward": -73.14666063387412, "Episode length": 999, "Policy Loss": 0.0016965449322015047, "Value Loss": 0.00109449855517596, "_runtime": 1203.0916631221771, "_timestamp": 1585571118.9362965, "_step": 337}
{"Episode reward": -72.10161339621156, "Episode length": 999, "Policy Loss": 0.003110362682491541, "Value Loss": 0.0010463251965120435, "_runtime": 1204.6419956684113, "_timestamp": 1585571120.486629, "_step": 338}
{"Episode reward": -71.38972324851126, "Episode length": 999, "Policy Loss": 0.004273919388651848, "Value Loss": 0.0011344413505867124, "_runtime": 1206.1753897666931, "_timestamp": 1585571122.020023, "_step": 339}
{"Episode reward": -73.53334876377497, "Episode length": 999, "Policy Loss": 0.004608155693858862, "Value Loss": 0.0012824867153540254, "_runtime": 1207.7283256053925, "_timestamp": 1585571123.572959, "_step": 340}
{"Episode reward": -70.70730870105494, "Episode length": 999, "Policy Loss": -2.4038074116106145e-05, "Value Loss": 0.0011437238426879048, "_runtime": 1209.3041536808014, "_timestamp": 1585571125.148787, "_step": 341}
{"Episode reward": -71.64432361161592, "Episode length": 999, "Policy Loss": -0.0008246835204772651, "Value Loss": 0.0011976814130321145, "_runtime": 1210.8545455932617, "_timestamp": 1585571126.699179, "_step": 342}
{"Episode reward": -72.93844751730795, "Episode length": 999, "Policy Loss": 0.0015945382183417678, "Value Loss": 0.0009334510541521013, "_runtime": 1212.4033994674683, "_timestamp": 1585571128.2480328, "_step": 343}
{"Episode reward": -72.05136811703557, "Episode length": 999, "Policy Loss": 0.001375550520606339, "Value Loss": 0.000935976451728493, "_runtime": 1213.945637702942, "_timestamp": 1585571129.790271, "_step": 344}
{"Episode reward": -74.36027575498231, "Episode length": 999, "Policy Loss": 0.0010716160759329796, "Value Loss": 0.0009381907875649631, "_runtime": 1215.4934616088867, "_timestamp": 1585571131.338095, "_step": 345}
{"Episode reward": -72.50892015795996, "Episode length": 999, "Policy Loss": 0.0031224358826875687, "Value Loss": 0.001299588824622333, "_runtime": 1217.0415155887604, "_timestamp": 1585571132.886149, "_step": 346}
{"Episode reward": -73.04597624450545, "Episode length": 999, "Policy Loss": -0.00043121943599544466, "Value Loss": 0.0010049360571429133, "_runtime": 1218.5917418003082, "_timestamp": 1585571134.4363751, "_step": 347}
{"Episode reward": -70.10159842852062, "Episode length": 999, "Policy Loss": 0.0034066529478877783, "Value Loss": 0.0012524775229394436, "_runtime": 1220.150638103485, "_timestamp": 1585571135.9952714, "_step": 348}
{"Episode reward": -72.13636742987192, "Episode length": 999, "Policy Loss": 0.0013333584647625685, "Value Loss": 0.0010195121867582202, "_runtime": 1221.7036468982697, "_timestamp": 1585571137.5482802, "_step": 349}
{"Episode reward": -72.86731020838623, "Episode length": 999, "Policy Loss": -0.00036057562101632357, "Value Loss": 0.0010749099310487509, "_runtime": 1223.2563889026642, "_timestamp": 1585571139.1010222, "_step": 350}
{"Episode reward": -70.74766910610342, "Episode length": 999, "Policy Loss": 0.0015651442809030414, "Value Loss": 0.001040506991557777, "_runtime": 1224.8101289272308, "_timestamp": 1585571140.6547623, "_step": 351}
{"Episode reward": -72.16415135527504, "Episode length": 999, "Policy Loss": 0.003125356277450919, "Value Loss": 0.0009758397354744375, "_runtime": 1226.3585333824158, "_timestamp": 1585571142.2031667, "_step": 352}
{"Episode reward": -71.87721401692284, "Episode length": 999, "Policy Loss": 0.0056428806856274605, "Value Loss": 0.001564734848216176, "_runtime": 1227.9231934547424, "_timestamp": 1585571143.7678268, "_step": 353}
{"Episode reward": -70.92296124481229, "Episode length": 999, "Policy Loss": 0.0010186557192355394, "Value Loss": 0.0010885734809562564, "_runtime": 1229.4881792068481, "_timestamp": 1585571145.3328125, "_step": 354}
{"Episode reward": -73.17952170700589, "Episode length": 999, "Policy Loss": 0.0014768991386517882, "Value Loss": 0.0009000447462312877, "_runtime": 1231.0527639389038, "_timestamp": 1585571146.8973973, "_step": 355}
{"Episode reward": -71.83366904309297, "Episode length": 999, "Policy Loss": 0.002689436310902238, "Value Loss": 0.0011244466295465827, "_runtime": 1232.6527478694916, "_timestamp": 1585571148.4973812, "_step": 356}
{"Episode reward": -71.26063337275313, "Episode length": 999, "Policy Loss": 0.004785337019711733, "Value Loss": 0.0012950743548572063, "_runtime": 1234.21568608284, "_timestamp": 1585571150.0603194, "_step": 357}
{"Episode reward": -70.9754070999345, "Episode length": 999, "Policy Loss": 0.006022993475198746, "Value Loss": 0.0012470103101804852, "_runtime": 1235.7795786857605, "_timestamp": 1585571151.624212, "_step": 358}
{"Episode reward": -71.75639182649496, "Episode length": 999, "Policy Loss": -9.914583642967045e-05, "Value Loss": 0.001194765092805028, "_runtime": 1237.343413591385, "_timestamp": 1585571153.188047, "_step": 359}
{"Episode reward": -72.11088796469659, "Episode length": 999, "Policy Loss": 0.0018878820119425654, "Value Loss": 0.0009830062044784427, "_runtime": 1238.9071803092957, "_timestamp": 1585571154.7518137, "_step": 360}
{"Episode reward": -72.36894764376417, "Episode length": 999, "Policy Loss": 0.0008468080195598304, "Value Loss": 0.00099967943970114, "_runtime": 1240.4680998325348, "_timestamp": 1585571156.3127332, "_step": 361}
{"Episode reward": -71.33948346276186, "Episode length": 999, "Policy Loss": 0.0004709541390184313, "Value Loss": 0.0011364404344931245, "_runtime": 1242.0314004421234, "_timestamp": 1585571157.8760338, "_step": 362}
{"Episode reward": -70.71498649384486, "Episode length": 999, "Policy Loss": 0.000697007984854281, "Value Loss": 0.001163749024271965, "_runtime": 1243.5930325984955, "_timestamp": 1585571159.437666, "_step": 363}
{"Episode reward": -71.40234762939885, "Episode length": 999, "Policy Loss": 0.004072241950780153, "Value Loss": 0.000982256606221199, "_runtime": 1245.1561748981476, "_timestamp": 1585571161.0008082, "_step": 364}
{"Episode reward": -71.95129044633359, "Episode length": 999, "Policy Loss": 0.005710723344236612, "Value Loss": 0.0015658519696444273, "_runtime": 1246.7191574573517, "_timestamp": 1585571162.5637908, "_step": 365}
{"Episode reward": -70.72949045531067, "Episode length": 999, "Policy Loss": 0.0014233870897442102, "Value Loss": 0.0009953476255759597, "_runtime": 1248.2708287239075, "_timestamp": 1585571164.115462, "_step": 366}
{"Episode reward": -72.43091925686075, "Episode length": 999, "Policy Loss": 0.003527419874444604, "Value Loss": 0.0009638459305278957, "_runtime": 1249.8246903419495, "_timestamp": 1585571165.6693237, "_step": 367}
{"Episode reward": -72.13901467351532, "Episode length": 999, "Policy Loss": 0.002183483215048909, "Value Loss": 0.0010485817911103368, "_runtime": 1251.3877601623535, "_timestamp": 1585571167.2323935, "_step": 368}
{"Episode reward": -70.76140560423522, "Episode length": 999, "Policy Loss": 0.00021204096265137196, "Value Loss": 0.0011086190352216363, "_runtime": 1252.9486198425293, "_timestamp": 1585571168.7932532, "_step": 369}
{"Episode reward": -69.40787565782784, "Episode length": 999, "Policy Loss": 0.0020517180673778057, "Value Loss": 0.0010191221954301, "_runtime": 1254.5126667022705, "_timestamp": 1585571170.3573, "_step": 370}
{"Episode reward": -71.88771094256796, "Episode length": 999, "Policy Loss": -0.00012339242675807327, "Value Loss": 0.0011414655018597841, "_runtime": 1256.1129357814789, "_timestamp": 1585571171.9575691, "_step": 371}
{"Episode reward": -72.69468175547547, "Episode length": 999, "Policy Loss": -0.00192371872253716, "Value Loss": 0.001001741155050695, "_runtime": 1257.6557838916779, "_timestamp": 1585571173.5004172, "_step": 372}
{"Episode reward": -71.7528849240423, "Episode length": 999, "Policy Loss": 0.0025409338995814323, "Value Loss": 0.0010719833662733436, "_runtime": 1259.2218379974365, "_timestamp": 1585571175.0664713, "_step": 373}
{"Episode reward": -72.65843578344804, "Episode length": 999, "Policy Loss": 0.002310930285602808, "Value Loss": 0.0010898590553551912, "_runtime": 1260.7878217697144, "_timestamp": 1585571176.632455, "_step": 374}
{"Episode reward": -72.20222263605032, "Episode length": 999, "Policy Loss": 0.0010866723023355007, "Value Loss": 0.0009587074746377766, "_runtime": 1262.339334487915, "_timestamp": 1585571178.1839678, "_step": 375}
{"Episode reward": -73.03228264552104, "Episode length": 999, "Policy Loss": 0.0007233237847685814, "Value Loss": 0.0011125558521598577, "_runtime": 1263.905196905136, "_timestamp": 1585571179.7498302, "_step": 376}
{"Episode reward": -69.25348420008106, "Episode length": 999, "Policy Loss": 0.004097023978829384, "Value Loss": 0.0010142382234334946, "_runtime": 1265.4682834148407, "_timestamp": 1585571181.3129168, "_step": 377}
{"Episode reward": -73.56250080826958, "Episode length": 999, "Policy Loss": 0.0016688547329977155, "Value Loss": 0.0008632916724309325, "_runtime": 1267.0204272270203, "_timestamp": 1585571182.8650606, "_step": 378}
{"Episode reward": -71.62786217131571, "Episode length": 999, "Policy Loss": 0.0035363584756851196, "Value Loss": 0.001049051177687943, "_runtime": 1268.575730085373, "_timestamp": 1585571184.4203634, "_step": 379}
{"Episode reward": -72.57304287467312, "Episode length": 999, "Policy Loss": 0.0009637902840040624, "Value Loss": 0.001040783361531794, "_runtime": 1270.1447327136993, "_timestamp": 1585571185.989366, "_step": 380}
{"Episode reward": -72.8402486391407, "Episode length": 999, "Policy Loss": -2.5228697268175893e-05, "Value Loss": 0.0010131420567631721, "_runtime": 1271.708129644394, "_timestamp": 1585571187.552763, "_step": 381}
{"Episode reward": -71.49116877467186, "Episode length": 999, "Policy Loss": 0.0034464336931705475, "Value Loss": 0.001479125116020441, "_runtime": 1273.2637991905212, "_timestamp": 1585571189.1084325, "_step": 382}
{"Episode reward": -71.66872122573132, "Episode length": 999, "Policy Loss": 0.0006171604618430138, "Value Loss": 0.0009937887080013752, "_runtime": 1274.8204038143158, "_timestamp": 1585571190.6650372, "_step": 383}
{"Episode reward": -72.92933545596784, "Episode length": 999, "Policy Loss": 0.004661713261157274, "Value Loss": 0.0014198527205735445, "_runtime": 1276.3817903995514, "_timestamp": 1585571192.2264237, "_step": 384}
{"Episode reward": -71.98780176647477, "Episode length": 999, "Policy Loss": 0.001932960469275713, "Value Loss": 0.0009282755781896412, "_runtime": 1277.9426379203796, "_timestamp": 1585571193.7872713, "_step": 385}
{"Episode reward": -71.42654457927523, "Episode length": 999, "Policy Loss": 0.0031029721722006798, "Value Loss": 0.0012521963799372315, "_runtime": 1279.5201189517975, "_timestamp": 1585571195.3647523, "_step": 386}
{"Episode reward": -73.29360487364116, "Episode length": 999, "Policy Loss": 0.0013064625672996044, "Value Loss": 0.001041690236888826, "_runtime": 1281.0817449092865, "_timestamp": 1585571196.9263783, "_step": 387}
{"Episode reward": -72.13108059142175, "Episode length": 999, "Policy Loss": 0.0016177685465663671, "Value Loss": 0.0009163865470327437, "_runtime": 1282.644919872284, "_timestamp": 1585571198.4895532, "_step": 388}
{"Episode reward": -72.35466693265045, "Episode length": 999, "Policy Loss": 0.001148835988715291, "Value Loss": 0.0008926708251237869, "_runtime": 1284.199002981186, "_timestamp": 1585571200.0436363, "_step": 389}
{"Episode reward": -73.50247381803838, "Episode length": 999, "Policy Loss": 0.0010784307960420847, "Value Loss": 0.001168358139693737, "_runtime": 1285.7637267112732, "_timestamp": 1585571201.60836, "_step": 390}
{"Episode reward": -71.50643256332367, "Episode length": 999, "Policy Loss": 0.00168178032618016, "Value Loss": 0.0008883619448170066, "_runtime": 1287.3232100009918, "_timestamp": 1585571203.1678433, "_step": 391}
{"Episode reward": -70.49901808223122, "Episode length": 999, "Policy Loss": 0.0032554285135120153, "Value Loss": 0.0010706954635679722, "_runtime": 1288.884230852127, "_timestamp": 1585571204.7288642, "_step": 392}
{"Episode reward": -71.0580894206188, "Episode length": 999, "Policy Loss": 0.004222394898533821, "Value Loss": 0.0013082906370982528, "_runtime": 1290.424663066864, "_timestamp": 1585571206.2692964, "_step": 393}
{"Episode reward": -70.9095942596559, "Episode length": 999, "Policy Loss": 0.0003727486764546484, "Value Loss": 0.0010867303935810924, "_runtime": 1291.9854109287262, "_timestamp": 1585571207.8300443, "_step": 394}
{"Episode reward": -72.84313435452077, "Episode length": 999, "Policy Loss": -0.00017577018297743052, "Value Loss": 0.0009616939933039248, "_runtime": 1293.546273946762, "_timestamp": 1585571209.3909073, "_step": 395}
{"Episode reward": -72.9140704611955, "Episode length": 999, "Policy Loss": 0.0018957086140289903, "Value Loss": 0.0009665075340308249, "_runtime": 1295.1063764095306, "_timestamp": 1585571210.9510098, "_step": 396}
{"Episode reward": -70.53161152458823, "Episode length": 999, "Policy Loss": 0.0034671626053750515, "Value Loss": 0.0010801556054502726, "_runtime": 1296.6375985145569, "_timestamp": 1585571212.4822319, "_step": 397}
{"Episode reward": -71.28831538890233, "Episode length": 999, "Policy Loss": 0.003191650379449129, "Value Loss": 0.001040593720972538, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874, 1.9104541540145874]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.8862988948822021, -1.814598798751831, -1.74289870262146, -1.6711987257003784, -1.5994986295700073, -1.5277985334396362, -1.4560985565185547, -1.3843984603881836, -1.3126983642578125, -1.2409982681274414, -1.1692981719970703, -1.0975981950759888, -1.0258980989456177, -0.9541980028152466, -0.882498025894165, -0.810797929763794, -0.7390978336334229, -0.6673977375030518, -0.5956976413726807, -0.5239976644515991, -0.452297568321228, -0.38059747219085693, -0.3088974952697754, -0.2371973991394043, -0.1654973030090332, -0.09379720687866211, -0.022097110748291016, 0.04960286617279053, 0.12130284309387207, 0.19300293922424316, 0.26470303535461426, 0.33640313148498535, 0.40810322761535645, 0.47980332374572754, 0.5515034198760986, 0.6232035160064697, 0.6949036121368408, 0.7666034698486328, 0.8383035659790039, 0.910003662109375, 0.9817037582397461, 1.0534038543701172, 1.1251039505004883, 1.1968040466308594, 1.2685039043426514, 1.3402040004730225, 1.4119040966033936, 1.4836041927337646, 1.5553042888641357, 1.6270043849945068, 1.698704481124878, 1.770404577255249, 1.8421046733856201, 1.913804531097412, 1.9855046272277832, 2.0572047233581543, 2.1289045810699463, 2.2006046772003174, 2.2723047733306885, 2.3440048694610596, 2.4157049655914307, 2.4874050617218018, 2.559105157852173, 2.630805253982544, 2.702505350112915]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.0506280660629272, -1.0251604318618774, -0.9996926784515381, -0.9742249846458435, -0.9487572908401489, -0.9232896566390991, -0.8978219032287598, -0.87235426902771, -0.8468865752220154, -0.8214188814163208, -0.7959511876106262, -0.7704834938049316, -0.7450157999992371, -0.7195481061935425, -0.6940804719924927, -0.6686127185821533, -0.6431450843811035, -0.6176773309707642, -0.5922096967697144, -0.5667420029640198, -0.5412743091583252, -0.5158066153526306, -0.49033892154693604, -0.46487122774124146, -0.4394035339355469, -0.4139358401298523, -0.3884681463241577, -0.3630005121231079, -0.33753281831741333, -0.31206512451171875, -0.28659743070602417, -0.2611297369003296, -0.235662043094635, -0.21019434928894043, -0.18472665548324585, -0.15925896167755127, -0.1337912678718567, -0.10832357406616211, -0.0828559398651123, -0.057388246059417725, -0.031920552253723145, -0.006452798843383789, 0.019014835357666016, 0.04448246955871582, 0.06995022296905518, 0.09541785717010498, 0.12088561058044434, 0.14635324478149414, 0.1718209981918335, 0.1972886323928833, 0.22275638580322266, 0.24822402000427246, 0.2736917734146118, 0.2991594076156616, 0.3246270418167114, 0.3500947952270508, 0.3755624294281006, 0.40103018283843994, 0.42649781703948975, 0.4519655704498291, 0.4774332046508789, 0.5029009580612183, 0.5283685922622681, 0.5538363456726074, 0.5793039798736572]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 5.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 2.0, 8.0, 9.0, 16.0, 19.0, 11.0, 16.0, 22.0, 27.0, 35.0, 52.0, 44.0, 31.0, 33.0, 18.0, 24.0, 8.0, 12.0, 13.0, 9.0, 10.0, 4.0, 7.0, 5.0, 3.0, 6.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0], "bins": [-1.7201883792877197, -1.6758424043655396, -1.6314964294433594, -1.5871503353118896, -1.5428043603897095, -1.4984583854675293, -1.4541124105453491, -1.409766435623169, -1.3654203414916992, -1.321074366569519, -1.2767283916473389, -1.2323824167251587, -1.1880364418029785, -1.1436903476715088, -1.0993444919586182, -1.0549983978271484, -1.0106524229049683, -0.9663064479827881, -0.9219604134559631, -0.877614438533783, -0.833268404006958, -0.7889224290847778, -0.7445764541625977, -0.7002304792404175, -0.6558845043182373, -0.6115384101867676, -0.5671924352645874, -0.5228464603424072, -0.47850048542022705, -0.4341545104980469, -0.38980841636657715, -0.345462441444397, -0.3011164665222168, -0.2567704916000366, -0.21242451667785645, -0.16807842254638672, -0.12373244762420654, -0.07938647270202637, -0.03504049777984619, 0.009305477142333984, 0.05365157127380371, 0.09799754619598389, 0.14234352111816406, 0.18668949604034424, 0.23103547096252441, 0.2753814458847046, 0.31972742080688477, 0.3640735149383545, 0.4084193706512451, 0.45276546478271484, 0.49711155891418457, 0.5414574146270752, 0.5858035087585449, 0.6301493644714355, 0.6744954586029053, 0.718841552734375, 0.7631874084472656, 0.8075335025787354, 0.851879358291626, 0.8962254524230957, 0.9405715465545654, 0.984917402267456, 1.0292634963989258, 1.0736093521118164, 1.1179554462432861]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7706930041313171, -0.7465988397598267, -0.7225046753883362, -0.6984105110168457, -0.6743163466453552, -0.6502221822738647, -0.6261279582977295, -0.6020338535308838, -0.5779396295547485, -0.5538455247879028, -0.5297513008117676, -0.5056571960449219, -0.4815629720687866, -0.45746880769729614, -0.43337464332580566, -0.4092804789543152, -0.3851863145828247, -0.36109215021133423, -0.33699798583984375, -0.31290382146835327, -0.2888096570968628, -0.2647154927253723, -0.24062132835388184, -0.21652716398239136, -0.1924329400062561, -0.16833877563476562, -0.14424461126327515, -0.12015044689178467, -0.09605628252029419, -0.07196211814880371, -0.04786795377731323, -0.023773789405822754, 0.0003203749656677246, 0.024414539337158203, 0.04850870370864868, 0.07260286808013916, 0.09669703245162964, 0.12079119682312012, 0.1448853611946106, 0.16897952556610107, 0.19307368993759155, 0.2171679139137268, 0.2412620186805725, 0.26535624265670776, 0.28945034742355347, 0.3135445713996887, 0.3376386761665344, 0.3617329001426697, 0.38582712411880493, 0.40992122888565063, 0.4340154528617859, 0.4581095576286316, 0.48220378160476685, 0.5062978863716125, 0.5303921103477478, 0.5544862151145935, 0.5785804390907288, 0.6026745438575745, 0.6267687678337097, 0.6508628726005554, 0.6749570965766907, 0.6990512013435364, 0.7231454253196716, 0.7472395300865173, 0.7713337540626526]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.0115725994110107, -1.9429879188537598, -1.8744032382965088, -1.8058185577392578, -1.7372338771820068, -1.6686491966247559, -1.6000645160675049, -1.531479835510254, -1.462895154953003, -1.394310474395752, -1.325725793838501, -1.25714111328125, -1.1885563135147095, -1.1199716329574585, -1.0513869524002075, -0.9828022718429565, -0.9142175912857056, -0.8456329107284546, -0.7770482301712036, -0.7084635496139526, -0.6398788690567017, -0.5712941884994507, -0.5027095079421997, -0.43412482738494873, -0.3655400276184082, -0.2969553470611572, -0.22837066650390625, -0.15978598594665527, -0.0912013053894043, -0.02261662483215332, 0.045968055725097656, 0.11455273628234863, 0.1831374168395996, 0.2517220973968506, 0.32030677795410156, 0.38889145851135254, 0.4574761390686035, 0.5260608196258545, 0.5946455001831055, 0.6632301807403564, 0.7318148612976074, 0.8003995418548584, 0.8689842224121094, 0.9375689029693604, 1.0061535835266113, 1.0747382640838623, 1.1433229446411133, 1.2119076251983643, 1.2804925441741943, 1.3490772247314453, 1.4176619052886963, 1.4862465858459473, 1.5548312664031982, 1.6234159469604492, 1.6920006275177002, 1.7605853080749512, 1.8291699886322021, 1.8977546691894531, 1.966339349746704, 2.034923791885376, 2.103508710861206, 2.172093152999878, 2.240678071975708, 2.30926251411438, 2.37784743309021]}, "_runtime": 1298.1858224868774, "_timestamp": 1585571214.0304558, "_step": 398}
{"Episode reward": -70.41256307707661, "Episode length": 999, "Policy Loss": 0.003513648174703121, "Value Loss": 0.001026101759634912, "_runtime": 1299.731392621994, "_timestamp": 1585571215.576026, "_step": 399}
{"Episode reward": -71.12889418599556, "Episode length": 999, "Policy Loss": 0.0026366885285824537, "Value Loss": 0.0010051733115687966, "_runtime": 1301.2694470882416, "_timestamp": 1585571217.1140804, "_step": 400}
{"Episode reward": -70.5044616453784, "Episode length": 999, "Policy Loss": 0.002848460106179118, "Value Loss": 0.0010400384198874235, "_runtime": 1302.849867105484, "_timestamp": 1585571218.6945004, "_step": 401}
{"Episode reward": -72.23444340943267, "Episode length": 999, "Policy Loss": 2.740435411396902e-05, "Value Loss": 0.0010074785677716136, "_runtime": 1304.3891077041626, "_timestamp": 1585571220.233741, "_step": 402}
{"Episode reward": -72.87024205956112, "Episode length": 999, "Policy Loss": -2.3030808733892627e-05, "Value Loss": 0.0010578965302556753, "_runtime": 1305.9249320030212, "_timestamp": 1585571221.7695653, "_step": 403}
{"Episode reward": -72.09382507407975, "Episode length": 999, "Policy Loss": 0.0009132484556175768, "Value Loss": 0.0009753934573382139, "_runtime": 1307.4690277576447, "_timestamp": 1585571223.313661, "_step": 404}
{"Episode reward": -72.84137704266908, "Episode length": 999, "Policy Loss": 0.0005132970400154591, "Value Loss": 0.0008207764476537704, "_runtime": 1309.0094633102417, "_timestamp": 1585571224.8540967, "_step": 405}
{"Episode reward": -71.97911002098178, "Episode length": 999, "Policy Loss": 0.00232210592366755, "Value Loss": 0.0010082469088956714, "_runtime": 1310.5534446239471, "_timestamp": 1585571226.398078, "_step": 406}
{"Episode reward": -71.8214491579899, "Episode length": 999, "Policy Loss": 0.0017446443671360612, "Value Loss": 0.0010456733871251345, "_runtime": 1312.0839409828186, "_timestamp": 1585571227.9285743, "_step": 407}
{"Episode reward": -74.42941083255127, "Episode length": 999, "Policy Loss": 0.0007057685288600624, "Value Loss": 0.0008799003553576767, "_runtime": 1313.6302797794342, "_timestamp": 1585571229.4749131, "_step": 408}
{"Episode reward": -70.79377194631535, "Episode length": 999, "Policy Loss": 0.0034786087926477194, "Value Loss": 0.0010939316125586629, "_runtime": 1315.1703028678894, "_timestamp": 1585571231.0149362, "_step": 409}
{"Episode reward": -73.48857578117725, "Episode length": 999, "Policy Loss": 0.0028635188937187195, "Value Loss": 0.001099511981010437, "_runtime": 1316.7071542739868, "_timestamp": 1585571232.5517876, "_step": 410}
{"Episode reward": -71.2897365944024, "Episode length": 999, "Policy Loss": 0.0030732834711670876, "Value Loss": 0.0010631821351125836, "_runtime": 1318.2479345798492, "_timestamp": 1585571234.092568, "_step": 411}
{"Episode reward": -73.52504548824199, "Episode length": 999, "Policy Loss": 0.004201625473797321, "Value Loss": 0.0013027614913880825, "_runtime": 1319.796002149582, "_timestamp": 1585571235.6406355, "_step": 412}
{"Episode reward": -71.55773628372495, "Episode length": 999, "Policy Loss": -0.0005742491921409965, "Value Loss": 0.000928104913327843, "_runtime": 1321.3298180103302, "_timestamp": 1585571237.1744514, "_step": 413}
{"Episode reward": -71.25740038971655, "Episode length": 999, "Policy Loss": 0.0009205516544170678, "Value Loss": 0.0010752453235909343, "_runtime": 1322.8747203350067, "_timestamp": 1585571238.7193537, "_step": 414}
{"Episode reward": -72.36913844142717, "Episode length": 999, "Policy Loss": -0.0006185916136018932, "Value Loss": 0.0010950729483738542, "_runtime": 1324.4542763233185, "_timestamp": 1585571240.2989097, "_step": 415}
{"Episode reward": -72.00399821091418, "Episode length": 999, "Policy Loss": 0.004114968236535788, "Value Loss": 0.0009763161651790142, "_runtime": 1326.003294467926, "_timestamp": 1585571241.8479278, "_step": 416}
{"Episode reward": -69.50896286440707, "Episode length": 999, "Policy Loss": 0.004391818773001432, "Value Loss": 0.0013565164990723133, "_runtime": 1327.548707485199, "_timestamp": 1585571243.3933408, "_step": 417}
{"Episode reward": -70.90671548534071, "Episode length": 999, "Policy Loss": 0.0019601827953010798, "Value Loss": 0.0008835401968099177, "_runtime": 1329.0906307697296, "_timestamp": 1585571244.935264, "_step": 418}
{"Episode reward": -72.04755488439288, "Episode length": 999, "Policy Loss": 0.0037175146862864494, "Value Loss": 0.0010700521524995565, "_runtime": 1330.6256799697876, "_timestamp": 1585571246.4703133, "_step": 419}
{"Episode reward": -72.60312924946905, "Episode length": 999, "Policy Loss": 0.0010716556571424007, "Value Loss": 0.001101308036595583, "_runtime": 1332.1563198566437, "_timestamp": 1585571248.0009532, "_step": 420}
{"Episode reward": -72.60462976436872, "Episode length": 999, "Policy Loss": 0.0005503755528479815, "Value Loss": 0.0010514636524021626, "_runtime": 1333.687679052353, "_timestamp": 1585571249.5323124, "_step": 421}
{"Episode reward": -71.7791370418966, "Episode length": 999, "Policy Loss": 0.00693031819537282, "Value Loss": 0.0014154049567878246, "_runtime": 1335.2314655780792, "_timestamp": 1585571251.076099, "_step": 422}
{"Episode reward": -70.43115023419189, "Episode length": 999, "Policy Loss": 0.0030999917071312666, "Value Loss": 0.0011168316705152392, "_runtime": 1336.7769048213959, "_timestamp": 1585571252.6215382, "_step": 423}
{"Episode reward": -71.84467899838674, "Episode length": 999, "Policy Loss": 7.201373227871954e-05, "Value Loss": 0.0010244575096294284, "_runtime": 1338.3198039531708, "_timestamp": 1585571254.1644373, "_step": 424}
{"Episode reward": -69.95246066093652, "Episode length": 999, "Policy Loss": -0.0005381529917940497, "Value Loss": 0.0010139491641893983, "_runtime": 1339.8629403114319, "_timestamp": 1585571255.7075737, "_step": 425}
{"Episode reward": -72.31459902170539, "Episode length": 999, "Policy Loss": 0.003005232661962509, "Value Loss": 0.0010867048986256123, "_runtime": 1341.4061596393585, "_timestamp": 1585571257.250793, "_step": 426}
{"Episode reward": -71.61424827167473, "Episode length": 999, "Policy Loss": 0.0033811593893915415, "Value Loss": 0.0010644512949511409, "_runtime": 1342.9500420093536, "_timestamp": 1585571258.7946754, "_step": 427}
{"Episode reward": -71.42765576171522, "Episode length": 999, "Policy Loss": 0.003817377844825387, "Value Loss": 0.0009852622170001268, "_runtime": 1344.4829993247986, "_timestamp": 1585571260.3276327, "_step": 428}
{"Episode reward": -70.99006345168718, "Episode length": 999, "Policy Loss": 0.0022626430727541447, "Value Loss": 0.0009679548093117774, "_runtime": 1346.020295381546, "_timestamp": 1585571261.8649287, "_step": 429}
{"Episode reward": -72.2301132987223, "Episode length": 999, "Policy Loss": 0.003605753881856799, "Value Loss": 0.001070701633580029, "_runtime": 1347.5881304740906, "_timestamp": 1585571263.4327638, "_step": 430}
{"Episode reward": -74.73978099525306, "Episode length": 999, "Policy Loss": 0.001270830980502069, "Value Loss": 0.000933201692532748, "_runtime": 1349.136679649353, "_timestamp": 1585571264.981313, "_step": 431}
{"Episode reward": -72.56530045371576, "Episode length": 999, "Policy Loss": 0.0010463121579959989, "Value Loss": 0.0009355529909953475, "_runtime": 1350.6787984371185, "_timestamp": 1585571266.5234318, "_step": 432}
{"Episode reward": -72.15649709555596, "Episode length": 999, "Policy Loss": 0.002699153032153845, "Value Loss": 0.001051061088219285, "_runtime": 1352.2304635047913, "_timestamp": 1585571268.0750968, "_step": 433}
{"Episode reward": -72.00416436599444, "Episode length": 999, "Policy Loss": -5.604380203294568e-05, "Value Loss": 0.0009253817261196673, "_runtime": 1353.767038822174, "_timestamp": 1585571269.6116722, "_step": 434}
{"Episode reward": -73.5038701245304, "Episode length": 999, "Policy Loss": -0.0006261032540351152, "Value Loss": 0.0010166456922888756, "_runtime": 1355.300901889801, "_timestamp": 1585571271.1455352, "_step": 435}
{"Episode reward": -71.3097769210887, "Episode length": 999, "Policy Loss": -0.0005939818802289665, "Value Loss": 0.000952922971919179, "_runtime": 1356.8331928253174, "_timestamp": 1585571272.6778262, "_step": 436}
{"Episode reward": -71.04414531023008, "Episode length": 999, "Policy Loss": -0.0005380682414397597, "Value Loss": 0.0008969715563580394, "_runtime": 1358.3794088363647, "_timestamp": 1585571274.2240422, "_step": 437}
{"Episode reward": -72.38621755115841, "Episode length": 999, "Policy Loss": 0.0011067816521972418, "Value Loss": 0.000954922114033252, "_runtime": 1359.924988269806, "_timestamp": 1585571275.7696216, "_step": 438}
{"Episode reward": -68.72132243818946, "Episode length": 999, "Policy Loss": 0.001345221884548664, "Value Loss": 0.0011526497546583414, "_runtime": 1361.4679765701294, "_timestamp": 1585571277.31261, "_step": 439}
{"Episode reward": -74.35995665459716, "Episode length": 999, "Policy Loss": 0.0010417146841064095, "Value Loss": 0.000996374641545117, "_runtime": 1363.0177962779999, "_timestamp": 1585571278.8624296, "_step": 440}
{"Episode reward": -72.74936624731706, "Episode length": 999, "Policy Loss": 0.0022214814089238644, "Value Loss": 0.0009269067086279392, "_runtime": 1364.5515723228455, "_timestamp": 1585571280.3962057, "_step": 441}
{"Episode reward": -71.13389211872345, "Episode length": 999, "Policy Loss": 0.0028278743848204613, "Value Loss": 0.0010242644930258393, "_runtime": 1366.0777797698975, "_timestamp": 1585571281.922413, "_step": 442}
{"Episode reward": -71.20188479022944, "Episode length": 999, "Policy Loss": 0.001798965153284371, "Value Loss": 0.0009954051347449422, "_runtime": 1367.6222486495972, "_timestamp": 1585571283.466882, "_step": 443}
{"Episode reward": -74.16375221022454, "Episode length": 999, "Policy Loss": 0.00238054059445858, "Value Loss": 0.0011262003099545836, "_runtime": 1369.1695909500122, "_timestamp": 1585571285.0142243, "_step": 444}
{"Episode reward": -71.58802634674612, "Episode length": 999, "Policy Loss": 0.0017971290508285165, "Value Loss": 0.0010117234196513891, "_runtime": 1370.752648115158, "_timestamp": 1585571286.5972815, "_step": 445}
{"Episode reward": -72.47071223575114, "Episode length": 999, "Policy Loss": -7.31405452825129e-05, "Value Loss": 0.0009125017677433789, "_runtime": 1372.2975792884827, "_timestamp": 1585571288.1422126, "_step": 446}
{"Episode reward": -72.81522390411315, "Episode length": 999, "Policy Loss": -0.0010308552300557494, "Value Loss": 0.0010374533012509346, "_runtime": 1373.8494892120361, "_timestamp": 1585571289.6941226, "_step": 447}
{"Episode reward": -74.0573208768827, "Episode length": 999, "Policy Loss": 0.0002619450388010591, "Value Loss": 0.0009822244755923748, "_runtime": 1375.3977751731873, "_timestamp": 1585571291.2424085, "_step": 448}
{"Episode reward": -74.45416217020171, "Episode length": 999, "Policy Loss": 2.455769936204888e-05, "Value Loss": 0.0009360250551253557, "_runtime": 1376.931649684906, "_timestamp": 1585571292.776283, "_step": 449}
{"Episode reward": -73.11696249340832, "Episode length": 999, "Policy Loss": 0.0015909533249214292, "Value Loss": 0.0009119098540395498, "_runtime": 1378.4688868522644, "_timestamp": 1585571294.3135202, "_step": 450}
{"Episode reward": -72.11416423969422, "Episode length": 999, "Policy Loss": 0.0019928154069930315, "Value Loss": 0.0009165166993625462, "_runtime": 1380.0154311656952, "_timestamp": 1585571295.8600645, "_step": 451}
{"Episode reward": -72.08659934914522, "Episode length": 999, "Policy Loss": 0.0005249581299722195, "Value Loss": 0.0009288190631195903, "_runtime": 1381.5487883090973, "_timestamp": 1585571297.3934216, "_step": 452}
{"Episode reward": -70.4308946086482, "Episode length": 999, "Policy Loss": 0.004431881941854954, "Value Loss": 0.0010951936710625887, "_runtime": 1383.0885212421417, "_timestamp": 1585571298.9331546, "_step": 453}
{"Episode reward": -71.53135969295303, "Episode length": 999, "Policy Loss": 0.002766791731119156, "Value Loss": 0.000995253911241889, "_runtime": 1384.625560283661, "_timestamp": 1585571300.4701936, "_step": 454}
{"Episode reward": -71.18955073954298, "Episode length": 999, "Policy Loss": 0.0026842837687581778, "Value Loss": 0.0009737914078868926, "_runtime": 1386.1782977581024, "_timestamp": 1585571302.022931, "_step": 455}
{"Episode reward": -71.88343632992516, "Episode length": 999, "Policy Loss": 0.00507510919123888, "Value Loss": 0.00109829381108284, "_runtime": 1387.7036855220795, "_timestamp": 1585571303.5483189, "_step": 456}
{"Episode reward": -72.55617964878662, "Episode length": 999, "Policy Loss": 0.002556509105488658, "Value Loss": 0.0010108996648341417, "_runtime": 1389.2464299201965, "_timestamp": 1585571305.0910633, "_step": 457}
{"Episode reward": -72.70601185704834, "Episode length": 999, "Policy Loss": 0.0019469548715278506, "Value Loss": 0.000886975263711065, "_runtime": 1390.7877252101898, "_timestamp": 1585571306.6323586, "_step": 458}
{"Episode reward": -71.40384108638258, "Episode length": 999, "Policy Loss": -0.0003454893303569406, "Value Loss": 0.001072527258656919, "_runtime": 1392.3319249153137, "_timestamp": 1585571308.1765583, "_step": 459}
{"Episode reward": -71.9784943091125, "Episode length": 999, "Policy Loss": 0.0017101421253755689, "Value Loss": 0.0009894475806504488, "_runtime": 1393.9087891578674, "_timestamp": 1585571309.7534225, "_step": 460}
{"Episode reward": -73.10775902378813, "Episode length": 999, "Policy Loss": 0.00039004458812996745, "Value Loss": 0.0009875718969851732, "_runtime": 1395.4549486637115, "_timestamp": 1585571311.299582, "_step": 461}
{"Episode reward": -71.32808983342673, "Episode length": 999, "Policy Loss": 0.0005057944217696786, "Value Loss": 0.0010866394732147455, "_runtime": 1397.0030801296234, "_timestamp": 1585571312.8477135, "_step": 462}
{"Episode reward": -72.19531848344349, "Episode length": 999, "Policy Loss": 0.0033328435383737087, "Value Loss": 0.0010021136840805411, "_runtime": 1398.5251321792603, "_timestamp": 1585571314.3697655, "_step": 463}
{"Episode reward": -71.67279089436246, "Episode length": 999, "Policy Loss": 0.0014098223764449358, "Value Loss": 0.001020678086206317, "_runtime": 1400.0587272644043, "_timestamp": 1585571315.9033606, "_step": 464}
{"Episode reward": -72.48197820983397, "Episode length": 999, "Policy Loss": 0.0014550734777003527, "Value Loss": 0.0009387965546920896, "_runtime": 1401.5822703838348, "_timestamp": 1585571317.4269037, "_step": 465}
{"Episode reward": -72.19916811233323, "Episode length": 999, "Policy Loss": 0.0029256255365908146, "Value Loss": 0.0009328401647508144, "_runtime": 1403.11821103096, "_timestamp": 1585571318.9628444, "_step": 466}
{"Episode reward": -74.05347800413105, "Episode length": 999, "Policy Loss": 0.0019471306586638093, "Value Loss": 0.0009168544784188271, "_runtime": 1404.6624963283539, "_timestamp": 1585571320.5071297, "_step": 467}
{"Episode reward": -72.055299016667, "Episode length": 999, "Policy Loss": 0.0053684888407588005, "Value Loss": 0.0013188390294089913, "_runtime": 1406.2089159488678, "_timestamp": 1585571322.0535493, "_step": 468}
{"Episode reward": -73.36977201846715, "Episode length": 999, "Policy Loss": 0.0005219152080826461, "Value Loss": 0.0009442608570680022, "_runtime": 1407.743229150772, "_timestamp": 1585571323.5878625, "_step": 469}
{"Episode reward": -71.11982382809973, "Episode length": 999, "Policy Loss": 0.00019648288434837013, "Value Loss": 0.0009392470819875598, "_runtime": 1409.288346529007, "_timestamp": 1585571325.1329799, "_step": 470}
{"Episode reward": -72.10364700140929, "Episode length": 999, "Policy Loss": 0.0012425632448866963, "Value Loss": 0.0008258586749434471, "_runtime": 1410.8340351581573, "_timestamp": 1585571326.6786685, "_step": 471}
{"Episode reward": -70.30585679634109, "Episode length": 999, "Policy Loss": 0.0017156361136585474, "Value Loss": 0.0009957653237506747, "_runtime": 1412.3657965660095, "_timestamp": 1585571328.21043, "_step": 472}
{"Episode reward": -72.4694477748828, "Episode length": 999, "Policy Loss": -0.00020524636784102768, "Value Loss": 0.0009660894866101444, "_runtime": 1413.9028134346008, "_timestamp": 1585571329.7474468, "_step": 473}
{"Episode reward": -70.31091059552125, "Episode length": 999, "Policy Loss": -0.00017067293811123818, "Value Loss": 0.0010752901434898376, "_runtime": 1415.4810423851013, "_timestamp": 1585571331.3256757, "_step": 474}
{"Episode reward": -71.42623046877151, "Episode length": 999, "Policy Loss": -0.00012675585458055139, "Value Loss": 0.0009144407231360674, "_runtime": 1417.0276205539703, "_timestamp": 1585571332.872254, "_step": 475}
{"Episode reward": -71.97131162327214, "Episode length": 999, "Policy Loss": 0.0032005670946091413, "Value Loss": 0.00092289102030918, "_runtime": 1418.5705740451813, "_timestamp": 1585571334.4152074, "_step": 476}
{"Episode reward": -70.8028806236344, "Episode length": 999, "Policy Loss": 0.0035825567319989204, "Value Loss": 0.00099190475884825, "_runtime": 1420.1097235679626, "_timestamp": 1585571335.954357, "_step": 477}
{"Episode reward": -72.65524621849744, "Episode length": 999, "Policy Loss": 0.002504706149920821, "Value Loss": 0.0010055945022031665, "_runtime": 1421.6544244289398, "_timestamp": 1585571337.4990578, "_step": 478}
{"Episode reward": -71.44479367516483, "Episode length": 999, "Policy Loss": 0.002211915794759989, "Value Loss": 0.0010620481334626675, "_runtime": 1423.203485250473, "_timestamp": 1585571339.0481186, "_step": 479}
{"Episode reward": -73.35284596992915, "Episode length": 999, "Policy Loss": 0.0030923676677048206, "Value Loss": 0.0010840221075341105, "_runtime": 1424.7371282577515, "_timestamp": 1585571340.5817616, "_step": 480}
{"Episode reward": -72.2516490267673, "Episode length": 999, "Policy Loss": 0.0006891366210766137, "Value Loss": 0.0009050077642314136, "_runtime": 1426.2660148143768, "_timestamp": 1585571342.1106482, "_step": 481}
{"Episode reward": -71.08269867764078, "Episode length": 999, "Policy Loss": -0.0010731951333582401, "Value Loss": 0.0009794651996344328, "_runtime": 1427.8022558689117, "_timestamp": 1585571343.6468892, "_step": 482}
{"Episode reward": -72.1071368847451, "Episode length": 999, "Policy Loss": 0.0012088560033589602, "Value Loss": 0.0009367950260639191, "_runtime": 1429.3419880867004, "_timestamp": 1585571345.1866214, "_step": 483}
{"Episode reward": -72.94359815206408, "Episode length": 999, "Policy Loss": 0.004318267107009888, "Value Loss": 0.0011784486705437303, "_runtime": 1430.8838069438934, "_timestamp": 1585571346.7284403, "_step": 484}
{"Episode reward": -71.30005398523114, "Episode length": 999, "Policy Loss": 0.00359216402284801, "Value Loss": 0.0012960280291736126, "_runtime": 1432.4243774414062, "_timestamp": 1585571348.2690108, "_step": 485}
{"Episode reward": -71.29606384565896, "Episode length": 999, "Policy Loss": 0.0017724859062582254, "Value Loss": 0.0010108237620443106, "_runtime": 1433.9732286930084, "_timestamp": 1585571349.817862, "_step": 486}
{"Episode reward": -71.96472244095021, "Episode length": 999, "Policy Loss": -0.0005938421236351132, "Value Loss": 0.0009616457391530275, "_runtime": 1435.5220680236816, "_timestamp": 1585571351.3667014, "_step": 487}
{"Episode reward": -71.8033119411737, "Episode length": 999, "Policy Loss": 0.0024151981342583895, "Value Loss": 0.0009803817374631763, "_runtime": 1437.0499918460846, "_timestamp": 1585571352.8946252, "_step": 488}
{"Episode reward": -71.68347518516813, "Episode length": 999, "Policy Loss": 0.001712517230771482, "Value Loss": 0.0010316111147403717, "_runtime": 1438.6315319538116, "_timestamp": 1585571354.4761653, "_step": 489}
{"Episode reward": -72.16693647499186, "Episode length": 999, "Policy Loss": 0.004138522781431675, "Value Loss": 0.0010329654905945063, "_runtime": 1440.1815705299377, "_timestamp": 1585571356.0262039, "_step": 490}
{"Episode reward": -70.24602801790283, "Episode length": 999, "Policy Loss": 0.002063379855826497, "Value Loss": 0.0009152187849394977, "_runtime": 1441.7286133766174, "_timestamp": 1585571357.5732467, "_step": 491}
{"Episode reward": -69.8453790373686, "Episode length": 999, "Policy Loss": 0.0062715234234929085, "Value Loss": 0.0011978161055594683, "_runtime": 1443.27734041214, "_timestamp": 1585571359.1219738, "_step": 492}
{"Episode reward": -72.88724360471626, "Episode length": 999, "Policy Loss": 0.0012830686755478382, "Value Loss": 0.0008213448454625905, "_runtime": 1444.8232510089874, "_timestamp": 1585571360.6678843, "_step": 493}
{"Episode reward": -72.12169943240258, "Episode length": 999, "Policy Loss": 0.0027128783985972404, "Value Loss": 0.0010599280940368772, "_runtime": 1446.3722040653229, "_timestamp": 1585571362.2168374, "_step": 494}
{"Episode reward": -72.6777471958249, "Episode length": 999, "Policy Loss": 0.0012552915140986443, "Value Loss": 0.0008752229623496532, "_runtime": 1447.8977391719818, "_timestamp": 1585571363.7423725, "_step": 495}
{"Episode reward": -70.7939490977858, "Episode length": 999, "Policy Loss": 0.0017604955937713385, "Value Loss": 0.0009174328297376633, "_runtime": 1449.435495853424, "_timestamp": 1585571365.2801292, "_step": 496}
{"Episode reward": -68.6683731241804, "Episode length": 999, "Policy Loss": 0.000422700890339911, "Value Loss": 0.0011914214119315147, "_runtime": 1450.9877126216888, "_timestamp": 1585571366.832346, "_step": 497}
{"Episode reward": -70.09243821640112, "Episode length": 999, "Policy Loss": 0.005919783376157284, "Value Loss": 0.0014512663474306464, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348, -4.076546669006348]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.6912670135498047, -3.6101083755493164, -3.5289499759674072, -3.447791337966919, -3.3666326999664307, -3.2854743003845215, -3.204315662384033, -3.123157024383545, -3.0419983863830566, -2.9608399868011475, -2.879681348800659, -2.79852294921875, -2.7173643112182617, -2.6362056732177734, -2.555047035217285, -2.473888397216797, -2.3927299976348877, -2.3115715980529785, -2.2304129600524902, -2.149254322052002, -2.0680956840515137, -1.986937165260315, -1.9057786464691162, -1.824620008468628, -1.7434614896774292, -1.6623029708862305, -1.5811443328857422, -1.499985694885254, -1.4188272953033447, -1.3376686573028564, -1.2565100193023682, -1.175351619720459, -1.0941929817199707, -1.0130343437194824, -0.9318759441375732, -0.850717306137085, -0.7695586681365967, -0.6884002685546875, -0.6072416305541992, -0.5260829925537109, -0.44492435455322266, -0.3637659549713135, -0.2826073169708252, -0.20144867897033691, -0.12029027938842773, -0.03913164138793945, 0.04202699661254883, 0.12318539619445801, 0.2043440341949463, 0.28550267219543457, 0.36666107177734375, 0.44781970977783203, 0.5289783477783203, 0.6101369857788086, 0.6912956237792969, 0.772453784942627, 0.8536124229431152, 0.9347710609436035, 1.0159296989440918, 1.09708833694458, 1.1782469749450684, 1.2594051361083984, 1.3405637741088867, 1.421722412109375, 1.5028810501098633]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-2.161391258239746, -2.09259295463562, -2.023794651031494, -1.9549963474273682, -1.8861980438232422, -1.8173997402191162, -1.7486014366149902, -1.6798031330108643, -1.6110048294067383, -1.5422065258026123, -1.4734082221984863, -1.4046099185943604, -1.335811734199524, -1.267013430595398, -1.198215126991272, -1.129416823387146, -1.06061851978302, -0.991820216178894, -0.9230219125747681, -0.8542236089706421, -0.7854253053665161, -0.7166270017623901, -0.6478286981582642, -0.5790303945541382, -0.5102322101593018, -0.4414339065551758, -0.3726356029510498, -0.30383729934692383, -0.23503899574279785, -0.16624069213867188, -0.0974423885345459, -0.028644084930419922, 0.040154218673706055, 0.10895252227783203, 0.177750825881958, 0.24654912948608398, 0.31534743309020996, 0.38414573669433594, 0.4529440402984619, 0.5217423439025879, 0.5905406475067139, 0.6593389511108398, 0.7281372547149658, 0.7969355583190918, 0.8657338619232178, 0.9345321655273438, 1.0033304691314697, 1.0721287727355957, 1.1409268379211426, 1.2097251415252686, 1.2785234451293945, 1.3473217487335205, 1.4161200523376465, 1.4849183559417725, 1.5537166595458984, 1.6225149631500244, 1.6913132667541504, 1.7601115703582764, 1.8289098739624023, 1.8977084159851074, 1.9665064811706543, 2.0353050231933594, 2.1041030883789062, 2.1729016304016113, 2.241699695587158]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 5.0, 2.0, 3.0, 8.0, 9.0, 10.0, 4.0, 10.0, 9.0, 18.0, 11.0, 9.0, 15.0, 13.0, 28.0, 35.0, 34.0, 67.0, 35.0, 27.0, 16.0, 23.0, 21.0, 9.0, 10.0, 4.0, 8.0, 8.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-1.737634301185608, -1.6822515726089478, -1.6268688440322876, -1.5714861154556274, -1.5161033868789673, -1.4607206583023071, -1.4053380489349365, -1.3499553203582764, -1.2945725917816162, -1.239189863204956, -1.183807134628296, -1.1284244060516357, -1.0730416774749756, -1.0176589488983154, -0.9622762203216553, -0.9068934917449951, -0.851510763168335, -0.7961280345916748, -0.7407453060150146, -0.6853625774383545, -0.6299798488616943, -0.5745971202850342, -0.519214391708374, -0.46383166313171387, -0.40844905376434326, -0.3530663251876831, -0.29768359661102295, -0.2423008680343628, -0.18691813945770264, -0.13153541088104248, -0.07615268230438232, -0.020769953727722168, 0.03461277484893799, 0.08999550342559814, 0.1453782320022583, 0.20076096057891846, 0.2561436891555786, 0.31152641773223877, 0.3669091463088989, 0.4222918748855591, 0.47767460346221924, 0.5330573320388794, 0.5884400606155396, 0.6438227891921997, 0.6992055177688599, 0.75458824634552, 0.8099709749221802, 0.8653537034988403, 0.9207361936569214, 0.9761189222335815, 1.0315016508102417, 1.0868843793869019, 1.142267107963562, 1.1976498365402222, 1.2530325651168823, 1.3084152936935425, 1.3637980222702026, 1.4191807508468628, 1.474563479423523, 1.529946208000183, 1.5853289365768433, 1.6407116651535034, 1.6960943937301636, 1.7514771223068237, 1.8068598508834839]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.7810035943984985, -1.7175053358078003, -1.6540069580078125, -1.5905086994171143, -1.5270103216171265, -1.4635120630264282, -1.4000136852264404, -1.3365154266357422, -1.273017168045044, -1.2095187902450562, -1.1460204124450684, -1.0825221538543701, -1.0190238952636719, -0.9555255770683289, -0.8920272588729858, -0.8285289406776428, -0.7650306224822998, -0.7015323638916016, -0.6380339860916138, -0.5745357275009155, -0.5110373497009277, -0.4475390911102295, -0.3840407133102417, -0.32054245471954346, -0.2570441961288452, -0.19354581832885742, -0.13004755973815918, -0.06654918193817139, -0.0030509233474731445, 0.06044745445251465, 0.12394571304321289, 0.18744409084320068, 0.2509423494338989, 0.31444060802459717, 0.3779388666152954, 0.44143736362457275, 0.504935622215271, 0.5684338808059692, 0.6319321393966675, 0.6954306364059448, 0.7589288949966431, 0.8224271535873413, 0.8859254121780396, 0.9494236707687378, 1.0129221677780151, 1.0764204263687134, 1.1399186849594116, 1.2034169435501099, 1.266915202140808, 1.3304136991500854, 1.3939119577407837, 1.457410216331482, 1.5209084749221802, 1.5844069719314575, 1.6479052305221558, 1.711403489112854, 1.7749017477035522, 1.8384000062942505, 1.9018985033035278, 1.965396761894226, 2.0288949012756348, 2.092393398284912, 2.1558918952941895, 2.2193899154663086, 2.282888412475586]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 6.0, 2.0, 5.0, 1.0, 1.0, 6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-2.7391180992126465, -2.6610565185546875, -2.5829949378967285, -2.5049333572387695, -2.4268717765808105, -2.3488101959228516, -2.2707486152648926, -2.1926870346069336, -2.1146254539489746, -2.0365638732910156, -1.9585022926330566, -1.8804407119750977, -1.8023791313171387, -1.7243175506591797, -1.6462559700012207, -1.5681943893432617, -1.4901328086853027, -1.4120712280273438, -1.3340096473693848, -1.2559480667114258, -1.1778864860534668, -1.0998249053955078, -1.0217633247375488, -0.9437017440795898, -0.8656401634216309, -0.7875785827636719, -0.7095170021057129, -0.6314554214477539, -0.5533938407897949, -0.47533226013183594, -0.39727067947387695, -0.31920909881591797, -0.24114751815795898, -0.1630859375, -0.08502435684204102, -0.006962776184082031, 0.07109880447387695, 0.14916038513183594, 0.22722196578979492, 0.3052835464477539, 0.3833451271057129, 0.4614067077636719, 0.5394682884216309, 0.6175298690795898, 0.6955914497375488, 0.7736530303955078, 0.8517146110534668, 0.9297761917114258, 1.0078377723693848, 1.0858993530273438, 1.1639609336853027, 1.2420225143432617, 1.3200840950012207, 1.3981456756591797, 1.4762072563171387, 1.5542688369750977, 1.6323304176330566, 1.7103919982910156, 1.7884535789489746, 1.8665151596069336, 1.9445767402648926, 2.0226383209228516, 2.1006999015808105, 2.1787614822387695, 2.2568230628967285]}, "_runtime": 1452.5269601345062, "_timestamp": 1585571368.3715935, "_step": 498}
{"Episode reward": -70.79420409965442, "Episode length": 999, "Policy Loss": 0.0042234137654304504, "Value Loss": 0.0012103216722607613, "_runtime": 1452.5269601345062, "_timestamp": 1585571368.3715935, "_step": 499}
