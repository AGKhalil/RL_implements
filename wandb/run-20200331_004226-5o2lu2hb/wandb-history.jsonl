{"Episode reward": -49.31884379621274, "Episode length": 999, "Policy Loss": -0.06118594855070114, "Value Loss": 0.007346527185291052, "_runtime": 17996.431303977966, "_timestamp": 1585615366.0641735, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0800042152404785, "Value Loss": 44.70631408691406, "_runtime": 17997.957713603973, "_timestamp": 1585615367.590583, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.052438974380493, "Value Loss": 220.09608459472656, "_runtime": 17998.30184841156, "_timestamp": 1585615367.934718, "_step": 2}
{"Episode reward": 82.79990982413295, "Episode length": 173, "Policy Loss": 2839.9326171875, "Value Loss": 377262.625, "_runtime": 17999.85528922081, "_timestamp": 1585615369.4881587, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.12219524383545, "Value Loss": 3508.949951171875, "_runtime": 18001.4094042778, "_timestamp": 1585615371.0422738, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.051898956298828, "Value Loss": 8474.94140625, "_runtime": 18002.902826070786, "_timestamp": 1585615372.5356956, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.665796279907227, "Value Loss": 7530.78369140625, "_runtime": 18004.492910385132, "_timestamp": 1585615374.1257799, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.254829406738281, "Value Loss": 257.6370544433594, "_runtime": 18006.044113636017, "_timestamp": 1585615375.676983, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.999465942382812, "Value Loss": 1622.0849609375, "_runtime": 18007.57912659645, "_timestamp": 1585615377.211996, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.700993537902832, "Value Loss": 1630.9613037109375, "_runtime": 18009.14762377739, "_timestamp": 1585615378.7804933, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1911861896514893, "Value Loss": 3557.483154296875, "_runtime": 18010.710921764374, "_timestamp": 1585615380.3437912, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 345.002685546875, "Value Loss": 37324.44921875, "_runtime": 18010.957477092743, "_timestamp": 1585615380.5903466, "_step": 11}
{"Episode reward": 89.28554726154428, "Episode length": 116, "Policy Loss": 68.23094940185547, "Value Loss": 104860.796875, "_runtime": 18011.556400299072, "_timestamp": 1585615381.1892698, "_step": 12}
{"Episode reward": 65.51672728291504, "Episode length": 364, "Policy Loss": 92.26180267333984, "Value Loss": 5722.3984375, "_runtime": 18012.01109290123, "_timestamp": 1585615381.6439624, "_step": 13}
{"Episode reward": 73.9754612028548, "Episode length": 267, "Policy Loss": -16.451406478881836, "Value Loss": 62162.12109375, "_runtime": 18012.188102006912, "_timestamp": 1585615381.8209715, "_step": 14}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": -47.79612731933594, "Value Loss": 96436.7421875, "_runtime": 18012.7879884243, "_timestamp": 1585615382.420858, "_step": 15}
{"Episode reward": 63.53758391868563, "Episode length": 372, "Policy Loss": 63.23814392089844, "Value Loss": 6704.8642578125, "_runtime": 18012.967612028122, "_timestamp": 1585615382.6004815, "_step": 16}
{"Episode reward": 89.1796780974627, "Episode length": 110, "Policy Loss": 103.38494110107422, "Value Loss": 10365.5693359375, "_runtime": 18013.13533616066, "_timestamp": 1585615382.7682056, "_step": 17}
{"Episode reward": 89.50828852930569, "Episode length": 108, "Policy Loss": 63.43367385864258, "Value Loss": 7967.84619140625, "_runtime": 18013.359431028366, "_timestamp": 1585615382.9923005, "_step": 18}
{"Episode reward": 86.40000000000003, "Episode length": 136, "Policy Loss": -72.32154083251953, "Value Loss": 14039.5146484375, "_runtime": 18013.52829504013, "_timestamp": 1585615383.1611645, "_step": 19}
{"Episode reward": 89.19967632553892, "Episode length": 109, "Policy Loss": -51.090518951416016, "Value Loss": 5753.44140625, "_runtime": 18013.693176031113, "_timestamp": 1585615383.3260455, "_step": 20}
{"Episode reward": 89.48392827214684, "Episode length": 106, "Policy Loss": 4.330745697021484, "Value Loss": 454.2229919433594, "_runtime": 18013.86592912674, "_timestamp": 1585615383.4987986, "_step": 21}
{"Episode reward": 89.04713995370406, "Episode length": 111, "Policy Loss": -26.083513259887695, "Value Loss": 2428.720703125, "_runtime": 18014.02684044838, "_timestamp": 1585615383.65971, "_step": 22}
{"Episode reward": 89.74230880259535, "Episode length": 104, "Policy Loss": 19.086795806884766, "Value Loss": 7520.31591796875, "_runtime": 18014.1978495121, "_timestamp": 1585615383.830719, "_step": 23}
{"Episode reward": 88.99974621687437, "Episode length": 111, "Policy Loss": -47.82051467895508, "Value Loss": 5410.87646484375, "_runtime": 18014.359308242798, "_timestamp": 1585615383.9921777, "_step": 24}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": -147.95382690429688, "Value Loss": 4442.935546875, "_runtime": 18015.86280107498, "_timestamp": 1585615385.4956706, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 46.56111526489258, "Value Loss": 31.373504638671875, "_runtime": 18017.35803437233, "_timestamp": 1585615386.9909039, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 46.9264030456543, "Value Loss": 185.9915771484375, "_runtime": 18018.85892343521, "_timestamp": 1585615388.491793, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 46.14143371582031, "Value Loss": 794.464599609375, "_runtime": 18020.442499637604, "_timestamp": 1585615390.0753691, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 52.15697479248047, "Value Loss": 569.2387084960938, "_runtime": 18021.994539499283, "_timestamp": 1585615391.627409, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 53.368988037109375, "Value Loss": 75.00276184082031, "_runtime": 18023.535630464554, "_timestamp": 1585615393.1685, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 54.071319580078125, "Value Loss": 2023.61474609375, "_runtime": 18025.130063056946, "_timestamp": 1585615394.7629325, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 54.64632034301758, "Value Loss": 2546.225830078125, "_runtime": 18026.692799806595, "_timestamp": 1585615396.3256693, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 56.03626251220703, "Value Loss": 3838.16357421875, "_runtime": 18028.23521757126, "_timestamp": 1585615397.868087, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 51.059173583984375, "Value Loss": 7604.4453125, "_runtime": 18029.83015012741, "_timestamp": 1585615399.4630196, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 57.937232971191406, "Value Loss": 35.18267059326172, "_runtime": 18031.409012317657, "_timestamp": 1585615401.0418818, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 57.459983825683594, "Value Loss": 38.120113372802734, "_runtime": 18031.7768304348, "_timestamp": 1585615401.4097, "_step": 36}
{"Episode reward": 80.1, "Episode length": 199, "Policy Loss": -396.7745056152344, "Value Loss": 14819.5166015625, "_runtime": 18031.992914438248, "_timestamp": 1585615401.625784, "_step": 37}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": -450.8179016113281, "Value Loss": 8406.5068359375, "_runtime": 18032.223949193954, "_timestamp": 1585615401.8568187, "_step": 38}
{"Episode reward": 89.09239602712772, "Episode length": 110, "Policy Loss": -1.9194507598876953, "Value Loss": 671.8567504882812, "_runtime": 18032.414325237274, "_timestamp": 1585615402.0471947, "_step": 39}
{"Episode reward": 88.16049146409127, "Episode length": 119, "Policy Loss": 106.09600067138672, "Value Loss": 1942.0833740234375, "_runtime": 18032.58889055252, "_timestamp": 1585615402.22176, "_step": 40}
{"Episode reward": 88.77448698835799, "Episode length": 113, "Policy Loss": 37.237674713134766, "Value Loss": 2670.65625, "_runtime": 18032.774050712585, "_timestamp": 1585615402.4069202, "_step": 41}
{"Episode reward": 87.99932370357568, "Episode length": 121, "Policy Loss": 20.48456573486328, "Value Loss": 3189.284423828125, "_runtime": 18032.943063259125, "_timestamp": 1585615402.5759327, "_step": 42}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": -6.997355937957764, "Value Loss": 2806.51025390625, "_runtime": 18033.118620872498, "_timestamp": 1585615402.7514904, "_step": 43}
{"Episode reward": 88.70720178682244, "Episode length": 114, "Policy Loss": -42.426307678222656, "Value Loss": 1447.1934814453125, "_runtime": 18033.412058591843, "_timestamp": 1585615403.044928, "_step": 44}
{"Episode reward": 80.4, "Episode length": 196, "Policy Loss": -108.71061706542969, "Value Loss": 1491.9412841796875, "_runtime": 18033.818745851517, "_timestamp": 1585615403.4516153, "_step": 45}
{"Episode reward": 72.49999999999989, "Episode length": 275, "Policy Loss": -79.28955078125, "Value Loss": 571.6610717773438, "_runtime": 18034.01599240303, "_timestamp": 1585615403.648862, "_step": 46}
{"Episode reward": 87.10000000000004, "Episode length": 129, "Policy Loss": -107.38439178466797, "Value Loss": 1422.5855712890625, "_runtime": 18034.202196598053, "_timestamp": 1585615403.835066, "_step": 47}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": -68.16439819335938, "Value Loss": 1297.4931640625, "_runtime": 18035.122685670853, "_timestamp": 1585615404.7555552, "_step": 48}
{"Episode reward": 38.49017636162984, "Episode length": 618, "Policy Loss": -40.208534240722656, "Value Loss": 175.25489807128906, "_runtime": 18035.33208298683, "_timestamp": 1585615404.9649525, "_step": 49}
{"Episode reward": 87.43561772552206, "Episode length": 127, "Policy Loss": -109.32533264160156, "Value Loss": 798.4385986328125, "_runtime": 18035.875133275986, "_timestamp": 1585615405.5080028, "_step": 50}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": -42.498355865478516, "Value Loss": 138.85008239746094, "_runtime": 18036.849719047546, "_timestamp": 1585615406.4825885, "_step": 51}
{"Episode reward": 36.376778413145175, "Episode length": 637, "Policy Loss": -24.399198532104492, "Value Loss": 48.45708465576172, "_runtime": 18037.075680971146, "_timestamp": 1585615406.7085505, "_step": 52}
{"Episode reward": 86.00000000000004, "Episode length": 140, "Policy Loss": -23.106237411499023, "Value Loss": 91.81412506103516, "_runtime": 18037.301743984222, "_timestamp": 1585615406.9346135, "_step": 53}
{"Episode reward": 86.20000000000005, "Episode length": 138, "Policy Loss": 4.38975715637207, "Value Loss": 86.25779724121094, "_runtime": 18037.554631471634, "_timestamp": 1585615407.187501, "_step": 54}
{"Episode reward": 85.99182606070976, "Episode length": 142, "Policy Loss": 30.167802810668945, "Value Loss": 129.75997924804688, "_runtime": 18038.587282896042, "_timestamp": 1585615408.2201524, "_step": 55}
{"Episode reward": 31.130661503853844, "Episode length": 691, "Policy Loss": -11.473167419433594, "Value Loss": 30.195171356201172, "_runtime": 18039.00084400177, "_timestamp": 1585615408.6337135, "_step": 56}
{"Episode reward": 73.0999999999999, "Episode length": 269, "Policy Loss": 7.979411602020264, "Value Loss": 94.42066192626953, "_runtime": 18039.198870658875, "_timestamp": 1585615408.8317401, "_step": 57}
{"Episode reward": 87.20000000000003, "Episode length": 128, "Policy Loss": 28.335453033447266, "Value Loss": 190.2523193359375, "_runtime": 18039.413949251175, "_timestamp": 1585615409.0468187, "_step": 58}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 58.50371551513672, "Value Loss": 450.3923645019531, "_runtime": 18039.599516630173, "_timestamp": 1585615409.232386, "_step": 59}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 76.5486831665039, "Value Loss": 441.114013671875, "_runtime": 18039.909715652466, "_timestamp": 1585615409.5425851, "_step": 60}
{"Episode reward": 79.39999999999998, "Episode length": 206, "Policy Loss": 32.66671371459961, "Value Loss": 171.60670471191406, "_runtime": 18040.59541130066, "_timestamp": 1585615410.2282808, "_step": 61}
{"Episode reward": 53.61571092456541, "Episode length": 464, "Policy Loss": 1.1141014099121094, "Value Loss": 46.87992858886719, "_runtime": 18041.602739095688, "_timestamp": 1585615411.2356086, "_step": 62}
{"Episode reward": 35.02972546897304, "Episode length": 651, "Policy Loss": 0.03295617178082466, "Value Loss": 38.04564666748047, "_runtime": 18042.056004285812, "_timestamp": 1585615411.6888738, "_step": 63}
{"Episode reward": 69.47115790806694, "Episode length": 306, "Policy Loss": 9.915610313415527, "Value Loss": 68.78925323486328, "_runtime": 18042.693153858185, "_timestamp": 1585615412.3260233, "_step": 64}
{"Episode reward": 57.99999999999968, "Episode length": 420, "Policy Loss": -1.7437351942062378, "Value Loss": 33.42775344848633, "_runtime": 18043.14044380188, "_timestamp": 1585615412.7733133, "_step": 65}
{"Episode reward": 72.79331071740005, "Episode length": 273, "Policy Loss": 15.011634826660156, "Value Loss": 81.01564025878906, "_runtime": 18044.368910312653, "_timestamp": 1585615414.0017798, "_step": 66}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": -6.007838249206543, "Value Loss": 17.518661499023438, "_runtime": 18045.43905735016, "_timestamp": 1585615415.0719268, "_step": 67}
{"Episode reward": 30.032190961669826, "Episode length": 701, "Policy Loss": -3.006404161453247, "Value Loss": 22.88237762451172, "_runtime": 18045.778153657913, "_timestamp": 1585615415.4110231, "_step": 68}
{"Episode reward": 78.74885620139537, "Episode length": 213, "Policy Loss": 25.43585205078125, "Value Loss": 106.54178619384766, "_runtime": 18046.435824871063, "_timestamp": 1585615416.0686944, "_step": 69}
{"Episode reward": 58.25728535056083, "Episode length": 418, "Policy Loss": -5.459439754486084, "Value Loss": 24.051782608032227, "_runtime": 18046.871443271637, "_timestamp": 1585615416.5043128, "_step": 70}
{"Episode reward": 73.87420024722805, "Episode length": 262, "Policy Loss": -1.5154753923416138, "Value Loss": 37.46498107910156, "_runtime": 18047.07442688942, "_timestamp": 1585615416.7072964, "_step": 71}
{"Episode reward": 87.22527418993417, "Episode length": 128, "Policy Loss": -3.5938217639923096, "Value Loss": 78.29273223876953, "_runtime": 18047.63100004196, "_timestamp": 1585615417.2638695, "_step": 72}
{"Episode reward": 63.39999999999976, "Episode length": 366, "Policy Loss": -7.148021221160889, "Value Loss": 28.246789932250977, "_runtime": 18047.81609272957, "_timestamp": 1585615417.4489622, "_step": 73}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 2.4242193698883057, "Value Loss": 89.32958984375, "_runtime": 18049.151326179504, "_timestamp": 1585615418.7841957, "_step": 74}
{"Episode reward": 10.593660417362926, "Episode length": 895, "Policy Loss": -4.540523052215576, "Value Loss": 17.267641067504883, "_runtime": 18049.354270219803, "_timestamp": 1585615418.9871397, "_step": 75}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": -1.5775831937789917, "Value Loss": 91.63372802734375, "_runtime": 18049.75050497055, "_timestamp": 1585615419.3833745, "_step": 76}
{"Episode reward": 73.2999999999999, "Episode length": 267, "Policy Loss": -8.361592292785645, "Value Loss": 40.71004867553711, "_runtime": 18050.30750322342, "_timestamp": 1585615419.9403727, "_step": 77}
{"Episode reward": 65.5999999999998, "Episode length": 344, "Policy Loss": -2.71225905418396, "Value Loss": 33.088016510009766, "_runtime": 18050.613695144653, "_timestamp": 1585615420.2465646, "_step": 78}
{"Episode reward": 79.6270969578807, "Episode length": 206, "Policy Loss": -5.426259994506836, "Value Loss": 51.338111877441406, "_runtime": 18050.80234026909, "_timestamp": 1585615420.4352098, "_step": 79}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -5.6202287673950195, "Value Loss": 91.64240264892578, "_runtime": 18051.189381599426, "_timestamp": 1585615420.822251, "_step": 80}
{"Episode reward": 74.99999999999991, "Episode length": 250, "Policy Loss": -8.297364234924316, "Value Loss": 44.67923355102539, "_runtime": 18051.37308740616, "_timestamp": 1585615421.005957, "_step": 81}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -4.996166229248047, "Value Loss": 90.2667465209961, "_runtime": 18051.57311964035, "_timestamp": 1585615421.2059891, "_step": 82}
{"Episode reward": 86.93675896690696, "Episode length": 131, "Policy Loss": -7.977378845214844, "Value Loss": 77.40544128417969, "_runtime": 18051.764419794083, "_timestamp": 1585615421.3972893, "_step": 83}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -2.776337146759033, "Value Loss": 81.22625732421875, "_runtime": 18052.100316286087, "_timestamp": 1585615421.7331858, "_step": 84}
{"Episode reward": 77.58793233793544, "Episode length": 225, "Policy Loss": -6.844991683959961, "Value Loss": 43.81443405151367, "_runtime": 18052.58760046959, "_timestamp": 1585615422.22047, "_step": 85}
{"Episode reward": 66.8999999999998, "Episode length": 331, "Policy Loss": -7.996993064880371, "Value Loss": 31.036365509033203, "_runtime": 18052.835424900055, "_timestamp": 1585615422.4682944, "_step": 86}
{"Episode reward": 83.50000000000004, "Episode length": 165, "Policy Loss": 7.808777809143066, "Value Loss": 62.55171585083008, "_runtime": 18053.01804637909, "_timestamp": 1585615422.6509159, "_step": 87}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -0.3791639506816864, "Value Loss": 79.7519302368164, "_runtime": 18053.69873690605, "_timestamp": 1585615423.3316064, "_step": 88}
{"Episode reward": 55.0879008661952, "Episode length": 451, "Policy Loss": -6.0847954750061035, "Value Loss": 20.492061614990234, "_runtime": 18053.881504058838, "_timestamp": 1585615423.5143735, "_step": 89}
{"Episode reward": 89.24583544460914, "Episode length": 108, "Policy Loss": 0.6256244778633118, "Value Loss": 80.30315399169922, "_runtime": 18054.04885315895, "_timestamp": 1585615423.6817226, "_step": 90}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 2.552957534790039, "Value Loss": 82.01841735839844, "_runtime": 18054.769978284836, "_timestamp": 1585615424.4028478, "_step": 91}
{"Episode reward": 52.79821198753595, "Episode length": 473, "Policy Loss": -4.162774085998535, "Value Loss": 18.875207901000977, "_runtime": 18056.02646803856, "_timestamp": 1585615425.6593375, "_step": 92}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": -5.2622833251953125, "Value Loss": 11.036626815795898, "_runtime": 18056.29997253418, "_timestamp": 1585615425.932842, "_step": 93}
{"Episode reward": 82.60000000000002, "Episode length": 174, "Policy Loss": -1.3677222728729248, "Value Loss": 51.47728729248047, "_runtime": 18056.712413311005, "_timestamp": 1585615426.3452828, "_step": 94}
{"Episode reward": 73.7999999999999, "Episode length": 262, "Policy Loss": -1.091814398765564, "Value Loss": 33.99539566040039, "_runtime": 18057.541271924973, "_timestamp": 1585615427.1741414, "_step": 95}
{"Episode reward": 47.19495169292157, "Episode length": 531, "Policy Loss": -3.8634955883026123, "Value Loss": 16.39261817932129, "_runtime": 18058.06547522545, "_timestamp": 1585615427.6983447, "_step": 96}
{"Episode reward": 64.49656374444581, "Episode length": 356, "Policy Loss": -0.8647273778915405, "Value Loss": 26.687877655029297, "_runtime": 18058.259881019592, "_timestamp": 1585615427.8927505, "_step": 97}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 1.8617078065872192, "Value Loss": 71.7492904663086, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836, -106.8476791381836]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0], "bins": [-612.6467895507812, -601.3955688476562, -590.1443481445312, -578.8931274414062, -567.6419067382812, -556.3906860351562, -545.1394653320312, -533.8882446289062, -522.6370239257812, -511.38580322265625, -500.13458251953125, -488.88336181640625, -477.63214111328125, -466.38092041015625, -455.12969970703125, -443.87847900390625, -432.62725830078125, -421.37603759765625, -410.12481689453125, -398.87359619140625, -387.62237548828125, -376.37115478515625, -365.11993408203125, -353.86871337890625, -342.61749267578125, -331.36627197265625, -320.11505126953125, -308.86383056640625, -297.61260986328125, -286.36138916015625, -275.11016845703125, -263.85894775390625, -252.60772705078125, -241.35650634765625, -230.10528564453125, -218.85406494140625, -207.60284423828125, -196.35162353515625, -185.10040283203125, -173.84918212890625, -162.59796142578125, -151.34674072265625, -140.09552001953125, -128.84429931640625, -117.59307861328125, -106.34185791015625, -95.09063720703125, -83.83941650390625, -72.58819580078125, -61.33697509765625, -50.08575439453125, -38.83453369140625, -27.58331298828125, -16.33209228515625, -5.08087158203125, 6.17034912109375, 17.42156982421875, 28.67279052734375, 39.92401123046875, 51.17523193359375, 62.42645263671875, 73.67767333984375, 84.92889404296875, 96.18011474609375, 107.43133544921875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-299.3314514160156, -290.0269775390625, -280.7225036621094, -271.4179992675781, -262.113525390625, -252.80905151367188, -243.50457763671875, -234.20010375976562, -224.89561462402344, -215.59112548828125, -206.28665161132812, -196.982177734375, -187.67770385742188, -178.3732147216797, -169.06874084472656, -159.76425170898438, -150.45977783203125, -141.15530395507812, -131.85081481933594, -122.54634094238281, -113.24185180664062, -103.9373779296875, -94.63290405273438, -85.32841491699219, -76.02394104003906, -66.71946716308594, -57.41497802734375, -48.110504150390625, -38.8060302734375, -29.501556396484375, -20.197052001953125, -10.892578125, -1.588104248046875, 7.71636962890625, 17.020843505859375, 26.325347900390625, 35.62982177734375, 44.934295654296875, 54.23876953125, 63.543243408203125, 72.84774780273438, 82.1522216796875, 91.45669555664062, 100.76116943359375, 110.06564331054688, 119.3701171875, 128.67462158203125, 137.97909545898438, 147.2835693359375, 156.58804321289062, 165.89251708984375, 175.197021484375, 184.50149536132812, 193.80596923828125, 203.11044311523438, 212.4149169921875, 221.71939086914062, 231.02389526367188, 240.32833862304688, 249.63284301757812, 258.9373474121094, 268.2417907714844, 277.5462951660156, 286.8507385253906, 296.1552429199219]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 3.0, 1.0, 5.0, 7.0, 13.0, 11.0, 7.0, 5.0, 5.0, 386.0, 15.0, 9.0, 2.0, 4.0, 1.0, 5.0, 2.0, 2.0, 4.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-666.2969970703125, -645.5556030273438, -624.814208984375, -604.07275390625, -583.3313598632812, -562.5899658203125, -541.8485107421875, -521.1071166992188, -500.36572265625, -479.62432861328125, -458.8829040527344, -438.1414794921875, -417.40008544921875, -396.65869140625, -375.9172668457031, -355.17584228515625, -334.4344482421875, -313.69305419921875, -292.9516296386719, -272.210205078125, -251.46881103515625, -230.7274169921875, -209.98599243164062, -189.24456787109375, -168.503173828125, -147.76177978515625, -127.0203857421875, -106.2789306640625, -85.53753662109375, -64.796142578125, -44.0546875, -23.31329345703125, -2.5718994140625, 18.16949462890625, 38.910888671875, 59.65234375, 80.39373779296875, 101.1351318359375, 121.8765869140625, 142.61798095703125, 163.359375, 184.10076904296875, 204.8421630859375, 225.5836181640625, 246.32501220703125, 267.06640625, 287.807861328125, 308.54925537109375, 329.2906494140625, 350.03204345703125, 370.7734375, 391.514892578125, 412.2562255859375, 432.9976806640625, 453.7391357421875, 474.48046875, 495.221923828125, 515.96337890625, 536.7047119140625, 557.4461669921875, 578.1876220703125, 598.928955078125, 619.67041015625, 640.4117431640625, 661.1531982421875]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 6.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-4272.4404296875, -4144.4716796875, -4016.50341796875, -3888.534912109375, -3760.56640625, -3632.59765625, -3504.629150390625, -3376.66064453125, -3248.692138671875, -3120.7236328125, -2992.755126953125, -2864.78662109375, -2736.81787109375, -2608.849609375, -2480.880859375, -2352.912353515625, -2224.94384765625, -2096.975341796875, -1969.0068359375, -1841.038330078125, -1713.06982421875, -1585.10107421875, -1457.132568359375, -1329.1640625, -1201.195556640625, -1073.22705078125, -945.258544921875, -817.2900390625, -689.3212890625, -561.352783203125, -433.38427734375, -305.415771484375, -177.447265625, -49.478515625, 78.48974609375, 206.45849609375, 334.4267578125, 462.3955078125, 590.36376953125, 718.33251953125, 846.30078125, 974.26953125, 1102.23828125, 1230.20654296875, 1358.17529296875, 1486.1435546875, 1614.1123046875, 1742.08056640625, 1870.04931640625, 1998.01806640625, 2125.986328125, 2253.955078125, 2381.92333984375, 2509.89208984375, 2637.8603515625, 2765.8291015625, 2893.7978515625, 3021.76611328125, 3149.73486328125, 3277.703125, 3405.671875, 3533.64013671875, 3661.60888671875, 3789.5771484375, 3917.5458984375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 11.0, 20.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-1330.109130859375, -1286.6636962890625, -1243.21826171875, -1199.77294921875, -1156.3275146484375, -1112.882080078125, -1069.4366455078125, -1025.9912109375, -982.5458984375, -939.1004638671875, -895.655029296875, -852.2096557617188, -808.7642211914062, -765.31884765625, -721.8734130859375, -678.4280395507812, -634.9826049804688, -591.5371704101562, -548.091796875, -504.6463623046875, -461.20098876953125, -417.75555419921875, -374.3101806640625, -330.86474609375, -287.4193115234375, -243.973876953125, -200.528564453125, -157.0831298828125, -113.6376953125, -70.1922607421875, -26.7469482421875, 16.698486328125, 60.1439208984375, 103.58935546875, 147.0347900390625, 190.4801025390625, 233.925537109375, 277.3709716796875, 320.81640625, 364.26171875, 407.7071533203125, 451.152587890625, 494.5980224609375, 538.04345703125, 581.48876953125, 624.9342041015625, 668.379638671875, 711.8250732421875, 755.2705078125, 798.7158203125, 842.161376953125, 885.606689453125, 929.052001953125, 972.49755859375, 1015.94287109375, 1059.38818359375, 1102.833740234375, 1146.279052734375, 1189.724609375, 1233.169921875, 1276.615234375, 1320.060791015625, 1363.506103515625, 1406.95166015625, 1450.39697265625]}, "_runtime": 18058.924719810486, "_timestamp": 1585615428.5575893, "_step": 98}
{"Episode reward": 56.53949473006617, "Episode length": 435, "Policy Loss": -2.9034125804901123, "Value Loss": 21.014982223510742, "_runtime": 18059.14129471779, "_timestamp": 1585615428.7741642, "_step": 99}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": 3.746666669845581, "Value Loss": 68.61964416503906, "_runtime": 18059.647252082825, "_timestamp": 1585615429.2801216, "_step": 100}
{"Episode reward": 65.39999999999978, "Episode length": 346, "Policy Loss": -2.999086856842041, "Value Loss": 25.534284591674805, "_runtime": 18059.974822998047, "_timestamp": 1585615429.6076925, "_step": 101}
{"Episode reward": 79.5948406360112, "Episode length": 205, "Policy Loss": -2.000772714614868, "Value Loss": 40.49839782714844, "_runtime": 18060.14647746086, "_timestamp": 1585615429.779347, "_step": 102}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 1.7927768230438232, "Value Loss": 79.24580383300781, "_runtime": 18060.33863210678, "_timestamp": 1585615429.9715016, "_step": 103}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 6.886258125305176, "Value Loss": 72.25535583496094, "_runtime": 18060.667446374893, "_timestamp": 1585615430.3003159, "_step": 104}
{"Episode reward": 78.39999999999998, "Episode length": 216, "Policy Loss": -2.262683391571045, "Value Loss": 37.845035552978516, "_runtime": 18060.840241909027, "_timestamp": 1585615430.4731114, "_step": 105}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": 6.364404201507568, "Value Loss": 78.47949981689453, "_runtime": 18061.05191731453, "_timestamp": 1585615430.6847868, "_step": 106}
{"Episode reward": 86.1987690839684, "Episode length": 139, "Policy Loss": -3.298253059387207, "Value Loss": 58.367958068847656, "_runtime": 18061.2344083786, "_timestamp": 1585615430.8672779, "_step": 107}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 5.394092559814453, "Value Loss": 73.68734741210938, "_runtime": 18061.416048288345, "_timestamp": 1585615431.0489178, "_step": 108}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 3.49932599067688, "Value Loss": 71.67589569091797, "_runtime": 18062.007865190506, "_timestamp": 1585615431.6407347, "_step": 109}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": -5.180260181427002, "Value Loss": 20.449304580688477, "_runtime": 18062.199696063995, "_timestamp": 1585615431.8325655, "_step": 110}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 1.5345953702926636, "Value Loss": 69.38420104980469, "_runtime": 18063.62982583046, "_timestamp": 1585615433.2626953, "_step": 111}
{"Episode reward": 4.659672547831406, "Episode length": 955, "Policy Loss": -6.558952331542969, "Value Loss": 9.412091255187988, "_runtime": 18063.824926376343, "_timestamp": 1585615433.4577959, "_step": 112}
{"Episode reward": 89.80000000000003, "Episode length": 102, "Policy Loss": 3.2280285358428955, "Value Loss": 80.63226318359375, "_runtime": 18064.01089167595, "_timestamp": 1585615433.6437612, "_step": 113}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": -1.9423577785491943, "Value Loss": 68.62255859375, "_runtime": 18064.242043733597, "_timestamp": 1585615433.8749132, "_step": 114}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -1.75684654712677, "Value Loss": 69.12346649169922, "_runtime": 18064.60956096649, "_timestamp": 1585615434.2424304, "_step": 115}
{"Episode reward": 75.49731085242232, "Episode length": 246, "Policy Loss": -7.7776336669921875, "Value Loss": 38.79325485229492, "_runtime": 18065.060256004333, "_timestamp": 1585615434.6931255, "_step": 116}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": -5.866441249847412, "Value Loss": 27.942209243774414, "_runtime": 18065.850284576416, "_timestamp": 1585615435.483154, "_step": 117}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": -5.166223526000977, "Value Loss": 17.4158992767334, "_runtime": 18066.16518163681, "_timestamp": 1585615435.798051, "_step": 118}
{"Episode reward": 79.49999999999999, "Episode length": 205, "Policy Loss": -4.91591215133667, "Value Loss": 45.96683120727539, "_runtime": 18066.486847877502, "_timestamp": 1585615436.1197174, "_step": 119}
{"Episode reward": 79.29999999999998, "Episode length": 207, "Policy Loss": -4.755423545837402, "Value Loss": 38.28582763671875, "_runtime": 18066.8156375885, "_timestamp": 1585615436.448507, "_step": 120}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": 1.5399070978164673, "Value Loss": 42.173336029052734, "_runtime": 18067.47134900093, "_timestamp": 1585615437.1042185, "_step": 121}
{"Episode reward": 55.599999999999646, "Episode length": 444, "Policy Loss": -2.9823782444000244, "Value Loss": 21.045175552368164, "_runtime": 18067.68655347824, "_timestamp": 1585615437.319423, "_step": 122}
{"Episode reward": 87.11124897263947, "Episode length": 129, "Policy Loss": -3.0394651889801025, "Value Loss": 67.51043701171875, "_runtime": 18067.967655658722, "_timestamp": 1585615437.6005251, "_step": 123}
{"Episode reward": 81.7585405177437, "Episode length": 183, "Policy Loss": 2.7390201091766357, "Value Loss": 47.84387969970703, "_runtime": 18068.360507249832, "_timestamp": 1585615437.9933767, "_step": 124}
{"Episode reward": 74.99999999999991, "Episode length": 250, "Policy Loss": 4.110701084136963, "Value Loss": 39.18998718261719, "_runtime": 18068.53911805153, "_timestamp": 1585615438.1719875, "_step": 125}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 1.0753165483474731, "Value Loss": 69.67903900146484, "_runtime": 18068.849309444427, "_timestamp": 1585615438.482179, "_step": 126}
{"Episode reward": 79.69999999999999, "Episode length": 203, "Policy Loss": -3.561385154724121, "Value Loss": 38.155418395996094, "_runtime": 18069.029599666595, "_timestamp": 1585615438.6624691, "_step": 127}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 0.36897116899490356, "Value Loss": 76.3906478881836, "_runtime": 18069.22640156746, "_timestamp": 1585615438.859271, "_step": 128}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": -3.017787218093872, "Value Loss": 62.91120910644531, "_runtime": 18069.413200616837, "_timestamp": 1585615439.04607, "_step": 129}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 1.323132872581482, "Value Loss": 71.21916961669922, "_runtime": 18069.58882546425, "_timestamp": 1585615439.221695, "_step": 130}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -0.34172648191452026, "Value Loss": 71.87347412109375, "_runtime": 18069.77380514145, "_timestamp": 1585615439.4066746, "_step": 131}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": -2.6315383911132812, "Value Loss": 65.29122924804688, "_runtime": 18070.610386371613, "_timestamp": 1585615440.2432559, "_step": 132}
{"Episode reward": 43.19999999999947, "Episode length": 568, "Policy Loss": -7.185871124267578, "Value Loss": 15.420401573181152, "_runtime": 18070.798125982285, "_timestamp": 1585615440.4309955, "_step": 133}
{"Episode reward": 88.81271618213508, "Episode length": 113, "Policy Loss": 2.674544095993042, "Value Loss": 66.90431213378906, "_runtime": 18071.176389217377, "_timestamp": 1585615440.8092587, "_step": 134}
{"Episode reward": 74.1999999999999, "Episode length": 258, "Policy Loss": -4.336215019226074, "Value Loss": 30.804405212402344, "_runtime": 18071.390885829926, "_timestamp": 1585615441.0237553, "_step": 135}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": -1.002382755279541, "Value Loss": 67.69712829589844, "_runtime": 18071.569029331207, "_timestamp": 1585615441.2018988, "_step": 136}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 0.5473954677581787, "Value Loss": 69.11824798583984, "_runtime": 18071.783552646637, "_timestamp": 1585615441.4164221, "_step": 137}
{"Episode reward": 86.60000000000004, "Episode length": 134, "Policy Loss": -5.2802534103393555, "Value Loss": 58.444740295410156, "_runtime": 18071.96634864807, "_timestamp": 1585615441.5992181, "_step": 138}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": -2.002098560333252, "Value Loss": 66.31389617919922, "_runtime": 18072.59943008423, "_timestamp": 1585615442.2322996, "_step": 139}
{"Episode reward": 57.167416381530536, "Episode length": 430, "Policy Loss": -6.626741409301758, "Value Loss": 18.97309684753418, "_runtime": 18073.008545160294, "_timestamp": 1585615442.6414146, "_step": 140}
{"Episode reward": 73.0999999999999, "Episode length": 269, "Policy Loss": -5.387490749359131, "Value Loss": 29.48243522644043, "_runtime": 18073.29630804062, "_timestamp": 1585615442.9291775, "_step": 141}
{"Episode reward": 80.69737897654996, "Episode length": 194, "Policy Loss": -1.3427760601043701, "Value Loss": 39.359718322753906, "_runtime": 18073.510385274887, "_timestamp": 1585615443.1432548, "_step": 142}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": 2.123095750808716, "Value Loss": 70.97881317138672, "_runtime": 18074.00308918953, "_timestamp": 1585615443.6359587, "_step": 143}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": -5.940135955810547, "Value Loss": 24.810991287231445, "_runtime": 18074.62582564354, "_timestamp": 1585615444.2586951, "_step": 144}
{"Episode reward": 57.96005795338541, "Episode length": 422, "Policy Loss": -7.229297637939453, "Value Loss": 19.729156494140625, "_runtime": 18074.824608802795, "_timestamp": 1585615444.4574783, "_step": 145}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -2.3576369285583496, "Value Loss": 64.28662872314453, "_runtime": 18075.02889561653, "_timestamp": 1585615444.661765, "_step": 146}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 0.8969133496284485, "Value Loss": 73.66854095458984, "_runtime": 18075.606738090515, "_timestamp": 1585615445.2396076, "_step": 147}
{"Episode reward": 62.46121983656132, "Episode length": 378, "Policy Loss": -6.914061069488525, "Value Loss": 22.35466766357422, "_runtime": 18075.79144883156, "_timestamp": 1585615445.4243183, "_step": 148}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -2.789248466491699, "Value Loss": 65.5119857788086, "_runtime": 18076.073459148407, "_timestamp": 1585615445.7063286, "_step": 149}
{"Episode reward": 81.04521160996774, "Episode length": 190, "Policy Loss": -0.9133792519569397, "Value Loss": 39.61803436279297, "_runtime": 18076.600634098053, "_timestamp": 1585615446.2335036, "_step": 150}
{"Episode reward": 65.38932582483955, "Episode length": 347, "Policy Loss": -6.354761600494385, "Value Loss": 22.702146530151367, "_runtime": 18076.911034822464, "_timestamp": 1585615446.5439043, "_step": 151}
{"Episode reward": 79.19999999999999, "Episode length": 208, "Policy Loss": -3.949540138244629, "Value Loss": 38.58173370361328, "_runtime": 18077.500153303146, "_timestamp": 1585615447.1330228, "_step": 152}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": -4.973449230194092, "Value Loss": 19.770488739013672, "_runtime": 18078.015919208527, "_timestamp": 1585615447.6487887, "_step": 153}
{"Episode reward": 65.79999999999978, "Episode length": 342, "Policy Loss": -6.326777458190918, "Value Loss": 23.8253231048584, "_runtime": 18078.495651960373, "_timestamp": 1585615448.1285214, "_step": 154}
{"Episode reward": 67.59999999999982, "Episode length": 324, "Policy Loss": -2.408176898956299, "Value Loss": 24.58841896057129, "_runtime": 18078.958547592163, "_timestamp": 1585615448.591417, "_step": 155}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": -7.573784351348877, "Value Loss": 27.035083770751953, "_runtime": 18079.622112751007, "_timestamp": 1585615449.2549822, "_step": 156}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": -6.243061065673828, "Value Loss": 17.98723030090332, "_runtime": 18079.812839508057, "_timestamp": 1585615449.445709, "_step": 157}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -1.2583770751953125, "Value Loss": 66.78660583496094, "_runtime": 18080.049347162247, "_timestamp": 1585615449.6822166, "_step": 158}
{"Episode reward": 85.13616785854106, "Episode length": 149, "Policy Loss": -6.721273422241211, "Value Loss": 56.44058609008789, "_runtime": 18080.351164102554, "_timestamp": 1585615449.9840336, "_step": 159}
{"Episode reward": 81.30000000000001, "Episode length": 187, "Policy Loss": -4.582264423370361, "Value Loss": 40.77707290649414, "_runtime": 18080.536422729492, "_timestamp": 1585615450.1692922, "_step": 160}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -1.530930757522583, "Value Loss": 63.552120208740234, "_runtime": 18080.701182603836, "_timestamp": 1585615450.334052, "_step": 161}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": 1.8202500343322754, "Value Loss": 72.50360870361328, "_runtime": 18081.27614545822, "_timestamp": 1585615450.909015, "_step": 162}
{"Episode reward": 61.255735765304145, "Episode length": 388, "Policy Loss": -6.965694427490234, "Value Loss": 20.567668914794922, "_runtime": 18081.46784734726, "_timestamp": 1585615451.1007168, "_step": 163}
{"Episode reward": 87.69101674635316, "Episode length": 124, "Policy Loss": 0.02752808667719364, "Value Loss": 59.61046600341797, "_runtime": 18081.64262652397, "_timestamp": 1585615451.275496, "_step": 164}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -0.046397626399993896, "Value Loss": 66.96072387695312, "_runtime": 18081.849408626556, "_timestamp": 1585615451.482278, "_step": 165}
{"Episode reward": 87.74420683234933, "Episode length": 123, "Policy Loss": -1.8692939281463623, "Value Loss": 61.693721771240234, "_runtime": 18082.05791091919, "_timestamp": 1585615451.6907804, "_step": 166}
{"Episode reward": 86.40000000000003, "Episode length": 136, "Policy Loss": -0.9662989377975464, "Value Loss": 56.925357818603516, "_runtime": 18082.23613882065, "_timestamp": 1585615451.8690083, "_step": 167}
{"Episode reward": 88.53036002746825, "Episode length": 115, "Policy Loss": 3.052698850631714, "Value Loss": 66.71978759765625, "_runtime": 18082.432510375977, "_timestamp": 1585615452.0653799, "_step": 168}
{"Episode reward": 87.20000000000003, "Episode length": 128, "Policy Loss": -1.0529558658599854, "Value Loss": 58.08635711669922, "_runtime": 18082.62582540512, "_timestamp": 1585615452.258695, "_step": 169}
{"Episode reward": 87.59935241049355, "Episode length": 125, "Policy Loss": -3.0842931270599365, "Value Loss": 62.596378326416016, "_runtime": 18082.798851966858, "_timestamp": 1585615452.4317214, "_step": 170}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 2.8465499877929688, "Value Loss": 68.12564849853516, "_runtime": 18083.077198266983, "_timestamp": 1585615452.7100677, "_step": 171}
{"Episode reward": 81.60000000000002, "Episode length": 184, "Policy Loss": -7.844783782958984, "Value Loss": 46.7237434387207, "_runtime": 18083.363555669785, "_timestamp": 1585615452.9964252, "_step": 172}
{"Episode reward": 80.9, "Episode length": 191, "Policy Loss": -2.651700496673584, "Value Loss": 39.70526123046875, "_runtime": 18083.57082772255, "_timestamp": 1585615453.2036972, "_step": 173}
{"Episode reward": 86.50000000000004, "Episode length": 135, "Policy Loss": -4.3877387046813965, "Value Loss": 54.628841400146484, "_runtime": 18084.03777718544, "_timestamp": 1585615453.6706467, "_step": 174}
{"Episode reward": 68.67602085433883, "Episode length": 314, "Policy Loss": -7.002303600311279, "Value Loss": 25.323312759399414, "_runtime": 18084.246471881866, "_timestamp": 1585615453.8793414, "_step": 175}
{"Episode reward": 86.60000000000004, "Episode length": 134, "Policy Loss": -3.085692882537842, "Value Loss": 55.507511138916016, "_runtime": 18084.42662858963, "_timestamp": 1585615454.059498, "_step": 176}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 0.43474704027175903, "Value Loss": 64.30941009521484, "_runtime": 18084.62986755371, "_timestamp": 1585615454.262737, "_step": 177}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -2.5420010089874268, "Value Loss": 61.43500518798828, "_runtime": 18084.965408086777, "_timestamp": 1585615454.5982776, "_step": 178}
{"Episode reward": 77.6965538374148, "Episode length": 224, "Policy Loss": -6.087536334991455, "Value Loss": 34.59905242919922, "_runtime": 18085.365931749344, "_timestamp": 1585615454.9988012, "_step": 179}
{"Episode reward": 72.99999999999989, "Episode length": 270, "Policy Loss": -6.469111919403076, "Value Loss": 28.816709518432617, "_runtime": 18085.912436008453, "_timestamp": 1585615455.5453055, "_step": 180}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": -6.648453235626221, "Value Loss": 21.076675415039062, "_runtime": 18086.10226893425, "_timestamp": 1585615455.7351384, "_step": 181}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": -0.1838018149137497, "Value Loss": 66.13711547851562, "_runtime": 18087.058564662933, "_timestamp": 1585615456.6914341, "_step": 182}
{"Episode reward": 35.82913266410988, "Episode length": 642, "Policy Loss": -7.571858882904053, "Value Loss": 13.125357627868652, "_runtime": 18087.477732658386, "_timestamp": 1585615457.1106021, "_step": 183}
{"Episode reward": 73.4999999999999, "Episode length": 265, "Policy Loss": -6.1637067794799805, "Value Loss": 28.06281089782715, "_runtime": 18088.270089387894, "_timestamp": 1585615457.9029589, "_step": 184}
{"Episode reward": 46.02311138499014, "Episode length": 542, "Policy Loss": -5.783540725708008, "Value Loss": 15.164752960205078, "_runtime": 18088.49299621582, "_timestamp": 1585615458.1258657, "_step": 185}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 11.7850923538208, "Value Loss": 76.97284698486328, "_runtime": 18088.675201416016, "_timestamp": 1585615458.308071, "_step": 186}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 1.5166295766830444, "Value Loss": 63.43885040283203, "_runtime": 18088.86977481842, "_timestamp": 1585615458.5026443, "_step": 187}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 7.937777519226074, "Value Loss": 69.58666229248047, "_runtime": 18089.04439973831, "_timestamp": 1585615458.6772692, "_step": 188}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": -0.3625528812408447, "Value Loss": 65.04563903808594, "_runtime": 18089.337290763855, "_timestamp": 1585615458.9701602, "_step": 189}
{"Episode reward": 80.56159151336642, "Episode length": 196, "Policy Loss": -7.12208890914917, "Value Loss": 39.69741439819336, "_runtime": 18089.857309103012, "_timestamp": 1585615459.4901786, "_step": 190}
{"Episode reward": 64.78136863708474, "Episode length": 353, "Policy Loss": -6.647090435028076, "Value Loss": 21.697893142700195, "_runtime": 18090.05145215988, "_timestamp": 1585615459.6843216, "_step": 191}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": -4.122241020202637, "Value Loss": 58.130531311035156, "_runtime": 18090.246591567993, "_timestamp": 1585615459.879461, "_step": 192}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -3.935091018676758, "Value Loss": 59.50272750854492, "_runtime": 18090.46291899681, "_timestamp": 1585615460.0957885, "_step": 193}
{"Episode reward": 87.50000000000003, "Episode length": 125, "Policy Loss": -3.727637767791748, "Value Loss": 59.48894500732422, "_runtime": 18090.77972817421, "_timestamp": 1585615460.4125977, "_step": 194}
{"Episode reward": 79.69999999999999, "Episode length": 203, "Policy Loss": -6.353966236114502, "Value Loss": 38.67724609375, "_runtime": 18090.957149267197, "_timestamp": 1585615460.5900187, "_step": 195}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": -1.8734972476959229, "Value Loss": 64.48871612548828, "_runtime": 18091.26751446724, "_timestamp": 1585615460.900384, "_step": 196}
{"Episode reward": 79.09999999999998, "Episode length": 209, "Policy Loss": -4.221871852874756, "Value Loss": 38.313106536865234, "_runtime": 18091.6913626194, "_timestamp": 1585615461.324232, "_step": 197}
{"Episode reward": 71.59999999999988, "Episode length": 284, "Policy Loss": -8.037923812866211, "Value Loss": 28.02618408203125, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625, 233408.015625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-233405.90625, -95294.21875, 42817.46875, 180929.15625, 319040.84375, 457152.53125, 595264.25, 733375.875, 871487.625, 1009599.375, 1147711.0, 1285822.625, 1423934.375, 1562046.125, 1700157.75, 1838269.375, 1976381.125, 2114492.75, 2252604.5, 2390716.0, 2528827.75, 2666939.5, 2805051.0, 2943162.75, 3081274.5, 3219386.25, 3357498.0, 3495609.5, 3633721.25, 3771833.0, 3909944.5, 4048056.5, 4186168.0, 4324279.5, 4462391.5, 4600503.0, 4738615.0, 4876726.5, 5014838.0, 5152950.0, 5291061.5, 5429173.0, 5567285.0, 5705396.5, 5843508.0, 5981620.0, 6119731.5, 6257843.5, 6395955.0, 6534066.5, 6672178.5, 6810290.0, 6948402.0, 7086513.5, 7224625.0, 7362737.0, 7500848.5, 7638960.0, 7777072.0, 7915183.5, 8053295.0, 8191407.0, 8329519.0, 8467630.0, 8605742.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], "bins": [-841916.75, -828746.875, -815577.0, -802407.125, -789237.25, -776067.375, -762897.5, -749727.625, -736557.75, -723387.875, -710218.0, -697048.1875, -683878.3125, -670708.4375, -657538.5625, -644368.6875, -631198.8125, -618028.9375, -604859.0625, -591689.1875, -578519.3125, -565349.5, -552179.625, -539009.75, -525839.875, -512669.96875, -499500.09375, -486330.21875, -473160.375, -459990.5, -446820.625, -433650.75, -420480.875, -407311.0, -394141.125, -380971.25, -367801.375, -354631.53125, -341461.65625, -328291.78125, -315121.875, -301952.0625, -288782.1875, -275612.3125, -262442.4375, -249272.5625, -236102.6875, -222932.8125, -209762.9375, -196593.0625, -183423.1875, -170253.3125, -157083.4375, -143913.5625, -130743.6875, -117573.8125, -104404.0, -91234.125, -78064.25, -64894.375, -51724.5, -38554.625, -25384.75, -12214.875, 955.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 4.0, 0.0, 6.0, 9.0, 19.0, 285.0, 26.0, 18.0, 4.0, 15.0, 18.0, 24.0, 14.0, 8.0, 6.0, 1.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 1.0, 0.0, 1.0], "bins": [-1740639.25, -1701285.5, -1661931.75, -1622578.0, -1583224.25, -1543870.5, -1504516.75, -1465163.0, -1425809.25, -1386455.5, -1347101.75, -1307748.0, -1268394.25, -1229040.5, -1189686.75, -1150333.0, -1110979.25, -1071625.5, -1032271.6875, -992917.9375, -953564.1875, -914210.4375, -874856.6875, -835502.9375, -796149.125, -756795.375, -717441.625, -678087.875, -638734.125, -599380.375, -560026.625, -520672.875, -481319.125, -441965.375, -402611.625, -363257.875, -323904.125, -284550.375, -245196.625, -205842.875, -166489.125, -127135.375, -87781.625, -48427.875, -9074.125, 30279.625, 69633.375, 108987.125, 148341.0, 187694.75, 227048.5, 266402.25, 305756.0, 345109.75, 384463.5, 423817.25, 463171.0, 502524.75, 541878.5, 581232.25, 620586.0, 659939.75, 699293.5, 738647.25, 778001.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0], "bins": [-19737500.0, -19153370.0, -18569242.0, -17985112.0, -17400984.0, -16816854.0, -16232724.0, -15648595.0, -15064466.0, -14480337.0, -13896208.0, -13312078.0, -12727949.0, -12143820.0, -11559690.0, -10975561.0, -10391432.0, -9807303.0, -9223174.0, -8639044.0, -8054915.0, -7470786.0, -6886656.0, -6302527.0, -5718398.0, -5134269.0, -4550140.0, -3966010.0, -3381881.0, -2797752.0, -2213622.0, -1629494.0, -1045364.0, -461234.0, 122894.0, 707024.0, 1291152.0, 1875282.0, 2459412.0, 3043540.0, 3627670.0, 4211800.0, 4795928.0, 5380058.0, 5964188.0, 6548316.0, 7132446.0, 7716574.0, 8300704.0, 8884834.0, 9468962.0, 10053092.0, 10637220.0, 11221350.0, 11805480.0, 12389608.0, 12973738.0, 13557868.0, 14141996.0, 14726124.0, 15310256.0, 15894384.0, 16478512.0, 17062644.0, 17646772.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 7.0, 30.0, 0.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-6380515.0, -6169312.5, -5958109.5, -5746907.0, -5535704.0, -5324501.5, -5113299.0, -4902096.0, -4690893.5, -4479691.0, -4268488.0, -4057285.5, -3846082.75, -3634880.0, -3423677.5, -3212474.75, -3001272.0, -2790069.25, -2578866.5, -2367664.0, -2156461.0, -1945258.5, -1734056.0, -1522853.0, -1311650.5, -1100448.0, -889245.0, -678042.5, -466840.0, -255637.0, -44434.5, 166768.5, 377971.0, 589173.5, 800376.5, 1011579.0, 1222782.0, 1433984.5, 1645187.0, 1856390.0, 2067593.0, 2278795.0, 2489998.0, 2701201.0, 2912403.0, 3123606.0, 3334809.0, 3546011.0, 3757214.0, 3968417.0, 4179619.0, 4390822.0, 4602025.0, 4813227.0, 5024430.0, 5235633.0, 5446835.0, 5658038.0, 5869241.0, 6080444.0, 6291646.0, 6502849.0, 6714052.0, 6925254.0, 7136457.0]}, "_runtime": 18091.96814417839, "_timestamp": 1585615461.6010137, "_step": 198}
{"Episode reward": 81.4, "Episode length": 186, "Policy Loss": -3.6981256008148193, "Value Loss": 40.126773834228516, "_runtime": 18092.147232055664, "_timestamp": 1585615461.7801015, "_step": 199}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": -1.3868389129638672, "Value Loss": 64.69122314453125, "_runtime": 18093.048266649246, "_timestamp": 1585615462.6811361, "_step": 200}
{"Episode reward": 39.59999999999942, "Episode length": 604, "Policy Loss": -7.76349401473999, "Value Loss": 13.807209968566895, "_runtime": 18093.23625779152, "_timestamp": 1585615462.8691273, "_step": 201}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -3.82039737701416, "Value Loss": 60.5259895324707, "_runtime": 18093.434113502502, "_timestamp": 1585615463.066983, "_step": 202}
{"Episode reward": 86.90000000000003, "Episode length": 131, "Policy Loss": -3.7299065589904785, "Value Loss": 57.7153205871582, "_runtime": 18093.64899134636, "_timestamp": 1585615463.2818608, "_step": 203}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -3.1459336280822754, "Value Loss": 60.77461242675781, "_runtime": 18093.81999349594, "_timestamp": 1585615463.452863, "_step": 204}
{"Episode reward": 88.97834619157368, "Episode length": 111, "Policy Loss": -1.0547611713409424, "Value Loss": 64.57756042480469, "_runtime": 18094.01730656624, "_timestamp": 1585615463.650176, "_step": 205}
{"Episode reward": 87.10000000000004, "Episode length": 129, "Policy Loss": -2.2540972232818604, "Value Loss": 58.67516326904297, "_runtime": 18094.396097421646, "_timestamp": 1585615464.028967, "_step": 206}
{"Episode reward": 74.59999999999991, "Episode length": 254, "Policy Loss": -5.554854393005371, "Value Loss": 29.952749252319336, "_runtime": 18094.57550430298, "_timestamp": 1585615464.2083738, "_step": 207}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 16.241416931152344, "Value Loss": 78.15580749511719, "_runtime": 18094.922152280807, "_timestamp": 1585615464.5550218, "_step": 208}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": -7.236496925354004, "Value Loss": 31.505840301513672, "_runtime": 18095.377710342407, "_timestamp": 1585615465.0105798, "_step": 209}
{"Episode reward": 69.69999999999985, "Episode length": 303, "Policy Loss": -6.690241813659668, "Value Loss": 25.321407318115234, "_runtime": 18095.684623003006, "_timestamp": 1585615465.3174925, "_step": 210}
{"Episode reward": 79.39385181581599, "Episode length": 207, "Policy Loss": -4.519278526306152, "Value Loss": 35.72141647338867, "_runtime": 18096.124378442764, "_timestamp": 1585615465.757248, "_step": 211}
{"Episode reward": 70.69783631414161, "Episode length": 294, "Policy Loss": -7.309409141540527, "Value Loss": 24.75872802734375, "_runtime": 18096.453753709793, "_timestamp": 1585615466.0866232, "_step": 212}
{"Episode reward": 78.6205171642568, "Episode length": 214, "Policy Loss": -5.970548629760742, "Value Loss": 34.49655532836914, "_runtime": 18096.73228788376, "_timestamp": 1585615466.3651574, "_step": 213}
{"Episode reward": 81.70000000000002, "Episode length": 183, "Policy Loss": -4.073146820068359, "Value Loss": 39.379638671875, "_runtime": 18096.91895341873, "_timestamp": 1585615466.551823, "_step": 214}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -2.2090632915496826, "Value Loss": 61.635704040527344, "_runtime": 18097.394454956055, "_timestamp": 1585615467.0273244, "_step": 215}
{"Episode reward": 68.12343482968845, "Episode length": 319, "Policy Loss": -6.045804977416992, "Value Loss": 23.538949966430664, "_runtime": 18097.579907417297, "_timestamp": 1585615467.212777, "_step": 216}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -0.3348478674888611, "Value Loss": 65.03941345214844, "_runtime": 18098.413417100906, "_timestamp": 1585615468.0462866, "_step": 217}
{"Episode reward": 43.374265310074605, "Episode length": 567, "Policy Loss": -7.302072048187256, "Value Loss": 13.969416618347168, "_runtime": 18099.066321611404, "_timestamp": 1585615468.699191, "_step": 218}
{"Episode reward": 56.49930449551287, "Episode length": 436, "Policy Loss": -7.508489608764648, "Value Loss": 18.40552520751953, "_runtime": 18099.238005161285, "_timestamp": 1585615468.8708746, "_step": 219}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 0.16459038853645325, "Value Loss": 65.97257995605469, "_runtime": 18099.52643442154, "_timestamp": 1585615469.159304, "_step": 220}
{"Episode reward": 82.70000000000003, "Episode length": 173, "Policy Loss": -5.9170050621032715, "Value Loss": 41.55282211303711, "_runtime": 18099.826957464218, "_timestamp": 1585615469.459827, "_step": 221}
{"Episode reward": 81.30000000000001, "Episode length": 187, "Policy Loss": -3.4774832725524902, "Value Loss": 39.4922981262207, "_runtime": 18100.31350851059, "_timestamp": 1585615469.946378, "_step": 222}
{"Episode reward": 66.9999999999998, "Episode length": 330, "Policy Loss": -5.8683013916015625, "Value Loss": 25.885263442993164, "_runtime": 18100.617901563644, "_timestamp": 1585615470.250771, "_step": 223}
{"Episode reward": 79.89999999999999, "Episode length": 201, "Policy Loss": -6.244537830352783, "Value Loss": 43.7935791015625, "_runtime": 18100.822820425034, "_timestamp": 1585615470.45569, "_step": 224}
{"Episode reward": 86.80000000000004, "Episode length": 132, "Policy Loss": -5.100722789764404, "Value Loss": 54.08659744262695, "_runtime": 18101.828987121582, "_timestamp": 1585615471.4618566, "_step": 225}
{"Episode reward": 32.53938647862479, "Episode length": 675, "Policy Loss": -7.228367328643799, "Value Loss": 12.010040283203125, "_runtime": 18102.391525030136, "_timestamp": 1585615472.0243945, "_step": 226}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": -6.88365364074707, "Value Loss": 21.113357543945312, "_runtime": 18102.713606357574, "_timestamp": 1585615472.3464758, "_step": 227}
{"Episode reward": 78.39525747299191, "Episode length": 217, "Policy Loss": -4.20642614364624, "Value Loss": 35.606719970703125, "_runtime": 18103.35652756691, "_timestamp": 1585615472.989397, "_step": 228}
{"Episode reward": 58.69999999999969, "Episode length": 413, "Policy Loss": -6.56842565536499, "Value Loss": 18.594072341918945, "_runtime": 18104.763022184372, "_timestamp": 1585615474.3958917, "_step": 229}
{"Episode reward": 7.600000000000975, "Episode length": 924, "Policy Loss": -7.058284282684326, "Value Loss": 9.039855003356934, "_runtime": 18104.98944425583, "_timestamp": 1585615474.6223137, "_step": 230}
{"Episode reward": 86.50000000000004, "Episode length": 135, "Policy Loss": -5.9261322021484375, "Value Loss": 52.80924606323242, "_runtime": 18105.342828273773, "_timestamp": 1585615474.9756978, "_step": 231}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": -6.288697242736816, "Value Loss": 34.63804244995117, "_runtime": 18105.589769363403, "_timestamp": 1585615475.2226388, "_step": 232}
{"Episode reward": 87.30000000000004, "Episode length": 127, "Policy Loss": -2.1219217777252197, "Value Loss": 59.25626754760742, "_runtime": 18106.025773525238, "_timestamp": 1585615475.658643, "_step": 233}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": -5.5593342781066895, "Value Loss": 25.67920684814453, "_runtime": 18106.223744153976, "_timestamp": 1585615475.8566136, "_step": 234}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -1.7980411052703857, "Value Loss": 59.50419616699219, "_runtime": 18106.38483786583, "_timestamp": 1585615476.0177073, "_step": 235}
{"Episode reward": 89.70000000000003, "Episode length": 103, "Policy Loss": 1.903188705444336, "Value Loss": 70.68798065185547, "_runtime": 18106.94398880005, "_timestamp": 1585615476.5768583, "_step": 236}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": -5.943460941314697, "Value Loss": 20.28335189819336, "_runtime": 18107.13773202896, "_timestamp": 1585615476.7706015, "_step": 237}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": 0.4258096516132355, "Value Loss": 58.54716491699219, "_runtime": 18107.523478269577, "_timestamp": 1585615477.1563478, "_step": 238}
{"Episode reward": 73.6999999999999, "Episode length": 263, "Policy Loss": -5.000577926635742, "Value Loss": 27.523008346557617, "_runtime": 18107.83191728592, "_timestamp": 1585615477.4647868, "_step": 239}
{"Episode reward": 80.4, "Episode length": 196, "Policy Loss": -2.8241727352142334, "Value Loss": 38.58433532714844, "_runtime": 18108.021822214127, "_timestamp": 1585615477.6546917, "_step": 240}
{"Episode reward": 87.74567987786143, "Episode length": 123, "Policy Loss": -1.7155230045318604, "Value Loss": 56.959712982177734, "_runtime": 18108.985859155655, "_timestamp": 1585615478.6187286, "_step": 241}
{"Episode reward": 35.59532237937613, "Episode length": 645, "Policy Loss": -6.512764930725098, "Value Loss": 13.48418140411377, "_runtime": 18109.18476653099, "_timestamp": 1585615478.817636, "_step": 242}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 3.238887071609497, "Value Loss": 63.029937744140625, "_runtime": 18109.37635922432, "_timestamp": 1585615479.0092287, "_step": 243}
{"Episode reward": 87.50000000000003, "Episode length": 125, "Policy Loss": -2.16921329498291, "Value Loss": 60.290260314941406, "_runtime": 18109.61077094078, "_timestamp": 1585615479.2436404, "_step": 244}
{"Episode reward": 87.00000000000003, "Episode length": 130, "Policy Loss": -3.069983959197998, "Value Loss": 55.6120719909668, "_runtime": 18109.783133745193, "_timestamp": 1585615479.4160032, "_step": 245}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": 2.3210580348968506, "Value Loss": 64.84172821044922, "_runtime": 18110.326605796814, "_timestamp": 1585615479.9594753, "_step": 246}
{"Episode reward": 63.29526810049986, "Episode length": 368, "Policy Loss": -5.70035457611084, "Value Loss": 22.230968475341797, "_runtime": 18110.556594848633, "_timestamp": 1585615480.1894643, "_step": 247}
{"Episode reward": 84.90000000000005, "Episode length": 151, "Policy Loss": -7.655019760131836, "Value Loss": 49.75086975097656, "_runtime": 18110.92129445076, "_timestamp": 1585615480.554164, "_step": 248}
{"Episode reward": 75.19999999999993, "Episode length": 248, "Policy Loss": -5.788629055023193, "Value Loss": 30.15398597717285, "_runtime": 18111.120411634445, "_timestamp": 1585615480.753281, "_step": 249}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 2.442652702331543, "Value Loss": 59.95547103881836, "_runtime": 18111.29968738556, "_timestamp": 1585615480.9325569, "_step": 250}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 2.1865031719207764, "Value Loss": 60.457618713378906, "_runtime": 18111.490561962128, "_timestamp": 1585615481.1234314, "_step": 251}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 4.391617298126221, "Value Loss": 61.802764892578125, "_runtime": 18112.608371973038, "_timestamp": 1585615482.2412415, "_step": 252}
{"Episode reward": 27.60495118664096, "Episode length": 724, "Policy Loss": -6.049286842346191, "Value Loss": 11.201087951660156, "_runtime": 18112.91642999649, "_timestamp": 1585615482.5492995, "_step": 253}
{"Episode reward": 80.19999999999999, "Episode length": 198, "Policy Loss": -2.046555995941162, "Value Loss": 36.45224380493164, "_runtime": 18113.10515856743, "_timestamp": 1585615482.738028, "_step": 254}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -1.9601020812988281, "Value Loss": 59.386993408203125, "_runtime": 18113.322558164597, "_timestamp": 1585615482.9554276, "_step": 255}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 0.5294733047485352, "Value Loss": 62.54694366455078, "_runtime": 18113.640906095505, "_timestamp": 1585615483.2737756, "_step": 256}
{"Episode reward": 79.14708853308392, "Episode length": 209, "Policy Loss": -5.261924743652344, "Value Loss": 38.39447784423828, "_runtime": 18113.959995269775, "_timestamp": 1585615483.5928648, "_step": 257}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": -5.254528045654297, "Value Loss": 35.827754974365234, "_runtime": 18115.070548772812, "_timestamp": 1585615484.7034183, "_step": 258}
{"Episode reward": 25.18450666628776, "Episode length": 749, "Policy Loss": -5.188747882843018, "Value Loss": 11.594001770019531, "_runtime": 18115.9844186306, "_timestamp": 1585615485.617288, "_step": 259}
{"Episode reward": 39.30889556135458, "Episode length": 608, "Policy Loss": -7.133090972900391, "Value Loss": 13.140396118164062, "_runtime": 18116.27986931801, "_timestamp": 1585615485.9127388, "_step": 260}
{"Episode reward": 81.50000000000001, "Episode length": 185, "Policy Loss": -4.823266506195068, "Value Loss": 39.23456954956055, "_runtime": 18116.4843916893, "_timestamp": 1585615486.1172612, "_step": 261}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": 2.6202774047851562, "Value Loss": 67.92777252197266, "_runtime": 18116.78369283676, "_timestamp": 1585615486.4165623, "_step": 262}
{"Episode reward": 81.90000000000002, "Episode length": 181, "Policy Loss": -4.502020359039307, "Value Loss": 39.78862380981445, "_runtime": 18117.114078760147, "_timestamp": 1585615486.7469482, "_step": 263}
{"Episode reward": 78.19999999999996, "Episode length": 218, "Policy Loss": -6.475497245788574, "Value Loss": 33.75199508666992, "_runtime": 18117.398325681686, "_timestamp": 1585615487.0311952, "_step": 264}
{"Episode reward": 81.0, "Episode length": 190, "Policy Loss": -5.709975719451904, "Value Loss": 38.062564849853516, "_runtime": 18117.597012281418, "_timestamp": 1585615487.2298818, "_step": 265}
{"Episode reward": 87.30000000000004, "Episode length": 127, "Policy Loss": -2.793178081512451, "Value Loss": 59.32976150512695, "_runtime": 18117.79696202278, "_timestamp": 1585615487.4298315, "_step": 266}
{"Episode reward": 87.4548409683572, "Episode length": 126, "Policy Loss": -4.100303649902344, "Value Loss": 55.734989166259766, "_runtime": 18117.975728988647, "_timestamp": 1585615487.6085985, "_step": 267}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 1.1455366611480713, "Value Loss": 63.33230209350586, "_runtime": 18118.154292821884, "_timestamp": 1585615487.7871623, "_step": 268}
{"Episode reward": 88.57775470605122, "Episode length": 115, "Policy Loss": -1.7999621629714966, "Value Loss": 62.87324142456055, "_runtime": 18118.571548461914, "_timestamp": 1585615488.204418, "_step": 269}
{"Episode reward": 72.15315183305636, "Episode length": 280, "Policy Loss": -7.614900588989258, "Value Loss": 27.236146926879883, "_runtime": 18118.852849006653, "_timestamp": 1585615488.4857185, "_step": 270}
{"Episode reward": 81.20000000000002, "Episode length": 188, "Policy Loss": -5.601775646209717, "Value Loss": 37.66901397705078, "_runtime": 18119.03308415413, "_timestamp": 1585615488.6659536, "_step": 271}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 3.347839832305908, "Value Loss": 60.79093933105469, "_runtime": 18119.23828625679, "_timestamp": 1585615488.8711557, "_step": 272}
{"Episode reward": 87.30000000000004, "Episode length": 127, "Policy Loss": -4.607980251312256, "Value Loss": 56.01882553100586, "_runtime": 18119.418376922607, "_timestamp": 1585615489.0512464, "_step": 273}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 0.3427417576313019, "Value Loss": 60.693817138671875, "_runtime": 18119.711116552353, "_timestamp": 1585615489.343986, "_step": 274}
{"Episode reward": 80.57817301368341, "Episode length": 195, "Policy Loss": -5.659693241119385, "Value Loss": 38.6505012512207, "_runtime": 18119.888818502426, "_timestamp": 1585615489.521688, "_step": 275}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 12.44853687286377, "Value Loss": 73.3227310180664, "_runtime": 18120.42223596573, "_timestamp": 1585615490.0551054, "_step": 276}
{"Episode reward": 63.733288274705174, "Episode length": 363, "Policy Loss": -6.69492769241333, "Value Loss": 21.000926971435547, "_runtime": 18120.613480567932, "_timestamp": 1585615490.24635, "_step": 277}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 1.7552180290222168, "Value Loss": 60.431724548339844, "_runtime": 18121.0043592453, "_timestamp": 1585615490.6372287, "_step": 278}
{"Episode reward": 73.4999999999999, "Episode length": 265, "Policy Loss": -4.019049644470215, "Value Loss": 27.095975875854492, "_runtime": 18121.200820684433, "_timestamp": 1585615490.8336902, "_step": 279}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 4.002981662750244, "Value Loss": 62.49958801269531, "_runtime": 18121.418312311172, "_timestamp": 1585615491.0511818, "_step": 280}
{"Episode reward": 85.70000000000005, "Episode length": 143, "Policy Loss": -5.104804515838623, "Value Loss": 53.05864715576172, "_runtime": 18121.60032391548, "_timestamp": 1585615491.2331934, "_step": 281}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": -0.9142429828643799, "Value Loss": 65.0492172241211, "_runtime": 18121.773522615433, "_timestamp": 1585615491.406392, "_step": 282}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": -0.5855613350868225, "Value Loss": 62.02109909057617, "_runtime": 18122.0067756176, "_timestamp": 1585615491.639645, "_step": 283}
{"Episode reward": 84.70000000000005, "Episode length": 153, "Policy Loss": -7.496060848236084, "Value Loss": 44.6844367980957, "_runtime": 18122.189529180527, "_timestamp": 1585615491.8223987, "_step": 284}
{"Episode reward": 88.19001572690907, "Episode length": 119, "Policy Loss": 0.5327301621437073, "Value Loss": 68.78755187988281, "_runtime": 18122.36872291565, "_timestamp": 1585615492.0015924, "_step": 285}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 0.5906452536582947, "Value Loss": 71.96369934082031, "_runtime": 18122.55245065689, "_timestamp": 1585615492.1853201, "_step": 286}
{"Episode reward": 88.29178228573896, "Episode length": 118, "Policy Loss": -2.162041425704956, "Value Loss": 61.16156005859375, "_runtime": 18123.120730400085, "_timestamp": 1585615492.7536, "_step": 287}
{"Episode reward": 61.59867315867423, "Episode length": 385, "Policy Loss": -8.135120391845703, "Value Loss": 19.695886611938477, "_runtime": 18123.290514945984, "_timestamp": 1585615492.9233844, "_step": 288}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": -2.1567635536193848, "Value Loss": 64.8053207397461, "_runtime": 18123.989612579346, "_timestamp": 1585615493.622482, "_step": 289}
{"Episode reward": 52.182670240010665, "Episode length": 479, "Policy Loss": -7.287907600402832, "Value Loss": 17.789249420166016, "_runtime": 18124.20637345314, "_timestamp": 1585615493.839243, "_step": 290}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": -1.4091861248016357, "Value Loss": 64.39581298828125, "_runtime": 18124.407854795456, "_timestamp": 1585615494.0407243, "_step": 291}
{"Episode reward": 86.82051010718573, "Episode length": 132, "Policy Loss": -6.704339981079102, "Value Loss": 56.82505416870117, "_runtime": 18124.774785995483, "_timestamp": 1585615494.4076555, "_step": 292}
{"Episode reward": 77.09999999999995, "Episode length": 229, "Policy Loss": -8.962394714355469, "Value Loss": 31.54026985168457, "_runtime": 18124.9431476593, "_timestamp": 1585615494.5760171, "_step": 293}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": -0.5391831398010254, "Value Loss": 62.59406661987305, "_runtime": 18125.269385576248, "_timestamp": 1585615494.902255, "_step": 294}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": -7.20498514175415, "Value Loss": 31.42026138305664, "_runtime": 18125.598202466965, "_timestamp": 1585615495.231072, "_step": 295}
{"Episode reward": 79.07220855669581, "Episode length": 210, "Policy Loss": -1.6763148307800293, "Value Loss": 32.97193908691406, "_runtime": 18126.637613773346, "_timestamp": 1585615496.2704833, "_step": 296}
{"Episode reward": 30.33054368710114, "Episode length": 697, "Policy Loss": -7.796386241912842, "Value Loss": 11.465977668762207, "_runtime": 18127.29301905632, "_timestamp": 1585615496.9258885, "_step": 297}
{"Episode reward": 55.894361773947836, "Episode length": 442, "Policy Loss": -7.8193359375, "Value Loss": 17.511938095092773, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483, 0.5211929082870483]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5211929082870483, -0.031521737575531006, 0.45814943313598633, 0.9478205442428589, 1.437491774559021, 1.927163004875183, 2.4168338775634766, 2.9065051078796387, 3.396176338195801, 3.885847568511963, 4.375518798828125, 4.865190029144287, 5.354860782623291, 5.844532012939453, 6.334203243255615, 6.823874473571777, 7.3135457038879395, 7.803216457366943, 8.292888641357422, 8.782559394836426, 9.272231101989746, 9.76190185546875, 10.25157356262207, 10.741244316101074, 11.230915069580078, 11.720586776733398, 12.210257530212402, 12.699929237365723, 13.189599990844727, 13.679271697998047, 14.16894245147705, 14.658614158630371, 15.148284912109375, 15.637956619262695, 16.127626419067383, 16.617298126220703, 17.106969833374023, 17.596641540527344, 18.08631134033203, 18.57598304748535, 19.065654754638672, 19.55532455444336, 20.04499626159668, 20.53466796875, 21.02433967590332, 21.514009475708008, 22.003681182861328, 22.49335289001465, 22.983022689819336, 23.472694396972656, 23.962366104125977, 24.452037811279297, 24.941707611083984, 25.431379318237305, 25.921051025390625, 26.410722732543945, 26.900392532348633, 27.390064239501953, 27.879735946655273, 28.36940574645996, 28.85907745361328, 29.3487491607666, 29.838420867919922, 30.32809066772461, 30.81776237487793]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6481831073760986, -0.615292489528656, -0.5824018716812134, -0.5495112538337708, -0.5166206359863281, -0.4837299883365631, -0.4508393406867981, -0.41794872283935547, -0.38505810499191284, -0.3521674871444702, -0.3192768692970276, -0.2863862216472626, -0.25349560379981995, -0.22060498595237732, -0.1877143383026123, -0.15482372045516968, -0.12193310260772705, -0.08904248476028442, -0.0561518669128418, -0.02326124906539917, 0.009629368782043457, 0.04252004623413086, 0.07541066408157349, 0.10830128192901611, 0.14119189977645874, 0.17408251762390137, 0.206973135471344, 0.23986375331878662, 0.272754430770874, 0.30564504861831665, 0.3385356664657593, 0.37142622470855713, 0.40431690216064453, 0.43720757961273193, 0.4700981378555298, 0.5029888153076172, 0.535879373550415, 0.5687700510025024, 0.6016606092453003, 0.6345512866973877, 0.6674418449401855, 0.700332522392273, 0.7332231998443604, 0.7661137580871582, 0.7990044355392456, 0.8318949937820435, 0.8647856712341309, 0.8976762294769287, 0.9305669069290161, 0.9634575843811035, 0.9963481426239014, 1.0292388200759888, 1.0621293783187866, 1.095020055770874, 1.1279106140136719, 1.1608012914657593, 1.1936919689178467, 1.2265825271606445, 1.259473204612732, 1.2923637628555298, 1.3252544403076172, 1.358144998550415, 1.391035556793213, 1.4239263534545898, 1.4568169116973877]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 4.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 22.0, 398.0, 7.0, 27.0, 5.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.7074968814849854, -1.5883610248565674, -1.4692250490188599, -1.350089192390442, -1.2309532165527344, -1.1118173599243164, -0.9926815032958984, -0.8735455870628357, -0.754409670829773, -0.635273814201355, -0.5161378383636475, -0.3970019817352295, -0.2778661251068115, -0.158730149269104, -0.039594292640686035, 0.07954168319702148, 0.19867753982543945, 0.3178133964538574, 0.4369492530822754, 0.5560853481292725, 0.6752212047576904, 0.7943570613861084, 0.9134929180145264, 1.0326287746429443, 1.1517646312713623, 1.2709007263183594, 1.3900365829467773, 1.5091724395751953, 1.6283082962036133, 1.7474441528320312, 1.8665802478790283, 1.9857161045074463, 2.1048519611358643, 2.2239878177642822, 2.3431236743927, 2.462259531021118, 2.581395387649536, 2.700531244277954, 2.8196675777435303, 2.9388034343719482, 3.057939291000366, 3.177075147628784, 3.296211004257202, 3.41534686088562, 3.534482717514038, 3.653618574142456, 3.772754430770874, 3.891890287399292, 4.011026382446289, 4.130162239074707, 4.249298095703125, 4.368433952331543, 4.487569808959961, 4.606705665588379, 4.725841522216797, 4.844977378845215, 4.964113235473633, 5.083249092102051, 5.202384948730469, 5.321521759033203, 5.440657615661621, 5.559793472290039, 5.678929328918457, 5.798065185546875, 5.917201042175293]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0], "bins": [-10.315777778625488, -10.050662994384766, -9.785547256469727, -9.520432472229004, -9.255317687988281, -8.990202903747559, -8.725088119506836, -8.459972381591797, -8.194857597351074, -7.929742813110352, -7.664627552032471, -7.39951229095459, -7.134397506713867, -6.8692827224731445, -6.604167461395264, -6.339052200317383, -6.07393741607666, -5.8088226318359375, -5.543707370758057, -5.278592109680176, -5.013477325439453, -4.7483625411987305, -4.48324728012085, -4.218132019042969, -3.953017234802246, -3.6879024505615234, -3.4227871894836426, -3.1576719284057617, -2.892557144165039, -2.6274423599243164, -2.3623270988464355, -2.0972118377685547, -1.832097053527832, -1.5669822692871094, -1.3018674850463867, -1.0367517471313477, -0.771636962890625, -0.5065221786499023, -0.24140644073486328, 0.023708343505859375, 0.28882312774658203, 0.5539379119873047, 0.8190526962280273, 1.0841684341430664, 1.349283218383789, 1.6143980026245117, 1.8795137405395508, 2.1446285247802734, 2.409743309020996, 2.6748580932617188, 2.9399728775024414, 3.2050886154174805, 3.470203399658203, 3.735318183898926, 4.000433921813965, 4.2655487060546875, 4.53066349029541, 4.795778274536133, 5.0608930587768555, 5.3260087966918945, 5.591123580932617, 5.85623836517334, 6.121354103088379, 6.386467933654785, 6.651583671569824]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 4.0, 10.0, 8.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-2.63521146774292, -2.540194272994995, -2.4451773166656494, -2.3501601219177246, -2.2551429271698, -2.160125732421875, -2.0651087760925293, -1.9700915813446045, -1.8750745058059692, -1.780057430267334, -1.6850402355194092, -1.590023159980774, -1.4950060844421387, -1.3999888896942139, -1.3049718141555786, -1.2099546194076538, -1.1149375438690186, -1.0199204683303833, -0.9249032735824585, -0.8298861980438232, -0.7348690032958984, -0.6398519277572632, -0.5448348522186279, -0.4498176574707031, -0.3548007011413574, -0.2597835063934326, -0.1647663116455078, -0.06974911689758301, 0.025267839431762695, 0.1202850341796875, 0.2153022289276123, 0.310319185256958, 0.4053363800048828, 0.5003535747528076, 0.5953705310821533, 0.6903877258300781, 0.7854049205780029, 0.8804218769073486, 0.9754390716552734, 1.0704562664031982, 1.165473461151123, 1.2604904174804688, 1.3555076122283936, 1.4505248069763184, 1.545541763305664, 1.6405587196350098, 1.7355761528015137, 1.8305931091308594, 1.925610065460205, 2.020627498626709, 2.1156444549560547, 2.2106618881225586, 2.3056788444519043, 2.40069580078125, 2.495713233947754, 2.5907301902770996, 2.6857471466064453, 2.780764579772949, 2.875781536102295, 2.9707984924316406, 3.0658159255981445, 3.1608328819274902, 3.255849838256836, 3.35086727142334, 3.4458842277526855]}, "_runtime": 18127.90161705017, "_timestamp": 1585615497.5344865, "_step": 298}
{"Episode reward": 59.425719984541885, "Episode length": 406, "Policy Loss": -6.352375507354736, "Value Loss": 18.905046463012695, "_runtime": 18128.126893520355, "_timestamp": 1585615497.759763, "_step": 299}
{"Episode reward": 88.76167979495129, "Episode length": 113, "Policy Loss": -0.40128010511398315, "Value Loss": 62.14060592651367, "_runtime": 18128.34008216858, "_timestamp": 1585615497.9729517, "_step": 300}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": -1.5821460485458374, "Value Loss": 55.39013671875, "_runtime": 18129.049498081207, "_timestamp": 1585615498.6823676, "_step": 301}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": -8.071527481079102, "Value Loss": 15.917501449584961, "_runtime": 18129.34409546852, "_timestamp": 1585615498.976965, "_step": 302}
{"Episode reward": 81.18328228034642, "Episode length": 189, "Policy Loss": -4.943829536437988, "Value Loss": 36.94758605957031, "_runtime": 18129.531383752823, "_timestamp": 1585615499.1642532, "_step": 303}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": -2.306931257247925, "Value Loss": 58.34088134765625, "_runtime": 18129.740324497223, "_timestamp": 1585615499.373194, "_step": 304}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": -2.8862075805664062, "Value Loss": 56.35108184814453, "_runtime": 18129.91440486908, "_timestamp": 1585615499.5472744, "_step": 305}
{"Episode reward": 89.18246382139625, "Episode length": 109, "Policy Loss": 0.5597723126411438, "Value Loss": 63.574954986572266, "_runtime": 18130.35144019127, "_timestamp": 1585615499.9843097, "_step": 306}
{"Episode reward": 70.7789456602883, "Episode length": 294, "Policy Loss": -6.167977809906006, "Value Loss": 27.175743103027344, "_runtime": 18130.72622179985, "_timestamp": 1585615500.3590913, "_step": 307}
{"Episode reward": 74.89999999999992, "Episode length": 251, "Policy Loss": -6.470015048980713, "Value Loss": 27.81561851501465, "_runtime": 18131.154252767563, "_timestamp": 1585615500.7871222, "_step": 308}
{"Episode reward": 70.89999999999986, "Episode length": 291, "Policy Loss": -6.642919540405273, "Value Loss": 23.906240463256836, "_runtime": 18131.447018623352, "_timestamp": 1585615501.079888, "_step": 309}
{"Episode reward": 81.20000000000002, "Episode length": 188, "Policy Loss": -0.4221310019493103, "Value Loss": 35.8016242980957, "_runtime": 18132.089439868927, "_timestamp": 1585615501.7223094, "_step": 310}
{"Episode reward": 56.899999999999665, "Episode length": 431, "Policy Loss": -6.167980194091797, "Value Loss": 17.215049743652344, "_runtime": 18132.29299044609, "_timestamp": 1585615501.92586, "_step": 311}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -0.6712746620178223, "Value Loss": 57.093910217285156, "_runtime": 18132.610434532166, "_timestamp": 1585615502.243304, "_step": 312}
{"Episode reward": 78.99999999999997, "Episode length": 210, "Policy Loss": -3.681269407272339, "Value Loss": 35.13931655883789, "_runtime": 18132.92743897438, "_timestamp": 1585615502.5603085, "_step": 313}
{"Episode reward": 80.19999999999999, "Episode length": 198, "Policy Loss": -5.343446254730225, "Value Loss": 36.99757766723633, "_runtime": 18133.21654200554, "_timestamp": 1585615502.8494115, "_step": 314}
{"Episode reward": 80.7, "Episode length": 193, "Policy Loss": -4.704559326171875, "Value Loss": 34.848426818847656, "_runtime": 18133.404407262802, "_timestamp": 1585615503.0372767, "_step": 315}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": -4.55950403213501, "Value Loss": 55.737632751464844, "_runtime": 18133.851685762405, "_timestamp": 1585615503.4845552, "_step": 316}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": -7.947765350341797, "Value Loss": 25.392221450805664, "_runtime": 18134.03884911537, "_timestamp": 1585615503.6717186, "_step": 317}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 11.318394660949707, "Value Loss": 65.45024108886719, "_runtime": 18134.428272247314, "_timestamp": 1585615504.0611417, "_step": 318}
{"Episode reward": 73.59999999999991, "Episode length": 264, "Policy Loss": -6.6374077796936035, "Value Loss": 27.015958786010742, "_runtime": 18135.012280225754, "_timestamp": 1585615504.6451497, "_step": 319}
{"Episode reward": 61.124079582020435, "Episode length": 390, "Policy Loss": -6.97075080871582, "Value Loss": 20.487411499023438, "_runtime": 18135.192667484283, "_timestamp": 1585615504.825537, "_step": 320}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -4.891574382781982, "Value Loss": 59.353981018066406, "_runtime": 18135.388171434402, "_timestamp": 1585615505.021041, "_step": 321}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": -1.8559565544128418, "Value Loss": 56.81214141845703, "_runtime": 18136.911000728607, "_timestamp": 1585615506.5438702, "_step": 322}
{"Episode reward": -99.800160434864, "Episode length": 999, "Policy Loss": -8.084012031555176, "Value Loss": 1.9269027709960938, "_runtime": 18137.771223306656, "_timestamp": 1585615507.4040928, "_step": 323}
{"Episode reward": 42.39175857296159, "Episode length": 577, "Policy Loss": -7.288357734680176, "Value Loss": 13.94118881225586, "_runtime": 18137.95369696617, "_timestamp": 1585615507.5865664, "_step": 324}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -1.3333159685134888, "Value Loss": 58.465579986572266, "_runtime": 18138.18759393692, "_timestamp": 1585615507.8204634, "_step": 325}
{"Episode reward": 88.81004822277322, "Episode length": 112, "Policy Loss": -0.7262490391731262, "Value Loss": 61.55077362060547, "_runtime": 18138.40761947632, "_timestamp": 1585615508.040489, "_step": 326}
{"Episode reward": 87.34191667906866, "Episode length": 127, "Policy Loss": -1.4022912979125977, "Value Loss": 54.27054214477539, "_runtime": 18138.595703840256, "_timestamp": 1585615508.2285733, "_step": 327}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 2.986325979232788, "Value Loss": 57.59189987182617, "_runtime": 18138.962908506393, "_timestamp": 1585615508.595778, "_step": 328}
{"Episode reward": 75.48024419676506, "Episode length": 246, "Policy Loss": -5.467315196990967, "Value Loss": 29.25205421447754, "_runtime": 18139.311007738113, "_timestamp": 1585615508.9438772, "_step": 329}
{"Episode reward": 76.68505901955062, "Episode length": 234, "Policy Loss": -7.6850714683532715, "Value Loss": 33.041717529296875, "_runtime": 18139.6048681736, "_timestamp": 1585615509.2377377, "_step": 330}
{"Episode reward": 80.33163049870636, "Episode length": 197, "Policy Loss": -5.782150745391846, "Value Loss": 37.35825729370117, "_runtime": 18139.926578760147, "_timestamp": 1585615509.5594482, "_step": 331}
{"Episode reward": 78.98316779601734, "Episode length": 211, "Policy Loss": -6.043694972991943, "Value Loss": 34.209373474121094, "_runtime": 18140.111854076385, "_timestamp": 1585615509.7447236, "_step": 332}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": -1.3080360889434814, "Value Loss": 57.92226028442383, "_runtime": 18140.401047468185, "_timestamp": 1585615510.033917, "_step": 333}
{"Episode reward": 81.12558864338818, "Episode length": 189, "Policy Loss": -4.755354404449463, "Value Loss": 35.598392486572266, "_runtime": 18140.956761837006, "_timestamp": 1585615510.5896313, "_step": 334}
{"Episode reward": 62.849713829348296, "Episode length": 372, "Policy Loss": -7.628432273864746, "Value Loss": 19.227108001708984, "_runtime": 18141.14644932747, "_timestamp": 1585615510.7793188, "_step": 335}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -2.137482166290283, "Value Loss": 61.36820602416992, "_runtime": 18141.336824417114, "_timestamp": 1585615510.969694, "_step": 336}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": -2.1265103816986084, "Value Loss": 57.02659606933594, "_runtime": 18141.776812791824, "_timestamp": 1585615511.4096823, "_step": 337}
{"Episode reward": 71.49999999999987, "Episode length": 285, "Policy Loss": -3.7363734245300293, "Value Loss": 22.954952239990234, "_runtime": 18141.95654320717, "_timestamp": 1585615511.5894127, "_step": 338}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 2.47546648979187, "Value Loss": 61.16310119628906, "_runtime": 18142.220650434494, "_timestamp": 1585615511.85352, "_step": 339}
{"Episode reward": 82.87703293822126, "Episode length": 174, "Policy Loss": -9.039381980895996, "Value Loss": 39.737701416015625, "_runtime": 18142.57746720314, "_timestamp": 1585615512.2103367, "_step": 340}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": -6.373833179473877, "Value Loss": 31.488229751586914, "_runtime": 18142.893949985504, "_timestamp": 1585615512.5268195, "_step": 341}
{"Episode reward": 78.69591113291678, "Episode length": 214, "Policy Loss": -5.040201187133789, "Value Loss": 34.10080337524414, "_runtime": 18143.190063238144, "_timestamp": 1585615512.8229327, "_step": 342}
{"Episode reward": 80.3, "Episode length": 197, "Policy Loss": -5.445315361022949, "Value Loss": 34.20260238647461, "_runtime": 18144.588176250458, "_timestamp": 1585615514.2210457, "_step": 343}
{"Episode reward": 7.475389051693028, "Episode length": 927, "Policy Loss": -7.033349990844727, "Value Loss": 8.386991500854492, "_runtime": 18144.913347005844, "_timestamp": 1585615514.5462165, "_step": 344}
{"Episode reward": 79.76756730434562, "Episode length": 203, "Policy Loss": -5.05100679397583, "Value Loss": 37.17241287231445, "_runtime": 18145.20954966545, "_timestamp": 1585615514.8424191, "_step": 345}
{"Episode reward": 80.56918984388467, "Episode length": 195, "Policy Loss": -4.531680107116699, "Value Loss": 34.82259750366211, "_runtime": 18145.589414596558, "_timestamp": 1585615515.222284, "_step": 346}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": -6.10678243637085, "Value Loss": 30.608793258666992, "_runtime": 18145.786858558655, "_timestamp": 1585615515.419728, "_step": 347}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": 1.0158381462097168, "Value Loss": 56.30680465698242, "_runtime": 18146.733545303345, "_timestamp": 1585615516.3664148, "_step": 348}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": -5.605762958526611, "Value Loss": 11.319385528564453, "_runtime": 18146.93391919136, "_timestamp": 1585615516.5667887, "_step": 349}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -0.7201116681098938, "Value Loss": 56.73726272583008, "_runtime": 18147.48153114319, "_timestamp": 1585615517.1144006, "_step": 350}
{"Episode reward": 62.59802160253723, "Episode length": 375, "Policy Loss": -5.657703876495361, "Value Loss": 18.475048065185547, "_runtime": 18147.89471244812, "_timestamp": 1585615517.527582, "_step": 351}
{"Episode reward": 74.39999999999992, "Episode length": 256, "Policy Loss": -5.918778896331787, "Value Loss": 26.65989112854004, "_runtime": 18148.192046880722, "_timestamp": 1585615517.8249164, "_step": 352}
{"Episode reward": 80.1898902787746, "Episode length": 199, "Policy Loss": -4.793543815612793, "Value Loss": 32.28763961791992, "_runtime": 18148.531604528427, "_timestamp": 1585615518.164474, "_step": 353}
{"Episode reward": 78.19999999999996, "Episode length": 218, "Policy Loss": -0.6942236423492432, "Value Loss": 31.25956916809082, "_runtime": 18148.871584415436, "_timestamp": 1585615518.504454, "_step": 354}
{"Episode reward": 77.77937190095977, "Episode length": 223, "Policy Loss": -4.287329196929932, "Value Loss": 29.601829528808594, "_runtime": 18149.10979294777, "_timestamp": 1585615518.7426624, "_step": 355}
{"Episode reward": 84.60000000000005, "Episode length": 154, "Policy Loss": -2.4397459030151367, "Value Loss": 55.80463790893555, "_runtime": 18149.5112285614, "_timestamp": 1585615519.144098, "_step": 356}
{"Episode reward": 73.39273035442446, "Episode length": 267, "Policy Loss": -4.316986083984375, "Value Loss": 25.006061553955078, "_runtime": 18149.980600118637, "_timestamp": 1585615519.6134696, "_step": 357}
{"Episode reward": 68.49999999999983, "Episode length": 315, "Policy Loss": -4.914201736450195, "Value Loss": 21.448577880859375, "_runtime": 18150.191648483276, "_timestamp": 1585615519.824518, "_step": 358}
{"Episode reward": 86.30000000000004, "Episode length": 137, "Policy Loss": -2.2750422954559326, "Value Loss": 50.44553756713867, "_runtime": 18150.631791591644, "_timestamp": 1585615520.264661, "_step": 359}
{"Episode reward": 70.97046438404345, "Episode length": 293, "Policy Loss": -4.656083583831787, "Value Loss": 22.543092727661133, "_runtime": 18151.165993452072, "_timestamp": 1585615520.798863, "_step": 360}
{"Episode reward": 64.39985120296456, "Episode length": 357, "Policy Loss": -4.918452739715576, "Value Loss": 19.496034622192383, "_runtime": 18151.861339092255, "_timestamp": 1585615521.4942086, "_step": 361}
{"Episode reward": 52.699999999999605, "Episode length": 473, "Policy Loss": -5.026029109954834, "Value Loss": 14.753040313720703, "_runtime": 18153.37760782242, "_timestamp": 1585615523.0104773, "_step": 362}
{"Episode reward": -99.72837332209899, "Episode length": 999, "Policy Loss": -7.1912455558776855, "Value Loss": 1.222334623336792, "_runtime": 18153.594607114792, "_timestamp": 1585615523.2274766, "_step": 363}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 5.290557384490967, "Value Loss": 57.046241760253906, "_runtime": 18153.8160572052, "_timestamp": 1585615523.4489267, "_step": 364}
{"Episode reward": 87.15841072648767, "Episode length": 129, "Policy Loss": -2.058104991912842, "Value Loss": 51.043067932128906, "_runtime": 18154.279082536697, "_timestamp": 1585615523.911952, "_step": 365}
{"Episode reward": 72.19999999999987, "Episode length": 278, "Policy Loss": -4.293935298919678, "Value Loss": 26.789127349853516, "_runtime": 18154.798855543137, "_timestamp": 1585615524.431725, "_step": 366}
{"Episode reward": 64.99984760576277, "Episode length": 351, "Policy Loss": 1.005120873451233, "Value Loss": 22.40597915649414, "_runtime": 18154.98782968521, "_timestamp": 1585615524.6206992, "_step": 367}
{"Episode reward": 87.81449761669504, "Episode length": 122, "Policy Loss": -0.6192740797996521, "Value Loss": 57.587833404541016, "_runtime": 18155.18767142296, "_timestamp": 1585615524.820541, "_step": 368}
{"Episode reward": 87.70000000000003, "Episode length": 123, "Policy Loss": -1.1486787796020508, "Value Loss": 53.838504791259766, "_runtime": 18156.297283649445, "_timestamp": 1585615525.9301531, "_step": 369}
{"Episode reward": 26.141380839841275, "Episode length": 741, "Policy Loss": -5.922092914581299, "Value Loss": 10.359736442565918, "_runtime": 18156.729275226593, "_timestamp": 1585615526.3621447, "_step": 370}
{"Episode reward": 72.07072690716001, "Episode length": 280, "Policy Loss": -4.069620132446289, "Value Loss": 25.1380615234375, "_runtime": 18157.032113552094, "_timestamp": 1585615526.664983, "_step": 371}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": -3.2579615116119385, "Value Loss": 33.80619812011719, "_runtime": 18157.374636411667, "_timestamp": 1585615527.007506, "_step": 372}
{"Episode reward": 79.99999193632392, "Episode length": 201, "Policy Loss": -1.4490196704864502, "Value Loss": 33.19872283935547, "_runtime": 18157.55131459236, "_timestamp": 1585615527.184184, "_step": 373}
{"Episode reward": 89.57629626838028, "Episode length": 106, "Policy Loss": 0.48565205931663513, "Value Loss": 59.03306198120117, "_runtime": 18158.3524889946, "_timestamp": 1585615527.9853585, "_step": 374}
{"Episode reward": 46.29333957256701, "Episode length": 539, "Policy Loss": -6.0346269607543945, "Value Loss": 14.17968463897705, "_runtime": 18159.86736893654, "_timestamp": 1585615529.5002384, "_step": 375}
{"Episode reward": -99.72113566351915, "Episode length": 999, "Policy Loss": -7.4535980224609375, "Value Loss": 1.174714207649231, "_runtime": 18160.309009552002, "_timestamp": 1585615529.941879, "_step": 376}
{"Episode reward": 70.99999999999986, "Episode length": 290, "Policy Loss": -5.440774917602539, "Value Loss": 25.327409744262695, "_runtime": 18160.891636133194, "_timestamp": 1585615530.5245056, "_step": 377}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": -5.155630111694336, "Value Loss": 18.55481719970703, "_runtime": 18162.13880419731, "_timestamp": 1585615531.7716737, "_step": 378}
{"Episode reward": 19.898159890529044, "Episode length": 802, "Policy Loss": -6.411739826202393, "Value Loss": 10.060500144958496, "_runtime": 18162.671632766724, "_timestamp": 1585615532.3045022, "_step": 379}
{"Episode reward": 65.19999999999979, "Episode length": 348, "Policy Loss": -2.0505988597869873, "Value Loss": 21.899587631225586, "_runtime": 18162.996829509735, "_timestamp": 1585615532.629699, "_step": 380}
{"Episode reward": 79.40388605510815, "Episode length": 206, "Policy Loss": -3.7673847675323486, "Value Loss": 33.77658462524414, "_runtime": 18163.3106276989, "_timestamp": 1585615532.9434972, "_step": 381}
{"Episode reward": 82.20000000000002, "Episode length": 178, "Policy Loss": -1.1418198347091675, "Value Loss": 35.63227844238281, "_runtime": 18163.629610538483, "_timestamp": 1585615533.26248, "_step": 382}
{"Episode reward": 79.6, "Episode length": 204, "Policy Loss": -4.0189714431762695, "Value Loss": 35.847049713134766, "_runtime": 18164.24750995636, "_timestamp": 1585615533.8803794, "_step": 383}
{"Episode reward": 58.29003500342338, "Episode length": 418, "Policy Loss": -5.756563186645508, "Value Loss": 16.466651916503906, "_runtime": 18164.69188117981, "_timestamp": 1585615534.3247507, "_step": 384}
{"Episode reward": 70.93705591116436, "Episode length": 291, "Policy Loss": -4.596808910369873, "Value Loss": 23.334272384643555, "_runtime": 18165.160606384277, "_timestamp": 1585615534.7934759, "_step": 385}
{"Episode reward": 68.74927001546587, "Episode length": 315, "Policy Loss": -5.0338826179504395, "Value Loss": 21.8391170501709, "_runtime": 18165.362421035767, "_timestamp": 1585615534.9952905, "_step": 386}
{"Episode reward": 88.32376825772229, "Episode length": 117, "Policy Loss": -1.0306755304336548, "Value Loss": 59.00967788696289, "_runtime": 18165.865991830826, "_timestamp": 1585615535.4988613, "_step": 387}
{"Episode reward": 66.9792079630306, "Episode length": 333, "Policy Loss": -4.845183849334717, "Value Loss": 19.202634811401367, "_runtime": 18166.31328868866, "_timestamp": 1585615535.9461582, "_step": 388}
{"Episode reward": 70.786411526217, "Episode length": 294, "Policy Loss": -4.093722343444824, "Value Loss": 22.732723236083984, "_runtime": 18167.488915205002, "_timestamp": 1585615537.1217847, "_step": 389}
{"Episode reward": 20.631385512557117, "Episode length": 794, "Policy Loss": -5.85317325592041, "Value Loss": 9.168440818786621, "_runtime": 18167.825548410416, "_timestamp": 1585615537.458418, "_step": 390}
{"Episode reward": 79.39999999999998, "Episode length": 206, "Policy Loss": -3.0318031311035156, "Value Loss": 34.070091247558594, "_runtime": 18168.821821689606, "_timestamp": 1585615538.4546912, "_step": 391}
{"Episode reward": 36.02594275614184, "Episode length": 640, "Policy Loss": -5.6313042640686035, "Value Loss": 10.512235641479492, "_runtime": 18169.172573566437, "_timestamp": 1585615538.805443, "_step": 392}
{"Episode reward": 80.1, "Episode length": 199, "Policy Loss": -1.9001356363296509, "Value Loss": 32.42696762084961, "_runtime": 18169.36747765541, "_timestamp": 1585615539.0003471, "_step": 393}
{"Episode reward": 87.70000000000003, "Episode length": 123, "Policy Loss": -0.6375975608825684, "Value Loss": 52.818870544433594, "_runtime": 18169.58367085457, "_timestamp": 1585615539.2165403, "_step": 394}
{"Episode reward": 88.2239878385015, "Episode length": 118, "Policy Loss": 0.02004849724471569, "Value Loss": 52.98979568481445, "_runtime": 18169.770868062973, "_timestamp": 1585615539.4037375, "_step": 395}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -0.39207157492637634, "Value Loss": 55.623592376708984, "_runtime": 18170.16615819931, "_timestamp": 1585615539.7990277, "_step": 396}
{"Episode reward": 73.66317379456004, "Episode length": 265, "Policy Loss": -2.4856741428375244, "Value Loss": 27.642192840576172, "_runtime": 18170.516748428345, "_timestamp": 1585615540.149618, "_step": 397}
{"Episode reward": 76.48993068896227, "Episode length": 236, "Policy Loss": -0.09209849685430527, "Value Loss": 29.4330997467041, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125, -555342.8125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0], "bins": [-14316367.0, -14083997.0, -13851626.0, -13619256.0, -13386885.0, -13154515.0, -12922144.0, -12689774.0, -12457403.0, -12225033.0, -11992662.0, -11760292.0, -11527921.0, -11295551.0, -11063180.0, -10830810.0, -10598439.0, -10366069.0, -10133698.0, -9901328.0, -9668958.0, -9436587.0, -9204216.0, -8971846.0, -8739476.0, -8507105.0, -8274734.5, -8042364.0, -7809993.5, -7577623.0, -7345252.5, -7112882.0, -6880511.5, -6648141.0, -6415770.5, -6183400.0, -5951029.5, -5718659.0, -5486289.0, -5253918.0, -5021548.0, -4789177.0, -4556807.0, -4324436.0, -4092066.0, -3859695.0, -3627325.0, -3394954.0, -3162584.0, -2930213.0, -2697843.0, -2465472.0, -2233102.0, -2000731.0, -1768361.0, -1535990.0, -1303620.0, -1071249.0, -838879.0, -606508.0, -374138.0, -141767.0, 90603.0, 322974.0, 555344.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-529884.8125, -490506.5625, -451128.28125, -411750.03125, -372371.75, -332993.5, -293615.25, -254236.96875, -214858.71875, -175480.46875, -136102.1875, -96723.9375, -57345.6875, -17967.40625, 21410.875, 60789.125, 100167.375, 139545.625, 178923.875, 218302.1875, 257680.4375, 297058.6875, 336436.9375, 375815.1875, 415193.4375, 454571.75, 493950.0, 533328.3125, 572706.5625, 612084.8125, 651463.0625, 690841.3125, 730219.5625, 769597.8125, 808976.0625, 848354.3125, 887732.5625, 927110.8125, 966489.1875, 1005867.4375, 1045245.6875, 1084624.0, 1124002.25, 1163380.5, 1202758.75, 1242137.0, 1281515.25, 1320893.5, 1360271.75, 1399650.0, 1439028.25, 1478406.5, 1517784.75, 1557163.0, 1596541.5, 1635919.75, 1675298.0, 1714676.25, 1754054.5, 1793432.75, 1832811.0, 1872189.25, 1911567.5, 1950945.75, 1990324.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 2.0, 1.0, 1.0, 0.0, 0.0, 5.0, 6.0, 2.0, 3.0, 19.0, 12.0, 9.0, 7.0, 2.0, 6.0, 10.0, 7.0, 3.0, 303.0, 10.0, 10.0, 14.0, 15.0, 12.0, 6.0, 5.0, 0.0, 3.0, 2.0, 1.0, 4.0, 0.0, 5.0, 0.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1967372.25, -1864888.75, -1762405.25, -1659921.75, -1557438.25, -1454954.75, -1352471.125, -1249987.625, -1147504.125, -1045020.625, -942537.125, -840053.625, -737570.0, -635086.5, -532603.0, -430119.5, -327636.0, -225152.5, -122669.0, -20185.5, 82298.0, 184781.5, 287265.0, 389748.5, 492232.25, 594715.75, 697199.25, 799682.75, 902166.25, 1004649.75, 1107133.25, 1209616.75, 1312100.25, 1414583.75, 1517067.25, 1619550.75, 1722034.25, 1824517.75, 1927001.25, 2029484.75, 2131968.25, 2234451.75, 2336935.25, 2439418.75, 2541902.25, 2644385.75, 2746869.25, 2849352.75, 2951836.75, 3054320.25, 3156803.75, 3259287.25, 3361770.75, 3464254.25, 3566737.75, 3669221.25, 3771704.75, 3874188.25, 3976671.75, 4079155.25, 4181638.75, 4284122.0, 4386606.0, 4489089.0, 4591573.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-36658192.0, -35207604.0, -33757016.0, -32306426.0, -30855838.0, -29405250.0, -27954660.0, -26504072.0, -25053484.0, -23602896.0, -22152308.0, -20701718.0, -19251130.0, -17800542.0, -16349952.0, -14899364.0, -13448776.0, -11998188.0, -10547600.0, -9097010.0, -7646422.0, -6195834.0, -4745244.0, -3294656.0, -1844068.0, -393480.0, 1057108.0, 2507696.0, 3958288.0, 5408876.0, 6859464.0, 8310052.0, 9760640.0, 11211228.0, 12661816.0, 14112404.0, 15562992.0, 17013584.0, 18464172.0, 19914760.0, 21365348.0, 22815936.0, 24266524.0, 25717112.0, 27167704.0, 28618292.0, 30068880.0, 31519464.0, 32970056.0, 34420648.0, 35871232.0, 37321824.0, 38772408.0, 40223000.0, 41673584.0, 43124176.0, 44574768.0, 46025352.0, 47475944.0, 48926528.0, 50377120.0, 51827704.0, 53278296.0, 54728880.0, 56179472.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 2.0, 4.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 8.0, 4.0, 0.0, 2.0], "bins": [-24006664.0, -23385688.0, -22764712.0, -22143738.0, -21522762.0, -20901786.0, -20280810.0, -19659836.0, -19038860.0, -18417884.0, -17796908.0, -17175932.0, -16554957.0, -15933982.0, -15313006.0, -14692031.0, -14071055.0, -13450079.0, -12829104.0, -12208128.0, -11587153.0, -10966177.0, -10345202.0, -9724226.0, -9103250.0, -8482275.0, -7861299.0, -7240324.0, -6619348.0, -5998372.0, -5377398.0, -4756422.0, -4135446.0, -3514470.0, -2893494.0, -2272520.0, -1651544.0, -1030568.0, -409592.0, 211382.0, 832358.0, 1453334.0, 2074310.0, 2695286.0, 3316260.0, 3937236.0, 4558212.0, 5179188.0, 5800164.0, 6421138.0, 7042114.0, 7663090.0, 8284066.0, 8905040.0, 9526016.0, 10146992.0, 10767968.0, 11388944.0, 12009920.0, 12630896.0, 13251868.0, 13872844.0, 14493820.0, 15114796.0, 15735772.0]}, "_runtime": 18170.714208364487, "_timestamp": 1585615540.3470778, "_step": 398}
{"Episode reward": 87.20000000000003, "Episode length": 128, "Policy Loss": 0.06632262468338013, "Value Loss": 52.33632278442383, "_runtime": 18171.114744901657, "_timestamp": 1585615540.7476144, "_step": 399}
{"Episode reward": 73.59999999999991, "Episode length": 264, "Policy Loss": -2.0787711143493652, "Value Loss": 24.701805114746094, "_runtime": 18171.305112361908, "_timestamp": 1585615540.9379818, "_step": 400}
{"Episode reward": 88.2999456625574, "Episode length": 118, "Policy Loss": -0.17589052021503448, "Value Loss": 56.66040802001953, "_runtime": 18172.11502814293, "_timestamp": 1585615541.7478976, "_step": 401}
{"Episode reward": 45.4633297107876, "Episode length": 548, "Policy Loss": -5.063313961029053, "Value Loss": 13.503009796142578, "_runtime": 18172.972571372986, "_timestamp": 1585615542.6054409, "_step": 402}
{"Episode reward": 43.19999999999947, "Episode length": 568, "Policy Loss": -4.8682708740234375, "Value Loss": 11.617072105407715, "_runtime": 18173.158403635025, "_timestamp": 1585615542.791273, "_step": 403}
{"Episode reward": 88.91443525932755, "Episode length": 111, "Policy Loss": 0.8305636048316956, "Value Loss": 58.645164489746094, "_runtime": 18173.678270578384, "_timestamp": 1585615543.31114, "_step": 404}
{"Episode reward": 66.5999999999998, "Episode length": 334, "Policy Loss": -3.944902181625366, "Value Loss": 20.14350128173828, "_runtime": 18173.889338970184, "_timestamp": 1585615543.5222085, "_step": 405}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 1.5143097639083862, "Value Loss": 54.18898391723633, "_runtime": 18174.417499303818, "_timestamp": 1585615544.0503688, "_step": 406}
{"Episode reward": 64.01251517077884, "Episode length": 360, "Policy Loss": -3.8338840007781982, "Value Loss": 18.060598373413086, "_runtime": 18174.75092792511, "_timestamp": 1585615544.3837974, "_step": 407}
{"Episode reward": 78.69999999999997, "Episode length": 213, "Policy Loss": -3.165151357650757, "Value Loss": 29.914085388183594, "_runtime": 18175.150371313095, "_timestamp": 1585615544.7832408, "_step": 408}
{"Episode reward": 72.98613137667988, "Episode length": 271, "Policy Loss": -3.7938404083251953, "Value Loss": 24.670686721801758, "_runtime": 18175.97887301445, "_timestamp": 1585615545.6117425, "_step": 409}
{"Episode reward": 44.95130487149531, "Episode length": 552, "Policy Loss": -5.0154900550842285, "Value Loss": 12.62751579284668, "_runtime": 18176.382630825043, "_timestamp": 1585615546.0155003, "_step": 410}
{"Episode reward": 73.8999999999999, "Episode length": 261, "Policy Loss": -3.0146636962890625, "Value Loss": 24.203964233398438, "_runtime": 18176.584211587906, "_timestamp": 1585615546.217081, "_step": 411}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -1.1311087608337402, "Value Loss": 50.78688430786133, "_runtime": 18177.546370744705, "_timestamp": 1585615547.1792402, "_step": 412}
{"Episode reward": 37.086961387725864, "Episode length": 631, "Policy Loss": -5.2401442527771, "Value Loss": 11.259855270385742, "_runtime": 18177.747672319412, "_timestamp": 1585615547.3805418, "_step": 413}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -0.6099861264228821, "Value Loss": 55.27274703979492, "_runtime": 18177.931771039963, "_timestamp": 1585615547.5646405, "_step": 414}
{"Episode reward": 88.26174580520022, "Episode length": 118, "Policy Loss": -0.10537797212600708, "Value Loss": 54.0240592956543, "_runtime": 18178.376930236816, "_timestamp": 1585615548.0097997, "_step": 415}
{"Episode reward": 72.41464464174737, "Episode length": 277, "Policy Loss": -2.468620777130127, "Value Loss": 23.033584594726562, "_runtime": 18178.64849805832, "_timestamp": 1585615548.2813675, "_step": 416}
{"Episode reward": 82.00000000000003, "Episode length": 180, "Policy Loss": -1.009151577949524, "Value Loss": 37.17595672607422, "_runtime": 18179.034945964813, "_timestamp": 1585615548.6678154, "_step": 417}
{"Episode reward": 73.7999999999999, "Episode length": 262, "Policy Loss": -3.189361572265625, "Value Loss": 25.16120719909668, "_runtime": 18179.740302801132, "_timestamp": 1585615549.3731723, "_step": 418}
{"Episode reward": 52.799999999999606, "Episode length": 472, "Policy Loss": -4.119751453399658, "Value Loss": 14.20789909362793, "_runtime": 18179.926277160645, "_timestamp": 1585615549.5591466, "_step": 419}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 1.9011164903640747, "Value Loss": 60.068912506103516, "_runtime": 18180.12543654442, "_timestamp": 1585615549.758306, "_step": 420}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": -1.9570527076721191, "Value Loss": 52.22722625732422, "_runtime": 18180.590198993683, "_timestamp": 1585615550.2230685, "_step": 421}
{"Episode reward": 70.1871944006531, "Episode length": 299, "Policy Loss": -4.263758659362793, "Value Loss": 22.536653518676758, "_runtime": 18180.88789176941, "_timestamp": 1585615550.5207613, "_step": 422}
{"Episode reward": 80.17549798339604, "Episode length": 199, "Policy Loss": -1.8236019611358643, "Value Loss": 31.62773323059082, "_runtime": 18181.263234376907, "_timestamp": 1585615550.8961039, "_step": 423}
{"Episode reward": 74.68759205394882, "Episode length": 254, "Policy Loss": -1.4274275302886963, "Value Loss": 25.67845344543457, "_runtime": 18181.712614774704, "_timestamp": 1585615551.3454843, "_step": 424}
{"Episode reward": 70.39778052018359, "Episode length": 297, "Policy Loss": -4.110940456390381, "Value Loss": 21.56753921508789, "_runtime": 18182.56681895256, "_timestamp": 1585615552.1996884, "_step": 425}
{"Episode reward": 42.29999999999946, "Episode length": 577, "Policy Loss": -5.435776233673096, "Value Loss": 12.06280517578125, "_runtime": 18183.025589704514, "_timestamp": 1585615552.6584592, "_step": 426}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": -3.6908867359161377, "Value Loss": 21.665573120117188, "_runtime": 18183.333554267883, "_timestamp": 1585615552.9664237, "_step": 427}
{"Episode reward": 79.99938678406178, "Episode length": 201, "Policy Loss": -2.3507163524627686, "Value Loss": 34.33665084838867, "_runtime": 18183.530782699585, "_timestamp": 1585615553.1636522, "_step": 428}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 1.4578529596328735, "Value Loss": 60.59895706176758, "_runtime": 18184.164248228073, "_timestamp": 1585615553.7971177, "_step": 429}
{"Episode reward": 57.69847051163637, "Episode length": 424, "Policy Loss": -4.487401008605957, "Value Loss": 17.590368270874023, "_runtime": 18184.62897157669, "_timestamp": 1585615554.261841, "_step": 430}
{"Episode reward": 69.90305027339475, "Episode length": 304, "Policy Loss": -3.3372795581817627, "Value Loss": 19.946422576904297, "_runtime": 18185.690098047256, "_timestamp": 1585615555.3229675, "_step": 431}
{"Episode reward": 28.299720296915424, "Episode length": 718, "Policy Loss": -5.2260026931762695, "Value Loss": 9.522644996643066, "_runtime": 18186.1101231575, "_timestamp": 1585615555.7429926, "_step": 432}
{"Episode reward": 73.16776090653137, "Episode length": 269, "Policy Loss": -2.603156566619873, "Value Loss": 24.37677764892578, "_runtime": 18186.61581301689, "_timestamp": 1585615556.2486825, "_step": 433}
{"Episode reward": 66.61351136229914, "Episode length": 334, "Policy Loss": -3.6045897006988525, "Value Loss": 22.403919219970703, "_runtime": 18186.945627212524, "_timestamp": 1585615556.5784967, "_step": 434}
{"Episode reward": 80.18942846009513, "Episode length": 199, "Policy Loss": -1.3120945692062378, "Value Loss": 32.76385498046875, "_runtime": 18187.268260002136, "_timestamp": 1585615556.9011295, "_step": 435}
{"Episode reward": 78.93893384539986, "Episode length": 211, "Policy Loss": -1.4365885257720947, "Value Loss": 32.37826919555664, "_runtime": 18187.79195713997, "_timestamp": 1585615557.4248266, "_step": 436}
{"Episode reward": 65.39999999999978, "Episode length": 346, "Policy Loss": -3.262077808380127, "Value Loss": 18.20499038696289, "_runtime": 18188.715960502625, "_timestamp": 1585615558.34883, "_step": 437}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": -4.816414833068848, "Value Loss": 12.074797630310059, "_runtime": 18189.052218914032, "_timestamp": 1585615558.6850884, "_step": 438}
{"Episode reward": 78.7191987304948, "Episode length": 213, "Policy Loss": -2.0280184745788574, "Value Loss": 33.36289978027344, "_runtime": 18189.26147866249, "_timestamp": 1585615558.8943481, "_step": 439}
{"Episode reward": 87.30000000000004, "Episode length": 127, "Policy Loss": -0.36637866497039795, "Value Loss": 51.77791213989258, "_runtime": 18189.778598308563, "_timestamp": 1585615559.4114678, "_step": 440}
{"Episode reward": 67.18752574520416, "Episode length": 329, "Policy Loss": -3.7470436096191406, "Value Loss": 19.408906936645508, "_runtime": 18189.959237337112, "_timestamp": 1585615559.5921068, "_step": 441}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 1.6376526355743408, "Value Loss": 54.2305793762207, "_runtime": 18190.135433912277, "_timestamp": 1585615559.7683034, "_step": 442}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 1.2232487201690674, "Value Loss": 57.170265197753906, "_runtime": 18190.86047911644, "_timestamp": 1585615560.4933486, "_step": 443}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": -3.8336753845214844, "Value Loss": 14.957836151123047, "_runtime": 18191.04358458519, "_timestamp": 1585615560.676454, "_step": 444}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 1.2572921514511108, "Value Loss": 59.508785247802734, "_runtime": 18191.221146583557, "_timestamp": 1585615560.854016, "_step": 445}
{"Episode reward": 88.533198511228, "Episode length": 115, "Policy Loss": 8.868209838867188, "Value Loss": 66.3619613647461, "_runtime": 18191.457117795944, "_timestamp": 1585615561.0899873, "_step": 446}
{"Episode reward": 86.10000000000004, "Episode length": 139, "Policy Loss": -1.183758020401001, "Value Loss": 50.5585823059082, "_runtime": 18191.876960754395, "_timestamp": 1585615561.5098302, "_step": 447}
{"Episode reward": 71.79999999999987, "Episode length": 282, "Policy Loss": -3.0446150302886963, "Value Loss": 21.181293487548828, "_runtime": 18192.903311252594, "_timestamp": 1585615562.5361807, "_step": 448}
{"Episode reward": 30.684463392197756, "Episode length": 694, "Policy Loss": -5.200315952301025, "Value Loss": 9.374175071716309, "_runtime": 18193.541338205338, "_timestamp": 1585615563.1742077, "_step": 449}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": -4.001221656799316, "Value Loss": 14.577584266662598, "_runtime": 18193.858924627304, "_timestamp": 1585615563.491794, "_step": 450}
{"Episode reward": 80.26714546204893, "Episode length": 198, "Policy Loss": -2.008199691772461, "Value Loss": 33.431053161621094, "_runtime": 18194.189683914185, "_timestamp": 1585615563.8225534, "_step": 451}
{"Episode reward": 80.48807529543993, "Episode length": 196, "Policy Loss": -2.1961050033569336, "Value Loss": 34.386802673339844, "_runtime": 18194.503893375397, "_timestamp": 1585615564.1367629, "_step": 452}
{"Episode reward": 80.19999999999999, "Episode length": 198, "Policy Loss": -2.3451902866363525, "Value Loss": 31.34827995300293, "_runtime": 18194.70668029785, "_timestamp": 1585615564.3395498, "_step": 453}
{"Episode reward": 87.23789235614207, "Episode length": 128, "Policy Loss": 0.6949585676193237, "Value Loss": 48.402931213378906, "_runtime": 18195.04193019867, "_timestamp": 1585615564.6747997, "_step": 454}
{"Episode reward": 77.69999999999996, "Episode length": 223, "Policy Loss": -1.2203747034072876, "Value Loss": 28.314313888549805, "_runtime": 18195.32377767563, "_timestamp": 1585615564.9566472, "_step": 455}
{"Episode reward": 81.50000000000001, "Episode length": 185, "Policy Loss": -0.994195818901062, "Value Loss": 34.02778244018555, "_runtime": 18195.512580394745, "_timestamp": 1585615565.1454499, "_step": 456}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": -1.663478970527649, "Value Loss": 51.940574645996094, "_runtime": 18195.72181749344, "_timestamp": 1585615565.354687, "_step": 457}
{"Episode reward": 86.82827200293545, "Episode length": 132, "Policy Loss": -1.252467155456543, "Value Loss": 46.16858673095703, "_runtime": 18196.122762441635, "_timestamp": 1585615565.755632, "_step": 458}
{"Episode reward": 73.38084953154892, "Episode length": 268, "Policy Loss": -2.8666205406188965, "Value Loss": 23.521007537841797, "_runtime": 18196.42285847664, "_timestamp": 1585615566.055728, "_step": 459}
{"Episode reward": 79.89999999999999, "Episode length": 201, "Policy Loss": -0.7846335768699646, "Value Loss": 31.537376403808594, "_runtime": 18196.69794845581, "_timestamp": 1585615566.330818, "_step": 460}
{"Episode reward": 81.70000000000002, "Episode length": 183, "Policy Loss": -0.012015754356980324, "Value Loss": 33.39659118652344, "_runtime": 18197.936076641083, "_timestamp": 1585615567.5689461, "_step": 461}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": -4.464323997497559, "Value Loss": 7.9674973487854, "_runtime": 18198.143933296204, "_timestamp": 1585615567.7768028, "_step": 462}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 0.25695839524269104, "Value Loss": 47.153587341308594, "_runtime": 18198.957847356796, "_timestamp": 1585615568.5907168, "_step": 463}
{"Episode reward": 44.79546580889677, "Episode length": 553, "Policy Loss": -3.608048677444458, "Value Loss": 12.32694149017334, "_runtime": 18200.179981708527, "_timestamp": 1585615569.8128512, "_step": 464}
{"Episode reward": 21.794532554969365, "Episode length": 783, "Policy Loss": -4.444153308868408, "Value Loss": 10.51292896270752, "_runtime": 18200.524842500687, "_timestamp": 1585615570.157712, "_step": 465}
{"Episode reward": 77.7662047110905, "Episode length": 224, "Policy Loss": -0.5690444111824036, "Value Loss": 28.751585006713867, "_runtime": 18200.84318947792, "_timestamp": 1585615570.476059, "_step": 466}
{"Episode reward": 80.5, "Episode length": 195, "Policy Loss": 0.6461233496665955, "Value Loss": 30.769197463989258, "_runtime": 18201.47537612915, "_timestamp": 1585615571.1082456, "_step": 467}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": -2.158686876296997, "Value Loss": 16.007709503173828, "_runtime": 18202.408310890198, "_timestamp": 1585615572.0411804, "_step": 468}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": -3.7659049034118652, "Value Loss": 10.807644844055176, "_runtime": 18202.604930639267, "_timestamp": 1585615572.2378001, "_step": 469}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": -1.706223726272583, "Value Loss": 49.66668701171875, "_runtime": 18202.923323392868, "_timestamp": 1585615572.5561929, "_step": 470}
{"Episode reward": 80.07298803009179, "Episode length": 201, "Policy Loss": 0.8424926996231079, "Value Loss": 31.077993392944336, "_runtime": 18203.26089668274, "_timestamp": 1585615572.8937662, "_step": 471}
{"Episode reward": 79.7321807438915, "Episode length": 203, "Policy Loss": -1.0997540950775146, "Value Loss": 29.835596084594727, "_runtime": 18203.70153427124, "_timestamp": 1585615573.3344038, "_step": 472}
{"Episode reward": 70.29999999999986, "Episode length": 297, "Policy Loss": -2.325568437576294, "Value Loss": 23.3431339263916, "_runtime": 18203.87117934227, "_timestamp": 1585615573.5040488, "_step": 473}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 0.5866700410842896, "Value Loss": 55.843849182128906, "_runtime": 18204.056767702103, "_timestamp": 1585615573.6896372, "_step": 474}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 1.4749184846878052, "Value Loss": 51.439735412597656, "_runtime": 18204.69303750992, "_timestamp": 1585615574.325907, "_step": 475}
{"Episode reward": 57.34571915231612, "Episode length": 427, "Policy Loss": -3.639551877975464, "Value Loss": 14.970885276794434, "_runtime": 18205.227809906006, "_timestamp": 1585615574.8606794, "_step": 476}
{"Episode reward": 64.57851138948877, "Episode length": 357, "Policy Loss": -3.394580841064453, "Value Loss": 19.597137451171875, "_runtime": 18205.438630342484, "_timestamp": 1585615575.0714998, "_step": 477}
{"Episode reward": 86.10000000000004, "Episode length": 139, "Policy Loss": 0.470851331949234, "Value Loss": 45.03541564941406, "_runtime": 18206.202783584595, "_timestamp": 1585615575.835653, "_step": 478}
{"Episode reward": 49.58659838661507, "Episode length": 506, "Policy Loss": -3.9602696895599365, "Value Loss": 13.616543769836426, "_runtime": 18206.542791366577, "_timestamp": 1585615576.1756608, "_step": 479}
{"Episode reward": 79.07615257259457, "Episode length": 211, "Policy Loss": -1.0275179147720337, "Value Loss": 29.169292449951172, "_runtime": 18206.92952466011, "_timestamp": 1585615576.5623941, "_step": 480}
{"Episode reward": 74.05638807638888, "Episode length": 261, "Policy Loss": -1.9482431411743164, "Value Loss": 25.519453048706055, "_runtime": 18207.133605718613, "_timestamp": 1585615576.7664752, "_step": 481}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": -0.5406949520111084, "Value Loss": 53.97248077392578, "_runtime": 18207.339847564697, "_timestamp": 1585615576.972717, "_step": 482}
{"Episode reward": 86.90000000000003, "Episode length": 131, "Policy Loss": -0.9896867871284485, "Value Loss": 47.078758239746094, "_runtime": 18207.784247159958, "_timestamp": 1585615577.4171166, "_step": 483}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": -2.027080535888672, "Value Loss": 23.431108474731445, "_runtime": 18208.489924669266, "_timestamp": 1585615578.1227942, "_step": 484}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": -4.080124378204346, "Value Loss": 14.717559814453125, "_runtime": 18209.994812250137, "_timestamp": 1585615579.6276817, "_step": 485}
{"Episode reward": -99.67757664678946, "Episode length": 999, "Policy Loss": -5.849210739135742, "Value Loss": 0.7377592921257019, "_runtime": 18210.31914281845, "_timestamp": 1585615579.9520123, "_step": 486}
{"Episode reward": 80.32852369891333, "Episode length": 198, "Policy Loss": -3.5072126388549805, "Value Loss": 31.590246200561523, "_runtime": 18210.756939888, "_timestamp": 1585615580.3898094, "_step": 487}
{"Episode reward": 72.29999999999988, "Episode length": 277, "Policy Loss": -2.8790371417999268, "Value Loss": 22.129169464111328, "_runtime": 18211.130917549133, "_timestamp": 1585615580.763787, "_step": 488}
{"Episode reward": 78.29999999999997, "Episode length": 217, "Policy Loss": -0.8883469104766846, "Value Loss": 27.91947364807129, "_runtime": 18211.6111369133, "_timestamp": 1585615581.2440064, "_step": 489}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": -2.1665945053100586, "Value Loss": 19.278614044189453, "_runtime": 18211.917841911316, "_timestamp": 1585615581.5507114, "_step": 490}
{"Episode reward": 80.38764634805402, "Episode length": 197, "Policy Loss": -1.3133232593536377, "Value Loss": 35.69440841674805, "_runtime": 18213.100692272186, "_timestamp": 1585615582.7335618, "_step": 491}
{"Episode reward": 20.841633906588186, "Episode length": 792, "Policy Loss": -4.581596374511719, "Value Loss": 9.316203117370605, "_runtime": 18213.309396743774, "_timestamp": 1585615582.9422662, "_step": 492}
{"Episode reward": 88.41675275319724, "Episode length": 116, "Policy Loss": 0.6535532474517822, "Value Loss": 48.86478805541992, "_runtime": 18213.80141067505, "_timestamp": 1585615583.4342802, "_step": 493}
{"Episode reward": 67.09999999999981, "Episode length": 329, "Policy Loss": -2.7016043663024902, "Value Loss": 18.99996566772461, "_runtime": 18214.174729585648, "_timestamp": 1585615583.807599, "_step": 494}
{"Episode reward": 77.79175068621986, "Episode length": 223, "Policy Loss": -1.076232671737671, "Value Loss": 33.59981155395508, "_runtime": 18214.512880325317, "_timestamp": 1585615584.1457498, "_step": 495}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": -2.1899876594543457, "Value Loss": 30.18263816833496, "_runtime": 18215.05934882164, "_timestamp": 1585615584.6922183, "_step": 496}
{"Episode reward": 63.87991062989435, "Episode length": 362, "Policy Loss": -1.6262332201004028, "Value Loss": 17.72737693786621, "_runtime": 18215.37158536911, "_timestamp": 1585615585.0044549, "_step": 497}
{"Episode reward": 79.75227272388874, "Episode length": 203, "Policy Loss": -1.7541191577911377, "Value Loss": 29.10696029663086, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947, -0.6294596195220947]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0], "bins": [-45.657630920410156, -44.93439483642578, -44.211158752441406, -43.48792266845703, -42.764686584472656, -42.04145050048828, -41.318214416503906, -40.59497833251953, -39.87174606323242, -39.14850997924805, -38.42527389526367, -37.7020378112793, -36.97880172729492, -36.25556564331055, -35.53232955932617, -34.8090934753418, -34.08585739135742, -33.36262130737305, -32.63938903808594, -31.91615104675293, -31.192914962768555, -30.469680786132812, -29.746444702148438, -29.023208618164062, -28.299972534179688, -27.576736450195312, -26.853500366210938, -26.130264282226562, -25.407028198242188, -24.683794021606445, -23.96055793762207, -23.237321853637695, -22.51408576965332, -21.790849685668945, -21.06761360168457, -20.344377517700195, -19.621143341064453, -18.897907257080078, -18.174671173095703, -17.451435089111328, -16.728199005126953, -16.004962921142578, -15.281728744506836, -14.558492660522461, -13.835256576538086, -13.112022399902344, -12.388786315917969, -11.665550231933594, -10.942314147949219, -10.219078063964844, -9.495841979980469, -8.772605895996094, -8.049369812011719, -7.326133728027344, -6.602897644042969, -5.879661560058594, -5.156425476074219, -4.433189392089844, -3.7099571228027344, -2.9867210388183594, -2.2634849548339844, -1.5402488708496094, -0.8170127868652344, -0.09377670288085938, 0.6294593811035156]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 12.0], "bins": [-1.7696815729141235, -1.7418681383132935, -1.714054822921753, -1.6862413883209229, -1.6584279537200928, -1.6306145191192627, -1.6028012037277222, -1.574987769126892, -1.5471744537353516, -1.5193610191345215, -1.4915475845336914, -1.4637341499328613, -1.4359208345413208, -1.4081073999404907, -1.3802940845489502, -1.3524806499481201, -1.32466721534729, -1.29685378074646, -1.2690403461456299, -1.2412270307540894, -1.2134135961532593, -1.1856002807617188, -1.1577868461608887, -1.1299734115600586, -1.1021599769592285, -1.074346661567688, -1.046533226966858, -1.0187199115753174, -0.9909064769744873, -0.9630930423736572, -0.9352796673774719, -0.9074662327766418, -0.8796528577804565, -0.8518394827842712, -0.8240260481834412, -0.7962126731872559, -0.7683992385864258, -0.7405859231948853, -0.7127724885940552, -0.6849590539932251, -0.657145619392395, -0.6293323040008545, -0.6015188694000244, -0.5737054347991943, -0.5458921194076538, -0.5180786848068237, -0.49026525020599365, -0.4624519348144531, -0.43463850021362305, -0.40682506561279297, -0.37901175022125244, -0.35119831562042236, -0.3233848810195923, -0.29557156562805176, -0.2677581310272217, -0.2399446964263916, -0.21213138103485107, -0.184317946434021, -0.15650451183319092, -0.12869107723236084, -0.10087776184082031, -0.07306432723999023, -0.045250892639160156, -0.01743757724761963, 0.01037585735321045]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 14.0, 4.0, 0.0, 9.0, 0.0, 1.0, 7.0, 9.0, 386.0, 38.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 4.0, 3.0], "bins": [-7.60412073135376, -7.460413455963135, -7.316705703735352, -7.172998428344727, -7.029291152954102, -6.885583877563477, -6.741876125335693, -6.598168849945068, -6.454461574554443, -6.31075382232666, -6.167046546936035, -6.02333927154541, -5.879631996154785, -5.735924243927002, -5.592216968536377, -5.448509693145752, -5.304801940917969, -5.161094665527344, -5.017387390136719, -4.873680114746094, -4.729972839355469, -4.5862650871276855, -4.4425578117370605, -4.298850059509277, -4.155142784118652, -4.011435508728027, -3.8677279949188232, -3.7240207195281982, -3.580313205718994, -3.436605930328369, -3.292898654937744, -3.149190902709961, -3.005483627319336, -2.861776351928711, -2.7180685997009277, -2.5743613243103027, -2.4306540489196777, -2.2869467735290527, -2.1432390213012695, -1.9995317459106445, -1.8558244705200195, -1.7121167182922363, -1.5684094429016113, -1.4247021675109863, -1.2809948921203613, -1.1372871398925781, -0.9935798645019531, -0.8498725891113281, -0.7061648368835449, -0.5624575614929199, -0.4187502861022949, -0.2750430107116699, -0.13133525848388672, 0.012372016906738281, 0.15607929229736328, 0.2997865676879883, 0.4434943199157715, 0.5872015953063965, 0.7309088706970215, 0.8746161460876465, 1.0183234214782715, 1.162031650543213, 1.305738925933838, 1.449446201324463, 1.593153476715088]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 0.0, 3.0, 0.0, 3.0, 1.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-8.028830528259277, -7.794924259185791, -7.561017990112305, -7.32711124420166, -7.093204975128174, -6.8592987060546875, -6.625392436981201, -6.391486167907715, -6.15757942199707, -5.923673152923584, -5.689766883850098, -5.455860137939453, -5.221954345703125, -4.9880475997924805, -4.754141330718994, -4.520235061645508, -4.286328315734863, -4.052422523498535, -3.8185157775878906, -3.5846095085144043, -3.350703239440918, -3.1167964935302734, -2.882890224456787, -2.648983955383301, -2.4150776863098145, -2.181171417236328, -1.9472646713256836, -1.7133584022521973, -1.479452133178711, -1.2455458641052246, -1.01163911819458, -0.7777328491210938, -0.5438265800476074, -0.3099203109741211, -0.07601404190063477, 0.15789222717285156, 0.3917989730834961, 0.6257057189941406, 0.8596115112304688, 1.0935182571411133, 1.3274240493774414, 1.561330795288086, 1.7952375411987305, 2.0291433334350586, 2.263050079345703, 2.4969558715820312, 2.730862617492676, 2.9647693634033203, 3.1986751556396484, 3.432581901550293, 3.666487693786621, 3.9003944396972656, 4.13430118560791, 4.368206977844238, 4.602113723754883, 4.836020469665527, 5.0699262619018555, 5.3038330078125, 5.537738800048828, 5.771645545959473, 6.005552291870117, 6.239458084106445, 6.47336483001709, 6.707270622253418, 6.9411773681640625]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.0743191242218018, -2.0263631343841553, -1.978407382965088, -1.930451512336731, -1.882495641708374, -1.834539771080017, -1.7865839004516602, -1.7386280298233032, -1.6906721591949463, -1.6427162885665894, -1.5947604179382324, -1.546804428100586, -1.4988486766815186, -1.450892686843872, -1.4029369354248047, -1.3549809455871582, -1.3070251941680908, -1.2590692043304443, -1.211113452911377, -1.1631574630737305, -1.115201711654663, -1.0672457218170166, -1.0192898511886597, -0.9713339805603027, -0.9233781099319458, -0.8754222393035889, -0.8274663686752319, -0.779510498046875, -0.7315546274185181, -0.6835987567901611, -0.6356428861618042, -0.5876870155334473, -0.5397311449050903, -0.4917752742767334, -0.44381940364837646, -0.39586353302001953, -0.3479076623916626, -0.29995179176330566, -0.25199592113494873, -0.2040400505065918, -0.15608417987823486, -0.10812830924987793, -0.060172319412231445, -0.012216567993164062, 0.03573942184448242, 0.0836951732635498, 0.1316511631011963, 0.17960691452026367, 0.22756290435791016, 0.27551865577697754, 0.323474645614624, 0.3714303970336914, 0.4193863868713379, 0.4673421382904053, 0.5152981281280518, 0.5632538795471191, 0.6112098693847656, 0.659165620803833, 0.7071216106414795, 0.7550773620605469, 0.8030333518981934, 0.8509891033172607, 0.8989450931549072, 0.9469008445739746, 0.9948568344116211]}, "_runtime": 18216.501764774323, "_timestamp": 1585615586.1346343, "_step": 498}
{"Episode reward": 24.292769297212388, "Episode length": 758, "Policy Loss": -4.545449256896973, "Value Loss": 8.522122383117676, "_runtime": 18216.501764774323, "_timestamp": 1585615586.1346343, "_step": 499}
