{"Episode reward": 84.68822015513092, "Episode length": 394, "Policy Loss": 0.10748623311519623, "Value Loss": 25.128387451171875, "_runtime": 21150.178691387177, "_timestamp": 1585618519.8115609, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.78299331665039, "Value Loss": 22.802019119262695, "_runtime": 21151.703493118286, "_timestamp": 1585618521.3363626, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.995806694030762, "Value Loss": 6223.5009765625, "_runtime": 21153.283484458923, "_timestamp": 1585618522.916354, "_step": 2}
{"Episode reward": -89.44537607969906, "Episode length": 999, "Policy Loss": -45.10323715209961, "Value Loss": 7260.708984375, "_runtime": 21154.884418964386, "_timestamp": 1585618524.5172884, "_step": 3}
{"Episode reward": -98.97169181637705, "Episode length": 999, "Policy Loss": 1.2828797101974487, "Value Loss": 14123.3505859375, "_runtime": 21156.450965881348, "_timestamp": 1585618526.0838354, "_step": 4}
{"Episode reward": -98.07940512119218, "Episode length": 999, "Policy Loss": -6.0741682052612305, "Value Loss": 4555.60400390625, "_runtime": 21156.84923005104, "_timestamp": 1585618526.4820995, "_step": 5}
{"Episode reward": 78.98911741944218, "Episode length": 215, "Policy Loss": -1.659915804862976, "Value Loss": 11393.5673828125, "_runtime": 21157.213988780975, "_timestamp": 1585618526.8468583, "_step": 6}
{"Episode reward": 80.27063299006645, "Episode length": 200, "Policy Loss": 110.1860580444336, "Value Loss": 5137.953125, "_runtime": 21158.787623643875, "_timestamp": 1585618528.4204931, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.056648254394531, "Value Loss": 2892.145751953125, "_runtime": 21160.31584095955, "_timestamp": 1585618529.9487104, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.9268741607666, "Value Loss": 2839.02880859375, "_runtime": 21160.629645347595, "_timestamp": 1585618530.2625148, "_step": 9}
{"Episode reward": 80.75841110545429, "Episode length": 194, "Policy Loss": -557.1470947265625, "Value Loss": 11190.705078125, "_runtime": 21162.20873951912, "_timestamp": 1585618531.841609, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -16.353670120239258, "Value Loss": 35.319854736328125, "_runtime": 21162.445531368256, "_timestamp": 1585618532.0784009, "_step": 11}
{"Episode reward": 88.99986423593299, "Episode length": 111, "Policy Loss": -764.1235961914062, "Value Loss": 12551.8447265625, "_runtime": 21162.614531755447, "_timestamp": 1585618532.2474012, "_step": 12}
{"Episode reward": 89.70000000000003, "Episode length": 103, "Policy Loss": 627.1199340820312, "Value Loss": 9899.6669921875, "_runtime": 21164.198072195053, "_timestamp": 1585618533.8309417, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6083970069885254, "Value Loss": 424.9246826171875, "_runtime": 21164.381672382355, "_timestamp": 1585618534.0145419, "_step": 14}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 2.396660327911377, "Value Loss": 340.47039794921875, "_runtime": 21164.549491882324, "_timestamp": 1585618534.1823614, "_step": 15}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": -270.6082458496094, "Value Loss": 1498.9559326171875, "_runtime": 21166.143262147903, "_timestamp": 1585618535.7761316, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.20172643661499, "Value Loss": 145.93014526367188, "_runtime": 21166.31877541542, "_timestamp": 1585618535.951645, "_step": 17}
{"Episode reward": 89.99993676543238, "Episode length": 101, "Policy Loss": -340.5741271972656, "Value Loss": 2519.134521484375, "_runtime": 21167.817647218704, "_timestamp": 1585618537.4505167, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.837394714355469, "Value Loss": 61.68754577636719, "_runtime": 21169.45507001877, "_timestamp": 1585618539.0879395, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.109645843505859, "Value Loss": 92.8155288696289, "_runtime": 21169.634480953217, "_timestamp": 1585618539.2673504, "_step": 20}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": -44.81117248535156, "Value Loss": 259.80938720703125, "_runtime": 21169.845102787018, "_timestamp": 1585618539.4779723, "_step": 21}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 27.798616409301758, "Value Loss": 152.49009704589844, "_runtime": 21170.18632888794, "_timestamp": 1585618539.8191984, "_step": 22}
{"Episode reward": 81.69629798940741, "Episode length": 185, "Policy Loss": 11.794977188110352, "Value Loss": 94.47798919677734, "_runtime": 21170.345548391342, "_timestamp": 1585618539.9784179, "_step": 23}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": 41.9256591796875, "Value Loss": 133.61183166503906, "_runtime": 21171.873474121094, "_timestamp": 1585618541.5063436, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.103353500366211, "Value Loss": 0.797412633895874, "_runtime": 21172.05761885643, "_timestamp": 1585618541.6904883, "_step": 25}
{"Episode reward": 89.80000000000003, "Episode length": 102, "Policy Loss": 44.761138916015625, "Value Loss": 133.27725219726562, "_runtime": 21172.225650548935, "_timestamp": 1585618541.85852, "_step": 26}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 38.70975112915039, "Value Loss": 117.506103515625, "_runtime": 21173.808866262436, "_timestamp": 1585618543.4417357, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.3304123878479, "Value Loss": 0.2941305935382843, "_runtime": 21173.968950510025, "_timestamp": 1585618543.60182, "_step": 28}
{"Episode reward": 90.30000000000003, "Episode length": 97, "Policy Loss": 31.152021408081055, "Value Loss": 116.51828002929688, "_runtime": 21174.12775540352, "_timestamp": 1585618543.760625, "_step": 29}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": 27.44835662841797, "Value Loss": 109.28480529785156, "_runtime": 21174.341332435608, "_timestamp": 1585618543.974202, "_step": 30}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 20.277938842773438, "Value Loss": 106.0853271484375, "_runtime": 21174.492554426193, "_timestamp": 1585618544.125424, "_step": 31}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": 8.453782081604004, "Value Loss": 100.21324157714844, "_runtime": 21174.66037774086, "_timestamp": 1585618544.2932472, "_step": 32}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": -8.959056854248047, "Value Loss": 91.20793151855469, "_runtime": 21174.81806921959, "_timestamp": 1585618544.4509387, "_step": 33}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -10.954105377197266, "Value Loss": 96.57235717773438, "_runtime": 21174.97559261322, "_timestamp": 1585618544.608462, "_step": 34}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -8.981083869934082, "Value Loss": 95.1005630493164, "_runtime": 21175.247650384903, "_timestamp": 1585618544.8805199, "_step": 35}
{"Episode reward": 82.09780110191753, "Episode length": 180, "Policy Loss": -1.3598138093948364, "Value Loss": 52.231536865234375, "_runtime": 21175.51744699478, "_timestamp": 1585618545.1503165, "_step": 36}
{"Episode reward": 82.10000000000002, "Episode length": 179, "Policy Loss": -6.372979164123535, "Value Loss": 54.25988006591797, "_runtime": 21175.697957992554, "_timestamp": 1585618545.3308275, "_step": 37}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -28.487096786499023, "Value Loss": 93.39713287353516, "_runtime": 21175.845663547516, "_timestamp": 1585618545.478533, "_step": 38}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": -15.632491111755371, "Value Loss": 107.3212890625, "_runtime": 21176.11757683754, "_timestamp": 1585618545.7504463, "_step": 39}
{"Episode reward": 82.40000000000003, "Episode length": 176, "Policy Loss": -7.850796222686768, "Value Loss": 56.02999496459961, "_runtime": 21176.266367197037, "_timestamp": 1585618545.8992367, "_step": 40}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -16.79511833190918, "Value Loss": 104.26713562011719, "_runtime": 21176.421959638596, "_timestamp": 1585618546.0548291, "_step": 41}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -21.680625915527344, "Value Loss": 102.13456726074219, "_runtime": 21176.584527254105, "_timestamp": 1585618546.2173967, "_step": 42}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -20.609725952148438, "Value Loss": 101.86616516113281, "_runtime": 21176.72738313675, "_timestamp": 1585618546.3602526, "_step": 43}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": -16.672496795654297, "Value Loss": 109.7882080078125, "_runtime": 21176.879173517227, "_timestamp": 1585618546.512043, "_step": 44}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": -15.040080070495605, "Value Loss": 102.8283462524414, "_runtime": 21177.022552490234, "_timestamp": 1585618546.655422, "_step": 45}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": -13.196684837341309, "Value Loss": 107.87026977539062, "_runtime": 21177.18061375618, "_timestamp": 1585618546.8134832, "_step": 46}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": -11.012614250183105, "Value Loss": 96.31986999511719, "_runtime": 21177.32794380188, "_timestamp": 1585618546.9608133, "_step": 47}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -6.44146203994751, "Value Loss": 101.43331146240234, "_runtime": 21177.484387636185, "_timestamp": 1585618547.117257, "_step": 48}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -11.82400894165039, "Value Loss": 99.00240325927734, "_runtime": 21177.633799791336, "_timestamp": 1585618547.2666693, "_step": 49}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": -2.5469958782196045, "Value Loss": 99.0373306274414, "_runtime": 21177.804916858673, "_timestamp": 1585618547.4377863, "_step": 50}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": -11.97035026550293, "Value Loss": 89.9151611328125, "_runtime": 21177.953235149384, "_timestamp": 1585618547.5861046, "_step": 51}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -2.1456148624420166, "Value Loss": 102.4031753540039, "_runtime": 21178.227506875992, "_timestamp": 1585618547.8603764, "_step": 52}
{"Episode reward": 81.80000000000001, "Episode length": 182, "Policy Loss": 8.455578804016113, "Value Loss": 54.15196990966797, "_runtime": 21178.38343143463, "_timestamp": 1585618548.016301, "_step": 53}
{"Episode reward": 90.20000000000002, "Episode length": 98, "Policy Loss": -4.646670818328857, "Value Loss": 99.01290130615234, "_runtime": 21178.5294175148, "_timestamp": 1585618548.162287, "_step": 54}
{"Episode reward": 90.80000000000003, "Episode length": 92, "Policy Loss": -1.3799434900283813, "Value Loss": 103.23336791992188, "_runtime": 21178.679758548737, "_timestamp": 1585618548.312628, "_step": 55}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 1.973160982131958, "Value Loss": 103.26306915283203, "_runtime": 21178.88846540451, "_timestamp": 1585618548.521335, "_step": 56}
{"Episode reward": 86.20000000000005, "Episode length": 138, "Policy Loss": -12.347831726074219, "Value Loss": 71.89497375488281, "_runtime": 21179.0401699543, "_timestamp": 1585618548.6730394, "_step": 57}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 5.7327752113342285, "Value Loss": 96.88335418701172, "_runtime": 21179.187377929688, "_timestamp": 1585618548.8202474, "_step": 58}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 5.233221054077148, "Value Loss": 101.33828735351562, "_runtime": 21179.341128110886, "_timestamp": 1585618548.9739976, "_step": 59}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 9.008489608764648, "Value Loss": 96.9621810913086, "_runtime": 21179.49298787117, "_timestamp": 1585618549.1258574, "_step": 60}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 2.600238084793091, "Value Loss": 99.87654876708984, "_runtime": 21179.649826049805, "_timestamp": 1585618549.2826955, "_step": 61}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": 9.611289024353027, "Value Loss": 95.02896118164062, "_runtime": 21179.809993505478, "_timestamp": 1585618549.442863, "_step": 62}
{"Episode reward": 89.80000000000003, "Episode length": 102, "Policy Loss": 1.1121501922607422, "Value Loss": 93.29059600830078, "_runtime": 21180.078120946884, "_timestamp": 1585618549.7109904, "_step": 63}
{"Episode reward": 82.20000000000002, "Episode length": 178, "Policy Loss": 11.050320625305176, "Value Loss": 53.58173370361328, "_runtime": 21180.22305369377, "_timestamp": 1585618549.8559232, "_step": 64}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 6.736542701721191, "Value Loss": 101.75094604492188, "_runtime": 21180.3673889637, "_timestamp": 1585618550.0002584, "_step": 65}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 9.212955474853516, "Value Loss": 103.793701171875, "_runtime": 21180.522256851196, "_timestamp": 1585618550.1551263, "_step": 66}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": 7.806920528411865, "Value Loss": 99.14260864257812, "_runtime": 21180.678155899048, "_timestamp": 1585618550.3110254, "_step": 67}
{"Episode reward": 90.10000000000002, "Episode length": 99, "Policy Loss": 7.85595703125, "Value Loss": 94.50096893310547, "_runtime": 21180.829778909683, "_timestamp": 1585618550.4626484, "_step": 68}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 7.952919006347656, "Value Loss": 98.10436248779297, "_runtime": 21180.975227832794, "_timestamp": 1585618550.6080973, "_step": 69}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 8.850830078125, "Value Loss": 100.5378189086914, "_runtime": 21181.130162000656, "_timestamp": 1585618550.7630315, "_step": 70}
{"Episode reward": 90.20000000000002, "Episode length": 98, "Policy Loss": 8.172762870788574, "Value Loss": 92.81805419921875, "_runtime": 21181.271560192108, "_timestamp": 1585618550.9044297, "_step": 71}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 6.0996479988098145, "Value Loss": 101.66028594970703, "_runtime": 21181.41861152649, "_timestamp": 1585618551.051481, "_step": 72}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 7.123015403747559, "Value Loss": 97.62490844726562, "_runtime": 21181.560396194458, "_timestamp": 1585618551.1932657, "_step": 73}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 4.244949817657471, "Value Loss": 101.25444030761719, "_runtime": 21181.71141076088, "_timestamp": 1585618551.3442802, "_step": 74}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 1.6231536865234375, "Value Loss": 96.4172592163086, "_runtime": 21181.875917434692, "_timestamp": 1585618551.508787, "_step": 75}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 0.5483548641204834, "Value Loss": 90.1988296508789, "_runtime": 21182.0561606884, "_timestamp": 1585618551.6890302, "_step": 76}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -1.4562560319900513, "Value Loss": 82.33134460449219, "_runtime": 21182.22163271904, "_timestamp": 1585618551.8545022, "_step": 77}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": -0.22221063077449799, "Value Loss": 88.79515838623047, "_runtime": 21182.371246814728, "_timestamp": 1585618552.0041163, "_step": 78}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 0.7760081887245178, "Value Loss": 96.95964813232422, "_runtime": 21182.518645763397, "_timestamp": 1585618552.1515152, "_step": 79}
{"Episode reward": 90.80000000000003, "Episode length": 92, "Policy Loss": 1.824968695640564, "Value Loss": 99.10859680175781, "_runtime": 21182.67706465721, "_timestamp": 1585618552.3099341, "_step": 80}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -0.4380490481853485, "Value Loss": 92.55894470214844, "_runtime": 21182.835706949234, "_timestamp": 1585618552.4685764, "_step": 81}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": -0.6582918167114258, "Value Loss": 92.61309051513672, "_runtime": 21183.108612775803, "_timestamp": 1585618552.7414823, "_step": 82}
{"Episode reward": 81.80000000000001, "Episode length": 182, "Policy Loss": 2.019085645675659, "Value Loss": 48.655921936035156, "_runtime": 21183.29755806923, "_timestamp": 1585618552.9304276, "_step": 83}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 0.4664415419101715, "Value Loss": 78.6148910522461, "_runtime": 21183.444644212723, "_timestamp": 1585618553.0775137, "_step": 84}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 1.6180541515350342, "Value Loss": 99.00460052490234, "_runtime": 21183.59721636772, "_timestamp": 1585618553.2300858, "_step": 85}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 1.9556589126586914, "Value Loss": 94.99891662597656, "_runtime": 21183.74156832695, "_timestamp": 1585618553.3744378, "_step": 86}
{"Episode reward": 91.00110329750677, "Episode length": 90, "Policy Loss": 2.5591728687286377, "Value Loss": 99.62889862060547, "_runtime": 21183.885555267334, "_timestamp": 1585618553.5184247, "_step": 87}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 1.1896189451217651, "Value Loss": 98.70108795166016, "_runtime": 21184.17879629135, "_timestamp": 1585618553.8116658, "_step": 88}
{"Episode reward": 81.4, "Episode length": 186, "Policy Loss": 0.5938147306442261, "Value Loss": 47.85801696777344, "_runtime": 21184.36162829399, "_timestamp": 1585618553.9944978, "_step": 89}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": -0.33832553029060364, "Value Loss": 81.64849853515625, "_runtime": 21184.50980782509, "_timestamp": 1585618554.1426773, "_step": 90}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 0.7336047291755676, "Value Loss": 96.74945068359375, "_runtime": 21184.67067360878, "_timestamp": 1585618554.303543, "_step": 91}
{"Episode reward": 90.10000000000002, "Episode length": 99, "Policy Loss": 2.4183459281921387, "Value Loss": 89.1741714477539, "_runtime": 21184.81727528572, "_timestamp": 1585618554.4501448, "_step": 92}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 6.597931861877441, "Value Loss": 96.96320343017578, "_runtime": 21184.95992207527, "_timestamp": 1585618554.5927916, "_step": 93}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 5.2199859619140625, "Value Loss": 97.94678497314453, "_runtime": 21185.109896421432, "_timestamp": 1585618554.742766, "_step": 94}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": -1.678127408027649, "Value Loss": 95.56846618652344, "_runtime": 21185.258490800858, "_timestamp": 1585618554.8913603, "_step": 95}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 2.477775812149048, "Value Loss": 95.60694122314453, "_runtime": 21185.401250600815, "_timestamp": 1585618555.03412, "_step": 96}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 1.9083292484283447, "Value Loss": 99.2552490234375, "_runtime": 21185.54776453972, "_timestamp": 1585618555.180634, "_step": 97}
{"Episode reward": 90.80000000000003, "Episode length": 92, "Policy Loss": 0.8434141278266907, "Value Loss": 96.48464965820312, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875, 42457.3046875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-42457.32421875, -36531.5078125, -30605.6875, -24679.869140625, -18754.05078125, -12828.232421875, -6902.4140625, -976.59765625, 4949.22265625, 10875.04296875, 16800.859375, 22726.67578125, 28652.49609375, 34578.31640625, 40504.12890625, 46429.94921875, 52355.76953125, 58281.58984375, 64207.41015625, 70133.21875, 76059.046875, 81984.859375, 87910.671875, 93836.5, 99762.3125, 105688.125, 111613.953125, 117539.765625, 123465.578125, 129391.40625, 135317.21875, 141243.046875, 147168.859375, 153094.671875, 159020.5, 164946.3125, 170872.140625, 176797.953125, 182723.765625, 188649.59375, 194575.40625, 200501.21875, 206427.046875, 212352.859375, 218278.671875, 224204.484375, 230130.328125, 236056.140625, 241981.953125, 247907.765625, 253833.578125, 259759.421875, 265685.25, 271611.0625, 277536.875, 283462.6875, 289388.5, 295314.34375, 301240.15625, 307165.96875, 313091.78125, 319017.59375, 324943.4375, 330869.25, 336795.0625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-149895.703125, -145790.453125, -141685.203125, -137579.953125, -133474.6875, -129369.4453125, -125264.1875, -121158.9375, -117053.6875, -112948.4375, -108843.1875, -104737.9296875, -100632.6796875, -96527.4296875, -92422.171875, -88316.921875, -84211.671875, -80106.421875, -76001.171875, -71895.9140625, -67790.6640625, -63685.4140625, -59580.15625, -55474.90625, -51369.65625, -47264.40625, -43159.15625, -39053.8984375, -34948.6484375, -30843.3984375, -26738.140625, -22632.890625, -18527.640625, -14422.390625, -10317.140625, -6211.890625, -2106.640625, 1998.625, 6103.875, 10209.125, 14314.375, 18419.625, 22524.875, 26630.125, 30735.390625, 34840.640625, 38945.890625, 43051.140625, 47156.390625, 51261.640625, 55366.890625, 59472.140625, 63577.390625, 67682.65625, 71787.90625, 75893.15625, 79998.40625, 84103.65625, 88208.90625, 92314.15625, 96419.421875, 100524.671875, 104629.921875, 108735.171875, 112840.421875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 6.0, 1.0, 6.0, 4.0, 4.0, 4.0, 5.0, 12.0, 11.0, 6.0, 10.0, 8.0, 6.0, 2.0, 2.0, 2.0, 0.0, 4.0, 7.0, 342.0, 3.0, 1.0, 0.0, 1.0, 4.0, 0.0, 7.0, 4.0, 15.0, 10.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-540269.0625, -525472.5, -510675.9375, -495879.375, -481082.84375, -466286.28125, -451489.71875, -436693.15625, -421896.625, -407100.0625, -392303.5, -377506.9375, -362710.375, -347913.8125, -333117.25, -318320.71875, -303524.15625, -288727.59375, -273931.03125, -259134.5, -244337.9375, -229541.375, -214744.8125, -199948.25, -185151.6875, -170355.15625, -155558.59375, -140762.03125, -125965.46875, -111168.90625, -96372.375, -81575.8125, -66779.25, -51982.6875, -37186.125, -22389.59375, -7593.0, 7203.5625, 22000.0625, 36796.625, 51593.1875, 66389.75, 81186.3125, 95982.875, 110779.4375, 125576.0, 140372.5625, 155169.125, 169965.6875, 184762.1875, 199558.75, 214355.3125, 229151.875, 243948.4375, 258745.0, 273541.5625, 288338.125, 303134.6875, 317931.25, 332727.75, 347524.3125, 362320.875, 377117.4375, 391914.0, 406710.5625]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2768666.0, -2672116.0, -2575566.25, -2479016.25, -2382466.25, -2285916.5, -2189366.5, -2092816.625, -1996266.75, -1899716.75, -1803166.875, -1706617.0, -1610067.0, -1513517.125, -1416967.25, -1320417.25, -1223867.375, -1127317.5, -1030767.5, -934217.625, -837667.75, -741117.75, -644568.0, -548018.0, -451468.0, -354918.25, -258368.25, -161818.25, -65268.5, 31281.5, 127831.5, 224381.25, 320931.25, 417481.25, 514031.0, 610581.0, 707131.0, 803680.75, 900230.75, 996780.75, 1093330.5, 1189880.5, 1286430.5, 1382980.25, 1479530.0, 1576080.0, 1672630.0, 1769180.0, 1865730.0, 1962280.0, 2058829.5, 2155379.5, 2251929.5, 2348479.5, 2445029.5, 2541579.5, 2638129.0, 2734679.0, 2831229.0, 2927779.0, 3024329.0, 3120879.0, 3217428.5, 3313978.5, 3410528.5]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 8.0, 2.0, 0.0, 12.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0], "bins": [-4334279.5, -4211579.0, -4088878.0, -3966177.25, -3843476.5, -3720775.75, -3598075.0, -3475374.5, -3352673.5, -3229973.0, -3107272.0, -2984571.5, -2861870.75, -2739170.0, -2616469.25, -2493768.5, -2371067.75, -2248367.0, -2125666.25, -2002965.5, -1880264.75, -1757564.0, -1634863.25, -1512162.5, -1389462.0, -1266761.25, -1144060.5, -1021359.75, -898659.0, -775958.25, -653257.5, -530556.75, -407856.0, -285155.25, -162454.5, -39754.0, 82947.0, 205647.5, 328348.5, 451049.0, 573750.0, 696450.5, 819151.5, 941852.0, 1064553.0, 1187253.5, 1309954.5, 1432655.0, 1555355.5, 1678056.5, 1800757.0, 1923458.0, 2046158.5, 2168859.5, 2291560.0, 2414261.0, 2536961.5, 2659662.5, 2782363.0, 2905064.0, 3027764.5, 3150465.5, 3273166.0, 3395867.0, 3518567.5]}, "_runtime": 21185.691296577454, "_timestamp": 1585618555.324166, "_step": 98}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 1.4387649297714233, "Value Loss": 98.72417449951172, "_runtime": 21185.842182397842, "_timestamp": 1585618555.4750519, "_step": 99}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": -1.0956939458847046, "Value Loss": 93.05604553222656, "_runtime": 21185.992002010345, "_timestamp": 1585618555.6248715, "_step": 100}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": -2.3232903480529785, "Value Loss": 95.0234146118164, "_runtime": 21186.149020671844, "_timestamp": 1585618555.7818902, "_step": 101}
{"Episode reward": 90.10000000000002, "Episode length": 99, "Policy Loss": -4.329082489013672, "Value Loss": 91.28723907470703, "_runtime": 21186.41838145256, "_timestamp": 1585618556.051251, "_step": 102}
{"Episode reward": 82.10000000000002, "Episode length": 179, "Policy Loss": 6.612377643585205, "Value Loss": 49.56394577026367, "_runtime": 21186.560980558395, "_timestamp": 1585618556.19385, "_step": 103}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 5.0765228271484375, "Value Loss": 97.83230590820312, "_runtime": 21186.72018456459, "_timestamp": 1585618556.353054, "_step": 104}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": -5.714378833770752, "Value Loss": 89.42804718017578, "_runtime": 21187.00512433052, "_timestamp": 1585618556.6379938, "_step": 105}
{"Episode reward": 81.50000000000001, "Episode length": 185, "Policy Loss": 7.264856815338135, "Value Loss": 48.56405258178711, "_runtime": 21187.14574766159, "_timestamp": 1585618556.7786171, "_step": 106}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": 5.719546318054199, "Value Loss": 98.30097198486328, "_runtime": 21187.294066905975, "_timestamp": 1585618556.9269364, "_step": 107}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -2.5948221683502197, "Value Loss": 94.0657958984375, "_runtime": 21187.451239824295, "_timestamp": 1585618557.0841093, "_step": 108}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": 6.619096755981445, "Value Loss": 93.09203338623047, "_runtime": 21187.702445030212, "_timestamp": 1585618557.3353145, "_step": 109}
{"Episode reward": 83.50000000000004, "Episode length": 165, "Policy Loss": 11.734644889831543, "Value Loss": 54.975486755371094, "_runtime": 21187.851741313934, "_timestamp": 1585618557.4846108, "_step": 110}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 7.037630081176758, "Value Loss": 91.08502197265625, "_runtime": 21188.001948595047, "_timestamp": 1585618557.634818, "_step": 111}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 11.452515602111816, "Value Loss": 90.36434173583984, "_runtime": 21188.15393424034, "_timestamp": 1585618557.7868037, "_step": 112}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 7.835789203643799, "Value Loss": 90.76303100585938, "_runtime": 21188.29815196991, "_timestamp": 1585618557.9310215, "_step": 113}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 10.142719268798828, "Value Loss": 93.39585876464844, "_runtime": 21188.573365688324, "_timestamp": 1585618558.2062352, "_step": 114}
{"Episode reward": 81.80000000000001, "Episode length": 182, "Policy Loss": 9.030922889709473, "Value Loss": 48.82689666748047, "_runtime": 21188.736563682556, "_timestamp": 1585618558.3694332, "_step": 115}
{"Episode reward": 89.61062328155242, "Episode length": 104, "Policy Loss": -13.296186447143555, "Value Loss": 85.9764404296875, "_runtime": 21188.885281085968, "_timestamp": 1585618558.5181506, "_step": 116}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": -10.5945463180542, "Value Loss": 96.31006622314453, "_runtime": 21189.067662715912, "_timestamp": 1585618558.7005322, "_step": 117}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": -20.283557891845703, "Value Loss": 85.73519897460938, "_runtime": 21189.348650455475, "_timestamp": 1585618558.98152, "_step": 118}
{"Episode reward": 81.4, "Episode length": 186, "Policy Loss": -3.5452489852905273, "Value Loss": 49.420631408691406, "_runtime": 21189.63674402237, "_timestamp": 1585618559.2696135, "_step": 119}
{"Episode reward": 80.9, "Episode length": 191, "Policy Loss": 5.645711898803711, "Value Loss": 46.59461975097656, "_runtime": 21189.779651403427, "_timestamp": 1585618559.412521, "_step": 120}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": -5.16963005065918, "Value Loss": 95.38658905029297, "_runtime": 21189.9408326149, "_timestamp": 1585618559.573702, "_step": 121}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": -2.139911651611328, "Value Loss": 92.81562805175781, "_runtime": 21190.10220003128, "_timestamp": 1585618559.7350695, "_step": 122}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": -0.6579706072807312, "Value Loss": 89.1015625, "_runtime": 21190.245517015457, "_timestamp": 1585618559.8783865, "_step": 123}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 1.2099145650863647, "Value Loss": 92.50590515136719, "_runtime": 21190.400943756104, "_timestamp": 1585618560.0338132, "_step": 124}
{"Episode reward": 90.20000000000002, "Episode length": 98, "Policy Loss": -11.759811401367188, "Value Loss": 92.08023834228516, "_runtime": 21190.55029439926, "_timestamp": 1585618560.183164, "_step": 125}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 5.956480503082275, "Value Loss": 90.81648254394531, "_runtime": 21190.69158744812, "_timestamp": 1585618560.324457, "_step": 126}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 10.482499122619629, "Value Loss": 96.50320434570312, "_runtime": 21190.837703943253, "_timestamp": 1585618560.4705734, "_step": 127}
{"Episode reward": 90.80000000000003, "Episode length": 92, "Policy Loss": -0.009480434469878674, "Value Loss": 90.40779113769531, "_runtime": 21190.990901470184, "_timestamp": 1585618560.623771, "_step": 128}
{"Episode reward": 90.30000000000003, "Episode length": 97, "Policy Loss": -8.822895050048828, "Value Loss": 90.4001693725586, "_runtime": 21191.137476682663, "_timestamp": 1585618560.7703462, "_step": 129}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -2.6476101875305176, "Value Loss": 92.5396499633789, "_runtime": 21191.285001277924, "_timestamp": 1585618560.9178708, "_step": 130}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 6.7229509353637695, "Value Loss": 89.36021423339844, "_runtime": 21191.42822957039, "_timestamp": 1585618561.061099, "_step": 131}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 12.315705299377441, "Value Loss": 93.86225891113281, "_runtime": 21191.570130109787, "_timestamp": 1585618561.2029996, "_step": 132}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 4.2116827964782715, "Value Loss": 94.6828384399414, "_runtime": 21191.713367700577, "_timestamp": 1585618561.3462372, "_step": 133}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 9.159844398498535, "Value Loss": 91.79951477050781, "_runtime": 21191.8609290123, "_timestamp": 1585618561.4937985, "_step": 134}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": 0.011318986304104328, "Value Loss": 88.62891387939453, "_runtime": 21192.002142190933, "_timestamp": 1585618561.6350117, "_step": 135}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": 4.558347702026367, "Value Loss": 93.15412139892578, "_runtime": 21192.160680294037, "_timestamp": 1585618561.7935498, "_step": 136}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": -15.353261947631836, "Value Loss": 91.51341247558594, "_runtime": 21192.336654663086, "_timestamp": 1585618561.9695241, "_step": 137}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": -17.055400848388672, "Value Loss": 85.23298645019531, "_runtime": 21192.482275009155, "_timestamp": 1585618562.1151445, "_step": 138}
{"Episode reward": 90.80000000000003, "Episode length": 92, "Policy Loss": -1.0262477397918701, "Value Loss": 89.01988983154297, "_runtime": 21192.62843799591, "_timestamp": 1585618562.2613075, "_step": 139}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 2.5866668224334717, "Value Loss": 89.81896209716797, "_runtime": 21192.777224063873, "_timestamp": 1585618562.4100935, "_step": 140}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -3.536797285079956, "Value Loss": 90.26040649414062, "_runtime": 21192.922777175903, "_timestamp": 1585618562.5556467, "_step": 141}
{"Episode reward": 90.90000000000002, "Episode length": 91, "Policy Loss": 9.870168685913086, "Value Loss": 89.374755859375, "_runtime": 21193.072771549225, "_timestamp": 1585618562.705641, "_step": 142}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": 3.719393014907837, "Value Loss": 87.22007751464844, "_runtime": 21193.23092317581, "_timestamp": 1585618562.8637927, "_step": 143}
{"Episode reward": 90.00000000000003, "Episode length": 100, "Policy Loss": -11.282031059265137, "Value Loss": 90.18917083740234, "_runtime": 21193.422860860825, "_timestamp": 1585618563.0557303, "_step": 144}
{"Episode reward": 87.58047292232517, "Episode length": 125, "Policy Loss": -11.778194427490234, "Value Loss": 76.47250366210938, "_runtime": 21193.57564663887, "_timestamp": 1585618563.2085161, "_step": 145}
{"Episode reward": 90.30985779426484, "Episode length": 97, "Policy Loss": -6.3414306640625, "Value Loss": 89.51817321777344, "_runtime": 21193.756429195404, "_timestamp": 1585618563.3892987, "_step": 146}
{"Episode reward": 88.44947386286331, "Episode length": 116, "Policy Loss": -9.513226509094238, "Value Loss": 80.9396743774414, "_runtime": 21194.036061763763, "_timestamp": 1585618563.6689312, "_step": 147}
{"Episode reward": 81.70000000000002, "Episode length": 183, "Policy Loss": 3.3328137397766113, "Value Loss": 49.1838493347168, "_runtime": 21194.17906165123, "_timestamp": 1585618563.8119311, "_step": 148}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": 5.680139541625977, "Value Loss": 93.68868255615234, "_runtime": 21194.336218833923, "_timestamp": 1585618563.9690883, "_step": 149}
{"Episode reward": 90.10000000000002, "Episode length": 99, "Policy Loss": -2.1677095890045166, "Value Loss": 88.52599334716797, "_runtime": 21194.482968568802, "_timestamp": 1585618564.115838, "_step": 150}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": 11.552699089050293, "Value Loss": 91.50827026367188, "_runtime": 21194.621819019318, "_timestamp": 1585618564.2546885, "_step": 151}
{"Episode reward": 91.38929881730482, "Episode length": 87, "Policy Loss": 5.914428234100342, "Value Loss": 94.6047134399414, "_runtime": 21194.77612566948, "_timestamp": 1585618564.4089952, "_step": 152}
{"Episode reward": 90.30000000000003, "Episode length": 97, "Policy Loss": 10.384352684020996, "Value Loss": 83.56770324707031, "_runtime": 21194.91647005081, "_timestamp": 1585618564.5493395, "_step": 153}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": 13.514400482177734, "Value Loss": 92.12529754638672, "_runtime": 21195.065698623657, "_timestamp": 1585618564.698568, "_step": 154}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 9.069437026977539, "Value Loss": 87.87236022949219, "_runtime": 21195.208070278168, "_timestamp": 1585618564.8409398, "_step": 155}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": -2.286391496658325, "Value Loss": 94.23440551757812, "_runtime": 21195.34852719307, "_timestamp": 1585618564.9813967, "_step": 156}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": 8.713456153869629, "Value Loss": 91.70985412597656, "_runtime": 21195.500557899475, "_timestamp": 1585618565.1334274, "_step": 157}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": -15.083255767822266, "Value Loss": 93.7150650024414, "_runtime": 21195.640892267227, "_timestamp": 1585618565.2737617, "_step": 158}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": 4.378014087677002, "Value Loss": 91.07006072998047, "_runtime": 21195.778750181198, "_timestamp": 1585618565.4116197, "_step": 159}
{"Episode reward": 91.40000000000002, "Episode length": 86, "Policy Loss": -3.8601741790771484, "Value Loss": 96.0135269165039, "_runtime": 21195.920866250992, "_timestamp": 1585618565.5537357, "_step": 160}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": -6.7163848876953125, "Value Loss": 94.22378540039062, "_runtime": 21196.055726528168, "_timestamp": 1585618565.688596, "_step": 161}
{"Episode reward": 91.60000000000002, "Episode length": 84, "Policy Loss": 10.956536293029785, "Value Loss": 95.4005355834961, "_runtime": 21196.197690963745, "_timestamp": 1585618565.8305604, "_step": 162}
{"Episode reward": 91.10000000000002, "Episode length": 89, "Policy Loss": -11.805063247680664, "Value Loss": 94.79924774169922, "_runtime": 21196.32977104187, "_timestamp": 1585618565.9626405, "_step": 163}
{"Episode reward": 91.80000000000001, "Episode length": 82, "Policy Loss": -6.9837422370910645, "Value Loss": 99.24855041503906, "_runtime": 21196.462919473648, "_timestamp": 1585618566.095789, "_step": 164}
{"Episode reward": 91.70000000000002, "Episode length": 83, "Policy Loss": 14.041245460510254, "Value Loss": 96.5169677734375, "_runtime": 21196.60635495186, "_timestamp": 1585618566.2392244, "_step": 165}
{"Episode reward": 91.00000000000003, "Episode length": 90, "Policy Loss": -12.237702369689941, "Value Loss": 93.93001556396484, "_runtime": 21196.753420591354, "_timestamp": 1585618566.38629, "_step": 166}
{"Episode reward": 90.70000000000002, "Episode length": 93, "Policy Loss": -0.41400712728500366, "Value Loss": 88.3441162109375, "_runtime": 21196.89061999321, "_timestamp": 1585618566.5234895, "_step": 167}
{"Episode reward": 91.40000000000002, "Episode length": 86, "Policy Loss": -10.990118980407715, "Value Loss": 98.21852111816406, "_runtime": 21197.02993297577, "_timestamp": 1585618566.6628025, "_step": 168}
{"Episode reward": 91.30000000000003, "Episode length": 87, "Policy Loss": 14.650808334350586, "Value Loss": 92.531005859375, "_runtime": 21197.171070814133, "_timestamp": 1585618566.8039403, "_step": 169}
{"Episode reward": 91.20000000000002, "Episode length": 88, "Policy Loss": -3.448593854904175, "Value Loss": 96.451904296875, "_runtime": 21197.321279525757, "_timestamp": 1585618566.954149, "_step": 170}
{"Episode reward": 90.50000000000003, "Episode length": 95, "Policy Loss": -11.61156940460205, "Value Loss": 95.71277618408203, "_runtime": 21197.454421043396, "_timestamp": 1585618567.0872905, "_step": 171}
{"Episode reward": 91.70000000000002, "Episode length": 83, "Policy Loss": 14.061450004577637, "Value Loss": 95.0914306640625, "_runtime": 21197.6204161644, "_timestamp": 1585618567.2532856, "_step": 172}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": 7.372595310211182, "Value Loss": 91.2990493774414, "_runtime": 21197.788924217224, "_timestamp": 1585618567.4217937, "_step": 173}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 0.5521001219749451, "Value Loss": 88.3587417602539, "_runtime": 21197.966213703156, "_timestamp": 1585618567.5990832, "_step": 174}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -5.524713039398193, "Value Loss": 80.52853393554688, "_runtime": 21198.135926246643, "_timestamp": 1585618567.7687957, "_step": 175}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": -0.5138203501701355, "Value Loss": 79.54177856445312, "_runtime": 21198.31173682213, "_timestamp": 1585618567.9446063, "_step": 176}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 2.574985980987549, "Value Loss": 74.1054916381836, "_runtime": 21198.494832754135, "_timestamp": 1585618568.1277022, "_step": 177}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 2.2487056255340576, "Value Loss": 73.99408721923828, "_runtime": 21199.159193754196, "_timestamp": 1585618568.7920632, "_step": 178}
{"Episode reward": 55.39498244374955, "Episode length": 447, "Policy Loss": -6.807884693145752, "Value Loss": 19.26333236694336, "_runtime": 21199.450059890747, "_timestamp": 1585618569.0829294, "_step": 179}
{"Episode reward": 81.60000000000002, "Episode length": 184, "Policy Loss": -5.423901081085205, "Value Loss": 50.722591400146484, "_runtime": 21200.215268611908, "_timestamp": 1585618569.848138, "_step": 180}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": -7.380137920379639, "Value Loss": 17.55865478515625, "_runtime": 21200.53412914276, "_timestamp": 1585618570.1669986, "_step": 181}
{"Episode reward": 80.45373633390959, "Episode length": 196, "Policy Loss": -3.6178016662597656, "Value Loss": 44.0241584777832, "_runtime": 21200.98800301552, "_timestamp": 1585618570.6208725, "_step": 182}
{"Episode reward": 70.29999999999986, "Episode length": 297, "Policy Loss": -8.64474868774414, "Value Loss": 31.81467628479004, "_runtime": 21201.854611635208, "_timestamp": 1585618571.487481, "_step": 183}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": -7.812131881713867, "Value Loss": 18.1878604888916, "_runtime": 21203.05325436592, "_timestamp": 1585618572.6861238, "_step": 184}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": -6.846548557281494, "Value Loss": 12.017047882080078, "_runtime": 21204.58743953705, "_timestamp": 1585618574.220309, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.131067276000977, "Value Loss": 1.4294068813323975, "_runtime": 21205.02591085434, "_timestamp": 1585618574.6587803, "_step": 186}
{"Episode reward": 73.05654821395864, "Episode length": 270, "Policy Loss": -5.17111349105835, "Value Loss": 32.38874435424805, "_runtime": 21206.214057922363, "_timestamp": 1585618575.8469274, "_step": 187}
{"Episode reward": 24.24325327128176, "Episode length": 759, "Policy Loss": -7.092502593994141, "Value Loss": 13.948710441589355, "_runtime": 21207.574578285217, "_timestamp": 1585618577.2074478, "_step": 188}
{"Episode reward": 13.100000000000662, "Episode length": 869, "Policy Loss": -7.0790815353393555, "Value Loss": 12.774150848388672, "_runtime": 21209.115296840668, "_timestamp": 1585618578.7481663, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.861038684844971, "Value Loss": 1.7824867963790894, "_runtime": 21210.637146949768, "_timestamp": 1585618580.2700164, "_step": 190}
{"Episode reward": 3.900000000001185, "Episode length": 961, "Policy Loss": -6.388711929321289, "Value Loss": 11.008172988891602, "_runtime": 21212.219880104065, "_timestamp": 1585618581.8527496, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.233720302581787, "Value Loss": 0.5375752449035645, "_runtime": 21213.792689323425, "_timestamp": 1585618583.4255588, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.536502361297607, "Value Loss": 1.1948738098144531, "_runtime": 21215.42877793312, "_timestamp": 1585618585.0616474, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.9865803718566895, "Value Loss": 0.776980996131897, "_runtime": 21217.02090072632, "_timestamp": 1585618586.6537702, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.961599349975586, "Value Loss": 1.137980341911316, "_runtime": 21217.809051513672, "_timestamp": 1585618587.441921, "_step": 195}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": -3.937502861022949, "Value Loss": 20.279441833496094, "_runtime": 21218.943407297134, "_timestamp": 1585618588.5762768, "_step": 196}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": -4.307158470153809, "Value Loss": 14.105255126953125, "_runtime": 21220.53231716156, "_timestamp": 1585618590.1651866, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.334023475646973, "Value Loss": 0.8544661402702332, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044, 0.0011721079936251044]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0011721079936251044, 0.01511963177472353, 0.03141137212514877, 0.04770311340689659, 0.06399484723806381, 0.08028658479452133, 0.09657832980155945, 0.11287006735801697, 0.1291618049144745, 0.145453542470932, 0.16174528002738953, 0.17803701758384705, 0.19432877004146576, 0.21062050759792328, 0.2269122451543808, 0.24320398271083832, 0.25949573516845703, 0.27578747272491455, 0.29207921028137207, 0.3083709478378296, 0.3246626853942871, 0.34095442295074463, 0.35724616050720215, 0.37353789806365967, 0.3898296654224396, 0.4061214029788971, 0.4224131405353546, 0.43870487809181213, 0.45499661564826965, 0.4712883532047272, 0.4875800907611847, 0.5038717985153198, 0.5201635360717773, 0.5364552736282349, 0.5527470111846924, 0.5690387487411499, 0.5853304862976074, 0.6016222238540649, 0.6179139614105225, 0.63420569896698, 0.6504974365234375, 0.666789174079895, 0.6830809116363525, 0.6993726491928101, 0.7156643867492676, 0.7319561243057251, 0.7482478618621826, 0.7645395994186401, 0.7808313965797424, 0.7971231341362, 0.8134148716926575, 0.829706609249115, 0.8459983468055725, 0.86229008436203, 0.8785818219184875, 0.8948735594749451, 0.9111652970314026, 0.9274570345878601, 0.9437487721443176, 0.9600405097007751, 0.9763322472572327, 0.9926239848136902, 1.0089157819747925, 1.02520751953125, 1.0414992570877075]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.001415298436768353, -0.0012881841976195574, -0.0011610699584707618, -0.0010339557193219662, -0.0009068414801731706, -0.000779727241024375, -0.0006526130018755794, -0.0005254987627267838, -0.00039838452357798815, -0.00027127028442919254, -0.00014415604528039694, -1.7041806131601334e-05, 0.00011007243301719427, 0.00023718667216598988, 0.0003643009113147855, 0.0004914151504635811, 0.0006185293896123767, 0.0007456437451764941, 0.0008727578679099679, 0.0009998719906434417, 0.0011269863462075591, 0.0012541007017716765, 0.0013812148245051503, 0.001508328947238624, 0.0016354433028027415, 0.001762557658366859, 0.0018896717811003327, 0.0020167860202491283, 0.0021439003758132458, 0.002271014731377363, 0.0023981286212801933, 0.0025252429768443108, 0.002652357332408428, 0.0027794716879725456, 0.002906586043536663, 0.003033699933439493, 0.0031608142890036106, 0.003287928644567728, 0.003415042534470558, 0.0035421568900346756, 0.003669271245598793, 0.0037963856011629105, 0.003923499956727028, 0.004050613846629858, 0.0041777282021939754, 0.004304842557758093, 0.004431956447660923, 0.0045590708032250404, 0.004686185158789158, 0.004813299514353275, 0.004940413869917393, 0.005067527759820223, 0.00519464211538434, 0.005321756470948458, 0.005448870360851288, 0.005575984716415405, 0.005703099071979523, 0.00583021342754364, 0.005957327783107758, 0.006084441673010588, 0.006211556028574705, 0.0063386703841388226, 0.006465784274041653, 0.00659289862960577, 0.0067200129851698875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 4.0, 1.0, 0.0, 1.0, 7.0, 8.0, 14.0, 37.0, 41.0, 31.0, 40.0, 181.0, 20.0, 20.0, 3.0, 4.0, 6.0, 8.0, 10.0, 4.0, 5.0, 8.0, 11.0, 6.0, 4.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07330785691738129, -0.06913089007139206, -0.06495392322540283, -0.060776952654123306, -0.05659998580813408, -0.05242301896214485, -0.048246048390865326, -0.0440690815448761, -0.03989211469888687, -0.035715147852897644, -0.03153818100690842, -0.02736121043562889, -0.023184243589639664, -0.019007276743650436, -0.01483030617237091, -0.010653339326381683, -0.006476372480392456, -0.0022994056344032288, 0.0018775612115859985, 0.006054528057575226, 0.010231494903564453, 0.014408469200134277, 0.018585436046123505, 0.022762402892112732, 0.02693936973810196, 0.031116336584091187, 0.035293303430080414, 0.03947027027606964, 0.043647244572639465, 0.04782421141862869, 0.05200117826461792, 0.05617813766002655, 0.060355111956596375, 0.0645320862531662, 0.06870904564857483, 0.07288601994514465, 0.07706297934055328, 0.08123995363712311, 0.08541691303253174, 0.08959388732910156, 0.09377084672451019, 0.09794782102108002, 0.10212479531764984, 0.10630175471305847, 0.1104787290096283, 0.11465568840503693, 0.11883266270160675, 0.12300962209701538, 0.1271865963935852, 0.13136357069015503, 0.13554053008556366, 0.13971750438213348, 0.14389446377754211, 0.14807143807411194, 0.15224839746952057, 0.1564253717660904, 0.16060234606266022, 0.16477930545806885, 0.16895627975463867, 0.1731332391500473, 0.17731021344661713, 0.18148718774318695, 0.1856641322374344, 0.1898411065340042, 0.19401808083057404]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.11814241111278534, -0.11478737741708755, -0.11143234372138977, -0.10807730257511139, -0.1047222688794136, -0.10136723518371582, -0.09801219403743744, -0.09465716034173965, -0.09130212664604187, -0.08794709295034409, -0.0845920592546463, -0.08123701810836792, -0.07788198441267014, -0.07452695071697235, -0.07117190957069397, -0.06781687587499619, -0.0644618421792984, -0.061106808483600616, -0.057751771062612534, -0.05439673364162445, -0.051041699945926666, -0.04768666625022888, -0.0443316251039505, -0.040976591408252716, -0.03762155771255493, -0.03426652401685715, -0.030911490321159363, -0.02755644917488098, -0.024201415479183197, -0.020846381783485413, -0.01749134063720703, -0.014136306941509247, -0.010781273245811462, -0.007426239550113678, -0.0040712058544158936, -0.0007161647081375122, 0.002638868987560272, 0.005993902683258057, 0.009348943829536438, 0.012703970074653625, 0.016059011220932007, 0.019414052367210388, 0.022769078612327576, 0.026124119758605957, 0.02947916090488434, 0.032834187150001526, 0.03618922829627991, 0.039544254541397095, 0.042899295687675476, 0.04625433683395386, 0.049609363079071045, 0.052964404225349426, 0.056319430470466614, 0.059674471616744995, 0.06302951276302338, 0.06638453900814056, 0.06973958015441895, 0.07309462130069733, 0.07644964754581451, 0.0798046886920929, 0.08315972983837128, 0.08651475608348846, 0.08986979722976685, 0.09322482347488403, 0.09657986462116241]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 0.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.15627191960811615, -0.15206626057624817, -0.1478606015443802, -0.1436549425125122, -0.13944928348064423, -0.13524362444877625, -0.13103796541690826, -0.12683230638504028, -0.1226266399025917, -0.11842098087072372, -0.11421532183885574, -0.11000965535640717, -0.10580399632453918, -0.1015983372926712, -0.09739267826080322, -0.09318701922893524, -0.08898136019706726, -0.08477570116519928, -0.0805700421333313, -0.07636438310146332, -0.07215872406959534, -0.06795305758714676, -0.06374739855527878, -0.0595417395234108, -0.055336080491542816, -0.051130421459674835, -0.046924762427806854, -0.04271910339593887, -0.038513436913490295, -0.034307777881622314, -0.030102118849754333, -0.025896459817886353, -0.02169080078601837, -0.01748514175415039, -0.01327948272228241, -0.009073823690414429, -0.004868164658546448, -0.0006625056266784668, 0.003543153405189514, 0.007748812437057495, 0.011954471468925476, 0.01616014540195465, 0.020365804433822632, 0.024571463465690613, 0.028777122497558594, 0.032982781529426575, 0.037188440561294556, 0.04139409959316254, 0.04559975862503052, 0.0498054176568985, 0.05401107668876648, 0.05821673572063446, 0.06242239475250244, 0.06662805378437042, 0.0708337128162384, 0.07503937184810638, 0.07924504578113556, 0.08345070481300354, 0.08765636384487152, 0.0918620228767395, 0.09606768190860748, 0.10027332603931427, 0.10447899997234344, 0.10868464410305023, 0.1128903180360794]}, "_runtime": 21222.08534002304, "_timestamp": 1585618591.7182095, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.360973358154297, "Value Loss": 0.4677512049674988, "_runtime": 21222.836406469345, "_timestamp": 1585618592.469276, "_step": 199}
{"Episode reward": 53.19999999999961, "Episode length": 468, "Policy Loss": -3.3844542503356934, "Value Loss": 20.978633880615234, "_runtime": 21224.012366056442, "_timestamp": 1585618593.6452355, "_step": 200}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": -3.7258057594299316, "Value Loss": 14.00247573852539, "_runtime": 21224.399266719818, "_timestamp": 1585618594.0321362, "_step": 201}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": -0.252591997385025, "Value Loss": 45.214115142822266, "_runtime": 21225.950853586197, "_timestamp": 1585618595.583723, "_step": 202}
{"Episode reward": -99.88647728562215, "Episode length": 999, "Policy Loss": -4.990131378173828, "Value Loss": 0.7920705080032349, "_runtime": 21227.116205215454, "_timestamp": 1585618596.7490747, "_step": 203}
{"Episode reward": 26.999999999999872, "Episode length": 730, "Policy Loss": -3.64859938621521, "Value Loss": 13.894099235534668, "_runtime": 21228.188054561615, "_timestamp": 1585618597.820924, "_step": 204}
{"Episode reward": 29.38468393683408, "Episode length": 707, "Policy Loss": -3.532181978225708, "Value Loss": 14.148538589477539, "_runtime": 21229.7725212574, "_timestamp": 1585618599.4053907, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.645834922790527, "Value Loss": 0.5558481812477112, "_runtime": 21231.34836792946, "_timestamp": 1585618600.9812374, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.696681499481201, "Value Loss": 0.3985683023929596, "_runtime": 21232.80210995674, "_timestamp": 1585618602.4349794, "_step": 207}
{"Episode reward": 6.500000000001037, "Episode length": 935, "Policy Loss": -3.4922451972961426, "Value Loss": 10.440305709838867, "_runtime": 21234.411417484283, "_timestamp": 1585618604.044287, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.525202751159668, "Value Loss": 0.570548415184021, "_runtime": 21236.01997566223, "_timestamp": 1585618605.6528451, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.448387145996094, "Value Loss": 0.2735365033149719, "_runtime": 21237.58286499977, "_timestamp": 1585618607.2157345, "_step": 210}
{"Episode reward": 0.7000000000013671, "Episode length": 993, "Policy Loss": -3.3076705932617188, "Value Loss": 10.104447364807129, "_runtime": 21238.95876979828, "_timestamp": 1585618608.5916393, "_step": 211}
{"Episode reward": 14.300000000000594, "Episode length": 857, "Policy Loss": -3.2233834266662598, "Value Loss": 11.522811889648438, "_runtime": 21240.591546058655, "_timestamp": 1585618610.2244155, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.110373020172119, "Value Loss": 0.3256071209907532, "_runtime": 21242.047981977463, "_timestamp": 1585618611.6808515, "_step": 213}
{"Episode reward": 8.100000000000946, "Episode length": 919, "Policy Loss": -3.077899694442749, "Value Loss": 10.737704277038574, "_runtime": 21243.65240573883, "_timestamp": 1585618613.2852752, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.016602039337158, "Value Loss": 0.34755241870880127, "_runtime": 21244.87019634247, "_timestamp": 1585618614.5030658, "_step": 215}
{"Episode reward": 24.89999999999999, "Episode length": 751, "Policy Loss": -2.671781539916992, "Value Loss": 13.04269027709961, "_runtime": 21246.157685756683, "_timestamp": 1585618615.7905552, "_step": 216}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": -2.714308977127075, "Value Loss": 11.9981689453125, "_runtime": 21247.754426717758, "_timestamp": 1585618617.3872962, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.888751745223999, "Value Loss": 0.18000607192516327, "_runtime": 21248.51171517372, "_timestamp": 1585618618.1445847, "_step": 218}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": -1.8229560852050781, "Value Loss": 21.15570068359375, "_runtime": 21250.099663496017, "_timestamp": 1585618619.732533, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.7255828380584717, "Value Loss": 0.21905450522899628, "_runtime": 21251.68666768074, "_timestamp": 1585618621.3195372, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.7471470832824707, "Value Loss": 0.25965064764022827, "_runtime": 21253.24031662941, "_timestamp": 1585618622.873186, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.670057773590088, "Value Loss": 0.19243809580802917, "_runtime": 21254.843190670013, "_timestamp": 1585618624.4760602, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6301660537719727, "Value Loss": 0.1526351422071457, "_runtime": 21255.766529798508, "_timestamp": 1585618625.3993993, "_step": 223}
{"Episode reward": 43.29999999999947, "Episode length": 567, "Policy Loss": -1.7388349771499634, "Value Loss": 17.052072525024414, "_runtime": 21257.354166984558, "_timestamp": 1585618626.9870365, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.532970905303955, "Value Loss": 0.18092657625675201, "_runtime": 21258.95423102379, "_timestamp": 1585618628.5871005, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4660391807556152, "Value Loss": 0.18288660049438477, "_runtime": 21259.78289628029, "_timestamp": 1585618629.4157658, "_step": 226}
{"Episode reward": 47.99089422225906, "Episode length": 521, "Policy Loss": -1.6500060558319092, "Value Loss": 18.687393188476562, "_runtime": 21261.378430128098, "_timestamp": 1585618631.0112996, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3451175689697266, "Value Loss": 0.13536924123764038, "_runtime": 21262.38093686104, "_timestamp": 1585618632.0138063, "_step": 228}
{"Episode reward": 37.899999999999395, "Episode length": 621, "Policy Loss": -1.6487582921981812, "Value Loss": 15.694314002990723, "_runtime": 21263.311563014984, "_timestamp": 1585618632.9444325, "_step": 229}
{"Episode reward": 41.09999999999944, "Episode length": 589, "Policy Loss": -1.656078815460205, "Value Loss": 16.4655818939209, "_runtime": 21264.599573373795, "_timestamp": 1585618634.2324429, "_step": 230}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": -2.0858161449432373, "Value Loss": 12.323780059814453, "_runtime": 21265.721311330795, "_timestamp": 1585618635.3541808, "_step": 231}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": -1.9923559427261353, "Value Loss": 13.62979507446289, "_runtime": 21267.080679178238, "_timestamp": 1585618636.7135487, "_step": 232}
{"Episode reward": 12.80000000000068, "Episode length": 872, "Policy Loss": -2.107294797897339, "Value Loss": 11.165502548217773, "_runtime": 21268.10328888893, "_timestamp": 1585618637.7361584, "_step": 233}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": -1.7459393739700317, "Value Loss": 15.245074272155762, "_runtime": 21269.671041727066, "_timestamp": 1585618639.3039112, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.191322088241577, "Value Loss": 0.14559541642665863, "_runtime": 21271.251876354218, "_timestamp": 1585618640.8847458, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1532299518585205, "Value Loss": 0.17575375735759735, "_runtime": 21272.820783138275, "_timestamp": 1585618642.4536526, "_step": 236}
{"Episode reward": -99.8042659997926, "Episode length": 999, "Policy Loss": -3.174713373184204, "Value Loss": 0.1461157202720642, "_runtime": 21274.42515063286, "_timestamp": 1585618644.05802, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1459038257598877, "Value Loss": 0.16522133350372314, "_runtime": 21275.067352056503, "_timestamp": 1585618644.7002215, "_step": 238}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": -0.18962691724300385, "Value Loss": 25.332870483398438, "_runtime": 21276.650614738464, "_timestamp": 1585618646.2834842, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1028740406036377, "Value Loss": 0.13070352375507355, "_runtime": 21278.249975681305, "_timestamp": 1585618647.8828452, "_step": 240}
{"Episode reward": -99.88913093209126, "Episode length": 999, "Policy Loss": -2.9892430305480957, "Value Loss": 0.15923817455768585, "_runtime": 21279.78665661812, "_timestamp": 1585618649.419526, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0615012645721436, "Value Loss": 0.12752920389175415, "_runtime": 21281.399928808212, "_timestamp": 1585618651.0327983, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.995831251144409, "Value Loss": 0.1247110590338707, "_runtime": 21282.998740673065, "_timestamp": 1585618652.6316102, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.9666895866394043, "Value Loss": 0.11079901456832886, "_runtime": 21284.598650693893, "_timestamp": 1585618654.2315202, "_step": 244}
{"Episode reward": -99.8079101562486, "Episode length": 999, "Policy Loss": -2.929165840148926, "Value Loss": 0.09831744432449341, "_runtime": 21285.875638008118, "_timestamp": 1585618655.5085075, "_step": 245}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": -1.7730942964553833, "Value Loss": 12.216496467590332, "_runtime": 21287.465494155884, "_timestamp": 1585618657.0983636, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8649849891662598, "Value Loss": 0.14835084974765778, "_runtime": 21289.05686855316, "_timestamp": 1585618658.689738, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8330845832824707, "Value Loss": 0.09580771625041962, "_runtime": 21290.132351398468, "_timestamp": 1585618659.7652209, "_step": 248}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": -1.395254135131836, "Value Loss": 14.71863842010498, "_runtime": 21291.743889570236, "_timestamp": 1585618661.376759, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.810382843017578, "Value Loss": 0.10893078148365021, "_runtime": 21293.340762853622, "_timestamp": 1585618662.9736323, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7406413555145264, "Value Loss": 0.13595236837863922, "_runtime": 21294.919238328934, "_timestamp": 1585618664.5521078, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.69852614402771, "Value Loss": 0.1215183362364769, "_runtime": 21295.93093562126, "_timestamp": 1585618665.563805, "_step": 252}
{"Episode reward": 38.31870970129907, "Episode length": 617, "Policy Loss": -1.1957979202270508, "Value Loss": 15.43027114868164, "_runtime": 21297.522658348083, "_timestamp": 1585618667.1555278, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6960296630859375, "Value Loss": 0.14388760924339294, "_runtime": 21298.947041511536, "_timestamp": 1585618668.579911, "_step": 254}
{"Episode reward": 11.000000000000782, "Episode length": 890, "Policy Loss": -1.419779658317566, "Value Loss": 10.87624740600586, "_runtime": 21300.5161755085, "_timestamp": 1585618670.149045, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6040492057800293, "Value Loss": 0.11838884651660919, "_runtime": 21301.59132695198, "_timestamp": 1585618671.2241964, "_step": 256}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": -1.2783946990966797, "Value Loss": 14.369996070861816, "_runtime": 21302.650249004364, "_timestamp": 1585618672.2831185, "_step": 257}
{"Episode reward": 34.59999999999944, "Episode length": 654, "Policy Loss": -1.2253119945526123, "Value Loss": 14.700977325439453, "_runtime": 21303.43157339096, "_timestamp": 1585618673.0644429, "_step": 258}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": -0.6097840666770935, "Value Loss": 19.66424560546875, "_runtime": 21304.083703517914, "_timestamp": 1585618673.716573, "_step": 259}
{"Episode reward": 59.5999999999997, "Episode length": 404, "Policy Loss": -0.20015566051006317, "Value Loss": 23.17572784423828, "_runtime": 21305.660292863846, "_timestamp": 1585618675.2931623, "_step": 260}
{"Episode reward": -99.86522455215314, "Episode length": 999, "Policy Loss": -2.573538064956665, "Value Loss": 0.13322892785072327, "_runtime": 21307.203183174133, "_timestamp": 1585618676.8360527, "_step": 261}
{"Episode reward": 0.9000000000013557, "Episode length": 991, "Policy Loss": -1.5960770845413208, "Value Loss": 9.60983657836914, "_runtime": 21308.73880672455, "_timestamp": 1585618678.3716762, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.545426607131958, "Value Loss": 0.09958568215370178, "_runtime": 21310.32816195488, "_timestamp": 1585618679.9610314, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5231385231018066, "Value Loss": 0.12074893712997437, "_runtime": 21311.10006928444, "_timestamp": 1585618680.7329388, "_step": 264}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": -0.6917259097099304, "Value Loss": 19.848535537719727, "_runtime": 21312.67443370819, "_timestamp": 1585618682.3073032, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5209553241729736, "Value Loss": 0.07226898521184921, "_runtime": 21313.738909244537, "_timestamp": 1585618683.3717787, "_step": 266}
{"Episode reward": 34.09999999999947, "Episode length": 659, "Policy Loss": -1.1279884576797485, "Value Loss": 14.31608772277832, "_runtime": 21315.3276283741, "_timestamp": 1585618684.9604979, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.545107364654541, "Value Loss": 0.10478173196315765, "_runtime": 21316.23549580574, "_timestamp": 1585618685.8683653, "_step": 268}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": -1.0993428230285645, "Value Loss": 17.075658798217773, "_runtime": 21317.806997060776, "_timestamp": 1585618687.4398665, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5039632320404053, "Value Loss": 0.09622681885957718, "_runtime": 21319.40151143074, "_timestamp": 1585618689.034381, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.501903533935547, "Value Loss": 0.12051979452371597, "_runtime": 21320.95098400116, "_timestamp": 1585618690.5838535, "_step": 271}
{"Episode reward": 0.3000000000013898, "Episode length": 997, "Policy Loss": -1.5998746156692505, "Value Loss": 9.604145050048828, "_runtime": 21322.54445052147, "_timestamp": 1585618692.17732, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.471879482269287, "Value Loss": 0.08958490192890167, "_runtime": 21324.13466691971, "_timestamp": 1585618693.7675364, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.492029905319214, "Value Loss": 0.1058555543422699, "_runtime": 21325.72847723961, "_timestamp": 1585618695.3613467, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.49173903465271, "Value Loss": 0.16648966073989868, "_runtime": 21326.916885614395, "_timestamp": 1585618696.549755, "_step": 275}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": -1.2930971384048462, "Value Loss": 12.869020462036133, "_runtime": 21328.27211213112, "_timestamp": 1585618697.9049816, "_step": 276}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": -1.4099199771881104, "Value Loss": 10.767481803894043, "_runtime": 21329.867627859116, "_timestamp": 1585618699.5004973, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3922626972198486, "Value Loss": 0.07846158742904663, "_runtime": 21331.444876670837, "_timestamp": 1585618701.0777462, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3660614490509033, "Value Loss": 0.07079674303531647, "_runtime": 21333.035041570663, "_timestamp": 1585618702.667911, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.329519271850586, "Value Loss": 0.08602064102888107, "_runtime": 21334.644918441772, "_timestamp": 1585618704.277788, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.319526195526123, "Value Loss": 0.07208086550235748, "_runtime": 21335.510437250137, "_timestamp": 1585618705.1433067, "_step": 281}
{"Episode reward": 48.79999999999955, "Episode length": 512, "Policy Loss": -0.6754632592201233, "Value Loss": 17.76278305053711, "_runtime": 21337.12650156021, "_timestamp": 1585618706.759371, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.27028226852417, "Value Loss": 0.08459644019603729, "_runtime": 21338.824866056442, "_timestamp": 1585618708.4577355, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2626419067382812, "Value Loss": 0.07620713114738464, "_runtime": 21339.44419813156, "_timestamp": 1585618709.0770676, "_step": 284}
{"Episode reward": 62.99999999999975, "Episode length": 370, "Policy Loss": 0.07347436994314194, "Value Loss": 24.76180076599121, "_runtime": 21340.955089092255, "_timestamp": 1585618710.5879586, "_step": 285}
{"Episode reward": 8.40000000000093, "Episode length": 916, "Policy Loss": -1.2680071592330933, "Value Loss": 10.436285972595215, "_runtime": 21342.603200912476, "_timestamp": 1585618712.2360704, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.24155592918396, "Value Loss": 0.09102793782949448, "_runtime": 21343.417217969894, "_timestamp": 1585618713.0500875, "_step": 287}
{"Episode reward": 49.899999999999565, "Episode length": 501, "Policy Loss": -0.6750203371047974, "Value Loss": 18.582571029663086, "_runtime": 21345.0725171566, "_timestamp": 1585618714.7053866, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2200310230255127, "Value Loss": 0.059627383947372437, "_runtime": 21346.74407672882, "_timestamp": 1585618716.3769462, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2068862915039062, "Value Loss": 0.07517965137958527, "_runtime": 21348.20458483696, "_timestamp": 1585618717.8374543, "_step": 290}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": -1.2570490837097168, "Value Loss": 10.364142417907715, "_runtime": 21348.963393688202, "_timestamp": 1585618718.5962632, "_step": 291}
{"Episode reward": 56.291186523437155, "Episode length": 438, "Policy Loss": -0.21791930496692657, "Value Loss": 21.530658721923828, "_runtime": 21350.617978572845, "_timestamp": 1585618720.250848, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.173635482788086, "Value Loss": 0.0874524638056755, "_runtime": 21351.89029955864, "_timestamp": 1585618721.523169, "_step": 293}
{"Episode reward": 22.200000000000145, "Episode length": 778, "Policy Loss": -1.0723880529403687, "Value Loss": 11.945075035095215, "_runtime": 21352.735939264297, "_timestamp": 1585618722.3688087, "_step": 294}
{"Episode reward": 45.0999999999995, "Episode length": 549, "Policy Loss": -0.3105798363685608, "Value Loss": 16.24895477294922, "_runtime": 21354.24314546585, "_timestamp": 1585618723.876015, "_step": 295}
{"Episode reward": 4.99996373653525, "Episode length": 951, "Policy Loss": -1.2954331636428833, "Value Loss": 10.235520362854004, "_runtime": 21355.08974480629, "_timestamp": 1585618724.7226143, "_step": 296}
{"Episode reward": 46.34855020046186, "Episode length": 537, "Policy Loss": -0.6034637689590454, "Value Loss": 17.70246696472168, "_runtime": 21356.62267756462, "_timestamp": 1585618726.255547, "_step": 297}
{"Episode reward": -99.81808741092541, "Episode length": 999, "Policy Loss": -2.198362112045288, "Value Loss": 0.07957153767347336, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059, 0.01602235995233059]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.15937276184558868, 0.3175300359725952, 0.47568732500076294, 0.6338446140289307, 0.7920019030570984, 0.9501591920852661, 1.1083165407180786, 1.2664737701416016, 1.424631118774414, 1.5827884674072266, 1.7409456968307495, 1.8991029262542725, 2.057260274887085, 2.2154176235198975, 2.373574733734131, 2.5317320823669434, 2.689889430999756, 2.8480467796325684, 3.006204128265381, 3.1643612384796143, 3.3225185871124268, 3.4806759357452393, 3.6388330459594727, 3.796990394592285, 3.9551477432250977, 4.11330509185791, 4.271462440490723, 4.429619789123535, 4.5877766609191895, 4.745934009552002, 4.9040913581848145, 5.062248706817627, 5.2204060554504395, 5.378563404083252, 5.5367207527160645, 5.694878101348877, 5.8530354499816895, 6.011192321777344, 6.169349670410156, 6.327507019042969, 6.485664367675781, 6.643821716308594, 6.801979064941406, 6.960136413574219, 7.118293285369873, 7.2764506340026855, 7.434607982635498, 7.5927653312683105, 7.750922679901123, 7.9090800285339355, 8.06723690032959, 8.225394248962402, 8.383551597595215, 8.541708946228027, 8.69986629486084, 8.858023643493652, 9.016180038452148, 9.174337387084961, 9.332494735717773, 9.490652084350586, 9.648809432983398, 9.806966781616211, 9.965124130249023, 10.123281478881836, 10.281438827514648]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.011133210733532906, -0.009539655409753323, -0.00794610008597374, -0.006352545693516731, -0.004758990369737148, -0.0031654350459575653, -0.001571880653500557, 2.167467027902603e-05, 0.001615229994058609, 0.003208785317838192, 0.004802340641617775, 0.006395895034074783, 0.007989449426531792, 0.00958300568163395, 0.011176560074090958, 0.012770116329193115, 0.014363670721650124, 0.015957225114107132, 0.01755078136920929, 0.019144335761666298, 0.020737892016768456, 0.022331444546580315, 0.023925000801682472, 0.02551855705678463, 0.02711210958659649, 0.028705665841698647, 0.030299222096800804, 0.03189277648925781, 0.03348632901906967, 0.03507988899946213, 0.03667344152927399, 0.038266994059085846, 0.0398605540394783, 0.04145410656929016, 0.04304765909910202, 0.044641219079494476, 0.046234771609306335, 0.047828324139118195, 0.04942188411951065, 0.05101543664932251, 0.052608996629714966, 0.054202549159526825, 0.055796101689338684, 0.05738966166973114, 0.058983214199543, 0.06057676672935486, 0.062170326709747314, 0.06376387923955917, 0.06535743176937103, 0.06695099174976349, 0.06854454427957535, 0.0701381042599678, 0.07173165678977966, 0.07332520931959152, 0.07491876929998398, 0.07651232182979584, 0.0781058743596077, 0.07969943434000015, 0.08129298686981201, 0.08288653939962387, 0.08448009938001633, 0.08607365190982819, 0.08766720443964005, 0.0892607644200325, 0.09085431694984436]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 3.0, 2.0, 9.0, 12.0, 34.0, 61.0, 135.0, 116.0, 31.0, 4.0, 5.0, 3.0, 2.0, 6.0, 2.0, 13.0, 9.0, 5.0, 8.0, 10.0, 10.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.17216400802135468, -0.15078622102737427, -0.12940841913223267, -0.10803063213825226, -0.08665283769369125, -0.06527504324913025, -0.04389725625514984, -0.02251945436000824, -0.001141667366027832, 0.020236119627952576, 0.04161392152309418, 0.06299170851707458, 0.08436949551105499, 0.1057472974061966, 0.1271250993013382, 0.1485028713941574, 0.169880673289299, 0.1912584751844406, 0.21263624727725983, 0.23401404917240143, 0.25539183616638184, 0.27676963806152344, 0.29814743995666504, 0.31952524185180664, 0.34090298414230347, 0.36228078603744507, 0.38365858793258667, 0.40503638982772827, 0.4264141917228699, 0.4477919340133667, 0.4691697359085083, 0.4905475378036499, 0.5119253396987915, 0.5333031415939331, 0.5546809434890747, 0.5760587453842163, 0.5974364876747131, 0.6188142895698547, 0.6401920914649963, 0.6615698933601379, 0.6829476952552795, 0.7043254971504211, 0.725703239440918, 0.7470810413360596, 0.7684588432312012, 0.7898366451263428, 0.8112144470214844, 0.8325921893119812, 0.8539699912071228, 0.8753477931022644, 0.896725594997406, 0.9181033968925476, 0.9394811987876892, 0.9608590006828308, 0.9822368025779724, 1.0036146640777588, 1.0249924659729004, 1.046370267868042, 1.067747950553894, 1.0891257524490356, 1.1105035543441772, 1.1318813562393188, 1.1532591581344604, 1.174636960029602, 1.1960147619247437]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 5.0, 4.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.14807087182998657, -0.12425406277179718, -0.10043726116418839, -0.07662045955657959, -0.0528036504983902, -0.028986841440200806, -0.005170047283172607, 0.018646761775016785, 0.04246357083320618, 0.06628037989139557, 0.09009718894958496, 0.11391398310661316, 0.13773077726364136, 0.16154760122299194, 0.18536439538002014, 0.20918121933937073, 0.23299801349639893, 0.2568148076534271, 0.2806316316127777, 0.3044484257698059, 0.3282652497291565, 0.3520820140838623, 0.3758988380432129, 0.3997156620025635, 0.4235324263572693, 0.4473492503166199, 0.47116607427597046, 0.49498289823532104, 0.5187996625900269, 0.5426164865493774, 0.566433310508728, 0.5902500748634338, 0.6140668988227844, 0.637883722782135, 0.6617004871368408, 0.6855173110961914, 0.709334135055542, 0.7331508994102478, 0.7569677233695984, 0.780784547328949, 0.8046013712882996, 0.8284181356430054, 0.8522348999977112, 0.8760517239570618, 0.8998685479164124, 0.9236853718757629, 0.9475021958351135, 0.9713190197944641, 0.9951357245445251, 1.0189526081085205, 1.042769432067871, 1.0665862560272217, 1.0904030799865723, 1.1142199039459229, 1.1380367279052734, 1.161853313446045, 1.1856701374053955, 1.209486961364746, 1.2333037853240967, 1.2571206092834473, 1.2809374332427979, 1.3047542572021484, 1.328571081161499, 1.3523879051208496, 1.3762047290802002]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 5.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0], "bins": [-0.22414912283420563, -0.21432872116565704, -0.20450833439826965, -0.19468793272972107, -0.18486753106117249, -0.1750471293926239, -0.1652267426252365, -0.15540634095668793, -0.14558595418930054, -0.13576555252075195, -0.12594515085220337, -0.11612475663423538, -0.1063043624162674, -0.09648396074771881, -0.08666355907917023, -0.07684317231178284, -0.06702277064323425, -0.05720236897468567, -0.04738198220729828, -0.037561580538749695, -0.02774117887020111, -0.01792079210281372, -0.008100390434265137, 0.0017200112342834473, 0.011540398001670837, 0.02136079967021942, 0.031181201338768005, 0.04100160300731659, 0.05082200467586517, 0.06064237654209137, 0.07046277821063995, 0.08028317987918854, 0.09010358154773712, 0.0999239832162857, 0.10974438488483429, 0.11956478655338287, 0.12938515841960907, 0.13920556008815765, 0.14902596175670624, 0.15884636342525482, 0.1686667650938034, 0.178487166762352, 0.18830753862857819, 0.19812794029712677, 0.20794834196567535, 0.21776874363422394, 0.22758914530277252, 0.2374095469713211, 0.2472299188375473, 0.2570503354072571, 0.26687073707580566, 0.27669113874435425, 0.28651154041290283, 0.2963319420814514, 0.30615234375, 0.3159727454185486, 0.32579314708709717, 0.33561354875564575, 0.34543389081954956, 0.35525429248809814, 0.36507469415664673, 0.3748950958251953, 0.3847154974937439, 0.3945358991622925, 0.40435630083084106]}, "_runtime": 21357.24110507965, "_timestamp": 1585618726.8739746, "_step": 298}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 0.10414297133684158, "Value Loss": 23.672035217285156, "_runtime": 21358.79834508896, "_timestamp": 1585618728.4312146, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.201401710510254, "Value Loss": 0.10282083600759506, "_runtime": 21360.376945734024, "_timestamp": 1585618730.0098152, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.185149908065796, "Value Loss": 0.0662941113114357, "_runtime": 21361.792459964752, "_timestamp": 1585618731.4253294, "_step": 301}
{"Episode reward": 7.700000000000969, "Episode length": 923, "Policy Loss": -1.3723615407943726, "Value Loss": 10.330205917358398, "_runtime": 21363.423983097076, "_timestamp": 1585618733.0568526, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1657824516296387, "Value Loss": 0.06342259049415588, "_runtime": 21365.0190615654, "_timestamp": 1585618734.651931, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.194655179977417, "Value Loss": 0.06633398681879044, "_runtime": 21366.58530497551, "_timestamp": 1585618736.2181745, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.148904800415039, "Value Loss": 0.06133569777011871, "_runtime": 21368.16588973999, "_timestamp": 1585618737.7987592, "_step": 305}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": -1.294842004776001, "Value Loss": 9.072382926940918, "_runtime": 21369.753928422928, "_timestamp": 1585618739.386798, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.176485300064087, "Value Loss": 0.09843800216913223, "_runtime": 21371.02998805046, "_timestamp": 1585618740.6628575, "_step": 307}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": -1.0607452392578125, "Value Loss": 11.560400009155273, "_runtime": 21372.642797470093, "_timestamp": 1585618742.275667, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.124588966369629, "Value Loss": 0.05998660624027252, "_runtime": 21373.662377357483, "_timestamp": 1585618743.2952468, "_step": 309}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": -0.8530701994895935, "Value Loss": 15.097796440124512, "_runtime": 21375.25134420395, "_timestamp": 1585618744.8842137, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.098726987838745, "Value Loss": 0.052887845784425735, "_runtime": 21376.01966524124, "_timestamp": 1585618745.6525347, "_step": 311}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": -0.11773502826690674, "Value Loss": 19.03531837463379, "_runtime": 21376.54858469963, "_timestamp": 1585618746.1814542, "_step": 312}
{"Episode reward": 67.98125782273692, "Episode length": 321, "Policy Loss": 0.44427490234375, "Value Loss": 29.565719604492188, "_runtime": 21378.130248069763, "_timestamp": 1585618747.7631176, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0589520931243896, "Value Loss": 0.0794905424118042, "_runtime": 21379.68815279007, "_timestamp": 1585618749.3210223, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0358829498291016, "Value Loss": 0.07241612672805786, "_runtime": 21380.805938720703, "_timestamp": 1585618750.4388082, "_step": 315}
{"Episode reward": 27.499999999999844, "Episode length": 725, "Policy Loss": -0.8795802593231201, "Value Loss": 11.969657897949219, "_runtime": 21382.405018806458, "_timestamp": 1585618752.0378883, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0466561317443848, "Value Loss": 0.08856561034917831, "_runtime": 21383.13009238243, "_timestamp": 1585618752.7629619, "_step": 317}
{"Episode reward": 55.39999999999964, "Episode length": 446, "Policy Loss": -0.12232735008001328, "Value Loss": 20.47663116455078, "_runtime": 21384.69167304039, "_timestamp": 1585618754.3245425, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0063791275024414, "Value Loss": 0.05920405685901642, "_runtime": 21386.29338002205, "_timestamp": 1585618755.9262495, "_step": 319}
{"Episode reward": -99.89346961974958, "Episode length": 999, "Policy Loss": -2.0060369968414307, "Value Loss": 0.06482266634702682, "_runtime": 21387.708532571793, "_timestamp": 1585618757.341402, "_step": 320}
{"Episode reward": 8.800000000000907, "Episode length": 912, "Policy Loss": -0.8038231134414673, "Value Loss": 9.53615665435791, "_runtime": 21389.331079244614, "_timestamp": 1585618758.9639487, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9927743673324585, "Value Loss": 0.06267780065536499, "_runtime": 21390.93334054947, "_timestamp": 1585618760.56621, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9974037408828735, "Value Loss": 0.05679294839501381, "_runtime": 21392.514912605286, "_timestamp": 1585618762.147782, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9546833038330078, "Value Loss": 0.059769872575998306, "_runtime": 21394.1178483963, "_timestamp": 1585618763.7507179, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.907462477684021, "Value Loss": 0.073154516518116, "_runtime": 21395.014082193375, "_timestamp": 1585618764.6469517, "_step": 325}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": -0.31501781940460205, "Value Loss": 16.09791374206543, "_runtime": 21396.609410762787, "_timestamp": 1585618766.2422802, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.881639003753662, "Value Loss": 0.07244507968425751, "_runtime": 21398.21228122711, "_timestamp": 1585618767.8451507, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8587654829025269, "Value Loss": 0.09259618073701859, "_runtime": 21399.76831293106, "_timestamp": 1585618769.4011824, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9180392026901245, "Value Loss": 0.05250483751296997, "_runtime": 21400.59699487686, "_timestamp": 1585618770.2298644, "_step": 329}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": -0.019910704344511032, "Value Loss": 18.387605667114258, "_runtime": 21402.189567804337, "_timestamp": 1585618771.8224373, "_step": 330}
{"Episode reward": -99.81740861534932, "Episode length": 999, "Policy Loss": -1.887693166732788, "Value Loss": 0.049326930195093155, "_runtime": 21403.796127319336, "_timestamp": 1585618773.4289968, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8778080940246582, "Value Loss": 0.040658753365278244, "_runtime": 21405.354026556015, "_timestamp": 1585618774.986896, "_step": 332}
{"Episode reward": -99.86882193088393, "Episode length": 999, "Policy Loss": -1.862480878829956, "Value Loss": 0.06961112469434738, "_runtime": 21406.961150169373, "_timestamp": 1585618776.5940197, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.840928554534912, "Value Loss": 0.03937485069036484, "_runtime": 21408.56788802147, "_timestamp": 1585618778.2007575, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8100414276123047, "Value Loss": 0.05529968813061714, "_runtime": 21410.16881585121, "_timestamp": 1585618779.8016853, "_step": 335}
{"Episode reward": -99.88890058994154, "Episode length": 999, "Policy Loss": -1.7939037084579468, "Value Loss": 0.061470333486795425, "_runtime": 21411.51490187645, "_timestamp": 1585618781.1477714, "_step": 336}
{"Episode reward": 16.700000000000458, "Episode length": 833, "Policy Loss": -0.8694790601730347, "Value Loss": 11.350831985473633, "_runtime": 21412.889710187912, "_timestamp": 1585618782.5225797, "_step": 337}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": -0.7674524188041687, "Value Loss": 10.458667755126953, "_runtime": 21414.537398815155, "_timestamp": 1585618784.1702683, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7472492456436157, "Value Loss": 0.140679731965065, "_runtime": 21416.129778146744, "_timestamp": 1585618785.7626476, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7194855213165283, "Value Loss": 0.04868030548095703, "_runtime": 21417.714158296585, "_timestamp": 1585618787.3470278, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6947964429855347, "Value Loss": 0.03568704426288605, "_runtime": 21419.321320056915, "_timestamp": 1585618788.9541895, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7535500526428223, "Value Loss": 0.29547277092933655, "_runtime": 21420.814105033875, "_timestamp": 1585618790.4469745, "_step": 342}
{"Episode reward": 7.100000000001003, "Episode length": 929, "Policy Loss": -0.7614747881889343, "Value Loss": 9.380451202392578, "_runtime": 21422.42838382721, "_timestamp": 1585618792.0612533, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6182206869125366, "Value Loss": 0.033296164125204086, "_runtime": 21423.268505096436, "_timestamp": 1585618792.9013746, "_step": 344}
{"Episode reward": 48.99999999999955, "Episode length": 510, "Policy Loss": 0.04631556198000908, "Value Loss": 17.673416137695312, "_runtime": 21424.866413354874, "_timestamp": 1585618794.4992828, "_step": 345}
{"Episode reward": -99.88462562560895, "Episode length": 999, "Policy Loss": -1.56533682346344, "Value Loss": 0.04596709460020065, "_runtime": 21426.486070632935, "_timestamp": 1585618796.11894, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.52170729637146, "Value Loss": 0.04843122884631157, "_runtime": 21428.047753572464, "_timestamp": 1585618797.680623, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5141563415527344, "Value Loss": 0.04270852729678154, "_runtime": 21429.656315803528, "_timestamp": 1585618799.2891853, "_step": 348}
{"Episode reward": -99.82453828453878, "Episode length": 999, "Policy Loss": -1.5607088804244995, "Value Loss": 0.15978360176086426, "_runtime": 21431.26610517502, "_timestamp": 1585618800.8989747, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.485939621925354, "Value Loss": 0.05573352053761482, "_runtime": 21432.859558820724, "_timestamp": 1585618802.4924283, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.458749532699585, "Value Loss": 0.041642386466264725, "_runtime": 21434.477543354034, "_timestamp": 1585618804.1104128, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4206757545471191, "Value Loss": 0.05435851216316223, "_runtime": 21436.09475517273, "_timestamp": 1585618805.7276247, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3839267492294312, "Value Loss": 0.09452469646930695, "_runtime": 21437.684364795685, "_timestamp": 1585618807.3172343, "_step": 353}
{"Episode reward": 3.200000000001225, "Episode length": 968, "Policy Loss": -0.4789569079875946, "Value Loss": 9.287012100219727, "_runtime": 21439.304869413376, "_timestamp": 1585618808.937739, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3774000406265259, "Value Loss": 0.029395049437880516, "_runtime": 21440.81922006607, "_timestamp": 1585618810.4520895, "_step": 355}
{"Episode reward": 6.900000000001015, "Episode length": 931, "Policy Loss": -0.5229820013046265, "Value Loss": 10.45347785949707, "_runtime": 21442.299583673477, "_timestamp": 1585618811.9324532, "_step": 356}
{"Episode reward": 8.263694667817106, "Episode length": 918, "Policy Loss": -0.4109236001968384, "Value Loss": 9.66326904296875, "_runtime": 21443.005353450775, "_timestamp": 1585618812.638223, "_step": 357}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 0.4777550995349884, "Value Loss": 22.707988739013672, "_runtime": 21443.412826776505, "_timestamp": 1585618813.0456963, "_step": 358}
{"Episode reward": 77.79999999999995, "Episode length": 222, "Policy Loss": 2.4945034980773926, "Value Loss": 41.4393424987793, "_runtime": 21445.010257959366, "_timestamp": 1585618814.6431274, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2363375425338745, "Value Loss": 0.055710554122924805, "_runtime": 21446.57421398163, "_timestamp": 1585618816.2070835, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2351406812667847, "Value Loss": 0.05346348136663437, "_runtime": 21447.37620306015, "_timestamp": 1585618817.0090725, "_step": 361}
{"Episode reward": 47.699999999999534, "Episode length": 523, "Policy Loss": 0.2918500304222107, "Value Loss": 17.71219253540039, "_runtime": 21448.55540728569, "_timestamp": 1585618818.1882768, "_step": 362}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": -0.15133075416088104, "Value Loss": 12.839167594909668, "_runtime": 21450.137592315674, "_timestamp": 1585618819.7704618, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2135846614837646, "Value Loss": 0.058493856340646744, "_runtime": 21451.683313131332, "_timestamp": 1585618821.3161826, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1875457763671875, "Value Loss": 0.06360688805580139, "_runtime": 21452.320307016373, "_timestamp": 1585618821.9531765, "_step": 365}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 1.2751988172531128, "Value Loss": 22.4726505279541, "_runtime": 21453.905905246735, "_timestamp": 1585618823.5387747, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2325760126113892, "Value Loss": 0.037458356469869614, "_runtime": 21455.483907938004, "_timestamp": 1585618825.1167774, "_step": 367}
{"Episode reward": -99.87716181278088, "Episode length": 999, "Policy Loss": -1.2434360980987549, "Value Loss": 0.04652261361479759, "_runtime": 21457.029011011124, "_timestamp": 1585618826.6618805, "_step": 368}
{"Episode reward": 0.1691237449660008, "Episode length": 999, "Policy Loss": -0.43545690178871155, "Value Loss": 9.242410659790039, "_runtime": 21458.637219667435, "_timestamp": 1585618828.2700891, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2449560165405273, "Value Loss": 0.027224143967032433, "_runtime": 21459.936727523804, "_timestamp": 1585618829.569597, "_step": 370}
{"Episode reward": 18.200000000000372, "Episode length": 818, "Policy Loss": -0.4392572343349457, "Value Loss": 12.061704635620117, "_runtime": 21461.571760892868, "_timestamp": 1585618831.2046304, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2671056985855103, "Value Loss": 0.12125540524721146, "_runtime": 21462.499470949173, "_timestamp": 1585618832.1323404, "_step": 372}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 0.013760354369878769, "Value Loss": 16.72443199157715, "_runtime": 21463.590919733047, "_timestamp": 1585618833.2237892, "_step": 373}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.03599036484956741, "Value Loss": 13.066110610961914, "_runtime": 21465.173793315887, "_timestamp": 1585618834.8066628, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1844563484191895, "Value Loss": 0.03943294286727905, "_runtime": 21466.749676465988, "_timestamp": 1585618836.382546, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1671340465545654, "Value Loss": 0.028965987265110016, "_runtime": 21468.325870990753, "_timestamp": 1585618837.9587405, "_step": 376}
{"Episode reward": -99.800074768065, "Episode length": 999, "Policy Loss": -1.1642191410064697, "Value Loss": 0.03274418041110039, "_runtime": 21469.9202811718, "_timestamp": 1585618839.5531507, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1548174619674683, "Value Loss": 0.0263831727206707, "_runtime": 21471.45202279091, "_timestamp": 1585618841.0848923, "_step": 378}
{"Episode reward": 4.2999484479438905, "Episode length": 958, "Policy Loss": -0.2508234977722168, "Value Loss": 9.478983879089355, "_runtime": 21473.01268863678, "_timestamp": 1585618842.645558, "_step": 379}
{"Episode reward": 2.4000000000012705, "Episode length": 976, "Policy Loss": -0.21419963240623474, "Value Loss": 9.323026657104492, "_runtime": 21474.600979328156, "_timestamp": 1585618844.2338488, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1035895347595215, "Value Loss": 0.07001771777868271, "_runtime": 21476.19915175438, "_timestamp": 1585618845.8320212, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1169257164001465, "Value Loss": 0.04095079377293587, "_runtime": 21477.803119182587, "_timestamp": 1585618847.4359887, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1042640209197998, "Value Loss": 0.017106004059314728, "_runtime": 21479.403393507004, "_timestamp": 1585618849.036263, "_step": 383}
{"Episode reward": -99.8123253107057, "Episode length": 999, "Policy Loss": -1.071640133857727, "Value Loss": 0.03997635468840599, "_runtime": 21481.003861665726, "_timestamp": 1585618850.6367311, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.083156943321228, "Value Loss": 0.03256252035498619, "_runtime": 21482.604163885117, "_timestamp": 1585618852.2370334, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0709043741226196, "Value Loss": 0.02481350116431713, "_runtime": 21483.753929376602, "_timestamp": 1585618853.3867989, "_step": 386}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": 0.04761030152440071, "Value Loss": 12.998498916625977, "_runtime": 21484.2822098732, "_timestamp": 1585618853.9150794, "_step": 387}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 1.7263069152832031, "Value Loss": 29.521841049194336, "_runtime": 21485.16233563423, "_timestamp": 1585618854.795205, "_step": 388}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 0.6155745387077332, "Value Loss": 16.126605987548828, "_runtime": 21486.74941778183, "_timestamp": 1585618856.3822873, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0638786554336548, "Value Loss": 0.023072408512234688, "_runtime": 21488.24783682823, "_timestamp": 1585618857.8807063, "_step": 390}
{"Episode reward": 5.4000000000011, "Episode length": 946, "Policy Loss": -0.12077005952596664, "Value Loss": 9.908626556396484, "_runtime": 21489.815866708755, "_timestamp": 1585618859.4487362, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0886162519454956, "Value Loss": 0.032983362674713135, "_runtime": 21491.4258787632, "_timestamp": 1585618861.0587482, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0799435377120972, "Value Loss": 0.018365906551480293, "_runtime": 21492.694801568985, "_timestamp": 1585618862.327671, "_step": 393}
{"Episode reward": 19.80000000000028, "Episode length": 802, "Policy Loss": 0.009835673496127129, "Value Loss": 11.70889663696289, "_runtime": 21494.28685426712, "_timestamp": 1585618863.9197237, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0679091215133667, "Value Loss": 0.03532110154628754, "_runtime": 21495.88037919998, "_timestamp": 1585618865.5132487, "_step": 395}
{"Episode reward": -99.81595315933087, "Episode length": 999, "Policy Loss": -1.0680086612701416, "Value Loss": 0.030277937650680542, "_runtime": 21497.016689777374, "_timestamp": 1585618866.6495593, "_step": 396}
{"Episode reward": 28.299999999999798, "Episode length": 717, "Policy Loss": 0.02284546196460724, "Value Loss": 12.74448013305664, "_runtime": 21497.41756606102, "_timestamp": 1585618867.0504355, "_step": 397}
{"Episode reward": 78.09999999999997, "Episode length": 219, "Policy Loss": 2.6639647483825684, "Value Loss": 41.38999557495117, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258, 0.0003399299457669258]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.059922609478235245, -0.010932181030511856, 0.03805824741721153, 0.08704867959022522, 0.1360391080379486, 0.185029536485672, 0.23401996493339539, 0.2830103933811188, 0.33200082182884216, 0.38099125027656555, 0.42998167872428894, 0.47897210717201233, 0.5279625058174133, 0.5769529342651367, 0.6259433627128601, 0.6749337911605835, 0.7239242196083069, 0.7729146480560303, 0.8219050765037537, 0.870895504951477, 0.9198859333992004, 0.9688764214515686, 1.017866849899292, 1.0668572187423706, 1.1158477067947388, 1.164838194847107, 1.2138285636901855, 1.2628189325332642, 1.3118094205856323, 1.3607999086380005, 1.409790277481079, 1.4587806463241577, 1.5077711343765259, 1.556761622428894, 1.6057519912719727, 1.6547423601150513, 1.7037328481674194, 1.7527233362197876, 1.8017137050628662, 1.8507040739059448, 1.899694561958313, 1.9486850500106812, 1.9976755380630493, 2.046665668487549, 2.095656156539917, 2.144646644592285, 2.193636894226074, 2.2426273822784424, 2.2916178703308105, 2.3406083583831787, 2.389598846435547, 2.438589096069336, 2.487579584121704, 2.5365700721740723, 2.5855603218078613, 2.6345508098602295, 2.6835412979125977, 2.732531785964966, 2.781522274017334, 2.830512523651123, 2.879503011703491, 2.9284934997558594, 2.9774837493896484, 3.0264742374420166, 3.0754647254943848]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 1.0, 3.0, 2.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0012254486791789532, -0.0003130519762635231, 0.000599344726651907, 0.001511741429567337, 0.002424138132482767, 0.003336534835398197, 0.004248931538313627, 0.005161328241229057, 0.006073724944144487, 0.00698612118139863, 0.007898518815636635, 0.008810915052890778, 0.00972331129014492, 0.010635707527399063, 0.011548105627298355, 0.012460501864552498, 0.01337289810180664, 0.014285294339060783, 0.015197690576314926, 0.016110088676214218, 0.01702248491346836, 0.017934881150722504, 0.018847279250621796, 0.01975967548787594, 0.02067207172513008, 0.021584467962384224, 0.022496864199638367, 0.02340926229953766, 0.0243216585367918, 0.025234054774045944, 0.026146452873945236, 0.02705884911119938, 0.02797124534845352, 0.028883641585707664, 0.029796037822961807, 0.0307084359228611, 0.03162083029747009, 0.032533228397369385, 0.03344562649726868, 0.03435802087187767, 0.03527041897177696, 0.036182817071676254, 0.03709521144628525, 0.03800760954618454, 0.03892000764608383, 0.039832402020692825, 0.04074480012059212, 0.04165719449520111, 0.0425695925951004, 0.043481990694999695, 0.04439438506960869, 0.04530678316950798, 0.046219177544116974, 0.047131575644016266, 0.04804397374391556, 0.04895636811852455, 0.04986876621842384, 0.050781164318323135, 0.05169355869293213, 0.05260595679283142, 0.05351835489273071, 0.054430749267339706, 0.055343147367239, 0.05625554174184799, 0.057167939841747284]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 4.0, 18.0, 29.0, 48.0, 170.0, 100.0, 15.0, 1.0, 14.0, 20.0, 1.0, 6.0, 9.0, 12.0, 4.0, 4.0, 4.0, 2.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0], "bins": [-0.07235530763864517, -0.06537144631147385, -0.05838759243488312, -0.05140373110771179, -0.04441987723112106, -0.03743601590394974, -0.03045215830206871, -0.023468300700187683, -0.016484443098306656, -0.009500585496425629, -0.002516724169254303, 0.004467129707336426, 0.011450991034507751, 0.01843484491109848, 0.025418706238269806, 0.032402560114860535, 0.03938642144203186, 0.046370282769203186, 0.053354136645793915, 0.06033799797296524, 0.06732185930013657, 0.0743057057261467, 0.08128956705331802, 0.08827342838048935, 0.09525728970766068, 0.102241151034832, 0.10922499746084213, 0.11620885878801346, 0.12319272011518478, 0.1301765739917755, 0.13716042041778564, 0.14414429664611816, 0.1511281430721283, 0.15811201930046082, 0.16509586572647095, 0.17207971215248108, 0.1790635883808136, 0.18604743480682373, 0.19303131103515625, 0.20001515746116638, 0.2069990336894989, 0.21398288011550903, 0.22096672654151917, 0.22795060276985168, 0.23493444919586182, 0.24191832542419434, 0.24890217185020447, 0.2558860182762146, 0.2628698945045471, 0.26985374093055725, 0.27683761715888977, 0.2838214635848999, 0.29080531001091003, 0.29778918623924255, 0.3047730326652527, 0.3117568790912628, 0.31874075531959534, 0.32572460174560547, 0.332708477973938, 0.3396923243999481, 0.34667617082595825, 0.35366004705429077, 0.3606438934803009, 0.3676277697086334, 0.37461161613464355]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.4926392436027527, -0.4761166572570801, -0.45959407091140747, -0.44307148456573486, -0.42654889822006226, -0.41002631187438965, -0.39350372552871704, -0.37698113918304443, -0.3604585528373718, -0.3439359664916992, -0.3274133801460266, -0.310890793800354, -0.2943682074546814, -0.2778456211090088, -0.2613230347633362, -0.24480044841766357, -0.22827786207199097, -0.21175527572631836, -0.19523268938064575, -0.17871010303497314, -0.16218751668930054, -0.14566493034362793, -0.12914234399795532, -0.11261975765228271, -0.09609717130661011, -0.0795745849609375, -0.06305199861526489, -0.046529412269592285, -0.030006825923919678, -0.01348423957824707, 0.003038346767425537, 0.019560933113098145, 0.03608351945877075, 0.05260610580444336, 0.06912869215011597, 0.08565127849578857, 0.10217386484146118, 0.11869645118713379, 0.1352190375328064, 0.151741623878479, 0.1682642102241516, 0.18478679656982422, 0.20130938291549683, 0.21783196926116943, 0.23435455560684204, 0.25087714195251465, 0.26739972829818726, 0.28392231464385986, 0.30044490098953247, 0.3169674873352051, 0.3334900736808777, 0.3500126600265503, 0.3665352463722229, 0.3830578327178955, 0.3995804190635681, 0.4161030054092407, 0.43262559175491333, 0.44914817810058594, 0.46567076444625854, 0.48219335079193115, 0.49871593713760376, 0.5152385830879211, 0.531761109828949, 0.5482836365699768, 0.5648062825202942]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 6.0, 8.0, 9.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], "bins": [-0.5766928791999817, -0.5626198649406433, -0.5485468506813049, -0.5344738364219666, -0.5204008221626282, -0.5063278079032898, -0.4922548234462738, -0.4781818091869354, -0.46410879492759705, -0.45003578066825867, -0.4359627664089203, -0.4218897819519043, -0.4078167676925659, -0.39374375343322754, -0.37967073917388916, -0.3655977249145508, -0.3515247106552124, -0.337451696395874, -0.32337868213653564, -0.30930566787719727, -0.2952326536178589, -0.2811596691608429, -0.2670866549015045, -0.25301364064216614, -0.23894062638282776, -0.22486761212348938, -0.210794597864151, -0.19672158360481262, -0.18264859914779663, -0.16857558488845825, -0.15450257062911987, -0.1404295563697815, -0.12635654211044312, -0.11228352785110474, -0.09821051359176636, -0.08413749933242798, -0.0700644850730896, -0.05599147081375122, -0.04191845655441284, -0.027845442295074463, -0.013772428035736084, 0.00030052661895751953, 0.014373540878295898, 0.028446555137634277, 0.042519569396972656, 0.056592583656311035, 0.07066559791564941, 0.08473861217498779, 0.09881162643432617, 0.11288464069366455, 0.12695765495300293, 0.1410306692123413, 0.1551036834716797, 0.16917669773101807, 0.18324971199035645, 0.19732272624969482, 0.21139568090438843, 0.2254686951637268, 0.23954170942306519, 0.25361472368240356, 0.26768773794174194, 0.2817607522010803, 0.2958337664604187, 0.3099067807197571, 0.32397979497909546]}, "_runtime": 21498.40128016472, "_timestamp": 1585618868.0341496, "_step": 398}
{"Episode reward": 38.79999999999941, "Episode length": 612, "Policy Loss": 0.22206081449985504, "Value Loss": 14.847930908203125, "_runtime": 21499.28463768959, "_timestamp": 1585618868.9175072, "_step": 399}
{"Episode reward": 44.199999999999484, "Episode length": 558, "Policy Loss": 0.2636585235595703, "Value Loss": 16.6758975982666, "_runtime": 21500.81915998459, "_timestamp": 1585618870.4520295, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0791535377502441, "Value Loss": 0.03544779121875763, "_runtime": 21502.38908982277, "_timestamp": 1585618872.0219593, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.136553406715393, "Value Loss": 0.21193435788154602, "_runtime": 21502.644816875458, "_timestamp": 1585618872.2776864, "_step": 402}
{"Episode reward": 85.80000000000004, "Episode length": 142, "Policy Loss": 5.221913814544678, "Value Loss": 63.42422866821289, "_runtime": 21504.148993253708, "_timestamp": 1585618873.7818627, "_step": 403}
{"Episode reward": 3.800000000001191, "Episode length": 962, "Policy Loss": -0.1418880671262741, "Value Loss": 9.239200592041016, "_runtime": 21505.73344373703, "_timestamp": 1585618875.3663132, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2201396226882935, "Value Loss": 0.27549710869789124, "_runtime": 21507.24725484848, "_timestamp": 1585618876.8801243, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1423661708831787, "Value Loss": 0.06555356830358505, "_runtime": 21508.565979242325, "_timestamp": 1585618878.1988487, "_step": 406}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": -0.3166142702102661, "Value Loss": 11.72385311126709, "_runtime": 21510.15500974655, "_timestamp": 1585618879.7878792, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1739188432693481, "Value Loss": 0.07030069082975388, "_runtime": 21510.772662878036, "_timestamp": 1585618880.4055324, "_step": 408}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 0.9626335501670837, "Value Loss": 22.882375717163086, "_runtime": 21512.37357854843, "_timestamp": 1585618882.006448, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.173494577407837, "Value Loss": 0.10544130206108093, "_runtime": 21513.976989507675, "_timestamp": 1585618883.609859, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2183207273483276, "Value Loss": 0.07359330356121063, "_runtime": 21515.51002264023, "_timestamp": 1585618885.1428921, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.206161618232727, "Value Loss": 0.045387767255306244, "_runtime": 21517.10176706314, "_timestamp": 1585618886.7346365, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1447771787643433, "Value Loss": 0.08642144501209259, "_runtime": 21518.486634731293, "_timestamp": 1585618888.1195042, "_step": 413}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": -0.37678492069244385, "Value Loss": 11.295433044433594, "_runtime": 21520.052693605423, "_timestamp": 1585618889.685563, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.123160481452942, "Value Loss": 0.09670835733413696, "_runtime": 21521.495282888412, "_timestamp": 1585618891.1281524, "_step": 415}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": -0.26557374000549316, "Value Loss": 10.003850936889648, "_runtime": 21522.744582891464, "_timestamp": 1585618892.3774524, "_step": 416}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": -0.14368857443332672, "Value Loss": 10.929337501525879, "_runtime": 21524.02761244774, "_timestamp": 1585618893.660482, "_step": 417}
{"Episode reward": 18.40000000000036, "Episode length": 816, "Policy Loss": -0.1870575100183487, "Value Loss": 11.015922546386719, "_runtime": 21525.2833237648, "_timestamp": 1585618894.9161932, "_step": 418}
{"Episode reward": 20.90000000000022, "Episode length": 791, "Policy Loss": -0.17484550178050995, "Value Loss": 11.00376033782959, "_runtime": 21526.415177106857, "_timestamp": 1585618896.0480466, "_step": 419}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": -0.024362929165363312, "Value Loss": 13.062541007995605, "_runtime": 21527.659076213837, "_timestamp": 1585618897.2919457, "_step": 420}
{"Episode reward": 20.50000000000024, "Episode length": 795, "Policy Loss": -0.14520539343357086, "Value Loss": 11.356117248535156, "_runtime": 21528.822459220886, "_timestamp": 1585618898.4553287, "_step": 421}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": -0.18597649037837982, "Value Loss": 12.35732650756836, "_runtime": 21530.389161109924, "_timestamp": 1585618900.0220306, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2261821031570435, "Value Loss": 0.057720594108104706, "_runtime": 21531.07207918167, "_timestamp": 1585618900.7049487, "_step": 423}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 0.26138433814048767, "Value Loss": 23.55950927734375, "_runtime": 21532.31289768219, "_timestamp": 1585618901.9457672, "_step": 424}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": -0.14365136623382568, "Value Loss": 11.30611515045166, "_runtime": 21533.901809453964, "_timestamp": 1585618903.534679, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.212598204612732, "Value Loss": 0.030817534774541855, "_runtime": 21535.481303453445, "_timestamp": 1585618905.114173, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1419991254806519, "Value Loss": 0.14246129989624023, "_runtime": 21537.05394601822, "_timestamp": 1585618906.6868155, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1530394554138184, "Value Loss": 0.08658121526241302, "_runtime": 21538.634743452072, "_timestamp": 1585618908.267613, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1610580682754517, "Value Loss": 0.0516618974506855, "_runtime": 21539.340962171555, "_timestamp": 1585618908.9738317, "_step": 429}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": 0.8607694506645203, "Value Loss": 19.789226531982422, "_runtime": 21540.322492599487, "_timestamp": 1585618909.955362, "_step": 430}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.042744141072034836, "Value Loss": 14.997612953186035, "_runtime": 21541.91071009636, "_timestamp": 1585618911.5435796, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1228200197219849, "Value Loss": 0.05055888742208481, "_runtime": 21543.443074941635, "_timestamp": 1585618913.0759444, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.103782296180725, "Value Loss": 0.030531056225299835, "_runtime": 21545.010716199875, "_timestamp": 1585618914.6435857, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0901012420654297, "Value Loss": 0.06365431100130081, "_runtime": 21546.595594882965, "_timestamp": 1585618916.2284644, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0775508880615234, "Value Loss": 0.08047392219305038, "_runtime": 21548.16451382637, "_timestamp": 1585618917.7973833, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.084431767463684, "Value Loss": 0.040517453104257584, "_runtime": 21549.738709688187, "_timestamp": 1585618919.3715792, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.037388563156128, "Value Loss": 0.05618537589907646, "_runtime": 21551.215080738068, "_timestamp": 1585618920.8479502, "_step": 437}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": -0.5522180795669556, "Value Loss": 11.869728088378906, "_runtime": 21552.796824216843, "_timestamp": 1585618922.4296937, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9920834302902222, "Value Loss": 0.06300412863492966, "_runtime": 21553.806735277176, "_timestamp": 1585618923.4396048, "_step": 439}
{"Episode reward": 37.199999999999385, "Episode length": 628, "Policy Loss": -0.10152973234653473, "Value Loss": 15.835907936096191, "_runtime": 21555.38433265686, "_timestamp": 1585618925.0172021, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.843590497970581, "Value Loss": 0.07807451486587524, "_runtime": 21556.974572896957, "_timestamp": 1585618926.6074424, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8800962567329407, "Value Loss": 0.053977787494659424, "_runtime": 21558.528943777084, "_timestamp": 1585618928.1618133, "_step": 442}
{"Episode reward": -99.85348336845497, "Episode length": 999, "Policy Loss": -0.854395866394043, "Value Loss": 0.026143210008740425, "_runtime": 21560.156554222107, "_timestamp": 1585618929.7894237, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8105694651603699, "Value Loss": 0.0354328490793705, "_runtime": 21560.97350692749, "_timestamp": 1585618930.6063764, "_step": 444}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 0.864729642868042, "Value Loss": 17.07843017578125, "_runtime": 21562.554631233215, "_timestamp": 1585618932.1875007, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.766267716884613, "Value Loss": 0.0687548965215683, "_runtime": 21564.153007030487, "_timestamp": 1585618933.7858765, "_step": 446}
{"Episode reward": -99.80253381728987, "Episode length": 999, "Policy Loss": -0.6826414465904236, "Value Loss": 0.08632034808397293, "_runtime": 21565.69700217247, "_timestamp": 1585618935.3298717, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6635027527809143, "Value Loss": 0.07259590923786163, "_runtime": 21567.284041643143, "_timestamp": 1585618936.9169111, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6563338041305542, "Value Loss": 0.09989534318447113, "_runtime": 21568.880697965622, "_timestamp": 1585618938.5135674, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6239646673202515, "Value Loss": 0.09321456402540207, "_runtime": 21569.773292541504, "_timestamp": 1585618939.406162, "_step": 450}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.8638855814933777, "Value Loss": 16.35038948059082, "_runtime": 21570.88821554184, "_timestamp": 1585618940.521085, "_step": 451}
{"Episode reward": 29.799999999999713, "Episode length": 702, "Policy Loss": 0.7736898064613342, "Value Loss": 12.814516067504883, "_runtime": 21572.48126387596, "_timestamp": 1585618942.1141334, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6583982706069946, "Value Loss": 0.06236349418759346, "_runtime": 21574.029319524765, "_timestamp": 1585618943.662189, "_step": 453}
{"Episode reward": -99.80476381778577, "Episode length": 999, "Policy Loss": -0.6352481245994568, "Value Loss": 0.03306947648525238, "_runtime": 21575.521126270294, "_timestamp": 1585618945.1539958, "_step": 454}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": 0.3239249289035797, "Value Loss": 9.590331077575684, "_runtime": 21577.108001708984, "_timestamp": 1585618946.7408712, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6587820649147034, "Value Loss": 0.01989012397825718, "_runtime": 21578.680071115494, "_timestamp": 1585618948.3129406, "_step": 456}
{"Episode reward": -99.85515673160414, "Episode length": 999, "Policy Loss": -0.6775236129760742, "Value Loss": 0.02411271072924137, "_runtime": 21580.26880288124, "_timestamp": 1585618949.9016724, "_step": 457}
{"Episode reward": -99.80041071325401, "Episode length": 999, "Policy Loss": -0.6715523600578308, "Value Loss": 0.050661906599998474, "_runtime": 21581.214787483215, "_timestamp": 1585618950.847657, "_step": 458}
{"Episode reward": 41.99999999999945, "Episode length": 580, "Policy Loss": 0.2768939733505249, "Value Loss": 15.89015007019043, "_runtime": 21581.94727563858, "_timestamp": 1585618951.5801451, "_step": 459}
{"Episode reward": 55.499999999999645, "Episode length": 445, "Policy Loss": 1.0066978931427002, "Value Loss": 20.928865432739258, "_runtime": 21583.585005283356, "_timestamp": 1585618953.2178748, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6637911200523376, "Value Loss": 0.09412425011396408, "_runtime": 21585.165130376816, "_timestamp": 1585618954.7979999, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6181343793869019, "Value Loss": 0.012764827348291874, "_runtime": 21586.71397948265, "_timestamp": 1585618956.346849, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.621408998966217, "Value Loss": 0.065925233066082, "_runtime": 21588.30816435814, "_timestamp": 1585618957.9410338, "_step": 463}
{"Episode reward": -99.80145493598981, "Episode length": 999, "Policy Loss": -0.6566094756126404, "Value Loss": 0.15347804129123688, "_runtime": 21589.894526958466, "_timestamp": 1585618959.5273964, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5524070858955383, "Value Loss": 0.0333072803914547, "_runtime": 21591.47565460205, "_timestamp": 1585618961.108524, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5546146035194397, "Value Loss": 0.015132216736674309, "_runtime": 21592.180842876434, "_timestamp": 1585618961.8137124, "_step": 466}
{"Episode reward": 57.699999999999676, "Episode length": 423, "Policy Loss": 1.334905982017517, "Value Loss": 21.799291610717773, "_runtime": 21593.773894548416, "_timestamp": 1585618963.406764, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5333433151245117, "Value Loss": 0.013837946578860283, "_runtime": 21594.62898349762, "_timestamp": 1585618964.261853, "_step": 468}
{"Episode reward": 47.699999999999534, "Episode length": 523, "Policy Loss": 1.1090365648269653, "Value Loss": 17.08712387084961, "_runtime": 21596.02246570587, "_timestamp": 1585618965.6553352, "_step": 469}
{"Episode reward": 9.500000000000867, "Episode length": 905, "Policy Loss": 0.4185806214809418, "Value Loss": 9.412068367004395, "_runtime": 21597.630407094955, "_timestamp": 1585618967.2632766, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5078285932540894, "Value Loss": 0.05280705541372299, "_runtime": 21599.193568706512, "_timestamp": 1585618968.8264382, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5468406677246094, "Value Loss": 0.017903819680213928, "_runtime": 21600.78121113777, "_timestamp": 1585618970.4140806, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4609532058238983, "Value Loss": 0.07621535658836365, "_runtime": 21601.70389866829, "_timestamp": 1585618971.3367682, "_step": 473}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 0.41024211049079895, "Value Loss": 17.740550994873047, "_runtime": 21603.300895929337, "_timestamp": 1585618972.9337654, "_step": 474}
{"Episode reward": -99.80481189638236, "Episode length": 999, "Policy Loss": -0.5008108615875244, "Value Loss": 0.07342982292175293, "_runtime": 21604.90687274933, "_timestamp": 1585618974.5397422, "_step": 475}
{"Episode reward": -99.84188895821431, "Episode length": 999, "Policy Loss": -0.4726663827896118, "Value Loss": 0.08711206167936325, "_runtime": 21605.28437113762, "_timestamp": 1585618974.9172406, "_step": 476}
{"Episode reward": 78.38258119672534, "Episode length": 217, "Policy Loss": 3.3357901573181152, "Value Loss": 43.46931076049805, "_runtime": 21606.89043521881, "_timestamp": 1585618976.5233047, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49288031458854675, "Value Loss": 0.053063489496707916, "_runtime": 21608.534645795822, "_timestamp": 1585618978.1675153, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5336956977844238, "Value Loss": 0.015833113342523575, "_runtime": 21608.91333270073, "_timestamp": 1585618978.5462022, "_step": 479}
{"Episode reward": 76.49999999999994, "Episode length": 235, "Policy Loss": 2.8089559078216553, "Value Loss": 39.59366226196289, "_runtime": 21610.507570028305, "_timestamp": 1585618980.1404395, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5224753618240356, "Value Loss": 0.05750487744808197, "_runtime": 21612.09902405739, "_timestamp": 1585618981.7318935, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5415534377098083, "Value Loss": 0.055289965122938156, "_runtime": 21613.57476735115, "_timestamp": 1585618983.2076368, "_step": 482}
{"Episode reward": 3.294449466468123, "Episode length": 968, "Policy Loss": 0.33258071541786194, "Value Loss": 8.62777042388916, "_runtime": 21615.174523115158, "_timestamp": 1585618984.8073926, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5692587494850159, "Value Loss": 0.038347162306308746, "_runtime": 21616.531891584396, "_timestamp": 1585618986.164761, "_step": 484}
{"Episode reward": 14.700000000000571, "Episode length": 853, "Policy Loss": 0.37353387475013733, "Value Loss": 10.617328643798828, "_runtime": 21618.098430871964, "_timestamp": 1585618987.7313004, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5929571390151978, "Value Loss": 0.03351535275578499, "_runtime": 21619.71180653572, "_timestamp": 1585618989.344676, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6314303874969482, "Value Loss": 0.017352527007460594, "_runtime": 21621.297924041748, "_timestamp": 1585618990.9307935, "_step": 487}
{"Episode reward": -99.8848053932176, "Episode length": 999, "Policy Loss": -0.6251638531684875, "Value Loss": 0.018912512809038162, "_runtime": 21622.875742435455, "_timestamp": 1585618992.508612, "_step": 488}
{"Episode reward": -99.82201845645766, "Episode length": 999, "Policy Loss": -0.6270714998245239, "Value Loss": 0.02879912592470646, "_runtime": 21623.7303917408, "_timestamp": 1585618993.3632612, "_step": 489}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 0.9426511526107788, "Value Loss": 16.635391235351562, "_runtime": 21625.331159114838, "_timestamp": 1585618994.9640286, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6529225707054138, "Value Loss": 0.024413831532001495, "_runtime": 21626.923365831375, "_timestamp": 1585618996.5562353, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6611953973770142, "Value Loss": 0.016442114487290382, "_runtime": 21628.474533319473, "_timestamp": 1585618998.1074028, "_step": 492}
{"Episode reward": -99.84599859714368, "Episode length": 999, "Policy Loss": -0.6688029170036316, "Value Loss": 0.023685229942202568, "_runtime": 21629.71296286583, "_timestamp": 1585618999.3458323, "_step": 493}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.5660037994384766, "Value Loss": 11.779563903808594, "_runtime": 21630.793946266174, "_timestamp": 1585619000.4268157, "_step": 494}
{"Episode reward": 32.79999999999954, "Episode length": 672, "Policy Loss": 0.5410631895065308, "Value Loss": 13.301655769348145, "_runtime": 21632.428863048553, "_timestamp": 1585619002.0617325, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6656396389007568, "Value Loss": 0.02591622807085514, "_runtime": 21634.004390716553, "_timestamp": 1585619003.6372602, "_step": 496}
{"Episode reward": -99.81808741092541, "Episode length": 999, "Policy Loss": -0.7512544393539429, "Value Loss": 0.245197132229805, "_runtime": 21635.01981973648, "_timestamp": 1585619004.6526892, "_step": 497}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.6330751776695251, "Value Loss": 14.092430114746094, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047, -0.00023327101371251047]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], "bins": [-0.1999180018901825, -0.1967906355857849, -0.19366326928138733, -0.19053590297698975, -0.18740855157375336, -0.18428118526935577, -0.1811538189649582, -0.1780264526605606, -0.17489908635616302, -0.17177173495292664, -0.16864436864852905, -0.16551700234413147, -0.1623896360397339, -0.1592622697353363, -0.15613490343093872, -0.15300753712654114, -0.14988018572330475, -0.14675281941890717, -0.14362545311450958, -0.140498086810112, -0.1373707354068756, -0.13424336910247803, -0.13111600279808044, -0.12798863649368286, -0.12486127018928528, -0.12173391133546829, -0.11860654503107071, -0.11547917872667313, -0.11235181987285614, -0.10922445356845856, -0.10609708726406097, -0.10296972841024399, -0.0998423621058464, -0.09671499580144882, -0.09358763694763184, -0.09046027064323425, -0.08733290433883667, -0.08420554548501968, -0.0810781791806221, -0.07795081287622452, -0.07482345402240753, -0.07169608771800995, -0.06856872141361237, -0.06544135510921478, -0.062314003705978394, -0.05918663740158081, -0.05605927109718323, -0.052931904792785645, -0.04980453848838806, -0.04667717218399048, -0.04354982078075409, -0.040422454476356506, -0.03729508817195892, -0.03416772186756134, -0.031040355563163757, -0.027912989258766174, -0.024785637855529785, -0.021658271551132202, -0.01853090524673462, -0.015403538942337036, -0.012276172637939453, -0.00914880633354187, -0.006021454930305481, -0.002894088625907898, 0.00023327767848968506]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0013158468063920736, -0.0012904376490041614, -0.001265028491616249, -0.0012396193342283368, -0.0012142101768404245, -0.0011888010194525123, -0.0011633918620646, -0.0011379827046766877, -0.0011125735472887754, -0.0010871643899008632, -0.001061755232512951, -0.0010363460751250386, -0.0010109369177371264, -0.000985527876764536, -0.0009601186611689627, -0.0009347095037810504, -0.0009093003463931382, -0.0008838911890052259, -0.0008584820316173136, -0.0008330728742294014, -0.0008076637168414891, -0.0007822545594535768, -0.0007568454020656645, -0.0007314362446777523, -0.0007060271454975009, -0.0006806179881095886, -0.0006552088307216763, -0.0006297996733337641, -0.0006043905159458518, -0.0005789813585579395, -0.0005535722011700273, -0.000528163043782115, -0.0005027538863942027, -0.00047734472900629044, -0.00045193557161837816, -0.0004265264142304659, -0.0004011172568425536, -0.00037570809945464134, -0.00035029894206672907, -0.0003248897846788168, -0.0002994806272909045, -0.00027407146990299225, -0.00024866231251508, -0.0002232531551271677, -0.00019784399773925543, -0.00017243484035134315, -0.00014702568296343088, -0.00012161652557551861, -9.620748460292816e-05, -7.079832721501589e-05, -4.5389169827103615e-05, -1.998001243919134e-05, 5.429144948720932e-06, 3.0838302336633205e-05, 5.624745972454548e-05, 8.165661711245775e-05, 0.00010706577450037003, 0.0001324749318882823, 0.00015788408927619457, 0.00018329324666410685, 0.00020870240405201912, 0.0002341115614399314, 0.00025952071882784367, 0.00028492987621575594, 0.0003103390336036682]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 5.0, 7.0, 7.0, 5.0, 3.0, 6.0, 9.0, 13.0, 6.0, 11.0, 3.0, 4.0, 6.0, 14.0, 40.0, 204.0, 22.0, 19.0, 34.0, 25.0, 20.0, 14.0, 4.0, 0.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0], "bins": [-0.034840263426303864, -0.03412455692887306, -0.03340884670615196, -0.03269314020872116, -0.03197742998600006, -0.03126172348856926, -0.03054601326584816, -0.02983030676841736, -0.02911459654569626, -0.028398890048265457, -0.027683179825544357, -0.026967473328113556, -0.026251764968037605, -0.025536056607961655, -0.024820348247885704, -0.024104639887809753, -0.023388931527733803, -0.022673223167657852, -0.0219575148075819, -0.02124180644750595, -0.02052609808743, -0.01981038972735405, -0.0190946813672781, -0.01837897300720215, -0.017663266509771347, -0.016947558149695396, -0.016231849789619446, -0.015516141429543495, -0.014800433069467545, -0.014084724709391594, -0.013369016349315643, -0.012653307989239693, -0.011937599629163742, -0.011221891269087791, -0.01050618290901184, -0.00979047454893589, -0.00907476618885994, -0.008359057828783989, -0.007643349468708038, -0.006927641108632088, -0.006211932748556137, -0.005496226251125336, -0.004780517891049385, -0.0040648095309734344, -0.0033490993082523346, -0.002633392810821533, -0.0019176825881004333, -0.001201976090669632, -0.00048626959323883057, 0.0002294406294822693, 0.0009451471269130707, 0.0016608573496341705, 0.002376563847064972, 0.0030922740697860718, 0.003807980567216873, 0.004523690789937973, 0.005239397287368774, 0.005955107510089874, 0.006670814007520676, 0.0073865242302417755, 0.008102230727672577, 0.008817940950393677, 0.009533647447824478, 0.010249357670545578, 0.01096506416797638]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.017122918739914894, -0.01635691709816456, -0.015590915456414223, -0.014824913814663887, -0.014058912172913551, -0.013292910531163216, -0.01252690888941288, -0.011760907247662544, -0.010994905605912209, -0.010228903964161873, -0.009462902322411537, -0.008696900680661201, -0.007930899038910866, -0.00716489739716053, -0.006398895755410194, -0.005632894113659859, -0.004866892471909523, -0.004100890830159187, -0.0033348891884088516, -0.002568887546658516, -0.0018028859049081802, -0.0010368842631578445, -0.00027088262140750885, 0.0004951190203428268, 0.0012611206620931625, 0.0020271223038434982, 0.002793123945593834, 0.0035591255873441696, 0.004325127229094505, 0.005091128870844841, 0.005857130512595177, 0.006623132154345512, 0.007389133796095848, 0.008155135437846184, 0.00892113707959652, 0.009687138721346855, 0.01045314036309719, 0.011219142004847527, 0.011985143646597862, 0.012751145288348198, 0.013517146930098534, 0.01428314857184887, 0.015049150213599205, 0.01581515185534954, 0.016581153497099876, 0.017347155138850212, 0.018113156780600548, 0.018879158422350883, 0.01964516006410122, 0.020411161705851555, 0.02117716334760189, 0.021943164989352226, 0.022709166631102562, 0.023475168272852898, 0.024241169914603233, 0.02500717155635357, 0.025773173198103905, 0.02653917483985424, 0.027305176481604576, 0.028071178123354912, 0.028837179765105247, 0.029603181406855583, 0.03036918304860592, 0.031135184690356255, 0.03190118819475174]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 6.0, 4.0, 7.0, 1.0, 3.0, 6.0, 10.0, 6.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04474155232310295, -0.04383924975991249, -0.04293694347143173, -0.04203464090824127, -0.04113233461976051, -0.04023003205657005, -0.03932772949337959, -0.038425423204898834, -0.037523120641708374, -0.036620818078517914, -0.035718511790037155, -0.034816209226846695, -0.033913902938365936, -0.033011600375175476, -0.032109297811985016, -0.031206991523504257, -0.030304688960313797, -0.02940238267183304, -0.028500080108642578, -0.02759777568280697, -0.02669547125697136, -0.0257931686937809, -0.02489086426794529, -0.02398855984210968, -0.02308625541627407, -0.02218395099043846, -0.021281648427248, -0.02037934400141239, -0.019477039575576782, -0.018574735149741173, -0.017672432586550713, -0.016770128160715103, -0.015867823734879494, -0.014965519309043884, -0.014063214883208275, -0.013160910457372665, -0.012258607894182205, -0.011356305330991745, -0.010453999042510986, -0.009551696479320526, -0.008649390190839767, -0.007747087627649307, -0.006844785064458847, -0.005942478775978088, -0.005040176212787628, -0.0041378699243068695, -0.0032355673611164093, -0.002333264797925949, -0.0014309585094451904, -0.0005286559462547302, 0.00037365034222602844, 0.0012759529054164886, 0.002178255468606949, 0.0030805617570877075, 0.003982864320278168, 0.004885166883468628, 0.005787473171949387, 0.006689775735139847, 0.0075920820236206055, 0.008494384586811066, 0.009396687150001526, 0.010298993438482285, 0.011201296001672745, 0.012103602290153503, 0.013005904853343964]}, "_runtime": 21636.608105897903, "_timestamp": 1585619006.2409754, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7201483249664307, "Value Loss": 0.019814373925328255, "_runtime": 21636.608105897903, "_timestamp": 1585619006.2409754, "_step": 499}
