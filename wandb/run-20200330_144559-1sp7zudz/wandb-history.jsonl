{"Episode reward": 57.186375695540065, "Episode length": 663, "Policy Loss": 0.2760975658893585, "Value Loss": 15.074787139892578, "_runtime": 9657.161812782288, "_timestamp": 1585579573.0064461, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.557564735412598, "Value Loss": 265.11846923828125, "_runtime": 9658.671327829361, "_timestamp": 1585579574.5159612, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6845929622650146, "Value Loss": 60.62278366088867, "_runtime": 9660.236503839493, "_timestamp": 1585579576.0811372, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8059756755828857, "Value Loss": 4103.2236328125, "_runtime": 9661.791512489319, "_timestamp": 1585579577.6361458, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.544436454772949, "Value Loss": 1070.1168212890625, "_runtime": 9663.384185552597, "_timestamp": 1585579579.228819, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0862619876861572, "Value Loss": 253.0145263671875, "_runtime": 9664.967962265015, "_timestamp": 1585579580.8125956, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0359551906585693, "Value Loss": 35.7384147644043, "_runtime": 9666.545157432556, "_timestamp": 1585579582.3897908, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7170872688293457, "Value Loss": 26.437349319458008, "_runtime": 9668.096747159958, "_timestamp": 1585579583.9413805, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8236162662506104, "Value Loss": 41.26694869995117, "_runtime": 9669.686317920685, "_timestamp": 1585579585.5309513, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.919821858406067, "Value Loss": 31.392065048217773, "_runtime": 9671.27765750885, "_timestamp": 1585579587.1222908, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5430645942687988, "Value Loss": 46.25282669067383, "_runtime": 9672.838856220245, "_timestamp": 1585579588.6834896, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.799146056175232, "Value Loss": 328.2384033203125, "_runtime": 9674.434537172318, "_timestamp": 1585579590.2791705, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.245180606842041, "Value Loss": 74.01254272460938, "_runtime": 9676.019970417023, "_timestamp": 1585579591.8646038, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.083948135375977, "Value Loss": 1648.172607421875, "_runtime": 9677.601039648056, "_timestamp": 1585579593.445673, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 15.687244415283203, "Value Loss": 148.40032958984375, "_runtime": 9679.203428983688, "_timestamp": 1585579595.0480623, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.340616226196289, "Value Loss": 567.2392578125, "_runtime": 9680.801483869553, "_timestamp": 1585579596.6461172, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 14.597660064697266, "Value Loss": 71.41596221923828, "_runtime": 9682.382732391357, "_timestamp": 1585579598.2273657, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.20958423614502, "Value Loss": 4.729190826416016, "_runtime": 9683.977117300034, "_timestamp": 1585579599.8217506, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.451430320739746, "Value Loss": 618.0653076171875, "_runtime": 9685.602778434753, "_timestamp": 1585579601.4474118, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.632710933685303, "Value Loss": 39.54013442993164, "_runtime": 9687.178144216537, "_timestamp": 1585579603.0227776, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5951109528541565, "Value Loss": 97.32540130615234, "_runtime": 9688.770494699478, "_timestamp": 1585579604.615128, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.910750150680542, "Value Loss": 81.34490203857422, "_runtime": 9690.358438968658, "_timestamp": 1585579606.2030723, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.594305515289307, "Value Loss": 137.76580810546875, "_runtime": 9691.95252752304, "_timestamp": 1585579607.7971609, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.030961036682129, "Value Loss": 129.57510375976562, "_runtime": 9693.544905424118, "_timestamp": 1585579609.3895388, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.156754970550537, "Value Loss": 6.615241050720215, "_runtime": 9695.134125232697, "_timestamp": 1585579610.9787586, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.295687198638916, "Value Loss": 87.6785659790039, "_runtime": 9696.716723203659, "_timestamp": 1585579612.5613565, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.500214576721191, "Value Loss": 83.25871276855469, "_runtime": 9698.29574227333, "_timestamp": 1585579614.1403756, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.747723579406738, "Value Loss": 26.56389045715332, "_runtime": 9699.88832616806, "_timestamp": 1585579615.7329595, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.786590099334717, "Value Loss": 75.96868896484375, "_runtime": 9701.472566366196, "_timestamp": 1585579617.3171997, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.029829978942871, "Value Loss": 13.50730037689209, "_runtime": 9703.07333111763, "_timestamp": 1585579618.9179645, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.397675037384033, "Value Loss": 68.49067687988281, "_runtime": 9704.673787117004, "_timestamp": 1585579620.5184205, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.78321647644043, "Value Loss": 80.43587493896484, "_runtime": 9706.266726493835, "_timestamp": 1585579622.1113598, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.1808443069458, "Value Loss": 3.6917831897735596, "_runtime": 9707.86612534523, "_timestamp": 1585579623.7107587, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.560439109802246, "Value Loss": 2.225984811782837, "_runtime": 9709.500514030457, "_timestamp": 1585579625.3451474, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.914874076843262, "Value Loss": 2.747812509536743, "_runtime": 9711.09156370163, "_timestamp": 1585579626.936197, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.226420402526855, "Value Loss": 37.448631286621094, "_runtime": 9712.684796571732, "_timestamp": 1585579628.52943, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.125860214233398, "Value Loss": 113.0797348022461, "_runtime": 9714.272852897644, "_timestamp": 1585579630.1174862, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.371788024902344, "Value Loss": 9.271883964538574, "_runtime": 9715.864605426788, "_timestamp": 1585579631.7092388, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.672093868255615, "Value Loss": 49.98285675048828, "_runtime": 9717.459154844284, "_timestamp": 1585579633.3037882, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.762359619140625, "Value Loss": 152.49154663085938, "_runtime": 9719.062928676605, "_timestamp": 1585579634.907562, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.635326385498047, "Value Loss": 27.03826904296875, "_runtime": 9720.63855957985, "_timestamp": 1585579636.483193, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.527538776397705, "Value Loss": 7.502015113830566, "_runtime": 9722.211944818497, "_timestamp": 1585579638.0565782, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.539184808731079, "Value Loss": 11.235836029052734, "_runtime": 9723.796164751053, "_timestamp": 1585579639.640798, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7596843242645264, "Value Loss": 2.172032117843628, "_runtime": 9725.376421451569, "_timestamp": 1585579641.2210548, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.084021806716919, "Value Loss": 0.14296084642410278, "_runtime": 9726.95119214058, "_timestamp": 1585579642.7958255, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4950133562088013, "Value Loss": 1.1212412118911743, "_runtime": 9728.536844730377, "_timestamp": 1585579644.381478, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0009630918502808, "Value Loss": 1.0860997438430786, "_runtime": 9730.109804391861, "_timestamp": 1585579645.9544377, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5650072693824768, "Value Loss": 1.0606646537780762, "_runtime": 9731.685859680176, "_timestamp": 1585579647.530493, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18163327872753143, "Value Loss": 8.507359504699707, "_runtime": 9733.300179719925, "_timestamp": 1585579649.144813, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17068466544151306, "Value Loss": 8.766884803771973, "_runtime": 9734.87536907196, "_timestamp": 1585579650.7200024, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5079166889190674, "Value Loss": 8.382152557373047, "_runtime": 9736.463015794754, "_timestamp": 1585579652.3076491, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.015474796295166, "Value Loss": 1.0464941263198853, "_runtime": 9738.052114486694, "_timestamp": 1585579653.8967478, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3684413433074951, "Value Loss": 0.31260308623313904, "_runtime": 9739.637342453003, "_timestamp": 1585579655.4819758, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7078131437301636, "Value Loss": 3.825019359588623, "_runtime": 9741.234561681747, "_timestamp": 1585579657.079195, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5500534772872925, "Value Loss": 2.5662975311279297, "_runtime": 9742.836123943329, "_timestamp": 1585579658.6807573, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7270574569702148, "Value Loss": 0.46418505907058716, "_runtime": 9744.431034326553, "_timestamp": 1585579660.2756677, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.882794976234436, "Value Loss": 0.03808559477329254, "_runtime": 9746.031814098358, "_timestamp": 1585579661.8764474, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.045705795288086, "Value Loss": 0.8167917132377625, "_runtime": 9747.622751235962, "_timestamp": 1585579663.4673846, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1750411987304688, "Value Loss": 0.08996330201625824, "_runtime": 9749.20804977417, "_timestamp": 1585579665.052683, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2970356941223145, "Value Loss": 0.46246129274368286, "_runtime": 9750.809356451035, "_timestamp": 1585579666.6539898, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.401916265487671, "Value Loss": 0.052961286157369614, "_runtime": 9752.399181604385, "_timestamp": 1585579668.243815, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4829516410827637, "Value Loss": 0.0847991481423378, "_runtime": 9753.99671292305, "_timestamp": 1585579669.8413463, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5489883422851562, "Value Loss": 0.13703559339046478, "_runtime": 9755.588464021683, "_timestamp": 1585579671.4330974, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.619460105895996, "Value Loss": 0.12459667026996613, "_runtime": 9757.228043079376, "_timestamp": 1585579673.0726764, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.693277359008789, "Value Loss": 0.4045881927013397, "_runtime": 9758.822201490402, "_timestamp": 1585579674.6668348, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7592265605926514, "Value Loss": 0.09127368777990341, "_runtime": 9760.423826217651, "_timestamp": 1585579676.2684596, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.802452802658081, "Value Loss": 0.11402694135904312, "_runtime": 9762.013021230698, "_timestamp": 1585579677.8576546, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.852855920791626, "Value Loss": 0.10195142775774002, "_runtime": 9763.611009836197, "_timestamp": 1585579679.4556432, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8899545669555664, "Value Loss": 0.8016454577445984, "_runtime": 9765.202459335327, "_timestamp": 1585579681.0470927, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9180779457092285, "Value Loss": 0.26835811138153076, "_runtime": 9766.793878555298, "_timestamp": 1585579682.638512, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9430601596832275, "Value Loss": 0.4370359480381012, "_runtime": 9768.392279148102, "_timestamp": 1585579684.2369125, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9728596210479736, "Value Loss": 0.1152799054980278, "_runtime": 9769.984006643295, "_timestamp": 1585579685.82864, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.980956554412842, "Value Loss": 0.687777578830719, "_runtime": 9771.573788166046, "_timestamp": 1585579687.4184215, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9876163005828857, "Value Loss": 0.1826864331960678, "_runtime": 9773.170437574387, "_timestamp": 1585579689.015071, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.981959342956543, "Value Loss": 0.6939002871513367, "_runtime": 9774.774889707565, "_timestamp": 1585579690.619523, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.956749200820923, "Value Loss": 0.44669753313064575, "_runtime": 9776.374793291092, "_timestamp": 1585579692.2194266, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9386563301086426, "Value Loss": 0.24879710376262665, "_runtime": 9777.972790241241, "_timestamp": 1585579693.8174236, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.901580333709717, "Value Loss": 0.24709460139274597, "_runtime": 9779.574229001999, "_timestamp": 1585579695.4188623, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8676679134368896, "Value Loss": 0.09226231276988983, "_runtime": 9781.212297916412, "_timestamp": 1585579697.0569313, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8232924938201904, "Value Loss": 0.4288528561592102, "_runtime": 9782.797342777252, "_timestamp": 1585579698.641976, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.774479627609253, "Value Loss": 0.33700522780418396, "_runtime": 9784.39699602127, "_timestamp": 1585579700.2416294, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7156574726104736, "Value Loss": 0.2470218688249588, "_runtime": 9785.985920190811, "_timestamp": 1585579701.8305535, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6578917503356934, "Value Loss": 0.1991390883922577, "_runtime": 9787.58340549469, "_timestamp": 1585579703.4280388, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.593653440475464, "Value Loss": 0.2774956524372101, "_runtime": 9789.183197975159, "_timestamp": 1585579705.0278313, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.528520345687866, "Value Loss": 0.20912733674049377, "_runtime": 9790.773450136185, "_timestamp": 1585579706.6180835, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4764931201934814, "Value Loss": 0.11430788785219193, "_runtime": 9792.366999387741, "_timestamp": 1585579708.2116327, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4203691482543945, "Value Loss": 0.054237231612205505, "_runtime": 9793.955728054047, "_timestamp": 1585579709.8003614, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.357816696166992, "Value Loss": 0.07645219564437866, "_runtime": 9795.543298006058, "_timestamp": 1585579711.3879313, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3145883083343506, "Value Loss": 0.08406468480825424, "_runtime": 9797.137674808502, "_timestamp": 1585579712.9823081, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.267392873764038, "Value Loss": 0.04761090874671936, "_runtime": 9798.733448266983, "_timestamp": 1585579714.5780816, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2223548889160156, "Value Loss": 0.04495309665799141, "_runtime": 9800.328317642212, "_timestamp": 1585579716.172951, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1779706478118896, "Value Loss": 0.055285193026065826, "_runtime": 9801.923060178757, "_timestamp": 1585579717.7676935, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1271114349365234, "Value Loss": 0.07488735765218735, "_runtime": 9803.554904222488, "_timestamp": 1585579719.3995376, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0896973609924316, "Value Loss": 0.11346454918384552, "_runtime": 9805.141700983047, "_timestamp": 1585579720.9863343, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.065037727355957, "Value Loss": 0.041815467178821564, "_runtime": 9806.726083755493, "_timestamp": 1585579722.570717, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.03035044670105, "Value Loss": 0.04958755522966385, "_runtime": 9808.323390960693, "_timestamp": 1585579724.1680243, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9996439218521118, "Value Loss": 0.04110193997621536, "_runtime": 9809.921249628067, "_timestamp": 1585579725.765883, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9650753736495972, "Value Loss": 0.06329824030399323, "_runtime": 9811.51944231987, "_timestamp": 1585579727.3640757, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9412356615066528, "Value Loss": 0.0406452901661396, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 9813.117066383362, "_timestamp": 1585579728.9616997, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9081698656082153, "Value Loss": 0.12886469066143036, "_runtime": 9814.710166931152, "_timestamp": 1585579730.5548003, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8905328512191772, "Value Loss": 0.06271500885486603, "_runtime": 9816.283120155334, "_timestamp": 1585579732.1277535, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8662477731704712, "Value Loss": 0.053886108100414276, "_runtime": 9817.877040624619, "_timestamp": 1585579733.721674, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.842952013015747, "Value Loss": 0.037948448210954666, "_runtime": 9819.457943201065, "_timestamp": 1585579735.3025765, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8153893947601318, "Value Loss": 0.054721709340810776, "_runtime": 9821.040542840958, "_timestamp": 1585579736.8851762, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7955982685089111, "Value Loss": 0.05145541578531265, "_runtime": 9822.641271352768, "_timestamp": 1585579738.4859047, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7729593515396118, "Value Loss": 0.04396756365895271, "_runtime": 9824.23746395111, "_timestamp": 1585579740.0820973, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7521252632141113, "Value Loss": 0.036240220069885254, "_runtime": 9825.83253288269, "_timestamp": 1585579741.6771662, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7340232133865356, "Value Loss": 0.037660449743270874, "_runtime": 9827.468795537949, "_timestamp": 1585579743.3134289, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7153414487838745, "Value Loss": 0.03284476324915886, "_runtime": 9829.06791639328, "_timestamp": 1585579744.9125497, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6955934762954712, "Value Loss": 0.038731951266527176, "_runtime": 9830.654742956161, "_timestamp": 1585579746.4993763, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.681087851524353, "Value Loss": 0.03597034141421318, "_runtime": 9832.244628190994, "_timestamp": 1585579748.0892615, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6702204942703247, "Value Loss": 0.026708567515015602, "_runtime": 9833.843212842941, "_timestamp": 1585579749.6878462, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6574478149414062, "Value Loss": 0.027378462255001068, "_runtime": 9835.441563606262, "_timestamp": 1585579751.286197, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6396695375442505, "Value Loss": 0.03636915981769562, "_runtime": 9837.041065216064, "_timestamp": 1585579752.8856986, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.623558759689331, "Value Loss": 0.030985912308096886, "_runtime": 9838.641517162323, "_timestamp": 1585579754.4861505, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6108205318450928, "Value Loss": 0.023331668227910995, "_runtime": 9840.23209810257, "_timestamp": 1585579756.0767314, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.59048593044281, "Value Loss": 0.03306128457188606, "_runtime": 9841.827340841293, "_timestamp": 1585579757.6719742, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5728205442428589, "Value Loss": 0.0300226379185915, "_runtime": 9843.40275478363, "_timestamp": 1585579759.2473881, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5510499477386475, "Value Loss": 0.03518000990152359, "_runtime": 9845.00198674202, "_timestamp": 1585579760.84662, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5298409461975098, "Value Loss": 0.02163873240351677, "_runtime": 9846.602615118027, "_timestamp": 1585579762.4472485, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5039176940917969, "Value Loss": 0.026710310950875282, "_runtime": 9848.192084550858, "_timestamp": 1585579764.036718, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4800620079040527, "Value Loss": 0.021502360701560974, "_runtime": 9849.77999663353, "_timestamp": 1585579765.62463, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4520630836486816, "Value Loss": 0.026330821216106415, "_runtime": 9851.41566157341, "_timestamp": 1585579767.260295, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4267710447311401, "Value Loss": 0.023452818393707275, "_runtime": 9853.013431310654, "_timestamp": 1585579768.8580647, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.400669813156128, "Value Loss": 0.018346121534705162, "_runtime": 9854.599276304245, "_timestamp": 1585579770.4439096, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3728238344192505, "Value Loss": 0.019533837214112282, "_runtime": 9856.195890665054, "_timestamp": 1585579772.040524, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3439894914627075, "Value Loss": 0.020682064816355705, "_runtime": 9857.792263269424, "_timestamp": 1585579773.6368966, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.317313313484192, "Value Loss": 0.017210066318511963, "_runtime": 9859.389040231705, "_timestamp": 1585579775.2336736, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.287916898727417, "Value Loss": 0.019106313586235046, "_runtime": 9860.988826274872, "_timestamp": 1585579776.8334596, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2620701789855957, "Value Loss": 0.016434242948889732, "_runtime": 9862.585707426071, "_timestamp": 1585579778.4303408, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2369636297225952, "Value Loss": 0.014638437889516354, "_runtime": 9864.180710315704, "_timestamp": 1585579780.0253437, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2079674005508423, "Value Loss": 0.016228625550866127, "_runtime": 9865.782090425491, "_timestamp": 1585579781.6267238, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.183417797088623, "Value Loss": 0.017115620896220207, "_runtime": 9867.367167711258, "_timestamp": 1585579783.211801, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1589272022247314, "Value Loss": 0.015939699485898018, "_runtime": 9868.96230006218, "_timestamp": 1585579784.8069334, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1367279291152954, "Value Loss": 0.011679011397063732, "_runtime": 9870.560059309006, "_timestamp": 1585579786.4046926, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1139261722564697, "Value Loss": 0.015812527388334274, "_runtime": 9872.158682584763, "_timestamp": 1585579788.003316, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0895377397537231, "Value Loss": 0.014888698235154152, "_runtime": 9873.754306316376, "_timestamp": 1585579789.5989397, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0701680183410645, "Value Loss": 0.015679897740483284, "_runtime": 9875.375534534454, "_timestamp": 1585579791.2201679, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0519970655441284, "Value Loss": 0.02027221955358982, "_runtime": 9876.9742705822, "_timestamp": 1585579792.818904, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0357059240341187, "Value Loss": 0.02121548168361187, "_runtime": 9878.572816848755, "_timestamp": 1585579794.4174502, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.020523190498352, "Value Loss": 0.01405250746756792, "_runtime": 9880.171965122223, "_timestamp": 1585579796.0165985, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0025233030319214, "Value Loss": 0.016471970826387405, "_runtime": 9881.767806529999, "_timestamp": 1585579797.6124399, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9907833933830261, "Value Loss": 0.011381704360246658, "_runtime": 9883.363903999329, "_timestamp": 1585579799.2085373, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.971632182598114, "Value Loss": 0.013699027709662914, "_runtime": 9884.953354597092, "_timestamp": 1585579800.797988, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9600157141685486, "Value Loss": 0.008715443313121796, "_runtime": 9886.540912628174, "_timestamp": 1585579802.385546, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.941990077495575, "Value Loss": 0.01274477131664753, "_runtime": 9888.127434015274, "_timestamp": 1585579803.9720674, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9291301369667053, "Value Loss": 0.009882135316729546, "_runtime": 9889.727058172226, "_timestamp": 1585579805.5716915, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9143456816673279, "Value Loss": 0.007600648328661919, "_runtime": 9891.313101530075, "_timestamp": 1585579807.1577349, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8980556726455688, "Value Loss": 0.010038228705525398, "_runtime": 9892.907615184784, "_timestamp": 1585579808.7522485, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8861770033836365, "Value Loss": 0.007169691380113363, "_runtime": 9894.506944179535, "_timestamp": 1585579810.3515775, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8717861175537109, "Value Loss": 0.007364782504737377, "_runtime": 9896.10994887352, "_timestamp": 1585579811.9545822, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.857489824295044, "Value Loss": 0.006998857483267784, "_runtime": 9897.742585420609, "_timestamp": 1585579813.5872188, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8421103358268738, "Value Loss": 0.009885712526738644, "_runtime": 9899.34030175209, "_timestamp": 1585579815.184935, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8290556073188782, "Value Loss": 0.00675245700404048, "_runtime": 9900.936701536179, "_timestamp": 1585579816.7813349, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8139768242835999, "Value Loss": 0.006596780382096767, "_runtime": 9902.521569013596, "_timestamp": 1585579818.3662024, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8002737164497375, "Value Loss": 0.006359794642776251, "_runtime": 9904.120371341705, "_timestamp": 1585579819.9650047, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7857906222343445, "Value Loss": 0.006022607441991568, "_runtime": 9905.717024087906, "_timestamp": 1585579821.5616574, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7694935202598572, "Value Loss": 0.009957126341760159, "_runtime": 9907.300530195236, "_timestamp": 1585579823.1451635, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7562853693962097, "Value Loss": 0.006381505634635687, "_runtime": 9908.887198448181, "_timestamp": 1585579824.7318318, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.742845892906189, "Value Loss": 0.005370691418647766, "_runtime": 9910.483481884003, "_timestamp": 1585579826.3281152, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7280357480049133, "Value Loss": 0.004828107543289661, "_runtime": 9912.076872348785, "_timestamp": 1585579827.9215057, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.713782548904419, "Value Loss": 0.005087331868708134, "_runtime": 9913.675074338913, "_timestamp": 1585579829.5197077, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6991135478019714, "Value Loss": 0.004737886134535074, "_runtime": 9915.268387556076, "_timestamp": 1585579831.113021, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.683815062046051, "Value Loss": 0.008314083330333233, "_runtime": 9916.86219573021, "_timestamp": 1585579832.706829, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6686887741088867, "Value Loss": 0.009523963555693626, "_runtime": 9918.445317983627, "_timestamp": 1585579834.2899513, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.655747652053833, "Value Loss": 0.005510759074240923, "_runtime": 9920.037402391434, "_timestamp": 1585579835.8820357, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6421766877174377, "Value Loss": 0.005036326125264168, "_runtime": 9921.661035776138, "_timestamp": 1585579837.505669, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6285194158554077, "Value Loss": 0.003688384313136339, "_runtime": 9923.243757247925, "_timestamp": 1585579839.0883906, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6140191555023193, "Value Loss": 0.007111683022230864, "_runtime": 9924.836611509323, "_timestamp": 1585579840.6812449, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6010530591011047, "Value Loss": 0.0057714758440852165, "_runtime": 9926.426253557205, "_timestamp": 1585579842.270887, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5887429714202881, "Value Loss": 0.0044479891657829285, "_runtime": 9928.021926164627, "_timestamp": 1585579843.8665595, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5751969218254089, "Value Loss": 0.003168844385072589, "_runtime": 9929.614961385727, "_timestamp": 1585579845.4595947, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.564045786857605, "Value Loss": 0.003397013060748577, "_runtime": 9931.205056667328, "_timestamp": 1585579847.04969, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5521242022514343, "Value Loss": 0.0031025437638163567, "_runtime": 9932.797659397125, "_timestamp": 1585579848.6422927, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5406153798103333, "Value Loss": 0.002868913346901536, "_runtime": 9934.369235992432, "_timestamp": 1585579850.2138693, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5282912850379944, "Value Loss": 0.005227023735642433, "_runtime": 9935.962540388107, "_timestamp": 1585579851.8071737, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.517764687538147, "Value Loss": 0.003264467930421233, "_runtime": 9937.561006069183, "_timestamp": 1585579853.4056394, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.507853090763092, "Value Loss": 0.002504331059753895, "_runtime": 9939.15481877327, "_timestamp": 1585579854.999452, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4969066381454468, "Value Loss": 0.0034537089522928, "_runtime": 9940.748377084732, "_timestamp": 1585579856.5930104, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4867931306362152, "Value Loss": 0.003243472659960389, "_runtime": 9942.335098743439, "_timestamp": 1585579858.179732, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4751046299934387, "Value Loss": 0.006369149312376976, "_runtime": 9943.924387931824, "_timestamp": 1585579859.7690213, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4666220545768738, "Value Loss": 0.0030986180063337088, "_runtime": 9945.53650689125, "_timestamp": 1585579861.3811402, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4567239284515381, "Value Loss": 0.0027594370767474174, "_runtime": 9947.134808540344, "_timestamp": 1585579862.979442, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44658714532852173, "Value Loss": 0.003990336786955595, "_runtime": 9948.732840776443, "_timestamp": 1585579864.577474, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.43749693036079407, "Value Loss": 0.0026705367490649223, "_runtime": 9950.317859888077, "_timestamp": 1585579866.1624932, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42806655168533325, "Value Loss": 0.0017716509755700827, "_runtime": 9951.915440797806, "_timestamp": 1585579867.7600741, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41993433237075806, "Value Loss": 0.0024734237231314182, "_runtime": 9953.513009309769, "_timestamp": 1585579869.3576427, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4122304916381836, "Value Loss": 0.0018703200621530414, "_runtime": 9955.110978603363, "_timestamp": 1585579870.955612, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.40388578176498413, "Value Loss": 0.0016050334088504314, "_runtime": 9956.708623886108, "_timestamp": 1585579872.5532572, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39455243945121765, "Value Loss": 0.005423285067081451, "_runtime": 9958.307851314545, "_timestamp": 1585579874.1524847, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.38817018270492554, "Value Loss": 0.0019175640773028135, "_runtime": 9959.90518450737, "_timestamp": 1585579875.7498178, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.379197895526886, "Value Loss": 0.003320924239233136, "_runtime": 9961.501096487045, "_timestamp": 1585579877.3457298, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37156370282173157, "Value Loss": 0.003117660293355584, "_runtime": 9963.08778309822, "_timestamp": 1585579878.9324164, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.36387133598327637, "Value Loss": 0.001697918982245028, "_runtime": 9964.684167861938, "_timestamp": 1585579880.5288012, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.35628581047058105, "Value Loss": 0.0017629081849008799, "_runtime": 9966.263667821884, "_timestamp": 1585579882.1083012, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3480541408061981, "Value Loss": 0.003067291108891368, "_runtime": 9967.849551916122, "_timestamp": 1585579883.6941853, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3414901793003082, "Value Loss": 0.0013130158185958862, "_runtime": 9969.482115983963, "_timestamp": 1585579885.3267493, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3340691030025482, "Value Loss": 0.0012711724266409874, "_runtime": 9971.07002067566, "_timestamp": 1585579886.914654, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32676997780799866, "Value Loss": 0.001193728414364159, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 9972.664683818817, "_timestamp": 1585579888.5093172, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3186945617198944, "Value Loss": 0.0028325351886451244, "_runtime": 9974.239539146423, "_timestamp": 1585579890.0841725, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.31199169158935547, "Value Loss": 0.0015659669879823923, "_runtime": 9975.825512647629, "_timestamp": 1585579891.670146, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.304463267326355, "Value Loss": 0.00197688490152359, "_runtime": 9977.409814834595, "_timestamp": 1585579893.2544482, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2965012192726135, "Value Loss": 0.002841947367414832, "_runtime": 9978.998131036758, "_timestamp": 1585579894.8427644, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29062896966934204, "Value Loss": 0.0008452879264950752, "_runtime": 9980.58478140831, "_timestamp": 1585579896.4294147, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2836625874042511, "Value Loss": 0.0009173188591375947, "_runtime": 9982.163391828537, "_timestamp": 1585579898.0080252, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27655738592147827, "Value Loss": 0.001614714041352272, "_runtime": 9983.760013103485, "_timestamp": 1585579899.6046464, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2698790431022644, "Value Loss": 0.0009266108390875161, "_runtime": 9985.346739530563, "_timestamp": 1585579901.1913729, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2624637186527252, "Value Loss": 0.0024863763246685266, "_runtime": 9986.932380199432, "_timestamp": 1585579902.7770135, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25593408942222595, "Value Loss": 0.0014828535495325923, "_runtime": 9988.529746770859, "_timestamp": 1585579904.37438, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2486000657081604, "Value Loss": 0.0022754063829779625, "_runtime": 9990.126108646393, "_timestamp": 1585579905.970742, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24257886409759521, "Value Loss": 0.0010128876892849803, "_runtime": 9991.724745512009, "_timestamp": 1585579907.5693789, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23596122860908508, "Value Loss": 0.0023014608304947615, "_runtime": 9993.358340978622, "_timestamp": 1585579909.2029743, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22922423481941223, "Value Loss": 0.003072597086429596, "_runtime": 9994.954592943192, "_timestamp": 1585579910.7992263, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2230563908815384, "Value Loss": 0.0018624963704496622, "_runtime": 9996.541003704071, "_timestamp": 1585579912.385637, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21723471581935883, "Value Loss": 0.002144568134099245, "_runtime": 9998.123793125153, "_timestamp": 1585579913.9684265, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21046578884124756, "Value Loss": 0.0032403504010289907, "_runtime": 9999.709620952606, "_timestamp": 1585579915.5542543, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20498065650463104, "Value Loss": 0.0011971659259870648, "_runtime": 10001.29746556282, "_timestamp": 1585579917.142099, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19900600612163544, "Value Loss": 0.000859000429045409, "_runtime": 10002.892051935196, "_timestamp": 1585579918.7366853, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19320596754550934, "Value Loss": 0.0009744057897478342, "_runtime": 10004.487877368927, "_timestamp": 1585579920.3325107, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18811416625976562, "Value Loss": 0.0017196257831528783, "_runtime": 10006.060018062592, "_timestamp": 1585579921.9046514, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18299052119255066, "Value Loss": 0.00043149763951078057, "_runtime": 10007.654407978058, "_timestamp": 1585579923.4990413, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1779806911945343, "Value Loss": 0.0003687456191983074, "_runtime": 10009.254767417908, "_timestamp": 1585579925.0994008, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17296671867370605, "Value Loss": 0.00037129875272512436, "_runtime": 10010.84813952446, "_timestamp": 1585579926.6927729, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16717101633548737, "Value Loss": 0.002426814753562212, "_runtime": 10012.44212770462, "_timestamp": 1585579928.286761, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1629055142402649, "Value Loss": 0.0014618989080190659, "_runtime": 10014.013827323914, "_timestamp": 1585579929.8584607, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1579941213130951, "Value Loss": 0.0027132434770464897, "_runtime": 10015.648097753525, "_timestamp": 1585579931.492731, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15395429730415344, "Value Loss": 0.00033655899460427463, "_runtime": 10017.23169374466, "_timestamp": 1585579933.076327, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1491321623325348, "Value Loss": 0.0004021526547148824, "_runtime": 10018.826572179794, "_timestamp": 1585579934.6712055, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1447770595550537, "Value Loss": 0.0015754456399008632, "_runtime": 10020.420387983322, "_timestamp": 1585579936.2650213, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14051537215709686, "Value Loss": 0.0016116078477352858, "_runtime": 10022.011401176453, "_timestamp": 1585579937.8560345, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1370375156402588, "Value Loss": 0.00035211635986343026, "_runtime": 10023.60938334465, "_timestamp": 1585579939.4540167, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.133682519197464, "Value Loss": 0.0006162495701573789, "_runtime": 10025.195318698883, "_timestamp": 1585579941.039952, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12969718873500824, "Value Loss": 0.00034170233993791044, "_runtime": 10026.780014514923, "_timestamp": 1585579942.6246479, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12644536793231964, "Value Loss": 0.0003515518910717219, "_runtime": 10028.35591340065, "_timestamp": 1585579944.2005467, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12304303050041199, "Value Loss": 0.00019711708591785282, "_runtime": 10029.95033788681, "_timestamp": 1585579945.7949712, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11974320560693741, "Value Loss": 0.00018966624338645488, "_runtime": 10031.545581817627, "_timestamp": 1585579947.3902152, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11619837582111359, "Value Loss": 0.0006169418338686228, "_runtime": 10033.12933754921, "_timestamp": 1585579948.973971, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1129717230796814, "Value Loss": 0.0002265974326292053, "_runtime": 10034.725491046906, "_timestamp": 1585579950.5701244, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10953978449106216, "Value Loss": 0.0010905591771006584, "_runtime": 10036.30433678627, "_timestamp": 1585579952.1489701, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10633179545402527, "Value Loss": 0.0003613646258600056, "_runtime": 10037.897622823715, "_timestamp": 1585579953.7422562, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10309718549251556, "Value Loss": 0.00026049348525702953, "_runtime": 10039.51874089241, "_timestamp": 1585579955.3633742, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09985397756099701, "Value Loss": 0.0006383870495483279, "_runtime": 10041.117327928543, "_timestamp": 1585579956.9619613, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09686557948589325, "Value Loss": 0.0018184779910370708, "_runtime": 10042.713606834412, "_timestamp": 1585579958.5582402, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09385840594768524, "Value Loss": 0.0002530574274715036, "_runtime": 10044.308247804642, "_timestamp": 1585579960.1528811, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09113582968711853, "Value Loss": 0.00022466873633675277, "_runtime": 10045.900762796402, "_timestamp": 1585579961.7453961, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08862968534231186, "Value Loss": 0.0002207459619967267, "_runtime": 10047.49775648117, "_timestamp": 1585579963.3423898, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08595294505357742, "Value Loss": 0.00042992664384655654, "_runtime": 10049.081193447113, "_timestamp": 1585579964.9258268, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08302595466375351, "Value Loss": 0.0010958741186186671, "_runtime": 10050.675643205643, "_timestamp": 1585579966.5202765, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08062160015106201, "Value Loss": 0.0003180184867233038, "_runtime": 10052.27118563652, "_timestamp": 1585579968.115819, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07801312953233719, "Value Loss": 0.00020324189972598106, "_runtime": 10053.866531133652, "_timestamp": 1585579969.7111645, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07544545829296112, "Value Loss": 0.00046486419159919024, "_runtime": 10055.451240301132, "_timestamp": 1585579971.2958736, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07277672737836838, "Value Loss": 0.00012701483501587063, "_runtime": 10057.03894853592, "_timestamp": 1585579972.8835819, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07029271870851517, "Value Loss": 0.00014888889563735574, "_runtime": 10058.628757238388, "_timestamp": 1585579974.4733906, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06784609705209732, "Value Loss": 0.0006616277969442308, "_runtime": 10060.212369203568, "_timestamp": 1585579976.0570025, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06550145894289017, "Value Loss": 0.0005727702518925071, "_runtime": 10061.80883860588, "_timestamp": 1585579977.653472, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06284673511981964, "Value Loss": 0.0004400299512781203, "_runtime": 10063.441729068756, "_timestamp": 1585579979.2863624, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.060181763023138046, "Value Loss": 0.0019367252243682742, "_runtime": 10065.037009239197, "_timestamp": 1585579980.8816426, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05783112719655037, "Value Loss": 0.0006186304381117225, "_runtime": 10066.619081258774, "_timestamp": 1585579982.4637146, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.055088914930820465, "Value Loss": 0.00015789951430633664, "_runtime": 10068.215532541275, "_timestamp": 1585579984.060166, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.052714839577674866, "Value Loss": 4.930219438392669e-05, "_runtime": 10069.810207128525, "_timestamp": 1585579985.6548405, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05020406097173691, "Value Loss": 0.0003089787205681205, "_runtime": 10071.39664363861, "_timestamp": 1585579987.241277, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04835744574666023, "Value Loss": 0.00016447680536657572, "_runtime": 10072.994666099548, "_timestamp": 1585579988.8392994, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0466126874089241, "Value Loss": 0.0003542235353961587, "_runtime": 10074.591814517975, "_timestamp": 1585579990.4364479, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04488622769713402, "Value Loss": 0.0012108266819268465, "_runtime": 10076.188678979874, "_timestamp": 1585579992.0333123, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04311986267566681, "Value Loss": 0.00017075700452551246, "_runtime": 10077.784672737122, "_timestamp": 1585579993.629306, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04153766110539436, "Value Loss": 0.000794477469753474, "_runtime": 10079.382536649704, "_timestamp": 1585579995.22717, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0406169667840004, "Value Loss": 0.00040004029870033264, "_runtime": 10080.981407165527, "_timestamp": 1585579996.8260405, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.039523497223854065, "Value Loss": 3.418017877265811e-05, "_runtime": 10082.578174114227, "_timestamp": 1585579998.4228075, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.038550201803445816, "Value Loss": 0.0005343476077541709, "_runtime": 10084.171989917755, "_timestamp": 1585580000.0166233, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.037564899772405624, "Value Loss": 0.0005855120252817869, "_runtime": 10085.768008947372, "_timestamp": 1585580001.6126423, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03645436838269234, "Value Loss": 0.0004948474233970046, "_runtime": 10087.39087486267, "_timestamp": 1585580003.2355082, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03516628220677376, "Value Loss": 0.0006902376771904528, "_runtime": 10088.973282337189, "_timestamp": 1585580004.8179157, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.033799879252910614, "Value Loss": 0.0011484503047540784, "_runtime": 10090.571262836456, "_timestamp": 1585580006.4158962, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03266489878296852, "Value Loss": 0.000655307958368212, "_runtime": 10092.160612821579, "_timestamp": 1585580008.0052462, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03174881264567375, "Value Loss": 0.0002473582571838051, "_runtime": 10093.745064735413, "_timestamp": 1585580009.589698, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030340565368533134, "Value Loss": 0.00013145868433639407, "_runtime": 10095.325803518295, "_timestamp": 1585580011.1704369, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02944345213472843, "Value Loss": 0.001460418337956071, "_runtime": 10096.899183511734, "_timestamp": 1585580012.7438169, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027980802580714226, "Value Loss": 8.896298822946846e-05, "_runtime": 10098.463225841522, "_timestamp": 1585580014.3078592, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026645004749298096, "Value Loss": 8.348771370947361e-05, "_runtime": 10100.036687850952, "_timestamp": 1585580015.8813212, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025283580645918846, "Value Loss": 0.00014335433661472052, "_runtime": 10101.622629642487, "_timestamp": 1585580017.467263, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02411147579550743, "Value Loss": 0.00017797655891627073, "_runtime": 10103.204939365387, "_timestamp": 1585580019.0495727, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023100532591342926, "Value Loss": 0.0003270659362897277, "_runtime": 10104.786855459213, "_timestamp": 1585580020.6314888, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021378809586167336, "Value Loss": 0.0004865849914494902, "_runtime": 10106.371334552765, "_timestamp": 1585580022.215968, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019752923399209976, "Value Loss": 0.0008436192292720079, "_runtime": 10107.953741312027, "_timestamp": 1585580023.7983747, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01808272674679756, "Value Loss": 0.00012253403838258237, "_runtime": 10109.566393136978, "_timestamp": 1585580025.4110265, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01688130758702755, "Value Loss": 0.001018832321278751, "_runtime": 10111.150657892227, "_timestamp": 1585580026.9952912, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015150370076298714, "Value Loss": 6.424127786885947e-05, "_runtime": 10112.733061552048, "_timestamp": 1585580028.577695, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014039024710655212, "Value Loss": 0.0009847009787335992, "_runtime": 10114.319051742554, "_timestamp": 1585580030.163685, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012601419351994991, "Value Loss": 0.000385138118872419, "_runtime": 10115.90371966362, "_timestamp": 1585580031.748353, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011521336622536182, "Value Loss": 0.0007430533296428621, "_runtime": 10117.488751411438, "_timestamp": 1585580033.3333848, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010052645578980446, "Value Loss": 0.00043889935477636755, "_runtime": 10119.062046289444, "_timestamp": 1585580034.9066796, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00902822706848383, "Value Loss": 2.092456998070702e-05, "_runtime": 10120.633660078049, "_timestamp": 1585580036.4782934, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007980992086231709, "Value Loss": 0.00026069264276884496, "_runtime": 10122.217291116714, "_timestamp": 1585580038.0619245, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006907805800437927, "Value Loss": 0.0003326425503473729, "_runtime": 10123.805132865906, "_timestamp": 1585580039.6497662, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0057975249364972115, "Value Loss": 0.00048390429583378136, "_runtime": 10125.39070224762, "_timestamp": 1585580041.2353356, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004539780784398317, "Value Loss": 0.00011506830924190581, "_runtime": 10126.95889377594, "_timestamp": 1585580042.803527, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0036635217256844044, "Value Loss": 0.000662811566144228, "_runtime": 10128.533385038376, "_timestamp": 1585580044.3780184, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026642954908311367, "Value Loss": 0.000692318077199161, "_runtime": 10130.10758137703, "_timestamp": 1585580045.9522147, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0020495455246418715, "Value Loss": 0.0008480682736262679, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 10131.679144859314, "_timestamp": 1585580047.5237782, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010172799229621887, "Value Loss": 0.0011822049273177981, "_runtime": 10133.30203461647, "_timestamp": 1585580049.146668, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00020841545483563095, "Value Loss": 8.136627729982138e-05, "_runtime": 10134.884537935257, "_timestamp": 1585580050.7291713, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008556906832382083, "Value Loss": 0.0012675137259066105, "_runtime": 10136.46842956543, "_timestamp": 1585580052.313063, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014985520392656326, "Value Loss": 1.51053536683321e-05, "_runtime": 10138.041110992432, "_timestamp": 1585580053.8857443, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002145015401765704, "Value Loss": 0.0009523039334453642, "_runtime": 10139.624457359314, "_timestamp": 1585580055.4690907, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032153904903680086, "Value Loss": 0.00010890904377447441, "_runtime": 10141.206855535507, "_timestamp": 1585580057.0514889, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003920855466276407, "Value Loss": 0.00010663086140993983, "_runtime": 10142.791947841644, "_timestamp": 1585580058.6365812, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00425828667357564, "Value Loss": 0.0002639620506670326, "_runtime": 10144.379678726196, "_timestamp": 1585580060.224312, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004901837557554245, "Value Loss": 2.2526945031131618e-05, "_runtime": 10145.961766958237, "_timestamp": 1585580061.8064003, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005393406841903925, "Value Loss": 8.937654638430104e-05, "_runtime": 10147.547407627106, "_timestamp": 1585580063.392041, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00598614988848567, "Value Loss": 0.000507598218973726, "_runtime": 10149.129455566406, "_timestamp": 1585580064.974089, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006554689723998308, "Value Loss": 0.00044163232087157667, "_runtime": 10150.709002494812, "_timestamp": 1585580066.5536358, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007152617443352938, "Value Loss": 0.000815564242657274, "_runtime": 10152.283289432526, "_timestamp": 1585580068.1279228, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007657359819859266, "Value Loss": 0.0009568887180648744, "_runtime": 10153.86447930336, "_timestamp": 1585580069.7091126, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008249926380813122, "Value Loss": 0.00016454613069072366, "_runtime": 10155.442133188248, "_timestamp": 1585580071.2867665, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008875596337020397, "Value Loss": 5.309056359692477e-05, "_runtime": 10157.061819553375, "_timestamp": 1585580072.906453, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00909416563808918, "Value Loss": 0.00030945087200962007, "_runtime": 10158.645495891571, "_timestamp": 1585580074.4901292, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009783276356756687, "Value Loss": 0.0003366289893165231, "_runtime": 10160.224078178406, "_timestamp": 1585580076.0687115, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010565542615950108, "Value Loss": 9.969413076760247e-05, "_runtime": 10161.80457520485, "_timestamp": 1585580077.6492085, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01097375713288784, "Value Loss": 1.373042687191628e-05, "_runtime": 10163.386897325516, "_timestamp": 1585580079.2315307, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0114560816437006, "Value Loss": 0.0004232419887557626, "_runtime": 10164.968363523483, "_timestamp": 1585580080.8129969, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01230466179549694, "Value Loss": 0.00011927622108487412, "_runtime": 10166.545931577682, "_timestamp": 1585580082.390565, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012537562288343906, "Value Loss": 0.0005930543411523104, "_runtime": 10168.128999710083, "_timestamp": 1585580083.973633, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012859323062002659, "Value Loss": 0.0011389886494725943, "_runtime": 10169.704527139664, "_timestamp": 1585580085.5491605, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013561748899519444, "Value Loss": 3.7489466194529086e-05, "_runtime": 10171.30036687851, "_timestamp": 1585580087.1450002, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013207579031586647, "Value Loss": 0.00027522112941369414, "_runtime": 10172.880552053452, "_timestamp": 1585580088.7251854, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013187757693231106, "Value Loss": 0.00048520672135055065, "_runtime": 10174.463817834854, "_timestamp": 1585580090.3084512, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013525561429560184, "Value Loss": 0.00016734754899516702, "_runtime": 10176.047355890274, "_timestamp": 1585580091.8919892, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013090871274471283, "Value Loss": 0.00023330045223701745, "_runtime": 10177.631513118744, "_timestamp": 1585580093.4761465, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013539611361920834, "Value Loss": 3.830872810794972e-05, "_runtime": 10179.221632480621, "_timestamp": 1585580095.0662658, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013143856078386307, "Value Loss": 0.000413998233852908, "_runtime": 10180.852552175522, "_timestamp": 1585580096.6971855, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013146977871656418, "Value Loss": 0.00048595824046060443, "_runtime": 10182.443485736847, "_timestamp": 1585580098.288119, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013051045127213001, "Value Loss": 0.0004110607551410794, "_runtime": 10184.023508310318, "_timestamp": 1585580099.8681417, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013433996587991714, "Value Loss": 0.00023983221035450697, "_runtime": 10185.618602514267, "_timestamp": 1585580101.4632359, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013819961808621883, "Value Loss": 8.034506026888266e-05, "_runtime": 10187.199246406555, "_timestamp": 1585580103.0438797, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013448558747768402, "Value Loss": 0.0009241865482181311, "_runtime": 10188.778760194778, "_timestamp": 1585580104.6233935, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013523255474865437, "Value Loss": 0.0006352828349918127, "_runtime": 10190.362185001373, "_timestamp": 1585580106.2068183, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013649340718984604, "Value Loss": 0.000602537882514298, "_runtime": 10191.955753326416, "_timestamp": 1585580107.8003867, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01409408263862133, "Value Loss": 0.0007332845707423985, "_runtime": 10193.537679672241, "_timestamp": 1585580109.382313, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014733243733644485, "Value Loss": 0.00015926078776828945, "_runtime": 10195.119911670685, "_timestamp": 1585580110.964545, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01598501205444336, "Value Loss": 9.239398059435189e-05, "_runtime": 10196.692466974258, "_timestamp": 1585580112.5371003, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015739571303129196, "Value Loss": 0.0003351227496750653, "_runtime": 10198.263263940811, "_timestamp": 1585580114.1078973, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016152095049619675, "Value Loss": 0.0005126895848661661, "_runtime": 10199.846468925476, "_timestamp": 1585580115.6911023, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.016382310539484024, "Value Loss": 0.0004675663949456066, "_runtime": 10201.430129051208, "_timestamp": 1585580117.2747624, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017262455075979233, "Value Loss": 0.00038031931035220623, "_runtime": 10203.00871706009, "_timestamp": 1585580118.8533504, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018064720556139946, "Value Loss": 9.979491005651653e-05, "_runtime": 10204.612175703049, "_timestamp": 1585580120.456809, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018080249428749084, "Value Loss": 0.00023991485068108886, "_runtime": 10206.185471534729, "_timestamp": 1585580122.0301049, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018839014694094658, "Value Loss": 8.355549653060734e-05, "_runtime": 10207.758030891418, "_timestamp": 1585580123.6026642, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018858633935451508, "Value Loss": 0.00035289593506604433, "_runtime": 10209.317882299423, "_timestamp": 1585580125.1625156, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018884198740124702, "Value Loss": 0.0006049911607988179, "_runtime": 10210.88926243782, "_timestamp": 1585580126.7338958, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019116481766104698, "Value Loss": 0.0005290757981128991, "_runtime": 10212.460968971252, "_timestamp": 1585580128.3056023, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01976032927632332, "Value Loss": 0.0005493992357514799, "_runtime": 10214.034469604492, "_timestamp": 1585580129.879103, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01977420039474964, "Value Loss": 0.0006329838070087135, "_runtime": 10215.60440826416, "_timestamp": 1585580131.4490416, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020842261612415314, "Value Loss": 7.790266681695357e-05, "_runtime": 10217.171988725662, "_timestamp": 1585580133.016622, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021142514422535896, "Value Loss": 9.586680971551687e-05, "_runtime": 10218.73408460617, "_timestamp": 1585580134.578718, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021369386464357376, "Value Loss": 8.867252472555265e-05, "_runtime": 10220.306351423264, "_timestamp": 1585580136.1509848, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021219225600361824, "Value Loss": 0.0008605418261140585, "_runtime": 10221.87532734871, "_timestamp": 1585580137.7199607, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021668691188097, "Value Loss": 0.00023540268011856824, "_runtime": 10223.447187185287, "_timestamp": 1585580139.2918205, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021665049716830254, "Value Loss": 7.760489825159311e-05, "_runtime": 10225.019592523575, "_timestamp": 1585580140.8642259, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022478584200143814, "Value Loss": 9.586807573214173e-05, "_runtime": 10226.62878537178, "_timestamp": 1585580142.4734187, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021744735538959503, "Value Loss": 0.000581312517169863, "_runtime": 10228.189823150635, "_timestamp": 1585580144.0344565, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02265765145421028, "Value Loss": 9.568988753017038e-05, "_runtime": 10229.753229618073, "_timestamp": 1585580145.597863, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021993983536958694, "Value Loss": 0.0003714323975145817, "_runtime": 10231.315158128738, "_timestamp": 1585580147.1597915, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02192716673016548, "Value Loss": 0.0007959752692840993, "_runtime": 10232.876993894577, "_timestamp": 1585580148.7216272, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022400792688131332, "Value Loss": 9.461765148444101e-05, "_runtime": 10234.449478387833, "_timestamp": 1585580150.2941117, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021451199427247047, "Value Loss": 0.0006700375233776867, "_runtime": 10236.008945941925, "_timestamp": 1585580151.8535793, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02145235799252987, "Value Loss": 0.00034657533979043365, "_runtime": 10237.57210111618, "_timestamp": 1585580153.4167345, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020894989371299744, "Value Loss": 0.0007847879896871746, "_runtime": 10239.143545627594, "_timestamp": 1585580154.988179, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020719069987535477, "Value Loss": 0.00023156274983193725, "_runtime": 10240.7055747509, "_timestamp": 1585580156.550208, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0209956094622612, "Value Loss": 0.000254978978773579, "_runtime": 10242.26882481575, "_timestamp": 1585580158.1134582, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021250523626804352, "Value Loss": 0.00010062730871140957, "_runtime": 10243.85296177864, "_timestamp": 1585580159.6975951, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020925229415297508, "Value Loss": 0.0003460870939306915, "_runtime": 10245.437243700027, "_timestamp": 1585580161.281877, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020699596032500267, "Value Loss": 0.00011806318798335269, "_runtime": 10247.010067939758, "_timestamp": 1585580162.8547013, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02132207341492176, "Value Loss": 0.00019197992514818907, "_runtime": 10248.594905138016, "_timestamp": 1585580164.4395385, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02142893336713314, "Value Loss": 0.0008035858045332134, "_runtime": 10250.213131189346, "_timestamp": 1585580166.0577645, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02137036621570587, "Value Loss": 0.00035608847974799573, "_runtime": 10251.800730466843, "_timestamp": 1585580167.6453638, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022155676037073135, "Value Loss": 4.268865450285375e-05, "_runtime": 10253.38481092453, "_timestamp": 1585580169.2294443, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02251923270523548, "Value Loss": 9.427469194633886e-05, "_runtime": 10254.968861818314, "_timestamp": 1585580170.8134952, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021698322147130966, "Value Loss": 0.0003307502483949065, "_runtime": 10256.553735733032, "_timestamp": 1585580172.398369, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021742388606071472, "Value Loss": 0.0005530912894755602, "_runtime": 10258.117162704468, "_timestamp": 1585580173.961796, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021933406591415405, "Value Loss": 5.7710243709152564e-05, "_runtime": 10259.689297437668, "_timestamp": 1585580175.5339308, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021573172882199287, "Value Loss": 5.35803337697871e-05, "_runtime": 10261.271491765976, "_timestamp": 1585580177.116125, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021817060187458992, "Value Loss": 0.00028150781872682273, "_runtime": 10262.843771457672, "_timestamp": 1585580178.6884048, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02142459526658058, "Value Loss": 0.0009966365760192275, "_runtime": 10264.42431306839, "_timestamp": 1585580180.2689464, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02211298793554306, "Value Loss": 0.00019428269297350198, "_runtime": 10266.00818324089, "_timestamp": 1585580181.8528166, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0216221883893013, "Value Loss": 0.0008326504030264914, "_runtime": 10267.590508699417, "_timestamp": 1585580183.435142, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022114628925919533, "Value Loss": 4.0413411625195295e-05, "_runtime": 10269.161145448685, "_timestamp": 1585580185.0057788, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02247653342783451, "Value Loss": 1.868413710326422e-05, "_runtime": 10270.723789453506, "_timestamp": 1585580186.5684228, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02243429236114025, "Value Loss": 0.00023799754853826016, "_runtime": 10272.30540895462, "_timestamp": 1585580188.1500423, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02212129347026348, "Value Loss": 0.00031174829928204417, "_runtime": 10273.926308631897, "_timestamp": 1585580189.770942, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02261698618531227, "Value Loss": 2.186864185205195e-05, "_runtime": 10275.498508691788, "_timestamp": 1585580191.343142, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022861802950501442, "Value Loss": 8.464576239930466e-05, "_runtime": 10277.081013441086, "_timestamp": 1585580192.9256468, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02164464071393013, "Value Loss": 0.0005695662694051862, "_runtime": 10278.662327289581, "_timestamp": 1585580194.5069606, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022145139053463936, "Value Loss": 0.0002585342444945127, "_runtime": 10280.23927116394, "_timestamp": 1585580196.0839045, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022265572100877762, "Value Loss": 5.379545473260805e-05, "_runtime": 10281.831521987915, "_timestamp": 1585580197.6761553, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021884208545088768, "Value Loss": 0.00026358934701420367, "_runtime": 10283.416862010956, "_timestamp": 1585580199.2614954, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022204505279660225, "Value Loss": 8.043770503718406e-05, "_runtime": 10285.000538825989, "_timestamp": 1585580200.8451722, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02184675633907318, "Value Loss": 0.00016639959358144552, "_runtime": 10286.573397397995, "_timestamp": 1585580202.4180307, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.022024884819984436, "Value Loss": 2.3136997697292827e-05, "_runtime": 10288.155849218369, "_timestamp": 1585580204.0004826, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021780047565698624, "Value Loss": 8.772793808020651e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 10289.741552829742, "_timestamp": 1585580205.5861862, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021209241822361946, "Value Loss": 0.00034281369880773127, "_runtime": 10291.315627336502, "_timestamp": 1585580207.1602607, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021571289747953415, "Value Loss": 2.2170383090269752e-05, "_runtime": 10292.899395942688, "_timestamp": 1585580208.7440293, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021314937621355057, "Value Loss": 0.0005036670481786132, "_runtime": 10294.47471666336, "_timestamp": 1585580210.31935, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02099812589585781, "Value Loss": 0.0006250878795981407, "_runtime": 10296.059699296951, "_timestamp": 1585580211.9043326, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021487724035978317, "Value Loss": 0.0001161879044957459, "_runtime": 10297.68370103836, "_timestamp": 1585580213.5283344, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02158903144299984, "Value Loss": 1.2599296496773604e-05, "_runtime": 10299.269781827927, "_timestamp": 1585580215.1144152, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02164326421916485, "Value Loss": 3.3826181606855243e-05, "_runtime": 10300.855662107468, "_timestamp": 1585580216.7002954, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.021229440346360207, "Value Loss": 0.0001040987262967974, "_runtime": 10302.429815292358, "_timestamp": 1585580218.2744486, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02105356752872467, "Value Loss": 3.8788290112279356e-05, "_runtime": 10304.002610445023, "_timestamp": 1585580219.8472438, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0203214343637228, "Value Loss": 0.0006016212282702327, "_runtime": 10305.58771109581, "_timestamp": 1585580221.4323444, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020808259025216103, "Value Loss": 1.0774493603094015e-05, "_runtime": 10307.156793832779, "_timestamp": 1585580223.0014272, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02020157314836979, "Value Loss": 0.0003485493070911616, "_runtime": 10308.720457553864, "_timestamp": 1585580224.565091, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020380781963467598, "Value Loss": 3.701221430674195e-05, "_runtime": 10310.283010482788, "_timestamp": 1585580226.1276438, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02036484144628048, "Value Loss": 4.4730732042808086e-05, "_runtime": 10311.84447646141, "_timestamp": 1585580227.6891098, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020015211775898933, "Value Loss": 2.9134211217751727e-05, "_runtime": 10313.418559074402, "_timestamp": 1585580229.2631924, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019715765491127968, "Value Loss": 4.034429366583936e-05, "_runtime": 10314.99014210701, "_timestamp": 1585580230.8347754, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01908698119223118, "Value Loss": 7.089773134794086e-05, "_runtime": 10316.561152935028, "_timestamp": 1585580232.4057863, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018169019371271133, "Value Loss": 0.0003209727583453059, "_runtime": 10318.134453296661, "_timestamp": 1585580233.9790866, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017844054847955704, "Value Loss": 0.0002757822803687304, "_runtime": 10319.743732213974, "_timestamp": 1585580235.5883656, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017685092985630035, "Value Loss": 0.00017827426199801266, "_runtime": 10321.302687168121, "_timestamp": 1585580237.1473205, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017264246940612793, "Value Loss": 0.000236996726016514, "_runtime": 10322.879733085632, "_timestamp": 1585580238.7243664, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.017493830993771553, "Value Loss": 1.6989457435556687e-05, "_runtime": 10324.444160938263, "_timestamp": 1585580240.2887943, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01725137047469616, "Value Loss": 5.947059617028572e-05, "_runtime": 10326.013989925385, "_timestamp": 1585580241.8586233, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01608486846089363, "Value Loss": 0.0003084746131207794, "_runtime": 10327.575928926468, "_timestamp": 1585580243.4205623, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015644416213035583, "Value Loss": 0.0003660725778900087, "_runtime": 10329.150094747543, "_timestamp": 1585580244.994728, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01588529534637928, "Value Loss": 4.524317046161741e-05, "_runtime": 10330.722890138626, "_timestamp": 1585580246.5675235, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01503858994692564, "Value Loss": 0.00019643297127913684, "_runtime": 10332.285786867142, "_timestamp": 1585580248.1304202, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014497663825750351, "Value Loss": 1.84862146852538e-05, "_runtime": 10333.861238956451, "_timestamp": 1585580249.7058723, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014825660735368729, "Value Loss": 5.8689223806140944e-05, "_runtime": 10335.431699514389, "_timestamp": 1585580251.2763329, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014248198829591274, "Value Loss": 0.0001329399092355743, "_runtime": 10336.996397018433, "_timestamp": 1585580252.8410304, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013595596887171268, "Value Loss": 5.915203655604273e-05, "_runtime": 10338.57383275032, "_timestamp": 1585580254.418466, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013447536155581474, "Value Loss": 2.3362194042420015e-05, "_runtime": 10340.145713329315, "_timestamp": 1585580255.9903467, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01344878226518631, "Value Loss": 1.9366463675396517e-05, "_runtime": 10341.722400426865, "_timestamp": 1585580257.5670338, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013086887076497078, "Value Loss": 7.830565300537273e-05, "_runtime": 10343.344280481339, "_timestamp": 1585580259.1889138, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013250136747956276, "Value Loss": 6.089540329412557e-05, "_runtime": 10344.929966688156, "_timestamp": 1585580260.7746, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012416312471032143, "Value Loss": 0.0004041238862555474, "_runtime": 10346.512994289398, "_timestamp": 1585580262.3576276, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012773345224559307, "Value Loss": 1.391746900480939e-05, "_runtime": 10348.096111774445, "_timestamp": 1585580263.940745, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012712782248854637, "Value Loss": 3.558072057785466e-05, "_runtime": 10349.680160045624, "_timestamp": 1585580265.5247934, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012205217033624649, "Value Loss": 3.140862099826336e-05, "_runtime": 10351.25344491005, "_timestamp": 1585580267.0980783, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011808094568550587, "Value Loss": 9.083791519515216e-05, "_runtime": 10352.83718752861, "_timestamp": 1585580268.6818209, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012078981846570969, "Value Loss": 0.0003373868821654469, "_runtime": 10354.419200658798, "_timestamp": 1585580270.263834, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012269487604498863, "Value Loss": 8.552416693419218e-05, "_runtime": 10356.003594398499, "_timestamp": 1585580271.8482277, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012492000125348568, "Value Loss": 0.00016255529772024602, "_runtime": 10357.58844447136, "_timestamp": 1585580273.4330778, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012245062738656998, "Value Loss": 0.000356596166966483, "_runtime": 10359.170897006989, "_timestamp": 1585580275.0155303, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012827680446207523, "Value Loss": 8.47170886117965e-05, "_runtime": 10360.745018005371, "_timestamp": 1585580276.5896513, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013297881931066513, "Value Loss": 0.000186485456652008, "_runtime": 10362.329871177673, "_timestamp": 1585580278.1745045, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01394455786794424, "Value Loss": 1.5439527487615123e-05, "_runtime": 10363.913085222244, "_timestamp": 1585580279.7577186, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01399589329957962, "Value Loss": 1.570399217598606e-05, "_runtime": 10365.488690376282, "_timestamp": 1585580281.3333237, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013659230433404446, "Value Loss": 0.00011708037345670164, "_runtime": 10367.10847401619, "_timestamp": 1585580282.9531074, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01358194462954998, "Value Loss": 0.000593092292547226, "_runtime": 10368.69398522377, "_timestamp": 1585580284.5386186, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014393741264939308, "Value Loss": 9.990907528845128e-06, "_runtime": 10370.269201517105, "_timestamp": 1585580286.1138349, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013714440166950226, "Value Loss": 0.00029415771132335067, "_runtime": 10371.844661474228, "_timestamp": 1585580287.6892948, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01433132030069828, "Value Loss": 5.897988012293354e-05, "_runtime": 10373.418200731277, "_timestamp": 1585580289.262834, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013288546353578568, "Value Loss": 4.599577732733451e-05, "_runtime": 10375.0063123703, "_timestamp": 1585580290.8509457, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013160846196115017, "Value Loss": 0.00021222290524747223, "_runtime": 10376.581336259842, "_timestamp": 1585580292.4259696, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01236248854547739, "Value Loss": 9.38100929488428e-05, "_runtime": 10378.1656498909, "_timestamp": 1585580294.0102832, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011575794778764248, "Value Loss": 0.00021780116367153823, "_runtime": 10379.752393484116, "_timestamp": 1585580295.5970268, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011560461483895779, "Value Loss": 5.458493251353502e-05, "_runtime": 10381.339849472046, "_timestamp": 1585580297.1844828, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010422409512102604, "Value Loss": 0.00020358122128527611, "_runtime": 10382.913862466812, "_timestamp": 1585580298.7584958, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010105295106768608, "Value Loss": 1.4012616702530067e-05, "_runtime": 10384.47871851921, "_timestamp": 1585580300.3233519, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009702969342470169, "Value Loss": 2.7933238015975803e-05, "_runtime": 10386.053868055344, "_timestamp": 1585580301.8985014, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008780814707279205, "Value Loss": 0.0004949555150233209, "_runtime": 10387.63895893097, "_timestamp": 1585580303.4835923, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009541924111545086, "Value Loss": 0.00010399524035165086, "_runtime": 10389.22601032257, "_timestamp": 1585580305.0706437, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010107602924108505, "Value Loss": 4.7255653043976054e-05, "_runtime": 10390.846762418747, "_timestamp": 1585580306.6913958, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010158664546906948, "Value Loss": 1.0773747817438561e-05, "_runtime": 10392.430071592331, "_timestamp": 1585580308.274705, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009883459657430649, "Value Loss": 0.00030201624031178653, "_runtime": 10394.01821231842, "_timestamp": 1585580309.8628457, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010021941736340523, "Value Loss": 0.00024389092868659645, "_runtime": 10395.593756914139, "_timestamp": 1585580311.4383903, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010268685407936573, "Value Loss": 7.049555279081687e-05, "_runtime": 10397.168553829193, "_timestamp": 1585580313.0131872, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010419171303510666, "Value Loss": 0.0004998547956347466, "_runtime": 10398.736329078674, "_timestamp": 1585580314.5809624, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011318045668303967, "Value Loss": 3.05155263049528e-05, "_runtime": 10400.326657533646, "_timestamp": 1585580316.1712909, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011155192740261555, "Value Loss": 0.00021100933372508734, "_runtime": 10401.91572189331, "_timestamp": 1585580317.7603552, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010953621938824654, "Value Loss": 0.00048200294259004295, "_runtime": 10403.51335477829, "_timestamp": 1585580319.357988, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011745222844183445, "Value Loss": 0.0002057109377346933, "_runtime": 10405.10277891159, "_timestamp": 1585580320.9474123, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01145230047404766, "Value Loss": 0.00033597153378650546, "_runtime": 10406.702004671097, "_timestamp": 1585580322.546638, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011944688856601715, "Value Loss": 4.875398371950723e-05, "_runtime": 10408.290465593338, "_timestamp": 1585580324.135099, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012222753837704659, "Value Loss": 8.806996447674464e-06, "_runtime": 10409.88980293274, "_timestamp": 1585580325.7344363, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012249846942722797, "Value Loss": 1.1910524335689843e-05, "_runtime": 10411.486074924469, "_timestamp": 1585580327.3307083, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011776048690080643, "Value Loss": 0.0003530454996507615, "_runtime": 10413.085865736008, "_timestamp": 1585580328.930499, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011427806690335274, "Value Loss": 0.00019096962932962924, "_runtime": 10414.715521097183, "_timestamp": 1585580330.5601544, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011051376350224018, "Value Loss": 0.00029083454865030944, "_runtime": 10416.318308591843, "_timestamp": 1585580332.162942, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010821077972650528, "Value Loss": 0.0002017324441112578, "_runtime": 10417.918513774872, "_timestamp": 1585580333.763147, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010670973919332027, "Value Loss": 0.00016698322724550962, "_runtime": 10419.516098737717, "_timestamp": 1585580335.360732, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010148974135518074, "Value Loss": 3.244289837311953e-05, "_runtime": 10421.112670898438, "_timestamp": 1585580336.9573042, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010432027280330658, "Value Loss": 0.00016828515799716115, "_runtime": 10422.699524879456, "_timestamp": 1585580338.5441582, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010379064828157425, "Value Loss": 4.14482165069785e-05, "_runtime": 10424.29336810112, "_timestamp": 1585580340.1380014, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010572421364486217, "Value Loss": 1.589495877851732e-05, "_runtime": 10425.881266117096, "_timestamp": 1585580341.7258995, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009837544523179531, "Value Loss": 0.000221907946979627, "_runtime": 10427.471528053284, "_timestamp": 1585580343.3161614, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009977039881050587, "Value Loss": 0.0005922989221289754, "_runtime": 10429.060672521591, "_timestamp": 1585580344.9053059, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010347208008170128, "Value Loss": 7.929153798613697e-05, "_runtime": 10430.646956920624, "_timestamp": 1585580346.4915903, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011366680264472961, "Value Loss": 5.6580247473903e-05, "_runtime": 10432.24625134468, "_timestamp": 1585580348.0908847, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011310196481645107, "Value Loss": 1.934922329382971e-05, "_runtime": 10433.846574544907, "_timestamp": 1585580349.691208, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011513011530041695, "Value Loss": 0.00016778461576905102, "_runtime": 10435.43579864502, "_timestamp": 1585580351.280432, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01251907180994749, "Value Loss": 6.068548827897757e-05, "_runtime": 10437.061681985855, "_timestamp": 1585580352.9063153, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012391443364322186, "Value Loss": 7.300225115614012e-05, "_runtime": 10438.659116268158, "_timestamp": 1585580354.5037496, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013025540858507156, "Value Loss": 0.00010807838407345116, "_runtime": 10440.257766962051, "_timestamp": 1585580356.1024003, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013240629807114601, "Value Loss": 0.00036463947617448866, "_runtime": 10441.846880674362, "_timestamp": 1585580357.691514, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013890605419874191, "Value Loss": 0.000250128039624542, "_runtime": 10443.437494754791, "_timestamp": 1585580359.282128, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01494324766099453, "Value Loss": 5.2844839956378564e-05, "_runtime": 10445.035871982574, "_timestamp": 1585580360.8805053, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014610831625759602, "Value Loss": 0.00014612008817493916, "_runtime": 10446.613035917282, "_timestamp": 1585580362.4576693, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014176110737025738, "Value Loss": 0.0005514525109902024, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 10448.213391542435, "_timestamp": 1585580364.058025, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.014570025727152824, "Value Loss": 0.00022184455883689225, "_runtime": 10448.213391542435, "_timestamp": 1585580364.058025, "_step": 499}
