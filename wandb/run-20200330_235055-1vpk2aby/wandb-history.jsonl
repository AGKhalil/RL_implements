{"Episode reward": -35.22808753995745, "Episode length": 999, "Policy Loss": -0.04247225075960159, "Value Loss": 0.06538115441799164, "_runtime": 14905.146976947784, "_timestamp": 1585612274.7798464, "_step": 0}
{"Episode reward": -89.60267136231876, "Episode length": 999, "Policy Loss": 0.4042983651161194, "Value Loss": 43.04649353027344, "_runtime": 14906.673841953278, "_timestamp": 1585612276.3067114, "_step": 1}
{"Episode reward": -94.18717856103605, "Episode length": 999, "Policy Loss": -0.6915975213050842, "Value Loss": 2548.782470703125, "_runtime": 14908.264506816864, "_timestamp": 1585612277.8973763, "_step": 2}
{"Episode reward": -88.6271619712246, "Episode length": 999, "Policy Loss": -4.634878158569336, "Value Loss": 3530.479248046875, "_runtime": 14909.83490896225, "_timestamp": 1585612279.4677784, "_step": 3}
{"Episode reward": -87.26112585496391, "Episode length": 999, "Policy Loss": 1.7349380254745483, "Value Loss": 91.77243041992188, "_runtime": 14911.382411241531, "_timestamp": 1585612281.0152807, "_step": 4}
{"Episode reward": -83.99065907238369, "Episode length": 999, "Policy Loss": 4.2485246658325195, "Value Loss": 450.0970458984375, "_runtime": 14912.98304271698, "_timestamp": 1585612282.6159122, "_step": 5}
{"Episode reward": -85.28777998793825, "Episode length": 999, "Policy Loss": 2.5850119590759277, "Value Loss": 85.80450439453125, "_runtime": 14914.552339315414, "_timestamp": 1585612284.1852088, "_step": 6}
{"Episode reward": -75.77116657663282, "Episode length": 999, "Policy Loss": 0.14036084711551666, "Value Loss": 101.09223175048828, "_runtime": 14916.09745812416, "_timestamp": 1585612285.7303276, "_step": 7}
{"Episode reward": -60.96761746413616, "Episode length": 999, "Policy Loss": 0.18180930614471436, "Value Loss": 21.1529541015625, "_runtime": 14917.689191818237, "_timestamp": 1585612287.3220613, "_step": 8}
{"Episode reward": -42.69813511682137, "Episode length": 999, "Policy Loss": -0.025062520056962967, "Value Loss": 10.4326171875, "_runtime": 14919.27092385292, "_timestamp": 1585612288.9037933, "_step": 9}
{"Episode reward": -33.967783997641746, "Episode length": 999, "Policy Loss": -0.024931402876973152, "Value Loss": 0.9739716649055481, "_runtime": 14920.835564374924, "_timestamp": 1585612290.4684339, "_step": 10}
{"Episode reward": -31.328406093095683, "Episode length": 999, "Policy Loss": -0.13106127083301544, "Value Loss": 0.405781090259552, "_runtime": 14922.45291852951, "_timestamp": 1585612292.085788, "_step": 11}
{"Episode reward": -36.150340114555256, "Episode length": 999, "Policy Loss": -0.17857395112514496, "Value Loss": 1.5220681428909302, "_runtime": 14924.056830406189, "_timestamp": 1585612293.6897, "_step": 12}
{"Episode reward": -47.94145743609004, "Episode length": 999, "Policy Loss": -0.09292544424533844, "Value Loss": 8.837617874145508, "_runtime": 14925.64614367485, "_timestamp": 1585612295.2790132, "_step": 13}
{"Episode reward": -70.63404789737397, "Episode length": 999, "Policy Loss": -0.08505809307098389, "Value Loss": 9.447134017944336, "_runtime": 14927.28748369217, "_timestamp": 1585612296.9203532, "_step": 14}
{"Episode reward": -97.94226197291812, "Episode length": 999, "Policy Loss": 3.6282472610473633, "Value Loss": 155.8646697998047, "_runtime": 14928.89273428917, "_timestamp": 1585612298.5256038, "_step": 15}
{"Episode reward": -67.72964117658964, "Episode length": 999, "Policy Loss": -0.1381005346775055, "Value Loss": 0.1571044772863388, "_runtime": 14930.484197616577, "_timestamp": 1585612300.117067, "_step": 16}
{"Episode reward": -40.467320299153585, "Episode length": 999, "Policy Loss": -0.2658914029598236, "Value Loss": 0.34948229789733887, "_runtime": 14932.09471487999, "_timestamp": 1585612301.7275844, "_step": 17}
{"Episode reward": -35.280230811845065, "Episode length": 999, "Policy Loss": -0.32145848870277405, "Value Loss": 0.384147584438324, "_runtime": 14933.698414802551, "_timestamp": 1585612303.3312843, "_step": 18}
{"Episode reward": -42.015202270759886, "Episode length": 999, "Policy Loss": -0.4008951187133789, "Value Loss": 0.5712618231773376, "_runtime": 14935.287657022476, "_timestamp": 1585612304.9205265, "_step": 19}
{"Episode reward": -49.43969266657643, "Episode length": 999, "Policy Loss": -0.45330938696861267, "Value Loss": 0.872560977935791, "_runtime": 14936.889819860458, "_timestamp": 1585612306.5226893, "_step": 20}
{"Episode reward": -54.410266150503716, "Episode length": 999, "Policy Loss": -0.42859044671058655, "Value Loss": 1.9567352533340454, "_runtime": 14938.497731924057, "_timestamp": 1585612308.1306014, "_step": 21}
{"Episode reward": -57.11056051094196, "Episode length": 999, "Policy Loss": -0.5618270039558411, "Value Loss": 1.8012101650238037, "_runtime": 14940.094473361969, "_timestamp": 1585612309.7273428, "_step": 22}
{"Episode reward": -62.008420124937686, "Episode length": 999, "Policy Loss": -0.11773473769426346, "Value Loss": 9.088315963745117, "_runtime": 14941.703356266022, "_timestamp": 1585612311.3362257, "_step": 23}
{"Episode reward": -61.093635288842925, "Episode length": 999, "Policy Loss": -0.5069926381111145, "Value Loss": 3.4937069416046143, "_runtime": 14943.313075304031, "_timestamp": 1585612312.9459448, "_step": 24}
{"Episode reward": -62.90282779041358, "Episode length": 999, "Policy Loss": -0.46766334772109985, "Value Loss": 2.9869861602783203, "_runtime": 14944.910477161407, "_timestamp": 1585612314.5433466, "_step": 25}
{"Episode reward": -67.10973631438218, "Episode length": 999, "Policy Loss": -0.45271816849708557, "Value Loss": 3.5017893314361572, "_runtime": 14946.503324270248, "_timestamp": 1585612316.1361938, "_step": 26}
{"Episode reward": -63.44930353223024, "Episode length": 999, "Policy Loss": -0.46919894218444824, "Value Loss": 0.6336851716041565, "_runtime": 14948.107006788254, "_timestamp": 1585612317.7398763, "_step": 27}
{"Episode reward": -60.917314194109935, "Episode length": 999, "Policy Loss": -0.44975289702415466, "Value Loss": 0.6616303324699402, "_runtime": 14949.74145412445, "_timestamp": 1585612319.3743236, "_step": 28}
{"Episode reward": -63.611159151564664, "Episode length": 999, "Policy Loss": -0.4514949917793274, "Value Loss": 0.5445706844329834, "_runtime": 14951.333477973938, "_timestamp": 1585612320.9663475, "_step": 29}
{"Episode reward": -62.78386625724553, "Episode length": 999, "Policy Loss": -0.4444620609283447, "Value Loss": 0.9603223204612732, "_runtime": 14952.92950630188, "_timestamp": 1585612322.5623758, "_step": 30}
{"Episode reward": -61.833086001199725, "Episode length": 999, "Policy Loss": -0.3994697332382202, "Value Loss": 0.5055546760559082, "_runtime": 14954.52804350853, "_timestamp": 1585612324.160913, "_step": 31}
{"Episode reward": -60.209693115890886, "Episode length": 999, "Policy Loss": -0.39818698167800903, "Value Loss": 0.4549447000026703, "_runtime": 14956.134630203247, "_timestamp": 1585612325.7674997, "_step": 32}
{"Episode reward": -56.8622806002802, "Episode length": 999, "Policy Loss": -0.387515664100647, "Value Loss": 0.2876640856266022, "_runtime": 14957.741766691208, "_timestamp": 1585612327.3746362, "_step": 33}
{"Episode reward": -52.714024929298766, "Episode length": 999, "Policy Loss": -0.3356325030326843, "Value Loss": 0.24329595267772675, "_runtime": 14959.344744682312, "_timestamp": 1585612328.9776142, "_step": 34}
{"Episode reward": -56.64707646081486, "Episode length": 999, "Policy Loss": -0.3601802885532379, "Value Loss": 0.20249469578266144, "_runtime": 14960.951102018356, "_timestamp": 1585612330.5839715, "_step": 35}
{"Episode reward": -57.292339631994615, "Episode length": 999, "Policy Loss": -0.3337205648422241, "Value Loss": 0.22153843939304352, "_runtime": 14962.548362970352, "_timestamp": 1585612332.1812325, "_step": 36}
{"Episode reward": -56.02235283483467, "Episode length": 999, "Policy Loss": -0.3272421061992645, "Value Loss": 0.19378896057605743, "_runtime": 14964.14664721489, "_timestamp": 1585612333.7795167, "_step": 37}
{"Episode reward": -54.97967317747526, "Episode length": 999, "Policy Loss": -0.2874671220779419, "Value Loss": 0.20485518872737885, "_runtime": 14965.75649356842, "_timestamp": 1585612335.389363, "_step": 38}
{"Episode reward": -54.78828086888233, "Episode length": 999, "Policy Loss": -0.3064296245574951, "Value Loss": 0.14901573956012726, "_runtime": 14967.353513002396, "_timestamp": 1585612336.9863825, "_step": 39}
{"Episode reward": -56.11050764532351, "Episode length": 999, "Policy Loss": -0.29784560203552246, "Value Loss": 0.13527338206768036, "_runtime": 14968.953783512115, "_timestamp": 1585612338.586653, "_step": 40}
{"Episode reward": -51.158766865570726, "Episode length": 999, "Policy Loss": -0.2931096851825714, "Value Loss": 0.07956931740045547, "_runtime": 14970.54775595665, "_timestamp": 1585612340.1806254, "_step": 41}
{"Episode reward": -48.4264806737919, "Episode length": 999, "Policy Loss": -0.2674923837184906, "Value Loss": 0.07002302259206772, "_runtime": 14972.152844429016, "_timestamp": 1585612341.785714, "_step": 42}
{"Episode reward": -43.80072298053899, "Episode length": 999, "Policy Loss": -0.23189355432987213, "Value Loss": 0.08745928853750229, "_runtime": 14973.777823209763, "_timestamp": 1585612343.4106927, "_step": 43}
{"Episode reward": -40.39111446341278, "Episode length": 999, "Policy Loss": -0.20837587118148804, "Value Loss": 0.05792967230081558, "_runtime": 14975.38187289238, "_timestamp": 1585612345.0147424, "_step": 44}
{"Episode reward": -38.26390509285675, "Episode length": 999, "Policy Loss": -0.19515211880207062, "Value Loss": 0.05127498880028725, "_runtime": 14976.976463317871, "_timestamp": 1585612346.6093328, "_step": 45}
{"Episode reward": -38.646281542716, "Episode length": 999, "Policy Loss": -0.1983998566865921, "Value Loss": 0.04333431273698807, "_runtime": 14978.575814723969, "_timestamp": 1585612348.2086842, "_step": 46}
{"Episode reward": -35.60099284692236, "Episode length": 999, "Policy Loss": -0.1399231255054474, "Value Loss": 0.039487916976213455, "_runtime": 14980.17958164215, "_timestamp": 1585612349.8124511, "_step": 47}
{"Episode reward": -37.183685162742236, "Episode length": 999, "Policy Loss": -0.12079396098852158, "Value Loss": 0.03536587953567505, "_runtime": 14981.783935308456, "_timestamp": 1585612351.4168048, "_step": 48}
{"Episode reward": -54.253364129452116, "Episode length": 999, "Policy Loss": -0.09163862466812134, "Value Loss": 0.039137400686740875, "_runtime": 14983.382778167725, "_timestamp": 1585612353.0156476, "_step": 49}
{"Episode reward": -66.11647474816124, "Episode length": 999, "Policy Loss": -0.0772390142083168, "Value Loss": 0.04278331622481346, "_runtime": 14984.986893415451, "_timestamp": 1585612354.619763, "_step": 50}
{"Episode reward": -84.6998023032668, "Episode length": 999, "Policy Loss": -0.03703375160694122, "Value Loss": 0.046371594071388245, "_runtime": 14986.591657400131, "_timestamp": 1585612356.224527, "_step": 51}
{"Episode reward": -93.75427647557915, "Episode length": 999, "Policy Loss": -0.011470210738480091, "Value Loss": 0.048475123941898346, "_runtime": 14988.190069198608, "_timestamp": 1585612357.8229387, "_step": 52}
{"Episode reward": -93.30075867965762, "Episode length": 999, "Policy Loss": -0.0050794403068721294, "Value Loss": 0.046034328639507294, "_runtime": 14989.792857408524, "_timestamp": 1585612359.425727, "_step": 53}
{"Episode reward": -97.47598405236897, "Episode length": 999, "Policy Loss": 0.021772436797618866, "Value Loss": 0.04679786041378975, "_runtime": 14991.386415958405, "_timestamp": 1585612361.0192854, "_step": 54}
{"Episode reward": -94.73754076570128, "Episode length": 999, "Policy Loss": 0.028879476711153984, "Value Loss": 0.043894924223423004, "_runtime": 14992.985174417496, "_timestamp": 1585612362.618044, "_step": 55}
{"Episode reward": -94.31256502872873, "Episode length": 999, "Policy Loss": -0.00296511547639966, "Value Loss": 0.04134337976574898, "_runtime": 14994.58822131157, "_timestamp": 1585612364.2210908, "_step": 56}
{"Episode reward": -93.02069177338598, "Episode length": 999, "Policy Loss": -0.004786201287060976, "Value Loss": 0.03866733983159065, "_runtime": 14996.191054344177, "_timestamp": 1585612365.8239238, "_step": 57}
{"Episode reward": -93.95634505583118, "Episode length": 999, "Policy Loss": -0.007471505086869001, "Value Loss": 0.03766505792737007, "_runtime": 14997.824938058853, "_timestamp": 1585612367.4578075, "_step": 58}
{"Episode reward": -94.71486554046754, "Episode length": 999, "Policy Loss": -0.009453498758375645, "Value Loss": 0.03624678775668144, "_runtime": 14999.433466911316, "_timestamp": 1585612369.0663364, "_step": 59}
{"Episode reward": -92.69725671323377, "Episode length": 999, "Policy Loss": -0.008368107490241528, "Value Loss": 0.0341348722577095, "_runtime": 15001.039415359497, "_timestamp": 1585612370.6722848, "_step": 60}
{"Episode reward": -95.30659618340216, "Episode length": 999, "Policy Loss": -0.00466911168769002, "Value Loss": 0.033546801656484604, "_runtime": 15002.639116287231, "_timestamp": 1585612372.2719858, "_step": 61}
{"Episode reward": -93.5502459190159, "Episode length": 999, "Policy Loss": -0.011693223379552364, "Value Loss": 0.03167624771595001, "_runtime": 15004.244540929794, "_timestamp": 1585612373.8774104, "_step": 62}
{"Episode reward": -94.33639768310991, "Episode length": 999, "Policy Loss": -0.0003930057573597878, "Value Loss": 0.030568253248929977, "_runtime": 15005.850725412369, "_timestamp": 1585612375.483595, "_step": 63}
{"Episode reward": -94.7352678113379, "Episode length": 999, "Policy Loss": 0.006527252960950136, "Value Loss": 0.02944248542189598, "_runtime": 15007.439888715744, "_timestamp": 1585612377.0727582, "_step": 64}
{"Episode reward": -96.38998952596357, "Episode length": 999, "Policy Loss": 0.027199555188417435, "Value Loss": 0.028606217354536057, "_runtime": 15009.0476770401, "_timestamp": 1585612378.6805465, "_step": 65}
{"Episode reward": -95.94021114714361, "Episode length": 999, "Policy Loss": 0.025138424709439278, "Value Loss": 0.02727126143872738, "_runtime": 15010.654350757599, "_timestamp": 1585612380.2872202, "_step": 66}
{"Episode reward": -95.89629074467086, "Episode length": 999, "Policy Loss": 0.02793607860803604, "Value Loss": 0.026130473241209984, "_runtime": 15012.24832201004, "_timestamp": 1585612381.8811915, "_step": 67}
{"Episode reward": -93.373626567563, "Episode length": 999, "Policy Loss": -0.007952476851642132, "Value Loss": 0.024286404252052307, "_runtime": 15013.854494333267, "_timestamp": 1585612383.4873638, "_step": 68}
{"Episode reward": -66.19995294699503, "Episode length": 999, "Policy Loss": -0.05009207874536514, "Value Loss": 0.0166167002171278, "_runtime": 15015.450829029083, "_timestamp": 1585612385.0836985, "_step": 69}
{"Episode reward": -41.8420699552447, "Episode length": 999, "Policy Loss": -0.06763064116239548, "Value Loss": 0.010634665377438068, "_runtime": 15017.051951408386, "_timestamp": 1585612386.684821, "_step": 70}
{"Episode reward": -34.040248431882155, "Episode length": 999, "Policy Loss": -0.08028454333543777, "Value Loss": 0.00848325528204441, "_runtime": 15018.6590924263, "_timestamp": 1585612388.291962, "_step": 71}
{"Episode reward": -39.59912141340776, "Episode length": 999, "Policy Loss": -0.0972033366560936, "Value Loss": 0.009157465770840645, "_runtime": 15020.263224363327, "_timestamp": 1585612389.8960938, "_step": 72}
{"Episode reward": -42.93640971650428, "Episode length": 999, "Policy Loss": -0.10148513317108154, "Value Loss": 0.009350936859846115, "_runtime": 15021.905146360397, "_timestamp": 1585612391.5380158, "_step": 73}
{"Episode reward": -47.67302579830707, "Episode length": 999, "Policy Loss": -0.11093513667583466, "Value Loss": 0.009861273691058159, "_runtime": 15023.512340784073, "_timestamp": 1585612393.1452103, "_step": 74}
{"Episode reward": -50.38030458696627, "Episode length": 999, "Policy Loss": -0.12071926146745682, "Value Loss": 0.009838944301009178, "_runtime": 15025.107060432434, "_timestamp": 1585612394.73993, "_step": 75}
{"Episode reward": -54.926339992369684, "Episode length": 999, "Policy Loss": -0.12625399231910706, "Value Loss": 0.0102872084826231, "_runtime": 15026.69810461998, "_timestamp": 1585612396.330974, "_step": 76}
{"Episode reward": -57.516716271971724, "Episode length": 999, "Policy Loss": -0.13440048694610596, "Value Loss": 0.010332649573683739, "_runtime": 15028.30555820465, "_timestamp": 1585612397.9384277, "_step": 77}
{"Episode reward": -57.86555346484663, "Episode length": 999, "Policy Loss": -0.12680107355117798, "Value Loss": 0.010097045451402664, "_runtime": 15029.901696920395, "_timestamp": 1585612399.5345664, "_step": 78}
{"Episode reward": -59.97862642282828, "Episode length": 999, "Policy Loss": -0.1340246945619583, "Value Loss": 0.0100459735840559, "_runtime": 15031.505096912384, "_timestamp": 1585612401.1379664, "_step": 79}
{"Episode reward": -61.57150838419089, "Episode length": 999, "Policy Loss": -0.13585202395915985, "Value Loss": 0.009860931895673275, "_runtime": 15033.11059975624, "_timestamp": 1585612402.7434692, "_step": 80}
{"Episode reward": -63.54168358260602, "Episode length": 999, "Policy Loss": -0.13957589864730835, "Value Loss": 0.009900031611323357, "_runtime": 15034.716802358627, "_timestamp": 1585612404.3496718, "_step": 81}
{"Episode reward": -63.44585693958738, "Episode length": 999, "Policy Loss": -0.13336081802845, "Value Loss": 0.009477957151830196, "_runtime": 15036.31081366539, "_timestamp": 1585612405.9436831, "_step": 82}
{"Episode reward": -62.845734740230675, "Episode length": 999, "Policy Loss": -0.12890209257602692, "Value Loss": 0.008838417939841747, "_runtime": 15037.907308578491, "_timestamp": 1585612407.540178, "_step": 83}
{"Episode reward": -64.4028037659522, "Episode length": 999, "Policy Loss": -0.13049182295799255, "Value Loss": 0.009458399377763271, "_runtime": 15039.503247976303, "_timestamp": 1585612409.1361175, "_step": 84}
{"Episode reward": -65.76704057514229, "Episode length": 999, "Policy Loss": -0.13398437201976776, "Value Loss": 0.008712164126336575, "_runtime": 15041.102956295013, "_timestamp": 1585612410.7358258, "_step": 85}
{"Episode reward": -61.889513066414665, "Episode length": 999, "Policy Loss": -0.11955564469099045, "Value Loss": 0.008232279680669308, "_runtime": 15042.711030721664, "_timestamp": 1585612412.3439002, "_step": 86}
{"Episode reward": -65.93763487121606, "Episode length": 999, "Policy Loss": -0.12646572291851044, "Value Loss": 0.008151141926646233, "_runtime": 15044.35503077507, "_timestamp": 1585612413.9879003, "_step": 87}
{"Episode reward": -69.04214805958547, "Episode length": 999, "Policy Loss": -0.1281706839799881, "Value Loss": 0.008286167867481709, "_runtime": 15045.95642375946, "_timestamp": 1585612415.5892932, "_step": 88}
{"Episode reward": -64.33362584927026, "Episode length": 999, "Policy Loss": -0.11643102020025253, "Value Loss": 0.0071644410490989685, "_runtime": 15047.552505016327, "_timestamp": 1585612417.1853745, "_step": 89}
{"Episode reward": -64.79535320109952, "Episode length": 999, "Policy Loss": -0.11557827144861221, "Value Loss": 0.007343976758420467, "_runtime": 15049.147986412048, "_timestamp": 1585612418.780856, "_step": 90}
{"Episode reward": -67.05757060901556, "Episode length": 999, "Policy Loss": -0.12004423886537552, "Value Loss": 0.008031670935451984, "_runtime": 15050.741084098816, "_timestamp": 1585612420.3739536, "_step": 91}
{"Episode reward": -67.52846793928111, "Episode length": 999, "Policy Loss": -0.1152079850435257, "Value Loss": 0.007143350318074226, "_runtime": 15052.335048437119, "_timestamp": 1585612421.967918, "_step": 92}
{"Episode reward": -67.23946105100568, "Episode length": 999, "Policy Loss": -0.11106497794389725, "Value Loss": 0.006991718430072069, "_runtime": 15053.933455705643, "_timestamp": 1585612423.5663252, "_step": 93}
{"Episode reward": -66.42869590566525, "Episode length": 999, "Policy Loss": -0.10725763440132141, "Value Loss": 0.00646322313696146, "_runtime": 15055.526452541351, "_timestamp": 1585612425.159322, "_step": 94}
{"Episode reward": -67.73887590953942, "Episode length": 999, "Policy Loss": -0.10734085738658905, "Value Loss": 0.006682217586785555, "_runtime": 15057.124164581299, "_timestamp": 1585612426.757034, "_step": 95}
{"Episode reward": -69.53930032883176, "Episode length": 999, "Policy Loss": -0.10738591104745865, "Value Loss": 0.006156081799417734, "_runtime": 15058.730468511581, "_timestamp": 1585612428.363338, "_step": 96}
{"Episode reward": -66.27918755149355, "Episode length": 999, "Policy Loss": -0.10108925402164459, "Value Loss": 0.005437945481389761, "_runtime": 15060.333518981934, "_timestamp": 1585612429.9663885, "_step": 97}
{"Episode reward": -65.45535232050884, "Episode length": 999, "Policy Loss": -0.09799282997846603, "Value Loss": 0.005394880194216967, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168, -6.598811149597168]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0], "bins": [-6.690816879272461, -6.513311862945557, -6.335806369781494, -6.15830135345459, -5.980795860290527, -5.803290843963623, -5.625785827636719, -5.448280334472656, -5.270775318145752, -5.093270301818848, -4.915764808654785, -4.738259792327881, -4.560754776000977, -4.383249282836914, -4.20574426651001, -4.0282392501831055, -3.850733757019043, -3.6732285022735596, -3.495723247528076, -3.318218231201172, -3.1407129764556885, -2.963207721710205, -2.785702705383301, -2.6081972122192383, -2.430692195892334, -2.2531871795654297, -2.075681686401367, -1.898176670074463, -1.7206716537475586, -1.543166160583496, -1.3656611442565918, -1.1881556510925293, -1.010650634765625, -0.8331456184387207, -0.6556401252746582, -0.4781351089477539, -0.3006296157836914, -0.12312459945678711, 0.05438041687011719, 0.2318859100341797, 0.409390926361084, 0.5868959426879883, 0.7644014358520508, 0.9419064521789551, 1.1194114685058594, 1.2969169616699219, 1.4744224548339844, 1.6519269943237305, 1.829432487487793, 2.0069379806518555, 2.1844425201416016, 2.361948013305664, 2.5394535064697266, 2.7169580459594727, 2.894463539123535, 3.0719690322875977, 3.2494735717773438, 3.4269790649414062, 3.6044845581054688, 3.7819900512695312, 3.9594945907592773, 4.13700008392334, 4.314505577087402, 4.492010116577148, 4.669515609741211]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.1563644409179688, -2.1012089252471924, -2.046053409576416, -1.9908978939056396, -1.9357423782348633, -1.880586862564087, -1.8254313468933105, -1.7702758312225342, -1.7151203155517578, -1.6599647998809814, -1.604809284210205, -1.5496537685394287, -1.494498372077942, -1.4393428564071655, -1.3841873407363892, -1.3290318250656128, -1.2738763093948364, -1.21872079372406, -1.1635652780532837, -1.1084097623825073, -1.053254246711731, -0.9980987310409546, -0.9429432153701782, -0.8877876996994019, -0.832632303237915, -0.7774767875671387, -0.7223212718963623, -0.6671657562255859, -0.6120102405548096, -0.5568547248840332, -0.5016992092132568, -0.44654369354248047, -0.3913881778717041, -0.33623266220092773, -0.28107714653015137, -0.225921630859375, -0.17076611518859863, -0.11561059951782227, -0.0604550838470459, -0.005299568176269531, 0.049855947494506836, 0.1050114631652832, 0.16016697883605957, 0.21532249450683594, 0.2704780101776123, 0.32563352584838867, 0.38078904151916504, 0.4359445571899414, 0.49109983444213867, 0.546255350112915, 0.6014108657836914, 0.6565663814544678, 0.7117218971252441, 0.7668774127960205, 0.8220329284667969, 0.8771884441375732, 0.9323439598083496, 0.987499475479126, 1.0426549911499023, 1.0978105068206787, 1.152966022491455, 1.2081215381622314, 1.2632770538330078, 1.3184325695037842, 1.3735880851745605]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 6.0, 8.0, 4.0, 13.0, 9.0, 16.0, 16.0, 16.0, 29.0, 23.0, 27.0, 83.0, 101.0, 24.0, 17.0, 20.0, 22.0, 15.0, 13.0, 6.0, 5.0, 5.0, 4.0, 1.0, 5.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], "bins": [-1.0205754041671753, -0.9937405586242676, -0.9669056534767151, -0.9400708079338074, -0.9132359027862549, -0.8864010572433472, -0.8595662117004395, -0.8327313661575317, -0.8058964610099792, -0.7790615558624268, -0.752226710319519, -0.7253918647766113, -0.6985570192337036, -0.6717221140861511, -0.6448872685432434, -0.6180523633956909, -0.5912175178527832, -0.5643826723098755, -0.537547767162323, -0.5107129216194153, -0.4838780164718628, -0.4570431709289551, -0.43020832538604736, -0.4033734202384949, -0.37653857469558716, -0.34970372915267944, -0.32286882400512695, -0.29603397846221924, -0.2691991329193115, -0.24236422777175903, -0.21552938222885132, -0.18869447708129883, -0.1618596315383911, -0.1350247859954834, -0.10818988084793091, -0.0813550353050232, -0.0545201301574707, -0.02768528461456299, -0.0008504390716552734, 0.02598440647125244, 0.05281937122344971, 0.07965421676635742, 0.10648906230926514, 0.13332390785217285, 0.16015875339508057, 0.18699359893798828, 0.21382856369018555, 0.24066340923309326, 0.267498254776001, 0.2943331003189087, 0.3211679458618164, 0.34800291061401367, 0.3748377561569214, 0.4016726016998291, 0.4285074472427368, 0.45534229278564453, 0.48217713832855225, 0.5090121030807495, 0.5358469486236572, 0.5626817941665649, 0.5895166397094727, 0.6163514852523804, 0.6431864500045776, 0.6700212955474854, 0.6968561410903931]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1299428939819336, -2.05063796043396, -1.9713330268859863, -1.8920280933380127, -1.812723159790039, -1.7334182262420654, -1.6541131734848022, -1.5748082399368286, -1.495503306388855, -1.4161983728408813, -1.3368934392929077, -1.2575883865356445, -1.178283452987671, -1.0989785194396973, -1.0196735858917236, -0.94036865234375, -0.8610637187957764, -0.7817587852478027, -0.7024538516998291, -0.6231489181518555, -0.5438439846038818, -0.46453893184661865, -0.385233998298645, -0.3059290647506714, -0.22662413120269775, -0.14731919765472412, -0.06801414489746094, 0.011290788650512695, 0.09059572219848633, 0.16990065574645996, 0.2492055892944336, 0.3285105228424072, 0.40781545639038086, 0.4871203899383545, 0.5664253234863281, 0.6457302570343018, 0.7250351905822754, 0.804340124130249, 0.8836450576782227, 0.9629499912261963, 1.04225492477417, 1.1215600967407227, 1.2008650302886963, 1.28016996383667, 1.3594748973846436, 1.4387798309326172, 1.5180847644805908, 1.5973896980285645, 1.676694631576538, 1.7559995651245117, 1.8353044986724854, 1.914609432220459, 1.9939146041870117, 2.0732192993164062, 2.152524471282959, 2.2318291664123535, 2.3111343383789062, 2.390439033508301, 2.4697442054748535, 2.549048900604248, 2.628354072570801, 2.7076587677001953, 2.786963939666748, 2.8662686347961426, 2.9455738067626953]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 7.0, 13.0, 14.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6321349143981934, -0.6149267554283142, -0.5977185368537903, -0.5805103778839111, -0.5633021593093872, -0.5460940003395081, -0.5288858413696289, -0.511677622795105, -0.49446946382522583, -0.4772612452507019, -0.46005308628082275, -0.4428448975086212, -0.4256367087364197, -0.4084285497665405, -0.3912203311920166, -0.37401217222213745, -0.3568039834499359, -0.3395957946777344, -0.32238760590553284, -0.3051794469356537, -0.28797125816345215, -0.2707630693912506, -0.2535548806190491, -0.23634669184684753, -0.219138503074646, -0.20193034410476685, -0.1847221553325653, -0.16751396656036377, -0.15030577778816223, -0.1330975890159607, -0.11588943004608154, -0.09868121147155762, -0.08147305250167847, -0.06426489353179932, -0.04705667495727539, -0.02984851598739624, -0.012640297412872314, 0.004567861557006836, 0.021776020526885986, 0.03898423910140991, 0.05619239807128906, 0.07340061664581299, 0.09060877561569214, 0.10781693458557129, 0.12502515316009521, 0.14223331212997437, 0.1594415307044983, 0.17664968967437744, 0.19385790824890137, 0.21106606721878052, 0.22827422618865967, 0.2454824447631836, 0.26269060373306274, 0.27989882230758667, 0.2971069812774658, 0.31431514024734497, 0.3315233588218689, 0.34873151779174805, 0.365939736366272, 0.38314783573150635, 0.4003560543060303, 0.4175642728805542, 0.4347724914550781, 0.4519805908203125, 0.4691888093948364]}, "_runtime": 15061.938708305359, "_timestamp": 1585612431.5715778, "_step": 98}
{"Episode reward": -67.31790801081016, "Episode length": 999, "Policy Loss": -0.09631874412298203, "Value Loss": 0.005140742287039757, "_runtime": 15063.544382572174, "_timestamp": 1585612433.177252, "_step": 99}
{"Episode reward": -67.30384967846261, "Episode length": 999, "Policy Loss": -0.09471222013235092, "Value Loss": 0.005161248613148928, "_runtime": 15065.146164894104, "_timestamp": 1585612434.7790344, "_step": 100}
{"Episode reward": -70.59193660941715, "Episode length": 999, "Policy Loss": -0.09819593280553818, "Value Loss": 0.005186866503208876, "_runtime": 15066.75195813179, "_timestamp": 1585612436.3848276, "_step": 101}
{"Episode reward": -71.08559634351751, "Episode length": 999, "Policy Loss": -0.09917091578245163, "Value Loss": 0.005019274074584246, "_runtime": 15068.385918617249, "_timestamp": 1585612438.018788, "_step": 102}
{"Episode reward": -70.78274722304113, "Episode length": 999, "Policy Loss": -0.09395554661750793, "Value Loss": 0.004716986324638128, "_runtime": 15069.98651432991, "_timestamp": 1585612439.6193838, "_step": 103}
{"Episode reward": -66.35288933805538, "Episode length": 999, "Policy Loss": -0.08469543606042862, "Value Loss": 0.004452814348042011, "_runtime": 15071.589595794678, "_timestamp": 1585612441.2224653, "_step": 104}
{"Episode reward": -69.15565140358834, "Episode length": 999, "Policy Loss": -0.08518185466527939, "Value Loss": 0.0043235886842012405, "_runtime": 15073.183826684952, "_timestamp": 1585612442.8166962, "_step": 105}
{"Episode reward": -67.05635968804522, "Episode length": 999, "Policy Loss": -0.08288037776947021, "Value Loss": 0.0041280100122094154, "_runtime": 15074.772685527802, "_timestamp": 1585612444.405555, "_step": 106}
{"Episode reward": -70.35307317346961, "Episode length": 999, "Policy Loss": -0.08277130126953125, "Value Loss": 0.004126475192606449, "_runtime": 15076.374148845673, "_timestamp": 1585612446.0070183, "_step": 107}
{"Episode reward": -68.52831568550519, "Episode length": 999, "Policy Loss": -0.07836300134658813, "Value Loss": 0.0038426232058554888, "_runtime": 15077.976298570633, "_timestamp": 1585612447.609168, "_step": 108}
{"Episode reward": -66.90659989064385, "Episode length": 999, "Policy Loss": -0.07204321026802063, "Value Loss": 0.003591818967834115, "_runtime": 15079.58098244667, "_timestamp": 1585612449.213852, "_step": 109}
{"Episode reward": -66.41784876671457, "Episode length": 999, "Policy Loss": -0.07009643316268921, "Value Loss": 0.003527554217725992, "_runtime": 15081.176764726639, "_timestamp": 1585612450.8096342, "_step": 110}
{"Episode reward": -69.88042480758322, "Episode length": 999, "Policy Loss": -0.07268776744604111, "Value Loss": 0.003529486246407032, "_runtime": 15082.774491786957, "_timestamp": 1585612452.4073613, "_step": 111}
{"Episode reward": -69.27230715372826, "Episode length": 999, "Policy Loss": -0.07275871932506561, "Value Loss": 0.00338749960064888, "_runtime": 15084.369414329529, "_timestamp": 1585612454.0022838, "_step": 112}
{"Episode reward": -68.78228745242957, "Episode length": 999, "Policy Loss": -0.0693221464753151, "Value Loss": 0.0032852597068995237, "_runtime": 15085.9659512043, "_timestamp": 1585612455.5988207, "_step": 113}
{"Episode reward": -68.33629095285079, "Episode length": 999, "Policy Loss": -0.06464039534330368, "Value Loss": 0.0031671770848333836, "_runtime": 15087.54501080513, "_timestamp": 1585612457.1778803, "_step": 114}
{"Episode reward": -70.02127653811702, "Episode length": 999, "Policy Loss": -0.06582768261432648, "Value Loss": 0.0031731771305203438, "_runtime": 15089.12768125534, "_timestamp": 1585612458.7605507, "_step": 115}
{"Episode reward": -68.04111939831884, "Episode length": 999, "Policy Loss": -0.06405603885650635, "Value Loss": 0.002915057120844722, "_runtime": 15090.711885213852, "_timestamp": 1585612460.3447547, "_step": 116}
{"Episode reward": -71.74974346467646, "Episode length": 999, "Policy Loss": -0.06756813824176788, "Value Loss": 0.003010076005011797, "_runtime": 15092.323894739151, "_timestamp": 1585612461.9567642, "_step": 117}
{"Episode reward": -71.46698003615592, "Episode length": 999, "Policy Loss": -0.0653131827712059, "Value Loss": 0.0029376728925853968, "_runtime": 15093.897823572159, "_timestamp": 1585612463.530693, "_step": 118}
{"Episode reward": -69.97338493626867, "Episode length": 999, "Policy Loss": -0.06208144873380661, "Value Loss": 0.0027739445213228464, "_runtime": 15095.485576152802, "_timestamp": 1585612465.1184456, "_step": 119}
{"Episode reward": -71.93973773859493, "Episode length": 999, "Policy Loss": -0.06287391483783722, "Value Loss": 0.002767681609839201, "_runtime": 15097.071447849274, "_timestamp": 1585612466.7043173, "_step": 120}
{"Episode reward": -70.53795843926403, "Episode length": 999, "Policy Loss": -0.05699465796351433, "Value Loss": 0.0026377507019788027, "_runtime": 15098.657835006714, "_timestamp": 1585612468.2907045, "_step": 121}
{"Episode reward": -68.63656944740335, "Episode length": 999, "Policy Loss": -0.05235571041703224, "Value Loss": 0.0025097564794123173, "_runtime": 15100.246465444565, "_timestamp": 1585612469.879335, "_step": 122}
{"Episode reward": -68.33189226299541, "Episode length": 999, "Policy Loss": -0.05039938911795616, "Value Loss": 0.0024752975441515446, "_runtime": 15101.834333658218, "_timestamp": 1585612471.4672031, "_step": 123}
{"Episode reward": -68.71007057929302, "Episode length": 999, "Policy Loss": -0.04900132119655609, "Value Loss": 0.002410060493275523, "_runtime": 15103.397723913193, "_timestamp": 1585612473.0305934, "_step": 124}
{"Episode reward": -68.53816176228729, "Episode length": 999, "Policy Loss": -0.04750552028417587, "Value Loss": 0.002356776501983404, "_runtime": 15104.986125469208, "_timestamp": 1585612474.618995, "_step": 125}
{"Episode reward": -69.92334855802468, "Episode length": 999, "Policy Loss": -0.04730500280857086, "Value Loss": 0.0023296254221349955, "_runtime": 15106.578840732574, "_timestamp": 1585612476.2117102, "_step": 126}
{"Episode reward": -68.49652745533972, "Episode length": 999, "Policy Loss": -0.04272284358739853, "Value Loss": 0.0022327357437461615, "_runtime": 15108.162994861603, "_timestamp": 1585612477.7958643, "_step": 127}
{"Episode reward": -68.39160424214178, "Episode length": 999, "Policy Loss": -0.041637372225522995, "Value Loss": 0.002197969937697053, "_runtime": 15109.747872829437, "_timestamp": 1585612479.3807423, "_step": 128}
{"Episode reward": -67.23245194568199, "Episode length": 999, "Policy Loss": -0.0388566218316555, "Value Loss": 0.0021219977643340826, "_runtime": 15111.332705497742, "_timestamp": 1585612480.965575, "_step": 129}
{"Episode reward": -66.85586905866742, "Episode length": 999, "Policy Loss": -0.03603346273303032, "Value Loss": 0.002083816332742572, "_runtime": 15112.909729480743, "_timestamp": 1585612482.542599, "_step": 130}
{"Episode reward": -66.6036207150985, "Episode length": 999, "Policy Loss": -0.03599090129137039, "Value Loss": 0.001985737821087241, "_runtime": 15114.484866857529, "_timestamp": 1585612484.1177363, "_step": 131}
{"Episode reward": -68.88056683702276, "Episode length": 999, "Policy Loss": -0.03528320789337158, "Value Loss": 0.0020381882786750793, "_runtime": 15116.110265254974, "_timestamp": 1585612485.7431347, "_step": 132}
{"Episode reward": -68.11618232805039, "Episode length": 999, "Policy Loss": -0.03561081364750862, "Value Loss": 0.001983941998332739, "_runtime": 15117.694850683212, "_timestamp": 1585612487.3277202, "_step": 133}
{"Episode reward": -67.86013394032967, "Episode length": 999, "Policy Loss": -0.03170093148946762, "Value Loss": 0.0019837720319628716, "_runtime": 15119.27942943573, "_timestamp": 1585612488.912299, "_step": 134}
{"Episode reward": -68.32519324973737, "Episode length": 999, "Policy Loss": -0.03113272227346897, "Value Loss": 0.001951505895704031, "_runtime": 15120.852620840073, "_timestamp": 1585612490.4854903, "_step": 135}
{"Episode reward": -69.83825096683577, "Episode length": 999, "Policy Loss": -0.03358760103583336, "Value Loss": 0.0019502468639984727, "_runtime": 15122.424300909042, "_timestamp": 1585612492.0571704, "_step": 136}
{"Episode reward": -65.98376612596424, "Episode length": 999, "Policy Loss": -0.02671216055750847, "Value Loss": 0.0018998526502400637, "_runtime": 15124.00822877884, "_timestamp": 1585612493.6410983, "_step": 137}
{"Episode reward": -66.21870123070589, "Episode length": 999, "Policy Loss": -0.02464967593550682, "Value Loss": 0.0018603721400722861, "_runtime": 15125.582475423813, "_timestamp": 1585612495.215345, "_step": 138}
{"Episode reward": -69.38311817782026, "Episode length": 999, "Policy Loss": -0.03080589324235916, "Value Loss": 0.0018157208105549216, "_runtime": 15127.164937973022, "_timestamp": 1585612496.7978075, "_step": 139}
{"Episode reward": -68.97274105115858, "Episode length": 999, "Policy Loss": -0.02635418064892292, "Value Loss": 0.0018376903608441353, "_runtime": 15128.75208735466, "_timestamp": 1585612498.3849568, "_step": 140}
{"Episode reward": -68.97217488078779, "Episode length": 999, "Policy Loss": -0.026883380487561226, "Value Loss": 0.001789006288163364, "_runtime": 15130.337766885757, "_timestamp": 1585612499.9706364, "_step": 141}
{"Episode reward": -66.82512878617862, "Episode length": 999, "Policy Loss": -0.02245183475315571, "Value Loss": 0.0017872547032311559, "_runtime": 15131.920926094055, "_timestamp": 1585612501.5537956, "_step": 142}
{"Episode reward": -67.82033506161959, "Episode length": 999, "Policy Loss": -0.02355916053056717, "Value Loss": 0.0017389748245477676, "_runtime": 15133.508955955505, "_timestamp": 1585612503.1418254, "_step": 143}
{"Episode reward": -69.62337914766863, "Episode length": 999, "Policy Loss": -0.024578526616096497, "Value Loss": 0.0017245589988306165, "_runtime": 15135.085812807083, "_timestamp": 1585612504.7186823, "_step": 144}
{"Episode reward": -69.39607453334307, "Episode length": 999, "Policy Loss": -0.024396877735853195, "Value Loss": 0.0016981357475742698, "_runtime": 15136.647152423859, "_timestamp": 1585612506.280022, "_step": 145}
{"Episode reward": -69.65656361579926, "Episode length": 999, "Policy Loss": -0.021793870255351067, "Value Loss": 0.00173544033896178, "_runtime": 15138.221907615662, "_timestamp": 1585612507.854777, "_step": 146}
{"Episode reward": -68.86237370843153, "Episode length": 999, "Policy Loss": -0.02064744010567665, "Value Loss": 0.0016965052345767617, "_runtime": 15139.851136446, "_timestamp": 1585612509.484006, "_step": 147}
{"Episode reward": -70.26458501368522, "Episode length": 999, "Policy Loss": -0.021460723131895065, "Value Loss": 0.0017240919405594468, "_runtime": 15141.424172878265, "_timestamp": 1585612511.0570424, "_step": 148}
{"Episode reward": -69.44801996348937, "Episode length": 999, "Policy Loss": -0.020617244765162468, "Value Loss": 0.0017370583955198526, "_runtime": 15143.009034633636, "_timestamp": 1585612512.641904, "_step": 149}
{"Episode reward": -68.99660962121668, "Episode length": 999, "Policy Loss": -0.02042718231678009, "Value Loss": 0.00170596269890666, "_runtime": 15144.583729505539, "_timestamp": 1585612514.216599, "_step": 150}
{"Episode reward": -69.38657378746493, "Episode length": 999, "Policy Loss": -0.017852863296866417, "Value Loss": 0.0016362385358661413, "_runtime": 15146.164733171463, "_timestamp": 1585612515.7976027, "_step": 151}
{"Episode reward": -68.33071979805887, "Episode length": 999, "Policy Loss": -0.017997974529862404, "Value Loss": 0.0016634525964036584, "_runtime": 15147.748388528824, "_timestamp": 1585612517.381258, "_step": 152}
{"Episode reward": -65.46025428083944, "Episode length": 999, "Policy Loss": -0.011585242114961147, "Value Loss": 0.0016848873347043991, "_runtime": 15149.332468986511, "_timestamp": 1585612518.9653385, "_step": 153}
{"Episode reward": -69.54658931615664, "Episode length": 999, "Policy Loss": -0.01750955916941166, "Value Loss": 0.0016264764126390219, "_runtime": 15150.91490149498, "_timestamp": 1585612520.547771, "_step": 154}
{"Episode reward": -68.16082562629819, "Episode length": 999, "Policy Loss": -0.015261469408869743, "Value Loss": 0.0016286576865240932, "_runtime": 15152.500688791275, "_timestamp": 1585612522.1335583, "_step": 155}
{"Episode reward": -67.94702537139985, "Episode length": 999, "Policy Loss": -0.014052015729248524, "Value Loss": 0.0016453629359602928, "_runtime": 15154.085801362991, "_timestamp": 1585612523.7186708, "_step": 156}
{"Episode reward": -69.61412228343868, "Episode length": 999, "Policy Loss": -0.014885352924466133, "Value Loss": 0.0016509126871824265, "_runtime": 15155.668085813522, "_timestamp": 1585612525.3009553, "_step": 157}
{"Episode reward": -69.01694749606693, "Episode length": 999, "Policy Loss": -0.012632309459149837, "Value Loss": 0.0015561174368485808, "_runtime": 15157.253077983856, "_timestamp": 1585612526.8859475, "_step": 158}
{"Episode reward": -69.01930611860345, "Episode length": 999, "Policy Loss": -0.013995806686580181, "Value Loss": 0.0015687306877225637, "_runtime": 15158.836553096771, "_timestamp": 1585612528.4694226, "_step": 159}
{"Episode reward": -69.97108709459847, "Episode length": 999, "Policy Loss": -0.015503604896366596, "Value Loss": 0.0015661241486668587, "_runtime": 15160.40927696228, "_timestamp": 1585612530.0421464, "_step": 160}
{"Episode reward": -69.74081382389922, "Episode length": 999, "Policy Loss": -0.014983524568378925, "Value Loss": 0.0015538999577984214, "_runtime": 15162.03153681755, "_timestamp": 1585612531.6644063, "_step": 161}
{"Episode reward": -71.23681990671798, "Episode length": 999, "Policy Loss": -0.016229795292019844, "Value Loss": 0.0016061639180406928, "_runtime": 15163.61509180069, "_timestamp": 1585612533.2479613, "_step": 162}
{"Episode reward": -69.18093026018472, "Episode length": 999, "Policy Loss": -0.010218855924904346, "Value Loss": 0.0015973574481904507, "_runtime": 15165.192616701126, "_timestamp": 1585612534.8254862, "_step": 163}
{"Episode reward": -69.06087057971266, "Episode length": 999, "Policy Loss": -0.010620729997754097, "Value Loss": 0.001589538180269301, "_runtime": 15166.780928373337, "_timestamp": 1585612536.4137979, "_step": 164}
{"Episode reward": -68.56735515492994, "Episode length": 999, "Policy Loss": -0.009257370606064796, "Value Loss": 0.0015739229274913669, "_runtime": 15168.355775117874, "_timestamp": 1585612537.9886446, "_step": 165}
{"Episode reward": -68.83575746485513, "Episode length": 999, "Policy Loss": -0.010521779768168926, "Value Loss": 0.0015556145226582885, "_runtime": 15169.928862810135, "_timestamp": 1585612539.5617323, "_step": 166}
{"Episode reward": -70.10819657135417, "Episode length": 999, "Policy Loss": -0.012882380746304989, "Value Loss": 0.0015483879251405597, "_runtime": 15171.504633903503, "_timestamp": 1585612541.1375034, "_step": 167}
{"Episode reward": -67.36308419762726, "Episode length": 999, "Policy Loss": -0.007422907743602991, "Value Loss": 0.0016063421498984098, "_runtime": 15173.088091135025, "_timestamp": 1585612542.7209606, "_step": 168}
{"Episode reward": -68.84047771552785, "Episode length": 999, "Policy Loss": -0.008607134222984314, "Value Loss": 0.001599760609678924, "_runtime": 15174.662848949432, "_timestamp": 1585612544.2957184, "_step": 169}
{"Episode reward": -68.60121383897521, "Episode length": 999, "Policy Loss": -0.007152458652853966, "Value Loss": 0.0015253158053383231, "_runtime": 15176.23669886589, "_timestamp": 1585612545.8695683, "_step": 170}
{"Episode reward": -69.94092484558668, "Episode length": 999, "Policy Loss": -0.008977098390460014, "Value Loss": 0.0015637939795851707, "_runtime": 15177.810596227646, "_timestamp": 1585612547.4434657, "_step": 171}
{"Episode reward": -69.09152789855537, "Episode length": 999, "Policy Loss": -0.007677273824810982, "Value Loss": 0.0015909996582195163, "_runtime": 15179.397579908371, "_timestamp": 1585612549.0304494, "_step": 172}
{"Episode reward": -70.06860424018674, "Episode length": 999, "Policy Loss": -0.010473589412868023, "Value Loss": 0.001529684872366488, "_runtime": 15180.970553159714, "_timestamp": 1585612550.6034226, "_step": 173}
{"Episode reward": -68.13417058363252, "Episode length": 999, "Policy Loss": -0.0029700957238674164, "Value Loss": 0.0016053281724452972, "_runtime": 15182.555419445038, "_timestamp": 1585612552.188289, "_step": 174}
{"Episode reward": -71.87457051760452, "Episode length": 999, "Policy Loss": -0.01126105897128582, "Value Loss": 0.0014959104591980577, "_runtime": 15184.138516664505, "_timestamp": 1585612553.7713861, "_step": 175}
{"Episode reward": -69.61286465286555, "Episode length": 999, "Policy Loss": -0.0065046693198382854, "Value Loss": 0.001587900798767805, "_runtime": 15185.759999275208, "_timestamp": 1585612555.3928688, "_step": 176}
{"Episode reward": -68.23887456289827, "Episode length": 999, "Policy Loss": -0.00452785799279809, "Value Loss": 0.001559662981890142, "_runtime": 15187.342388629913, "_timestamp": 1585612556.975258, "_step": 177}
{"Episode reward": -70.48844480422851, "Episode length": 999, "Policy Loss": -0.00769475381821394, "Value Loss": 0.0015190655831247568, "_runtime": 15188.923723220825, "_timestamp": 1585612558.5565927, "_step": 178}
{"Episode reward": -68.83571530123095, "Episode length": 999, "Policy Loss": -0.0059273736551404, "Value Loss": 0.0015683794626966119, "_runtime": 15190.50929760933, "_timestamp": 1585612560.142167, "_step": 179}
{"Episode reward": -68.54215660042902, "Episode length": 999, "Policy Loss": -0.004913090728223324, "Value Loss": 0.0015738466754555702, "_runtime": 15192.090991020203, "_timestamp": 1585612561.7238605, "_step": 180}
{"Episode reward": -71.01927842743919, "Episode length": 999, "Policy Loss": -0.008150071837008, "Value Loss": 0.0015292101306840777, "_runtime": 15193.662223100662, "_timestamp": 1585612563.2950926, "_step": 181}
{"Episode reward": -71.27276764274075, "Episode length": 999, "Policy Loss": -0.00901746191084385, "Value Loss": 0.0015339000383391976, "_runtime": 15195.243013620377, "_timestamp": 1585612564.875883, "_step": 182}
{"Episode reward": -72.2362450295521, "Episode length": 999, "Policy Loss": -0.009493718855082989, "Value Loss": 0.0015033730305731297, "_runtime": 15196.827699422836, "_timestamp": 1585612566.460569, "_step": 183}
{"Episode reward": -69.13727100107242, "Episode length": 999, "Policy Loss": -0.004496303386986256, "Value Loss": 0.0015777136432006955, "_runtime": 15198.3982026577, "_timestamp": 1585612568.0310721, "_step": 184}
{"Episode reward": -70.82480931640222, "Episode length": 999, "Policy Loss": -0.005469838622957468, "Value Loss": 0.0015228097327053547, "_runtime": 15199.98007273674, "_timestamp": 1585612569.6129422, "_step": 185}
{"Episode reward": -71.73252307100465, "Episode length": 999, "Policy Loss": -0.007848596200346947, "Value Loss": 0.0014814083697274327, "_runtime": 15201.553987979889, "_timestamp": 1585612571.1868575, "_step": 186}
{"Episode reward": -72.49859449440616, "Episode length": 999, "Policy Loss": -0.010549522005021572, "Value Loss": 0.0014816215261816978, "_runtime": 15203.122365236282, "_timestamp": 1585612572.7552347, "_step": 187}
{"Episode reward": -69.44280152773418, "Episode length": 999, "Policy Loss": -0.0028647484723478556, "Value Loss": 0.0015422971919178963, "_runtime": 15204.70579957962, "_timestamp": 1585612574.338669, "_step": 188}
{"Episode reward": -70.09812016091566, "Episode length": 999, "Policy Loss": -0.005186767317354679, "Value Loss": 0.0015277786878868937, "_runtime": 15206.278289318085, "_timestamp": 1585612575.9111588, "_step": 189}
{"Episode reward": -71.77382753650623, "Episode length": 999, "Policy Loss": -0.0070532457903027534, "Value Loss": 0.0015192440478131175, "_runtime": 15207.85875916481, "_timestamp": 1585612577.4916286, "_step": 190}
{"Episode reward": -72.04928773001913, "Episode length": 999, "Policy Loss": -0.006679452024400234, "Value Loss": 0.0014887175057083368, "_runtime": 15209.469141721725, "_timestamp": 1585612579.1020112, "_step": 191}
{"Episode reward": -72.19410687117615, "Episode length": 999, "Policy Loss": -0.007782542146742344, "Value Loss": 0.0015275694895535707, "_runtime": 15211.055389642715, "_timestamp": 1585612580.6882591, "_step": 192}
{"Episode reward": -71.6658911366544, "Episode length": 999, "Policy Loss": -0.007558682933449745, "Value Loss": 0.0014651318779215217, "_runtime": 15212.642985582352, "_timestamp": 1585612582.275855, "_step": 193}
{"Episode reward": -70.49381972346995, "Episode length": 999, "Policy Loss": -0.005167199298739433, "Value Loss": 0.001495823496952653, "_runtime": 15214.217786550522, "_timestamp": 1585612583.850656, "_step": 194}
{"Episode reward": -70.90852708431825, "Episode length": 999, "Policy Loss": -0.005112012382596731, "Value Loss": 0.0015541121829301119, "_runtime": 15215.795111179352, "_timestamp": 1585612585.4279807, "_step": 195}
{"Episode reward": -70.97079941844066, "Episode length": 999, "Policy Loss": -0.004143931902945042, "Value Loss": 0.001521249650977552, "_runtime": 15217.36858844757, "_timestamp": 1585612587.001458, "_step": 196}
{"Episode reward": -71.13578806947227, "Episode length": 999, "Policy Loss": -0.005814033094793558, "Value Loss": 0.0015137663576751947, "_runtime": 15218.954124689102, "_timestamp": 1585612588.5869942, "_step": 197}
{"Episode reward": -74.92783897589675, "Episode length": 999, "Policy Loss": -0.01101729553192854, "Value Loss": 0.0014009916922077537, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376, 1.6663585901260376]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0277830362319946, -0.9920023083686829, -0.9562215805053711, -0.9204408526420593, -0.8846601247787476, -0.8488793969154358, -0.813098669052124, -0.7773179411888123, -0.7415372133255005, -0.7057564854621887, -0.669975757598877, -0.6341950297355652, -0.5984143018722534, -0.5626335740089417, -0.5268528461456299, -0.4910721182823181, -0.45529139041900635, -0.4195106625556946, -0.3837299346923828, -0.34794920682907104, -0.3121684789657593, -0.2763877511024475, -0.24060702323913574, -0.20482629537582397, -0.1690455675125122, -0.13326483964920044, -0.09748411178588867, -0.061703383922576904, -0.025922656059265137, 0.009858012199401855, 0.0456387996673584, 0.08141958713531494, 0.11720025539398193, 0.15298092365264893, 0.18876171112060547, 0.224542498588562, 0.260323166847229, 0.296103835105896, 0.33188462257385254, 0.3676654100418091, 0.4034460783004761, 0.43922674655914307, 0.4750075340270996, 0.5107883214950562, 0.5465689897537231, 0.5823496580123901, 0.6181304454803467, 0.6539112329483032, 0.6896919012069702, 0.7254725694656372, 0.7612533569335938, 0.7970341444015503, 0.8328148126602173, 0.8685954809188843, 0.9043762683868408, 0.9401570558547974, 0.9759377241134644, 1.0117183923721313, 1.0474990606307983, 1.0832799673080444, 1.1190606355667114, 1.1548413038253784, 1.1906222105026245, 1.2264028787612915, 1.2621835470199585]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.31455686688423157, -0.30120426416397095, -0.2878516912460327, -0.2744990885257721, -0.2611464858055115, -0.24779389798641205, -0.23444131016731262, -0.221088707447052, -0.20773611962795258, -0.19438353180885315, -0.18103092908859253, -0.1676783412694931, -0.15432575345039368, -0.14097315073013306, -0.12762056291103363, -0.11426796019077301, -0.10091537237167358, -0.08756278455257416, -0.07421018183231354, -0.06085759401321411, -0.04750499129295349, -0.03415241837501526, -0.02079981565475464, -0.0074472129344940186, 0.005905359983444214, 0.019257962703704834, 0.032610565423965454, 0.045963168144226074, 0.05931574106216431, 0.07266834378242493, 0.08602094650268555, 0.09937351942062378, 0.1127261221408844, 0.12607872486114502, 0.13943129777908325, 0.15278390049934387, 0.1661365032196045, 0.17948907613754272, 0.19284167885780334, 0.20619425177574158, 0.21954688429832458, 0.23289945721626282, 0.24625203013420105, 0.25960466265678406, 0.2729572355747223, 0.2863098084926605, 0.29966244101524353, 0.31301501393318176, 0.32636758685112, 0.339720219373703, 0.35307279229164124, 0.36642542481422424, 0.3797779977321625, 0.3931305706501007, 0.4064832031726837, 0.41983577609062195, 0.4331883490085602, 0.4465409815311432, 0.4598935544490814, 0.47324612736701965, 0.48659875988960266, 0.4999513328075409, 0.5133038759231567, 0.5266565084457397, 0.5400091409683228]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 6.0, 9.0, 10.0, 15.0, 17.0, 16.0, 22.0, 26.0, 28.0, 65.0, 56.0, 37.0, 31.0, 27.0, 23.0, 24.0, 14.0, 15.0, 11.0, 9.0, 7.0, 4.0, 3.0, 4.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.14910584688186646, -0.1431962102651596, -0.13728657364845276, -0.1313769370317459, -0.12546730041503906, -0.11955766379833221, -0.11364801973104477, -0.10773838311433792, -0.10182874649763107, -0.09591910988092422, -0.09000947326421738, -0.08409983664751053, -0.07819019258022308, -0.07228055596351624, -0.06637091934680939, -0.06046128273010254, -0.05455164611339569, -0.04864200949668884, -0.042732372879981995, -0.036822736263275146, -0.0309130996465683, -0.025003455579280853, -0.019093826413154602, -0.013184189796447754, -0.007274538278579712, -0.0013649016618728638, 0.004544734954833984, 0.010454371571540833, 0.01636400818824768, 0.02227364480495453, 0.028183281421661377, 0.034092918038368225, 0.04000255465507507, 0.04591219127178192, 0.05182182788848877, 0.05773146450519562, 0.06364110112190247, 0.06955073773860931, 0.07546037435531616, 0.08137001097202301, 0.08727964758872986, 0.0931892991065979, 0.09909893572330475, 0.1050085723400116, 0.11091819405555725, 0.11682784557342529, 0.12273746728897095, 0.128647118806839, 0.13455677032470703, 0.14046639204025269, 0.14637604355812073, 0.15228566527366638, 0.15819531679153442, 0.16410493850708008, 0.17001459002494812, 0.17592421174049377, 0.18183386325836182, 0.18774348497390747, 0.1936531364917755, 0.19956275820732117, 0.2054724097251892, 0.21138203144073486, 0.2172916829586029, 0.22320130467414856, 0.2291109561920166]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7954428791999817, -0.773097574710846, -0.7507522702217102, -0.7284069657325745, -0.706061601638794, -0.6837162971496582, -0.6613709926605225, -0.6390256881713867, -0.616680383682251, -0.5943350791931152, -0.5719897747039795, -0.5496444702148438, -0.527299165725708, -0.5049538612365723, -0.48260849714279175, -0.460263192653656, -0.43791788816452026, -0.4155725836753845, -0.3932272791862488, -0.37088194489479065, -0.3485366404056549, -0.32619133591651917, -0.30384600162506104, -0.2815006971359253, -0.25915539264678955, -0.2368100881576538, -0.21446478366851807, -0.19211947917938232, -0.1697741150856018, -0.14742881059646606, -0.12508350610733032, -0.10273820161819458, -0.08039289712905884, -0.058047592639923096, -0.035702288150787354, -0.013356983661651611, 0.00898832082748413, 0.03133368492126465, 0.05367898941040039, 0.07602429389953613, 0.09836959838867188, 0.12071490287780762, 0.14306020736694336, 0.1654055118560791, 0.18775087594985962, 0.21009618043899536, 0.2324414849281311, 0.25478678941726685, 0.2771320939064026, 0.29947739839553833, 0.3218227028846741, 0.3441680073738098, 0.36651331186294556, 0.3888586163520813, 0.41120392084121704, 0.4335492253303528, 0.4558946490287781, 0.4782399535179138, 0.5005852580070496, 0.5229305624961853, 0.545275866985321, 0.5676211714744568, 0.5899664759635925, 0.6123117804527283, 0.634657084941864]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.13850747048854828, -0.13406400382518768, -0.1296205371618271, -0.1251770704984665, -0.1207336038351059, -0.1162901371717453, -0.1118466779589653, -0.1074032112956047, -0.10295974463224411, -0.09851627796888351, -0.09407281130552292, -0.08962935209274292, -0.08518588542938232, -0.08074241876602173, -0.07629895210266113, -0.07185548543930054, -0.06741201877593994, -0.06296855211257935, -0.05852508544921875, -0.054081618785858154, -0.04963815212249756, -0.04519469290971756, -0.040751226246356964, -0.03630775958299637, -0.03186429291963577, -0.027420826256275177, -0.02297735959291458, -0.018533892929553986, -0.014090433716773987, -0.009646967053413391, -0.005203500390052795, -0.0007600337266921997, 0.003683432936668396, 0.008126899600028992, 0.012570366263389587, 0.017013832926750183, 0.02145729959011078, 0.025900766253471375, 0.03034423291683197, 0.034787699580192566, 0.03923116624355316, 0.043674618005752563, 0.04811808466911316, 0.052561551332473755, 0.05700501799583435, 0.061448484659194946, 0.06589195132255554, 0.07033541798591614, 0.07477888464927673, 0.07922235131263733, 0.08366581797599792, 0.08810928463935852, 0.09255275130271912, 0.09699621796607971, 0.10143968462944031, 0.1058831512928009, 0.1103266030550003, 0.1147700697183609, 0.1192135363817215, 0.12365700304508209, 0.1281004697084427, 0.13254393637180328, 0.13698740303516388, 0.14143086969852448, 0.14587433636188507]}, "_runtime": 15220.533024311066, "_timestamp": 1585612590.1658938, "_step": 198}
{"Episode reward": -73.58414630285299, "Episode length": 999, "Policy Loss": -0.009190631099045277, "Value Loss": 0.0014390969881787896, "_runtime": 15222.107676267624, "_timestamp": 1585612591.7405457, "_step": 199}
{"Episode reward": -71.00228550598621, "Episode length": 999, "Policy Loss": -0.004532769788056612, "Value Loss": 0.0014874583575874567, "_runtime": 15223.694007873535, "_timestamp": 1585612593.3268774, "_step": 200}
{"Episode reward": -72.35387392803183, "Episode length": 999, "Policy Loss": -0.008046647533774376, "Value Loss": 0.0014864514814689755, "_runtime": 15225.27122092247, "_timestamp": 1585612594.9040904, "_step": 201}
{"Episode reward": -70.25591572239095, "Episode length": 999, "Policy Loss": -1.2776977200701367e-05, "Value Loss": 0.001542409067042172, "_runtime": 15226.856088638306, "_timestamp": 1585612596.4889581, "_step": 202}
{"Episode reward": -71.38096271653298, "Episode length": 999, "Policy Loss": -0.003988190088421106, "Value Loss": 0.0014719212194904685, "_runtime": 15228.445834159851, "_timestamp": 1585612598.0787036, "_step": 203}
{"Episode reward": -70.36866129775306, "Episode length": 999, "Policy Loss": -0.0019498966867104173, "Value Loss": 0.0015087096253409982, "_runtime": 15230.031304121017, "_timestamp": 1585612599.6641736, "_step": 204}
{"Episode reward": -74.32590092962546, "Episode length": 999, "Policy Loss": -0.009501675143837929, "Value Loss": 0.0013970243744552135, "_runtime": 15231.604761838913, "_timestamp": 1585612601.2376313, "_step": 205}
{"Episode reward": -71.68887942049649, "Episode length": 999, "Policy Loss": -0.00490623340010643, "Value Loss": 0.001467656809836626, "_runtime": 15233.229493141174, "_timestamp": 1585612602.8623626, "_step": 206}
{"Episode reward": -73.78349894195833, "Episode length": 999, "Policy Loss": -0.007661169860512018, "Value Loss": 0.0014549654442816973, "_runtime": 15234.814628362656, "_timestamp": 1585612604.4474978, "_step": 207}
{"Episode reward": -72.72086185161821, "Episode length": 999, "Policy Loss": -0.0059964461252093315, "Value Loss": 0.0014431927120313048, "_runtime": 15236.38692522049, "_timestamp": 1585612606.0197947, "_step": 208}
{"Episode reward": -71.56004526723301, "Episode length": 999, "Policy Loss": -0.003850697074085474, "Value Loss": 0.0014717122539877892, "_runtime": 15237.971950054169, "_timestamp": 1585612607.6048195, "_step": 209}
{"Episode reward": -73.88041049476931, "Episode length": 999, "Policy Loss": -0.007121589034795761, "Value Loss": 0.0014845415716990829, "_runtime": 15239.553742647171, "_timestamp": 1585612609.1866121, "_step": 210}
{"Episode reward": -70.90550525510493, "Episode length": 999, "Policy Loss": -0.000365431304089725, "Value Loss": 0.0015138931339606643, "_runtime": 15241.124798297882, "_timestamp": 1585612610.7576678, "_step": 211}
{"Episode reward": -69.659173385868, "Episode length": 999, "Policy Loss": 4.461830394575372e-05, "Value Loss": 0.0015315668424591422, "_runtime": 15242.698171377182, "_timestamp": 1585612612.3310409, "_step": 212}
{"Episode reward": -71.35914691712796, "Episode length": 999, "Policy Loss": -0.0021216312889009714, "Value Loss": 0.0014801609795540571, "_runtime": 15244.267322778702, "_timestamp": 1585612613.9001923, "_step": 213}
{"Episode reward": -71.98420762410097, "Episode length": 999, "Policy Loss": -0.0033579657319933176, "Value Loss": 0.0014702342450618744, "_runtime": 15245.837484359741, "_timestamp": 1585612615.4703538, "_step": 214}
{"Episode reward": -71.09284064941883, "Episode length": 999, "Policy Loss": -0.0016828106017783284, "Value Loss": 0.0014777117175981402, "_runtime": 15247.412467718124, "_timestamp": 1585612617.0453372, "_step": 215}
{"Episode reward": -69.93178727160014, "Episode length": 999, "Policy Loss": 0.0008357996121048927, "Value Loss": 0.0015362141421064734, "_runtime": 15248.984198331833, "_timestamp": 1585612618.6170678, "_step": 216}
{"Episode reward": -71.64030717915239, "Episode length": 999, "Policy Loss": -0.0024937987327575684, "Value Loss": 0.001441222964785993, "_runtime": 15250.554233312607, "_timestamp": 1585612620.1871028, "_step": 217}
{"Episode reward": -74.28934890144802, "Episode length": 999, "Policy Loss": -0.006398466415703297, "Value Loss": 0.0014144257875159383, "_runtime": 15252.139182567596, "_timestamp": 1585612621.772052, "_step": 218}
{"Episode reward": -70.51502639584929, "Episode length": 999, "Policy Loss": -0.000997779774479568, "Value Loss": 0.0015294092008844018, "_runtime": 15253.721636772156, "_timestamp": 1585612623.3545063, "_step": 219}
{"Episode reward": -71.39495580411976, "Episode length": 999, "Policy Loss": -0.001876533729955554, "Value Loss": 0.0014744559302926064, "_runtime": 15255.340700864792, "_timestamp": 1585612624.9735703, "_step": 220}
{"Episode reward": -73.3909007362154, "Episode length": 999, "Policy Loss": -0.004674587398767471, "Value Loss": 0.0014221364399418235, "_runtime": 15256.912546396255, "_timestamp": 1585612626.5454159, "_step": 221}
{"Episode reward": -73.4196100572881, "Episode length": 999, "Policy Loss": -0.006521753966808319, "Value Loss": 0.0014275944558903575, "_runtime": 15258.48716711998, "_timestamp": 1585612628.1200366, "_step": 222}
{"Episode reward": -72.21932424911894, "Episode length": 999, "Policy Loss": -0.004687527660280466, "Value Loss": 0.0014444183325394988, "_runtime": 15260.067460298538, "_timestamp": 1585612629.7003298, "_step": 223}
{"Episode reward": -70.79932424050602, "Episode length": 999, "Policy Loss": -0.0015041932929307222, "Value Loss": 0.0015048219356685877, "_runtime": 15261.65469789505, "_timestamp": 1585612631.2875674, "_step": 224}
{"Episode reward": -72.31853780010717, "Episode length": 999, "Policy Loss": -0.0021518750581890345, "Value Loss": 0.001462864107452333, "_runtime": 15263.235569238663, "_timestamp": 1585612632.8684387, "_step": 225}
{"Episode reward": -72.40389311864153, "Episode length": 999, "Policy Loss": -0.0030926454346626997, "Value Loss": 0.0014660988235846162, "_runtime": 15264.81604552269, "_timestamp": 1585612634.448915, "_step": 226}
{"Episode reward": -72.48316317771764, "Episode length": 999, "Policy Loss": -0.002056679455563426, "Value Loss": 0.0014860741794109344, "_runtime": 15266.39885377884, "_timestamp": 1585612636.0317233, "_step": 227}
{"Episode reward": -70.23755880708163, "Episode length": 999, "Policy Loss": 0.002138787414878607, "Value Loss": 0.001458720420487225, "_runtime": 15267.973086118698, "_timestamp": 1585612637.6059556, "_step": 228}
{"Episode reward": -68.33758254965774, "Episode length": 999, "Policy Loss": 0.004342983476817608, "Value Loss": 0.0015977993607521057, "_runtime": 15269.542998313904, "_timestamp": 1585612639.1758678, "_step": 229}
{"Episode reward": -72.2450155482528, "Episode length": 999, "Policy Loss": -0.0007588682929053903, "Value Loss": 0.0014655075501650572, "_runtime": 15271.116621494293, "_timestamp": 1585612640.749491, "_step": 230}
{"Episode reward": -70.94560020052313, "Episode length": 999, "Policy Loss": 0.0026058186776936054, "Value Loss": 0.0014806059189140797, "_runtime": 15272.689018249512, "_timestamp": 1585612642.3218877, "_step": 231}
{"Episode reward": -71.53249235725384, "Episode length": 999, "Policy Loss": -0.0006567825330421329, "Value Loss": 0.001481432467699051, "_runtime": 15274.270638227463, "_timestamp": 1585612643.9035077, "_step": 232}
{"Episode reward": -72.51384601704818, "Episode length": 999, "Policy Loss": -0.003040991025045514, "Value Loss": 0.0014098958345130086, "_runtime": 15275.853335142136, "_timestamp": 1585612645.4862046, "_step": 233}
{"Episode reward": -70.98441151292508, "Episode length": 999, "Policy Loss": -5.718145257560536e-05, "Value Loss": 0.0014899942325428128, "_runtime": 15277.438354253769, "_timestamp": 1585612647.0712237, "_step": 234}
{"Episode reward": -71.40037728977082, "Episode length": 999, "Policy Loss": -0.0010517615592107177, "Value Loss": 0.0015065015759319067, "_runtime": 15279.055965423584, "_timestamp": 1585612648.688835, "_step": 235}
{"Episode reward": -67.84273059043302, "Episode length": 999, "Policy Loss": 0.006557699758559465, "Value Loss": 0.001624191994778812, "_runtime": 15280.638612270355, "_timestamp": 1585612650.2714818, "_step": 236}
{"Episode reward": -69.48727606292258, "Episode length": 999, "Policy Loss": 0.0021144298370927572, "Value Loss": 0.0015309846494346857, "_runtime": 15282.2208776474, "_timestamp": 1585612651.8537471, "_step": 237}
{"Episode reward": -71.78115456102286, "Episode length": 999, "Policy Loss": -0.0009665241232141852, "Value Loss": 0.0014603909803554416, "_runtime": 15283.802230834961, "_timestamp": 1585612653.4351003, "_step": 238}
{"Episode reward": -71.51371420836887, "Episode length": 999, "Policy Loss": 3.6548241041600704e-05, "Value Loss": 0.001476577832363546, "_runtime": 15285.375035762787, "_timestamp": 1585612655.0079052, "_step": 239}
{"Episode reward": -70.76417187970362, "Episode length": 999, "Policy Loss": -0.00015441709547303617, "Value Loss": 0.0015249444404616952, "_runtime": 15286.946824073792, "_timestamp": 1585612656.5796936, "_step": 240}
{"Episode reward": -70.49769919946857, "Episode length": 999, "Policy Loss": 0.0020541290286928415, "Value Loss": 0.0014866498531773686, "_runtime": 15288.515744447708, "_timestamp": 1585612658.148614, "_step": 241}
{"Episode reward": -70.34168955925182, "Episode length": 999, "Policy Loss": 0.00223323586396873, "Value Loss": 0.0015292332973331213, "_runtime": 15290.096697568893, "_timestamp": 1585612659.729567, "_step": 242}
{"Episode reward": -70.88129366999293, "Episode length": 999, "Policy Loss": 0.00032829155679792166, "Value Loss": 0.0014964035945013165, "_runtime": 15291.676093101501, "_timestamp": 1585612661.3089626, "_step": 243}
{"Episode reward": -69.70181221863888, "Episode length": 999, "Policy Loss": 0.002732290420681238, "Value Loss": 0.0015205945819616318, "_runtime": 15293.257624387741, "_timestamp": 1585612662.8904939, "_step": 244}
{"Episode reward": -70.54062953635966, "Episode length": 999, "Policy Loss": 0.0012286637211218476, "Value Loss": 0.0015126819489523768, "_runtime": 15294.842720508575, "_timestamp": 1585612664.47559, "_step": 245}
{"Episode reward": -69.28660884789862, "Episode length": 999, "Policy Loss": 0.0030269422568380833, "Value Loss": 0.0015448416816070676, "_runtime": 15296.429871797562, "_timestamp": 1585612666.0627413, "_step": 246}
{"Episode reward": -69.82560351930158, "Episode length": 999, "Policy Loss": 0.0012766651343554258, "Value Loss": 0.001507937558926642, "_runtime": 15298.019533872604, "_timestamp": 1585612667.6524034, "_step": 247}
{"Episode reward": -68.31646567188751, "Episode length": 999, "Policy Loss": 0.006125168409198523, "Value Loss": 0.001582527533173561, "_runtime": 15299.591138124466, "_timestamp": 1585612669.2240076, "_step": 248}
{"Episode reward": -68.95538442625704, "Episode length": 999, "Policy Loss": 0.004817829933017492, "Value Loss": 0.001518210512585938, "_runtime": 15301.174325227737, "_timestamp": 1585612670.8071947, "_step": 249}
{"Episode reward": -69.57727682001669, "Episode length": 999, "Policy Loss": 0.000168329817824997, "Value Loss": 0.0015470156213268638, "_runtime": 15302.793282747269, "_timestamp": 1585612672.4261522, "_step": 250}
{"Episode reward": -71.33742575951861, "Episode length": 999, "Policy Loss": -0.00173858436755836, "Value Loss": 0.0014583186712116003, "_runtime": 15304.368921995163, "_timestamp": 1585612674.0017915, "_step": 251}
{"Episode reward": -67.91538866993207, "Episode length": 999, "Policy Loss": 0.004135414958000183, "Value Loss": 0.0015318762743845582, "_runtime": 15305.946156263351, "_timestamp": 1585612675.5790257, "_step": 252}
{"Episode reward": -69.55860880364325, "Episode length": 999, "Policy Loss": 0.001929036807268858, "Value Loss": 0.0015409047482535243, "_runtime": 15307.520521640778, "_timestamp": 1585612677.1533911, "_step": 253}
{"Episode reward": -68.37817582791187, "Episode length": 999, "Policy Loss": 0.0054108016192913055, "Value Loss": 0.0015582250198349357, "_runtime": 15309.098768472672, "_timestamp": 1585612678.731638, "_step": 254}
{"Episode reward": -68.90458637773696, "Episode length": 999, "Policy Loss": 0.004426329396665096, "Value Loss": 0.0015687609557062387, "_runtime": 15310.676410913467, "_timestamp": 1585612680.3092804, "_step": 255}
{"Episode reward": -69.50435526999787, "Episode length": 999, "Policy Loss": 0.002559835556894541, "Value Loss": 0.0014812757726758718, "_runtime": 15312.258084535599, "_timestamp": 1585612681.890954, "_step": 256}
{"Episode reward": -69.78187605106605, "Episode length": 999, "Policy Loss": 0.0018896762048825622, "Value Loss": 0.0015099014854058623, "_runtime": 15313.845946788788, "_timestamp": 1585612683.4788163, "_step": 257}
{"Episode reward": -71.04315633818159, "Episode length": 999, "Policy Loss": -0.001824554638005793, "Value Loss": 0.0014655409613624215, "_runtime": 15315.430352210999, "_timestamp": 1585612685.0632217, "_step": 258}
{"Episode reward": -69.41165780988851, "Episode length": 999, "Policy Loss": 0.001299026538617909, "Value Loss": 0.0015286353882402182, "_runtime": 15317.016542196274, "_timestamp": 1585612686.6494117, "_step": 259}
{"Episode reward": -69.28771133117348, "Episode length": 999, "Policy Loss": 0.0027349183801561594, "Value Loss": 0.001544903963804245, "_runtime": 15318.593598127365, "_timestamp": 1585612688.2264676, "_step": 260}
{"Episode reward": -71.07319412739712, "Episode length": 999, "Policy Loss": 0.00047338439617305994, "Value Loss": 0.001453676726669073, "_runtime": 15320.178046941757, "_timestamp": 1585612689.8109164, "_step": 261}
{"Episode reward": -66.53924629729659, "Episode length": 999, "Policy Loss": 0.006976310163736343, "Value Loss": 0.0016208530869334936, "_runtime": 15321.762338161469, "_timestamp": 1585612691.3952076, "_step": 262}
{"Episode reward": -67.9816654860452, "Episode length": 999, "Policy Loss": 0.0028895805589854717, "Value Loss": 0.001547300023958087, "_runtime": 15323.338155508041, "_timestamp": 1585612692.971025, "_step": 263}
{"Episode reward": -68.69264948535665, "Episode length": 999, "Policy Loss": 0.0027741543017327785, "Value Loss": 0.0014948442112654448, "_runtime": 15324.923758268356, "_timestamp": 1585612694.5566278, "_step": 264}
{"Episode reward": -68.49124818155269, "Episode length": 999, "Policy Loss": 0.004516339860856533, "Value Loss": 0.0015365773579105735, "_runtime": 15326.547972679138, "_timestamp": 1585612696.1808422, "_step": 265}
{"Episode reward": -66.86649911149847, "Episode length": 999, "Policy Loss": 0.0057663461193442345, "Value Loss": 0.0015974411508068442, "_runtime": 15328.134137392044, "_timestamp": 1585612697.7670069, "_step": 266}
{"Episode reward": -70.2450086475804, "Episode length": 999, "Policy Loss": -0.0014995187520980835, "Value Loss": 0.0014850335428491235, "_runtime": 15329.719052791595, "_timestamp": 1585612699.3519223, "_step": 267}
{"Episode reward": -70.9272047768163, "Episode length": 999, "Policy Loss": -0.0007401357288472354, "Value Loss": 0.0014686774229630828, "_runtime": 15331.298907995224, "_timestamp": 1585612700.9317775, "_step": 268}
{"Episode reward": -68.7073375925446, "Episode length": 999, "Policy Loss": 0.0008643115288577974, "Value Loss": 0.0015511729288846254, "_runtime": 15332.881126642227, "_timestamp": 1585612702.5139961, "_step": 269}
{"Episode reward": -68.13175801515429, "Episode length": 999, "Policy Loss": 0.0029859489295631647, "Value Loss": 0.0015389672480523586, "_runtime": 15334.454286336899, "_timestamp": 1585612704.0871558, "_step": 270}
{"Episode reward": -66.80777914197867, "Episode length": 999, "Policy Loss": 0.006769248750060797, "Value Loss": 0.001611185958608985, "_runtime": 15336.039606332779, "_timestamp": 1585612705.6724758, "_step": 271}
{"Episode reward": -70.15367610292964, "Episode length": 999, "Policy Loss": -0.0009262065286748111, "Value Loss": 0.0015544288326054811, "_runtime": 15337.624041557312, "_timestamp": 1585612707.256911, "_step": 272}
{"Episode reward": -68.68038578405252, "Episode length": 999, "Policy Loss": 0.0013392464024946094, "Value Loss": 0.0015294455224648118, "_runtime": 15339.206664800644, "_timestamp": 1585612708.8395343, "_step": 273}
{"Episode reward": -68.7702531107299, "Episode length": 999, "Policy Loss": 0.0014327921671792865, "Value Loss": 0.001497521996498108, "_runtime": 15340.787639379501, "_timestamp": 1585612710.4205089, "_step": 274}
{"Episode reward": -69.56330793639363, "Episode length": 999, "Policy Loss": 8.655923011247069e-05, "Value Loss": 0.0015256705228239298, "_runtime": 15342.369557380676, "_timestamp": 1585612712.0024269, "_step": 275}
{"Episode reward": -69.31712250835406, "Episode length": 999, "Policy Loss": 0.0006615796592086554, "Value Loss": 0.0014888375299051404, "_runtime": 15343.954955816269, "_timestamp": 1585612713.5878253, "_step": 276}
{"Episode reward": -72.00513789466103, "Episode length": 999, "Policy Loss": -0.003515670308843255, "Value Loss": 0.0014122477732598782, "_runtime": 15345.527033090591, "_timestamp": 1585612715.1599026, "_step": 277}
{"Episode reward": -69.68008579028785, "Episode length": 999, "Policy Loss": 0.0007181618129834533, "Value Loss": 0.0015174549771472812, "_runtime": 15347.112634658813, "_timestamp": 1585612716.7455041, "_step": 278}
{"Episode reward": -69.77777908527779, "Episode length": 999, "Policy Loss": 0.0007962423260323703, "Value Loss": 0.0015518818981945515, "_runtime": 15348.693811655045, "_timestamp": 1585612718.3266811, "_step": 279}
{"Episode reward": -68.65955473378902, "Episode length": 999, "Policy Loss": 0.0012379619292914867, "Value Loss": 0.001509881461970508, "_runtime": 15350.305916786194, "_timestamp": 1585612719.9387863, "_step": 280}
{"Episode reward": -69.13526285551976, "Episode length": 999, "Policy Loss": -1.5640938727301545e-05, "Value Loss": 0.0015324250562116504, "_runtime": 15351.881947278976, "_timestamp": 1585612721.5148168, "_step": 281}
{"Episode reward": -69.31739903585, "Episode length": 999, "Policy Loss": 0.0002828063734341413, "Value Loss": 0.0015381996054202318, "_runtime": 15353.470477581024, "_timestamp": 1585612723.103347, "_step": 282}
{"Episode reward": -68.39162962111473, "Episode length": 999, "Policy Loss": 0.003312057117000222, "Value Loss": 0.001562759978696704, "_runtime": 15355.053869962692, "_timestamp": 1585612724.6867394, "_step": 283}
{"Episode reward": -67.24346706277649, "Episode length": 999, "Policy Loss": 0.005749494768679142, "Value Loss": 0.0016322345472872257, "_runtime": 15356.629516124725, "_timestamp": 1585612726.2623856, "_step": 284}
{"Episode reward": -69.52043773930143, "Episode length": 999, "Policy Loss": 0.0013599684461951256, "Value Loss": 0.0015264853136613965, "_runtime": 15358.215465068817, "_timestamp": 1585612727.8483346, "_step": 285}
{"Episode reward": -70.5931038065721, "Episode length": 999, "Policy Loss": -0.0015883399173617363, "Value Loss": 0.0015292195603251457, "_runtime": 15359.79747724533, "_timestamp": 1585612729.4303467, "_step": 286}
{"Episode reward": -69.80074089780334, "Episode length": 999, "Policy Loss": 0.0006767458980903029, "Value Loss": 0.0015209218254312873, "_runtime": 15361.388026952744, "_timestamp": 1585612731.0208964, "_step": 287}
{"Episode reward": -68.33213992587763, "Episode length": 999, "Policy Loss": 0.003372685518115759, "Value Loss": 0.0015756674110889435, "_runtime": 15362.961229801178, "_timestamp": 1585612732.5940993, "_step": 288}
{"Episode reward": -69.997316560824, "Episode length": 999, "Policy Loss": -0.0019125170074403286, "Value Loss": 0.0015586803201586008, "_runtime": 15364.548247098923, "_timestamp": 1585612734.1811166, "_step": 289}
{"Episode reward": -68.1699117102158, "Episode length": 999, "Policy Loss": 0.0035271181259304285, "Value Loss": 0.0015439928974956274, "_runtime": 15366.146344661713, "_timestamp": 1585612735.7792141, "_step": 290}
{"Episode reward": -68.82866421021336, "Episode length": 999, "Policy Loss": 0.0011874163756147027, "Value Loss": 0.0015707042766734958, "_runtime": 15367.745261192322, "_timestamp": 1585612737.3781307, "_step": 291}
{"Episode reward": -67.6186889830651, "Episode length": 999, "Policy Loss": 0.003832377027720213, "Value Loss": 0.0015640959609299898, "_runtime": 15369.329308748245, "_timestamp": 1585612738.9621782, "_step": 292}
{"Episode reward": -70.26386514196487, "Episode length": 999, "Policy Loss": -5.853419497725554e-05, "Value Loss": 0.0014916345244273543, "_runtime": 15370.92519235611, "_timestamp": 1585612740.5580618, "_step": 293}
{"Episode reward": -68.96705656459858, "Episode length": 999, "Policy Loss": 0.0005492487107403576, "Value Loss": 0.0015381955308839679, "_runtime": 15372.557261228561, "_timestamp": 1585612742.1901307, "_step": 294}
{"Episode reward": -69.85287476819995, "Episode length": 999, "Policy Loss": -2.8840189770562574e-05, "Value Loss": 0.0015390560729429126, "_runtime": 15374.150858163834, "_timestamp": 1585612743.7837276, "_step": 295}
{"Episode reward": -67.91985877346643, "Episode length": 999, "Policy Loss": 0.0025355215184390545, "Value Loss": 0.0015520964516326785, "_runtime": 15375.747240066528, "_timestamp": 1585612745.3801095, "_step": 296}
{"Episode reward": -70.86076408894854, "Episode length": 999, "Policy Loss": -0.003405765863135457, "Value Loss": 0.0014846568228676915, "_runtime": 15377.34032201767, "_timestamp": 1585612746.9731915, "_step": 297}
{"Episode reward": -67.51410735657338, "Episode length": 999, "Policy Loss": 0.0009049499640241265, "Value Loss": 0.0016286087920889258, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052, 0.21118813753128052]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.3425750434398651, -0.3285496234893799, -0.31452417373657227, -0.30049875378608704, -0.2864733338356018, -0.2724478840827942, -0.25842246413230896, -0.24439702928066254, -0.2303715944290161, -0.2163461595773697, -0.20232072472572327, -0.18829530477523804, -0.1742698699235916, -0.1602444350719452, -0.14621901512145996, -0.13219358026981354, -0.11816814541816711, -0.10414271056652069, -0.09011727571487427, -0.07609185576438904, -0.06206640601158142, -0.04804098606109619, -0.03401556611061096, -0.019990116357803345, -0.005964696407318115, 0.008060723543167114, 0.02208617329597473, 0.03611159324645996, 0.05013701319694519, 0.06416246294975281, 0.07818788290023804, 0.09221333265304565, 0.10623875260353088, 0.12026417255401611, 0.13428962230682373, 0.14831504225730896, 0.16234049201011658, 0.17636588215827942, 0.19039133191108704, 0.20441678166389465, 0.21844223141670227, 0.2324676215648651, 0.24649307131767273, 0.26051852107048035, 0.2745439112186432, 0.2885693609714508, 0.3025948107242584, 0.31662020087242126, 0.3306456506252289, 0.3446711003780365, 0.35869649052619934, 0.37272194027900696, 0.3867473900318146, 0.4007727801799774, 0.41479822993278503, 0.42882367968559265, 0.4428490698337555, 0.4568745195865631, 0.4708999693393707, 0.48492541909217834, 0.4989508092403412, 0.5129762887954712, 0.5270017385482788, 0.5410270690917969, 0.5550525188446045]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03979936242103577, -0.03819265961647034, -0.03658595681190491, -0.03497925400733948, -0.03337255120277405, -0.03176584839820862, -0.030159147456288338, -0.028552446514368057, -0.026945743709802628, -0.025339040905237198, -0.023732338100671768, -0.02212563529610634, -0.02051893249154091, -0.01891222968697548, -0.0173055287450552, -0.01569882594048977, -0.01409212313592434, -0.01248542033135891, -0.01087871752679348, -0.0092720165848732, -0.00766531378030777, -0.00605861097574234, -0.00445190817117691, -0.0028452053666114807, -0.001238502562046051, 0.00036820024251937866, 0.0019749030470848083, 0.0035816021263599396, 0.005188304930925369, 0.006795007735490799, 0.008401710540056229, 0.010008413344621658, 0.011615116149187088, 0.013221818953752518, 0.014828521758317947, 0.016435224562883377, 0.018041927367448807, 0.019648630172014236, 0.021255329251289368, 0.022862032055854797, 0.024468734860420227, 0.026075437664985657, 0.027682140469551086, 0.029288843274116516, 0.030895546078681946, 0.032502248883247375, 0.034108951687812805, 0.035715654492378235, 0.037322357296943665, 0.038929060101509094, 0.040535762906074524, 0.042142465710639954, 0.04374916851520538, 0.04535587131977081, 0.046962566673755646, 0.048569269478321075, 0.050175972282886505, 0.051782675087451935, 0.053389377892017365, 0.054996080696582794, 0.056602783501148224, 0.058209486305713654, 0.05981618911027908, 0.06142289191484451, 0.06302959471940994]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 4.0, 5.0, 6.0, 8.0, 10.0, 7.0, 14.0, 14.0, 17.0, 11.0, 18.0, 15.0, 23.0, 40.0, 42.0, 48.0, 30.0, 20.0, 16.0, 16.0, 17.0, 9.0, 19.0, 10.0, 10.0, 13.0, 13.0, 7.0, 7.0, 5.0, 2.0, 2.0, 6.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.05071857571601868, -0.04929950460791588, -0.04788042977452278, -0.04646135866641998, -0.045042283833026886, -0.04362321272492409, -0.04220414161682129, -0.04078506678342819, -0.039365991950035095, -0.0379469208419323, -0.0365278497338295, -0.0351087749004364, -0.0336897037923336, -0.032270632684230804, -0.030851557850837708, -0.02943248488008976, -0.028013411909341812, -0.026594338938593864, -0.025175265967845917, -0.02375619299709797, -0.02233712002635002, -0.020918048918247223, -0.019498975947499275, -0.018079902976751328, -0.01666083186864853, -0.015241757035255432, -0.013822685927152634, -0.012403611093759537, -0.010984539985656738, -0.009565465152263641, -0.008146394044160843, -0.006727319210767746, -0.0053082481026649475, -0.003889176994562149, -0.002470102161169052, -0.0010510310530662537, 0.00036804378032684326, 0.0017871148884296417, 0.0032061897218227386, 0.004625260829925537, 0.006044335663318634, 0.0074634067714214325, 0.008882477879524231, 0.010301552712917328, 0.011720623821020126, 0.013139694929122925, 0.014558769762516022, 0.01597784459590912, 0.01739691197872162, 0.018815986812114716, 0.020235061645507812, 0.02165413647890091, 0.02307320386171341, 0.024492278695106506, 0.025911353528499603, 0.0273304283618927, 0.0287494957447052, 0.030168570578098297, 0.031587645411491394, 0.033006712794303894, 0.03442578762769699, 0.03584486246109009, 0.037263937294483185, 0.038683004677295685, 0.04010207951068878]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0838097408413887, -0.08113311231136322, -0.07845649123191833, -0.07577986270189285, -0.07310323417186737, -0.07042660564184189, -0.067749984562397, -0.06507335603237152, -0.06239672750234604, -0.059720102697610855, -0.05704347789287567, -0.05436684936285019, -0.051690224558115005, -0.04901359602808952, -0.04633697122335434, -0.04366034269332886, -0.040983717888593674, -0.03830709308385849, -0.03563046455383301, -0.032953839749097824, -0.030277211219072342, -0.027600586414337158, -0.024923957884311676, -0.022247333079576492, -0.01957070827484131, -0.016894079744815826, -0.014217451214790344, -0.011540830135345459, -0.008864201605319977, -0.006187573075294495, -0.0035109445452690125, -0.0008343234658241272, 0.001842305064201355, 0.004518933594226837, 0.007195554673671722, 0.009872183203697205, 0.012548811733722687, 0.015225440263748169, 0.017902061343193054, 0.020578689873218536, 0.02325531840324402, 0.025931939482688904, 0.028608568012714386, 0.03128519654273987, 0.03396182507276535, 0.036638446152210236, 0.03931507468223572, 0.0419917032122612, 0.044668324291706085, 0.047344960272312164, 0.05002158135175705, 0.052698202431201935, 0.055374838411808014, 0.0580514594912529, 0.060728080570697784, 0.06340471655130386, 0.06608133763074875, 0.06875795871019363, 0.07143459469079971, 0.0741112157702446, 0.07678785175085068, 0.07946447283029556, 0.08214109390974045, 0.08481772989034653, 0.08749435096979141]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 1.0, 6.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06283897906541824, -0.06059066951274872, -0.05834235996007919, -0.05609405040740967, -0.053845737129449844, -0.05159742757678032, -0.049349118024110794, -0.04710080474615097, -0.044852495193481445, -0.04260418564081192, -0.040355876088142395, -0.03810756653547287, -0.035859256982803345, -0.03361094743013382, -0.031362634152173996, -0.02911432459950447, -0.026866015046834946, -0.02461770549416542, -0.022369395941495895, -0.020121082663536072, -0.017872773110866547, -0.015624463558197021, -0.013376154005527496, -0.011127844452857971, -0.008879534900188446, -0.0066312216222286224, -0.004382912069559097, -0.002134602516889572, 0.00011371076107025146, 0.0023620203137397766, 0.004610329866409302, 0.006858639419078827, 0.009106948971748352, 0.011355258524417877, 0.013603568077087402, 0.015851877629756927, 0.018100187182426453, 0.020348496735095978, 0.0225968137383461, 0.024845123291015625, 0.02709343284368515, 0.029341742396354675, 0.0315900519490242, 0.033838361501693726, 0.03608667105436325, 0.038334980607032776, 0.0405832901597023, 0.042831599712371826, 0.04507990926504135, 0.04732822626829147, 0.049576535820961, 0.051824845373630524, 0.05407315492630005, 0.056321464478969574, 0.0585697740316391, 0.060818083584308624, 0.06306640058755875, 0.06531470268964767, 0.0675630196928978, 0.06981132179498672, 0.07205963879823685, 0.07430794090032578, 0.0765562579035759, 0.07880456000566483, 0.08105287700891495]}, "_runtime": 15378.94337439537, "_timestamp": 1585612748.5762439, "_step": 298}
{"Episode reward": -72.16929123051861, "Episode length": 999, "Policy Loss": -0.006279504392296076, "Value Loss": 0.0014812074368819594, "_runtime": 15380.548101186752, "_timestamp": 1585612750.1809707, "_step": 299}
{"Episode reward": -72.50769394999384, "Episode length": 999, "Policy Loss": -0.006489529274404049, "Value Loss": 0.0014486809959635139, "_runtime": 15382.152541399002, "_timestamp": 1585612751.785411, "_step": 300}
{"Episode reward": -69.23337025103939, "Episode length": 999, "Policy Loss": 0.0005158017156645656, "Value Loss": 0.0014831438893452287, "_runtime": 15383.754915952682, "_timestamp": 1585612753.3877854, "_step": 301}
{"Episode reward": -69.73332383861327, "Episode length": 999, "Policy Loss": -0.0020586950704455376, "Value Loss": 0.0015410586493089795, "_runtime": 15385.351041316986, "_timestamp": 1585612754.9839108, "_step": 302}
{"Episode reward": -70.15386604522674, "Episode length": 999, "Policy Loss": -0.002523841569200158, "Value Loss": 0.0015159760368987918, "_runtime": 15386.945876598358, "_timestamp": 1585612756.578746, "_step": 303}
{"Episode reward": -71.57419933359503, "Episode length": 999, "Policy Loss": -0.0048092626966536045, "Value Loss": 0.001482364721596241, "_runtime": 15388.536541938782, "_timestamp": 1585612758.1694114, "_step": 304}
{"Episode reward": -69.26208401141675, "Episode length": 999, "Policy Loss": -0.0009697828209027648, "Value Loss": 0.0015393097419291735, "_runtime": 15390.13873744011, "_timestamp": 1585612759.771607, "_step": 305}
{"Episode reward": -68.4296302662756, "Episode length": 999, "Policy Loss": 0.0023088573943823576, "Value Loss": 0.0015856564277783036, "_runtime": 15391.742104768753, "_timestamp": 1585612761.3749743, "_step": 306}
{"Episode reward": -67.90972711305179, "Episode length": 999, "Policy Loss": 0.0014205940533429384, "Value Loss": 0.001538542564958334, "_runtime": 15393.332917928696, "_timestamp": 1585612762.9657874, "_step": 307}
{"Episode reward": -69.87480712819335, "Episode length": 999, "Policy Loss": -0.0023675302509218454, "Value Loss": 0.001512673101387918, "_runtime": 15394.936051130295, "_timestamp": 1585612764.5689206, "_step": 308}
{"Episode reward": -68.44930329241886, "Episode length": 999, "Policy Loss": 0.0020160360727459192, "Value Loss": 0.0015297953505069017, "_runtime": 15396.555813789368, "_timestamp": 1585612766.1886833, "_step": 309}
{"Episode reward": -67.26223228337798, "Episode length": 999, "Policy Loss": 0.0040217312052845955, "Value Loss": 0.0015931418165564537, "_runtime": 15398.162193775177, "_timestamp": 1585612767.7950633, "_step": 310}
{"Episode reward": -66.70831644875882, "Episode length": 999, "Policy Loss": 0.006331561598926783, "Value Loss": 0.001611888175830245, "_runtime": 15399.763640880585, "_timestamp": 1585612769.3965104, "_step": 311}
{"Episode reward": -66.76566609931314, "Episode length": 999, "Policy Loss": 0.005530575755983591, "Value Loss": 0.0015749504091218114, "_runtime": 15401.355485916138, "_timestamp": 1585612770.9883554, "_step": 312}
{"Episode reward": -69.36157215001869, "Episode length": 999, "Policy Loss": 0.0011290931142866611, "Value Loss": 0.0015010847710072994, "_runtime": 15402.953933000565, "_timestamp": 1585612772.5868025, "_step": 313}
{"Episode reward": -66.94155009728442, "Episode length": 999, "Policy Loss": 0.003918591886758804, "Value Loss": 0.001594007364474237, "_runtime": 15404.546387672424, "_timestamp": 1585612774.1792572, "_step": 314}
{"Episode reward": -67.92614008464433, "Episode length": 999, "Policy Loss": 0.0025962453801184893, "Value Loss": 0.001559667638503015, "_runtime": 15406.140924453735, "_timestamp": 1585612775.773794, "_step": 315}
{"Episode reward": -68.69704633628743, "Episode length": 999, "Policy Loss": -0.0015793152851983905, "Value Loss": 0.001486368477344513, "_runtime": 15407.72066617012, "_timestamp": 1585612777.3535357, "_step": 316}
{"Episode reward": -69.34627785804408, "Episode length": 999, "Policy Loss": 0.0009544658823870122, "Value Loss": 0.0014820826472714543, "_runtime": 15409.30984377861, "_timestamp": 1585612778.9427133, "_step": 317}
{"Episode reward": -69.04517101661662, "Episode length": 999, "Policy Loss": 4.991064270143397e-05, "Value Loss": 0.0015280209481716156, "_runtime": 15410.905360221863, "_timestamp": 1585612780.5382297, "_step": 318}
{"Episode reward": -67.43088979769801, "Episode length": 999, "Policy Loss": 0.0023571469355374575, "Value Loss": 0.0015440213028341532, "_runtime": 15412.498028755188, "_timestamp": 1585612782.1308982, "_step": 319}
{"Episode reward": -68.67750449785126, "Episode length": 999, "Policy Loss": -5.059539762442e-05, "Value Loss": 0.0015573024284094572, "_runtime": 15414.08345746994, "_timestamp": 1585612783.716327, "_step": 320}
{"Episode reward": -71.14661072869325, "Episode length": 999, "Policy Loss": -0.0025978232733905315, "Value Loss": 0.0014635119587182999, "_runtime": 15415.665771007538, "_timestamp": 1585612785.2986405, "_step": 321}
{"Episode reward": -64.94283003942842, "Episode length": 999, "Policy Loss": 0.007036096882075071, "Value Loss": 0.0016745588509365916, "_runtime": 15417.252414941788, "_timestamp": 1585612786.8852844, "_step": 322}
{"Episode reward": -67.5603195573631, "Episode length": 999, "Policy Loss": 0.0019799936562776566, "Value Loss": 0.0015845884336158633, "_runtime": 15418.837213754654, "_timestamp": 1585612788.4700832, "_step": 323}
{"Episode reward": -66.35933318211667, "Episode length": 999, "Policy Loss": 0.002392143476754427, "Value Loss": 0.0015867314068600535, "_runtime": 15420.46060705185, "_timestamp": 1585612790.0934765, "_step": 324}
{"Episode reward": -70.35209558845067, "Episode length": 999, "Policy Loss": -0.0010161481332033873, "Value Loss": 0.001494326745159924, "_runtime": 15422.037588834763, "_timestamp": 1585612791.6704583, "_step": 325}
{"Episode reward": -68.15751923288546, "Episode length": 999, "Policy Loss": 0.0011017827782779932, "Value Loss": 0.001600734074600041, "_runtime": 15423.624408721924, "_timestamp": 1585612793.2572782, "_step": 326}
{"Episode reward": -67.27672299743199, "Episode length": 999, "Policy Loss": 0.004456171300262213, "Value Loss": 0.001545160892419517, "_runtime": 15425.214082956314, "_timestamp": 1585612794.8469524, "_step": 327}
{"Episode reward": -66.45952248526385, "Episode length": 999, "Policy Loss": 0.0028966176323592663, "Value Loss": 0.0016047913813963532, "_runtime": 15426.787071943283, "_timestamp": 1585612796.4199414, "_step": 328}
{"Episode reward": -66.45021629068353, "Episode length": 999, "Policy Loss": 0.0042092399671673775, "Value Loss": 0.0015971323009580374, "_runtime": 15428.372884273529, "_timestamp": 1585612798.0057538, "_step": 329}
{"Episode reward": -66.31997651500166, "Episode length": 999, "Policy Loss": 0.0026559075340628624, "Value Loss": 0.0015872549265623093, "_runtime": 15429.960925102234, "_timestamp": 1585612799.5937946, "_step": 330}
{"Episode reward": -67.1769758568943, "Episode length": 999, "Policy Loss": 0.003763836110010743, "Value Loss": 0.0015801384579390287, "_runtime": 15431.548064947128, "_timestamp": 1585612801.1809344, "_step": 331}
{"Episode reward": -67.98957303631448, "Episode length": 999, "Policy Loss": 0.0006650967989116907, "Value Loss": 0.0015491580124944448, "_runtime": 15433.125801086426, "_timestamp": 1585612802.7586706, "_step": 332}
{"Episode reward": -68.9471789620942, "Episode length": 999, "Policy Loss": 0.001953510567545891, "Value Loss": 0.0015544352354481816, "_runtime": 15434.70248556137, "_timestamp": 1585612804.335355, "_step": 333}
{"Episode reward": -68.56448777208116, "Episode length": 999, "Policy Loss": -0.0021312793251127005, "Value Loss": 0.001480843173339963, "_runtime": 15436.286683321, "_timestamp": 1585612805.9195528, "_step": 334}
{"Episode reward": -66.4868076649893, "Episode length": 999, "Policy Loss": 0.002978939563035965, "Value Loss": 0.0016325614415109158, "_runtime": 15437.871104955673, "_timestamp": 1585612807.5039744, "_step": 335}
{"Episode reward": -66.94895100040746, "Episode length": 999, "Policy Loss": 0.0012448624474927783, "Value Loss": 0.0015754809137433767, "_runtime": 15439.458459615707, "_timestamp": 1585612809.091329, "_step": 336}
{"Episode reward": -67.09591163329081, "Episode length": 999, "Policy Loss": 0.002805186901241541, "Value Loss": 0.0015473270323127508, "_runtime": 15441.046090364456, "_timestamp": 1585612810.6789598, "_step": 337}
{"Episode reward": -67.5970564106312, "Episode length": 999, "Policy Loss": 0.0008948497124947608, "Value Loss": 0.0016013151034712791, "_runtime": 15442.632271528244, "_timestamp": 1585612812.265141, "_step": 338}
{"Episode reward": -64.50924955219102, "Episode length": 999, "Policy Loss": 0.005821945145726204, "Value Loss": 0.001582581433467567, "_runtime": 15444.258524894714, "_timestamp": 1585612813.8913944, "_step": 339}
{"Episode reward": -67.48508212627911, "Episode length": 999, "Policy Loss": -0.00037789467023685575, "Value Loss": 0.0015620291233062744, "_runtime": 15445.829675674438, "_timestamp": 1585612815.4625452, "_step": 340}
{"Episode reward": -67.14944395183018, "Episode length": 999, "Policy Loss": 0.0013367536012083292, "Value Loss": 0.0015433777589350939, "_runtime": 15447.405720233917, "_timestamp": 1585612817.0385897, "_step": 341}
{"Episode reward": -65.67624079013252, "Episode length": 999, "Policy Loss": 0.004263949580490589, "Value Loss": 0.0016335445689037442, "_runtime": 15448.99234676361, "_timestamp": 1585612818.6252162, "_step": 342}
{"Episode reward": -64.23015586599438, "Episode length": 999, "Policy Loss": 0.0063955774530768394, "Value Loss": 0.0016833434347063303, "_runtime": 15450.572480916977, "_timestamp": 1585612820.2053504, "_step": 343}
{"Episode reward": -66.12747108292652, "Episode length": 999, "Policy Loss": 0.0032339487224817276, "Value Loss": 0.0016619577072560787, "_runtime": 15452.158734798431, "_timestamp": 1585612821.7916043, "_step": 344}
{"Episode reward": -64.1424726232271, "Episode length": 999, "Policy Loss": 0.00709905382245779, "Value Loss": 0.0016376799903810024, "_runtime": 15453.74238872528, "_timestamp": 1585612823.3752582, "_step": 345}
{"Episode reward": -64.5563075095372, "Episode length": 999, "Policy Loss": 0.005077893380075693, "Value Loss": 0.0016693018842488527, "_runtime": 15455.323313713074, "_timestamp": 1585612824.9561832, "_step": 346}
{"Episode reward": -64.00751160371709, "Episode length": 999, "Policy Loss": 0.005079051945358515, "Value Loss": 0.0016483699437230825, "_runtime": 15456.902481079102, "_timestamp": 1585612826.5353506, "_step": 347}
{"Episode reward": -66.94577068280836, "Episode length": 999, "Policy Loss": -0.0003001130244228989, "Value Loss": 0.0015422633150592446, "_runtime": 15458.485870838165, "_timestamp": 1585612828.1187403, "_step": 348}
{"Episode reward": -63.79133522806021, "Episode length": 999, "Policy Loss": 0.004882550798356533, "Value Loss": 0.001660331734456122, "_runtime": 15460.06987452507, "_timestamp": 1585612829.702744, "_step": 349}
{"Episode reward": -63.30195100434664, "Episode length": 999, "Policy Loss": 0.005981810856610537, "Value Loss": 0.001661880873143673, "_runtime": 15461.653563022614, "_timestamp": 1585612831.2864325, "_step": 350}
{"Episode reward": -62.46745611252543, "Episode length": 999, "Policy Loss": 0.009471041150391102, "Value Loss": 0.001652554958127439, "_runtime": 15463.239176750183, "_timestamp": 1585612832.8720462, "_step": 351}
{"Episode reward": -64.146832545971, "Episode length": 999, "Policy Loss": 0.0036333256866782904, "Value Loss": 0.0015831416239961982, "_runtime": 15464.801625967026, "_timestamp": 1585612834.4344954, "_step": 352}
{"Episode reward": -63.88030060642011, "Episode length": 999, "Policy Loss": 0.005626042373478413, "Value Loss": 0.0016250528860837221, "_runtime": 15466.415282726288, "_timestamp": 1585612836.0481522, "_step": 353}
{"Episode reward": -61.711078730503424, "Episode length": 999, "Policy Loss": 0.010017368011176586, "Value Loss": 0.0017027885187417269, "_runtime": 15467.989911794662, "_timestamp": 1585612837.6227813, "_step": 354}
{"Episode reward": -64.64090604430305, "Episode length": 999, "Policy Loss": 0.004867898765951395, "Value Loss": 0.0016092178411781788, "_runtime": 15469.57230591774, "_timestamp": 1585612839.2051754, "_step": 355}
{"Episode reward": -63.09644910391541, "Episode length": 999, "Policy Loss": 0.0049690608866512775, "Value Loss": 0.001670770812779665, "_runtime": 15471.156253099442, "_timestamp": 1585612840.7891226, "_step": 356}
{"Episode reward": -66.21275737529012, "Episode length": 999, "Policy Loss": 0.0015597715973854065, "Value Loss": 0.0015807036543264985, "_runtime": 15472.721048116684, "_timestamp": 1585612842.3539176, "_step": 357}
{"Episode reward": -62.49461797033599, "Episode length": 999, "Policy Loss": 0.007723081391304731, "Value Loss": 0.0016530422726646066, "_runtime": 15474.30213212967, "_timestamp": 1585612843.9350016, "_step": 358}
{"Episode reward": -62.163990181614246, "Episode length": 999, "Policy Loss": 0.004912410397082567, "Value Loss": 0.0016464932123199105, "_runtime": 15475.885135173798, "_timestamp": 1585612845.5180047, "_step": 359}
{"Episode reward": -64.7384261902979, "Episode length": 999, "Policy Loss": 0.0023486686404794455, "Value Loss": 0.0015876458492130041, "_runtime": 15477.469062328339, "_timestamp": 1585612847.1019318, "_step": 360}
{"Episode reward": -64.82894218446903, "Episode length": 999, "Policy Loss": 0.0028666730504482985, "Value Loss": 0.001637370907701552, "_runtime": 15479.055410385132, "_timestamp": 1585612848.6882799, "_step": 361}
{"Episode reward": -63.15598164623321, "Episode length": 999, "Policy Loss": 0.002427320694550872, "Value Loss": 0.0016697357641533017, "_runtime": 15480.633253335953, "_timestamp": 1585612850.2661228, "_step": 362}
{"Episode reward": -66.34781793065375, "Episode length": 999, "Policy Loss": 0.000837688276078552, "Value Loss": 0.0015401931013911963, "_runtime": 15482.218648672104, "_timestamp": 1585612851.8515182, "_step": 363}
{"Episode reward": -65.14598589559778, "Episode length": 999, "Policy Loss": 0.000685210048686713, "Value Loss": 0.0015980268362909555, "_runtime": 15483.788430452347, "_timestamp": 1585612853.4213, "_step": 364}
{"Episode reward": -65.0251571403399, "Episode length": 999, "Policy Loss": 0.0008653589757159352, "Value Loss": 0.0016300873830914497, "_runtime": 15485.372995615005, "_timestamp": 1585612855.005865, "_step": 365}
{"Episode reward": -65.30175441357245, "Episode length": 999, "Policy Loss": 0.00017729269166011363, "Value Loss": 0.0015777037478983402, "_runtime": 15486.95482969284, "_timestamp": 1585612856.5876992, "_step": 366}
{"Episode reward": -63.38979358681341, "Episode length": 999, "Policy Loss": 0.004295336548238993, "Value Loss": 0.0016490689013153315, "_runtime": 15488.537857532501, "_timestamp": 1585612858.170727, "_step": 367}
{"Episode reward": -62.61532769768159, "Episode length": 999, "Policy Loss": 0.0050650122575461864, "Value Loss": 0.0015882288571447134, "_runtime": 15490.155169248581, "_timestamp": 1585612859.7880387, "_step": 368}
{"Episode reward": -64.63808448809964, "Episode length": 999, "Policy Loss": -0.00036031537456437945, "Value Loss": 0.001630557468160987, "_runtime": 15491.73917555809, "_timestamp": 1585612861.372045, "_step": 369}
{"Episode reward": -63.15212358700788, "Episode length": 999, "Policy Loss": 0.003921713680028915, "Value Loss": 0.0016691847704350948, "_runtime": 15493.32351732254, "_timestamp": 1585612862.9563868, "_step": 370}
{"Episode reward": -62.45792779401433, "Episode length": 999, "Policy Loss": 0.004921716172248125, "Value Loss": 0.0016914046136662364, "_runtime": 15494.906966209412, "_timestamp": 1585612864.5398357, "_step": 371}
{"Episode reward": -64.21328837217915, "Episode length": 999, "Policy Loss": 0.0020794046577066183, "Value Loss": 0.001619347371160984, "_runtime": 15496.469779968262, "_timestamp": 1585612866.1026495, "_step": 372}
{"Episode reward": -65.32420396380545, "Episode length": 999, "Policy Loss": -0.0013506895629689097, "Value Loss": 0.0015663113445043564, "_runtime": 15498.05930519104, "_timestamp": 1585612867.6921747, "_step": 373}
{"Episode reward": -62.840481774852385, "Episode length": 999, "Policy Loss": 0.003861821023747325, "Value Loss": 0.001653063460253179, "_runtime": 15499.64170742035, "_timestamp": 1585612869.274577, "_step": 374}
{"Episode reward": -61.9304209291506, "Episode length": 999, "Policy Loss": 0.00570411654189229, "Value Loss": 0.0016733361408114433, "_runtime": 15501.205368041992, "_timestamp": 1585612870.8382375, "_step": 375}
{"Episode reward": -63.18870868036971, "Episode length": 999, "Policy Loss": 0.002826735842972994, "Value Loss": 0.0015756274806335568, "_runtime": 15502.770159244537, "_timestamp": 1585612872.4030287, "_step": 376}
{"Episode reward": -63.709813173399844, "Episode length": 999, "Policy Loss": 0.0016562121454626322, "Value Loss": 0.0015675370814278722, "_runtime": 15504.344276189804, "_timestamp": 1585612873.9771457, "_step": 377}
{"Episode reward": -64.43034544460721, "Episode length": 999, "Policy Loss": -8.803942910162732e-05, "Value Loss": 0.0015741068636998534, "_runtime": 15505.915565490723, "_timestamp": 1585612875.548435, "_step": 378}
{"Episode reward": -65.52889354615552, "Episode length": 999, "Policy Loss": -0.002489499282091856, "Value Loss": 0.0016574639594182372, "_runtime": 15507.488718748093, "_timestamp": 1585612877.1215882, "_step": 379}
{"Episode reward": -64.85647640627218, "Episode length": 999, "Policy Loss": -0.0012909723445773125, "Value Loss": 0.0016327638877555728, "_runtime": 15509.07199716568, "_timestamp": 1585612878.7048666, "_step": 380}
{"Episode reward": -64.99546650150126, "Episode length": 999, "Policy Loss": -0.0018800541292876005, "Value Loss": 0.0016533551970496774, "_runtime": 15510.651364326477, "_timestamp": 1585612880.2842338, "_step": 381}
{"Episode reward": -63.62257486814622, "Episode length": 999, "Policy Loss": 0.002030312782153487, "Value Loss": 0.0016423611668869853, "_runtime": 15512.223132371902, "_timestamp": 1585612881.8560019, "_step": 382}
{"Episode reward": -63.64178364861709, "Episode length": 999, "Policy Loss": 0.0005442312103696167, "Value Loss": 0.0016764713218435645, "_runtime": 15513.834910869598, "_timestamp": 1585612883.4677804, "_step": 383}
{"Episode reward": -63.94752095590178, "Episode length": 999, "Policy Loss": 0.0010337182320654392, "Value Loss": 0.0015975824790075421, "_runtime": 15515.408190250397, "_timestamp": 1585612885.0410597, "_step": 384}
{"Episode reward": -63.44771775099516, "Episode length": 999, "Policy Loss": 0.0022886230144649744, "Value Loss": 0.0016798635479062796, "_runtime": 15516.967788219452, "_timestamp": 1585612886.6006577, "_step": 385}
{"Episode reward": -63.78819230299074, "Episode length": 999, "Policy Loss": 0.0005371253937482834, "Value Loss": 0.001599521841853857, "_runtime": 15518.543677568436, "_timestamp": 1585612888.176547, "_step": 386}
{"Episode reward": -64.79031348361902, "Episode length": 999, "Policy Loss": -0.0018071068916469812, "Value Loss": 0.0016046172240749002, "_runtime": 15520.116697072983, "_timestamp": 1585612889.7495666, "_step": 387}
{"Episode reward": -64.35565901832206, "Episode length": 999, "Policy Loss": -0.001543713267892599, "Value Loss": 0.0016136930789798498, "_runtime": 15521.690303087234, "_timestamp": 1585612891.3231726, "_step": 388}
{"Episode reward": -65.55226905478544, "Episode length": 999, "Policy Loss": -0.0023421100340783596, "Value Loss": 0.0015907775377854705, "_runtime": 15523.264471530914, "_timestamp": 1585612892.897341, "_step": 389}
{"Episode reward": -63.97814711619232, "Episode length": 999, "Policy Loss": 0.0009140173788182437, "Value Loss": 0.001646992634050548, "_runtime": 15524.828933954239, "_timestamp": 1585612894.4618034, "_step": 390}
{"Episode reward": -65.18877700010384, "Episode length": 999, "Policy Loss": -0.001287516439333558, "Value Loss": 0.001557513838633895, "_runtime": 15526.403086423874, "_timestamp": 1585612896.035956, "_step": 391}
{"Episode reward": -61.38951655860251, "Episode length": 999, "Policy Loss": 0.003968199249356985, "Value Loss": 0.0016910595586523414, "_runtime": 15527.97733259201, "_timestamp": 1585612897.610202, "_step": 392}
{"Episode reward": -63.67051811394839, "Episode length": 999, "Policy Loss": 0.0007007268141023815, "Value Loss": 0.0016515894094482064, "_runtime": 15529.552608251572, "_timestamp": 1585612899.1854777, "_step": 393}
{"Episode reward": -63.74090492607706, "Episode length": 999, "Policy Loss": -0.00010661445412551984, "Value Loss": 0.0016152571188285947, "_runtime": 15531.113820552826, "_timestamp": 1585612900.74669, "_step": 394}
{"Episode reward": -64.09922624380899, "Episode length": 999, "Policy Loss": -0.0007128232973627746, "Value Loss": 0.0016316554974764585, "_runtime": 15532.688534498215, "_timestamp": 1585612902.321404, "_step": 395}
{"Episode reward": -61.4892894622372, "Episode length": 999, "Policy Loss": 0.0032741203904151917, "Value Loss": 0.0016857926966622472, "_runtime": 15534.266912937164, "_timestamp": 1585612903.8997824, "_step": 396}
{"Episode reward": -64.81602549587578, "Episode length": 999, "Policy Loss": -0.0030439693946391344, "Value Loss": 0.0015669864369556308, "_runtime": 15535.839194774628, "_timestamp": 1585612905.4720643, "_step": 397}
{"Episode reward": -64.26894649743764, "Episode length": 999, "Policy Loss": 0.0006145387305878103, "Value Loss": 0.001591436448507011, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377, 2.5904228687286377]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.8732751607894897, -1.7940967082977295, -1.7149182558059692, -1.635739803314209, -1.5565614700317383, -1.4773828983306885, -1.3982045650482178, -1.3190261125564575, -1.2398476600646973, -1.160669207572937, -1.0814907550811768, -1.002312421798706, -0.923133909702301, -0.8439555168151855, -0.7647770643234253, -0.685598611831665, -0.6064201593399048, -0.5272417068481445, -0.4480632543563843, -0.368884801864624, -0.28970634937286377, -0.21052801609039307, -0.1313495635986328, -0.05217111110687256, 0.027007341384887695, 0.10618579387664795, 0.18536412715911865, 0.26454269886016846, 0.34372103214263916, 0.42289960384368896, 0.5020779371261597, 0.5812565088272095, 0.6604348421096802, 0.7396131753921509, 0.8187917470932007, 0.8979700803756714, 0.9771486520767212, 1.056326985359192, 1.1355055570602417, 1.2146838903427124, 1.2938624620437622, 1.373040795326233, 1.4522191286087036, 1.5313977003097534, 1.6105760335922241, 1.689754605293274, 1.7689329385757446, 1.8481115102767944, 1.9272898435592651, 2.0064682960510254, 2.085646629333496, 2.164824962615967, 2.2440032958984375, 2.3231821060180664, 2.402360439300537, 2.481538772583008, 2.5607171058654785, 2.639895439147949, 2.719074249267578, 2.798252582550049, 2.8774309158325195, 2.9566092491149902, 3.035788059234619, 3.11496639251709, 3.1941447257995605]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4978254437446594, -0.4784395694732666, -0.4590536653995514, -0.43966779112815857, -0.42028191685676575, -0.40089601278305054, -0.3815101385116577, -0.3621242642402649, -0.34273838996887207, -0.32335248589515686, -0.30396661162376404, -0.28458070755004883, -0.265194833278656, -0.24580895900726318, -0.22642308473587036, -0.20703718066215515, -0.18765130639076233, -0.1682654321193695, -0.1488795280456543, -0.12949365377426147, -0.11010777950286865, -0.09072187542915344, -0.07133600115776062, -0.0519501268863678, -0.03256422281265259, -0.013178348541259766, 0.006207525730133057, 0.02559340000152588, 0.0449792742729187, 0.0643652081489563, 0.08375108242034912, 0.10313695669174194, 0.12252283096313477, 0.1419087052345276, 0.1612945795059204, 0.18068045377731323, 0.20006638765335083, 0.21945226192474365, 0.23883813619613647, 0.2582240104675293, 0.2776098847389221, 0.29699575901031494, 0.31638169288635254, 0.33576756715774536, 0.3551534414291382, 0.374539315700531, 0.39392518997192383, 0.41331106424331665, 0.43269699811935425, 0.45208287239074707, 0.4714687466621399, 0.4908546209335327, 0.5102404952049255, 0.5296264290809631, 0.5490122437477112, 0.5683981776237488, 0.5877839922904968, 0.6071699261665344, 0.626555860042572, 0.6459416747093201, 0.6653276085853577, 0.6847134232521057, 0.7040993571281433, 0.7234851717948914, 0.742871105670929]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 2.0, 3.0, 13.0, 9.0, 13.0, 21.0, 20.0, 28.0, 26.0, 34.0, 77.0, 46.0, 23.0, 32.0, 15.0, 12.0, 15.0, 16.0, 14.0, 11.0, 9.0, 12.0, 5.0, 5.0, 4.0, 2.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2707144021987915, -0.2609105706214905, -0.25110673904418945, -0.24130290746688843, -0.2314990758895874, -0.22169524431228638, -0.21189141273498535, -0.20208758115768433, -0.1922837495803833, -0.18247991800308228, -0.17267608642578125, -0.16287225484848022, -0.1530684232711792, -0.14326459169387817, -0.13346076011657715, -0.12365692853927612, -0.1138530969619751, -0.10404926538467407, -0.09424543380737305, -0.08444160223007202, -0.074637770652771, -0.06483393907546997, -0.055030107498168945, -0.04522627592086792, -0.035422444343566895, -0.02561861276626587, -0.015814781188964844, -0.006010949611663818, 0.003792881965637207, 0.013596713542938232, 0.023400545120239258, 0.03320437669754028, 0.04300820827484131, 0.052812039852142334, 0.06261587142944336, 0.07241970300674438, 0.08222353458404541, 0.09202736616134644, 0.10183119773864746, 0.11163502931594849, 0.12143886089324951, 0.13124269247055054, 0.14104652404785156, 0.1508503556251526, 0.1606541872024536, 0.17045801877975464, 0.18026185035705566, 0.1900656819343567, 0.19986951351165771, 0.20967334508895874, 0.21947717666625977, 0.2292810082435608, 0.23908483982086182, 0.24888867139816284, 0.25869250297546387, 0.2684963345527649, 0.2783001661300659, 0.28810399770736694, 0.29790782928466797, 0.307711660861969, 0.31751549243927, 0.32731932401657104, 0.33712315559387207, 0.3469269871711731, 0.3567308187484741]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0489170551300049, -1.0199496746063232, -0.9909822344779968, -0.9620147943496704, -0.9330474138259888, -0.9040799736976624, -0.8751125931739807, -0.8461451530456543, -0.8171777725219727, -0.7882103323936462, -0.7592428922653198, -0.7302755117416382, -0.7013081312179565, -0.6723406910896301, -0.6433732509613037, -0.6144058704376221, -0.5854384899139404, -0.556471049785614, -0.5275036096572876, -0.49853622913360596, -0.46956878900527954, -0.4406014084815979, -0.4116339683532715, -0.38266658782958984, -0.3536991477012634, -0.3247317671775818, -0.29576432704925537, -0.26679694652557373, -0.23782950639724731, -0.20886212587356567, -0.17989468574523926, -0.15092730522155762, -0.1219598650932312, -0.09299242496490479, -0.06402504444122314, -0.035057663917541504, -0.0060901641845703125, 0.022877216339111328, 0.05184459686279297, 0.08081197738647461, 0.1097794771194458, 0.13874685764312744, 0.16771423816680908, 0.19668161869049072, 0.22564911842346191, 0.25461649894714355, 0.2835838794708252, 0.31255125999450684, 0.341518759727478, 0.37048614025115967, 0.3994535207748413, 0.4284210205078125, 0.45738840103149414, 0.4863557815551758, 0.5153231620788574, 0.5442906618118286, 0.5732580423355103, 0.6022254228591919, 0.6311928033828735, 0.6601603031158447, 0.6891276836395264, 0.718095064163208, 0.7470624446868896, 0.7760299444198608, 0.8049973249435425]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 0.0, 6.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.29607704281806946, -0.2856649160385132, -0.2752527892589569, -0.26484066247940063, -0.25442853569984436, -0.24401640892028809, -0.233604297041893, -0.22319217026233673, -0.21278004348278046, -0.20236791670322418, -0.1919557899236679, -0.18154367804527283, -0.17113155126571655, -0.16071942448616028, -0.150307297706604, -0.13989517092704773, -0.12948304414749146, -0.11907091736793518, -0.1086587905883789, -0.09824666380882263, -0.08783453702926636, -0.07742242515087128, -0.067010298371315, -0.05659817159175873, -0.046186044812202454, -0.03577393293380737, -0.0253618061542511, -0.014949679374694824, -0.00453755259513855, 0.005874574184417725, 0.016286700963974, 0.026698827743530273, 0.03711095452308655, 0.04752308130264282, 0.0579352080821991, 0.06834733486175537, 0.07875946164131165, 0.08917158842086792, 0.0995837152004242, 0.10999584197998047, 0.12040796875953674, 0.13082006573677063, 0.1412321925163269, 0.15164431929588318, 0.16205644607543945, 0.17246857285499573, 0.182880699634552, 0.19329282641410828, 0.20370495319366455, 0.21411707997322083, 0.2245291769504547, 0.23494133353233337, 0.24535343050956726, 0.2557655870914459, 0.2661776840686798, 0.27658984065055847, 0.28700193762779236, 0.297414094209671, 0.3078261911869049, 0.31823834776878357, 0.32865044474601746, 0.3390626013278961, 0.34947469830513, 0.35988685488700867, 0.37029895186424255]}, "_runtime": 15537.452659606934, "_timestamp": 1585612907.085529, "_step": 398}
{"Episode reward": -62.997786069435286, "Episode length": 999, "Policy Loss": 0.00037958964821882546, "Value Loss": 0.0016350271180272102, "_runtime": 15539.024490833282, "_timestamp": 1585612908.6573603, "_step": 399}
{"Episode reward": -64.27974639019422, "Episode length": 999, "Policy Loss": 0.0008660415187478065, "Value Loss": 0.0016100751236081123, "_runtime": 15540.595373153687, "_timestamp": 1585612910.2282426, "_step": 400}
{"Episode reward": -62.487610710100824, "Episode length": 999, "Policy Loss": 0.003539267461746931, "Value Loss": 0.0016393394907936454, "_runtime": 15542.166043519974, "_timestamp": 1585612911.798913, "_step": 401}
{"Episode reward": -64.17898552708836, "Episode length": 999, "Policy Loss": -0.0002157952985726297, "Value Loss": 0.0016065672971308231, "_runtime": 15543.727900743484, "_timestamp": 1585612913.3607702, "_step": 402}
{"Episode reward": -62.15156962293833, "Episode length": 999, "Policy Loss": 0.0022932204883545637, "Value Loss": 0.0016376660205423832, "_runtime": 15545.290706634521, "_timestamp": 1585612914.923576, "_step": 403}
{"Episode reward": -62.25715464450232, "Episode length": 999, "Policy Loss": 0.003977434244006872, "Value Loss": 0.0016173362964764237, "_runtime": 15546.853940963745, "_timestamp": 1585612916.4868104, "_step": 404}
{"Episode reward": -63.110262212056156, "Episode length": 999, "Policy Loss": 0.003156522521749139, "Value Loss": 0.0015970709500834346, "_runtime": 15548.417911529541, "_timestamp": 1585612918.050781, "_step": 405}
{"Episode reward": -64.48331919269982, "Episode length": 999, "Policy Loss": -0.001186756300739944, "Value Loss": 0.0015826198505237699, "_runtime": 15549.977979183197, "_timestamp": 1585612919.6108487, "_step": 406}
{"Episode reward": -62.83989002577647, "Episode length": 999, "Policy Loss": 0.0009833446238189936, "Value Loss": 0.0016339396825060248, "_runtime": 15551.548876285553, "_timestamp": 1585612921.1817458, "_step": 407}
{"Episode reward": -61.22296958358707, "Episode length": 999, "Policy Loss": 0.0027989207301288843, "Value Loss": 0.0016686185263097286, "_runtime": 15553.126398324966, "_timestamp": 1585612922.7592678, "_step": 408}
{"Episode reward": -62.43510687461587, "Episode length": 999, "Policy Loss": 0.0024950604420155287, "Value Loss": 0.0016858113231137395, "_runtime": 15554.696094036102, "_timestamp": 1585612924.3289635, "_step": 409}
{"Episode reward": -64.59231018855638, "Episode length": 999, "Policy Loss": -0.00046631283476017416, "Value Loss": 0.0016105396207422018, "_runtime": 15556.267870664597, "_timestamp": 1585612925.9007401, "_step": 410}
{"Episode reward": -61.799367202591654, "Episode length": 999, "Policy Loss": 0.003449007635936141, "Value Loss": 0.001649282407015562, "_runtime": 15557.837871551514, "_timestamp": 1585612927.470741, "_step": 411}
{"Episode reward": -63.04096345849542, "Episode length": 999, "Policy Loss": 0.000351489259628579, "Value Loss": 0.0016232767375186086, "_runtime": 15559.408290147781, "_timestamp": 1585612929.0411596, "_step": 412}
{"Episode reward": -63.287267291515924, "Episode length": 999, "Policy Loss": -0.0024235465098172426, "Value Loss": 0.0016310111386701465, "_runtime": 15561.025833129883, "_timestamp": 1585612930.6587026, "_step": 413}
{"Episode reward": -64.3016870374791, "Episode length": 999, "Policy Loss": -0.00093176553491503, "Value Loss": 0.001597982132807374, "_runtime": 15562.600643873215, "_timestamp": 1585612932.2335134, "_step": 414}
{"Episode reward": -64.26037470068646, "Episode length": 999, "Policy Loss": -0.002054924611002207, "Value Loss": 0.0015871734358370304, "_runtime": 15564.174540281296, "_timestamp": 1585612933.8074098, "_step": 415}
{"Episode reward": -62.90258966214434, "Episode length": 999, "Policy Loss": 0.001038095448166132, "Value Loss": 0.0016615245258435607, "_runtime": 15565.748508930206, "_timestamp": 1585612935.3813784, "_step": 416}
{"Episode reward": -62.66612293925012, "Episode length": 999, "Policy Loss": 0.0012466423213481903, "Value Loss": 0.001625656965188682, "_runtime": 15567.337048768997, "_timestamp": 1585612936.9699183, "_step": 417}
{"Episode reward": -63.98555939877738, "Episode length": 999, "Policy Loss": 2.887704067688901e-05, "Value Loss": 0.0016178812365978956, "_runtime": 15568.921392679214, "_timestamp": 1585612938.5542622, "_step": 418}
{"Episode reward": -65.1417777850907, "Episode length": 999, "Policy Loss": -0.0025877822190523148, "Value Loss": 0.0016018146416172385, "_runtime": 15570.511623382568, "_timestamp": 1585612940.1444929, "_step": 419}
{"Episode reward": -62.6410992944645, "Episode length": 999, "Policy Loss": 0.0010696921963244677, "Value Loss": 0.0016731504583731294, "_runtime": 15572.085748672485, "_timestamp": 1585612941.7186182, "_step": 420}
{"Episode reward": -63.69418344667526, "Episode length": 999, "Policy Loss": -0.0008775945752859116, "Value Loss": 0.0016224868595600128, "_runtime": 15573.671488523483, "_timestamp": 1585612943.304358, "_step": 421}
{"Episode reward": -63.20431026647979, "Episode length": 999, "Policy Loss": 0.0009917806601151824, "Value Loss": 0.0015928857028484344, "_runtime": 15575.258736371994, "_timestamp": 1585612944.8916059, "_step": 422}
{"Episode reward": -62.40936151011664, "Episode length": 999, "Policy Loss": 0.0012328375596553087, "Value Loss": 0.001670021447353065, "_runtime": 15576.835823059082, "_timestamp": 1585612946.4686925, "_step": 423}
{"Episode reward": -62.61101218418033, "Episode length": 999, "Policy Loss": 0.001214522635564208, "Value Loss": 0.001653139479458332, "_runtime": 15578.42020869255, "_timestamp": 1585612948.0530782, "_step": 424}
{"Episode reward": -62.8146136526147, "Episode length": 999, "Policy Loss": 0.0027477224357426167, "Value Loss": 0.001662013353779912, "_runtime": 15580.00799202919, "_timestamp": 1585612949.6408615, "_step": 425}
{"Episode reward": -64.56580284065345, "Episode length": 999, "Policy Loss": -0.0034275820944458246, "Value Loss": 0.0015790153993293643, "_runtime": 15581.585453510284, "_timestamp": 1585612951.218323, "_step": 426}
{"Episode reward": -61.00662806051622, "Episode length": 999, "Policy Loss": 0.004325173329561949, "Value Loss": 0.0016182154649868608, "_runtime": 15583.198882341385, "_timestamp": 1585612952.8317518, "_step": 427}
{"Episode reward": -61.916813925695365, "Episode length": 999, "Policy Loss": 0.004715160466730595, "Value Loss": 0.001676308223977685, "_runtime": 15584.779913902283, "_timestamp": 1585612954.4127834, "_step": 428}
{"Episode reward": -64.04394119766306, "Episode length": 999, "Policy Loss": -0.0003351724299136549, "Value Loss": 0.0016030916012823582, "_runtime": 15586.366045951843, "_timestamp": 1585612955.9989154, "_step": 429}
{"Episode reward": -62.75781637007304, "Episode length": 999, "Policy Loss": 0.00138007546775043, "Value Loss": 0.0016761457081884146, "_runtime": 15587.941843032837, "_timestamp": 1585612957.5747125, "_step": 430}
{"Episode reward": -64.62595619880652, "Episode length": 999, "Policy Loss": -0.0013857886660844088, "Value Loss": 0.0015845410525798798, "_runtime": 15589.529234409332, "_timestamp": 1585612959.162104, "_step": 431}
{"Episode reward": -64.3385689011134, "Episode length": 999, "Policy Loss": -0.0017945339204743505, "Value Loss": 0.0015984016936272383, "_runtime": 15591.113946676254, "_timestamp": 1585612960.7468162, "_step": 432}
{"Episode reward": -62.920924871098265, "Episode length": 999, "Policy Loss": 0.000487814744701609, "Value Loss": 0.001612591091543436, "_runtime": 15592.690267086029, "_timestamp": 1585612962.3231366, "_step": 433}
{"Episode reward": -63.732338860448, "Episode length": 999, "Policy Loss": -0.0012336431536823511, "Value Loss": 0.001667588367126882, "_runtime": 15594.278082847595, "_timestamp": 1585612963.9109523, "_step": 434}
{"Episode reward": -64.11063278925596, "Episode length": 999, "Policy Loss": -0.0008195350528694689, "Value Loss": 0.0016114931786432862, "_runtime": 15595.865451574326, "_timestamp": 1585612965.498321, "_step": 435}
{"Episode reward": -63.60386359545217, "Episode length": 999, "Policy Loss": 0.0006431569345295429, "Value Loss": 0.0016102184308692813, "_runtime": 15597.449274539948, "_timestamp": 1585612967.082144, "_step": 436}
{"Episode reward": -67.1558599603763, "Episode length": 999, "Policy Loss": -0.006645882502198219, "Value Loss": 0.0016094176098704338, "_runtime": 15599.03628540039, "_timestamp": 1585612968.669155, "_step": 437}
{"Episode reward": -64.65426830138506, "Episode length": 999, "Policy Loss": -0.0009518019505776465, "Value Loss": 0.00158852303866297, "_runtime": 15600.622192621231, "_timestamp": 1585612970.255062, "_step": 438}
{"Episode reward": -66.10079751441167, "Episode length": 999, "Policy Loss": -0.004636059980839491, "Value Loss": 0.0015571421245113015, "_runtime": 15602.20731472969, "_timestamp": 1585612971.8401842, "_step": 439}
{"Episode reward": -66.27054114949092, "Episode length": 999, "Policy Loss": -0.005033858120441437, "Value Loss": 0.001605888013727963, "_runtime": 15603.786074876785, "_timestamp": 1585612973.4189444, "_step": 440}
{"Episode reward": -64.74857906890429, "Episode length": 999, "Policy Loss": -0.0018044825410470366, "Value Loss": 0.0015934266848489642, "_runtime": 15605.364384651184, "_timestamp": 1585612974.9972541, "_step": 441}
{"Episode reward": -65.69751660415204, "Episode length": 999, "Policy Loss": -0.005050603300333023, "Value Loss": 0.0016134717734530568, "_runtime": 15606.986532211304, "_timestamp": 1585612976.6194017, "_step": 442}
{"Episode reward": -63.88870085535381, "Episode length": 999, "Policy Loss": -0.00020890393352601677, "Value Loss": 0.0016154447803273797, "_runtime": 15608.571626663208, "_timestamp": 1585612978.2044961, "_step": 443}
{"Episode reward": -62.71803456427709, "Episode length": 999, "Policy Loss": 0.0020037288777530193, "Value Loss": 0.0016825511120259762, "_runtime": 15610.156617879868, "_timestamp": 1585612979.7894874, "_step": 444}
{"Episode reward": -64.9173082289152, "Episode length": 999, "Policy Loss": -0.0033927783370018005, "Value Loss": 0.0016122286906465888, "_runtime": 15611.738790273666, "_timestamp": 1585612981.3716598, "_step": 445}
{"Episode reward": -65.11324794171746, "Episode length": 999, "Policy Loss": -0.0029418275225907564, "Value Loss": 0.0016184537671506405, "_runtime": 15613.322533607483, "_timestamp": 1585612982.955403, "_step": 446}
{"Episode reward": -65.51032365525526, "Episode length": 999, "Policy Loss": -0.0024453308433294296, "Value Loss": 0.0015775390202179551, "_runtime": 15614.905449151993, "_timestamp": 1585612984.5383186, "_step": 447}
{"Episode reward": -67.62576823251393, "Episode length": 999, "Policy Loss": -0.007343490142375231, "Value Loss": 0.0015417244285345078, "_runtime": 15616.476697206497, "_timestamp": 1585612986.1095667, "_step": 448}
{"Episode reward": -65.61240620850226, "Episode length": 999, "Policy Loss": -0.0023032850585877895, "Value Loss": 0.0016012471169233322, "_runtime": 15618.05059337616, "_timestamp": 1585612987.6834629, "_step": 449}
{"Episode reward": -67.10898272433467, "Episode length": 999, "Policy Loss": -0.005744107533246279, "Value Loss": 0.0016236891970038414, "_runtime": 15619.635649204254, "_timestamp": 1585612989.2685187, "_step": 450}
{"Episode reward": -66.02486198758578, "Episode length": 999, "Policy Loss": -0.0036361869424581528, "Value Loss": 0.0015581173356622458, "_runtime": 15621.221965789795, "_timestamp": 1585612990.8548353, "_step": 451}
{"Episode reward": -64.3393921684231, "Episode length": 999, "Policy Loss": -0.001600413117557764, "Value Loss": 0.0016420631436631083, "_runtime": 15622.805736780167, "_timestamp": 1585612992.4386063, "_step": 452}
{"Episode reward": -67.70940213521473, "Episode length": 999, "Policy Loss": -0.005162144545465708, "Value Loss": 0.0015795724466443062, "_runtime": 15624.39108657837, "_timestamp": 1585612994.023956, "_step": 453}
{"Episode reward": -67.43928937740797, "Episode length": 999, "Policy Loss": -0.005171321798115969, "Value Loss": 0.0015366867883130908, "_runtime": 15625.973977804184, "_timestamp": 1585612995.6068473, "_step": 454}
{"Episode reward": -68.6407990312508, "Episode length": 999, "Policy Loss": -0.006343879736959934, "Value Loss": 0.0015474014217033982, "_runtime": 15627.552497625351, "_timestamp": 1585612997.185367, "_step": 455}
{"Episode reward": -65.7928677639738, "Episode length": 999, "Policy Loss": -0.001433834433555603, "Value Loss": 0.0016076869796961546, "_runtime": 15629.13627243042, "_timestamp": 1585612998.769142, "_step": 456}
{"Episode reward": -67.28504937512203, "Episode length": 999, "Policy Loss": -0.0028154351748526096, "Value Loss": 0.0015886238543316722, "_runtime": 15630.758764266968, "_timestamp": 1585613000.3916337, "_step": 457}
{"Episode reward": -67.59070429076546, "Episode length": 999, "Policy Loss": -0.0040125115774571896, "Value Loss": 0.0015929423971101642, "_runtime": 15632.346650600433, "_timestamp": 1585613001.97952, "_step": 458}
{"Episode reward": -71.19531541687749, "Episode length": 999, "Policy Loss": -0.010647529736161232, "Value Loss": 0.001502311322838068, "_runtime": 15633.931134462357, "_timestamp": 1585613003.564004, "_step": 459}
{"Episode reward": -68.40303711536546, "Episode length": 999, "Policy Loss": -0.006889041047543287, "Value Loss": 0.001548080355860293, "_runtime": 15635.519463777542, "_timestamp": 1585613005.1523333, "_step": 460}
{"Episode reward": -68.49079201222379, "Episode length": 999, "Policy Loss": -0.004980199038982391, "Value Loss": 0.0015709263971075416, "_runtime": 15637.099427223206, "_timestamp": 1585613006.7322967, "_step": 461}
{"Episode reward": -69.01648393488541, "Episode length": 999, "Policy Loss": -0.0072205462493002415, "Value Loss": 0.0015520780580118299, "_runtime": 15638.663975000381, "_timestamp": 1585613008.2968445, "_step": 462}
{"Episode reward": -68.46191717719319, "Episode length": 999, "Policy Loss": -0.0034189545549452305, "Value Loss": 0.0015360063407570124, "_runtime": 15640.24032831192, "_timestamp": 1585613009.8731978, "_step": 463}
{"Episode reward": -69.52927581091782, "Episode length": 999, "Policy Loss": -0.006761093158274889, "Value Loss": 0.0015476621920242906, "_runtime": 15641.815996408463, "_timestamp": 1585613011.448866, "_step": 464}
{"Episode reward": -68.67285933104628, "Episode length": 999, "Policy Loss": -0.004399959463626146, "Value Loss": 0.0015759272500872612, "_runtime": 15643.404703617096, "_timestamp": 1585613013.037573, "_step": 465}
{"Episode reward": -69.85695374896754, "Episode length": 999, "Policy Loss": -0.0070434389635920525, "Value Loss": 0.0015245877439156175, "_runtime": 15644.990274906158, "_timestamp": 1585613014.6231444, "_step": 466}
{"Episode reward": -69.66376483107845, "Episode length": 999, "Policy Loss": -0.007740456145256758, "Value Loss": 0.0015243599191308022, "_runtime": 15646.566293478012, "_timestamp": 1585613016.199163, "_step": 467}
{"Episode reward": -68.19255434541427, "Episode length": 999, "Policy Loss": -0.004638427868485451, "Value Loss": 0.0015866769244894385, "_runtime": 15648.142633199692, "_timestamp": 1585613017.7755027, "_step": 468}
{"Episode reward": -71.02613070418835, "Episode length": 999, "Policy Loss": -0.007700358051806688, "Value Loss": 0.0014726066729053855, "_runtime": 15649.726547956467, "_timestamp": 1585613019.3594174, "_step": 469}
{"Episode reward": -70.07286264554834, "Episode length": 999, "Policy Loss": -0.005701031070202589, "Value Loss": 0.0015511602396145463, "_runtime": 15651.313606739044, "_timestamp": 1585613020.9464762, "_step": 470}
{"Episode reward": -66.35659488176162, "Episode length": 999, "Policy Loss": 0.0009132195846177638, "Value Loss": 0.0015887267654761672, "_runtime": 15652.889931678772, "_timestamp": 1585613022.5228012, "_step": 471}
{"Episode reward": -70.00645525350559, "Episode length": 999, "Policy Loss": -0.004323775880038738, "Value Loss": 0.0015259330393746495, "_runtime": 15654.513490438461, "_timestamp": 1585613024.14636, "_step": 472}
{"Episode reward": -70.38294368276651, "Episode length": 999, "Policy Loss": -0.0070138913579285145, "Value Loss": 0.0014810217544436455, "_runtime": 15656.102150440216, "_timestamp": 1585613025.73502, "_step": 473}
{"Episode reward": -71.98608470003782, "Episode length": 999, "Policy Loss": -0.006866408046334982, "Value Loss": 0.0015022037550807, "_runtime": 15657.699758291245, "_timestamp": 1585613027.3326278, "_step": 474}
{"Episode reward": -70.8511060700615, "Episode length": 999, "Policy Loss": -0.00724282069131732, "Value Loss": 0.0014970669290050864, "_runtime": 15659.293765068054, "_timestamp": 1585613028.9266346, "_step": 475}
{"Episode reward": -70.96905417952071, "Episode length": 999, "Policy Loss": -0.0043593961745500565, "Value Loss": 0.0015389438485726714, "_runtime": 15660.878402709961, "_timestamp": 1585613030.5112722, "_step": 476}
{"Episode reward": -71.75049504373314, "Episode length": 999, "Policy Loss": -0.008342545479536057, "Value Loss": 0.0014884785050526261, "_runtime": 15662.462821006775, "_timestamp": 1585613032.0956905, "_step": 477}
{"Episode reward": -69.75417072854941, "Episode length": 999, "Policy Loss": -0.0031400020234286785, "Value Loss": 0.0015381636330857873, "_runtime": 15664.045239925385, "_timestamp": 1585613033.6781094, "_step": 478}
{"Episode reward": -71.14536483704597, "Episode length": 999, "Policy Loss": -0.00799055676907301, "Value Loss": 0.0015338798984885216, "_runtime": 15665.62943649292, "_timestamp": 1585613035.262306, "_step": 479}
{"Episode reward": -69.6300262981887, "Episode length": 999, "Policy Loss": -0.0009034297545440495, "Value Loss": 0.0015127835795283318, "_runtime": 15667.226301193237, "_timestamp": 1585613036.8591707, "_step": 480}
{"Episode reward": -71.49295294190883, "Episode length": 999, "Policy Loss": -0.005203180015087128, "Value Loss": 0.0015016775578260422, "_runtime": 15668.805158138275, "_timestamp": 1585613038.4380276, "_step": 481}
{"Episode reward": -70.21757569105851, "Episode length": 999, "Policy Loss": -0.004024891648441553, "Value Loss": 0.001540981698781252, "_runtime": 15670.385045289993, "_timestamp": 1585613040.0179148, "_step": 482}
{"Episode reward": -73.45864777606768, "Episode length": 999, "Policy Loss": -0.008412315510213375, "Value Loss": 0.0014608936617150903, "_runtime": 15671.96874833107, "_timestamp": 1585613041.6016178, "_step": 483}
{"Episode reward": -71.59346285159475, "Episode length": 999, "Policy Loss": -0.0064996653236448765, "Value Loss": 0.0014904552372172475, "_runtime": 15673.553851366043, "_timestamp": 1585613043.1867208, "_step": 484}
{"Episode reward": -73.5061923872675, "Episode length": 999, "Policy Loss": -0.007719672750681639, "Value Loss": 0.001440501189790666, "_runtime": 15675.139151573181, "_timestamp": 1585613044.772021, "_step": 485}
{"Episode reward": -68.79248571790046, "Episode length": 999, "Policy Loss": -8.926049486035481e-05, "Value Loss": 0.0015408714534714818, "_runtime": 15676.764320611954, "_timestamp": 1585613046.39719, "_step": 486}
{"Episode reward": -70.00275274385105, "Episode length": 999, "Policy Loss": -0.0006821185234002769, "Value Loss": 0.0015290399314835668, "_runtime": 15678.348158121109, "_timestamp": 1585613047.9810276, "_step": 487}
{"Episode reward": -72.70530744453629, "Episode length": 999, "Policy Loss": -0.00723815243691206, "Value Loss": 0.00141557352617383, "_runtime": 15679.934519290924, "_timestamp": 1585613049.5673888, "_step": 488}
{"Episode reward": -71.13965620269994, "Episode length": 999, "Policy Loss": -0.0015230209100991488, "Value Loss": 0.001488099922426045, "_runtime": 15681.519150018692, "_timestamp": 1585613051.1520195, "_step": 489}
{"Episode reward": -74.15214448321578, "Episode length": 999, "Policy Loss": -0.008342904970049858, "Value Loss": 0.0014050842728465796, "_runtime": 15683.101114749908, "_timestamp": 1585613052.7339842, "_step": 490}
{"Episode reward": -72.57789961134691, "Episode length": 999, "Policy Loss": -0.007627086713910103, "Value Loss": 0.0014815950999036431, "_runtime": 15684.68609213829, "_timestamp": 1585613054.3189616, "_step": 491}
{"Episode reward": -74.25420432741089, "Episode length": 999, "Policy Loss": -0.00812084786593914, "Value Loss": 0.0014162174193188548, "_runtime": 15686.270641803741, "_timestamp": 1585613055.9035113, "_step": 492}
{"Episode reward": -71.23268469256578, "Episode length": 999, "Policy Loss": -0.0009998214663937688, "Value Loss": 0.0015018865233287215, "_runtime": 15687.853603363037, "_timestamp": 1585613057.4864728, "_step": 493}
{"Episode reward": -74.03923174242921, "Episode length": 999, "Policy Loss": -0.006536815315485001, "Value Loss": 0.0014168083434924483, "_runtime": 15689.43891453743, "_timestamp": 1585613059.071784, "_step": 494}
{"Episode reward": -73.81837230651426, "Episode length": 999, "Policy Loss": -0.007018886506557465, "Value Loss": 0.001389852142892778, "_runtime": 15691.024050474167, "_timestamp": 1585613060.65692, "_step": 495}
{"Episode reward": -70.95520592472172, "Episode length": 999, "Policy Loss": -0.0002982955484185368, "Value Loss": 0.0014936430379748344, "_runtime": 15692.607894897461, "_timestamp": 1585613062.2407644, "_step": 496}
{"Episode reward": -73.27232998427381, "Episode length": 999, "Policy Loss": -0.004851195029914379, "Value Loss": 0.0014358819462358952, "_runtime": 15694.195362091064, "_timestamp": 1585613063.8282316, "_step": 497}
{"Episode reward": -71.93823802936697, "Episode length": 999, "Policy Loss": -0.0027449019253253937, "Value Loss": 0.0014723904896527529, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487, -1.3445252180099487]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-2.0240135192871094, -1.9758132696151733, -1.9276130199432373, -1.8794127702713013, -1.8312125205993652, -1.7830122709274292, -1.7348120212554932, -1.6866118907928467, -1.638411521911621, -1.5902113914489746, -1.542011022567749, -1.4938108921051025, -1.4456106424331665, -1.3974103927612305, -1.3492101430892944, -1.3010098934173584, -1.2528096437454224, -1.2046093940734863, -1.1564091444015503, -1.1082088947296143, -1.0600086450576782, -1.0118083953857422, -0.9636081457138062, -0.9154078960418701, -0.8672077655792236, -0.8190075159072876, -0.7708072662353516, -0.7226070165634155, -0.6744067668914795, -0.6262065172195435, -0.5780062675476074, -0.5298060178756714, -0.48160576820373535, -0.4334055185317993, -0.3852052688598633, -0.33700501918792725, -0.2888047695159912, -0.24060451984405518, -0.19240427017211914, -0.1442040205001831, -0.09600377082824707, -0.047803640365600586, 0.000396728515625, 0.048596858978271484, 0.09679722785949707, 0.14499735832214355, 0.19319772720336914, 0.24139785766601562, 0.2895979881286621, 0.3377983570098877, 0.3859984874725342, 0.43419885635375977, 0.48239898681640625, 0.5305993556976318, 0.5787994861602783, 0.6269998550415039, 0.6751999855041504, 0.723400354385376, 0.7716004848480225, 0.819800853729248, 0.8680009841918945, 0.9162013530731201, 0.9644014835357666, 1.0126018524169922, 1.0608019828796387]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.41436564922332764, -0.40379005670547485, -0.39321449398994446, -0.38263893127441406, -0.3720633387565613, -0.3614877462387085, -0.3509121835231781, -0.3403366208076477, -0.3297610282897949, -0.31918543577194214, -0.30860987305641174, -0.29803431034088135, -0.28745871782302856, -0.2768831253051758, -0.2663075625896454, -0.255731999874115, -0.2451564073562622, -0.23458082973957062, -0.22400525212287903, -0.21342967450618744, -0.20285409688949585, -0.19227851927280426, -0.18170294165611267, -0.17112736403942108, -0.1605517864227295, -0.1499761939048767, -0.1394006311893463, -0.12882506847381592, -0.11824947595596313, -0.10767388343811035, -0.09709832072257996, -0.08652275800704956, -0.07594716548919678, -0.065371572971344, -0.0547960102558136, -0.0442204475402832, -0.03364485502243042, -0.023069262504577637, -0.012493699789047241, -0.0019181370735168457, 0.008657455444335938, 0.01923304796218872, 0.029808610677719116, 0.04038417339324951, 0.050959765911102295, 0.06153535842895508, 0.07211092114448547, 0.08268648386001587, 0.09326207637786865, 0.10383766889572144, 0.11441326141357422, 0.12498879432678223, 0.135564386844635, 0.1461399793624878, 0.1567155122756958, 0.16729110479354858, 0.17786669731140137, 0.18844228982925415, 0.19901788234710693, 0.20959341526031494, 0.22016900777816772, 0.2307446002960205, 0.24132013320922852, 0.2518957257270813, 0.2624713182449341]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 6.0, 5.0, 6.0, 6.0, 14.0, 14.0, 10.0, 20.0, 17.0, 17.0, 26.0, 32.0, 47.0, 52.0, 57.0, 34.0, 23.0, 24.0, 13.0, 15.0, 10.0, 6.0, 10.0, 4.0, 5.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.21323011815547943, -0.20706607401371002, -0.2009020447731018, -0.1947380006313324, -0.18857397139072418, -0.18240992724895477, -0.17624589800834656, -0.17008185386657715, -0.16391780972480774, -0.15775378048419952, -0.1515897512435913, -0.1454257071018219, -0.1392616629600525, -0.13309761881828308, -0.12693358957767487, -0.12076955288648605, -0.11460551619529724, -0.10844147950410843, -0.10227744281291962, -0.0961134061217308, -0.08994936943054199, -0.08378532528877258, -0.07762129604816437, -0.07145725190639496, -0.06529320776462555, -0.059129178524017334, -0.052965134382247925, -0.04680110514163971, -0.0406370609998703, -0.034473031759262085, -0.028308987617492676, -0.02214495837688446, -0.01598091423511505, -0.009816870093345642, -0.0036528408527374268, 0.0025112032890319824, 0.008675232529640198, 0.014839276671409607, 0.021003305912017822, 0.02716735005378723, 0.03333137929439545, 0.039495423436164856, 0.045659467577934265, 0.051823511719703674, 0.057987526059150696, 0.0641515702009201, 0.07031561434268951, 0.07647965848445892, 0.08264370262622833, 0.08880771696567535, 0.09497176110744476, 0.10113580524921417, 0.10729984939098358, 0.1134638637304306, 0.11962790787220001, 0.12579195201396942, 0.13195599615573883, 0.13812004029750824, 0.14428405463695526, 0.15044809877872467, 0.15661214292049408, 0.1627761870622635, 0.1689402014017105, 0.17510424554347992, 0.18126828968524933]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.49425408244132996, -0.4779037833213806, -0.4615534842014313, -0.44520318508148193, -0.428852915763855, -0.41250258684158325, -0.3961523175239563, -0.37980201840400696, -0.3634517192840576, -0.3471014201641083, -0.33075112104415894, -0.314400851726532, -0.29805052280426025, -0.2817002534866333, -0.26534995436668396, -0.24899965524673462, -0.23264935612678528, -0.21629905700683594, -0.1999487578868866, -0.18359845876693726, -0.16724815964698792, -0.15089789032936096, -0.13454759120941162, -0.11819729208946228, -0.10184699296951294, -0.0854966938495636, -0.06914639472961426, -0.05279609560966492, -0.036445826292037964, -0.020095527172088623, -0.0037452280521392822, 0.012605100870132446, 0.0289553701877594, 0.04530563950538635, 0.06165596842765808, 0.07800623774528503, 0.09435656666755676, 0.11070683598518372, 0.12705716490745544, 0.1434074342250824, 0.15975776314735413, 0.17610803246498108, 0.19245830178260803, 0.20880863070487976, 0.2251589000225067, 0.24150922894477844, 0.2578594982624054, 0.2742098271846771, 0.2905600965023041, 0.30691036581993103, 0.32326069474220276, 0.3396109640598297, 0.35596129298210144, 0.3723115622997284, 0.3886618912220001, 0.4050121605396271, 0.42136242985725403, 0.43771275877952576, 0.4540630280971527, 0.47041335701942444, 0.4867636263370514, 0.5031139850616455, 0.5194642543792725, 0.5358145236968994, 0.5521647930145264]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 6.0, 6.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2457849383354187, -0.23883560299873352, -0.23188628256320953, -0.22493694722652435, -0.21798762679100037, -0.21103829145431519, -0.20408895611763, -0.19713963568210602, -0.19019031524658203, -0.18324097990989685, -0.17629164457321167, -0.16934232413768768, -0.1623929888010025, -0.15544366836547852, -0.14849433302879333, -0.14154499769210815, -0.13459567725658417, -0.12764635682106018, -0.120697021484375, -0.11374768614768982, -0.10679836571216583, -0.09984903037548065, -0.09289970993995667, -0.08595037460327148, -0.0790010392665863, -0.07205171883106232, -0.06510238349437714, -0.05815306305885315, -0.05120372772216797, -0.04425440728664398, -0.0373050719499588, -0.030355751514434814, -0.023406416177749634, -0.016457080841064453, -0.009507760405540466, -0.0025584250688552856, 0.004390895366668701, 0.011340230703353882, 0.018289566040039062, 0.025238871574401855, 0.032188206911087036, 0.03913754224777222, 0.0460868775844574, 0.05303621292114258, 0.05998551845550537, 0.06693485379219055, 0.07388418912887573, 0.08083352446556091, 0.0877828598022461, 0.09473216533660889, 0.10168150067329407, 0.10863083600997925, 0.11558017134666443, 0.12252947688102722, 0.1294788122177124, 0.13642814755439758, 0.14337748289108276, 0.15032681822776794, 0.15727612376213074, 0.16422545909881592, 0.1711747944355011, 0.17812412977218628, 0.18507343530654907, 0.19202277064323425, 0.19897210597991943]}, "_runtime": 15695.782447576523, "_timestamp": 1585613065.415317, "_step": 498}
{"Episode reward": -74.36500529207814, "Episode length": 999, "Policy Loss": -0.00678055826574564, "Value Loss": 0.0013995831832289696, "_runtime": 15695.782447576523, "_timestamp": 1585613065.415317, "_step": 499}
