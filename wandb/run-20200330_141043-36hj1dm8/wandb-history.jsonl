{"Episode reward": -94.80989180898202, "Episode length": 999, "Policy Loss": -0.005714048631489277, "Value Loss": 0.01170508936047554, "_runtime": 7546.813711881638, "_timestamp": 1585577462.6583452, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043599531054496765, "Value Loss": 4.214614391326904, "_runtime": 7548.3123433589935, "_timestamp": 1585577464.1569767, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16444432735443115, "Value Loss": 62.16706466674805, "_runtime": 7549.883908748627, "_timestamp": 1585577465.728542, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4866178035736084, "Value Loss": 23.289819717407227, "_runtime": 7551.417830944061, "_timestamp": 1585577467.2624643, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.946657657623291, "Value Loss": 2970.507568359375, "_runtime": 7551.652290344238, "_timestamp": 1585577467.4969237, "_step": 4}
{"Episode reward": 89.05324025970597, "Episode length": 112, "Policy Loss": 23.111148834228516, "Value Loss": 1124.054443359375, "_runtime": 7553.223500490189, "_timestamp": 1585577469.0681338, "_step": 5}
{"Episode reward": -96.94154217592026, "Episode length": 999, "Policy Loss": -1.1798138618469238, "Value Loss": 6.103623867034912, "_runtime": 7554.795295476913, "_timestamp": 1585577470.6399288, "_step": 6}
{"Episode reward": -97.40959160260614, "Episode length": 999, "Policy Loss": -1.208085060119629, "Value Loss": 2.6368865966796875, "_runtime": 7556.2882487773895, "_timestamp": 1585577472.132882, "_step": 7}
{"Episode reward": -94.03699074186284, "Episode length": 999, "Policy Loss": -0.6536033749580383, "Value Loss": 0.1364467591047287, "_runtime": 7557.881928682327, "_timestamp": 1585577473.726562, "_step": 8}
{"Episode reward": -91.6965334998908, "Episode length": 999, "Policy Loss": 0.06121419742703438, "Value Loss": 0.3082413375377655, "_runtime": 7559.457011938095, "_timestamp": 1585577475.3016453, "_step": 9}
{"Episode reward": -92.50831883087292, "Episode length": 999, "Policy Loss": 0.25748077034950256, "Value Loss": 0.5251611471176147, "_runtime": 7560.981140375137, "_timestamp": 1585577476.8257737, "_step": 10}
{"Episode reward": -93.66167054560358, "Episode length": 999, "Policy Loss": -1.3939348459243774, "Value Loss": 1.3922879695892334, "_runtime": 7562.567029714584, "_timestamp": 1585577478.411663, "_step": 11}
{"Episode reward": -94.41376907770163, "Episode length": 999, "Policy Loss": -3.920654535293579, "Value Loss": 7.754765510559082, "_runtime": 7564.1481721401215, "_timestamp": 1585577479.9928055, "_step": 12}
{"Episode reward": -96.13963545114147, "Episode length": 999, "Policy Loss": -6.692458152770996, "Value Loss": 55.55642318725586, "_runtime": 7565.734716892242, "_timestamp": 1585577481.5793502, "_step": 13}
{"Episode reward": -97.61533053904971, "Episode length": 999, "Policy Loss": -2.2164359092712402, "Value Loss": 79.69320678710938, "_runtime": 7567.324463367462, "_timestamp": 1585577483.1690967, "_step": 14}
{"Episode reward": -98.61701355190449, "Episode length": 999, "Policy Loss": -5.565840721130371, "Value Loss": 202.30728149414062, "_runtime": 7568.647616147995, "_timestamp": 1585577484.4922495, "_step": 15}
{"Episode reward": 16.812517590307195, "Episode length": 835, "Policy Loss": -6.939218997955322, "Value Loss": 27.174306869506836, "_runtime": 7570.2062520980835, "_timestamp": 1585577486.0508854, "_step": 16}
{"Episode reward": -99.32302197184663, "Episode length": 999, "Policy Loss": -8.95290756225586, "Value Loss": 397.99725341796875, "_runtime": 7571.128457546234, "_timestamp": 1585577486.973091, "_step": 17}
{"Episode reward": 43.28374812528438, "Episode length": 568, "Policy Loss": -7.712454795837402, "Value Loss": 50.57236862182617, "_runtime": 7572.712379932404, "_timestamp": 1585577488.5570133, "_step": 18}
{"Episode reward": -99.60787909406214, "Episode length": 999, "Policy Loss": -11.556206703186035, "Value Loss": 153.01881408691406, "_runtime": 7574.279356002808, "_timestamp": 1585577490.1239893, "_step": 19}
{"Episode reward": -99.41983038108602, "Episode length": 999, "Policy Loss": -12.84472370147705, "Value Loss": 197.1407928466797, "_runtime": 7574.789952039719, "_timestamp": 1585577490.6345854, "_step": 20}
{"Episode reward": 68.98639251394181, "Episode length": 312, "Policy Loss": -5.733505725860596, "Value Loss": 75.66596221923828, "_runtime": 7575.288275241852, "_timestamp": 1585577491.1329086, "_step": 21}
{"Episode reward": 70.89862133932752, "Episode length": 292, "Policy Loss": -7.854504585266113, "Value Loss": 1773.2156982421875, "_runtime": 7576.855135440826, "_timestamp": 1585577492.6997688, "_step": 22}
{"Episode reward": -99.82323372092802, "Episode length": 999, "Policy Loss": -6.842074394226074, "Value Loss": 4.215861797332764, "_runtime": 7578.373500347137, "_timestamp": 1585577494.2181337, "_step": 23}
{"Episode reward": -99.77764956068573, "Episode length": 999, "Policy Loss": -18.40789031982422, "Value Loss": 586.5902709960938, "_runtime": 7579.283506155014, "_timestamp": 1585577495.1281395, "_step": 24}
{"Episode reward": 40.03103622049036, "Episode length": 600, "Policy Loss": -12.801887512207031, "Value Loss": 576.4705200195312, "_runtime": 7580.854533433914, "_timestamp": 1585577496.6991668, "_step": 25}
{"Episode reward": -99.75658926982439, "Episode length": 999, "Policy Loss": -15.68737506866455, "Value Loss": 96.62928771972656, "_runtime": 7582.424896001816, "_timestamp": 1585577498.2695293, "_step": 26}
{"Episode reward": -99.82723121086461, "Episode length": 999, "Policy Loss": -12.550002098083496, "Value Loss": 26.61137580871582, "_runtime": 7583.5757484436035, "_timestamp": 1585577499.4203818, "_step": 27}
{"Episode reward": 24.353543431328973, "Episode length": 758, "Policy Loss": -8.087347984313965, "Value Loss": 33.52898025512695, "_runtime": 7585.1625020504, "_timestamp": 1585577501.0071354, "_step": 28}
{"Episode reward": -99.71842479424676, "Episode length": 999, "Policy Loss": -9.803108215332031, "Value Loss": 60.46287155151367, "_runtime": 7586.741062879562, "_timestamp": 1585577502.5856962, "_step": 29}
{"Episode reward": -99.85093449689309, "Episode length": 999, "Policy Loss": -6.048830032348633, "Value Loss": 135.3095703125, "_runtime": 7588.276465654373, "_timestamp": 1585577504.121099, "_step": 30}
{"Episode reward": -99.78577080489927, "Episode length": 999, "Policy Loss": -3.746659994125366, "Value Loss": 90.66213989257812, "_runtime": 7589.897456407547, "_timestamp": 1585577505.7420897, "_step": 31}
{"Episode reward": -99.86988935507694, "Episode length": 999, "Policy Loss": 1.228079080581665, "Value Loss": 119.10833740234375, "_runtime": 7591.480891942978, "_timestamp": 1585577507.3255253, "_step": 32}
{"Episode reward": -99.63257612952592, "Episode length": 999, "Policy Loss": 1.8977513313293457, "Value Loss": 18.181209564208984, "_runtime": 7593.047149419785, "_timestamp": 1585577508.8917828, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.672302722930908, "Value Loss": 58.60239028930664, "_runtime": 7594.356300354004, "_timestamp": 1585577510.2009337, "_step": 34}
{"Episode reward": 17.96774877598547, "Episode length": 821, "Policy Loss": 5.190147876739502, "Value Loss": 192.60888671875, "_runtime": 7595.941817045212, "_timestamp": 1585577511.7864504, "_step": 35}
{"Episode reward": -99.63738462755435, "Episode length": 999, "Policy Loss": 5.025150775909424, "Value Loss": 29.917871475219727, "_runtime": 7597.5248374938965, "_timestamp": 1585577513.3694708, "_step": 36}
{"Episode reward": -99.78463545190031, "Episode length": 999, "Policy Loss": 3.4876768589019775, "Value Loss": 1.4693007469177246, "_runtime": 7599.107026576996, "_timestamp": 1585577514.95166, "_step": 37}
{"Episode reward": -99.59157941004821, "Episode length": 999, "Policy Loss": 2.440126895904541, "Value Loss": 0.740217387676239, "_runtime": 7600.683100700378, "_timestamp": 1585577516.527734, "_step": 38}
{"Episode reward": -99.75336849641032, "Episode length": 999, "Policy Loss": 1.0184919834136963, "Value Loss": 1.7930541038513184, "_runtime": 7602.266477823257, "_timestamp": 1585577518.1111112, "_step": 39}
{"Episode reward": -99.3753929759784, "Episode length": 999, "Policy Loss": 0.34970623254776, "Value Loss": 13.50504207611084, "_runtime": 7603.8560473918915, "_timestamp": 1585577519.7006807, "_step": 40}
{"Episode reward": -99.80004612505878, "Episode length": 999, "Policy Loss": 0.1067054495215416, "Value Loss": 12.677330017089844, "_runtime": 7605.43764257431, "_timestamp": 1585577521.282276, "_step": 41}
{"Episode reward": -99.82087241692794, "Episode length": 999, "Policy Loss": -0.2862248420715332, "Value Loss": 4.911883354187012, "_runtime": 7606.521966934204, "_timestamp": 1585577522.3666003, "_step": 42}
{"Episode reward": 31.60246146782262, "Episode length": 684, "Policy Loss": 1.5537015199661255, "Value Loss": 23.367780685424805, "_runtime": 7608.102186203003, "_timestamp": 1585577523.9468195, "_step": 43}
{"Episode reward": -99.62272337200126, "Episode length": 999, "Policy Loss": 0.9976762533187866, "Value Loss": 1.6474969387054443, "_runtime": 7609.6923151016235, "_timestamp": 1585577525.5369484, "_step": 44}
{"Episode reward": -99.79798397743586, "Episode length": 999, "Policy Loss": 1.3953142166137695, "Value Loss": 11.523024559020996, "_runtime": 7611.241701364517, "_timestamp": 1585577527.0863347, "_step": 45}
{"Episode reward": -99.8005850489834, "Episode length": 999, "Policy Loss": 1.7517861127853394, "Value Loss": 19.705568313598633, "_runtime": 7612.852933168411, "_timestamp": 1585577528.6975665, "_step": 46}
{"Episode reward": 0.8580654410542508, "Episode length": 994, "Policy Loss": 2.9316725730895996, "Value Loss": 21.94356346130371, "_runtime": 7614.445332288742, "_timestamp": 1585577530.2899656, "_step": 47}
{"Episode reward": -99.8015762630836, "Episode length": 999, "Policy Loss": 1.004563570022583, "Value Loss": 27.427635192871094, "_runtime": 7614.956015110016, "_timestamp": 1585577530.8006485, "_step": 48}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 4.322288990020752, "Value Loss": 41.378299713134766, "_runtime": 7616.539764881134, "_timestamp": 1585577532.3843982, "_step": 49}
{"Episode reward": -99.70573946349182, "Episode length": 999, "Policy Loss": -0.43439579010009766, "Value Loss": 7.193385601043701, "_runtime": 7618.117691755295, "_timestamp": 1585577533.962325, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06240672990679741, "Value Loss": 11.745832443237305, "_runtime": 7619.633922815323, "_timestamp": 1585577535.4785562, "_step": 51}
{"Episode reward": -99.80006095329159, "Episode length": 999, "Policy Loss": -1.379457712173462, "Value Loss": 25.311222076416016, "_runtime": 7621.22323012352, "_timestamp": 1585577537.0678635, "_step": 52}
{"Episode reward": -99.55920576572396, "Episode length": 999, "Policy Loss": -0.34481266140937805, "Value Loss": 5.20745849609375, "_runtime": 7622.803977012634, "_timestamp": 1585577538.6486104, "_step": 53}
{"Episode reward": -99.62712306904002, "Episode length": 999, "Policy Loss": 0.2461511194705963, "Value Loss": 2.7837095260620117, "_runtime": 7624.054558753967, "_timestamp": 1585577539.899192, "_step": 54}
{"Episode reward": 20.655876675900316, "Episode length": 795, "Policy Loss": 2.1680142879486084, "Value Loss": 13.652159690856934, "_runtime": 7624.8232498168945, "_timestamp": 1585577540.6678832, "_step": 55}
{"Episode reward": 53.77015615915842, "Episode length": 463, "Policy Loss": 4.025363445281982, "Value Loss": 38.896854400634766, "_runtime": 7625.783442258835, "_timestamp": 1585577541.6280756, "_step": 56}
{"Episode reward": 40.7989461828425, "Episode length": 593, "Policy Loss": 2.678917407989502, "Value Loss": 19.64664649963379, "_runtime": 7627.345506191254, "_timestamp": 1585577543.1901395, "_step": 57}
{"Episode reward": -99.82120176537288, "Episode length": 999, "Policy Loss": 0.9411563277244568, "Value Loss": 0.4467984139919281, "_runtime": 7628.215944290161, "_timestamp": 1585577544.0605776, "_step": 58}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": 1.4542723894119263, "Value Loss": 24.909671783447266, "_runtime": 7628.849515676498, "_timestamp": 1585577544.694149, "_step": 59}
{"Episode reward": 59.96331118941278, "Episode length": 401, "Policy Loss": 2.683183431625366, "Value Loss": 30.620779037475586, "_runtime": 7630.411728858948, "_timestamp": 1585577546.2563622, "_step": 60}
{"Episode reward": -99.7780774292522, "Episode length": 999, "Policy Loss": 1.1106104850769043, "Value Loss": 0.030241793021559715, "_runtime": 7631.411869049072, "_timestamp": 1585577547.2565024, "_step": 61}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 3.0625340938568115, "Value Loss": 18.145418167114258, "_runtime": 7632.75678396225, "_timestamp": 1585577548.6014173, "_step": 62}
{"Episode reward": 10.170664130152105, "Episode length": 899, "Policy Loss": 3.1607143878936768, "Value Loss": 23.455364227294922, "_runtime": 7634.302733421326, "_timestamp": 1585577550.1473668, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9271482229232788, "Value Loss": 0.9651331305503845, "_runtime": 7635.832495927811, "_timestamp": 1585577551.6771293, "_step": 64}
{"Episode reward": -99.70151218939434, "Episode length": 999, "Policy Loss": 1.1481581926345825, "Value Loss": 0.2897636890411377, "_runtime": 7637.411489248276, "_timestamp": 1585577553.2561226, "_step": 65}
{"Episode reward": -99.8001104474985, "Episode length": 999, "Policy Loss": 0.8760822415351868, "Value Loss": 0.9779839515686035, "_runtime": 7638.740808725357, "_timestamp": 1585577554.585442, "_step": 66}
{"Episode reward": 15.85519069823836, "Episode length": 843, "Policy Loss": 0.8192117214202881, "Value Loss": 17.59117317199707, "_runtime": 7640.308668613434, "_timestamp": 1585577556.153302, "_step": 67}
{"Episode reward": -99.69319981075685, "Episode length": 999, "Policy Loss": 0.7922235131263733, "Value Loss": 0.41941720247268677, "_runtime": 7641.641275882721, "_timestamp": 1585577557.4859092, "_step": 68}
{"Episode reward": 14.630335248419428, "Episode length": 856, "Policy Loss": 1.7923568487167358, "Value Loss": 12.657160758972168, "_runtime": 7643.204085350037, "_timestamp": 1585577559.0487187, "_step": 69}
{"Episode reward": -99.75219506305154, "Episode length": 999, "Policy Loss": 1.1327604055404663, "Value Loss": 0.17475874722003937, "_runtime": 7644.775244951248, "_timestamp": 1585577560.6198783, "_step": 70}
{"Episode reward": -99.82617936171451, "Episode length": 999, "Policy Loss": 1.2588768005371094, "Value Loss": 0.14992894232273102, "_runtime": 7646.322762012482, "_timestamp": 1585577562.1673954, "_step": 71}
{"Episode reward": -99.82904238933557, "Episode length": 999, "Policy Loss": 1.6255314350128174, "Value Loss": 0.4075390696525574, "_runtime": 7647.898993968964, "_timestamp": 1585577563.7436273, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.559407353401184, "Value Loss": 3.403902769088745, "_runtime": 7649.473355054855, "_timestamp": 1585577565.3179884, "_step": 73}
{"Episode reward": -99.6604493980515, "Episode length": 999, "Policy Loss": 1.3605719804763794, "Value Loss": 1.658295750617981, "_runtime": 7651.062078475952, "_timestamp": 1585577566.9067118, "_step": 74}
{"Episode reward": -99.78788622286963, "Episode length": 999, "Policy Loss": 0.879589319229126, "Value Loss": 0.16501261293888092, "_runtime": 7652.6512150764465, "_timestamp": 1585577568.4958484, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6616759300231934, "Value Loss": 0.1414080262184143, "_runtime": 7653.256477355957, "_timestamp": 1585577569.1011107, "_step": 76}
{"Episode reward": 64.29999999999977, "Episode length": 357, "Policy Loss": 2.172564744949341, "Value Loss": 29.936309814453125, "_runtime": 7654.8361439704895, "_timestamp": 1585577570.6807773, "_step": 77}
{"Episode reward": -99.80033550001541, "Episode length": 999, "Policy Loss": 0.3031741976737976, "Value Loss": 0.5543172955513, "_runtime": 7656.417947053909, "_timestamp": 1585577572.2625804, "_step": 78}
{"Episode reward": -99.74571726091533, "Episode length": 999, "Policy Loss": 0.4278784394264221, "Value Loss": 0.20429010689258575, "_runtime": 7657.927952051163, "_timestamp": 1585577573.7725854, "_step": 79}
{"Episode reward": -99.7150695898789, "Episode length": 999, "Policy Loss": 0.38206949830055237, "Value Loss": 0.1049010306596756, "_runtime": 7658.742860078812, "_timestamp": 1585577574.5874934, "_step": 80}
{"Episode reward": 50.40639975931802, "Episode length": 497, "Policy Loss": 2.045720100402832, "Value Loss": 20.124984741210938, "_runtime": 7660.156574249268, "_timestamp": 1585577576.0012076, "_step": 81}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 1.4189128875732422, "Value Loss": 11.636813163757324, "_runtime": 7661.024717092514, "_timestamp": 1585577576.8693504, "_step": 82}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 1.8742318153381348, "Value Loss": 18.447168350219727, "_runtime": 7662.568085670471, "_timestamp": 1585577578.412719, "_step": 83}
{"Episode reward": -99.86441646374738, "Episode length": 999, "Policy Loss": 0.43487778306007385, "Value Loss": 0.042204808443784714, "_runtime": 7664.143568754196, "_timestamp": 1585577579.988202, "_step": 84}
{"Episode reward": -99.81137271060003, "Episode length": 999, "Policy Loss": 0.30578550696372986, "Value Loss": 0.026332803070545197, "_runtime": 7664.859308719635, "_timestamp": 1585577580.703942, "_step": 85}
{"Episode reward": 54.69999999999963, "Episode length": 453, "Policy Loss": 1.8411046266555786, "Value Loss": 21.593860626220703, "_runtime": 7665.778159618378, "_timestamp": 1585577581.622793, "_step": 86}
{"Episode reward": 42.795630639581404, "Episode length": 573, "Policy Loss": 1.632510781288147, "Value Loss": 17.06694984436035, "_runtime": 7666.633446931839, "_timestamp": 1585577582.4780803, "_step": 87}
{"Episode reward": 46.792884018805736, "Episode length": 533, "Policy Loss": 1.3882169723510742, "Value Loss": 18.331661224365234, "_runtime": 7668.175497531891, "_timestamp": 1585577584.0201309, "_step": 88}
{"Episode reward": -99.69060697527465, "Episode length": 999, "Policy Loss": -0.11977129429578781, "Value Loss": 0.10958188772201538, "_runtime": 7669.717201948166, "_timestamp": 1585577585.5618353, "_step": 89}
{"Episode reward": -99.81247842796007, "Episode length": 999, "Policy Loss": -0.2217024266719818, "Value Loss": 0.06132594868540764, "_runtime": 7671.254275798798, "_timestamp": 1585577587.0989091, "_step": 90}
{"Episode reward": -99.80099981690152, "Episode length": 999, "Policy Loss": -0.1834416389465332, "Value Loss": 0.04942300543189049, "_runtime": 7672.812175273895, "_timestamp": 1585577588.6568086, "_step": 91}
{"Episode reward": -99.80864016041166, "Episode length": 999, "Policy Loss": -0.18687711656093597, "Value Loss": 0.10826984792947769, "_runtime": 7673.963533639908, "_timestamp": 1585577589.808167, "_step": 92}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.9050366282463074, "Value Loss": 13.248514175415039, "_runtime": 7674.569176435471, "_timestamp": 1585577590.4138098, "_step": 93}
{"Episode reward": 63.69999999999976, "Episode length": 363, "Policy Loss": 2.0251989364624023, "Value Loss": 26.905397415161133, "_runtime": 7676.127782344818, "_timestamp": 1585577591.9724157, "_step": 94}
{"Episode reward": -99.64369743736322, "Episode length": 999, "Policy Loss": -0.2406644970178604, "Value Loss": 0.12612658739089966, "_runtime": 7677.696811676025, "_timestamp": 1585577593.541445, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2780512571334839, "Value Loss": 0.05461417883634567, "_runtime": 7678.414311885834, "_timestamp": 1585577594.2589452, "_step": 96}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 1.5331151485443115, "Value Loss": 21.0699520111084, "_runtime": 7679.985460519791, "_timestamp": 1585577595.8300939, "_step": 97}
{"Episode reward": -99.70121955120564, "Episode length": 999, "Policy Loss": -0.4124774932861328, "Value Loss": 0.04545355960726738, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642, -0.012416374869644642]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1948572397232056, -1.0829817056655884, -0.971106231212616, -0.8592307567596436, -0.7473552227020264, -0.6354796886444092, -0.5236042141914368, -0.41172873973846436, -0.29985320568084717, -0.18797767162322998, -0.07610213756561279, 0.035773277282714844, 0.14764881134033203, 0.2595243453979492, 0.37139976024627686, 0.48327529430389404, 0.5951508283615112, 0.7070263624191284, 0.8189018964767456, 0.9307774305343628, 1.04265296459198, 1.154528260231018, 1.2664037942886353, 1.3782793283462524, 1.4901548624038696, 1.6020303964614868, 1.713905930519104, 1.8257814645767212, 1.9376567602157593, 2.049532413482666, 2.161407947540283, 2.2732834815979004, 2.3851590156555176, 2.4970345497131348, 2.608910083770752, 2.720785617828369, 2.8326611518859863, 2.9445366859436035, 3.0564122200012207, 3.168287754058838, 3.280163288116455, 3.392038345336914, 3.5039138793945312, 3.6157894134521484, 3.7276649475097656, 3.839540481567383, 3.951416015625, 4.063291549682617, 4.175167083740234, 4.287042617797852, 4.398918151855469, 4.510793685913086, 4.622669219970703, 4.73454475402832, 4.8464202880859375, 4.958295822143555, 5.070170879364014, 5.182046413421631, 5.293921947479248, 5.405797481536865, 5.517673015594482, 5.6295485496521, 5.741424083709717, 5.853299617767334, 5.965175151824951]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.27166417241096497, -0.2617343068122864, -0.2518044412136078, -0.2418745756149292, -0.2319447100162506, -0.22201484441757202, -0.21208496391773224, -0.20215509831905365, -0.19222523272037506, -0.18229536712169647, -0.17236550152301788, -0.1624356210231781, -0.1525057554244995, -0.14257588982582092, -0.13264602422714233, -0.12271615862846375, -0.11278629302978516, -0.10285642743110657, -0.09292656183242798, -0.08299669623374939, -0.0730668306350708, -0.06313695013523102, -0.05320708453655243, -0.04327721893787384, -0.03334735333919525, -0.023417487740516663, -0.01348760724067688, -0.003557741641998291, 0.006372123956680298, 0.016301989555358887, 0.026231855154037476, 0.036161720752716064, 0.04609158635139465, 0.05602145195007324, 0.06595131754875183, 0.07588118314743042, 0.08581104874610901, 0.0957409143447876, 0.10567077994346619, 0.11560064554214478, 0.12553051114082336, 0.13546040654182434, 0.14539027214050293, 0.15532013773918152, 0.1652500033378601, 0.1751798689365387, 0.18510973453521729, 0.19503960013389587, 0.20496946573257446, 0.21489933133125305, 0.22482919692993164, 0.23475906252861023, 0.2446889579296112, 0.2546187937259674, 0.2645486891269684, 0.2744785249233246, 0.28440842032432556, 0.29433825612068176, 0.30426815152168274, 0.31419798731803894, 0.3241278827190399, 0.3340577185153961, 0.3439876139163971, 0.3539174497127533, 0.3638473451137543]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 8.0, 6.0, 10.0, 14.0, 24.0, 21.0, 32.0, 18.0, 15.0, 8.0, 5.0, 4.0, 163.0, 11.0, 0.0, 4.0, 1.0, 7.0, 25.0, 48.0, 13.0, 28.0, 11.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.5816764831542969, -0.5573483109474182, -0.5330200791358948, -0.5086919069290161, -0.4843636751174927, -0.460035502910614, -0.43570730090141296, -0.4113790988922119, -0.38705089688301086, -0.3627226948738098, -0.33839449286460876, -0.3140662908554077, -0.28973811864852905, -0.265409916639328, -0.24108171463012695, -0.2167535126209259, -0.19242531061172485, -0.1680971086025238, -0.14376890659332275, -0.1194407045841217, -0.09511250257492065, -0.07078433036804199, -0.046456098556518555, -0.022127926349639893, 0.0022002458572387695, 0.026528477668762207, 0.05085664987564087, 0.0751848816871643, 0.09951305389404297, 0.1238412857055664, 0.14816945791244507, 0.1724976897239685, 0.19682586193084717, 0.22115403413772583, 0.24548226594924927, 0.26981043815612793, 0.29413866996765137, 0.31846684217453003, 0.34279507398605347, 0.36712324619293213, 0.39145147800445557, 0.41577965021133423, 0.4401078224182129, 0.46443605422973633, 0.48876428604125977, 0.5130923986434937, 0.5374206304550171, 0.5617488622665405, 0.5860769748687744, 0.6104052066802979, 0.6347334384918213, 0.6590616703033447, 0.6833897829055786, 0.707718014717102, 0.7320462465286255, 0.7563744783401489, 0.7807025909423828, 0.8050308227539062, 0.8293590545654297, 0.8536871671676636, 0.878015398979187, 0.9023436307907104, 0.9266718626022339, 0.9509999752044678, 0.9753282070159912]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0], "bins": [-6.383562088012695, -6.158818244934082, -5.934074878692627, -5.709331035614014, -5.4845871925354, -5.259843826293945, -5.035099983215332, -4.810356140136719, -4.5856122970581055, -4.36086893081665, -4.136125087738037, -3.911381483078003, -3.6866378784179688, -3.4618940353393555, -3.2371504306793213, -3.012406587600708, -2.787662982940674, -2.5629193782806396, -2.3381757736206055, -2.113431930541992, -1.888688087463379, -1.6639447212219238, -1.4392008781433105, -1.2144570350646973, -0.9897136688232422, -0.7649698257446289, -0.5402259826660156, -0.31548213958740234, -0.09073877334594727, 0.13400506973266602, 0.3587489128112793, 0.5834922790527344, 0.8082361221313477, 1.032979965209961, 1.257723331451416, 1.4824671745300293, 1.7072105407714844, 1.9319543838500977, 2.156698226928711, 2.381442070007324, 2.6061859130859375, 2.830929756164551, 3.0556726455688477, 3.280416488647461, 3.505160331726074, 3.7299041748046875, 3.954648017883301, 4.179391860961914, 4.404134750366211, 4.628878593444824, 4.8536224365234375, 5.078366279602051, 5.303110122680664, 5.527853965759277, 5.752597808837891, 5.9773406982421875, 6.202084541320801, 6.426828384399414, 6.651572227478027, 6.876316070556641, 7.101059913635254, 7.325802803039551, 7.550546646118164, 7.775290489196777, 8.00003433227539]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 5.0, 4.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], "bins": [-2.93672513961792, -2.8387882709503174, -2.740851402282715, -2.6429145336151123, -2.5449776649475098, -2.4470407962799072, -2.3491039276123047, -2.251167058944702, -2.1532301902770996, -2.055293321609497, -1.9573564529418945, -1.8594194650650024, -1.7614825963974, -1.6635457277297974, -1.5656088590621948, -1.4676719903945923, -1.3697351217269897, -1.2717982530593872, -1.1738613843917847, -1.0759245157241821, -0.9779876470565796, -0.8800506591796875, -0.782113790512085, -0.6841769218444824, -0.5862400531768799, -0.48830318450927734, -0.3903663158416748, -0.29242944717407227, -0.19449257850646973, -0.09655570983886719, 0.0013811588287353516, 0.09931802749633789, 0.19725489616394043, 0.29519176483154297, 0.3931286334991455, 0.49106550216674805, 0.5890023708343506, 0.6869392395019531, 0.7848761081695557, 0.8828129768371582, 0.9807498455047607, 1.0786867141723633, 1.176623821258545, 1.2745604515075684, 1.37249755859375, 1.4704341888427734, 1.568371295928955, 1.6663079261779785, 1.7642450332641602, 1.8621816635131836, 1.9601187705993652, 2.0580554008483887, 2.1559925079345703, 2.2539291381835938, 2.3518662452697754, 2.449802875518799, 2.5477399826049805, 2.645676612854004, 2.7436137199401855, 2.841550350189209, 2.9394874572753906, 3.037424087524414, 3.1353611946105957, 3.233297824859619, 3.331234931945801]}, "_runtime": 7681.570898532867, "_timestamp": 1585577597.4155319, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43662235140800476, "Value Loss": 0.2387991100549698, "_runtime": 7683.098183393478, "_timestamp": 1585577598.9428167, "_step": 99}
{"Episode reward": -99.61063117711318, "Episode length": 999, "Policy Loss": -0.469258576631546, "Value Loss": 0.12638232111930847, "_runtime": 7684.697894334793, "_timestamp": 1585577600.5425277, "_step": 100}
{"Episode reward": 1.0844230690460677, "Episode length": 990, "Policy Loss": 0.29850098490715027, "Value Loss": 9.913297653198242, "_runtime": 7686.283398628235, "_timestamp": 1585577602.128032, "_step": 101}
{"Episode reward": -99.80012770676846, "Episode length": 999, "Policy Loss": -0.3834412693977356, "Value Loss": 0.2756465673446655, "_runtime": 7687.84491443634, "_timestamp": 1585577603.6895478, "_step": 102}
{"Episode reward": -99.82773711569467, "Episode length": 999, "Policy Loss": -0.3753402829170227, "Value Loss": 0.06358716636896133, "_runtime": 7689.412395238876, "_timestamp": 1585577605.2570286, "_step": 103}
{"Episode reward": -99.86846352920408, "Episode length": 999, "Policy Loss": -0.4086971879005432, "Value Loss": 0.241536945104599, "_runtime": 7691.001604557037, "_timestamp": 1585577606.846238, "_step": 104}
{"Episode reward": -99.70116983228806, "Episode length": 999, "Policy Loss": -0.3231842815876007, "Value Loss": 0.011224279180169106, "_runtime": 7692.581753015518, "_timestamp": 1585577608.4263864, "_step": 105}
{"Episode reward": -99.89708876313968, "Episode length": 999, "Policy Loss": -0.2998262643814087, "Value Loss": 0.06479440629482269, "_runtime": 7693.719781160355, "_timestamp": 1585577609.5644145, "_step": 106}
{"Episode reward": 29.278562037343832, "Episode length": 709, "Policy Loss": 0.7760226726531982, "Value Loss": 13.626155853271484, "_runtime": 7694.238837480545, "_timestamp": 1585577610.0834708, "_step": 107}
{"Episode reward": 69.79999999999984, "Episode length": 302, "Policy Loss": 2.2296228408813477, "Value Loss": 32.192535400390625, "_runtime": 7695.809424161911, "_timestamp": 1585577611.6540575, "_step": 108}
{"Episode reward": -99.59440953680175, "Episode length": 999, "Policy Loss": -0.2954045534133911, "Value Loss": 0.05890855938196182, "_runtime": 7696.535789489746, "_timestamp": 1585577612.3804228, "_step": 109}
{"Episode reward": 54.59768471382522, "Episode length": 455, "Policy Loss": 1.2351278066635132, "Value Loss": 21.217695236206055, "_runtime": 7698.055851221085, "_timestamp": 1585577613.9004846, "_step": 110}
{"Episode reward": -99.81489000573062, "Episode length": 999, "Policy Loss": -0.32913652062416077, "Value Loss": 0.011422712355852127, "_runtime": 7698.945058107376, "_timestamp": 1585577614.7896914, "_step": 111}
{"Episode reward": 45.79999999999951, "Episode length": 542, "Policy Loss": 1.109866738319397, "Value Loss": 18.031883239746094, "_runtime": 7700.282453775406, "_timestamp": 1585577616.127087, "_step": 112}
{"Episode reward": 12.825406003458866, "Episode length": 873, "Policy Loss": 0.7339516878128052, "Value Loss": 11.28032112121582, "_runtime": 7701.030708789825, "_timestamp": 1585577616.8753421, "_step": 113}
{"Episode reward": 53.69152388423643, "Episode length": 464, "Policy Loss": 1.4930130243301392, "Value Loss": 21.24959945678711, "_runtime": 7702.565979480743, "_timestamp": 1585577618.4106128, "_step": 114}
{"Episode reward": -99.77780711985984, "Episode length": 999, "Policy Loss": -0.2501499056816101, "Value Loss": 0.004484663251787424, "_runtime": 7704.128690004349, "_timestamp": 1585577619.9733233, "_step": 115}
{"Episode reward": -99.72832312830585, "Episode length": 999, "Policy Loss": -0.2737363278865814, "Value Loss": 0.027888933196663857, "_runtime": 7705.65168261528, "_timestamp": 1585577621.496316, "_step": 116}
{"Episode reward": -99.68539591143352, "Episode length": 999, "Policy Loss": -0.3941406309604645, "Value Loss": 0.07235008478164673, "_runtime": 7707.218403339386, "_timestamp": 1585577623.0630367, "_step": 117}
{"Episode reward": -99.54764018715804, "Episode length": 999, "Policy Loss": -0.36899369955062866, "Value Loss": 0.0034381826408207417, "_runtime": 7708.021641492844, "_timestamp": 1585577623.8662748, "_step": 118}
{"Episode reward": 50.79999999999958, "Episode length": 492, "Policy Loss": 1.1100910902023315, "Value Loss": 19.69645118713379, "_runtime": 7709.24675989151, "_timestamp": 1585577625.0913932, "_step": 119}
{"Episode reward": 24.65256637930871, "Episode length": 754, "Policy Loss": 0.6298585534095764, "Value Loss": 12.909671783447266, "_runtime": 7710.824071884155, "_timestamp": 1585577626.6687052, "_step": 120}
{"Episode reward": -99.8531424448113, "Episode length": 999, "Policy Loss": -0.46113717555999756, "Value Loss": 0.03887871280312538, "_runtime": 7711.576814174652, "_timestamp": 1585577627.4214475, "_step": 121}
{"Episode reward": 52.066992910752425, "Episode length": 480, "Policy Loss": 1.2019267082214355, "Value Loss": 20.096202850341797, "_runtime": 7713.1233904361725, "_timestamp": 1585577628.9680238, "_step": 122}
{"Episode reward": -99.721781827882, "Episode length": 999, "Policy Loss": -0.43245041370391846, "Value Loss": 0.0820864737033844, "_runtime": 7713.806035041809, "_timestamp": 1585577629.6506684, "_step": 123}
{"Episode reward": 58.49999999999969, "Episode length": 415, "Policy Loss": 1.5203378200531006, "Value Loss": 23.7557373046875, "_runtime": 7715.352235555649, "_timestamp": 1585577631.196869, "_step": 124}
{"Episode reward": -99.62093296395476, "Episode length": 999, "Policy Loss": -0.36826133728027344, "Value Loss": 0.005599962081760168, "_runtime": 7716.921140670776, "_timestamp": 1585577632.765774, "_step": 125}
{"Episode reward": -99.6487408223548, "Episode length": 999, "Policy Loss": -0.4902374744415283, "Value Loss": 0.01537371426820755, "_runtime": 7718.443194389343, "_timestamp": 1585577634.2878277, "_step": 126}
{"Episode reward": -99.80075580333802, "Episode length": 999, "Policy Loss": -0.5559448003768921, "Value Loss": 0.36103910207748413, "_runtime": 7719.599410533905, "_timestamp": 1585577635.4440439, "_step": 127}
{"Episode reward": 27.599519499105938, "Episode length": 725, "Policy Loss": 0.5570980906486511, "Value Loss": 13.43634033203125, "_runtime": 7720.699042797089, "_timestamp": 1585577636.5436761, "_step": 128}
{"Episode reward": 31.074760592635357, "Episode length": 691, "Policy Loss": 0.6695598363876343, "Value Loss": 14.163357734680176, "_runtime": 7722.256552934647, "_timestamp": 1585577638.1011863, "_step": 129}
{"Episode reward": -99.81955135920876, "Episode length": 999, "Policy Loss": -0.3334957957267761, "Value Loss": 0.08981490135192871, "_runtime": 7723.535989284515, "_timestamp": 1585577639.3806226, "_step": 130}
{"Episode reward": 18.840808137617174, "Episode length": 814, "Policy Loss": 0.5446649789810181, "Value Loss": 11.903156280517578, "_runtime": 7725.006701231003, "_timestamp": 1585577640.8513346, "_step": 131}
{"Episode reward": 5.800000000001077, "Episode length": 942, "Policy Loss": 0.4057270884513855, "Value Loss": 10.45151424407959, "_runtime": 7726.583804368973, "_timestamp": 1585577642.4284377, "_step": 132}
{"Episode reward": -99.85202931314568, "Episode length": 999, "Policy Loss": -0.5793561339378357, "Value Loss": 0.06761614233255386, "_runtime": 7728.145754814148, "_timestamp": 1585577643.9903882, "_step": 133}
{"Episode reward": -99.68036824837706, "Episode length": 999, "Policy Loss": -0.5680026412010193, "Value Loss": 0.16903501749038696, "_runtime": 7728.814984560013, "_timestamp": 1585577644.659618, "_step": 134}
{"Episode reward": 59.099999999999696, "Episode length": 409, "Policy Loss": 2.0840704441070557, "Value Loss": 23.297292709350586, "_runtime": 7730.159428119659, "_timestamp": 1585577646.0040615, "_step": 135}
{"Episode reward": 14.89514919808191, "Episode length": 852, "Policy Loss": 0.44423267245292664, "Value Loss": 11.454538345336914, "_runtime": 7730.944252252579, "_timestamp": 1585577646.7888856, "_step": 136}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": 1.1227353811264038, "Value Loss": 20.188722610473633, "_runtime": 7732.51705622673, "_timestamp": 1585577648.3616896, "_step": 137}
{"Episode reward": -99.73254273347999, "Episode length": 999, "Policy Loss": -0.551327109336853, "Value Loss": 0.04848514124751091, "_runtime": 7734.080616950989, "_timestamp": 1585577649.9252503, "_step": 138}
{"Episode reward": -99.81687166655762, "Episode length": 999, "Policy Loss": -0.6491528153419495, "Value Loss": 0.042610373347997665, "_runtime": 7734.954660177231, "_timestamp": 1585577650.7992935, "_step": 139}
{"Episode reward": 44.034331056102594, "Episode length": 560, "Policy Loss": 0.8458096385002136, "Value Loss": 17.44579315185547, "_runtime": 7736.510387659073, "_timestamp": 1585577652.355021, "_step": 140}
{"Episode reward": -99.80323349787948, "Episode length": 999, "Policy Loss": -0.7679877281188965, "Value Loss": 0.023254457861185074, "_runtime": 7738.0174787044525, "_timestamp": 1585577653.862112, "_step": 141}
{"Episode reward": 3.8458636972133746, "Episode length": 963, "Policy Loss": 0.07706817239522934, "Value Loss": 10.220403671264648, "_runtime": 7739.555155754089, "_timestamp": 1585577655.399789, "_step": 142}
{"Episode reward": -99.74505004221433, "Episode length": 999, "Policy Loss": -0.6193720102310181, "Value Loss": 0.012633761391043663, "_runtime": 7740.220854759216, "_timestamp": 1585577656.065488, "_step": 143}
{"Episode reward": 59.786241397424305, "Episode length": 403, "Policy Loss": 1.250872254371643, "Value Loss": 23.912151336669922, "_runtime": 7741.78929567337, "_timestamp": 1585577657.633929, "_step": 144}
{"Episode reward": -99.43694434694925, "Episode length": 999, "Policy Loss": -0.5388452410697937, "Value Loss": 0.02087661810219288, "_runtime": 7743.154671907425, "_timestamp": 1585577658.9993052, "_step": 145}
{"Episode reward": 12.799483760294194, "Episode length": 873, "Policy Loss": 0.36208391189575195, "Value Loss": 11.109230041503906, "_runtime": 7743.86714720726, "_timestamp": 1585577659.7117805, "_step": 146}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 1.0606625080108643, "Value Loss": 20.501188278198242, "_runtime": 7745.418703317642, "_timestamp": 1585577661.2633367, "_step": 147}
{"Episode reward": -99.70035951250325, "Episode length": 999, "Policy Loss": -0.6630719304084778, "Value Loss": 0.1685675084590912, "_runtime": 7746.966820716858, "_timestamp": 1585577662.811454, "_step": 148}
{"Episode reward": -99.65375018506317, "Episode length": 999, "Policy Loss": -0.7122876644134521, "Value Loss": 0.15423350036144257, "_runtime": 7747.6839945316315, "_timestamp": 1585577663.5286279, "_step": 149}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.2007684707641602, "Value Loss": 20.704179763793945, "_runtime": 7749.246718883514, "_timestamp": 1585577665.0913522, "_step": 150}
{"Episode reward": -99.83998146208329, "Episode length": 999, "Policy Loss": -0.6435861587524414, "Value Loss": 0.013455302454531193, "_runtime": 7750.812651872635, "_timestamp": 1585577666.6572852, "_step": 151}
{"Episode reward": -99.80047594369832, "Episode length": 999, "Policy Loss": -0.6246390342712402, "Value Loss": 0.029286926612257957, "_runtime": 7752.324519872665, "_timestamp": 1585577668.1691532, "_step": 152}
{"Episode reward": -99.7437399157309, "Episode length": 999, "Policy Loss": -0.5583609938621521, "Value Loss": 0.013514867052435875, "_runtime": 7753.896646499634, "_timestamp": 1585577669.7412798, "_step": 153}
{"Episode reward": -99.8980745443129, "Episode length": 999, "Policy Loss": -0.5670731663703918, "Value Loss": 0.017505252733826637, "_runtime": 7754.419057846069, "_timestamp": 1585577670.2636912, "_step": 154}
{"Episode reward": 69.29999999999984, "Episode length": 307, "Policy Loss": 2.068655014038086, "Value Loss": 31.622541427612305, "_runtime": 7755.504478693008, "_timestamp": 1585577671.349112, "_step": 155}
{"Episode reward": 29.9999999999997, "Episode length": 700, "Policy Loss": 0.448883593082428, "Value Loss": 13.711883544921875, "_runtime": 7757.107948541641, "_timestamp": 1585577672.952582, "_step": 156}
{"Episode reward": -99.76837743576478, "Episode length": 999, "Policy Loss": -0.7869396209716797, "Value Loss": 0.07376060634851456, "_runtime": 7758.421005010605, "_timestamp": 1585577674.2656384, "_step": 157}
{"Episode reward": 12.398261928559052, "Episode length": 877, "Policy Loss": -0.09858177602291107, "Value Loss": 10.989093780517578, "_runtime": 7759.95801782608, "_timestamp": 1585577675.8026512, "_step": 158}
{"Episode reward": -99.82621528750612, "Episode length": 999, "Policy Loss": -0.7476935386657715, "Value Loss": 0.05610481649637222, "_runtime": 7761.51824593544, "_timestamp": 1585577677.3628793, "_step": 159}
{"Episode reward": -99.78754835249717, "Episode length": 999, "Policy Loss": -0.6869437098503113, "Value Loss": 0.05479208752512932, "_runtime": 7763.052759408951, "_timestamp": 1585577678.8973927, "_step": 160}
{"Episode reward": -99.80872896998632, "Episode length": 999, "Policy Loss": -0.6590867638587952, "Value Loss": 0.018228884786367416, "_runtime": 7764.622932910919, "_timestamp": 1585577680.4675663, "_step": 161}
{"Episode reward": -99.79326959732431, "Episode length": 999, "Policy Loss": -0.5198717713356018, "Value Loss": 0.014829210937023163, "_runtime": 7766.198312759399, "_timestamp": 1585577682.042946, "_step": 162}
{"Episode reward": -99.76223299244747, "Episode length": 999, "Policy Loss": -0.3483058512210846, "Value Loss": 0.06388255953788757, "_runtime": 7767.747150659561, "_timestamp": 1585577683.591784, "_step": 163}
{"Episode reward": -99.70017280729815, "Episode length": 999, "Policy Loss": -0.36389413475990295, "Value Loss": 0.07035496830940247, "_runtime": 7768.9244503974915, "_timestamp": 1585577684.7690837, "_step": 164}
{"Episode reward": 24.86696798352932, "Episode length": 755, "Policy Loss": 0.702359676361084, "Value Loss": 13.00796890258789, "_runtime": 7770.031403541565, "_timestamp": 1585577685.876037, "_step": 165}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.6349486112594604, "Value Loss": 13.610051155090332, "_runtime": 7771.594144582748, "_timestamp": 1585577687.438778, "_step": 166}
{"Episode reward": -99.63934500855255, "Episode length": 999, "Policy Loss": -0.6727631092071533, "Value Loss": 0.01888968050479889, "_runtime": 7772.277812242508, "_timestamp": 1585577688.1224456, "_step": 167}
{"Episode reward": 57.48215864484631, "Episode length": 427, "Policy Loss": 1.0839624404907227, "Value Loss": 22.574214935302734, "_runtime": 7773.830663442612, "_timestamp": 1585577689.6752968, "_step": 168}
{"Episode reward": -99.79295846547909, "Episode length": 999, "Policy Loss": -0.8328206539154053, "Value Loss": 0.560619056224823, "_runtime": 7775.304895162582, "_timestamp": 1585577691.1495285, "_step": 169}
{"Episode reward": 6.029661460076355, "Episode length": 941, "Policy Loss": 0.4438394010066986, "Value Loss": 11.261964797973633, "_runtime": 7776.813412904739, "_timestamp": 1585577692.6580462, "_step": 170}
{"Episode reward": -99.8986859858022, "Episode length": 999, "Policy Loss": -0.3061208128929138, "Value Loss": 0.1039675772190094, "_runtime": 7778.232755899429, "_timestamp": 1585577694.0773892, "_step": 171}
{"Episode reward": 9.777536549536435, "Episode length": 905, "Policy Loss": 0.8002389669418335, "Value Loss": 11.287193298339844, "_runtime": 7779.831320285797, "_timestamp": 1585577695.6759536, "_step": 172}
{"Episode reward": -99.81660323738912, "Episode length": 999, "Policy Loss": 0.07352914661169052, "Value Loss": 2.3249595165252686, "_runtime": 7781.390970945358, "_timestamp": 1585577697.2356043, "_step": 173}
{"Episode reward": -99.6619303905624, "Episode length": 999, "Policy Loss": -0.2507193982601166, "Value Loss": 0.09246881306171417, "_runtime": 7782.4908838272095, "_timestamp": 1585577698.3355172, "_step": 174}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": 0.7599489092826843, "Value Loss": 13.9485445022583, "_runtime": 7784.0578956604, "_timestamp": 1585577699.902529, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8657560348510742, "Value Loss": 0.47803324460983276, "_runtime": 7785.6238877773285, "_timestamp": 1585577701.468521, "_step": 176}
{"Episode reward": -99.80385084329616, "Episode length": 999, "Policy Loss": -0.8150802850723267, "Value Loss": 0.15177933871746063, "_runtime": 7786.603147745132, "_timestamp": 1585577702.447781, "_step": 177}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": 0.3872872591018677, "Value Loss": 16.27532196044922, "_runtime": 7787.243409395218, "_timestamp": 1585577703.0880427, "_step": 178}
{"Episode reward": 60.99999999999972, "Episode length": 390, "Policy Loss": 1.5158461332321167, "Value Loss": 24.452356338500977, "_runtime": 7788.286728620529, "_timestamp": 1585577704.131362, "_step": 179}
{"Episode reward": 32.71078333339929, "Episode length": 673, "Policy Loss": 0.988038182258606, "Value Loss": 15.048276901245117, "_runtime": 7789.829189777374, "_timestamp": 1585577705.673823, "_step": 180}
{"Episode reward": -99.82599699015124, "Episode length": 999, "Policy Loss": -0.23631268739700317, "Value Loss": 0.052349403500556946, "_runtime": 7791.340054512024, "_timestamp": 1585577707.1846879, "_step": 181}
{"Episode reward": -99.72393214900373, "Episode length": 999, "Policy Loss": -0.37701502442359924, "Value Loss": 0.03306810185313225, "_runtime": 7792.601409912109, "_timestamp": 1585577708.4460433, "_step": 182}
{"Episode reward": 18.18292339211368, "Episode length": 819, "Policy Loss": 0.4844417870044708, "Value Loss": 11.798666954040527, "_runtime": 7793.263715982437, "_timestamp": 1585577709.1083493, "_step": 183}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 1.661625862121582, "Value Loss": 23.906492233276367, "_runtime": 7794.807497262955, "_timestamp": 1585577710.6521306, "_step": 184}
{"Episode reward": -99.7736946657286, "Episode length": 999, "Policy Loss": -0.6568236947059631, "Value Loss": 0.033615317195653915, "_runtime": 7796.354798793793, "_timestamp": 1585577712.1994321, "_step": 185}
{"Episode reward": -99.47776958487675, "Episode length": 999, "Policy Loss": -0.5906950235366821, "Value Loss": 0.04461761564016342, "_runtime": 7797.863848686218, "_timestamp": 1585577713.708482, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5198758244514465, "Value Loss": 0.045564472675323486, "_runtime": 7799.409689903259, "_timestamp": 1585577715.2543232, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4557706415653229, "Value Loss": 0.008109712973237038, "_runtime": 7800.981463909149, "_timestamp": 1585577716.8260972, "_step": 188}
{"Episode reward": -99.82758108833666, "Episode length": 999, "Policy Loss": -0.35865285992622375, "Value Loss": 0.010335609316825867, "_runtime": 7802.529855966568, "_timestamp": 1585577718.3744893, "_step": 189}
{"Episode reward": -99.80151367785734, "Episode length": 999, "Policy Loss": -0.3311270773410797, "Value Loss": 0.04425555840134621, "_runtime": 7803.352535247803, "_timestamp": 1585577719.1971686, "_step": 190}
{"Episode reward": 51.46688694357831, "Episode length": 486, "Policy Loss": 1.4080206155776978, "Value Loss": 19.942182540893555, "_runtime": 7804.910577058792, "_timestamp": 1585577720.7552104, "_step": 191}
{"Episode reward": -99.83206777721503, "Episode length": 999, "Policy Loss": -0.44052836298942566, "Value Loss": 0.013921837322413921, "_runtime": 7806.476944208145, "_timestamp": 1585577722.3215775, "_step": 192}
{"Episode reward": -99.80829935073713, "Episode length": 999, "Policy Loss": -0.4925220012664795, "Value Loss": 0.4506117105484009, "_runtime": 7807.590555906296, "_timestamp": 1585577723.4351892, "_step": 193}
{"Episode reward": 27.00594704620876, "Episode length": 731, "Policy Loss": 0.6887931227684021, "Value Loss": 13.1336088180542, "_runtime": 7809.162922382355, "_timestamp": 1585577725.0075557, "_step": 194}
{"Episode reward": -99.76863284054068, "Episode length": 999, "Policy Loss": -0.3614065945148468, "Value Loss": 0.46355438232421875, "_runtime": 7810.525155067444, "_timestamp": 1585577726.3697884, "_step": 195}
{"Episode reward": 13.411765716970606, "Episode length": 866, "Policy Loss": 0.5783759951591492, "Value Loss": 11.150635719299316, "_runtime": 7812.054576635361, "_timestamp": 1585577727.89921, "_step": 196}
{"Episode reward": -99.6523725222084, "Episode length": 999, "Policy Loss": -0.19002372026443481, "Value Loss": 0.22206714749336243, "_runtime": 7813.63427233696, "_timestamp": 1585577729.4789057, "_step": 197}
{"Episode reward": -99.87223547436157, "Episode length": 999, "Policy Loss": -0.025777505710721016, "Value Loss": 0.3174961805343628, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355, 0.2770039439201355]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2770039439201355, 0.1187763512134552, 0.5145566463470459, 0.9103369116783142, 1.306117296218872, 1.7018976211547852, 2.097677707672119, 2.4934580326080322, 2.8892383575439453, 3.2850186824798584, 3.6807990074157715, 4.076579570770264, 4.472359657287598, 4.86814022064209, 5.263920307159424, 5.659700870513916, 6.05548095703125, 6.451261043548584, 6.847041606903076, 7.24282169342041, 7.638602256774902, 8.034381866455078, 8.43016242980957, 8.825942993164062, 9.221722602844238, 9.61750316619873, 10.013283729553223, 10.409063339233398, 10.80484390258789, 11.200624465942383, 11.596405029296875, 11.99218463897705, 12.387965202331543, 12.783745765686035, 13.179525375366211, 13.575305938720703, 13.971086502075195, 14.366867065429688, 14.762646675109863, 15.158427238464355, 15.554207801818848, 15.949987411499023, 16.345767974853516, 16.741548538208008, 17.1373291015625, 17.533109664916992, 17.928890228271484, 18.324668884277344, 18.720449447631836, 19.116230010986328, 19.51201057434082, 19.907791137695312, 20.303571701049805, 20.699352264404297, 21.095130920410156, 21.49091148376465, 21.88669204711914, 22.282472610473633, 22.678253173828125, 23.074033737182617, 23.46981430053711, 23.86559295654297, 24.26137351989746, 24.657154083251953, 25.052934646606445]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11937259137630463, -0.10105359554290771, -0.0827346071600914, -0.06441561877727509, -0.046096622943878174, -0.027777627110481262, -0.009458638727664948, 0.008860349655151367, 0.02717934548854828, 0.04549834132194519, 0.0638173371553421, 0.08213631808757782, 0.10045531392097473, 0.11877430975437164, 0.13709329068660736, 0.15541230142116547, 0.17373128235340118, 0.1920502632856369, 0.210369274020195, 0.22868825495243073, 0.24700726568698883, 0.26532626152038574, 0.2836452126502991, 0.3019642233848572, 0.3202832341194153, 0.3386021852493286, 0.3569211959838867, 0.3752402067184448, 0.39355915784835815, 0.41187816858291626, 0.43019717931747437, 0.4485161304473877, 0.4668351411819458, 0.4851541519165039, 0.5034731030464172, 0.5217921137809753, 0.5401111245155334, 0.5584300756454468, 0.5767490863800049, 0.595068097114563, 0.6133871078491211, 0.6317060589790344, 0.6500250697135925, 0.6683440804481506, 0.686663031578064, 0.7049820423126221, 0.7233010530471802, 0.7416200041770935, 0.7599390149116516, 0.7782580256462097, 0.796576976776123, 0.8148959875106812, 0.8332149982452393, 0.8515339493751526, 0.8698529601097107, 0.888171911239624, 0.9064909219741821, 0.9248099327087402, 0.9431289434432983, 0.9614479541778564, 0.9797669649124146, 0.9980858564376831, 1.0164048671722412, 1.0347238779067993, 1.0530428886413574]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [11.0, 6.0, 4.0, 16.0, 16.0, 4.0, 4.0, 4.0, 18.0, 246.0, 39.0, 9.0, 50.0, 30.0, 8.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.128641128540039, -1.0124346017837524, -0.8962281346321106, -0.7800216674804688, -0.6638151407241821, -0.5476086139678955, -0.43140214681625366, -0.3151956796646118, -0.1989891529083252, -0.08278262615203857, 0.03342390060424805, 0.14963030815124512, 0.26583683490753174, 0.38204336166381836, 0.49824976921081543, 0.614456295967102, 0.7306628227233887, 0.8468693494796753, 0.9630758762359619, 1.079282283782959, 1.1954889297485352, 1.3116953372955322, 1.4279017448425293, 1.5441083908081055, 1.6603147983551025, 1.7765212059020996, 1.8927278518676758, 2.008934259414673, 2.12514066696167, 2.241347312927246, 2.357553720474243, 2.4737603664398193, 2.5899667739868164, 2.7061731815338135, 2.8223798274993896, 2.9385862350463867, 3.054792881011963, 3.170999050140381, 3.287205696105957, 3.403412342071533, 3.5196189880371094, 3.6358251571655273, 3.7520318031311035, 3.8682384490966797, 3.9844446182250977, 4.100651264190674, 4.21685791015625, 4.333064079284668, 4.449270725250244, 4.56547737121582, 4.681683540344238, 4.7978901863098145, 4.914096832275391, 5.030303001403809, 5.146509647369385, 5.262716293334961, 5.378922462463379, 5.495129108428955, 5.611335754394531, 5.727542400360107, 5.843748569488525, 5.959955215454102, 6.076161861419678, 6.192368030548096, 6.308574676513672]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 6.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0], "bins": [-8.408811569213867, -8.102462768554688, -7.796114444732666, -7.489765644073486, -7.183416843414307, -6.877068519592285, -6.5707197189331055, -6.264370918273926, -5.958022117614746, -5.651673793792725, -5.345324993133545, -5.038976669311523, -4.732627868652344, -4.426279067993164, -4.119930267333984, -3.813581943511963, -3.507233142852783, -3.2008843421936035, -2.894536018371582, -2.5881872177124023, -2.2818384170532227, -1.9754900932312012, -1.6691412925720215, -1.3627924919128418, -1.0564441680908203, -0.7500953674316406, -0.44374656677246094, -0.13739776611328125, 0.16895103454589844, 0.4752988815307617, 0.7816476821899414, 1.087996482849121, 1.3943452835083008, 1.7006940841674805, 2.00704288482666, 2.31339168548584, 2.619739532470703, 2.926088333129883, 3.2324371337890625, 3.538785934448242, 3.845134735107422, 4.151483535766602, 4.457831382751465, 4.7641801834106445, 5.070528984069824, 5.376877784729004, 5.683226585388184, 5.989575386047363, 6.295923233032227, 6.602272033691406, 6.908620834350586, 7.214969635009766, 7.521318435668945, 7.827667236328125, 8.134016036987305, 8.440364837646484, 8.746713638305664, 9.053062438964844, 9.35940933227539, 9.66575813293457, 9.97210693359375, 10.27845573425293, 10.58480453491211, 10.891153335571289, 11.197502136230469]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 3.0, 7.0, 3.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 2.0, 1.0], "bins": [-3.232172966003418, -3.149616241455078, -3.0670595169067383, -2.9845027923583984, -2.9019460678100586, -2.8193893432617188, -2.736832618713379, -2.654275894165039, -2.571719169616699, -2.4891624450683594, -2.4066057205200195, -2.3240489959716797, -2.24149227142334, -2.158935546875, -2.07637882232666, -1.9938220977783203, -1.9112653732299805, -1.8287086486816406, -1.7461519241333008, -1.663595199584961, -1.581038475036621, -1.4984817504882812, -1.4159250259399414, -1.3333683013916016, -1.2508115768432617, -1.1682548522949219, -1.085698127746582, -1.0031414031982422, -0.9205846786499023, -0.8380279541015625, -0.7554712295532227, -0.6729145050048828, -0.590357780456543, -0.5078010559082031, -0.4252443313598633, -0.34268760681152344, -0.2601308822631836, -0.17757415771484375, -0.0950174331665039, -0.012460708618164062, 0.07009601593017578, 0.15265274047851562, 0.23520946502685547, 0.3177661895751953, 0.40032291412353516, 0.482879638671875, 0.5654363632202148, 0.6479930877685547, 0.7305498123168945, 0.8131065368652344, 0.8956632614135742, 0.9782199859619141, 1.060776710510254, 1.1433334350585938, 1.2258901596069336, 1.3084468841552734, 1.3910036087036133, 1.4735603332519531, 1.556117057800293, 1.6386737823486328, 1.7212305068969727, 1.8037872314453125, 1.8863439559936523, 1.9689006805419922, 2.051457405090332]}, "_runtime": 7814.74755859375, "_timestamp": 1585577730.592192, "_step": 198}
{"Episode reward": 29.12959531105564, "Episode length": 710, "Policy Loss": 0.9302607774734497, "Value Loss": 14.135160446166992, "_runtime": 7815.364052057266, "_timestamp": 1585577731.2086854, "_step": 199}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 1.5695116519927979, "Value Loss": 25.00529670715332, "_runtime": 7816.920498371124, "_timestamp": 1585577732.7651317, "_step": 200}
{"Episode reward": -99.56885873240397, "Episode length": 999, "Policy Loss": -0.7460131049156189, "Value Loss": 0.1143401637673378, "_runtime": 7818.462389945984, "_timestamp": 1585577734.3070233, "_step": 201}
{"Episode reward": -99.83243823566015, "Episode length": 999, "Policy Loss": -1.023589015007019, "Value Loss": 1.5613166093826294, "_runtime": 7819.614649772644, "_timestamp": 1585577735.459283, "_step": 202}
{"Episode reward": 23.690737844718456, "Episode length": 766, "Policy Loss": 0.27663344144821167, "Value Loss": 13.34166145324707, "_runtime": 7821.169198989868, "_timestamp": 1585577737.0138323, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7427282333374023, "Value Loss": 0.10691674053668976, "_runtime": 7822.72723197937, "_timestamp": 1585577738.5718653, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4072815179824829, "Value Loss": 0.013095791451632977, "_runtime": 7824.234330415726, "_timestamp": 1585577740.0789638, "_step": 205}
{"Episode reward": 1.8848014807050504, "Episode length": 984, "Policy Loss": 0.7760025262832642, "Value Loss": 10.128231048583984, "_runtime": 7825.305491447449, "_timestamp": 1585577741.1501248, "_step": 206}
{"Episode reward": 32.272460566460666, "Episode length": 678, "Policy Loss": 1.078872799873352, "Value Loss": 14.705118179321289, "_runtime": 7826.698196649551, "_timestamp": 1585577742.54283, "_step": 207}
{"Episode reward": 13.32461908699544, "Episode length": 868, "Policy Loss": 0.685217022895813, "Value Loss": 11.2378568649292, "_runtime": 7828.261273860931, "_timestamp": 1585577744.1059072, "_step": 208}
{"Episode reward": -99.40412705759961, "Episode length": 999, "Policy Loss": -0.6023566126823425, "Value Loss": 0.02012372948229313, "_runtime": 7829.348967075348, "_timestamp": 1585577745.1936004, "_step": 209}
{"Episode reward": 29.766075931985384, "Episode length": 703, "Policy Loss": 0.6046637296676636, "Value Loss": 14.547630310058594, "_runtime": 7830.896613836288, "_timestamp": 1585577746.7412472, "_step": 210}
{"Episode reward": -99.80218709148328, "Episode length": 999, "Policy Loss": -0.7490420341491699, "Value Loss": 0.1387035846710205, "_runtime": 7832.046233892441, "_timestamp": 1585577747.8908672, "_step": 211}
{"Episode reward": 27.402246423810567, "Episode length": 727, "Policy Loss": 0.44080543518066406, "Value Loss": 14.007003784179688, "_runtime": 7833.609717607498, "_timestamp": 1585577749.454351, "_step": 212}
{"Episode reward": -99.70423755945964, "Episode length": 999, "Policy Loss": -0.2140578180551529, "Value Loss": 0.1640617698431015, "_runtime": 7835.196453332901, "_timestamp": 1585577751.0410867, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17312303185462952, "Value Loss": 0.1309932917356491, "_runtime": 7836.337413311005, "_timestamp": 1585577752.1820467, "_step": 214}
{"Episode reward": 26.999999999999872, "Episode length": 730, "Policy Loss": 1.1312814950942993, "Value Loss": 20.258893966674805, "_runtime": 7837.904116392136, "_timestamp": 1585577753.7487497, "_step": 215}
{"Episode reward": -99.73076732681227, "Episode length": 999, "Policy Loss": -0.09228602796792984, "Value Loss": 0.24979650974273682, "_runtime": 7838.946659564972, "_timestamp": 1585577754.791293, "_step": 216}
{"Episode reward": 35.06336477601377, "Episode length": 650, "Policy Loss": 0.5751136541366577, "Value Loss": 15.587264060974121, "_runtime": 7840.509858131409, "_timestamp": 1585577756.3544915, "_step": 217}
{"Episode reward": -99.80573319531838, "Episode length": 999, "Policy Loss": -0.8285614848136902, "Value Loss": 0.8655330538749695, "_runtime": 7842.0947942733765, "_timestamp": 1585577757.9394276, "_step": 218}
{"Episode reward": -99.89995117783407, "Episode length": 999, "Policy Loss": -1.1568045616149902, "Value Loss": 3.7992770671844482, "_runtime": 7843.583935260773, "_timestamp": 1585577759.4285686, "_step": 219}
{"Episode reward": 3.9995161664668473, "Episode length": 961, "Policy Loss": 0.26985180377960205, "Value Loss": 10.846901893615723, "_runtime": 7845.170610904694, "_timestamp": 1585577761.0152442, "_step": 220}
{"Episode reward": -99.80154765809282, "Episode length": 999, "Policy Loss": -0.01741391234099865, "Value Loss": 0.09325519949197769, "_runtime": 7846.32452917099, "_timestamp": 1585577762.1691625, "_step": 221}
{"Episode reward": 27.574362056188747, "Episode length": 725, "Policy Loss": 1.4175232648849487, "Value Loss": 18.375612258911133, "_runtime": 7847.754276037216, "_timestamp": 1585577763.5989094, "_step": 222}
{"Episode reward": 9.246921573993461, "Episode length": 911, "Policy Loss": 0.9052075147628784, "Value Loss": 11.105807304382324, "_runtime": 7848.664395093918, "_timestamp": 1585577764.5090284, "_step": 223}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.7366476058959961, "Value Loss": 16.934911727905273, "_runtime": 7849.403206586838, "_timestamp": 1585577765.24784, "_step": 224}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.090297818183899, "Value Loss": 22.83026885986328, "_runtime": 7850.999670982361, "_timestamp": 1585577766.8443043, "_step": 225}
{"Episode reward": -99.82062636650959, "Episode length": 999, "Policy Loss": -0.5493923425674438, "Value Loss": 0.2280321568250656, "_runtime": 7852.539927959442, "_timestamp": 1585577768.3845613, "_step": 226}
{"Episode reward": -99.75987001852924, "Episode length": 999, "Policy Loss": -0.37974101305007935, "Value Loss": 0.02994128130376339, "_runtime": 7854.069415092468, "_timestamp": 1585577769.9140484, "_step": 227}
{"Episode reward": -99.80647476352611, "Episode length": 999, "Policy Loss": -0.013147336430847645, "Value Loss": 0.21477612853050232, "_runtime": 7855.649094104767, "_timestamp": 1585577771.4937274, "_step": 228}
{"Episode reward": -99.70810251115333, "Episode length": 999, "Policy Loss": 0.12248078733682632, "Value Loss": 0.4075472354888916, "_runtime": 7856.1608600616455, "_timestamp": 1585577772.0054934, "_step": 229}
{"Episode reward": 70.3605886334028, "Episode length": 297, "Policy Loss": 3.0408260822296143, "Value Loss": 34.7553596496582, "_runtime": 7857.724540948868, "_timestamp": 1585577773.5691743, "_step": 230}
{"Episode reward": -99.85513870257424, "Episode length": 999, "Policy Loss": -0.49472782015800476, "Value Loss": 0.41707056760787964, "_runtime": 7858.576821088791, "_timestamp": 1585577774.4214544, "_step": 231}
{"Episode reward": 47.59761736355675, "Episode length": 525, "Policy Loss": 0.44633010029792786, "Value Loss": 20.2211971282959, "_runtime": 7859.03154873848, "_timestamp": 1585577774.876182, "_step": 232}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 1.6216468811035156, "Value Loss": 34.12295150756836, "_runtime": 7860.598197698593, "_timestamp": 1585577776.442831, "_step": 233}
{"Episode reward": -99.8311720208251, "Episode length": 999, "Policy Loss": -0.5807838439941406, "Value Loss": 0.03067128174006939, "_runtime": 7862.136191129684, "_timestamp": 1585577777.9808245, "_step": 234}
{"Episode reward": -99.62816976860492, "Episode length": 999, "Policy Loss": -0.01607622019946575, "Value Loss": 0.34958696365356445, "_runtime": 7863.646534919739, "_timestamp": 1585577779.4911683, "_step": 235}
{"Episode reward": -99.88126278603309, "Episode length": 999, "Policy Loss": 0.10420041531324387, "Value Loss": 2.646312713623047, "_runtime": 7864.9900822639465, "_timestamp": 1585577780.8347156, "_step": 236}
{"Episode reward": 15.346990949888081, "Episode length": 848, "Policy Loss": 1.0856542587280273, "Value Loss": 12.310139656066895, "_runtime": 7866.55761885643, "_timestamp": 1585577782.4022522, "_step": 237}
{"Episode reward": -99.73348224407388, "Episode length": 999, "Policy Loss": -0.2546999454498291, "Value Loss": 0.2578688859939575, "_runtime": 7868.1140859127045, "_timestamp": 1585577783.9587193, "_step": 238}
{"Episode reward": -99.71189155015607, "Episode length": 999, "Policy Loss": -0.6490055322647095, "Value Loss": 0.0509069487452507, "_runtime": 7869.695951223373, "_timestamp": 1585577785.5405846, "_step": 239}
{"Episode reward": -99.71929569195497, "Episode length": 999, "Policy Loss": -1.0099869966506958, "Value Loss": 0.9502184391021729, "_runtime": 7871.269883155823, "_timestamp": 1585577787.1145165, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.834907054901123, "Value Loss": 0.34093424677848816, "_runtime": 7872.8422021865845, "_timestamp": 1585577788.6868355, "_step": 241}
{"Episode reward": -99.80872716680612, "Episode length": 999, "Policy Loss": -1.0425621271133423, "Value Loss": 0.2644609212875366, "_runtime": 7874.45992398262, "_timestamp": 1585577790.3045573, "_step": 242}
{"Episode reward": -99.73751046676048, "Episode length": 999, "Policy Loss": -0.7069772481918335, "Value Loss": 0.6006283164024353, "_runtime": 7875.183759689331, "_timestamp": 1585577791.028393, "_step": 243}
{"Episode reward": 55.18914107643032, "Episode length": 449, "Policy Loss": 1.2798420190811157, "Value Loss": 21.046161651611328, "_runtime": 7875.984335184097, "_timestamp": 1585577791.8289685, "_step": 244}
{"Episode reward": 50.599999999999575, "Episode length": 494, "Policy Loss": 1.458680510520935, "Value Loss": 19.65465545654297, "_runtime": 7876.74223446846, "_timestamp": 1585577792.5868678, "_step": 245}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.3921313285827637, "Value Loss": 20.127519607543945, "_runtime": 7878.272800207138, "_timestamp": 1585577794.1174335, "_step": 246}
{"Episode reward": -99.7833294265191, "Episode length": 999, "Policy Loss": -0.5215798020362854, "Value Loss": 0.047978777438402176, "_runtime": 7878.925785303116, "_timestamp": 1585577794.7704186, "_step": 247}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 1.4530888795852661, "Value Loss": 24.02679443359375, "_runtime": 7879.984298706055, "_timestamp": 1585577795.828932, "_step": 248}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": 0.6785304546356201, "Value Loss": 13.898208618164062, "_runtime": 7880.955711841583, "_timestamp": 1585577796.8003452, "_step": 249}
{"Episode reward": 38.99999999999941, "Episode length": 610, "Policy Loss": 0.8453824520111084, "Value Loss": 15.40257453918457, "_runtime": 7882.468057870865, "_timestamp": 1585577798.3126912, "_step": 250}
{"Episode reward": -99.75861617058843, "Episode length": 999, "Policy Loss": -0.33785921335220337, "Value Loss": 0.016281915828585625, "_runtime": 7884.013026714325, "_timestamp": 1585577799.85766, "_step": 251}
{"Episode reward": -99.80980879331916, "Episode length": 999, "Policy Loss": -0.2258400022983551, "Value Loss": 0.11164945363998413, "_runtime": 7885.546824216843, "_timestamp": 1585577801.3914576, "_step": 252}
{"Episode reward": -99.77974221743504, "Episode length": 999, "Policy Loss": -0.3146445155143738, "Value Loss": 0.21173633635044098, "_runtime": 7886.67665719986, "_timestamp": 1585577802.5212905, "_step": 253}
{"Episode reward": 28.86720403523627, "Episode length": 712, "Policy Loss": 0.6928285956382751, "Value Loss": 13.334874153137207, "_runtime": 7887.900965213776, "_timestamp": 1585577803.7455986, "_step": 254}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.37403619289398193, "Value Loss": 12.108292579650879, "_runtime": 7889.475627183914, "_timestamp": 1585577805.3202605, "_step": 255}
{"Episode reward": -99.7042404700988, "Episode length": 999, "Policy Loss": -0.8980141282081604, "Value Loss": 0.1000342145562172, "_runtime": 7890.613340616226, "_timestamp": 1585577806.457974, "_step": 256}
{"Episode reward": 27.557543466985067, "Episode length": 726, "Policy Loss": 0.39394423365592957, "Value Loss": 13.744131088256836, "_runtime": 7891.975883245468, "_timestamp": 1585577807.8205166, "_step": 257}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": 0.2173372209072113, "Value Loss": 11.375402450561523, "_runtime": 7893.544083356857, "_timestamp": 1585577809.3887167, "_step": 258}
{"Episode reward": -99.63218238477573, "Episode length": 999, "Policy Loss": -0.4016436040401459, "Value Loss": 0.5308772325515747, "_runtime": 7894.980006456375, "_timestamp": 1585577810.8246398, "_step": 259}
{"Episode reward": 7.22123220823805, "Episode length": 928, "Policy Loss": 0.6319999694824219, "Value Loss": 11.050909042358398, "_runtime": 7896.059522151947, "_timestamp": 1585577811.9041555, "_step": 260}
{"Episode reward": 31.7999999999996, "Episode length": 682, "Policy Loss": 0.9637120962142944, "Value Loss": 14.142560958862305, "_runtime": 7897.672983884811, "_timestamp": 1585577813.5176172, "_step": 261}
{"Episode reward": -99.8866135597215, "Episode length": 999, "Policy Loss": -0.25992336869239807, "Value Loss": 0.05551210045814514, "_runtime": 7899.180574417114, "_timestamp": 1585577815.0252078, "_step": 262}
{"Episode reward": 3.7023037491145345, "Episode length": 964, "Policy Loss": 0.4352421164512634, "Value Loss": 9.888359069824219, "_runtime": 7899.561166524887, "_timestamp": 1585577815.4057999, "_step": 263}
{"Episode reward": 78.15956669430594, "Episode length": 219, "Policy Loss": 3.2123169898986816, "Value Loss": 43.400753021240234, "_runtime": 7901.12797832489, "_timestamp": 1585577816.9726117, "_step": 264}
{"Episode reward": -99.81387544311443, "Episode length": 999, "Policy Loss": -0.6451578736305237, "Value Loss": 0.12119006365537643, "_runtime": 7902.613985776901, "_timestamp": 1585577818.458619, "_step": 265}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.12579160928726196, "Value Loss": 10.0696382522583, "_runtime": 7903.497202396393, "_timestamp": 1585577819.3418357, "_step": 266}
{"Episode reward": 41.69999999999945, "Episode length": 583, "Policy Loss": 0.5386275053024292, "Value Loss": 16.980318069458008, "_runtime": 7905.069967508316, "_timestamp": 1585577820.9146008, "_step": 267}
{"Episode reward": -99.88610874870652, "Episode length": 999, "Policy Loss": -0.40704545378685, "Value Loss": 0.06623632460832596, "_runtime": 7905.578255414963, "_timestamp": 1585577821.4228888, "_step": 268}
{"Episode reward": 70.59999999999985, "Episode length": 294, "Policy Loss": 2.5510175228118896, "Value Loss": 33.439579010009766, "_runtime": 7906.197954654694, "_timestamp": 1585577822.042588, "_step": 269}
{"Episode reward": 59.82686952613265, "Episode length": 402, "Policy Loss": 1.5121697187423706, "Value Loss": 23.466753005981445, "_runtime": 7907.764972686768, "_timestamp": 1585577823.609606, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8118740320205688, "Value Loss": 0.05942477285861969, "_runtime": 7909.278529167175, "_timestamp": 1585577825.1231625, "_step": 271}
{"Episode reward": -99.78964425020246, "Episode length": 999, "Policy Loss": -0.9670988321304321, "Value Loss": 0.503084123134613, "_runtime": 7910.801193475723, "_timestamp": 1585577826.6458268, "_step": 272}
{"Episode reward": -99.736687685641, "Episode length": 999, "Policy Loss": -1.26212477684021, "Value Loss": 0.8383525609970093, "_runtime": 7912.369380950928, "_timestamp": 1585577828.2140143, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9815333485603333, "Value Loss": 0.4554844796657562, "_runtime": 7913.931109428406, "_timestamp": 1585577829.7757428, "_step": 274}
{"Episode reward": -99.81788744251686, "Episode length": 999, "Policy Loss": -0.7589522004127502, "Value Loss": 0.0462787002325058, "_runtime": 7915.050166130066, "_timestamp": 1585577830.8947995, "_step": 275}
{"Episode reward": 29.3851704661499, "Episode length": 708, "Policy Loss": 0.676810085773468, "Value Loss": 13.382183074951172, "_runtime": 7916.631404876709, "_timestamp": 1585577832.4760382, "_step": 276}
{"Episode reward": 0.8953257604515699, "Episode length": 992, "Policy Loss": 0.6553903222084045, "Value Loss": 9.596579551696777, "_runtime": 7918.207267045975, "_timestamp": 1585577834.0519004, "_step": 277}
{"Episode reward": -99.88976012701029, "Episode length": 999, "Policy Loss": -0.22717998921871185, "Value Loss": 0.5429165363311768, "_runtime": 7919.460402011871, "_timestamp": 1585577835.3050354, "_step": 278}
{"Episode reward": 19.54721956215829, "Episode length": 805, "Policy Loss": 0.7100175619125366, "Value Loss": 12.093606948852539, "_runtime": 7921.048474311829, "_timestamp": 1585577836.8931077, "_step": 279}
{"Episode reward": -99.71190230122161, "Episode length": 999, "Policy Loss": -0.5010170340538025, "Value Loss": 0.03921154513955116, "_runtime": 7922.623180627823, "_timestamp": 1585577838.467814, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6812813878059387, "Value Loss": 0.016751784831285477, "_runtime": 7924.215549945831, "_timestamp": 1585577840.0601833, "_step": 281}
{"Episode reward": -99.80200855880835, "Episode length": 999, "Policy Loss": -0.6970085501670837, "Value Loss": 0.4771746098995209, "_runtime": 7925.198334693909, "_timestamp": 1585577841.042968, "_step": 282}
{"Episode reward": 39.49999999999942, "Episode length": 605, "Policy Loss": 0.7576187252998352, "Value Loss": 15.58741283416748, "_runtime": 7926.481761932373, "_timestamp": 1585577842.3263953, "_step": 283}
{"Episode reward": 19.498922124132818, "Episode length": 806, "Policy Loss": 0.3883073925971985, "Value Loss": 11.882243156433105, "_runtime": 7928.056687116623, "_timestamp": 1585577843.9013205, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4466582238674164, "Value Loss": 0.26765766739845276, "_runtime": 7929.448994398117, "_timestamp": 1585577845.2936277, "_step": 285}
{"Episode reward": 10.269139537629329, "Episode length": 898, "Policy Loss": 0.43412867188453674, "Value Loss": 10.481282234191895, "_runtime": 7931.0082767009735, "_timestamp": 1585577846.85291, "_step": 286}
{"Episode reward": -99.75710066752369, "Episode length": 999, "Policy Loss": -0.23641304671764374, "Value Loss": 0.08193917572498322, "_runtime": 7931.861818313599, "_timestamp": 1585577847.7064517, "_step": 287}
{"Episode reward": 47.40966648459388, "Episode length": 526, "Policy Loss": 1.4593509435653687, "Value Loss": 18.687623977661133, "_runtime": 7933.128121852875, "_timestamp": 1585577848.9727552, "_step": 288}
{"Episode reward": 20.069002851797535, "Episode length": 801, "Policy Loss": 0.8412970304489136, "Value Loss": 12.179052352905273, "_runtime": 7934.699018955231, "_timestamp": 1585577850.5436523, "_step": 289}
{"Episode reward": -99.88104972076113, "Episode length": 999, "Policy Loss": -0.45466166734695435, "Value Loss": 0.02415337599813938, "_runtime": 7935.6652109622955, "_timestamp": 1585577851.5098443, "_step": 290}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.7131632566452026, "Value Loss": 15.167896270751953, "_runtime": 7937.1381804943085, "_timestamp": 1585577852.9828138, "_step": 291}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": 0.08504805713891983, "Value Loss": 10.036108016967773, "_runtime": 7938.720269680023, "_timestamp": 1585577854.564903, "_step": 292}
{"Episode reward": -99.7413413643823, "Episode length": 999, "Policy Loss": -0.6784704923629761, "Value Loss": 0.06648775935173035, "_runtime": 7940.260835886002, "_timestamp": 1585577856.1054692, "_step": 293}
{"Episode reward": -99.80143256820598, "Episode length": 999, "Policy Loss": -0.6663897037506104, "Value Loss": 0.26932671666145325, "_runtime": 7941.842658042908, "_timestamp": 1585577857.6872914, "_step": 294}
{"Episode reward": -99.89289222992817, "Episode length": 999, "Policy Loss": -0.3533349931240082, "Value Loss": 0.06937474757432938, "_runtime": 7943.406531572342, "_timestamp": 1585577859.251165, "_step": 295}
{"Episode reward": -99.72847529058205, "Episode length": 999, "Policy Loss": -0.2656501531600952, "Value Loss": 0.11485077440738678, "_runtime": 7944.653062820435, "_timestamp": 1585577860.4976962, "_step": 296}
{"Episode reward": 21.50059479540232, "Episode length": 786, "Policy Loss": 0.9307835698127747, "Value Loss": 12.609686851501465, "_runtime": 7945.412981033325, "_timestamp": 1585577861.2576144, "_step": 297}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.4407588243484497, "Value Loss": 20.54583740234375, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142, 0.02788078971207142]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 2.0, 6.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02788078971207142, -0.008663356304168701, 0.010554077103734016, 0.029771512374281883, 0.0489889457821846, 0.06820637732744217, 0.08742381632328033, 0.1066412478685379, 0.12585867941379547, 0.14507611095905304, 0.1642935425043106, 0.18351097404956818, 0.20272842049598694, 0.2219458520412445, 0.24116328358650208, 0.26038071513175964, 0.2795981466770172, 0.2988155782222748, 0.31803300976753235, 0.3372504413127899, 0.3564678728580475, 0.37568530440330505, 0.3949027359485626, 0.4141201674938202, 0.43333762884140015, 0.4525550603866577, 0.4717724919319153, 0.49098992347717285, 0.5102073550224304, 0.529424786567688, 0.5486422181129456, 0.5678596496582031, 0.5870770812034607, 0.6062945127487183, 0.6255119442939758, 0.6447293758392334, 0.663946807384491, 0.6831642389297485, 0.7023816704750061, 0.7215991020202637, 0.7408165335655212, 0.7600339651107788, 0.7792513966560364, 0.798468828201294, 0.8176862597465515, 0.8369036912918091, 0.8561211228370667, 0.8753385543823242, 0.8945560455322266, 0.9137734770774841, 0.9329909086227417, 0.9522083401679993, 0.9714257717132568, 0.9906431436538696, 1.009860634803772, 1.0290780067443848, 1.048295497894287, 1.0675128698349, 1.0867303609848022, 1.105947732925415, 1.1251652240753174, 1.1443825960159302, 1.1636000871658325, 1.1828174591064453, 1.2020349502563477]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.043899696320295334, -0.041555728763341904, -0.039211761206388474, -0.03686779364943504, -0.03452382609248161, -0.03217985853552818, -0.029835892841219902, -0.027491925284266472, -0.02514795772731304, -0.02280399017035961, -0.02046002261340618, -0.01811605505645275, -0.01577208936214447, -0.01342812180519104, -0.01108415424823761, -0.00874018669128418, -0.0063962191343307495, -0.004052251577377319, -0.0017082840204238892, 0.000635683536529541, 0.002979651093482971, 0.005323618650436401, 0.0076675862073898315, 0.010011553764343262, 0.012355517596006393, 0.014699485152959824, 0.017043452709913254, 0.019387420266866684, 0.021731387823820114, 0.024075355380773544, 0.026419322937726974, 0.028763290494680405, 0.031107258051633835, 0.033451225608587265, 0.035795193165540695, 0.038139160722494125, 0.040483128279447556, 0.042827095836400986, 0.045171063393354416, 0.047515030950307846, 0.049858998507261276, 0.052202966064214706, 0.05454693362116814, 0.05689090117812157, 0.059234868735075, 0.06157883629202843, 0.06392280757427216, 0.06626677513122559, 0.06861072778701782, 0.07095469534397125, 0.07329866290092468, 0.07564263045787811, 0.07798659801483154, 0.08033056557178497, 0.0826745331287384, 0.08501850068569183, 0.08736246824264526, 0.0897064357995987, 0.09205040335655212, 0.09439437091350555, 0.09673833847045898, 0.09908230602741241, 0.10142627358436584, 0.10377024114131927, 0.1061142086982727]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [13.0, 5.0, 4.0, 3.0, 1.0, 3.0, 2.0, 8.0, 9.0, 45.0, 49.0, 17.0, 15.0, 172.0, 9.0, 9.0, 14.0, 13.0, 38.0, 19.0, 11.0, 18.0, 2.0, 3.0, 0.0, 3.0, 1.0, 2.0, 4.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10296385735273361, -0.0953112244606018, -0.0876585990190506, -0.08000596612691879, -0.07235333323478699, -0.06470070779323578, -0.05704807490110397, -0.049395445734262466, -0.04174281656742096, -0.034090183675289154, -0.026437558233737946, -0.01878492534160614, -0.011132292449474335, -0.0034796670079231262, 0.004172965884208679, 0.011825591325759888, 0.019478224217891693, 0.0271308496594429, 0.034783490002155304, 0.04243611544370651, 0.05008874088525772, 0.05774138122797012, 0.06539400666952133, 0.07304663211107254, 0.08069927245378494, 0.08835189789533615, 0.09600452333688736, 0.10365714877843857, 0.11130978912115097, 0.11896241456270218, 0.12661504745483398, 0.1342676877975464, 0.1419202983379364, 0.1495729386806488, 0.15722554922103882, 0.16487818956375122, 0.17253082990646362, 0.18018344044685364, 0.18783608078956604, 0.19548872113227844, 0.20314133167266846, 0.21079397201538086, 0.21844661235809326, 0.22609922289848328, 0.23375186324119568, 0.24140450358390808, 0.2490571141242981, 0.2567097544670105, 0.2643623948097229, 0.2720150053501129, 0.2796676456928253, 0.28732025623321533, 0.29497289657592773, 0.30262553691864014, 0.31027814745903015, 0.31793078780174255, 0.32558342814445496, 0.33323603868484497, 0.3408886790275574, 0.3485413193702698, 0.3561939299106598, 0.3638465702533722, 0.3714992105960846, 0.3791518211364746, 0.386804461479187]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 11.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.2036513239145279, -0.19761502742767334, -0.1915787160396576, -0.18554241955280304, -0.1795061230659485, -0.17346982657909393, -0.16743353009223938, -0.16139721870422363, -0.15536092221736908, -0.14932462573051453, -0.14328831434249878, -0.13725201785564423, -0.13121572136878967, -0.12517942488193512, -0.11914312094449997, -0.11310681700706482, -0.10707052052021027, -0.10103422403335571, -0.09499792009592056, -0.08896161615848541, -0.08292531967163086, -0.0768890231847763, -0.07085271179676056, -0.064816415309906, -0.05878011882305145, -0.0527438223361969, -0.046707525849342346, -0.0406712144613266, -0.034634917974472046, -0.028598621487617493, -0.022562310099601746, -0.016526013612747192, -0.01048971712589264, -0.004453420639038086, 0.0015828758478164673, 0.007619187235832214, 0.013655483722686768, 0.01969178020954132, 0.025728091597557068, 0.03176438808441162, 0.037800684571266174, 0.04383698105812073, 0.04987327754497528, 0.05590958893299103, 0.061945900321006775, 0.06798218190670013, 0.07401849329471588, 0.08005477488040924, 0.08609108626842499, 0.09212739765644073, 0.0981636792421341, 0.10419999063014984, 0.1102362722158432, 0.11627258360385895, 0.1223088949918747, 0.12834517657756805, 0.1343814879655838, 0.14041779935359955, 0.1464540809392929, 0.15249039232730865, 0.1585267037153244, 0.16456298530101776, 0.1705992966890335, 0.17663557827472687, 0.18267188966274261]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 21.0, 9.0, 11.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.18979552388191223, -0.18441791832447052, -0.1790403127670288, -0.1736627072095871, -0.16828510165214539, -0.16290748119354248, -0.15752989053726196, -0.15215227007865906, -0.14677466452121735, -0.14139705896377563, -0.13601945340633392, -0.1306418478488922, -0.1252642422914505, -0.11988663673400879, -0.11450902372598648, -0.10913141816854477, -0.10375381261110306, -0.09837620705366135, -0.09299860149621964, -0.08762098848819733, -0.08224338293075562, -0.0768657773733139, -0.07148817181587219, -0.06611056625843048, -0.06073296070098877, -0.05535535514354706, -0.04997774958610535, -0.04460012912750244, -0.03922252357006073, -0.03384491801261902, -0.028467312455177307, -0.023089706897735596, -0.017712101340293884, -0.012334495782852173, -0.006956890225410461, -0.00157928466796875, 0.0037983208894729614, 0.009175926446914673, 0.014553546905517578, 0.01993115246295929, 0.025308758020401, 0.030686363577842712, 0.036063969135284424, 0.041441574692726135, 0.04681918025016785, 0.05219678580760956, 0.05757439136505127, 0.06295201182365417, 0.06832960247993469, 0.0737072229385376, 0.07908481359481812, 0.08446243405342102, 0.08984002470970154, 0.09521764516830444, 0.10059526562690735, 0.10597285628318787, 0.11135047674179077, 0.11672806739807129, 0.1221056878566742, 0.1274832785129547, 0.13286089897155762, 0.13823848962783813, 0.14361611008644104, 0.14899370074272156, 0.15437132120132446]}, "_runtime": 7946.996545553207, "_timestamp": 1585577862.841179, "_step": 298}
{"Episode reward": -99.77844146657596, "Episode length": 999, "Policy Loss": -0.45475679636001587, "Value Loss": 0.01484151091426611, "_runtime": 7948.113123893738, "_timestamp": 1585577863.9577572, "_step": 299}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": 0.6774346828460693, "Value Loss": 14.27489185333252, "_runtime": 7949.64354968071, "_timestamp": 1585577865.488183, "_step": 300}
{"Episode reward": -99.8747891370193, "Episode length": 999, "Policy Loss": -0.5605238080024719, "Value Loss": 0.1331460177898407, "_runtime": 7951.220893383026, "_timestamp": 1585577867.0655267, "_step": 301}
{"Episode reward": -99.80001730033987, "Episode length": 999, "Policy Loss": -0.3714694380760193, "Value Loss": 0.18098707497119904, "_runtime": 7952.781986713409, "_timestamp": 1585577868.62662, "_step": 302}
{"Episode reward": -99.8647669835526, "Episode length": 999, "Policy Loss": -0.22283333539962769, "Value Loss": 0.15447565913200378, "_runtime": 7954.366297245026, "_timestamp": 1585577870.2109306, "_step": 303}
{"Episode reward": -99.75194214330848, "Episode length": 999, "Policy Loss": -0.16155366599559784, "Value Loss": 0.12990215420722961, "_runtime": 7955.9565987586975, "_timestamp": 1585577871.801232, "_step": 304}
{"Episode reward": -99.81231995432032, "Episode length": 999, "Policy Loss": -0.1696285456418991, "Value Loss": 0.09282414615154266, "_runtime": 7957.528336048126, "_timestamp": 1585577873.3729694, "_step": 305}
{"Episode reward": -99.64002700781428, "Episode length": 999, "Policy Loss": -0.17262354493141174, "Value Loss": 0.08955751359462738, "_runtime": 7959.113225221634, "_timestamp": 1585577874.9578586, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22180531919002533, "Value Loss": 0.05919179692864418, "_runtime": 7960.698834896088, "_timestamp": 1585577876.5434682, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3102777600288391, "Value Loss": 0.04316422715783119, "_runtime": 7962.262529850006, "_timestamp": 1585577878.1071632, "_step": 308}
{"Episode reward": -99.83955998457829, "Episode length": 999, "Policy Loss": -0.32774704694747925, "Value Loss": 0.023948268964886665, "_runtime": 7963.842131137848, "_timestamp": 1585577879.6867645, "_step": 309}
{"Episode reward": -99.66959388212277, "Episode length": 999, "Policy Loss": -0.4367258548736572, "Value Loss": 0.005308215040713549, "_runtime": 7964.487220525742, "_timestamp": 1585577880.3318539, "_step": 310}
{"Episode reward": 61.66812462340432, "Episode length": 384, "Policy Loss": 2.2728264331817627, "Value Loss": 26.692461013793945, "_runtime": 7965.422095298767, "_timestamp": 1585577881.2667286, "_step": 311}
{"Episode reward": 41.428457973896904, "Episode length": 586, "Policy Loss": 1.2900840044021606, "Value Loss": 16.543899536132812, "_runtime": 7967.001619815826, "_timestamp": 1585577882.8462532, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19144956767559052, "Value Loss": 0.581855297088623, "_runtime": 7968.527623414993, "_timestamp": 1585577884.3722568, "_step": 313}
{"Episode reward": -99.67050510460838, "Episode length": 999, "Policy Loss": 0.171892449259758, "Value Loss": 0.1601763218641281, "_runtime": 7969.490949630737, "_timestamp": 1585577885.335583, "_step": 314}
{"Episode reward": 38.79999999999941, "Episode length": 612, "Policy Loss": 1.9279423952102661, "Value Loss": 16.397586822509766, "_runtime": 7971.059029817581, "_timestamp": 1585577886.9036632, "_step": 315}
{"Episode reward": -99.72215225715051, "Episode length": 999, "Policy Loss": -0.3695204257965088, "Value Loss": 0.020486198365688324, "_runtime": 7972.661682844162, "_timestamp": 1585577888.5063162, "_step": 316}
{"Episode reward": -99.74900133120688, "Episode length": 999, "Policy Loss": -0.7307777404785156, "Value Loss": 0.4769135117530823, "_runtime": 7974.196321964264, "_timestamp": 1585577890.0409553, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7656589150428772, "Value Loss": 0.377986878156662, "_runtime": 7975.775368452072, "_timestamp": 1585577891.6200018, "_step": 318}
{"Episode reward": -99.66363715996603, "Episode length": 999, "Policy Loss": -1.0745329856872559, "Value Loss": 1.7413262128829956, "_runtime": 7977.352676868439, "_timestamp": 1585577893.1973102, "_step": 319}
{"Episode reward": -99.8341039676438, "Episode length": 999, "Policy Loss": -0.7155513763427734, "Value Loss": 0.4275115728378296, "_runtime": 7978.9355437755585, "_timestamp": 1585577894.780177, "_step": 320}
{"Episode reward": -99.72382614277745, "Episode length": 999, "Policy Loss": -0.19871704280376434, "Value Loss": 0.03236427530646324, "_runtime": 7980.515084266663, "_timestamp": 1585577896.3597176, "_step": 321}
{"Episode reward": -99.8869675206996, "Episode length": 999, "Policy Loss": -0.0302374716848135, "Value Loss": 0.4338749945163727, "_runtime": 7981.263917922974, "_timestamp": 1585577897.1085513, "_step": 322}
{"Episode reward": 54.22170418414716, "Episode length": 460, "Policy Loss": 1.8979994058609009, "Value Loss": 23.808666229248047, "_runtime": 7982.834926128387, "_timestamp": 1585577898.6795595, "_step": 323}
{"Episode reward": -99.80547147889015, "Episode length": 999, "Policy Loss": 0.1899133324623108, "Value Loss": 0.1509036123752594, "_runtime": 7984.425132751465, "_timestamp": 1585577900.269766, "_step": 324}
{"Episode reward": -99.85043479064339, "Episode length": 999, "Policy Loss": -0.10936647653579712, "Value Loss": 0.08919217437505722, "_runtime": 7985.95227432251, "_timestamp": 1585577901.7969077, "_step": 325}
{"Episode reward": -99.83676440647584, "Episode length": 999, "Policy Loss": -0.5979613065719604, "Value Loss": 0.26126939058303833, "_runtime": 7987.533735275269, "_timestamp": 1585577903.3783686, "_step": 326}
{"Episode reward": -99.80016486553801, "Episode length": 999, "Policy Loss": -0.5898993015289307, "Value Loss": 0.07254993915557861, "_runtime": 7989.112579345703, "_timestamp": 1585577904.9572127, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6815853714942932, "Value Loss": 0.18049567937850952, "_runtime": 7990.68843960762, "_timestamp": 1585577906.533073, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8010931611061096, "Value Loss": 0.6332047581672668, "_runtime": 7991.82337641716, "_timestamp": 1585577907.6680098, "_step": 329}
{"Episode reward": 28.99075927576027, "Episode length": 711, "Policy Loss": 0.7975348830223083, "Value Loss": 15.689001083374023, "_runtime": 7993.412353754044, "_timestamp": 1585577909.256987, "_step": 330}
{"Episode reward": -99.88284607845131, "Episode length": 999, "Policy Loss": 0.14096154272556305, "Value Loss": 0.19726768136024475, "_runtime": 7994.382807970047, "_timestamp": 1585577910.2274413, "_step": 331}
{"Episode reward": 39.797128281276095, "Episode length": 604, "Policy Loss": 1.6904300451278687, "Value Loss": 17.83334732055664, "_runtime": 7995.975766181946, "_timestamp": 1585577911.8203995, "_step": 332}
{"Episode reward": -99.70352993932326, "Episode length": 999, "Policy Loss": 0.6668909788131714, "Value Loss": 4.994956016540527, "_runtime": 7996.899308919907, "_timestamp": 1585577912.7439423, "_step": 333}
{"Episode reward": 42.69999999999946, "Episode length": 573, "Policy Loss": 1.463834524154663, "Value Loss": 17.55074119567871, "_runtime": 7998.452912092209, "_timestamp": 1585577914.2975454, "_step": 334}
{"Episode reward": -99.78776172119984, "Episode length": 999, "Policy Loss": -0.5635032653808594, "Value Loss": 0.28253334760665894, "_runtime": 8000.036901950836, "_timestamp": 1585577915.8815353, "_step": 335}
{"Episode reward": -99.60507238496072, "Episode length": 999, "Policy Loss": -1.0509883165359497, "Value Loss": 1.6792482137680054, "_runtime": 8000.880449771881, "_timestamp": 1585577916.725083, "_step": 336}
{"Episode reward": 46.299999999999514, "Episode length": 537, "Policy Loss": 0.40516144037246704, "Value Loss": 24.879928588867188, "_runtime": 8002.4563908576965, "_timestamp": 1585577918.3010242, "_step": 337}
{"Episode reward": -99.8112526178346, "Episode length": 999, "Policy Loss": -0.9244707822799683, "Value Loss": 0.19189408421516418, "_runtime": 8004.041291952133, "_timestamp": 1585577919.8859253, "_step": 338}
{"Episode reward": -99.72401721100765, "Episode length": 999, "Policy Loss": -0.3074360489845276, "Value Loss": 0.07414592802524567, "_runtime": 8005.531545162201, "_timestamp": 1585577921.3761785, "_step": 339}
{"Episode reward": 3.400040740165906, "Episode length": 968, "Policy Loss": 1.1014515161514282, "Value Loss": 10.628724098205566, "_runtime": 8007.134325742722, "_timestamp": 1585577922.978959, "_step": 340}
{"Episode reward": -99.6885792095171, "Episode length": 999, "Policy Loss": 0.334212064743042, "Value Loss": 1.110927939414978, "_runtime": 8008.715040206909, "_timestamp": 1585577924.5596735, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37191274762153625, "Value Loss": 1.5703682899475098, "_runtime": 8010.268441915512, "_timestamp": 1585577926.1130753, "_step": 342}
{"Episode reward": -99.74616527706246, "Episode length": 999, "Policy Loss": 0.26818159222602844, "Value Loss": 0.4123225510120392, "_runtime": 8011.835400819778, "_timestamp": 1585577927.6800342, "_step": 343}
{"Episode reward": -99.63148975647498, "Episode length": 999, "Policy Loss": -0.20258475840091705, "Value Loss": 0.005561728496104479, "_runtime": 8013.401512622833, "_timestamp": 1585577929.246146, "_step": 344}
{"Episode reward": -99.74731402406329, "Episode length": 999, "Policy Loss": -0.6089418530464172, "Value Loss": 0.22350864112377167, "_runtime": 8014.684543609619, "_timestamp": 1585577930.529177, "_step": 345}
{"Episode reward": 18.815935598314155, "Episode length": 813, "Policy Loss": 0.7060883045196533, "Value Loss": 12.717168807983398, "_runtime": 8016.257258653641, "_timestamp": 1585577932.101892, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7941032648086548, "Value Loss": 0.17270655930042267, "_runtime": 8017.825683832169, "_timestamp": 1585577933.6703172, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9992141127586365, "Value Loss": 1.0397313833236694, "_runtime": 8019.4247217178345, "_timestamp": 1585577935.269355, "_step": 348}
{"Episode reward": -99.80549104433018, "Episode length": 999, "Policy Loss": -0.5772273540496826, "Value Loss": 0.11995796114206314, "_runtime": 8020.682110548019, "_timestamp": 1585577936.526744, "_step": 349}
{"Episode reward": 20.4759248098361, "Episode length": 798, "Policy Loss": 0.7347925305366516, "Value Loss": 11.952445983886719, "_runtime": 8022.254449367523, "_timestamp": 1585577938.0990827, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16047237813472748, "Value Loss": 0.1717986762523651, "_runtime": 8023.829281330109, "_timestamp": 1585577939.6739147, "_step": 351}
{"Episode reward": -99.79507416272979, "Episode length": 999, "Policy Loss": 0.3096742033958435, "Value Loss": 0.23157243430614471, "_runtime": 8024.986443042755, "_timestamp": 1585577940.8310764, "_step": 352}
{"Episode reward": 25.699999999999946, "Episode length": 743, "Policy Loss": 1.3538923263549805, "Value Loss": 13.942644119262695, "_runtime": 8026.547011613846, "_timestamp": 1585577942.391645, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03611888363957405, "Value Loss": 0.015933405607938766, "_runtime": 8028.1113612651825, "_timestamp": 1585577943.9559946, "_step": 354}
{"Episode reward": -99.88526410034252, "Episode length": 999, "Policy Loss": -0.2381315380334854, "Value Loss": 0.014659078791737556, "_runtime": 8029.658217191696, "_timestamp": 1585577945.5028505, "_step": 355}
{"Episode reward": -99.67483161799471, "Episode length": 999, "Policy Loss": -0.2285824865102768, "Value Loss": 0.7651771903038025, "_runtime": 8030.691009283066, "_timestamp": 1585577946.5356426, "_step": 356}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.836189329624176, "Value Loss": 14.798360824584961, "_runtime": 8032.261871814728, "_timestamp": 1585577948.1065052, "_step": 357}
{"Episode reward": -99.80015217094193, "Episode length": 999, "Policy Loss": -0.39024144411087036, "Value Loss": 0.49436309933662415, "_runtime": 8033.83225107193, "_timestamp": 1585577949.6768844, "_step": 358}
{"Episode reward": -99.73617137493426, "Episode length": 999, "Policy Loss": -0.0028055415023118258, "Value Loss": 0.020535562187433243, "_runtime": 8034.501271486282, "_timestamp": 1585577950.3459048, "_step": 359}
{"Episode reward": 57.62694323304863, "Episode length": 424, "Policy Loss": 2.42252779006958, "Value Loss": 22.542949676513672, "_runtime": 8036.073435544968, "_timestamp": 1585577951.918069, "_step": 360}
{"Episode reward": -99.83386538112396, "Episode length": 999, "Policy Loss": 0.40273332595825195, "Value Loss": 0.26643678545951843, "_runtime": 8036.743199825287, "_timestamp": 1585577952.5878332, "_step": 361}
{"Episode reward": 58.59999999999969, "Episode length": 414, "Policy Loss": 2.2689433097839355, "Value Loss": 24.4505672454834, "_runtime": 8038.282540798187, "_timestamp": 1585577954.1271741, "_step": 362}
{"Episode reward": -99.7095312625156, "Episode length": 999, "Policy Loss": -0.14875881373882294, "Value Loss": 0.1992957592010498, "_runtime": 8039.86211681366, "_timestamp": 1585577955.7067502, "_step": 363}
{"Episode reward": -99.80051366651756, "Episode length": 999, "Policy Loss": -0.5841650366783142, "Value Loss": 0.1252106875181198, "_runtime": 8041.376197099686, "_timestamp": 1585577957.2208304, "_step": 364}
{"Episode reward": -99.68405121677067, "Episode length": 999, "Policy Loss": -0.809716522693634, "Value Loss": 0.1583506166934967, "_runtime": 8042.990106344223, "_timestamp": 1585577958.8347397, "_step": 365}
{"Episode reward": -99.67960695035732, "Episode length": 999, "Policy Loss": -0.8673089742660522, "Value Loss": 1.2002629041671753, "_runtime": 8043.887445449829, "_timestamp": 1585577959.7320788, "_step": 366}
{"Episode reward": 44.698279586061325, "Episode length": 554, "Policy Loss": 0.6719223856925964, "Value Loss": 20.077714920043945, "_runtime": 8044.656910657883, "_timestamp": 1585577960.501544, "_step": 367}
{"Episode reward": 52.3999999999996, "Episode length": 476, "Policy Loss": 1.3896743059158325, "Value Loss": 20.24327850341797, "_runtime": 8046.235356330872, "_timestamp": 1585577962.0799897, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27158284187316895, "Value Loss": 0.466936320066452, "_runtime": 8047.779349088669, "_timestamp": 1585577963.6239824, "_step": 369}
{"Episode reward": -99.75249011702697, "Episode length": 999, "Policy Loss": 0.7739124298095703, "Value Loss": 0.7969464659690857, "_runtime": 8049.319367170334, "_timestamp": 1585577965.1640005, "_step": 370}
{"Episode reward": -99.81397109627584, "Episode length": 999, "Policy Loss": 1.0442270040512085, "Value Loss": 0.43429580330848694, "_runtime": 8050.306345701218, "_timestamp": 1585577966.150979, "_step": 371}
{"Episode reward": 38.13652820251822, "Episode length": 619, "Policy Loss": 1.880896806716919, "Value Loss": 20.1463623046875, "_runtime": 8051.782845258713, "_timestamp": 1585577967.6274786, "_step": 372}
{"Episode reward": 5.89425291267797, "Episode length": 942, "Policy Loss": 1.4574384689331055, "Value Loss": 13.348151206970215, "_runtime": 8053.347282886505, "_timestamp": 1585577969.1919162, "_step": 373}
{"Episode reward": -99.89641935825207, "Episode length": 999, "Policy Loss": -0.02758794091641903, "Value Loss": 0.3018377125263214, "_runtime": 8054.830065488815, "_timestamp": 1585577970.6746988, "_step": 374}
{"Episode reward": 3.6000000000012022, "Episode length": 964, "Policy Loss": 0.358003705739975, "Value Loss": 10.333247184753418, "_runtime": 8056.401296377182, "_timestamp": 1585577972.2459297, "_step": 375}
{"Episode reward": -99.84776206947723, "Episode length": 999, "Policy Loss": -1.0356457233428955, "Value Loss": 1.361940622329712, "_runtime": 8057.971221923828, "_timestamp": 1585577973.8158553, "_step": 376}
{"Episode reward": -99.82867189384858, "Episode length": 999, "Policy Loss": -1.3340567350387573, "Value Loss": 4.410120010375977, "_runtime": 8058.380829811096, "_timestamp": 1585577974.2254632, "_step": 377}
{"Episode reward": 76.39999999999995, "Episode length": 236, "Policy Loss": 2.078596353530884, "Value Loss": 45.65460968017578, "_runtime": 8059.960385322571, "_timestamp": 1585577975.8050187, "_step": 378}
{"Episode reward": -99.8489205644452, "Episode length": 999, "Policy Loss": -0.19265764951705933, "Value Loss": 0.019923601299524307, "_runtime": 8061.530061244965, "_timestamp": 1585577977.3746946, "_step": 379}
{"Episode reward": -99.68235717092037, "Episode length": 999, "Policy Loss": 0.575206995010376, "Value Loss": 0.8938145637512207, "_runtime": 8063.02551651001, "_timestamp": 1585577978.8701499, "_step": 380}
{"Episode reward": -99.76148843839626, "Episode length": 999, "Policy Loss": 1.2532095909118652, "Value Loss": 2.8626792430877686, "_runtime": 8064.600450515747, "_timestamp": 1585577980.4450839, "_step": 381}
{"Episode reward": -99.86263455893355, "Episode length": 999, "Policy Loss": 2.582315683364868, "Value Loss": 10.107001304626465, "_runtime": 8066.201182126999, "_timestamp": 1585577982.0458155, "_step": 382}
{"Episode reward": -99.6413108488822, "Episode length": 999, "Policy Loss": 1.9688888788223267, "Value Loss": 5.1671247482299805, "_runtime": 8067.500241994858, "_timestamp": 1585577983.3448753, "_step": 383}
{"Episode reward": 16.020543067314364, "Episode length": 841, "Policy Loss": 1.9854859113693237, "Value Loss": 16.8546142578125, "_runtime": 8067.902950763702, "_timestamp": 1585577983.747584, "_step": 384}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 3.5693352222442627, "Value Loss": 42.47019958496094, "_runtime": 8069.025144100189, "_timestamp": 1585577984.8697774, "_step": 385}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": 0.0688275620341301, "Value Loss": 14.364850044250488, "_runtime": 8070.574978113174, "_timestamp": 1585577986.4196115, "_step": 386}
{"Episode reward": -99.8449032136458, "Episode length": 999, "Policy Loss": -2.0475454330444336, "Value Loss": 0.5332364439964294, "_runtime": 8072.070272445679, "_timestamp": 1585577987.9149058, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0564825534820557, "Value Loss": 2.5961713790893555, "_runtime": 8073.618288755417, "_timestamp": 1585577989.462922, "_step": 388}
{"Episode reward": -99.85593915134528, "Episode length": 999, "Policy Loss": -3.171297073364258, "Value Loss": 6.587521553039551, "_runtime": 8074.709179878235, "_timestamp": 1585577990.5538132, "_step": 389}
{"Episode reward": 30.36025994382767, "Episode length": 698, "Policy Loss": -2.6686313152313232, "Value Loss": 31.491701126098633, "_runtime": 8075.4882555007935, "_timestamp": 1585577991.3328888, "_step": 390}
{"Episode reward": 50.399999986588526, "Episode length": 497, "Policy Loss": -1.961357831954956, "Value Loss": 44.111732482910156, "_runtime": 8077.068587779999, "_timestamp": 1585577992.9132211, "_step": 391}
{"Episode reward": -99.80940659083286, "Episode length": 999, "Policy Loss": -1.8325203657150269, "Value Loss": 5.847322940826416, "_runtime": 8077.7306344509125, "_timestamp": 1585577993.5752678, "_step": 392}
{"Episode reward": 59.03206382987525, "Episode length": 410, "Policy Loss": 1.8789832592010498, "Value Loss": 22.852336883544922, "_runtime": 8079.269046783447, "_timestamp": 1585577995.1136801, "_step": 393}
{"Episode reward": -99.64208311182308, "Episode length": 999, "Policy Loss": 1.3575040102005005, "Value Loss": 0.5048304200172424, "_runtime": 8080.854730606079, "_timestamp": 1585577996.699364, "_step": 394}
{"Episode reward": -99.6863193916667, "Episode length": 999, "Policy Loss": 2.5710930824279785, "Value Loss": 1.5162702798843384, "_runtime": 8082.110760688782, "_timestamp": 1585577997.955394, "_step": 395}
{"Episode reward": 17.400000000000418, "Episode length": 826, "Policy Loss": 4.429571628570557, "Value Loss": 18.299474716186523, "_runtime": 8083.046657085419, "_timestamp": 1585577998.8912904, "_step": 396}
{"Episode reward": 41.217343437298574, "Episode length": 588, "Policy Loss": 5.645592212677002, "Value Loss": 22.2167911529541, "_runtime": 8084.630126953125, "_timestamp": 1585578000.4747603, "_step": 397}
{"Episode reward": -99.82680450910563, "Episode length": 999, "Policy Loss": 5.014476299285889, "Value Loss": 1.4146555662155151, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122, 0.11131353676319122]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11131353676319122, 0.06354297697544098, 0.23839949071407318, 0.4132559895515442, 0.5881125330924988, 0.7629690766334534, 0.9378255009651184, 1.1126819849014282, 1.2875385284423828, 1.4623950719833374, 1.637251615524292, 1.812108039855957, 1.986964464187622, 2.161821126937866, 2.3366775512695312, 2.5115342140197754, 2.6863906383514404, 2.8612470626831055, 3.0361037254333496, 3.2109601497650146, 3.385816812515259, 3.560673236846924, 3.735529661178589, 3.910386323928833, 4.085242748260498, 4.260099411010742, 4.434956073760986, 4.6098127365112305, 4.784668922424316, 4.9595255851745605, 5.134382247924805, 5.309238433837891, 5.484095096588135, 5.658951759338379, 5.833807945251465, 6.008664608001709, 6.183521270751953, 6.358377456665039, 6.533234119415283, 6.708090782165527, 6.8829474449157715, 7.057803630828857, 7.232660293579102, 7.407516956329346, 7.582373142242432, 7.757229804992676, 7.93208646774292, 8.106942176818848, 8.281798362731934, 8.456655502319336, 8.631511688232422, 8.806368827819824, 8.98122501373291, 9.156081199645996, 9.330938339233398, 9.505794525146484, 9.68065071105957, 9.855507850646973, 10.030364036560059, 10.205220222473145, 10.380077362060547, 10.554933547973633, 10.729789733886719, 10.904646873474121, 11.079503059387207]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4306500554084778, -0.4048228859901428, -0.37899571657180786, -0.3531685471534729, -0.32734137773513794, -0.301514208316803, -0.27568700909614563, -0.24985983967781067, -0.2240326702594757, -0.19820550084114075, -0.1723783314228058, -0.14655116200447083, -0.12072396278381348, -0.09489679336547852, -0.06906962394714355, -0.043242454528808594, -0.017415285110473633, 0.008411884307861328, 0.03423905372619629, 0.06006622314453125, 0.08589339256286621, 0.11172056198120117, 0.13754773139953613, 0.1633749008178711, 0.18920212984085083, 0.2150292992591858, 0.24085646867752075, 0.2666836380958557, 0.2925108075141907, 0.31833797693252563, 0.3441651463508606, 0.36999231576919556, 0.3958194851875305, 0.4216466546058655, 0.44747382402420044, 0.4733009934425354, 0.49912816286087036, 0.5249553322792053, 0.5507825016975403, 0.5766096711158752, 0.6024368405342102, 0.6282640099525452, 0.6540911793708801, 0.6799183487892151, 0.70574551820755, 0.731572687625885, 0.75739985704422, 0.7832270264625549, 0.8090543150901794, 0.8348814845085144, 0.8607086539268494, 0.8865358233451843, 0.9123629927635193, 0.9381901621818542, 0.9640173316001892, 0.9898445010185242, 1.015671730041504, 1.0414988994598389, 1.0673260688781738, 1.0931532382965088, 1.1189804077148438, 1.1448075771331787, 1.1706347465515137, 1.1964619159698486, 1.2222890853881836]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 17.0, 3.0, 7.0, 15.0, 2.0, 0.0, 10.0, 5.0, 83.0, 44.0, 177.0, 16.0, 9.0, 24.0, 25.0, 24.0, 3.0, 6.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2983311414718628, -1.1847084760665894, -1.0710859298706055, -0.957463264465332, -0.8438405990600586, -0.7302179336547852, -0.6165953278541565, -0.5029727220535278, -0.3893500566482544, -0.27572739124298096, -0.16210472583770752, -0.04848217964172363, 0.0651404857635498, 0.17876315116882324, 0.29238569736480713, 0.40600836277008057, 0.519631028175354, 0.6332536935806274, 0.7468763589859009, 0.8604990243911743, 0.9741216897964478, 1.087744116783142, 1.2013667821884155, 1.314989447593689, 1.4286121129989624, 1.5422347784042358, 1.6558574438095093, 1.7694801092147827, 1.883102536201477, 1.9967252016067505, 2.1103477478027344, 2.223970413208008, 2.3375930786132812, 2.4512157440185547, 2.564838409423828, 2.6784610748291016, 2.792083740234375, 2.9057064056396484, 3.019329071044922, 3.1329517364501953, 3.2465744018554688, 3.360196590423584, 3.4738192558288574, 3.587441921234131, 3.7010645866394043, 3.8146872520446777, 3.928309917449951, 4.041932582855225, 4.155555248260498, 4.2691779136657715, 4.382800579071045, 4.496423244476318, 4.610045909881592, 4.723668575286865, 4.837291240692139, 4.950913906097412, 5.064536094665527, 5.178158760070801, 5.291781425476074, 5.405404090881348, 5.519026756286621, 5.6326494216918945, 5.746272087097168, 5.859894752502441, 5.973517417907715]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-6.700852394104004, -6.488456726074219, -6.276061058044434, -6.063665866851807, -5.8512701988220215, -5.638874530792236, -5.426479339599609, -5.214083671569824, -5.001688003540039, -4.789292335510254, -4.576896667480469, -4.364501476287842, -4.152105808258057, -3.9397101402282715, -3.7273147106170654, -3.5149192810058594, -3.302523612976074, -3.090127944946289, -2.877732515335083, -2.665337085723877, -2.452941417694092, -2.2405457496643066, -2.0281505584716797, -1.8157548904418945, -1.6033592224121094, -1.3909635543823242, -1.178567886352539, -0.9661726951599121, -0.753777027130127, -0.5413813591003418, -0.32898616790771484, -0.11659049987792969, 0.09580516815185547, 0.3082008361816406, 0.5205965042114258, 0.7329916954040527, 0.9453873634338379, 1.157783031463623, 1.37017822265625, 1.5825738906860352, 1.7949695587158203, 2.0073652267456055, 2.2197608947753906, 2.432156562805176, 2.6445512771606445, 2.8569469451904297, 3.069342613220215, 3.28173828125, 3.494133949279785, 3.7065296173095703, 3.9189252853393555, 4.131320953369141, 4.343716621398926, 4.5561113357543945, 4.76850700378418, 4.980902671813965, 5.19329833984375, 5.405694007873535, 5.61808967590332, 5.8304853439331055, 6.042880058288574, 6.255275726318359, 6.4676713943481445, 6.68006706237793, 6.892462730407715]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 1.0, 2.0, 6.0, 2.0, 0.0, 1.0, 8.0, 9.0, 4.0, 5.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0], "bins": [-4.5729827880859375, -4.438255310058594, -4.303527355194092, -4.168799877166748, -4.034071922302246, -3.8993444442749023, -3.7646169662475586, -3.6298892498016357, -3.495161533355713, -3.36043381690979, -3.225706100463867, -3.0909786224365234, -2.9562509059906006, -2.8215231895446777, -2.686795711517334, -2.552067995071411, -2.4173402786254883, -2.2826125621795654, -2.1478848457336426, -2.013157367706299, -1.878429651260376, -1.7437019348144531, -1.6089744567871094, -1.4742467403411865, -1.3395190238952637, -1.2047913074493408, -1.070063591003418, -0.9353361129760742, -0.8006083965301514, -0.6658806800842285, -0.5311532020568848, -0.3964252471923828, -0.26169776916503906, -0.1269702911376953, 0.007757663726806641, 0.1424851417541504, 0.27721309661865234, 0.4119405746459961, 0.5466680526733398, 0.6813960075378418, 0.8161234855651855, 0.9508509635925293, 1.0855789184570312, 1.220306396484375, 1.3550338745117188, 1.4897618293762207, 1.6244893074035645, 1.7592172622680664, 1.8939447402954102, 2.028672218322754, 2.163400173187256, 2.2981276512145996, 2.4328556060791016, 2.5675830841064453, 2.702310562133789, 2.837038516998291, 2.9717659950256348, 3.1064934730529785, 3.2412214279174805, 3.375948905944824, 3.510676383972168, 3.6454038619995117, 3.780132293701172, 3.9148597717285156, 4.049587249755859]}, "_runtime": 8085.805139780045, "_timestamp": 1585578001.6497731, "_step": 398}
{"Episode reward": 24.72250406143722, "Episode length": 754, "Policy Loss": 6.510295867919922, "Value Loss": 13.821508407592773, "_runtime": 8086.615678787231, "_timestamp": 1585578002.4603121, "_step": 399}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 7.526576519012451, "Value Loss": 19.457347869873047, "_runtime": 8088.194005250931, "_timestamp": 1585578004.0386386, "_step": 400}
{"Episode reward": -99.88556588748331, "Episode length": 999, "Policy Loss": 5.995934009552002, "Value Loss": 1.0928922891616821, "_runtime": 8089.747002840042, "_timestamp": 1585578005.5916362, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.939367771148682, "Value Loss": 1.8063609600067139, "_runtime": 8091.3131449222565, "_timestamp": 1585578007.1577783, "_step": 402}
{"Episode reward": -99.85423139417404, "Episode length": 999, "Policy Loss": 5.932143688201904, "Value Loss": 3.649871349334717, "_runtime": 8092.89866065979, "_timestamp": 1585578008.743294, "_step": 403}
{"Episode reward": -99.80432418621936, "Episode length": 999, "Policy Loss": 6.815726280212402, "Value Loss": 9.121451377868652, "_runtime": 8093.544777393341, "_timestamp": 1585578009.3894107, "_step": 404}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 8.464341163635254, "Value Loss": 35.358123779296875, "_runtime": 8095.095044136047, "_timestamp": 1585578010.9396775, "_step": 405}
{"Episode reward": -99.86314884500904, "Episode length": 999, "Policy Loss": 5.404674530029297, "Value Loss": 0.9701496362686157, "_runtime": 8096.693262338638, "_timestamp": 1585578012.5378957, "_step": 406}
{"Episode reward": -99.86200336898187, "Episode length": 999, "Policy Loss": 4.7693681716918945, "Value Loss": 0.9232383966445923, "_runtime": 8098.215817689896, "_timestamp": 1585578014.060451, "_step": 407}
{"Episode reward": -99.80104954922432, "Episode length": 999, "Policy Loss": 4.748188018798828, "Value Loss": 1.0619319677352905, "_runtime": 8098.715379953384, "_timestamp": 1585578014.5600133, "_step": 408}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 7.182030200958252, "Value Loss": 34.09312057495117, "_runtime": 8100.282415151596, "_timestamp": 1585578016.1270485, "_step": 409}
{"Episode reward": -99.81637645626766, "Episode length": 999, "Policy Loss": 3.5402166843414307, "Value Loss": 0.5029451847076416, "_runtime": 8101.847209692001, "_timestamp": 1585578017.691843, "_step": 410}
{"Episode reward": -99.85655023476436, "Episode length": 999, "Policy Loss": 3.3585145473480225, "Value Loss": 0.8009927868843079, "_runtime": 8103.358516931534, "_timestamp": 1585578019.2031503, "_step": 411}
{"Episode reward": -99.6935259450446, "Episode length": 999, "Policy Loss": 2.467442274093628, "Value Loss": 0.5114864110946655, "_runtime": 8104.946202516556, "_timestamp": 1585578020.7908359, "_step": 412}
{"Episode reward": -99.62561133124261, "Episode length": 999, "Policy Loss": 2.2248101234436035, "Value Loss": 0.302703857421875, "_runtime": 8105.665016651154, "_timestamp": 1585578021.50965, "_step": 413}
{"Episode reward": 55.48559869243728, "Episode length": 446, "Policy Loss": 3.560697078704834, "Value Loss": 25.66900634765625, "_runtime": 8107.22861123085, "_timestamp": 1585578023.0732446, "_step": 414}
{"Episode reward": -99.8139357574503, "Episode length": 999, "Policy Loss": 1.388649344444275, "Value Loss": 1.099226951599121, "_runtime": 8107.5133402347565, "_timestamp": 1585578023.3579736, "_step": 415}
{"Episode reward": 86.7998450186104, "Episode length": 133, "Policy Loss": 7.616875171661377, "Value Loss": 74.0050048828125, "_runtime": 8109.06311917305, "_timestamp": 1585578024.9077525, "_step": 416}
{"Episode reward": -99.57501071643063, "Episode length": 999, "Policy Loss": 0.9227652549743652, "Value Loss": 0.9229350686073303, "_runtime": 8110.6356835365295, "_timestamp": 1585578026.4803169, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23683421313762665, "Value Loss": 0.37698325514793396, "_runtime": 8112.129858016968, "_timestamp": 1585578027.9744914, "_step": 418}
{"Episode reward": -99.52903983228614, "Episode length": 999, "Policy Loss": -0.014821173623204231, "Value Loss": 1.412739634513855, "_runtime": 8113.355904579163, "_timestamp": 1585578029.200538, "_step": 419}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": 0.8683995008468628, "Value Loss": 13.928285598754883, "_runtime": 8114.959021568298, "_timestamp": 1585578030.803655, "_step": 420}
{"Episode reward": -99.88327648579585, "Episode length": 999, "Policy Loss": -0.5828421711921692, "Value Loss": 0.3079456388950348, "_runtime": 8116.507709741592, "_timestamp": 1585578032.352343, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0062180757522583, "Value Loss": 0.6439334750175476, "_runtime": 8118.071003913879, "_timestamp": 1585578033.9156373, "_step": 422}
{"Episode reward": -99.718465038504, "Episode length": 999, "Policy Loss": -1.0452121496200562, "Value Loss": 0.9950974583625793, "_runtime": 8119.640341758728, "_timestamp": 1585578035.484975, "_step": 423}
{"Episode reward": -99.70662595492183, "Episode length": 999, "Policy Loss": -1.313068151473999, "Value Loss": 0.21371932327747345, "_runtime": 8120.3836443424225, "_timestamp": 1585578036.2282777, "_step": 424}
{"Episode reward": 53.79999999999962, "Episode length": 462, "Policy Loss": 0.5322855114936829, "Value Loss": 20.9782657623291, "_runtime": 8121.293750762939, "_timestamp": 1585578037.138384, "_step": 425}
{"Episode reward": 43.164263844466234, "Episode length": 570, "Policy Loss": -0.06408447027206421, "Value Loss": 17.42198371887207, "_runtime": 8122.855589866638, "_timestamp": 1585578038.7002232, "_step": 426}
{"Episode reward": -99.64328747615079, "Episode length": 999, "Policy Loss": -1.6500455141067505, "Value Loss": 0.1787811815738678, "_runtime": 8123.679184913635, "_timestamp": 1585578039.5238183, "_step": 427}
{"Episode reward": 46.568084120749944, "Episode length": 535, "Policy Loss": -0.43403610587120056, "Value Loss": 17.645030975341797, "_runtime": 8124.805511713028, "_timestamp": 1585578040.650145, "_step": 428}
{"Episode reward": 27.207519096135954, "Episode length": 728, "Policy Loss": -0.7205276489257812, "Value Loss": 13.68154239654541, "_runtime": 8126.364130973816, "_timestamp": 1585578042.2087643, "_step": 429}
{"Episode reward": -99.6814666804378, "Episode length": 999, "Policy Loss": -2.0013461112976074, "Value Loss": 0.2186700850725174, "_runtime": 8127.886404752731, "_timestamp": 1585578043.731038, "_step": 430}
{"Episode reward": -99.73784684866993, "Episode length": 999, "Policy Loss": -1.9501407146453857, "Value Loss": 0.10098505020141602, "_runtime": 8129.431989908218, "_timestamp": 1585578045.2766232, "_step": 431}
{"Episode reward": -99.79476589239209, "Episode length": 999, "Policy Loss": -2.138770341873169, "Value Loss": 0.14839091897010803, "_runtime": 8130.999404430389, "_timestamp": 1585578046.8440378, "_step": 432}
{"Episode reward": -99.77432278268832, "Episode length": 999, "Policy Loss": -2.09567928314209, "Value Loss": 0.1054774597287178, "_runtime": 8132.526612520218, "_timestamp": 1585578048.3712459, "_step": 433}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": -1.456205129623413, "Value Loss": 9.869474411010742, "_runtime": 8134.097456932068, "_timestamp": 1585578049.9420903, "_step": 434}
{"Episode reward": -99.65039670817647, "Episode length": 999, "Policy Loss": -2.0936262607574463, "Value Loss": 0.162514328956604, "_runtime": 8135.377969264984, "_timestamp": 1585578051.2226026, "_step": 435}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": -1.4374291896820068, "Value Loss": 12.210623741149902, "_runtime": 8135.86542224884, "_timestamp": 1585578051.7100556, "_step": 436}
{"Episode reward": 71.39999999999986, "Episode length": 286, "Policy Loss": 0.40125685930252075, "Value Loss": 34.17610549926758, "_runtime": 8136.896438837051, "_timestamp": 1585578052.7410722, "_step": 437}
{"Episode reward": 33.89999999999948, "Episode length": 661, "Policy Loss": -1.1160801649093628, "Value Loss": 15.043630599975586, "_runtime": 8138.463197469711, "_timestamp": 1585578054.3078308, "_step": 438}
{"Episode reward": -99.68728162089688, "Episode length": 999, "Policy Loss": -2.257436990737915, "Value Loss": 0.15074361860752106, "_runtime": 8139.962330341339, "_timestamp": 1585578055.8069637, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3781518936157227, "Value Loss": 0.13900163769721985, "_runtime": 8141.500295639038, "_timestamp": 1585578057.344929, "_step": 440}
{"Episode reward": -99.7557494371417, "Episode length": 999, "Policy Loss": -2.366870880126953, "Value Loss": 0.12594462931156158, "_runtime": 8143.054006099701, "_timestamp": 1585578058.8986394, "_step": 441}
{"Episode reward": -99.7906543325808, "Episode length": 999, "Policy Loss": -2.446869134902954, "Value Loss": 0.14412428438663483, "_runtime": 8144.596329689026, "_timestamp": 1585578060.440963, "_step": 442}
{"Episode reward": -99.64620655116022, "Episode length": 999, "Policy Loss": -2.4173405170440674, "Value Loss": 0.12029435485601425, "_runtime": 8145.365450382233, "_timestamp": 1585578061.2100837, "_step": 443}
{"Episode reward": 52.296582105382875, "Episode length": 478, "Policy Loss": -0.6740543842315674, "Value Loss": 20.07904815673828, "_runtime": 8146.938796520233, "_timestamp": 1585578062.7834299, "_step": 444}
{"Episode reward": -99.71698439195613, "Episode length": 999, "Policy Loss": -2.3388121128082275, "Value Loss": 0.11102098226547241, "_runtime": 8147.329479932785, "_timestamp": 1585578063.1741133, "_step": 445}
{"Episode reward": 77.99999999999997, "Episode length": 220, "Policy Loss": 1.290502905845642, "Value Loss": 43.08208084106445, "_runtime": 8148.8393676280975, "_timestamp": 1585578064.684001, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.371377468109131, "Value Loss": 0.11635507643222809, "_runtime": 8149.51189994812, "_timestamp": 1585578065.3565333, "_step": 447}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": -0.31830137968063354, "Value Loss": 23.72385025024414, "_runtime": 8151.012316942215, "_timestamp": 1585578066.8569503, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.29484224319458, "Value Loss": 0.12367407977581024, "_runtime": 8152.5646460056305, "_timestamp": 1585578068.4092793, "_step": 449}
{"Episode reward": -99.82833950668434, "Episode length": 999, "Policy Loss": -2.283945083618164, "Value Loss": 0.2132573425769806, "_runtime": 8154.063115596771, "_timestamp": 1585578069.907749, "_step": 450}
{"Episode reward": -99.8497278191368, "Episode length": 999, "Policy Loss": -2.128312587738037, "Value Loss": 0.12000551074743271, "_runtime": 8155.119251728058, "_timestamp": 1585578070.963885, "_step": 451}
{"Episode reward": 33.37709935894188, "Episode length": 667, "Policy Loss": -0.7373817563056946, "Value Loss": 14.569302558898926, "_runtime": 8156.433103084564, "_timestamp": 1585578072.2777364, "_step": 452}
{"Episode reward": 16.510900226950767, "Episode length": 836, "Policy Loss": -0.9934300780296326, "Value Loss": 11.787850379943848, "_runtime": 8157.991626262665, "_timestamp": 1585578073.8362596, "_step": 453}
{"Episode reward": -99.61077404132091, "Episode length": 999, "Policy Loss": -1.801628589630127, "Value Loss": 0.08719614148139954, "_runtime": 8159.515760183334, "_timestamp": 1585578075.3603935, "_step": 454}
{"Episode reward": -99.53209047710851, "Episode length": 999, "Policy Loss": -1.698872447013855, "Value Loss": 0.08390000462532043, "_runtime": 8161.068613529205, "_timestamp": 1585578076.9132469, "_step": 455}
{"Episode reward": 2.4992759857499465, "Episode length": 977, "Policy Loss": -0.5145643949508667, "Value Loss": 9.912374496459961, "_runtime": 8162.50727558136, "_timestamp": 1585578078.351909, "_step": 456}
{"Episode reward": 7.592005879760876, "Episode length": 926, "Policy Loss": -0.6592241525650024, "Value Loss": 10.318437576293945, "_runtime": 8164.073853492737, "_timestamp": 1585578079.9184868, "_step": 457}
{"Episode reward": -99.67565395408171, "Episode length": 999, "Policy Loss": -1.3398573398590088, "Value Loss": 0.03891089931130409, "_runtime": 8164.8501262664795, "_timestamp": 1585578080.6947596, "_step": 458}
{"Episode reward": 51.997771645686186, "Episode length": 481, "Policy Loss": 0.48376724123954773, "Value Loss": 19.616662979125977, "_runtime": 8166.38182425499, "_timestamp": 1585578082.2264576, "_step": 459}
{"Episode reward": 2.2597003360291694, "Episode length": 981, "Policy Loss": -0.06797370314598083, "Value Loss": 9.739314079284668, "_runtime": 8167.939880609512, "_timestamp": 1585578083.784514, "_step": 460}
{"Episode reward": -99.69621402099591, "Episode length": 999, "Policy Loss": -1.0375378131866455, "Value Loss": 0.027776051312685013, "_runtime": 8169.458497285843, "_timestamp": 1585578085.3031306, "_step": 461}
{"Episode reward": -99.71806557476381, "Episode length": 999, "Policy Loss": -0.9737454652786255, "Value Loss": 0.02912965603172779, "_runtime": 8170.532709598541, "_timestamp": 1585578086.377343, "_step": 462}
{"Episode reward": 32.81027307437053, "Episode length": 674, "Policy Loss": 0.30673128366470337, "Value Loss": 13.9716796875, "_runtime": 8172.08975148201, "_timestamp": 1585578087.9343848, "_step": 463}
{"Episode reward": -99.88698317417735, "Episode length": 999, "Policy Loss": -0.8039880990982056, "Value Loss": 0.03951437026262283, "_runtime": 8173.642387866974, "_timestamp": 1585578089.4870212, "_step": 464}
{"Episode reward": -99.82657590026362, "Episode length": 999, "Policy Loss": -0.6555010676383972, "Value Loss": 0.06719018518924713, "_runtime": 8175.179497718811, "_timestamp": 1585578091.024131, "_step": 465}
{"Episode reward": -99.70553907276924, "Episode length": 999, "Policy Loss": -0.6534790992736816, "Value Loss": 0.03302804380655289, "_runtime": 8176.741171121597, "_timestamp": 1585578092.5858045, "_step": 466}
{"Episode reward": -99.78609384719608, "Episode length": 999, "Policy Loss": -0.6196021437644958, "Value Loss": 0.03605001047253609, "_runtime": 8177.124531984329, "_timestamp": 1585578092.9691653, "_step": 467}
{"Episode reward": 78.89999999999998, "Episode length": 211, "Policy Loss": 3.3034818172454834, "Value Loss": 44.92646789550781, "_runtime": 8178.670431137085, "_timestamp": 1585578094.5150645, "_step": 468}
{"Episode reward": -99.86114726441306, "Episode length": 999, "Policy Loss": -0.3529811501502991, "Value Loss": 0.257163941860199, "_runtime": 8179.314421415329, "_timestamp": 1585578095.1590548, "_step": 469}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.458599328994751, "Value Loss": 24.230297088623047, "_runtime": 8180.803019285202, "_timestamp": 1585578096.6476526, "_step": 470}
{"Episode reward": -99.8677218774567, "Episode length": 999, "Policy Loss": -0.5225223302841187, "Value Loss": 0.07050527632236481, "_runtime": 8181.163553953171, "_timestamp": 1585578097.0081873, "_step": 471}
{"Episode reward": 80.6, "Episode length": 194, "Policy Loss": 3.3999297618865967, "Value Loss": 48.019386291503906, "_runtime": 8182.688257217407, "_timestamp": 1585578098.5328906, "_step": 472}
{"Episode reward": -99.81186651186879, "Episode length": 999, "Policy Loss": -0.5653476715087891, "Value Loss": 0.008377364836633205, "_runtime": 8183.827447891235, "_timestamp": 1585578099.6720812, "_step": 473}
{"Episode reward": 27.653432537522008, "Episode length": 724, "Policy Loss": 0.6758619546890259, "Value Loss": 13.014928817749023, "_runtime": 8184.383979558945, "_timestamp": 1585578100.228613, "_step": 474}
{"Episode reward": 62.89999999999975, "Episode length": 371, "Policy Loss": 1.690276026725769, "Value Loss": 25.8455867767334, "_runtime": 8185.963783740997, "_timestamp": 1585578101.808417, "_step": 475}
{"Episode reward": -99.7358237250927, "Episode length": 999, "Policy Loss": -0.6542727947235107, "Value Loss": 0.009559580124914646, "_runtime": 8187.2813222408295, "_timestamp": 1585578103.1259556, "_step": 476}
{"Episode reward": 14.334460283606901, "Episode length": 858, "Policy Loss": 0.258186012506485, "Value Loss": 11.129013061523438, "_runtime": 8188.777127981186, "_timestamp": 1585578104.6217613, "_step": 477}
{"Episode reward": -99.81443265622808, "Episode length": 999, "Policy Loss": -0.7435057759284973, "Value Loss": 0.01793546788394451, "_runtime": 8189.285183906555, "_timestamp": 1585578105.1298172, "_step": 478}
{"Episode reward": 69.41627314386407, "Episode length": 306, "Policy Loss": 1.8763058185577393, "Value Loss": 30.403345108032227, "_runtime": 8190.4187569618225, "_timestamp": 1585578106.2633903, "_step": 479}
{"Episode reward": 26.4459423184161, "Episode length": 737, "Policy Loss": 0.5319011211395264, "Value Loss": 13.550904273986816, "_runtime": 8191.2807195186615, "_timestamp": 1585578107.1253529, "_step": 480}
{"Episode reward": 44.09999999999948, "Episode length": 559, "Policy Loss": 0.7210188508033752, "Value Loss": 16.98033332824707, "_runtime": 8192.75423836708, "_timestamp": 1585578108.5988717, "_step": 481}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": 0.13441112637519836, "Value Loss": 9.513411521911621, "_runtime": 8194.300914764404, "_timestamp": 1585578110.145548, "_step": 482}
{"Episode reward": -99.70165273288592, "Episode length": 999, "Policy Loss": -0.8470627069473267, "Value Loss": 0.022251516580581665, "_runtime": 8195.321074724197, "_timestamp": 1585578111.165708, "_step": 483}
{"Episode reward": 33.023010387130014, "Episode length": 671, "Policy Loss": 0.48294690251350403, "Value Loss": 14.499080657958984, "_runtime": 8196.41254067421, "_timestamp": 1585578112.257174, "_step": 484}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.4133215844631195, "Value Loss": 13.496984481811523, "_runtime": 8197.354483604431, "_timestamp": 1585578113.199117, "_step": 485}
{"Episode reward": 40.89999999999944, "Episode length": 591, "Policy Loss": 0.5343539714813232, "Value Loss": 15.854602813720703, "_runtime": 8198.890508890152, "_timestamp": 1585578114.7351422, "_step": 486}
{"Episode reward": -99.80152760185162, "Episode length": 999, "Policy Loss": -0.5819091796875, "Value Loss": 0.3286021947860718, "_runtime": 8200.414798259735, "_timestamp": 1585578116.2594316, "_step": 487}
{"Episode reward": -99.72202756423364, "Episode length": 999, "Policy Loss": -0.6512270569801331, "Value Loss": 0.2102765142917633, "_runtime": 8201.942264080048, "_timestamp": 1585578117.7868974, "_step": 488}
{"Episode reward": -99.72006218103203, "Episode length": 999, "Policy Loss": -0.7124543190002441, "Value Loss": 0.039310235530138016, "_runtime": 8203.506071567535, "_timestamp": 1585578119.350705, "_step": 489}
{"Episode reward": -99.7246372014503, "Episode length": 999, "Policy Loss": -0.6425896883010864, "Value Loss": 0.03278028592467308, "_runtime": 8205.057555913925, "_timestamp": 1585578120.9021893, "_step": 490}
{"Episode reward": -99.71936858578562, "Episode length": 999, "Policy Loss": -0.40258389711380005, "Value Loss": 0.3751526176929474, "_runtime": 8205.83173775673, "_timestamp": 1585578121.676371, "_step": 491}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 1.2153944969177246, "Value Loss": 19.672687530517578, "_runtime": 8206.962505102158, "_timestamp": 1585578122.8071384, "_step": 492}
{"Episode reward": 27.865784675231964, "Episode length": 723, "Policy Loss": 0.4916526675224304, "Value Loss": 13.129499435424805, "_runtime": 8208.557299852371, "_timestamp": 1585578124.4019332, "_step": 493}
{"Episode reward": -99.89169020959967, "Episode length": 999, "Policy Loss": -0.6014140248298645, "Value Loss": 0.022761506959795952, "_runtime": 8210.077562332153, "_timestamp": 1585578125.9221957, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5612812042236328, "Value Loss": 0.0667031779885292, "_runtime": 8210.573748111725, "_timestamp": 1585578126.4183815, "_step": 495}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 2.078019857406616, "Value Loss": 31.561471939086914, "_runtime": 8211.896523237228, "_timestamp": 1585578127.7411566, "_step": 496}
{"Episode reward": 14.060764694255226, "Episode length": 860, "Policy Loss": 0.4391251802444458, "Value Loss": 10.801142692565918, "_runtime": 8212.297189950943, "_timestamp": 1585578128.1418233, "_step": 497}
{"Episode reward": 77.09999999999995, "Episode length": 229, "Policy Loss": 2.8609399795532227, "Value Loss": 41.04511260986328, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753, 0.012575173750519753]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.41585808992385864, -0.39241960644721985, -0.36898112297058105, -0.3455426096916199, -0.32210415601730347, -0.2986656427383423, -0.2752271592617035, -0.2517886757850647, -0.2283501923084259, -0.2049117088317871, -0.18147322535514832, -0.15803474187850952, -0.13459622859954834, -0.11115774512290955, -0.08771926164627075, -0.06428077816963196, -0.040842294692993164, -0.01740381121635437, 0.006034672260284424, 0.029473155736923218, 0.05291163921356201, 0.0763501524925232, 0.0997886061668396, 0.12322711944580078, 0.14666563272476196, 0.17010408639907837, 0.19354259967803955, 0.21698105335235596, 0.24041956663131714, 0.26385802030563354, 0.2872965335845947, 0.31073498725891113, 0.3341735005378723, 0.3576120138168335, 0.3810504674911499, 0.4044889807701111, 0.4279274344444275, 0.45136594772338867, 0.4748044013977051, 0.49824291467666626, 0.5216813683509827, 0.5451198816299438, 0.568558394908905, 0.5919968485832214, 0.6154353022575378, 0.6388738751411438, 0.6623123288154602, 0.6857507824897766, 0.7091893553733826, 0.732627809047699, 0.7560662627220154, 0.7795047163963318, 0.8029432892799377, 0.8263817429542542, 0.8498201966285706, 0.873258650302887, 0.8966972231864929, 0.9201356768608093, 0.9435741305351257, 0.9670127034187317, 0.9904511570930481, 1.0138895511627197, 1.0373280048370361, 1.0607666969299316, 1.084205150604248]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06997928768396378, -0.06723333895206451, -0.06448739022016525, -0.06174143776297569, -0.05899548530578613, -0.05624953657388687, -0.05350358784198761, -0.05075763911008835, -0.04801168665289879, -0.04526573419570923, -0.04251978546380997, -0.039773836731910706, -0.037027888000011444, -0.034281935542821884, -0.03153598681092262, -0.028790034353733063, -0.0260440856218338, -0.02329813688993454, -0.02055218443274498, -0.01780623570084572, -0.015060283243656158, -0.012314334511756897, -0.009568385779857635, -0.006822437047958374, -0.0040764883160591125, -0.0013305321335792542, 0.0014154165983200073, 0.004161365330219269, 0.00690731406211853, 0.009653262794017792, 0.01239921897649765, 0.015145167708396912, 0.017891116440296173, 0.020637065172195435, 0.023383013904094696, 0.026128970086574554, 0.028874918818473816, 0.03162086755037308, 0.03436681628227234, 0.0371127650141716, 0.03985872119665146, 0.04260466992855072, 0.04535061866044998, 0.04809656739234924, 0.050842516124248505, 0.053588464856147766, 0.05633441358804703, 0.059080369770526886, 0.06182631105184555, 0.06457226723432541, 0.06731822341680527, 0.07006416469812393, 0.07281012088060379, 0.07555606216192245, 0.07830201834440231, 0.08104797452688217, 0.08379391580820084, 0.0865398719906807, 0.08928581327199936, 0.09203176945447922, 0.09477772563695908, 0.09752366691827774, 0.1002696231007576, 0.10301556438207626, 0.10576152056455612]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 13.0, 8.0, 45.0, 20.0, 45.0, 10.0, 12.0, 1.0, 161.0, 12.0, 15.0, 6.0, 15.0, 5.0, 2.0, 3.0, 7.0, 9.0, 4.0, 10.0, 11.0, 4.0, 11.0, 17.0, 12.0, 7.0, 5.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-0.41868889331817627, -0.4060610830783844, -0.3934333026409149, -0.38080549240112305, -0.3681776821613312, -0.3555498719215393, -0.3429220914840698, -0.33029428124427795, -0.3176664710044861, -0.3050386905670166, -0.29241088032722473, -0.27978307008743286, -0.2671552896499634, -0.2545274794101715, -0.24189968407154083, -0.22927187383174896, -0.2166440784931183, -0.2040162831544876, -0.19138847291469574, -0.17876067757606506, -0.1661328673362732, -0.1535050868988037, -0.14087727665901184, -0.12824946641921997, -0.11562168598175049, -0.10299387574195862, -0.09036606550216675, -0.07773825526237488, -0.0651104748249054, -0.052482664585113525, -0.039854854345321655, -0.027227073907852173, -0.014599263668060303, -0.0019714534282684326, 0.01065632700920105, 0.02328413724899292, 0.03591194748878479, 0.04853972792625427, 0.06116753816604614, 0.07379534840583801, 0.08642315864562988, 0.09905093908309937, 0.11167871952056885, 0.1243065595626831, 0.1369343400001526, 0.14956212043762207, 0.16218996047973633, 0.1748177409172058, 0.1874455213546753, 0.20007336139678955, 0.21270114183425903, 0.2253289818763733, 0.23795676231384277, 0.25058454275131226, 0.2632123827934265, 0.275840163230896, 0.2884679436683655, 0.30109578371047974, 0.3137235641479492, 0.3263513445854187, 0.33897918462753296, 0.35160696506500244, 0.3642347455024719, 0.3768625855445862, 0.38949036598205566]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1.8399015665054321, -1.7922003269195557, -1.7444990873336792, -1.6967978477478027, -1.6490966081619263, -1.6013953685760498, -1.553694248199463, -1.5059930086135864, -1.45829176902771, -1.4105905294418335, -1.362889289855957, -1.3151880502700806, -1.267486810684204, -1.2197855710983276, -1.1720843315124512, -1.1243832111358643, -1.0766818523406982, -1.0289807319641113, -0.9812794327735901, -0.9335782527923584, -0.8858770132064819, -0.8381757736206055, -0.790474534034729, -0.7427732944488525, -0.6950720548629761, -0.6473708152770996, -0.5996695756912231, -0.5519684553146362, -0.5042672157287598, -0.4565659761428833, -0.40886473655700684, -0.36116349697113037, -0.3134622573852539, -0.26576101779937744, -0.21805977821350098, -0.1703585386276245, -0.12265729904174805, -0.07495605945587158, -0.027254939079284668, 0.020446300506591797, 0.06814754009246826, 0.11584877967834473, 0.1635500192642212, 0.2112511396408081, 0.2589524984359741, 0.30665361881256104, 0.35435497760772705, 0.40205609798431396, 0.44975745677948, 0.4974585771560669, 0.5451599359512329, 0.5928610563278198, 0.6405624151229858, 0.6882635354995728, 0.7359646558761597, 0.7836660146713257, 0.8313671350479126, 0.8790684938430786, 0.9267696142196655, 0.9744709730148315, 1.0221720933914185, 1.0698734521865845, 1.1175745725631714, 1.1652759313583374, 1.2129770517349243]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 8.0, 12.0, 7.0, 1.0, 0.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 4.0, 0.0, 1.0, 1.0], "bins": [-0.9697515964508057, -0.9437206983566284, -0.9176898002624512, -0.8916589021682739, -0.8656280040740967, -0.8395971059799194, -0.8135661482810974, -0.7875352501869202, -0.7615043520927429, -0.7354734539985657, -0.7094425559043884, -0.6834115982055664, -0.6573807001113892, -0.6313498020172119, -0.6053189039230347, -0.5792880058288574, -0.5532571077346802, -0.5272262096405029, -0.5011953115463257, -0.47516438364982605, -0.4491335153579712, -0.42310255765914917, -0.3970716595649719, -0.3710407614707947, -0.34500986337661743, -0.3189789652824402, -0.29294806718826294, -0.2669171690940857, -0.24088621139526367, -0.21485531330108643, -0.18882441520690918, -0.16279351711273193, -0.1367626190185547, -0.11073172092437744, -0.0847008228302002, -0.05866992473602295, -0.0326390266418457, -0.006608068943023682, 0.019422829151153564, 0.045453667640686035, 0.07148456573486328, 0.09751558303833008, 0.12354648113250732, 0.14957737922668457, 0.17560827732086182, 0.20163917541503906, 0.2276700735092163, 0.25370097160339355, 0.2797318696975708, 0.30576276779174805, 0.3317936658859253, 0.35782456398010254, 0.3838554620742798, 0.40988636016845703, 0.4359172582626343, 0.4619481563568115, 0.4879791736602783, 0.5140100717544556, 0.5400409698486328, 0.5660718679428101, 0.5921027660369873, 0.6181336641311646, 0.6441645622253418, 0.670195460319519, 0.6962263584136963]}, "_runtime": 8213.800208806992, "_timestamp": 1585578129.6448421, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6592233180999756, "Value Loss": 0.1355501264333725, "_runtime": 8213.800208806992, "_timestamp": 1585578129.6448421, "_step": 499}
