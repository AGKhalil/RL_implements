{"Episode reward": -50.89823306423115, "Episode length": 999, "Policy Loss": -0.05763625353574753, "Value Loss": 0.004108191933482885, "_runtime": 19747.462420225143, "_timestamp": 1585617117.0952897, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6385633945465088, "Value Loss": 10.871212005615234, "_runtime": 19748.5825278759, "_timestamp": 1585617118.2153974, "_step": 1}
{"Episode reward": 37.94573766094702, "Episode length": 728, "Policy Loss": -1.8878767490386963, "Value Loss": 35.8406982421875, "_runtime": 19749.138525485992, "_timestamp": 1585617118.771395, "_step": 2}
{"Episode reward": 70.45642955762222, "Episode length": 319, "Policy Loss": 0.5715501308441162, "Value Loss": 36.92597579956055, "_runtime": 19749.344563245773, "_timestamp": 1585617118.9774327, "_step": 3}
{"Episode reward": 90.58810943638656, "Episode length": 98, "Policy Loss": -10.281338691711426, "Value Loss": 144.97100830078125, "_runtime": 19749.579959392548, "_timestamp": 1585617119.2128289, "_step": 4}
{"Episode reward": 87.11477492571437, "Episode length": 130, "Policy Loss": 107.03768157958984, "Value Loss": 337.283203125, "_runtime": 19749.764098405838, "_timestamp": 1585617119.396968, "_step": 5}
{"Episode reward": 89.29186808820039, "Episode length": 108, "Policy Loss": -8.684767723083496, "Value Loss": 101.58419799804688, "_runtime": 19749.9440741539, "_timestamp": 1585617119.5769436, "_step": 6}
{"Episode reward": 90.1948412870824, "Episode length": 116, "Policy Loss": 8.857012748718262, "Value Loss": 146.9990234375, "_runtime": 19750.899842500687, "_timestamp": 1585617120.532712, "_step": 7}
{"Episode reward": 39.811752243573764, "Episode length": 640, "Policy Loss": -0.2071671038866043, "Value Loss": 16.155166625976562, "_runtime": 19751.424803972244, "_timestamp": 1585617121.0576735, "_step": 8}
{"Episode reward": 66.34660107237013, "Episode length": 349, "Policy Loss": 0.3160698115825653, "Value Loss": 32.85404586791992, "_runtime": 19752.915979385376, "_timestamp": 1585617122.5488489, "_step": 9}
{"Episode reward": -97.62030726016035, "Episode length": 999, "Policy Loss": -0.9161958694458008, "Value Loss": 3.4340932369232178, "_runtime": 19754.471254348755, "_timestamp": 1585617124.1041238, "_step": 10}
{"Episode reward": -97.93719513465287, "Episode length": 999, "Policy Loss": -1.0800893306732178, "Value Loss": 4.958616733551025, "_runtime": 19756.00026369095, "_timestamp": 1585617125.6331332, "_step": 11}
{"Episode reward": -98.15030131341717, "Episode length": 999, "Policy Loss": -0.7651325464248657, "Value Loss": 1.690877914428711, "_runtime": 19757.02668452263, "_timestamp": 1585617126.659554, "_step": 12}
{"Episode reward": 35.530700699865605, "Episode length": 654, "Policy Loss": -0.09111400693655014, "Value Loss": 15.146286010742188, "_runtime": 19757.87730717659, "_timestamp": 1585617127.5101767, "_step": 13}
{"Episode reward": 47.11867310987316, "Episode length": 533, "Policy Loss": 0.12678639590740204, "Value Loss": 18.239917755126953, "_runtime": 19759.451335668564, "_timestamp": 1585617129.0842052, "_step": 14}
{"Episode reward": -99.02674047427547, "Episode length": 999, "Policy Loss": -0.7545756697654724, "Value Loss": 0.07308433204889297, "_runtime": 19760.989163160324, "_timestamp": 1585617130.6220326, "_step": 15}
{"Episode reward": -99.0197778079602, "Episode length": 999, "Policy Loss": -0.964189887046814, "Value Loss": 0.39966443181037903, "_runtime": 19762.529892206192, "_timestamp": 1585617132.1627617, "_step": 16}
{"Episode reward": -98.82882706560697, "Episode length": 999, "Policy Loss": -0.8632214665412903, "Value Loss": 0.12865741550922394, "_runtime": 19763.28854036331, "_timestamp": 1585617132.9214098, "_step": 17}
{"Episode reward": 53.990330559545676, "Episode length": 464, "Policy Loss": 0.3008410632610321, "Value Loss": 21.247234344482422, "_runtime": 19764.38226056099, "_timestamp": 1585617134.01513, "_step": 18}
{"Episode reward": 34.013907552697674, "Episode length": 664, "Policy Loss": -0.08301649987697601, "Value Loss": 14.846392631530762, "_runtime": 19765.628462553024, "_timestamp": 1585617135.261332, "_step": 19}
{"Episode reward": 21.874108648030756, "Episode length": 789, "Policy Loss": -0.22238439321517944, "Value Loss": 12.578084945678711, "_runtime": 19767.156269788742, "_timestamp": 1585617136.7891393, "_step": 20}
{"Episode reward": -99.59626319332754, "Episode length": 999, "Policy Loss": -0.931184709072113, "Value Loss": 0.0503382571041584, "_runtime": 19768.70215845108, "_timestamp": 1585617138.335028, "_step": 21}
{"Episode reward": -99.58582474055045, "Episode length": 999, "Policy Loss": -0.9543172121047974, "Value Loss": 0.1275802105665207, "_runtime": 19770.26596403122, "_timestamp": 1585617139.8988335, "_step": 22}
{"Episode reward": -99.63665997677933, "Episode length": 999, "Policy Loss": -1.0164982080459595, "Value Loss": 0.1206640675663948, "_runtime": 19771.59708881378, "_timestamp": 1585617141.2299583, "_step": 23}
{"Episode reward": 16.139840670815232, "Episode length": 842, "Policy Loss": -0.45762473344802856, "Value Loss": 11.797513961791992, "_runtime": 19773.17275094986, "_timestamp": 1585617142.8056204, "_step": 24}
{"Episode reward": -99.48589188254708, "Episode length": 999, "Policy Loss": -1.057152509689331, "Value Loss": 0.140904501080513, "_runtime": 19774.50969195366, "_timestamp": 1585617144.1425614, "_step": 25}
{"Episode reward": 16.816596518062227, "Episode length": 839, "Policy Loss": -0.24103645980358124, "Value Loss": 11.625507354736328, "_runtime": 19774.91272497177, "_timestamp": 1585617144.5455945, "_step": 26}
{"Episode reward": 77.50642312940177, "Episode length": 226, "Policy Loss": 1.4691354036331177, "Value Loss": 43.640655517578125, "_runtime": 19776.201284646988, "_timestamp": 1585617145.8341541, "_step": 27}
{"Episode reward": 18.74137962842977, "Episode length": 815, "Policy Loss": -0.34433841705322266, "Value Loss": 12.101635932922363, "_runtime": 19777.788967370987, "_timestamp": 1585617147.4218369, "_step": 28}
{"Episode reward": -99.82033539474368, "Episode length": 999, "Policy Loss": -1.1130404472351074, "Value Loss": 0.2541361451148987, "_runtime": 19779.295147895813, "_timestamp": 1585617148.9280174, "_step": 29}
{"Episode reward": -99.41044037951077, "Episode length": 999, "Policy Loss": -1.1451255083084106, "Value Loss": 0.18221507966518402, "_runtime": 19780.86683821678, "_timestamp": 1585617150.4997077, "_step": 30}
{"Episode reward": -99.5529831029161, "Episode length": 999, "Policy Loss": -1.1089706420898438, "Value Loss": 0.08013255149126053, "_runtime": 19782.445009469986, "_timestamp": 1585617152.077879, "_step": 31}
{"Episode reward": -99.39524154889524, "Episode length": 999, "Policy Loss": -1.1205247640609741, "Value Loss": 0.1200367659330368, "_runtime": 19783.997870206833, "_timestamp": 1585617153.6307397, "_step": 32}
{"Episode reward": -99.55929355334965, "Episode length": 999, "Policy Loss": -0.9990045428276062, "Value Loss": 0.14837364852428436, "_runtime": 19785.588312864304, "_timestamp": 1585617155.2211823, "_step": 33}
{"Episode reward": -99.20647117257478, "Episode length": 999, "Policy Loss": -0.998718798160553, "Value Loss": 0.09129838645458221, "_runtime": 19786.70167207718, "_timestamp": 1585617156.3345416, "_step": 34}
{"Episode reward": 30.98852994471055, "Episode length": 692, "Policy Loss": -0.05140939727425575, "Value Loss": 14.881302833557129, "_runtime": 19788.261922121048, "_timestamp": 1585617157.8947916, "_step": 35}
{"Episode reward": 2.195220525174051, "Episode length": 981, "Policy Loss": -0.3388828635215759, "Value Loss": 10.120306968688965, "_runtime": 19789.338897705078, "_timestamp": 1585617158.9717672, "_step": 36}
{"Episode reward": 33.131627718661434, "Episode length": 672, "Policy Loss": -0.1684112846851349, "Value Loss": 14.493313789367676, "_runtime": 19790.90966463089, "_timestamp": 1585617160.542534, "_step": 37}
{"Episode reward": -99.62156205277432, "Episode length": 999, "Policy Loss": -1.4745745658874512, "Value Loss": 2.196152925491333, "_runtime": 19792.4495511055, "_timestamp": 1585617162.0824206, "_step": 38}
{"Episode reward": 2.278626440430145, "Episode length": 980, "Policy Loss": -0.7099407315254211, "Value Loss": 10.798399925231934, "_runtime": 19793.379878520966, "_timestamp": 1585617163.012748, "_step": 39}
{"Episode reward": 40.281792660474615, "Episode length": 598, "Policy Loss": 0.06733386963605881, "Value Loss": 16.210708618164062, "_runtime": 19794.657380342484, "_timestamp": 1585617164.2902498, "_step": 40}
{"Episode reward": 19.933229980123258, "Episode length": 804, "Policy Loss": 0.0005112916114740074, "Value Loss": 13.211559295654297, "_runtime": 19796.23467540741, "_timestamp": 1585617165.867545, "_step": 41}
{"Episode reward": -99.51916365091319, "Episode length": 999, "Policy Loss": -0.8732283115386963, "Value Loss": 0.09050627797842026, "_runtime": 19797.779325008392, "_timestamp": 1585617167.4121945, "_step": 42}
{"Episode reward": -99.31776804461705, "Episode length": 999, "Policy Loss": -0.7584535479545593, "Value Loss": 0.35156577825546265, "_runtime": 19798.993803739548, "_timestamp": 1585617168.6266732, "_step": 43}
{"Episode reward": 22.367366602714313, "Episode length": 778, "Policy Loss": -0.16021375358104706, "Value Loss": 12.668615341186523, "_runtime": 19800.573498487473, "_timestamp": 1585617170.206368, "_step": 44}
{"Episode reward": -99.49014569196012, "Episode length": 999, "Policy Loss": -1.0072940587997437, "Value Loss": 0.30128467082977295, "_runtime": 19802.155039310455, "_timestamp": 1585617171.7879088, "_step": 45}
{"Episode reward": -99.71085620061663, "Episode length": 999, "Policy Loss": -1.062881588935852, "Value Loss": 0.4862528443336487, "_runtime": 19803.036966323853, "_timestamp": 1585617172.6698358, "_step": 46}
{"Episode reward": 44.89969640464937, "Episode length": 552, "Policy Loss": 0.13572104275226593, "Value Loss": 17.196483612060547, "_runtime": 19804.606567382812, "_timestamp": 1585617174.2394369, "_step": 47}
{"Episode reward": 0.8177449307445102, "Episode length": 996, "Policy Loss": -0.52587890625, "Value Loss": 10.134984970092773, "_runtime": 19806.196944713593, "_timestamp": 1585617175.8298142, "_step": 48}
{"Episode reward": -99.54490354496383, "Episode length": 999, "Policy Loss": -0.9447915554046631, "Value Loss": 0.1493253856897354, "_runtime": 19807.74038052559, "_timestamp": 1585617177.37325, "_step": 49}
{"Episode reward": -99.548245177242, "Episode length": 999, "Policy Loss": -0.7896054983139038, "Value Loss": 0.05275939777493477, "_runtime": 19809.322780132294, "_timestamp": 1585617178.9556496, "_step": 50}
{"Episode reward": -99.65547631664528, "Episode length": 999, "Policy Loss": -0.6455850005149841, "Value Loss": 0.23304511606693268, "_runtime": 19810.904524326324, "_timestamp": 1585617180.5373938, "_step": 51}
{"Episode reward": -99.51132623321146, "Episode length": 999, "Policy Loss": -0.692213773727417, "Value Loss": 0.2817310094833374, "_runtime": 19812.51527070999, "_timestamp": 1585617182.1481402, "_step": 52}
{"Episode reward": -99.38308255442726, "Episode length": 999, "Policy Loss": -0.7090359926223755, "Value Loss": 0.517889142036438, "_runtime": 19814.03430747986, "_timestamp": 1585617183.667177, "_step": 53}
{"Episode reward": 4.3398851590104215, "Episode length": 959, "Policy Loss": 0.03460806608200073, "Value Loss": 10.70806884765625, "_runtime": 19815.629515886307, "_timestamp": 1585617185.2623854, "_step": 54}
{"Episode reward": -99.43943923324596, "Episode length": 999, "Policy Loss": -0.7503975033760071, "Value Loss": 0.06890158355236053, "_runtime": 19816.27561736107, "_timestamp": 1585617185.9084868, "_step": 55}
{"Episode reward": 61.49963395099012, "Episode length": 386, "Policy Loss": 0.6953035593032837, "Value Loss": 25.005355834960938, "_runtime": 19817.112020730972, "_timestamp": 1585617186.7448902, "_step": 56}
{"Episode reward": 48.04627062082661, "Episode length": 522, "Policy Loss": 0.43023818731307983, "Value Loss": 18.916152954101562, "_runtime": 19818.691908359528, "_timestamp": 1585617188.3247778, "_step": 57}
{"Episode reward": -99.8017475390851, "Episode length": 999, "Policy Loss": -0.762078046798706, "Value Loss": 0.09604907780885696, "_runtime": 19819.813518047333, "_timestamp": 1585617189.4463875, "_step": 58}
{"Episode reward": 26.751458817049453, "Episode length": 735, "Policy Loss": 0.06602755934000015, "Value Loss": 13.76168441772461, "_runtime": 19821.0592815876, "_timestamp": 1585617190.692151, "_step": 59}
{"Episode reward": 18.861748342577243, "Episode length": 813, "Policy Loss": -0.1887313425540924, "Value Loss": 12.409125328063965, "_runtime": 19822.634650707245, "_timestamp": 1585617192.2675202, "_step": 60}
{"Episode reward": -99.57128845858975, "Episode length": 999, "Policy Loss": -0.6342750787734985, "Value Loss": 0.18014951050281525, "_runtime": 19824.182002305984, "_timestamp": 1585617193.8148718, "_step": 61}
{"Episode reward": -99.37891991135737, "Episode length": 999, "Policy Loss": -0.6231871247291565, "Value Loss": 0.272546648979187, "_runtime": 19825.170477867126, "_timestamp": 1585617194.8033473, "_step": 62}
{"Episode reward": 37.52677568938755, "Episode length": 628, "Policy Loss": 0.4631960391998291, "Value Loss": 15.829865455627441, "_runtime": 19826.748059749603, "_timestamp": 1585617196.3809292, "_step": 63}
{"Episode reward": -99.56186316946265, "Episode length": 999, "Policy Loss": -0.5374441742897034, "Value Loss": 0.14274962246418, "_runtime": 19827.882236480713, "_timestamp": 1585617197.515106, "_step": 64}
{"Episode reward": 28.800507666903783, "Episode length": 715, "Policy Loss": 0.3323174715042114, "Value Loss": 14.035096168518066, "_runtime": 19829.423863887787, "_timestamp": 1585617199.0567334, "_step": 65}
{"Episode reward": -99.61381326898561, "Episode length": 999, "Policy Loss": -0.6635971069335938, "Value Loss": 0.02651173807680607, "_runtime": 19830.559574365616, "_timestamp": 1585617200.1924438, "_step": 66}
{"Episode reward": 29.171758453635945, "Episode length": 713, "Policy Loss": 0.08833719044923782, "Value Loss": 13.698251724243164, "_runtime": 19832.112278223038, "_timestamp": 1585617201.7451477, "_step": 67}
{"Episode reward": -99.80825160902319, "Episode length": 999, "Policy Loss": -0.8203766345977783, "Value Loss": 0.13620273768901825, "_runtime": 19833.695518016815, "_timestamp": 1585617203.3283875, "_step": 68}
{"Episode reward": -99.50731624019545, "Episode length": 999, "Policy Loss": -0.9806956648826599, "Value Loss": 0.5975745320320129, "_runtime": 19835.289495944977, "_timestamp": 1585617204.9223654, "_step": 69}
{"Episode reward": -99.39533970458297, "Episode length": 999, "Policy Loss": -0.8362224102020264, "Value Loss": 0.17783550918102264, "_runtime": 19836.866630077362, "_timestamp": 1585617206.4994996, "_step": 70}
{"Episode reward": -99.50651236310085, "Episode length": 999, "Policy Loss": -0.7683650851249695, "Value Loss": 0.1087377667427063, "_runtime": 19837.727654457092, "_timestamp": 1585617207.360524, "_step": 71}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 0.2262382060289383, "Value Loss": 18.292634963989258, "_runtime": 19839.309748649597, "_timestamp": 1585617208.9426181, "_step": 72}
{"Episode reward": -99.70036254043669, "Episode length": 999, "Policy Loss": -0.7152352929115295, "Value Loss": 0.025714363902807236, "_runtime": 19840.890043497086, "_timestamp": 1585617210.522913, "_step": 73}
{"Episode reward": -99.28243905677493, "Episode length": 999, "Policy Loss": -0.6245710253715515, "Value Loss": 0.1073819100856781, "_runtime": 19842.415103435516, "_timestamp": 1585617212.047973, "_step": 74}
{"Episode reward": -99.27017852692963, "Episode length": 999, "Policy Loss": -0.6483926177024841, "Value Loss": 0.045740120112895966, "_runtime": 19844.00091767311, "_timestamp": 1585617213.6337872, "_step": 75}
{"Episode reward": -99.53632235976846, "Episode length": 999, "Policy Loss": -0.6012220978736877, "Value Loss": 0.07184212654829025, "_runtime": 19845.034807682037, "_timestamp": 1585617214.6676772, "_step": 76}
{"Episode reward": 35.52369095582337, "Episode length": 647, "Policy Loss": 0.40919676423072815, "Value Loss": 15.83395767211914, "_runtime": 19846.612661123276, "_timestamp": 1585617216.2455306, "_step": 77}
{"Episode reward": -99.71171990815061, "Episode length": 999, "Policy Loss": -0.5909743309020996, "Value Loss": 0.13271555304527283, "_runtime": 19847.516273260117, "_timestamp": 1585617217.1491427, "_step": 78}
{"Episode reward": 44.939278033573146, "Episode length": 553, "Policy Loss": 0.4240628480911255, "Value Loss": 17.620141983032227, "_runtime": 19849.06956553459, "_timestamp": 1585617218.702435, "_step": 79}
{"Episode reward": -99.54913847186843, "Episode length": 999, "Policy Loss": -0.7082615494728088, "Value Loss": 0.023042185232043266, "_runtime": 19850.65965628624, "_timestamp": 1585617220.2925258, "_step": 80}
{"Episode reward": -99.71178341797791, "Episode length": 999, "Policy Loss": -0.766197144985199, "Value Loss": 0.08404536545276642, "_runtime": 19851.92236685753, "_timestamp": 1585617221.5552363, "_step": 81}
{"Episode reward": 18.466498335515965, "Episode length": 818, "Policy Loss": 0.1010160818696022, "Value Loss": 12.019142150878906, "_runtime": 19853.43859887123, "_timestamp": 1585617223.0714684, "_step": 82}
{"Episode reward": 4.670217897480754, "Episode length": 960, "Policy Loss": -0.1702701598405838, "Value Loss": 10.652344703674316, "_runtime": 19855.01539850235, "_timestamp": 1585617224.648268, "_step": 83}
{"Episode reward": -99.34163421939601, "Episode length": 999, "Policy Loss": -0.8970118165016174, "Value Loss": 0.19462332129478455, "_runtime": 19856.577909469604, "_timestamp": 1585617226.210779, "_step": 84}
{"Episode reward": -99.65646490655935, "Episode length": 999, "Policy Loss": -0.7802144289016724, "Value Loss": 0.045111749321222305, "_runtime": 19858.181605815887, "_timestamp": 1585617227.8144753, "_step": 85}
{"Episode reward": -99.30244374313489, "Episode length": 999, "Policy Loss": -0.8065831065177917, "Value Loss": 0.13587217032909393, "_runtime": 19859.76097035408, "_timestamp": 1585617229.3938398, "_step": 86}
{"Episode reward": -99.70265134515147, "Episode length": 999, "Policy Loss": -0.720923900604248, "Value Loss": 0.042231783270835876, "_runtime": 19861.34575152397, "_timestamp": 1585617230.978621, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6410189867019653, "Value Loss": 0.07953411340713501, "_runtime": 19862.720156908035, "_timestamp": 1585617232.3530264, "_step": 88}
{"Episode reward": 13.535541746329457, "Episode length": 868, "Policy Loss": 0.12528128921985626, "Value Loss": 11.42172908782959, "_runtime": 19863.857068538666, "_timestamp": 1585617233.489938, "_step": 89}
{"Episode reward": 28.699999999999775, "Episode length": 713, "Policy Loss": 0.28492113947868347, "Value Loss": 14.141804695129395, "_runtime": 19865.431410074234, "_timestamp": 1585617235.0642796, "_step": 90}
{"Episode reward": -99.61215613107386, "Episode length": 999, "Policy Loss": -0.564523458480835, "Value Loss": 0.2308361530303955, "_runtime": 19867.011616945267, "_timestamp": 1585617236.6444864, "_step": 91}
{"Episode reward": -99.55703995202063, "Episode length": 999, "Policy Loss": -0.6468279361724854, "Value Loss": 0.1580619364976883, "_runtime": 19867.86822104454, "_timestamp": 1585617237.5010905, "_step": 92}
{"Episode reward": 46.431586074264004, "Episode length": 538, "Policy Loss": 0.4847826063632965, "Value Loss": 18.112586975097656, "_runtime": 19869.28644299507, "_timestamp": 1585617238.9193125, "_step": 93}
{"Episode reward": 10.688513926911824, "Episode length": 895, "Policy Loss": -0.13038475811481476, "Value Loss": 10.879680633544922, "_runtime": 19870.137717723846, "_timestamp": 1585617239.7705872, "_step": 94}
{"Episode reward": 47.87567812995357, "Episode length": 525, "Policy Loss": 0.26758503913879395, "Value Loss": 18.515642166137695, "_runtime": 19871.6696665287, "_timestamp": 1585617241.302536, "_step": 95}
{"Episode reward": -99.80681058990163, "Episode length": 999, "Policy Loss": -0.7769662737846375, "Value Loss": 0.0700124204158783, "_runtime": 19873.24317598343, "_timestamp": 1585617242.8760455, "_step": 96}
{"Episode reward": -99.47498563987182, "Episode length": 999, "Policy Loss": -0.7931597828865051, "Value Loss": 0.10767018795013428, "_runtime": 19874.777028799057, "_timestamp": 1585617244.4098983, "_step": 97}
{"Episode reward": -99.74789220698301, "Episode length": 999, "Policy Loss": -0.7970594763755798, "Value Loss": 0.06415948271751404, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406, 1.0610084533691406]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.8342599868774414, -2.7381508350372314, -1.6420416831970215, -0.5459325313568115, 0.5501766204833984, 1.6462860107421875, 2.7423949241638184, 3.838503837585449, 4.934613227844238, 6.030722618103027, 7.126832008361816, 8.222940444946289, 9.319049835205078, 10.415159225463867, 11.51126766204834, 12.607377052307129, 13.703486442565918, 14.799595832824707, 15.895705223083496, 16.99181365966797, 18.08792495727539, 19.184032440185547, 20.280139923095703, 21.376251220703125, 22.47235870361328, 23.568470001220703, 24.66457748413086, 25.76068878173828, 26.856796264648438, 27.952903747558594, 29.049015045166016, 30.145126342773438, 31.241233825683594, 32.33734130859375, 33.43345260620117, 34.52956008911133, 35.62567138671875, 36.721778869628906, 37.81789016723633, 38.913997650146484, 40.010108947753906, 41.10621643066406, 42.20232391357422, 43.29843521118164, 44.3945426940918, 45.49065399169922, 46.586761474609375, 47.6828727722168, 48.77898025512695, 49.87508773803711, 50.97119903564453, 52.06730651855469, 53.16341781616211, 54.259525299072266, 55.35563659667969, 56.451744079589844, 57.5478515625, 58.64396286010742, 59.74007034301758, 60.836181640625, 61.932289123535156, 63.02839660644531, 64.12451171875, 65.22061920166016, 66.31672668457031]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 6.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3691571056842804, -0.3298911452293396, -0.2906251847743988, -0.251359224319458, -0.2120932638645172, -0.17282730340957642, -0.13356134295463562, -0.09429538249969482, -0.05502942204475403, -0.015763461589813232, 0.023502498865127563, 0.06276845932006836, 0.10203441977500916, 0.14130041003227234, 0.18056634068489075, 0.21983227133750916, 0.25909826159477234, 0.2983642518520355, 0.33763018250465393, 0.37689611315727234, 0.4161621034145355, 0.4554280936717987, 0.4946940243244171, 0.5339599847793579, 0.5732259750366211, 0.6124919652938843, 0.6517579555511475, 0.6910238265991211, 0.7302898168563843, 0.7695558071136475, 0.8088216781616211, 0.8480876684188843, 0.8873536586761475, 0.9266196489334106, 0.9658856391906738, 1.0051515102386475, 1.0444175004959106, 1.0836834907531738, 1.1229493618011475, 1.1622153520584106, 1.2014813423156738, 1.240747332572937, 1.2800133228302002, 1.3192791938781738, 1.358545184135437, 1.3978111743927002, 1.4370770454406738, 1.476343035697937, 1.5156090259552002, 1.5548750162124634, 1.5941410064697266, 1.6334068775177002, 1.672672986984253, 1.7119388580322266, 1.7512047290802002, 1.790470838546753, 1.8297367095947266, 1.8690025806427002, 1.908268690109253, 1.9475345611572266, 1.9868004322052002, 2.026066541671753, 2.0653324127197266, 2.1045985221862793, 2.143864393234253]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [10.0, 0.0, 3.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 6.0, 23.0, 42.0, 307.0, 75.0, 15.0, 5.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.13683819770813, -2.013007640838623, -1.8891770839691162, -1.7653465270996094, -1.6415159702301025, -1.5176854133605957, -1.3938548564910889, -1.270024299621582, -1.1461937427520752, -1.0223631858825684, -0.8985326290130615, -0.7747020721435547, -0.6508715152740479, -0.527040958404541, -0.4032104015350342, -0.27937984466552734, -0.1555492877960205, -0.03171873092651367, 0.09211182594299316, 0.2159423828125, 0.33977293968200684, 0.46360349655151367, 0.5874340534210205, 0.7112646102905273, 0.8350951671600342, 0.958925724029541, 1.0827562808990479, 1.2065868377685547, 1.3304173946380615, 1.4542479515075684, 1.5780785083770752, 1.701909065246582, 1.8257396221160889, 1.9495704174041748, 2.0734007358551025, 2.1972310543060303, 2.321061849594116, 2.444892644882202, 2.56872296333313, 2.6925532817840576, 2.8163840770721436, 2.9402148723602295, 3.0640451908111572, 3.187875509262085, 3.311706304550171, 3.435537099838257, 3.5593674182891846, 3.6831977367401123, 3.8070285320281982, 3.930859327316284, 4.054689407348633, 4.178520202636719, 4.302350997924805, 4.426181793212891, 4.55001163482666, 4.673842430114746, 4.797673225402832, 4.921504020690918, 5.0453338623046875, 5.169164657592773, 5.292995452880859, 5.416826248168945, 5.540656089782715, 5.664486885070801, 5.788317680358887]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.57650625705719, -1.406651258468628, -1.236796259880066, -1.066941261291504, -0.8970862030982971, -0.7272312045097351, -0.5573761463165283, -0.3875211477279663, -0.2176661491394043, -0.047811150550842285, 0.12204384803771973, 0.29189884662628174, 0.4617539644241333, 0.6316088438034058, 0.8014639616012573, 0.9713188409805298, 1.1411739587783813, 1.311029076576233, 1.4808839559555054, 1.650739073753357, 1.8205939531326294, 1.990449070930481, 2.160304069519043, 2.3301591873168945, 2.500014305114746, 2.6698694229125977, 2.839724063873291, 3.0095791816711426, 3.179434299468994, 3.3492894172668457, 3.519144058227539, 3.6889991760253906, 3.858854293823242, 4.028709411621094, 4.198564529418945, 4.368419170379639, 4.53827428817749, 4.708129405975342, 4.877984523773193, 5.047839164733887, 5.217694282531738, 5.38754940032959, 5.557404518127441, 5.727259635925293, 5.897114276885986, 6.066969394683838, 6.2368245124816895, 6.406679630279541, 6.576534748077393, 6.746389865875244, 6.916244983673096, 7.086099147796631, 7.255954265594482, 7.425809383392334, 7.5956645011901855, 7.765519618988037, 7.935374736785889, 8.105229377746582, 8.275084495544434, 8.444939613342285, 8.61479377746582, 8.784648895263672, 8.954504013061523, 9.124359130859375, 9.294214248657227]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 5.0, 3.0, 4.0, 1.0, 1.0, 5.0, 1.0, 5.0, 1.0, 2.0, 1.0, 0.0, 2.0, 5.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0], "bins": [-4.090102195739746, -4.00435209274292, -3.9186017513275146, -3.8328514099121094, -3.747101306915283, -3.661350965499878, -3.5756006240844727, -3.4898505210876465, -3.404100179672241, -3.318349838256836, -3.2325997352600098, -3.1468493938446045, -3.061099052429199, -2.975348949432373, -2.8895986080169678, -2.8038482666015625, -2.7180981636047363, -2.63234806060791, -2.546597719192505, -2.4608473777770996, -2.3750972747802734, -2.289346933364868, -2.203596591949463, -2.1178464889526367, -2.0320961475372314, -1.9463458061218262, -1.860595703125, -1.7748453617095947, -1.6890950202941895, -1.6033449172973633, -1.517594575881958, -1.4318444728851318, -1.3460941314697266, -1.2603437900543213, -1.1745936870574951, -1.0888433456420898, -1.0030932426452637, -0.9173429012298584, -0.8315925598144531, -0.745842456817627, -0.6600921154022217, -0.5743417739868164, -0.48859167098999023, -0.40284132957458496, -0.3170909881591797, -0.23134088516235352, -0.14559054374694824, -0.05984020233154297, 0.025909900665283203, 0.11166000366210938, 0.19741058349609375, 0.2831606864929199, 0.3689107894897461, 0.45466136932373047, 0.5404114723205566, 0.6261615753173828, 0.7119121551513672, 0.7976622581481934, 0.8834123611450195, 0.9691624641418457, 1.05491304397583, 1.1406631469726562, 1.2264132499694824, 1.3121638298034668, 1.397913932800293]}, "_runtime": 19876.05246925354, "_timestamp": 1585617245.6853387, "_step": 98}
{"Episode reward": 19.505070159375038, "Episode length": 805, "Policy Loss": -0.09937822073698044, "Value Loss": 12.015284538269043, "_runtime": 19877.64071416855, "_timestamp": 1585617247.2735837, "_step": 99}
{"Episode reward": -99.30699948172995, "Episode length": 999, "Policy Loss": -0.8258986473083496, "Value Loss": 0.12306846678256989, "_runtime": 19878.387379169464, "_timestamp": 1585617248.0202487, "_step": 100}
{"Episode reward": 53.451849952793765, "Episode length": 467, "Policy Loss": 0.4506761431694031, "Value Loss": 20.492225646972656, "_runtime": 19879.946258544922, "_timestamp": 1585617249.579128, "_step": 101}
{"Episode reward": -99.65110916693236, "Episode length": 999, "Policy Loss": -0.8629157543182373, "Value Loss": 0.1728263944387436, "_runtime": 19881.534291505814, "_timestamp": 1585617251.167161, "_step": 102}
{"Episode reward": -99.43510910516044, "Episode length": 999, "Policy Loss": -0.7421159148216248, "Value Loss": 0.07089795172214508, "_runtime": 19883.10569882393, "_timestamp": 1585617252.7385683, "_step": 103}
{"Episode reward": -99.63604802947299, "Episode length": 999, "Policy Loss": -0.740729808807373, "Value Loss": 0.08860839903354645, "_runtime": 19884.42582154274, "_timestamp": 1585617254.058691, "_step": 104}
{"Episode reward": 17.01875688085667, "Episode length": 835, "Policy Loss": 0.02520502544939518, "Value Loss": 11.784296989440918, "_runtime": 19886.014220952988, "_timestamp": 1585617255.6470904, "_step": 105}
{"Episode reward": -99.43510762125233, "Episode length": 999, "Policy Loss": -0.7053537964820862, "Value Loss": 0.03202518820762634, "_runtime": 19887.58821797371, "_timestamp": 1585617257.2210875, "_step": 106}
{"Episode reward": -99.61108295794556, "Episode length": 999, "Policy Loss": -0.6688101887702942, "Value Loss": 0.03927372023463249, "_runtime": 19888.352566719055, "_timestamp": 1585617257.9854362, "_step": 107}
{"Episode reward": 52.91398707238802, "Episode length": 472, "Policy Loss": 0.8951445817947388, "Value Loss": 20.174440383911133, "_runtime": 19888.782863855362, "_timestamp": 1585617258.4157333, "_step": 108}
{"Episode reward": 75.99733307617129, "Episode length": 241, "Policy Loss": 1.7457983493804932, "Value Loss": 40.641456604003906, "_runtime": 19890.35363149643, "_timestamp": 1585617259.986501, "_step": 109}
{"Episode reward": -99.63574882017427, "Episode length": 999, "Policy Loss": -0.7307538986206055, "Value Loss": 0.02616201713681221, "_runtime": 19891.887154340744, "_timestamp": 1585617261.5200238, "_step": 110}
{"Episode reward": -99.37724805642358, "Episode length": 999, "Policy Loss": -0.7704195380210876, "Value Loss": 0.053809523582458496, "_runtime": 19893.395092010498, "_timestamp": 1585617263.0279615, "_step": 111}
{"Episode reward": -99.42453190205714, "Episode length": 999, "Policy Loss": -0.7995913624763489, "Value Loss": 0.040006574243307114, "_runtime": 19894.44155740738, "_timestamp": 1585617264.074427, "_step": 112}
{"Episode reward": 34.89438547854604, "Episode length": 652, "Policy Loss": 0.037077367305755615, "Value Loss": 14.747986793518066, "_runtime": 19895.30488371849, "_timestamp": 1585617264.9377532, "_step": 113}
{"Episode reward": 46.342476608114765, "Episode length": 537, "Policy Loss": 0.3850474953651428, "Value Loss": 17.749723434448242, "_runtime": 19896.87791824341, "_timestamp": 1585617266.5107877, "_step": 114}
{"Episode reward": -99.71290770978673, "Episode length": 999, "Policy Loss": -0.810700535774231, "Value Loss": 0.04038763791322708, "_runtime": 19898.457111358643, "_timestamp": 1585617268.0899808, "_step": 115}
{"Episode reward": -99.5069667988676, "Episode length": 999, "Policy Loss": -0.7860468029975891, "Value Loss": 0.035762470215559006, "_runtime": 19899.865679502487, "_timestamp": 1585617269.498549, "_step": 116}
{"Episode reward": 9.662860745993868, "Episode length": 908, "Policy Loss": -0.1740473061800003, "Value Loss": 10.833266258239746, "_runtime": 19901.45841741562, "_timestamp": 1585617271.091287, "_step": 117}
{"Episode reward": -99.52575995962695, "Episode length": 999, "Policy Loss": -0.7503567337989807, "Value Loss": 0.018350766971707344, "_runtime": 19903.05921292305, "_timestamp": 1585617272.6920824, "_step": 118}
{"Episode reward": -99.58722661563668, "Episode length": 999, "Policy Loss": -0.7874718308448792, "Value Loss": 0.06237879768013954, "_runtime": 19904.36341190338, "_timestamp": 1585617273.9962814, "_step": 119}
{"Episode reward": 18.119974408445714, "Episode length": 820, "Policy Loss": -0.09572020918130875, "Value Loss": 11.628747940063477, "_runtime": 19905.695920705795, "_timestamp": 1585617275.3287902, "_step": 120}
{"Episode reward": 15.952956426961862, "Episode length": 842, "Policy Loss": 0.1370488405227661, "Value Loss": 11.315370559692383, "_runtime": 19907.324561595917, "_timestamp": 1585617276.957431, "_step": 121}
{"Episode reward": -99.31360038345356, "Episode length": 999, "Policy Loss": -0.7026274800300598, "Value Loss": 0.07855753600597382, "_runtime": 19908.900039434433, "_timestamp": 1585617278.532909, "_step": 122}
{"Episode reward": -99.50650799160219, "Episode length": 999, "Policy Loss": -0.6875596046447754, "Value Loss": 0.029822830110788345, "_runtime": 19909.892109632492, "_timestamp": 1585617279.524979, "_step": 123}
{"Episode reward": 38.00447753332495, "Episode length": 620, "Policy Loss": 0.20795607566833496, "Value Loss": 15.170857429504395, "_runtime": 19911.491360664368, "_timestamp": 1585617281.1242301, "_step": 124}
{"Episode reward": -99.62028175854218, "Episode length": 999, "Policy Loss": -0.6857898831367493, "Value Loss": 0.022896969690918922, "_runtime": 19913.090847969055, "_timestamp": 1585617282.7237175, "_step": 125}
{"Episode reward": -99.35790573206621, "Episode length": 999, "Policy Loss": -0.6726206541061401, "Value Loss": 0.07267985492944717, "_runtime": 19914.64722776413, "_timestamp": 1585617284.2800972, "_step": 126}
{"Episode reward": -99.86671795691805, "Episode length": 999, "Policy Loss": -0.6783245205879211, "Value Loss": 0.03001873753964901, "_runtime": 19915.671003341675, "_timestamp": 1585617285.3038728, "_step": 127}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.282154381275177, "Value Loss": 14.694019317626953, "_runtime": 19916.918893814087, "_timestamp": 1585617286.5517633, "_step": 128}
{"Episode reward": 21.964608248695882, "Episode length": 781, "Policy Loss": 0.12037290632724762, "Value Loss": 12.24045181274414, "_runtime": 19918.500443696976, "_timestamp": 1585617288.1333132, "_step": 129}
{"Episode reward": -99.6099593321022, "Episode length": 999, "Policy Loss": -0.7025200128555298, "Value Loss": 0.02355240471661091, "_runtime": 19920.067172288895, "_timestamp": 1585617289.7000418, "_step": 130}
{"Episode reward": -99.57235982114805, "Episode length": 999, "Policy Loss": -0.6930462718009949, "Value Loss": 0.022926591336727142, "_runtime": 19921.628869771957, "_timestamp": 1585617291.2617393, "_step": 131}
{"Episode reward": -99.47437456068445, "Episode length": 999, "Policy Loss": -0.6955395936965942, "Value Loss": 0.03600898012518883, "_runtime": 19922.735980033875, "_timestamp": 1585617292.3688495, "_step": 132}
{"Episode reward": 30.541630155504222, "Episode length": 697, "Policy Loss": 0.12573041021823883, "Value Loss": 13.83851146697998, "_runtime": 19924.31971359253, "_timestamp": 1585617293.952583, "_step": 133}
{"Episode reward": -99.76501574857981, "Episode length": 999, "Policy Loss": -0.7065099477767944, "Value Loss": 0.03136454522609711, "_runtime": 19925.91032886505, "_timestamp": 1585617295.5431983, "_step": 134}
{"Episode reward": -99.35276207805009, "Episode length": 999, "Policy Loss": -0.6253553032875061, "Value Loss": 0.01747681200504303, "_runtime": 19926.93390059471, "_timestamp": 1585617296.56677, "_step": 135}
{"Episode reward": 34.5592026651715, "Episode length": 657, "Policy Loss": 0.3789518177509308, "Value Loss": 14.60720157623291, "_runtime": 19928.242166757584, "_timestamp": 1585617297.8750362, "_step": 136}
{"Episode reward": 17.764718101017735, "Episode length": 827, "Policy Loss": 0.30982300639152527, "Value Loss": 11.672390937805176, "_runtime": 19929.82954311371, "_timestamp": 1585617299.4624126, "_step": 137}
{"Episode reward": -99.46071900986723, "Episode length": 999, "Policy Loss": -0.5678502917289734, "Value Loss": 0.05207987129688263, "_runtime": 19930.97907447815, "_timestamp": 1585617300.611944, "_step": 138}
{"Episode reward": 29.35235850596193, "Episode length": 708, "Policy Loss": 0.29634299874305725, "Value Loss": 13.377205848693848, "_runtime": 19932.54002404213, "_timestamp": 1585617302.1728935, "_step": 139}
{"Episode reward": -99.45049958105238, "Episode length": 999, "Policy Loss": -0.5506177544593811, "Value Loss": 0.025243058800697327, "_runtime": 19934.128671646118, "_timestamp": 1585617303.7615411, "_step": 140}
{"Episode reward": -99.69491605493101, "Episode length": 999, "Policy Loss": -0.5588230490684509, "Value Loss": 0.01615648716688156, "_runtime": 19935.680452108383, "_timestamp": 1585617305.3133216, "_step": 141}
{"Episode reward": -99.75796300793162, "Episode length": 999, "Policy Loss": -0.5612345337867737, "Value Loss": 0.019954388961195946, "_runtime": 19937.26971721649, "_timestamp": 1585617306.9025867, "_step": 142}
{"Episode reward": -99.66001171342657, "Episode length": 999, "Policy Loss": -0.5577250719070435, "Value Loss": 0.015206236392259598, "_runtime": 19938.849042654037, "_timestamp": 1585617308.4819121, "_step": 143}
{"Episode reward": -99.73308805453895, "Episode length": 999, "Policy Loss": -0.6026347279548645, "Value Loss": 0.05867492035031319, "_runtime": 19940.43100142479, "_timestamp": 1585617310.063871, "_step": 144}
{"Episode reward": -99.5426809566722, "Episode length": 999, "Policy Loss": -0.6099984645843506, "Value Loss": 0.42113667726516724, "_runtime": 19941.33657336235, "_timestamp": 1585617310.9694428, "_step": 145}
{"Episode reward": 43.949660311219695, "Episode length": 562, "Policy Loss": 0.5327199697494507, "Value Loss": 17.129472732543945, "_runtime": 19941.82714867592, "_timestamp": 1585617311.4600182, "_step": 146}
{"Episode reward": 71.33731833538027, "Episode length": 287, "Policy Loss": 1.444565773010254, "Value Loss": 32.74505615234375, "_runtime": 19943.411343812943, "_timestamp": 1585617313.0442133, "_step": 147}
{"Episode reward": -99.52469634765738, "Episode length": 999, "Policy Loss": -0.5810683369636536, "Value Loss": 0.21200649440288544, "_runtime": 19944.958563804626, "_timestamp": 1585617314.5914333, "_step": 148}
{"Episode reward": -99.46857126043768, "Episode length": 999, "Policy Loss": -0.4920448958873749, "Value Loss": 0.016006169840693474, "_runtime": 19946.072937965393, "_timestamp": 1585617315.7058074, "_step": 149}
{"Episode reward": 26.245064263977028, "Episode length": 740, "Policy Loss": 0.29638922214508057, "Value Loss": 13.02691650390625, "_runtime": 19947.64945268631, "_timestamp": 1585617317.2823222, "_step": 150}
{"Episode reward": -99.53993421875958, "Episode length": 999, "Policy Loss": -0.5209351181983948, "Value Loss": 0.025804081931710243, "_runtime": 19949.231451511383, "_timestamp": 1585617318.864321, "_step": 151}
{"Episode reward": -99.69287534500916, "Episode length": 999, "Policy Loss": -0.4393097758293152, "Value Loss": 0.04603972285985947, "_runtime": 19950.768104314804, "_timestamp": 1585617320.4009738, "_step": 152}
{"Episode reward": -99.55282480291326, "Episode length": 999, "Policy Loss": -0.46258315443992615, "Value Loss": 0.0770675539970398, "_runtime": 19951.76021671295, "_timestamp": 1585617321.3930862, "_step": 153}
{"Episode reward": 38.243649353412316, "Episode length": 619, "Policy Loss": 0.5702604055404663, "Value Loss": 15.402481079101562, "_runtime": 19953.352694272995, "_timestamp": 1585617322.9855638, "_step": 154}
{"Episode reward": -99.41313942725992, "Episode length": 999, "Policy Loss": -0.47102370858192444, "Value Loss": 0.028406815603375435, "_runtime": 19954.23396706581, "_timestamp": 1585617323.8668365, "_step": 155}
{"Episode reward": 47.22749704288531, "Episode length": 528, "Policy Loss": 0.7941988706588745, "Value Loss": 17.409164428710938, "_runtime": 19955.78972697258, "_timestamp": 1585617325.4225965, "_step": 156}
{"Episode reward": -99.55887600649157, "Episode length": 999, "Policy Loss": -0.5252233147621155, "Value Loss": 0.03809702396392822, "_runtime": 19956.204889059067, "_timestamp": 1585617325.8377585, "_step": 157}
{"Episode reward": 76.83344895000913, "Episode length": 232, "Policy Loss": 1.940191626548767, "Value Loss": 41.86501693725586, "_runtime": 19957.76175713539, "_timestamp": 1585617327.3946266, "_step": 158}
{"Episode reward": -99.5502228255661, "Episode length": 999, "Policy Loss": -0.5304614901542664, "Value Loss": 0.047025166451931, "_runtime": 19959.345505952835, "_timestamp": 1585617328.9783754, "_step": 159}
{"Episode reward": -99.50577059145442, "Episode length": 999, "Policy Loss": -0.5019407868385315, "Value Loss": 0.012590373866260052, "_runtime": 19960.863201856613, "_timestamp": 1585617330.4960713, "_step": 160}
{"Episode reward": -99.7080235422284, "Episode length": 999, "Policy Loss": -0.4926779866218567, "Value Loss": 0.010745324194431305, "_runtime": 19962.45724630356, "_timestamp": 1585617332.0901158, "_step": 161}
{"Episode reward": -99.70871891111462, "Episode length": 999, "Policy Loss": -0.5077174305915833, "Value Loss": 0.07820965349674225, "_runtime": 19964.037803649902, "_timestamp": 1585617333.6706731, "_step": 162}
{"Episode reward": -99.612959635332, "Episode length": 999, "Policy Loss": -0.500920295715332, "Value Loss": 0.037777699530124664, "_runtime": 19965.359337091446, "_timestamp": 1585617334.9922066, "_step": 163}
{"Episode reward": 14.821614051108753, "Episode length": 853, "Policy Loss": 0.22156375646591187, "Value Loss": 10.865891456604004, "_runtime": 19965.982706546783, "_timestamp": 1585617335.615576, "_step": 164}
{"Episode reward": 62.615101882087515, "Episode length": 374, "Policy Loss": 1.02977454662323, "Value Loss": 25.514862060546875, "_runtime": 19967.57448720932, "_timestamp": 1585617337.2073567, "_step": 165}
{"Episode reward": -99.4652484309511, "Episode length": 999, "Policy Loss": -0.47182807326316833, "Value Loss": 0.014601089060306549, "_runtime": 19969.147123336792, "_timestamp": 1585617338.7799928, "_step": 166}
{"Episode reward": -99.87055425792794, "Episode length": 999, "Policy Loss": -0.48837801814079285, "Value Loss": 0.013414434157311916, "_runtime": 19970.241684675217, "_timestamp": 1585617339.8745542, "_step": 167}
{"Episode reward": 28.362035318124782, "Episode length": 719, "Policy Loss": 0.21110765635967255, "Value Loss": 13.119694709777832, "_runtime": 19971.836033582687, "_timestamp": 1585617341.468903, "_step": 168}
{"Episode reward": -99.37913990422976, "Episode length": 999, "Policy Loss": -0.5227435827255249, "Value Loss": 0.03135326877236366, "_runtime": 19973.411645412445, "_timestamp": 1585617343.044515, "_step": 169}
{"Episode reward": -99.62157608113603, "Episode length": 999, "Policy Loss": -0.5284309387207031, "Value Loss": 0.2882637679576874, "_runtime": 19973.949472427368, "_timestamp": 1585617343.582342, "_step": 170}
{"Episode reward": 66.8999999999998, "Episode length": 331, "Policy Loss": 1.3401461839675903, "Value Loss": 28.20904541015625, "_runtime": 19975.46095776558, "_timestamp": 1585617345.0938272, "_step": 171}
{"Episode reward": 5.551204673196111, "Episode length": 948, "Policy Loss": 0.32357338070869446, "Value Loss": 9.927314758300781, "_runtime": 19976.107048034668, "_timestamp": 1585617345.7399175, "_step": 172}
{"Episode reward": 60.76248672077135, "Episode length": 395, "Policy Loss": 0.9684051275253296, "Value Loss": 23.58554458618164, "_runtime": 19977.18179154396, "_timestamp": 1585617346.814661, "_step": 173}
{"Episode reward": 29.712134911655156, "Episode length": 707, "Policy Loss": 0.285162091255188, "Value Loss": 12.984209060668945, "_runtime": 19977.73966860771, "_timestamp": 1585617347.372538, "_step": 174}
{"Episode reward": 69.29925074883343, "Episode length": 308, "Policy Loss": 1.3325380086898804, "Value Loss": 29.54892349243164, "_runtime": 19978.78045630455, "_timestamp": 1585617348.4133258, "_step": 175}
{"Episode reward": 32.59321544852493, "Episode length": 679, "Policy Loss": 0.15561716258525848, "Value Loss": 14.12686538696289, "_runtime": 19980.337770700455, "_timestamp": 1585617349.9706402, "_step": 176}
{"Episode reward": -99.84638022333243, "Episode length": 999, "Policy Loss": -0.568501353263855, "Value Loss": 0.029783818870782852, "_runtime": 19981.84741783142, "_timestamp": 1585617351.4802873, "_step": 177}
{"Episode reward": -99.75077957273905, "Episode length": 999, "Policy Loss": -0.6116946935653687, "Value Loss": 0.023208266124129295, "_runtime": 19983.40159344673, "_timestamp": 1585617353.034463, "_step": 178}
{"Episode reward": -99.55939423295649, "Episode length": 999, "Policy Loss": -0.6201509237289429, "Value Loss": 0.10556067526340485, "_runtime": 19984.357288122177, "_timestamp": 1585617353.9901576, "_step": 179}
{"Episode reward": 40.2048776760517, "Episode length": 600, "Policy Loss": 0.2362721711397171, "Value Loss": 15.861136436462402, "_runtime": 19985.923548221588, "_timestamp": 1585617355.5564177, "_step": 180}
{"Episode reward": -99.635350385173, "Episode length": 999, "Policy Loss": -0.6535418629646301, "Value Loss": 0.24283654987812042, "_runtime": 19987.422981500626, "_timestamp": 1585617357.055851, "_step": 181}
{"Episode reward": 5.122612263030561, "Episode length": 949, "Policy Loss": -0.021708935499191284, "Value Loss": 9.935712814331055, "_runtime": 19988.96760725975, "_timestamp": 1585617358.6004767, "_step": 182}
{"Episode reward": -99.71623878792022, "Episode length": 999, "Policy Loss": -0.5511417388916016, "Value Loss": 0.07111087441444397, "_runtime": 19990.5416431427, "_timestamp": 1585617360.1745126, "_step": 183}
{"Episode reward": -99.53994261974375, "Episode length": 999, "Policy Loss": -0.5084653496742249, "Value Loss": 1.0621074438095093, "_runtime": 19991.675164222717, "_timestamp": 1585617361.3080337, "_step": 184}
{"Episode reward": 29.72739559156443, "Episode length": 707, "Policy Loss": 0.2605282962322235, "Value Loss": 13.390545845031738, "_runtime": 19992.681775331497, "_timestamp": 1585617362.3146448, "_step": 185}
{"Episode reward": 36.54552449159611, "Episode length": 635, "Policy Loss": 0.2886328399181366, "Value Loss": 15.114476203918457, "_runtime": 19994.25672698021, "_timestamp": 1585617363.8895965, "_step": 186}
{"Episode reward": -99.16639990357555, "Episode length": 999, "Policy Loss": -0.5971121191978455, "Value Loss": 0.07655113935470581, "_runtime": 19995.81967830658, "_timestamp": 1585617365.4525478, "_step": 187}
{"Episode reward": -99.78926099829701, "Episode length": 999, "Policy Loss": -0.7752197980880737, "Value Loss": 0.29024559259414673, "_runtime": 19997.369871616364, "_timestamp": 1585617367.002741, "_step": 188}
{"Episode reward": -99.63047142391451, "Episode length": 999, "Policy Loss": -0.5893696546554565, "Value Loss": 0.04975017160177231, "_runtime": 19998.309178829193, "_timestamp": 1585617367.9420483, "_step": 189}
{"Episode reward": 41.35642702053682, "Episode length": 589, "Policy Loss": 0.7290831208229065, "Value Loss": 16.243864059448242, "_runtime": 19999.883803844452, "_timestamp": 1585617369.5166733, "_step": 190}
{"Episode reward": -99.60475314078948, "Episode length": 999, "Policy Loss": -0.5060322880744934, "Value Loss": 0.12427404522895813, "_runtime": 20001.504150867462, "_timestamp": 1585617371.1370203, "_step": 191}
{"Episode reward": -99.7187227444069, "Episode length": 999, "Policy Loss": -0.5107702016830444, "Value Loss": 0.08813716471195221, "_runtime": 20002.44487309456, "_timestamp": 1585617372.0777426, "_step": 192}
{"Episode reward": 39.8555695672275, "Episode length": 605, "Policy Loss": 0.44935715198516846, "Value Loss": 15.48514175415039, "_runtime": 20004.027614593506, "_timestamp": 1585617373.660484, "_step": 193}
{"Episode reward": -99.68153974143796, "Episode length": 999, "Policy Loss": -0.4994015097618103, "Value Loss": 0.1667139083147049, "_runtime": 20005.12212061882, "_timestamp": 1585617374.75499, "_step": 194}
{"Episode reward": 32.00736936160787, "Episode length": 680, "Policy Loss": 0.24721257388591766, "Value Loss": 13.991752624511719, "_runtime": 20006.655615329742, "_timestamp": 1585617376.2884848, "_step": 195}
{"Episode reward": 1.2994478597377253, "Episode length": 989, "Policy Loss": 0.07506182044744492, "Value Loss": 9.39319133758545, "_runtime": 20008.255355596542, "_timestamp": 1585617377.888225, "_step": 196}
{"Episode reward": -99.66920091806139, "Episode length": 999, "Policy Loss": -0.5079924464225769, "Value Loss": 0.03638143092393875, "_runtime": 20009.814736127853, "_timestamp": 1585617379.4476056, "_step": 197}
{"Episode reward": -99.62066158315872, "Episode length": 999, "Policy Loss": -0.46125394105911255, "Value Loss": 0.024743445217609406, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377, 0.07950127124786377]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5774759650230408, -0.5613387823104858, -0.5452015995979309, -0.529064416885376, -0.5129272937774658, -0.4967901110649109, -0.48065292835235596, -0.464515745639801, -0.4483785629272461, -0.43224141001701355, -0.4161042273044586, -0.3999670743942261, -0.38382989168167114, -0.3676927089691162, -0.3515555262565613, -0.33541834354400635, -0.3192811906337738, -0.30314400792121887, -0.28700685501098633, -0.2708696722984314, -0.25473248958587646, -0.23859533667564392, -0.222458153963089, -0.20632097125053406, -0.1901838183403015, -0.17404663562774658, -0.15790945291519165, -0.14177227020263672, -0.12563511729240417, -0.10949793457984924, -0.09336075186729431, -0.07722359895706177, -0.061086416244506836, -0.044949233531951904, -0.028812050819396973, -0.012674868106842041, 0.0034622550010681152, 0.019599437713623047, 0.03573662042617798, 0.05187380313873291, 0.06801098585128784, 0.08414816856384277, 0.10028529167175293, 0.11642247438430786, 0.1325596570968628, 0.14869683980941772, 0.16483402252197266, 0.1809712052345276, 0.19710832834243774, 0.21324551105499268, 0.2293826937675476, 0.24551987648010254, 0.26165705919265747, 0.2777942419052124, 0.29393142461776733, 0.3100685477256775, 0.3262057304382324, 0.34234291315078735, 0.3584800958633423, 0.3746172785758972, 0.39075446128845215, 0.4068915843963623, 0.42302876710891724, 0.43916600942611694, 0.4553031325340271]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [2.65616165506799e-07, 0.0025240585673600435, 0.005047851242125034, 0.007571644149720669, 0.010095437057316303, 0.012619229964911938, 0.015143022872507572, 0.01766681671142578, 0.020190609619021416, 0.02271440252661705, 0.025238195434212685, 0.02776198834180832, 0.030285781249403954, 0.03280957415699959, 0.03533336520195007, 0.03785715624690056, 0.04038095101714134, 0.042904745787382126, 0.04542853683233261, 0.047952327877283096, 0.05047612264752388, 0.052999917417764664, 0.05552370846271515, 0.058047499507665634, 0.06057129427790642, 0.0630950927734375, 0.06561888754367828, 0.06814267486333847, 0.07066646963357925, 0.07319026440382004, 0.07571405172348022, 0.07823784649372101, 0.08076164126396179, 0.08328543603420258, 0.08580923080444336, 0.08833301812410355, 0.09085681289434433, 0.09338060766458511, 0.0959043949842453, 0.09842818975448608, 0.10095198452472687, 0.10347577929496765, 0.10599957406520844, 0.10852336138486862, 0.1110471561551094, 0.11357095092535019, 0.11609473824501038, 0.11861853301525116, 0.12114232778549194, 0.12366612255573273, 0.1261899173259735, 0.1287137120962143, 0.13123750686645508, 0.13376128673553467, 0.13628508150577545, 0.13880887627601624, 0.14133267104625702, 0.1438564658164978, 0.1463802605867386, 0.14890405535697937, 0.15142783522605896, 0.15395162999629974, 0.15647542476654053, 0.1589992195367813, 0.1615230143070221]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 2.0, 1.0, 7.0, 6.0, 4.0, 10.0, 9.0, 3.0, 6.0, 24.0, 17.0, 8.0, 37.0, 22.0, 6.0, 9.0, 26.0, 162.0, 13.0, 9.0, 12.0, 3.0, 4.0, 2.0, 5.0, 3.0, 11.0, 4.0, 8.0, 12.0, 7.0, 5.0, 5.0, 1.0, 4.0, 2.0, 6.0, 8.0, 1.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.10432906448841095, -0.09914939850568771, -0.09396973252296448, -0.08879006654024124, -0.083610400557518, -0.07843073457479477, -0.07325106859207153, -0.0680714026093483, -0.06289173662662506, -0.057712070643901825, -0.05253240466117859, -0.04735273867845535, -0.04217307269573212, -0.03699340671300888, -0.031813740730285645, -0.02663407474756241, -0.021454408764839172, -0.016274742782115936, -0.0110950767993927, -0.005915410816669464, -0.000735744833946228, 0.004443921148777008, 0.009623587131500244, 0.01480325311422348, 0.019982919096946716, 0.02516259253025055, 0.03034225106239319, 0.03552190959453583, 0.04070158302783966, 0.045881256461143494, 0.05106091499328613, 0.05624057352542877, 0.061420246958732605, 0.06659992039203644, 0.07177957892417908, 0.07695923745632172, 0.08213891088962555, 0.08731858432292938, 0.09249824285507202, 0.09767790138721466, 0.1028575748205185, 0.10803724825382233, 0.11321690678596497, 0.1183965653181076, 0.12357623875141144, 0.12875591218471527, 0.1339355707168579, 0.13911522924900055, 0.14429490268230438, 0.14947457611560822, 0.15465424954891205, 0.1598338931798935, 0.16501356661319733, 0.17019324004650116, 0.1753728836774826, 0.18055255711078644, 0.18573223054409027, 0.1909119039773941, 0.19609157741069794, 0.20127122104167938, 0.20645089447498322, 0.21163056790828705, 0.2168102115392685, 0.22198988497257233, 0.22716955840587616]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0], "bins": [-1.2846317291259766, -1.2534970045089722, -1.2223622798919678, -1.1912274360656738, -1.1600927114486694, -1.128957986831665, -1.0978232622146606, -1.0666885375976562, -1.0355536937713623, -1.004418969154358, -0.9732842445373535, -0.9421494603157043, -0.9110147356987, -0.8798799514770508, -0.8487452268600464, -0.817610502243042, -0.7864757180213928, -0.7553409934043884, -0.7242062091827393, -0.6930714845657349, -0.6619367003440857, -0.6308019757270813, -0.5996671915054321, -0.5685324668884277, -0.5373977422714233, -0.5062629580497742, -0.4751282334327698, -0.4439934492111206, -0.4128587245941162, -0.38172394037246704, -0.35058921575546265, -0.3194544315338135, -0.2883197069168091, -0.2571849822998047, -0.2260502576828003, -0.19491541385650635, -0.16378068923950195, -0.13264596462249756, -0.10151124000549316, -0.07037639617919922, -0.039241671562194824, -0.00810694694519043, 0.023027777671813965, 0.05416250228881836, 0.0852973461151123, 0.1164320707321167, 0.1475667953491211, 0.1787015199661255, 0.20983624458312988, 0.24097108840942383, 0.2721058130264282, 0.3032405376434326, 0.334375262260437, 0.36551010608673096, 0.39664483070373535, 0.42777955532073975, 0.45891427993774414, 0.49004900455474854, 0.5211838483810425, 0.5523185729980469, 0.5834532976150513, 0.6145880222320557, 0.6457228660583496, 0.676857590675354, 0.7079923152923584]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 2.0, 5.0, 0.0, 4.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0], "bins": [-1.088074803352356, -1.0547986030578613, -1.0215222835540771, -0.9882460832595825, -0.9549698233604431, -0.9216935634613037, -0.8884173631668091, -0.8551411032676697, -0.8218648433685303, -0.7885885834693909, -0.7553123235702515, -0.7220361232757568, -0.6887598633766174, -0.655483603477478, -0.6222074031829834, -0.588931143283844, -0.5556548833847046, -0.5223786234855652, -0.4891023635864258, -0.45582616329193115, -0.42254990339279175, -0.38927364349365234, -0.3559974431991577, -0.3227211833000183, -0.2894449234008789, -0.2561686635017395, -0.2228924036026001, -0.18961620330810547, -0.15633994340896606, -0.12306368350982666, -0.08978748321533203, -0.05651116371154785, -0.023234963417053223, 0.010041236877441406, 0.043317556381225586, 0.07659375667572021, 0.1098700761795044, 0.14314627647399902, 0.17642247676849365, 0.20969879627227783, 0.24297499656677246, 0.2762511968612671, 0.30952751636505127, 0.3428037166595459, 0.3760799169540405, 0.4093562364578247, 0.44263243675231934, 0.4759087562561035, 0.5091849565505981, 0.5424611568450928, 0.575737476348877, 0.6090136766433716, 0.6422899961471558, 0.6755661964416504, 0.708842396736145, 0.7421187162399292, 0.7753949165344238, 0.8086711168289185, 0.8419474363327026, 0.8752236366271973, 0.9084998369216919, 0.9417761564254761, 0.9750524759292603, 1.0083285570144653, 1.0416048765182495]}, "_runtime": 20011.392156362534, "_timestamp": 1585617381.0250258, "_step": 198}
{"Episode reward": -99.57239715870098, "Episode length": 999, "Policy Loss": -0.4380667507648468, "Value Loss": 0.12096881866455078, "_runtime": 20012.709708929062, "_timestamp": 1585617382.3425784, "_step": 199}
{"Episode reward": 17.572622879076917, "Episode length": 825, "Policy Loss": 0.261643648147583, "Value Loss": 11.032451629638672, "_runtime": 20014.30050110817, "_timestamp": 1585617383.9333706, "_step": 200}
{"Episode reward": -99.61685051870488, "Episode length": 999, "Policy Loss": -0.40352457761764526, "Value Loss": 0.0970442071557045, "_runtime": 20015.594358682632, "_timestamp": 1585617385.2272282, "_step": 201}
{"Episode reward": 19.09015745333778, "Episode length": 810, "Policy Loss": 0.3482024371623993, "Value Loss": 11.45687484741211, "_runtime": 20017.054426193237, "_timestamp": 1585617386.6872957, "_step": 202}
{"Episode reward": 8.227306656864883, "Episode length": 918, "Policy Loss": 0.2550179660320282, "Value Loss": 10.069798469543457, "_runtime": 20018.63863182068, "_timestamp": 1585617388.2715013, "_step": 203}
{"Episode reward": -99.71739846088902, "Episode length": 999, "Policy Loss": -0.3331950008869171, "Value Loss": 0.009190806187689304, "_runtime": 20020.209041118622, "_timestamp": 1585617389.8419106, "_step": 204}
{"Episode reward": -99.67208549436188, "Episode length": 999, "Policy Loss": -0.38656607270240784, "Value Loss": 0.10258089751005173, "_runtime": 20021.79355955124, "_timestamp": 1585617391.426429, "_step": 205}
{"Episode reward": -99.67639585360891, "Episode length": 999, "Policy Loss": -0.3227061927318573, "Value Loss": 0.08829638361930847, "_runtime": 20023.380522489548, "_timestamp": 1585617393.013392, "_step": 206}
{"Episode reward": -99.69242211750104, "Episode length": 999, "Policy Loss": -0.33202868700027466, "Value Loss": 0.03920123353600502, "_runtime": 20024.961312055588, "_timestamp": 1585617394.5941815, "_step": 207}
{"Episode reward": -99.43092799236626, "Episode length": 999, "Policy Loss": -0.2523643970489502, "Value Loss": 0.02757103368639946, "_runtime": 20026.604824066162, "_timestamp": 1585617396.2376935, "_step": 208}
{"Episode reward": -99.70255833767447, "Episode length": 999, "Policy Loss": -0.2516317665576935, "Value Loss": 0.032492589205503464, "_runtime": 20028.189074993134, "_timestamp": 1585617397.8219445, "_step": 209}
{"Episode reward": -99.70901641838144, "Episode length": 999, "Policy Loss": -0.25088149309158325, "Value Loss": 0.09593519568443298, "_runtime": 20029.2493288517, "_timestamp": 1585617398.8821983, "_step": 210}
{"Episode reward": 33.76512966452488, "Episode length": 666, "Policy Loss": 0.5477349758148193, "Value Loss": 13.854347229003906, "_runtime": 20030.836573123932, "_timestamp": 1585617400.4694426, "_step": 211}
{"Episode reward": -99.7103443621804, "Episode length": 999, "Policy Loss": -0.2662951946258545, "Value Loss": 0.020288312807679176, "_runtime": 20032.104378461838, "_timestamp": 1585617401.737248, "_step": 212}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.42462262511253357, "Value Loss": 11.84854793548584, "_runtime": 20033.67796421051, "_timestamp": 1585617403.3108337, "_step": 213}
{"Episode reward": -99.71725753403014, "Episode length": 999, "Policy Loss": -0.2950884699821472, "Value Loss": 0.03671632334589958, "_runtime": 20035.283205747604, "_timestamp": 1585617404.9160752, "_step": 214}
{"Episode reward": -99.56747076999027, "Episode length": 999, "Policy Loss": -0.34596505761146545, "Value Loss": 0.0866951122879982, "_runtime": 20035.668333768845, "_timestamp": 1585617405.3012033, "_step": 215}
{"Episode reward": 78.81308691198934, "Episode length": 213, "Policy Loss": 2.3830575942993164, "Value Loss": 42.78395462036133, "_runtime": 20037.25253367424, "_timestamp": 1585617406.8854032, "_step": 216}
{"Episode reward": -99.74210485291995, "Episode length": 999, "Policy Loss": -0.2412947714328766, "Value Loss": 0.009076150134205818, "_runtime": 20038.857053041458, "_timestamp": 1585617408.4899225, "_step": 217}
{"Episode reward": -99.57583797958658, "Episode length": 999, "Policy Loss": -0.2181357592344284, "Value Loss": 0.09397076815366745, "_runtime": 20040.379631996155, "_timestamp": 1585617410.0125015, "_step": 218}
{"Episode reward": -99.44654076664457, "Episode length": 999, "Policy Loss": -0.21811503171920776, "Value Loss": 0.06278729438781738, "_runtime": 20041.97547698021, "_timestamp": 1585617411.6083465, "_step": 219}
{"Episode reward": -99.58743459373807, "Episode length": 999, "Policy Loss": -0.25413188338279724, "Value Loss": 0.07308505475521088, "_runtime": 20042.986216783524, "_timestamp": 1585617412.6190863, "_step": 220}
{"Episode reward": 37.39981733036632, "Episode length": 627, "Policy Loss": 0.634350061416626, "Value Loss": 14.183738708496094, "_runtime": 20044.553481578827, "_timestamp": 1585617414.186351, "_step": 221}
{"Episode reward": -99.7821492353091, "Episode length": 999, "Policy Loss": -0.43492722511291504, "Value Loss": 0.11190761625766754, "_runtime": 20045.621312856674, "_timestamp": 1585617415.2541823, "_step": 222}
{"Episode reward": 34.523963430828545, "Episode length": 660, "Policy Loss": 0.63946533203125, "Value Loss": 15.657151222229004, "_runtime": 20047.077607154846, "_timestamp": 1585617416.7104766, "_step": 223}
{"Episode reward": 7.692840676464641, "Episode length": 925, "Policy Loss": 0.29974430799484253, "Value Loss": 10.448837280273438, "_runtime": 20047.89465546608, "_timestamp": 1585617417.527525, "_step": 224}
{"Episode reward": 49.648223525448266, "Episode length": 504, "Policy Loss": 1.768258810043335, "Value Loss": 20.045312881469727, "_runtime": 20048.501502752304, "_timestamp": 1585617418.1343722, "_step": 225}
{"Episode reward": 62.74026851102219, "Episode length": 374, "Policy Loss": 1.3717122077941895, "Value Loss": 25.394454956054688, "_runtime": 20048.929756641388, "_timestamp": 1585617418.5626261, "_step": 226}
{"Episode reward": 75.31100954452405, "Episode length": 249, "Policy Loss": 1.7978004217147827, "Value Loss": 39.08562088012695, "_runtime": 20050.522027015686, "_timestamp": 1585617420.1548965, "_step": 227}
{"Episode reward": -99.58380989896112, "Episode length": 999, "Policy Loss": -0.6313141584396362, "Value Loss": 0.6390812397003174, "_runtime": 20051.91019129753, "_timestamp": 1585617421.5430608, "_step": 228}
{"Episode reward": 9.50425278699926, "Episode length": 906, "Policy Loss": 0.21979814767837524, "Value Loss": 10.62043285369873, "_runtime": 20053.429631471634, "_timestamp": 1585617423.062501, "_step": 229}
{"Episode reward": -99.41704005783265, "Episode length": 999, "Policy Loss": -0.33626776933670044, "Value Loss": 0.17195521295070648, "_runtime": 20054.535926103592, "_timestamp": 1585617424.1687956, "_step": 230}
{"Episode reward": 31.280246760864614, "Episode length": 689, "Policy Loss": 0.5562061071395874, "Value Loss": 13.114213943481445, "_runtime": 20056.11829471588, "_timestamp": 1585617425.7511642, "_step": 231}
{"Episode reward": -99.72060006406835, "Episode length": 999, "Policy Loss": -0.32078152894973755, "Value Loss": 0.06015665829181671, "_runtime": 20057.693958997726, "_timestamp": 1585617427.3268285, "_step": 232}
{"Episode reward": -99.80879662182276, "Episode length": 999, "Policy Loss": -0.2810271680355072, "Value Loss": 0.3891516923904419, "_runtime": 20059.262452602386, "_timestamp": 1585617428.895322, "_step": 233}
{"Episode reward": -99.31803758807227, "Episode length": 999, "Policy Loss": -0.3217605948448181, "Value Loss": 0.15252785384655, "_runtime": 20060.232909202576, "_timestamp": 1585617429.8657787, "_step": 234}
{"Episode reward": 40.21690420982138, "Episode length": 599, "Policy Loss": 0.5413811206817627, "Value Loss": 15.734370231628418, "_runtime": 20061.670881032944, "_timestamp": 1585617431.3037505, "_step": 235}
{"Episode reward": 8.550157916989164, "Episode length": 916, "Policy Loss": 0.3618406355381012, "Value Loss": 10.523427963256836, "_runtime": 20063.258516550064, "_timestamp": 1585617432.891386, "_step": 236}
{"Episode reward": -99.67609157230478, "Episode length": 999, "Policy Loss": -0.3765513300895691, "Value Loss": 0.09569378197193146, "_runtime": 20064.81468605995, "_timestamp": 1585617434.4475555, "_step": 237}
{"Episode reward": -99.46662970368642, "Episode length": 999, "Policy Loss": -0.5035654306411743, "Value Loss": 0.024741007015109062, "_runtime": 20065.92580151558, "_timestamp": 1585617435.558671, "_step": 238}
{"Episode reward": 29.541512221464387, "Episode length": 707, "Policy Loss": 0.30735787749290466, "Value Loss": 13.548748016357422, "_runtime": 20067.512902259827, "_timestamp": 1585617437.1457717, "_step": 239}
{"Episode reward": -99.64225107611716, "Episode length": 999, "Policy Loss": -0.5759679675102234, "Value Loss": 0.10121700167655945, "_runtime": 20069.09341788292, "_timestamp": 1585617438.7262874, "_step": 240}
{"Episode reward": -99.42100336148734, "Episode length": 999, "Policy Loss": -0.60106360912323, "Value Loss": 0.22227494418621063, "_runtime": 20070.009585380554, "_timestamp": 1585617439.6424549, "_step": 241}
{"Episode reward": 41.462638985271944, "Episode length": 586, "Policy Loss": 0.4059820771217346, "Value Loss": 16.536827087402344, "_runtime": 20070.6483168602, "_timestamp": 1585617440.2811863, "_step": 242}
{"Episode reward": 61.09126877577482, "Episode length": 390, "Policy Loss": 0.9899061918258667, "Value Loss": 23.51975440979004, "_runtime": 20072.22242975235, "_timestamp": 1585617441.8552992, "_step": 243}
{"Episode reward": -99.79044109452958, "Episode length": 999, "Policy Loss": -0.6430291533470154, "Value Loss": 0.09506915509700775, "_runtime": 20073.806612968445, "_timestamp": 1585617443.4394825, "_step": 244}
{"Episode reward": -99.65297687369028, "Episode length": 999, "Policy Loss": -0.5529627799987793, "Value Loss": 0.017235860228538513, "_runtime": 20075.332531690598, "_timestamp": 1585617444.9654012, "_step": 245}
{"Episode reward": -99.46590875014815, "Episode length": 999, "Policy Loss": -0.5577637553215027, "Value Loss": 0.02004188485443592, "_runtime": 20075.979266643524, "_timestamp": 1585617445.6121361, "_step": 246}
{"Episode reward": 61.16454098340446, "Episode length": 390, "Policy Loss": 1.001950979232788, "Value Loss": 23.795787811279297, "_runtime": 20076.78586101532, "_timestamp": 1585617446.4187305, "_step": 247}
{"Episode reward": 49.73138348137684, "Episode length": 504, "Policy Loss": 0.5600677728652954, "Value Loss": 18.755971908569336, "_runtime": 20078.26553583145, "_timestamp": 1585617447.8984053, "_step": 248}
{"Episode reward": 6.313169364213124, "Episode length": 940, "Policy Loss": 0.011105936951935291, "Value Loss": 10.117178916931152, "_runtime": 20079.68256664276, "_timestamp": 1585617449.3154361, "_step": 249}
{"Episode reward": 7.147276396433426, "Episode length": 930, "Policy Loss": -0.057079464197158813, "Value Loss": 10.190457344055176, "_runtime": 20081.219146728516, "_timestamp": 1585617450.8520162, "_step": 250}
{"Episode reward": -99.65856351350529, "Episode length": 999, "Policy Loss": -0.7293738722801208, "Value Loss": 0.06389403343200684, "_runtime": 20082.79580783844, "_timestamp": 1585617452.4286773, "_step": 251}
{"Episode reward": -99.78312664571573, "Episode length": 999, "Policy Loss": -0.6616172194480896, "Value Loss": 0.11140154302120209, "_runtime": 20084.35366678238, "_timestamp": 1585617453.9865363, "_step": 252}
{"Episode reward": -99.45429596784389, "Episode length": 999, "Policy Loss": -0.7864962220191956, "Value Loss": 0.026083536446094513, "_runtime": 20084.980667829514, "_timestamp": 1585617454.6135373, "_step": 253}
{"Episode reward": 61.69062707424137, "Episode length": 384, "Policy Loss": 0.5592647790908813, "Value Loss": 23.591577529907227, "_runtime": 20085.489574193954, "_timestamp": 1585617455.1224437, "_step": 254}
{"Episode reward": 69.90022114871374, "Episode length": 303, "Policy Loss": 1.1397838592529297, "Value Loss": 30.18311309814453, "_runtime": 20087.07146215439, "_timestamp": 1585617456.7043316, "_step": 255}
{"Episode reward": -99.55466797680573, "Episode length": 999, "Policy Loss": -0.8749879002571106, "Value Loss": 0.028543245047330856, "_runtime": 20088.596923351288, "_timestamp": 1585617458.2297928, "_step": 256}
{"Episode reward": -99.640315425949, "Episode length": 999, "Policy Loss": -0.9118183255195618, "Value Loss": 0.034069228917360306, "_runtime": 20089.852046966553, "_timestamp": 1585617459.4849164, "_step": 257}
{"Episode reward": 16.90446549588276, "Episode length": 832, "Policy Loss": -0.26826196908950806, "Value Loss": 11.192363739013672, "_runtime": 20091.02818608284, "_timestamp": 1585617460.6610556, "_step": 258}
{"Episode reward": 25.898527102667074, "Episode length": 744, "Policy Loss": -0.15268534421920776, "Value Loss": 12.270437240600586, "_runtime": 20091.797204732895, "_timestamp": 1585617461.4300742, "_step": 259}
{"Episode reward": 51.95401945202571, "Episode length": 482, "Policy Loss": 0.4447242319583893, "Value Loss": 19.31943130493164, "_runtime": 20093.35188102722, "_timestamp": 1585617462.9847505, "_step": 260}
{"Episode reward": -99.80551822653366, "Episode length": 999, "Policy Loss": -0.900124192237854, "Value Loss": 0.13952720165252686, "_runtime": 20094.922852277756, "_timestamp": 1585617464.5557218, "_step": 261}
{"Episode reward": -99.69537425500464, "Episode length": 999, "Policy Loss": -0.9465000629425049, "Value Loss": 0.04575366526842117, "_runtime": 20095.561345100403, "_timestamp": 1585617465.1942146, "_step": 262}
{"Episode reward": 59.089788746885795, "Episode length": 410, "Policy Loss": 0.3363889753818512, "Value Loss": 22.043642044067383, "_runtime": 20097.11851477623, "_timestamp": 1585617466.7513843, "_step": 263}
{"Episode reward": -99.71541500271857, "Episode length": 999, "Policy Loss": -0.9909205436706543, "Value Loss": 0.0370776392519474, "_runtime": 20098.389581680298, "_timestamp": 1585617468.0224512, "_step": 264}
{"Episode reward": 22.697833907138673, "Episode length": 775, "Policy Loss": -0.2959256172180176, "Value Loss": 10.91640853881836, "_runtime": 20099.91202068329, "_timestamp": 1585617469.5448902, "_step": 265}
{"Episode reward": -99.89168290421809, "Episode length": 999, "Policy Loss": -1.0344337224960327, "Value Loss": 0.06124724820256233, "_runtime": 20100.563623666763, "_timestamp": 1585617470.1964931, "_step": 266}
{"Episode reward": 60.093484706792225, "Episode length": 401, "Policy Loss": 0.5477629899978638, "Value Loss": 22.977386474609375, "_runtime": 20100.932982206345, "_timestamp": 1585617470.5658517, "_step": 267}
{"Episode reward": 78.39999999999998, "Episode length": 216, "Policy Loss": 1.7704423666000366, "Value Loss": 39.688838958740234, "_runtime": 20102.484719753265, "_timestamp": 1585617472.1175892, "_step": 268}
{"Episode reward": 1.6486889387708743, "Episode length": 990, "Policy Loss": -0.32725635170936584, "Value Loss": 9.439884185791016, "_runtime": 20103.605122089386, "_timestamp": 1585617473.2379916, "_step": 269}
{"Episode reward": 26.86605151377141, "Episode length": 737, "Policy Loss": -0.1218978613615036, "Value Loss": 11.712798118591309, "_runtime": 20104.848893880844, "_timestamp": 1585617474.4817634, "_step": 270}
{"Episode reward": 17.160527438128028, "Episode length": 833, "Policy Loss": -0.002603533212095499, "Value Loss": 12.24241828918457, "_runtime": 20105.85501718521, "_timestamp": 1585617475.4878867, "_step": 271}
{"Episode reward": 36.672011922320706, "Episode length": 637, "Policy Loss": -0.15808770060539246, "Value Loss": 14.042267799377441, "_runtime": 20107.416549921036, "_timestamp": 1585617477.0494194, "_step": 272}
{"Episode reward": -99.5883272204316, "Episode length": 999, "Policy Loss": -1.017479658126831, "Value Loss": 0.0701771080493927, "_runtime": 20108.017557144165, "_timestamp": 1585617477.6504266, "_step": 273}
{"Episode reward": 62.19698553555037, "Episode length": 379, "Policy Loss": 0.7297077178955078, "Value Loss": 24.33788299560547, "_runtime": 20108.643605470657, "_timestamp": 1585617478.276475, "_step": 274}
{"Episode reward": 60.45041146303964, "Episode length": 397, "Policy Loss": 0.6362508535385132, "Value Loss": 23.739501953125, "_runtime": 20110.21845793724, "_timestamp": 1585617479.8513274, "_step": 275}
{"Episode reward": -99.64555489598607, "Episode length": 999, "Policy Loss": -0.9445890784263611, "Value Loss": 0.14818790555000305, "_runtime": 20111.74105834961, "_timestamp": 1585617481.3739278, "_step": 276}
{"Episode reward": -99.52957912749851, "Episode length": 999, "Policy Loss": -0.8476929068565369, "Value Loss": 0.3482479751110077, "_runtime": 20113.26759147644, "_timestamp": 1585617482.900461, "_step": 277}
{"Episode reward": -99.64000660183817, "Episode length": 999, "Policy Loss": -0.8997421264648438, "Value Loss": 0.05447068065404892, "_runtime": 20114.856573581696, "_timestamp": 1585617484.489443, "_step": 278}
{"Episode reward": -99.65062539764774, "Episode length": 999, "Policy Loss": -0.9843354225158691, "Value Loss": 0.13301189243793488, "_runtime": 20116.419743299484, "_timestamp": 1585617486.0526128, "_step": 279}
{"Episode reward": -99.24206477424025, "Episode length": 999, "Policy Loss": -0.84316486120224, "Value Loss": 0.043229538947343826, "_runtime": 20117.98056077957, "_timestamp": 1585617487.6134303, "_step": 280}
{"Episode reward": -99.60370852494533, "Episode length": 999, "Policy Loss": -0.7762823104858398, "Value Loss": 0.1199408546090126, "_runtime": 20119.566833734512, "_timestamp": 1585617489.1997032, "_step": 281}
{"Episode reward": -99.65199689700246, "Episode length": 999, "Policy Loss": -0.728166401386261, "Value Loss": 0.11303168535232544, "_runtime": 20121.005317926407, "_timestamp": 1585617490.6381874, "_step": 282}
{"Episode reward": 11.556915799796869, "Episode length": 890, "Policy Loss": 0.02256673388183117, "Value Loss": 9.774114608764648, "_runtime": 20122.38898730278, "_timestamp": 1585617492.0218568, "_step": 283}
{"Episode reward": 12.586969502875917, "Episode length": 877, "Policy Loss": -0.20691902935504913, "Value Loss": 9.768218040466309, "_runtime": 20123.804080724716, "_timestamp": 1585617493.4369502, "_step": 284}
{"Episode reward": 11.51758806541406, "Episode length": 889, "Policy Loss": -0.07960692793130875, "Value Loss": 9.6015043258667, "_runtime": 20124.441101551056, "_timestamp": 1585617494.073971, "_step": 285}
{"Episode reward": 61.087041776124984, "Episode length": 390, "Policy Loss": 0.8213386535644531, "Value Loss": 23.098514556884766, "_runtime": 20125.765676021576, "_timestamp": 1585617495.3985455, "_step": 286}
{"Episode reward": 15.89843727946186, "Episode length": 845, "Policy Loss": 0.07838976383209229, "Value Loss": 10.217419624328613, "_runtime": 20126.754070997238, "_timestamp": 1585617496.3869405, "_step": 287}
{"Episode reward": 38.402441172985746, "Episode length": 617, "Policy Loss": 0.3194217383861542, "Value Loss": 14.531166076660156, "_runtime": 20127.73523044586, "_timestamp": 1585617497.3681, "_step": 288}
{"Episode reward": 36.69000222226543, "Episode length": 634, "Policy Loss": 0.14273163676261902, "Value Loss": 12.598268508911133, "_runtime": 20128.18465733528, "_timestamp": 1585617497.8175268, "_step": 289}
{"Episode reward": 74.0710525155474, "Episode length": 260, "Policy Loss": 1.5254191160202026, "Value Loss": 33.67247772216797, "_runtime": 20128.845583438873, "_timestamp": 1585617498.478453, "_step": 290}
{"Episode reward": 58.27305744697192, "Episode length": 420, "Policy Loss": 0.47552135586738586, "Value Loss": 19.93303108215332, "_runtime": 20129.459846019745, "_timestamp": 1585617499.0927155, "_step": 291}
{"Episode reward": 61.03976761019412, "Episode length": 393, "Policy Loss": 0.8071216940879822, "Value Loss": 21.68551254272461, "_runtime": 20131.001665830612, "_timestamp": 1585617500.6345353, "_step": 292}
{"Episode reward": -99.63481873168355, "Episode length": 999, "Policy Loss": -0.7116316556930542, "Value Loss": 0.10982222855091095, "_runtime": 20132.533067703247, "_timestamp": 1585617502.1659372, "_step": 293}
{"Episode reward": -99.84699745178082, "Episode length": 999, "Policy Loss": -0.7506958842277527, "Value Loss": 0.45121151208877563, "_runtime": 20133.298074245453, "_timestamp": 1585617502.9309437, "_step": 294}
{"Episode reward": 50.52908120445421, "Episode length": 499, "Policy Loss": 0.18528389930725098, "Value Loss": 19.491291046142578, "_runtime": 20134.86705470085, "_timestamp": 1585617504.4999242, "_step": 295}
{"Episode reward": -99.72417445138045, "Episode length": 999, "Policy Loss": -0.4684706926345825, "Value Loss": 0.691897451877594, "_runtime": 20135.694528341293, "_timestamp": 1585617505.3273978, "_step": 296}
{"Episode reward": 48.26350261725972, "Episode length": 521, "Policy Loss": 0.668199896812439, "Value Loss": 14.922926902770996, "_runtime": 20136.482237815857, "_timestamp": 1585617506.1151073, "_step": 297}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 0.658003568649292, "Value Loss": 17.879220962524414, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329, 0.333445280790329]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [5.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.41136467456817627, -0.25998449325561523, -0.10860434174537659, 0.04277580976486206, 0.1941559910774231, 0.34553617238998413, 0.4969162940979004, 0.6482964754104614, 0.7996766567230225, 0.9510568380355835, 1.1024370193481445, 1.2538172006607056, 1.405197262763977, 1.556577444076538, 1.7079576253890991, 1.8593379259109497, 2.0107178688049316, 2.162097930908203, 2.313478469848633, 2.4648585319519043, 2.616238594055176, 2.7676186561584473, 2.918999195098877, 3.0703792572021484, 3.22175931930542, 3.3731393814086914, 3.524519443511963, 3.6758999824523926, 3.827280044555664, 3.9786601066589355, 4.130040645599365, 4.281420707702637, 4.432800769805908, 4.58418083190918, 4.735560894012451, 4.886941432952881, 5.038321495056152, 5.189701557159424, 5.341081619262695, 5.492462158203125, 5.6438422203063965, 5.795222282409668, 5.9466023445129395, 6.097982406616211, 6.249362945556641, 6.400743007659912, 6.552123069763184, 6.703503131866455, 6.854883193969727, 7.006263732910156, 7.157643795013428, 7.309023857116699, 7.460403919219971, 7.611783981323242, 7.763164520263672, 7.914545059204102, 8.065924644470215, 8.217305183410645, 8.368684768676758, 8.520065307617188, 8.671445846557617, 8.82282543182373, 8.97420597076416, 9.125585556030273, 9.276966094970703]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.015572836622595787, -0.004376026801764965, 0.006820783019065857, 0.018017591908574104, 0.0292144026607275, 0.04041121155023575, 0.051608018577098846, 0.06280483305454254, 0.07400164008140564, 0.08519844710826874, 0.09639526158571243, 0.10759206861257553, 0.11878887563943863, 0.12998569011688232, 0.14118251204490662, 0.15237931907176971, 0.1635761260986328, 0.1747729331254959, 0.185969740152359, 0.1971665620803833, 0.2083633691072464, 0.2195601761341095, 0.2307569831609726, 0.2419538050889969, 0.2531505823135376, 0.2643474042415619, 0.2755441963672638, 0.2867410182952881, 0.2979378402233124, 0.3091346323490143, 0.3203314542770386, 0.3315282464027405, 0.34272506833076477, 0.35392189025878906, 0.36511868238449097, 0.37631550431251526, 0.38751229643821716, 0.39870911836624146, 0.40990594029426575, 0.42110273241996765, 0.43229955434799194, 0.44349634647369385, 0.45469316840171814, 0.46588999032974243, 0.47708678245544434, 0.48828357458114624, 0.4994804263114929, 0.5106772184371948, 0.5218740105628967, 0.5330708622932434, 0.5442676544189453, 0.5554644465446472, 0.5666612386703491, 0.5778580904006958, 0.5890548825263977, 0.6002516746520996, 0.6114485263824463, 0.6226453185081482, 0.6338421106338501, 0.6450389623641968, 0.6562357544898987, 0.6674325466156006, 0.6786293387413025, 0.6898261904716492, 0.7010229825973511]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 6.0, 2.0, 1.0, 6.0, 5.0, 6.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 81.0, 244.0, 47.0, 15.0, 25.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 7.0, 4.0, 2.0, 1.0, 0.0, 0.0, 2.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0], "bins": [-0.6125813126564026, -0.5926081538200378, -0.5726350545883179, -0.5526618957519531, -0.5326887369155884, -0.5127156376838684, -0.49274247884750366, -0.4727693498134613, -0.45279622077941895, -0.4328230917453766, -0.41284996271133423, -0.3928768038749695, -0.3729036748409271, -0.35293054580688477, -0.33295738697052, -0.31298425793647766, -0.2930111289024353, -0.27303799986839294, -0.2530648708343506, -0.23309171199798584, -0.21311858296394348, -0.19314545392990112, -0.17317229509353638, -0.15319916605949402, -0.13322603702545166, -0.1132529079914093, -0.09327977895736694, -0.0733066201210022, -0.05333346128463745, -0.03336036205291748, -0.013387203216552734, 0.006585896015167236, 0.026559054851531982, 0.04653221368789673, 0.0665053129196167, 0.08647847175598145, 0.10645157098770142, 0.12642472982406616, 0.1463978886604309, 0.16637098789215088, 0.18634414672851562, 0.20631730556488037, 0.22629040479660034, 0.2462635636329651, 0.26623672246932983, 0.2862098217010498, 0.30618298053741455, 0.3261560797691345, 0.34612923860549927, 0.366102397441864, 0.386075496673584, 0.40604859590530396, 0.4260217547416687, 0.44599491357803345, 0.4659680724143982, 0.48594123125076294, 0.5059143900871277, 0.5258874297142029, 0.5458605885505676, 0.5658337473869324, 0.5858069062232971, 0.6057800650596619, 0.6257531046867371, 0.6457262635231018, 0.6656994223594666]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0], "bins": [-2.021228790283203, -1.9362989664077759, -1.8513691425323486, -1.766439437866211, -1.6815094947814941, -1.5965797901153564, -1.5116499662399292, -1.426720142364502, -1.3417903184890747, -1.2568604946136475, -1.1719306707382202, -1.087000846862793, -1.0020711421966553, -0.917141318321228, -0.8322114944458008, -0.7472816705703735, -0.6623518466949463, -0.577422022819519, -0.4924921989440918, -0.40756237506866455, -0.3226325511932373, -0.2377028465270996, -0.15277302265167236, -0.06784319877624512, 0.017086505889892578, 0.10201644897460938, 0.18694615364074707, 0.27187609672546387, 0.35680580139160156, 0.44173574447631836, 0.526665449142456, 0.6115953922271729, 0.6965250968933105, 0.7814548015594482, 0.866384744644165, 0.9513144493103027, 1.0362443923950195, 1.1211740970611572, 1.206104040145874, 1.2910337448120117, 1.3759636878967285, 1.4608933925628662, 1.545823097229004, 1.6307530403137207, 1.7156827449798584, 1.8006126880645752, 1.885542392730713, 1.9704723358154297, 2.0554018020629883, 2.140331745147705, 2.225261688232422, 2.3101916313171387, 2.3951210975646973, 2.480051040649414, 2.564980983734131, 2.6499109268188477, 2.7348403930664062, 2.819770336151123, 2.90470027923584, 2.9896297454833984, 3.0745596885681152, 3.159489631652832, 3.244419574737549, 3.3293490409851074, 3.414278984069824]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 5.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0], "bins": [-0.8882429003715515, -0.8528842329978943, -0.8175255656242371, -0.7821668386459351, -0.7468081712722778, -0.7114495038986206, -0.6760908365249634, -0.6407321691513062, -0.6053735017776489, -0.5700148344039917, -0.5346561074256897, -0.49929744005203247, -0.46393877267837524, -0.42858007550239563, -0.3932214081287384, -0.3578627109527588, -0.32250404357910156, -0.28714537620544434, -0.2517867088317871, -0.2164279818534851, -0.18106931447982788, -0.14571064710617065, -0.11035197973251343, -0.0749933123588562, -0.039634644985198975, -0.004275918006896973, 0.031082749366760254, 0.06644141674041748, 0.10180008411407471, 0.1371588110923767, 0.17251747846603394, 0.20787614583969116, 0.2432348132133484, 0.2785934805870056, 0.31395214796066284, 0.34931081533432007, 0.3846694827079773, 0.4200281500816345, 0.4553869366645813, 0.4907456040382385, 0.5261042714118958, 0.561462938785553, 0.5968216061592102, 0.6321802735328674, 0.6675389409065247, 0.7028976082801819, 0.7382562756538391, 0.7736149430274963, 0.8089736104011536, 0.8443323969841003, 0.8796910643577576, 0.9150497317314148, 0.950408399105072, 0.9857670664787292, 1.0211257934570312, 1.0564844608306885, 1.0918431282043457, 1.127201795578003, 1.1625604629516602, 1.1979191303253174, 1.2332777976989746, 1.2686364650726318, 1.303995132446289, 1.3393537998199463, 1.3747124671936035]}, "_runtime": 20138.056502342224, "_timestamp": 1585617507.6893718, "_step": 298}
{"Episode reward": -99.58080606794108, "Episode length": 999, "Policy Loss": -0.5213791131973267, "Value Loss": 0.08614481985569, "_runtime": 20139.563005924225, "_timestamp": 1585617509.1958754, "_step": 299}
{"Episode reward": 2.4981503522090804, "Episode length": 981, "Policy Loss": -0.18291421234607697, "Value Loss": 9.302545547485352, "_runtime": 20141.099477767944, "_timestamp": 1585617510.7323472, "_step": 300}
{"Episode reward": -99.63816069579195, "Episode length": 999, "Policy Loss": -0.705164909362793, "Value Loss": 0.16100817918777466, "_runtime": 20142.674780845642, "_timestamp": 1585617512.3076503, "_step": 301}
{"Episode reward": -99.68231022053085, "Episode length": 999, "Policy Loss": -0.5782458186149597, "Value Loss": 0.14103884994983673, "_runtime": 20144.25551176071, "_timestamp": 1585617513.8883812, "_step": 302}
{"Episode reward": -99.4500824959542, "Episode length": 999, "Policy Loss": -0.4198300242424011, "Value Loss": 0.15411047637462616, "_runtime": 20145.861124515533, "_timestamp": 1585617515.493994, "_step": 303}
{"Episode reward": -99.7330514223592, "Episode length": 999, "Policy Loss": -0.41688498854637146, "Value Loss": 0.3347831070423126, "_runtime": 20147.449459552765, "_timestamp": 1585617517.082329, "_step": 304}
{"Episode reward": -99.86566399792069, "Episode length": 999, "Policy Loss": -0.49603500962257385, "Value Loss": 0.02488473616540432, "_runtime": 20149.03848171234, "_timestamp": 1585617518.6713512, "_step": 305}
{"Episode reward": -99.75055311202165, "Episode length": 999, "Policy Loss": -0.5469444394111633, "Value Loss": 0.04164281487464905, "_runtime": 20150.349348068237, "_timestamp": 1585617519.9822176, "_step": 306}
{"Episode reward": 16.951276545372536, "Episode length": 834, "Policy Loss": 0.1710774451494217, "Value Loss": 10.213935852050781, "_runtime": 20151.935321331024, "_timestamp": 1585617521.5681908, "_step": 307}
{"Episode reward": -99.49875645403961, "Episode length": 999, "Policy Loss": -0.5949227213859558, "Value Loss": 0.22986792027950287, "_runtime": 20153.53088736534, "_timestamp": 1585617523.1637568, "_step": 308}
{"Episode reward": -99.74821020836832, "Episode length": 999, "Policy Loss": -0.4250399172306061, "Value Loss": 0.012639536522328854, "_runtime": 20155.03741121292, "_timestamp": 1585617524.6702807, "_step": 309}
{"Episode reward": 4.112274308428169, "Episode length": 960, "Policy Loss": 0.3998175859451294, "Value Loss": 9.812515258789062, "_runtime": 20156.62468934059, "_timestamp": 1585617526.2575588, "_step": 310}
{"Episode reward": -99.72691491627491, "Episode length": 999, "Policy Loss": -0.3274599611759186, "Value Loss": 0.06938736885786057, "_runtime": 20157.598391532898, "_timestamp": 1585617527.231261, "_step": 311}
{"Episode reward": 39.39188381316431, "Episode length": 607, "Policy Loss": 0.6734943389892578, "Value Loss": 15.497237205505371, "_runtime": 20158.37885451317, "_timestamp": 1585617528.011724, "_step": 312}
{"Episode reward": 51.49999999999959, "Episode length": 485, "Policy Loss": 0.7518910765647888, "Value Loss": 17.98552131652832, "_runtime": 20159.960793972015, "_timestamp": 1585617529.5936635, "_step": 313}
{"Episode reward": -99.74515603199113, "Episode length": 999, "Policy Loss": -0.4810643494129181, "Value Loss": 0.05594432353973389, "_runtime": 20160.453467845917, "_timestamp": 1585617530.0863373, "_step": 314}
{"Episode reward": 69.71306880653559, "Episode length": 305, "Policy Loss": 1.6179250478744507, "Value Loss": 32.134334564208984, "_runtime": 20161.99387216568, "_timestamp": 1585617531.6267416, "_step": 315}
{"Episode reward": -99.47617373744588, "Episode length": 999, "Policy Loss": -0.26369407773017883, "Value Loss": 0.13557447493076324, "_runtime": 20162.963202238083, "_timestamp": 1585617532.5960717, "_step": 316}
{"Episode reward": 39.59988343552046, "Episode length": 605, "Policy Loss": 1.1594176292419434, "Value Loss": 15.001619338989258, "_runtime": 20164.479912996292, "_timestamp": 1585617534.1127825, "_step": 317}
{"Episode reward": -99.80378045600234, "Episode length": 999, "Policy Loss": -0.11999660730361938, "Value Loss": 0.5064954161643982, "_runtime": 20166.066054582596, "_timestamp": 1585617535.698924, "_step": 318}
{"Episode reward": -99.71510229857965, "Episode length": 999, "Policy Loss": -0.06311964243650436, "Value Loss": 0.4197707176208496, "_runtime": 20167.607761621475, "_timestamp": 1585617537.240631, "_step": 319}
{"Episode reward": -99.55021295058985, "Episode length": 999, "Policy Loss": -0.14264722168445587, "Value Loss": 0.13311496376991272, "_runtime": 20168.45612859726, "_timestamp": 1585617538.088998, "_step": 320}
{"Episode reward": 46.87014446926139, "Episode length": 532, "Policy Loss": 0.8425014019012451, "Value Loss": 15.97675895690918, "_runtime": 20170.083039045334, "_timestamp": 1585617539.7159085, "_step": 321}
{"Episode reward": -99.80089226034913, "Episode length": 999, "Policy Loss": -0.4289321303367615, "Value Loss": 0.36931055784225464, "_runtime": 20171.67467212677, "_timestamp": 1585617541.3075416, "_step": 322}
{"Episode reward": -99.74515467362222, "Episode length": 999, "Policy Loss": -0.481851726770401, "Value Loss": 0.3748075067996979, "_runtime": 20173.028370141983, "_timestamp": 1585617542.6612396, "_step": 323}
{"Episode reward": 12.536037442222707, "Episode length": 877, "Policy Loss": 0.2096441686153412, "Value Loss": 10.073190689086914, "_runtime": 20174.50453543663, "_timestamp": 1585617544.137405, "_step": 324}
{"Episode reward": 6.7678291550614915, "Episode length": 933, "Policy Loss": 0.07847262918949127, "Value Loss": 9.550745010375977, "_runtime": 20176.101838827133, "_timestamp": 1585617545.7347083, "_step": 325}
{"Episode reward": -99.47688517385258, "Episode length": 999, "Policy Loss": -0.3785010874271393, "Value Loss": 0.040986672043800354, "_runtime": 20177.673620224, "_timestamp": 1585617547.3064897, "_step": 326}
{"Episode reward": -99.46488151816747, "Episode length": 999, "Policy Loss": -0.3145170509815216, "Value Loss": 0.007124845404177904, "_runtime": 20178.439902067184, "_timestamp": 1585617548.0727715, "_step": 327}
{"Episode reward": 53.726209079281745, "Episode length": 463, "Policy Loss": 0.9453502297401428, "Value Loss": 18.691892623901367, "_runtime": 20180.029342889786, "_timestamp": 1585617549.6622124, "_step": 328}
{"Episode reward": -99.56009100343078, "Episode length": 999, "Policy Loss": -0.24658209085464478, "Value Loss": 0.08736888319253922, "_runtime": 20181.61528968811, "_timestamp": 1585617551.2481592, "_step": 329}
{"Episode reward": -99.41556245292749, "Episode length": 999, "Policy Loss": -0.11069872975349426, "Value Loss": 0.6656409502029419, "_runtime": 20182.94282078743, "_timestamp": 1585617552.5756903, "_step": 330}
{"Episode reward": 14.539030571571985, "Episode length": 859, "Policy Loss": 0.441252738237381, "Value Loss": 10.145245552062988, "_runtime": 20184.54053044319, "_timestamp": 1585617554.1734, "_step": 331}
{"Episode reward": -99.58265377520773, "Episode length": 999, "Policy Loss": -0.25412020087242126, "Value Loss": 0.09199080616235733, "_runtime": 20185.33454322815, "_timestamp": 1585617554.9674127, "_step": 332}
{"Episode reward": 51.60723333441961, "Episode length": 485, "Policy Loss": 0.8083957433700562, "Value Loss": 18.245567321777344, "_runtime": 20186.343507051468, "_timestamp": 1585617555.9763765, "_step": 333}
{"Episode reward": 36.72094696396318, "Episode length": 635, "Policy Loss": 0.5051834583282471, "Value Loss": 13.900141716003418, "_runtime": 20187.877665758133, "_timestamp": 1585617557.5105352, "_step": 334}
{"Episode reward": 3.9247801144557286, "Episode length": 964, "Policy Loss": 0.0227134358137846, "Value Loss": 9.02519702911377, "_runtime": 20189.429482221603, "_timestamp": 1585617559.0623517, "_step": 335}
{"Episode reward": -99.52815185985325, "Episode length": 999, "Policy Loss": -0.5505568981170654, "Value Loss": 0.106291264295578, "_runtime": 20190.07268691063, "_timestamp": 1585617559.7055564, "_step": 336}
{"Episode reward": 59.69837800715438, "Episode length": 404, "Policy Loss": 0.7694380283355713, "Value Loss": 22.1339168548584, "_runtime": 20191.668040275574, "_timestamp": 1585617561.3009098, "_step": 337}
{"Episode reward": -99.45290740346726, "Episode length": 999, "Policy Loss": -0.5461918115615845, "Value Loss": 0.07608974725008011, "_runtime": 20193.297842025757, "_timestamp": 1585617562.9307115, "_step": 338}
{"Episode reward": -99.705369837604, "Episode length": 999, "Policy Loss": -0.506382405757904, "Value Loss": 0.018146537244319916, "_runtime": 20193.642119407654, "_timestamp": 1585617563.274989, "_step": 339}
{"Episode reward": 78.8189162869399, "Episode length": 213, "Policy Loss": 1.9349735975265503, "Value Loss": 42.068058013916016, "_runtime": 20195.237439632416, "_timestamp": 1585617564.870309, "_step": 340}
{"Episode reward": -99.44963596666356, "Episode length": 999, "Policy Loss": -0.5372558236122131, "Value Loss": 0.02554887905716896, "_runtime": 20196.40494275093, "_timestamp": 1585617566.0378122, "_step": 341}
{"Episode reward": 27.49895304202603, "Episode length": 728, "Policy Loss": 0.19652177393436432, "Value Loss": 11.943896293640137, "_runtime": 20197.58507657051, "_timestamp": 1585617567.217946, "_step": 342}
{"Episode reward": 21.740146516268027, "Episode length": 783, "Policy Loss": 0.013582573272287846, "Value Loss": 11.0506591796875, "_runtime": 20198.60876250267, "_timestamp": 1585617568.241632, "_step": 343}
{"Episode reward": 36.88036104214636, "Episode length": 633, "Policy Loss": 0.26695677638053894, "Value Loss": 13.82028579711914, "_runtime": 20199.814751148224, "_timestamp": 1585617569.4476206, "_step": 344}
{"Episode reward": 23.416955352929733, "Episode length": 768, "Policy Loss": 0.13222233951091766, "Value Loss": 10.94176197052002, "_runtime": 20201.37990450859, "_timestamp": 1585617571.012774, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5320444703102112, "Value Loss": 0.3171508312225342, "_runtime": 20202.662626981735, "_timestamp": 1585617572.2954965, "_step": 346}
{"Episode reward": 17.98579079140366, "Episode length": 822, "Policy Loss": 0.2663702368736267, "Value Loss": 12.023652076721191, "_runtime": 20204.23212003708, "_timestamp": 1585617573.8649895, "_step": 347}
{"Episode reward": -99.54937996828966, "Episode length": 999, "Policy Loss": -0.6215656995773315, "Value Loss": 0.07838372886180878, "_runtime": 20205.8138794899, "_timestamp": 1585617575.446749, "_step": 348}
{"Episode reward": -99.49879476239883, "Episode length": 999, "Policy Loss": -0.7153179049491882, "Value Loss": 0.08644809573888779, "_runtime": 20207.389999866486, "_timestamp": 1585617577.0228693, "_step": 349}
{"Episode reward": -99.54808750254313, "Episode length": 999, "Policy Loss": -0.8364464044570923, "Value Loss": 0.2809807360172272, "_runtime": 20208.97932243347, "_timestamp": 1585617578.612192, "_step": 350}
{"Episode reward": -99.47215533798891, "Episode length": 999, "Policy Loss": -0.6895269751548767, "Value Loss": 0.15594831109046936, "_runtime": 20209.46343779564, "_timestamp": 1585617579.0963073, "_step": 351}
{"Episode reward": 71.66685269073919, "Episode length": 284, "Policy Loss": 1.2937393188476562, "Value Loss": 32.89426803588867, "_runtime": 20210.907995939255, "_timestamp": 1585617580.5408654, "_step": 352}
{"Episode reward": 8.900848473184467, "Episode length": 913, "Policy Loss": -0.12352315336465836, "Value Loss": 10.477095603942871, "_runtime": 20211.557120084763, "_timestamp": 1585617581.1899896, "_step": 353}
{"Episode reward": 61.5913264849919, "Episode length": 386, "Policy Loss": 0.9474903345108032, "Value Loss": 23.932945251464844, "_runtime": 20213.0879342556, "_timestamp": 1585617582.7208037, "_step": 354}
{"Episode reward": -99.47568362682948, "Episode length": 999, "Policy Loss": -0.5500539541244507, "Value Loss": 0.01848193071782589, "_runtime": 20214.675676584244, "_timestamp": 1585617584.308546, "_step": 355}
{"Episode reward": -99.69262233694178, "Episode length": 999, "Policy Loss": -0.40531468391418457, "Value Loss": 0.04485577344894409, "_runtime": 20215.471305131912, "_timestamp": 1585617585.1041746, "_step": 356}
{"Episode reward": 48.99382198326594, "Episode length": 512, "Policy Loss": 0.7913478016853333, "Value Loss": 16.77971839904785, "_runtime": 20217.084503173828, "_timestamp": 1585617586.7173727, "_step": 357}
{"Episode reward": -99.59808228453046, "Episode length": 999, "Policy Loss": -0.37187933921813965, "Value Loss": 0.07801871746778488, "_runtime": 20218.682158470154, "_timestamp": 1585617588.315028, "_step": 358}
{"Episode reward": -99.6714311863864, "Episode length": 999, "Policy Loss": -0.37716180086135864, "Value Loss": 0.2109156847000122, "_runtime": 20220.220445632935, "_timestamp": 1585617589.853315, "_step": 359}
{"Episode reward": -99.44114758582299, "Episode length": 999, "Policy Loss": -0.44737163186073303, "Value Loss": 0.06517032533884048, "_runtime": 20221.809991836548, "_timestamp": 1585617591.4428613, "_step": 360}
{"Episode reward": -99.83965821389435, "Episode length": 999, "Policy Loss": -0.3891538977622986, "Value Loss": 0.21114566922187805, "_runtime": 20222.805366754532, "_timestamp": 1585617592.4382362, "_step": 361}
{"Episode reward": 38.50277656597695, "Episode length": 618, "Policy Loss": 0.2642350494861603, "Value Loss": 15.120956420898438, "_runtime": 20224.39572262764, "_timestamp": 1585617594.028592, "_step": 362}
{"Episode reward": -99.79909164059214, "Episode length": 999, "Policy Loss": -0.44550731778144836, "Value Loss": 0.011931154876947403, "_runtime": 20225.983942985535, "_timestamp": 1585617595.6168125, "_step": 363}
{"Episode reward": -99.51834723160704, "Episode length": 999, "Policy Loss": -0.42217180132865906, "Value Loss": 0.008078428916633129, "_runtime": 20226.81465291977, "_timestamp": 1585617596.4475224, "_step": 364}
{"Episode reward": 47.950861028021144, "Episode length": 524, "Policy Loss": 0.7626140713691711, "Value Loss": 16.54051399230957, "_runtime": 20228.403086662292, "_timestamp": 1585617598.0359561, "_step": 365}
{"Episode reward": -99.59659057725663, "Episode length": 999, "Policy Loss": -0.34803536534309387, "Value Loss": 0.006326405797153711, "_runtime": 20229.996524333954, "_timestamp": 1585617599.6293938, "_step": 366}
{"Episode reward": -99.41800560732526, "Episode length": 999, "Policy Loss": -0.3202782869338989, "Value Loss": 0.00720496941357851, "_runtime": 20231.541532039642, "_timestamp": 1585617601.1744015, "_step": 367}
{"Episode reward": -99.52022508251109, "Episode length": 999, "Policy Loss": -0.2954259514808655, "Value Loss": 0.0050448584370315075, "_runtime": 20232.01948237419, "_timestamp": 1585617601.6523519, "_step": 368}
{"Episode reward": 72.99999999999989, "Episode length": 270, "Policy Loss": 2.0490918159484863, "Value Loss": 35.54281997680664, "_runtime": 20232.882753133774, "_timestamp": 1585617602.5156226, "_step": 369}
{"Episode reward": 45.66599141485008, "Episode length": 545, "Policy Loss": 1.2062246799468994, "Value Loss": 17.21393585205078, "_runtime": 20233.650058746338, "_timestamp": 1585617603.2829282, "_step": 370}
{"Episode reward": 52.514407292560975, "Episode length": 475, "Policy Loss": 0.8217527270317078, "Value Loss": 19.685447692871094, "_runtime": 20235.17540383339, "_timestamp": 1585617604.8082733, "_step": 371}
{"Episode reward": -99.32589909769787, "Episode length": 999, "Policy Loss": -0.4585942327976227, "Value Loss": 0.04385967552661896, "_runtime": 20236.714653253555, "_timestamp": 1585617606.3475227, "_step": 372}
{"Episode reward": -99.7473205541596, "Episode length": 999, "Policy Loss": -0.5051397085189819, "Value Loss": 0.059157222509384155, "_runtime": 20238.244067192078, "_timestamp": 1585617607.8769367, "_step": 373}
{"Episode reward": -99.61852582747677, "Episode length": 999, "Policy Loss": -0.47850722074508667, "Value Loss": 0.0287556704133749, "_runtime": 20239.82469677925, "_timestamp": 1585617609.4575663, "_step": 374}
{"Episode reward": -99.42215263534898, "Episode length": 999, "Policy Loss": -0.49083876609802246, "Value Loss": 0.023229625076055527, "_runtime": 20241.419296741486, "_timestamp": 1585617611.0521662, "_step": 375}
{"Episode reward": -99.65907746761084, "Episode length": 999, "Policy Loss": -0.502822995185852, "Value Loss": 0.019368741661310196, "_runtime": 20242.809903621674, "_timestamp": 1585617612.442773, "_step": 376}
{"Episode reward": 12.260784804815898, "Episode length": 882, "Policy Loss": 0.15123014152050018, "Value Loss": 10.509109497070312, "_runtime": 20244.38116455078, "_timestamp": 1585617614.014034, "_step": 377}
{"Episode reward": -99.5731196157504, "Episode length": 999, "Policy Loss": -0.5858827233314514, "Value Loss": 0.048908066004514694, "_runtime": 20245.457543849945, "_timestamp": 1585617615.0904133, "_step": 378}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": 0.12293807417154312, "Value Loss": 11.595477104187012, "_runtime": 20246.7008125782, "_timestamp": 1585617616.333682, "_step": 379}
{"Episode reward": 22.093828801500948, "Episode length": 782, "Policy Loss": 0.12152393907308578, "Value Loss": 10.97014331817627, "_runtime": 20248.281237125397, "_timestamp": 1585617617.9141066, "_step": 380}
{"Episode reward": -99.27145462471972, "Episode length": 999, "Policy Loss": -0.6498627066612244, "Value Loss": 0.021841472014784813, "_runtime": 20248.94549226761, "_timestamp": 1585617618.5783617, "_step": 381}
{"Episode reward": 58.620928567275094, "Episode length": 414, "Policy Loss": 0.6391602754592896, "Value Loss": 22.772050857543945, "_runtime": 20250.435754537582, "_timestamp": 1585617620.068624, "_step": 382}
{"Episode reward": 6.361444813246962, "Episode length": 939, "Policy Loss": -0.07772025465965271, "Value Loss": 8.632003784179688, "_runtime": 20252.024335861206, "_timestamp": 1585617621.6572053, "_step": 383}
{"Episode reward": -99.55975580733947, "Episode length": 999, "Policy Loss": -0.6764522194862366, "Value Loss": 0.09851262718439102, "_runtime": 20253.561103582382, "_timestamp": 1585617623.193973, "_step": 384}
{"Episode reward": -99.57637859497815, "Episode length": 999, "Policy Loss": -0.6029216051101685, "Value Loss": 0.28601372241973877, "_runtime": 20255.140655994415, "_timestamp": 1585617624.7735255, "_step": 385}
{"Episode reward": -99.64439796917583, "Episode length": 999, "Policy Loss": -0.6239783763885498, "Value Loss": 0.3410419225692749, "_runtime": 20256.01532101631, "_timestamp": 1585617625.6481905, "_step": 386}
{"Episode reward": 46.41222526712885, "Episode length": 537, "Policy Loss": 0.5811330080032349, "Value Loss": 17.96504020690918, "_runtime": 20257.03840494156, "_timestamp": 1585617626.6712744, "_step": 387}
{"Episode reward": 36.17012436036976, "Episode length": 642, "Policy Loss": 0.06722721457481384, "Value Loss": 11.921576499938965, "_runtime": 20258.62788248062, "_timestamp": 1585617628.260752, "_step": 388}
{"Episode reward": -99.51475175209205, "Episode length": 999, "Policy Loss": -0.7864376902580261, "Value Loss": 0.05651812255382538, "_runtime": 20260.168082237244, "_timestamp": 1585617629.8009517, "_step": 389}
{"Episode reward": -99.40242833515522, "Episode length": 999, "Policy Loss": -0.9776679277420044, "Value Loss": 0.5867998003959656, "_runtime": 20261.729705810547, "_timestamp": 1585617631.3625753, "_step": 390}
{"Episode reward": -99.56073784394982, "Episode length": 999, "Policy Loss": -0.8178401589393616, "Value Loss": 0.36939746141433716, "_runtime": 20263.224271297455, "_timestamp": 1585617632.8571408, "_step": 391}
{"Episode reward": 6.454944058227866, "Episode length": 937, "Policy Loss": -0.1657959371805191, "Value Loss": 9.319979667663574, "_runtime": 20264.115345716476, "_timestamp": 1585617633.7482152, "_step": 392}
{"Episode reward": 45.20599149208815, "Episode length": 550, "Policy Loss": 0.3366982638835907, "Value Loss": 15.907203674316406, "_runtime": 20265.08454489708, "_timestamp": 1585617634.7174144, "_step": 393}
{"Episode reward": 41.68350272257175, "Episode length": 586, "Policy Loss": 0.44367048144340515, "Value Loss": 14.33602237701416, "_runtime": 20266.675221443176, "_timestamp": 1585617636.308091, "_step": 394}
{"Episode reward": -99.64415688006163, "Episode length": 999, "Policy Loss": -0.41525977849960327, "Value Loss": 0.032221365720033646, "_runtime": 20268.22714996338, "_timestamp": 1585617637.8600194, "_step": 395}
{"Episode reward": -99.5130555939556, "Episode length": 999, "Policy Loss": -0.2977096438407898, "Value Loss": 0.0504678376019001, "_runtime": 20269.782757520676, "_timestamp": 1585617639.415627, "_step": 396}
{"Episode reward": -99.70089573189622, "Episode length": 999, "Policy Loss": -0.07797115296125412, "Value Loss": 0.7456859350204468, "_runtime": 20271.287170171738, "_timestamp": 1585617640.9200397, "_step": 397}
{"Episode reward": 5.324002761709849, "Episode length": 949, "Policy Loss": 0.385162889957428, "Value Loss": 9.559571266174316, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503, 1.425419569015503]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.8913960456848145, -2.8453240394592285, -1.7992522716522217, -0.7531805038452148, 0.2928915023803711, 1.338963508605957, 2.3850350379943848, 3.4311070442199707, 4.477179050445557, 5.523251056671143, 6.5693230628967285, 7.6153950691223145, 8.661466598510742, 9.707538604736328, 10.753610610961914, 11.7996826171875, 12.845754623413086, 13.891826629638672, 14.937898635864258, 15.983970642089844, 17.03004264831543, 18.076114654541016, 19.1221866607666, 20.168258666992188, 21.21432876586914, 22.260400772094727, 23.306472778320312, 24.3525447845459, 25.398616790771484, 26.44468879699707, 27.490760803222656, 28.536834716796875, 29.582904815673828, 30.62897491455078, 31.675048828125, 32.72111892700195, 33.76719284057617, 34.813262939453125, 35.859336853027344, 36.9054069519043, 37.951480865478516, 38.99755096435547, 40.04362487792969, 41.08969497680664, 42.13576889038086, 43.18183898925781, 44.22791290283203, 45.273983001708984, 46.32005310058594, 47.366127014160156, 48.41219711303711, 49.45827102661133, 50.50434112548828, 51.5504150390625, 52.59648513793945, 53.64255905151367, 54.688629150390625, 55.734703063964844, 56.7807731628418, 57.826847076416016, 58.87291717529297, 59.91899108886719, 60.965065002441406, 62.011131286621094, 63.05720520019531]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0760909765958786, -0.027896519750356674, 0.020297937095165253, 0.06849239766597748, 0.1166868507862091, 0.16488130390644073, 0.21307577192783356, 0.2612702250480652, 0.309464693069458, 0.35765916109085083, 0.4058535695075989, 0.4540480375289917, 0.5022425055503845, 0.5504369735717773, 0.5986313819885254, 0.6468258500099182, 0.695020318031311, 0.7432147860527039, 0.7914092540740967, 0.8396036624908447, 0.8877981305122375, 0.9359926581382751, 0.9841870665550232, 1.032381534576416, 1.0805760622024536, 1.1287704706192017, 1.1769649982452393, 1.2251594066619873, 1.2733538150787354, 1.321548342704773, 1.369742751121521, 1.4179372787475586, 1.4661316871643066, 1.5143260955810547, 1.5625206232070923, 1.6107150316238403, 1.658909559249878, 1.707103967666626, 1.755298376083374, 1.8034929037094116, 1.8516873121261597, 1.8998818397521973, 1.9480763673782349, 1.996270775794983, 2.0444650650024414, 2.0926594734191895, 2.1408538818359375, 2.1890485286712646, 2.2372429370880127, 2.2854373455047607, 2.333631753921509, 2.381826162338257, 2.430020809173584, 2.478215217590332, 2.52640962600708, 2.574604034423828, 2.622798442840576, 2.6709930896759033, 2.7191874980926514, 2.7673819065093994, 2.8155763149261475, 2.8637707233428955, 2.9119653701782227, 2.9601597785949707, 3.0083541870117188]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 6.0, 47.0, 273.0, 129.0, 16.0, 5.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-2.444639205932617, -2.3212544918060303, -2.1978697776794434, -2.0744850635528564, -1.9511003494262695, -1.8277156352996826, -1.7043310403823853, -1.5809463262557983, -1.4575616121292114, -1.3341768980026245, -1.2107921838760376, -1.0874074697494507, -0.9640228748321533, -0.8406381607055664, -0.7172534465789795, -0.5938687324523926, -0.47048401832580566, -0.34709930419921875, -0.22371459007263184, -0.10032987594604492, 0.023054838180541992, 0.1464395523071289, 0.2698242664337158, 0.39320898056030273, 0.5165934562683105, 0.6399781703948975, 0.7633628845214844, 0.8867475986480713, 1.0101323127746582, 1.1335170269012451, 1.256901741027832, 1.380286455154419, 1.5036711692810059, 1.6270556449890137, 1.7504405975341797, 1.8738250732421875, 1.9972100257873535, 2.1205945014953613, 2.2439794540405273, 2.367363929748535, 2.490748882293701, 2.614133358001709, 2.737518310546875, 2.860902786254883, 2.984287738800049, 3.1076722145080566, 3.2310571670532227, 3.3544416427612305, 3.4778261184692383, 3.6012110710144043, 3.724595546722412, 3.847980499267578, 3.971364974975586, 4.094749927520752, 4.21813440322876, 4.341519355773926, 4.464903831481934, 4.5882887840271, 4.711673259735107, 4.835058212280273, 4.958442687988281, 5.081827640533447, 5.205212116241455, 5.328597068786621, 5.451981544494629]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-5.782793998718262, -5.526390552520752, -5.269987106323242, -5.013583183288574, -4.7571797370910645, -4.500776290893555, -4.244372367858887, -3.987968921661377, -3.731565475463867, -3.4751620292663574, -3.2187583446502686, -2.9623546600341797, -2.70595121383667, -2.44954776763916, -2.1931440830230713, -1.9367403984069824, -1.6803369522094727, -1.423933506011963, -1.1675300598144531, -0.9111261367797852, -0.6547226905822754, -0.3983192443847656, -0.14191532135009766, 0.11448812484741211, 0.3708915710449219, 0.6272950172424316, 0.8836984634399414, 1.1401023864746094, 1.3965058326721191, 1.652909278869629, 1.9093132019042969, 2.1657166481018066, 2.4221200942993164, 2.6785240173339844, 2.934926986694336, 3.191330909729004, 3.4477338790893555, 3.7041378021240234, 3.9605417251586914, 4.216944694519043, 4.473348617553711, 4.729752540588379, 4.9861555099487305, 5.242559432983398, 5.498963356018066, 5.755366325378418, 6.011770248413086, 6.2681732177734375, 6.5245771408081055, 6.780981063842773, 7.037384033203125, 7.293787956237793, 7.5501909255981445, 7.8065948486328125, 8.06299877166748, 8.319401741027832, 8.5758056640625, 8.832209587097168, 9.08861255645752, 9.345016479492188, 9.601420402526855, 9.857823371887207, 10.114227294921875, 10.370631217956543, 10.627034187316895]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 4.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 10.0, 3.0, 2.0, 2.0, 0.0, 3.0, 7.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0], "bins": [-3.2748827934265137, -3.2110533714294434, -3.147223711013794, -3.0833942890167236, -3.019564628601074, -2.955735206604004, -2.8919055461883545, -2.828076124191284, -2.7642464637756348, -2.7004170417785645, -2.636587381362915, -2.5727579593658447, -2.5089282989501953, -2.445098876953125, -2.3812694549560547, -2.3174397945404053, -2.253610134124756, -2.1897807121276855, -2.1259512901306152, -2.062121629714966, -1.998292088508606, -1.934462547302246, -1.8706330060958862, -1.8068034648895264, -1.742974042892456, -1.6791445016860962, -1.6153149604797363, -1.5514854192733765, -1.4876558780670166, -1.4238263368606567, -1.3599967956542969, -1.296167254447937, -1.2323377132415771, -1.1685082912445068, -1.1046786308288574, -1.040849208831787, -0.9770195484161377, -0.9131901264190674, -0.849360466003418, -0.7855310440063477, -0.7217013835906982, -0.6578719615936279, -0.5940423011779785, -0.5302128791809082, -0.4663832187652588, -0.4025537967681885, -0.33872413635253906, -0.27489471435546875, -0.21106529235839844, -0.14723563194274902, -0.08340620994567871, -0.019576549530029297, 0.044252872467041016, 0.10808253288269043, 0.17191195487976074, 0.23574161529541016, 0.29957103729248047, 0.3634006977081299, 0.4272301197052002, 0.4910597801208496, 0.5548892021179199, 0.6187188625335693, 0.6825482845306396, 0.7463779449462891, 0.8102073669433594]}, "_runtime": 20272.36359667778, "_timestamp": 1585617641.9964662, "_step": 398}
{"Episode reward": 33.23414585719826, "Episode length": 671, "Policy Loss": 0.5648080706596375, "Value Loss": 13.911559104919434, "_runtime": 20273.431577920914, "_timestamp": 1585617643.0644474, "_step": 399}
{"Episode reward": 33.34216398673259, "Episode length": 668, "Policy Loss": 0.6572620272636414, "Value Loss": 13.863824844360352, "_runtime": 20275.01548910141, "_timestamp": 1585617644.6483586, "_step": 400}
{"Episode reward": -99.73715560912248, "Episode length": 999, "Policy Loss": -0.219688281416893, "Value Loss": 0.13239817321300507, "_runtime": 20276.571134090424, "_timestamp": 1585617646.2040036, "_step": 401}
{"Episode reward": -99.77560102318718, "Episode length": 999, "Policy Loss": -0.15640060603618622, "Value Loss": 0.08863653987646103, "_runtime": 20277.336918592453, "_timestamp": 1585617646.969788, "_step": 402}
{"Episode reward": 52.40193777892233, "Episode length": 477, "Policy Loss": 1.2207056283950806, "Value Loss": 17.510711669921875, "_runtime": 20278.78257369995, "_timestamp": 1585617648.4154432, "_step": 403}
{"Episode reward": 9.620336877303757, "Episode length": 906, "Policy Loss": 0.47308653593063354, "Value Loss": 10.21407413482666, "_runtime": 20280.37952852249, "_timestamp": 1585617650.012398, "_step": 404}
{"Episode reward": -99.45106185145424, "Episode length": 999, "Policy Loss": -0.3456750214099884, "Value Loss": 0.01892418973147869, "_runtime": 20280.980464696884, "_timestamp": 1585617650.6133342, "_step": 405}
{"Episode reward": 61.82277776646634, "Episode length": 384, "Policy Loss": 1.069188117980957, "Value Loss": 22.101240158081055, "_runtime": 20282.364766597748, "_timestamp": 1585617651.997636, "_step": 406}
{"Episode reward": 12.7463865648147, "Episode length": 876, "Policy Loss": 0.26598167419433594, "Value Loss": 12.022368431091309, "_runtime": 20283.95882844925, "_timestamp": 1585617653.591698, "_step": 407}
{"Episode reward": -99.74719448431505, "Episode length": 999, "Policy Loss": -0.5857480764389038, "Value Loss": 0.013993263244628906, "_runtime": 20285.490644454956, "_timestamp": 1585617655.123514, "_step": 408}
{"Episode reward": -99.59518148679642, "Episode length": 999, "Policy Loss": -0.590198814868927, "Value Loss": 0.021743128076195717, "_runtime": 20287.056240797043, "_timestamp": 1585617656.6891103, "_step": 409}
{"Episode reward": 1.3660796398659585, "Episode length": 989, "Policy Loss": -0.09776049107313156, "Value Loss": 8.215372085571289, "_runtime": 20288.65460371971, "_timestamp": 1585617658.2874732, "_step": 410}
{"Episode reward": -99.65916395059764, "Episode length": 999, "Policy Loss": -0.5921204090118408, "Value Loss": 0.3002490699291229, "_runtime": 20289.34681892395, "_timestamp": 1585617658.9796884, "_step": 411}
{"Episode reward": 60.501938158105105, "Episode length": 395, "Policy Loss": 0.6912735104560852, "Value Loss": 23.327680587768555, "_runtime": 20289.739703178406, "_timestamp": 1585617659.3725727, "_step": 412}
{"Episode reward": 77.89999999999996, "Episode length": 221, "Policy Loss": 1.9930986166000366, "Value Loss": 40.449153900146484, "_runtime": 20291.325922966003, "_timestamp": 1585617660.9587924, "_step": 413}
{"Episode reward": -99.37645685870092, "Episode length": 999, "Policy Loss": -0.7377927899360657, "Value Loss": 0.069735586643219, "_runtime": 20292.86508178711, "_timestamp": 1585617662.4979513, "_step": 414}
{"Episode reward": -99.50162221946384, "Episode length": 999, "Policy Loss": -0.7034087181091309, "Value Loss": 0.04957578331232071, "_runtime": 20293.834740161896, "_timestamp": 1585617663.4676096, "_step": 415}
{"Episode reward": 36.08185489062972, "Episode length": 642, "Policy Loss": 0.030920986086130142, "Value Loss": 14.932352066040039, "_runtime": 20295.43466448784, "_timestamp": 1585617665.067534, "_step": 416}
{"Episode reward": -99.56717746428193, "Episode length": 999, "Policy Loss": -0.737722635269165, "Value Loss": 0.0307806096971035, "_runtime": 20297.019060373306, "_timestamp": 1585617666.6519299, "_step": 417}
{"Episode reward": -99.71878213407332, "Episode length": 999, "Policy Loss": -0.704199492931366, "Value Loss": 0.029005059972405434, "_runtime": 20298.040274381638, "_timestamp": 1585617667.6731439, "_step": 418}
{"Episode reward": 33.243717737885405, "Episode length": 670, "Policy Loss": 0.09086897224187851, "Value Loss": 12.639822959899902, "_runtime": 20299.639099121094, "_timestamp": 1585617669.2719686, "_step": 419}
{"Episode reward": -99.23197624923387, "Episode length": 999, "Policy Loss": -0.6088570952415466, "Value Loss": 0.012265834026038647, "_runtime": 20301.223967552185, "_timestamp": 1585617670.856837, "_step": 420}
{"Episode reward": -99.5624964582618, "Episode length": 999, "Policy Loss": -0.5944769382476807, "Value Loss": 0.021128440275788307, "_runtime": 20301.798127174377, "_timestamp": 1585617671.4309967, "_step": 421}
{"Episode reward": 64.61091588027608, "Episode length": 354, "Policy Loss": 0.835540235042572, "Value Loss": 22.242496490478516, "_runtime": 20302.470600128174, "_timestamp": 1585617672.1034696, "_step": 422}
{"Episode reward": 58.98091141020383, "Episode length": 411, "Policy Loss": 0.8893594741821289, "Value Loss": 20.193134307861328, "_runtime": 20303.505564928055, "_timestamp": 1585617673.1384344, "_step": 423}
{"Episode reward": 35.25174377450398, "Episode length": 652, "Policy Loss": 0.684097409248352, "Value Loss": 11.938122749328613, "_runtime": 20304.540256261826, "_timestamp": 1585617674.1731257, "_step": 424}
{"Episode reward": 32.89767457199942, "Episode length": 675, "Policy Loss": 0.4345476031303406, "Value Loss": 13.482928276062012, "_runtime": 20306.073040485382, "_timestamp": 1585617675.70591, "_step": 425}
{"Episode reward": -99.45176427650156, "Episode length": 999, "Policy Loss": -0.5829465985298157, "Value Loss": 0.06613761931657791, "_runtime": 20307.632271766663, "_timestamp": 1585617677.2651412, "_step": 426}
{"Episode reward": -99.72127736989502, "Episode length": 999, "Policy Loss": -0.5829777717590332, "Value Loss": 0.06786970794200897, "_runtime": 20309.174382209778, "_timestamp": 1585617678.8072517, "_step": 427}
{"Episode reward": -99.75344599488169, "Episode length": 999, "Policy Loss": -0.5522064566612244, "Value Loss": 0.148344486951828, "_runtime": 20310.76307439804, "_timestamp": 1585617680.3959439, "_step": 428}
{"Episode reward": -99.80005200342717, "Episode length": 999, "Policy Loss": -0.6060086488723755, "Value Loss": 0.06506045162677765, "_runtime": 20311.557945251465, "_timestamp": 1585617681.1908147, "_step": 429}
{"Episode reward": 51.87685330442578, "Episode length": 483, "Policy Loss": 0.5110594034194946, "Value Loss": 19.105409622192383, "_runtime": 20312.927300214767, "_timestamp": 1585617682.5601697, "_step": 430}
{"Episode reward": 13.179484134356443, "Episode length": 871, "Policy Loss": 0.006184828467667103, "Value Loss": 8.715380668640137, "_runtime": 20314.504440546036, "_timestamp": 1585617684.13731, "_step": 431}
{"Episode reward": -99.41817135135652, "Episode length": 999, "Policy Loss": -0.74606853723526, "Value Loss": 0.031121771782636642, "_runtime": 20315.991864681244, "_timestamp": 1585617685.6247342, "_step": 432}
{"Episode reward": 6.438433570712689, "Episode length": 938, "Policy Loss": -0.2299003005027771, "Value Loss": 8.776956558227539, "_runtime": 20317.57092475891, "_timestamp": 1585617687.2037942, "_step": 433}
{"Episode reward": -99.64378897522555, "Episode length": 999, "Policy Loss": -0.8095306754112244, "Value Loss": 0.03714686632156372, "_runtime": 20319.16193127632, "_timestamp": 1585617688.7948008, "_step": 434}
{"Episode reward": -99.75720779925328, "Episode length": 999, "Policy Loss": -0.8377426862716675, "Value Loss": 0.028882957994937897, "_runtime": 20320.73805999756, "_timestamp": 1585617690.3709295, "_step": 435}
{"Episode reward": -99.851942424661, "Episode length": 999, "Policy Loss": -0.8960506916046143, "Value Loss": 0.021515652537345886, "_runtime": 20322.34003829956, "_timestamp": 1585617691.9729078, "_step": 436}
{"Episode reward": -99.62182458505711, "Episode length": 999, "Policy Loss": -0.8992323875427246, "Value Loss": 0.022725572809576988, "_runtime": 20323.939367055893, "_timestamp": 1585617693.5722365, "_step": 437}
{"Episode reward": -99.61013090342611, "Episode length": 999, "Policy Loss": -0.9261201620101929, "Value Loss": 0.03071403317153454, "_runtime": 20325.14879655838, "_timestamp": 1585617694.781666, "_step": 438}
{"Episode reward": 23.395657711610042, "Episode length": 768, "Policy Loss": -0.1383109986782074, "Value Loss": 12.170472145080566, "_runtime": 20325.935189962387, "_timestamp": 1585617695.5680594, "_step": 439}
{"Episode reward": 52.44692469177777, "Episode length": 477, "Policy Loss": 0.1000317931175232, "Value Loss": 15.39862060546875, "_runtime": 20326.78237748146, "_timestamp": 1585617696.415247, "_step": 440}
{"Episode reward": 48.02761595808942, "Episode length": 520, "Policy Loss": 0.3784841001033783, "Value Loss": 17.66545295715332, "_runtime": 20328.352734327316, "_timestamp": 1585617697.9856038, "_step": 441}
{"Episode reward": -99.59696912643129, "Episode length": 999, "Policy Loss": -0.7473188638687134, "Value Loss": 0.018291734158992767, "_runtime": 20329.366468906403, "_timestamp": 1585617698.9993384, "_step": 442}
{"Episode reward": 35.04314188262157, "Episode length": 650, "Policy Loss": 0.24781757593154907, "Value Loss": 13.061225891113281, "_runtime": 20330.896825313568, "_timestamp": 1585617700.5296948, "_step": 443}
{"Episode reward": -99.81477687750454, "Episode length": 999, "Policy Loss": -0.6760327219963074, "Value Loss": 0.015800874680280685, "_runtime": 20332.483170986176, "_timestamp": 1585617702.1160405, "_step": 444}
{"Episode reward": -99.46433938114068, "Episode length": 999, "Policy Loss": -0.6855573058128357, "Value Loss": 0.03779956325888634, "_runtime": 20333.793434858322, "_timestamp": 1585617703.4263043, "_step": 445}
{"Episode reward": 16.27096149257315, "Episode length": 840, "Policy Loss": -0.07285111397504807, "Value Loss": 9.555222511291504, "_runtime": 20335.38008761406, "_timestamp": 1585617705.012957, "_step": 446}
{"Episode reward": -99.62756668178342, "Episode length": 999, "Policy Loss": -0.700631320476532, "Value Loss": 0.01717660389840603, "_runtime": 20336.97950387001, "_timestamp": 1585617706.6123734, "_step": 447}
{"Episode reward": -99.82133327023918, "Episode length": 999, "Policy Loss": -0.7433319687843323, "Value Loss": 0.0248569305986166, "_runtime": 20338.53840994835, "_timestamp": 1585617708.1712794, "_step": 448}
{"Episode reward": -99.63560715482464, "Episode length": 999, "Policy Loss": -0.754753828048706, "Value Loss": 0.01942450739443302, "_runtime": 20340.17366695404, "_timestamp": 1585617709.8065364, "_step": 449}
{"Episode reward": -99.51435231536169, "Episode length": 999, "Policy Loss": -0.798337459564209, "Value Loss": 0.031146138906478882, "_runtime": 20341.78119778633, "_timestamp": 1585617711.4140673, "_step": 450}
{"Episode reward": -99.71439588140208, "Episode length": 999, "Policy Loss": -0.8082990050315857, "Value Loss": 0.02950042486190796, "_runtime": 20343.37570953369, "_timestamp": 1585617713.008579, "_step": 451}
{"Episode reward": -99.74061949482862, "Episode length": 999, "Policy Loss": -0.7327659726142883, "Value Loss": 0.01738179288804531, "_runtime": 20344.97384619713, "_timestamp": 1585617714.6067157, "_step": 452}
{"Episode reward": -99.3875227979618, "Episode length": 999, "Policy Loss": -0.6966161727905273, "Value Loss": 0.0171582642942667, "_runtime": 20346.567960500717, "_timestamp": 1585617716.20083, "_step": 453}
{"Episode reward": -99.73450925553195, "Episode length": 999, "Policy Loss": -0.6706537008285522, "Value Loss": 0.026667432859539986, "_runtime": 20348.16089963913, "_timestamp": 1585617717.7937691, "_step": 454}
{"Episode reward": -99.47669263233556, "Episode length": 999, "Policy Loss": -0.6289734840393066, "Value Loss": 0.01887873187661171, "_runtime": 20349.75588274002, "_timestamp": 1585617719.3887522, "_step": 455}
{"Episode reward": -99.60636805296971, "Episode length": 999, "Policy Loss": -0.6193763017654419, "Value Loss": 0.023388845846056938, "_runtime": 20351.34999203682, "_timestamp": 1585617720.9828615, "_step": 456}
{"Episode reward": -99.71135545871662, "Episode length": 999, "Policy Loss": -0.5545847415924072, "Value Loss": 0.021294789388775826, "_runtime": 20352.956459999084, "_timestamp": 1585617722.5893295, "_step": 457}
{"Episode reward": -99.37428894132472, "Episode length": 999, "Policy Loss": -0.5277667045593262, "Value Loss": 0.010978754609823227, "_runtime": 20354.540191173553, "_timestamp": 1585617724.1730607, "_step": 458}
{"Episode reward": -99.7544329498302, "Episode length": 999, "Policy Loss": -0.5183236598968506, "Value Loss": 0.01801968924701214, "_runtime": 20355.699320316315, "_timestamp": 1585617725.3321898, "_step": 459}
{"Episode reward": 28.319825815100714, "Episode length": 719, "Policy Loss": 0.24042461812496185, "Value Loss": 11.009575843811035, "_runtime": 20357.1932220459, "_timestamp": 1585617726.8260915, "_step": 460}
{"Episode reward": 6.688177706705318, "Episode length": 938, "Policy Loss": 0.10863149911165237, "Value Loss": 9.41142463684082, "_runtime": 20358.621785402298, "_timestamp": 1585617728.254655, "_step": 461}
{"Episode reward": 10.90553111761443, "Episode length": 894, "Policy Loss": 0.18529687821865082, "Value Loss": 9.423237800598145, "_runtime": 20360.205805301666, "_timestamp": 1585617729.8386748, "_step": 462}
{"Episode reward": -99.64411806885482, "Episode length": 999, "Policy Loss": -0.4718465805053711, "Value Loss": 0.010535233654081821, "_runtime": 20361.445026636124, "_timestamp": 1585617731.077896, "_step": 463}
{"Episode reward": 22.42715559984076, "Episode length": 778, "Policy Loss": 0.23492777347564697, "Value Loss": 10.917717933654785, "_runtime": 20362.91209936142, "_timestamp": 1585617732.5449688, "_step": 464}
{"Episode reward": 7.545731022369608, "Episode length": 927, "Policy Loss": 0.021026479080319405, "Value Loss": 8.956806182861328, "_runtime": 20364.540443897247, "_timestamp": 1585617734.1733134, "_step": 465}
{"Episode reward": -99.69443541106746, "Episode length": 999, "Policy Loss": -0.4147428572177887, "Value Loss": 0.09696695953607559, "_runtime": 20366.11623764038, "_timestamp": 1585617735.7491071, "_step": 466}
{"Episode reward": -99.2097831861117, "Episode length": 999, "Policy Loss": -0.32555529475212097, "Value Loss": 0.17163051664829254, "_runtime": 20367.360602378845, "_timestamp": 1585617736.9934719, "_step": 467}
{"Episode reward": 22.199682556495887, "Episode length": 779, "Policy Loss": 0.19784806668758392, "Value Loss": 12.230788230895996, "_runtime": 20368.446868658066, "_timestamp": 1585617738.0797381, "_step": 468}
{"Episode reward": 32.94830216251448, "Episode length": 677, "Policy Loss": 0.21779823303222656, "Value Loss": 12.210186004638672, "_runtime": 20369.715839147568, "_timestamp": 1585617739.3487086, "_step": 469}
{"Episode reward": 20.65358746379958, "Episode length": 796, "Policy Loss": 0.13625536859035492, "Value Loss": 10.794716835021973, "_runtime": 20371.301327943802, "_timestamp": 1585617740.9341974, "_step": 470}
{"Episode reward": -99.43512682487354, "Episode length": 999, "Policy Loss": -0.6850174069404602, "Value Loss": 0.12419978529214859, "_runtime": 20372.51060795784, "_timestamp": 1585617742.1434774, "_step": 471}
{"Episode reward": 24.36108758784661, "Episode length": 763, "Policy Loss": -0.13128088414669037, "Value Loss": 12.163167953491211, "_runtime": 20374.006980657578, "_timestamp": 1585617743.6398501, "_step": 472}
{"Episode reward": 4.58470888689159, "Episode length": 958, "Policy Loss": -0.2768974304199219, "Value Loss": 10.015353202819824, "_runtime": 20375.604271173477, "_timestamp": 1585617745.2371407, "_step": 473}
{"Episode reward": -99.341462453465, "Episode length": 999, "Policy Loss": -1.1007803678512573, "Value Loss": 0.06389344483613968, "_runtime": 20376.927670240402, "_timestamp": 1585617746.5605397, "_step": 474}
{"Episode reward": 16.358599941684346, "Episode length": 838, "Policy Loss": -0.5672025680541992, "Value Loss": 10.10975170135498, "_runtime": 20378.504633188248, "_timestamp": 1585617748.1375027, "_step": 475}
{"Episode reward": -99.40742715864248, "Episode length": 999, "Policy Loss": -1.2639212608337402, "Value Loss": 0.16058780252933502, "_runtime": 20380.096029281616, "_timestamp": 1585617749.7288988, "_step": 476}
{"Episode reward": -99.28293005127934, "Episode length": 999, "Policy Loss": -1.3855241537094116, "Value Loss": 0.14577452838420868, "_runtime": 20381.677389860153, "_timestamp": 1585617751.3102593, "_step": 477}
{"Episode reward": -99.86198013392719, "Episode length": 999, "Policy Loss": -1.321802020072937, "Value Loss": 0.09911234676837921, "_runtime": 20383.27789592743, "_timestamp": 1585617752.9107654, "_step": 478}
{"Episode reward": -99.67023246132165, "Episode length": 999, "Policy Loss": -1.2724355459213257, "Value Loss": 0.10987459123134613, "_runtime": 20384.684220075607, "_timestamp": 1585617754.3170896, "_step": 479}
{"Episode reward": 12.226165427863066, "Episode length": 881, "Policy Loss": -0.6449074149131775, "Value Loss": 10.910665512084961, "_runtime": 20386.226425647736, "_timestamp": 1585617755.8592951, "_step": 480}
{"Episode reward": 3.2756788212061565, "Episode length": 970, "Policy Loss": -0.6434453725814819, "Value Loss": 9.315346717834473, "_runtime": 20387.868703126907, "_timestamp": 1585617757.5015726, "_step": 481}
{"Episode reward": -99.66689053686943, "Episode length": 999, "Policy Loss": -1.2498456239700317, "Value Loss": 0.06210877746343613, "_runtime": 20389.4539437294, "_timestamp": 1585617759.0868132, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1670639514923096, "Value Loss": 0.10841474682092667, "_runtime": 20391.03450345993, "_timestamp": 1585617760.667373, "_step": 483}
{"Episode reward": -99.48531042345428, "Episode length": 999, "Policy Loss": -1.1656132936477661, "Value Loss": 0.08277665823698044, "_runtime": 20392.629764556885, "_timestamp": 1585617762.262634, "_step": 484}
{"Episode reward": -99.2117930167763, "Episode length": 999, "Policy Loss": -1.0647937059402466, "Value Loss": 0.2532385289669037, "_runtime": 20393.53217601776, "_timestamp": 1585617763.1650455, "_step": 485}
{"Episode reward": 44.5862791992195, "Episode length": 556, "Policy Loss": -0.01908915676176548, "Value Loss": 15.158109664916992, "_runtime": 20394.560332536697, "_timestamp": 1585617764.193202, "_step": 486}
{"Episode reward": 36.77396542496801, "Episode length": 635, "Policy Loss": -0.0873054787516594, "Value Loss": 12.028205871582031, "_runtime": 20396.099699258804, "_timestamp": 1585617765.7325687, "_step": 487}
{"Episode reward": 2.9801525076267126, "Episode length": 975, "Policy Loss": -0.3307875096797943, "Value Loss": 7.976851463317871, "_runtime": 20397.071328401566, "_timestamp": 1585617766.704198, "_step": 488}
{"Episode reward": 38.5566103435915, "Episode length": 617, "Policy Loss": 0.14797475934028625, "Value Loss": 13.111515045166016, "_runtime": 20398.126690626144, "_timestamp": 1585617767.75956, "_step": 489}
{"Episode reward": 33.19943162967961, "Episode length": 669, "Policy Loss": 0.3026913106441498, "Value Loss": 15.43458080291748, "_runtime": 20399.70706653595, "_timestamp": 1585617769.339936, "_step": 490}
{"Episode reward": -99.67074139086041, "Episode length": 999, "Policy Loss": -0.5533807873725891, "Value Loss": 0.038818202912807465, "_runtime": 20401.202216386795, "_timestamp": 1585617770.8350859, "_step": 491}
{"Episode reward": 3.4221763651815564, "Episode length": 969, "Policy Loss": 0.14919376373291016, "Value Loss": 9.247445106506348, "_runtime": 20402.39938020706, "_timestamp": 1585617772.0322497, "_step": 492}
{"Episode reward": 23.18018046616207, "Episode length": 770, "Policy Loss": 0.2891669273376465, "Value Loss": 10.7435302734375, "_runtime": 20403.984744548798, "_timestamp": 1585617773.617614, "_step": 493}
{"Episode reward": -99.76222807024467, "Episode length": 999, "Policy Loss": -0.5014433264732361, "Value Loss": 0.08428509533405304, "_runtime": 20405.096654891968, "_timestamp": 1585617774.7295244, "_step": 494}
{"Episode reward": 30.394582692504315, "Episode length": 697, "Policy Loss": 0.24535661935806274, "Value Loss": 12.622965812683105, "_runtime": 20406.406880140305, "_timestamp": 1585617776.0397496, "_step": 495}
{"Episode reward": 16.391697132215384, "Episode length": 837, "Policy Loss": 0.09839857369661331, "Value Loss": 10.378170013427734, "_runtime": 20407.999311685562, "_timestamp": 1585617777.6321812, "_step": 496}
{"Episode reward": -99.42484962485062, "Episode length": 999, "Policy Loss": -0.5220819711685181, "Value Loss": 0.3031448721885681, "_runtime": 20409.563141584396, "_timestamp": 1585617779.196011, "_step": 497}
{"Episode reward": -99.72316858212855, "Episode length": 999, "Policy Loss": -0.19512708485126495, "Value Loss": 0.008338813669979572, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169, 0.004424639046192169]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0679868534207344, -0.06291700154542923, -0.05784715339541435, -0.052777305245399475, -0.0477074533700943, -0.04263760522007942, -0.037567757070064545, -0.03249790519475937, -0.02742805704474449, -0.022358208894729614, -0.01728835701942444, -0.012218508869409561, -0.007148660719394684, -0.002078808844089508, 0.0029910430312156677, 0.008060887455940247, 0.013130739331245422, 0.018200591206550598, 0.023270435631275177, 0.028340287506580353, 0.03341013938188553, 0.03847998380661011, 0.04354983568191528, 0.04861968755722046, 0.05368953198194504, 0.058759383857250214, 0.06382923573255539, 0.06889908760786057, 0.07396893948316574, 0.07903877645730972, 0.0841086283326149, 0.08917848020792007, 0.09424833208322525, 0.09931818395853043, 0.1043880358338356, 0.10945788770914078, 0.11452772468328476, 0.11959757655858994, 0.12466742843389511, 0.12973728775978088, 0.13480713963508606, 0.13987699151039124, 0.14494681358337402, 0.1500166654586792, 0.15508651733398438, 0.16015636920928955, 0.16522622108459473, 0.1702960729598999, 0.17536592483520508, 0.18043577671051025, 0.18550562858581543, 0.1905754804611206, 0.19564533233642578, 0.20071518421173096, 0.20578503608703613, 0.2108548879623413, 0.21592473983764648, 0.22099459171295166, 0.22606441378593445, 0.23113426566123962, 0.2362041175365448, 0.24127396941184998, 0.24634382128715515, 0.2514136731624603, 0.2564835250377655]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.004173216409981251, -0.0037413453683257103, -0.00330947432667017, -0.0028776032850146294, -0.002445732243359089, -0.0020138612017035484, -0.001581990160048008, -0.0011501191183924675, -0.000718248076736927, -0.00028637703508138657, 0.0001454940065741539, 0.0005773650482296944, 0.0010092360898852348, 0.0014411071315407753, 0.0018729781731963158, 0.0023048492148518562, 0.0027367202565073967, 0.003168591298162937, 0.0036004623398184776, 0.004032333381474018, 0.0044642044231295586, 0.004896075464785099, 0.0053279465064406395, 0.00575981754809618, 0.00619168858975172, 0.006623559631407261, 0.007055430673062801, 0.007487301714718342, 0.007919172756373882, 0.008351043798029423, 0.008782914839684963, 0.009214785881340504, 0.009646656922996044, 0.010078527964651585, 0.010510399006307125, 0.010942270047962666, 0.011374141089618206, 0.011806012131273746, 0.012237883172929287, 0.012669754214584827, 0.013101625256240368, 0.013533496297895908, 0.013965367339551449, 0.01439723838120699, 0.01482910942286253, 0.01526098046451807, 0.015692852437496185, 0.016124721616506577, 0.016556594520807266, 0.016988463699817657, 0.017420336604118347, 0.01785220578312874, 0.018284078687429428, 0.01871594786643982, 0.01914782077074051, 0.0195796899497509, 0.02001156285405159, 0.02044343203306198, 0.02087530493736267, 0.021307174116373062, 0.021739047020673752, 0.022170916199684143, 0.022602789103984833, 0.023034658282995224, 0.023466531187295914]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 3.0, 7.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 11.0, 18.0, 14.0, 13.0, 40.0, 23.0, 19.0, 31.0, 198.0, 14.0, 41.0, 14.0, 4.0, 3.0, 2.0, 3.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 5.0, 3.0, 1.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.027180196717381477, -0.025963719934225082, -0.024747241288423538, -0.023530764505267143, -0.02231428772211075, -0.021097809076309204, -0.01988133229315281, -0.018664855509996414, -0.01744837686419487, -0.016231900081038475, -0.01501542329788208, -0.01379894558340311, -0.012582467868924141, -0.011365991085767746, -0.010149514302611351, -0.008933035656809807, -0.007716558873653412, -0.006500082090497017, -0.005283603444695473, -0.004067126661539078, -0.002850649878382683, -0.0016341712325811386, -0.00041769444942474365, 0.0007987823337316513, 0.0020152609795331955, 0.0032317377626895905, 0.004448214545845985, 0.00566469319164753, 0.006881168112158775, 0.00809764675796032, 0.009314125403761864, 0.01053060032427311, 0.011747078970074654, 0.012963557615876198, 0.014180032536387444, 0.015396511182188988, 0.016612989827990532, 0.017829464748501778, 0.019045943394303322, 0.020262422040104866, 0.021478896960616112, 0.022695375606417656, 0.0239118542522192, 0.025128329172730446, 0.02634480781853199, 0.027561286464333534, 0.02877776138484478, 0.029994240030646324, 0.03121071867644787, 0.032427191734313965, 0.03364367038011551, 0.03486014902591705, 0.0360766276717186, 0.03729310631752014, 0.038509584963321686, 0.03972606360912323, 0.04094253480434418, 0.04215901345014572, 0.043375492095947266, 0.04459197074174881, 0.045808449387550354, 0.0470249280333519, 0.048241399228572845, 0.04945787787437439, 0.050674356520175934]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 4.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06042813882231712, -0.05741707980632782, -0.054406024515628815, -0.05139496549963951, -0.04838390648365021, -0.0453728511929512, -0.0423617921769619, -0.039350733160972595, -0.03633967787027359, -0.033328618854284286, -0.030317559838294983, -0.02730650082230568, -0.024295445531606674, -0.02128438651561737, -0.018273327499628067, -0.015262272208929062, -0.012251213192939758, -0.009240154176950455, -0.00622909888625145, -0.003218039870262146, -0.0002069808542728424, 0.0028040744364261627, 0.005815137177705765, 0.00882619246840477, 0.011837247759103775, 0.014848310500383377, 0.017859365791082382, 0.020870421081781387, 0.02388148382306099, 0.026892539113759995, 0.029903594404459, 0.0329146571457386, 0.03592571243643761, 0.03893676772713661, 0.041947830468416214, 0.04495888575911522, 0.047969941049814224, 0.050981003791093826, 0.05399205908179283, 0.05700311437249184, 0.06001417711377144, 0.06302523612976074, 0.06603628396987915, 0.06904734671115875, 0.07205840945243835, 0.07506945729255676, 0.07808052003383636, 0.08109158277511597, 0.08410263061523438, 0.08711369335651398, 0.09012475609779358, 0.09313580393791199, 0.09614686667919159, 0.09915792942047119, 0.1021689772605896, 0.1051800400018692, 0.1081911027431488, 0.11120215058326721, 0.11421321332454681, 0.11722427606582642, 0.12023532390594482, 0.12324638664722443, 0.12625744938850403, 0.12926849722862244, 0.13227955996990204]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 3.0, 5.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 5.0, 4.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.036785125732421875, -0.03516296669840813, -0.03354080393910408, -0.03191864490509033, -0.030296484008431435, -0.028674323111772537, -0.02705216407775879, -0.02543000318109989, -0.023807842284440994, -0.022185681387782097, -0.0205635204911232, -0.01894136145710945, -0.017319200560450554, -0.015697039663791656, -0.014074880629777908, -0.012452719733119011, -0.010830558836460114, -0.009208397939801216, -0.007586237043142319, -0.0059640780091285706, -0.004341915249824524, -0.0027197562158107758, -0.0010975971817970276, 0.000524565577507019, 0.002146724611520767, 0.0037688836455345154, 0.005391046404838562, 0.00701320543885231, 0.008635364472866058, 0.010257527232170105, 0.011879686266183853, 0.0135018490254879, 0.015124008059501648, 0.016746167093515396, 0.018368329852819443, 0.01999048888683319, 0.021612651646137238, 0.023234810680150986, 0.024856969714164734, 0.02647913247346878, 0.028101295232772827, 0.029723450541496277, 0.031345613300800323, 0.03296777606010437, 0.03458993136882782, 0.036212094128131866, 0.03783425688743591, 0.03945641219615936, 0.04107857495546341, 0.042700737714767456, 0.044322893023490906, 0.04594505578279495, 0.047567218542099, 0.04918937385082245, 0.050811536610126495, 0.05243369936943054, 0.05405585467815399, 0.05567801743745804, 0.057300180196762085, 0.05892234295606613, 0.06054449826478958, 0.06216666102409363, 0.06378882378339767, 0.06541097909212112, 0.06703314185142517]}, "_runtime": 20411.178652763367, "_timestamp": 1585617780.8115222, "_step": 498}
{"Episode reward": -99.5838982888367, "Episode length": 999, "Policy Loss": -0.007166950032114983, "Value Loss": 0.008357055485248566, "_runtime": 20411.178652763367, "_timestamp": 1585617780.8115222, "_step": 499}
