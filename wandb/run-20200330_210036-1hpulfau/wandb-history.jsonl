{"Episode reward": 75.20961101871656, "Episode length": 390, "Policy Loss": 0.3538348078727722, "Value Loss": 25.50013542175293, "_runtime": 4674.780942201614, "_timestamp": 1585602044.4138117, "_step": 0}
{"Episode reward": 74.3090988354229, "Episode length": 456, "Policy Loss": 2.5369162559509277, "Value Loss": 306.80413818359375, "_runtime": 4675.430635929108, "_timestamp": 1585602045.0635054, "_step": 1}
{"Episode reward": 73.8993736699867, "Episode length": 440, "Policy Loss": -0.9333289265632629, "Value Loss": 183.9223175048828, "_runtime": 4676.286535024643, "_timestamp": 1585602045.9194045, "_step": 2}
{"Episode reward": 68.5154036647127, "Episode length": 563, "Policy Loss": 2.401031017303467, "Value Loss": 172.5245361328125, "_runtime": 4676.741472005844, "_timestamp": 1585602046.3743415, "_step": 3}
{"Episode reward": 83.2353548823126, "Episode length": 285, "Policy Loss": 0.8114567995071411, "Value Loss": 67.21758270263672, "_runtime": 4677.079123497009, "_timestamp": 1585602046.711993, "_step": 4}
{"Episode reward": 87.31234110127762, "Episode length": 216, "Policy Loss": 0.3227401673793793, "Value Loss": 44.36381912231445, "_runtime": 4677.8801946640015, "_timestamp": 1585602047.5130641, "_step": 5}
{"Episode reward": 66.83310255275356, "Episode length": 526, "Policy Loss": 0.02056720480322838, "Value Loss": 19.87247657775879, "_runtime": 4678.593551158905, "_timestamp": 1585602048.2264206, "_step": 6}
{"Episode reward": 72.82624895723839, "Episode length": 471, "Policy Loss": 0.008966157212853432, "Value Loss": 23.347753524780273, "_runtime": 4679.286917448044, "_timestamp": 1585602048.919787, "_step": 7}
{"Episode reward": 73.55179928290886, "Episode length": 472, "Policy Loss": 0.2059558928012848, "Value Loss": 21.920406341552734, "_runtime": 4679.768871307373, "_timestamp": 1585602049.4017408, "_step": 8}
{"Episode reward": 82.44318779492615, "Episode length": 304, "Policy Loss": 0.3624386489391327, "Value Loss": 33.2082405090332, "_runtime": 4680.691034555435, "_timestamp": 1585602050.323904, "_step": 9}
{"Episode reward": 62.68640377998828, "Episode length": 607, "Policy Loss": -0.0848553255200386, "Value Loss": 16.399898529052734, "_runtime": 4681.381020307541, "_timestamp": 1585602051.0138898, "_step": 10}
{"Episode reward": 72.63985214587915, "Episode length": 449, "Policy Loss": 0.19582369923591614, "Value Loss": 22.009675979614258, "_runtime": 4681.961464643478, "_timestamp": 1585602051.5943341, "_step": 11}
{"Episode reward": 76.2040786463351, "Episode length": 383, "Policy Loss": -0.08293595910072327, "Value Loss": 26.335664749145508, "_runtime": 4682.321224689484, "_timestamp": 1585602051.9540942, "_step": 12}
{"Episode reward": 86.08533314655591, "Episode length": 220, "Policy Loss": 0.2754112482070923, "Value Loss": 43.887325286865234, "_runtime": 4682.969784975052, "_timestamp": 1585602052.6026545, "_step": 13}
{"Episode reward": 74.3898115314128, "Episode length": 425, "Policy Loss": -0.06865383684635162, "Value Loss": 23.676025390625, "_runtime": 4683.899358034134, "_timestamp": 1585602053.5322275, "_step": 14}
{"Episode reward": 63.81076746324286, "Episode length": 612, "Policy Loss": -0.10157889127731323, "Value Loss": 15.779294967651367, "_runtime": 4684.377331018448, "_timestamp": 1585602054.0102005, "_step": 15}
{"Episode reward": 80.53345671573956, "Episode length": 323, "Policy Loss": 0.17632992565631866, "Value Loss": 28.544105529785156, "_runtime": 4684.942877531052, "_timestamp": 1585602054.575747, "_step": 16}
{"Episode reward": 77.63566112251327, "Episode length": 371, "Policy Loss": 0.5197441577911377, "Value Loss": 24.490995407104492, "_runtime": 4685.580316781998, "_timestamp": 1585602055.2131863, "_step": 17}
{"Episode reward": 75.04771522025243, "Episode length": 416, "Policy Loss": -0.0015900868456810713, "Value Loss": 21.15965461730957, "_runtime": 4686.144906044006, "_timestamp": 1585602055.7777755, "_step": 18}
{"Episode reward": 77.00205763967554, "Episode length": 370, "Policy Loss": 0.2824292480945587, "Value Loss": 24.064537048339844, "_runtime": 4687.014652729034, "_timestamp": 1585602056.6475222, "_step": 19}
{"Episode reward": 64.98339314766802, "Episode length": 577, "Policy Loss": -0.0839979499578476, "Value Loss": 15.319117546081543, "_runtime": 4687.67195558548, "_timestamp": 1585602057.304825, "_step": 20}
{"Episode reward": 73.86488390964388, "Episode length": 428, "Policy Loss": 0.039459310472011566, "Value Loss": 20.356992721557617, "_runtime": 4688.402570962906, "_timestamp": 1585602058.0354404, "_step": 21}
{"Episode reward": 71.47092051775198, "Episode length": 479, "Policy Loss": -0.04523279145359993, "Value Loss": 17.808685302734375, "_runtime": 4689.342887878418, "_timestamp": 1585602058.9757574, "_step": 22}
{"Episode reward": 63.027479880359124, "Episode length": 608, "Policy Loss": -0.12002154439687729, "Value Loss": 14.205467224121094, "_runtime": 4689.904389858246, "_timestamp": 1585602059.5372593, "_step": 23}
{"Episode reward": 78.79286658952495, "Episode length": 369, "Policy Loss": 0.16458119451999664, "Value Loss": 22.460500717163086, "_runtime": 4690.3705677986145, "_timestamp": 1585602060.0034373, "_step": 24}
{"Episode reward": 80.81196424871187, "Episode length": 302, "Policy Loss": -0.0050424993969500065, "Value Loss": 26.76142692565918, "_runtime": 4690.817307710648, "_timestamp": 1585602060.4501772, "_step": 25}
{"Episode reward": 82.73107133217269, "Episode length": 282, "Policy Loss": 0.19772717356681824, "Value Loss": 30.127368927001953, "_runtime": 4691.374246835709, "_timestamp": 1585602061.0071163, "_step": 26}
{"Episode reward": 76.57905267222014, "Episode length": 370, "Policy Loss": 0.06668896228075027, "Value Loss": 23.545616149902344, "_runtime": 4691.843049526215, "_timestamp": 1585602061.475919, "_step": 27}
{"Episode reward": 80.44044269648036, "Episode length": 311, "Policy Loss": 0.011595690622925758, "Value Loss": 28.738134384155273, "_runtime": 4692.274466514587, "_timestamp": 1585602061.907336, "_step": 28}
{"Episode reward": 82.45714689451495, "Episode length": 285, "Policy Loss": 0.18573424220085144, "Value Loss": 29.001049041748047, "_runtime": 4692.839813709259, "_timestamp": 1585602062.4726832, "_step": 29}
{"Episode reward": 77.20578068931505, "Episode length": 376, "Policy Loss": 0.1346113383769989, "Value Loss": 22.49072265625, "_runtime": 4693.585721492767, "_timestamp": 1585602063.218591, "_step": 30}
{"Episode reward": 69.81474476618017, "Episode length": 499, "Policy Loss": 0.009272375144064426, "Value Loss": 16.756811141967773, "_runtime": 4693.952016830444, "_timestamp": 1585602063.5848863, "_step": 31}
{"Episode reward": 85.87848024156915, "Episode length": 231, "Policy Loss": 0.23543275892734528, "Value Loss": 37.834327697753906, "_runtime": 4694.51500248909, "_timestamp": 1585602064.147872, "_step": 32}
{"Episode reward": 75.49342472920802, "Episode length": 373, "Policy Loss": 0.07211919873952866, "Value Loss": 22.274202346801758, "_runtime": 4695.208802700043, "_timestamp": 1585602064.8416722, "_step": 33}
{"Episode reward": 72.55139998772549, "Episode length": 456, "Policy Loss": -0.06406854838132858, "Value Loss": 17.336076736450195, "_runtime": 4695.780209302902, "_timestamp": 1585602065.4130788, "_step": 34}
{"Episode reward": 78.18471893645858, "Episode length": 377, "Policy Loss": 0.04896870627999306, "Value Loss": 21.150056838989258, "_runtime": 4696.665053367615, "_timestamp": 1585602066.2979228, "_step": 35}
{"Episode reward": 65.00569882954184, "Episode length": 587, "Policy Loss": -0.12915362417697906, "Value Loss": 12.966485023498535, "_runtime": 4697.344524145126, "_timestamp": 1585602066.9773936, "_step": 36}
{"Episode reward": 74.60667827206332, "Episode length": 433, "Policy Loss": -0.06483781337738037, "Value Loss": 18.06450653076172, "_runtime": 4697.850335359573, "_timestamp": 1585602067.4832048, "_step": 37}
{"Episode reward": 80.5991367840621, "Episode length": 325, "Policy Loss": -0.05999505892395973, "Value Loss": 23.542173385620117, "_runtime": 4698.869093179703, "_timestamp": 1585602068.5019627, "_step": 38}
{"Episode reward": 59.231700209058765, "Episode length": 676, "Policy Loss": -0.1801093965768814, "Value Loss": 13.810364723205566, "_runtime": 4699.448590755463, "_timestamp": 1585602069.0814602, "_step": 39}
{"Episode reward": 78.42720823839295, "Episode length": 373, "Policy Loss": -0.056767988950014114, "Value Loss": 19.253978729248047, "_runtime": 4700.2814083099365, "_timestamp": 1585602069.9142778, "_step": 40}
{"Episode reward": 64.45364309315565, "Episode length": 559, "Policy Loss": -0.08170923590660095, "Value Loss": 12.862685203552246, "_runtime": 4701.005367279053, "_timestamp": 1585602070.6382368, "_step": 41}
{"Episode reward": 71.43738514602998, "Episode length": 461, "Policy Loss": -0.1655760556459427, "Value Loss": 15.500287055969238, "_runtime": 4701.569576501846, "_timestamp": 1585602071.202446, "_step": 42}
{"Episode reward": 77.92409896764626, "Episode length": 367, "Policy Loss": -0.1173831894993782, "Value Loss": 19.586524963378906, "_runtime": 4702.058215141296, "_timestamp": 1585602071.6910846, "_step": 43}
{"Episode reward": 80.12013876960127, "Episode length": 313, "Policy Loss": -0.055015288293361664, "Value Loss": 24.010427474975586, "_runtime": 4702.514634609222, "_timestamp": 1585602072.147504, "_step": 44}
{"Episode reward": 82.31817166360293, "Episode length": 299, "Policy Loss": 0.0954957827925682, "Value Loss": 23.414688110351562, "_runtime": 4703.975045204163, "_timestamp": 1585602073.6079147, "_step": 45}
{"Episode reward": 43.05692106524818, "Episode length": 976, "Policy Loss": -0.09382403641939163, "Value Loss": 7.2421464920043945, "_runtime": 4704.540641069412, "_timestamp": 1585602074.1735106, "_step": 46}
{"Episode reward": 78.00479760708538, "Episode length": 366, "Policy Loss": -0.05324934422969818, "Value Loss": 17.627214431762695, "_runtime": 4704.969101667404, "_timestamp": 1585602074.6019711, "_step": 47}
{"Episode reward": 82.09743672219969, "Episode length": 286, "Policy Loss": 0.0023964433930814266, "Value Loss": 23.071624755859375, "_runtime": 4705.437273740768, "_timestamp": 1585602075.0701432, "_step": 48}
{"Episode reward": 84.05893939433868, "Episode length": 284, "Policy Loss": -0.017397088930010796, "Value Loss": 22.66748809814453, "_runtime": 4705.875954389572, "_timestamp": 1585602075.5088239, "_step": 49}
{"Episode reward": 82.98276123310336, "Episode length": 289, "Policy Loss": 0.2098265141248703, "Value Loss": 22.07269287109375, "_runtime": 4706.480152130127, "_timestamp": 1585602076.1130216, "_step": 50}
{"Episode reward": 74.89362434901598, "Episode length": 409, "Policy Loss": -0.10652701556682587, "Value Loss": 15.879286766052246, "_runtime": 4706.995694637299, "_timestamp": 1585602076.6285641, "_step": 51}
{"Episode reward": 81.30552729163196, "Episode length": 310, "Policy Loss": -0.13126298785209656, "Value Loss": 20.847993850708008, "_runtime": 4707.583003759384, "_timestamp": 1585602077.2158732, "_step": 52}
{"Episode reward": 76.01559614249175, "Episode length": 397, "Policy Loss": 0.061237286776304245, "Value Loss": 16.75639533996582, "_runtime": 4708.208662509918, "_timestamp": 1585602077.841532, "_step": 53}
{"Episode reward": 73.8482839096309, "Episode length": 417, "Policy Loss": -0.1274661421775818, "Value Loss": 16.01799201965332, "_runtime": 4708.7981877326965, "_timestamp": 1585602078.4310572, "_step": 54}
{"Episode reward": 78.57205467895655, "Episode length": 392, "Policy Loss": -0.20858199894428253, "Value Loss": 17.245254516601562, "_runtime": 4709.253926753998, "_timestamp": 1585602078.8867962, "_step": 55}
{"Episode reward": 81.19524287005669, "Episode length": 301, "Policy Loss": -0.05968397855758667, "Value Loss": 21.439212799072266, "_runtime": 4710.245157241821, "_timestamp": 1585602079.8780267, "_step": 56}
{"Episode reward": 58.97953824353115, "Episode length": 670, "Policy Loss": -0.19432894885540009, "Value Loss": 8.638531684875488, "_runtime": 4710.837804555893, "_timestamp": 1585602080.470674, "_step": 57}
{"Episode reward": 76.7047521720979, "Episode length": 390, "Policy Loss": -0.003974767867475748, "Value Loss": 16.14711570739746, "_runtime": 4711.178154468536, "_timestamp": 1585602080.811024, "_step": 58}
{"Episode reward": 87.1603417857704, "Episode length": 222, "Policy Loss": 0.015069480054080486, "Value Loss": 26.57023811340332, "_runtime": 4711.534347295761, "_timestamp": 1585602081.1672168, "_step": 59}
{"Episode reward": 87.69854157298224, "Episode length": 220, "Policy Loss": 0.044303540140390396, "Value Loss": 25.851533889770508, "_runtime": 4712.070954799652, "_timestamp": 1585602081.7038243, "_step": 60}
{"Episode reward": 78.03601723170604, "Episode length": 357, "Policy Loss": 0.050477270036935806, "Value Loss": 13.323269844055176, "_runtime": 4712.968574047089, "_timestamp": 1585602082.6014435, "_step": 61}
{"Episode reward": 66.05287531551163, "Episode length": 609, "Policy Loss": 0.10702826827764511, "Value Loss": 13.032485961914062, "_runtime": 4713.6972444057465, "_timestamp": 1585602083.330114, "_step": 62}
{"Episode reward": 71.87021628052794, "Episode length": 484, "Policy Loss": -0.11904344707727432, "Value Loss": 10.10562515258789, "_runtime": 4714.267908334732, "_timestamp": 1585602083.9007778, "_step": 63}
{"Episode reward": 78.52133733962938, "Episode length": 371, "Policy Loss": 0.10573788732290268, "Value Loss": 16.271535873413086, "_runtime": 4714.736798524857, "_timestamp": 1585602084.369668, "_step": 64}
{"Episode reward": 81.26389753412377, "Episode length": 296, "Policy Loss": -0.008713271468877792, "Value Loss": 23.79721450805664, "_runtime": 4715.741658210754, "_timestamp": 1585602085.3745277, "_step": 65}
{"Episode reward": 60.48387825447072, "Episode length": 665, "Policy Loss": -0.2264808863401413, "Value Loss": 7.0975022315979, "_runtime": 4716.307857036591, "_timestamp": 1585602085.9407265, "_step": 66}
{"Episode reward": 76.50756069420446, "Episode length": 373, "Policy Loss": -0.31326955556869507, "Value Loss": 14.47048568725586, "_runtime": 4716.7501039505005, "_timestamp": 1585602086.3829734, "_step": 67}
{"Episode reward": 83.2517780391403, "Episode length": 293, "Policy Loss": -0.09957513958215714, "Value Loss": 18.292064666748047, "_runtime": 4717.292939424515, "_timestamp": 1585602086.925809, "_step": 68}
{"Episode reward": 79.18548326941533, "Episode length": 346, "Policy Loss": -0.06575488299131393, "Value Loss": 15.403258323669434, "_runtime": 4717.74338555336, "_timestamp": 1585602087.376255, "_step": 69}
{"Episode reward": 82.89888600090359, "Episode length": 294, "Policy Loss": 0.059162165969610214, "Value Loss": 23.279001235961914, "_runtime": 4718.364569425583, "_timestamp": 1585602087.997439, "_step": 70}
{"Episode reward": 75.10589684344362, "Episode length": 416, "Policy Loss": -0.0851297676563263, "Value Loss": 21.744129180908203, "_runtime": 4719.035427570343, "_timestamp": 1585602088.668297, "_step": 71}
{"Episode reward": 72.89971888771784, "Episode length": 441, "Policy Loss": -0.03833017498254776, "Value Loss": 22.313270568847656, "_runtime": 4719.932582139969, "_timestamp": 1585602089.5654516, "_step": 72}
{"Episode reward": 64.20810922746047, "Episode length": 597, "Policy Loss": -0.1540081650018692, "Value Loss": 16.62435531616211, "_runtime": 4720.765359163284, "_timestamp": 1585602090.3982286, "_step": 73}
{"Episode reward": 66.99052115028513, "Episode length": 544, "Policy Loss": -0.04731059446930885, "Value Loss": 18.355209350585938, "_runtime": 4721.791192293167, "_timestamp": 1585602091.4240618, "_step": 74}
{"Episode reward": 60.71693848878383, "Episode length": 677, "Policy Loss": -0.18114937841892242, "Value Loss": 14.744123458862305, "_runtime": 4722.270555257797, "_timestamp": 1585602091.9034247, "_step": 75}
{"Episode reward": 82.00252818209658, "Episode length": 297, "Policy Loss": -0.023399725556373596, "Value Loss": 28.832244873046875, "_runtime": 4722.98420715332, "_timestamp": 1585602092.6170766, "_step": 76}
{"Episode reward": 71.84252637333228, "Episode length": 466, "Policy Loss": -0.15197445452213287, "Value Loss": 24.967266082763672, "_runtime": 4723.582967281342, "_timestamp": 1585602093.2158368, "_step": 77}
{"Episode reward": 78.01717360880917, "Episode length": 377, "Policy Loss": -0.08440544456243515, "Value Loss": 12.52735424041748, "_runtime": 4724.20916056633, "_timestamp": 1585602093.84203, "_step": 78}
{"Episode reward": 75.57698838045783, "Episode length": 424, "Policy Loss": -0.11584926396608353, "Value Loss": 12.471907615661621, "_runtime": 4724.931258916855, "_timestamp": 1585602094.5641284, "_step": 79}
{"Episode reward": 71.3799421421403, "Episode length": 474, "Policy Loss": -0.15782222151756287, "Value Loss": 16.747802734375, "_runtime": 4725.5729830265045, "_timestamp": 1585602095.2058525, "_step": 80}
{"Episode reward": 73.40442546738107, "Episode length": 423, "Policy Loss": -0.11026763916015625, "Value Loss": 18.602481842041016, "_runtime": 4725.946108818054, "_timestamp": 1585602095.5789783, "_step": 81}
{"Episode reward": 86.30277262714611, "Episode length": 231, "Policy Loss": -0.011561439372599125, "Value Loss": 24.99209213256836, "_runtime": 4726.433364391327, "_timestamp": 1585602096.0662339, "_step": 82}
{"Episode reward": 81.0187939023794, "Episode length": 310, "Policy Loss": 0.046775348484516144, "Value Loss": 20.11802864074707, "_runtime": 4726.856085538864, "_timestamp": 1585602096.488955, "_step": 83}
{"Episode reward": 82.27642217830339, "Episode length": 277, "Policy Loss": -0.07547242939472198, "Value Loss": 18.955001831054688, "_runtime": 4727.5957996845245, "_timestamp": 1585602097.2286692, "_step": 84}
{"Episode reward": 70.26988793461538, "Episode length": 504, "Policy Loss": -0.03516675531864166, "Value Loss": 13.099172592163086, "_runtime": 4728.082710981369, "_timestamp": 1585602097.7155805, "_step": 85}
{"Episode reward": 81.24500145485734, "Episode length": 315, "Policy Loss": -0.07955026626586914, "Value Loss": 13.560522079467773, "_runtime": 4728.571362018585, "_timestamp": 1585602098.2042315, "_step": 86}
{"Episode reward": 80.74240404979253, "Episode length": 328, "Policy Loss": -0.0029345606453716755, "Value Loss": 16.866933822631836, "_runtime": 4729.615561008453, "_timestamp": 1585602099.2484305, "_step": 87}
{"Episode reward": 59.13292110058222, "Episode length": 694, "Policy Loss": -0.23780466616153717, "Value Loss": 6.187775135040283, "_runtime": 4730.234243154526, "_timestamp": 1585602099.8671126, "_step": 88}
{"Episode reward": 74.51025109495785, "Episode length": 407, "Policy Loss": 0.12655022740364075, "Value Loss": 18.211565017700195, "_runtime": 4731.034415483475, "_timestamp": 1585602100.667285, "_step": 89}
{"Episode reward": 68.6596306998098, "Episode length": 533, "Policy Loss": -0.16725991666316986, "Value Loss": 10.577253341674805, "_runtime": 4731.940422296524, "_timestamp": 1585602101.5732918, "_step": 90}
{"Episode reward": 66.73739337730024, "Episode length": 587, "Policy Loss": -0.10763317346572876, "Value Loss": 6.602908134460449, "_runtime": 4732.482789039612, "_timestamp": 1585602102.1156585, "_step": 91}
{"Episode reward": 78.68212250590412, "Episode length": 360, "Policy Loss": -0.07993579655885696, "Value Loss": 16.432937622070312, "_runtime": 4733.359726905823, "_timestamp": 1585602102.9925964, "_step": 92}
{"Episode reward": 65.3745675080997, "Episode length": 587, "Policy Loss": -0.18741916120052338, "Value Loss": 7.977097988128662, "_runtime": 4733.933958530426, "_timestamp": 1585602103.566828, "_step": 93}
{"Episode reward": 79.62506036047088, "Episode length": 366, "Policy Loss": -0.28137531876564026, "Value Loss": 28.458898544311523, "_runtime": 4734.485999584198, "_timestamp": 1585602104.118869, "_step": 94}
{"Episode reward": 78.79541608920178, "Episode length": 370, "Policy Loss": 0.09991509467363358, "Value Loss": 26.929651260375977, "_runtime": 4735.070176362991, "_timestamp": 1585602104.7030458, "_step": 95}
{"Episode reward": 78.53920337623796, "Episode length": 381, "Policy Loss": 0.009350981563329697, "Value Loss": 26.1611328125, "_runtime": 4736.564471483231, "_timestamp": 1585602106.197341, "_step": 96}
{"Episode reward": -60.16978954861597, "Episode length": 999, "Policy Loss": -0.29249119758605957, "Value Loss": 0.04081594944000244, "_runtime": 4737.265474081039, "_timestamp": 1585602106.8983436, "_step": 97}
{"Episode reward": 72.64779505869788, "Episode length": 456, "Policy Loss": 0.05707832798361778, "Value Loss": 21.866382598876953, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094, -79.95701599121094]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-62.76060485839844, -61.1268424987793, -59.493080139160156, -57.859317779541016, -56.225555419921875, -54.59178924560547, -52.958030700683594, -51.32426452636719, -49.69050216674805, -48.056739807128906, -46.422977447509766, -44.789215087890625, -43.155452728271484, -41.521690368652344, -39.88792419433594, -38.25416564941406, -36.620399475097656, -34.98664093017578, -33.352874755859375, -31.719112396240234, -30.085350036621094, -28.451587677001953, -26.817825317382812, -25.184062957763672, -23.55030059814453, -21.91653823852539, -20.28277587890625, -18.649009704589844, -17.015247344970703, -15.381484985351562, -13.747722625732422, -12.113960266113281, -10.48019790649414, -8.846435546875, -7.212673187255859, -5.578910827636719, -3.945148468017578, -2.3113861083984375, -0.6776199340820312, 0.9561424255371094, 2.58990478515625, 4.223663330078125, 5.857429504394531, 7.4911956787109375, 9.124954223632812, 10.758720397949219, 12.392478942871094, 14.0262451171875, 15.660003662109375, 17.29376983642578, 18.927528381347656, 20.561294555664062, 22.195053100585938, 23.828819274902344, 25.46258544921875, 27.096343994140625, 28.73011016845703, 30.363868713378906, 31.997634887695312, 33.63139343261719, 35.265159606933594, 36.89891815185547, 38.532684326171875, 40.16644287109375, 41.800209045410156]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-36.840694427490234, -35.61117935180664, -34.38166427612305, -33.15214920043945, -31.92263412475586, -30.693119049072266, -29.463603973388672, -28.234088897705078, -27.004573822021484, -25.77505874633789, -24.545543670654297, -23.316028594970703, -22.086515426635742, -20.85700035095215, -19.627485275268555, -18.39797019958496, -17.168455123901367, -15.938940048217773, -14.70942497253418, -13.479909896850586, -12.250394821166992, -11.020879745483398, -9.791364669799805, -8.561849594116211, -7.33233642578125, -6.102821350097656, -4.8733062744140625, -3.6437911987304688, -2.414276123046875, -1.1847610473632812, 0.0447540283203125, 1.2742691040039062, 2.5037841796875, 3.7332992553710938, 4.9628143310546875, 6.192329406738281, 7.421844482421875, 8.651359558105469, 9.880874633789062, 11.110389709472656, 12.33990478515625, 13.569419860839844, 14.798934936523438, 16.02845001220703, 17.257965087890625, 18.48748016357422, 19.716995239257812, 20.946510314941406, 22.176021575927734, 23.405536651611328, 24.635051727294922, 25.864566802978516, 27.09408187866211, 28.323596954345703, 29.553112030029297, 30.78262710571289, 32.012142181396484, 33.24165725708008, 34.47117233276367, 35.700687408447266, 36.93020248413086, 38.15971755981445, 39.38923263549805, 40.61874771118164, 41.848262786865234]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 5.0, 7.0, 6.0, 4.0, 4.0, 7.0, 7.0, 10.0, 8.0, 11.0, 10.0, 13.0, 16.0, 15.0, 10.0, 15.0, 24.0, 35.0, 51.0, 20.0, 34.0, 16.0, 18.0, 10.0, 17.0, 20.0, 11.0, 9.0, 11.0, 11.0, 10.0, 4.0, 7.0, 8.0, 6.0, 6.0, 2.0, 1.0, 4.0, 5.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-25.554141998291016, -24.701284408569336, -23.848426818847656, -22.99557113647461, -22.14271354675293, -21.28985595703125, -20.43699836730957, -19.58414077758789, -18.731285095214844, -17.878427505493164, -17.025569915771484, -16.172712326049805, -15.319854736328125, -14.466998100280762, -13.614140510559082, -12.761283874511719, -11.908426284790039, -11.05556869506836, -10.202712059020996, -9.349855422973633, -8.496997833251953, -7.644140243530273, -6.791282653808594, -5.938425064086914, -5.085567474365234, -4.2327117919921875, -3.379854202270508, -2.526996612548828, -1.6741390228271484, -0.8212814331054688, 0.031574249267578125, 0.8844318389892578, 1.7372894287109375, 2.590147018432617, 3.443004608154297, 4.295860290527344, 5.148717880249023, 6.001575469970703, 6.85443115234375, 7.7072906494140625, 8.56014633178711, 9.413005828857422, 10.265861511230469, 11.118717193603516, 11.971576690673828, 12.824432373046875, 13.677291870117188, 14.530147552490234, 15.383007049560547, 16.235862731933594, 17.08871841430664, 17.941577911376953, 18.79443359375, 19.647293090820312, 20.50014877319336, 21.353004455566406, 22.20586395263672, 23.058719635009766, 23.911579132080078, 24.764434814453125, 25.617290496826172, 26.470149993896484, 27.32300567626953, 28.175865173339844, 29.02872085571289]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-29.890396118164062, -28.652021408081055, -27.413646697998047, -26.17527198791504, -24.93689727783203, -23.698522567749023, -22.460147857666016, -21.221771240234375, -19.9833984375, -18.74502182006836, -17.506649017333984, -16.268272399902344, -15.029897689819336, -13.791522979736328, -12.55314826965332, -11.314773559570312, -10.076398849487305, -8.838024139404297, -7.599649429321289, -6.361274719238281, -5.122900009155273, -3.8845252990722656, -2.646150588989258, -1.40777587890625, -0.16939926147460938, 1.0689754486083984, 2.3073501586914062, 3.5457229614257812, 4.784099578857422, 6.022472381591797, 7.2608489990234375, 8.499221801757812, 9.737598419189453, 10.975975036621094, 12.214347839355469, 13.45272445678711, 14.691097259521484, 15.929473876953125, 17.1678466796875, 18.40622329711914, 19.644596099853516, 20.882972717285156, 22.12134552001953, 23.359722137451172, 24.598094940185547, 25.836471557617188, 27.074844360351562, 28.313220977783203, 29.551597595214844, 30.78997039794922, 32.02834701538086, 33.266719818115234, 34.505096435546875, 35.74346923828125, 36.981842041015625, 38.22022247314453, 39.458595275878906, 40.69696807861328, 41.935340881347656, 43.17372131347656, 44.41209411621094, 45.65046691894531, 46.88883972167969, 48.127220153808594, 49.36559295654297]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 19.0, 14.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-20.496652603149414, -19.983783721923828, -19.470916748046875, -18.95804786682129, -18.445178985595703, -17.93231201171875, -17.419443130493164, -16.906574249267578, -16.393707275390625, -15.880838394165039, -15.367969512939453, -14.855101585388184, -14.342233657836914, -13.829364776611328, -13.316496849060059, -12.803628921508789, -12.290760040283203, -11.777892112731934, -11.265023231506348, -10.752155303955078, -10.239286422729492, -9.726418495178223, -9.213550567626953, -8.700681686401367, -8.187813758850098, -7.674945831298828, -7.162076950073242, -6.649209022521973, -6.136341094970703, -5.623472213745117, -5.110604286193848, -4.597735404968262, -4.084867477416992, -3.5719985961914062, -3.059131622314453, -2.546262741088867, -2.0333938598632812, -1.5205268859863281, -1.0076580047607422, -0.49478912353515625, 0.018079757690429688, 0.5309467315673828, 1.0438156127929688, 1.5566844940185547, 2.069551467895508, 2.5824203491210938, 3.0952892303466797, 3.608156204223633, 4.121025085449219, 4.633893966674805, 5.146760940551758, 5.659629821777344, 6.17249870300293, 6.685365676879883, 7.198234558105469, 7.711103439331055, 8.223970413208008, 8.736839294433594, 9.24970817565918, 9.762577056884766, 10.275444030761719, 10.788312911987305, 11.30118179321289, 11.814050674438477, 12.32691764831543]}, "_runtime": 4737.705217599869, "_timestamp": 1585602107.338087, "_step": 98}
{"Episode reward": 82.36067636147553, "Episode length": 291, "Policy Loss": 1.1004505157470703, "Value Loss": 34.291770935058594, "_runtime": 4738.177269458771, "_timestamp": 1585602107.810139, "_step": 99}
{"Episode reward": 83.25520079447757, "Episode length": 287, "Policy Loss": 0.34203898906707764, "Value Loss": 34.719051361083984, "_runtime": 4738.881507873535, "_timestamp": 1585602108.5143774, "_step": 100}
{"Episode reward": 72.56292072545585, "Episode length": 467, "Policy Loss": -0.07564388960599899, "Value Loss": 21.394514083862305, "_runtime": 4739.557503461838, "_timestamp": 1585602109.190373, "_step": 101}
{"Episode reward": 74.80629120850736, "Episode length": 446, "Policy Loss": -0.0091927545145154, "Value Loss": 22.354652404785156, "_runtime": 4740.258503675461, "_timestamp": 1585602109.8913732, "_step": 102}
{"Episode reward": 73.80280374915058, "Episode length": 466, "Policy Loss": 0.03130996599793434, "Value Loss": 21.40447998046875, "_runtime": 4740.6081635952, "_timestamp": 1585602110.241033, "_step": 103}
{"Episode reward": 86.87496015571634, "Episode length": 216, "Policy Loss": 0.22520151734352112, "Value Loss": 46.120113372802734, "_runtime": 4741.09543132782, "_timestamp": 1585602110.7283008, "_step": 104}
{"Episode reward": 81.26939137078563, "Episode length": 320, "Policy Loss": 0.21210739016532898, "Value Loss": 31.184642791748047, "_runtime": 4741.451957702637, "_timestamp": 1585602111.0848272, "_step": 105}
{"Episode reward": 86.28896778040314, "Episode length": 230, "Policy Loss": 0.1238999292254448, "Value Loss": 43.31391525268555, "_runtime": 4742.328808784485, "_timestamp": 1585602111.9616783, "_step": 106}
{"Episode reward": 65.07122282624104, "Episode length": 598, "Policy Loss": -0.07158967107534409, "Value Loss": 16.682912826538086, "_runtime": 4743.2449362277985, "_timestamp": 1585602112.8778057, "_step": 107}
{"Episode reward": 62.48984878615122, "Episode length": 608, "Policy Loss": -0.11108413338661194, "Value Loss": 16.4359188079834, "_runtime": 4743.812948465347, "_timestamp": 1585602113.445818, "_step": 108}
{"Episode reward": 77.49285653795408, "Episode length": 375, "Policy Loss": 0.02056337706744671, "Value Loss": 26.597455978393555, "_runtime": 4744.6581127643585, "_timestamp": 1585602114.2909822, "_step": 109}
{"Episode reward": 66.78543430423888, "Episode length": 551, "Policy Loss": -0.01767292618751526, "Value Loss": 18.12523078918457, "_runtime": 4745.232703447342, "_timestamp": 1585602114.865573, "_step": 110}
{"Episode reward": 78.32277731573016, "Episode length": 362, "Policy Loss": 0.055421698838472366, "Value Loss": 27.533241271972656, "_runtime": 4746.251458406448, "_timestamp": 1585602115.884328, "_step": 111}
{"Episode reward": 61.016824479341004, "Episode length": 683, "Policy Loss": -0.05814416706562042, "Value Loss": 14.61161994934082, "_runtime": 4746.768483638763, "_timestamp": 1585602116.4013531, "_step": 112}
{"Episode reward": 78.42891927611501, "Episode length": 323, "Policy Loss": 0.11432845145463943, "Value Loss": 30.855066299438477, "_runtime": 4747.108680009842, "_timestamp": 1585602116.7415495, "_step": 113}
{"Episode reward": 87.69253169485361, "Episode length": 218, "Policy Loss": 0.44591742753982544, "Value Loss": 45.69012451171875, "_runtime": 4747.826424360275, "_timestamp": 1585602117.4592938, "_step": 114}
{"Episode reward": 73.5419175519935, "Episode length": 465, "Policy Loss": 0.005779497791081667, "Value Loss": 21.455678939819336, "_runtime": 4748.70317530632, "_timestamp": 1585602118.3360448, "_step": 115}
{"Episode reward": 66.55456569582495, "Episode length": 583, "Policy Loss": -0.0015469235368072987, "Value Loss": 17.111352920532227, "_runtime": 4749.174133300781, "_timestamp": 1585602118.8070028, "_step": 116}
{"Episode reward": 81.79104383973814, "Episode length": 315, "Policy Loss": 0.018674103543162346, "Value Loss": 31.63279151916504, "_runtime": 4749.633340358734, "_timestamp": 1585602119.2662098, "_step": 117}
{"Episode reward": 82.40775617488008, "Episode length": 297, "Policy Loss": 0.3130965232849121, "Value Loss": 33.564292907714844, "_runtime": 4750.091495990753, "_timestamp": 1585602119.7243655, "_step": 118}
{"Episode reward": 83.57637120240815, "Episode length": 291, "Policy Loss": 0.07904016971588135, "Value Loss": 34.23677062988281, "_runtime": 4750.988744735718, "_timestamp": 1585602120.6216142, "_step": 119}
{"Episode reward": 64.15136989855975, "Episode length": 599, "Policy Loss": -0.13229496777057648, "Value Loss": 16.656917572021484, "_runtime": 4751.434627056122, "_timestamp": 1585602121.0674965, "_step": 120}
{"Episode reward": 83.51095392352948, "Episode length": 286, "Policy Loss": 0.06241850554943085, "Value Loss": 34.83405303955078, "_runtime": 4751.868985414505, "_timestamp": 1585602121.501855, "_step": 121}
{"Episode reward": 84.26636942496833, "Episode length": 286, "Policy Loss": 0.045616667717695236, "Value Loss": 34.89942169189453, "_runtime": 4752.303205013275, "_timestamp": 1585602121.9360745, "_step": 122}
{"Episode reward": 82.81051964137043, "Episode length": 275, "Policy Loss": 0.20710395276546478, "Value Loss": 36.26258850097656, "_runtime": 4752.849683523178, "_timestamp": 1585602122.482553, "_step": 123}
{"Episode reward": 79.8247438513468, "Episode length": 365, "Policy Loss": -0.018165770918130875, "Value Loss": 27.302879333496094, "_runtime": 4753.305852890015, "_timestamp": 1585602122.9387224, "_step": 124}
{"Episode reward": 82.50357578609301, "Episode length": 302, "Policy Loss": -0.004228634759783745, "Value Loss": 33.05335998535156, "_runtime": 4754.182646512985, "_timestamp": 1585602123.815516, "_step": 125}
{"Episode reward": 63.52405785842526, "Episode length": 588, "Policy Loss": -0.12108352780342102, "Value Loss": 16.969614028930664, "_runtime": 4754.725259065628, "_timestamp": 1585602124.3581285, "_step": 126}
{"Episode reward": 79.09457131282497, "Episode length": 357, "Policy Loss": 0.16265010833740234, "Value Loss": 27.914363861083984, "_runtime": 4755.164427518845, "_timestamp": 1585602124.797297, "_step": 127}
{"Episode reward": 83.39265135247848, "Episode length": 289, "Policy Loss": 0.18576660752296448, "Value Loss": 34.53826904296875, "_runtime": 4755.979860305786, "_timestamp": 1585602125.6127298, "_step": 128}
{"Episode reward": 69.58329651675277, "Episode length": 509, "Policy Loss": -0.1549920290708542, "Value Loss": 19.622093200683594, "_runtime": 4756.787614107132, "_timestamp": 1585602126.4204836, "_step": 129}
{"Episode reward": 69.04778554552767, "Episode length": 537, "Policy Loss": 0.3218243420124054, "Value Loss": 18.574960708618164, "_runtime": 4757.343901395798, "_timestamp": 1585602126.9767709, "_step": 130}
{"Episode reward": 78.04410331393738, "Episode length": 365, "Policy Loss": 0.14750882983207703, "Value Loss": 27.353017807006836, "_runtime": 4757.864656209946, "_timestamp": 1585602127.4975257, "_step": 131}
{"Episode reward": 79.92616401338614, "Episode length": 337, "Policy Loss": 0.1893845945596695, "Value Loss": 29.615894317626953, "_runtime": 4758.672647237778, "_timestamp": 1585602128.3055167, "_step": 132}
{"Episode reward": 68.66250392037041, "Episode length": 532, "Policy Loss": -0.14122675359249115, "Value Loss": 18.773033142089844, "_runtime": 4759.141900777817, "_timestamp": 1585602128.7747703, "_step": 133}
{"Episode reward": 82.32758122410738, "Episode length": 299, "Policy Loss": 0.1718946248292923, "Value Loss": 33.317100524902344, "_runtime": 4759.622227191925, "_timestamp": 1585602129.2550967, "_step": 134}
{"Episode reward": 80.56769449218123, "Episode length": 318, "Policy Loss": -0.056651368737220764, "Value Loss": 31.33053207397461, "_runtime": 4760.245940923691, "_timestamp": 1585602129.8788104, "_step": 135}
{"Episode reward": 75.76005860849415, "Episode length": 408, "Policy Loss": 0.03766417130827904, "Value Loss": 24.431535720825195, "_runtime": 4760.795953273773, "_timestamp": 1585602130.4288228, "_step": 136}
{"Episode reward": 79.05925275373814, "Episode length": 357, "Policy Loss": 0.2540826201438904, "Value Loss": 27.96686553955078, "_runtime": 4761.615239858627, "_timestamp": 1585602131.2481093, "_step": 137}
{"Episode reward": 67.07595030425952, "Episode length": 547, "Policy Loss": -0.17419570684432983, "Value Loss": 18.245100021362305, "_runtime": 4762.587069749832, "_timestamp": 1585602132.2199392, "_step": 138}
{"Episode reward": 62.01063367621124, "Episode length": 638, "Policy Loss": -0.10173160582780838, "Value Loss": 15.645649909973145, "_runtime": 4763.202263593674, "_timestamp": 1585602132.835133, "_step": 139}
{"Episode reward": 76.20031539685971, "Episode length": 400, "Policy Loss": -0.10287013649940491, "Value Loss": 24.947267532348633, "_runtime": 4763.7349152565, "_timestamp": 1585602133.3677847, "_step": 140}
{"Episode reward": 80.56809545722503, "Episode length": 345, "Policy Loss": 0.194515198469162, "Value Loss": 28.880361557006836, "_runtime": 4764.201081752777, "_timestamp": 1585602133.8339512, "_step": 141}
{"Episode reward": 81.63282371113723, "Episode length": 296, "Policy Loss": 0.15647448599338531, "Value Loss": 33.65402603149414, "_runtime": 4764.766027212143, "_timestamp": 1585602134.3988967, "_step": 142}
{"Episode reward": 77.74437837525704, "Episode length": 371, "Policy Loss": -0.03949727118015289, "Value Loss": 26.862260818481445, "_runtime": 4765.454510211945, "_timestamp": 1585602135.0873797, "_step": 143}
{"Episode reward": 72.47565691979136, "Episode length": 459, "Policy Loss": 0.20624607801437378, "Value Loss": 21.724000930786133, "_runtime": 4766.069615840912, "_timestamp": 1585602135.7024853, "_step": 144}
{"Episode reward": 77.03050224290527, "Episode length": 404, "Policy Loss": 0.19614875316619873, "Value Loss": 24.671602249145508, "_runtime": 4766.5112154483795, "_timestamp": 1585602136.144085, "_step": 145}
{"Episode reward": 84.88296938522207, "Episode length": 282, "Policy Loss": 0.2146381288766861, "Value Loss": 35.317020416259766, "_runtime": 4767.007645845413, "_timestamp": 1585602136.6405153, "_step": 146}
{"Episode reward": 80.98292987716184, "Episode length": 323, "Policy Loss": 0.1188836470246315, "Value Loss": 30.84404945373535, "_runtime": 4767.794923782349, "_timestamp": 1585602137.4277933, "_step": 147}
{"Episode reward": 69.36695081311892, "Episode length": 525, "Policy Loss": 0.42085129022598267, "Value Loss": 19.01857566833496, "_runtime": 4768.372300386429, "_timestamp": 1585602138.0051699, "_step": 148}
{"Episode reward": 78.11953655477284, "Episode length": 377, "Policy Loss": -0.020429538562893867, "Value Loss": 26.486827850341797, "_runtime": 4769.229967355728, "_timestamp": 1585602138.8628368, "_step": 149}
{"Episode reward": 65.9831826058772, "Episode length": 572, "Policy Loss": -0.20080047845840454, "Value Loss": 17.445106506347656, "_runtime": 4769.69779920578, "_timestamp": 1585602139.3306687, "_step": 150}
{"Episode reward": 83.00285231532904, "Episode length": 294, "Policy Loss": 0.597311794757843, "Value Loss": 33.87929153442383, "_runtime": 4770.467287302017, "_timestamp": 1585602140.1001568, "_step": 151}
{"Episode reward": 70.01874679536236, "Episode length": 510, "Policy Loss": -0.16591891646385193, "Value Loss": 19.557865142822266, "_runtime": 4770.816785335541, "_timestamp": 1585602140.4496548, "_step": 152}
{"Episode reward": 87.01142191344464, "Episode length": 210, "Policy Loss": 0.07073558866977692, "Value Loss": 47.4071044921875, "_runtime": 4771.457093954086, "_timestamp": 1585602141.0899634, "_step": 153}
{"Episode reward": 74.29426374689751, "Episode length": 429, "Policy Loss": -0.13433508574962616, "Value Loss": 23.269813537597656, "_runtime": 4772.2878086566925, "_timestamp": 1585602141.9206781, "_step": 154}
{"Episode reward": 66.92893400016288, "Episode length": 537, "Policy Loss": -0.11168698221445084, "Value Loss": 18.579376220703125, "_runtime": 4772.93899679184, "_timestamp": 1585602142.5718663, "_step": 155}
{"Episode reward": 73.21555182647349, "Episode length": 433, "Policy Loss": -0.1218215823173523, "Value Loss": 23.068246841430664, "_runtime": 4774.052860021591, "_timestamp": 1585602143.6857295, "_step": 156}
{"Episode reward": 56.30488610288333, "Episode length": 731, "Policy Loss": -0.06610243767499924, "Value Loss": 13.665701866149902, "_runtime": 4774.966684103012, "_timestamp": 1585602144.5995536, "_step": 157}
{"Episode reward": 64.77206027911782, "Episode length": 589, "Policy Loss": -0.12003620713949203, "Value Loss": 16.946218490600586, "_runtime": 4775.551846981049, "_timestamp": 1585602145.1847165, "_step": 158}
{"Episode reward": 76.89289058392588, "Episode length": 379, "Policy Loss": -0.06332516670227051, "Value Loss": 26.296737670898438, "_runtime": 4776.245455503464, "_timestamp": 1585602145.878325, "_step": 159}
{"Episode reward": 71.49077799159812, "Episode length": 447, "Policy Loss": 0.08662250638008118, "Value Loss": 22.311609268188477, "_runtime": 4776.802895784378, "_timestamp": 1585602146.4357653, "_step": 160}
{"Episode reward": 78.3522538909119, "Episode length": 351, "Policy Loss": -0.04676367715001106, "Value Loss": 28.44515609741211, "_runtime": 4777.412031173706, "_timestamp": 1585602147.0449007, "_step": 161}
{"Episode reward": 75.91014232005833, "Episode length": 404, "Policy Loss": -0.057969994843006134, "Value Loss": 24.673011779785156, "_runtime": 4778.618353366852, "_timestamp": 1585602148.2512228, "_step": 162}
{"Episode reward": 54.12804806815385, "Episode length": 789, "Policy Loss": -0.12813153862953186, "Value Loss": 12.665031433105469, "_runtime": 4779.12374997139, "_timestamp": 1585602148.7566195, "_step": 163}
{"Episode reward": 81.83703981078058, "Episode length": 322, "Policy Loss": 0.8670509457588196, "Value Loss": 30.937694549560547, "_runtime": 4779.84561419487, "_timestamp": 1585602149.4784837, "_step": 164}
{"Episode reward": 70.57493403912898, "Episode length": 480, "Policy Loss": -0.1697932630777359, "Value Loss": 20.77760124206543, "_runtime": 4780.297466516495, "_timestamp": 1585602149.930336, "_step": 165}
{"Episode reward": 83.79790474391365, "Episode length": 277, "Policy Loss": 0.40314069390296936, "Value Loss": 35.954437255859375, "_runtime": 4781.720802307129, "_timestamp": 1585602151.3536718, "_step": 166}
{"Episode reward": 43.393591078428, "Episode length": 941, "Policy Loss": -0.19625967741012573, "Value Loss": 10.630485534667969, "_runtime": 4782.30536532402, "_timestamp": 1585602151.9382348, "_step": 167}
{"Episode reward": 77.37929481291768, "Episode length": 369, "Policy Loss": -0.0598042868077755, "Value Loss": 27.049072265625, "_runtime": 4782.790576219559, "_timestamp": 1585602152.4234457, "_step": 168}
{"Episode reward": 80.35669688404505, "Episode length": 322, "Policy Loss": 0.6226701140403748, "Value Loss": 30.94014549255371, "_runtime": 4783.509002447128, "_timestamp": 1585602153.141872, "_step": 169}
{"Episode reward": 73.20827164195461, "Episode length": 451, "Policy Loss": -0.10400684177875519, "Value Loss": 22.108306884765625, "_runtime": 4784.261161565781, "_timestamp": 1585602153.894031, "_step": 170}
{"Episode reward": 71.15434374860129, "Episode length": 493, "Policy Loss": -0.08121516555547714, "Value Loss": 20.229942321777344, "_runtime": 4785.38131737709, "_timestamp": 1585602155.0141869, "_step": 171}
{"Episode reward": 54.00163276395463, "Episode length": 741, "Policy Loss": -0.026279065757989883, "Value Loss": 13.496221542358398, "_runtime": 4785.977931499481, "_timestamp": 1585602155.610801, "_step": 172}
{"Episode reward": 79.32081955654067, "Episode length": 382, "Policy Loss": 0.06109560281038284, "Value Loss": 26.087432861328125, "_runtime": 4786.562284708023, "_timestamp": 1585602156.1951542, "_step": 173}
{"Episode reward": 77.30181394720114, "Episode length": 383, "Policy Loss": -0.11475712060928345, "Value Loss": 26.05889892578125, "_runtime": 4787.105255126953, "_timestamp": 1585602156.7381246, "_step": 174}
{"Episode reward": 78.13064700584857, "Episode length": 345, "Policy Loss": 0.18965081870555878, "Value Loss": 28.883197784423828, "_runtime": 4787.652325868607, "_timestamp": 1585602157.2851954, "_step": 175}
{"Episode reward": 77.67880833632499, "Episode length": 358, "Policy Loss": 0.550159752368927, "Value Loss": 27.836284637451172, "_runtime": 4788.586781263351, "_timestamp": 1585602158.2196507, "_step": 176}
{"Episode reward": 62.58134064049919, "Episode length": 620, "Policy Loss": -0.16336286067962646, "Value Loss": 16.09977149963379, "_runtime": 4789.306648015976, "_timestamp": 1585602158.9395175, "_step": 177}
{"Episode reward": 71.35000577641472, "Episode length": 471, "Policy Loss": -0.1741238683462143, "Value Loss": 21.172794342041016, "_runtime": 4789.776151180267, "_timestamp": 1585602159.4090207, "_step": 178}
{"Episode reward": 81.99885862088088, "Episode length": 299, "Policy Loss": -0.04144342243671417, "Value Loss": 33.315364837646484, "_runtime": 4790.259976148605, "_timestamp": 1585602159.8928456, "_step": 179}
{"Episode reward": 81.95656918311627, "Episode length": 306, "Policy Loss": -0.03878389671444893, "Value Loss": 32.61520767211914, "_runtime": 4790.952402353287, "_timestamp": 1585602160.5852718, "_step": 180}
{"Episode reward": 71.98164924330527, "Episode length": 455, "Policy Loss": -0.1336555927991867, "Value Loss": 21.91547203063965, "_runtime": 4791.397490739822, "_timestamp": 1585602161.0303602, "_step": 181}
{"Episode reward": 82.83285349280929, "Episode length": 286, "Policy Loss": 0.494854599237442, "Value Loss": 34.82679748535156, "_runtime": 4791.930926799774, "_timestamp": 1585602161.5637963, "_step": 182}
{"Episode reward": 78.05073693590857, "Episode length": 355, "Policy Loss": -0.050968945026397705, "Value Loss": 28.08332633972168, "_runtime": 4792.507349252701, "_timestamp": 1585602162.1402187, "_step": 183}
{"Episode reward": 79.32287494613465, "Episode length": 377, "Policy Loss": 0.17387931048870087, "Value Loss": 26.48490333557129, "_runtime": 4792.808181285858, "_timestamp": 1585602162.4410508, "_step": 184}
{"Episode reward": 88.8152853199835, "Episode length": 195, "Policy Loss": 0.13037435710430145, "Value Loss": 51.11099624633789, "_runtime": 4793.305219888687, "_timestamp": 1585602162.9380894, "_step": 185}
{"Episode reward": 80.63355071181505, "Episode length": 325, "Policy Loss": -0.06711249053478241, "Value Loss": 30.654766082763672, "_runtime": 4794.049643754959, "_timestamp": 1585602163.6825132, "_step": 186}
{"Episode reward": 71.39478057417753, "Episode length": 469, "Policy Loss": -0.15890878438949585, "Value Loss": 21.263080596923828, "_runtime": 4794.440359115601, "_timestamp": 1585602164.0732286, "_step": 187}
{"Episode reward": 83.69992298192726, "Episode length": 254, "Policy Loss": 0.7370923161506653, "Value Loss": 39.20725631713867, "_runtime": 4795.0135633945465, "_timestamp": 1585602164.6464329, "_step": 188}
{"Episode reward": 75.9125442359134, "Episode length": 382, "Policy Loss": 0.09052295237779617, "Value Loss": 26.091772079467773, "_runtime": 4795.832775115967, "_timestamp": 1585602165.4656446, "_step": 189}
{"Episode reward": 66.22869050798707, "Episode length": 542, "Policy Loss": -0.15567216277122498, "Value Loss": 18.409135818481445, "_runtime": 4796.277250766754, "_timestamp": 1585602165.9101202, "_step": 190}
{"Episode reward": 81.28176014112489, "Episode length": 295, "Policy Loss": -0.04471573233604431, "Value Loss": 33.834354400634766, "_runtime": 4796.836027622223, "_timestamp": 1585602166.468897, "_step": 191}
{"Episode reward": 77.99743507735758, "Episode length": 371, "Policy Loss": 0.014418449252843857, "Value Loss": 26.879114151000977, "_runtime": 4797.392471790314, "_timestamp": 1585602167.0253413, "_step": 192}
{"Episode reward": 77.80493974412799, "Episode length": 362, "Policy Loss": -0.09956784546375275, "Value Loss": 27.532546997070312, "_runtime": 4798.212495088577, "_timestamp": 1585602167.8453646, "_step": 193}
{"Episode reward": 68.0149887551162, "Episode length": 541, "Policy Loss": -0.10624697059392929, "Value Loss": 18.45313262939453, "_runtime": 4798.831843852997, "_timestamp": 1585602168.4647133, "_step": 194}
{"Episode reward": 75.79827144409036, "Episode length": 400, "Policy Loss": -0.11929889023303986, "Value Loss": 24.961406707763672, "_runtime": 4799.589367389679, "_timestamp": 1585602169.2222369, "_step": 195}
{"Episode reward": 68.91830983676428, "Episode length": 505, "Policy Loss": -0.1808379739522934, "Value Loss": 19.75314712524414, "_runtime": 4801.07914352417, "_timestamp": 1585602170.712013, "_step": 196}
{"Episode reward": 41.1404110485903, "Episode length": 978, "Policy Loss": -0.18575842678546906, "Value Loss": 10.236506462097168, "_runtime": 4801.574261426926, "_timestamp": 1585602171.207131, "_step": 197}
{"Episode reward": 81.14341239181425, "Episode length": 311, "Policy Loss": -0.0816865935921669, "Value Loss": 32.03105926513672, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836, -15.28261947631836]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-13.294761657714844, -12.982133865356445, -12.66950511932373, -12.356877326965332, -12.044248580932617, -11.731620788574219, -11.41899299621582, -11.106364250183105, -10.793736457824707, -10.481107711791992, -10.168479919433594, -9.855852127075195, -9.54322338104248, -9.230594635009766, -8.917966842651367, -8.605339050292969, -8.29271125793457, -7.9800825119018555, -7.667454242706299, -7.3548264503479, -7.042198181152344, -6.729569911956787, -6.4169416427612305, -6.104313373565674, -5.791685104370117, -5.479057312011719, -5.166428565979004, -4.8538007736206055, -4.541172981262207, -4.228544235229492, -3.9159164428710938, -3.603287696838379, -3.2906599044799805, -2.978032112121582, -2.665403366088867, -2.3527755737304688, -2.040146827697754, -1.7275190353393555, -1.414891242980957, -1.1022624969482422, -0.7896347045898438, -0.4770059585571289, -0.16437816619873047, 0.14824962615966797, 0.4608783721923828, 0.7735061645507812, 1.086134910583496, 1.3987627029418945, 1.7113914489746094, 2.024019241333008, 2.3366470336914062, 2.649275779724121, 2.961904525756836, 3.2745323181152344, 3.587160110473633, 3.8997879028320312, 4.21241569519043, 4.525045394897461, 4.837673187255859, 5.150300979614258, 5.462928771972656, 5.775556564331055, 6.088186264038086, 6.400814056396484, 6.713441848754883]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.059223175048828, -6.831799507141113, -6.60437536239624, -6.376951694488525, -6.1495280265808105, -5.9221038818359375, -5.694680213928223, -5.467256546020508, -5.239832878112793, -5.01240873336792, -4.784985065460205, -4.557560920715332, -4.330137252807617, -4.102713584899902, -3.8752896785736084, -3.6478660106658936, -3.4204421043395996, -3.1930181980133057, -2.9655942916870117, -2.738170623779297, -2.510746955871582, -2.283322811126709, -2.055899143218994, -1.8284754753112793, -1.6010513305664062, -1.3736276626586914, -1.1462039947509766, -0.9187803268432617, -0.6913561820983887, -0.46393251419067383, -0.23650884628295898, -0.009084701538085938, 0.2183389663696289, 0.44576263427734375, 0.6731867790222168, 0.9006104469299316, 1.1280345916748047, 1.3554582595825195, 1.5828819274902344, 1.8103055953979492, 2.037729263305664, 2.265152931213379, 2.49257755279541, 2.720001220703125, 2.94742488861084, 3.1748485565185547, 3.4022722244262695, 3.6296958923339844, 3.8571205139160156, 4.0845441818237305, 4.311967849731445, 4.53939151763916, 4.766815185546875, 4.99423885345459, 5.221662521362305, 5.449087142944336, 5.676510810852051, 5.903934478759766, 6.1313581466674805, 6.358781814575195, 6.58620548248291, 6.813630104064941, 7.041053771972656, 7.268477439880371, 7.495901107788086]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 4.0, 5.0, 1.0, 4.0, 7.0, 3.0, 7.0, 5.0, 5.0, 9.0, 7.0, 7.0, 12.0, 14.0, 15.0, 16.0, 9.0, 15.0, 16.0, 28.0, 31.0, 36.0, 25.0, 36.0, 11.0, 18.0, 18.0, 14.0, 8.0, 15.0, 12.0, 12.0, 9.0, 9.0, 6.0, 7.0, 5.0, 6.0, 3.0, 7.0, 3.0, 6.0, 0.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-4.685181617736816, -4.532589912414551, -4.379998207092285, -4.227406024932861, -4.074814319610596, -3.92222261428833, -3.7696309089660645, -3.6170389652252197, -3.464447021484375, -3.3118553161621094, -3.1592636108398438, -3.006671667098999, -2.8540799617767334, -2.7014880180358887, -2.548896312713623, -2.3963043689727783, -2.2437126636505127, -2.091120958328247, -1.9385290145874023, -1.7859373092651367, -1.633345365524292, -1.4807536602020264, -1.3281617164611816, -1.175570011138916, -1.0229783058166504, -0.8703863620758057, -0.71779465675354, -0.5652027130126953, -0.4126110076904297, -0.26001930236816406, -0.10742712020874023, 0.04516458511352539, 0.19775629043579102, 0.35034799575805664, 0.5029397010803223, 0.6555318832397461, 0.8081235885620117, 0.9607152938842773, 1.113306999206543, 1.2658991813659668, 1.4184908866882324, 1.571082592010498, 1.7236742973327637, 1.8762660026550293, 2.028858184814453, 2.1814498901367188, 2.3340415954589844, 2.48663330078125, 2.6392250061035156, 2.7918171882629395, 2.944408893585205, 3.0970005989074707, 3.2495923042297363, 3.40218448638916, 3.554776191711426, 3.7073678970336914, 3.859959602355957, 4.012551307678223, 4.165143013000488, 4.317734718322754, 4.470327377319336, 4.622919082641602, 4.775510787963867, 4.928102493286133, 5.080694198608398]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.737285137176514, -5.504001617431641, -5.270718574523926, -5.037435054779053, -4.804152011871338, -4.570868492126465, -4.33758544921875, -4.104301929473877, -3.871018648147583, -3.637735366821289, -3.404452085494995, -3.171168804168701, -2.937885284423828, -2.704602003097534, -2.4713187217712402, -2.2380354404449463, -2.0047521591186523, -1.7714688777923584, -1.5381855964660645, -1.3049020767211914, -1.0716190338134766, -0.8383355140686035, -0.6050524711608887, -0.3717689514160156, -0.13848543167114258, 0.09479761123657227, 0.3280811309814453, 0.5613641738891602, 0.7946476936340332, 1.027930736541748, 1.261214256286621, 1.494497299194336, 1.727780818939209, 1.961064338684082, 2.194347381591797, 2.42763090133667, 2.6609139442443848, 2.8941969871520996, 3.127480983734131, 3.3607640266418457, 3.5940470695495605, 3.827331066131592, 4.060614109039307, 4.2938971519470215, 4.527180194854736, 4.760464191436768, 4.993747234344482, 5.227030277252197, 5.4603142738342285, 5.693597316741943, 5.926880359649658, 6.160163402557373, 6.393447399139404, 6.626730442047119, 6.860013484954834, 7.093296527862549, 7.32658052444458, 7.559863567352295, 7.79314661026001, 8.026430130004883, 8.259714126586914, 8.492996215820312, 8.726280212402344, 8.959564208984375, 9.192846298217773]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5025018453598022, -0.4877486526966095, -0.47299546003341675, -0.4582422375679016, -0.44348904490470886, -0.4287358522415161, -0.413982629776001, -0.3992294371128082, -0.3844762444496155, -0.36972305178642273, -0.35496985912323, -0.34021663665771484, -0.3254634439945221, -0.31071025133132935, -0.2959570288658142, -0.28120383620262146, -0.2664506435394287, -0.25169745087623596, -0.2369442582130432, -0.22219103574752808, -0.20743784308433533, -0.19268465042114258, -0.17793142795562744, -0.1631782352924347, -0.14842504262924194, -0.1336718499660492, -0.11891865730285645, -0.10416543483734131, -0.08941224217414856, -0.07465904951095581, -0.059905827045440674, -0.045152634382247925, -0.030399441719055176, -0.015646249055862427, -0.0008930563926696777, 0.013860166072845459, 0.02861332893371582, 0.04336655139923096, 0.058119773864746094, 0.07287293672561646, 0.08762615919113159, 0.10237938165664673, 0.11713254451751709, 0.13188576698303223, 0.14663898944854736, 0.16139215230941772, 0.17614537477493286, 0.19089853763580322, 0.20565176010131836, 0.2204049825668335, 0.23515814542770386, 0.249911367893219, 0.26466453075408936, 0.2794177532196045, 0.29417097568511963, 0.30892413854599, 0.3236773610115051, 0.33843058347702026, 0.3531837463378906, 0.36793696880340576, 0.3826901912689209, 0.39744335412979126, 0.4121965765953064, 0.42694973945617676, 0.4417029619216919]}, "_runtime": 4802.023594617844, "_timestamp": 1585602171.656464, "_step": 198}
{"Episode reward": 82.72250474062787, "Episode length": 288, "Policy Loss": 0.01810615509748459, "Value Loss": 34.583282470703125, "_runtime": 4802.75474524498, "_timestamp": 1585602172.3876147, "_step": 199}
{"Episode reward": 72.09599016734896, "Episode length": 460, "Policy Loss": -0.18064512312412262, "Value Loss": 21.678319931030273, "_runtime": 4803.156776428223, "_timestamp": 1585602172.789646, "_step": 200}
{"Episode reward": 82.92803433293811, "Episode length": 263, "Policy Loss": 0.13253070414066315, "Value Loss": 37.88376235961914, "_runtime": 4803.773032665253, "_timestamp": 1585602173.4059021, "_step": 201}
{"Episode reward": 75.39212344270841, "Episode length": 413, "Policy Loss": -0.1333092749118805, "Value Loss": 24.145923614501953, "_runtime": 4804.251220941544, "_timestamp": 1585602173.8840904, "_step": 202}
{"Episode reward": 81.08528968275125, "Episode length": 303, "Policy Loss": -0.07539708912372589, "Value Loss": 32.87571334838867, "_runtime": 4805.528367519379, "_timestamp": 1585602175.161237, "_step": 203}
{"Episode reward": 46.12972702522979, "Episode length": 854, "Policy Loss": -0.26440998911857605, "Value Loss": 11.710471153259277, "_runtime": 4806.001979351044, "_timestamp": 1585602175.6348488, "_step": 204}
{"Episode reward": 81.60088401746162, "Episode length": 298, "Policy Loss": -0.018572596833109856, "Value Loss": 33.42576599121094, "_runtime": 4806.436060428619, "_timestamp": 1585602176.06893, "_step": 205}
{"Episode reward": 82.3917108319626, "Episode length": 284, "Policy Loss": 0.021607741713523865, "Value Loss": 35.07012176513672, "_runtime": 4806.902756929398, "_timestamp": 1585602176.5356264, "_step": 206}
{"Episode reward": 80.83092225219448, "Episode length": 287, "Policy Loss": 0.9014880657196045, "Value Loss": 34.717071533203125, "_runtime": 4807.842212677002, "_timestamp": 1585602177.4750822, "_step": 207}
{"Episode reward": 62.58275402004427, "Episode length": 628, "Policy Loss": -0.1261633336544037, "Value Loss": 15.897552490234375, "_runtime": 4808.297840595245, "_timestamp": 1585602177.93071, "_step": 208}
{"Episode reward": 82.59204122975669, "Episode length": 293, "Policy Loss": 0.4241505563259125, "Value Loss": 33.993473052978516, "_runtime": 4808.793178796768, "_timestamp": 1585602178.4260483, "_step": 209}
{"Episode reward": 80.42187076862159, "Episode length": 330, "Policy Loss": -0.014583911746740341, "Value Loss": 30.189918518066406, "_runtime": 4809.734201431274, "_timestamp": 1585602179.367071, "_step": 210}
{"Episode reward": 61.6569562915237, "Episode length": 615, "Policy Loss": -0.11182248592376709, "Value Loss": 16.235424041748047, "_runtime": 4810.316418647766, "_timestamp": 1585602179.9492881, "_step": 211}
{"Episode reward": 76.65642021608937, "Episode length": 381, "Policy Loss": -0.10986468940973282, "Value Loss": 26.15916633605957, "_runtime": 4811.2597506046295, "_timestamp": 1585602180.89262, "_step": 212}
{"Episode reward": 60.480112235901004, "Episode length": 631, "Policy Loss": -0.1766309142112732, "Value Loss": 15.824234008789062, "_runtime": 4811.64994096756, "_timestamp": 1585602181.2828104, "_step": 213}
{"Episode reward": 85.28191216764273, "Episode length": 233, "Policy Loss": 0.062146347016096115, "Value Loss": 42.73332977294922, "_runtime": 4812.2229347229, "_timestamp": 1585602181.8558042, "_step": 214}
{"Episode reward": 76.39287790855619, "Episode length": 377, "Policy Loss": 0.14542439579963684, "Value Loss": 26.43666648864746, "_runtime": 4812.644961357117, "_timestamp": 1585602182.2778308, "_step": 215}
{"Episode reward": 83.69459565957035, "Episode length": 265, "Policy Loss": 0.1358577311038971, "Value Loss": 37.578453063964844, "_runtime": 4813.187346935272, "_timestamp": 1585602182.8202164, "_step": 216}
{"Episode reward": 77.87051898522168, "Episode length": 364, "Policy Loss": -0.12826699018478394, "Value Loss": 27.391286849975586, "_runtime": 4813.792966842651, "_timestamp": 1585602183.4258363, "_step": 217}
{"Episode reward": 74.11975669448157, "Episode length": 400, "Policy Loss": -0.0890701487660408, "Value Loss": 24.9630069732666, "_runtime": 4814.906574487686, "_timestamp": 1585602184.539444, "_step": 218}
{"Episode reward": 54.216685613495464, "Episode length": 745, "Policy Loss": -0.1475294530391693, "Value Loss": 13.413824081420898, "_runtime": 4815.744493722916, "_timestamp": 1585602185.3773632, "_step": 219}
{"Episode reward": 65.94512909063165, "Episode length": 549, "Policy Loss": -0.20509327948093414, "Value Loss": 18.17698097229004, "_runtime": 4816.473994970322, "_timestamp": 1585602186.1068645, "_step": 220}
{"Episode reward": 72.22481178611869, "Episode length": 475, "Policy Loss": -0.15380315482616425, "Value Loss": 20.995441436767578, "_runtime": 4817.298548221588, "_timestamp": 1585602186.9314177, "_step": 221}
{"Episode reward": 66.67637969359458, "Episode length": 533, "Policy Loss": -0.21635864675045013, "Value Loss": 18.725208282470703, "_runtime": 4817.778486728668, "_timestamp": 1585602187.4113562, "_step": 222}
{"Episode reward": 81.2423932811193, "Episode length": 302, "Policy Loss": -0.05110524222254753, "Value Loss": 33.03597640991211, "_runtime": 4818.327162265778, "_timestamp": 1585602187.9600317, "_step": 223}
{"Episode reward": 77.94517830881517, "Episode length": 356, "Policy Loss": -0.07886992394924164, "Value Loss": 27.991506576538086, "_runtime": 4819.305635690689, "_timestamp": 1585602188.9385052, "_step": 224}
{"Episode reward": 62.77489516922341, "Episode length": 647, "Policy Loss": -0.20894739031791687, "Value Loss": 15.459527969360352, "_runtime": 4819.8452525138855, "_timestamp": 1585602189.478122, "_step": 225}
{"Episode reward": 78.0427107007063, "Episode length": 358, "Policy Loss": -0.05564216524362564, "Value Loss": 27.889846801757812, "_runtime": 4820.60223698616, "_timestamp": 1585602190.2351065, "_step": 226}
{"Episode reward": 69.51157396816919, "Episode length": 503, "Policy Loss": -0.1515188366174698, "Value Loss": 19.831436157226562, "_runtime": 4821.228632926941, "_timestamp": 1585602190.8615024, "_step": 227}
{"Episode reward": 74.85022084069499, "Episode length": 396, "Policy Loss": -0.14618104696273804, "Value Loss": 25.17222023010254, "_runtime": 4822.64003610611, "_timestamp": 1585602192.2729056, "_step": 228}
{"Episode reward": 43.227057635861804, "Episode length": 934, "Policy Loss": -0.24668659269809723, "Value Loss": 10.712610244750977, "_runtime": 4823.301209449768, "_timestamp": 1585602192.934079, "_step": 229}
{"Episode reward": 75.8368198898085, "Episode length": 423, "Policy Loss": 0.06383395940065384, "Value Loss": 23.566646575927734, "_runtime": 4823.778292894363, "_timestamp": 1585602193.4111624, "_step": 230}
{"Episode reward": 82.2396719652972, "Episode length": 304, "Policy Loss": 0.1071334108710289, "Value Loss": 32.76593017578125, "_runtime": 4824.559389829636, "_timestamp": 1585602194.1922593, "_step": 231}
{"Episode reward": 68.35560094885393, "Episode length": 497, "Policy Loss": -0.04208783432841301, "Value Loss": 20.07105827331543, "_runtime": 4825.541489839554, "_timestamp": 1585602195.1743593, "_step": 232}
{"Episode reward": 58.80420131069251, "Episode length": 648, "Policy Loss": -0.0670926570892334, "Value Loss": 15.441174507141113, "_runtime": 4826.85085272789, "_timestamp": 1585602196.4837222, "_step": 233}
{"Episode reward": 46.16605459212256, "Episode length": 868, "Policy Loss": -0.1963028460741043, "Value Loss": 11.521234512329102, "_runtime": 4828.262739658356, "_timestamp": 1585602197.8956091, "_step": 234}
{"Episode reward": 45.10167279751591, "Episode length": 922, "Policy Loss": -0.262050986289978, "Value Loss": 10.859228134155273, "_runtime": 4828.748622894287, "_timestamp": 1585602198.3814924, "_step": 235}
{"Episode reward": 81.278467269098, "Episode length": 296, "Policy Loss": 0.4625178277492523, "Value Loss": 33.66278076171875, "_runtime": 4829.536771297455, "_timestamp": 1585602199.1696408, "_step": 236}
{"Episode reward": 68.97902609649, "Episode length": 503, "Policy Loss": -0.17500998079776764, "Value Loss": 19.830766677856445, "_runtime": 4830.845881938934, "_timestamp": 1585602200.4787514, "_step": 237}
{"Episode reward": 49.841487021055144, "Episode length": 839, "Policy Loss": -0.24088570475578308, "Value Loss": 11.936762809753418, "_runtime": 4831.555951595306, "_timestamp": 1585602201.188821, "_step": 238}
{"Episode reward": 71.24648409043053, "Episode length": 464, "Policy Loss": -0.047197047621011734, "Value Loss": 21.49192237854004, "_runtime": 4832.0658349990845, "_timestamp": 1585602201.6987045, "_step": 239}
{"Episode reward": 79.59423346832864, "Episode length": 321, "Policy Loss": -0.0583634227514267, "Value Loss": 31.04781723022461, "_runtime": 4832.610349655151, "_timestamp": 1585602202.2432191, "_step": 240}
{"Episode reward": 80.28616721440252, "Episode length": 312, "Policy Loss": 0.20287150144577026, "Value Loss": 31.93143081665039, "_runtime": 4833.031345129013, "_timestamp": 1585602202.6642146, "_step": 241}
{"Episode reward": 83.1900319131537, "Episode length": 272, "Policy Loss": 0.055676091462373734, "Value Loss": 36.682430267333984, "_runtime": 4833.801753997803, "_timestamp": 1585602203.4346235, "_step": 242}
{"Episode reward": 68.79719962906329, "Episode length": 514, "Policy Loss": -0.16794127225875854, "Value Loss": 19.445438385009766, "_runtime": 4834.251428604126, "_timestamp": 1585602203.884298, "_step": 243}
{"Episode reward": 81.5774796248022, "Episode length": 289, "Policy Loss": -0.03463484346866608, "Value Loss": 34.46812438964844, "_runtime": 4834.708370685577, "_timestamp": 1585602204.3412402, "_step": 244}
{"Episode reward": 83.02208811700396, "Episode length": 307, "Policy Loss": -0.0022943057119846344, "Value Loss": 32.494808197021484, "_runtime": 4835.294617891312, "_timestamp": 1585602204.9274874, "_step": 245}
{"Episode reward": 75.71394182285344, "Episode length": 385, "Policy Loss": -0.12426234781742096, "Value Loss": 25.89506721496582, "_runtime": 4835.745438575745, "_timestamp": 1585602205.378308, "_step": 246}
{"Episode reward": 80.87343220952226, "Episode length": 303, "Policy Loss": 0.19938775897026062, "Value Loss": 32.878265380859375, "_runtime": 4836.283730983734, "_timestamp": 1585602205.9166005, "_step": 247}
{"Episode reward": 77.71638100535345, "Episode length": 362, "Policy Loss": -0.06566142290830612, "Value Loss": 27.529205322265625, "_runtime": 4836.919952630997, "_timestamp": 1585602206.552822, "_step": 248}
{"Episode reward": 73.60942674491548, "Episode length": 428, "Policy Loss": -0.08220487087965012, "Value Loss": 23.316564559936523, "_runtime": 4837.598746299744, "_timestamp": 1585602207.2316158, "_step": 249}
{"Episode reward": 71.70172446854326, "Episode length": 453, "Policy Loss": 0.2728748023509979, "Value Loss": 22.01226234436035, "_runtime": 4837.931428909302, "_timestamp": 1585602207.5642984, "_step": 250}
{"Episode reward": 87.30378057271479, "Episode length": 210, "Policy Loss": 0.4206211566925049, "Value Loss": 47.48484420776367, "_runtime": 4838.850053787231, "_timestamp": 1585602208.4829233, "_step": 251}
{"Episode reward": 61.145890975568314, "Episode length": 615, "Policy Loss": 0.005682026036083698, "Value Loss": 16.252655029296875, "_runtime": 4840.329040288925, "_timestamp": 1585602209.9619098, "_step": 252}
{"Episode reward": 37.91067490782917, "Episode length": 983, "Policy Loss": -0.2764163017272949, "Value Loss": 10.17926025390625, "_runtime": 4840.724520683289, "_timestamp": 1585602210.3573902, "_step": 253}
{"Episode reward": 84.05703404467471, "Episode length": 255, "Policy Loss": 0.5915860533714294, "Value Loss": 39.05400466918945, "_runtime": 4841.297447919846, "_timestamp": 1585602210.9303174, "_step": 254}
{"Episode reward": 76.4620389250453, "Episode length": 372, "Policy Loss": -0.0620904341340065, "Value Loss": 26.791648864746094, "_runtime": 4841.926113128662, "_timestamp": 1585602211.5589826, "_step": 255}
{"Episode reward": 76.870305900625, "Episode length": 397, "Policy Loss": 0.14875103533267975, "Value Loss": 25.139326095581055, "_runtime": 4842.511265993118, "_timestamp": 1585602212.1441355, "_step": 256}
{"Episode reward": 76.42407288458521, "Episode length": 396, "Policy Loss": -0.029026271775364876, "Value Loss": 25.2083797454834, "_runtime": 4843.0812129974365, "_timestamp": 1585602212.7140825, "_step": 257}
{"Episode reward": 77.18758844926415, "Episode length": 381, "Policy Loss": -0.09490987658500671, "Value Loss": 26.209009170532227, "_runtime": 4844.3441524505615, "_timestamp": 1585602213.977022, "_step": 258}
{"Episode reward": 48.52841939512108, "Episode length": 848, "Policy Loss": -0.25927266478538513, "Value Loss": 11.788694381713867, "_runtime": 4844.907921791077, "_timestamp": 1585602214.5407913, "_step": 259}
{"Episode reward": 78.7834784554761, "Episode length": 365, "Policy Loss": -0.02844853140413761, "Value Loss": 27.301603317260742, "_runtime": 4845.745335817337, "_timestamp": 1585602215.3782053, "_step": 260}
{"Episode reward": 65.89206311129598, "Episode length": 561, "Policy Loss": -0.11719779670238495, "Value Loss": 17.786548614501953, "_runtime": 4846.283381462097, "_timestamp": 1585602215.916251, "_step": 261}
{"Episode reward": 80.57655912205314, "Episode length": 329, "Policy Loss": -0.01876675896346569, "Value Loss": 30.33087921142578, "_runtime": 4847.316334962845, "_timestamp": 1585602216.9492044, "_step": 262}
{"Episode reward": 55.902022187093195, "Episode length": 694, "Policy Loss": -0.24256716668605804, "Value Loss": 14.41873550415039, "_runtime": 4848.083500385284, "_timestamp": 1585602217.7163699, "_step": 263}
{"Episode reward": 68.56930870290742, "Episode length": 498, "Policy Loss": -0.12336049228906631, "Value Loss": 20.029537200927734, "_runtime": 4848.539739847183, "_timestamp": 1585602218.1726093, "_step": 264}
{"Episode reward": 81.47208455527269, "Episode length": 294, "Policy Loss": 0.44285848736763, "Value Loss": 33.882080078125, "_runtime": 4849.826645851135, "_timestamp": 1585602219.4595153, "_step": 265}
{"Episode reward": 44.16854461531127, "Episode length": 857, "Policy Loss": -0.2763447165489197, "Value Loss": 11.667449951171875, "_runtime": 4850.605713605881, "_timestamp": 1585602220.238583, "_step": 266}
{"Episode reward": 69.7056306472433, "Episode length": 502, "Policy Loss": 0.8026725053787231, "Value Loss": 19.868968963623047, "_runtime": 4851.097860574722, "_timestamp": 1585602220.73073, "_step": 267}
{"Episode reward": 78.88779435909962, "Episode length": 320, "Policy Loss": -0.04311368614435196, "Value Loss": 31.136098861694336, "_runtime": 4851.6950759887695, "_timestamp": 1585602221.3279455, "_step": 268}
{"Episode reward": 77.21182313241816, "Episode length": 379, "Policy Loss": -0.11031359434127808, "Value Loss": 26.296581268310547, "_runtime": 4852.410546064377, "_timestamp": 1585602222.0434155, "_step": 269}
{"Episode reward": 71.33889873768425, "Episode length": 473, "Policy Loss": -0.14214661717414856, "Value Loss": 21.09210205078125, "_runtime": 4853.001586437225, "_timestamp": 1585602222.634456, "_step": 270}
{"Episode reward": 73.73171045065834, "Episode length": 390, "Policy Loss": -0.12933291494846344, "Value Loss": 25.570398330688477, "_runtime": 4853.577112913132, "_timestamp": 1585602223.2099824, "_step": 271}
{"Episode reward": 76.49757855991817, "Episode length": 385, "Policy Loss": 0.11853429675102234, "Value Loss": 25.88814926147461, "_runtime": 4854.744397878647, "_timestamp": 1585602224.3772674, "_step": 272}
{"Episode reward": 54.58030030376467, "Episode length": 780, "Policy Loss": -0.20793388783931732, "Value Loss": 12.808601379394531, "_runtime": 4855.581125974655, "_timestamp": 1585602225.2139955, "_step": 273}
{"Episode reward": 65.05096823521228, "Episode length": 553, "Policy Loss": -0.11729340255260468, "Value Loss": 18.05583381652832, "_runtime": 4856.100586891174, "_timestamp": 1585602225.7334564, "_step": 274}
{"Episode reward": 77.94804628117012, "Episode length": 338, "Policy Loss": 0.07845030725002289, "Value Loss": 29.539052963256836, "_runtime": 4856.766872644424, "_timestamp": 1585602226.3997421, "_step": 275}
{"Episode reward": 75.51516091122905, "Episode length": 429, "Policy Loss": -0.12221594899892807, "Value Loss": 23.266366958618164, "_runtime": 4857.348514556885, "_timestamp": 1585602226.981384, "_step": 276}
{"Episode reward": 77.27656722417795, "Episode length": 372, "Policy Loss": 0.14497298002243042, "Value Loss": 26.820507049560547, "_runtime": 4858.013419389725, "_timestamp": 1585602227.6462889, "_step": 277}
{"Episode reward": 70.66300710926967, "Episode length": 445, "Policy Loss": -0.13229547441005707, "Value Loss": 22.4531307220459, "_runtime": 4858.731031894684, "_timestamp": 1585602228.3639014, "_step": 278}
{"Episode reward": 69.51869663795281, "Episode length": 467, "Policy Loss": -0.008556384593248367, "Value Loss": 21.355314254760742, "_runtime": 4859.530188798904, "_timestamp": 1585602229.1630583, "_step": 279}
{"Episode reward": 67.13983482012432, "Episode length": 527, "Policy Loss": -0.01749660074710846, "Value Loss": 18.939701080322266, "_runtime": 4859.9782547950745, "_timestamp": 1585602229.6111243, "_step": 280}
{"Episode reward": 82.43373122109418, "Episode length": 291, "Policy Loss": 0.1837565153837204, "Value Loss": 34.275081634521484, "_runtime": 4860.601457834244, "_timestamp": 1585602230.2343273, "_step": 281}
{"Episode reward": 74.81522075695075, "Episode length": 410, "Policy Loss": -0.11519313603639603, "Value Loss": 24.31363296508789, "_runtime": 4861.11234998703, "_timestamp": 1585602230.7452195, "_step": 282}
{"Episode reward": 79.4662894708503, "Episode length": 325, "Policy Loss": -0.08157209306955338, "Value Loss": 30.657482147216797, "_runtime": 4861.732809305191, "_timestamp": 1585602231.3656788, "_step": 283}
{"Episode reward": 75.16029269225368, "Episode length": 420, "Policy Loss": -0.10107094794511795, "Value Loss": 23.754838943481445, "_runtime": 4862.200158834457, "_timestamp": 1585602231.8330283, "_step": 284}
{"Episode reward": 81.86077658643973, "Episode length": 299, "Policy Loss": -0.00733193987980485, "Value Loss": 33.31689453125, "_runtime": 4862.957794904709, "_timestamp": 1585602232.5906644, "_step": 285}
{"Episode reward": 69.87038702231496, "Episode length": 512, "Policy Loss": -0.13587439060211182, "Value Loss": 19.480730056762695, "_runtime": 4863.770147562027, "_timestamp": 1585602233.403017, "_step": 286}
{"Episode reward": 65.6154619308769, "Episode length": 545, "Policy Loss": -0.1781615912914276, "Value Loss": 18.343366622924805, "_runtime": 4864.102366924286, "_timestamp": 1585602233.7352364, "_step": 287}
{"Episode reward": 86.40635005349682, "Episode length": 210, "Policy Loss": 0.08705155551433563, "Value Loss": 47.41300964355469, "_runtime": 4865.20346736908, "_timestamp": 1585602234.8363369, "_step": 288}
{"Episode reward": 53.79123211797485, "Episode length": 733, "Policy Loss": -0.23899173736572266, "Value Loss": 13.627341270446777, "_runtime": 4865.7420082092285, "_timestamp": 1585602235.3748777, "_step": 289}
{"Episode reward": 78.8465035683937, "Episode length": 344, "Policy Loss": -0.024328861385583878, "Value Loss": 28.96672821044922, "_runtime": 4866.180130720139, "_timestamp": 1585602235.8130002, "_step": 290}
{"Episode reward": 81.41985447803062, "Episode length": 297, "Policy Loss": -0.003064357442781329, "Value Loss": 33.54140090942383, "_runtime": 4866.531479358673, "_timestamp": 1585602236.1643488, "_step": 291}
{"Episode reward": 86.94511065104976, "Episode length": 213, "Policy Loss": 1.0242878198623657, "Value Loss": 46.78987503051758, "_runtime": 4866.835798501968, "_timestamp": 1585602236.468668, "_step": 292}
{"Episode reward": 87.09352796271163, "Episode length": 196, "Policy Loss": 0.15823444724082947, "Value Loss": 50.7942008972168, "_runtime": 4867.63186621666, "_timestamp": 1585602237.2647357, "_step": 293}
{"Episode reward": 67.11253447371232, "Episode length": 538, "Policy Loss": -0.1688336580991745, "Value Loss": 18.57221794128418, "_runtime": 4868.376424789429, "_timestamp": 1585602238.0092943, "_step": 294}
{"Episode reward": 71.14870019228695, "Episode length": 502, "Policy Loss": -0.009224423207342625, "Value Loss": 19.86759376525879, "_runtime": 4868.831469774246, "_timestamp": 1585602238.4643393, "_step": 295}
{"Episode reward": 81.71134671704696, "Episode length": 310, "Policy Loss": -0.04900701716542244, "Value Loss": 32.13472366333008, "_runtime": 4869.281322479248, "_timestamp": 1585602238.914192, "_step": 296}
{"Episode reward": 83.20266456223925, "Episode length": 290, "Policy Loss": 0.8082273602485657, "Value Loss": 34.34577178955078, "_runtime": 4869.811901092529, "_timestamp": 1585602239.4447706, "_step": 297}
{"Episode reward": 78.97278281496634, "Episode length": 350, "Policy Loss": -0.08130544424057007, "Value Loss": 28.496347427368164, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188, -100.74606323242188]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-76.43821716308594, -74.3909912109375, -72.34376525878906, -70.29653930664062, -68.24931335449219, -66.20208740234375, -64.15486145019531, -62.10763931274414, -60.0604133605957, -58.013187408447266, -55.96596145629883, -53.918739318847656, -51.87151336669922, -49.82428741455078, -47.777061462402344, -45.729835510253906, -43.68260955810547, -41.63538360595703, -39.588157653808594, -37.540931701660156, -35.49370574951172, -33.44648361206055, -31.39925765991211, -29.352031707763672, -27.304805755615234, -25.257579803466797, -23.21035385131836, -21.163127899169922, -19.11590576171875, -17.068679809570312, -15.021453857421875, -12.974227905273438, -10.927001953125, -8.879776000976562, -6.832550048828125, -4.7853240966796875, -2.73809814453125, -0.6908721923828125, 1.356353759765625, 3.4035797119140625, 5.4508056640625, 7.498023986816406, 9.545249938964844, 11.592475891113281, 13.639701843261719, 15.686927795410156, 17.734153747558594, 19.78137969970703, 21.82860565185547, 23.875831604003906, 25.923057556152344, 27.97028350830078, 30.01750946044922, 32.064735412597656, 34.111961364746094, 36.15918731689453, 38.20640563964844, 40.253631591796875, 42.30085754394531, 44.34808349609375, 46.39530944824219, 48.442535400390625, 50.48976135253906, 52.5369873046875, 54.58421325683594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-46.50938415527344, -44.93927001953125, -43.36915588378906, -41.79904556274414, -40.22893142700195, -38.658817291259766, -37.088706970214844, -35.518592834472656, -33.94847869873047, -32.37836456298828, -30.808252334594727, -29.238140106201172, -27.668025970458984, -26.097911834716797, -24.527799606323242, -22.957687377929688, -21.3875732421875, -19.817459106445312, -18.247346878051758, -16.677234649658203, -15.107120513916016, -13.537006378173828, -11.966896057128906, -10.396781921386719, -8.826667785644531, -7.256553649902344, -5.686439514160156, -4.116329193115234, -2.546215057373047, -0.9761009216308594, 0.5940093994140625, 2.16412353515625, 3.7342376708984375, 5.304351806640625, 6.8744659423828125, 8.444576263427734, 10.014690399169922, 11.58480453491211, 13.154914855957031, 14.725028991699219, 16.295143127441406, 17.865257263183594, 19.43537139892578, 21.00548553466797, 22.575592041015625, 24.145706176757812, 25.7158203125, 27.285934448242188, 28.856048583984375, 30.426162719726562, 31.99627685546875, 33.56639099121094, 35.136505126953125, 36.70661163330078, 38.27672576904297, 39.846839904785156, 41.416954040527344, 42.98706817626953, 44.55718231201172, 46.127296447753906, 47.69740295410156, 49.26751708984375, 50.83763122558594, 52.407745361328125, 53.97785949707031]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 1.0, 10.0, 8.0, 4.0, 5.0, 5.0, 4.0, 11.0, 13.0, 14.0, 10.0, 9.0, 19.0, 15.0, 11.0, 17.0, 22.0, 48.0, 34.0, 29.0, 23.0, 20.0, 14.0, 17.0, 18.0, 14.0, 12.0, 9.0, 9.0, 11.0, 9.0, 11.0, 6.0, 5.0, 3.0, 5.0, 2.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-32.4503173828125, -31.35443687438965, -30.258556365966797, -29.162675857543945, -28.066795349121094, -26.970914840698242, -25.87503433227539, -24.779151916503906, -23.683273315429688, -22.587390899658203, -21.491512298583984, -20.3956298828125, -19.29974937438965, -18.203868865966797, -17.107988357543945, -16.012107849121094, -14.916227340698242, -13.82034683227539, -12.724466323852539, -11.628585815429688, -10.532705307006836, -9.436824798583984, -8.340944290161133, -7.245063781738281, -6.149181365966797, -5.053300857543945, -3.9574203491210938, -2.861539840698242, -1.7656593322753906, -0.6697788238525391, 0.4261016845703125, 1.5219802856445312, 2.6178627014160156, 3.7137451171875, 4.809623718261719, 5.905506134033203, 7.001384735107422, 8.097267150878906, 9.193145751953125, 10.28902816772461, 11.384906768798828, 12.480789184570312, 13.576667785644531, 14.672550201416016, 15.768428802490234, 16.86431121826172, 17.960189819335938, 19.056072235107422, 20.151954650878906, 21.247833251953125, 22.34371566772461, 23.439594268798828, 24.535476684570312, 25.63135528564453, 26.727237701416016, 27.823116302490234, 28.91899871826172, 30.014877319335938, 31.110759735107422, 32.206642150878906, 33.302520751953125, 34.398399353027344, 35.49427795410156, 36.59016418457031, 37.68604278564453]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-38.17195510864258, -36.60237121582031, -35.03278350830078, -33.463199615478516, -31.89361572265625, -30.324031829833984, -28.754446029663086, -27.184860229492188, -25.615276336669922, -24.045692443847656, -22.476106643676758, -20.90652084350586, -19.336936950683594, -17.767353057861328, -16.19776725769043, -14.628181457519531, -13.058597564697266, -11.489013671875, -9.919427871704102, -8.349842071533203, -6.7802581787109375, -5.210674285888672, -3.6410865783691406, -2.071502685546875, -0.5019187927246094, 1.0676651000976562, 2.637248992919922, 4.206836700439453, 5.776420593261719, 7.346004486083984, 8.915592193603516, 10.485176086425781, 12.054759979248047, 13.624343872070312, 15.193927764892578, 16.76351547241211, 18.333099365234375, 19.90268325805664, 21.472270965576172, 23.041854858398438, 24.611438751220703, 26.181026458740234, 27.750606536865234, 29.320194244384766, 30.889781951904297, 32.4593620300293, 34.02894973754883, 35.59852981567383, 37.16811752319336, 38.73770523071289, 40.30728530883789, 41.87687301635742, 43.44645309448242, 45.01604080200195, 46.585628509521484, 48.155208587646484, 49.724796295166016, 51.29438400268555, 52.86396408081055, 54.43355178833008, 56.00313949584961, 57.57271957397461, 59.14230728149414, 60.71188735961914, 62.28147506713867]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 7.0, 21.0, 7.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-34.69309997558594, -33.8179817199707, -32.9428596496582, -32.06774139404297, -31.1926212310791, -30.317502975463867, -29.4423828125, -28.567264556884766, -27.6921443939209, -26.81702423095703, -25.941905975341797, -25.06678581237793, -24.191665649414062, -23.316547393798828, -22.44142723083496, -21.566307067871094, -20.69118881225586, -19.816068649291992, -18.940948486328125, -18.06583023071289, -17.190710067749023, -16.315589904785156, -15.440471649169922, -14.565351486206055, -13.690231323242188, -12.815113067626953, -11.939992904663086, -11.064872741699219, -10.189754486083984, -9.314634323120117, -8.43951416015625, -7.564395904541016, -6.689275741577148, -5.814155578613281, -4.939037322998047, -4.06391716003418, -3.1887969970703125, -2.313678741455078, -1.4385604858398438, -0.5634384155273438, 0.3116798400878906, 1.186798095703125, 2.061920166015625, 2.9370384216308594, 3.8121566772460938, 4.687278747558594, 5.562397003173828, 6.4375152587890625, 7.3126373291015625, 8.187755584716797, 9.062873840332031, 9.937995910644531, 10.813114166259766, 11.688232421875, 12.5633544921875, 13.438472747802734, 14.313591003417969, 15.188713073730469, 16.063831329345703, 16.938949584960938, 17.814071655273438, 18.689189910888672, 19.564308166503906, 20.439430236816406, 21.31454849243164]}, "_runtime": 4870.144162654877, "_timestamp": 1585602239.7770321, "_step": 298}
{"Episode reward": 86.3148934465541, "Episode length": 219, "Policy Loss": 1.548558235168457, "Value Loss": 45.4613037109375, "_runtime": 4870.751294851303, "_timestamp": 1585602240.3841643, "_step": 299}
{"Episode reward": 75.54027832182007, "Episode length": 409, "Policy Loss": -0.11086849868297577, "Value Loss": 24.372163772583008, "_runtime": 4871.214105606079, "_timestamp": 1585602240.846975, "_step": 300}
{"Episode reward": 81.27910283738537, "Episode length": 301, "Policy Loss": 0.05557957664132118, "Value Loss": 33.09404754638672, "_runtime": 4871.8495416641235, "_timestamp": 1585602241.4824111, "_step": 301}
{"Episode reward": 77.42219007140707, "Episode length": 435, "Policy Loss": -0.06382060796022415, "Value Loss": 22.960634231567383, "_runtime": 4872.466030597687, "_timestamp": 1585602242.0989, "_step": 302}
{"Episode reward": 74.88884339065207, "Episode length": 404, "Policy Loss": -0.11511967331171036, "Value Loss": 24.674301147460938, "_runtime": 4873.360687017441, "_timestamp": 1585602242.9935565, "_step": 303}
{"Episode reward": 64.43358254878267, "Episode length": 609, "Policy Loss": -0.026717159897089005, "Value Loss": 16.39054298400879, "_runtime": 4873.915200710297, "_timestamp": 1585602243.5480702, "_step": 304}
{"Episode reward": 78.11385834560434, "Episode length": 369, "Policy Loss": -0.11274465173482895, "Value Loss": 27.00653076171875, "_runtime": 4874.615741252899, "_timestamp": 1585602244.2486107, "_step": 305}
{"Episode reward": 73.33154382809664, "Episode length": 444, "Policy Loss": -0.1524960994720459, "Value Loss": 22.45693588256836, "_runtime": 4875.352830886841, "_timestamp": 1585602244.9857004, "_step": 306}
{"Episode reward": 70.16591737931672, "Episode length": 479, "Policy Loss": -0.1733391433954239, "Value Loss": 20.822341918945312, "_runtime": 4875.820871114731, "_timestamp": 1585602245.4537406, "_step": 307}
{"Episode reward": 80.41220149069837, "Episode length": 305, "Policy Loss": 0.1973278820514679, "Value Loss": 32.6658935546875, "_runtime": 4876.307565450668, "_timestamp": 1585602245.940435, "_step": 308}
{"Episode reward": 79.73071609139947, "Episode length": 320, "Policy Loss": -0.08693743497133255, "Value Loss": 31.133068084716797, "_runtime": 4877.430724143982, "_timestamp": 1585602247.0635936, "_step": 309}
{"Episode reward": 54.59105620387548, "Episode length": 750, "Policy Loss": 0.341278612613678, "Value Loss": 13.341519355773926, "_runtime": 4877.931900024414, "_timestamp": 1585602247.5647695, "_step": 310}
{"Episode reward": 80.14553433460102, "Episode length": 327, "Policy Loss": -0.1121678277850151, "Value Loss": 30.517013549804688, "_runtime": 4878.609304666519, "_timestamp": 1585602248.2421741, "_step": 311}
{"Episode reward": 72.64652580983112, "Episode length": 457, "Policy Loss": -0.14998658001422882, "Value Loss": 21.820261001586914, "_runtime": 4879.630710840225, "_timestamp": 1585602249.2635803, "_step": 312}
{"Episode reward": 59.23518517867573, "Episode length": 670, "Policy Loss": -0.16031689941883087, "Value Loss": 14.931035995483398, "_runtime": 4880.330307483673, "_timestamp": 1585602249.963177, "_step": 313}
{"Episode reward": 72.83582058956019, "Episode length": 465, "Policy Loss": -0.10247737169265747, "Value Loss": 21.445289611816406, "_runtime": 4880.805785894394, "_timestamp": 1585602250.4386554, "_step": 314}
{"Episode reward": 81.76362324696278, "Episode length": 303, "Policy Loss": 0.04951221123337746, "Value Loss": 32.8740348815918, "_runtime": 4881.490402936935, "_timestamp": 1585602251.1232724, "_step": 315}
{"Episode reward": 72.80869432484972, "Episode length": 446, "Policy Loss": -0.09601928293704987, "Value Loss": 22.357152938842773, "_runtime": 4882.094539880753, "_timestamp": 1585602251.7274094, "_step": 316}
{"Episode reward": 76.91886626704814, "Episode length": 394, "Policy Loss": 0.21701247990131378, "Value Loss": 25.297054290771484, "_runtime": 4882.942487478256, "_timestamp": 1585602252.575357, "_step": 317}
{"Episode reward": 66.78937692129327, "Episode length": 571, "Policy Loss": -0.21185462176799774, "Value Loss": 17.47712516784668, "_runtime": 4883.411438465118, "_timestamp": 1585602253.044308, "_step": 318}
{"Episode reward": 82.50462796434533, "Episode length": 299, "Policy Loss": -0.018315233290195465, "Value Loss": 33.312129974365234, "_runtime": 4884.783884525299, "_timestamp": 1585602254.416754, "_step": 319}
{"Episode reward": 45.82766817590126, "Episode length": 917, "Policy Loss": -0.2232671082019806, "Value Loss": 10.930755615234375, "_runtime": 4885.525242090225, "_timestamp": 1585602255.1581116, "_step": 320}
{"Episode reward": 71.12677757836256, "Episode length": 479, "Policy Loss": -0.12488818168640137, "Value Loss": 20.82120704650879, "_runtime": 4886.007612705231, "_timestamp": 1585602255.6404822, "_step": 321}
{"Episode reward": 80.97623191575798, "Episode length": 316, "Policy Loss": -0.04164266213774681, "Value Loss": 31.524858474731445, "_runtime": 4887.14729309082, "_timestamp": 1585602256.7801626, "_step": 322}
{"Episode reward": 55.356534832410155, "Episode length": 743, "Policy Loss": -0.17903615534305573, "Value Loss": 13.447887420654297, "_runtime": 4887.742958545685, "_timestamp": 1585602257.375828, "_step": 323}
{"Episode reward": 78.14252557072524, "Episode length": 384, "Policy Loss": 0.3799006938934326, "Value Loss": 25.953168869018555, "_runtime": 4888.498503923416, "_timestamp": 1585602258.1313734, "_step": 324}
{"Episode reward": 70.54967587753592, "Episode length": 510, "Policy Loss": 0.009386096149682999, "Value Loss": 19.559606552124023, "_runtime": 4889.1967804431915, "_timestamp": 1585602258.82965, "_step": 325}
{"Episode reward": 71.8573332181786, "Episode length": 445, "Policy Loss": -0.1701889932155609, "Value Loss": 22.407987594604492, "_runtime": 4889.749192237854, "_timestamp": 1585602259.3820617, "_step": 326}
{"Episode reward": 77.16152036746432, "Episode length": 359, "Policy Loss": 0.14920052886009216, "Value Loss": 27.759185791015625, "_runtime": 4890.423130273819, "_timestamp": 1585602260.0559998, "_step": 327}
{"Episode reward": 74.54580121993408, "Episode length": 448, "Policy Loss": -0.14544637501239777, "Value Loss": 22.254974365234375, "_runtime": 4890.897919893265, "_timestamp": 1585602260.5307894, "_step": 328}
{"Episode reward": 81.25696413797476, "Episode length": 305, "Policy Loss": 0.0532333105802536, "Value Loss": 32.6607666015625, "_runtime": 4891.520994901657, "_timestamp": 1585602261.1538644, "_step": 329}
{"Episode reward": 74.6217213368632, "Episode length": 418, "Policy Loss": -0.02841811627149582, "Value Loss": 23.849361419677734, "_runtime": 4892.070175886154, "_timestamp": 1585602261.7030454, "_step": 330}
{"Episode reward": 77.92251485388527, "Episode length": 366, "Policy Loss": -0.004497244022786617, "Value Loss": 27.22804069519043, "_runtime": 4892.829559087753, "_timestamp": 1585602262.4624286, "_step": 331}
{"Episode reward": 67.4883844216181, "Episode length": 513, "Policy Loss": -0.2001587599515915, "Value Loss": 19.446529388427734, "_runtime": 4893.435343503952, "_timestamp": 1585602263.068213, "_step": 332}
{"Episode reward": 76.40082521429997, "Episode length": 395, "Policy Loss": 0.3191932141780853, "Value Loss": 25.233675003051758, "_runtime": 4893.915193557739, "_timestamp": 1585602263.548063, "_step": 333}
{"Episode reward": 81.66705556776685, "Episode length": 319, "Policy Loss": -0.05552486330270767, "Value Loss": 31.228506088256836, "_runtime": 4894.422035932541, "_timestamp": 1585602264.0549054, "_step": 334}
{"Episode reward": 80.63309450693025, "Episode length": 331, "Policy Loss": 0.30045750737190247, "Value Loss": 30.09939193725586, "_runtime": 4895.463987827301, "_timestamp": 1585602265.0968573, "_step": 335}
{"Episode reward": 58.61970672753227, "Episode length": 697, "Policy Loss": -0.18785876035690308, "Value Loss": 14.328662872314453, "_runtime": 4896.195654153824, "_timestamp": 1585602265.8285236, "_step": 336}
{"Episode reward": 71.18163935424137, "Episode length": 485, "Policy Loss": 0.3173189163208008, "Value Loss": 20.56931495666504, "_runtime": 4896.677816152573, "_timestamp": 1585602266.3106856, "_step": 337}
{"Episode reward": 79.61641472638203, "Episode length": 315, "Policy Loss": 0.17784994840621948, "Value Loss": 31.628082275390625, "_runtime": 4897.615660667419, "_timestamp": 1585602267.2485301, "_step": 338}
{"Episode reward": 62.9110764135987, "Episode length": 617, "Policy Loss": -0.2242729663848877, "Value Loss": 16.178146362304688, "_runtime": 4898.218505144119, "_timestamp": 1585602267.8513746, "_step": 339}
{"Episode reward": 75.75699196572134, "Episode length": 392, "Policy Loss": -0.11323942244052887, "Value Loss": 25.42735481262207, "_runtime": 4898.935255527496, "_timestamp": 1585602268.568125, "_step": 340}
{"Episode reward": 69.94814527750664, "Episode length": 484, "Policy Loss": -0.1644909530878067, "Value Loss": 20.6066837310791, "_runtime": 4899.652824640274, "_timestamp": 1585602269.2856941, "_step": 341}
{"Episode reward": 72.42052928000808, "Episode length": 462, "Policy Loss": 0.042029593139886856, "Value Loss": 21.626007080078125, "_runtime": 4900.1457006931305, "_timestamp": 1585602269.7785702, "_step": 342}
{"Episode reward": 79.35531328894514, "Episode length": 328, "Policy Loss": -0.06818211078643799, "Value Loss": 30.376617431640625, "_runtime": 4900.720308542252, "_timestamp": 1585602270.353178, "_step": 343}
{"Episode reward": 77.47081724534944, "Episode length": 380, "Policy Loss": -0.022445937618613243, "Value Loss": 26.275693893432617, "_runtime": 4902.053900718689, "_timestamp": 1585602271.6867702, "_step": 344}
{"Episode reward": 45.29366002105788, "Episode length": 890, "Policy Loss": -0.2252529412508011, "Value Loss": 11.23555850982666, "_runtime": 4902.636105298996, "_timestamp": 1585602272.2689748, "_step": 345}
{"Episode reward": 76.2680925761604, "Episode length": 380, "Policy Loss": -0.04639897495508194, "Value Loss": 26.269420623779297, "_runtime": 4903.413918972015, "_timestamp": 1585602273.0467885, "_step": 346}
{"Episode reward": 66.85186778791962, "Episode length": 526, "Policy Loss": -0.1681886613368988, "Value Loss": 18.9665470123291, "_runtime": 4904.235287904739, "_timestamp": 1585602273.8681574, "_step": 347}
{"Episode reward": 70.27521023906658, "Episode length": 524, "Policy Loss": -0.09430528432130814, "Value Loss": 19.035558700561523, "_runtime": 4905.044161319733, "_timestamp": 1585602274.6770308, "_step": 348}
{"Episode reward": 67.92337217425671, "Episode length": 535, "Policy Loss": 0.05211377516388893, "Value Loss": 18.646982192993164, "_runtime": 4905.567049026489, "_timestamp": 1585602275.1999185, "_step": 349}
{"Episode reward": 79.7245368450304, "Episode length": 344, "Policy Loss": -0.05119776353240013, "Value Loss": 28.993432998657227, "_runtime": 4905.93492102623, "_timestamp": 1585602275.5677905, "_step": 350}
{"Episode reward": 84.3334266281487, "Episode length": 233, "Policy Loss": 0.4961378276348114, "Value Loss": 42.739009857177734, "_runtime": 4906.400143623352, "_timestamp": 1585602276.033013, "_step": 351}
{"Episode reward": 81.82757071478248, "Episode length": 300, "Policy Loss": -0.014001377858221531, "Value Loss": 33.205223083496094, "_runtime": 4906.944357633591, "_timestamp": 1585602276.577227, "_step": 352}
{"Episode reward": 80.02650644408465, "Episode length": 365, "Policy Loss": 0.025294477120041847, "Value Loss": 27.300235748291016, "_runtime": 4907.553695678711, "_timestamp": 1585602277.1865652, "_step": 353}
{"Episode reward": 74.52418179200932, "Episode length": 415, "Policy Loss": -0.11881192773580551, "Value Loss": 24.04729652404785, "_runtime": 4907.973628044128, "_timestamp": 1585602277.6064975, "_step": 354}
{"Episode reward": 83.16385936284672, "Episode length": 283, "Policy Loss": 0.27170461416244507, "Value Loss": 35.19548034667969, "_runtime": 4908.664674520493, "_timestamp": 1585602278.297544, "_step": 355}
{"Episode reward": 72.83457011586836, "Episode length": 464, "Policy Loss": -0.12820811569690704, "Value Loss": 21.53284454345703, "_runtime": 4909.245427370071, "_timestamp": 1585602278.8782969, "_step": 356}
{"Episode reward": 78.9952511992237, "Episode length": 382, "Policy Loss": -0.014844953082501888, "Value Loss": 26.088058471679688, "_runtime": 4909.877400159836, "_timestamp": 1585602279.5102696, "_step": 357}
{"Episode reward": 74.38784160543209, "Episode length": 429, "Policy Loss": -0.019791018217802048, "Value Loss": 23.238754272460938, "_runtime": 4910.471592903137, "_timestamp": 1585602280.1044624, "_step": 358}
{"Episode reward": 76.69043919473164, "Episode length": 386, "Policy Loss": -0.08501383662223816, "Value Loss": 25.865406036376953, "_runtime": 4910.786998271942, "_timestamp": 1585602280.4198678, "_step": 359}
{"Episode reward": 87.20683293787322, "Episode length": 202, "Policy Loss": 0.4806334376335144, "Value Loss": 49.2846565246582, "_runtime": 4911.342586994171, "_timestamp": 1585602280.9754565, "_step": 360}
{"Episode reward": 77.06395660633963, "Episode length": 368, "Policy Loss": -0.091478630900383, "Value Loss": 27.081632614135742, "_runtime": 4911.994507074356, "_timestamp": 1585602281.6273766, "_step": 361}
{"Episode reward": 73.6450991742659, "Episode length": 437, "Policy Loss": -0.028928309679031372, "Value Loss": 22.814899444580078, "_runtime": 4912.621621847153, "_timestamp": 1585602282.2544913, "_step": 362}
{"Episode reward": 74.4530289979278, "Episode length": 422, "Policy Loss": 0.08463898301124573, "Value Loss": 23.67021369934082, "_runtime": 4913.007225751877, "_timestamp": 1585602282.6400952, "_step": 363}
{"Episode reward": 85.20298438091041, "Episode length": 246, "Policy Loss": 0.3595123589038849, "Value Loss": 40.54563903808594, "_runtime": 4913.709381580353, "_timestamp": 1585602283.342251, "_step": 364}
{"Episode reward": 73.42522223779903, "Episode length": 471, "Policy Loss": -0.14355263113975525, "Value Loss": 21.195852279663086, "_runtime": 4914.29292178154, "_timestamp": 1585602283.9257913, "_step": 365}
{"Episode reward": 79.51387133598124, "Episode length": 356, "Policy Loss": -0.009323092177510262, "Value Loss": 28.04550552368164, "_runtime": 4915.2129342556, "_timestamp": 1585602284.8458037, "_step": 366}
{"Episode reward": 62.20125975249189, "Episode length": 625, "Policy Loss": -0.011999929323792458, "Value Loss": 15.972455024719238, "_runtime": 4915.8052842617035, "_timestamp": 1585602285.4381537, "_step": 367}
{"Episode reward": 77.27335489191339, "Episode length": 385, "Policy Loss": -0.11519864201545715, "Value Loss": 25.938936233520508, "_runtime": 4916.378031492233, "_timestamp": 1585602286.010901, "_step": 368}
{"Episode reward": 75.24674793415969, "Episode length": 384, "Policy Loss": -0.06086013838648796, "Value Loss": 26.000383377075195, "_runtime": 4916.886993646622, "_timestamp": 1585602286.5198631, "_step": 369}
{"Episode reward": 80.34813175277486, "Episode length": 330, "Policy Loss": 0.5174849033355713, "Value Loss": 30.248132705688477, "_runtime": 4917.474249601364, "_timestamp": 1585602287.107119, "_step": 370}
{"Episode reward": 76.14021496073109, "Episode length": 393, "Policy Loss": 0.0774478167295456, "Value Loss": 25.362274169921875, "_runtime": 4917.821212053299, "_timestamp": 1585602287.4540815, "_step": 371}
{"Episode reward": 85.66891058400844, "Episode length": 226, "Policy Loss": 0.026436442509293556, "Value Loss": 44.054527282714844, "_runtime": 4918.376032114029, "_timestamp": 1585602288.0089016, "_step": 372}
{"Episode reward": 77.44774944518895, "Episode length": 373, "Policy Loss": 0.0056468285620212555, "Value Loss": 26.744543075561523, "_runtime": 4918.855553627014, "_timestamp": 1585602288.488423, "_step": 373}
{"Episode reward": 80.7044754559306, "Episode length": 317, "Policy Loss": 0.271647185087204, "Value Loss": 31.426298141479492, "_runtime": 4919.296384572983, "_timestamp": 1585602288.929254, "_step": 374}
{"Episode reward": 82.84707408206242, "Episode length": 299, "Policy Loss": 0.019889747723937035, "Value Loss": 33.31210708618164, "_runtime": 4919.646084070206, "_timestamp": 1585602289.2789536, "_step": 375}
{"Episode reward": 86.78356085669846, "Episode length": 229, "Policy Loss": 0.12079544365406036, "Value Loss": 43.473934173583984, "_runtime": 4920.507163524628, "_timestamp": 1585602290.140033, "_step": 376}
{"Episode reward": 64.82233825609616, "Episode length": 584, "Policy Loss": -0.18166483938694, "Value Loss": 17.09041976928711, "_runtime": 4921.334444761276, "_timestamp": 1585602290.9673142, "_step": 377}
{"Episode reward": 66.05819595729261, "Episode length": 551, "Policy Loss": 0.012245392426848412, "Value Loss": 18.110559463500977, "_runtime": 4922.370635271072, "_timestamp": 1585602292.0035048, "_step": 378}
{"Episode reward": 56.80564744985905, "Episode length": 701, "Policy Loss": 0.047885481268167496, "Value Loss": 14.251895904541016, "_runtime": 4923.205819129944, "_timestamp": 1585602292.8386886, "_step": 379}
{"Episode reward": 66.98026719620034, "Episode length": 541, "Policy Loss": -0.20586934685707092, "Value Loss": 18.44390869140625, "_runtime": 4923.9850952625275, "_timestamp": 1585602293.6179647, "_step": 380}
{"Episode reward": 69.94218513965318, "Episode length": 508, "Policy Loss": -0.16945457458496094, "Value Loss": 19.63639259338379, "_runtime": 4924.750818729401, "_timestamp": 1585602294.3836882, "_step": 381}
{"Episode reward": 71.08243786588508, "Episode length": 505, "Policy Loss": -0.17484834790229797, "Value Loss": 19.76675033569336, "_runtime": 4925.219211101532, "_timestamp": 1585602294.8520806, "_step": 382}
{"Episode reward": 82.82483799520924, "Episode length": 295, "Policy Loss": 0.049376893788576126, "Value Loss": 33.7627067565918, "_runtime": 4925.923688173294, "_timestamp": 1585602295.5565577, "_step": 383}
{"Episode reward": 72.8147806036369, "Episode length": 465, "Policy Loss": -0.1670500785112381, "Value Loss": 21.485074996948242, "_runtime": 4926.489923238754, "_timestamp": 1585602296.1227927, "_step": 384}
{"Episode reward": 78.10615577087607, "Episode length": 366, "Policy Loss": 0.1460847109556198, "Value Loss": 27.227598190307617, "_runtime": 4927.092360496521, "_timestamp": 1585602296.72523, "_step": 385}
{"Episode reward": 75.01263502156803, "Episode length": 407, "Policy Loss": -0.05344716086983681, "Value Loss": 24.49274444580078, "_runtime": 4927.568071126938, "_timestamp": 1585602297.2009406, "_step": 386}
{"Episode reward": 83.62177160626322, "Episode length": 304, "Policy Loss": -0.04415920376777649, "Value Loss": 32.76303482055664, "_runtime": 4928.410581111908, "_timestamp": 1585602298.0434506, "_step": 387}
{"Episode reward": 66.24144991840717, "Episode length": 567, "Policy Loss": -0.21241424977779388, "Value Loss": 17.609416961669922, "_runtime": 4929.014260530472, "_timestamp": 1585602298.64713, "_step": 388}
{"Episode reward": 76.00064539791558, "Episode length": 393, "Policy Loss": 0.15714341402053833, "Value Loss": 25.362443923950195, "_runtime": 4929.541599035263, "_timestamp": 1585602299.1744685, "_step": 389}
{"Episode reward": 79.6662412988098, "Episode length": 355, "Policy Loss": -0.10107000917196274, "Value Loss": 28.067800521850586, "_runtime": 4930.225514173508, "_timestamp": 1585602299.8583837, "_step": 390}
{"Episode reward": 73.89707228366329, "Episode length": 451, "Policy Loss": -0.16034406423568726, "Value Loss": 22.14959144592285, "_runtime": 4931.1902639865875, "_timestamp": 1585602300.8231335, "_step": 391}
{"Episode reward": 60.16033170052195, "Episode length": 641, "Policy Loss": 0.03840961679816246, "Value Loss": 15.5779390335083, "_runtime": 4932.151658535004, "_timestamp": 1585602301.784528, "_step": 392}
{"Episode reward": 60.867271547072626, "Episode length": 641, "Policy Loss": -0.2406991571187973, "Value Loss": 15.608367919921875, "_runtime": 4932.811927556992, "_timestamp": 1585602302.444797, "_step": 393}
{"Episode reward": 74.01650723680785, "Episode length": 432, "Policy Loss": 0.014890532940626144, "Value Loss": 23.07866668701172, "_runtime": 4933.3198783397675, "_timestamp": 1585602302.9527478, "_step": 394}
{"Episode reward": 81.0834045366885, "Episode length": 319, "Policy Loss": 0.12396962195634842, "Value Loss": 31.22871208190918, "_runtime": 4934.138932943344, "_timestamp": 1585602303.7718024, "_step": 395}
{"Episode reward": 67.57229633223386, "Episode length": 541, "Policy Loss": 0.0024812978226691484, "Value Loss": 18.476665496826172, "_runtime": 4934.503403425217, "_timestamp": 1585602304.136273, "_step": 396}
{"Episode reward": 86.20120289934479, "Episode length": 227, "Policy Loss": 0.5157350897789001, "Value Loss": 43.858642578125, "_runtime": 4935.2829377651215, "_timestamp": 1585602304.9158072, "_step": 397}
{"Episode reward": 70.19355298458737, "Episode length": 527, "Policy Loss": -0.13729935884475708, "Value Loss": 18.965591430664062, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453, -89.09522247314453]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-69.37427520751953, -67.54329681396484, -65.71231079101562, -63.88133239746094, -62.050350189208984, -60.21936798095703, -58.388389587402344, -56.55740737915039, -54.72642517089844, -52.895442962646484, -51.06446075439453, -49.233482360839844, -47.40250015258789, -45.57151794433594, -43.74053955078125, -41.9095573425293, -40.078575134277344, -38.24759292602539, -36.41661071777344, -34.58563232421875, -32.7546501159668, -30.923667907714844, -29.092689514160156, -27.261707305908203, -25.43072509765625, -23.599742889404297, -21.768760681152344, -19.937782287597656, -18.106800079345703, -16.27581787109375, -14.444839477539062, -12.61385726928711, -10.782875061035156, -8.951892852783203, -7.12091064453125, -5.2899322509765625, -3.4589462280273438, -1.6279678344726562, 0.20301055908203125, 2.03399658203125, 3.8649749755859375, 5.695953369140625, 7.526939392089844, 9.357917785644531, 11.188896179199219, 13.019882202148438, 14.850860595703125, 16.681846618652344, 18.51282501220703, 20.34380340576172, 22.174789428710938, 24.005767822265625, 25.836753845214844, 27.66773223876953, 29.49871063232422, 31.329696655273438, 33.160675048828125, 34.99165344238281, 36.82263946533203, 38.65361785888672, 40.484596252441406, 42.315582275390625, 44.14656066894531, 45.97754669189453, 47.80852508544922]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-41.050235748291016, -39.67335891723633, -38.29648208618164, -36.91960525512695, -35.542724609375, -34.16584777832031, -32.788970947265625, -31.412094116210938, -30.03521728515625, -28.658340454101562, -27.281463623046875, -25.904584884643555, -24.527708053588867, -23.15083122253418, -21.77395248413086, -20.397075653076172, -19.020198822021484, -17.643321990966797, -16.26644515991211, -14.889566421508789, -13.512689590454102, -12.135812759399414, -10.758934020996094, -9.382057189941406, -8.005180358886719, -6.628303527832031, -5.251426696777344, -3.8745498657226562, -2.497669219970703, -1.1207923889160156, 0.2560844421386719, 1.6329612731933594, 3.009838104248047, 4.386714935302734, 5.763591766357422, 7.140468597412109, 8.517345428466797, 9.89422607421875, 11.271102905273438, 12.647979736328125, 14.024856567382812, 15.4017333984375, 16.778610229492188, 18.155487060546875, 19.532367706298828, 20.909244537353516, 22.286121368408203, 23.66299819946289, 25.039875030517578, 26.416751861572266, 27.793628692626953, 29.17050552368164, 30.547382354736328, 31.924259185791016, 33.3011360168457, 34.67801284790039, 36.05489730834961, 37.4317741394043, 38.808650970458984, 40.18552780151367, 41.56240463256836, 42.93928146362305, 44.316158294677734, 45.69303512573242, 47.06991195678711]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 7.0, 8.0, 6.0, 4.0, 4.0, 6.0, 13.0, 7.0, 15.0, 10.0, 12.0, 15.0, 16.0, 9.0, 17.0, 22.0, 40.0, 43.0, 25.0, 34.0, 17.0, 14.0, 17.0, 17.0, 16.0, 10.0, 9.0, 11.0, 11.0, 8.0, 7.0, 8.0, 7.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-28.902387619018555, -27.93221664428711, -26.96204376220703, -25.991870880126953, -25.021699905395508, -24.051528930664062, -23.081356048583984, -22.111183166503906, -21.14101219177246, -20.170841217041016, -19.200668334960938, -18.23049545288086, -17.260324478149414, -16.29015350341797, -15.31998062133789, -14.349808692932129, -13.379636764526367, -12.409463882446289, -11.439292907714844, -10.469121932983398, -9.49894905090332, -8.528776168823242, -7.558605194091797, -6.588434219360352, -5.618261337280273, -4.648088455200195, -3.67791748046875, -2.7077465057373047, -1.7375736236572266, -0.7674007415771484, 0.20277023315429688, 1.1729412078857422, 2.1431140899658203, 3.1132869720458984, 4.083459854125977, 5.053628921508789, 6.023801803588867, 6.993974685668945, 7.964143753051758, 8.934316635131836, 9.904489517211914, 10.874662399291992, 11.84483528137207, 12.815004348754883, 13.785177230834961, 14.755350112915039, 15.725519180297852, 16.69569206237793, 17.665864944458008, 18.636037826538086, 19.606210708618164, 20.576379776000977, 21.546552658081055, 22.516725540161133, 23.486894607543945, 24.457067489624023, 25.4272403717041, 26.39741325378418, 27.367586135864258, 28.33775520324707, 29.30792808532715, 30.278100967407227, 31.24827003479004, 32.21844482421875, 33.18861389160156]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-33.300506591796875, -31.921031951904297, -30.54155731201172, -29.162084579467773, -27.782609939575195, -26.403135299682617, -25.023662567138672, -23.644187927246094, -22.264713287353516, -20.885238647460938, -19.50576400756836, -18.126291275024414, -16.746816635131836, -15.367341995239258, -13.987869262695312, -12.608394622802734, -11.228919982910156, -9.849445343017578, -8.469970703125, -7.090497970581055, -5.711023330688477, -4.331548690795898, -2.952075958251953, -1.572601318359375, -0.19312667846679688, 1.1863479614257812, 2.5658226013183594, 3.9452972412109375, 5.32476806640625, 6.704242706298828, 8.083717346191406, 9.463191986083984, 10.842666625976562, 12.22214126586914, 13.601615905761719, 14.981090545654297, 16.360565185546875, 17.740036010742188, 19.119510650634766, 20.498985290527344, 21.878459930419922, 23.2579345703125, 24.637409210205078, 26.016883850097656, 27.39635467529297, 28.775829315185547, 30.155303955078125, 31.53478240966797, 32.91425323486328, 34.293724060058594, 35.67320251464844, 37.05267333984375, 38.432151794433594, 39.811622619628906, 41.19110107421875, 42.57057189941406, 43.950042724609375, 45.32952117919922, 46.70899200439453, 48.088470458984375, 49.46794128417969, 50.84741973876953, 52.226890563964844, 53.60636901855469, 54.98583984375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 23.0, 10.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-25.85359001159668, -25.205081939697266, -24.55657196044922, -23.908061981201172, -23.259553909301758, -22.611045837402344, -21.962535858154297, -21.31402587890625, -20.665517807006836, -20.017009735107422, -19.368499755859375, -18.719989776611328, -18.071481704711914, -17.4229736328125, -16.774463653564453, -16.125953674316406, -15.477445602416992, -14.828936576843262, -14.180427551269531, -13.5319185256958, -12.88340950012207, -12.23490047454834, -11.58639144897461, -10.937882423400879, -10.289373397827148, -9.640863418579102, -8.992355346679688, -8.343847274780273, -7.695337295532227, -7.04682731628418, -6.398319244384766, -5.749811172485352, -5.101301193237305, -4.452791213989258, -3.8042831420898438, -3.1557750701904297, -2.507265090942383, -1.858755111694336, -1.2102470397949219, -0.5617389678955078, 0.08677101135253906, 0.7352809906005859, 1.3837890625, 2.032297134399414, 2.680807113647461, 3.329317092895508, 3.977825164794922, 4.626333236694336, 5.274843215942383, 5.92335319519043, 6.571863174438477, 7.220369338989258, 7.868879318237305, 8.517389297485352, 9.165895462036133, 9.81440544128418, 10.462915420532227, 11.111425399780273, 11.75993537902832, 12.408441543579102, 13.056951522827148, 13.705461502075195, 14.353967666625977, 15.002477645874023, 15.65098762512207]}, "_runtime": 4936.262921094894, "_timestamp": 1585602305.8957906, "_step": 398}
{"Episode reward": 60.66393562409094, "Episode length": 646, "Policy Loss": -0.1639474779367447, "Value Loss": 15.459733009338379, "_runtime": 4936.719967126846, "_timestamp": 1585602306.3528366, "_step": 399}
{"Episode reward": 80.475200665032, "Episode length": 301, "Policy Loss": 0.5217465162277222, "Value Loss": 33.095314025878906, "_runtime": 4937.051055669785, "_timestamp": 1585602306.6839252, "_step": 400}
{"Episode reward": 88.45125462900528, "Episode length": 207, "Policy Loss": 0.11225477606058121, "Value Loss": 48.08767318725586, "_runtime": 4937.680793523788, "_timestamp": 1585602307.313663, "_step": 401}
{"Episode reward": 75.73009565913743, "Episode length": 408, "Policy Loss": -0.09209831804037094, "Value Loss": 24.43872833251953, "_runtime": 4938.353667020798, "_timestamp": 1585602307.9865365, "_step": 402}
{"Episode reward": 73.60587787909783, "Episode length": 448, "Policy Loss": 0.4229569137096405, "Value Loss": 22.25605583190918, "_runtime": 4938.996648073196, "_timestamp": 1585602308.6295176, "_step": 403}
{"Episode reward": 74.20229006554969, "Episode length": 433, "Policy Loss": -0.15794305503368378, "Value Loss": 23.07126235961914, "_runtime": 4939.46883392334, "_timestamp": 1585602309.1017034, "_step": 404}
{"Episode reward": 82.40649453487477, "Episode length": 304, "Policy Loss": 0.071790412068367, "Value Loss": 32.7658576965332, "_runtime": 4940.106588125229, "_timestamp": 1585602309.7394576, "_step": 405}
{"Episode reward": 75.24712481363039, "Episode length": 427, "Policy Loss": -0.11883500218391418, "Value Loss": 23.346759796142578, "_runtime": 4940.620010137558, "_timestamp": 1585602310.2528796, "_step": 406}
{"Episode reward": 80.56205905664474, "Episode length": 331, "Policy Loss": -0.050877247005701065, "Value Loss": 30.128997802734375, "_runtime": 4941.36466217041, "_timestamp": 1585602310.9975317, "_step": 407}
{"Episode reward": 69.92647674877858, "Episode length": 499, "Policy Loss": -0.1433802843093872, "Value Loss": 19.98919677734375, "_runtime": 4941.806641101837, "_timestamp": 1585602311.4395106, "_step": 408}
{"Episode reward": 82.10266586863207, "Episode length": 289, "Policy Loss": 0.19658349454402924, "Value Loss": 34.51854705810547, "_runtime": 4942.601495742798, "_timestamp": 1585602312.2343652, "_step": 409}
{"Episode reward": 67.82678646634565, "Episode length": 537, "Policy Loss": -0.1647193431854248, "Value Loss": 18.616207122802734, "_runtime": 4943.459923744202, "_timestamp": 1585602313.0927932, "_step": 410}
{"Episode reward": 66.49009697527248, "Episode length": 563, "Policy Loss": -0.199711874127388, "Value Loss": 17.724416732788086, "_runtime": 4944.208156585693, "_timestamp": 1585602313.841026, "_step": 411}
{"Episode reward": 70.30064332837577, "Episode length": 500, "Policy Loss": -0.1405380815267563, "Value Loss": 19.9488582611084, "_runtime": 4944.788636684418, "_timestamp": 1585602314.4215062, "_step": 412}
{"Episode reward": 77.32201016172883, "Episode length": 376, "Policy Loss": -0.1205834448337555, "Value Loss": 26.505624771118164, "_runtime": 4945.764943361282, "_timestamp": 1585602315.3978128, "_step": 413}
{"Episode reward": 62.79293588936555, "Episode length": 647, "Policy Loss": -0.19209004938602448, "Value Loss": 15.460916519165039, "_runtime": 4946.347107172012, "_timestamp": 1585602315.9799767, "_step": 414}
{"Episode reward": 78.5809863645661, "Episode length": 377, "Policy Loss": -0.12146522104740143, "Value Loss": 26.433761596679688, "_runtime": 4946.999670982361, "_timestamp": 1585602316.6325405, "_step": 415}
{"Episode reward": 72.43777604562788, "Episode length": 439, "Policy Loss": -0.15715688467025757, "Value Loss": 22.712921142578125, "_runtime": 4947.815402984619, "_timestamp": 1585602317.4482725, "_step": 416}
{"Episode reward": 69.20429192446564, "Episode length": 527, "Policy Loss": -0.10452720522880554, "Value Loss": 18.958703994750977, "_runtime": 4948.350187778473, "_timestamp": 1585602317.9830573, "_step": 417}
{"Episode reward": 80.21285419346867, "Episode length": 349, "Policy Loss": -0.00313185784034431, "Value Loss": 28.56521224975586, "_runtime": 4949.097492456436, "_timestamp": 1585602318.730362, "_step": 418}
{"Episode reward": 70.64501755947947, "Episode length": 500, "Policy Loss": -0.10369395464658737, "Value Loss": 19.948217391967773, "_runtime": 4949.692686319351, "_timestamp": 1585602319.3255558, "_step": 419}
{"Episode reward": 77.23730947075686, "Episode length": 383, "Policy Loss": 0.013561581261456013, "Value Loss": 26.02194595336914, "_runtime": 4950.436626434326, "_timestamp": 1585602320.069496, "_step": 420}
{"Episode reward": 70.32625470145794, "Episode length": 500, "Policy Loss": 0.10462719202041626, "Value Loss": 19.980579376220703, "_runtime": 4951.01864862442, "_timestamp": 1585602320.651518, "_step": 421}
{"Episode reward": 77.53380254391695, "Episode length": 377, "Policy Loss": -0.10452324897050858, "Value Loss": 26.435165405273438, "_runtime": 4951.485369443893, "_timestamp": 1585602321.118239, "_step": 422}
{"Episode reward": 82.29387552410351, "Episode length": 308, "Policy Loss": -0.05633622780442238, "Value Loss": 32.40220642089844, "_runtime": 4952.1613092422485, "_timestamp": 1585602321.7941787, "_step": 423}
{"Episode reward": 72.86205130573653, "Episode length": 450, "Policy Loss": -0.15998217463493347, "Value Loss": 22.157865524291992, "_runtime": 4952.514659404755, "_timestamp": 1585602322.147529, "_step": 424}
{"Episode reward": 86.28506686191669, "Episode length": 222, "Policy Loss": 0.025123661383986473, "Value Loss": 44.84748840332031, "_runtime": 4952.884449481964, "_timestamp": 1585602322.517319, "_step": 425}
{"Episode reward": 85.40588695751781, "Episode length": 244, "Policy Loss": 0.39737847447395325, "Value Loss": 40.878787994384766, "_runtime": 4954.061730623245, "_timestamp": 1585602323.6946, "_step": 426}
{"Episode reward": 52.967168907379936, "Episode length": 789, "Policy Loss": -0.21421435475349426, "Value Loss": 12.665752410888672, "_runtime": 4954.985579967499, "_timestamp": 1585602324.6184494, "_step": 427}
{"Episode reward": 64.65596652731377, "Episode length": 619, "Policy Loss": -0.045358721166849136, "Value Loss": 16.124921798706055, "_runtime": 4955.408479452133, "_timestamp": 1585602325.041349, "_step": 428}
{"Episode reward": 83.74193298034288, "Episode length": 275, "Policy Loss": 0.1771474927663803, "Value Loss": 36.215450286865234, "_runtime": 4955.7731301784515, "_timestamp": 1585602325.4059997, "_step": 429}
{"Episode reward": 86.30101489504708, "Episode length": 219, "Policy Loss": 0.8193339705467224, "Value Loss": 45.46070861816406, "_runtime": 4956.465486288071, "_timestamp": 1585602326.0983558, "_step": 430}
{"Episode reward": 73.67125904164443, "Episode length": 452, "Policy Loss": 0.0773385614156723, "Value Loss": 22.076265335083008, "_runtime": 4957.075226545334, "_timestamp": 1585602326.708096, "_step": 431}
{"Episode reward": 75.45519510359776, "Episode length": 404, "Policy Loss": -0.15139652788639069, "Value Loss": 24.722578048706055, "_runtime": 4957.401172637939, "_timestamp": 1585602327.0340421, "_step": 432}
{"Episode reward": 87.0659896592798, "Episode length": 220, "Policy Loss": 0.11488395184278488, "Value Loss": 45.25166320800781, "_runtime": 4957.827774763107, "_timestamp": 1585602327.4606442, "_step": 433}
{"Episode reward": 83.94762483957675, "Episode length": 279, "Policy Loss": 0.09803925454616547, "Value Loss": 35.6956672668457, "_runtime": 4958.237539052963, "_timestamp": 1585602327.8704085, "_step": 434}
{"Episode reward": 83.43201848928521, "Episode length": 269, "Policy Loss": -0.01819624751806259, "Value Loss": 37.06412124633789, "_runtime": 4958.626456975937, "_timestamp": 1585602328.2593265, "_step": 435}
{"Episode reward": 83.96201988144824, "Episode length": 263, "Policy Loss": 0.19062401354312897, "Value Loss": 37.864158630371094, "_runtime": 4959.487636566162, "_timestamp": 1585602329.120506, "_step": 436}
{"Episode reward": 66.52278383631759, "Episode length": 580, "Policy Loss": -0.19822348654270172, "Value Loss": 17.206527709960938, "_runtime": 4960.208857536316, "_timestamp": 1585602329.841727, "_step": 437}
{"Episode reward": 72.70966345457475, "Episode length": 456, "Policy Loss": -0.03559024631977081, "Value Loss": 21.874347686767578, "_runtime": 4960.685940027237, "_timestamp": 1585602330.3188095, "_step": 438}
{"Episode reward": 81.33067034305152, "Episode length": 315, "Policy Loss": -0.06495357304811478, "Value Loss": 31.623939514160156, "_runtime": 4961.168787956238, "_timestamp": 1585602330.8016574, "_step": 439}
{"Episode reward": 80.61884417555898, "Episode length": 313, "Policy Loss": 0.5056038498878479, "Value Loss": 31.82670783996582, "_runtime": 4961.603390693665, "_timestamp": 1585602331.2362602, "_step": 440}
{"Episode reward": 83.59423358268309, "Episode length": 284, "Policy Loss": 0.0029590348713099957, "Value Loss": 35.06674575805664, "_runtime": 4962.281298875809, "_timestamp": 1585602331.9141684, "_step": 441}
{"Episode reward": 73.17867642368311, "Episode length": 462, "Policy Loss": -0.00671720365062356, "Value Loss": 21.584291458129883, "_runtime": 4962.928504228592, "_timestamp": 1585602332.5613737, "_step": 442}
{"Episode reward": 73.28786420913671, "Episode length": 429, "Policy Loss": -0.10473936796188354, "Value Loss": 23.24123764038086, "_runtime": 4963.4826118946075, "_timestamp": 1585602333.1154814, "_step": 443}
{"Episode reward": 78.65129199545322, "Episode length": 367, "Policy Loss": 0.23451222479343414, "Value Loss": 27.15253257751465, "_runtime": 4963.836979866028, "_timestamp": 1585602333.4698493, "_step": 444}
{"Episode reward": 85.70126718268259, "Episode length": 223, "Policy Loss": 0.9537912607192993, "Value Loss": 44.72850799560547, "_runtime": 4964.298582315445, "_timestamp": 1585602333.9314518, "_step": 445}
{"Episode reward": 83.04610169731059, "Episode length": 299, "Policy Loss": -0.06766633689403534, "Value Loss": 33.32199478149414, "_runtime": 4964.673748016357, "_timestamp": 1585602334.3066175, "_step": 446}
{"Episode reward": 83.6831285090046, "Episode length": 246, "Policy Loss": 0.04708074405789375, "Value Loss": 40.475284576416016, "_runtime": 4965.092685222626, "_timestamp": 1585602334.7255547, "_step": 447}
{"Episode reward": 82.9340199736744, "Episode length": 285, "Policy Loss": -0.062226686626672745, "Value Loss": 34.94386672973633, "_runtime": 4965.628535032272, "_timestamp": 1585602335.2614045, "_step": 448}
{"Episode reward": 77.97777938384657, "Episode length": 361, "Policy Loss": -0.13780558109283447, "Value Loss": 27.60422706604004, "_runtime": 4966.585891485214, "_timestamp": 1585602336.218761, "_step": 449}
{"Episode reward": 59.96516628133916, "Episode length": 650, "Policy Loss": -0.16274850070476532, "Value Loss": 15.373608589172363, "_runtime": 4967.345922708511, "_timestamp": 1585602336.9787922, "_step": 450}
{"Episode reward": 69.89702281131778, "Episode length": 507, "Policy Loss": -0.08226363360881805, "Value Loss": 19.677265167236328, "_runtime": 4968.341187000275, "_timestamp": 1585602337.9740565, "_step": 451}
{"Episode reward": 58.82255928920524, "Episode length": 675, "Policy Loss": -0.00010508215200388804, "Value Loss": 14.800596237182617, "_runtime": 4969.287307500839, "_timestamp": 1585602338.920177, "_step": 452}
{"Episode reward": 63.7373735614402, "Episode length": 615, "Policy Loss": -0.05235357955098152, "Value Loss": 16.23566436767578, "_runtime": 4970.416407108307, "_timestamp": 1585602340.0492766, "_step": 453}
{"Episode reward": 53.824516890836755, "Episode length": 753, "Policy Loss": -0.23250705003738403, "Value Loss": 13.275981903076172, "_runtime": 4971.3248517513275, "_timestamp": 1585602340.9577212, "_step": 454}
{"Episode reward": 65.75101391876478, "Episode length": 591, "Policy Loss": -0.1914837509393692, "Value Loss": 16.89151954650879, "_runtime": 4971.904030323029, "_timestamp": 1585602341.5368998, "_step": 455}
{"Episode reward": 77.07130456755723, "Episode length": 368, "Policy Loss": -0.0912090390920639, "Value Loss": 27.081340789794922, "_runtime": 4972.195595741272, "_timestamp": 1585602341.8284652, "_step": 456}
{"Episode reward": 89.46575353241128, "Episode length": 172, "Policy Loss": 0.8511910438537598, "Value Loss": 57.849830627441406, "_runtime": 4972.667088985443, "_timestamp": 1585602342.2999585, "_step": 457}
{"Episode reward": 82.68311083379557, "Episode length": 303, "Policy Loss": -0.08371379971504211, "Value Loss": 32.87088394165039, "_runtime": 4972.927364587784, "_timestamp": 1585602342.560234, "_step": 458}
{"Episode reward": 90.25813916032169, "Episode length": 163, "Policy Loss": 0.24085740745067596, "Value Loss": 61.10299301147461, "_runtime": 4973.250074863434, "_timestamp": 1585602342.8829443, "_step": 459}
{"Episode reward": 86.61456573416292, "Episode length": 217, "Policy Loss": 0.03878699243068695, "Value Loss": 45.86935043334961, "_runtime": 4974.012319087982, "_timestamp": 1585602343.6451886, "_step": 460}
{"Episode reward": 67.4269334202273, "Episode length": 517, "Policy Loss": -0.22425885498523712, "Value Loss": 19.300464630126953, "_runtime": 4974.391371250153, "_timestamp": 1585602344.0242407, "_step": 461}
{"Episode reward": 84.39387000376315, "Episode length": 249, "Policy Loss": 0.08016998320817947, "Value Loss": 40.05988693237305, "_runtime": 4975.127478837967, "_timestamp": 1585602344.7603483, "_step": 462}
{"Episode reward": 69.07417659203684, "Episode length": 502, "Policy Loss": -0.22819364070892334, "Value Loss": 19.913856506347656, "_runtime": 4975.570943593979, "_timestamp": 1585602345.203813, "_step": 463}
{"Episode reward": 83.13192108225154, "Episode length": 278, "Policy Loss": 0.008316128514707088, "Value Loss": 35.82078552246094, "_runtime": 4976.2317106723785, "_timestamp": 1585602345.8645802, "_step": 464}
{"Episode reward": 72.94703525038207, "Episode length": 448, "Policy Loss": -0.16320334374904633, "Value Loss": 22.271440505981445, "_runtime": 4976.690005064011, "_timestamp": 1585602346.3228745, "_step": 465}
{"Episode reward": 81.52452243118567, "Episode length": 293, "Policy Loss": -0.06096385419368744, "Value Loss": 33.99232482910156, "_runtime": 4977.117617368698, "_timestamp": 1585602346.7504869, "_step": 466}
{"Episode reward": 82.96636834699123, "Episode length": 288, "Policy Loss": -0.035172294825315475, "Value Loss": 34.6309700012207, "_runtime": 4977.460310935974, "_timestamp": 1585602347.0931804, "_step": 467}
{"Episode reward": 86.55547028311769, "Episode length": 221, "Policy Loss": 0.7733139991760254, "Value Loss": 45.11756896972656, "_runtime": 4977.906220912933, "_timestamp": 1585602347.5390904, "_step": 468}
{"Episode reward": 83.35812981154686, "Episode length": 299, "Policy Loss": -0.00824953243136406, "Value Loss": 33.30744934082031, "_runtime": 4978.450955867767, "_timestamp": 1585602348.0838253, "_step": 469}
{"Episode reward": 77.51799849864179, "Episode length": 366, "Policy Loss": -0.16170725226402283, "Value Loss": 27.228744506835938, "_runtime": 4978.934437990189, "_timestamp": 1585602348.5673075, "_step": 470}
{"Episode reward": 81.13518982371383, "Episode length": 327, "Policy Loss": 0.4732916057109833, "Value Loss": 30.488807678222656, "_runtime": 4979.4667019844055, "_timestamp": 1585602349.0995715, "_step": 471}
{"Episode reward": 79.27650288984333, "Episode length": 355, "Policy Loss": 0.25231412053108215, "Value Loss": 28.112285614013672, "_runtime": 4980.795168638229, "_timestamp": 1585602350.4280381, "_step": 472}
{"Episode reward": 46.35281822346046, "Episode length": 885, "Policy Loss": -0.2786374092102051, "Value Loss": 11.332626342773438, "_runtime": 4981.671090126038, "_timestamp": 1585602351.3039596, "_step": 473}
{"Episode reward": 63.12035345552634, "Episode length": 580, "Policy Loss": -0.1246064156293869, "Value Loss": 17.216617584228516, "_runtime": 4982.234937667847, "_timestamp": 1585602351.8678071, "_step": 474}
{"Episode reward": 78.63451650411942, "Episode length": 366, "Policy Loss": -0.10422681272029877, "Value Loss": 27.227142333984375, "_runtime": 4982.986778259277, "_timestamp": 1585602352.6196477, "_step": 475}
{"Episode reward": 71.30980647433968, "Episode length": 481, "Policy Loss": -0.06651320308446884, "Value Loss": 20.739173889160156, "_runtime": 4983.348259449005, "_timestamp": 1585602352.981129, "_step": 476}
{"Episode reward": 86.12417561570686, "Episode length": 221, "Policy Loss": 0.011388538405299187, "Value Loss": 45.09198760986328, "_runtime": 4984.049026012421, "_timestamp": 1585602353.6818955, "_step": 477}
{"Episode reward": 69.94096892344574, "Episode length": 470, "Policy Loss": -0.2183607816696167, "Value Loss": 21.24485969543457, "_runtime": 4984.994617938995, "_timestamp": 1585602354.6274874, "_step": 478}
{"Episode reward": 61.716633239667736, "Episode length": 617, "Policy Loss": -0.2616964280605316, "Value Loss": 16.188617706298828, "_runtime": 4985.651080369949, "_timestamp": 1585602355.2839499, "_step": 479}
{"Episode reward": 73.421610827076, "Episode length": 435, "Policy Loss": -0.21682152152061462, "Value Loss": 22.95979118347168, "_runtime": 4986.311902523041, "_timestamp": 1585602355.944772, "_step": 480}
{"Episode reward": 75.09260746227591, "Episode length": 429, "Policy Loss": 0.10098470002412796, "Value Loss": 23.287330627441406, "_runtime": 4986.8272478580475, "_timestamp": 1585602356.4601173, "_step": 481}
{"Episode reward": 79.87290523567563, "Episode length": 326, "Policy Loss": -0.1086442619562149, "Value Loss": 30.588415145874023, "_runtime": 4987.401467084885, "_timestamp": 1585602357.0343366, "_step": 482}
{"Episode reward": 76.06232680219352, "Episode length": 383, "Policy Loss": -0.14925622940063477, "Value Loss": 26.024625778198242, "_runtime": 4988.174937486649, "_timestamp": 1585602357.807807, "_step": 483}
{"Episode reward": 68.18628158994166, "Episode length": 517, "Policy Loss": -0.12212900817394257, "Value Loss": 19.30158042907715, "_runtime": 4988.743771314621, "_timestamp": 1585602358.3766408, "_step": 484}
{"Episode reward": 75.48301475475074, "Episode length": 374, "Policy Loss": -0.06950318813323975, "Value Loss": 26.650484085083008, "_runtime": 4989.2272391319275, "_timestamp": 1585602358.8601086, "_step": 485}
{"Episode reward": 79.52154781170495, "Episode length": 322, "Policy Loss": -0.05875524505972862, "Value Loss": 30.964832305908203, "_runtime": 4990.019960165024, "_timestamp": 1585602359.6528296, "_step": 486}
{"Episode reward": 67.63330969001495, "Episode length": 529, "Policy Loss": -0.24257951974868774, "Value Loss": 18.865032196044922, "_runtime": 4990.7854545116425, "_timestamp": 1585602360.418324, "_step": 487}
{"Episode reward": 68.61137151541011, "Episode length": 505, "Policy Loss": -0.22894687950611115, "Value Loss": 19.757810592651367, "_runtime": 4991.256727218628, "_timestamp": 1585602360.8895967, "_step": 488}
{"Episode reward": 80.69796731329988, "Episode length": 308, "Policy Loss": -0.10189619660377502, "Value Loss": 32.40552520751953, "_runtime": 4991.589279174805, "_timestamp": 1585602361.2221487, "_step": 489}
{"Episode reward": 87.43617441989629, "Episode length": 208, "Policy Loss": 0.18910206854343414, "Value Loss": 47.84739303588867, "_runtime": 4992.20752620697, "_timestamp": 1585602361.8403957, "_step": 490}
{"Episode reward": 73.8865014772612, "Episode length": 408, "Policy Loss": -0.1949813812971115, "Value Loss": 24.435705184936523, "_runtime": 4992.767551183701, "_timestamp": 1585602362.4004207, "_step": 491}
{"Episode reward": 76.3970129890665, "Episode length": 369, "Policy Loss": 0.10530395060777664, "Value Loss": 27.054536819458008, "_runtime": 4993.192398071289, "_timestamp": 1585602362.8252676, "_step": 492}
{"Episode reward": 82.1335892589144, "Episode length": 289, "Policy Loss": 0.1995171308517456, "Value Loss": 34.52328872680664, "_runtime": 4994.108856678009, "_timestamp": 1585602363.7417262, "_step": 493}
{"Episode reward": 62.039262827561224, "Episode length": 613, "Policy Loss": -0.13995571434497833, "Value Loss": 16.29096221923828, "_runtime": 4995.363321065903, "_timestamp": 1585602364.9961905, "_step": 494}
{"Episode reward": 46.795543780307455, "Episode length": 841, "Policy Loss": -0.299518883228302, "Value Loss": 11.897590637207031, "_runtime": 4995.973074913025, "_timestamp": 1585602365.6059444, "_step": 495}
{"Episode reward": 76.23053740609606, "Episode length": 403, "Policy Loss": -0.11815622448921204, "Value Loss": 24.774446487426758, "_runtime": 4996.667106866837, "_timestamp": 1585602366.2999763, "_step": 496}
{"Episode reward": 72.80030484891739, "Episode length": 453, "Policy Loss": -0.1921631097793579, "Value Loss": 22.014114379882812, "_runtime": 4997.834356069565, "_timestamp": 1585602367.4672256, "_step": 497}
{"Episode reward": 52.15399730909331, "Episode length": 762, "Policy Loss": -0.27100133895874023, "Value Loss": 13.121191024780273, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375, -81.99609375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-63.65116882324219, -61.97121810913086, -60.29126739501953, -58.6113166809082, -56.931365966796875, -55.25141143798828, -53.57146453857422, -51.891510009765625, -50.2115592956543, -48.53160858154297, -46.85165786743164, -45.17170715332031, -43.491756439208984, -41.811805725097656, -40.13185119628906, -38.451904296875, -36.771949768066406, -35.092002868652344, -33.41204833984375, -31.732097625732422, -30.052146911621094, -28.372196197509766, -26.692245483398438, -25.01229476928711, -23.33234405517578, -21.652393341064453, -19.972442626953125, -18.29248809814453, -16.612537384033203, -14.932586669921875, -13.252635955810547, -11.572685241699219, -9.89273452758789, -8.212783813476562, -6.532833099365234, -4.852882385253906, -3.172931671142578, -1.49298095703125, 0.18697357177734375, 1.8669204711914062, 3.546875, 5.2268218994140625, 6.906776428222656, 8.58673095703125, 10.266677856445312, 11.946632385253906, 13.626579284667969, 15.306533813476562, 16.986480712890625, 18.66643524169922, 20.34638214111328, 22.026336669921875, 23.706283569335938, 25.38623809814453, 27.066192626953125, 28.746139526367188, 30.42609405517578, 32.106040954589844, 33.78599548339844, 35.4659423828125, 37.145896911621094, 38.825843811035156, 40.50579833984375, 42.18574523925781, 43.865699768066406]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-37.88692092895508, -36.6158561706543, -35.344791412353516, -34.073726654052734, -32.80266189575195, -31.531597137451172, -30.26053237915039, -28.98946762084961, -27.718402862548828, -26.447338104248047, -25.176273345947266, -23.905208587646484, -22.634143829345703, -21.363079071044922, -20.09201431274414, -18.82094955444336, -17.549884796142578, -16.278820037841797, -15.007755279541016, -13.736690521240234, -12.465625762939453, -11.194561004638672, -9.92349624633789, -8.65243148803711, -7.381366729736328, -6.110301971435547, -4.839237213134766, -3.5681724548339844, -2.297107696533203, -1.0260429382324219, 0.24502182006835938, 1.5160865783691406, 2.787151336669922, 4.058216094970703, 5.329280853271484, 6.600345611572266, 7.871410369873047, 9.142475128173828, 10.41353988647461, 11.68460464477539, 12.955669403076172, 14.226734161376953, 15.497798919677734, 16.768863677978516, 18.039928436279297, 19.310993194580078, 20.58205795288086, 21.85312271118164, 23.124187469482422, 24.395252227783203, 25.666316986083984, 26.937381744384766, 28.208446502685547, 29.479511260986328, 30.75057601928711, 32.02164077758789, 33.29270553588867, 34.56377029418945, 35.834835052490234, 37.105899810791016, 38.3769645690918, 39.64802932739258, 40.91909408569336, 42.19015884399414, 43.46122360229492]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 7.0, 8.0, 4.0, 7.0, 3.0, 5.0, 12.0, 8.0, 13.0, 12.0, 8.0, 18.0, 19.0, 10.0, 16.0, 20.0, 40.0, 41.0, 27.0, 33.0, 17.0, 15.0, 16.0, 16.0, 18.0, 11.0, 9.0, 11.0, 10.0, 10.0, 8.0, 5.0, 8.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-26.72012710571289, -25.823091506958008, -24.926055908203125, -24.029020309448242, -23.13198471069336, -22.234949111938477, -21.337913513183594, -20.440876007080078, -19.543842315673828, -18.646804809570312, -17.749771118164062, -16.852733612060547, -15.955698013305664, -15.058662414550781, -14.161626815795898, -13.264591217041016, -12.367555618286133, -11.47052001953125, -10.573484420776367, -9.676448822021484, -8.779413223266602, -7.882377624511719, -6.985342025756836, -6.088306427001953, -5.1912689208984375, -4.294233322143555, -3.397197723388672, -2.500162124633789, -1.6031265258789062, -0.7060909271240234, 0.19094467163085938, 1.0879802703857422, 1.985015869140625, 2.882051467895508, 3.7790870666503906, 4.676122665405273, 5.573158264160156, 6.470195770263672, 7.367229461669922, 8.264266967773438, 9.161300659179688, 10.058338165283203, 10.955371856689453, 11.852409362792969, 12.749443054199219, 13.646480560302734, 14.543514251708984, 15.4405517578125, 16.337589263916016, 17.234622955322266, 18.13166046142578, 19.02869415283203, 19.925731658935547, 20.822765350341797, 21.719802856445312, 22.616836547851562, 23.513874053955078, 24.410907745361328, 25.307945251464844, 26.204978942871094, 27.10201644897461, 27.99905014038086, 28.896087646484375, 29.793121337890625, 30.69015884399414]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-31.10224151611328, -29.833406448364258, -28.564571380615234, -27.29573631286621, -26.026901245117188, -24.758066177368164, -23.48923110961914, -22.220396041870117, -20.951560974121094, -19.68272590637207, -18.413890838623047, -17.145055770874023, -15.876220703125, -14.607385635375977, -13.338550567626953, -12.06971549987793, -10.800880432128906, -9.532045364379883, -8.26321029663086, -6.994375228881836, -5.7255401611328125, -4.456705093383789, -3.1878700256347656, -1.9190349578857422, -0.6501998901367188, 0.6186351776123047, 1.8874702453613281, 3.1563034057617188, 4.425140380859375, 5.693977355957031, 6.962810516357422, 8.231643676757812, 9.500480651855469, 10.769317626953125, 12.038150787353516, 13.306983947753906, 14.575820922851562, 15.844657897949219, 17.11349105834961, 18.38232421875, 19.651161193847656, 20.919998168945312, 22.188831329345703, 23.457664489746094, 24.72650146484375, 25.995338439941406, 27.264171600341797, 28.533004760742188, 29.801841735839844, 31.0706787109375, 32.33951187133789, 33.60834503173828, 34.87718200683594, 36.146018981933594, 37.41484832763672, 38.683685302734375, 39.95252227783203, 41.22135925292969, 42.490196228027344, 43.75902557373047, 45.027862548828125, 46.29669952392578, 47.565528869628906, 48.83436584472656, 50.10320281982422]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 32.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-26.566675186157227, -25.893529891967773, -25.220386505126953, -24.5472412109375, -23.874095916748047, -23.200950622558594, -22.527807235717773, -21.85466194152832, -21.1815185546875, -20.508373260498047, -19.835227966308594, -19.16208267211914, -18.48893928527832, -17.815793991088867, -17.142650604248047, -16.469505310058594, -15.79636001586914, -15.123215675354004, -14.45007038116455, -13.776926040649414, -13.103780746459961, -12.430636405944824, -11.757492065429688, -11.084346771240234, -10.411203384399414, -9.738058090209961, -9.064912796020508, -8.391767501831055, -7.718624114990234, -7.045478820800781, -6.372333526611328, -5.699190139770508, -5.026044845581055, -4.352899551391602, -3.6797561645507812, -3.006610870361328, -2.333465576171875, -1.6603221893310547, -0.9871768951416016, -0.31403160095214844, 0.3591136932373047, 1.032257080078125, 1.7054023742675781, 2.3785476684570312, 3.0516910552978516, 3.7248363494873047, 4.397981643676758, 5.071125030517578, 5.744268417358398, 6.417413711547852, 7.090559005737305, 7.763704299926758, 8.436849594116211, 9.109994888305664, 9.783140182495117, 10.456281661987305, 11.129426956176758, 11.802572250366211, 12.475717544555664, 13.148862838745117, 13.82200813293457, 14.495149612426758, 15.168294906616211, 15.841440200805664, 16.514585494995117]}, "_runtime": 4998.288273572922, "_timestamp": 1585602367.921143, "_step": 498}
{"Episode reward": 82.12603466072524, "Episode length": 296, "Policy Loss": 0.9359064102172852, "Value Loss": 33.647945404052734, "_runtime": 4998.288273572922, "_timestamp": 1585602367.921143, "_step": 499}
