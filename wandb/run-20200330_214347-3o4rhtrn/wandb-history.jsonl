{"Episode reward": -48.3272747782682, "Episode length": 999, "Policy Loss": -0.033794596791267395, "Value Loss": 0.05671610310673714, "_runtime": 7276.656661987305, "_timestamp": 1585604646.2895315, "_step": 0}
{"Episode reward": -89.07700223277084, "Episode length": 999, "Policy Loss": 0.01344597153365612, "Value Loss": 2.8795852661132812, "_runtime": 7277.842063188553, "_timestamp": 1585604647.4749327, "_step": 1}
{"Episode reward": 24.706625864466744, "Episode length": 806, "Policy Loss": 0.25914859771728516, "Value Loss": 43.16071319580078, "_runtime": 7279.4148190021515, "_timestamp": 1585604649.0476885, "_step": 2}
{"Episode reward": -96.0672124226684, "Episode length": 999, "Policy Loss": -0.44051358103752136, "Value Loss": 380.2546081542969, "_runtime": 7280.776291131973, "_timestamp": 1585604650.4091606, "_step": 3}
{"Episode reward": 14.676342705632507, "Episode length": 883, "Policy Loss": 1.0896475315093994, "Value Loss": 207.88211059570312, "_runtime": 7282.141138792038, "_timestamp": 1585604651.7740083, "_step": 4}
{"Episode reward": 12.908016760446898, "Episode length": 897, "Policy Loss": 1.6565767526626587, "Value Loss": 42.85558319091797, "_runtime": 7283.1877982616425, "_timestamp": 1585604652.8206677, "_step": 5}
{"Episode reward": 35.879729929418176, "Episode length": 654, "Policy Loss": 1.0698695182800293, "Value Loss": 23.922258377075195, "_runtime": 7284.7883903980255, "_timestamp": 1585604654.4212599, "_step": 6}
{"Episode reward": -98.10113804169134, "Episode length": 999, "Policy Loss": -0.5901214480400085, "Value Loss": 6.284163475036621, "_runtime": 7286.327968835831, "_timestamp": 1585604655.9608383, "_step": 7}
{"Episode reward": -97.64983998902947, "Episode length": 999, "Policy Loss": -0.8575648069381714, "Value Loss": 37.71432876586914, "_runtime": 7286.860710859299, "_timestamp": 1585604656.4935803, "_step": 8}
{"Episode reward": 67.93930584689494, "Episode length": 330, "Policy Loss": -0.44256699085235596, "Value Loss": 42.07661437988281, "_runtime": 7288.395918369293, "_timestamp": 1585604658.0287879, "_step": 9}
{"Episode reward": 4.757395277399922, "Episode length": 973, "Policy Loss": -2.0295989513397217, "Value Loss": 110.99076080322266, "_runtime": 7289.9576206207275, "_timestamp": 1585604659.59049, "_step": 10}
{"Episode reward": -98.4342420165297, "Episode length": 999, "Policy Loss": -1.2929563522338867, "Value Loss": 2.827148914337158, "_runtime": 7291.228399753571, "_timestamp": 1585604660.8612692, "_step": 11}
{"Episode reward": 17.40808877843193, "Episode length": 843, "Policy Loss": 0.018627777695655823, "Value Loss": 47.84223175048828, "_runtime": 7292.822152137756, "_timestamp": 1585604662.4550216, "_step": 12}
{"Episode reward": -98.09312063410651, "Episode length": 999, "Policy Loss": -0.04175829142332077, "Value Loss": 36.70888137817383, "_runtime": 7294.394204378128, "_timestamp": 1585604664.0270739, "_step": 13}
{"Episode reward": -98.39544700715543, "Episode length": 999, "Policy Loss": 0.20381414890289307, "Value Loss": 8.667046546936035, "_runtime": 7295.942374944687, "_timestamp": 1585604665.5752444, "_step": 14}
{"Episode reward": -98.00733383600264, "Episode length": 999, "Policy Loss": 0.9286208748817444, "Value Loss": 19.14426040649414, "_runtime": 7297.53954076767, "_timestamp": 1585604667.1724102, "_step": 15}
{"Episode reward": -98.13548288794982, "Episode length": 999, "Policy Loss": 1.3039419651031494, "Value Loss": 3.699084520339966, "_runtime": 7297.958838701248, "_timestamp": 1585604667.5917082, "_step": 16}
{"Episode reward": 78.00842569774511, "Episode length": 232, "Policy Loss": 2.326467275619507, "Value Loss": 62.244956970214844, "_runtime": 7299.520930290222, "_timestamp": 1585604669.1537998, "_step": 17}
{"Episode reward": -97.66017566256379, "Episode length": 999, "Policy Loss": 1.424526333808899, "Value Loss": 1.7057816982269287, "_runtime": 7301.111205339432, "_timestamp": 1585604670.7440748, "_step": 18}
{"Episode reward": -94.64615927149204, "Episode length": 999, "Policy Loss": 2.07899808883667, "Value Loss": 7.472698211669922, "_runtime": 7302.617407798767, "_timestamp": 1585604672.2502773, "_step": 19}
{"Episode reward": -96.53054844174959, "Episode length": 999, "Policy Loss": -1.9733836650848389, "Value Loss": 53.6931037902832, "_runtime": 7304.193284988403, "_timestamp": 1585604673.8261545, "_step": 20}
{"Episode reward": -97.84262651634215, "Episode length": 999, "Policy Loss": 1.0793583393096924, "Value Loss": 4.744497776031494, "_runtime": 7305.7871906757355, "_timestamp": 1585604675.4200602, "_step": 21}
{"Episode reward": -97.71181933090618, "Episode length": 999, "Policy Loss": 1.9344885349273682, "Value Loss": 20.4254093170166, "_runtime": 7307.37913441658, "_timestamp": 1585604677.012004, "_step": 22}
{"Episode reward": -98.41602135098924, "Episode length": 999, "Policy Loss": 0.43457695841789246, "Value Loss": 2.0719707012176514, "_runtime": 7308.629714012146, "_timestamp": 1585604678.2625835, "_step": 23}
{"Episode reward": 22.191686125697785, "Episode length": 788, "Policy Loss": 1.3730922937393188, "Value Loss": 19.092409133911133, "_runtime": 7310.215211868286, "_timestamp": 1585604679.8480814, "_step": 24}
{"Episode reward": -99.10385558783976, "Episode length": 999, "Policy Loss": 0.7670726180076599, "Value Loss": 9.406251907348633, "_runtime": 7311.791546344757, "_timestamp": 1585604681.4244158, "_step": 25}
{"Episode reward": -99.01428708653376, "Episode length": 999, "Policy Loss": 0.874809741973877, "Value Loss": 32.783233642578125, "_runtime": 7312.877767801285, "_timestamp": 1585604682.5106373, "_step": 26}
{"Episode reward": 31.86188535159414, "Episode length": 686, "Policy Loss": 1.1162140369415283, "Value Loss": 29.985912322998047, "_runtime": 7314.468562602997, "_timestamp": 1585604684.101432, "_step": 27}
{"Episode reward": -99.21523726055757, "Episode length": 999, "Policy Loss": 0.13871149718761444, "Value Loss": 2.9204771518707275, "_runtime": 7316.048622846603, "_timestamp": 1585604685.6814923, "_step": 28}
{"Episode reward": -99.40460953832233, "Episode length": 999, "Policy Loss": -0.40469691157341003, "Value Loss": 0.6189182996749878, "_runtime": 7316.822345018387, "_timestamp": 1585604686.4552145, "_step": 29}
{"Episode reward": 50.98425457751395, "Episode length": 494, "Policy Loss": 0.17133286595344543, "Value Loss": 27.0867862701416, "_runtime": 7318.401444911957, "_timestamp": 1585604688.0343144, "_step": 30}
{"Episode reward": -99.42696362806173, "Episode length": 999, "Policy Loss": -1.2920321226119995, "Value Loss": 0.6119604706764221, "_runtime": 7319.972773551941, "_timestamp": 1585604689.605643, "_step": 31}
{"Episode reward": 0.38891040901064855, "Episode length": 998, "Policy Loss": -0.9103162884712219, "Value Loss": 12.49609088897705, "_runtime": 7320.856260061264, "_timestamp": 1585604690.4891295, "_step": 32}
{"Episode reward": 43.563031686724045, "Episode length": 567, "Policy Loss": -0.4891931712627411, "Value Loss": 20.586027145385742, "_runtime": 7322.434079885483, "_timestamp": 1585604692.0669494, "_step": 33}
{"Episode reward": -99.7017883945257, "Episode length": 999, "Policy Loss": -1.4320846796035767, "Value Loss": 0.21403896808624268, "_runtime": 7324.0050666332245, "_timestamp": 1585604693.637936, "_step": 34}
{"Episode reward": -99.47970664564646, "Episode length": 999, "Policy Loss": -1.2717807292938232, "Value Loss": 0.1827680915594101, "_runtime": 7324.502510070801, "_timestamp": 1585604694.1353796, "_step": 35}
{"Episode reward": 69.95297360674579, "Episode length": 304, "Policy Loss": 0.7100794315338135, "Value Loss": 32.23443603515625, "_runtime": 7325.293407201767, "_timestamp": 1585604694.9262767, "_step": 36}
{"Episode reward": 51.256534824864815, "Episode length": 491, "Policy Loss": 0.28102463483810425, "Value Loss": 20.838701248168945, "_runtime": 7326.872239589691, "_timestamp": 1585604696.505109, "_step": 37}
{"Episode reward": -99.06612726603062, "Episode length": 999, "Policy Loss": -0.8772315979003906, "Value Loss": 0.37231072783470154, "_runtime": 7328.385758638382, "_timestamp": 1585604698.0186281, "_step": 38}
{"Episode reward": -99.69206681795191, "Episode length": 999, "Policy Loss": -0.7686907649040222, "Value Loss": 0.7460176348686218, "_runtime": 7329.014980316162, "_timestamp": 1585604698.6478498, "_step": 39}
{"Episode reward": 61.153594196712675, "Episode length": 396, "Policy Loss": 0.5192321538925171, "Value Loss": 25.23211669921875, "_runtime": 7330.5979261398315, "_timestamp": 1585604700.2307956, "_step": 40}
{"Episode reward": -99.30166573156758, "Episode length": 999, "Policy Loss": -0.6420191526412964, "Value Loss": 0.22284334897994995, "_runtime": 7332.2053344249725, "_timestamp": 1585604701.838204, "_step": 41}
{"Episode reward": -99.32162320871147, "Episode length": 999, "Policy Loss": -0.6376380324363708, "Value Loss": 0.09181573987007141, "_runtime": 7333.512901306152, "_timestamp": 1585604703.1457708, "_step": 42}
{"Episode reward": 14.215422352107154, "Episode length": 861, "Policy Loss": -0.037632569670677185, "Value Loss": 12.284449577331543, "_runtime": 7335.0896780490875, "_timestamp": 1585604704.7225475, "_step": 43}
{"Episode reward": -99.57526808484845, "Episode length": 999, "Policy Loss": -0.621462345123291, "Value Loss": 0.4969002604484558, "_runtime": 7336.2691655159, "_timestamp": 1585604705.902035, "_step": 44}
{"Episode reward": 25.26283848864547, "Episode length": 750, "Policy Loss": -0.10108936578035355, "Value Loss": 16.42262840270996, "_runtime": 7336.983712673187, "_timestamp": 1585604706.6165822, "_step": 45}
{"Episode reward": 55.87309599248367, "Episode length": 444, "Policy Loss": 1.331619381904602, "Value Loss": 23.66873550415039, "_runtime": 7337.636262178421, "_timestamp": 1585604707.2691317, "_step": 46}
{"Episode reward": 61.10826661591973, "Episode length": 392, "Policy Loss": 0.7655357718467712, "Value Loss": 25.608083724975586, "_runtime": 7339.19350194931, "_timestamp": 1585604708.8263714, "_step": 47}
{"Episode reward": -99.58018854170811, "Episode length": 999, "Policy Loss": -0.5404644012451172, "Value Loss": 0.4553065001964569, "_runtime": 7340.7265520095825, "_timestamp": 1585604710.3594215, "_step": 48}
{"Episode reward": -99.39262803463943, "Episode length": 999, "Policy Loss": -0.4679408073425293, "Value Loss": 1.026371955871582, "_runtime": 7342.246656417847, "_timestamp": 1585604711.879526, "_step": 49}
{"Episode reward": -99.18701208886642, "Episode length": 999, "Policy Loss": -0.656038761138916, "Value Loss": 1.4949944019317627, "_runtime": 7343.83159160614, "_timestamp": 1585604713.464461, "_step": 50}
{"Episode reward": -99.53296703323876, "Episode length": 999, "Policy Loss": -0.5198807716369629, "Value Loss": 2.1557817459106445, "_runtime": 7345.407160282135, "_timestamp": 1585604715.0400298, "_step": 51}
{"Episode reward": -99.19630911950672, "Episode length": 999, "Policy Loss": -0.6956081390380859, "Value Loss": 0.8224284052848816, "_runtime": 7346.285577058792, "_timestamp": 1585604715.9184465, "_step": 52}
{"Episode reward": 45.66036361428365, "Episode length": 545, "Policy Loss": 0.14876702427864075, "Value Loss": 18.522586822509766, "_runtime": 7347.867402791977, "_timestamp": 1585604717.5002723, "_step": 53}
{"Episode reward": -99.36240689860142, "Episode length": 999, "Policy Loss": -1.0393900871276855, "Value Loss": 0.16781601309776306, "_runtime": 7349.4542100429535, "_timestamp": 1585604719.0870795, "_step": 54}
{"Episode reward": -99.07395553256657, "Episode length": 999, "Policy Loss": -1.1269266605377197, "Value Loss": 0.11308588087558746, "_runtime": 7350.994029045105, "_timestamp": 1585604720.6268985, "_step": 55}
{"Episode reward": -99.10429397580494, "Episode length": 999, "Policy Loss": -1.203802466392517, "Value Loss": 0.1827898621559143, "_runtime": 7352.568252801895, "_timestamp": 1585604722.2011223, "_step": 56}
{"Episode reward": -99.21222469253854, "Episode length": 999, "Policy Loss": -1.332411766052246, "Value Loss": 0.12650129199028015, "_runtime": 7354.157322883606, "_timestamp": 1585604723.7901924, "_step": 57}
{"Episode reward": -99.52535824513042, "Episode length": 999, "Policy Loss": -1.401774287223816, "Value Loss": 0.10751841962337494, "_runtime": 7355.75923871994, "_timestamp": 1585604725.3921082, "_step": 58}
{"Episode reward": -99.28422139173354, "Episode length": 999, "Policy Loss": -1.497709035873413, "Value Loss": 0.21263821423053741, "_runtime": 7357.3478853702545, "_timestamp": 1585604726.9807549, "_step": 59}
{"Episode reward": -99.48464502925789, "Episode length": 999, "Policy Loss": -1.5678156614303589, "Value Loss": 0.3218995928764343, "_runtime": 7358.942069768906, "_timestamp": 1585604728.5749393, "_step": 60}
{"Episode reward": -99.26989140282977, "Episode length": 999, "Policy Loss": -1.544803261756897, "Value Loss": 0.19829204678535461, "_runtime": 7360.524907588959, "_timestamp": 1585604730.157777, "_step": 61}
{"Episode reward": -99.70399982536334, "Episode length": 999, "Policy Loss": -1.6150860786437988, "Value Loss": 0.398946076631546, "_runtime": 7362.115191459656, "_timestamp": 1585604731.748061, "_step": 62}
{"Episode reward": -99.33982644471698, "Episode length": 999, "Policy Loss": -1.5794044733047485, "Value Loss": 0.15465900301933289, "_runtime": 7363.546952486038, "_timestamp": 1585604733.179822, "_step": 63}
{"Episode reward": 10.714656197620997, "Episode length": 899, "Policy Loss": -1.0385059118270874, "Value Loss": 11.798820495605469, "_runtime": 7364.43282699585, "_timestamp": 1585604734.0656965, "_step": 64}
{"Episode reward": 46.062487824599756, "Episode length": 544, "Policy Loss": -0.6541471481323242, "Value Loss": 18.96556854248047, "_runtime": 7365.743653535843, "_timestamp": 1585604735.376523, "_step": 65}
{"Episode reward": 17.5132174021321, "Episode length": 826, "Policy Loss": -0.8602898716926575, "Value Loss": 12.15258502960205, "_runtime": 7367.322025775909, "_timestamp": 1585604736.9548953, "_step": 66}
{"Episode reward": -99.80866125366889, "Episode length": 999, "Policy Loss": -1.4309818744659424, "Value Loss": 0.08824586868286133, "_runtime": 7368.858761310577, "_timestamp": 1585604738.4916308, "_step": 67}
{"Episode reward": -99.31991978080634, "Episode length": 999, "Policy Loss": -1.3648921251296997, "Value Loss": 0.1816595196723938, "_runtime": 7370.421085357666, "_timestamp": 1585604740.0539548, "_step": 68}
{"Episode reward": -99.38490358708087, "Episode length": 999, "Policy Loss": -1.3614377975463867, "Value Loss": 0.12819969654083252, "_runtime": 7371.3647384643555, "_timestamp": 1585604740.997608, "_step": 69}
{"Episode reward": 41.39975413271257, "Episode length": 591, "Policy Loss": -0.3600858747959137, "Value Loss": 16.519329071044922, "_runtime": 7372.941958665848, "_timestamp": 1585604742.5748281, "_step": 70}
{"Episode reward": -99.26261266451047, "Episode length": 999, "Policy Loss": -1.2290643453598022, "Value Loss": 0.3908042907714844, "_runtime": 7374.527576446533, "_timestamp": 1585604744.160446, "_step": 71}
{"Episode reward": -99.36787336565476, "Episode length": 999, "Policy Loss": -1.2189757823944092, "Value Loss": 0.24019373953342438, "_runtime": 7376.072847604752, "_timestamp": 1585604745.705717, "_step": 72}
{"Episode reward": -99.5911108646659, "Episode length": 999, "Policy Loss": -1.224256157875061, "Value Loss": 0.6054099202156067, "_runtime": 7377.087960243225, "_timestamp": 1585604746.7208297, "_step": 73}
{"Episode reward": 36.98823965084095, "Episode length": 631, "Policy Loss": -0.4012768566608429, "Value Loss": 15.870810508728027, "_runtime": 7378.688374996185, "_timestamp": 1585604748.3212445, "_step": 74}
{"Episode reward": -99.52978406361515, "Episode length": 999, "Policy Loss": -1.2821879386901855, "Value Loss": 0.13341712951660156, "_runtime": 7380.261658668518, "_timestamp": 1585604749.8945282, "_step": 75}
{"Episode reward": -99.12672201193647, "Episode length": 999, "Policy Loss": -1.3270143270492554, "Value Loss": 0.09652678668498993, "_runtime": 7381.810384273529, "_timestamp": 1585604751.4432538, "_step": 76}
{"Episode reward": -99.30326538161034, "Episode length": 999, "Policy Loss": -1.2976555824279785, "Value Loss": 0.20043690502643585, "_runtime": 7383.387518167496, "_timestamp": 1585604753.0203876, "_step": 77}
{"Episode reward": -99.24046838300575, "Episode length": 999, "Policy Loss": -1.3485260009765625, "Value Loss": 0.13786132633686066, "_runtime": 7384.667951822281, "_timestamp": 1585604754.3008213, "_step": 78}
{"Episode reward": 19.745091267000234, "Episode length": 804, "Policy Loss": -0.6930636167526245, "Value Loss": 12.570175170898438, "_runtime": 7386.052802801132, "_timestamp": 1585604755.6856723, "_step": 79}
{"Episode reward": 12.212611149899743, "Episode length": 882, "Policy Loss": -0.5733293890953064, "Value Loss": 11.702873229980469, "_runtime": 7386.595777511597, "_timestamp": 1585604756.228647, "_step": 80}
{"Episode reward": 68.48413358898235, "Episode length": 317, "Policy Loss": 0.5498619079589844, "Value Loss": 31.7252197265625, "_runtime": 7388.158916950226, "_timestamp": 1585604757.7917864, "_step": 81}
{"Episode reward": -99.18574210853123, "Episode length": 999, "Policy Loss": -1.1037039756774902, "Value Loss": 0.10258869081735611, "_runtime": 7388.810750961304, "_timestamp": 1585604758.4436204, "_step": 82}
{"Episode reward": 61.229062205912214, "Episode length": 392, "Policy Loss": 0.3464885950088501, "Value Loss": 25.234302520751953, "_runtime": 7390.330549955368, "_timestamp": 1585604759.9634194, "_step": 83}
{"Episode reward": -99.3827769560842, "Episode length": 999, "Policy Loss": -0.8581559658050537, "Value Loss": 0.06335856765508652, "_runtime": 7391.364780664444, "_timestamp": 1585604760.9976501, "_step": 84}
{"Episode reward": 36.816886133074256, "Episode length": 640, "Policy Loss": 0.10376033931970596, "Value Loss": 15.366975784301758, "_runtime": 7392.888757944107, "_timestamp": 1585604762.5216274, "_step": 85}
{"Episode reward": -99.69963272269823, "Episode length": 999, "Policy Loss": -0.6367813348770142, "Value Loss": 0.045792412012815475, "_runtime": 7394.467652797699, "_timestamp": 1585604764.1005223, "_step": 86}
{"Episode reward": -99.55485639835248, "Episode length": 999, "Policy Loss": -0.5151193141937256, "Value Loss": 0.051243338733911514, "_runtime": 7395.769955158234, "_timestamp": 1585604765.4028246, "_step": 87}
{"Episode reward": 16.450507988878712, "Episode length": 837, "Policy Loss": 0.20747147500514984, "Value Loss": 11.953521728515625, "_runtime": 7396.849977970123, "_timestamp": 1585604766.4828475, "_step": 88}
{"Episode reward": 31.819158880748333, "Episode length": 686, "Policy Loss": 0.33515602350234985, "Value Loss": 14.459282875061035, "_runtime": 7397.838495731354, "_timestamp": 1585604767.4713652, "_step": 89}
{"Episode reward": 38.45491741326927, "Episode length": 618, "Policy Loss": 0.5181609392166138, "Value Loss": 16.25934600830078, "_runtime": 7399.344627857208, "_timestamp": 1585604768.9774973, "_step": 90}
{"Episode reward": 4.028805737872318, "Episode length": 965, "Policy Loss": 0.1982872188091278, "Value Loss": 10.250317573547363, "_runtime": 7400.896871805191, "_timestamp": 1585604770.5297413, "_step": 91}
{"Episode reward": -99.56752867541952, "Episode length": 999, "Policy Loss": -0.37110841274261475, "Value Loss": 0.01898794434964657, "_runtime": 7401.48077583313, "_timestamp": 1585604771.1136453, "_step": 92}
{"Episode reward": 64.03566227651294, "Episode length": 361, "Policy Loss": 1.0017940998077393, "Value Loss": 27.082509994506836, "_runtime": 7402.402612686157, "_timestamp": 1585604772.0354822, "_step": 93}
{"Episode reward": 42.01583041178765, "Episode length": 583, "Policy Loss": 1.3099766969680786, "Value Loss": 16.76287078857422, "_runtime": 7403.993522882462, "_timestamp": 1585604773.6263924, "_step": 94}
{"Episode reward": -99.34519871703387, "Episode length": 999, "Policy Loss": -0.38617995381355286, "Value Loss": 0.10749296844005585, "_runtime": 7405.510850906372, "_timestamp": 1585604775.1437204, "_step": 95}
{"Episode reward": -99.57902249251644, "Episode length": 999, "Policy Loss": -0.4366356134414673, "Value Loss": 0.03772348910570145, "_runtime": 7406.217399358749, "_timestamp": 1585604775.8502688, "_step": 96}
{"Episode reward": 55.49730910057516, "Episode length": 446, "Policy Loss": 0.7366757392883301, "Value Loss": 21.962696075439453, "_runtime": 7406.973613500595, "_timestamp": 1585604776.606483, "_step": 97}
{"Episode reward": 53.63213041482048, "Episode length": 469, "Policy Loss": 0.6904829144477844, "Value Loss": 20.925464630126953, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634, 1.8207441568374634]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.8207619190216064, -1.3802675008773804, -0.9397730827331543, -0.4992786645889282, -0.05878424644470215, 0.3817102909088135, 0.82220458984375, 1.2626988887786865, 1.7031934261322021, 2.1436879634857178, 2.5841825008392334, 3.024676561355591, 3.4651710987091064, 3.905665636062622, 4.346159934997559, 4.786654472351074, 5.22714900970459, 5.6676435470581055, 6.108138084411621, 6.548632621765137, 6.989127159118652, 7.429620742797852, 7.870115280151367, 8.310609817504883, 8.751104354858398, 9.191598892211914, 9.63209342956543, 10.072587966918945, 10.513081550598145, 10.95357608795166, 11.394070625305176, 11.834565162658691, 12.275059700012207, 12.715554237365723, 13.156048774719238, 13.596543312072754, 14.03703784942627, 14.477532386779785, 14.9180269241333, 15.358521461486816, 15.799015998840332, 16.2395076751709, 16.680002212524414, 17.12049674987793, 17.560991287231445, 18.00148582458496, 18.441980361938477, 18.882474899291992, 19.322969436645508, 19.763463973999023, 20.20395851135254, 20.644453048706055, 21.08494758605957, 21.525442123413086, 21.9659366607666, 22.406431198120117, 22.846923828125, 23.287418365478516, 23.72791290283203, 24.168407440185547, 24.608901977539062, 25.049396514892578, 25.489891052246094, 25.93038558959961, 26.370880126953125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.457993772026384e-08, 0.04106364771723747, 0.08212738484144211, 0.12319111824035645, 0.16425484418869019, 0.20531857013702393, 0.24638231098651886, 0.2874460518360138, 0.32850977778434753, 0.3695735037326813, 0.410637229681015, 0.45170098543167114, 0.4927647113800049, 0.5338284969329834, 0.5748922228813171, 0.6159559488296509, 0.6570196747779846, 0.6980834007263184, 0.7391471266746521, 0.7802108526229858, 0.8212745785713196, 0.8623383641242981, 0.9034020900726318, 0.9444658160209656, 0.9855295419692993, 1.0265932083129883, 1.0676569938659668, 1.1087206602096558, 1.1497844457626343, 1.1908481121063232, 1.2319118976593018, 1.2729755640029907, 1.3140393495559692, 1.3551031351089478, 1.3961668014526367, 1.4372305870056152, 1.4782942533493042, 1.5193580389022827, 1.5604217052459717, 1.6014854907989502, 1.6425491571426392, 1.6836129426956177, 1.7246767282485962, 1.7657403945922852, 1.8068041801452637, 1.8478678464889526, 1.8889316320419312, 1.9299952983856201, 1.9710590839385986, 2.012122869491577, 2.0531866550445557, 2.094250440597534, 2.1353142261505127, 2.176377773284912, 2.2174415588378906, 2.258505344390869, 2.2995691299438477, 2.340632915496826, 2.3816964626312256, 2.422760248184204, 2.4638240337371826, 2.504887819290161, 2.5459513664245605, 2.587015151977539, 2.6280789375305176]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 3.0, 1.0, 2.0, 6.0, 3.0, 12.0, 9.0, 8.0, 9.0, 8.0, 6.0, 5.0, 2.0, 8.0, 5.0, 4.0, 1.0, 0.0, 0.0, 320.0, 1.0, 0.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.965319275856018, -1.867743968963623, -1.7701687812805176, -1.672593593597412, -1.575018286705017, -1.477442979812622, -1.3798677921295166, -1.2822926044464111, -1.1847172975540161, -1.087141990661621, -0.9895668029785156, -0.8919914960861206, -0.7944163084030151, -0.6968411207199097, -0.5992658138275146, -0.5016905069351196, -0.40411531925201416, -0.3065401315689087, -0.20896482467651367, -0.11138951778411865, -0.013814330101013184, 0.08376085758209229, 0.18133628368377686, 0.2789114713668823, 0.3764866590499878, 0.47406184673309326, 0.5716370344161987, 0.6692124605178833, 0.7667876482009888, 0.8643628358840942, 0.9619382619857788, 1.0595134496688843, 1.1570886373519897, 1.2546638250350952, 1.3522390127182007, 1.4498144388198853, 1.5473896265029907, 1.6449648141860962, 1.7425402402877808, 1.8401154279708862, 1.9376906156539917, 2.0352659225463867, 2.132841110229492, 2.2304162979125977, 2.3279919624328613, 2.425567150115967, 2.5231423377990723, 2.6207175254821777, 2.718292713165283, 2.8158679008483887, 2.913443088531494, 3.0110182762145996, 3.108593463897705, 3.2061691284179688, 3.303744316101074, 3.4013195037841797, 3.498894691467285, 3.5964698791503906, 3.694045066833496, 3.7916202545166016, 3.8891959190368652, 3.9867711067199707, 4.084346294403076, 4.181921482086182, 4.279496669769287]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0], "bins": [-8.341266632080078, -8.016357421875, -7.691448211669922, -7.366539001464844, -7.041630268096924, -6.716721057891846, -6.391811847686768, -6.066903114318848, -5.7419939041137695, -5.417084693908691, -5.092175483703613, -4.767266273498535, -4.442357063293457, -4.117447853088379, -3.792539119720459, -3.467629909515381, -3.1427206993103027, -2.8178114891052246, -2.4929022789001465, -2.1679935455322266, -1.8430843353271484, -1.5181751251220703, -1.1932659149169922, -0.8683567047119141, -0.5434474945068359, -0.2185382843017578, 0.10637092590332031, 0.43127918243408203, 0.7561883926391602, 1.0810976028442383, 1.4060068130493164, 1.7309160232543945, 2.0558252334594727, 2.380734443664551, 2.705643653869629, 3.030552864074707, 3.355462074279785, 3.6803712844848633, 4.005279541015625, 4.330188751220703, 4.655097961425781, 4.980007171630859, 5.3049163818359375, 5.629825592041016, 5.954734802246094, 6.279644012451172, 6.60455322265625, 6.929462432861328, 7.254371643066406, 7.579279899597168, 7.9041900634765625, 8.22909927368164, 8.554008483886719, 8.878917694091797, 9.203824996948242, 9.52873420715332, 9.853643417358398, 10.178552627563477, 10.503461837768555, 10.828371047973633, 11.153280258178711, 11.478189468383789, 11.803098678588867, 12.128007888793945, 12.452917098999023]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 7.0, 6.0, 4.0, 7.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 5.0, 3.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.8534374237060547, -1.803328514099121, -1.7532196044921875, -1.703110694885254, -1.6530017852783203, -1.6028928756713867, -1.5527838468551636, -1.50267493724823, -1.4525660276412964, -1.4024571180343628, -1.3523482084274292, -1.302239179611206, -1.2521302700042725, -1.2020213603973389, -1.1519124507904053, -1.1018035411834717, -1.051694631576538, -1.0015857219696045, -0.9514768123626709, -0.9013678431510925, -0.8512589931488037, -0.8011499643325806, -0.751041054725647, -0.7009321451187134, -0.6508232355117798, -0.6007143259048462, -0.5506054162979126, -0.500496506690979, -0.45038747787475586, -0.40027856826782227, -0.35016965866088867, -0.3000607490539551, -0.24995183944702148, -0.1998429298400879, -0.1497340202331543, -0.0996251106262207, -0.04951620101928711, 0.0005928277969360352, 0.05070173740386963, 0.10081064701080322, 0.15091943740844727, 0.20102858543395996, 0.25113749504089355, 0.30124640464782715, 0.35135531425476074, 0.40146422386169434, 0.45157313346862793, 0.5016820430755615, 0.5517909526824951, 0.6018998622894287, 0.6520087718963623, 0.7021176815032959, 0.7522265911102295, 0.8023355007171631, 0.8524444103240967, 0.9025533199310303, 0.952662467956543, 1.0027713775634766, 1.0528802871704102, 1.1029891967773438, 1.1530981063842773, 1.203207015991211, 1.2533159255981445, 1.3034248352050781, 1.3535337448120117]}, "_runtime": 7408.443759202957, "_timestamp": 1585604778.0766287, "_step": 98}
{"Episode reward": 5.161050432335131, "Episode length": 955, "Policy Loss": 0.1269737035036087, "Value Loss": 10.3556547164917, "_runtime": 7409.9084503650665, "_timestamp": 1585604779.5413198, "_step": 99}
{"Episode reward": 4.836113032370889, "Episode length": 956, "Policy Loss": 0.09616930037736893, "Value Loss": 10.241166114807129, "_runtime": 7411.37061715126, "_timestamp": 1585604781.0034866, "_step": 100}
{"Episode reward": 5.070846190409455, "Episode length": 957, "Policy Loss": 0.24009348452091217, "Value Loss": 10.378654479980469, "_runtime": 7412.929105520248, "_timestamp": 1585604782.561975, "_step": 101}
{"Episode reward": -99.4287399924754, "Episode length": 999, "Policy Loss": -0.4320206046104431, "Value Loss": 0.030511585995554924, "_runtime": 7414.500772237778, "_timestamp": 1585604784.1336417, "_step": 102}
{"Episode reward": -99.54794019216213, "Episode length": 999, "Policy Loss": -0.4290553033351898, "Value Loss": 0.044332362711429596, "_runtime": 7416.068508863449, "_timestamp": 1585604785.7013783, "_step": 103}
{"Episode reward": -99.48281316909711, "Episode length": 999, "Policy Loss": -0.41565051674842834, "Value Loss": 0.052382055670022964, "_runtime": 7417.6380734443665, "_timestamp": 1585604787.270943, "_step": 104}
{"Episode reward": -99.37826236871341, "Episode length": 999, "Policy Loss": -0.4079212546348572, "Value Loss": 0.0897013321518898, "_runtime": 7418.559668540955, "_timestamp": 1585604788.192538, "_step": 105}
{"Episode reward": 43.32302886466006, "Episode length": 572, "Policy Loss": 1.0391608476638794, "Value Loss": 17.284442901611328, "_runtime": 7420.124601840973, "_timestamp": 1585604789.7574713, "_step": 106}
{"Episode reward": -99.45570071761185, "Episode length": 999, "Policy Loss": -0.45588749647140503, "Value Loss": 0.041020337492227554, "_runtime": 7421.708181619644, "_timestamp": 1585604791.341051, "_step": 107}
{"Episode reward": -99.60083002123146, "Episode length": 999, "Policy Loss": -0.4801557958126068, "Value Loss": 0.024145582690835, "_runtime": 7423.249825954437, "_timestamp": 1585604792.8826954, "_step": 108}
{"Episode reward": -99.58119548554686, "Episode length": 999, "Policy Loss": -0.43379294872283936, "Value Loss": 0.08888158947229385, "_runtime": 7424.264037847519, "_timestamp": 1585604793.8969073, "_step": 109}
{"Episode reward": 37.148652163042534, "Episode length": 630, "Policy Loss": 0.3668910562992096, "Value Loss": 15.543581008911133, "_runtime": 7425.841435432434, "_timestamp": 1585604795.474305, "_step": 110}
{"Episode reward": -99.55224715116792, "Episode length": 999, "Policy Loss": -0.46632879972457886, "Value Loss": 0.07994958758354187, "_runtime": 7427.456724643707, "_timestamp": 1585604797.0895941, "_step": 111}
{"Episode reward": -99.1458121560093, "Episode length": 999, "Policy Loss": -0.5017750263214111, "Value Loss": 0.014156914316117764, "_runtime": 7428.440868616104, "_timestamp": 1585604798.073738, "_step": 112}
{"Episode reward": 37.64102826292449, "Episode length": 626, "Policy Loss": 0.5077488422393799, "Value Loss": 15.699836730957031, "_runtime": 7429.497988462448, "_timestamp": 1585604799.130858, "_step": 113}
{"Episode reward": 32.813906212598795, "Episode length": 673, "Policy Loss": 0.40171507000923157, "Value Loss": 14.622698783874512, "_runtime": 7430.377493858337, "_timestamp": 1585604800.0103633, "_step": 114}
{"Episode reward": 45.714442508041486, "Episode length": 548, "Policy Loss": 0.46128129959106445, "Value Loss": 17.91820526123047, "_runtime": 7431.927677869797, "_timestamp": 1585604801.5605474, "_step": 115}
{"Episode reward": -99.53869967974614, "Episode length": 999, "Policy Loss": -0.49835309386253357, "Value Loss": 0.07448907941579819, "_runtime": 7433.471427679062, "_timestamp": 1585604803.1042972, "_step": 116}
{"Episode reward": -99.68130935341476, "Episode length": 999, "Policy Loss": -0.48261260986328125, "Value Loss": 0.15981975197792053, "_runtime": 7435.009695291519, "_timestamp": 1585604804.6425648, "_step": 117}
{"Episode reward": -99.34026463351192, "Episode length": 999, "Policy Loss": -0.4848877489566803, "Value Loss": 0.03678349778056145, "_runtime": 7436.574984788895, "_timestamp": 1585604806.2078543, "_step": 118}
{"Episode reward": -99.61329979269512, "Episode length": 999, "Policy Loss": -0.5068024396896362, "Value Loss": 0.009694942273199558, "_runtime": 7438.154632568359, "_timestamp": 1585604807.787502, "_step": 119}
{"Episode reward": -99.52698810804148, "Episode length": 999, "Policy Loss": -0.5103996992111206, "Value Loss": 0.024930695071816444, "_runtime": 7438.986645698547, "_timestamp": 1585604808.6195152, "_step": 120}
{"Episode reward": 48.79796451375979, "Episode length": 514, "Policy Loss": 0.6463280916213989, "Value Loss": 19.124828338623047, "_runtime": 7440.554444074631, "_timestamp": 1585604810.1873136, "_step": 121}
{"Episode reward": -99.30183171739927, "Episode length": 999, "Policy Loss": -0.4975241422653198, "Value Loss": 0.0600632019340992, "_runtime": 7442.092448472977, "_timestamp": 1585604811.725318, "_step": 122}
{"Episode reward": 2.77483378940795, "Episode length": 978, "Policy Loss": 0.10415147244930267, "Value Loss": 10.079943656921387, "_runtime": 7443.498813152313, "_timestamp": 1585604813.1316826, "_step": 123}
{"Episode reward": 8.364310068649715, "Episode length": 918, "Policy Loss": 0.14663465321063995, "Value Loss": 10.716044425964355, "_runtime": 7445.083884477615, "_timestamp": 1585604814.716754, "_step": 124}
{"Episode reward": -99.47337650208367, "Episode length": 999, "Policy Loss": -0.47926202416419983, "Value Loss": 0.03791059926152229, "_runtime": 7446.361652612686, "_timestamp": 1585604815.994522, "_step": 125}
{"Episode reward": 19.45927317441705, "Episode length": 807, "Policy Loss": 0.24910561740398407, "Value Loss": 12.188368797302246, "_runtime": 7447.9292068481445, "_timestamp": 1585604817.5620763, "_step": 126}
{"Episode reward": -99.56460739596957, "Episode length": 999, "Policy Loss": -0.44013115763664246, "Value Loss": 0.02648393251001835, "_runtime": 7448.564360380173, "_timestamp": 1585604818.1972299, "_step": 127}
{"Episode reward": 62.07433435571121, "Episode length": 381, "Policy Loss": 0.9923300743103027, "Value Loss": 25.764352798461914, "_runtime": 7449.670637130737, "_timestamp": 1585604819.3035066, "_step": 128}
{"Episode reward": 29.158907067274882, "Episode length": 711, "Policy Loss": 0.3524237871170044, "Value Loss": 13.84460163116455, "_runtime": 7451.2765374183655, "_timestamp": 1585604820.909407, "_step": 129}
{"Episode reward": -99.6327172973936, "Episode length": 999, "Policy Loss": -0.3490748107433319, "Value Loss": 0.0421750508248806, "_runtime": 7452.806697845459, "_timestamp": 1585604822.4395673, "_step": 130}
{"Episode reward": -99.60875830540907, "Episode length": 999, "Policy Loss": -0.3303300440311432, "Value Loss": 0.04698159173130989, "_runtime": 7454.35878443718, "_timestamp": 1585604823.991654, "_step": 131}
{"Episode reward": -99.38764940322153, "Episode length": 999, "Policy Loss": -0.29681846499443054, "Value Loss": 0.07340395450592041, "_runtime": 7455.920342206955, "_timestamp": 1585604825.5532117, "_step": 132}
{"Episode reward": -99.0118937479333, "Episode length": 999, "Policy Loss": -0.31654292345046997, "Value Loss": 0.03184688463807106, "_runtime": 7457.488424777985, "_timestamp": 1585604827.1212943, "_step": 133}
{"Episode reward": -99.45795236920101, "Episode length": 999, "Policy Loss": -0.31511783599853516, "Value Loss": 0.006428559310734272, "_runtime": 7459.058432340622, "_timestamp": 1585604828.6913018, "_step": 134}
{"Episode reward": -99.17889781592976, "Episode length": 999, "Policy Loss": -0.29284897446632385, "Value Loss": 0.00828538741916418, "_runtime": 7460.644290447235, "_timestamp": 1585604830.27716, "_step": 135}
{"Episode reward": -99.57547615854425, "Episode length": 999, "Policy Loss": -0.2988336682319641, "Value Loss": 0.009196058847010136, "_runtime": 7462.219558954239, "_timestamp": 1585604831.8524284, "_step": 136}
{"Episode reward": -99.47789542182007, "Episode length": 999, "Policy Loss": -0.28368401527404785, "Value Loss": 0.02052403800189495, "_runtime": 7462.878618240356, "_timestamp": 1585604832.5114877, "_step": 137}
{"Episode reward": 60.20387408724026, "Episode length": 398, "Policy Loss": 1.1157374382019043, "Value Loss": 24.645553588867188, "_runtime": 7464.10381937027, "_timestamp": 1585604833.7366889, "_step": 138}
{"Episode reward": 22.27311504140394, "Episode length": 779, "Policy Loss": 0.5275495648384094, "Value Loss": 12.697417259216309, "_runtime": 7465.048316001892, "_timestamp": 1585604834.6811855, "_step": 139}
{"Episode reward": 41.31290907759484, "Episode length": 590, "Policy Loss": 0.658206045627594, "Value Loss": 16.597007751464844, "_runtime": 7466.580447912216, "_timestamp": 1585604836.2133174, "_step": 140}
{"Episode reward": -99.49186873699517, "Episode length": 999, "Policy Loss": -0.26587241888046265, "Value Loss": 0.011323327198624611, "_runtime": 7467.925137758255, "_timestamp": 1585604837.5580072, "_step": 141}
{"Episode reward": 13.700000000000628, "Episode length": 863, "Policy Loss": 0.4065037667751312, "Value Loss": 11.309471130371094, "_runtime": 7469.455958843231, "_timestamp": 1585604839.0888283, "_step": 142}
{"Episode reward": -99.47050248712338, "Episode length": 999, "Policy Loss": -0.23349529504776, "Value Loss": 0.011129013262689114, "_runtime": 7470.517514228821, "_timestamp": 1585604840.1503837, "_step": 143}
{"Episode reward": 33.582127341802206, "Episode length": 669, "Policy Loss": 0.7218675017356873, "Value Loss": 14.572071075439453, "_runtime": 7472.087807416916, "_timestamp": 1585604841.720677, "_step": 144}
{"Episode reward": -99.48613660916897, "Episode length": 999, "Policy Loss": -0.2058780938386917, "Value Loss": 0.026573723182082176, "_runtime": 7473.651051998138, "_timestamp": 1585604843.2839215, "_step": 145}
{"Episode reward": -99.53288441965569, "Episode length": 999, "Policy Loss": -0.19458115100860596, "Value Loss": 0.010059542022645473, "_runtime": 7475.193802833557, "_timestamp": 1585604844.8266723, "_step": 146}
{"Episode reward": 3.3305031454843004, "Episode length": 972, "Policy Loss": 0.3785407543182373, "Value Loss": 10.055371284484863, "_runtime": 7476.663280487061, "_timestamp": 1585604846.29615, "_step": 147}
{"Episode reward": 7.666684774217245, "Episode length": 926, "Policy Loss": 0.43004271388053894, "Value Loss": 10.483942031860352, "_runtime": 7477.546705722809, "_timestamp": 1585604847.1795752, "_step": 148}
{"Episode reward": 44.62313911483456, "Episode length": 555, "Policy Loss": 0.788165807723999, "Value Loss": 17.53516960144043, "_runtime": 7478.47798204422, "_timestamp": 1585604848.1108515, "_step": 149}
{"Episode reward": 41.257133632525246, "Episode length": 588, "Policy Loss": 0.7054800987243652, "Value Loss": 16.927404403686523, "_runtime": 7480.053622245789, "_timestamp": 1585604849.6864917, "_step": 150}
{"Episode reward": -99.61515456271597, "Episode length": 999, "Policy Loss": -0.17146165668964386, "Value Loss": 0.10262975841760635, "_runtime": 7481.423046588898, "_timestamp": 1585604851.055916, "_step": 151}
{"Episode reward": 11.160801245376263, "Episode length": 892, "Policy Loss": 0.4296966791152954, "Value Loss": 11.027077674865723, "_runtime": 7482.95582151413, "_timestamp": 1585604852.588691, "_step": 152}
{"Episode reward": -99.44451185026566, "Episode length": 999, "Policy Loss": -0.23548467457294464, "Value Loss": 0.009773343801498413, "_runtime": 7483.78231716156, "_timestamp": 1585604853.4151866, "_step": 153}
{"Episode reward": 49.31647107376877, "Episode length": 509, "Policy Loss": 0.8337368965148926, "Value Loss": 19.105117797851562, "_runtime": 7485.337127685547, "_timestamp": 1585604854.9699972, "_step": 154}
{"Episode reward": -99.53242037584576, "Episode length": 999, "Policy Loss": -0.2356245070695877, "Value Loss": 0.08081498742103577, "_runtime": 7486.911648511887, "_timestamp": 1585604856.544518, "_step": 155}
{"Episode reward": -99.70623707552883, "Episode length": 999, "Policy Loss": -0.29225438833236694, "Value Loss": 0.003670785343274474, "_runtime": 7488.363771438599, "_timestamp": 1585604857.996641, "_step": 156}
{"Episode reward": 5.720278532932198, "Episode length": 948, "Policy Loss": 0.25220900774002075, "Value Loss": 10.295886039733887, "_runtime": 7489.945879936218, "_timestamp": 1585604859.5787494, "_step": 157}
{"Episode reward": -99.68303559075437, "Episode length": 999, "Policy Loss": -0.301406592130661, "Value Loss": 0.05304007977247238, "_runtime": 7491.5248329639435, "_timestamp": 1585604861.1577024, "_step": 158}
{"Episode reward": -99.26460533309736, "Episode length": 999, "Policy Loss": -0.3097512423992157, "Value Loss": 0.019915789365768433, "_runtime": 7493.083659410477, "_timestamp": 1585604862.716529, "_step": 159}
{"Episode reward": 0.5860182436240393, "Episode length": 997, "Policy Loss": 0.24401959776878357, "Value Loss": 9.776820182800293, "_runtime": 7494.659555435181, "_timestamp": 1585604864.292425, "_step": 160}
{"Episode reward": -99.67742145001547, "Episode length": 999, "Policy Loss": -0.3164806067943573, "Value Loss": 0.003973078448325396, "_runtime": 7496.078665018082, "_timestamp": 1585604865.7115345, "_step": 161}
{"Episode reward": 10.57054062960458, "Episode length": 901, "Policy Loss": 0.32376977801322937, "Value Loss": 10.807755470275879, "_runtime": 7497.1090795993805, "_timestamp": 1585604866.741949, "_step": 162}
{"Episode reward": 35.445594844495034, "Episode length": 649, "Policy Loss": 0.5552747249603271, "Value Loss": 15.022543907165527, "_runtime": 7498.720488071442, "_timestamp": 1585604868.3533576, "_step": 163}
{"Episode reward": -99.78203674639086, "Episode length": 999, "Policy Loss": -0.2894466519355774, "Value Loss": 0.004979255143553019, "_runtime": 7500.285923480988, "_timestamp": 1585604869.918793, "_step": 164}
{"Episode reward": -99.71052041053633, "Episode length": 999, "Policy Loss": -0.2702910006046295, "Value Loss": 0.027466902509331703, "_runtime": 7501.793734788895, "_timestamp": 1585604871.4266043, "_step": 165}
{"Episode reward": 3.2257463915373137, "Episode length": 972, "Policy Loss": 0.29764652252197266, "Value Loss": 10.024162292480469, "_runtime": 7502.58552980423, "_timestamp": 1585604872.2183993, "_step": 166}
{"Episode reward": 51.28623525806429, "Episode length": 488, "Policy Loss": 0.8945258855819702, "Value Loss": 19.810131072998047, "_runtime": 7503.276303529739, "_timestamp": 1585604872.909173, "_step": 167}
{"Episode reward": 58.95244376321176, "Episode length": 411, "Policy Loss": 1.0471783876419067, "Value Loss": 23.281936645507812, "_runtime": 7504.048335790634, "_timestamp": 1585604873.6812053, "_step": 168}
{"Episode reward": 52.095048595929576, "Episode length": 480, "Policy Loss": 0.890682578086853, "Value Loss": 20.00482177734375, "_runtime": 7505.563128948212, "_timestamp": 1585604875.1959984, "_step": 169}
{"Episode reward": -99.4350407861698, "Episode length": 999, "Policy Loss": -0.1880979984998703, "Value Loss": 0.12735092639923096, "_runtime": 7506.49986577034, "_timestamp": 1585604876.1327353, "_step": 170}
{"Episode reward": 38.27243202222393, "Episode length": 618, "Policy Loss": 0.7598381638526917, "Value Loss": 15.859432220458984, "_runtime": 7507.996545314789, "_timestamp": 1585604877.6294148, "_step": 171}
{"Episode reward": -99.81337436091131, "Episode length": 999, "Policy Loss": -0.15070906281471252, "Value Loss": 0.16163526475429535, "_runtime": 7509.552942991257, "_timestamp": 1585604879.1858125, "_step": 172}
{"Episode reward": -99.28797605303707, "Episode length": 999, "Policy Loss": -0.14910046756267548, "Value Loss": 0.11347003281116486, "_runtime": 7511.063390016556, "_timestamp": 1585604880.6962595, "_step": 173}
{"Episode reward": -99.26785212301192, "Episode length": 999, "Policy Loss": -0.20242181420326233, "Value Loss": 0.06033654510974884, "_runtime": 7512.60768198967, "_timestamp": 1585604882.2405515, "_step": 174}
{"Episode reward": -99.34194814288941, "Episode length": 999, "Policy Loss": -0.21209163963794708, "Value Loss": 0.02263876423239708, "_runtime": 7513.284150600433, "_timestamp": 1585604882.91702, "_step": 175}
{"Episode reward": 57.998469567944674, "Episode length": 421, "Policy Loss": 1.2604495286941528, "Value Loss": 23.097293853759766, "_runtime": 7514.012832164764, "_timestamp": 1585604883.6457016, "_step": 176}
{"Episode reward": 53.811285883071456, "Episode length": 463, "Policy Loss": 0.997733473777771, "Value Loss": 20.817256927490234, "_runtime": 7514.463822603226, "_timestamp": 1585604884.096692, "_step": 177}
{"Episode reward": 73.17772924607841, "Episode length": 271, "Policy Loss": 2.014014482498169, "Value Loss": 35.33546829223633, "_runtime": 7514.815192699432, "_timestamp": 1585604884.4480622, "_step": 178}
{"Episode reward": 77.39999999999995, "Episode length": 226, "Policy Loss": 2.146348237991333, "Value Loss": 42.259010314941406, "_runtime": 7515.166884422302, "_timestamp": 1585604884.799754, "_step": 179}
{"Episode reward": 77.59889213582497, "Episode length": 225, "Policy Loss": 2.104430913925171, "Value Loss": 42.48514938354492, "_runtime": 7516.661568641663, "_timestamp": 1585604886.2944381, "_step": 180}
{"Episode reward": -99.69270212222915, "Episode length": 999, "Policy Loss": -0.34865260124206543, "Value Loss": 0.022939026355743408, "_runtime": 7517.884268283844, "_timestamp": 1585604887.5171378, "_step": 181}
{"Episode reward": 16.917442509593542, "Episode length": 833, "Policy Loss": 0.48667261004447937, "Value Loss": 11.911530494689941, "_runtime": 7518.822823762894, "_timestamp": 1585604888.4556932, "_step": 182}
{"Episode reward": 35.88260409359728, "Episode length": 644, "Policy Loss": 0.45518213510513306, "Value Loss": 14.669942855834961, "_runtime": 7519.681401968002, "_timestamp": 1585604889.3142715, "_step": 183}
{"Episode reward": 45.265301047426554, "Episode length": 552, "Policy Loss": 0.534531831741333, "Value Loss": 17.99037742614746, "_runtime": 7520.764939069748, "_timestamp": 1585604890.3978086, "_step": 184}
{"Episode reward": 29.03857383608677, "Episode length": 711, "Policy Loss": 0.28592100739479065, "Value Loss": 13.664411544799805, "_runtime": 7522.31130027771, "_timestamp": 1585604891.9441698, "_step": 185}
{"Episode reward": -99.45119404355218, "Episode length": 999, "Policy Loss": -0.5500589609146118, "Value Loss": 0.13771359622478485, "_runtime": 7523.156147003174, "_timestamp": 1585604892.7890165, "_step": 186}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 0.2514400780200958, "Value Loss": 17.393722534179688, "_runtime": 7523.793248176575, "_timestamp": 1585604893.4261177, "_step": 187}
{"Episode reward": 59.00847620869723, "Episode length": 411, "Policy Loss": 0.9269075989723206, "Value Loss": 23.950124740600586, "_runtime": 7525.157231330872, "_timestamp": 1585604894.7901008, "_step": 188}
{"Episode reward": 10.552264709528473, "Episode length": 898, "Policy Loss": -0.15384437143802643, "Value Loss": 10.684932708740234, "_runtime": 7526.468914747238, "_timestamp": 1585604896.1017842, "_step": 189}
{"Episode reward": 13.124870738358666, "Episode length": 870, "Policy Loss": -0.21934036910533905, "Value Loss": 11.121639251708984, "_runtime": 7527.9615297317505, "_timestamp": 1585604897.5943992, "_step": 190}
{"Episode reward": -99.29440945667021, "Episode length": 999, "Policy Loss": -0.8573698997497559, "Value Loss": 0.11580974608659744, "_runtime": 7528.996000051498, "_timestamp": 1585604898.6288695, "_step": 191}
{"Episode reward": 32.72170331971965, "Episode length": 675, "Policy Loss": -0.05294627323746681, "Value Loss": 14.342025756835938, "_runtime": 7530.546374320984, "_timestamp": 1585604900.1792438, "_step": 192}
{"Episode reward": -99.10058523057097, "Episode length": 999, "Policy Loss": -0.9367231130599976, "Value Loss": 0.06367108970880508, "_runtime": 7532.076533794403, "_timestamp": 1585604901.7094033, "_step": 193}
{"Episode reward": -99.62414619244525, "Episode length": 999, "Policy Loss": -0.9725347757339478, "Value Loss": 0.038479890674352646, "_runtime": 7533.167587757111, "_timestamp": 1585604902.8004572, "_step": 194}
{"Episode reward": 28.901769746925623, "Episode length": 714, "Policy Loss": -0.2517291009426117, "Value Loss": 13.450806617736816, "_runtime": 7534.725368976593, "_timestamp": 1585604904.3582385, "_step": 195}
{"Episode reward": -99.36212863590053, "Episode length": 999, "Policy Loss": -0.9829735159873962, "Value Loss": 0.18029125034809113, "_runtime": 7536.283737659454, "_timestamp": 1585604905.9166071, "_step": 196}
{"Episode reward": -99.63473354692549, "Episode length": 999, "Policy Loss": -0.9716207981109619, "Value Loss": 0.03663094341754913, "_runtime": 7537.662650108337, "_timestamp": 1585604907.2955196, "_step": 197}
{"Episode reward": 10.522866144794605, "Episode length": 897, "Policy Loss": -0.3594452440738678, "Value Loss": 10.708940505981445, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448, 0.05721396207809448]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05726349353790283, -0.034493252635002136, -0.011723008006811142, 0.011047236621379852, 0.03381747752428055, 0.056587718427181244, 0.07935796678066254, 0.10212820768356323, 0.12489844858646393, 0.14766868948936462, 0.17043893039226532, 0.19320917129516602, 0.2159794270992279, 0.2387496531009674, 0.2615199089050293, 0.2842901349067688, 0.3070603907108307, 0.3298306465148926, 0.3526008725166321, 0.37537112832069397, 0.39814135432243347, 0.42091161012649536, 0.44368183612823486, 0.46645206212997437, 0.48922234773635864, 0.5119925737380981, 0.5347627997398376, 0.5575330853462219, 0.5803033113479614, 0.6030735373497009, 0.6258437633514404, 0.6486140489578247, 0.6713842749595642, 0.6941545009613037, 0.716924786567688, 0.7396950125694275, 0.762465238571167, 0.7852354645729065, 0.8080057501792908, 0.8307759761810303, 0.8535462021827698, 0.876316487789154, 0.8990867137908936, 0.9218569397926331, 0.9446271657943726, 0.9673974514007568, 0.9901676177978516, 1.0129379034042358, 1.0357081890106201, 1.0584783554077148, 1.0812486410140991, 1.1040189266204834, 1.1267890930175781, 1.1495593786239624, 1.1723296642303467, 1.1950998306274414, 1.2178701162338257, 1.24064040184021, 1.2634105682373047, 1.286180853843689, 1.3089510202407837, 1.331721305847168, 1.3544915914535522, 1.377261757850647, 1.4000320434570312]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.661527312535327e-05, 0.0012288885191082954, 0.0024743922986090183, 0.003719896078109741, 0.004965399857610464, 0.006210903637111187, 0.00745640741661191, 0.008701910264790058, 0.009947414509952068, 0.011192918755114079, 0.012438422068953514, 0.01368392538279295, 0.01492942962795496, 0.016174934804439545, 0.017420437186956406, 0.018665941432118416, 0.019911445677280426, 0.021156949922442436, 0.022402454167604446, 0.023647956550121307, 0.024893460795283318, 0.026138965040445328, 0.02738446742296219, 0.0286299716681242, 0.02987547591328621, 0.03112098015844822, 0.03236648440361023, 0.03361198678612709, 0.03485748916864395, 0.03610299527645111, 0.03734849765896797, 0.03859400376677513, 0.03983950614929199, 0.04108500853180885, 0.04233051463961601, 0.043576017022132874, 0.04482152312994003, 0.046067025512456894, 0.047312527894973755, 0.048558034002780914, 0.049803536385297775, 0.051049038767814636, 0.052294544875621796, 0.05354004725813866, 0.05478554964065552, 0.05603105574846268, 0.05727655813097954, 0.0585220642387867, 0.05976756662130356, 0.06101306900382042, 0.06225857511162758, 0.06350407749414444, 0.0647495836019516, 0.06599508225917816, 0.06724058836698532, 0.06848609447479248, 0.06973159313201904, 0.0709770992398262, 0.07222260534763336, 0.07346811145544052, 0.07471361011266708, 0.07595911622047424, 0.0772046223282814, 0.07845012098550797, 0.07969562709331512]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 0.0, 4.0, 7.0, 5.0, 9.0, 13.0, 11.0, 7.0, 7.0, 7.0, 10.0, 4.0, 321.0, 0.0, 2.0, 1.0, 3.0, 6.0, 6.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 2.0, 4.0, 6.0, 5.0, 5.0, 3.0, 1.0, 4.0, 2.0, 5.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.1293303370475769, -0.1237051784992218, -0.1180800125002861, -0.1124548465013504, -0.1068296879529953, -0.1012045294046402, -0.0955793634057045, -0.0899541974067688, -0.0843290388584137, -0.0787038803100586, -0.0730787143111229, -0.0674535483121872, -0.06182838976383209, -0.05620323121547699, -0.05057806521654129, -0.04495289921760559, -0.03932774066925049, -0.033702582120895386, -0.028077416121959686, -0.022452250123023987, -0.016827091574668884, -0.011201933026313782, -0.005576767027378082, 4.839897155761719e-05, 0.00567355751991272, 0.011298716068267822, 0.016923874616622925, 0.02254904806613922, 0.028174206614494324, 0.033799365162849426, 0.03942453861236572, 0.045049697160720825, 0.05067485570907593, 0.05630001425743103, 0.06192517280578613, 0.06755034625530243, 0.07317550480365753, 0.07880066335201263, 0.08442583680152893, 0.09005099534988403, 0.09567615389823914, 0.10130131244659424, 0.10692647099494934, 0.11255164444446564, 0.11817680299282074, 0.12380197644233704, 0.12942713499069214, 0.13505229353904724, 0.14067745208740234, 0.14630261063575745, 0.15192776918411255, 0.15755292773246765, 0.16317808628082275, 0.16880327463150024, 0.17442843317985535, 0.18005359172821045, 0.18567875027656555, 0.19130390882492065, 0.19692906737327576, 0.20255422592163086, 0.20817941427230835, 0.21380457282066345, 0.21942973136901855, 0.22505488991737366, 0.23068004846572876]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1815253496170044, -0.17294639348983765, -0.1643674373626709, -0.15578849613666534, -0.1472095400094986, -0.13863058388233185, -0.1300516426563263, -0.12147268652915955, -0.1128937304019928, -0.10431477427482605, -0.0957358255982399, -0.08715687692165375, -0.078577920794487, -0.06999896466732025, -0.0614200159907341, -0.05284106731414795, -0.0442621111869812, -0.03568315505981445, -0.027104198932647705, -0.01852525770664215, -0.009946301579475403, -0.0013673454523086548, 0.007211595773696899, 0.015790551900863647, 0.024369508028030396, 0.032948464155197144, 0.04152742028236389, 0.050106361508369446, 0.058685317635536194, 0.06726427376270294, 0.0758432149887085, 0.08442217111587524, 0.09300112724304199, 0.10158008337020874, 0.11015903949737549, 0.11873799562454224, 0.12731695175170898, 0.13589587807655334, 0.1444748342037201, 0.15305379033088684, 0.1616327464580536, 0.17021170258522034, 0.17879065871238708, 0.18736961483955383, 0.1959485411643982, 0.20452749729156494, 0.2131064534187317, 0.22168540954589844, 0.23026436567306519, 0.23884332180023193, 0.24742227792739868, 0.25600123405456543, 0.2645801901817322, 0.27315911650657654, 0.2817380726337433, 0.29031702876091003, 0.2988959848880768, 0.30747494101524353, 0.3160538971424103, 0.32463282346725464, 0.3332117795944214, 0.34179073572158813, 0.3503696918487549, 0.35894864797592163, 0.3675276041030884]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 7.0, 5.0, 14.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2869740128517151, -0.2734118402004242, -0.2598496675491333, -0.2462874948978424, -0.2327253371477127, -0.21916316449642181, -0.20560099184513092, -0.19203883409500122, -0.17847666144371033, -0.16491448879241943, -0.15135231614112854, -0.13779014348983765, -0.12422797083854675, -0.11066579818725586, -0.09710364043712616, -0.08354146778583527, -0.06997929513454437, -0.05641712248325348, -0.042854949831962585, -0.029292792081832886, -0.015730619430541992, -0.0021684467792510986, 0.011393725872039795, 0.02495589852333069, 0.03851807117462158, 0.052080243825912476, 0.06564241647720337, 0.07920455932617188, 0.09276673197746277, 0.10632890462875366, 0.11989107728004456, 0.13345324993133545, 0.14701542258262634, 0.16057759523391724, 0.17413976788520813, 0.18770194053649902, 0.20126411318778992, 0.2148262858390808, 0.22838842868804932, 0.2419506311416626, 0.2555127739906311, 0.2690749764442444, 0.2826371192932129, 0.2961992621421814, 0.3097614645957947, 0.3233236074447632, 0.33688580989837646, 0.35044795274734497, 0.36401015520095825, 0.37757229804992676, 0.39113450050354004, 0.40469664335250854, 0.4182588458061218, 0.43182098865509033, 0.44538313150405884, 0.4589453339576721, 0.4725074768066406, 0.4860696792602539, 0.4996318221092224, 0.5131940245628357, 0.5267561674118042, 0.5403183698654175, 0.553880512714386, 0.5674427151679993, 0.5810048580169678]}, "_runtime": 7538.657965183258, "_timestamp": 1585604908.2908347, "_step": 198}
{"Episode reward": 36.59539386948392, "Episode length": 635, "Policy Loss": -0.10888964682817459, "Value Loss": 15.127673149108887, "_runtime": 7540.220854997635, "_timestamp": 1585604909.8537245, "_step": 199}
{"Episode reward": -99.22762840527439, "Episode length": 999, "Policy Loss": -0.8800410032272339, "Value Loss": 0.13458147644996643, "_runtime": 7541.154727935791, "_timestamp": 1585604910.7875974, "_step": 200}
{"Episode reward": 41.16556278804436, "Episode length": 592, "Policy Loss": -0.014296470209956169, "Value Loss": 16.160125732421875, "_runtime": 7542.694682359695, "_timestamp": 1585604912.3275518, "_step": 201}
{"Episode reward": -99.62103149165203, "Episode length": 999, "Policy Loss": -0.8552818298339844, "Value Loss": 0.2021639049053192, "_runtime": 7544.248985528946, "_timestamp": 1585604913.881855, "_step": 202}
{"Episode reward": -99.54466085623287, "Episode length": 999, "Policy Loss": -0.7956876754760742, "Value Loss": 0.025813763961195946, "_runtime": 7545.195771217346, "_timestamp": 1585604914.8286407, "_step": 203}
{"Episode reward": 39.67404769696347, "Episode length": 611, "Policy Loss": 0.08672074228525162, "Value Loss": 16.241310119628906, "_runtime": 7546.754068613052, "_timestamp": 1585604916.386938, "_step": 204}
{"Episode reward": -99.07945792340188, "Episode length": 999, "Policy Loss": -0.7355589866638184, "Value Loss": 0.020842546597123146, "_runtime": 7547.884505033493, "_timestamp": 1585604917.5173745, "_step": 205}
{"Episode reward": 30.386416467067875, "Episode length": 699, "Policy Loss": 0.08794430643320084, "Value Loss": 13.70903491973877, "_runtime": 7549.065534353256, "_timestamp": 1585604918.6984038, "_step": 206}
{"Episode reward": 23.746495454317525, "Episode length": 768, "Policy Loss": 0.028811967000365257, "Value Loss": 12.496868133544922, "_runtime": 7549.452641487122, "_timestamp": 1585604919.085511, "_step": 207}
{"Episode reward": 78.36706976415441, "Episode length": 217, "Policy Loss": 1.7877528667449951, "Value Loss": 44.211639404296875, "_runtime": 7550.434663295746, "_timestamp": 1585604920.0675328, "_step": 208}
{"Episode reward": 36.45064607917821, "Episode length": 640, "Policy Loss": 0.2157430350780487, "Value Loss": 15.339218139648438, "_runtime": 7551.976263999939, "_timestamp": 1585604921.6091335, "_step": 209}
{"Episode reward": -98.98594637320213, "Episode length": 999, "Policy Loss": -0.5695103406906128, "Value Loss": 0.04382553696632385, "_runtime": 7553.467448711395, "_timestamp": 1585604923.1003182, "_step": 210}
{"Episode reward": -99.42108594997272, "Episode length": 999, "Policy Loss": -0.5697212219238281, "Value Loss": 0.13977941870689392, "_runtime": 7554.98832654953, "_timestamp": 1585604924.621196, "_step": 211}
{"Episode reward": -99.14749827130008, "Episode length": 999, "Policy Loss": -0.5513187050819397, "Value Loss": 0.016977490857243538, "_runtime": 7556.401695728302, "_timestamp": 1585604926.0345652, "_step": 212}
{"Episode reward": 9.503926080384701, "Episode length": 909, "Policy Loss": 0.0558975525200367, "Value Loss": 10.801223754882812, "_runtime": 7557.9462604522705, "_timestamp": 1585604927.57913, "_step": 213}
{"Episode reward": -99.25168250137368, "Episode length": 999, "Policy Loss": -0.5092350244522095, "Value Loss": 0.025195108726620674, "_runtime": 7559.50151014328, "_timestamp": 1585604929.1343796, "_step": 214}
{"Episode reward": -99.08057253798917, "Episode length": 999, "Policy Loss": -0.4938783049583435, "Value Loss": 0.06512580066919327, "_runtime": 7561.053547620773, "_timestamp": 1585604930.686417, "_step": 215}
{"Episode reward": -99.40276753786318, "Episode length": 999, "Policy Loss": -0.4571674168109894, "Value Loss": 0.030334554612636566, "_runtime": 7562.599848031998, "_timestamp": 1585604932.2327175, "_step": 216}
{"Episode reward": -99.20984628238232, "Episode length": 999, "Policy Loss": -0.4370565116405487, "Value Loss": 0.019066866487264633, "_runtime": 7564.06575012207, "_timestamp": 1585604933.6986196, "_step": 217}
{"Episode reward": 6.446864894295089, "Episode length": 942, "Policy Loss": 0.12169860303401947, "Value Loss": 10.087506294250488, "_runtime": 7565.6247091293335, "_timestamp": 1585604935.2575786, "_step": 218}
{"Episode reward": -99.04603658342032, "Episode length": 999, "Policy Loss": -0.39817574620246887, "Value Loss": 0.1016840785741806, "_runtime": 7567.185309410095, "_timestamp": 1585604936.818179, "_step": 219}
{"Episode reward": -99.23477022501184, "Episode length": 999, "Policy Loss": -0.3590256869792938, "Value Loss": 0.010927840135991573, "_runtime": 7568.753394365311, "_timestamp": 1585604938.3862638, "_step": 220}
{"Episode reward": -99.40490602400433, "Episode length": 999, "Policy Loss": -0.31816935539245605, "Value Loss": 0.11990207433700562, "_runtime": 7570.31617474556, "_timestamp": 1585604939.9490442, "_step": 221}
{"Episode reward": -99.2628536934034, "Episode length": 999, "Policy Loss": -0.3098407983779907, "Value Loss": 0.02010299079120159, "_runtime": 7571.9052357673645, "_timestamp": 1585604941.5381052, "_step": 222}
{"Episode reward": -99.35035367536082, "Episode length": 999, "Policy Loss": -0.28914737701416016, "Value Loss": 0.03982163220643997, "_runtime": 7573.470638513565, "_timestamp": 1585604943.103508, "_step": 223}
{"Episode reward": -99.3519760550961, "Episode length": 999, "Policy Loss": -0.267543762922287, "Value Loss": 0.015318367630243301, "_runtime": 7575.040970802307, "_timestamp": 1585604944.6738403, "_step": 224}
{"Episode reward": -99.36046455241895, "Episode length": 999, "Policy Loss": -0.24600467085838318, "Value Loss": 0.07806508243083954, "_runtime": 7576.599472761154, "_timestamp": 1585604946.2323422, "_step": 225}
{"Episode reward": -99.23581984601923, "Episode length": 999, "Policy Loss": -0.23124511539936066, "Value Loss": 0.015412216074764729, "_runtime": 7577.7461977005005, "_timestamp": 1585604947.3790672, "_step": 226}
{"Episode reward": 27.62643060991816, "Episode length": 726, "Policy Loss": 0.45135730504989624, "Value Loss": 13.491326332092285, "_runtime": 7579.211481809616, "_timestamp": 1585604948.8443513, "_step": 227}
{"Episode reward": 7.671304702849611, "Episode length": 931, "Policy Loss": 0.3132469654083252, "Value Loss": 10.178592681884766, "_runtime": 7580.484916210175, "_timestamp": 1585604950.1177857, "_step": 228}
{"Episode reward": 19.413911825745828, "Episode length": 813, "Policy Loss": 0.624653697013855, "Value Loss": 11.739789962768555, "_runtime": 7582.024892807007, "_timestamp": 1585604951.6577623, "_step": 229}
{"Episode reward": -99.16295667048409, "Episode length": 999, "Policy Loss": -0.15902845561504364, "Value Loss": 0.04427473619580269, "_runtime": 7583.576300144196, "_timestamp": 1585604953.2091696, "_step": 230}
{"Episode reward": -99.72286425242643, "Episode length": 999, "Policy Loss": -0.17153280973434448, "Value Loss": 0.0039379349909722805, "_runtime": 7585.11661863327, "_timestamp": 1585604954.749488, "_step": 231}
{"Episode reward": -99.47246859091109, "Episode length": 999, "Policy Loss": -0.1592780202627182, "Value Loss": 0.0074695926159620285, "_runtime": 7586.305463075638, "_timestamp": 1585604955.9383326, "_step": 232}
{"Episode reward": 24.852385869116915, "Episode length": 759, "Policy Loss": 0.4781106412410736, "Value Loss": 12.570467948913574, "_runtime": 7587.871876716614, "_timestamp": 1585604957.5047462, "_step": 233}
{"Episode reward": -99.08673021290605, "Episode length": 999, "Policy Loss": -0.1461295187473297, "Value Loss": 0.022897031158208847, "_runtime": 7589.434583187103, "_timestamp": 1585604959.0674527, "_step": 234}
{"Episode reward": -99.04929254924805, "Episode length": 999, "Policy Loss": -0.14085565507411957, "Value Loss": 0.02283615805208683, "_runtime": 7590.976778507233, "_timestamp": 1585604960.609648, "_step": 235}
{"Episode reward": -98.9789220959968, "Episode length": 999, "Policy Loss": -0.14308494329452515, "Value Loss": 0.043887604027986526, "_runtime": 7591.900754213333, "_timestamp": 1585604961.5336237, "_step": 236}
{"Episode reward": 42.088326813972714, "Episode length": 582, "Policy Loss": 0.7418185472488403, "Value Loss": 16.515701293945312, "_runtime": 7592.732829809189, "_timestamp": 1585604962.3656993, "_step": 237}
{"Episode reward": 47.36267151543241, "Episode length": 531, "Policy Loss": 1.4257742166519165, "Value Loss": 18.75018310546875, "_runtime": 7593.261064529419, "_timestamp": 1585604962.893934, "_step": 238}
{"Episode reward": 68.84949356035487, "Episode length": 315, "Policy Loss": 1.285646915435791, "Value Loss": 30.25021743774414, "_runtime": 7594.820845127106, "_timestamp": 1585604964.4537146, "_step": 239}
{"Episode reward": -98.80910190674997, "Episode length": 999, "Policy Loss": -0.190384179353714, "Value Loss": 0.06231149658560753, "_runtime": 7596.330929756165, "_timestamp": 1585604965.9637992, "_step": 240}
{"Episode reward": -99.40264024258222, "Episode length": 999, "Policy Loss": -0.22776015102863312, "Value Loss": 0.029718613252043724, "_runtime": 7597.309980630875, "_timestamp": 1585604966.94285, "_step": 241}
{"Episode reward": 35.17080873218852, "Episode length": 654, "Policy Loss": 0.45455002784729004, "Value Loss": 14.703656196594238, "_runtime": 7598.426370382309, "_timestamp": 1585604968.0592399, "_step": 242}
{"Episode reward": 28.941670013391686, "Episode length": 717, "Policy Loss": 0.451736181974411, "Value Loss": 13.345940589904785, "_runtime": 7599.967301607132, "_timestamp": 1585604969.600171, "_step": 243}
{"Episode reward": -99.34769831387247, "Episode length": 999, "Policy Loss": -0.3289986550807953, "Value Loss": 0.020704880356788635, "_runtime": 7601.033561229706, "_timestamp": 1585604970.6664307, "_step": 244}
{"Episode reward": 30.835391798484878, "Episode length": 695, "Policy Loss": 0.355867862701416, "Value Loss": 14.053428649902344, "_runtime": 7602.563852071762, "_timestamp": 1585604972.1967216, "_step": 245}
{"Episode reward": -99.13944567986411, "Episode length": 999, "Policy Loss": -0.40958184003829956, "Value Loss": 0.04458098113536835, "_runtime": 7603.759139537811, "_timestamp": 1585604973.392009, "_step": 246}
{"Episode reward": 23.294918260297067, "Episode length": 771, "Policy Loss": 0.22245903313159943, "Value Loss": 12.039732933044434, "_runtime": 7605.281262397766, "_timestamp": 1585604974.9141319, "_step": 247}
{"Episode reward": -99.45519316554753, "Episode length": 999, "Policy Loss": -0.4029943645000458, "Value Loss": 0.2731544077396393, "_runtime": 7606.844210624695, "_timestamp": 1585604976.47708, "_step": 248}
{"Episode reward": -99.22205043611622, "Episode length": 999, "Policy Loss": -0.4787348806858063, "Value Loss": 0.017667867243289948, "_runtime": 7608.08602309227, "_timestamp": 1585604977.7188926, "_step": 249}
{"Episode reward": 21.359442165320615, "Episode length": 795, "Policy Loss": 0.2876746952533722, "Value Loss": 11.779412269592285, "_runtime": 7609.626350641251, "_timestamp": 1585604979.2592201, "_step": 250}
{"Episode reward": -99.74322812518082, "Episode length": 999, "Policy Loss": -0.46475234627723694, "Value Loss": 0.24640057981014252, "_runtime": 7611.18016409874, "_timestamp": 1585604980.8130336, "_step": 251}
{"Episode reward": -99.41719778016457, "Episode length": 999, "Policy Loss": -0.48670607805252075, "Value Loss": 0.0142165282741189, "_runtime": 7612.718490600586, "_timestamp": 1585604982.35136, "_step": 252}
{"Episode reward": -98.97175328209426, "Episode length": 999, "Policy Loss": -0.48176032304763794, "Value Loss": 0.009300853125751019, "_runtime": 7614.265427350998, "_timestamp": 1585604983.8982968, "_step": 253}
{"Episode reward": -99.54779696415798, "Episode length": 999, "Policy Loss": -0.4632818400859833, "Value Loss": 0.018080899491906166, "_runtime": 7615.825455904007, "_timestamp": 1585604985.4583254, "_step": 254}
{"Episode reward": -99.21111905800399, "Episode length": 999, "Policy Loss": -0.4417242705821991, "Value Loss": 0.013227496296167374, "_runtime": 7617.391589164734, "_timestamp": 1585604987.0244586, "_step": 255}
{"Episode reward": -99.3003620161705, "Episode length": 999, "Policy Loss": -0.41780227422714233, "Value Loss": 0.016516024246811867, "_runtime": 7618.983456373215, "_timestamp": 1585604988.6163259, "_step": 256}
{"Episode reward": -99.28388245501274, "Episode length": 999, "Policy Loss": -0.4017868638038635, "Value Loss": 0.02394581213593483, "_runtime": 7620.553703069687, "_timestamp": 1585604990.1865726, "_step": 257}
{"Episode reward": -99.06284527178553, "Episode length": 999, "Policy Loss": -0.38210850954055786, "Value Loss": 0.03455381840467453, "_runtime": 7621.812693595886, "_timestamp": 1585604991.445563, "_step": 258}
{"Episode reward": 20.67065808751927, "Episode length": 800, "Policy Loss": 0.5270995497703552, "Value Loss": 12.014350891113281, "_runtime": 7623.3755440711975, "_timestamp": 1585604993.0084136, "_step": 259}
{"Episode reward": -99.35716730379254, "Episode length": 999, "Policy Loss": -0.3200804889202118, "Value Loss": 0.15181410312652588, "_runtime": 7624.948442459106, "_timestamp": 1585604994.581312, "_step": 260}
{"Episode reward": -99.17843987054523, "Episode length": 999, "Policy Loss": -0.29996490478515625, "Value Loss": 0.09053575247526169, "_runtime": 7626.495187759399, "_timestamp": 1585604996.1280572, "_step": 261}
{"Episode reward": -99.25325084317456, "Episode length": 999, "Policy Loss": -0.2943333089351654, "Value Loss": 0.013236386701464653, "_runtime": 7628.038408994675, "_timestamp": 1585604997.6712785, "_step": 262}
{"Episode reward": -99.35426467469523, "Episode length": 999, "Policy Loss": -0.2673722207546234, "Value Loss": 0.010225829668343067, "_runtime": 7629.600419282913, "_timestamp": 1585604999.2332888, "_step": 263}
{"Episode reward": -99.39691842979381, "Episode length": 999, "Policy Loss": -0.24126987159252167, "Value Loss": 0.018314173445105553, "_runtime": 7631.148095607758, "_timestamp": 1585605000.780965, "_step": 264}
{"Episode reward": -99.55349009329228, "Episode length": 999, "Policy Loss": -0.20619311928749084, "Value Loss": 0.031054288148880005, "_runtime": 7632.705322980881, "_timestamp": 1585605002.3381925, "_step": 265}
{"Episode reward": -99.28445270673119, "Episode length": 999, "Policy Loss": -0.19673894345760345, "Value Loss": 0.020796097815036774, "_runtime": 7633.325964689255, "_timestamp": 1585605002.9588342, "_step": 266}
{"Episode reward": 62.69970201155495, "Episode length": 374, "Policy Loss": 1.2610708475112915, "Value Loss": 25.51936912536621, "_runtime": 7634.88677072525, "_timestamp": 1585605004.5196402, "_step": 267}
{"Episode reward": -99.28634825708441, "Episode length": 999, "Policy Loss": -0.1734093576669693, "Value Loss": 0.02681140787899494, "_runtime": 7636.442711353302, "_timestamp": 1585605006.0755808, "_step": 268}
{"Episode reward": -99.69756147394807, "Episode length": 999, "Policy Loss": -0.1583361178636551, "Value Loss": 0.011773142963647842, "_runtime": 7637.37392449379, "_timestamp": 1585605007.006794, "_step": 269}
{"Episode reward": 38.93008648434566, "Episode length": 612, "Policy Loss": 1.1975258588790894, "Value Loss": 15.544585227966309, "_runtime": 7638.929295301437, "_timestamp": 1585605008.5621648, "_step": 270}
{"Episode reward": -99.22009853840439, "Episode length": 999, "Policy Loss": -0.14501634240150452, "Value Loss": 0.007409338839352131, "_runtime": 7640.207734584808, "_timestamp": 1585605009.840604, "_step": 271}
{"Episode reward": 19.03903691990888, "Episode length": 813, "Policy Loss": 0.5001541376113892, "Value Loss": 11.663613319396973, "_runtime": 7641.756618022919, "_timestamp": 1585605011.3894875, "_step": 272}
{"Episode reward": -99.21373672604396, "Episode length": 999, "Policy Loss": -0.14861682057380676, "Value Loss": 0.003559998469427228, "_runtime": 7643.3177354335785, "_timestamp": 1585605012.950605, "_step": 273}
{"Episode reward": -99.55187921698682, "Episode length": 999, "Policy Loss": -0.1471422165632248, "Value Loss": 0.012876980006694794, "_runtime": 7644.858682632446, "_timestamp": 1585605014.491552, "_step": 274}
{"Episode reward": -99.25017569252677, "Episode length": 999, "Policy Loss": -0.0865769162774086, "Value Loss": 0.09583234041929245, "_runtime": 7645.998736619949, "_timestamp": 1585605015.631606, "_step": 275}
{"Episode reward": 26.962540521594804, "Episode length": 733, "Policy Loss": 0.5523303747177124, "Value Loss": 13.00032901763916, "_runtime": 7647.569329500198, "_timestamp": 1585605017.202199, "_step": 276}
{"Episode reward": -99.65054028382882, "Episode length": 999, "Policy Loss": -0.12532156705856323, "Value Loss": 0.031054068356752396, "_runtime": 7649.136051416397, "_timestamp": 1585605018.768921, "_step": 277}
{"Episode reward": -99.27104291687, "Episode length": 999, "Policy Loss": -0.14334118366241455, "Value Loss": 0.008242253214120865, "_runtime": 7649.938049793243, "_timestamp": 1585605019.5709193, "_step": 278}
{"Episode reward": 49.199999999999555, "Episode length": 508, "Policy Loss": 1.007498860359192, "Value Loss": 18.876218795776367, "_runtime": 7651.16780090332, "_timestamp": 1585605020.8006704, "_step": 279}
{"Episode reward": 22.02303333038597, "Episode length": 782, "Policy Loss": 0.5496177673339844, "Value Loss": 12.392781257629395, "_runtime": 7652.721770763397, "_timestamp": 1585605022.3546402, "_step": 280}
{"Episode reward": -99.38985908154146, "Episode length": 999, "Policy Loss": -0.16661480069160461, "Value Loss": 0.0418558306992054, "_runtime": 7654.237118244171, "_timestamp": 1585605023.8699877, "_step": 281}
{"Episode reward": -99.85269732908789, "Episode length": 999, "Policy Loss": -0.19530126452445984, "Value Loss": 0.030089743435382843, "_runtime": 7655.189824819565, "_timestamp": 1585605024.8226943, "_step": 282}
{"Episode reward": 39.464155702775464, "Episode length": 606, "Policy Loss": 0.7237926125526428, "Value Loss": 15.688565254211426, "_runtime": 7656.753127574921, "_timestamp": 1585605026.385997, "_step": 283}
{"Episode reward": -99.53870155895574, "Episode length": 999, "Policy Loss": -0.22756817936897278, "Value Loss": 0.02493605576455593, "_runtime": 7658.149658918381, "_timestamp": 1585605027.7825284, "_step": 284}
{"Episode reward": 9.6066163608522, "Episode length": 906, "Policy Loss": 0.3986496329307556, "Value Loss": 10.495949745178223, "_runtime": 7658.897190570831, "_timestamp": 1585605028.53006, "_step": 285}
{"Episode reward": 52.49742717146834, "Episode length": 476, "Policy Loss": 0.9875375628471375, "Value Loss": 19.510730743408203, "_runtime": 7659.266869544983, "_timestamp": 1585605028.899739, "_step": 286}
{"Episode reward": 79.13344711522075, "Episode length": 210, "Policy Loss": 2.265019655227661, "Value Loss": 45.975868225097656, "_runtime": 7660.8104293346405, "_timestamp": 1585605030.4432988, "_step": 287}
{"Episode reward": -99.5109316982839, "Episode length": 999, "Policy Loss": -0.33056437969207764, "Value Loss": 0.015849314630031586, "_runtime": 7662.065394878387, "_timestamp": 1585605031.6982644, "_step": 288}
{"Episode reward": 18.295213492696718, "Episode length": 822, "Policy Loss": 0.2688245177268982, "Value Loss": 11.652264595031738, "_runtime": 7662.756463527679, "_timestamp": 1585605032.389333, "_step": 289}
{"Episode reward": 52.94484553483741, "Episode length": 471, "Policy Loss": 0.7433250546455383, "Value Loss": 20.79742431640625, "_runtime": 7664.311199903488, "_timestamp": 1585605033.9440694, "_step": 290}
{"Episode reward": -99.64574412956142, "Episode length": 999, "Policy Loss": -0.45101332664489746, "Value Loss": 0.04782610014081001, "_runtime": 7665.88259100914, "_timestamp": 1585605035.5154605, "_step": 291}
{"Episode reward": -99.30204272482086, "Episode length": 999, "Policy Loss": -0.49281439185142517, "Value Loss": 0.1523119956254959, "_runtime": 7666.459037542343, "_timestamp": 1585605036.091907, "_step": 292}
{"Episode reward": 62.953827765698705, "Episode length": 373, "Policy Loss": 0.9040393829345703, "Value Loss": 24.981454849243164, "_runtime": 7667.325519323349, "_timestamp": 1585605036.9583888, "_step": 293}
{"Episode reward": 44.797798895253294, "Episode length": 553, "Policy Loss": 0.4188893437385559, "Value Loss": 17.06849479675293, "_runtime": 7668.865810871124, "_timestamp": 1585605038.4986804, "_step": 294}
{"Episode reward": -99.65744778223896, "Episode length": 999, "Policy Loss": -0.5745474100112915, "Value Loss": 0.01922825165092945, "_runtime": 7669.2163252830505, "_timestamp": 1585605038.8491948, "_step": 295}
{"Episode reward": 78.61967474239643, "Episode length": 215, "Policy Loss": 2.210865020751953, "Value Loss": 42.886077880859375, "_runtime": 7670.721846342087, "_timestamp": 1585605040.3547158, "_step": 296}
{"Episode reward": -99.60409340742488, "Episode length": 999, "Policy Loss": -0.616228461265564, "Value Loss": 0.023936713114380836, "_runtime": 7671.732822418213, "_timestamp": 1585605041.365692, "_step": 297}
{"Episode reward": 36.2602155469992, "Episode length": 640, "Policy Loss": 0.3540270924568176, "Value Loss": 14.702679634094238, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505, -0.0368245504796505]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.5841739773750305, -0.5744708776473999, -0.5647677779197693, -0.5550646781921387, -0.5453615784645081, -0.5356584787368774, -0.5259553790092468, -0.5162522792816162, -0.5065491795539856, -0.496846079826355, -0.48714298009872437, -0.47743988037109375, -0.46773678064346313, -0.4580336809158325, -0.4483305811882019, -0.4386274814605713, -0.4289243817329407, -0.41922128200531006, -0.40951818227767944, -0.39981508255004883, -0.3901119828224182, -0.3804088830947876, -0.370705783367157, -0.36100268363952637, -0.35129955410957336, -0.34159645438194275, -0.33189335465431213, -0.3221902549266815, -0.3124871551990509, -0.3027840554714203, -0.2930809557437897, -0.28337785601615906, -0.27367475628852844, -0.2639716565608978, -0.2542685568332672, -0.2445654571056366, -0.23486235737800598, -0.22515925765037537, -0.21545615792274475, -0.20575305819511414, -0.19604995846748352, -0.1863468587398529, -0.1766437590122223, -0.16694065928459167, -0.15723755955696106, -0.14753445982933044, -0.13783136010169983, -0.1281282603740692, -0.11842513084411621, -0.1087220311164856, -0.09901893138885498, -0.08931583166122437, -0.07961273193359375, -0.06990963220596313, -0.06020653247833252, -0.050503432750701904, -0.04080033302307129, -0.031097233295440674, -0.02139413356781006, -0.011691033840179443, -0.001987934112548828, 0.007715165615081787, 0.017418265342712402, 0.027121365070343018, 0.03682446479797363]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.057348087430000305, -0.056452009826898575, -0.055555928498506546, -0.054659850895404816, -0.053763773292303085, -0.052867695689201355, -0.051971614360809326, -0.051075536757707596, -0.050179459154605865, -0.04928337782621384, -0.048387300223112106, -0.047491222620010376, -0.04659514129161835, -0.04569906368851662, -0.044802986085414886, -0.043906908482313156, -0.043010830879211426, -0.0421147495508194, -0.04121867194771767, -0.040322594344615936, -0.03942651301622391, -0.03853043541312218, -0.03763435781002045, -0.03673827648162842, -0.03584219887852669, -0.03494612127542496, -0.03405003994703293, -0.0331539660692215, -0.03225788474082947, -0.03136180713772774, -0.030465727671980858, -0.029569650068879128, -0.028673570603132248, -0.02777749113738537, -0.026881413534283638, -0.02598533406853676, -0.025089256465435028, -0.024193178862333298, -0.02329709753394127, -0.02240101993083954, -0.021504942327737808, -0.02060886099934578, -0.01971278339624405, -0.01881670579314232, -0.01792062819004059, -0.01702454686164856, -0.01612846925854683, -0.015232391655445099, -0.01433631032705307, -0.01344023272395134, -0.01254415512084961, -0.011648077517747879, -0.01075199618935585, -0.00985591858625412, -0.00895984098315239, -0.00806376338005066, -0.00716768205165863, -0.0062716044485569, -0.00537552684545517, -0.004479445517063141, -0.0035833679139614105, -0.00268729031085968, -0.0017912127077579498, -0.000895131379365921, 9.462237358093262e-07]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 6.0, 1.0, 6.0, 5.0, 7.0, 1.0, 10.0, 3.0, 2.0, 6.0, 2.0, 5.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 6.0, 8.0, 10.0, 7.0, 8.0, 9.0, 9.0, 7.0, 4.0, 4.0, 3.0, 1.0, 3.0, 3.0], "bins": [-0.09213781356811523, -0.09001818299293518, -0.08789855986833572, -0.08577892929315567, -0.08365930616855621, -0.08153967559337616, -0.0794200524687767, -0.07730042189359665, -0.07518079876899719, -0.07306116819381714, -0.07094153761863708, -0.06882191449403763, -0.06670228391885757, -0.06458266079425812, -0.062463030219078064, -0.06034340336918831, -0.05822377651929855, -0.0561041496694088, -0.05398452281951904, -0.05186489596962929, -0.04974526911973953, -0.04762563854455948, -0.045506011694669724, -0.04338638484477997, -0.04126675799489021, -0.03914713114500046, -0.0370275042951107, -0.03490787744522095, -0.032788246870040894, -0.03066862002015114, -0.028548993170261383, -0.026429370045661926, -0.024309739470481873, -0.02219010889530182, -0.020070485770702362, -0.01795085519552231, -0.01583123207092285, -0.013711601495742798, -0.011591978371143341, -0.009472347795963287, -0.007352724671363831, -0.005233094096183777, -0.003113463521003723, -0.0009938403964042664, 0.0011257901787757874, 0.003245413303375244, 0.005365043878555298, 0.007484667003154755, 0.009604297578334808, 0.011723928153514862, 0.013843551278114319, 0.015963181853294373, 0.01808280497789383, 0.020202435553073883, 0.02232205867767334, 0.024441689252853394, 0.026561319828033447, 0.028680942952632904, 0.030800573527812958, 0.032920196652412415, 0.03503982722759247, 0.03715945780277252, 0.03927907347679138, 0.041398704051971436, 0.04351833462715149]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3304752707481384, -0.3226672112941742, -0.3148591220378876, -0.30705106258392334, -0.2992430031299591, -0.2914349436759949, -0.28362685441970825, -0.275818794965744, -0.2680107355117798, -0.26020264625549316, -0.25239458680152893, -0.2445865273475647, -0.23677845299243927, -0.22897037863731384, -0.2211623191833496, -0.21335425972938538, -0.20554618537425995, -0.19773811101913452, -0.1899300515651703, -0.18212197721004486, -0.17431391775608063, -0.1665058434009552, -0.15869778394699097, -0.15088970959186554, -0.1430816352367401, -0.13527357578277588, -0.12746550142765045, -0.11965744197368622, -0.11184936761856079, -0.10404130816459656, -0.09623323380947113, -0.0884251743555069, -0.08061710000038147, -0.07280904054641724, -0.06500095129013062, -0.05719289183616638, -0.04938483238220215, -0.041576772928237915, -0.033768683671951294, -0.02596062421798706, -0.018152564764022827, -0.010344475507736206, -0.0025364160537719727, 0.005271643400192261, 0.013079702854156494, 0.020887792110443115, 0.02869585156440735, 0.03650391101837158, 0.0443120002746582, 0.052120059728622437, 0.05992811918258667, 0.0677361786365509, 0.07554426789283752, 0.08335232734680176, 0.09116038680076599, 0.09896844625473022, 0.10677653551101685, 0.11458459496498108, 0.12239265441894531, 0.13020074367523193, 0.13800880312919617, 0.1458168625831604, 0.15362492203712463, 0.16143301129341125, 0.1692410707473755]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 4.0, 7.0, 5.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16456250846385956, -0.160988911986351, -0.15741531550884247, -0.15384173393249512, -0.15026813745498657, -0.14669454097747803, -0.14312094449996948, -0.13954734802246094, -0.1359737515449524, -0.13240015506744385, -0.1288265585899353, -0.12525297701358795, -0.1216793805360794, -0.11810578405857086, -0.11453218758106232, -0.11095859110355377, -0.10738500207662582, -0.10381141304969788, -0.10023781657218933, -0.09666422009468079, -0.09309062361717224, -0.0895170345902443, -0.08594343811273575, -0.0823698416352272, -0.07879625260829926, -0.07522265613079071, -0.07164905965328217, -0.06807546317577362, -0.06450187414884567, -0.06092827767133713, -0.05735468119382858, -0.053781092166900635, -0.05020749568939209, -0.046633899211883545, -0.0430603101849556, -0.039486706256866455, -0.035913124680519104, -0.03233952820301056, -0.028765931725502014, -0.02519233524799347, -0.021618738770484924, -0.01804514229297638, -0.014471560716629028, -0.010897964239120483, -0.0073243677616119385, -0.0037507712841033936, -0.00017717480659484863, 0.0033964216709136963, 0.006970003247261047, 0.010543599724769592, 0.014117196202278137, 0.017690792679786682, 0.021264389157295227, 0.024837985634803772, 0.028411582112312317, 0.03198516368865967, 0.03555876016616821, 0.03913235664367676, 0.0427059531211853, 0.04627954959869385, 0.04985314607620239, 0.053426727652549744, 0.05700032413005829, 0.060573920607566833, 0.06414751708507538]}, "_runtime": 7673.219826221466, "_timestamp": 1585605042.8526957, "_step": 298}
{"Episode reward": -99.55280622166326, "Episode length": 999, "Policy Loss": -0.6465907096862793, "Value Loss": 0.06922217458486557, "_runtime": 7674.778625011444, "_timestamp": 1585605044.4114945, "_step": 299}
{"Episode reward": -99.58148973236537, "Episode length": 999, "Policy Loss": -0.6526319980621338, "Value Loss": 0.02995576336979866, "_runtime": 7676.277549505234, "_timestamp": 1585605045.910419, "_step": 300}
{"Episode reward": 1.5866483827833235, "Episode length": 987, "Policy Loss": -0.046507880091667175, "Value Loss": 9.749176025390625, "_runtime": 7676.819454908371, "_timestamp": 1585605046.4523244, "_step": 301}
{"Episode reward": 67.3571399960083, "Episode length": 328, "Policy Loss": 1.0065878629684448, "Value Loss": 28.888416290283203, "_runtime": 7678.368152618408, "_timestamp": 1585605048.001022, "_step": 302}
{"Episode reward": -99.59697789450738, "Episode length": 999, "Policy Loss": -0.687311589717865, "Value Loss": 0.058994341641664505, "_runtime": 7678.99852347374, "_timestamp": 1585605048.631393, "_step": 303}
{"Episode reward": 62.130509822879425, "Episode length": 382, "Policy Loss": 0.8030287027359009, "Value Loss": 24.020357131958008, "_runtime": 7680.498193264008, "_timestamp": 1585605050.1310627, "_step": 304}
{"Episode reward": -99.41034934165516, "Episode length": 999, "Policy Loss": -0.7365771532058716, "Value Loss": 0.07419034093618393, "_runtime": 7681.809597015381, "_timestamp": 1585605051.4424665, "_step": 305}
{"Episode reward": 16.15132620116978, "Episode length": 842, "Policy Loss": -0.046900659799575806, "Value Loss": 11.25990104675293, "_runtime": 7682.901966333389, "_timestamp": 1585605052.5348358, "_step": 306}
{"Episode reward": 27.39248184356242, "Episode length": 727, "Policy Loss": 0.07580124586820602, "Value Loss": 13.298023223876953, "_runtime": 7684.44314789772, "_timestamp": 1585605054.0760174, "_step": 307}
{"Episode reward": -99.44442519845188, "Episode length": 999, "Policy Loss": -0.7759974598884583, "Value Loss": 0.20770683884620667, "_runtime": 7685.988138914108, "_timestamp": 1585605055.6210084, "_step": 308}
{"Episode reward": -99.46579722810866, "Episode length": 999, "Policy Loss": -0.8080723881721497, "Value Loss": 0.03409601002931595, "_runtime": 7687.513231754303, "_timestamp": 1585605057.1461012, "_step": 309}
{"Episode reward": -99.57583341735744, "Episode length": 999, "Policy Loss": -0.8031561374664307, "Value Loss": 0.032947126775979996, "_runtime": 7688.275271654129, "_timestamp": 1585605057.9081411, "_step": 310}
{"Episode reward": 54.354066490882175, "Episode length": 459, "Policy Loss": 0.33858704566955566, "Value Loss": 20.0322208404541, "_runtime": 7689.860116481781, "_timestamp": 1585605059.492986, "_step": 311}
{"Episode reward": -99.55108170224129, "Episode length": 999, "Policy Loss": -0.7720104455947876, "Value Loss": 0.04924929514527321, "_runtime": 7690.3813099861145, "_timestamp": 1585605060.0141795, "_step": 312}
{"Episode reward": 68.48122742341349, "Episode length": 316, "Policy Loss": 0.8610025644302368, "Value Loss": 30.000612258911133, "_runtime": 7691.88259100914, "_timestamp": 1585605061.5154605, "_step": 313}
{"Episode reward": -99.45759090088985, "Episode length": 999, "Policy Loss": -0.7614750862121582, "Value Loss": 0.026128258556127548, "_runtime": 7693.4369161129, "_timestamp": 1585605063.0697856, "_step": 314}
{"Episode reward": -99.64602573438177, "Episode length": 999, "Policy Loss": -0.7478888034820557, "Value Loss": 0.09146013110876083, "_runtime": 7694.310350894928, "_timestamp": 1585605063.9432204, "_step": 315}
{"Episode reward": 41.26900668768593, "Episode length": 589, "Policy Loss": 0.3737238943576813, "Value Loss": 16.46317481994629, "_runtime": 7695.839874744415, "_timestamp": 1585605065.4727442, "_step": 316}
{"Episode reward": -99.71758758039074, "Episode length": 999, "Policy Loss": -0.7168317437171936, "Value Loss": 0.09247120469808578, "_runtime": 7697.02335357666, "_timestamp": 1585605066.656223, "_step": 317}
{"Episode reward": 23.94483672869832, "Episode length": 763, "Policy Loss": 0.1847720891237259, "Value Loss": 12.706256866455078, "_runtime": 7698.5260417461395, "_timestamp": 1585605068.1589112, "_step": 318}
{"Episode reward": -99.29668390423767, "Episode length": 999, "Policy Loss": -0.6639615893363953, "Value Loss": 0.07793905586004257, "_runtime": 7699.150260448456, "_timestamp": 1585605068.78313, "_step": 319}
{"Episode reward": 61.20992678915909, "Episode length": 390, "Policy Loss": 0.714138925075531, "Value Loss": 24.348222732543945, "_runtime": 7700.660877943039, "_timestamp": 1585605070.2937474, "_step": 320}
{"Episode reward": 1.3978369415285385, "Episode length": 987, "Policy Loss": -0.12581713497638702, "Value Loss": 9.726056098937988, "_runtime": 7701.432411193848, "_timestamp": 1585605071.0652807, "_step": 321}
{"Episode reward": 51.386352290428064, "Episode length": 489, "Policy Loss": 0.40026524662971497, "Value Loss": 19.871109008789062, "_runtime": 7702.527958393097, "_timestamp": 1585605072.1608279, "_step": 322}
{"Episode reward": 26.947677998737944, "Episode length": 734, "Policy Loss": 0.3003006875514984, "Value Loss": 12.61522388458252, "_runtime": 7704.0790429115295, "_timestamp": 1585605073.7119124, "_step": 323}
{"Episode reward": -99.41906031283295, "Episode length": 999, "Policy Loss": -0.7477257251739502, "Value Loss": 0.03329397365450859, "_runtime": 7705.342495203018, "_timestamp": 1585605074.9753647, "_step": 324}
{"Episode reward": 15.78437784885078, "Episode length": 846, "Policy Loss": 0.05643868073821068, "Value Loss": 11.4467191696167, "_runtime": 7706.852648496628, "_timestamp": 1585605076.485518, "_step": 325}
{"Episode reward": -99.54163533258114, "Episode length": 999, "Policy Loss": -0.8079236745834351, "Value Loss": 0.2850087285041809, "_runtime": 7708.398559331894, "_timestamp": 1585605078.0314288, "_step": 326}
{"Episode reward": -99.36518591119537, "Episode length": 999, "Policy Loss": -0.8330994248390198, "Value Loss": 0.10725077241659164, "_runtime": 7709.925213575363, "_timestamp": 1585605079.558083, "_step": 327}
{"Episode reward": -99.57628949245415, "Episode length": 999, "Policy Loss": -0.8604481220245361, "Value Loss": 0.05943332239985466, "_runtime": 7711.4813549518585, "_timestamp": 1585605081.1142244, "_step": 328}
{"Episode reward": -99.39253731462969, "Episode length": 999, "Policy Loss": -0.8654174208641052, "Value Loss": 0.02499343827366829, "_runtime": 7713.0892679691315, "_timestamp": 1585605082.7221375, "_step": 329}
{"Episode reward": -99.2585300839609, "Episode length": 999, "Policy Loss": -0.8640557527542114, "Value Loss": 0.022858746349811554, "_runtime": 7714.648370981216, "_timestamp": 1585605084.2812405, "_step": 330}
{"Episode reward": -99.48000574272454, "Episode length": 999, "Policy Loss": -0.8343177437782288, "Value Loss": 0.05544117093086243, "_runtime": 7715.542685508728, "_timestamp": 1585605085.175555, "_step": 331}
{"Episode reward": 43.75556459449238, "Episode length": 566, "Policy Loss": 0.17544768750667572, "Value Loss": 16.45442008972168, "_runtime": 7717.09873509407, "_timestamp": 1585605086.7316046, "_step": 332}
{"Episode reward": -99.83695454821434, "Episode length": 999, "Policy Loss": -0.7808877229690552, "Value Loss": 0.03434399142861366, "_runtime": 7717.8551387786865, "_timestamp": 1585605087.4880083, "_step": 333}
{"Episode reward": 53.037429321519056, "Episode length": 473, "Policy Loss": 0.6318027973175049, "Value Loss": 19.888154983520508, "_runtime": 7718.721972942352, "_timestamp": 1585605088.3548424, "_step": 334}
{"Episode reward": 42.98073228785017, "Episode length": 572, "Policy Loss": 0.3016852140426636, "Value Loss": 17.125661849975586, "_runtime": 7719.3829028606415, "_timestamp": 1585605089.0157723, "_step": 335}
{"Episode reward": 58.86611146393667, "Episode length": 413, "Policy Loss": 0.9186438322067261, "Value Loss": 22.299531936645508, "_runtime": 7720.8655598163605, "_timestamp": 1585605090.4984293, "_step": 336}
{"Episode reward": 1.4611405174144778, "Episode length": 989, "Policy Loss": 0.08188187330961227, "Value Loss": 9.281830787658691, "_runtime": 7721.36770606041, "_timestamp": 1585605091.0005755, "_step": 337}
{"Episode reward": 68.02142582757934, "Episode length": 320, "Policy Loss": 1.3320226669311523, "Value Loss": 28.52616310119629, "_runtime": 7722.862581253052, "_timestamp": 1585605092.4954507, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5199775099754333, "Value Loss": 0.023072509095072746, "_runtime": 7724.407735347748, "_timestamp": 1585605094.0406048, "_step": 339}
{"Episode reward": -99.65651164469172, "Episode length": 999, "Policy Loss": -0.4749163091182709, "Value Loss": 0.08092936873435974, "_runtime": 7725.8859322071075, "_timestamp": 1585605095.5188017, "_step": 340}
{"Episode reward": -99.51280718749483, "Episode length": 999, "Policy Loss": -0.4711669981479645, "Value Loss": 0.08533752709627151, "_runtime": 7727.4388518333435, "_timestamp": 1585605097.0717213, "_step": 341}
{"Episode reward": -99.28152931429806, "Episode length": 999, "Policy Loss": -0.4252398908138275, "Value Loss": 0.13510674238204956, "_runtime": 7728.990963459015, "_timestamp": 1585605098.623833, "_step": 342}
{"Episode reward": -99.4341100412058, "Episode length": 999, "Policy Loss": -0.44932880997657776, "Value Loss": 0.3141234517097473, "_runtime": 7730.519151210785, "_timestamp": 1585605100.1520207, "_step": 343}
{"Episode reward": -99.31434288371975, "Episode length": 999, "Policy Loss": -0.38921022415161133, "Value Loss": 0.18885323405265808, "_runtime": 7731.721609830856, "_timestamp": 1585605101.3544793, "_step": 344}
{"Episode reward": 23.150437323673486, "Episode length": 770, "Policy Loss": 0.34284573793411255, "Value Loss": 13.03955364227295, "_runtime": 7733.28866147995, "_timestamp": 1585605102.921531, "_step": 345}
{"Episode reward": -99.63231094832743, "Episode length": 999, "Policy Loss": -0.3186663091182709, "Value Loss": 0.05271592363715172, "_runtime": 7734.848953008652, "_timestamp": 1585605104.4818225, "_step": 346}
{"Episode reward": -99.5940309347222, "Episode length": 999, "Policy Loss": -0.30980193614959717, "Value Loss": 0.13750553131103516, "_runtime": 7735.766515493393, "_timestamp": 1585605105.399385, "_step": 347}
{"Episode reward": 44.29157629475761, "Episode length": 559, "Policy Loss": 0.9093138575553894, "Value Loss": 16.743661880493164, "_runtime": 7737.323223114014, "_timestamp": 1585605106.9560926, "_step": 348}
{"Episode reward": -99.81626426586742, "Episode length": 999, "Policy Loss": -0.2895376682281494, "Value Loss": 0.025546949356794357, "_runtime": 7738.884791851044, "_timestamp": 1585605108.5176613, "_step": 349}
{"Episode reward": -99.5381701594554, "Episode length": 999, "Policy Loss": -0.28902876377105713, "Value Loss": 0.04346593841910362, "_runtime": 7740.398331403732, "_timestamp": 1585605110.031201, "_step": 350}
{"Episode reward": -99.47491831673403, "Episode length": 999, "Policy Loss": -0.2738378047943115, "Value Loss": 0.06862796097993851, "_runtime": 7741.602722406387, "_timestamp": 1585605111.235592, "_step": 351}
{"Episode reward": 23.87889188167179, "Episode length": 765, "Policy Loss": 0.4383559823036194, "Value Loss": 12.163496017456055, "_runtime": 7743.153112411499, "_timestamp": 1585605112.785982, "_step": 352}
{"Episode reward": -99.5328107772323, "Episode length": 999, "Policy Loss": -0.28015702962875366, "Value Loss": 0.011002139188349247, "_runtime": 7744.717742919922, "_timestamp": 1585605114.3506124, "_step": 353}
{"Episode reward": -99.72428906759458, "Episode length": 999, "Policy Loss": -0.28663700819015503, "Value Loss": 0.003968226257711649, "_runtime": 7746.260668039322, "_timestamp": 1585605115.8935375, "_step": 354}
{"Episode reward": -99.49281957610374, "Episode length": 999, "Policy Loss": -0.27726447582244873, "Value Loss": 0.010012952610850334, "_runtime": 7747.822086572647, "_timestamp": 1585605117.454956, "_step": 355}
{"Episode reward": -99.65260648859991, "Episode length": 999, "Policy Loss": -0.2711026668548584, "Value Loss": 0.014437495730817318, "_runtime": 7749.390079021454, "_timestamp": 1585605119.0229485, "_step": 356}
{"Episode reward": -99.19750055267222, "Episode length": 999, "Policy Loss": -0.24401171505451202, "Value Loss": 0.13218119740486145, "_runtime": 7750.948004961014, "_timestamp": 1585605120.5808744, "_step": 357}
{"Episode reward": -99.59507691754122, "Episode length": 999, "Policy Loss": -0.2401726245880127, "Value Loss": 0.0060394941829144955, "_runtime": 7752.510340690613, "_timestamp": 1585605122.1432102, "_step": 358}
{"Episode reward": -99.59550246129373, "Episode length": 999, "Policy Loss": -0.21997299790382385, "Value Loss": 0.014638891443610191, "_runtime": 7753.517796039581, "_timestamp": 1585605123.1506655, "_step": 359}
{"Episode reward": 37.40079560236711, "Episode length": 628, "Policy Loss": 0.6483855843544006, "Value Loss": 14.92424201965332, "_runtime": 7754.876212596893, "_timestamp": 1585605124.509082, "_step": 360}
{"Episode reward": 13.208233596484135, "Episode length": 871, "Policy Loss": 0.5171414613723755, "Value Loss": 11.026246070861816, "_runtime": 7755.599598646164, "_timestamp": 1585605125.2324681, "_step": 361}
{"Episode reward": 54.9998830183813, "Episode length": 451, "Policy Loss": 1.0631537437438965, "Value Loss": 21.0234317779541, "_runtime": 7757.139236211777, "_timestamp": 1585605126.7721057, "_step": 362}
{"Episode reward": -99.51034706742364, "Episode length": 999, "Policy Loss": -0.21320447325706482, "Value Loss": 0.013725047931075096, "_runtime": 7758.700075387955, "_timestamp": 1585605128.3329449, "_step": 363}
{"Episode reward": -99.66793153631595, "Episode length": 999, "Policy Loss": -0.23296372592449188, "Value Loss": 0.0029029245488345623, "_runtime": 7760.248711824417, "_timestamp": 1585605129.8815813, "_step": 364}
{"Episode reward": -99.65580409120894, "Episode length": 999, "Policy Loss": -0.20445948839187622, "Value Loss": 0.072768434882164, "_runtime": 7761.212689876556, "_timestamp": 1585605130.8455594, "_step": 365}
{"Episode reward": 39.05461098807223, "Episode length": 614, "Policy Loss": 0.7205994725227356, "Value Loss": 15.09943962097168, "_runtime": 7762.767484426498, "_timestamp": 1585605132.400354, "_step": 366}
{"Episode reward": -99.63323454517385, "Episode length": 999, "Policy Loss": -0.21496137976646423, "Value Loss": 0.007978594861924648, "_runtime": 7763.962956666946, "_timestamp": 1585605133.5958261, "_step": 367}
{"Episode reward": 23.471170952299218, "Episode length": 770, "Policy Loss": 0.5401342511177063, "Value Loss": 11.831334114074707, "_runtime": 7765.362094640732, "_timestamp": 1585605134.9949641, "_step": 368}
{"Episode reward": 8.844205701974886, "Episode length": 917, "Policy Loss": 0.42363670468330383, "Value Loss": 9.978442192077637, "_runtime": 7766.915092945099, "_timestamp": 1585605136.5479624, "_step": 369}
{"Episode reward": -99.37186283792697, "Episode length": 999, "Policy Loss": -0.2288258671760559, "Value Loss": 0.06061436980962753, "_runtime": 7768.449582338333, "_timestamp": 1585605138.0824518, "_step": 370}
{"Episode reward": -99.65083363145685, "Episode length": 999, "Policy Loss": -0.24270956218242645, "Value Loss": 0.011801258660852909, "_runtime": 7769.451132297516, "_timestamp": 1585605139.0840018, "_step": 371}
{"Episode reward": 36.181253462278356, "Episode length": 639, "Policy Loss": 0.4756571054458618, "Value Loss": 13.923311233520508, "_runtime": 7771.003390073776, "_timestamp": 1585605140.6362596, "_step": 372}
{"Episode reward": -99.7448560573496, "Episode length": 999, "Policy Loss": -0.27015647292137146, "Value Loss": 0.007630515843629837, "_runtime": 7772.54350733757, "_timestamp": 1585605142.1763768, "_step": 373}
{"Episode reward": -99.62339838711202, "Episode length": 999, "Policy Loss": -0.2864561975002289, "Value Loss": 0.02595476806163788, "_runtime": 7773.927311420441, "_timestamp": 1585605143.560181, "_step": 374}
{"Episode reward": 10.275667011476699, "Episode length": 899, "Policy Loss": 0.28970304131507874, "Value Loss": 10.68220329284668, "_runtime": 7775.258664608002, "_timestamp": 1585605144.891534, "_step": 375}
{"Episode reward": 15.829032778936892, "Episode length": 849, "Policy Loss": 0.32285717129707336, "Value Loss": 10.638711929321289, "_runtime": 7776.807233572006, "_timestamp": 1585605146.440103, "_step": 376}
{"Episode reward": -99.28350009938593, "Episode length": 999, "Policy Loss": -0.29571545124053955, "Value Loss": 0.05557394027709961, "_runtime": 7778.213015556335, "_timestamp": 1585605147.845885, "_step": 377}
{"Episode reward": 9.742632892687965, "Episode length": 907, "Policy Loss": 0.2837183177471161, "Value Loss": 10.164558410644531, "_runtime": 7779.762510538101, "_timestamp": 1585605149.39538, "_step": 378}
{"Episode reward": -99.55475182441158, "Episode length": 999, "Policy Loss": -0.29814013838768005, "Value Loss": 0.021649125963449478, "_runtime": 7781.316064596176, "_timestamp": 1585605150.948934, "_step": 379}
{"Episode reward": -99.34416594219084, "Episode length": 999, "Policy Loss": -0.25502315163612366, "Value Loss": 0.0959915816783905, "_runtime": 7782.890355348587, "_timestamp": 1585605152.5232248, "_step": 380}
{"Episode reward": -99.58688684243688, "Episode length": 999, "Policy Loss": -0.27849623560905457, "Value Loss": 0.025342745706439018, "_runtime": 7784.449767112732, "_timestamp": 1585605154.0826366, "_step": 381}
{"Episode reward": -99.31666895389797, "Episode length": 999, "Policy Loss": -0.2692491412162781, "Value Loss": 0.013243181630969048, "_runtime": 7786.004667758942, "_timestamp": 1585605155.6375372, "_step": 382}
{"Episode reward": -99.66369391240303, "Episode length": 999, "Policy Loss": -0.26570528745651245, "Value Loss": 0.019250664860010147, "_runtime": 7787.567927122116, "_timestamp": 1585605157.2007966, "_step": 383}
{"Episode reward": -99.11373690640184, "Episode length": 999, "Policy Loss": -0.2501467168331146, "Value Loss": 0.006588307209312916, "_runtime": 7789.136011123657, "_timestamp": 1585605158.7688806, "_step": 384}
{"Episode reward": -99.48222617795552, "Episode length": 999, "Policy Loss": -0.24628177285194397, "Value Loss": 0.005666087381541729, "_runtime": 7789.709184885025, "_timestamp": 1585605159.3420544, "_step": 385}
{"Episode reward": 65.8555243543347, "Episode length": 342, "Policy Loss": 1.2666759490966797, "Value Loss": 27.455520629882812, "_runtime": 7791.213536262512, "_timestamp": 1585605160.8464057, "_step": 386}
{"Episode reward": 3.248897477787736, "Episode length": 971, "Policy Loss": 0.3162887692451477, "Value Loss": 9.434832572937012, "_runtime": 7791.8751764297485, "_timestamp": 1585605161.508046, "_step": 387}
{"Episode reward": 59.84672573145333, "Episode length": 403, "Policy Loss": 1.1624786853790283, "Value Loss": 21.486465454101562, "_runtime": 7793.377281427383, "_timestamp": 1585605163.010151, "_step": 388}
{"Episode reward": -99.46668993006469, "Episode length": 999, "Policy Loss": -0.23108166456222534, "Value Loss": 0.00925523042678833, "_runtime": 7794.020787000656, "_timestamp": 1585605163.6536565, "_step": 389}
{"Episode reward": 61.14155460959273, "Episode length": 389, "Policy Loss": 1.052640438079834, "Value Loss": 22.282114028930664, "_runtime": 7795.531202554703, "_timestamp": 1585605165.164072, "_step": 390}
{"Episode reward": -99.71690600899025, "Episode length": 999, "Policy Loss": -0.20252709090709686, "Value Loss": 0.017953108996152878, "_runtime": 7796.967465639114, "_timestamp": 1585605166.6003351, "_step": 391}
{"Episode reward": 8.570044765133417, "Episode length": 918, "Policy Loss": 0.6110460162162781, "Value Loss": 9.757078170776367, "_runtime": 7798.473538637161, "_timestamp": 1585605168.106408, "_step": 392}
{"Episode reward": -99.54461123154476, "Episode length": 999, "Policy Loss": -0.19398754835128784, "Value Loss": 0.014410137198865414, "_runtime": 7799.324444293976, "_timestamp": 1585605168.9573138, "_step": 393}
{"Episode reward": 47.011174067522624, "Episode length": 531, "Policy Loss": 0.8658109903335571, "Value Loss": 16.77461814880371, "_runtime": 7800.870409965515, "_timestamp": 1585605170.5032794, "_step": 394}
{"Episode reward": -99.36170089563248, "Episode length": 999, "Policy Loss": -0.23381170630455017, "Value Loss": 0.14005662500858307, "_runtime": 7802.422908782959, "_timestamp": 1585605172.0557783, "_step": 395}
{"Episode reward": -99.47597064197042, "Episode length": 999, "Policy Loss": -0.22372134029865265, "Value Loss": 0.0330837108194828, "_runtime": 7803.933505773544, "_timestamp": 1585605173.5663753, "_step": 396}
{"Episode reward": -99.10811967754863, "Episode length": 999, "Policy Loss": -0.23738987743854523, "Value Loss": 0.02286965399980545, "_runtime": 7804.5703184604645, "_timestamp": 1585605174.203188, "_step": 397}
{"Episode reward": 61.580437053260994, "Episode length": 386, "Policy Loss": 1.0816160440444946, "Value Loss": 24.04346466064453, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819, 0.8031133413314819]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8031133413314819, -0.6244344711303711, -0.44575560092926025, -0.2670767307281494, -0.08839786052703857, 0.09028100967407227, 0.2689598798751831, 0.44763875007629395, 0.6263176202774048, 0.8049964904785156, 0.9836753606796265, 1.1623542308807373, 1.3410331010818481, 1.5197120904922485, 1.6983908414840698, 1.8770695924758911, 2.055748462677002, 2.2344274520874023, 2.4131064414978027, 2.591784954071045, 2.7704639434814453, 2.9491429328918457, 3.127821922302246, 3.3065004348754883, 3.4851794242858887, 3.663858413696289, 3.8425374031066895, 4.021215915679932, 4.199894905090332, 4.378573894500732, 4.557252407073975, 4.735931396484375, 4.914610385894775, 5.093289375305176, 5.271968364715576, 5.450646877288818, 5.629325866699219, 5.808004856109619, 5.986683368682861, 6.165362358093262, 6.344041347503662, 6.5227203369140625, 6.701399326324463, 6.880077838897705, 7.0587568283081055, 7.237435817718506, 7.416114330291748, 7.594793796539307, 7.773472309112549, 7.952150821685791, 8.130830764770508, 8.30950927734375, 8.488188743591309, 8.66686725616455, 8.845545768737793, 9.024225234985352, 9.202903747558594, 9.381582260131836, 9.560261726379395, 9.738940238952637, 9.917618751525879, 10.096298217773438, 10.27497673034668, 10.453656196594238, 10.63233470916748]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.4987674603617052e-06, 0.018640795722603798, 0.037283092737197876, 0.055925387889146805, 0.07456768304109573, 0.09320997446775436, 0.11185227334499359, 0.13049456477165222, 0.14913685619831085, 0.16777914762496948, 0.1864214390516281, 0.20506374537944794, 0.22370603680610657, 0.2423483282327652, 0.2609906494617462, 0.27963292598724365, 0.2982752323150635, 0.3169175386428833, 0.33555981516838074, 0.35420212149620056, 0.372844398021698, 0.3914867043495178, 0.41012901067733765, 0.4287712872028351, 0.4474135935306549, 0.46605589985847473, 0.48469817638397217, 0.503340482711792, 0.5219827890396118, 0.5406250953674316, 0.5592673420906067, 0.5779096484184265, 0.5965519547462463, 0.6151942610740662, 0.633836567401886, 0.652478814125061, 0.6711211204528809, 0.6897634267807007, 0.7084057331085205, 0.7270480394363403, 0.7456902861595154, 0.7643325924873352, 0.782974898815155, 0.8016172051429749, 0.8202595114707947, 0.8389018177986145, 0.8575440645217896, 0.8761863708496094, 0.8948286771774292, 0.913470983505249, 0.9321132898330688, 0.9507555365562439, 0.9693978428840637, 0.9880401492118835, 1.0066823959350586, 1.0253247022628784, 1.0439670085906982, 1.062609314918518, 1.081251621246338, 1.0998938083648682, 1.118536114692688, 1.1371784210205078, 1.1558207273483276, 1.1744630336761475, 1.1931053400039673]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 2.0, 4.0, 4.0, 7.0, 10.0, 10.0, 12.0, 12.0, 5.0, 9.0, 8.0, 3.0, 1.0, 5.0, 13.0, 320.0, 0.0, 1.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 2.0, 4.0, 1.0, 4.0, 3.0, 4.0, 4.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9088978171348572, -0.8534934520721436, -0.7980891466140747, -0.7426847815513611, -0.6872804164886475, -0.6318761110305786, -0.576471745967865, -0.5210673809051514, -0.4656630754470825, -0.4102587401866913, -0.35485440492630005, -0.2994500398635864, -0.2440456748008728, -0.18864136934280396, -0.13323700428009033, -0.07783269882202148, -0.02242833375930786, 0.03297603130340576, 0.08838033676147461, 0.14378470182418823, 0.19918900728225708, 0.2545934319496155, 0.3099977374076843, 0.3654020428657532, 0.4208064675331116, 0.4762107729911804, 0.5316150784492493, 0.5870193839073181, 0.6424238085746765, 0.6978281140327454, 0.7532324194908142, 0.8086368441581726, 0.8640411496162415, 0.9194454550743103, 0.9748498797416687, 1.0302541255950928, 1.0856585502624512, 1.1410627365112305, 1.1964671611785889, 1.2518715858459473, 1.3072757720947266, 1.362680196762085, 1.4180846214294434, 1.4734888076782227, 1.528893232345581, 1.5842976570129395, 1.6397018432617188, 1.6951062679290771, 1.7505106925964355, 1.8059148788452148, 1.8613193035125732, 1.9167234897613525, 1.972127914428711, 2.0275323390960693, 2.0829365253448486, 2.138340950012207, 2.1937453746795654, 2.2491495609283447, 2.304553985595703, 2.3599584102630615, 2.415362596511841, 2.470767021179199, 2.5261714458465576, 2.581575632095337, 2.6369800567626953]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-5.095102310180664, -4.926042079925537, -4.756982326507568, -4.587922096252441, -4.4188618659973145, -4.249802112579346, -4.080741882324219, -3.911681890487671, -3.742621898651123, -3.573561668395996, -3.4045016765594482, -3.2354416847229004, -3.0663814544677734, -2.8973214626312256, -2.7282614707946777, -2.559201240539551, -2.390141248703003, -2.221081256866455, -2.052021026611328, -1.8829610347747803, -1.7139010429382324, -1.5448408126831055, -1.3757808208465576, -1.2067208290100098, -1.0376605987548828, -0.8686008453369141, -0.6995406150817871, -0.5304803848266602, -0.3614206314086914, -0.19236040115356445, -0.0233001708984375, 0.14575958251953125, 0.3148198127746582, 0.48388004302978516, 0.6529397964477539, 0.8220000267028809, 0.9910602569580078, 1.1601200103759766, 1.3291802406311035, 1.4982404708862305, 1.6673002243041992, 1.8363604545593262, 2.005420684814453, 2.174480438232422, 2.343540668487549, 2.512600898742676, 2.6816606521606445, 2.8507208824157715, 3.0197811126708984, 3.188840866088867, 3.357900619506836, 3.526961326599121, 3.69602108001709, 3.8650808334350586, 4.034141540527344, 4.2032012939453125, 4.372261047363281, 4.541321754455566, 4.710381507873535, 4.879441261291504, 5.048501968383789, 5.217561721801758, 5.386621475219727, 5.555682182312012, 5.7247419357299805]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 5.0, 5.0, 5.0, 6.0, 6.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-6.629480361938477, -6.47749662399292, -6.325512886047363, -6.173529148101807, -6.02154541015625, -5.869562149047852, -5.717578411102295, -5.565594673156738, -5.413610935211182, -5.261627197265625, -5.109643459320068, -4.957659721374512, -4.805676460266113, -4.653692245483398, -4.501708984375, -4.349725246429443, -4.197741508483887, -4.04575777053833, -3.8937740325927734, -3.741790533065796, -3.5898067951202393, -3.4378230571746826, -3.285839557647705, -3.1338558197021484, -2.981872081756592, -2.829888343811035, -2.6779046058654785, -2.525920867919922, -2.3739376068115234, -2.221953868865967, -2.06997013092041, -1.9179863929748535, -1.7660026550292969, -1.6140189170837402, -1.4620351791381836, -1.310051441192627, -1.1580677032470703, -1.0060844421386719, -0.8541007041931152, -0.7021169662475586, -0.550133228302002, -0.3981494903564453, -0.24616575241088867, -0.09418201446533203, 0.057801246643066406, 0.20978498458862305, 0.3617687225341797, 0.5137524604797363, 0.665736198425293, 0.8177199363708496, 0.9697036743164062, 1.121687412261963, 1.2736711502075195, 1.425654411315918, 1.5776386260986328, 1.7296218872070312, 1.8816051483154297, 2.0335893630981445, 2.185572624206543, 2.337556838989258, 2.4895401000976562, 2.641524314880371, 2.7935075759887695, 2.9454917907714844, 3.097475051879883]}, "_runtime": 7805.4045741558075, "_timestamp": 1585605175.0374436, "_step": 398}
{"Episode reward": 47.338454469042595, "Episode length": 530, "Policy Loss": 0.6903224587440491, "Value Loss": 17.240896224975586, "_runtime": 7805.799255847931, "_timestamp": 1585605175.4321253, "_step": 399}
{"Episode reward": 77.64566900035129, "Episode length": 225, "Policy Loss": 2.1927144527435303, "Value Loss": 41.349891662597656, "_runtime": 7806.750212907791, "_timestamp": 1585605176.3830824, "_step": 400}
{"Episode reward": 38.94071286678604, "Episode length": 611, "Policy Loss": 0.5028403997421265, "Value Loss": 14.649948120117188, "_runtime": 7808.278418779373, "_timestamp": 1585605177.9112883, "_step": 401}
{"Episode reward": -99.69709013225953, "Episode length": 999, "Policy Loss": -0.4558959901332855, "Value Loss": 0.17932306230068207, "_runtime": 7809.764054775238, "_timestamp": 1585605179.3969243, "_step": 402}
{"Episode reward": -99.58768966761424, "Episode length": 999, "Policy Loss": -0.4730319380760193, "Value Loss": 0.24328096210956573, "_runtime": 7811.280697345734, "_timestamp": 1585605180.9135668, "_step": 403}
{"Episode reward": -99.62351313513797, "Episode length": 999, "Policy Loss": -0.539070725440979, "Value Loss": 0.10697174072265625, "_runtime": 7812.839426517487, "_timestamp": 1585605182.472296, "_step": 404}
{"Episode reward": -99.52865179860827, "Episode length": 999, "Policy Loss": -0.5662019848823547, "Value Loss": 0.041748661547899246, "_runtime": 7813.581468820572, "_timestamp": 1585605183.2143383, "_step": 405}
{"Episode reward": 52.86382602322225, "Episode length": 472, "Policy Loss": 0.5148842930793762, "Value Loss": 19.928743362426758, "_runtime": 7814.9669880867, "_timestamp": 1585605184.5998576, "_step": 406}
{"Episode reward": 11.276143699802233, "Episode length": 892, "Policy Loss": -0.07908131927251816, "Value Loss": 10.355268478393555, "_runtime": 7816.361493349075, "_timestamp": 1585605185.9943628, "_step": 407}
{"Episode reward": 10.936355869554305, "Episode length": 893, "Policy Loss": -0.04059307649731636, "Value Loss": 10.60507869720459, "_runtime": 7817.870530605316, "_timestamp": 1585605187.5034, "_step": 408}
{"Episode reward": -99.15253448155136, "Episode length": 999, "Policy Loss": -0.710516095161438, "Value Loss": 0.19124464690685272, "_runtime": 7818.906886339188, "_timestamp": 1585605188.5397558, "_step": 409}
{"Episode reward": 34.31532890110921, "Episode length": 659, "Policy Loss": 0.10931996256113052, "Value Loss": 14.808829307556152, "_runtime": 7819.87063908577, "_timestamp": 1585605189.5035086, "_step": 410}
{"Episode reward": 38.08051335845897, "Episode length": 621, "Policy Loss": 0.08594551682472229, "Value Loss": 15.091811180114746, "_runtime": 7821.419027328491, "_timestamp": 1585605191.0518968, "_step": 411}
{"Episode reward": -99.4354421115714, "Episode length": 999, "Policy Loss": -0.8203907608985901, "Value Loss": 0.07274754345417023, "_runtime": 7822.439164638519, "_timestamp": 1585605192.0720341, "_step": 412}
{"Episode reward": 34.49786561703604, "Episode length": 656, "Policy Loss": -0.006750316359102726, "Value Loss": 14.255180358886719, "_runtime": 7823.963082313538, "_timestamp": 1585605193.5959518, "_step": 413}
{"Episode reward": -99.52924773464336, "Episode length": 999, "Policy Loss": -0.9118964672088623, "Value Loss": 0.0902930349111557, "_runtime": 7825.4980618953705, "_timestamp": 1585605195.1309314, "_step": 414}
{"Episode reward": -98.7614967593386, "Episode length": 999, "Policy Loss": -0.9211726188659668, "Value Loss": 0.2840639650821686, "_runtime": 7827.027623653412, "_timestamp": 1585605196.6604931, "_step": 415}
{"Episode reward": -99.33875577973677, "Episode length": 999, "Policy Loss": -0.943594753742218, "Value Loss": 0.18153320252895355, "_runtime": 7828.589161157608, "_timestamp": 1585605198.2220306, "_step": 416}
{"Episode reward": -99.08869805317381, "Episode length": 999, "Policy Loss": -0.9219123125076294, "Value Loss": 0.05196696147322655, "_runtime": 7829.516532897949, "_timestamp": 1585605199.1494024, "_step": 417}
{"Episode reward": 41.83017727528877, "Episode length": 583, "Policy Loss": -0.042336590588092804, "Value Loss": 17.282827377319336, "_runtime": 7831.03986954689, "_timestamp": 1585605200.672739, "_step": 418}
{"Episode reward": 4.880057957525096, "Episode length": 953, "Policy Loss": -0.3033691644668579, "Value Loss": 10.024981498718262, "_runtime": 7831.694162845612, "_timestamp": 1585605201.3270323, "_step": 419}
{"Episode reward": 60.202761272489155, "Episode length": 399, "Policy Loss": 0.5375664234161377, "Value Loss": 21.511478424072266, "_runtime": 7833.215599298477, "_timestamp": 1585605202.8484688, "_step": 420}
{"Episode reward": -99.05071864162467, "Episode length": 999, "Policy Loss": -0.7646468877792358, "Value Loss": 0.06736037135124207, "_runtime": 7834.774865627289, "_timestamp": 1585605204.407735, "_step": 421}
{"Episode reward": -99.20523058104018, "Episode length": 999, "Policy Loss": -0.6699955463409424, "Value Loss": 0.11396903544664383, "_runtime": 7836.270835876465, "_timestamp": 1585605205.9037054, "_step": 422}
{"Episode reward": -99.32737971621546, "Episode length": 999, "Policy Loss": -0.6030600666999817, "Value Loss": 0.08962192386388779, "_runtime": 7837.828698158264, "_timestamp": 1585605207.4615676, "_step": 423}
{"Episode reward": -99.23968754027163, "Episode length": 999, "Policy Loss": -0.5242323875427246, "Value Loss": 0.03802122548222542, "_runtime": 7839.396667003632, "_timestamp": 1585605209.0295365, "_step": 424}
{"Episode reward": -99.46298281388164, "Episode length": 999, "Policy Loss": -0.5100501179695129, "Value Loss": 0.20393799245357513, "_runtime": 7840.942214250565, "_timestamp": 1585605210.5750837, "_step": 425}
{"Episode reward": -99.40963090591403, "Episode length": 999, "Policy Loss": -0.4442906379699707, "Value Loss": 0.11770250648260117, "_runtime": 7842.5124526023865, "_timestamp": 1585605212.145322, "_step": 426}
{"Episode reward": -99.16084211929275, "Episode length": 999, "Policy Loss": -0.4002254903316498, "Value Loss": 0.06085842475295067, "_runtime": 7844.081069231033, "_timestamp": 1585605213.7139387, "_step": 427}
{"Episode reward": -99.48183043613106, "Episode length": 999, "Policy Loss": -0.36241576075553894, "Value Loss": 0.007808047812432051, "_runtime": 7845.356829166412, "_timestamp": 1585605214.9896986, "_step": 428}
{"Episode reward": 19.141127872234534, "Episode length": 813, "Policy Loss": 0.503600001335144, "Value Loss": 11.82062816619873, "_runtime": 7846.008947134018, "_timestamp": 1585605215.6418166, "_step": 429}
{"Episode reward": 60.2001346168964, "Episode length": 399, "Policy Loss": 0.9773446321487427, "Value Loss": 24.092021942138672, "_runtime": 7846.6769251823425, "_timestamp": 1585605216.3097947, "_step": 430}
{"Episode reward": 58.70039830947468, "Episode length": 414, "Policy Loss": 0.8146586418151855, "Value Loss": 21.963241577148438, "_runtime": 7847.961492776871, "_timestamp": 1585605217.5943623, "_step": 431}
{"Episode reward": 17.069370241962744, "Episode length": 832, "Policy Loss": 0.24581927061080933, "Value Loss": 11.310832023620605, "_runtime": 7848.582962036133, "_timestamp": 1585605218.2158315, "_step": 432}
{"Episode reward": 59.86060236266174, "Episode length": 403, "Policy Loss": 0.9808840155601501, "Value Loss": 24.684005737304688, "_runtime": 7849.851516962051, "_timestamp": 1585605219.4843864, "_step": 433}
{"Episode reward": 15.251289598383096, "Episode length": 854, "Policy Loss": 0.40390628576278687, "Value Loss": 11.027609825134277, "_runtime": 7850.855376243591, "_timestamp": 1585605220.4882457, "_step": 434}
{"Episode reward": 36.04254505170184, "Episode length": 641, "Policy Loss": 0.22106558084487915, "Value Loss": 14.617085456848145, "_runtime": 7852.302070379257, "_timestamp": 1585605221.9349399, "_step": 435}
{"Episode reward": 3.750030447286264, "Episode length": 970, "Policy Loss": -0.10142147541046143, "Value Loss": 9.565930366516113, "_runtime": 7853.8703734874725, "_timestamp": 1585605223.503243, "_step": 436}
{"Episode reward": -98.93071874143072, "Episode length": 999, "Policy Loss": -0.6500460505485535, "Value Loss": 0.061296917498111725, "_runtime": 7855.3972425460815, "_timestamp": 1585605225.030112, "_step": 437}
{"Episode reward": -99.29124277727831, "Episode length": 999, "Policy Loss": -0.6657646894454956, "Value Loss": 0.5971169471740723, "_runtime": 7856.387807369232, "_timestamp": 1585605226.0206769, "_step": 438}
{"Episode reward": 36.93327768076935, "Episode length": 631, "Policy Loss": 0.08271655440330505, "Value Loss": 14.071745872497559, "_runtime": 7857.532871246338, "_timestamp": 1585605227.1657407, "_step": 439}
{"Episode reward": 27.270677226262194, "Episode length": 732, "Policy Loss": 0.14685966074466705, "Value Loss": 12.638591766357422, "_runtime": 7858.289346933365, "_timestamp": 1585605227.9222164, "_step": 440}
{"Episode reward": 53.24183519554606, "Episode length": 470, "Policy Loss": 0.31538698077201843, "Value Loss": 18.256013870239258, "_runtime": 7859.304620981216, "_timestamp": 1585605228.9374905, "_step": 441}
{"Episode reward": 34.27677784328063, "Episode length": 660, "Policy Loss": -0.056495632976293564, "Value Loss": 13.07983684539795, "_runtime": 7860.238274097443, "_timestamp": 1585605229.8711436, "_step": 442}
{"Episode reward": 39.884119105598955, "Episode length": 602, "Policy Loss": 0.3384522795677185, "Value Loss": 14.978911399841309, "_runtime": 7861.746714830399, "_timestamp": 1585605231.3795843, "_step": 443}
{"Episode reward": -99.5055217229529, "Episode length": 999, "Policy Loss": -0.7484825849533081, "Value Loss": 0.28427591919898987, "_runtime": 7863.271336078644, "_timestamp": 1585605232.9042056, "_step": 444}
{"Episode reward": -99.48346010039684, "Episode length": 999, "Policy Loss": -0.7852519154548645, "Value Loss": 0.3067744970321655, "_runtime": 7864.792941093445, "_timestamp": 1585605234.4258106, "_step": 445}
{"Episode reward": -99.64161462582568, "Episode length": 999, "Policy Loss": -0.7168192267417908, "Value Loss": 0.07700782269239426, "_runtime": 7866.2141127586365, "_timestamp": 1585605235.8469822, "_step": 446}
{"Episode reward": 8.586634863157272, "Episode length": 918, "Policy Loss": -0.16440218687057495, "Value Loss": 9.570928573608398, "_runtime": 7867.772671699524, "_timestamp": 1585605237.4055412, "_step": 447}
{"Episode reward": -99.57626566579135, "Episode length": 999, "Policy Loss": -0.7240334749221802, "Value Loss": 0.03474525734782219, "_runtime": 7868.791749000549, "_timestamp": 1585605238.4246185, "_step": 448}
{"Episode reward": 36.12301986153262, "Episode length": 642, "Policy Loss": 0.02327648736536503, "Value Loss": 13.770730018615723, "_runtime": 7869.610989809036, "_timestamp": 1585605239.2438593, "_step": 449}
{"Episode reward": 48.61418895031047, "Episode length": 516, "Policy Loss": 0.2307635396718979, "Value Loss": 16.40159797668457, "_runtime": 7871.16609954834, "_timestamp": 1585605240.798969, "_step": 450}
{"Episode reward": -99.47729757591158, "Episode length": 999, "Policy Loss": -0.763617992401123, "Value Loss": 0.06865357607603073, "_runtime": 7872.697642326355, "_timestamp": 1585605242.3305118, "_step": 451}
{"Episode reward": -99.4963212006857, "Episode length": 999, "Policy Loss": -0.7567555904388428, "Value Loss": 0.037341129034757614, "_runtime": 7874.211996555328, "_timestamp": 1585605243.844866, "_step": 452}
{"Episode reward": -99.38139159558786, "Episode length": 999, "Policy Loss": -0.7215409874916077, "Value Loss": 0.02653634361922741, "_runtime": 7875.763726472855, "_timestamp": 1585605245.396596, "_step": 453}
{"Episode reward": -99.35864487063962, "Episode length": 999, "Policy Loss": -0.6321655511856079, "Value Loss": 0.10927379131317139, "_runtime": 7877.354706764221, "_timestamp": 1585605246.9875762, "_step": 454}
{"Episode reward": -99.0854051272313, "Episode length": 999, "Policy Loss": -0.584855318069458, "Value Loss": 0.05720473453402519, "_runtime": 7878.191172361374, "_timestamp": 1585605247.8240418, "_step": 455}
{"Episode reward": 47.776027893489925, "Episode length": 525, "Policy Loss": 0.6226807236671448, "Value Loss": 16.527151107788086, "_runtime": 7879.7543206214905, "_timestamp": 1585605249.38719, "_step": 456}
{"Episode reward": -99.56464947927022, "Episode length": 999, "Policy Loss": -0.44328492879867554, "Value Loss": 0.016805723309516907, "_runtime": 7881.323534488678, "_timestamp": 1585605250.956404, "_step": 457}
{"Episode reward": -99.57789518798245, "Episode length": 999, "Policy Loss": -0.3436426818370819, "Value Loss": 0.06264111399650574, "_runtime": 7882.843211889267, "_timestamp": 1585605252.4760814, "_step": 458}
{"Episode reward": -99.12850962254316, "Episode length": 999, "Policy Loss": -0.3001731038093567, "Value Loss": 0.010704223066568375, "_runtime": 7883.648316144943, "_timestamp": 1585605253.2811856, "_step": 459}
{"Episode reward": 49.56103394088961, "Episode length": 506, "Policy Loss": 1.0345944166183472, "Value Loss": 17.226037979125977, "_runtime": 7885.201766014099, "_timestamp": 1585605254.8346355, "_step": 460}
{"Episode reward": -99.67814918172523, "Episode length": 999, "Policy Loss": -0.2114582508802414, "Value Loss": 0.015460535883903503, "_runtime": 7885.599803686142, "_timestamp": 1585605255.2326732, "_step": 461}
{"Episode reward": 77.87817657794217, "Episode length": 222, "Policy Loss": 2.0691914558410645, "Value Loss": 39.89464569091797, "_runtime": 7886.544044017792, "_timestamp": 1585605256.1769135, "_step": 462}
{"Episode reward": 37.81802025595037, "Episode length": 623, "Policy Loss": 0.6204816102981567, "Value Loss": 14.558807373046875, "_runtime": 7888.105674505234, "_timestamp": 1585605257.738544, "_step": 463}
{"Episode reward": -99.4688038858804, "Episode length": 999, "Policy Loss": -0.24136902391910553, "Value Loss": 0.004060827661305666, "_runtime": 7888.881024360657, "_timestamp": 1585605258.5138938, "_step": 464}
{"Episode reward": 48.332220949086604, "Episode length": 517, "Policy Loss": 0.6819252371788025, "Value Loss": 16.928388595581055, "_runtime": 7890.395964622498, "_timestamp": 1585605260.028834, "_step": 465}
{"Episode reward": 0.9646841836815838, "Episode length": 994, "Policy Loss": 0.18218809366226196, "Value Loss": 9.990985870361328, "_runtime": 7891.866477966309, "_timestamp": 1585605261.4993474, "_step": 466}
{"Episode reward": 4.8611550036887365, "Episode length": 954, "Policy Loss": 0.2278471440076828, "Value Loss": 9.279501914978027, "_runtime": 7892.307014226913, "_timestamp": 1585605261.9398837, "_step": 467}
{"Episode reward": 72.69852567430924, "Episode length": 274, "Policy Loss": 1.43278968334198, "Value Loss": 31.393234252929688, "_runtime": 7893.848690986633, "_timestamp": 1585605263.4815605, "_step": 468}
{"Episode reward": -99.4943729043517, "Episode length": 999, "Policy Loss": -0.47448456287384033, "Value Loss": 0.24425695836544037, "_runtime": 7895.4097266197205, "_timestamp": 1585605265.042596, "_step": 469}
{"Episode reward": -99.23403689486302, "Episode length": 999, "Policy Loss": -0.4720725119113922, "Value Loss": 0.12081277370452881, "_runtime": 7896.636880874634, "_timestamp": 1585605266.2697504, "_step": 470}
{"Episode reward": 17.72376501738367, "Episode length": 825, "Policy Loss": 0.15850117802619934, "Value Loss": 10.404020309448242, "_runtime": 7897.34370136261, "_timestamp": 1585605266.9765708, "_step": 471}
{"Episode reward": 56.12256519547629, "Episode length": 440, "Policy Loss": 1.009853720664978, "Value Loss": 20.589189529418945, "_runtime": 7898.364474534988, "_timestamp": 1585605267.997344, "_step": 472}
{"Episode reward": 35.2780219211179, "Episode length": 650, "Policy Loss": 0.46861815452575684, "Value Loss": 13.345010757446289, "_runtime": 7899.900356054306, "_timestamp": 1585605269.5332255, "_step": 473}
{"Episode reward": -99.66455841269205, "Episode length": 999, "Policy Loss": -0.2721179723739624, "Value Loss": 0.031156470999121666, "_runtime": 7901.448075771332, "_timestamp": 1585605271.0809453, "_step": 474}
{"Episode reward": -99.71908606199874, "Episode length": 999, "Policy Loss": -0.23124434053897858, "Value Loss": 0.04044506326317787, "_runtime": 7902.9785034656525, "_timestamp": 1585605272.611373, "_step": 475}
{"Episode reward": -99.61540822241665, "Episode length": 999, "Policy Loss": -0.21178826689720154, "Value Loss": 0.3028685748577118, "_runtime": 7903.843131065369, "_timestamp": 1585605273.4760005, "_step": 476}
{"Episode reward": 45.74002049151992, "Episode length": 544, "Policy Loss": 0.8105130195617676, "Value Loss": 16.600006103515625, "_runtime": 7904.846096277237, "_timestamp": 1585605274.4789658, "_step": 477}
{"Episode reward": 36.194545230897454, "Episode length": 641, "Policy Loss": 0.47392988204956055, "Value Loss": 12.576506614685059, "_runtime": 7906.407004833221, "_timestamp": 1585605276.0398743, "_step": 478}
{"Episode reward": -99.5608766783306, "Episode length": 999, "Policy Loss": -0.33253034949302673, "Value Loss": 0.01890062727034092, "_runtime": 7907.158358097076, "_timestamp": 1585605276.7912276, "_step": 479}
{"Episode reward": 51.962741806654556, "Episode length": 482, "Policy Loss": 0.7112069725990295, "Value Loss": 19.928390502929688, "_runtime": 7908.690668344498, "_timestamp": 1585605278.3235378, "_step": 480}
{"Episode reward": -99.42259576408986, "Episode length": 999, "Policy Loss": -0.4666152894496918, "Value Loss": 0.07509942352771759, "_runtime": 7910.119579076767, "_timestamp": 1585605279.7524486, "_step": 481}
{"Episode reward": 9.198546261601749, "Episode length": 911, "Policy Loss": 0.08790428936481476, "Value Loss": 10.340782165527344, "_runtime": 7911.163282394409, "_timestamp": 1585605280.7961519, "_step": 482}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": 0.28436535596847534, "Value Loss": 14.164844512939453, "_runtime": 7912.698915719986, "_timestamp": 1585605282.3317852, "_step": 483}
{"Episode reward": -99.3791734565967, "Episode length": 999, "Policy Loss": -0.5559129118919373, "Value Loss": 0.0396275632083416, "_runtime": 7913.647710323334, "_timestamp": 1585605283.2805798, "_step": 484}
{"Episode reward": 40.25510169073765, "Episode length": 600, "Policy Loss": 0.326903760433197, "Value Loss": 15.002874374389648, "_runtime": 7915.182757854462, "_timestamp": 1585605284.8156273, "_step": 485}
{"Episode reward": -99.62555817706023, "Episode length": 999, "Policy Loss": -0.5477743744850159, "Value Loss": 0.010559852235019207, "_runtime": 7916.66458773613, "_timestamp": 1585605286.2974572, "_step": 486}
{"Episode reward": 4.568328000738688, "Episode length": 958, "Policy Loss": -0.05874565243721008, "Value Loss": 8.880943298339844, "_runtime": 7917.5060069561005, "_timestamp": 1585605287.1388764, "_step": 487}
{"Episode reward": 46.507167989009275, "Episode length": 539, "Policy Loss": 0.2966457009315491, "Value Loss": 16.147300720214844, "_runtime": 7919.065676450729, "_timestamp": 1585605288.698546, "_step": 488}
{"Episode reward": -99.72819870638055, "Episode length": 999, "Policy Loss": -0.6060276627540588, "Value Loss": 0.03834804147481918, "_runtime": 7920.0072729587555, "_timestamp": 1585605289.6401424, "_step": 489}
{"Episode reward": 40.59060042769941, "Episode length": 595, "Policy Loss": 0.2568211257457733, "Value Loss": 14.378849983215332, "_runtime": 7921.1066954135895, "_timestamp": 1585605290.739565, "_step": 490}
{"Episode reward": 29.189175798841205, "Episode length": 715, "Policy Loss": -0.0546661913394928, "Value Loss": 11.214082717895508, "_runtime": 7922.66238451004, "_timestamp": 1585605292.295254, "_step": 491}
{"Episode reward": -99.33418320937788, "Episode length": 999, "Policy Loss": -0.7870740294456482, "Value Loss": 0.04155487194657326, "_runtime": 7924.221496105194, "_timestamp": 1585605293.8543656, "_step": 492}
{"Episode reward": -99.5677124486029, "Episode length": 999, "Policy Loss": -0.8594174981117249, "Value Loss": 0.06115365028381348, "_runtime": 7925.756283283234, "_timestamp": 1585605295.3891528, "_step": 493}
{"Episode reward": -99.41705898629742, "Episode length": 999, "Policy Loss": -0.8604973554611206, "Value Loss": 0.1508907973766327, "_runtime": 7927.308018684387, "_timestamp": 1585605296.9408882, "_step": 494}
{"Episode reward": -99.52661235860879, "Episode length": 999, "Policy Loss": -0.8243141770362854, "Value Loss": 0.1500874012708664, "_runtime": 7928.807564496994, "_timestamp": 1585605298.440434, "_step": 495}
{"Episode reward": 3.81188505637229, "Episode length": 965, "Policy Loss": -0.15732881426811218, "Value Loss": 9.30409049987793, "_runtime": 7929.685460090637, "_timestamp": 1585605299.3183296, "_step": 496}
{"Episode reward": 44.93347384356261, "Episode length": 551, "Policy Loss": 0.08769889175891876, "Value Loss": 16.64061737060547, "_runtime": 7930.964785575867, "_timestamp": 1585605300.597655, "_step": 497}
{"Episode reward": 18.593758737859375, "Episode length": 816, "Policy Loss": -0.0051541985012590885, "Value Loss": 10.956047058105469, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952, -0.16470018029212952]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-4.058778762817383, -3.9927868843078613, -3.92679500579834, -3.8608031272888184, -3.794811487197876, -3.7288196086883545, -3.662827730178833, -3.5968358516693115, -3.53084397315979, -3.4648523330688477, -3.398860454559326, -3.3328685760498047, -3.266876697540283, -3.2008848190307617, -3.1348929405212402, -3.0689010620117188, -3.0029091835021973, -2.936917304992676, -2.8709256649017334, -2.804933786392212, -2.7389419078826904, -2.672950267791748, -2.6069583892822266, -2.540966510772705, -2.4749746322631836, -2.408982753753662, -2.3429908752441406, -2.276998996734619, -2.2110071182250977, -2.145015239715576, -2.0790233612060547, -2.0130317211151123, -1.9470398426055908, -1.8810479640960693, -1.8150560855865479, -1.7490642070770264, -1.683072566986084, -1.6170806884765625, -1.551088809967041, -1.4850969314575195, -1.419105052947998, -1.3531131744384766, -1.2871215343475342, -1.2211296558380127, -1.1551377773284912, -1.0891458988189697, -1.0231540203094482, -0.9571621417999268, -0.8911705017089844, -0.8251786231994629, -0.7591867446899414, -0.6931948661804199, -0.6272029876708984, -0.561211109161377, -0.49521923065185547, -0.4292275905609131, -0.3632357120513916, -0.2972438335418701, -0.23125195503234863, -0.16526007652282715, -0.09926819801330566, -0.03327655792236328, 0.0327153205871582, 0.09870719909667969, 0.16469907760620117]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.24250131845474243, -0.23871199786663055, -0.23492266237735748, -0.2311333417892456, -0.22734402120113373, -0.22355470061302185, -0.21976536512374878, -0.2159760445356369, -0.21218672394752502, -0.20839738845825195, -0.20460806787014008, -0.2008187472820282, -0.19702941179275513, -0.19324009120464325, -0.18945077061653137, -0.1856614351272583, -0.18187211453914642, -0.17808279395103455, -0.17429345846176147, -0.1705041378736496, -0.16671481728553772, -0.16292548179626465, -0.15913616120815277, -0.1553468406200409, -0.15155750513076782, -0.14776818454265594, -0.14397886395454407, -0.140189528465271, -0.13640020787715912, -0.13261088728904724, -0.12882155179977417, -0.1250322461128235, -0.12124291062355042, -0.11745359003543854, -0.11366425454616547, -0.10987493395805359, -0.10608561336994171, -0.10229627788066864, -0.09850695729255676, -0.09471763670444489, -0.09092831611633301, -0.08713898062705994, -0.08334966003894806, -0.07956033945083618, -0.07577100396156311, -0.07198168337345123, -0.06819236278533936, -0.06440302729606628, -0.06061370670795441, -0.05682438611984253, -0.05303505063056946, -0.04924573004245758, -0.0454564094543457, -0.04166707396507263, -0.037877753376960754, -0.03408843278884888, -0.030299097299575806, -0.026509776711463928, -0.02272045612335205, -0.018931135535240173, -0.015141800045967102, -0.011352479457855225, -0.007563158869743347, -0.003773823380470276, 1.5497207641601562e-05]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 6.0, 4.0, 5.0, 3.0, 7.0, 4.0, 5.0, 3.0, 4.0, 6.0, 1.0, 5.0, 5.0, 2.0, 0.0, 2.0, 0.0, 0.0, 320.0, 2.0, 6.0, 9.0, 7.0, 7.0, 11.0, 11.0, 10.0, 8.0, 7.0, 6.0, 5.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.6996082067489624, -0.6841290593147278, -0.6686499714851379, -0.6531708240509033, -0.6376917362213135, -0.6222125887870789, -0.6067334413528442, -0.5912543535232544, -0.5757752060890198, -0.5602960586547852, -0.5448169708251953, -0.5293378233909607, -0.5138587355613708, -0.49837958812713623, -0.482900470495224, -0.46742135286331177, -0.45194220542907715, -0.4364630877971649, -0.4209839701652527, -0.40550485253334045, -0.3900257349014282, -0.3745465874671936, -0.35906746983528137, -0.34358835220336914, -0.3281092345714569, -0.3126301169395447, -0.29715096950531006, -0.2816718518733978, -0.2661927342414856, -0.25071361660957336, -0.23523446917533875, -0.2197553515434265, -0.20427623391151428, -0.18879711627960205, -0.17331796884536743, -0.1578388810157776, -0.14235973358154297, -0.12688058614730835, -0.1114014983177185, -0.09592235088348389, -0.08044326305389404, -0.06496411561965942, -0.049484968185424805, -0.03400588035583496, -0.018526732921600342, -0.003047645092010498, 0.012431502342224121, 0.02791064977645874, 0.043389737606048584, 0.0588688850402832, 0.07434797286987305, 0.08982712030410767, 0.10530626773834229, 0.12078535556793213, 0.13626450300216675, 0.15174365043640137, 0.1672227382659912, 0.18270188570022583, 0.19818097352981567, 0.2136601209640503, 0.2291392683982849, 0.24461835622787476, 0.2600975036621094, 0.2755765914916992, 0.29105573892593384]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.151057243347168, -1.1247117519378662, -1.0983662605285645, -1.0720207691192627, -1.0456753969192505, -1.0193299055099487, -0.992984414100647, -0.9666389226913452, -0.9402934312820435, -0.9139479994773865, -0.8876025080680847, -0.8612570762634277, -0.834911584854126, -0.8085660934448242, -0.7822206020355225, -0.7558751106262207, -0.7295296788215637, -0.7031842470169067, -0.676838755607605, -0.6504932641983032, -0.6241477727890015, -0.5978023409843445, -0.5714568495750427, -0.545111358165741, -0.518765926361084, -0.4924204349517822, -0.46607494354248047, -0.4397294521331787, -0.41338402032852173, -0.38703852891921997, -0.3606930375099182, -0.33434760570526123, -0.3080021142959595, -0.2816566228866577, -0.25531119108200073, -0.22896569967269897, -0.20262020826339722, -0.17627477645874023, -0.14992928504943848, -0.12358379364013672, -0.09723830223083496, -0.0708928108215332, -0.044547438621520996, -0.01820194721221924, 0.00814354419708252, 0.03448903560638428, 0.060834527015686035, 0.08718001842498779, 0.113525390625, 0.13987088203430176, 0.16621637344360352, 0.19256186485290527, 0.21890735626220703, 0.2452528476715088, 0.27159833908081055, 0.29794371128082275, 0.3242892026901245, 0.35063469409942627, 0.376980185508728, 0.4033256769180298, 0.42967116832733154, 0.45601654052734375, 0.4823620319366455, 0.5087075233459473, 0.535053014755249]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 7.0, 13.0, 3.0, 6.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.678234338760376, -1.6398231983184814, -1.601412057876587, -1.5630009174346924, -1.5245896577835083, -1.4861785173416138, -1.4477673768997192, -1.4093562364578247, -1.3709450960159302, -1.332533836364746, -1.2941226959228516, -1.255711555480957, -1.2173004150390625, -1.178889274597168, -1.1404781341552734, -1.102066993713379, -1.0636558532714844, -1.0252447128295898, -0.9868334531784058, -0.9484223127365112, -0.9100111722946167, -0.8715999722480774, -0.8331888318061829, -0.7947776913642883, -0.756366491317749, -0.7179553508758545, -0.67954421043396, -0.6411330699920654, -0.6027219295501709, -0.5643106698989868, -0.5258995294570923, -0.48748838901519775, -0.4490772485733032, -0.4106661081314087, -0.37225496768951416, -0.33384382724761963, -0.29543256759643555, -0.257021427154541, -0.21861028671264648, -0.18019914627075195, -0.14178800582885742, -0.10337686538696289, -0.06496560573577881, -0.026554465293884277, 0.011856675148010254, 0.050267815589904785, 0.08867895603179932, 0.12709009647369385, 0.16550135612487793, 0.20391249656677246, 0.242323637008667, 0.2807347774505615, 0.31914591789245605, 0.3575570583343506, 0.3959681987762451, 0.43437933921813965, 0.4727904796600342, 0.5112016201019287, 0.5496129989624023, 0.5880241394042969, 0.6264352798461914, 0.6648464202880859, 0.7032575607299805, 0.741668701171875, 0.7800798416137695]}, "_runtime": 7932.197234630585, "_timestamp": 1585605301.830104, "_step": 498}
{"Episode reward": 21.28723406983063, "Episode length": 794, "Policy Loss": 0.01473262533545494, "Value Loss": 10.536735534667969, "_runtime": 7932.197234630585, "_timestamp": 1585605301.830104, "_step": 499}
