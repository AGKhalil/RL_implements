{"Episode reward": -50.296187868022635, "Episode length": 999, "Policy Loss": -0.09468448162078857, "Value Loss": 0.07087016850709915, "_runtime": 1631.7913320064545, "_timestamp": 1585599001.4242015, "_step": 0}
{"Episode reward": -98.61874405481154, "Episode length": 999, "Policy Loss": 0.5144044756889343, "Value Loss": 656.341064453125, "_runtime": 1631.924162387848, "_timestamp": 1585599001.5570319, "_step": 1}
{"Episode reward": 92.53241971559285, "Episode length": 79, "Policy Loss": 273.5237731933594, "Value Loss": 6918.88671875, "_runtime": 1633.4715423583984, "_timestamp": 1585599003.1044118, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.525822639465332, "Value Loss": 21232.537109375, "_runtime": 1635.0067811012268, "_timestamp": 1585599004.6396506, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.334773063659668, "Value Loss": 1916.4459228515625, "_runtime": 1636.5032122135162, "_timestamp": 1585599006.1360817, "_step": 4}
{"Episode reward": -85.57565087919761, "Episode length": 999, "Policy Loss": 21.727527618408203, "Value Loss": 3814.868408203125, "_runtime": 1637.8963227272034, "_timestamp": 1585599007.5291922, "_step": 5}
{"Episode reward": 17.073085925161294, "Episode length": 890, "Policy Loss": -25.77756690979004, "Value Loss": 2334.200439453125, "_runtime": 1639.4504435062408, "_timestamp": 1585599009.083313, "_step": 6}
{"Episode reward": -97.52105219074069, "Episode length": 999, "Policy Loss": -0.01016814261674881, "Value Loss": 686.6582641601562, "_runtime": 1641.0288405418396, "_timestamp": 1585599010.66171, "_step": 7}
{"Episode reward": -98.93283405032447, "Episode length": 999, "Policy Loss": 6.862542629241943, "Value Loss": 7054.19921875, "_runtime": 1642.589983701706, "_timestamp": 1585599012.2228532, "_step": 8}
{"Episode reward": -97.90078907285562, "Episode length": 999, "Policy Loss": -13.160584449768066, "Value Loss": 6667.8408203125, "_runtime": 1643.8188569545746, "_timestamp": 1585599013.4517264, "_step": 9}
{"Episode reward": 23.582654407202213, "Episode length": 783, "Policy Loss": -20.60411834716797, "Value Loss": 4789.06591796875, "_runtime": 1645.3612232208252, "_timestamp": 1585599014.9940927, "_step": 10}
{"Episode reward": -98.01310617124098, "Episode length": 999, "Policy Loss": -16.518503189086914, "Value Loss": 12360.9853515625, "_runtime": 1646.9351484775543, "_timestamp": 1585599016.568018, "_step": 11}
{"Episode reward": -98.08976720221426, "Episode length": 999, "Policy Loss": -36.43053436279297, "Value Loss": 890.6009521484375, "_runtime": 1648.480082988739, "_timestamp": 1585599018.1129525, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10124565660953522, "Value Loss": 27.752239227294922, "_runtime": 1650.0309205055237, "_timestamp": 1585599019.66379, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.515900135040283, "Value Loss": 2617.117431640625, "_runtime": 1651.6111752986908, "_timestamp": 1585599021.2440448, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.509002685546875, "Value Loss": 670.4237060546875, "_runtime": 1653.1877629756927, "_timestamp": 1585599022.8206325, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.036855220794678, "Value Loss": 2277.61474609375, "_runtime": 1654.754159450531, "_timestamp": 1585599024.387029, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2984235286712646, "Value Loss": 20041.912109375, "_runtime": 1656.3247413635254, "_timestamp": 1585599025.9576108, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.031686782836914, "Value Loss": 2110.341796875, "_runtime": 1657.8955383300781, "_timestamp": 1585599027.5284078, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 17.2054500579834, "Value Loss": 1474.18896484375, "_runtime": 1659.455512046814, "_timestamp": 1585599029.0883815, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.946664810180664, "Value Loss": 213.83822631835938, "_runtime": 1661.0371959209442, "_timestamp": 1585599030.6700654, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.535381317138672, "Value Loss": 142.0200958251953, "_runtime": 1662.6038281917572, "_timestamp": 1585599032.2366977, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.06029510498047, "Value Loss": 333.9185791015625, "_runtime": 1664.2045304775238, "_timestamp": 1585599033.8374, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.753721237182617, "Value Loss": 4976.46826171875, "_runtime": 1665.7783737182617, "_timestamp": 1585599035.4112432, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 17.34273338317871, "Value Loss": 912.1591796875, "_runtime": 1667.3635277748108, "_timestamp": 1585599036.9963973, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 15.88304328918457, "Value Loss": 14.889755249023438, "_runtime": 1668.9315104484558, "_timestamp": 1585599038.56438, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 14.537810325622559, "Value Loss": 134.01300048828125, "_runtime": 1670.5066463947296, "_timestamp": 1585599040.1395159, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 14.716121673583984, "Value Loss": 3236.063232421875, "_runtime": 1672.0920293331146, "_timestamp": 1585599041.7248988, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 15.394036293029785, "Value Loss": 3091.31103515625, "_runtime": 1673.6588084697723, "_timestamp": 1585599043.291678, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 16.67388916015625, "Value Loss": 159.9785614013672, "_runtime": 1675.2308399677277, "_timestamp": 1585599044.8637094, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.47256851196289, "Value Loss": 6.332276821136475, "_runtime": 1676.8185317516327, "_timestamp": 1585599046.4514012, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 20.103063583374023, "Value Loss": 79.86023712158203, "_runtime": 1678.3855578899384, "_timestamp": 1585599048.0184274, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.65471649169922, "Value Loss": 9.86812686920166, "_runtime": 1679.9685606956482, "_timestamp": 1585599049.6014302, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.907007217407227, "Value Loss": 434.7000732421875, "_runtime": 1681.5421259403229, "_timestamp": 1585599051.1749954, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 22.56871795654297, "Value Loss": 52.30725860595703, "_runtime": 1683.1102912425995, "_timestamp": 1585599052.7431607, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.785324096679688, "Value Loss": 13.392226219177246, "_runtime": 1684.6827538013458, "_timestamp": 1585599054.3156233, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 21.349470138549805, "Value Loss": 44.29500198364258, "_runtime": 1686.2565426826477, "_timestamp": 1585599055.8894122, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 20.838773727416992, "Value Loss": 28.558286666870117, "_runtime": 1687.8704540729523, "_timestamp": 1585599057.5033236, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 20.795387268066406, "Value Loss": 17.219358444213867, "_runtime": 1689.4536309242249, "_timestamp": 1585599059.0865004, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 19.555097579956055, "Value Loss": 783.1922607421875, "_runtime": 1691.0393192768097, "_timestamp": 1585599060.6721888, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 17.392974853515625, "Value Loss": 622.6614379882812, "_runtime": 1692.6065106391907, "_timestamp": 1585599062.2393801, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.332216262817383, "Value Loss": 260.9668273925781, "_runtime": 1694.186636209488, "_timestamp": 1585599063.8195057, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.079554557800293, "Value Loss": 100.65861511230469, "_runtime": 1695.7705693244934, "_timestamp": 1585599065.4034388, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.796669006347656, "Value Loss": 8.943772315979004, "_runtime": 1697.3501236438751, "_timestamp": 1585599066.9829931, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8676173090934753, "Value Loss": 8.196430206298828, "_runtime": 1698.9239478111267, "_timestamp": 1585599068.5568173, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6984779834747314, "Value Loss": 4.123831272125244, "_runtime": 1700.4953355789185, "_timestamp": 1585599070.128205, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.000575065612793, "Value Loss": 104.37403106689453, "_runtime": 1702.0803763866425, "_timestamp": 1585599071.7132459, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.407037734985352, "Value Loss": 360.3934020996094, "_runtime": 1703.6599638462067, "_timestamp": 1585599073.2928333, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.252522468566895, "Value Loss": 13.6605863571167, "_runtime": 1705.244428396225, "_timestamp": 1585599074.8772979, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.379302024841309, "Value Loss": 31.571104049682617, "_runtime": 1706.8236706256866, "_timestamp": 1585599076.45654, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.494054794311523, "Value Loss": 331.764404296875, "_runtime": 1708.4083635807037, "_timestamp": 1585599078.041233, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.087510108947754, "Value Loss": 7.358423709869385, "_runtime": 1710.0191009044647, "_timestamp": 1585599079.6519704, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.538280487060547, "Value Loss": 20.239871978759766, "_runtime": 1711.5878257751465, "_timestamp": 1585599081.2206953, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.48798942565918, "Value Loss": 234.60008239746094, "_runtime": 1713.1598348617554, "_timestamp": 1585599082.7927043, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.294973373413086, "Value Loss": 2.557016372680664, "_runtime": 1714.7444109916687, "_timestamp": 1585599084.3772805, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.055743217468262, "Value Loss": 1.5812627077102661, "_runtime": 1716.3148488998413, "_timestamp": 1585599085.9477184, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.932842254638672, "Value Loss": 31.54137420654297, "_runtime": 1717.8878231048584, "_timestamp": 1585599087.5206926, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.555220603942871, "Value Loss": 25.5711727142334, "_runtime": 1719.4716708660126, "_timestamp": 1585599089.1045403, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -12.17907428741455, "Value Loss": 13.584970474243164, "_runtime": 1721.0530846118927, "_timestamp": 1585599090.685954, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.844687461853027, "Value Loss": 11.85403823852539, "_runtime": 1722.6368355751038, "_timestamp": 1585599092.269705, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.482304573059082, "Value Loss": 13.099589347839355, "_runtime": 1724.2202076911926, "_timestamp": 1585599093.8530772, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -11.181123733520508, "Value Loss": 53.13959503173828, "_runtime": 1725.7898440361023, "_timestamp": 1585599095.4227135, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.717090606689453, "Value Loss": 32.31182098388672, "_runtime": 1727.3620448112488, "_timestamp": 1585599096.9949143, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.132043838500977, "Value Loss": 5.538626194000244, "_runtime": 1728.936586856842, "_timestamp": 1585599098.5694563, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.617586135864258, "Value Loss": 4.443742752075195, "_runtime": 1730.514662027359, "_timestamp": 1585599100.1475315, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.177971839904785, "Value Loss": 10.03196907043457, "_runtime": 1732.0876355171204, "_timestamp": 1585599101.720505, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.713757514953613, "Value Loss": 10.279890060424805, "_runtime": 1733.6955919265747, "_timestamp": 1585599103.3284614, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.279072761535645, "Value Loss": 3.8446688652038574, "_runtime": 1735.2736160755157, "_timestamp": 1585599104.9064856, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.887610912322998, "Value Loss": 4.2422051429748535, "_runtime": 1736.843073129654, "_timestamp": 1585599106.4759426, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.515827178955078, "Value Loss": 5.38358211517334, "_runtime": 1738.4259085655212, "_timestamp": 1585599108.058778, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.213676929473877, "Value Loss": 1.242258071899414, "_runtime": 1739.9947350025177, "_timestamp": 1585599109.6276045, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.912477493286133, "Value Loss": 0.6648987531661987, "_runtime": 1741.576397895813, "_timestamp": 1585599111.2092674, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.650588035583496, "Value Loss": 0.800956130027771, "_runtime": 1743.149293422699, "_timestamp": 1585599112.782163, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.409355163574219, "Value Loss": 2.593027353286743, "_runtime": 1744.719791173935, "_timestamp": 1585599114.3526607, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.223647594451904, "Value Loss": 4.8837385177612305, "_runtime": 1746.2914280891418, "_timestamp": 1585599115.9242976, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.99827241897583, "Value Loss": 2.7510087490081787, "_runtime": 1747.8628952503204, "_timestamp": 1585599117.4957647, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.765310287475586, "Value Loss": 20.85723114013672, "_runtime": 1749.431838274002, "_timestamp": 1585599119.0647078, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.624359130859375, "Value Loss": 6.987734317779541, "_runtime": 1751.0153183937073, "_timestamp": 1585599120.6481879, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.407370567321777, "Value Loss": 9.354719161987305, "_runtime": 1752.5876166820526, "_timestamp": 1585599122.2204862, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.21509313583374, "Value Loss": 0.8984955549240112, "_runtime": 1754.165697336197, "_timestamp": 1585599123.7985668, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.158699035644531, "Value Loss": 12.488863945007324, "_runtime": 1755.746574163437, "_timestamp": 1585599125.3794436, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.012996196746826, "Value Loss": 5.214282512664795, "_runtime": 1757.3662865161896, "_timestamp": 1585599126.999156, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.891623020172119, "Value Loss": 0.641546905040741, "_runtime": 1758.9222910404205, "_timestamp": 1585599128.5551605, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.7437896728515625, "Value Loss": 0.23382668197155, "_runtime": 1760.5065858364105, "_timestamp": 1585599130.1394553, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.650240421295166, "Value Loss": 0.4320714771747589, "_runtime": 1762.090806722641, "_timestamp": 1585599131.7236762, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.546600818634033, "Value Loss": 1.4383604526519775, "_runtime": 1763.6723070144653, "_timestamp": 1585599133.3051765, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.430311679840088, "Value Loss": 0.28243115544319153, "_runtime": 1765.2461700439453, "_timestamp": 1585599134.8790395, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.3145527839660645, "Value Loss": 0.32832565903663635, "_runtime": 1766.8287291526794, "_timestamp": 1585599136.4615986, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.240219593048096, "Value Loss": 4.5231757164001465, "_runtime": 1768.3979489803314, "_timestamp": 1585599138.0308185, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.12912130355835, "Value Loss": 3.5352916717529297, "_runtime": 1769.9804241657257, "_timestamp": 1585599139.6132936, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.046988487243652, "Value Loss": 2.9001388549804688, "_runtime": 1771.5628826618195, "_timestamp": 1585599141.1957521, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.9804842472076416, "Value Loss": 1.463843584060669, "_runtime": 1773.1474962234497, "_timestamp": 1585599142.7803657, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.8813912868499756, "Value Loss": 1.588629126548767, "_runtime": 1774.72110080719, "_timestamp": 1585599144.3539703, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.822037696838379, "Value Loss": 1.0597808361053467, "_runtime": 1776.2917201519012, "_timestamp": 1585599145.9245896, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.743299722671509, "Value Loss": 2.145089864730835, "_runtime": 1777.8563821315765, "_timestamp": 1585599147.4892516, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6623551845550537, "Value Loss": 0.8773707151412964, "_runtime": 1779.4253222942352, "_timestamp": 1585599149.0581918, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5935614109039307, "Value Loss": 0.3756025731563568, "_runtime": 1781.031319141388, "_timestamp": 1585599150.6641886, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.527269124984741, "Value Loss": 0.5973813533782959, "_runtime": 1782.598403930664, "_timestamp": 1585599152.2312734, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.4514589309692383, "Value Loss": 0.13115713000297546, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1784.1706185340881, "_timestamp": 1585599153.803488, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3826677799224854, "Value Loss": 0.2754056751728058, "_runtime": 1785.7379429340363, "_timestamp": 1585599155.3708124, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3295345306396484, "Value Loss": 0.4026884436607361, "_runtime": 1787.2912559509277, "_timestamp": 1585599156.9241254, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2628250122070312, "Value Loss": 0.10977987945079803, "_runtime": 1788.8497655391693, "_timestamp": 1585599158.482635, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2113749980926514, "Value Loss": 0.3111708462238312, "_runtime": 1790.4084010124207, "_timestamp": 1585599160.0412705, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1514365673065186, "Value Loss": 0.15816450119018555, "_runtime": 1791.973916053772, "_timestamp": 1585599161.6067855, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.096863269805908, "Value Loss": 0.1099705919623375, "_runtime": 1793.5292451381683, "_timestamp": 1585599163.1621146, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0480995178222656, "Value Loss": 0.12318732589483261, "_runtime": 1795.0978906154633, "_timestamp": 1585599164.73076, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.00168776512146, "Value Loss": 0.2600705921649933, "_runtime": 1796.6633524894714, "_timestamp": 1585599166.296222, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.955947160720825, "Value Loss": 0.3835609555244446, "_runtime": 1798.2197136878967, "_timestamp": 1585599167.8525832, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.9097225666046143, "Value Loss": 0.09569288790225983, "_runtime": 1799.7846393585205, "_timestamp": 1585599169.4175088, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8680906295776367, "Value Loss": 0.09682418406009674, "_runtime": 1801.3475892543793, "_timestamp": 1585599170.9804587, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.828859806060791, "Value Loss": 0.14209996163845062, "_runtime": 1802.9392528533936, "_timestamp": 1585599172.5721223, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.792208433151245, "Value Loss": 0.26884350180625916, "_runtime": 1804.5200397968292, "_timestamp": 1585599174.1529093, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7472944259643555, "Value Loss": 0.10440487414598465, "_runtime": 1806.0975332260132, "_timestamp": 1585599175.7304027, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.715862989425659, "Value Loss": 0.2408190220594406, "_runtime": 1807.6648108959198, "_timestamp": 1585599177.2976804, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6719415187835693, "Value Loss": 0.11252564936876297, "_runtime": 1809.2443957328796, "_timestamp": 1585599178.8772652, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6332197189331055, "Value Loss": 0.14299242198467255, "_runtime": 1810.8255517482758, "_timestamp": 1585599180.4584212, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.598257064819336, "Value Loss": 0.10131208598613739, "_runtime": 1812.3935720920563, "_timestamp": 1585599182.0264416, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5614497661590576, "Value Loss": 0.09670405834913254, "_runtime": 1813.9707202911377, "_timestamp": 1585599183.6035898, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5239155292510986, "Value Loss": 0.1015128493309021, "_runtime": 1815.5455164909363, "_timestamp": 1585599185.178386, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4880402088165283, "Value Loss": 0.0638195276260376, "_runtime": 1817.124564409256, "_timestamp": 1585599186.757434, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.4611434936523438, "Value Loss": 0.17931689321994781, "_runtime": 1818.6917943954468, "_timestamp": 1585599188.3246639, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.425969362258911, "Value Loss": 0.1736675500869751, "_runtime": 1820.2591030597687, "_timestamp": 1585599189.8919725, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3872458934783936, "Value Loss": 0.07933907955884933, "_runtime": 1821.838838815689, "_timestamp": 1585599191.4717083, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3536124229431152, "Value Loss": 0.05761679634451866, "_runtime": 1823.397300004959, "_timestamp": 1585599193.0301695, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3204405307769775, "Value Loss": 0.052977554500103, "_runtime": 1824.9651699066162, "_timestamp": 1585599194.5980394, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.288466453552246, "Value Loss": 0.048748742789030075, "_runtime": 1826.5729207992554, "_timestamp": 1585599196.2057903, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.258481740951538, "Value Loss": 0.053968336433172226, "_runtime": 1828.1417632102966, "_timestamp": 1585599197.7746327, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.226573944091797, "Value Loss": 0.1519049108028412, "_runtime": 1829.707978963852, "_timestamp": 1585599199.3408484, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.194206476211548, "Value Loss": 0.06159991770982742, "_runtime": 1831.2779726982117, "_timestamp": 1585599200.9108422, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1634936332702637, "Value Loss": 0.05449255183339119, "_runtime": 1832.8558161258698, "_timestamp": 1585599202.4886856, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.138557195663452, "Value Loss": 0.08555912971496582, "_runtime": 1834.4190928936005, "_timestamp": 1585599204.0519624, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.102757215499878, "Value Loss": 0.1029948815703392, "_runtime": 1835.9879865646362, "_timestamp": 1585599205.620856, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.080977201461792, "Value Loss": 0.12037049978971481, "_runtime": 1837.5682020187378, "_timestamp": 1585599207.2010715, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0504205226898193, "Value Loss": 0.07400970906019211, "_runtime": 1839.1348628997803, "_timestamp": 1585599208.7677324, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0194313526153564, "Value Loss": 0.07085764408111572, "_runtime": 1840.7019078731537, "_timestamp": 1585599210.3347774, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9855846166610718, "Value Loss": 0.05331600084900856, "_runtime": 1842.2827560901642, "_timestamp": 1585599211.9156256, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9594272375106812, "Value Loss": 0.13023029267787933, "_runtime": 1843.8583753108978, "_timestamp": 1585599213.4912448, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9365333318710327, "Value Loss": 0.12480847537517548, "_runtime": 1845.4346477985382, "_timestamp": 1585599215.0675173, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9034395217895508, "Value Loss": 0.03286983445286751, "_runtime": 1847.0061931610107, "_timestamp": 1585599216.6390626, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.873685598373413, "Value Loss": 0.06067756190896034, "_runtime": 1848.5729835033417, "_timestamp": 1585599218.205853, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.847977876663208, "Value Loss": 0.03311222419142723, "_runtime": 1850.1635460853577, "_timestamp": 1585599219.7964156, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8170456886291504, "Value Loss": 0.05389474332332611, "_runtime": 1851.740419626236, "_timestamp": 1585599221.373289, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7921324968338013, "Value Loss": 0.05599397420883179, "_runtime": 1853.3173825740814, "_timestamp": 1585599222.950252, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7652851343154907, "Value Loss": 0.05729273334145546, "_runtime": 1854.8988420963287, "_timestamp": 1585599224.5317116, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.739296793937683, "Value Loss": 0.03797687590122223, "_runtime": 1856.4694664478302, "_timestamp": 1585599226.102336, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7123388051986694, "Value Loss": 0.05363990366458893, "_runtime": 1858.0497920513153, "_timestamp": 1585599227.6826615, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6923221349716187, "Value Loss": 0.08845995366573334, "_runtime": 1859.6290638446808, "_timestamp": 1585599229.2619333, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6611769199371338, "Value Loss": 0.05149150639772415, "_runtime": 1861.1981489658356, "_timestamp": 1585599230.8310184, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6375921964645386, "Value Loss": 0.04145250841975212, "_runtime": 1862.7762594223022, "_timestamp": 1585599232.409129, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.611966609954834, "Value Loss": 0.023736190050840378, "_runtime": 1864.3471264839172, "_timestamp": 1585599233.979996, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5886675119400024, "Value Loss": 0.04794251546263695, "_runtime": 1865.9235846996307, "_timestamp": 1585599235.5564542, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5638567209243774, "Value Loss": 0.041705042123794556, "_runtime": 1867.4927096366882, "_timestamp": 1585599237.125579, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5435757637023926, "Value Loss": 0.10819550603628159, "_runtime": 1869.0630922317505, "_timestamp": 1585599238.6959617, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5190670490264893, "Value Loss": 0.08501536399126053, "_runtime": 1870.6422295570374, "_timestamp": 1585599240.275099, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4927575588226318, "Value Loss": 0.03965628519654274, "_runtime": 1872.1989314556122, "_timestamp": 1585599241.831801, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4749879837036133, "Value Loss": 0.07335080951452255, "_runtime": 1873.8129608631134, "_timestamp": 1585599243.4458303, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4458038806915283, "Value Loss": 0.03992920741438866, "_runtime": 1875.3918895721436, "_timestamp": 1585599245.024759, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.426337480545044, "Value Loss": 0.03429069742560387, "_runtime": 1876.9688057899475, "_timestamp": 1585599246.6016753, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4015198945999146, "Value Loss": 0.039893988519907, "_runtime": 1878.5386023521423, "_timestamp": 1585599248.1714718, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3805454969406128, "Value Loss": 0.031674448400735855, "_runtime": 1880.1067509651184, "_timestamp": 1585599249.7396204, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3592766523361206, "Value Loss": 0.031573377549648285, "_runtime": 1881.675814628601, "_timestamp": 1585599251.308684, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3376061916351318, "Value Loss": 0.0656493753194809, "_runtime": 1883.2372996807098, "_timestamp": 1585599252.8701692, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3168526887893677, "Value Loss": 0.034154921770095825, "_runtime": 1884.7942600250244, "_timestamp": 1585599254.4271295, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2940365076065063, "Value Loss": 0.039688777178525925, "_runtime": 1886.3622722625732, "_timestamp": 1585599255.9951417, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2736321687698364, "Value Loss": 0.0617779865860939, "_runtime": 1887.9329016208649, "_timestamp": 1585599257.565771, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2534693479537964, "Value Loss": 0.01562495343387127, "_runtime": 1889.5040173530579, "_timestamp": 1585599259.1368868, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2326254844665527, "Value Loss": 0.024278368800878525, "_runtime": 1891.0735371112823, "_timestamp": 1585599260.7064066, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.215781331062317, "Value Loss": 0.06633513420820236, "_runtime": 1892.654301404953, "_timestamp": 1585599262.287171, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1911922693252563, "Value Loss": 0.053303543478250504, "_runtime": 1894.2109389305115, "_timestamp": 1585599263.8438084, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.174304723739624, "Value Loss": 0.04176715761423111, "_runtime": 1895.780720949173, "_timestamp": 1585599265.4135904, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1520249843597412, "Value Loss": 0.012976085767149925, "_runtime": 1897.3967742919922, "_timestamp": 1585599267.0296438, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.134897232055664, "Value Loss": 0.05657942220568657, "_runtime": 1898.9639031887054, "_timestamp": 1585599268.5967727, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1180609464645386, "Value Loss": 0.06520862877368927, "_runtime": 1900.5365602970123, "_timestamp": 1585599270.1694298, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0942541360855103, "Value Loss": 0.02599254436790943, "_runtime": 1902.1113238334656, "_timestamp": 1585599271.7441933, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0764257907867432, "Value Loss": 0.0522584542632103, "_runtime": 1903.6730513572693, "_timestamp": 1585599273.3059208, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0587499141693115, "Value Loss": 0.013230734504759312, "_runtime": 1905.2289445400238, "_timestamp": 1585599274.861814, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0385946035385132, "Value Loss": 0.04549379646778107, "_runtime": 1906.7974429130554, "_timestamp": 1585599276.4303124, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0228729248046875, "Value Loss": 0.049070216715335846, "_runtime": 1908.3759241104126, "_timestamp": 1585599278.0087936, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.002148151397705, "Value Loss": 0.022893210873007774, "_runtime": 1909.9532279968262, "_timestamp": 1585599279.5860975, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9832530617713928, "Value Loss": 0.037461213767528534, "_runtime": 1911.5194396972656, "_timestamp": 1585599281.1523092, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9646903872489929, "Value Loss": 0.03175815939903259, "_runtime": 1913.09770154953, "_timestamp": 1585599282.730571, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9503663778305054, "Value Loss": 0.05182427540421486, "_runtime": 1914.6574258804321, "_timestamp": 1585599284.2902954, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.929165244102478, "Value Loss": 0.02414531446993351, "_runtime": 1916.213075876236, "_timestamp": 1585599285.8459454, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9114264249801636, "Value Loss": 0.023578107357025146, "_runtime": 1917.780954837799, "_timestamp": 1585599287.4138243, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8946936726570129, "Value Loss": 0.023128332570195198, "_runtime": 1919.3811438083649, "_timestamp": 1585599289.0140133, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8810195922851562, "Value Loss": 0.05726724863052368, "_runtime": 1920.959688425064, "_timestamp": 1585599290.592558, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8642228245735168, "Value Loss": 0.05631310120224953, "_runtime": 1922.5358266830444, "_timestamp": 1585599292.1686962, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8442708849906921, "Value Loss": 0.009202511981129646, "_runtime": 1924.1138334274292, "_timestamp": 1585599293.746703, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8293067812919617, "Value Loss": 0.01144776027649641, "_runtime": 1925.6885504722595, "_timestamp": 1585599295.32142, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8118501305580139, "Value Loss": 0.017492955550551414, "_runtime": 1927.2531282901764, "_timestamp": 1585599296.8859978, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.798562228679657, "Value Loss": 0.013742229901254177, "_runtime": 1928.8267204761505, "_timestamp": 1585599298.45959, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7842986583709717, "Value Loss": 0.019027478992938995, "_runtime": 1930.3943791389465, "_timestamp": 1585599300.0272486, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7696084976196289, "Value Loss": 0.019472116604447365, "_runtime": 1931.9618701934814, "_timestamp": 1585599301.5947397, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7553831934928894, "Value Loss": 0.01766102761030197, "_runtime": 1933.5364134311676, "_timestamp": 1585599303.169283, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7424789667129517, "Value Loss": 0.01883978210389614, "_runtime": 1935.0895810127258, "_timestamp": 1585599304.7224505, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7299814820289612, "Value Loss": 0.016713647171854973, "_runtime": 1936.6674630641937, "_timestamp": 1585599306.3003325, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7156258225440979, "Value Loss": 0.017657317221164703, "_runtime": 1938.2367515563965, "_timestamp": 1585599307.869621, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7038995623588562, "Value Loss": 0.010949739255011082, "_runtime": 1939.803219795227, "_timestamp": 1585599309.4360893, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6939995884895325, "Value Loss": 0.04432797059416771, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1941.3840832710266, "_timestamp": 1585599311.0169528, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.678354024887085, "Value Loss": 0.005175792146474123, "_runtime": 1942.9971933364868, "_timestamp": 1585599312.6300628, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6655647158622742, "Value Loss": 0.011526334099471569, "_runtime": 1944.5753145217896, "_timestamp": 1585599314.208184, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6572715044021606, "Value Loss": 0.032821957021951675, "_runtime": 1946.1525206565857, "_timestamp": 1585599315.7853901, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6431865692138672, "Value Loss": 0.009118537418544292, "_runtime": 1947.7320766448975, "_timestamp": 1585599317.3649461, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6333603858947754, "Value Loss": 0.032901693135499954, "_runtime": 1949.2908656597137, "_timestamp": 1585599318.9237351, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6235225796699524, "Value Loss": 0.04290882498025894, "_runtime": 1950.8611171245575, "_timestamp": 1585599320.4939866, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6100866198539734, "Value Loss": 0.00799867045134306, "_runtime": 1952.4277276992798, "_timestamp": 1585599322.0605972, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5969774723052979, "Value Loss": 0.008318714797496796, "_runtime": 1954.0069553852081, "_timestamp": 1585599323.6398249, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.58607017993927, "Value Loss": 0.007565072271972895, "_runtime": 1955.576992034912, "_timestamp": 1585599325.2098615, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5747268199920654, "Value Loss": 0.01090526394546032, "_runtime": 1957.1507949829102, "_timestamp": 1585599326.7836645, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5644341111183167, "Value Loss": 0.010419285856187344, "_runtime": 1958.7165608406067, "_timestamp": 1585599328.3494303, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.553822934627533, "Value Loss": 0.021762598305940628, "_runtime": 1960.270123720169, "_timestamp": 1585599329.9029932, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5422464609146118, "Value Loss": 0.011537889949977398, "_runtime": 1961.8611977100372, "_timestamp": 1585599331.4940672, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5329123139381409, "Value Loss": 0.012404128909111023, "_runtime": 1963.4329912662506, "_timestamp": 1585599333.0658607, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5209424495697021, "Value Loss": 0.012391077354550362, "_runtime": 1964.9972522258759, "_timestamp": 1585599334.6301217, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5141717195510864, "Value Loss": 0.03497176617383957, "_runtime": 1966.5844402313232, "_timestamp": 1585599336.2173097, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4995821416378021, "Value Loss": 0.009933541528880596, "_runtime": 1968.1375243663788, "_timestamp": 1585599337.7703938, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4897444546222687, "Value Loss": 0.013993258588016033, "_runtime": 1969.7019400596619, "_timestamp": 1585599339.3348095, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47940558195114136, "Value Loss": 0.021657127887010574, "_runtime": 1971.2650518417358, "_timestamp": 1585599340.8979213, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46853435039520264, "Value Loss": 0.014937713742256165, "_runtime": 1972.8297934532166, "_timestamp": 1585599342.462663, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4570510983467102, "Value Loss": 0.008463558740913868, "_runtime": 1974.3920121192932, "_timestamp": 1585599344.0248816, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.450705349445343, "Value Loss": 0.03585205227136612, "_runtime": 1975.9338850975037, "_timestamp": 1585599345.5667546, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4369331896305084, "Value Loss": 0.012365964241325855, "_runtime": 1977.4911098480225, "_timestamp": 1585599347.1239793, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42687302827835083, "Value Loss": 0.005051148124039173, "_runtime": 1979.0474305152893, "_timestamp": 1585599348.6803, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4169454276561737, "Value Loss": 0.004048539791256189, "_runtime": 1980.600216627121, "_timestamp": 1585599350.233086, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40633249282836914, "Value Loss": 0.008451897650957108, "_runtime": 1982.1563808918, "_timestamp": 1585599351.7892504, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39978787302970886, "Value Loss": 0.009479804895818233, "_runtime": 1983.7211515903473, "_timestamp": 1585599353.354021, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38923344016075134, "Value Loss": 0.003005755366757512, "_runtime": 1985.2736489772797, "_timestamp": 1585599354.9065185, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38228559494018555, "Value Loss": 0.025065630674362183, "_runtime": 1986.8295550346375, "_timestamp": 1585599356.4624245, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3723621666431427, "Value Loss": 0.01030912809073925, "_runtime": 1988.3932869434357, "_timestamp": 1585599358.0261564, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3650953769683838, "Value Loss": 0.009702214039862156, "_runtime": 1989.9802663326263, "_timestamp": 1585599359.6131358, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35561516880989075, "Value Loss": 0.009150700643658638, "_runtime": 1991.5471515655518, "_timestamp": 1585599361.180021, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3512788414955139, "Value Loss": 0.03248703107237816, "_runtime": 1993.1136002540588, "_timestamp": 1585599362.7464697, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3402283787727356, "Value Loss": 0.0018160180188715458, "_runtime": 1994.6637132167816, "_timestamp": 1585599364.2965827, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3317856788635254, "Value Loss": 0.009148635901510715, "_runtime": 1996.222651720047, "_timestamp": 1585599365.8555212, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3242844343185425, "Value Loss": 0.015795348212122917, "_runtime": 1997.7713232040405, "_timestamp": 1585599367.4041927, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3169056475162506, "Value Loss": 0.008010187186300755, "_runtime": 1999.318782567978, "_timestamp": 1585599368.951652, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3083373010158539, "Value Loss": 0.0019855229184031487, "_runtime": 2000.890645980835, "_timestamp": 1585599370.5235155, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30158963799476624, "Value Loss": 0.02224382944405079, "_runtime": 2002.445872783661, "_timestamp": 1585599372.0787423, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2933778166770935, "Value Loss": 0.002620449522510171, "_runtime": 2004.0151782035828, "_timestamp": 1585599373.6480477, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2880590856075287, "Value Loss": 0.030487503856420517, "_runtime": 2005.5686764717102, "_timestamp": 1585599375.201546, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.28004878759384155, "Value Loss": 0.028974950313568115, "_runtime": 2007.1357247829437, "_timestamp": 1585599376.7685943, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2694934010505676, "Value Loss": 0.017855143174529076, "_runtime": 2008.6896817684174, "_timestamp": 1585599378.3225513, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2623817026615143, "Value Loss": 0.020731987431645393, "_runtime": 2010.2575869560242, "_timestamp": 1585599379.8904564, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25273409485816956, "Value Loss": 0.004741003271192312, "_runtime": 2011.864929676056, "_timestamp": 1585599381.4977992, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24786551296710968, "Value Loss": 0.021527402102947235, "_runtime": 2013.4301652908325, "_timestamp": 1585599383.0630348, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2383219301700592, "Value Loss": 0.019060704857110977, "_runtime": 2014.9979119300842, "_timestamp": 1585599384.6307814, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22943072021007538, "Value Loss": 0.004437337629497051, "_runtime": 2016.564911365509, "_timestamp": 1585599386.1977808, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22350360453128815, "Value Loss": 0.01980280503630638, "_runtime": 2018.1310346126556, "_timestamp": 1585599387.763904, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21780061721801758, "Value Loss": 0.02828112430870533, "_runtime": 2019.6941220760345, "_timestamp": 1585599389.3269916, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21009385585784912, "Value Loss": 0.026485465466976166, "_runtime": 2021.2506890296936, "_timestamp": 1585599390.8835585, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20219586789608002, "Value Loss": 0.027346845716238022, "_runtime": 2022.8108775615692, "_timestamp": 1585599392.443747, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19174998998641968, "Value Loss": 0.0008875154890120029, "_runtime": 2024.3784430027008, "_timestamp": 1585599394.0113125, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18474788963794708, "Value Loss": 0.0024084041360765696, "_runtime": 2025.9362919330597, "_timestamp": 1585599395.5691614, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17964471876621246, "Value Loss": 0.016403015702962875, "_runtime": 2027.4902350902557, "_timestamp": 1585599397.1231046, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17323429882526398, "Value Loss": 0.01945437863469124, "_runtime": 2029.0596799850464, "_timestamp": 1585599398.6925495, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1667795181274414, "Value Loss": 0.006672297604382038, "_runtime": 2030.616362810135, "_timestamp": 1585599400.2492323, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16255265474319458, "Value Loss": 0.02430056408047676, "_runtime": 2032.1712770462036, "_timestamp": 1585599401.8041465, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15597248077392578, "Value Loss": 0.013966192491352558, "_runtime": 2033.7397100925446, "_timestamp": 1585599403.3725796, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14811380207538605, "Value Loss": 0.0060936021618545055, "_runtime": 2035.3446817398071, "_timestamp": 1585599404.9775512, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14473199844360352, "Value Loss": 0.003693929174914956, "_runtime": 2036.9121539592743, "_timestamp": 1585599406.5450234, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13827402889728546, "Value Loss": 0.006443813443183899, "_runtime": 2038.475254058838, "_timestamp": 1585599408.1081235, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1357622891664505, "Value Loss": 0.017112726345658302, "_runtime": 2040.0360045433044, "_timestamp": 1585599409.668874, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12996624410152435, "Value Loss": 0.003716419916599989, "_runtime": 2041.5923540592194, "_timestamp": 1585599411.2252235, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12797105312347412, "Value Loss": 0.022664858028292656, "_runtime": 2043.1379857063293, "_timestamp": 1585599412.7708552, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12084969878196716, "Value Loss": 0.0024273775052279234, "_runtime": 2044.7037155628204, "_timestamp": 1585599414.336585, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11551881581544876, "Value Loss": 0.0058992113918066025, "_runtime": 2046.2686531543732, "_timestamp": 1585599415.9015226, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11208806931972504, "Value Loss": 0.006905352231115103, "_runtime": 2047.833158493042, "_timestamp": 1585599417.466028, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10785091668367386, "Value Loss": 0.0004051980213262141, "_runtime": 2049.3891665935516, "_timestamp": 1585599419.022036, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10400765389204025, "Value Loss": 0.015357057563960552, "_runtime": 2050.9531037807465, "_timestamp": 1585599420.5859733, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10008347034454346, "Value Loss": 0.00648690527305007, "_runtime": 2052.518947124481, "_timestamp": 1585599422.1518166, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09628735482692719, "Value Loss": 0.003992550540715456, "_runtime": 2054.074654817581, "_timestamp": 1585599423.7075243, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09217426180839539, "Value Loss": 0.015584047883749008, "_runtime": 2055.6312925815582, "_timestamp": 1585599425.264162, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08958113938570023, "Value Loss": 0.014562712050974369, "_runtime": 2057.1979789733887, "_timestamp": 1585599426.8308485, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08415008336305618, "Value Loss": 0.01566540263593197, "_runtime": 2058.7987761497498, "_timestamp": 1585599428.4316456, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08236351609230042, "Value Loss": 0.019652463495731354, "_runtime": 2060.36474108696, "_timestamp": 1585599429.9976106, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07590906322002411, "Value Loss": 0.000503679970279336, "_runtime": 2061.9307951927185, "_timestamp": 1585599431.5636647, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0737842321395874, "Value Loss": 0.019213220104575157, "_runtime": 2063.487968683243, "_timestamp": 1585599433.1208382, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06687363237142563, "Value Loss": 0.009975184686481953, "_runtime": 2065.040896654129, "_timestamp": 1585599434.6737661, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06241903454065323, "Value Loss": 0.0022068198304623365, "_runtime": 2066.607187271118, "_timestamp": 1585599436.2400568, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05740707740187645, "Value Loss": 0.005810234230011702, "_runtime": 2068.162948846817, "_timestamp": 1585599437.7958183, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05524357408285141, "Value Loss": 0.0030386706348508596, "_runtime": 2069.727686882019, "_timestamp": 1585599439.3605564, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05055322125554085, "Value Loss": 0.005458251107484102, "_runtime": 2071.2920558452606, "_timestamp": 1585599440.9249253, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04923084005713463, "Value Loss": 0.0177693460136652, "_runtime": 2072.8592143058777, "_timestamp": 1585599442.4920838, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04473663493990898, "Value Loss": 0.0034466248471289873, "_runtime": 2074.4243578910828, "_timestamp": 1585599444.0572274, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04299914836883545, "Value Loss": 0.016068892553448677, "_runtime": 2075.977995634079, "_timestamp": 1585599445.610865, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.037401240319013596, "Value Loss": 0.014541646465659142, "_runtime": 2077.534494638443, "_timestamp": 1585599447.1673641, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03485054895281792, "Value Loss": 0.012309305369853973, "_runtime": 2079.096881866455, "_timestamp": 1585599448.7297513, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029747365042567253, "Value Loss": 0.01023853663355112, "_runtime": 2080.6515951156616, "_timestamp": 1585599450.2844646, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0283755362033844, "Value Loss": 0.018277298659086227, "_runtime": 2082.239941596985, "_timestamp": 1585599451.872811, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.020506396889686584, "Value Loss": 0.005034571047872305, "_runtime": 2083.8043353557587, "_timestamp": 1585599453.4372048, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.019780751317739487, "Value Loss": 0.010076379403471947, "_runtime": 2085.369544506073, "_timestamp": 1585599455.002414, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01396902371197939, "Value Loss": 0.001663054688833654, "_runtime": 2086.9350781440735, "_timestamp": 1585599456.5679476, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010344840586185455, "Value Loss": 0.0034901981707662344, "_runtime": 2088.4879891872406, "_timestamp": 1585599458.1208587, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007901998236775398, "Value Loss": 0.0014525172300636768, "_runtime": 2090.042861700058, "_timestamp": 1585599459.6757312, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003913644701242447, "Value Loss": 0.0002660985919646919, "_runtime": 2091.6109969615936, "_timestamp": 1585599461.2438664, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002985798753798008, "Value Loss": 0.004869996570050716, "_runtime": 2093.1523332595825, "_timestamp": 1585599462.7852027, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00048784975660964847, "Value Loss": 0.004035992547869682, "_runtime": 2094.706043481827, "_timestamp": 1585599464.338913, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026238306891173124, "Value Loss": 0.015072322450578213, "_runtime": 2096.2501635551453, "_timestamp": 1585599465.883033, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006346819456666708, "Value Loss": 0.010842174291610718, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2097.805192708969, "_timestamp": 1585599467.4380622, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009399698115885258, "Value Loss": 0.00017525177099741995, "_runtime": 2099.3733146190643, "_timestamp": 1585599469.006184, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009495561942458153, "Value Loss": 0.015699738636612892, "_runtime": 2100.9265167713165, "_timestamp": 1585599470.5593863, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012581664137542248, "Value Loss": 0.012544321827590466, "_runtime": 2102.4807658195496, "_timestamp": 1585599472.1136353, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018937556073069572, "Value Loss": 0.0036892446223646402, "_runtime": 2104.0464754104614, "_timestamp": 1585599473.679345, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020396048203110695, "Value Loss": 0.0016499735647812486, "_runtime": 2105.637362241745, "_timestamp": 1585599475.2702317, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02192644774913788, "Value Loss": 0.01598142459988594, "_runtime": 2107.2013359069824, "_timestamp": 1585599476.8342054, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025292618200182915, "Value Loss": 0.002841668901965022, "_runtime": 2108.768840789795, "_timestamp": 1585599478.4017103, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02742471732199192, "Value Loss": 0.00063055579084903, "_runtime": 2110.3353159427643, "_timestamp": 1585599479.9681854, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027823027223348618, "Value Loss": 0.01407666876912117, "_runtime": 2111.9018540382385, "_timestamp": 1585599481.5347235, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03275732323527336, "Value Loss": 0.006926719099283218, "_runtime": 2113.466888666153, "_timestamp": 1585599483.0997581, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.035208236426115036, "Value Loss": 0.006148341111838818, "_runtime": 2115.031685113907, "_timestamp": 1585599484.6645546, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03733082115650177, "Value Loss": 0.004657104145735502, "_runtime": 2116.5950486660004, "_timestamp": 1585599486.2279181, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04025473818182945, "Value Loss": 0.0029451821465045214, "_runtime": 2118.1488604545593, "_timestamp": 1585599487.78173, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.041826169937849045, "Value Loss": 0.002485032891854644, "_runtime": 2119.701413869858, "_timestamp": 1585599489.3342834, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04494883865118027, "Value Loss": 0.0039046918973326683, "_runtime": 2121.2578778266907, "_timestamp": 1585599490.8907473, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04356915503740311, "Value Loss": 0.014919827692210674, "_runtime": 2122.825980901718, "_timestamp": 1585599492.4588504, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04568645358085632, "Value Loss": 0.014969919808208942, "_runtime": 2124.3808562755585, "_timestamp": 1585599494.0137258, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04913615062832832, "Value Loss": 0.010526085272431374, "_runtime": 2125.9322769641876, "_timestamp": 1585599495.5651464, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05034131929278374, "Value Loss": 0.012570424005389214, "_runtime": 2127.5136761665344, "_timestamp": 1585599497.1465456, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.053216878324747086, "Value Loss": 0.008149283938109875, "_runtime": 2129.0679433345795, "_timestamp": 1585599498.7008128, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05652853846549988, "Value Loss": 0.0044346582144498825, "_runtime": 2130.6363184452057, "_timestamp": 1585599500.269188, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.058678243309259415, "Value Loss": 0.0012404636945575476, "_runtime": 2132.1986095905304, "_timestamp": 1585599501.831479, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05905275419354439, "Value Loss": 0.0004022393259219825, "_runtime": 2133.7735481262207, "_timestamp": 1585599503.4064176, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06070626527070999, "Value Loss": 0.0018713186727836728, "_runtime": 2135.3445930480957, "_timestamp": 1585599504.9774625, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06261973083019257, "Value Loss": 0.006563649512827396, "_runtime": 2136.9193363189697, "_timestamp": 1585599506.5522058, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06402728706598282, "Value Loss": 8.549547055736184e-05, "_runtime": 2138.486712217331, "_timestamp": 1585599508.1195817, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06522884964942932, "Value Loss": 0.004357823170721531, "_runtime": 2140.0523936748505, "_timestamp": 1585599509.6852632, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06599218398332596, "Value Loss": 0.0037856129929423332, "_runtime": 2141.621059656143, "_timestamp": 1585599511.2539291, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06597188115119934, "Value Loss": 0.0037364009767770767, "_runtime": 2143.1823167800903, "_timestamp": 1585599512.8151863, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.067893847823143, "Value Loss": 0.0042547546327114105, "_runtime": 2144.7522411346436, "_timestamp": 1585599514.3851106, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06711417436599731, "Value Loss": 0.013243980705738068, "_runtime": 2146.3305802345276, "_timestamp": 1585599515.9634497, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06937183439731598, "Value Loss": 0.0006583250360563397, "_runtime": 2147.8992805480957, "_timestamp": 1585599517.53215, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0698363333940506, "Value Loss": 0.009984237141907215, "_runtime": 2149.4612925052643, "_timestamp": 1585599519.094162, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07057160139083862, "Value Loss": 0.011209089308977127, "_runtime": 2151.056177377701, "_timestamp": 1585599520.6890469, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06992889940738678, "Value Loss": 0.013364975340664387, "_runtime": 2152.6229367256165, "_timestamp": 1585599522.2558062, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07371754944324493, "Value Loss": 0.0032515106722712517, "_runtime": 2154.1895644664764, "_timestamp": 1585599523.822434, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07492434233427048, "Value Loss": 0.009217669256031513, "_runtime": 2155.761063337326, "_timestamp": 1585599525.3939328, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07699268311262131, "Value Loss": 0.003939277026802301, "_runtime": 2157.3157062530518, "_timestamp": 1585599526.9485757, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07900938391685486, "Value Loss": 0.003962081857025623, "_runtime": 2158.871240377426, "_timestamp": 1585599528.5041099, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08054465055465698, "Value Loss": 0.006638512015342712, "_runtime": 2160.427440881729, "_timestamp": 1585599530.0603104, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08234058320522308, "Value Loss": 0.005980221554636955, "_runtime": 2161.9934544563293, "_timestamp": 1585599531.626324, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08247873932123184, "Value Loss": 0.012395461089909077, "_runtime": 2163.5603079795837, "_timestamp": 1585599533.1931775, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08454179018735886, "Value Loss": 0.007311889436095953, "_runtime": 2165.117609024048, "_timestamp": 1585599534.7504785, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08732429891824722, "Value Loss": 0.003518682671710849, "_runtime": 2166.6861097812653, "_timestamp": 1585599536.3189793, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08863517642021179, "Value Loss": 0.0016913458239287138, "_runtime": 2168.2572894096375, "_timestamp": 1585599537.890159, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09018518775701523, "Value Loss": 0.0008193828398361802, "_runtime": 2169.827983856201, "_timestamp": 1585599539.4608533, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0914163663983345, "Value Loss": 0.006339741870760918, "_runtime": 2171.4019796848297, "_timestamp": 1585599541.0348492, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09001772850751877, "Value Loss": 0.012417953461408615, "_runtime": 2172.9813957214355, "_timestamp": 1585599542.6142652, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09332886338233948, "Value Loss": 0.0013548263814300299, "_runtime": 2174.5863790512085, "_timestamp": 1585599544.2192485, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09431646019220352, "Value Loss": 0.004018186125904322, "_runtime": 2176.157069683075, "_timestamp": 1585599545.7899392, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0929950550198555, "Value Loss": 0.01142176054418087, "_runtime": 2177.7251436710358, "_timestamp": 1585599547.3580132, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09651124477386475, "Value Loss": 0.00213215546682477, "_runtime": 2179.293072938919, "_timestamp": 1585599548.9259424, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09698819369077682, "Value Loss": 0.001991900149732828, "_runtime": 2180.853229045868, "_timestamp": 1585599550.4860985, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09613147377967834, "Value Loss": 0.003692610887810588, "_runtime": 2182.4205524921417, "_timestamp": 1585599552.053422, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09445832669734955, "Value Loss": 0.011370150372385979, "_runtime": 2183.9881381988525, "_timestamp": 1585599553.6210077, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09734438359737396, "Value Loss": 0.0031882748007774353, "_runtime": 2185.5568566322327, "_timestamp": 1585599555.189726, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09553425759077072, "Value Loss": 0.011767287738621235, "_runtime": 2187.125122308731, "_timestamp": 1585599556.7579918, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09855487197637558, "Value Loss": 0.00027024411247111857, "_runtime": 2188.704276561737, "_timestamp": 1585599558.337146, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09687446057796478, "Value Loss": 0.010562852025032043, "_runtime": 2190.283430337906, "_timestamp": 1585599559.9162998, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09889489412307739, "Value Loss": 0.0035310653038322926, "_runtime": 2191.841861963272, "_timestamp": 1585599561.4747314, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09973818063735962, "Value Loss": 0.0032966083381325006, "_runtime": 2193.4095656871796, "_timestamp": 1585599563.0424352, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09726706892251968, "Value Loss": 0.009542425163090229, "_runtime": 2194.9793050289154, "_timestamp": 1585599564.6121745, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09946715086698532, "Value Loss": 0.0013206085423007607, "_runtime": 2196.5456907749176, "_timestamp": 1585599566.1785603, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09891470521688461, "Value Loss": 0.0011388484854251146, "_runtime": 2198.1584708690643, "_timestamp": 1585599567.7913404, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09641631692647934, "Value Loss": 0.011107712052762508, "_runtime": 2199.7390987873077, "_timestamp": 1585599569.3719683, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09628237783908844, "Value Loss": 0.010928410105407238, "_runtime": 2201.3044855594635, "_timestamp": 1585599570.937355, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09864576160907745, "Value Loss": 0.0006294511840678751, "_runtime": 2202.855952501297, "_timestamp": 1585599572.488822, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09850380569696426, "Value Loss": 0.0007421018672175705, "_runtime": 2204.429550409317, "_timestamp": 1585599574.06242, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09591544419527054, "Value Loss": 0.010755755938589573, "_runtime": 2205.9956560134888, "_timestamp": 1585599575.6285255, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09846291691064835, "Value Loss": 0.0015983335906639695, "_runtime": 2207.5574872493744, "_timestamp": 1585599577.1903567, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09794739633798599, "Value Loss": 0.003244322258979082, "_runtime": 2209.12975358963, "_timestamp": 1585599578.762623, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09826340526342392, "Value Loss": 0.0017339972546324134, "_runtime": 2210.7065908908844, "_timestamp": 1585599580.3394604, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09810550510883331, "Value Loss": 0.0032819299958646297, "_runtime": 2212.28480553627, "_timestamp": 1585599581.917675, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09558897465467453, "Value Loss": 0.010299189947545528, "_runtime": 2213.8422474861145, "_timestamp": 1585599583.475117, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09794285148382187, "Value Loss": 0.0029821107164025307, "_runtime": 2215.3984916210175, "_timestamp": 1585599585.031361, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09795989096164703, "Value Loss": 0.0019252398051321507, "_runtime": 2216.9541013240814, "_timestamp": 1585599586.5869708, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09780986607074738, "Value Loss": 0.0021663696970790625, "_runtime": 2218.520198583603, "_timestamp": 1585599588.153068, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09796898812055588, "Value Loss": 0.004302009008824825, "_runtime": 2220.110580921173, "_timestamp": 1585599589.7434504, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09696047753095627, "Value Loss": 0.00039834121707826853, "_runtime": 2221.667428255081, "_timestamp": 1585599591.3002977, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09777871519327164, "Value Loss": 0.0021728090941905975, "_runtime": 2223.2213504314423, "_timestamp": 1585599592.85422, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09712155163288116, "Value Loss": 0.00290839490480721, "_runtime": 2224.764628648758, "_timestamp": 1585599594.3974981, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09558885544538498, "Value Loss": 0.006193740293383598, "_runtime": 2226.3200562000275, "_timestamp": 1585599595.9529257, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09704011678695679, "Value Loss": 0.001971235265955329, "_runtime": 2227.87504696846, "_timestamp": 1585599597.5079165, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09413482248783112, "Value Loss": 0.00977266114205122, "_runtime": 2229.438159942627, "_timestamp": 1585599599.0710294, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09587705135345459, "Value Loss": 0.008503139019012451, "_runtime": 2231.003208875656, "_timestamp": 1585599600.6360784, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09697218239307404, "Value Loss": 0.00012502398749347776, "_runtime": 2232.569633245468, "_timestamp": 1585599602.2025027, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09584037959575653, "Value Loss": 0.0023734853602945805, "_runtime": 2234.132084608078, "_timestamp": 1585599603.764954, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09685088694095612, "Value Loss": 0.0030546030029654503, "_runtime": 2235.698561191559, "_timestamp": 1585599605.3314307, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09749951213598251, "Value Loss": 0.002201766474172473, "_runtime": 2237.2597324848175, "_timestamp": 1585599606.892602, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09627719968557358, "Value Loss": 0.0013339149300009012, "_runtime": 2238.823251247406, "_timestamp": 1585599608.4561207, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0962134450674057, "Value Loss": 0.00012267772399354726, "_runtime": 2240.375152349472, "_timestamp": 1585599610.0080218, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09549469500780106, "Value Loss": 0.002981636207550764, "_runtime": 2241.9319660663605, "_timestamp": 1585599611.5648355, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09391079097986221, "Value Loss": 0.007055451162159443, "_runtime": 2243.531606197357, "_timestamp": 1585599613.1644757, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09482377022504807, "Value Loss": 0.0019012914272025228, "_runtime": 2245.0944545269012, "_timestamp": 1585599614.727324, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09398329257965088, "Value Loss": 0.0026422131340950727, "_runtime": 2246.653330564499, "_timestamp": 1585599616.2862, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09241369366645813, "Value Loss": 0.006484581157565117, "_runtime": 2248.218738794327, "_timestamp": 1585599617.8516083, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09313061088323593, "Value Loss": 0.0025518403854221106, "_runtime": 2249.7725672721863, "_timestamp": 1585599619.4054368, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0923243910074234, "Value Loss": 0.0008348275441676378, "_runtime": 2251.3274269104004, "_timestamp": 1585599620.9602964, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08998855203390121, "Value Loss": 0.009250784292817116, "_runtime": 2252.883143901825, "_timestamp": 1585599622.5160134, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0921984612941742, "Value Loss": 0.0029238746501505375, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2254.437626361847, "_timestamp": 1585599624.0704958, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09173089265823364, "Value Loss": 0.002834879094734788, "_runtime": 2256.0048332214355, "_timestamp": 1585599625.6377027, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09196707606315613, "Value Loss": 0.002659378107637167, "_runtime": 2257.569650888443, "_timestamp": 1585599627.2025204, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08904223144054413, "Value Loss": 0.00859068427234888, "_runtime": 2259.1331753730774, "_timestamp": 1585599628.7660449, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09113925695419312, "Value Loss": 0.0016241701086983085, "_runtime": 2260.6866171360016, "_timestamp": 1585599630.3194866, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09004776924848557, "Value Loss": 0.008728121407330036, "_runtime": 2262.2414054870605, "_timestamp": 1585599631.874275, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0903601199388504, "Value Loss": 0.0007611223845742643, "_runtime": 2263.807610273361, "_timestamp": 1585599633.4404798, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09098484367132187, "Value Loss": 0.006533373612910509, "_runtime": 2265.3625631332397, "_timestamp": 1585599634.9954326, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08919981867074966, "Value Loss": 0.008055033162236214, "_runtime": 2266.963990211487, "_timestamp": 1585599636.5968597, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09238073229789734, "Value Loss": 0.002493242034688592, "_runtime": 2268.5216059684753, "_timestamp": 1585599638.1544755, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09152039140462875, "Value Loss": 0.0007889996632002294, "_runtime": 2270.0869846343994, "_timestamp": 1585599639.719854, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09234631806612015, "Value Loss": 0.000140542775625363, "_runtime": 2271.64234995842, "_timestamp": 1585599641.2752194, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0923205092549324, "Value Loss": 0.005611608736217022, "_runtime": 2273.208240509033, "_timestamp": 1585599642.84111, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09020476788282394, "Value Loss": 0.008634277619421482, "_runtime": 2274.7627992630005, "_timestamp": 1585599644.3956687, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09282886981964111, "Value Loss": 0.002689649583771825, "_runtime": 2276.3249514102936, "_timestamp": 1585599645.957821, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09326227009296417, "Value Loss": 0.00016579819202888757, "_runtime": 2277.889954805374, "_timestamp": 1585599647.5228243, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09182730317115784, "Value Loss": 0.005092841573059559, "_runtime": 2279.4434580802917, "_timestamp": 1585599649.0763276, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09331820160150528, "Value Loss": 0.0026774678844958544, "_runtime": 2280.999396085739, "_timestamp": 1585599650.6322656, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09111006557941437, "Value Loss": 0.004037963226437569, "_runtime": 2282.5634474754333, "_timestamp": 1585599652.196317, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09016316384077072, "Value Loss": 0.008360353298485279, "_runtime": 2284.126570701599, "_timestamp": 1585599653.7594402, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0920841246843338, "Value Loss": 0.002563472604379058, "_runtime": 2285.6786823272705, "_timestamp": 1585599655.3115518, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08963876217603683, "Value Loss": 0.00775030767545104, "_runtime": 2287.2451248168945, "_timestamp": 1585599656.8779943, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09153936803340912, "Value Loss": 0.00024964852491393685, "_runtime": 2288.8096475601196, "_timestamp": 1585599658.442517, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09048347920179367, "Value Loss": 0.0076409089379012585, "_runtime": 2290.3873200416565, "_timestamp": 1585599660.0201895, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08859312534332275, "Value Loss": 0.008079487830400467, "_runtime": 2291.943120956421, "_timestamp": 1585599661.5759904, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09072187542915344, "Value Loss": 0.0019736296962946653, "_runtime": 2293.5000739097595, "_timestamp": 1585599663.1329434, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0907435342669487, "Value Loss": 0.002372950781136751, "_runtime": 2295.05384683609, "_timestamp": 1585599664.6867163, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08880589157342911, "Value Loss": 0.007648651022464037, "_runtime": 2296.6055307388306, "_timestamp": 1585599666.2384002, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09085345268249512, "Value Loss": 0.0009743556729517877, "_runtime": 2298.1702365875244, "_timestamp": 1585599667.803106, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09052018821239471, "Value Loss": 0.004904467612504959, "_runtime": 2299.734399795532, "_timestamp": 1585599669.3672693, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09122635424137115, "Value Loss": 0.0022757728584110737, "_runtime": 2301.288800239563, "_timestamp": 1585599670.9216697, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08954575657844543, "Value Loss": 0.005462086759507656, "_runtime": 2302.8466148376465, "_timestamp": 1585599672.4794843, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0885673463344574, "Value Loss": 0.00764714740216732, "_runtime": 2304.399528026581, "_timestamp": 1585599674.0323975, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09106212109327316, "Value Loss": 0.002314668847247958, "_runtime": 2305.973484516144, "_timestamp": 1585599675.606354, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09074050188064575, "Value Loss": 0.005780476611107588, "_runtime": 2307.543679714203, "_timestamp": 1585599677.1765492, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09010586887598038, "Value Loss": 0.0032353647984564304, "_runtime": 2309.112334728241, "_timestamp": 1585599678.7452042, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09146468341350555, "Value Loss": 0.00452045351266861, "_runtime": 2310.6648161411285, "_timestamp": 1585599680.2976856, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09093189984560013, "Value Loss": 0.006657477002590895, "_runtime": 2312.21932554245, "_timestamp": 1585599681.852195, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09183098375797272, "Value Loss": 0.002836529165506363, "_runtime": 2313.817511320114, "_timestamp": 1585599683.4503808, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09078221768140793, "Value Loss": 0.007246834225952625, "_runtime": 2315.3805079460144, "_timestamp": 1585599685.0133774, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09444993734359741, "Value Loss": 0.0019901907071471214, "_runtime": 2316.9435143470764, "_timestamp": 1585599686.5763838, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.094491146504879, "Value Loss": 0.004540816880762577, "_runtime": 2318.5015976428986, "_timestamp": 1585599688.1344671, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09462366998195648, "Value Loss": 0.0004516183689702302, "_runtime": 2320.0437200069427, "_timestamp": 1585599689.6765895, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09530092030763626, "Value Loss": 0.0029822250362485647, "_runtime": 2321.58265209198, "_timestamp": 1585599691.2155216, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09671040624380112, "Value Loss": 0.00019504770170897245, "_runtime": 2323.1359629631042, "_timestamp": 1585599692.7688324, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09751635789871216, "Value Loss": 0.002057734876871109, "_runtime": 2324.699682712555, "_timestamp": 1585599694.3325522, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09723041206598282, "Value Loss": 0.001281867385841906, "_runtime": 2326.2517609596252, "_timestamp": 1585599695.8846304, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09547998756170273, "Value Loss": 0.007251451723277569, "_runtime": 2327.8051540851593, "_timestamp": 1585599697.4380236, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09677295386791229, "Value Loss": 0.0005300732445903122, "_runtime": 2329.371055841446, "_timestamp": 1585599699.0039253, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09608085453510284, "Value Loss": 0.006566163618117571, "_runtime": 2330.9416151046753, "_timestamp": 1585599700.5744846, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09719543159008026, "Value Loss": 0.001367616350762546, "_runtime": 2332.505724668503, "_timestamp": 1585599702.1385942, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09717757254838943, "Value Loss": 0.0022354330867528915, "_runtime": 2334.061018228531, "_timestamp": 1585599703.6938877, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09741776436567307, "Value Loss": 0.001778937759809196, "_runtime": 2335.6393196582794, "_timestamp": 1585599705.2721891, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09452727437019348, "Value Loss": 0.006727501749992371, "_runtime": 2337.204459667206, "_timestamp": 1585599706.8373291, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09550435841083527, "Value Loss": 0.00212671491317451, "_runtime": 2338.76934838295, "_timestamp": 1585599708.4022179, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09612993896007538, "Value Loss": 0.00227062008343637, "_runtime": 2340.3322248458862, "_timestamp": 1585599709.9650943, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09566355496644974, "Value Loss": 0.0013720501447096467, "_runtime": 2341.8986353874207, "_timestamp": 1585599711.5315049, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09388003498315811, "Value Loss": 0.004313620738685131, "_runtime": 2343.461450815201, "_timestamp": 1585599713.0943203, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09530998766422272, "Value Loss": 0.0011356823379173875, "_runtime": 2345.0059230327606, "_timestamp": 1585599714.6387925, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09262480586767197, "Value Loss": 0.005204501561820507, "_runtime": 2346.570429086685, "_timestamp": 1585599716.2032986, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09316450357437134, "Value Loss": 0.0022013746201992035, "_runtime": 2348.1374242305756, "_timestamp": 1585599717.7702937, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09033500403165817, "Value Loss": 0.006465654820203781, "_runtime": 2349.6941571235657, "_timestamp": 1585599719.3270266, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0918613150715828, "Value Loss": 0.004217031877487898, "_runtime": 2351.2479457855225, "_timestamp": 1585599720.8808153, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09169331192970276, "Value Loss": 0.000561752007342875, "_runtime": 2352.8135201931, "_timestamp": 1585599722.4463897, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09056179970502853, "Value Loss": 0.0005448252195492387, "_runtime": 2354.3590190410614, "_timestamp": 1585599723.9918885, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09048635512590408, "Value Loss": 0.001256958581507206, "_runtime": 2355.912567138672, "_timestamp": 1585599725.5454366, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08924469351768494, "Value Loss": 0.0005532097420655191, "_runtime": 2357.4787080287933, "_timestamp": 1585599727.1115775, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08928228914737701, "Value Loss": 0.00040126172825694084, "_runtime": 2359.078943490982, "_timestamp": 1585599728.711813, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08752685785293579, "Value Loss": 0.00046008097706362605, "_runtime": 2360.6432616710663, "_timestamp": 1585599730.2761312, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08736476302146912, "Value Loss": 0.000800020236056298, "_runtime": 2362.2158522605896, "_timestamp": 1585599731.8487217, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08608760684728622, "Value Loss": 0.001141440705396235, "_runtime": 2363.76921916008, "_timestamp": 1585599733.4020886, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08597416430711746, "Value Loss": 0.0011724336072802544, "_runtime": 2365.332403421402, "_timestamp": 1585599734.965273, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08467375487089157, "Value Loss": 0.0017152014188468456, "_runtime": 2366.874410867691, "_timestamp": 1585599736.5072803, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08313126862049103, "Value Loss": 0.0027247967664152384, "_runtime": 2368.436690568924, "_timestamp": 1585599738.06956, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08041758090257645, "Value Loss": 0.005424925126135349, "_runtime": 2369.9904885292053, "_timestamp": 1585599739.623358, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.081649050116539, "Value Loss": 0.001983455615118146, "_runtime": 2371.5511844158173, "_timestamp": 1585599741.184054, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07938791066408157, "Value Loss": 0.002934647724032402, "_runtime": 2373.119607448578, "_timestamp": 1585599742.752477, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08031623065471649, "Value Loss": 0.001158942119218409, "_runtime": 2374.6747632026672, "_timestamp": 1585599744.3076327, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07825654000043869, "Value Loss": 0.004322572611272335, "_runtime": 2376.228362560272, "_timestamp": 1585599745.861232, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0778345912694931, "Value Loss": 0.00144485617056489, "_runtime": 2377.7818624973297, "_timestamp": 1585599747.414732, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07493573427200317, "Value Loss": 0.006105316802859306, "_runtime": 2379.3355996608734, "_timestamp": 1585599748.9684691, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07644064724445343, "Value Loss": 0.004251255188137293, "_runtime": 2380.888856649399, "_timestamp": 1585599750.5217261, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07649718970060349, "Value Loss": 0.0001125238704844378, "_runtime": 2382.4923906326294, "_timestamp": 1585599752.12526, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07526573538780212, "Value Loss": 0.00034048082306981087, "_runtime": 2384.0364134311676, "_timestamp": 1585599753.669283, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07480571419000626, "Value Loss": 0.005400151014328003, "_runtime": 2385.6009504795074, "_timestamp": 1585599755.23382, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07540149986743927, "Value Loss": 0.0018913692329078913, "_runtime": 2387.154858827591, "_timestamp": 1585599756.7877283, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07514685392379761, "Value Loss": 0.0004114813928026706, "_runtime": 2388.7196202278137, "_timestamp": 1585599758.3524897, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07456521689891815, "Value Loss": 0.0006960661266930401, "_runtime": 2390.2810599803925, "_timestamp": 1585599759.9139295, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07478666305541992, "Value Loss": 0.0015418423572555184, "_runtime": 2391.844236135483, "_timestamp": 1585599761.4771056, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07264966517686844, "Value Loss": 0.001889592851512134, "_runtime": 2393.406056880951, "_timestamp": 1585599763.0389264, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07274109125137329, "Value Loss": 0.004096304066479206, "_runtime": 2394.9599092006683, "_timestamp": 1585599764.5927787, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07154795527458191, "Value Loss": 0.0012134520802646875, "_runtime": 2396.5143644809723, "_timestamp": 1585599766.147234, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07182223349809647, "Value Loss": 0.0018468014895915985, "_runtime": 2398.059281349182, "_timestamp": 1585599767.6921508, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07134190946817398, "Value Loss": 0.0017758661415427923, "_runtime": 2399.6012666225433, "_timestamp": 1585599769.234136, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06979300081729889, "Value Loss": 0.001735267578624189, "_runtime": 2401.1598558425903, "_timestamp": 1585599770.7927253, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07038961350917816, "Value Loss": 0.0015407389728352427, "_runtime": 2402.7141358852386, "_timestamp": 1585599772.3470054, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06925059854984283, "Value Loss": 0.0017703734338283539, "_runtime": 2404.2791237831116, "_timestamp": 1585599773.9119933, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06953883916139603, "Value Loss": 0.0011660692980512977, "_runtime": 2405.86861205101, "_timestamp": 1585599775.5014815, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0681023895740509, "Value Loss": 0.0016772502567619085, "_runtime": 2407.4343540668488, "_timestamp": 1585599777.0672235, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06736589223146439, "Value Loss": 0.00400112010538578, "_runtime": 2408.998951435089, "_timestamp": 1585599778.631821, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0673101395368576, "Value Loss": 0.0001483711675973609, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 2410.544768810272, "_timestamp": 1585599780.1776383, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06679800152778625, "Value Loss": 0.0017757685855031013, "_runtime": 2410.544768810272, "_timestamp": 1585599780.1776383, "_step": 499}
