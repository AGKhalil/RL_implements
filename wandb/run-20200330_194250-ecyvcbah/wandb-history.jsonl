{"Episode reward": -41.65661190629164, "Episode length": 999, "Policy Loss": -0.0514799989759922, "Value Loss": 0.0038807522505521774, "_runtime": 19.746811628341675, "_timestamp": 1585597389.379681, "_step": 0}
{"Episode reward": -98.39427089656942, "Episode length": 999, "Policy Loss": 1.0930333137512207, "Value Loss": 210.54354858398438, "_runtime": 21.206024408340454, "_timestamp": 1585597390.838894, "_step": 1}
{"Episode reward": -99.7756943701578, "Episode length": 999, "Policy Loss": -9.891526222229004, "Value Loss": 4162.0908203125, "_runtime": 22.691328048706055, "_timestamp": 1585597392.3241975, "_step": 2}
{"Episode reward": -99.60911053877652, "Episode length": 999, "Policy Loss": -7.442556381225586, "Value Loss": 299.9153137207031, "_runtime": 24.187750101089478, "_timestamp": 1585597393.8206196, "_step": 3}
{"Episode reward": -99.8584955618761, "Episode length": 999, "Policy Loss": -4.1944193840026855, "Value Loss": 315.5631408691406, "_runtime": 25.606616735458374, "_timestamp": 1585597395.2394862, "_step": 4}
{"Episode reward": 5.734906357655902, "Episode length": 945, "Policy Loss": -0.20710085332393646, "Value Loss": 15.132022857666016, "_runtime": 26.73917818069458, "_timestamp": 1585597396.3720477, "_step": 5}
{"Episode reward": 25.796616434655093, "Episode length": 743, "Policy Loss": 0.25536155700683594, "Value Loss": 522.279541015625, "_runtime": 28.248941659927368, "_timestamp": 1585597397.8818111, "_step": 6}
{"Episode reward": -99.77248645779189, "Episode length": 999, "Policy Loss": -0.906318187713623, "Value Loss": 0.0228482186794281, "_runtime": 28.987147092819214, "_timestamp": 1585597398.6200166, "_step": 7}
{"Episode reward": 52.8659319281967, "Episode length": 475, "Policy Loss": 0.5475268363952637, "Value Loss": 21.01581382751465, "_runtime": 29.50964045524597, "_timestamp": 1585597399.14251, "_step": 8}
{"Episode reward": 66.74759248354802, "Episode length": 333, "Policy Loss": 21.439115524291992, "Value Loss": 173.68539428710938, "_runtime": 29.92416262626648, "_timestamp": 1585597399.557032, "_step": 9}
{"Episode reward": 74.20640575391435, "Episode length": 259, "Policy Loss": 1.900219440460205, "Value Loss": 38.5534782409668, "_runtime": 30.11142373085022, "_timestamp": 1585597399.7442932, "_step": 10}
{"Episode reward": 88.99510124267033, "Episode length": 112, "Policy Loss": 4.053277969360352, "Value Loss": 89.16943359375, "_runtime": 30.25079894065857, "_timestamp": 1585597399.8836684, "_step": 11}
{"Episode reward": 91.62743133388932, "Episode length": 84, "Policy Loss": 4.591215133666992, "Value Loss": 118.91319274902344, "_runtime": 30.41457772254944, "_timestamp": 1585597400.0474472, "_step": 12}
{"Episode reward": 89.28255215205576, "Episode length": 108, "Policy Loss": 3.7757253646850586, "Value Loss": 92.49905395507812, "_runtime": 30.544124603271484, "_timestamp": 1585597400.176994, "_step": 13}
{"Episode reward": 91.50934048571706, "Episode length": 86, "Policy Loss": 0.7634828090667725, "Value Loss": 116.16797637939453, "_runtime": 31.954257249832153, "_timestamp": 1585597401.5871267, "_step": 14}
{"Episode reward": -96.03061099058426, "Episode length": 999, "Policy Loss": 0.20982016623020172, "Value Loss": 0.0022430296521633863, "_runtime": 33.38410234451294, "_timestamp": 1585597403.0169718, "_step": 15}
{"Episode reward": -97.58631230628697, "Episode length": 999, "Policy Loss": 0.15246696770191193, "Value Loss": 0.0021895982790738344, "_runtime": 34.17978858947754, "_timestamp": 1585597403.812658, "_step": 16}
{"Episode reward": 45.17415063005531, "Episode length": 565, "Policy Loss": -1.7367424964904785, "Value Loss": 17.68482208251953, "_runtime": 34.369024991989136, "_timestamp": 1585597404.0018945, "_step": 17}
{"Episode reward": 90.34603515321945, "Episode length": 97, "Policy Loss": -5.97230339050293, "Value Loss": 103.00019836425781, "_runtime": 35.83159399032593, "_timestamp": 1585597405.4644635, "_step": 18}
{"Episode reward": -98.26965988705619, "Episode length": 999, "Policy Loss": 0.16333787143230438, "Value Loss": 0.002234546933323145, "_runtime": 37.30350422859192, "_timestamp": 1585597406.9363737, "_step": 19}
{"Episode reward": -99.20706413280877, "Episode length": 999, "Policy Loss": 0.21283741295337677, "Value Loss": 0.0023572780191898346, "_runtime": 38.788456439971924, "_timestamp": 1585597408.421326, "_step": 20}
{"Episode reward": -98.80073268027486, "Episode length": 999, "Policy Loss": -0.005792839452624321, "Value Loss": 0.0024719256907701492, "_runtime": 40.30382490158081, "_timestamp": 1585597409.9366944, "_step": 21}
{"Episode reward": -98.49698947126342, "Episode length": 999, "Policy Loss": -0.20899875462055206, "Value Loss": 0.0025427667424082756, "_runtime": 41.82607865333557, "_timestamp": 1585597411.4589481, "_step": 22}
{"Episode reward": -99.88084036498336, "Episode length": 999, "Policy Loss": 0.5095122456550598, "Value Loss": 0.0026381220668554306, "_runtime": 43.332648277282715, "_timestamp": 1585597412.9655178, "_step": 23}
{"Episode reward": -99.80023715308067, "Episode length": 999, "Policy Loss": 0.5269825458526611, "Value Loss": 0.0026888533029705286, "_runtime": 44.873403549194336, "_timestamp": 1585597414.506273, "_step": 24}
{"Episode reward": -99.8631227398028, "Episode length": 999, "Policy Loss": 0.5410344004631042, "Value Loss": 0.0027188987005501986, "_runtime": 46.409239292144775, "_timestamp": 1585597416.0421088, "_step": 25}
{"Episode reward": -99.80099739625744, "Episode length": 999, "Policy Loss": 0.542807936668396, "Value Loss": 0.0027366243302822113, "_runtime": 47.956156730651855, "_timestamp": 1585597417.5890262, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5413477420806885, "Value Loss": 0.0027377824299037457, "_runtime": 49.48377537727356, "_timestamp": 1585597419.1166449, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5529540181159973, "Value Loss": 0.002724326914176345, "_runtime": 51.01105976104736, "_timestamp": 1585597420.6439292, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.54833984375, "Value Loss": 0.002698006108403206, "_runtime": 52.53809118270874, "_timestamp": 1585597422.1709607, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5384443402290344, "Value Loss": 0.002660146914422512, "_runtime": 54.06981635093689, "_timestamp": 1585597423.7026858, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5414211750030518, "Value Loss": 0.0026118687819689512, "_runtime": 55.58791160583496, "_timestamp": 1585597425.220781, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5354296565055847, "Value Loss": 0.0025543863885104656, "_runtime": 57.11705994606018, "_timestamp": 1585597426.7499294, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5249923467636108, "Value Loss": 0.0024889204651117325, "_runtime": 58.63810682296753, "_timestamp": 1585597428.2709763, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5207801461219788, "Value Loss": 0.002416518982499838, "_runtime": 60.160510301589966, "_timestamp": 1585597429.7933798, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5122883319854736, "Value Loss": 0.0023383547086268663, "_runtime": 61.71497845649719, "_timestamp": 1585597431.347848, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.503109872341156, "Value Loss": 0.0022553119342774153, "_runtime": 63.253881216049194, "_timestamp": 1585597432.8867507, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4899027347564697, "Value Loss": 0.0021684826351702213, "_runtime": 64.77824640274048, "_timestamp": 1585597434.411116, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4830043613910675, "Value Loss": 0.0020786598324775696, "_runtime": 66.32573699951172, "_timestamp": 1585597435.9586065, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4711652994155884, "Value Loss": 0.001986737595871091, "_runtime": 67.87323379516602, "_timestamp": 1585597437.5061033, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4609892666339874, "Value Loss": 0.0018934906693175435, "_runtime": 69.4092309474945, "_timestamp": 1585597439.0421004, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44941607117652893, "Value Loss": 0.001799610210582614, "_runtime": 70.95573115348816, "_timestamp": 1585597440.5886006, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4375346004962921, "Value Loss": 0.0017057142686098814, "_runtime": 72.49327039718628, "_timestamp": 1585597442.1261399, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42540085315704346, "Value Loss": 0.0016124183312058449, "_runtime": 74.04226398468018, "_timestamp": 1585597443.6751335, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41305986046791077, "Value Loss": 0.001520221820101142, "_runtime": 75.57952356338501, "_timestamp": 1585597445.212393, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4005567729473114, "Value Loss": 0.0014295841101557016, "_runtime": 77.12894010543823, "_timestamp": 1585597446.7618096, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.38793307542800903, "Value Loss": 0.001340895309112966, "_runtime": 78.66831040382385, "_timestamp": 1585597448.30118, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37523341178894043, "Value Loss": 0.0012545386562123895, "_runtime": 80.2047758102417, "_timestamp": 1585597449.8376453, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3624880611896515, "Value Loss": 0.0011707619996741414, "_runtime": 81.72888231277466, "_timestamp": 1585597451.3617518, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3497326970100403, "Value Loss": 0.0010898180771619081, "_runtime": 83.26624250411987, "_timestamp": 1585597452.899112, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33700278401374817, "Value Loss": 0.0010119248181581497, "_runtime": 84.83754587173462, "_timestamp": 1585597454.4704154, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32432839274406433, "Value Loss": 0.0009372400818392634, "_runtime": 86.37629199028015, "_timestamp": 1585597456.0091615, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3117397725582123, "Value Loss": 0.0008658951846882701, "_runtime": 87.91477584838867, "_timestamp": 1585597457.5476453, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2992572486400604, "Value Loss": 0.0007979401852935553, "_runtime": 89.46397590637207, "_timestamp": 1585597459.0968454, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.28690579533576965, "Value Loss": 0.0007334331749007106, "_runtime": 91.00136184692383, "_timestamp": 1585597460.6342313, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.27471643686294556, "Value Loss": 0.0006724355043843389, "_runtime": 92.5504195690155, "_timestamp": 1585597462.183289, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2626986503601074, "Value Loss": 0.0006148890824988484, "_runtime": 94.09202790260315, "_timestamp": 1585597463.7248974, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.250872939825058, "Value Loss": 0.0005607750499621034, "_runtime": 95.6371660232544, "_timestamp": 1585597465.2700355, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2392592430114746, "Value Loss": 0.0005100565613247454, "_runtime": 97.18445491790771, "_timestamp": 1585597466.8173244, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.22787289321422577, "Value Loss": 0.00046266490244306624, "_runtime": 98.71959352493286, "_timestamp": 1585597468.352463, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21672920882701874, "Value Loss": 0.0004185193101875484, "_runtime": 100.26558327674866, "_timestamp": 1585597469.8984528, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.20584291219711304, "Value Loss": 0.00037753116339445114, "_runtime": 101.81172323226929, "_timestamp": 1585597471.4445927, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.19521433115005493, "Value Loss": 0.0003395504900254309, "_runtime": 103.35938692092896, "_timestamp": 1585597472.9922564, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.18485848605632782, "Value Loss": 0.0003044809855055064, "_runtime": 104.909419298172, "_timestamp": 1585597474.5422888, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17477552592754364, "Value Loss": 0.0002721712808124721, "_runtime": 106.49062037467957, "_timestamp": 1585597476.1234899, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.16498543322086334, "Value Loss": 0.00024253394803963602, "_runtime": 108.03974866867065, "_timestamp": 1585597477.6726182, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15549854934215546, "Value Loss": 0.0002154437534045428, "_runtime": 109.5868821144104, "_timestamp": 1585597479.2197516, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14629459381103516, "Value Loss": 0.00019069398695137352, "_runtime": 111.13470149040222, "_timestamp": 1585597480.767571, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1374036967754364, "Value Loss": 0.00016822015459183604, "_runtime": 112.68223404884338, "_timestamp": 1585597482.3151035, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1288159340620041, "Value Loss": 0.00014784978702664375, "_runtime": 114.2301733493805, "_timestamp": 1585597483.8630428, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12053131312131882, "Value Loss": 0.0001294437824981287, "_runtime": 115.7660653591156, "_timestamp": 1585597485.3989348, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.112549789249897, "Value Loss": 0.0001128679359680973, "_runtime": 117.3033516407013, "_timestamp": 1585597486.9362211, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10487134009599686, "Value Loss": 9.79929682216607e-05, "_runtime": 118.85023021697998, "_timestamp": 1585597488.4830997, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09750605374574661, "Value Loss": 8.471196633763611e-05, "_runtime": 120.38522577285767, "_timestamp": 1585597490.0180953, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09044396132230759, "Value Loss": 7.288536289706826e-05, "_runtime": 121.92241406440735, "_timestamp": 1585597491.5552835, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08368492871522903, "Value Loss": 6.239870708668604e-05, "_runtime": 123.46769976615906, "_timestamp": 1585597493.1005692, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07721883803606033, "Value Loss": 5.312856592354365e-05, "_runtime": 125.00476312637329, "_timestamp": 1585597494.6376326, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07104578614234924, "Value Loss": 4.497362533584237e-05, "_runtime": 126.55154323577881, "_timestamp": 1585597496.1844127, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06516571342945099, "Value Loss": 3.7837267882423475e-05, "_runtime": 128.09793400764465, "_timestamp": 1585597497.7308035, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05957864969968796, "Value Loss": 3.162731445627287e-05, "_runtime": 129.67132592201233, "_timestamp": 1585597499.3041954, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05426434054970741, "Value Loss": 2.6236773919663392e-05, "_runtime": 131.20951390266418, "_timestamp": 1585597500.8423834, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04922282695770264, "Value Loss": 2.1588115487247705e-05, "_runtime": 132.74525427818298, "_timestamp": 1585597502.3781238, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04445412755012512, "Value Loss": 1.7607815607334487e-05, "_runtime": 134.29442167282104, "_timestamp": 1585597503.9272912, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.039958205074071884, "Value Loss": 1.4226333405531477e-05, "_runtime": 135.84166193008423, "_timestamp": 1585597505.4745314, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.035704754292964935, "Value Loss": 1.1358814845152665e-05, "_runtime": 137.38766932487488, "_timestamp": 1585597507.0205388, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0317038893699646, "Value Loss": 8.955829798651394e-06, "_runtime": 138.93450093269348, "_timestamp": 1585597508.5673704, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027945468202233315, "Value Loss": 6.958320227568038e-06, "_runtime": 140.4814417362213, "_timestamp": 1585597510.1143112, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024419475346803665, "Value Loss": 5.313166184350848e-06, "_runtime": 142.02191877365112, "_timestamp": 1585597511.6547883, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02112581394612789, "Value Loss": 3.976566858909791e-06, "_runtime": 143.56889390945435, "_timestamp": 1585597513.2017634, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018054436892271042, "Value Loss": 2.9043515041848877e-06, "_runtime": 145.10532116889954, "_timestamp": 1585597514.7381907, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015185127034783363, "Value Loss": 2.0545555798889836e-06, "_runtime": 146.6406376361847, "_timestamp": 1585597516.273507, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01252798456698656, "Value Loss": 1.3984385986987036e-06, "_runtime": 148.18800377845764, "_timestamp": 1585597517.8208733, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010062804445624352, "Value Loss": 9.022331823871355e-07, "_runtime": 149.72609090805054, "_timestamp": 1585597519.3589604, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007789578288793564, "Value Loss": 5.406407126429258e-07, "_runtime": 151.2732388973236, "_timestamp": 1585597520.9061084, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005698214750736952, "Value Loss": 2.8930651296832366e-07, "_runtime": 152.8586986064911, "_timestamp": 1585597522.491568, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0037786010652780533, "Value Loss": 1.2721645248348068e-07, "_runtime": 154.40844774246216, "_timestamp": 1585597524.0413172, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002030746079981327, "Value Loss": 3.6744488340900716e-08, "_runtime": 155.9596598148346, "_timestamp": 1585597525.5925293, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000424334779381752, "Value Loss": 1.6043486539274454e-09, "_runtime": 157.50881123542786, "_timestamp": 1585597527.1416807, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0010204241843894124, "Value Loss": 9.277755452785641e-09, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 159.04775500297546, "_timestamp": 1585597528.6806245, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0023237382993102074, "Value Loss": 4.8112269723787904e-08, "_runtime": 160.58302330970764, "_timestamp": 1585597530.2158928, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003495710203424096, "Value Loss": 1.0888103929573845e-07, "_runtime": 162.11826181411743, "_timestamp": 1585597531.7511313, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004536342807114124, "Value Loss": 1.8335505558297882e-07, "_runtime": 163.64903092384338, "_timestamp": 1585597533.2819004, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0054557351395487785, "Value Loss": 2.6520854135014815e-07, "_runtime": 165.18639016151428, "_timestamp": 1585597534.8192596, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00626399228349328, "Value Loss": 3.496096496746759e-07, "_runtime": 166.72385239601135, "_timestamp": 1585597536.3567219, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006961112841963768, "Value Loss": 4.3175623432034627e-07, "_runtime": 168.26239895820618, "_timestamp": 1585597537.8952684, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00756730604916811, "Value Loss": 5.102276077195711e-07, "_runtime": 169.81024432182312, "_timestamp": 1585597539.4431138, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00807247031480074, "Value Loss": 5.806222702631203e-07, "_runtime": 171.3438642024994, "_timestamp": 1585597540.9767337, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008486701175570488, "Value Loss": 6.417394615709782e-07, "_runtime": 172.89130020141602, "_timestamp": 1585597542.5241697, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008830207400023937, "Value Loss": 6.947414021851728e-07, "_runtime": 174.42407131195068, "_timestamp": 1585597544.0569408, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009092896245419979, "Value Loss": 7.366905947492342e-07, "_runtime": 176.00630354881287, "_timestamp": 1585597545.639173, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0092848539352417, "Value Loss": 7.681232432332763e-07, "_runtime": 177.5497703552246, "_timestamp": 1585597547.1826398, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009416197426617146, "Value Loss": 7.900088121459703e-07, "_runtime": 179.0826292037964, "_timestamp": 1585597548.7154987, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009486916474997997, "Value Loss": 8.019203505682526e-07, "_runtime": 180.6234850883484, "_timestamp": 1585597550.2563546, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009507120586931705, "Value Loss": 8.053401643337565e-07, "_runtime": 182.14387607574463, "_timestamp": 1585597551.7767456, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009476810693740845, "Value Loss": 8.002136837603757e-07, "_runtime": 183.67372107505798, "_timestamp": 1585597553.3065906, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009395984932780266, "Value Loss": 7.866220244068245e-07, "_runtime": 185.2057921886444, "_timestamp": 1585597554.8386617, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0092848539352417, "Value Loss": 7.681232432332763e-07, "_runtime": 186.72414827346802, "_timestamp": 1585597556.3570178, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00913330726325512, "Value Loss": 7.432536222040653e-07, "_runtime": 188.24287867546082, "_timestamp": 1585597557.8757482, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008951443247497082, "Value Loss": 7.13949930286617e-07, "_runtime": 189.7630844116211, "_timestamp": 1585597559.395954, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008739280514419079, "Value Loss": 6.805064458603738e-07, "_runtime": 191.29535937309265, "_timestamp": 1585597560.9282289, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008506905287504196, "Value Loss": 6.447992291214177e-07, "_runtime": 192.82525968551636, "_timestamp": 1585597562.4581292, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008244222961366177, "Value Loss": 6.055925041437149e-07, "_runtime": 194.34938669204712, "_timestamp": 1585597563.9822562, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007971434853971004, "Value Loss": 5.661794375555473e-07, "_runtime": 195.8782603740692, "_timestamp": 1585597565.5111299, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007688548415899277, "Value Loss": 5.267075380288588e-07, "_runtime": 197.41060185432434, "_timestamp": 1585597567.0434713, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007385445758700371, "Value Loss": 4.859985551775026e-07, "_runtime": 198.97829151153564, "_timestamp": 1585597568.611161, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007072253152728081, "Value Loss": 4.456522901818971e-07, "_runtime": 200.50267267227173, "_timestamp": 1585597570.1355422, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006759048905223608, "Value Loss": 4.070543013767747e-07, "_runtime": 202.03348112106323, "_timestamp": 1585597571.6663506, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0064357491210103035, "Value Loss": 3.6904469880028046e-07, "_runtime": 203.563405752182, "_timestamp": 1585597573.1962752, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006102340761572123, "Value Loss": 3.3179810543515487e-07, "_runtime": 205.08507180213928, "_timestamp": 1585597574.7179413, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005779040511697531, "Value Loss": 2.9757200081803603e-07, "_runtime": 206.6148555278778, "_timestamp": 1585597576.247725, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0054557351395487785, "Value Loss": 2.6520854135014815e-07, "_runtime": 208.14566659927368, "_timestamp": 1585597577.778536, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005132430698722601, "Value Loss": 2.3470784071832895e-07, "_runtime": 209.6672294139862, "_timestamp": 1585597579.300099, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004809126257896423, "Value Loss": 2.06069671548903e-07, "_runtime": 211.18707990646362, "_timestamp": 1585597580.8199494, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004495932720601559, "Value Loss": 1.8010274516200298e-07, "_runtime": 212.71826601028442, "_timestamp": 1585597582.3511355, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004182732198387384, "Value Loss": 1.5588372548336338e-07, "_runtime": 214.25032806396484, "_timestamp": 1585597583.8831975, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003879634430631995, "Value Loss": 1.341104507446289e-07, "_runtime": 215.78103160858154, "_timestamp": 1585597585.413901, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035866412799805403, "Value Loss": 1.1461907689636064e-07, "_runtime": 217.31296300888062, "_timestamp": 1585597586.9458325, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003303751116618514, "Value Loss": 9.725135186045009e-08, "_runtime": 218.84350156784058, "_timestamp": 1585597588.476371, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0030309639405459166, "Value Loss": 8.185452315956354e-08, "_runtime": 220.41417622566223, "_timestamp": 1585597590.0470457, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027581765316426754, "Value Loss": 6.778372352300721e-08, "_runtime": 221.94568943977356, "_timestamp": 1585597591.578559, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025055971927940845, "Value Loss": 5.593756213784218e-08, "_runtime": 223.47004580497742, "_timestamp": 1585597593.1029153, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002263120375573635, "Value Loss": 4.563480615615845e-08, "_runtime": 225.0004324913025, "_timestamp": 1585597594.633302, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002030746079981327, "Value Loss": 3.6744488340900716e-08, "_runtime": 226.53372049331665, "_timestamp": 1585597596.16659, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018084757030010223, "Value Loss": 2.9141112634079036e-08, "_runtime": 228.06531763076782, "_timestamp": 1585597597.698187, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0015963084297254682, "Value Loss": 2.270462573505938e-08, "_runtime": 229.59693217277527, "_timestamp": 1585597599.2298017, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00139424332883209, "Value Loss": 1.7320417100563645e-08, "_runtime": 231.1207311153412, "_timestamp": 1585597600.7536006, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0012022815644741058, "Value Loss": 1.2879354471806437e-08, "_runtime": 232.64566779136658, "_timestamp": 1585597602.2785373, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001030527870170772, "Value Loss": 9.462382877245545e-09, "_runtime": 234.16727352142334, "_timestamp": 1585597603.800143, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008587731281295419, "Value Loss": 6.5710992203094065e-09, "_runtime": 235.68037486076355, "_timestamp": 1585597605.3132443, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007072244770824909, "Value Loss": 4.456524038687348e-09, "_runtime": 237.21215391159058, "_timestamp": 1585597606.8450234, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005657800938934088, "Value Loss": 2.852175384759903e-09, "_runtime": 238.73617362976074, "_timestamp": 1585597608.369043, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0004344379703979939, "Value Loss": 1.6816557035781443e-09, "_runtime": 240.26744651794434, "_timestamp": 1585597609.900316, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00030309619614854455, "Value Loss": 8.185452315956354e-10, "_runtime": 241.79091477394104, "_timestamp": 1585597611.4237843, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00019196094945073128, "Value Loss": 3.283275873400271e-10, "_runtime": 243.35383248329163, "_timestamp": 1585597612.986702, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 244.8739194869995, "_timestamp": 1585597614.506789, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 246.40353727340698, "_timestamp": 1585597616.0364068, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 247.93519496917725, "_timestamp": 1585597617.5680645, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001616514491615817, "Value Loss": 2.3283064365386963e-10, "_runtime": 249.4671607017517, "_timestamp": 1585597619.1000302, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023237382993102074, "Value Loss": 4.81122697237879e-10, "_runtime": 250.99845933914185, "_timestamp": 1585597620.6313288, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000292993092443794, "Value Loss": 7.648850441910326e-10, "_runtime": 252.52951526641846, "_timestamp": 1585597622.1623847, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0003435090184211731, "Value Loss": 1.051375875249505e-09, "_runtime": 254.0583701133728, "_timestamp": 1585597623.6912396, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00038392189890146255, "Value Loss": 1.3133103493601084e-09, "_runtime": 255.58664774894714, "_timestamp": 1585597625.2195172, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000424334779381752, "Value Loss": 1.6043486539274454e-09, "_runtime": 257.1172215938568, "_timestamp": 1585597626.750091, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00045464449794963, "Value Loss": 1.8417267710901797e-09, "_runtime": 258.646014213562, "_timestamp": 1585597628.2788837, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004849543038289994, "Value Loss": 2.0954757928848267e-09, "_runtime": 260.180522441864, "_timestamp": 1585597629.813392, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005051605403423309, "Value Loss": 2.2737367544323206e-09, "_runtime": 261.71050572395325, "_timestamp": 1585597631.3433752, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000515263935085386, "Value Loss": 2.3655957193113863e-09, "_runtime": 263.2417325973511, "_timestamp": 1585597632.874602, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005253670969977975, "Value Loss": 2.459273673593998e-09, "_runtime": 264.7703535556793, "_timestamp": 1585597634.403223, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005354704917408526, "Value Loss": 2.5547706172801554e-09, "_runtime": 266.32685804367065, "_timestamp": 1585597635.9597275, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005354704917408526, "Value Loss": 2.5547706172801554e-09, "_runtime": 267.85885310173035, "_timestamp": 1585597637.4917226, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005354704917408526, "Value Loss": 2.5547706172801554e-09, "_runtime": 269.3804042339325, "_timestamp": 1585597639.0132737, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005354704917408526, "Value Loss": 2.5547706172801554e-09, "_runtime": 270.91391229629517, "_timestamp": 1585597640.5467818, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005253670969977975, "Value Loss": 2.459273673593998e-09, "_runtime": 272.43051290512085, "_timestamp": 1585597642.0633824, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000515263935085386, "Value Loss": 2.3655957193113863e-09, "_runtime": 273.95234179496765, "_timestamp": 1585597643.5852113, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0005051605403423309, "Value Loss": 2.2737367544323206e-09, "_runtime": 275.48681688308716, "_timestamp": 1585597645.1196864, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004950574366375804, "Value Loss": 2.1836967789568007e-09, "_runtime": 276.9976713657379, "_timestamp": 1585597646.6305408, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004748508508782834, "Value Loss": 2.0090737962163985e-09, "_runtime": 278.5305440425873, "_timestamp": 1585597648.1634135, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00045464449794963, "Value Loss": 1.8417267710901797e-09, "_runtime": 280.06314396858215, "_timestamp": 1585597649.6960135, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00044454142334870994, "Value Loss": 1.760781742632389e-09, "_runtime": 281.59487891197205, "_timestamp": 1585597651.2277484, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000424334779381752, "Value Loss": 1.6043486539274454e-09, "_runtime": 283.1263008117676, "_timestamp": 1585597652.7591703, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0004041285428684205, "Value Loss": 1.4551915228366852e-09, "_runtime": 284.647625207901, "_timestamp": 1585597654.2804947, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00038392189890146255, "Value Loss": 1.3133103493601084e-09, "_runtime": 286.17916655540466, "_timestamp": 1585597655.812036, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00036371563328430057, "Value Loss": 1.178705133497715e-09, "_runtime": 287.71177411079407, "_timestamp": 1585597657.3446436, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00033340597292408347, "Value Loss": 9.904397302307189e-10, "_runtime": 289.2800438404083, "_timestamp": 1585597658.9129133, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00031319964909926057, "Value Loss": 8.74024408403784e-10, "_runtime": 290.8126571178436, "_timestamp": 1585597660.4455266, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000292993092443794, "Value Loss": 7.648850441910326e-10, "_runtime": 292.3353843688965, "_timestamp": 1585597661.9682539, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0002727867104113102, "Value Loss": 6.630216375924647e-10, "_runtime": 293.8639991283417, "_timestamp": 1585597663.4968686, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00025258027017116547, "Value Loss": 5.684341886080801e-10, "_runtime": 295.3966975212097, "_timestamp": 1585597665.029567, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00023237382993102074, "Value Loss": 4.81122697237879e-10, "_runtime": 296.9268090724945, "_timestamp": 1585597666.5596786, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.000212167389690876, "Value Loss": 4.0108716348186135e-10, "_runtime": 298.4497826099396, "_timestamp": 1585597668.082652, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00019196094945073128, "Value Loss": 3.283275873400271e-10, "_runtime": 299.9784576892853, "_timestamp": 1585597669.6113272, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00017175450921058655, "Value Loss": 2.6284396881237626e-10, "_runtime": 301.51014614105225, "_timestamp": 1585597671.1430156, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00015154809807427227, "Value Loss": 2.0463630789890885e-10, "_runtime": 303.0284333229065, "_timestamp": 1585597672.6613028, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0001414450234733522, "Value Loss": 1.7826096154749393e-10, "_runtime": 304.56340765953064, "_timestamp": 1585597674.1962771, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00012123857595724985, "Value Loss": 1.3096723705530167e-10, "_runtime": 306.08375787734985, "_timestamp": 1585597675.7166274, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00011113535583717749, "Value Loss": 1.1004885891452432e-10, "_runtime": 307.6214029788971, "_timestamp": 1585597677.2542725, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.092890832107514e-05, "Value Loss": 7.366907084360719e-11, "_runtime": 309.1425230503082, "_timestamp": 1585597678.7753925, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.082572458079085e-05, "Value Loss": 5.820766091346741e-11, "_runtime": 310.7120361328125, "_timestamp": 1585597680.3449056, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.0619287978624925e-05, "Value Loss": 3.2741809263825417e-11, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 312.23385286331177, "_timestamp": 1585597681.8667223, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.051606785855256e-05, "Value Loss": 2.2737367544323206e-11, "_runtime": 313.75695037841797, "_timestamp": 1585597683.3898199, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 315.2787175178528, "_timestamp": 1585597684.911587, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 316.78769540786743, "_timestamp": 1585597686.420565, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 318.32005643844604, "_timestamp": 1585597687.952926, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 319.8405644893646, "_timestamp": 1585597689.473434, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 321.363228559494, "_timestamp": 1585597690.996098, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 322.8933455944061, "_timestamp": 1585597692.526215, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 324.42508816719055, "_timestamp": 1585597694.0579576, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 325.9542896747589, "_timestamp": 1585597695.5871592, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 327.47959899902344, "_timestamp": 1585597697.1124685, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 328.9987232685089, "_timestamp": 1585597698.6315928, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 330.52919268608093, "_timestamp": 1585597700.1620622, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 332.06376361846924, "_timestamp": 1585597701.696633, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 333.62962555885315, "_timestamp": 1585597703.262495, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 335.16278624534607, "_timestamp": 1585597704.7956557, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 336.69805812835693, "_timestamp": 1585597706.3309276, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 338.2306537628174, "_timestamp": 1585597707.8635232, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 339.7519962787628, "_timestamp": 1585597709.3848658, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 341.28401350975037, "_timestamp": 1585597710.916883, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 342.8138806819916, "_timestamp": 1585597712.4467502, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 344.33814215660095, "_timestamp": 1585597713.9710116, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 345.8683445453644, "_timestamp": 1585597715.501214, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 347.38920760154724, "_timestamp": 1585597717.022077, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 348.919796705246, "_timestamp": 1585597718.5526662, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 350.4441204071045, "_timestamp": 1585597720.07699, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 351.96530652046204, "_timestamp": 1585597721.598176, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 353.4983961582184, "_timestamp": 1585597723.1312656, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.0412862290395424e-05, "Value Loss": 1.4551915228366852e-11, "_runtime": 355.0190076828003, "_timestamp": 1585597724.6518772, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 356.58705163002014, "_timestamp": 1585597726.219921, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 358.1197350025177, "_timestamp": 1585597727.7526045, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 359.6538989543915, "_timestamp": 1585597729.2867684, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 361.1869659423828, "_timestamp": 1585597730.8198354, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 362.71062874794006, "_timestamp": 1585597732.3434982, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.0309643989312463e-05, "Value Loss": 8.185452315956354e-12, "_runtime": 364.2410111427307, "_timestamp": 1585597733.8738806, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 365.77366161346436, "_timestamp": 1585597735.406531, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 367.3060643672943, "_timestamp": 1585597736.9389338, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 368.82841873168945, "_timestamp": 1585597738.4612882, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 370.36143732070923, "_timestamp": 1585597739.9943068, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0206431145197712e-05, "Value Loss": 3.637978807091713e-12, "_runtime": 371.89866495132446, "_timestamp": 1585597741.5315344, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 373.4279637336731, "_timestamp": 1585597743.0608332, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 374.9485583305359, "_timestamp": 1585597744.5814278, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 376.4610686302185, "_timestamp": 1585597746.093938, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 377.9729869365692, "_timestamp": 1585597747.6058564, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 379.5198721885681, "_timestamp": 1585597749.1527417, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 381.04106426239014, "_timestamp": 1585597750.6739337, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 382.5724308490753, "_timestamp": 1585597752.2053003, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 384.0904076099396, "_timestamp": 1585597753.723277, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 385.6226370334625, "_timestamp": 1585597755.2555065, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 387.15079498291016, "_timestamp": 1585597756.7836645, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 388.67153310775757, "_timestamp": 1585597758.3044026, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 390.19111943244934, "_timestamp": 1585597759.823989, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 391.7114052772522, "_timestamp": 1585597761.3442748, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 393.2209622859955, "_timestamp": 1585597762.8538318, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 394.7308051586151, "_timestamp": 1585597764.3636746, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 396.2507281303406, "_timestamp": 1585597765.8835976, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 397.7706022262573, "_timestamp": 1585597767.4034717, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 399.2895851135254, "_timestamp": 1585597768.9224546, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 400.81236839294434, "_timestamp": 1585597770.4452379, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 402.3676722049713, "_timestamp": 1585597772.0005417, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 403.88698053359985, "_timestamp": 1585597773.51985, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 405.4064931869507, "_timestamp": 1585597775.0393627, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 406.9235198497772, "_timestamp": 1585597776.5563893, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 408.4453766345978, "_timestamp": 1585597778.078246, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 409.96418809890747, "_timestamp": 1585597779.5970576, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 411.48322439193726, "_timestamp": 1585597781.1160939, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 413.00360441207886, "_timestamp": 1585597782.636474, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 414.52356719970703, "_timestamp": 1585597784.1564367, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 416.03301668167114, "_timestamp": 1585597785.6658862, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0103215572598856e-05, "Value Loss": 9.094947017729282e-13, "_runtime": 417.56544613838196, "_timestamp": 1585597787.1983156, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 419.0765163898468, "_timestamp": 1585597788.7093859, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 420.6094045639038, "_timestamp": 1585597790.242274, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 422.1435341835022, "_timestamp": 1585597791.7764037, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 423.6988568305969, "_timestamp": 1585597793.3317263, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 425.21943521499634, "_timestamp": 1585597794.8523047, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 426.75278329849243, "_timestamp": 1585597796.3856528, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 428.2842700481415, "_timestamp": 1585597797.9171395, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 429.80695390701294, "_timestamp": 1585597799.4398234, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 431.3347678184509, "_timestamp": 1585597800.9676373, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 432.8641631603241, "_timestamp": 1585597802.4970326, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 434.3955514431, "_timestamp": 1585597804.028421, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 435.9165766239166, "_timestamp": 1585597805.549446, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 437.44786620140076, "_timestamp": 1585597807.0807357, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 438.9792242050171, "_timestamp": 1585597808.6120937, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 440.49778151512146, "_timestamp": 1585597810.130651, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 442.0272903442383, "_timestamp": 1585597811.6601598, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 443.559645652771, "_timestamp": 1585597813.1925151, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 445.0894286632538, "_timestamp": 1585597814.7222981, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 446.6564271450043, "_timestamp": 1585597816.2892966, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 448.187153339386, "_timestamp": 1585597817.8200228, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 449.7177662849426, "_timestamp": 1585597819.3506358, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 451.2372796535492, "_timestamp": 1585597820.8701491, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 452.76659417152405, "_timestamp": 1585597822.3994637, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 454.295530796051, "_timestamp": 1585597823.9284003, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 455.8264012336731, "_timestamp": 1585597825.4592707, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 457.35621190071106, "_timestamp": 1585597826.9890814, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 458.87534976005554, "_timestamp": 1585597828.5082192, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 460.3968198299408, "_timestamp": 1585597830.0296893, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 461.9043538570404, "_timestamp": 1585597831.5372233, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 463.43548703193665, "_timestamp": 1585597833.0683565, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 464.96424555778503, "_timestamp": 1585597834.597115, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 466.4912781715393, "_timestamp": 1585597836.1241477, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 468.0212392807007, "_timestamp": 1585597837.6541088, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 469.58941626548767, "_timestamp": 1585597839.2222857, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 471.1237950325012, "_timestamp": 1585597840.7566645, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 472.63729095458984, "_timestamp": 1585597842.2701604, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 474.1698133945465, "_timestamp": 1585597843.8026829, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 475.70172119140625, "_timestamp": 1585597845.3345907, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 477.23426365852356, "_timestamp": 1585597846.8671331, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 478.7674753665924, "_timestamp": 1585597848.4003448, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 480.298681974411, "_timestamp": 1585597849.9315515, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 481.830851316452, "_timestamp": 1585597851.4637208, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 483.3576762676239, "_timestamp": 1585597852.9905457, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 484.8913276195526, "_timestamp": 1585597854.524197, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 486.4265582561493, "_timestamp": 1585597856.0594277, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 487.94761204719543, "_timestamp": 1585597857.5804815, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 489.4700903892517, "_timestamp": 1585597859.1029599, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 490.9995505809784, "_timestamp": 1585597860.63242, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 492.56714129447937, "_timestamp": 1585597862.2000108, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 494.0904231071472, "_timestamp": 1585597863.7232926, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 495.62490463256836, "_timestamp": 1585597865.257774, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 497.1563882827759, "_timestamp": 1585597866.7892578, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 498.67891454696655, "_timestamp": 1585597868.311784, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 500.20951437950134, "_timestamp": 1585597869.8423839, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 501.7335035800934, "_timestamp": 1585597871.366373, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 503.2661485671997, "_timestamp": 1585597872.899018, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 504.7873306274414, "_timestamp": 1585597874.4202, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 506.3077139854431, "_timestamp": 1585597875.9405835, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 507.8299865722656, "_timestamp": 1585597877.462856, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 509.36151099205017, "_timestamp": 1585597878.9943805, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 510.88482999801636, "_timestamp": 1585597880.5176995, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 512.4209537506104, "_timestamp": 1585597882.0538232, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 513.9672815799713, "_timestamp": 1585597883.600151, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 515.4890601634979, "_timestamp": 1585597885.1219296, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 517.0183947086334, "_timestamp": 1585597886.6512642, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 518.5477550029755, "_timestamp": 1585597888.1806245, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 520.0782074928284, "_timestamp": 1585597889.711077, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 521.6086518764496, "_timestamp": 1585597891.2415214, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 523.1373026371002, "_timestamp": 1585597892.770172, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 524.6591312885284, "_timestamp": 1585597894.2920008, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 526.1754298210144, "_timestamp": 1585597895.8082993, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 527.7046983242035, "_timestamp": 1585597897.3375678, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 529.2332782745361, "_timestamp": 1585597898.8661478, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 530.7625539302826, "_timestamp": 1585597900.3954234, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 532.2918379306793, "_timestamp": 1585597901.9247074, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 533.8235886096954, "_timestamp": 1585597903.456458, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 535.3525679111481, "_timestamp": 1585597904.9854374, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 536.9065406322479, "_timestamp": 1585597906.53941, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 538.4355728626251, "_timestamp": 1585597908.0684423, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 539.9655497074127, "_timestamp": 1585597909.5984192, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 541.4962015151978, "_timestamp": 1585597911.129071, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 543.0290477275848, "_timestamp": 1585597912.6619172, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 544.5477683544159, "_timestamp": 1585597914.1806378, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 546.0798444747925, "_timestamp": 1585597915.712714, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 547.5907647609711, "_timestamp": 1585597917.2236342, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 549.1108832359314, "_timestamp": 1585597918.7437527, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 550.6400821208954, "_timestamp": 1585597920.2729516, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 552.1621441841125, "_timestamp": 1585597921.7950137, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 553.6823461055756, "_timestamp": 1585597923.3152156, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 555.2008130550385, "_timestamp": 1585597924.8336825, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 556.7216820716858, "_timestamp": 1585597926.3545516, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 558.2527239322662, "_timestamp": 1585597927.8855934, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 559.808295249939, "_timestamp": 1585597929.4411647, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 561.3337345123291, "_timestamp": 1585597930.966604, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 562.8665342330933, "_timestamp": 1585597932.4994037, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 564.4015891551971, "_timestamp": 1585597934.0344586, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 565.9229233264923, "_timestamp": 1585597935.5557928, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 567.4546642303467, "_timestamp": 1585597937.0875337, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 568.9887301921844, "_timestamp": 1585597938.6215997, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 570.5089557170868, "_timestamp": 1585597940.1418252, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 572.0416920185089, "_timestamp": 1585597941.6745615, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 573.5640137195587, "_timestamp": 1585597943.1968832, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 575.095380783081, "_timestamp": 1585597944.7282503, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 576.6279554367065, "_timestamp": 1585597946.260825, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 578.1531190872192, "_timestamp": 1585597947.7859886, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 579.675886631012, "_timestamp": 1585597949.308756, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 581.211989402771, "_timestamp": 1585597950.844859, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 582.7814011573792, "_timestamp": 1585597952.4142706, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 584.2900161743164, "_timestamp": 1585597953.9228857, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 585.8216209411621, "_timestamp": 1585597955.4544904, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 587.353399515152, "_timestamp": 1585597956.986269, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 588.8752963542938, "_timestamp": 1585597958.5081658, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 590.3974401950836, "_timestamp": 1585597960.0303097, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 591.9278512001038, "_timestamp": 1585597961.5607207, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 593.463086605072, "_timestamp": 1585597963.095956, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 594.9857261180878, "_timestamp": 1585597964.6185956, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 596.5188488960266, "_timestamp": 1585597966.1517184, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 598.0507643222809, "_timestamp": 1585597967.6836338, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 599.5827744007111, "_timestamp": 1585597969.215644, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 601.1150386333466, "_timestamp": 1585597970.747908, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 602.6472058296204, "_timestamp": 1585597972.2800753, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 604.1773724555969, "_timestamp": 1585597973.810242, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 605.7367141246796, "_timestamp": 1585597975.3695836, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 607.2669949531555, "_timestamp": 1585597976.8998644, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 608.7975299358368, "_timestamp": 1585597978.4303994, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 610.34308385849, "_timestamp": 1585597979.9759533, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 611.8951654434204, "_timestamp": 1585597981.528035, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 613.4438765048981, "_timestamp": 1585597983.076746, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 614.9882209300995, "_timestamp": 1585597984.6210904, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 616.5193209648132, "_timestamp": 1585597986.1521904, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 618.0643043518066, "_timestamp": 1585597987.6971738, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 619.5994079113007, "_timestamp": 1585597989.2322774, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 621.1386706829071, "_timestamp": 1585597990.7715402, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 622.685964345932, "_timestamp": 1585597992.3188338, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 624.2329950332642, "_timestamp": 1585597993.8658645, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 625.7695968151093, "_timestamp": 1585597995.4024663, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 627.3421764373779, "_timestamp": 1585597996.975046, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 628.876800775528, "_timestamp": 1585597998.5096703, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 630.4122898578644, "_timestamp": 1585598000.0451593, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 631.9512417316437, "_timestamp": 1585598001.5841112, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 633.4870707988739, "_timestamp": 1585598003.1199403, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 635.0210871696472, "_timestamp": 1585598004.6539567, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 636.5672755241394, "_timestamp": 1585598006.200145, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 638.10453748703, "_timestamp": 1585598007.737407, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 639.6500220298767, "_timestamp": 1585598009.2828915, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 641.1968309879303, "_timestamp": 1585598010.8297005, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 642.7314105033875, "_timestamp": 1585598012.36428, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 644.2773013114929, "_timestamp": 1585598013.9101708, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 645.8227345943451, "_timestamp": 1585598015.455604, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 647.3683745861053, "_timestamp": 1585598017.001244, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 648.9130022525787, "_timestamp": 1585598018.5458717, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 650.4931144714355, "_timestamp": 1585598020.125984, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 652.0406627655029, "_timestamp": 1585598021.6735322, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 653.5843403339386, "_timestamp": 1585598023.2172098, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 655.1194233894348, "_timestamp": 1585598024.7522929, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 656.6635146141052, "_timestamp": 1585598026.296384, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 658.2091000080109, "_timestamp": 1585598027.8419695, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 659.7319202423096, "_timestamp": 1585598029.3647897, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 661.2806868553162, "_timestamp": 1585598030.9135563, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 662.8155341148376, "_timestamp": 1585598032.4484036, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 664.3507235050201, "_timestamp": 1585598033.983593, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 665.895917892456, "_timestamp": 1585598035.5287874, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 667.4285242557526, "_timestamp": 1585598037.0613937, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 668.973827123642, "_timestamp": 1585598038.6066966, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 670.5196981430054, "_timestamp": 1585598040.1525676, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 672.0652000904083, "_timestamp": 1585598041.6980696, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 673.644433259964, "_timestamp": 1585598043.2773027, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 675.1804978847504, "_timestamp": 1585598044.8133674, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 676.7149577140808, "_timestamp": 1585598046.3478272, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 678.2620799541473, "_timestamp": 1585598047.8949494, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 679.8131332397461, "_timestamp": 1585598049.4460027, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 681.3498141765594, "_timestamp": 1585598050.9826837, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 682.8937137126923, "_timestamp": 1585598052.5265832, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 684.4413077831268, "_timestamp": 1585598054.0741773, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 685.9769239425659, "_timestamp": 1585598055.6097934, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 687.5230305194855, "_timestamp": 1585598057.1559, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 689.0703077316284, "_timestamp": 1585598058.7031772, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 690.6059145927429, "_timestamp": 1585598060.238784, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 692.1509697437286, "_timestamp": 1585598061.7838392, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 693.698486328125, "_timestamp": 1585598063.3313558, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 695.2329561710358, "_timestamp": 1585598064.8658257, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 696.7915868759155, "_timestamp": 1585598066.4244564, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 698.3285703659058, "_timestamp": 1585598067.9614398, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 699.8561000823975, "_timestamp": 1585598069.4889696, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 701.3906252384186, "_timestamp": 1585598071.0234947, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 702.9109132289886, "_timestamp": 1585598072.5437827, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 704.4444527626038, "_timestamp": 1585598074.0773222, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 705.9694674015045, "_timestamp": 1585598075.602337, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 707.4806613922119, "_timestamp": 1585598077.1135309, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 709.0133969783783, "_timestamp": 1585598078.6462665, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 710.5356402397156, "_timestamp": 1585598080.1685097, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 712.0685334205627, "_timestamp": 1585598081.701403, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 713.5896308422089, "_timestamp": 1585598083.2225003, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 715.1196908950806, "_timestamp": 1585598084.7525604, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 716.6502892971039, "_timestamp": 1585598086.2831588, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 718.206353187561, "_timestamp": 1585598087.8392227, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 719.7391378879547, "_timestamp": 1585598089.3720074, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 721.2719988822937, "_timestamp": 1585598090.9048684, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 722.8026733398438, "_timestamp": 1585598092.4355428, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 724.3263094425201, "_timestamp": 1585598093.959179, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 725.8573887348175, "_timestamp": 1585598095.4902582, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 727.3781352043152, "_timestamp": 1585598097.0110047, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 728.89648604393, "_timestamp": 1585598098.5293555, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 730.4297912120819, "_timestamp": 1585598100.0626607, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 731.96049451828, "_timestamp": 1585598101.593364, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 733.4925637245178, "_timestamp": 1585598103.1254332, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 735.0229494571686, "_timestamp": 1585598104.655819, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 736.5569951534271, "_timestamp": 1585598106.1898646, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 738.1004908084869, "_timestamp": 1585598107.7333603, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 739.6356194019318, "_timestamp": 1585598109.268489, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 741.2304184436798, "_timestamp": 1585598110.863288, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 742.7666866779327, "_timestamp": 1585598112.3995562, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 744.2996759414673, "_timestamp": 1585598113.9325454, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 745.82177567482, "_timestamp": 1585598115.4546452, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 747.342777967453, "_timestamp": 1585598116.9756474, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 748.864734172821, "_timestamp": 1585598118.4976037, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 750.3880550861359, "_timestamp": 1585598120.0209246, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 751.9131460189819, "_timestamp": 1585598121.5460155, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 753.4461662769318, "_timestamp": 1585598123.0790358, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 754.9807469844818, "_timestamp": 1585598124.6136165, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 756.5026352405548, "_timestamp": 1585598126.1355047, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 758.0272026062012, "_timestamp": 1585598127.660072, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 759.5596776008606, "_timestamp": 1585598129.192547, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 761.0913746356964, "_timestamp": 1585598130.724244, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 762.6377062797546, "_timestamp": 1585598132.2705758, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 764.2194993495941, "_timestamp": 1585598133.8523688, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 765.7666082382202, "_timestamp": 1585598135.3994777, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 767.31543135643, "_timestamp": 1585598136.9483008, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 768.8633241653442, "_timestamp": 1585598138.4961936, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 770.4095075130463, "_timestamp": 1585598140.042377, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 771.9349133968353, "_timestamp": 1585598141.5677829, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0, "Value Loss": 0.0, "_runtime": 771.9349133968353, "_timestamp": 1585598141.5677829, "_step": 499}
