{"Episode reward": -36.59487364750224, "Episode length": 999, "Policy Loss": -0.03685760498046875, "Value Loss": 0.0138088408857584, "_runtime": 4634.607896089554, "_timestamp": 1585574550.4525294, "_step": 0}
{"Episode reward": -86.64504033510566, "Episode length": 999, "Policy Loss": -2.106309413909912, "Value Loss": 40.056793212890625, "_runtime": 4636.117376804352, "_timestamp": 1585574551.9620101, "_step": 1}
{"Episode reward": -97.97151257499308, "Episode length": 999, "Policy Loss": 1.6490888595581055, "Value Loss": 315.3894958496094, "_runtime": 4637.700799942017, "_timestamp": 1585574553.5454333, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 18.274744033813477, "Value Loss": 11822.3671875, "_runtime": 4639.263823509216, "_timestamp": 1585574555.1084569, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.7834553718566895, "Value Loss": 233.90493774414062, "_runtime": 4640.807634115219, "_timestamp": 1585574556.6522675, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.581857681274414, "Value Loss": 3827.2607421875, "_runtime": 4642.400959968567, "_timestamp": 1585574558.2455933, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.900327682495117, "Value Loss": 6445.48828125, "_runtime": 4643.974030256271, "_timestamp": 1585574559.8186636, "_step": 6}
{"Episode reward": -94.95134300848694, "Episode length": 999, "Policy Loss": 0.17459823191165924, "Value Loss": 44.65049362182617, "_runtime": 4645.517616033554, "_timestamp": 1585574561.3622494, "_step": 7}
{"Episode reward": -36.50107067300525, "Episode length": 999, "Policy Loss": 0.20496666431427002, "Value Loss": 53.18017578125, "_runtime": 4647.113255739212, "_timestamp": 1585574562.957889, "_step": 8}
{"Episode reward": -35.62419500732476, "Episode length": 999, "Policy Loss": -0.0343470573425293, "Value Loss": 51.108245849609375, "_runtime": 4648.698154449463, "_timestamp": 1585574564.5427878, "_step": 9}
{"Episode reward": -39.99107355379233, "Episode length": 999, "Policy Loss": 0.19048389792442322, "Value Loss": 3.551422595977783, "_runtime": 4649.223510026932, "_timestamp": 1585574565.0681434, "_step": 10}
{"Episode reward": 85.78128301959356, "Episode length": 320, "Policy Loss": -2.2683217525482178, "Value Loss": 754.9138793945312, "_runtime": 4649.655022144318, "_timestamp": 1585574565.4996555, "_step": 11}
{"Episode reward": 85.94998754196324, "Episode length": 247, "Policy Loss": 0.3999911844730377, "Value Loss": 74.21024322509766, "_runtime": 4649.884847402573, "_timestamp": 1585574565.7294807, "_step": 12}
{"Episode reward": 92.02409412907284, "Episode length": 106, "Policy Loss": 3.8593664169311523, "Value Loss": 146.30648803710938, "_runtime": 4650.095098972321, "_timestamp": 1585574565.9397323, "_step": 13}
{"Episode reward": 90.40463423746463, "Episode length": 126, "Policy Loss": 8.38932991027832, "Value Loss": 217.35797119140625, "_runtime": 4650.3630294799805, "_timestamp": 1585574566.2076628, "_step": 14}
{"Episode reward": 85.4031864304203, "Episode length": 173, "Policy Loss": 1.2751734256744385, "Value Loss": 57.13874053955078, "_runtime": 4650.5209403038025, "_timestamp": 1585574566.3655736, "_step": 15}
{"Episode reward": 90.78751503668822, "Episode length": 102, "Policy Loss": 1.6819567680358887, "Value Loss": 118.78050994873047, "_runtime": 4650.684506654739, "_timestamp": 1585574566.52914, "_step": 16}
{"Episode reward": 90.58900800266832, "Episode length": 105, "Policy Loss": 4.163429260253906, "Value Loss": 110.748779296875, "_runtime": 4650.994103193283, "_timestamp": 1585574566.8387365, "_step": 17}
{"Episode reward": 82.348088518189, "Episode length": 205, "Policy Loss": -2.5331358909606934, "Value Loss": 77.92385864257812, "_runtime": 4651.1603307724, "_timestamp": 1585574567.004964, "_step": 18}
{"Episode reward": 89.89339559157966, "Episode length": 107, "Policy Loss": 1.409549355506897, "Value Loss": 103.76177215576172, "_runtime": 4651.345205783844, "_timestamp": 1585574567.1898391, "_step": 19}
{"Episode reward": 88.8102728297841, "Episode length": 120, "Policy Loss": -0.702001690864563, "Value Loss": 108.37320709228516, "_runtime": 4651.5333478450775, "_timestamp": 1585574567.3779812, "_step": 20}
{"Episode reward": 88.8061046251273, "Episode length": 118, "Policy Loss": -0.5903181433677673, "Value Loss": 112.04959106445312, "_runtime": 4651.699150800705, "_timestamp": 1585574567.5437841, "_step": 21}
{"Episode reward": 90.07292304428813, "Episode length": 107, "Policy Loss": -3.299820899963379, "Value Loss": 91.02661895751953, "_runtime": 4651.871135473251, "_timestamp": 1585574567.7157688, "_step": 22}
{"Episode reward": 89.72827616773803, "Episode length": 111, "Policy Loss": 1.082424521446228, "Value Loss": 118.21278381347656, "_runtime": 4652.0402846336365, "_timestamp": 1585574567.884918, "_step": 23}
{"Episode reward": 89.8041402765217, "Episode length": 109, "Policy Loss": 5.8409833908081055, "Value Loss": 126.04061889648438, "_runtime": 4652.363308191299, "_timestamp": 1585574568.2079415, "_step": 24}
{"Episode reward": 79.64428671373891, "Episode length": 217, "Policy Loss": -2.9113786220550537, "Value Loss": 73.1302719116211, "_runtime": 4652.545879364014, "_timestamp": 1585574568.3905127, "_step": 25}
{"Episode reward": 88.84218196836274, "Episode length": 118, "Policy Loss": 2.6336543560028076, "Value Loss": 86.67317199707031, "_runtime": 4652.8153648376465, "_timestamp": 1585574568.6599982, "_step": 26}
{"Episode reward": 82.51331472692397, "Episode length": 180, "Policy Loss": -8.88716983795166, "Value Loss": 80.2176513671875, "_runtime": 4653.043041706085, "_timestamp": 1585574568.887675, "_step": 27}
{"Episode reward": 86.23340734906137, "Episode length": 146, "Policy Loss": 5.682719707489014, "Value Loss": 87.31218719482422, "_runtime": 4653.217228889465, "_timestamp": 1585574569.0618622, "_step": 28}
{"Episode reward": 88.92494241092724, "Episode length": 113, "Policy Loss": -2.0656890869140625, "Value Loss": 97.02043914794922, "_runtime": 4653.486820936203, "_timestamp": 1585574569.3314543, "_step": 29}
{"Episode reward": 83.22880282855604, "Episode length": 176, "Policy Loss": 3.6926004886627197, "Value Loss": 56.83796691894531, "_runtime": 4653.660024166107, "_timestamp": 1585574569.5046575, "_step": 30}
{"Episode reward": 89.36948689445022, "Episode length": 110, "Policy Loss": 2.8695731163024902, "Value Loss": 89.0414047241211, "_runtime": 4654.2970333099365, "_timestamp": 1585574570.1416667, "_step": 31}
{"Episode reward": 58.27656839632991, "Episode length": 433, "Policy Loss": -0.18849031627178192, "Value Loss": 25.31616973876953, "_runtime": 4654.912984609604, "_timestamp": 1585574570.757618, "_step": 32}
{"Episode reward": 59.47250598920504, "Episode length": 412, "Policy Loss": -0.15374307334423065, "Value Loss": 29.090423583984375, "_runtime": 4655.471182346344, "_timestamp": 1585574571.3158157, "_step": 33}
{"Episode reward": 63.229248010969776, "Episode length": 377, "Policy Loss": -0.4141249656677246, "Value Loss": 27.066783905029297, "_runtime": 4656.0364372730255, "_timestamp": 1585574571.8810706, "_step": 34}
{"Episode reward": 66.11158446664362, "Episode length": 345, "Policy Loss": 0.22798068821430206, "Value Loss": 31.43545913696289, "_runtime": 4656.312474012375, "_timestamp": 1585574572.1571074, "_step": 35}
{"Episode reward": 83.57552175262902, "Episode length": 172, "Policy Loss": 1.631257176399231, "Value Loss": 59.15376281738281, "_runtime": 4657.287837743759, "_timestamp": 1585574573.132471, "_step": 36}
{"Episode reward": 36.55874909093478, "Episode length": 654, "Policy Loss": -0.8648046851158142, "Value Loss": 15.888714790344238, "_runtime": 4657.70326089859, "_timestamp": 1585574573.5478942, "_step": 37}
{"Episode reward": 74.19735712672123, "Episode length": 262, "Policy Loss": -0.8240669369697571, "Value Loss": 38.035518646240234, "_runtime": 4658.209304571152, "_timestamp": 1585574574.053938, "_step": 38}
{"Episode reward": 66.37617395196992, "Episode length": 345, "Policy Loss": -0.35566818714141846, "Value Loss": 31.22511100769043, "_runtime": 4659.097295761108, "_timestamp": 1585574574.941929, "_step": 39}
{"Episode reward": 43.003802556565745, "Episode length": 580, "Policy Loss": -0.2657660245895386, "Value Loss": 20.34300994873047, "_runtime": 4659.693830490112, "_timestamp": 1585574575.5384638, "_step": 40}
{"Episode reward": 61.314106622770105, "Episode length": 393, "Policy Loss": -0.7148213982582092, "Value Loss": 26.02882957458496, "_runtime": 4660.311543464661, "_timestamp": 1585574576.1561768, "_step": 41}
{"Episode reward": 59.07675405168037, "Episode length": 415, "Policy Loss": 0.8927199840545654, "Value Loss": 24.133346557617188, "_runtime": 4661.251827716827, "_timestamp": 1585574577.096461, "_step": 42}
{"Episode reward": 40.61748733223468, "Episode length": 611, "Policy Loss": 0.5751702189445496, "Value Loss": 16.818038940429688, "_runtime": 4662.758289813995, "_timestamp": 1585574578.6029232, "_step": 43}
{"Episode reward": -97.96597154243337, "Episode length": 999, "Policy Loss": -1.9706467390060425, "Value Loss": 0.3759411871433258, "_runtime": 4664.288663387299, "_timestamp": 1585574580.1332967, "_step": 44}
{"Episode reward": -96.40083863903293, "Episode length": 999, "Policy Loss": 2.2724928855895996, "Value Loss": 2.2555129528045654, "_runtime": 4665.821233987808, "_timestamp": 1585574581.6658673, "_step": 45}
{"Episode reward": -97.27653984343014, "Episode length": 999, "Policy Loss": -1.5499399900436401, "Value Loss": 1.968942642211914, "_runtime": 4667.391408205032, "_timestamp": 1585574583.2360415, "_step": 46}
{"Episode reward": -96.48383497658658, "Episode length": 999, "Policy Loss": -1.1627780199050903, "Value Loss": 2.049070119857788, "_runtime": 4668.949889421463, "_timestamp": 1585574584.7945228, "_step": 47}
{"Episode reward": -97.31408201482994, "Episode length": 999, "Policy Loss": -1.8833760023117065, "Value Loss": 0.4483354091644287, "_runtime": 4670.5213713645935, "_timestamp": 1585574586.3660047, "_step": 48}
{"Episode reward": -98.78773628462838, "Episode length": 999, "Policy Loss": -2.1018850803375244, "Value Loss": 0.29663488268852234, "_runtime": 4672.107638597488, "_timestamp": 1585574587.952272, "_step": 49}
{"Episode reward": -97.54714285897212, "Episode length": 999, "Policy Loss": -1.8749191761016846, "Value Loss": 0.34984561800956726, "_runtime": 4673.686856031418, "_timestamp": 1585574589.5314894, "_step": 50}
{"Episode reward": -98.71597506844205, "Episode length": 999, "Policy Loss": -2.073065757751465, "Value Loss": 0.21330979466438293, "_runtime": 4675.257818937302, "_timestamp": 1585574591.1024523, "_step": 51}
{"Episode reward": -97.59031304255332, "Episode length": 999, "Policy Loss": -1.9809879064559937, "Value Loss": 0.23437754809856415, "_runtime": 4676.829968452454, "_timestamp": 1585574592.6746018, "_step": 52}
{"Episode reward": -97.40601741878713, "Episode length": 999, "Policy Loss": -2.0733864307403564, "Value Loss": 0.48103997111320496, "_runtime": 4678.398882389069, "_timestamp": 1585574594.2435157, "_step": 53}
{"Episode reward": -97.83005405053423, "Episode length": 999, "Policy Loss": -2.077589988708496, "Value Loss": 0.5231506824493408, "_runtime": 4680.014908313751, "_timestamp": 1585574595.8595417, "_step": 54}
{"Episode reward": -97.74135446820263, "Episode length": 999, "Policy Loss": -2.0726096630096436, "Value Loss": 0.5225518941879272, "_runtime": 4681.589918136597, "_timestamp": 1585574597.4345515, "_step": 55}
{"Episode reward": -96.68770454880416, "Episode length": 999, "Policy Loss": -2.301640748977661, "Value Loss": 1.2919254302978516, "_runtime": 4683.162203073502, "_timestamp": 1585574599.0068364, "_step": 56}
{"Episode reward": -97.10180459558967, "Episode length": 999, "Policy Loss": -1.8426854610443115, "Value Loss": 0.23491358757019043, "_runtime": 4684.749698400497, "_timestamp": 1585574600.5943317, "_step": 57}
{"Episode reward": -97.66516429200341, "Episode length": 999, "Policy Loss": -1.8592629432678223, "Value Loss": 0.3606685400009155, "_runtime": 4686.324916601181, "_timestamp": 1585574602.16955, "_step": 58}
{"Episode reward": -96.92959274626955, "Episode length": 999, "Policy Loss": -1.7036534547805786, "Value Loss": 0.16814547777175903, "_runtime": 4687.899840116501, "_timestamp": 1585574603.7444735, "_step": 59}
{"Episode reward": -97.50076825168641, "Episode length": 999, "Policy Loss": -1.6223207712173462, "Value Loss": 0.14480188488960266, "_runtime": 4689.479601860046, "_timestamp": 1585574605.3242352, "_step": 60}
{"Episode reward": -98.20812286653099, "Episode length": 999, "Policy Loss": -1.4854003190994263, "Value Loss": 0.23201394081115723, "_runtime": 4691.056145191193, "_timestamp": 1585574606.9007785, "_step": 61}
{"Episode reward": -96.93099616723701, "Episode length": 999, "Policy Loss": -1.1976521015167236, "Value Loss": 0.3780224919319153, "_runtime": 4692.6440098285675, "_timestamp": 1585574608.4886432, "_step": 62}
{"Episode reward": -95.23133148714007, "Episode length": 999, "Policy Loss": -0.950989305973053, "Value Loss": 0.7526124119758606, "_runtime": 4694.232481479645, "_timestamp": 1585574610.0771148, "_step": 63}
{"Episode reward": -98.24966813900456, "Episode length": 999, "Policy Loss": -1.1953388452529907, "Value Loss": 0.39542463421821594, "_runtime": 4695.822878837585, "_timestamp": 1585574611.6675122, "_step": 64}
{"Episode reward": -95.92734632057054, "Episode length": 999, "Policy Loss": -1.3506073951721191, "Value Loss": 0.12018968909978867, "_runtime": 4697.401458501816, "_timestamp": 1585574613.2460918, "_step": 65}
{"Episode reward": -94.84384515861446, "Episode length": 999, "Policy Loss": -1.275580644607544, "Value Loss": 0.09978949278593063, "_runtime": 4698.993422269821, "_timestamp": 1585574614.8380556, "_step": 66}
{"Episode reward": -98.1503185449393, "Episode length": 999, "Policy Loss": -1.4271886348724365, "Value Loss": 0.14450326561927795, "_runtime": 4700.580485343933, "_timestamp": 1585574616.4251187, "_step": 67}
{"Episode reward": -96.71710181763028, "Episode length": 999, "Policy Loss": -1.459683895111084, "Value Loss": 0.33427852392196655, "_runtime": 4702.161388397217, "_timestamp": 1585574618.0060217, "_step": 68}
{"Episode reward": -97.65784122144834, "Episode length": 999, "Policy Loss": -1.4347881078720093, "Value Loss": 0.38428831100463867, "_runtime": 4703.785559892654, "_timestamp": 1585574619.6301932, "_step": 69}
{"Episode reward": -97.66863916497228, "Episode length": 999, "Policy Loss": -1.2573723793029785, "Value Loss": 0.22157572209835052, "_runtime": 4705.37495803833, "_timestamp": 1585574621.2195914, "_step": 70}
{"Episode reward": -97.54353585319502, "Episode length": 999, "Policy Loss": -1.1723753213882446, "Value Loss": 0.16269350051879883, "_runtime": 4706.963664531708, "_timestamp": 1585574622.8082979, "_step": 71}
{"Episode reward": -98.49014404785837, "Episode length": 999, "Policy Loss": -1.1558703184127808, "Value Loss": 0.09652408957481384, "_runtime": 4708.541753768921, "_timestamp": 1585574624.386387, "_step": 72}
{"Episode reward": -95.55597823555952, "Episode length": 999, "Policy Loss": -1.1864057779312134, "Value Loss": 0.12131603062152863, "_runtime": 4710.133769035339, "_timestamp": 1585574625.9784024, "_step": 73}
{"Episode reward": -97.47773077891517, "Episode length": 999, "Policy Loss": -1.046717882156372, "Value Loss": 0.05136803537607193, "_runtime": 4711.710280179977, "_timestamp": 1585574627.5549135, "_step": 74}
{"Episode reward": -98.55308915732832, "Episode length": 999, "Policy Loss": -0.9508172273635864, "Value Loss": 0.05411529168486595, "_runtime": 4713.288511991501, "_timestamp": 1585574629.1331453, "_step": 75}
{"Episode reward": -97.96614759976585, "Episode length": 999, "Policy Loss": -0.941807746887207, "Value Loss": 0.049229878932237625, "_runtime": 4714.879716157913, "_timestamp": 1585574630.7243495, "_step": 76}
{"Episode reward": -98.14761170145064, "Episode length": 999, "Policy Loss": -0.8520143032073975, "Value Loss": 0.14032046496868134, "_runtime": 4716.465266227722, "_timestamp": 1585574632.3098996, "_step": 77}
{"Episode reward": -98.54116552862237, "Episode length": 999, "Policy Loss": -0.6932860016822815, "Value Loss": 0.24426333606243134, "_runtime": 4718.0516929626465, "_timestamp": 1585574633.8963263, "_step": 78}
{"Episode reward": -99.10928031138783, "Episode length": 999, "Policy Loss": -0.6634274125099182, "Value Loss": 0.21025338768959045, "_runtime": 4719.6390125751495, "_timestamp": 1585574635.483646, "_step": 79}
{"Episode reward": -98.63955795093857, "Episode length": 999, "Policy Loss": -0.7793933749198914, "Value Loss": 0.05306267365813255, "_runtime": 4721.230127096176, "_timestamp": 1585574637.0747604, "_step": 80}
{"Episode reward": -98.04487638189909, "Episode length": 999, "Policy Loss": -0.6952570676803589, "Value Loss": 0.04760892689228058, "_runtime": 4722.807988882065, "_timestamp": 1585574638.6526222, "_step": 81}
{"Episode reward": -97.00135595277533, "Episode length": 999, "Policy Loss": -0.6675851345062256, "Value Loss": 0.025262631475925446, "_runtime": 4724.386859893799, "_timestamp": 1585574640.2314932, "_step": 82}
{"Episode reward": -95.74848001560895, "Episode length": 999, "Policy Loss": -0.7191463708877563, "Value Loss": 0.0392305925488472, "_runtime": 4725.965262889862, "_timestamp": 1585574641.8098962, "_step": 83}
{"Episode reward": -98.42577653190254, "Episode length": 999, "Policy Loss": -0.6771109700202942, "Value Loss": 0.026433151215314865, "_runtime": 4727.580259799957, "_timestamp": 1585574643.4248931, "_step": 84}
{"Episode reward": -98.26732104628132, "Episode length": 999, "Policy Loss": -0.6672770977020264, "Value Loss": 0.050846707075834274, "_runtime": 4729.174399137497, "_timestamp": 1585574645.0190325, "_step": 85}
{"Episode reward": -96.42580162990004, "Episode length": 999, "Policy Loss": -0.5798370242118835, "Value Loss": 0.06962831318378448, "_runtime": 4730.755991697311, "_timestamp": 1585574646.600625, "_step": 86}
{"Episode reward": -97.37505907284299, "Episode length": 999, "Policy Loss": -0.6259158849716187, "Value Loss": 0.10991862416267395, "_runtime": 4732.341500520706, "_timestamp": 1585574648.1861339, "_step": 87}
{"Episode reward": -95.95711648512473, "Episode length": 999, "Policy Loss": -0.5773527026176453, "Value Loss": 0.04488486796617508, "_runtime": 4733.937815904617, "_timestamp": 1585574649.7824492, "_step": 88}
{"Episode reward": -98.80281469595077, "Episode length": 999, "Policy Loss": -0.512216329574585, "Value Loss": 0.012983322143554688, "_runtime": 4735.5150899887085, "_timestamp": 1585574651.3597233, "_step": 89}
{"Episode reward": -94.9428983411571, "Episode length": 999, "Policy Loss": -0.41668978333473206, "Value Loss": 0.011652322486042976, "_runtime": 4737.093695640564, "_timestamp": 1585574652.938329, "_step": 90}
{"Episode reward": -95.88533277106454, "Episode length": 999, "Policy Loss": -0.36332014203071594, "Value Loss": 0.012688030488789082, "_runtime": 4738.676246881485, "_timestamp": 1585574654.5208802, "_step": 91}
{"Episode reward": -98.82182937118614, "Episode length": 999, "Policy Loss": -0.4050697684288025, "Value Loss": 0.014425158500671387, "_runtime": 4740.256083488464, "_timestamp": 1585574656.1007168, "_step": 92}
{"Episode reward": -94.63245441094347, "Episode length": 999, "Policy Loss": -0.19878654181957245, "Value Loss": 0.05802349001169205, "_runtime": 4741.843022108078, "_timestamp": 1585574657.6876554, "_step": 93}
{"Episode reward": -94.9716131021484, "Episode length": 999, "Policy Loss": -0.17354023456573486, "Value Loss": 0.05373658984899521, "_runtime": 4743.417994022369, "_timestamp": 1585574659.2626274, "_step": 94}
{"Episode reward": -97.91181452141691, "Episode length": 999, "Policy Loss": -0.32454943656921387, "Value Loss": 0.011720607057213783, "_runtime": 4744.992439746857, "_timestamp": 1585574660.837073, "_step": 95}
{"Episode reward": -96.688099214686, "Episode length": 999, "Policy Loss": -0.3088698387145996, "Value Loss": 0.005157670006155968, "_runtime": 4746.573989152908, "_timestamp": 1585574662.4186225, "_step": 96}
{"Episode reward": -98.38253473273595, "Episode length": 999, "Policy Loss": -0.34567880630493164, "Value Loss": 0.011728813871741295, "_runtime": 4748.158374071121, "_timestamp": 1585574664.0030074, "_step": 97}
{"Episode reward": -94.79584319000969, "Episode length": 999, "Policy Loss": -0.2518742084503174, "Value Loss": 0.013067939318716526, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511, 0.6985775828361511]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0], "bins": [-0.7098484039306641, -0.4811922013759613, -0.25253599882125854, -0.0238797664642334, 0.20477640628814697, 0.43343257904052734, 0.6620888710021973, 0.8907450437545776, 1.119401216506958, 1.348057508468628, 1.5767135620117188, 1.8053698539733887, 2.0340261459350586, 2.2626821994781494, 2.4913384914398193, 2.71999454498291, 2.94865083694458, 3.17730712890625, 3.40596342086792, 3.6346192359924316, 3.8632755279541016, 4.0919318199157715, 4.320588111877441, 4.549244403839111, 4.777900695800781, 5.006556510925293, 5.235212802886963, 5.463869094848633, 5.692525386810303, 5.921181678771973, 6.149837493896484, 6.378493785858154, 6.607150077819824, 6.835806369781494, 7.064462661743164, 7.293118476867676, 7.521775245666504, 7.750431060791016, 7.979086875915527, 8.207743644714355, 8.436399459838867, 8.665056228637695, 8.893712043762207, 9.122367858886719, 9.351024627685547, 9.579680442810059, 9.808337211608887, 10.036993026733398, 10.265649795532227, 10.494305610656738, 10.72296142578125, 10.951618194580078, 11.18027400970459, 11.408930778503418, 11.63758659362793, 11.866242408752441, 12.09489917755127, 12.323554992675781, 12.55221176147461, 12.780867576599121, 13.009523391723633, 13.238180160522461, 13.466835975646973, 13.6954927444458, 13.924148559570312]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.0012227196712046862, 0.0038964671548455954, 0.00901565421372652, 0.014134841039776802, 0.01925402693450451, 0.024373212829232216, 0.029492400586605072, 0.03461159020662308, 0.039730776101350784, 0.04484996199607849, 0.0499691478908062, 0.055088337510824203, 0.06020752340555191, 0.06532670557498932, 0.07044589519500732, 0.07556507736444473, 0.08068426698446274, 0.08580345660448074, 0.09092263877391815, 0.09604182839393616, 0.10116101056337357, 0.10628020018339157, 0.11139938980340958, 0.11651857197284698, 0.12163776159286499, 0.126756951212883, 0.131876140832901, 0.136995330452919, 0.142114520072937, 0.14723370969295502, 0.15235288441181183, 0.15747207403182983, 0.16259126365184784, 0.16771045327186584, 0.17282964289188385, 0.17794881761074066, 0.18306800723075867, 0.18818719685077667, 0.19330638647079468, 0.19842557609081268, 0.2035447508096695, 0.2086639404296875, 0.2137831300497055, 0.2189023196697235, 0.22402150928974152, 0.22914069890975952, 0.23425987362861633, 0.23937906324863434, 0.24449825286865234, 0.24961744248867035, 0.25473660230636597, 0.25985580682754517, 0.264974981546402, 0.2700941860675812, 0.275213360786438, 0.2803325355052948, 0.285451740026474, 0.2905709147453308, 0.29569011926651, 0.3008092939853668, 0.30592846870422363, 0.31104767322540283, 0.31616684794425964, 0.32128605246543884, 0.32640522718429565]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 5.0, 5.0, 5.0, 7.0, 9.0, 8.0, 6.0, 6.0, 4.0, 2.0, 7.0, 6.0, 7.0, 9.0, 2.0, 13.0, 15.0, 6.0, 3.0, 259.0, 3.0, 6.0, 7.0, 3.0, 6.0, 10.0, 7.0, 3.0, 1.0, 2.0, 2.0, 4.0, 6.0, 4.0, 2.0, 4.0, 0.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 5.0, 1.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0], "bins": [-0.35613515973091125, -0.3383996784687042, -0.3206641972064972, -0.30292871594429016, -0.28519320487976074, -0.2674577236175537, -0.24972224235534668, -0.23198676109313965, -0.21425127983093262, -0.19651579856872559, -0.17878031730651855, -0.16104482114315033, -0.1433093398809433, -0.12557385861873627, -0.10783836245536804, -0.09010288119316101, -0.07236739993095398, -0.05463191866874695, -0.03689643740653992, -0.019160956144332886, -0.0014254748821258545, 0.016310036182403564, 0.034045517444610596, 0.05178099870681763, 0.06951647996902466, 0.08725196123123169, 0.10498744249343872, 0.12272292375564575, 0.14045843482017517, 0.1581939160823822, 0.17592939734458923, 0.19366487860679626, 0.2114003598690033, 0.22913584113121033, 0.24687132239341736, 0.2646068036556244, 0.2823422849178314, 0.30007776618003845, 0.3178132474422455, 0.3355487287044525, 0.35328420996665955, 0.37101975083351135, 0.3887552320957184, 0.4064907133579254, 0.42422619462013245, 0.4419616758823395, 0.4596971571445465, 0.47743263840675354, 0.49516811966896057, 0.5129035711288452, 0.5306390523910522, 0.5483745336532593, 0.5661100149154663, 0.5838454961776733, 0.6015809774398804, 0.6193164587020874, 0.637052059173584, 0.654787540435791, 0.672523021697998, 0.6902585029602051, 0.7079939842224121, 0.7257294654846191, 0.7434649467468262, 0.7612004280090332, 0.7789359092712402]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-1.258665919303894, -1.2208898067474365, -1.183113694190979, -1.1453375816345215, -1.107561469078064, -1.0697853565216064, -1.032009243965149, -0.9942330718040466, -0.9564569592475891, -0.9186808466911316, -0.8809047341346741, -0.8431285619735718, -0.8053524494171143, -0.7675763368606567, -0.7298002243041992, -0.6920241117477417, -0.6542479991912842, -0.6164718866348267, -0.5786957740783691, -0.5409196615219116, -0.5031435489654541, -0.4653673768043518, -0.4275912642478943, -0.38981515169143677, -0.35203903913497925, -0.31426292657852173, -0.2764868140220642, -0.23871064186096191, -0.2009345293045044, -0.16315841674804688, -0.12538230419158936, -0.08760619163513184, -0.049830079078674316, -0.012053966522216797, 0.025722146034240723, 0.06349825859069824, 0.10127437114715576, 0.13905048370361328, 0.1768265962600708, 0.21460270881652832, 0.25237882137298584, 0.2901550531387329, 0.32793116569519043, 0.36570727825164795, 0.40348339080810547, 0.441259503364563, 0.4790356159210205, 0.516811728477478, 0.5545878410339355, 0.5923639535903931, 0.6301400661468506, 0.6679161787033081, 0.7056922912597656, 0.7434684038162231, 0.7812446355819702, 0.8190206289291382, 0.8567968606948853, 0.8945728540420532, 0.9323490858078003, 0.9701250791549683, 1.0079013109207153, 1.0456773042678833, 1.0834535360336304, 1.1212295293807983, 1.1590057611465454]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 3.0, 3.0, 5.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.523775041103363, -0.5080352425575256, -0.4922954738140106, -0.4765556752681732, -0.4608159065246582, -0.4450761079788208, -0.4293363094329834, -0.4135965406894684, -0.39785677194595337, -0.38211697340011597, -0.36637717485427856, -0.35063740611076355, -0.33489760756492615, -0.31915783882141113, -0.30341804027557373, -0.28767824172973633, -0.2719384729862213, -0.2561986744403839, -0.2404589056968689, -0.2247191071510315, -0.20897933840751648, -0.19323953986167908, -0.17749977111816406, -0.16175997257232666, -0.14602017402648926, -0.13028040528297424, -0.11454060673713684, -0.09880083799362183, -0.08306103944778442, -0.06732127070426941, -0.05158147215843201, -0.03584170341491699, -0.02010190486907959, -0.0043621063232421875, 0.011377692222595215, 0.027117431163787842, 0.042857229709625244, 0.058597028255462646, 0.07433682680130005, 0.09007656574249268, 0.10581636428833008, 0.12155616283416748, 0.13729596138000488, 0.15303575992584229, 0.1687754988670349, 0.18451529741287231, 0.20025509595870972, 0.21599489450454712, 0.23173469305038452, 0.24747443199157715, 0.26321423053741455, 0.27895402908325195, 0.29469382762908936, 0.310433566570282, 0.3261733651161194, 0.3419131636619568, 0.3576529622077942, 0.3733927607536316, 0.3891324996948242, 0.4048722982406616, 0.420612096786499, 0.4363518953323364, 0.45209163427352905, 0.46783143281936646, 0.48357123136520386]}, "_runtime": 4749.7352521419525, "_timestamp": 1585574665.5798855, "_step": 98}
{"Episode reward": -98.30827744071804, "Episode length": 999, "Policy Loss": -0.33799606561660767, "Value Loss": 0.030852042138576508, "_runtime": 4751.356856107712, "_timestamp": 1585574667.2014894, "_step": 99}
{"Episode reward": -96.59896590753279, "Episode length": 999, "Policy Loss": -0.2905246913433075, "Value Loss": 0.021729355677962303, "_runtime": 4752.94152879715, "_timestamp": 1585574668.7861621, "_step": 100}
{"Episode reward": -96.62685369448985, "Episode length": 999, "Policy Loss": -0.2715604305267334, "Value Loss": 0.026125360280275345, "_runtime": 4754.513423681259, "_timestamp": 1585574670.358057, "_step": 101}
{"Episode reward": -98.25762120119968, "Episode length": 999, "Policy Loss": -0.227031871676445, "Value Loss": 0.003394531551748514, "_runtime": 4756.094279766083, "_timestamp": 1585574671.938913, "_step": 102}
{"Episode reward": -98.33386574397457, "Episode length": 999, "Policy Loss": -0.2003423273563385, "Value Loss": 0.002088339300826192, "_runtime": 4757.6686153411865, "_timestamp": 1585574673.5132487, "_step": 103}
{"Episode reward": -98.15368764601344, "Episode length": 999, "Policy Loss": -0.15579655766487122, "Value Loss": 0.004042916931211948, "_runtime": 4759.2497363090515, "_timestamp": 1585574675.0943696, "_step": 104}
{"Episode reward": -96.30671669314157, "Episode length": 999, "Policy Loss": -0.14457263052463531, "Value Loss": 0.003587492974475026, "_runtime": 4760.83646941185, "_timestamp": 1585574676.6811028, "_step": 105}
{"Episode reward": -95.08483559142428, "Episode length": 999, "Policy Loss": -0.09268198162317276, "Value Loss": 0.016377562656998634, "_runtime": 4762.410384178162, "_timestamp": 1585574678.2550175, "_step": 106}
{"Episode reward": -98.10308577562112, "Episode length": 999, "Policy Loss": -0.11399298906326294, "Value Loss": 0.009552404284477234, "_runtime": 4763.983268022537, "_timestamp": 1585574679.8279014, "_step": 107}
{"Episode reward": -96.70014979114266, "Episode length": 999, "Policy Loss": -0.07109168916940689, "Value Loss": 0.010116634890437126, "_runtime": 4765.566205024719, "_timestamp": 1585574681.4108384, "_step": 108}
{"Episode reward": -98.95004317390679, "Episode length": 999, "Policy Loss": -0.12457677721977234, "Value Loss": 0.0013964242534711957, "_runtime": 4767.140887260437, "_timestamp": 1585574682.9855206, "_step": 109}
{"Episode reward": -98.51600285539163, "Episode length": 999, "Policy Loss": -0.10938999056816101, "Value Loss": 0.0009238073835149407, "_runtime": 4768.724096059799, "_timestamp": 1585574684.5687294, "_step": 110}
{"Episode reward": -96.8347665576786, "Episode length": 999, "Policy Loss": -0.09737517684698105, "Value Loss": 0.0009255988406948745, "_runtime": 4770.309005737305, "_timestamp": 1585574686.153639, "_step": 111}
{"Episode reward": -98.02259589202309, "Episode length": 999, "Policy Loss": -0.09564924240112305, "Value Loss": 0.0015958111034706235, "_runtime": 4771.8912358284, "_timestamp": 1585574687.7358692, "_step": 112}
{"Episode reward": -97.79706934160181, "Episode length": 999, "Policy Loss": -0.09150347858667374, "Value Loss": 0.003566800383850932, "_runtime": 4773.475996494293, "_timestamp": 1585574689.3206298, "_step": 113}
{"Episode reward": -98.01653978590085, "Episode length": 999, "Policy Loss": -0.08849858492612839, "Value Loss": 0.00418598297983408, "_runtime": 4775.089987754822, "_timestamp": 1585574690.934621, "_step": 114}
{"Episode reward": -98.37038084745605, "Episode length": 999, "Policy Loss": -0.07665225118398666, "Value Loss": 0.001917573856189847, "_runtime": 4776.673475265503, "_timestamp": 1585574692.5181086, "_step": 115}
{"Episode reward": -97.6515458245898, "Episode length": 999, "Policy Loss": -0.08023224025964737, "Value Loss": 0.004646793007850647, "_runtime": 4778.258966684341, "_timestamp": 1585574694.1036, "_step": 116}
{"Episode reward": -98.09371337591962, "Episode length": 999, "Policy Loss": -0.08315359055995941, "Value Loss": 0.005563040263950825, "_runtime": 4779.845309972763, "_timestamp": 1585574695.6899433, "_step": 117}
{"Episode reward": -96.43384812465973, "Episode length": 999, "Policy Loss": -0.04992684721946716, "Value Loss": 0.0015444436576217413, "_runtime": 4781.421821117401, "_timestamp": 1585574697.2664545, "_step": 118}
{"Episode reward": -97.72389769743755, "Episode length": 999, "Policy Loss": -0.03735830634832382, "Value Loss": 0.0002339082129765302, "_runtime": 4782.99663233757, "_timestamp": 1585574698.8412657, "_step": 119}
{"Episode reward": -98.5714153897729, "Episode length": 999, "Policy Loss": -0.03361649066209793, "Value Loss": 0.0005562390433624387, "_runtime": 4784.57723069191, "_timestamp": 1585574700.421864, "_step": 120}
{"Episode reward": -97.63441415858694, "Episode length": 999, "Policy Loss": -0.0062070852145552635, "Value Loss": 0.0034654070623219013, "_runtime": 4786.165691137314, "_timestamp": 1585574702.0103245, "_step": 121}
{"Episode reward": -96.6866620021671, "Episode length": 999, "Policy Loss": -0.006618854124099016, "Value Loss": 0.002231632126495242, "_runtime": 4787.740712881088, "_timestamp": 1585574703.5853462, "_step": 122}
{"Episode reward": -95.75325486550757, "Episode length": 999, "Policy Loss": 0.04818079620599747, "Value Loss": 0.006356072146445513, "_runtime": 4789.325787305832, "_timestamp": 1585574705.1704206, "_step": 123}
{"Episode reward": -96.74576043302238, "Episode length": 999, "Policy Loss": 0.006827173754572868, "Value Loss": 0.001975299557670951, "_runtime": 4790.914944410324, "_timestamp": 1585574706.7595778, "_step": 124}
{"Episode reward": -97.93121068930384, "Episode length": 999, "Policy Loss": -0.006715091411024332, "Value Loss": 0.0005777832120656967, "_runtime": 4792.488145112991, "_timestamp": 1585574708.3327785, "_step": 125}
{"Episode reward": -96.85025797670389, "Episode length": 999, "Policy Loss": 0.003983742091804743, "Value Loss": 0.00041005967068485916, "_runtime": 4794.0641713142395, "_timestamp": 1585574709.9088047, "_step": 126}
{"Episode reward": -96.89346762158831, "Episode length": 999, "Policy Loss": -0.002629464026540518, "Value Loss": 0.0002661821781657636, "_runtime": 4795.639054298401, "_timestamp": 1585574711.4836876, "_step": 127}
{"Episode reward": -98.35548891254672, "Episode length": 999, "Policy Loss": -0.006774443667382002, "Value Loss": 0.000356111180735752, "_runtime": 4797.26216840744, "_timestamp": 1585574713.1068017, "_step": 128}
{"Episode reward": -94.4839211955785, "Episode length": 999, "Policy Loss": -0.013268590904772282, "Value Loss": 0.0028002778999507427, "_runtime": 4798.837854385376, "_timestamp": 1585574714.6824877, "_step": 129}
{"Episode reward": -95.75810158080533, "Episode length": 999, "Policy Loss": -0.0011263721389696002, "Value Loss": 0.0014437943464145064, "_runtime": 4800.426019668579, "_timestamp": 1585574716.270653, "_step": 130}
{"Episode reward": -96.75888497976396, "Episode length": 999, "Policy Loss": -0.003165724454447627, "Value Loss": 0.0008758891490288079, "_runtime": 4802.012729167938, "_timestamp": 1585574717.8573625, "_step": 131}
{"Episode reward": -97.92447349636711, "Episode length": 999, "Policy Loss": 0.00467172684147954, "Value Loss": 0.00025675498181954026, "_runtime": 4803.598697423935, "_timestamp": 1585574719.4433308, "_step": 132}
{"Episode reward": -98.15833007244126, "Episode length": 999, "Policy Loss": 0.007473606616258621, "Value Loss": 0.0001464162633055821, "_runtime": 4805.185281038284, "_timestamp": 1585574721.0299144, "_step": 133}
{"Episode reward": -96.32051512291109, "Episode length": 999, "Policy Loss": 0.01963737979531288, "Value Loss": 0.0005391628947108984, "_runtime": 4806.774118900299, "_timestamp": 1585574722.6187522, "_step": 134}
{"Episode reward": -97.28619053971262, "Episode length": 999, "Policy Loss": 0.013872701674699783, "Value Loss": 0.0002976628893520683, "_runtime": 4808.350948810577, "_timestamp": 1585574724.1955822, "_step": 135}
{"Episode reward": -98.0280741185746, "Episode length": 999, "Policy Loss": 0.02012099325656891, "Value Loss": 0.000763454067055136, "_runtime": 4809.930408477783, "_timestamp": 1585574725.7750418, "_step": 136}
{"Episode reward": -97.04935867835755, "Episode length": 999, "Policy Loss": 0.021292340010404587, "Value Loss": 0.0007530676084570587, "_runtime": 4811.512928724289, "_timestamp": 1585574727.357562, "_step": 137}
{"Episode reward": -99.32009599534967, "Episode length": 999, "Policy Loss": 0.009561686776578426, "Value Loss": 0.0002126194885931909, "_runtime": 4813.089440822601, "_timestamp": 1585574728.9340742, "_step": 138}
{"Episode reward": -98.7596407786104, "Episode length": 999, "Policy Loss": 0.011643153615295887, "Value Loss": 0.00025827722856774926, "_runtime": 4814.6716957092285, "_timestamp": 1585574730.516329, "_step": 139}
{"Episode reward": -98.37169768925104, "Episode length": 999, "Policy Loss": 0.015047507360577583, "Value Loss": 0.0002061419509118423, "_runtime": 4816.261422395706, "_timestamp": 1585574732.1060557, "_step": 140}
{"Episode reward": -96.98043428951944, "Episode length": 999, "Policy Loss": 0.02105223573744297, "Value Loss": 0.00031959923217073083, "_runtime": 4817.845480918884, "_timestamp": 1585574733.6901143, "_step": 141}
{"Episode reward": -96.69851819400039, "Episode length": 999, "Policy Loss": 0.026198843494057655, "Value Loss": 0.00038348196540027857, "_runtime": 4819.423393249512, "_timestamp": 1585574735.2680266, "_step": 142}
{"Episode reward": -97.26642160347073, "Episode length": 999, "Policy Loss": 0.017113160341978073, "Value Loss": 0.0002241634501842782, "_runtime": 4821.03225851059, "_timestamp": 1585574736.8768919, "_step": 143}
{"Episode reward": -95.83514788915201, "Episode length": 999, "Policy Loss": 0.020295875146985054, "Value Loss": 0.00034705770667642355, "_runtime": 4822.619197368622, "_timestamp": 1585574738.4638307, "_step": 144}
{"Episode reward": -98.75713080032013, "Episode length": 999, "Policy Loss": 0.008324253372848034, "Value Loss": 0.00019482735660858452, "_runtime": 4824.204687356949, "_timestamp": 1585574740.0493207, "_step": 145}
{"Episode reward": -98.85857181278138, "Episode length": 999, "Policy Loss": 0.006161914207041264, "Value Loss": 0.0003573399444576353, "_runtime": 4825.779450416565, "_timestamp": 1585574741.6240838, "_step": 146}
{"Episode reward": -98.60023136756358, "Episode length": 999, "Policy Loss": 0.006894940044730902, "Value Loss": 0.0003234490577597171, "_runtime": 4827.3600397109985, "_timestamp": 1585574743.204673, "_step": 147}
{"Episode reward": -96.26624006333383, "Episode length": 999, "Policy Loss": 0.009046555496752262, "Value Loss": 0.0007145758718252182, "_runtime": 4828.936218261719, "_timestamp": 1585574744.7808516, "_step": 148}
{"Episode reward": -98.27952700041342, "Episode length": 999, "Policy Loss": 0.010719947516918182, "Value Loss": 0.0001728731585899368, "_runtime": 4830.519833087921, "_timestamp": 1585574746.3644664, "_step": 149}
{"Episode reward": -97.11844272986262, "Episode length": 999, "Policy Loss": 0.016667533665895462, "Value Loss": 0.0002120745339198038, "_runtime": 4832.089985370636, "_timestamp": 1585574747.9346187, "_step": 150}
{"Episode reward": -98.1207822020855, "Episode length": 999, "Policy Loss": 0.01538089383393526, "Value Loss": 0.00020784567459486425, "_runtime": 4833.669704914093, "_timestamp": 1585574749.5143383, "_step": 151}
{"Episode reward": -97.66811922104323, "Episode length": 999, "Policy Loss": 0.018991557881236076, "Value Loss": 0.0003457072307355702, "_runtime": 4835.256069660187, "_timestamp": 1585574751.100703, "_step": 152}
{"Episode reward": -97.4137009786122, "Episode length": 999, "Policy Loss": 0.015834376215934753, "Value Loss": 0.00024482281878590584, "_runtime": 4836.834159851074, "_timestamp": 1585574752.6787932, "_step": 153}
{"Episode reward": -96.36801833883968, "Episode length": 999, "Policy Loss": 0.02453588880598545, "Value Loss": 0.0005523056024685502, "_runtime": 4838.4079377651215, "_timestamp": 1585574754.252571, "_step": 154}
{"Episode reward": -97.58906406499206, "Episode length": 999, "Policy Loss": 0.016995195299386978, "Value Loss": 0.00032098087831400335, "_runtime": 4839.98385477066, "_timestamp": 1585574755.828488, "_step": 155}
{"Episode reward": -98.35009613732588, "Episode length": 999, "Policy Loss": 0.009171069599688053, "Value Loss": 0.00012843507283832878, "_runtime": 4841.569394111633, "_timestamp": 1585574757.4140275, "_step": 156}
{"Episode reward": -97.8123749736008, "Episode length": 999, "Policy Loss": 0.008499461226165295, "Value Loss": 0.00015845010057091713, "_runtime": 4843.1451296806335, "_timestamp": 1585574758.989763, "_step": 157}
{"Episode reward": -98.15596558020258, "Episode length": 999, "Policy Loss": 0.006221923045814037, "Value Loss": 0.0002616677666082978, "_runtime": 4844.758847951889, "_timestamp": 1585574760.6034813, "_step": 158}
{"Episode reward": -98.30245316579229, "Episode length": 999, "Policy Loss": 0.005925264675170183, "Value Loss": 0.00024319591466337442, "_runtime": 4846.3365161418915, "_timestamp": 1585574762.1811495, "_step": 159}
{"Episode reward": -96.90961133409691, "Episode length": 999, "Policy Loss": 0.012097718194127083, "Value Loss": 0.00023629709903616458, "_runtime": 4847.910698413849, "_timestamp": 1585574763.7553318, "_step": 160}
{"Episode reward": -98.39713773489439, "Episode length": 999, "Policy Loss": 0.0022738114930689335, "Value Loss": 0.0002640049788169563, "_runtime": 4849.488228082657, "_timestamp": 1585574765.3328614, "_step": 161}
{"Episode reward": -98.60203504752695, "Episode length": 999, "Policy Loss": 0.0044760024175047874, "Value Loss": 0.00011825065303128213, "_runtime": 4851.063999176025, "_timestamp": 1585574766.9086325, "_step": 162}
{"Episode reward": -97.66491192783305, "Episode length": 999, "Policy Loss": 0.008277366869151592, "Value Loss": 0.00018970480596181005, "_runtime": 4852.650821685791, "_timestamp": 1585574768.495455, "_step": 163}
{"Episode reward": -97.21309953159817, "Episode length": 999, "Policy Loss": 0.01021091639995575, "Value Loss": 0.0001920495560625568, "_runtime": 4854.21782374382, "_timestamp": 1585574770.062457, "_step": 164}
{"Episode reward": -98.50769484029067, "Episode length": 999, "Policy Loss": 0.004674753174185753, "Value Loss": 0.00011626916966633871, "_runtime": 4855.798786401749, "_timestamp": 1585574771.6434197, "_step": 165}
{"Episode reward": -96.51282049357746, "Episode length": 999, "Policy Loss": 0.017066067084670067, "Value Loss": 0.0003025385085493326, "_runtime": 4857.36360168457, "_timestamp": 1585574773.208235, "_step": 166}
{"Episode reward": -97.87781783940318, "Episode length": 999, "Policy Loss": 0.008342108689248562, "Value Loss": 0.00019300215353723615, "_runtime": 4858.9517941474915, "_timestamp": 1585574774.7964275, "_step": 167}
{"Episode reward": -92.533272267937, "Episode length": 999, "Policy Loss": 0.018452201038599014, "Value Loss": 0.0006052509997971356, "_runtime": 4860.536991119385, "_timestamp": 1585574776.3816245, "_step": 168}
{"Episode reward": -98.39318520991598, "Episode length": 999, "Policy Loss": 0.0029857633635401726, "Value Loss": 0.00012473143578972667, "_runtime": 4862.114555120468, "_timestamp": 1585574777.9591885, "_step": 169}
{"Episode reward": -98.87995750416768, "Episode length": 999, "Policy Loss": 0.0007879420882090926, "Value Loss": 7.007943349890411e-05, "_runtime": 4863.701870679855, "_timestamp": 1585574779.546504, "_step": 170}
{"Episode reward": -95.7420148584479, "Episode length": 999, "Policy Loss": 0.015087251551449299, "Value Loss": 0.00033589309896342456, "_runtime": 4865.290166378021, "_timestamp": 1585574781.1347997, "_step": 171}
{"Episode reward": -98.66348323817867, "Episode length": 999, "Policy Loss": 0.0003235084586776793, "Value Loss": 9.881803271127865e-05, "_runtime": 4866.871234416962, "_timestamp": 1585574782.7158678, "_step": 172}
{"Episode reward": -98.01172777637842, "Episode length": 999, "Policy Loss": 0.0017542151035740972, "Value Loss": 0.00015112565597519279, "_runtime": 4868.482489109039, "_timestamp": 1585574784.3271224, "_step": 173}
{"Episode reward": -96.33620833208563, "Episode length": 999, "Policy Loss": 0.007350392639636993, "Value Loss": 0.00028795000980608165, "_runtime": 4870.058931350708, "_timestamp": 1585574785.9035647, "_step": 174}
{"Episode reward": -99.09529091634042, "Episode length": 999, "Policy Loss": -0.0034293695352971554, "Value Loss": 6.348270107991993e-05, "_runtime": 4871.645698547363, "_timestamp": 1585574787.490332, "_step": 175}
{"Episode reward": -96.30997055789089, "Episode length": 999, "Policy Loss": 0.008905000053346157, "Value Loss": 0.0002880417159758508, "_runtime": 4873.23220705986, "_timestamp": 1585574789.0768404, "_step": 176}
{"Episode reward": -96.54280723378652, "Episode length": 999, "Policy Loss": 0.006425315979868174, "Value Loss": 0.00027355446945875883, "_runtime": 4874.8183472156525, "_timestamp": 1585574790.6629806, "_step": 177}
{"Episode reward": -95.69834487535739, "Episode length": 999, "Policy Loss": 0.008373130112886429, "Value Loss": 0.0003470337833277881, "_runtime": 4876.393949508667, "_timestamp": 1585574792.2385828, "_step": 178}
{"Episode reward": -96.82226486114928, "Episode length": 999, "Policy Loss": 0.006006197072565556, "Value Loss": 0.0002342373481951654, "_runtime": 4877.984787940979, "_timestamp": 1585574793.8294213, "_step": 179}
{"Episode reward": -97.98900762962337, "Episode length": 999, "Policy Loss": 2.5880028260871768e-05, "Value Loss": 0.000151612694025971, "_runtime": 4879.570798873901, "_timestamp": 1585574795.4154322, "_step": 180}
{"Episode reward": -95.42559482628678, "Episode length": 999, "Policy Loss": 0.007161884102970362, "Value Loss": 0.0003385256277397275, "_runtime": 4881.147843122482, "_timestamp": 1585574796.9924765, "_step": 181}
{"Episode reward": -97.75718595163696, "Episode length": 999, "Policy Loss": 0.001011523068882525, "Value Loss": 0.00016457276069559157, "_runtime": 4882.721853494644, "_timestamp": 1585574798.5664868, "_step": 182}
{"Episode reward": -97.6334028151403, "Episode length": 999, "Policy Loss": 0.0008043366833589971, "Value Loss": 0.0001893419394036755, "_runtime": 4884.3012528419495, "_timestamp": 1585574800.1458862, "_step": 183}
{"Episode reward": -97.70713981087457, "Episode length": 999, "Policy Loss": 0.0005470588221214712, "Value Loss": 0.00017046496213879436, "_runtime": 4885.890436410904, "_timestamp": 1585574801.7350698, "_step": 184}
{"Episode reward": -97.15886378590082, "Episode length": 999, "Policy Loss": 0.003362138755619526, "Value Loss": 0.00021413851936813444, "_runtime": 4887.465380907059, "_timestamp": 1585574803.3100142, "_step": 185}
{"Episode reward": -96.46773969287615, "Episode length": 999, "Policy Loss": 0.005097434390336275, "Value Loss": 0.00026176011306233704, "_runtime": 4889.045783519745, "_timestamp": 1585574804.8904169, "_step": 186}
{"Episode reward": -95.36678528532354, "Episode length": 999, "Policy Loss": 0.008460544049739838, "Value Loss": 0.00035333484993316233, "_runtime": 4890.664160728455, "_timestamp": 1585574806.508794, "_step": 187}
{"Episode reward": -95.64801628828084, "Episode length": 999, "Policy Loss": 0.007481744047254324, "Value Loss": 0.00034574742312543094, "_runtime": 4892.2390694618225, "_timestamp": 1585574808.0837028, "_step": 188}
{"Episode reward": -97.12794018150929, "Episode length": 999, "Policy Loss": 0.00048261514166370034, "Value Loss": 0.00021870469208806753, "_runtime": 4893.825045585632, "_timestamp": 1585574809.669679, "_step": 189}
{"Episode reward": -96.35717909957107, "Episode length": 999, "Policy Loss": 0.004815718624740839, "Value Loss": 0.0002841436944436282, "_runtime": 4895.412775754929, "_timestamp": 1585574811.257409, "_step": 190}
{"Episode reward": -98.21682471497758, "Episode length": 999, "Policy Loss": -0.005163366440683603, "Value Loss": 0.00012857771071139723, "_runtime": 4896.997844457626, "_timestamp": 1585574812.8424778, "_step": 191}
{"Episode reward": -96.0371319678141, "Episode length": 999, "Policy Loss": 0.005137377884238958, "Value Loss": 0.00027202771161682904, "_runtime": 4898.573189020157, "_timestamp": 1585574814.4178224, "_step": 192}
{"Episode reward": -99.04684641783874, "Episode length": 999, "Policy Loss": -0.00898033194243908, "Value Loss": 5.811794108012691e-05, "_runtime": 4900.1564400196075, "_timestamp": 1585574816.0010734, "_step": 193}
{"Episode reward": -97.25207310674575, "Episode length": 999, "Policy Loss": -0.0010559530928730965, "Value Loss": 0.0002130695356754586, "_runtime": 4901.739350557327, "_timestamp": 1585574817.583984, "_step": 194}
{"Episode reward": -97.9920229964707, "Episode length": 999, "Policy Loss": -0.0036403413396328688, "Value Loss": 0.0001431336422683671, "_runtime": 4903.32736325264, "_timestamp": 1585574819.1719966, "_step": 195}
{"Episode reward": -97.22251197551338, "Episode length": 999, "Policy Loss": 0.0004729140200652182, "Value Loss": 0.00020790075359400362, "_runtime": 4904.912687063217, "_timestamp": 1585574820.7573204, "_step": 196}
{"Episode reward": -96.46670528459663, "Episode length": 999, "Policy Loss": 0.0038776753935962915, "Value Loss": 0.00025042943889275193, "_runtime": 4906.499153137207, "_timestamp": 1585574822.3437865, "_step": 197}
{"Episode reward": -97.07829576981172, "Episode length": 999, "Policy Loss": 0.0002614881086628884, "Value Loss": 0.0002185521589126438, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517, -0.019457215443253517]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], "bins": [-0.2746337950229645, -0.27003878355026245, -0.2654438018798828, -0.2608487904071808, -0.25625380873680115, -0.2516587972640991, -0.24706381559371948, -0.24246880412101746, -0.23787380754947662, -0.2332788109779358, -0.22868381440639496, -0.22408881783485413, -0.2194938212633133, -0.21489882469177246, -0.21030381321907043, -0.2057088315486908, -0.20111382007598877, -0.19651883840560913, -0.1919238269329071, -0.18732883036136627, -0.18273383378982544, -0.1781388372182846, -0.17354384064674377, -0.16894884407520294, -0.1643538475036621, -0.15975883603096008, -0.15516385436058044, -0.15056884288787842, -0.14597384631633759, -0.14137884974479675, -0.13678385317325592, -0.1321888566017151, -0.12759386003017426, -0.12299886345863342, -0.11840386688709259, -0.11380887031555176, -0.10921387374401093, -0.10461887717247009, -0.10002386569976807, -0.09542886912822723, -0.0908338725566864, -0.08623887598514557, -0.08164387941360474, -0.0770488828420639, -0.07245388627052307, -0.06785888969898224, -0.0632638931274414, -0.058668896555900574, -0.05407389998435974, -0.049478888511657715, -0.04488389194011688, -0.04028889536857605, -0.03569389879703522, -0.031098902225494385, -0.026503905653953552, -0.02190890908241272, -0.017313897609710693, -0.012718915939331055, -0.008123904466629028, -0.0035289227962493896, 0.0010660886764526367, 0.005661070346832275, 0.010256081819534302, 0.01485106348991394, 0.019446074962615967]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], "bins": [-0.009091251529753208, -0.008949125185608864, -0.00880699884146452, -0.008664872497320175, -0.00852274615317583, -0.008380619809031487, -0.008238493464887142, -0.008096367120742798, -0.007954240776598454, -0.007812114432454109, -0.007669988088309765, -0.0075278617441654205, -0.007385735400021076, -0.007243609055876732, -0.0071014827117323875, -0.006959356367588043, -0.006817230023443699, -0.0066751036792993546, -0.00653297733515501, -0.006390850991010666, -0.0062487246468663216, -0.006106598302721977, -0.005964471958577633, -0.005822345614433289, -0.005680218804627657, -0.005538092460483313, -0.005395966116338968, -0.005253839772194624, -0.00511171342805028, -0.004969587083905935, -0.004827460739761591, -0.004685334395617247, -0.004543208051472902, -0.004401081707328558, -0.004258955363184214, -0.004116829019039869, -0.003974702674895525, -0.0038325763307511806, -0.0036904499866068363, -0.003548323642462492, -0.0034061972983181477, -0.0032640709541738033, -0.003121944610029459, -0.0029798182658851147, -0.0028376919217407703, -0.002695565577596426, -0.0025534392334520817, -0.0024113128893077374, -0.0022691860795021057, -0.0021270597353577614, -0.001984933391213417, -0.0018428070470690727, -0.0017006807029247284, -0.001558554358780384, -0.0014164280146360397, -0.0012743016704916954, -0.001132175326347351, -0.0009900489822030067, -0.0008479226380586624, -0.0007057962939143181, -0.0005636699497699738, -0.0004215436056256294, -0.0002794172614812851, -0.00013729091733694077, 4.8354268074035645e-06]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 6.0, 1.0, 4.0, 4.0, 2.0, 6.0, 1.0, 3.0, 3.0, 1.0, 8.0, 8.0, 9.0, 6.0, 8.0, 4.0, 7.0, 7.0, 6.0, 1.0, 259.0, 5.0, 11.0, 13.0, 7.0, 11.0, 10.0, 8.0, 4.0, 5.0, 9.0, 6.0, 6.0, 7.0, 7.0, 8.0, 2.0, 4.0, 0.0, 2.0], "bins": [-0.01867595687508583, -0.01825335994362831, -0.01783076487481594, -0.01740816794335842, -0.016985571011900902, -0.01656297594308853, -0.016140379011631012, -0.015717782080173492, -0.015295187011361122, -0.014872590079903603, -0.014449994079768658, -0.014027398079633713, -0.013604801148176193, -0.013182206079363823, -0.012759609147906303, -0.012337013147771358, -0.011914417147636414, -0.011491820216178894, -0.011069224216043949, -0.010646628215909004, -0.010224031284451485, -0.00980143528431654, -0.009378839284181595, -0.00895624328404665, -0.00853364635258913, -0.008111050352454185, -0.007688454352319241, -0.007265857420861721, -0.006843261420726776, -0.006420665420591831, -0.005998069420456886, -0.005575472488999367, -0.005152876488864422, -0.004730280488729477, -0.004307683557271957, -0.0038850875571370125, -0.0034624915570020676, -0.003039894625544548, -0.0026172995567321777, -0.002194702625274658, -0.0017721056938171387, -0.0013495106250047684, -0.0009269136935472488, -0.0005043167620897293, -8.172169327735901e-05, 0.0003408752381801605, 0.0007634703069925308, 0.0011860672384500504, 0.0016086641699075699, 0.00203125923871994, 0.0024538561701774597, 0.0028764531016349792, 0.0032990481704473495, 0.003721645101904869, 0.004144242033362389, 0.004566837102174759, 0.0049894340336322784, 0.005412030965089798, 0.005834626033902168, 0.006257222965359688, 0.006679818034172058, 0.007102414965629578, 0.007525011897087097, 0.007947606965899467, 0.008370203897356987]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03075322136282921, -0.02992452308535576, -0.02909582294523716, -0.02826712466776371, -0.02743842452764511, -0.02660972625017166, -0.02578102797269821, -0.024952329695224762, -0.024123629555106163, -0.023294929414987564, -0.022466231137514114, -0.021637532860040665, -0.020808834582567215, -0.019980134442448616, -0.019151436164975166, -0.018322736024856567, -0.017494037747383118, -0.016665339469909668, -0.01583663932979107, -0.01500794105231762, -0.01417924091219902, -0.01335054263472557, -0.012521844357252121, -0.011693144217133522, -0.010864445939660072, -0.010035747662186623, -0.009207047522068024, -0.008378349244594574, -0.007549650967121124, -0.006720950827002525, -0.005892252549529076, -0.005063552409410477, -0.004234854131937027, -0.0034061558544635773, -0.0025774557143449783, -0.0017487574368715286, -0.0009200572967529297, -9.135901927947998e-05, 0.0007373392581939697, 0.0015660375356674194, 0.0023947395384311676, 0.0032234378159046173, 0.004052136093378067, 0.004880834370851517, 0.005709532648324966, 0.006538230925798416, 0.007366932928562164, 0.008195631206035614, 0.009024329483509064, 0.009853027760982513, 0.010681726038455963, 0.011510428041219711, 0.012339126318693161, 0.01316782459616661, 0.01399652287364006, 0.01482522115111351, 0.01565391942858696, 0.016482621431350708, 0.017311319708824158, 0.018140017986297607, 0.018968716263771057, 0.019797414541244507, 0.020626116544008255, 0.021454814821481705, 0.022283513098955154]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 3.0, 0.0, 7.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.024744948372244835, -0.023977436125278473, -0.02320992201566696, -0.02244240790605545, -0.02167489565908909, -0.020907383412122726, -0.020139869302511215, -0.019372355192899704, -0.018604842945933342, -0.01783733069896698, -0.01706981658935547, -0.016302302479743958, -0.015534790232777596, -0.014767277054488659, -0.013999763876199722, -0.013232250697910786, -0.012464737519621849, -0.011697224341332912, -0.010929711163043976, -0.01016219798475504, -0.009394684806466103, -0.008627170696854591, -0.00785965844988823, -0.007092146202921867, -0.006324632093310356, -0.005557117983698845, -0.004789605736732483, -0.004022093489766121, -0.0032545793801546097, -0.0024870652705430984, -0.0017195530235767365, -0.0009520407766103745, -0.00018452666699886322, 0.000582987442612648, 0.00135049968957901, 0.002118011936545372, 0.0028855260461568832, 0.0036530401557683945, 0.0044205524027347565, 0.0051880646497011185, 0.00595557875931263, 0.006723092868924141, 0.007490606978535652, 0.008258117362856865, 0.009025631472468376, 0.009793145582079887, 0.0105606559664011, 0.011328170076012611, 0.012095684185624123, 0.012863198295235634, 0.013630712404847145, 0.014398222789168358, 0.015165736898779869, 0.01593325100839138, 0.016700761392712593, 0.017468275502324104, 0.018235789611935616, 0.019003303721547127, 0.019770817831158638, 0.02053832821547985, 0.021305842325091362, 0.022073356434702873, 0.022840866819024086, 0.023608380928635597, 0.02437589503824711]}, "_runtime": 4908.084967374802, "_timestamp": 1585574823.9296007, "_step": 198}
{"Episode reward": -98.20680356854562, "Episode length": 999, "Policy Loss": -0.0056203086860477924, "Value Loss": 0.0001426130038453266, "_runtime": 4909.6689121723175, "_timestamp": 1585574825.5135455, "_step": 199}
{"Episode reward": -96.3907351832145, "Episode length": 999, "Policy Loss": 0.0015364410355687141, "Value Loss": 0.00028242895496077836, "_runtime": 4911.254535198212, "_timestamp": 1585574827.0991685, "_step": 200}
{"Episode reward": -97.8764810450237, "Episode length": 999, "Policy Loss": -0.004653166979551315, "Value Loss": 0.00015235392493195832, "_runtime": 4912.838881492615, "_timestamp": 1585574828.6835148, "_step": 201}
{"Episode reward": -97.75210544466883, "Episode length": 999, "Policy Loss": -0.0039010283071547747, "Value Loss": 0.00016835547285154462, "_runtime": 4914.459757328033, "_timestamp": 1585574830.3043907, "_step": 202}
{"Episode reward": -97.49772133042927, "Episode length": 999, "Policy Loss": -0.0025667487643659115, "Value Loss": 0.00018312083557248116, "_runtime": 4916.048257827759, "_timestamp": 1585574831.8928912, "_step": 203}
{"Episode reward": -98.502607366839, "Episode length": 999, "Policy Loss": -0.006887548137456179, "Value Loss": 0.00011009715672116727, "_runtime": 4917.613798618317, "_timestamp": 1585574833.458432, "_step": 204}
{"Episode reward": -96.6661444608536, "Episode length": 999, "Policy Loss": 0.0025023145135492086, "Value Loss": 0.00024169056268874556, "_runtime": 4919.201908826828, "_timestamp": 1585574835.0465422, "_step": 205}
{"Episode reward": -98.53444129102552, "Episode length": 999, "Policy Loss": -0.007162010762840509, "Value Loss": 0.00010259391274303198, "_runtime": 4920.789391517639, "_timestamp": 1585574836.6340249, "_step": 206}
{"Episode reward": -97.617299888004, "Episode length": 999, "Policy Loss": -0.002066405024379492, "Value Loss": 0.00018034367531072348, "_runtime": 4922.3651003837585, "_timestamp": 1585574838.2097337, "_step": 207}
{"Episode reward": -96.14352429082395, "Episode length": 999, "Policy Loss": 0.003993878606706858, "Value Loss": 0.0002910165349021554, "_runtime": 4923.942534685135, "_timestamp": 1585574839.787168, "_step": 208}
{"Episode reward": -98.0045145434839, "Episode length": 999, "Policy Loss": -0.004135467577725649, "Value Loss": 0.00015732967585790902, "_runtime": 4925.523279666901, "_timestamp": 1585574841.367913, "_step": 209}
{"Episode reward": -96.57543000063096, "Episode length": 999, "Policy Loss": 0.003221656195819378, "Value Loss": 0.00024760246742516756, "_runtime": 4927.106681108475, "_timestamp": 1585574842.9513144, "_step": 210}
{"Episode reward": -96.92686914811107, "Episode length": 999, "Policy Loss": 0.00016829665401019156, "Value Loss": 0.00024306969135068357, "_runtime": 4928.6936647892, "_timestamp": 1585574844.5382981, "_step": 211}
{"Episode reward": -98.67708071321694, "Episode length": 999, "Policy Loss": -0.008196764625608921, "Value Loss": 8.961988351074979e-05, "_runtime": 4930.287273406982, "_timestamp": 1585574846.1319067, "_step": 212}
{"Episode reward": -96.50849476203315, "Episode length": 999, "Policy Loss": 0.001961235422641039, "Value Loss": 0.00025826890487223864, "_runtime": 4931.867187976837, "_timestamp": 1585574847.7118213, "_step": 213}
{"Episode reward": -97.28342500667317, "Episode length": 999, "Policy Loss": -0.0017157384427264333, "Value Loss": 0.00019264858565293252, "_runtime": 4933.443717241287, "_timestamp": 1585574849.2883506, "_step": 214}
{"Episode reward": -98.91937118806717, "Episode length": 999, "Policy Loss": -0.00872722826898098, "Value Loss": 7.248794281622395e-05, "_runtime": 4935.019174575806, "_timestamp": 1585574850.863808, "_step": 215}
{"Episode reward": -98.17646732317968, "Episode length": 999, "Policy Loss": -0.005219749175012112, "Value Loss": 0.0001381610200041905, "_runtime": 4936.595749616623, "_timestamp": 1585574852.440383, "_step": 216}
{"Episode reward": -98.70227116208021, "Episode length": 999, "Policy Loss": -0.00773536367341876, "Value Loss": 8.988007175503299e-05, "_runtime": 4938.194014072418, "_timestamp": 1585574854.0386474, "_step": 217}
{"Episode reward": -94.76013343109369, "Episode length": 999, "Policy Loss": 0.008660911582410336, "Value Loss": 0.00039682138594798744, "_runtime": 4939.769925832748, "_timestamp": 1585574855.6145592, "_step": 218}
{"Episode reward": -98.25084211106372, "Episode length": 999, "Policy Loss": -0.004864559508860111, "Value Loss": 0.00013025838416069746, "_runtime": 4941.358446359634, "_timestamp": 1585574857.2030797, "_step": 219}
{"Episode reward": -98.65493735854537, "Episode length": 999, "Policy Loss": -0.006682786624878645, "Value Loss": 9.197681356454268e-05, "_runtime": 4942.945988893509, "_timestamp": 1585574858.7906222, "_step": 220}
{"Episode reward": -98.33606477394628, "Episode length": 999, "Policy Loss": -0.005165846087038517, "Value Loss": 0.00011148641351610422, "_runtime": 4944.523484706879, "_timestamp": 1585574860.368118, "_step": 221}
{"Episode reward": -94.97209797469839, "Episode length": 999, "Policy Loss": 0.006770019885152578, "Value Loss": 0.00039543129969388247, "_runtime": 4946.103353023529, "_timestamp": 1585574861.9479864, "_step": 222}
{"Episode reward": -98.01129662792373, "Episode length": 999, "Policy Loss": -0.0026748450472950935, "Value Loss": 0.0001560600649099797, "_runtime": 4947.68133354187, "_timestamp": 1585574863.525967, "_step": 223}
{"Episode reward": -98.03023961454326, "Episode length": 999, "Policy Loss": -0.0030684713274240494, "Value Loss": 0.00014322904462460428, "_runtime": 4949.246121168137, "_timestamp": 1585574865.0907545, "_step": 224}
{"Episode reward": -98.74688512602931, "Episode length": 999, "Policy Loss": -0.006464820355176926, "Value Loss": 8.826080738799646e-05, "_runtime": 4950.825126886368, "_timestamp": 1585574866.6697602, "_step": 225}
{"Episode reward": -94.57100303372769, "Episode length": 999, "Policy Loss": 0.009682649746537209, "Value Loss": 0.00042518426198512316, "_runtime": 4952.38959646225, "_timestamp": 1585574868.2342298, "_step": 226}
{"Episode reward": -98.09574664935805, "Episode length": 999, "Policy Loss": -0.0033331902232021093, "Value Loss": 0.00014139858831185848, "_runtime": 4953.9681441783905, "_timestamp": 1585574869.8127775, "_step": 227}
{"Episode reward": -96.28534336777231, "Episode length": 999, "Policy Loss": 0.004268258810043335, "Value Loss": 0.0002944155130535364, "_runtime": 4955.545828342438, "_timestamp": 1585574871.3904617, "_step": 228}
{"Episode reward": -98.23684853975678, "Episode length": 999, "Policy Loss": -0.004767984617501497, "Value Loss": 0.00013950686843600124, "_runtime": 4957.10652589798, "_timestamp": 1585574872.9511592, "_step": 229}
{"Episode reward": -98.06404194493014, "Episode length": 999, "Policy Loss": -0.0031118374317884445, "Value Loss": 0.00015224447997752577, "_runtime": 4958.6817898750305, "_timestamp": 1585574874.5264232, "_step": 230}
{"Episode reward": -98.68458736275255, "Episode length": 999, "Policy Loss": -0.006207348313182592, "Value Loss": 9.73245914792642e-05, "_runtime": 4960.248804330826, "_timestamp": 1585574876.0934377, "_step": 231}
{"Episode reward": -97.29404045326572, "Episode length": 999, "Policy Loss": 0.0005217519938014448, "Value Loss": 0.00020542096171993762, "_runtime": 4961.847714424133, "_timestamp": 1585574877.6923478, "_step": 232}
{"Episode reward": -95.23091636468821, "Episode length": 999, "Policy Loss": 0.01059073768556118, "Value Loss": 0.00036664423532783985, "_runtime": 4963.411100149155, "_timestamp": 1585574879.2557335, "_step": 233}
{"Episode reward": -97.26554394229177, "Episode length": 999, "Policy Loss": 6.372114148689434e-05, "Value Loss": 0.00018489875947125256, "_runtime": 4964.979825496674, "_timestamp": 1585574880.8244588, "_step": 234}
{"Episode reward": -95.49019986820494, "Episode length": 999, "Policy Loss": 0.00681984331458807, "Value Loss": 0.00032832982833497226, "_runtime": 4966.548515796661, "_timestamp": 1585574882.3931491, "_step": 235}
{"Episode reward": -96.04697389612288, "Episode length": 999, "Policy Loss": 0.004639878869056702, "Value Loss": 0.0003154475416522473, "_runtime": 4968.1154816150665, "_timestamp": 1585574883.960115, "_step": 236}
{"Episode reward": -98.1302464628714, "Episode length": 999, "Policy Loss": -0.004288827534765005, "Value Loss": 0.0001479627244407311, "_runtime": 4969.677001237869, "_timestamp": 1585574885.5216346, "_step": 237}
{"Episode reward": -98.46909651630537, "Episode length": 999, "Policy Loss": -0.005078223068267107, "Value Loss": 0.00011479174281703308, "_runtime": 4971.260177373886, "_timestamp": 1585574887.1048107, "_step": 238}
{"Episode reward": -97.8770284772543, "Episode length": 999, "Policy Loss": -0.002984641119837761, "Value Loss": 0.00014632413513027132, "_runtime": 4972.839435577393, "_timestamp": 1585574888.684069, "_step": 239}
{"Episode reward": -98.38083756519542, "Episode length": 999, "Policy Loss": -0.005585066508501768, "Value Loss": 0.0001357163127977401, "_runtime": 4974.432758808136, "_timestamp": 1585574890.2773921, "_step": 240}
{"Episode reward": -99.09951872886532, "Episode length": 999, "Policy Loss": -0.008028167299926281, "Value Loss": 6.916264101164415e-05, "_runtime": 4976.008140087128, "_timestamp": 1585574891.8527734, "_step": 241}
{"Episode reward": -96.536945332384, "Episode length": 999, "Policy Loss": 0.004722803831100464, "Value Loss": 0.00025552272563800216, "_runtime": 4977.593210697174, "_timestamp": 1585574893.437844, "_step": 242}
{"Episode reward": -98.08771585930855, "Episode length": 999, "Policy Loss": -0.0029409851413220167, "Value Loss": 0.00013952328299637884, "_runtime": 4979.1710913181305, "_timestamp": 1585574895.0157247, "_step": 243}
{"Episode reward": -95.32251210098484, "Episode length": 999, "Policy Loss": 0.0054320055060088634, "Value Loss": 0.00035916155320592225, "_runtime": 4980.748384714127, "_timestamp": 1585574896.593018, "_step": 244}
{"Episode reward": -98.12481961492956, "Episode length": 999, "Policy Loss": -0.0036681608762592077, "Value Loss": 0.00013954209862276912, "_runtime": 4982.322525501251, "_timestamp": 1585574898.1671588, "_step": 245}
{"Episode reward": -96.42994443571001, "Episode length": 999, "Policy Loss": 0.002902030711993575, "Value Loss": 0.0002867181901820004, "_runtime": 4983.897438526154, "_timestamp": 1585574899.7420719, "_step": 246}
{"Episode reward": -97.18579006895136, "Episode length": 999, "Policy Loss": 0.0027907162439078093, "Value Loss": 0.0001948729041032493, "_runtime": 4985.511813163757, "_timestamp": 1585574901.3564465, "_step": 247}
{"Episode reward": -95.18764583691348, "Episode length": 999, "Policy Loss": 0.008929334580898285, "Value Loss": 0.00036298137274570763, "_runtime": 4987.095005273819, "_timestamp": 1585574902.9396386, "_step": 248}
{"Episode reward": -97.28981171007551, "Episode length": 999, "Policy Loss": 0.0005052970955148339, "Value Loss": 0.00020170514471828938, "_runtime": 4988.681451320648, "_timestamp": 1585574904.5260847, "_step": 249}
{"Episode reward": -97.59374502545657, "Episode length": 999, "Policy Loss": -0.0012669434072449803, "Value Loss": 0.00015465264732483774, "_runtime": 4990.254396677017, "_timestamp": 1585574906.09903, "_step": 250}
{"Episode reward": -94.34318270179119, "Episode length": 999, "Policy Loss": 0.006628212984651327, "Value Loss": 0.0004218424728605896, "_runtime": 4991.829490184784, "_timestamp": 1585574907.6741235, "_step": 251}
{"Episode reward": -96.63170454310207, "Episode length": 999, "Policy Loss": 0.0033042242284864187, "Value Loss": 0.0002600603620521724, "_runtime": 4993.407802820206, "_timestamp": 1585574909.2524362, "_step": 252}
{"Episode reward": -96.10534271142326, "Episode length": 999, "Policy Loss": 0.004750915803015232, "Value Loss": 0.0002971299400087446, "_runtime": 4994.9948143959045, "_timestamp": 1585574910.8394477, "_step": 253}
{"Episode reward": -94.28000755866073, "Episode length": 999, "Policy Loss": 0.009386143647134304, "Value Loss": 0.0004350908857304603, "_runtime": 4996.570893526077, "_timestamp": 1585574912.4155269, "_step": 254}
{"Episode reward": -98.66562933567451, "Episode length": 999, "Policy Loss": -0.007071168627589941, "Value Loss": 9.695078915683553e-05, "_runtime": 4998.155220270157, "_timestamp": 1585574913.9998536, "_step": 255}
{"Episode reward": -93.96758173083785, "Episode length": 999, "Policy Loss": 0.008038809522986412, "Value Loss": 0.00046935060527175665, "_runtime": 4999.729084968567, "_timestamp": 1585574915.5737183, "_step": 256}
{"Episode reward": -96.01543614798607, "Episode length": 999, "Policy Loss": 0.00357445259578526, "Value Loss": 0.00030101349693723023, "_runtime": 5001.306552886963, "_timestamp": 1585574917.1511862, "_step": 257}
{"Episode reward": -97.58712623226474, "Episode length": 999, "Policy Loss": -0.002458747010678053, "Value Loss": 0.00017491616017650813, "_runtime": 5002.895236968994, "_timestamp": 1585574918.7398703, "_step": 258}
{"Episode reward": -94.43482461048966, "Episode length": 999, "Policy Loss": 0.0060069747269153595, "Value Loss": 0.00043340245611034334, "_runtime": 5004.479695558548, "_timestamp": 1585574920.324329, "_step": 259}
{"Episode reward": -98.12151906348254, "Episode length": 999, "Policy Loss": -0.005687356926500797, "Value Loss": 0.000132963148644194, "_runtime": 5006.06326842308, "_timestamp": 1585574921.9079018, "_step": 260}
{"Episode reward": -95.99744132386205, "Episode length": 999, "Policy Loss": 0.0030235834419727325, "Value Loss": 0.0002947225875686854, "_runtime": 5007.686884880066, "_timestamp": 1585574923.5315182, "_step": 261}
{"Episode reward": -95.97519199986257, "Episode length": 999, "Policy Loss": 0.001156496349722147, "Value Loss": 0.0003115491126663983, "_runtime": 5009.284044981003, "_timestamp": 1585574925.1286783, "_step": 262}
{"Episode reward": -98.64127648826314, "Episode length": 999, "Policy Loss": -0.00843766424804926, "Value Loss": 0.0001031772480928339, "_runtime": 5010.858761310577, "_timestamp": 1585574926.7033947, "_step": 263}
{"Episode reward": -97.8458014712514, "Episode length": 999, "Policy Loss": -0.004937997553497553, "Value Loss": 0.0001614938082639128, "_runtime": 5012.4368686676025, "_timestamp": 1585574928.281502, "_step": 264}
{"Episode reward": -99.03701949625186, "Episode length": 999, "Policy Loss": -0.010730759240686893, "Value Loss": 6.746272993041202e-05, "_runtime": 5014.019543647766, "_timestamp": 1585574929.864177, "_step": 265}
{"Episode reward": -97.80786696404101, "Episode length": 999, "Policy Loss": -0.0044716582633554935, "Value Loss": 0.00015797583910170943, "_runtime": 5015.606618881226, "_timestamp": 1585574931.4512522, "_step": 266}
{"Episode reward": -97.51318903983523, "Episode length": 999, "Policy Loss": -0.00326428166590631, "Value Loss": 0.0001891015563160181, "_runtime": 5017.195229768753, "_timestamp": 1585574933.039863, "_step": 267}
{"Episode reward": -98.11618489327209, "Episode length": 999, "Policy Loss": -0.00597449392080307, "Value Loss": 0.00014243405894376338, "_runtime": 5018.769182443619, "_timestamp": 1585574934.6138158, "_step": 268}
{"Episode reward": -95.63854950890152, "Episode length": 999, "Policy Loss": 0.005051733925938606, "Value Loss": 0.0003391639038454741, "_runtime": 5020.357584953308, "_timestamp": 1585574936.2022183, "_step": 269}
{"Episode reward": -97.54366849444335, "Episode length": 999, "Policy Loss": -0.0041283913888037205, "Value Loss": 0.00018787800217978656, "_runtime": 5021.932295799255, "_timestamp": 1585574937.7769291, "_step": 270}
{"Episode reward": -96.09102392386768, "Episode length": 999, "Policy Loss": 0.004331335891038179, "Value Loss": 0.00028850306989625096, "_runtime": 5023.495136260986, "_timestamp": 1585574939.3397696, "_step": 271}
{"Episode reward": -96.50196623353129, "Episode length": 999, "Policy Loss": 7.830046524759382e-05, "Value Loss": 0.0002642061735969037, "_runtime": 5025.068842411041, "_timestamp": 1585574940.9134758, "_step": 272}
{"Episode reward": -97.54744172911008, "Episode length": 999, "Policy Loss": -0.004151879344135523, "Value Loss": 0.00018987715884577483, "_runtime": 5026.660140991211, "_timestamp": 1585574942.5047743, "_step": 273}
{"Episode reward": -97.72608208879328, "Episode length": 999, "Policy Loss": -0.004350980278104544, "Value Loss": 0.0001618161186343059, "_runtime": 5028.236897945404, "_timestamp": 1585574944.0815313, "_step": 274}
{"Episode reward": -95.54757770375693, "Episode length": 999, "Policy Loss": 0.0041618263348937035, "Value Loss": 0.00034141953801736236, "_runtime": 5029.823384046555, "_timestamp": 1585574945.6680174, "_step": 275}
{"Episode reward": -98.77166258021848, "Episode length": 999, "Policy Loss": -0.008893268182873726, "Value Loss": 9.234503522748128e-05, "_runtime": 5031.436174154282, "_timestamp": 1585574947.2808075, "_step": 276}
{"Episode reward": -94.22048200152437, "Episode length": 999, "Policy Loss": 0.004978860262781382, "Value Loss": 0.00045556743862107396, "_runtime": 5033.010063171387, "_timestamp": 1585574948.8546965, "_step": 277}
{"Episode reward": -97.42161280029919, "Episode length": 999, "Policy Loss": -0.0014309914549812675, "Value Loss": 0.00018857441318687052, "_runtime": 5034.599174499512, "_timestamp": 1585574950.4438078, "_step": 278}
{"Episode reward": -95.50213306088645, "Episode length": 999, "Policy Loss": 0.0001387998927384615, "Value Loss": 0.0003305428836029023, "_runtime": 5036.172885417938, "_timestamp": 1585574952.0175188, "_step": 279}
{"Episode reward": -94.92784270426752, "Episode length": 999, "Policy Loss": 0.008960793726146221, "Value Loss": 0.0003930552047677338, "_runtime": 5037.74956536293, "_timestamp": 1585574953.5941987, "_step": 280}
{"Episode reward": -98.18362545594293, "Episode length": 999, "Policy Loss": -0.006424079183489084, "Value Loss": 0.00013867582310922444, "_runtime": 5039.328065872192, "_timestamp": 1585574955.1726992, "_step": 281}
{"Episode reward": -96.34263753590116, "Episode length": 999, "Policy Loss": 0.0015138216549530625, "Value Loss": 0.00026790236006490886, "_runtime": 5040.900807857513, "_timestamp": 1585574956.7454412, "_step": 282}
{"Episode reward": -97.45216951860218, "Episode length": 999, "Policy Loss": -0.00419290317222476, "Value Loss": 0.00019410754612181336, "_runtime": 5042.478186130524, "_timestamp": 1585574958.3228195, "_step": 283}
{"Episode reward": -98.3404661783066, "Episode length": 999, "Policy Loss": -0.007627617567777634, "Value Loss": 0.00013739689893554896, "_runtime": 5044.064395666122, "_timestamp": 1585574959.909029, "_step": 284}
{"Episode reward": -98.3113384535927, "Episode length": 999, "Policy Loss": -0.007437155116349459, "Value Loss": 0.0001330803061136976, "_runtime": 5045.636572360992, "_timestamp": 1585574961.4812057, "_step": 285}
{"Episode reward": -96.47635390197202, "Episode length": 999, "Policy Loss": 0.0018255969043821096, "Value Loss": 0.0002430053718853742, "_runtime": 5047.220060825348, "_timestamp": 1585574963.0646942, "_step": 286}
{"Episode reward": -97.6167727594691, "Episode length": 999, "Policy Loss": -0.003603460732847452, "Value Loss": 0.00017933080380316824, "_runtime": 5048.793808698654, "_timestamp": 1585574964.638442, "_step": 287}
{"Episode reward": -97.98594650739346, "Episode length": 999, "Policy Loss": -0.005251704715192318, "Value Loss": 0.00016305652388837188, "_runtime": 5050.355870723724, "_timestamp": 1585574966.200504, "_step": 288}
{"Episode reward": -98.37650616976237, "Episode length": 999, "Policy Loss": -0.0065916553139686584, "Value Loss": 0.000121898359793704, "_runtime": 5051.940925359726, "_timestamp": 1585574967.7855587, "_step": 289}
{"Episode reward": -98.53875862026895, "Episode length": 999, "Policy Loss": -0.007838291116058826, "Value Loss": 0.00011573686788324267, "_runtime": 5053.526990652084, "_timestamp": 1585574969.371624, "_step": 290}
{"Episode reward": -96.8454359642945, "Episode length": 999, "Policy Loss": 0.0013358599971979856, "Value Loss": 0.00024699390633031726, "_runtime": 5055.146490812302, "_timestamp": 1585574970.9911242, "_step": 291}
{"Episode reward": -98.15723720647777, "Episode length": 999, "Policy Loss": -0.005319321062415838, "Value Loss": 0.00012872737715952098, "_runtime": 5056.723340272903, "_timestamp": 1585574972.5679736, "_step": 292}
{"Episode reward": -98.62096818213817, "Episode length": 999, "Policy Loss": -0.007598293479532003, "Value Loss": 0.00010022636706707999, "_runtime": 5058.2990074157715, "_timestamp": 1585574974.1436408, "_step": 293}
{"Episode reward": -97.48904666049863, "Episode length": 999, "Policy Loss": -0.000771176244597882, "Value Loss": 0.00017953771748580039, "_runtime": 5059.889905929565, "_timestamp": 1585574975.7345393, "_step": 294}
{"Episode reward": -98.69132388430124, "Episode length": 999, "Policy Loss": -0.006772380787879229, "Value Loss": 8.862429240252823e-05, "_runtime": 5061.474719047546, "_timestamp": 1585574977.3193524, "_step": 295}
{"Episode reward": -97.25706484220021, "Episode length": 999, "Policy Loss": -0.0010939848143607378, "Value Loss": 0.0002063530555460602, "_runtime": 5063.057857036591, "_timestamp": 1585574978.9024904, "_step": 296}
{"Episode reward": -96.33335931362832, "Episode length": 999, "Policy Loss": 0.0030914561357349157, "Value Loss": 0.00026577457902021706, "_runtime": 5064.635773181915, "_timestamp": 1585574980.4804065, "_step": 297}
{"Episode reward": -98.49493618163785, "Episode length": 999, "Policy Loss": -0.006464481353759766, "Value Loss": 0.00011715832079062238, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252, -0.004365673754364252]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.9868449568748474, -0.971219003200531, -0.9555931091308594, -0.939967155456543, -0.9243412017822266, -0.9087152481079102, -0.8930893540382385, -0.8774634003639221, -0.8618375062942505, -0.8462115526199341, -0.8305855989456177, -0.8149596452713013, -0.7993337512016296, -0.7837077975273132, -0.7680819034576416, -0.7524559497833252, -0.7368299961090088, -0.7212040424346924, -0.705578088760376, -0.6899521946907043, -0.6743262410163879, -0.6587003469467163, -0.6430743932723999, -0.6274484395980835, -0.6118224859237671, -0.5961965918540955, -0.580570638179779, -0.5649447441101074, -0.549318790435791, -0.5336928367614746, -0.5180668830871582, -0.5024409294128418, -0.48681503534317017, -0.47118908166885376, -0.45556318759918213, -0.4399372339248657, -0.4243112802505493, -0.4086853861808777, -0.3930594325065613, -0.3774334788322449, -0.36180752515792847, -0.34618163108825684, -0.33055567741394043, -0.314929723739624, -0.2993038296699524, -0.283677875995636, -0.2680519223213196, -0.25242602825164795, -0.23680007457733154, -0.22117412090301514, -0.2055482268333435, -0.1899222731590271, -0.1742963194847107, -0.15867042541503906, -0.14304447174072266, -0.12741851806640625, -0.11179262399673462, -0.09616667032241821, -0.0805407166481018, -0.0649147629737854, -0.04928886890411377, -0.03366291522979736, -0.018036961555480957, -0.002411067485809326, 0.01321488618850708]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 5.0], "bins": [-0.03698616102337837, -0.03639664873480797, -0.035807136446237564, -0.03521762415766716, -0.034628111869096756, -0.03403859958052635, -0.03344908356666565, -0.032859571278095245, -0.03227005898952484, -0.03168054670095444, -0.031091034412384033, -0.03050152212381363, -0.029912009835243225, -0.02932249754667282, -0.028732985258102417, -0.028143472969532013, -0.02755396068096161, -0.026964448392391205, -0.02637493424117565, -0.025785421952605247, -0.025195909664034843, -0.02460639551281929, -0.024016883224248886, -0.023427370935678482, -0.022837858647108078, -0.022248346358537674, -0.02165883406996727, -0.021069321781396866, -0.020479809492826462, -0.01989029534161091, -0.019300783053040504, -0.0187112707644701, -0.018121758475899696, -0.017532246187329292, -0.016942733898758888, -0.016353221610188484, -0.01576370745897293, -0.015174195170402527, -0.014584682881832123, -0.013995170593261719, -0.013405658304691315, -0.01281614601612091, -0.012226631864905357, -0.011637119576334953, -0.01104760728776455, -0.010458094999194145, -0.009868582710623741, -0.009279070422053337, -0.008689556270837784, -0.00810004398226738, -0.007510531693696976, -0.006921019405126572, -0.006331507116556168, -0.0057419948279857635, -0.0051524825394153595, -0.0045629702508449554, -0.003973457962274551, -0.0033839456737041473, -0.002794429659843445, -0.0022049173712730408, -0.0016154050827026367, -0.0010258927941322327, -0.0004363805055618286, 0.00015313178300857544, 0.0007426440715789795]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 4.0, 5.0, 6.0, 4.0, 7.0, 7.0, 3.0, 280.0, 15.0, 7.0, 4.0, 6.0, 11.0, 4.0, 5.0, 10.0, 5.0, 2.0, 3.0, 2.0, 6.0, 4.0, 5.0, 5.0, 5.0, 2.0, 8.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.055095236748456955, -0.0535864531993866, -0.05207766965031624, -0.05056888237595558, -0.04906009882688522, -0.047551315277814865, -0.04604253172874451, -0.04453374445438385, -0.04302496090531349, -0.041516177356243134, -0.040007393807172775, -0.03849861025810242, -0.03698982298374176, -0.0354810394346714, -0.033972255885601044, -0.03246346861124039, -0.030954686924815178, -0.02944590337574482, -0.027937117964029312, -0.026428334414958954, -0.024919549003243446, -0.02341076359152794, -0.02190198004245758, -0.020393196493387222, -0.018884412944316864, -0.017375629395246506, -0.01586684212088585, -0.01435805857181549, -0.012849275022745132, -0.011340491473674774, -0.009831704199314117, -0.00832292065024376, -0.006814137101173401, -0.005305353552103043, -0.0037965700030326843, -0.0022877827286720276, -0.0007789991796016693, 0.000729784369468689, 0.0022385679185390472, 0.003747355192899704, 0.005256138741970062, 0.0067649222910404205, 0.008273709565401077, 0.009782489389181137, 0.011291276663541794, 0.012800056487321854, 0.01430884376168251, 0.015817631036043167, 0.017326410859823227, 0.018835198134183884, 0.020343977957963943, 0.0218527652323246, 0.023361552506685257, 0.024870332330465317, 0.026379119604825974, 0.02788790687918663, 0.02939668670296669, 0.030905473977327347, 0.03241425380110741, 0.03392304107546806, 0.03543182834982872, 0.03694060817360878, 0.03844939544796944, 0.039958175271749496, 0.04146696254611015]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08902951329946518, -0.08658647537231445, -0.08414344489574432, -0.0817004069685936, -0.07925737649202347, -0.07681433856487274, -0.07437130808830261, -0.07192827016115189, -0.06948523223400116, -0.06704220175743103, -0.0645991712808609, -0.062156133353710175, -0.05971309542655945, -0.05727006122469902, -0.05482702702283859, -0.052383992820978165, -0.04994095861911774, -0.04749792441725731, -0.04505489021539688, -0.04261185601353645, -0.040168821811676025, -0.0377257838845253, -0.03528274968266487, -0.03283971548080444, -0.030396681278944016, -0.027953647077083588, -0.02551060914993286, -0.023067578673362732, -0.020624540746212006, -0.018181510269641876, -0.01573847234249115, -0.01329544186592102, -0.010852403938770294, -0.008409366011619568, -0.0059663355350494385, -0.003523297607898712, -0.0010802671313285828, 0.0013627707958221436, 0.003805801272392273, 0.006248839199542999, 0.008691869676113129, 0.011134907603263855, 0.013577945530414581, 0.01602097600698471, 0.018464013934135437, 0.020907044410705566, 0.023350082337856293, 0.025793112814426422, 0.02823615074157715, 0.030679188668727875, 0.033122219145298004, 0.03556525707244873, 0.03800829499959946, 0.040451325476169586, 0.042894355952739716, 0.045337386429309845, 0.04778043180704117, 0.0502234622836113, 0.05266649276018143, 0.05510953813791275, 0.05755256861448288, 0.05999559909105301, 0.06243862956762314, 0.06488167494535446, 0.06732470542192459]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.08230903744697571, -0.0794159322977066, -0.0765228345990181, -0.07362972944974899, -0.07073663175106049, -0.06784352660179138, -0.06495042145252228, -0.06205732375383377, -0.059164222329854965, -0.05627112090587616, -0.053378019481897354, -0.05048491805791855, -0.047591812908649445, -0.04469871148467064, -0.041805610060691833, -0.03891250863671303, -0.03601940721273422, -0.03312630578875542, -0.03023320436477661, -0.027340102940797806, -0.024447001516819, -0.021553896367549896, -0.01866079866886139, -0.015767693519592285, -0.012874588370323181, -0.009981490671634674, -0.00708838552236557, -0.004195287823677063, -0.001302182674407959, 0.001590915024280548, 0.004484020173549652, 0.007377117872238159, 0.010270223021507263, 0.013163328170776367, 0.016056425869464874, 0.01894953101873398, 0.021842628717422485, 0.02473573386669159, 0.027628831565380096, 0.0305219367146492, 0.03341503441333771, 0.03630813956260681, 0.039201244711875916, 0.04209434241056442, 0.04498744010925293, 0.047880545258522034, 0.05077365040779114, 0.05366675555706024, 0.056559860706329346, 0.059452950954437256, 0.06234605610370636, 0.06523916125297546, 0.06813226640224457, 0.07102535665035248, 0.07391846179962158, 0.07681156694889069, 0.07970467209815979, 0.0825977772474289, 0.0854908674955368, 0.08838397264480591, 0.09127707779407501, 0.09417018294334412, 0.09706327319145203, 0.09995637834072113, 0.10284948348999023]}, "_runtime": 5066.218377113342, "_timestamp": 1585574982.0630105, "_step": 298}
{"Episode reward": -94.56593277056885, "Episode length": 999, "Policy Loss": 0.011570570059120655, "Value Loss": 0.0004064149979967624, "_runtime": 5067.80925989151, "_timestamp": 1585574983.6538932, "_step": 299}
{"Episode reward": -94.78646695905253, "Episode length": 999, "Policy Loss": 0.010305451229214668, "Value Loss": 0.00039234774885699153, "_runtime": 5069.400235176086, "_timestamp": 1585574985.2448685, "_step": 300}
{"Episode reward": -97.63957607150161, "Episode length": 999, "Policy Loss": -0.0034672070760279894, "Value Loss": 0.0001741044980008155, "_runtime": 5070.981649875641, "_timestamp": 1585574986.8262832, "_step": 301}
{"Episode reward": -95.032127243378, "Episode length": 999, "Policy Loss": 0.01127669122070074, "Value Loss": 0.0003518551238812506, "_runtime": 5072.566486120224, "_timestamp": 1585574988.4111195, "_step": 302}
{"Episode reward": -96.66706790722137, "Episode length": 999, "Policy Loss": 0.0005079396651126444, "Value Loss": 0.0002561259316280484, "_runtime": 5074.152766704559, "_timestamp": 1585574989.9974, "_step": 303}
{"Episode reward": -98.64894085948949, "Episode length": 999, "Policy Loss": -0.006565212272107601, "Value Loss": 9.623560617910698e-05, "_runtime": 5075.73219037056, "_timestamp": 1585574991.5768237, "_step": 304}
{"Episode reward": -98.73777110051826, "Episode length": 999, "Policy Loss": -0.007223145104944706, "Value Loss": 9.815965313464403e-05, "_runtime": 5077.308006763458, "_timestamp": 1585574993.15264, "_step": 305}
{"Episode reward": -97.78065066359484, "Episode length": 999, "Policy Loss": -0.004519074223935604, "Value Loss": 0.00017221998132299632, "_runtime": 5078.921273231506, "_timestamp": 1585574994.7659066, "_step": 306}
{"Episode reward": -96.64791574240058, "Episode length": 999, "Policy Loss": 0.004391083028167486, "Value Loss": 0.0002508765901438892, "_runtime": 5080.495193243027, "_timestamp": 1585574996.3398266, "_step": 307}
{"Episode reward": -98.3000981485931, "Episode length": 999, "Policy Loss": -0.005044940393418074, "Value Loss": 0.0001252949150511995, "_runtime": 5082.0589010715485, "_timestamp": 1585574997.9035344, "_step": 308}
{"Episode reward": -98.36754308839716, "Episode length": 999, "Policy Loss": -0.004642815794795752, "Value Loss": 0.00011889683810295537, "_runtime": 5083.634481430054, "_timestamp": 1585574999.4791148, "_step": 309}
{"Episode reward": -98.62143131244687, "Episode length": 999, "Policy Loss": -0.006671087816357613, "Value Loss": 0.00010865970398299396, "_runtime": 5085.212420463562, "_timestamp": 1585575001.0570538, "_step": 310}
{"Episode reward": -97.43440977746575, "Episode length": 999, "Policy Loss": 0.00020483354455791414, "Value Loss": 0.00019261777924839407, "_runtime": 5086.786075353622, "_timestamp": 1585575002.6307087, "_step": 311}
{"Episode reward": -98.42243549631819, "Episode length": 999, "Policy Loss": -0.005105568096041679, "Value Loss": 0.0001067709454218857, "_runtime": 5088.372310638428, "_timestamp": 1585575004.216944, "_step": 312}
{"Episode reward": -98.53630127834461, "Episode length": 999, "Policy Loss": -0.006087903399020433, "Value Loss": 0.00011034414637833834, "_runtime": 5089.932949304581, "_timestamp": 1585575005.7775826, "_step": 313}
{"Episode reward": -97.09511003562584, "Episode length": 999, "Policy Loss": 0.00027538641006685793, "Value Loss": 0.0002086688909912482, "_runtime": 5091.5057282447815, "_timestamp": 1585575007.3503616, "_step": 314}
{"Episode reward": -97.25483670450214, "Episode length": 999, "Policy Loss": -0.000658785633277148, "Value Loss": 0.0002096974931191653, "_runtime": 5093.0777933597565, "_timestamp": 1585575008.9224267, "_step": 315}
{"Episode reward": -98.60477583461545, "Episode length": 999, "Policy Loss": -0.005550647620111704, "Value Loss": 0.00010438518802402541, "_runtime": 5094.655383825302, "_timestamp": 1585575010.5000172, "_step": 316}
{"Episode reward": -98.19362958828795, "Episode length": 999, "Policy Loss": -0.003271625842899084, "Value Loss": 0.00013055934687145054, "_runtime": 5096.227895021439, "_timestamp": 1585575012.0725284, "_step": 317}
{"Episode reward": -98.42952216875523, "Episode length": 999, "Policy Loss": -0.004826490767300129, "Value Loss": 0.00010779606964206323, "_runtime": 5097.803900003433, "_timestamp": 1585575013.6485333, "_step": 318}
{"Episode reward": -98.66818572519136, "Episode length": 999, "Policy Loss": -0.004685748368501663, "Value Loss": 9.346417209599167e-05, "_runtime": 5099.385761260986, "_timestamp": 1585575015.2303946, "_step": 319}
{"Episode reward": -98.21610844510423, "Episode length": 999, "Policy Loss": -0.0024248315021395683, "Value Loss": 0.00013581689563579857, "_runtime": 5100.990796804428, "_timestamp": 1585575016.8354301, "_step": 320}
{"Episode reward": -97.58711831457444, "Episode length": 999, "Policy Loss": 0.00016714879893697798, "Value Loss": 0.0001796082651708275, "_runtime": 5102.566609859467, "_timestamp": 1585575018.4112432, "_step": 321}
{"Episode reward": -98.55343539942888, "Episode length": 999, "Policy Loss": -0.0036919000558555126, "Value Loss": 0.00012103874905733392, "_runtime": 5104.135578870773, "_timestamp": 1585575019.9802122, "_step": 322}
{"Episode reward": -97.28333288100687, "Episode length": 999, "Policy Loss": 0.0031169794965535402, "Value Loss": 0.00021590248798020184, "_runtime": 5105.712871313095, "_timestamp": 1585575021.5575047, "_step": 323}
{"Episode reward": -94.75207626761662, "Episode length": 999, "Policy Loss": 0.011740981601178646, "Value Loss": 0.000394722301280126, "_runtime": 5107.288533449173, "_timestamp": 1585575023.1331668, "_step": 324}
{"Episode reward": -97.9698968459115, "Episode length": 999, "Policy Loss": -0.0012932757381349802, "Value Loss": 0.00014499602548312396, "_runtime": 5108.8709416389465, "_timestamp": 1585575024.715575, "_step": 325}
{"Episode reward": -98.2483519311946, "Episode length": 999, "Policy Loss": -0.0027813406195491552, "Value Loss": 0.00012626993702724576, "_runtime": 5110.461587667465, "_timestamp": 1585575026.306221, "_step": 326}
{"Episode reward": -97.88766960738002, "Episode length": 999, "Policy Loss": -0.0019696198869496584, "Value Loss": 0.0001688429620116949, "_runtime": 5112.03905081749, "_timestamp": 1585575027.8836842, "_step": 327}
{"Episode reward": -97.6762580902169, "Episode length": 999, "Policy Loss": 4.901265128864907e-05, "Value Loss": 0.00016858663002494723, "_runtime": 5113.619584083557, "_timestamp": 1585575029.4642174, "_step": 328}
{"Episode reward": -97.95046651890246, "Episode length": 999, "Policy Loss": -0.0017008200520649552, "Value Loss": 0.00014564392040483654, "_runtime": 5115.198726654053, "_timestamp": 1585575031.04336, "_step": 329}
{"Episode reward": -96.77335184550836, "Episode length": 999, "Policy Loss": 0.00506910216063261, "Value Loss": 0.00024366701836697757, "_runtime": 5116.764981508255, "_timestamp": 1585575032.6096148, "_step": 330}
{"Episode reward": -97.98292422365546, "Episode length": 999, "Policy Loss": -0.0007025084923952818, "Value Loss": 0.00014601835573557764, "_runtime": 5118.335361003876, "_timestamp": 1585575034.1799943, "_step": 331}
{"Episode reward": -95.6679782114278, "Episode length": 999, "Policy Loss": 0.012403427623212337, "Value Loss": 0.00032909514266066253, "_runtime": 5119.907534837723, "_timestamp": 1585575035.7521682, "_step": 332}
{"Episode reward": -98.14290016661619, "Episode length": 999, "Policy Loss": -0.0018021960277110338, "Value Loss": 0.00014316099986899644, "_runtime": 5121.47523355484, "_timestamp": 1585575037.319867, "_step": 333}
{"Episode reward": -96.07856816406547, "Episode length": 999, "Policy Loss": 0.005895712878555059, "Value Loss": 0.0003001144214067608, "_runtime": 5123.042090654373, "_timestamp": 1585575038.886724, "_step": 334}
{"Episode reward": -95.4751992143518, "Episode length": 999, "Policy Loss": 0.008718594908714294, "Value Loss": 0.0003358576213940978, "_runtime": 5124.646840572357, "_timestamp": 1585575040.491474, "_step": 335}
{"Episode reward": -99.01965790271953, "Episode length": 999, "Policy Loss": -0.006647702772170305, "Value Loss": 6.875779217807576e-05, "_runtime": 5126.216338396072, "_timestamp": 1585575042.0609717, "_step": 336}
{"Episode reward": -97.77507947801278, "Episode length": 999, "Policy Loss": -0.0024223828222602606, "Value Loss": 0.0001679683045949787, "_runtime": 5127.797068119049, "_timestamp": 1585575043.6417015, "_step": 337}
{"Episode reward": -98.65962620343974, "Episode length": 999, "Policy Loss": -0.004940357990562916, "Value Loss": 9.83817080850713e-05, "_runtime": 5129.365004777908, "_timestamp": 1585575045.209638, "_step": 338}
{"Episode reward": -97.07477635236856, "Episode length": 999, "Policy Loss": 0.0022928842809051275, "Value Loss": 0.0002199505688622594, "_runtime": 5130.919812202454, "_timestamp": 1585575046.7644455, "_step": 339}
{"Episode reward": -97.61212206677962, "Episode length": 999, "Policy Loss": -0.0004905576934106648, "Value Loss": 0.0001790790556697175, "_runtime": 5132.494112730026, "_timestamp": 1585575048.338746, "_step": 340}
{"Episode reward": -98.76990352904208, "Episode length": 999, "Policy Loss": -0.004936699755489826, "Value Loss": 8.874646300682798e-05, "_runtime": 5134.060287952423, "_timestamp": 1585575049.9049213, "_step": 341}
{"Episode reward": -97.50607710747143, "Episode length": 999, "Policy Loss": 0.0009362765704281628, "Value Loss": 0.00018937700951937586, "_runtime": 5135.640727996826, "_timestamp": 1585575051.4853613, "_step": 342}
{"Episode reward": -98.2371922374401, "Episode length": 999, "Policy Loss": -0.001732576871290803, "Value Loss": 0.00012120312021579593, "_runtime": 5137.209468841553, "_timestamp": 1585575053.0541022, "_step": 343}
{"Episode reward": -94.32950002662845, "Episode length": 999, "Policy Loss": 0.011363159865140915, "Value Loss": 0.0004491456493269652, "_runtime": 5138.774758577347, "_timestamp": 1585575054.619392, "_step": 344}
{"Episode reward": -98.10418029163726, "Episode length": 999, "Policy Loss": -0.0024033277295529842, "Value Loss": 0.00014212923997547477, "_runtime": 5140.341290950775, "_timestamp": 1585575056.1859243, "_step": 345}
{"Episode reward": -95.99192389069067, "Episode length": 999, "Policy Loss": 0.00588232884183526, "Value Loss": 0.0003079302841797471, "_runtime": 5141.915735006332, "_timestamp": 1585575057.7603683, "_step": 346}
{"Episode reward": -97.18128477085736, "Episode length": 999, "Policy Loss": 0.0007313340902328491, "Value Loss": 0.00021170536638237536, "_runtime": 5143.494659662247, "_timestamp": 1585575059.339293, "_step": 347}
{"Episode reward": -96.7859107766757, "Episode length": 999, "Policy Loss": 0.0033941520377993584, "Value Loss": 0.0002395289484411478, "_runtime": 5145.0620675086975, "_timestamp": 1585575060.9067008, "_step": 348}
{"Episode reward": -97.49731530561287, "Episode length": 999, "Policy Loss": -0.0005088091711513698, "Value Loss": 0.00020188016060274094, "_runtime": 5146.628184080124, "_timestamp": 1585575062.4728174, "_step": 349}
{"Episode reward": -97.04326379565497, "Episode length": 999, "Policy Loss": 0.002102435100823641, "Value Loss": 0.00023035118647385389, "_runtime": 5148.231105327606, "_timestamp": 1585575064.0757387, "_step": 350}
{"Episode reward": -97.2315194167222, "Episode length": 999, "Policy Loss": 0.0009483029716648161, "Value Loss": 0.00021443975856527686, "_runtime": 5149.800134897232, "_timestamp": 1585575065.6447682, "_step": 351}
{"Episode reward": -98.99300941064267, "Episode length": 999, "Policy Loss": -0.007109451107680798, "Value Loss": 7.248698238981888e-05, "_runtime": 5151.375241518021, "_timestamp": 1585575067.2198749, "_step": 352}
{"Episode reward": -96.7802368980822, "Episode length": 999, "Policy Loss": 0.0001263313606614247, "Value Loss": 0.00023802948999218643, "_runtime": 5152.959822654724, "_timestamp": 1585575068.804456, "_step": 353}
{"Episode reward": -98.54926243938894, "Episode length": 999, "Policy Loss": -0.00508385943248868, "Value Loss": 0.00010095797915710136, "_runtime": 5154.533074378967, "_timestamp": 1585575070.3777077, "_step": 354}
{"Episode reward": -98.7580208115796, "Episode length": 999, "Policy Loss": -0.0063180578872561455, "Value Loss": 9.004831372294575e-05, "_runtime": 5156.1093072891235, "_timestamp": 1585575071.9539406, "_step": 355}
{"Episode reward": -98.23797628117536, "Episode length": 999, "Policy Loss": -0.003983479458838701, "Value Loss": 0.000128326631966047, "_runtime": 5157.689568281174, "_timestamp": 1585575073.5342016, "_step": 356}
{"Episode reward": -95.20222602019139, "Episode length": 999, "Policy Loss": 0.011216011829674244, "Value Loss": 0.0003814932715613395, "_runtime": 5159.259895801544, "_timestamp": 1585575075.1045291, "_step": 357}
{"Episode reward": -96.72049912611172, "Episode length": 999, "Policy Loss": 0.0027948275674134493, "Value Loss": 0.00023798814800102264, "_runtime": 5160.828236341476, "_timestamp": 1585575076.6728697, "_step": 358}
{"Episode reward": -97.95973294829491, "Episode length": 999, "Policy Loss": -0.0030148259829729795, "Value Loss": 0.00015775643987581134, "_runtime": 5162.396372079849, "_timestamp": 1585575078.2410054, "_step": 359}
{"Episode reward": -97.71759623015416, "Episode length": 999, "Policy Loss": -0.002295555081218481, "Value Loss": 0.00016993636381812394, "_runtime": 5163.959933996201, "_timestamp": 1585575079.8045673, "_step": 360}
{"Episode reward": -98.01275062570322, "Episode length": 999, "Policy Loss": -0.0034221643581986427, "Value Loss": 0.00015516382700297982, "_runtime": 5165.539595127106, "_timestamp": 1585575081.3842285, "_step": 361}
{"Episode reward": -98.8678314344862, "Episode length": 999, "Policy Loss": -0.007487232331186533, "Value Loss": 8.046401489991695e-05, "_runtime": 5167.1060745716095, "_timestamp": 1585575082.950708, "_step": 362}
{"Episode reward": -98.52023287351139, "Episode length": 999, "Policy Loss": -0.005533050280064344, "Value Loss": 0.00010774294059956446, "_runtime": 5168.676931142807, "_timestamp": 1585575084.5215645, "_step": 363}
{"Episode reward": -98.87544482316754, "Episode length": 999, "Policy Loss": -0.00748548936098814, "Value Loss": 7.891974382800981e-05, "_runtime": 5170.245765924454, "_timestamp": 1585575086.0903993, "_step": 364}
{"Episode reward": -98.01638048797588, "Episode length": 999, "Policy Loss": -0.0028580601792782545, "Value Loss": 0.00015954916307237, "_runtime": 5171.850932836533, "_timestamp": 1585575087.6955662, "_step": 365}
{"Episode reward": -95.61099990438753, "Episode length": 999, "Policy Loss": 0.009663598611950874, "Value Loss": 0.000344887055689469, "_runtime": 5173.4240119457245, "_timestamp": 1585575089.2686453, "_step": 366}
{"Episode reward": -97.70235994760904, "Episode length": 999, "Policy Loss": -0.00012798943498637527, "Value Loss": 0.00017393102461937815, "_runtime": 5174.993253707886, "_timestamp": 1585575090.837887, "_step": 367}
{"Episode reward": -98.2704947443609, "Episode length": 999, "Policy Loss": -0.003946033772081137, "Value Loss": 0.00014365075912792236, "_runtime": 5176.560535907745, "_timestamp": 1585575092.4051692, "_step": 368}
{"Episode reward": -98.35241973807081, "Episode length": 999, "Policy Loss": -0.004259558394551277, "Value Loss": 0.00012688116112258285, "_runtime": 5178.1192100048065, "_timestamp": 1585575093.9638433, "_step": 369}
{"Episode reward": -97.95652508208998, "Episode length": 999, "Policy Loss": -0.0015816972590982914, "Value Loss": 0.0001497613120591268, "_runtime": 5179.698353767395, "_timestamp": 1585575095.542987, "_step": 370}
{"Episode reward": -98.61602118848326, "Episode length": 999, "Policy Loss": -0.005099187139421701, "Value Loss": 9.155659790849313e-05, "_runtime": 5181.264712095261, "_timestamp": 1585575097.1093454, "_step": 371}
{"Episode reward": -98.06107797891443, "Episode length": 999, "Policy Loss": -0.0024029891937971115, "Value Loss": 0.00014969227777328342, "_runtime": 5182.834164142609, "_timestamp": 1585575098.6787975, "_step": 372}
{"Episode reward": -99.09673583003905, "Episode length": 999, "Policy Loss": -0.006886701099574566, "Value Loss": 6.410839705495164e-05, "_runtime": 5184.413195848465, "_timestamp": 1585575100.2578292, "_step": 373}
{"Episode reward": -96.69870580032217, "Episode length": 999, "Policy Loss": 0.0035304068587720394, "Value Loss": 0.0002515250234864652, "_runtime": 5185.977711439133, "_timestamp": 1585575101.8223448, "_step": 374}
{"Episode reward": -92.86788277513159, "Episode length": 999, "Policy Loss": 0.012610512785613537, "Value Loss": 0.0005596686969511211, "_runtime": 5187.536306858063, "_timestamp": 1585575103.3809402, "_step": 375}
{"Episode reward": -96.33809549270921, "Episode length": 999, "Policy Loss": 0.005029707215726376, "Value Loss": 0.0002686898224055767, "_runtime": 5189.093452453613, "_timestamp": 1585575104.9380858, "_step": 376}
{"Episode reward": -96.67676186575878, "Episode length": 999, "Policy Loss": 0.004378538578748703, "Value Loss": 0.0002490369661245495, "_runtime": 5190.669899463654, "_timestamp": 1585575106.5145328, "_step": 377}
{"Episode reward": -95.85445071404831, "Episode length": 999, "Policy Loss": 0.005363080184906721, "Value Loss": 0.0003075574350077659, "_runtime": 5192.2467613220215, "_timestamp": 1585575108.0913947, "_step": 378}
{"Episode reward": -98.99987714531137, "Episode length": 999, "Policy Loss": -0.006661423482000828, "Value Loss": 7.723961607553065e-05, "_runtime": 5193.823858499527, "_timestamp": 1585575109.6684918, "_step": 379}
{"Episode reward": -94.71447872654207, "Episode length": 999, "Policy Loss": 0.013887040317058563, "Value Loss": 0.000387226085877046, "_runtime": 5195.426296234131, "_timestamp": 1585575111.2709296, "_step": 380}
{"Episode reward": -95.44388076275726, "Episode length": 999, "Policy Loss": 0.007241318002343178, "Value Loss": 0.000353493494912982, "_runtime": 5196.995379447937, "_timestamp": 1585575112.8400128, "_step": 381}
{"Episode reward": -95.62316400990022, "Episode length": 999, "Policy Loss": 0.0064125568605959415, "Value Loss": 0.00031370314536616206, "_runtime": 5198.575641155243, "_timestamp": 1585575114.4202745, "_step": 382}
{"Episode reward": -95.23912027769437, "Episode length": 999, "Policy Loss": 0.006058166269212961, "Value Loss": 0.00034082779893651605, "_runtime": 5200.14319396019, "_timestamp": 1585575115.9878273, "_step": 383}
{"Episode reward": -97.02675134548814, "Episode length": 999, "Policy Loss": 0.00030048179905861616, "Value Loss": 0.0002204557094955817, "_runtime": 5201.711758613586, "_timestamp": 1585575117.556392, "_step": 384}
{"Episode reward": -97.70724666571232, "Episode length": 999, "Policy Loss": -0.0024005069863051176, "Value Loss": 0.0001715557591523975, "_runtime": 5203.278351068497, "_timestamp": 1585575119.1229844, "_step": 385}
{"Episode reward": -97.72912655851957, "Episode length": 999, "Policy Loss": -0.0031758120749145746, "Value Loss": 0.00018344164709560573, "_runtime": 5204.848042011261, "_timestamp": 1585575120.6926754, "_step": 386}
{"Episode reward": -97.39080987699835, "Episode length": 999, "Policy Loss": -0.0005474169156514108, "Value Loss": 0.0001889022096293047, "_runtime": 5206.418677568436, "_timestamp": 1585575122.263311, "_step": 387}
{"Episode reward": -98.70516756071788, "Episode length": 999, "Policy Loss": -0.007061381358653307, "Value Loss": 9.765435243025422e-05, "_runtime": 5207.990235328674, "_timestamp": 1585575123.8348687, "_step": 388}
{"Episode reward": -98.0800513801188, "Episode length": 999, "Policy Loss": -0.004069938790053129, "Value Loss": 0.00015629411791451275, "_runtime": 5209.559374570847, "_timestamp": 1585575125.404008, "_step": 389}
{"Episode reward": -97.81243187588959, "Episode length": 999, "Policy Loss": -0.0018629382830113173, "Value Loss": 0.00016240766854025424, "_runtime": 5211.130568981171, "_timestamp": 1585575126.9752023, "_step": 390}
{"Episode reward": -98.6262568642532, "Episode length": 999, "Policy Loss": -0.006285383366048336, "Value Loss": 0.00010960512008750811, "_runtime": 5212.7005207538605, "_timestamp": 1585575128.545154, "_step": 391}
{"Episode reward": -95.23242541040436, "Episode length": 999, "Policy Loss": 0.007733128499239683, "Value Loss": 0.0003601725329644978, "_runtime": 5214.279004812241, "_timestamp": 1585575130.1236382, "_step": 392}
{"Episode reward": -98.1684449031434, "Episode length": 999, "Policy Loss": -0.005274983588606119, "Value Loss": 0.00013615062925964594, "_runtime": 5215.861382007599, "_timestamp": 1585575131.7060153, "_step": 393}
{"Episode reward": -98.21242788561227, "Episode length": 999, "Policy Loss": -0.00520821800455451, "Value Loss": 0.00014601896691601723, "_runtime": 5217.4749076366425, "_timestamp": 1585575133.319541, "_step": 394}
{"Episode reward": -98.40007304864297, "Episode length": 999, "Policy Loss": -0.006220696028321981, "Value Loss": 0.0001204792206408456, "_runtime": 5219.053541898727, "_timestamp": 1585575134.8981752, "_step": 395}
{"Episode reward": -98.08886388444233, "Episode length": 999, "Policy Loss": -0.005161545239388943, "Value Loss": 0.0001466741960030049, "_runtime": 5220.620690107346, "_timestamp": 1585575136.4653234, "_step": 396}
{"Episode reward": -95.51673346687681, "Episode length": 999, "Policy Loss": 0.005875694565474987, "Value Loss": 0.00034466839861124754, "_runtime": 5222.200313806534, "_timestamp": 1585575138.0449471, "_step": 397}
{"Episode reward": -98.03695217964362, "Episode length": 999, "Policy Loss": -0.005395509302616119, "Value Loss": 0.0001534660259494558, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495, 0.056395042687654495]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0], "bins": [-0.05638934299349785, -0.0477137565612793, -0.03903816640377045, -0.030362578108906746, -0.021686989814043045, -0.013011399656534195, -0.004335813224315643, 0.004339773207902908, 0.013015363365411758, 0.02169095352292061, 0.03036654368042946, 0.03904212638735771, 0.04771771654486656, 0.05639330670237541, 0.06506888568401337, 0.07374447584152222, 0.08242006599903107, 0.09109565615653992, 0.09977124631404877, 0.10844683647155762, 0.11712242662906647, 0.12579800188541412, 0.13447359204292297, 0.14314918220043182, 0.15182477235794067, 0.16050036251544952, 0.16917595267295837, 0.17785154283046722, 0.18652711808681488, 0.19520272314548492, 0.20387829840183258, 0.21255390346050262, 0.22122947871685028, 0.22990505397319794, 0.23858065903186798, 0.24725623428821564, 0.2559318542480469, 0.26460742950439453, 0.2732830345630646, 0.28195860981941223, 0.2906342148780823, 0.29930979013442993, 0.3079853653907776, 0.31666097044944763, 0.3253365457057953, 0.33401215076446533, 0.342687726020813, 0.35136333107948303, 0.3600389063358307, 0.36871448159217834, 0.3773900866508484, 0.38606566190719604, 0.3947412669658661, 0.40341684222221375, 0.4120924472808838, 0.42076802253723145, 0.4294435977935791, 0.43811920285224915, 0.4467948079109192, 0.45547038316726685, 0.4641459584236145, 0.47282153367996216, 0.4814971685409546, 0.49017274379730225, 0.4988483190536499]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-7.506504857701657e-07, 0.0004109827568754554, 0.0008227161597460508, 0.0012344495626166463, 0.0016461829654872417, 0.002057916484773159, 0.0024696497712284327, 0.0028813830576837063, 0.0032931165769696236, 0.003704850096255541, 0.004116583615541458, 0.004528316669166088, 0.004940050188452005, 0.005351783707737923, 0.005763516761362553, 0.00617525028064847, 0.006586983799934387, 0.0069987173192203045, 0.007410450838506222, 0.007822183892130852, 0.008233917877078056, 0.008645650930702686, 0.009057383984327316, 0.009469117969274521, 0.00988085102289915, 0.01029258407652378, 0.010704318061470985, 0.011116051115095615, 0.011527784168720245, 0.01193951815366745, 0.01235125120729208, 0.012762985192239285, 0.013174718245863914, 0.013586451299488544, 0.013998185284435749, 0.014409918338060379, 0.014821652323007584, 0.015233385376632214, 0.015645118430256844, 0.016056852415204048, 0.016468586400151253, 0.016880318522453308, 0.017292052507400513, 0.017703786492347717, 0.018115518614649773, 0.018527252599596977, 0.018938986584544182, 0.019350718706846237, 0.019762452691793442, 0.020174186676740646, 0.0205859187990427, 0.020997652783989906, 0.02140938676893711, 0.021821118891239166, 0.02223285287618637, 0.022644586861133575, 0.02305631898343563, 0.023468052968382835, 0.02387978695333004, 0.024291520938277245, 0.0247032530605793, 0.025114987045526505, 0.02552672103047371, 0.025938453152775764, 0.02635018713772297]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 2.0, 4.0, 7.0, 4.0, 2.0, 7.0, 5.0, 2.0, 5.0, 4.0, 1.0, 8.0, 6.0, 3.0, 8.0, 13.0, 5.0, 12.0, 17.0, 260.0, 7.0, 9.0, 11.0, 8.0, 7.0, 6.0, 8.0, 4.0, 1.0, 1.0, 8.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 5.0, 1.0, 1.0, 5.0, 1.0, 0.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0], "bins": [-0.019212601706385612, -0.0184924453496933, -0.017772290855646133, -0.01705213449895382, -0.016331980004906654, -0.01561182364821434, -0.0148916682228446, -0.014171512797474861, -0.013451357372105122, -0.012731201946735382, -0.012011046521365643, -0.011290891095995903, -0.010570734739303589, -0.00985057931393385, -0.00913042388856411, -0.00841026846319437, -0.007690113037824631, -0.006969957612454891, -0.006249802187085152, -0.005529646761715412, -0.004809491336345673, -0.0040893349796533585, -0.0033691804856061935, -0.0026490241289138794, -0.0019288677722215652, -0.0012087132781744003, -0.0004885569214820862, 0.00023159757256507874, 0.0009517539292573929, 0.0016719084233045578, 0.002392064779996872, 0.003112219274044037, 0.003832375630736351, 0.004552531987428665, 0.00527268648147583, 0.005992842838168144, 0.006712997332215309, 0.007433153688907623, 0.008153308182954788, 0.008873464539647102, 0.009593619033694267, 0.010313775390386581, 0.011033931747078896, 0.01175408624112606, 0.012474240735173225, 0.013194398954510689, 0.013914553448557854, 0.014634707942605019, 0.015354866161942482, 0.016075020655989647, 0.016795175150036812, 0.017515329644083977, 0.01823548786342144, 0.018955642357468605, 0.01967579685151577, 0.020395951345562935, 0.021116109564900398, 0.021836264058947563, 0.022556418552994728, 0.02327657677233219, 0.023996731266379356, 0.02471688576042652, 0.025437040254473686, 0.02615719847381115, 0.026877352967858315]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0583060048520565, -0.05607716366648674, -0.053848326206207275, -0.05161948502063751, -0.04939064383506775, -0.047161806374788284, -0.04493296518921852, -0.042704127728939056, -0.04047528654336929, -0.03824644535779953, -0.036017607897520065, -0.0337887667119503, -0.03155992925167084, -0.029331088066101074, -0.02710224688053131, -0.024873409420251846, -0.022644568234682083, -0.02041572704911232, -0.018186889588832855, -0.015958048403263092, -0.013729210942983627, -0.011500369757413864, -0.009271528571844101, -0.007042691111564636, -0.004813849925994873, -0.00258500874042511, -0.00035617128014564514, 0.001872669905424118, 0.004101511090993881, 0.006330352276563644, 0.00855918601155281, 0.010788027197122574, 0.013016868382692337, 0.0152457095682621, 0.017474550753831863, 0.01970338448882103, 0.021932225674390793, 0.024161066859960556, 0.02638990804553032, 0.028618749231100082, 0.03084758296608925, 0.03307642415165901, 0.035305265337228775, 0.03753410652279854, 0.0397629477083683, 0.041991788893938065, 0.04422062262892723, 0.046449463814496994, 0.04867830500006676, 0.05090714618563652, 0.053135987371206284, 0.05536482110619545, 0.05759366229176521, 0.059822503477334976, 0.06205134466290474, 0.0642801821231842, 0.06650902330875397, 0.06873786449432373, 0.0709667056798935, 0.07319553196430206, 0.07542437314987183, 0.07765321433544159, 0.07988205552101135, 0.08211089670658112, 0.08433973789215088]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.014432180672883987, -0.013974972069263458, -0.013517762534320354, -0.013060553930699825, -0.012603345327079296, -0.012146135792136192, -0.011688927188515663, -0.011231718584895134, -0.01077450904995203, -0.010317300446331501, -0.009860090911388397, -0.009402882307767868, -0.008945673704147339, -0.00848846510052681, -0.008031255565583706, -0.007574046961963177, -0.00711683789268136, -0.006659628823399544, -0.006202420219779015, -0.005745210684835911, -0.005288002081215382, -0.0048307934775948524, -0.004373583942651749, -0.0039163753390312195, -0.0034591667354106903, -0.0030019572004675865, -0.0025447485968470573, -0.002087539993226528, -0.0016303304582834244, -0.0011731218546628952, -0.000715913251042366, -0.00025870371609926224, 0.00019850488752126694, 0.0006557134911417961, 0.0011129230260849, 0.001570131629705429, 0.0020273402333259583, 0.0024845488369464874, 0.002941759303212166, 0.003398967906832695, 0.003856176510453224, 0.004313385114073753, 0.0047705937176942825, 0.005227802321314812, 0.00568501278758049, 0.006142221391201019, 0.0065994299948215485, 0.007056638598442078, 0.007513847202062607, 0.007971055805683136, 0.008428266271948814, 0.008885474875569344, 0.009342683479189873, 0.009799892082810402, 0.010257100686430931, 0.01071430929005146, 0.011171519756317139, 0.011628728359937668, 0.012085936963558197, 0.012543145567178726, 0.013000354170799255, 0.013457562774419785, 0.013914773240685463, 0.014371981844305992, 0.014829190447926521]}, "_runtime": 5223.779346466064, "_timestamp": 1585575139.6239798, "_step": 398}
{"Episode reward": -98.71465948084872, "Episode length": 999, "Policy Loss": -0.007898248732089996, "Value Loss": 9.485359623795375e-05, "_runtime": 5225.356324195862, "_timestamp": 1585575141.2009575, "_step": 399}
{"Episode reward": -95.96354904742509, "Episode length": 999, "Policy Loss": 0.006994076073169708, "Value Loss": 0.0002978991251438856, "_runtime": 5226.937191724777, "_timestamp": 1585575142.781825, "_step": 400}
{"Episode reward": -98.71310834404522, "Episode length": 999, "Policy Loss": -0.007082473486661911, "Value Loss": 9.601880447007716e-05, "_runtime": 5228.515153646469, "_timestamp": 1585575144.359787, "_step": 401}
{"Episode reward": -99.06930883291291, "Episode length": 999, "Policy Loss": -0.008894052356481552, "Value Loss": 6.353170465445146e-05, "_runtime": 5230.095762968063, "_timestamp": 1585575145.9403963, "_step": 402}
{"Episode reward": -97.10602565162415, "Episode length": 999, "Policy Loss": 0.0017292127013206482, "Value Loss": 0.0002195872220909223, "_runtime": 5231.677410364151, "_timestamp": 1585575147.5220437, "_step": 403}
{"Episode reward": -95.56599785698499, "Episode length": 999, "Policy Loss": 0.01009613648056984, "Value Loss": 0.00034239559317938983, "_runtime": 5233.254841804504, "_timestamp": 1585575149.0994751, "_step": 404}
{"Episode reward": -98.61798453125841, "Episode length": 999, "Policy Loss": -0.0062968614511191845, "Value Loss": 0.00010952608135994524, "_runtime": 5234.832743167877, "_timestamp": 1585575150.6773765, "_step": 405}
{"Episode reward": -99.11352723649263, "Episode length": 999, "Policy Loss": -0.008727652952075005, "Value Loss": 7.005481893429533e-05, "_runtime": 5236.4118621349335, "_timestamp": 1585575152.2564955, "_step": 406}
{"Episode reward": -96.50664003832654, "Episode length": 999, "Policy Loss": 0.00226039532572031, "Value Loss": 0.0002696548472158611, "_runtime": 5237.99482011795, "_timestamp": 1585575153.8394535, "_step": 407}
{"Episode reward": -98.46906805819154, "Episode length": 999, "Policy Loss": -0.006825076881796122, "Value Loss": 0.0001540624798508361, "_runtime": 5239.578500509262, "_timestamp": 1585575155.4231339, "_step": 408}
{"Episode reward": -96.42565502455604, "Episode length": 999, "Policy Loss": 0.002166206482797861, "Value Loss": 0.00028209525044076145, "_runtime": 5241.198947668076, "_timestamp": 1585575157.043581, "_step": 409}
{"Episode reward": -97.90053165623091, "Episode length": 999, "Policy Loss": -0.002496202476322651, "Value Loss": 0.00017215921252500266, "_runtime": 5242.770844459534, "_timestamp": 1585575158.6154778, "_step": 410}
{"Episode reward": -95.41233924085007, "Episode length": 999, "Policy Loss": 0.011099358089268208, "Value Loss": 0.00036161503521725535, "_runtime": 5244.346992015839, "_timestamp": 1585575160.1916254, "_step": 411}
{"Episode reward": -94.33083156832545, "Episode length": 999, "Policy Loss": 0.016644421964883804, "Value Loss": 0.00047782063484191895, "_runtime": 5245.9235208034515, "_timestamp": 1585575161.7681541, "_step": 412}
{"Episode reward": -97.27477007058597, "Episode length": 999, "Policy Loss": 0.001634308136999607, "Value Loss": 0.0002124353195540607, "_runtime": 5247.495441198349, "_timestamp": 1585575163.3400745, "_step": 413}
{"Episode reward": -98.48616189073252, "Episode length": 999, "Policy Loss": -0.00497060501947999, "Value Loss": 0.00011562625149963424, "_runtime": 5249.067799329758, "_timestamp": 1585575164.9124327, "_step": 414}
{"Episode reward": -98.62308218923705, "Episode length": 999, "Policy Loss": -0.006694357376545668, "Value Loss": 0.00012058995343977585, "_runtime": 5250.633043050766, "_timestamp": 1585575166.4776764, "_step": 415}
{"Episode reward": -95.93188723238106, "Episode length": 999, "Policy Loss": 0.0033997935242950916, "Value Loss": 0.00032483870745636523, "_runtime": 5252.206008911133, "_timestamp": 1585575168.0506423, "_step": 416}
{"Episode reward": -97.53982121927973, "Episode length": 999, "Policy Loss": -0.0015040099387988448, "Value Loss": 0.00021260710491333157, "_runtime": 5253.776753664017, "_timestamp": 1585575169.621387, "_step": 417}
{"Episode reward": -99.01859097762909, "Episode length": 999, "Policy Loss": -0.008080163970589638, "Value Loss": 7.481861393898726e-05, "_runtime": 5255.35675406456, "_timestamp": 1585575171.2013874, "_step": 418}
{"Episode reward": -98.01296251985066, "Episode length": 999, "Policy Loss": -0.0037983632646501064, "Value Loss": 0.0001411897101206705, "_runtime": 5256.937089204788, "_timestamp": 1585575172.7817225, "_step": 419}
{"Episode reward": -96.97468083850742, "Episode length": 999, "Policy Loss": 0.0026570591144263744, "Value Loss": 0.0002211073151556775, "_runtime": 5258.5090918540955, "_timestamp": 1585575174.3537252, "_step": 420}
{"Episode reward": -98.85288722257923, "Episode length": 999, "Policy Loss": -0.0065841348841786385, "Value Loss": 7.043175719445571e-05, "_runtime": 5260.079420566559, "_timestamp": 1585575175.924054, "_step": 421}
{"Episode reward": -95.72791495192695, "Episode length": 999, "Policy Loss": 0.005072328262031078, "Value Loss": 0.0003380939888302237, "_runtime": 5261.647762060165, "_timestamp": 1585575177.4923954, "_step": 422}
{"Episode reward": -94.50283502471017, "Episode length": 999, "Policy Loss": 0.019640514627099037, "Value Loss": 0.00048256502486765385, "_runtime": 5263.212929487228, "_timestamp": 1585575179.0575628, "_step": 423}
{"Episode reward": -92.13999558508034, "Episode length": 999, "Policy Loss": 0.02281872183084488, "Value Loss": 0.0005850985762663186, "_runtime": 5264.816155433655, "_timestamp": 1585575180.6607888, "_step": 424}
{"Episode reward": -98.31795892774943, "Episode length": 999, "Policy Loss": -0.0047293975949287415, "Value Loss": 0.00014196276606526226, "_runtime": 5266.387589931488, "_timestamp": 1585575182.2322233, "_step": 425}
{"Episode reward": -95.37092225937376, "Episode length": 999, "Policy Loss": 0.004540863446891308, "Value Loss": 0.0003717782674357295, "_runtime": 5267.956621170044, "_timestamp": 1585575183.8012545, "_step": 426}
{"Episode reward": -96.40627918737593, "Episode length": 999, "Policy Loss": -0.0005792120937258005, "Value Loss": 0.0003114126739092171, "_runtime": 5269.526117801666, "_timestamp": 1585575185.3707511, "_step": 427}
{"Episode reward": -98.94745234600335, "Episode length": 999, "Policy Loss": -0.010176443494856358, "Value Loss": 0.00011530536721693352, "_runtime": 5271.098395109177, "_timestamp": 1585575186.9430285, "_step": 428}
{"Episode reward": -95.2037863843565, "Episode length": 999, "Policy Loss": 0.006759254727512598, "Value Loss": 0.0003561661869753152, "_runtime": 5272.665425300598, "_timestamp": 1585575188.5100586, "_step": 429}
{"Episode reward": -99.05165404624469, "Episode length": 999, "Policy Loss": -0.00922820158302784, "Value Loss": 7.499424827983603e-05, "_runtime": 5274.23055267334, "_timestamp": 1585575190.075186, "_step": 430}
{"Episode reward": -98.7709751704754, "Episode length": 999, "Policy Loss": -0.007364611141383648, "Value Loss": 8.917938976082951e-05, "_runtime": 5275.800887584686, "_timestamp": 1585575191.645521, "_step": 431}
{"Episode reward": -98.29810362371008, "Episode length": 999, "Policy Loss": -0.0030800069216638803, "Value Loss": 0.0001585261052241549, "_runtime": 5277.371009111404, "_timestamp": 1585575193.2156425, "_step": 432}
{"Episode reward": -98.3751278504658, "Episode length": 999, "Policy Loss": -0.005544258281588554, "Value Loss": 0.00016049979603849351, "_runtime": 5278.950687885284, "_timestamp": 1585575194.7953212, "_step": 433}
{"Episode reward": -98.12627350277063, "Episode length": 999, "Policy Loss": -0.0035632362123578787, "Value Loss": 0.00016537502233404666, "_runtime": 5280.527001619339, "_timestamp": 1585575196.371635, "_step": 434}
{"Episode reward": -96.41092066158893, "Episode length": 999, "Policy Loss": 0.004381456878036261, "Value Loss": 0.00030186978983692825, "_runtime": 5282.107548236847, "_timestamp": 1585575197.9521816, "_step": 435}
{"Episode reward": -97.8945122145012, "Episode length": 999, "Policy Loss": -0.003710238030180335, "Value Loss": 0.00014948587340768427, "_runtime": 5283.687584877014, "_timestamp": 1585575199.5322182, "_step": 436}
{"Episode reward": -98.18781900176366, "Episode length": 999, "Policy Loss": -0.006042507477104664, "Value Loss": 0.00014556660607922822, "_runtime": 5285.257460594177, "_timestamp": 1585575201.102094, "_step": 437}
{"Episode reward": -98.8994225881944, "Episode length": 999, "Policy Loss": -0.008559581823647022, "Value Loss": 7.835301948944107e-05, "_runtime": 5286.822799921036, "_timestamp": 1585575202.6674333, "_step": 438}
{"Episode reward": -97.14540419854819, "Episode length": 999, "Policy Loss": -0.005485256668180227, "Value Loss": 0.00031687301816418767, "_runtime": 5288.43837594986, "_timestamp": 1585575204.2830093, "_step": 439}
{"Episode reward": -98.72605586651783, "Episode length": 999, "Policy Loss": -0.007633901666849852, "Value Loss": 0.00010558128997217864, "_runtime": 5290.008408308029, "_timestamp": 1585575205.8530416, "_step": 440}
{"Episode reward": -98.27027677587957, "Episode length": 999, "Policy Loss": -0.005438150838017464, "Value Loss": 0.00012212348519824445, "_runtime": 5291.587109565735, "_timestamp": 1585575207.431743, "_step": 441}
{"Episode reward": -97.3782526424659, "Episode length": 999, "Policy Loss": -0.0004908852861262858, "Value Loss": 0.00017862755339592695, "_runtime": 5293.1678965091705, "_timestamp": 1585575209.0125299, "_step": 442}
{"Episode reward": -96.53636641389332, "Episode length": 999, "Policy Loss": 0.008365856483578682, "Value Loss": 0.00035808616667054594, "_runtime": 5294.747958183289, "_timestamp": 1585575210.5925915, "_step": 443}
{"Episode reward": -97.77892725869407, "Episode length": 999, "Policy Loss": -0.0004299619176890701, "Value Loss": 0.00017570875934325159, "_runtime": 5296.324026107788, "_timestamp": 1585575212.1686594, "_step": 444}
{"Episode reward": -96.77012953922373, "Episode length": 999, "Policy Loss": 0.003380977315828204, "Value Loss": 0.0002301246568094939, "_runtime": 5297.8933782577515, "_timestamp": 1585575213.7380116, "_step": 445}
{"Episode reward": -98.07875018793962, "Episode length": 999, "Policy Loss": -0.003898242022842169, "Value Loss": 0.00014192803064361215, "_runtime": 5299.474533319473, "_timestamp": 1585575215.3191667, "_step": 446}
{"Episode reward": -95.96573103824234, "Episode length": 999, "Policy Loss": 0.005334039218723774, "Value Loss": 0.0003281930403318256, "_runtime": 5301.053280591965, "_timestamp": 1585575216.897914, "_step": 447}
{"Episode reward": -97.94307944260856, "Episode length": 999, "Policy Loss": -0.006028944160789251, "Value Loss": 0.00019375808187760413, "_runtime": 5302.622827768326, "_timestamp": 1585575218.467461, "_step": 448}
{"Episode reward": -95.95497372311871, "Episode length": 999, "Policy Loss": 0.005805468186736107, "Value Loss": 0.0002930469636339694, "_runtime": 5304.200706243515, "_timestamp": 1585575220.0453396, "_step": 449}
{"Episode reward": -98.36749944258139, "Episode length": 999, "Policy Loss": -0.004151640925556421, "Value Loss": 0.00012597019667737186, "_runtime": 5305.769095659256, "_timestamp": 1585575221.613729, "_step": 450}
{"Episode reward": -97.45679782034301, "Episode length": 999, "Policy Loss": 0.0006254879990592599, "Value Loss": 0.00019488140242174268, "_runtime": 5307.340746164322, "_timestamp": 1585575223.1853795, "_step": 451}
{"Episode reward": -98.69635574269539, "Episode length": 999, "Policy Loss": -0.005576481577008963, "Value Loss": 9.948763181455433e-05, "_runtime": 5308.911983728409, "_timestamp": 1585575224.756617, "_step": 452}
{"Episode reward": -94.20867364565206, "Episode length": 999, "Policy Loss": 0.014323010109364986, "Value Loss": 0.0004742085875477642, "_runtime": 5310.519526720047, "_timestamp": 1585575226.36416, "_step": 453}
{"Episode reward": -98.64658287466136, "Episode length": 999, "Policy Loss": -0.0047931671142578125, "Value Loss": 0.00010775416740216315, "_runtime": 5312.091019153595, "_timestamp": 1585575227.9356525, "_step": 454}
{"Episode reward": -97.18302921041034, "Episode length": 999, "Policy Loss": 0.002209702041000128, "Value Loss": 0.00020631808729376644, "_runtime": 5313.6579077243805, "_timestamp": 1585575229.502541, "_step": 455}
{"Episode reward": -97.51933017002425, "Episode length": 999, "Policy Loss": -0.0008178119896911085, "Value Loss": 0.00019481273193378001, "_runtime": 5315.229865789413, "_timestamp": 1585575231.0744991, "_step": 456}
{"Episode reward": -98.66275412653218, "Episode length": 999, "Policy Loss": -0.006089304573833942, "Value Loss": 0.00010466911771800369, "_runtime": 5316.79804110527, "_timestamp": 1585575232.6426744, "_step": 457}
{"Episode reward": -97.42039473194606, "Episode length": 999, "Policy Loss": -0.0009705271804705262, "Value Loss": 0.0002323908993275836, "_runtime": 5318.3803079128265, "_timestamp": 1585575234.2249413, "_step": 458}
{"Episode reward": -94.8667901691725, "Episode length": 999, "Policy Loss": 0.0056653860956430435, "Value Loss": 0.0004005690279882401, "_runtime": 5319.951258182526, "_timestamp": 1585575235.7958915, "_step": 459}
{"Episode reward": -95.09983282486762, "Episode length": 999, "Policy Loss": 0.006638954859226942, "Value Loss": 0.00035150357871316373, "_runtime": 5321.520297288895, "_timestamp": 1585575237.3649306, "_step": 460}
{"Episode reward": -98.53197845032132, "Episode length": 999, "Policy Loss": -0.0054810442961752415, "Value Loss": 0.00012046557094436139, "_runtime": 5323.099006652832, "_timestamp": 1585575238.94364, "_step": 461}
{"Episode reward": -98.92027493439694, "Episode length": 999, "Policy Loss": -0.0067950524389743805, "Value Loss": 8.184950274880975e-05, "_runtime": 5324.677752256393, "_timestamp": 1585575240.5223856, "_step": 462}
{"Episode reward": -97.77857756920581, "Episode length": 999, "Policy Loss": 0.0006730005843564868, "Value Loss": 0.000165108242072165, "_runtime": 5326.258243322372, "_timestamp": 1585575242.1028767, "_step": 463}
{"Episode reward": -96.83961658961168, "Episode length": 999, "Policy Loss": 0.0037758725229650736, "Value Loss": 0.0002619944862090051, "_runtime": 5327.837826490402, "_timestamp": 1585575243.6824598, "_step": 464}
{"Episode reward": -97.42783634577964, "Episode length": 999, "Policy Loss": 0.0026082119438797235, "Value Loss": 0.00022962267394177616, "_runtime": 5329.4165670871735, "_timestamp": 1585575245.2612004, "_step": 465}
{"Episode reward": -96.97248056682965, "Episode length": 999, "Policy Loss": 0.002671413589268923, "Value Loss": 0.00023973021598067135, "_runtime": 5330.98895406723, "_timestamp": 1585575246.8335874, "_step": 466}
{"Episode reward": -96.89539918250337, "Episode length": 999, "Policy Loss": 0.0020865625701844692, "Value Loss": 0.00021720273070968688, "_runtime": 5332.564148187637, "_timestamp": 1585575248.4087815, "_step": 467}
{"Episode reward": -97.29990175268695, "Episode length": 999, "Policy Loss": -0.0020739813335239887, "Value Loss": 0.00022348477796185762, "_runtime": 5334.181208848953, "_timestamp": 1585575250.0258422, "_step": 468}
{"Episode reward": -99.06877917988922, "Episode length": 999, "Policy Loss": -0.009138098917901516, "Value Loss": 9.240483632311225e-05, "_runtime": 5335.752306699753, "_timestamp": 1585575251.59694, "_step": 469}
{"Episode reward": -95.48137067310269, "Episode length": 999, "Policy Loss": 0.005112561397254467, "Value Loss": 0.0003854648384731263, "_runtime": 5337.323449373245, "_timestamp": 1585575253.1680827, "_step": 470}
{"Episode reward": -97.94598908022326, "Episode length": 999, "Policy Loss": -0.002892022719606757, "Value Loss": 0.00014968146570026875, "_runtime": 5338.906131267548, "_timestamp": 1585575254.7507646, "_step": 471}
{"Episode reward": -96.60311888253125, "Episode length": 999, "Policy Loss": 0.0032125923316925764, "Value Loss": 0.00026261969469487667, "_runtime": 5340.474891662598, "_timestamp": 1585575256.319525, "_step": 472}
{"Episode reward": -96.56688381038973, "Episode length": 999, "Policy Loss": 0.0035090469755232334, "Value Loss": 0.0002733023138716817, "_runtime": 5342.051935195923, "_timestamp": 1585575257.8965685, "_step": 473}
{"Episode reward": -97.40679745468994, "Episode length": 999, "Policy Loss": 0.003079033922404051, "Value Loss": 0.00025841998285613954, "_runtime": 5343.634206533432, "_timestamp": 1585575259.4788399, "_step": 474}
{"Episode reward": -96.71916087116122, "Episode length": 999, "Policy Loss": 0.0029345937073230743, "Value Loss": 0.00027133215917274356, "_runtime": 5345.213978290558, "_timestamp": 1585575261.0586116, "_step": 475}
{"Episode reward": -96.62263700851133, "Episode length": 999, "Policy Loss": 0.0011584137100726366, "Value Loss": 0.0002693983551580459, "_runtime": 5346.776846885681, "_timestamp": 1585575262.6214802, "_step": 476}
{"Episode reward": -96.10216575574587, "Episode length": 999, "Policy Loss": 0.004941834136843681, "Value Loss": 0.00029257446294650435, "_runtime": 5348.350150585175, "_timestamp": 1585575264.194784, "_step": 477}
{"Episode reward": -95.5028168301315, "Episode length": 999, "Policy Loss": 0.0023881476372480392, "Value Loss": 0.0003624905366450548, "_runtime": 5349.924656629562, "_timestamp": 1585575265.76929, "_step": 478}
{"Episode reward": -98.33570921365595, "Episode length": 999, "Policy Loss": -0.006114584393799305, "Value Loss": 0.0001262322475668043, "_runtime": 5351.5068690776825, "_timestamp": 1585575267.3515024, "_step": 479}
{"Episode reward": -97.62513409230687, "Episode length": 999, "Policy Loss": -0.0024536685086786747, "Value Loss": 0.0001766764180501923, "_runtime": 5353.085500240326, "_timestamp": 1585575268.9301336, "_step": 480}
{"Episode reward": -98.7936853860176, "Episode length": 999, "Policy Loss": -0.007920503616333008, "Value Loss": 8.492567576467991e-05, "_runtime": 5354.644288778305, "_timestamp": 1585575270.488922, "_step": 481}
{"Episode reward": -98.3614687641956, "Episode length": 999, "Policy Loss": -0.004542806651443243, "Value Loss": 0.00013571945601142943, "_runtime": 5356.209861278534, "_timestamp": 1585575272.0544946, "_step": 482}
{"Episode reward": -98.00119902010758, "Episode length": 999, "Policy Loss": -0.003381508868187666, "Value Loss": 0.00015930747031234205, "_runtime": 5357.816567897797, "_timestamp": 1585575273.6612012, "_step": 483}
{"Episode reward": -95.97376508545723, "Episode length": 999, "Policy Loss": 0.007974067702889442, "Value Loss": 0.0003141310007777065, "_runtime": 5359.384680271149, "_timestamp": 1585575275.2293136, "_step": 484}
{"Episode reward": -96.90680808491109, "Episode length": 999, "Policy Loss": 0.0006869197823107243, "Value Loss": 0.0002380238875048235, "_runtime": 5360.963011264801, "_timestamp": 1585575276.8076446, "_step": 485}
{"Episode reward": -98.7194064974497, "Episode length": 999, "Policy Loss": -0.007567796390503645, "Value Loss": 0.00010009924881160259, "_runtime": 5362.539896726608, "_timestamp": 1585575278.38453, "_step": 486}
{"Episode reward": -98.13903014962445, "Episode length": 999, "Policy Loss": -0.004888924304395914, "Value Loss": 0.00013580219820141792, "_runtime": 5364.118237018585, "_timestamp": 1585575279.9628704, "_step": 487}
{"Episode reward": -98.76406501383111, "Episode length": 999, "Policy Loss": -0.007401793729513884, "Value Loss": 0.00011441923561505973, "_runtime": 5365.686233758926, "_timestamp": 1585575281.530867, "_step": 488}
{"Episode reward": -96.19271012168494, "Episode length": 999, "Policy Loss": 0.003968183416873217, "Value Loss": 0.00028307162574492395, "_runtime": 5367.265115022659, "_timestamp": 1585575283.1097484, "_step": 489}
{"Episode reward": -98.19600730022435, "Episode length": 999, "Policy Loss": -0.005095961038023233, "Value Loss": 0.00013075399328954518, "_runtime": 5368.844027042389, "_timestamp": 1585575284.6886604, "_step": 490}
{"Episode reward": -98.24006206853063, "Episode length": 999, "Policy Loss": -0.005106768105179071, "Value Loss": 0.00012255234469193965, "_runtime": 5370.404383897781, "_timestamp": 1585575286.2490172, "_step": 491}
{"Episode reward": -96.92138647511415, "Episode length": 999, "Policy Loss": 0.0011467031436040998, "Value Loss": 0.00024380160903092474, "_runtime": 5371.977322816849, "_timestamp": 1585575287.8219562, "_step": 492}
{"Episode reward": -96.8185971923847, "Episode length": 999, "Policy Loss": -0.00039162402390502393, "Value Loss": 0.0002484676952008158, "_runtime": 5373.556748390198, "_timestamp": 1585575289.4013817, "_step": 493}
{"Episode reward": -98.69383027358046, "Episode length": 999, "Policy Loss": -0.004773068707436323, "Value Loss": 0.0001187119196401909, "_runtime": 5375.123165130615, "_timestamp": 1585575290.9677985, "_step": 494}
{"Episode reward": -96.48071889773321, "Episode length": 999, "Policy Loss": 0.00889578741043806, "Value Loss": 0.00033908840850926936, "_runtime": 5376.691230297089, "_timestamp": 1585575292.5358636, "_step": 495}
{"Episode reward": -95.6157190200167, "Episode length": 999, "Policy Loss": 0.008227628655731678, "Value Loss": 0.0003324224962852895, "_runtime": 5378.274699211121, "_timestamp": 1585575294.1193326, "_step": 496}
{"Episode reward": -98.75188278450572, "Episode length": 999, "Policy Loss": -0.006964994128793478, "Value Loss": 0.00010022270726040006, "_runtime": 5379.849949836731, "_timestamp": 1585575295.6945832, "_step": 497}
{"Episode reward": -94.05298206815085, "Episode length": 999, "Policy Loss": 0.01150023378431797, "Value Loss": 0.0005069056642241776, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846, -0.8806524872779846]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0], "bins": [-0.24475689232349396, -0.22722455859184265, -0.20969222486019135, -0.19215989112854004, -0.17462754249572754, -0.15709522366523743, -0.13956287503242493, -0.12203054130077362, -0.10449820756912231, -0.08696587383747101, -0.0694335401058197, -0.051901206374168396, -0.034368857741355896, -0.01683652400970459, 0.0006958097219467163, 0.01822812855243683, 0.03576047718524933, 0.05329282581806183, 0.07082514464855194, 0.08835749328136444, 0.10588981211185455, 0.12342216074466705, 0.14095447957515717, 0.15848682820796967, 0.17601917684078217, 0.19355149567127228, 0.21108384430408478, 0.2286161631345749, 0.2461485117673874, 0.2636808753013611, 0.2812131643295288, 0.2987455129623413, 0.3162778615951538, 0.3338102102279663, 0.3513425588607788, 0.36887484788894653, 0.38640719652175903, 0.40393954515457153, 0.42147189378738403, 0.43900418281555176, 0.45653653144836426, 0.47406888008117676, 0.49160122871398926, 0.5091335773468018, 0.5266658663749695, 0.544198215007782, 0.5617305636405945, 0.579262912273407, 0.5967952609062195, 0.6143275499343872, 0.6318598985671997, 0.6493922472000122, 0.6669245958328247, 0.6844568848609924, 0.7019892334938049, 0.7195215821266174, 0.7370539307594299, 0.7545862793922424, 0.7721186280250549, 0.7896509766578674, 0.8071832060813904, 0.8247155547142029, 0.8422479033470154, 0.8597802519798279, 0.8773126006126404]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 6.0, 1.0, 1.0], "bins": [-0.40668627619743347, -0.40009060502052307, -0.3934949040412903, -0.3868992328643799, -0.3803035616874695, -0.3737078905105591, -0.3671122193336487, -0.3605165183544159, -0.3539208471775055, -0.3473251760005951, -0.3407294750213623, -0.3341338038444519, -0.3275381326675415, -0.3209424614906311, -0.3143467903137207, -0.3077510893344879, -0.3011554181575775, -0.2945597469806671, -0.2879640460014343, -0.2813683748245239, -0.2747727036476135, -0.2681770324707031, -0.2615813612937927, -0.25498566031455994, -0.24838998913764954, -0.24179431796073914, -0.23519863188266754, -0.22860294580459595, -0.22200727462768555, -0.21541160345077515, -0.20881591737270355, -0.20222023129463196, -0.19562456011772156, -0.18902888894081116, -0.18243320286273956, -0.17583751678466797, -0.16924184560775757, -0.16264617443084717, -0.15605047345161438, -0.14945480227470398, -0.14285913109779358, -0.13626345992088318, -0.12966778874397278, -0.12307208776473999, -0.11647641658782959, -0.10988074541091919, -0.1032850444316864, -0.096689373254776, -0.0900937020778656, -0.0834980309009552, -0.0769023597240448, -0.07030665874481201, -0.06371098756790161, -0.05711531639099121, -0.05051961541175842, -0.04392394423484802, -0.03732827305793762, -0.03073260188102722, -0.02413693070411682, -0.017541229724884033, -0.010945558547973633, -0.004349887371063232, 0.0022458136081695557, 0.008841484785079956, 0.015437155961990356]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 6.0, 3.0, 13.0, 33.0, 347.0, 31.0, 8.0, 13.0, 5.0, 8.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.28898459672927856, -0.2791934609413147, -0.26940232515335083, -0.25961118936538696, -0.2498200386762619, -0.24002890288829803, -0.23023775219917297, -0.2204466164112091, -0.21065548062324524, -0.20086434483528137, -0.1910732090473175, -0.18128205835819244, -0.17149092257022858, -0.1616997867822647, -0.15190863609313965, -0.14211750030517578, -0.13232636451721191, -0.12253522872924805, -0.11274409294128418, -0.10295294225215912, -0.09316180646419525, -0.08337067067623138, -0.07357951998710632, -0.06378838419914246, -0.05399724841117859, -0.04420611262321472, -0.034414976835250854, -0.024623841047286987, -0.014832675457000732, -0.005041539669036865, 0.004749596118927002, 0.01454073190689087, 0.024331867694854736, 0.034123003482818604, 0.04391413927078247, 0.05370527505874634, 0.0634964108467102, 0.07328757643699646, 0.08307871222496033, 0.0928698480129242, 0.10266098380088806, 0.11245211958885193, 0.1222432553768158, 0.13203439116477966, 0.14182555675506592, 0.15161669254302979, 0.16140782833099365, 0.17119896411895752, 0.1809900999069214, 0.19078123569488525, 0.20057237148284912, 0.210363507270813, 0.22015464305877686, 0.22994577884674072, 0.2397369146347046, 0.24952805042266846, 0.2593192458152771, 0.26911038160324097, 0.27890151739120483, 0.2886926531791687, 0.29848378896713257, 0.30827492475509644, 0.3180660605430603, 0.32785719633102417, 0.33764833211898804]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6346354484558105, -0.615193247795105, -0.5957509875297546, -0.5763087272644043, -0.5568665266036987, -0.5374243259429932, -0.5179820656776428, -0.49853983521461487, -0.4790976047515869, -0.45965537428855896, -0.440213143825531, -0.42077091336250305, -0.4013286828994751, -0.38188645243644714, -0.3624442219734192, -0.34300199151039124, -0.3235597610473633, -0.3041175305843353, -0.2846753001213074, -0.2652330696582794, -0.24579083919525146, -0.2263486087322235, -0.20690637826919556, -0.1874641478061676, -0.16802191734313965, -0.1485796868801117, -0.12913745641708374, -0.1096951961517334, -0.09025299549102783, -0.07081079483032227, -0.051368534564971924, -0.03192627429962158, -0.012484073638916016, 0.006958127021789551, 0.026400387287139893, 0.045842647552490234, 0.0652848482131958, 0.08472704887390137, 0.10416930913925171, 0.12361156940460205, 0.14305377006530762, 0.16249597072601318, 0.18193823099136353, 0.20138049125671387, 0.22082269191741943, 0.240264892578125, 0.25970715284347534, 0.2791494131088257, 0.29859161376953125, 0.3180338144302368, 0.33747607469558716, 0.3569183349609375, 0.37636053562164307, 0.39580273628234863, 0.41524505615234375, 0.4346872568130493, 0.4541294574737549, 0.47357165813446045, 0.493013858795166, 0.5124561786651611, 0.5318983793258667, 0.5513405799865723, 0.5707828998565674, 0.590225100517273, 0.6096673011779785]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.48732346296310425, -0.4720218777656555, -0.4567202925682068, -0.44141870737075806, -0.4261171221733093, -0.4108155369758606, -0.39551395177841187, -0.3802123963832855, -0.3649108111858368, -0.34960922598838806, -0.33430764079093933, -0.3190060555934906, -0.30370447039604187, -0.28840288519859314, -0.2731013298034668, -0.25779974460601807, -0.24249814450740814, -0.2271965742111206, -0.21189498901367188, -0.19659340381622314, -0.18129181861877441, -0.16599023342132568, -0.15068864822387695, -0.13538706302642822, -0.12008547782897949, -0.10478389263153076, -0.08948230743408203, -0.07418075203895569, -0.05887916684150696, -0.04357758164405823, -0.028275996446609497, -0.012974411249160767, 0.002327173948287964, 0.017628729343414307, 0.03293031454086304, 0.04823189973831177, 0.0635334849357605, 0.07883507013320923, 0.09413665533065796, 0.10943824052810669, 0.12473982572555542, 0.14004141092300415, 0.15534299612045288, 0.1706445813179016, 0.18594616651535034, 0.20124775171279907, 0.2165493369102478, 0.23185092210769653, 0.24715250730514526, 0.262454092502594, 0.2777556777000427, 0.29305726289749146, 0.3083588480949402, 0.3236604332923889, 0.33896195888519287, 0.3542635440826416, 0.36956512928009033, 0.38486671447753906, 0.4001682996749878, 0.4154698848724365, 0.43077147006988525, 0.446073055267334, 0.4613746404647827, 0.47667622566223145, 0.4919778108596802]}, "_runtime": 5381.455147743225, "_timestamp": 1585575297.299781, "_step": 498}
{"Episode reward": -97.36559152533039, "Episode length": 999, "Policy Loss": -0.0036042688880115747, "Value Loss": 0.0002533624938223511, "_runtime": 5381.455147743225, "_timestamp": 1585575297.299781, "_step": 499}
