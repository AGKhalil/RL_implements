{"Episode reward": -58.96647384235958, "Episode length": 999, "Policy Loss": -0.09506550431251526, "Value Loss": 0.07366792857646942, "_runtime": 705.6889674663544, "_timestamp": 1585509784.109697, "_step": 0}
{"Episode reward": -59.41682704800932, "Episode length": 999, "Policy Loss": 0.2047511488199234, "Value Loss": 12.463935852050781, "_runtime": 707.0052852630615, "_timestamp": 1585509785.426015, "_step": 1}
{"Episode reward": 47.51750845556166, "Episode length": 903, "Policy Loss": 0.014733400195837021, "Value Loss": 26.669660568237305, "_runtime": 708.5300920009613, "_timestamp": 1585509786.9508216, "_step": 2}
{"Episode reward": -57.923135433240574, "Episode length": 999, "Policy Loss": 0.002475332235917449, "Value Loss": 142.71978759765625, "_runtime": 709.9550514221191, "_timestamp": 1585509788.375781, "_step": 3}
{"Episode reward": 46.29771786207266, "Episode length": 944, "Policy Loss": -0.16856345534324646, "Value Loss": 12.907451629638672, "_runtime": 711.4691059589386, "_timestamp": 1585509789.8898356, "_step": 4}
{"Episode reward": -58.58688594163588, "Episode length": 999, "Policy Loss": -0.15642528235912323, "Value Loss": 2.6904165744781494, "_runtime": 712.6757740974426, "_timestamp": 1585509791.0965037, "_step": 5}
{"Episode reward": 58.06112576781499, "Episode length": 772, "Policy Loss": 0.037286996841430664, "Value Loss": 17.909154891967773, "_runtime": 713.7561028003693, "_timestamp": 1585509792.1768324, "_step": 6}
{"Episode reward": 59.851551251962526, "Episode length": 697, "Policy Loss": -0.2517460584640503, "Value Loss": 28.61269187927246, "_runtime": 715.2960419654846, "_timestamp": 1585509793.7167716, "_step": 7}
{"Episode reward": -54.8095848145168, "Episode length": 999, "Policy Loss": -0.136685311794281, "Value Loss": 0.1597156524658203, "_runtime": 716.0125961303711, "_timestamp": 1585509794.4333258, "_step": 8}
{"Episode reward": 73.50720277012842, "Episode length": 454, "Policy Loss": 0.09876815229654312, "Value Loss": 28.80032730102539, "_runtime": 716.6808407306671, "_timestamp": 1585509795.1015704, "_step": 9}
{"Episode reward": 76.01495538304906, "Episode length": 430, "Policy Loss": 0.05521146208047867, "Value Loss": 24.12228012084961, "_runtime": 718.1360805034637, "_timestamp": 1585509796.5568101, "_step": 10}
{"Episode reward": 44.7043619150646, "Episode length": 952, "Policy Loss": -0.13927125930786133, "Value Loss": 13.176044464111328, "_runtime": 718.8402428627014, "_timestamp": 1585509797.2609725, "_step": 11}
{"Episode reward": 74.10613474076538, "Episode length": 459, "Policy Loss": -0.03200283274054527, "Value Loss": 21.910167694091797, "_runtime": 719.7813818454742, "_timestamp": 1585509798.2021115, "_step": 12}
{"Episode reward": 65.47700128687703, "Episode length": 599, "Policy Loss": -0.1421927958726883, "Value Loss": 16.40658187866211, "_runtime": 720.7788689136505, "_timestamp": 1585509799.1995986, "_step": 13}
{"Episode reward": 63.29413257090771, "Episode length": 656, "Policy Loss": -0.053669389337301254, "Value Loss": 15.684637069702148, "_runtime": 722.2714681625366, "_timestamp": 1585509800.6921978, "_step": 14}
{"Episode reward": -57.03182361210931, "Episode length": 999, "Policy Loss": -0.37367159128189087, "Value Loss": 0.6968087553977966, "_runtime": 723.0038135051727, "_timestamp": 1585509801.4245431, "_step": 15}
{"Episode reward": 75.02054448255475, "Episode length": 473, "Policy Loss": -0.04642500728368759, "Value Loss": 21.708038330078125, "_runtime": 723.6918070316315, "_timestamp": 1585509802.1125367, "_step": 16}
{"Episode reward": 74.91673896870732, "Episode length": 447, "Policy Loss": 0.31119734048843384, "Value Loss": 22.636524200439453, "_runtime": 725.1291286945343, "_timestamp": 1585509803.5498583, "_step": 17}
{"Episode reward": 47.163811453494745, "Episode length": 931, "Policy Loss": -0.14041073620319366, "Value Loss": 10.780723571777344, "_runtime": 725.6821231842041, "_timestamp": 1585509804.1028528, "_step": 18}
{"Episode reward": 80.92732760900137, "Episode length": 353, "Policy Loss": 0.011894703842699528, "Value Loss": 27.466053009033203, "_runtime": 727.1684763431549, "_timestamp": 1585509805.589206, "_step": 19}
{"Episode reward": -56.51551025110108, "Episode length": 999, "Policy Loss": -0.23982758820056915, "Value Loss": 0.03813109174370766, "_runtime": 728.1069676876068, "_timestamp": 1585509806.5276973, "_step": 20}
{"Episode reward": 64.41234068730283, "Episode length": 604, "Policy Loss": 0.10784163326025009, "Value Loss": 16.049501419067383, "_runtime": 729.6005897521973, "_timestamp": 1585509808.0213194, "_step": 21}
{"Episode reward": -56.580131226802465, "Episode length": 999, "Policy Loss": -0.24548010528087616, "Value Loss": 0.04975193366408348, "_runtime": 730.9527304172516, "_timestamp": 1585509809.37346, "_step": 22}
{"Episode reward": 51.844965764644805, "Episode length": 878, "Policy Loss": -0.10627218335866928, "Value Loss": 11.205726623535156, "_runtime": 731.5696485042572, "_timestamp": 1585509809.9903781, "_step": 23}
{"Episode reward": 77.09308196974135, "Episode length": 394, "Policy Loss": 0.020096253603696823, "Value Loss": 24.748594284057617, "_runtime": 732.9768476486206, "_timestamp": 1585509811.3975773, "_step": 24}
{"Episode reward": 48.27025299581227, "Episode length": 919, "Policy Loss": -0.11109189689159393, "Value Loss": 10.862712860107422, "_runtime": 734.5236859321594, "_timestamp": 1585509812.9444156, "_step": 25}
{"Episode reward": -58.77616069756042, "Episode length": 999, "Policy Loss": -0.2660509943962097, "Value Loss": 0.23028692603111267, "_runtime": 735.4415075778961, "_timestamp": 1585509813.8622372, "_step": 26}
{"Episode reward": 66.41510085699349, "Episode length": 608, "Policy Loss": -0.05074173957109451, "Value Loss": 16.576187133789062, "_runtime": 736.4625227451324, "_timestamp": 1585509814.8832524, "_step": 27}
{"Episode reward": 61.903458421983395, "Episode length": 667, "Policy Loss": -0.16663077473640442, "Value Loss": 15.783447265625, "_runtime": 737.5908606052399, "_timestamp": 1585509816.0115902, "_step": 28}
{"Episode reward": 58.39540279963958, "Episode length": 726, "Policy Loss": -0.12272639572620392, "Value Loss": 13.68635082244873, "_runtime": 738.8297464847565, "_timestamp": 1585509817.2504761, "_step": 29}
{"Episode reward": 53.59320517429399, "Episode length": 812, "Policy Loss": -0.1629563719034195, "Value Loss": 11.957318305969238, "_runtime": 739.6240012645721, "_timestamp": 1585509818.044731, "_step": 30}
{"Episode reward": 71.4124351453058, "Episode length": 514, "Policy Loss": -0.05944913998246193, "Value Loss": 19.02704429626465, "_runtime": 740.4295151233673, "_timestamp": 1585509818.8502448, "_step": 31}
{"Episode reward": 71.71185474930239, "Episode length": 521, "Policy Loss": 0.16955778002738953, "Value Loss": 19.768999099731445, "_runtime": 741.3634536266327, "_timestamp": 1585509819.7841833, "_step": 32}
{"Episode reward": 64.3245183596436, "Episode length": 605, "Policy Loss": -0.11332527548074722, "Value Loss": 15.984918594360352, "_runtime": 741.9585771560669, "_timestamp": 1585509820.3793068, "_step": 33}
{"Episode reward": 78.35904001951157, "Episode length": 385, "Policy Loss": -0.0632607713341713, "Value Loss": 25.167213439941406, "_runtime": 743.3552916049957, "_timestamp": 1585509821.7760212, "_step": 34}
{"Episode reward": 47.39688467721915, "Episode length": 937, "Policy Loss": -0.17282211780548096, "Value Loss": 10.568459510803223, "_runtime": 744.0734519958496, "_timestamp": 1585509822.4941816, "_step": 35}
{"Episode reward": 75.3971108574591, "Episode length": 439, "Policy Loss": 0.2605316936969757, "Value Loss": 22.42790985107422, "_runtime": 745.5652892589569, "_timestamp": 1585509823.986019, "_step": 36}
{"Episode reward": -55.33305226661095, "Episode length": 999, "Policy Loss": -0.29689452052116394, "Value Loss": 0.07727240025997162, "_runtime": 746.3862173557281, "_timestamp": 1585509824.806947, "_step": 37}
{"Episode reward": 71.58353660993342, "Episode length": 523, "Policy Loss": 0.7253208756446838, "Value Loss": 18.602479934692383, "_runtime": 747.4588353633881, "_timestamp": 1585509825.879565, "_step": 38}
{"Episode reward": 61.07821549684991, "Episode length": 715, "Policy Loss": -0.12187330424785614, "Value Loss": 13.54151439666748, "_runtime": 748.8696677684784, "_timestamp": 1585509827.2903974, "_step": 39}
{"Episode reward": 47.76915100437548, "Episode length": 915, "Policy Loss": -0.1874525099992752, "Value Loss": 10.552606582641602, "_runtime": 750.3647360801697, "_timestamp": 1585509828.7854657, "_step": 40}
{"Episode reward": -55.83069786662837, "Episode length": 999, "Policy Loss": -0.2618849575519562, "Value Loss": 0.04198396950960159, "_runtime": 751.872579574585, "_timestamp": 1585509830.2933092, "_step": 41}
{"Episode reward": 43.7888122215134, "Episode length": 987, "Policy Loss": -0.1533513069152832, "Value Loss": 9.987869262695312, "_runtime": 752.922266960144, "_timestamp": 1585509831.3429966, "_step": 42}
{"Episode reward": 64.01332645637851, "Episode length": 671, "Policy Loss": -0.03714264929294586, "Value Loss": 14.4768648147583, "_runtime": 754.1584641933441, "_timestamp": 1585509832.5791938, "_step": 43}
{"Episode reward": 54.10569154431178, "Episode length": 793, "Policy Loss": -0.16739943623542786, "Value Loss": 12.829672813415527, "_runtime": 754.8559992313385, "_timestamp": 1585509833.2767289, "_step": 44}
{"Episode reward": 74.78097364094201, "Episode length": 445, "Policy Loss": -0.053007155656814575, "Value Loss": 21.65789222717285, "_runtime": 756.0972726345062, "_timestamp": 1585509834.5180023, "_step": 45}
{"Episode reward": 52.00342658177626, "Episode length": 816, "Policy Loss": -0.13836517930030823, "Value Loss": 11.918046951293945, "_runtime": 757.6391870975494, "_timestamp": 1585509836.0599167, "_step": 46}
{"Episode reward": -52.8771839114536, "Episode length": 999, "Policy Loss": -0.24702906608581543, "Value Loss": 0.17988988757133484, "_runtime": 759.1462125778198, "_timestamp": 1585509837.5669422, "_step": 47}
{"Episode reward": -55.08928461430124, "Episode length": 999, "Policy Loss": -0.23606544733047485, "Value Loss": 0.0444093719124794, "_runtime": 760.6849944591522, "_timestamp": 1585509839.105724, "_step": 48}
{"Episode reward": -55.55660437786889, "Episode length": 999, "Policy Loss": -0.2281724512577057, "Value Loss": 0.043901871889829636, "_runtime": 762.2369754314423, "_timestamp": 1585509840.657705, "_step": 49}
{"Episode reward": -56.70642737477353, "Episode length": 999, "Policy Loss": -0.2200823575258255, "Value Loss": 0.05030614137649536, "_runtime": 763.7956721782684, "_timestamp": 1585509842.2164018, "_step": 50}
{"Episode reward": -55.658983100347314, "Episode length": 999, "Policy Loss": -0.2058156579732895, "Value Loss": 0.026394950225949287, "_runtime": 764.6869158744812, "_timestamp": 1585509843.1076455, "_step": 51}
{"Episode reward": 67.46883775462376, "Episode length": 559, "Policy Loss": 0.03767814859747887, "Value Loss": 17.830036163330078, "_runtime": 765.611545085907, "_timestamp": 1585509844.0322747, "_step": 52}
{"Episode reward": 66.92354845856238, "Episode length": 584, "Policy Loss": -0.005752475466579199, "Value Loss": 17.08721351623535, "_runtime": 766.3789360523224, "_timestamp": 1585509844.7996657, "_step": 53}
{"Episode reward": 71.41212055620103, "Episode length": 490, "Policy Loss": 0.06487509608268738, "Value Loss": 20.378591537475586, "_runtime": 767.9282536506653, "_timestamp": 1585509846.3489833, "_step": 54}
{"Episode reward": -55.907982863989446, "Episode length": 999, "Policy Loss": -0.16602441668510437, "Value Loss": 0.01568295806646347, "_runtime": 769.4463024139404, "_timestamp": 1585509847.867032, "_step": 55}
{"Episode reward": -57.52914351132637, "Episode length": 999, "Policy Loss": -0.16901327669620514, "Value Loss": 0.015498505905270576, "_runtime": 770.1536133289337, "_timestamp": 1585509848.574343, "_step": 56}
{"Episode reward": 74.9044541476714, "Episode length": 460, "Policy Loss": 0.1942649483680725, "Value Loss": 21.691940307617188, "_runtime": 771.6965293884277, "_timestamp": 1585509850.117259, "_step": 57}
{"Episode reward": -58.33944256917549, "Episode length": 999, "Policy Loss": -0.16455166041851044, "Value Loss": 0.014752442017197609, "_runtime": 773.2408926486969, "_timestamp": 1585509851.6616223, "_step": 58}
{"Episode reward": -57.95895122572499, "Episode length": 999, "Policy Loss": -0.16066452860832214, "Value Loss": 0.014382462948560715, "_runtime": 774.4979422092438, "_timestamp": 1585509852.9186718, "_step": 59}
{"Episode reward": 50.71552708490985, "Episode length": 834, "Policy Loss": 0.018349476158618927, "Value Loss": 11.96731948852539, "_runtime": 775.2947714328766, "_timestamp": 1585509853.715501, "_step": 60}
{"Episode reward": 71.53979667877032, "Episode length": 500, "Policy Loss": 0.0378088615834713, "Value Loss": 19.989412307739258, "_runtime": 776.162755727768, "_timestamp": 1585509854.5834854, "_step": 61}
{"Episode reward": 67.79848546615378, "Episode length": 549, "Policy Loss": 0.19954244792461395, "Value Loss": 18.20263671875, "_runtime": 777.2355027198792, "_timestamp": 1585509855.6562324, "_step": 62}
{"Episode reward": 60.73344940923018, "Episode length": 709, "Policy Loss": -0.016849014908075333, "Value Loss": 14.102845191955566, "_runtime": 778.2774150371552, "_timestamp": 1585509856.6981447, "_step": 63}
{"Episode reward": 59.0372490798887, "Episode length": 685, "Policy Loss": -0.011022645980119705, "Value Loss": 14.590096473693848, "_runtime": 779.1227941513062, "_timestamp": 1585509857.5435238, "_step": 64}
{"Episode reward": 67.96263333359741, "Episode length": 549, "Policy Loss": 0.0982009619474411, "Value Loss": 18.173961639404297, "_runtime": 780.388744354248, "_timestamp": 1585509858.809474, "_step": 65}
{"Episode reward": 53.05426498530637, "Episode length": 833, "Policy Loss": -0.03614215552806854, "Value Loss": 12.006004333496094, "_runtime": 781.467777967453, "_timestamp": 1585509859.8885076, "_step": 66}
{"Episode reward": 59.56105183814311, "Episode length": 705, "Policy Loss": 0.09638260304927826, "Value Loss": 14.155693054199219, "_runtime": 782.5597031116486, "_timestamp": 1585509860.9804327, "_step": 67}
{"Episode reward": 58.71760576096378, "Episode length": 720, "Policy Loss": 0.08099961280822754, "Value Loss": 13.874589920043945, "_runtime": 783.779543876648, "_timestamp": 1585509862.2002735, "_step": 68}
{"Episode reward": 57.603765831469026, "Episode length": 804, "Policy Loss": 0.2107432335615158, "Value Loss": 12.420463562011719, "_runtime": 784.7623507976532, "_timestamp": 1585509863.1830804, "_step": 69}
{"Episode reward": 61.84596787120863, "Episode length": 647, "Policy Loss": 0.2040172964334488, "Value Loss": 15.450798988342285, "_runtime": 786.27996301651, "_timestamp": 1585509864.7006927, "_step": 70}
{"Episode reward": -58.36890331634696, "Episode length": 999, "Policy Loss": -0.14069688320159912, "Value Loss": 0.01743321120738983, "_runtime": 787.3459746837616, "_timestamp": 1585509865.7667043, "_step": 71}
{"Episode reward": 59.29368426504482, "Episode length": 691, "Policy Loss": -0.012341734953224659, "Value Loss": 14.47174072265625, "_runtime": 788.0518712997437, "_timestamp": 1585509866.472601, "_step": 72}
{"Episode reward": 75.1541614838109, "Episode length": 454, "Policy Loss": 0.20986466109752655, "Value Loss": 21.964487075805664, "_runtime": 788.9299540519714, "_timestamp": 1585509867.3506837, "_step": 73}
{"Episode reward": 66.25248714711859, "Episode length": 572, "Policy Loss": 0.019493885338306427, "Value Loss": 17.452119827270508, "_runtime": 789.799656867981, "_timestamp": 1585509868.2203865, "_step": 74}
{"Episode reward": 67.18547033875359, "Episode length": 564, "Policy Loss": 0.10491732507944107, "Value Loss": 17.690126419067383, "_runtime": 790.8370041847229, "_timestamp": 1585509869.2577338, "_step": 75}
{"Episode reward": 60.30723552520129, "Episode length": 688, "Policy Loss": 0.051246464252471924, "Value Loss": 14.519031524658203, "_runtime": 791.5348281860352, "_timestamp": 1585509869.9555578, "_step": 76}
{"Episode reward": 73.06413570014138, "Episode length": 454, "Policy Loss": 0.21620959043502808, "Value Loss": 21.977577209472656, "_runtime": 792.3574161529541, "_timestamp": 1585509870.7781458, "_step": 77}
{"Episode reward": 69.81297706809586, "Episode length": 515, "Policy Loss": 0.10207680612802505, "Value Loss": 19.395408630371094, "_runtime": 793.3774755001068, "_timestamp": 1585509871.7982051, "_step": 78}
{"Episode reward": 61.50308906699, "Episode length": 673, "Policy Loss": 0.10553392022848129, "Value Loss": 14.84858512878418, "_runtime": 794.8631584644318, "_timestamp": 1585509873.283888, "_step": 79}
{"Episode reward": -58.291365253145685, "Episode length": 999, "Policy Loss": -0.1567285805940628, "Value Loss": 0.014236599206924438, "_runtime": 796.3668217658997, "_timestamp": 1585509874.7875514, "_step": 80}
{"Episode reward": -57.3449761791399, "Episode length": 999, "Policy Loss": -0.1551627367734909, "Value Loss": 0.022911056876182556, "_runtime": 796.949038028717, "_timestamp": 1585509875.3697677, "_step": 81}
{"Episode reward": 78.82846214736486, "Episode length": 368, "Policy Loss": 0.33645081520080566, "Value Loss": 27.135343551635742, "_runtime": 797.5363025665283, "_timestamp": 1585509875.9570322, "_step": 82}
{"Episode reward": 78.31211225527841, "Episode length": 373, "Policy Loss": 0.13364984095096588, "Value Loss": 26.72085189819336, "_runtime": 799.064471244812, "_timestamp": 1585509877.485201, "_step": 83}
{"Episode reward": -54.68418654669905, "Episode length": 999, "Policy Loss": -0.14076091349124908, "Value Loss": 0.0335003025829792, "_runtime": 800.1152215003967, "_timestamp": 1585509878.5359511, "_step": 84}
{"Episode reward": 58.57515291077743, "Episode length": 697, "Policy Loss": -0.016553230583667755, "Value Loss": 14.302005767822266, "_runtime": 801.6048560142517, "_timestamp": 1585509880.0255857, "_step": 85}
{"Episode reward": -59.04989294782124, "Episode length": 999, "Policy Loss": -0.15945373475551605, "Value Loss": 0.02003694511950016, "_runtime": 803.0995275974274, "_timestamp": 1585509881.5202572, "_step": 86}
{"Episode reward": 42.504664388058174, "Episode length": 968, "Policy Loss": -0.057985059916973114, "Value Loss": 10.331835746765137, "_runtime": 804.2458214759827, "_timestamp": 1585509882.666551, "_step": 87}
{"Episode reward": 55.781920011419544, "Episode length": 746, "Policy Loss": 0.007122286595404148, "Value Loss": 13.373163223266602, "_runtime": 805.2856616973877, "_timestamp": 1585509883.7063913, "_step": 88}
{"Episode reward": 61.49256924222786, "Episode length": 668, "Policy Loss": 0.04666023701429367, "Value Loss": 14.921188354492188, "_runtime": 806.1448163986206, "_timestamp": 1585509884.565546, "_step": 89}
{"Episode reward": 65.74460464463195, "Episode length": 548, "Policy Loss": 0.0504879392683506, "Value Loss": 18.21284294128418, "_runtime": 807.0579390525818, "_timestamp": 1585509885.4786687, "_step": 90}
{"Episode reward": 64.01700939973941, "Episode length": 600, "Policy Loss": 0.36174848675727844, "Value Loss": 16.650856018066406, "_runtime": 807.8580973148346, "_timestamp": 1585509886.278827, "_step": 91}
{"Episode reward": 70.57565972867098, "Episode length": 519, "Policy Loss": 0.7875117659568787, "Value Loss": 19.172277450561523, "_runtime": 809.0305142402649, "_timestamp": 1585509887.4512439, "_step": 92}
{"Episode reward": 54.116730357197966, "Episode length": 773, "Policy Loss": 0.09672822803258896, "Value Loss": 12.891804695129395, "_runtime": 810.3624610900879, "_timestamp": 1585509888.7831907, "_step": 93}
{"Episode reward": 47.913619690552856, "Episode length": 882, "Policy Loss": -0.04744391888380051, "Value Loss": 11.358336448669434, "_runtime": 811.3441922664642, "_timestamp": 1585509889.764922, "_step": 94}
{"Episode reward": 62.3247144642084, "Episode length": 646, "Policy Loss": 0.0177276860922575, "Value Loss": 15.44455623626709, "_runtime": 812.774133682251, "_timestamp": 1585509891.1948633, "_step": 95}
{"Episode reward": 45.44620900402423, "Episode length": 934, "Policy Loss": 0.09828877449035645, "Value Loss": 10.680567741394043, "_runtime": 814.2285783290863, "_timestamp": 1585509892.649308, "_step": 96}
{"Episode reward": 43.116461635487155, "Episode length": 949, "Policy Loss": -0.08093657344579697, "Value Loss": 10.511809349060059, "_runtime": 815.3578984737396, "_timestamp": 1585509893.778628, "_step": 97}
{"Episode reward": 58.068245384722886, "Episode length": 737, "Policy Loss": -0.02380368486046791, "Value Loss": 13.531084060668945, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453, 90.87207794189453]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-44.52394104003906, -43.168434143066406, -41.812931060791016, -40.45742416381836, -39.1019172668457, -37.74641418457031, -36.390907287597656, -35.035400390625, -33.679893493652344, -32.32439041137695, -30.968883514404297, -29.613378524780273, -28.25787353515625, -26.902366638183594, -25.54686164855957, -24.191354751586914, -22.83584976196289, -21.480344772338867, -20.12483787536621, -18.769332885742188, -17.41382598876953, -16.058320999145508, -14.702816009521484, -13.347309112548828, -11.991806030273438, -10.636299133300781, -9.280792236328125, -7.925285339355469, -6.569782257080078, -5.214275360107422, -3.8587684631347656, -2.503265380859375, -1.1477584838867188, 0.2077484130859375, 1.5632514953613281, 2.9187583923339844, 4.274265289306641, 5.629768371582031, 6.9852752685546875, 8.340782165527344, 9.6962890625, 11.05179214477539, 12.407299041748047, 13.762805938720703, 15.118309020996094, 16.47381591796875, 17.829322814941406, 19.184825897216797, 20.540328979492188, 21.895835876464844, 23.2513427734375, 24.606849670410156, 25.962356567382812, 27.31786346435547, 28.673370361328125, 30.02886962890625, 31.384376525878906, 32.73988342285156, 34.09539031982422, 35.450897216796875, 36.80640411376953, 38.161903381347656, 39.51741027832031, 40.87291717529297, 42.228424072265625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-40.37385559082031, -38.90254211425781, -37.43122863769531, -35.95991516113281, -34.48859786987305, -33.01728439331055, -31.545970916748047, -30.074657440185547, -28.603342056274414, -27.13202667236328, -25.66071319580078, -24.18939971923828, -22.71808624267578, -21.24677085876465, -19.77545738220215, -18.304141998291016, -16.832828521728516, -15.361515045166016, -13.890199661254883, -12.418886184692383, -10.94757080078125, -9.47625732421875, -8.00494384765625, -6.53363037109375, -5.06231689453125, -3.5909996032714844, -2.1196861267089844, -0.6483726501464844, 0.8229408264160156, 2.2942543029785156, 3.7655715942382812, 5.236885070800781, 6.708198547363281, 8.179512023925781, 9.650825500488281, 11.122142791748047, 12.593456268310547, 14.064769744873047, 15.536083221435547, 17.007396697998047, 18.478713989257812, 19.950027465820312, 21.421340942382812, 22.892654418945312, 24.363967895507812, 25.835281372070312, 27.306594848632812, 28.777908325195312, 30.249221801757812, 31.720542907714844, 33.191856384277344, 34.663169860839844, 36.134483337402344, 37.605796813964844, 39.077110290527344, 40.548423767089844, 42.019737243652344, 43.491050720214844, 44.962364196777344, 46.433685302734375, 47.904998779296875, 49.376312255859375, 50.847625732421875, 52.318939208984375, 53.790252685546875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 4.0, 5.0, 5.0, 4.0, 5.0, 9.0, 9.0, 6.0, 10.0, 10.0, 21.0, 13.0, 17.0, 22.0, 25.0, 21.0, 13.0, 20.0, 67.0, 14.0, 20.0, 20.0, 19.0, 18.0, 18.0, 17.0, 13.0, 9.0, 8.0, 11.0, 8.0, 6.0, 5.0, 4.0, 4.0, 4.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-29.748441696166992, -28.66518211364746, -27.58192253112793, -26.4986629486084, -25.415403366088867, -24.332143783569336, -23.248884201049805, -22.165624618530273, -21.082365036010742, -19.99910545349121, -18.91584587097168, -17.83258628845215, -16.749326705932617, -15.666067123413086, -14.582807540893555, -13.499547958374023, -12.416288375854492, -11.333028793334961, -10.24976921081543, -9.166509628295898, -8.083250045776367, -6.999990463256836, -5.916730880737305, -4.833471298217773, -3.750211715698242, -2.666952133178711, -1.5836925506591797, -0.5004329681396484, 0.5828266143798828, 1.666086196899414, 2.7493457794189453, 3.8326053619384766, 4.915864944458008, 5.999124526977539, 7.08238410949707, 8.165643692016602, 9.248903274536133, 10.332162857055664, 11.415422439575195, 12.498682022094727, 13.581941604614258, 14.665201187133789, 15.74846076965332, 16.83172035217285, 17.914979934692383, 18.998239517211914, 20.081499099731445, 21.164758682250977, 22.248018264770508, 23.33127784729004, 24.41453742980957, 25.4977970123291, 26.581056594848633, 27.664316177368164, 28.747575759887695, 29.830835342407227, 30.914094924926758, 31.99735450744629, 33.08061218261719, 34.16387176513672, 35.24713134765625, 36.33039093017578, 37.41365051269531, 38.496910095214844, 39.580169677734375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-37.356571197509766, -36.026512145996094, -34.69645690917969, -33.366397857666016, -32.036338806152344, -30.706279754638672, -29.376222610473633, -28.046165466308594, -26.716106414794922, -25.38604736328125, -24.05599021911621, -22.725933074951172, -21.3958740234375, -20.065814971923828, -18.73575782775879, -17.40570068359375, -16.075641632080078, -14.745582580566406, -13.415525436401367, -12.085468292236328, -10.755409240722656, -9.425350189208984, -8.095293045043945, -6.765235900878906, -5.435176849365234, -4.1051177978515625, -2.7750587463378906, -1.4450035095214844, -0.1149444580078125, 1.2151145935058594, 2.5451698303222656, 3.8752288818359375, 5.205287933349609, 6.535346984863281, 7.865406036376953, 9.19546127319336, 10.525520324707031, 11.855579376220703, 13.18563461303711, 14.515693664550781, 15.845752716064453, 17.175811767578125, 18.505870819091797, 19.835926055908203, 21.165985107421875, 22.496044158935547, 23.826099395751953, 25.156158447265625, 26.486217498779297, 27.816272735595703, 29.14633560180664, 30.476390838623047, 31.806453704833984, 33.13650894165039, 34.4665641784668, 35.796627044677734, 37.12668228149414, 38.45673751831055, 39.786800384521484, 41.11685562133789, 42.4469108581543, 43.776973724365234, 45.10702896118164, 46.43709182739258, 47.767147064208984]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 17.0, 13.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-10.644247055053711, -10.3477201461792, -10.051192283630371, -9.75466537475586, -9.458138465881348, -9.161611557006836, -8.865083694458008, -8.568556785583496, -8.272029876708984, -7.975502014160156, -7.6789751052856445, -7.382447719573975, -7.085920333862305, -6.789393424987793, -6.492866039276123, -6.196339130401611, -5.899811744689941, -5.6032843589782715, -5.30675745010376, -5.01023006439209, -4.713703155517578, -4.417175769805908, -4.120648384094238, -3.8241214752197266, -3.5275940895080566, -3.2310667037963867, -2.934539794921875, -2.6380128860473633, -2.341485023498535, -2.0449581146240234, -1.7484312057495117, -1.4519033432006836, -1.1553764343261719, -0.8588495254516602, -0.562321662902832, -0.2657947540283203, 0.030732154846191406, 0.32726001739501953, 0.6237869262695312, 0.920313835144043, 1.2168407440185547, 1.5133686065673828, 1.8098955154418945, 2.1064224243164062, 2.4029502868652344, 2.699477195739746, 2.996004104614258, 3.292531967163086, 3.5890588760375977, 3.8855857849121094, 4.1821136474609375, 4.478640556335449, 4.775167465209961, 5.071695327758789, 5.368221282958984, 5.6647491455078125, 5.961277008056641, 6.257802963256836, 6.554330825805664, 6.850858688354492, 7.1473846435546875, 7.443912506103516, 7.740440368652344, 8.036966323852539, 8.333494186401367]}, "_runtime": 816.0755245685577, "_timestamp": 1585509894.4962542, "_step": 98}
{"Episode reward": 73.71884115953219, "Episode length": 430, "Policy Loss": 0.15769222378730774, "Value Loss": 23.14861488342285, "_runtime": 817.2176291942596, "_timestamp": 1585509895.6383588, "_step": 99}
{"Episode reward": 53.614925687029086, "Episode length": 750, "Policy Loss": 0.00734078511595726, "Value Loss": 13.27916145324707, "_runtime": 818.6215102672577, "_timestamp": 1585509897.04224, "_step": 100}
{"Episode reward": 43.53042738406571, "Episode length": 921, "Policy Loss": -0.03471377491950989, "Value Loss": 10.854397773742676, "_runtime": 820.1261374950409, "_timestamp": 1585509898.5468671, "_step": 101}
{"Episode reward": -58.7370160018072, "Episode length": 999, "Policy Loss": -0.1802671253681183, "Value Loss": 0.2517506778240204, "_runtime": 821.5754923820496, "_timestamp": 1585509899.996222, "_step": 102}
{"Episode reward": 42.55473645255781, "Episode length": 947, "Policy Loss": -0.023028403520584106, "Value Loss": 10.563264846801758, "_runtime": 822.8797211647034, "_timestamp": 1585509901.3004508, "_step": 103}
{"Episode reward": 48.638519109678604, "Episode length": 852, "Policy Loss": -0.05707821249961853, "Value Loss": 12.0103120803833, "_runtime": 824.4283826351166, "_timestamp": 1585509902.8491123, "_step": 104}
{"Episode reward": -59.7115520484561, "Episode length": 999, "Policy Loss": -0.2000284045934677, "Value Loss": 0.01941191777586937, "_runtime": 825.610271692276, "_timestamp": 1585509904.0310013, "_step": 105}
{"Episode reward": 55.32254066001438, "Episode length": 762, "Policy Loss": -0.01400720700621605, "Value Loss": 13.11158561706543, "_runtime": 826.8579061031342, "_timestamp": 1585509905.2786357, "_step": 106}
{"Episode reward": 53.650855129896975, "Episode length": 810, "Policy Loss": -0.024199385195970535, "Value Loss": 12.318304061889648, "_runtime": 828.065582036972, "_timestamp": 1585509906.4863117, "_step": 107}
{"Episode reward": 53.43630205108087, "Episode length": 783, "Policy Loss": -0.01864396408200264, "Value Loss": 12.77556037902832, "_runtime": 829.6052663326263, "_timestamp": 1585509908.025996, "_step": 108}
{"Episode reward": -59.651862022476635, "Episode length": 999, "Policy Loss": -0.1780514121055603, "Value Loss": 0.02890886180102825, "_runtime": 830.9468483924866, "_timestamp": 1585509909.367578, "_step": 109}
{"Episode reward": 49.116474890005954, "Episode length": 872, "Policy Loss": -0.0058395350351929665, "Value Loss": 11.450484275817871, "_runtime": 832.2164559364319, "_timestamp": 1585509910.6371856, "_step": 110}
{"Episode reward": 50.41899713372024, "Episode length": 815, "Policy Loss": -0.05960341542959213, "Value Loss": 12.295622825622559, "_runtime": 833.5034120082855, "_timestamp": 1585509911.9241416, "_step": 111}
{"Episode reward": 51.082718094440445, "Episode length": 832, "Policy Loss": -0.06456361711025238, "Value Loss": 12.007064819335938, "_runtime": 834.4626777172089, "_timestamp": 1585509912.8834074, "_step": 112}
{"Episode reward": 63.49152705021175, "Episode length": 618, "Policy Loss": 0.003952715080231428, "Value Loss": 16.113563537597656, "_runtime": 835.6264786720276, "_timestamp": 1585509914.0472083, "_step": 113}
{"Episode reward": 57.15546091215816, "Episode length": 761, "Policy Loss": -0.008734970353543758, "Value Loss": 13.083786964416504, "_runtime": 836.5974614620209, "_timestamp": 1585509915.018191, "_step": 114}
{"Episode reward": 62.64126316982403, "Episode length": 631, "Policy Loss": 0.10117078572511673, "Value Loss": 15.830304145812988, "_runtime": 837.3166134357452, "_timestamp": 1585509915.737343, "_step": 115}
{"Episode reward": 72.16498063912161, "Episode length": 477, "Policy Loss": 0.08097293227910995, "Value Loss": 20.829334259033203, "_runtime": 838.8607914447784, "_timestamp": 1585509917.281521, "_step": 116}
{"Episode reward": -61.68733743495997, "Episode length": 999, "Policy Loss": -0.15229344367980957, "Value Loss": 0.026450984179973602, "_runtime": 839.7571425437927, "_timestamp": 1585509918.1778722, "_step": 117}
{"Episode reward": 65.03058546755662, "Episode length": 590, "Policy Loss": 0.01787610538303852, "Value Loss": 16.86250114440918, "_runtime": 840.699901342392, "_timestamp": 1585509919.120631, "_step": 118}
{"Episode reward": 62.511966780801465, "Episode length": 629, "Policy Loss": 0.06372247636318207, "Value Loss": 15.78867244720459, "_runtime": 841.658668756485, "_timestamp": 1585509920.0793984, "_step": 119}
{"Episode reward": 63.00729723324925, "Episode length": 624, "Policy Loss": -0.020234210416674614, "Value Loss": 15.966931343078613, "_runtime": 843.1667857170105, "_timestamp": 1585509921.5875154, "_step": 120}
{"Episode reward": -58.864004417522615, "Episode length": 999, "Policy Loss": -0.17916348576545715, "Value Loss": 0.03742522746324539, "_runtime": 844.6696729660034, "_timestamp": 1585509923.0904026, "_step": 121}
{"Episode reward": -61.949429472385866, "Episode length": 999, "Policy Loss": -0.1902269423007965, "Value Loss": 0.018890265375375748, "_runtime": 845.3818249702454, "_timestamp": 1585509923.8025546, "_step": 122}
{"Episode reward": 72.115701644981, "Episode length": 463, "Policy Loss": 0.19659370183944702, "Value Loss": 21.59309196472168, "_runtime": 846.9178628921509, "_timestamp": 1585509925.3385925, "_step": 123}
{"Episode reward": -59.65389074543337, "Episode length": 999, "Policy Loss": -0.1825844943523407, "Value Loss": 0.022043801844120026, "_runtime": 848.0562403202057, "_timestamp": 1585509926.47697, "_step": 124}
{"Episode reward": 53.475745055856336, "Episode length": 737, "Policy Loss": -0.037079717963933945, "Value Loss": 13.493793487548828, "_runtime": 849.3186731338501, "_timestamp": 1585509927.7394028, "_step": 125}
{"Episode reward": 50.467042252753444, "Episode length": 846, "Policy Loss": -0.017026184126734734, "Value Loss": 11.814240455627441, "_runtime": 850.6231234073639, "_timestamp": 1585509929.043853, "_step": 126}
{"Episode reward": 49.52662404740848, "Episode length": 852, "Policy Loss": -0.015603182837367058, "Value Loss": 11.70295238494873, "_runtime": 851.8733973503113, "_timestamp": 1585509930.294127, "_step": 127}
{"Episode reward": 53.12911392103292, "Episode length": 818, "Policy Loss": -0.0025495896115899086, "Value Loss": 12.171738624572754, "_runtime": 852.6035912036896, "_timestamp": 1585509931.0243208, "_step": 128}
{"Episode reward": 72.0262976057901, "Episode length": 469, "Policy Loss": 0.09087923914194107, "Value Loss": 21.14675521850586, "_runtime": 854.1330423355103, "_timestamp": 1585509932.553772, "_step": 129}
{"Episode reward": -58.386539164266324, "Episode length": 999, "Policy Loss": -0.15963251888751984, "Value Loss": 0.030825220048427582, "_runtime": 855.089852809906, "_timestamp": 1585509933.5105824, "_step": 130}
{"Episode reward": 63.84314137188982, "Episode length": 618, "Policy Loss": 0.03282872214913368, "Value Loss": 15.99959659576416, "_runtime": 856.584018945694, "_timestamp": 1585509935.0047486, "_step": 131}
{"Episode reward": -61.24372002639255, "Episode length": 999, "Policy Loss": -0.1564595103263855, "Value Loss": 0.028428107500076294, "_runtime": 857.9239213466644, "_timestamp": 1585509936.344651, "_step": 132}
{"Episode reward": 49.15501567258258, "Episode length": 875, "Policy Loss": -0.009216397069394588, "Value Loss": 11.440765380859375, "_runtime": 859.4299330711365, "_timestamp": 1585509937.8506627, "_step": 133}
{"Episode reward": -59.47083507132469, "Episode length": 999, "Policy Loss": -0.16380371153354645, "Value Loss": 0.03956377133727074, "_runtime": 860.6238338947296, "_timestamp": 1585509939.0445635, "_step": 134}
{"Episode reward": 54.3119225474122, "Episode length": 781, "Policy Loss": 0.029555607587099075, "Value Loss": 12.743947982788086, "_runtime": 862.1868410110474, "_timestamp": 1585509940.6075706, "_step": 135}
{"Episode reward": -58.78339954446611, "Episode length": 999, "Policy Loss": -0.17288018763065338, "Value Loss": 0.033607274293899536, "_runtime": 863.0284016132355, "_timestamp": 1585509941.4491313, "_step": 136}
{"Episode reward": 69.54183262360502, "Episode length": 535, "Policy Loss": 0.10392565280199051, "Value Loss": 18.619441986083984, "_runtime": 863.9318709373474, "_timestamp": 1585509942.3526006, "_step": 137}
{"Episode reward": 63.954296761364404, "Episode length": 590, "Policy Loss": 0.04554431885480881, "Value Loss": 16.85700035095215, "_runtime": 864.9430420398712, "_timestamp": 1585509943.3637717, "_step": 138}
{"Episode reward": 63.78070721581653, "Episode length": 660, "Policy Loss": 0.30591267347335815, "Value Loss": 15.044610977172852, "_runtime": 866.0968697071075, "_timestamp": 1585509944.5175993, "_step": 139}
{"Episode reward": 54.63455261849107, "Episode length": 775, "Policy Loss": 0.11020553857088089, "Value Loss": 12.805278778076172, "_runtime": 867.3646728992462, "_timestamp": 1585509945.7854025, "_step": 140}
{"Episode reward": 48.2746559943909, "Episode length": 846, "Policy Loss": -0.0410369448363781, "Value Loss": 11.740650177001953, "_runtime": 868.4958553314209, "_timestamp": 1585509946.916585, "_step": 141}
{"Episode reward": 56.080862002168644, "Episode length": 751, "Policy Loss": 0.04309389367699623, "Value Loss": 13.166626930236816, "_runtime": 869.4674706459045, "_timestamp": 1585509947.8882003, "_step": 142}
{"Episode reward": 63.14887822777396, "Episode length": 633, "Policy Loss": 0.06871012598276138, "Value Loss": 15.579113960266113, "_runtime": 870.7116630077362, "_timestamp": 1585509949.1323926, "_step": 143}
{"Episode reward": 50.541687949209845, "Episode length": 818, "Policy Loss": -0.014308247715234756, "Value Loss": 12.174280166625977, "_runtime": 871.6965374946594, "_timestamp": 1585509950.1172671, "_step": 144}
{"Episode reward": 61.66121177546982, "Episode length": 646, "Policy Loss": 0.011757838539779186, "Value Loss": 15.393545150756836, "_runtime": 872.8001248836517, "_timestamp": 1585509951.2208545, "_step": 145}
{"Episode reward": 59.15337013144598, "Episode length": 730, "Policy Loss": 0.00939815305173397, "Value Loss": 13.522661209106445, "_runtime": 874.3090512752533, "_timestamp": 1585509952.729781, "_step": 146}
{"Episode reward": -59.849213255030065, "Episode length": 999, "Policy Loss": -0.16211801767349243, "Value Loss": 0.030342111364006996, "_runtime": 875.7875275611877, "_timestamp": 1585509954.2082572, "_step": 147}
{"Episode reward": 43.10288109107811, "Episode length": 982, "Policy Loss": -0.03597644716501236, "Value Loss": 10.088050842285156, "_runtime": 876.9246220588684, "_timestamp": 1585509955.3453517, "_step": 148}
{"Episode reward": 57.37705876184171, "Episode length": 757, "Policy Loss": 0.01969172991812229, "Value Loss": 13.098132133483887, "_runtime": 878.4485783576965, "_timestamp": 1585509956.869308, "_step": 149}
{"Episode reward": -57.7819378890852, "Episode length": 999, "Policy Loss": -0.1611962616443634, "Value Loss": 0.016879066824913025, "_runtime": 879.5093564987183, "_timestamp": 1585509957.9300861, "_step": 150}
{"Episode reward": 60.65720978798983, "Episode length": 683, "Policy Loss": -0.0057193078100681305, "Value Loss": 14.529241561889648, "_runtime": 880.2926995754242, "_timestamp": 1585509958.7134292, "_step": 151}
{"Episode reward": 69.74694386066132, "Episode length": 513, "Policy Loss": 0.0826224684715271, "Value Loss": 19.297977447509766, "_runtime": 881.6039872169495, "_timestamp": 1585509960.0247169, "_step": 152}
{"Episode reward": 47.8413140992382, "Episode length": 861, "Policy Loss": -0.016924995929002762, "Value Loss": 11.522194862365723, "_runtime": 882.4062256813049, "_timestamp": 1585509960.8269553, "_step": 153}
{"Episode reward": 69.67500893945774, "Episode length": 520, "Policy Loss": 0.050165507942438126, "Value Loss": 18.947078704833984, "_runtime": 883.6112408638, "_timestamp": 1585509962.0319705, "_step": 154}
{"Episode reward": 51.315860281515484, "Episode length": 808, "Policy Loss": -0.02169335074722767, "Value Loss": 12.178583145141602, "_runtime": 884.5324285030365, "_timestamp": 1585509962.9531581, "_step": 155}
{"Episode reward": 65.26287938458978, "Episode length": 598, "Policy Loss": 0.06729840487241745, "Value Loss": 16.551536560058594, "_runtime": 885.3507437705994, "_timestamp": 1585509963.7714734, "_step": 156}
{"Episode reward": 69.78116744383937, "Episode length": 540, "Policy Loss": 0.1237286776304245, "Value Loss": 18.34464454650879, "_runtime": 886.5745146274567, "_timestamp": 1585509964.9952443, "_step": 157}
{"Episode reward": 53.0412308832333, "Episode length": 807, "Policy Loss": -0.017982900142669678, "Value Loss": 12.162843704223633, "_runtime": 888.099203824997, "_timestamp": 1585509966.5199335, "_step": 158}
{"Episode reward": -59.58676816316909, "Episode length": 999, "Policy Loss": -0.14247743785381317, "Value Loss": 0.013888995163142681, "_runtime": 889.5938959121704, "_timestamp": 1585509968.0146255, "_step": 159}
{"Episode reward": -59.753657523677894, "Episode length": 999, "Policy Loss": -0.15091268718242645, "Value Loss": 0.03802916035056114, "_runtime": 890.4551250934601, "_timestamp": 1585509968.8758547, "_step": 160}
{"Episode reward": 68.03686504982694, "Episode length": 556, "Policy Loss": 0.00037859895383007824, "Value Loss": 17.803850173950195, "_runtime": 891.9894926548004, "_timestamp": 1585509970.4102223, "_step": 161}
{"Episode reward": -57.826794780219856, "Episode length": 999, "Policy Loss": -0.15025600790977478, "Value Loss": 0.023474741727113724, "_runtime": 892.8597326278687, "_timestamp": 1585509971.2804623, "_step": 162}
{"Episode reward": 66.33461168559745, "Episode length": 564, "Policy Loss": 0.08160267770290375, "Value Loss": 17.299280166625977, "_runtime": 893.8880922794342, "_timestamp": 1585509972.308822, "_step": 163}
{"Episode reward": 57.38679554883637, "Episode length": 685, "Policy Loss": 0.2724758982658386, "Value Loss": 14.2594633102417, "_runtime": 894.7312252521515, "_timestamp": 1585509973.151955, "_step": 164}
{"Episode reward": 69.49611375841059, "Episode length": 539, "Policy Loss": 0.5526691675186157, "Value Loss": 18.191377639770508, "_runtime": 895.5384919643402, "_timestamp": 1585509973.9592216, "_step": 165}
{"Episode reward": 68.99029866997311, "Episode length": 534, "Policy Loss": 0.0903858095407486, "Value Loss": 18.40082359313965, "_runtime": 897.0359842777252, "_timestamp": 1585509975.456714, "_step": 166}
{"Episode reward": -58.25631233624835, "Episode length": 999, "Policy Loss": -0.14558805525302887, "Value Loss": 0.1344127058982849, "_runtime": 897.4724884033203, "_timestamp": 1585509975.893218, "_step": 167}
{"Episode reward": 84.95682865758832, "Episode length": 284, "Policy Loss": 0.12360473722219467, "Value Loss": 34.02985382080078, "_runtime": 898.6159853935242, "_timestamp": 1585509977.036715, "_step": 168}
{"Episode reward": 56.069156859980374, "Episode length": 771, "Policy Loss": -0.07596023380756378, "Value Loss": 12.782069206237793, "_runtime": 899.7678117752075, "_timestamp": 1585509978.1885414, "_step": 169}
{"Episode reward": 55.06486864541733, "Episode length": 752, "Policy Loss": 0.23267105221748352, "Value Loss": 12.821737289428711, "_runtime": 900.3029496669769, "_timestamp": 1585509978.7236793, "_step": 170}
{"Episode reward": 79.41791122698955, "Episode length": 358, "Policy Loss": 0.14161671698093414, "Value Loss": 27.059646606445312, "_runtime": 901.375159740448, "_timestamp": 1585509979.7958894, "_step": 171}
{"Episode reward": 59.882770824884794, "Episode length": 714, "Policy Loss": 0.06567467749118805, "Value Loss": 13.676328659057617, "_runtime": 902.3504559993744, "_timestamp": 1585509980.7711856, "_step": 172}
{"Episode reward": 62.82324533964642, "Episode length": 643, "Policy Loss": -0.04698530584573746, "Value Loss": 15.26256275177002, "_runtime": 903.5130131244659, "_timestamp": 1585509981.9337428, "_step": 173}
{"Episode reward": 55.27101715671189, "Episode length": 794, "Policy Loss": -0.009224233217537403, "Value Loss": 12.180477142333984, "_runtime": 904.1629858016968, "_timestamp": 1585509982.5837154, "_step": 174}
{"Episode reward": 77.45986763455386, "Episode length": 423, "Policy Loss": 0.04193955287337303, "Value Loss": 22.881513595581055, "_runtime": 905.2967896461487, "_timestamp": 1585509983.7175193, "_step": 175}
{"Episode reward": 57.428022805415225, "Episode length": 754, "Policy Loss": 0.4507397711277008, "Value Loss": 12.78022575378418, "_runtime": 906.0927603244781, "_timestamp": 1585509984.51349, "_step": 176}
{"Episode reward": 70.80144843652731, "Episode length": 520, "Policy Loss": 0.06589502841234207, "Value Loss": 18.637428283691406, "_runtime": 907.5353832244873, "_timestamp": 1585509985.9561129, "_step": 177}
{"Episode reward": 45.342262639116676, "Episode length": 973, "Policy Loss": -0.04272414371371269, "Value Loss": 9.979822158813477, "_runtime": 908.2976682186127, "_timestamp": 1585509986.7183979, "_step": 178}
{"Episode reward": 70.59402544365831, "Episode length": 503, "Policy Loss": 0.0637725293636322, "Value Loss": 18.793258666992188, "_runtime": 909.275951385498, "_timestamp": 1585509987.696681, "_step": 179}
{"Episode reward": 63.178183703458, "Episode length": 653, "Policy Loss": 0.08087877184152603, "Value Loss": 14.628211975097656, "_runtime": 910.0671079158783, "_timestamp": 1585509988.4878376, "_step": 180}
{"Episode reward": 70.92243007690794, "Episode length": 510, "Policy Loss": 0.09230978041887283, "Value Loss": 18.423824310302734, "_runtime": 910.519697189331, "_timestamp": 1585509988.9404268, "_step": 181}
{"Episode reward": 83.45838520617686, "Episode length": 292, "Policy Loss": 0.15260574221611023, "Value Loss": 32.60896301269531, "_runtime": 911.6445560455322, "_timestamp": 1585509990.0652857, "_step": 182}
{"Episode reward": 57.028111298228055, "Episode length": 760, "Policy Loss": 0.08367308229207993, "Value Loss": 12.672738075256348, "_runtime": 913.1586856842041, "_timestamp": 1585509991.5794153, "_step": 183}
{"Episode reward": -58.77569029290033, "Episode length": 999, "Policy Loss": -0.15318810939788818, "Value Loss": 0.174943745136261, "_runtime": 914.6334738731384, "_timestamp": 1585509993.0542035, "_step": 184}
{"Episode reward": -57.24314417437502, "Episode length": 999, "Policy Loss": -0.15504439175128937, "Value Loss": 0.12457440793514252, "_runtime": 916.1340107917786, "_timestamp": 1585509994.5547404, "_step": 185}
{"Episode reward": 42.75713571378864, "Episode length": 991, "Policy Loss": -0.01269999984651804, "Value Loss": 9.443477630615234, "_runtime": 917.5630896091461, "_timestamp": 1585509995.9838192, "_step": 186}
{"Episode reward": 48.10970871405427, "Episode length": 927, "Policy Loss": 0.008964601904153824, "Value Loss": 10.089579582214355, "_runtime": 918.8466453552246, "_timestamp": 1585509997.267375, "_step": 187}
{"Episode reward": 52.88259819539601, "Episode length": 841, "Policy Loss": -0.014245543628931046, "Value Loss": 11.74161148071289, "_runtime": 919.7445285320282, "_timestamp": 1585509998.1652582, "_step": 188}
{"Episode reward": 67.56790383622791, "Episode length": 575, "Policy Loss": 0.16649627685546875, "Value Loss": 16.470680236816406, "_runtime": 920.4446787834167, "_timestamp": 1585509998.8654084, "_step": 189}
{"Episode reward": 75.4296698136618, "Episode length": 443, "Policy Loss": 0.3526003360748291, "Value Loss": 21.551733016967773, "_runtime": 921.5715124607086, "_timestamp": 1585509999.992242, "_step": 190}
{"Episode reward": 55.59353395633459, "Episode length": 744, "Policy Loss": 0.01640979014337063, "Value Loss": 13.13321590423584, "_runtime": 922.6610825061798, "_timestamp": 1585510001.0818121, "_step": 191}
{"Episode reward": 56.055974962717826, "Episode length": 722, "Policy Loss": 0.19439412653446198, "Value Loss": 12.69704532623291, "_runtime": 924.1492471694946, "_timestamp": 1585510002.5699768, "_step": 192}
{"Episode reward": -56.586164114442425, "Episode length": 999, "Policy Loss": -0.09676794707775116, "Value Loss": 0.3380891680717468, "_runtime": 925.6634631156921, "_timestamp": 1585510004.0841928, "_step": 193}
{"Episode reward": -58.88792049292159, "Episode length": 999, "Policy Loss": -0.11704529076814651, "Value Loss": 0.04394283890724182, "_runtime": 926.4775936603546, "_timestamp": 1585510004.8983233, "_step": 194}
{"Episode reward": 70.21899548690739, "Episode length": 527, "Policy Loss": 0.14059574902057648, "Value Loss": 17.953584671020508, "_runtime": 928.0117964744568, "_timestamp": 1585510006.432526, "_step": 195}
{"Episode reward": -58.12373522986508, "Episode length": 999, "Policy Loss": -0.165232315659523, "Value Loss": 0.17617835104465485, "_runtime": 929.5427644252777, "_timestamp": 1585510007.963494, "_step": 196}
{"Episode reward": -56.430958738544895, "Episode length": 999, "Policy Loss": -0.1609245091676712, "Value Loss": 0.19354145228862762, "_runtime": 931.0445334911346, "_timestamp": 1585510009.4652631, "_step": 197}
{"Episode reward": -57.200704532724075, "Episode length": 999, "Policy Loss": -0.1897619068622589, "Value Loss": 0.5313471555709839, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039, 63.16922378540039]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-30.10533905029297, -29.069900512695312, -28.03446388244629, -26.999025344848633, -25.96358871459961, -24.928150177001953, -23.892711639404297, -22.85727310180664, -21.821836471557617, -20.786399841308594, -19.750961303710938, -18.71552276611328, -17.680084228515625, -16.6446475982666, -15.609209060668945, -14.573771476745605, -13.538333892822266, -12.50289535522461, -11.467458724975586, -10.43202018737793, -9.396583557128906, -8.36114501953125, -7.325706481933594, -6.29026985168457, -5.254831314086914, -4.219392776489258, -3.1839561462402344, -2.148517608642578, -1.1130790710449219, -0.07764244079589844, 0.9577960968017578, 1.9932327270507812, 3.0286712646484375, 4.064109802246094, 5.09954833984375, 6.134983062744141, 7.170421600341797, 8.205860137939453, 9.24129867553711, 10.276737213134766, 11.312171936035156, 12.347610473632812, 13.383049011230469, 14.418487548828125, 15.453926086425781, 16.489364624023438, 17.524799346923828, 18.560237884521484, 19.59567642211914, 20.631114959716797, 21.666553497314453, 22.701988220214844, 23.7374267578125, 24.772865295410156, 25.808303833007812, 26.84374237060547, 27.879180908203125, 28.914615631103516, 29.950054168701172, 30.985492706298828, 32.020931243896484, 33.05636978149414, 34.09180450439453, 35.12724304199219, 36.162681579589844]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-26.79555892944336, -25.827898025512695, -24.86023712158203, -23.892576217651367, -22.924915313720703, -21.957252502441406, -20.989593505859375, -20.021930694580078, -19.054269790649414, -18.08660888671875, -17.118947982788086, -16.151287078857422, -15.183626174926758, -14.215965270996094, -13.248303413391113, -12.28064250946045, -11.312981605529785, -10.345319747924805, -9.37765884399414, -8.409997940063477, -7.4423370361328125, -6.474676132202148, -5.507015228271484, -4.53935432434082, -3.5716934204101562, -2.604032516479492, -1.6363716125488281, -0.6687088012695312, 0.2989521026611328, 1.2666130065917969, 2.234273910522461, 3.201934814453125, 4.169595718383789, 5.137256622314453, 6.10491943359375, 7.072578430175781, 8.040241241455078, 9.00790023803711, 9.975563049316406, 10.943222045898438, 11.910884857177734, 12.878543853759766, 13.846206665039062, 14.81386947631836, 15.78152847290039, 16.749191284179688, 17.71685028076172, 18.684513092041016, 19.652172088623047, 20.619834899902344, 21.587493896484375, 22.555156707763672, 23.522815704345703, 24.490478515625, 25.458141326904297, 26.425800323486328, 27.393463134765625, 28.361122131347656, 29.328784942626953, 30.296443939208984, 31.26410675048828, 32.23176574707031, 33.19942855834961, 34.16708755493164, 35.13475036621094]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 7.0, 8.0, 8.0, 10.0, 10.0, 13.0, 14.0, 8.0, 17.0, 21.0, 18.0, 25.0, 23.0, 36.0, 51.0, 22.0, 14.0, 19.0, 20.0, 16.0, 15.0, 15.0, 8.0, 11.0, 5.0, 13.0, 6.0, 3.0, 3.0, 5.0, 4.0, 4.0, 6.0, 4.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-17.484819412231445, -16.885499954223633, -16.286178588867188, -15.686858177185059, -15.08753776550293, -14.488218307495117, -13.888897895812988, -13.28957748413086, -12.69025707244873, -12.090936660766602, -11.491616249084473, -10.892295837402344, -10.292976379394531, -9.693655014038086, -9.094335556030273, -8.495015144348145, -7.895694732666016, -7.296374320983887, -6.697053909301758, -6.097733497619629, -5.4984130859375, -4.8990936279296875, -4.299773216247559, -3.7004528045654297, -3.101132392883301, -2.501811981201172, -1.902491569519043, -1.303171157836914, -0.7038516998291016, -0.10453033447265625, 0.49478912353515625, 1.0941104888916016, 1.693429946899414, 2.2927494049072266, 2.892070770263672, 3.4913902282714844, 4.09071159362793, 4.690031051635742, 5.2893524169921875, 5.888671875, 6.487993240356445, 7.087312698364258, 7.68663215637207, 8.285953521728516, 8.885272979736328, 9.484594345092773, 10.083913803100586, 10.683235168457031, 11.282554626464844, 11.881874084472656, 12.481195449829102, 13.080514907836914, 13.67983627319336, 14.279155731201172, 14.878477096557617, 15.47779655456543, 16.077116012573242, 16.676435470581055, 17.275758743286133, 17.875078201293945, 18.474397659301758, 19.07371711730957, 19.67304039001465, 20.27235984802246, 20.871679306030273]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-22.845478057861328, -22.039100646972656, -21.232723236083984, -20.426345825195312, -19.619970321655273, -18.8135929107666, -18.00721549987793, -17.200838088989258, -16.39446258544922, -15.588085174560547, -14.781707763671875, -13.975330352783203, -13.168952941894531, -12.362576484680176, -11.556199073791504, -10.749822616577148, -9.943445205688477, -9.137067794799805, -8.33069133758545, -7.524313926696777, -6.717937469482422, -5.91156005859375, -5.105182647705078, -4.298805236816406, -3.4924278259277344, -2.6860523223876953, -1.8796749114990234, -1.0732975006103516, -0.2669200897216797, 0.5394573211669922, 1.3458328247070312, 2.152210235595703, 2.958587646484375, 3.764965057373047, 4.571342468261719, 5.377717971801758, 6.18409538269043, 6.990472793579102, 7.796850204467773, 8.603227615356445, 9.409603118896484, 10.215980529785156, 11.022357940673828, 11.8287353515625, 12.635112762451172, 13.441490173339844, 14.247867584228516, 15.054244995117188, 15.86062240600586, 16.666996002197266, 17.473373413085938, 18.27975082397461, 19.08612823486328, 19.892505645751953, 20.698883056640625, 21.505260467529297, 22.31163787841797, 23.11801528930664, 23.924392700195312, 24.73076629638672, 25.53714370727539, 26.343521118164062, 27.149898529052734, 27.956275939941406, 28.762653350830078]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-10.203283309936523, -9.857595443725586, -9.511908531188965, -9.166220664978027, -8.820533752441406, -8.474845886230469, -8.129158020019531, -7.78347110748291, -7.437783241271973, -7.092096328735352, -6.746408462524414, -6.400721073150635, -6.0550336837768555, -5.709346294403076, -5.363658428192139, -5.017971038818359, -4.67228364944458, -4.326596260070801, -3.9809088706970215, -3.635221004486084, -3.2895336151123047, -2.9438462257385254, -2.598158836364746, -2.252471446990967, -1.9067840576171875, -1.56109619140625, -1.215409278869629, -0.8697214126586914, -0.5240335464477539, -0.1783466339111328, 0.1673412322998047, 0.5130281448364258, 0.8587160110473633, 1.2044038772583008, 1.5500907897949219, 1.8957786560058594, 2.2414655685424805, 2.587153434753418, 2.9328413009643555, 3.2785282135009766, 3.624216079711914, 3.969902992248535, 4.315590858459473, 4.66127872467041, 5.006965637207031, 5.352653503417969, 5.69834041595459, 6.044027328491211, 6.389715194702148, 6.735403060913086, 7.081090927124023, 7.426778793334961, 7.772464752197266, 8.118152618408203, 8.46384048461914, 8.809528350830078, 9.155216217041016, 9.50090217590332, 9.846590042114258, 10.192277908325195, 10.537965774536133, 10.88365364074707, 11.229339599609375, 11.575027465820312, 11.92071533203125]}, "_runtime": 932.4755370616913, "_timestamp": 1585510010.8962667, "_step": 198}
{"Episode reward": 45.94105801778844, "Episode length": 929, "Policy Loss": -0.0617857426404953, "Value Loss": 10.457561492919922, "_runtime": 933.8701357841492, "_timestamp": 1585510012.2908654, "_step": 199}
{"Episode reward": 48.80153790607313, "Episode length": 900, "Policy Loss": -0.05113520845770836, "Value Loss": 10.617554664611816, "_runtime": 934.9386692047119, "_timestamp": 1585510013.3593988, "_step": 200}
{"Episode reward": 61.534031108865015, "Episode length": 688, "Policy Loss": 0.24864628911018372, "Value Loss": 16.471261978149414, "_runtime": 936.5013535022736, "_timestamp": 1585510014.9220831, "_step": 201}
{"Episode reward": -58.873801224840776, "Episode length": 999, "Policy Loss": -0.18976114690303802, "Value Loss": 0.06758560985326767, "_runtime": 938.0561664104462, "_timestamp": 1585510016.476896, "_step": 202}
{"Episode reward": -57.65315603518103, "Episode length": 999, "Policy Loss": -0.24366545677185059, "Value Loss": 0.6961862444877625, "_runtime": 939.5686142444611, "_timestamp": 1585510017.989344, "_step": 203}
{"Episode reward": -56.92511627769686, "Episode length": 999, "Policy Loss": -0.2573583424091339, "Value Loss": 0.16711688041687012, "_runtime": 941.094443321228, "_timestamp": 1585510019.515173, "_step": 204}
{"Episode reward": -57.65366662374574, "Episode length": 999, "Policy Loss": -0.2674751579761505, "Value Loss": 0.07253866642713547, "_runtime": 942.4890058040619, "_timestamp": 1585510020.9097354, "_step": 205}
{"Episode reward": 46.22958036048433, "Episode length": 908, "Policy Loss": -0.1542329341173172, "Value Loss": 11.299797058105469, "_runtime": 943.6335244178772, "_timestamp": 1585510022.054254, "_step": 206}
{"Episode reward": 56.77085665373495, "Episode length": 749, "Policy Loss": -0.0904417484998703, "Value Loss": 13.748637199401855, "_runtime": 944.6056623458862, "_timestamp": 1585510023.026392, "_step": 207}
{"Episode reward": 64.19368960018366, "Episode length": 629, "Policy Loss": -0.05135839059948921, "Value Loss": 16.036441802978516, "_runtime": 946.1312384605408, "_timestamp": 1585510024.551968, "_step": 208}
{"Episode reward": -58.30452233176826, "Episode length": 999, "Policy Loss": -0.24596887826919556, "Value Loss": 0.03244830667972565, "_runtime": 947.6505784988403, "_timestamp": 1585510026.0713081, "_step": 209}
{"Episode reward": -59.292175527669656, "Episode length": 999, "Policy Loss": -0.25324222445487976, "Value Loss": 0.031782105565071106, "_runtime": 948.7774243354797, "_timestamp": 1585510027.198154, "_step": 210}
{"Episode reward": 57.69946250724032, "Episode length": 752, "Policy Loss": -0.10321774333715439, "Value Loss": 13.288747787475586, "_runtime": 949.4907622337341, "_timestamp": 1585510027.9114919, "_step": 211}
{"Episode reward": 73.38367188837441, "Episode length": 458, "Policy Loss": 0.00641213683411479, "Value Loss": 21.81201934814453, "_runtime": 950.8294169902802, "_timestamp": 1585510029.2501466, "_step": 212}
{"Episode reward": 48.43588454411361, "Episode length": 882, "Policy Loss": -0.12451386451721191, "Value Loss": 11.334083557128906, "_runtime": 952.3354387283325, "_timestamp": 1585510030.7561684, "_step": 213}
{"Episode reward": -55.74302649283919, "Episode length": 999, "Policy Loss": -0.21765445172786713, "Value Loss": 0.026702582836151123, "_runtime": 953.0825672149658, "_timestamp": 1585510031.5032969, "_step": 214}
{"Episode reward": 69.71817236770455, "Episode length": 498, "Policy Loss": 0.003650868311524391, "Value Loss": 20.059925079345703, "_runtime": 954.1837756633759, "_timestamp": 1585510032.6045053, "_step": 215}
{"Episode reward": 59.516507740451914, "Episode length": 727, "Policy Loss": -0.041893716901540756, "Value Loss": 13.73836612701416, "_runtime": 955.1757664680481, "_timestamp": 1585510033.596496, "_step": 216}
{"Episode reward": 63.587671884277356, "Episode length": 645, "Policy Loss": 0.07170780003070831, "Value Loss": 15.496768951416016, "_runtime": 956.1878988742828, "_timestamp": 1585510034.6086285, "_step": 217}
{"Episode reward": 60.98005834062245, "Episode length": 680, "Policy Loss": -0.06814664602279663, "Value Loss": 14.673437118530273, "_runtime": 956.8358013629913, "_timestamp": 1585510035.256531, "_step": 218}
{"Episode reward": 74.94061737544811, "Episode length": 426, "Policy Loss": 0.10930278152227402, "Value Loss": 23.44696807861328, "_runtime": 957.6953792572021, "_timestamp": 1585510036.116109, "_step": 219}
{"Episode reward": 68.44140809221197, "Episode length": 572, "Policy Loss": -0.025594331324100494, "Value Loss": 17.458982467651367, "_runtime": 958.6910405158997, "_timestamp": 1585510037.1117702, "_step": 220}
{"Episode reward": 63.5206505935285, "Episode length": 641, "Policy Loss": 0.11571814864873886, "Value Loss": 15.573978424072266, "_runtime": 959.5918679237366, "_timestamp": 1585510038.0125976, "_step": 221}
{"Episode reward": 65.69783694194538, "Episode length": 611, "Policy Loss": 0.218014657497406, "Value Loss": 16.327600479125977, "_runtime": 961.0712823867798, "_timestamp": 1585510039.492012, "_step": 222}
{"Episode reward": -55.914352151295006, "Episode length": 999, "Policy Loss": -0.20177288353443146, "Value Loss": 0.021934261545538902, "_runtime": 961.9657006263733, "_timestamp": 1585510040.3864303, "_step": 223}
{"Episode reward": 64.8816056946498, "Episode length": 598, "Policy Loss": 0.028973694890737534, "Value Loss": 16.714405059814453, "_runtime": 963.44731092453, "_timestamp": 1585510041.8680406, "_step": 224}
{"Episode reward": -57.3564557529318, "Episode length": 999, "Policy Loss": -0.20652471482753754, "Value Loss": 0.021579546853899956, "_runtime": 964.6915421485901, "_timestamp": 1585510043.1122718, "_step": 225}
{"Episode reward": 53.71621646352693, "Episode length": 818, "Policy Loss": -0.0197132658213377, "Value Loss": 12.225685119628906, "_runtime": 965.7104876041412, "_timestamp": 1585510044.1312172, "_step": 226}
{"Episode reward": 60.32686776724102, "Episode length": 677, "Policy Loss": -0.021664761006832123, "Value Loss": 14.767426490783691, "_runtime": 966.6665041446686, "_timestamp": 1585510045.0872338, "_step": 227}
{"Episode reward": 66.31383774950599, "Episode length": 619, "Policy Loss": 0.07730090618133545, "Value Loss": 16.147933959960938, "_runtime": 968.1670973300934, "_timestamp": 1585510046.587827, "_step": 228}
{"Episode reward": -56.06575964656445, "Episode length": 999, "Policy Loss": -0.1943655014038086, "Value Loss": 0.019761264324188232, "_runtime": 969.6624586582184, "_timestamp": 1585510048.0831883, "_step": 229}
{"Episode reward": -57.766851626399294, "Episode length": 999, "Policy Loss": -0.19307386875152588, "Value Loss": 0.019818933680653572, "_runtime": 971.1516075134277, "_timestamp": 1585510049.5723372, "_step": 230}
{"Episode reward": -56.69849197909338, "Episode length": 999, "Policy Loss": -0.18396708369255066, "Value Loss": 0.01900663785636425, "_runtime": 972.16486287117, "_timestamp": 1585510050.5855925, "_step": 231}
{"Episode reward": 62.721914814810994, "Episode length": 660, "Policy Loss": -0.03572656586766243, "Value Loss": 15.139602661132812, "_runtime": 973.5171718597412, "_timestamp": 1585510051.9379015, "_step": 232}
{"Episode reward": 47.138031246321155, "Episode length": 886, "Policy Loss": 0.009906310588121414, "Value Loss": 11.289167404174805, "_runtime": 974.1626994609833, "_timestamp": 1585510052.583429, "_step": 233}
{"Episode reward": 77.18830867949055, "Episode length": 412, "Policy Loss": 0.06155294552445412, "Value Loss": 24.20699119567871, "_runtime": 975.2983329296112, "_timestamp": 1585510053.7190626, "_step": 234}
{"Episode reward": 56.027199337567104, "Episode length": 761, "Policy Loss": 0.10636881738901138, "Value Loss": 13.138023376464844, "_runtime": 976.216016292572, "_timestamp": 1585510054.636746, "_step": 235}
{"Episode reward": 64.97099455179281, "Episode length": 605, "Policy Loss": 0.02045031264424324, "Value Loss": 16.52315902709961, "_runtime": 977.7150497436523, "_timestamp": 1585510056.1357794, "_step": 236}
{"Episode reward": -56.98634061656838, "Episode length": 999, "Policy Loss": -0.17791330814361572, "Value Loss": 0.016772527247667313, "_runtime": 979.2190382480621, "_timestamp": 1585510057.639768, "_step": 237}
{"Episode reward": -58.035066835763836, "Episode length": 999, "Policy Loss": -0.17388422787189484, "Value Loss": 0.016736863180994987, "_runtime": 980.5286672115326, "_timestamp": 1585510058.9493968, "_step": 238}
{"Episode reward": 49.26970434314388, "Episode length": 872, "Policy Loss": 0.10799482464790344, "Value Loss": 11.460323333740234, "_runtime": 981.5549423694611, "_timestamp": 1585510059.975672, "_step": 239}
{"Episode reward": 62.521288672521266, "Episode length": 668, "Policy Loss": 0.17725440859794617, "Value Loss": 14.946547508239746, "_runtime": 983.1259579658508, "_timestamp": 1585510061.5466876, "_step": 240}
{"Episode reward": -55.6825464763095, "Episode length": 999, "Policy Loss": -0.1584758162498474, "Value Loss": 0.015125849284231663, "_runtime": 984.2663748264313, "_timestamp": 1585510062.6871045, "_step": 241}
{"Episode reward": 58.45878341296761, "Episode length": 753, "Policy Loss": -0.007111635059118271, "Value Loss": 13.279050827026367, "_runtime": 985.5246338844299, "_timestamp": 1585510063.9453635, "_step": 242}
{"Episode reward": 54.256079481360636, "Episode length": 835, "Policy Loss": -0.010449866764247417, "Value Loss": 11.962835311889648, "_runtime": 986.6673483848572, "_timestamp": 1585510065.088078, "_step": 243}
{"Episode reward": 57.94255101637042, "Episode length": 739, "Policy Loss": 0.3160761594772339, "Value Loss": 13.504019737243652, "_runtime": 988.0609030723572, "_timestamp": 1585510066.4816327, "_step": 244}
{"Episode reward": 47.02718840343841, "Episode length": 912, "Policy Loss": -0.046628259122371674, "Value Loss": 10.96730899810791, "_runtime": 988.9925372600555, "_timestamp": 1585510067.413267, "_step": 245}
{"Episode reward": 65.36129882428583, "Episode length": 604, "Policy Loss": 0.12615561485290527, "Value Loss": 16.5192928314209, "_runtime": 990.5054912567139, "_timestamp": 1585510068.926221, "_step": 246}
{"Episode reward": -59.75706067607067, "Episode length": 999, "Policy Loss": -0.1632544994354248, "Value Loss": 0.014555992558598518, "_runtime": 991.3925478458405, "_timestamp": 1585510069.8132775, "_step": 247}
{"Episode reward": 68.2949850588325, "Episode length": 573, "Policy Loss": 0.026198936626315117, "Value Loss": 17.446857452392578, "_runtime": 992.3100056648254, "_timestamp": 1585510070.7307353, "_step": 248}
{"Episode reward": 65.52320632916592, "Episode length": 607, "Policy Loss": 0.09803172945976257, "Value Loss": 16.45404624938965, "_runtime": 993.3254678249359, "_timestamp": 1585510071.7461975, "_step": 249}
{"Episode reward": 61.209148524042256, "Episode length": 663, "Policy Loss": 0.05172954872250557, "Value Loss": 15.051011085510254, "_runtime": 994.3549826145172, "_timestamp": 1585510072.7757123, "_step": 250}
{"Episode reward": 62.12463572444109, "Episode length": 683, "Policy Loss": 0.345976322889328, "Value Loss": 14.610004425048828, "_runtime": 995.4688181877136, "_timestamp": 1585510073.8895478, "_step": 251}
{"Episode reward": 57.111797788053465, "Episode length": 743, "Policy Loss": 0.12774787843227386, "Value Loss": 13.431690216064453, "_runtime": 996.7392947673798, "_timestamp": 1585510075.1600244, "_step": 252}
{"Episode reward": 52.14980799993678, "Episode length": 847, "Policy Loss": 0.00629357248544693, "Value Loss": 11.8064546585083, "_runtime": 997.9173467159271, "_timestamp": 1585510076.3380764, "_step": 253}
{"Episode reward": 55.41178433302808, "Episode length": 783, "Policy Loss": -0.005799456033855677, "Value Loss": 12.746109008789062, "_runtime": 998.7902276515961, "_timestamp": 1585510077.2109573, "_step": 254}
{"Episode reward": 68.46569290478888, "Episode length": 570, "Policy Loss": 0.02117053046822548, "Value Loss": 17.5333309173584, "_runtime": 999.7612297534943, "_timestamp": 1585510078.1819594, "_step": 255}
{"Episode reward": 64.68933315521639, "Episode length": 637, "Policy Loss": 7.106417615432292e-05, "Value Loss": 15.663966178894043, "_runtime": 1000.6167988777161, "_timestamp": 1585510079.0375285, "_step": 256}
{"Episode reward": 68.15848199852992, "Episode length": 568, "Policy Loss": 0.08313589543104172, "Value Loss": 17.58922004699707, "_runtime": 1002.1132698059082, "_timestamp": 1585510080.5339994, "_step": 257}
{"Episode reward": -57.62955113975003, "Episode length": 999, "Policy Loss": -0.1597655862569809, "Value Loss": 0.014221254736185074, "_runtime": 1002.914300441742, "_timestamp": 1585510081.33503, "_step": 258}
{"Episode reward": 68.98585020931482, "Episode length": 523, "Policy Loss": 0.016333552077412605, "Value Loss": 19.075956344604492, "_runtime": 1003.8662660121918, "_timestamp": 1585510082.2869956, "_step": 259}
{"Episode reward": 62.91544252711016, "Episode length": 633, "Policy Loss": -0.013134576380252838, "Value Loss": 15.785418510437012, "_runtime": 1005.3198826313019, "_timestamp": 1585510083.7406123, "_step": 260}
{"Episode reward": 46.45446949999703, "Episode length": 957, "Policy Loss": -0.05799085274338722, "Value Loss": 10.430932998657227, "_runtime": 1006.523225069046, "_timestamp": 1585510084.9439547, "_step": 261}
{"Episode reward": 53.34940268906992, "Episode length": 780, "Policy Loss": 0.04257775843143463, "Value Loss": 12.810525894165039, "_runtime": 1007.8979289531708, "_timestamp": 1585510086.3186586, "_step": 262}
{"Episode reward": 46.85752815516879, "Episode length": 917, "Policy Loss": -0.005010013468563557, "Value Loss": 10.89133358001709, "_runtime": 1009.1055498123169, "_timestamp": 1585510087.5262794, "_step": 263}
{"Episode reward": 55.940638744027616, "Episode length": 797, "Policy Loss": 0.007372954394668341, "Value Loss": 12.546943664550781, "_runtime": 1010.6201684474945, "_timestamp": 1585510089.040898, "_step": 264}
{"Episode reward": -58.02141404822952, "Episode length": 999, "Policy Loss": -0.1678687483072281, "Value Loss": 0.015338991768658161, "_runtime": 1011.2956647872925, "_timestamp": 1585510089.7163944, "_step": 265}
{"Episode reward": 75.56873899392978, "Episode length": 439, "Policy Loss": 0.9524233937263489, "Value Loss": 22.721479415893555, "_runtime": 1012.2319324016571, "_timestamp": 1585510090.652662, "_step": 266}
{"Episode reward": 63.64973226372756, "Episode length": 610, "Policy Loss": 0.11890766769647598, "Value Loss": 16.373279571533203, "_runtime": 1013.5373780727386, "_timestamp": 1585510091.9581077, "_step": 267}
{"Episode reward": 51.54215798553196, "Episode length": 858, "Policy Loss": -0.052630212157964706, "Value Loss": 11.649901390075684, "_runtime": 1014.5422728061676, "_timestamp": 1585510092.9630024, "_step": 268}
{"Episode reward": 62.98335246646508, "Episode length": 670, "Policy Loss": 0.018400557339191437, "Value Loss": 14.892476081848145, "_runtime": 1015.3198726177216, "_timestamp": 1585510093.7406023, "_step": 269}
{"Episode reward": 71.48697920785254, "Episode length": 509, "Policy Loss": 0.3782563805580139, "Value Loss": 19.636335372924805, "_runtime": 1016.3704364299774, "_timestamp": 1585510094.791166, "_step": 270}
{"Episode reward": 59.53217451865112, "Episode length": 692, "Policy Loss": 0.037099141627550125, "Value Loss": 14.423542976379395, "_runtime": 1017.044322013855, "_timestamp": 1585510095.4650517, "_step": 271}
{"Episode reward": 74.46299416124452, "Episode length": 438, "Policy Loss": 0.14950568974018097, "Value Loss": 22.818553924560547, "_runtime": 1018.2278714179993, "_timestamp": 1585510096.648601, "_step": 272}
{"Episode reward": 55.50974850647616, "Episode length": 792, "Policy Loss": 0.044190067797899246, "Value Loss": 12.613700866699219, "_runtime": 1019.7158560752869, "_timestamp": 1585510098.1365857, "_step": 273}
{"Episode reward": 47.39600930633666, "Episode length": 990, "Policy Loss": -0.06432656943798065, "Value Loss": 10.10261344909668, "_runtime": 1021.2041389942169, "_timestamp": 1585510099.6248686, "_step": 274}
{"Episode reward": -57.00774935460081, "Episode length": 999, "Policy Loss": -0.1797432005405426, "Value Loss": 0.017008807510137558, "_runtime": 1022.2376840114594, "_timestamp": 1585510100.6584136, "_step": 275}
{"Episode reward": 61.880951721412636, "Episode length": 677, "Policy Loss": -0.032934993505477905, "Value Loss": 14.767736434936523, "_runtime": 1023.1801609992981, "_timestamp": 1585510101.6008906, "_step": 276}
{"Episode reward": 65.06273128603308, "Episode length": 608, "Policy Loss": 0.05932949110865593, "Value Loss": 16.442462921142578, "_runtime": 1024.2778916358948, "_timestamp": 1585510102.6986213, "_step": 277}
{"Episode reward": 61.29942698988225, "Episode length": 716, "Policy Loss": -0.01441736426204443, "Value Loss": 13.960188865661621, "_runtime": 1025.7975487709045, "_timestamp": 1585510104.2182784, "_step": 278}
{"Episode reward": -55.62307943678157, "Episode length": 999, "Policy Loss": -0.17825372517108917, "Value Loss": 0.017180047929286957, "_runtime": 1026.6993520259857, "_timestamp": 1585510105.1200817, "_step": 279}
{"Episode reward": 65.34885135335321, "Episode length": 592, "Policy Loss": -0.00802229531109333, "Value Loss": 16.88069725036621, "_runtime": 1028.109091758728, "_timestamp": 1585510106.5298214, "_step": 280}
{"Episode reward": 44.77556275503796, "Episode length": 934, "Policy Loss": -0.07758447527885437, "Value Loss": 10.688532829284668, "_runtime": 1029.00315117836, "_timestamp": 1585510107.4238808, "_step": 281}
{"Episode reward": 66.40878771552426, "Episode length": 573, "Policy Loss": 0.019895369186997414, "Value Loss": 17.41090965270996, "_runtime": 1030.5062065124512, "_timestamp": 1585510108.9269361, "_step": 282}
{"Episode reward": -57.694431898507816, "Episode length": 999, "Policy Loss": -0.1803099513053894, "Value Loss": 0.01779130846261978, "_runtime": 1031.3291804790497, "_timestamp": 1585510109.74991, "_step": 283}
{"Episode reward": 70.0561477902887, "Episode length": 528, "Policy Loss": 0.0058746603317558765, "Value Loss": 18.910907745361328, "_runtime": 1032.404792547226, "_timestamp": 1585510110.8255222, "_step": 284}
{"Episode reward": 62.009651440745905, "Episode length": 693, "Policy Loss": 0.06860614567995071, "Value Loss": 14.427058219909668, "_runtime": 1033.9198098182678, "_timestamp": 1585510112.3405395, "_step": 285}
{"Episode reward": -57.14800107163196, "Episode length": 999, "Policy Loss": -0.175002783536911, "Value Loss": 0.01759057492017746, "_runtime": 1034.7298710346222, "_timestamp": 1585510113.1506007, "_step": 286}
{"Episode reward": 68.82940914846053, "Episode length": 531, "Policy Loss": 0.3974439203739166, "Value Loss": 18.793834686279297, "_runtime": 1036.0831005573273, "_timestamp": 1585510114.5038302, "_step": 287}
{"Episode reward": 49.160517525064456, "Episode length": 899, "Policy Loss": -0.027817213907837868, "Value Loss": 11.115628242492676, "_runtime": 1037.6153280735016, "_timestamp": 1585510116.0360577, "_step": 288}
{"Episode reward": -57.16792229996935, "Episode length": 999, "Policy Loss": -0.17931367456912994, "Value Loss": 0.017427723854780197, "_runtime": 1038.9761354923248, "_timestamp": 1585510117.3968651, "_step": 289}
{"Episode reward": 47.35563072315565, "Episode length": 915, "Policy Loss": 0.05030263587832451, "Value Loss": 10.909663200378418, "_runtime": 1040.1584358215332, "_timestamp": 1585510118.5791655, "_step": 290}
{"Episode reward": 56.120570520413885, "Episode length": 775, "Policy Loss": -0.0030752690508961678, "Value Loss": 12.877043724060059, "_runtime": 1041.6927564144135, "_timestamp": 1585510120.113486, "_step": 291}
{"Episode reward": -55.4072975117, "Episode length": 999, "Policy Loss": -0.17341060936450958, "Value Loss": 0.01645030826330185, "_runtime": 1043.2184278964996, "_timestamp": 1585510121.6391575, "_step": 292}
{"Episode reward": -56.06921637676993, "Episode length": 999, "Policy Loss": -0.1725563406944275, "Value Loss": 0.016267746686935425, "_runtime": 1044.7392647266388, "_timestamp": 1585510123.1599944, "_step": 293}
{"Episode reward": -56.28386131938388, "Episode length": 999, "Policy Loss": -0.16971753537654877, "Value Loss": 0.015962274745106697, "_runtime": 1045.7054643630981, "_timestamp": 1585510124.126194, "_step": 294}
{"Episode reward": 65.09440886659925, "Episode length": 617, "Policy Loss": 0.02563202753663063, "Value Loss": 16.202871322631836, "_runtime": 1046.8870031833649, "_timestamp": 1585510125.3077328, "_step": 295}
{"Episode reward": 56.766943987535115, "Episode length": 768, "Policy Loss": -0.029733741655945778, "Value Loss": 13.019810676574707, "_runtime": 1048.010883808136, "_timestamp": 1585510126.4316134, "_step": 296}
{"Episode reward": 60.02559748674161, "Episode length": 731, "Policy Loss": 0.0665980875492096, "Value Loss": 13.672965049743652, "_runtime": 1048.8094882965088, "_timestamp": 1585510127.230218, "_step": 297}
{"Episode reward": 70.07562938839676, "Episode length": 528, "Policy Loss": 0.0639076754450798, "Value Loss": 18.898344039916992, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621, 9.688216209411621]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-4.459492206573486, -4.313446044921875, -4.167399883270264, -4.021353721618652, -3.875307559967041, -3.7292613983154297, -3.5832149982452393, -3.437168836593628, -3.2911226749420166, -3.1450765132904053, -2.999030351638794, -2.8529839515686035, -2.706937789916992, -2.560891628265381, -2.4148454666137695, -2.268799304962158, -2.122753143310547, -1.9767069816589355, -1.8306608200073242, -1.684614658355713, -1.5385684967041016, -1.3925220966339111, -1.2464759349822998, -1.1004297733306885, -0.9543836116790771, -0.8083374500274658, -0.6622912883758545, -0.5162451267242432, -0.37019872665405273, -0.2241525650024414, -0.07810640335083008, 0.06793975830078125, 0.21398591995239258, 0.3600320816040039, 0.5060782432556152, 0.6521244049072266, 0.7981705665588379, 0.9442167282104492, 1.0902628898620605, 1.2363090515136719, 1.3823552131652832, 1.5284018516540527, 1.674448013305664, 1.8204941749572754, 1.9665403366088867, 2.112586498260498, 2.2586326599121094, 2.4046788215637207, 2.550724983215332, 2.6967711448669434, 2.8428173065185547, 2.988863468170166, 3.1349096298217773, 3.2809557914733887, 3.427001953125, 3.5730481147766113, 3.719094753265381, 3.865140438079834, 4.0111870765686035, 4.157232761383057, 4.303279399871826, 4.449325084686279, 4.595371723175049, 4.741417407989502, 4.8874640464782715]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.401185035705566, -4.248133659362793, -4.0950822830200195, -3.942030906677246, -3.7889795303344727, -3.635928153991699, -3.482876777648926, -3.3298254013061523, -3.176774024963379, -3.0237226486206055, -2.870671272277832, -2.7176198959350586, -2.5645687580108643, -2.411517381668091, -2.2584660053253174, -2.105414628982544, -1.9523632526397705, -1.799311876296997, -1.6462604999542236, -1.4932091236114502, -1.3401577472686768, -1.1871063709259033, -1.0340549945831299, -0.8810036182403564, -0.7279524803161621, -0.5749011039733887, -0.42184972763061523, -0.2687983512878418, -0.11574697494506836, 0.03730440139770508, 0.19035577774047852, 0.34340715408325195, 0.4964585304260254, 0.6495099067687988, 0.8025612831115723, 0.9556126594543457, 1.1086640357971191, 1.2617154121398926, 1.414766788482666, 1.5678181648254395, 1.720869541168213, 1.8739209175109863, 2.0269722938537598, 2.180023670196533, 2.3330750465393066, 2.48612642288208, 2.6391777992248535, 2.792229175567627, 2.945280075073242, 3.0983314514160156, 3.251382827758789, 3.4044342041015625, 3.557485580444336, 3.7105369567871094, 3.863588333129883, 4.016639709472656, 4.16969108581543, 4.322742462158203, 4.475793838500977, 4.62884521484375, 4.781896591186523, 4.934947967529297, 5.08799934387207, 5.241050720214844, 5.394102096557617]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0, 4.0, 1.0, 6.0, 3.0, 6.0, 4.0, 4.0, 3.0, 9.0, 12.0, 12.0, 9.0, 14.0, 15.0, 15.0, 18.0, 18.0, 17.0, 14.0, 23.0, 41.0, 46.0, 14.0, 18.0, 24.0, 18.0, 15.0, 15.0, 9.0, 12.0, 9.0, 5.0, 13.0, 1.0, 6.0, 3.0, 6.0, 6.0, 2.0, 9.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.6159708499908447, -2.529101848602295, -2.442232608795166, -2.355363607406616, -2.2684946060180664, -2.1816253662109375, -2.0947563648223877, -2.007887363433838, -1.921018123626709, -1.8341490030288696, -1.7472798824310303, -1.6604108810424805, -1.5735417604446411, -1.4866726398468018, -1.399803638458252, -1.3129345178604126, -1.2260653972625732, -1.1391962766647339, -1.0523271560668945, -0.9654581546783447, -0.8785890340805054, -0.791719913482666, -0.7048509120941162, -0.6179817914962769, -0.5311126708984375, -0.4442436695098877, -0.3573744297027588, -0.270505428314209, -0.18363642692565918, -0.09676718711853027, -0.009898185729980469, 0.07697105407714844, 0.16384005546569824, 0.25070905685424805, 0.33757829666137695, 0.42444729804992676, 0.5113165378570557, 0.5981855392456055, 0.6850545406341553, 0.7719237804412842, 0.858792781829834, 0.9456617832183838, 1.0325310230255127, 1.1194000244140625, 1.2062690258026123, 1.2931382656097412, 1.380007266998291, 1.4668762683868408, 1.5537455081939697, 1.6406147480010986, 1.7274835109710693, 1.8143527507781982, 1.9012219905853271, 1.9880907535552979, 2.0749599933624268, 2.1618292331695557, 2.2486979961395264, 2.3355672359466553, 2.422436475753784, 2.509305715560913, 2.596174478530884, 2.6830437183380127, 2.7699129581451416, 2.8567817211151123, 2.943650960922241]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.795100688934326, -3.664159059524536, -3.533217430114746, -3.402275800704956, -3.271334171295166, -3.140392780303955, -3.009451150894165, -2.878509521484375, -2.747567892074585, -2.616626262664795, -2.485684633255005, -2.354743003845215, -2.223801612854004, -2.0928597450256348, -1.9619183540344238, -1.8309767246246338, -1.7000350952148438, -1.5690934658050537, -1.4381518363952637, -1.3072102069854736, -1.1762685775756836, -1.0453271865844727, -0.9143855571746826, -0.7834439277648926, -0.6525022983551025, -0.5215606689453125, -0.39061903953552246, -0.2596774101257324, -0.12873601913452148, 0.0022056102752685547, 0.1331472396850586, 0.26408910751342773, 0.39503049850463867, 0.5259718894958496, 0.6569137573242188, 0.7878551483154297, 0.9187970161437988, 1.0497384071350098, 1.180680274963379, 1.3116216659545898, 1.442563533782959, 1.57350492477417, 1.7044463157653809, 1.83538818359375, 1.966329574584961, 2.09727144241333, 2.228212833404541, 2.35915470123291, 2.490096092224121, 2.621037483215332, 2.751979351043701, 2.882920742034912, 3.0138626098632812, 3.144804000854492, 3.2757458686828613, 3.4066872596740723, 3.537628650665283, 3.6685705184936523, 3.7995119094848633, 3.9304537773132324, 4.061395168304443, 4.1923370361328125, 4.323278903961182, 4.454220294952393, 4.5851616859436035]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 9.0, 7.0, 8.0, 3.0, 1.0, 4.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3666669130325317, -1.3194730281829834, -1.2722790241241455, -1.2250851392745972, -1.1778912544250488, -1.130697250366211, -1.0835033655166626, -1.0363094806671143, -0.9891155362129211, -0.941921591758728, -0.8947277069091797, -0.8475337624549866, -0.8003398180007935, -0.7531459331512451, -0.705951988697052, -0.6587581038475037, -0.6115641593933105, -0.5643702149391174, -0.5171763300895691, -0.469982385635376, -0.42278850078582764, -0.3755945563316345, -0.3284006118774414, -0.28120672702789307, -0.23401272296905518, -0.18681883811950684, -0.1396249532699585, -0.09243106842041016, -0.045237064361572266, 0.0019568204879760742, 0.049150705337524414, 0.0963447093963623, 0.14353859424591064, 0.19073247909545898, 0.23792648315429688, 0.2851203680038452, 0.33231425285339355, 0.37950825691223145, 0.4267021417617798, 0.4738960266113281, 0.5210899114608765, 0.5682839155197144, 0.6154778003692627, 0.662671685218811, 0.7098656892776489, 0.7570596933364868, 0.8042534589767456, 0.8514474630355835, 0.8986414670944214, 0.9458352327346802, 0.9930292367935181, 1.0402230024337769, 1.0874170064926147, 1.1346110105514526, 1.1818047761917114, 1.2289987802505493, 1.2761927843093872, 1.323386549949646, 1.3705805540084839, 1.4177745580673218, 1.4649683237075806, 1.5121623277664185, 1.5593563318252563, 1.6065500974655151, 1.653744101524353]}, "_runtime": 1050.3196942806244, "_timestamp": 1585510128.740424, "_step": 298}
{"Episode reward": -57.882139501653796, "Episode length": 999, "Policy Loss": -0.16746440529823303, "Value Loss": 0.014739026315510273, "_runtime": 1051.012475013733, "_timestamp": 1585510129.4332047, "_step": 299}
{"Episode reward": 75.00572325860927, "Episode length": 443, "Policy Loss": 0.05730165168642998, "Value Loss": 22.5595760345459, "_runtime": 1052.4496507644653, "_timestamp": 1585510130.8703804, "_step": 300}
{"Episode reward": 46.9858916242702, "Episode length": 958, "Policy Loss": 0.0037888435181230307, "Value Loss": 10.41987419128418, "_runtime": 1053.770256280899, "_timestamp": 1585510132.190986, "_step": 301}
{"Episode reward": 51.85759494327867, "Episode length": 864, "Policy Loss": -0.03759109973907471, "Value Loss": 11.552082061767578, "_runtime": 1054.4094619750977, "_timestamp": 1585510132.8301916, "_step": 302}
{"Episode reward": 75.04286349629314, "Episode length": 428, "Policy Loss": 0.07406998425722122, "Value Loss": 23.32614517211914, "_runtime": 1055.9666197299957, "_timestamp": 1585510134.3873494, "_step": 303}
{"Episode reward": -55.26992109824637, "Episode length": 999, "Policy Loss": -0.1547907143831253, "Value Loss": 0.0136546166613698, "_runtime": 1057.198637008667, "_timestamp": 1585510135.6193666, "_step": 304}
{"Episode reward": 53.69367891997909, "Episode length": 811, "Policy Loss": -0.039048053324222565, "Value Loss": 12.33105754852295, "_runtime": 1058.485095500946, "_timestamp": 1585510136.9058251, "_step": 305}
{"Episode reward": 53.312682162875376, "Episode length": 866, "Policy Loss": -0.01474946178495884, "Value Loss": 11.547975540161133, "_runtime": 1060.0157089233398, "_timestamp": 1585510138.4364386, "_step": 306}
{"Episode reward": -53.83854442461132, "Episode length": 999, "Policy Loss": -0.14487504959106445, "Value Loss": 0.01317939069122076, "_runtime": 1060.8410618305206, "_timestamp": 1585510139.2617915, "_step": 307}
{"Episode reward": 71.31560049581921, "Episode length": 533, "Policy Loss": 0.02829010784626007, "Value Loss": 18.73945426940918, "_runtime": 1062.060317516327, "_timestamp": 1585510140.4810472, "_step": 308}
{"Episode reward": 53.349541894194445, "Episode length": 804, "Policy Loss": -0.0041956184431910515, "Value Loss": 12.433553695678711, "_runtime": 1062.7487516403198, "_timestamp": 1585510141.1694813, "_step": 309}
{"Episode reward": 74.97553649138555, "Episode length": 433, "Policy Loss": 0.35415753722190857, "Value Loss": 23.077890396118164, "_runtime": 1063.8999395370483, "_timestamp": 1585510142.3206692, "_step": 310}
{"Episode reward": 54.2849190621943, "Episode length": 770, "Policy Loss": -0.03969442844390869, "Value Loss": 12.987507820129395, "_runtime": 1065.1162610054016, "_timestamp": 1585510143.5369906, "_step": 311}
{"Episode reward": 55.990860335878395, "Episode length": 797, "Policy Loss": 0.031239371746778488, "Value Loss": 12.541459083557129, "_runtime": 1066.0125999450684, "_timestamp": 1585510144.4333296, "_step": 312}
{"Episode reward": 66.50680656030885, "Episode length": 597, "Policy Loss": 0.03485177084803581, "Value Loss": 16.728843688964844, "_runtime": 1066.9027614593506, "_timestamp": 1585510145.323491, "_step": 313}
{"Episode reward": 67.89033248162288, "Episode length": 581, "Policy Loss": 0.1029723510146141, "Value Loss": 17.201087951660156, "_runtime": 1068.4095556735992, "_timestamp": 1585510146.8302853, "_step": 314}
{"Episode reward": -55.25801247620302, "Episode length": 999, "Policy Loss": -0.16062065958976746, "Value Loss": 0.013968165032565594, "_runtime": 1069.5232818126678, "_timestamp": 1585510147.9440114, "_step": 315}
{"Episode reward": 59.7513707650293, "Episode length": 741, "Policy Loss": -0.01339380256831646, "Value Loss": 13.467008590698242, "_runtime": 1070.7114708423615, "_timestamp": 1585510149.1322005, "_step": 316}
{"Episode reward": 56.34836983467854, "Episode length": 794, "Policy Loss": -0.0180473942309618, "Value Loss": 12.57220458984375, "_runtime": 1071.4581046104431, "_timestamp": 1585510149.8788342, "_step": 317}
{"Episode reward": 71.50560288249652, "Episode length": 478, "Policy Loss": 0.030692683532834053, "Value Loss": 20.911901473999023, "_runtime": 1072.9768285751343, "_timestamp": 1585510151.3975582, "_step": 318}
{"Episode reward": -53.49720410750523, "Episode length": 999, "Policy Loss": -0.1557503491640091, "Value Loss": 0.014073279686272144, "_runtime": 1073.5870895385742, "_timestamp": 1585510152.0078192, "_step": 319}
{"Episode reward": 79.02198635313229, "Episode length": 388, "Policy Loss": 0.19003555178642273, "Value Loss": 25.757522583007812, "_runtime": 1074.355702161789, "_timestamp": 1585510152.7764318, "_step": 320}
{"Episode reward": 71.99394869118517, "Episode length": 517, "Policy Loss": 0.02327648177742958, "Value Loss": 19.32827377319336, "_runtime": 1075.5895416736603, "_timestamp": 1585510154.0102713, "_step": 321}
{"Episode reward": 58.301659814348035, "Episode length": 806, "Policy Loss": 0.05512218177318573, "Value Loss": 12.405792236328125, "_runtime": 1076.416268825531, "_timestamp": 1585510154.8369985, "_step": 322}
{"Episode reward": 68.30514680849267, "Episode length": 559, "Policy Loss": 0.07300441712141037, "Value Loss": 17.847061157226562, "_runtime": 1077.3326375484467, "_timestamp": 1585510155.7533672, "_step": 323}
{"Episode reward": 65.56917850538716, "Episode length": 613, "Policy Loss": -0.00929118599742651, "Value Loss": 16.294095993041992, "_runtime": 1078.765461921692, "_timestamp": 1585510157.1861916, "_step": 324}
{"Episode reward": 49.589866903009046, "Episode length": 919, "Policy Loss": 0.08721237629652023, "Value Loss": 10.861467361450195, "_runtime": 1079.445953130722, "_timestamp": 1585510157.8666828, "_step": 325}
{"Episode reward": 76.70738287351539, "Episode length": 448, "Policy Loss": 0.5769500732421875, "Value Loss": 22.263134002685547, "_runtime": 1080.9407334327698, "_timestamp": 1585510159.361463, "_step": 326}
{"Episode reward": -54.83258247951924, "Episode length": 999, "Policy Loss": -0.17212648689746857, "Value Loss": 0.016444368287920952, "_runtime": 1082.4439599514008, "_timestamp": 1585510160.8646896, "_step": 327}
{"Episode reward": -56.412808054841044, "Episode length": 999, "Policy Loss": -0.17428267002105713, "Value Loss": 0.01701977662742138, "_runtime": 1083.918452501297, "_timestamp": 1585510162.3391821, "_step": 328}
{"Episode reward": 47.371363510166205, "Episode length": 990, "Policy Loss": -0.07307540625333786, "Value Loss": 10.103594779968262, "_runtime": 1085.158276796341, "_timestamp": 1585510163.5790064, "_step": 329}
{"Episode reward": 56.2927797951581, "Episode length": 796, "Policy Loss": -0.058978211134672165, "Value Loss": 12.561832427978516, "_runtime": 1086.7110254764557, "_timestamp": 1585510165.131755, "_step": 330}
{"Episode reward": -54.61666083344579, "Episode length": 999, "Policy Loss": -0.16643325984477997, "Value Loss": 0.01664120890200138, "_runtime": 1088.1221253871918, "_timestamp": 1585510166.542855, "_step": 331}
{"Episode reward": 49.50973915822017, "Episode length": 923, "Policy Loss": -0.016469072550535202, "Value Loss": 10.834625244140625, "_runtime": 1089.0120503902435, "_timestamp": 1585510167.43278, "_step": 332}
{"Episode reward": 67.6312736918715, "Episode length": 582, "Policy Loss": 0.015583428554236889, "Value Loss": 17.1743221282959, "_runtime": 1090.265506029129, "_timestamp": 1585510168.6862357, "_step": 333}
{"Episode reward": 54.64370977122957, "Episode length": 816, "Policy Loss": -0.050592899322509766, "Value Loss": 12.230643272399902, "_runtime": 1090.9892644882202, "_timestamp": 1585510169.4099941, "_step": 334}
{"Episode reward": 75.58635535429147, "Episode length": 460, "Policy Loss": 0.15548016130924225, "Value Loss": 21.72607421875, "_runtime": 1092.139083623886, "_timestamp": 1585510170.5598133, "_step": 335}
{"Episode reward": 60.26419689498077, "Episode length": 761, "Policy Loss": 0.03225722908973694, "Value Loss": 13.112560272216797, "_runtime": 1093.6451818943024, "_timestamp": 1585510172.0659115, "_step": 336}
{"Episode reward": 45.94737162579067, "Episode length": 999, "Policy Loss": -0.07985278218984604, "Value Loss": 9.992876052856445, "_runtime": 1095.13898563385, "_timestamp": 1585510173.5597153, "_step": 337}
{"Episode reward": -55.22132523905089, "Episode length": 999, "Policy Loss": -0.171513170003891, "Value Loss": 0.016627831384539604, "_runtime": 1096.6565613746643, "_timestamp": 1585510175.077291, "_step": 338}
{"Episode reward": -55.48166739293329, "Episode length": 999, "Policy Loss": -0.1669754981994629, "Value Loss": 0.016568992286920547, "_runtime": 1097.772257566452, "_timestamp": 1585510176.1929872, "_step": 339}
{"Episode reward": 60.91251829127506, "Episode length": 724, "Policy Loss": 0.28942015767097473, "Value Loss": 13.793211936950684, "_runtime": 1098.925178527832, "_timestamp": 1585510177.3459082, "_step": 340}
{"Episode reward": 61.662639112372275, "Episode length": 747, "Policy Loss": -0.024760285392403603, "Value Loss": 13.373801231384277, "_runtime": 1099.9459817409515, "_timestamp": 1585510178.3667114, "_step": 341}
{"Episode reward": 63.826288391866896, "Episode length": 657, "Policy Loss": 0.08149212598800659, "Value Loss": 15.210992813110352, "_runtime": 1101.468510389328, "_timestamp": 1585510179.88924, "_step": 342}
{"Episode reward": -51.79689523089323, "Episode length": 999, "Policy Loss": -0.15678565204143524, "Value Loss": 0.015148486010730267, "_runtime": 1102.2340948581696, "_timestamp": 1585510180.6548245, "_step": 343}
{"Episode reward": 73.44714356993336, "Episode length": 469, "Policy Loss": 0.02235380746424198, "Value Loss": 21.293312072753906, "_runtime": 1103.4437289237976, "_timestamp": 1585510181.8644586, "_step": 344}
{"Episode reward": 58.49639161974388, "Episode length": 796, "Policy Loss": -0.0460880808532238, "Value Loss": 12.561903953552246, "_runtime": 1104.983995437622, "_timestamp": 1585510183.404725, "_step": 345}
{"Episode reward": -50.794901452413804, "Episode length": 999, "Policy Loss": -0.1483800858259201, "Value Loss": 0.014476638287305832, "_runtime": 1106.1156425476074, "_timestamp": 1585510184.5363722, "_step": 346}
{"Episode reward": 60.233099895499535, "Episode length": 755, "Policy Loss": -0.03768486529588699, "Value Loss": 13.216941833496094, "_runtime": 1107.0792150497437, "_timestamp": 1585510185.4999447, "_step": 347}
{"Episode reward": 66.25718466627418, "Episode length": 625, "Policy Loss": 0.061908088624477386, "Value Loss": 15.985686302185059, "_runtime": 1107.8747322559357, "_timestamp": 1585510186.295462, "_step": 348}
{"Episode reward": 71.88780554028187, "Episode length": 509, "Policy Loss": 0.16162210702896118, "Value Loss": 19.598323822021484, "_runtime": 1108.7958076000214, "_timestamp": 1585510187.2165372, "_step": 349}
{"Episode reward": 65.73811285946374, "Episode length": 608, "Policy Loss": 0.06946256011724472, "Value Loss": 16.438329696655273, "_runtime": 1109.4460046291351, "_timestamp": 1585510187.8667343, "_step": 350}
{"Episode reward": 76.47650738619345, "Episode length": 431, "Policy Loss": 0.3959810733795166, "Value Loss": 23.17551612854004, "_runtime": 1110.098913192749, "_timestamp": 1585510188.5196428, "_step": 351}
{"Episode reward": 78.20751509970118, "Episode length": 441, "Policy Loss": 0.09459845721721649, "Value Loss": 22.640390396118164, "_runtime": 1111.5800833702087, "_timestamp": 1585510190.000813, "_step": 352}
{"Episode reward": -53.73013836729307, "Episode length": 999, "Policy Loss": -0.15776273608207703, "Value Loss": 0.015249770134687424, "_runtime": 1112.7907729148865, "_timestamp": 1585510191.2115026, "_step": 353}
{"Episode reward": 56.23637420570211, "Episode length": 823, "Policy Loss": -0.0411653108894825, "Value Loss": 12.142195701599121, "_runtime": 1113.8002080917358, "_timestamp": 1585510192.2209377, "_step": 354}
{"Episode reward": 61.86338915661033, "Episode length": 688, "Policy Loss": -0.015833519399166107, "Value Loss": 14.528402328491211, "_runtime": 1114.2759132385254, "_timestamp": 1585510192.6966429, "_step": 355}
{"Episode reward": 83.89656587569715, "Episode length": 300, "Policy Loss": 0.14235062897205353, "Value Loss": 33.281890869140625, "_runtime": 1115.4262766838074, "_timestamp": 1585510193.8470063, "_step": 356}
{"Episode reward": 57.155370344928585, "Episode length": 768, "Policy Loss": -0.006784910801798105, "Value Loss": 13.009407043457031, "_runtime": 1116.0234591960907, "_timestamp": 1585510194.4441888, "_step": 357}
{"Episode reward": 77.85210434816598, "Episode length": 395, "Policy Loss": 0.06220155209302902, "Value Loss": 25.248531341552734, "_runtime": 1117.346393108368, "_timestamp": 1585510195.7671227, "_step": 358}
{"Episode reward": 50.75860451096302, "Episode length": 903, "Policy Loss": -0.07342077791690826, "Value Loss": 11.053729057312012, "_runtime": 1118.2452342510223, "_timestamp": 1585510196.665964, "_step": 359}
{"Episode reward": 67.7583262958826, "Episode length": 595, "Policy Loss": -0.0068238298408687115, "Value Loss": 16.766557693481445, "_runtime": 1119.5035405158997, "_timestamp": 1585510197.9242702, "_step": 360}
{"Episode reward": 55.85990843008946, "Episode length": 859, "Policy Loss": 0.013508534990251064, "Value Loss": 11.628006935119629, "_runtime": 1120.8494937419891, "_timestamp": 1585510199.2702234, "_step": 361}
{"Episode reward": 48.7814220874933, "Episode length": 895, "Policy Loss": -0.09226924926042557, "Value Loss": 11.174885749816895, "_runtime": 1121.4737296104431, "_timestamp": 1585510199.8944592, "_step": 362}
{"Episode reward": 77.39195697060217, "Episode length": 407, "Policy Loss": 0.15175393223762512, "Value Loss": 24.502416610717773, "_runtime": 1122.2641651630402, "_timestamp": 1585510200.6848948, "_step": 363}
{"Episode reward": 72.62409131849607, "Episode length": 520, "Policy Loss": 0.0036039685364812613, "Value Loss": 19.2174015045166, "_runtime": 1123.5543131828308, "_timestamp": 1585510201.9750428, "_step": 364}
{"Episode reward": 53.82354453065694, "Episode length": 851, "Policy Loss": -0.06403516232967377, "Value Loss": 11.749837875366211, "_runtime": 1124.5855824947357, "_timestamp": 1585510203.0063121, "_step": 365}
{"Episode reward": 62.86128922890185, "Episode length": 690, "Policy Loss": -0.03501260653138161, "Value Loss": 14.460112571716309, "_runtime": 1125.9190380573273, "_timestamp": 1585510204.3397677, "_step": 366}
{"Episode reward": 53.85779201699701, "Episode length": 873, "Policy Loss": -0.086046501994133, "Value Loss": 11.437024116516113, "_runtime": 1127.427531003952, "_timestamp": 1585510205.8482606, "_step": 367}
{"Episode reward": -51.19360283344649, "Episode length": 999, "Policy Loss": -0.18176861107349396, "Value Loss": 0.019903266802430153, "_runtime": 1127.9813601970673, "_timestamp": 1585510206.4020898, "_step": 368}
{"Episode reward": 80.23297668105744, "Episode length": 353, "Policy Loss": 0.47072547674179077, "Value Loss": 28.29960060119629, "_runtime": 1128.8065309524536, "_timestamp": 1585510207.2272606, "_step": 369}
{"Episode reward": 69.15339982131127, "Episode length": 545, "Policy Loss": 0.04900018125772476, "Value Loss": 18.30928611755371, "_runtime": 1130.1224386692047, "_timestamp": 1585510208.5431683, "_step": 370}
{"Episode reward": 52.62375567714356, "Episode length": 866, "Policy Loss": -0.08322751522064209, "Value Loss": 11.533308982849121, "_runtime": 1131.607283115387, "_timestamp": 1585510210.0280128, "_step": 371}
{"Episode reward": -53.81426797406718, "Episode length": 999, "Policy Loss": -0.19268293678760529, "Value Loss": 0.021670648828148842, "_runtime": 1132.507991552353, "_timestamp": 1585510210.9287212, "_step": 372}
{"Episode reward": 67.54571017373678, "Episode length": 591, "Policy Loss": 0.21818707883358002, "Value Loss": 16.88434600830078, "_runtime": 1133.723711013794, "_timestamp": 1585510212.1444407, "_step": 373}
{"Episode reward": 55.80306504415258, "Episode length": 798, "Policy Loss": -0.04143338277935982, "Value Loss": 12.516915321350098, "_runtime": 1134.6908149719238, "_timestamp": 1585510213.1115446, "_step": 374}
{"Episode reward": 65.5149449605018, "Episode length": 626, "Policy Loss": 0.015029543079435825, "Value Loss": 15.968391418457031, "_runtime": 1135.4186794757843, "_timestamp": 1585510213.839409, "_step": 375}
{"Episode reward": 73.0249997945344, "Episode length": 476, "Policy Loss": -0.01474509947001934, "Value Loss": 20.99211311340332, "_runtime": 1136.3389241695404, "_timestamp": 1585510214.7596538, "_step": 376}
{"Episode reward": 65.75140955803539, "Episode length": 604, "Policy Loss": -0.04900765046477318, "Value Loss": 16.546974182128906, "_runtime": 1136.9486722946167, "_timestamp": 1585510215.369402, "_step": 377}
{"Episode reward": 78.04966630691233, "Episode length": 396, "Policy Loss": 0.584598958492279, "Value Loss": 25.179527282714844, "_runtime": 1137.4832513332367, "_timestamp": 1585510215.903981, "_step": 378}
{"Episode reward": 81.6786265574149, "Episode length": 358, "Policy Loss": 0.19839364290237427, "Value Loss": 27.848207473754883, "_runtime": 1138.9734435081482, "_timestamp": 1585510217.3941731, "_step": 379}
{"Episode reward": -52.74067522376073, "Episode length": 999, "Policy Loss": -0.20021463930606842, "Value Loss": 0.0226583331823349, "_runtime": 1139.6072046756744, "_timestamp": 1585510218.0279343, "_step": 380}
{"Episode reward": 77.4538065601143, "Episode length": 420, "Policy Loss": 0.020597197115421295, "Value Loss": 23.740909576416016, "_runtime": 1140.4572277069092, "_timestamp": 1585510218.8779573, "_step": 381}
{"Episode reward": 69.65802265139902, "Episode length": 575, "Policy Loss": -0.0073378970846533775, "Value Loss": 17.377765655517578, "_runtime": 1141.890969991684, "_timestamp": 1585510220.3116996, "_step": 382}
{"Episode reward": 47.160106898056846, "Episode length": 956, "Policy Loss": -0.10155747830867767, "Value Loss": 10.443741798400879, "_runtime": 1142.6935002803802, "_timestamp": 1585510221.11423, "_step": 383}
{"Episode reward": 71.41281509333683, "Episode length": 533, "Policy Loss": -0.008694804273545742, "Value Loss": 18.748666763305664, "_runtime": 1143.5255002975464, "_timestamp": 1585510221.94623, "_step": 384}
{"Episode reward": 70.51811367648342, "Episode length": 553, "Policy Loss": -0.029030032455921173, "Value Loss": 18.036190032958984, "_runtime": 1145.0376834869385, "_timestamp": 1585510223.4584131, "_step": 385}
{"Episode reward": -54.80579795224722, "Episode length": 999, "Policy Loss": -0.21086464822292328, "Value Loss": 0.024955356493592262, "_runtime": 1145.6274948120117, "_timestamp": 1585510224.0482244, "_step": 386}
{"Episode reward": 79.67199119930359, "Episode length": 385, "Policy Loss": 0.1055867001414299, "Value Loss": 25.901941299438477, "_runtime": 1147.1119496822357, "_timestamp": 1585510225.5326793, "_step": 387}
{"Episode reward": -54.0928610788448, "Episode length": 999, "Policy Loss": -0.20966841280460358, "Value Loss": 0.024982089176774025, "_runtime": 1148.6365485191345, "_timestamp": 1585510227.0572782, "_step": 388}
{"Episode reward": -53.455263312687606, "Episode length": 999, "Policy Loss": -0.21004050970077515, "Value Loss": 0.024736253544688225, "_runtime": 1149.513545513153, "_timestamp": 1585510227.9342752, "_step": 389}
{"Episode reward": 68.48872564627385, "Episode length": 589, "Policy Loss": -0.04785386845469475, "Value Loss": 16.96666145324707, "_runtime": 1151.0134491920471, "_timestamp": 1585510229.4341788, "_step": 390}
{"Episode reward": 45.43664747267709, "Episode length": 984, "Policy Loss": -0.09888423979282379, "Value Loss": 10.167046546936035, "_runtime": 1152.0941228866577, "_timestamp": 1585510230.5148525, "_step": 391}
{"Episode reward": 61.212673567675985, "Episode length": 706, "Policy Loss": -0.07336729764938354, "Value Loss": 14.14095401763916, "_runtime": 1153.5823049545288, "_timestamp": 1585510232.0030346, "_step": 392}
{"Episode reward": -55.43283900944128, "Episode length": 999, "Policy Loss": -0.21032845973968506, "Value Loss": 0.024247679859399796, "_runtime": 1154.3863697052002, "_timestamp": 1585510232.8070993, "_step": 393}
{"Episode reward": 72.16243706158694, "Episode length": 511, "Policy Loss": 0.0051830788142979145, "Value Loss": 19.549888610839844, "_runtime": 1155.5063638687134, "_timestamp": 1585510233.9270935, "_step": 394}
{"Episode reward": 61.02206941128428, "Episode length": 713, "Policy Loss": 0.19403351843357086, "Value Loss": 14.02245807647705, "_runtime": 1156.948231935501, "_timestamp": 1585510235.3689616, "_step": 395}
{"Episode reward": 50.80760428333278, "Episode length": 942, "Policy Loss": -0.08163405954837799, "Value Loss": 10.613221168518066, "_runtime": 1157.655336856842, "_timestamp": 1585510236.0760665, "_step": 396}
{"Episode reward": 75.37376045758373, "Episode length": 459, "Policy Loss": 0.35640063881874084, "Value Loss": 21.760841369628906, "_runtime": 1158.7204854488373, "_timestamp": 1585510237.141215, "_step": 397}
{"Episode reward": 63.75010542512914, "Episode length": 693, "Policy Loss": -0.03175578638911247, "Value Loss": 14.425872802734375, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084, 9.60855770111084]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.539699077606201, -4.389195919036865, -4.238692760467529, -4.088189601898193, -3.9376864433288574, -3.7871832847595215, -3.6366801261901855, -3.4861769676208496, -3.3356738090515137, -3.1851706504821777, -3.034667491912842, -2.884164333343506, -2.73366117477417, -2.583158016204834, -2.432654857635498, -2.282151699066162, -2.131648540496826, -1.9811453819274902, -1.8306422233581543, -1.6801390647888184, -1.5296359062194824, -1.3791327476501465, -1.2286295890808105, -1.0781264305114746, -0.9276232719421387, -0.7771201133728027, -0.6266169548034668, -0.47611379623413086, -0.3256106376647949, -0.17510747909545898, -0.024604320526123047, 0.1258988380432129, 0.27640199661254883, 0.42690515518188477, 0.5774083137512207, 0.7279114723205566, 0.8784146308898926, 1.0289177894592285, 1.1794209480285645, 1.3299241065979004, 1.4804272651672363, 1.6309304237365723, 1.7814335823059082, 1.9319367408752441, 2.08243989944458, 2.232943058013916, 2.383446216583252, 2.533949375152588, 2.684452533721924, 2.8349556922912598, 2.9854588508605957, 3.1359620094299316, 3.2864651679992676, 3.4369683265686035, 3.5874714851379395, 3.7379746437072754, 3.8884778022766113, 4.038980960845947, 4.189484119415283, 4.339987277984619, 4.490490436553955, 4.640993595123291, 4.791496753692627, 4.941999912261963, 5.092503070831299]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.4746832847595215, -4.316397190093994, -4.158111095428467, -3.9998247623443604, -3.841538667678833, -3.6832525730133057, -3.524966239929199, -3.366680145263672, -3.2083940505981445, -3.050107955932617, -2.89182186126709, -2.7335355281829834, -2.575249433517456, -2.4169633388519287, -2.2586770057678223, -2.100390911102295, -1.9421048164367676, -1.7838187217712402, -1.625532627105713, -1.4672462940216064, -1.308960199356079, -1.1506741046905518, -0.9923877716064453, -0.834101676940918, -0.6758155822753906, -0.5175294876098633, -0.35924339294433594, -0.2009572982788086, -0.04267072677612305, 0.1156153678894043, 0.27390146255493164, 0.432187557220459, 0.5904736518859863, 0.7487597465515137, 0.907045841217041, 1.0653319358825684, 1.2236180305480957, 1.3819046020507812, 1.5401906967163086, 1.698476791381836, 1.8567628860473633, 2.0150489807128906, 2.173335075378418, 2.3316211700439453, 2.489907741546631, 2.648193836212158, 2.8064799308776855, 2.964766025543213, 3.1230521202087402, 3.2813382148742676, 3.439624309539795, 3.5979104042053223, 3.7561964988708496, 3.914482593536377, 4.072768688201904, 4.231054782867432, 4.389341831207275, 4.547627925872803, 4.70591402053833, 4.864200115203857, 5.022486209869385, 5.180772304534912, 5.3390583992004395, 5.497344493865967, 5.655630588531494]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 5.0, 8.0, 6.0, 13.0, 7.0, 15.0, 17.0, 14.0, 16.0, 18.0, 21.0, 17.0, 20.0, 31.0, 53.0, 19.0, 21.0, 26.0, 13.0, 21.0, 14.0, 14.0, 13.0, 5.0, 9.0, 10.0, 6.0, 4.0, 6.0, 9.0, 4.0, 3.0, 1.0, 3.0, 2.0, 4.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-3.0430665016174316, -2.9358675479888916, -2.8286688327789307, -2.7214698791503906, -2.6142709255218506, -2.5070719718933105, -2.3998732566833496, -2.2926743030548096, -2.1854753494262695, -2.0782766342163086, -1.9710776805877686, -1.863878846168518, -1.7566800117492676, -1.6494810581207275, -1.542282223701477, -1.435083270072937, -1.3278844356536865, -1.220685601234436, -1.113486647605896, -1.0062878131866455, -0.8990888595581055, -0.7918901443481445, -0.6846911907196045, -0.5774922370910645, -0.4702935218811035, -0.3630945682525635, -0.25589561462402344, -0.1486966609954834, -0.04149794578552246, 0.06570100784301758, 0.17289996147155762, 0.28009867668151855, 0.3872976303100586, 0.49449658393859863, 0.6016952991485596, 0.7088942527770996, 0.8160932064056396, 0.9232919216156006, 1.0304908752441406, 1.1376895904541016, 1.2448887825012207, 1.3520874977111816, 1.4592862129211426, 1.5664854049682617, 1.6736841201782227, 1.7808828353881836, 1.8880820274353027, 1.9952807426452637, 2.1024794578552246, 2.2096786499023438, 2.3168773651123047, 2.424076557159424, 2.5312752723693848, 2.6384739875793457, 2.745673179626465, 2.852871894836426, 2.9600706100463867, 3.067269802093506, 3.174468517303467, 3.2816672325134277, 3.388866424560547, 3.496065139770508, 3.6032638549804688, 3.710463047027588, 3.817661762237549]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.067306995391846, -3.9262120723724365, -3.7851171493530273, -3.644022226333618, -3.502927303314209, -3.361832618713379, -3.2207376956939697, -3.0796427726745605, -2.9385478496551514, -2.797452926635742, -2.656358003616333, -2.515263080596924, -2.3741683959960938, -2.2330732345581055, -2.0919785499572754, -1.9508836269378662, -1.809788703918457, -1.6686937808990479, -1.5275988578796387, -1.3865039348602295, -1.2454090118408203, -1.1043143272399902, -0.963219404220581, -0.8221244812011719, -0.6810295581817627, -0.5399346351623535, -0.39883971214294434, -0.25774478912353516, -0.11665010452270508, 0.024445056915283203, 0.16553974151611328, 0.30663490295410156, 0.44772958755493164, 0.5888242721557617, 0.72991943359375, 0.8710141181945801, 1.0121092796325684, 1.1532039642333984, 1.2942991256713867, 1.4353938102722168, 1.576488971710205, 1.7175836563110352, 1.8586783409118652, 1.9997735023498535, 2.1408681869506836, 2.281963348388672, 2.423058032989502, 2.5641531944274902, 2.7052478790283203, 2.8463425636291504, 2.9874377250671387, 3.1285324096679688, 3.269627571105957, 3.410722255706787, 3.5518174171447754, 3.6929121017456055, 3.8340067863464355, 3.975101947784424, 4.116197109222412, 4.257291316986084, 4.398386478424072, 4.5394816398620605, 4.680576801300049, 4.821671009063721, 4.962766170501709]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 5.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.076043725013733, -1.046584129333496, -1.0171244144439697, -0.9876647591590881, -0.9582051038742065, -0.9287455081939697, -0.8992858529090881, -0.8698261976242065, -0.840366542339325, -0.8109068870544434, -0.7814472317695618, -0.7519875764846802, -0.7225279808044434, -0.693068265914917, -0.6636086702346802, -0.6341490149497986, -0.604689359664917, -0.5752297043800354, -0.5457700490951538, -0.5163103938102722, -0.4868507385253906, -0.4573911428451538, -0.4279314875602722, -0.3984718322753906, -0.36901217699050903, -0.33955252170562744, -0.31009286642074585, -0.28063321113586426, -0.25117361545562744, -0.22171396017074585, -0.19225430488586426, -0.16279464960098267, -0.13333499431610107, -0.10387533903121948, -0.07441568374633789, -0.044956088066101074, -0.015496373176574707, 0.01396322250366211, 0.04342293739318848, 0.07288253307342529, 0.10234224796295166, 0.13180184364318848, 0.1612614393234253, 0.19072115421295166, 0.22018074989318848, 0.24964046478271484, 0.27910006046295166, 0.308559775352478, 0.33801937103271484, 0.36747896671295166, 0.396938681602478, 0.42639827728271484, 0.4558579921722412, 0.485317587852478, 0.5147773027420044, 0.5442368984222412, 0.573696494102478, 0.6031562089920044, 0.6326158046722412, 0.6620755195617676, 0.6915351152420044, 0.7209948301315308, 0.7504544258117676, 0.779914140701294, 0.8093737363815308]}, "_runtime": 1160.2529203891754, "_timestamp": 1585510238.67365, "_step": 398}
{"Episode reward": -55.612095693393954, "Episode length": 999, "Policy Loss": -0.2028190642595291, "Value Loss": 0.022551655769348145, "_runtime": 1161.4566230773926, "_timestamp": 1585510239.8773527, "_step": 399}
{"Episode reward": 56.509034991974275, "Episode length": 798, "Policy Loss": -0.07909088581800461, "Value Loss": 12.506148338317871, "_runtime": 1162.963572025299, "_timestamp": 1585510241.3843017, "_step": 400}
{"Episode reward": -53.092773778823535, "Episode length": 999, "Policy Loss": -0.18967455625534058, "Value Loss": 0.021152377128601074, "_runtime": 1163.649705171585, "_timestamp": 1585510242.0704348, "_step": 401}
{"Episode reward": 77.81364934607903, "Episode length": 430, "Policy Loss": 0.04458712041378021, "Value Loss": 23.213138580322266, "_runtime": 1164.8761262893677, "_timestamp": 1585510243.296856, "_step": 402}
{"Episode reward": 57.61238477395442, "Episode length": 803, "Policy Loss": -0.07488095760345459, "Value Loss": 12.427903175354004, "_runtime": 1165.8497483730316, "_timestamp": 1585510244.270478, "_step": 403}
{"Episode reward": 67.04327623207703, "Episode length": 621, "Policy Loss": 0.07146549969911575, "Value Loss": 16.064340591430664, "_runtime": 1166.4559333324432, "_timestamp": 1585510244.876663, "_step": 404}
{"Episode reward": 79.81151757791034, "Episode length": 395, "Policy Loss": 0.07958152145147324, "Value Loss": 25.26577377319336, "_runtime": 1167.8454983234406, "_timestamp": 1585510246.266228, "_step": 405}
{"Episode reward": 52.308105095687516, "Episode length": 919, "Policy Loss": -0.0856778621673584, "Value Loss": 10.883111000061035, "_runtime": 1168.862678527832, "_timestamp": 1585510247.2834082, "_step": 406}
{"Episode reward": 64.2936997826518, "Episode length": 674, "Policy Loss": 0.0004916309262625873, "Value Loss": 14.825881004333496, "_runtime": 1169.4646801948547, "_timestamp": 1585510247.8854098, "_step": 407}
{"Episode reward": 77.16159633640558, "Episode length": 398, "Policy Loss": 0.19438695907592773, "Value Loss": 25.094390869140625, "_runtime": 1170.981520652771, "_timestamp": 1585510249.4022503, "_step": 408}
{"Episode reward": -54.328709267793485, "Episode length": 999, "Policy Loss": -0.1851077675819397, "Value Loss": 0.020138241350650787, "_runtime": 1172.1107745170593, "_timestamp": 1585510250.5315042, "_step": 409}
{"Episode reward": 59.888171899436266, "Episode length": 740, "Policy Loss": -0.012798644602298737, "Value Loss": 13.503808975219727, "_runtime": 1173.1131777763367, "_timestamp": 1585510251.5339074, "_step": 410}
{"Episode reward": 64.81363558909817, "Episode length": 677, "Policy Loss": 0.08211088925600052, "Value Loss": 14.761222839355469, "_runtime": 1173.9694375991821, "_timestamp": 1585510252.3901672, "_step": 411}
{"Episode reward": 71.15007220362173, "Episode length": 548, "Policy Loss": 0.09307625889778137, "Value Loss": 18.2288818359375, "_runtime": 1175.211234331131, "_timestamp": 1585510253.631964, "_step": 412}
{"Episode reward": 57.87873840735243, "Episode length": 816, "Policy Loss": 0.00770233990624547, "Value Loss": 12.253654479980469, "_runtime": 1176.4148366451263, "_timestamp": 1585510254.8355663, "_step": 413}
{"Episode reward": 58.11768675990798, "Episode length": 796, "Policy Loss": -0.06966643780469894, "Value Loss": 12.560004234313965, "_runtime": 1176.9227709770203, "_timestamp": 1585510255.3435006, "_step": 414}
{"Episode reward": 82.09506297872127, "Episode length": 323, "Policy Loss": 0.6789169907569885, "Value Loss": 30.924488067626953, "_runtime": 1178.2843809127808, "_timestamp": 1585510256.7051105, "_step": 415}
{"Episode reward": 51.39091093359783, "Episode length": 901, "Policy Loss": -0.03741424158215523, "Value Loss": 11.090658187866211, "_runtime": 1179.3538637161255, "_timestamp": 1585510257.7745934, "_step": 416}
{"Episode reward": 64.30907743443508, "Episode length": 674, "Policy Loss": -0.039433177560567856, "Value Loss": 14.83138370513916, "_runtime": 1180.5977156162262, "_timestamp": 1585510259.0184453, "_step": 417}
{"Episode reward": 53.327640937180256, "Episode length": 837, "Policy Loss": -0.04236319661140442, "Value Loss": 11.924599647521973, "_runtime": 1182.129730939865, "_timestamp": 1585510260.5504606, "_step": 418}
{"Episode reward": -54.093608459640194, "Episode length": 999, "Policy Loss": -0.18757671117782593, "Value Loss": 0.020583121106028557, "_runtime": 1183.3213744163513, "_timestamp": 1585510261.742104, "_step": 419}
{"Episode reward": 58.175850085945115, "Episode length": 783, "Policy Loss": 0.2159559428691864, "Value Loss": 12.756431579589844, "_runtime": 1184.8418142795563, "_timestamp": 1585510263.262544, "_step": 420}
{"Episode reward": -55.35311675650244, "Episode length": 999, "Policy Loss": -0.19432853162288666, "Value Loss": 0.02082202583551407, "_runtime": 1185.7563602924347, "_timestamp": 1585510264.17709, "_step": 421}
{"Episode reward": 69.01772720925268, "Episode length": 580, "Policy Loss": 0.000687492429278791, "Value Loss": 17.229333877563477, "_runtime": 1187.0804424285889, "_timestamp": 1585510265.501172, "_step": 422}
{"Episode reward": 52.05800387040226, "Episode length": 866, "Policy Loss": 0.0268088448792696, "Value Loss": 11.548080444335938, "_runtime": 1187.84756398201, "_timestamp": 1585510266.2682936, "_step": 423}
{"Episode reward": 73.57256732891312, "Episode length": 483, "Policy Loss": 0.004968743771314621, "Value Loss": 20.685413360595703, "_runtime": 1188.887258529663, "_timestamp": 1585510267.3079882, "_step": 424}
{"Episode reward": 63.6025644125415, "Episode length": 691, "Policy Loss": 0.0490647628903389, "Value Loss": 14.459586143493652, "_runtime": 1189.9503071308136, "_timestamp": 1585510268.3710368, "_step": 425}
{"Episode reward": 62.834879635312895, "Episode length": 687, "Policy Loss": -0.04587388038635254, "Value Loss": 14.55231761932373, "_runtime": 1191.467482328415, "_timestamp": 1585510269.888212, "_step": 426}
{"Episode reward": -53.991518554739585, "Episode length": 999, "Policy Loss": -0.18799155950546265, "Value Loss": 0.01964135654270649, "_runtime": 1192.178726196289, "_timestamp": 1585510270.5994558, "_step": 427}
{"Episode reward": 76.75621513978365, "Episode length": 456, "Policy Loss": 0.13830752670764923, "Value Loss": 21.912181854248047, "_runtime": 1193.2280685901642, "_timestamp": 1585510271.6487982, "_step": 428}
{"Episode reward": 62.82837657622195, "Episode length": 684, "Policy Loss": -0.01980850286781788, "Value Loss": 14.592476844787598, "_runtime": 1194.2197210788727, "_timestamp": 1585510272.6404507, "_step": 429}
{"Episode reward": 65.18161017349479, "Episode length": 646, "Policy Loss": -0.031850118190050125, "Value Loss": 15.44373893737793, "_runtime": 1194.912133693695, "_timestamp": 1585510273.3328633, "_step": 430}
{"Episode reward": 75.12106968568723, "Episode length": 455, "Policy Loss": 0.32845205068588257, "Value Loss": 21.918806076049805, "_runtime": 1196.424468755722, "_timestamp": 1585510274.8451984, "_step": 431}
{"Episode reward": -53.681498632080626, "Episode length": 999, "Policy Loss": -0.18525412678718567, "Value Loss": 0.019372297450900078, "_runtime": 1197.0430703163147, "_timestamp": 1585510275.4638, "_step": 432}
{"Episode reward": 80.77876628072966, "Episode length": 397, "Policy Loss": 0.2599523365497589, "Value Loss": 25.144193649291992, "_runtime": 1197.7960255146027, "_timestamp": 1585510276.2167552, "_step": 433}
{"Episode reward": 74.08727869576106, "Episode length": 505, "Policy Loss": 0.013301519677042961, "Value Loss": 19.771549224853516, "_runtime": 1199.1950798034668, "_timestamp": 1585510277.6158094, "_step": 434}
{"Episode reward": 50.26557956566822, "Episode length": 906, "Policy Loss": -0.020989391952753067, "Value Loss": 11.033171653747559, "_runtime": 1200.063061952591, "_timestamp": 1585510278.4837916, "_step": 435}
{"Episode reward": 68.80707107483474, "Episode length": 575, "Policy Loss": -0.01857246644794941, "Value Loss": 17.364896774291992, "_runtime": 1201.5509810447693, "_timestamp": 1585510279.9717107, "_step": 436}
{"Episode reward": -56.396009084659255, "Episode length": 999, "Policy Loss": -0.19086652994155884, "Value Loss": 0.020560840144753456, "_runtime": 1203.0333678722382, "_timestamp": 1585510281.4540975, "_step": 437}
{"Episode reward": 47.372280304462095, "Episode length": 966, "Policy Loss": -0.08996234089136124, "Value Loss": 10.35348892211914, "_runtime": 1203.9785776138306, "_timestamp": 1585510282.3993073, "_step": 438}
{"Episode reward": 65.30824302268198, "Episode length": 616, "Policy Loss": 0.10358212143182755, "Value Loss": 16.226388931274414, "_runtime": 1204.4467108249664, "_timestamp": 1585510282.8674405, "_step": 439}
{"Episode reward": 84.13716993352094, "Episode length": 283, "Policy Loss": 0.21800664067268372, "Value Loss": 35.2471809387207, "_runtime": 1205.2887647151947, "_timestamp": 1585510283.7094944, "_step": 440}
{"Episode reward": 70.12361761232748, "Episode length": 544, "Policy Loss": 0.023597009479999542, "Value Loss": 18.33587074279785, "_runtime": 1206.660460948944, "_timestamp": 1585510285.0811906, "_step": 441}
{"Episode reward": 54.68347689913952, "Episode length": 882, "Policy Loss": -0.0049665835686028, "Value Loss": 11.317007064819336, "_runtime": 1207.5061151981354, "_timestamp": 1585510285.9268448, "_step": 442}
{"Episode reward": 68.30032828410205, "Episode length": 572, "Policy Loss": -0.038807205855846405, "Value Loss": 17.443822860717773, "_runtime": 1208.827540397644, "_timestamp": 1585510287.24827, "_step": 443}
{"Episode reward": 54.162311865773454, "Episode length": 881, "Policy Loss": 0.10033443570137024, "Value Loss": 11.329998016357422, "_runtime": 1209.8272442817688, "_timestamp": 1585510288.247974, "_step": 444}
{"Episode reward": 64.41170374234605, "Episode length": 660, "Policy Loss": -0.01525703351944685, "Value Loss": 15.116369247436523, "_runtime": 1210.743482351303, "_timestamp": 1585510289.164212, "_step": 445}
{"Episode reward": 67.20598193808107, "Episode length": 603, "Policy Loss": 0.2739875912666321, "Value Loss": 16.567602157592773, "_runtime": 1211.2077152729034, "_timestamp": 1585510289.628445, "_step": 446}
{"Episode reward": 85.74286772138377, "Episode length": 270, "Policy Loss": 0.3656386137008667, "Value Loss": 36.98936080932617, "_runtime": 1212.257735490799, "_timestamp": 1585510290.6784651, "_step": 447}
{"Episode reward": 60.725805071683965, "Episode length": 698, "Policy Loss": -0.00771619938313961, "Value Loss": 14.32192611694336, "_runtime": 1213.7445809841156, "_timestamp": 1585510292.1653106, "_step": 448}
{"Episode reward": -53.18298586898155, "Episode length": 999, "Policy Loss": -0.1931334137916565, "Value Loss": 0.022276073694229126, "_runtime": 1214.4796257019043, "_timestamp": 1585510292.9003553, "_step": 449}
{"Episode reward": 70.95509531271321, "Episode length": 504, "Policy Loss": 0.11368703842163086, "Value Loss": 19.805849075317383, "_runtime": 1215.9785442352295, "_timestamp": 1585510294.3992739, "_step": 450}
{"Episode reward": -54.014970936695775, "Episode length": 999, "Policy Loss": -0.201793372631073, "Value Loss": 0.023123836144804955, "_runtime": 1216.8965003490448, "_timestamp": 1585510295.31723, "_step": 451}
{"Episode reward": 67.08357348835557, "Episode length": 599, "Policy Loss": -0.0045380969531834126, "Value Loss": 16.685060501098633, "_runtime": 1217.4710488319397, "_timestamp": 1585510295.8917785, "_step": 452}
{"Episode reward": 80.96970220844499, "Episode length": 374, "Policy Loss": 0.3752942681312561, "Value Loss": 26.657270431518555, "_runtime": 1218.5306510925293, "_timestamp": 1585510296.9513807, "_step": 453}
{"Episode reward": 62.76151113156413, "Episode length": 696, "Policy Loss": -0.05418311432003975, "Value Loss": 14.349711418151855, "_runtime": 1219.740210533142, "_timestamp": 1585510298.1609402, "_step": 454}
{"Episode reward": 57.597777969420086, "Episode length": 798, "Policy Loss": -0.08590181916952133, "Value Loss": 12.521099090576172, "_runtime": 1220.9634215831757, "_timestamp": 1585510299.3841512, "_step": 455}
{"Episode reward": 56.190843027800454, "Episode length": 825, "Policy Loss": -0.08703560382127762, "Value Loss": 12.118619918823242, "_runtime": 1221.5453021526337, "_timestamp": 1585510299.9660318, "_step": 456}
{"Episode reward": 81.12417695716735, "Episode length": 372, "Policy Loss": 0.23183505237102509, "Value Loss": 26.85010528564453, "_runtime": 1222.4185888767242, "_timestamp": 1585510300.8393185, "_step": 457}
{"Episode reward": 68.4645737181317, "Episode length": 575, "Policy Loss": -0.03693892061710358, "Value Loss": 17.36495590209961, "_runtime": 1223.064224243164, "_timestamp": 1585510301.4849539, "_step": 458}
{"Episode reward": 75.65265965577737, "Episode length": 416, "Policy Loss": 0.038656868040561676, "Value Loss": 23.969587326049805, "_runtime": 1223.912222623825, "_timestamp": 1585510302.3329523, "_step": 459}
{"Episode reward": 68.8605008545977, "Episode length": 567, "Policy Loss": 0.3347284495830536, "Value Loss": 17.62626075744629, "_runtime": 1225.3577539920807, "_timestamp": 1585510303.7784836, "_step": 460}
{"Episode reward": 47.89758849345885, "Episode length": 962, "Policy Loss": -0.11801570653915405, "Value Loss": 10.3978271484375, "_runtime": 1226.3567280769348, "_timestamp": 1585510304.7774577, "_step": 461}
{"Episode reward": 62.79629373480378, "Episode length": 675, "Policy Loss": -0.06473609805107117, "Value Loss": 14.781309127807617, "_runtime": 1227.3477199077606, "_timestamp": 1585510305.7684495, "_step": 462}
{"Episode reward": 64.18896807043473, "Episode length": 658, "Policy Loss": -0.06736249476671219, "Value Loss": 15.174736022949219, "_runtime": 1228.8103320598602, "_timestamp": 1585510307.2310617, "_step": 463}
{"Episode reward": 49.622898872052176, "Episode length": 956, "Policy Loss": 0.003486797446385026, "Value Loss": 10.448163986206055, "_runtime": 1229.4882678985596, "_timestamp": 1585510307.9089975, "_step": 464}
{"Episode reward": 76.17375306918282, "Episode length": 446, "Policy Loss": 0.20167209208011627, "Value Loss": 22.398527145385742, "_runtime": 1230.3070087432861, "_timestamp": 1585510308.7277384, "_step": 465}
{"Episode reward": 70.89786751106415, "Episode length": 535, "Policy Loss": 0.0064048171043396, "Value Loss": 18.650741577148438, "_runtime": 1231.3398206233978, "_timestamp": 1585510309.7605503, "_step": 466}
{"Episode reward": 63.224134663930144, "Episode length": 672, "Policy Loss": -0.08434027433395386, "Value Loss": 14.859530448913574, "_runtime": 1232.3507459163666, "_timestamp": 1585510310.7714756, "_step": 467}
{"Episode reward": 62.95163443888646, "Episode length": 672, "Policy Loss": -0.07719336450099945, "Value Loss": 14.874222755432129, "_runtime": 1233.5222556591034, "_timestamp": 1585510311.9429853, "_step": 468}
{"Episode reward": 56.03901354952722, "Episode length": 785, "Policy Loss": -0.035811640322208405, "Value Loss": 12.725483894348145, "_runtime": 1234.6836082935333, "_timestamp": 1585510313.104338, "_step": 469}
{"Episode reward": 57.80373545241703, "Episode length": 767, "Policy Loss": 0.11220933496952057, "Value Loss": 13.033612251281738, "_runtime": 1236.1902163028717, "_timestamp": 1585510314.610946, "_step": 470}
{"Episode reward": -58.080271295696505, "Episode length": 999, "Policy Loss": -0.23266080021858215, "Value Loss": 0.028416186571121216, "_runtime": 1237.5954835414886, "_timestamp": 1585510316.0162132, "_step": 471}
{"Episode reward": 51.153352272914816, "Episode length": 907, "Policy Loss": -0.011300605721771717, "Value Loss": 11.021230697631836, "_runtime": 1238.6512780189514, "_timestamp": 1585510317.0720077, "_step": 472}
{"Episode reward": 62.64145283234646, "Episode length": 693, "Policy Loss": -0.07805929332971573, "Value Loss": 14.397712707519531, "_runtime": 1239.7916119098663, "_timestamp": 1585510318.2123415, "_step": 473}
{"Episode reward": 58.96333872537952, "Episode length": 742, "Policy Loss": -0.04944773390889168, "Value Loss": 13.475741386413574, "_runtime": 1241.256796836853, "_timestamp": 1585510319.6775265, "_step": 474}
{"Episode reward": 45.514134768448365, "Episode length": 961, "Policy Loss": -0.05948865786194801, "Value Loss": 10.39504623413086, "_runtime": 1242.349854707718, "_timestamp": 1585510320.7705843, "_step": 475}
{"Episode reward": 60.20264783591784, "Episode length": 715, "Policy Loss": 0.011704159900546074, "Value Loss": 13.971145629882812, "_runtime": 1243.6015133857727, "_timestamp": 1585510322.022243, "_step": 476}
{"Episode reward": 54.01232737684679, "Episode length": 822, "Policy Loss": -0.011270616203546524, "Value Loss": 12.14276123046875, "_runtime": 1244.5861837863922, "_timestamp": 1585510323.0069134, "_step": 477}
{"Episode reward": 64.23940913590579, "Episode length": 635, "Policy Loss": -0.007224132306873798, "Value Loss": 15.742526054382324, "_runtime": 1245.613356590271, "_timestamp": 1585510324.0340862, "_step": 478}
{"Episode reward": 62.336651142371814, "Episode length": 677, "Policy Loss": 0.11125405132770538, "Value Loss": 14.73782730102539, "_runtime": 1246.9066033363342, "_timestamp": 1585510325.327333, "_step": 479}
{"Episode reward": 51.533911789361696, "Episode length": 854, "Policy Loss": -0.09747884422540665, "Value Loss": 11.703672409057617, "_runtime": 1248.3999025821686, "_timestamp": 1585510326.8206322, "_step": 480}
{"Episode reward": -56.42435866350698, "Episode length": 999, "Policy Loss": -0.21116472780704498, "Value Loss": 0.024726271629333496, "_runtime": 1249.6286108493805, "_timestamp": 1585510328.0493405, "_step": 481}
{"Episode reward": 55.96981635354814, "Episode length": 819, "Policy Loss": -0.06991837173700333, "Value Loss": 12.18612003326416, "_runtime": 1250.9593982696533, "_timestamp": 1585510329.380128, "_step": 482}
{"Episode reward": 50.135594773589254, "Episode length": 870, "Policy Loss": -0.09519407153129578, "Value Loss": 11.490949630737305, "_runtime": 1251.985606431961, "_timestamp": 1585510330.406336, "_step": 483}
{"Episode reward": 62.59988810371105, "Episode length": 663, "Policy Loss": -0.02146320231258869, "Value Loss": 15.074667930603027, "_runtime": 1252.5440526008606, "_timestamp": 1585510330.9647822, "_step": 484}
{"Episode reward": 80.68346367388433, "Episode length": 357, "Policy Loss": 0.1110534593462944, "Value Loss": 27.97294044494629, "_runtime": 1253.5470209121704, "_timestamp": 1585510331.9677505, "_step": 485}
{"Episode reward": 62.02794061831843, "Episode length": 661, "Policy Loss": -0.0581737644970417, "Value Loss": 15.121454238891602, "_runtime": 1254.6374933719635, "_timestamp": 1585510333.058223, "_step": 486}
{"Episode reward": 60.89674406594522, "Episode length": 720, "Policy Loss": 0.16710719466209412, "Value Loss": 13.872611045837402, "_runtime": 1255.1553795337677, "_timestamp": 1585510333.5761092, "_step": 487}
{"Episode reward": 80.32241528144759, "Episode length": 341, "Policy Loss": 0.0660131573677063, "Value Loss": 29.275508880615234, "_runtime": 1256.6429843902588, "_timestamp": 1585510335.063714, "_step": 488}
{"Episode reward": -54.81735070170954, "Episode length": 999, "Policy Loss": -0.19965963065624237, "Value Loss": 0.02186138741672039, "_runtime": 1257.4482357501984, "_timestamp": 1585510335.8689654, "_step": 489}
{"Episode reward": 70.2592920805854, "Episode length": 525, "Policy Loss": -0.012558763846755028, "Value Loss": 19.028919219970703, "_runtime": 1258.0435855388641, "_timestamp": 1585510336.4643152, "_step": 490}
{"Episode reward": 76.04617881913018, "Episode length": 404, "Policy Loss": 0.04432842135429382, "Value Loss": 24.73249626159668, "_runtime": 1259.5608117580414, "_timestamp": 1585510337.9815414, "_step": 491}
{"Episode reward": -57.09542378767627, "Episode length": 999, "Policy Loss": -0.20129704475402832, "Value Loss": 0.02242898754775524, "_runtime": 1260.3099055290222, "_timestamp": 1585510338.7306352, "_step": 492}
{"Episode reward": 72.97464111700538, "Episode length": 493, "Policy Loss": -0.015039117075502872, "Value Loss": 20.26907730102539, "_runtime": 1261.1924741268158, "_timestamp": 1585510339.6132038, "_step": 493}
{"Episode reward": 68.25526646402307, "Episode length": 593, "Policy Loss": -0.040300652384757996, "Value Loss": 16.828943252563477, "_runtime": 1262.7476239204407, "_timestamp": 1585510341.1683536, "_step": 494}
{"Episode reward": -52.69951960861575, "Episode length": 999, "Policy Loss": -0.1900225132703781, "Value Loss": 0.02112543024122715, "_runtime": 1263.75430893898, "_timestamp": 1585510342.1750386, "_step": 495}
{"Episode reward": 64.15498852207338, "Episode length": 678, "Policy Loss": -0.02745467983186245, "Value Loss": 14.739145278930664, "_runtime": 1264.5311625003815, "_timestamp": 1585510342.9518921, "_step": 496}
{"Episode reward": 68.75357016713468, "Episode length": 511, "Policy Loss": -0.02800355851650238, "Value Loss": 19.519983291625977, "_runtime": 1265.2334270477295, "_timestamp": 1585510343.6541567, "_step": 497}
{"Episode reward": 74.05092422628093, "Episode length": 448, "Policy Loss": 0.140999436378479, "Value Loss": 22.301254272460938, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125, 114.45361328125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-54.0301399230957, -52.312049865722656, -50.593955993652344, -48.8758659362793, -47.15777587890625, -45.43968200683594, -43.72159194946289, -42.003501892089844, -40.28540802001953, -38.56731414794922, -36.84922409057617, -35.131134033203125, -33.41304016113281, -31.694950103759766, -29.97686004638672, -28.25876808166504, -26.54067611694336, -24.82258415222168, -23.1044921875, -21.386402130126953, -19.66830825805664, -17.950218200683594, -16.232128143310547, -14.514034271240234, -12.795944213867188, -11.07785415649414, -9.359760284423828, -7.641670227050781, -5.923580169677734, -4.205486297607422, -2.487396240234375, -0.7693023681640625, 0.9487876892089844, 2.6668777465820312, 4.384971618652344, 6.103061676025391, 7.821155548095703, 9.53924560546875, 11.257335662841797, 12.97542953491211, 14.693523406982422, 16.411609649658203, 18.129703521728516, 19.847797393798828, 21.56588363647461, 23.283977508544922, 25.002071380615234, 26.720157623291016, 28.438251495361328, 30.15634536743164, 31.874431610107422, 33.592525482177734, 35.31061935424805, 37.02870559692383, 38.74679946899414, 40.46489334106445, 42.182979583740234, 43.90107345581055, 45.61916732788086, 47.33726119995117, 49.05534744262695, 50.773441314697266, 52.49153518676758, 54.20962142944336, 55.92771530151367]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-50.53276443481445, -48.69070053100586, -46.848636627197266, -45.006568908691406, -43.16450500488281, -41.32244110107422, -39.480377197265625, -37.63831329345703, -35.79624938964844, -33.954185485839844, -32.112117767333984, -30.27005386352539, -28.427989959716797, -26.58592414855957, -24.743860244750977, -22.90179443359375, -21.059730529785156, -19.217666625976562, -17.37560272216797, -15.53353500366211, -13.691471099853516, -11.849407196044922, -10.007343292236328, -8.165279388427734, -6.323215484619141, -4.481147766113281, -2.6390838623046875, -0.7970199584960938, 1.0450439453125, 2.8871078491210938, 4.729175567626953, 6.571239471435547, 8.41330337524414, 10.255367279052734, 12.097431182861328, 13.939495086669922, 15.781558990478516, 17.62362289428711, 19.465694427490234, 21.307758331298828, 23.149822235107422, 24.991886138916016, 26.83395004272461, 28.676013946533203, 30.518077850341797, 32.36014175415039, 34.202205657958984, 36.04426956176758, 37.88633346557617, 39.7284049987793, 41.57046890258789, 43.412532806396484, 45.25459671020508, 47.09666061401367, 48.938724517822266, 50.78078842163086, 52.62285232543945, 54.46491622924805, 56.30698013305664, 58.149051666259766, 59.99111557006836, 61.83317947387695, 63.67524337768555, 65.51730346679688, 67.359375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 5.0, 1.0, 2.0, 2.0, 5.0, 5.0, 3.0, 11.0, 4.0, 6.0, 9.0, 9.0, 14.0, 18.0, 13.0, 19.0, 21.0, 24.0, 24.0, 14.0, 21.0, 62.0, 21.0, 19.0, 16.0, 21.0, 18.0, 19.0, 18.0, 11.0, 11.0, 10.0, 8.0, 7.0, 6.0, 5.0, 6.0, 4.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-38.69527053833008, -37.2827033996582, -35.87013626098633, -34.45756912231445, -33.04500198364258, -31.632434844970703, -30.219867706298828, -28.807300567626953, -27.394733428955078, -25.982166290283203, -24.569599151611328, -23.157032012939453, -21.744462966918945, -20.33189582824707, -18.919328689575195, -17.50676155090332, -16.094194412231445, -14.68162727355957, -13.269060134887695, -11.85649299621582, -10.443925857543945, -9.03135871887207, -7.618791580200195, -6.2062225341796875, -4.7936553955078125, -3.3810882568359375, -1.9685211181640625, -0.5559539794921875, 0.8566131591796875, 2.2691802978515625, 3.6817474365234375, 5.0943145751953125, 6.5068817138671875, 7.9194488525390625, 9.332015991210938, 10.744583129882812, 12.157150268554688, 13.569717407226562, 14.982284545898438, 16.394851684570312, 17.807418823242188, 19.219985961914062, 20.632553100585938, 22.045120239257812, 23.457687377929688, 24.870254516601562, 26.282825469970703, 27.695392608642578, 29.107959747314453, 30.520526885986328, 31.933094024658203, 33.34566116333008, 34.75822830200195, 36.17079544067383, 37.5833625793457, 38.99592971801758, 40.40849685668945, 41.82106399536133, 43.2336311340332, 44.64619827270508, 46.05876541137695, 47.47133255004883, 48.8838996887207, 50.29646682739258, 51.70903396606445]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-44.996803283691406, -43.37287902832031, -41.748958587646484, -40.12503433227539, -38.5011100769043, -36.87718963623047, -35.253265380859375, -33.62934112548828, -32.00542068481445, -30.38149642944336, -28.7575740814209, -27.133651733398438, -25.509727478027344, -23.885805130004883, -22.261882781982422, -20.637958526611328, -19.014036178588867, -17.390113830566406, -15.766189575195312, -14.142267227172852, -12.51834487915039, -10.894420623779297, -9.270500183105469, -7.646575927734375, -6.022651672363281, -4.398731231689453, -2.7748069763183594, -1.1508827209472656, 0.4730377197265625, 2.0969619750976562, 3.72088623046875, 5.344806671142578, 6.968730926513672, 8.592655181884766, 10.216575622558594, 11.840499877929688, 13.464424133300781, 15.08834457397461, 16.712268829345703, 18.336193084716797, 19.960113525390625, 21.58403778076172, 23.207962036132812, 24.831886291503906, 26.45580291748047, 28.079727172851562, 29.703651428222656, 31.32757568359375, 32.951499938964844, 34.57542419433594, 36.1993408203125, 37.823265075683594, 39.44718933105469, 41.07111358642578, 42.695037841796875, 44.31896209716797, 45.94287872314453, 47.566802978515625, 49.19072723388672, 50.81465148925781, 52.438575744628906, 54.0625, 55.68641662597656, 57.310340881347656, 58.93426513671875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-17.18979263305664, -16.716768264770508, -16.243743896484375, -15.770719528198242, -15.297694206237793, -14.82466983795166, -14.351645469665527, -13.878621101379395, -13.405595779418945, -12.932571411132812, -12.45954704284668, -11.986522674560547, -11.513498306274414, -11.040473937988281, -10.567449569702148, -10.0944242477417, -9.621399879455566, -9.148375511169434, -8.6753511428833, -8.202325820922852, -7.729301452636719, -7.256277084350586, -6.783252716064453, -6.31022834777832, -5.8372039794921875, -5.364178657531738, -4.8911542892456055, -4.418129920959473, -3.94510555267334, -3.472081184387207, -2.999055862426758, -2.526031494140625, -2.053007125854492, -1.5799827575683594, -1.1069583892822266, -0.6339340209960938, -0.16090965270996094, 0.3121147155761719, 0.7851409912109375, 1.2581653594970703, 1.7311897277832031, 2.204214096069336, 2.6772384643554688, 3.1502628326416016, 3.6232872009277344, 4.096311569213867, 4.5693359375, 5.042360305786133, 5.515384674072266, 5.988410949707031, 6.461435317993164, 6.934459686279297, 7.40748405456543, 7.8805084228515625, 8.353532791137695, 8.826557159423828, 9.299581527709961, 9.772605895996094, 10.245630264282227, 10.718656539916992, 11.191680908203125, 11.664705276489258, 12.13772964477539, 12.610754013061523, 13.083778381347656]}, "_runtime": 1266.5949771404266, "_timestamp": 1585510345.0157068, "_step": 498}
{"Episode reward": 49.69357984716609, "Episode length": 903, "Policy Loss": -0.06238099932670593, "Value Loss": 11.072565078735352, "_runtime": 1266.5949771404266, "_timestamp": 1585510345.0157068, "_step": 499}
