{"Episode reward": -48.729910582203786, "Episode length": 999, "Policy Loss": -0.07518411427736282, "Value Loss": 0.030202778056263924, "_runtime": 7640.430038452148, "_timestamp": 1585516718.850768, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16145385801792145, "Value Loss": 2.980769395828247, "_runtime": 7640.613927364349, "_timestamp": 1585516719.034657, "_step": 1}
{"Episode reward": 89.32557936833938, "Episode length": 114, "Policy Loss": 7.381207466125488, "Value Loss": 1009.7557373046875, "_runtime": 7642.18551325798, "_timestamp": 1585516720.606243, "_step": 2}
{"Episode reward": -95.93163860654867, "Episode length": 999, "Policy Loss": 36.500579833984375, "Value Loss": 2176.5927734375, "_runtime": 7643.750987291336, "_timestamp": 1585516722.171717, "_step": 3}
{"Episode reward": -99.85731240371102, "Episode length": 999, "Policy Loss": -0.29582473635673523, "Value Loss": 11.255577087402344, "_runtime": 7645.260365009308, "_timestamp": 1585516723.6810946, "_step": 4}
{"Episode reward": -99.88921738723154, "Episode length": 999, "Policy Loss": -0.017586801201105118, "Value Loss": 110.34194946289062, "_runtime": 7646.852410078049, "_timestamp": 1585516725.2731397, "_step": 5}
{"Episode reward": -99.62459383356311, "Episode length": 999, "Policy Loss": -2.0759999752044678, "Value Loss": 406.464599609375, "_runtime": 7648.431509256363, "_timestamp": 1585516726.852239, "_step": 6}
{"Episode reward": -99.6297353827338, "Episode length": 999, "Policy Loss": 3.3831593990325928, "Value Loss": 34.96466064453125, "_runtime": 7650.022018432617, "_timestamp": 1585516728.442748, "_step": 7}
{"Episode reward": -99.59712845160453, "Episode length": 999, "Policy Loss": -4.9573211669921875, "Value Loss": 128.31861877441406, "_runtime": 7651.600455760956, "_timestamp": 1585516730.0211854, "_step": 8}
{"Episode reward": -99.83264553285996, "Episode length": 999, "Policy Loss": -0.8151402473449707, "Value Loss": 591.9466552734375, "_runtime": 7653.187714576721, "_timestamp": 1585516731.6084442, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.157212734222412, "Value Loss": 68.34286499023438, "_runtime": 7654.737161874771, "_timestamp": 1585516733.1578915, "_step": 10}
{"Episode reward": -99.83112805578659, "Episode length": 999, "Policy Loss": -5.666668891906738, "Value Loss": 3.2632064819335938, "_runtime": 7656.32373046875, "_timestamp": 1585516734.74446, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -7.5231733322143555, "Value Loss": 25.777029037475586, "_runtime": 7657.904947757721, "_timestamp": 1585516736.3256774, "_step": 12}
{"Episode reward": -99.78808841742818, "Episode length": 999, "Policy Loss": -13.930802345275879, "Value Loss": 52.14096450805664, "_runtime": 7659.463800191879, "_timestamp": 1585516737.8845298, "_step": 13}
{"Episode reward": -99.67035142474106, "Episode length": 999, "Policy Loss": -7.456831455230713, "Value Loss": 11.684769630432129, "_runtime": 7661.058242797852, "_timestamp": 1585516739.4789724, "_step": 14}
{"Episode reward": -99.67939999346927, "Episode length": 999, "Policy Loss": -7.346400737762451, "Value Loss": 14.68352222442627, "_runtime": 7662.651978731155, "_timestamp": 1585516741.0727084, "_step": 15}
{"Episode reward": -98.88776279127389, "Episode length": 999, "Policy Loss": -3.794642925262451, "Value Loss": 13.978525161743164, "_runtime": 7664.22661113739, "_timestamp": 1585516742.6473408, "_step": 16}
{"Episode reward": -99.78860975580444, "Episode length": 999, "Policy Loss": -2.6200382709503174, "Value Loss": 5.501448154449463, "_runtime": 7665.810745477676, "_timestamp": 1585516744.231475, "_step": 17}
{"Episode reward": -99.65747137884728, "Episode length": 999, "Policy Loss": -0.45246005058288574, "Value Loss": 4.281412601470947, "_runtime": 7667.3967072963715, "_timestamp": 1585516745.817437, "_step": 18}
{"Episode reward": -99.77260768902967, "Episode length": 999, "Policy Loss": 1.2522600889205933, "Value Loss": 1.495214819908142, "_runtime": 7668.974367141724, "_timestamp": 1585516747.3950968, "_step": 19}
{"Episode reward": -99.53088305695029, "Episode length": 999, "Policy Loss": 3.459455728530884, "Value Loss": 2.302816390991211, "_runtime": 7670.563477516174, "_timestamp": 1585516748.9842072, "_step": 20}
{"Episode reward": -99.65770290599677, "Episode length": 999, "Policy Loss": 1.8835469484329224, "Value Loss": 0.6574749946594238, "_runtime": 7672.1600613594055, "_timestamp": 1585516750.580791, "_step": 21}
{"Episode reward": -99.73235167079118, "Episode length": 999, "Policy Loss": 2.7656686305999756, "Value Loss": 1.8085217475891113, "_runtime": 7673.775270938873, "_timestamp": 1585516752.1960006, "_step": 22}
{"Episode reward": -99.69413552119629, "Episode length": 999, "Policy Loss": 4.474742412567139, "Value Loss": 2.9941763877868652, "_runtime": 7675.357038259506, "_timestamp": 1585516753.777768, "_step": 23}
{"Episode reward": -99.6533014522525, "Episode length": 999, "Policy Loss": 4.255969524383545, "Value Loss": 2.4325904846191406, "_runtime": 7676.929819107056, "_timestamp": 1585516755.3505487, "_step": 24}
{"Episode reward": -99.62661564965919, "Episode length": 999, "Policy Loss": 3.5999133586883545, "Value Loss": 1.897545337677002, "_runtime": 7678.510974884033, "_timestamp": 1585516756.9317045, "_step": 25}
{"Episode reward": -99.1707443268166, "Episode length": 999, "Policy Loss": 3.6360349655151367, "Value Loss": 1.7989251613616943, "_runtime": 7680.094198226929, "_timestamp": 1585516758.5149279, "_step": 26}
{"Episode reward": -99.55452444732369, "Episode length": 999, "Policy Loss": 2.87469220161438, "Value Loss": 0.8420000076293945, "_runtime": 7681.68451666832, "_timestamp": 1585516760.1052463, "_step": 27}
{"Episode reward": -99.80041464602014, "Episode length": 999, "Policy Loss": 1.8684759140014648, "Value Loss": 0.7179734110832214, "_runtime": 7683.271039485931, "_timestamp": 1585516761.6917691, "_step": 28}
{"Episode reward": -99.70318782894942, "Episode length": 999, "Policy Loss": 0.7429549098014832, "Value Loss": 0.38166865706443787, "_runtime": 7684.853884458542, "_timestamp": 1585516763.274614, "_step": 29}
{"Episode reward": -99.50435182071209, "Episode length": 999, "Policy Loss": -0.8017892837524414, "Value Loss": 0.30941855907440186, "_runtime": 7686.45560669899, "_timestamp": 1585516764.8763363, "_step": 30}
{"Episode reward": -99.80379356695781, "Episode length": 999, "Policy Loss": -1.305761456489563, "Value Loss": 0.977708101272583, "_runtime": 7688.029750585556, "_timestamp": 1585516766.4504802, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.830997109413147, "Value Loss": 0.4325498044490814, "_runtime": 7689.603621006012, "_timestamp": 1585516768.0243506, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11094141006469727, "Value Loss": 52.40226364135742, "_runtime": 7691.183580636978, "_timestamp": 1585516769.6043103, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.5918402671813965, "Value Loss": 21.978961944580078, "_runtime": 7692.731812238693, "_timestamp": 1585516771.1525419, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5729082822799683, "Value Loss": 257.5044250488281, "_runtime": 7694.296159744263, "_timestamp": 1585516772.7168894, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5425637364387512, "Value Loss": 548.4695434570312, "_runtime": 7695.87477016449, "_timestamp": 1585516774.2954998, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.184412002563477, "Value Loss": 76.96607208251953, "_runtime": 7697.469970464706, "_timestamp": 1585516775.8907, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.897774696350098, "Value Loss": 12.984378814697266, "_runtime": 7699.047799110413, "_timestamp": 1585516777.4685287, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8320602178573608, "Value Loss": 254.32188415527344, "_runtime": 7700.625683784485, "_timestamp": 1585516779.0464134, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6756685972213745, "Value Loss": 34.83492660522461, "_runtime": 7702.196529865265, "_timestamp": 1585516780.6172595, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.205382823944092, "Value Loss": 139.64393615722656, "_runtime": 7703.761500120163, "_timestamp": 1585516782.1822298, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.674308776855469, "Value Loss": 97.21234893798828, "_runtime": 7705.341412067413, "_timestamp": 1585516783.7621417, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.694193363189697, "Value Loss": 8.464132308959961, "_runtime": 7706.901764392853, "_timestamp": 1585516785.322494, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.327729225158691, "Value Loss": 482.0154724121094, "_runtime": 7708.464695453644, "_timestamp": 1585516786.885425, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.426055669784546, "Value Loss": 122.31974029541016, "_runtime": 7710.034601211548, "_timestamp": 1585516788.4553308, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3367793560028076, "Value Loss": 75.31385040283203, "_runtime": 7711.607112646103, "_timestamp": 1585516790.0278423, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7936323881149292, "Value Loss": 0.3174890875816345, "_runtime": 7713.1836841106415, "_timestamp": 1585516791.6044137, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4535733461380005, "Value Loss": 3.1100716590881348, "_runtime": 7714.752059936523, "_timestamp": 1585516793.1727896, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2281575202941895, "Value Loss": 111.67724609375, "_runtime": 7716.327988147736, "_timestamp": 1585516794.7487178, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7112413644790649, "Value Loss": 12.356276512145996, "_runtime": 7717.903057813644, "_timestamp": 1585516796.3237875, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.842677593231201, "Value Loss": 12.4319429397583, "_runtime": 7719.480320692062, "_timestamp": 1585516797.9010503, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.391499042510986, "Value Loss": 7.593866348266602, "_runtime": 7721.090461492538, "_timestamp": 1585516799.5111911, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.500633716583252, "Value Loss": 108.66523742675781, "_runtime": 7722.665463685989, "_timestamp": 1585516801.0861933, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.781558036804199, "Value Loss": 6.996711254119873, "_runtime": 7724.244221448898, "_timestamp": 1585516802.664951, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.705512285232544, "Value Loss": 0.825285792350769, "_runtime": 7725.803148269653, "_timestamp": 1585516804.223878, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.7153239250183105, "Value Loss": 5.115091800689697, "_runtime": 7727.375281095505, "_timestamp": 1585516805.7960107, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7867990732192993, "Value Loss": 5.508061408996582, "_runtime": 7728.943454504013, "_timestamp": 1585516807.3641841, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8682929277420044, "Value Loss": 73.39366912841797, "_runtime": 7730.5073091983795, "_timestamp": 1585516808.9280388, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7697276473045349, "Value Loss": 34.8582878112793, "_runtime": 7732.072388410568, "_timestamp": 1585516810.493118, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9404103755950928, "Value Loss": 8.141373634338379, "_runtime": 7733.649305820465, "_timestamp": 1585516812.0700355, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1429239511489868, "Value Loss": 29.8675479888916, "_runtime": 7735.213471889496, "_timestamp": 1585516813.6342015, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5571603775024414, "Value Loss": 7.833454132080078, "_runtime": 7736.7672119140625, "_timestamp": 1585516815.1879416, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9538166522979736, "Value Loss": 1.1060634851455688, "_runtime": 7738.344970941544, "_timestamp": 1585516816.7657006, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3396832942962646, "Value Loss": 12.196596145629883, "_runtime": 7739.90758395195, "_timestamp": 1585516818.3283136, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.923448324203491, "Value Loss": 0.84879469871521, "_runtime": 7741.48085474968, "_timestamp": 1585516819.9015844, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.571240186691284, "Value Loss": 6.161641597747803, "_runtime": 7743.0602424144745, "_timestamp": 1585516821.480972, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.9793496131896973, "Value Loss": 3.7676074504852295, "_runtime": 7744.6725244522095, "_timestamp": 1585516823.093254, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.2722487449646, "Value Loss": 2.9596283435821533, "_runtime": 7746.249274730682, "_timestamp": 1585516824.6700044, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.6048126220703125, "Value Loss": 41.15259552001953, "_runtime": 7747.814063072205, "_timestamp": 1585516826.2347927, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.7381391525268555, "Value Loss": 23.116477966308594, "_runtime": 7749.37574338913, "_timestamp": 1585516827.796473, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.7415008544921875, "Value Loss": 4.751070499420166, "_runtime": 7750.949533462524, "_timestamp": 1585516829.370263, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.702488899230957, "Value Loss": 0.3663642108440399, "_runtime": 7752.528910636902, "_timestamp": 1585516830.9496403, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.6286725997924805, "Value Loss": 2.6296868324279785, "_runtime": 7754.101891279221, "_timestamp": 1585516832.522621, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.578910827636719, "Value Loss": 1.3396086692810059, "_runtime": 7755.672946929932, "_timestamp": 1585516834.0936766, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.492575645446777, "Value Loss": 11.030245780944824, "_runtime": 7757.248539686203, "_timestamp": 1585516835.6692693, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.268458843231201, "Value Loss": 5.8179216384887695, "_runtime": 7758.810153961182, "_timestamp": 1585516837.2308836, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.9726734161376953, "Value Loss": 7.824626922607422, "_runtime": 7760.381084442139, "_timestamp": 1585516838.801814, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.543386459350586, "Value Loss": 0.519544780254364, "_runtime": 7761.956513643265, "_timestamp": 1585516840.3772433, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.100607395172119, "Value Loss": 7.792943477630615, "_runtime": 7763.52756524086, "_timestamp": 1585516841.9482949, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6816344261169434, "Value Loss": 4.64238977432251, "_runtime": 7765.105083465576, "_timestamp": 1585516843.525813, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2923364639282227, "Value Loss": 0.5182358026504517, "_runtime": 7766.714389801025, "_timestamp": 1585516845.1351194, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9336405992507935, "Value Loss": 2.080554485321045, "_runtime": 7768.28738117218, "_timestamp": 1585516846.7081108, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6082358360290527, "Value Loss": 0.47984400391578674, "_runtime": 7769.850262403488, "_timestamp": 1585516848.270992, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3860256671905518, "Value Loss": 0.07571613788604736, "_runtime": 7771.426294803619, "_timestamp": 1585516849.8470244, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1667252779006958, "Value Loss": 1.3513209819793701, "_runtime": 7772.996156454086, "_timestamp": 1585516851.416886, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9295616745948792, "Value Loss": 0.42913004755973816, "_runtime": 7774.584144830704, "_timestamp": 1585516853.0048745, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8223279714584351, "Value Loss": 10.045673370361328, "_runtime": 7776.162673711777, "_timestamp": 1585516854.5834033, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8268539905548096, "Value Loss": 0.009249433875083923, "_runtime": 7777.752351284027, "_timestamp": 1585516856.173081, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8156631588935852, "Value Loss": 1.0080547332763672, "_runtime": 7779.342881679535, "_timestamp": 1585516857.7636113, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8607425689697266, "Value Loss": 0.3796636462211609, "_runtime": 7780.923768043518, "_timestamp": 1585516859.3444977, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8860899806022644, "Value Loss": 1.5318256616592407, "_runtime": 7782.513703107834, "_timestamp": 1585516860.9344327, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8972257971763611, "Value Loss": 2.622666597366333, "_runtime": 7784.091161489487, "_timestamp": 1585516862.5118911, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0020320415496826, "Value Loss": 1.1933517456054688, "_runtime": 7785.682760715485, "_timestamp": 1585516864.1034904, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.096824049949646, "Value Loss": 1.4884902238845825, "_runtime": 7787.270400762558, "_timestamp": 1585516865.6911304, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2072721719741821, "Value Loss": 1.3708202838897705, "_runtime": 7788.851475954056, "_timestamp": 1585516867.2722056, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.360215663909912, "Value Loss": 0.5492389798164368, "_runtime": 7790.476650476456, "_timestamp": 1585516868.89738, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5009700059890747, "Value Loss": 0.05292266979813576, "_runtime": 7792.059630155563, "_timestamp": 1585516870.4803598, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6364684104919434, "Value Loss": 0.036503106355667114, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 7793.648000001907, "_timestamp": 1585516872.0687296, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7503116130828857, "Value Loss": 0.13383981585502625, "_runtime": 7795.237723112106, "_timestamp": 1585516873.6584527, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8402125835418701, "Value Loss": 0.15461981296539307, "_runtime": 7796.823859453201, "_timestamp": 1585516875.244589, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9096611738204956, "Value Loss": 0.18291319906711578, "_runtime": 7798.411741495132, "_timestamp": 1585516876.8324711, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9567668437957764, "Value Loss": 0.16439656913280487, "_runtime": 7799.977381944656, "_timestamp": 1585516878.3981116, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9888659715652466, "Value Loss": 0.20338179171085358, "_runtime": 7801.5544719696045, "_timestamp": 1585516879.9752016, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.005354166030884, "Value Loss": 0.06872177869081497, "_runtime": 7803.132409334183, "_timestamp": 1585516881.553139, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0109152793884277, "Value Loss": 0.05494484677910805, "_runtime": 7804.722188949585, "_timestamp": 1585516883.1429186, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0052590370178223, "Value Loss": 0.30516403913497925, "_runtime": 7806.31080365181, "_timestamp": 1585516884.7315333, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9825270175933838, "Value Loss": 0.3487115204334259, "_runtime": 7807.898072481155, "_timestamp": 1585516886.318802, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.942049503326416, "Value Loss": 0.3425334393978119, "_runtime": 7809.476513385773, "_timestamp": 1585516887.897243, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8976892232894897, "Value Loss": 0.041107241064310074, "_runtime": 7811.06350851059, "_timestamp": 1585516889.4842381, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8433945178985596, "Value Loss": 0.1416175663471222, "_runtime": 7812.640237569809, "_timestamp": 1585516891.0609672, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7811020612716675, "Value Loss": 0.6643733978271484, "_runtime": 7814.258570194244, "_timestamp": 1585516892.6792998, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6985702514648438, "Value Loss": 0.1559636890888214, "_runtime": 7815.83398938179, "_timestamp": 1585516894.254719, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.60346519947052, "Value Loss": 0.2613769471645355, "_runtime": 7817.422216415405, "_timestamp": 1585516895.842946, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.513649344444275, "Value Loss": 0.0846327543258667, "_runtime": 7819.011301994324, "_timestamp": 1585516897.4320316, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4216755628585815, "Value Loss": 0.2350766807794571, "_runtime": 7820.588125228882, "_timestamp": 1585516899.0088549, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.329161286354065, "Value Loss": 0.17722055315971375, "_runtime": 7822.166986703873, "_timestamp": 1585516900.5877163, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.23078453540802, "Value Loss": 0.12290908396244049, "_runtime": 7823.755949258804, "_timestamp": 1585516902.176679, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1442257165908813, "Value Loss": 0.03488030657172203, "_runtime": 7825.345452547073, "_timestamp": 1585516903.7661822, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.053604006767273, "Value Loss": 0.188177227973938, "_runtime": 7826.926702260971, "_timestamp": 1585516905.347432, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9667054414749146, "Value Loss": 0.030860789120197296, "_runtime": 7828.504798173904, "_timestamp": 1585516906.9255278, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8788591623306274, "Value Loss": 0.03941506892442703, "_runtime": 7830.074578762054, "_timestamp": 1585516908.4953084, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7989137172698975, "Value Loss": 0.044119108468294144, "_runtime": 7831.636700630188, "_timestamp": 1585516910.0574303, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.723096489906311, "Value Loss": 0.05806243047118187, "_runtime": 7833.201319932938, "_timestamp": 1585516911.6220496, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6446202993392944, "Value Loss": 0.07714425772428513, "_runtime": 7834.784276485443, "_timestamp": 1585516913.2050061, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5625815987586975, "Value Loss": 0.0374557189643383, "_runtime": 7836.36731338501, "_timestamp": 1585516914.788043, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4851774573326111, "Value Loss": 0.013795671053230762, "_runtime": 7837.984191894531, "_timestamp": 1585516916.4049215, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4082455039024353, "Value Loss": 0.00589255103841424, "_runtime": 7839.55605840683, "_timestamp": 1585516917.976788, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3391730487346649, "Value Loss": 0.010807371698319912, "_runtime": 7841.126369714737, "_timestamp": 1585516919.5470994, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2740963101387024, "Value Loss": 0.0010041509522125125, "_runtime": 7842.707164525986, "_timestamp": 1585516921.1278942, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2160162478685379, "Value Loss": 0.0034704403951764107, "_runtime": 7844.287646770477, "_timestamp": 1585516922.7083764, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16281788051128387, "Value Loss": 0.003046751022338867, "_runtime": 7845.876038074493, "_timestamp": 1585516924.2967677, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11538860201835632, "Value Loss": 0.005799032282084227, "_runtime": 7847.460485696793, "_timestamp": 1585516925.8812153, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07276014238595963, "Value Loss": 0.0004839369503315538, "_runtime": 7849.029092550278, "_timestamp": 1585516927.4498222, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.035419266670942307, "Value Loss": 0.007757122162729502, "_runtime": 7850.591980934143, "_timestamp": 1585516929.0127106, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017322204075753689, "Value Loss": 0.0026340617332607508, "_runtime": 7852.158396482468, "_timestamp": 1585516930.5791261, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027579547837376595, "Value Loss": 0.005045748315751553, "_runtime": 7853.729975700378, "_timestamp": 1585516932.1507053, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05491941049695015, "Value Loss": 0.0027760628145188093, "_runtime": 7855.301343679428, "_timestamp": 1585516933.7220733, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07733350992202759, "Value Loss": 0.009698963724076748, "_runtime": 7856.871870279312, "_timestamp": 1585516935.2926, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0961569994688034, "Value Loss": 0.016529850661754608, "_runtime": 7858.44352889061, "_timestamp": 1585516936.8642585, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10974070429801941, "Value Loss": 0.013498220592737198, "_runtime": 7860.043888092041, "_timestamp": 1585516938.4646177, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12144569307565689, "Value Loss": 0.0067099956795573235, "_runtime": 7861.6156685352325, "_timestamp": 1585516940.0363982, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1290217489004135, "Value Loss": 0.011176876723766327, "_runtime": 7863.176397800446, "_timestamp": 1585516941.5971274, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13550575077533722, "Value Loss": 0.0021606399677693844, "_runtime": 7864.748909235001, "_timestamp": 1585516943.1696389, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1405864804983139, "Value Loss": 0.009645714424550533, "_runtime": 7866.330496788025, "_timestamp": 1585516944.7512264, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1432439088821411, "Value Loss": 0.0005137898260727525, "_runtime": 7867.909361600876, "_timestamp": 1585516946.3300912, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14538423717021942, "Value Loss": 0.006582055706530809, "_runtime": 7869.482140541077, "_timestamp": 1585516947.9028702, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.14433294534683228, "Value Loss": 0.014700520783662796, "_runtime": 7871.05343413353, "_timestamp": 1585516949.4741638, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1394844651222229, "Value Loss": 0.011883256025612354, "_runtime": 7872.6148500442505, "_timestamp": 1585516951.0355797, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13448750972747803, "Value Loss": 0.0005336893373169005, "_runtime": 7874.187913656235, "_timestamp": 1585516952.6086433, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1300964057445526, "Value Loss": 0.00272233784198761, "_runtime": 7875.759121417999, "_timestamp": 1585516954.179851, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12201561033725739, "Value Loss": 0.00937320664525032, "_runtime": 7877.32891702652, "_timestamp": 1585516955.7496467, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1159241572022438, "Value Loss": 0.004361636936664581, "_runtime": 7878.901858091354, "_timestamp": 1585516957.3225877, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10884486138820648, "Value Loss": 0.0038039893843233585, "_runtime": 7880.467052221298, "_timestamp": 1585516958.8877819, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10289821773767471, "Value Loss": 0.004095807671546936, "_runtime": 7882.040675878525, "_timestamp": 1585516960.4614055, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09588459134101868, "Value Loss": 0.004160778131335974, "_runtime": 7883.648354768753, "_timestamp": 1585516962.0690844, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08988863229751587, "Value Loss": 0.0025842797476798296, "_runtime": 7885.209090471268, "_timestamp": 1585516963.62982, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08439401537179947, "Value Loss": 0.0008829010766930878, "_runtime": 7886.778849601746, "_timestamp": 1585516965.1995792, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07932228595018387, "Value Loss": 0.0015792901394888759, "_runtime": 7888.349974155426, "_timestamp": 1585516966.7707038, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07395961880683899, "Value Loss": 0.0043575880117714405, "_runtime": 7889.92239356041, "_timestamp": 1585516968.3431232, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06844476610422134, "Value Loss": 0.0008722363272681832, "_runtime": 7891.491909503937, "_timestamp": 1585516969.9126391, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06292316317558289, "Value Loss": 0.0038180332630872726, "_runtime": 7893.052745580673, "_timestamp": 1585516971.4734752, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05830982327461243, "Value Loss": 0.00026766551309265196, "_runtime": 7894.625265836716, "_timestamp": 1585516973.0459955, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05396021902561188, "Value Loss": 0.00019712313951458782, "_runtime": 7896.185483217239, "_timestamp": 1585516974.6062129, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04959655553102493, "Value Loss": 0.00027668714756146073, "_runtime": 7897.765654802322, "_timestamp": 1585516976.1863844, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.045464202761650085, "Value Loss": 0.0035617772955447435, "_runtime": 7899.33607172966, "_timestamp": 1585516977.7568014, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04223472997546196, "Value Loss": 0.000976599520072341, "_runtime": 7900.910840034485, "_timestamp": 1585516979.3315697, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.038396090269088745, "Value Loss": 0.0023807338438928127, "_runtime": 7902.498270750046, "_timestamp": 1585516980.9190004, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03465503081679344, "Value Loss": 0.0017923446139320731, "_runtime": 7904.084224939346, "_timestamp": 1585516982.5049546, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02998761087656021, "Value Loss": 0.001474930439144373, "_runtime": 7905.668210744858, "_timestamp": 1585516984.0889404, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025889599695801735, "Value Loss": 0.00010976739577017725, "_runtime": 7907.29235291481, "_timestamp": 1585516985.7130826, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021370135247707367, "Value Loss": 0.0034500365145504475, "_runtime": 7908.879836797714, "_timestamp": 1585516987.3005664, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018143367022275925, "Value Loss": 0.00343987881205976, "_runtime": 7910.464477062225, "_timestamp": 1585516988.8852067, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015922289341688156, "Value Loss": 0.0002492348139639944, "_runtime": 7912.034774780273, "_timestamp": 1585516990.4555044, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013674682937562466, "Value Loss": 0.00022973594604991376, "_runtime": 7913.621567964554, "_timestamp": 1585516992.0422976, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011400113813579082, "Value Loss": 0.0009708807338029146, "_runtime": 7915.209221363068, "_timestamp": 1585516993.629951, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009316193871200085, "Value Loss": 0.001533462549559772, "_runtime": 7916.782667398453, "_timestamp": 1585516995.203397, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007829989306628704, "Value Loss": 0.00018624981748871505, "_runtime": 7918.371593475342, "_timestamp": 1585516996.792323, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006563103757798672, "Value Loss": 0.0011113558430224657, "_runtime": 7919.958674192429, "_timestamp": 1585516998.3794038, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004759793169796467, "Value Loss": 0.0029029264114797115, "_runtime": 7921.54706454277, "_timestamp": 1585516999.9677942, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004182103089988232, "Value Loss": 0.00015331317263189703, "_runtime": 7923.133780241013, "_timestamp": 1585517001.5545099, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003269567620009184, "Value Loss": 0.00025155601906590164, "_runtime": 7924.718791246414, "_timestamp": 1585517003.139521, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002850097371265292, "Value Loss": 0.0003386582247912884, "_runtime": 7926.306935071945, "_timestamp": 1585517004.7276647, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018809775356203318, "Value Loss": 0.0014393724268302321, "_runtime": 7927.886622905731, "_timestamp": 1585517006.3073525, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0014626400079578161, "Value Loss": 0.0009402238065376878, "_runtime": 7929.47117972374, "_timestamp": 1585517007.8919094, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0010516035836189985, "Value Loss": 0.0013444431824609637, "_runtime": 7931.097239732742, "_timestamp": 1585517009.5179694, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0008551626815460622, "Value Loss": 0.00022867077495902777, "_runtime": 7932.675469875336, "_timestamp": 1585517011.0961995, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001008925843052566, "Value Loss": 0.00015178117610048503, "_runtime": 7934.2623081207275, "_timestamp": 1585517012.6830378, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009773741476237774, "Value Loss": 0.00046917659346945584, "_runtime": 7935.848068714142, "_timestamp": 1585517014.2687984, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0013792345998808742, "Value Loss": 0.00016616244101896882, "_runtime": 7937.424179315567, "_timestamp": 1585517015.844909, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.001723230117931962, "Value Loss": 0.00013509640120901167, "_runtime": 7938.9899706840515, "_timestamp": 1585517017.4107003, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0016775482799857855, "Value Loss": 0.00023056923237163574, "_runtime": 7940.569585800171, "_timestamp": 1585517018.9903154, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0022340661380439997, "Value Loss": 0.0002571699151303619, "_runtime": 7942.162136077881, "_timestamp": 1585517020.5828657, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0018807747401297092, "Value Loss": 0.0029157851822674274, "_runtime": 7943.731029033661, "_timestamp": 1585517022.1517587, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002995668211951852, "Value Loss": 4.460778654902242e-05, "_runtime": 7945.319808959961, "_timestamp": 1585517023.7405386, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0031875683926045895, "Value Loss": 0.002890548435971141, "_runtime": 7946.897867202759, "_timestamp": 1585517025.3185968, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004016901832073927, "Value Loss": 0.0025216713547706604, "_runtime": 7948.47655749321, "_timestamp": 1585517026.8972871, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005325508303940296, "Value Loss": 0.002785478252917528, "_runtime": 7950.055562257767, "_timestamp": 1585517028.476292, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007360114715993404, "Value Loss": 0.00019179000810254365, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 7951.6445748806, "_timestamp": 1585517030.0653045, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008757310919463634, "Value Loss": 0.0002973154478240758, "_runtime": 7953.234945297241, "_timestamp": 1585517031.655675, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009832306765019894, "Value Loss": 0.0015968825900927186, "_runtime": 7954.862088441849, "_timestamp": 1585517033.282818, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011266334913671017, "Value Loss": 0.0025363878812640905, "_runtime": 7956.451197385788, "_timestamp": 1585517034.871927, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01346332486718893, "Value Loss": 0.00011201977758901194, "_runtime": 7958.038111209869, "_timestamp": 1585517036.4588408, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014895866625010967, "Value Loss": 0.0024581761099398136, "_runtime": 7959.626863002777, "_timestamp": 1585517038.0475926, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017016997560858727, "Value Loss": 0.00016152866010088474, "_runtime": 7961.211321353912, "_timestamp": 1585517039.632051, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018772762268781662, "Value Loss": 0.00013605397543869913, "_runtime": 7962.798808336258, "_timestamp": 1585517041.219538, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020117327570915222, "Value Loss": 0.00019895016157533973, "_runtime": 7964.385341644287, "_timestamp": 1585517042.8060713, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021310264244675636, "Value Loss": 0.0007738374988548458, "_runtime": 7965.970101118088, "_timestamp": 1585517044.3908308, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022448306903243065, "Value Loss": 0.00010816188296303153, "_runtime": 7967.549530982971, "_timestamp": 1585517045.9702606, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02299339696764946, "Value Loss": 0.0009660704527050257, "_runtime": 7969.129250049591, "_timestamp": 1585517047.5499797, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023605220019817352, "Value Loss": 0.00011623827595030889, "_runtime": 7970.705574274063, "_timestamp": 1585517049.126304, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023808561265468597, "Value Loss": 0.0022184797562658787, "_runtime": 7972.277966499329, "_timestamp": 1585517050.6986961, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024670619517564774, "Value Loss": 9.823342406889424e-05, "_runtime": 7973.852966547012, "_timestamp": 1585517052.2736962, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024943923577666283, "Value Loss": 0.0001770675298757851, "_runtime": 7975.4266974925995, "_timestamp": 1585517053.8474271, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02536272257566452, "Value Loss": 2.8422211471479386e-05, "_runtime": 7977.025456190109, "_timestamp": 1585517055.4461858, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025524374097585678, "Value Loss": 0.000601421867031604, "_runtime": 7978.613085985184, "_timestamp": 1585517057.0338156, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025943249464035034, "Value Loss": 0.0006725567509420216, "_runtime": 7980.200901031494, "_timestamp": 1585517058.6216307, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025604071095585823, "Value Loss": 8.95038028829731e-05, "_runtime": 7981.793318271637, "_timestamp": 1585517060.214048, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025250080972909927, "Value Loss": 2.6436955522513017e-05, "_runtime": 7983.382335186005, "_timestamp": 1585517061.8030648, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024868154898285866, "Value Loss": 0.000621349667198956, "_runtime": 7984.969406366348, "_timestamp": 1585517063.390136, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024353152140975, "Value Loss": 0.0005846847197972238, "_runtime": 7986.5556972026825, "_timestamp": 1585517064.9764268, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023691747337579727, "Value Loss": 0.0005986614269204438, "_runtime": 7988.132537841797, "_timestamp": 1585517066.5532675, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02297709882259369, "Value Loss": 2.624881744850427e-05, "_runtime": 7989.718915224075, "_timestamp": 1585517068.1396449, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022154951468110085, "Value Loss": 0.00011728356184903532, "_runtime": 7991.295620679855, "_timestamp": 1585517069.7163503, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021255582571029663, "Value Loss": 0.0020152225624769926, "_runtime": 7992.885990858078, "_timestamp": 1585517071.3067205, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020777253434062004, "Value Loss": 0.0010321092559024692, "_runtime": 7994.4746079444885, "_timestamp": 1585517072.8953376, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021015817299485207, "Value Loss": 0.00026660141884349287, "_runtime": 7996.060675621033, "_timestamp": 1585517074.4814053, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02026178501546383, "Value Loss": 0.00015894633543211967, "_runtime": 7997.647136449814, "_timestamp": 1585517076.067866, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02038852497935295, "Value Loss": 2.9955881473142654e-05, "_runtime": 7999.222580432892, "_timestamp": 1585517077.64331, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01953837089240551, "Value Loss": 0.00045656098518520594, "_runtime": 8000.847286939621, "_timestamp": 1585517079.2680166, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018935758620500565, "Value Loss": 0.00016902618517633528, "_runtime": 8002.435843706131, "_timestamp": 1585517080.8565733, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019099874421954155, "Value Loss": 0.00026208345661871135, "_runtime": 8004.021363258362, "_timestamp": 1585517082.442093, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018863091245293617, "Value Loss": 0.0008865388226695359, "_runtime": 8005.608000278473, "_timestamp": 1585517084.02873, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019423754885792732, "Value Loss": 0.00010822821786860004, "_runtime": 8007.186465263367, "_timestamp": 1585517085.607195, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019706716760993004, "Value Loss": 0.0010390718234702945, "_runtime": 8008.774484395981, "_timestamp": 1585517087.195214, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020053226500749588, "Value Loss": 5.9199803217779845e-05, "_runtime": 8010.35812830925, "_timestamp": 1585517088.778858, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020412303507328033, "Value Loss": 0.0006793889915570617, "_runtime": 8011.934972286224, "_timestamp": 1585517090.355702, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020747851580381393, "Value Loss": 0.0001379049790557474, "_runtime": 8013.5253846645355, "_timestamp": 1585517091.9461143, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02115001529455185, "Value Loss": 0.0016570169245824218, "_runtime": 8015.089814662933, "_timestamp": 1585517093.5105443, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022101854905486107, "Value Loss": 2.9824675948475488e-05, "_runtime": 8016.667919874191, "_timestamp": 1585517095.0886495, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022165045142173767, "Value Loss": 4.367666770122014e-05, "_runtime": 8018.253811120987, "_timestamp": 1585517096.6745408, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02236797846853733, "Value Loss": 2.012638833548408e-05, "_runtime": 8019.8404750823975, "_timestamp": 1585517098.2612047, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0226407740265131, "Value Loss": 3.297299917903729e-05, "_runtime": 8021.421553850174, "_timestamp": 1585517099.8422835, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02224073000252247, "Value Loss": 9.35748394113034e-05, "_runtime": 8023.011360883713, "_timestamp": 1585517101.4320905, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022027449682354927, "Value Loss": 0.00016769020294304937, "_runtime": 8024.635157585144, "_timestamp": 1585517103.0558872, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021591687574982643, "Value Loss": 0.001823035883717239, "_runtime": 8026.223011732101, "_timestamp": 1585517104.6437414, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021474862471222878, "Value Loss": 0.0018063080497086048, "_runtime": 8027.800843715668, "_timestamp": 1585517106.2215734, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02133498340845108, "Value Loss": 4.201216870569624e-05, "_runtime": 8029.386164903641, "_timestamp": 1585517107.8068945, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021367769688367844, "Value Loss": 9.180436609312892e-05, "_runtime": 8030.967626094818, "_timestamp": 1585517109.3883557, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02139521762728691, "Value Loss": 4.9539270548848435e-05, "_runtime": 8032.550793647766, "_timestamp": 1585517110.9715233, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02128085121512413, "Value Loss": 0.00014759523037355393, "_runtime": 8034.135894536972, "_timestamp": 1585517112.5566242, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021743007004261017, "Value Loss": 2.9008613637415692e-05, "_runtime": 8035.725562572479, "_timestamp": 1585517114.1462922, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021166060119867325, "Value Loss": 0.000788546574767679, "_runtime": 8037.316168308258, "_timestamp": 1585517115.736898, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020948948338627815, "Value Loss": 0.0004323679895605892, "_runtime": 8038.903715133667, "_timestamp": 1585517117.3244448, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021211711689829826, "Value Loss": 0.0011901401448994875, "_runtime": 8040.491430282593, "_timestamp": 1585517118.91216, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02097206562757492, "Value Loss": 7.380601164186373e-05, "_runtime": 8042.080395460129, "_timestamp": 1585517120.501125, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021146530285477638, "Value Loss": 2.4693701561773196e-05, "_runtime": 8043.670223474503, "_timestamp": 1585517122.090953, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02085069566965103, "Value Loss": 0.00011949407053180039, "_runtime": 8045.256309747696, "_timestamp": 1585517123.6770394, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021047867834568024, "Value Loss": 0.0015784420538693666, "_runtime": 8046.845259189606, "_timestamp": 1585517125.2659888, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020926855504512787, "Value Loss": 3.0752791644772515e-05, "_runtime": 8048.468700647354, "_timestamp": 1585517126.8894303, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020594198256731033, "Value Loss": 0.00015074432303663343, "_runtime": 8050.049988269806, "_timestamp": 1585517128.470718, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020498529076576233, "Value Loss": 0.00015369811444543302, "_runtime": 8051.63248872757, "_timestamp": 1585517130.0532184, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020526310428977013, "Value Loss": 0.0004125295381527394, "_runtime": 8053.199910640717, "_timestamp": 1585517131.6206403, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020587535575032234, "Value Loss": 0.0012633417500182986, "_runtime": 8054.77321434021, "_timestamp": 1585517133.193944, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020378172397613525, "Value Loss": 0.00142201641574502, "_runtime": 8056.34344291687, "_timestamp": 1585517134.7641726, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020493481308221817, "Value Loss": 4.245227682986297e-05, "_runtime": 8057.909091711044, "_timestamp": 1585517136.3298213, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020983440801501274, "Value Loss": 0.001493648742325604, "_runtime": 8059.4896993637085, "_timestamp": 1585517137.910429, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02107386663556099, "Value Loss": 0.00012896467524114996, "_runtime": 8061.06960606575, "_timestamp": 1585517139.4903357, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021881038323044777, "Value Loss": 0.0004950049333274364, "_runtime": 8062.640118837357, "_timestamp": 1585517141.0608485, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021845731884241104, "Value Loss": 4.473434091778472e-05, "_runtime": 8064.218427658081, "_timestamp": 1585517142.6391573, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022489355877041817, "Value Loss": 0.0005842771497555077, "_runtime": 8065.803596496582, "_timestamp": 1585517144.2243261, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022721678018569946, "Value Loss": 7.323588215513155e-05, "_runtime": 8067.377952575684, "_timestamp": 1585517145.7986822, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023045580834150314, "Value Loss": 0.001389628741890192, "_runtime": 8068.957656145096, "_timestamp": 1585517147.3783858, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02324751205742359, "Value Loss": 0.0003684778930619359, "_runtime": 8070.573639154434, "_timestamp": 1585517148.9943688, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023300254717469215, "Value Loss": 0.00015718729991931468, "_runtime": 8072.135384082794, "_timestamp": 1585517150.5561137, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024148179218173027, "Value Loss": 0.0008650111849419773, "_runtime": 8073.714804649353, "_timestamp": 1585517152.1355343, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025091657415032387, "Value Loss": 0.0007598177762702107, "_runtime": 8075.29105257988, "_timestamp": 1585517153.7117822, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02525346726179123, "Value Loss": 0.0001510983711341396, "_runtime": 8076.87560915947, "_timestamp": 1585517155.2963388, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026475347578525543, "Value Loss": 0.0005762670771218836, "_runtime": 8078.463011264801, "_timestamp": 1585517156.883741, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02716371789574623, "Value Loss": 0.00017574979574419558, "_runtime": 8080.028584718704, "_timestamp": 1585517158.4493144, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027570728212594986, "Value Loss": 9.754120401339605e-05, "_runtime": 8081.613564491272, "_timestamp": 1585517160.0342941, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028190087527036667, "Value Loss": 0.0011734692379832268, "_runtime": 8083.202678203583, "_timestamp": 1585517161.6234078, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028476497158408165, "Value Loss": 6.763563578715548e-05, "_runtime": 8084.791572809219, "_timestamp": 1585517163.2123024, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028502225875854492, "Value Loss": 0.00011716307926690206, "_runtime": 8086.374999761581, "_timestamp": 1585517164.7957294, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02875477634370327, "Value Loss": 0.00011095849185949191, "_runtime": 8087.949583768845, "_timestamp": 1585517166.3703134, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028848858550190926, "Value Loss": 6.661699444521219e-05, "_runtime": 8089.530602216721, "_timestamp": 1585517167.9513319, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028854018077254295, "Value Loss": 0.000572711112909019, "_runtime": 8091.097925186157, "_timestamp": 1585517169.5186548, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028348764404654503, "Value Loss": 7.064810779411346e-05, "_runtime": 8092.677772760391, "_timestamp": 1585517171.0985024, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02816932462155819, "Value Loss": 0.00013591513561550528, "_runtime": 8094.303428173065, "_timestamp": 1585517172.7241578, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028589943423867226, "Value Loss": 0.0008728356333449483, "_runtime": 8095.8908314704895, "_timestamp": 1585517174.311561, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028729764744639397, "Value Loss": 0.0005951912607997656, "_runtime": 8097.479667901993, "_timestamp": 1585517175.9003975, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028383653610944748, "Value Loss": 1.3189701348892413e-05, "_runtime": 8099.067853212357, "_timestamp": 1585517177.4885828, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029598506167531013, "Value Loss": 3.619581912062131e-05, "_runtime": 8100.653393745422, "_timestamp": 1585517179.0741234, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029552727937698364, "Value Loss": 0.0007114630425348878, "_runtime": 8102.240119934082, "_timestamp": 1585517180.6608496, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0301434975117445, "Value Loss": 0.00015653407899662852, "_runtime": 8103.827680826187, "_timestamp": 1585517182.2484105, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030212262645363808, "Value Loss": 0.0002264537470182404, "_runtime": 8105.414320707321, "_timestamp": 1585517183.8350503, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030497685074806213, "Value Loss": 5.6877579481806606e-05, "_runtime": 8107.004700422287, "_timestamp": 1585517185.42543, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03022293746471405, "Value Loss": 9.061495075002313e-05, "_runtime": 8108.585005283356, "_timestamp": 1585517187.005735, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030894069001078606, "Value Loss": 0.0009525454370304942, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8110.158508300781, "_timestamp": 1585517188.579238, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031095324084162712, "Value Loss": 0.0011201348388567567, "_runtime": 8111.734480857849, "_timestamp": 1585517190.1552105, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03130243346095085, "Value Loss": 0.0011303274659439921, "_runtime": 8113.297323942184, "_timestamp": 1585517191.7180536, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031105395406484604, "Value Loss": 0.000285215035546571, "_runtime": 8114.867792844772, "_timestamp": 1585517193.2885225, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03129185736179352, "Value Loss": 4.870192424277775e-05, "_runtime": 8116.457422018051, "_timestamp": 1585517194.8781517, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030846592038869858, "Value Loss": 1.4713990822201595e-05, "_runtime": 8118.081742048264, "_timestamp": 1585517196.5024717, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03146130219101906, "Value Loss": 0.0009546158835291862, "_runtime": 8119.666601896286, "_timestamp": 1585517198.0873315, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030916841700673103, "Value Loss": 0.00022612795874010772, "_runtime": 8121.254758834839, "_timestamp": 1585517199.6754885, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031355299055576324, "Value Loss": 0.00047035780153237283, "_runtime": 8122.834120512009, "_timestamp": 1585517201.2548501, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.031122997403144836, "Value Loss": 0.0009766988223418593, "_runtime": 8124.421991825104, "_timestamp": 1585517202.8427215, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03015715256333351, "Value Loss": 6.559283065143973e-05, "_runtime": 8126.003021240234, "_timestamp": 1585517204.4237509, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030043555423617363, "Value Loss": 6.216560723260045e-05, "_runtime": 8127.581952571869, "_timestamp": 1585517206.0026822, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03055187501013279, "Value Loss": 0.00031888639205135405, "_runtime": 8129.160192728043, "_timestamp": 1585517207.5809224, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.030322421342134476, "Value Loss": 0.00040365473250858486, "_runtime": 8130.751548290253, "_timestamp": 1585517209.172278, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029822776094079018, "Value Loss": 4.991533205611631e-05, "_runtime": 8132.34105181694, "_timestamp": 1585517210.7617815, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.029909754171967506, "Value Loss": 1.6129763025674038e-05, "_runtime": 8133.915744304657, "_timestamp": 1585517212.336474, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02951294183731079, "Value Loss": 0.0005555705865845084, "_runtime": 8135.505433797836, "_timestamp": 1585517213.9261634, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02894357219338417, "Value Loss": 0.00024110353842843324, "_runtime": 8137.095217466354, "_timestamp": 1585517215.515947, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028338033705949783, "Value Loss": 3.308310988359153e-05, "_runtime": 8138.682027339935, "_timestamp": 1585517217.102757, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028374500572681427, "Value Loss": 9.018364653456956e-05, "_runtime": 8140.259562253952, "_timestamp": 1585517218.680292, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027547597885131836, "Value Loss": 0.0001018313632812351, "_runtime": 8141.887726306915, "_timestamp": 1585517220.308456, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.027603233233094215, "Value Loss": 3.6706340324599296e-05, "_runtime": 8143.473428726196, "_timestamp": 1585517221.8941584, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026238378137350082, "Value Loss": 1.5088237887539435e-05, "_runtime": 8145.054828166962, "_timestamp": 1585517223.4755578, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026542067527770996, "Value Loss": 0.0004564751870930195, "_runtime": 8146.635426998138, "_timestamp": 1585517225.0561566, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026101280003786087, "Value Loss": 1.20816876005847e-05, "_runtime": 8148.22110581398, "_timestamp": 1585517226.6418355, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026321861892938614, "Value Loss": 0.0006252081366255879, "_runtime": 8149.809006929398, "_timestamp": 1585517228.2297366, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026159008964896202, "Value Loss": 8.127232285914943e-05, "_runtime": 8151.399914741516, "_timestamp": 1585517229.8206444, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02584681659936905, "Value Loss": 0.000339245394570753, "_runtime": 8152.990660905838, "_timestamp": 1585517231.4113905, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025174899026751518, "Value Loss": 9.422691073268652e-05, "_runtime": 8154.577658414841, "_timestamp": 1585517232.998388, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.026201140135526657, "Value Loss": 0.0007985923439264297, "_runtime": 8156.165132284164, "_timestamp": 1585517234.585862, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025828203186392784, "Value Loss": 0.00036484102020040154, "_runtime": 8157.75187087059, "_timestamp": 1585517236.1726005, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02528867870569229, "Value Loss": 8.581477595726028e-05, "_runtime": 8159.341744422913, "_timestamp": 1585517237.762474, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025320321321487427, "Value Loss": 2.774259883153718e-05, "_runtime": 8160.929279565811, "_timestamp": 1585517239.3500092, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025664854794740677, "Value Loss": 0.00014113428187556565, "_runtime": 8162.504951477051, "_timestamp": 1585517240.925681, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025397442281246185, "Value Loss": 0.00023314064310397953, "_runtime": 8164.093079805374, "_timestamp": 1585517242.5138094, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025667008012533188, "Value Loss": 0.0007553257746621966, "_runtime": 8165.7211792469025, "_timestamp": 1585517244.141909, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.025385059416294098, "Value Loss": 0.000153553337440826, "_runtime": 8167.297746419907, "_timestamp": 1585517245.718476, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02514698915183544, "Value Loss": 0.0005585604812949896, "_runtime": 8168.876690149307, "_timestamp": 1585517247.2974198, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02407725900411606, "Value Loss": 8.967588655650616e-05, "_runtime": 8170.452937602997, "_timestamp": 1585517248.8736672, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.023195935413241386, "Value Loss": 9.924220648827031e-06, "_runtime": 8172.028962850571, "_timestamp": 1585517250.4496925, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02302890084683895, "Value Loss": 7.315984839806333e-05, "_runtime": 8173.61069560051, "_timestamp": 1585517252.0314252, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022777801379561424, "Value Loss": 0.00031877963920123875, "_runtime": 8175.190367698669, "_timestamp": 1585517253.6110973, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.022569293156266212, "Value Loss": 0.0001767439825925976, "_runtime": 8176.779622077942, "_timestamp": 1585517255.2003517, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02161834016442299, "Value Loss": 0.00032630827627144754, "_runtime": 8178.3702075481415, "_timestamp": 1585517256.7909372, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020811252295970917, "Value Loss": 9.346139268018305e-05, "_runtime": 8179.949849128723, "_timestamp": 1585517258.3705788, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01980120688676834, "Value Loss": 0.00010739493154687807, "_runtime": 8181.535922050476, "_timestamp": 1585517259.9566517, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019846471026539803, "Value Loss": 0.0003149318799842149, "_runtime": 8183.130666732788, "_timestamp": 1585517261.5513964, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.019533148035407066, "Value Loss": 0.00016351496742572635, "_runtime": 8184.710082292557, "_timestamp": 1585517263.130812, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.018465032801032066, "Value Loss": 0.00011822054511867464, "_runtime": 8186.297014951706, "_timestamp": 1585517264.7177446, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01744643785059452, "Value Loss": 9.823383879847825e-05, "_runtime": 8187.924142599106, "_timestamp": 1585517266.3448722, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017866453155875206, "Value Loss": 3.7307148886611685e-05, "_runtime": 8189.516526222229, "_timestamp": 1585517267.9372559, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017260808497667313, "Value Loss": 0.0004992572939954698, "_runtime": 8191.101717948914, "_timestamp": 1585517269.5224476, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01627938076853752, "Value Loss": 0.00015849228657316417, "_runtime": 8192.690595626831, "_timestamp": 1585517271.1113253, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016397127881646156, "Value Loss": 9.933026740327477e-05, "_runtime": 8194.27788734436, "_timestamp": 1585517272.698617, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015802254900336266, "Value Loss": 0.00020475819474086165, "_runtime": 8195.854049921036, "_timestamp": 1585517274.2747796, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015703709796071053, "Value Loss": 2.8070400730939582e-05, "_runtime": 8197.427515506744, "_timestamp": 1585517275.8482451, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014041018672287464, "Value Loss": 2.7198935640626587e-05, "_runtime": 8199.002655982971, "_timestamp": 1585517277.4233856, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013643968850374222, "Value Loss": 3.497974466881715e-05, "_runtime": 8200.561062812805, "_timestamp": 1585517278.9817924, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013277918100357056, "Value Loss": 3.259084769524634e-05, "_runtime": 8202.126692771912, "_timestamp": 1585517280.5474224, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013841128908097744, "Value Loss": 0.00020264455815777183, "_runtime": 8203.700913906097, "_timestamp": 1585517282.1216435, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01379813626408577, "Value Loss": 0.0003592579741962254, "_runtime": 8205.249955654144, "_timestamp": 1585517283.6706853, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013783715665340424, "Value Loss": 3.8072113966336474e-05, "_runtime": 8206.822603940964, "_timestamp": 1585517285.2433336, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013586070388555527, "Value Loss": 5.833183240611106e-05, "_runtime": 8208.393849372864, "_timestamp": 1585517286.814579, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013197697699069977, "Value Loss": 1.3012337149120867e-05, "_runtime": 8209.963080406189, "_timestamp": 1585517288.38381, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014045164920389652, "Value Loss": 1.543637517897878e-05, "_runtime": 8211.562814712524, "_timestamp": 1585517289.9835443, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013618889264762402, "Value Loss": 4.502015144680627e-05, "_runtime": 8213.1360309124, "_timestamp": 1585517291.5567605, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014255502261221409, "Value Loss": 0.0001306426274823025, "_runtime": 8214.705685377121, "_timestamp": 1585517293.126415, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01439628191292286, "Value Loss": 0.0005713573773391545, "_runtime": 8216.268535375595, "_timestamp": 1585517294.689265, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014545328915119171, "Value Loss": 7.752184319542721e-05, "_runtime": 8217.8429749012, "_timestamp": 1585517296.2637045, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013708340935409069, "Value Loss": 8.037848601816222e-05, "_runtime": 8219.411971569061, "_timestamp": 1585517297.8327012, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014810692518949509, "Value Loss": 0.00013696761743631214, "_runtime": 8220.984734773636, "_timestamp": 1585517299.4054644, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015465390868484974, "Value Loss": 0.0006028895149938762, "_runtime": 8222.556010484695, "_timestamp": 1585517300.9767401, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014859408140182495, "Value Loss": 4.6076351281953976e-05, "_runtime": 8224.124470710754, "_timestamp": 1585517302.5452003, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015942810103297234, "Value Loss": 0.000563797599170357, "_runtime": 8225.698415517807, "_timestamp": 1585517304.1191452, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016109425574541092, "Value Loss": 0.0005343140219338238, "_runtime": 8227.260120630264, "_timestamp": 1585517305.6808503, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016583500429987907, "Value Loss": 0.0005173509125597775, "_runtime": 8228.830266237259, "_timestamp": 1585517307.2509959, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01616600900888443, "Value Loss": 0.00012198108743177727, "_runtime": 8230.400636672974, "_timestamp": 1585517308.8213663, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016398437321186066, "Value Loss": 0.0001372142432956025, "_runtime": 8231.973821640015, "_timestamp": 1585517310.3945513, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015935802832245827, "Value Loss": 1.4972054486861452e-05, "_runtime": 8233.54277253151, "_timestamp": 1585517311.9635022, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01644551381468773, "Value Loss": 0.00015725436969660223, "_runtime": 8235.152858257294, "_timestamp": 1585517313.573588, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016040967777371407, "Value Loss": 7.316729897866026e-05, "_runtime": 8236.726103305817, "_timestamp": 1585517315.146833, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016224747523665428, "Value Loss": 2.6932417313219048e-05, "_runtime": 8238.284538269043, "_timestamp": 1585517316.705268, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015437051653862, "Value Loss": 0.00013923349615652114, "_runtime": 8239.860665082932, "_timestamp": 1585517318.2813947, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014417687430977821, "Value Loss": 5.134116145200096e-05, "_runtime": 8241.43322968483, "_timestamp": 1585517319.8539593, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014064328745007515, "Value Loss": 8.113466174108908e-05, "_runtime": 8243.011582612991, "_timestamp": 1585517321.4323123, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013319430872797966, "Value Loss": 3.055859633604996e-05, "_runtime": 8244.59372329712, "_timestamp": 1585517323.014453, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013770951889455318, "Value Loss": 5.3975792980054393e-05, "_runtime": 8246.177644729614, "_timestamp": 1585517324.5983744, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012318355031311512, "Value Loss": 1.0106944500876125e-05, "_runtime": 8247.757412433624, "_timestamp": 1585517326.178142, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012488794513046741, "Value Loss": 0.00012972202966921031, "_runtime": 8249.32241511345, "_timestamp": 1585517327.7431448, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012014753185212612, "Value Loss": 8.199857984436676e-05, "_runtime": 8250.901725769043, "_timestamp": 1585517329.3224554, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01103203184902668, "Value Loss": 4.153745248913765e-05, "_runtime": 8252.477939844131, "_timestamp": 1585517330.8986695, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010745590552687645, "Value Loss": 6.339752144413069e-05, "_runtime": 8254.071194887161, "_timestamp": 1585517332.4919245, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010118008591234684, "Value Loss": 5.696309744962491e-05, "_runtime": 8255.650919437408, "_timestamp": 1585517334.071649, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011043772101402283, "Value Loss": 2.8988972189836204e-05, "_runtime": 8257.236941576004, "_timestamp": 1585517335.6576712, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01053362712264061, "Value Loss": 9.5764386060182e-05, "_runtime": 8258.863765239716, "_timestamp": 1585517337.2844949, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01050171721726656, "Value Loss": 0.00042470882181078196, "_runtime": 8260.445980072021, "_timestamp": 1585517338.8667097, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008879379369318485, "Value Loss": 1.1332565918564796e-05, "_runtime": 8262.032730102539, "_timestamp": 1585517340.4534597, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008936325088143349, "Value Loss": 5.994894672767259e-05, "_runtime": 8263.619207143784, "_timestamp": 1585517342.0399368, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008938400074839592, "Value Loss": 3.529773312038742e-05, "_runtime": 8265.20864868164, "_timestamp": 1585517343.6293783, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00979628600180149, "Value Loss": 8.198522118618712e-05, "_runtime": 8266.793297052383, "_timestamp": 1585517345.2140267, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00910019502043724, "Value Loss": 0.00018899065617006272, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8268.382112979889, "_timestamp": 1585517346.8028426, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008119635283946991, "Value Loss": 5.8204284869134426e-05, "_runtime": 8269.989993333817, "_timestamp": 1585517348.410723, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008183258585631847, "Value Loss": 2.7838157620863058e-05, "_runtime": 8271.568579435349, "_timestamp": 1585517349.989309, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009050951339304447, "Value Loss": 0.0001538007491035387, "_runtime": 8273.148668527603, "_timestamp": 1585517351.5693982, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007888627238571644, "Value Loss": 1.7787577235139906e-05, "_runtime": 8274.72874379158, "_timestamp": 1585517353.1494734, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008092026226222515, "Value Loss": 8.102587344183121e-06, "_runtime": 8276.301687002182, "_timestamp": 1585517354.7224166, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.009248072281479836, "Value Loss": 5.415127361629857e-06, "_runtime": 8277.878226995468, "_timestamp": 1585517356.2989566, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010039135813713074, "Value Loss": 0.0005223623593337834, "_runtime": 8279.458973884583, "_timestamp": 1585517357.8797035, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010334301739931107, "Value Loss": 0.0004331391246523708, "_runtime": 8281.077486991882, "_timestamp": 1585517359.4982166, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010234786197543144, "Value Loss": 5.073172360425815e-05, "_runtime": 8282.649449110031, "_timestamp": 1585517361.0701787, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010134099051356316, "Value Loss": 5.144630267750472e-05, "_runtime": 8284.234870195389, "_timestamp": 1585517362.6555998, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011369369924068451, "Value Loss": 0.00038908186252228916, "_runtime": 8285.801319360733, "_timestamp": 1585517364.222049, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010174299590289593, "Value Loss": 2.46004419750534e-05, "_runtime": 8287.396495819092, "_timestamp": 1585517365.8172255, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010995724238455296, "Value Loss": 8.697931480128318e-05, "_runtime": 8288.98615694046, "_timestamp": 1585517367.4068866, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011948063969612122, "Value Loss": 0.00026605918537825346, "_runtime": 8290.571281433105, "_timestamp": 1585517368.992011, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011831478215754032, "Value Loss": 4.7801931941648945e-05, "_runtime": 8292.163594722748, "_timestamp": 1585517370.5843244, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013410977087914944, "Value Loss": 0.00047315756091848016, "_runtime": 8293.751905441284, "_timestamp": 1585517372.172635, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012509860098361969, "Value Loss": 6.380097329383716e-05, "_runtime": 8295.339723825455, "_timestamp": 1585517373.7604535, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013026581145823002, "Value Loss": 6.320780084934086e-05, "_runtime": 8296.92891407013, "_timestamp": 1585517375.3496437, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014662805013358593, "Value Loss": 8.343934314325452e-05, "_runtime": 8298.50589799881, "_timestamp": 1585517376.9266276, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014097725041210651, "Value Loss": 5.036624861531891e-05, "_runtime": 8300.094029903412, "_timestamp": 1585517378.5147595, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01530384086072445, "Value Loss": 0.00023737779702059925, "_runtime": 8301.683942556381, "_timestamp": 1585517380.1046722, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015604275278747082, "Value Loss": 8.581874863011762e-05, "_runtime": 8303.273157835007, "_timestamp": 1585517381.6938875, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015155819244682789, "Value Loss": 7.082067895680666e-05, "_runtime": 8304.898380279541, "_timestamp": 1585517383.31911, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01566181145608425, "Value Loss": 6.692233000649139e-05, "_runtime": 8306.4861369133, "_timestamp": 1585517384.9068666, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01576303318142891, "Value Loss": 6.307208241196349e-05, "_runtime": 8308.075259923935, "_timestamp": 1585517386.4959896, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016435004770755768, "Value Loss": 9.849946218309924e-05, "_runtime": 8309.662444353104, "_timestamp": 1585517388.083174, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016942055895924568, "Value Loss": 0.0001245589810423553, "_runtime": 8311.255811452866, "_timestamp": 1585517389.676541, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01580587401986122, "Value Loss": 5.537517154152738e-06, "_runtime": 8312.846853017807, "_timestamp": 1585517391.2675827, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.017392683774232864, "Value Loss": 2.4746801500441507e-05, "_runtime": 8314.423115730286, "_timestamp": 1585517392.8438454, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015592079609632492, "Value Loss": 4.3600434764812235e-06, "_runtime": 8316.005984783173, "_timestamp": 1585517394.4267144, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01659281924366951, "Value Loss": 0.00013609086454380304, "_runtime": 8317.593356609344, "_timestamp": 1585517396.0140862, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016787417232990265, "Value Loss": 0.0003855375980492681, "_runtime": 8319.180591106415, "_timestamp": 1585517397.6013207, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016786018386483192, "Value Loss": 0.00033975637052208185, "_runtime": 8320.768260478973, "_timestamp": 1585517399.18899, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015024043619632721, "Value Loss": 1.2631596291612368e-05, "_runtime": 8322.359452724457, "_timestamp": 1585517400.7801824, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016655180603265762, "Value Loss": 0.000413272762671113, "_runtime": 8323.947674274445, "_timestamp": 1585517402.368404, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016366709023714066, "Value Loss": 0.00019826892821583897, "_runtime": 8325.538493156433, "_timestamp": 1585517403.9592228, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016396570950746536, "Value Loss": 7.36449146643281e-05, "_runtime": 8327.118424654007, "_timestamp": 1585517405.5391543, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01723029837012291, "Value Loss": 0.00029438722413033247, "_runtime": 8328.72372674942, "_timestamp": 1585517407.1444564, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01683640293776989, "Value Loss": 4.392798291519284e-05, "_runtime": 8330.3048017025, "_timestamp": 1585517408.7255313, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015925263985991478, "Value Loss": 2.7022409994970076e-05, "_runtime": 8331.88747048378, "_timestamp": 1585517410.3082001, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016506070271134377, "Value Loss": 6.364654109347612e-05, "_runtime": 8333.467587947845, "_timestamp": 1585517411.8883176, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015949422493577003, "Value Loss": 5.6740380387054756e-05, "_runtime": 8335.052576303482, "_timestamp": 1585517413.473306, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016446322202682495, "Value Loss": 9.088955994229764e-05, "_runtime": 8336.631377220154, "_timestamp": 1585517415.0521069, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016488229855895042, "Value Loss": 0.0001122014073189348, "_runtime": 8338.219111204147, "_timestamp": 1585517416.6398408, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016843168064951897, "Value Loss": 0.0002774784225039184, "_runtime": 8339.800616502762, "_timestamp": 1585517418.2213461, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.016623862087726593, "Value Loss": 0.00027279372443445027, "_runtime": 8341.393564939499, "_timestamp": 1585517419.8142946, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0153264831751585, "Value Loss": 9.702907846076414e-05, "_runtime": 8342.981747627258, "_timestamp": 1585517421.4024773, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01484965905547142, "Value Loss": 6.441378354793414e-05, "_runtime": 8344.55014872551, "_timestamp": 1585517422.9708784, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014892670325934887, "Value Loss": 4.77480461995583e-05, "_runtime": 8346.119550943375, "_timestamp": 1585517424.5402806, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014729472808539867, "Value Loss": 0.0001313770335400477, "_runtime": 8347.706593990326, "_timestamp": 1585517426.1273236, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014219054020941257, "Value Loss": 0.00010168158769374713, "_runtime": 8349.291508436203, "_timestamp": 1585517427.712238, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.014564049430191517, "Value Loss": 0.00030117228743620217, "_runtime": 8350.86960363388, "_timestamp": 1585517429.2903333, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013174396939575672, "Value Loss": 5.92669821344316e-05, "_runtime": 8352.474053382874, "_timestamp": 1585517430.894783, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.013985942117869854, "Value Loss": 4.050037023262121e-05, "_runtime": 8354.052858829498, "_timestamp": 1585517432.4735885, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.012717547826468945, "Value Loss": 7.037425530143082e-05, "_runtime": 8355.636874437332, "_timestamp": 1585517434.057604, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011816056445240974, "Value Loss": 6.39389400021173e-05, "_runtime": 8357.225094556808, "_timestamp": 1585517435.6458242, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01136605441570282, "Value Loss": 7.421984628308564e-05, "_runtime": 8358.813408136368, "_timestamp": 1585517437.2341378, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.011822720058262348, "Value Loss": 0.00031213441980071366, "_runtime": 8360.39120221138, "_timestamp": 1585517438.8119318, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01022688951343298, "Value Loss": 5.654919004882686e-05, "_runtime": 8361.976992845535, "_timestamp": 1585517440.3977225, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01042683981359005, "Value Loss": 8.229189552366734e-05, "_runtime": 8363.56734585762, "_timestamp": 1585517441.9880755, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010050483047962189, "Value Loss": 0.00023883843095973134, "_runtime": 8365.160180807114, "_timestamp": 1585517443.5809104, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0077972435392439365, "Value Loss": 1.1863949112012051e-05, "_runtime": 8366.746387720108, "_timestamp": 1585517445.1671174, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007913636974990368, "Value Loss": 6.112107803346589e-05, "_runtime": 8368.338207483292, "_timestamp": 1585517446.7589371, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008565027266740799, "Value Loss": 3.941017348552123e-05, "_runtime": 8369.926573753357, "_timestamp": 1585517448.3473034, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006881754379719496, "Value Loss": 7.396176079055294e-05, "_runtime": 8371.513961076736, "_timestamp": 1585517449.9346907, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006331710610538721, "Value Loss": 7.431331323459744e-05, "_runtime": 8373.105720996857, "_timestamp": 1585517451.5264506, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007577915210276842, "Value Loss": 0.00021569688396994025, "_runtime": 8374.697644472122, "_timestamp": 1585517453.118374, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005590738728642464, "Value Loss": 7.181454566307366e-05, "_runtime": 8376.311849594116, "_timestamp": 1585517454.7325792, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005746593698859215, "Value Loss": 6.283327093115076e-05, "_runtime": 8377.899498939514, "_timestamp": 1585517456.3202286, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00486412551254034, "Value Loss": 6.814739026594907e-05, "_runtime": 8379.489164590836, "_timestamp": 1585517457.9098942, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004762052092701197, "Value Loss": 4.3361185817047954e-05, "_runtime": 8381.077997684479, "_timestamp": 1585517459.4987273, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0048177060671150684, "Value Loss": 3.256899435655214e-05, "_runtime": 8382.6668009758, "_timestamp": 1585517461.0875306, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003906464669853449, "Value Loss": 3.4467990190023556e-05, "_runtime": 8384.247161149979, "_timestamp": 1585517462.6678908, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004112017806619406, "Value Loss": 8.048827294260263e-05, "_runtime": 8385.834305524826, "_timestamp": 1585517464.2550352, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002637919271364808, "Value Loss": 3.822839062195271e-05, "_runtime": 8387.424520730972, "_timestamp": 1585517465.8452504, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0024393240455538034, "Value Loss": 5.0362388719804585e-05, "_runtime": 8389.01404953003, "_timestamp": 1585517467.4347792, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0023563343565911055, "Value Loss": 4.179132156423293e-05, "_runtime": 8390.601418018341, "_timestamp": 1585517469.0221477, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026732045225799084, "Value Loss": 5.6024040532065555e-05, "_runtime": 8392.191894769669, "_timestamp": 1585517470.6126244, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.003248248714953661, "Value Loss": 9.235773904947564e-05, "_runtime": 8393.761749505997, "_timestamp": 1585517472.1824791, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0019253547070547938, "Value Loss": 4.0004415495786816e-05, "_runtime": 8395.34241938591, "_timestamp": 1585517473.763149, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0036556448321789503, "Value Loss": 0.00025331065990030766, "_runtime": 8396.923160552979, "_timestamp": 1585517475.3438902, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0020552403293550014, "Value Loss": 3.828138142125681e-05, "_runtime": 8398.549197435379, "_timestamp": 1585517476.969927, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0024383431300520897, "Value Loss": 2.2070666091167368e-05, "_runtime": 8400.125220060349, "_timestamp": 1585517478.5459497, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002795940497890115, "Value Loss": 3.9954829844646156e-05, "_runtime": 8401.713808059692, "_timestamp": 1585517480.1345377, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.00211617280729115, "Value Loss": 8.393956704821903e-06, "_runtime": 8403.30283999443, "_timestamp": 1585517481.7235696, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002264070324599743, "Value Loss": 8.6791260400787e-06, "_runtime": 8404.8911318779, "_timestamp": 1585517483.3118615, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0028950003907084465, "Value Loss": 2.0438375941012055e-05, "_runtime": 8406.460251808167, "_timestamp": 1585517484.8809814, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0033223384525626898, "Value Loss": 4.278717824490741e-05, "_runtime": 8408.050501346588, "_timestamp": 1585517486.471231, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004402937833219767, "Value Loss": 1.9827675714623183e-05, "_runtime": 8409.62728524208, "_timestamp": 1585517488.0480149, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0028967601247131824, "Value Loss": 7.453981652361108e-06, "_runtime": 8411.219501018524, "_timestamp": 1585517489.6402307, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004118399228900671, "Value Loss": 4.720332071883604e-05, "_runtime": 8412.807922124863, "_timestamp": 1585517491.2286518, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004594868049025536, "Value Loss": 1.9794557374552824e-05, "_runtime": 8414.400002717972, "_timestamp": 1585517492.8207324, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.005739039741456509, "Value Loss": 0.00025173622998408973, "_runtime": 8415.990502119064, "_timestamp": 1585517494.4112318, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006046069320291281, "Value Loss": 0.00023917235375847667, "_runtime": 8417.579875946045, "_timestamp": 1585517496.0006056, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004384440835565329, "Value Loss": 2.0028297512908466e-05, "_runtime": 8419.158066749573, "_timestamp": 1585517497.5787964, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006216622889041901, "Value Loss": 0.00019388333021197468, "_runtime": 8420.73837685585, "_timestamp": 1585517499.1591065, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0056302305310964584, "Value Loss": 2.833667713275645e-05, "_runtime": 8422.364659309387, "_timestamp": 1585517500.785389, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006293036974966526, "Value Loss": 2.9102418920956552e-05, "_runtime": 8423.951672315598, "_timestamp": 1585517502.372402, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007773516234010458, "Value Loss": 4.7611643822165206e-05, "_runtime": 8425.543147325516, "_timestamp": 1585517503.963877, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008730448782444, "Value Loss": 0.0001468528207624331, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 8427.133389472961, "_timestamp": 1585517505.554119, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008498319424688816, "Value Loss": 2.0445579139050096e-05, "_runtime": 8427.133389472961, "_timestamp": 1585517505.554119, "_step": 499}
