{"Episode reward": 72.54447589052032, "Episode length": 611, "Policy Loss": 0.16578151285648346, "Value Loss": 16.44867706298828, "_runtime": 746.2599771022797, "_timestamp": 1585595495.2766507, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1523454487323761, "Value Loss": 15.375226974487305, "_runtime": 747.7196252346039, "_timestamp": 1585595496.7362988, "_step": 1}
{"Episode reward": -74.91856257277456, "Episode length": 999, "Policy Loss": -0.04647013172507286, "Value Loss": 0.019603915512561798, "_runtime": 748.5997321605682, "_timestamp": 1585595497.6164057, "_step": 2}
{"Episode reward": 75.26149322801695, "Episode length": 581, "Policy Loss": 0.06632617115974426, "Value Loss": 18.009355545043945, "_runtime": 750.1205017566681, "_timestamp": 1585595499.1371753, "_step": 3}
{"Episode reward": -44.736887462081086, "Episode length": 999, "Policy Loss": -0.07558140903711319, "Value Loss": 0.013253283686935902, "_runtime": 751.6289002895355, "_timestamp": 1585595500.6455739, "_step": 4}
{"Episode reward": -35.36819857460832, "Episode length": 999, "Policy Loss": -0.05131692811846733, "Value Loss": 0.00485983258113265, "_runtime": 753.1452889442444, "_timestamp": 1585595502.1619625, "_step": 5}
{"Episode reward": -44.72659333027082, "Episode length": 999, "Policy Loss": -0.23987123370170593, "Value Loss": 1.0345089435577393, "_runtime": 754.0589122772217, "_timestamp": 1585595503.0755858, "_step": 6}
{"Episode reward": 56.24888075271532, "Episode length": 588, "Policy Loss": -0.35311946272850037, "Value Loss": 17.156005859375, "_runtime": 754.4617567062378, "_timestamp": 1585595503.4784303, "_step": 7}
{"Episode reward": 81.67901075181412, "Episode length": 238, "Policy Loss": 2.0147621631622314, "Value Loss": 41.819541931152344, "_runtime": 754.8116691112518, "_timestamp": 1585595503.8283427, "_step": 8}
{"Episode reward": 82.65966886161613, "Episode length": 206, "Policy Loss": 0.2859923839569092, "Value Loss": 48.44923400878906, "_runtime": 755.0914213657379, "_timestamp": 1585595504.108095, "_step": 9}
{"Episode reward": 85.44806755606945, "Episode length": 170, "Policy Loss": 0.6269218921661377, "Value Loss": 58.44709396362305, "_runtime": 755.3453059196472, "_timestamp": 1585595504.3619795, "_step": 10}
{"Episode reward": 84.42031473181517, "Episode length": 169, "Policy Loss": 0.7741885185241699, "Value Loss": 58.526824951171875, "_runtime": 755.5983295440674, "_timestamp": 1585595504.615003, "_step": 11}
{"Episode reward": 83.99911467365695, "Episode length": 173, "Policy Loss": 0.6321180462837219, "Value Loss": 56.93716049194336, "_runtime": 756.0800728797913, "_timestamp": 1585595505.0967464, "_step": 12}
{"Episode reward": 69.25869147162682, "Episode length": 336, "Policy Loss": 0.4743109345436096, "Value Loss": 29.147005081176758, "_runtime": 756.3258066177368, "_timestamp": 1585595505.3424802, "_step": 13}
{"Episode reward": 84.55113627326537, "Episode length": 169, "Policy Loss": 0.81402587890625, "Value Loss": 57.64896774291992, "_runtime": 756.5963385105133, "_timestamp": 1585595505.613012, "_step": 14}
{"Episode reward": 81.93509911191082, "Episode length": 188, "Policy Loss": -2.276142120361328, "Value Loss": 52.1921272277832, "_runtime": 756.867625951767, "_timestamp": 1585595505.8842995, "_step": 15}
{"Episode reward": 82.65339163877776, "Episode length": 181, "Policy Loss": -0.6650391221046448, "Value Loss": 54.54035568237305, "_runtime": 757.1646337509155, "_timestamp": 1585595506.1813073, "_step": 16}
{"Episode reward": 80.32716969565894, "Episode length": 203, "Policy Loss": -4.856561183929443, "Value Loss": 51.30711364746094, "_runtime": 757.4236631393433, "_timestamp": 1585595506.4403367, "_step": 17}
{"Episode reward": 82.91371383025302, "Episode length": 179, "Policy Loss": 0.6665893793106079, "Value Loss": 54.81877517700195, "_runtime": 758.456779718399, "_timestamp": 1585595507.4734533, "_step": 18}
{"Episode reward": 32.631109265653166, "Episode length": 719, "Policy Loss": -0.33061668276786804, "Value Loss": 14.119688034057617, "_runtime": 759.9269835948944, "_timestamp": 1585595508.9436572, "_step": 19}
{"Episode reward": -91.0133975474115, "Episode length": 999, "Policy Loss": -0.46079394221305847, "Value Loss": 0.035545364022254944, "_runtime": 761.4089214801788, "_timestamp": 1585595510.425595, "_step": 20}
{"Episode reward": -91.39261748501067, "Episode length": 999, "Policy Loss": -0.39108890295028687, "Value Loss": 0.030809909105300903, "_runtime": 762.9138534069061, "_timestamp": 1585595511.930527, "_step": 21}
{"Episode reward": -94.87804480854905, "Episode length": 999, "Policy Loss": -0.4368096590042114, "Value Loss": 0.02246403507888317, "_runtime": 764.4358224868774, "_timestamp": 1585595513.452496, "_step": 22}
{"Episode reward": -92.92794359376259, "Episode length": 999, "Policy Loss": -0.383506715297699, "Value Loss": 0.03507811203598976, "_runtime": 765.9911556243896, "_timestamp": 1585595515.0078292, "_step": 23}
{"Episode reward": -93.49440272075483, "Episode length": 999, "Policy Loss": -0.37250757217407227, "Value Loss": 0.04775740206241608, "_runtime": 767.5345561504364, "_timestamp": 1585595516.5512297, "_step": 24}
{"Episode reward": -90.72760435658482, "Episode length": 999, "Policy Loss": -0.39559274911880493, "Value Loss": 0.0265257079154253, "_runtime": 769.0790431499481, "_timestamp": 1585595518.0957167, "_step": 25}
{"Episode reward": -93.60751435369957, "Episode length": 999, "Policy Loss": -0.4262867867946625, "Value Loss": 0.027703944593667984, "_runtime": 770.6090884208679, "_timestamp": 1585595519.625762, "_step": 26}
{"Episode reward": -93.15915222124289, "Episode length": 999, "Policy Loss": -0.3690255880355835, "Value Loss": 0.06137677654623985, "_runtime": 772.1390047073364, "_timestamp": 1585595521.1556783, "_step": 27}
{"Episode reward": -93.99513259248077, "Episode length": 999, "Policy Loss": -0.4336526691913605, "Value Loss": 0.02874753065407276, "_runtime": 773.6886048316956, "_timestamp": 1585595522.7052784, "_step": 28}
{"Episode reward": -92.00419514175407, "Episode length": 999, "Policy Loss": -0.3675801455974579, "Value Loss": 0.05262720212340355, "_runtime": 775.2384214401245, "_timestamp": 1585595524.255095, "_step": 29}
{"Episode reward": -94.16147179260334, "Episode length": 999, "Policy Loss": -0.4273770749568939, "Value Loss": 0.03337324783205986, "_runtime": 776.7835052013397, "_timestamp": 1585595525.8001788, "_step": 30}
{"Episode reward": -94.69422593168485, "Episode length": 999, "Policy Loss": -0.43584927916526794, "Value Loss": 0.02313416264951229, "_runtime": 778.3284482955933, "_timestamp": 1585595527.3451219, "_step": 31}
{"Episode reward": -91.33130696318497, "Episode length": 999, "Policy Loss": -0.3991352915763855, "Value Loss": 0.027471141889691353, "_runtime": 779.8678302764893, "_timestamp": 1585595528.8845038, "_step": 32}
{"Episode reward": -93.58355821944356, "Episode length": 999, "Policy Loss": -0.4233877956867218, "Value Loss": 0.020752426236867905, "_runtime": 781.4194467067719, "_timestamp": 1585595530.4361203, "_step": 33}
{"Episode reward": -91.41938359991406, "Episode length": 999, "Policy Loss": -0.39197829365730286, "Value Loss": 0.02368548884987831, "_runtime": 782.9678559303284, "_timestamp": 1585595531.9845295, "_step": 34}
{"Episode reward": -91.0553622841744, "Episode length": 999, "Policy Loss": -0.3916415572166443, "Value Loss": 0.018833408132195473, "_runtime": 784.5245571136475, "_timestamp": 1585595533.5412307, "_step": 35}
{"Episode reward": -92.02160654863974, "Episode length": 999, "Policy Loss": -0.4094894826412201, "Value Loss": 0.01893552392721176, "_runtime": 786.0815222263336, "_timestamp": 1585595535.0981958, "_step": 36}
{"Episode reward": -89.82499557390402, "Episode length": 999, "Policy Loss": -0.39039158821105957, "Value Loss": 0.01832345686852932, "_runtime": 787.6259932518005, "_timestamp": 1585595536.6426668, "_step": 37}
{"Episode reward": -90.99335826007555, "Episode length": 999, "Policy Loss": -0.39942529797554016, "Value Loss": 0.018564598634839058, "_runtime": 789.2064166069031, "_timestamp": 1585595538.2230902, "_step": 38}
{"Episode reward": -90.89099549807364, "Episode length": 999, "Policy Loss": -0.40819206833839417, "Value Loss": 0.01834857277572155, "_runtime": 790.7488646507263, "_timestamp": 1585595539.7655382, "_step": 39}
{"Episode reward": -87.35681707273318, "Episode length": 999, "Policy Loss": -0.37285876274108887, "Value Loss": 0.018107062205672264, "_runtime": 792.3055863380432, "_timestamp": 1585595541.32226, "_step": 40}
{"Episode reward": -86.36083849540718, "Episode length": 999, "Policy Loss": -0.35755640268325806, "Value Loss": 0.021116843447089195, "_runtime": 793.8499186038971, "_timestamp": 1585595542.8665922, "_step": 41}
{"Episode reward": -86.72665838321686, "Episode length": 999, "Policy Loss": -0.36208006739616394, "Value Loss": 0.02245435118675232, "_runtime": 795.3976981639862, "_timestamp": 1585595544.4143717, "_step": 42}
{"Episode reward": -83.97510837128756, "Episode length": 999, "Policy Loss": -0.3929179608821869, "Value Loss": 0.020938104018568993, "_runtime": 796.9441244602203, "_timestamp": 1585595545.960798, "_step": 43}
{"Episode reward": -86.56963182058527, "Episode length": 999, "Policy Loss": -0.3676506280899048, "Value Loss": 0.019765306264162064, "_runtime": 798.4919340610504, "_timestamp": 1585595547.5086076, "_step": 44}
{"Episode reward": -90.18854371140193, "Episode length": 999, "Policy Loss": -0.3728044331073761, "Value Loss": 0.019536377862095833, "_runtime": 799.1582736968994, "_timestamp": 1585595548.1749473, "_step": 45}
{"Episode reward": 63.55100026282621, "Episode length": 420, "Policy Loss": 0.6180760264396667, "Value Loss": 23.74003028869629, "_runtime": 799.5065388679504, "_timestamp": 1585595548.5232124, "_step": 46}
{"Episode reward": 84.93180005618991, "Episode length": 191, "Policy Loss": 1.4581365585327148, "Value Loss": 52.15776824951172, "_runtime": 800.268098115921, "_timestamp": 1585595549.2847717, "_step": 47}
{"Episode reward": 58.414535862636406, "Episode length": 487, "Policy Loss": 0.8055140376091003, "Value Loss": 20.477947235107422, "_runtime": 800.6816184520721, "_timestamp": 1585595549.698292, "_step": 48}
{"Episode reward": 77.76509123830041, "Episode length": 265, "Policy Loss": 0.8599417209625244, "Value Loss": 37.56836700439453, "_runtime": 801.1691362857819, "_timestamp": 1585595550.1858099, "_step": 49}
{"Episode reward": 70.49686332989232, "Episode length": 339, "Policy Loss": 0.5095075964927673, "Value Loss": 29.37066650390625, "_runtime": 801.4622933864594, "_timestamp": 1585595550.478967, "_step": 50}
{"Episode reward": 83.61562694192429, "Episode length": 186, "Policy Loss": 1.9222843647003174, "Value Loss": 53.43376541137695, "_runtime": 801.7295591831207, "_timestamp": 1585595550.7462327, "_step": 51}
{"Episode reward": 84.8771297330462, "Episode length": 179, "Policy Loss": 1.3250051736831665, "Value Loss": 55.54969024658203, "_runtime": 802.0069463253021, "_timestamp": 1585595551.02362, "_step": 52}
{"Episode reward": 83.10705036894336, "Episode length": 186, "Policy Loss": 1.6733258962631226, "Value Loss": 53.33049392700195, "_runtime": 802.1775488853455, "_timestamp": 1585595551.1942225, "_step": 53}
{"Episode reward": 89.84483666782423, "Episode length": 113, "Policy Loss": 2.5794074535369873, "Value Loss": 87.53952026367188, "_runtime": 802.5923101902008, "_timestamp": 1585595551.6089838, "_step": 54}
{"Episode reward": 73.00484514384773, "Episode length": 289, "Policy Loss": 0.7041565775871277, "Value Loss": 34.22312545776367, "_runtime": 803.3192446231842, "_timestamp": 1585595552.3359182, "_step": 55}
{"Episode reward": 53.627744749065116, "Episode length": 507, "Policy Loss": 0.2196541279554367, "Value Loss": 19.530410766601562, "_runtime": 803.4948942661285, "_timestamp": 1585595552.5115678, "_step": 56}
{"Episode reward": 89.30864709085756, "Episode length": 109, "Policy Loss": 3.27681040763855, "Value Loss": 90.09522247314453, "_runtime": 803.6767928600311, "_timestamp": 1585595552.6934664, "_step": 57}
{"Episode reward": 89.3932690032249, "Episode length": 115, "Policy Loss": 1.5391271114349365, "Value Loss": 84.97826385498047, "_runtime": 803.9594841003418, "_timestamp": 1585595552.9761577, "_step": 58}
{"Episode reward": 82.5941525011765, "Episode length": 182, "Policy Loss": -0.035313136875629425, "Value Loss": 54.20440673828125, "_runtime": 804.1310765743256, "_timestamp": 1585595553.1477501, "_step": 59}
{"Episode reward": 89.4816074776219, "Episode length": 116, "Policy Loss": 0.9709585309028625, "Value Loss": 84.15923309326172, "_runtime": 804.3070876598358, "_timestamp": 1585595553.3237612, "_step": 60}
{"Episode reward": 88.5287277223684, "Episode length": 120, "Policy Loss": 2.5333895683288574, "Value Loss": 81.5733413696289, "_runtime": 804.5953977108002, "_timestamp": 1585595553.6120713, "_step": 61}
{"Episode reward": 81.28029195140007, "Episode length": 200, "Policy Loss": 1.6278802156448364, "Value Loss": 48.805301666259766, "_runtime": 804.7658574581146, "_timestamp": 1585595553.782531, "_step": 62}
{"Episode reward": 89.23027561503447, "Episode length": 116, "Policy Loss": 3.7055249214172363, "Value Loss": 83.91551971435547, "_runtime": 804.9221515655518, "_timestamp": 1585595553.9388251, "_step": 63}
{"Episode reward": 89.97812761324644, "Episode length": 106, "Policy Loss": 1.545448899269104, "Value Loss": 91.15984344482422, "_runtime": 805.3979306221008, "_timestamp": 1585595554.4146042, "_step": 64}
{"Episode reward": 68.23421995809537, "Episode length": 334, "Policy Loss": -0.2598015367984772, "Value Loss": 29.262134552001953, "_runtime": 805.6559071540833, "_timestamp": 1585595554.6725807, "_step": 65}
{"Episode reward": 84.11396940125675, "Episode length": 180, "Policy Loss": 0.6135557889938354, "Value Loss": 53.113792419433594, "_runtime": 805.9261116981506, "_timestamp": 1585595554.9427853, "_step": 66}
{"Episode reward": 82.67840986893316, "Episode length": 190, "Policy Loss": 0.557131826877594, "Value Loss": 50.12079620361328, "_runtime": 806.221200466156, "_timestamp": 1585595555.237874, "_step": 67}
{"Episode reward": 81.29592445569114, "Episode length": 198, "Policy Loss": 0.6483615636825562, "Value Loss": 47.35663604736328, "_runtime": 806.4899411201477, "_timestamp": 1585595555.5066147, "_step": 68}
{"Episode reward": 83.15002338625479, "Episode length": 186, "Policy Loss": 0.7244278192520142, "Value Loss": 50.70387649536133, "_runtime": 806.9584174156189, "_timestamp": 1585595555.975091, "_step": 69}
{"Episode reward": 69.47723534375554, "Episode length": 330, "Policy Loss": -0.30510222911834717, "Value Loss": 29.21714973449707, "_runtime": 807.1358964443207, "_timestamp": 1585595556.15257, "_step": 70}
{"Episode reward": 89.13227735008114, "Episode length": 116, "Policy Loss": 2.3186981678009033, "Value Loss": 80.75643157958984, "_runtime": 807.4055421352386, "_timestamp": 1585595556.4222157, "_step": 71}
{"Episode reward": 82.97182578350964, "Episode length": 186, "Policy Loss": -0.6153316497802734, "Value Loss": 50.59705352783203, "_runtime": 807.673778295517, "_timestamp": 1585595556.6904519, "_step": 72}
{"Episode reward": 83.5853482385783, "Episode length": 181, "Policy Loss": 0.5706725716590881, "Value Loss": 50.41802978515625, "_runtime": 807.8323712348938, "_timestamp": 1585595556.8490448, "_step": 73}
{"Episode reward": 90.07671302835638, "Episode length": 107, "Policy Loss": 2.4816861152648926, "Value Loss": 87.23614501953125, "_runtime": 807.9980137348175, "_timestamp": 1585595557.0146873, "_step": 74}
{"Episode reward": 89.68234364956504, "Episode length": 110, "Policy Loss": 1.903044581413269, "Value Loss": 82.05789947509766, "_runtime": 808.4486045837402, "_timestamp": 1585595557.4652781, "_step": 75}
{"Episode reward": 70.78487371471736, "Episode length": 316, "Policy Loss": -0.3891482651233673, "Value Loss": 29.78216552734375, "_runtime": 808.6184606552124, "_timestamp": 1585595557.6351342, "_step": 76}
{"Episode reward": 89.57540905267717, "Episode length": 115, "Policy Loss": 0.8040520548820496, "Value Loss": 79.61207580566406, "_runtime": 808.7867846488953, "_timestamp": 1585595557.8034582, "_step": 77}
{"Episode reward": 89.43691873293844, "Episode length": 115, "Policy Loss": 2.293762445449829, "Value Loss": 76.99332427978516, "_runtime": 809.1485075950623, "_timestamp": 1585595558.1651812, "_step": 78}
{"Episode reward": 76.80443125176531, "Episode length": 248, "Policy Loss": -0.8956394791603088, "Value Loss": 34.97348403930664, "_runtime": 809.3129289150238, "_timestamp": 1585595558.3296025, "_step": 79}
{"Episode reward": 90.00884380991863, "Episode length": 108, "Policy Loss": -0.1010764092206955, "Value Loss": 79.10126495361328, "_runtime": 809.4650177955627, "_timestamp": 1585595558.4816914, "_step": 80}
{"Episode reward": 90.28830426202391, "Episode length": 103, "Policy Loss": 2.04952335357666, "Value Loss": 80.70352172851562, "_runtime": 809.8629882335663, "_timestamp": 1585595558.8796618, "_step": 81}
{"Episode reward": 73.874222387052, "Episode length": 277, "Policy Loss": -2.0953571796417236, "Value Loss": 38.10335159301758, "_runtime": 810.6218996047974, "_timestamp": 1585595559.6385732, "_step": 82}
{"Episode reward": 50.59708548856049, "Episode length": 533, "Policy Loss": 0.22103536128997803, "Value Loss": 17.272350311279297, "_runtime": 810.8015418052673, "_timestamp": 1585595559.8182154, "_step": 83}
{"Episode reward": 89.20176578352626, "Episode length": 112, "Policy Loss": 3.727311372756958, "Value Loss": 87.76024627685547, "_runtime": 811.0995924472809, "_timestamp": 1585595560.116266, "_step": 84}
{"Episode reward": 81.16489908007023, "Episode length": 201, "Policy Loss": -0.10402829200029373, "Value Loss": 47.8272705078125, "_runtime": 811.378026008606, "_timestamp": 1585595560.3946996, "_step": 85}
{"Episode reward": 82.97845679509476, "Episode length": 179, "Policy Loss": -5.648194313049316, "Value Loss": 60.360023498535156, "_runtime": 811.629768371582, "_timestamp": 1585595560.646442, "_step": 86}
{"Episode reward": 84.1159253224312, "Episode length": 176, "Policy Loss": 0.3747757077217102, "Value Loss": 48.9084358215332, "_runtime": 811.8276822566986, "_timestamp": 1585595560.8443558, "_step": 87}
{"Episode reward": 88.19131331233268, "Episode length": 132, "Policy Loss": 1.5133706331253052, "Value Loss": 71.22781372070312, "_runtime": 812.3016135692596, "_timestamp": 1585595561.3182871, "_step": 88}
{"Episode reward": 68.8455233827713, "Episode length": 333, "Policy Loss": 2.2879953384399414, "Value Loss": 28.34765625, "_runtime": 812.6517779827118, "_timestamp": 1585595561.6684515, "_step": 89}
{"Episode reward": 77.81501902888442, "Episode length": 245, "Policy Loss": 2.8106958866119385, "Value Loss": 37.41166687011719, "_runtime": 812.9019711017609, "_timestamp": 1585595561.9186447, "_step": 90}
{"Episode reward": 84.05095531969287, "Episode length": 173, "Policy Loss": 3.098054885864258, "Value Loss": 52.69195556640625, "_runtime": 813.0787990093231, "_timestamp": 1585595562.0954726, "_step": 91}
{"Episode reward": 89.56315832716038, "Episode length": 111, "Policy Loss": 1.5372649431228638, "Value Loss": 84.46088409423828, "_runtime": 813.2971062660217, "_timestamp": 1585595562.3137798, "_step": 92}
{"Episode reward": 86.38005729600818, "Episode length": 146, "Policy Loss": 0.5306563377380371, "Value Loss": 64.7201919555664, "_runtime": 813.7639534473419, "_timestamp": 1585595562.780627, "_step": 93}
{"Episode reward": 69.16085722800216, "Episode length": 328, "Policy Loss": -1.0768681764602661, "Value Loss": 29.521181106567383, "_runtime": 813.9258573055267, "_timestamp": 1585595562.9425309, "_step": 94}
{"Episode reward": 90.11763132268139, "Episode length": 109, "Policy Loss": 1.6424049139022827, "Value Loss": 86.1834945678711, "_runtime": 814.278226852417, "_timestamp": 1585595563.2949004, "_step": 95}
{"Episode reward": 77.33984541440473, "Episode length": 247, "Policy Loss": 1.2990942001342773, "Value Loss": 36.99637222290039, "_runtime": 814.5562272071838, "_timestamp": 1585595563.5729008, "_step": 96}
{"Episode reward": 83.92691849173579, "Episode length": 186, "Policy Loss": -0.6506801843643188, "Value Loss": 49.17307662963867, "_runtime": 815.0723872184753, "_timestamp": 1585595564.0890608, "_step": 97}
{"Episode reward": 67.44343109774475, "Episode length": 366, "Policy Loss": -0.09903554618358612, "Value Loss": 24.724483489990234, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059, 5.813323020935059]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0], "bins": [42.894527435302734, 46.17387771606445, 49.45322799682617, 52.732582092285156, 56.011932373046875, 59.291282653808594, 62.57063293457031, 65.84998321533203, 69.12933349609375, 72.40868377685547, 75.68803405761719, 78.96739196777344, 82.24673461914062, 85.52609252929688, 88.8054428100586, 92.08479309082031, 95.36414337158203, 98.64349365234375, 101.92284393310547, 105.20219421386719, 108.48155212402344, 111.76089477539062, 115.04025268554688, 118.31959533691406, 121.59895324707031, 124.8782958984375, 128.15765380859375, 131.43701171875, 134.7163543701172, 137.99571228027344, 141.27505493164062, 144.55441284179688, 147.83375549316406, 151.1131134033203, 154.3924560546875, 157.67181396484375, 160.95115661621094, 164.2305145263672, 167.50987243652344, 170.78921508789062, 174.06857299804688, 177.34791564941406, 180.6272735595703, 183.90663146972656, 187.18597412109375, 190.46533203125, 193.7446746826172, 197.02403259277344, 200.30337524414062, 203.58273315429688, 206.86207580566406, 210.1414337158203, 213.4207763671875, 216.70013427734375, 219.9794921875, 223.2588348388672, 226.53819274902344, 229.81753540039062, 233.09689331054688, 236.37623596191406, 239.6555938720703, 242.9349365234375, 246.21429443359375, 249.49363708496094, 252.7729949951172]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.5270156860351562, -2.3578929901123047, -2.188770055770874, -2.0196473598480225, -1.8505245447158813, -1.6814017295837402, -1.5122790336608887, -1.3431562185287476, -1.1740334033966064, -1.0049105882644653, -0.8357877731323242, -0.6666650772094727, -0.4975423812866211, -0.32841944694519043, -0.15929675102233887, 0.009826183319091797, 0.17894887924194336, 0.3480715751647949, 0.5171945095062256, 0.6863172054290771, 0.8554401397705078, 1.0245628356933594, 1.193685531616211, 1.3628084659576416, 1.531930923461914, 1.7010540962219238, 1.8701767921447754, 2.039299488067627, 2.2084221839904785, 2.37754487991333, 2.54666805267334, 2.7157907485961914, 2.884913444519043, 3.0540361404418945, 3.223158836364746, 3.392282009124756, 3.5614047050476074, 3.730527400970459, 3.8996500968933105, 4.068772792816162, 4.237895965576172, 4.407018661499023, 4.576141357421875, 4.745264053344727, 4.914386749267578, 5.08350944519043, 5.2526326179504395, 5.421755313873291, 5.590877532958984, 5.760001182556152, 5.929123878479004, 6.0982465744018555, 6.267369270324707, 6.436491966247559, 6.60561466217041, 6.774737358093262, 6.943860054016113, 7.112982749938965, 7.282105445861816, 7.451229095458984, 7.620351791381836, 7.7894744873046875, 7.958597183227539, 8.12771987915039, 8.296842575073242]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 1.0, 4.0, 5.0, 2.0, 3.0, 4.0, 7.0, 8.0, 7.0, 5.0, 9.0, 10.0, 8.0, 6.0, 9.0, 26.0, 29.0, 20.0, 24.0, 14.0, 15.0, 23.0, 77.0, 18.0, 13.0, 4.0, 9.0, 9.0, 28.0, 18.0, 15.0, 8.0, 8.0, 7.0, 4.0, 3.0, 3.0, 2.0, 2.0, 5.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-5.7344818115234375, -5.508215427398682, -5.281949043273926, -5.05568265914917, -4.829416275024414, -4.6031494140625, -4.376883506774902, -4.150616645812988, -3.9243502616882324, -3.6980838775634766, -3.4718174934387207, -3.245551109313965, -3.019284725189209, -2.793018341064453, -2.566751718521118, -2.3404853343963623, -2.1142189502716064, -1.8879525661468506, -1.6616859436035156, -1.4354195594787598, -1.209153175354004, -0.982886791229248, -0.7566204071044922, -0.5303540229797363, -0.30408763885498047, -0.07782125473022461, 0.14844512939453125, 0.3747119903564453, 0.6009783744812012, 0.827244758605957, 1.053511142730713, 1.2797775268554688, 1.5060439109802246, 1.7323102951049805, 1.9585766792297363, 2.184843063354492, 2.4111099243164062, 2.637375831604004, 2.863642692565918, 3.0899085998535156, 3.3161754608154297, 3.5424413681030273, 3.7687082290649414, 3.9949750900268555, 4.221240997314453, 4.447507858276367, 4.673773765563965, 4.900040626525879, 5.126306533813477, 5.352573394775391, 5.578839302062988, 5.805106163024902, 6.0313720703125, 6.257638931274414, 6.483905792236328, 6.710171699523926, 6.93643856048584, 7.1627044677734375, 7.388971328735352, 7.615237236022949, 7.841504096984863, 8.067770004272461, 8.294036865234375, 8.520302772521973, 8.746569633483887]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.255963325500488, -7.887501239776611, -7.519038677215576, -7.150576591491699, -6.782114028930664, -6.413651943206787, -6.04518985748291, -5.676727294921875, -5.308265209197998, -4.939803123474121, -4.571340560913086, -4.202878475189209, -3.834416389465332, -3.465953826904297, -3.09749174118042, -2.7290291786193848, -2.360567092895508, -1.9921050071716309, -1.6236424446105957, -1.2551803588867188, -0.8867177963256836, -0.5182557106018066, -0.1497936248779297, 0.21866893768310547, 0.5871305465698242, 0.9555931091308594, 1.3240556716918945, 1.6925182342529297, 2.0609798431396484, 2.4294424057006836, 2.7979049682617188, 3.1663665771484375, 3.5348291397094727, 3.903291702270508, 4.271753311157227, 4.640215873718262, 5.008678436279297, 5.377140045166016, 5.745602607727051, 6.114065170288086, 6.482527732849121, 6.85098934173584, 7.219451904296875, 7.58791446685791, 7.956376075744629, 8.324837684631348, 8.6933012008667, 9.061762809753418, 9.430224418640137, 9.798687934875488, 10.167149543762207, 10.535613059997559, 10.904074668884277, 11.272536277770996, 11.640999794006348, 12.009461402893066, 12.377923011779785, 12.746386528015137, 13.114848136901855, 13.483309745788574, 13.851773262023926, 14.220234870910645, 14.588696479797363, 14.957159996032715, 15.325621604919434]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 8.0, 8.0, 13.0, 9.0, 6.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-35.42450714111328, -34.135318756103516, -32.846134185791016, -31.55694580078125, -30.267759323120117, -28.978572845458984, -27.68938446044922, -26.400197982788086, -25.111011505126953, -23.82182502746582, -22.532638549804688, -21.243450164794922, -19.95426368713379, -18.665077209472656, -17.37588882446289, -16.086702346801758, -14.797515869140625, -13.508329391479492, -12.21914291381836, -10.929954528808594, -9.640768051147461, -8.351581573486328, -7.0623931884765625, -5.77320671081543, -4.484020233154297, -3.1948318481445312, -1.9056472778320312, -0.6164588928222656, 0.6727294921875, 1.9619140625, 3.2511024475097656, 4.540287017822266, 5.829475402832031, 7.118663787841797, 8.407848358154297, 9.697036743164062, 10.986221313476562, 12.275409698486328, 13.564598083496094, 14.853782653808594, 16.14297103881836, 17.432159423828125, 18.721343994140625, 20.01053237915039, 21.299720764160156, 22.588905334472656, 23.878093719482422, 25.167278289794922, 26.456466674804688, 27.745655059814453, 29.03484344482422, 30.32402801513672, 31.61321258544922, 32.90240478515625, 34.19158935546875, 35.48077392578125, 36.76996612548828, 38.05915069580078, 39.34833526611328, 40.63751983642578, 41.92671203613281, 43.21589660644531, 44.50508117675781, 45.794273376464844, 47.083457946777344]}, "_runtime": 815.5787024497986, "_timestamp": 1585595564.595376, "_step": 98}
{"Episode reward": 68.87276857428968, "Episode length": 352, "Policy Loss": -1.3774051666259766, "Value Loss": 27.18634033203125, "_runtime": 815.8911001682281, "_timestamp": 1585595564.9077737, "_step": 99}
{"Episode reward": 81.70475259387648, "Episode length": 215, "Policy Loss": -1.684413194656372, "Value Loss": 45.200809478759766, "_runtime": 816.2740676403046, "_timestamp": 1585595565.2907412, "_step": 100}
{"Episode reward": 78.14614335485828, "Episode length": 261, "Policy Loss": -0.733035683631897, "Value Loss": 33.39395523071289, "_runtime": 817.1989805698395, "_timestamp": 1585595566.2156541, "_step": 101}
{"Episode reward": 42.967367839218454, "Episode length": 639, "Policy Loss": -0.4192218780517578, "Value Loss": 12.992928504943848, "_runtime": 817.8058087825775, "_timestamp": 1585595566.8224823, "_step": 102}
{"Episode reward": 63.831332560698996, "Episode length": 414, "Policy Loss": 0.7056614756584167, "Value Loss": 20.60984992980957, "_runtime": 818.1932239532471, "_timestamp": 1585595567.2098975, "_step": 103}
{"Episode reward": 77.74982646513243, "Episode length": 257, "Policy Loss": 1.3229951858520508, "Value Loss": 36.61452102661133, "_runtime": 818.8817245960236, "_timestamp": 1585595567.8983982, "_step": 104}
{"Episode reward": 59.28521774489777, "Episode length": 463, "Policy Loss": 0.6801260709762573, "Value Loss": 19.287084579467773, "_runtime": 819.2879614830017, "_timestamp": 1585595568.304635, "_step": 105}
{"Episode reward": 77.53171159416361, "Episode length": 264, "Policy Loss": 1.182676076889038, "Value Loss": 35.30329513549805, "_runtime": 820.0849664211273, "_timestamp": 1585595569.10164, "_step": 106}
{"Episode reward": 50.6027622509126, "Episode length": 553, "Policy Loss": -0.03618296980857849, "Value Loss": 16.92005729675293, "_runtime": 820.7316610813141, "_timestamp": 1585595569.7483346, "_step": 107}
{"Episode reward": 63.21812603760928, "Episode length": 431, "Policy Loss": -1.3945093154907227, "Value Loss": 26.96595001220703, "_runtime": 821.6611921787262, "_timestamp": 1585595570.6778657, "_step": 108}
{"Episode reward": 44.143098486564206, "Episode length": 634, "Policy Loss": -0.0909256637096405, "Value Loss": 13.720088958740234, "_runtime": 822.1786828041077, "_timestamp": 1585595571.1953564, "_step": 109}
{"Episode reward": 71.96073810810427, "Episode length": 337, "Policy Loss": 0.24534712731838226, "Value Loss": 26.246065139770508, "_runtime": 823.1806147098541, "_timestamp": 1585595572.1972883, "_step": 110}
{"Episode reward": 40.60324740919263, "Episode length": 659, "Policy Loss": -0.46451741456985474, "Value Loss": 13.374964714050293, "_runtime": 824.2435309886932, "_timestamp": 1585595573.2602046, "_step": 111}
{"Episode reward": 35.585605336089586, "Episode length": 717, "Policy Loss": -0.5458555817604065, "Value Loss": 12.259756088256836, "_runtime": 824.944503068924, "_timestamp": 1585595573.9611766, "_step": 112}
{"Episode reward": 56.61843528071866, "Episode length": 472, "Policy Loss": -0.2246694415807724, "Value Loss": 18.336509704589844, "_runtime": 826.1147685050964, "_timestamp": 1585595575.131442, "_step": 113}
{"Episode reward": 29.442533922473814, "Episode length": 786, "Policy Loss": -1.253078579902649, "Value Loss": 12.18509292602539, "_runtime": 826.8903057575226, "_timestamp": 1585595575.9069793, "_step": 114}
{"Episode reward": 55.84712173544942, "Episode length": 514, "Policy Loss": -1.3970396518707275, "Value Loss": 16.890413284301758, "_runtime": 827.4078226089478, "_timestamp": 1585595576.4244962, "_step": 115}
{"Episode reward": 71.27131298900314, "Episode length": 342, "Policy Loss": -1.1909087896347046, "Value Loss": 23.724790573120117, "_runtime": 828.1283130645752, "_timestamp": 1585595577.1449866, "_step": 116}
{"Episode reward": 57.957690873909925, "Episode length": 481, "Policy Loss": -0.6253246068954468, "Value Loss": 16.211183547973633, "_runtime": 828.774347782135, "_timestamp": 1585595577.7910213, "_step": 117}
{"Episode reward": 63.93986915205778, "Episode length": 432, "Policy Loss": -2.1602399349212646, "Value Loss": 24.210664749145508, "_runtime": 829.620169878006, "_timestamp": 1585595578.6368434, "_step": 118}
{"Episode reward": 49.85261443698314, "Episode length": 582, "Policy Loss": -0.31332895159721375, "Value Loss": 14.895110130310059, "_runtime": 830.5427148342133, "_timestamp": 1585595579.5593884, "_step": 119}
{"Episode reward": 45.5922483219466, "Episode length": 624, "Policy Loss": -0.05524637922644615, "Value Loss": 13.169626235961914, "_runtime": 831.0639793872833, "_timestamp": 1585595580.080653, "_step": 120}
{"Episode reward": 70.71782364595572, "Episode length": 354, "Policy Loss": 0.8129473328590393, "Value Loss": 23.103538513183594, "_runtime": 831.9931719303131, "_timestamp": 1585595581.0098455, "_step": 121}
{"Episode reward": 47.962629471823156, "Episode length": 634, "Policy Loss": 0.473114937543869, "Value Loss": 14.097736358642578, "_runtime": 832.435745716095, "_timestamp": 1585595581.4524193, "_step": 122}
{"Episode reward": 75.99740904212402, "Episode length": 283, "Policy Loss": 0.9052566289901733, "Value Loss": 31.373435974121094, "_runtime": 833.1672308444977, "_timestamp": 1585595582.1839044, "_step": 123}
{"Episode reward": 57.1883722465145, "Episode length": 505, "Policy Loss": 0.5150302648544312, "Value Loss": 17.017274856567383, "_runtime": 834.2324867248535, "_timestamp": 1585595583.2491603, "_step": 124}
{"Episode reward": 36.79732756450027, "Episode length": 718, "Policy Loss": 0.0392780639231205, "Value Loss": 11.122283935546875, "_runtime": 835.0153286457062, "_timestamp": 1585595584.0320022, "_step": 125}
{"Episode reward": 53.93216807242839, "Episode length": 536, "Policy Loss": -0.25211089849472046, "Value Loss": 15.966780662536621, "_runtime": 835.8762400150299, "_timestamp": 1585595584.8929136, "_step": 126}
{"Episode reward": 50.50258806631282, "Episode length": 582, "Policy Loss": -0.22983799874782562, "Value Loss": 15.34072494506836, "_runtime": 836.5468378067017, "_timestamp": 1585595585.5635114, "_step": 127}
{"Episode reward": 63.04745636688588, "Episode length": 448, "Policy Loss": -0.14812050759792328, "Value Loss": 18.195680618286133, "_runtime": 837.0772459506989, "_timestamp": 1585595586.0939195, "_step": 128}
{"Episode reward": 69.80945244740629, "Episode length": 351, "Policy Loss": 0.014500292018055916, "Value Loss": 24.711793899536133, "_runtime": 837.8635168075562, "_timestamp": 1585595586.8801904, "_step": 129}
{"Episode reward": 54.73644227520772, "Episode length": 533, "Policy Loss": -0.10558601468801498, "Value Loss": 13.183311462402344, "_runtime": 839.0095756053925, "_timestamp": 1585595588.0262492, "_step": 130}
{"Episode reward": 35.492243998980015, "Episode length": 779, "Policy Loss": -0.17063866555690765, "Value Loss": 10.632688522338867, "_runtime": 839.5417659282684, "_timestamp": 1585595588.5584395, "_step": 131}
{"Episode reward": 68.95439316551072, "Episode length": 357, "Policy Loss": 0.05799299478530884, "Value Loss": 19.385997772216797, "_runtime": 840.7528419494629, "_timestamp": 1585595589.7695155, "_step": 132}
{"Episode reward": 30.114705670227096, "Episode length": 827, "Policy Loss": -0.2897558808326721, "Value Loss": 9.500542640686035, "_runtime": 841.6412856578827, "_timestamp": 1585595590.6579592, "_step": 133}
{"Episode reward": 47.8129919765951, "Episode length": 585, "Policy Loss": -0.26102614402770996, "Value Loss": 12.22414779663086, "_runtime": 842.6664230823517, "_timestamp": 1585595591.6830966, "_step": 134}
{"Episode reward": 39.092450866395296, "Episode length": 699, "Policy Loss": -0.32558125257492065, "Value Loss": 11.55370044708252, "_runtime": 843.9764778614044, "_timestamp": 1585595592.9931514, "_step": 135}
{"Episode reward": 21.43624631866679, "Episode length": 878, "Policy Loss": -0.35954803228378296, "Value Loss": 10.502734184265137, "_runtime": 845.0602016448975, "_timestamp": 1585595594.0768752, "_step": 136}
{"Episode reward": 36.03620495877647, "Episode length": 729, "Policy Loss": -0.42427873611450195, "Value Loss": 11.616815567016602, "_runtime": 845.929826259613, "_timestamp": 1585595594.9464998, "_step": 137}
{"Episode reward": 50.577386740292, "Episode length": 577, "Policy Loss": -0.3204938471317291, "Value Loss": 15.939437866210938, "_runtime": 846.4160273075104, "_timestamp": 1585595595.4327009, "_step": 138}
{"Episode reward": 74.82990719507269, "Episode length": 302, "Policy Loss": -1.4484999179840088, "Value Loss": 29.22402000427246, "_runtime": 847.8968904018402, "_timestamp": 1585595596.913564, "_step": 139}
{"Episode reward": 17.62931360687152, "Episode length": 994, "Policy Loss": -0.7164962291717529, "Value Loss": 8.080330848693848, "_runtime": 848.7013041973114, "_timestamp": 1585595597.7179778, "_step": 140}
{"Episode reward": 54.301426737671775, "Episode length": 534, "Policy Loss": -0.46009698510169983, "Value Loss": 14.367110252380371, "_runtime": 849.6257684230804, "_timestamp": 1585595598.642442, "_step": 141}
{"Episode reward": 49.24745234305226, "Episode length": 607, "Policy Loss": -0.14795154333114624, "Value Loss": 11.400413513183594, "_runtime": 850.1945147514343, "_timestamp": 1585595599.2111883, "_step": 142}
{"Episode reward": 70.5297852312254, "Episode length": 358, "Policy Loss": 0.037688959389925, "Value Loss": 23.797706604003906, "_runtime": 851.6770665645599, "_timestamp": 1585595600.6937401, "_step": 143}
{"Episode reward": -81.95195722200022, "Episode length": 999, "Policy Loss": -0.6717061400413513, "Value Loss": 0.04953104630112648, "_runtime": 852.2202141284943, "_timestamp": 1585595601.2368877, "_step": 144}
{"Episode reward": 69.09825362190719, "Episode length": 361, "Policy Loss": 0.2648695707321167, "Value Loss": 26.96027946472168, "_runtime": 853.266419172287, "_timestamp": 1585595602.2830927, "_step": 145}
{"Episode reward": 38.7397429019155, "Episode length": 721, "Policy Loss": -0.3960602283477783, "Value Loss": 11.361770629882812, "_runtime": 854.5893239974976, "_timestamp": 1585595603.6059976, "_step": 146}
{"Episode reward": 20.01658751089566, "Episode length": 878, "Policy Loss": -0.7187403440475464, "Value Loss": 9.307632446289062, "_runtime": 855.8030159473419, "_timestamp": 1585595604.8196895, "_step": 147}
{"Episode reward": 27.209478086975196, "Episode length": 828, "Policy Loss": -0.6633152365684509, "Value Loss": 11.214207649230957, "_runtime": 856.5438675880432, "_timestamp": 1585595605.5605412, "_step": 148}
{"Episode reward": 57.47481188343641, "Episode length": 489, "Policy Loss": -0.6059300899505615, "Value Loss": 15.962160110473633, "_runtime": 857.8102185726166, "_timestamp": 1585595606.8268921, "_step": 149}
{"Episode reward": 23.267094583937947, "Episode length": 838, "Policy Loss": -0.5826343297958374, "Value Loss": 8.51383113861084, "_runtime": 858.8215312957764, "_timestamp": 1585595607.8382049, "_step": 150}
{"Episode reward": 41.86568024662757, "Episode length": 669, "Policy Loss": -0.19992920756340027, "Value Loss": 13.962569236755371, "_runtime": 859.6846489906311, "_timestamp": 1585595608.7013226, "_step": 151}
{"Episode reward": 49.56444529308798, "Episode length": 580, "Policy Loss": 0.08320643752813339, "Value Loss": 16.210248947143555, "_runtime": 860.9157836437225, "_timestamp": 1585595609.9324572, "_step": 152}
{"Episode reward": 29.339656525444866, "Episode length": 816, "Policy Loss": -0.3104723393917084, "Value Loss": 8.407962799072266, "_runtime": 861.8830759525299, "_timestamp": 1585595610.8997495, "_step": 153}
{"Episode reward": 45.0896936202392, "Episode length": 647, "Policy Loss": -0.07697102427482605, "Value Loss": 13.413588523864746, "_runtime": 862.3957097530365, "_timestamp": 1585595611.4123833, "_step": 154}
{"Episode reward": 71.6882419994857, "Episode length": 335, "Policy Loss": -0.025731641799211502, "Value Loss": 20.68240737915039, "_runtime": 863.8224987983704, "_timestamp": 1585595612.8391724, "_step": 155}
{"Episode reward": 13.330645227459485, "Episode length": 961, "Policy Loss": -0.7000675201416016, "Value Loss": 7.567875862121582, "_runtime": 865.3066160678864, "_timestamp": 1585595614.3232896, "_step": 156}
{"Episode reward": -84.7318478772795, "Episode length": 999, "Policy Loss": -0.706450343132019, "Value Loss": 0.43642738461494446, "_runtime": 866.2000246047974, "_timestamp": 1585595615.2166982, "_step": 157}
{"Episode reward": 48.80558288090466, "Episode length": 609, "Policy Loss": -0.24683959782123566, "Value Loss": 10.624267578125, "_runtime": 866.7650756835938, "_timestamp": 1585595615.7817492, "_step": 158}
{"Episode reward": 70.13552191086666, "Episode length": 354, "Policy Loss": 0.6330872178077698, "Value Loss": 22.07544708251953, "_runtime": 867.7321403026581, "_timestamp": 1585595616.7488139, "_step": 159}
{"Episode reward": 48.19742004392728, "Episode length": 639, "Policy Loss": -0.13557089865207672, "Value Loss": 12.351751327514648, "_runtime": 868.3481142520905, "_timestamp": 1585595617.3647878, "_step": 160}
{"Episode reward": 66.22825263431541, "Episode length": 407, "Policy Loss": -0.09761445969343185, "Value Loss": 20.574573516845703, "_runtime": 869.1935551166534, "_timestamp": 1585595618.2102287, "_step": 161}
{"Episode reward": 49.053862929660234, "Episode length": 586, "Policy Loss": -0.6529200673103333, "Value Loss": 16.003828048706055, "_runtime": 869.6366922855377, "_timestamp": 1585595618.6533659, "_step": 162}
{"Episode reward": 75.83095082905604, "Episode length": 282, "Policy Loss": 0.23245269060134888, "Value Loss": 21.99439811706543, "_runtime": 870.9341108798981, "_timestamp": 1585595619.9507844, "_step": 163}
{"Episode reward": 24.666636590797694, "Episode length": 890, "Policy Loss": -0.29967424273490906, "Value Loss": 6.65361213684082, "_runtime": 871.7062036991119, "_timestamp": 1585595620.7228773, "_step": 164}
{"Episode reward": 53.48191641292752, "Episode length": 516, "Policy Loss": -0.46770039200782776, "Value Loss": 11.258768081665039, "_runtime": 873.0003955364227, "_timestamp": 1585595622.017069, "_step": 165}
{"Episode reward": 19.195308015718282, "Episode length": 897, "Policy Loss": -0.5377635359764099, "Value Loss": 7.814002990722656, "_runtime": 873.6752002239227, "_timestamp": 1585595622.6918738, "_step": 166}
{"Episode reward": 64.28033869831496, "Episode length": 435, "Policy Loss": -0.7374787926673889, "Value Loss": 20.45524024963379, "_runtime": 874.1986153125763, "_timestamp": 1585595623.2152889, "_step": 167}
{"Episode reward": 70.46709898530958, "Episode length": 352, "Policy Loss": 0.03598267212510109, "Value Loss": 23.05976104736328, "_runtime": 874.8514556884766, "_timestamp": 1585595623.8681293, "_step": 168}
{"Episode reward": 63.450540662169196, "Episode length": 433, "Policy Loss": -0.0536591112613678, "Value Loss": 17.479568481445312, "_runtime": 875.488579750061, "_timestamp": 1585595624.5052533, "_step": 169}
{"Episode reward": 64.34700393129324, "Episode length": 430, "Policy Loss": 0.14533638954162598, "Value Loss": 18.755596160888672, "_runtime": 876.0025346279144, "_timestamp": 1585595625.0192082, "_step": 170}
{"Episode reward": 70.82384395969667, "Episode length": 347, "Policy Loss": 0.34208378195762634, "Value Loss": 19.314777374267578, "_runtime": 877.4627711772919, "_timestamp": 1585595626.4794447, "_step": 171}
{"Episode reward": -84.77511285902082, "Episode length": 999, "Policy Loss": -0.7202652096748352, "Value Loss": 0.060690220445394516, "_runtime": 878.3402962684631, "_timestamp": 1585595627.3569698, "_step": 172}
{"Episode reward": 51.56642767809042, "Episode length": 592, "Policy Loss": -3.315995454788208, "Value Loss": 45.566261291503906, "_runtime": 879.8368377685547, "_timestamp": 1585595628.8535113, "_step": 173}
{"Episode reward": -89.84694200341221, "Episode length": 999, "Policy Loss": -0.576650857925415, "Value Loss": 0.0445052869617939, "_runtime": 881.3476526737213, "_timestamp": 1585595630.3643262, "_step": 174}
{"Episode reward": -85.06851156896269, "Episode length": 999, "Policy Loss": 0.0779852569103241, "Value Loss": 0.2778570353984833, "_runtime": 881.9013438224792, "_timestamp": 1585595630.9180174, "_step": 175}
{"Episode reward": 69.58428754037723, "Episode length": 360, "Policy Loss": 1.1635537147521973, "Value Loss": 28.900732040405273, "_runtime": 882.6546931266785, "_timestamp": 1585595631.6713667, "_step": 176}
{"Episode reward": 58.31646282707555, "Episode length": 495, "Policy Loss": 0.8545630574226379, "Value Loss": 20.972667694091797, "_runtime": 884.1704323291779, "_timestamp": 1585595633.187106, "_step": 177}
{"Episode reward": -84.04950060450138, "Episode length": 999, "Policy Loss": 0.15184184908866882, "Value Loss": 0.2650928795337677, "_runtime": 884.830995798111, "_timestamp": 1585595633.8476694, "_step": 178}
{"Episode reward": 62.49489698480964, "Episode length": 445, "Policy Loss": 0.9937390089035034, "Value Loss": 23.070402145385742, "_runtime": 885.9148228168488, "_timestamp": 1585595634.9314964, "_step": 179}
{"Episode reward": 34.78693088151526, "Episode length": 741, "Policy Loss": 0.050979867577552795, "Value Loss": 13.699867248535156, "_runtime": 886.9354784488678, "_timestamp": 1585595635.952152, "_step": 180}
{"Episode reward": 41.46113977077181, "Episode length": 674, "Policy Loss": 0.26423633098602295, "Value Loss": 14.970833778381348, "_runtime": 888.4038066864014, "_timestamp": 1585595637.4204803, "_step": 181}
{"Episode reward": -83.0882784566961, "Episode length": 999, "Policy Loss": -0.1909063756465912, "Value Loss": 0.14573942124843597, "_runtime": 889.254504442215, "_timestamp": 1585595638.271178, "_step": 182}
{"Episode reward": 52.201673593678024, "Episode length": 563, "Policy Loss": 0.3099406361579895, "Value Loss": 17.719074249267578, "_runtime": 889.7825589179993, "_timestamp": 1585595638.7992325, "_step": 183}
{"Episode reward": 72.03115673360536, "Episode length": 341, "Policy Loss": 0.31305888295173645, "Value Loss": 29.175580978393555, "_runtime": 890.2072706222534, "_timestamp": 1585595639.2239442, "_step": 184}
{"Episode reward": 77.49669903715997, "Episode length": 266, "Policy Loss": 0.675609290599823, "Value Loss": 37.16096496582031, "_runtime": 891.4431393146515, "_timestamp": 1585595640.4598129, "_step": 185}
{"Episode reward": 27.68800739845426, "Episode length": 841, "Policy Loss": -0.2537737190723419, "Value Loss": 11.88824462890625, "_runtime": 892.9159271717072, "_timestamp": 1585595641.9326007, "_step": 186}
{"Episode reward": -87.30946845012885, "Episode length": 999, "Policy Loss": -0.615729033946991, "Value Loss": 0.31385335326194763, "_runtime": 894.3844652175903, "_timestamp": 1585595643.4011388, "_step": 187}
{"Episode reward": -84.70834610462465, "Episode length": 999, "Policy Loss": -0.8877739310264587, "Value Loss": 0.43716859817504883, "_runtime": 895.1955466270447, "_timestamp": 1585595644.2122202, "_step": 188}
{"Episode reward": 54.99238521589104, "Episode length": 527, "Policy Loss": 0.04068424180150032, "Value Loss": 18.850088119506836, "_runtime": 896.4071898460388, "_timestamp": 1585595645.4238634, "_step": 189}
{"Episode reward": 30.091125982197127, "Episode length": 807, "Policy Loss": -0.2688182592391968, "Value Loss": 12.36767292022705, "_runtime": 897.1624186038971, "_timestamp": 1585595646.1790922, "_step": 190}
{"Episode reward": 57.04035723310959, "Episode length": 489, "Policy Loss": 0.11395341157913208, "Value Loss": 20.45729637145996, "_runtime": 898.1425681114197, "_timestamp": 1585595647.1592417, "_step": 191}
{"Episode reward": 45.78687499075122, "Episode length": 657, "Policy Loss": -0.032260533422231674, "Value Loss": 15.187670707702637, "_runtime": 899.650351524353, "_timestamp": 1585595648.667025, "_step": 192}
{"Episode reward": -86.19162012022974, "Episode length": 999, "Policy Loss": -0.9891843795776367, "Value Loss": 0.5012633204460144, "_runtime": 900.3392503261566, "_timestamp": 1585595649.355924, "_step": 193}
{"Episode reward": 61.47582402800432, "Episode length": 459, "Policy Loss": 0.06156953051686287, "Value Loss": 21.521989822387695, "_runtime": 900.894380569458, "_timestamp": 1585595649.9110541, "_step": 194}
{"Episode reward": 69.62666750183567, "Episode length": 361, "Policy Loss": -0.13608330488204956, "Value Loss": 27.377323150634766, "_runtime": 901.6811339855194, "_timestamp": 1585595650.6978076, "_step": 195}
{"Episode reward": 55.32074817083849, "Episode length": 518, "Policy Loss": -0.031199201941490173, "Value Loss": 19.092628479003906, "_runtime": 903.1354353427887, "_timestamp": 1585595652.152109, "_step": 196}
{"Episode reward": 13.138714443049096, "Episode length": 989, "Policy Loss": -0.32502779364585876, "Value Loss": 10.055344581604004, "_runtime": 904.4534196853638, "_timestamp": 1585595653.4700933, "_step": 197}
{"Episode reward": 25.996630899176907, "Episode length": 877, "Policy Loss": -0.22886069118976593, "Value Loss": 11.346817970275879, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709, 5.129514217376709]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [26.338693618774414, 26.724462509155273, 27.1102294921875, 27.49599838256836, 27.881765365600586, 28.267534255981445, 28.653301239013672, 29.03907012939453, 29.42483901977539, 29.810606002807617, 30.196374893188477, 30.582141876220703, 30.967910766601562, 31.353679656982422, 31.73944664001465, 32.125213623046875, 32.510982513427734, 32.896751403808594, 33.28252029418945, 33.66828918457031, 34.054054260253906, 34.439823150634766, 34.825592041015625, 35.211360931396484, 35.597129821777344, 35.98289489746094, 36.3686637878418, 36.754432678222656, 37.14019775390625, 37.525970458984375, 37.91173553466797, 38.29750442504883, 38.68327331542969, 39.06903839111328, 39.45480728149414, 39.840576171875, 40.22634506225586, 40.61211395263672, 40.99787902832031, 41.38364791870117, 41.76941680908203, 42.15518569946289, 42.54095458984375, 42.926719665527344, 43.3124885559082, 43.69825744628906, 44.08402633666992, 44.46979522705078, 44.855560302734375, 45.241329193115234, 45.627098083496094, 46.01286315917969, 46.39863586425781, 46.784400939941406, 47.170169830322266, 47.555938720703125, 47.94170379638672, 48.327476501464844, 48.71324157714844, 49.0990104675293, 49.484779357910156, 49.87054443359375, 50.256317138671875, 50.64208221435547, 51.02785110473633]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-1.3338119983673096, -1.2673990726470947, -1.2009861469268799, -1.134573221206665, -1.0681602954864502, -1.0017473697662354, -0.935334324836731, -0.8689213991165161, -0.8025084733963013, -0.7360955476760864, -0.6696826219558716, -0.603269636631012, -0.5368567109107971, -0.4704437851905823, -0.40403079986572266, -0.3376178741455078, -0.27120494842529297, -0.20479202270507812, -0.13837909698486328, -0.07196617126464844, -0.005553245544433594, 0.0608597993850708, 0.12727272510528564, 0.1936856508255005, 0.26009857654571533, 0.3265115022659302, 0.392924427986145, 0.45933735370635986, 0.5257503986358643, 0.5921633243560791, 0.658576250076294, 0.7249891757965088, 0.7914021015167236, 0.8578150272369385, 0.9242279529571533, 0.9906408786773682, 1.057053804397583, 1.1234667301177979, 1.1898796558380127, 1.2562925815582275, 1.3227055072784424, 1.3891186714172363, 1.4555315971374512, 1.521944522857666, 1.5883574485778809, 1.6547703742980957, 1.7211833000183105, 1.7875962257385254, 1.8540091514587402, 1.920422077178955, 1.98683500289917, 2.0532479286193848, 2.1196608543395996, 2.1860737800598145, 2.2524867057800293, 2.318899631500244, 2.385312795639038, 2.451725721359253, 2.5181386470794678, 2.5845515727996826, 2.6509644985198975, 2.7173774242401123, 2.783790349960327, 2.850203275680542, 2.916616201400757]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 2.0, 8.0, 7.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 5.0, 5.0, 2.0, 6.0, 4.0, 9.0, 14.0, 14.0, 35.0, 26.0, 22.0, 61.0, 81.0, 16.0, 20.0, 24.0, 16.0, 18.0, 14.0, 4.0, 5.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 3.0, 2.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.855889320373535, -2.750744342803955, -2.645599603652954, -2.540454626083374, -2.435309886932373, -2.330164909362793, -2.225019931793213, -2.119875192642212, -2.014730453491211, -1.9095854759216309, -1.8044406175613403, -1.6992957592010498, -1.5941507816314697, -1.4890059232711792, -1.3838610649108887, -1.2787162065505981, -1.1735713481903076, -1.068426489830017, -0.9632816314697266, -0.858136773109436, -0.7529919147491455, -0.6478469371795654, -0.5427021980285645, -0.4375572204589844, -0.3324122428894043, -0.22726750373840332, -0.12212252616882324, -0.016977787017822266, 0.08816719055175781, 0.1933119297027588, 0.29845690727233887, 0.40360164642333984, 0.5087466239929199, 0.6138916015625, 0.719036340713501, 0.824181318283081, 0.929326057434082, 1.034471035003662, 1.139615774154663, 1.244760513305664, 1.3499054908752441, 1.4550504684448242, 1.5601954460144043, 1.6653404235839844, 1.7704849243164062, 1.8756299018859863, 1.9807748794555664, 2.0859198570251465, 2.1910648345947266, 2.2962093353271484, 2.4013543128967285, 2.5064992904663086, 2.6116442680358887, 2.7167887687683105, 2.8219337463378906, 2.9270787239074707, 3.032223701477051, 3.137368679046631, 3.2425131797790527, 3.347658157348633, 3.452803134918213, 3.557948112487793, 3.663092613220215, 3.768237590789795, 3.873382568359375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-10.40921688079834, -9.995495796203613, -9.58177375793457, -9.168052673339844, -8.7543306350708, -8.340609550476074, -7.9268879890441895, -7.513166427612305, -7.09944486618042, -6.685723304748535, -6.27200174331665, -5.858280181884766, -5.444559097290039, -5.030837535858154, -4.6171159744262695, -4.203394412994385, -3.7896728515625, -3.3759512901306152, -2.9622297286987305, -2.5485081672668457, -2.134786605834961, -1.7210655212402344, -1.3073434829711914, -0.8936223983764648, -0.4799013137817383, -0.06617927551269531, 0.34754180908203125, 0.7612638473510742, 1.1749849319458008, 1.5887069702148438, 2.0024280548095703, 2.4161500930786133, 2.82987117767334, 3.2435922622680664, 3.6573143005371094, 4.071035385131836, 4.484757423400879, 4.8984785079956055, 5.312200546264648, 5.725922584533691, 6.139643669128418, 6.5533647537231445, 6.967085838317871, 7.380806922912598, 7.794529914855957, 8.208250999450684, 8.62197208404541, 9.035693168640137, 9.449414253234863, 9.863137245178223, 10.27685832977295, 10.690579414367676, 11.104300498962402, 11.518023490905762, 11.931744575500488, 12.345465660095215, 12.759186744689941, 13.172907829284668, 13.586630821228027, 14.000351905822754, 14.41407299041748, 14.827794075012207, 15.241517066955566, 15.655238151550293, 16.068958282470703]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 19.0, 9.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-16.564905166625977, -16.073965072631836, -15.583023071289062, -15.092082023620605, -14.601140975952148, -14.110199928283691, -13.619258880615234, -13.128318786621094, -12.63737678527832, -12.14643669128418, -11.655494689941406, -11.164554595947266, -10.673613548278809, -10.182672500610352, -9.691731452941895, -9.200790405273438, -8.70984935760498, -8.218908309936523, -7.727967262268066, -7.237026214599609, -6.746085166931152, -6.255144119262695, -5.764203071594238, -5.273262023925781, -4.782321929931641, -4.291380882263184, -3.8004398345947266, -3.3094987869262695, -2.8185577392578125, -2.3276166915893555, -1.8366756439208984, -1.3457345962524414, -0.8547935485839844, -0.36385345458984375, 0.1270885467529297, 0.6180286407470703, 1.1089706420898438, 1.5999107360839844, 2.090852737426758, 2.5817928314208984, 3.072734832763672, 3.5636749267578125, 4.054616928100586, 4.545557022094727, 5.0364990234375, 5.527439117431641, 6.018381118774414, 6.509321212768555, 7.000261306762695, 7.491203308105469, 7.982143402099609, 8.473085403442383, 8.964025497436523, 9.454967498779297, 9.945907592773438, 10.436849594116211, 10.927789688110352, 11.418731689453125, 11.909671783447266, 12.400613784790039, 12.89155387878418, 13.382495880126953, 13.873435974121094, 14.364377975463867, 14.855318069458008]}, "_runtime": 905.0100047588348, "_timestamp": 1585595654.0266783, "_step": 198}
{"Episode reward": 70.0390193282944, "Episode length": 366, "Policy Loss": -0.018368437886238098, "Value Loss": 27.0341854095459, "_runtime": 906.5120177268982, "_timestamp": 1585595655.5286913, "_step": 199}
{"Episode reward": -92.3118747858198, "Episode length": 999, "Policy Loss": -0.614237904548645, "Value Loss": 0.03535968065261841, "_runtime": 907.6972343921661, "_timestamp": 1585595656.713908, "_step": 200}
{"Episode reward": 28.420091833027726, "Episode length": 791, "Policy Loss": -0.06013662368059158, "Value Loss": 12.52604866027832, "_runtime": 908.2202894687653, "_timestamp": 1585595657.236963, "_step": 201}
{"Episode reward": 69.68008905304802, "Episode length": 347, "Policy Loss": 0.20290838181972504, "Value Loss": 28.499853134155273, "_runtime": 909.0592889785767, "_timestamp": 1585595658.0759625, "_step": 202}
{"Episode reward": 50.53299703295337, "Episode length": 554, "Policy Loss": -0.08898864686489105, "Value Loss": 17.863197326660156, "_runtime": 910.5633175373077, "_timestamp": 1585595659.579991, "_step": 203}
{"Episode reward": -84.92807883011662, "Episode length": 999, "Policy Loss": -0.7581837773323059, "Value Loss": 0.08537346124649048, "_runtime": 911.2017042636871, "_timestamp": 1585595660.2183778, "_step": 204}
{"Episode reward": 63.16915988172434, "Episode length": 436, "Policy Loss": 0.35616326332092285, "Value Loss": 22.702625274658203, "_runtime": 911.730131149292, "_timestamp": 1585595660.7468047, "_step": 205}
{"Episode reward": 70.77271943689128, "Episode length": 349, "Policy Loss": 0.16941915452480316, "Value Loss": 28.338895797729492, "_runtime": 913.2317290306091, "_timestamp": 1585595662.2484026, "_step": 206}
{"Episode reward": -93.60934416842325, "Episode length": 999, "Policy Loss": -0.6185715794563293, "Value Loss": 0.036110781133174896, "_runtime": 914.3700933456421, "_timestamp": 1585595663.386767, "_step": 207}
{"Episode reward": 30.88874472942061, "Episode length": 773, "Policy Loss": 0.025266434997320175, "Value Loss": 12.816656112670898, "_runtime": 915.2388668060303, "_timestamp": 1585595664.2555404, "_step": 208}
{"Episode reward": 51.22713336485934, "Episode length": 597, "Policy Loss": -0.12224661558866501, "Value Loss": 16.545923233032227, "_runtime": 916.278350353241, "_timestamp": 1585595665.295024, "_step": 209}
{"Episode reward": 42.8053821632125, "Episode length": 683, "Policy Loss": -0.054628390818834305, "Value Loss": 14.472748756408691, "_runtime": 917.6705565452576, "_timestamp": 1585595666.68723, "_step": 210}
{"Episode reward": 24.4456522533156, "Episode length": 925, "Policy Loss": -0.26702573895454407, "Value Loss": 10.691740989685059, "_runtime": 918.9522171020508, "_timestamp": 1585595667.9688907, "_step": 211}
{"Episode reward": 24.97276617077374, "Episode length": 870, "Policy Loss": -0.24457420408725739, "Value Loss": 11.403834342956543, "_runtime": 919.7580707073212, "_timestamp": 1585595668.7747443, "_step": 212}
{"Episode reward": 56.32219410088889, "Episode length": 530, "Policy Loss": -0.030985044315457344, "Value Loss": 18.67759895324707, "_runtime": 920.3569550514221, "_timestamp": 1585595669.3736286, "_step": 213}
{"Episode reward": 68.26888079063025, "Episode length": 378, "Policy Loss": 0.019004980102181435, "Value Loss": 26.129552841186523, "_runtime": 921.5171508789062, "_timestamp": 1585595670.5338244, "_step": 214}
{"Episode reward": 30.183273885053524, "Episode length": 773, "Policy Loss": -0.2743006944656372, "Value Loss": 12.792166709899902, "_runtime": 921.9467375278473, "_timestamp": 1585595670.963411, "_step": 215}
{"Episode reward": 76.60720236269307, "Episode length": 273, "Policy Loss": 0.2186547815799713, "Value Loss": 35.946102142333984, "_runtime": 922.2556998729706, "_timestamp": 1585595671.2723734, "_step": 216}
{"Episode reward": 82.75961349497025, "Episode length": 205, "Policy Loss": 0.771826982498169, "Value Loss": 47.801414489746094, "_runtime": 922.9177689552307, "_timestamp": 1585595671.9344425, "_step": 217}
{"Episode reward": 61.39881445007688, "Episode length": 442, "Policy Loss": 0.19213415682315826, "Value Loss": 22.239717483520508, "_runtime": 923.6356291770935, "_timestamp": 1585595672.6523027, "_step": 218}
{"Episode reward": 57.95995757285315, "Episode length": 500, "Policy Loss": -0.07910275459289551, "Value Loss": 19.606101989746094, "_runtime": 924.2365365028381, "_timestamp": 1585595673.25321, "_step": 219}
{"Episode reward": 64.56438829183946, "Episode length": 415, "Policy Loss": 0.25632449984550476, "Value Loss": 23.55990982055664, "_runtime": 924.8689563274384, "_timestamp": 1585595673.88563, "_step": 220}
{"Episode reward": 64.34286192738386, "Episode length": 435, "Policy Loss": -0.29850396513938904, "Value Loss": 22.520166397094727, "_runtime": 925.4821388721466, "_timestamp": 1585595674.4988124, "_step": 221}
{"Episode reward": 63.71982834850473, "Episode length": 414, "Policy Loss": -0.1725086271762848, "Value Loss": 23.65013885498047, "_runtime": 926.3943722248077, "_timestamp": 1585595675.4110458, "_step": 222}
{"Episode reward": 43.639104234087185, "Episode length": 631, "Policy Loss": -0.05312759056687355, "Value Loss": 15.606033325195312, "_runtime": 927.452837228775, "_timestamp": 1585595676.4695108, "_step": 223}
{"Episode reward": 35.1044073937026, "Episode length": 721, "Policy Loss": -0.31689760088920593, "Value Loss": 13.596016883850098, "_runtime": 927.8572990894318, "_timestamp": 1585595676.8739727, "_step": 224}
{"Episode reward": 77.40991877000512, "Episode length": 264, "Policy Loss": 0.2085268646478653, "Value Loss": 36.84537887573242, "_runtime": 928.4791424274445, "_timestamp": 1585595677.495816, "_step": 225}
{"Episode reward": 64.37779999249896, "Episode length": 422, "Policy Loss": -0.5321204662322998, "Value Loss": 23.428577423095703, "_runtime": 929.2180263996124, "_timestamp": 1585595678.2347, "_step": 226}
{"Episode reward": 57.1984727752308, "Episode length": 490, "Policy Loss": 0.06059492379426956, "Value Loss": 20.202922821044922, "_runtime": 929.6202676296234, "_timestamp": 1585595678.6369412, "_step": 227}
{"Episode reward": 77.36361437362054, "Episode length": 269, "Policy Loss": 0.24707399308681488, "Value Loss": 36.13499069213867, "_runtime": 930.1315324306488, "_timestamp": 1585595679.148206, "_step": 228}
{"Episode reward": 70.88708219080704, "Episode length": 351, "Policy Loss": 0.136908620595932, "Value Loss": 27.818042755126953, "_runtime": 930.6266956329346, "_timestamp": 1585595679.6433692, "_step": 229}
{"Episode reward": 71.72057584068398, "Episode length": 335, "Policy Loss": 0.0229998417198658, "Value Loss": 28.97854232788086, "_runtime": 931.2564318180084, "_timestamp": 1585595680.2731054, "_step": 230}
{"Episode reward": 61.78472697725437, "Episode length": 442, "Policy Loss": -0.391876220703125, "Value Loss": 22.257699966430664, "_runtime": 932.1039011478424, "_timestamp": 1585595681.1205747, "_step": 231}
{"Episode reward": 49.57294773763098, "Episode length": 556, "Policy Loss": -0.32538896799087524, "Value Loss": 17.72397232055664, "_runtime": 932.4973402023315, "_timestamp": 1585595681.5140138, "_step": 232}
{"Episode reward": 77.70842925109477, "Episode length": 260, "Policy Loss": 0.3639039993286133, "Value Loss": 37.282901763916016, "_runtime": 932.7920365333557, "_timestamp": 1585595681.80871, "_step": 233}
{"Episode reward": 83.4474346514589, "Episode length": 195, "Policy Loss": 0.6042126417160034, "Value Loss": 49.573455810546875, "_runtime": 933.3277018070221, "_timestamp": 1585595682.3443754, "_step": 234}
{"Episode reward": 69.75375939967488, "Episode length": 364, "Policy Loss": -0.3759929835796356, "Value Loss": 26.844181060791016, "_runtime": 933.6952586174011, "_timestamp": 1585595682.7119322, "_step": 235}
{"Episode reward": 78.50380454226035, "Episode length": 253, "Policy Loss": 0.2940799593925476, "Value Loss": 38.18791198730469, "_runtime": 934.8578989505768, "_timestamp": 1585595683.8745725, "_step": 236}
{"Episode reward": 26.67894439726841, "Episode length": 813, "Policy Loss": -0.2690925896167755, "Value Loss": 11.991640090942383, "_runtime": 935.6244492530823, "_timestamp": 1585595684.6411228, "_step": 237}
{"Episode reward": 52.929595485857305, "Episode length": 521, "Policy Loss": -0.23195813596248627, "Value Loss": 18.731124877929688, "_runtime": 936.0161321163177, "_timestamp": 1585595685.0328057, "_step": 238}
{"Episode reward": 78.76347533551933, "Episode length": 263, "Policy Loss": 0.4611998200416565, "Value Loss": 36.83222198486328, "_runtime": 936.4509122371674, "_timestamp": 1585595685.4675858, "_step": 239}
{"Episode reward": 75.53309725892767, "Episode length": 282, "Policy Loss": 0.41416531801223755, "Value Loss": 34.57081985473633, "_runtime": 937.0214998722076, "_timestamp": 1585595686.0381734, "_step": 240}
{"Episode reward": 64.86037140337865, "Episode length": 390, "Policy Loss": 0.026878489181399345, "Value Loss": 24.695613861083984, "_runtime": 937.5713586807251, "_timestamp": 1585595686.5880322, "_step": 241}
{"Episode reward": 65.10556362512052, "Episode length": 384, "Policy Loss": -0.08714952319860458, "Value Loss": 25.123666763305664, "_runtime": 937.85111784935, "_timestamp": 1585595686.8677914, "_step": 242}
{"Episode reward": 83.55514617528544, "Episode length": 191, "Policy Loss": 0.6207588315010071, "Value Loss": 50.27549743652344, "_runtime": 938.341498374939, "_timestamp": 1585595687.358172, "_step": 243}
{"Episode reward": 70.16551963257143, "Episode length": 338, "Policy Loss": 0.02339509129524231, "Value Loss": 28.35129165649414, "_runtime": 939.0177707672119, "_timestamp": 1585595688.0344443, "_step": 244}
{"Episode reward": 57.751827674824945, "Episode length": 468, "Policy Loss": -0.049643922597169876, "Value Loss": 20.485782623291016, "_runtime": 939.397349357605, "_timestamp": 1585595688.414023, "_step": 245}
{"Episode reward": 77.03302507261043, "Episode length": 258, "Policy Loss": 0.3758552372455597, "Value Loss": 37.01647186279297, "_runtime": 939.9423174858093, "_timestamp": 1585595688.958991, "_step": 246}
{"Episode reward": 65.49499576298554, "Episode length": 381, "Policy Loss": 0.009109951555728912, "Value Loss": 25.02879524230957, "_runtime": 940.2164919376373, "_timestamp": 1585595689.2331655, "_step": 247}
{"Episode reward": 84.7135532502058, "Episode length": 178, "Policy Loss": 0.053426362574100494, "Value Loss": 53.394203186035156, "_runtime": 940.71009349823, "_timestamp": 1585595689.726767, "_step": 248}
{"Episode reward": 69.10504730748626, "Episode length": 346, "Policy Loss": 0.07239346206188202, "Value Loss": 27.39146614074707, "_runtime": 941.1906752586365, "_timestamp": 1585595690.2073488, "_step": 249}
{"Episode reward": 70.59619370131838, "Episode length": 331, "Policy Loss": -0.26231515407562256, "Value Loss": 29.017799377441406, "_runtime": 941.3598985671997, "_timestamp": 1585595690.3765721, "_step": 250}
{"Episode reward": 90.10503029997558, "Episode length": 112, "Policy Loss": 1.1767469644546509, "Value Loss": 85.32953643798828, "_runtime": 941.7340166568756, "_timestamp": 1585595690.7506902, "_step": 251}
{"Episode reward": 77.57086518425083, "Episode length": 257, "Policy Loss": 0.28435230255126953, "Value Loss": 36.7008056640625, "_runtime": 942.0014848709106, "_timestamp": 1585595691.0181584, "_step": 252}
{"Episode reward": 84.20476462782885, "Episode length": 180, "Policy Loss": 0.1449548751115799, "Value Loss": 52.5263786315918, "_runtime": 942.3516149520874, "_timestamp": 1585595691.3682885, "_step": 253}
{"Episode reward": 77.47140669778358, "Episode length": 248, "Policy Loss": 0.21831074357032776, "Value Loss": 37.76192855834961, "_runtime": 942.6629219055176, "_timestamp": 1585595691.6795955, "_step": 254}
{"Episode reward": 81.10322542973326, "Episode length": 213, "Policy Loss": 0.6826085448265076, "Value Loss": 43.67229080200195, "_runtime": 942.9314363002777, "_timestamp": 1585595691.9481099, "_step": 255}
{"Episode reward": 83.04827554840175, "Episode length": 188, "Policy Loss": 0.81486976146698, "Value Loss": 49.09765625, "_runtime": 943.0971531867981, "_timestamp": 1585595692.1138268, "_step": 256}
{"Episode reward": 90.30529658243124, "Episode length": 109, "Policy Loss": 1.4269899129867554, "Value Loss": 85.15943908691406, "_runtime": 943.5193574428558, "_timestamp": 1585595692.536031, "_step": 257}
{"Episode reward": 72.55959439158661, "Episode length": 297, "Policy Loss": -0.12170491367578506, "Value Loss": 31.250812530517578, "_runtime": 943.9596476554871, "_timestamp": 1585595692.9763212, "_step": 258}
{"Episode reward": 71.80029945624536, "Episode length": 311, "Policy Loss": -0.295854389667511, "Value Loss": 30.39811134338379, "_runtime": 944.5228385925293, "_timestamp": 1585595693.5395122, "_step": 259}
{"Episode reward": 62.37992089182999, "Episode length": 403, "Policy Loss": -0.2018885463476181, "Value Loss": 22.862091064453125, "_runtime": 944.7784175872803, "_timestamp": 1585595693.7950912, "_step": 260}
{"Episode reward": 84.19143743153448, "Episode length": 172, "Policy Loss": 0.05067465081810951, "Value Loss": 53.87833786010742, "_runtime": 945.1648457050323, "_timestamp": 1585595694.1815193, "_step": 261}
{"Episode reward": 75.1525699285355, "Episode length": 267, "Policy Loss": -0.02597718872129917, "Value Loss": 36.72167205810547, "_runtime": 945.4392430782318, "_timestamp": 1585595694.4559166, "_step": 262}
{"Episode reward": 83.39683050826162, "Episode length": 183, "Policy Loss": -1.768262505531311, "Value Loss": 54.58223342895508, "_runtime": 945.8613967895508, "_timestamp": 1585595694.8780704, "_step": 263}
{"Episode reward": 72.7517681522414, "Episode length": 299, "Policy Loss": -0.36375677585601807, "Value Loss": 31.57655143737793, "_runtime": 946.030029296875, "_timestamp": 1585595695.0467029, "_step": 264}
{"Episode reward": 90.12166732994602, "Episode length": 109, "Policy Loss": 2.848459243774414, "Value Loss": 86.45230102539062, "_runtime": 946.2899374961853, "_timestamp": 1585595695.306611, "_step": 265}
{"Episode reward": 83.7175368820606, "Episode length": 180, "Policy Loss": 3.473355531692505, "Value Loss": 52.56758499145508, "_runtime": 946.5477857589722, "_timestamp": 1585595695.5644593, "_step": 266}
{"Episode reward": 84.83566577265348, "Episode length": 174, "Policy Loss": 1.5477783679962158, "Value Loss": 53.259857177734375, "_runtime": 946.7171015739441, "_timestamp": 1585595695.7337751, "_step": 267}
{"Episode reward": 89.89648071923139, "Episode length": 116, "Policy Loss": 0.7593751549720764, "Value Loss": 81.45942687988281, "_runtime": 946.9778339862823, "_timestamp": 1585595695.9945076, "_step": 268}
{"Episode reward": 84.55364842605088, "Episode length": 181, "Policy Loss": 0.11804201453924179, "Value Loss": 50.571014404296875, "_runtime": 947.2474286556244, "_timestamp": 1585595696.2641022, "_step": 269}
{"Episode reward": 83.6880951948725, "Episode length": 189, "Policy Loss": -2.618494987487793, "Value Loss": 52.832950592041016, "_runtime": 947.5008342266083, "_timestamp": 1585595696.5175078, "_step": 270}
{"Episode reward": 84.3508217746044, "Episode length": 179, "Policy Loss": 0.14527878165245056, "Value Loss": 49.57887268066406, "_runtime": 947.7667968273163, "_timestamp": 1585595696.7834704, "_step": 271}
{"Episode reward": 84.23302362498866, "Episode length": 185, "Policy Loss": -0.5748703479766846, "Value Loss": 49.41911315917969, "_runtime": 948.0269606113434, "_timestamp": 1585595697.0436342, "_step": 272}
{"Episode reward": 83.85894487955986, "Episode length": 182, "Policy Loss": 0.185642808675766, "Value Loss": 48.721214294433594, "_runtime": 948.2876577377319, "_timestamp": 1585595697.3043313, "_step": 273}
{"Episode reward": 84.361142846152, "Episode length": 183, "Policy Loss": 0.7257211208343506, "Value Loss": 49.07548904418945, "_runtime": 948.465048789978, "_timestamp": 1585595697.4817224, "_step": 274}
{"Episode reward": 89.71158927918927, "Episode length": 119, "Policy Loss": 1.6929054260253906, "Value Loss": 76.55262756347656, "_runtime": 948.9393391609192, "_timestamp": 1585595697.9560127, "_step": 275}
{"Episode reward": 70.57770382769314, "Episode length": 336, "Policy Loss": -0.23242413997650146, "Value Loss": 27.08639144897461, "_runtime": 949.3634307384491, "_timestamp": 1585595698.3801043, "_step": 276}
{"Episode reward": 73.10324131820752, "Episode length": 300, "Policy Loss": 0.2860422730445862, "Value Loss": 30.08757781982422, "_runtime": 949.6285526752472, "_timestamp": 1585595698.6452262, "_step": 277}
{"Episode reward": 83.92418135893595, "Episode length": 187, "Policy Loss": 0.341445654630661, "Value Loss": 47.67299270629883, "_runtime": 950.4691298007965, "_timestamp": 1585595699.4858034, "_step": 278}
{"Episode reward": 47.369006062550135, "Episode length": 587, "Policy Loss": -0.787705659866333, "Value Loss": 15.880521774291992, "_runtime": 950.8608884811401, "_timestamp": 1585595699.877562, "_step": 279}
{"Episode reward": 76.88816044651566, "Episode length": 263, "Policy Loss": -0.6855016946792603, "Value Loss": 36.220279693603516, "_runtime": 951.1269252300262, "_timestamp": 1585595700.1435988, "_step": 280}
{"Episode reward": 83.88994799234933, "Episode length": 183, "Policy Loss": 0.20401346683502197, "Value Loss": 51.213233947753906, "_runtime": 951.9063711166382, "_timestamp": 1585595700.9230447, "_step": 281}
{"Episode reward": 50.760465101582746, "Episode length": 534, "Policy Loss": -0.5853880643844604, "Value Loss": 16.954727172851562, "_runtime": 952.2956771850586, "_timestamp": 1585595701.3123507, "_step": 282}
{"Episode reward": 76.53571422075112, "Episode length": 263, "Policy Loss": 0.0320172943174839, "Value Loss": 33.34584045410156, "_runtime": 952.5612065792084, "_timestamp": 1585595701.5778801, "_step": 283}
{"Episode reward": 83.35911666004445, "Episode length": 183, "Policy Loss": 0.6384952068328857, "Value Loss": 48.625667572021484, "_runtime": 953.0293459892273, "_timestamp": 1585595702.0460196, "_step": 284}
{"Episode reward": 70.87696878021889, "Episode length": 317, "Policy Loss": -0.18213289976119995, "Value Loss": 27.637027740478516, "_runtime": 953.6239485740662, "_timestamp": 1585595702.6406221, "_step": 285}
{"Episode reward": 61.205540150637866, "Episode length": 418, "Policy Loss": -0.5927030444145203, "Value Loss": 21.585323333740234, "_runtime": 953.8879923820496, "_timestamp": 1585595702.904666, "_step": 286}
{"Episode reward": 83.38495726459786, "Episode length": 183, "Policy Loss": -0.34592288732528687, "Value Loss": 47.86247634887695, "_runtime": 954.1492421627045, "_timestamp": 1585595703.1659157, "_step": 287}
{"Episode reward": 83.90016776056387, "Episode length": 172, "Policy Loss": 0.2628991901874542, "Value Loss": 49.60679244995117, "_runtime": 954.3321115970612, "_timestamp": 1585595703.3487852, "_step": 288}
{"Episode reward": 89.9526928365742, "Episode length": 108, "Policy Loss": 0.2832300364971161, "Value Loss": 82.20343017578125, "_runtime": 954.4998359680176, "_timestamp": 1585595703.5165095, "_step": 289}
{"Episode reward": 90.05764774595168, "Episode length": 109, "Policy Loss": 1.1704059839248657, "Value Loss": 79.62735748291016, "_runtime": 954.7627463340759, "_timestamp": 1585595703.77942, "_step": 290}
{"Episode reward": 83.09514724757902, "Episode length": 183, "Policy Loss": 0.06064755842089653, "Value Loss": 45.95147705078125, "_runtime": 954.9133598804474, "_timestamp": 1585595703.9300334, "_step": 291}
{"Episode reward": 90.14001998185266, "Episode length": 103, "Policy Loss": 1.2017738819122314, "Value Loss": 78.85507202148438, "_runtime": 955.0748827457428, "_timestamp": 1585595704.0915563, "_step": 292}
{"Episode reward": 89.5168219691256, "Episode length": 111, "Policy Loss": 1.1625984907150269, "Value Loss": 72.0385971069336, "_runtime": 955.2472548484802, "_timestamp": 1585595704.2639284, "_step": 293}
{"Episode reward": 88.9569683705818, "Episode length": 116, "Policy Loss": 0.9950209856033325, "Value Loss": 73.81306457519531, "_runtime": 955.4095940589905, "_timestamp": 1585595704.4262676, "_step": 294}
{"Episode reward": 89.67108640673112, "Episode length": 111, "Policy Loss": 0.7210540771484375, "Value Loss": 70.92384338378906, "_runtime": 955.5689902305603, "_timestamp": 1585595704.5856638, "_step": 295}
{"Episode reward": 90.17442278402405, "Episode length": 109, "Policy Loss": -0.3409917950630188, "Value Loss": 73.59893035888672, "_runtime": 956.0370028018951, "_timestamp": 1585595705.0536764, "_step": 296}
{"Episode reward": 69.2765291079048, "Episode length": 335, "Policy Loss": -0.8527723550796509, "Value Loss": 25.074567794799805, "_runtime": 956.2850568294525, "_timestamp": 1585595705.3017304, "_step": 297}
{"Episode reward": 83.96866147672766, "Episode length": 175, "Policy Loss": -0.3386339843273163, "Value Loss": 51.87543487548828, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375, -139.75189208984375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-2269.009033203125, -2230.573486328125, -2192.13818359375, -2153.70263671875, -2115.267333984375, -2076.831787109375, -2038.396484375, -1999.9609375, -1961.525634765625, -1923.090087890625, -1884.65478515625, -1846.21923828125, -1807.7838134765625, -1769.348388671875, -1730.9129638671875, -1692.4775390625, -1654.0421142578125, -1615.606689453125, -1577.1712646484375, -1538.73583984375, -1500.3004150390625, -1461.864990234375, -1423.429443359375, -1384.994140625, -1346.55859375, -1308.123291015625, -1269.687744140625, -1231.2523193359375, -1192.81689453125, -1154.3814697265625, -1115.946044921875, -1077.5106201171875, -1039.0751953125, -1000.6397705078125, -962.204345703125, -923.7689208984375, -885.33349609375, -846.8980712890625, -808.462646484375, -770.0272216796875, -731.591796875, -693.15625, -654.7208251953125, -616.285400390625, -577.8499755859375, -539.41455078125, -500.9791259765625, -462.543701171875, -424.1082763671875, -385.6728515625, -347.2374267578125, -308.802001953125, -270.3665771484375, -231.93115234375, -193.49560546875, -155.060302734375, -116.624755859375, -78.189453125, -39.75390625, -1.318603515625, 37.116943359375, 75.55224609375, 113.98779296875, 152.423095703125, 190.858642578125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-21.732641220092773, -20.96101188659668, -20.189380645751953, -19.41775131225586, -18.646121978759766, -17.874492645263672, -17.102861404418945, -16.33123207092285, -15.559601783752441, -14.787971496582031, -14.016342163085938, -13.244711875915527, -12.473081588745117, -11.701452255249023, -10.929821968078613, -10.15819263458252, -9.38656234741211, -8.6149320602417, -7.8433027267456055, -7.071672439575195, -6.300043106079102, -5.528411865234375, -4.756782531738281, -3.9851531982421875, -3.213521957397461, -2.441892623901367, -1.6702632904052734, -0.8986339569091797, -0.12700271606445312, 0.6446266174316406, 1.4162559509277344, 2.187887191772461, 2.9595165252685547, 3.7311458587646484, 4.502777099609375, 5.274406433105469, 6.0460357666015625, 6.817667007446289, 7.589296340942383, 8.360925674438477, 9.13255500793457, 9.904186248779297, 10.675817489624023, 11.447446823120117, 12.219076156616211, 12.990705490112305, 13.762334823608398, 14.533964157104492, 15.305597305297852, 16.077226638793945, 16.84885597229004, 17.620485305786133, 18.392114639282227, 19.16374397277832, 19.935373306274414, 20.707006454467773, 21.478635787963867, 22.25026512145996, 23.021894454956055, 23.79352378845215, 24.565153121948242, 25.3367862701416, 26.108415603637695, 26.88004493713379, 27.651674270629883]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 8.0, 5.0, 8.0, 5.0, 15.0, 20.0, 14.0, 8.0, 8.0, 32.0, 171.0, 89.0, 10.0, 26.0, 28.0, 16.0, 3.0, 7.0, 10.0, 4.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-60.35697937011719, -58.19236373901367, -56.027748107910156, -53.863136291503906, -51.69852066040039, -49.533905029296875, -47.369293212890625, -45.20467758178711, -43.040061950683594, -40.87544631958008, -38.71083068847656, -36.54621887207031, -34.3816032409668, -32.21698760986328, -30.0523738861084, -27.887760162353516, -25.72314453125, -23.558528900146484, -21.39391326904297, -19.22930145263672, -17.064685821533203, -14.900070190429688, -12.735458374023438, -10.570842742919922, -8.406227111816406, -6.241611480712891, -4.076995849609375, -1.912384033203125, 0.2522315979003906, 2.4168472290039062, 4.581459045410156, 6.7460784912109375, 8.910690307617188, 11.075302124023438, 13.239921569824219, 15.404533386230469, 17.56915283203125, 19.7337646484375, 21.89837646484375, 24.06299591064453, 26.22760772705078, 28.39221954345703, 30.556838989257812, 32.72145080566406, 34.88606262207031, 37.050682067871094, 39.215293884277344, 41.379913330078125, 43.544525146484375, 45.709136962890625, 47.873756408691406, 50.038368225097656, 52.20298767089844, 54.36759948730469, 56.53221130371094, 58.69683074951172, 60.86144256591797, 63.02605438232422, 65.190673828125, 67.35528564453125, 69.5198974609375, 71.68450927734375, 73.84913635253906, 76.01374816894531, 78.17835998535156]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-12.991082191467285, -12.399772644042969, -11.808463096618652, -11.217153549194336, -10.62584400177002, -10.034534454345703, -9.443225860595703, -8.85191535949707, -8.26060676574707, -7.669296741485596, -7.077987194061279, -6.486677646636963, -5.895368576049805, -5.304059028625488, -4.712749481201172, -4.1214399337768555, -3.530130386352539, -2.9388208389282227, -2.3475112915039062, -1.7562017440795898, -1.1648921966552734, -0.573582649230957, 0.017726898193359375, 0.6090364456176758, 1.2003450393676758, 1.7916545867919922, 2.3829641342163086, 2.974273681640625, 3.5655832290649414, 4.156893730163574, 4.748202323913574, 5.339512825012207, 5.930821418762207, 6.522130012512207, 7.11344051361084, 7.70474910736084, 8.296059608459473, 8.887368202209473, 9.478678703308105, 10.069987297058105, 10.661297798156738, 11.252606391906738, 11.843916893005371, 12.435225486755371, 13.026535987854004, 13.617844581604004, 14.209155082702637, 14.800463676452637, 15.391772270202637, 15.98308277130127, 16.574390411376953, 17.16570281982422, 17.75701141357422, 18.34832000732422, 18.93962860107422, 19.530941009521484, 20.122249603271484, 20.713558197021484, 21.30487060546875, 21.89617919921875, 22.48748779296875, 23.07879638671875, 23.670108795166016, 24.261417388916016, 24.852725982666016]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 2.0, 3.0, 9.0, 4.0, 8.0, 4.0, 3.0, 5.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-38.23535919189453, -37.41462326049805, -36.59389114379883, -35.773155212402344, -34.95241928100586, -34.13168716430664, -33.310951232910156, -32.49021530151367, -31.669483184814453, -30.84874725341797, -30.028013229370117, -29.207279205322266, -28.38654327392578, -27.56580924987793, -26.745075225830078, -25.924339294433594, -25.103605270385742, -24.28287124633789, -23.462135314941406, -22.641401290893555, -21.820667266845703, -20.99993133544922, -20.179197311401367, -19.358463287353516, -18.53772735595703, -17.71699333190918, -16.896259307861328, -16.075525283813477, -15.254789352416992, -14.43405532836914, -13.613321304321289, -12.792585372924805, -11.971851348876953, -11.151117324829102, -10.330381393432617, -9.509647369384766, -8.688913345336914, -7.86817741394043, -7.047443389892578, -6.226707458496094, -5.405975341796875, -4.585239410400391, -3.7645034790039062, -2.9437713623046875, -2.123035430908203, -1.3022994995117188, -0.4815673828125, 0.3391685485839844, 1.1599044799804688, 1.9806365966796875, 2.801372528076172, 3.6221046447753906, 4.442840576171875, 5.263576507568359, 6.084308624267578, 6.9050445556640625, 7.725780487060547, 8.546512603759766, 9.36724853515625, 10.187984466552734, 11.008716583251953, 11.829452514648438, 12.650188446044922, 13.47092056274414, 14.291656494140625]}, "_runtime": 956.7122988700867, "_timestamp": 1585595705.7289724, "_step": 298}
{"Episode reward": 71.8400902264504, "Episode length": 305, "Policy Loss": -1.1521073579788208, "Value Loss": 30.417238235473633, "_runtime": 956.9763395786285, "_timestamp": 1585595705.9930131, "_step": 299}
{"Episode reward": 83.4148932978394, "Episode length": 177, "Policy Loss": 0.9031491279602051, "Value Loss": 50.574832916259766, "_runtime": 957.1348555088043, "_timestamp": 1585595706.151529, "_step": 300}
{"Episode reward": 90.00673729426975, "Episode length": 106, "Policy Loss": 2.4991681575775146, "Value Loss": 79.1903305053711, "_runtime": 957.2931759357452, "_timestamp": 1585595706.3098495, "_step": 301}
{"Episode reward": 90.4122760478111, "Episode length": 101, "Policy Loss": 2.0259814262390137, "Value Loss": 78.35408782958984, "_runtime": 957.4648344516754, "_timestamp": 1585595706.481508, "_step": 302}
{"Episode reward": 89.38258537384274, "Episode length": 115, "Policy Loss": -1.9733895063400269, "Value Loss": 70.9961166381836, "_runtime": 957.6254312992096, "_timestamp": 1585595706.6421049, "_step": 303}
{"Episode reward": 89.75545348719504, "Episode length": 110, "Policy Loss": -8.258383750915527, "Value Loss": 162.77256774902344, "_runtime": 957.7896082401276, "_timestamp": 1585595706.8062818, "_step": 304}
{"Episode reward": 89.55646723250855, "Episode length": 113, "Policy Loss": -0.18956999480724335, "Value Loss": 71.67634582519531, "_runtime": 958.0428891181946, "_timestamp": 1585595707.0595627, "_step": 305}
{"Episode reward": 84.28506933024383, "Episode length": 179, "Policy Loss": -0.2178158313035965, "Value Loss": 46.533714294433594, "_runtime": 958.6482307910919, "_timestamp": 1585595707.6649044, "_step": 306}
{"Episode reward": 59.64075349547192, "Episode length": 432, "Policy Loss": -0.4166853427886963, "Value Loss": 20.207576751708984, "_runtime": 958.9984881877899, "_timestamp": 1585595708.0151618, "_step": 307}
{"Episode reward": 77.33338279526558, "Episode length": 249, "Policy Loss": -0.11302580684423447, "Value Loss": 38.33327102661133, "_runtime": 959.151878118515, "_timestamp": 1585595708.1685517, "_step": 308}
{"Episode reward": 90.66709369198372, "Episode length": 101, "Policy Loss": 2.561342716217041, "Value Loss": 91.79259490966797, "_runtime": 959.4323108196259, "_timestamp": 1585595708.4489844, "_step": 309}
{"Episode reward": 83.23301179998212, "Episode length": 186, "Policy Loss": 0.834558367729187, "Value Loss": 51.63004684448242, "_runtime": 959.6984665393829, "_timestamp": 1585595708.71514, "_step": 310}
{"Episode reward": 83.26819053460156, "Episode length": 184, "Policy Loss": 0.3048553764820099, "Value Loss": 52.238346099853516, "_runtime": 959.8592207431793, "_timestamp": 1585595708.8758943, "_step": 311}
{"Episode reward": 90.24381501027963, "Episode length": 110, "Policy Loss": 2.1307437419891357, "Value Loss": 86.3918228149414, "_runtime": 960.2319359779358, "_timestamp": 1585595709.2486095, "_step": 312}
{"Episode reward": 76.61962745526418, "Episode length": 263, "Policy Loss": -0.12703125178813934, "Value Loss": 37.376766204833984, "_runtime": 960.495370388031, "_timestamp": 1585595709.512044, "_step": 313}
{"Episode reward": 83.9585727996014, "Episode length": 183, "Policy Loss": 0.10022988170385361, "Value Loss": 52.647071838378906, "_runtime": 960.7545247077942, "_timestamp": 1585595709.7711983, "_step": 314}
{"Episode reward": 84.22918457998374, "Episode length": 184, "Policy Loss": -0.3313567638397217, "Value Loss": 52.70119857788086, "_runtime": 961.1504549980164, "_timestamp": 1585595710.1671286, "_step": 315}
{"Episode reward": 75.40605701473234, "Episode length": 278, "Policy Loss": -0.18000440299510956, "Value Loss": 35.95470428466797, "_runtime": 961.4190452098846, "_timestamp": 1585595710.4357188, "_step": 316}
{"Episode reward": 83.8093863079282, "Episode length": 184, "Policy Loss": 0.18740786612033844, "Value Loss": 52.08501434326172, "_runtime": 961.6881551742554, "_timestamp": 1585595710.7048287, "_step": 317}
{"Episode reward": 83.79311971616617, "Episode length": 186, "Policy Loss": -0.025815576314926147, "Value Loss": 51.651302337646484, "_runtime": 962.0668258666992, "_timestamp": 1585595711.0834994, "_step": 318}
{"Episode reward": 78.05295003139344, "Episode length": 261, "Policy Loss": -0.27036353945732117, "Value Loss": 37.319725036621094, "_runtime": 962.3436238765717, "_timestamp": 1585595711.3602974, "_step": 319}
{"Episode reward": 82.66510667478359, "Episode length": 191, "Policy Loss": 0.4249518811702728, "Value Loss": 50.822479248046875, "_runtime": 962.5133993625641, "_timestamp": 1585595711.530073, "_step": 320}
{"Episode reward": 90.32297710963425, "Episode length": 112, "Policy Loss": 1.7756221294403076, "Value Loss": 85.95697784423828, "_runtime": 962.782080411911, "_timestamp": 1585595711.798754, "_step": 321}
{"Episode reward": 83.9092190855654, "Episode length": 183, "Policy Loss": 0.9320220351219177, "Value Loss": 52.45692443847656, "_runtime": 963.3541641235352, "_timestamp": 1585595712.3708377, "_step": 322}
{"Episode reward": 63.53239394126755, "Episode length": 403, "Policy Loss": -0.32532957196235657, "Value Loss": 24.156414031982422, "_runtime": 963.7191436290741, "_timestamp": 1585595712.7358172, "_step": 323}
{"Episode reward": 78.05107937628112, "Episode length": 257, "Policy Loss": -0.2614821493625641, "Value Loss": 37.63420867919922, "_runtime": 963.8845779895782, "_timestamp": 1585595712.9012516, "_step": 324}
{"Episode reward": 90.64347836915988, "Episode length": 109, "Policy Loss": 1.52705979347229, "Value Loss": 87.38821411132812, "_runtime": 964.1632008552551, "_timestamp": 1585595713.1798744, "_step": 325}
{"Episode reward": 84.95977626655339, "Episode length": 177, "Policy Loss": 0.22971825301647186, "Value Loss": 53.956119537353516, "_runtime": 964.3425223827362, "_timestamp": 1585595713.359196, "_step": 326}
{"Episode reward": 90.10774810968603, "Episode length": 115, "Policy Loss": 1.200853943824768, "Value Loss": 83.3192138671875, "_runtime": 964.637613773346, "_timestamp": 1585595713.6542873, "_step": 327}
{"Episode reward": 82.39483813557766, "Episode length": 207, "Policy Loss": 0.5306035876274109, "Value Loss": 46.79607009887695, "_runtime": 965.1837046146393, "_timestamp": 1585595714.2003782, "_step": 328}
{"Episode reward": 64.68130679579113, "Episode length": 386, "Policy Loss": -0.7574266195297241, "Value Loss": 24.754533767700195, "_runtime": 965.5665323734283, "_timestamp": 1585595714.583206, "_step": 329}
{"Episode reward": 76.07033262014058, "Episode length": 270, "Policy Loss": -0.8014445900917053, "Value Loss": 36.119651794433594, "_runtime": 966.1284968852997, "_timestamp": 1585595715.1451705, "_step": 330}
{"Episode reward": 65.08241238153343, "Episode length": 395, "Policy Loss": -1.3863869905471802, "Value Loss": 25.38995933532715, "_runtime": 966.4065270423889, "_timestamp": 1585595715.4232006, "_step": 331}
{"Episode reward": 84.76534163610192, "Episode length": 183, "Policy Loss": -1.0277953147888184, "Value Loss": 52.03335189819336, "_runtime": 967.0346510410309, "_timestamp": 1585595716.0513246, "_step": 332}
{"Episode reward": 60.67079957504016, "Episode length": 442, "Policy Loss": -0.428362637758255, "Value Loss": 22.496152877807617, "_runtime": 967.3251504898071, "_timestamp": 1585595716.341824, "_step": 333}
{"Episode reward": 83.96598562239775, "Episode length": 186, "Policy Loss": -0.7192687392234802, "Value Loss": 51.296775817871094, "_runtime": 967.6908450126648, "_timestamp": 1585595716.7075186, "_step": 334}
{"Episode reward": 78.64098224132624, "Episode length": 256, "Policy Loss": -0.6160843372344971, "Value Loss": 36.95720672607422, "_runtime": 968.1810853481293, "_timestamp": 1585595717.197759, "_step": 335}
{"Episode reward": 71.49671607018198, "Episode length": 338, "Policy Loss": -0.8037954568862915, "Value Loss": 28.792953491210938, "_runtime": 968.4524700641632, "_timestamp": 1585595717.4691436, "_step": 336}
{"Episode reward": 84.09882780249168, "Episode length": 188, "Policy Loss": 0.9923025965690613, "Value Loss": 51.59031677246094, "_runtime": 969.0463347434998, "_timestamp": 1585595718.0630083, "_step": 337}
{"Episode reward": 61.989433496307676, "Episode length": 419, "Policy Loss": -0.3554663360118866, "Value Loss": 22.96824836730957, "_runtime": 969.5382397174835, "_timestamp": 1585595718.5549133, "_step": 338}
{"Episode reward": 70.43775516238387, "Episode length": 341, "Policy Loss": -0.39074021577835083, "Value Loss": 28.189922332763672, "_runtime": 970.3624000549316, "_timestamp": 1585595719.3790736, "_step": 339}
{"Episode reward": 47.34423364726071, "Episode length": 580, "Policy Loss": -0.9211920499801636, "Value Loss": 16.984569549560547, "_runtime": 970.661773443222, "_timestamp": 1585595719.678447, "_step": 340}
{"Episode reward": 84.08557831734701, "Episode length": 189, "Policy Loss": -0.11137440800666809, "Value Loss": 50.009361267089844, "_runtime": 970.9374489784241, "_timestamp": 1585595719.9541225, "_step": 341}
{"Episode reward": 84.45344483249029, "Episode length": 184, "Policy Loss": -0.04031888395547867, "Value Loss": 51.55268478393555, "_runtime": 971.2323338985443, "_timestamp": 1585595720.2490075, "_step": 342}
{"Episode reward": 83.24976510176032, "Episode length": 191, "Policy Loss": 0.2631368935108185, "Value Loss": 49.220096588134766, "_runtime": 971.5974187850952, "_timestamp": 1585595720.6140924, "_step": 343}
{"Episode reward": 78.43819595642411, "Episode length": 256, "Policy Loss": -0.04362456500530243, "Value Loss": 37.34770965576172, "_runtime": 972.0832960605621, "_timestamp": 1585595721.0999696, "_step": 344}
{"Episode reward": 69.1967505106122, "Episode length": 343, "Policy Loss": -0.7172183990478516, "Value Loss": 28.14883804321289, "_runtime": 972.455828666687, "_timestamp": 1585595721.4725022, "_step": 345}
{"Episode reward": 78.77357488902497, "Episode length": 261, "Policy Loss": 0.3054902255535126, "Value Loss": 36.16951370239258, "_runtime": 972.7284903526306, "_timestamp": 1585595721.745164, "_step": 346}
{"Episode reward": 84.16022994115119, "Episode length": 187, "Policy Loss": -0.2438562512397766, "Value Loss": 49.8178825378418, "_runtime": 973.1372594833374, "_timestamp": 1585595722.153933, "_step": 347}
{"Episode reward": 75.55818104766132, "Episode length": 283, "Policy Loss": 0.1740739494562149, "Value Loss": 33.97046661376953, "_runtime": 973.4137561321259, "_timestamp": 1585595722.4304297, "_step": 348}
{"Episode reward": 83.90227996963827, "Episode length": 189, "Policy Loss": -0.6552628874778748, "Value Loss": 50.84679412841797, "_runtime": 973.7905812263489, "_timestamp": 1585595722.8072548, "_step": 349}
{"Episode reward": 77.60129072473917, "Episode length": 265, "Policy Loss": -0.6046678423881531, "Value Loss": 36.406002044677734, "_runtime": 974.3181509971619, "_timestamp": 1585595723.3348246, "_step": 350}
{"Episode reward": 66.24074591346229, "Episode length": 372, "Policy Loss": -0.9233718514442444, "Value Loss": 25.49589729309082, "_runtime": 974.9806253910065, "_timestamp": 1585595723.997299, "_step": 351}
{"Episode reward": 58.605169778551314, "Episode length": 467, "Policy Loss": -0.6085609793663025, "Value Loss": 20.403316497802734, "_runtime": 975.7632701396942, "_timestamp": 1585595724.7799437, "_step": 352}
{"Episode reward": 51.48375098604196, "Episode length": 549, "Policy Loss": -1.0168273448944092, "Value Loss": 17.523658752441406, "_runtime": 976.3206787109375, "_timestamp": 1585595725.3373523, "_step": 353}
{"Episode reward": 65.88467576082995, "Episode length": 372, "Policy Loss": -0.31765589118003845, "Value Loss": 25.26836395263672, "_runtime": 976.8391544818878, "_timestamp": 1585595725.855828, "_step": 354}
{"Episode reward": 71.27162670783972, "Episode length": 351, "Policy Loss": -0.5645399689674377, "Value Loss": 27.221988677978516, "_runtime": 977.3360300064087, "_timestamp": 1585595726.3527036, "_step": 355}
{"Episode reward": 71.56127065247506, "Episode length": 333, "Policy Loss": -0.757275402545929, "Value Loss": 28.07973861694336, "_runtime": 977.7228543758392, "_timestamp": 1585595726.739528, "_step": 356}
{"Episode reward": 77.99105329928467, "Episode length": 260, "Policy Loss": -0.5918336510658264, "Value Loss": 35.86782455444336, "_runtime": 978.0137338638306, "_timestamp": 1585595727.0304074, "_step": 357}
{"Episode reward": 83.90817417727997, "Episode length": 194, "Policy Loss": -0.14629574120044708, "Value Loss": 48.01388931274414, "_runtime": 978.2955296039581, "_timestamp": 1585595727.3122032, "_step": 358}
{"Episode reward": 83.90641916473648, "Episode length": 187, "Policy Loss": -0.24542202055454254, "Value Loss": 49.21711730957031, "_runtime": 978.5750589370728, "_timestamp": 1585595727.5917325, "_step": 359}
{"Episode reward": 83.22898062258247, "Episode length": 189, "Policy Loss": -0.42366939783096313, "Value Loss": 49.531497955322266, "_runtime": 978.8343269824982, "_timestamp": 1585595727.8510005, "_step": 360}
{"Episode reward": 84.527089799847, "Episode length": 177, "Policy Loss": -0.23008446395397186, "Value Loss": 52.68339920043945, "_runtime": 979.1127982139587, "_timestamp": 1585595728.1294718, "_step": 361}
{"Episode reward": 83.64374704439768, "Episode length": 192, "Policy Loss": -0.03489696979522705, "Value Loss": 47.20170211791992, "_runtime": 979.3782756328583, "_timestamp": 1585595728.3949492, "_step": 362}
{"Episode reward": 84.50080000804333, "Episode length": 182, "Policy Loss": -0.719592273235321, "Value Loss": 49.19829177856445, "_runtime": 979.8534452915192, "_timestamp": 1585595728.8701189, "_step": 363}
{"Episode reward": 70.10025651995129, "Episode length": 334, "Policy Loss": -1.3830311298370361, "Value Loss": 26.501548767089844, "_runtime": 980.2371337413788, "_timestamp": 1585595729.2538073, "_step": 364}
{"Episode reward": 77.74863292628598, "Episode length": 264, "Policy Loss": -1.2302465438842773, "Value Loss": 33.18573760986328, "_runtime": 980.4936544895172, "_timestamp": 1585595729.510328, "_step": 365}
{"Episode reward": 84.747472555646, "Episode length": 175, "Policy Loss": -0.6335041522979736, "Value Loss": 51.54863357543945, "_runtime": 980.760541677475, "_timestamp": 1585595729.7772152, "_step": 366}
{"Episode reward": 84.9046978632502, "Episode length": 178, "Policy Loss": 0.24659758806228638, "Value Loss": 47.62881851196289, "_runtime": 981.4996204376221, "_timestamp": 1585595730.516294, "_step": 367}
{"Episode reward": 53.007335862458746, "Episode length": 515, "Policy Loss": -2.72137451171875, "Value Loss": 19.941980361938477, "_runtime": 981.956814289093, "_timestamp": 1585595730.9734879, "_step": 368}
{"Episode reward": 73.14361488028362, "Episode length": 311, "Policy Loss": -1.5229957103729248, "Value Loss": 28.247774124145508, "_runtime": 982.2216577529907, "_timestamp": 1585595731.2383313, "_step": 369}
{"Episode reward": 84.78382529527374, "Episode length": 182, "Policy Loss": -1.2371221780776978, "Value Loss": 46.87384796142578, "_runtime": 982.6278185844421, "_timestamp": 1585595731.6444921, "_step": 370}
{"Episode reward": 76.01206493820729, "Episode length": 270, "Policy Loss": -0.6938895583152771, "Value Loss": 33.143638610839844, "_runtime": 982.8128757476807, "_timestamp": 1585595731.8295493, "_step": 371}
{"Episode reward": 89.41425712866923, "Episode length": 118, "Policy Loss": 1.084883213043213, "Value Loss": 73.34095764160156, "_runtime": 983.0955817699432, "_timestamp": 1585595732.1122553, "_step": 372}
{"Episode reward": 82.54313486243149, "Episode length": 194, "Policy Loss": -1.598623514175415, "Value Loss": 50.086769104003906, "_runtime": 983.4889957904816, "_timestamp": 1585595732.5056694, "_step": 373}
{"Episode reward": 75.53810824030721, "Episode length": 271, "Policy Loss": -1.3226983547210693, "Value Loss": 31.732177734375, "_runtime": 983.7610628604889, "_timestamp": 1585595732.7777364, "_step": 374}
{"Episode reward": 82.55137243905597, "Episode length": 190, "Policy Loss": -1.2268153429031372, "Value Loss": 47.16310119628906, "_runtime": 983.9373149871826, "_timestamp": 1585595732.9539886, "_step": 375}
{"Episode reward": 89.90362416200372, "Episode length": 110, "Policy Loss": 1.6062588691711426, "Value Loss": 77.24321746826172, "_runtime": 984.2062106132507, "_timestamp": 1585595733.2228842, "_step": 376}
{"Episode reward": 84.38912555653869, "Episode length": 176, "Policy Loss": -0.3863573372364044, "Value Loss": 47.08757019042969, "_runtime": 984.3888328075409, "_timestamp": 1585595733.4055064, "_step": 377}
{"Episode reward": 88.83635688173278, "Episode length": 121, "Policy Loss": -1.5412919521331787, "Value Loss": 77.18154907226562, "_runtime": 984.6563653945923, "_timestamp": 1585595733.673039, "_step": 378}
{"Episode reward": 83.93227161684445, "Episode length": 188, "Policy Loss": -0.038982756435871124, "Value Loss": 43.60490417480469, "_runtime": 984.916955947876, "_timestamp": 1585595733.9336295, "_step": 379}
{"Episode reward": 83.68308108127547, "Episode length": 180, "Policy Loss": -0.06126917898654938, "Value Loss": 44.694068908691406, "_runtime": 986.2718684673309, "_timestamp": 1585595735.288542, "_step": 380}
{"Episode reward": 13.845000535558881, "Episode length": 934, "Policy Loss": -1.65825617313385, "Value Loss": 9.232132911682129, "_runtime": 986.7325041294098, "_timestamp": 1585595735.7491777, "_step": 381}
{"Episode reward": 71.64044015869372, "Episode length": 314, "Policy Loss": -1.7842583656311035, "Value Loss": 28.963029861450195, "_runtime": 987.1086986064911, "_timestamp": 1585595736.1253722, "_step": 382}
{"Episode reward": 76.49863082297836, "Episode length": 263, "Policy Loss": -0.6333459615707397, "Value Loss": 30.90769386291504, "_runtime": 987.5178465843201, "_timestamp": 1585595736.5345201, "_step": 383}
{"Episode reward": 76.57403871930754, "Episode length": 259, "Policy Loss": 0.38911423087120056, "Value Loss": 32.44780731201172, "_runtime": 987.8913643360138, "_timestamp": 1585595736.908038, "_step": 384}
{"Episode reward": 76.76925735329327, "Episode length": 257, "Policy Loss": 0.05085175111889839, "Value Loss": 31.849666595458984, "_runtime": 988.0640919208527, "_timestamp": 1585595737.0807655, "_step": 385}
{"Episode reward": 90.14812397580422, "Episode length": 112, "Policy Loss": 0.9684913754463196, "Value Loss": 77.96588134765625, "_runtime": 988.3435897827148, "_timestamp": 1585595737.3602633, "_step": 386}
{"Episode reward": 83.09004937399177, "Episode length": 191, "Policy Loss": -1.4530757665634155, "Value Loss": 45.727943420410156, "_runtime": 988.6024949550629, "_timestamp": 1585595737.6191685, "_step": 387}
{"Episode reward": 84.16317131702321, "Episode length": 177, "Policy Loss": -1.1431005001068115, "Value Loss": 45.94050216674805, "_runtime": 988.7621252536774, "_timestamp": 1585595737.7787988, "_step": 388}
{"Episode reward": 89.73906032577312, "Episode length": 109, "Policy Loss": 1.2119839191436768, "Value Loss": 73.42332458496094, "_runtime": 989.0495858192444, "_timestamp": 1585595738.0662594, "_step": 389}
{"Episode reward": 81.45399255078155, "Episode length": 201, "Policy Loss": -0.7301135659217834, "Value Loss": 41.83616256713867, "_runtime": 989.2192840576172, "_timestamp": 1585595738.2359576, "_step": 390}
{"Episode reward": 89.35851990617094, "Episode length": 114, "Policy Loss": 1.6042958498001099, "Value Loss": 70.0511245727539, "_runtime": 989.4741015434265, "_timestamp": 1585595738.490775, "_step": 391}
{"Episode reward": 83.91643596554015, "Episode length": 180, "Policy Loss": -0.5666669011116028, "Value Loss": 46.24079132080078, "_runtime": 989.7359924316406, "_timestamp": 1585595738.752666, "_step": 392}
{"Episode reward": 83.0509321525699, "Episode length": 182, "Policy Loss": -2.9220142364501953, "Value Loss": 48.94063949584961, "_runtime": 990.1052918434143, "_timestamp": 1585595739.1219654, "_step": 393}
{"Episode reward": 76.39248291911967, "Episode length": 263, "Policy Loss": 0.9673613905906677, "Value Loss": 32.91921615600586, "_runtime": 990.542688369751, "_timestamp": 1585595739.559362, "_step": 394}
{"Episode reward": 71.31713036512147, "Episode length": 310, "Policy Loss": 0.5439504981040955, "Value Loss": 27.401304244995117, "_runtime": 990.7139818668365, "_timestamp": 1585595739.7306554, "_step": 395}
{"Episode reward": 89.47587073864298, "Episode length": 115, "Policy Loss": 3.0249075889587402, "Value Loss": 78.30912017822266, "_runtime": 991.0749003887177, "_timestamp": 1585595740.091574, "_step": 396}
{"Episode reward": 77.35019062543495, "Episode length": 249, "Policy Loss": -0.21375270187854767, "Value Loss": 37.86973190307617, "_runtime": 991.2406449317932, "_timestamp": 1585595740.2573185, "_step": 397}
{"Episode reward": 91.14867526433298, "Episode length": 106, "Policy Loss": -1.0581315755844116, "Value Loss": 76.18972778320312, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484, -43.418880462646484]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [59.655616760253906, 60.3949089050293, 61.13419723510742, 61.87348937988281, 62.6127815246582, 63.35206985473633, 64.09136199951172, 64.83065032958984, 65.5699462890625, 66.30923461914062, 67.04852294921875, 67.7878189086914, 68.52710723876953, 69.26639556884766, 70.00569152832031, 70.74497985839844, 71.48426818847656, 72.22356414794922, 72.96285247802734, 73.70214080810547, 74.44143676757812, 75.18072509765625, 75.92001342773438, 76.6593017578125, 77.39859771728516, 78.13788604736328, 78.87718200683594, 79.61647033691406, 80.35575866699219, 81.09504699707031, 81.83434295654297, 82.5736312866211, 83.31292724609375, 84.05221557617188, 84.79150390625, 85.53079223632812, 86.27008819580078, 87.0093765258789, 87.74867248535156, 88.48796081542969, 89.22724914550781, 89.96653747558594, 90.7058334350586, 91.44512176513672, 92.18441772460938, 92.9237060546875, 93.66299438476562, 94.40228271484375, 95.1415786743164, 95.88086700439453, 96.62016296386719, 97.35945129394531, 98.09873962402344, 98.83802795410156, 99.57731628417969, 100.31661224365234, 101.055908203125, 101.79519653320312, 102.53448486328125, 103.27377319335938, 104.0130615234375, 104.75235748291016, 105.49165344238281, 106.23094177246094, 106.97023010253906]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.8539350032806396, -1.7432178258895874, -1.6325006484985352, -1.5217835903167725, -1.4110664129257202, -1.300349235534668, -1.1896321773529053, -1.078914999961853, -0.9681978225708008, -0.8574806451797485, -0.7467634677886963, -0.6360464096069336, -0.5253292322158813, -0.4146120548248291, -0.3038949966430664, -0.19317781925201416, -0.08246064186096191, 0.028256535530090332, 0.13897371292114258, 0.24969077110290527, 0.36040806770324707, 0.47112512588500977, 0.5818421840667725, 0.6925594806671143, 0.803276538848877, 0.9139935970306396, 1.0247108936309814, 1.1354279518127441, 1.2461450099945068, 1.3568623065948486, 1.4675793647766113, 1.5782966613769531, 1.6890137195587158, 1.7997307777404785, 1.9104480743408203, 2.021165132522583, 2.131882429122925, 2.2425992488861084, 2.35331654548645, 2.464033842086792, 2.574751138687134, 2.6854679584503174, 2.796185255050659, 2.906902551651001, 3.0176193714141846, 3.1283366680145264, 3.239053964614868, 3.3497707843780518, 3.4604880809783936, 3.5712053775787354, 3.681922197341919, 3.7926394939422607, 3.9033567905426025, 4.014073371887207, 4.124791145324707, 4.235507965087891, 4.346224784851074, 4.456942558288574, 4.567659378051758, 4.678377151489258, 4.789093971252441, 4.899810791015625, 5.010528564453125, 5.121245384216309, 5.231962203979492]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 6.0, 4.0, 7.0, 8.0, 4.0, 11.0, 5.0, 12.0, 12.0, 15.0, 12.0, 11.0, 11.0, 17.0, 19.0, 33.0, 75.0, 54.0, 15.0, 17.0, 11.0, 20.0, 14.0, 12.0, 6.0, 16.0, 8.0, 8.0, 6.0, 7.0, 6.0, 5.0, 8.0, 7.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-4.093767166137695, -3.9414258003234863, -3.7890844345092773, -3.6367430686950684, -3.4844017028808594, -3.3320603370666504, -3.1797187328338623, -3.0273773670196533, -2.8750360012054443, -2.7226946353912354, -2.5703532695770264, -2.4180116653442383, -2.2656702995300293, -2.1133289337158203, -1.9609875679016113, -1.8086462020874023, -1.6563048362731934, -1.5039634704589844, -1.3516221046447754, -1.1992807388305664, -1.0469393730163574, -0.8945977687835693, -0.7422564029693604, -0.5899150371551514, -0.4375736713409424, -0.2852323055267334, -0.13289093971252441, 0.019450664520263672, 0.17179203033447266, 0.32413339614868164, 0.4764747619628906, 0.6288161277770996, 0.7811574935913086, 0.9334988594055176, 1.0858402252197266, 1.2381815910339355, 1.3905229568481445, 1.5428643226623535, 1.6952056884765625, 1.8475470542907715, 1.9998884201049805, 2.1522302627563477, 2.3045716285705566, 2.4569129943847656, 2.6092543601989746, 2.7615957260131836, 2.9139370918273926, 3.0662784576416016, 3.2186198234558105, 3.3709611892700195, 3.5233025550842285, 3.6756439208984375, 3.8279852867126465, 3.9803266525268555, 4.132668495178223, 4.285009384155273, 4.437351226806641, 4.589692115783691, 4.742033958435059, 4.894374847412109, 5.046716690063477, 5.199057579040527, 5.3513994216918945, 5.503740310668945, 5.6560821533203125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-12.99116325378418, -12.57589340209961, -12.160622596740723, -11.745352745056152, -11.330082893371582, -10.914812088012695, -10.499542236328125, -10.084272384643555, -9.669001579284668, -9.253731727600098, -8.838460922241211, -8.42319107055664, -8.00792121887207, -7.592650890350342, -7.177380561828613, -6.762110710144043, -6.3468403816223145, -5.931570053100586, -5.516300201416016, -5.101029872894287, -4.685759544372559, -4.270489692687988, -3.8552188873291016, -3.4399490356445312, -3.024679183959961, -2.609408378601074, -2.194138526916504, -1.7788686752319336, -1.3635978698730469, -0.9483280181884766, -0.5330581665039062, -0.11778736114501953, 0.2974824905395508, 0.7127523422241211, 1.1280231475830078, 1.5432929992675781, 1.9585628509521484, 2.373833656311035, 2.7891035079956055, 3.204374313354492, 3.6196441650390625, 4.034914016723633, 4.450183868408203, 4.865453720092773, 5.280725479125977, 5.695995330810547, 6.111265182495117, 6.5265350341796875, 6.941804885864258, 7.357074737548828, 7.772346496582031, 8.187616348266602, 8.602886199951172, 9.018156051635742, 9.433425903320312, 9.848695755004883, 10.263967514038086, 10.679237365722656, 11.094507217407227, 11.509777069091797, 11.925046920776367, 12.340316772460938, 12.75558853149414, 13.170858383178711, 13.586128234863281]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 6.0, 9.0, 5.0, 5.0, 5.0, 4.0, 5.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-11.67381477355957, -11.281968116760254, -10.890121459960938, -10.498273849487305, -10.106427192687988, -9.714580535888672, -9.322733879089355, -8.930887222290039, -8.539039611816406, -8.14719295501709, -7.755346298217773, -7.363499641418457, -6.971652984619141, -6.579805850982666, -6.18795919418335, -5.796112060546875, -5.404265403747559, -5.012418746948242, -4.620571613311768, -4.228724956512451, -3.8368778228759766, -3.44503116607666, -3.0531845092773438, -2.6613378524780273, -2.269491195678711, -1.8776435852050781, -1.4857969284057617, -1.0939502716064453, -0.7021036148071289, -0.3102569580078125, 0.08159065246582031, 0.4734373092651367, 0.8652839660644531, 1.2571306228637695, 1.648977279663086, 2.0408248901367188, 2.432671546936035, 2.8245182037353516, 3.216364860534668, 3.6082115173339844, 4.000059127807617, 4.391904830932617, 4.78375244140625, 5.175600051879883, 5.567445755004883, 5.959293365478516, 6.351139068603516, 6.742986679077148, 7.134832382202148, 7.526679992675781, 7.918527603149414, 8.310373306274414, 8.702220916748047, 9.094066619873047, 9.48591423034668, 9.877761840820312, 10.269607543945312, 10.661455154418945, 11.053300857543945, 11.445148468017578, 11.836996078491211, 12.228841781616211, 12.620689392089844, 13.012535095214844, 13.404382705688477]}, "_runtime": 991.6060810089111, "_timestamp": 1585595740.6227546, "_step": 398}
{"Episode reward": 78.81460438943074, "Episode length": 260, "Policy Loss": -2.1167352199554443, "Value Loss": 34.87316131591797, "_runtime": 991.8868963718414, "_timestamp": 1585595740.90357, "_step": 399}
{"Episode reward": 83.77612392415074, "Episode length": 193, "Policy Loss": -1.5888235569000244, "Value Loss": 42.34368133544922, "_runtime": 992.7781660556793, "_timestamp": 1585595741.7948396, "_step": 400}
{"Episode reward": 44.93572623199902, "Episode length": 634, "Policy Loss": -1.3396114110946655, "Value Loss": 14.145873069763184, "_runtime": 993.5841012001038, "_timestamp": 1585595742.6007748, "_step": 401}
{"Episode reward": 52.221673592307546, "Episode length": 555, "Policy Loss": -1.5047814846038818, "Value Loss": 22.828691482543945, "_runtime": 994.3111839294434, "_timestamp": 1585595743.3278575, "_step": 402}
{"Episode reward": 62.20881608627935, "Episode length": 478, "Policy Loss": -2.7657454013824463, "Value Loss": 34.743778228759766, "_runtime": 995.7917659282684, "_timestamp": 1585595744.8084395, "_step": 403}
{"Episode reward": -86.05711997152801, "Episode length": 999, "Policy Loss": -0.9441413283348083, "Value Loss": 1.835046648979187, "_runtime": 997.266027212143, "_timestamp": 1585595746.2827008, "_step": 404}
{"Episode reward": -83.60393876915731, "Episode length": 999, "Policy Loss": -1.2874499559402466, "Value Loss": 1.415123701095581, "_runtime": 998.7507436275482, "_timestamp": 1585595747.7674172, "_step": 405}
{"Episode reward": -84.28541455275183, "Episode length": 999, "Policy Loss": -0.9335523843765259, "Value Loss": 0.8673550486564636, "_runtime": 999.9450414180756, "_timestamp": 1585595748.961715, "_step": 406}
{"Episode reward": 26.871026233455467, "Episode length": 789, "Policy Loss": -0.7890546917915344, "Value Loss": 12.626935958862305, "_runtime": 1001.4674906730652, "_timestamp": 1585595750.4841642, "_step": 407}
{"Episode reward": -89.33419828305998, "Episode length": 999, "Policy Loss": -1.218092679977417, "Value Loss": 0.7037337422370911, "_runtime": 1002.9689939022064, "_timestamp": 1585595751.9856675, "_step": 408}
{"Episode reward": -85.09430029730501, "Episode length": 999, "Policy Loss": -1.4790691137313843, "Value Loss": 0.5476230382919312, "_runtime": 1004.4719293117523, "_timestamp": 1585595753.4886029, "_step": 409}
{"Episode reward": -85.58689304631322, "Episode length": 999, "Policy Loss": -1.1379597187042236, "Value Loss": 0.9211366772651672, "_runtime": 1005.9935088157654, "_timestamp": 1585595755.0101824, "_step": 410}
{"Episode reward": -89.96899928580761, "Episode length": 999, "Policy Loss": -0.933282196521759, "Value Loss": 0.20571446418762207, "_runtime": 1007.5244615077972, "_timestamp": 1585595756.541135, "_step": 411}
{"Episode reward": -85.56910276387727, "Episode length": 999, "Policy Loss": -1.0051063299179077, "Value Loss": 0.12396670132875443, "_runtime": 1009.0532071590424, "_timestamp": 1585595758.0698807, "_step": 412}
{"Episode reward": -91.55780216542479, "Episode length": 999, "Policy Loss": -0.865627110004425, "Value Loss": 0.0731060728430748, "_runtime": 1010.5776479244232, "_timestamp": 1585595759.5943215, "_step": 413}
{"Episode reward": -86.80965575026732, "Episode length": 999, "Policy Loss": -0.9905043244361877, "Value Loss": 0.17991399765014648, "_runtime": 1012.1118860244751, "_timestamp": 1585595761.1285596, "_step": 414}
{"Episode reward": -85.9799668648035, "Episode length": 999, "Policy Loss": -1.0540276765823364, "Value Loss": 0.2390901893377304, "_runtime": 1013.6463720798492, "_timestamp": 1585595762.6630456, "_step": 415}
{"Episode reward": -84.96622278087298, "Episode length": 999, "Policy Loss": -0.6070835590362549, "Value Loss": 0.13542771339416504, "_runtime": 1015.1818125247955, "_timestamp": 1585595764.198486, "_step": 416}
{"Episode reward": -89.52984184098266, "Episode length": 999, "Policy Loss": -0.6124492883682251, "Value Loss": 0.10411595553159714, "_runtime": 1016.7455348968506, "_timestamp": 1585595765.7622085, "_step": 417}
{"Episode reward": -86.64312353652608, "Episode length": 999, "Policy Loss": -0.821137547492981, "Value Loss": 0.21404604613780975, "_runtime": 1018.2713012695312, "_timestamp": 1585595767.2879748, "_step": 418}
{"Episode reward": -87.371075305532, "Episode length": 999, "Policy Loss": -0.37585240602493286, "Value Loss": 0.12566711008548737, "_runtime": 1019.7988841533661, "_timestamp": 1585595768.8155577, "_step": 419}
{"Episode reward": -88.18302013782437, "Episode length": 999, "Policy Loss": -0.35981595516204834, "Value Loss": 0.11517634987831116, "_runtime": 1021.3285465240479, "_timestamp": 1585595770.34522, "_step": 420}
{"Episode reward": -90.78179682604652, "Episode length": 999, "Policy Loss": -0.37780481576919556, "Value Loss": 0.04583000764250755, "_runtime": 1022.8675088882446, "_timestamp": 1585595771.8841825, "_step": 421}
{"Episode reward": -93.90635935242643, "Episode length": 999, "Policy Loss": -0.3588374853134155, "Value Loss": 0.016697881743311882, "_runtime": 1024.3860971927643, "_timestamp": 1585595773.4027708, "_step": 422}
{"Episode reward": -92.39879869216666, "Episode length": 999, "Policy Loss": -0.28291428089141846, "Value Loss": 0.060165878385305405, "_runtime": 1025.9160935878754, "_timestamp": 1585595774.9327672, "_step": 423}
{"Episode reward": -91.62917057067882, "Episode length": 999, "Policy Loss": -0.2719476521015167, "Value Loss": 0.1331440657377243, "_runtime": 1027.4469454288483, "_timestamp": 1585595776.463619, "_step": 424}
{"Episode reward": -92.53275327728734, "Episode length": 999, "Policy Loss": -0.1860620528459549, "Value Loss": 0.073492132127285, "_runtime": 1028.9789514541626, "_timestamp": 1585595777.995625, "_step": 425}
{"Episode reward": -91.19582173839058, "Episode length": 999, "Policy Loss": -0.2631775736808777, "Value Loss": 0.03420906886458397, "_runtime": 1030.5053713321686, "_timestamp": 1585595779.522045, "_step": 426}
{"Episode reward": -87.63878806755596, "Episode length": 999, "Policy Loss": 0.19655492901802063, "Value Loss": 0.3324200212955475, "_runtime": 1032.0341889858246, "_timestamp": 1585595781.0508626, "_step": 427}
{"Episode reward": -91.72360396777528, "Episode length": 999, "Policy Loss": -0.12843875586986542, "Value Loss": 0.1486588567495346, "_runtime": 1033.5679881572723, "_timestamp": 1585595782.5846617, "_step": 428}
{"Episode reward": -90.54292347065999, "Episode length": 999, "Policy Loss": -0.03192827105522156, "Value Loss": 0.11611787229776382, "_runtime": 1035.107834815979, "_timestamp": 1585595784.1245084, "_step": 429}
{"Episode reward": -89.66105049467029, "Episode length": 999, "Policy Loss": -0.17385515570640564, "Value Loss": 0.06029333174228668, "_runtime": 1036.6382768154144, "_timestamp": 1585595785.6549504, "_step": 430}
{"Episode reward": -93.5798791572028, "Episode length": 999, "Policy Loss": -0.17957668006420135, "Value Loss": 0.025243960320949554, "_runtime": 1038.1792840957642, "_timestamp": 1585595787.1959577, "_step": 431}
{"Episode reward": -91.30388220653532, "Episode length": 999, "Policy Loss": -0.2344641387462616, "Value Loss": 0.04234019294381142, "_runtime": 1039.7535455226898, "_timestamp": 1585595788.770219, "_step": 432}
{"Episode reward": -91.86887197294855, "Episode length": 999, "Policy Loss": -0.22173452377319336, "Value Loss": 0.11975116282701492, "_runtime": 1040.8064680099487, "_timestamp": 1585595789.8231416, "_step": 433}
{"Episode reward": 39.637779714225715, "Episode length": 686, "Policy Loss": 0.4125758111476898, "Value Loss": 14.771013259887695, "_runtime": 1042.3413889408112, "_timestamp": 1585595791.3580625, "_step": 434}
{"Episode reward": -95.22234078439675, "Episode length": 999, "Policy Loss": -0.18822833895683289, "Value Loss": 0.011768407188355923, "_runtime": 1043.8786342144012, "_timestamp": 1585595792.8953078, "_step": 435}
{"Episode reward": -91.90496448691182, "Episode length": 999, "Policy Loss": -0.22844001650810242, "Value Loss": 0.07400887459516525, "_runtime": 1045.3382983207703, "_timestamp": 1585595794.354972, "_step": 436}
{"Episode reward": 14.445340275751462, "Episode length": 969, "Policy Loss": -0.08111215382814407, "Value Loss": 10.500852584838867, "_runtime": 1046.8655314445496, "_timestamp": 1585595795.882205, "_step": 437}
{"Episode reward": -90.77979584767789, "Episode length": 999, "Policy Loss": -0.3137834072113037, "Value Loss": 0.06687122583389282, "_runtime": 1048.403198003769, "_timestamp": 1585595797.4198716, "_step": 438}
{"Episode reward": -90.93274421360674, "Episode length": 999, "Policy Loss": -0.31656506657600403, "Value Loss": 0.07970990985631943, "_runtime": 1049.9259223937988, "_timestamp": 1585595798.942596, "_step": 439}
{"Episode reward": -94.1337651290677, "Episode length": 999, "Policy Loss": -0.2629900276660919, "Value Loss": 0.03691743314266205, "_runtime": 1051.4525802135468, "_timestamp": 1585595800.4692538, "_step": 440}
{"Episode reward": -88.77947896979786, "Episode length": 999, "Policy Loss": -0.33737924695014954, "Value Loss": 0.11855398118495941, "_runtime": 1052.990356206894, "_timestamp": 1585595802.0070298, "_step": 441}
{"Episode reward": -86.94691077105982, "Episode length": 999, "Policy Loss": -0.4760850667953491, "Value Loss": 0.2595941722393036, "_runtime": 1054.5259745121002, "_timestamp": 1585595803.542648, "_step": 442}
{"Episode reward": -85.52917529178043, "Episode length": 999, "Policy Loss": -0.3438304364681244, "Value Loss": 0.1373976320028305, "_runtime": 1056.0654332637787, "_timestamp": 1585595805.0821068, "_step": 443}
{"Episode reward": -91.1231432602189, "Episode length": 999, "Policy Loss": -0.18344053626060486, "Value Loss": 0.033235616981983185, "_runtime": 1057.5987350940704, "_timestamp": 1585595806.6154087, "_step": 444}
{"Episode reward": -94.20575208673623, "Episode length": 999, "Policy Loss": -0.19854183495044708, "Value Loss": 0.006337203551083803, "_runtime": 1059.137146949768, "_timestamp": 1585595808.1538205, "_step": 445}
{"Episode reward": -93.0879244868819, "Episode length": 999, "Policy Loss": -0.17836140096187592, "Value Loss": 0.025731056928634644, "_runtime": 1060.6272041797638, "_timestamp": 1585595809.6438777, "_step": 446}
{"Episode reward": 10.974912779364871, "Episode length": 973, "Policy Loss": 0.1857452541589737, "Value Loss": 10.408895492553711, "_runtime": 1062.198944568634, "_timestamp": 1585595811.2156181, "_step": 447}
{"Episode reward": -89.90204011458403, "Episode length": 999, "Policy Loss": -0.04702344536781311, "Value Loss": 0.0483391135931015, "_runtime": 1063.7357766628265, "_timestamp": 1585595812.7524502, "_step": 448}
{"Episode reward": -92.34573134406531, "Episode length": 999, "Policy Loss": -0.1344021111726761, "Value Loss": 0.03347642347216606, "_runtime": 1065.2596538066864, "_timestamp": 1585595814.2763274, "_step": 449}
{"Episode reward": -92.96071468729309, "Episode length": 999, "Policy Loss": -0.20971402525901794, "Value Loss": 0.016890812665224075, "_runtime": 1066.7982008457184, "_timestamp": 1585595815.8148744, "_step": 450}
{"Episode reward": -94.54246223313487, "Episode length": 999, "Policy Loss": -0.18272016942501068, "Value Loss": 0.019466063007712364, "_runtime": 1068.3244540691376, "_timestamp": 1585595817.3411276, "_step": 451}
{"Episode reward": -89.41330098272934, "Episode length": 999, "Policy Loss": -0.12010504305362701, "Value Loss": 0.10839386284351349, "_runtime": 1069.863651752472, "_timestamp": 1585595818.8803253, "_step": 452}
{"Episode reward": -89.16491452947758, "Episode length": 999, "Policy Loss": -0.015152023173868656, "Value Loss": 0.08449879288673401, "_runtime": 1071.4025073051453, "_timestamp": 1585595820.4191809, "_step": 453}
{"Episode reward": -91.18700868408652, "Episode length": 999, "Policy Loss": -0.1355283260345459, "Value Loss": 0.09163513034582138, "_runtime": 1072.9417703151703, "_timestamp": 1585595821.9584439, "_step": 454}
{"Episode reward": -89.9503608926335, "Episode length": 999, "Policy Loss": -0.12760573625564575, "Value Loss": 0.05379658192396164, "_runtime": 1074.1432394981384, "_timestamp": 1585595823.159913, "_step": 455}
{"Episode reward": 29.603284579083535, "Episode length": 783, "Policy Loss": 0.2537746727466583, "Value Loss": 12.854970932006836, "_runtime": 1075.6785788536072, "_timestamp": 1585595824.6952524, "_step": 456}
{"Episode reward": -89.63169321263068, "Episode length": 999, "Policy Loss": -0.21237778663635254, "Value Loss": 0.04518857225775719, "_runtime": 1077.2159848213196, "_timestamp": 1585595826.2326584, "_step": 457}
{"Episode reward": -88.30298802254677, "Episode length": 999, "Policy Loss": -0.2263393998146057, "Value Loss": 0.047458868473768234, "_runtime": 1078.7287175655365, "_timestamp": 1585595827.7453911, "_step": 458}
{"Episode reward": -88.8456781541935, "Episode length": 999, "Policy Loss": -0.31615447998046875, "Value Loss": 0.031879156827926636, "_runtime": 1080.2605967521667, "_timestamp": 1585595829.2772703, "_step": 459}
{"Episode reward": -87.17776955539227, "Episode length": 999, "Policy Loss": -0.31258267164230347, "Value Loss": 0.0809924378991127, "_runtime": 1081.796993970871, "_timestamp": 1585595830.8136675, "_step": 460}
{"Episode reward": -91.62798412996237, "Episode length": 999, "Policy Loss": -0.3269457519054413, "Value Loss": 0.03491578996181488, "_runtime": 1083.313369512558, "_timestamp": 1585595832.330043, "_step": 461}
{"Episode reward": 11.533206131866962, "Episode length": 986, "Policy Loss": 0.038363613188266754, "Value Loss": 10.130865097045898, "_runtime": 1084.8793008327484, "_timestamp": 1585595833.8959744, "_step": 462}
{"Episode reward": -94.15106296419921, "Episode length": 999, "Policy Loss": -0.3202766478061676, "Value Loss": 0.02162429504096508, "_runtime": 1086.4185409545898, "_timestamp": 1585595835.4352145, "_step": 463}
{"Episode reward": -93.88323089491288, "Episode length": 999, "Policy Loss": -0.3433550298213959, "Value Loss": 0.017890190705657005, "_runtime": 1087.9587087631226, "_timestamp": 1585595836.9753823, "_step": 464}
{"Episode reward": -91.91118620004035, "Episode length": 999, "Policy Loss": -0.3562396764755249, "Value Loss": 0.02352399192750454, "_runtime": 1089.487799167633, "_timestamp": 1585595838.5044727, "_step": 465}
{"Episode reward": -94.41188075963717, "Episode length": 999, "Policy Loss": -0.32610151171684265, "Value Loss": 0.01263978611677885, "_runtime": 1091.0257563591003, "_timestamp": 1585595840.04243, "_step": 466}
{"Episode reward": -90.92340789762686, "Episode length": 999, "Policy Loss": -0.36929476261138916, "Value Loss": 0.02905331179499626, "_runtime": 1092.5658004283905, "_timestamp": 1585595841.582474, "_step": 467}
{"Episode reward": -89.02161977639737, "Episode length": 999, "Policy Loss": -0.35701608657836914, "Value Loss": 0.0373753122985363, "_runtime": 1093.5457062721252, "_timestamp": 1585595842.5623798, "_step": 468}
{"Episode reward": 44.54794992856054, "Episode length": 630, "Policy Loss": 0.2174055576324463, "Value Loss": 15.938117027282715, "_runtime": 1095.0821280479431, "_timestamp": 1585595844.0988016, "_step": 469}
{"Episode reward": -87.80419712311162, "Episode length": 999, "Policy Loss": -0.44222497940063477, "Value Loss": 0.05782409757375717, "_runtime": 1096.6204075813293, "_timestamp": 1585595845.6370811, "_step": 470}
{"Episode reward": -90.71292613553402, "Episode length": 999, "Policy Loss": -0.3439926505088806, "Value Loss": 0.020048419013619423, "_runtime": 1098.1217091083527, "_timestamp": 1585595847.1383827, "_step": 471}
{"Episode reward": -92.42345310965648, "Episode length": 999, "Policy Loss": -0.38102924823760986, "Value Loss": 0.03208950534462929, "_runtime": 1099.6605231761932, "_timestamp": 1585595848.6771967, "_step": 472}
{"Episode reward": -91.80694569360789, "Episode length": 999, "Policy Loss": -0.37005120515823364, "Value Loss": 0.03456537425518036, "_runtime": 1101.1996138095856, "_timestamp": 1585595850.2162874, "_step": 473}
{"Episode reward": -90.75982884394692, "Episode length": 999, "Policy Loss": -0.3810960054397583, "Value Loss": 0.02417750097811222, "_runtime": 1102.7344863414764, "_timestamp": 1585595851.75116, "_step": 474}
{"Episode reward": -90.26171393103411, "Episode length": 999, "Policy Loss": -0.37621623277664185, "Value Loss": 0.02351374924182892, "_runtime": 1104.2630360126495, "_timestamp": 1585595853.2797096, "_step": 475}
{"Episode reward": -86.41504560854187, "Episode length": 999, "Policy Loss": -0.32157522439956665, "Value Loss": 0.02537275105714798, "_runtime": 1105.8036758899689, "_timestamp": 1585595854.8203495, "_step": 476}
{"Episode reward": -88.55986267379781, "Episode length": 999, "Policy Loss": -0.42622849345207214, "Value Loss": 0.031199568882584572, "_runtime": 1107.3675837516785, "_timestamp": 1585595856.3842573, "_step": 477}
{"Episode reward": -89.54020598532301, "Episode length": 999, "Policy Loss": -0.38605421781539917, "Value Loss": 0.023783354088664055, "_runtime": 1108.896678686142, "_timestamp": 1585595857.9133523, "_step": 478}
{"Episode reward": -90.53181498489167, "Episode length": 999, "Policy Loss": -0.3421761095523834, "Value Loss": 0.026150021702051163, "_runtime": 1110.4368605613708, "_timestamp": 1585595859.4535341, "_step": 479}
{"Episode reward": -90.16858911089987, "Episode length": 999, "Policy Loss": -0.3355063796043396, "Value Loss": 0.024061279371380806, "_runtime": 1111.9646165370941, "_timestamp": 1585595860.98129, "_step": 480}
{"Episode reward": -93.36293896783431, "Episode length": 999, "Policy Loss": -0.338867723941803, "Value Loss": 0.01286993082612753, "_runtime": 1113.4948995113373, "_timestamp": 1585595862.511573, "_step": 481}
{"Episode reward": -88.95949587022723, "Episode length": 999, "Policy Loss": -0.30944135785102844, "Value Loss": 0.02691689506173134, "_runtime": 1115.036242723465, "_timestamp": 1585595864.0529163, "_step": 482}
{"Episode reward": -89.49046724347926, "Episode length": 999, "Policy Loss": -0.3074207603931427, "Value Loss": 0.018756968900561333, "_runtime": 1116.563438653946, "_timestamp": 1585595865.5801122, "_step": 483}
{"Episode reward": -91.66472177275517, "Episode length": 999, "Policy Loss": -0.29492607712745667, "Value Loss": 0.01397163700312376, "_runtime": 1118.0897991657257, "_timestamp": 1585595867.1064727, "_step": 484}
{"Episode reward": -94.39556384782368, "Episode length": 999, "Policy Loss": -0.32161322236061096, "Value Loss": 0.013064611703157425, "_runtime": 1119.6300978660583, "_timestamp": 1585595868.6467714, "_step": 485}
{"Episode reward": -91.11503042265687, "Episode length": 999, "Policy Loss": -0.3038344085216522, "Value Loss": 0.013277905061841011, "_runtime": 1121.1672577857971, "_timestamp": 1585595870.1839314, "_step": 486}
{"Episode reward": -90.64289215969593, "Episode length": 999, "Policy Loss": -0.2605796158313751, "Value Loss": 0.015552233904600143, "_runtime": 1122.706193447113, "_timestamp": 1585595871.722867, "_step": 487}
{"Episode reward": -94.09383567694394, "Episode length": 999, "Policy Loss": -0.2956314980983734, "Value Loss": 0.013755039311945438, "_runtime": 1124.245765209198, "_timestamp": 1585595873.2624388, "_step": 488}
{"Episode reward": -91.41872870435508, "Episode length": 999, "Policy Loss": -0.290648490190506, "Value Loss": 0.014122150838375092, "_runtime": 1125.7856137752533, "_timestamp": 1585595874.8022873, "_step": 489}
{"Episode reward": -93.27515958274843, "Episode length": 999, "Policy Loss": -0.3022940754890442, "Value Loss": 0.01193836610764265, "_runtime": 1127.3245043754578, "_timestamp": 1585595876.341178, "_step": 490}
{"Episode reward": -89.28551938249161, "Episode length": 999, "Policy Loss": -0.24682395160198212, "Value Loss": 0.02234777808189392, "_runtime": 1128.8633482456207, "_timestamp": 1585595877.8800218, "_step": 491}
{"Episode reward": -87.34026309147131, "Episode length": 999, "Policy Loss": -0.21406273543834686, "Value Loss": 0.026355821639299393, "_runtime": 1130.4347326755524, "_timestamp": 1585595879.4514062, "_step": 492}
{"Episode reward": -88.52222748399782, "Episode length": 999, "Policy Loss": -0.2711968421936035, "Value Loss": 0.01129432488232851, "_runtime": 1131.973159790039, "_timestamp": 1585595880.9898334, "_step": 493}
{"Episode reward": -89.49852550810193, "Episode length": 999, "Policy Loss": -0.23651531338691711, "Value Loss": 0.01697133667767048, "_runtime": 1133.5116682052612, "_timestamp": 1585595882.5283418, "_step": 494}
{"Episode reward": -88.91514770278485, "Episode length": 999, "Policy Loss": -0.2695186138153076, "Value Loss": 0.022272715345025063, "_runtime": 1135.0507853031158, "_timestamp": 1585595884.0674589, "_step": 495}
{"Episode reward": -94.26290861658677, "Episode length": 999, "Policy Loss": -0.27080515027046204, "Value Loss": 0.011924385093152523, "_runtime": 1136.5776617527008, "_timestamp": 1585595885.5943353, "_step": 496}
{"Episode reward": -86.82375334669106, "Episode length": 999, "Policy Loss": -0.2278749942779541, "Value Loss": 0.01856943964958191, "_runtime": 1138.108749628067, "_timestamp": 1585595887.1254232, "_step": 497}
{"Episode reward": -94.42551648515919, "Episode length": 999, "Policy Loss": -0.29395928978919983, "Value Loss": 0.008980941027402878, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832, -0.8324284553527832]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0], "bins": [-9.070456504821777, -8.907968521118164, -8.745481491088867, -8.582993507385254, -8.420506477355957, -8.258018493652344, -8.095531463623047, -7.933043479919434, -7.7705559730529785, -7.608068466186523, -7.445580959320068, -7.283093452453613, -7.120605945587158, -6.958118438720703, -6.79563045501709, -6.633143424987793, -6.47065544128418, -6.308168411254883, -6.1456804275512695, -5.9831929206848145, -5.820705413818359, -5.658217906951904, -5.495730400085449, -5.333242893218994, -5.170755386352539, -5.008267879486084, -4.845780372619629, -4.683292388916016, -4.5208048820495605, -4.3583173751831055, -4.19582986831665, -4.033342361450195, -3.8708548545837402, -3.708367347717285, -3.54587984085083, -3.383392333984375, -3.22090482711792, -3.058417320251465, -2.8959293365478516, -2.7334418296813965, -2.5709543228149414, -2.4084668159484863, -2.2459793090820312, -2.083491802215576, -1.921004295349121, -1.758516788482666, -1.596029281616211, -1.4335417747497559, -1.2710542678833008, -1.1085662841796875, -0.9460792541503906, -0.7835912704467773, -0.6211042404174805, -0.4586162567138672, -0.2961282730102539, -0.13364124298095703, 0.02884674072265625, 0.19133377075195312, 0.3538217544555664, 0.5163087844848633, 0.6787967681884766, 0.8412837982177734, 1.0037717819213867, 1.1662588119506836, 1.3287467956542969]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2580835819244385, -0.25194716453552246, -0.24581077694892883, -0.23967435956001282, -0.233537957072258, -0.22740155458450317, -0.22126515209674835, -0.21512874960899353, -0.2089923471212387, -0.2028559446334839, -0.19671952724456787, -0.19058313965797424, -0.18444672226905823, -0.1783103197813034, -0.17217391729354858, -0.16603749990463257, -0.15990111231803894, -0.15376469492912292, -0.1476282924413681, -0.14149188995361328, -0.13535548746585846, -0.12921908497810364, -0.12308268249034882, -0.1169462651014328, -0.11080986261367798, -0.10467346012592316, -0.09853705763816833, -0.09240065515041351, -0.08626425266265869, -0.08012783527374268, -0.07399143278598785, -0.06785503029823303, -0.06171862781047821, -0.05558222532272339, -0.04944582283496857, -0.043309420347213745, -0.03717300295829773, -0.031036600470542908, -0.024900197982788086, -0.018763795495033264, -0.012627393007278442, -0.006490975618362427, -0.00035458803176879883, 0.005781829357147217, 0.011918216943740845, 0.01805463433265686, 0.024191051721572876, 0.030327439308166504, 0.03646385669708252, 0.04260024428367615, 0.04873666167259216, 0.05487304925918579, 0.06100946664810181, 0.06714588403701782, 0.07328227162361145, 0.07941868901252747, 0.0855550765991211, 0.09169149398803711, 0.09782791137695312, 0.10396429896354675, 0.11010071635246277, 0.1162371039390564, 0.12237352132797241, 0.12850990891456604, 0.13464632630348206]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 6.0, 11.0, 7.0, 8.0, 9.0, 5.0, 11.0, 11.0, 14.0, 21.0, 14.0, 26.0, 20.0, 17.0, 8.0, 47.0, 51.0, 15.0, 2.0, 7.0, 11.0, 20.0, 24.0, 15.0, 22.0, 15.0, 15.0, 7.0, 9.0, 8.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0], "bins": [-0.295221745967865, -0.2874964773654938, -0.27977120876312256, -0.27204596996307373, -0.2643207013607025, -0.2565954327583313, -0.24887016415596008, -0.24114489555358887, -0.23341964185237885, -0.22569438815116882, -0.2179691195487976, -0.2102438509464264, -0.20251858234405518, -0.19479332864284515, -0.18706806004047394, -0.17934280633926392, -0.1716175377368927, -0.16389226913452148, -0.15616701543331146, -0.14844174683094025, -0.14071649312973022, -0.132991224527359, -0.1252659559249878, -0.11754070222377777, -0.10981543362140656, -0.10209016501903534, -0.09436491131782532, -0.0866396427154541, -0.07891437411308289, -0.07118912041187286, -0.06346385180950165, -0.055738598108291626, -0.04801332950592041, -0.040288060903549194, -0.03256279230117798, -0.02483755350112915, -0.017112284898757935, -0.009387016296386719, -0.001661747694015503, 0.006063520908355713, 0.013788759708404541, 0.021514028310775757, 0.029239296913146973, 0.03696456551551819, 0.044689834117889404, 0.05241510272026062, 0.06014034152030945, 0.06786561012268066, 0.07559087872505188, 0.0833161473274231, 0.09104141592979431, 0.09876665472984314, 0.10649192333221436, 0.11421719193458557, 0.12194246053695679, 0.129667729139328, 0.13739299774169922, 0.14511823654174805, 0.15284350514411926, 0.16056877374649048, 0.1682940423488617, 0.1760193109512329, 0.18374454975128174, 0.19146981835365295, 0.19919508695602417]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5743756890296936, -0.5501835346221924, -0.5259914398193359, -0.5017992854118347, -0.4776071310043335, -0.4534149765968323, -0.42922285199165344, -0.4050307273864746, -0.3808385729789734, -0.35664641857147217, -0.33245429396629333, -0.3082621693611145, -0.2840700149536133, -0.25987786054611206, -0.23568573594093323, -0.2114936113357544, -0.18730145692825317, -0.16310930252075195, -0.13891717791557312, -0.11472505331039429, -0.09053289890289307, -0.06634074449539185, -0.0421486496925354, -0.01795649528503418, 0.006235659122467041, 0.03042781352996826, 0.05461996793746948, 0.07881206274032593, 0.10300421714782715, 0.12719637155532837, 0.15138846635818481, 0.17558062076568604, 0.19977277517318726, 0.22396492958068848, 0.2481570839881897, 0.27234917879104614, 0.29654133319854736, 0.3207334876060486, 0.34492558240890503, 0.36911773681640625, 0.39330989122390747, 0.4175020456314087, 0.4416942000389099, 0.46588629484176636, 0.4900783896446228, 0.5142706036567688, 0.5384626984596252, 0.5626549124717712, 0.5868470072746277, 0.6110391020774841, 0.6352313160896301, 0.6594234108924866, 0.6836156249046326, 0.707807719707489, 0.7319998145103455, 0.7561920285224915, 0.7803841233253479, 0.8045762181282043, 0.8287684321403503, 0.8529605269432068, 0.8771526217460632, 0.9013448357582092, 0.9255369305610657, 0.9497291445732117, 0.9739212393760681]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.16922631859779358, -0.16342565417289734, -0.1576249897480011, -0.15182432532310486, -0.14602366089820862, -0.14022299647331238, -0.13442233204841614, -0.1286216676235199, -0.12282099574804306, -0.11702033132314682, -0.11121966689825058, -0.10541900247335434, -0.0996183305978775, -0.09381766617298126, -0.08801700174808502, -0.08221633732318878, -0.07641567289829254, -0.0706150084733963, -0.06481434404850006, -0.05901367962360382, -0.05321301519870758, -0.04741234332323074, -0.0416116863489151, -0.03581102192401886, -0.030010342597961426, -0.024209678173065186, -0.018409013748168945, -0.012608349323272705, -0.006807684898376465, -0.0010070204734802246, 0.004793643951416016, 0.010594308376312256, 0.016394972801208496, 0.022195637226104736, 0.027996301651000977, 0.03379696607589722, 0.03959763050079346, 0.0453982949256897, 0.05119895935058594, 0.05699962377548218, 0.06280028820037842, 0.06860096752643585, 0.07440163195133209, 0.08020229637622833, 0.08600294589996338, 0.09180361032485962, 0.09760427474975586, 0.1034049391746521, 0.10920563340187073, 0.11500629782676697, 0.12080696225166321, 0.12660762667655945, 0.1324082911014557, 0.13820895552635193, 0.14400961995124817, 0.1498102843761444, 0.15561094880104065, 0.1614116132259369, 0.16721227765083313, 0.17301294207572937, 0.1788136065006256, 0.18461427092552185, 0.1904149353504181, 0.19621559977531433, 0.20201626420021057]}, "_runtime": 1139.6457965373993, "_timestamp": 1585595888.66247, "_step": 498}
{"Episode reward": -93.92198069520335, "Episode length": 999, "Policy Loss": -0.2875214219093323, "Value Loss": 0.011749815195798874, "_runtime": 1139.6457965373993, "_timestamp": 1585595888.66247, "_step": 499}
