{"Episode reward": -96.86190245660765, "Episode length": 999, "Policy Loss": 0.008133312687277794, "Value Loss": 0.0289850402623415, "_runtime": 17153.839371919632, "_timestamp": 1585614523.4722414, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8918541073799133, "Value Loss": 20.43915367126465, "_runtime": 17155.178950309753, "_timestamp": 1585614524.8118198, "_step": 1}
{"Episode reward": 12.26745087892121, "Episode length": 880, "Policy Loss": -4.868675708770752, "Value Loss": 450.134033203125, "_runtime": 17156.76924943924, "_timestamp": 1585614526.402119, "_step": 2}
{"Episode reward": -98.77715679133789, "Episode length": 999, "Policy Loss": -3.957015037536621, "Value Loss": 220.90538024902344, "_runtime": 17158.304200172424, "_timestamp": 1585614527.9370697, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5846259593963623, "Value Loss": 9.689653396606445, "_runtime": 17159.843880176544, "_timestamp": 1585614529.4767497, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1724563837051392, "Value Loss": 3.5537831783294678, "_runtime": 17161.437670469284, "_timestamp": 1585614531.07054, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5939136743545532, "Value Loss": 1388.1751708984375, "_runtime": 17162.98909664154, "_timestamp": 1585614532.6219661, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7292479276657104, "Value Loss": 0.07707508653402328, "_runtime": 17164.529579401016, "_timestamp": 1585614534.162449, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7619080543518066, "Value Loss": 18.971435546875, "_runtime": 17166.119879722595, "_timestamp": 1585614535.7527492, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.656454086303711, "Value Loss": 19.78858757019043, "_runtime": 17167.69641184807, "_timestamp": 1585614537.3292813, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.097465515136719, "Value Loss": 0.6860289573669434, "_runtime": 17169.242384195328, "_timestamp": 1585614538.8752537, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.115551948547363, "Value Loss": 0.7087268829345703, "_runtime": 17170.870459079742, "_timestamp": 1585614540.5033286, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.51369857788086, "Value Loss": 111.30892181396484, "_runtime": 17172.455372333527, "_timestamp": 1585614542.0882418, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.728655815124512, "Value Loss": 24.392908096313477, "_runtime": 17174.029210090637, "_timestamp": 1585614543.6620796, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 11.748978614807129, "Value Loss": 12.785528182983398, "_runtime": 17175.627198457718, "_timestamp": 1585614545.260068, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 13.759037971496582, "Value Loss": 37.00351333618164, "_runtime": 17177.212991714478, "_timestamp": 1585614546.8458612, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 12.623697280883789, "Value Loss": 157.37811279296875, "_runtime": 17178.790195703506, "_timestamp": 1585614548.4230652, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.851773262023926, "Value Loss": 141.22653198242188, "_runtime": 17180.386208295822, "_timestamp": 1585614550.0190778, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 10.055020332336426, "Value Loss": 46.5212287902832, "_runtime": 17181.97945165634, "_timestamp": 1585614551.6123211, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 8.101984024047852, "Value Loss": 223.31817626953125, "_runtime": 17183.56266283989, "_timestamp": 1585614553.1955323, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.748079299926758, "Value Loss": 20.113327026367188, "_runtime": 17185.162301778793, "_timestamp": 1585614554.7951713, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5248792171478271, "Value Loss": 90.82392883300781, "_runtime": 17186.752655744553, "_timestamp": 1585614556.3855252, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21296846866607666, "Value Loss": 60.90938949584961, "_runtime": 17188.32382297516, "_timestamp": 1585614557.9566925, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40782108902931213, "Value Loss": 15.045109748840332, "_runtime": 17189.91136956215, "_timestamp": 1585614559.544239, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25365886092185974, "Value Loss": 0.7149777412414551, "_runtime": 17191.50377058983, "_timestamp": 1585614561.13664, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.46868234872817993, "Value Loss": 47.86605453491211, "_runtime": 17193.09117078781, "_timestamp": 1585614562.7240403, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.015952490270137787, "Value Loss": 18.93646812438965, "_runtime": 17194.71283555031, "_timestamp": 1585614564.345705, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7646034955978394, "Value Loss": 16.486087799072266, "_runtime": 17196.309250354767, "_timestamp": 1585614565.9421198, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.334989547729492, "Value Loss": 32.75679016113281, "_runtime": 17197.885415315628, "_timestamp": 1585614567.5182848, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5990052223205566, "Value Loss": 12.051526069641113, "_runtime": 17199.45718884468, "_timestamp": 1585614569.0900583, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.141944646835327, "Value Loss": 2.749119281768799, "_runtime": 17201.0313873291, "_timestamp": 1585614570.6642568, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6024162769317627, "Value Loss": 0.4376389682292938, "_runtime": 17202.609616041183, "_timestamp": 1585614572.2424855, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8455730676651, "Value Loss": 7.193477153778076, "_runtime": 17204.189388513565, "_timestamp": 1585614573.822258, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9350648522377014, "Value Loss": 31.33949089050293, "_runtime": 17205.781980276108, "_timestamp": 1585614575.4148498, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37059900164604187, "Value Loss": 5.041018009185791, "_runtime": 17207.36801314354, "_timestamp": 1585614577.0008826, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2301691621541977, "Value Loss": 15.573518753051758, "_runtime": 17208.962431430817, "_timestamp": 1585614578.595301, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4502418339252472, "Value Loss": 10.133281707763672, "_runtime": 17210.556166648865, "_timestamp": 1585614580.1890361, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9099863171577454, "Value Loss": 5.896579265594482, "_runtime": 17212.14241361618, "_timestamp": 1585614581.775283, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.585170865058899, "Value Loss": 1.3443540334701538, "_runtime": 17213.735956192017, "_timestamp": 1585614583.3688257, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2353971004486084, "Value Loss": 0.15125267207622528, "_runtime": 17215.331154346466, "_timestamp": 1585614584.9640238, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8490207195281982, "Value Loss": 0.08998952060937881, "_runtime": 17216.909145593643, "_timestamp": 1585614586.542015, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3362696170806885, "Value Loss": 7.305768966674805, "_runtime": 17218.529876232147, "_timestamp": 1585614588.1627457, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.5350003242492676, "Value Loss": 10.757863998413086, "_runtime": 17220.114642620087, "_timestamp": 1585614589.747512, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.46547269821167, "Value Loss": 8.855899810791016, "_runtime": 17221.691774845123, "_timestamp": 1585614591.3246443, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3137001991271973, "Value Loss": 17.527769088745117, "_runtime": 17223.28835439682, "_timestamp": 1585614592.9212239, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6556644439697266, "Value Loss": 4.1153974533081055, "_runtime": 17224.8810403347, "_timestamp": 1585614594.5139098, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9247772693634033, "Value Loss": 0.6478149890899658, "_runtime": 17226.470266103745, "_timestamp": 1585614596.1031356, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3891597986221313, "Value Loss": 1.215863823890686, "_runtime": 17228.066984176636, "_timestamp": 1585614597.6998537, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.975640058517456, "Value Loss": 0.4881114959716797, "_runtime": 17229.653027534485, "_timestamp": 1585614599.285897, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6000558137893677, "Value Loss": 8.77107048034668, "_runtime": 17231.253512382507, "_timestamp": 1585614600.8863819, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4467087984085083, "Value Loss": 5.277871131896973, "_runtime": 17232.849959135056, "_timestamp": 1585614602.4828286, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32167571783065796, "Value Loss": 6.483039379119873, "_runtime": 17234.45344233513, "_timestamp": 1585614604.0863118, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2203855663537979, "Value Loss": 4.878040313720703, "_runtime": 17236.041781187057, "_timestamp": 1585614605.6746507, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1412753015756607, "Value Loss": 7.918139457702637, "_runtime": 17237.637410879135, "_timestamp": 1585614607.2702804, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008838670328259468, "Value Loss": 3.9315056800842285, "_runtime": 17239.231914281845, "_timestamp": 1585614608.8647838, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17449136078357697, "Value Loss": 2.687490940093994, "_runtime": 17240.821787834167, "_timestamp": 1585614610.4546573, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37993839383125305, "Value Loss": 1.2334226369857788, "_runtime": 17242.457124471664, "_timestamp": 1585614612.089994, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5722132325172424, "Value Loss": 0.33536526560783386, "_runtime": 17244.05020070076, "_timestamp": 1585614613.6830702, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7760303020477295, "Value Loss": 0.8315385580062866, "_runtime": 17245.639166116714, "_timestamp": 1585614615.2720356, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9738032817840576, "Value Loss": 0.36602890491485596, "_runtime": 17247.23430109024, "_timestamp": 1585614616.8671706, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1680935621261597, "Value Loss": 0.01552103366702795, "_runtime": 17248.817078351974, "_timestamp": 1585614618.4499478, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3515708446502686, "Value Loss": 0.018165798857808113, "_runtime": 17250.382774591446, "_timestamp": 1585614620.015644, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5201730728149414, "Value Loss": 0.0336788035929203, "_runtime": 17251.966661691666, "_timestamp": 1585614621.5995312, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6746513843536377, "Value Loss": 0.08266227692365646, "_runtime": 17253.548597097397, "_timestamp": 1585614623.1814666, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.819684624671936, "Value Loss": 0.40421032905578613, "_runtime": 17255.14624929428, "_timestamp": 1585614624.7791188, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9107475280761719, "Value Loss": 0.2178458273410797, "_runtime": 17256.74892091751, "_timestamp": 1585614626.3817904, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0516347885131836, "Value Loss": 0.40133383870124817, "_runtime": 17258.348386764526, "_timestamp": 1585614627.9812562, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.14227294921875, "Value Loss": 0.4776993691921234, "_runtime": 17259.953380584717, "_timestamp": 1585614629.58625, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2252871990203857, "Value Loss": 0.7101079821586609, "_runtime": 17261.566824436188, "_timestamp": 1585614631.199694, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.264216899871826, "Value Loss": 1.7638448476791382, "_runtime": 17263.178051948547, "_timestamp": 1585614632.8109214, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3115410804748535, "Value Loss": 0.08236664533615112, "_runtime": 17264.813641548157, "_timestamp": 1585614634.446511, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.348435640335083, "Value Loss": 0.05586070567369461, "_runtime": 17266.415901184082, "_timestamp": 1585614636.0487707, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3919119834899902, "Value Loss": 0.05417703092098236, "_runtime": 17268.025825738907, "_timestamp": 1585614637.6586952, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.419471025466919, "Value Loss": 0.11978461593389511, "_runtime": 17269.629019498825, "_timestamp": 1585614639.261889, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.436779737472534, "Value Loss": 0.2959706783294678, "_runtime": 17271.241394996643, "_timestamp": 1585614640.8742645, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4359030723571777, "Value Loss": 0.13894277811050415, "_runtime": 17272.835392475128, "_timestamp": 1585614642.468262, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.422097682952881, "Value Loss": 0.43863943219184875, "_runtime": 17274.42230606079, "_timestamp": 1585614644.0551755, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4327926635742188, "Value Loss": 0.1050724983215332, "_runtime": 17276.02747797966, "_timestamp": 1585614645.6603475, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.425645112991333, "Value Loss": 0.09697958827018738, "_runtime": 17277.620955705643, "_timestamp": 1585614647.2538252, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.413943290710449, "Value Loss": 0.08667948842048645, "_runtime": 17279.210326194763, "_timestamp": 1585614648.8431957, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3921384811401367, "Value Loss": 0.06421556323766708, "_runtime": 17280.792901992798, "_timestamp": 1585614650.4257715, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3798022270202637, "Value Loss": 0.05448193475604057, "_runtime": 17282.38612484932, "_timestamp": 1585614652.0189943, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.354433298110962, "Value Loss": 0.050498392432928085, "_runtime": 17283.980169057846, "_timestamp": 1585614653.6130385, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3333792686462402, "Value Loss": 0.048596128821372986, "_runtime": 17285.575187921524, "_timestamp": 1585614655.2080574, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.299459218978882, "Value Loss": 0.062350668013095856, "_runtime": 17287.18021798134, "_timestamp": 1585614656.8130875, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2715508937835693, "Value Loss": 0.06601583957672119, "_runtime": 17288.80587220192, "_timestamp": 1585614658.4387417, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.238947868347168, "Value Loss": 0.06707850843667984, "_runtime": 17290.4120221138, "_timestamp": 1585614660.0448916, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.206002950668335, "Value Loss": 0.05518760159611702, "_runtime": 17292.003873348236, "_timestamp": 1585614661.6367428, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1742677688598633, "Value Loss": 0.04431941360235214, "_runtime": 17293.58826804161, "_timestamp": 1585614663.2211375, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.137582778930664, "Value Loss": 0.056032612919807434, "_runtime": 17295.176035404205, "_timestamp": 1585614664.808905, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.096271514892578, "Value Loss": 0.08050962537527084, "_runtime": 17296.747668743134, "_timestamp": 1585614666.3805382, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0490095615386963, "Value Loss": 0.19913826882839203, "_runtime": 17298.328501224518, "_timestamp": 1585614667.9613707, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.004528522491455, "Value Loss": 0.08219584822654724, "_runtime": 17299.901936769485, "_timestamp": 1585614669.5348063, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9537638425827026, "Value Loss": 0.07692906260490417, "_runtime": 17301.48759508133, "_timestamp": 1585614671.1204646, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8999826908111572, "Value Loss": 0.07079549878835678, "_runtime": 17303.07783794403, "_timestamp": 1585614672.7107074, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8451895713806152, "Value Loss": 0.04027962312102318, "_runtime": 17304.671565055847, "_timestamp": 1585614674.3044345, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7845110893249512, "Value Loss": 0.07569985091686249, "_runtime": 17306.265655755997, "_timestamp": 1585614675.8985252, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.733375906944275, "Value Loss": 0.03906336799263954, "_runtime": 17307.854788541794, "_timestamp": 1585614677.487658, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6775373220443726, "Value Loss": 0.04226166754961014, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17309.451598882675, "_timestamp": 1585614679.0844684, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.621181607246399, "Value Loss": 0.03777170926332474, "_runtime": 17311.03085875511, "_timestamp": 1585614680.6637282, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5608328580856323, "Value Loss": 0.06597739458084106, "_runtime": 17312.630014181137, "_timestamp": 1585614682.2628837, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4983830451965332, "Value Loss": 0.033020466566085815, "_runtime": 17314.211891889572, "_timestamp": 1585614683.8447614, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4380494356155396, "Value Loss": 0.025812046602368355, "_runtime": 17315.789665460587, "_timestamp": 1585614685.422535, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3782795667648315, "Value Loss": 0.017359072342514992, "_runtime": 17317.377602100372, "_timestamp": 1585614687.0104716, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3201805353164673, "Value Loss": 0.018522106111049652, "_runtime": 17318.97220802307, "_timestamp": 1585614688.6050775, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2638965845108032, "Value Loss": 0.014892689883708954, "_runtime": 17320.552011489868, "_timestamp": 1585614690.184881, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2085189819335938, "Value Loss": 0.015142434276640415, "_runtime": 17322.116426706314, "_timestamp": 1585614691.7492962, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1580942869186401, "Value Loss": 0.016904328018426895, "_runtime": 17323.71046590805, "_timestamp": 1585614693.3433354, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.112389087677002, "Value Loss": 0.014819800853729248, "_runtime": 17325.30092525482, "_timestamp": 1585614694.9337947, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0664970874786377, "Value Loss": 0.012038879096508026, "_runtime": 17326.884839057922, "_timestamp": 1585614696.5177085, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.022696614265442, "Value Loss": 0.011520939879119396, "_runtime": 17328.476938724518, "_timestamp": 1585614698.1098082, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9811927080154419, "Value Loss": 0.016166208311915398, "_runtime": 17330.066823244095, "_timestamp": 1585614699.6996927, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9417006373405457, "Value Loss": 0.01647118851542473, "_runtime": 17331.654076337814, "_timestamp": 1585614701.2869458, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9024595022201538, "Value Loss": 0.008941052481532097, "_runtime": 17333.24740242958, "_timestamp": 1585614702.880272, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8677510619163513, "Value Loss": 0.006970259826630354, "_runtime": 17334.82685661316, "_timestamp": 1585614704.459726, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8335692882537842, "Value Loss": 0.026282375678420067, "_runtime": 17336.455196142197, "_timestamp": 1585614706.0880656, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8038344979286194, "Value Loss": 0.0062313624657690525, "_runtime": 17338.042500972748, "_timestamp": 1585614707.6753705, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7743264436721802, "Value Loss": 0.011576411314308643, "_runtime": 17339.63446688652, "_timestamp": 1585614709.2673364, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7504317164421082, "Value Loss": 0.011192942969501019, "_runtime": 17341.209290742874, "_timestamp": 1585614710.8421602, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7253342866897583, "Value Loss": 0.012927682138979435, "_runtime": 17342.803766727448, "_timestamp": 1585614712.4366362, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6996267437934875, "Value Loss": 0.006314394064247608, "_runtime": 17344.38395524025, "_timestamp": 1585614714.0168247, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6776167750358582, "Value Loss": 0.0044301836751401424, "_runtime": 17345.949000597, "_timestamp": 1585614715.58187, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6549346446990967, "Value Loss": 0.0150733208283782, "_runtime": 17347.53940629959, "_timestamp": 1585614717.1722758, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6384598016738892, "Value Loss": 0.008421290665864944, "_runtime": 17349.127155065536, "_timestamp": 1585614718.7600245, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6208829879760742, "Value Loss": 0.0056233336217701435, "_runtime": 17350.72177386284, "_timestamp": 1585614720.3546433, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6025128364562988, "Value Loss": 0.006365434266626835, "_runtime": 17352.323407649994, "_timestamp": 1585614721.9562771, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5855887532234192, "Value Loss": 0.007170530501753092, "_runtime": 17353.922593832016, "_timestamp": 1585614723.5554633, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5710309743881226, "Value Loss": 0.005712867248803377, "_runtime": 17355.518807411194, "_timestamp": 1585614725.151677, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5567951202392578, "Value Loss": 0.005308849271386862, "_runtime": 17357.12517929077, "_timestamp": 1585614726.7580488, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5450271964073181, "Value Loss": 0.0033936609979718924, "_runtime": 17358.71486067772, "_timestamp": 1585614728.3477302, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5313907265663147, "Value Loss": 0.0036524177994579077, "_runtime": 17360.35240483284, "_timestamp": 1585614729.9852743, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5194337964057922, "Value Loss": 0.002783175092190504, "_runtime": 17361.95894265175, "_timestamp": 1585614731.5918121, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5064700245857239, "Value Loss": 0.0027047882322221994, "_runtime": 17363.56121325493, "_timestamp": 1585614733.1940827, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4939168095588684, "Value Loss": 0.0024327170103788376, "_runtime": 17365.147674798965, "_timestamp": 1585614734.7805443, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.479565292596817, "Value Loss": 0.0023210810031741858, "_runtime": 17366.727831363678, "_timestamp": 1585614736.3607008, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4661639928817749, "Value Loss": 0.002709584543481469, "_runtime": 17368.33038878441, "_timestamp": 1585614737.9632583, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4511372148990631, "Value Loss": 0.004794015083462, "_runtime": 17369.927247047424, "_timestamp": 1585614739.5601165, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4363931715488434, "Value Loss": 0.002675827359780669, "_runtime": 17371.539914369583, "_timestamp": 1585614741.1727839, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42017626762390137, "Value Loss": 0.003064132994040847, "_runtime": 17373.121109485626, "_timestamp": 1585614742.753979, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4033680260181427, "Value Loss": 0.003770278301090002, "_runtime": 17374.684920310974, "_timestamp": 1585614744.3177898, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3865209221839905, "Value Loss": 0.0018518331926316023, "_runtime": 17376.26318693161, "_timestamp": 1585614745.8960564, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.36833512783050537, "Value Loss": 0.0013508267002180219, "_runtime": 17377.829697847366, "_timestamp": 1585614747.4625673, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3513978123664856, "Value Loss": 0.001473473384976387, "_runtime": 17379.403285741806, "_timestamp": 1585614749.0361552, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3352833092212677, "Value Loss": 0.001126402523368597, "_runtime": 17380.979756116867, "_timestamp": 1585614750.6126256, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3187761902809143, "Value Loss": 0.0010830300161615014, "_runtime": 17382.587728261948, "_timestamp": 1585614752.2205977, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.30122148990631104, "Value Loss": 0.0024251844733953476, "_runtime": 17384.160544633865, "_timestamp": 1585614753.793414, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.28618764877319336, "Value Loss": 0.0007388143567368388, "_runtime": 17385.742590904236, "_timestamp": 1585614755.3754604, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2688998281955719, "Value Loss": 0.0012396000092849135, "_runtime": 17387.320623874664, "_timestamp": 1585614756.9534934, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25431907176971436, "Value Loss": 0.0006012923549860716, "_runtime": 17388.888063192368, "_timestamp": 1585614758.5209327, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23942218720912933, "Value Loss": 0.0005339689087122679, "_runtime": 17390.46052670479, "_timestamp": 1585614760.0933962, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2235954999923706, "Value Loss": 0.001059513189829886, "_runtime": 17392.03090596199, "_timestamp": 1585614761.6637754, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2099698930978775, "Value Loss": 0.0005901834229007363, "_runtime": 17393.597190141678, "_timestamp": 1585614763.2300596, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1968390792608261, "Value Loss": 0.0008882029796950519, "_runtime": 17395.16530418396, "_timestamp": 1585614764.7981737, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1850578486919403, "Value Loss": 0.0004699791024904698, "_runtime": 17396.73633956909, "_timestamp": 1585614766.369209, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17223377525806427, "Value Loss": 0.0011982067953795195, "_runtime": 17398.302523851395, "_timestamp": 1585614767.9353933, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1610461175441742, "Value Loss": 0.0009649868588894606, "_runtime": 17399.879611968994, "_timestamp": 1585614769.5124815, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15162178874015808, "Value Loss": 0.0004035714373458177, "_runtime": 17401.456491947174, "_timestamp": 1585614771.0893614, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1420157253742218, "Value Loss": 0.0007754092221148312, "_runtime": 17403.028876781464, "_timestamp": 1585614772.6617463, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.133032888174057, "Value Loss": 0.0006765129510313272, "_runtime": 17404.60563635826, "_timestamp": 1585614774.2385058, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12491419166326523, "Value Loss": 0.0003405997413210571, "_runtime": 17406.228666067123, "_timestamp": 1585614775.8615355, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11597787588834763, "Value Loss": 0.0010159739758819342, "_runtime": 17407.806485176086, "_timestamp": 1585614777.4393547, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10919211059808731, "Value Loss": 0.0007977541536092758, "_runtime": 17409.387526988983, "_timestamp": 1585614779.0203965, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10246964544057846, "Value Loss": 0.0003999479522462934, "_runtime": 17410.97358226776, "_timestamp": 1585614780.6064517, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0966794341802597, "Value Loss": 0.000620765786152333, "_runtime": 17412.556046009064, "_timestamp": 1585614782.1889155, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09091416746377945, "Value Loss": 0.0007641927804797888, "_runtime": 17414.133282661438, "_timestamp": 1585614783.7661521, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08602267503738403, "Value Loss": 0.0004167825391050428, "_runtime": 17415.722976207733, "_timestamp": 1585614785.3558457, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08064262568950653, "Value Loss": 0.0006553190178237855, "_runtime": 17417.29793715477, "_timestamp": 1585614786.9308066, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07566885650157928, "Value Loss": 0.0005926502635702491, "_runtime": 17418.88689184189, "_timestamp": 1585614788.5197613, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.070778988301754, "Value Loss": 0.0006989833200350404, "_runtime": 17420.476513385773, "_timestamp": 1585614790.1093829, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06573809683322906, "Value Loss": 0.0007869472028687596, "_runtime": 17422.042985200882, "_timestamp": 1585614791.6758547, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06120847165584564, "Value Loss": 8.056788647081703e-05, "_runtime": 17423.637940645218, "_timestamp": 1585614793.2708101, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05670425668358803, "Value Loss": 7.453319994965568e-05, "_runtime": 17425.216307878494, "_timestamp": 1585614794.8491774, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0512860044836998, "Value Loss": 0.00041794549906626344, "_runtime": 17426.802010536194, "_timestamp": 1585614796.43488, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0476563461124897, "Value Loss": 0.00010301271686330438, "_runtime": 17428.393906354904, "_timestamp": 1585614798.0267758, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.04315586015582085, "Value Loss": 7.709767669439316e-05, "_runtime": 17430.020431041718, "_timestamp": 1585614799.6533005, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0395038016140461, "Value Loss": 0.000126560204080306, "_runtime": 17431.597131967545, "_timestamp": 1585614801.2300014, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.034992534667253494, "Value Loss": 0.0005829667788930237, "_runtime": 17433.18641090393, "_timestamp": 1585614802.8192804, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.032166268676519394, "Value Loss": 7.265368913067505e-05, "_runtime": 17434.78343486786, "_timestamp": 1585614804.4163043, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.028293468058109283, "Value Loss": 4.596408689394593e-05, "_runtime": 17436.365411043167, "_timestamp": 1585614805.9982805, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02558346837759018, "Value Loss": 0.00012044893082929775, "_runtime": 17437.975274801254, "_timestamp": 1585614807.6081443, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.021658413112163544, "Value Loss": 0.00011755819286918268, "_runtime": 17439.580348968506, "_timestamp": 1585614809.2132185, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01990821212530136, "Value Loss": 0.00011334998271195218, "_runtime": 17441.170765399933, "_timestamp": 1585614810.803635, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0169262383133173, "Value Loss": 4.3569296394707635e-05, "_runtime": 17442.779941082, "_timestamp": 1585614812.4128106, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.015041107311844826, "Value Loss": 7.571127207484096e-05, "_runtime": 17444.38410949707, "_timestamp": 1585614814.016979, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01304974127560854, "Value Loss": 7.862973870942369e-05, "_runtime": 17445.985322475433, "_timestamp": 1585614815.618192, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.010451375506818295, "Value Loss": 0.0006559006869792938, "_runtime": 17447.591840982437, "_timestamp": 1585614817.2247105, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.008679792284965515, "Value Loss": 7.183658453868702e-05, "_runtime": 17449.199073314667, "_timestamp": 1585614818.8319428, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007652631960809231, "Value Loss": 4.7586290747858584e-05, "_runtime": 17450.80499625206, "_timestamp": 1585614820.4378657, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006143319886177778, "Value Loss": 4.7442485083593056e-05, "_runtime": 17452.41058397293, "_timestamp": 1585614822.0434535, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.004830023739486933, "Value Loss": 5.69343646930065e-05, "_runtime": 17454.056931495667, "_timestamp": 1585614823.689801, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.002943702507764101, "Value Loss": 0.0003951669204980135, "_runtime": 17455.651324748993, "_timestamp": 1585614825.2841942, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0026603711303323507, "Value Loss": 4.815246938960627e-05, "_runtime": 17457.24078154564, "_timestamp": 1585614826.873651, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.0009684726246632636, "Value Loss": 0.0003833455848507583, "_runtime": 17458.837810754776, "_timestamp": 1585614828.4706802, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.227906058280496e-06, "Value Loss": 0.0003738350060302764, "_runtime": 17460.43213224411, "_timestamp": 1585614830.0650017, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0005168820498511195, "Value Loss": 0.00010100022336700931, "_runtime": 17462.042850971222, "_timestamp": 1585614831.6757205, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001854581874795258, "Value Loss": 0.00021795328939333558, "_runtime": 17463.65025639534, "_timestamp": 1585614833.2831259, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025699881371110678, "Value Loss": 0.00030335038900375366, "_runtime": 17465.253040790558, "_timestamp": 1585614834.8859103, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0037141190841794014, "Value Loss": 0.0003427083429414779, "_runtime": 17466.849942922592, "_timestamp": 1585614836.4828124, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004136997275054455, "Value Loss": 0.00027787117869593203, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17468.446160316467, "_timestamp": 1585614838.0790298, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004924390465021133, "Value Loss": 4.3506286601768807e-05, "_runtime": 17470.05028486252, "_timestamp": 1585614839.6831543, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005213378928601742, "Value Loss": 4.8719481128500775e-05, "_runtime": 17471.6494512558, "_timestamp": 1585614841.2823207, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006650938652455807, "Value Loss": 0.0005070398328825831, "_runtime": 17473.237070798874, "_timestamp": 1585614842.8699403, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007113087456673384, "Value Loss": 0.00021680975623894483, "_runtime": 17474.8408100605, "_timestamp": 1585614844.4736795, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006970366463065147, "Value Loss": 8.435616473434493e-05, "_runtime": 17476.48685336113, "_timestamp": 1585614846.1197228, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007177366875112057, "Value Loss": 4.967968197888695e-05, "_runtime": 17478.073570013046, "_timestamp": 1585614847.7064395, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007674961816519499, "Value Loss": 0.00029144331347197294, "_runtime": 17479.67760324478, "_timestamp": 1585614849.3104727, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0077291494235396385, "Value Loss": 4.4952204916626215e-05, "_runtime": 17481.278716802597, "_timestamp": 1585614850.9115863, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008089952170848846, "Value Loss": 0.00017660431331023574, "_runtime": 17482.866676568985, "_timestamp": 1585614852.499546, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007276670075953007, "Value Loss": 0.00010059735359391198, "_runtime": 17484.46047616005, "_timestamp": 1585614854.0933456, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007451376412063837, "Value Loss": 0.00030747251003049314, "_runtime": 17486.053545713425, "_timestamp": 1585614855.6864152, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007699332665652037, "Value Loss": 0.00031662368564866483, "_runtime": 17487.642556905746, "_timestamp": 1585614857.2754264, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007111195474863052, "Value Loss": 5.42763045814354e-05, "_runtime": 17489.22860598564, "_timestamp": 1585614858.8614755, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006845962721854448, "Value Loss": 0.00012990976392757148, "_runtime": 17490.82018017769, "_timestamp": 1585614860.4530497, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006604103837162256, "Value Loss": 5.418142973212525e-05, "_runtime": 17492.418991088867, "_timestamp": 1585614862.0518606, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007254057563841343, "Value Loss": 0.0003724935813806951, "_runtime": 17494.004519939423, "_timestamp": 1585614863.6373894, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007429464720189571, "Value Loss": 0.0005531287752091885, "_runtime": 17495.590480804443, "_timestamp": 1585614865.2233503, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007682577706873417, "Value Loss": 0.00015338767843786627, "_runtime": 17497.16695690155, "_timestamp": 1585614866.7998264, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008264227770268917, "Value Loss": 0.000137462790007703, "_runtime": 17498.754069566727, "_timestamp": 1585614868.386939, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00835791602730751, "Value Loss": 7.662360440008342e-05, "_runtime": 17500.381618499756, "_timestamp": 1585614870.014488, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008678478188812733, "Value Loss": 0.00014952229685150087, "_runtime": 17501.9599981308, "_timestamp": 1585614871.5928676, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009463772177696228, "Value Loss": 0.0003074207343161106, "_runtime": 17503.540868282318, "_timestamp": 1585614873.1737378, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009725714102387428, "Value Loss": 4.5476081140805036e-05, "_runtime": 17505.120912075043, "_timestamp": 1585614874.7537816, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009857771918177605, "Value Loss": 0.0003691453312058002, "_runtime": 17506.711740016937, "_timestamp": 1585614876.3446095, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010359513573348522, "Value Loss": 0.0006828594487160444, "_runtime": 17508.297819375992, "_timestamp": 1585614877.9306889, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010792569257318974, "Value Loss": 0.00048018188681453466, "_runtime": 17509.88859272003, "_timestamp": 1585614879.5214622, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011389993131160736, "Value Loss": 0.0003822984581347555, "_runtime": 17511.47959804535, "_timestamp": 1585614881.1124675, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01194571889936924, "Value Loss": 0.00030272151343524456, "_runtime": 17513.06515598297, "_timestamp": 1585614882.6980255, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012799677439033985, "Value Loss": 0.0005443064728751779, "_runtime": 17514.653948307037, "_timestamp": 1585614884.2868178, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013353412970900536, "Value Loss": 8.778594201430678e-05, "_runtime": 17516.233263015747, "_timestamp": 1585614885.8661325, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012769095599651337, "Value Loss": 0.00011516217637108639, "_runtime": 17517.819079637527, "_timestamp": 1585614887.4519491, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.013128655031323433, "Value Loss": 6.470500375144184e-05, "_runtime": 17519.400074481964, "_timestamp": 1585614889.032944, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.012666333466768265, "Value Loss": 0.00015522063768003136, "_runtime": 17520.96772646904, "_timestamp": 1585614890.600596, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01282813772559166, "Value Loss": 0.00032215521787293255, "_runtime": 17522.546365499496, "_timestamp": 1585614892.179235, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011730304919183254, "Value Loss": 0.00012502691242843866, "_runtime": 17524.17470908165, "_timestamp": 1585614893.8075786, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01090224552899599, "Value Loss": 0.00013269615010358393, "_runtime": 17525.774993419647, "_timestamp": 1585614895.407863, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009891540743410587, "Value Loss": 0.00014302824274636805, "_runtime": 17527.37349176407, "_timestamp": 1585614897.0063612, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009688355028629303, "Value Loss": 0.0007545063854195178, "_runtime": 17528.95320391655, "_timestamp": 1585614898.5860734, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008614367805421352, "Value Loss": 7.538773206761107e-05, "_runtime": 17530.53113436699, "_timestamp": 1585614900.1640038, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007643307559192181, "Value Loss": 0.00010223793651675805, "_runtime": 17532.107442617416, "_timestamp": 1585614901.740312, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00782670360058546, "Value Loss": 0.0008396334014832973, "_runtime": 17533.675207853317, "_timestamp": 1585614903.3080773, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0077439057640731335, "Value Loss": 0.0003465564805082977, "_runtime": 17535.23973965645, "_timestamp": 1585614904.8726091, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006809120532125235, "Value Loss": 3.427354386076331e-05, "_runtime": 17536.81688928604, "_timestamp": 1585614906.4497588, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0074322219006717205, "Value Loss": 0.0008106745663098991, "_runtime": 17538.39382624626, "_timestamp": 1585614908.0266957, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006827557925134897, "Value Loss": 4.283719681552611e-05, "_runtime": 17539.958032369614, "_timestamp": 1585614909.5909019, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006962954066693783, "Value Loss": 0.00011369696585461497, "_runtime": 17541.521376371384, "_timestamp": 1585614911.1542459, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007020661141723394, "Value Loss": 9.906764171319082e-05, "_runtime": 17543.098526000977, "_timestamp": 1585614912.7313955, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006777273491024971, "Value Loss": 5.70385527680628e-05, "_runtime": 17544.666199684143, "_timestamp": 1585614914.2990692, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00659217918291688, "Value Loss": 0.00011157729022670537, "_runtime": 17546.22933125496, "_timestamp": 1585614915.8622007, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006179991643875837, "Value Loss": 0.00011065672151744366, "_runtime": 17547.84933066368, "_timestamp": 1585614917.4822001, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0056976862251758575, "Value Loss": 8.609869109932333e-05, "_runtime": 17549.41623234749, "_timestamp": 1585614919.0491018, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005500769708305597, "Value Loss": 0.0002930329064838588, "_runtime": 17550.98074054718, "_timestamp": 1585614920.61361, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005509549286216497, "Value Loss": 0.0006856587715446949, "_runtime": 17552.559297323227, "_timestamp": 1585614922.1921668, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004795870743691921, "Value Loss": 2.6947622245643288e-05, "_runtime": 17554.135257720947, "_timestamp": 1585614923.7681272, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005103276111185551, "Value Loss": 5.2355862862896174e-05, "_runtime": 17555.70927143097, "_timestamp": 1585614925.342141, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005052628461271524, "Value Loss": 6.306046998361126e-05, "_runtime": 17557.285889863968, "_timestamp": 1585614926.9187593, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0056316545233130455, "Value Loss": 0.0006723987753503025, "_runtime": 17558.861830711365, "_timestamp": 1585614928.4947002, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005769804585725069, "Value Loss": 0.0002866302093025297, "_runtime": 17560.440415859222, "_timestamp": 1585614930.0732853, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005842468235641718, "Value Loss": 3.511464819894172e-05, "_runtime": 17562.017746925354, "_timestamp": 1585614931.6506164, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006808675359934568, "Value Loss": 0.00011876066855620593, "_runtime": 17563.585864543915, "_timestamp": 1585614933.218734, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007249990478157997, "Value Loss": 0.0003289039887022227, "_runtime": 17565.162519931793, "_timestamp": 1585614934.7953894, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007912746630609035, "Value Loss": 0.0004886156530119479, "_runtime": 17566.733156442642, "_timestamp": 1585614936.366026, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00877069029957056, "Value Loss": 0.00031731146737001836, "_runtime": 17568.310713768005, "_timestamp": 1585614937.9435833, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008973767049610615, "Value Loss": 0.00034394668182358146, "_runtime": 17569.889155626297, "_timestamp": 1585614939.522025, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009044993668794632, "Value Loss": 0.00015785900177434087, "_runtime": 17571.507002830505, "_timestamp": 1585614941.1398723, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009336702525615692, "Value Loss": 0.00012896815314888954, "_runtime": 17573.085248947144, "_timestamp": 1585614942.7181184, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009873953647911549, "Value Loss": 0.0002535589737817645, "_runtime": 17574.661292791367, "_timestamp": 1585614944.2941623, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009489172138273716, "Value Loss": 0.00025909353280439973, "_runtime": 17576.239426136017, "_timestamp": 1585614945.8722956, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009609105065464973, "Value Loss": 0.000655468029435724, "_runtime": 17577.815484285355, "_timestamp": 1585614947.4483538, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00909485388547182, "Value Loss": 4.223000360070728e-05, "_runtime": 17579.38064932823, "_timestamp": 1585614949.0135188, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009403986856341362, "Value Loss": 0.000319197541102767, "_runtime": 17580.958971500397, "_timestamp": 1585614950.591841, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009125779382884502, "Value Loss": 5.913012137170881e-05, "_runtime": 17582.537407159805, "_timestamp": 1585614952.1702766, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00988138746470213, "Value Loss": 0.0006202722433954477, "_runtime": 17584.112723588943, "_timestamp": 1585614953.745593, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009767520241439342, "Value Loss": 7.045789971016347e-05, "_runtime": 17585.69187116623, "_timestamp": 1585614955.3247406, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.01081512775272131, "Value Loss": 0.0003648411948233843, "_runtime": 17587.270123243332, "_timestamp": 1585614956.9029927, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010547826066613197, "Value Loss": 0.0001603231648914516, "_runtime": 17588.842783927917, "_timestamp": 1585614958.4756534, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010802123695611954, "Value Loss": 0.00010947640112135559, "_runtime": 17590.41215777397, "_timestamp": 1585614960.0450273, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010902874171733856, "Value Loss": 6.720235978718847e-05, "_runtime": 17591.988486528397, "_timestamp": 1585614961.621356, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.011480416171252728, "Value Loss": 0.00022454884310718626, "_runtime": 17593.602821350098, "_timestamp": 1585614963.2356908, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.010138307698071003, "Value Loss": 0.00011522084241732955, "_runtime": 17595.181582927704, "_timestamp": 1585614964.8144524, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00947487074881792, "Value Loss": 0.00011564504529815167, "_runtime": 17596.749398708344, "_timestamp": 1585614966.3822682, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008844124153256416, "Value Loss": 9.195890015689656e-05, "_runtime": 17598.316269874573, "_timestamp": 1585614967.9491394, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008847370743751526, "Value Loss": 0.00023166755272541195, "_runtime": 17599.895901441574, "_timestamp": 1585614969.528771, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006841210648417473, "Value Loss": 8.984234591480345e-05, "_runtime": 17601.46284365654, "_timestamp": 1585614971.0957131, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006479072384536266, "Value Loss": 0.000522525398992002, "_runtime": 17603.030645370483, "_timestamp": 1585614972.6635149, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0055589210242033005, "Value Loss": 0.0002669351815711707, "_runtime": 17604.60815358162, "_timestamp": 1585614974.241023, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004898935556411743, "Value Loss": 0.00019285341841168702, "_runtime": 17606.186932086945, "_timestamp": 1585614975.8198016, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004556912928819656, "Value Loss": 0.00036296050529927015, "_runtime": 17607.75225496292, "_timestamp": 1585614977.3851244, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0043404679745435715, "Value Loss": 0.0003508009831421077, "_runtime": 17609.31915807724, "_timestamp": 1585614978.9520276, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0039601256139576435, "Value Loss": 5.760008207289502e-05, "_runtime": 17610.89897084236, "_timestamp": 1585614980.5318403, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004338920582085848, "Value Loss": 0.0005899538518860936, "_runtime": 17612.47368979454, "_timestamp": 1585614982.1065593, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00406023720279336, "Value Loss": 8.850456651998684e-05, "_runtime": 17614.067812919617, "_timestamp": 1585614983.7006824, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0045821270905435085, "Value Loss": 0.0005942166317254305, "_runtime": 17615.675497055054, "_timestamp": 1585614985.3083665, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005049030762165785, "Value Loss": 0.0003048710059374571, "_runtime": 17617.303201675415, "_timestamp": 1585614986.9360712, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005265199579298496, "Value Loss": 0.0004968380089849234, "_runtime": 17618.899920225143, "_timestamp": 1585614988.5327897, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005217455327510834, "Value Loss": 0.00010890495468629524, "_runtime": 17620.49591255188, "_timestamp": 1585614990.128782, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006308460608124733, "Value Loss": 0.00031569163547828794, "_runtime": 17622.098372220993, "_timestamp": 1585614991.7312417, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006211280357092619, "Value Loss": 0.00010642778215697035, "_runtime": 17623.695767879486, "_timestamp": 1585614993.3286374, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0072227963246405125, "Value Loss": 5.5657237680861726e-05, "_runtime": 17625.29060435295, "_timestamp": 1585614994.9234738, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007132666185498238, "Value Loss": 0.0002062647690763697, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17626.896457910538, "_timestamp": 1585614996.5293274, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007069104351103306, "Value Loss": 8.973958028946072e-05, "_runtime": 17628.493832349777, "_timestamp": 1585614998.1267018, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006252817343920469, "Value Loss": 0.00011523183638928458, "_runtime": 17630.092759609222, "_timestamp": 1585614999.725629, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006906421389430761, "Value Loss": 5.740834239986725e-05, "_runtime": 17631.68754005432, "_timestamp": 1585615001.3204095, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0060134646482765675, "Value Loss": 0.00026397622423246503, "_runtime": 17633.284605503082, "_timestamp": 1585615002.917475, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00633353041484952, "Value Loss": 0.00029924354748800397, "_runtime": 17634.892597913742, "_timestamp": 1585615004.5254674, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005744167137891054, "Value Loss": 6.299179221969098e-05, "_runtime": 17636.49595618248, "_timestamp": 1585615006.1288257, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00563227292150259, "Value Loss": 0.00010157399083254859, "_runtime": 17638.10734152794, "_timestamp": 1585615007.740211, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006484623998403549, "Value Loss": 0.00015063861792441458, "_runtime": 17639.71384525299, "_timestamp": 1585615009.3467147, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005847443826496601, "Value Loss": 0.00010964417742798105, "_runtime": 17641.345482587814, "_timestamp": 1585615010.978352, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005454946309328079, "Value Loss": 5.783432425232604e-05, "_runtime": 17642.940682172775, "_timestamp": 1585615012.5735517, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0052676270715892315, "Value Loss": 5.71877317270264e-05, "_runtime": 17644.545740365982, "_timestamp": 1585615014.1786098, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005317809525877237, "Value Loss": 0.00011178454587934539, "_runtime": 17646.149839878082, "_timestamp": 1585615015.7827094, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004907866474241018, "Value Loss": 0.0002607975620776415, "_runtime": 17647.735466241837, "_timestamp": 1585615017.3683357, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004978143144398928, "Value Loss": 0.0005468122544698417, "_runtime": 17649.33272242546, "_timestamp": 1585615018.965592, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005029417108744383, "Value Loss": 0.00010525462130317464, "_runtime": 17650.926112890244, "_timestamp": 1585615020.5589824, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005193040706217289, "Value Loss": 3.486258356133476e-05, "_runtime": 17652.521263837814, "_timestamp": 1585615022.1541333, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0057766614481806755, "Value Loss": 0.0005357118789106607, "_runtime": 17654.128450632095, "_timestamp": 1585615023.76132, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006007547955960035, "Value Loss": 3.121305053355172e-05, "_runtime": 17655.73271560669, "_timestamp": 1585615025.365585, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0073509919457137585, "Value Loss": 2.3215936380438507e-05, "_runtime": 17657.341666936874, "_timestamp": 1585615026.9745364, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007986331358551979, "Value Loss": 0.0003293534682597965, "_runtime": 17658.93586874008, "_timestamp": 1585615028.5687382, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008209765888750553, "Value Loss": 9.486871567787603e-05, "_runtime": 17660.52699446678, "_timestamp": 1585615030.159864, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008794772438704967, "Value Loss": 6.539563037222251e-05, "_runtime": 17662.125907182693, "_timestamp": 1585615031.7587767, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009075202979147434, "Value Loss": 9.332407353213057e-05, "_runtime": 17663.730094909668, "_timestamp": 1585615033.3629644, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009142507798969746, "Value Loss": 0.00010707126057241112, "_runtime": 17665.36429333687, "_timestamp": 1585615034.9971628, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00929940678179264, "Value Loss": 3.7269346648827195e-05, "_runtime": 17666.97110104561, "_timestamp": 1585615036.6039705, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009012996219098568, "Value Loss": 5.4736290621804073e-05, "_runtime": 17668.576615333557, "_timestamp": 1585615038.2094848, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009495078586041927, "Value Loss": 8.750350389163941e-05, "_runtime": 17670.18017745018, "_timestamp": 1585615039.813047, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008599847555160522, "Value Loss": 4.6797071263426915e-05, "_runtime": 17671.786217451096, "_timestamp": 1585615041.419087, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00878467783331871, "Value Loss": 0.0002528521290514618, "_runtime": 17673.382499217987, "_timestamp": 1585615043.0153687, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008478841744363308, "Value Loss": 0.00024184832000173628, "_runtime": 17674.976389169693, "_timestamp": 1585615044.6092587, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008366582915186882, "Value Loss": 0.0003237354103475809, "_runtime": 17676.58184504509, "_timestamp": 1585615046.2147145, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007570713758468628, "Value Loss": 3.999321779701859e-05, "_runtime": 17678.169592142105, "_timestamp": 1585615047.8024616, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008346953429281712, "Value Loss": 0.00018365232972428203, "_runtime": 17679.76340484619, "_timestamp": 1585615049.3962743, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007694987114518881, "Value Loss": 3.5396049497649074e-05, "_runtime": 17681.35239291191, "_timestamp": 1585615050.9852624, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008092107251286507, "Value Loss": 0.0006539073074236512, "_runtime": 17682.962606668472, "_timestamp": 1585615052.5954762, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008202251978218555, "Value Loss": 3.979082976002246e-05, "_runtime": 17684.57061290741, "_timestamp": 1585615054.2034824, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008211636915802956, "Value Loss": 0.000131122738821432, "_runtime": 17686.17997789383, "_timestamp": 1585615055.8128474, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009290982969105244, "Value Loss": 0.0005319868214428425, "_runtime": 17687.82558655739, "_timestamp": 1585615057.458456, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009651623666286469, "Value Loss": 9.007366315927356e-05, "_runtime": 17689.41921401024, "_timestamp": 1585615059.0520835, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009096776135265827, "Value Loss": 0.0001785467757144943, "_runtime": 17691.0270383358, "_timestamp": 1585615060.6599078, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00963691808283329, "Value Loss": 0.0001680641871644184, "_runtime": 17692.62052631378, "_timestamp": 1585615062.2533958, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008516897447407246, "Value Loss": 0.00015181099297478795, "_runtime": 17694.224284172058, "_timestamp": 1585615063.8571537, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008932453580200672, "Value Loss": 4.6122611820464954e-05, "_runtime": 17695.82468175888, "_timestamp": 1585615065.4575512, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008039881475269794, "Value Loss": 0.0002602827444206923, "_runtime": 17697.404094219208, "_timestamp": 1585615067.0369637, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007120773196220398, "Value Loss": 5.952989886282012e-05, "_runtime": 17698.98035144806, "_timestamp": 1585615068.613221, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0072457436472177505, "Value Loss": 5.460077591123991e-05, "_runtime": 17700.57090163231, "_timestamp": 1585615070.203771, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005973294842988253, "Value Loss": 0.00012957846047356725, "_runtime": 17702.149398326874, "_timestamp": 1585615071.7822678, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005668944679200649, "Value Loss": 7.593254849780351e-05, "_runtime": 17703.727172851562, "_timestamp": 1585615073.3600423, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005066291894763708, "Value Loss": 0.00023468522704206407, "_runtime": 17705.319483041763, "_timestamp": 1585615074.9523525, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00484163174405694, "Value Loss": 0.00027894348022527993, "_runtime": 17706.900631904602, "_timestamp": 1585615076.5335014, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003512874012812972, "Value Loss": 8.212780085159466e-05, "_runtime": 17708.47784304619, "_timestamp": 1585615078.1107125, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034486555960029364, "Value Loss": 0.0003163569781463593, "_runtime": 17710.068732976913, "_timestamp": 1585615079.7016025, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032961454708129168, "Value Loss": 0.00045762205263599753, "_runtime": 17711.6960337162, "_timestamp": 1585615081.3289032, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0028130621649324894, "Value Loss": 2.5731196728884242e-05, "_runtime": 17713.273594379425, "_timestamp": 1585615082.9064639, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0034580810461193323, "Value Loss": 0.0003006950137205422, "_runtime": 17714.864865779877, "_timestamp": 1585615084.4977353, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0031503315549343824, "Value Loss": 5.684051939169876e-05, "_runtime": 17716.4436981678, "_timestamp": 1585615086.0765676, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003857940435409546, "Value Loss": 1.5032230294309556e-05, "_runtime": 17718.03213119507, "_timestamp": 1585615087.6650007, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0036335447803139687, "Value Loss": 0.0003070484381169081, "_runtime": 17719.61084842682, "_timestamp": 1585615089.243718, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035329596139490604, "Value Loss": 0.00014823568926658481, "_runtime": 17721.2020509243, "_timestamp": 1585615090.8349204, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032070979941636324, "Value Loss": 2.6750720280688256e-05, "_runtime": 17722.787611961365, "_timestamp": 1585615092.4204814, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032828059047460556, "Value Loss": 9.154600411420688e-05, "_runtime": 17724.377057790756, "_timestamp": 1585615094.0099273, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0038528938312083483, "Value Loss": 0.0006808044272474945, "_runtime": 17725.967227220535, "_timestamp": 1585615095.6000967, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035781660117208958, "Value Loss": 0.0001044149903464131, "_runtime": 17727.55357003212, "_timestamp": 1585615097.1864395, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0038398676551878452, "Value Loss": 4.819767127628438e-05, "_runtime": 17729.122785568237, "_timestamp": 1585615098.755655, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004119723569601774, "Value Loss": 6.950386159587651e-05, "_runtime": 17730.702917575836, "_timestamp": 1585615100.335787, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004753973800688982, "Value Loss": 0.0005532518844120204, "_runtime": 17732.27872610092, "_timestamp": 1585615101.9115956, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005295123904943466, "Value Loss": 0.00038389727706089616, "_runtime": 17733.871169567108, "_timestamp": 1585615103.504039, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006196030881255865, "Value Loss": 0.0005389387370087206, "_runtime": 17735.49690103531, "_timestamp": 1585615105.1297705, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007401823531836271, "Value Loss": 0.000238191380049102, "_runtime": 17737.08787035942, "_timestamp": 1585615106.7207398, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00789532158523798, "Value Loss": 0.0001082574890460819, "_runtime": 17738.664819717407, "_timestamp": 1585615108.2976892, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008628091774880886, "Value Loss": 7.181014370871708e-05, "_runtime": 17740.253356933594, "_timestamp": 1585615109.8862264, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009239747188985348, "Value Loss": 0.0001052183797582984, "_runtime": 17741.83073592186, "_timestamp": 1585615111.4636054, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009890224784612656, "Value Loss": 0.00021134631242603064, "_runtime": 17743.421528816223, "_timestamp": 1585615113.0543983, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009041517041623592, "Value Loss": 0.00016060165944509208, "_runtime": 17745.01174068451, "_timestamp": 1585615114.6446102, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.009235609322786331, "Value Loss": 0.00022921161144040525, "_runtime": 17746.59628868103, "_timestamp": 1585615116.2291582, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007757325656712055, "Value Loss": 0.00016185463755391538, "_runtime": 17748.186074256897, "_timestamp": 1585615117.8189437, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006906329654157162, "Value Loss": 5.597144627245143e-05, "_runtime": 17749.77707529068, "_timestamp": 1585615119.4099448, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006157629657536745, "Value Loss": 5.610613152384758e-05, "_runtime": 17751.362983942032, "_timestamp": 1585615120.9958534, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005220053251832724, "Value Loss": 5.787654663436115e-05, "_runtime": 17752.955505371094, "_timestamp": 1585615122.5883749, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004484046250581741, "Value Loss": 0.0001860734191723168, "_runtime": 17754.550612926483, "_timestamp": 1585615124.1834824, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004155323375016451, "Value Loss": 0.0007243919535540044, "_runtime": 17756.13045692444, "_timestamp": 1585615125.7633264, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003385799704119563, "Value Loss": 2.4265578758786432e-05, "_runtime": 17757.719965219498, "_timestamp": 1585615127.3528347, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0033105870243161917, "Value Loss": 6.501522148028016e-05, "_runtime": 17759.336315393448, "_timestamp": 1585615128.9691849, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035327067598700523, "Value Loss": 0.00021645201195497066, "_runtime": 17760.921391248703, "_timestamp": 1585615130.5542607, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003634021617472172, "Value Loss": 5.825568950967863e-05, "_runtime": 17762.51269197464, "_timestamp": 1585615132.1455615, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0028900045435875654, "Value Loss": 2.2965796233620495e-05, "_runtime": 17764.099090576172, "_timestamp": 1585615133.73196, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00271650031208992, "Value Loss": 2.482505442458205e-05, "_runtime": 17765.686616182327, "_timestamp": 1585615135.3194857, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027502893935889006, "Value Loss": 3.977028245572001e-05, "_runtime": 17767.278997659683, "_timestamp": 1585615136.9118671, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002352197654545307, "Value Loss": 3.0906412575859576e-05, "_runtime": 17768.85475873947, "_timestamp": 1585615138.4876282, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001539147226139903, "Value Loss": 1.6160618542926386e-05, "_runtime": 17770.43095111847, "_timestamp": 1585615140.0638206, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014646928757429123, "Value Loss": 3.687740536406636e-05, "_runtime": 17772.02157688141, "_timestamp": 1585615141.6544464, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014127212343737483, "Value Loss": 0.0005404117400757968, "_runtime": 17773.601063489914, "_timestamp": 1585615143.233933, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001697593368589878, "Value Loss": 0.00044118723599240184, "_runtime": 17775.179271936417, "_timestamp": 1585615144.8121414, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001822289894334972, "Value Loss": 6.818020483478904e-05, "_runtime": 17776.761150360107, "_timestamp": 1585615146.3940198, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002082475461065769, "Value Loss": 4.598435407388024e-05, "_runtime": 17778.352552175522, "_timestamp": 1585615147.9854217, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0031165212858468294, "Value Loss": 0.0007204429130069911, "_runtime": 17779.934775352478, "_timestamp": 1585615149.5676448, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003931221552193165, "Value Loss": 1.437249102309579e-05, "_runtime": 17781.5244679451, "_timestamp": 1585615151.1573374, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004253350663930178, "Value Loss": 6.067008143872954e-05, "_runtime": 17783.155616998672, "_timestamp": 1585615152.7884865, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0051027401350438595, "Value Loss": 3.641887451522052e-05, "_runtime": 17784.740742206573, "_timestamp": 1585615154.3736117, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005538563244044781, "Value Loss": 8.431365131400526e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17786.334601402283, "_timestamp": 1585615155.967471, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005999285262078047, "Value Loss": 0.00011196386185474694, "_runtime": 17787.928827285767, "_timestamp": 1585615157.5616968, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006654396187514067, "Value Loss": 0.00013063462392892689, "_runtime": 17789.514247894287, "_timestamp": 1585615159.1471174, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007294496987015009, "Value Loss": 0.00048148431233130395, "_runtime": 17791.104076385498, "_timestamp": 1585615160.7369459, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007035295013338327, "Value Loss": 0.00014042963448446244, "_runtime": 17792.6936545372, "_timestamp": 1585615162.326524, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007365373894572258, "Value Loss": 9.661573858466e-05, "_runtime": 17794.28125357628, "_timestamp": 1585615163.914123, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007866863161325455, "Value Loss": 0.00019680960394907743, "_runtime": 17795.871223926544, "_timestamp": 1585615165.5040934, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007702552247792482, "Value Loss": 0.0005320578929968178, "_runtime": 17797.46217751503, "_timestamp": 1585615167.095047, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007793205790221691, "Value Loss": 0.00018232309957966208, "_runtime": 17799.038917541504, "_timestamp": 1585615168.671787, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00675484212115407, "Value Loss": 3.42536841344554e-05, "_runtime": 17800.631376981735, "_timestamp": 1585615170.2642465, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006139860488474369, "Value Loss": 5.9209458413533866e-05, "_runtime": 17802.222472667694, "_timestamp": 1585615171.8553421, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006244635209441185, "Value Loss": 0.0006636230973526835, "_runtime": 17803.809606790543, "_timestamp": 1585615173.4424763, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005687805823981762, "Value Loss": 3.696608837344684e-05, "_runtime": 17805.441405773163, "_timestamp": 1585615175.0742753, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006587488576769829, "Value Loss": 0.00018693720630835742, "_runtime": 17807.03078198433, "_timestamp": 1585615176.6636515, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006226764991879463, "Value Loss": 0.0002459067036397755, "_runtime": 17808.618863344193, "_timestamp": 1585615178.2517328, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00563837168738246, "Value Loss": 0.00011781845387304202, "_runtime": 17810.19836807251, "_timestamp": 1585615179.8312376, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005462511908262968, "Value Loss": 0.00011079762043664232, "_runtime": 17811.779235363007, "_timestamp": 1585615181.4121048, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005954321473836899, "Value Loss": 0.00037661331589333713, "_runtime": 17813.359161376953, "_timestamp": 1585615182.9920309, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005733830388635397, "Value Loss": 0.00042530219070613384, "_runtime": 17814.949026823044, "_timestamp": 1585615184.5818963, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006033558864146471, "Value Loss": 0.0002653489063959569, "_runtime": 17816.530434846878, "_timestamp": 1585615186.1633043, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0066749462857842445, "Value Loss": 0.0004054491873830557, "_runtime": 17818.11055636406, "_timestamp": 1585615187.7434258, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006719384808093309, "Value Loss": 0.0001600142422830686, "_runtime": 17819.691799640656, "_timestamp": 1585615189.3246691, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007688362617045641, "Value Loss": 0.00031931509147398174, "_runtime": 17821.273270368576, "_timestamp": 1585615190.9061399, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008114710450172424, "Value Loss": 5.493597564054653e-05, "_runtime": 17822.852628707886, "_timestamp": 1585615192.4854982, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007205279543995857, "Value Loss": 0.00010139274672837928, "_runtime": 17824.43367266655, "_timestamp": 1585615194.0665421, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007142424583435059, "Value Loss": 0.00030236333259381354, "_runtime": 17826.02566051483, "_timestamp": 1585615195.65853, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0067679183557629585, "Value Loss": 0.00041073065949603915, "_runtime": 17827.615436553955, "_timestamp": 1585615197.248306, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006630297284573317, "Value Loss": 0.00016013599815778434, "_runtime": 17829.22318458557, "_timestamp": 1585615198.856054, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0059167020954191685, "Value Loss": 0.0004982967511750758, "_runtime": 17830.803990840912, "_timestamp": 1585615200.4368603, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005933166481554508, "Value Loss": 0.0001454348093830049, "_runtime": 17832.38186788559, "_timestamp": 1585615202.0147374, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004633966367691755, "Value Loss": 9.466928167967126e-05, "_runtime": 17833.9706428051, "_timestamp": 1585615203.6035123, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004035793710500002, "Value Loss": 9.235121979145333e-05, "_runtime": 17835.560158252716, "_timestamp": 1585615205.1930277, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032755944412201643, "Value Loss": 2.253497405035887e-05, "_runtime": 17837.149011850357, "_timestamp": 1585615206.7818813, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003142726141959429, "Value Loss": 0.0003814939991571009, "_runtime": 17838.74095082283, "_timestamp": 1585615208.3738203, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025463232304900885, "Value Loss": 7.44313801988028e-05, "_runtime": 17840.320801734924, "_timestamp": 1585615209.9536712, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002647568006068468, "Value Loss": 6.262445822358131e-05, "_runtime": 17841.90858578682, "_timestamp": 1585615211.5414553, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025961410719901323, "Value Loss": 6.678979843854904e-05, "_runtime": 17843.492837667465, "_timestamp": 1585615213.1257071, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002974086906760931, "Value Loss": 0.00032422083313576877, "_runtime": 17845.08263683319, "_timestamp": 1585615214.7155063, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027660855557769537, "Value Loss": 1.712310222501401e-05, "_runtime": 17846.65929889679, "_timestamp": 1585615216.2921684, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003450484713539481, "Value Loss": 5.7860790548147634e-05, "_runtime": 17848.248553991318, "_timestamp": 1585615217.8814235, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003778490237891674, "Value Loss": 1.6816173229017295e-05, "_runtime": 17849.84034729004, "_timestamp": 1585615219.4732168, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0038323537446558475, "Value Loss": 8.467266889056191e-05, "_runtime": 17851.41608119011, "_timestamp": 1585615221.0489507, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004467051476240158, "Value Loss": 0.0002897178055718541, "_runtime": 17853.045379161835, "_timestamp": 1585615222.6782486, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004823530558496714, "Value Loss": 0.0002773559535853565, "_runtime": 17854.63643336296, "_timestamp": 1585615224.2693028, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005555927753448486, "Value Loss": 0.00010289821511832997, "_runtime": 17856.223370075226, "_timestamp": 1585615225.8562396, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005587886553257704, "Value Loss": 7.525536057073623e-05, "_runtime": 17857.81303024292, "_timestamp": 1585615227.4458997, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006188880652189255, "Value Loss": 4.461186472326517e-05, "_runtime": 17859.393542528152, "_timestamp": 1585615229.026412, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006201451178640127, "Value Loss": 0.00011652403918560594, "_runtime": 17860.981877565384, "_timestamp": 1585615230.614747, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006925595458596945, "Value Loss": 0.00033906998578459024, "_runtime": 17862.572818040848, "_timestamp": 1585615232.2056875, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006612345110625029, "Value Loss": 0.0001182252453872934, "_runtime": 17864.164774656296, "_timestamp": 1585615233.7976441, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0068882061168551445, "Value Loss": 8.130176865961403e-05, "_runtime": 17865.742876291275, "_timestamp": 1585615235.3757458, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007005308289080858, "Value Loss": 5.061058982391842e-05, "_runtime": 17867.32289648056, "_timestamp": 1585615236.955766, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007278094068169594, "Value Loss": 0.0005683302879333496, "_runtime": 17868.902855873108, "_timestamp": 1585615238.5357254, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007359498180449009, "Value Loss": 3.115883737336844e-05, "_runtime": 17870.48183274269, "_timestamp": 1585615240.1147022, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00751630449667573, "Value Loss": 0.0002289490366820246, "_runtime": 17872.07440829277, "_timestamp": 1585615241.7072778, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007257303223013878, "Value Loss": 7.696059765294194e-05, "_runtime": 17873.654884815216, "_timestamp": 1585615243.2877543, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007325790356844664, "Value Loss": 4.0122387872543186e-05, "_runtime": 17875.244865179062, "_timestamp": 1585615244.8777347, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006846448872238398, "Value Loss": 3.112740523647517e-05, "_runtime": 17876.875079870224, "_timestamp": 1585615246.5079494, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006859080400317907, "Value Loss": 6.50500733172521e-05, "_runtime": 17878.47211241722, "_timestamp": 1585615248.104982, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006737496703863144, "Value Loss": 0.0002204199117841199, "_runtime": 17880.03898525238, "_timestamp": 1585615249.6718547, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005669369362294674, "Value Loss": 0.0005287740495987236, "_runtime": 17881.620157003403, "_timestamp": 1585615251.2530265, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004889995791018009, "Value Loss": 1.8568824089015834e-05, "_runtime": 17883.211691856384, "_timestamp": 1585615252.8445613, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004784766584634781, "Value Loss": 4.175708454567939e-05, "_runtime": 17884.800883293152, "_timestamp": 1585615254.4337528, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00476514408364892, "Value Loss": 0.0004954103496856987, "_runtime": 17886.39003634453, "_timestamp": 1585615256.0229058, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005110020749270916, "Value Loss": 9.160989429801702e-05, "_runtime": 17887.980315685272, "_timestamp": 1585615257.6131852, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005877248477190733, "Value Loss": 0.000336153811076656, "_runtime": 17889.55781030655, "_timestamp": 1585615259.1906798, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007156718987971544, "Value Loss": 0.00023086996225174516, "_runtime": 17891.14821910858, "_timestamp": 1585615260.7810886, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007437512278556824, "Value Loss": 0.00011564950546016917, "_runtime": 17892.729079008102, "_timestamp": 1585615262.3619485, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00810974556952715, "Value Loss": 7.430972618749365e-05, "_runtime": 17894.31467485428, "_timestamp": 1585615263.9475443, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008327818475663662, "Value Loss": 0.00011339967750245705, "_runtime": 17895.903089523315, "_timestamp": 1585615265.535959, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008105751127004623, "Value Loss": 4.777115464094095e-05, "_runtime": 17897.493615865707, "_timestamp": 1585615267.1264853, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.007627733517438173, "Value Loss": 0.00014665631169918925, "_runtime": 17899.120196819305, "_timestamp": 1585615268.7530663, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006836730055510998, "Value Loss": 8.119433914544061e-05, "_runtime": 17900.71419763565, "_timestamp": 1585615270.347067, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.006346476264297962, "Value Loss": 0.00035518669756129384, "_runtime": 17902.294143915176, "_timestamp": 1585615271.9270134, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.004765136167407036, "Value Loss": 5.64124493394047e-05, "_runtime": 17903.87961912155, "_timestamp": 1585615273.5124886, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003606098238378763, "Value Loss": 2.6024370527011342e-05, "_runtime": 17905.45957493782, "_timestamp": 1585615275.0924444, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0029240353032946587, "Value Loss": 7.429762626998127e-05, "_runtime": 17907.04927945137, "_timestamp": 1585615276.682149, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0012429176131263375, "Value Loss": 1.063988202076871e-05, "_runtime": 17908.626638174057, "_timestamp": 1585615278.2595077, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0010344814509153366, "Value Loss": 0.000690327025949955, "_runtime": 17910.216345071793, "_timestamp": 1585615279.8492146, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0009952322579920292, "Value Loss": 0.0005886897561140358, "_runtime": 17911.806468725204, "_timestamp": 1585615281.4393382, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007937444024719298, "Value Loss": 1.0762853889900725e-05, "_runtime": 17913.38335776329, "_timestamp": 1585615283.0162272, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013610412133857608, "Value Loss": 1.5235364116961136e-05, "_runtime": 17914.961635112762, "_timestamp": 1585615284.5945046, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001758636673912406, "Value Loss": 4.4914726458955556e-05, "_runtime": 17916.55091357231, "_timestamp": 1585615286.183783, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018097595311701298, "Value Loss": 7.684974116273224e-05, "_runtime": 17918.137800455093, "_timestamp": 1585615287.77067, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001563762896694243, "Value Loss": 6.105503416620195e-05, "_runtime": 17919.705926656723, "_timestamp": 1585615289.3387961, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0019071606220677495, "Value Loss": 0.0002518445544410497, "_runtime": 17921.281167030334, "_timestamp": 1585615290.9140365, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001298793707974255, "Value Loss": 0.00012941272871103138, "_runtime": 17922.905999183655, "_timestamp": 1585615292.5388687, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001119848689995706, "Value Loss": 0.00017416354967281222, "_runtime": 17924.48508167267, "_timestamp": 1585615294.1179512, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018389668548479676, "Value Loss": 0.00045014472561888397, "_runtime": 17926.063698530197, "_timestamp": 1585615295.696568, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013876596931368113, "Value Loss": 0.00012302858522161841, "_runtime": 17927.643131256104, "_timestamp": 1585615297.2760007, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00211601285263896, "Value Loss": 0.0002688464883249253, "_runtime": 17929.230254411697, "_timestamp": 1585615298.863124, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0025865843053907156, "Value Loss": 1.3452961866278201e-05, "_runtime": 17930.818337202072, "_timestamp": 1585615300.4512067, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002753120381385088, "Value Loss": 0.0002120731951436028, "_runtime": 17932.40589785576, "_timestamp": 1585615302.0387673, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0032915957272052765, "Value Loss": 0.00013059275806881487, "_runtime": 17934.000511407852, "_timestamp": 1585615303.633381, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0027116460260003805, "Value Loss": 5.9215875808149576e-05, "_runtime": 17935.589328289032, "_timestamp": 1585615305.2221978, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0033365970011800528, "Value Loss": 0.00022901031479705125, "_runtime": 17937.17520594597, "_timestamp": 1585615306.8080754, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0030504728201776743, "Value Loss": 7.016767631284893e-05, "_runtime": 17938.76130437851, "_timestamp": 1585615308.3941739, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0030729847494512796, "Value Loss": 4.056337274960242e-05, "_runtime": 17940.342606067657, "_timestamp": 1585615309.9754755, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0033665040973573923, "Value Loss": 2.8977436159038916e-05, "_runtime": 17941.920783519745, "_timestamp": 1585615311.553653, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003371620550751686, "Value Loss": 3.749192546820268e-05, "_runtime": 17943.50275325775, "_timestamp": 1585615313.1356227, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0036217120941728354, "Value Loss": 0.00032413622830063105, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 17945.09215760231, "_timestamp": 1585615314.725027, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003557574702426791, "Value Loss": 4.0182494558393955e-05, "_runtime": 17945.09215760231, "_timestamp": 1585615314.725027, "_step": 499}
