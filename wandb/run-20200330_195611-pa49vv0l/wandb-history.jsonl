{"Episode reward": -32.83524954245227, "Episode length": 999, "Policy Loss": -0.02543226256966591, "Value Loss": 0.0021583056077361107, "_runtime": 821.5260372161865, "_timestamp": 1585598191.1589067, "_step": 0}
{"Episode reward": -94.96488352180485, "Episode length": 999, "Policy Loss": -1.8659045696258545, "Value Loss": 184.41024780273438, "_runtime": 822.9652733802795, "_timestamp": 1585598192.5981429, "_step": 1}
{"Episode reward": -97.24080459642954, "Episode length": 999, "Policy Loss": 50.33549499511719, "Value Loss": 7445.42578125, "_runtime": 824.4659910202026, "_timestamp": 1585598194.0988605, "_step": 2}
{"Episode reward": -99.53178760833988, "Episode length": 999, "Policy Loss": 0.3861848711967468, "Value Loss": 2278.360107421875, "_runtime": 825.9612810611725, "_timestamp": 1585598195.5941505, "_step": 3}
{"Episode reward": -98.7492433382578, "Episode length": 999, "Policy Loss": -11.462687492370605, "Value Loss": 1089.871826171875, "_runtime": 827.4794890880585, "_timestamp": 1585598197.1123586, "_step": 4}
{"Episode reward": -98.87662724807754, "Episode length": 999, "Policy Loss": -22.884288787841797, "Value Loss": 1104.2760009765625, "_runtime": 828.3133027553558, "_timestamp": 1585598197.9461722, "_step": 5}
{"Episode reward": 45.87381543597791, "Episode length": 544, "Policy Loss": -20.727161407470703, "Value Loss": 2232.894775390625, "_runtime": 829.8179385662079, "_timestamp": 1585598199.450808, "_step": 6}
{"Episode reward": -99.30511169167049, "Episode length": 999, "Policy Loss": 2.6595094203948975, "Value Loss": 357.6197814941406, "_runtime": 831.3174858093262, "_timestamp": 1585598200.9503553, "_step": 7}
{"Episode reward": -99.10377649163722, "Episode length": 999, "Policy Loss": 8.979520797729492, "Value Loss": 605.865966796875, "_runtime": 832.7938740253448, "_timestamp": 1585598202.4267435, "_step": 8}
{"Episode reward": -98.94876179879805, "Episode length": 999, "Policy Loss": 19.145780563354492, "Value Loss": 3316.779052734375, "_runtime": 833.6857006549835, "_timestamp": 1585598203.3185701, "_step": 9}
{"Episode reward": 42.30085589208085, "Episode length": 583, "Policy Loss": 7.140068054199219, "Value Loss": 584.9739990234375, "_runtime": 835.1804533004761, "_timestamp": 1585598204.8133228, "_step": 10}
{"Episode reward": -99.55906758021017, "Episode length": 999, "Policy Loss": 2.09734845161438, "Value Loss": 225.2169952392578, "_runtime": 835.664909362793, "_timestamp": 1585598205.2977788, "_step": 11}
{"Episode reward": 70.15153540762098, "Episode length": 302, "Policy Loss": -8.066845893859863, "Value Loss": 3796.44091796875, "_runtime": 837.1479353904724, "_timestamp": 1585598206.7808049, "_step": 12}
{"Episode reward": 1.058017573747449, "Episode length": 996, "Policy Loss": -2.7129642963409424, "Value Loss": 513.8028564453125, "_runtime": 838.6593930721283, "_timestamp": 1585598208.2922626, "_step": 13}
{"Episode reward": -98.82035733235404, "Episode length": 999, "Policy Loss": -1.2825675010681152, "Value Loss": 47.375450134277344, "_runtime": 839.7038841247559, "_timestamp": 1585598209.3367536, "_step": 14}
{"Episode reward": 28.07828543159465, "Episode length": 727, "Policy Loss": 0.4572204351425171, "Value Loss": 206.43914794921875, "_runtime": 841.2180833816528, "_timestamp": 1585598210.8509529, "_step": 15}
{"Episode reward": -98.89556571275364, "Episode length": 999, "Policy Loss": 0.7290375828742981, "Value Loss": 488.25518798828125, "_runtime": 842.7180337905884, "_timestamp": 1585598212.3509033, "_step": 16}
{"Episode reward": -98.31793005023398, "Episode length": 999, "Policy Loss": 1.0384634733200073, "Value Loss": 150.3590087890625, "_runtime": 844.1949717998505, "_timestamp": 1585598213.8278413, "_step": 17}
{"Episode reward": -95.74820124785124, "Episode length": 999, "Policy Loss": 0.39613577723503113, "Value Loss": 8.294319152832031, "_runtime": 845.7076251506805, "_timestamp": 1585598215.3404946, "_step": 18}
{"Episode reward": -99.17206547336903, "Episode length": 999, "Policy Loss": 5.181768894195557, "Value Loss": 4.479555130004883, "_runtime": 847.2256305217743, "_timestamp": 1585598216.8585, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4760332107543945, "Value Loss": 13.614547729492188, "_runtime": 848.7381711006165, "_timestamp": 1585598218.3710406, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.553401470184326, "Value Loss": 8.197165489196777, "_runtime": 850.2999737262726, "_timestamp": 1585598219.9328432, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.84118390083313, "Value Loss": 23.472171783447266, "_runtime": 851.8127589225769, "_timestamp": 1585598221.4456284, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.734978199005127, "Value Loss": 8.928274154663086, "_runtime": 853.3325500488281, "_timestamp": 1585598222.9654195, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.721235275268555, "Value Loss": 41.69276428222656, "_runtime": 854.8590667247772, "_timestamp": 1585598224.4919362, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.377879619598389, "Value Loss": 0.3516311049461365, "_runtime": 856.3833954334259, "_timestamp": 1585598226.016265, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.902428150177002, "Value Loss": 2.368140697479248, "_runtime": 857.9039099216461, "_timestamp": 1585598227.5367794, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.1977128982543945, "Value Loss": 79.38331604003906, "_runtime": 859.4309389591217, "_timestamp": 1585598229.0638084, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.1674089431762695, "Value Loss": 5.099206447601318, "_runtime": 860.9482133388519, "_timestamp": 1585598230.5810828, "_step": 28}
{"Episode reward": -99.75434536308339, "Episode length": 999, "Policy Loss": 4.58380126953125, "Value Loss": 0.6224409937858582, "_runtime": 862.4856514930725, "_timestamp": 1585598232.118521, "_step": 29}
{"Episode reward": -99.6539397063922, "Episode length": 999, "Policy Loss": 5.000948905944824, "Value Loss": 1.0858503580093384, "_runtime": 864.0245151519775, "_timestamp": 1585598233.6573846, "_step": 30}
{"Episode reward": -99.70787410165153, "Episode length": 999, "Policy Loss": 4.055134296417236, "Value Loss": 4.142141342163086, "_runtime": 865.5612630844116, "_timestamp": 1585598235.1941326, "_step": 31}
{"Episode reward": -99.71003080899173, "Episode length": 999, "Policy Loss": 4.646117687225342, "Value Loss": 0.4084254205226898, "_runtime": 867.0854516029358, "_timestamp": 1585598236.718321, "_step": 32}
{"Episode reward": -94.65950979937993, "Episode length": 999, "Policy Loss": -1.8178659677505493, "Value Loss": 1.5993332862854004, "_runtime": 868.6048452854156, "_timestamp": 1585598238.2377148, "_step": 33}
{"Episode reward": -97.98682015665624, "Episode length": 999, "Policy Loss": 4.274375915527344, "Value Loss": 88.74671173095703, "_runtime": 870.1311099529266, "_timestamp": 1585598239.7639794, "_step": 34}
{"Episode reward": -97.86081507165714, "Episode length": 999, "Policy Loss": 2.15207839012146, "Value Loss": 1.0038760900497437, "_runtime": 871.6680698394775, "_timestamp": 1585598241.3009393, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3883466720581055, "Value Loss": 4.5849609375, "_runtime": 873.2316498756409, "_timestamp": 1585598242.8645194, "_step": 36}
{"Episode reward": -99.75325585384246, "Episode length": 999, "Policy Loss": 4.769121170043945, "Value Loss": 7.6737775802612305, "_runtime": 874.7599029541016, "_timestamp": 1585598244.3927724, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.814442157745361, "Value Loss": 26.009000778198242, "_runtime": 876.2971999645233, "_timestamp": 1585598245.9300694, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.789705753326416, "Value Loss": 18.126802444458008, "_runtime": 877.8387823104858, "_timestamp": 1585598247.4716518, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.644909381866455, "Value Loss": 18.35744857788086, "_runtime": 879.3786675930023, "_timestamp": 1585598249.011537, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.231446266174316, "Value Loss": 29.146713256835938, "_runtime": 880.9154605865479, "_timestamp": 1585598250.54833, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.863608360290527, "Value Loss": 7.0989789962768555, "_runtime": 882.459144115448, "_timestamp": 1585598252.0920136, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.755384922027588, "Value Loss": 14.214930534362793, "_runtime": 883.9870758056641, "_timestamp": 1585598253.6199453, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.9836983680725098, "Value Loss": 13.510873794555664, "_runtime": 885.523598909378, "_timestamp": 1585598255.1564684, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.4568982124328613, "Value Loss": 2.449491024017334, "_runtime": 887.0628607273102, "_timestamp": 1585598256.6957302, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.013899803161621, "Value Loss": 0.33811357617378235, "_runtime": 888.5998122692108, "_timestamp": 1585598258.2326818, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4968810081481934, "Value Loss": 0.707432746887207, "_runtime": 890.1360726356506, "_timestamp": 1585598259.768942, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0900630950927734, "Value Loss": 0.2671107351779938, "_runtime": 891.6726212501526, "_timestamp": 1585598261.3054907, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6057575941085815, "Value Loss": 1.8896539211273193, "_runtime": 893.1994009017944, "_timestamp": 1585598262.8322704, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2972084283828735, "Value Loss": 1.5151652097702026, "_runtime": 894.7292392253876, "_timestamp": 1585598264.3621087, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0076309442520142, "Value Loss": 0.49878814816474915, "_runtime": 896.300954580307, "_timestamp": 1585598265.933824, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.748613715171814, "Value Loss": 3.920520305633545, "_runtime": 897.8348863124847, "_timestamp": 1585598267.4677558, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6329432129859924, "Value Loss": 21.184675216674805, "_runtime": 899.3704526424408, "_timestamp": 1585598269.0033221, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.46692749857902527, "Value Loss": 3.327042818069458, "_runtime": 900.8880181312561, "_timestamp": 1585598270.5208876, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3588554859161377, "Value Loss": 11.943532943725586, "_runtime": 902.4259195327759, "_timestamp": 1585598272.058789, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.384375661611557, "Value Loss": 2.537309408187866, "_runtime": 903.9621922969818, "_timestamp": 1585598273.5950618, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37849822640419006, "Value Loss": 1.6831647157669067, "_runtime": 905.5002133846283, "_timestamp": 1585598275.1330829, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3898897171020508, "Value Loss": 0.22446990013122559, "_runtime": 907.0358695983887, "_timestamp": 1585598276.668739, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.35249796509742737, "Value Loss": 1.6772515773773193, "_runtime": 908.5724318027496, "_timestamp": 1585598278.2053013, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3526793122291565, "Value Loss": 1.1121666431427002, "_runtime": 910.0992181301117, "_timestamp": 1585598279.7320876, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.333358496427536, "Value Loss": 0.4721662104129791, "_runtime": 911.627712726593, "_timestamp": 1585598281.2605822, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2911595106124878, "Value Loss": 3.541539430618286, "_runtime": 913.152218580246, "_timestamp": 1585598282.785088, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24908608198165894, "Value Loss": 0.23942731320858002, "_runtime": 914.6801595687866, "_timestamp": 1585598284.313029, "_step": 63}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.17851674556732178, "Value Loss": 0.9396896362304688, "_runtime": 916.2057995796204, "_timestamp": 1585598285.838669, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07215609401464462, "Value Loss": 4.636309623718262, "_runtime": 917.7301268577576, "_timestamp": 1585598287.3629963, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032134994864463806, "Value Loss": 0.6250885128974915, "_runtime": 919.3004231452942, "_timestamp": 1585598288.9332926, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1410219669342041, "Value Loss": 0.07030905783176422, "_runtime": 920.8371770381927, "_timestamp": 1585598290.4700465, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24614761769771576, "Value Loss": 5.37351131439209, "_runtime": 922.373420715332, "_timestamp": 1585598292.0062902, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4135590195655823, "Value Loss": 1.1284637451171875, "_runtime": 923.912239074707, "_timestamp": 1585598293.5451086, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5588539242744446, "Value Loss": 5.131551265716553, "_runtime": 925.4484252929688, "_timestamp": 1585598295.0812948, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7363676428794861, "Value Loss": 0.08018464595079422, "_runtime": 926.9864809513092, "_timestamp": 1585598296.6193504, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9199327826499939, "Value Loss": 0.7417601346969604, "_runtime": 928.5162868499756, "_timestamp": 1585598298.1491563, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0618634223937988, "Value Loss": 0.10620764642953873, "_runtime": 930.0521459579468, "_timestamp": 1585598299.6850154, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1953741312026978, "Value Loss": 0.3334119915962219, "_runtime": 931.5893974304199, "_timestamp": 1585598301.222267, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3228477239608765, "Value Loss": 0.24594618380069733, "_runtime": 933.1285307407379, "_timestamp": 1585598302.7614002, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.437339425086975, "Value Loss": 0.1376054435968399, "_runtime": 934.6657366752625, "_timestamp": 1585598304.2986062, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5639467239379883, "Value Loss": 0.4297527074813843, "_runtime": 936.2012090682983, "_timestamp": 1585598305.8340786, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6303000450134277, "Value Loss": 0.1356128454208374, "_runtime": 937.7390303611755, "_timestamp": 1585598307.3718998, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7297967672348022, "Value Loss": 0.06576056778430939, "_runtime": 939.2675724029541, "_timestamp": 1585598308.900442, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7791157960891724, "Value Loss": 0.2921583354473114, "_runtime": 940.8500912189484, "_timestamp": 1585598310.4829607, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8595250844955444, "Value Loss": 0.5567263960838318, "_runtime": 942.3836445808411, "_timestamp": 1585598312.016514, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9393994808197021, "Value Loss": 0.11528334021568298, "_runtime": 943.9216547012329, "_timestamp": 1585598313.5545242, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9480661153793335, "Value Loss": 0.48285436630249023, "_runtime": 945.4590785503387, "_timestamp": 1585598315.091948, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.028170108795166, "Value Loss": 0.1519448608160019, "_runtime": 946.9897499084473, "_timestamp": 1585598316.6226194, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0221550464630127, "Value Loss": 0.4935741126537323, "_runtime": 948.512814283371, "_timestamp": 1585598318.1456838, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0679776668548584, "Value Loss": 0.6992203593254089, "_runtime": 950.0491733551025, "_timestamp": 1585598319.6820428, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0781750679016113, "Value Loss": 0.32563692331314087, "_runtime": 951.5747084617615, "_timestamp": 1585598321.207578, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1392252445220947, "Value Loss": 0.08740543574094772, "_runtime": 953.0998604297638, "_timestamp": 1585598322.73273, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.120488166809082, "Value Loss": 0.359211802482605, "_runtime": 954.6266002655029, "_timestamp": 1585598324.2594697, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1502623558044434, "Value Loss": 0.6255027651786804, "_runtime": 956.1619782447815, "_timestamp": 1585598325.7948477, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1444337368011475, "Value Loss": 0.06491848826408386, "_runtime": 957.6950652599335, "_timestamp": 1585598327.3279347, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.150546073913574, "Value Loss": 0.08130384236574173, "_runtime": 959.2194771766663, "_timestamp": 1585598328.8523467, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1609976291656494, "Value Loss": 0.2132028341293335, "_runtime": 960.7564656734467, "_timestamp": 1585598330.3893352, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1892457008361816, "Value Loss": 0.054917920380830765, "_runtime": 962.2955176830292, "_timestamp": 1585598331.9283872, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.161954402923584, "Value Loss": 0.04536309838294983, "_runtime": 963.8674459457397, "_timestamp": 1585598333.5003154, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.170513868331909, "Value Loss": 0.20284633338451385, "_runtime": 965.4006836414337, "_timestamp": 1585598335.0335531, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.15364670753479, "Value Loss": 0.04653095081448555, "_runtime": 966.9382374286652, "_timestamp": 1585598336.571107, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1492152214050293, "Value Loss": 0.09282901883125305, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 968.474155664444, "_timestamp": 1585598338.1070251, "_step": 98}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1482186317443848, "Value Loss": 0.04874535650014877, "_runtime": 970.0097522735596, "_timestamp": 1585598339.6426218, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.143742799758911, "Value Loss": 0.049345895648002625, "_runtime": 971.5441880226135, "_timestamp": 1585598341.1770575, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.124584674835205, "Value Loss": 0.049334120005369186, "_runtime": 973.0795292854309, "_timestamp": 1585598342.7123988, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.103116512298584, "Value Loss": 0.044947199523448944, "_runtime": 974.6138153076172, "_timestamp": 1585598344.2466848, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1047470569610596, "Value Loss": 0.04697399586439133, "_runtime": 976.1504466533661, "_timestamp": 1585598345.7833161, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0840749740600586, "Value Loss": 0.0503309965133667, "_runtime": 977.6733417510986, "_timestamp": 1585598347.3062112, "_step": 104}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.055121660232544, "Value Loss": 0.041886284947395325, "_runtime": 979.2105259895325, "_timestamp": 1585598348.8433955, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.046382188796997, "Value Loss": 0.04208695888519287, "_runtime": 980.7371201515198, "_timestamp": 1585598350.3699896, "_step": 106}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.025193214416504, "Value Loss": 0.04725411534309387, "_runtime": 982.2645769119263, "_timestamp": 1585598351.8974464, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0017805099487305, "Value Loss": 0.03750811144709587, "_runtime": 983.7894814014435, "_timestamp": 1585598353.422351, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9955897331237793, "Value Loss": 0.052365053445100784, "_runtime": 985.3248755931854, "_timestamp": 1585598354.957745, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9711068868637085, "Value Loss": 0.04793272539973259, "_runtime": 986.8839621543884, "_timestamp": 1585598356.5168316, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9469127655029297, "Value Loss": 0.035220690071582794, "_runtime": 988.4185547828674, "_timestamp": 1585598358.0514243, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9396536350250244, "Value Loss": 0.0561460517346859, "_runtime": 989.9281284809113, "_timestamp": 1585598359.560998, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.91255784034729, "Value Loss": 0.04362902417778969, "_runtime": 991.4596157073975, "_timestamp": 1585598361.0924852, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8942025899887085, "Value Loss": 0.04957270994782448, "_runtime": 992.9939324855804, "_timestamp": 1585598362.626802, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8696039915084839, "Value Loss": 0.032281436026096344, "_runtime": 994.5304012298584, "_timestamp": 1585598364.1632707, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8653839826583862, "Value Loss": 0.050345178693532944, "_runtime": 996.0590541362762, "_timestamp": 1585598365.6919236, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8301640748977661, "Value Loss": 0.031264498829841614, "_runtime": 997.591551065445, "_timestamp": 1585598367.2244205, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.814814805984497, "Value Loss": 0.039836060255765915, "_runtime": 999.124767780304, "_timestamp": 1585598368.7576373, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7941460609436035, "Value Loss": 0.036206018179655075, "_runtime": 1000.6568810939789, "_timestamp": 1585598370.2897506, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7770569324493408, "Value Loss": 0.028895767405629158, "_runtime": 1002.1897614002228, "_timestamp": 1585598371.822631, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7564995288848877, "Value Loss": 0.028532670810818672, "_runtime": 1003.7233214378357, "_timestamp": 1585598373.356191, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.734702706336975, "Value Loss": 0.04672720655798912, "_runtime": 1005.2551856040955, "_timestamp": 1585598374.888055, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7168296575546265, "Value Loss": 0.04716864973306656, "_runtime": 1006.7891192436218, "_timestamp": 1585598376.4219887, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7039551734924316, "Value Loss": 0.029220545664429665, "_runtime": 1008.312390089035, "_timestamp": 1585598377.9452596, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6811676025390625, "Value Loss": 0.027205834165215492, "_runtime": 1009.8803322315216, "_timestamp": 1585598379.5132017, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6495660543441772, "Value Loss": 0.02620295248925686, "_runtime": 1011.4128928184509, "_timestamp": 1585598381.0457623, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.641700267791748, "Value Loss": 0.04851973056793213, "_runtime": 1012.934534072876, "_timestamp": 1585598382.5674036, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6166785955429077, "Value Loss": 0.04089464992284775, "_runtime": 1014.4670660495758, "_timestamp": 1585598384.0999355, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6072447299957275, "Value Loss": 0.026221463456749916, "_runtime": 1015.9912431240082, "_timestamp": 1585598385.6241126, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5881887674331665, "Value Loss": 0.04429106041789055, "_runtime": 1017.5249767303467, "_timestamp": 1585598387.1578462, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5629440546035767, "Value Loss": 0.023250717669725418, "_runtime": 1019.0504803657532, "_timestamp": 1585598388.6833498, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.539682388305664, "Value Loss": 0.02899855375289917, "_runtime": 1020.5655045509338, "_timestamp": 1585598390.198374, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5160645246505737, "Value Loss": 0.021946413442492485, "_runtime": 1022.0888192653656, "_timestamp": 1585598391.7216887, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5029513835906982, "Value Loss": 0.03275175765156746, "_runtime": 1023.6158201694489, "_timestamp": 1585598393.2486897, "_step": 134}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4901119470596313, "Value Loss": 0.03483809158205986, "_runtime": 1025.1511833667755, "_timestamp": 1585598394.7840528, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4643617868423462, "Value Loss": 0.025566747412085533, "_runtime": 1026.6770677566528, "_timestamp": 1585598396.3099372, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4416213035583496, "Value Loss": 0.019730011001229286, "_runtime": 1028.2157845497131, "_timestamp": 1585598397.848654, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4400079250335693, "Value Loss": 0.02480022981762886, "_runtime": 1029.7551064491272, "_timestamp": 1585598399.387976, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.409332275390625, "Value Loss": 0.025645578280091286, "_runtime": 1031.2894740104675, "_timestamp": 1585598400.9223435, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3927092552185059, "Value Loss": 0.024114569649100304, "_runtime": 1032.8580374717712, "_timestamp": 1585598402.490907, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3682852983474731, "Value Loss": 0.01782110519707203, "_runtime": 1034.391747713089, "_timestamp": 1585598404.0246172, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3674068450927734, "Value Loss": 0.02954544872045517, "_runtime": 1035.9125833511353, "_timestamp": 1585598405.5454528, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3450642824172974, "Value Loss": 0.02241518162190914, "_runtime": 1037.4461421966553, "_timestamp": 1585598407.0790117, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3231228590011597, "Value Loss": 0.016201211139559746, "_runtime": 1038.9785771369934, "_timestamp": 1585598408.6114466, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3051741123199463, "Value Loss": 0.016321351751685143, "_runtime": 1040.511034488678, "_timestamp": 1585598410.143904, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.280173659324646, "Value Loss": 0.015369470231235027, "_runtime": 1042.040864944458, "_timestamp": 1585598411.6737344, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2700302600860596, "Value Loss": 0.021496517583727837, "_runtime": 1043.5743696689606, "_timestamp": 1585598413.2072392, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2488837242126465, "Value Loss": 0.018878543749451637, "_runtime": 1045.096397638321, "_timestamp": 1585598414.7292671, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2330666780471802, "Value Loss": 0.01637677103281021, "_runtime": 1046.618893623352, "_timestamp": 1585598416.251763, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.217226505279541, "Value Loss": 0.018439076840877533, "_runtime": 1048.1522016525269, "_timestamp": 1585598417.7850711, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2006969451904297, "Value Loss": 0.01763688586652279, "_runtime": 1049.6828360557556, "_timestamp": 1585598419.3157055, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1863197088241577, "Value Loss": 0.015211513265967369, "_runtime": 1051.2067046165466, "_timestamp": 1585598420.839574, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1626766920089722, "Value Loss": 0.015801290050148964, "_runtime": 1052.7428679466248, "_timestamp": 1585598422.3757374, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.156990885734558, "Value Loss": 0.020231688395142555, "_runtime": 1054.3124327659607, "_timestamp": 1585598423.9453022, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.125575304031372, "Value Loss": 0.012717929668724537, "_runtime": 1055.8466651439667, "_timestamp": 1585598425.4795346, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1275925636291504, "Value Loss": 0.014764108695089817, "_runtime": 1057.3773589134216, "_timestamp": 1585598427.0102284, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.097951054573059, "Value Loss": 0.012469679117202759, "_runtime": 1058.909751176834, "_timestamp": 1585598428.5426207, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0772714614868164, "Value Loss": 0.011371196247637272, "_runtime": 1060.4453728199005, "_timestamp": 1585598430.0782423, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0790756940841675, "Value Loss": 0.013805204071104527, "_runtime": 1061.9686212539673, "_timestamp": 1585598431.6014907, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0499236583709717, "Value Loss": 0.010843140073120594, "_runtime": 1063.4893584251404, "_timestamp": 1585598433.122228, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.033216118812561, "Value Loss": 0.011823873035609722, "_runtime": 1065.023404121399, "_timestamp": 1585598434.6562736, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.027687430381775, "Value Loss": 0.019308367744088173, "_runtime": 1066.5466837882996, "_timestamp": 1585598436.1795533, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0120574235916138, "Value Loss": 0.011866903863847256, "_runtime": 1068.0792152881622, "_timestamp": 1585598437.7120848, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9856940507888794, "Value Loss": 0.013178588822484016, "_runtime": 1069.60933303833, "_timestamp": 1585598439.2422025, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9704403877258301, "Value Loss": 0.012868275865912437, "_runtime": 1071.1439204216003, "_timestamp": 1585598440.77679, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9563429355621338, "Value Loss": 0.009506074711680412, "_runtime": 1072.677475452423, "_timestamp": 1585598442.310345, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9548807144165039, "Value Loss": 0.022748783230781555, "_runtime": 1074.1993417739868, "_timestamp": 1585598443.8322113, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9229394197463989, "Value Loss": 0.008589419536292553, "_runtime": 1075.7318575382233, "_timestamp": 1585598445.364727, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.910698652267456, "Value Loss": 0.010132177732884884, "_runtime": 1077.3006491661072, "_timestamp": 1585598446.9335186, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9008359909057617, "Value Loss": 0.012796168215572834, "_runtime": 1078.8337275981903, "_timestamp": 1585598448.466597, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8943312764167786, "Value Loss": 0.00875122845172882, "_runtime": 1080.3667006492615, "_timestamp": 1585598449.9995701, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8689578175544739, "Value Loss": 0.009159955196082592, "_runtime": 1081.8889219760895, "_timestamp": 1585598451.5217915, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8598637580871582, "Value Loss": 0.007376137189567089, "_runtime": 1083.4204893112183, "_timestamp": 1585598453.0533588, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8398534059524536, "Value Loss": 0.009293443523347378, "_runtime": 1084.9582703113556, "_timestamp": 1585598454.5911398, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8342504501342773, "Value Loss": 0.01510641910135746, "_runtime": 1086.49090051651, "_timestamp": 1585598456.12377, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8175742626190186, "Value Loss": 0.012465403415262699, "_runtime": 1088.0242233276367, "_timestamp": 1585598457.6570928, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7993918061256409, "Value Loss": 0.010000771842896938, "_runtime": 1089.5501956939697, "_timestamp": 1585598459.1830652, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7862066030502319, "Value Loss": 0.009834975935518742, "_runtime": 1091.0843403339386, "_timestamp": 1585598460.7172098, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7810291051864624, "Value Loss": 0.015063558705151081, "_runtime": 1092.6206469535828, "_timestamp": 1585598462.2535164, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7621681690216064, "Value Loss": 0.006399898789823055, "_runtime": 1094.155208826065, "_timestamp": 1585598463.7880783, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7559010982513428, "Value Loss": 0.00816822424530983, "_runtime": 1095.6871330738068, "_timestamp": 1585598465.3200026, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7505151629447937, "Value Loss": 0.011960620060563087, "_runtime": 1097.2187519073486, "_timestamp": 1585598466.8516214, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.71767258644104, "Value Loss": 0.006763775832951069, "_runtime": 1098.7522466182709, "_timestamp": 1585598468.385116, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7065920233726501, "Value Loss": 0.005937873851507902, "_runtime": 1100.3186264038086, "_timestamp": 1585598469.951496, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7066634297370911, "Value Loss": 0.007076316513121128, "_runtime": 1101.8421039581299, "_timestamp": 1585598471.4749734, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6811927556991577, "Value Loss": 0.006244806572794914, "_runtime": 1103.3748693466187, "_timestamp": 1585598473.0077388, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6741769313812256, "Value Loss": 0.008172119036316872, "_runtime": 1104.9081666469574, "_timestamp": 1585598474.5410361, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6596899032592773, "Value Loss": 0.00467649195343256, "_runtime": 1106.4434432983398, "_timestamp": 1585598476.0763128, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6657312512397766, "Value Loss": 0.018017800524830818, "_runtime": 1107.9790270328522, "_timestamp": 1585598477.6118965, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6526743173599243, "Value Loss": 0.009354846552014351, "_runtime": 1109.5087547302246, "_timestamp": 1585598479.1416242, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6425248384475708, "Value Loss": 0.02196715958416462, "_runtime": 1111.0431232452393, "_timestamp": 1585598480.6759927, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6289703249931335, "Value Loss": 0.007095223292708397, "_runtime": 1112.5655119419098, "_timestamp": 1585598482.1983814, "_step": 192}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6155688762664795, "Value Loss": 0.01342693343758583, "_runtime": 1114.0953834056854, "_timestamp": 1585598483.728253, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5989823341369629, "Value Loss": 0.004263609182089567, "_runtime": 1115.6258523464203, "_timestamp": 1585598485.2587218, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5882334113121033, "Value Loss": 0.006014666985720396, "_runtime": 1117.1590445041656, "_timestamp": 1585598486.791914, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5858871936798096, "Value Loss": 0.012637842446565628, "_runtime": 1118.6913928985596, "_timestamp": 1585598488.3242624, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5721091032028198, "Value Loss": 0.008029243908822536, "_runtime": 1120.2247552871704, "_timestamp": 1585598489.8576248, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5563194155693054, "Value Loss": 0.003906966187059879, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1121.7581751346588, "_timestamp": 1585598491.3910446, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5639117360115051, "Value Loss": 0.0179913192987442, "_runtime": 1123.323927640915, "_timestamp": 1585598492.9567971, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5499929189682007, "Value Loss": 0.010547119192779064, "_runtime": 1124.8338432312012, "_timestamp": 1585598494.4667127, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5324627161026001, "Value Loss": 0.0035618157126009464, "_runtime": 1126.3674631118774, "_timestamp": 1585598496.0003326, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5294889211654663, "Value Loss": 0.006934693083167076, "_runtime": 1127.9005014896393, "_timestamp": 1585598497.533371, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5129436254501343, "Value Loss": 0.006597027648240328, "_runtime": 1129.4338726997375, "_timestamp": 1585598499.0667422, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5057370662689209, "Value Loss": 0.003300079610198736, "_runtime": 1130.9663734436035, "_timestamp": 1585598500.599243, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5104377865791321, "Value Loss": 0.007051998283714056, "_runtime": 1132.4965388774872, "_timestamp": 1585598502.1294084, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48760098218917847, "Value Loss": 0.0050392295233905315, "_runtime": 1134.0309374332428, "_timestamp": 1585598503.663807, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4732929766178131, "Value Loss": 0.004104644060134888, "_runtime": 1135.5552096366882, "_timestamp": 1585598505.188079, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4781290590763092, "Value Loss": 0.004857736639678478, "_runtime": 1137.0782418251038, "_timestamp": 1585598506.7111113, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4621921181678772, "Value Loss": 0.0061461408622562885, "_runtime": 1138.6122572422028, "_timestamp": 1585598508.2451267, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4601612687110901, "Value Loss": 0.003445375245064497, "_runtime": 1140.1366314888, "_timestamp": 1585598509.769501, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4595569670200348, "Value Loss": 0.018658945336937904, "_runtime": 1141.6458225250244, "_timestamp": 1585598511.278692, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4328087270259857, "Value Loss": 0.0038304270710796118, "_runtime": 1143.160215139389, "_timestamp": 1585598512.7930846, "_step": 212}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42587903141975403, "Value Loss": 0.003643806790933013, "_runtime": 1144.7184438705444, "_timestamp": 1585598514.3513134, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42121219635009766, "Value Loss": 0.0035847306717187166, "_runtime": 1146.2391030788422, "_timestamp": 1585598515.8719726, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42985060811042786, "Value Loss": 0.006354187149554491, "_runtime": 1147.7586343288422, "_timestamp": 1585598517.3915038, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4069168269634247, "Value Loss": 0.004685480147600174, "_runtime": 1149.279441356659, "_timestamp": 1585598518.9123108, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41483262181282043, "Value Loss": 0.005045796744525433, "_runtime": 1150.7993204593658, "_timestamp": 1585598520.43219, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.38785725831985474, "Value Loss": 0.0034582510124891996, "_runtime": 1152.3178000450134, "_timestamp": 1585598521.9506695, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3810785114765167, "Value Loss": 0.00314173917286098, "_runtime": 1153.8384969234467, "_timestamp": 1585598523.4713664, "_step": 219}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3744676113128662, "Value Loss": 0.0026179340202361345, "_runtime": 1155.3585114479065, "_timestamp": 1585598524.991381, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36910760402679443, "Value Loss": 0.0028075033333152533, "_runtime": 1156.8853936195374, "_timestamp": 1585598526.518263, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3734285533428192, "Value Loss": 0.008823911659419537, "_runtime": 1158.4201114177704, "_timestamp": 1585598528.052981, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35674911737442017, "Value Loss": 0.005265909247100353, "_runtime": 1159.9545373916626, "_timestamp": 1585598529.5874069, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35050061345100403, "Value Loss": 0.002955490257591009, "_runtime": 1161.4868342876434, "_timestamp": 1585598531.1197038, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3399917483329773, "Value Loss": 0.0019176218193024397, "_runtime": 1163.0194005966187, "_timestamp": 1585598532.65227, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3405914902687073, "Value Loss": 0.007016506511718035, "_runtime": 1164.5510702133179, "_timestamp": 1585598534.1839397, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33654624223709106, "Value Loss": 0.004143085330724716, "_runtime": 1166.0755219459534, "_timestamp": 1585598535.7083914, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3243063688278198, "Value Loss": 0.0023153957445174456, "_runtime": 1167.6445541381836, "_timestamp": 1585598537.2774236, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3116140365600586, "Value Loss": 0.002614166121929884, "_runtime": 1169.1770930290222, "_timestamp": 1585598538.8099625, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32511404156684875, "Value Loss": 0.014729268848896027, "_runtime": 1170.7086379528046, "_timestamp": 1585598540.3415074, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3091866374015808, "Value Loss": 0.006386264692991972, "_runtime": 1172.2457263469696, "_timestamp": 1585598541.8785958, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3132910132408142, "Value Loss": 0.018147844821214676, "_runtime": 1173.7775444984436, "_timestamp": 1585598543.410414, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2933690845966339, "Value Loss": 0.003689367789775133, "_runtime": 1175.3000361919403, "_timestamp": 1585598544.9329057, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30348965525627136, "Value Loss": 0.010046468116343021, "_runtime": 1176.8325514793396, "_timestamp": 1585598546.465421, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2807721197605133, "Value Loss": 0.001441034022718668, "_runtime": 1178.3639073371887, "_timestamp": 1585598547.9967768, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.28372570872306824, "Value Loss": 0.006908949464559555, "_runtime": 1179.896891117096, "_timestamp": 1585598549.5297606, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.27110180258750916, "Value Loss": 0.0014216442359611392, "_runtime": 1181.4289677143097, "_timestamp": 1585598551.0618372, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2690656781196594, "Value Loss": 0.004317550454288721, "_runtime": 1182.9507274627686, "_timestamp": 1585598552.583597, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2669152021408081, "Value Loss": 0.002665216801688075, "_runtime": 1184.4851400852203, "_timestamp": 1585598554.1180096, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2699339687824249, "Value Loss": 0.00886039063334465, "_runtime": 1186.0083293914795, "_timestamp": 1585598555.6411989, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2596175968647003, "Value Loss": 0.006230509839951992, "_runtime": 1187.5418152809143, "_timestamp": 1585598557.1746848, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26527154445648193, "Value Loss": 0.007524756249040365, "_runtime": 1189.063496351242, "_timestamp": 1585598558.6963658, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2429017871618271, "Value Loss": 0.0014390709111467004, "_runtime": 1190.6339299678802, "_timestamp": 1585598560.2667994, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24979080259799957, "Value Loss": 0.009981722570955753, "_runtime": 1192.1665649414062, "_timestamp": 1585598561.7994344, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23664484918117523, "Value Loss": 0.002344579203054309, "_runtime": 1193.6990208625793, "_timestamp": 1585598563.3318903, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23264452815055847, "Value Loss": 0.0025261854752898216, "_runtime": 1195.2214260101318, "_timestamp": 1585598564.8542955, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24406765401363373, "Value Loss": 0.003724749432876706, "_runtime": 1196.7406778335571, "_timestamp": 1585598566.3735473, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22853673994541168, "Value Loss": 0.003601871896535158, "_runtime": 1198.273447751999, "_timestamp": 1585598567.9063172, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22755789756774902, "Value Loss": 0.001313770073466003, "_runtime": 1199.8060574531555, "_timestamp": 1585598569.438927, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21255648136138916, "Value Loss": 0.0022083704825490713, "_runtime": 1201.339376449585, "_timestamp": 1585598570.972246, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21735818684101105, "Value Loss": 0.005182396154850721, "_runtime": 1202.8728532791138, "_timestamp": 1585598572.5057228, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.20556597411632538, "Value Loss": 0.001573506509885192, "_runtime": 1204.4073417186737, "_timestamp": 1585598574.0402112, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2018900364637375, "Value Loss": 0.0013214999344199896, "_runtime": 1205.9379601478577, "_timestamp": 1585598575.5708296, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2060626894235611, "Value Loss": 0.006310320924967527, "_runtime": 1207.4706139564514, "_timestamp": 1585598577.1034834, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.203205406665802, "Value Loss": 0.0009591004345566034, "_runtime": 1209.0024466514587, "_timestamp": 1585598578.6353161, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2021074891090393, "Value Loss": 0.0026551089249551296, "_runtime": 1210.535789489746, "_timestamp": 1585598580.168659, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19101929664611816, "Value Loss": 0.0013743519084528089, "_runtime": 1212.0691056251526, "_timestamp": 1585598581.701975, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18977612257003784, "Value Loss": 0.005379491951316595, "_runtime": 1213.6364784240723, "_timestamp": 1585598583.269348, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18277980387210846, "Value Loss": 0.0024182675406336784, "_runtime": 1215.1642897129059, "_timestamp": 1585598584.7971592, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17884108424186707, "Value Loss": 0.0036453003995120525, "_runtime": 1216.6961200237274, "_timestamp": 1585598586.3289895, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17594653367996216, "Value Loss": 0.0021460275165736675, "_runtime": 1218.2277336120605, "_timestamp": 1585598587.860603, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18155716359615326, "Value Loss": 0.007154636085033417, "_runtime": 1219.7600870132446, "_timestamp": 1585598589.3929565, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16559427976608276, "Value Loss": 0.000829906843136996, "_runtime": 1221.2832491397858, "_timestamp": 1585598590.9161186, "_step": 263}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16971537470817566, "Value Loss": 0.005597273353487253, "_runtime": 1222.8159079551697, "_timestamp": 1585598592.4487774, "_step": 264}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16151484847068787, "Value Loss": 0.0027464241720736027, "_runtime": 1224.3384807109833, "_timestamp": 1585598593.9713502, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1541745811700821, "Value Loss": 0.001819971832446754, "_runtime": 1225.873144865036, "_timestamp": 1585598595.5060143, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16514816880226135, "Value Loss": 0.004826808348298073, "_runtime": 1227.4059057235718, "_timestamp": 1585598597.0387752, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1520310491323471, "Value Loss": 0.0025189463049173355, "_runtime": 1228.939561843872, "_timestamp": 1585598598.5724313, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14475089311599731, "Value Loss": 0.0017404245445504785, "_runtime": 1230.4749376773834, "_timestamp": 1585598600.1078072, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16096003353595734, "Value Loss": 0.004973060917109251, "_runtime": 1232.0076150894165, "_timestamp": 1585598601.6404846, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.155519500374794, "Value Loss": 0.009120417758822441, "_runtime": 1233.5379223823547, "_timestamp": 1585598603.1707919, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14099515974521637, "Value Loss": 0.003720910055562854, "_runtime": 1235.0732419490814, "_timestamp": 1585598604.7061114, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13460640609264374, "Value Loss": 0.0013020692858844995, "_runtime": 1236.6396932601929, "_timestamp": 1585598606.2725627, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14110787212848663, "Value Loss": 0.00598778435960412, "_runtime": 1238.1625082492828, "_timestamp": 1585598607.7953777, "_step": 274}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14521241188049316, "Value Loss": 0.007445199880748987, "_runtime": 1239.6964643001556, "_timestamp": 1585598609.3293338, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14590944349765778, "Value Loss": 0.01830925978720188, "_runtime": 1241.227698802948, "_timestamp": 1585598610.8605683, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14508913457393646, "Value Loss": 0.007576082833111286, "_runtime": 1242.750456571579, "_timestamp": 1585598612.383326, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13845627009868622, "Value Loss": 0.005405189469456673, "_runtime": 1244.2864620685577, "_timestamp": 1585598613.9193316, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12380973994731903, "Value Loss": 0.0011651070090010762, "_runtime": 1245.7976989746094, "_timestamp": 1585598615.4305685, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1256663054227829, "Value Loss": 0.0034320466220378876, "_runtime": 1247.3293766975403, "_timestamp": 1585598616.9622462, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12147456407546997, "Value Loss": 0.0008491865010000765, "_runtime": 1248.8521075248718, "_timestamp": 1585598618.484977, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12410183250904083, "Value Loss": 0.0011461583198979497, "_runtime": 1250.3867156505585, "_timestamp": 1585598620.0195851, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12486900389194489, "Value Loss": 0.005249244626611471, "_runtime": 1251.9181554317474, "_timestamp": 1585598621.551025, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12610787153244019, "Value Loss": 0.006729298271238804, "_runtime": 1253.4517295360565, "_timestamp": 1585598623.084599, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11226579546928406, "Value Loss": 0.0018528312211856246, "_runtime": 1254.9823215007782, "_timestamp": 1585598624.615191, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11086325347423553, "Value Loss": 0.0016176808858290315, "_runtime": 1256.5014095306396, "_timestamp": 1585598626.134279, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10830351710319519, "Value Loss": 0.0018736893543973565, "_runtime": 1258.0722947120667, "_timestamp": 1585598627.7051642, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.12546221911907196, "Value Loss": 0.0039561134763062, "_runtime": 1259.6062271595001, "_timestamp": 1585598629.2390966, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11003513634204865, "Value Loss": 0.00199045124463737, "_runtime": 1261.141404390335, "_timestamp": 1585598630.7742739, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11039675027132034, "Value Loss": 0.0030224998481571674, "_runtime": 1262.6743466854095, "_timestamp": 1585598632.3072162, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1081768125295639, "Value Loss": 0.0022236674558371305, "_runtime": 1264.2082786560059, "_timestamp": 1585598633.8411481, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10271582007408142, "Value Loss": 0.001829597749747336, "_runtime": 1265.7398900985718, "_timestamp": 1585598635.3727596, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10191497951745987, "Value Loss": 0.0035723221953958273, "_runtime": 1267.2628095149994, "_timestamp": 1585598636.895679, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10019545257091522, "Value Loss": 0.003735429374501109, "_runtime": 1268.7855966091156, "_timestamp": 1585598638.418466, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11287327110767365, "Value Loss": 0.0039024099241942167, "_runtime": 1270.3103785514832, "_timestamp": 1585598639.943248, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1066519245505333, "Value Loss": 0.006836653687059879, "_runtime": 1271.8362836837769, "_timestamp": 1585598641.4691532, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09085126221179962, "Value Loss": 0.0017722465563565493, "_runtime": 1273.3622643947601, "_timestamp": 1585598642.9951339, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0913877785205841, "Value Loss": 0.0009114734712056816, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1274.8959710597992, "_timestamp": 1585598644.5288405, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1030154600739479, "Value Loss": 0.0019425142090767622, "_runtime": 1276.4226987361908, "_timestamp": 1585598646.0555682, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09298411756753922, "Value Loss": 0.0024622983764857054, "_runtime": 1277.945701599121, "_timestamp": 1585598647.578571, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10290724784135818, "Value Loss": 0.006614241749048233, "_runtime": 1279.4800086021423, "_timestamp": 1585598649.112878, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.087553471326828, "Value Loss": 0.0033790103625506163, "_runtime": 1281.0493416786194, "_timestamp": 1585598650.6822112, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08683888614177704, "Value Loss": 0.0016242117853835225, "_runtime": 1282.5826363563538, "_timestamp": 1585598652.2155058, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09680085629224777, "Value Loss": 0.0038002394139766693, "_runtime": 1284.1180827617645, "_timestamp": 1585598653.7509522, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09134392440319061, "Value Loss": 0.007292134687304497, "_runtime": 1285.6386723518372, "_timestamp": 1585598655.2715418, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07833068817853928, "Value Loss": 0.0015961412573233247, "_runtime": 1287.16424202919, "_timestamp": 1585598656.7971115, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08177782595157623, "Value Loss": 0.0030053011141717434, "_runtime": 1288.68621301651, "_timestamp": 1585598658.3190825, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08152972161769867, "Value Loss": 0.000989108462817967, "_runtime": 1290.2180302143097, "_timestamp": 1585598659.8508997, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09047640860080719, "Value Loss": 0.007125569973140955, "_runtime": 1291.7507841587067, "_timestamp": 1585598661.3836536, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07764721661806107, "Value Loss": 0.0023517112713307142, "_runtime": 1293.2852697372437, "_timestamp": 1585598662.9181392, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09158056229352951, "Value Loss": 0.003637166228145361, "_runtime": 1294.8255355358124, "_timestamp": 1585598664.458405, "_step": 311}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07204776257276535, "Value Loss": 0.0018205500673502684, "_runtime": 1296.3478555679321, "_timestamp": 1585598665.980725, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08333050459623337, "Value Loss": 0.0016395642887800932, "_runtime": 1297.8797211647034, "_timestamp": 1585598667.5125906, "_step": 313}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08376965671777725, "Value Loss": 0.007322276476770639, "_runtime": 1299.403464794159, "_timestamp": 1585598669.0363343, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07847592234611511, "Value Loss": 0.0007149341981858015, "_runtime": 1300.914516210556, "_timestamp": 1585598670.5473857, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07690641283988953, "Value Loss": 0.0006610893760807812, "_runtime": 1302.449415922165, "_timestamp": 1585598672.0822854, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07765568792819977, "Value Loss": 0.0016854017740115523, "_runtime": 1304.0194714069366, "_timestamp": 1585598673.652341, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06826068460941315, "Value Loss": 0.0035275504924356937, "_runtime": 1305.5512614250183, "_timestamp": 1585598675.184131, "_step": 318}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07528013736009598, "Value Loss": 0.0021985704079270363, "_runtime": 1307.085218667984, "_timestamp": 1585598676.7180882, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07584907859563828, "Value Loss": 0.0025711378548294306, "_runtime": 1308.618045091629, "_timestamp": 1585598678.2509146, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07811633497476578, "Value Loss": 0.006327959708869457, "_runtime": 1310.1518549919128, "_timestamp": 1585598679.7847245, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.061195265501737595, "Value Loss": 0.0011751444544643164, "_runtime": 1311.6833579540253, "_timestamp": 1585598681.3162274, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0756453350186348, "Value Loss": 0.009873438626527786, "_runtime": 1313.2158665657043, "_timestamp": 1585598682.848736, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05616943910717964, "Value Loss": 0.001635911175981164, "_runtime": 1314.7391953468323, "_timestamp": 1585598684.3720648, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06729666143655777, "Value Loss": 0.0033394545316696167, "_runtime": 1316.270429134369, "_timestamp": 1585598685.9032986, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07274679094552994, "Value Loss": 0.002844823058694601, "_runtime": 1317.803414106369, "_timestamp": 1585598687.4362836, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06947897374629974, "Value Loss": 0.0021773388143628836, "_runtime": 1319.3276162147522, "_timestamp": 1585598688.9604857, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05886467173695564, "Value Loss": 0.0011124927550554276, "_runtime": 1320.859611272812, "_timestamp": 1585598690.4924808, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06409037113189697, "Value Loss": 0.004021619912236929, "_runtime": 1322.3979053497314, "_timestamp": 1585598692.0307748, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.059121958911418915, "Value Loss": 0.0025642351247370243, "_runtime": 1323.93150472641, "_timestamp": 1585598693.5643742, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0572761707007885, "Value Loss": 0.0009172093123197556, "_runtime": 1325.4621539115906, "_timestamp": 1585598695.0950234, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05724069103598595, "Value Loss": 0.0014588602352887392, "_runtime": 1327.0182378292084, "_timestamp": 1585598696.6511073, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06182143837213516, "Value Loss": 0.004573224112391472, "_runtime": 1328.55371427536, "_timestamp": 1585598698.1865838, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.053734343498945236, "Value Loss": 0.0029487013816833496, "_runtime": 1330.0764591693878, "_timestamp": 1585598699.7093287, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05220050364732742, "Value Loss": 0.0016950048739090562, "_runtime": 1331.6020426750183, "_timestamp": 1585598701.2349122, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04926159232854843, "Value Loss": 0.0015011465875431895, "_runtime": 1333.125691652298, "_timestamp": 1585598702.7585611, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06607339531183243, "Value Loss": 0.0027295853942632675, "_runtime": 1334.6500916481018, "_timestamp": 1585598704.2829611, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.058847397565841675, "Value Loss": 0.0038532076869159937, "_runtime": 1336.1720101833344, "_timestamp": 1585598705.8048797, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04758792370557785, "Value Loss": 0.0013336131814867258, "_runtime": 1337.6935667991638, "_timestamp": 1585598707.3264363, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04542519897222519, "Value Loss": 0.0018457871628925204, "_runtime": 1339.2156925201416, "_timestamp": 1585598708.848562, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06322644650936127, "Value Loss": 0.0027340357191860676, "_runtime": 1340.7502703666687, "_timestamp": 1585598710.3831398, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05620034039020538, "Value Loss": 0.0015224581584334373, "_runtime": 1342.2842440605164, "_timestamp": 1585598711.9171135, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.061741314828395844, "Value Loss": 0.004320685751736164, "_runtime": 1343.8183424472809, "_timestamp": 1585598713.451212, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.059697672724723816, "Value Loss": 0.00574801629409194, "_runtime": 1345.3517684936523, "_timestamp": 1585598714.984638, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.042362380772829056, "Value Loss": 0.0018189098918810487, "_runtime": 1346.8897948265076, "_timestamp": 1585598716.5226643, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05460134521126747, "Value Loss": 0.0033401467371731997, "_runtime": 1348.45938038826, "_timestamp": 1585598718.0922499, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05885536968708038, "Value Loss": 0.011929629370570183, "_runtime": 1349.9812796115875, "_timestamp": 1585598719.614149, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.052508022636175156, "Value Loss": 0.006870186887681484, "_runtime": 1351.5130398273468, "_timestamp": 1585598721.1459093, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05244441330432892, "Value Loss": 0.0011031234171241522, "_runtime": 1353.0453758239746, "_timestamp": 1585598722.6782453, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0435723140835762, "Value Loss": 0.0022990091238170862, "_runtime": 1354.5815751552582, "_timestamp": 1585598724.2144446, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.042425259947776794, "Value Loss": 0.0016002492047846317, "_runtime": 1356.1153492927551, "_timestamp": 1585598725.7482188, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05061052739620209, "Value Loss": 0.006597602739930153, "_runtime": 1357.6368918418884, "_timestamp": 1585598727.2697613, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04433570057153702, "Value Loss": 0.0009326268918812275, "_runtime": 1359.160585641861, "_timestamp": 1585598728.7934551, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04276915639638901, "Value Loss": 0.0034803126472979784, "_runtime": 1360.6846277713776, "_timestamp": 1585598730.3174973, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04385530948638916, "Value Loss": 0.0008561760187149048, "_runtime": 1362.2071387767792, "_timestamp": 1585598731.8400083, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.055883850902318954, "Value Loss": 0.0024402274284511805, "_runtime": 1363.7420148849487, "_timestamp": 1585598733.3748844, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04638320207595825, "Value Loss": 0.00476148771122098, "_runtime": 1365.2618200778961, "_timestamp": 1585598734.8946896, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038071151822805405, "Value Loss": 0.001554018002934754, "_runtime": 1366.794228553772, "_timestamp": 1585598736.427098, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.048039600253105164, "Value Loss": 0.00291903386823833, "_runtime": 1368.32932639122, "_timestamp": 1585598737.9621959, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05418055132031441, "Value Loss": 0.011564905755221844, "_runtime": 1369.862431049347, "_timestamp": 1585598739.4953005, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.051527369767427444, "Value Loss": 0.006594822276383638, "_runtime": 1371.4112603664398, "_timestamp": 1585598741.0441298, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03572848066687584, "Value Loss": 0.0017257160507142544, "_runtime": 1372.9455630779266, "_timestamp": 1585598742.5784326, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043122004717588425, "Value Loss": 0.002702672267332673, "_runtime": 1374.4810271263123, "_timestamp": 1585598744.1138966, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.040991537272930145, "Value Loss": 0.0010692853247746825, "_runtime": 1376.0007827281952, "_timestamp": 1585598745.6336522, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043802306056022644, "Value Loss": 0.0040598479099571705, "_runtime": 1377.536608695984, "_timestamp": 1585598747.1694782, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04427477717399597, "Value Loss": 0.0007443437352776527, "_runtime": 1379.0689942836761, "_timestamp": 1585598748.7018638, "_step": 366}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04585371911525726, "Value Loss": 0.005385424476116896, "_runtime": 1380.6029574871063, "_timestamp": 1585598750.235827, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.035887062549591064, "Value Loss": 0.0009467307245358825, "_runtime": 1382.1266810894012, "_timestamp": 1585598751.7595506, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.033165283501148224, "Value Loss": 0.0015388353494927287, "_runtime": 1383.658982038498, "_timestamp": 1585598753.2918515, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04723149910569191, "Value Loss": 0.0034752709325402975, "_runtime": 1385.1919734477997, "_timestamp": 1585598754.824843, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.035651564598083496, "Value Loss": 0.0014537906972691417, "_runtime": 1386.731559753418, "_timestamp": 1585598756.3644292, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04974590241909027, "Value Loss": 0.0034953204449266195, "_runtime": 1388.2732629776, "_timestamp": 1585598757.9061325, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04499003291130066, "Value Loss": 0.0055045634508132935, "_runtime": 1389.8029656410217, "_timestamp": 1585598759.4358351, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.048987939953804016, "Value Loss": 0.005759659688919783, "_runtime": 1391.3259253501892, "_timestamp": 1585598760.9587948, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04537154734134674, "Value Loss": 0.004438423551619053, "_runtime": 1392.858184337616, "_timestamp": 1585598762.4910538, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04198767989873886, "Value Loss": 0.00274551659822464, "_runtime": 1394.4246008396149, "_timestamp": 1585598764.0574703, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03170420601963997, "Value Loss": 0.0011442271061241627, "_runtime": 1395.9580085277557, "_timestamp": 1585598765.590878, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030830634757876396, "Value Loss": 0.0014388328418135643, "_runtime": 1397.4811460971832, "_timestamp": 1585598767.1140156, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04318133741617203, "Value Loss": 0.003127062227576971, "_runtime": 1399.0154802799225, "_timestamp": 1585598768.6483498, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04767497628927231, "Value Loss": 0.004436335526406765, "_runtime": 1400.5490500926971, "_timestamp": 1585598770.1819196, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04736477509140968, "Value Loss": 0.0029421646613627672, "_runtime": 1402.0830445289612, "_timestamp": 1585598771.715914, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03199774771928787, "Value Loss": 0.0008667430956847966, "_runtime": 1403.6122651100159, "_timestamp": 1585598773.2451346, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038939185440540314, "Value Loss": 0.000510984449647367, "_runtime": 1405.1359596252441, "_timestamp": 1585598774.768829, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03170882910490036, "Value Loss": 0.0010143506806343794, "_runtime": 1406.6697471141815, "_timestamp": 1585598776.3026166, "_step": 384}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03756934404373169, "Value Loss": 0.0006988620734773576, "_runtime": 1408.2014780044556, "_timestamp": 1585598777.8343475, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03421136736869812, "Value Loss": 0.0009795279474928975, "_runtime": 1409.7259562015533, "_timestamp": 1585598779.3588257, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.045114580541849136, "Value Loss": 0.008641541935503483, "_runtime": 1411.249585390091, "_timestamp": 1585598780.8824549, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04193197935819626, "Value Loss": 0.0017597569385543466, "_runtime": 1412.772134065628, "_timestamp": 1585598782.4050035, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.039338115602731705, "Value Loss": 0.0009888361673802137, "_runtime": 1414.3071987628937, "_timestamp": 1585598783.9400682, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04471239820122719, "Value Loss": 0.003395994193851948, "_runtime": 1415.8326740264893, "_timestamp": 1585598785.4655435, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028100430965423584, "Value Loss": 0.00105978362262249, "_runtime": 1417.4023139476776, "_timestamp": 1585598787.0351834, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03213988617062569, "Value Loss": 0.0017848777351900935, "_runtime": 1418.938747882843, "_timestamp": 1585598788.5716174, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02798759937286377, "Value Loss": 0.0010447949171066284, "_runtime": 1420.4721393585205, "_timestamp": 1585598790.1050088, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04424319043755531, "Value Loss": 0.006753366906195879, "_runtime": 1422.0036406517029, "_timestamp": 1585598791.6365101, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04421551525592804, "Value Loss": 0.006699586287140846, "_runtime": 1423.537865638733, "_timestamp": 1585598793.1707351, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02934245951473713, "Value Loss": 0.0010737295961007476, "_runtime": 1425.0692880153656, "_timestamp": 1585598794.7021575, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.038589928299188614, "Value Loss": 0.0010795916896313429, "_runtime": 1426.5915882587433, "_timestamp": 1585598796.2244577, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02683417685329914, "Value Loss": 0.0015647972468286753, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1428.1266975402832, "_timestamp": 1585598797.759567, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03762200474739075, "Value Loss": 0.002805003896355629, "_runtime": 1429.6601042747498, "_timestamp": 1585598799.2929738, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03507043048739433, "Value Loss": 0.004072756040841341, "_runtime": 1431.194636106491, "_timestamp": 1585598800.8275056, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03757808730006218, "Value Loss": 0.0053816563449800014, "_runtime": 1432.7315120697021, "_timestamp": 1585598802.3643816, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028094002977013588, "Value Loss": 0.0010183562990278006, "_runtime": 1434.263164281845, "_timestamp": 1585598803.8960338, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025871071964502335, "Value Loss": 0.0015126002253964543, "_runtime": 1435.796023607254, "_timestamp": 1585598805.428893, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043209508061409, "Value Loss": 0.006461319513618946, "_runtime": 1437.3303666114807, "_timestamp": 1585598806.963236, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027477502822875977, "Value Loss": 0.0009695382323116064, "_runtime": 1438.8673284053802, "_timestamp": 1585598808.500198, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.033030446618795395, "Value Loss": 0.003073577070608735, "_runtime": 1440.4367022514343, "_timestamp": 1585598810.0695717, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03359891474246979, "Value Loss": 0.004002801608294249, "_runtime": 1441.9676315784454, "_timestamp": 1585598811.600501, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03051254153251648, "Value Loss": 0.0008792396984063089, "_runtime": 1443.5005571842194, "_timestamp": 1585598813.1334267, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03304094448685646, "Value Loss": 0.0035711212549358606, "_runtime": 1445.0178854465485, "_timestamp": 1585598814.650755, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03085266426205635, "Value Loss": 0.001188320224173367, "_runtime": 1446.5525538921356, "_timestamp": 1585598816.1854234, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028139514848589897, "Value Loss": 0.0020984516013413668, "_runtime": 1448.075493812561, "_timestamp": 1585598817.7083633, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02963847853243351, "Value Loss": 0.0010026093805208802, "_runtime": 1449.5992255210876, "_timestamp": 1585598819.232095, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.026181016117334366, "Value Loss": 0.0008413438918069005, "_runtime": 1451.1220343112946, "_timestamp": 1585598820.7549038, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029601605609059334, "Value Loss": 0.0007730686338618398, "_runtime": 1452.6467072963715, "_timestamp": 1585598822.2795768, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0338565967977047, "Value Loss": 0.0015392664354294538, "_runtime": 1454.1709070205688, "_timestamp": 1585598823.8037765, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.034709248691797256, "Value Loss": 0.0015905286418274045, "_runtime": 1455.6827023029327, "_timestamp": 1585598825.3155718, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029723895713686943, "Value Loss": 0.0016542829107493162, "_runtime": 1457.2049050331116, "_timestamp": 1585598826.8377745, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0376276820898056, "Value Loss": 0.005711224861443043, "_runtime": 1458.728407382965, "_timestamp": 1585598828.3612769, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03460689261555672, "Value Loss": 0.0009564986103214324, "_runtime": 1460.2636890411377, "_timestamp": 1585598829.8965585, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03383200615644455, "Value Loss": 0.005136928521096706, "_runtime": 1461.8349859714508, "_timestamp": 1585598831.4678555, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03545885160565376, "Value Loss": 0.003751913318410516, "_runtime": 1463.3693764209747, "_timestamp": 1585598833.002246, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027602849528193474, "Value Loss": 0.0017602198058739305, "_runtime": 1464.900872707367, "_timestamp": 1585598834.5337422, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02931065298616886, "Value Loss": 0.001633909298107028, "_runtime": 1466.4231338500977, "_timestamp": 1585598836.0560033, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03103899583220482, "Value Loss": 0.0036851284094154835, "_runtime": 1467.9563293457031, "_timestamp": 1585598837.5891988, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.026987776160240173, "Value Loss": 0.002799911657348275, "_runtime": 1469.4917330741882, "_timestamp": 1585598839.1246026, "_step": 425}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02741536684334278, "Value Loss": 0.001829115324653685, "_runtime": 1471.024634361267, "_timestamp": 1585598840.6575038, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.039461106061935425, "Value Loss": 0.01157134398818016, "_runtime": 1472.5591859817505, "_timestamp": 1585598842.1920555, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03580230474472046, "Value Loss": 0.004089635796844959, "_runtime": 1474.0907399654388, "_timestamp": 1585598843.7236094, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.039475880563259125, "Value Loss": 0.011631843633949757, "_runtime": 1475.6235213279724, "_timestamp": 1585598845.2563908, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03240526467561722, "Value Loss": 0.0037611990701407194, "_runtime": 1477.1463432312012, "_timestamp": 1585598846.7792127, "_step": 430}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024752940982580185, "Value Loss": 0.0014074245700612664, "_runtime": 1478.6805474758148, "_timestamp": 1585598848.313417, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.024574533104896545, "Value Loss": 0.0014111618511378765, "_runtime": 1480.2136318683624, "_timestamp": 1585598849.8465014, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02936672419309616, "Value Loss": 0.0026794641744345427, "_runtime": 1481.7478048801422, "_timestamp": 1585598851.3806744, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.035527583211660385, "Value Loss": 0.002159198746085167, "_runtime": 1483.2827067375183, "_timestamp": 1585598852.9155762, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0274222269654274, "Value Loss": 0.0009123898344114423, "_runtime": 1484.8504362106323, "_timestamp": 1585598854.4833057, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025015203282237053, "Value Loss": 0.0013714005472138524, "_runtime": 1486.3732085227966, "_timestamp": 1585598856.006078, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041823990643024445, "Value Loss": 0.006251150276511908, "_runtime": 1487.8957183361053, "_timestamp": 1585598857.5285878, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03151993080973625, "Value Loss": 0.0016804673941805959, "_runtime": 1489.4193682670593, "_timestamp": 1585598859.0522377, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03928280621767044, "Value Loss": 0.0017886925488710403, "_runtime": 1490.941196680069, "_timestamp": 1585598860.5740662, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029526391997933388, "Value Loss": 0.0025306236930191517, "_runtime": 1492.4695451259613, "_timestamp": 1585598862.1024146, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0333031564950943, "Value Loss": 0.0034048298839479685, "_runtime": 1493.9989562034607, "_timestamp": 1585598863.6318257, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0253413338214159, "Value Loss": 0.0013298384146764874, "_runtime": 1495.5279428958893, "_timestamp": 1585598865.1608124, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025418145582079887, "Value Loss": 0.0012934341793879867, "_runtime": 1497.0548195838928, "_timestamp": 1585598866.687689, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03169829025864601, "Value Loss": 0.001967551652342081, "_runtime": 1498.589002609253, "_timestamp": 1585598868.221872, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03380754962563515, "Value Loss": 0.0005252458504401147, "_runtime": 1500.1213660240173, "_timestamp": 1585598869.7542355, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04018142446875572, "Value Loss": 0.010394732467830181, "_runtime": 1501.6549899578094, "_timestamp": 1585598871.2878594, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03247686102986336, "Value Loss": 0.00307391001842916, "_runtime": 1503.1867153644562, "_timestamp": 1585598872.8195848, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03228804096579552, "Value Loss": 0.0030433267820626497, "_runtime": 1504.7186524868011, "_timestamp": 1585598874.351522, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025158030912280083, "Value Loss": 0.001083218026906252, "_runtime": 1506.2577848434448, "_timestamp": 1585598875.8906543, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025280751287937164, "Value Loss": 0.0009689099970273674, "_runtime": 1507.8255543708801, "_timestamp": 1585598877.4584239, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.040650732815265656, "Value Loss": 0.004932386334985495, "_runtime": 1509.347810268402, "_timestamp": 1585598878.9806798, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0285979975014925, "Value Loss": 0.00259123626165092, "_runtime": 1510.8797607421875, "_timestamp": 1585598880.5126302, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028382442891597748, "Value Loss": 0.0029048193246126175, "_runtime": 1512.4118194580078, "_timestamp": 1585598882.044689, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028655264526605606, "Value Loss": 0.0026941464748233557, "_runtime": 1513.9428706169128, "_timestamp": 1585598883.57574, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032428499311208725, "Value Loss": 0.0013542877277359366, "_runtime": 1515.4778845310211, "_timestamp": 1585598885.110754, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03061877191066742, "Value Loss": 0.0012444198364391923, "_runtime": 1517.0086505413055, "_timestamp": 1585598886.64152, "_step": 456}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028539516031742096, "Value Loss": 0.0024827842134982347, "_runtime": 1518.531354188919, "_timestamp": 1585598888.1642237, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027579788118600845, "Value Loss": 0.0012305123964324594, "_runtime": 1520.065416097641, "_timestamp": 1585598889.6982856, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03255876898765564, "Value Loss": 0.003111321944743395, "_runtime": 1521.5984976291656, "_timestamp": 1585598891.231367, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04098593443632126, "Value Loss": 0.0061507136560976505, "_runtime": 1523.13067984581, "_timestamp": 1585598892.7635493, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03146412596106529, "Value Loss": 0.0019120358629152179, "_runtime": 1524.6636154651642, "_timestamp": 1585598894.296485, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02888915315270424, "Value Loss": 0.0022548690903931856, "_runtime": 1526.1973576545715, "_timestamp": 1585598895.8302271, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02629157342016697, "Value Loss": 0.0008078502141870558, "_runtime": 1527.7312095165253, "_timestamp": 1585598897.364079, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041516296565532684, "Value Loss": 0.007336108013987541, "_runtime": 1529.2529318332672, "_timestamp": 1585598898.8858013, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030013885349035263, "Value Loss": 0.0014898760709911585, "_runtime": 1530.814799785614, "_timestamp": 1585598900.4476693, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029766106978058815, "Value Loss": 0.002472190884873271, "_runtime": 1532.3518207073212, "_timestamp": 1585598901.9846902, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027834774926304817, "Value Loss": 0.0007310924120247364, "_runtime": 1533.8737106323242, "_timestamp": 1585598903.50658, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04113297164440155, "Value Loss": 0.009294665418565273, "_runtime": 1535.394014120102, "_timestamp": 1585598905.0268836, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.031139589846134186, "Value Loss": 0.0011140580754727125, "_runtime": 1536.9113585948944, "_timestamp": 1585598906.544228, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.037749387323856354, "Value Loss": 0.0007789615774527192, "_runtime": 1538.4320685863495, "_timestamp": 1585598908.064938, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043053340166807175, "Value Loss": 0.009045135229825974, "_runtime": 1539.9625301361084, "_timestamp": 1585598909.5953996, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.030302343890070915, "Value Loss": 0.0012178262695670128, "_runtime": 1541.490740776062, "_timestamp": 1585598911.1236103, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03286290913820267, "Value Loss": 0.0005335278692655265, "_runtime": 1543.014404296875, "_timestamp": 1585598912.6472738, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.028191890567541122, "Value Loss": 0.0014546712627634406, "_runtime": 1544.5340611934662, "_timestamp": 1585598914.1669307, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.043125029653310776, "Value Loss": 0.008973806165158749, "_runtime": 1546.053947210312, "_timestamp": 1585598915.6868167, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03615407645702362, "Value Loss": 0.0029958088416606188, "_runtime": 1547.5749564170837, "_timestamp": 1585598917.207826, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03000742197036743, "Value Loss": 0.0010888585820794106, "_runtime": 1549.0938007831573, "_timestamp": 1585598918.7266703, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032932497560977936, "Value Loss": 0.0015144131612032652, "_runtime": 1550.606166601181, "_timestamp": 1585598920.239036, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03462725132703781, "Value Loss": 0.0016091151628643274, "_runtime": 1552.164006471634, "_timestamp": 1585598921.796876, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032306086272001266, "Value Loss": 0.0025404696352779865, "_runtime": 1553.6907863616943, "_timestamp": 1585598923.3236558, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03580499067902565, "Value Loss": 0.0028875013813376427, "_runtime": 1555.2122733592987, "_timestamp": 1585598924.8451428, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03846065327525139, "Value Loss": 0.0017077961238101125, "_runtime": 1556.7316489219666, "_timestamp": 1585598926.3645184, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02937423624098301, "Value Loss": 0.0010775674600154161, "_runtime": 1558.254895210266, "_timestamp": 1585598927.8877647, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041071392595767975, "Value Loss": 0.004024785477668047, "_runtime": 1559.776010274887, "_timestamp": 1585598929.4088798, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03228875994682312, "Value Loss": 0.0006700874073430896, "_runtime": 1561.298573255539, "_timestamp": 1585598930.9314427, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.029280981048941612, "Value Loss": 0.0010789427906274796, "_runtime": 1562.8174130916595, "_timestamp": 1585598932.4502826, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03978796303272247, "Value Loss": 0.0015470043290406466, "_runtime": 1564.337660074234, "_timestamp": 1585598933.9705296, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03223532438278198, "Value Loss": 0.0010583437979221344, "_runtime": 1565.8607666492462, "_timestamp": 1585598935.4936361, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03025166690349579, "Value Loss": 0.0021984016057103872, "_runtime": 1567.3802778720856, "_timestamp": 1585598937.0131474, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041735660284757614, "Value Loss": 0.004374245181679726, "_runtime": 1568.8970651626587, "_timestamp": 1585598938.5299346, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.041596416383981705, "Value Loss": 0.0024381200782954693, "_runtime": 1570.4073367118835, "_timestamp": 1585598940.0402062, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02561783790588379, "Value Loss": 0.0013191713951528072, "_runtime": 1571.9305865764618, "_timestamp": 1585598941.563456, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.025437666103243828, "Value Loss": 0.0013222411507740617, "_runtime": 1573.4527566432953, "_timestamp": 1585598943.0856261, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03568512201309204, "Value Loss": 0.0006950145470909774, "_runtime": 1575.01136136055, "_timestamp": 1585598944.6442308, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.040059708058834076, "Value Loss": 0.008095597848296165, "_runtime": 1576.5331242084503, "_timestamp": 1585598946.1659937, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03204299136996269, "Value Loss": 0.0025311331264674664, "_runtime": 1578.05393075943, "_timestamp": 1585598947.6868002, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027653958648443222, "Value Loss": 0.0014463840052485466, "_runtime": 1579.5750935077667, "_timestamp": 1585598949.207963, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03180580958724022, "Value Loss": 0.00255304342135787, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 512.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "_runtime": 1581.0961315631866, "_timestamp": 1585598950.729001, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02711350843310356, "Value Loss": 0.0013684637378901243, "_runtime": 1581.0961315631866, "_timestamp": 1585598950.729001, "_step": 499}
